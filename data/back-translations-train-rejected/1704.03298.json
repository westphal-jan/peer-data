{"id": "1704.03298", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Apr-2017", "title": "The MATLAB Toolbox SciXMiner: User's Manual and Programmer's Guide", "abstract": "The Matlab toolbox SciXMiner is designed for the visualization and analysis of time series and features with a special focus to classification problems. It was developed at the Institute of Applied Computer Science of the Karlsruhe Institute of Technology (KIT), a member of the Helmholtz Association of German Research Centres in Germany. The aim was to provide an open platform for the development and improvement of data mining methods and its applications to various medical and technical problems. SciXMiner bases on Matlab (tested for the version 2017a). Many functions do not require additional standard toolboxes but some parts of Signal, Statistics and Wavelet toolboxes are used for special cases. The decision to a Matlab-based solution was made to use the wide mathematical functionality of this package provided by The Mathworks Inc. SciXMiner is controlled by a graphical user interface (GUI) with menu items and control elements like popup lists, checkboxes and edit elements. This makes it easier to work with SciXMiner for inexperienced users. Furthermore, an automatization and batch standardization of analyzes is possible using macros. The standard Matlab style using the command line is also available. SciXMiner is an open source software. The download page is", "histories": [["v1", "Tue, 11 Apr 2017 14:17:47 GMT  (2623kb,D)", "http://arxiv.org/abs/1704.03298v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ralf mikut", "reas bartschat", "wolfgang doneit", "jorge \\'angel gonz\\'alez ordiano", "benjamin schott", "johannes stegmaier", "simon waczowicz", "markus reischl"], "accepted": false, "id": "1704.03298"}, "pdf": {"name": "1704.03298.pdf", "metadata": {"source": "CRF", "title": "The MATLAB Toolbox SciXMiner: User\u2019s Manual and Programmer\u2019s Guide", "authors": ["Ralf Mikut", "Andreas Bartschat", "Wolfgang Doneit", "Jorge \u00c1ngel Gonz\u00e1lez Ordiano", "Benjamin Schott", "Johannes Stegmaier", "Simon Waczowicz", "Markus Reischl"], "emails": ["ralf.mikut@kit.edu"], "sections": [{"heading": null, "text": "The MATLAB Toolbox SciXMiner: User's Manual and Programmer's GuideRalf Mikut, Andreas Bartschat, Wolfgang Doneit, Jorge \u00c1ngel Gonz\u00e1lez Ordiano, Benjamin Schott, Johannes Stegmaier, Simon Waczowicz, Markus ReischlKarlsruhe Institute of Technology (KIT), Institute of Applied Informatics P.O. Box 3640, 76021 Karlsruhe, Germany Phone: + + + 49 / 721 / 608-25731, Fax: + + + 49 / 721 / 608-25702Email: ralf.mikut @ kit.eduVersion 2017a (12.04.2017) ar Xiv: 170 4.03 298v 1 [cs.L G] 11 Apr 201 7iiContentsContents ii"}, {"heading": "1 Motivation 1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 Installation 3", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3 Methods 4", "text": "3.1 Handling and functionality........................................................................................................................"}, {"heading": "4 Working with SciXMiner 9", "text": "??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????"}, {"heading": "5 Sample projects 19", "text": "Construction data.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "6 Menu items 32", "text": "In the second half of the year, the death toll will rise to more than 2,000, and in the second half of the year, the death toll will rise to more than 2,000."}, {"heading": "6.3.13 FFT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58", "text": "In the second half of 2008, the number of unemployed women increased by more than half. In the second half of the year, the number of unemployed women increased by 0.2 percent. In the second half of the year, the number of unemployed women increased by 0.2 percent."}, {"heading": "7 Control elements 75", "text": "..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "8 Feature extraction from time series 141", "text": "8.1 Definition of characteristic types by plugins................................................. 141 8.2 Standard plugins in SciXMiner..................................................................................................................................................................................................."}, {"heading": "9 Conclusions and perspectives 147", "text": "A Important file structures 148B Important internal data structures 150"}, {"heading": "C Needed Standard Toolboxes 152", "text": "E Included External Toolboxes (GNU License) 153"}, {"heading": "E Symbols and abbreviations 157", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "F Known errors and problems 158", "text": "History of G version 160 G.1 Versions......................................... 160 G.2 Selected changes between Gait CAD version 2014b and SciXMiner version 2016b.... 160 G.3 Selected changes between SciXMiner versions 2016b and 2017a......... 161"}, {"heading": "H Plugins 162", "text": "Bibliography 181"}, {"heading": "1 Motivation", "text": "The Matlab toolbox SciXMiner is designed for the visualization and analysis of time series and functions with a special focus on classification problems. It was developed at the Institute of Applied Computer Science of Karlsruhe Institute of Technology (KIT), a member of the Helmholtz Association of German Research Centres in Germany. The goal was to provide an open platform for the development and improvement of data mining methods and their applications for various medical and technical problems. SciXMiner is based on Matlab (tested for version 2017a). Many functions do not require additional standard toolboxes, but some parts of signal, statistics, and wavelet toolboxes are used for special cases. The decision to use a Matlab-based solution was made to use the broad mathematical functionality of this package, which is provided by The Mathworks Inc. MATLAB R \u00a9 and Simulink R \u00a9 are registered trademarks of The Mathense Works, Inc.SciXMiner is designed by a graphical user interface (GUI) and Simulink R \u00a9."}, {"heading": "2 Chapter 1. Motivation", "text": "This manual is structured as follows: Chapter 2 explains the installation process; Chapter 3 outlines the functionality of SciXMiner implemented, followed by some recommendations for working with SciXMiner. Analysis of two benchmark data sets is described in Chapter 5. Detailed information on using menu items (Chapter 6) and controls (Chapter 7) follows; Chapter 8 presents possible application-specific extensions for function extraction from time series; the appendix contains information on file formats (Appendix A), internal data structures (Appendix B), required standard toolboxes (Appendix C) and integrated GNU-GPL Matlab toolboxes of various groups (Appendix D); a list of symbols and abbreviations (Appendix E); and a list of known bugs and problems (Appendix F)."}, {"heading": "2 Installation", "text": "sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc.sc."}, {"heading": "3 Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Handling and functionality", "text": "Data mining methods are useful in the search for unknown or partially known connections in large data sets (KDD: Knowledge Discovery from Databases). A well-known definition is given by [30]: Data mining is a step in the KDD process, which consists in applying data analysis and discovery algorithms that generate a certain enumeration of patterns (or models) over the data. Pattern describes typical significant features in characteristics of the data set. This is an input variable for the data mining algorithm that is relevant to the data mining problem. In this manual, each input variable is considered a possible feature, as it can be helpful in solving the problem. Starting from a verbalized data mining problem, an adequate formalization must be found. This formalization influences, as does the collection of the training data set from a (external) database (i.e., by special import routines for AT94, as possible XD94)."}, {"heading": "3.2. Problem description 5", "text": "SciXMiner allows convenient handling of numerous algorithms for the \u2022 selection of data points (e.g. outlier detection, discarding of incomplete data points and characteristics, selection of data sets), \u2022 extraction of characteristics (e.g. spectrograms, FFT analysis, correlation analysis, linear filtering, calculation of extremes, averages, fusion, etc.), \u2022 evaluation of characteristics and their selection (e.g. multivariate variant analysis (ICA), \u2022 supervised and unsupervised classification (e.g. decision trees, cluster algorithms, classification calculators, application analysis (PCA), independent component analysis (ICA)), \u2022 unsupervised and unsupervised classification (e.g. matrix algorithms, Bayes classification boxes)."}, {"heading": "3.2 Problem description", "text": "A mandatory element to start a calculation is a training data set with n = 1,.., N data points, each containing \u2022 sz time series (matrices XTS [n] with xTS, r [k, n] HR, r = 1,..., sz, k = 1,.., K sample points), \u2022 s characteristics (vectors x [n] with xl [n], l = 1,., s) and \u2022 sy discrete output variables (vector y [n] with yj [n], j = 1,., sy).Here R is the set of real numbers and N + the set of natural numbers. Ordinary, interval scaled and rationally scaled characteristics can be processed. Ordinary characteristics are discrete in relation to the value in relation to the order scale (i. e. quantities with values such as very small, small, medium and large). The values do not contain information about the semantic characteristics of their spacing in the order scale."}, {"heading": "6 Chapter 3. Methods", "text": "In addition to other information such as a priori preferences for characteristics can be processed, mainly to generate static or quasi-static estimates for a data point (N + 1) = f (x [N + 1]) or (3.1) y-j [N + 1] = f (x [N + 1] (XTS [N + 1]))) (3.2) for a data point (N + 1) with an unknown output variable, as well as to generate intermediate results such as tables or catalogs of relevant features for specific problems. In addition, the management of multiple output variables (e.g. diagnoses of diseases in medical applications, treatment decisions, qualitative evaluations of treatment success, gender, age groups, etc.) for each data point can allow a flexible selection of multiple classification problems. In addition, input and output variables can be changed depending on the problem."}, {"heading": "3.3 Further reading", "text": "A comprehensive presentation of all the algorithms mentioned in this section cannot be made in this manual. Therefore, some examples for further reading are given: \u2022 Basic knowledge of multivariate statistics and classification [107, 69, 49] and specializations for time series [73], \u2022 Basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 Cluster algorithms and fuzzy C means (FCM): Basics: [46, 48], specializations for time series [64], \u2022 Decision trees (Basics: [16, 85], implemented design algorithms [50, 76], \u2022 Fuzzy systems (Basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12], specialties to improve interpretability [31, 76] \u2022 a priori relevance [114, 76], \u2022 Independent component analysis [117, 55, 61, 60], implemented design algorithms [50, 13, 76, 12], 88, support machines."}, {"heading": "3.3. Further reading 7", "text": "\u2022 alternative data mining software such as Weka [41], Knime [14], Apache Spark's Machine Learning Library [68], Keel [1], Rattle / R [112], see surveys in [77, 62, 39] Selected SciXMiner applications are listed in Table 3.1. Further details on parameterization can be found in the description of menu items (Chapter 6) and controls (Chapter 7)."}, {"heading": "8 Chapter 3. Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.4 Further toolboxes for classification (selection)", "text": "\u2022 PRTools (http: / / www.prtools.org /) University of Delft (Netherlands): Matlab Toolbox, e.g. Principal Component Analysis, Subspace Classifiers, Artificial Neural Networks, without GUI, free for academic use \u2022 NEFCLASS (http: / / fuzzy.cs.uni-magdeburg.de / nefclass /) University of Magdeburg (Germany): JAVA, e.g. Neuro-Fuzzy Classifiers, free for academic use"}, {"heading": "4 Working with SciXMiner", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Handling", "text": "SciXMiner's graphical user interface (GUI) includes menu items and control elements such as listboxes, checkboxes, and text fields. They are implemented with Matlab functions (uicontrol, uimenu), some of which are called by encapsulated SciXMiner functions with additional functionality, which use callback functions to exchange data with workspace variables and call functions that are independent of the GUI. Thus, Matlab-type programming is also possible using command prompt and variables, and the elements of the graphical user interface are described in the following sections."}, {"heading": "4.2 Import and export of projects", "text": "SciXMiner offers the possibility to import and export projects to and from ASCII files. The possible options are explained in the next two sections, focusing on the import and export of time series. Also, some differences in the export of individual features are explained."}, {"heading": "4.2.1 Import of data", "text": "The latter option is also available for existing subdirectories, but requires special naming conventions. To import time series, each data point is read from a separate file. It contains the time series in the columns and the sample points in the rows. For individual attributes, all data points are normally read from a file that contains the individual attributes in the columns and the data points in the rows. An import from multiple files is also possible to characterize different output classes by file and directory names. Fig. 4.1 shows the window for an import with File - Import Data - From a Directory.... The \"Search in Subdirectories\" option defines whether subdirectories are searched for matching files or not. The \"Write to Separate Projects\" option defines that separate SciXMiner projects are created for each import file."}, {"heading": "10 Chapter 4. Working with SciXMiner", "text": "Example: Importing three file endings:\\ prj\\ names\\ Anna\\ Post-therapeutic.txtd:\\ prj\\ names\\ Anna\\ Pre-therapeutic.txtd:\\ prj\\ names\\ Peter\\ Post-therapeutic.txt from a folder d:\\ prj\\ names and the file extension '*.txt' creates two terms for the first output variable (\"Anna,\" \"Peter\") and two terms for the second output variable (\"Pre-therapeutic,\" \"Post-therapeutic\").For file - data - import - from a file... the single file to be imported is selected through a standard window. Afterwards, a slightly different window is shown to specify the import, but the lower part of the window matches Fig. 4.1. Within a file, two different separators are expected for separating columns (e.g. tabs for different time series or individual features) and decimals (e.g. \"Point for German File: some\" 17.3)."}, {"heading": "4.2. Import and export of projects 11", "text": "The \"Import as\" option switches between importing individual features and importing time series. Various options exist: simultaneous import by the standard Matlab command (from the signal toolbox) is currently not possible; the \"Normalization of the length of time series\" option is only necessary if time series of different lengths are imported; SciXMiner assumes always identical lengths; various options exist: a resampling by the standard Matlab command (from the signal toolbox) to obtain the length of the longest time series; a filling of shorter time series with zeros or the last valid value; the last option \"Import with\" switches between different import techniques; the \"Normal mode\" generates a temporary file after a possible separation correction; it is usually the best version, especially for large files. \"Write copy and read again\" do the same line with a standard file function. \""}, {"heading": "4.2.2 Export of data", "text": "For the export of time series, each data point is written to a separate file, containing the time series in the columns and the sample points in the lines. Possible options are controlled by the window in Fig. 4.2. The target directory must be manually defined for compatibility with Matlab version 5.3 (due to the lack of a window to select directories), a copy from the clipboard is possible, and the target directory must exist. The file for each data point is essentially determined by the following options. \"Write output variables to subdirectories\" creates subdirectories for the first (n \u2212 1) output variables and encodes the n-th output variable in the file name. The file for each data point is stored in the directories and the file with the corresponding name. Otherwise, the file name is generated by all terms. The parts are separated by the delimiter defined by \"Separator for the output variables for the file name.\""}, {"heading": "12 Chapter 4. Working with SciXMiner", "text": "Exporting time series to the target directory d:\\ prj\\ names in a project with the output variables \"Names\" (terms: \"Anna,\" \"Maria,\" \"Thomas,\" \"Peter\") and \"Examination\" (terms: \"Pre-therapeutic,\" \"Post-therapeutic\") results in the following file structure using the option \"Write output variables in subdirectories\": d:\\ prj\\ names\\ Anna\\ Post-therapeutic.txtd:\\ prj\\ names\\ Pre-therapeutic.txtd:\\ prj\\ names\\ Post-therapeutic.txtd:\\ prj\\ names\\ Pre-therapeutic.txtd:\\ prj\\ names\\ Post-therapeutic.txtd:\\ prj\\ names\\ Pre-therapeutic.txtd:\\ prj\\ files:\\ print-therapeutic.s. \""}, {"heading": "4.2.3 Manual creation of SciXMiner projects", "text": "This section describes how to create a SciXMiner project file, either manually or semi-automatically, if a fully automatic import is not possible. An overview of the identifiers used by SciXMiner can be found in Appendix B.SciXMiner projects are binary Matlab files. These files contain variables and at least one of the following identifiers must be defined within the project file: \u2022 d _ orgs: contains project time series. 3D array with the dimension N \u00b7 K \u00b7 sz \u2022 d _ org: contains project features. 2D array with the dimension N \u00b7 s.N denotes the number of data points, K the number of sample points of the time series, sz the number of time series, and s the number of attributes (see Section 3.2). The most convenient way to use the function generate _ new _ scixminer _ projekt.N. This function supports the conversion of MATLAB variables in SciXMiner projects. If these elements are explained in the following text class and in the following order, each of which is different from the other."}, {"heading": "14 Chapter 4. Working with SciXMiner", "text": "This identifier contains a string matrix in which the number of lines matches the number of output variables, and the number of columns depends on the length of the output variables. A simple method of generating bez code is the built-in Matlab function strvcat. If bez code is not defined, the output variables are referred to as \"y1,\" \"y2...\" The classes of the output variables can also be named by an identifier, so the structure zgf _ y _ bez with the dimension sy \u00b7 max (my, i) is used."}, {"heading": "4.3 Automation of analysis", "text": "The most important strategic elements for the automation of analysis processes are \u2022 Macros,"}, {"heading": "4.3. Automation of analysis 15", "text": "You can avoid the input of data from a GUI by adding the following lines in a GUI: \"You add to the name of the current GUI project.\" \"You,\" it says in the message, \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"You,\" \"\" You, \"\" You, \"\" You, \"\" \"You,\" \"\" You, \"\" \"\" You, \"\" \"\" You, \"\" \"You,\" \"\" You, \"\" \"You,\" \"\" \"You,\" \"\" \"You,\" \"\" \"\" You, \"\" \"\" You, \"\" \"\" \"\" You, \"\" \"\" \"You,\" \"\" \"\" \"You,\" \"\" \"\" \"\" You, \"\" \"\" \"\" You, \"\" \"\" \"\" You, \"\""}, {"heading": "16 Chapter 4. Working with SciXMiner", "text": "All project, batch, macro, option, and m files can be written with absolute directory names. Relative directory names should be defined in the variable gaitcad _ extern.user. This strategy simplifies the modification of SciXMiner batch files with complex function calls, e.g. for transferring to a computer with a different folder structure. It supports both a project and macro directory as well as the current working directory (pwd).For example, the directories in a SciXMiner batch file named local _ directories.batch: gaitcad _ extern.user.project _ directory = 'd:\\ projects' gaitcad _ extern.user.user.macro _ directory = 'd:\\ macros versus macro.makro.makro.makro.makro.makro.makro.makro.makro.extern.user.user.user.user."}, {"heading": "4.4 Errors and warnings", "text": "Many errors and warnings in functions are displayed in a separate message box (see example of a warning message in Fig. 4.3). Three different options are available for a warning message: \u2022 \"Next\": The function continues. \u2022 \"Cancel\": The function is aborted. An error message \"Canceled by the user!\" is displayed in the Matlab command window. \u2022 \"Ignore all warnings\": It is similar to \"Next,\" but all future warning methods are ignored for the rest of the SciXMiner session."}, {"heading": "4.5 Generation of application-specific extension packages", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.5. Generation of application-specific extension packages 17", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "18 Chapter 4. Working with SciXMiner", "text": "with functions such as menu _ elements _ diagnosis.m (menu items), control _ elements _ diagnosis.m (controls), options _ fields _ diagnosis.m (position of controls), and callback function templates can be used to integrate custom functions with any parameters from the controls or available variables."}, {"heading": "4.6 Known errors and problems", "text": "The toolbox has been tested with Matlab 2017a. However, we may have missed one or two errors. To some extent, problems arise that are based on Matlab itself. In particular, many problems can be attributed to a lack of backward compatibility of Matlab, which leads to differences in the syntax of some commands and demands for lengthy commissions. In terms of activating and deactivating menu entries, we decided to enable some menu entries, although the recently selected parameters do not allow the execution of the underlying function. However, this allows the user to detect and correct his error. If the menu settings remain disabled until the correct parameters are selected, the user would have to try various combinations without obtaining an output. Errors in functions are usually caught by separate warnings and error messages. Possible settings in the Matlab editor \"Stop if Error\" or \"Known if Warning\" guide the user in case of warnings or errors, it is better to disable the source code for these problems in detail and for use in the Matlab."}, {"heading": "5 Sample projects", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Building data set", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1.1 Introduction", "text": "The purpose of the building dataset was to investigate the effects of different parameters on the power consumption of a known building [59]. It contains a single example with ten time series (e.g. year, month, day, hour, energy consumption, temperature) and without further characteristics. Time series are recorded for 175 days, 24 measurements per day (per hour). This dataset covers the following topics: \u2022 Splitting of time series and manipulation of data sets \u2022 Use of macros and plugins \u2022 Use of cluster algorithms The problem is the investigation and comparison of power consumption over a day.The subdirectory \"prj\" of the SciXMiner plant contains the building dataset as a SciXMiner project file (building.prjz)."}, {"heading": "5.1.2 Preparation of the data set", "text": "For the analysis of power consumption over a day, the time series must be divided into several data points, so that only the data of a single day is included in the time series. This is done via Edit - Convert - Separate time series with trigger events.... The time series is split in relation to a specific trigger signal. A typical application is the extraction of time series segments from long recordings. Examples of trigger events are the occurrence of errors, the start of a new measurement or external events. The trigger signal contains only zeros, except at the example points where a trigger event occurs. At these example points, the amplitude of the trigger signal corresponds to the linguistic concept of the output variable.Since this data set does not contain defined trigger events, a trigger signal must be generated first. There are three different options \u2022 Use of a graphic editor for a manual definition by editing - trigger time series or editing trigger series,"}, {"heading": "20 Chapter 5. Sample projects", "text": "The result is the same for all approaches: a time series that contains values not equal to 0 for trigger events. This time series is called trigger signal.In this project, the trigger events are extracted from a time series that contains the hours of a day.The trigger events are defined as sample points where the hour from 23 to 0.For completeness, we will consider all three approaches to extract the trigger events:"}, {"heading": "5.1.2.1 Graphical generation and editing of a trigger time series", "text": "A trigger time series can be created or edited using the window in Fig. 5.1. Details are explained in Edit - Create trigger time series. Fig. 5.1 shows four trigger events for example points 23, 47, 71 and 95 with two different classes for the output variable (weekend: 1 and working day: 2). The displayed time series show the \"hour\" and the \"energy.\" The time resolution is matched by the two fields in the lower left corner (left: length of the shown time series segment, here: 110, right: each n-th element is displayed, here: 1)."}, {"heading": "5.1. Building data set 21", "text": "The disadvantage of these methods is a very high manual effort for long time series. Consequently, the following two methods are better:"}, {"heading": "5.1.2.2 Extraction of trigger signal by use of macros", "text": "The following time series and extraction intervals are specific to each project: \u2022 Tools - q q o... \u2022 Edit - Extract - Time series, Time series - > Single features... \u2022 Select the time series \"Day,\" interval \"Whole time series\" and plugin \"Velocity\" (V.) Finish the selection by clicking \"OK\" \u2022 Tools - f macro recordThe content of the macro file is as follows:% MAKRO SELECT Z e i t i h e \u2212 > Z e i t r i h _ e, c i t r _ c. \""}, {"heading": "22 Chapter 5. Sample projects", "text": "The use of this macro by Tools - Play macro... leads to a new time series called \"Day V.\" The subdirectory \"prj\" of the SciXMiner installation contains the file of the macro (building _ trigger.makrog)."}, {"heading": "5.1.2.3 Extraction of trigger signal by plugins", "text": "Another approach to the extraction of a trigger signal is the use of plugins. A plugin is a function that is automatically included in SciXMiner. The related M file must be in the subdirectory \"\\ plugins\\ m generation.\" \"The code of a plugin for the extraction of the trigger signal is as follows (for a detailed description of the plugins we refer to Chapter 8): 1 f u n c i n [da tenOut, r e t, i n f o] = p l u n s p u n g (p a r a s, d a) e: t t t a n n n, c n e,\" z z z z r. \""}, {"heading": "5.1. Building data set 23", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1.2.4 Splitting of the time series", "text": "After extracting the trigger signal, the project is ready for conversion by editing - converting - separate time series with trigger events.... The options are shown as shown in the figure below (use \"Hours Jump\" as the time series when the trigger signal is extracted from the plugin).If the first option is set to \"Work Area\" instead of \"Time Series,\" variables from the workspace can be used as trigger signals. As the extraction of the individual attempts should start exactly at a trigger event and end 23 sample points after the trigger event (which results in 24 hours after the trigger event), the offset is set to [0, 23].Clicking \"OK\" will save the project with a new name and load it automatically, and the new project contains the same amount of time series (10) but 175 examples instead of 1 (or 174 after the trigger signal is extracted by the plugin)."}, {"heading": "5.1.3 Application of cluster algorithms", "text": "This section shows the application of clusters. It is applied to the time series \"Energy\" in the project, which contains the split time series. If you have not done the conversion of the time series described in the previous sections, please use the project \"building _ day.prjz,\" which is contained in the subdirectory \"prj\" of the SciXMiner installation. In the options window Controls: Time Series: General Options, the time series \"Energy\" is selected. The settings for the cluster algorithm are shown in Fig. 5.3.The clustering is started by clicking on Data Mining - Clustering - Design and Application. Once the calculation is complete, the result can be visualized by View - Clustering - Cluster memberships (sorted by data points) on weekdays (cluster 2, green) or weekends or Fridays (cluster 1, red)."}, {"heading": "24 Chapter 5. Sample projects", "text": "Data Mining: Clustering - Attaching clusters as output variables must be set to \"new cluster number\"): Set the output variable to the new one generated by using the cluster algorithm (Option window Controls: Time series: General options) and set the time series to \"Energy\" by clicking View."}, {"heading": "5.1. Building data set 25", "text": "Time Series (TS) - Original Time Series Each example of time series \"Energy\" is displayed as a single curve (see Fig. 5.5). The class averages of the time series are displayed by clicking View - Time Series (TS) - Middle Time Series. All commands are contained in the macrostructure _ cluster.macrog in the subdirectory \"prj\" of the SciXMiner installation."}, {"heading": "5.1.4 Time series prediction", "text": "In this example, all selected time series are used for regression. An example that uses linear regression coefficients for a feature preselection is later shown using the iris dataset. Previous day samples are used as features for regression (samples k \u2212 24, k \u2212 25,.., k \u2212 48). Normal Matlab syntax is allowed to edit the samples (e.g. -48: -24 or -72: -24: -168). Sample 0 is automatically removed from the vector to avoid trivial predictions.Necessary settings for the polynomial are the degree (here: 2, control: Data Mining: Special Methods - Polynomial degree) and the maximum number of internal features (here: 4, control: Data Mining: Data Mining value)."}, {"heading": "26 Chapter 5. Sample projects", "text": "By clicking on Data Mining - Regression - Design and application of the regression algorithm, the coefficients and a prediction of the time series are calculated. A graphical examination of the result can be achieved by the functions included in View - Regression (see Figure 5.7 for a scatter graph of the output variable and the estimate).The scatter graph contains all values of the output variable compared to the estimate of the output variable for all samples. A disadvantage of this diagram is the lost time information. However, since the prediction of the output variable is added to the project as a new time series, all built-in visualizations can be used, e.g. the visualization of the original time series compared to the predicted time series. To force SciXMiner to display both time series in the same subplot, the option Control-Element: View: Time Series - Show Time Series as subplots must be disabled."}, {"heading": "5.2.2 Classification", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.2.1 Introduction", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.2 Iris data set", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.2. Iris data set 27", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "150 data points 2 features ... Complete ...", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "28 Chapter 5. Sample projects", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.2.3 Regression", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.2. Iris data set 29", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "30 Chapter 5. Sample projects", "text": "In this example, the degree of the polynomial is set to 1 and the maximum number of internal features to 4 (see example using the Baudataset for a description of this option).The design and application of the regression is done by Data Mining - Regression - Design and Application. After leaving the algorithm, the command window contains: Fitness of regression: mean absolute value: 0.154808 Correlation coefficient between actual value and estimate: 0.964228 to get a first impression of the quality of the regression. The estimate of the \"flower width\" feature has been added as a new feature. Be sure to exclude the estimated feature from the list of used features for further regressions. Select a method for feature selection that contains \"selected features\" in the description (e.g. \"linear regression coefficients (multivariat, selected features).\" The output variable is automatically removed from the list of used features but not the selected ones."}, {"heading": "5.2. Iris data set 31", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6 Menu items", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Menu items \u2019File\u2019", "text": "This item covers all file operations."}, {"heading": "6.1.1 Load project", "text": "Required variables are \"d _ org\" or \"d _ orgs.\" In addition, the variables \"code,\" \"code _ alle,\" \"dorgbez,\" \"var _ bez,\" \"zgf _ y _ bez,\" \"bez _ code,\" \"options,\" \"project,\" \"interpret _ merk\" are read."}, {"heading": "6.1.2 Save project", "text": "stores the current SciXMiner project *.prjz under the same filename. This function stores the dataset (but without analysis results as designed classifiers) and optionally the current settings of the controls (if selected in controls: General Options)."}, {"heading": "6.1.3 Save project as...", "text": "stores the SciXMiner project file *.prjz under a new name (see File - Save Project)."}, {"heading": "6.1.4 Mean value project (based on the selected output variable)", "text": "generates a new SciXMiner project with average values for all linguistic terms of the selected output variable. In the new project, there is only one data point per linguistic term."}, {"heading": "6.1.5 Export data", "text": "The separators for columns and decimals can be selected in the opened configuration window. \u2022 Time series in multiple files...: The time series of the given project (variable \"d _ orgs\") are exported to different files. We assume at least one output variable. If more output variables exist, the first (n-1) output variable32"}, {"heading": "6.1. Menu items \u2019File\u2019 33", "text": "When building a directory structure, the information about the n-th output variable is encoded in the file name. Alternatively, all n output variables can be encoded in the file name by selecting the option \"Separator for output variables in the file name.\" \u2022 Individual features in a file...: The single feature of the given project (variable \"d _ org\") is exported as a file (all data points in a file)."}, {"heading": "6.1.6 Import data", "text": "It contains all functions for importing data from files. \u2022 From a directory...: imports data from a directory structure. Its definition is explained in Section 4.2 and for the menu item File - Export Data - Individual features in a file.... Parallel import of individual features and time series is impossible. Output variables should be included as individual features in the file and can be converted after import with Edit - Convert - Output variable. \u2022 From a file...: imports data from a file. Some import versions encode the output classes. Parallel import of individual features and time series is impossible. Output variables should be included as individual features in the file and can be converted into output variables after import. \u2022 From a file...: imports data from a file."}, {"heading": "6.1.7 Fusion of projects", "text": "contains functions for merging existing SciXMiner projects into a common project called fusion.prjz. It uses all projects from a directory that is selected via a configuration window. Incompatible projects are ignored."}, {"heading": "34 Chapter 6. Menu items", "text": "Other Time Series and Individual Features: Backup data from all SciXMiner projects in a directory by adding the data as new time series and individual features. The number of data points, length of time series and number and values of output variables must be identical for all projects. Example: SciXMiner project a.prjz with 5 data points, 2 time series, 1 single feature and 1 output variable SciXMiner project b.prjz with 5 data points, 2 time series, 1 single feature, and 1 output variable SciXMiner project b.prjz with 5 data points, 4 time series, 2 single features and 1 output variable. Additional data points: Backups from all SciXMiner projects in a directory, 2 time series, 1 single feature, 1 single feature."}, {"heading": "6.1.8 Apply SciXMiner batch file", "text": "executes a SciXMiner batch file with the extension *.batch. It can contain one or more projects or even directories with projects. Optionally, a file with a list of controls with the extension *.uihdg is loaded under File - Options - Load. For each of these projects, a list of macros is executed. A recursive definition with other batch projects is possible."}, {"heading": "6.1. Menu items \u2019File\u2019 35", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1.9 Apply SciXMiner batch file (debug mode)", "text": "Like File - Apply SciXMiner batch file, but with a stop after errors and warnings. This option is useful for debugging SciXMiner batch files. After a stop, processing can be continued with Return."}, {"heading": "6.1.10 Apply SciXMiner batch file (step and debug mode)", "text": "How to File - Apply SciXMiner batch file (debug mode), but with an additional step-by-step execution of each macro in a SciXMiner batch file (continued with Return)."}, {"heading": "6.1.11 Normative data", "text": "Normative data is defined by means and standard deviations for all time series and individual characteristics. It can be used for comparison with a freely definable reference value (e.g. for typical plant behavior). \u2022 Load normative data: loads normative data (mean and standard deviation) for time series and individual characteristics from a '*.norm' file. \u2022 Save authority data: stores normative data (averages and standard deviations) for time series and individual characteristics in a '*.norm' file. Specifically, the variables' dorgbez, '' mstd _ em, '\"my,''my _ em,' parameters, '' titleline, '' var _ bez 'are stored in a' normative 'file. This function requires the execution of file - normative data - mean for selecting authority data for the newer data (\" parameters, \"\" titleline, \"\" \"var _ bez\")."}, {"heading": "6.1.12 Data mining", "text": "This menu item contains functions for loading and saving parameters from conceived data mining systems. \u2022 Load fuzzy system: loads a conceived fuzzy system from a file with the extension \"*. fuzzy.\" The assignment of input (individual features) and output variables is based on the variable names. The file must contain the variables \"gaitcad _ struct,\" \"features _ project\" and \"mode.\" Using files from other projects leads to misleading results, especially with identical variable names. The loaded fuzzy system is not yet directly usable as a fuzzy classifier."}, {"heading": "36 Chapter 6. Menu items", "text": "The results are stored in the variables \"gaitcad _ struct,\" \"features _ project\" and \"mode.\" \u2022 Export ANSI C code fuzzy rulebase: exports the recent fuzzy rulebase in a c file. This C file needs a pointer to a vector x that contains the selected input variables (individual features) and to a pointer of the input variables. The numbers of the input variables are explained in the function header. Output of the function is the linguistic term for the output variables: \"output variables.\" The function starts with x [0] instead of x."}, {"heading": "6.1.13 Options", "text": "contains all functions for loading and saving SciXMiner options.6.2. Menu items \"Edit\" 37 \u2022 Load options: restores all options for the controls as defined in the loaded option file with the extension *.uihdg. \u2022 Save options: saves all options for the controls and command lines of the plugins into an option file with the extension *.uihdg. \u2022 Save default options: saves all options for the controls and command lines of the plugins into an option file with the extension standard _ options.uihdg. This file is loaded every time SciXMiner starts. \u2022 Load frequency list: loads a MATLAB file for defining frequency ranges and overtones. 6.1.14 leaves the application."}, {"heading": "6.2 Menu items \u2019Edit\u2019", "text": "contains all functions for editing a dataset. It includes the selection of data points, time series and attributes, the extraction of new attributes from time series or other attributes, multiple conversions, deletion functions and data preprocessing operations."}, {"heading": "6.2.1 Select", "text": "contains functions for selecting data points, individual characteristics and time series. \u2022 All data points: selects all data points and removes any selected selection of data points. \u2022 Data points with classes...: performs a selection of data points by connecting and separating linguistic terms from output variables. It contains 1. a separation of all selected terms of an output variable and 2. a connection of the data points thus selected for all output variables. A selection of \"ALL\" means that no data point is excluded due to its value for this output variable. The result should be evaluated using View - classes for selected data points. \u2022 Data points with numbers...: allows a manual selection of data points using its numbers. \u2022 Data point from the GUI: selects the data points defined by the control: General Options - Manual selection of data points. This function is particularly useful when the data point numbers are known for a desired selection."}, {"heading": "38 Chapter 6. Menu items", "text": "\u2022 Random data points (defined percentage of selected data points): Selects a predefined percentage of selected data points by random. The percentage is defined by control: General options - Percentage for selection. \u2022 Data points by most common terms: Selects all data points belonging to common terms for the selected output variable. The minimum number of data points is defined by control: Data pre-processing - Minimum number of data points in a class.Example: 100 data points for o.k., 50 data points for error type A, 2 data points for error type B; parameter 10; Selection of 150 data points for o.k. and error type A \u2022 Data points by values of single characteristics: Selects all selected data points with logical true values in the control: Data pre-processing - function values for selection for the first selected single element. Multiple queries must be performed step for selecting values of all values."}, {"heading": "6.2.2 Extract", "text": "contains all functions for extracting time series from time series and individual features from time series or other individual features. \u2022 Time Series \u2192 Time Series, Time Series \u2192 Individual Features...: opens a configuration window to extract new time series or individual features from existing time series by selecting the existing time series, segment and type of extracted function. Extraction is done by plugins (see Section 8.1)."}, {"heading": "6.2. Menu items \u2019Edit\u2019 39", "text": "\u2022 Time Series \u2192 Time Series, Time Series \u2192 Individual Features (via plugin sequence)...: similar to Edit - Extract - Time Series \u2192 Time Series, Time Series \u2192 Individual Features..., but with a predefined sequence of plugins for extraction. In the configuration windows, only the existing time series and segments are selected. Feature Extraction uses the sequence of plugins defined by control element: Plugin Sequence - Selection of Plugins. \u2022 Individual Features (with the selected feature aggregation from Options-Data Mining: Classification of Individual Features): Extracts new individual features from existing individual features. It uses the parameters for feature selection and aggregation of plugins. All temporary results are deleted. \u2022 Individual Features (with the selected feature aggregation from Options-Data Mining: Classification of Single Features): Extracts new individual features from existing features."}, {"heading": "6.2.3 Convert", "text": "contains all functions for converting time series, individual attributes, classes and data points to each other. \u2022 Selected Individual Features \u2192 Output Variables: converts the selected individual attributes to output variables. The same values are used as linguistic values if the attributes have discrete values with no more than a defined maximum number (defined by control: Individual Features - Number of terms for individual attributes \u2192 Output Variable) or if the option Control: Individual Features - All Values has been selected. Otherwise, the term name depends on the maximum of the fuzzy membership function (e.g. \"approx. 7.5\"). \u2022 Selected Individual Features \u2192 Time Series: The number of values is determined by control: Individual Features - Number of terms for individual attributes \u2192 Output Variable. The term name depends on the maximum of the fuzzy membership function and a subsequent generation of crisp memory functions."}, {"heading": "40 Chapter 6. Menu items", "text": "\u2022 Selected Individual Features (Timestamp) \u2192 Individual Features (Year, Month, Day, Hour, Minute, Second): assumes that the selected Individual Feature is a MATLAB Timestamp. This function generates new Individual Features with numbers for the year, month, day, hour, minute and second. \u2022 Selected Individual Features (Timestamp) \u2192 Day of the Week: assumes that the selected Individual Feature is a MATLAB Timestamp. The result is converted into a new output variable containing the weekday. \u2022 All Individual Features: Data Point \u2192 Time Series: The function assumes a chronological order of all Data Points. Data Points of all Individual Features are converted into sample Time Series Points. Existing Time Series are deleted. These functions allow visualization of Data Points as Time Series. Example: A project consists of 100 Data Points and 2 Individual Features. The function generates a project consists of 100 Data Points and two Individual Points."}, {"heading": "6.2. Menu items \u2019Edit\u2019 41", "text": "\u2022 All Time Series: Example Points \u2192 Data Points: convert the sample points of all time series into data points of individual features. \u2022 The number of sample points is stored as a new feature. All individual features of the old project are deleted. The results are stored as a new project. \u2022 This allows a classification of time series with a separate class assignment of each example point. This function is a reverse function for Edit - Convert - All individual features: Data Point \u2192 Time Series. Example: A project consists of 1 data point with 2 time series and 100 example points. The menu items Edit - Convert - All Time Series: Example Points \u2192 Data Points create a new project without time series but with 3 new single time series and the number of data points. \u2022 Time Series \u2192 Data Points: process Time Series are converted into data series."}, {"heading": "42 Chapter 6. Menu items", "text": "This function is called \"Estimation.\" This menu item can be selected if a valid classification variable exists. \u2022 Estimated output variable converts the result of the last classification into a new discrete single attribute. This attribute is called \"Estimation.\" This menu item can be selected if a valid classification variable exists. \u2022 Estimated output variable (percentage) \u2192 Single attribute: converts the estimated percentage of member values (as a result of the last use of a classifier)."}, {"heading": "6.2. Menu items \u2019Edit\u2019 43", "text": "\u2022 Clean up all variable names (start and end spaces): Deletes end spaces in the names of output variables, time series and individual attributes."}, {"heading": "6.2.4 Delete", "text": "Deletes data points, time series, individual features or output variables. \u2022 Selected data points: deletes all selected data points. Finally, the data points are renumbered. \u2022 Unselected data points: deletes all unselected data points. \u2022 Selected data points: deletes all selected time series. \u2022 Unselected time series: deletes all unselected time series. \u2022 Unselected example points: deletes all selected example points from all time series. \u2022 All individual features: deletes all selected time series. \u2022 Unselected time series: deletes all unselected time series. \u2022 Unselected example points: deletes all unselected example points from all time series. \u2022 All individual features: deletes all individual features."}, {"heading": "44 Chapter 6. Menu items", "text": "The preference is controlled by the threshold in the Data Preprocessing - Threshold to Delete [Percentage of Missing Data] control. Example: Threshold 20% 1. All time series with missing values for more than 20% of the data points will be deleted. 2. All individual features with missing values for more than 20% of the data points will be deleted. 3. All remaining data points with missing values will be deleted. Hint: Misleading defaults for missing values of a single feature (e.g. -1) can be set to NaN values using a macro for consistent handling."}, {"heading": "6.2.5 Sorting", "text": "alphabetically sorting the names in a project (i.e. very useful for merging projects with identical variable names in different order). \u2022 Individual features: sorts individual attributes in a project alphabetically. \u2022 Time Series (TS): sorts time series in a project alphabetically. \u2022 Output variables: sorts output variables in a project alphabetically. \u2022 Images: sorts images in a project alphabetically."}, {"heading": "6.2.6 Outlier detection", "text": "Creates a classifier to detect outliers for the selected individual characteristics and data points. It can be applied to unknown data points. Some hints about the algorithms are given in [19]. \u2022 Design data set (selected data points, options from the classification): Outlier detection is based on a single-class classification problem. It decides whether a data point belongs to that one class or not. However, the implemented methods for feature selection and classification are based on data points that comprise at least two classes. \u2022 Design (selected data points, designed data set): Designs a classifier for outlier detection. This step uses the data set prepared by Edit - Outlier Detection - Design data set (selected data points, designed data sets): Designs a classifier for outlier detection. This step uses the data set in the Data Mining control element: Normally select data points for classification - single characteristics."}, {"heading": "6.2. Menu items \u2019Edit\u2019 45", "text": "The single-class method uses an SVM optimization proposed by [23]. The distance-based method calculates the mean and standard deviation for the selected data points and uses the Mahalanobis distance as a criterion. The density-based method evaluates the number of data points in a predefined neighborhood. \u2022 Apply (selected data points, designed dataset): applies the classification design by editing - Outlier detection - design (selected datasets, designed datasets) for outlier detection. The parameter in the control: Data preprocessing - Threshold for outliers adjusts the threshold for this decision. The value of the control: Data preprocessing - Save result as output variable determines whether the result is added as a new output variable. Through the menu item Edit - Outlier detection - Compile class discriminating functions (selected datasets, selected datasets) all datasets are applied."}, {"heading": "6.2.7 Category", "text": "Categories summarize similar individual characteristics and time series for different analysis and visualization functions (see Section 8.5, [64]). They classify individual characteristics and time series into different output classes of several output variables, so-called categories (e.g. by sensor type or by type of feature extraction). Matching is done by category files with the extension *.category. \u2022 Select individual characteristics...: enables the selection of individual characteristics by linking or separating several categories and their linguistic terms. The function assumes calculated categories using Edit - Category - Compress individual characteristics. \u2022 Compress individual characteristics: Assigns categories to all existing individual characteristics using their names. For safety reasons, the categories are deleted when the number of individual characteristics is changed (by adding or deleting individual characteristics)."}, {"heading": "46 Chapter 6. Menu items", "text": "\u2022 calculate a priori relevance: calculates a priori relevance of individual characteristics using existing categories. \u2022 a priori relevance of selected characteristics...: sets a priori relevance for all selected individual characteristics to a defined value. \u2022 Selection of time series...: allows a selection of time series by linking or separating several categories and their linguistic terms. The function presupposes computed categories using editing - Category - Calculate time series. \u2022 Calculate time series: allocates categories for all existing time series using their names. For safety reasons, the categories are deleted when the number of time series is changed (by adding or deleting time series). \u2022 Search time series relating to the selected individual characteristics: selects all time series belonging to the selected characteristics. The criterion is an extraction of the selected individual characteristics from the associated time series."}, {"heading": "6.2.8 Rename...", "text": "This function opens a window to rename time series, individual attributes, output variables and the corresponding linguistic terms (possible discrete values). The upper element is used to select the type of variable to be renamed. In the lower element, a time series, a single feature or output variable is selected, which is represented by the (old) name. For linguistic terms, an additional element is shown to the selected term. The new name must be written in the bottom element and saved by pressing ENTER.The corresponding figure shows Figure 6.1."}, {"heading": "6.2.9 Generating trigger time series", "text": "The upper part of the figure shows time series and existing trigger events (red, dotted thin lines). The selection of time series is made in the element in the lower right corner of the figure. The class number for a trigger event is located at the trigger line. The default value is One. The time series window can be zoomed through two controls in the lower left corner (left element: length of the time series segment, right: each nth point is displayed) The grid is switched on or off by the corresponding element. The slider below the time series allows a time shift. A click on the time series part of the window selects a new pattern point (black dashed line). For this pattern point, a new trigger event is added by clicking on the \"Add\" button. The list of the last trigger events is displayed with the syntax pattern point (class), e.g. \"Import a point = 23\" and the pre-click is deleted."}, {"heading": "6.3. Menu items \u2019View\u2019 47", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.2.10 Edit trigger time series", "text": "edits an existing trigger time series selected via the control: Time Series: General Options - Time Series Selection (TS). An incorrect selection results in an error message or a time series with many trigger events. Handling is explained in Edit - Create Trigger Time Series."}, {"heading": "6.2.11 Looking for missing data", "text": "searches for missing values and displays the results for time series vs. data points and individual features vs. data points. See Edit - Delete - Missing data to define missing values."}, {"heading": "6.3 Menu items \u2019View\u2019", "text": "contains all visualization functions including many results of the applied algorithms."}, {"heading": "6.3.1 Classes for selected data points", "text": "displays the selected data points with their output variables as a text file."}, {"heading": "48 Chapter 6. Menu items", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.3.2 Number of terms for selected data points", "text": "shows the number of terms for each output variable and all selected data points. Only common terms are listed in detail, terms with one or two data points are only summarized. This function is suitable for large projects, because unlike view classes for selected data points, not all rare terms and data point descriptions are listed. The result is stored in a file named [project _ name] _ ind _ terms.txt."}, {"heading": "6.3.3 Time series (TS)", "text": "Displaying time series (control element: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series: Time series:"}, {"heading": "6.3. Menu items \u2019View\u2019 49", "text": "\u2022 Poincare Plot Time Series (3D): Display the selected time series as 3D Poincare Plot (x-axis: x [k], y-axis x [k + 1], z-axis x [k + 2]). The following times can be displayed as connected or unconnected points, depending on the selection in the control: View: Time Series - Poincare Plot: Connecting Points. \u2022 Transformation vectors for feature extraction: determine whether data-dependent transformations for feature extractions are calculated from the current data, saved and / or loaded from a file. The main difference is in the handling of e.g. member functions or a main component analysis. Storing in a file is necessary for a design with a training dataset and later use for test data using the same parameters. The data is stored in a file named [Project Name]."}, {"heading": "6.3.4 Single features", "text": "contains all functions for visualizing individual characteristics and their derived characteristics. \u2022 Individual characteristics vs. output classes: displays terminological histograms for the first selected individual characteristic on the x-axis versus the number of corresponding linguistic terms of the selected output variables on the y-axis. \u2022 Individual characteristics vs. individual characteristics: displays a scatter graph of the selected individual characteristics. The functions show paired scatter diagrams (x2 = f (x1), x4 = f (x3), etc.) when more than three characteristics have been selected. \u2022 Manual class assignment by individual characteristics: allows interactive assignment of linguistic terms of output variables or the selection of data points with a figure containing two selected output variables. Here an image with different options opens in the menu bar. \"Mark\" contains all operations for handling a list of interactively selected data points. \"This list will be initialized as a list of\" Dependent \"to the following menu items."}, {"heading": "50 Chapter 6. Menu items", "text": "Alternatively: \"Change: Term of the output variable\" can assign new linguistic terms to all visible data points for the selected output variable \u2022 single view features for the selected output variable (\"New term\") are available able.The figure can be opened different times with different single features \u2022 Refresh \"updates all open figures with the new linguistic terms or the entry of the list. \u2022 Discrete single features (2D histogram): shows a two-dimensional histogram for the first two single features are generated if the single features are continuous values or if the single features have continuous values or if only one or if only single feature have been selected single feature. \u2022 Discrete single features of the output features with output class): shows a two-dimensional histogram for two selected single features. In contrast to View - Single features (2D histogram), separate bars are shown for different terms of the output variable."}, {"heading": "52 Chapter 6. Menu items", "text": "\u2022 Show feature relevance (unsorted table): Shows all calculated feature relevance sorted by descending relevance values. \u2022 Show feature relevance (unsorted table): Shows all calculated feature relevance sorted by ascending feature numbers. \u2022 Add feature relevance to an archive: stores the current feature relevance to an archive, e.g. to compare different methods of feature evaluation. This archive can be saved as a separate SciXMiner project under View - Individual Features - Archive with feature relevance. \u2022 Save the current archive with feature relevance as a separate SciXMiner project ([Project Name '_ feature _ releances.prjz'). In this SciXMiner project, the individual feature relevance is displayed as an output variable and the values of the feature relevance are stored as individual feature relevance."}, {"heading": "6.3.5 Single features (multivariate)", "text": "groups multidimensional visualizations for individual characteristics. \u2022 Parallel coordinates: draw the selected individual characteristics in the form of parallel coordinates. \u2022 Andrews diagram: draws the selected individual characteristics as \"Andrews diagram.\" \u2022 Glyphs diagram: draws a glyphs diagram of the selected characteristics. \u2022 Heatmap: draws a heat map of the selected individual characteristics."}, {"heading": "6.3.6 Classification", "text": "contains all functions for visualizing the classification results. \u2022 Result: shows a scatter graph of the last classification result in the (optional aggregated) feature space of the classifier. The type of linguistic terms selected (e.g. real class assignment, classifier result, another control-defined output variable: view: individual features - different output variable, etc.) can be toggled through the options in the control: view: classification and regression - display classes for output variables. \u2022 2D classification with covariance matrices: such as view - classification - result, but adds estimated covariance matrices for the linguistic terms of the output variable. This menu item is only available if a Bayes classifier was used."}, {"heading": "6.3. Menu items \u2019View\u2019 53", "text": "\u2022 2D plot classifier with support vectors: like view - classification - result, but marks support vectors with triangles. This menu item is only available if a support vector machine was used as classifier. \u2022 ROC curve...: calculates a receiver-operating-characteristic curve (ROC curve) and shows all possible compromises between sensitivity and specificity in relation to the classification decision for a selected linguistic term of the output variable. This term is chosen by a separate configuration window. \u2022 Tuning parameter for the ROC curve is gradual class membership for a decision of the last used classifier. \u2022 Time series classification error vs. time: shows the classification error of a time series classification vs. time. \u2022 Used features of the time series classifier: shows an image with the selected time series series series series series series series (marked by points) of a time series classifier vs. time."}, {"heading": "6.3.7 Regression", "text": "\u2022 Output variable and estimation: shows the output variable of the regression versus the estimate by the regression model. \u2022 Output variable and error: shows the output variable of the regression versus the estimate by the regression model. \u2022 Output variable and error: shows the output variable of the regression versus the regression error. \u2022 Input variable (s), output variable and regression function (2D or 3D): shows the function of the estimated regression model. It is additionally compressed by a grid of additional data points. The number of data points is defined by control: View: Classification and regression - Number of grid points. The grid is tuned for the analysis of the interpolation and extrapolation behavior. In addition, the values of the input variables versus the output variables are displayed as a scatter plot during the design. If a normalization or aggregation of the features is selected, the input function of the 3D can be visualized."}, {"heading": "54 Chapter 6. Menu items", "text": "The input parameters on the left can be set to a constant value by typing the value into the field. This visualization works according to the same principles as View - Regression - Input Variable (s), Output Variable (s) and Regression Function (2D or 3D). In addition, the region for the scatter plot can be defined with the columns \"Min:\" and \"Max:.\" The function is only available for existing regression models with more than two inputs. \u2022 Generate Macro for Multi-dimensional Visualization: Creates and opens a macro for 3D visualization of a regression model. Further information on handling can be found within the macro. \u2022 Apply Macro for Multi-dimensional Visualization: Execut the macro generated by View - Regression: Mression - Generate macro for Multi-dimensional Visualization. Alternatively, the macro can be started via Exhisional Regression. \u2022 The coefficient structure is the current structure for the polynoable *."}, {"heading": "6.3.8 Aggregated features", "text": "include all functions for visualizing aggregated individual characteristics. It contains the transformation matrices for dimension reduction and the associated membership functions for the aggregated individual characteristics. \u2022 eigenvectors and transformation vectors: shows the factor charges or weights of the individual characteristics for generating the aggregated characteristics. A different color is selected for each aggregated characteristic. \u2022 Factor charges (2D property vectors or transformation vectors): draws the elements of the first two transformation vectors for characteristic aggregation as a scatter chart in a two-dimensional space. \u2022 Membership function: diagrams for each aggregated characteristic include a figure with the membership functions for all linguistic terms. \u2022 Membership function and overall histogram: such as View - Aggregate characteristics - Membership function, but with separate subimages that contain an additional histogram for each selected data point. \u2022 Membership function and view - histogram: such as View - Membership function."}, {"heading": "6.3. Menu items \u2019View\u2019 55", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.3.9 Output variables", "text": "contain all functions for visualizing output variables. \u2022 Qualitative output variables: record the selected output variable against the number of associated data points. \u2022 2D histogram...: shows the distribution of two output variables as histograms. Both output variables are selected through a configuration window. \u2022 Term number of the output variable: writes the number of selected data points for all linguistic terms of the output variable to a log file."}, {"heading": "6.3.10 Spectrogram", "text": "\u2022 Calculation and representation: calculates and displays a separate spectrogram for each selected data point and each selected time series. Each spectrogram is normalized to values between zero and one (see View - Spectrogram - Calculation and representation (mean for selected data points) or View - Spectrogram - Calculation and representation (mean for selected class) for means of spectrograms. A warning is displayed for a very large number of spectrograms based on many selected data points. In many cases, the interpretability of spectrograms could be improved by adjusting the selection of the control element: View: Spectrogram, FFT, CCF - function for color bars and associated parameters. This controls the color scaling especially to a finer resolution for lower amplitudes. The compromise between time and frequency resolution is adjusted by the control element: View: Spectrogram, FFT, CCF - window size [sample elements]."}, {"heading": "56 Chapter 6. Menu items", "text": "\u2022 Calculate and Show (Mean for selected data points): first calculates a separate spectrogram for each selected data point and each selected time series. Each spectrogram is normalized to values between zero and one. In the next step, the mean is calculated over all data points of the calculated spectrograms and finally displayed. The resulting \"mean spectrogram\" gives only a qualitative impression due to the artifacts caused by separate normalization. \u2022 Calculate and Show (Mean for selected class): similar to View - Spectrogram - Calculation and Display (Mean for selected data points), but with separate averages of the spectrograms for all existing classes of the selected output variable."}, {"heading": "6.3.11 Morlet spectrogram", "text": "contains all functions for visualizing morlet spectrograms. \u2022 Calculate and display (selected data points and time series): Calculates new time series for the selected time series by folding with complex morlet waves. \u2022 After folding, the new time series are filtered by an IIR filter. IIR parameters are defined by control element: Time series: Extraction - Parameter - Parameter - Parameter IIR filter. Results are displayed as tree-dimensional diagrams (x-axis: Time, y-axis: Frequency, Color: Coefficient of the filtered signal). Frequency range of the morlet wave series is defined by control element: Time series: Extraction - Parameter - Frequencies (FIL, Morlet spectrogram) and control element: Time series: Extraction - Parameter - Morlet wave frequency. The parameters describe the lower and higher limit. Control element: Spectrogram - F- classes: FT, FT - can be used."}, {"heading": "6.3.12 Cross and Auto Correlation Functions", "text": "contains all functions for displaying cross and autocorrelation functions. \u2022 Separated for each data point: Calculation and display of autocorrelation functions for each selected data point. The selection of time series takes place in a separate configuration window with two fields."}, {"heading": "6.3. Menu items \u2019View\u2019 57", "text": "Multiple selection of time series is possible. See also View - Cross and Auto Correlation Functions - Mean for selected data points and View - Cross and Auto Correlation Functions - Mean for selected data points and View - Cross and Auto Correlation Functions - Separately for each data point, but with a calculation and visualization of a short-term correlation analysis. The lengths of the time window are selected in the control element: View: Spectrogram, FFT, CCF - Window Size [Sample points]. This function provides an overview of time variant correlations. \u2022 Mean values of correlation of correlation of correlation (defined time shift): similar to control element: spectrogram, FFT, CCF - converted data maps."}, {"heading": "58 Chapter 6. Menu items", "text": "\u2022 Correlation function for different data points and selected time series (mean): such as view - cross and autocorrelation functions - correlation function for different data points and selected time series, but averages for the correlation functions are calculated. As a result, only one function is generated for each time series. \u2022 Correlation coefficients for selected data points and time series (predefined time shift tau): such as view - cross and autocorrelation functions - correlation function for different data points and selected time series, but the data points are selected through the main window. \u2022 Mean correlation coefficient is calculated for each combination of data points and a predefined time shift tau. The result is displayed as a color matrix. Hereby, the correlation coefficient of a type according to the control: Data Mining: Statistical options - type for correlation parameters. \u2022 Mean correlation coefficient is used via time series for selected data points and time series (defined time shift T- mean view and autocorrelation functions)."}, {"heading": "6.3.13 FFT", "text": "\u2022 Calculate and show FFT (selected data points and time series): calculate an Fast Fourier Transformation (FFT) for all selected time series and data points and draw the results. The control: View: Spectrogram, FFT, CCF - Plot FFT vs. Period Length (instead of Frequency) toggles between Chart vs. Period Length and Frequency (default value). \u2022 Show dominant frequencies (sorted by amplitude): Show the most dominant frequencies of the FFT sorted by amplitudes. The number is defined under Control: View: Spectrogram, FFT, CCF - Number of dominant frequencies for visualization. \u2022 Show dominant frequencies of the FFT sorted by amplitudes."}, {"heading": "6.3.14 Fuzzy systems", "text": "contains all functions for visualizing a fuzzy system conceived by Data Mining - Fuzzy Systems - Design (single rules), Data Mining - Fuzzy Systems - Design (rule base) or by a selected fuzzy classifier. \u2022 Show rules (with variable names): Displays a list of current fuzzy rules. It results from loading a rule base from a file, generating individual rules or rule bases. The input and output variables are written in the form of variable names."}, {"heading": "6.3. Menu items \u2019View\u2019 59", "text": "\u2022 Show rules (with variable numbers): such as View - Blurred Systems - Show rules (with variable names), but use the number of input variables and a symbolic output variable y. \u2022 Show rules (Figure): Show blurred rules with a maximum number of three input variables in one figure. The corresponding figure shows Figure 6.2."}, {"heading": "6.3.16 Clustering", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.3.15 Decision tree (LaTeX)", "text": "60 Chapter 6. Menu items \u2022 Clustergram: Calculates a two-dimensional cluster formation for the selected individual features and data points. This command executes the function \"Clustergram\" of the MATLAB Bioinformatics Toolbox."}, {"heading": "6.3.17 Self Organizing Maps...", "text": "contains all functions for visualizing Self Organizing Maps. \u2022 Positions: shows the positions of the weight vectors of Self Organizing Maps in the (single) feature space (for 2D with the MATLAB function plotsompos.m). \u2022 Hits: shows the number of hits per neuron for Self Organizing Maps (based on the design)."}, {"heading": "6.3.18 Data point distances", "text": "contains all functions for calculating data point spacing. \u2022 Calculation (selected data points): Calculation of pair-wise distances between all selected data points. Here, the Frobenius standard is applied to all selected individual characteristics. In addition, an optional normalization is used, which is defined by the control: Data Mining: Classification of individual characteristics - normalization of individual characteristics. \u2022 Calculation (selected data points vs. manual selection): Calculation of pair-wise distances between all selected data points in the control: General options - Manual selection of data points. \u2022 Calculation (search for neighbors of the first element of the manual selection): Calculation of the nearest neighbors for the first data point in the control: General options - Manual selection of data points using the data point spacing to the selected data points. \u2022 Sort (VAT algorithm): Resort (search for neighbors of the first element of the manual selection): Resources in the chart based on value point selection (Visual assessment of the punctuation algorithm) of the data points in the selection algorithm:"}, {"heading": "6.4. Menu items \u2019Data mining\u2019 61", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.3.19 Project report", "text": "displays information about the current project (name, number of data points, etc.) and all selected parameters in the controls."}, {"heading": "6.3.20 Recoding table", "text": "displays modified class numbers if an output variable was not originally numbered with 1... n in the code variable."}, {"heading": "6.4 Menu items \u2019Data mining\u2019", "text": "contains all functions for supervised and unsupervised classification as well as for regression of individual characteristics and time series."}, {"heading": "6.4.1 Selection and evaluation of single features", "text": "In contrast to the MANOVA method, redundancies between features are not examined. The method assumes a normal distribution for each output class (linguistic term) in the input area. \u2022 MANOVA, multivariate: calculates feature relevance using the MANOVA method. It performs a step-by-step selection by adding a best single feature to an existing set of selected features. \u2022 The selection ends when the desired number of features in the control element: Data Mining: Classification of individual features - the number of selected features is achieved or when the next feature does not increase the feature relevance of the feature set. \u2022 Information theory measures: similar to data mining - Selection and evaluation of individual features - ANOVA, but the method does not require a normal distribution."}, {"heading": "62 Chapter 6. Menu items", "text": "In fact, most people who are able are able to move, to move and to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "6.4. Menu items \u2019Data mining\u2019 63", "text": "Several tests can be defined by the control: Data mining: Statistical options - Bonferroni correction. \u2022 Normal distribution test: Test the selected individual characteristics for normal distribution and log the result, for all selected data points and for each individual class of the selected output variable. \u2022 Chi Square test for normal distribution is required for this function. \u2022 Chi Square test variable vs. discretely evaluated individual characteristics: such as Data Mining - Initial variable evaluation - Chi Square test for continuity tables, but for the selected output variables and the selected individual characteristics. The latter are assumed to have discrete values. \u2022 Linear regression coefficient values (absolute values)."}, {"heading": "64 Chapter 6. Menu items", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.4.2 Evaluation of time series", "text": "Analysis is performed only for the sample point selected by the control: Time Series: Extraction - Parameter - Time Series Sample Point: Individual characteristics. The number of selected time series is defined by the control: Data Mining: Classification of individual characteristics - Number of selected characteristics. \u2022 MANOVA (with sample point for time series: Individual characteristics): see Data Mining - Time Series Evaluation: ANOVA (with sample point for time series: Individual characteristics), but using a multivariate analysis of variances (MANOVA). \u2022 Compute best sample points to search for the best sample points of time series \u2192 Single feature: see Data Mining - Evaluation of time series - ANOVA (with sample point for time series \u2192 Single feature)."}, {"heading": "6.4.3 Evaluation of output variables", "text": "contains functions for evaluating output variables."}, {"heading": "6.4. Menu items \u2019Data mining\u2019 65", "text": "\u2022 Chi-Square test for output variable contingency tables: Performs a Pearson Chi-Square test (using the \"Crosstab\" function of the MATLAB Statistics Toolbox) that the output variables are pairs independent (null hypothesis).The p value indicates that this null hypothesis is randomly discarded; the results apply to sample size > 5 data points in each cell of the cross table. Otherwise, for cross tables with only two values 0 and 1, the (more conservative) Two-Tail Exact Fisher test is used in the implementation of [108] (\"Fish Test\" function).A method for correcting multiple tests can be defined by control elements: Data Mining: Statistical Options - Bonferroni Correction."}, {"heading": "6.4.4 Classification", "text": "contains all the functions for a complete classification run based on individual characteristics (including feature selection and aggregation). \u2022 Design: trains a classifier based on the selected data points. The output variable for the monitored classification is defined by controls: Time series: General options - Selection of output variables (also in other windows, see e.g. controls: Data Mining: Classification of individual characteristics). This run includes all the steps defined by controls: Data Mining: Classification of individual characteristics (optional feature selection, normalization, feature reaction, normalization of aggregated characteristics and classification itself). The run is defined by all parameters from controls: Data Mining: Classification of individual characteristics and controls: Data Mining: Special methods. \u2022 Apply: applies a classification design through data mining - classification - design to all selected data points. This application includes all the steps of classification, standardization selection, and standardization reaction."}, {"heading": "6.4.5 Time series classification", "text": "contains all functions for classification of time series. \u2022 Draft: Draft of a time series classifier using parameters in controls: Data Mining: Classification of time series. The different classifier types are described in [22]. Detailed parameters for the classifiers are defined by controls: Data Mining: Special methods. \u2022 Application: Application of a classifier designed by Data Mining - Time series classification - Design on the selected data points. \u2022 Design and application: performs a subsequent processing of Data Mining - Time series classification - Design and Data Mining - Time series classification - Application. Chapter 6. Menu items \u2022 Time aggregation: Aggregates classification decisions over time using filter parameters in (Control: Data Mining: Classification of time series - Filtering of results), resulting in modified classification decisions. \u2022 Time aggregation with result plots: such as Data Mining - Time series classification - Time series aggregation, but with additional results."}, {"heading": "6.4.6 Hierarchical Bayes classifier", "text": "contains functions for the design and application of hierarchical Bayes classifiers. \u2022 Design: designs a hierarchical Bayes classifier by gradually separating individual classes from all other classes [87]. The maximum number of selected and aggregated characteristics is defined by (control: Data Mining: classification of individual characteristics - number of selected characteristics) or control: Data Mining: classification of individual characteristics - number of aggregated characteristics. The feature aggregation is carried out by a discriminant analysis with optimization. This function always uses a Bayes classifier. \u2022 Apply: applies a classifier designed by data mining - Hierarchical Bayes classifier - design to all selected data points. \u2022 Design and Apply: performs a subsequent processing of data mining - Hierarchical Bayes classifier - design and data mining - Hierarchical Bayes classifier - application."}, {"heading": "6.4.7 Fuzzy systems", "text": "Design algorithms are described in [76]. \u2022 Design: Search for relevant fuzzy rules using only the selected individual characteristics and the selected output variable. This design does not take into account the cooperation of the designed rules in a rule base (e.g. to avoid redundancies). Existing rules are deleted. \u2022 Design (Rule Base): Search for a relevant fuzzy rule base using only the selected individual characteristics and the selected output variable. This design searches for individual rules as a first step and collects a small set of cooperating rules by optimizing them. The evaluation measure prefers rules without redundancies and full coverage of the input area. Existing rules are deleted. \u2022 Delete rules: Open a window to manually delete fuzzy rules."}, {"heading": "6.4. Menu items \u2019Data mining\u2019 67", "text": "\u2022 Design Membership Functions for Individual Functions: designs membership functions for all individual functions using the method specified by the control: Data Mining: Special Methods - Type of Membership Function. \u2022 Export fuzzy system to classifier: exports a designed fuzzy system as a classifier. A design of data mining - fuzzy systems - design (rule base) corresponds to a classification design with the selected functions without aggregation. Design of data mining - fuzzy systems - design (single rules) is also possible, but in many cases leads to bad results due to redundant rules and lack of priorities of good individual rules. \u2022 Import of fuzzy system from classifier: imports a fuzzy system from a designed fuzzy classifier. This function is only available if \"fuzzy classifier\" has been selected in the control: Data Mining: Classification of time series - classifier type during the last design. It is useful to visualize a fuzzy system (see also Fuzzy System)."}, {"heading": "6.4.8 Clustering", "text": "contains all functions for the design and application of clusters. \u2022 Design and apply: contains various methods for searching for subgroups with fuzzy cluster methods (FCM) for the selected time series or individual characteristics (see e.g. [64]). The design methods use only the selected data points. The application for cluster assignment takes place for all data points. The necessary parameters and methods as well as the options for converting clusters into new output variables are defined in controls: Data Mining: Clustering. Here, own cluster functions are used. \u2022 Design and Application (Statistic Toolbox): calculates clusters for the selected individual characteristics or time series. The necessary parameters and methods as well as the options for converting clusters into new output variables are defined in controls: Data Mining: Clustering. In contrast to Data Mining - Clustering - Design and Application, the crisp and hierarchical cluster algorithms of the Statistic Matolbox are \"(e.g. found in the description)."}, {"heading": "6.4.9 Association analysis", "text": "performs an association analysis for all output variables. An implementation of Narine Manukyan has been integrated, the results of which are saved as a file. If this analysis is to include individual characteristics, these individual characteristics must be converted into output variables by editing - converting - selecting individual characteristics \u2192 output variables."}, {"heading": "68 Chapter 6. Menu items", "text": "Output variables with too many linguistic terms are ignored, the maximum number of terms is defined by a control: Data Mining: Special methods - Ignore output variables with too many terms. Only rules with a minimum of trust and support are displayed (definition in the control: Data Mining: Special methods - Minimum of trust or control: Data Mining: Special methods - Minimum of support)."}, {"heading": "6.4.10 Self Organizing Maps", "text": "contains the functions for designing and applying Self Organizing Maps. This is where the selforgmap.m function of MATLAB Neural Network Toolbox is used. \u2022 Design: designs Self Organizing Maps for all selected individual features with the selforgmap.m function of MATLAB Neural Network Toolbox. Dimensionality is defined by control: Data Mining: Special methods - Dimension, the number of neurons per dimension by control: Data Mining: Special methods - Number of neurons and the number of training periods by control: Data Mining: Special methods - Number of learning periods. \u2022 Apply: applies a Self Organizing Map designed by Data Mining - Self Organizing Maps - Design to the selected data points. A new output variable is generated with the number of winning neurons in the terms."}, {"heading": "6.4.11 Regression", "text": "contains all functions for designing and applying regression models. \u2022 Design: designs a regression model using the selected data points and the parameters selected in controls: Data Mining: Regression. The associated options (regression of time series or individual characteristics, feature selection and aggregation, normalization, regression method) are selected in controls: Data Mining: Regression. The methods can be selected and parameterized with controls: Data Mining: Special methods. \u2022 Apply: applies the current regression model to the selected data points. The current model results from the last design step or a loaded regression model. This performs all associated operations (regression of time series or individual characteristics, feature selection and aggregation, normalization, regression method). \u2022 Design and Apply: performs a subsequent processing of Data Mining - Regression - Design - Data Mining - Regression by application."}, {"heading": "6.4. Menu items \u2019Data mining\u2019 69", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.4.12 Validation", "text": "Validates the classification of individual characteristics and time series. \u2022 Classification of individual characteristics: Validation of individual test series. Possible validation strategies include cross-validation (with different subtypes) and bootstrap method (selection by control: Data Mining: Validation - Validation Strategy). The menu item Data Mining - Classification - Design is performed for each produced training data set with the defined options. The resulting classification is applied to each validation data set using Data Mining - Classification - Application. The results are aggregated and written to log files. \u2022 Classification of individual characteristics (selected macros): similar to Data Mining - Validation - Classification of individual characteristics, but with macros for classification design and application instead of the corresponding menu items."}, {"heading": "70 Chapter 6. Menu items", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.5 Menu items \u2019Extras\u2019", "text": "contains all functions for working with macros and managing application-specific expansion packages."}, {"heading": "6.5.1 Play macro...", "text": "If an error message about a missing macro occurs in the search path, macros or errors will be deleted during the last macro run. In the latter case, using Tools - Reset Macro Name can help."}, {"heading": "6.5.2 Play macro (debug mode)...", "text": "The selected macro is copied into an m file named \"makro _ m _ file.m.\" This option provides the full debugging functionality of MATLAB. After a restart SciXMiner checks if \"makro _ m _ file.m\" has been changed manually. If so, it asks if these changes should be transferred to the macro."}, {"heading": "6.5.3 Record macro...", "text": "The macro name is defined by an additional window. The background of the SciXMiner window is yellow during the recording. All menu entries are executed in parallel. The recording is stopped by Tools - Stop Macro Recording. Some functions (especially file operations) are not available during the macro recording. They can be added manually via the corresponding callbacks from the file menu _ elements. A critical evaluation of the recorded macros is highly recommended especially for complex tasks. A modified mapping of drawn figures (e.g. to plot several figures in subplots instead of in separate windows) is possible via the control: General Options - For Macros: Plot always in the current mapping. Such commands (e.g. subplot) should be placed directly in front of the menu item in the macro to avoid a plot in incorrect images (especially in the SciXMiner main window)."}, {"heading": "6.5.4 Stop macro record", "text": "terminates the record of a macro."}, {"heading": "6.5.5 Edit macro...", "text": "opens an existing macro in an editor window for manual modification."}, {"heading": "6.5.6 Reset macro names", "text": "This function is important after an error occurring during macro execution. Otherwise, problems with the execution of different macros are possible."}, {"heading": "6.5. Menu items \u2019Extras\u2019 71", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.5.7 Execute M-file...", "text": "executes an M file."}, {"heading": "6.5.8 Edit M-file...", "text": "opens an existing M file in an editor window for manual modification."}, {"heading": "6.5.9 Edit SciXMiner batch file ...", "text": "opens an existing SciXMiner batch file in an editor window for manual modification."}, {"heading": "6.5.10 Generate PDF project report (needs Latex)", "text": "The function creates a subdirectory \"Report\" in the current working directory of SciXMiner. All new or modified files can be saved for the project report. Only for the first report, the contents of the template will be copied into a new file \"project _ results _ *\" in the directory \"report.\" After that, it can be modified for individual needs only for this project or directory. If they exist, the following contents will be added: Once per report, the contents of the template will be copied into a new file \"project _ results _ *. *\" in the directory \"report.\" After that, it can also be modified for individual needs only for this project or directory. If they exist, the following contents will be added: Once per PDF: 1. File \"general _ comments _ text.\" Here, all project-related metadata can be added (e.g. Scip.2.)"}, {"heading": "72 Chapter 6. Menu items", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.5.11 Translate German Gait-CAD m-files and macros into English", "text": "This menu item supports the translation of German Gait CAD m files and macros into English. It converts strings in all macros and m files of a selected directory using a dictionary. The corresponding directory and another directory for a backup copy are selected in a separate window."}, {"heading": "6.5.12 Choose application-specific extension packages...", "text": "Switching packs with application-specific extensions on or off. This selection is made after the next SciXMiner start. Currently, the \"Peptides,\" \"Images and Videos\" and \"Tracking\" expansion packs are available. Beta versions of the \"Gait Analysis\" and \"Text Mining\" expansion packs are available on request."}, {"heading": "6.5.13 Search path for m-files and plugins", "text": "adds a directory to the MATLAB search path to use m files and plugins in that directory in SciXMiner. \u2022 Permanent: permanently adds a directory to the MATLAB search path to use m files and plugins in that directory in SciXMiner. \u2022 Reset (permanent search path): resets the permanent search path added by Tools - Search path for m files and plugins - Permanent and stored in read _ gaitcad _ searchpath. \u2022 Reset (temporary for the session): resets the search path for the SciXMiner session defined by Tools - Search path for m files and plugins - Temporary for the session."}, {"heading": "6.5.14 Matlab Parallel", "text": "controls the use of the configurations of the MATLAB Parallel Computing Toolbox. \u2022 Start: Starts using the selected configuration of the MATLAB Parallel Computing Toolbox. Here the configuration with the name defined by the control element is used: General Options - Configuration name for MATLAB Parallel (see also Parallel - Manage configurations in the menu of the MATLAB command window). \u2022 Stop: stops using the current configuration of the MATLAB Parallel Computing Toolbox."}, {"heading": "6.6. Menu items \u2019Favorites\u2019 73", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.6 Menu items \u2019Favorites\u2019", "text": "contains all functions for quick access to frequently used or user-defined menu items and macros. All deactivated entries (e.g. due to missing individual functions) are displayed in light gray."}, {"heading": "6.6.1 Edit user-defined favorites", "text": "Opens a configuration window to add and delete menu items from the favorites listing. 6.6.2 Delete all favorites Deletes all favorites."}, {"heading": "6.7 Menu items \u2019Window\u2019", "text": "activates or closes all open Matlab figures except the main SciXMiner window."}, {"heading": "6.7.1 Close figures", "text": "closes all figures except the main SciXMiner window."}, {"heading": "6.7.2 Arrange figures", "text": "contains various options for placing pieces. \u2022 Horizontal: places all pieces horizontally. \u2022 Vertical: places all pieces vertically. \u2022 Cascade: places all pieces as a cascade. \u2022 Position of the current piece: places all pieces at the position of the last opened piece. This command is particularly useful for comparing pieces with small differences by toggling between pieces of the same size and position."}, {"heading": "74 Chapter 6. Menu items", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.7.3 Logarithmic scaling of current figures", "text": "applies a logarithmic scale to all open MATLAB figures. \u2022 only x-axis: applies a logarithmic scale to the x-axis of all open MATLAB figures. \u2022 only y-axis: applies a logarithmic scale to the y-axis of all open MATLAB figures. \u2022 x and y-axis: applies a logarithmic scale to the x- and y-axis of all open MATLAB figures."}, {"heading": "6.7.4 Remove Latex codes in MATLAB figures", "text": "removes latex-style variables that are interpreted as equations (e.g. x1 instead of x _ 1) from all open MATLAB numbers."}, {"heading": "6.7.5 Update font and font size in figures", "text": "sets the font and font size in all open MATLAB images to the values defined by the control: View: Single Features - Font and Control: View: Single Features - Font Size."}, {"heading": "6.7.6 Plot all figures as images in files", "text": "outputs the contents of all numbers in files, the file name is generated from the project and the figure name, the file type is defined by control: General Options - File type for images, the image in the file depends on the size on the monitor."}, {"heading": "6.8 Menu items \u2019Help\u2019", "text": "contains SciXMiner version and license information as well as SciXMiner manuals."}, {"heading": "6.8.1 Show SciXMiner documentation (PDF)", "text": "opens the SciXMiner manual and the help file as PDF."}, {"heading": "6.8.2 About SciXMiner", "text": "contains the release information and the contact address to the development team."}, {"heading": "6.8.3 License information", "text": "displays the license file for the GNU license."}, {"heading": "7 Control elements", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.1 Control elements for \u2019Project overview\u2019", "text": ""}, {"heading": "76 Chapter 7. Control elements", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.2 Control elements for \u2019Time series: General options\u2019", "text": "\u2022 Selection of the output variable: selects an output variable. This selection influences many functions such as the evaluation of individual characteristics and time series, the design of classifiers, almost all visualization functions, etc. \u2022 Sampling frequency of time series: defines the sampling frequency for the time series in the dataset. It is assumed that this value is the same for all time series. It mainly influences the visualization of time series by time or frequency. \u2022 Unit: defines the physical size for time series (e.g. sampling frequency in kHz, per day, etc.). The parameter mainly influences the visualization of time series or spectrograms by time or frequency. \u2022 Selection of time series (TS): selects time series for visualization and all subsequent processing steps. The selection can be made by mouse click in the listbox by writing the numbers in the input field on the left or by pressing the \"ALL\" button to select all the different time series."}, {"heading": "7.2. Control elements for \u2019Time series: General options\u2019 77", "text": "\u2022 Full Time Series: Selects all sampling points of the time series. \u2022 Time Series Segment of: defines the beginning of a time series segment to visualize sampling points. This parameter can also be defined by zooming in a time series visualization (View - Time Series (TS)) and pressing the \"Select Time Series Segment\" button in the menu bar. Beginning is the left boundary of the current x-axis. \"Select Time Series Segment to All Sampling Points\" button in the menu bar defines the end of a time series segment to visualize sampling points. This parameter can also be specified by zooming in a time series visualization (View - Time Series (TS) and pressing the \"Select Time Series Segment\" button in the menu bar. The end is the right boundary of the current x-axis."}, {"heading": "78 Chapter 7. Control elements", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.3 Control elements for \u2019Time series: Extraction - Parameters\u2019", "text": "\u2022 Data-dependent function extraction in plugins: Defines the handling of plugins with data-dependent transformation functions (and not only data-dependent output variables for time series and individual features!) Typical examples are a transformation matrix for a Principal Component Analysis or Fuzzy Membership functions. Possible options are a calculation with and without storing the results in a *.plugpar file with the same project name or loading from this file. When loading, the name of the time series, the plugin description and the segments must be the same. \u2022 Parameter IIR Filter: defines the filter parameter a for an Infinite Impulse Response (IR) value for all functions by using only one example point for a conversion of time series into individual features. \u2022 Parameter IIR Filter: defines the filter parameter a for an Infinite Impulse Response (IR) value [IR filter + a first order filter = 1]."}, {"heading": "7.3. Control elements for \u2019Time series: Extraction - Parameters\u2019 79", "text": "\u2022 IIR parameters (aF, aS, aSigma): defines the parameters for three different IIR filters for trend and standard deviation calculation (see [90]). \u2022 Filter order (FIL): defines the order of the filter for feature extraction. \u2022 High-pass: switches to a high-pass filter for feature extraction. \u2022 Low-pass: switches to a low-pass filter for feature extraction. \u2022 Frequencies (FIL, morlet spectrogram): defines the cut-off frequencies for different filters. \u2022 Wavelet: selects the wavelet type for a wave formation (see e.g. [63] or the documentation of the laboratory."}, {"heading": "80 Chapter 7. Control elements", "text": "\u2022 Shortening Time Series: Window length or x-sampling point: defines the window lengths (Edit - Convert - Shortening Time Series - Shortening by Window Methods) or step width (Edit - Convert - Shortening Time Series - Use only every x-sampling point) to short time series. \u2022 Shortening Time Series: Method: selects the method for shortening all time series in a project by means of control: Time Series: Extraction - Parameters - Shortening Time Series: Window length or x-sampling point. First, a window is selected with a by Edit - Convert - Shortending Time Series - Shortending by Window Methods. Secondly, the new value for the short time series is calculated by the mean, median, minimum or maximum value of these windows. The windows do not overlap. \u2022 Match Time Series Length to: defines the length for the shortening of the time series (Shortening of Time Series - Convert)."}, {"heading": "7.4. Control elements for \u2019Plugin sequence\u2019 81", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.4 Control elements for \u2019Plugin sequence\u2019", "text": "\u2022 Show plugins: Selection of the shown plugins by type (e.g. time series \u2192 time series). \u2022 Add: adds the selected plugins from the control element: Plugin order - Selection of plugins in a plugin order. \u2022 Update plugins: reads the available plugins from all plugin files. It is useful for the development of plugins to avoid a restart of SciXMiner. \u2022 Show plugin list: writes the properties and descriptions of all available plugins to a file and displays this file. \u2022 Selection of plugins: selects the plugins used by Edit - Extract - Time Series. \u2022 Time Series, Time Series \u2192 Single Features (via plugin order).... Only a definition in the edit window guarantees the selected order of the plugins. A definition in the list box ignores this order and sorts the plugins by their numbers. \u2022 Plugin parameter: Select the plugin parameter from the control: the plugin element selected."}, {"heading": "82 Chapter 7. Control elements", "text": "Plugins or controls: Plugin sequence - Selected plugin sequence \u2022 Switching between multiple parameters is done by Control Element: Plugin sequence - No.. \u2022 No.: selects a specific parameter for plugins with multiple parameters. \u2022 Forward: moves the selected plugins in Control Element: Plugin sequence - Selected plugin sequence to earlier positions in the sequence. \u2022 XPIWIT: Execute Pipeline step by step: Execute plugins in XPIWIT separately. In this option, a separate call of XPIWIT.exe is executed for each plugin. This option is only used by the extension package \"Images and Videos.\" \u2022 Down: moves the selected plugins in Control Element: Plugin sequence - Selected plugin sequences to later positions in the sequence. \u2022 Delete: delete: delete the latest plugin plugin sequence from the sequence. \""}, {"heading": "7.4. Control elements for \u2019Plugin sequence\u2019 83", "text": "\u2022 Save performance log file: determines whether computing times for individual plugins or complete plugin sequences should be written to a log file \"* _ PerformanceLog.csv\" in the current project directory. \u2022 Execute: execute the current plugin sequence in Control Element: Plugin Sequence - Selected plugin sequence. \u2022 Use the same transformation matrix (e.g. PCA) to reduce all data points into time series: affects the reduction of time series by the Principal Component Analysis. If this option is checked, an identical transformation matrix is used for all data points. Otherwise, a separate transformation matrix is calculated for each data point."}, {"heading": "84 Chapter 7. Control elements", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.5 Control elements for \u2019Single features\u2019", "text": "\u2022 Selection of the output variable: Selection of an output variable. This selection influences many functions such as the evaluation of individual characteristics and time series, the design of classifiers, almost all visualization functions, etc. \u2022 Selection of individual characteristics (SF): Selection of individual characteristics for visualization and all subsequent editing steps. Selection can be done by mouse clicks in the listbox by writing the numbers in the input field on the left or by pressing the button \"ALL\" to select all individual characteristics. The different fields are synchronized after input. TIP: An input in the input field allows selection in a different order (e.g. 2-4-1 for a visualization) as opposed to the listbox. \u2022 Number of terms for individual function \u2192 output variable: defines the number of terms for a new output variable that is generated by editing - converting - output variables."}, {"heading": "7.5. Control elements for \u2019Single features\u2019 85", "text": "A single attribute has the values 1, 2.5, 3.5, and 7. The result is an output variable with four terms called \"ca. 1,\" \"ca. 2.5,\" \"ca. 3.5,\" and \"ca. 7.\" In contrast, new terms are computed with the number defined in the control element: Individual features - Number of terms for a single attribute \u2192 Output variable when the check box is disabled. \u2022 A priori Feature Relevances: Enables the use of a priori relevance of individual attribute. In the feature selection, features with higher a priori relevance are preferred, ranging from zero (bad attribute) to one (preferred attribute). You can define relevance (variable interpretability) - implementable relevance for the value, or manually modified exponence for the value in the project file (variable interpretability)."}, {"heading": "86 Chapter 7. Control elements", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.6 Control elements for \u2019Data preprocessing\u2019", "text": "The \"New Output Variable\" option always adds a new output variable with the result of outlier detection. The variable name is \"Outlier\" with the name of the method used. The \"Replace Identical Output Variable\" option replaces the results in an existing output variable that is calculated using the same method. Otherwise, a new outlier variable is added. \u2022 Outlier Threshold: defines a threshold if a data point is classified as an outlier or not (see Edit - Outlier Detection - Application (selected data points, designed dataset). The meaning of the parameter depends on the method: SVM - a value less than zero (tolerated distance to class boundary) distance-based: Distance value density based: Number of neighborhoodThe level curves in the visualization are helpful for parameter definition (see View: Classification and Regression - Outlier Detection control)."}, {"heading": "7.6. Control elements for \u2019Data preprocessing\u2019 87", "text": "This function supports outlier detection in complicated cases because these data points are not evaluated as good measurements. Depending on the corresponding positions in the functionality, it usually increases the likelihood of automatic outlier detection of these data points by applying outlier detection. \u2022 All selected data points are used when the field is empty or \"[]\" is written in the field. During the application, all data points are evaluated. The number of data points is shown when the control element: View: Individual Features - Show the data point number is highlighted. \u2022 Method: Selects the classification type for outlier detection. The inclusion method optimizes the coefficients ai and b of the function: f (z) = an aiK + b, with an unknown data point z and the data points xi of the training data set."}, {"heading": "88 Chapter 7. Control elements", "text": "\u2022 Delete Threshold [Percentage of Missing Data]: defines the percentage threshold in data pre-processing for deleting time series or individual characteristics in case of missing values. Otherwise, any data point with at least one missing value in each individual feature or data point will be deleted. A time series contains missing values if at least one example point is missing. Missing values must be encoded with NaN values or Inf values. Time series with zero values for all sample points are also considered as missing values. For example: Project with 100 data points and 15% missing values (data points 1-15) for time series x1 and 5% missing values for time series x2 (data point 96-100) and threshold of 10%: Time series x1 will be completely deleted, data points 96-100 will be deleted. \u2022 Function values to choose from: Value range for selecting data points based on individual characteristic values in the control: Data pre-processing - function values to choose from. \u2022 Date format: defines the date format for the output of the data (MB) and an hour."}, {"heading": "7.6. Control elements for \u2019Data preprocessing\u2019 89", "text": "The \"New Output Variable\" option always adds a new output variable with the result of outlier detection. The variable name is \"Outlier\" with the name of the method used. The \"Replace Identical Output Variable\" option replaces the results in an existing output variable calculated using the same method. Otherwise, a new outlier variable is added. \u2022 Outlier Threshold: defines a threshold if a data point is classified as an outlier or not (see Edit - Outlier Detection - Application (selected data points, designed dataset). The meaning of the parameter depends on the method: SVM - a value less than zero (tolerated distance to the class boundary) distance-based: Distance density-based: number of neighborhoods The level curves in the visualization are helpful for parameter definition (see View: Classification and Outlier Control)."}, {"heading": "90 Chapter 7. Control elements", "text": "The number of data points is displayed when the field is empty or \"[]\" is written in the field. The one-class method optimizes the coefficients ai and b of the function: f (z) i aiK (z, xi) + b, with an unknown data point z and the data points xi of the training dataset."}, {"heading": "7.7. Control elements for \u2019View: Single features\u2019 91", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.7 Control elements for \u2019View: Single features\u2019", "text": "\u2022 Display numbers: switches between color-coded, numbered (for the number of linguistic terms of output variables) and (black-and-white) symbol-coded features and time series. \u2022 Color Style: modifies the visualization of output variables using different color and style combinations for time series and individual characteristics. It defines the mapping of linguistic terms to colors and styles. \u2022 Custom colors: defines the order of custom colors for visualizing linguistic terms of the selected output variable in time series and individual feature plans. It uses Matlab color abbreviations (see function plot help text). The option is only active if custom (color or symbol) or user-defined symbols (color and symbol) are selected in control: View: Individual features - Color style and Color."}, {"heading": "92 Chapter 7. Control elements", "text": "Features - Color style and black-and-white icon is selected in the control: View: Single features - Show figures. \u2022 Different output variable: displays the results of classification and regression with a freely selectable output variable if \"Different output variable\" is selected in the control. \u2022 Inverse plot order terms: plots all data points in reverse order of the terms of the output variables. \u2022 Show data point number: enables or disables the display of data point numbers. \u2022 Evaluate only selected single features: evaluates only the selected single features. \u2022 Show legend: plots the legend with the linguistic terms of the output variables. \u2022 Show term names of data point number: toggles the display of data point numbers on or off."}, {"heading": "7.7. Control elements for \u2019View: Single features\u2019 93", "text": "\u2022 Decimal symbol in German format (comma): defines a German number format with commas as a decimal point. \u2022 Output Variable Log Files Absolute values: defines the log option of output variables in files generated by View - single attributes - absolute values. Possible values are all, the selected or no output variables. \u2022 Classes as rows: switches the style of log files for averages etc. as created by View - single attributes - mean, standard deviation, minimum, maximum. If checked, each class is written in a row and each attribute in a column. Otherwise, each attribute is written in a row and each class in a column. \u2022 Font: defines the font defined by windows - Update font and font size in numbers for all opened MATLAB figures. \u2022 Marker: font size in markers of individual attributes."}, {"heading": "94 Chapter 7. Control elements", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.8 Control elements for \u2019View: Time series\u2019", "text": "\u2022 Display numbers: switches between color-coded, numbered (for the number of linguistic terms of output variables) and (black-and-white) symbol-coded features and time series. \u2022 Color Style: modifies the visualization of output variables using different color and style combinations for time series and individual characteristics. It defines the mapping of linguistic terms to colors and styles. \u2022 Custom colors: defines the order of custom colors for visualizing linguistic terms of the selected output variable in time series and individual feature plans. It uses Matlab color abbreviations (see function plot help text). The option is only active if custom (color or symbol) or user-defined symbols (color and symbol) are selected in control: View: Individual features - Color style and Color."}, {"heading": "7.8. Control elements for \u2019View: Time series\u2019 95", "text": "Properties - Color style and black and white icon is selected in the control: View: Individual Features - Show Numbers. \u2022 Percental (Ignore Sampling Frequency): switches to a percentage x-axis to visualize time series. The length of the time series is set to 100%. \u2022 The selected sampling frequency is ignored. \u2022 Sampling Points: switches to the number of sampling points on the x-axis to visualize time series. The selected sampling frequency is ignored. \u2022 Time [Unit]: switches to the time on the x-axis for visualizing time series. The selected sampling frequency in the control: Time Series: General Options - Sampling frequency of time series are used to transform sampling points into time. Time always starts from zero. Project Specific: uses a project-specific time scale defined by (parameters.) Projecttime scaling for visualizing time series."}, {"heading": "96 Chapter 7. Control elements", "text": "\u2022 Display Normative Data: displays normative data as a light gray region in the visualization of time series. Normative data must be displayed by file - Normative data - Mean of normative data (internal from the project) or by file - Normative data - Load normative data from a file. \u2022 Normative data in the foreground: The visualization of many original time series can overlay the normative data. Activate this option to display the normative data in the foreground. \u2022 Logarithmic visualization: Optionally select a logarithmic scaling of times or amplitudes of time series for visualization. \u2022 Line width: Changes the line width for the visualization of time series. For example, it is useful for the export of numbers in LATEXfigures with values of e.g. 1.5 or 2. \u2022 Font: defines the font type that is set by windows - Update font and font size in numbers for all opened MATLAB figures."}, {"heading": "7.9. Control elements for \u2019View: Spectrogram, FFT, CCF\u2019 97", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.9 Control elements for \u2019View: Spectrogram, FFT, CCF\u2019", "text": "\u2022 Window size [sample points]: defines the window size for the calculation of spectrograms. It controls the compromise between a temporal and a frequency resolution. A small value prefers a better temporal resolution. The value is automatically reduced to the next power of two to obtain the efficiency of the FFT algorithm (e.g. 27 = 128, 210 = 1024, etc.). The value is limited by the number of sample points. \u2022 Normalization for cross-correlation: defines the normalization mode for auto- and cross-correlation functions: - \"distorted,\" scaled to the length of the time series, see MATLAB function \"x-unbiased,\" scaled to (length of the time series - delayed), see MATLAB function xcorr (less robust results for long delays) - \"coeff,\" normalizes the result to the length of the time series, see MATLAB function xr- unbiased, \"see MATLAB as a middle line correction, but not a middle line correction for simultaneous point)."}, {"heading": "98 Chapter 7. Control elements", "text": "Results of the correlation with the workspace: defines whether the auto or cross-correlation functions are stored separately for each data point in a workspace variable kkfs. \u2022 Time Shift Tau [SP]: sets the time shift for visualizing the correlation coefficients in View - Cross and Auto Correlation Functions - Mean Values of Correlation coefficient (defined time shift) and View - Cross and Auto Correlation Functions - Class Mean Values of Correlation Coefficient (with defined time shift). A value of zero uses the same sample point for both time series. \u2022 Show correlation figures: defines if the numbers of the correlative correlation functions are shown or not. Deactivating is useful if the results are stored in a variable (see Control Element: Spectrograms, FFT, CCF - Copy Correlation results to Workspace)."}, {"heading": "7.9. Control elements for \u2019View: Spectrogram, FFT, CCF\u2019 99", "text": "View: Spectrogram, FFT, CCF - exponential function exponent or q. control element: View: Spectrogram, FFT, CCF - root index control the quantitative characteristic. \u2022 Exponent for exponential function: see control element: View: Spectrogram, FFT, CCF - function for color bars (exponent for exponential characteristic). \u2022 A larger value increases the resolution for smaller amplitudes. \u2022 Root index: see control element: View: Spectrogram, FFT, CCF - function for color bars (n-fold root). A larger value increases the resolution for smaller amplitudes. \u2022 Colormap: changes the color style for some functions (e.g. for spectrograms). The color charts are explained in the Matlab documentation (e.g. for Jet: help jet)."}, {"heading": "7.10 Control elements for \u2019View: Classification and regression\u2019", "text": "\u2022 Display classes for output variables: Toggles the visualization of the classification results with View - Classification - Result and similar functions: \"only learning data:\" shows the true class mapping for the learning dataset. \"Only Classification:\" shows the classification decisions. \"DS-No Misclassification:\" shows the true class mapping for the learning dataset with the data point count for incorrectly classified data points. \"Class-No Misclassification:\" shows the true class mapping for the learning dataset with the number of class decisions for incorrectly classified data points. \u2022 Shows discriminatory functions: plots the discrimination functions for the class boundaries with the current classification space. \u2022 Number of netpoints: defines the number of netpoints for the learning datasets (in x and y direction) for the compression of regression elements: \"Differentiated class boundaries.\" The function is applied to each netpoint, resulting in (number of netpoints)."}, {"heading": "7.11 Control elements for \u2019Data mining: Classification of single features\u2019", "text": "This selection influences many functions such as the evaluation of individual characteristics and time series, the design of classification systems, almost all visualization functions, etc. \u2022 Selection of individual characteristics: defines the method for selecting individual characteristics (e.g. the use of the most recent selected characteristics, automatic selection by ANOVA), see Data mining - Selection and evaluation of individual characteristics. \u2022 Number of selected characteristics: defines the maximum number of individual characteristics for automatic feature selection. \u2022 Normalization of individual characteristics: leads to normalization of the characteristics before classification. It improves the results for all methods that are sensitive to different scaled characteristics. Two approaches are implemented; the interval [0, 1] or an average of zero and a standard deviation from a normal distribution."}, {"heading": "7.12 Control elements for \u2019Data mining: Classification of time series\u2019", "text": "iSe rf\u00fc ide rf\u00fc ide rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc"}, {"heading": "7.13 Control elements for \u2019Data mining: Regression\u2019", "text": "In fact, most of them will be able to play by the rules they have established in the past."}, {"heading": "7.14 Control elements for \u2019Data mining: Clustering\u2019", "text": "In this case, the number of clusters: defines the number of clusters calculated by the cluster algorithms if the control element: Data Mining - Unlimited iteration steps: Unlimited iteration elements: Unlimited iteration steps: Data Mining - Unlimited iteration steps is deactivated. If the algorithms converge before this step, the algorithm is terminated. Unlimited iteration steps of the cluster algorithm: Data Mining - Unlimited iteration steps is deactivated."}, {"heading": "7.15 Control elements for \u2019Data mining: Special methods\u2019", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "7.16 Control elements for \u2019Data mining: Statistical options\u2019", "text": "\u2022 Correlation parameter type: defines the type of correlation (Linear: Pearson; Ranked: Kendall, Spearman) to be used in visualizations or output files for correlations. \u2022 Correlation coefficient threshold: defines a threshold for the correlation coefficient. A greater value is interpreted as a relevant pair of correlations between two characteristics. This value influences, for example, the listing of relevant correlation coefficients or the downgrading of correlated characteristics in the feature selection. \u2022 Show correlation only for a selected characteristic: calculates only the correlations of all selected individual characteristics to the characteristic defined by the control: Data Mining: Regression - output variable of the regression. \u2022 p value for the t test: defines the p value for the t test (accepted error probability of a statistical test)."}, {"heading": "7.17 Control elements for \u2019Data mining: Validation\u2019", "text": "\u2022 n-fold cross-validation: defines the number of n parts for n-fold cross-validation. As an example: a value of 10 means that the training data set is divided into 10 parts. For each run, 9 parts are used as training data and one part as validation data set. Consequently, a complete cross-validation check requires 10 passes containing each selected data point exactly once in the validation data set. \u2022 Number of attempts: defines the number of attempts for cross-validation. Internally, a random mapping of data to the different parts is selected (n corresponds to the number of selected data points) or \"bootstrap\" in the control: Data Mining: Validation - Validation Strategy. \u2022 Number of attempts: defines the number of attempts for cross-validation. Internally, a random mapping of data to the different parts is selected."}, {"heading": "7.18 Control elements for \u2019General options\u2019", "text": "In this case, it is only a matter of time before the first steps in the right direction are taken."}, {"heading": "8 Feature extraction from time series", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8.1 Definition of feature types by plugins", "text": "In fact, it is the case that you will be able to put yourself at the top without being able to put yourself at the top."}, {"heading": "8.2 Standard plugins in SciXMiner", "text": "A list of all include plugins in the default SciXMiner installation can be found in Section H. In a project, the list of all available plugins can be displayed using the View plugin order control."}, {"heading": "8.3 Plugins for single features from single features", "text": "There are two different alternatives: \u2022 Implementation of individual plugins via macros (see two examples in the directory default macros: feature _ plugin _ div2.makrog for dividing two selected individual features and feature _ plugin _ log.makrog for calculating the logarithm of all selected features) \u2022 Calculation of aggregated features (see Edit - Extract - Individual features - > Individual features (with the selected feature aggregation from Options-Data Mining: Classification of individual features)."}, {"heading": "8.4 Defining intervals via files", "text": "After loading a SciXMiner project, all *.indent files in the current directory and in the subdirectory plugins / einggenerierung of the SciXMiner installation will be imported. An interval file is an ASCII file with a diagram of the intervals. Lines are separated by line breaks, columns by tabs. To avoid an empty interval, do not add a line break after the last interval. The first line of the file must contain the following four column names (separated by tabs): Identifier Short Identifier Start StopThe intervals can be defined in the following lines, e.g.: Standing phase ST _ P 1 [FootOff] Oscillation phase SW _ P [FootOff] + 1 -18.5. Definition of a feature ontology by category 145. Special features are: \u2022 Features and mathematical operations can be used in the definition, e.g. during working hours, which cannot be used."}, {"heading": "8.5 Definition of a feature ontology by categories", "text": "You have defined one or more categories that can be used in different areas (see [64, 114]) and they can be assigned to categories by plugins, segments or name fragments. These functions are contained in text files with the extension *.kategorie. Here, all files are contained in the current working directory or in the subdirectory \"SciXMiner\" or in a custom extension package. These functions are text files and have a predefined format."}, {"heading": "9 Conclusions and perspectives", "text": "In fact, most of them are able to go in search of a solution that puts them in the position in which they find themselves."}, {"heading": "C Needed Standard Toolboxes", "text": "ii\u2212 i\u2212 i\u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 i\u2212 i\u2212 i\u2212 i\u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 \u2212 i\u2212 i\u2212 i\u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 i\u2212 \u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 \u2212 i\u2212 \u2212 i\u2212 i\u2212 i\u2212 \u2212 i\u2212 i\u2212 i\u2212 \u2212 i\u2212 \u2212 i\u2212 \u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 i\u2212 i\u2212 i\u2212 \u2212 i\u2212 i\u2212 i\u2212 i\u2212 \u2212 i\u2212 i\u2212 i\u2212 \u2212 \u2212 i\u2212 i\u2212 \u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 \u2212 i\u2212 i\u2212 \u2212 \u2212 \u2212 i\u2212 i\u2212 \u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 i\u2212 \u2212 \u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 i\u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 \u2212 i\u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 i\u2212 \u2212 \u2212 \u2212 i\u2212 i\u2212 \u2212 \u2212 \u2212 \u2212 i\u2212 i\u2212 \u2212 \u2212 \u2212 i\u2212 i\u2212 \u2212 i\u2212 i\u2212 i\u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 i\u2212 i\u2212 \u2212 \u2212 \u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 i\u2212 \u2212 i\u2212 i\u2212 i\u2212 \u2212 \u2212 \u2212 i\u2212 \u2212 \u2212 \u2212 \u2212 i\u2212 i\u2212 i\u2212 i\u2212 \u2212 \u2212 \u2212 iv \u2212 iv \u2212 \u2212 iv \u2212 iv \u2212 iv \u2212 iv \u2212 \u2212 \u2212 iv \u2212 iv \u2212 \u2212 iv \u2212 \u2212 \u2212 \u2212 iv \u2212 iv \u2212 \u2212 \u2212 iv \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 i"}, {"heading": "E Symbols and abbreviations", "text": "Symbol Meaning ACF Autocorrelation Function ANOVA Variance Analysis CCF Cross-Correlation Function CCOEF Cross-Correlation Function DA Discriminance Analysis FFT Fast Fourier Transformation ICA Independent Component Analysis k-NN k-nearest Neighbor MBF Membership Function MEAN Mean MLP Multivariate Variance Analysis PCA Main Component Analysis SF Single Feature STD Standard Deviation SVM Support Vector Machines TS Time Series K Number of Samples m Number of Linguistic Terms of All Characteristics ml Number of Linguistic Terms of the L-th Feature xl my Number of Linguistic Terms (Classes) of the Output Variable N Number of Data Points s Number of Characteristics sm Number of Characteristics sd Number of Transformed (Aggregated) Characteristics sz Number of Time Series"}, {"heading": "F Known errors and problems", "text": "In fact, it is so that it will be able to fix and correct the mentioned bugs."}, {"heading": "H Plugins", "text": "\u2022 COG SF (COG): calculates the center of gravity of a time series or a time series segment. \u2022 Single Series: yes, Type Series: plugin _ em.m - Type: SF - Time series: 1 Inputs, 0 Outputs, Segments possible: yes - Single Features: 0 Inputs, 1 Outputs - Images: 0 Inputs, 0 Outputs - Direct Callback: none - Number of parameters: 0 \u2022 Maximum (MAX): calculates the maximum of a time series or a time series segment as a single feature. - Function name: plugins: 0 Inputs, 0 Outputs: none - Type: Pictures: 1 Time Series: 1 Inputs, 0 Outputs: yes - Segments: 0 Inputs, 1 Outputs: 0 Outputs: 0 Outputs: none: none - Number of parameters: none."}], "references": [{"title": "KEEL Data-mining Software Tool: Data Set Repository, Integration of Algorithms and Experimental Analysis Framework", "author": ["J. ALCAL\u00c1", "A. FERN\u00c1NDEZ", "J. LUENGO", "J. DERRAC", "S. GARC\u00cdA", "L. S\u00c1NCHEZ", "F. HER- RERA"], "venue": "Journal of Multiple-Valued Logic and Soft Computing", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Konzept f\u00fcr Bildanalysen in Hochdurchsatz-Systemen am Beispiel des Zebrab\u00e4rblings", "author": ["R. ALSHUT"], "venue": "Dissertation, Karlsruher Institut fu\u0308r Technologie (KIT),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Methods for Automated High-Throughput Toxicity Testing using Zebrafish Embryos", "author": ["R. ALSHUT", "J. LEGRADI", "U. LIEBEL", "L. YANG", "J. VAN WEZEL", "U. STR\u00c4HLE", "R. MIKUT", "M. REISCHL"], "venue": "Lecture Notes in Artificial Intelligence", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Automatische Klassifikation von Bildzeitreihen f\u00fcr toxikologische Hochdurchsatz- Untersuchungen", "author": ["R. ALSHUT", "R. MIKUT", "J. LEGRADI", "U. LIEBEL", "U. STR\u00c4HLE", "G. BRETTHAUER", "M. REIS- CHL"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "The Irises of the Gasp\u00e9 Peninsula", "author": ["E. ANDERSON"], "venue": "Bulletin of the American Iris Society", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1935}, {"title": "Application of Data Mining Methods for Power Forecast of Wind Power Plants", "author": ["A. ARNOLDT", "S. K\u00d6NIG", "R. MIKUT", "P. BRETSCHNEIDER"], "venue": "Proc., 9th International Workshop on Large-scale Integration of Wind Power and Transmission Networks for Offshore Wind Farms, Quebec,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "XPIWIT - An XML Pipeline Wrapper for the Insight Toolkit", "author": ["A. BARTSCHAT", "E. H\u00dcBNER", "M. REISCHL", "R. MIKUT", "J. STEGMAIER"], "venue": "Bioinformatics", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Neues Konzept zur Bewegungsanalyse und -synthese f\u00fcr Humanoide Roboter basierend auf Vorbildern aus der Biologie", "author": ["C. BAUER"], "venue": "Dissertation, Karlsruher Institut fu\u0308r Technologie, KIT Scientific Publishing,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Hardware Design and Mathematical Modeling for an Artificial Pneumatic Spine for a Biped Humanoid Robot", "author": ["C. BAUER", "M. ENGELMANN", "I. GAISER", "T. STEIN", "A. FISCHER", "R. MIKUT", "S. SCHULZ"], "venue": "Proc., German Conference on Robotics, S. 7\u201311,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Human-like Reflexes for Robotic Manipulation using Leaky Integrate-and-Fire Neurons", "author": ["C. BAUER", "G. MILIGHETTI", "W. YAN", "R. MIKUT"], "venue": "Proc., IEEE/RSJ International Conference on Intelligent Robots and Systems", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Konzept f\u00fcr einen biologisch inspirierten, semi-passiven pneumatisch angetriebenen zweibeinigen Prothesen- Roboter-Hybrid", "author": ["C. BAUER", "M. MORS", "A. FISCHER", "T. STEIN", "R. MIKUT", "S. SCHULZ"], "venue": "at-Automatisierungstechnik", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Ein Beitrag zum automatischen Entwurf von Fuzzy-Entscheidungssystemen bei unvollst\u00e4ndiger Information", "author": ["S. BECK"], "venue": "Dissertation, Universita\u0308t Karlsruhe, Universita\u0308tsverlag Karlsruhe,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "A Cost-Sensitive Learning Algorithm for Fuzzy Rule-Based Classifiers", "author": ["S. BECK", "R. MIKUT", "J. J\u00c4KEL"], "venue": "Mathware and Soft Computing", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "KNIME: The Konstanz Information Miner", "author": ["M.R. BERTHOLD", "N. CEBRON", "F. DILL", "T.R. GABRIEL", "T. K\u00d6TTER", "T. MEINL", "P. OHL", "C. SIEB", "K. THIEL", "B. WISWEDEL"], "venue": "Data Analysis, Machine Learning and Applications,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Data Mining with Graphical Models", "author": ["C. BORGELT"], "venue": "Dissertation, O.-v.-Guericke Universita\u0308t Magdeburg,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2000}, {"title": "Classification and Regression Trees", "author": ["L. BREIMAN", "J.H. FRIEDMAN", "R.A. OLSHEN", "C.J. STONE"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1984}, {"title": "Neue Methodik zur Modellierung und zum Entwurf keramischer Aktorelemente", "author": ["B.W. BR\u00dcCKNER"], "venue": "Dissertation, Karlsruher Institut fu\u0308r Technologie (KIT),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "A Tutorial on Support Vector Machines for Pattern Recognition. Knowledge Discovery and Data Mining", "author": ["C. BURGES"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1998}, {"title": "Analyse von Zeitreihen in der Medizin: Informationsgehalt, Klassifikation und Unsicherheit", "author": ["O. BURMEISTER"], "venue": "Proc., 16. Workshop Computational Intelligence,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2006}, {"title": "Zeitvariante Klassifikatoren zur Analyse und Interpretation multimodaler Biosignale und deren Anwendung in der Prothetik und Rehabilitation", "author": ["O. BURMEISTER"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Data-Mining-Analysen mit der MATLAB-Toolbox Gait-CAD", "author": ["O. BURMEISTER", "M. REISCHL", "G. BRETTHAUER", "R. MIKUT"], "venue": "at-Automatisierungstechnik", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "Zeitvariante Klassifikatoren zur Steuerung von Brain Machine Interfaces und Neuroprothesen", "author": ["O. BURMEISTER", "M. REISCHL", "L. GR\u00d6LL", "R. MIKUT"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "A Linear Programming Approach to Novelty Detection", "author": ["C. CAMPBELL", "K.P. BENNETT"], "venue": "Proc., Neural Information Processing Systems Conference,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2000}, {"title": "SVM and Kernel Methods Matlab Toolbox", "author": ["S. CANU", "Y. GRANDVALET", "A. RAKOTOMAMONJY"], "venue": "Perception Syste\u0300mes et Information, INSA de Rouen, Rouen, France,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "Hg.): Medical Data Mining and Knowledge Discovery, Bd. 60 von Studies in Fuzziness and Soft Computing", "author": ["K. CIOS"], "venue": "Heidelberg: Physica,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2001}, {"title": "Nearest Neighbor Pattern Classification", "author": ["T. COVER", "P. HART"], "venue": "IEEE Transactions on Information Theory", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1967}, {"title": "Robust Fuzzy Clustering of Relational Data", "author": ["R. DAV\u00c9", "S. SEN"], "venue": "IEEE Transactions on Fuzzy Systems", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2002}, {"title": "DaMoQ: An Open Source MATLAB Toolbox for Data and Model Quality Assessment", "author": ["W. DONEIT", "R. MIKUT", "L. GR\u00d6LL", "T. PYCHYNSKI", "M. REISCHL"], "venue": "at-Automatisierungstechnik", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2017}, {"title": "Cross-Validation and the Bootstrap: Estimating the Error Rate of a Prediction Rule", "author": ["B. EFRON", "R. TIBSHIRANI"], "venue": "Techn. Ber. TR-477,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1995}, {"title": "From Data Mining to Knowledge Discovery in Databases", "author": ["U. FAYYAD", "G. PIATETSKY-SHAPIRO", "P. SMYTH"], "venue": "AI Magazine", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1996}, {"title": "Interpretability of Linguistic fuzzy Rule-based Systems: An Overview of Interpretability Measures", "author": ["M.J. GACTO", "R. ALCAL\u00c1", "F. HERRERA"], "venue": "Information Sciences", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2011}, {"title": "Automated High Throughput Mapping of Promoter- Enhancer Interactions in Zebrafish Embryos", "author": ["J. GEHRIG", "M. REISCHL", "E. KALMAR", "M. FERG", "Y. HADZHIEV", "A. ZAUCKER", "C. SONG", "S. SCHINDLER", "U. LIEBEL", "F. M\u00dcLLER"], "venue": "Nature Methods", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2009}, {"title": "Robust Adaptive Fault Detection using Global State Information and Application to Mobile Working Machines", "author": ["P. GERLAND", "D. GROSS", "H. SCHULTE", "A. KROLL"], "venue": "In: Conference on Control and Fault-Tolerant Systems (SysTol),", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2010}, {"title": "Probability-based Global State Detection of Complex Technical Systems and Application to Mobile Working Machines", "author": ["P. GERLAND", "H. SCHULTE", "A. KROLL"], "venue": "Control Conference (ECC),", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2009}, {"title": "Nearest-Neighbor Based Non-Parametric Probabilistic Forecasting with Applications in Photovoltaic Systems", "author": ["J.\u00c1. GONZ\u00c1LEZ ORDIANO", "W. DONEIT", "S. WACZOWICZ", "L. GR\u00d6LL", "R. MIKUT", "V. HAGEN- MEYER"], "venue": "Proc., 26. Workshop Computational Intelligence,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2016}, {"title": "Photovoltaic Power Forecasting using Simple Data-driven Models without Weather Data. Computer Science - Research and Development", "author": ["J.\u00c1. GONZ\u00c1LEZ ORDIANO", "S. WACZOWICZ", "M. REISCHL", "R. MIKUT", "V. HAGENMEYER"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2016}, {"title": "Ein neues Konzept zur Diagnose elektrochemischer Sensoren am Beispiel von pH- Glaselektroden. Dissertation, Karlsruher Institut f\u00fcr Technologie (KIT), KIT Scientific Publishing", "author": ["M. GRUBE"], "venue": "Vorbereitung,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2011}, {"title": "Small Angle X-ray Scattering as a High-throughput Method to Classify Antimicrobial Modes of Action", "author": ["A. VON GUNDLACH", "V. GARAMUS", "T. GORNIAK", "H. DAVIES", "M. REISCHL", "R. MIKUT", "K. HILPERT", "A. ROSENHAHN"], "venue": "Biochimica et Biophysica Acta (BBA)-Biomembranes", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2016}, {"title": "Scalable Machine-Learning Algorithms for Big Data Analytics: A Comprehensive Review. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery", "author": ["P. GUPTA", "A. SHARMA", "R. JINDAL"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2016}, {"title": "The WEKA Data Mining Software: An Update", "author": ["M. HALL", "E. FRANK", "G. HOLMES", "B. PFAHRINGER", "P. REUTEMANN", "I.H. WITTEN"], "venue": "Association for Computing Machinery SIGKDD Explorations Newsletter", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2009}, {"title": "Neural Networks: A Comprehensive Foundation", "author": ["S. HAYKIN"], "venue": "Upper Saddle River, NJ: Prentice Hall,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 1994}, {"title": "The UCI KDD Archive", "author": ["S. HETTICH", "S.D. BAY"], "venue": "University of California, Department of Information and Computer Science. http://kdd.ics.uci.edu,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1999}, {"title": "In vivo Assessment of Tissue Compatibility and Functionality of a Polyimide Cuff Electrode for Recording Afferent Peripheral Nerve Signals", "author": ["B. HIEBL", "S. BOG", "R. MIKUT", "C. BAUER", "O. GEMEINHARDT", "F. JUNG", "T. KR\u00dcGER"], "venue": "Applied Cardiopulmonary Pathophysiology", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2010}, {"title": "Gene Responses in the Central Nervous System of Zebrafish Embryos Exposed to the Neurotoxicant Methyl Mercury", "author": ["N.Y. HO", "L. YANG", "J. LEGRADI", "O. ARMANT", "M. TAKAMIYA", "S. RASTEGAR", "U. STR\u00c4HLE"], "venue": "Environmental Science & Technology", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2013}, {"title": "Fuzzy Cluster Analysis", "author": ["F. H\u00d6PPNER", "F. KLAWONN", "R. KRUSE"], "venue": "New York: John Wiley,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 1999}, {"title": "Survey on Independent Component Analysis", "author": ["A. HYV\u00c4RINEN"], "venue": "Neural Computing Surveys", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 1999}, {"title": "Data Clustering: 50 Years Beyond K-means", "author": ["A.K. JAIN"], "venue": "Pattern Recognition Letters", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2010}, {"title": "Statistical Pattern Recognition: A Review", "author": ["A.K. JAIN", "R.P.W. DUIN", "J. MAO"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2000}, {"title": "Tree-Oriented Hypothesis Generation for Interpretable Fuzzy Rules", "author": ["J. J\u00c4KEL", "L. GR\u00d6LL", "R. MIKUT"], "venue": "Proc., 7th European Congress on Intelligent Techniques and Soft Computing", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 1999}, {"title": "Datenbasierte Analyse und Modellbildung zur Absch\u00e4tzung spezifischer Gefahren des Klimawandels f\u00fcr Stra\u00dfen-Methodik und Szenarien", "author": ["S. KELLER"], "venue": null, "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2015}, {"title": "Feedback-Driven Design of Normalization Techniques for Biological Images Using Fuzzy Formulation of a Priori Knowledge", "author": ["A. KHAN", "M. REISCHL", "B. SCHWEITZER", "C. WEISS", "R. MIKUT"], "venue": "Studies in Computational Intelligence", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2013}, {"title": "A Benchmark Data Set to Evaluate the Illumination Robustness of Image Processing Algorithms for Object Segmentation and Classification", "author": ["A.U.M. KHAN", "R. MIKUT", "M. REISCHL"], "venue": "PLoS One", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2015}, {"title": "A New Feedback-Based Method for Parameter Adaptation in Image Processing Routines", "author": ["A.U.M. KHAN", "R. MIKUT", "M. REISCHL"], "venue": "PloS one", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2016}, {"title": "Fuzzy Control methodenorientiert", "author": ["H. KIENDL"], "venue": "Mu\u0308nchen: Oldenbourg,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 1997}, {"title": "Optimization of Oncocin for Antibacterial Activity using a SPOT Synthesis Approach: Extending the Pathogen Spectrum to Staphylococcus aureus", "author": ["D. KNAPPE", "S. RUDEN", "S. LANGANKE", "T. TIKKOO", "J. RITZER", "R. MIKUT", "L.L. MARTIN", "R. HOFFMANN", "K. HILPERT"], "venue": "Amino Acids", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2016}, {"title": "Identification of Non-visual Photomotor Response Cells in the Vertebrate Hindbrain", "author": ["D. KOKEL", "T. DUNN", "M. AHRENS", "R. ALSHUT", "C.Y. CHEUNG", "L. SAINT-AMANT", "G. BRUNI", "R. MATEUS", "T. VAN HAM", "T. SHIRAKI", "Y. FUKADA", "D. KOJIMA", "J.- R. YEH", "R. MIKUT", "J. VON LINTIG", "F. ENGERT", "R. PETERSON"], "venue": "The Journal of Neuroscience", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2013}, {"title": "Tuned Data Mining: A Benchmark Study on Different Tuners", "author": ["W. KONEN", "P. KOCH", "O. FLASCH", "T. BARTZ-BEIELSTEIN", "M. FRIESE", "B. NAUJOKS"], "venue": "Proc., 13th Annual Conference on Genetic and Evolutionary", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2011}, {"title": "The Great Energy Predictor Shootout", "author": ["J.F. KREIDER", "J.S. HABERL"], "venue": "Proc., ASHRAE Meeting,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 1993}, {"title": "Computational Intelligence", "author": ["A. KROLL"], "venue": "De Gruyter Oldenbourg,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2016}, {"title": "Foundations of Fuzzy Systems", "author": ["R. KRUSE", "F.K.J. GEBHARDT"], "venue": "New York: John Wiley,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 1994}, {"title": "A Survey of Open Source Tools for Machine Learning with Big Data in the Hadoop Ecosystem", "author": ["S. LANDSET", "T.M. KHOSHGOFTAAR", "A.N. RICHTER", "T. HASANIN"], "venue": "Journal of Big Data", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2015}, {"title": "Evaluation of Biometric Signal Characteristics for Movement Classification. Diplomarbeit, Universit\u00e4t Bukarest", "author": ["M. LIPOVEI"], "venue": "Forschungszentrum Karlsruhe,", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2004}, {"title": "Konzept f\u00fcr eine modellgest\u00fctzte Diagnostik mittels Data Mining am Beispiel der Bewegungsanalyse", "author": ["T. LOOSE"], "venue": null, "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2004}, {"title": "STUCKY, K.-U.; KUEHNAPFEL, U.: First Evaluation Results Using the New Electrical Data Recorder for Power Grid Analysis", "author": ["H. MAASS", "H. CAKMAK", "W. SUESS", "A. QUINTE", "W. JAKOB"], "venue": "IEEE Transactions on Instrumentation and Measurement", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2013}, {"title": "Data Processing of High Rate Low Voltage Distribution Grid Recordings for Smart Grid Monitoring and Analysis", "author": ["H. MAASS", "H.K. CAKMAK", "F. BACH", "R. MIKUT", "A. HARRABI", "W. S\u00dcSS", "W. JAKOB", "K.-U. STUCKY", "U.G. K\u00dcHNAPFEL", "V. HAGENMEYER"], "venue": "EURASIP Journal on Advances in Signal Processing", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2015}, {"title": "An Automated and High-throughput Photomotor Response Platform for Chemical Screens", "author": ["D. MARCATO", "R. ALSHUT", "H. BREITWIESER", "R. MIKUT", "U. STR\u00c4HLE", "C. PYLATIUK", "R. PERAVALI"], "venue": "Proc., 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBS),", "citeRegEx": "67", "shortCiteRegEx": "67", "year": 2015}, {"title": "MLlib: Machine Learning in Apache Spark", "author": ["X. MENG", "J. BRADLEY", "B. YUVAZ", "E. SPARKS", "S. VENKATARAMAN", "D. LIU", "J. FREEMAN", "D. TSAI", "M. AMDE", "S OWEN"], "venue": "Journal of Machine Learning Research", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 2016}, {"title": "Machine Learning, Neural and Statistical Classification", "author": ["D. MICHIE", "D. SPIEGELHALTER", "C. TAYLOR"], "venue": null, "citeRegEx": "69", "shortCiteRegEx": "69", "year": 1994}, {"title": "Data Mining in der Medizin und Medizintechnik", "author": ["R. MIKUT"], "venue": "Universita\u0308tsverlag Karlsruhe,", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 2008}, {"title": "Computer-based Analysis, Visualization, and Interpretation of Antimicrobial Peptide Activities", "author": ["R. MIKUT"], "venue": "Methods in Molecular Biology", "citeRegEx": "71", "shortCiteRegEx": "71", "year": 2010}, {"title": "The Open Source Matlab Toolbox Gait-CAD and its Application to Bioelectric Signal Processing", "author": ["R. MIKUT", "O. BURMEISTER", "S. BRAUN", "M. REISCHL"], "venue": "Proc., DGBMT-Workshop Biosignalverarbeitung,", "citeRegEx": "72", "shortCiteRegEx": "72", "year": 2008}, {"title": "Takagi-Sugeno-Kang Fuzzy Classifiers for a Special Class of Time-Varying Systems", "author": ["R. MIKUT", "O. BURMEISTER", "L. GR\u00d6LL", "M. REISCHL"], "venue": "IEEE Transactions on Fuzzy Systems", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 2008}, {"title": "Interpretable Features for the Activity Prediction of Short Antimicrobial Peptides", "author": ["R. MIKUT", "K. HILPERT"], "venue": "Using Fuzzy Logic. International Journal of Peptide Research and Therapeutics", "citeRegEx": "74", "shortCiteRegEx": "74", "year": 2009}, {"title": "Inference Methods for Partially Redundant Rule Bases. In: Fuzzy Control: Theory and Practice (HAMPEL, R.; WAGENKNECHT, M.; CHAKER, N., Hg.)", "author": ["R. MIKUT", "J. J\u00c4KEL", "L. GR\u00d6LL"], "venue": "Advances in Soft Computing,", "citeRegEx": "75", "shortCiteRegEx": "75", "year": 2000}, {"title": "Interpretability Issues in Data-Based Learning of Fuzzy Systems", "author": ["R. MIKUT", "J. J\u00c4KEL", "L. GR\u00d6LL"], "venue": "Fuzzy Sets and Systems", "citeRegEx": "76", "shortCiteRegEx": "76", "year": 2005}, {"title": "Data Mining Tools. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery", "author": ["R. MIKUT", "M. REISCHL"], "venue": null, "citeRegEx": "77", "shortCiteRegEx": "77", "year": 2011}, {"title": "Data Mining in Medical Time Series", "author": ["R. MIKUT", "M. REISCHL", "O. BURMEISTER", "T. LOOSE"], "venue": "Biomedizinische Technik", "citeRegEx": "78", "shortCiteRegEx": "78", "year": 2006}, {"title": "Improving Short Antimicrobial Peptides Despite Elusive Rules for Activity", "author": ["R. MIKUT", "S. RUDEN", "M. REISCHL", "F. BREITLING", "R. VOLKMER", "K. HILPERT"], "venue": "Biochimica et Biophysica Acta (BBA)-Biomembranes", "citeRegEx": "79", "shortCiteRegEx": "79", "year": 2016}, {"title": "SciXMiner: A MATLAB Toolbox for Data Mining of Multidimensional Data", "author": ["R. MIKUT", "J. STEGMAIER", "A. BARTSCHAT", "W. DONEIT", "J. \u00c1NGEL GONZ\u00c1LEZ ORDIANO", "N. PETER", "B. SCHOTT", "S. WACZOWICZ", "M. REISCHL"], "venue": null, "citeRegEx": "80", "shortCiteRegEx": "80", "year": 2017}, {"title": "Neues Konzept f\u00fcr ein modulares Robotersystem zur automatischen Untersuchung von Zebrab\u00e4rblingen in Hochdurchsatzverfahren", "author": ["A. PFRIEM"], "venue": null, "citeRegEx": "81", "shortCiteRegEx": "81", "year": 2016}, {"title": "Modelling the Labyrinth Seal Discharge Coefficient Using Data Mining Methods", "author": ["T. PYCHYNSKI", "G. BLESINGER", "R. MIKUT", "K. DULLENKOPF", "H.-J. BAUER"], "venue": "Proc., ASME TURBO EXPO; Glasgow,", "citeRegEx": "82", "shortCiteRegEx": "82", "year": 2010}, {"title": "Comparison of Surface EMG Monitoring Electrodes for Long-term Use in Rehabilitation Device Control", "author": ["C. PYLATIUK", "M. M\u00dcLLER-RIEDERER", "A. KARGOV", "S. SCHULZ", "O. SCHILL", "M. REISCHL", "G. BRETTHAUER"], "venue": "Proc., International Conference on Rehabilitation Robotics,", "citeRegEx": "83", "shortCiteRegEx": "83", "year": 2009}, {"title": "Automatic Zebrafish Heartbeat Detection and Analysis for Zebrafish Embryos", "author": ["C. PYLATIUK", "D. SANCHEZ", "R. MIKUT", "R. ALSHUT", "M. REISCHL", "S. HIRTH", "W. ROT- TBAUER", "S. JUST"], "venue": "Zebrafish", "citeRegEx": "84", "shortCiteRegEx": "84", "year": 2014}, {"title": "Programs for Machine Learning", "author": ["QUINLAN", "J.R.: C"], "venue": null, "citeRegEx": "85", "shortCiteRegEx": "85", "year": 1993}, {"title": "Targeting Mycobacterium tuberculosis and other Microbial Pathogens using Improved Synthetic Antibacterial Peptides", "author": ["S. RAMON-GARCIA", "R. MIKUT", "C. NG", "S. RUDEN", "R. VOLKMER", "M. REISCHL", "K. HILPERT", "C.J. THOMPSON"], "venue": "Antimicrobial Agents and Chemotherapy", "citeRegEx": "86", "shortCiteRegEx": "86", "year": 2013}, {"title": "Ein Verfahren zum automatischen Entwurf von Mensch-Maschine-Schnittstellen am Beispiel myoelektrischer Handprothesen", "author": ["M. REISCHL"], "venue": null, "citeRegEx": "87", "shortCiteRegEx": "87", "year": 2006}, {"title": "Optimized Classification of Multiclass Problems Applied to EMG-Control of Hand Prostheses", "author": ["M. REISCHL", "L. GR\u00d6LL", "R. MIKUT"], "venue": "Proc., IEEE International Joint Conference on Neural Networks,", "citeRegEx": "88", "shortCiteRegEx": "88", "year": 2004}, {"title": "Evaluation of Data Mining Approaches for the Control of Multifunctional Arm Prostheses", "author": ["M. REISCHL", "L. GR\u00d6LL", "R. MIKUT"], "venue": "Integrated Computer-Aided Engineering", "citeRegEx": "89", "shortCiteRegEx": "89", "year": 2011}, {"title": "Steuerungs- und Signalverarbeitungskonzepte f\u00fcr eine multifunktionale Handprothese", "author": ["M. REISCHL", "R. MIKUT", "C. PYLATIUK", "S. SCHULZ", "S. BECK", "G. BRETTHAUER"], "venue": "at- Automatisierungstechnik", "citeRegEx": "90", "shortCiteRegEx": "90", "year": 2002}, {"title": "Einfluss von Trainingseffekten auf die Parameteradaption f\u00fcr Mensch-Maschine- Schnittstellen in der Medizintechnik", "author": ["M. REISCHL", "M.R. TUGA", "L. MEISTER", "E. ALBERG", "W. DONEIT", "D. LIEBETANZ", "R. RUPP", "R. MIKUT"], "venue": "at-Automatisierungstechnik", "citeRegEx": "91", "shortCiteRegEx": "91", "year": 2016}, {"title": "Asphalt Image Miner: A Tool for Automatic Quantification of Grains", "author": ["M. REISCHL", "A. WITTENBERG", "C. KARCHER", "R. MIKUT"], "venue": "Asphalt Samples. at-Automatisierungstechnik", "citeRegEx": "92", "shortCiteRegEx": "92", "year": 2014}, {"title": "Data Analytics: Models and Algorithms for Intelligent Data Analysis", "author": ["T.A. RUNKLER"], "venue": null, "citeRegEx": "93", "shortCiteRegEx": "93", "year": 2016}, {"title": "HeiDATAProVIT-Heidelberg Data Archiving, Tag Assembling, Processing and Visualization Tool", "author": ["M. SCHABLOWSKI", "J. SCHWEIDLER", "R. RUPP"], "venue": "Computer Methods and Programs in Biomedicine", "citeRegEx": "94", "shortCiteRegEx": "94", "year": 2004}, {"title": "Konzept zur Analyse der Lokomotion auf dem Laufband bei inkompletter Querschnittl\u00e4hmung mit Verfahren der nichtlinearen Dynamik", "author": ["M. SCHABLOWSKI-TRAUTMANN"], "venue": null, "citeRegEx": "95", "shortCiteRegEx": "95", "year": 2006}, {"title": "Konzept zur automatisierten Anpassung der neuronalen Schnittstellen bei nichtinvasiven Neuroprothesen. Dissertation, Karlsruher Institut f\u00fcr Technologie", "author": ["O. SCHILL"], "venue": "KIT Scientific Publishing,", "citeRegEx": "96", "shortCiteRegEx": "96", "year": 2014}, {"title": "Automatic Adaptation of a Self-Adhesive Multi-Electrode Array for Active Wrist Joint Stabilization in Tetraplegics", "author": ["O. SCHILL", "R. RUPP", "C. PYLATIUK", "S. SCHULZ", "M. REISCHL"], "venue": "Proc., IEEE Toronto International Conference\u2013Science and Technology for Humanity,", "citeRegEx": "97", "shortCiteRegEx": "97", "year": 2009}, {"title": "Support Vector Learning", "author": ["B. SCH\u00d6LKOPF"], "venue": "Mu\u0308nchen: Oldenbourg,", "citeRegEx": "98", "shortCiteRegEx": "98", "year": 1997}, {"title": "Robust Individual Circadian Parameter Estimation for Biosignal-based Personalisation of Cancer Chronotherapy", "author": ["B. SCHOTT", "J. STEGMAIER", "A. ARBAUD", "M. REISCHL", "R. MIKUT", "F. L\u00c9VI"], "venue": "Proc., Workshop Biosignal Processing, Berlin, arXiv preprint arXiv:1604.02909,", "citeRegEx": "99", "shortCiteRegEx": "99", "year": 2016}, {"title": "Zebrafish Biosensor for Toxicant Induced Muscle Hyperactivity", "author": ["M. SHAHID", "M. TAKAMIYA", "J. STEGMAIER", "V. MIDDEL", "M. GRADL", "N. KL\u00dcVER", "R. MIKUT", "T. DICKMEIS", "S. SCHOLZ", "S. RASTEGAR", "L. YANG", "U. STR\u00c4HLE"], "venue": "Scientific Reports", "citeRegEx": "100", "shortCiteRegEx": "100", "year": 2016}, {"title": "New Methods to Improve Large-Scale Microscopy Image Analysis with Prior Knowledge and Uncertainty", "author": ["J. STEGMAIER"], "venue": "Dissertation, Karlsruhe Institute of Technology,", "citeRegEx": "101", "shortCiteRegEx": "101", "year": 2016}, {"title": "Information Fusion of Image Analysis, Video Object Tracking, and Data Mining of Biological Images using the Open Source MATLAB Toolbox Gait-CAD", "author": ["J. STEGMAIER", "R. ALSHUT", "M. REISCHL", "R. MIKUT"], "venue": "Biomedizinische Technik (Biomedical Engineering)", "citeRegEx": "102", "shortCiteRegEx": "102", "year": 2012}, {"title": "Real-Time Three-Dimensional Cell Segmentation in Large-Scale Microscopy Data of Developing Embryos", "author": ["J. STEGMAIER", "F. AMAT", "W.B. LEMON", "K. MCDOLE", "Y. WAN", "G. TEODORO", "R. MIKUT", "P.J. KELLER"], "venue": "Developmental Cell", "citeRegEx": "103", "shortCiteRegEx": "103", "year": 2016}, {"title": "Automation Strategies for Large-Scale 3D", "author": ["J. STEGMAIER", "B. SCHOTT", "E. H\u00dcBNER", "M. TRAUB", "M. SHAHID", "M. TAKAMIYA", "A. KO- BITSKI", "V. HARTMANN", "R. STOTZKA", "J. VAN WEZEL", "A. STREIT", "G.U. NIENHAUS", "U. STR\u00c4HLE", "M. REISCHL", "R. MIKUT"], "venue": "Image Analysis. at-Automatisierungstechnik", "citeRegEx": "104", "shortCiteRegEx": "104", "year": 2016}, {"title": "Automated Prior Knowledge-Based Quantification of Neuronal Patterns in the Spinal Cord of Zebrafish", "author": ["J. STEGMAIER", "M. SHAHID", "M. TAKAMIYA", "L. YANG", "S. RASTEGAR", "M. REISCHL", "U. STR\u00c4HLE", "R. MIKUT"], "venue": "Bioinformatics", "citeRegEx": "105", "shortCiteRegEx": "105", "year": 2014}, {"title": "Independent Component Analysis: An Introduction", "author": ["J. STONE"], "venue": "Trends in Cognitive Sciences", "citeRegEx": "106", "shortCiteRegEx": "106", "year": 2002}, {"title": "Multivariate Analysis", "author": ["M.M. TATSUOKA"], "venue": "New York: Macmillan,", "citeRegEx": "107", "shortCiteRegEx": "107", "year": 1988}, {"title": "RAMOS-DELGADO; GARCIA-SANCHEZ, R.: Fisherextest: Fisher\u2019s Exact Probability Test", "author": ["A. TRUJILLO-ORTIZ", "R. HERNANDEZ-WALLS", "A. CASTRO-PEREZ", "N.L. RODRIGUEZ-CARDOZO"], "venue": "A MATLAB file. [WWW document]", "citeRegEx": "108", "shortCiteRegEx": "108", "year": 2004}, {"title": "SOM Toolbox for MAT- LAB", "author": ["J. VESANTO", "J. HIMBERG", "E. ALHONIEMI", "J. PARHANKANGAS"], "venue": "Techn. Ber., Helsinki University of Technology,", "citeRegEx": "109", "shortCiteRegEx": "109", "year": 2000}, {"title": "Data mining to analyse the effects of price signals on household electricity customers", "author": ["S. WACZOWICZ", "S. KLAIBER", "P. BRETSCHNEIDER", "I. KONOTOP", "D. WESTERMANN", "M. REISCHL", "R. MIKUT"], "venue": "at-Automatisierungstechnik", "citeRegEx": "110", "shortCiteRegEx": "110", "year": 2014}, {"title": "Virtual Storages as Theoretically Motivated Demand Response Models for Enhanced Smart Grid Operations", "author": ["S. WACZOWICZ", "M. REISCHL", "S. KLAIBER", "P. BRETSCHNEIDER", "I. KONOTOP", "D. WESTER- MANN", "V. HAGENMEYER", "R. MIKUT"], "venue": "Energy Technology", "citeRegEx": "111", "shortCiteRegEx": "111", "year": 2016}, {"title": "Data Mining with Rattle and R: The Art of Excavating Data for Knowledge Discovery", "author": ["G. WILLIAMS"], "venue": "Springer Science & Business Media,", "citeRegEx": "112", "shortCiteRegEx": "112", "year": 2011}, {"title": "Gait analysis may help to distinguish hereditary spastic paraplegia from cerebral palsy", "author": ["S. WOLF", "F. BRAATZ", "D. METAXIOTIS", "P. ARMBRUST", "T. DREHER", "L. D\u00d6DERLEIN", "R. MIKUT"], "venue": "Gait & Posture", "citeRegEx": "113", "shortCiteRegEx": "113", "year": 2011}, {"title": "Automated Feature Assessment in Instrumented Gait Analysis", "author": ["S. WOLF", "T. LOOSE", "M. SCHABLOWSKI", "L. D\u00d6DERLEIN", "R. RUPP", "H.J. GERNER", "G. BRET- THAUER", "R. MIKUT"], "venue": "Gait & Posture", "citeRegEx": "114", "shortCiteRegEx": "114", "year": 2006}, {"title": "Which Functional Impairments are the Main Contributors to Pelvic Anterior Tilt during Gait in Individuals with Cerebral Palsy", "author": ["S.I. WOLF", "R. MIKUT", "A. KRANZL", "T. DREHER"], "venue": "Gait & Posture", "citeRegEx": "115", "shortCiteRegEx": "115", "year": 2014}, {"title": "Interaction of Blood Components with Cathelicidins and their Modified Versions", "author": ["K. YU", "B.F. LAI", "J. GANI", "R. MIKUT", "K. HILPERT", "J.N. KIZHAKKEDATHU"], "venue": "Biomaterials", "citeRegEx": "116", "shortCiteRegEx": "116", "year": 2015}], "referenceMentions": [{"referenceID": 62, "context": "The toolbox bases on earlier internal versions of Gait-CAD [64, 72].", "startOffset": 59, "endOffset": 67}, {"referenceID": 70, "context": "The toolbox bases on earlier internal versions of Gait-CAD [64, 72].", "startOffset": 59, "endOffset": 67}, {"referenceID": 78, "context": "Please refer to [80] if you use SciXMiner for your scientific work.", "startOffset": 16, "endOffset": 20}, {"referenceID": 100, "context": "\u2022 analysis of images and videos [102, 101] including a link to the ITK-based pipeline generation tool XPIWIT [7], \u2022 object tracking [102, 101], \u2022 tissue detection and fluorescence quantification for zebrafish larvae (algorithms from [32]), \u2022 feature extraction and peptide optimization based on amino-acid distributions and chemical descriptors [71], \u2022 image processing and feature extraction for segmentation of grains in asphalt samples [92], and \u2022 extended measures and visualization to evaluate the quality of data and regression models [28].", "startOffset": 32, "endOffset": 42}, {"referenceID": 99, "context": "\u2022 analysis of images and videos [102, 101] including a link to the ITK-based pipeline generation tool XPIWIT [7], \u2022 object tracking [102, 101], \u2022 tissue detection and fluorescence quantification for zebrafish larvae (algorithms from [32]), \u2022 feature extraction and peptide optimization based on amino-acid distributions and chemical descriptors [71], \u2022 image processing and feature extraction for segmentation of grains in asphalt samples [92], and \u2022 extended measures and visualization to evaluate the quality of data and regression models [28].", "startOffset": 32, "endOffset": 42}, {"referenceID": 6, "context": "\u2022 analysis of images and videos [102, 101] including a link to the ITK-based pipeline generation tool XPIWIT [7], \u2022 object tracking [102, 101], \u2022 tissue detection and fluorescence quantification for zebrafish larvae (algorithms from [32]), \u2022 feature extraction and peptide optimization based on amino-acid distributions and chemical descriptors [71], \u2022 image processing and feature extraction for segmentation of grains in asphalt samples [92], and \u2022 extended measures and visualization to evaluate the quality of data and regression models [28].", "startOffset": 109, "endOffset": 112}, {"referenceID": 100, "context": "\u2022 analysis of images and videos [102, 101] including a link to the ITK-based pipeline generation tool XPIWIT [7], \u2022 object tracking [102, 101], \u2022 tissue detection and fluorescence quantification for zebrafish larvae (algorithms from [32]), \u2022 feature extraction and peptide optimization based on amino-acid distributions and chemical descriptors [71], \u2022 image processing and feature extraction for segmentation of grains in asphalt samples [92], and \u2022 extended measures and visualization to evaluate the quality of data and regression models [28].", "startOffset": 132, "endOffset": 142}, {"referenceID": 99, "context": "\u2022 analysis of images and videos [102, 101] including a link to the ITK-based pipeline generation tool XPIWIT [7], \u2022 object tracking [102, 101], \u2022 tissue detection and fluorescence quantification for zebrafish larvae (algorithms from [32]), \u2022 feature extraction and peptide optimization based on amino-acid distributions and chemical descriptors [71], \u2022 image processing and feature extraction for segmentation of grains in asphalt samples [92], and \u2022 extended measures and visualization to evaluate the quality of data and regression models [28].", "startOffset": 132, "endOffset": 142}, {"referenceID": 31, "context": "\u2022 analysis of images and videos [102, 101] including a link to the ITK-based pipeline generation tool XPIWIT [7], \u2022 object tracking [102, 101], \u2022 tissue detection and fluorescence quantification for zebrafish larvae (algorithms from [32]), \u2022 feature extraction and peptide optimization based on amino-acid distributions and chemical descriptors [71], \u2022 image processing and feature extraction for segmentation of grains in asphalt samples [92], and \u2022 extended measures and visualization to evaluate the quality of data and regression models [28].", "startOffset": 233, "endOffset": 237}, {"referenceID": 69, "context": "\u2022 analysis of images and videos [102, 101] including a link to the ITK-based pipeline generation tool XPIWIT [7], \u2022 object tracking [102, 101], \u2022 tissue detection and fluorescence quantification for zebrafish larvae (algorithms from [32]), \u2022 feature extraction and peptide optimization based on amino-acid distributions and chemical descriptors [71], \u2022 image processing and feature extraction for segmentation of grains in asphalt samples [92], and \u2022 extended measures and visualization to evaluate the quality of data and regression models [28].", "startOffset": 345, "endOffset": 349}, {"referenceID": 90, "context": "\u2022 analysis of images and videos [102, 101] including a link to the ITK-based pipeline generation tool XPIWIT [7], \u2022 object tracking [102, 101], \u2022 tissue detection and fluorescence quantification for zebrafish larvae (algorithms from [32]), \u2022 feature extraction and peptide optimization based on amino-acid distributions and chemical descriptors [71], \u2022 image processing and feature extraction for segmentation of grains in asphalt samples [92], and \u2022 extended measures and visualization to evaluate the quality of data and regression models [28].", "startOffset": 439, "endOffset": 443}, {"referenceID": 27, "context": "\u2022 analysis of images and videos [102, 101] including a link to the ITK-based pipeline generation tool XPIWIT [7], \u2022 object tracking [102, 101], \u2022 tissue detection and fluorescence quantification for zebrafish larvae (algorithms from [32]), \u2022 feature extraction and peptide optimization based on amino-acid distributions and chemical descriptors [71], \u2022 image processing and feature extraction for segmentation of grains in asphalt samples [92], and \u2022 extended measures and visualization to evaluate the quality of data and regression models [28].", "startOffset": 541, "endOffset": 545}, {"referenceID": 29, "context": "A well known definition is given by [30]: Data mining is a step in the KDD process that consists of applying data analysis and discovery algorithms that produce a particular enumeration of patterns (or models) over the data.", "startOffset": 36, "endOffset": 40}, {"referenceID": 92, "context": "by special import routines, like HeiDATAProViT in gait analysis [94]) as the collective of possible evaluation measures in SciXMiner (Figure 3.", "startOffset": 64, "endOffset": 68}, {"referenceID": 23, "context": "Depending on the availability, functions from different toolboxes are called, thereunder standard Matlab functions, functions from internal Matlab toolboxes (see Appendix C), free available Matlab toolboxes (FastICA1, SVM and Kernel Methods Matlab Toolbox [24]2, SOM Toolbox [109]3, lp_solve4, see Appendix D) and many SciXMiner internal functions.", "startOffset": 256, "endOffset": 260}, {"referenceID": 107, "context": "Depending on the availability, functions from different toolboxes are called, thereunder standard Matlab functions, functions from internal Matlab toolboxes (see Appendix C), free available Matlab toolboxes (FastICA1, SVM and Kernel Methods Matlab Toolbox [24]2, SOM Toolbox [109]3, lp_solve4, see Appendix D) and many SciXMiner internal functions.", "startOffset": 275, "endOffset": 280}, {"referenceID": 105, "context": "\u2022 basic knowledge about multivariate statistics and classification [107, 69, 49] and specialties for time series [73],", "startOffset": 67, "endOffset": 80}, {"referenceID": 67, "context": "\u2022 basic knowledge about multivariate statistics and classification [107, 69, 49] and specialties for time series [73],", "startOffset": 67, "endOffset": 80}, {"referenceID": 47, "context": "\u2022 basic knowledge about multivariate statistics and classification [107, 69, 49] and specialties for time series [73],", "startOffset": 67, "endOffset": 80}, {"referenceID": 71, "context": "\u2022 basic knowledge about multivariate statistics and classification [107, 69, 49] and specialties for time series [73],", "startOffset": 113, "endOffset": 117}, {"referenceID": 29, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 24, "endOffset": 44}, {"referenceID": 14, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 24, "endOffset": 44}, {"referenceID": 24, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 24, "endOffset": 44}, {"referenceID": 76, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 24, "endOffset": 44}, {"referenceID": 91, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 24, "endOffset": 44}, {"referenceID": 56, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 71, "endOffset": 75}, {"referenceID": 44, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 131, "endOffset": 139}, {"referenceID": 46, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 131, "endOffset": 139}, {"referenceID": 62, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 169, "endOffset": 173}, {"referenceID": 15, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 201, "endOffset": 209}, {"referenceID": 83, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 201, "endOffset": 209}, {"referenceID": 48, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 241, "endOffset": 249}, {"referenceID": 74, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 241, "endOffset": 249}, {"referenceID": 53, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 277, "endOffset": 294}, {"referenceID": 59, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 277, "endOffset": 294}, {"referenceID": 58, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 277, "endOffset": 294}, {"referenceID": 48, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 326, "endOffset": 342}, {"referenceID": 74, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 326, "endOffset": 342}, {"referenceID": 12, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 326, "endOffset": 342}, {"referenceID": 11, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 326, "endOffset": 342}, {"referenceID": 30, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 388, "endOffset": 396}, {"referenceID": 74, "context": "\u2022 basics in data mining [30, 15, 25, 78, 93] including tuning concepts [58], \u2022 cluster algorithms and Fuzzy C-Means (FCM): basics: [46, 48], specialties for time series [64], \u2022 decision trees (basics: [16, 85], implemented design algorithms [50, 76]), \u2022 fuzzy systems (basics: [117, 55, 61, 60], implemented design algorithms [50, 76, 13, 12]), , specialities to improve interpretability [31, 76]", "startOffset": 388, "endOffset": 396}, {"referenceID": 112, "context": "\u2022 a priori relevances [114, 76], \u2022 Independent Component Analysis [47, 106], \u2022 Support Vector Machines [18, 24, 98], \u2022 k-Nearest Neighbor Methods [26], \u2022 Artificial Neural Networks [42], \u2022 feature aggregation and selection using wrapper approaches [88], \u2022 validation strategies [69], and", "startOffset": 22, "endOffset": 31}, {"referenceID": 74, "context": "\u2022 a priori relevances [114, 76], \u2022 Independent Component Analysis [47, 106], \u2022 Support Vector Machines [18, 24, 98], \u2022 k-Nearest Neighbor Methods [26], \u2022 Artificial Neural Networks [42], \u2022 feature aggregation and selection using wrapper approaches [88], \u2022 validation strategies [69], and", "startOffset": 22, "endOffset": 31}, {"referenceID": 45, "context": "\u2022 a priori relevances [114, 76], \u2022 Independent Component Analysis [47, 106], \u2022 Support Vector Machines [18, 24, 98], \u2022 k-Nearest Neighbor Methods [26], \u2022 Artificial Neural Networks [42], \u2022 feature aggregation and selection using wrapper approaches [88], \u2022 validation strategies [69], and", "startOffset": 66, "endOffset": 75}, {"referenceID": 104, "context": "\u2022 a priori relevances [114, 76], \u2022 Independent Component Analysis [47, 106], \u2022 Support Vector Machines [18, 24, 98], \u2022 k-Nearest Neighbor Methods [26], \u2022 Artificial Neural Networks [42], \u2022 feature aggregation and selection using wrapper approaches [88], \u2022 validation strategies [69], and", "startOffset": 66, "endOffset": 75}, {"referenceID": 17, "context": "\u2022 a priori relevances [114, 76], \u2022 Independent Component Analysis [47, 106], \u2022 Support Vector Machines [18, 24, 98], \u2022 k-Nearest Neighbor Methods [26], \u2022 Artificial Neural Networks [42], \u2022 feature aggregation and selection using wrapper approaches [88], \u2022 validation strategies [69], and", "startOffset": 103, "endOffset": 115}, {"referenceID": 23, "context": "\u2022 a priori relevances [114, 76], \u2022 Independent Component Analysis [47, 106], \u2022 Support Vector Machines [18, 24, 98], \u2022 k-Nearest Neighbor Methods [26], \u2022 Artificial Neural Networks [42], \u2022 feature aggregation and selection using wrapper approaches [88], \u2022 validation strategies [69], and", "startOffset": 103, "endOffset": 115}, {"referenceID": 96, "context": "\u2022 a priori relevances [114, 76], \u2022 Independent Component Analysis [47, 106], \u2022 Support Vector Machines [18, 24, 98], \u2022 k-Nearest Neighbor Methods [26], \u2022 Artificial Neural Networks [42], \u2022 feature aggregation and selection using wrapper approaches [88], \u2022 validation strategies [69], and", "startOffset": 103, "endOffset": 115}, {"referenceID": 25, "context": "\u2022 a priori relevances [114, 76], \u2022 Independent Component Analysis [47, 106], \u2022 Support Vector Machines [18, 24, 98], \u2022 k-Nearest Neighbor Methods [26], \u2022 Artificial Neural Networks [42], \u2022 feature aggregation and selection using wrapper approaches [88], \u2022 validation strategies [69], and", "startOffset": 146, "endOffset": 150}, {"referenceID": 40, "context": "\u2022 a priori relevances [114, 76], \u2022 Independent Component Analysis [47, 106], \u2022 Support Vector Machines [18, 24, 98], \u2022 k-Nearest Neighbor Methods [26], \u2022 Artificial Neural Networks [42], \u2022 feature aggregation and selection using wrapper approaches [88], \u2022 validation strategies [69], and", "startOffset": 181, "endOffset": 185}, {"referenceID": 86, "context": "\u2022 a priori relevances [114, 76], \u2022 Independent Component Analysis [47, 106], \u2022 Support Vector Machines [18, 24, 98], \u2022 k-Nearest Neighbor Methods [26], \u2022 Artificial Neural Networks [42], \u2022 feature aggregation and selection using wrapper approaches [88], \u2022 validation strategies [69], and", "startOffset": 248, "endOffset": 252}, {"referenceID": 67, "context": "\u2022 a priori relevances [114, 76], \u2022 Independent Component Analysis [47, 106], \u2022 Support Vector Machines [18, 24, 98], \u2022 k-Nearest Neighbor Methods [26], \u2022 Artificial Neural Networks [42], \u2022 feature aggregation and selection using wrapper approaches [88], \u2022 validation strategies [69], and", "startOffset": 278, "endOffset": 282}, {"referenceID": 90, "context": "Application Data Domain References Asphalt grain analysis Images Engineering [92] Brain-Machine-Interfaces Time series Medicine [70] Cell classification Images and single features Biology [52]", "startOffset": 77, "endOffset": 81}, {"referenceID": 68, "context": "Application Data Domain References Asphalt grain analysis Images Engineering [92] Brain-Machine-Interfaces Time series Medicine [70] Cell classification Images and single features Biology [52]", "startOffset": 128, "endOffset": 132}, {"referenceID": 50, "context": "Application Data Domain References Asphalt grain analysis Images Engineering [92] Brain-Machine-Interfaces Time series Medicine [70] Cell classification Images and single features Biology [52]", "startOffset": 188, "endOffset": 192}, {"referenceID": 16, "context": "Ceramic actuator optimization Time series and single features Engineering [17]", "startOffset": 74, "endOffset": 78}, {"referenceID": 97, "context": "Circadian parameter estimation Time series Medical technology [99]", "startOffset": 62, "endOffset": 66}, {"referenceID": 49, "context": "Climate change events on streets Time series Engineering [51]", "startOffset": 57, "endOffset": 61}, {"referenceID": 81, "context": "Control of prosthesis with muscle signals Time series Medical technology [83, 87, 89, 91, 97, 96]", "startOffset": 73, "endOffset": 97}, {"referenceID": 85, "context": "Control of prosthesis with muscle signals Time series Medical technology [83, 87, 89, 91, 97, 96]", "startOffset": 73, "endOffset": 97}, {"referenceID": 87, "context": "Control of prosthesis with muscle signals Time series Medical technology [83, 87, 89, 91, 97, 96]", "startOffset": 73, "endOffset": 97}, {"referenceID": 89, "context": "Control of prosthesis with muscle signals Time series Medical technology [83, 87, 89, 91, 97, 96]", "startOffset": 73, "endOffset": 97}, {"referenceID": 95, "context": "Control of prosthesis with muscle signals Time series Medical technology [83, 87, 89, 91, 97, 96]", "startOffset": 73, "endOffset": 97}, {"referenceID": 94, "context": "Control of prosthesis with muscle signals Time series Medical technology [83, 87, 89, 91, 97, 96]", "startOffset": 73, "endOffset": 97}, {"referenceID": 1, "context": "Heartbeat detection of zebrafish Videos Biology [2, 84, 81]", "startOffset": 48, "endOffset": 59}, {"referenceID": 82, "context": "Heartbeat detection of zebrafish Videos Biology [2, 84, 81]", "startOffset": 48, "endOffset": 59}, {"referenceID": 79, "context": "Heartbeat detection of zebrafish Videos Biology [2, 84, 81]", "startOffset": 48, "endOffset": 59}, {"referenceID": 99, "context": "Light-sheet microscopy 3D-Images, 3DVideos Biology [101, 103, 104]", "startOffset": 51, "endOffset": 66}, {"referenceID": 101, "context": "Light-sheet microscopy 3D-Images, 3DVideos Biology [101, 103, 104]", "startOffset": 51, "endOffset": 66}, {"referenceID": 102, "context": "Light-sheet microscopy 3D-Images, 3DVideos Biology [101, 103, 104]", "startOffset": 51, "endOffset": 66}, {"referenceID": 32, "context": "Mobile working machines Time series Engineering [33, 34] Modeling of labyrinth seals Single features Engineering [82]", "startOffset": 48, "endOffset": 56}, {"referenceID": 33, "context": "Mobile working machines Time series Engineering [33, 34] Modeling of labyrinth seals Single features Engineering [82]", "startOffset": 48, "endOffset": 56}, {"referenceID": 80, "context": "Mobile working machines Time series Engineering [33, 34] Modeling of labyrinth seals Single features Engineering [82]", "startOffset": 113, "endOffset": 117}, {"referenceID": 1, "context": "Morphology analysis of zebrafish Images Biology [2, 3, 100, 105]", "startOffset": 48, "endOffset": 64}, {"referenceID": 2, "context": "Morphology analysis of zebrafish Images Biology [2, 3, 100, 105]", "startOffset": 48, "endOffset": 64}, {"referenceID": 98, "context": "Morphology analysis of zebrafish Images Biology [2, 3, 100, 105]", "startOffset": 48, "endOffset": 64}, {"referenceID": 103, "context": "Morphology analysis of zebrafish Images Biology [2, 3, 100, 105]", "startOffset": 48, "endOffset": 64}, {"referenceID": 19, "context": "Movement analysis Time series Medicine [20, 95, 113, 114, 115] Object segmentation of hardware items Images Engineering [53, 54]", "startOffset": 39, "endOffset": 62}, {"referenceID": 93, "context": "Movement analysis Time series Medicine [20, 95, 113, 114, 115] Object segmentation of hardware items Images Engineering [53, 54]", "startOffset": 39, "endOffset": 62}, {"referenceID": 111, "context": "Movement analysis Time series Medicine [20, 95, 113, 114, 115] Object segmentation of hardware items Images Engineering [53, 54]", "startOffset": 39, "endOffset": 62}, {"referenceID": 112, "context": "Movement analysis Time series Medicine [20, 95, 113, 114, 115] Object segmentation of hardware items Images Engineering [53, 54]", "startOffset": 39, "endOffset": 62}, {"referenceID": 113, "context": "Movement analysis Time series Medicine [20, 95, 113, 114, 115] Object segmentation of hardware items Images Engineering [53, 54]", "startOffset": 39, "endOffset": 62}, {"referenceID": 51, "context": "Movement analysis Time series Medicine [20, 95, 113, 114, 115] Object segmentation of hardware items Images Engineering [53, 54]", "startOffset": 120, "endOffset": 128}, {"referenceID": 52, "context": "Movement analysis Time series Medicine [20, 95, 113, 114, 115] Object segmentation of hardware items Images Engineering [53, 54]", "startOffset": 120, "endOffset": 128}, {"referenceID": 37, "context": "Optimization of antimicrobial peptides Sequences Chemistry [38, 56, 71, 74, 86, 79, 116] Peripheral nerve signals of rats Time series Biology [44]", "startOffset": 59, "endOffset": 88}, {"referenceID": 54, "context": "Optimization of antimicrobial peptides Sequences Chemistry [38, 56, 71, 74, 86, 79, 116] Peripheral nerve signals of rats Time series Biology [44]", "startOffset": 59, "endOffset": 88}, {"referenceID": 69, "context": "Optimization of antimicrobial peptides Sequences Chemistry [38, 56, 71, 74, 86, 79, 116] Peripheral nerve signals of rats Time series Biology [44]", "startOffset": 59, "endOffset": 88}, {"referenceID": 72, "context": "Optimization of antimicrobial peptides Sequences Chemistry [38, 56, 71, 74, 86, 79, 116] Peripheral nerve signals of rats Time series Biology [44]", "startOffset": 59, "endOffset": 88}, {"referenceID": 84, "context": "Optimization of antimicrobial peptides Sequences Chemistry [38, 56, 71, 74, 86, 79, 116] Peripheral nerve signals of rats Time series Biology [44]", "startOffset": 59, "endOffset": 88}, {"referenceID": 77, "context": "Optimization of antimicrobial peptides Sequences Chemistry [38, 56, 71, 74, 86, 79, 116] Peripheral nerve signals of rats Time series Biology [44]", "startOffset": 59, "endOffset": 88}, {"referenceID": 114, "context": "Optimization of antimicrobial peptides Sequences Chemistry [38, 56, 71, 74, 86, 79, 116] Peripheral nerve signals of rats Time series Biology [44]", "startOffset": 59, "endOffset": 88}, {"referenceID": 42, "context": "Optimization of antimicrobial peptides Sequences Chemistry [38, 56, 71, 74, 86, 79, 116] Peripheral nerve signals of rats Time series Biology [44]", "startOffset": 142, "endOffset": 146}, {"referenceID": 36, "context": "pH sensor diagnosis Time series Engineering [37] Photo-Motor Response Images, Time series Biology [57, 67]", "startOffset": 44, "endOffset": 48}, {"referenceID": 55, "context": "pH sensor diagnosis Time series Engineering [37] Photo-Motor Response Images, Time series Biology [57, 67]", "startOffset": 98, "endOffset": 106}, {"referenceID": 65, "context": "pH sensor diagnosis Time series Engineering [37] Photo-Motor Response Images, Time series Biology [57, 67]", "startOffset": 98, "endOffset": 106}, {"referenceID": 34, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 45, "endOffset": 53}, {"referenceID": 35, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 45, "endOffset": 53}, {"referenceID": 7, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 87, "endOffset": 101}, {"referenceID": 9, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 87, "endOffset": 101}, {"referenceID": 8, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 87, "endOffset": 101}, {"referenceID": 10, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 87, "endOffset": 101}, {"referenceID": 20, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 145, "endOffset": 171}, {"referenceID": 63, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 145, "endOffset": 171}, {"referenceID": 64, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 145, "endOffset": 171}, {"referenceID": 108, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 145, "endOffset": 171}, {"referenceID": 109, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 145, "endOffset": 171}, {"referenceID": 2, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 202, "endOffset": 212}, {"referenceID": 3, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 202, "endOffset": 212}, {"referenceID": 43, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 202, "endOffset": 212}, {"referenceID": 5, "context": "Photovoltaic systems Time series Engineering [35, 36] Robotics Time series Engineering [8, 10, 9, 11] Smart energy grids Time series Engineering [21, 40, 65, 66, 110, 111] Toxicity tests Images Biology [3, 4, 45] Wind power systems Time series Engineering [6]", "startOffset": 256, "endOffset": 259}, {"referenceID": 39, "context": "\u2022 alternative data mining software as Weka [41], Knime [14], Apache Spark\u2019s machine learning library [68], Keel [1], Rattle/R [112], see surveys in [77, 62, 39]", "startOffset": 43, "endOffset": 47}, {"referenceID": 13, "context": "\u2022 alternative data mining software as Weka [41], Knime [14], Apache Spark\u2019s machine learning library [68], Keel [1], Rattle/R [112], see surveys in [77, 62, 39]", "startOffset": 55, "endOffset": 59}, {"referenceID": 66, "context": "\u2022 alternative data mining software as Weka [41], Knime [14], Apache Spark\u2019s machine learning library [68], Keel [1], Rattle/R [112], see surveys in [77, 62, 39]", "startOffset": 101, "endOffset": 105}, {"referenceID": 0, "context": "\u2022 alternative data mining software as Weka [41], Knime [14], Apache Spark\u2019s machine learning library [68], Keel [1], Rattle/R [112], see surveys in [77, 62, 39]", "startOffset": 112, "endOffset": 115}, {"referenceID": 110, "context": "\u2022 alternative data mining software as Weka [41], Knime [14], Apache Spark\u2019s machine learning library [68], Keel [1], Rattle/R [112], see surveys in [77, 62, 39]", "startOffset": 126, "endOffset": 131}, {"referenceID": 75, "context": "\u2022 alternative data mining software as Weka [41], Knime [14], Apache Spark\u2019s machine learning library [68], Keel [1], Rattle/R [112], see surveys in [77, 62, 39]", "startOffset": 148, "endOffset": 160}, {"referenceID": 60, "context": "\u2022 alternative data mining software as Weka [41], Knime [14], Apache Spark\u2019s machine learning library [68], Keel [1], Rattle/R [112], see surveys in [77, 62, 39]", "startOffset": 148, "endOffset": 160}, {"referenceID": 38, "context": "\u2022 alternative data mining software as Weka [41], Knime [14], Apache Spark\u2019s machine learning library [68], Keel [1], Rattle/R [112], see surveys in [77, 62, 39]", "startOffset": 148, "endOffset": 160}, {"referenceID": 57, "context": "The goal of the Building-data set was to examine the effect of different parameters on the power consumption of a known building [59].", "startOffset": 129, "endOffset": 133}, {"referenceID": 22, "context": "Since the extraction of the single trials should be start exactly at a trigger event and end 23 sample points after the trigger event (resulting in 24 hours after the trigger event), the offset is set to [0, 23].", "startOffset": 204, "endOffset": 211}, {"referenceID": 41, "context": "The Iris data set (downloadable from UCI-Repository [43]) is one of the most-famous benchmark data sets for the comparison of classifiers.", "startOffset": 52, "endOffset": 56}, {"referenceID": 4, "context": "The data set contains 150 examples of three different irises, every single iris is represented by 50 examples [5].", "startOffset": 110, "endOffset": 113}, {"referenceID": 0, "context": "The feature numbers start with x[1] instead of x[0]!", "startOffset": 32, "endOffset": 35}, {"referenceID": 18, "context": "Some hints to the algorithms are given in [19].", "startOffset": 42, "endOffset": 46}, {"referenceID": 22, "context": "The one-class method uses a SVM optimization proposed by [23].", "startOffset": 57, "endOffset": 61}, {"referenceID": 62, "context": "5, [64]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 74, "context": "However, a split by existing membership functions is used instead of a new computed binary split in each node [76].", "startOffset": 110, "endOffset": 114}, {"referenceID": 85, "context": "2) in [87]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 85, "context": "4) in [87]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 85, "context": "7) in [87]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 18, "context": "\u2022 Feature maps (all time series, selected data points): computes feature relevances of all time series and shows the results as scatter plot (x axis: Time, y axis: number of time series, color: feature relevance) [19].", "startOffset": 213, "endOffset": 217}, {"referenceID": 106, "context": "Otherwise for cross tabulations with only two values 0 and 1, the (more conservative) Two-tail Exact Fisher Test is used in the implementation of [108] (function \u201dfisherextest\u201d).", "startOffset": 146, "endOffset": 151}, {"referenceID": 21, "context": "The different classifier types are described in [22].", "startOffset": 48, "endOffset": 52}, {"referenceID": 85, "context": "\u2022 Design: designs a Hierarchical Bayes classifier by a step-wise separation of single classes from all other classes [87].", "startOffset": 117, "endOffset": 121}, {"referenceID": 74, "context": "The design algorithms are described in [76].", "startOffset": 39, "endOffset": 43}, {"referenceID": 62, "context": "[64]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "For stability reasons, the value is limited to [0, 1].", "startOffset": 47, "endOffset": 53}, {"referenceID": 88, "context": "\u2022 IIR parameter (aF, aS, aSigma): defines the parameters for three different IIR filters for trend and standard deviation computation (see [90]).", "startOffset": 139, "endOffset": 143}, {"referenceID": 61, "context": "[63] or the documentation of the Matlab Wavelet Toolbox).", "startOffset": 0, "endOffset": 4}, {"referenceID": 61, "context": "\u2022 Matlab wavelet decomposition: uses the Matlab implementation instead of the implementation of [63] for the wavelet decomposition.", "startOffset": 96, "endOffset": 100}, {"referenceID": 22, "context": "A data point z is handled as outlier if f(z) < Threshold (see [23] for algorithm details).", "startOffset": 62, "endOffset": 66}, {"referenceID": 0, "context": "The neighborhood is defined by a maximal ([0,1]-normalized Euclidean) distance.", "startOffset": 42, "endOffset": 47}, {"referenceID": 22, "context": "A data point z is handled as outlier if f(z) < Threshold (see [23] for algorithm details).", "startOffset": 62, "endOffset": 66}, {"referenceID": 0, "context": "The neighborhood is defined by a maximal ([0,1]-normalized Euclidean) distance.", "startOffset": 42, "endOffset": 47}, {"referenceID": 0, "context": "Two approaches are implemented; to the interval [0, 1] or to a mean value of zero and a standard deviation of one under the assumption of a normal distribution.", "startOffset": 48, "endOffset": 54}, {"referenceID": 85, "context": "[87]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 85, "context": "Available options are an a maximization of the classification accuracy (\u201dbest_class\u201d) or a maximization of the minimal distance between two classes using class-specific covariance matrixes as metric (\u201dbest_ldf\u201d) [87].", "startOffset": 212, "endOffset": 216}, {"referenceID": 0, "context": "Two approaches are implemented; to the interval [0, 1] or to a mean value of zero and a standard deviation of one under the assumption of a normal distribution.", "startOffset": 48, "endOffset": 54}, {"referenceID": 21, "context": "[22, 73] give a detailed description of the classifiers.", "startOffset": 0, "endOffset": 8}, {"referenceID": 71, "context": "[22, 73] give a detailed description of the classifiers.", "startOffset": 0, "endOffset": 8}, {"referenceID": 21, "context": "[22, 73] give a detailed description of the classifiers.", "startOffset": 0, "endOffset": 8}, {"referenceID": 71, "context": "[22, 73] give a detailed description of the classifiers.", "startOffset": 0, "endOffset": 8}, {"referenceID": 0, "context": "Two approaches are implemented; to the interval [0, 1] or to a mean value of zero and a standard deviation of one under the assumption of a normal distribution.", "startOffset": 48, "endOffset": 54}, {"referenceID": 85, "context": "[87]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "Two approaches are implemented; to the interval [0, 1] or to a mean value of zero and a standard deviation of one under the assumption of a normal distribution.", "startOffset": 48, "endOffset": 54}, {"referenceID": 26, "context": "\u2022 Distance measure for the noise cluster: defines the method for the definition of a noise cluster [27] for a Fuzzy C-Means method.", "startOffset": 99, "endOffset": 103}, {"referenceID": 26, "context": "Possible distance measures are the mean distance of all data points to all other clusters [27] or the median of these distances.", "startOffset": 90, "endOffset": 94}, {"referenceID": 17, "context": "\u2022 Kernel: defines the used kernel function for Support Vector Machines [18].", "startOffset": 71, "endOffset": 75}, {"referenceID": 74, "context": "The choice \u201dwith interpretability\u201d rounds the found parameters using a method described in [76] to improve the interpretability.", "startOffset": 91, "endOffset": 95}, {"referenceID": 74, "context": "\u2022 Exponent for clearness: defines the evaluation method for the pruning of fuzzy rules [76].", "startOffset": 87, "endOffset": 91}, {"referenceID": 73, "context": "An additional correction of overlapping rules [75] was implemented for artifacts by rules with the same or concurrent conclusions in case of the SUM-PROD inference.", "startOffset": 46, "endOffset": 50}, {"referenceID": 74, "context": "The choice \u201dwith interpretability\u201d rounds the found parameters using a method described in [76] to improve the interpretability.", "startOffset": 91, "endOffset": 95}, {"referenceID": 28, "context": "[29]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 62, "context": "Such categories might be used in different analysis and visualization functions (see [64, 114]).", "startOffset": 85, "endOffset": 94}, {"referenceID": 112, "context": "Such categories might be used in different analysis and visualization functions (see [64, 114]).", "startOffset": 85, "endOffset": 94}, {"referenceID": 112, "context": "(3) in [114] for a segment)", "startOffset": 7, "endOffset": 12}, {"referenceID": 112, "context": "(3) in [114] without the absolute value in the nominator)", "startOffset": 7, "endOffset": 12}, {"referenceID": 62, "context": "3) in [64]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 88, "context": "The computation is explained in [90].", "startOffset": 32, "endOffset": 36}, {"referenceID": 88, "context": "(2-6) in [90] with aF = aSigma, aL = aSlow, aS = aFast.", "startOffset": 9, "endOffset": 13}, {"referenceID": 112, "context": "(3) in [114])", "startOffset": 7, "endOffset": 12}, {"referenceID": 62, "context": "9) in [64])", "startOffset": 6, "endOffset": 10}, {"referenceID": 62, "context": "2) in [64])", "startOffset": 6, "endOffset": 10}], "year": 2017, "abstractText": null, "creator": "LaTeX with hyperref package"}}}