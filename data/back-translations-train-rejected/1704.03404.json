{"id": "1704.03404", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Apr-2017", "title": "ENWalk: Learning Network Features for Spam Detection in Twitter", "abstract": "Social medias are increasing their influence with the vast public information leading to their active use for marketing by the companies and organizations. Such marketing promotions are difficult to identify unlike the traditional medias like TV and newspaper. So, it is very much important to identify the promoters in the social media. Although, there are active ongoing researches, existing approaches are far from solving the problem. To identify such imposters, it is very much important to understand their strategies of social circle creation and dynamics of content posting. Are there any specific spammer types? How successful are each types? We analyze these questions in the light of social relationships in Twitter. Our analyses discover two types of spammers and their relationships with the dynamics of content posts. Our results discover novel dynamics of spamming which are intuitive and arguable. We propose ENWalk, a framework to detect the spammers by learning the feature representations of the users in the social media. We learn the feature representations using the random walks biased on the spam dynamics. Experimental results on large-scale twitter network and the corresponding tweets show the effectiveness of our approach that outperforms the existing approaches", "histories": [["v1", "Tue, 11 Apr 2017 16:37:37 GMT  (313kb)", "http://arxiv.org/abs/1704.03404v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.SI", "authors": ["k c santosh", "suman kalyan maity", "arjun mukherjee"], "accepted": false, "id": "1704.03404"}, "pdf": {"name": "1704.03404.pdf", "metadata": {"source": "CRF", "title": "ENWalk: Learning Network Features for Spam Detection in Twitter", "authors": ["Santosh K C", "Suman Kalyan Maity", "Arjun Mukherjee"], "emails": ["skc@uh.edu,", "sumankalyan.maity@cse.iitkgp.ernet.in,", "arjun@uh.edu"], "sections": [{"heading": null, "text": "Tags: Social Network; Spam Detection; Feature Learning"}, {"heading": "1 Introduction", "text": "Twitter is one of the popular platforms on which people post information in the form of tweets and share the tweets. Twitter is available to all people from a wide range of web-enabled services. Thus, the real-time reflection of a society can be viewed on Twitter. Celebrities, governments, politicians, companies are active on Twitter to provide updates and listen to people's views. Thus, the bidirectional flow of information is high. The openness of online platforms and the dependence on users makes it easier for spammers to easily penetrate the platform and overwhelm users with malicious intent and content. This work attempts to use a case study of twitter.Spammers on social networks constantly adapt to avoid detection. Furthermore, they follow reflexive reciprocity [6, 17] (Users follow back when they are pursued by someone to show courtesy, valorize and act normally."}, {"heading": "2 Related Work", "text": "There has been several work on spam detection in general, in particular spam verification [7] and opinion spam, but there are limited experiments in Twitter. One of the earliest work was done by Benevenuto et al. [1], which manually designated and trained a traditional classifier using properties extracted from user content and behavior. Lee et al. used profile-based functions and social honey throwers to detect new social spammers [9]. Stringhini et al. also investigated spam detection using honey profiles [14]. Ghosh et al. investigated the problem of linking farming in Twitter [4] and introduced a ranking methodology to punish the left-wing. Abuse of online social networks was investigated in [16]. Campaign spams were investigated using honey profiles [3, 10, 19]."}, {"heading": "3 Dataset", "text": "For this work, we use the Twitter data set used in [18], which contains 17 million users who blocked 467 million Twitter posts for a seven-month period between June 1, 2009 and December 31, 2009. To extract the network graph for these 17 million users, we extracted the following topology from Twitter [8], which includes all Twitter user profiles and their social relationships through July 2009. To obtain the suspension status of accounts in [8] and tweets in [18], we left 4,405,698 users behind. Twitter suspends the accounts involved in the malicious activity (https: / / support.twitter.com / articles / 18311). To obtain the suspension status of accounts, we re-searched the profile pages of all 17 million users, resulting in a total of 100,758 accounts that have been suspended (the profile page leads to the https: / / / twitter.com / / account)."}, {"heading": "4 Spam Analysis", "text": "Characterizing the dominant types of spammers is important because it is the first step in understanding spamming dynamics. We examined the spammers \"networking strategies based on the following strategies: (1) post-flood spammers and (2) vigilant spammers. So why are some spammers more successful? In this section, we will examine the behavioral aspects of spammers\" tweet dynamics. Later, we will use them in modeling."}, {"heading": "4.1 Spammer Type", "text": "To analyze follower tracking strategies, we calculated the number of followers (users following the current user) and the number of followers (users following the current user) for each spammer. Figure 1 shows the chart in log scale counting. It shows that the follower and the following count are different for each spammer. Users with more followers than followers tend to be more successful because they have been able to \"earn\" a lot of users following them. Therefore, we define the success rate as: = # the follower of followers of (1) Based on the success rate of network expansion, we find two dominant spamming strategies: 4.2 Activity Window We calculate the activity window as the number of days on which a user is active on the Twitter network. Since we do not have the exact time a user has been suspended, we estimate the time of the default spamming rate as the date of the last tweet of a usage window with an average of 13 days. We found out that the duration of a user's suspension varies from 13 to 19 days."}, {"heading": "4.3 Fraudulence", "text": "One of the main reasons for spam is the injection of constant fraudulent information. Therefore, we analyzed the fraudulent behavior of the two types of spammers. We called the tweets containing advertising, adult or black URLs fraudulent tweets. So we calculate fraudulent tweets as: = # fraudulent tweets out of a total of tweets of (2) We found that the average fraudulent activity of vigilant spammers is 0.34 compared to 0.86 subsequent spammers. So spammers are more involved in spam after the flood."}, {"heading": "4.4 Mentioning Celebrities and Popular Hashtags", "text": "Mentioning popular celebrities or hashtags strengthens a tweet. Therefore, one of the usual strategies of spammers is to include popular celebrities in their tweets. We looked at mentioning phenomena and found that vigilant spammers mention half the celebrities per tweet, compared to the subsequent spammers."}, {"heading": "5 Learning Latent Features for Spam Detection", "text": "After characterizing the dynamics of spamming on Twitter, can we improve spam detection beyond existing state-of-the-art approaches? To answer this, we used our Twitter data to set up a latent feature-learning problem in networks. Our analysis is general and can be used for any social network."}, {"heading": "5.1 Overview", "text": "As discussed in the previous section, the dynamics of Twitter are interesting and can be used to catch the spammers. Therefore, we use spam dynamics to formulate the latent feature learning in social networks. Let's be a given network with vertices, edges and the social network data of users on the social network. We aim to learn a mapping function: from nodes to a d-dimensional feature representation that can be used to predict. This parameter specifies the number of dimensions of the latent features so that the size is of. We present a novel sampling strategy in which nodes on the network exploit the spam dynamics so that the corresponding neighborhood () contains the node that exhibits a similar Twitter behavior with the node. We generate () for each node on the network a sampling strategy that predicts which nodes which nodes are members of the corresponding neighbors of, based on the features learned that have a similar behavior to the node."}, {"heading": "5.2 The Optimization Problem", "text": "Since our goal is to learn the latent features that best describe the equivalent neighborhood () of the node (expensive) (current), we define the optimization problem as follows: () () () () () (3) In order to solve the optimization problem, we extend the SkipGram architecture [5, 13, 15], which approximates conditional probability using the assumption that the probability of observing an equivalent neighborhood node is independent of observing another equivalent neighborhood node. () () () ()) ()) () () () ()) () () ()) () () ()) () () () () ()) () () () ()) () () () () ()) () () () () () ()) () () () () ()) () () () () ()) () () () () () () () () () () () () () () () ()) () () () ()) () () () () ()) () () () () ()) () () () ()) () () ()) () () ()) () () ()) () () ()) () () ()) () () ()) () () () () ()) () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () (() () () () () () () () () (() () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () ()"}, {"heading": "5.3 Equivalent Neighborhood Generation", "text": "Analysis of spam dynamics leads to an important conclusion that the nodes are similar when they exhibit similar spam dynamics. (So we want to use these dynamics to generate the equivalent neighborhood based on the four dynamics: shared activity time (), success rate difference (), fraudulent similarities ("}, {"heading": "5.4 Algorithm: ENWalk", "text": "Algorithm 1 describes our entire scheme. We start with random paths of fixed length at each node times. To obtain each migration, we use GetEquivalentNeighbor, the random sampler, which randomly captures the node based on the transition probabilities calculated in Eq.12. It is worth noting that the tweet dynamics between the nodes (,,,,), defined in Eq.7, 8, 9, 10 and / or. Once we have random shifts, we can use the optimization function in Eq.6 to obtain a window size of dimensional numerical characteristics. The three phases of preprocessing, random sampling and optimization are asynchronous, so that ENWalk is scalable."}, {"heading": "6 Experiment", "text": "We have used ENWalk on Twitter data sets to evaluate their effectiveness. In this section we discuss the basic methods and compare them with ENWalk for classification and ranking."}, {"heading": "6.1 Baseline Methods", "text": "In fact, most of them are able to outdo themselves."}, {"heading": "6.2 Node Classification", "text": "Similar to node2vec and DeepWalk, we used the parameters = 128, = 10, = 80, = 10. We found that the parameters are sensitive in a similar way to node2vec and DeepWalk. We used each feature representation as an example of a standard SVM classifier. We used a 10-fold cross-validation using balancedS M N S 0.80 0.40 0.025 M 0.15 0.50 0.125 N 0.05 0.10 0.850 is effective to examine the nodes that are likely to be spammers. To evaluate ENWalk's ranking performance, we use logistic regression for the features obtained from the model. We compare our model with PageRank and MarRandom Field models that have the highest precision."}, {"heading": "7 Conclusion", "text": "This data-driven approach is very important as there is a lot of data from social media online today. We have demonstrated the helpfulness of biased random walks in embedding learning nodes that can be used for classification and ranking tasks. Recognition: This work is partially supported by NSF 1527364. We also thank anonymous reviewers for their helpful feedback. Figure 2. Cumulative Distribution Function of Suspended NodesTable 3. Ranking Results: Area Under CDF Curve (AUC) and Precision @ 100 (P @ 100) Model AUC P @ 100 PR-T 0.4059 0.02 PR-TITP 0.4181 0.03 MRF 0.4944 0.02 DeepF Curve (AUC) and Precision @ 100 (P @ 100) Model AUC P @ 100 PR-T 0.4181 0.02 0.505 Walnok 0.5360,005"}, {"heading": "8 References", "text": "[1] Benevenuto, F., Magno, G., Rodrigues, T. and Almeida, V. 2010. Detecting spammers ontwitter. Collaboration, electronic messaging, anti-abuse and spam conference (CEAS). 6, (2010), 12. [2] Fei, G., Mukherjee, A., Liu, B., Hsu, M., Castellanos, M. and Ghosh, R. 2013. ExploitingBurstiness in Reviews G. H. Proceedings of the Seventh International Conference on Weblogs and Social Media, {ICWSM} 2013, Cambridge, Massachusetts, USA, July 8-11, 2013. (2013) Gao, H., J., Wilson, C., Z., Chen, Y. and Zhao, B.Y. 2010. Detecting and characterizing social spam campaigns. Proceedings of the 10th ACM SIGM SIGCOMM conference on Internet measurement."}], "references": [{"title": "Detecting spammers on twitter. Collaboration, electronic messaging, anti-abuse and spam conference (CEAS)", "author": ["F. Benevenuto", "G. Magno", "T. Rodrigues", "V. Almeida"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Exploiting Burstiness in Reviews for Review Spammer Detection", "author": ["G. Fei", "A. Mukherjee", "B. Liu", "M. Hsu", "M. Castellanos", "R. Ghosh"], "venue": "Proceedings of the Seventh International Conference on Weblogs and Social Media,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Detecting and characterizing social spam campaigns", "author": ["H. Gao", "J. Hu", "C. Wilson", "Z. Li", "Y. Chen", "B.Y. Zhao"], "venue": "Proceedings of the 10th ACM SIGCOMM conference on Internet measurement", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Understanding and combating link farming in the twitter social network", "author": ["S. Ghosh", "B. Viswanath", "F. Kooti", "N.K. Sharma", "G. Korlam", "F. Benevenuto", "N. Ganguly", "K.P. Gummadi"], "venue": "Proceedings of the 21st ...", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "node2vec: Scalable feature learning for networks", "author": ["A. Grover", "J. Leskovec"], "venue": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Social Spammer Detection in Microblogging", "author": ["X. Hu", "J. Tang", "Y. Zhang", "H. Liu"], "venue": "IJCAI", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "On the Temporal Dynamics of Opinion Spamming: Case Studies on Yelp", "author": ["S. K C", "A. Mukherjee"], "venue": "25th International World Wide Web Conference,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "What is Twitter , a Social Network or a News Media", "author": ["H. Kwak", "C. Lee", "H. Park", "S. Moon"], "venue": "The International World Wide Web Conference Committee", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Uncovering social spammers: social honeypots+ machine learning", "author": ["K. Lee", "J. Caverlee", "S. Webb"], "venue": "Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Detecting Campaign Promoters on Twitter", "author": ["H. Li", "A. Mukherjee", "B. Liu", "R. Kornfield", "S. Emery"], "venue": "Using Markov Random Fields. 2014 {IEEE} International Conference on Data Mining,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Distributed Representations of Words and Phrases and their Compositionality. Nips", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Efficient Estimation of Word Representations in Vector Space", "author": ["T. Mikolov", "G. Corrado", "K. Chen", "J. Dean"], "venue": "Proceedings of the International Conference on Learning Representations (ICLR", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Deepwalk: Online learning of social representations", "author": ["B. Perozzi", "R. Al-Rfou", "S. Skiena"], "venue": "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Detecting spammers on social networks. Proceedings of the 26th annual computer security applications conference", "author": ["G. Stringhini", "C. Kruegel", "G. Vigna"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Line: Large-scale information network embedding", "author": ["J. Tang", "M. Qu", "M. Wang", "M. Zhang", "J. Yan", "Q. Mei"], "venue": "Proceedings of the 24th International Conference on World Wide Web", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Suspended accounts in retrospect: an analysis of twitter spam", "author": ["K. Thomas", "C. Grier", "D. Song", "V. Paxson"], "venue": "Proceedings of the 2011 ACM ...", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Twitterrank: Finding topic-sensitive influential twitterers", "author": ["J. Weng", "E.P. Lim", "J. Jiang", "Q. He"], "venue": "Proceedings of the 3rd ACM International Conference on Web Search and Data Mining (WSDM", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Patterns of temporal variation in online media", "author": ["J. Yang", "J. Leskovec"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Detecting spam and promoting campaigns in the Twitter social network", "author": ["X. Zhang", "S. Zhu", "W. Liang"], "venue": "Proceedings - IEEE International Conference on Data Mining,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}], "referenceMentions": [{"referenceID": 5, "context": "Moreover, they follow reflexive reciprocity [6, 17] (users following back when they are followed by someone to show courtesy) to establish social influence and act normal.", "startOffset": 44, "endOffset": 51}, {"referenceID": 16, "context": "Moreover, they follow reflexive reciprocity [6, 17] (users following back when they are followed by someone to show courtesy) to establish social influence and act normal.", "startOffset": 44, "endOffset": 51}, {"referenceID": 6, "context": "There have been several works on spam detection in general, especially review spam [7], and opinion spam.", "startOffset": 83, "endOffset": 86}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "leveraged profile-based features and deployed social honeypots to detect new social spammers [9].", "startOffset": 93, "endOffset": 96}, {"referenceID": 13, "context": "also studied spam detection using honey profiles [14].", "startOffset": 49, "endOffset": 53}, {"referenceID": 3, "context": "studied the problem of link farming in Twitter [4] and introduced a ranking methodology to penalize the link farmers.", "startOffset": 47, "endOffset": 50}, {"referenceID": 15, "context": "Abuse of online social networks was studied in [16].", "startOffset": 47, "endOffset": 51}, {"referenceID": 2, "context": "Campaign spams was studied on [3, 10, 19].", "startOffset": 30, "endOffset": 41}, {"referenceID": 9, "context": "Campaign spams was studied on [3, 10, 19].", "startOffset": 30, "endOffset": 41}, {"referenceID": 18, "context": "Campaign spams was studied on [3, 10, 19].", "startOffset": 30, "endOffset": 41}, {"referenceID": 11, "context": "Skip-gram model [12] has been popular to learn the features from a large corpus of data.", "startOffset": 16, "endOffset": 20}, {"referenceID": 12, "context": "DeepWalk [13] learns d-dimensional feature representations by simulating uniform random walks.", "startOffset": 9, "endOffset": 13}, {"referenceID": 14, "context": "LINE [15] learns the d-dimensional features into two phases: d/2 BFS-style simulations and another d/2 2-hop distant nodes.", "startOffset": 5, "endOffset": 9}, {"referenceID": 4, "context": "Node2vec [5] creates the ordered sequence simulating the BFS and DFS approaches.", "startOffset": 9, "endOffset": 12}, {"referenceID": 17, "context": "For this work, we use the Twitter dataset used in [18].", "startOffset": 50, "endOffset": 54}, {"referenceID": 7, "context": "To extract the network graph for those 17 million users, we extracted the follower-following topology of Twitter from [8] which contains all the entire twitter user profiles and their social relationships till July 2009.", "startOffset": 118, "endOffset": 121}, {"referenceID": 7, "context": "We pruned the users so that they have social relationship in [8] and tweets in [18] and are left with 4,405,698 users.", "startOffset": 61, "endOffset": 64}, {"referenceID": 17, "context": "We pruned the users so that they have social relationship in [8] and tweets in [18] and are left with 4,405,698 users.", "startOffset": 79, "endOffset": 83}, {"referenceID": 4, "context": "To solve the optimization problem, we extend the SkipGram architecture [5, 13, 15] which approximates the conditional probability using an independence assumption that the likelihood of observing an equivalent neighborhood node is independent of observing any other equivalent neighborhood given the latent features of the source node.", "startOffset": 71, "endOffset": 82}, {"referenceID": 12, "context": "To solve the optimization problem, we extend the SkipGram architecture [5, 13, 15] which approximates the conditional probability using an independence assumption that the likelihood of observing an equivalent neighborhood node is independent of observing any other equivalent neighborhood given the latent features of the source node.", "startOffset": 71, "endOffset": 82}, {"referenceID": 14, "context": "To solve the optimization problem, we extend the SkipGram architecture [5, 13, 15] which approximates the conditional probability using an independence assumption that the likelihood of observing an equivalent neighborhood node is independent of observing any other equivalent neighborhood given the latent features of the source node.", "startOffset": 71, "endOffset": 82}, {"referenceID": 11, "context": "So, we use negative sampling [12] to approximate it.", "startOffset": 29, "endOffset": 33}, {"referenceID": 10, "context": "Feature learning methods based on Skip-gram architecture are developed for natural language [11].", "startOffset": 92, "endOffset": 96}, {"referenceID": 4, "context": "To mitigate this problem, we use multiple biased random walks each one in principle exploring a different neighborhood [5].", "startOffset": 119, "endOffset": 122}, {"referenceID": 0, "context": "We did not use feature extraction techniques like [1] as they only use the node features without using the graph structure.", "startOffset": 50, "endOffset": 53}, {"referenceID": 12, "context": "Deepwalk [13].", "startOffset": 9, "endOffset": 13}, {"referenceID": 12, "context": "Node2vec [13].", "startOffset": 9, "endOffset": 13}, {"referenceID": 1, "context": "Inspired by spam detection in [2], we define 3 hidden states {Spammer, Mixed, NonSpammer} and the Propagation Matrix is used as in Table 1.", "startOffset": 30, "endOffset": 33}], "year": 2017, "abstractText": null, "creator": "PScript5.dll Version 5.2.2"}}}