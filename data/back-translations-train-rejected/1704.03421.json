{"id": "1704.03421", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Apr-2017", "title": "Efficient Large Scale Clustering based on data partitioning", "abstract": "Clustering techniques are very attractive for extracting and identifying patterns in datasets. However, their application to very large spatial datasets presents numerous challenges such as high-dimensionality data, heterogeneity, and high complexity of some algorithms. For instance, some algorithms may have linear complexity but they require the domain knowledge in order to determine their input parameters. Distributed clustering techniques constitute a very good alternative to the big data challenges (e.g.,Volume, Variety, Veracity, and Velocity). Usually these techniques consist of two phases. The first phase generates local models or patterns and the second one tends to aggregate the local results to obtain global models. While the first phase can be executed in parallel on each site and, therefore, efficient, the aggregation phase is complex, time consuming and may produce incorrect and ambiguous global clusters and therefore incorrect models. In this paper we propose a new distributed clustering approach to deal efficiently with both phases; generation of local results and generation of global models by aggregation. For the first phase, our approach is capable of analysing the datasets located in each site using different clustering techniques. The aggregation phase is designed in such a way that the final clusters are compact and accurate while the overall process is efficient in time and memory allocation. For the evaluation, we use two well-known clustering algorithms; K-Means and DBSCAN. One of the key outputs of this distributed clustering technique is that the number of global clusters is dynamic; no need to be fixed in advance. Experimental results show that the approach is scalable and produces high quality results.", "histories": [["v1", "Tue, 11 Apr 2017 17:05:01 GMT  (1236kb)", "http://arxiv.org/abs/1704.03421v1", null]], "reviews": [], "SUBJECTS": "cs.DB cs.LG", "authors": ["malika bendechache", "nhien-an le-khac", "m-tahar kechadi"], "accepted": false, "id": "1704.03421"}, "pdf": {"name": "1704.03421.pdf", "metadata": {"source": "CRF", "title": "Efficient Large Scale Clustering based on Data Partitioning", "authors": ["Malika Bendechache", "Nhien-An Le-Khac"], "emails": ["malika.bendechache@ucdconnect.ie", "an.lekhac@ucd.ie", "tahar.kechadi@ucd.ie"], "sections": [{"heading": null, "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}], "references": [{"title": "Data Mining: Concepts and Techniques, 2nd ed", "author": ["J. Han", "M. Kamber"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "weight clustering technique for distributed data mining applications", "author": ["L. Aouad", "N.-A. Le-Khac", "M.-T. Kechadi"], "venue": "LNCS on advances in data mining \u2013 theoretical aspects and applications, vol. 4597, pp. 120\u2013134, 2007.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Grid-based approaches for distributed data mining applications", "author": ["L.Aouad", "N.-A. Le-Khac", "M.-T. Kechadi"], "venue": "Journal of Algorithms & Computational Technology, vol. 3, no. 4, pp. 517\u2013534, 2009.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Performance study of distributed apriori-like frequent itemsets mining", "author": ["L. Aouad", "N.-A. Le-Khac", "M.-T. Kechadi"], "venue": "Knowledge and Information Systems, vol. 23, no. 1, pp. 55\u201372, 2010.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Performance evaluation of a density-based clustering method for reducing very large spatio-temporal dataset", "author": ["M. Whelan", "N.-A.L. Khac", "M.-T. Kechadi"], "venue": "in Proc. of International Conference on Information and Knowledge Engineering, July 18-21 2011.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Towards a framework for mining and analysing spatio-temporal datasets", "author": ["M. Bertolotto", "S. Di Martino", "F. Ferrucci", "M.-T. Kechadi"], "venue": "International Journal of Geographical Information Science, vol. 21, no. 8, pp. 895\u2013906, 2007.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "Knowledge map layer for distributed data mining", "author": ["N.-A. Le-Khac", "L. Aouad", "M.-T. Kechadi"], "venue": "Journal of ISAST Transactions on Intelligent Systems, vol. 1, no. 1, 2008.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "A comparative evaluation of voting and metalearning on partitioned data", "author": ["P. Chan", "S. Stolfo"], "venue": "12th International Conference on Machine Learning, 1995, pp. 90\u201398.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1995}, {"title": "Modern heuristic techniques for combinatorial problems", "author": ["C. Reeves"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1993}, {"title": "An experimental comparison of three methods for constructing ensembles of decision trees: Bagging, boosting, and randomization", "author": ["T.G. Dietterich"], "venue": "Machine Learning, vol. 40, no. 2, pp. 139\u2013157, 2000.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2000}, {"title": "Advances in distributed and Parallel Knowledge Discovery", "author": ["H. Kargupta", "P. Chan"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2000}, {"title": "Data mining for association rules and sequential patterns: sequential and parallel algorithms", "author": ["J.-M. Adamo"], "venue": "Springer Science & Business Media,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Performance study of distributed apriori-like frequent itemsets mining", "author": ["N.-A. Le-Khac", "L. Aouad", "M.-T. Kechadi"], "venue": "Knowledge and Information Systems, vol. 23, no. 1, pp. 55\u201372, 2010.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Emergent Web Intelligence: Advanced Semantic Technologies", "author": ["N.A. Le Khac", "L.M. Aouad", "M.-T. Kechadi"], "venue": "ch. Toward Distributed Knowledge Discovery onGrid Systems,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Advances in Database Technology - EDBT 2004: 9th International Conference on Extending Database Technology, Heraklion, Crete, Greece", "author": ["E. Januzaj", "H.-P. Kriegel", "M. Pfeifle"], "venue": "March 14-18,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "Data Management. Data, Data Everywhere: 24th British National Conference on Databases, BNCOD", "author": ["N. Le-Khac", "L.Aouad", "M.-T. Kechadi"], "venue": "Proceedings. Berlin, Heidelberg: Springer Berlin Heidelberg,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "Advances in Data Mining. Theoretical Aspects and Applications: 7th Industrial Conference (ICDM", "author": ["L. Aouad", "N.-A.L. Khac", "M.-T. Kechadi"], "venue": "Proceedings. Berlin, Heidelberg: Springer Berlin Heidelberg,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Efficient distributed approach for density-based clustering", "author": ["J.-F. Laloux", "N.-A. Le-Khac", "M.-T. Kechadi"], "venue": "Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE), 20th IEEE International Workshops, pp. 145\u2013150, 27-29 June 2011.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Data Mining: Concepts and Techniques, 2nd ed", "author": ["M.K. Jiawei Han"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2006}, {"title": "Le data mining spatial et les bases de donn\u00e9es spatiales", "author": ["Y. Karine ZeitouniLaurent"], "venue": "Revue internationale de g\u00e9omatique. Volume, vol. 9, no. 4, 1999.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1999}, {"title": "Large-Scale Parallel Data Mining", "author": ["M.J. Zaki"], "venue": "ch. Parallel and Distributed Data Mining: An Introduction,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2000}, {"title": "Distributed systems: an algorithmic approach", "author": ["S. Ghosh"], "venue": "CRC press,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Image analysis platform for data management in the meteorological domain", "author": ["L. Aouad", "N.-A. Le-Khac", "M.-T. Kechadi."], "venue": "7th Industrial Conference, ICDM 2007, Leipzig, Germany, July 14-18, 2007. Proceedings, vol. 4597. Springer Berlin Heidelberg, 2007, pp. 120\u2013134.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "Data mining with big data", "author": ["X. Wu", "X. Zhu", "G.Q. Wu", "W. Ding"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 26, no. 1, pp. 97\u2013107, 2014.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Ensemble methods for multi-label classification", "author": ["L. Rokach", "A. Schclar", "E. Itach"], "venue": "Expert Systems with Applications, vol. 41, no. 16, pp. 7507 \u2013 7523, 2014.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "An empirical comparison of voting classification algorithms: Bagging, boosting, and variants", "author": ["R.K. Eric Bauer"], "venue": "springer Link:Machine Learning, vol. 36, pp. 105\u2013139, 1999.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1999}, {"title": "Birch: An efficient data clustering method for very large databases", "author": ["M.L. Tian Zhang", "Raghu Ramakrishnan"], "venue": "SIGMOD \u201996 Proceedings of the 1996 ACM SIGMOD international conference on Management of data, vol. 25, 1996, pp. 103\u2013114.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1996}, {"title": "Data clustering: a review", "author": ["P.J.F.A.K. Jain", "M.N. Murty"], "venue": "ACM Computing Surveys (CSUR), vol. 31, pp. 264\u2013323, 1999.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1999}, {"title": "Utilisation des mthodes d\u2019apprentissage ensembliste dans le datamining distribu", "author": ["B.H. Mokeddem Djamila"], "venue": "RIST ISSN 1111-0015, vol. 17, 2007.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}, {"title": "A data-clustering algorithm on distributed memory multiprocessor", "author": ["I. Dhillon", "D. Modha"], "venue": "large-Scale Parallel Data Mining, Workshop on Large-Scale Parallel KDD Systems, SIGKDD. Springer-Verlag London, UK, 1999, pp. 245\u2013260.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1999}, {"title": "A density-based algorithm for discovering clusters in large spatial databases with noise.", "author": ["M. Ester", "H.-P. Kriegel", "J. Sander", "X. Xu"], "venue": "in Kdd,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1996}, {"title": "Pbirch: A scalable parallel clustering algorithm for incremental data", "author": ["Garg", "Mangla", "Bhatnagar", "Gupta"], "venue": "Database Engineering and Applications Symposium. IDEAS \u201906. 10th International, Delhi, pp. 315\u2013316, 2006.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2006}, {"title": "A new clustering algorithm using message passing and its applications in analyzing microarray data", "author": ["H.Geng", "Omaha", "X. Deng"], "venue": "ICMLA \u201905 Proceedings of the Fourth International Conference on Machine Learning and Applications. IEEE, 15-17 December 2005, p. 145150.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "A data-clustering algorithm on distributed memory multiprocessors", "author": ["I.D. Dhillon", "D.S. Modha"], "venue": "Large-Scale Parallel Data Mining. Springer Berlin Heidelberg, 2000, pp. 245\u2013260.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2000}, {"title": "A fast parallel clustering algorithm for large spatial databases", "author": ["X. Xu", "J. Jger", "H.-P. Kriegel"], "venue": "Data Mining and Knowledge Discovery archive, vol. 3, pp. 263\u2013290, September 1999.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1999}, {"title": "A knowledgebased data reduction for very large spatio-temporal datasets", "author": ["N.-A. Le-Khac", "M. Bue", "M. Whelan", "M-T.Kechadi"], "venue": "International Conference on Advanced Data Mining and Applications, (ADMA2010), 19-21 November 2010.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2010}, {"title": "ElMoataza, Pattern Recognition Letters:Non-convex onion-peeling using a shape hull algorithm", "author": ["M. Fadilia", "M. Melkemib"], "venue": "EL- SEVIER,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2004}, {"title": "A novel approach to computation of the shape of a dot pattern and extraction of its perceptual border", "author": ["A. Chaudhuri", "B. Chaudhuri", "S. Parui"], "venue": "Computer vision and Image Understranding, vol. 68, pp. 257\u2013 275, 03 December 1997.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1997}, {"title": "Computing the shape of a planar points set", "author": ["M. Melkemi", "M. Djebali"], "venue": "Elsevier Science, vol. 33, p. 14231436, 9 September 2000.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2000}, {"title": "On the shape of a set of points in the plane", "author": ["H. Edelsbrunner", "D.G. Kirkpatrick", "R. Seidel"], "venue": "Information Theory, IEEE Transactions on, vol. 29, no. 4, pp. 551\u2013559, 1983.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1983}, {"title": "Concave hull: A k-nearest neighbours approach for the computation of the region occupied by a set of points", "author": ["A. Moreira", "M.Y. Santos"], "venue": "International Conference on Computer Graphics Theory and Applications (GRAPP 2007), Barcelona, Spani, 8-11 March 2007, pp. 61\u201368.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2007}, {"title": "Efficient generation of simple polygons for characterizing the shape of a set of points in the plane", "author": ["M. Duckhama", "L. Kulikb", "M. Worboysc", "A. Galtond"], "venue": "Elsevier Science Inc. New York, NY, USA, vol. 41, pp. 3224\u20133236, 15 March 2008.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2008}, {"title": "Distributed clustering algorithm for spatial data mining", "author": ["M. Bendechache", "M.-T. Kechadi"], "venue": "Spatial Data Mining and Geographical Knowledge Services (ICSDM), 2015 2nd IEEE International Conference on, 2015, pp. 60\u201365.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2015}, {"title": "A density-based algorithm for discovering clusters in large spatial databases with noise", "author": ["M.Ester", "H. Kriegel", "J. Sander", "X. Xu"], "venue": "2nd Int. Conf., Knowledge Discovery and Data Mining (KDD 96), 1996.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1996}, {"title": "An efficient k-means clustering algorithm: Analysis and implementation", "author": ["T. Kanungo", "S. Jose", "D.M. Mount", "N.S. Netanyahu", "C.D. Piatko"], "venue": "IEEE Transactions on pattern analysis and machine intelligence, vol. 24, July 2002.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2002}, {"title": "Birch: An efficient data clustering method for very large databases", "author": ["T. Zhang", "R. Ramakrishnan", "M. Livny"], "venue": "SIGMOD-96 Proceedings of the 1996 ACM SIGMOD international conference on Management of data, vol. 25. ACM New York, USA, 1996, pp. 103\u2013114.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 1996}, {"title": "Sting: A statistical information grid approach to spatial data mining", "author": ["W. Wang", "J. Yang", "R.R. Muntz"], "venue": "Proceedings of the 23rd International Conference on Very Large Data Bases, ser. VLDB \u201997. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 1997, pp. 186\u2013195.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 1997}, {"title": "Cure: An efficient clustering algorithm for large databases", "author": ["S. Guha", "R. Rastogi", "K. Shim"], "venue": "Information Systems, vol. 26. Elsevier Science Ltd. Oxford, UK, 17 November 2001, pp. 35\u201358.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "This is even more critical when the collected data is located on different sites, and are owned by different organisations [1].", "startOffset": 123, "endOffset": 126}, {"referenceID": 1, "context": "Briefly, an efficient management of distributed knowledge is one of the key factors affecting the outputs of these techniques [2], [3], [4], [5].", "startOffset": 126, "endOffset": 129}, {"referenceID": 2, "context": "Briefly, an efficient management of distributed knowledge is one of the key factors affecting the outputs of these techniques [2], [3], [4], [5].", "startOffset": 131, "endOffset": 134}, {"referenceID": 3, "context": "Briefly, an efficient management of distributed knowledge is one of the key factors affecting the outputs of these techniques [2], [3], [4], [5].", "startOffset": 136, "endOffset": 139}, {"referenceID": 4, "context": "Briefly, an efficient management of distributed knowledge is one of the key factors affecting the outputs of these techniques [2], [3], [4], [5].", "startOffset": 141, "endOffset": 144}, {"referenceID": 5, "context": "Traditional, centralised data mining techniques have not considered all the issues of datadriven applications, such as scalability in both response time and accuracy of solutions, distribution, and heterogeneity [6].", "startOffset": 212, "endOffset": 215}, {"referenceID": 6, "context": "Some DDM approaches are based on ensemble learning, which uses various techniques to aggregate the results [7], among the most cited in the literature: majority voting, weighted voting, and stacking [8], [9].", "startOffset": 107, "endOffset": 110}, {"referenceID": 7, "context": "Some DDM approaches are based on ensemble learning, which uses various techniques to aggregate the results [7], among the most cited in the literature: majority voting, weighted voting, and stacking [8], [9].", "startOffset": 199, "endOffset": 202}, {"referenceID": 8, "context": "Some DDM approaches are based on ensemble learning, which uses various techniques to aggregate the results [7], among the most cited in the literature: majority voting, weighted voting, and stacking [8], [9].", "startOffset": 204, "endOffset": 207}, {"referenceID": 9, "context": "Many DDM methods such as distributed association rules and distributed classification [10], [11], [12], [3], [13], [14] have been proposed and developed in the last few years.", "startOffset": 86, "endOffset": 90}, {"referenceID": 10, "context": "Many DDM methods such as distributed association rules and distributed classification [10], [11], [12], [3], [13], [14] have been proposed and developed in the last few years.", "startOffset": 92, "endOffset": 96}, {"referenceID": 11, "context": "Many DDM methods such as distributed association rules and distributed classification [10], [11], [12], [3], [13], [14] have been proposed and developed in the last few years.", "startOffset": 98, "endOffset": 102}, {"referenceID": 2, "context": "Many DDM methods such as distributed association rules and distributed classification [10], [11], [12], [3], [13], [14] have been proposed and developed in the last few years.", "startOffset": 104, "endOffset": 107}, {"referenceID": 12, "context": "Many DDM methods such as distributed association rules and distributed classification [10], [11], [12], [3], [13], [14] have been proposed and developed in the last few years.", "startOffset": 109, "endOffset": 113}, {"referenceID": 13, "context": "Many DDM methods such as distributed association rules and distributed classification [10], [11], [12], [3], [13], [14] have been proposed and developed in the last few years.", "startOffset": 115, "endOffset": 119}, {"referenceID": 14, "context": "Recent researches [15], [16], [17] have proposed distributed clustering approaches based on the same 2-step process: perform partial analysis on local data at individual sites and then aggregate them to obtain global results.", "startOffset": 18, "endOffset": 22}, {"referenceID": 15, "context": "Recent researches [15], [16], [17] have proposed distributed clustering approaches based on the same 2-step process: perform partial analysis on local data at individual sites and then aggregate them to obtain global results.", "startOffset": 24, "endOffset": 28}, {"referenceID": 16, "context": "Recent researches [15], [16], [17] have proposed distributed clustering approaches based on the same 2-step process: perform partial analysis on local data at individual sites and then aggregate them to obtain global results.", "startOffset": 30, "endOffset": 34}, {"referenceID": 17, "context": "A case study of an efficient aggregation phase has been developed on spatial datasets and proven to be very efficient; the data exchanged is reduced by more than 98% of the original datasets [18].", "startOffset": 191, "endOffset": 195}, {"referenceID": 18, "context": "Distributed Data Mining (DDM) is a line of research that has attracted much interest in recent years [19].", "startOffset": 101, "endOffset": 105}, {"referenceID": 19, "context": "DDM was developed because of the need to process data that can be very large or geographically distributed across multiple sites [20].", "startOffset": 129, "endOffset": 133}, {"referenceID": 20, "context": "DDM techniques can be divided into two categories based on the targeted architectures of computing platforms [21].", "startOffset": 109, "endOffset": 113}, {"referenceID": 21, "context": "These are called distributed systems, and are characterised by a distributed communication network connecting low-speed machines that can be of different architectures, but they are very abundant [22].", "startOffset": 196, "endOffset": 200}, {"referenceID": 22, "context": "Some of these techniques have already been developed and implemented in [23], [24].", "startOffset": 72, "endOffset": 76}, {"referenceID": 23, "context": "Some of these techniques have already been developed and implemented in [23], [24].", "startOffset": 78, "endOffset": 82}, {"referenceID": 24, "context": "This has led to the development of techniques that rely on ensemble learning [25], [26].", "startOffset": 77, "endOffset": 81}, {"referenceID": 25, "context": "This has led to the development of techniques that rely on ensemble learning [25], [26].", "startOffset": 83, "endOffset": 87}, {"referenceID": 26, "context": "These samples will be analysed using a single global algorithm [27], [28].", "startOffset": 63, "endOffset": 67}, {"referenceID": 27, "context": "These samples will be analysed using a single global algorithm [27], [28].", "startOffset": 69, "endOffset": 73}, {"referenceID": 28, "context": "However, this technique has a disadvantage that the sampling depends on the transfer time which may impact on the quality of the samples [29].", "startOffset": 137, "endOffset": 141}, {"referenceID": 16, "context": "Many parallel clustering versions based on these algorithms have been proposed in the literature [17], [30], [31], [32], [33], [34], [35].", "startOffset": 97, "endOffset": 101}, {"referenceID": 29, "context": "Many parallel clustering versions based on these algorithms have been proposed in the literature [17], [30], [31], [32], [33], [34], [35].", "startOffset": 103, "endOffset": 107}, {"referenceID": 30, "context": "Many parallel clustering versions based on these algorithms have been proposed in the literature [17], [30], [31], [32], [33], [34], [35].", "startOffset": 109, "endOffset": 113}, {"referenceID": 31, "context": "Many parallel clustering versions based on these algorithms have been proposed in the literature [17], [30], [31], [32], [33], [34], [35].", "startOffset": 115, "endOffset": 119}, {"referenceID": 32, "context": "Many parallel clustering versions based on these algorithms have been proposed in the literature [17], [30], [31], [32], [33], [34], [35].", "startOffset": 121, "endOffset": 125}, {"referenceID": 33, "context": "Many parallel clustering versions based on these algorithms have been proposed in the literature [17], [30], [31], [32], [33], [34], [35].", "startOffset": 127, "endOffset": 131}, {"referenceID": 34, "context": "Many parallel clustering versions based on these algorithms have been proposed in the literature [17], [30], [31], [32], [33], [34], [35].", "startOffset": 133, "endOffset": 137}, {"referenceID": 17, "context": "The second subcategory consists of methods that build local clustering models and send them to a central site to build global models [18].", "startOffset": 133, "endOffset": 137}, {"referenceID": 29, "context": "In [30] and [34], message-passing versions of the widely used K-Means algorithm were proposed.", "startOffset": 3, "endOffset": 7}, {"referenceID": 33, "context": "In [30] and [34], message-passing versions of the widely used K-Means algorithm were proposed.", "startOffset": 12, "endOffset": 16}, {"referenceID": 30, "context": "In [31] and [35], the authors dealt with the parallelisation of the DBSCAN densitybased clustering algorithm.", "startOffset": 3, "endOffset": 7}, {"referenceID": 34, "context": "In [31] and [35], the authors dealt with the parallelisation of the DBSCAN densitybased clustering algorithm.", "startOffset": 12, "endOffset": 16}, {"referenceID": 31, "context": "In [32] a parallel message passing version of the BIRCH algorithm was presented.", "startOffset": 3, "endOffset": 7}, {"referenceID": 32, "context": "A parallel version of a hierarchical clustering algorithm, called MPC for Message Passing Clustering, which is especially dedicated to Microarray data was introduced in [33].", "startOffset": 169, "endOffset": 173}, {"referenceID": 16, "context": "Most of the parallel approaches need either multiple synchronisation constraints between processes or a global view of the dataset, or both [17].", "startOffset": 140, "endOffset": 144}, {"referenceID": 16, "context": "Another approach presented in [17] also applied a merging of local models to create the global models.", "startOffset": 30, "endOffset": 34}, {"referenceID": 17, "context": "If the local models cannot effectively represent local datasets then global models accuracy will be very poor [18].", "startOffset": 110, "endOffset": 114}, {"referenceID": 35, "context": "In [36], an efficient reduction technique has been proposed; it is based on density-based clustering algorithms.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "However, selecting representatives is still a challenge in terms of quality and size [15], [18].", "startOffset": 85, "endOffset": 89}, {"referenceID": 17, "context": "However, selecting representatives is still a challenge in terms of quality and size [15], [18].", "startOffset": 91, "endOffset": 95}, {"referenceID": 36, "context": "Many algorithms for extracting the boundaries from a cluster can be found in the literature [37], [38], [39], [40], [41].", "startOffset": 92, "endOffset": 96}, {"referenceID": 37, "context": "Many algorithms for extracting the boundaries from a cluster can be found in the literature [37], [38], [39], [40], [41].", "startOffset": 98, "endOffset": 102}, {"referenceID": 38, "context": "Many algorithms for extracting the boundaries from a cluster can be found in the literature [37], [38], [39], [40], [41].", "startOffset": 104, "endOffset": 108}, {"referenceID": 39, "context": "Many algorithms for extracting the boundaries from a cluster can be found in the literature [37], [38], [39], [40], [41].", "startOffset": 110, "endOffset": 114}, {"referenceID": 40, "context": "Many algorithms for extracting the boundaries from a cluster can be found in the literature [37], [38], [39], [40], [41].", "startOffset": 116, "endOffset": 120}, {"referenceID": 41, "context": "We used the algorithm proposed in [42], which is based on triangulation to generate the cluster boundaries.", "startOffset": 34, "endOffset": 38}, {"referenceID": 42, "context": "It has been shown in [43] that DDC-K-Means dynamically determines the number of the clusters without a priori knowledge about the data or an estimation process of the number of the clusters.", "startOffset": 21, "endOffset": 25}, {"referenceID": 43, "context": "1) DBSCAN: DBSCAN (Density-Based spatial Clustering of Applications with Noise) is a well-known density based clustering algorithm capable of discovering clusters with arbitrary shapes and eliminating noisy data [44].", "startOffset": 212, "endOffset": 216}, {"referenceID": 43, "context": "More details can be found in [44].", "startOffset": 29, "endOffset": 33}, {"referenceID": 44, "context": "Compared with other popular clustering methods such as K-Means [45], BIRCH [46], and STING [47], DBSCAN has several key features.", "startOffset": 63, "endOffset": 67}, {"referenceID": 45, "context": "Compared with other popular clustering methods such as K-Means [45], BIRCH [46], and STING [47], DBSCAN has several key features.", "startOffset": 75, "endOffset": 79}, {"referenceID": 46, "context": "Compared with other popular clustering methods such as K-Means [45], BIRCH [46], and STING [47], DBSCAN has several key features.", "startOffset": 91, "endOffset": 95}, {"referenceID": 45, "context": "BIRCH: We used the BIRCH implementation provided in [46].", "startOffset": 52, "endOffset": 56}, {"referenceID": 45, "context": "We set its parameters to the default values suggested in [46].", "startOffset": 57, "endOffset": 61}, {"referenceID": 47, "context": "CURE: We used the implementation of CURE provided in [48].", "startOffset": 53, "endOffset": 57}, {"referenceID": 47, "context": "As described in [48], when two clusters are merged in each step of the algorithm, representative points for the new merged cluster are selected from the ones of the two original clusters rather than all the points in the merged clusters.", "startOffset": 16, "endOffset": 20}], "year": 2017, "abstractText": "Clustering techniques are very attractive for extracting and identifying patterns in datasets. However, their application to very large spatial datasets presents numerous challenges such as high-dimensionality data, heterogeneity, and high complexity of some algorithms. For instance, some algorithms may have linear complexity but they require the domain knowledge in order to determine their input parameters. Distributed clustering techniques constitute a very good alternative to the big data challenges (e.g.,Volume, Variety, Veracity, and Velocity). Usually these techniques consist of two phases. The first phase generates local models or patterns and the second one tends to aggregate the local results to obtain global models. While the first phase can be executed in parallel on each site and, therefore, efficient, the aggregation phase is complex, time consuming and may produce incorrect and ambiguous global clusters and therefore incorrect models. In this paper we propose a new distributed clustering approach to deal efficiently with both phases; generation of local results and generation of global models by aggregation. For the first phase, our approach is capable of analysing the datasets located in each site using different clustering techniques. The aggregation phase is designed in such a way that the final clusters are compact and accurate while the overall process is efficient in time and memory allocation. For the evaluation, we use two well-known clustering algorithms; K-Means and DBSCAN. One of the key outputs of this distributed clustering technique is that the number of global clusters is dynamic; no need to be fixed in advance. Experimental results show that the approach is scalable and produces high quality results.", "creator": "Word"}}}