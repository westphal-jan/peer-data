{"id": "1704.03693", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Apr-2017", "title": "Trainable Referring Expression Generation using Overspecification Preferences", "abstract": "Referring expression generation (REG) models that use speaker-dependent information require a considerable amount of training data produced by every individual speaker, or may otherwise perform poorly. In this work we present a simple REG experiment that allows the use of larger training data sets by grouping speakers according to their overspecification preferences. Intrinsic evaluation shows that this method generally outperforms the personalised method found in previous work.", "histories": [["v1", "Wed, 12 Apr 2017 10:47:10 GMT  (9kb)", "http://arxiv.org/abs/1704.03693v1", "8 pages"]], "COMMENTS": "8 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["thiago castro ferreira", "ivandre paraboni"], "accepted": false, "id": "1704.03693"}, "pdf": {"name": "1704.03693.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 4.03 693v 1 [cs.C L] 12 Apr 201 7Information requires a considerable amount of training data produced by each speaker or otherwise performing poorly. In this paper, we present a simple REG experiment that allows the use of larger training data sets by grouping speakers according to their over-specific preferences. Intrinsic evaluations show that this method generally exceeds the personalized method found in previous work."}, {"heading": "1 Introduction", "text": "In natural language generation systems, reference generation (REG) is the micro-planning task responsible for generating descriptions of discourse objects. REG includes the well-known content selection task for definitive generation, which is at the heart of the current work. In other words, work in computational REG and related fields has identified a wide range of factors that can drive content selection. However, it is well known that content selection is influenced by human variation [2]. In other words, under identical circumstances (i.e., in the same reference context) different speakers will often produce different descriptions. Differences between speakers can be observed in at least two aspects of reference behavior: (a) in the choice of attributes (the big sphere) against the red sphere. \""}, {"heading": "2 Related Work", "text": "In the following, we will summarize a number of studies following this method - which corresponds to our referent base method, which are evaluated in Section 3.2.In [3], the incremental algorithm [5] and a number of extensions of the fullbrevity algorithm [6] are evaluated on the basis of TUNA data. In the case of the incremental algorithm, human variation is taken into account by calculating individual preference lists based on the attribute frequency of each individual speaker observed in the training data. In the case of fullbrevity, all possible descriptions for a given speaker are calculated, and the description that most closely resembles those generated by the speaker is selected using a closest neighbor. Working in [8] also makes use of the fullbrevity [6] and incremental [5] algorithms for generating TUNA descriptions. In the case of human variability, the complete accountability for individual variation is determined by the individual."}, {"heading": "3 Experimental Setup", "text": "We developed an experiment to compare two training methods for loudspeaker-dependent REG. Both methods are based on the REG model described in Section 3.1. The methods themselves are described in Section 3.2."}, {"heading": "3.1 Basic REG model", "text": "In this case, it is as if one (i), one (i), one (i), one (i), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), one (r), \"(r),\" (r), \"(r),\" (r), \"(r),\" (r), \"(r),\" (r), \"(r),\" (r), \"(r,\" (r), \"(r),\" (r, \"(r),\" (r), \"(r,\" (r), \"(r),\" (r), \"(r,\" (r), \"(r),\" (r), \"(r,\" (r), \"(r),\" (r, \"(r),\" (r), \"(r),\" (r, \"(r,\" (r), \"(r),\" (r), \"(r),\" (r), \"(r,\"), \"(r,\" (r, \"(r,\" (r), \"(r),\" (r), \"(r),\" (r), \"(r,\"), \"(r),\"), \"(r),\" (), \"),\" (, \"(r,\"), \"(,\"), (r, \"),\" (r, \"(,\" (, \"(),\" (), \"(),\"), \"(),\"), \"(),\" (, (), \"), (), (, (, (,\"), \"), (, ((((,\"), \"),\"), ("}, {"heading": "3.2 Training methods", "text": "We will consider two training methods for the basic REG model described in the previous section: a basic method called Speaker and our proposed profile method. In the Speaker method, classifiers are trained on the basis of the reference expressions produced by each individual speaker as in [3]. This method will effectively create personalized REG models and can in principle be considered ideal for modelling human variations in REG. However, to be successful, the method requires a sufficiently large number of descriptions created by each individual speaker, which may not always be available. As an alternative to the standard speaker approach, we propose a training method based on simple observation - of [2] and others - that some speakers follow a consistent pattern in reference production, while others do not. Specifically, speakers in the present method - which is called Profile - are divided into three general categories: those who have always produced overspecified descriptions, those who have always followed a minimal REG pattern, and those who have always failed to follow a distinctive REG pattern, and those who have only been trained in a distinct category."}, {"heading": "3.3 Evaluation", "text": "The speaker and profile training methods were compared using six REG datasets: TUNA-Furniture and TUNA-People - only descriptions of individual objects were taken into account -, GRE3D3, GRE3D7, Stars [13] and Stars2 [14]. All models were cross-validated using a balanced number of reference expressions per participant within each fold. For TUNA and Stars, descriptions were divided into six folds each. For GRE3D3 / 7 and Stars2, descriptions were divided into ten folds each. Optimal values for the SVM C parameter and for the Gaussian kernel \u03b3 parameter were determined by means of grid search. We tested C values of 1, 10, 100 and 1000 and Gamma values of 1, 0.1, 0.1, 0.01 and 0.001 in a validation set before testing the models. As k-folds were used in a cross-validation, F2-old were used."}, {"heading": "4 Results", "text": "Table 1 presents the results of the REG model using the speaker and profile training methods in each of the test areas.Overall results suggest that the profile training method outperforms the speaker interms of Dice (WilcoxonW = 3188296.5, p <.01) and Accuracy (Chi-Square\u03c72 = 104.28, p <.01), the main exception being the star corpus, where the profile model is unable to accurately predict the use of ubiquitous relational properties in this area. More work will be needed to shed light on this particular problem. the results are also confirmed in four separate areas: TUNA-People (W = 17969, p <.01), GRE3D3 (W = 21483, p <.01), GRE3D7 (W = 7599lt; < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <"}, {"heading": "5 Final remarks", "text": "This paper presented an experiment in machine learning REG, which takes speaker-dependent information into account and uses a simple training method based on speaker profiles to circumvent the problem of data poverty. By grouping the speakers according to their over-specific preferences, we were able to outline a speaker-dependent REG model that exceeds the standard use of individual speaker information suggested in previous work. Of course, despite the overall positive results of this first experiment, we can ask what alternative training methods might be considered for the task. As the use of more training data - as we have done by considering groups of similar speakers - leads to improved results, it may be that by simply training our REG models on the data of all speakers, we can further improve the results. Although we are not currently trying to confirm this claim (which would in any case fail the purpose of using speaker-related information in REG), there is much evidence that this would not be the case."}, {"heading": "Acknowledgements", "text": "This work was supported by the National Council for Scientific and Technological Development of Brazil (CNPq) and FAPESP."}], "references": [{"title": "Computational generation of referring expressions: A survey", "author": ["E. Krahmer", "K. van Deemter"], "venue": "Computational Linguistics 38(1)", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Speaker-dependent variation in content selection for referring expression generation", "author": ["J. Viethen", "R. Dale"], "venue": "Australasian Language Technology Association Workshop 2010, Melbourne, Australia", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "The fingerprint of human referring expressions and their surface realization with graph transducers", "author": ["B. Bohnet"], "venue": "Fifth International Natural Language Generation Conference, Stroudsburg, PA, USA", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Generating natural language descriptions using speakerdependent information", "author": ["T.C. Ferreira", "I. Paraboni"], "venue": "Natural Language Engineering", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2017}, {"title": "Computational interpretations of the Gricean maxims in the generation of referring expressions", "author": ["R. Dale", "E. Reiter"], "venue": "Cognitive Science 19(2)", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1995}, {"title": "Cooking up referring expressions", "author": ["R. Dale"], "venue": "Proc. ACL-1989, Stroudsburg, USA", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1989}, {"title": "Evaluating algorithms for the generation of referring expressions using a balanced corpus", "author": ["A. Gatt", "I. van der Sluis", "K. van Deemter"], "venue": "Proceedings of ENLG-07.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Trainable speaker-based referring expression generation", "author": ["G.D. Fabbrizio", "A. Stent", "S. Bangalore"], "venue": "12th Conference on Computational Natural Language Learning, Manchester, UK, Association for Computational Linguistics", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Referring expression generation through attribute-based heuristics", "author": ["R. Dale", "J. Viethen"], "venue": "Proceedings of ENLG-2009.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "GRE3D7: A corpus of distinguishing descriptions for objects in visual scenes", "author": ["J. Viethen", "R. Dale"], "venue": "Proceedings of UCNLG+Eval-2011.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Classification-based referring expression generation", "author": ["T.C. Ferreira", "I. Paraboni"], "venue": "Computational Linguistics and Intelligent Text Processing, Lecture Notes in Computer Science 8403, Kathmandu, Nepal, Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Referring expression generation: taking speakers\u2019 preferences into account", "author": ["T.C. Ferreira", "I. Paraboni"], "venue": "Text, Speech and Dialogue, Lecture Notes in Artificial Intelligence 8655, Brno, Czech Republic, Springer", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Generating relational descriptions involving mutual disambiguation", "author": ["C.V.M. Teixeira", "I. Paraboni", "A.S.R. da Silva", "A.K. Yamasaki"], "venue": "LNCS 8403", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Stars2: a corpus of object descriptions in a visual domain", "author": ["I. Paraboni", "M. Galindo", "D. Iacovelli"], "venue": "Language Resources and Evaluation", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Measures of the amount of ecologic association between species", "author": ["L.R. Dice"], "venue": "Ecology 26(3)", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1945}, {"title": "Speaker-dependent variation in content selection for referring expression generation", "author": ["J. Viethen", "R. Dale"], "venue": "Australasian Language Technology Association Workshop 2010, Melbourne, Australia", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "In natural language generation systems, referring expression generation (REG) is the microplanning task responsible for generating descriptions of discourse objects [1].", "startOffset": 165, "endOffset": 168}, {"referenceID": 1, "context": "To a considerable extent, however, content selection is known to be influenced by human variation [2].", "startOffset": 98, "endOffset": 101}, {"referenceID": 2, "context": "Existing REG algorithms as in [3,4] usually pay regard to human variation by computing personalised features from a training set of descriptions produced by each individual speaker.", "startOffset": 30, "endOffset": 35}, {"referenceID": 3, "context": "Existing REG algorithms as in [3,4] usually pay regard to human variation by computing personalised features from a training set of descriptions produced by each individual speaker.", "startOffset": 30, "endOffset": 35}, {"referenceID": 2, "context": "In [3], the Incremental algorithm [5] and a number of extensions of the Full Brevity algorithm [6] are evaluated on TUNA data [7].", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "In [3], the Incremental algorithm [5] and a number of extensions of the Full Brevity algorithm [6] are evaluated on TUNA data [7].", "startOffset": 34, "endOffset": 37}, {"referenceID": 5, "context": "In [3], the Incremental algorithm [5] and a number of extensions of the Full Brevity algorithm [6] are evaluated on TUNA data [7].", "startOffset": 95, "endOffset": 98}, {"referenceID": 6, "context": "In [3], the Incremental algorithm [5] and a number of extensions of the Full Brevity algorithm [6] are evaluated on TUNA data [7].", "startOffset": 126, "endOffset": 129}, {"referenceID": 7, "context": "The work in [8] also makes use of the Full Brevity [6] and Incremental [5] algorithms to generate TUNA descriptions.", "startOffset": 12, "endOffset": 15}, {"referenceID": 5, "context": "The work in [8] also makes use of the Full Brevity [6] and Incremental [5] algorithms to generate TUNA descriptions.", "startOffset": 51, "endOffset": 54}, {"referenceID": 4, "context": "The work in [8] also makes use of the Full Brevity [6] and Incremental [5] algorithms to generate TUNA descriptions.", "startOffset": 71, "endOffset": 74}, {"referenceID": 2, "context": "In the case of the Incremental algorithm, human variation is implemented as in [3], that is, by computing individual preference lists for each speaker.", "startOffset": 79, "endOffset": 82}, {"referenceID": 1, "context": "The work in [2] makes use of decision-tree induction to predict content patterns (i.", "startOffset": 12, "endOffset": 15}, {"referenceID": 8, "context": ", full attribute sets representing actual referring expressions) from GRE3D3/7 data [9,10].", "startOffset": 84, "endOffset": 90}, {"referenceID": 9, "context": ", full attribute sets representing actual referring expressions) from GRE3D3/7 data [9,10].", "startOffset": 84, "endOffset": 90}, {"referenceID": 10, "context": "Finally, the work in [11,12,4] presents a SVM-based approach to speaker-dependent REG tested on GRE3D3/7 and Stars/Stars2 [13,14] data.", "startOffset": 21, "endOffset": 30}, {"referenceID": 11, "context": "Finally, the work in [11,12,4] presents a SVM-based approach to speaker-dependent REG tested on GRE3D3/7 and Stars/Stars2 [13,14] data.", "startOffset": 21, "endOffset": 30}, {"referenceID": 3, "context": "Finally, the work in [11,12,4] presents a SVM-based approach to speaker-dependent REG tested on GRE3D3/7 and Stars/Stars2 [13,14] data.", "startOffset": 21, "endOffset": 30}, {"referenceID": 12, "context": "Finally, the work in [11,12,4] presents a SVM-based approach to speaker-dependent REG tested on GRE3D3/7 and Stars/Stars2 [13,14] data.", "startOffset": 122, "endOffset": 129}, {"referenceID": 13, "context": "Finally, the work in [11,12,4] presents a SVM-based approach to speaker-dependent REG tested on GRE3D3/7 and Stars/Stars2 [13,14] data.", "startOffset": 122, "endOffset": 129}, {"referenceID": 3, "context": "Our experiment makes use of a speaker-dependent REG model adapted from [4].", "startOffset": 71, "endOffset": 74}, {"referenceID": 1, "context": "These features - hereby called context features - are based on the ones proposed in [2], and are intended to model target and landmark properties (if any), and similarities between objects.", "startOffset": 84, "endOffset": 87}, {"referenceID": 1, "context": "Speaker\u2019s personal features consist of a unique speaker identifier as in [2], gender and age bracket.", "startOffset": 73, "endOffset": 76}, {"referenceID": 3, "context": "As in [4], all classifiers are built using Support Vector Machines (SVMs) with a Gaussian Kernel.", "startOffset": 6, "endOffset": 9}, {"referenceID": 2, "context": "In the Speaker method, classifiers are trained on the set of referring expressions produced by each individual speaker as in [3].", "startOffset": 125, "endOffset": 128}, {"referenceID": 1, "context": "As an alternative to the standard Speaker approach, we propose a training method based on the simple observation - made by [2] and others - that some speakers follow a consistent pattern in reference production, whereas others do not.", "startOffset": 123, "endOffset": 126}, {"referenceID": 12, "context": "The Speaker and Profile training methods were compared against each other using six REG datasets: TUNA-Furniture and TUNA-People - only descriptions to single objects were considered -, GRE3D3, GRE3D7, Stars [13] and Stars2 [14].", "startOffset": 208, "endOffset": 212}, {"referenceID": 13, "context": "The Speaker and Profile training methods were compared against each other using six REG datasets: TUNA-Furniture and TUNA-People - only descriptions to single objects were considered -, GRE3D3, GRE3D7, Stars [13] and Stars2 [14].", "startOffset": 224, "endOffset": 228}, {"referenceID": 14, "context": "We measured Dice coefficients [15] to assess the similarity between each description generated by the model and the corpus description.", "startOffset": 30, "endOffset": 34}, {"referenceID": 2, "context": "Studies such as in [3,16], for instance, have consistently shown that using individual training datasets for each speaker outperforms speaker-independentREG and, in particular, the work in [4] has shown that SVM-based REG models generally produce best results when trained on personalised datasets.", "startOffset": 19, "endOffset": 25}, {"referenceID": 15, "context": "Studies such as in [3,16], for instance, have consistently shown that using individual training datasets for each speaker outperforms speaker-independentREG and, in particular, the work in [4] has shown that SVM-based REG models generally produce best results when trained on personalised datasets.", "startOffset": 19, "endOffset": 25}, {"referenceID": 3, "context": "Studies such as in [3,16], for instance, have consistently shown that using individual training datasets for each speaker outperforms speaker-independentREG and, in particular, the work in [4] has shown that SVM-based REG models generally produce best results when trained on personalised datasets.", "startOffset": 189, "endOffset": 192}], "year": 2017, "abstractText": "Referring expression generation (REG)models that use speaker-dependent information require a considerable amount of training data produced by every individual speaker, or may otherwise perform poorly. In this work we present a simple REG experiment that allows the use of larger training data sets by grouping speakers according to their overspecification preferences. Intrinsic evaluation shows that this method generally outperforms the personalised method found in previous work.", "creator": "LaTeX with hyperref package"}}}