{"id": "1704.03738", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Apr-2017", "title": "Counterexample Guided Inductive Optimization", "abstract": "This paper describes three variants of a counterexample guided inductive optimization (CEGIO) approach based on Satisfiability Modulo Theories (SMT) solvers. In particular, CEGIO relies on iterative executions to constrain a verification procedure, in order to perform inductive generalization, based on counterexamples extracted from SMT solvers. CEGIO is able to successfully optimize a wide range of functions, including non-linear and non-convex optimization problems based on SMT solvers, in which data provided by counterexamples are employed to guide the verification engine, thus reducing the optimization domain. The present algorithms are evaluated using a large set of benchmarks typically employed for evaluating optimization techniques. Experimental results show the efficiency and effectiveness of the proposed algorithms, which find the optimal solution in all evaluated benchmarks, while traditional techniques are usually trapped by local minima.", "histories": [["v1", "Tue, 11 Apr 2017 15:33:50 GMT  (151kb)", "http://arxiv.org/abs/1704.03738v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LO", "authors": ["rodrigo f araujo", "higo f albuquerque", "iury v de bessa", "lucas c cordeiro", "joao edgar c filho"], "accepted": false, "id": "1704.03738"}, "pdf": {"name": "1704.03738.pdf", "metadata": {"source": "CRF", "title": "Counterexample Guided Inductive Optimization", "authors": ["Rodrigo F. Ara\u00fajoa", "Higo F. Albuquerqueb", "Iury V. de Bessab", "Lucas C. Cordeiroc", "Jo\u00e3o Edgar C. Filhob"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 4.03 738v 1 [cs.A I] 1 1A prThis paper describes three variants of a contrast-based inductive optimization approach (CEGIO) based on Satisfiability Modulo Theories (SMT) solvers. Specifically, CEGIO relies on iterative designs to narrow down a verification process to perform an inductive generalization based on counter-examples derived from SMT solvers. CEGIO is able to successfully optimize a wide range of functions, including nonlinear and nonconvex optimization problems based on SMT solvers, using data from counter-examples to guide the verification engine, thereby reducing the optimization range. Current algorithms are evaluated using a large number of benchmarks typically used to evaluate optimization techniques typically used to guide the verification engine, thereby reducing the optimization range."}, {"heading": "1. Introduction", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "1.1. Contributions", "text": "Our main original contributions are: \u2022 Novel counterexample guided inductive optimization approach. This paper describes three novel variants of a counterexample guided induc-tive optimization approach based on SMT solvers: generalized, simplified, and fast algorithms. The generalized algorithm can be used for any limited optimization problem and represents minor improvements over the generalized and simplified ones. [13] The simplified algorithm is faster than the generalized one and can only be applied if information about the minimal position is provided, e.g. the cost function is semi-definite positive. The fast algorithm represents significant acceleration compared to the generalized and simplified ones, but it can only be used for convexact functions. \u2022 Convergence proofs. This paper presents evidence of convergence and completeness (omitted in Ara\u00fajo et al. [13]) for the proposed counterexample guided inductive optimization algorithms SMT solvers comparison."}, {"heading": "1.2. Availability of Data and Tools", "text": "Our experiments are based on publicly available benchmarks. All tools, benchmarks and results of our evaluation are available on a complementary website http: / / esbmc.org / benchmarks / jscp2017.zip."}, {"heading": "1.3. Outline", "text": "Section 2 covers related studies. Section 3 provides an overview of optimization problems and techniques and describes background information for testing software models. Section 4 describes the ANSI-C model developed for optimization problems, which is suitable for the contrasting inductive optimization method. Section 5 describes the generalized and simplified optimization algorithms and the corresponding completeness verifications. Section 6 describes the fast optimization algorithm and the corresponding completeness verification. Section 7 reports on the experimental results for evaluating all proposed optimization algorithms, while Section 8 concludes this work and proposes further studies."}, {"heading": "2. Related Work", "text": "They are typically used to test the satisfaction of a logical formula by returning mappings to variables that evaluate the formula to true when it is satisfactory; otherwise, the formula is called unsatisfactory to solve optimization problems, for example, minimizing errors in linear fixed-point arithmetics in SMSM [22] presents the first study on the application of SMT to solve optimization problems. [23] Reduce the number of gates in FPGA digital circuits [24]; hardware / software partitions in embedded systems to determine the most efficient system implementation [25-27]; and time applications for a multi-processor platform [28]. All of these prior studies use SMT-based optimization over a Boolean domain to find the best configuration of a particular problem."}, {"heading": "3. Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Optimization Problems Overview", "text": "Let f: X \u2192 R be a cost function so that X-Rn represents the decision variables vector x1, x2,..., xn (x1, x2,..., xn) and f (x). Let X-X be a subset governed by a series of constraints. Definition 1. One problem with multivariable optimization is to find an optimal vector x that minimizes f-in-range. According to Definition 1, an optimization problem can be written as min f (x), s.t. x-range of optimization. (1) In particular, this optimization problem can be classified in different ways."}, {"heading": "3.2. Optimization Techniques", "text": "This complexity mainly refers to the robustness (e.g. continuity, differentiability and suppleness) and the dimensionality of the problem (i.e., the dimension, and in the final case the number of elements) Depending on these factors, different optimization techniques can be more efficient in solving a particular optimization problem. Generally, traditional optimization techniques can be divided into two groups: deterministic and stochastic optimization techniques use a search engine in which each step is directly and deterministically related to the previous steps."}, {"heading": "3.3. Model Checking", "text": "Model verification typically consists of three steps: modeling, specification, and verification. Modeling is the first step in which the system is transformed into a formalism that is accepted by an examiner. Modeling usually requires the use of an abstraction to eliminate irrelevant (or less) important system details [47]. The second step is the specification that describes the behavior of the system and the property to be tested. An important issue in the specification is correctness. Checking the model provides ways to verify whether a given specification meets the property of a system, but it is difficult to determine whether such a specification includes all the properties in which the system should be satisfied. Finally, the verification step verifies whether a given property is met or whether a particular model is met, i.e. all relevant system states are checked to check for a condition that may contain the verified property violation.Finally, in the case of an original property violation, the falsification system also reports the faulty condition."}, {"heading": "3.3.1. Bounded Model Checking (BMC)", "text": "BMC is an important verification technology that has produced attractive results in recent years [48]. BMC techniques based on Boolean Satisfiability (SAT) [49] or Satisfiability Modulo Theories (SMT) [50] have been successfully applied to verify single and multi-thread programs, as well as to find subtle errors in real programs [51, 52]. BMC verifies the denial of a given property at a given depth via a transition system M.Definition 3. [49] - In the face of a transition system M, a property \u03c6 and a limit; BMC unrolls the system time and translates it into a verification state (VC) that is satisfactory if a counterexample of depth is smaller or equal. In this study, the ESBMC tool [53] is used as a verification engine, as it is one of the most efficient BMC tools participating in recent software verification competitions."}, {"heading": "4. Verification Model for Counterexample Guided Inductive Optimization", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Modeling Optimization Problems using a Software Model Checker", "text": "There are two important directives in the C / C + + programming language that can be used to model and control a verification process: ASSUME and ASSERT. The ASSUME directive can define constraints on (non-deterministic) variables, and the ASSERT directive is used to verify the correctness of the system against a given property. With these two directives, any standard C / C + + model checker (e.g. CBMC [52], CPAChecker [57], and ESBMC [53]) can be applied to verify specific limitations on optimization problems as described by Equation (1). Here, the verification process is iteratively repeated to solve an optimization problem with intrinsic functions available in ESBMC (e.g. _ ESBMC _ take and _ ESBMC _ assed). We apply step by step to BMC to perform the object search based on the problem that is efficiently generated by the space search."}, {"heading": "4.2. Illustrative Example", "text": "The function of Ursem03 is used to illustrate the current SMT-based optimization method for non-convex optimization problems. [17] The function of Ursem03 is represented by a two-variable function with only a global minimum in f (x1, x2) = \u2212 3 and has four regularly arranged local minimums in a circle with the global minimum in the middle. Ursem03 is defined by Equation (3); Figure 1 shows the respective graph. F (x1, x2) = \u2212 sin (2,2\u03c0x1 \u2212 \u03c02) (2 \u2212 | x1 |) (3 \u2212 | x1 |) (3 \u2212 sin (2,2\u03c0x2 |) (3)"}, {"heading": "4.3. Modeling", "text": "The modeling process defines the constraints, i.e. the limits of Eq (cf. Section 3.1).This step is important in order to reduce the search for states in space and thus to avoid the explosion of the state in space by the underlying method of model verification. Our verification engine is not efficient for unlimited optimization; fortunately, the verification time can be drastically shortened by a suitable choice of constraints.Consider the optimization problem of Equation. (4), which is related to the function of Ursem03 specified in Equation. (3): min f (x1, x2) s.t. x1 \u2265 0x2 \u2265 0. (4) Note that inequalities x1 \u2265 0 and x2 \u2265 0 lead the state space search back to the first quadrant; but even so it creates a (huge) state space to explore, since x1 and x2 variables can be written by very high modules as the problem of Eq \u2212 equality."}, {"heading": "4.4. Specification", "text": "The next step in the proposed methodology is the specification, which describes the system behavior and the property to be tested. For the function of Ursem03, the result of the specification step is the C program shown in Fig. 3, which is iteratively checked by the underlying verifier. Note that the decision variables shown in Fig. 2 are declared as an integral type and their initialization depends on a given precision p, which is iteratively adjusted as soon as the counterexample is produced by the SMT solver. In fact, the C program shown in Fig. 2 leads the verifier to a significant level of state noise detection when the decision variables are declared as a non-deterministic sliding point type. In this study, decision variables are defined as non-deterministic integers, thereby declaring the discretization and reduction of state noise detection; this also reduces the state space exploration process in its precision."}, {"heading": "4.5. Verification", "text": "Finally, in the verification step, the C program shown in Fig. 3 is verified by the verifier and returns a counterexample with a series of decision variables x, where the objective function value converges with the optimal value. A given C program returns a successful verification result only if the previous function value is the optimal point for this specific precision (defined by p), i.e. f (x (i \u2212 1) = f (x \u0445). For the example shown in Fig. 3, the verifier shows a counterexample with the following decision variables: x1 = 2 and x2 = 0. These decision variables are used to calculate a new minimum candidate, note that f (2, 0) = \u2212 1,5 is the new minimum candidate solution provided by this verification step. Of course, it is smaller than the initial value (100), and this verification can be obtained with the new value of the minimum candidate (f \u2212 1.5), which comes close to the optimal value for each function step \u2212 1 in the example."}, {"heading": "5. Counterexample Guided Inductive Optimization of Non-convex Functions", "text": "This section presents two variants of the Counterexample Guided Inductive Optimization (CEGIO) algorithm for global restricted optimization: A generalized CEGIO algorithm is explained in Section 5.1, along with a convergence proof in Section 5.2, while Section 5.3 is a simplified version of this algorithm."}, {"heading": "5.1. CEGIO: the Generalized Algorithm (CEGIO-G)", "text": "The generalized SMT-based optimization method used by Ara\u00fajo et al. [13] is able to find the global optimum for each optimization problem that can be modeled using the methodology outlined in Section 4. [13] The execution time of this algorithm depends on how limited the search for integer optimal points is and how many decimal solutions are quickly found. In particular, this algorithm could take longer to achieve the optimal solution of unlimited optimization problems with non-integer solutions as it depends on the precision required. Although this algorithm often produces a longer execution time than other traditional techniques, its error rate is typically lower than other existing methods once it is based on a complete and solid verification method."}, {"heading": "5.2. Proof of Convergence", "text": "A general optimization problem described in the previous section is formalized as follows: In the face of a specified number of elements that are able to define a minimum of functional elements (i.e., the optimization is the lowest value of the function f, i.e., min f (x), in which each solution is an element of the rational domain, i.e., it is the image set of f (i.e., it is the image set of f (i.e., it is the image set of f). Our approach solves the decimal digit optimization problem, i.e., the solution x) is an element of the rational domain, i.e., the image set of f (i.e., it is the minimum number of elements in which it exists). Therefore, the x component is the minimum of the function f (i.e., it is the minimum number of elements f).Let it be a finite number, composed of all values f (x) &ltfc; fc is a minimum problem, i.e. where (c) is."}, {"heading": "5.2.1. Avoiding the Local Minima", "text": "As already mentioned, an important feature of this proposed CEGIO method is always to find the global minimum (cf. Theorem 1). Many optimization algorithms may be trapped by local minima and solve optimization problems incorrectly. However, the current technique ensures the avoidance of these local minima by satisfaction testing performed by successive SMT queries. This property is maintained for each functional class and for each initial state.Figures 4 and 5 show the above property of this algorithm and compare its performance with the genetic algorithm. In these figures, the function of Ursem03 is adjusted for a single variable problem via x1, i.e. x2 is considered fixed and corresponds to 0.0, and the respective function is reduced to a level that exceeds the global optimum in x1 = \u2212 3. The partial results after each iteration are illustrated by the different markers in these diagrams."}, {"heading": "5.3. A Simplified Algorithm for CEGIO (CEGIO-S)", "text": "Alg. 1 is suitable for each function class, but there are some special functions that contain further knowledge about their behavior (e.g. positive semi-definite functions such as f (x) \u2265 0).With this knowledge, Alg. 1 is slightly modified to handle this particular function class. However, this algorithm is called a \"simplified CEGIO algorithm\" (CEGIO-S) and it is modified slightly in Alg. 2.Note: Alg. 2 contains three nested loops after variable initialization and declaration (lines 1-4), which is similar to the algorithm depicted in [13].In each execution of the outer loop f x, while (lines 5-25) the boundaries and accuracy are updated accordingly.The main difference in this algorithm w.r.t is Alg. 1 is the presence of the condition in line 9, i.e. it is not necessary to generate new checks if this condition does not already meet the minimum limit, i.e. the solution is already fixed."}, {"heading": "6. Counterexample Guided Inductive Optimization of Convex Problems", "text": "This section presents the fast CEGIO algorithm for convex optimization problems. Section 6.1 presents the convex optimization problems, while the fast SMT algorithm is explained in Section 6.2. In addition, Section 6.3 describes a convergence proof for the CEGIO-convex problem."}, {"heading": "6.1. Convex Optimization Problems", "text": "Convex functions represent an important class of functions that are common in many fields of mathematics, physics and engineering [59]. A convex optimization problem is similar to Equation (1), where f (x) is a convex function, the equation (8) equation (\u03b1x1 + \u03b2x2) \u2264 \u03b1 f (x1) + \u03b2 f (x2) (8) for all xi-R n with i = 1, 2 and all \u03b1, \u03b2-R with \u03b1 + \u03b2 = 1, \u03b1 \u2265 0, \u03b2 \u2265 0.Theorem 2 is an important theorem for convex optimization used by most convex optimization algorithms. Theorem 2. A local minimum of a convex function f on a convex subset is always a global minimum of f [60]."}, {"heading": "6.2. Fast CEGIO (CEGIO-F)", "text": "Alg. 1 develops by increasing the precision of the decision variables, i.e. in the first execution of its while loop, the obtained global minimum is integer, since p = 1, called x-thousand times, 0. Alg. 3 is an improved algorithm of this alg. 1 for use in convex functions. It is called a fast CEGIO algorithm here. Note that the only difference of Alg. 1 is the insertion of line 13, which k updates before p. For each execution of the while loop, the solution is optimal for precision p. A new search domain is obtained from a CEGIO process that defines k-thousand, where k-thousand times, k-1-thousand-times, k-thousand-times, k-thousand-times, k-thousand-times, k-thousand-times, k-thousand-times, k-thousand-times, k-thousand-times, etc."}, {"heading": "6.3. Proof of Convergence for the Fast CEGIO Algorithm", "text": "The fast CEGIO algorithm calculates iteratively for each k, 0 \u2265 k \u2264 \u03b7. Theorem 1 ensures global minimization for each finite k. The global convergence of the fast CEGIO algorithm is guaranteed if the minimum of each k-1 solution is within k. It applies to the generalized algorithm since the k-1 solution. However, the fast CEGIO algorithm modifies k limits using the k-1 solution. Lemma 2. Let f: k \u2192 R be a convex function since k is a finite set, theorem 1 ensures that the minimum x-k in k is a local minimum for the accuracy loop, where k = log p p. Moreover, since f is a convex-k + 1 function, each element outside the x-p, x-p, k + p] represents a local minimum for the accuracy loop, where k = the minimum log is f."}, {"heading": "7. Experimental Evaluation", "text": "This section describes the design, execution and analysis of the experiments for the proposed CEGIO algorithms. We use the ESBMC tool as a verification machine to find the optimal solution for a particular functional class. We also compare the current approaches with other existing techniques, including genetic algorithms, particle swarm, pattern search, simulated annealing and nonlinear programming. Preliminary results allowed us to improve the experimental evaluation as follows. (i) There are functions with multiplication operations and large inputs that lead to an overflow in some specific benchmarks. Thus, the data-typical float in some specific functions is replaced by double to avoid overflow. (ii) ESBMC uses different SMT solvers to perform program verifications. Depending on the solver selected, the results, verification time and verification examples for the system may be different. (This is observed in several studies; 61, 54, also used here; different SMT results)."}, {"heading": "7.1. Experimental Objectives", "text": "The experiments aim to answer two research questions: RQ1 (health assessment) What are the results of the proposed CEGIO algorithms in the search for the optimal solution for the functions? RQ2 (performance) What is the performance of the proposed CEGIO algorithms compared to genetic algorithms, particle swarm, pattern search, simulated annealing and nonlinear programming?"}, {"heading": "7.2. Description of Benchmarks", "text": "To answer these research questions, we consider 30 reference functions of global optimization problems extracted from the literature [62]; all reference functions are multivariable with two decision variables. These functions represent different formats, e.g. polynomials, sine, cosine, soil, sum, square root; and can be continuous, differentiable, separable, non-separable, scalable, non-scalable, unimodal, and multimodal. The used benchmark suite is described in Table 1 as follows: benchmark name, domain, and global minimum. In order to conduct the experiments with three different CEGIO algorithms, generalized (Alg. 1), simplified (Alg. 2), and fast (Alg. 3), a series of programs has been developed for each function, taking each individual algorithm into account and varying the data type accordingly."}, {"heading": "7.3. Experimental Results", "text": "In the next subsections, we will evaluate the proposed CEGIO algorithms per performance and compare them with other traditional techniques."}, {"heading": "7.3.1. Generalized Algorithm (CEGIO-G) Evaluation", "text": "The experimental results shown in Table 2 refer to the performance evaluation of the Generalized Algorithm (CEGIO-G) (CF-A), where the CPU time is measured in seconds to find the global minimum with the ESBMC solver. Each column of the table is described as follows: Columns 1 and 5 refer to the functions of the benchmark series; columns 2 and 6 refer to the configuration of the ESBMC with the boolector; columns 3 and 7 refer to columns 4 and 8 refer to the column."}, {"heading": "7.3.2. Simplified Algorithm (CEGIO-S) Evaluation", "text": "The simplified algorithm (CEGIO-S) is applied to functions that contain invariants above the global minimum, e.g. semi-definite positive functions where it is not necessary to search for their minimum in the f negative values. For example, the Leon function shown in Eq. (9) has the global minimum at f (1, 1) = 0 as follows (x1, x2) = 100 (x2 \u2212 x1 2) 2 + (1 \u2212 x1) 2. (9) By escaping, it is possible to claim that there are no negative values for f (x). Thus, to effectively evaluate algorithm 2, 15 benchmarks are selected that have modules or exponential pairs, i.e. the lowest possible value to the global minimum is a non-negative value. The experiments are performed using the float data type and are twice as necessary to avoid overflow by using the solver described in subsection 7.3.1."}, {"heading": "7.3.3. Fast Algorithm (CEGIO-F) Evaluation", "text": "The experimental results for the fast algorithm (CEGIO-F) are presented in Table 4. This algorithm is applied to convex functions where there is only a global minimum; in particular, the state space is reduced with each iteration of the while loop in algorithm 3, ensuring that the global minimum is in the new (delimited) space, and then it performs a new search in that space to reduce the overall optimization time. To evaluate the effectiveness of algorithm 3, we selected about 10 convex functions of the benchmark suite; we also compare the results of the fast algorithm (CEGIO-F) with the generalized (CEGIO-G) algorithm. We observed that there are significant performance improvements when comparing CEGIO-F with CEGIO-G for convex function benchmarks, i.e. the CEGIO-F algorithm is compared with the CEZIO-F algorithm with the 750 times faster solver SMT and SMT-1000 times faster than the original SMT algorithm."}, {"heading": "7.3.4. Comparison to Other Traditional Techniques", "text": "In this section, our CEGIO algorithms are compared with other traditional optimization techniques: genetic algorithm (GA), particle swarm (ParSwarm), pattern search (PatSearch), simulated annealing (SA), and nonlinear programming (NLP).Table 5 describes the hit rates and mean time for each function w.r.t. Our proposal (ESBMC) and other existing techniques (GA, ParSwarm, PatSearch, SA, and NLP) defines an identification for each algorithm: (1) Generic, (2) Simplified, and (3) Fast. All traditional optimization techniques are performed 20 times with MATLAB to maintain the correctness rate and mean time for each function. Our hit rate is omitted for space reasons, but our algorithms have found the correct global minima in 100% of the experiments."}, {"heading": "8. Conclusions", "text": "This paper presented three variants of a contrast-oriented inductive optimization approach for optimizing a wide range of functions based on counter-examples obtained from SMT solvers. Specifically, this paper proposed algorithms for performing inductive generalization based on counter-examples provided by a verification oracle for optimizing convex and non-convex functions, and also presented corresponding evidence of global convergence. In addition, the present study provided an analysis of the influence of solver and data types on the performance of the proposed algorithms. All proposed algorithms were evaluated exhaustively using a large number of publicly available benchmarks. We also evaluated the current performance of algorithms using different SMT solvers and compared them with other modern optimization techniques (genetic algorithm, particle swarm, pattern search, nonlinear programming, and simulated glutation)."}], "references": [{"title": "Optimization for Engineering Design: Algorithms and Examples", "author": ["K. Deb"], "venue": "Prentice-Hall of India", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "Curricular value and instructional needs for infusing engineering design into k-12 technology education", "author": ["D.K. Gattie", "R.C. Wicklein"], "venue": "Journal of Technology Education 19 (1) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Computer science and game theory", "author": ["Y. Shoham"], "venue": "Commun. ACM 51 (8) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Hardware/software codesign: The past", "author": ["J. Teich"], "venue": "the present, and predicting the future, Proceedings of the IEEE 100 (Special Centennial Issue) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Selected Topics in Approximation and Computation", "author": ["M. Kowalski", "C. Sikorski", "F. Stenger"], "venue": "Oxford University Press", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1995}, {"title": "Optimization and Operations Research \u2013 Volume I", "author": ["U. Derigs"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Integer programming", "author": ["R. Garfinkel", "G. Nemhauser"], "venue": "Series in decision and control, Wiley", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1972}, {"title": "The Steepest Descent Method", "author": ["M. Bartholomew-Biggs"], "venue": "Springer US, Boston, MA", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Genetic Algorithms in Search", "author": ["D. Goldberg"], "venue": "Optimization, and Machine Learning, Artificial Intelligence, Addison-Wesley Publishing Company", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1989}, {"title": "Optimization Methods: From Theory to Design Scientific and Technological Aspects in Mechanics", "author": ["M. Cavazzuti"], "venue": "Springer Berlin Heidelberg", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Syntax-guided synthesis", "author": ["R. Alur", "R. Bodik", "G. Juniwal", "M.M.K. Martin", "M. Raghothaman", "S.A. Seshia", "R. Singh", "A. Solar-Lezama", "E. Torlak", "A. Udupa"], "venue": "in: 2013 Formal Methods in Computer-Aided Design", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Ant colony optimization", "author": ["M. Dorigo", "M. Birattari", "T. Stutzle"], "venue": "IEEE Computat. Intell. Mag. 1 (4) ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "SMt-based verification applied to non-convex optimization problems", "author": ["R. Ara\u00fajo", "I. Bessa", "L. Cordeiro", "J.E.C. Filho"], "venue": "in: Proceedings of VI Brazilian Symposium on Computing Systems Engineering", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Z3: An efficient SMT solver", "author": ["L. De Moura", "N. Bj\u00f8rner"], "venue": "in: TACAS, Springer-Verlag, Berlin, Heidelberg", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Boolector: An Efficient SMT Solver for Bit- Vectors and Arrays", "author": ["R. Brummayer", "A. Biere"], "venue": "in: Tools and Algorithms for the Construction and Analysis of Systems (TACAS)", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "The mathSAT5 SMT solver", "author": ["A. Cimatti", "A. Griggio", "B. Schaafsma", "R. Sebastiani"], "venue": "in: Tools and Algorithms for the Construction and Analysis of Systems", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "A literature survey of benchmark functions for global optimisation problems", "author": ["M. Jamil", "X.-S. Yang"], "venue": "IJMMNO 4 (2) ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Particle Swarm Optimization: Theory", "author": ["A. Olsson"], "venue": "Techniques and Applications, Engineering tools, techniques and tables, Nova Science Publishers", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Pattern search methods for user-provided points: Application to molecular geometry problems", "author": ["P. Alberto", "F. Nogueira", "H. Rocha", "L.N. Vicente"], "venue": "SIAM Journal on Optimization 14 (4) ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2004}, {"title": "E", "author": ["P.J.M. Laarhoven"], "venue": "H. L. Aarts (Eds.), Simulated Annealing: Theory and Applications, Kluwer Academic Publishers, Norwell, MA, USA", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1987}, {"title": "A trust region method based on interior point techniques for nonlinear programming", "author": ["R.H. Byrd", "J.C. Gilbert", "J. Nocedal"], "venue": "Mathematical Programming 89 (1) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2000}, {"title": "On SATModulo Theories and Optimization Problems", "author": ["R. Nieuwenhuis", "A. Oliveras"], "venue": "Springer Berlin Heidelberg, Berlin, Heidelberg", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "An SMT based method for optimizing arithmetic computations in embedded software code", "author": ["H. Eldib", "C. Wang"], "venue": "IEEE CAD 33 (11) ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "A note on designing logical circuits using SAT", "author": ["G.G. Estrada"], "venue": "in: ICES, Springer Berlin Heidelberg", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "Applying multi-core model checking to hardware-software partitioning in embedded systems", "author": ["A. Trindade", "H. Ismail", "L. Cordeiro"], "venue": "in: SBESC", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "L", "author": ["A. Trindade"], "venue": "Cordeiro, Aplicando verifica\u00e7\u00e3o de modelos para o particionamento de hardware/softw in: SBESC", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Applying SMT-based verification to hardware/software partitioning in embedded systems", "author": ["A. Trindade", "L. Cordeiro"], "venue": "DES AUTOM EMBED SYST 20 (1) ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2016}, {"title": "Multi-criteria optimization for mapping programs to multi-processors", "author": ["S. Cotton", "O. Maler", "J. Legriel", "S. Saidi"], "venue": "in: SIES", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "Scalable lazy SMT-based motion planning", "author": ["Y. Shoukry", "P. Nuzzo", "I. Saha", "A.L. Sangiovanni-Vincentelli", "S.A. Seshia", "G.J. Pappas", "P. Tabuada"], "venue": "in: 55th IEEE Conference on Decision and Control, CDC 2016, Las Vegas, NV, USA, December 12-14, 2016", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2016}, {"title": "Tool-support for the analysis of hybrid systems and models", "author": ["M. Pister", "M. Tautschnig", "A. Bauer"], "venue": "2007 10th Design, Automation and Test in Europe Conference and Exhibition 00 ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "CalCS: SMT solving for non-linear convex constraints", "author": ["P. Nuzzo", "A.A.A. Puggelli", "S.A. Seshia", "A.L. Sangiovanni-Vincentelli"], "venue": "Tech. Rep. UCB/EECS-2010-100, EECS Department, University of California, Berkeley ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2010}, {"title": "SMC: Satisfiability modulo convex optimization", "author": ["Y. Shoukry", "P. Nuzzo", "A.L. Sangiovanni-Vincentelli", "S.A. Seshia", "G.J. Pappas", "P. Tabuada"], "venue": "in: Proceedings of the 20th ACM International Conference on Hybrid Systems: Computation and Control, HSCC \u201917, ACM, New York, NY, USA", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2017}, {"title": "\u03bdZ - an optimizing SMT solver", "author": ["N. Bj\u00f8rner", "A.-D. Phan", "L. Fleckenstein"], "venue": "in: TACAS, Springer Berlin Heidelberg", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2015}, {"title": "Symbolic optimization with SMT solvers", "author": ["Y. Li", "A. Albarghouthi", "Z. Kincaid", "A. Gurfinkel", "M. Chechik"], "venue": "in: Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL \u201914, ACM, New York, NY, USA", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2014}, {"title": "OptiMathSAT: A tool for optimization modulo theories", "author": ["R. Sebastiani", "P. Trentin"], "venue": "in: CAV, Springer International Publishing", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2015}, {"title": "Optimization modulo theories with linear rational costs", "author": ["R. Sebastiani", "S. Tomasi"], "venue": "ACM TOCL 16 (2) ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2015}, {"title": "Pushing the envelope of optimization modulo theories with linear-arithmetic cost functions", "author": ["R. Sebastiani", "P. Trentin"], "venue": "in: TACAS, Springer Berlin Heidelberg", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2015}, {"title": "Practical SMT-based type error localization", "author": ["Z. Pavlinovic", "T. King", "T. Wies"], "venue": "in: ICFP", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2015}, {"title": "Problem-method classification in optimization and control", "author": ["E.A. Galperin"], "venue": "Computers & Mathematics with Applications 21 (6?7) ", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1221}, {"title": "Deterministic Global Optimization", "author": ["C. Floudas"], "venue": "Nonconvex Optimization and Its Applications, Springer", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2000}, {"title": "Practical Mathematical Optimization: An Introduction to Basic Optimization Theory and Classical and New Gradient-Based Algorithms", "author": ["J. Snyman"], "venue": "Applied Optimization, Springer", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2005}, {"title": "Deterministic Global Optimization: Geometric Branch-andbound Methods and their Applications", "author": ["D. Scholz"], "venue": "Springer Optimization and Its Applications, Springer New York", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2011}, {"title": "Pattern search for optimization", "author": ["N.V. Findler", "C. Lo", "R. Lo"], "venue": "Mathematics and Computers in Simulation 29 (1) ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 1016}, {"title": "Stochastic Optimization Methods", "author": ["K. Marti"], "venue": "Springer", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2005}, {"title": "dReal: An SMT Solver for Nonlinear Theories over the Reals", "author": ["S. Gao", "S. Kong", "E.M. Clarke"], "venue": "Springer Berlin Heidelberg, Berlin, Heidelberg", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2013}, {"title": "Principles of Model Checking (Representation and Mind Series)", "author": ["C. Baier", "J.-P. Katoen"], "venue": "The MIT Press", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2008}, {"title": "Reliable and Reproducible Competition Results with BenchExec and Witnesses (Report on SV-COMP 2016)", "author": ["D. Beyer"], "venue": "Springer Berlin Heidelberg", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2016}, {"title": "Bounded model checking", "author": ["A. Biere"], "venue": "in: Handbook of Satisfiability, IOS Press", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2009}, {"title": "Satisfiability modulo theories", "author": ["C.W. Barrett", "R. Sebastiani", "S.A. Seshia", "C. Tinelli"], "venue": "in: Handbook of Satisfiability, IOS Press", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2009}, {"title": "SMT-based bounded model checking for embedded ANSI-C software", "author": ["L. Cordeiro", "B. Fischer", "J. Marques-Silva"], "venue": "IEEE TSE 38 (4) ", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2012}, {"title": "M", "author": ["D. Kroening"], "venue": "Tautschnig, CBMC \u2013 c bounded model checker ", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2014}, {"title": "B", "author": ["J. Morse", "M. Ramalho", "L. Cordeiro", "D. Nicole"], "venue": "Fischer, ESBMC 1.22 - (competition contribution), in: TACAS", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2014}, {"title": "B", "author": ["B.R. Abreu", "Y.M.R. Gadelha", "C.L. Cordeiro"], "venue": "E. de Lima Filho, S. W. da Silva, Bounded model checking for fixed-point digital filters, JBCS 22 (1) ", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2016}, {"title": "Verification of fixed-point digital controllers using direct and delta forms realizations", "author": ["I.V. Bessa", "H.I. Ismail", "L.C. Cordeiro", "J.E.C. Filho"], "venue": "DES AUTOM EMBED SYST 20 (2) ", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2016}, {"title": "Verification of Delta Form Realization in Fixed-Point Digital Controllers Using Bounded Model Checking", "author": ["I. Bessa", "H. Ibrahim", "L. Cordeiro", "J.E. Filho"], "venue": "in: SBESC", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2014}, {"title": "CPAchecker: A tool for configurable software verification", "author": ["D. Beyer", "M.E. Keremoglu"], "venue": "in: CAV, Springer Berlin Heidelberg", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2011}, {"title": "Handling loops in bounded model checking of C programs via k-induction", "author": ["M.Y.R. Gadelha", "H.I. Ismail", "L.C. Cordeiro"], "venue": "STTT 19 (1) ", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2017}, {"title": "Selected Applications of Convex Optimization", "author": ["L. Li"], "venue": "Springer Optimization and Its Applications, Springer Berlin Heidelberg", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2015}, {"title": "Convex Optimization", "author": ["S. Boyd", "L. Vandenberghe"], "venue": "Cambridge University Press, New York, NY, USA", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2004}, {"title": "Verifying CUDA programs using SMT-based context-bounded model checking", "author": ["P. Pereira", "H. Albuquerque", "H. Marques", "I. Silva", "C. Carvalho", "L. Cordeiro", "V. Santos", "R. Ferreira"], "venue": "in: Proceedings of the 31st Annual ACM Symposium on Applied Computing, SAC \u201916, ACM, New York, NY, USA", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2016}, {"title": "Model checking embedded c software using k-induction and invariants", "author": ["H. Rocha", "H. Ismail", "L. Cordeiro", "R. Barreto"], "venue": "in: Proceedings of VI Brazilian Symposium on Computing Systems Engineering", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Optimization is an important research topic in many fields, especially in computer science and engineering [1].", "startOffset": 107, "endOffset": 110}, {"referenceID": 1, "context": "Optimization characterizes and distinguishes the engineering gaze over a problem; for this particular reason, previous studies showed that optimization is one of the main differences between engineering design and technological design [2].", "startOffset": 235, "endOffset": 238}, {"referenceID": 2, "context": ", game theory [3]), resource allocation problems (e.", "startOffset": 14, "endOffset": 17}, {"referenceID": 3, "context": ", hardware/software co-design [4]), and computational estimation and approximation (e.", "startOffset": 30, "endOffset": 33}, {"referenceID": 4, "context": ", numerical analysis [5]) represent", "startOffset": 21, "endOffset": 24}, {"referenceID": 5, "context": "Conversely, computer science plays an important role in recent optimization studies, developing efficient algorithms and providing respective tools for supporting model management and results analysis [6].", "startOffset": 201, "endOffset": 204}, {"referenceID": 6, "context": ", simplex [7], gradient descent [8], and genetic algorithms [9]), which are suitable for different classes of optimization problems (e.", "startOffset": 10, "endOffset": 13}, {"referenceID": 7, "context": ", simplex [7], gradient descent [8], and genetic algorithms [9]), which are suitable for different classes of optimization problems (e.", "startOffset": 32, "endOffset": 35}, {"referenceID": 8, "context": ", simplex [7], gradient descent [8], and genetic algorithms [9]), which are suitable for different classes of optimization problems (e.", "startOffset": 60, "endOffset": 63}, {"referenceID": 9, "context": ", gradients and Hessians [10].", "startOffset": 25, "endOffset": 29}, {"referenceID": 9, "context": "Stochastic optimization employs randomness in the optima search procedure [10].", "startOffset": 74, "endOffset": 78}, {"referenceID": 10, "context": "This class of techniques is defined here as counterexample guided inductive optimization (CEGIO), which is inspired by the syntax-guided synthesis (SyGuS) to perform inductive generalization based on counterexamples provided by a verification oracle [11].", "startOffset": 250, "endOffset": 254}, {"referenceID": 0, "context": ", NewtonRaphson [1] and Gradient Descent [8]) are inefficient to solve that specific class of problems [1].", "startOffset": 16, "endOffset": 19}, {"referenceID": 7, "context": ", NewtonRaphson [1] and Gradient Descent [8]) are inefficient to solve that specific class of problems [1].", "startOffset": 41, "endOffset": 44}, {"referenceID": 0, "context": ", NewtonRaphson [1] and Gradient Descent [8]) are inefficient to solve that specific class of problems [1].", "startOffset": 103, "endOffset": 106}, {"referenceID": 11, "context": ", ant colony [12] and genetic algorithms [9]) offer faster solutions for complex problems, but they sacrifice the system\u2019s correctness and are easily trapped by local optimal solutions.", "startOffset": 13, "endOffset": 17}, {"referenceID": 8, "context": ", ant colony [12] and genetic algorithms [9]) offer faster solutions for complex problems, but they sacrifice the system\u2019s correctness and are easily trapped by local optimal solutions.", "startOffset": 41, "endOffset": 44}, {"referenceID": 12, "context": "[13] and presents three variants of a counterexample guided inductive optimization approach based on SMT solvers, which improve the technique performance for specific class of functions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13].", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13]) for the proposed counterexample guided inductive optimization algorithms.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "The experiments are performed with three different SMT solvers: Z3 [14], Boolector [15], and MathSAT [16].", "startOffset": 67, "endOffset": 71}, {"referenceID": 14, "context": "The experiments are performed with three different SMT solvers: Z3 [14], Boolector [15], and MathSAT [16].", "startOffset": 83, "endOffset": 87}, {"referenceID": 15, "context": "The experiments are performed with three different SMT solvers: Z3 [14], Boolector [15], and MathSAT [16].", "startOffset": 101, "endOffset": 105}, {"referenceID": 16, "context": "The benchmark suite is expanded to 30 optimization functions extracted from the literature [17].", "startOffset": 91, "endOffset": 95}, {"referenceID": 8, "context": "The proposed technique is compared to genetic algorithm [9], particle swarm [18], pattern search [19], simulated annealing [20], and nonlinear programming [21], which are traditional optimization techniques employed for non-convex functions.", "startOffset": 56, "endOffset": 59}, {"referenceID": 17, "context": "The proposed technique is compared to genetic algorithm [9], particle swarm [18], pattern search [19], simulated annealing [20], and nonlinear programming [21], which are traditional optimization techniques employed for non-convex functions.", "startOffset": 76, "endOffset": 80}, {"referenceID": 18, "context": "The proposed technique is compared to genetic algorithm [9], particle swarm [18], pattern search [19], simulated annealing [20], and nonlinear programming [21], which are traditional optimization techniques employed for non-convex functions.", "startOffset": 97, "endOffset": 101}, {"referenceID": 19, "context": "The proposed technique is compared to genetic algorithm [9], particle swarm [18], pattern search [19], simulated annealing [20], and nonlinear programming [21], which are traditional optimization techniques employed for non-convex functions.", "startOffset": 123, "endOffset": 127}, {"referenceID": 20, "context": "The proposed technique is compared to genetic algorithm [9], particle swarm [18], pattern search [19], simulated annealing [20], and nonlinear programming [21], which are traditional optimization techniques employed for non-convex functions.", "startOffset": 155, "endOffset": 159}, {"referenceID": 21, "context": "Nieuwenhuis and Oliveras [22] presented the first research about the application of SMT to solve optimization problems.", "startOffset": 25, "endOffset": 29}, {"referenceID": 22, "context": ", minimize errors in linear fixed-point arithmetic computations in embedded control software [23]; reduce the number of gates in FPGA digital circuits [24]; hardware/software partition in embedded systems to decide the most efficient system implementation [25\u201327]; and schedule applications for a multi-processor platform [28].", "startOffset": 93, "endOffset": 97}, {"referenceID": 23, "context": ", minimize errors in linear fixed-point arithmetic computations in embedded control software [23]; reduce the number of gates in FPGA digital circuits [24]; hardware/software partition in embedded systems to decide the most efficient system implementation [25\u201327]; and schedule applications for a multi-processor platform [28].", "startOffset": 151, "endOffset": 155}, {"referenceID": 24, "context": ", minimize errors in linear fixed-point arithmetic computations in embedded control software [23]; reduce the number of gates in FPGA digital circuits [24]; hardware/software partition in embedded systems to decide the most efficient system implementation [25\u201327]; and schedule applications for a multi-processor platform [28].", "startOffset": 256, "endOffset": 263}, {"referenceID": 25, "context": ", minimize errors in linear fixed-point arithmetic computations in embedded control software [23]; reduce the number of gates in FPGA digital circuits [24]; hardware/software partition in embedded systems to decide the most efficient system implementation [25\u201327]; and schedule applications for a multi-processor platform [28].", "startOffset": 256, "endOffset": 263}, {"referenceID": 26, "context": ", minimize errors in linear fixed-point arithmetic computations in embedded control software [23]; reduce the number of gates in FPGA digital circuits [24]; hardware/software partition in embedded systems to decide the most efficient system implementation [25\u201327]; and schedule applications for a multi-processor platform [28].", "startOffset": 256, "endOffset": 263}, {"referenceID": 27, "context": ", minimize errors in linear fixed-point arithmetic computations in embedded control software [23]; reduce the number of gates in FPGA digital circuits [24]; hardware/software partition in embedded systems to decide the most efficient system implementation [25\u201327]; and schedule applications for a multi-processor platform [28].", "startOffset": 322, "endOffset": 326}, {"referenceID": 27, "context": "[28] the problem is formulated as a multi-objective optimization problem.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] proposed a scalable solution for synthesizing a digital controller and motion planning for under-actuated robots from LTL specifications.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": ", the ABsolver [30], which is used for automatic analysis and verification of hybrid-system and control-system.", "startOffset": 15, "endOffset": 19}, {"referenceID": 30, "context": "Similarly, CalCs [31] is also an SMT solver that combines convex optimization and lazy SMT to determine the satisfiability of conjunctions of convex non-linear constraints.", "startOffset": 17, "endOffset": 21}, {"referenceID": 31, "context": "[32] show that a particular class of logic formulas (named SMC formulas) generalizes a wide range of formulas over Boolean and nonlinear real arithmetic, and propose the Satisfiability Modulo Convex Optimization to solve satisfiability problems over SMC formulas.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "Our work differs from those previous studies [30\u201332] since it does not focus on speeding up SMT solvers, but it employs an SMT-based model-checking tool to guide (via counterexample) an optimization search procedure in order to ensure the global optimization.", "startOffset": 45, "endOffset": 52}, {"referenceID": 30, "context": "Our work differs from those previous studies [30\u201332] since it does not focus on speeding up SMT solvers, but it employs an SMT-based model-checking tool to guide (via counterexample) an optimization search procedure in order to ensure the global optimization.", "startOffset": 45, "endOffset": 52}, {"referenceID": 31, "context": "Our work differs from those previous studies [30\u201332] since it does not focus on speeding up SMT solvers, but it employs an SMT-based model-checking tool to guide (via counterexample) an optimization search procedure in order to ensure the global optimization.", "startOffset": 45, "endOffset": 52}, {"referenceID": 32, "context": "Recently, \u03bdZ [33] extends the SMT solver Z3 for linear optimization problems; Li et al.", "startOffset": 13, "endOffset": 17}, {"referenceID": 33, "context": "proposed the SYMBA algorithm [34], which is an SMT-based symbolic optimization algorithm that uses the theory of linear real arithmetic and SMT solver as black box.", "startOffset": 29, "endOffset": 33}, {"referenceID": 34, "context": "Sebastiani and Trentin [35] present OptiMathSat, which is an optimization tool that extends MathSAT5 SMT solver to allow solving linear functions in the Boolean, rational, and integer domains or a combination of them; in Sebastiani and Tomasi [36], the authors used a combination of SMT and LP techniques to minimize rational functions; the related work [37] extends their work with linear arithmetic on the mixed integer/rational domain, thus combining SMT, LP, and ILP techniques.", "startOffset": 23, "endOffset": 27}, {"referenceID": 35, "context": "Sebastiani and Trentin [35] present OptiMathSat, which is an optimization tool that extends MathSAT5 SMT solver to allow solving linear functions in the Boolean, rational, and integer domains or a combination of them; in Sebastiani and Tomasi [36], the authors used a combination of SMT and LP techniques to minimize rational functions; the related work [37] extends their work with linear arithmetic on the mixed integer/rational domain, thus combining SMT, LP, and ILP techniques.", "startOffset": 243, "endOffset": 247}, {"referenceID": 36, "context": "Sebastiani and Trentin [35] present OptiMathSat, which is an optimization tool that extends MathSAT5 SMT solver to allow solving linear functions in the Boolean, rational, and integer domains or a combination of them; in Sebastiani and Tomasi [36], the authors used a combination of SMT and LP techniques to minimize rational functions; the related work [37] extends their work with linear arithmetic on the mixed integer/rational domain, thus combining SMT, LP, and ILP techniques.", "startOffset": 354, "endOffset": 358}, {"referenceID": 37, "context": "[38] propose an approach which considers all possible compiler error sources for statically typed functional programming languages and reports the most useful one subject to some usefulness criterion.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "Only a few studies [29] are able to solve non-linear problems, but they are also constrained to convex functions.", "startOffset": 19, "endOffset": 23}, {"referenceID": 38, "context": "Depending on the cost function nature, the optimization problem can be hard to solve, given the time and memory resources [39].", "startOffset": 122, "endOffset": 126}, {"referenceID": 39, "context": "The deterministic techniques employ a search engine, where each step is directly and deterministically related to the previous steps [40].", "startOffset": 133, "endOffset": 137}, {"referenceID": 40, "context": ", gradient-descent [41] and Newton\u2019s optimization [1].", "startOffset": 19, "endOffset": 23}, {"referenceID": 0, "context": ", gradient-descent [41] and Newton\u2019s optimization [1].", "startOffset": 50, "endOffset": 53}, {"referenceID": 41, "context": ", dynamic programming, branch and bound [42], and pattern search [43].", "startOffset": 40, "endOffset": 44}, {"referenceID": 42, "context": ", dynamic programming, branch and bound [42], and pattern search [43].", "startOffset": 65, "endOffset": 69}, {"referenceID": 43, "context": "Stochastic techniques employ randomness to avoid the local minima and to ensure the global optimization; such techniques are usually based on metaheuristics [44].", "startOffset": 157, "endOffset": 161}, {"referenceID": 19, "context": "Among those stochastic techniques, simulated annealing [20], particle swarm [18], and evolutionary algorithms (e.", "startOffset": 55, "endOffset": 59}, {"referenceID": 17, "context": "Among those stochastic techniques, simulated annealing [20], particle swarm [18], and evolutionary algorithms (e.", "startOffset": 76, "endOffset": 80}, {"referenceID": 8, "context": ", genetic algorithms [9]) are usually employed in practice.", "startOffset": 21, "endOffset": 24}, {"referenceID": 30, "context": "Recently, optimization techniques and tools that employ SMT solvers and non-deterministic variables were applied to solve optimization problems [29\u2013 31, 33\u201337, 45], which searches for the global optima in a search-space that is symbolically defined and uses counterexamples produced by SMT solvers to further constrain the search-space.", "startOffset": 144, "endOffset": 163}, {"referenceID": 32, "context": "Recently, optimization techniques and tools that employ SMT solvers and non-deterministic variables were applied to solve optimization problems [29\u2013 31, 33\u201337, 45], which searches for the global optima in a search-space that is symbolically defined and uses counterexamples produced by SMT solvers to further constrain the search-space.", "startOffset": 144, "endOffset": 163}, {"referenceID": 33, "context": "Recently, optimization techniques and tools that employ SMT solvers and non-deterministic variables were applied to solve optimization problems [29\u2013 31, 33\u201337, 45], which searches for the global optima in a search-space that is symbolically defined and uses counterexamples produced by SMT solvers to further constrain the search-space.", "startOffset": 144, "endOffset": 163}, {"referenceID": 34, "context": "Recently, optimization techniques and tools that employ SMT solvers and non-deterministic variables were applied to solve optimization problems [29\u2013 31, 33\u201337, 45], which searches for the global optima in a search-space that is symbolically defined and uses counterexamples produced by SMT solvers to further constrain the search-space.", "startOffset": 144, "endOffset": 163}, {"referenceID": 35, "context": "Recently, optimization techniques and tools that employ SMT solvers and non-deterministic variables were applied to solve optimization problems [29\u2013 31, 33\u201337, 45], which searches for the global optima in a search-space that is symbolically defined and uses counterexamples produced by SMT solvers to further constrain the search-space.", "startOffset": 144, "endOffset": 163}, {"referenceID": 36, "context": "Recently, optimization techniques and tools that employ SMT solvers and non-deterministic variables were applied to solve optimization problems [29\u2013 31, 33\u201337, 45], which searches for the global optima in a search-space that is symbolically defined and uses counterexamples produced by SMT solvers to further constrain the search-space.", "startOffset": 144, "endOffset": 163}, {"referenceID": 44, "context": "Recently, optimization techniques and tools that employ SMT solvers and non-deterministic variables were applied to solve optimization problems [29\u2013 31, 33\u201337, 45], which searches for the global optima in a search-space that is symbolically defined and uses counterexamples produced by SMT solvers to further constrain the search-space.", "startOffset": 144, "endOffset": 163}, {"referenceID": 45, "context": "The modeling step usually requires the use of an abstraction to eliminate irrelevant (or less) important system details [47].", "startOffset": 120, "endOffset": 124}, {"referenceID": 46, "context": "BMC is an important verification technique, which has presented attractive results over the last years [48].", "startOffset": 103, "endOffset": 107}, {"referenceID": 47, "context": "BMC techniques based on Boolean Satisfiability (SAT) [49] or Satisfiability Modulo Theories (SMT) [50] have been successfully applied to verify single- and multi-threaded programs, and also to find subtle bugs in real programs [51, 52].", "startOffset": 53, "endOffset": 57}, {"referenceID": 48, "context": "BMC techniques based on Boolean Satisfiability (SAT) [49] or Satisfiability Modulo Theories (SMT) [50] have been successfully applied to verify single- and multi-threaded programs, and also to find subtle bugs in real programs [51, 52].", "startOffset": 98, "endOffset": 102}, {"referenceID": 49, "context": "BMC techniques based on Boolean Satisfiability (SAT) [49] or Satisfiability Modulo Theories (SMT) [50] have been successfully applied to verify single- and multi-threaded programs, and also to find subtle bugs in real programs [51, 52].", "startOffset": 227, "endOffset": 235}, {"referenceID": 50, "context": "BMC techniques based on Boolean Satisfiability (SAT) [49] or Satisfiability Modulo Theories (SMT) [50] have been successfully applied to verify single- and multi-threaded programs, and also to find subtle bugs in real programs [51, 52].", "startOffset": 227, "endOffset": 235}, {"referenceID": 47, "context": "[49] \u2013 Given a transition system M, a property \u03c6, and a bound k; BMC unrolls the system k times and translates it into a verification condition (VC) \u03c8, which is satisfiable iff \u03c6 has a counterexample of depth less than or equal to k.", "startOffset": 0, "endOffset": 4}, {"referenceID": 51, "context": "In this study, the ESBMC tool [53] is used as verification engine, as it represents one of the most efficient BMC tools that participated in the last software verification competitions [48].", "startOffset": 30, "endOffset": 34}, {"referenceID": 46, "context": "In this study, the ESBMC tool [53] is used as verification engine, as it represents one of the most efficient BMC tools that participated in the last software verification competitions [48].", "startOffset": 185, "endOffset": 189}, {"referenceID": 52, "context": "In addition to software verification, ESBMC has been applied to ensure correctness of digital filters and controllers [54\u201356].", "startOffset": 118, "endOffset": 125}, {"referenceID": 53, "context": "In addition to software verification, ESBMC has been applied to ensure correctness of digital filters and controllers [54\u201356].", "startOffset": 118, "endOffset": 125}, {"referenceID": 54, "context": "In addition to software verification, ESBMC has been applied to ensure correctness of digital filters and controllers [54\u201356].", "startOffset": 118, "endOffset": 125}, {"referenceID": 24, "context": "Recently, ESBMC has been applied to optimize HW/SW co-design [25\u201327].", "startOffset": 61, "endOffset": 68}, {"referenceID": 25, "context": "Recently, ESBMC has been applied to optimize HW/SW co-design [25\u201327].", "startOffset": 61, "endOffset": 68}, {"referenceID": 26, "context": "Recently, ESBMC has been applied to optimize HW/SW co-design [25\u201327].", "startOffset": 61, "endOffset": 68}, {"referenceID": 50, "context": ", CBMC [52], CPAChecker [57], and ESBMC [53]) can be applied to check specific constraints in optimization problems, as described by Eq.", "startOffset": 7, "endOffset": 11}, {"referenceID": 55, "context": ", CBMC [52], CPAChecker [57], and ESBMC [53]) can be applied to check specific constraints in optimization problems, as described by Eq.", "startOffset": 24, "endOffset": 28}, {"referenceID": 51, "context": ", CBMC [52], CPAChecker [57], and ESBMC [53]) can be applied to check specific constraints in optimization problems, as described by Eq.", "startOffset": 40, "endOffset": 44}, {"referenceID": 56, "context": "Definitions 1 and 2) since our optimization problems are represented by loop-free programs [58].", "startOffset": 91, "endOffset": 95}, {"referenceID": 16, "context": "The Ursem03\u2019s function is employed to illustrate the present SMT-based optimization method for non-convex optimization problems [17].", "startOffset": 128, "endOffset": 132}, {"referenceID": 16, "context": "The boundaries are chosen based on Jamil and Yang [17], which define the domain in which the optimization algorithms can evaluate the benchmark functions.", "startOffset": 50, "endOffset": 54}, {"referenceID": 12, "context": "[13] is able to find the global optima for any optimization problem that can be modeled with the methodology presented in Section 4.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13]; this algorithm is denoted here as \u201dGeneralized CEGIO algorithm\u201d (CEGIO-G).", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13].", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "2 contains three nested loops after the variable initialization and declaration (lines 1-4), which is similar to the algorithm presented in [13].", "startOffset": 140, "endOffset": 144}, {"referenceID": 57, "context": "Convex functions are an important class of functions commonly found in many areas of mathematics, physics, and engineering [59].", "startOffset": 123, "endOffset": 127}, {"referenceID": 58, "context": "A local minimum of a convex function f , on a convex subset, is always a global minimum of f [60].", "startOffset": 93, "endOffset": 97}, {"referenceID": 26, "context": "This is observed in several studies [27, 54, 55, 61]; as a result, our evaluation here is also carried out using different SMT solvers such as Boolector [15], Z3 [14], and MathSAT [16], in order to check whether a particular solver heavily influences the performance of the CEGIO algorithms.", "startOffset": 36, "endOffset": 52}, {"referenceID": 52, "context": "This is observed in several studies [27, 54, 55, 61]; as a result, our evaluation here is also carried out using different SMT solvers such as Boolector [15], Z3 [14], and MathSAT [16], in order to check whether a particular solver heavily influences the performance of the CEGIO algorithms.", "startOffset": 36, "endOffset": 52}, {"referenceID": 53, "context": "This is observed in several studies [27, 54, 55, 61]; as a result, our evaluation here is also carried out using different SMT solvers such as Boolector [15], Z3 [14], and MathSAT [16], in order to check whether a particular solver heavily influences the performance of the CEGIO algorithms.", "startOffset": 36, "endOffset": 52}, {"referenceID": 59, "context": "This is observed in several studies [27, 54, 55, 61]; as a result, our evaluation here is also carried out using different SMT solvers such as Boolector [15], Z3 [14], and MathSAT [16], in order to check whether a particular solver heavily influences the performance of the CEGIO algorithms.", "startOffset": 36, "endOffset": 52}, {"referenceID": 14, "context": "This is observed in several studies [27, 54, 55, 61]; as a result, our evaluation here is also carried out using different SMT solvers such as Boolector [15], Z3 [14], and MathSAT [16], in order to check whether a particular solver heavily influences the performance of the CEGIO algorithms.", "startOffset": 153, "endOffset": 157}, {"referenceID": 13, "context": "This is observed in several studies [27, 54, 55, 61]; as a result, our evaluation here is also carried out using different SMT solvers such as Boolector [15], Z3 [14], and MathSAT [16], in order to check whether a particular solver heavily influences the performance of the CEGIO algorithms.", "startOffset": 162, "endOffset": 166}, {"referenceID": 15, "context": "This is observed in several studies [27, 54, 55, 61]; as a result, our evaluation here is also carried out using different SMT solvers such as Boolector [15], Z3 [14], and MathSAT [16], in order to check whether a particular solver heavily influences the performance of the CEGIO algorithms.", "startOffset": 180, "endOffset": 184}, {"referenceID": 12, "context": "[13].", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "Future studies include the application of the present approach to autonomous vehicles navigation systems, enhancements in the model-checking procedure for reducing the verification time by means of multi-core verification [25] and invariant generation [58, 64].", "startOffset": 222, "endOffset": 226}, {"referenceID": 56, "context": "Future studies include the application of the present approach to autonomous vehicles navigation systems, enhancements in the model-checking procedure for reducing the verification time by means of multi-core verification [25] and invariant generation [58, 64].", "startOffset": 252, "endOffset": 260}, {"referenceID": 60, "context": "Future studies include the application of the present approach to autonomous vehicles navigation systems, enhancements in the model-checking procedure for reducing the verification time by means of multi-core verification [25] and invariant generation [58, 64].", "startOffset": 252, "endOffset": 260}], "year": 2017, "abstractText": "This paper describes three variants of a counterexample guided inductive optimization (CEGIO) approach based on Satisfiability Modulo Theories (SMT) solvers. In particular, CEGIO relies on iterative executions to constrain a verification procedure, in order to perform inductive generalization, based on counterexamples extracted from SMT solvers. CEGIO is able to successfully optimize a wide range of functions, including non-linear and non-convex optimization problems based on SMT solvers, in which data provided by counterexamples are employed to guide the verification engine, thus reducing the optimization domain. The present algorithms are evaluated using a large set of benchmarks typically employed for evaluating optimization techniques. Experimental results show the efficiency and effectiveness of the proposed algorithms, which find the optimal solution in all evaluated benchmarks, while traditional techniques are usually trapped by local minima.", "creator": "LaTeX with hyperref package"}}}