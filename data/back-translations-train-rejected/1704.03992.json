{"id": "1704.03992", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Apr-2017", "title": "Fully Distributed and Asynchronized Stochastic Gradient Descent for Networked Systems", "abstract": "This paper considers a general data-fitting problem over a networked system, in which many computing nodes are connected by an undirected graph. This kind of problem can find many real-world applications and has been studied extensively in the literature. However, existing solutions either need a central controller for information sharing or requires slot synchronization among different nodes, which increases the difficulty of practical implementations, especially for a very large and heterogeneous system.", "histories": [["v1", "Thu, 13 Apr 2017 04:58:54 GMT  (265kb,D)", "http://arxiv.org/abs/1704.03992v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.PF", "authors": ["ying zhang"], "accepted": false, "id": "1704.03992"}, "pdf": {"name": "1704.03992.pdf", "metadata": {"source": "CRF", "title": "Fully Distributed and Asynchronized Stochastic Gradient Descent for Networked Systems", "authors": ["Ying Zhang"], "emails": [], "sections": [{"heading": null, "text": "In this paper, we address the problem of data adaptation in this \"big data\" age with examples from the population era. \"It is a\" complex programming problem with many limitations. \"By adapting the results in a recent paper [18], we are designing a completely distributed and asynchronized system of data susceptibility (SGD). We show that our algorithm can achieve global optimism and consensus asymptomatically by taking only local calculations and communications into account. In addition, we offer a significantly lower limit on convergence speed in the regular graph case. This result fits intuition and provides guidance on how to design a\" good \"network to accelerate convergence and accelerate consensus. Also, the merits of our design are validated by experiments on both synthetic and real datasets. I. INTRODUCTION As one of the most important optimization algorithms, many derivative algorithms, and variants of its SchaD have been proposed (many variants have been proposed)."}, {"heading": "II. PROBLEM DESCRIPTION", "text": "We are looking at a scenario in which the N computer nodes are connected as a graph. (...) We have an optimization variable \u03b2 as a vector (...) and the loss of the node i as a vector (...). An example is that the node i as a vector (...) has an objective problem, and that such a model is able to detect many popular examples such as the loss of the UK (...), the averaged losses of the UK (...). (...) We are assuming that the loss of the UK (...) and the averaged losses of the UK (...) is able to detect the distributive capacity of the UK (...). (...) We are going to detect the distributions of the UK (...) and the distributions of the UK (...) and the distributions of the UK (...) in the UK. (...)"}, {"heading": "III. ALGORITHM DESIGN", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Problem Reformulation", "text": "Before presenting our algorithm, we designate Ni as the set of neighbors of the node i and reformulate the original problem. (2) As follows: min \u03b21, \u03b22, \u00b7 \u00b7 \u00b7, \u03b2N1N N \u2211 i = 1 fi (\u03b2i) (3) s.t. \u03b2i = \u03b2k, \u0435k \u0192Ni, \u0418i. (4) In the new formulation, we increase the number of variables by assigning a local optimization variable to each node. We assume that this networked system is interconnected, so that for every feasible solution a global consensus is guaranteed by equation. (4) This reformulation is trivial at first sight, but really helpful for the design and analysis of the algorithm, as we will show in a moment."}, {"heading": "B. A Distributed Algorithm", "text": "The authors examined a general stochastic programming problem in the following form: \"There is only one problem we need to solve.\" \"There is only one problem we need to solve.\" \"There is only one problem we need to solve.\" \"There is an optimal solution for GenPro1.\" \"There is no solution for GenPro Require.\" \"There is no solution for GenPro Require.\" \"There is no solution for GenPro Require.\" \"There is no solution for GenPro Require.\" \"There is no solution for GenPro Require.\" There is a data sample, and there is a calculation for the data sample (Xk, vk) with current variable Xk.3: \"Updating current variable Xk + 1 = Xk \u2212.\" \"There is no solution for GenPro Require.\" \"There is no solution for GenPro Require.\" \"There is no solution for GenPro Require.\" There is no solution for GenPro Require. \""}, {"heading": "C. Theoretical Results", "text": "In this part, we present some theoretical results in connection with the feasibility and optimality of Alg. 2. Unless otherwise mentioned, we assume that the objective function assumption 1 in [18] is fulfilled and the stage sizes are determined accordingly. To provide a clear representation, we use DF (\u03b2k) as the distance from the current optimization variable to the feasible region B1-B2 and DO value (\u03b2k) as the distance from the current optimization variable to the optimal region. Theorem 1: (feasibility and optimality) [18] Both DF (\u03b2k) and DO (\u03b2k) will almost certainly converge to zero. We also provide the asymptotic convergence velocity in the following theorems. 2It should be noted that this region is a polyhedron and can be characterized by linear convergence. 5 Theorem 2: (convergence velocity) We can haveE [DF (\u03b2k] + 1-B1) and B1-B2-B2-DF-B4-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-B2-2-B2-2-2-B2-2-2-2-B2-2-2-2-B2-B2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-2-"}, {"heading": "IV. DISCUSSIONS OF PRACTICAL IMPLEMENTATIONS", "text": "In this part we will try to discuss some details on the implementation of Alg. 2."}, {"heading": "A. Node Selection", "text": "In Alg. 2, a node is randomly selected in each iteration to achieve a decent gradient or local average. A trivial way to do this is to generate a random integer from 1 to N and evoke the corresponding node according to these results. However, this method cannot be realized without a central controller. A distributed alternative would be to generate a random variable for each node according to a geometric distribution and then count it backwards. It is \"selected\" when it counts to 0. We can even carefully design the parameter of geometric distributions for different nodes, so that the probability of selecting different nodes is preferred. The logic behind this mechanism is similar to that of Monto Carlo Markov Chain Sampling [10], CSMA [7], etc."}, {"heading": "B. Communication Overhead", "text": "A common understanding is that communication between nodes is much less efficient than local calculations and is not preferred. To reduce communication effort, we can reduce the likelihood of achieving a local average if a node is selected, but this mechanism will reduce the rate of convergence to the global consensus."}, {"heading": "C. Update Conflict", "text": "Since we select the nodes in a distributed manner, it is possible for two nodes to be selected in the same time window. (Imagine that two nodes create the same value and count down to 0 at the same time.) If the two nodes are far apart, i.e., they6 do not share neighbors, a simultaneous update does not harm and is even preferred, since it is tantamount to performing the update separately. However, if two nodes are connected, such updates lead to conflicts, for example, if a node plans to cause a drop-off, but its neighbor asks it to update according to the average. A reasonable method of solving this problem is that a node, when \"selected,\" sends a message to its neighbors to block it. Such a mechanism can avoid update conflicts, but cause additional communication costs."}, {"heading": "V. SIMULATIONS", "text": "In this part we try to evaluate the performance of Alg. 2 and the effects of various parameters. We describe the simulation setting in paragraph V-A. The results from paragraph V-B to paragraph V-D are based on synthetic data, while the results in paragraph V-E are based on real data."}, {"heading": "A. Simulation Data and Settings", "text": "In our simulation, we perform a multi-class classification task by logistic regression (multinomial logistic regression). The goal of the training process is to minimize the cross entropy between the empirical distribution and the predicted distribution, which is a convex function. From sec. V-B to sec. V-D, we let each node have its own distribution to generate data samples. We have 10 categories and 50 characteristics. In addition, we assume that the distributions are different for different nodes, so that training with only one or more nodes differs from global optimality. In sec. V-E, we test performance using a real dataset: notMNIST, which is about 12G in size. For this dataset, we have 10 categories and 256 features. All simulations are implemented by tensor flow, and the codes are available [2]."}, {"heading": "B. Global Consensus", "text": "Our first interest in Alg. 2 is to show whether it can guarantee a global consensus and how much time it takes to reach a consensus. To this end, we define dk = \u2211 N i = 1 node systems connected by a regular graph: Fig. 2. Distance from the global consensus Fig. 3. Prediction error by a 4-regular graph and the other by a 15-regular graph. The result is in Fig. 2. Note that the y axis is logarithmic, and we can see that dk converges very quickly to zero. Specifically, the value of dk is below 10 after 10k updates. Considering the number of features (50) and nodes (30), this result indicates that the global consensus is almost reached."}, {"heading": "C. Prediction Error", "text": "We are testing two 30-node systems: one with 2-regular diagram and the other with 10-regular diagram. The results are shown in Fig. 3. As we can see, the prediction error decreases in both cases with more iterations (more data feeding).7 The prediction errors will be below 0.4 after 40k iterations (a random guess leads to 0.9 prediction errors) and the prediction error decreases faster with 10-regular diagram. Considering that we add noise to the generated data samples in the training process and the distributions of different nodes are different, we can conclude that our mechanism is very effective."}, {"heading": "D. With Network Size Increasing", "text": "To answer this question, we test the final prediction error, in which the number of nodes increases from 10 to 30, and each node generates an average of 500 data samples. In addition, we set the number of neighbors for each node to 4 or 10, respectively. The result is in Fig. 4.As we can see from Fig. 4, the decreasing trend of prediction error with more nodes is fairly clear (not always due to the stochastic nature of the algorithm). Also, the advantage of a better connected system is clearer for a larger system (the number of nodes is greater). The reasons for this phenomenon can be explained as follows: If the size of the system is small, the distances between the two nodes are relatively small, so that the information of a node is easily distributed among all nodes, although the number of neighbors of each node is small."}, {"heading": "E. Simulation based on a real-world dataset", "text": "We are also testing the performance of Alg. 2 on a real dataset that is not MNIST. This dataset contains the illustrations of letters in the alphabet and digits. A look at the letter \"A\" in the dataset is shown in Fig. 5.We select 10 categories to form a dataset to perform a multinomial logistic regression task. The simulation setting is similar to that of Fig. V-C. And we report the result in Fig. 6.As we can see, the prediction error approaches less than 0.1, which is almost the same result of a centralized version of the SGD. In addition, the performance of two systems with different connectivity converges to the same value. This result indicates that as long as the system is connected, even the convergence speed is asymptotically achieved by the system topology."}, {"heading": "VI. CONCLUSION", "text": "In this paper, we propose a fully distributed and asynchronized stochastic gradient method for a networked system. We expand the variable size and reformulate a stochastic programming problem with many limitations. By adapting some of the results from recent literature, we can achieve global consensus and optimism only through local calculation and communication. A significantly lower limit of convergence speed for the normal graph case is characterized and some simulation results are also provided to validate the value of our design. One possible future work is the implementation of this algorithm on real systems, especially on the heterogeneous system, including powerful computing clusters and low-performance mobile devices."}, {"heading": "A. Definition", "text": "We say that the condition of linear regularity applies to B = B1-B2-B2-BN with a constant scalar number of rooms (0, 1), if we can have a linear regularity for all x in space. \u2022 If the condition of linear regularity applies to \u03b70, then it also applies to the number of rounds (0, \u03b70). \u2022 For the result in theorem 2, a greater progression automatically leads to a faster convergence rate. \u2022 For the constraints, the linear regularity that is projected onto it successively with many rounds is sufficient (a cyclic projection method). \u2022 The condition of linear regularity applies automatically if Bi are linear half-spaces [9]. Thus, it applies to equality (5)."}, {"heading": "B. Proof of Lemma. 1", "text": "Suppose we have a random variable Y, evenly distributed to {\u03b21, \u03b22, \u00b7 \u00b7, \u03b2N}. Also, we have another random variable I distributed to {1, 2, \u00b7 \u00b7, N}. Due to the law of total variance, we can Var (Y) = E [Var (Y | I)] + Var (E [Y | I]]] + Var (E [Y | I]). Note that Var (Y) = 1N (B) \u2212 B (\u03b2) and E [Var (Y | I) = Var (V) = V (V)."}], "references": [{"title": "Distributed dual averaging in networks", "author": ["A. Agarwal", "M.J. Wainwright", "J.C. Duchi"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Large-scale machine learning with stochastic gradient descent", "author": ["L. Bottou"], "venue": "In Proceedings of COMPSTAT\u20192010,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Stochastic gradient descent tricks", "author": ["L. Bottou"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Fastest mixing markov chain on a graph", "author": ["S. Boyd", "P. Diaconis", "L. Xiao"], "venue": "SIAM review,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Markov approximation for combinatorial network optimization", "author": ["M. Chen", "S.C. Liew", "Z. Shao", "C. Kai"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Large scale distributed deep networks", "author": ["J. Dean", "G. Corrado", "R. Monga", "K. Chen", "M. Devin", "M. Mao", "A. Senior", "P. Tucker", "K. Yang", "Q.V. Le"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "The rate of convergence for the cyclic projections algorithm iii: regularity of convex sets", "author": ["F. Deutsch", "H. Hundal"], "venue": "Journal of Approximation Theory,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Markov chain monte carlo", "author": ["W.R. Gilks"], "venue": "Wiley Online Library,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Passcode: Parallel asynchronous stochastic dual co-ordinate descent", "author": ["C.-J. Hsieh", "H.-F. Yu", "I.S. Dhillon"], "venue": "arXiv preprint,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Scaling distributed machine learning with the parameter server", "author": ["M. Li", "D.G. Andersen", "J.W. Park", "A.J. Smola", "A. Ahmed", "V. Josifovski", "J. Long", "E.J. Shekita", "B.-Y. Su"], "venue": "In 11th USENIX Symposium on Operating Systems Design and Implementation", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Asynchronous parallel stochastic gradient for nonconvex optimization", "author": ["X. Lian", "Y. Huang", "Y. Li", "J. Liu"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Distributed subgradient methods for multi-agent optimization", "author": ["A. Nedic", "A. Ozdaglar"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Convergence rate of distributed averaging dynamics and optimization in networks", "author": ["A. Nedich"], "venue": "Foundations and Trends R  \u00a9 in Systems and Control,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Dogwild!\u0142distributed hogwild for cpu & gpu", "author": ["C. Noel", "S. Osindero"], "venue": "In NIPS workshop on Distributed Machine Learning and Matrix Computations,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Hogwild: A lockfree approach to parallelizing stochastic gradient descent", "author": ["B. Recht", "C. Re", "S. Wright", "F. Niu"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Random multi-constraint projection: Stochastic gradient methods for convex optimization with many constraints", "author": ["M. Wang", "Y. Chen", "J. Liu", "Y. Gu"], "venue": "arXiv preprint arXiv:1511.03760,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}], "referenceMentions": [{"referenceID": 15, "context": "By adapting the results in a recent paper [18], we design a fully distributed and asynchronized stochastic gradient descent (SGD) algorithm.", "startOffset": 42, "endOffset": 46}, {"referenceID": 1, "context": "As one of the most important optimization algorithms, stochastic gradient descent (SGD) and many of its variants have been proposed to solve different optimization problems, and are gaining their popularity in this \u2018big-data\u2019 era [4].", "startOffset": 230, "endOffset": 233}, {"referenceID": 2, "context": "Popular examples include SVM, Logistic Regression for the convex cases [5], and deep neural networks for the non-convex cases [8].", "startOffset": 71, "endOffset": 74}, {"referenceID": 5, "context": "Popular examples include SVM, Logistic Regression for the convex cases [5], and deep neural networks for the non-convex cases [8].", "startOffset": 126, "endOffset": 129}, {"referenceID": 5, "context": "To handle this issue, distributed versions of SGD have been tried by many practioneer [8], [16] and analyzed by theoretical researchers [11], [13], [17].", "startOffset": 86, "endOffset": 89}, {"referenceID": 13, "context": "To handle this issue, distributed versions of SGD have been tried by many practioneer [8], [16] and analyzed by theoretical researchers [11], [13], [17].", "startOffset": 91, "endOffset": 95}, {"referenceID": 8, "context": "To handle this issue, distributed versions of SGD have been tried by many practioneer [8], [16] and analyzed by theoretical researchers [11], [13], [17].", "startOffset": 136, "endOffset": 140}, {"referenceID": 10, "context": "To handle this issue, distributed versions of SGD have been tried by many practioneer [8], [16] and analyzed by theoretical researchers [11], [13], [17].", "startOffset": 142, "endOffset": 146}, {"referenceID": 14, "context": "To handle this issue, distributed versions of SGD have been tried by many practioneer [8], [16] and analyzed by theoretical researchers [11], [13], [17].", "startOffset": 148, "endOffset": 152}, {"referenceID": 9, "context": "In practice, the \u2018server\u2019 and the workers can be many computers, connected by a computer network, like the design of the \u2018parameter-server\u2019 [12]; also, the \u2018server\u2019 can be the shared memory of one computer and the workers can be different threads, like the design of \u2019Hogwild!\u2019 [17].", "startOffset": 140, "endOffset": 144}, {"referenceID": 14, "context": "In practice, the \u2018server\u2019 and the workers can be many computers, connected by a computer network, like the design of the \u2018parameter-server\u2019 [12]; also, the \u2018server\u2019 can be the shared memory of one computer and the workers can be different threads, like the design of \u2019Hogwild!\u2019 [17].", "startOffset": 278, "endOffset": 282}, {"referenceID": 10, "context": "In a recent work [13], the authors show that, for the \u2018server-worker\u2019 structure, an asynchronized dual-based algorithm can achieve", "startOffset": 17, "endOffset": 21}, {"referenceID": 15, "context": "\u2022 By apply the result of the recent paper on stochastic optimization problem with many constraints [18], we design an algorithm for the reformulated optimization problem.", "startOffset": 99, "endOffset": 103}, {"referenceID": 15, "context": "The stochastic programming problem with convex objective functions has been extensively studied in the literature, and many off-the-shelf algorithm can be used, see [18] and the reference therein.", "startOffset": 165, "endOffset": 169}, {"referenceID": 0, "context": "The results in [3], [14], [15] also consider to minimize an objective function over a networked system, but the algorithms require all nodes to perform update in each slot and synchronization is needed for realworld implementation, which, however, is difficult to achieve.", "startOffset": 15, "endOffset": 18}, {"referenceID": 11, "context": "The results in [3], [14], [15] also consider to minimize an objective function over a networked system, but the algorithms require all nodes to perform update in each slot and synchronization is needed for realworld implementation, which, however, is difficult to achieve.", "startOffset": 20, "endOffset": 24}, {"referenceID": 12, "context": "The results in [3], [14], [15] also consider to minimize an objective function over a networked system, but the algorithms require all nodes to perform update in each slot and synchronization is needed for realworld implementation, which, however, is difficult to achieve.", "startOffset": 26, "endOffset": 30}, {"referenceID": 15, "context": "In [18], the authors investigated a general stochastic programming problem in the following form,", "startOffset": 3, "endOffset": 7}, {"referenceID": 15, "context": "Unless otherwise mentioned, we will assume that the objective function satisfies Assumption 1 in [18] and stepsizes are set properly.", "startOffset": 97, "endOffset": 101}, {"referenceID": 15, "context": "Theorem 1: (Feasibility and Optimality) [18] Both DF (\u03b2) and DO(\u03b2) will converge to zero almost surely.", "startOffset": 40, "endOffset": 44}, {"referenceID": 15, "context": "Theorem 2: (Convergence Speed) [18] We can have", "startOffset": 31, "endOffset": 35}, {"referenceID": 15, "context": "We omit the proofs of Theorem 1 and 2 since they are established directly from the results in [18] (on Page 9 and Page 10), but we want to provide some results specifically related to our problem.", "startOffset": 94, "endOffset": 98}, {"referenceID": 3, "context": "The readers can refer to [6] for more information.", "startOffset": 25, "endOffset": 28}, {"referenceID": 7, "context": "The rationale behind this mechanism is similar to that of Monto Carlo Markov Chain Sampling [10], CSMA [7], etc.", "startOffset": 92, "endOffset": 96}, {"referenceID": 4, "context": "The rationale behind this mechanism is similar to that of Monto Carlo Markov Chain Sampling [10], CSMA [7], etc.", "startOffset": 103, "endOffset": 106}], "year": 2017, "abstractText": "This paper considers a general data-fitting problem over a networked system, in which many computing nodes are connected by an undirected graph. This kind of problem can find many real-world applications and has been studied extensively in the literature. However, existing solutions either need a central controller for information sharing or requires slot synchronization among different nodes, which increases the difficulty of practical implementations, especially for a very large and heterogeneous system. As a contrast, in this paper, we treat the data-fitting problem over the network as a stochastic programming problem with many constraints. By adapting the results in a recent paper [18], we design a fully distributed and asynchronized stochastic gradient descent (SGD) algorithm. We show that our algorithm can achieve global optimality and consensus asymptotically by only local computations and communications. Additionally, we provide a sharp lower bound for the convergence speed in the regular graph case. This result fits the intuition and provides guidance to design a \u2018good\u2019 network topology to speed up the convergence. Also, the merit of our design is validated by experiments on both synthetic and real-world datasets.", "creator": "LaTeX with hyperref package"}}}