{"id": "1704.04055", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Apr-2017", "title": "Land Cover Classification via Multi-temporal Spatial Data by Recurrent Neural Networks", "abstract": "Nowadays, modern earth observation programs produce huge volumes of satellite images time series (SITS) that can be useful to monitor geographical areas through time. How to efficiently analyze such kind of information is still an open question in the remote sensing field. Recently, deep learning methods proved suitable to deal with remote sensing data mainly for scene classification (i.e. Convolutional Neural Networks - CNNs - on single images) while only very few studies exist involving temporal deep learning approaches (i.e Recurrent Neural Networks - RNNs) to deal with remote sensing time series. In this letter we evaluate the ability of Recurrent Neural Networks, in particular the Long-Short Term Memory (LSTM) model, to perform land cover classification considering multi-temporal spatial data derived from a time series of satellite images. We carried out experiments on two different datasets considering both pixel-based and object-based classification. The obtained results show that Recurrent Neural Networks are competitive compared to state-of-the-art classifiers, and may outperform classical approaches in presence of low represented and/or highly mixed classes. We also show that using the alternative feature representation generated by LSTM can improve the performances of standard classifiers.", "histories": [["v1", "Thu, 13 Apr 2017 09:47:12 GMT  (251kb,D)", "http://arxiv.org/abs/1704.04055v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["dino ienco", "raffaele gaetano", "claire dupaquier", "pierre maurel"], "accepted": false, "id": "1704.04055"}, "pdf": {"name": "1704.04055.pdf", "metadata": {"source": "CRF", "title": "Land Cover Classification via Multi-temporal Spatial Data by Recurrent Neural Networks", "authors": ["Dino Ienco", "Raffaele Gaetano", "Claire Dupaquier", "Pierre Maurel"], "emails": [], "sections": [{"heading": null, "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "II. METHOD", "text": "We propose a neural architecture that incorporates the LSTM unit to handle the classification of land cover using multitemporal spatial data. We also evaluate the representation learned through the RNN model with standard classification strategies commonly used to predict remote sensing."}, {"heading": "A. Long-Short Term Memory", "text": "Recurrent Neural Networks are well-established machine learning techniques that demonstrate their quality in various areas such as speech recognition (9), signal processing (17), natural language processing (14), and image completion (18). Unlike standard starters (i.e. CNNs), RNNs will explicitly manage temporal data dependencies, since the output of the neuron at time t-1 is used along with the next input to feed the neuron itself at time t. A sketch of a typical RNN neuron is shown in Figure 1. The most common type of RNN is the Long-Short Term Memory (LSTM) model. There are many variants of the LSTM network [10], but here we refer to the architecture proposed in [8]. LSTM models were introduced primarily with the purpose of learning long-term dependencies [10], as previous RN models have failed this task."}, {"heading": "B. LSTM-Based Time Series Classification", "text": "The LSTM neuron learns an internal representation of the input sequences (in our case objects or pixel time series), but it does not make its own prediction. To perform the classification task, we stack a SoftMax layer [9] over the LSTM neuron to achieve the final multi-class prediction. The SoftMax layer has as many neurons as the number of classes to predict. We choose SoftMax instead of the Sigmoid function, because the value of the SoftMax layer can be considered a probability distribution over the classes, which add up to 1, while each of the Sigmoid neurons can output a value between 0 and 1. This is due to the fact that for the SoftMax neuron the values per layer are normalized, while in the case of the Sigmoid layer no normalization is performed. From an architectural point of view, in our context (multi-class prediction) the SoftMax layer is preferred, as we know that our samples belong exclusively to one class."}, {"heading": "C. Representation Learning with LSTM for time series data", "text": "Another way to assess the quality of the LSTM unit for our land coverage classification task is to use the features learned from the LSTM layer to feed a standard classifier. Specifically, we propose to use the last hidden state vector produced by the LSTM unit as a new data representation, and to train successive standard classifiers for machine learning of such new features."}, {"heading": "III. DATA", "text": "To prove the universality of our proposal, it was tested using two different remote sensing-based datasets: the first is a collection of spatial objects described by a set of regional statistics extracted from images with very high spatial resolution (VHSR) but limited in time; the second is a pixel-based dataset, noisy but rich in spectral and temporal resolution. Detailed descriptions can be found in the following subsections."}, {"heading": "A. THAU dataset", "text": "The first dataset was created using a time series of Ple \u0301 iades VHSR images (2m) acquired in connection with the distribution of Airbus DS / Spot Image (July and September 2012, March 2013, c \u00a9 CNES). The study site is the THAU basin in southern France, near Montpellier. It covers an area of 42,000 ha with 70% of the land area. The north is mainly composed of agricultural fields (i.e. vineyards) and natural spaces, while the south is dominated by urban and industrial zones. For each date, two orthorectified, atmospherically corrected scenes were mosaiced. Using the multitemporal stack, a segmentation was performed to extract a consistent multitemporal object layer. Segmentation was performed using the multi-resolution segmentation technique [2] available in the eCognition Developer software. Each object was represented using statistical means and standard deviations."}, {"heading": "B. REUNION ISLAND dataset", "text": "The second dataset was generated from an annual time series of 23 Landsat-8 images taken in 2014 above the island of La R\u00e9union (2866 x 2633 pixels at 30 m spatial resolution), provided at level 2A1. Source data was further processed to independently fill the cloudy observations with pixel-by-pixel multitemporal linear interpolation on each multispectral band (OLI) and to calculate complementary radiometric indices (NDVI, NDWI and brightness index - BI). A total of 10 features (7 surface reflections plus 3 indices) are considered for each pixel at each time stamp. The most important land coverage data for the study area were generated using two publicly available datasets, namely the 2012 map of Corine Land Cover (CLC) and the 2014 graphical plot registration of farmers (Re-gistre Parcellaire Graphique - RPG). The most important land coverage data for the study area were compiled using two publicly available datasets, the Corine Land Cover (CLC) map of 2012 and the 2014 graphical plot registration of farmers (Re-gistre Parcellaire Graphique - RPG)."}, {"heading": "IV. EXPERIMENTAL RESULTS", "text": "In this section, we report on the experimental settings and discuss the results we achieved with the two SITS datasets we presented in Section III."}, {"heading": "A. Experimental Settings", "text": "We compare the LSTM-based classification model with standard machine learning approaches commonly used to perform land cover classifications from multi-temporal spatial data [7], [12]. We also evaluate the value of the representation learned by the proposed model. For our purpose, we use Random Forest (RF) and Support Vector Machine (SVM) as standard classification strategies. For the RF model, we set the number of trees generated equal to 400 and we allow a maximum tree depth of 10. For the SVM model, we use RBF kernels with complexity parameters and gamma equal to 100 and 0.01. For the Python implementation supplied by the Scikit learning library, while for SVM we use the LibSVM implementation."}, {"heading": "B. Results and Discussions", "text": "In this context, it should be noted that this project is a project, which is primarily a project, which is primarily a project, which is primarily a project."}, {"heading": "V. CONCLUSION", "text": "We validated the proposed model against two distinct SITS-based datasets, which show that the proposed framework handles both pixel-based and object-based classifications efficiently; the proposed framework has proven to be competitive, but outperforms classical approaches, with the remarkable advantage of improving the quality of predictions of \"weak\" classes of unbalanced datasets; and we highlight that the proposed LSTM-based classification model can be used as a feature extractor to learn a new data representation that positively impacts the performance of standard classification approaches on SITS data."}, {"heading": "ACKNOWLEDGMENT", "text": "The authors also acknowledge the National Research Agency under the Investissements d'Avenir programme for the GEOSUD project (ANR-10-EQPX-20) for the dissemination of Ple'iades satellite images."}], "references": [{"title": "Comparative analysis of modis time-series classification using support vector machines and methods based upon distance and similarity measures in the brazilian cerrado-caatinga boundary", "author": ["N.A. Abade", "O. Ablio de Carvalho Jnior", "R. Fontes Guimares", "S.N. de Oliveira"], "venue": "Remote Sensing,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Multiresolution segmentation: an optimization approach for high quality multi-scale image segmentation", "author": ["M. Baatz", "A. Sch\u00e4pe"], "venue": "Angewandte Geographische Informationsverarbeitung XII,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2000}, {"title": "Representation learning: A review and new perspectives", "author": ["Y. Bengio", "A.C. Courville", "P. Vincent"], "venue": "IEEE TPAMI,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "LIBSVM: A library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM TIST,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Rmsprop and equilibrated adaptive learning rates for non-convex optimization", "author": ["Y.N. Dauphin", "H. de Vries", "J. Chung", "Y. Bengio"], "venue": "CoRR, abs/1502.04390,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Analysis of multitemporal classification techniques for forecasting image time series", "author": ["R. Flamary", "M. Fauvel", "M. Dalla Mura", "S. Valero"], "venue": "IEEE Geosci. Remote Sensing Lett.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Learning to forget: Continual prediction with LSTM", "author": ["F.A. Gers", "J. Schmidhuber", "F.A. Cummins"], "venue": "Neural Comp.,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2000}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "A.-r. Mohamed", "G.E. Hinton"], "venue": "In ICASSP,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "LSTM: A search space odyssey", "author": ["K. Greff", "R. Kumar Srivastava", "J. Koutn\u0131\u0301k", "B.R. Steunebrink", "J. Schmidhuber"], "venue": "CoRR, abs/1503.04069,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "A multi-temporal and multi-spectral method to estimate aerosol optical thickness over land, for the atmospheric correction of formosat-2, landsat, vens and sentinel-2 images", "author": ["O. Hagolle", "M. Huc", "D. Villa Pascual", "G. Dedieu"], "venue": "Remote Sensing,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Classification and monitoring of reed belts using dual-polarimetric terrasar-x time series", "author": ["I. Heine", "T. Jagdhuber", "S. Itzerott"], "venue": "Remote Sensing,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Monitoring land-cover changes: A machine-learning perspective", "author": ["A. Karpatne", "Z. Jiang", "R.R. Vatsavai", "S. Shekhar", "V. Kumar"], "venue": "IEEE Geoscience and Remote Sensing Magazine,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "Assessing the ability of lstms to learn syntax-sensitive", "author": ["T. Linzen", "E. Dupoux", "Y. Goldberg"], "venue": "dependencies. TACL,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Learning a transferable change rule from a recurrent neural network for land cover change detection", "author": ["H. Lyu", "H. Lu", "L. Mou"], "venue": "Remote Sensing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Scikit-learn: Machine learning in Python", "author": ["F. Pedregosa", "G. Varoquaux", "A. Gramfort", "V. Michel", "B. Thirion", "O. Grisel", "M. Blondel", "P. Prettenhofer", "R. Weiss", "V. Dubourg", "J. Vanderplas", "A. Passos", "D. Cournapeau", "M. Brucher", "M. Perrot", "E. Duchesnay"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Simultaneous multichannel signal transfers via chaos in a recurrent neural network", "author": ["K. Soma", "R. Mori", "R. Sato", "N. Furumai", "S. Nara"], "venue": "Neural Computation,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Conditional image generation with pixelcnn decoders", "author": ["A. van den Oord", "N. Kalchbrenner", "L. Espeholt", "K. Kavukcuoglu", "O. Vinyals", "A. Graves"], "venue": "In NIPS,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2016}, {"title": "Deep learning for remote sensing data: A technical tutorial on the state of the art", "author": ["L. Zhang", "B. Du"], "venue": "IEEE Geoscience and Remote Sensing Magazine,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}], "referenceMentions": [{"referenceID": 11, "context": "Efficiently manage and analyze remote sensing time series is still an open challenge in the remote sensing field [13].", "startOffset": 113, "endOffset": 117}, {"referenceID": 0, "context": "In the context of land cover classification, exploiting time series of satellite images, instead that one single image, can be fruitful to distinguish among classes based on the fact they have different temporal profiles [1].", "startOffset": 221, "endOffset": 224}, {"referenceID": 5, "context": "Despite the usefulness of temporal trends that can be derived from remote sensing time series, most of the proposed strategies [7], [12] directly apply standard machine learning approaches (i.", "startOffset": 127, "endOffset": 130}, {"referenceID": 10, "context": "Despite the usefulness of temporal trends that can be derived from remote sensing time series, most of the proposed strategies [7], [12] directly apply standard machine learning approaches (i.", "startOffset": 132, "endOffset": 136}, {"referenceID": 17, "context": "Recently, the deep learning revolution [19] has shown that neural network models are well adapted tools to manage and automatically classify remote sensing data.", "startOffset": 39, "endOffset": 43}, {"referenceID": 2, "context": "While standard CNNs techniques are well suited to deal with spatial autocorrelation, the same approaches are not adapted to correctly manage long and complex temporal dependencies [3].", "startOffset": 180, "endOffset": 183}, {"referenceID": 2, "context": "A family of deep learning methods especially tailored to cope with temporal correlations are Recurrent Neural Networks [3] and, in particular, Long Short Term Memory (LSTM) networks [10].", "startOffset": 119, "endOffset": 122}, {"referenceID": 8, "context": "A family of deep learning methods especially tailored to cope with temporal correlations are Recurrent Neural Networks [3] and, in particular, Long Short Term Memory (LSTM) networks [10].", "startOffset": 182, "endOffset": 186}, {"referenceID": 7, "context": "Such models explicitly capture temporal correlations by recursion and they have already proved to be effective in different domains such as speech recognition [9], natural language processing [14], image completion [18].", "startOffset": 159, "endOffset": 162}, {"referenceID": 12, "context": "Such models explicitly capture temporal correlations by recursion and they have already proved to be effective in different domains such as speech recognition [9], natural language processing [14], image completion [18].", "startOffset": 192, "endOffset": 196}, {"referenceID": 16, "context": "Such models explicitly capture temporal correlations by recursion and they have already proved to be effective in different domains such as speech recognition [9], natural language processing [14], image completion [18].", "startOffset": 215, "endOffset": 219}, {"referenceID": 13, "context": "Only recently, in the remote sensing field, the work proposed in [15] performs preliminary experiments with LSTM model on a (small) time series composed of only two dates to perform supervised change detection.", "startOffset": 65, "endOffset": 69}, {"referenceID": 2, "context": "Like any other deep learning model [3], LSTM can be used as a classifier itself or employed to extract new discriminative features (or representation).", "startOffset": 35, "endOffset": 38}, {"referenceID": 7, "context": "Recurrent Neural Networks are well established machine learning techniques that demonstrate their quality in different domains such as speech recognition [9], signal processing [17], natural language processing [14] and image completion [18].", "startOffset": 154, "endOffset": 157}, {"referenceID": 15, "context": "Recurrent Neural Networks are well established machine learning techniques that demonstrate their quality in different domains such as speech recognition [9], signal processing [17], natural language processing [14] and image completion [18].", "startOffset": 177, "endOffset": 181}, {"referenceID": 12, "context": "Recurrent Neural Networks are well established machine learning techniques that demonstrate their quality in different domains such as speech recognition [9], signal processing [17], natural language processing [14] and image completion [18].", "startOffset": 211, "endOffset": 215}, {"referenceID": 16, "context": "Recurrent Neural Networks are well established machine learning techniques that demonstrate their quality in different domains such as speech recognition [9], signal processing [17], natural language processing [14] and image completion [18].", "startOffset": 237, "endOffset": 241}, {"referenceID": 8, "context": "The most well-known type of RNN is the Long-Short Term Memory (LSTM) [10] model.", "startOffset": 69, "endOffset": 73}, {"referenceID": 8, "context": "There are many variants of LSTM network [10] but here we refer to the architecture proposed in [8].", "startOffset": 40, "endOffset": 44}, {"referenceID": 6, "context": "There are many variants of LSTM network [10] but here we refer to the architecture proposed in [8].", "startOffset": 95, "endOffset": 98}, {"referenceID": 8, "context": "LSTM models were mainly introduced with the purpose to learn long term dependencies [10], since previous RNN models failed in this task due to the problem of vanishing and exploding gradients.", "startOffset": 84, "endOffset": 88}, {"referenceID": 7, "context": "To perform the classification task, we stack on top of the LSTM neuron a SoftMax layer [9] to accomplish the final multi-class prediction.", "startOffset": 87, "endOffset": 90}, {"referenceID": 2, "context": "Standard deep learning approaches can also be seen as a way to produce a new, more discriminative representation of the original data [3].", "startOffset": 134, "endOffset": 137}, {"referenceID": 1, "context": "Segmentation was performed using the Multiresolution Segmentation technique [2] available in the eCognition Developer software.", "startOffset": 76, "endOffset": 79}, {"referenceID": 5, "context": "We compare the LSTM-based Time Series Classification model to standard machine learning approaches commonly employed to perform land cover classification from multi-temporal spatial data [7], [12].", "startOffset": 187, "endOffset": 190}, {"referenceID": 10, "context": "We compare the LSTM-based Time Series Classification model to standard machine learning approaches commonly employed to perform land cover classification from multi-temporal spatial data [7], [12].", "startOffset": 192, "endOffset": 196}, {"referenceID": 14, "context": "For Random Forest we used the python implementation supplied by the Scikit-learn library [16] while for SVM we use the LibSVM implementation [4].", "startOffset": 89, "endOffset": 93}, {"referenceID": 3, "context": "For Random Forest we used the python implementation supplied by the Scikit-learn library [16] while for SVM we use the LibSVM implementation [4].", "startOffset": 141, "endOffset": 144}, {"referenceID": 4, "context": "We used as optimization method the RMSprop strategy that is commonly employed to train LSTM units [6].", "startOffset": 98, "endOffset": 101}, {"referenceID": 9, "context": "fr) and preprocessed by the Multi-sensor Atmospheric Correction and Cloud Screening (MACCS) level 2A processor [11] developed at the French National Space Agency (CNES) to provide accurate atmospheric, environmental and geometric corrections as well as precise cloud masks.", "startOffset": 111, "endOffset": 115}, {"referenceID": 7, "context": "We remind that our proposal uses only one LSTM layer while more layers can be stacked together to build more complex architectures [9].", "startOffset": 131, "endOffset": 134}], "year": 2017, "abstractText": "Nowadays, modern earth observation programs produce huge volumes of satellite images time series (SITS) that can be useful to monitor geographical areas through time. How to efficiently analyze such kind of information is still an open question in the remote sensing field. Recently, deep learning methods proved suitable to deal with remote sensing data mainly for scene classification (i.e. Convolutional Neural Networks CNNs on single images) while only very few studies exist involving temporal deep learning approaches (i.e Recurrent Neural Networks RNNs) to deal with remote sensing time series. In this letter we evaluate the ability of Recurrent Neural Networks, in particular the Long-Short Term Memory (LSTM) model, to perform land cover classification considering multi-temporal spatial data derived from a time series of satellite images. We carried out experiments on two different datasets considering both pixel-based and object-based classification. The obtained results show that Recurrent Neural Networks are competitive compared to state-of-the-art classifiers, and may outperform classical approaches in presence of low represented and/or highly mixed classes. We also show that using the alternative feature representation generated by LSTM can improve the performances of standard classifiers.", "creator": "LaTeX with hyperref package"}}}