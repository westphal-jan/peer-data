{"id": "1704.04095", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Feb-2017", "title": "Training Neural Networks Based on Imperialist Competitive Algorithm for Predicting Earthquake Intensity", "abstract": "In this study we determined neural network weights and biases by Imperialist Competitive Algorithm (ICA) in order to train network for predicting earthquake intensity in Richter. For this reason, we used dependent parameters like earthquake occurrence time, epicenter's latitude and longitude in degree, focal depth in kilometer, and the seismological center distance from epicenter and earthquake focal center in kilometer which has been provided by Berkeley data base. The studied neural network has two hidden layer: its first layer has 16 neurons and the second layer has 24 neurons. By using ICA algorithm, average error for testing data is 0.0007 with a variance equal to 0.318. The earthquake prediction error in Richter by MSE criteria for ICA algorithm is 0.101, but by using GA, the MSE value is 0.115.", "histories": [["v1", "Mon, 13 Feb 2017 22:42:52 GMT  (575kb,D)", "http://arxiv.org/abs/1704.04095v1", "5 pages, 6 figures"]], "COMMENTS": "5 pages, 6 figures", "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["mohsen moradi"], "accepted": false, "id": "1704.04095"}, "pdf": {"name": "1704.04095.pdf", "metadata": {"source": "CRF", "title": "Training Neural Networks Based on Imperialist Competitive Algorithm for Predicting Earthquake Intensity", "authors": ["Mohsen Moradi"], "emails": ["m.moradi8111@aut.ac.ir"], "sections": [{"heading": null, "text": "Index terms - earthquake intensity, multi-layered perception, imperialist competition algorithm, artificial neural networks that can be added. INTRODUCTIONTHE Artificial Neural Network (ANN) consists of several layers and nodes. Each network should have an initial and input layer and some other hidden networks that can be added. Each layer has some nodes known as neurons. Relationships between layers are based on the connection between neurons. A weight is set for each of these connections. In addition, an independent parameter is defined for each neuron under the name bias. Weights and distortions of the next layers are caused by a transition function that can be linear or non-linear and is defined by the user. Neural networks have many uses in image processing, communication theory and finance. Kaastra et al. Neural networks used to predict time series data [1] are used in the study of neural networks, which will be covered by Neurohal (Shaexal) for other networks."}, {"heading": "II. RELATED WORKS", "text": "This year it is more than ever before."}, {"heading": "IV. GENETIC ALGORITHM", "text": "Genetic Algorithm (GA) is an optimization method introduced by John H. Holland in the 1970s. [12] This algorithm is inspired by natural laws of evolution in the following steps: a) All living beings fight each other for survival and those who are stronger have a greater chance of staying alive and adapting; b) Those with high adaptability survive and produce the next generation. This next generation will be more advanced than the previous generation. c) Children are similar to their parents, but they are not identical with them. As they inherit not only their parentage, but also due to genetic mutations, they may become better than their parents.d) The genetic algorithm does the same thing in a way that is necessary for the implementation of the algorithm, we should define the population size as they reproduce and the rate of adaptation."}, {"heading": "V. USED NEURAL NETWORK", "text": "rf\u00fc ide rf\u00fc ide eeisrsrteeVnlrteeeeerln rf\u00fc eid rf\u00fc ide eeisrteeeeerln rf\u00fc rrrrrrrrrrrrrrrgne\u00fceeeetnlrrrrrrrrteeeeeeeeeeeeoiuiuiuiuiueaeaeetnlrrrrrrrrrsrsrrsrrllrsrsrsrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrllrrrrrrrrrrrrreeeoioioioioiuiuiuiuiuiuiueeeteeteeteerrrrrrrrrrrrrrrrrrrrrrrsrrsrsrrrsrsrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrreeeeeeeeoioioioioioioioioioioioioiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiueeeeeeeeeeteeteeeeteeteerrrrrrrrrrrrrsrrrsrrrrrsrsrrsrsrsrrsrsrrrrsrrrrsrrrsrrsrsrsrrrsrsrsrsrsrsrsrsrsrsrsrln"}, {"heading": "VI. CONCLUSION", "text": "To define the problem of earthquake intensity, we determined 6 input parameters as an input matrix and then set the parameter of earthquake intensity as the target variable. MSE measurement and regression analysis were used to assess the neural network. Defining artificial neural networks in this way does not have the ability to choose parameters such as the number of hidden layers. Therefore, after designing the primary neural network with two hidden layers, the number of neurons in each layer and the type of training functions was changed to determine the effects of these parameters by using the ICA algorithms we assign weights and distortion values to the network, and it was compared to a neural network trained by GA. As we have obtained, ICA was better than GA for this training network."}, {"heading": "VII. ACKNOWLEDGMENT", "text": "We are immensely grateful to the Iran Seismological Center for creating a situation in which research on the application of neural networks in seismology could be carried out."}], "references": [{"title": "Designing a neural network for forecasting financial and economic time series", "author": ["I. Kaastra", "M. Boyd"], "venue": "Neurocomputing, vol.10, no.3, pp.215-236, 1996.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1996}, {"title": "Neural network based steganalysis in still images", "author": ["L. Shaohui", "Y. Hongxun", "G. Wen"], "venue": "Multimedia and Expo, 2003. ICME\u201903. Proceedings. 2003 International Conference on, vol.2, pp.II-509, IEEE, 2003.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "Combining and steganography of 3d face textures", "author": ["M. Moradi"], "venue": "arXiv preprint arXiv:1702.01325, 2017.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2017}, {"title": "A review of application of data mining in earthquake prediction", "author": ["G. Otari", "R. Kulkarni"], "venue": "International Journal of Computer Science and Information Technologies, vol.3, no.2, pp.3570-3574, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Layered neural networks based analysis of radon concentration and environmental parameters in earthquake prediction", "author": ["A. Negarestani", "S. Setayeshi", "M. Ghannadi-Maragheh", "B. Akashe"], "venue": "Journal of environmental radioactivity, vol.62, no.3, pp.225-233, 2002.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Neural network model for liquefaction potential in soil deposits using turkey and taiwan earthquake data", "author": ["A.M. Hanna", "D. Ural", "G. Saygili"], "venue": "Soil Dynamics and Earthquake Engineering, vol.27, no.6, pp.521- 540, 2007.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "Neural networkbased model for assessing failure potential of highway slopes in the alishan, taiwan area: Pre-and post-earthquake investigation", "author": ["H.-M. Lin", "S.-K. Chang", "J.-H. Wu", "C.H. Juang"], "venue": "Engineering Geology, vol.104, no.3, pp.280-289, 2009.  5 Fig. 5. test data evaluation of trained neural network by ICA algorithm Fig. 6. test data evaluation of trained neural network by genetic algorithm", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Assessing structural vulnerability against earthquakes using multi-dimensional fragility surfaces: a bayesian framework", "author": ["P. Koutsourelakis"], "venue": "Probabilistic Engineering Mechanics, vol.25, no.1, pp.49-60, 2010.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Prediction of seismic slope stability through combination of particle swarm optimization and neural network", "author": ["B. Gordan", "D.J. Armaghani", "M. Hajihassani", "M. Monjezi"], "venue": "Engineering with Computers, vol.32, no.1, pp.85-97, 2016.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Application of a radial basis function artificial neural network to seismic data inversion", "author": ["K. Baddari", "T. Aifa", "N. Djarfour", "J. Ferahtia"], "venue": "Computers and Geosciences, vol.35, no.12, pp.2338-2344, 2009.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Imperialist competitive algorithm:  an algorithm for optimization inspired by imperialistic competition", "author": ["E. Atashpaz-Gargari", "C. Lucas"], "venue": "Evolutionary computation, 2007. CEC 2007. IEEE Congress on, pp.4661- 4667, IEEE, 2007.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence.", "author": ["J.H. Holland"], "venue": "MIT press,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1992}], "referenceMentions": [{"referenceID": 0, "context": "used neural networks for forecasting time series data [1].", "startOffset": 54, "endOffset": 57}, {"referenceID": 1, "context": ", (2003), neural networks are used in steganography for detecting hidden images which this is done by finding statistical features [2].", "startOffset": 131, "endOffset": 134}, {"referenceID": 2, "context": "concealing substantial features of face images like texture in other pictures [3].", "startOffset": 78, "endOffset": 81}, {"referenceID": 3, "context": "In [4], for detecting and forecasting natural disasters like earthquake, some data mining techniques have been used.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "Negarestani used neural networks for measuring Radon density in soil by local parameters [5].", "startOffset": 89, "endOffset": 92}, {"referenceID": 5, "context": "In another work Hanna used a General Regression Neural Network (GRNN) for estimating soil slide potential [6].", "startOffset": 106, "endOffset": 109}, {"referenceID": 6, "context": "by using a neural network approach and 955 data set related to Alishan\u2019s neighbourhood highways in Taiwan, created a model for research on earthquake [7].", "startOffset": 150, "endOffset": 153}, {"referenceID": 7, "context": "Another research done in this area is about assessing structures vulnerability against earthquake [8].", "startOffset": 98, "endOffset": 101}, {"referenceID": 8, "context": "studied forecasting seismic slope stability by a hybrid Artificial Neural Network and Particle Swarm Optimization [9].", "startOffset": 114, "endOffset": 117}, {"referenceID": 9, "context": "have used Radial Basis Function (RBF) for studying seismic data to identify and eliminate accidental noises which have been produced [10].", "startOffset": 133, "endOffset": 137}, {"referenceID": 10, "context": "have introduced ICA as an optimization goal for modeling processes [11].", "startOffset": 67, "endOffset": 71}, {"referenceID": 11, "context": "Holland in the 1970s [12].", "startOffset": 21, "endOffset": 25}], "year": 2017, "abstractText": "In this study we determined neural network weights and biases by Imperialist Competitive Algorithm (ICA) in order to train network for predicting earthquake intensity in Richter. For this reason, we used dependent parameters like earthquake occurrence time, epicenter\u2019s latitude and longitude in degree, focal depth in kilometer, and the seismological center distance from epicenter and earthquake focal center in kilometer which has been provided by Berkeley data base. The studied neural network has two hidden layer: its first layer has 16 neurons and the second layer has 24 neurons. By using ICA algorithm, average error for testing data is 0.0007 with a variance equal to 0.318. The earthquake prediction error in Richter by MSE criteria for ICA algorithm is 0.101, but by using GA, the MSE value is 0.115.", "creator": "LaTeX with hyperref package"}}}