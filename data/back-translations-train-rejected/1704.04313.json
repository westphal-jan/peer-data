{"id": "1704.04313", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Apr-2017", "title": "CBinfer: Change-Based Inference for Convolutional Neural Networks on Video Data", "abstract": "Extracting per-frame features using convolutional neural networks for real-time processing of video data is currently mainly performed on powerful GPU-accelerated workstations and compute clusters. However, there are many applications such as smart surveillance cameras that require or would benefit from on-site processing. To this end, we propose and evaluate a novel algorithm for change-based evaluation of CNNs for video data recorded with a static camera setting, exploiting the spatio-temporal sparsity of pixel changes. We achieve an average speed-up of 8.6x over a cuDNN baseline on a realistic benchmark with a negligible accuracy loss of less than 0.1% and no retraining of the network. The resulting energy efficiency is 10x higher than per-frame evaluation and reaches an equivalent of 328 GOp/s/W on the Tegra X1 platform.", "histories": [["v1", "Fri, 14 Apr 2017 00:36:55 GMT  (2331kb,D)", "http://arxiv.org/abs/1704.04313v1", null], ["v2", "Wed, 21 Jun 2017 09:27:14 GMT  (2333kb,D)", "http://arxiv.org/abs/1704.04313v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.PF", "authors": ["lukas cavigelli", "philippe degen", "luca benini"], "accepted": false, "id": "1704.04313"}, "pdf": {"name": "1704.04313.pdf", "metadata": {"source": "META", "title": "CBinfer: Change-Based Inference for Convolutional Neural Networks on Video Data", "authors": ["Lukas Cavigelli", "Philippe Degen", "Luca Benini"], "emails": ["cavigelli@iis.ee.ethz.ch", "degenp@ee.ethz.ch", "benini@iis.ee.ethz.ch"], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, it is so that most of them are able to survive themselves without being able to survive themselves. In fact, it is so that they are able to survive themselves, and that they are not able to survive themselves. In fact, it is so that they are able to survive themselves, and that they are not able to survive themselves. In fact, it is so that they are able to survive themselves, and that they are not able to survive themselves."}, {"heading": "2 RELATEDWORK", "text": "In this section, we will first discuss available datasets and CNNs to evaluate our proposed algorithm, then describe existing optimized implementations for CNN inferences and existing approaches that trade accuracy for throughput, and finally explore related approaches that exploit the limited changes in video data to reduce the computing effort needed to perform CNN inferences. 1The Nvidia Tegra X1 is a system-on-chip running on an embedded board with an affordable power budget (< 15W) for a stationary camera.ar Xiv: 170 4.04 313v 1 [cs.C V] 14 Apr 201 7"}, {"heading": "2.1 Suitable Datasets and Neural Networks", "text": "For our evaluations, we are interested in object detection or semantic segmentation, which is often applied to both high-resolution images and video streams with frame rates above 10 frames / s for meaningful applications. Since the classification of still images is considered to be solved because it goes beyond human accuracy [18, 39], there is now a rapidly increasing interest in extracting information from video data, e.g. video tagging and action detection on recently available data sets (Sports-1M [25], Youtube-8M [1]). We are particularly interested in video sequences obtained from a static camera. Although there are some such data sets, most of them specifically target person tracking and / or re-identification and do not provide labeled data for detecting or segmenting objects of multiple classes. However, the data set used in [4] provides floor-to-level labels for segmenting images from the perspective of 10 street surveillance images during multiple segmentation."}, {"heading": "2.2 Optimized Embedded System Implementations", "text": "The recent wave of interest in neural networks can be attributed to their sudden success, driven by the availability of large data sets and increasingly powerful computing platforms. One of the most economical and practicable solutions for training medium-sized CNNs is the use of a workstation with GPUs. The available software frameworks for implementing and training CNNs provide strong support for this type of platform. The enormous amounts of computing time spent on training CNNs have driven the development of highly optimized GPU implementations. Firstly, the most widely used frameworks rely on their own expert implementations, which have all converted to methods based on matrix multiplications [8, 23] which leverage the availability of highly optimized code in BLAS libraries and the fact that GPUs are able to achieve an additional rate of 28 percent of computing throughput with less of these top-level DNs]."}, {"heading": "2.3 Approximations Trading Accuracy for Throughput", "text": "Admitting limited losses in accuracy in order to achieve higher throughput by approximating existing networks, inference algorithms, and arithmetic operations can help overcome the computational obstacles that prevent the widespread adoption of CNN-based algorithms on embedded and mobile platforms. One such option is to reduce the required arithmetic precision to the evaluation of NNN. Various methods exist, from normal fixed-point analysis to the retraining of networks to adapt to quantified weights and activations. While most fixed-point methods are of limited use on many commercially available software programming platforms, some may benefit from vectorization of less precise operations [15]. Extreme methods go so far as to enforce binary weights [2, 10] and in some cases binary activations [36]. This means that multiplications can fall completely, and even collapse in the case of binary activations."}, {"heading": "2.4 Video-based Computation Reduction", "text": "Limited movement of objects in a frame can be exploited in object tracking by working with a limited search window within the frame [20], which not only reduces the size of the problem, but also simplifies the regression task - until the target is obscured by a large object. For object detection and semantic segmentation, the work available in this direction is limited to CNNs clockwork [40]. The authors of [32] have expanded their work on fully revolutionary semantic segmentation networks, which CNN presents with skip connections and deconvolution layers to refine the low-resolution maps obtained deep in the network, while making use of the functions extracted early in the network, taking advantage of the fact that lower-resolution maps within the network are more stable than full data inputs."}, {"heading": "3 METHODOLOGY", "text": "Unlike the previous work, which aimed to re-evaluate whole frames, we do not take advantage of the limited number of pixels that change within the frame to increase throughput without loss of classification accuracy; the most direct pixel approach is to detect pixels at the input that are based on a threshold to the previous frame, and then update all pixels that are affected by them, and increase the number of pixels that are updated layer by layer. For example, a 7 \u00d7 7 convolution can trigger a one-pixel change that triggers an update of 49 pixels in the next layer and 169 pixels after another 7 \u00d7 7 convolution. Strided operations (often with pooling layers) reduce this effect, but do not prevent it. This problem might seem prohibitive for multi-layer CNNs, especially considering that individual pixels do not exceed the threshold due to Noise.The change only locally at the input."}, {"heading": "3.1 Processing Steps", "text": "In this step, modified pixels are defined as those in which the absolute difference between the individual features / channels plays a decisive role."}, {"heading": "3.2 Memory Requirements", "text": "The memory requirements of the DNN frameworks are known to be very high, to the point where they become a limiting factor for increasing the mini-batch size during learning, thereby reducing the throughput of parallelism between multiple GPUs. These requirements vary widely when looking at embedded inference systems: (1) Inferences are typically performed on single frames, and mini-batches often introduce unacceptable latency, and the benefit is limited to a few percent of the additional performance. (2) To maximize modularity and because it is required during training, each layer of memory must be allocated to store its output except for ReLU activation layers, which are often applied on the spot. (3) To maintain high modularity, memory X is often not shared between layers, although its values are never used again. (4) Batch normalization layers are used."}, {"heading": "3.3 Threshold Selection", "text": "The proposed algorithm adds a parameter to each folding layer, the detection threshold, which is set offline using sample video sequences after training. A zero threshold should provide identical results to the non-modification-based implementation used for functional verification. We used the following approach to selecting the thresholds for our evaluations: First, we set all thresholds to zero. Then, we iterate from the first to the last layer, sweep the threshold for each layer and maintain the maximum value before noticing a significant performance deterioration in the evaluation of the entire validation set. The following evaluations will show that these thresholds do not need to be recalibrated per video sequence and neither the accuracy nor the acceleration are oversensitive to it."}, {"heading": "4 RESULTS & DISCUSSION", "text": "In this section, we first present the evaluation environment and analyze the basic calculation time distribution, then show how the threshold parameters were selected, before discussing throughput measurements and the trade-off between accuracy and throughput. Finally, we discuss the calculation time distribution and how changes spread across the network to confirm the quality of our GPU implementation and justify the design decisions made during the algorithm's construction."}, {"heading": "4.1 Evaluation Environment", "text": "While the algorithm is not limited to scene labeling / semantic segmentation, we perform our evaluations using the urban surveillance data set described in [4] and using the corresponding scene caption CNN, not the multispectral image data. The data set contains 51 training images and 6 validation images with 776 x 1040 pixels and the corresponding ground-level scene caption, with each pixel divided into one of the following 8 classes: buildings, street, tree, sky, tram, car / truck, water, distant background. For the validation set, the described images are part of short video sequences with 5 additional frames available in front of the frame for which the ground truth labeling is available. A network based on this is described in [4] and its parameters will be reused unchanged for our evaluations. The method by which we perform our evaluation is based on Figure 5.We have implemented the algorithm UDA as the basis for the Xcumenus module on 1."}, {"heading": "4.2 Baseline Throughput and Computation Breakdown", "text": "Before discussing the performance of the proposed algorithm, we analyze the base throughput and time breakdown in Table 1. Most of the time is clearly spent executing coils, and layers 1-3, which perform 7 x 7 coils and are part of the feature extraction part of the network, dominate with 91.9% (492 ms) of the total computation time (535 ms or 1.87 frames / s), so we focus our analyses specifically on these 3 layers and replace them only with our CBconv layer."}, {"heading": "4.3 Threshold Selection", "text": "Our algorithm introduces a threshold value for each level, for which we outline the selection process in Section 3.3. While we may want to leave it variable to examine throughput against an accuracy compromise, we also want to ensure that the threshold of a single layer does not limit overall accuracy by aligning the tipping point at which accuracy begins to decline. We select the thresholds conservatively and accept a very low accuracy drop, as each classification error focuses on the moving objects that are our area of interest. We sweep out the parameters of each layer to determine the error increase (see Figure 6). We do this first for layer 1 with \u03c42 = \u03c43 = 0 and select \u03c41 = 0.04 before repeating it for layers 2 and 3 one after the other and using the thresholds already selected for the previous layers, using the values 2 = 0.3 and \u041a3 = 1.0.With this selection of thresholds we can scale them together to clarify the trade-off classification (where the 7 is clearer)."}, {"heading": "4.4 Throughput Evaluations", "text": "The motivation for the entire proposed algorithm was to increase throughput by focusing only on the frame-to-frame changes. Therefore, the performance gain in Figure 7 (right) with the specified baseline, which analyzes the entire frame on the same network using cuDNN. In extreme cases, when all thresholds are set to zero, the entire frame is updated, resulting in a significant performance loss due to the overhead of the modification check, as well as fewer optimization options such as less cache-friendly access patterns when generating the X matrix. As the threshold factor increases, throughput quickly increases to about 16 frames / s, and it begins to saturate, because the detection step of the change, as well as other non-varying components such as pooling and pixel classification layers, become dominant and the number of captured modified pixels does not decrease further. We already reach this plateau for a threshold of 1, where we have almost no loss of accuracy due to construction."}, {"heading": "4.5 Accuracy-Throughput Trade-Off", "text": "While in some scenarios any drop in accuracy is unacceptable, many applications allow for a certain trade-off between accuracy and throughput - after all, selecting a particular CNN system already implies selecting a network with the accuracy and computing costs associated with it. We analyze the trade-off directly in Figure 8. The most extreme case is updating the entire frame each time, resulting in the lowest throughput with the same accuracy as full-screen inference. Increasing the threshold factor in steps of 0.25 immediately leads to a significant throughput gain, and for most sequences, the trade-off only begins at frame rates near saturation above 16 frames / s. The same image sequence already deviates from the norm before it behaves differently here. However, an adaptive selection of the threshold factor, such as a simple control loop that receives feedback about the number of pixels changed, could allow guaranteed throughput by reducing accuracy in such cases and being investigated in future work."}, {"heading": "4.6 Compute Time Breakdown", "text": "In order to gain a deeper understanding of the boundary factors of our proposed algorithm, we show in Figure 9 a detailed breakdown of the calculation time only of the change-based folding layers. The time spent on detecting changes is similar across all three convection layers, which is in line with our expectations, as the volume of the function board is identical for input of nch \u00b7 h \u00b7 w values for L2 and L3 and 25% smaller for L1. That this step already accounts for more than 23.4% of the total time underlines the importance of a very simple change detection function: any increase in the calculation time for detecting changes must be offset by saving time in the other steps by significantly reducing the number of changes."}, {"heading": "4.7 Change Propagation", "text": "During the construction of the algorithm, we argued that detecting changes for each layer of folding should not only be done for modularity reasons, but also that otherwise it would result in higher computational effort. We verified this experimentally and show an example case in Figure 10. For layer 2, the number of changes decreases by 6.8 x from 7.57% to 1.11%, and for layer 3 from 2.58% to 1.94% by 1.33 x. While it clearly pays off for layer 2, we analyze the situation for layer 3. From the previous section, we know that detecting changes accounts for only 22% of the total computation time in layer 3, increasing the time to generate the X matrix, performing matrix multiplication, and significantly exceeding the overhead introduced by the change detection step."}, {"heading": "4.8 Energy Efficiency", "text": "We measured the power consumption of the entire Jetson TX1 board with only one Ethernet connection and no other external peripherals, resulting in continuous CNN usage. Average power usage when running the cuDNN-based base implementation was measured at 680mA (12.9W), power consumption decreased to 10.92W when running CBinfer. At idle, we measured 1.7W under normal conditions, which increased to 2.5W with maximum clock frequency enforcement, as was done in previous measurements to maximize throughput. The CNN we used has a computational complexity of 210GOp / frame, with the number of operations (options) being the sum of the addition and multiplications required for the folding layers, giving us 413GOp / s and 32.0 GOp / s / s with the cuDNN baseline. With the proposed binfer method, we obtain a Perfect Frame Inquisition of 772.3p / 3273p of GO3p energy efficiency and 3273p / 3p of GO32.3p."}, {"heading": "5 CONCLUSION", "text": "We have proposed and evaluated a novel algorithm for modified evaluation of CNNs for videos taken with a static camera setting, taking advantage of the spatial and temporal rarity of pixel changes. Results clearly show that even with conservative selection of parameters to detect changes, so as not to cause a significant increase in misclassified pixels during semantic segmentation, an average acceleration of 8.6 x over a cuDNN baseline using optimized GPU implementation was achieved. An in-depth evaluation of the trade-off between throughput and accuracy shows the above-mentioned performance jump without losses and shows how to further increase throughput at the expense of accuracy. An analysis of the calculated time distribution of each step of the algorithm shows that the GPU is fully utilized despite some additional costs to update the modified pixels using the highly optimized cuBLAS matrix multiplication."}, {"heading": "ACKNOWLEDGMENTS", "text": "The authors thank armasuisse Science & Technology for funding this research."}], "references": [{"title": "Origami: A 803 GOp/s/W Convolutional Network Accelerator", "author": ["Lukas Cavigelli", "Luca Benini"], "venue": "IEEE TCSVT", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Accelerating Real-Time Embedded Scene Labeling with Convolutional Networks", "author": ["Lukas Cavigelli", "Michele Magno", "Luca Benini"], "venue": "In Proc. ACM/IEEE DAC", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Torch7: AMatlab-like Environment for Machine Learning", "author": ["Ronan Collobert"], "venue": "Advances in Neural Information Processing Systems Workshops", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "BinaryConnect: Training Deep Neural Networks with binary weights during propagations", "author": ["Matthieu Courbariaux", "Yoshua Bengio", "Jean-Pierre David"], "venue": "In Adv", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Hardwareoriented Approximation of Convolutional Neural Networks", "author": ["Philipp Gysel", "Mohammad Motamedi", "Soheil Ghiasi"], "venue": "In ICLR Workshops", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Learning to track at 100 FPS with deep regression networks", "author": ["David Held", "Sebastian Thrun", "Silvio Savarese"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Speeding up Convolutional Neural Networks with Low Rank Expansions", "author": ["Max Jaderberg", "Andrea Vedaldi", "A Zisserman"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Caffe: An Open Source Convolutional Architecture for Fast Feature Embedding", "author": ["Yangqing Jia"], "venue": "http://caffe.berkeleyvision.org", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Imagenet Classification With Deep Convolutional Neural Networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": "In Adv. NIPS", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "CCTV Surveillance: Video Practices and Technology", "author": ["Herman Kruegle"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1995}, {"title": "maxDNN: An Efficient Convolution Kernel for Deep Learning with Maxwell GPUs", "author": ["Andrew Lavin"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}, {"title": "Fast Algorithms for Convolutional Neural Networks", "author": ["Andrew Lavin", "Scott Gray"], "venue": "In Proc. IEEE CVPR", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "Fully Convolutional Networks for Semantic Segmentation", "author": ["Jonathan Long", "Evan Shelhamer", "Trevor Darrell"], "venue": "In Proc. IEEE CVPR", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}, {"title": "CNN-based in-loop filtering for coding efficiency improvement", "author": ["Woon-sung Park", "Munchurl Kim"], "venue": "In Proc. IEEE Image,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2016}], "referenceMentions": [{"referenceID": 8, "context": "In recent years, the most competitive approaches to address many CV challenges have relied on machine learning with complex, multi-layered, trained feature extractors commonly referred to as deep learning [18, 26, 41].", "startOffset": 205, "endOffset": 217}, {"referenceID": 12, "context": "CNNs keep on expanding to more areas of computer vision and data analytics in general [1, 14, 19, 32, 33, 43].", "startOffset": 86, "endOffset": 109}, {"referenceID": 13, "context": "CNNs keep on expanding to more areas of computer vision and data analytics in general [1, 14, 19, 32, 33, 43].", "startOffset": 86, "endOffset": 109}, {"referenceID": 1, "context": "However, the inference of state-of-the-art CNNs also requires several billions of multiplications and additions to classify even low resolution images by today\u2019s standards [5].", "startOffset": 172, "endOffset": 175}, {"referenceID": 9, "context": "Furthermore, collecting large amounts of data at a central site raises privacy concerns and the required high-bandwidth communication channel causes additional reliability problems and potentially prohibitive cost of deployment and during operation [27].", "startOffset": 249, "endOffset": 253}, {"referenceID": 1, "context": "These push the evaluation of such networks for real-time semantic segmentation or object detection out of reach of even the most powerful embedded platforms available today for high-resolution video data [5].", "startOffset": 204, "endOffset": 207}, {"referenceID": 9, "context": "However, exactly such systems are required for a wide range of applications limited in cost (CCTV/urban surveillance, perimeter surveillance, consumer behavior and highway monitoring) and latency (aerospace and UAV monitoring and defence, visual authentication) [27, 35].", "startOffset": 262, "endOffset": 270}, {"referenceID": 1, "context": "Large efforts have thus already been taken to develop optimized software for heterogeneous platforms [5, 7, 23, 28, 29, 42], to design specialized hardware architectures [2, 3, 6, 12, 33], and to adapt the networks to avoid expensive arithmetic operations or [10, 36, 43].", "startOffset": 101, "endOffset": 123}, {"referenceID": 7, "context": "Large efforts have thus already been taken to develop optimized software for heterogeneous platforms [5, 7, 23, 28, 29, 42], to design specialized hardware architectures [2, 3, 6, 12, 33], and to adapt the networks to avoid expensive arithmetic operations or [10, 36, 43].", "startOffset": 101, "endOffset": 123}, {"referenceID": 10, "context": "Large efforts have thus already been taken to develop optimized software for heterogeneous platforms [5, 7, 23, 28, 29, 42], to design specialized hardware architectures [2, 3, 6, 12, 33], and to adapt the networks to avoid expensive arithmetic operations or [10, 36, 43].", "startOffset": 101, "endOffset": 123}, {"referenceID": 11, "context": "Large efforts have thus already been taken to develop optimized software for heterogeneous platforms [5, 7, 23, 28, 29, 42], to design specialized hardware architectures [2, 3, 6, 12, 33], and to adapt the networks to avoid expensive arithmetic operations or [10, 36, 43].", "startOffset": 101, "endOffset": 123}, {"referenceID": 0, "context": "Large efforts have thus already been taken to develop optimized software for heterogeneous platforms [5, 7, 23, 28, 29, 42], to design specialized hardware architectures [2, 3, 6, 12, 33], and to adapt the networks to avoid expensive arithmetic operations or [10, 36, 43].", "startOffset": 170, "endOffset": 187}, {"referenceID": 13, "context": "Large efforts have thus already been taken to develop optimized software for heterogeneous platforms [5, 7, 23, 28, 29, 42], to design specialized hardware architectures [2, 3, 6, 12, 33], and to adapt the networks to avoid expensive arithmetic operations or [10, 36, 43].", "startOffset": 170, "endOffset": 187}, {"referenceID": 3, "context": "Large efforts have thus already been taken to develop optimized software for heterogeneous platforms [5, 7, 23, 28, 29, 42], to design specialized hardware architectures [2, 3, 6, 12, 33], and to adapt the networks to avoid expensive arithmetic operations or [10, 36, 43].", "startOffset": 259, "endOffset": 271}, {"referenceID": 2, "context": "First, most widely used frameworks relied on their own custom implementations which have all converged to methods relying on matrix-multiplications [8, 23], leveraging the availability of highly optimized code in BLAS libraries and the fact that GPUs are capable of achieving a throughput within a few percent of their peak performance with this type of workload.", "startOffset": 148, "endOffset": 155}, {"referenceID": 7, "context": "First, most widely used frameworks relied on their own custom implementations which have all converged to methods relying on matrix-multiplications [8, 23], leveraging the availability of highly optimized code in BLAS libraries and the fact that GPUs are capable of achieving a throughput within a few percent of their peak performance with this type of workload.", "startOffset": 148, "endOffset": 155}, {"referenceID": 10, "context": "Specialized libraries such as Nvidia\u2019s cuDNN and Nervana Systems\u2019 Neon provide some additional performance gains through assembly-level implementations [28] and additional algorithmic improvements such as Winograd and FFT-based convolution [29].", "startOffset": 152, "endOffset": 156}, {"referenceID": 11, "context": "Specialized libraries such as Nvidia\u2019s cuDNN and Nervana Systems\u2019 Neon provide some additional performance gains through assembly-level implementations [28] and additional algorithmic improvements such as Winograd and FFT-based convolution [29].", "startOffset": 240, "endOffset": 244}, {"referenceID": 1, "context": "A specific implementation for nonbatched inference on an embedded platform building on a matrix multiplication is documented in [5], also showing that more than 90% of time is spent computing convolutions.", "startOffset": 128, "endOffset": 131}, {"referenceID": 4, "context": "While most fixed-point methods are of limited use on many off-the-shelf software programmable platforms, some can benefit from vectorization of lower-precision operations [15].", "startOffset": 171, "endOffset": 175}, {"referenceID": 3, "context": "Extreme methods go as far as to enforce binary weights [2, 10], and in some cases also binary activations [36].", "startOffset": 55, "endOffset": 62}, {"referenceID": 0, "context": "Many networks can be quantized with 8 bit without an increase in error rate, before there is a trade-off between precision and accuracy [3, 17].", "startOffset": 136, "endOffset": 143}, {"referenceID": 12, "context": "Further research has focused on optimizing semantic segmentation and object detection algorithms to better reuse already computed features by eliminating any non-convolutional elements from the network [32, 37, 38].", "startOffset": 202, "endOffset": 214}, {"referenceID": 6, "context": "Simplifying the operations in a network, such as low-rank approximations of 2D convolutions or by simply designing smaller networks with state-of-the-art methods have been evaluated in [21, 22, 34].", "startOffset": 185, "endOffset": 197}, {"referenceID": 5, "context": "Limited movement of objects in a frame can be exploited in object tracking by working with a limited search window within the frame [20], not only reducing the problem size, but also simplifying the regression task\u2014up until the tracked target is occluded by a large object.", "startOffset": 132, "endOffset": 136}, {"referenceID": 12, "context": "The authors of [32] have extended their work on fully convolutional networks for semantic segmentation, which presents a CNN with skip connections and deconvolution layers to refine the lower-resolution feature maps obtained deep within the network using the features extracted early in the network.", "startOffset": 15, "endOffset": 19}, {"referenceID": 1, "context": "This means adapting the widely used, simple and well-performing matrix-generation and matrix-multiplication sequence of operations [5, 23].", "startOffset": 131, "endOffset": 138}, {"referenceID": 7, "context": "This means adapting the widely used, simple and well-performing matrix-generation and matrix-multiplication sequence of operations [5, 23].", "startOffset": 131, "endOffset": 138}, {"referenceID": 1, "context": "Matrix multiplication-based implementations of the convolution layer relying on this are widely available and are highly efficient [5, 24] and is described earlier in this section.", "startOffset": 131, "endOffset": 138}, {"referenceID": 1, "context": "(1) Inference is typically done on single frames and creating mini-batches would introduce often unacceptable latency and the benefit of doing so is limited to a few percent of additional performance [5].", "startOffset": 200, "endOffset": 203}, {"referenceID": 2, "context": "We have implemented the proposed algorithm using CUDA and wrapped them as modules for the Torch framework [8].", "startOffset": 106, "endOffset": 109}], "year": 2017, "abstractText": "Extracting per-frame features using convolutional neural networks for real-time processing of video data is currently mainly performed on powerful GPU-accelerated workstations and compute clusters. However, there are many applications such as smart surveillance cameras that require or would benefit from on-site processing. To this end, we propose and evaluate a novel algorithm for changebased evaluation of CNNs for video data recorded with a static camera setting, exploiting the spatio-temporal sparsity of pixel changes. We achieve an average speed-up of 8.6\u00d7 over a cuDNN baseline on a realistic benchmark with a negligible accuracy loss of less than 0.1% and no retraining of the network. The resulting energy efficiency is 10\u00d7 higher than per-frame evaluation and reaches an equivalent of 328GOp/s/W on the Tegra X1 platform.", "creator": "LaTeX with hyperref package"}}}