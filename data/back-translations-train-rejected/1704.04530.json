{"id": "1704.04530", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Apr-2017", "title": "Neural Extractive Summarization with Side Information", "abstract": "Most extractive summarization methods focus on the main body of the document from which sentences need to be extracted. The gist of the document often lies in the side information of the document, such as title and image captions. These types of side information are often available for newswire articles. We propose to explore side information in the context of single-document extractive summarization. We develop a framework for single-document summarization composed of a hierarchical document encoder and an attention-based extractor with attention over side information. We evaluate our models on a large scale news dataset. We show that extractive summarization with side information consistently outperforms its counterpart (that does not use any side information), in terms on both informativeness and fluency.", "histories": [["v1", "Fri, 14 Apr 2017 20:29:23 GMT  (91kb,D)", "http://arxiv.org/abs/1704.04530v1", "10 pages"], ["v2", "Sun, 10 Sep 2017 19:56:15 GMT  (88kb,D)", "http://arxiv.org/abs/1704.04530v2", "9 pages"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["shashi narayan", "nikos papasarantopoulos", "shay b cohen", "mirella lapata"], "accepted": false, "id": "1704.04530"}, "pdf": {"name": "1704.04530.pdf", "metadata": {"source": "CRF", "title": "Neural Extractive Summarization with Side Information", "authors": ["Shashi Narayan", "Nikos Papasarantopoulos", "Mirella Lapata", "Shay B. Cohen"], "emails": ["shashi.narayan@ed.ac.uk", "nikos.papasa@ed.ac.uk", "mlap@inf.ed.ac.uk", "scohen@inf.ed.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "Most people who live and work in the US are able to understand and understand themselves. (...) Most people who live and work in the US are able to understand the world. (...) Most people who live in the US are able to understand and understand the world. (...) Most people who live in the US have grown up in the US. (...) Most people who live in the US have grown up in the US. (...) Most people who live in the US have been born and raised in the US. (...) Most people who grew up in the US have grown up in the US. (...) Most of those who have grown up in the US have grown up in the US. (...) Most of those I know, those I know, those I don't know. \"(...) Most of those I don't know, those I don't know.\""}, {"heading": "2 Problem Formulation", "text": "In this section, we formally define our extractive summary problem with ancillary information. In the face of document D, which consists of a sequence of sentences (s1, s2,..., sn) and a sequence of page information (c1, c2,..., cp), we generate a summary S of D by selecting sentences from D (where m < n). We evaluate each sentence si for its relevance in the summary and label it with yi, 0, 1, where 1 indicates that si should be taken into account for the summary and 0, otherwise. In this essay, we approach this problem in a monitored environment in which we aim to maximize the probability of the set of terms Y = (y1, y2,..., yn) in light of the input document D and the model parameters \u03b8: P (Y | D; xi) = n, i P (yi | D; \u03b8) (1)."}, {"heading": "3 Neural Extractive Summarization", "text": "We model our extractive summary problem using a hierarchical encoder-decoder architecture, composed of recursive neural networks (RNNs) and revolutionary neural networks (CNNs). The main components of our model are an encoder for revolutionary neural networks, a recursive encoder for neural networks, and an attention-based recursive sentence extractor for neural networks. Our model takes advantage of the compositivity of the document. It reflects that a document is constructed from a meaningful sequence of sentences, and each sentence consists of a meaningful sequence of words. To this end, we first obtain continuous representations of sentences by applying single-layered constitutional neural networks over sequences of word embedding, and then rely on a recursive neural network to compose a sequence of sentences in order to obtain document embedding."}, {"heading": "3.1 Sentence Encoder", "text": "In fact, it is a matter of a way in which the people move in the most diverse areas of the world: from the USA to the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA to the USA, from the USA to the USA, from the USA to the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA to the USA, from the USA to the USA to the USA, from the USA to the USA to the USA, from the USA to the USA to the USA to the USA, from the USA to the USA to the USA, from the USA to the USA to the USA, from the USA to the USA to the USA, from the USA to the USA to the USA to the USA, from the USA to the USA to the USA, from the USA to the USA to the USA, from the USA to the USA to the USA, from the USA to the USA to the USA, from the USA to the USA to the USA, from the USA to the USA, from the USA to the USA, from the USA to the USA to the United States from the United States from the United States from the United States to the United States from the United States from the United States to the United States from the United States to the United States, from the United States to the United States from the United States to the United States from the United States from the United States to the United States from the United States to the United States from the United States to the United States to the United States from the United States to the United States from the United States"}, {"heading": "3.2 Document Encoder", "text": "The document encoder (Figure 2, upper left) assembles a sequence of sentences to obtain a document representation. Sentence extractor (\u00a7 3.3) makes decisive use of the document representation together with the page information to determine the local and global meaning of a sentence in the document in order to make a decision on whether it should be considered for the summary. We use a recurring neural network with Long-Term Memory (LSTM) cells to avoid the disappearing gradient problem when training long sequences (Hochreiter and Schmidhuber, 1997). In the face of a document D consisting of a sequence of sentences (s1, s2,..., sn), we follow the common practice of feeding sentences in reverse order (Sutskever et al., 2014; Li et al., 2015; Filippova et al al al., 2015). In this way, we ensure that the network excludes the uppermost sentences of the document (p. 1, not p. 1, Rush., which are particularly important for 2015, p. 6c., al., al., Rush.)."}, {"heading": "3.3 Sentence Extractor", "text": "Our sentence extractor (Figure 2, top right) identifies each sentence in the document with the names 1 or 0, implicitly estimating its relevance in the document and directly aligning itself with the page information for important clues. Instead, it is implemented using another recurring neural network with LSTM cells and an attention mechanism (Bahdanau et al., 2014). Our attention mechanism differs from the usual practice of taking into account intermediate states of input (encoders). Instead, our extractor reads the page information in the document for keywords. For example, when we look at document D: < (s1, s2,..., sn), (c1, c2,..., cp) >, it reads sentences in order and labels them individually, and also reads the page information in the order in which they appear in the document."}, {"heading": "4 Experimental Setup", "text": "In this section, we present our experimental setup to evaluate our models. We discuss the training and evaluation data set. We also explain how to supplement existing data sets with page information and describe implementation details to facilitate replication of our results. We present a brief description of our base systems."}, {"heading": "4.1 Training and Test data", "text": "We need documents with punctuation meaning, i.e., each sentence in a document is marked 1 (summary-worthy) or 0 (not summary-worthy).For our purposes, we used an extended version of the CNN datasets (Hermann et al., 2015).5However, our dataset is an advanced version of the CNN datasets, which were first used by Svore et al. (2007) for the highlights of our datasets. (2007) we noticed that CNN articles are often associated with \"story highlights\" so that readers can quickly gather information about stories. They also collected a small dataset for5Hermann et al. (2015) have published the DailyMail dataset, but we do not report on these datasets. We found that the script by Hermann et al. to crawl DailyMail article mistakenly extracted captions as part of the main body of the document. Since image descriptions often have no sentence boundaries, they blend with the judgments of the document."}, {"heading": "4.2 Comparison Systems", "text": "We compared the results of our model with the standard basis of simply selecting the first three sentences from each document as a summary. We refer to this baseline in the rest of the paper as BLEAD. We also compared our system with the sentence extraction system of Cheng and Lapata (2016). We refer to this system as POINTERNET.9 It does not use ancillary information but has an attention mechanism to pay attention to sentences during reading. As the results of your system are not available in the CNN dataset, we have implemented POINTERNET in TensorFlow.10."}, {"heading": "4.3 Implementation Details", "text": "We used our training data to train word embedding using the Word2vec model (Mikolov et al., 2013) with context window size 6, negative sampling size 10 and hierarchical Softmax size 1. Word embedding variables with pre-trained word embedding size 200 were initialized for known words. For unknown words, embedding was set to zero but trained during training. All sentences, including titles and captions, were added to a sentence length of 100. For the Convolutionary Sentence Coder, we followed Kim et al. (2016) and used a list of grains ranging from widths 1 to 7, each with an output channel size of 50. This results in the sentence embedding the size into our model to 350. For the recurring Neural8We also experimented with the de-anonymized articles, but the results were worse than those presented here with the anonymized data."}, {"heading": "5 Results and Discussion", "text": "We performed both an automatic and a human evaluation. We begin this section with an ablation study on the validation set. The best model from this study is selected for the test set. In the rest of the work, we refer to our model as SIDENET because of its ability to utilize ancillary information."}, {"heading": "5.1 Automatic Evaluation", "text": "In this context, it is worth mentioning that this project is a project, which is a project that is, first and foremost, a project that responds to the needs of the people."}, {"heading": "5.2 Human Evaluation", "text": "We randomly selected 20 articles from the test set. Annotators were presented with a news article and summaries from four different systems, including the LEAD baseline, POINTERNET, SIDENET, and human-written highlights. We followed the guidelines in Cheng and Lapata (2016) and asked our stakeholders to rate the summaries from the best to the worst in the order of informativity (does the summary capture important information in the article?) and fluently (is the summary written in well-formed English?). We did not allow relationships, we sampled articles with non-identical summaries. We assigned this task to five annotators who were competent native speakers or bilingual English speakers. Each annotator was presented with all 20 articles. The results of our human assessment study are presented in Table 3."}, {"heading": "6 Conclusion", "text": "In this work, we developed a neural network framework for extractive summaries of individual documents with ancillary information. We evaluated our system based on the extensive CNN dataset. Our experiments show that ancillary information is useful for extracting distinctive sentences from the document for the summary. Our framework is very general and could exploit various types of ancillary information."}], "references": [{"title": "TensorFlow: Large-scale machine learning on heterogeneous systems. Software available from tensorflow.org", "author": ["sudevan", "Fernanda Vi\u00e9gas", "Oriol Vinyals", "Pete Warden", "Martin Wattenberg", "Martin Wicke", "Yuan Yu", "Xiaoqiang Zheng"], "venue": null, "citeRegEx": "sudevan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "sudevan et al\\.", "year": 2015}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "arXiv .", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Tgsum: Build tweet guided multi-document summarization dataset", "author": ["Ziqiang Cao", "Chengyao Chen", "Wenjie Li", "Sujian Li", "Furu Wei", "Ming Zhou."], "venue": "Proceedings of the Thirtieth AAAI Conference on Artificial Intelli-", "citeRegEx": "Cao et al\\.,? 2016", "shortCiteRegEx": "Cao et al\\.", "year": 2016}, {"title": "Neural summarization by extracting sentences and words", "author": ["Jianpeng Cheng", "Mirella Lapata."], "venue": "ACL.", "citeRegEx": "Cheng and Lapata.,? 2016", "shortCiteRegEx": "Cheng and Lapata.", "year": 2016}, {"title": "Learning phrase representations using rnn encoder\u2013decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio."], "venue": "EMNLP.", "citeRegEx": "Cho et al\\.,? 2014", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "J. Mach. Learn. Res. 12:2493\u20132537. http://dl.acm.org/citation.cfm?id=1953048.2078186.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "New methods in automatic extracting", "author": ["H.P. Edmundson."], "venue": "J. ACM 16(2):264\u2013285.", "citeRegEx": "Edmundson.,? 1969", "shortCiteRegEx": "Edmundson.", "year": 1969}, {"title": "Event-based extractive summarization", "author": ["Elena Filatova."], "venue": "ACL Workshop on Summarization.", "citeRegEx": "Filatova.,? 2004", "shortCiteRegEx": "Filatova.", "year": 2004}, {"title": "Sentence compression by deletion with lstms", "author": ["Katja Filippova", "Enrique Alfonseca", "Carlos A. Colmenares", "Lukasz Kaiser", "Oriol Vinyals."], "venue": "EMNLP.", "citeRegEx": "Filippova et al\\.,? 2015", "shortCiteRegEx": "Filippova et al\\.", "year": 2015}, {"title": "Teaching machines to read and comprehend", "author": ["Karl Moritz Hermann", "Tom\u00e1\u0161 Ko\u010disk\u00fd", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom."], "venue": "Proceedings of the 28th International Conference on Neural", "citeRegEx": "Hermann et al\\.,? 2015", "shortCiteRegEx": "Hermann et al\\.", "year": 2015}, {"title": "Multimodal pivots for image caption translation", "author": ["Julian Hitschler", "Shigehiko Schamoni", "Stefan Riezler."], "venue": "ACL. Association for Computational Linguistics, Berlin, Germany, pages 2399\u20132409. http://www.aclweb.org/anthology/P16-1227.", "citeRegEx": "Hitschler et al\\.,? 2016", "shortCiteRegEx": "Hitschler et al\\.", "year": 2016}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural Computation 9(8):1735\u20131780. https://doi.org/10.1162/neco.1997.9.8.1735.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "A convolutional neural network for modelling sentences", "author": ["Nal Kalchbrenner", "Edward Grefenstette", "Phil Blunsom."], "venue": "ACL.", "citeRegEx": "Kalchbrenner et al\\.,? 2014", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "EMNLP.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Character-aware neural language models", "author": ["Yoon Kim", "Yacine Jernite", "David Sontag", "Alexander M. Rush."], "venue": "AAAI.", "citeRegEx": "Kim et al\\.,? 2016", "shortCiteRegEx": "Kim et al\\.", "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik P. Kingma", "Jimmy Ba."], "venue": "CoRR abs/1412.6980. http://arxiv.org/abs/1412.6980.", "citeRegEx": "Kingma and Ba.,? 2014", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Extractive summarization using continuous vector space models", "author": ["Mikael K\u00e5geb\u00e4ck", "Olof Mogren", "Nina Tahmasebi", "Devdatt Dubhashi."], "venue": "Proceedings of the 2nd Workshop on Continuous Vector Space Models and their Composition-", "citeRegEx": "K\u00e5geb\u00e4ck et al\\.,? 2014", "shortCiteRegEx": "K\u00e5geb\u00e4ck et al\\.", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton."], "venue": "NIPS.", "citeRegEx": "Krizhevsky et al\\.,? 2012", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "A trainable document summarizer", "author": ["Julian Kupiec", "Jan Pedersen", "Francine Chen."], "venue": "Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. New York, NY, USA, SIGIR \u201995,", "citeRegEx": "Kupiec et al\\.,? 1995", "shortCiteRegEx": "Kupiec et al\\.", "year": 1995}, {"title": "Distributed representations of sentences and documents", "author": ["Quoc V. Le", "Tomas Mikolov."], "venue": "ICML. volume 32, pages 1188\u20131196.", "citeRegEx": "Le and Mikolov.,? 2014", "shortCiteRegEx": "Le and Mikolov.", "year": 2014}, {"title": "Handwritten digit recognition with a backpropagation network", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "R.E. Howard", "W. Habbard", "L.D. Jackel", "D. Henderson."], "venue": "David S. Touretzky, editor, Advances in Neural Information Processing Systems", "citeRegEx": "LeCun et al\\.,? 1990", "shortCiteRegEx": "LeCun et al\\.", "year": 1990}, {"title": "Molding cnns for text: non-linear, non-consecutive convolutions", "author": ["Tao Lei", "Regina Barzilay", "Tommi Jaakkola."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational", "citeRegEx": "Lei et al\\.,? 2015", "shortCiteRegEx": "Lei et al\\.", "year": 2015}, {"title": "A hierarchical neural autoencoder for paragraphs and documents", "author": ["Jiwei Li", "Thang Luong", "Dan Jurafsky."], "venue": "ACL. Association for Computational Linguistics, Beijing, China, pages 1106\u2013 1115. http://www.aclweb.org/anthology/P15-1107.", "citeRegEx": "Li et al\\.,? 2015", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Automatic evaluation of summaries using ngram co-occurrence statistics", "author": ["Chin-Yew Lin", "Eduard Hovy."], "venue": "NAACL. Association for Computational Linguistics, Stroudsburg, PA, USA, pages 71\u201378.", "citeRegEx": "Lin and Hovy.,? 2003", "shortCiteRegEx": "Lin and Hovy.", "year": 2003}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "Proceedings of the 26th International Conference on Neural", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Abstractive text summarization using sequence-tosequence rnns and beyond", "author": ["Ramesh Nallapati", "Bowen Zhou", "C\u0131\u0301cero Nogueira dos Santos", "\u00c7aglar G\u00fcl\u00e7ehre", "Bing Xiang"], "venue": "In Proceedings of the 20th SIGNLL Conference on Computational Natural", "citeRegEx": "Nallapati et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nallapati et al\\.", "year": 2016}, {"title": "Classify or select: Neural architectures for extractive document summarization", "author": ["Ramesh Nallapati", "Bowen Zhou", "Mingbo Ma."], "venue": "CoRR abs/1611.04244. http://arxiv.org/abs/1611.04244.", "citeRegEx": "Nallapati et al\\.,? 2016b", "shortCiteRegEx": "Nallapati et al\\.", "year": 2016}, {"title": "A compositional context sensitive multi-document summarizer: Exploring the factors that influence summarization", "author": ["Ani Nenkova", "Lucy Vanderwende", "Kathleen McKeown."], "venue": "ACM SIGIR. ACM, New York, NY, USA, pages 573\u2013580.", "citeRegEx": "Nenkova et al\\.,? 2006", "shortCiteRegEx": "Nenkova et al\\.", "year": 2006}, {"title": "MEAD \u2014 A platform for multidocument multilingual text summarization", "author": ["Winkel", "Zhu Zhang."], "venue": "Conference on Language Resources and Evaluation (LREC). Lisbon, Portugal.", "citeRegEx": "Winkel and Zhang.,? 2004", "shortCiteRegEx": "Winkel and Zhang.", "year": 2004}, {"title": "A neural attention model for abstractive sentence summarization", "author": ["Alexander M. Rush", "Sumit Chopra", "Jason Weston."], "venue": "EMNLP. pages 379\u2013389.", "citeRegEx": "Rush et al\\.,? 2015", "shortCiteRegEx": "Rush et al\\.", "year": 2015}, {"title": "Automatic summarising: The state of the art", "author": ["Karen Sp\u00e4rck Jones."], "venue": "Inf. Process. Manage. 43(6):1449\u20131481.", "citeRegEx": "Jones.,? 2007", "shortCiteRegEx": "Jones.", "year": 2007}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V. Le."], "venue": "NIPS.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Enhancing singledocument summarization by combining ranknet and third-party sources", "author": ["Krysta Marie Svore", "Lucy Vanderwende", "Christopher J.C. Burges."], "venue": "EMNLP-CoNLL. ACL, pages 448\u2013457.", "citeRegEx": "Svore et al\\.,? 2007", "shortCiteRegEx": "Svore et al\\.", "year": 2007}, {"title": "Pointer networks", "author": ["Oriol Vinyals", "Meire Fortunato", "Navdeep Jaitly."], "venue": "C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, Curran Associates, Inc.,", "citeRegEx": "Vinyals et al\\.,? 2015", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Automatic generation of story highlights", "author": ["Kristian Woodsend", "Mirella Lapata."], "venue": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics,", "citeRegEx": "Woodsend and Lapata.,? 2010", "shortCiteRegEx": "Woodsend and Lapata.", "year": 2010}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["Kelvin Xu", "Jimmy Lei Ba", "Ryan Kiros", "Kyunghyun Cho", "Aaron Courville", "Ruslan Salakhutdinov", "Richard S. Zemel", "Yoshua Bengio"], "venue": null, "citeRegEx": "Xu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Optimizing sentence modeling and selection for document summarization", "author": ["Wenpeng Yin", "Yulong Pei."], "venue": "Proceedings of the 24th International Conference on Artificial Intelligence. AAAI Press, IJCAI\u201915, pages 1383\u20131389.", "citeRegEx": "Yin and Pei.,? 2015", "shortCiteRegEx": "Yin and Pei.", "year": 2015}, {"title": "Character-level convolutional networks for text classification", "author": ["Xiang Zhang", "Junbo Zhao", "Yann LeCun."], "venue": "Proceedings of the 28th International Conference on Neural Information Processing Systems.", "citeRegEx": "Zhang et al\\.,? 2015", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 27, "context": "(Nenkova et al., 2006) and low-level event-based features describing relationships between important actors in a document (Filatova, 2004).", "startOffset": 0, "endOffset": 22}, {"referenceID": 7, "context": ", 2006) and low-level event-based features describing relationships between important actors in a document (Filatova, 2004).", "startOffset": 107, "endOffset": 123}, {"referenceID": 15, "context": "K\u00e5geb\u00e4ck et al. (2014) and Yin and Pei (2015) map sentences to a continuous vector space which is used for similarity measurement to reduce the redundancy in the generated summaries.", "startOffset": 0, "endOffset": 23}, {"referenceID": 15, "context": "K\u00e5geb\u00e4ck et al. (2014) and Yin and Pei (2015) map sentences to a continuous vector space which is used for similarity measurement to reduce the redundancy in the generated summaries.", "startOffset": 0, "endOffset": 46}, {"referenceID": 3, "context": "Cheng and Lapata (2016) and Nallapati et al.", "startOffset": 0, "endOffset": 24}, {"referenceID": 3, "context": "Cheng and Lapata (2016) and Nallapati et al. (2016b) used recurrent neural networks to read sequences of sentences to get a document representation which they use to label each sentence for extraction.", "startOffset": 0, "endOffset": 53}, {"referenceID": 3, "context": "Our hierarchical document encoder resembles the architectures proposed by Cheng and Lapata (2016)", "startOffset": 74, "endOffset": 98}, {"referenceID": 25, "context": "and Nallapati et al. (2016b), in that it derives the document meaning representation from its sentences and their constituent words.", "startOffset": 4, "endOffset": 29}, {"referenceID": 1, "context": "tence extractor combines this document meaning representation with an attention mechanism (Bahdanau et al., 2014) over the side information to select sentences of the input document as the output summary.", "startOffset": 90, "endOffset": 113}, {"referenceID": 1, "context": "both the standard attention mechanism (Bahdanau et al., 2014) which is used to locate the region of focus in the input, and the mechanism of Cheng and Lapata (2016) which directly extracts salient sentences after reading them.", "startOffset": 38, "endOffset": 61}, {"referenceID": 1, "context": "both the standard attention mechanism (Bahdanau et al., 2014) which is used to locate the region of focus in the input, and the mechanism of Cheng and Lapata (2016) which directly extracts salient sentences after reading them.", "startOffset": 39, "endOffset": 165}, {"referenceID": 6, "context": "Edmundson (1969)", "startOffset": 0, "endOffset": 17}, {"referenceID": 18, "context": "used subjectively weighted combination of these human-engineered features, whereas Kupiec et al. (1995) and Mani (2001) trained their feature weights using a corpus.", "startOffset": 83, "endOffset": 104}, {"referenceID": 18, "context": "used subjectively weighted combination of these human-engineered features, whereas Kupiec et al. (1995) and Mani (2001) trained their feature weights using a corpus.", "startOffset": 83, "endOffset": 120}, {"referenceID": 9, "context": "We evaluate our models both automatically (in terms of ROUGE scores) and by conducting human evaluations on the CNN news highlights dataset (Hermann et al., 2015).", "startOffset": 140, "endOffset": 162}, {"referenceID": 4, "context": "We model extractive summarization as a sequence labelling problem using a standard encoder-decoder architecture (Cho et al., 2014; Sutskever et al., 2014).", "startOffset": 112, "endOffset": 154}, {"referenceID": 31, "context": "We model extractive summarization as a sequence labelling problem using a standard encoder-decoder architecture (Cho et al., 2014; Sutskever et al., 2014).", "startOffset": 112, "endOffset": 154}, {"referenceID": 20, "context": "2 CNNs (LeCun et al., 1990) have shown to be very effective in computer vision (Krizhevsky et al.", "startOffset": 7, "endOffset": 27}, {"referenceID": 17, "context": ", 1990) have shown to be very effective in computer vision (Krizhevsky et al., 2012) and for various NLP tasks (Collobert et al.", "startOffset": 59, "endOffset": 84}, {"referenceID": 5, "context": ", 2012) and for various NLP tasks (Collobert et al., 2011; Kim, 2014; Kalchbrenner et al., 2014; Zhang et al., 2015; Lei et al., 2015; Kim et al., 2016; Cheng and Lapata, 2016).", "startOffset": 34, "endOffset": 176}, {"referenceID": 13, "context": ", 2012) and for various NLP tasks (Collobert et al., 2011; Kim, 2014; Kalchbrenner et al., 2014; Zhang et al., 2015; Lei et al., 2015; Kim et al., 2016; Cheng and Lapata, 2016).", "startOffset": 34, "endOffset": 176}, {"referenceID": 12, "context": ", 2012) and for various NLP tasks (Collobert et al., 2011; Kim, 2014; Kalchbrenner et al., 2014; Zhang et al., 2015; Lei et al., 2015; Kim et al., 2016; Cheng and Lapata, 2016).", "startOffset": 34, "endOffset": 176}, {"referenceID": 37, "context": ", 2012) and for various NLP tasks (Collobert et al., 2011; Kim, 2014; Kalchbrenner et al., 2014; Zhang et al., 2015; Lei et al., 2015; Kim et al., 2016; Cheng and Lapata, 2016).", "startOffset": 34, "endOffset": 176}, {"referenceID": 21, "context": ", 2012) and for various NLP tasks (Collobert et al., 2011; Kim, 2014; Kalchbrenner et al., 2014; Zhang et al., 2015; Lei et al., 2015; Kim et al., 2016; Cheng and Lapata, 2016).", "startOffset": 34, "endOffset": 176}, {"referenceID": 14, "context": ", 2012) and for various NLP tasks (Collobert et al., 2011; Kim, 2014; Kalchbrenner et al., 2014; Zhang et al., 2015; Lei et al., 2015; Kim et al., 2016; Cheng and Lapata, 2016).", "startOffset": 34, "endOffset": 176}, {"referenceID": 3, "context": ", 2012) and for various NLP tasks (Collobert et al., 2011; Kim, 2014; Kalchbrenner et al., 2014; Zhang et al., 2015; Lei et al., 2015; Kim et al., 2016; Cheng and Lapata, 2016).", "startOffset": 34, "endOffset": 176}, {"referenceID": 35, "context": "For example, for the caption generation task (Xu et al., 2015), CNNs successfully identify salient objects in the image for the corresponding words in the caption.", "startOffset": 45, "endOffset": 62}, {"referenceID": 19, "context": "We tried sentence/paragraph vector (Le and Mikolov, 2014) to infer sentence embeddings in advance, but the results were inferior to those presented in this paper with CNNs.", "startOffset": 35, "endOffset": 57}, {"referenceID": 4, "context": "by Collobert et al. (2011), Kim (2014) and Cheng and Lapata (2016).", "startOffset": 3, "endOffset": 27}, {"referenceID": 4, "context": "by Collobert et al. (2011), Kim (2014) and Cheng and Lapata (2016).", "startOffset": 3, "endOffset": 39}, {"referenceID": 3, "context": "(2011), Kim (2014) and Cheng and Lapata (2016). A sentence s of length k in D can be represented as a dense matrix W = [w1 \u2295 w2 \u2295 .", "startOffset": 23, "endOffset": 47}, {"referenceID": 5, "context": "We then apply max pooling over time (Collobert et al., 2011) over the feature map f and get fmax = max(f) as the feature corresponding to this particular filter K.", "startOffset": 36, "endOffset": 60}, {"referenceID": 17, "context": "Max-pooling is followed by local response normalization for better generalization (Krizhevsky et al., 2012).", "startOffset": 82, "endOffset": 107}, {"referenceID": 3, "context": "Cheng and Lapata (2016) sum over feature lists to get the final sentence embedding.", "startOffset": 0, "endOffset": 24}, {"referenceID": 3, "context": "Cheng and Lapata (2016) sum over feature lists to get the final sentence embedding. In contrast, we follow Kim et al. (2016) and concatenate them.", "startOffset": 0, "endOffset": 125}, {"referenceID": 11, "context": "Short-Term Memory (LSTM) cells to avoid the vanishing gradient problem when training long sequences (Hochreiter and Schmidhuber, 1997).", "startOffset": 100, "endOffset": 134}, {"referenceID": 31, "context": ", sn), we follow the common practice of feeding sentences in the reverse order (Sutskever et al., 2014; Li et al., 2015; Filippova et al., 2015).", "startOffset": 79, "endOffset": 144}, {"referenceID": 22, "context": ", sn), we follow the common practice of feeding sentences in the reverse order (Sutskever et al., 2014; Li et al., 2015; Filippova et al., 2015).", "startOffset": 79, "endOffset": 144}, {"referenceID": 8, "context": ", sn), we follow the common practice of feeding sentences in the reverse order (Sutskever et al., 2014; Li et al., 2015; Filippova et al., 2015).", "startOffset": 79, "endOffset": 144}, {"referenceID": 1, "context": "It is implemented with another recurrent neural network with LSTM cells and an attention mechanism (Bahdanau et al., 2014).", "startOffset": 99, "endOffset": 122}, {"referenceID": 9, "context": "For our purposes, we used an augmented version of the CNN dataset (Hermann et al., 2015).", "startOffset": 66, "endOffset": 88}, {"referenceID": 9, "context": "For our purposes, we used an augmented version of the CNN dataset (Hermann et al., 2015).5 Our dataset is an evolved version of the CNN dataset first collected by Svore et al. (2007) for highlight generation.", "startOffset": 67, "endOffset": 183}, {"referenceID": 9, "context": "For our purposes, we used an augmented version of the CNN dataset (Hermann et al., 2015).5 Our dataset is an evolved version of the CNN dataset first collected by Svore et al. (2007) for highlight generation. Svore et al. (2007) noticed that CNN articles often come with \u201cstory highlights\u201d to allow readers to quickly gather information on stories.", "startOffset": 67, "endOffset": 229}, {"referenceID": 9, "context": "Recently, Hermann et al. (2015) crawled 93K CNN articles to build a large-scale corpus to set a benchmark for deep learning methods.", "startOffset": 10, "endOffset": 32}, {"referenceID": 3, "context": "this dataset has been used for single-document summarization (Nallapati et al., 2016a; Cheng and Lapata, 2016; Nallapati et al., 2016b).", "startOffset": 61, "endOffset": 135}, {"referenceID": 26, "context": "this dataset has been used for single-document summarization (Nallapati et al., 2016a; Cheng and Lapata, 2016; Nallapati et al., 2016b).", "startOffset": 61, "endOffset": 135}, {"referenceID": 3, "context": ", 2016a; Cheng and Lapata, 2016; Nallapati et al., 2016b). Cheng and Lapata (2016) annotated this dataset with Woodsend and Lapata (2010) style gold annotation.", "startOffset": 9, "endOffset": 83}, {"referenceID": 3, "context": ", 2016a; Cheng and Lapata, 2016; Nallapati et al., 2016b). Cheng and Lapata (2016) annotated this dataset with Woodsend and Lapata (2010) style gold annotation.", "startOffset": 9, "endOffset": 138}, {"referenceID": 9, "context": "We used a modified script of Hermann et al. (2015) to extract title and image captions, and we associated them with the corresponding articles.", "startOffset": 29, "endOffset": 51}, {"referenceID": 34, "context": "Collective oracle The gold annotation of Woodsend and Lapata (2010) labels each sentence of the document in isolation for sentence extraction", "startOffset": 41, "endOffset": 68}, {"referenceID": 23, "context": "ROUGE (Lin and Hovy, 2003), a recall-oriented metric, is often used to evaluate summarization systems.", "startOffset": 6, "endOffset": 26}, {"referenceID": 24, "context": "We used our training data to train word embeddings using the Word2vec (Mikolov et al., 2013) skip-gram model with context window size 6, negative sampling size 10 and hierarchical softmax", "startOffset": 70, "endOffset": 92}, {"referenceID": 13, "context": "For the convolutional sentence encoder, we followed Kim et al. (2016), and used a list of kernels of widths 1 to 7, each with output channel size of 50.", "startOffset": 52, "endOffset": 70}, {"referenceID": 33, "context": "The neural attention architecture in Cheng and Lapata (2016) resembles the one in Pointer Networks (Vinyals et al., 2015).", "startOffset": 99, "endOffset": 121}, {"referenceID": 3, "context": "The neural attention architecture in Cheng and Lapata (2016) resembles the one in Pointer Networks (Vinyals et al.", "startOffset": 37, "endOffset": 61}, {"referenceID": 3, "context": "The neural attention architecture in Cheng and Lapata (2016) resembles the one in Pointer Networks (Vinyals et al., 2015). For sanity check, we have trained our implementation of POINTERNET on the DailyMail dataset and achieved comparable results to what has been reported by Cheng and Lapata (2016). MODELS R1 R2 R3 R4 RL Avg.", "startOffset": 37, "endOffset": 300}, {"referenceID": 15, "context": "(Kingma and Ba, 2014) with initial learning rate 0.", "startOffset": 0, "endOffset": 21}, {"referenceID": 23, "context": "To automatically assess the quality of our summaries, we used ROUGE (Lin and Hovy, 2003),", "startOffset": 68, "endOffset": 88}, {"referenceID": 29, "context": "However, we wanted to explore the idea that the first sentence of the document plays a crucial part in generating summaries (Rush et al., 2015; Nallapati et al., 2016a).", "startOffset": 124, "endOffset": 168}, {"referenceID": 6, "context": "Our result demonstrates the importance of the title of the document in extractive summarization (Edmundson, 1969; Kupiec et al., 1995; Mani, 2001).", "startOffset": 96, "endOffset": 146}, {"referenceID": 18, "context": "Our result demonstrates the importance of the title of the document in extractive summarization (Edmundson, 1969; Kupiec et al., 1995; Mani, 2001).", "startOffset": 96, "endOffset": 146}, {"referenceID": 3, "context": "We followed the guidelines in Cheng and Lapata (2016), and asked our participants to rank the summaries from best to worst in order of informativeness (does the summary cap-", "startOffset": 30, "endOffset": 54}], "year": 2017, "abstractText": "Most extractive summarization methods focus on the main body of the document from which sentences need to be extracted. The gist of the document often lies in the side information of the document, such as title and image captions. These types of side information are often available for newswire articles. We propose to explore side information in the context of singledocument extractive summarization. We develop a framework for single-document summarization composed of a hierarchical document encoder and an attentionbased extractor with attention over side information. We evaluate our models on a large scale news dataset. We show that extractive summarization with side information consistently outperforms its counterpart (that does not use any side information), in terms on both informativeness and", "creator": "LaTeX with hyperref package"}}}