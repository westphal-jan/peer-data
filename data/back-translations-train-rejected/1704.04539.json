{"id": "1704.04539", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Apr-2017", "title": "Cross-lingual Abstract Meaning Representation Parsing", "abstract": "Abstract Meaning Representation (AMR) annotation efforts have mostly focused on English. In order to train parsers on other languages, we propose a method based on annotation projection, which involves exploiting annotations in a source language and a parallel corpus of the source language and a target language. Using English as the source language, we show promising results for Italian, Spanish, German and Chinese as target languages. Besides evaluating the target parsers on non-gold datasets, we further propose an evaluation method that exploits the English gold annotations and does not require access to gold annotations for the target languages. This is achieved by inverting the projection process: a new English parser is learned from the target language parser and evaluated on the existing English gold standard.", "histories": [["v1", "Fri, 14 Apr 2017 20:41:27 GMT  (26kb)", "http://arxiv.org/abs/1704.04539v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["marco damonte", "shay b cohen"], "accepted": false, "id": "1704.04539"}, "pdf": {"name": "1704.04539.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["m.damonte@sms.ed.ac.uk,", "scohen@inf.ed.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 170 4.04 539v 1 [cs.C L] 14 Apr 201 7Cross-lingual Abstract Meaning Representation ParsingMarco Damonte and Shay B. Cohen School of InformaticsUniversity of Edinburghm.damonte @ sms.ed.ac.uk, scohen @ inf.ed.ac.ukAbstract Meaning Representation (AMR) annotation efforts have been predominantly focused on English. To train parsers in other languages, we propose a method based on annotation projection, in which annotations in one source language and a parallel corpus of source and target languages are evaluated. Using English as the source language, we show promising results for Italian, Spanish, German and Chinese as target languages. In addition to evaluating the target parsers on lengthy datasets, we propose another evaluation method that uses English gold annotations and does not require access to gold annotations for the target languages by parsing the existing gold projectors on the English parser."}, {"heading": "1 Introduction", "text": "In fact, we will be able to go in search of a solution that will enable us, that will enable us to find a solution that will enable us, that will enable us to put ourselves in a position, that will enable us to put ourselves in a position, that will enable us to put ourselves in a position, that will enable us to put ourselves in a position, that will enable us to put ourselves in a position, that will enable us to put ourselves in a position, that will enable us to put ourselves in a position, that will enable us to put ourselves in a position."}, {"heading": "2 AMR Parsing", "text": "AMR is a meaning representation that originally aimed at English sentences. It relies on Propbank (Kingsbury and Palmer, 2002) to define the most important predicates in the sentence. AMRs are rooted and directed graphs G = (V, E) with V and E the set of nodes and edges, respectively. Ritter 64 predicates, units and concepts mentioned in the sentence are represented as graph nodes and the relationships between them are represented as graph margins. AMR nodes are either propbank frames or English words, meaning that parsers can in some cases use the English tokens in the input sets or their stems to label nodes. A key feature of AMRs is that they allow re-entry, meaning that one node may have multiple incoming edges. This allows AMR to represent corners and control bands. Nodes in AMR diagram SR are matched with different sets of data."}, {"heading": "3 Cross-lingual Learning for AMR", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 AMR Annotation Projection", "text": "It is easy to project the AMR note onto the target language: since AMR is not based on the input sentences, we can keep the AMR note as it is. We think of English terms for graph nodes as using an independent language, which, by the way, is very similar to English. AMR parses for foreign languages therefore represent an additional complexity: converting tokens into node labels involves an implicit lexical translation. We also need to project the AMR alignments necessary to train AMR parsers, since we do not have an AMR aligner for the target languages: this is the part that depends on the actual word marks in the sentence, and we therefore need to use word alignments, as in other annotation work, to project the adaptations to the target language. An example of AMR chart shared via English and Italian, we make in Figure 1.Our approach depends on a basic assumption."}, {"heading": "3.2 Evaluation on gold annotations", "text": "Once a parser for a target language (target parser) has been learned, we are interested in evaluating its performance. We can create a silver test set in the same way as we created the training set, and use it for the evaluation. However, the silver test set is affected by the errors made by the English AMR parser, as well as by the errors made during the projection, which we will analyze later. To perform the evaluation on a gold test set, we reverse the projection process and train a new English parser from the target parser. We can now evaluate the resulting English parser on a gold test set, and its match score can then be used as a substitute for the score of the target parser."}, {"heading": "3.3 Method pipeline", "text": "Our method of training and evaluating a parser in a target language is summarized as follows: 1. Analyze the English side of a parallel corpus with an English AMR parser; 2. Projecting the parsed annotation on the target side of the parallel corpus (Equation 1); 3. Train a parser for the target language and evaluate it on silver data; 4. Reverse the above procedure to train a new en-glish parser from the parser learned in step 3.5. Rate the new English parser on gold data. As we rely on several automatic tools, the method has several sound sources: 1) The parsers are trained on silver data trained by an automatic parser for English (e \u2192 f) or even by an automatic parser trained on data from a parser learned with silver data (f \u2192 e); 2) the projection uses noisy word alignments (Pado 'and also do not allow for translations between the 2009 and 2009 sources; 3) are also the source languages; 3)."}, {"heading": "4 Experimental setup", "text": "We experiment with several languages: Italian, Spanish, German, and Chinese. For Italian, Spanish, and German, we instead use Europarl (Koehn, 2005), which contains about 1.9M sentences for each language pair, and TED Talks Corpus (Cettolo et al., 2012) for Chinese, which contains about 120K sentences. To train the AMR parsers, we extract 20,000 sentences from each parallel corpus for training, 2,000 for development, and 2,000 for the test; we collect two such records for each language to have non-overlapping records for the two phases of the process (e \u2192 f \u2192 e); the rest of the parallel corpus is used to train the word alignment models; the golden AMR data set used is LDC2015E86, which contains 16,833 training sets, 1,368 development sets, and 1,371 test sets for NIS-NIS languages."}, {"heading": "5 Results", "text": "In addition to the English gold standard rating, as explained in Section 3.2, we also report on the evaluation of the silver data for the target parser. We also define an upper limit for each parser, with English also being used as the target language: the English side of each parallel corpus is used in both directions, so that we filter out the problems of loud word alignment and translation divergence. It is necessary to have a different upper limit for each parser, as the English sides of each parallel corpus are different. Results are in Table 1. The gap between the original English parser (which receives 0.64 points on the gold dataset) and the upper limits shown is about 5%, which is entirely due to the effect of retraining on parsed (silver) data. Italian, Spanish and German have comparable performance. For these languages, the gap with the original English parser is about 20%, which is similar to the gap of 15% reported for the annotation projector."}, {"heading": "6 Analysis", "text": "Figure 2 shows examples of output parses for all tested languages, including AMR alignments as a by-product of the parsing process that we use to discuss the errors of the parsers. In the Italian example, the only obvious error is that Infine (Finally) should be ignored. In the Spanish example, the word medida (Measure) is incorrectly ignored: It should be used to create a child of the impact-01 node. Some of the: ARG roles are also incorrect. In the German example, my (mine) should reflect the fact that the speaker is talking about his own country. Finally, in the Chinese examples, product and increase, both central to the meaning of the sentence, are ignored. We find that the rest of the AMR is solid, leading to the correct AMR chart for another sentence: Finland exports high technology. Most errors involve concept identification and, in particular, relevant words that are erroneously ignored when the word is paralyzed by the paralyzer."}, {"heading": "6.1 Translational divergence", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "6.2 Analysis of the Chinese Parser", "text": "As already mentioned, the performance of the Chinese parser is lower than that of any other parser. Table 2 shows the differences between the Spanish and Chinese parsers (silver rating), using the submetrics outlined by Damonte et al. (2017) to better investigate where the Chinese parser lags behind. These metrics evaluate specific problems that the AMR parsers must face, such as concept recognition, semantic role designation and negation recognition. We note large gaps in Wikification (identification of Wikipedia identifiers for designated entities), while I (a) ES: Tengo envidia de ti (I am jealous of you) Answer-01we (b) IT: Noi daremo una risposta (we will answer) enter-01home (c) IT: Lui e entrato nella casa (He entered the house), however, has a small impact on the overall identification and concept identification."}, {"heading": "7 Related Work", "text": "In previous work on AMR for other languages (Li et al., 2016; Xue et al., 2014; Bojar, 2014), nodes of the target diagram were labeled either with English words or with words in the target language. Instead, we use the same AMR annotation for English into the target language without translating a word. To our knowledge, the only previous work that attempted to automatically parse AMR diagrams for non-English sentences, by Vanderwende et al. (2015). Sentences in multiple languages (French, German, Spanish and Japanese) are converted into a logical representation, which is then converted into AMR with a small set of rules. Comparing with this work is difficult as the authors do not report the results for the parsers (due to the lack of a commented company) or their code.In addition to AMR, other semantic parsing frameworks for non-English languages."}, {"heading": "8 Conclusion", "text": "We proposed a method to overcome the lack of non-English AMR data sets and presented the initial results for Italian, Spanish, German and Chinese. Automatic and manual evaluations for these languages are promising and give hope for further development of AMR analysis for languages other than English. We also proposed a novel method for evaluating target parsers that does not require manual annotations of the target language. This reverse procedure is not limited to AMR analysis and can be used for other problems in NLP. Finally, we identified weaknesses and sources of interference in the proposed method that could address future work."}], "references": [{"title": "Italy goes to stanford: a collection of corenlp modules for italian", "author": ["Alessio Palmero Aprosio", "Giovanni Moretti."], "venue": "arXiv preprint arXiv:1609.06204 .", "citeRegEx": "Aprosio and Moretti.,? 2016", "shortCiteRegEx": "Aprosio and Moretti.", "year": 2016}, {"title": "Abstract meaning representation for sembanking", "author": ["Laura Banarescu", "Claire Bonial", "Shu Cai", "Madalina Georgescu", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Philipp Koehn", "Martha Palmer", "Nathan Schneider."], "venue": "Linguistic Annotation Workshop .", "citeRegEx": "Banarescu et al\\.,? 2013", "shortCiteRegEx": "Banarescu et al\\.", "year": 2013}, {"title": "Comparing czech and english amrs", "author": ["Zdenka Ure\u0161ov\u00e1 Jan Hajic Ondrej Bojar."], "venue": "InWorkshop on Lexical and Grammatical Resources for Language Processing.", "citeRegEx": "Bojar.,? 2014", "shortCiteRegEx": "Bojar.", "year": 2014}, {"title": "Smatch: an evaluation metric for semantic feature structures", "author": ["Shu Cai", "Kevin Knight."], "venue": "Proceedings of ACL .", "citeRegEx": "Cai and Knight.,? 2013", "shortCiteRegEx": "Cai and Knight.", "year": 2013}, {"title": "Freeling: An open-source suite of language analyzers", "author": ["Xavier Carreras", "Isaac Chao", "Llus Padr", "Muntsa Padr."], "venue": "Proceedings of LREC).", "citeRegEx": "Carreras et al\\.,? 2004", "shortCiteRegEx": "Carreras et al\\.", "year": 2004}, {"title": "Wit: Web inventory of transcribed and translated talks", "author": ["Mauro Cettolo", "Christian Girardi", "Marcello Federico."], "venue": "Proceedings of the 16 Conference of the European Association for Machine Translation (EAMT). Trento, Italy, pages 261\u2013268.", "citeRegEx": "Cettolo et al\\.,? 2012", "shortCiteRegEx": "Cettolo et al\\.", "year": 2012}, {"title": "Tectogrammatical annotation of the wall street", "author": ["Silvie Cinkov\u00e1", "Josef Toman", "Jan Hajic", "Krist\u1ef3na Cerm\u00e1kov\u00e1", "V\u00e1clav Klime\u0161", "Lucie Mladov\u00e1", "Jana \u0160indlerov\u00e1", "Krist\u1ef3na Tom\u0161u", "Zdenek Zabokrtsk\u1ef3."], "venue": "The Prague Bulletin of", "citeRegEx": "Cinkov\u00e1 et al\\.,? 2009", "shortCiteRegEx": "Cinkov\u00e1 et al\\.", "year": 2009}, {"title": "Unsupervised structure prediction with nonparallel multilingual guidance", "author": ["Shay B. Cohen", "Dipanjan Das", "Noah A. Smith."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Cohen et al\\.,? 2011", "shortCiteRegEx": "Cohen et al\\.", "year": 2011}, {"title": "Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction", "author": ["Shay B Cohen", "Noah A Smith."], "venue": "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the", "citeRegEx": "Cohen and Smith.,? 2009", "shortCiteRegEx": "Cohen and Smith.", "year": 2009}, {"title": "An incremental parser for abstract meaning representation", "author": ["Marco Damonte", "Shay B Cohen", "Giorgio Satta."], "venue": "Proceedings of EACL.", "citeRegEx": "Damonte et al\\.,? 2017", "shortCiteRegEx": "Damonte et al\\.", "year": 2017}, {"title": "Machine translation divergences: A formal description and proposed solution", "author": ["Bonnie J Dorr."], "venue": "Computational Linguistics 20(4):597\u2013633.", "citeRegEx": "Dorr.,? 1994", "shortCiteRegEx": "Dorr.", "year": 1994}, {"title": "Improved word-level alignment: Injecting knowledge about mt divergences", "author": ["Bonnie J Dorr", "Lisa Pearl", "Rebecca Hwa", "Nizar Habash."], "venue": "Technical report, DTIC Document.", "citeRegEx": "Dorr et al\\.,? 2002", "shortCiteRegEx": "Dorr et al\\.", "year": 2002}, {"title": "A simple, fast, and effective reparameterization of ibm model 2", "author": ["Chris Dyer", "Victor Chahuneau", "Noah A Smith."], "venue": "Proceedings of NAACL-HLT.", "citeRegEx": "Dyer et al\\.,? 2013", "shortCiteRegEx": "Dyer et al\\.", "year": 2013}, {"title": "Cross-lingual learning of an open-domain semantic parser", "author": ["Kilian Evang", "Johan Bos."], "venue": "Proceedings of COLING.", "citeRegEx": "Evang and Bos.,? 2016", "shortCiteRegEx": "Evang and Bos.", "year": 2016}, {"title": "A discriminative graph-based parser for the abstract meaning representation", "author": ["Jeffrey Flanigan", "Sam Thomson", "Jaime G Carbonell", "Chris Dyer", "Noah A Smith."], "venue": "Proceedings of ACL .", "citeRegEx": "Flanigan et al\\.,? 2014", "shortCiteRegEx": "Flanigan et al\\.", "year": 2014}, {"title": "A latent variable model of synchronous syntactic-semantic parsing for multiple languages", "author": ["Andrea Gesmundo", "James Henderson", "Paola Merlo", "Ivan Titov."], "venue": "Proceedings of CoNLL. Association for Computational Linguistics.", "citeRegEx": "Gesmundo et al\\.,? 2009", "shortCiteRegEx": "Gesmundo et al\\.", "year": 2009}, {"title": "A ccg approach to free word order languages", "author": ["Beryl Hoffman."], "venue": "Proceedings of ACL.", "citeRegEx": "Hoffman.,? 1992", "shortCiteRegEx": "Hoffman.", "year": 1992}, {"title": "Bootstrapping parsers via syntactic projection across parallel texts", "author": ["Rebecca Hwa", "Philip Resnik", "Amy Weinberg", "Clara Cabezas", "Okan Kolak."], "venue": "Natural language engineering 11(03):311\u2013325.", "citeRegEx": "Hwa et al\\.,? 2005", "shortCiteRegEx": "Hwa et al\\.", "year": 2005}, {"title": "From treebank to propbank", "author": ["Paul Kingsbury", "Martha Palmer."], "venue": "Proceedings of LREC .", "citeRegEx": "Kingsbury and Palmer.,? 2002", "shortCiteRegEx": "Kingsbury and Palmer.", "year": 2002}, {"title": "Europarl: A parallel corpus for statistical machine translation", "author": ["Philipp Koehn."], "venue": "MT summit. volume 5, pages 79\u201386.", "citeRegEx": "Koehn.,? 2005", "shortCiteRegEx": "Koehn.", "year": 2005}, {"title": "Annotating the little prince with chinese amrs", "author": ["Bin Li", "Yuan Wen", "Lijun Bu", "Weiguang Qu", "Nianwen Xue."], "venue": "LAW X Workshop .", "citeRegEx": "Li et al\\.,? 2016", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky."], "venue": "ACL System Demonstrations.", "citeRegEx": "Manning et al\\.,? 2014", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Multi-source transfer of delexicalized dependency parsers", "author": ["Ryan McDonald", "Slav Petrov", "Keith Hall."], "venue": "Proceedings of EMNLP.", "citeRegEx": "McDonald et al\\.,? 2011", "shortCiteRegEx": "McDonald et al\\.", "year": 2011}, {"title": "Incrementality in deterministic dependency parsing", "author": ["Joakim Nivre."], "venue": "ACL Workshop on Incremental Parsing: Bringing Engineering and Cognition Together .", "citeRegEx": "Nivre.,? 2004", "shortCiteRegEx": "Nivre.", "year": 2004}, {"title": "Crosslingual annotation projection for semantic roles", "author": ["Sebastian Pad\u00f3", "Mirella Lapata."], "venue": "Journal of Artificial Intelligence Research 36(1):307\u2013340.", "citeRegEx": "Pad\u00f3 and Lapata.,? 2009", "shortCiteRegEx": "Pad\u00f3 and Lapata.", "year": 2009}, {"title": "Data point selection for crosslanguage adaptation of dependency parsers", "author": ["Anders S\u00f8gaard."], "venue": "Proceedings of ACL-HLT.", "citeRegEx": "S\u00f8gaard.,? 2011", "shortCiteRegEx": "S\u00f8gaard.", "year": 2011}, {"title": "Conceptual annotations preserve structure across translations: A french-english case study", "author": ["Elior Sulem", "Omri Abend", "Ari Rappoport."], "venue": "Workshop on Semantics-Driven Statistical Machine Translation.", "citeRegEx": "Sulem et al\\.,? 2015", "shortCiteRegEx": "Sulem et al\\.", "year": 2015}, {"title": "Cross-lingual validity of propbank in the manual annotation of french", "author": ["Lonneke Van der Plas", "Tanja Samard\u017ei\u0107", "Paola Merlo."], "venue": "Linguistic Annotation Workshop.", "citeRegEx": "Plas et al\\.,? 2010", "shortCiteRegEx": "Plas et al\\.", "year": 2010}, {"title": "An amr parser for english, french, german, spanish and japanese and a new amr-annotated corpus", "author": ["Lucy Vanderwende", "Arul Menezes", "Chris Quirk."], "venue": "Proceedings of NAACL-HLT. pages 26\u201330.", "citeRegEx": "Vanderwende et al\\.,? 2015", "shortCiteRegEx": "Vanderwende et al\\.", "year": 2015}, {"title": "Camr at semeval-2016 task 8: An extended transition-based amr parser", "author": ["Chuan Wang", "Sameer Pradhan", "Nianwen Xue", "Xiaoman Pan", "Heng Ji."], "venue": "Proceedings of SemEval pages 1173\u20131178.", "citeRegEx": "Wang et al\\.,? 2016", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Not an interlingua, but close: Comparison of english amrs to chinese and czech", "author": ["Nianwen Xue", "Ondrej Bojar", "Jan Hajic", "Martha Palmer", "Zdenka Uresova", "Xiuhong Zhang."], "venue": "Proceedings of LREC.", "citeRegEx": "Xue et al\\.,? 2014", "shortCiteRegEx": "Xue et al\\.", "year": 2014}, {"title": "Crosslanguage parser adaptation between related languages", "author": ["Daniel Zeman", "Philip Resnik."], "venue": "IJCNLP.", "citeRegEx": "Zeman and Resnik.,? 2008", "shortCiteRegEx": "Zeman and Resnik.", "year": 2008}], "referenceMentions": [{"referenceID": 1, "context": "Abstract Meaning Representation (AMR) parsing converts natural language sentences into their corresponding AMRs (Banarescu et al., 2013).", "startOffset": 112, "endOffset": 136}, {"referenceID": 17, "context": "One way to do this is by annotation projection, where the existing annotations are projected to a target language through a parallel corpus (Hwa et al., 2005).", "startOffset": 140, "endOffset": 158}, {"referenceID": 1, "context": "The original AMR definition states that AMR is not an interlingua (Banarescu et al., 2013).", "startOffset": 66, "endOffset": 90}, {"referenceID": 1, "context": "The original AMR definition states that AMR is not an interlingua (Banarescu et al., 2013). Bojar (2014) categorizes the different kinds of divergences in the annotation between English AMRs and Czech AMRs.", "startOffset": 67, "endOffset": 105}, {"referenceID": 1, "context": "The original AMR definition states that AMR is not an interlingua (Banarescu et al., 2013). Bojar (2014) categorizes the different kinds of divergences in the annotation between English AMRs and Czech AMRs. Xue et al. (2014) showed that structurally aligning Czech and English AMRs is problematic but reached different conclusions for the language pair EnglishChinese, showing that their AMRs can be aligned, suggesting that, with tailored annotation guidelines, it could be possible to make AMR behave as an interlingua.", "startOffset": 67, "endOffset": 225}, {"referenceID": 18, "context": "It relies on Propbank (Kingsbury and Palmer, 2002) to define the main predicates in the sentence.", "startOffset": 22, "endOffset": 50}, {"referenceID": 3, "context": "In order to evaluate AMR parsers, the Smatch score (Cai and Knight, 2013) is traditionally used.", "startOffset": 51, "endOffset": 73}, {"referenceID": 23, "context": "parser (Nivre, 2004): the sentence is stored in a buffer, which is scanned once left-to-right and the words in the sentences are either ignored or trigger a subgraph in a stack.", "startOffset": 7, "endOffset": 20}, {"referenceID": 29, "context": "67 on the same dataset (Wang et al., 2016).", "startOffset": 23, "endOffset": 42}, {"referenceID": 24, "context": "Since we rely on several automatic tools, there are several sources of noise in the method: 1) the parsers are trained on silver data obtained by an automatic parser for English (e \u2192 f ) or even by an automatic parser trained on data obtained by a parser which in turn was learned with silver data (f \u2192 e); 2) the projection uses noisy word alignments (Pad\u00f3 and Lapata, 2009); 3) the AMR alignments on the source side are also noisy; 4) translation divergences exist between the languages, making it sometimes not possible to project the annotation without loss of information.", "startOffset": 352, "endOffset": 375}, {"referenceID": 19, "context": "For Italian, Spanish and German we use Europarl (Koehn, 2005), containing around 1.", "startOffset": 48, "endOffset": 61}, {"referenceID": 5, "context": "9M sentences for each language pair, and the TED talks corpus (Cettolo et al., 2012) for Chinese, containing around 120K sentences.", "startOffset": 62, "endOffset": 84}, {"referenceID": 12, "context": "Word alignments were generated using fast align (Dyer et al., 2013), while AMR alignments were generated with JAMR (Flanigan et al.", "startOffset": 48, "endOffset": 67}, {"referenceID": 14, "context": ", 2013), while AMR alignments were generated with JAMR (Flanigan et al., 2014).", "startOffset": 55, "endOffset": 78}, {"referenceID": 9, "context": "As an English AMR parser and a starting point to develop the target parsers we used AMREager (Damonte et al., 2017), which is an open-source AMR parser for English that requires only small modifications for re-use on other languages.", "startOffset": 93, "endOffset": 115}, {"referenceID": 21, "context": "parsing, which for English, German and Chinese are provided by CoreNLP (Manning et al., 2014).", "startOffset": 71, "endOffset": 93}, {"referenceID": 4, "context": "We use Freeling (Carreras et al., 2004) instead.", "startOffset": 16, "endOffset": 39}, {"referenceID": 0, "context": "Italian is not supported in CoreNLP: we use Tint (Aprosio and Moretti, 2016), which is a CoreNLP-compatible NLP pipeline for Italian.", "startOffset": 49, "endOffset": 76}, {"referenceID": 13, "context": "For these languages, the gap with the original English parser is around 20%, which is comparable to the 15% gap reported for annotation projection based cross-lingual semantic parsing for French under the combinatory categorial grammar (CCG) framework (Evang and Bos, 2016).", "startOffset": 252, "endOffset": 273}, {"referenceID": 5, "context": "Even within the TED talks corpus, the Chinese-English pair has been shown to be especially challenging (Cettolo et al., 2012).", "startOffset": 103, "endOffset": 125}, {"referenceID": 11, "context": "In this section, we look at this type of divergence and discuss how it affects parsing, following the classification used in previous work (Dorr et al., 2002; Dorr, 1994), which identify classes of divergences for several languages.", "startOffset": 139, "endOffset": 170}, {"referenceID": 10, "context": "In this section, we look at this type of divergence and discuss how it affects parsing, following the classification used in previous work (Dorr et al., 2002; Dorr, 1994), which identify classes of divergences for several languages.", "startOffset": 139, "endOffset": 170}, {"referenceID": 10, "context": "In this section, we look at this type of divergence and discuss how it affects parsing, following the classification used in previous work (Dorr et al., 2002; Dorr, 1994), which identify classes of divergences for several languages. Sulem et al. (2015) also follow the same categorization for French.", "startOffset": 140, "endOffset": 253}, {"referenceID": 9, "context": "Table 2 shows the differences between the Spanish and the Chinese parsers (silver evaluation), using the submetrics outlined by Damonte et al. (2017) to better investigate where the Chinese parser falls behind.", "startOffset": 128, "endOffset": 150}, {"referenceID": 20, "context": "work on AMR for other languages (Li et al., 2016; Xue et al., 2014; Bojar, 2014) nodes of the target graph were labeled with either English words or with words in the target language.", "startOffset": 32, "endOffset": 80}, {"referenceID": 30, "context": "work on AMR for other languages (Li et al., 2016; Xue et al., 2014; Bojar, 2014) nodes of the target graph were labeled with either English words or with words in the target language.", "startOffset": 32, "endOffset": 80}, {"referenceID": 2, "context": "work on AMR for other languages (Li et al., 2016; Xue et al., 2014; Bojar, 2014) nodes of the target graph were labeled with either English words or with words in the target language.", "startOffset": 32, "endOffset": 80}, {"referenceID": 2, "context": ", 2014; Bojar, 2014) nodes of the target graph were labeled with either English words or with words in the target language. We instead use the same AMR annotation used for English to the target language, without translating any word. To the best of our knowledge, the only previous work that attempts to automatically parse AMR graphs for non-English sentences is by Vanderwende et al. (2015). Sentences in several languages (French, German, Spanish and Japanese) are parsed into a logical representation, which is then converted to AMR using a small set of rules.", "startOffset": 8, "endOffset": 393}, {"referenceID": 16, "context": "Besides AMR, other semantic parsing frameworks for non-English languages have been investigated (Hoffman, 1992; Cinkov\u00e1 et al., 2009; Gesmundo et al., 2009; Evang and Bos, 2016).", "startOffset": 96, "endOffset": 177}, {"referenceID": 6, "context": "Besides AMR, other semantic parsing frameworks for non-English languages have been investigated (Hoffman, 1992; Cinkov\u00e1 et al., 2009; Gesmundo et al., 2009; Evang and Bos, 2016).", "startOffset": 96, "endOffset": 177}, {"referenceID": 15, "context": "Besides AMR, other semantic parsing frameworks for non-English languages have been investigated (Hoffman, 1992; Cinkov\u00e1 et al., 2009; Gesmundo et al., 2009; Evang and Bos, 2016).", "startOffset": 96, "endOffset": 177}, {"referenceID": 13, "context": "Besides AMR, other semantic parsing frameworks for non-English languages have been investigated (Hoffman, 1992; Cinkov\u00e1 et al., 2009; Gesmundo et al., 2009; Evang and Bos, 2016).", "startOffset": 96, "endOffset": 177}, {"referenceID": 6, "context": "Besides AMR, other semantic parsing frameworks for non-English languages have been investigated (Hoffman, 1992; Cinkov\u00e1 et al., 2009; Gesmundo et al., 2009; Evang and Bos, 2016). Evang and Bos (2016) is the most closely related to our work as it uses a projection mechanism similar to ours for CCG.", "startOffset": 112, "endOffset": 200}, {"referenceID": 30, "context": "Previous work has also focused on assessing the stability across languages of semantic frameworks such as AMR (Xue et al., 2014; Bojar, 2014), UCCA (Sulem et al.", "startOffset": 110, "endOffset": 141}, {"referenceID": 2, "context": "Previous work has also focused on assessing the stability across languages of semantic frameworks such as AMR (Xue et al., 2014; Bojar, 2014), UCCA (Sulem et al.", "startOffset": 110, "endOffset": 141}, {"referenceID": 26, "context": ", 2014; Bojar, 2014), UCCA (Sulem et al., 2015) and Propbank (Van der Plas et al.", "startOffset": 27, "endOffset": 47}, {"referenceID": 30, "context": "Supporting evidence comes from the preliminary work on Chinese (Xue et al., 2014) and investigation of the cross-lingual stability of Propbank, on which AMR is partially based (Van der Plas et al.", "startOffset": 63, "endOffset": 81}, {"referenceID": 17, "context": "It was introduced for dependency parsing (Hwa et al., 2005) but it has also been used for role labeling (Pad\u00f3 and Lapata, 2009) and semantic parsing (Evang and Bos, 2016).", "startOffset": 41, "endOffset": 59}, {"referenceID": 24, "context": ", 2005) but it has also been used for role labeling (Pad\u00f3 and Lapata, 2009) and semantic parsing (Evang and Bos, 2016).", "startOffset": 52, "endOffset": 75}, {"referenceID": 13, "context": ", 2005) but it has also been used for role labeling (Pad\u00f3 and Lapata, 2009) and semantic parsing (Evang and Bos, 2016).", "startOffset": 97, "endOffset": 118}, {"referenceID": 31, "context": "Another common thread of cross-lingual work is of the model transfer type, where parameters are shared across languages (Zeman and Resnik, 2008; Cohen et al., 2011; Cohen and Smith, 2009; McDonald et al., 2011; S\u00f8gaard, 2011).", "startOffset": 120, "endOffset": 225}, {"referenceID": 7, "context": "Another common thread of cross-lingual work is of the model transfer type, where parameters are shared across languages (Zeman and Resnik, 2008; Cohen et al., 2011; Cohen and Smith, 2009; McDonald et al., 2011; S\u00f8gaard, 2011).", "startOffset": 120, "endOffset": 225}, {"referenceID": 8, "context": "Another common thread of cross-lingual work is of the model transfer type, where parameters are shared across languages (Zeman and Resnik, 2008; Cohen et al., 2011; Cohen and Smith, 2009; McDonald et al., 2011; S\u00f8gaard, 2011).", "startOffset": 120, "endOffset": 225}, {"referenceID": 22, "context": "Another common thread of cross-lingual work is of the model transfer type, where parameters are shared across languages (Zeman and Resnik, 2008; Cohen et al., 2011; Cohen and Smith, 2009; McDonald et al., 2011; S\u00f8gaard, 2011).", "startOffset": 120, "endOffset": 225}, {"referenceID": 25, "context": "Another common thread of cross-lingual work is of the model transfer type, where parameters are shared across languages (Zeman and Resnik, 2008; Cohen et al., 2011; Cohen and Smith, 2009; McDonald et al., 2011; S\u00f8gaard, 2011).", "startOffset": 120, "endOffset": 225}], "year": 2017, "abstractText": "Abstract Meaning Representation (AMR) annotation efforts have mostly focused on English. In order to train parsers on other languages, we propose a method based on annotation projection, which involves exploiting annotations in a source language and a parallel corpus of the source language and a target language. Using English as the source language, we show promising results for Italian, Spanish, German and Chinese as target languages. Besides evaluating the target parsers on nongold datasets, we further propose an evaluation method that exploits the English gold annotations and does not require access to gold annotations for the target languages. This is achieved by inverting the projection process: a new English parser is learned from the target language parser and evaluated on the existing English gold standard.Meaning Representation (AMR) annotation efforts have mostly focused on English. In order to train parsers on other languages, we propose a method based on annotation projection, which involves exploiting annotations in a source language and a parallel corpus of the source language and a target language. Using English as the source language, we show promising results for Italian, Spanish, German and Chinese as target languages. Besides evaluating the target parsers on nongold datasets, we further propose an evaluation method that exploits the English gold annotations and does not require access to gold annotations for the target languages. This is achieved by inverting the projection process: a new English parser is learned from the target language parser and evaluated on the existing English gold standard.", "creator": "LaTeX with hyperref package"}}}