{"id": "1704.04977", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Apr-2017", "title": "Probabilistic programs for inferring the goals of autonomous agents", "abstract": "Intelligent systems sometimes need to infer the probable goals of people, cars, and robots, based on partial observations of their motion. This paper introduces a class of probabilistic programs for formulating and solving these problems. The formulation uses randomized path planning algorithms as the basis for probabilistic models of the process by which autonomous agents plan to achieve their goals. Because these path planning algorithms do not have tractable likelihood functions, new inference algorithms are needed. This paper proposes two Monte Carlo techniques for these \"likelihood-free\" models, one of which can use likelihood estimates from neural networks to accelerate inference. The paper demonstrates efficacy on three simple examples, each using under 50 lines of probabilistic code.", "histories": [["v1", "Mon, 17 Apr 2017 14:34:02 GMT  (3995kb,D)", "http://arxiv.org/abs/1704.04977v1", null], ["v2", "Tue, 18 Apr 2017 14:40:03 GMT  (3995kb,D)", "http://arxiv.org/abs/1704.04977v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["marco f cusumano-towner", "alexey radul", "david wingate", "vikash k mansinghka"], "accepted": false, "id": "1704.04977"}, "pdf": {"name": "1704.04977.pdf", "metadata": {"source": "CRF", "title": "Probabilistic programs for inferring the goals of autonomous agents", "authors": ["Marco F. Cusumano-Towner", "Alexey Radul", "David Wingate", "Vikash K. Mansinghka"], "emails": [], "sections": [{"heading": null, "text": "Intelligent systems sometimes have to derive the likely goals of humans, cars and robots based on partial observations of their movements. In this paper, a class of probabilistic programs is presented to formulate and solve these problems, using randomized path planning algorithms as the basis for probabilistic models of the process by which autonomous actors aim to achieve their goals. Since these path planning algorithms do not have tractable probability functions, new inference algorithms are needed. In this paper, two Monte Carlo techniques are proposed for these \"probability-free\" models, one of which can use probability estimates from neural networks to accelerate conclusions."}, {"heading": "1 INTRODUCTION", "text": "In fact, most of us are able to play by the rules they have imposed on ourselves."}, {"heading": "2 MODELING GOAL-DIRECTED BEHAVIOR USING RANDOMIZED PATH PLANNERS", "text": "The planner assumes a limited two-dimensional space (e.g. the square [0, 1] and a sequence of T-points t = (t1,.., tT), and gives either a sequence of locations z [0, 1] 2T on a path from s to g at any time ti, or \"no-path-found.\" The planner operates by being a rapidly exploring random tree (RRT, 1998) from the starting point to the fulfillment of the space between the goal and the search for a clear line."}, {"heading": "3 INFERENCE IN PROBABILISTIC PROGRAMS WITH LIKELIHOOD-FREE PRIMITIVES", "text": "We assume that the planner is implemented either in a probable programming language or by treating the planner as a primitive random choice. We treat the planner as a random choice, as this allows the use of an optimized C implementation of the planner. However, probable programming languages such as Church, Stan, BLOG and Figaro require all random choices to have tractable marginal choices., 2012; Carpenter et al., 2016; Milch et al., 2007; Pfeffer, 2009] Calculation of the marginal choices of the AGENT-PATH for outputs z and M, s, g, and t would provide an intractable intregral via the (thousands of) internal random choices in AGENT-PATH.This section presents two strategies for influencing probability programs that include random choices."}, {"heading": "3.1 CASCADING RESIMULATION METROPOLIS-HASTINGS", "text": "How can a probability program deal with complex, probability-free choices? Our core finding is that if the proposed distribution m (z'i; \u00b7) for a random choice (z'i) is the same as the previous one (z'i), then the probability looks like this: a (prototypical) acceptance rate is cancelled in a Metropolis-Hastings (MH) and therefore does not need to be calculated explicitly."}, {"heading": "3.2 NESTED INFERENCE METROPOLIS-HASTINGS", "text": "For these problems and for real-time applications, we propose an alternative Metropolis-Hastings algorithm that uses probability values for internal random decisions after a probable free choice (e.g. a randomized planning algorithm) (e.g. x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "3.2.1 Nested Inference Metropolis-Hastings", "text": "It is assumed that all children of i also made random decisions themselves. (I, E) Proposed random decisions are also possible. (Z) Proposed random decisions for all random decisions. (Z) Proposed random decisions. (Z) Proposed random decisions. (Z) Proposed random decisions. (Z) Proposed random decisions. (Z) Proposed random decisions. (Z) Proposed random decisions. (Z) Proposed random decisions. (Z) Proposed random decisions. (Z) Proposed random decisions. (Z) Proposed random decisions. (Z) Proposed. (Z) Proposed. (Z) Proposed. (Z) Proposed. (Z) Proposed."}, {"heading": "3.2.2 Learning a nested inference algorithm", "text": "It is possible to learn a nested inference algorithm qt (u; x, z) that approximates pt (u | z; x). The idea of oflected inference for probabilistic generative models goes back at least to Morris [2001] and was also used in Stuhlm\u00fcller et al. [2013] and Kingma and Welling [2013]. We apply this idea to nested inference as follows: Let qt, \u03b8 (u; x, z) denote a nested inference algorithm that is parameterized by \u03b8 - for example, the weights of a neural network used as part of the inference algorithm. We establish a training distribution dt (x) via the arguments for the primitive t and approximately solve the following optimization problem: Minimum du ()."}, {"heading": "4 EXAMPLE APPLICATIONS", "text": "We have implemented four sample applications to illustrate the flexibility of our framework: 1. Inferring the likely destination of a simulated drone with a more complex planner. This example shows that small changes in the environment, such as the inclusion of an additional door opening, can lead to major changes in the derived objectives. 2. Inferring the likely destination of a simulated drone with a more complex planner. Specifically, we model the drone to follow a multi-part path created by a planner who first randomly selects a waypoint and then recursively solves the two planning problems caused by the choice of the waypoint. This example shows (a) the applicability of the framework to more complex models of targeted behavior, and (b) that nested inference MH can outperform a learned neural network cascading resimulation MH.3."}, {"heading": "4.1 EXAMPLE 1: SENSITIVITY OF GOAL INFERENCE TO SMALL MAP CHANGES", "text": "Figure 2 shows a comparison of the gate conclusions in two different maps taking into account the same observations. The map of the scenario on the left shows an enclosure with two openings, one above and one below, while the map of the scenario on the right shows a single opening. In the map on the left, the derived door samples fall outside the enclosure, because if the drone had intended to enter the enclosure, it could have taken a much shorter path. In the map on the right, there is a significant fraction of the door samples inside the enclosure, as relatively efficient paths into the enclosure go through the partial orbit observed so far. The samples shown are the final states of 480 independent replicas of a Markov chain initialized from the previous one, with 1000 cascading resistance transitions MH (algorithm 2) using the previous ones as a suggestion. Planner parameters are R = 10, N = 0.01, J = 2000, S = 10000."}, {"heading": "4.2 EXAMPLE 2: HANDLING PATH PLANNERS WITH WAYPOINTS VIA", "text": "NESTED INFERENCENext 4 Pseudo-code for a probable free movement where the agent can select a waypoint and separately plan a path to the waypoint and a path from the waypoint to the destination (AGENTWAYPOINT-PATH, algorithm 4). In contrast to the simpler AGENT-PATH model, which typically consists of a small number of modes focusing on efficient routes from start to finish (AGENT-WAYPOINT-PATH), paths result that are unpredictable without the knowledge of the waypoint. Parameters R and N of the PLAN-PATH are ignored for simplicity. We consider the same target task as in Example 1, but with the alternative planner. Cascading Resimulation MH shapes this task badly because the previous proposal is a bad suggestion for the internal random decisions of the AGENT-WAYPOT algorithm H.4."}, {"heading": "4.3 EXAMPLE 3: MODELING REAL-WORLD HUMAN MOTION", "text": "The Venture program in Figure 4 (c) defines a model with two agents whose destinations may or may not be the same. Environment (world) and starting points of the agents are known; the is _ common _ goal flag determines whether the agents share the same destination; the paths of both agents are modeled using AGENT-PATH; the corresponding Bayesian network is shown in Figure 4 (e); we collected videos of two collaborators walking in a scene with tables, for two conditions - one in which they meet in a common place, and one in which they differ; for the frequent condition, we constructed short and extended sequences of observed locations (Figure 4 (a) and (b); we used Cascading Resimulation MH as a conclusion initialized from the previous one, with a common previous proposal on all the latent variables; we performed 60 chains of 200 transitions each, and calculated the final states in each figure by an average of 63 calibrations (the common calibration) for each of their ability (the average of each of each of the overlap)."}, {"heading": "5 DISCUSSION", "text": "This paper introduced a class of probabilistic programs for formulating goal conclusions as approximate conclusions in probabilistic generative models of goal-oriented behavior; the technical contributions are: (i) a probabilistic programming formulation that makes complex goal and map priorities easy to specify; (ii) the use of randomized path planning algorithms as the backbone of generative models; and (iii) the introduction of Monte Carlo techniques that can handle the insoluble probabilities of these path planners; the experiments showed that it is possible for short probabilistic programs to draw meaningful conclusions about goal-oriented behavior; from the standpoint of robotics, autonomous driving, or detection, the examples in this work are fairly predictive; further experiments are needed to explore the accuracy of approximate conclusions in these models, as well as the accuracy of the models themselves, especially in real-world problems; the probabilistic programming formulation makes it easy to examine variations of these models, and inferences in models."}, {"heading": "Acknowledgements", "text": "The authors thank Feras Saad for obtaining human judgement data. 3D models of trees and cars in numbers come from http: / / www.f-lohmueller.de / [Lohm\u00fcller, 2016] This research was supported by DARPA (PPAML program, contract number FA875014-2-0004), IARPA (research contract 2015 - 15061000003), the Office of Naval Research (research contract N000141310333), the Army Research Office (contract number W911NF-13-1-0212) and gifts from Analog Devices and Google. Marco Cusumano-Towner is supported by the Department of Defense (DoD) through the National Defense Science & Engineering Graduate Fellowship (NDSEG) program."}, {"heading": "A PLANNER DETAILS", "text": "We will now describe details of the scheduler omitted from the main text, including the procedures SIMPLIFY-PATH, REFINE-PATH and WALK-PATH defined in algorithm 6. Paths p are presented as a sequence of points, with lines connecting the dots. Path p begins with start s and ends with destination g. To be a valid path in relation to the map M, no point on the path must lie within an obstacle (polygon) of M (i.e. M.IS-VALID (pi)), and no line between two adjacent path points can cross an obstacle of M (i.e. M.CLEAR-LINE (pi, pi + 1). Algorithm 6 Further details of the AGENT-PATH model of target-directed behavior (pi)."}, {"heading": "30: d\u2190 d+ \u03b4", "text": "31: Return g. If you reach the goal, you stay forever 32: Procedure WALK-PATH (p, t, v) 33: for i \u2190 1 to T 34: zi \u2190 WALK-TO (p, ti, v) 35: Return z"}, {"heading": "B ADDITIONAL EXPERIMENTS", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "C NESTED INFERENCE DERIVATIONS", "text": "The variance of the probability forecast with K = 1 is: K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K ="}], "references": [{"title": "The pseudomarginal approach for efficient monte carlo computations", "author": ["Christophe Andrieu", "Gareth O Roberts"], "venue": "The Annals of Statistics,", "citeRegEx": "Andrieu and Roberts.,? \\Q2009\\E", "shortCiteRegEx": "Andrieu and Roberts.", "year": 2009}, {"title": "Particle markov chain monte carlo methods", "author": ["Christophe Andrieu", "Arnaud Doucet", "Roman Holenstein"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Andrieu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Andrieu et al\\.", "year": 2010}, {"title": "Perception for collision avoidance and autonomous driving", "author": ["Romuald Aufr\u00e8re", "Jay Gowdy", "Christoph Mertz", "Chuck Thorpe", "Chieh-Chih Wang", "Teruko Yata"], "venue": null, "citeRegEx": "Aufr\u00e8re et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Aufr\u00e8re et al\\.", "year": 2003}, {"title": "Goal inference as inverse planning", "author": ["Chris L Baker", "Joshua B Tenenbaum", "Rebecca R Saxe"], "venue": "In Proceedings of the Cognitive Science Society,", "citeRegEx": "Baker et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Baker et al\\.", "year": 2007}, {"title": "Estimation of population growth or decline in genetically monitored populations", "author": ["Mark A Beaumont"], "venue": "Genetics, 164(3):1139\u20131160,", "citeRegEx": "Beaumont.,? \\Q2003\\E", "shortCiteRegEx": "Beaumont.", "year": 2003}, {"title": "Stan: A probabilistic programming language", "author": ["Bob Carpenter", "Andrew Gelman", "Matt Hoffman", "Daniel Lee", "Ben Goodrich", "Michael Betancourt", "Michael A Brubaker", "Jiqiang Guo", "Peter Li", "Allen Riddell"], "venue": "Journal of Statistical Software,", "citeRegEx": "Carpenter et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Carpenter et al\\.", "year": 2016}, {"title": "Autonomous driving goes downtown", "author": ["Uwe Franke", "Dariu Gavrila", "Steffen Gorzig", "Frank Lindner", "F Puetzold", "Christian Wohler"], "venue": "IEEE Intelligent Systems and Their Applications,", "citeRegEx": "Franke et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Franke et al\\.", "year": 1998}, {"title": "Church: a language for generative models", "author": ["Noah Goodman", "Vikash Mansinghka", "Daniel M Roy", "Keith Bonawitz", "Joshua B Tenenbaum"], "venue": "arXiv preprint arXiv:1206.3255,", "citeRegEx": "Goodman et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Goodman et al\\.", "year": 2012}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "Kingma and Welling.,? \\Q2013\\E", "shortCiteRegEx": "Kingma and Welling.", "year": 2013}, {"title": "On information and sufficiency", "author": ["Solomon Kullback", "Richard A Leibler"], "venue": "The annals of mathematical statistics,", "citeRegEx": "Kullback and Leibler.,? \\Q1951\\E", "shortCiteRegEx": "Kullback and Leibler.", "year": 1951}, {"title": "Opportunities and challenges with autonomous micro aerial vehicles", "author": ["Vijay Kumar", "Nathan Michael"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "Kumar and Michael.,? \\Q2012\\E", "shortCiteRegEx": "Kumar and Michael.", "year": 2012}, {"title": "Rapidly-exploring random trees: A new tool for path planning", "author": ["Steven M LaValle"], "venue": null, "citeRegEx": "LaValle.,? \\Q1998\\E", "shortCiteRegEx": "LaValle.", "year": 1998}, {"title": "Location-based activity recognition", "author": ["Lin Liao", "Dieter Fox", "Henry Kautz"], "venue": null, "citeRegEx": "Liao et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Liao et al\\.", "year": 2006}, {"title": "Venture: a higher-order probabilistic programming platform with programmable inference", "author": ["Vikash Mansinghka", "Daniel Selsam", "Yura Perov"], "venue": "arXiv preprint arXiv:1404.0099,", "citeRegEx": "Mansinghka et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mansinghka et al\\.", "year": 2014}, {"title": "blog: Probabilistic models with unknown objects", "author": ["Brian Milch", "Bhaskara Marthi", "Stuart Russell", "David Sontag", "Daniel L Ong", "Andrey Kolobov"], "venue": "Statistical relational learning,", "citeRegEx": "Milch et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Milch et al\\.", "year": 2007}, {"title": "Recognition networks for approximate inference in bn20 networks. In Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence, pages 370\u2013377", "author": ["Quaid Morris"], "venue": null, "citeRegEx": "Morris.,? \\Q2001\\E", "shortCiteRegEx": "Morris.", "year": 2001}, {"title": "On the chi square and higher-order chi distances for approximating fdivergences", "author": ["Frank Nielsen", "Richard Nock"], "venue": "IEEE Signal Processing Letters,", "citeRegEx": "Nielsen and Nock.,? \\Q2014\\E", "shortCiteRegEx": "Nielsen and Nock.", "year": 2014}, {"title": "Figaro: An object-oriented probabilistic programming language. Charles River Analytics", "author": ["Avi Pfeffer"], "venue": "Technical Report,", "citeRegEx": "Pfeffer.,? \\Q2009\\E", "shortCiteRegEx": "Pfeffer.", "year": 2009}, {"title": "Learning stochastic inverses", "author": ["Andreas Stuhlm\u00fcller", "Jacob Taylor", "Noah Goodman"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Stuhlm\u00fcller et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Stuhlm\u00fcller et al\\.", "year": 2013}, {"title": "Event modeling and recognition using markov logic networks", "author": ["Son Tran", "Larry Davis"], "venue": "Computer vision\u2013 ECCV", "citeRegEx": "Tran and Davis.,? \\Q2008\\E", "shortCiteRegEx": "Tran and Davis.", "year": 2008}, {"title": "Lightweight implementations of probabilistic programming languages via transformational compilation", "author": ["David Wingate", "Andreas Stuhlm\u00fcller", "Noah D Goodman"], "venue": "In AISTATS,", "citeRegEx": "Wingate et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wingate et al\\.", "year": 2011}, {"title": "Planning-based prediction for pedestrians", "author": ["Brian D Ziebart", "Nathan Ratliff", "Garratt Gallagher", "Christoph Mertz", "Kevin Peterson", "J Andrew Bagnell", "Martial Hebert", "Anind K Dey", "Siddhartha Srinivasa"], "venue": "In Intelligent Robots and Systems,", "citeRegEx": "Ziebart et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Ziebart et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 6, "context": "These problems are central to autonomous driving and driver assistance [Franke et al., 1998; Urmson et al., 2008; Aufr\u00e8re et al., 2003], but also arise in aerial robotics, reconnaissance, and security applications [Kumar and Michael, 2012; Liao et al.", "startOffset": 71, "endOffset": 135}, {"referenceID": 2, "context": "These problems are central to autonomous driving and driver assistance [Franke et al., 1998; Urmson et al., 2008; Aufr\u00e8re et al., 2003], but also arise in aerial robotics, reconnaissance, and security applications [Kumar and Michael, 2012; Liao et al.", "startOffset": 71, "endOffset": 135}, {"referenceID": 10, "context": ", 2003], but also arise in aerial robotics, reconnaissance, and security applications [Kumar and Michael, 2012; Liao et al., 2006; Tran and Davis, 2008].", "startOffset": 86, "endOffset": 152}, {"referenceID": 12, "context": ", 2003], but also arise in aerial robotics, reconnaissance, and security applications [Kumar and Michael, 2012; Liao et al., 2006; Tran and Davis, 2008].", "startOffset": 86, "endOffset": 152}, {"referenceID": 19, "context": ", 2003], but also arise in aerial robotics, reconnaissance, and security applications [Kumar and Michael, 2012; Liao et al., 2006; Tran and Davis, 2008].", "startOffset": 86, "endOffset": 152}, {"referenceID": 3, "context": "Most existing work along these lines has focused on modeling goal-directed behavior using Markov decision processes and related approaches from stochastic control [Baker et al., 2007; Ziebart et al., 2009].", "startOffset": 163, "endOffset": 205}, {"referenceID": 21, "context": "Most existing work along these lines has focused on modeling goal-directed behavior using Markov decision processes and related approaches from stochastic control [Baker et al., 2007; Ziebart et al., 2009].", "startOffset": 163, "endOffset": 205}, {"referenceID": 11, "context": "The planner operates by growing a rapidly-exploring random tree (RRT) [LaValle, 1998] from the start location s to fill the space, searching for a clear line of sight between the tree and the goal.", "startOffset": 70, "endOffset": 85}, {"referenceID": 13, "context": "Figure 2 and Figure 4 show this planner being used as a modeling primitive in the Venture probabilistic programming platform [Mansinghka et al., 2014].", "startOffset": 125, "endOffset": 150}, {"referenceID": 7, "context": "However, probabilistic programming languages such as Church, Stan, BLOG, and Figaro all require random choices to have tractable marginal likelihoods [Goodman et al., 2012; Carpenter et al., 2016; Milch et al., 2007; Pfeffer, 2009].", "startOffset": 150, "endOffset": 231}, {"referenceID": 5, "context": "However, probabilistic programming languages such as Church, Stan, BLOG, and Figaro all require random choices to have tractable marginal likelihoods [Goodman et al., 2012; Carpenter et al., 2016; Milch et al., 2007; Pfeffer, 2009].", "startOffset": 150, "endOffset": 231}, {"referenceID": 14, "context": "However, probabilistic programming languages such as Church, Stan, BLOG, and Figaro all require random choices to have tractable marginal likelihoods [Goodman et al., 2012; Carpenter et al., 2016; Milch et al., 2007; Pfeffer, 2009].", "startOffset": 150, "endOffset": 231}, {"referenceID": 17, "context": "However, probabilistic programming languages such as Church, Stan, BLOG, and Figaro all require random choices to have tractable marginal likelihoods [Goodman et al., 2012; Carpenter et al., 2016; Milch et al., 2007; Pfeffer, 2009].", "startOffset": 150, "endOffset": 231}, {"referenceID": 20, "context": "Following Wingate et al. [2011], for a probabilistic program P , we assume there is a name i \u2208 I assigned to every possible random choice, for some countable I.", "startOffset": 10, "endOffset": 32}, {"referenceID": 20, "context": "Relaxations of this are left for future work; more general formalizations of probabilistic programs can be found in [Wingate et al., 2011; Mansinghka et al., 2014].", "startOffset": 116, "endOffset": 163}, {"referenceID": 13, "context": "Relaxations of this are left for future work; more general formalizations of probabilistic programs can be found in [Wingate et al., 2011; Mansinghka et al., 2014].", "startOffset": 116, "endOffset": 163}, {"referenceID": 16, "context": "where D\u03c72 denotes the chi-square divergence [Nielsen and Nock, 2014], and where pt(u|z;x) and qt(u;x, z) on the right-hand side represent density functions over u, not specific density values.", "startOffset": 44, "endOffset": 68}, {"referenceID": 9, "context": "where DKL denotes the Kullback-Leibler (KL) divergence [Kullback and Leibler, 1951].", "startOffset": 55, "endOffset": 83}, {"referenceID": 0, "context": "Our use of unbiased likelihood estimates in place of the true likelihoods when computing the MetropolisHastings acceptance ratio in Algorithm 3 is closely related to pseudo-marginal MCMC [Andrieu and Roberts, 2009] and particle MCMC [Andrieu et al.", "startOffset": 187, "endOffset": 214}, {"referenceID": 1, "context": "Our use of unbiased likelihood estimates in place of the true likelihoods when computing the MetropolisHastings acceptance ratio in Algorithm 3 is closely related to pseudo-marginal MCMC [Andrieu and Roberts, 2009] and particle MCMC [Andrieu et al., 2010].", "startOffset": 233, "endOffset": 255}, {"referenceID": 4, "context": "Indeed, each single-site Nested Inference MH transition can be seen as a compositional variant of a \u2018grouped independence MH\u2019 transition [Beaumont, 2003] in which several pseudo-marginal likelihoods (one for each random choice j \u2208 {i} \u222a cG(i)) are used in the same update.", "startOffset": 137, "endOffset": 153}, {"referenceID": 14, "context": "The idea of learned inference for probabilistic generative models goes back at least to Morris [2001] and has also been used in Stuhlm\u00fcller et al.", "startOffset": 88, "endOffset": 102}, {"referenceID": 14, "context": "The idea of learned inference for probabilistic generative models goes back at least to Morris [2001] and has also been used in Stuhlm\u00fcller et al. [2013] and Kingma and Welling [2013].", "startOffset": 88, "endOffset": 154}, {"referenceID": 8, "context": "[2013] and Kingma and Welling [2013]. We apply this idea to nested inference as follows.", "startOffset": 11, "endOffset": 37}], "year": 2017, "abstractText": "Intelligent systems sometimes need to infer the probable goals of people, cars, and robots, based on partial observations of their motion. This paper introduces a class of probabilistic programs for formulating and solving these problems. The formulation uses randomized path planning algorithms as the basis for probabilistic models of the process by which autonomous agents plan to achieve their goals. Because these path planning algorithms do not have tractable likelihood functions, new inference algorithms are needed. This paper proposes two Monte Carlo techniques for these \u201clikelihood-free\u201d models, one of which can use likelihood estimates from neural networks to accelerate inference. The paper demonstrates efficacy on three simple examples, each using under 50 lines of probabilistic code.", "creator": "LaTeX with hyperref package"}}}