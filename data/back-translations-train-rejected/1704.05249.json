{"id": "1704.05249", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Apr-2017", "title": "Hot or not? Forecasting cellular network hot spots using sector performance indicators", "abstract": "To manage and maintain large-scale cellular networks, operators need to know which sectors underperform at any given time. For this purpose, they use the so-called hot spot score, which is the result of a combination of multiple network measurements and reflects the instantaneous overall performance of individual sectors. While operators have a good understanding of the current performance of a network and its overall trend, forecasting the performance of each sector over time is a challenging task, as it is affected by both regular and non-regular events, triggered by human behavior and hardware failures. In this paper, we study the spatio-temporal patterns of the hot spot score and uncover its regularities. Based on our observations, we then explore the possibility to use recent measurements' history to predict future hot spots. To this end, we consider tree-based machine learning models, and study their performance as a function of time, amount of past data, and prediction horizon. Our results indicate that, compared to the best baseline, tree-based models can deliver up to 14% better forecasts for regular hot spots and 153% better forecasts for non-regular hot spots. The latter brings strong evidence that, for moderate horizons, forecasts can be made even for sectors exhibiting isolated, non-regular behavior. Overall, our work provides insight into the dynamics of cellular sectors and their predictability. It also paves the way for more proactive network operations with greater forecasting horizons.", "histories": [["v1", "Tue, 18 Apr 2017 09:34:48 GMT  (336kb,D)", "http://arxiv.org/abs/1704.05249v1", "Accepted for publication at ICDE 2017 - Industrial Track"]], "COMMENTS": "Accepted for publication at ICDE 2017 - Industrial Track", "reviews": [], "SUBJECTS": "cs.LG cs.NI cs.SY", "authors": ["joan serr\\`a", "ilias leontiadis", "alexandros karatzoglou", "konstantina papagiannaki"], "accepted": false, "id": "1704.05249"}, "pdf": {"name": "1704.05249.pdf", "metadata": {"source": "CRF", "title": "Hot or not? Forecasting cellular network hot spots using sector performance indicators", "authors": ["Joan Serr\u00e0", "Ilias Leontiadis", "Alexandros Karatzoglou", "Konstantina Papagiannaki"], "emails": ["firstname.lastname@telefonica.com"], "sections": [{"heading": null, "text": "In fact, most of them are able to survive on their own if they do not play by the rules they have set themselves."}, {"heading": "II. DATA DESCRIPTION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Notation", "text": "We use lowercase italics for individual numbers (e.g. q), lowercase letters bold for one-dimensional vectors (e.g. q), uppercase letters bold for two-dimensional matrices (e.g. Q), bold calligraphy for higher-dimensional arrays or tensors (e.g. Q), and colons for discs across dimensions (e.g. Qi, 1: 24,:). A quick guide to the mathematical variables and functions used can be found in Table I."}, {"heading": "B. From key performance indicators to the hot spot score", "text": "It is important that the number of users waiting for a resource is recorded by a top-tier mobile operator from an entire European country with more than 10 million subscribers. (The indicators used correspond to the results of 3G sectors and were not explicitly shown on the basis of both internal1We whether the number of services in the papers is higher for proprietary reasons. (However, our observations and conclusions are still fully supported by the reported results.) We can group such KPIs into the following classes: reporting (e.g. radio interference, noise levels, performance characteristics), accessibility (e.g. the establishment of a voice or data channel, allocation of high-speed data channels), availability (e.g. handovers' success rate), availability and transmission time (e.g. number of transmission time intervals, number of waiting times for a resource, free channels)."}, {"heading": "C. Dealing with missing values", "text": "Unfortunately, KPIs are not always present for every sector, every hour and every indicator, which can be due to several reasons, including cases where the page was offline, the backbone was overloaded (priority is given to the customer's data), the collection server was overloaded afterwards, or the probes failed. Generally, we find missing values for a particular sector, an hour and a KPI (Ki, j, k), for cuts over indicators of a specific sector and an hour (Ki, j,:), and for cuts over time and indicators for a specific sector (Ki, j: j + t,:). To deal with missing values, we proceed in two steps. First, we perform a sector filtering operation, discarding a sector i if it has more than 50% of the missing values in one or more weeks, i.e. if1 j + y."}, {"heading": "III. HOT SPOT DYNAMICS", "text": "Before making the actual predictions, we want to justify their feasibility and learn about the data by taking a closer look at their dynamics. In the previous sections, we have already shown examples of voice-based and data-based KPIs (fig. 1). We will now focus on the hotspot labels Yh and Yd, and show some of their aggregated patterns (fig. 2 and 3). First, we can study the number of hours that a particular sector claims as a hotspot (fig. 6), so that we can empirically find a threshold of 16 hours that matches an 8-hour sleep pattern. We can study the number of hours that a particular sector remains as a hotspot (fig. 6)."}, {"heading": "IV. HOT SPOT FORECASTING", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Methodology", "text": "As already mentioned, we want to use the KPI information to predict whether a sector will be a hotspot or not. As the main target for prediction is intervention, and such interventions cannot typically be made \"in the hour\" by operators, we will also work with the daily resolution. Therefore, our target variables will be the binary labels Yd, which correspond to the term \"a hotspot\" on a given day (Sec. II-B). In addition to this goal, we will also consider the \"become a hotspot\" target. Taking this second target into account will allow us to go a step further and examine the behavior of our methods on an important subset of sectors: those that were not hotspots for a period but became hotspots for the next few days. To achieve the \"hot spot target,\" we take weekly averages of daily results before and after each given day j, thresholds and throwaway consequent activations."}, {"heading": "B. Evaluation measures", "text": "The evaluation is done with the probabilities Y:, t + h and the binary variables Y:, t + h. In essence, we want to obtain a ranking of the available sectors using the probabilities Y:, t + h (maximum values first), with the uppermost sectors corresponding to the true hotspot sectors i, which are called Yi, t + h = 1. This corresponds to a classic information retrieval task, where relevant documents for a given query must come first in the provided answer [20]. Therefore, we can use classic and known information retrieval measures. In particular, we work with precision curves and average precision measurement [20]. However, since both are sensitive to the number of positive instances and can therefore give a rough estimate of the total number of hotspots that we cannot show, we will report lift values relative to random performance [19] here. On the basis of this sensitivity, both measures are always evaluated in terms of random performance [20].The value of a model of the elevator is equal to the one of the model of the i that i is equal."}, {"heading": "C. Forecast models \u2013 Baselines", "text": "Random Model: We measure random power using Y-i, t + h = G (0, 1), where G (x, y) is a uniform random generator for real numbers, so that x-i (x, y) \u2264 y. This will be our F-0 model. As already mentioned, the results of this model will give us an indication of the random level. Persistent Model: Another trivial model that can be used as a starting point for any prediction task is the persistence model [18]. This model will only use the current value of the soil truth variable to make a prediction: Y-i, t + h = Yi, t. This model can actually provide very good predictions in situations where the variable Y occurs in outbreaks or does not change much over time [16]. The results of this model thus give us an indication of how consistent the signal we are in the short-term forecast is: the Y-oscillating value and not the short-term Soscillating value."}, {"heading": "D. Forecast models \u2013 Classifiers", "text": "This year, it is more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, in which it is a country, in which it is a region and in which it is a country."}, {"heading": "E. Tasks\u2019 summary", "text": "With t we want to investigate the power variability in relation to time, with h we want to investigate how far into the future we can make a reliable prediction, with w we want to investigate how much information from the past we need to take into account in order to make such predictions. Overall, we have a number of combinations between these four most important variables of interest (Table III)."}, {"heading": "V. FORECASTING RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Temporal stability", "text": "The first aspect we consider is the dependence of the results on the day of our analysis. Specifically, with a combination of model, h and w, we assess whether there are significant power fluctuations in t. To this end, we perform a statistical hypotheses test to quantify differences in power distributions obtained for different periods of time. First, we create two equally large slices of the variables t: [52, 69] and t: [70, 87]. Next, we take the average precision values corresponding to the two slices, and perform a Kolmogorov-Smirnov test on two samples [26]. The KolmogorovSmirnov test is a non-parametric test for the equality of continuous, one-dimensional probability distributions that are sensitive to differences both in the location and in the form of empirical cumulative distribution. It can be used to compare a sample with a probability distribution, or in our case."}, {"heading": "B. Prediction horizon", "text": "We focus on the performance of the models as a function of the predictive horizon h (fig. 9). First, we confirm that the random model has an elevator that lasts 12 days as expected. Next, we observe that the persist and trend models perform much less well than the rest. Interestingly, for the persist model, we observe two peaks in weekly regularity that are ahead of today's peaks for 7 and 14 days (e.g., if today is a Saturday that predicts the same label for the next Saturday). This result stems from the weekly regularities observed in sec. III. Another indication of weekly regularities is in the peaks of the trend model that occur at h = 8, 16, 22 and 29 days. The fact that they occur at multiples of 7 plus one day, as we have seen for the next day, makes perfect sense: a trend forms a projection for the next day while persist works."}, {"heading": "C. Past history", "text": "With only one day of past information (w = 1), the models are already able to make predictions that are almost 10 times better than random. This performance is increased to w = 7 (one week), where it reaches a plateau with the maximum lift. A similar situation occurs with the prediction \"to a hotspot\" (Fig. 14). In this case, however, the performance for w > 7 decreases slightly and usually reaches a plateau for w \u2265 10 days. Here, we also find that the effect of w for large horizons h is much less pronounced, as it practically does not exist for h = 16 or h = 26 days. Nevertheless, the latter shows a minimal but consistent increase with w. This could be an indication that with much more data and a machine learning algorithm that can handle high dimensions, we could potentially improve our lift numbers for long time horizons."}, {"heading": "D. Features\u2019 importance", "text": "We conclude our part of the results with a look at the relative importance of KPIs for predicting hot spots (Fig. 15). We find that the most important feature is the weekly hotnessscore Sw (k = 29), and that its importance increases with j, i.e. that we move closer to the present. However, we cannot integrate much temporal information (j < 25), whereas the contribution of the hourly score Sh (k = 27) is scattered along the timeline."}, {"heading": "VI. RELATED WORK", "text": "The only exception might be the work of Nika et al. [6], where a dataset with more than 700K users is analyzed to understand the temporal properties of data hotspots. Predictability is evaluated, but taking into account repetitions of hotspots in the exact time and location in the coming week. However, we note that the focus of the work is not on performance, but on load, with hotspots being defined on the basis of relative daily cell traffic. A few other research papers have been written in an attempt to understand how the load in cell networks develops. For example, Paul et al. [28] analyzed the spatio-temporal behavior of network resource use in a real 3G network. Interestingly, their results suggest that aggregated network use exhibits periodic behavior, but individual sectors do not exhibit such characteristics (but in [29], Jiang aldo we find such cell networks in correlations investigated)."}, {"heading": "VII. CONCLUSION", "text": "To the best of our knowledge, this is the first work to provide an in-depth analysis of the dynamics of hot spots in mobile networks. We have done this by considering a large dataset of real-world hourly measured KPIs covering tens of thousands of sectors of a high-level mobile network operator over a four-month period. We have examined both temporal and spatial regularities present in our dataset, and identified prominent hourly, daily and weekly patterns. We have also provided a formal methodology to project such patterns into the future and perform predictions of hot spots in mobile networks. We have considered a variety of base and tree models, assessing their accuracy as a function of time, predictive horizon and amount of information needed in the past. Overall, we have gained insights into the dynamics of mobile sectors and the predictability of their sub-average situations, paving the way for more proactive network operations."}], "references": [{"title": "Robust assessment of changes in cellular networks", "author": ["A. Mahimkar", "Z. Ge", "J. Yates", "C. Hristov", "V. Cordaro", "S. Smith", "J. Xu", "M. Stockert"], "venue": "Proc. of the ACM Conf. on Emerging Networking Experiments and Technologies (CoNEXT), 2013, pp. 175\u2013186.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Fundamentals of Cellular Network Planning and Optimisation: 2G/2.5G/3G.", "author": ["A.R. Mishra"], "venue": "Evolution to 4G. Hoboken,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2004}, {"title": "Radio Network Planning and Optimisation for UMTS", "author": ["J. Laiho"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Gaenger, Key Performance Indicators and Measurements for LTE Radio Network Optimization", "author": ["K.R. Kreher"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "WCDMA: KPI analysis & optimization", "author": ["N. Agarwal"], "venue": "Nokia Technologies Co., Ltd., 2008.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Understanding data hotspots in cellular networks", "author": ["A. Nika", "A. Ismail", "B.Y. Zhao", "S. Gaito", "G.P. Rossi", "H. Zheng"], "venue": "Proc. of the Int. Conf. on Heterogeneous Networking for Quality, Reliability, Security and Robustness (QShine), 2014, pp. 70\u201376.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "GSM KPI monitoring and improvement guide", "author": ["X. Kaiping", "G. Hao"], "venue": "Huawei Technologies Co., Ltd., 2008.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Stochastic forecasts achieve high throughput and low delay over cellular networks", "author": ["K. Winstein", "A. Sivaraman", "H. Balakrishnan"], "venue": "Proc. of the USENIX Symp. on Networked Systems Design and Implementation (NSDI), 2013, pp. 459\u2013471. [Online]. Available: https://www.usenix. org/conference/nsdi13/technical-sessions/presentation/winstein", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "LTE Self-Organising Networks (SON): Network Management Automation for Operational Efficiency, 1st ed", "author": ["S. Hmlinen", "H. Sanneck", "C. Sartori"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion", "author": ["P. Vincent", "H. Larochelle", "I. Lajoie", "Y. Bengio", "P.-A. Manzagol"], "venue": "Journal of Machine Learning Research, vol. 11, pp. 3371\u20133408, 2010.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Delving deep into rectifiers: surpassing human-level performance on ImageNet classification", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "Proc. of the IEEE Int. Conf. on Computer Vision (ICCV), 2015, pp. 1026\u20131034.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude", "author": ["T. Tieleman", "G. Hinton"], "venue": "COURSERA: Neural Networks for Machine Learning 4, 2, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Predicting land use allocation in France: a spatial panel data analysis", "author": ["R. Chakir", "J. Le Gallo"], "venue": "Ecological Economics, vol. 92, pp. 114\u2013125, 2012.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Characterization of non-urbanized areas for land-use planning of agricultural and green infrastructure in urban contexts", "author": ["D. La Rosa", "R. Privitera"], "venue": "Landscape and Urban Planning, vol. 109, pp. 94\u2013106, 2013.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Nonlinear time series analysis", "author": ["H. Kantz", "T. Schreiber"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2004}, {"title": "On the mean accuracy of statistical pattern recognizers", "author": ["G.F. Hughes"], "venue": "IEEE Trans. on Information Theory, vol. 14, no. 1, pp. 55\u201363, 1968.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1968}, {"title": "Forecasting: principles and practice", "author": ["R. Hyndman", "G. Athanasopoulos"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "The elements of statistical learning, 2nd ed", "author": ["T. Hastie", "R. Tibshirani", "J. Friedman"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "Classification and regression trees", "author": ["L. Breiman", "J. Friedman"], "venue": "Monterey, USA: Chapman and Hall/CRC,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1984}, {"title": "Scikit-learn: machine learning in python", "author": ["F. Pedregosa", "G. Varoquaux", "A. Gramfort", "V. Michel", "B. Thirion", "O. Grisel", "M. Blondel", "P. Prettenhofer", "R. Weiss", "V. Dubourg", "J. Vanderplas", "A. Passos", "D. Cournapeau", "M. Brucher", "M. Perrot", "E. Duchesnay"], "venue": "Journal of Machine Learning Research, vol. 12, pp. 2825\u20132830, 2011.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Random decision forests", "author": ["T.K. Ho"], "venue": "Proc. of the Int. Conf. on Document Analysis and Recognition (ICDAR), 1995, pp. 278\u2013282.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1995}, {"title": "Random forests", "author": ["L. Breiman"], "venue": "Machine Learning, vol. 45, no. 1, pp. 5\u201332, 2001.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2001}, {"title": "Bagging predictors", "author": ["\u2014\u2014"], "venue": "Machine Learning, vol. 24, no. 2, pp. 123\u2013 140, 1996.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1996}, {"title": "Nonparametric statistical methods, 2nd ed", "author": ["M. Hollander", "D.A. Wolfe"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1999}, {"title": "Simultaneous statistical inference", "author": ["R.G. Miller"], "venue": "New York, USA: Springer-Verlag,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1981}, {"title": "Understanding traffic dynamics in cellular data networks", "author": ["U. Paul", "A.P. Subramanian", "M.M. Buddhikot", "S.R. Das"], "venue": "Proc. of the IEEE INFOCOM, 2011, pp. 882\u2013890.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "Correlating real-time monitoring data for mobile network management", "author": ["N. Jiang", "G. Jiang", "H. Chen", "K. Yoshihira"], "venue": "Proc. of the Int. Symp. on a World of Wireless, Mobile and Multimedia Networks (WoWMoM), 2008, pp. 1\u20138.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}, {"title": "Geospatial and temporal dynamics of application usage in cellular data networks", "author": ["M.Z. Shafiq", "L. Ji", "A.X. Liu", "J. Pang", "J. Wang"], "venue": "IEEE Trans. on Mobile Computing, vol. 14, no. 7, pp. 1369\u20131381, 2015.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Understanding the effects of hotspots in wireless cellular networks", "author": ["J. Jobin", "M. Faloutsos", "S.K. Tripathi", "S.V. Krishnamurthy"], "venue": "Proc. of the Joint Conf. of the IEEE Computer and Communications Societies (INFOCOM), vol. 1, 2004, pp. 671\u2013677.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2004}, {"title": "Forecasting network performance to support dynamic scheduling using the network weather service", "author": ["R. Wolski"], "venue": "Proc. of the Int. Symp. on High Performance Distributed Computing (HPDC), 1997, pp. 316\u2013 325.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1997}, {"title": "PROTEUS: Network performance forecast for real-time, interactive mobile applications", "author": ["Q. Xu", "S. Mehrotra", "Z.M. Mao", "J. Li"], "venue": "Proc. of the ACM Int. Conf. in Mobile Systems, Applications, and Services (MobiSys), 2013, pp. 347\u2013360. [Online]. Available: http://research.microsoft.com/apps/pubs/default.aspx?id=191172", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}, {"title": "Predicting execution bottlenecks in map-reduce clusters", "author": ["E. Bortnikov", "A. Frank", "E. Hillel", "S. Rao"], "venue": "Proc. of the USENIX Conference on Hot Topics in Cloud Computing (HotCloud), 2012, pp. 18\u201318. [Online]. Available: http://dl.acm.org/citation.cfm?id=2342763.2342781", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "The performance of a cellular network is dynamic; it changes with time, affected by internal and external factors, including hardware and software failures, human behavior, weather conditions, and seasonal changes [1].", "startOffset": 214, "endOffset": 217}, {"referenceID": 1, "context": "Operators make huge investments to accurately monitor and understand performance dynamics, as they are key to cellular networks\u2019 management, planning [2], and optimization [3].", "startOffset": 150, "endOffset": 153}, {"referenceID": 2, "context": "Operators make huge investments to accurately monitor and understand performance dynamics, as they are key to cellular networks\u2019 management, planning [2], and optimization [3].", "startOffset": 172, "endOffset": 175}, {"referenceID": 3, "context": "KPIs provide insights about each cellular sector over a certain time window, typically on the order of minutes or hours [4].", "startOffset": 120, "endOffset": 123}, {"referenceID": 4, "context": "To facilitate their analysis, operators combine the available KPIs into a single metric that, besides capturing the overall sectors\u2019 \u2018health\u2019, can be used to rank them based on their performance over time [5]\u2013[7].", "startOffset": 205, "endOffset": 208}, {"referenceID": 6, "context": "To facilitate their analysis, operators combine the available KPIs into a single metric that, besides capturing the overall sectors\u2019 \u2018health\u2019, can be used to rank them based on their performance over time [5]\u2013[7].", "startOffset": 209, "endOffset": 212}, {"referenceID": 2, "context": "The methodology to combine KPIs into a single metric and the threshold to determine hot spots have been established over the years by vendors and the industry, based on domain knowledge, logical decisions, service level agreements, and controlled experiments [3].", "startOffset": 259, "endOffset": 262}, {"referenceID": 5, "context": "Not only because it provides knowledge about possible root causes of such hot spots [6], but also because it brings an intuition on how they will evolve over time.", "startOffset": 84, "endOffset": 87}, {"referenceID": 1, "context": "Being able to forecast hot spots would provide a number of advantages: (1) as investment plans are finalized weeks in advance, forecasting future demands would allow operators to optimize capex spending [2]; (2) short-term forecasting would allow operators to proactively troubleshoot their network [8]; (3) it would also allow to dynamically balance resources as an input to self-organizing networks [9].", "startOffset": 203, "endOffset": 206}, {"referenceID": 7, "context": "Being able to forecast hot spots would provide a number of advantages: (1) as investment plans are finalized weeks in advance, forecasting future demands would allow operators to optimize capex spending [2]; (2) short-term forecasting would allow operators to proactively troubleshoot their network [8]; (3) it would also allow to dynamically balance resources as an input to self-organizing networks [9].", "startOffset": 299, "endOffset": 302}, {"referenceID": 8, "context": "Being able to forecast hot spots would provide a number of advantages: (1) as investment plans are finalized weeks in advance, forecasting future demands would allow operators to optimize capex spending [2]; (2) short-term forecasting would allow operators to proactively troubleshoot their network [8]; (3) it would also allow to dynamically balance resources as an input to self-organizing networks [9].", "startOffset": 401, "endOffset": 404}, {"referenceID": 9, "context": "For that, we use a stacked denoising autoencoder [10].", "startOffset": 49, "endOffset": 53}, {"referenceID": 10, "context": "The encoder layers are dense layers of half of the size of their input, with parametric rectified linear units [12] as activation functions.", "startOffset": 111, "endOffset": 115}, {"referenceID": 11, "context": "After some experimentation, we train the autoencoder using RMSprop [13] for 1000 epochs of nmw/128 batches each, using a learning rate of 10\u22124 and a smoothing factor of 0.", "startOffset": 67, "endOffset": 71}, {"referenceID": 12, "context": "[14], [15]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14], [15]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 14, "context": "This intuitive statement has been formally confirmed in the literature for uncountable scenarios and information sources [16].", "startOffset": 121, "endOffset": 125}, {"referenceID": 15, "context": "Secondly, machine learning algorithms can suffer with an unreasonably high dimensionality, which can hamper their accuracy and interpretability [17].", "startOffset": 144, "endOffset": 148}, {"referenceID": 16, "context": "Thirdly, we do not dispose of infinite data, and we need to save part of it for testing/evaluation purposes [18].", "startOffset": 108, "endOffset": 112}, {"referenceID": 17, "context": "real-valued probability outputs [19].", "startOffset": 32, "endOffset": 36}, {"referenceID": 17, "context": "total number of hot spots, which we cannot reveal, we will here report lift values relative to random performance [19].", "startOffset": 114, "endOffset": 118}, {"referenceID": 16, "context": "Persist model: Another trivial model to use as baseline in any forecasting task is the persistence model [18].", "startOffset": 105, "endOffset": 109}, {"referenceID": 14, "context": "This model can actually provide very good forecasts in situations where the variable Y comes in bursts or does not change much with time [16].", "startOffset": 137, "endOffset": 141}, {"referenceID": 18, "context": "tree [21].", "startOffset": 5, "endOffset": 9}, {"referenceID": 17, "context": "Classification trees could be regarded as the \u2018offthe-shelf\u2019 procedure for classification, as they are invariant under scaling and other feature transformations, robust to the inclusion of irrelevant features, and produce interpretable models [19].", "startOffset": 243, "endOffset": 247}, {"referenceID": 17, "context": "There are several stopping criteria for the partitioning, as well as metrics to evaluate the best split point and feature [19].", "startOffset": 122, "endOffset": 126}, {"referenceID": 19, "context": "In our study, we employ the implementation in the scikit-learn package [22] (version 0.", "startOffset": 71, "endOffset": 75}, {"referenceID": 17, "context": "We use the Gini coefficient [19] as the split metric, and evaluate a random subset of 80% of the features at every partition of the tree.", "startOffset": 28, "endOffset": 32}, {"referenceID": 17, "context": "Random forest: It is well known however that classification and regression trees present a series of limitations, including local optimality effects and poor generalization capabilities [19].", "startOffset": 186, "endOffset": 190}, {"referenceID": 20, "context": "A classical approach to that is random forests [23].", "startOffset": 47, "endOffset": 51}, {"referenceID": 21, "context": "Random forests train a number of trees on randomized subsets of the available instances, using also a randomized subset of the features at each tree partition [24].", "startOffset": 159, "endOffset": 163}, {"referenceID": 22, "context": "Predictions can then be performed by, for instance, aggregating the class probabilities computed for each tree in a so-called bootstrap aggregating or bagging schema [25].", "startOffset": 166, "endOffset": 170}, {"referenceID": 21, "context": "However, at every partition, we now only evaluate a random subset of the features whose size cannot exceed the square root of the total number of input features [24].", "startOffset": 161, "endOffset": 165}, {"referenceID": 17, "context": "It is demonstrated that random forests can use deep decision trees without the risk of overfitting to the training data [19].", "startOffset": 120, "endOffset": 124}, {"referenceID": 21, "context": "Random forests lose a little bit of the interpretability of trees but, nonetheless, can be used to derive feature importances in an intuitive way [24].", "startOffset": 146, "endOffset": 150}, {"referenceID": 15, "context": "Random forest with percentile features: Despite the generalization and feature selection capabilities of a machine learning algorithm, it is well known that the total number [17] and the quality of such features is crucial to obtain accurate predictions [19].", "startOffset": 174, "endOffset": 178}, {"referenceID": 17, "context": "Random forest with percentile features: Despite the generalization and feature selection capabilities of a machine learning algorithm, it is well known that the total number [17] and the quality of such features is crucial to obtain accurate predictions [19].", "startOffset": 254, "endOffset": 258}, {"referenceID": 23, "context": "two-sample Kolmogorov-Smirnov test [26].", "startOffset": 35, "endOffset": 39}, {"referenceID": 24, "context": "This is strong evidence that the two distributions of average precision values \u03c8 do not present a significant difference, and the evidence becomes even stronger if we consider the effect of multiple comparisons [27].", "startOffset": 211, "endOffset": 215}, {"referenceID": 19, "context": "Finally, we find that the enhanced calendar information C (k \u2208 [22, 26]) has almost no contribution to the forecast.", "startOffset": 63, "endOffset": 71}, {"referenceID": 23, "context": "Finally, we find that the enhanced calendar information C (k \u2208 [22, 26]) has almost no contribution to the forecast.", "startOffset": 63, "endOffset": 71}, {"referenceID": 5, "context": "[6], where a data set with more than 700K users is analyzed to understand temporal characteristics of data hot spots.", "startOffset": 0, "endOffset": 3}, {"referenceID": 25, "context": "[28] analyzed the spatio-temporal behavior of network resource usage in a real 3G network.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "Interestingly, their results indicate that aggregate network usage exhibits periodic behavior, but individual sectors do not exhibit such properties (however, in [29], Jiang et al.", "startOffset": 162, "endOffset": 166}, {"referenceID": 27, "context": "[30].", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "Finally, simulation has been also used to quantify hot spots in wireless cellular networks [31].", "startOffset": 91, "endOffset": 95}, {"referenceID": 29, "context": "The network weather service [32] was one of the first systems to make predictions of TCP/IP throughput and latency.", "startOffset": 28, "endOffset": 32}, {"referenceID": 30, "context": "Another example is the Proteus [33] system, which uses regression trees to forecast short-term performance in cellular networks, with the objective to proactively adapt mobile application network patterns.", "startOffset": 31, "endOffset": 35}, {"referenceID": 7, "context": "Similarly, Sprout [8] attempts to predict immediate network load in cellular networks to optimize TCPlayer parameters.", "startOffset": 18, "endOffset": 21}, {"referenceID": 31, "context": "Finally, in [34], the authors use gradient boosted trees to forecast hot spots within a data center, in order to avoid stranglers and, therefore, speed up map-reduce computation.", "startOffset": 12, "endOffset": 16}], "year": 2017, "abstractText": "To manage and maintain large-scale cellular networks, operators need to know which sectors underperform at any given time. For this purpose, they use the so-called hot spot score, which is the result of a combination of multiple network measurements and reflects the instantaneous overall performance of individual sectors. While operators have a good understanding of the current performance of a network and its overall trend, forecasting the performance of each sector over time is a challenging task, as it is affected by both regular and non-regular events, triggered by human behavior and hardware failures. In this paper, we study the spatio-temporal patterns of the hot spot score and uncover its regularities. Based on our observations, we then explore the possibility to use recent measurements\u2019 history to predict future hot spots. To this end, we consider tree-based machine learning models, and study their performance as a function of time, amount of past data, and prediction horizon. Our results indicate that, compared to the best baseline, tree-based models can deliver up to 14% better forecasts for regular hot spots and 153% better forecasts for non-regular hot spots. The latter brings strong evidence that, for moderate horizons, forecasts can be made even for sectors exhibiting isolated, non-regular behavior. Overall, our work provides insight into the dynamics of cellular sectors and their predictability. It also paves the way for more proactive network operations with greater forecasting horizons.", "creator": "LaTeX with hyperref package"}}}