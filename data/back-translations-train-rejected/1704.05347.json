{"id": "1704.05347", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Apr-2017", "title": "Baselines and test data for cross-lingual inference", "abstract": "Research in natural language inference is currently exclusive to English. Here, we propose to advance toward multilingual evaluation. To that end, we provide test data for four major languages. We experiment with a set of baselines based on cross-lingual embeddings and machine translation. While our best system scores an average accuracy of just over 75%, we focus largely on enabling further research in multilingual inference.", "histories": [["v1", "Tue, 18 Apr 2017 14:12:37 GMT  (43kb,D)", "http://arxiv.org/abs/1704.05347v1", "Submitted for review at EMNLP 2017"]], "COMMENTS": "Submitted for review at EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["\\v{z}eljko agi\\'c", "natalie schluter"], "accepted": false, "id": "1704.05347"}, "pdf": {"name": "1704.05347.pdf", "metadata": {"source": "CRF", "title": "Baselines and test data for cross-lingual inference", "authors": ["\u017deljko Agi\u0107", "Natalie Schluter"], "emails": ["zeag@itu.dk", "nael@itu.dk"], "sections": [{"heading": "1 Introduction", "text": "The processing of natural language marks a very recent resurgence of interest in textual engagement. Now revised as Natural Language Conclusion (NLI) by Bowman et al. (2015) with their SNLI dataset, the task of distinguishing contradictory, associated and unrelated sentence pairs (Fig. 1) has entertained a large number of suggestions. However, the timely challenge lends itself to various deep learning approaches, such as Rockta \u00bc schel et al. (2015), Parikh et al. (2016) or Wang et al. (2017), which feature a number of very remarkable results. Nevertheless, the SNLI corpus is only in English. Lately, it contains more test data from several genres, but it remains exclusively for English. Following Bender (2009) in the search for true language independence, we propose to expand current NLI research beyond English and further into the majority languages."}, {"heading": "2 Cross-lingual inference", "text": "It is only a matter of time before we get involved with the requirement planning condition, and it is particularly suitable for the baseline that we are presenting here: a purely multilingual embedding that is based on most languages that are based on different languages that are based on different languages. It is also an approach that is much emptier than most other languages, so that it can be a fast and scalable language. (2016) Model sends sentence pairs, i.e., premises and hypotheses, through a neural pipeline that consists of three separate components: i) ATTENTION: Scores Combinations of word pairs that extend over a few, i.e. scores of these word pairs and hypotheses, we are a network that consists of three separate components."}, {"heading": "3 Test data", "text": "The SNLI data are essentially pairs of sentences - premises and hypotheses - paired with a relationship etiquette: contradiction, division, or neutrality. We had human experts manually translate the first 1,332 test pairs from English into Arabic, French, Russian, and Spanish. We simply copied the original naming of the relationships, allowing us to directly evaluate the NLI performance for these five languages. We also translated our test sentences using Google Translate for our MT-based system, as it adapts through translation and therefore expects input into English. We also automatically translated the 1,332 original English sentences into our new test languages to see how well we can approximate the \"true\" accuracy using translated test data. In this way, we can facilitate cross-language NLI ratings on a larger scale. BLEU values for the two translation directions are given in Table 1, where we see a clear typological separation."}, {"heading": "4 Experiment", "text": "In fact, it is a way in which the people of the United States, Europe and the United States of America, Europe and the Caribbean, who have set out in the United States, Europe and the Caribbean in search of a new home, are not only looking for a new home, but also for a new home, where people in the United States, in Europe and throughout the world have had the idea of finding a new home, \"he said.\" We have to get involved in the search for a new home, \"he said."}, {"heading": "5 Related work", "text": "Prior to SNLI, there was work on cross-language word processing using parallel corpora (Mehdad et al., 2011) and lexical resources (Castillo et al., 2011) or crowdsourcing multilingual training data from Negri et al. (2011). We also note two common tasks on cross-language linking with five languages (Negri et al., 2013) and on kinship and inference of English (Marelli et al., 2014). SNLI is the first large-scale data set for NLI in English (Bowman et al., 2015), two orders of magnitude larger than any predecessor. Recently, it has been expanded to include test data for multiple genres of English.12 Prior to our work, there were no cross-border SNLI-style methods or evaluations."}, {"heading": "6 Conclusions", "text": "In experiments with three types of transfer systems, we record practicable results while exploring the scalability of linguistic conclusions for low-resource languages. We are actively expanding the test data and introducing new languages. Our multilingual test sets and word embeddings are freely available.1312 https: / / www.nyu.edu / projects / bowman / multinli / 13 https: / / bitbucket.org / nlpitu / xnli"}, {"heading": "Acknowledgements", "text": "We thank Ivan Vulic \"and Nikola Mrks\" ic \"for their help with the bilingual embedding and NVIDIA Corporation for their support of our research."}], "references": [{"title": "Linguistically na\u0131\u0308ve !=", "author": [], "venue": null, "citeRegEx": "Bender.,? \\Q2009\\E", "shortCiteRegEx": "Bender.", "year": 2009}, {"title": "Structured attention networks", "author": ["Yoon Kim", "Carl Denton", "Luong Hoang", "Alexander M Rush."], "venue": "arXiv preprint arXiv:1702.00887 .", "citeRegEx": "Kim et al\\.,? 2017", "shortCiteRegEx": "Kim et al\\.", "year": 2017}, {"title": "A strong baseline for learning cross-lingual word embeddings from sentence alignments", "author": ["Omer Levy", "Anders S\u00f8gaard", "Yoav Goldberg."], "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Lin-", "citeRegEx": "Levy et al\\.,? 2017", "shortCiteRegEx": "Levy et al\\.", "year": 2017}, {"title": "Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and tex", "author": ["Marco Marelli", "Luisa Bentivogli", "Marco Baroni", "Raffaella Bernardi", "Stefano Menini", "Roberto Zamparelli"], "venue": null, "citeRegEx": "Marelli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "Using bilingual parallel corpora for cross-lingual textual entailment", "author": ["Yashar Mehdad", "Matteo Negri", "Marcello Federico."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Tech-", "citeRegEx": "Mehdad et al\\.,? 2011", "shortCiteRegEx": "Mehdad et al\\.", "year": 2011}, {"title": "Exploiting similarities among languages for machine translation", "author": ["Tomas Mikolov", "Quoc Le", "Ilya Sutskever."], "venue": "arXiv preprint arXiv:1309.4168 .", "citeRegEx": "Mikolov et al\\.,? 2013a", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in Neural Information Processing Systems. pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013b", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Divide and conquer: Crowdsourcing", "author": ["Matteo Negri", "Luisa Bentivogli", "Yashar Mehdad", "Danilo Giampiccolo", "Alessandro Marchetti"], "venue": null, "citeRegEx": "Negri et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Negri et al\\.", "year": 2011}, {"title": "Semeval-2013 task 8: Cross-lingual textual entailment for content synchronization", "author": ["Matteo Negri", "Alessandro Marchetti", "Yashar Mehdad", "Luisa Bentivogli", "Danilo Giampiccolo."], "venue": "Second Joint Conference on Lexical and Computational Seman-", "citeRegEx": "Negri et al\\.,? 2013", "shortCiteRegEx": "Negri et al\\.", "year": 2013}, {"title": "A decomposable attention model for natural language inference", "author": ["Ankur Parikh", "Oscar T\u00e4ckstr\u00f6m", "Dipanjan Das", "Jakob Uszkoreit."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association", "citeRegEx": "Parikh et al\\.,? 2016", "shortCiteRegEx": "Parikh et al\\.", "year": 2016}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher Manning."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computa-", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Reasoning about entailment with neural attention", "author": ["Tim Rockt\u00e4schel", "Edward Grefenstette", "Karl Moritz Hermann", "Tom\u00e1\u0161 Ko\u010disk\u1ef3", "Phil Blunsom."], "venue": "arXiv preprint arXiv:1509.06664 .", "citeRegEx": "Rockt\u00e4schel et al\\.,? 2015", "shortCiteRegEx": "Rockt\u00e4schel et al\\.", "year": 2015}, {"title": "Inverted indexing for crosslingual nlp", "author": ["Anders S\u00f8gaard", "\u017deljko Agi\u0107", "H\u00e9ctor Mart\u0131\u0301nez Alonso", "Barbara Plank", "Bernd Bohnet", "Anders Johannsen"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association", "citeRegEx": "S\u00f8gaard et al\\.,? \\Q2015\\E", "shortCiteRegEx": "S\u00f8gaard et al\\.", "year": 2015}, {"title": "Treebank translation for cross-lingual parser induction", "author": ["J\u00f6rg Tiedemann", "\u017deljko Agi\u0107", "Joakim Nivre."], "venue": "Proceedings of the Eighteenth Conference on Computational Natural Language Learning. Association for Computational", "citeRegEx": "Tiedemann et al\\.,? 2014", "shortCiteRegEx": "Tiedemann et al\\.", "year": 2014}, {"title": "Bilingual distributed word representations from document-aligned comparable data", "author": ["Ivan Vuli\u0107", "Marie-Francine Moens."], "venue": "Journal of Artificial Intelligence Research 55:953\u2013994. https://doi.org/doi:10.1613/jair.4986.", "citeRegEx": "Vuli\u0107 and Moens.,? 2016", "shortCiteRegEx": "Vuli\u0107 and Moens.", "year": 2016}, {"title": "Bilateral multi-perspective matching for natural language sentences", "author": ["Zhiguo Wang", "Wael Hamza", "Radu Florian."], "venue": "arXiv preprint arXiv:1702.03814 .", "citeRegEx": "Wang et al\\.,? 2017", "shortCiteRegEx": "Wang et al\\.", "year": 2017}, {"title": "The united nations parallel corpus v1.0", "author": ["Micha\u0142 Ziemski", "Marcin Junczys-Dowmunt", "Bruno Pouliquen"], "venue": "In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)", "citeRegEx": "Ziemski et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ziemski et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 10, "context": "1 The timely challenge lends itself to various deep learning approaches such as by Rockt\u00e4schel et al. (2015), Parikh et al.", "startOffset": 83, "endOffset": 109}, {"referenceID": 9, "context": "(2015), Parikh et al. (2016), or Wang et al.", "startOffset": 8, "endOffset": 29}, {"referenceID": 9, "context": "(2015), Parikh et al. (2016), or Wang et al. (2017), which mark a string of very notable results.", "startOffset": 8, "endOffset": 52}, {"referenceID": 0, "context": "Following Bender (2009) in seeking true language independence, we propose to extend the current NLI research beyond English, and further into the majority realm of low-resource languages.", "startOffset": 10, "endOffset": 24}, {"referenceID": 9, "context": "Following the success of neural networks in SNLIstyle inference, we take the neural attention-based model of Parikh et al. (2016) as our starting point.", "startOffset": 109, "endOffset": 130}, {"referenceID": 9, "context": "In short, the Parikh et al. (2016) model sends sentence pairs, i.", "startOffset": 14, "endOffset": 35}, {"referenceID": 5, "context": "One method for obtaining multilingual word embeddings is to apply the translation matrix technique to a set of monolingual embeddings (Mikolov et al., 2013a) with the aid of a", "startOffset": 134, "endOffset": 157}, {"referenceID": 11, "context": "sentence IDs as indexing features, with SVD dimensionality reduction on top, following S\u00f8gaard et al. (2015) in the recent implementation by Levy et al.", "startOffset": 87, "endOffset": 109}, {"referenceID": 2, "context": "(2015) in the recent implementation by Levy et al. (2017).5 Instead of embedding just language pairs, this method embeds multiple languages into", "startOffset": 39, "endOffset": 58}, {"referenceID": 12, "context": "RANDOM: Our implementation of the approach by Vuli\u0107 and Moens (2016) whereby bilingual SGNS embeddings of Mikolov et al.", "startOffset": 46, "endOffset": 69}, {"referenceID": 5, "context": "RANDOM: Our implementation of the approach by Vuli\u0107 and Moens (2016) whereby bilingual SGNS embeddings of Mikolov et al. (2013b) are trained on top of merged pairs of parallel sentences with randomly shuffled tokens.", "startOffset": 106, "endOffset": 129}, {"referenceID": 13, "context": "Moreover, we can translate the training data and train target language models similar to Tiedemann et al. (2014) in cross-lingual de-", "startOffset": 89, "endOffset": 113}, {"referenceID": 1, "context": "We run the Kim et al. (2017) implementation of the attention-based system of Parikh et al.", "startOffset": 11, "endOffset": 29}, {"referenceID": 1, "context": "We run the Kim et al. (2017) implementation of the attention-based system of Parikh et al. (2016).6 All models are trained for 15 epochs and otherwise with default settings.", "startOffset": 11, "endOffset": 98}, {"referenceID": 5, "context": "We map the target language embeddings to English as Mikolov et al. (2013a), using the Dinu et al.", "startOffset": 52, "endOffset": 75}, {"referenceID": 5, "context": "We map the target language embeddings to English as Mikolov et al. (2013a), using the Dinu et al. (2014) implementation8 and Wiktionary data.", "startOffset": 52, "endOffset": 105}, {"referenceID": 16, "context": "We train our bilingual embeddings on the UN corpus (Ziemski et al., 2016).", "startOffset": 51, "endOffset": 73}, {"referenceID": 10, "context": "There, we use two English SNLI models: one with FASTTEXT and the other with GLOVE 840B embeddings (Pennington et al., 2014).", "startOffset": 98, "endOffset": 123}, {"referenceID": 9, "context": "This also holds true for the original Parikh et al. (2016) evaluation on English.", "startOffset": 38, "endOffset": 59}, {"referenceID": 9, "context": "In 100 training epochs, Parikh et al. (2016) score 86.", "startOffset": 24, "endOffset": 45}, {"referenceID": 12, "context": "As per S\u00f8gaard et al. (2015) most language pairs can offer no more than 100k sentence pairs, this puts forth a challenge for future cross-lingual NLI learning research.", "startOffset": 7, "endOffset": 29}, {"referenceID": 4, "context": "Prior to SNLI, there has been work in cross-lingual textual entailment using parallel corpora (Mehdad et al., 2011) and lexical resources (Castillo, 2011), or crowdsourcing for multilingual training data by", "startOffset": 94, "endOffset": 115}, {"referenceID": 8, "context": "We also note two shared tasks, on cross-lingual entailment with five languages (Negri et al., 2013) and English relatedness and inference (Marelli et al.", "startOffset": 79, "endOffset": 99}, {"referenceID": 3, "context": ", 2013) and English relatedness and inference (Marelli et al., 2014).", "startOffset": 46, "endOffset": 68}], "year": 2017, "abstractText": "Research in natural language inference is currently exclusive to English. Here, we propose to advance toward multilingual evaluation. To that end, we provide test data for four major languages. We experiment with a set of baselines based on cross-lingual embeddings and machine translation. While our best system scores an average accuracy of just over 75%, we focus largely on enabling further research in multilingual inference.", "creator": "LaTeX with hyperref package"}}}