{"id": "1704.05415", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Apr-2017", "title": "An Empirical Analysis of NMT-Derived Interlingual Embeddings and their Use in Parallel Sentence Identification", "abstract": "End-to-end neural machine translation has overtaken statistical machine translation in terms of translation quality for some language pairs, specially those with a large amount of parallel data available. Beside this palpable improvement, neural networks embrace several new properties. A single system can be trained to translate between many languages at almost no additional cost other than training time. Furthermore, internal representations learned by the network serve as a new semantic representation of words -or sentences- which, unlike standard word embeddings, are learned in an essentially bilingual or even multilingual context. In view of these properties, the contribution of the present work is two-fold. First, we systematically study the context vectors, i.e. output of the encoder, and their prowess as an interlingua representation of a sentence. Their quality and effectiveness are assessed by similarity measures across translations, semantically related, and semantically unrelated sentence pairs. Second, and as extrinsic evaluation of the first point, we identify parallel sentences in comparable corpora, obtaining an F1=98.2% on data from a shared task when using only context vectors. F1 reaches 98.9% when complementary similarity measures are used.", "histories": [["v1", "Tue, 18 Apr 2017 16:38:01 GMT  (294kb,D)", "http://arxiv.org/abs/1704.05415v1", "15 pages, 3 figures"]], "COMMENTS": "15 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["cristina espa\\~na-bonet", "\\'ad\\'am csaba varga", "alberto barr\\'on-cede\\~no", "josef van genabith"], "accepted": false, "id": "1704.05415"}, "pdf": {"name": "1704.05415.pdf", "metadata": {"source": "CRF", "title": "An Empirical Analysis of NMT-Derived Interlingual Embeddings and their Use in Parallel Sentence Identification", "authors": ["Cristina Espa\u00f1a-Bonet", "\u00c1d\u00e1m Csaba Varga", "Alberto Barr\u00f3n-Cede\u00f1o", "Josef van Genabith"], "emails": ["cristinae@dfki.de,", "adamcs.varga@gmail.com,", "albarron@hbku.edu.qa,", "Josef.Van_Genabith@dfki.de"], "sections": [{"heading": "1 Introduction", "text": "In principle, this space is simply multilingual, but it is more than the network (Kalchbrennerand Blunsom, 2013) as a promising alternative to statistical and rule-based systems. Nowadays, they are more than a promise. NMT systems are state-of-the-art for language pairs with a large amount of parallel data (Bojar et al., 2016) and have nice features that other paradigms lack. Just to point out three of them, where a deep learning architecture does not require manually predefined sentences, it allows the simultaneous formation of systems in multiple languages, and it can provide zero-shot translations, i.e. translations for language pairs that are not directly visible in the training data (Ha et al., 2016). Multilingual Neural Machine Translation Systems (ML-NMT) we have particularly interesting features."}, {"heading": "2 Background", "text": "Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder Encoder"}, {"heading": "3 NMT Systems Description", "text": "In fact, it is true that this is a type and manner in which people in the United States, Europe and the United States of America, Europe and the United States of America, Europe and the Caribbean, who are located in the United States, Europe and the Caribbean, are able to conquer the world. (...) It is as if they are able to change the world. \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "4 Context Vectors in Multilingual NMT Systems", "text": "In fact, it is the case that most people are able to survive themselves, and that they are able to survive themselves. (...) It is not the case that they are able to survive themselves. (...) It is not the case that they are able to survive themselves. (...) It is not the case that they are able to survive themselves. (...) It is the case that they are not able to survive themselves. (...) It is the case that they are able to survive themselves. (...) It is the case that they are able to survive themselves. (...) It is the case that they are able to survive themselves. (...) It is the case that they are able to survive themselves. (...) (...) (...) () (...) (...) () (...) () (...) () (...) (...) (() () (...) () (...) () (...) () (...) () (()) (()) (())) ((()))) ((()))) (((())))) (((())))) (((...)) () () ()) () () () () () ()) () () ()) () () ()) () () () ()) () () ()) () () () () ()) () () ()) () () ()) () () () () ()) () () () () () () ()) () () () () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () (() () () () (() ()) (() () () () () ())) ((() ()) (((()) ((()))) ((()) ((()))) (((((())))) ((((("}, {"heading": "5 Use Case: Parallel Sentence Extraction", "text": "In fact, most people are able to decide for themselves what they want and what they want."}, {"heading": "6 Conclusions", "text": "In this article, we provide evidence of the interlingual nature of context vectors generated by a multilingual neural machine translation system. We examine how the representation of a sentence varies to be adapted to a particular target language, and find that the difference is negligible, even if it increases when we look at distant target languages such as Arabic and English. Even in these cases, the representation of a sentence is unique enough, as closely related sentences are less similar than different cases of the same sentence. The results also show that contextual interlingual vectors are able to differentiate between sentences with identical, similar and different meanings in different languages - including Arabic, English, French, German, and Spanish. Our training evolution experiments show that vectors are best at early training to make a similarity assessment, whereas the optimal vectors for translation require further training."}, {"heading": "Acknowledgments", "text": "Part of the research in this thesis was funded by the Leibniz Association through the SAW-2016-ZPID-2 project. A. Barro \u0301 n-Ceden \u0435o's research is carried out as part of the Interactive sYstems for Answer Search (IYAS) project at the Qatar Computing Research Institute, HBKU."}], "references": [{"title": "IXA pipeline: Efficient and Ready to Use Multilingual NLP Tools", "author": ["Rodrigo Agerri", "Josu Bermudez", "German Rigau."], "venue": "(Calzolari et al., 2014).", "citeRegEx": "Agerri et al\\.,? 2014", "shortCiteRegEx": "Agerri et al\\.", "year": 2014}, {"title": "Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation", "author": ["Eneko Agirre", "Daniel Cer", "Mona Diab", "I\u00f1igo Lopez-Gazpioa", "Lucia Specia"], "venue": null, "citeRegEx": "Agirre et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Agirre et al\\.", "year": 2017}, {"title": "Neural Machine Translation by Jointly Learning to Align and Translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "CoRR abs/1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Findings of the 2016 Conference on Machine Translation", "author": ["Martin Popel", "Matt Post", "Raphael Rubino", "Carolina Scarton", "Lucia Specia", "Marco Turchi", "Karin Verspoor", "Marcos Zampieri."], "venue": "Proceedings of the First Con-", "citeRegEx": "Popel et al\\.,? 2016", "shortCiteRegEx": "Popel et al\\.", "year": 2016}, {"title": "Question Answering with Joost at CLEF 2008", "author": ["Gosse Bouma", "Jori Mur", "Gertjan van Noord."], "venue": "(Peters et al., 2008).", "citeRegEx": "Bouma et al\\.,? 2008", "shortCiteRegEx": "Bouma et al\\.", "year": 2008}, {"title": "MultiUN v2: UN Documents with Multilingual Alignments", "author": ["Yu Chen", "Andreas Eisele."], "venue": "Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Mehmet U\u011fur Do\u011fan, Bente Maegaard, Joseph Mariani, Asuncion Moreno,", "citeRegEx": "Chen and Eisele.,? 2012", "shortCiteRegEx": "Chen and Eisele.", "year": 2012}, {"title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine", "author": ["Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": null, "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Automatically constructing a corpus of sentential paraphrases", "author": ["Bill Dolan", "Chris Brockett."], "venue": "Third International Workshop on Paraphrasing (IWP2005). Asia Federation of Natural Language Processing.", "citeRegEx": "Dolan and Brockett.,? 2005", "shortCiteRegEx": "Dolan and Brockett.", "year": 2005}, {"title": "Multi-Task Learning for Multiple Language Translation", "author": ["Daxiang Dong", "Hua Wu", "Wei He", "Dianhai Yu", "Haifeng Wang."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the", "citeRegEx": "Dong et al\\.,? 2015", "shortCiteRegEx": "Dong et al\\.", "year": 2015}, {"title": "Improving Vector Space Word Representations Using Multilingual Correlation", "author": ["Manaal Faruqui", "Chris Dyer."], "venue": "Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics. Asso-", "citeRegEx": "Faruqui and Dyer.,? 2014", "shortCiteRegEx": "Faruqui and Dyer.", "year": 2014}, {"title": "Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism", "author": ["Orhan Firat", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "(Knight et al., 2016), pages 866\u2013875.", "citeRegEx": "Firat et al\\.,? 2016", "shortCiteRegEx": "Firat et al\\.", "year": 2016}, {"title": "Multi-Document Summarization By Sentence Extraction", "author": ["Jade Goldstein", "Vibhu Mittal", "Jaime Carbonell", "Mark Kantrowitz."], "venue": "NAACL-ANLP 2000 Workshop on Automatic Summarization. Association for Computational", "citeRegEx": "Goldstein et al\\.,? 2000", "shortCiteRegEx": "Goldstein et al\\.", "year": 2000}, {"title": "Natural language question answering: the view from here", "author": ["L. Hirschman", "R. Gaizauskas."], "venue": "Natural Language Engineering 7(4):275\u2013300. https://doi.org/10.1017/S1351324901002807.", "citeRegEx": "Hirschman and Gaizauskas.,? 2001", "shortCiteRegEx": "Hirschman and Gaizauskas.", "year": 2001}, {"title": "Recurrent Continuous Translation Models", "author": ["Nal Kalchbrenner", "Phil Blunsom."], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Seattle,", "citeRegEx": "Kalchbrenner and Blunsom.,? 2013", "shortCiteRegEx": "Kalchbrenner and Blunsom.", "year": 2013}, {"title": "Europarl: A Parallel Corpus for Statistical Machine Translation", "author": ["Philipp Koehn."], "venue": "Conference Proceedings: the Tenth Machine Translation Summit. AAMT, AAMT, Phuket, Thailand, pages 79\u201386.", "citeRegEx": "Koehn.,? 2005", "shortCiteRegEx": "Koehn.", "year": 2005}, {"title": "Fully Character-Level Neural Machine Translation without Explicit Segmentation", "author": ["Jason Lee", "Kyunghyun Cho", "Thomas Hofmann."], "venue": "CoRR abs/1610.03017.", "citeRegEx": "Lee et al\\.,? 2016", "shortCiteRegEx": "Lee et al\\.", "year": 2016}, {"title": "Multitask Sequence to Sequence Learning", "author": ["Minh-Thang Luong", "Quoc V. Le", "Ilya Sutskever", "Oriol Vinyals", "Lukasz Kaiser."], "venue": "CoRR abs/1511.06114.", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Resolving Out-ofVocabulary Words with Bilingual Embeddings in Machine Translation", "author": ["Pranava Swaroop Madhyastha", "Cristina Espa\u00f1a-Bonet."], "venue": "CoRR abs/1608.01910.", "citeRegEx": "Madhyastha and Espa\u00f1a.Bonet.,? 2016", "shortCiteRegEx": "Madhyastha and Espa\u00f1a.Bonet.", "year": 2016}, {"title": "Foundations of Statistical Natural Language Processing", "author": ["Christopher D. Manning", "Hinrich Sch\u00fctze."], "venue": "The MIT Press.", "citeRegEx": "Manning and Sch\u00fctze.,? 1999", "shortCiteRegEx": "Manning and Sch\u00fctze.", "year": 1999}, {"title": "Character n-gram tokenization for european language text retrieval", "author": ["Paul McNamee", "James Mayfield."], "venue": "Information retrieval 7(1-2):73\u2013", "citeRegEx": "McNamee and Mayfield.,? 2004", "shortCiteRegEx": "McNamee and Mayfield.", "year": 2004}, {"title": "Exploiting Similarities among Languages for Machine Translation", "author": ["Tomas Mikolov", "Quoc V. Le", "Ilya Sutskever."], "venue": "CoRR abs/1309.4168.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "AliQAn, Spanish QA System at multilingual QA@CLEF2008", "author": ["R. Mu\u00f1oz Terol", "M. Puchol-Blasco", "M. Pardi\u00f1o", "J.M. G\u00f3mez", "S. Roger", "K. Vila", "A. Ferr\u00e1ndez", "J. Peral", "P. Mart\u0301inez-Barco"], "venue": "In (Peters et al.,", "citeRegEx": "Terol et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Terol et al\\.", "year": 2008}, {"title": "Improving Machine Translation Performance by Exploiting Non-Parallel Corpora", "author": ["Dragos Stefan Munteanu", "Daniel Marcu."], "venue": "Computational Linguistics 31(4):477\u2013504. https://doi.org/10.1162/089120105775299168.", "citeRegEx": "Munteanu and Marcu.,? 2005", "shortCiteRegEx": "Munteanu and Marcu.", "year": 2005}, {"title": "MADAMIRA: A Fast, Comprehensive Tool for Morphological Analysis and", "author": ["Arfath Pasha", "Mohamed Al-Badrashiny", "Mona Diab", "Ahmed El Kholy", "Ramy Eskander", "Nizar Habash", "Manoj Pooleery", "Owen Rambow", "Ryan Roth"], "venue": null, "citeRegEx": "Pasha et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pasha et al\\.", "year": 2014}, {"title": "Cross-language plagiarism detection", "author": ["Martin Potthast", "Alberto Barr\u00f3n-Cede\u00f1o", "Benno Stein", "Paolo Rosso."], "venue": "Language Resources and Evaluation (LRE), Special Issue on Plagiarism and Authorship Analysis 45(1):1\u201318.", "citeRegEx": "Potthast et al\\.,? 2011", "shortCiteRegEx": "Potthast et al\\.", "year": 2011}, {"title": "An Evaluation Framework for Plagiarism Detection", "author": ["Martin Potthast", "Benno Stein", "Alberto Barr\u00f3nCede\u00f1o", "Paolo Rosso."], "venue": "Chu-Ren Huang and Dan Jurafsky, editors, Proceedings of the 23rd International Conference", "citeRegEx": "Potthast et al\\.,? 2010", "shortCiteRegEx": "Potthast et al\\.", "year": 2010}, {"title": "Automatic Identification of Document Translations in Large Multilingual Document Collections", "author": ["Bruno Pouliquen", "Ralf Steinberger", "Camelia Ignat."], "venue": "Proceedings of the International Conference on Recent Advances in", "citeRegEx": "Pouliquen et al\\.,? 2003", "shortCiteRegEx": "Pouliquen et al\\.", "year": 2003}, {"title": "United Nations General Assembly Resolutions: A Six-Language Parallel Corpus", "author": ["Alexandre Rafalovitch", "Robert Dale."], "venue": "Proceedings of the Machine Translation Summit XII. International Association of Machine Translation,", "citeRegEx": "Rafalovitch and Dale.,? 2009", "shortCiteRegEx": "Rafalovitch and Dale.", "year": 2009}, {"title": "Nematus: a Toolkit for Neural Machine Translation", "author": ["Hitschler", "Marcin Junczys-Dowmunt", "Samuel L\u00e4ubli", "Antonio Valerio Miceli Barone", "Jozef Mokry", "Maria Nadejde."], "venue": "Proceedings of the Demonstrations at the 15th", "citeRegEx": "Hitschler et al\\.,? 2017", "shortCiteRegEx": "Hitschler et al\\.", "year": 2017}, {"title": "Neural Machine Translation of Rare Words with Subword Units", "author": ["Rico Sennrich", "Barry Haddow", "Alexandra Birch."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016,", "citeRegEx": "Sennrich et al\\.,? 2016", "shortCiteRegEx": "Sennrich et al\\.", "year": 2016}, {"title": "Acquiring Paraphrases from Corpora and Its Application to Machine Translation", "author": ["Mitsuo Shimohata."], "venue": "Ph.D. thesis, Nara Institute of Science and Technology, Nara, Japan.", "citeRegEx": "Shimohata.,? 2004", "shortCiteRegEx": "Shimohata.", "year": 2004}, {"title": "Using Cognates to Align Sentences in Bilingual Corpora", "author": ["Michel Simard", "George F Foster", "Pierre Isabelle."], "venue": "Proceedings of the 1993 conference of the Centre for Advanced Studies on Collaborative research: distributed", "citeRegEx": "Simard et al\\.,? 1993", "shortCiteRegEx": "Simard et al\\.", "year": 1993}, {"title": "Sequence to Sequence Learning with Neural Networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."], "venue": "Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, editors, Advances in Neural Information", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "News from OPUS A Collection of Multilingual Parallel Corpora with Tools and Interfaces", "author": ["J\u00f6rg Tiedemann."], "venue": "N. Nicolov, K. Bontcheva, G. Angelova, and R. Mitkov, editors, Recent Advances in Natural Lan-", "citeRegEx": "Tiedemann.,? 2009", "shortCiteRegEx": "Tiedemann.", "year": 2009}, {"title": "Accelerating tSNE Using Tree-based Algorithms", "author": ["Laurens Van Der Maaten."], "venue": "Journal of Machine Learning Research 15(1):3221\u20133245.", "citeRegEx": "Maaten.,? 2014", "shortCiteRegEx": "Maaten.", "year": 2014}, {"title": "MultiSource Neural Translation", "author": ["Barret Zoph", "Kevin Knight."], "venue": "(Knight et al.,", "citeRegEx": "Zoph and Knight.,? 2016", "shortCiteRegEx": "Zoph and Knight.", "year": 2016}], "referenceMentions": [{"referenceID": 13, "context": "End-to-end neural machine translation systems (NMT) emerged in 2013 (Kalchbrenner and Blunsom, 2013) as a promising alternative to statistical and rule-based systems.", "startOffset": 68, "endOffset": 100}, {"referenceID": 32, "context": "Previous analyses suggest that the network locates words according to their semantics, irrespective of their language (Sutskever et al., 2014; Ha et al., 2016; Johnson et al., 2016).", "startOffset": 118, "endOffset": 181}, {"referenceID": 6, "context": "State-of-the-art NMT systems utilise a twostage encoder\u2013decoder architecture with recurrent neural networks (RNN) (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2014).", "startOffset": 114, "endOffset": 179}, {"referenceID": 32, "context": "State-of-the-art NMT systems utilise a twostage encoder\u2013decoder architecture with recurrent neural networks (RNN) (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2014).", "startOffset": 114, "endOffset": 179}, {"referenceID": 2, "context": "State-of-the-art NMT systems utilise a twostage encoder\u2013decoder architecture with recurrent neural networks (RNN) (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2014).", "startOffset": 114, "endOffset": 179}, {"referenceID": 6, "context": "where f is a recurrent unit (Gated Recurrent Units (GRU) (Cho et al., 2014) in our experiments) and r is a representation of the source sentence given by the product of the word embeddings matrix and the one-hot vector representation of xi: r = Wx \u00b7 xi.", "startOffset": 57, "endOffset": 75}, {"referenceID": 2, "context": "The weighted context vector qj is calculated by the attention mechanism as described in Bahdanau et al. (2014). Its function is to assign weights to the context vectors in order to selectively focus on different source words at different time steps of the translation.", "startOffset": 88, "endOffset": 111}, {"referenceID": 2, "context": "Called \u201cannotation vectors\u201d by Bahdanau et al. (2014), who use \u201ccontext vectors\u201d to designate the vectors after the attention mechanism.", "startOffset": 31, "endOffset": 54}, {"referenceID": 16, "context": "A number of papers extend this architecture to deal with multilingual translation by using multiple encoders and/or decoders either with multiple or shared attention mechanisms (Luong et al., 2015; Dong et al., 2015; Firat et al., 2016; Zoph and Knight, 2016; Lee et al., 2016).", "startOffset": 177, "endOffset": 277}, {"referenceID": 8, "context": "A number of papers extend this architecture to deal with multilingual translation by using multiple encoders and/or decoders either with multiple or shared attention mechanisms (Luong et al., 2015; Dong et al., 2015; Firat et al., 2016; Zoph and Knight, 2016; Lee et al., 2016).", "startOffset": 177, "endOffset": 277}, {"referenceID": 10, "context": "A number of papers extend this architecture to deal with multilingual translation by using multiple encoders and/or decoders either with multiple or shared attention mechanisms (Luong et al., 2015; Dong et al., 2015; Firat et al., 2016; Zoph and Knight, 2016; Lee et al., 2016).", "startOffset": 177, "endOffset": 277}, {"referenceID": 35, "context": "A number of papers extend this architecture to deal with multilingual translation by using multiple encoders and/or decoders either with multiple or shared attention mechanisms (Luong et al., 2015; Dong et al., 2015; Firat et al., 2016; Zoph and Knight, 2016; Lee et al., 2016).", "startOffset": 177, "endOffset": 277}, {"referenceID": 15, "context": "A number of papers extend this architecture to deal with multilingual translation by using multiple encoders and/or decoders either with multiple or shared attention mechanisms (Luong et al., 2015; Dong et al., 2015; Firat et al., 2016; Zoph and Knight, 2016; Lee et al., 2016).", "startOffset": 177, "endOffset": 277}, {"referenceID": 8, "context": ", 2015; Dong et al., 2015; Firat et al., 2016; Zoph and Knight, 2016; Lee et al., 2016). A simpler approximation (Ha et al., 2016; Johnson et al., 2016) considers exactly the same architecture as the one-toone NMT for many-to-many NMT using multilingual data with some additional labelling. Johnson et al. (2016) append the tag of the target language to the source-side sentences, forcing the decoder to translate to the appropriate language.", "startOffset": 8, "endOffset": 313}, {"referenceID": 8, "context": ", 2015; Dong et al., 2015; Firat et al., 2016; Zoph and Knight, 2016; Lee et al., 2016). A simpler approximation (Ha et al., 2016; Johnson et al., 2016) considers exactly the same architecture as the one-toone NMT for many-to-many NMT using multilingual data with some additional labelling. Johnson et al. (2016) append the tag of the target language to the source-side sentences, forcing the decoder to translate to the appropriate language. Ha et al. (2016) also include tags specifying the language of every source word.", "startOffset": 8, "endOffset": 460}, {"referenceID": 32, "context": "Sutskever et al. (2014) show how a monolingual NMT encoder represents sentences with", "startOffset": 0, "endOffset": 24}, {"referenceID": 30, "context": "chine translation (Shimohata, 2004), is essentially similarity assessment, and so is the task of plagiarism detection (Potthast et al.", "startOffset": 18, "endOffset": 35}, {"referenceID": 25, "context": "chine translation (Shimohata, 2004), is essentially similarity assessment, and so is the task of plagiarism detection (Potthast et al., 2010).", "startOffset": 118, "endOffset": 141}, {"referenceID": 11, "context": "In multi-document summarisation (Goldstein et al., 2000) finding two highly-similar pieces of information from two texts may imply it is worth adding it into a good summary.", "startOffset": 32, "endOffset": 56}, {"referenceID": 12, "context": "In information retrieval, and in particular in question answering (Hirschman and Gaizauskas, 2001), a high similarity between a document and an", "startOffset": 66, "endOffset": 98}, {"referenceID": 22, "context": "It is essential in MT evaluation and, in the current cross-language setting, to identify parallel corpora to feed a (neural) machine translation model with (Munteanu and Marcu, 2005).", "startOffset": 156, "endOffset": 182}, {"referenceID": 4, "context": ", (Bouma et al., 2008; Mu\u00f1oz Terol et al., 2008; Potthast et al., 2011)), but using interlingua or multilingual representations instead.", "startOffset": 2, "endOffset": 71}, {"referenceID": 24, "context": ", (Bouma et al., 2008; Mu\u00f1oz Terol et al., 2008; Potthast et al., 2011)), but using interlingua or multilingual representations instead.", "startOffset": 2, "endOffset": 71}, {"referenceID": 20, "context": "To some extent, it can be thought as a generalisation of methods that project monolingual embeddings in two different languages into a common space to obtain bilingual word embeddings (Mikolov et al., 2013; Faruqui and Dyer, 2014; Madhyastha and Espa\u00f1a-Bonet, 2016).", "startOffset": 184, "endOffset": 265}, {"referenceID": 9, "context": "To some extent, it can be thought as a generalisation of methods that project monolingual embeddings in two different languages into a common space to obtain bilingual word embeddings (Mikolov et al., 2013; Faruqui and Dyer, 2014; Madhyastha and Espa\u00f1a-Bonet, 2016).", "startOffset": 184, "endOffset": 265}, {"referenceID": 17, "context": "To some extent, it can be thought as a generalisation of methods that project monolingual embeddings in two different languages into a common space to obtain bilingual word embeddings (Mikolov et al., 2013; Faruqui and Dyer, 2014; Madhyastha and Espa\u00f1a-Bonet, 2016).", "startOffset": 184, "endOffset": 265}, {"referenceID": 29, "context": "We carry out our experiments with two multilingual many-to-many NMT systems trained with Nematus (Sennrich et al., 2017). As done in Johnson et al. (2016) and similarly to Ha et al.", "startOffset": 98, "endOffset": 155}, {"referenceID": 29, "context": "We carry out our experiments with two multilingual many-to-many NMT systems trained with Nematus (Sennrich et al., 2017). As done in Johnson et al. (2016) and similarly to Ha et al. (2016), our systems are trained on parallel corpora for several language pairs simultaneously, with the only addition of a tag in the source sentence to account for the target language \u201c<2L2>\u201d (e.", "startOffset": 98, "endOffset": 189}, {"referenceID": 27, "context": "The parallel corpus includes data from United Nations (Rafalovitch and Dale, 2009), Common Crawl2, News Commentary3 and IWSLT4.", "startOffset": 54, "endOffset": 82}, {"referenceID": 23, "context": "We used MADAMIRA (Pasha et al., 2014) for Arabic and the Moses tokeniser for the other languages.", "startOffset": 17, "endOffset": 37}, {"referenceID": 0, "context": "A second system called S1-l is trained on lemmatised sentences using the MADAMIRA lemmatiser for Arabic, and the IXA pipeline (Agerri et al., 2014) for", "startOffset": 126, "endOffset": 147}, {"referenceID": 29, "context": "In both cases we employ a vocabulary of 60K tokens plus 2K for subword units, segmented using Byte Pair Encoding (BPE) (Sennrich et al., 2016).", "startOffset": 119, "endOffset": 142}, {"referenceID": 5, "context": "The parallel corpus includes data from United Nations (Chen and Eisele, 2012), Common Crawl, Europarl (Koehn, 2005), EMEA (Tiedemann, 2009) and Scielo7.", "startOffset": 54, "endOffset": 77}, {"referenceID": 14, "context": "The parallel corpus includes data from United Nations (Chen and Eisele, 2012), Common Crawl, Europarl (Koehn, 2005), EMEA (Tiedemann, 2009) and Scielo7.", "startOffset": 102, "endOffset": 115}, {"referenceID": 33, "context": "The parallel corpus includes data from United Nations (Chen and Eisele, 2012), Common Crawl, Europarl (Koehn, 2005), EMEA (Tiedemann, 2009) and Scielo7.", "startOffset": 122, "endOffset": 139}, {"referenceID": 7, "context": "We extract the subset of sentences with the highest similarity, 4 and 5, and use 140 sentences originally derived from the Microsoft Research Paraphrase Corpus (Dolan and Brockett, 2005) (MSR), and 203 sentences from WMT20089 to build our final test set with 343 sentences (subSTS2017).", "startOffset": 160, "endOffset": 186}, {"referenceID": 19, "context": "We borrow two well known representations from cross-language information retrieval to account for syntactic features by means of cosine similarities: (i) character n-grams (McNamee and Mayfield, 2004), considering n = [2, 5] and (ii) pseudo-cognates.", "startOffset": 172, "endOffset": 200}, {"referenceID": 18, "context": "From a natural language point of view, cognates are \u201cwords that are similar across languages\u201d (Manning and Sch\u00fctze, 1999).", "startOffset": 94, "endOffset": 121}, {"referenceID": 31, "context": "The resulting tokens are cut off to four characters (Simard et al., 1993).", "startOffset": 52, "endOffset": 73}, {"referenceID": 26, "context": "Besides, we include general features at sentence level such as (iii) token and (iv) character counts, and (v) the length factor measure (Pouliquen et al., 2003).", "startOffset": 136, "endOffset": 160}], "year": 2017, "abstractText": "End-to-end neural machine translation has overtaken statistical machine translation in terms of translation quality for some language pairs, specially those with a large amount of parallel data available. Beside this palpable improvement, neural networks embrace several new properties. A single system can be trained to translate between many languages at almost no additional cost other than training time. Furthermore, internal representations learned by the network serve as a new semantic representation of words \u2014or sentences\u2014 which, unlike standard word embeddings, are learned in an essentially bilingual or even multilingual context. In view of these properties, the contribution of the present work is twofold. First, we systematically study the context vectors, i.e. output of the encoder, and their prowess as an interlingua representation of a sentence. Their quality and effectiveness are assessed by similarity measures across translations, semantically related, and semantically unrelated sentence pairs. Second, and as extrinsic evaluation of the first point, we identify parallel sentences in comparable corpora, obtaining an F1 = 98.2% on data from a shared task when using only context vectors. F1 reaches 98.9% when complementary similarity measures are used.", "creator": "LaTeX with hyperref package"}}}