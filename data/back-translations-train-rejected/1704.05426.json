{"id": "1704.05426", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Apr-2017", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference", "abstract": "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. In addition to being one of the largest corpora available for the task of NLI, at 433k examples, this corpus improves upon available resources in its coverage: it offers data from ten distinct genres of written and spoken English--making it possible to evaluate systems on nearly the full complexity of the language--and it offers an explicit setting for the evaluation of cross-genre domain adaptation.", "histories": [["v1", "Tue, 18 Apr 2017 17:10:13 GMT  (86kb,D)", "http://arxiv.org/abs/1704.05426v1", "10 pages, 2 figures, 5 tables, submitted to EMNLP 2017"], ["v2", "Thu, 18 May 2017 16:40:41 GMT  (86kb,D)", "http://arxiv.org/abs/1704.05426v2", "10 pages, 2 figures, 5 tables, submitted to EMNLP 2017. v2 corrects a misreported accuracy number for the CBOW model in the 'matched' setting"], ["v3", "Tue, 5 Sep 2017 18:25:11 GMT  (91kb,D)", "http://arxiv.org/abs/1704.05426v3", "12 pages, 2 figures, 7 tables. v2 corrects a misreported accuracy number for the CBOW model in the 'matched' setting. v3 adds a discussion of the difficulty of the corpus to the analysis section"]], "COMMENTS": "10 pages, 2 figures, 5 tables, submitted to EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["adina williams", "nikita nangia", "samuel r bowman"], "accepted": false, "id": "1704.05426"}, "pdf": {"name": "1704.05426.pdf", "metadata": {"source": "CRF", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference", "authors": ["Adina Williams", "Nikita Nangia", "Samuel R. Bowman"], "emails": ["adinawilliams@nyu.edu", "nikitanangia@nyu.edu", "bowman@nyu.edu"], "sections": [{"heading": "1 Introduction", "text": "This year, it has reached the stage where it will be able to take the lead, in the same way as it has done in recent years."}, {"heading": "2 The Corpus", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Data Collection", "text": "The basic collection methodology for MultiNLI in the early 2000s is similar to the SNLI: we create each pair of sentences by selecting a premise sentence from an existing text source and asking a human commentator to write a novel sentence to pair it with a hypothesis. This section describes the sources of our premise sentences, our method of collecting hypotheses sentences, and our relabeling strategies stemming from the second publication of the Open American National Corpus (OANC; Fillmore et al., 1998; Macleod, 2000; Ide and Suderman, 2006, downloaded 12 / 2016): Nine of these sources are from the second publication of the Open American National Corpus."}, {"heading": "2.2 The Resulting Corpus", "text": "In fact, most of them are able to survive on their own, without being able to survive on their own."}, {"heading": "3 Baselines", "text": "To test the difficulty of the NLI task on this corpus, we are experimenting with three neural network models that should be as close as possible to strong published work on SNLI. The first two models are built to produce a sin-gle vector that represents each set, and compute label predictions based on the two resulting vectors. To do this, they link the two representations, their difference, and their elementary product (according to Mou et al., 2016b), and pass the result to a single tanh layer, followed by a three softmax classifier. The first such model is a simple, continuous pocket of words (CBOW) model in which each sentence is represented as the embedding of representations of its words."}, {"heading": "4 Discussion", "text": "This year it is more than ever before."}, {"heading": "5 Conclusion", "text": "The inference from natural language facilitates the assessment of the degree to which neural network models capture the full meaning of natural language sentences for sentence comprehension. Existing NLI datasets such as SNLI have enabled significant advances in modeling, but limited headroom and coverage of the full meaning diversity expressed in English. This paper presents a new dataset that offers dramatically greater difficulty and diversity, as well as serving as a benchmark for studying cross-genre domain adaptations."}, {"heading": "Acknowledgments", "text": "This work was made possible by a Google Faculty Research Award to Sam Bowman and Angeliki Lazaridou. We also thank George Dahl, the organizer of the RepEval 2016 and RepEval 2017 workshops, Andrew Drozdov, and our other NYU colleagues for their help and advice."}], "references": [{"title": "Recognising textual entailment with logical inference", "author": ["Johan Bos", "Katja Markert."], "venue": "Proc. EMNLP.", "citeRegEx": "Bos and Markert.,? 2005", "shortCiteRegEx": "Bos and Markert.", "year": 2005}, {"title": "A large annotated corpus for learning natural language inference", "author": ["Samuel R. Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D. Manning."], "venue": "Proc. EMNLP.", "citeRegEx": "Bowman et al\\.,? 2015", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "A fast unified model for parsing and sentence understanding", "author": ["Samuel R. Bowman", "Jon Gauthier", "Abhinav Rastogi", "Raghav Gupta", "Christopher D. Manning", "Christopher Potts."], "venue": "Proc. ACL.", "citeRegEx": "Bowman et al\\.,? 2016", "shortCiteRegEx": "Bowman et al\\.", "year": 2016}, {"title": "Enhanced LSTM for natural language inference", "author": ["Qian Chen", "Xiaodan Zhu", "Zhen-Hua Ling", "Si Wei", "Hui Jiang", "Diana Inkpen."], "venue": "Proc. ACL.", "citeRegEx": "Chen et al\\.,? 2017", "shortCiteRegEx": "Chen et al\\.", "year": 2017}, {"title": "Entailment, intensionality and text understanding", "author": ["Cleo Condoravdi", "Dick Crouch", "Valeria de Paiva", "Reinhard Stolle", "Daniel G. Bobrow."], "venue": "Proc. NAACL.", "citeRegEx": "Condoravdi et al\\.,? 2003", "shortCiteRegEx": "Condoravdi et al\\.", "year": 2003}, {"title": "The PASCAL recognising textual entailment challenge", "author": ["Ido Dagan", "Oren Glickman", "Bernardo Magnini."], "venue": "Machine learning challenges. Evaluating predictive uncertainty, visual object classification, and recognising textual entailment, Springer.", "citeRegEx": "Dagan et al\\.,? 2006", "shortCiteRegEx": "Dagan et al\\.", "year": 2006}, {"title": "Finding contradictions in text", "author": ["Marie-Catherine de Marneffe", "Anna N. Rafferty", "Christopher D. Manning."], "venue": "Proc. ACL.", "citeRegEx": "Marneffe et al\\.,? 2008", "shortCiteRegEx": "Marneffe et al\\.", "year": 2008}, {"title": "DeCAF: A deep convolutional activation feature for generic visual recognition", "author": ["Jeff Donahue", "Yangqing Jia", "Oriol Vinyals", "Judy Hoffman", "Ning Zhang", "Eric Tzeng", "Trevor Darrell."], "venue": "Proc. ICML.", "citeRegEx": "Donahue et al\\.,? 2014", "shortCiteRegEx": "Donahue et al\\.", "year": 2014}, {"title": "An American national corpus: A proposal", "author": ["Charles Fillmore", "Nancy Ide", "Daniel Jurafsky", "Catherine Macleod."], "venue": "Proc. LREC.", "citeRegEx": "Fillmore et al\\.,? 1998", "shortCiteRegEx": "Fillmore et al\\.", "year": 1998}, {"title": "A natural logic inference system", "author": ["Yaroslav Fyodorov", "Yoad Winter", "Nissim Francez."], "venue": "Proceedings of the 2nd Workshop on Inference in Computational Semantics.", "citeRegEx": "Fyodorov et al\\.,? 2000", "shortCiteRegEx": "Fyodorov et al\\.", "year": 2000}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation 9(8).", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Integrating linguistic resources: The national corpus model", "author": ["Nancy Ide", "Keith Suderman."], "venue": "Proc. LREC.", "citeRegEx": "Ide and Suderman.,? 2006", "shortCiteRegEx": "Ide and Suderman.", "year": 2006}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba."], "venue": "Proc. ICLR.", "citeRegEx": "Kingma and Ba.,? 2015", "shortCiteRegEx": "Kingma and Ba.", "year": 2015}, {"title": "Accurate unlexicalized parsing", "author": ["Dan Klein", "Christopher D. Manning."], "venue": "Proc. ACL. https://doi.org/10.3115/1075096.1075150.", "citeRegEx": "Klein and Manning.,? 2003", "shortCiteRegEx": "Klein and Manning.", "year": 2003}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton."], "venue": "Advances in Neural Information Processing Systems 25.", "citeRegEx": "Krizhevsky et al\\.,? 2012", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Natural Language Inference", "author": ["Bill MacCartney."], "venue": "Ph.D. thesis, Stanford University.", "citeRegEx": "MacCartney.,? 2009", "shortCiteRegEx": "MacCartney.", "year": 2009}, {"title": "An extended model of natural logic", "author": ["Bill MacCartney", "Christopher D Manning."], "venue": "Proceedings of the of the Eighth International Conference on Computational Semantics.", "citeRegEx": "MacCartney and Manning.,? 2009", "shortCiteRegEx": "MacCartney and Manning.", "year": 2009}, {"title": "The american national corpus: Standardized resources for american english", "author": ["Catherine Ide-Nancy Grishman Ralph Macleod."], "venue": "Proc. LREC.", "citeRegEx": "Macleod.,? 2000", "shortCiteRegEx": "Macleod.", "year": 2000}, {"title": "SemEval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual", "author": ["Marco Marelli", "Luisa Bentivogli", "Marco Baroni", "Raffaella Bernardi", "Stefano Menini", "Roberto Zamparelli"], "venue": null, "citeRegEx": "Marelli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "A sick cure for the evaluation of compositional distributional semantic models", "author": ["Marco Marelli", "Stefano Menini", "Marco Baroni", "Luisa Bentivogli", "Raffaella bernardi", "Roberto Zamparelli."], "venue": "Proc. LREC.", "citeRegEx": "Marelli et al\\.,? 2014b", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "How transferable are neural networks in nlp applications? In Proc", "author": ["Lili Mou", "Zhao Meng", "Rui Yan", "Ge Li", "Yan Xu", "Lu Zhang", "Zhi Jin."], "venue": "EMNLP.", "citeRegEx": "Mou et al\\.,? 2016a", "shortCiteRegEx": "Mou et al\\.", "year": 2016}, {"title": "Natural language inference by tree-based convolution and heuristic matching", "author": ["Lili Mou", "Men Rui", "Ge Li", "Yan Xu", "Lu Zhang", "Rui Yan", "Zhi Jin."], "venue": "Proc. ACL.", "citeRegEx": "Mou et al\\.,? 2016b", "shortCiteRegEx": "Mou et al\\.", "year": 2016}, {"title": "Neural semantic encoders", "author": ["Tsendsuren Munkhdalai", "Hong Yu."], "venue": "Proc. EACL.", "citeRegEx": "Munkhdalai and Yu.,? 2017", "shortCiteRegEx": "Munkhdalai and Yu.", "year": 2017}, {"title": "GloVe: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning."], "venue": "Proc. EMNLP.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov."], "venue": "JMLR 15.", "citeRegEx": "Srivastava et al\\.,? 2014", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Learning natural language inference with LSTM", "author": ["Shuohang Wang", "Jing Jiang."], "venue": "Proc. NAACL.", "citeRegEx": "Wang and Jiang.,? 2016", "shortCiteRegEx": "Wang and Jiang.", "year": 2016}, {"title": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions", "author": ["Peter Young", "Alice Lai", "Micah Hodosh", "Julia Hockenmaier."], "venue": "TACL 2.", "citeRegEx": "Young et al\\.,? 2014", "shortCiteRegEx": "Young et al\\.", "year": 2014}, {"title": "Visualizing and understanding convolutional networks", "author": ["Matthew D. Zeiler", "Rob Fergus."], "venue": "Proc. ECCV .", "citeRegEx": "Zeiler and Fergus.,? 2014", "shortCiteRegEx": "Zeiler and Fergus.", "year": 2014}], "referenceMentions": [{"referenceID": 9, "context": "In this task, also known as recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship between their meanings by picking a label from a small set: typically entailment, neutral, and contradiction.", "startOffset": 59, "endOffset": 185}, {"referenceID": 4, "context": "In this task, also known as recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship between their meanings by picking a label from a small set: typically entailment, neutral, and contradiction.", "startOffset": 59, "endOffset": 185}, {"referenceID": 0, "context": "In this task, also known as recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship between their meanings by picking a label from a small set: typically entailment, neutral, and contradiction.", "startOffset": 59, "endOffset": 185}, {"referenceID": 5, "context": "In this task, also known as recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship between their meanings by picking a label from a small set: typically entailment, neutral, and contradiction.", "startOffset": 59, "endOffset": 185}, {"referenceID": 16, "context": "In this task, also known as recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship between their meanings by picking a label from a small set: typically entailment, neutral, and contradiction.", "startOffset": 59, "endOffset": 185}, {"referenceID": 1, "context": "As the only large, human-annotated corpus for NLI currently available, the Stanford NLI Corpus (SNLI; Bowman et al., 2015) has enabled a good deal of progress on NLU, serving as a standard benchmark for sentence understanding and spurring work on core representation learning techniques for NLU such as attention (Wang and Jiang, 2016), memory (Munkhdalai and Yu, 2017), and the use of parse structure (Mou et al.", "startOffset": 95, "endOffset": 122}, {"referenceID": 25, "context": ", 2015) has enabled a good deal of progress on NLU, serving as a standard benchmark for sentence understanding and spurring work on core representation learning techniques for NLU such as attention (Wang and Jiang, 2016), memory (Munkhdalai and Yu, 2017), and the use of parse structure (Mou et al.", "startOffset": 198, "endOffset": 220}, {"referenceID": 22, "context": ", 2015) has enabled a good deal of progress on NLU, serving as a standard benchmark for sentence understanding and spurring work on core representation learning techniques for NLU such as attention (Wang and Jiang, 2016), memory (Munkhdalai and Yu, 2017), and the use of parse structure (Mou et al.", "startOffset": 229, "endOffset": 254}, {"referenceID": 21, "context": ", 2015) has enabled a good deal of progress on NLU, serving as a standard benchmark for sentence understanding and spurring work on core representation learning techniques for NLU such as attention (Wang and Jiang, 2016), memory (Munkhdalai and Yu, 2017), and the use of parse structure (Mou et al., 2016b; Bowman et al., 2016).", "startOffset": 287, "endOffset": 327}, {"referenceID": 2, "context": ", 2015) has enabled a good deal of progress on NLU, serving as a standard benchmark for sentence understanding and spurring work on core representation learning techniques for NLU such as attention (Wang and Jiang, 2016), memory (Munkhdalai and Yu, 2017), and the use of parse structure (Mou et al., 2016b; Bowman et al., 2016).", "startOffset": 287, "endOffset": 327}, {"referenceID": 3, "context": "Because of these two factors it is not sufficiently demanding to serve as an effective benchmark for NLU, with the best current model performance (Chen et al., 2017) falling within a few percentage points of human accuracy, and limited room left for fine-grained comparisons between models.", "startOffset": 146, "endOffset": 165}, {"referenceID": 14, "context": "In many application areas outside NLU, artificial neural network techniques have made it possible to train general-purpose feature extractors that, with no or minimal retraining, can extract useful features for a variety of styles of data (Krizhevsky et al., 2012; Zeiler and Fergus, 2014; Donahue et al., 2014).", "startOffset": 239, "endOffset": 311}, {"referenceID": 27, "context": "In many application areas outside NLU, artificial neural network techniques have made it possible to train general-purpose feature extractors that, with no or minimal retraining, can extract useful features for a variety of styles of data (Krizhevsky et al., 2012; Zeiler and Fergus, 2014; Donahue et al., 2014).", "startOffset": 239, "endOffset": 311}, {"referenceID": 7, "context": "In many application areas outside NLU, artificial neural network techniques have made it possible to train general-purpose feature extractors that, with no or minimal retraining, can extract useful features for a variety of styles of data (Krizhevsky et al., 2012; Zeiler and Fergus, 2014; Donahue et al., 2014).", "startOffset": 239, "endOffset": 311}, {"referenceID": 26, "context": "SNLI consists only of sentences derived from image captions from the Flickr30k corpus (Young et al., 2014), and thus can be treated as a large additional CAPTIONS genre.", "startOffset": 86, "endOffset": 106}, {"referenceID": 19, "context": "The validation phase follows the procedure used in SICK (Marelli et al., 2014b) and SNLI: Workers are presented with pairs of sentences and asked to supply a single label (entailment, contradiction, neutral) for the pair.", "startOffset": 56, "endOffset": 79}, {"referenceID": 10, "context": "The second uses the average of the states of a bidirectional LSTM RNN (BiLSTM; Hochreiter and Schmidhuber, 1997) over the words to compute representations.", "startOffset": 70, "endOffset": 112}, {"referenceID": 3, "context": "In addition to these two baselines, we also implement and evaluate Chen et al.\u2019s (2017) Enhanced Sequential Inference Model (ESIM), which represents the state of the art on SNLI at the time of writing.", "startOffset": 67, "endOffset": 88}, {"referenceID": 23, "context": "All three models are initialized with 300D reference GloVe vectors (840B token version; Pennington et al., 2014).", "startOffset": 67, "endOffset": 112}, {"referenceID": 24, "context": "We use Dropout (Srivastava et al., 2014) for regularization.", "startOffset": 15, "endOffset": 40}, {"referenceID": 12, "context": "We use the Adam (Kingma and Ba, 2015) optimizer with the default parameters.", "startOffset": 16, "endOffset": 37}, {"referenceID": 1, "context": "Data Collection In data collection for NLI, different annotator decisions about the coreference between entities and events across the two sentences in a pair can lead to very different assignments of pairs to labels (de Marneffe et al., 2008; Marelli et al., 2014a; Bowman et al., 2015).", "startOffset": 217, "endOffset": 287}], "year": 2017, "abstractText": "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. In addition to being one of the largest corpora available for the task of NLI, at 433k examples, this corpus improves upon available resources in its coverage: it offers data from ten distinct genres of written and spoken English\u2014making it possible to evaluate systems on nearly the full complexity of the language\u2014and it offers an explicit setting for the evaluation of crossgenre domain adaptation.", "creator": "TeX"}}}