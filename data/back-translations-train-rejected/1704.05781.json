{"id": "1704.05781", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Apr-2017", "title": "Redefining Context Windows for Word Embedding Models: An Experimental Study", "abstract": "Distributional semantic models learn vector representations of words through the contexts they occur in. Although the choice of context (which often takes the form of a sliding window) has a direct influence on the resulting embeddings, the exact role of this model component is still not fully understood. This paper presents a systematic analysis of context windows based on a set of four distinct hyper-parameters. We train continuous Skip-Gram models on two English-language corpora for various combinations of these hyper-parameters, and evaluate them on both lexical similarity and analogy tasks. Notable experimental results are the positive impact of cross-sentential contexts and the surprisingly good performance of right-context windows.", "histories": [["v1", "Wed, 19 Apr 2017 15:41:34 GMT  (106kb,D)", "http://arxiv.org/abs/1704.05781v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["pierre lison", "rey kutuzov"], "accepted": false, "id": "1704.05781"}, "pdf": {"name": "1704.05781.pdf", "metadata": {"source": "CRF", "title": "Redefining Context Windows for Word Embedding Models: An Experimental Study", "authors": ["Pierre Lison", "Andrei Kutuzov"], "emails": ["plison@nr.no", "andreku@ifi.uio.no"], "sections": [{"heading": "1 Introduction", "text": "Distributional semantic models represent words by real-value fixed-dimensional vectors based on the distributional properties of these words observed in large corpora. Recent approaches such as predictive models (Mikolov et al., 2013b) and GloVe (Pennington et al., 2014) have shown that it is possible to estimate dense, low-dimensional vectors (often referred to as embeddings) that are able to capture various functional or current relationships between words. These embeddings are used in a wide range of NLP tasks, including the tagging of parts of language, syntactic parses, called entity recognition, and semantic role labeling; see (Collobert et al., 2011; Lin et al., 2015; Zhou et al., 2016), among others. As recently demonstrated by (Levy et al., 2015), empirical variations between the embedside models are largely based on subparameters."}, {"heading": "2 Background", "text": "This year, more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country and in which it is a country, in which it is a country and in which it is a country, in which it is a country, in which it is a country and in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country and in which it is a country, in which it is a country, in which it is a country and in which it is a country, in which it is a country, in which it is a country and in which it is a country, in which it is a country, in which it is a country and in which it is a country, in which it is a country, in which it is a country, in which it is a country and in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country and in which it is a country and in which it is a country and in which it is a country and in which it is a country and in which it is a country and in which it is a country and in which it is a country and in which it is a country and in which it is a country and in which it is a country and in which it is a country and in which it is a country, a country, a country, a country, a country, a country and a country, a country, a country and a country, a country and a country, a country, a country and a country, a country and a country, a country, a country and a country, a country, a country, a country and a country, a country, a country, a country and a country, a country, a country, a country, a country, a country, a country and a country, a country, a country, a country, a country, a country,"}, {"heading": "3 Experimental setup", "text": "To assess how context windows affect embedding, we trained Continuous Skip-gram with Negative Sampling (SGNS) embedding for different configurations of hyperparameters, the values of which are detailed in Table 1. Specifically, the \"weighting scheme\" encodes how context words should be weighted according to their distance with the focus word. This hyperparameter receives two possible values: a linear weighting scheme corresponding to the default wort2vec, or an alternative scheme using the square root of distancing. Embedding was trained on two English-speaking companies: Gigaword v5 (Parker et al., 2011), a large message wire corpus of approximately 4 billion word tokens, and the English version of OpenSubtitles (Lison and Tiedemann, 2016), a large repository of film and TV subtitles, of approximately 700 million word tokens. The two companies correspond to a single sentence of 7, with one large generic."}, {"heading": "4 Results", "text": "In total, we trained 96 models on Gigaword (GW) and 96 models on OpenSubtitles (OS) 2. Figure 1 illustrates the results of the SGNS embedding to lexical similarity and analogy tasks using different types of context windows. The most important results of the experiments are the following."}, {"heading": "Window size", "text": "As expected for a lexical similarity task (Sch\u00fctzten und Pedersen, 1993), tight context windows with the SimLex999 dataset, which contains semantically similar pairs of words (not just related), perform best. For the analogy task, larger context windows are usually advantageous, but not always: Word embeddings trained on OpenSubtitles perform best with window size 10, while the best results are achieved with the analogy task for Gigaword with window size 2."}, {"heading": "Window position", "text": "Table 2 shows how the position of the context window affects average model performance. Note that symmetrical windows with, for example, 10 words are actually 2 times larger than the \"left\" or \"right\" 2 windows of the same size, since they take into account 10 words both to the left and right of the focus word. This is most likely the reason why symmetrical windows consistently outperform \"one-sided\" windows in the analogy task, as they can contain twice as many contextual inputs. However, the average performance for the semantic similarity task (as the Spearman correlation with the SimLex999 test theorem indicates) does not show the same trend. \"left\" windows are actually worse than symmetrical windows, but \"right\" windows are equivalent to the symmetrical windows for OpenSubtitles and only one percent behind them is sufficient to take into account at least 99 words for many words in context."}, {"heading": "Cross-sentential contexts", "text": "The usefulness of cross-sentential contexts depends on several covariates, especially on the type of corpus and the nature of the evaluation task. In similarity tasks, cross-sentential contexts do not make sense and can even be disadvantageous for large window sizes. However, in analogy tasks, cross-sentential contexts lead to improved results due to the resulting enlarged window. This is particularly pronounced in corpora with short sentences such as OpenSubtitles (see Table 3)."}, {"heading": "Weighting scheme", "text": "Our experimental results show that neither of the two weighting schemes studied (with weights that decrease linearly or with the square root of the distance) offers a consistent advantage on average across all models. However, the square weighting scheme is much slower (since it increases the number of context words to be considered for each focus word), which reduces the training speed with window size 5 by about 25%. Therefore, the linear weighting scheme originally proposed in (Mikolov et al., 2013b) should be preferred."}, {"heading": "Stop words removal", "text": "As shown in Table 4, the removal of stopwords does not really affect the average model performance for the semantic similarity task. However, the analogy task benefits significantly from this filtering for both corpora. Although not shown in the table, the filtering of stopwords also significantly reduces the size of the corpus, reducing the overall effort required to embed the word."}, {"heading": "5 Conclusion", "text": "Our experiments show how important it is to choose the right type of context window when learning text embedding models, the two most prominent results being (1) the positive role of cross-sentential contexts and (2) the fact that, at least for English corpora, right contexts seem to be more important for similarity tasks than left contexts and achieve performance comparable to symmetric windows. In the future, we would like to extend this study to the CBOW algorithm, other weighting schemes (such as the harmonic series used by GloVe) and non-English corpora."}], "references": [{"title": "Georgiana Dinu", "author": ["Marco Baroni"], "venue": "and Germ\u00e1n Kruszewski.", "citeRegEx": "Baroni et al.2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Rejean Ducharme", "author": ["Yoshua Bengio"], "venue": "and Pascal Vincent.", "citeRegEx": "Bengio et al.2003", "shortCiteRegEx": null, "year": 2003}, {"title": "Koray Kavukcuoglu", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen"], "venue": "and Pavel Kuksa.", "citeRegEx": "Collobert et al.2011", "shortCiteRegEx": null, "year": 2011}, {"title": "NonSentential Utterances in Dialogue: Classification, Resolution and Use", "author": ["Raquel Fern\u00e1ndez"], "venue": "Ph.D. thesis, King\u2019s College London", "citeRegEx": "Fern\u00e1ndez.,? \\Q2006\\E", "shortCiteRegEx": "Fern\u00e1ndez.", "year": 2006}, {"title": "A primer on neural network models for natural language processing", "author": ["Yoav Goldberg"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Goldberg.,? \\Q2016\\E", "shortCiteRegEx": "Goldberg.", "year": 2016}, {"title": "Roi Reichart", "author": ["Felix Hill"], "venue": "and Anna Korhonen.", "citeRegEx": "Hill et al.2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Kazuya Kawakami", "author": ["Guillaume Lample", "Miguel Ballesteros", "Sandeep Subramanian"], "venue": "and Chris Dyer.", "citeRegEx": "Lample et al.2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Dependency-based word embeddings", "author": ["Levy", "Goldberg2014] Omer Levy", "Yoav Goldberg"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Levy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2014}, {"title": "Yoav Goldberg", "author": ["Omer Levy"], "venue": "and Ido Dagan.", "citeRegEx": "Levy et al.2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Chris Dyer", "author": ["Chu-Cheng Lin", "Waleed Ammar"], "venue": "and Lori Levin.", "citeRegEx": "Lin et al.2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Opensubtitles2016: Extracting large parallel corpora from movie and TV subtitles", "author": ["Lison", "Tiedemann2016] P. Lison", "J. Tiedemann"], "venue": "In Proceedings of the 10th International Conference on Language Resources and Evaluation", "citeRegEx": "Lison et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lison et al\\.", "year": 2016}, {"title": "Bethard", "author": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J"], "venue": "and David McClosky.", "citeRegEx": "Manning et al.2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Ke Chen", "author": ["Robert Parker", "David Graff", "Junbo Kong"], "venue": "and Kazuaki Maeda.", "citeRegEx": "Parker et al.2011", "shortCiteRegEx": null, "year": 2011}, {"title": "and Christopher D", "author": ["Jeffrey Pennington", "Richard Socher"], "venue": "Manning.", "citeRegEx": "Pennington et al.2014", "shortCiteRegEx": null, "year": 2014}, {"title": "A vector model for syntagmatic and paradigmatic relatedness", "author": ["Sch\u00fctze", "Pedersen1993] Hinrich Sch\u00fctze", "Jan Pedersen"], "venue": "In Proceedings of the 9th Annual Conference of the UW Centre for the New OED and Text Research,", "citeRegEx": "Sch\u00fctze et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Sch\u00fctze et al\\.", "year": 1993}, {"title": "Chris Dyer", "author": ["Shyam Upadhyay", "Manaal Faruqui"], "venue": "and Dan Roth.", "citeRegEx": "Upadhyay et al.2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Endto-end learning of semantic role labeling using recurrent neural networks", "author": ["Zhou", "Xu2015] Jie Zhou", "Wei Xu"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint", "citeRegEx": "Zhou et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2015}], "referenceMentions": [], "year": 2017, "abstractText": "Distributional semantic models learn vector representations of words through the contexts they occur in. Although the choice of context (which often takes the form of a sliding window) has a direct influence on the resulting embeddings, the exact role of this model component is still not fully understood. This paper presents a systematic analysis of context windows based on a set of four distinct hyperparameters. We train continuous SkipGram models on two English-language corpora for various combinations of these hyper-parameters, and evaluate them on both lexical similarity and analogy tasks. Notable experimental results are the positive impact of cross-sentential contexts and the surprisingly good performance of right-context windows.", "creator": "LaTeX with hyperref package"}}}