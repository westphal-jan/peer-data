{"id": "1704.05915", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Apr-2017", "title": "User-driven Intelligent Interface on the Basis of Multimodal Augmented Reality and Brain-Computer Interaction for People with Functional Disabilities", "abstract": "The analysis of the current integration attempts of some modes and use cases of user-machine interaction is presented. The new concept of the user-driven intelligent interface is proposed on the basis of multimodal augmented reality and brain-computer interaction for various applications: in disabilities studies, education, home care, health care, etc. The several use cases of multimodal augmentation are presented. The perspectives of the better human comprehension by the immediate feedback through neurophysical channels by means of brain-computer interaction are outlined. It is shown that brain-computer interface (BCI) technology provides new strategies to overcome limits of the currently available user interfaces, especially for people with functional disabilities. The results of the previous studies of the low end consumer and open-source BCI-devices allow us to conclude that combination of machine learning (ML), multimodal interactions (visual, sound, tactile) with BCI will profit from the immediate feedback from the actual neurophysical reactions classified by ML methods. In general, BCI in combination with other modes of AR interaction can deliver much more information than these types of interaction themselves. Even in the current state the combined AR-BCI interfaces could provide the highly adaptable and personal services, especially for people with functional disabilities.", "histories": [["v1", "Wed, 12 Apr 2017 21:03:52 GMT  (444kb)", "http://arxiv.org/abs/1704.05915v1", "6 pages, 3 figures, 1 table, IEEE First Ukraine Conference on Electrical and Computer Engineering (UKRCON-2017)"], ["v2", "Tue, 15 Aug 2017 22:51:53 GMT  (1941kb)", "http://arxiv.org/abs/1704.05915v2", "10 pages, 11 figures, 1 table, submitted to Future of Information and Communication Conference (FICC) 2018, 5-6 April 2018, Singapore"]], "COMMENTS": "6 pages, 3 figures, 1 table, IEEE First Ukraine Conference on Electrical and Computer Engineering (UKRCON-2017)", "reviews": [], "SUBJECTS": "cs.HC cs.AI cs.DC", "authors": ["s stirenko", "yu gordienko", "t shemsedinov", "o alienin", "yu kochura", "n gordienko", "a rojbi", "j r l\\'opez benito", "e artetxe gonz\\'alez"], "accepted": false, "id": "1704.05915"}, "pdf": {"name": "1704.05915.pdf", "metadata": {"source": "CRF", "title": "User-driven Intelligent Interface on the Basis of Multimodal Augmented Reality and Brain-Computer Interaction for People with Functional Disabilities", "authors": [], "emails": ["sergii.stirenko@gmail.com"], "sections": [{"heading": null, "text": "The new concept of the user-controlled intelligent interface is proposed for various applications based on multimodal augmented reality and brain-computer interaction. It is shown that the different use cases of multimodal augmentation offer new strategies for overcoming the limitations of the currently available user interfaces, especially for people with functional disabilities. The results of the previous studies on the low consumer and open source BCI devices suggest that the combination of machine learning (ML), multimodal interactions (visual, tactile) and BCI will benefit from the immediate feedback."}, {"heading": "A. Tactile Interaction and ML for People with Visual Disabilities", "text": "Graphic information is inaccessible to people with visual impairments or people with special needs. Studies have shown that tactile graphics is the best modality for understanding graphic images for blind users. Normally, graphic images are converted into tactile form by tactile graphic specialists (TGS), which involve non-trivial manual steps. Although some techniques exist to help convert graphic images into a tactile format, the procedures involved are typically time-consuming, expensive and laboratory-intensive. In continuation of this effort, the new software program was developed by authors at the University of Paris, which converts a geographic map into a formatted image file suitable for people with special needs. Advanced image processing techniques and machine learning techniques were used to produce the tactile map and recognize text within the image."}, {"heading": "C. TV-based Visual and Sound AR for Home and Health Care", "text": "This year it is so far that it will only take one year to move on to the next round."}, {"heading": "A. BCI for People with Visual Disabilities", "text": "The application mentioned in Section III.A was developed on the basis of advanced image processing and ML techniques to generate the tactile map and recognize text within the image. Available tools enable automation of the transformation of a visual geographic map into tactile form and help tactile graphics specialists to be more efficient in their work. Previous analysis of the available working methods and possible improvements has opened up the following possibilities to improve cognitive skills in reading various multimedia materials through tactile contacts. Even the low-end consumer and open source BCI devices (such as 1-channel MindWave Mobile by Neurosky or 4-channel Ganglion by OpenBCI) can distinguish such tactical skills in reading different materials through tactile contacts."}, {"heading": "B. BCI for Educational Purposes", "text": "The various successful attempts to combine AR and other interaction modes were demonstrated in Section III.B based on tactile tactile feedback analysis in education, where the simple classification of functions was used to develop tactile metaphors that help students memorize learning items in addition to AR tools through the sense of touch. The aim of the tactile accessory was to generate various vibrotactile metaphors that are easily distinguishable without ambiguity. Experiments showed that vibrotactile feedback is well perceived by the user thanks to the wide range of frequencies and amplitude vibrations provided by the innovative combination of vibrotactuous actuators. The next important step may be to measure whether metaphors are relevant and to effectively help students implement learning concepts (especially in lifelong learning) through additional neurophysical feedback provided by BCI along with tactile actuators \"role in providing the interaction zone.\""}, {"heading": "C. BCI for TV-based Home Care", "text": "The television system based on iDTV technology (described in Section III.C) enables the exchange of general data structures of different types, such as interactive questions and answers (with different input devices) and values obtained from sensors, electronic devices and different devices. It can process calls, events and data synchronization for distributed applications. Combined with neurophysical data obtained by users through BCI devices in intrinsically interactive mode, this technology can be useful for much better communication among older people, relatives, caregivers, doctors, social workers. Communication comprises several platforms: mobile, web, desktop and specialized interactive TV interface with voice and video input for target users. The TV-based AR and BCI can provide a very different way to assess the concentration level of older people directly during their sessions while watching TV programs and broadcasts, choosing food, goods and services. These BCI-based diagnostics can provide non-medical feedback and the remote diagnostics."}, {"heading": "D. BCI for Wearable Health Care", "text": "The differentiated assessment of the different types of daily and chronic exhaustion (including physical) can be achieved by measuring the user's concentration on external stimuli."}, {"heading": "Acknowledgment", "text": "The work was partially supported by the Ukraine-France Collaboration Project (PHC DNIPRO Programme) (http: / / www.campusfrance.org / fr / dnipro), the Twinning Grant of the EU project IncoNet EaP (http: / / www.inco-eap.net /) and the EU project TEMPUS LeAGUe (http: / / tempusleague.eu)."}], "references": [{"title": "A survey of augmented reality", "author": ["M. Billinghurst", "A. Clark", "G. Lee"], "venue": "Foundations and Trends Human\u2013Computer Interaction,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Multimodal Interaction with W3C Standards: Toward Natural User Interfaces to Everything", "author": ["D. Dahl"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2017}, {"title": "Brain-Computer Interfaces", "author": ["A.E. Hassanien", "A.T. Azar"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Fundamentals of wearable computers and augmented reality", "author": ["W. Barfield"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Brain\u2013computer interfaces for communication and control", "author": ["J.R. Wolpaw", "N. Birbaumer", "D.J. McFarland", "G. Pfurtscheller", "T.M. Vaughan"], "venue": "Clinical neurophysiology,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "Electroencephalography: basic principles, clinical applications, and related fields", "author": ["E. Niedermeyer", "da Silva", "F.L. (Eds"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2005}, {"title": "Handbook of psychophysiology", "author": ["J.T. Cacioppo", "L.G. Tassinary", "G. Berntson"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "An introduction to physiological player metrics for evaluating games. In Game Analytics (pp. 585-619)", "author": ["L.E. Nacke"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "New tools for automating tactile geographic map translation", "author": ["N. Bouhlel", "A. Rojbi"], "venue": "In Proceedings of the 16th international ACM SIGACCESS conference on Computers & accessibility (pp", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Conception d'un dispositif de pointagenavigation accessible et adaptatif pour plusieurs cas d'handicap moteur, (http://www2.univ-paris8.fr/ingenierie-cognition/masterhandi/recherche/handicap-dern-ver.pdf)", "author": ["N. Belhabib", "A. Rojbi"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Fuzzy Global segmentation system for video-telephony sequences, presented at The 8th World Multiconferenceon Systemics, Cybermics, cybernetics and Informatics", "author": ["A. Rojbi"], "venue": "Invited sessions in Color Image Processing", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}, {"title": "Dual-mode registration of dynamic contrast-enhanced ultrasound combining tissue and contrast", "author": ["N. Bouhlel", "A. Coron", "G. Barrois", "O. Lucidarme", "S.L. Bridal"], "venue": "sequences, Ultrasonics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Augmented Reality Interface for E2LP: Assistance in Electronic Laboratories through Augmented Reality, Embedded Engineering Education, Advances in Intelligent Systems and Computing", "author": ["E. Artetxe Gonz\u00e1lez", "F. Souvestre", "J.R. L\u00f3pez Benito"], "venue": "(Volume 421,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "E2LP: A Unified Embedded Engineering Learning Platform", "author": ["I. Kastelan", "J.R. Lopez Benito", "E. Artetxe Gonzalez", "J. Piwinski", "M. Barak", "M. Temerinac"], "venue": "Microprocessors and Microsystems, Elsevier,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "A Review of Accelerometer Based Physical Activity Measurement", "author": ["Yao Meng", "HeeCheol Kim"], "venue": "Proceedings of the International Conference on IT Convergence and Security", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Synergy of volunteer measurements and volunteer computing for effective data collecting, processing, simulating and analyzing on a worldwide scale", "author": ["N. Gordienko", "O. Lodygensky", "G. Fedak", "Y. Gordienko"], "venue": "In Proc. IEEE 38th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO) (pp. 193-198)", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Multi-Parametric Statistical Method for Estimation of Accumulated Fatigue by Sensors in Ordinary Gadgets", "author": ["N. Gordienko"], "venue": "arXiv preprint arXiv:1605.04984", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "The current development of various ICTs, especially related with augmented reality (AR) [1], multimodal user interfaces (MUI) [2], brain-computer interfaces (BCI) [3], machine learning techniques for interpretation of complex signals [4], wearable electronics (like smart glasses, watches, bracelets, heart beat monitors, and others gadgets) [5] open the", "startOffset": 88, "endOffset": 91}, {"referenceID": 1, "context": "The current development of various ICTs, especially related with augmented reality (AR) [1], multimodal user interfaces (MUI) [2], brain-computer interfaces (BCI) [3], machine learning techniques for interpretation of complex signals [4], wearable electronics (like smart glasses, watches, bracelets, heart beat monitors, and others gadgets) [5] open the", "startOffset": 126, "endOffset": 129}, {"referenceID": 2, "context": "The current development of various ICTs, especially related with augmented reality (AR) [1], multimodal user interfaces (MUI) [2], brain-computer interfaces (BCI) [3], machine learning techniques for interpretation of complex signals [4], wearable electronics (like smart glasses, watches, bracelets, heart beat monitors, and others gadgets) [5] open the", "startOffset": 163, "endOffset": 166}, {"referenceID": 3, "context": "The current development of various ICTs, especially related with augmented reality (AR) [1], multimodal user interfaces (MUI) [2], brain-computer interfaces (BCI) [3], machine learning techniques for interpretation of complex signals [4], wearable electronics (like smart glasses, watches, bracelets, heart beat monitors, and others gadgets) [5] open the", "startOffset": 342, "endOffset": 345}, {"referenceID": 4, "context": "Some of the most promising UDII are based on psychophysiological data, like heart beat monitoring (HRM), electrocardiogram (ECG), electroencephalography (EEG) and that can be used to infer users\u2019 mental states in different scenarios, although they have become more popular recently to evaluate user experience in various applications [6-7].", "startOffset": 334, "endOffset": 339}, {"referenceID": 5, "context": "Some of the most promising UDII are based on psychophysiological data, like heart beat monitoring (HRM), electrocardiogram (ECG), electroencephalography (EEG) and that can be used to infer users\u2019 mental states in different scenarios, although they have become more popular recently to evaluate user experience in various applications [6-7].", "startOffset": 334, "endOffset": 339}, {"referenceID": 6, "context": "These electrodes measure the electrical current differentials stemming from the increase of sweat activity, which often are consequences of the personal excitement [8-9].", "startOffset": 164, "endOffset": 169}, {"referenceID": 7, "context": "These electrodes measure the electrical current differentials stemming from the increase of sweat activity, which often are consequences of the personal excitement [8-9].", "startOffset": 164, "endOffset": 169}, {"referenceID": 8, "context": "The software is designed to semi-automate the translation from visual maps to tactile versions, and to help TGS to be faster and more efficient in producing the tactile geographic map [10-14].", "startOffset": 184, "endOffset": 191}, {"referenceID": 9, "context": "The software is designed to semi-automate the translation from visual maps to tactile versions, and to help TGS to be faster and more efficient in producing the tactile geographic map [10-14].", "startOffset": 184, "endOffset": 191}, {"referenceID": 10, "context": "The software is designed to semi-automate the translation from visual maps to tactile versions, and to help TGS to be faster and more efficient in producing the tactile geographic map [10-14].", "startOffset": 184, "endOffset": 191}, {"referenceID": 11, "context": "The software is designed to semi-automate the translation from visual maps to tactile versions, and to help TGS to be faster and more efficient in producing the tactile geographic map [10-14].", "startOffset": 184, "endOffset": 191}, {"referenceID": 12, "context": "One of its main innovations consisted in creation of the totally non-obtrusive Augmented Reality Interface (ARI) by authors from CreativiTIC Innova SL that detects different electronic boards and superposes relevant information over their components, serving also as a guide through laboratory exercises [15-16].", "startOffset": 304, "endOffset": 311}, {"referenceID": 13, "context": "One of its main innovations consisted in creation of the totally non-obtrusive Augmented Reality Interface (ARI) by authors from CreativiTIC Innova SL that detects different electronic boards and superposes relevant information over their components, serving also as a guide through laboratory exercises [15-16].", "startOffset": 304, "endOffset": 311}, {"referenceID": 14, "context": "[18].", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "The new method was proposed recently by authors from National Technical University of Ukraine \"Igor Sikorsky Kyiv Polytechnic Institute\" to monitor the level of currently accumulated fatigue and estimate it by the several statistical methods [19].", "startOffset": 242, "endOffset": 246}, {"referenceID": 16, "context": "The method can be used in practice for ordinary people in everyday situations (to estimate their fatigue, give tips about it and advice on context related information) [20].", "startOffset": 168, "endOffset": 172}], "year": 2017, "abstractText": "The analysis of the current integration attempts of some modes and use cases of user-machine interaction is presented. The new concept of the user-driven intelligent interface is proposed on the basis of multimodal augmented reality and brain-computer interaction for various applications: in disabilities studies, education, home care, health care, etc. The several use cases of multimodal augmentation are presented. The perspectives of the better human comprehension by the immediate feedback through neurophysical channels by means of brain-computer interaction are outlined. It is shown that brain\u2013 computer interface (BCI) technology provides new strategies to overcome limits of the currently available user interfaces, especially for people with functional disabilities. The results of the previous studies of the low end consumer and open-source BCI-devices allow us to conclude that combination of machine learning (ML), multimodal interactions (visual, sound, tactile) with BCI will profit from the immediate feedback from the actual neurophysical reactions classified by ML methods. In general, BCI in combination with other modes of AR interaction can deliver much more information than these types of interaction themselves. Even in the current state the combined AR-BCI interfaces could provide the highly adaptable and personal services, especially for people with functional disabilities. Keywords\u2014 augmented reality, interfaces for accessibility, multimodal user interface, brain-computer interface, eHealth, machine learning, machine-to-machine interactions, human-tohuman interactions, human-to-machine interactions", "creator": "Microsoft\u00ae Office Word 2007"}}}