{"id": "1704.06767", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Apr-2017", "title": "Risk Minimization Framework for Multiple Instance Learning from Positive and Unlabeled Bags", "abstract": "Multiple instance learning (MIL) is a variation of traditional supervised learning problems where data (referred to as bags) are composed of sub-elements (referred to as instances) and only bag labels are available. MIL has a variety of applications such as content-based image retrieval, text categorization and medical diagnosis. Most of the previous work for MIL assume that the training bags are fully labeled. However, it is often difficult to obtain an enough number of labeled bags in practical situations, while many unlabeled bags are available. A learning framework called PU learning (positive and unlabeled learning) can address this problem. In this paper, we propose a convex PU learning method to solve an MIL problem. We experimentally show that the proposed method achieves better performance with significantly lower computational costs than an existing method for PU-MIL.", "histories": [["v1", "Sat, 22 Apr 2017 08:50:19 GMT  (234kb)", "http://arxiv.org/abs/1704.06767v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["han bao", "tomoya sakai", "issei sato", "masashi sugiyama"], "accepted": false, "id": "1704.06767"}, "pdf": {"name": "1704.06767.pdf", "metadata": {"source": "CRF", "title": "Risk Minimization Framework for Multiple Instance Learning from Positive and Unlabeled Bags", "authors": ["Han Bao", "Tomoya Sakai", "Issei Sato", "Masashi Sugiyama"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 4.06 767v 1 [cs.L G] 2"}, {"heading": "1 Introduction", "text": "This year, it is more than ever in the history of the city, where it is so far that it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, a place, a place, a place, a place, a place where it is about."}, {"heading": "2 Problem Formulation and Related Work", "text": "In this section, we will formulate the problems we discuss in this paper (see Figure 1) and review the related work."}, {"heading": "2.1 Ordinary Binary Classification", "text": "Let x-Rd be a d-dimensional feature vector and y-vector and y-vector (+ 1, \u2212 1) its corresponding class name. In the usual problem of binary classification, we construct from a training data set D = {(xi, yi)} Ni = 1, where N is the number of training samples. Here, we use a linear parameter model for g: g (x) = \u03b1 (x) + \u03b2, where \u03b1 denotes the transpose, \u03b1-Rm is a m-dimensional parameter vector, \u03b2-R is a bias parameter and wire: Rd \u2192 Rm is a vector of basic functions. The support vector engine (SVM) [6] is one of the standard methods for forming a binary classifier. The optimization problem of SVM follows as follows: Rd \u2192 Rm is a vector of basic functions."}, {"heading": "2.2 Multiple Instance Learning", "text": "Here we formulate the problem of multiple instance learning (MIL) and review an existing method. The formulation in the following P (A) denotes the max. instance of A. Let X = max. instance of A. The problem is to construct a binary classifier: f (X) = character (g (X))), which contains n instances whose dimensions are d, and Y (Rd) {+ 1, \u2212 1} a pocket label corresponding to X. The problem is to construct a binary classifier: f (X) = character (g (X))). The power quantity of A is a set of all subsets of A, including the minimum quantity, and A itself. In the MIL setting, bags belong to P (Rd), i.e. bags consist of some elements in the Rd.5 instance of k."}, {"heading": "2.3 Learning from Positive and Unlabeled Data", "text": "Here we formulate the binary classification problem of learning positive and blank instances and reviewing existing methods on the basis of the classification. Formulation We assume that positive samples (xPi) NP i = 1 and blank samples (xUi) NU i = 1 are generated as follows: {xPi} NP i = 1 i.i.d. p + (x) p + (x) p + (x) p + (x) p (x) p (x) p (x) p (x) p (x) p (x) p (x) p (x) p (x) p (x) + (x) p (p \u2212 P \u2212 i = 1 i.d. \u2212 p (x) p (x) p (x): = 1) p (x) p (x) p (x) p (x) p (x) p (x), (x). Our goal is to construct a binary classification (1) from positive samples only and blank samples."}, {"heading": "3 Positive and Unlabeled Set Kernel Classifier", "text": "In this section we propose a convex method for PU-MIL called PU-SKC (positive and unlabeled set kernel classifier)."}, {"heading": "3.1 Multiple Instance Learning from Positive and Unlabeled Bags", "text": "The purpose of PU-MIL is to construct the bag level classifier (3) from a positively labeled training dataset DP = {(XPb, Yb = + 1)} NP b = 1 and an unlabeled training dataset DU = {XUb \u2032} NU b \u2032 = 1, with NP and NU indicating the number of positive pockets in DP and the number of unlabeled pockets in YU respectively."}, {"heading": "3.2 Formulation", "text": "As we mentioned in Section 2.3, du Plessis et al. [19,20] formulates the PU learning problem in the empirical risk mitigation framework. If we use a loss function l (z) such that l (z) \u2212 l (\u2212 z) = \u2212 z, we have the following objective function: J (g) = \u03c0EP [\u2212 g (X)] + EU [(\u2012 g (X)]]. (14) Here we use a linear in-parameter model with the defined core function as classifier: g (X) = \u03b1 (\u03b1) + \u03b2, (15) where it is the vector of the basic functions: \u03c6 (X) = k-min-max (X, P 1)... k-max (X, P NP) k-min-max (X, NP) k-max (X U 1)... k-min-max (X, U-1)."}, {"heading": "3.3 Bag-Level Class Prior Estimation", "text": "By simply extending the version described in Appendix A to the instance level, an algorithm can be achieved for pre-bag level estimation.The difference is in the basic functions used in the empirical estimator of r (x).We use the Minimax polynomic kernel (5) to obtain the basic functions at the bag level (16)."}, {"heading": "4 Experiments", "text": "In this section, we compare the proposed method7 experimentally with the existing methodology (see Appendix B) and answer the following research questions: Q1: Does the proposed methodology work well regardless of the actual previous class? Q2: Is the proposed methodology mathematically efficient?"}, {"heading": "4.1 Dataset", "text": "We use standard MIL datasets: Musk and Corel8. Details of these benchmark datasets are listed in Table 2.7. Implementation is available at https: / / github.com / levelfour / pumil. 8 http: / / www.cs.columbia.edu / ~ andrews / mil / datasets.html9Algorithm 1 Generation of Training / Test Sets for Benchmark MIL DatasetsInput: DP: original positive bags, DN: original negative bags, \u03c0: true bag-level class before, L: # {labeled positive bags}, U: # {labeled positive bags}, T: # {test bags} 1: DL-DP, DL: = L 2: DP-DL 3: NPU-B (U + T, \u03c0) 4: NNU + T \u2212 N P-U-5: = D-P-P-P-D-U-D-D-U-U-U-U-U-U-U-U-D-U-U-U-U-D-D-U-U-U-U-D-U-U-D-U-U-U-U-U-U-D-D-U-U-D-U-U-U-U-U-U-U-D-D-D-U-U-U-D-U-U-U-D-U-U-U-U-U-U-D-D-U-D-D-U-D-U-U-D-U-U-U-U-D-U-U-U-U-U-U-D-D-U-U-U-D-U-U-U-U-U-D-U-U-U-U-D-U-U-U-D-U-U-D-U-U-U-D-U-U-D-U-U-U-U-D-U-U-U-U-U-D-U-U-U-D-U-U-U-U-U-U-D-U-U-D-U-U-U-D-U-U-U-U-U-U-U-U-"}, {"heading": "4.2 Evaluation Method", "text": "Hyperparameters (the degree parameter \u03c1 in the polynomial nucleus (5) and the regularization parameter \u03bb in the objective function (17) are selected by means of a 5-fold cross-validation from \u03c1 [1, 2, 3] and \u03bb [100, 10 \u2212 3, 10 \u2212 6]. We use the range below the operating curve of the receiver [5] as an evaluation yardstick that is robust against the class imbalance, i.e. the situation in which the class before \u03c0 exhibits extremely high or low values. AUC is defined as follows: AUC: = EP [EN (g (xP) [EN (xP) \u2265 g (xN)]] = 1 \u2212 EP [EN (xP) < g (xP) < g (xN)]] = 1 \u2212 EP [EP] = 1 \u2212 EP (EN [EP) = 1 \u2212 EP-1 (EN [E) = 1 (UE) = UE-1 (UE-1 (UE))."}, {"heading": "4.3 Results", "text": "In this section we present the experimental results and provide answers to the research questions."}, {"heading": "A1: The proposed method outperforms the existing method regardless of the true bag-level class prior.", "text": "Table 3 shows averages with standard deviations of predictions, which are performed 50 times in each class beforehand. Bold surfaces represent the best methods in each class beforehand. This is tested by the unilateral t-test with a significant level of 5% (first, the higher method is selected as the best method, then the other method is checked by the unilateral ttest if it is competitive or not). As shown in Table 3, PU-SKC exceeds the existing method puMIL [24] among the various class priorities. Note that the true class before Table 3 means the predefined value for generating data sets (see Algorithm 1), not the estimated class before the learning process (see Section 3.3)."}, {"heading": "A2: The proposed method is much more computationally efficient than the existing method.", "text": "Next, we compare the execution time between the proposed method and the existing method.The result is shown in Figure 2. This result shows that PU-SKC is mathematically much more efficient than the existing method.11"}, {"heading": "5 Conclusion", "text": "In this paper, we considered a multiple instance learning problem when only positive and unlabeled bags are available, which does not require all training bags to be labeled. We proposed a convex method, PU-SKC, to solve the PU multiple classification, which is based on the convex formulation of PU learning [20] and the specified core [11]. PU-SKC performed better than the existing PU multiple classification method [24] in classifying MIL benchmark data sets (drug activity prediction and image annotation). Furthermore, we confirmed that the proposed method was mathematically considerably more efficient than the existing method through the experiment."}, {"heading": "B Multiple Instance Learning from Positive and Unlabeled Bags", "text": "Wu et al. (24) Where is the PU-MIL problematic for the PUMIL problematic (PUMIL = PUMIL = PUMIL = PUMIL = PUMIL = PUMIL = PUMIL = PUMIL = PUMIL = PUMIL = PUMIL = PUMIL = PUMIL = PUMIL = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = PUR = P"}], "references": [{"title": "Support vector machines for multiple-instance learning", "author": ["S. Andrews", "I. Tsochantaridis", "T. Hofmann"], "venue": "Advances in Neural Information Processing Systems 15. pp. 577\u2013584. MIT Press, Cambridge, MA, USA", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "Visual tracking with online multiple instance learning", "author": ["B. Babenko", "M.H. Yang", "S. Belongie"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition. pp. 983\u2013990", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Model-directed learning of production rules", "author": ["B.G. Buchanan", "T.M. Mitchell"], "venue": "Tech. rep., Stanford, CA, USA", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1977}, {"title": "Multiple instance learning for sparse positive bags", "author": ["R.C. Bunescu", "R.J. Mooney"], "venue": "Proceedings of the 24th International Conference on Machine Learning. pp. 105\u2013112. ACM, New York, NY, USA", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "AUC optimization vs", "author": ["C. Cortes", "M. Mohri"], "venue": "error rate minimization. In: Proceedings of the 16th International Conference on Neural Information Processing Systems. pp. 313\u2013320. MIT Press, Cambridge, MA, USA", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "Support-vector networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Mach. Learn. 20(3), 273\u2013297", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1995}, {"title": "An inductive approach to solving the imperfect theory problem", "author": ["T.G. Dietterich", "N.S. Flann"], "venue": "Proceedings of the American Association for Artificial Intelligence Spring Symposium Series: Explanation-Based Learning. pp. 42\u201346", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1988}, {"title": "Solving the multiple instance problem with axis-parallel rectangles", "author": ["T.G. Dietterich", "R.H. Lathrop", "T. Lozano-P\u00e9rez"], "venue": "Artificial Intelligence 89(1), 31\u201371", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1997}, {"title": "Multiple-instance learning algorithms for computer-aided detection", "author": ["M.M. Dundar", "G. Fung", "B. Krishnapuram", "R.B. Rao"], "venue": "IEEE Transactions on Biomedical Engineering 55(3), 1015\u20131021", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "MILIS: Multiple instance learning with instance selection", "author": ["Z. Fu", "A. Robles-Kelly", "J. Zhou"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 33(5), 958\u2013977", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Multi-instance kernels", "author": ["T. G\u00e4rtner", "P.A. Flach", "A. Kowalczyk", "A.J. Smola"], "venue": "Proceedings of the 19th International Conference on Machine Learning. pp. 179\u2013 186. Morgan Kaufmann", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2002}, {"title": "Scale and rotation invariant color features for weakly-supervised object learning in 3D space", "author": ["A. Kanezaki", "T. Harada", "Y. Kuniyoshi"], "venue": "International Conference on Computer Vision Workshops. pp. 617\u2013624", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Multiple instance learning for soft bags via top instances", "author": ["W. Li", "N. Vasconcelos"], "venue": "The IEEE Conference on Computer Vision and Pattern Recognition", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "A convex method for locating regions of interest with multi-instance learning", "author": ["Y.F. Li", "J.T. Kwok", "I.W. Tsang", "Z.H. Zhou"], "venue": "Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases: Part II. pp. 15\u201330. ECML PKDD \u201909", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Applications of artificial intelligence for organic chemistry : the DENDRAL project", "author": ["R.K. Lindsay"], "venue": "McGraw-Hill Book Co New York", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1980}, {"title": "A framework for multiple-instance learning", "author": ["O. Maron", "T. Lozano-P\u00e9rez"], "venue": "Advances in Neural Information Processing Systems 10. pp. 570\u2013576. MIT Press, Cambridge, MA, USA", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1998}, {"title": "Multiple-instance learning for natural scene classification", "author": ["O. Maron", "A.L. Ratan"], "venue": "Proceedings of the 15th International Conference on Machine Learning. pp. 341\u2013349. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1998}, {"title": "Scene recognition and weakly supervised object localization with deformable part-based models", "author": ["M. Pandey", "S. Lazebnik"], "venue": "Proceedings of the 2011 International Conference on Computer Vision. pp. 1307\u20131314. IEEE Computer Society, Washington, DC, USA", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Analysis of learning from positive and unlabeled data", "author": ["M.C. du Plessis", "G. Niu", "M. Sugiyama"], "venue": "Advances in Neural Information Processing Systems 27, pp. 703\u2013711. Curran Associates, Inc.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Convex formulation for learning from positive and unlabeled data", "author": ["M.C. du Plessis", "G. Niu", "M. Sugiyama"], "venue": "Proceedings of the 32nd International Conference on Machine Learning. pp. 1386\u20131394. JMLR Workshop and Conference Proceedings", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Class prior estimation from positive and unlabeled data", "author": ["M.C. du Plessis", "M. Sugiyama"], "venue": "IEICE Transactions on Information and Systems 97(5), 1358\u20131362", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Multiple instance learning for classification of dementia in brain MRI", "author": ["T. Tong", "R. Wolz", "Q. Gao", "R. Guerrero", "J.V. Hajnal", "D. Rueckert"], "venue": "Medical Image Analysis 18(5), 808\u2013818", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Solving the multiple-instance problem: A lazy learning approach", "author": ["J. Wang", "J.D. Zucker"], "venue": "Proceedings of the 17th International Conference on Machine Learning. pp. 1119\u20131126. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2000}, {"title": "Multi-instance learning from positive and unlabeled bags", "author": ["J. Wu", "X. Zhu", "C. Zhang", "Z. Cai"], "venue": "Proceeding of the 18th Pacific-Asia Conference on Knowledge Discovery and Data Mining. pp. 237\u2013248. Springer International Publishing", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep multiple instance learning for image classification and auto-annotation", "author": ["J. Wu", "Yinan Yu", "Chang Huang", "Kai Yu"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition pp. 3460\u20133469", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "EM-DD: An improved multiple-instance learning technique", "author": ["Q. Zhang", "S.A. Goldman"], "venue": "Advances in Neural Information Processing Systems 13. pp. 1073\u20131080. MIT Press", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2001}, {"title": "Multi-instance learning by treating instances as non-i.i.d. samples", "author": ["Z.H. Zhou", "Y.Y. Sun", "Y.F. Li"], "venue": "Proceedings of the 26th Annual International Conference on Machine Learning", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "On the relation between multi-instance learning and semisupervised learning", "author": ["Z.H. Zhou", "J.M. Xu"], "venue": "Proceedings of the 24th International Conference on Machine Learning. pp. 1167\u20131174. ACM, New York, NY, USA", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 7, "context": "Multiple instance learning (MIL) [8] is a learning problem with bags and instances.", "startOffset": 33, "endOffset": 36}, {"referenceID": 2, "context": "MIL is applicable to a wide range of real-world problems such as molecule behavior prediction [3,15], drug activity prediction [8], domain theory [7], content-based image retrieval [17,13,25], visual tracking [2], object detection [18,12], text categorization [1] and medical diagnosis [9,22].", "startOffset": 94, "endOffset": 100}, {"referenceID": 14, "context": "MIL is applicable to a wide range of real-world problems such as molecule behavior prediction [3,15], drug activity prediction [8], domain theory [7], content-based image retrieval [17,13,25], visual tracking [2], object detection [18,12], text categorization [1] and medical diagnosis [9,22].", "startOffset": 94, "endOffset": 100}, {"referenceID": 7, "context": "MIL is applicable to a wide range of real-world problems such as molecule behavior prediction [3,15], drug activity prediction [8], domain theory [7], content-based image retrieval [17,13,25], visual tracking [2], object detection [18,12], text categorization [1] and medical diagnosis [9,22].", "startOffset": 127, "endOffset": 130}, {"referenceID": 6, "context": "MIL is applicable to a wide range of real-world problems such as molecule behavior prediction [3,15], drug activity prediction [8], domain theory [7], content-based image retrieval [17,13,25], visual tracking [2], object detection [18,12], text categorization [1] and medical diagnosis [9,22].", "startOffset": 146, "endOffset": 149}, {"referenceID": 16, "context": "MIL is applicable to a wide range of real-world problems such as molecule behavior prediction [3,15], drug activity prediction [8], domain theory [7], content-based image retrieval [17,13,25], visual tracking [2], object detection [18,12], text categorization [1] and medical diagnosis [9,22].", "startOffset": 181, "endOffset": 191}, {"referenceID": 12, "context": "MIL is applicable to a wide range of real-world problems such as molecule behavior prediction [3,15], drug activity prediction [8], domain theory [7], content-based image retrieval [17,13,25], visual tracking [2], object detection [18,12], text categorization [1] and medical diagnosis [9,22].", "startOffset": 181, "endOffset": 191}, {"referenceID": 24, "context": "MIL is applicable to a wide range of real-world problems such as molecule behavior prediction [3,15], drug activity prediction [8], domain theory [7], content-based image retrieval [17,13,25], visual tracking [2], object detection [18,12], text categorization [1] and medical diagnosis [9,22].", "startOffset": 181, "endOffset": 191}, {"referenceID": 1, "context": "MIL is applicable to a wide range of real-world problems such as molecule behavior prediction [3,15], drug activity prediction [8], domain theory [7], content-based image retrieval [17,13,25], visual tracking [2], object detection [18,12], text categorization [1] and medical diagnosis [9,22].", "startOffset": 209, "endOffset": 212}, {"referenceID": 17, "context": "MIL is applicable to a wide range of real-world problems such as molecule behavior prediction [3,15], drug activity prediction [8], domain theory [7], content-based image retrieval [17,13,25], visual tracking [2], object detection [18,12], text categorization [1] and medical diagnosis [9,22].", "startOffset": 231, "endOffset": 238}, {"referenceID": 11, "context": "MIL is applicable to a wide range of real-world problems such as molecule behavior prediction [3,15], drug activity prediction [8], domain theory [7], content-based image retrieval [17,13,25], visual tracking [2], object detection [18,12], text categorization [1] and medical diagnosis [9,22].", "startOffset": 231, "endOffset": 238}, {"referenceID": 0, "context": "MIL is applicable to a wide range of real-world problems such as molecule behavior prediction [3,15], drug activity prediction [8], domain theory [7], content-based image retrieval [17,13,25], visual tracking [2], object detection [18,12], text categorization [1] and medical diagnosis [9,22].", "startOffset": 260, "endOffset": 263}, {"referenceID": 8, "context": "MIL is applicable to a wide range of real-world problems such as molecule behavior prediction [3,15], drug activity prediction [8], domain theory [7], content-based image retrieval [17,13,25], visual tracking [2], object detection [18,12], text categorization [1] and medical diagnosis [9,22].", "startOffset": 286, "endOffset": 292}, {"referenceID": 21, "context": "MIL is applicable to a wide range of real-world problems such as molecule behavior prediction [3,15], drug activity prediction [8], domain theory [7], content-based image retrieval [17,13,25], visual tracking [2], object detection [18,12], text categorization [1] and medical diagnosis [9,22].", "startOffset": 286, "endOffset": 292}, {"referenceID": 7, "context": "A lot of approaches for MIL have been developed [8,16,26,1,11,23], which are classified into two groups in general: (1) The methods in the first group are based on generative modeling, including", "startOffset": 48, "endOffset": 65}, {"referenceID": 15, "context": "A lot of approaches for MIL have been developed [8,16,26,1,11,23], which are classified into two groups in general: (1) The methods in the first group are based on generative modeling, including", "startOffset": 48, "endOffset": 65}, {"referenceID": 25, "context": "A lot of approaches for MIL have been developed [8,16,26,1,11,23], which are classified into two groups in general: (1) The methods in the first group are based on generative modeling, including", "startOffset": 48, "endOffset": 65}, {"referenceID": 0, "context": "A lot of approaches for MIL have been developed [8,16,26,1,11,23], which are classified into two groups in general: (1) The methods in the first group are based on generative modeling, including", "startOffset": 48, "endOffset": 65}, {"referenceID": 10, "context": "A lot of approaches for MIL have been developed [8,16,26,1,11,23], which are classified into two groups in general: (1) The methods in the first group are based on generative modeling, including", "startOffset": 48, "endOffset": 65}, {"referenceID": 22, "context": "A lot of approaches for MIL have been developed [8,16,26,1,11,23], which are classified into two groups in general: (1) The methods in the first group are based on generative modeling, including", "startOffset": 48, "endOffset": 65}, {"referenceID": 15, "context": "the diverse density [16] and its extension, the expectation-maximization diverse density (EM-DD) [26].", "startOffset": 20, "endOffset": 24}, {"referenceID": 25, "context": "the diverse density [16] and its extension, the expectation-maximization diverse density (EM-DD) [26].", "startOffset": 97, "endOffset": 101}, {"referenceID": 0, "context": "The multiple-instance support vector machine (MI-SVM) [1] is an approach based on SVMs.", "startOffset": 54, "endOffset": 57}, {"referenceID": 13, "context": "The key-instance support vector machine (KI-SVM) [14] converts MI-SVM into a convex problem by using a discrete vector, but it is still difficult to optimize due to a large number of optimization variables.", "startOffset": 49, "endOffset": 53}, {"referenceID": 10, "context": "[11] introduced set kernels (a.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "Our contribution in this paper is to propose a novel PU-MIL method based on the risk minimization framework [20].", "startOffset": 108, "endOffset": 112}, {"referenceID": 0, "context": "Through experiments, we demonstrate that the proposed method combined with the minimax kernel [1] compares favorably with an existing method.", "startOffset": 94, "endOffset": 97}, {"referenceID": 18, "context": "2, we review existing methods for PU learning [19,20] and MIL [11], on which our proposed method 4 The fact that the consumer did not buy an album does not directly mean that the album is not attracting (negative).", "startOffset": 46, "endOffset": 53}, {"referenceID": 19, "context": "2, we review existing methods for PU learning [19,20] and MIL [11], on which our proposed method 4 The fact that the consumer did not buy an album does not directly mean that the album is not attracting (negative).", "startOffset": 46, "endOffset": 53}, {"referenceID": 10, "context": "2, we review existing methods for PU learning [19,20] and MIL [11], on which our proposed method 4 The fact that the consumer did not buy an album does not directly mean that the album is not attracting (negative).", "startOffset": 62, "endOffset": 66}, {"referenceID": 10, "context": "Positive and Negative set kernels [11] sMIL [4] KI-SVM [14] miGraph [27] MI-SVM [1] MissSVM [28] soft-bag SVM [13] dMIL [25]", "startOffset": 34, "endOffset": 38}, {"referenceID": 3, "context": "Positive and Negative set kernels [11] sMIL [4] KI-SVM [14] miGraph [27] MI-SVM [1] MissSVM [28] soft-bag SVM [13] dMIL [25]", "startOffset": 44, "endOffset": 47}, {"referenceID": 13, "context": "Positive and Negative set kernels [11] sMIL [4] KI-SVM [14] miGraph [27] MI-SVM [1] MissSVM [28] soft-bag SVM [13] dMIL [25]", "startOffset": 55, "endOffset": 59}, {"referenceID": 26, "context": "Positive and Negative set kernels [11] sMIL [4] KI-SVM [14] miGraph [27] MI-SVM [1] MissSVM [28] soft-bag SVM [13] dMIL [25]", "startOffset": 68, "endOffset": 72}, {"referenceID": 0, "context": "Positive and Negative set kernels [11] sMIL [4] KI-SVM [14] miGraph [27] MI-SVM [1] MissSVM [28] soft-bag SVM [13] dMIL [25]", "startOffset": 80, "endOffset": 83}, {"referenceID": 27, "context": "Positive and Negative set kernels [11] sMIL [4] KI-SVM [14] miGraph [27] MI-SVM [1] MissSVM [28] soft-bag SVM [13] dMIL [25]", "startOffset": 92, "endOffset": 96}, {"referenceID": 12, "context": "Positive and Negative set kernels [11] sMIL [4] KI-SVM [14] miGraph [27] MI-SVM [1] MissSVM [28] soft-bag SVM [13] dMIL [25]", "startOffset": 110, "endOffset": 114}, {"referenceID": 24, "context": "Positive and Negative set kernels [11] sMIL [4] KI-SVM [14] miGraph [27] MI-SVM [1] MissSVM [28] soft-bag SVM [13] dMIL [25]", "startOffset": 120, "endOffset": 124}, {"referenceID": 23, "context": "3) puMIL [24]", "startOffset": 9, "endOffset": 13}, {"referenceID": 23, "context": "4, we experimentally compare the proposed method (PU-SKC) with the existing method (puMIL) [24].", "startOffset": 91, "endOffset": 95}, {"referenceID": 5, "context": "The support vector machine (SVM) [6] is one of the standard methods for training a binary classifier.", "startOffset": 33, "endOffset": 36}, {"referenceID": 10, "context": "[11] proposed set kernels (multiple instance kernels).", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] showed that the statistic kernel with the minimax statistics (4) for s and the polynomial kernel for k outperforms other set kernels in the standard MIL:", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19,20] proposed methods based on the empirical risk minimization framework to learn only from positive and unlabeled samples.", "startOffset": 0, "endOffset": 7}, {"referenceID": 19, "context": "[19,20] proposed methods based on the empirical risk minimization framework to learn only from positive and unlabeled samples.", "startOffset": 0, "endOffset": 7}, {"referenceID": 18, "context": "[19,20] formulated the PU learning problem in the empirical risk minimization framework.", "startOffset": 0, "endOffset": 7}, {"referenceID": 19, "context": "[19,20] formulated the PU learning problem in the empirical risk minimization framework.", "startOffset": 0, "endOffset": 7}, {"referenceID": 19, "context": "[20] reported that it achieved the best performance in the ordinary PU classification setting.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "Hyperparameters (the degree parameter \u03c1 in the polynomial kernel (5) and the regularization parameter \u03bb in the objective function (17)) are selected via 5-fold cross-validation from \u03c1 \u2208 [1, 2, 3] and \u03bb \u2208 [10, 10, 10].", "startOffset": 186, "endOffset": 195}, {"referenceID": 1, "context": "Hyperparameters (the degree parameter \u03c1 in the polynomial kernel (5) and the regularization parameter \u03bb in the objective function (17)) are selected via 5-fold cross-validation from \u03c1 \u2208 [1, 2, 3] and \u03bb \u2208 [10, 10, 10].", "startOffset": 186, "endOffset": 195}, {"referenceID": 2, "context": "Hyperparameters (the degree parameter \u03c1 in the polynomial kernel (5) and the regularization parameter \u03bb in the objective function (17)) are selected via 5-fold cross-validation from \u03c1 \u2208 [1, 2, 3] and \u03bb \u2208 [10, 10, 10].", "startOffset": 186, "endOffset": 195}, {"referenceID": 9, "context": "Hyperparameters (the degree parameter \u03c1 in the polynomial kernel (5) and the regularization parameter \u03bb in the objective function (17)) are selected via 5-fold cross-validation from \u03c1 \u2208 [1, 2, 3] and \u03bb \u2208 [10, 10, 10].", "startOffset": 204, "endOffset": 216}, {"referenceID": 9, "context": "Hyperparameters (the degree parameter \u03c1 in the polynomial kernel (5) and the regularization parameter \u03bb in the objective function (17)) are selected via 5-fold cross-validation from \u03c1 \u2208 [1, 2, 3] and \u03bb \u2208 [10, 10, 10].", "startOffset": 204, "endOffset": 216}, {"referenceID": 9, "context": "Hyperparameters (the degree parameter \u03c1 in the polynomial kernel (5) and the regularization parameter \u03bb in the objective function (17)) are selected via 5-fold cross-validation from \u03c1 \u2208 [1, 2, 3] and \u03bb \u2208 [10, 10, 10].", "startOffset": 204, "endOffset": 216}, {"referenceID": 4, "context": "We use the area under the receiver operating characteristics curve (AUC) [5] as the evaluation metric, which is robust to the class imbalance, i.", "startOffset": 73, "endOffset": 76}, {"referenceID": 23, "context": "As it can be seen from Table 3, PU-SKC outperforms the existing method puMIL [24] under the different class priors.", "startOffset": 77, "endOffset": 81}, {"referenceID": 23, "context": "dataset true class prior PU-SKC puMIL [24] Musk1 0.", "startOffset": 38, "endOffset": 42}, {"referenceID": 19, "context": "This method is based on the convex formulation of PU learning [20] and the set kernel [11].", "startOffset": 62, "endOffset": 66}, {"referenceID": 10, "context": "This method is based on the convex formulation of PU learning [20] and the set kernel [11].", "startOffset": 86, "endOffset": 90}, {"referenceID": 23, "context": "PU-SKC performed better than the existing PU multiple instance classification method [24] in the classifications of the benchmark MIL datasets (drug activity prediction and image annotation).", "startOffset": 85, "endOffset": 89}], "year": 2017, "abstractText": "Multiple instance learning (MIL) is a variation of traditional supervised learning problems where data (referred to as bags) are composed of sub-elements (referred to as instances) and only bag labels are available. MIL has a variety of applications such as content-based image retrieval, text categorization and medical diagnosis. Most of the previous work for MIL assume that the training bags are fully labeled. However, it is often difficult to obtain an enough number of labeled bags in practical situations, while many unlabeled bags are available. A learning framework called PU learning (positive and unlabeled learning) can address this problem. In this paper, we propose a convex PU learning method to solve an MIL problem. We experimentally show that the proposed method achieves better performance with significantly lower computational costs than an existing method for PU-MIL.", "creator": "LaTeX with hyperref package"}}}