{"id": "1704.06850", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Apr-2017", "title": "Testing from One Sample: Is the casino really using a riffle shuffle?", "abstract": "Classical distribution testing assumes access to i.i.d. samples from the distributions that are being tested. We initiate the study of Markov chain testing, assuming access to a single sample from the Markov Chains that are being tested. In particular, we get to observe a single trajectory X_0 ,...,X_t ,... of an unknown Markov Chain M, for which we do not even get to control the distribution of the starting state X_0 . Our goal is to test whether M is identical to a model Markov Chain M_0 . In the first part of the paper, we propose a measure of difference between two Markov chains, which captures the scaling behavior of the total variation distance between words sampled from the Markov chains as the length of these words grows. We provide efficient and sample near- optimal testers for identity testing under our proposed measure of difference. In the second part of the paper, we study Markov chains whose state space is exponential in their description, providing testers for testing identity of card shuffles. We apply our results to testing the validity of the Gilbert, Shannon, and Reeds model for the riffle shuffle.", "histories": [["v1", "Sat, 22 Apr 2017 21:02:31 GMT  (682kb,D)", "http://arxiv.org/abs/1704.06850v1", "35 pages, 5 figures"]], "COMMENTS": "35 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["constantinos daskalakis", "nishanth dikkala", "nick gravin"], "accepted": false, "id": "1704.06850"}, "pdf": {"name": "1704.06850.pdf", "metadata": {"source": "CRF", "title": "Testing from One Sample: Is the casino really using a riffle shuffle?", "authors": ["Constantinos Daskalakis", "Nishanth Dikkala", "Nick Gravin"], "emails": ["costis@mit.edu", "nishanthd@csail.mit.edu", "ngravin@gmail.com"], "sections": [{"heading": null, "text": "In the first part of the paper, we propose a measure of the difference between two Markov chains that captures the scaling behavior of the total deviation between words from the Markov chains as the length of these words grows. We provide efficient and random identity testers as part of our proposed measure of difference. In the second part of the paper, we examine Markov chains whose state space is exponential in their description, and provide testers for verifying the identity of card changes. We apply our results to verifying the validity of the Gilbert, Shannon, and Reed model for reef blending. \u2022 Supported by a Microsoft Research Faculty Fellowship and the NSF Prize CCF-1551875, CCF-1617730, and CCF1650733. \u2020 Supported by the NSF Prize CCF-1550733."}, {"heading": "1 Introduction", "text": "We formulate theories about the laws that govern physical phenomena by making observations and measuring them by our hypotheses. A common scenario is when our observations can be defined to some extent as i.e. patterns from a distribution that we are trying to understand. This is the setting that is tackled by most classic work in statistics. Of course, access to i.i.d. samples from a distribution is rare and quite often a mere approximation to reality. We typically only have access to approximate samples from a stationary distribution sampled by a Markov chain whose transition matrix / kernel is unknown and which can only be observed for a few limited time horizons. In fact, the underlying Markov chain is not even quickly mixed up, so there is no guarantee that we will ever see samples distributed roughly according to the stationary distribution. These problems are specified in high-dimensional settings, for example, when observing the configurations of a map system - or where they are distributed completely."}, {"heading": "2 Preliminaries", "text": "A discrete Markov time chain is a stochastic process {Xt} t-q-q-q-q-q-q over a state space S that fulfills the Markov property: The probability of being in a state at the time t + 1 depends only on the state at the time before t. In this essay we consider only Markov chains with a finite state space, so that | S | = n. Such Markov chains can be specified completely by a n \u00b7 n transition matrix (kernel) that contains probabilities of transition from state i to state j in the ith line and jth column. The transition matrix does not have negative entries and is a stochastic matrix. We use the capital letters P, Q, M to represent Markov chains and their respective transition matrices. The stationary distribution of a Markov chain P is a distribution over the state space S (written as a column vector) so that it fulfills the density."}, {"heading": "2.1 Notations", "text": "We list the generic notation conventions used in this work. We denote vectors with lower case letters such as ~ v and matrices with uppercase letters such as A, B, P, Q. The ith entry of the vector ~ v is denoted by vi or v [i] and the (ij) th entry of the matrix A (with line, jth. column) is denoted by Aij or A [ij]; ~ ei denotes the standard analysis vector with 1 in its ith coordinate and 0 elsewhere; ~ 1 denotes the vector of all. The \"entrywise\" L1 and L2 standards of a matrix A are respectfully denoted as \"A\" 1 and \"A\" 2."}, {"heading": "2.2 Distance between Markov Chains", "text": "We begin by looking at the following simple question: how close is the behavior of two given Markov chains P = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q =\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"=\" Q \"=\" Q \"=\" = \"Q\" = \"Q\" = \"=\" Q \"=\" = \"Q\" = \"Q\" = \"=\" Q \"=\" = \"Q\" = \"Q\" = \"=\" Q \"=\" Q \"=\" = \"Q\" = \"Q\" = \"Q\" = \"=\" Q \"=\" Q = \"=\" Q = \"=\" Q = \"=\" Q = \"=\" Q = \"=\" Q = \"=\" Q = \"=\" Q = \"=\" Q = \"=\" Q = \"=\" Q = \"=\" Q = \"=\" Q = \"=\" Q = \"=\" Q = \"=\" Q = \"=\" = \"Q =\" = \"=\" Q = \"=\" Q = \"=\" = \"Q =\" = \"=\" Q = \"=\" = \"=\" = \"Q =\" = \"Q =\" = \"=\" Q = \"=\" = \"Q =\" = \"=\" Q = \"=\" = \"Q =\" = \"=\" = \"Q =\" = \"=\" Q = \"=\" = \"=\" = \"Q =\" = \"=\" Q = \"=\" = \"=\" Q = \"=\" Q = \"=\" = \"Q =\" = \"=\" = \"Q =\" = \"=\" Q = \"=\" = \"=\" = \"Q =\" = \"=\" Q = \"=\" = \"Q =\" = \"=\" = \"Q =\" = \"=\" Q = \"=\" = \"Q =\" = \"=\" = \"=\" Q ="}, {"heading": "3 Identity Testing of Symmetric Markov Chains", "text": "Since we have an idea of the distance between symmetric Markov chains in the previous section, we get a well-defined framework from the property testing literature (BFF + 01, Pan08, LRR13) for testing the properties of distributions generated by Markov chains. (The next fundamental question is completely unknown to us) coincides with a given hypothesis distribution. (In this section, we present our results for the identity tests of symmetric Markov chains.) We first present a polynomial time algorithm that provides an efficient reduction of identity tests with i.i.d. The algorithms improve the performance of a naive reduction that waits for a time to get a multiplicative problem."}, {"heading": "3.1 Lower Bound.", "text": "In this section, we provide almost matching lower distributions, which are adapted to our results in Theorem 3.1.Theorem 3.2. There is an instance of identity verification problem for symmetric Markov chain Q, which requires a word of length to verify the identity of Q with 99% confidence.Proof. We use Le Cam's two-point method and construct a class of Markov chains P s.t. (i) Each P-P is at least far removed from Q for a given constant. That is 1 \u2212 \u03c1 ([P, Q]). For each P-P, there is a constant c > 0, s.t. It is impossible to distinguish a word of length m generated by a randomly chosen Markov chain P, from a word of length m produced by Q with the probability equal to or greater than 99100 for m. To prove (ii), we show that the total variation between m-word distributions obtained from the two processes, Q-P and P-P is achieved."}, {"heading": "4 Card Shuffling", "text": "This year, more than ever in the history of the city, where it is so far that it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a, a place, a place, a place, a place, a, a place, a place, a place, a place, a, a, a place, a place, a place, a, a, a, a, a place, a, a place, a place, a, a, a place, a, a place, a, a place, a, a, a place, a, a, a place, a, a, a, a place, a,"}, {"heading": "4.1 Upper Bound", "text": "We have it in our hands that we are able to move in the world, namely in the world in which we find ourselves in the world, and in the world in which we find ourselves, in the world in which we find ourselves, in the world, in the world, in the world, in the world in which we live, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the, in the world, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in, in the, in the, in the, in the, in the, in the, in the, in, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in the, in"}, {"heading": "4.2 More Details on the Tester for Sparse Markov Chains", "text": "We are considering all single-step transitions that have a positive probability in the Markov chain Q or P. (We) are considering all single-step transitions that have a positive probability in the Markov chain Q or P. (We) are considering all single-step transitions to the E level. (We) We are considering all single-step transitions to the E level. (We) are considering whether to move the transitions to the E level to the E level and time to the E level. (We) We are considering all rare transitions to the E level. (We) We are considering all the transitions to the E level. (We) We are considering all rare transitions that are marked less than O level. (We) are considering all rare transitions that are marked with the probability that the transitions will be marked in the E level. (We) are considering all rare transitions that are marked with the probability that less than O level will be marked. (We) We are considering the transitions in the E level."}, {"heading": "4.3 Lower Bound", "text": "In this section, we will show that any algorithm that verifies the identity of a sparse Markov chain in which we have gone to a high level requires at least two independent studies, in which each study is a noun generated by a sparse Markov chain. (n) We remember Definition 2 of a sparse Markov chain that adapts it for each time. (n) The Markov chain starts from a single state at t = 0; there are only O (1) possible transitions Pt (ij) 6 = 0 from each state i to other states, but the very first time t > 0.Theorem 4.4 There is an instance of identity testing for a sparse Markov chain Q, which at least m (n) i.i.i.i."}, {"heading": "5 Open Questions", "text": "In this paper, we have proposed a new framework for the investigation of property control issues in Markov chains. There seem to be several possibilities for future research and an abundance of open problems arising from this framework. First, we list some questions that may be of interest here.1. What is the optimal sample complexity for identity testing on symmetrical Markov chains? In this paper, we show an upper limit of O chains (HitTQ \u00b7 log (HitTQ) + n\u03b5) samples (Theorem 3.1). We suspect that it is the correct sample complexity for this problem and an explicit dependence on the hit time of the chain Q. \u2212 It is implicitly covered to some extent by the warranty we provide from the parameter \u03b5.2. What is the optimal sample complexity for identity testing on the sparse Markov chains defined in Section 4? In this paper, we show an upper limit of 22 (theorem) (4.O / 3) chains."}], "references": [{"title": "Optimal testing for properties of distributions", "author": ["Jayadev Acharya", "Constantinos Daskalakis", "Gautam Kamath"], "venue": "In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems", "citeRegEx": "Acharya et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Acharya et al\\.", "year": 2015}, {"title": "The frequency goodness of fit test for probability chains", "author": ["Maurice S Bartlett"], "venue": "In Mathematical Proceedings of the Cambridge Philosophical Society,", "citeRegEx": "Bartlett.,? \\Q1951\\E", "shortCiteRegEx": "Bartlett.", "year": 1951}, {"title": "Trailing the dovetail shuffle to its lair", "author": ["Dave Bayer", "Persi Diaconis"], "venue": "Ann. Appl. Probab., 2(2):294\u2013313,", "citeRegEx": "Bayer and Diaconis.,? \\Q1992\\E", "shortCiteRegEx": "Bayer and Diaconis.", "year": 1992}, {"title": "Testing random variables for independence and identity", "author": ["Tugkan Batu", "Eldar Fischer", "Lance Fortnow", "Ravi Kumar", "Ronitt Rubinfeld", "Patrick White"], "venue": "In Proceedings of the 42nd Annual IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "Batu et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Batu et al\\.", "year": 2001}, {"title": "Testing closeness of discrete distributions", "author": ["Tu\u011fkan Batu", "Lance Fortnow", "Ronitt Rubinfeld", "Warren D Smith", "Patrick White"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Batu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Batu et al\\.", "year": 2013}, {"title": "Hypothesis testing for markovian models with random time observations", "author": ["Flavia Barsotti", "Anne Philippe", "Paul Rochet"], "venue": "Journal of Statistical Planning and Inference,", "citeRegEx": "Barsotti et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Barsotti et al\\.", "year": 2016}, {"title": "Testing shape restrictions of discrete distributions", "author": ["Cl\u00e9ment L. Canonne", "Ilias Diakonikolas", "Themis Gouleakis", "Ronitt Rubinfeld"], "venue": "In Proceedings of the 33rd Symposium on Theoretical Aspects of Computer Science,", "citeRegEx": "Canonne et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Canonne et al\\.", "year": 2016}, {"title": "Optimal algorithms for testing closeness of discrete distributions", "author": ["Siu-On Chan", "Ilias Diakonikolas", "Gregory Valiant", "Paul Valiant"], "venue": "In Proceedings of the Twenty-Fifth Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "Chan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chan et al\\.", "year": 2014}, {"title": "Testing equivalence between distributions using conditional samples", "author": ["Cl\u00e9ment L. Canonne", "Dana Ron", "Rocco A. Servedio"], "venue": "In Proceedings of the Twenty-Fifth Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "Canonne et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Canonne et al\\.", "year": 2014}, {"title": "Testing k -modal distributions: Optimal algorithms via reductions", "author": ["Constantinos Daskalakis", "Ilias Diakonikolas", "Rocco A. Servedio", "Gregory Valiant", "Paul Valiant"], "venue": "In Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "Daskalakis et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Daskalakis et al\\.", "year": 2013}, {"title": "Group representations in probability and statistics", "author": ["Persi Diaconis"], "venue": "Lecture notes. Hayward, Calif. Institute of Mathematical Statistics,", "citeRegEx": "Diaconis.,? \\Q1988\\E", "shortCiteRegEx": "Diaconis.", "year": 1988}, {"title": "Mathematical Developments from the Analysis of Riffle Shuffling", "author": ["P. Diaconis"], "venue": "Technical report (Stanford University. Dept. of Statistics)", "citeRegEx": "Diaconis.,? \\Q2002\\E", "shortCiteRegEx": "Diaconis.", "year": 2002}, {"title": "A new approach for testing properties of discrete distributions", "author": ["Ilias Diakonikolas", "Daniel M. Kane"], "venue": "In Proceedings of the 57th Annual IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "Diakonikolas and Kane.,? \\Q2016\\E", "shortCiteRegEx": "Diakonikolas and Kane.", "year": 2016}, {"title": "The effect of dependence on chi-squared and empiric distribution tests of fit", "author": ["Leon J Gleser", "David S Moore"], "venue": "The Annals of Statistics,", "citeRegEx": "Gleser and Moore,? \\Q1983\\E", "shortCiteRegEx": "Gleser and Moore", "year": 1983}, {"title": "Mixing time estimation in reversible markov chains from a single sample path", "author": ["Daniel J Hsu", "Aryeh Kontorovich", "Csaba Szepesv\u00e1ri"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Hsu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2015}, {"title": "The bhattacharyya distance and detection between markov chains", "author": ["Dimitri Kazakos"], "venue": "IEEE Trans. Information Theory,", "citeRegEx": "Kazakos.,? \\Q1978\\E", "shortCiteRegEx": "Kazakos.", "year": 1978}, {"title": "Markov chains and mixing times. Providence, R.I", "author": ["David Asher Levin", "Yuval Peres", "Elizabeth Lee Wilmer"], "venue": "American Mathematical Society,", "citeRegEx": "Levin et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Levin et al\\.", "year": 2009}, {"title": "Testing properties of collections of distributions", "author": ["Reut Levi", "Dana Ron", "Ronitt Rubinfeld"], "venue": "Theory of Computing,", "citeRegEx": "Levi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Levi et al\\.", "year": 2013}, {"title": "The effect of dependence on chi squared tests of fit", "author": ["David S Moore"], "venue": "The Annals of Statistics,", "citeRegEx": "Moore,? \\Q1982\\E", "shortCiteRegEx": "Moore", "year": 1982}, {"title": "On size increase for goodness of fit tests when observations are positively dependent", "author": ["I Molina", "D Morales", "L Pardo", "I Vajda"], "venue": "Statistics & Risk Modeling,", "citeRegEx": "Molina et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Molina et al\\.", "year": 2002}, {"title": "A coincidence-based test for uniformity given very sparsely sampled discrete data", "author": ["Liam Paninski"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Paninski.,? \\Q2008\\E", "shortCiteRegEx": "Paninski.", "year": 2008}, {"title": "On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling", "author": ["Karl Pearson"], "venue": "Philosophical Magazine Series", "citeRegEx": "Pearson.,? \\Q1900\\E", "shortCiteRegEx": "Pearson.", "year": 1900}, {"title": "The analysis of categorical data from complex sample surveys: Chi-squared tests for goodness of fit and independence in two-way tables", "author": ["Jon N.K. Rao", "Alastair J. Scott"], "venue": "Journal of the Americal Statistical Association,", "citeRegEx": "Rao and Scott.,? \\Q1981\\E", "shortCiteRegEx": "Rao and Scott.", "year": 1981}, {"title": "Serial dependence of observations leading to contingency tables, and corrections to chi-squared statistics", "author": ["Simon Tavare", "Patricia M.E. Altham"], "venue": null, "citeRegEx": "Tavare and Altham.,? \\Q1983\\E", "shortCiteRegEx": "Tavare and Altham.", "year": 1983}, {"title": "Error exponents for composite hypothesis testing of Markov forest distributions", "author": ["Vincent Y.F. Tan", "Animashree Anandkumar", "Alan S. Willsky"], "venue": "In Proceedings of the 2010 IEEE International Symposium on Information Theory, ISIT", "citeRegEx": "Tan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Tan et al\\.", "year": 2010}, {"title": "An automatic inequality prover and instance optimal identity testing", "author": ["Gregory Valiant", "Paul Valiant"], "venue": "In Proceedings of the 55th Annual IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "Valiant and Valiant.,? \\Q2014\\E", "shortCiteRegEx": "Valiant and Valiant.", "year": 2014}], "referenceMentions": [], "year": 2017, "abstractText": "Classical distribution testing assumes access to i.i.d. samples from the distributions that are being tested. We initiate the study of Markov chain testing, assuming access to a single sample from the Markov Chains that are being tested. In particular, we get to observe a single trajectory X0, . . . , Xt, . . . of an unknown Markov Chain M, for which we do not even get to control the distribution of the starting state X0. Our goal is to test whether M is identical to a model Markov Chain M\u2032. In the first part of the paper, we propose a measure of difference between two Markov chains, which captures the scaling behavior of the total variation distance between words sampled from the Markov chains as the length of these words grows. We provide efficient and sample nearoptimal testers for identity testing under our proposed measure of difference. In the second part of the paper, we study Markov chains whose state space is exponential in their description, providing testers for testing identity of card shuffles. We apply our results to testing the validity of the Gilbert, Shannon, and Reeds model for the riffle shuffle. Supported by a Microsoft Research Faculty Fellowship, and NSF Award CCF-1551875, CCF-1617730 and CCF1650733. Supported by NSF Award CCF-1551875, CCF-1617730 and CCF-1650733. Supported by NSF Award CCF-1551875, CCF-1617730 and CCF-1650733. ar X iv :1 70 4. 06 85 0v 1 [ cs .L G ] 2 2 A pr 2 01 7", "creator": "LaTeX with hyperref package"}}}