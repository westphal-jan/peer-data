{"id": "1704.07221", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Apr-2017", "title": "Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-LSTM", "abstract": "This paper describes team Turing's submission to SemEval 2017 RumourEval: Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A). Subtask A addresses the challenge of rumour stance classification, which involves identifying the attitude of Twitter users towards the truthfulness of the rumour they are discussing. Stance classification is considered to be an important step towards rumour verification, therefore performing well in this task is expected to be useful in debunking false rumours. In this work we classify a set of Twitter posts discussing rumours into either supporting, denying, questioning or commenting on the underlying rumours. We propose a LSTM-based sequential model that, through modelling the conversational structure of tweets, which achieves an accuracy of 0.784 on the RumourEval test set outperforming all other systems in Subtask A.", "histories": [["v1", "Mon, 24 Apr 2017 13:41:25 GMT  (149kb,D)", "http://arxiv.org/abs/1704.07221v1", "SemEval 2017 RumourEval: Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A)"]], "COMMENTS": "SemEval 2017 RumourEval: Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A)", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["elena kochkina", "maria liakata", "isabelle augenstein"], "accepted": false, "id": "1704.07221"}, "pdf": {"name": "1704.07221.pdf", "metadata": {"source": "CRF", "title": "Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-LSTM", "authors": ["Elena Kochkina", "Maria Liakata", "Isabelle Augenstein"], "emails": ["M.Liakata}@warwick.ac.uk,", "I.Augenstein@ucl.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "The classification of tweets is about determining the attitude of the author of a text towards a target (Mohammad et al., 2016). Targets can range from abstract ideas to concrete entities and events. Classification of tweets is an active area of research that has been studied in various areas (Ranade et al., 2013; Chuang and Hsieh, 2015). Here, we focus on classifying tweets in relation to the veracity of rumors circulating in Twitter conversations in the context of breaking news. Each conversation is defined by a tweet that initiates the conversation and a series of nested responses to it that form a conversation thread. The goal is to classify each tweet in the conversation thread as either supportive, denying, questioning or commenting (SDQC) on the rumor that is triggered by the source tweet. Being able to automatically detect posture is very useful in the context of events that provoke, challenge or hasten public rumors (o) in 2015."}, {"heading": "2 Related Work", "text": "Zeng et al. (2016) perform a position classification for rumors arising in times of crisis. Both works use tweets related to the same rumor during training and testing. A model based on the bidirectional LSTM encoding of tweets based on targets has shown that it is state-of-the-art on SemEval2016 dataset 6 (Augenstein et al., 2016). However, the RumourEval task differs in addressing conversation threads. The sequential stance classification Lukasik et al. (2016) and Zubiaga et al. (2016a) consider the sequential nature of tweet threads in their work. Lukasik et al al al al al al al al al al al. (2016) use falcon processes to classify temporal tweets. They show the importance of both textual content and temporal information about the discourse structure Xiaasis Qasis S424 and Xia24 (2014a)."}, {"heading": "3 Dataset", "text": "The data set provided for this task contains Twitter conversation threads associated with rumors of ten different events in the news industry, including the Paris attacks, the Ferguson riots, and the crash of a Germanwings plane. These events include 325 conversation threads consisting of 5,568 underlying tweets commented on at the tweet level (breakdown between training, testing, and development phases is in Table 1) (Derczynski et al., 2017).Each thread contains a source tweet that triggers a conversation, and nested tweets that respond to either the source tweet or previous replies. The thread can be divided into linear branches of tweets, with a branch defined as a chain that begins with a leaf tweet, including its direct parent tweets, down to the source tweet. Figure 1 shows an example of a conversation along with its annotations, which are presented as a tree of highlighted branches. 66 The depth of a tweet is based on the number of its parent versus the number of its parent, and the depth of its parent."}, {"heading": "4 System Description", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Features", "text": "Before creating functions for the tweets, we perform a pre-processing step in which we remove nonalphabetic characters, convert all words into lowercase letters and tokenize texts.1 Once tweet texts are pre-edited, we extract the following functions: \u2022 Word vectors: we use a word2vec (Mikolovet al., 2013) model preschooled on the Google News dataset (300d). \u2022 Tweet lexicon: (1) number of negative words 3and (2) number of swear words. (41) For implementing all pre-processing routines, we use Python 2.7 with the NLTK package. \u2022 We have also tried to use word embedding of gloves trained on Twitter datasets, but it does not reduce performance on both development and test sets, which are compared with the Google News word vectors3A."}, {"heading": "4.2 Branch - LSTM Model", "text": "To address the task of classifying rumors, we propose a branch LSTM, a neural network architecture that uses layers of LSTM units (Hochreiter and Schmidhuber, 1997) to process the entire Tweet branch, thus incorporating structural information from the conversation (see the picture of the branch LSTM in Figure 3). Input in each step i of the LSTM layer is the representation of the tweet as a vector. We record the output of each time step to label each tweet in a Branch5. This output is fed by multiple dense ReLU layers, a 50% fail layer, and then a Softmax layer to obtain class probabilities. We use zero padding and masks to account for the different lengths of the Tweet branches. The model is trained on the categorical cross-entropy loss function, and then by a Softmax layer to obtain class probabilities. We use zero padding and masks to account for the different lengths of the Tweet branches, the model is coached on the categorical cross-entropy loss function, since the tweeting function is represented by the overlapping of the two words, where the difference between the source of the two words is represented in the masks."}, {"heading": "5 Experimental Setup", "text": "We have determined the optimal set of hyperparameters by testing the performance of our model on the development set for different parameter combinations. To implement all models, we have used the Python libraries Theano (Bastien et al., 2012) and Lasagne (Dieleman et al., 2015).Tree of Parzen Estimators (TPE) algorithm 6 to search the parameter space defined as follows: The number of dense ReLU layers varies from one to four; the number of LSTM layers is one or two; the minibatch size is either 32 or 64; the number of units in the ReLU layer is one of {100, 200, 300, 400, 500}, and in the LSTM layer one of {100, 200, 300}; the thickness of L2 hyperametrization is one of {0.0, 1e-4, 3e-4, solid-500}, and the best number of experiments is selected from the number performed."}, {"heading": "6 Results", "text": "Along with accuracy, we show macro-averaged Fscore and macro-averaged F scores per class, as these measures are responsible for class imbalance.The difference in accuracy between test and development package is minimal, but we see significant differences in macro-F scores due to different class balance in these groups.The macro-F score could be improved if we use it as a metric for optimizing hyperparameters.The branch LSTM model predicts comments, the majority class good, but cannot single out denial, the most sophisticated underrepresented class. Most deny-6We used the implementation of the TPE algorithm in the hyperopt package (Bergstra et al., 2013), where instances are misclassified as comments (see Table 5), with only one tweet being misclassified and two tweets being supportive (Figure 2).An increased amount of overall data would be helpful to improve the performance of this model by analyzing the twofold differences in most of the two categories."}, {"heading": "7 Conclusions", "text": "This paper describes the Turing system contained in the SemEval-2017 Task 8 Subtask A. Our method breaks down the tree structure of conversations into linear sequences and achieves an accuracy of 0.784 on the test set and represents the state of the art for classifying rumors. In future work, we plan to explore various methods for modeling tree-structured conversations."}, {"heading": "Acknowledgments", "text": "This work was supported by the Alan Turing Institute under the EPSRC grant EP / N510129 / 1. Cloud computing resources were kindly provided by a Microsoft Azure for Research Award. Elena Kochkina's work was partially supported by the Leverhulme Trust through the Bridges programme."}], "references": [{"title": "Stance Detection with Bidirectional Conditional Encoding", "author": ["Isabelle Augenstein", "Tim Rockt\u00e4schel", "Andreas Vlachos", "Kalina Bontcheva."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Augenstein et al\\.,? 2016", "shortCiteRegEx": "Augenstein et al\\.", "year": 2016}, {"title": "Theano: new features and speed improvements", "author": ["Fr\u00e9d\u00e9ric Bastien", "Pascal Lamblin", "Razvan Pascanu", "James Bergstra", "Ian Goodfellow", "Arnaud Bergeron", "Nicolas Bouchard", "David Warde-Farley", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1211.5590 .", "citeRegEx": "Bastien et al\\.,? 2012", "shortCiteRegEx": "Bastien et al\\.", "year": 2012}, {"title": "Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures", "author": ["James Bergstra", "Daniel Yamins", "David D Cox."], "venue": "ICML (1) 28:115\u2013123.", "citeRegEx": "Bergstra et al\\.,? 2013", "shortCiteRegEx": "Bergstra et al\\.", "year": 2013}, {"title": "Stance classification on ptt comments", "author": ["Ju-han Chuang", "Shukai Hsieh."], "venue": "Proceedings of the 29th Pacific Asia Conference on Language, Information and Computation.", "citeRegEx": "Chuang and Hsieh.,? 2015", "shortCiteRegEx": "Chuang and Hsieh.", "year": 2015}, {"title": "Semeval-2017 task 8: Rumoureval: Determining rumour veracity and support for rumours", "author": ["Leon Derczynski", "Kalina Bontcheva", "Maria Liakata", "Arkaitz Zubiaga", "Rob Procter", "Geraldine Wong Sak Hoi."], "venue": "Proceedings of the International Work-", "citeRegEx": "Derczynski et al\\.,? 2017", "shortCiteRegEx": "Derczynski et al\\.", "year": 2017}, {"title": "Pheme: computing veracity: the fourth challenge of big social data", "author": ["Leon Derczynski", "Kalina Bontcheva", "Michal Lukasik", "Thierry Declerck", "Arno Scharl", "Georgi Georgiev", "Petya Osenova", "Toms Pariente Lobo", "Anna Kolliakou", "Robert Stewart"], "venue": null, "citeRegEx": "Derczynski et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Derczynski et al\\.", "year": 2014}, {"title": "Lasagne: First release", "author": ["Gbor Tak\u00e1cs", "Peter de Rivaz", "Jon Crall", "Gregory Sanders", "Kashif Rasul", "Cong Liu", "Geoffrey French", "Jonas Degrave."], "venue": "https://doi.org/10.5281/zenodo.27878.", "citeRegEx": "Tak\u00e1cs et al\\.,? 2015", "shortCiteRegEx": "Tak\u00e1cs et al\\.", "year": 2015}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Hawkes processes for continuous time sequence classification: an application to rumour stance classification in twitter", "author": ["Michal Lukasik", "P.K. Srijith", "Duy Vu", "Kalina Bontcheva", "Arkaitz Zubiaga", "Trevor Cohn."], "venue": "Proceedings of the", "citeRegEx": "Lukasik et al\\.,? 2016", "shortCiteRegEx": "Lukasik et al\\.", "year": 2016}, {"title": "Twitter under crisis: Can we trust what we RT? In 1st Workshop on Social Media Analytics", "author": ["Marcelo Mendoza", "Barbara Poblete", "Carlos Castillo."], "venue": "SOMA\u201910, pages 71\u201379.", "citeRegEx": "Mendoza et al\\.,? 2010", "shortCiteRegEx": "Mendoza et al\\.", "year": 2010}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "arXiv preprint arXiv:1301.3781 .", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Semeval-2016 task 6: Detecting stance in tweets", "author": ["Saif M Mohammad", "Svetlana Kiritchenko", "Parinaz Sobhani", "Xiaodan Zhu", "Colin Cherry."], "venue": "Proceedings of the International Workshop on Semantic Evaluation, SemEval. volume 16.", "citeRegEx": "Mohammad et al\\.,? 2016", "shortCiteRegEx": "Mohammad et al\\.", "year": 2016}, {"title": "Reading the riots on twitter: methodological innovation for the analysis of big data", "author": ["Rob Procter", "Farida Vis", "Alex Voss."], "venue": "International journal of social research methodology 16(3):197\u2013214.", "citeRegEx": "Procter et al\\.,? 2013", "shortCiteRegEx": "Procter et al\\.", "year": 2013}, {"title": "Rumor has it: Identifying misinformation in microblogs", "author": ["Vahed Qazvinian", "Emily Rosengren", "Dragomir R Radev", "Qiaozhu Mei."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Compu-", "citeRegEx": "Qazvinian et al\\.,? 2011", "shortCiteRegEx": "Qazvinian et al\\.", "year": 2011}, {"title": "Stance classification in online debates by recognizing users\u2019 intentions", "author": ["Sarvesh Ranade", "Rajeev Sangal", "Radhika Mamidi."], "venue": "Proceedings of the SIGDIAL 2013 Conference. pages 61\u201369.", "citeRegEx": "Ranade et al\\.,? 2013", "shortCiteRegEx": "Ranade et al\\.", "year": 2013}, {"title": "Software Framework for Topic Modelling with Large Corpora", "author": ["Radim \u0158eh\u016f\u0159ek", "Petr Sojka."], "venue": "Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks. ELRA, Valletta, Malta, pages 45\u201350. http://is.muni.cz/", "citeRegEx": "\u0158eh\u016f\u0159ek and Sojka.,? 2010", "shortCiteRegEx": "\u0158eh\u016f\u0159ek and Sojka.", "year": 2010}, {"title": "unconfirmed: Classifying rumor stance in crisisrelated social media messages", "author": ["Li Zeng", "Kate Starbird", "Emma S Spiro."], "venue": "Tenth International AAAI Conference on Web and Social Media.", "citeRegEx": "Zeng et al\\.,? 2016", "shortCiteRegEx": "Zeng et al\\.", "year": 2016}, {"title": "Enquiring minds: Early detection of rumors in social media from enquiry posts", "author": ["Zhe Zhao", "Paul Resnick", "Qiaozhu Mei."], "venue": "Proceedings of the 24th International Conference on World Wide Web. ACM, pages 1395\u20131405.", "citeRegEx": "Zhao et al\\.,? 2015", "shortCiteRegEx": "Zhao et al\\.", "year": 2015}, {"title": "Stance classification in rumours as a sequential task exploiting the tree structure of social media conversations", "author": ["Arkaitz Zubiaga", "Elena Kochkina", "Maria Liakata", "Rob Procter", "Michal Lukasik."], "venue": "Proceedings of COLING, the International Conference", "citeRegEx": "Zubiaga et al\\.,? 2016a", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2016}, {"title": "Analysing how people orient to and spread rumours in social media by looking at conversational threads", "author": ["Arkaitz Zubiaga", "Maria Liakata", "Rob Procter", "Geraldine Wong Sak Hoi", "Peter Tolmie."], "venue": "PloS one 11(3):e0150989.", "citeRegEx": "Zubiaga et al\\.,? 2016b", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 11, "context": "In stance classification one is concerned with determining the attitude of the author of a text towards a target (Mohammad et al., 2016).", "startOffset": 113, "endOffset": 136}, {"referenceID": 14, "context": "Stance classification is an active research area that has been studied in different domains (Ranade et al., 2013; Chuang and Hsieh, 2015).", "startOffset": 92, "endOffset": 137}, {"referenceID": 3, "context": "Stance classification is an active research area that has been studied in different domains (Ranade et al., 2013; Chuang and Hsieh, 2015).", "startOffset": 92, "endOffset": 137}, {"referenceID": 17, "context": "Being able to detect stance automatically is very useful in the context of events provoking public resonance and associated rumours, as a first step towards verification of early reports (Zhao et al., 2015).", "startOffset": 187, "endOffset": 206}, {"referenceID": 9, "context": "For instance, t has been shown that rumours that are later proven to be false tend to spark significantly larger numbers of denying tweets than rumours that are later confirmed to be true (Mendoza et al., 2010; Procter et al., 2013; Derczynski et al., 2014; Zubiaga et al., 2016b).", "startOffset": 188, "endOffset": 280}, {"referenceID": 12, "context": "For instance, t has been shown that rumours that are later proven to be false tend to spark significantly larger numbers of denying tweets than rumours that are later confirmed to be true (Mendoza et al., 2010; Procter et al., 2013; Derczynski et al., 2014; Zubiaga et al., 2016b).", "startOffset": 188, "endOffset": 280}, {"referenceID": 5, "context": "For instance, t has been shown that rumours that are later proven to be false tend to spark significantly larger numbers of denying tweets than rumours that are later confirmed to be true (Mendoza et al., 2010; Procter et al., 2013; Derczynski et al., 2014; Zubiaga et al., 2016b).", "startOffset": 188, "endOffset": 280}, {"referenceID": 19, "context": "For instance, t has been shown that rumours that are later proven to be false tend to spark significantly larger numbers of denying tweets than rumours that are later confirmed to be true (Mendoza et al., 2010; Procter et al., 2013; Derczynski et al., 2014; Zubiaga et al., 2016b).", "startOffset": 188, "endOffset": 280}, {"referenceID": 13, "context": "Single Tweet Stance Classification Stance classification for rumours was pioneered by Qazvinian et al. (2011) as a binary classification task (support/denial).", "startOffset": 86, "endOffset": 110}, {"referenceID": 13, "context": "Single Tweet Stance Classification Stance classification for rumours was pioneered by Qazvinian et al. (2011) as a binary classification task (support/denial). Zeng et al. (2016) perform stance classification for rumours emerging during crises.", "startOffset": 86, "endOffset": 179}, {"referenceID": 0, "context": "A model based on bidirectional LSTM encoding of tweets conditioned on targets has been shown to achieve state-of-the-art on the SemEval2016 task 6 dataset (Augenstein et al., 2016).", "startOffset": 155, "endOffset": 180}, {"referenceID": 8, "context": "Sequential Stance Classification Lukasik et al. (2016) and Zubiaga et al.", "startOffset": 33, "endOffset": 55}, {"referenceID": 8, "context": "Sequential Stance Classification Lukasik et al. (2016) and Zubiaga et al. (2016a) consider the sequential nature of tweet threads in their works.", "startOffset": 33, "endOffset": 82}, {"referenceID": 8, "context": "Sequential Stance Classification Lukasik et al. (2016) and Zubiaga et al. (2016a) consider the sequential nature of tweet threads in their works. Lukasik et al. (2016) employ Hawkes processes to classify temporal sequences of tweets.", "startOffset": 33, "endOffset": 168}, {"referenceID": 8, "context": "They use linear- and tree- versions of a CRF classifier, outperforming the approach by Lukasik et al. (2016).", "startOffset": 87, "endOffset": 109}, {"referenceID": 4, "context": "These events include 325 conversation threads consisting of 5568 underlying tweets annotated for stance at the tweet level (breakdown between training, testing and development sets is shown in Table 1) (Derczynski et al., 2017).", "startOffset": 202, "endOffset": 227}, {"referenceID": 10, "context": "1 Once tweet texts are preprocessed, we extract the following features: \u2022 Word vectors: we use a word2vec (Mikolov et al., 2013) model pre-trained on the Google News dataset (300d) 2 using the gensim package (\u0158eh\u016f\u0159ek and Sojka, 2010).", "startOffset": 106, "endOffset": 128}, {"referenceID": 15, "context": ", 2013) model pre-trained on the Google News dataset (300d) 2 using the gensim package (\u0158eh\u016f\u0159ek and Sojka, 2010).", "startOffset": 87, "endOffset": 112}, {"referenceID": 7, "context": "To tackle the task of rumour stance classificaiton, we propose branch-LSTM, a neural network architecture that uses layers of LSTM units (Hochreiter and Schmidhuber, 1997) to process the whole branch of tweets, thus incorporating structural information of the conversation (see the illustration of the branch-LSTM on the Figure 3).", "startOffset": 137, "endOffset": 171}, {"referenceID": 1, "context": "For implementation of all models we used Python libraries Theano (Bastien et al., 2012) and Lasagne (Dieleman et al.", "startOffset": 65, "endOffset": 87}, {"referenceID": 2, "context": "We used the implementation of the TPE algorithm in the hyperopt package (Bergstra et al., 2013) Label Prediction C D Q S", "startOffset": 72, "endOffset": 95}], "year": 2017, "abstractText": "This paper describes team Turing\u2019s submission to SemEval 2017 RumourEval: Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A). Subtask A addresses the challenge of rumour stance classification, which involves identifying the attitude of Twitter users towards the truthfulness of the rumour they are discussing. Stance classification is considered to be an important step towards rumour verification, therefore performing well in this task is expected to be useful in debunking false rumours. In this work we classify a set of Twitter posts discussing rumours into either supporting, denying, questioning or commenting on the underlying rumours. We propose a LSTM-based sequential model that, through modelling the conversational structure of tweets, which achieves an accuracy of 0.784 on the RumourEval test set outperforming all other systems in Subtask A.", "creator": "LaTeX with hyperref package"}}}