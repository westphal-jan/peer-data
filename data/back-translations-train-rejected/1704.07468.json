{"id": "1704.07468", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Apr-2017", "title": "GaKCo: a Fast GApped k-mer string Kernel using COunting", "abstract": "String Kernel (SK) techniques, especially those using gapped $k$-mers as features (gk), have obtained great success in classifying sequences like DNA, protein, and text. However, the state-of-the-art gk-SK runs extremely slow when we increase the dictionary size ($\\Sigma$) or allow more mismatches ($M$). This is because current gk-SK uses a trie-based algorithm to calculate co-occurrence of mismatched substrings resulting in a time cost proportional to $O(\\Sigma^{M})$. We propose a \\textbf{fast} algorithm for calculating \\underline{Ga}pped $k$-mer \\underline{K}ernel using \\underline{Co}unting (GaKCo). GaKCo uses associative arrays to calculate the co-occurrence of substrings using cumulative counting. This algorithm is fast, scalable to larger $\\Sigma$ and $M$, and naturally parallelizable. We provide a rigorous asymptotic analysis that compares GaKCo with the state-of-the-art gk-SK. Theoretically, the time cost of GaKCo is independent of the $\\Sigma^{M}$ term that slows down the trie-based approach. Experimentally, we observe that GaKCo achieves the same accuracy as the state-of-the-art and outperforms its speed by factors of 2, 100, and 4, on classifying sequences of DNA (5 datasets), protein (12 datasets), and character-based English text (2 datasets), respectively", "histories": [["v1", "Mon, 24 Apr 2017 21:43:21 GMT  (890kb,D)", "http://arxiv.org/abs/1704.07468v1", null], ["v2", "Sun, 30 Apr 2017 20:12:01 GMT  (1797kb,D)", "http://arxiv.org/abs/1704.07468v2", null], ["v3", "Mon, 18 Sep 2017 17:25:17 GMT  (1786kb,D)", "http://arxiv.org/abs/1704.07468v3", "@ECML 2017"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CC cs.CL cs.DS", "authors": ["ritambhara singh", "arshdeep sekhon", "kamran kowsari", "jack lanchantin", "beilun wang", "yanjun qi"], "accepted": false, "id": "1704.07468"}, "pdf": {"name": "1704.07468.pdf", "metadata": {"source": "CRF", "title": "GaKCo: a Fast Gapped k-mer string Kernel using Counting", "authors": ["Ritambhara Singh", "Arshdeep Sekhon", "Kamran Kowsari", "Jack Lanchantin", "Beilun Wang", "Yanjun Qi"], "emails": [], "sections": [{"heading": null, "text": "Keywords: Fast Learning, String Kernel, Sequence Classification, Gapped k-mer String Kernel, Counting Statistics"}, {"heading": "1 Introduction", "text": "This year it is more than ever before in the history of the city."}, {"heading": "2 Method", "text": "In fact, it is such that it is a matter of a way in which people are able to put themselves into the world, in which they are able to move, in which they are able to move, in which they are able to live, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they are able to put themselves, in the world, in which they are able to put themselves, in the world, in which they are able to put themselves, in the world, in which they are able to put themselves, in the world, in which they live, in which they live, in which they are able to put themselves, in which they are able to put themselves, in the world, in which they are able to move, in which they are able, in which they are able, in which they are able to"}, {"heading": "2.3 Theoretical Comparison of Time Complexity", "text": "(1) This means that we divide the temporal costs of GaKCo into two groups: (1), (2), (2), (2), (3), (3), (3), (3), (3), (3), (3), (3), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5, (5), (5), (5), (5), \"(5),\" (5, \"(5),\" (5), \"(5),\" (5), \"(5),\" (5), \"(5,\" (5), \"(5),\" (5), \"(5,\" (5), \"(5),\" (5, \"(5),\" (5), \"(5),\" (5, \"(5),\" (5), \"(5,\" (5), \"(5),\" (5), \"(5,\" (5), \"(5),\" (5), (5, \"(5),\" (5), \"(5),\" (5), \"(5),\" (5),"}, {"heading": "2.4 Connecting to Previous Studies", "text": "In fact, it's as if most people who are able to do it are able to determine themselves what they want and what they want. (7) It's as if they were able to determine themselves. (7) It's as if they were able to determine themselves. (7) It's as if they were able to determine themselves. (7) It's as if they weren't able to do it. (8) It's as if they were able to do it, as if they were able to do it, as if they were doing it, as if they were doing it, as if they were doing it, as if they were doing it, as if they were doing it, as if they were doing it, as if they were doing it, as if they were doing it, as if they were doing it, as if they were doing it, as if they were doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing it, doing"}, {"heading": "3 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Benchmark Tasks of Sequence Classification", "text": "Most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to play, to"}, {"heading": "3.2 Experimental Setup", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "3.3 Kernel Calculation Time Performance", "text": "eiD rf\u00fc rf\u00fc ide rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rtef\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the"}, {"heading": "3.4 Empirical Performance", "text": "Figure 1 (b) shows that GaKCo achieves the same empirical performance as gk-SVM (AUC values or F1 values), because GaKCo's patchy k-mer formulation is the same as gk-SVM, but with improved (faster) implementation. In this section, we compare GaKCo's empirical performance with the state-of-the-art CNN model [16]. Figure 7 (b) shows the results in AUC values (or micro-averaged F1 values for web KB) of GaKCo and CNN [16]. For 16 / 19 tasks, GaKCo outperforms the CNN model with an average accuracy of 20%. This result can be explained by the fact that CNNs trained with a small number of samples (1000-10,000 values) often exhibit unstable behavior in training."}, {"heading": "4 Conclusion", "text": "In this paper, we introduced GaKCo, a fast and naturally parallelizable algorithm for calculating a gaping k-mer-based string core. For sequence classification, it is an e-cient and complementary approach to the DNN system when training samples are scarce (see Fig. 7 (b)). Advantages of this work are: - Fast: GaKCo is a novel combination of two e-mer concepts: (1) reduced gaping k-mer attribute space and (2) associative array-based counting method, making it faster than the state-of-the-art gaping k-mer string core with the same accuracy (observed in Fig. 1). - GaKCo can scale to larger values of m and B (Fig. 5 and Fig. 6 (a)))) - Parallelizable: The GaKCo algorithm naturally leads to a parallelizable implementation (Fig. 5 and Fig. 3). We have presented the SVK with the analysis - the best time."}], "references": [{"title": "Predicting the sequence specificities of DNA- and RNA- binding proteins by deep learning", "author": ["Babak Alipanahi", "Andrew Delong", "Matthew T Weirauch", "Brendan J Frey"], "venue": "Nature Biotechnology,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Sequence and chromatin determinants of cell-type\u2013specific transcription factor binding", "author": ["Aaron Arvey", "Phaedra Agius", "William Sta\u21b5ord Noble", "Christina Leslie"], "venue": "Genome research,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Bioinformatics: the machine learning approach", "author": ["Pierre Baldi", "S\u00f8ren Brunak"], "venue": "MIT press,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2001}, {"title": "Improved transition-based parsing by modeling characters instead of words with lstms", "author": ["Miguel Ballesteros", "Chris Dyer", "Noah A Smith"], "venue": "arXiv preprint arXiv:1508.00657,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Improving Methods for Single-label Text, Categorization", "author": ["Ana Cardoso-Cachopo"], "venue": "PdD Thesis, Instituto Superior Tecnico, Universidade Tecnica de Lisboa,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "LIBSVM: A library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Cluster kernels for semi-supervised learning", "author": ["Olivier Chapelle", "Jason Weston", "Bernhard Sch\u00f6lkopf"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "et al", "author": ["ENCODE Project Consortiu"], "venue": "An integrated encyclopedia of dna elements in the human genome. Nature, 489(7414):57\u201374,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Liblinear: A library for large linear classification", "author": ["Rong-En Fan", "Kai-Wei Chang", "Cho-Jui Hsieh", "Xiang-Rui Wang", "Chih-Jen Lin"], "venue": "Journal of machine learning research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Enhanced regulatory sequence prediction using gapped k-mer features", "author": ["Mahmoud Ghandi", "Dongwon Lee", "Morteza Mohammad-Noori", "Michael A Beer"], "venue": "PLoS Comput Biol,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Robust k-mer frequency estimation using gapped k-mers", "author": ["Mahmoud Ghandi", "Morteza Mohammad-Noori", "Michael A Beer"], "venue": "Journal of mathematical biology,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "A discriminative framework for detecting remote protein homologies", "author": ["Tommi Jaakkola", "Mark Diekhans", "David Haussler"], "venue": "Journal of computational biology,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2000}, {"title": "Profilebased string kernels for remote homology detection and motif extraction", "author": ["Rui Kuang", "Eugene Ie", "Ke Wang", "Kai Wang", "Mahira Siddiqi", "Yoav Freund", "Christina Leslie"], "venue": "Journal of bioinformatics and computational biology,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "Scalable algorithms for string kernels with inexact matching", "author": ["Pavel P. Kuksa", "Pai-Hsi Huang", "Vladimir Pavlovic"], "venue": "In NIPS\u201908,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "E cient use of unlabeled data for protein sequence classification: a comparative study", "author": ["Pavel P. Kuksa", "Pai-Hsi Huang", "Vladimir Pavlovic"], "venue": "BMC Bioinformatics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Deep motif dashboard: Visualizing and understanding genomic sequences using deep neural networks", "author": ["Jack Lanchantin", "Ritambhara Singh", "Beilun Wang", "Yanjun Qi"], "venue": "arXiv preprint arXiv:1608.03644,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Fast string kernels using inexact matching for protein sequences", "author": ["Christina Leslie", "Rui Kuang"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "The spectrum kernel: A string kernel for svm protein classification", "author": ["Christina S. Leslie", "Eleazar Eskin", "William Sta\u21b5ord Noble"], "venue": "In Pacific Symposium on Biocomputing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2002}, {"title": "MUST-CNN: A multilayer shift-and-stitch deep convolutional architecture for sequence-based protein structure prediction", "author": ["Zeming Lin", "Jack Lanchantin", "Yanjun Qi"], "venue": "In Proceedings of the 30th AAAI Conference on Artificial Intelligence", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Text classification using string kernels", "author": ["Huma Lodhi", "Craig Saunders", "John Shawe-Taylor", "Nello Cristianini", "Chris Watkins"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2002}, {"title": "Biology: The big challenges of big data", "author": ["Vivien Marx"], "venue": "Nature, 498(7453):255\u2013260,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Aggressive assembly of pyrosequencing reads with mates", "author": ["Jason R Miller", "Arthur L Delcher", "Sergey Koren", "Eli Venter", "Brian P Walenz", "Anushka Brownley", "Justin Johnson", "Kelvin Li", "Clark Mobarry", "Granger Sutton"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}, {"title": "Chip\u2013seq: advantages and challenges of a maturing technology", "author": ["Peter J Park"], "venue": "Nature Reviews Genetics,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "A unified multitask architecture for predicting local protein properties", "author": ["Yanjun Qi", "Merja Oja", "Jason Weston", "William Sta\u21b5ord Noble"], "venue": "PloS One,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Exact algorithms for planted motif problems", "author": ["Sanguthevar Rajasekaran", "Sudha Balla", "C-H Huang"], "venue": "Journal of Computational Biology,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2005}, {"title": "Seqgl identifies context-dependent binding signals in genome-wide regulatory element maps", "author": ["Manu Setty", "Christina S Leslie"], "venue": "PLoS Comput Biol,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Character based string kernels for bio-entity relation detection", "author": ["Ritambhara Singh", "Yanjun Qi"], "venue": "ACL 2016,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Richard Socher", "Alex Perelygin", "Jean Y Wu", "Jason Chuang", "Christopher D Manning", "Andrew Y Ng", "Christopher Potts"], "venue": "In Proceedings of the conference on empirical methods in natural language processing (EMNLP),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "Document modeling with gated recurrent neural network for sentiment classification", "author": ["Duyu Tang", "Bing Qin", "Ting Liu"], "venue": "In EMNLP,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}, {"title": "Statistical Learning Theory", "author": ["Vladimir N. Vapnik"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1998}, {"title": "Alexander Johannes Smola, et al", "author": ["SVN Vishwanathan"], "venue": "Fast kernels for string and tree matching. Kernel methods in computational biology, pages 113\u2013130,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2004}, {"title": "Character-level convolutional networks for text classification", "author": ["Xiang Zhang", "Junbo Zhao", "Yann LeCun"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}, {"title": "Deep supervised and convolutional generative stochastic network for protein secondary structure prediction", "author": ["Jian Zhou", "Olga G Troyanskaya"], "venue": "arXiv preprint arXiv:1403.1347,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2014}], "referenceMentions": [{"referenceID": 20, "context": "For example, with the advancement of sequencing technologies, a massive amount of protein and DNA sequence data is produced daily [21].", "startOffset": 130, "endOffset": 134}, {"referenceID": 16, "context": "SK-SVM methods have been successfully used for classifying sequences like DNA [17, 14, 2, 26], protein [12] or character based natural language text [27].", "startOffset": 78, "endOffset": 93}, {"referenceID": 13, "context": "SK-SVM methods have been successfully used for classifying sequences like DNA [17, 14, 2, 26], protein [12] or character based natural language text [27].", "startOffset": 78, "endOffset": 93}, {"referenceID": 1, "context": "SK-SVM methods have been successfully used for classifying sequences like DNA [17, 14, 2, 26], protein [12] or character based natural language text [27].", "startOffset": 78, "endOffset": 93}, {"referenceID": 25, "context": "SK-SVM methods have been successfully used for classifying sequences like DNA [17, 14, 2, 26], protein [12] or character based natural language text [27].", "startOffset": 78, "endOffset": 93}, {"referenceID": 11, "context": "SK-SVM methods have been successfully used for classifying sequences like DNA [17, 14, 2, 26], protein [12] or character based natural language text [27].", "startOffset": 103, "endOffset": 107}, {"referenceID": 26, "context": "SK-SVM methods have been successfully used for classifying sequences like DNA [17, 14, 2, 26], protein [12] or character based natural language text [27].", "startOffset": 149, "endOffset": 153}, {"referenceID": 29, "context": "They have provided state-of-the-art classification accuracy and can guarantee nice asymptotic behavior due to SVM\u2019s convex formulation and theoretical property [30].", "startOffset": 160, "endOffset": 164}, {"referenceID": 9, "context": "[10] developed the state-of-the-art SK-SVM tool called gk-SVM.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "gk-SVM uses a gapped k-mer formulation [11] that reduces the feature space considerably compared to other k-mer based SK approaches.", "startOffset": 39, "endOffset": 43}, {"referenceID": 13, "context": "GaKCo uses the associative array-based data structure to calculate kernel similarity through cumulative k-mer counting [14].", "startOffset": 119, "endOffset": 123}, {"referenceID": 0, "context": "Related Work: Recently, Deep Neural Networks (NNs) have provided state-of-the-art performances for various sequence classification tasks like analyzing DNA [1, 16], proteins [24, 33], and natural language [32, 28] sequences.", "startOffset": 156, "endOffset": 163}, {"referenceID": 15, "context": "Related Work: Recently, Deep Neural Networks (NNs) have provided state-of-the-art performances for various sequence classification tasks like analyzing DNA [1, 16], proteins [24, 33], and natural language [32, 28] sequences.", "startOffset": 156, "endOffset": 163}, {"referenceID": 23, "context": "Related Work: Recently, Deep Neural Networks (NNs) have provided state-of-the-art performances for various sequence classification tasks like analyzing DNA [1, 16], proteins [24, 33], and natural language [32, 28] sequences.", "startOffset": 174, "endOffset": 182}, {"referenceID": 32, "context": "Related Work: Recently, Deep Neural Networks (NNs) have provided state-of-the-art performances for various sequence classification tasks like analyzing DNA [1, 16], proteins [24, 33], and natural language [32, 28] sequences.", "startOffset": 174, "endOffset": 182}, {"referenceID": 31, "context": "Related Work: Recently, Deep Neural Networks (NNs) have provided state-of-the-art performances for various sequence classification tasks like analyzing DNA [1, 16], proteins [24, 33], and natural language [32, 28] sequences.", "startOffset": 205, "endOffset": 213}, {"referenceID": 27, "context": "Related Work: Recently, Deep Neural Networks (NNs) have provided state-of-the-art performances for various sequence classification tasks like analyzing DNA [1, 16], proteins [24, 33], and natural language [32, 28] sequences.", "startOffset": 205, "endOffset": 213}, {"referenceID": 15, "context": "We compare GaKCo\u2019s empirical performance with a state-of-the-art deep convolutional neural network (CNN) model [16].", "startOffset": 111, "endOffset": 115}, {"referenceID": 29, "context": "In this space, we apply a standard classifier such as Support Vector Machine (SVM) [30].", "startOffset": 83, "endOffset": 87}, {"referenceID": 16, "context": "String kernels ([17, 14, 10]), implicitly compute K(x, x0) as an inner product in the feature space (x) as: K(x, x0) = h (x), (x0)i, (2) 2 There is also one C parameter for tuning SVM training (while using linear kernel)", "startOffset": 16, "endOffset": 28}, {"referenceID": 13, "context": "String kernels ([17, 14, 10]), implicitly compute K(x, x0) as an inner product in the feature space (x) as: K(x, x0) = h (x), (x0)i, (2) 2 There is also one C parameter for tuning SVM training (while using linear kernel)", "startOffset": 16, "endOffset": 28}, {"referenceID": 9, "context": "String kernels ([17, 14, 10]), implicitly compute K(x, x0) as an inner product in the feature space (x) as: K(x, x0) = h (x), (x0)i, (2) 2 There is also one C parameter for tuning SVM training (while using linear kernel)", "startOffset": 16, "endOffset": 28}, {"referenceID": 17, "context": "The string kernel using this representation is called spectrum kernel [18] (see Fig.", "startOffset": 70, "endOffset": 74}, {"referenceID": 10, "context": "[11] introduced a new set of feature representations, called gapped k-mers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "(4) (implemented as gk-SVM [10]) includes only those k-mers whose gapped formulation has appeared as g-mers in a given dataset D.", "startOffset": 27, "endOffset": 31}, {"referenceID": 9, "context": "[10] use this intuition to reformulate Eq.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10] formulate this observation formally into the coe cient hm:", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "Nm(x, x0) is named as mismatch profile by [10].", "startOffset": 42, "endOffset": 46}, {"referenceID": 9, "context": "The state-of-the-art tool gk-SVM [10] calculates Nm(x, x 0) using a trie based data structure that is similar to [17] (with some modifications, details in Section 2.", "startOffset": 33, "endOffset": 37}, {"referenceID": 16, "context": "The state-of-the-art tool gk-SVM [10] calculates Nm(x, x 0) using a trie based data structure that is similar to [17] (with some modifications, details in Section 2.", "startOffset": 113, "endOffset": 117}, {"referenceID": 9, "context": "Implementations GaKCo gk-SVM [10] Pre-processing cgkgNl ug Kernel updates cgkzN 2 \u2318uN Table 2.", "startOffset": 29, "endOffset": 33}, {"referenceID": 9, "context": "\u2318: estimated size of nodelist used in gk-SVM [10].", "startOffset": 45, "endOffset": 49}, {"referenceID": 16, "context": "String Kernels Aside from the spectrum kernel [17] and gapped k-mer kernel [10], a few other notable string kernels include (but are not limited to): (1) (k, m)-Mismatch Kernel.", "startOffset": 46, "endOffset": 50}, {"referenceID": 9, "context": "String Kernels Aside from the spectrum kernel [17] and gapped k-mer kernel [10], a few other notable string kernels include (but are not limited to): (1) (k, m)-Mismatch Kernel.", "startOffset": 75, "endOffset": 79}, {"referenceID": 13, "context": "The cumulative matching statistic idea was first proposed by [14] for this kernel.", "startOffset": 61, "endOffset": 65}, {"referenceID": 30, "context": ", substrings) [31].", "startOffset": 14, "endOffset": 18}, {"referenceID": 12, "context": "profile) [13].", "startOffset": 9, "endOffset": 13}, {"referenceID": 6, "context": "The \u201csequence neighborhood\u201d kernel or \u201ccluster\u201d kernel [7] is a semi-supervised extension of the string kernel.", "startOffset": 55, "endOffset": 58}, {"referenceID": 21, "context": "It has been used previously in tools used for genome assembly [22], discovery of motifs (or most common fixed length patterns) [25], and string kernel calculation [14].", "startOffset": 62, "endOffset": 66}, {"referenceID": 24, "context": "It has been used previously in tools used for genome assembly [22], discovery of motifs (or most common fixed length patterns) [25], and string kernel calculation [14].", "startOffset": 127, "endOffset": 131}, {"referenceID": 13, "context": "It has been used previously in tools used for genome assembly [22], discovery of motifs (or most common fixed length patterns) [25], and string kernel calculation [14].", "startOffset": 163, "endOffset": 167}, {"referenceID": 23, "context": "[24] used a deep multi-layer perceptron (MLP) architecture with multitask learning to perform sequence-based", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "4 Because [14] uses all possible k-mers built from the dictionary with m mismatches as the feature space, the authors [14] need to precompute a complex weight matrix to incorporate all possible k-mers with m mismatches.", "startOffset": 10, "endOffset": 14}, {"referenceID": 13, "context": "4 Because [14] uses all possible k-mers built from the dictionary with m mismatches as the feature space, the authors [14] need to precompute a complex weight matrix to incorporate all possible k-mers with m mismatches.", "startOffset": 118, "endOffset": 122}, {"referenceID": 4, "context": "Text Classification Stanford Treebank Sentiment 3883 3579 877 878 9217 36 260 Dataset from [5] WebKB 335, 620, 744, 1083 166, 306, 371, 538 4163 36 14218", "startOffset": 91, "endOffset": 94}, {"referenceID": 32, "context": "[33] created a generative stochastic network to predict secondary structure on the same data as used by Qi et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24].", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] outperformed all the state-of-the-art works for protein property prediction task by using a deep convolutional neural network architecture.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[1] applied a convolutional neural network model for predicting sequence specificity of DNA and RNA-binding proteins as well as generating motifs, or consensus patterns, from the features that were learned by their model.", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "[16] proposed a deep convolutional/highway MLP framework for the same task and demonstrated improved performance.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "In the field of natural language processing, multiple works like [29] have used deep learning models for document [32] or sentiment [28] classification.", "startOffset": 65, "endOffset": 69}, {"referenceID": 31, "context": "In the field of natural language processing, multiple works like [29] have used deep learning models for document [32] or sentiment [28] classification.", "startOffset": 114, "endOffset": 118}, {"referenceID": 27, "context": "In the field of natural language processing, multiple works like [29] have used deep learning models for document [32] or sentiment [28] classification.", "startOffset": 132, "endOffset": 136}, {"referenceID": 22, "context": "Owing to the development of chromatin immunoprecipitation and massively parallel DNA sequencing (ChIP-seq) technologies [23], maps of genome-wide binding sites are currently available for multiple TFs across di\u21b5erent organisms.", "startOffset": 120, "endOffset": 124}, {"referenceID": 2, "context": "Protein sequences that are a part of the same protein superfamily are evolutionally related and functionally and structurally relevant to each other [3].", "startOffset": 149, "endOffset": 152}, {"referenceID": 26, "context": "Several recent studies have discovered that character-based representation provides straightforward and powerful models for relation extraction [27], sentiment classification [32], and transition based parsing [4].", "startOffset": 144, "endOffset": 148}, {"referenceID": 31, "context": "Several recent studies have discovered that character-based representation provides straightforward and powerful models for relation extraction [27], sentiment classification [32], and transition based parsing [4].", "startOffset": 175, "endOffset": 179}, {"referenceID": 3, "context": "Several recent studies have discovered that character-based representation provides straightforward and powerful models for relation extraction [27], sentiment classification [32], and transition based parsing [4].", "startOffset": 210, "endOffset": 213}, {"referenceID": 19, "context": "[20] first used string kernels with character level features for text categorization.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Over recent years, more e cient string kernel methods have been devised [17, 13\u201315, 10].", "startOffset": 72, "endOffset": 87}, {"referenceID": 12, "context": "Over recent years, more e cient string kernel methods have been devised [17, 13\u201315, 10].", "startOffset": 72, "endOffset": 87}, {"referenceID": 13, "context": "Over recent years, more e cient string kernel methods have been devised [17, 13\u201315, 10].", "startOffset": 72, "endOffset": 87}, {"referenceID": 14, "context": "Over recent years, more e cient string kernel methods have been devised [17, 13\u201315, 10].", "startOffset": 72, "endOffset": 87}, {"referenceID": 9, "context": "Over recent years, more e cient string kernel methods have been devised [17, 13\u201315, 10].", "startOffset": 72, "endOffset": 87}, {"referenceID": 7, "context": "Datasets: ENCODE ChIP-Seq DNA Sequences: Maps of genome-wide binding sites are currently available for multiple TFs for human genome via the ENCODE [8] database.", "startOffset": 148, "endOffset": 151}, {"referenceID": 11, "context": "SCOP Protein Sequences: The SCOP domain database consists of protein domains, no two of which have 90% or more residual identity [12].", "startOffset": 129, "endOffset": 133}, {"referenceID": 4, "context": ") from [5].", "startOffset": 7, "endOffset": 10}, {"referenceID": 27, "context": "For the sentiment analysis experiments, we used the Stanford sentiment treebank dataset [28].", "startOffset": 88, "endOffset": 92}, {"referenceID": 0, "context": "The dictionary includes all the alphabets [A-Z] and numbers [0-9].", "startOffset": 60, "endOffset": 65}, {"referenceID": 1, "context": "The dictionary includes all the alphabets [A-Z] and numbers [0-9].", "startOffset": 60, "endOffset": 65}, {"referenceID": 2, "context": "The dictionary includes all the alphabets [A-Z] and numbers [0-9].", "startOffset": 60, "endOffset": 65}, {"referenceID": 3, "context": "The dictionary includes all the alphabets [A-Z] and numbers [0-9].", "startOffset": 60, "endOffset": 65}, {"referenceID": 4, "context": "The dictionary includes all the alphabets [A-Z] and numbers [0-9].", "startOffset": 60, "endOffset": 65}, {"referenceID": 5, "context": "The dictionary includes all the alphabets [A-Z] and numbers [0-9].", "startOffset": 60, "endOffset": 65}, {"referenceID": 6, "context": "The dictionary includes all the alphabets [A-Z] and numbers [0-9].", "startOffset": 60, "endOffset": 65}, {"referenceID": 7, "context": "The dictionary includes all the alphabets [A-Z] and numbers [0-9].", "startOffset": 60, "endOffset": 65}, {"referenceID": 8, "context": "The dictionary includes all the alphabets [A-Z] and numbers [0-9].", "startOffset": 60, "endOffset": 65}, {"referenceID": 9, "context": "Baselines: We compare the kernel calculation times and empirical performance of GaKCo with gk-SVM [10].", "startOffset": 98, "endOffset": 102}, {"referenceID": 15, "context": "We also run the CNN implementation from [16] for all the datasets.", "startOffset": 40, "endOffset": 44}, {"referenceID": 8, "context": "Classification: After calculation, we input the N \u21e5 N kernel matrix into an SVM classifier as an empirical feature map using a linear kernel in LIBLINEAR [9].", "startOffset": 154, "endOffset": 157}, {"referenceID": 5, "context": "For the multi-class classification of WebKB data, we use the multi-class version of LIBSVM [6].", "startOffset": 91, "endOffset": 94}, {"referenceID": 15, "context": "(b) Di\u21b5erences in AUC Scores (or micro-averaged F1-score for Web-KB) between GaKCo and state-of-the-art CNN model [16].", "startOffset": 114, "endOffset": 118}, {"referenceID": 15, "context": "In this section, we compare GaKCo\u2019s empirical performance with state-of-theart CNN model [16].", "startOffset": 89, "endOffset": 93}, {"referenceID": 15, "context": "7 (b) shows the di\u21b5erences in AUC Scores (or micro-averaged F1-score for Web-KB) of GaKCo and CNN [16].", "startOffset": 98, "endOffset": 102}], "year": 2017, "abstractText": "String Kernel (SK) techniques, especially those using gapped k-mers as features (gk), have obtained great success in classifying sequences like DNA, protein, and text. However, the state-of-the-art gk-SK runs extremely slow when we increase the dictionary size (\u2303) or allow more number of mismatches (M). This is because current gk-SK uses a trie-based algorithm to calculate co-occurrence of mismatched substrings resulting in a time cost proportional to O(\u2303 ). We propose a fast algorithm for calculating Gapped k-mer Kernel using Counting (GaKCo). GaKCo uses associative arrays to calculate the co-occurrence of substrings using cumulative counting. This algorithm is fast, scalable to larger \u2303 and M , and naturally parallelizable. We provide a rigorous asymptotic analysis that compares GaKCo with the state-of-the-art gk-SK. Theoretically, the time cost of GaKCo is independent of the \u2303 term that slows down the trie-based approach. Experimentally, we observe that GaKCo achieves the same accuracy as the state-of-the-art and outperforms its speed by factors of 2, 100, and 4, on classifying sequences of DNA (5 datasets), protein (12 datasets), and character-based English text (2 datasets), respectively .", "creator": "LaTeX with hyperref package"}}}