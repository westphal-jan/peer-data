{"id": "1704.07626", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Apr-2017", "title": "Taxonomy Induction using Hypernym Subsequences", "abstract": "We propose a novel, semi-supervised approach towards domain taxonomy induction from an input vocabulary of seed terms. Unlike most previous approaches, which typically extract direct hypernym edges for terms, our approach utilizes a novel probabilistic framework to extract hypernym subsequences. Taxonomy induction from extracted subsequences is cast as an instance of the minimum-cost flow problem on a carefully designed directed graph. Through experiments, we demonstrate that our approach outperforms state-of-the-art taxonomy induction approaches across four languages. Furthermore, we show that our approach is robust to the presence of noise in the input vocabulary.", "histories": [["v1", "Tue, 25 Apr 2017 10:49:53 GMT  (432kb,D)", "https://arxiv.org/abs/1704.07626v1", null], ["v2", "Fri, 5 May 2017 17:03:17 GMT  (432kb,D)", "http://arxiv.org/abs/1704.07626v2", null], ["v3", "Fri, 26 May 2017 14:42:59 GMT  (2114kb,D)", "http://arxiv.org/abs/1704.07626v3", null], ["v4", "Thu, 14 Sep 2017 20:34:26 GMT  (2657kb,D)", "http://arxiv.org/abs/1704.07626v4", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.IR", "authors": ["amit gupta", "r\\'emi lebret", "hamza harkous", "karl aberer"], "accepted": false, "id": "1704.07626"}, "pdf": {"name": "1704.07626.pdf", "metadata": {"source": "META", "title": "Taxonomy Induction Using Hypernym Subsequences", "authors": ["Amit Gupta", "R\u00e9mi Lebret", "Hamza Harkous", "Karl Aberer"], "emails": ["amit.gupta@epfl.ch", "remi.lebret@epfl.ch", "hamza.harkous@epfl.ch", "karl.aberer@epfl.ch", "permissions@acm.org."], "sections": [{"heading": null, "text": "CCS CONCEPTS \u2022 Computer Methods \u2192 Artificial Intelligence; Information Extraction; Ontology Engineering; Semantic Networks; KEYWORDS Knowledge Acquisition; Taxonomy Induction; Term Taxonomy; Algorithms; Flow Networks; Optimization of Minimal Costs;"}, {"heading": "1 INTRODUCTION", "text": "The idea behind it is that the two protagonists, who in recent years have come into the public eye in the USA, in Europe, in Europe, in Europe and throughout the world, are a kind of counter-reaction that is taking place in the USA. (...) The idea behind it is not new, but it is that it has established itself in the USA, in Europe and throughout the world. (...) The idea behind it is that the people in the USA, in the USA, in the USA, in Europe, in Europe, in Europe, in Europe, in Europe, in the USA, in Europe, in the USA, in Europe, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in Europe, in the USA, in the USA, in the USA, in Europe and in the USA, in the USA, in the USA, in the USA and in the USA, in the USA, in the USA, in the USA and in the USA, in the USA, in the USA, in the USA and in the USA, in the USA, in the USA and in the USA, in the USA, in the USA, in the USA and in the USA, in the USA, in the USA, in the USA, in the USA, in the USA and in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the"}, {"heading": "2 TAXONOMY INDUCTION", "text": "Considering a potentially noisy vocabulary 1 of the seed terms as input, we define our goal as the introduction of a taxonomy consisting of these seed terms (and possibly other terms).This taxonomy is a directed acyclic graph with terms such as the nodes and edges that a1In this work, we use terminology and vocabulary interchangeable.For our task, we assume the availability of a database of hypernymic relationships between candidates. Over the years, several such resources have been compiled and made publicly available. A prominent example of such a resource is WebIsA [33], a collection of more than 400 million hypernymic relationships in English extracted from the commoncrawl web corpus using lexico-syntactic patterns. However, such resources come with a significant number of loud candidate hyperonnyms (which typically contain a mixture of relationships such as hypersequonymy, synonymy, and hyponymy)."}, {"heading": "2.1 Hypernym Subsequences Extraction", "text": "In fact, it is so that it is a matter of a way in which it concerns the terminology of people who are able to move in the world. (...) It is as if they were able to move in the world. (...) It is as if they were able to move in the world. (...) It is as if they were able to move in the world. (...) It is as if they were able to move in the world. (...) It is as if they were able to move in the world of the world, in the world of the world, in the world of the world, in the world of the world, in the world of the world, in the world of the world, in the world of the world, in the world of the world, in the world of the world, in the world of the world, in the world of the world, in the world of the world, in the world of the world, in the world of the world, in the world, in the world, in the world of the world, in the world in the world, in the world of the world, in the world of the world, in the world of the world, in the world of the world, in the world in the world of the world, in the world of the world in the world in the world, in the world of the world in the world, in the world of the world in the world in the world, in the world in the world in the world in the world in the world, in the world of the world in the world in the world in the world, in the world in the world in the world in the world, in the world in the world in the world in the world, in the world in the world in the world in the world, in the world in the world in the world in the world, in the world in the world in the world in the world, in the world in the world in the world, in the world in the world in the world, in the world in the world in the world, in the world in the world, in the world in the world, in the world in the world in the world, in the world in the world, in the world in the world in the world in the world, in the world in the world in the world, in the world in the world, in the world in the world in the world of the, in the world in the world in the"}, {"heading": "2.2 Aggregation of Subsequences", "text": "In this section, we aggregate the hypernym subsequences we obtained for a number of seed terms to construct an initial hypernym graph by performing the following steps: domain filtering. In the case of a term t0, the usual case is that several hypernym subsequences corresponding to different senses of the term t0 are extracted. For example, apple may be a company or a fruit, resulting in sub-sequences Apple \u2192 Fruit and Apple \u2192 Software Companies. However, many of these sub-sequences do not belong to the sphere of interest (as determined by the seed terms). To eliminate the irrelevant ones, we estimate a smoothed unigram model5 from all the extracted sub-sequences, and we remove those with probabilities of generation below a fixed threshold. Hypernym graph construction."}, {"heading": "2.3 Taxonomy Construction", "text": "In this step, we aim to generate a tree-like taxonomy from the hypernym DAG, which we select in the previous step. We cast this as an example of the Minimum Cost Flow Problem (MCFP). MCFP is an optimization problem that aims to find the cheapest way to flow a certain amount of flow through a flow network. It has been used to find the optimal solution in applications such as the transportation problem, where the goal is to send the cheapest routes from a group of facilities to customers via a transport network. Similarly, we cast the problem of taxonomy induction as the cheapest way that leads the seeds terms to the basic concepts."}, {"heading": "3 EVALUATION", "text": "The aim of the empirical evaluation is to answer the following questions: \u25cf How does our approach compare to the state of the art under the assumption of a clean input vocabulary? \u25cf How does our approach work with a loud input vocabulary? \u25cf What are the advantages of extracting longer hypernym subsequences in comparison to individual hypernym edges? To this end, we conduct two experiments. In Section 3.1, we then compare our taxonomy induction approach with the state of the art under the simplified assumption of a clean input vocabulary. The evaluations are performed automatically by calculating standard precision, recall and F1 measures against a gold standard. Subsequently, we drop the simplistic assumption into Section 3.2, where we show that our taxonomy induction works well even under the presence of significant noise in the input vocabulary. The evaluation is performed both manually and automatically against WordNet as the gold standard."}, {"heading": "3.1 Evaluation against the State of the Art", "text": "In fact, it is the case that one will be able to move to another world, in which one must move to another world, in which one can move to another world, in which one must move to another world, in which one can move to another world, in which one must move to another world, in which one can move to another world, in which one can move to another world, in which one can move to another world."}, {"heading": "3.2 Evaluation with Noisy Vocabulary", "text": "In the previous experiment, we performed a taxonomy induction under the simplistic assumption that a clean input vocabulary of the relevant domain terms is available. However, as explained in Section 1, this assumption is rarely fulfilled for most domains. Therefore, in this experiment, we evaluate the performance of SubSeq in the presence of significant disruptors in the input mask, which is an edges-based variant of SubSeq.Setup. We first build a corpus of relevant documents for the food domain by comparing all English Wikipedia articles with titles that match at least one seed term (post-lemmatization) in the SemEval food vocabulary."}, {"heading": "4 RELATEDWORK", "text": "In fact, the fact is that most of them are able to survive themselves, and that they are able to survive themselves, \"he said in an interview with the\" New York Times. \""}, {"heading": "5 CONCLUSIONS", "text": "In this paper, we have proposed a new probabilistic framework for extracting hypernym subsequences from individual hypernomy relationships and presented an approach to minimize cost-flow optimization in taxonomy induction from a loud hypernym graph. We have demonstrated that our subsequence-based approach outperforms state-of-the-art approaches to taxonomy induction that utilize individual hypernomy edge characteristics. Contrary to previous approaches, our approach to taxonomy induction is robust against the significant presence of noise in input terminology. It also provides a user-defined parameter to control the accuracy and coverage of terms and edges in output taxonomies. As a result, our approach is applicable to any area without manual intervention, thereby truly automating the process of taxonomy induction. This work is supported by a Sinergia grant from the Swiss National Foundation for Marijuana Science (SNF) (SNF 14\u015fca)."}], "references": [{"title": "Unsupervised learning of an is-a taxonomy from a limited domain-specific corpus", "author": ["Daniele Alfarone", "Jesse Davis"], "venue": "In Proceedings of the 24th International Joint Conference on Artificial Intelligence", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Structured Learning for Taxonomy Induction with Belief Propagation", "author": ["Mohit Bansal", "David Burkett", "Gerard De Melo", "Dan Klein"], "venue": "ACL", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Ontology Learning from Text: A Survey of Methods", "author": ["Chris Biemann"], "venue": "LDV Forum 20,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "Semeval-2015 task 17: Taxonomy Extraction Evaluation (TExEval)", "author": ["Georgeta Bordea", "Paul Buitelaar", "Stefano Faralli", "Roberto Navigli"], "venue": "In Proceedings of the 9th International Workshop on Semantic Evaluation", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Semeval-2016 task 13: Taxonomy Extraction Evaluation (TExEval-2)", "author": ["Georgeta Bordea", "Els Lefever", "Paul Buitelaar"], "venue": "In Proceedings of the 10th International Workshop on Semantic Evaluation", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Termsuite: Terminology extraction with term variant detection", "author": ["Damien Cram", "B\u00e9atrice Daille"], "venue": "ACL 2016 (2016),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "MultiWiBi: The multilingual Wikipedia bitaxonomy project", "author": ["Tiziano Flati", "Daniele Vannella", "Tommaso Pasini", "Roberto Navigli"], "venue": "Artif. Intell", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "INRIASAC: Simple hypernym extraction methods", "author": ["Gregory Grefenstette"], "venue": "arXiv preprint arXiv:1502.01271", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Birds with One Stone: Inducing Multilingual Taxonomies from Wikipedia using Characterlevel Classification", "author": ["Amit Gupta", "R\u00e9mi Lebret", "Hamza Harkous", "Karl Aberer"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2017}, {"title": "Revisiting Taxonomy Induction overWikipedia", "author": ["Amit Gupta", "Francesco Piccinno", "Mikhail Kozhevnikov", "Marius Pasca", "Daniele Pighin"], "venue": "COLING", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Expert-Built and Collaboratively Constructed Lexical Semantic Resources", "author": ["Iryna Gurevych", "Elisabeth Wolf"], "venue": "Language and Linguistics Compass 4,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Automatic acquisition of hyponyms from large text corpora", "author": ["Marti A Hearst"], "venue": "In Proceedings of the 14th conference on Computational linguistics-Volume 2. Association for Computational Linguistics,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1992}, {"title": "YAGO2: A spatially and temporally enhanced knowledge base from Wikipedia", "author": ["Johannes Hoffart", "Fabian M. Suchanek", "Klaus Berberich", "Gerhard Weikum"], "venue": "Artif. Intell", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Toward completeness in concept extraction and classification", "author": ["Eduard Hovy", "Zornitsa Kozareva", "Ellen Riloff"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2-Volume", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Collaboratively built semi-structured content and Artificial Intelligence: The story so far", "author": ["Eduard H. Hovy", "Roberto Navigli", "Simone Paolo Ponzetto"], "venue": "Artif. Intell", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "A primal method for minimal cost flows with applications to the assignment and transportation problems", "author": ["Morton Klein"], "venue": "Management Science 14,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1967}, {"title": "Linked hypernyms dataset-generation framework and use cases. In 3rd Workshop on Linked Data in  Linguistics: Multilingual Knowledge Resources and Natural Language Processing", "author": ["Tom\u00e1\u0161 Kliegr", "V\u00e1clav Zeman", "Milan Dojchinovski"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "A semi-supervised method to learn and construct taxonomies using the web", "author": ["Zornitsa Kozareva", "Eduard Hovy"], "venue": "In Proceedings of the 2010 conference on empirical methods in natural language processing. Association for Computational Linguistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs", "author": ["Zornitsa Kozareva", "Ellen Riloff", "Eduard H Hovy"], "venue": "In ACL,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "CYC: A large-scale investment in knowledge infrastructure", "author": ["Douglas B Lenat"], "venue": "Commun. ACM 38,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1995}, {"title": "WORDNET: A Lexical Database for English. In Human Language Technology, Proceedings of a Workshop held at Plainsboro, New Jerey", "author": ["George A. Miller"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1994}, {"title": "PATTY: a taxonomy of relational patterns with semantic types", "author": ["Ndapandula Nakashole", "Gerhard Weikum", "Fabian Suchanek"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Association for Computational Linguistics,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "WikiNet: A Very Large Scale Multi-Lingual Concept Network", "author": ["Vivi Nastase", "Michael Strube", "Benjamin Boerschinger", "C\u00e4cilia Zirn", "Anas Elghafari"], "venue": "In Proceedings of the International Conference on Language Resources and Evaluation,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "A graph-based algorithm for inducing lexical taxonomies from scratch", "author": ["Roberto Navigli", "Paola Velardi", "Stefano Faralli"], "venue": "In IJCAI,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Using Hearst\u2019s Rules for the Automatic Acquisition of Hyponyms for Mining a Pharmaceutical Corpus", "author": ["Michael P Oakes"], "venue": "In RANLP Text Mining Workshop,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2005}, {"title": "A polynomial time primal network simplex algorithm for minimum cost flows", "author": ["James B Orlin"], "venue": "Mathematical Programming 78,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1997}, {"title": "TAXI at SemEval-2016 Task 13: a taxonomy induction method based on lexico-syntactic patterns, substrings and focused crawling", "author": ["Alexander Panchenko", "Stefano Faralli", "Eugen Ruppert", "Steffen Remus", "Hubert Naets", "C\u00e9drick Fairon", "Simone Paolo Ponzetto", "Chris Biemann"], "venue": "Proceedings of SemEval (2016),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Deriving a Large Scale Taxonomy from Wikipedia", "author": ["S. Ponzetto", "M. Strube"], "venue": "In Proceedings of the 22nd National Conference on Artificial Intelligence. Vancouver, British Columbia,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2007}, {"title": "WikiTaxonomy: A Large Scale Knowledge Resource", "author": ["Simone Paolo Ponzetto", "Michael Strube"], "venue": "In ECAI 2008 - 18th European Conference on Artificial Intelligence,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2008}, {"title": "Taxonomy induction based on a collaboratively built knowledge repository", "author": ["Simone Paolo Ponzetto", "Michael Strube"], "venue": "Artificial Intelligence 175,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2011}, {"title": "Termextractor: a web application to learn the shared terminology of emergent web communities", "author": ["Francesco Sclano", "Paola Velardi"], "venue": "In Enterprise Interoperability II. Springer,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2007}, {"title": "A Large DataBase of Hypernymy Relations Extracted from the Web", "author": ["Julian Seitner", "Christian Bizer", "Kai Eckert", "Stefano Faralli", "Robert Meusel", "Heiko Paulheim", "Simone Paolo Ponzetto"], "venue": "In Proceedings of the Tenth International Conference on Language Resources and Evaluation LREC 2016, Portoroz\u030c,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2016}, {"title": "Semantic taxonomy induction from heterogenous evidence", "author": ["Rion Snow", "Daniel Jurafsky", "Andrew Y Ng"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics. Association for Computational Linguistics,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2006}, {"title": "Yago: a core of semantic knowledge", "author": ["Fabian M. Suchanek", "Gjergji Kasneci", "Gerhard Weikum"], "venue": "In Proceedings of the 16th International Conference on World Wide Web,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2007}, {"title": "The singularity is not near: slowing growth of Wikipedia", "author": ["Bongwon Suh", "Gregorio Convertino", "Ed H Chi", "Peter Pirolli"], "venue": "In Proceedings of the 5th International Symposium on Wikis and Open Collaboration. ACM,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2009}, {"title": "OntoLearn Reloaded: A Graph-Based Algorithm for Taxonomy Induction", "author": ["Paola Velardi", "Stefano Faralli", "Roberto Navigli"], "venue": "Computational Linguistics 39,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2013}, {"title": "Unsupervised methods for developing taxonomies by combining syntactic and statistical information", "author": ["Dominic Widdows"], "venue": "In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2003}, {"title": "A metric-based framework for automatic taxonomy induction", "author": ["Hui Yang", "Jamie Callan"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2009}], "referenceMentions": [{"referenceID": 2, "context": "Lexical semantic knowledge in the form of term taxonomies has been beneficial in a variety of NLP tasks, including inference, textual entailment, question answering and information extraction [3].", "startOffset": 192, "endOffset": 195}, {"referenceID": 20, "context": "tiple large-scale manual efforts towards taxonomy induction, such asWordNet [22] and Cyc [21].", "startOffset": 76, "endOffset": 80}, {"referenceID": 19, "context": "tiple large-scale manual efforts towards taxonomy induction, such asWordNet [22] and Cyc [21].", "startOffset": 89, "endOffset": 93}, {"referenceID": 13, "context": "However, such manually constructed taxonomies suffer from low coverage [15] and are unavailable for", "startOffset": 71, "endOffset": 75}, {"referenceID": 3, "context": "Therefore, in recent years, there has been substantial interest in extending existing taxonomies automatically or building new ones [4, 5, 19, 34, 38, 40].", "startOffset": 132, "endOffset": 154}, {"referenceID": 4, "context": "Therefore, in recent years, there has been substantial interest in extending existing taxonomies automatically or building new ones [4, 5, 19, 34, 38, 40].", "startOffset": 132, "endOffset": 154}, {"referenceID": 17, "context": "Therefore, in recent years, there has been substantial interest in extending existing taxonomies automatically or building new ones [4, 5, 19, 34, 38, 40].", "startOffset": 132, "endOffset": 154}, {"referenceID": 32, "context": "Therefore, in recent years, there has been substantial interest in extending existing taxonomies automatically or building new ones [4, 5, 19, 34, 38, 40].", "startOffset": 132, "endOffset": 154}, {"referenceID": 35, "context": "Therefore, in recent years, there has been substantial interest in extending existing taxonomies automatically or building new ones [4, 5, 19, 34, 38, 40].", "startOffset": 132, "endOffset": 154}, {"referenceID": 37, "context": "Therefore, in recent years, there has been substantial interest in extending existing taxonomies automatically or building new ones [4, 5, 19, 34, 38, 40].", "startOffset": 132, "endOffset": 154}, {"referenceID": 11, "context": "In contrast, Pattern-based approaches utilize pre-defined rules or lexico-syntactic patterns to extract terms and hypernymy relations from text [13, 26].", "startOffset": 144, "endOffset": 152}, {"referenceID": 24, "context": "In contrast, Pattern-based approaches utilize pre-defined rules or lexico-syntactic patterns to extract terms and hypernymy relations from text [13, 26].", "startOffset": 144, "endOffset": 152}, {"referenceID": 11, "context": "Patterns are either chosen manually [13, 20] or learnt automatically via bootstrapping [35].", "startOffset": 36, "endOffset": 44}, {"referenceID": 18, "context": "Patterns are either chosen manually [13, 20] or learnt automatically via bootstrapping [35].", "startOffset": 36, "endOffset": 44}, {"referenceID": 32, "context": "Early work on the second stage of taxonomy induction, namely the structured organization of terms into a taxonomy, focused on extending existing partial taxonomies such asWordNet by inserting missing terms at appropriate positions [34, 39, 40].", "startOffset": 231, "endOffset": 243}, {"referenceID": 36, "context": "Early work on the second stage of taxonomy induction, namely the structured organization of terms into a taxonomy, focused on extending existing partial taxonomies such asWordNet by inserting missing terms at appropriate positions [34, 39, 40].", "startOffset": 231, "endOffset": 243}, {"referenceID": 37, "context": "Early work on the second stage of taxonomy induction, namely the structured organization of terms into a taxonomy, focused on extending existing partial taxonomies such asWordNet by inserting missing terms at appropriate positions [34, 39, 40].", "startOffset": 231, "endOffset": 243}, {"referenceID": 0, "context": "corpus or the Web [1, 2, 19, 25, 28, 38].", "startOffset": 18, "endOffset": 40}, {"referenceID": 1, "context": "corpus or the Web [1, 2, 19, 25, 28, 38].", "startOffset": 18, "endOffset": 40}, {"referenceID": 17, "context": "corpus or the Web [1, 2, 19, 25, 28, 38].", "startOffset": 18, "endOffset": 40}, {"referenceID": 23, "context": "corpus or the Web [1, 2, 19, 25, 28, 38].", "startOffset": 18, "endOffset": 40}, {"referenceID": 26, "context": "corpus or the Web [1, 2, 19, 25, 28, 38].", "startOffset": 18, "endOffset": 40}, {"referenceID": 35, "context": "corpus or the Web [1, 2, 19, 25, 28, 38].", "startOffset": 18, "endOffset": 40}, {"referenceID": 23, "context": "Automated taxonomy induction from scratch is preferred because it can be used over arbitrary domains, including highly specific or technical domains, such as Finance or Artificial Intelligence [25].", "startOffset": 193, "endOffset": 197}, {"referenceID": 10, "context": "frequent and the most important nouns, adjectives, verbs, and adverbs [11, 23].", "startOffset": 70, "endOffset": 78}, {"referenceID": 21, "context": "frequent and the most important nouns, adjectives, verbs, and adverbs [11, 23].", "startOffset": 70, "endOffset": 78}, {"referenceID": 16, "context": "Similarly,Wikipedia is limited to popular entities [18], and its utility is further diminished by slowed growth [37].", "startOffset": 51, "endOffset": 55}, {"referenceID": 34, "context": "Similarly,Wikipedia is limited to popular entities [18], and its utility is further diminished by slowed growth [37].", "startOffset": 112, "endOffset": 116}, {"referenceID": 26, "context": "Past approaches to taxonomy induction from scratch either assume the availability of a clean input vocabulary [28] or employ a time-consuming manual cleaning step over a noisy input vocabulary [38].", "startOffset": 110, "endOffset": 114}, {"referenceID": 35, "context": "Past approaches to taxonomy induction from scratch either assume the availability of a clean input vocabulary [28] or employ a time-consuming manual cleaning step over a noisy input vocabulary [38].", "startOffset": 193, "endOffset": 197}, {"referenceID": 35, "context": "Figure 1: Traditional process for taxonomy induction from a domain-specific corpus [38].", "startOffset": 83, "endOffset": 87}, {"referenceID": 35, "context": "taxonomy induction approach from a domain corpus [38].", "startOffset": 49, "endOffset": 53}, {"referenceID": 30, "context": "tial noisy vocabulary is automatically extracted from the domain corpus using a term extraction tool, such as TermExtractor [32], and is further cleaned manually to produce the final vocabulary.", "startOffset": 124, "endOffset": 128}, {"referenceID": 31, "context": "A prominent example of such a resource is WebIsA [33], a collection of more than 400 million hypernymy relations for English, extracted from the CommonCrawl web corpus using lexico-syntactic patterns.", "startOffset": 49, "endOffset": 53}, {"referenceID": 17, "context": "Unsupervised or semi-supervised approaches to taxonomy induction typically aim to extract single hypernym edges among terms from noisy candidate hypernyms [19, 28].", "startOffset": 155, "endOffset": 163}, {"referenceID": 26, "context": "Unsupervised or semi-supervised approaches to taxonomy induction typically aim to extract single hypernym edges among terms from noisy candidate hypernyms [19, 28].", "startOffset": 155, "endOffset": 163}, {"referenceID": 35, "context": "[38], who demonstrated that hypernym extraction becomes increasingly erroneous as the generality of terms increases, mainly due to the increase in term ambiguity.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "3Lexical heads of terms have consistently played a special role in taxonomy induction [10, 31].", "startOffset": 86, "endOffset": 94}, {"referenceID": 29, "context": "3Lexical heads of terms have consistently played a special role in taxonomy induction [10, 31].", "startOffset": 86, "endOffset": 94}, {"referenceID": 26, "context": "Equation 5): \u25cf Normalized Frequency Diff (nd ): Similar to [28], this feature is an asymmetric hypernymy score based on frequency counts.", "startOffset": 59, "endOffset": 63}, {"referenceID": 15, "context": "It has been used to find the optimal solution in applications like the transportation problem [17], where the goal is to find the cheapest paths to send commodities from a group of facilities to the customers via a transportation network.", "startOffset": 94, "endOffset": 98}, {"referenceID": 25, "context": "We use the network simplex algorithm [27] to compute the optimal flow for F , and we select all edges with positive flow as part of our final taxonomy.", "startOffset": 37, "endOffset": 41}, {"referenceID": 35, "context": "6If roots are not provided, a small set of upper terms can be used as roots [38].", "startOffset": 76, "endOffset": 80}, {"referenceID": 4, "context": "We use the setting of the SemEval 2016 task for taxonomy extraction [5].", "startOffset": 68, "endOffset": 71}, {"referenceID": 26, "context": "first place in all subtasks of the SemEval task [28].", "startOffset": 48, "endOffset": 52}, {"referenceID": 26, "context": "[28] also report that alternate configurations of TAXI with different term-level and edge-level features as well as different classifiers such as Logistic Regression, Gradient Boosted Trees, and Random Forest fail to provide improvements over their approach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "We run TermSuite [6], a state-of-the-art term extraction approach to extract an initial terminology of 12,645 terms.", "startOffset": 17, "endOffset": 20}, {"referenceID": 36, "context": "Widdows [39] places the missing terms in regions with most semantically-similar neighbors.", "startOffset": 8, "endOffset": 12}, {"referenceID": 32, "context": "[34] use a probabilistic model to attach novel terms in an incremental greedy fashion, such that the conditional probability of a set of relational evidence given a taxonomy is maximized.", "startOffset": 0, "endOffset": 4}, {"referenceID": 37, "context": "Yang and Callan [40]", "startOffset": 16, "endOffset": 20}, {"referenceID": 27, "context": "WikiTaxonomy [29, 30] labels these links as hypernymy or non-hypernymy, using a cascade of", "startOffset": 13, "endOffset": 21}, {"referenceID": 28, "context": "WikiTaxonomy [29, 30] labels these links as hypernymy or non-hypernymy, using a cascade of", "startOffset": 13, "endOffset": 21}, {"referenceID": 11, "context": "heuristics based on the syntactic structure of Wikipedia category labels, the topology of the network and lexico-syntactic patterns for detecting subsumption and meronymy, similar to Hearst patterns [13].", "startOffset": 199, "endOffset": 203}, {"referenceID": 22, "context": "WikiNet [24] extends WikiTaxonomy by expanding non-", "startOffset": 8, "endOffset": 12}, {"referenceID": 12, "context": "YAGO induces a taxonomy by employing heuristics linking Wikipedia categories to corresponding synsets in WordNet [14].", "startOffset": 113, "endOffset": 117}, {"referenceID": 6, "context": "[7] and Gupta et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] propose approaches towardsmultilingual taxonomy induction fromWikipedia,", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "[16], these taxonomy induction approaches are non-transferable, i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "Kozareva and Hovy [19] start from an initial set of root terms and basic level terms and use hearst-like lexico-syntactic patterns recursively to harvest new terms from the Web.", "startOffset": 18, "endOffset": 22}, {"referenceID": 35, "context": "[38] extract hypernymy relations from textual definitions discovered on the Web, and further employ an optimal branching algorithm to induce a taxonomy.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[4, 5] introduced the first shared tasks on open-domain Taxonomy Extraction, thus providing a common ground for evaluation.", "startOffset": 0, "endOffset": 6}, {"referenceID": 4, "context": "[4, 5] introduced the first shared tasks on open-domain Taxonomy Extraction, thus providing a common ground for evaluation.", "startOffset": 0, "endOffset": 6}, {"referenceID": 7, "context": "INRIASAC, the top system in 2015 task, uses features based on substrings and co-occurrence statistics [8] whereas TAXI, the top system in 2016 task, uses lexico-syntactic patterns, substrings and focused crawling [28].", "startOffset": 102, "endOffset": 105}, {"referenceID": 26, "context": "INRIASAC, the top system in 2015 task, uses features based on substrings and co-occurrence statistics [8] whereas TAXI, the top system in 2016 task, uses lexico-syntactic patterns, substrings and focused crawling [28].", "startOffset": 213, "endOffset": 217}, {"referenceID": 35, "context": "removing hypernyms corresponding to domain-irrelevant senses of the terms [38].", "startOffset": 74, "endOffset": 78}, {"referenceID": 1, "context": "Although taxonomies should ideally contain senses rather than terms, term taxonomies have shown significant efficacy in a variety of NLP tasks [2, 3, 38].", "startOffset": 143, "endOffset": 153}, {"referenceID": 2, "context": "Although taxonomies should ideally contain senses rather than terms, term taxonomies have shown significant efficacy in a variety of NLP tasks [2, 3, 38].", "startOffset": 143, "endOffset": 153}, {"referenceID": 35, "context": "Although taxonomies should ideally contain senses rather than terms, term taxonomies have shown significant efficacy in a variety of NLP tasks [2, 3, 38].", "startOffset": 143, "endOffset": 153}], "year": 2017, "abstractText": "We propose a novel, semi-supervised approach towards domain taxonomy induction from an input vocabulary of seed terms. Unlike all previous approaches, which typically extract direct hypernym edges for terms, our approach utilizes a novel probabilistic framework to extract hypernym subsequences. Taxonomy induction from extracted subsequences is cast as an instance of the minimumcost flow problem on a carefully designed directed graph. Through experiments, we demonstrate that our approach outperforms stateof-the-art taxonomy induction approaches across four languages. Importantly, we also show that our approach is robust to the presence of noise in the input vocabulary. To the best of our knowledge, this robustness has not been empirically proven in any previous approach.", "creator": "LaTeX with hyperref package"}}}