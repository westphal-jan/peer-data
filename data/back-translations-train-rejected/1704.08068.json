{"id": "1704.08068", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Apr-2017", "title": "Understanding the Feedforward Artificial Neural Network Model From the Perspective of Network Flow", "abstract": "In recent years, deep learning based on artificial neural network (ANN) has achieved great success in pattern recognition. However, there is no clear understanding of such neural computational models. In this paper, we try to unravel \"black-box\" structure of Ann model from network flow. Specifically, we consider the feed forward Ann as a network flow model, which consists of many directional class-pathways. Each class-pathway encodes one class. The class-pathway of a class is obtained by connecting the activated neural nodes in each layer from input to output, where activation value of neural node (node-value) is defined by the weights of each layer in a trained ANN-classifier. From the perspective of the class-pathway, training an ANN-classifier can be regarded as the formulation process of class-pathways of different classes. By analyzing the the distances of each two class-pathways in a trained ANN-classifiers, we try to answer the questions, why the classifier performs so? At last, from the neural encodes view, we define the importance of each neural node through the class-pathways, which is helpful to optimize the structure of a classifier. Experiments for two types of ANN model including multi-layer MLP and CNN verify that the network flow based on class-pathway is a reasonable explanation for ANN models.", "histories": [["v1", "Wed, 26 Apr 2017 11:45:05 GMT  (819kb)", "http://arxiv.org/abs/1704.08068v1", "arXiv admin note: text overlap witharXiv:1702.04595by other authors"]], "COMMENTS": "arXiv admin note: text overlap witharXiv:1702.04595by other authors", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["dawei dai", "weimin tan", "hong zhan"], "accepted": false, "id": "1704.08068"}, "pdf": {"name": "1704.08068.pdf", "metadata": {"source": "CRF", "title": "Understanding the Feedforward Artificial Neural Network Model From the Perspective of Network Flow", "authors": ["Dawei Dai", "Weimin Tan", "Hong Zhan"], "emails": ["{dw_dai@163.com}"], "sections": [{"heading": null, "text": "However, there is no clear understanding of such models of neuralism, in which one can stand up to one another."}, {"heading": "8.9698 8.3604 8.4424 8.1579 8.3393 8.5392 8.9135 8.8437 8.1188 7.8282", "text": "The number of examples, which can be considered as a kind of neural code, can be located in other classrooms. So it is not the way in which the individual classes are distinguished, but the way in which the individual classes are distinguished. (It is the way in which the individual classes are distinguished.) It is the way in which the individual classes are distinguished. (It is the way in which the individual classes are distinguished.) It is the way in which the individual classes are distinguished. (It is the way in which we are distinguished the individual classes. (It is the way in which the individual classes are distinguished.) It is the way in which the individual classes are distinguished. (It is the way in which we are distinguished the individual classes.) It is the way in which the manner, the way, the way in which the classes are distinguished.) It is the way in which the classes are distinguished. It is the way in which the classes are distinguished. (It is the way in which we are distinguished the way, the way in which the manner, and in which the manner in which the manner, and in which the manner in which the classes are distinguished.)"}, {"heading": "Refs", "text": "[1] Zeiler, Matthew D., and Rob Fergus E. Hinz \". Visualizing and understanding convolutionalnetworks.\" European conference on computer vision. \"[2] S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "In recent years, deep learning based on artificial neural network (ANN) has achieved great success in pattern recognition. However, there is no clear understanding of such neural computational models [1], for instance, for a trained ANN-classifier, we have no idea of why some classes are easy to be predicted correctly, but some are difficult to be predicted correctly. In this paper, we try to unravel ''black-box\" structure of classifiers and explain the mechanism of classification decisions made by classifiers from network flow. Specifically, we consider the feed forward artificial neural network as a network flow model, which consists of many directional class-pathways. Each class-pathway encodes one class. The class-pathway of a class is obtained by connecting the activated neural nodes in each layer from input to output, where activation value of neural node (node-value) is defined by the weights of each layer in a trained ANN-classifier. From the perspective of the class-pathway, training an ANN-classifier can be regarded as the formulation process of class-pathways of different classes. By analyzing the the distances of each two class-pathways in a trained ANN-classifiers, we try to answer the questions, why the classifier performs so? The smaller the distance of the class-pathways between two classes is, the higher the probability of the predicted error each other for these two classes will be. Furthermore, we can use the analysis as a new way to measure the performance of classifier and compare them despite their high prediction accuracy reporting on the small test sets. At last, from the neural encodes view, we define the importance of each neural node through the class-pathways, which is helpful to optimize the structure of a classifier. Experiments for two types of ANN model including multi-layer perceptron (MLP) and convolutional neural network (CNN) verify that the network flow based on class-pathway is a reasonable explanation for ANN models.", "creator": "Microsoft\u00ae Office Word 2007"}}}