{"id": "1704.08350", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Apr-2017", "title": "The MacGyver Test - A Framework for Evaluating Machine Resourcefulness and Creative Problem Solving", "abstract": "Current measures of machine intelligence are either difficult to evaluate or lack the ability to test a robot's problem-solving capacity in open worlds. We propose a novel evaluation framework based on the formal notion of MacGyver Test which provides a practical way for assessing the resilience and resourcefulness of artificial agents.", "histories": [["v1", "Wed, 26 Apr 2017 21:05:27 GMT  (25kb)", "http://arxiv.org/abs/1704.08350v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["vasanth sarathy", "matthias scheutz"], "accepted": false, "id": "1704.08350"}, "pdf": {"name": "1704.08350.pdf", "metadata": {"source": "CRF", "title": "The MacGyver Test - A Framework for Evaluating Machine Resourcefulness and Creative Problem Solving", "authors": ["Vasanth Sarathy", "Matthias Scheutz"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 4.08 350v 1 [cs.A I] 2 6A pr2 01"}, {"heading": "1 Introduction", "text": "Consider a situation where your only suit is covered in lint and you don't have a lint remover. Being resourceful, you argue that a roll of duct tape could be a good substitute. Then, you solve the problem of lint removal by peeling off the entire lint tape and attaching it back to the roll to expose the sticky side around the roll. By rolling it over your suit, you can now do all the lint removal. This kind of everyday creativity and resourcefulness is a hallmark of human intelligence and was best exemplified in the 1980s TV series MacGyver, in which a clever secret agent was seen using ordinary objects like paper clips and rubber bands in an inventive way to escape difficult life and death. 1But current suggestions for machine intelligence testing don't measure skills such as resourcefulness or creativity, although this is exactly what is required for artificial means such as home search and rescue, or even space agents."}, {"heading": "2 Background: Turing Test and its Progeny", "text": "He suggested that if a questioner is unable to see this as a test, rather a prediction of sorts [Cooper and Van Leeuwen, 2013]. However, since Turing, other candidates have developed tests for machine intelligence that have variations of the so-called Turing tests, to formulate a common criticism that it is easy to deceive the questioner."}, {"heading": "3 The MacGyver Evaluation Framework", "text": "The proposed evaluation framework, based on the idea of MacGyver-like creativity, is designed to answer the question of whether embodied machines can generate, execute, and learn strategies for identifying and solving seemingly intractable problems from the real world. The idea is to present an agent with a problem that is intractable with the agent's initial knowledge, and to observe the agent's problem-solving processes to assess the likelihood that the agent is creative: if the agent can think outside his current context, takes some exploratory action, and incorporates relevant environmental cues and acquired knowledge to make the problem manageable (or at least predictable), then the agent has the general ability to solve open-world problems more effectively."}, {"heading": "3.1 Preliminaries - Classical Planning", "text": "We define L as a first-order language with predicates p (t1,.., tn) and their negations p (t1,.., tn), where ti represents terms that can be variables or constants. A predicate is established if and only if all its terms are constants. We will use classical planning terms of a planning area in L, which can be represented as \u03a3 = (S, A, \u03b3), where S represents the totality of states, A the totality of actions and \u03b3 are the transition functions. A classical planning problem is a triple P = (\u03a3, s0, g), where s0 is the initial state and g the target state. A plan \u03c0 is an arbitrary sequence of actions and a plan \u03c0 is a solution to the planning problem if g (s0, \u03c0) are the transition functions. We also point out that the proposed MT is a subset of urea T3, but instead of requiring humans to do everything. \""}, {"heading": "3.2 A MacGyver Problem", "text": "To formalize a MacGyver problem (MGP), we define a universe and then a world within that universe."}, {"heading": "3.3 Solving a MacGyver Problem", "text": "From theories 1 and 2, we know that while it is possible for an agent to know whether a particular problem is an MGP, solving an MGP is like solving a planning problem with the additional requirement of recognizing a previously unknown condition, transitional function, or action. Specifically, solving an MGP means taking some action in the environment, requiring observation, extension, and contraction of the agent's subdomain, and exploration of different contexts. Definition 6 (Agent Domain Modification) involves a domain modification that involves either domain extension or domain contraction3. An agent's domain extension is a subdomain located in the agent's world but not in the agent's subdomain."}, {"heading": "4 Operationalizing a MacGyver Problem", "text": "We will look at two examples that will help to operationalize the formalism presented so far: the first is a modification of the popular planning problem of Blocks World; the second is a more practical task to tighten the screws, but with the caveat that certain common tools are not available and the problem-solver needs to improvise; and we will discuss specifically various skills that an agent needs to possess in order to meet the challenges arising from the examples."}, {"heading": "4.1 Toy Example: Block-and-Towel World", "text": "Consider an agent with the task of moving a block from one location to another that the agent will not be able to discover an object without first discovering any new domain information (\u00ac 1). Let the agent locationOf: o \u2192 l, which represents the location of the object o, consist of a series of locations l = {L1, L2, L3}, two objects o = {T, B} a towel and a block and a function locationOf: o \u2192 l, which represents the location of the object o. Suppose the agent is aware of the following predicates and their denials: an object o = {T, B} a towel and a block nearby (l): the agent is near the position l (o): the agent touches the object o \u2022 holding (o): the agent holds the object oWe define a series of actions in the agent domain as follows: \u2022 Achieve (o, l): Move the robot arm in the proximity of the object preo {conl), {cono: (o)."}, {"heading": "4.2 Practical Example: Makeshift Screwdriver", "text": "In fact, one is able to establish oneself in a country where most people are able to integrate and integrate, \"he told the Deutsche Presse-Agentur."}, {"heading": "4.3 Optimal Solution and M-Number", "text": "In general, we can assume that a solvable MGP has the best solution, which includes an agent who takes the most effective action, makes the necessary observations as needed, and uncovers a solution with the most elegant strategy. We formalize these terms by first defining optimal solutions, and then the M number, which is the measure of the complexity of a revealing strategy in the optimal solution. Let PM = (Wt, s0, g) be a MGP for the agent. Let it be an optimal solution plan for PM. A set of optimal domain modifications is a set of domain modifications that are suitable to use domain modifications that are required to include measures in the optimal solution plan. An optimal solution strategy is a solution strategy."}, {"heading": "4.4 Measuring Progress and Agent Success", "text": "When we challenge each other with creative problems, we often know if the problem-solver is getting closer (\"warmer\") than the solution. We formalize this idea with the help of Solomonoff induction. To do this, we will first designate a \"judge\" who, based on a strategy currently being executed by the agent, estimates the probability that the agent has probably developed an insightful strategy in a limited number of steps. Consider an agent executing a strategy to try to solve an MGP problem and a judge evaluating the agent's performance. First, the judge must understand what the agent is trying to do. So, the judge must first hypothesize an agent model that is capable of generating a model."}, {"heading": "5 Conclusion and Future Work", "text": "During the Apollo 13 space mission, astronauts had to overcome several challenges along with ground control to safely return the team to Earth [Lovell and Kluger, 2006]. One of these challenges was controlling carbon dioxide levels aboard the spacecraft: \"For two days, they had been working to point the Odysseys canisters at the Aquarius life support system. Now, we've used materials available on board the spacecraft - a sock, a plastic bag, the lid of an aircraft, lots of duct tape and so on - the crew has put together a strange juxtaping and put them into position. Carbon dioxide levels immediately began to fall into the safe range.\" [Cass, 2005; Team, 1970] We proposed the MacGyver test as a practical alternative to the Turing Test and as a formal alternative to the robotic and mechanical learning challenges."}], "references": [{"title": "Kybernetes", "author": ["Margaret A. Boden. The Turing test", "artistic creativity"], "venue": "39(3):409\u2013413,", "citeRegEx": "Boden. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "On Creative Self-Driving Cars: Hire the Computational Logicians", "author": ["Selmer Bringsjord", "Atriya Sen"], "venue": "Fast. page Forthcoming,", "citeRegEx": "Bringsjord and Sen. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "the Turing test", "author": ["Selmer Bringsjord", "Paul Bello", "David Ferrucci. Creativity"], "venue": "and the (better) Lovelace Test. Minds and Machines, 11(1):3\u201327,", "citeRegEx": "Bringsjord et al.. 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "Apollo 13", "author": ["Stephen Cass"], "venue": "we have a solution. IEEE Spectrum On-line, 04, 1,", "citeRegEx": "Cass. 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "If not turing\u2019s test", "author": ["Paul R Cohen"], "venue": "then what? AI Magazine, 26(4):61,", "citeRegEx": "Cohen. 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "Journal of the ACM", "author": ["Edward A. Feigenbaum. Some challenges", "grand challenges for computational intelligence"], "venue": "50(1):32\u201340,", "citeRegEx": "Feigenbaum. 2003", "shortCiteRegEx": null, "year": 2003}, {"title": "and Paolo Traverso", "author": ["Malik Ghallab", "Dana Nau"], "venue": "Automated Planning: Theory and Practice.", "citeRegEx": "Ghallab et al.. 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "other minds: A machine incarnation of an old philosophical problem", "author": ["Stevan Harnad. Other bodies"], "venue": "Minds and Machines, 1(1):43\u201354,", "citeRegEx": "Harnad. 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "pages 275\u2013300", "author": ["G\u00fcnther Knoblich. Psychological research on insight problem solving. In Recasting reality"], "venue": "Springer,", "citeRegEx": "Knoblich. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "The Winograd Schema Challenge", "author": ["Hector Levesque", "Ernest Davis", "Leora Morgenstern"], "venue": "Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning,", "citeRegEx": "Levesque et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Second edition)", "author": ["M Li", "Paul Vit\u00e1nyi. An introduction to Kolmogorov complexity", "its applications"], "venue": "Computers & Mathematics with Applications, 34:137,", "citeRegEx": "Li and Vit\u00e1nyi. 1997", "shortCiteRegEx": null, "year": 1997}, {"title": "Apollo 13", "author": ["Jim Lovell", "Jeffrey Kluger"], "venue": "Houghton Mifflin Harcourt,", "citeRegEx": "Lovell and Kluger. 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "Riedl", "author": ["O Mark"], "venue": "The Lovelace 2.0 Test of Artificial Creativity and Intelligence. arXiv preprint arXiv:1410.6142v3, page 2,", "citeRegEx": "Riedl. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Minds and Machines", "author": ["Paul Schweizer. The externalist foundations of a truly total turing test"], "venue": "22(3):191\u2013212,", "citeRegEx": "Schweizer. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "A preliminary report on a general theory of inductive inference", "author": ["RJ Solomonoff"], "venue": "Zator Technical Bulletin, (138)", "citeRegEx": "Solomonoff. 1960", "shortCiteRegEx": null, "year": 1960}, {"title": "MIND", "author": ["Alan M Turing. Computing Machine", "Intelligence"], "venue": "LIX(236):433\u2013460,", "citeRegEx": "Turing. 1950", "shortCiteRegEx": null, "year": 1950}], "referenceMentions": [{"referenceID": 15, "context": ", natural language) that we (humans)would say required thought in people [Turing, 1950].", "startOffset": 73, "endOffset": 87}, {"referenceID": 9, "context": "The question asks to determine the referent of this ambiguous pronoun or possessive adjective, by selecting one of two choices [Levesque et al., 2012].", "startOffset": 127, "endOffset": 150}, {"referenceID": 5, "context": "Feigenbaum proposed a variation of the Turing Test in which a machine can be tested against a team of subject matter specialists through natural language conversation [Feigenbaum, 2003].", "startOffset": 167, "endOffset": 185}, {"referenceID": 0, "context": "Other tests attempted to study a machine\u2019s ability to produce creative artifacts and solve novel problems [Boden, 2010; Bringsjord et al., 2001; Bringsjord and Sen, 2016; Riedl, 2014].", "startOffset": 106, "endOffset": 183}, {"referenceID": 2, "context": "Other tests attempted to study a machine\u2019s ability to produce creative artifacts and solve novel problems [Boden, 2010; Bringsjord et al., 2001; Bringsjord and Sen, 2016; Riedl, 2014].", "startOffset": 106, "endOffset": 183}, {"referenceID": 1, "context": "Other tests attempted to study a machine\u2019s ability to produce creative artifacts and solve novel problems [Boden, 2010; Bringsjord et al., 2001; Bringsjord and Sen, 2016; Riedl, 2014].", "startOffset": 106, "endOffset": 183}, {"referenceID": 12, "context": "Other tests attempted to study a machine\u2019s ability to produce creative artifacts and solve novel problems [Boden, 2010; Bringsjord et al., 2001; Bringsjord and Sen, 2016; Riedl, 2014].", "startOffset": 106, "endOffset": 183}, {"referenceID": 7, "context": "Extending capabilities beyond linguistic and creative, Harnad\u2019s Total Turing Test (T3) suggested that the range of capabilities must be expanded to a full set of robotic capacities found in embodied systems [Harnad, 1991].", "startOffset": 207, "endOffset": 221}, {"referenceID": 13, "context": "Schweizer extended the T3 to incorporate species evolution and development over time and proposed the Truly Total Turing Test (T4) to test not only individual cognitive systems but whether as a species the candidate cognitive architecture in question is capable of long-term evolutionary achievement [Schweizer, 2012].", "startOffset": 300, "endOffset": 317}, {"referenceID": 4, "context": "Specific task-based goals were designed couched as toy problems that were representative of a real-world task [Cohen, 2005].", "startOffset": 110, "endOffset": 123}, {"referenceID": 6, "context": "Each of these problems are PLAN-EXISTENCE problems, which are in EXPSPACE for the unrestricted case [Ghallab et al., 2004].", "startOffset": 100, "endOffset": 122}, {"referenceID": 8, "context": "When humans solve problems, particularly creative insight problems, they tend to use various heuristics to simplify the search space and to identify invariants in the environment that may or may not be relevant [Knoblich, 2009].", "startOffset": 211, "endOffset": 227}, {"referenceID": 10, "context": "then use Kolmogorov complexity of the set of these insightful strategies, K(\u03a9\u0302) := minp\u2208B\u2217{|p| : U(p) computes \u03a9\u0302} [Li and Vit\u00e1nyi, 1997].", "startOffset": 115, "endOffset": 137}, {"referenceID": 14, "context": "Solomonoff devised a universal distribution over a set of computable hypotheses from the perspective of computability theory [Solomonoff, 1960].", "startOffset": 125, "endOffset": 143}, {"referenceID": 11, "context": "In the Apollo 13 space mission, astronauts together with ground control had to overcome several challenges to bring the team safely back to Earth [Lovell and Kluger, 2006].", "startOffset": 146, "endOffset": 171}, {"referenceID": 3, "context": "\u201d [Cass, 2005; Team, 1970].", "startOffset": 2, "endOffset": 26}], "year": 2017, "abstractText": "Current measures of machine intelligence are either difficult to evaluate or lack the ability to test a robot\u2019s problem-solving capacity in open worlds. We propose a novel evaluation framework based on the formal notion ofMacGyver Testwhich provides a practical way for assessing the resilience and resourcefulness of artificial agents.", "creator": "LaTeX with hyperref package"}}}