{"id": "1705.00045", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Apr-2017", "title": "Understanding and Detecting Supporting Arguments of Diverse Types", "abstract": "We investigate the problem of sentence-level supporting argument detection from relevant documents for user-specified claims. A dataset containing claims and associated citation articles is collected from online debate website idebate.org. We then manually label sentence-level supporting arguments from the documents along with their types as study, factual, opinion, or reasoning. We further characterize arguments of different types, and explore whether leveraging type information can facilitate the supporting arguments detection task. Experimental results show that LambdaMART (Burges, 2010) ranker that uses features informed by argument types yields better performance than the same ranker trained without type information.", "histories": [["v1", "Fri, 28 Apr 2017 19:29:54 GMT  (59kb,D)", "http://arxiv.org/abs/1705.00045v1", null], ["v2", "Tue, 2 May 2017 22:00:13 GMT  (56kb,D)", "http://arxiv.org/abs/1705.00045v2", "This paper is accepted as a short paper in ACL 2017"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["xinyu hua", "lu wang"], "accepted": false, "id": "1705.00045"}, "pdf": {"name": "1705.00045.pdf", "metadata": {"source": "CRF", "title": "Understanding and Detecting Supporting Arguments of Diverse Types", "authors": ["Xinyu Hua", "Lu Wang"], "emails": ["hua.x@husky.neu.edu", "luwang@ccs.neu.edu"], "sections": [{"heading": "1 Introduction", "text": "This year it is more than ever before."}, {"heading": "2 Related Work", "text": "Our work is consistent with reasoning mining, which has recently aroused much research interest. Existing work focuses on extracting arguments from news articles, legal documents, or online commentary without user-specific assertion (Moens et al., 2007; Palau and Moens, 2009; Mochales and Moens, 2011; Park and Cardie, 2014). The classification of arguments is also extensively studied (Biran and Rambow, 2011; Feng and Hirst, 2011; Rooney et al., 2012; Stab and Gurevych, 2014; Al Khatib et al., 2016), focusing on the distinction between different types of argument. To our knowledge, none of them examines the interaction between types of argument and their use to support a user-specific claim."}, {"heading": "3 Data and Annotation", "text": "We rely on data from idebate.org, where human editors construct paragraphs of arguments that either support or reject the claims of controversial topics. We also extract textual quotes from articles as a source of information used by editors during the argumentation. In total, we have collected 383 unique debates, of which 200 arguments were randomly selected for the study. After removing invalid arguments, our final dataset includes 450 claims and 621 quotes from articles with approximately 53,000 sentences. As shown in Figure 2, we first comment on the arguments of a quote article used by the editor as supporting arguments. Then, we comment on the nature of them as STUDY, FACTUAL, OPINIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONIONION"}, {"heading": "4 A Study On Argument Type Prediction", "text": "Here we characterize arguments of different types based on different characteristics under the task of predicting argument types. Supporting arguments identified from the previous section are used for experiments. We also use the learned classifier in this section to mark the sentences that do not support arguments used in the next section to support reasoning recognition. Four important types of characteristics are taken into account. Basic characteristics. We calculate frequencies of uniform and bigram words, number of four important types of part-of-speech tags (verb, noun, adjective and adverb), number of dependency relationships, starting with a low match for REASONING. 4http: / / www.alexa.com / topsites / category number of seven types of called entities (chinchor and robin, 1997). Sentiment attributes. We also calculate number of positive, negative and neutral words, the number of encyclopaedias, the encyclopaedia number of Wilson and Robinson, 1997)."}, {"heading": "5 Supporting Argument Detection", "text": "We will throw out the sentence level supporting reasoning problem as ranking tasks.6 Features5Categories used: Strong, Weak, Virtue, Vice, Ovrst (Overstated), Undrst (Understated), Academ (Academic), Doctrine (Doctrine), Econ (Economic), Relig (Religious), Causal, Ought, and Perception (Perception).6Many sentences in the citation article are relevant to the topic in different degrees. We focus on identifying the most relevant, and therefore treat it as ranking problem instead of rankings Section 4, which are also used here as \"Sentence Features\" with additional features that take into account the sentence position in the article. We will deal with other features that measure similarity between claims and sentences, and the compound features that represent a kind of argumentation.Similarities between claims. We will compile similarity between claim and candidate features."}, {"heading": "6 Conclusion", "text": "We presented a novel study on the task of detecting arguments at the sentence level from relevant documents for a user-specific claim. Based on our newly collected data set, we characterized arguments of different types with a rich set of features. We also demonstrated that the use of argument type information can further improve the performance of supporting argument detection."}, {"heading": "Acknowledgments", "text": "This work was partially supported by the National Science Foundation grant IIS-1566382 and a GPU gift from Nvidia. We thank Kechen Qin for his help in collecting data. We also appreciate the valuable suggestions on various aspects of this work from three anonymous reviewers."}], "references": [{"title": "A news editorial corpus for mining argumentation strategies", "author": ["References Khalid Al Khatib", "Henning Wachsmuth", "Johannes Kiesel", "Matthias Hagen", "Benno Stein."], "venue": "Proceedings of COLING 2016, the", "citeRegEx": "Khatib et al\\.,? 2016", "shortCiteRegEx": "Khatib et al\\.", "year": 2016}, {"title": "Identifying justifications in written dialogs by classifying text as argumentative", "author": ["Or Biran", "Owen Rambow."], "venue": "International Journal of Semantic Computing 5(04):363\u2013381.", "citeRegEx": "Biran and Rambow.,? 2011", "shortCiteRegEx": "Biran and Rambow.", "year": 2011}, {"title": "Concreteness ratings for 40 thousand generally known english word lemmas", "author": ["Marc Brysbaert", "Amy Beth Warriner", "Victor Kuperman."], "venue": "Behavior research methods 46(3):904\u2013911.", "citeRegEx": "Brysbaert et al\\.,? 2014", "shortCiteRegEx": "Brysbaert et al\\.", "year": 2014}, {"title": "From ranknet to lambdarank to lambdamart: An overview", "author": ["Christopher JC Burges."], "venue": "Learning 11(23-581):81.", "citeRegEx": "Burges.,? 2010", "shortCiteRegEx": "Burges.", "year": 2010}, {"title": "Yahoo! learning to rank challenge overview", "author": ["Olivier Chapelle", "Yi Chang."], "venue": "Yahoo! Learning to Rank Challenge. pages 1\u201324.", "citeRegEx": "Chapelle and Chang.,? 2011", "shortCiteRegEx": "Chapelle and Chang.", "year": 2011}, {"title": "Muc7 named entity task definition", "author": ["Nancy Chinchor", "Patricia Robinson."], "venue": "Proceedings of the 7th Conference on Message Understanding. volume 29.", "citeRegEx": "Chinchor and Robinson.,? 1997", "shortCiteRegEx": "Chinchor and Robinson.", "year": 1997}, {"title": "Classifying arguments by scheme", "author": ["Vanessa Wei Feng", "Graeme Hirst."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1. Association for Computa-", "citeRegEx": "Feng and Hirst.,? 2011", "shortCiteRegEx": "Feng and Hirst.", "year": 2011}, {"title": "Exploiting debate portals for semi-supervised argumentation mining in user-generated web discourse", "author": ["Ivan Habernal", "Iryna Gurevych."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Associ-", "citeRegEx": "Habernal and Gurevych.,? 2015", "shortCiteRegEx": "Habernal and Gurevych.", "year": 2015}, {"title": "Rouge: A package for automatic evaluation of summaries", "author": ["Chin-Yew Lin."], "venue": "Text summarization branches out: Proceedings of the ACL-04 workshop. Barcelona, Spain, volume 8.", "citeRegEx": "Lin.,? 2004", "shortCiteRegEx": "Lin.", "year": 2004}, {"title": "Argumentation mining", "author": ["Raquel Mochales", "Marie-Francine Moens."], "venue": "Artificial Intelligence and Law 19(1):1\u201322.", "citeRegEx": "Mochales and Moens.,? 2011", "shortCiteRegEx": "Mochales and Moens.", "year": 2011}, {"title": "Automatic detection of arguments in legal texts", "author": ["Marie-Francine Moens", "Erik Boiy", "Raquel Mochales Palau", "Chris Reed."], "venue": "Proceedings of the 11th international conference on Artificial intelligence and law. ACM, pages 225\u2013230.", "citeRegEx": "Moens et al\\.,? 2007", "shortCiteRegEx": "Moens et al\\.", "year": 2007}, {"title": "Context-aware argumentative relation mining", "author": ["Huy Nguyen", "Diane Litman."], "venue": "Proceedings of", "citeRegEx": "Nguyen and Litman.,? 2016", "shortCiteRegEx": "Nguyen and Litman.", "year": 2016}, {"title": "Argumentation mining: the detection, classification and structure of arguments in text", "author": ["Raquel Mochales Palau", "Marie-Francine Moens."], "venue": "Proceedings of the 12th international conference on artificial intelligence and law. ACM, pages 98\u2013107.", "citeRegEx": "Palau and Moens.,? 2009", "shortCiteRegEx": "Palau and Moens.", "year": 2009}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu."], "venue": "Proceedings of the 40th annual meeting on association for computational linguistics. Association for Computational", "citeRegEx": "Papineni et al\\.,? 2002", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Identifying appropriate support for propositions in online user comments", "author": ["Joonsuk Park", "Claire Cardie."], "venue": "Proceedings of the First Workshop on Argumentation Mining. pages 29\u201338.", "citeRegEx": "Park and Cardie.,? 2014", "shortCiteRegEx": "Park and Cardie.", "year": 2014}, {"title": "The penn discourse treebank 2.0 annotation", "author": ["Rashmi Prasad", "Eleni Miltsakaki", "Nikhil Dinesh", "Alan Lee", "Aravind Joshi", "Livio Robaldo", "Bonnie L Webber"], "venue": null, "citeRegEx": "Prasad et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Prasad et al\\.", "year": 2007}, {"title": "Argumentation and critical decision making", "author": ["Richard D Rieke", "Malcolm Osgood Sillars", "Tarla Rai Peterson."], "venue": "New York: Longman.", "citeRegEx": "Rieke et al\\.,? 1997", "shortCiteRegEx": "Rieke et al\\.", "year": 1997}, {"title": "Show me your evidence-an automatic method for context dependent evidence detection", "author": ["Ruty Rinott", "Lena Dankin", "Carlos Alzate Perez", "Mitesh M Khapra", "Ehud Aharoni", "Noam Slonim."], "venue": "EMNLP. pages 440\u2013450.", "citeRegEx": "Rinott et al\\.,? 2015", "shortCiteRegEx": "Rinott et al\\.", "year": 2015}, {"title": "Applying kernel methods to argumentation mining", "author": ["Niall Rooney", "Hui Wang", "Fiona Browne."], "venue": "Twenty-Fifth International FLAIRS Conference.", "citeRegEx": "Rooney et al\\.,? 2012", "shortCiteRegEx": "Rooney et al\\.", "year": 2012}, {"title": "Identifying argumentative discourse structures in persuasive essays", "author": ["Christian Stab", "Iryna Gurevych."], "venue": "EMNLP. pages 46\u201356.", "citeRegEx": "Stab and Gurevych.,? 2014", "shortCiteRegEx": "Stab and Gurevych.", "year": 2014}, {"title": "The general inquirer: A computer approach to content analysis", "author": ["Philip J Stone", "Dexter C Dunphy", "Marshall S Smith."], "venue": ".", "citeRegEx": "Stone et al\\.,? 1966", "shortCiteRegEx": "Stone et al\\.", "year": 1966}, {"title": "Norms of valence, arousal, and dominance for 13,915 english lemmas", "author": ["Amy Beth Warriner", "Victor Kuperman", "Marc Brysbaert."], "venue": "Behavior research methods 45(4):1191\u20131207.", "citeRegEx": "Warriner et al\\.,? 2013", "shortCiteRegEx": "Warriner et al\\.", "year": 2013}, {"title": "Recognizing contextual polarity in phraselevel sentiment analysis", "author": ["Theresa Wilson", "Janyce Wiebe", "Paul Hoffmann."], "venue": "Proceedings of the conference on human language technology and empirical methods in natural language processing. Associ-", "citeRegEx": "Wilson et al\\.,? 2005", "shortCiteRegEx": "Wilson et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 3, "context": "Experimental results show that LambdaMART (Burges, 2010) ranker that uses features informed by argument types yields better performance than the same ranker trained without type information.", "startOffset": 42, "endOffset": 56}, {"referenceID": 16, "context": "Constructing arguments of high quality would require the inclusion of diverse information, such as factual evidence and solid reasoning (Rieke et al., 1997; Park and Cardie, 2014).", "startOffset": 136, "endOffset": 179}, {"referenceID": 14, "context": "Constructing arguments of high quality would require the inclusion of diverse information, such as factual evidence and solid reasoning (Rieke et al., 1997; Park and Cardie, 2014).", "startOffset": 136, "endOffset": 179}, {"referenceID": 6, "context": "2011; Stab and Gurevych, 2014; Feng and Hirst, 2011; Habernal and Gurevych, 2015; Nguyen and Litman, 2016). Limited work has been done for retrieving supporting arguments from external resources. Initial effort by Rinott et al. (2015) investigates the detection of relevant factual evidence from Wikipedia articles.", "startOffset": 31, "endOffset": 235}, {"referenceID": 3, "context": "Experimental results based on LambdaMART (Burges, 2010) show that utilizing features composite with argument types achieves a Mean Reciprocal Rank (MRR) score of 57.", "startOffset": 41, "endOffset": 55}, {"referenceID": 1, "context": "Argument scheme classification is also widely studied (Biran and Rambow, 2011; Feng and Hirst, 2011; Rooney et al., 2012; Stab and Gurevych, 2014; Al Khatib et al., 2016), which emphasizes on distinguishing different types of arguments.", "startOffset": 54, "endOffset": 170}, {"referenceID": 6, "context": "Argument scheme classification is also widely studied (Biran and Rambow, 2011; Feng and Hirst, 2011; Rooney et al., 2012; Stab and Gurevych, 2014; Al Khatib et al., 2016), which emphasizes on distinguishing different types of arguments.", "startOffset": 54, "endOffset": 170}, {"referenceID": 18, "context": "Argument scheme classification is also widely studied (Biran and Rambow, 2011; Feng and Hirst, 2011; Rooney et al., 2012; Stab and Gurevych, 2014; Al Khatib et al., 2016), which emphasizes on distinguishing different types of arguments.", "startOffset": 54, "endOffset": 170}, {"referenceID": 19, "context": "Argument scheme classification is also widely studied (Biran and Rambow, 2011; Feng and Hirst, 2011; Rooney et al., 2012; Stab and Gurevych, 2014; Al Khatib et al., 2016), which emphasizes on distinguishing different types of arguments.", "startOffset": 54, "endOffset": 170}, {"referenceID": 5, "context": "number of seven types of named entities (Chinchor and Robinson, 1997).", "startOffset": 40, "endOffset": 69}, {"referenceID": 22, "context": "We also compute number of positive, negative and neutral words in MPQA lexicon (Wilson et al., 2005), and number of words from a subset of semantic categories from General Inquirer (Stone et al.", "startOffset": 79, "endOffset": 100}, {"referenceID": 20, "context": ", 2005), and number of words from a subset of semantic categories from General Inquirer (Stone et al., 1966).", "startOffset": 88, "endOffset": 108}, {"referenceID": 15, "context": "We use the number of discourse connectives from the top two levels of Penn Discourse Tree Bank (Prasad et al., 2007).", "startOffset": 95, "endOffset": 116}, {"referenceID": 2, "context": "emotion), and dominance (or degree of control) based on the lexicons collected by Brysbaert et al. (2014) and Warriner et al.", "startOffset": 82, "endOffset": 106}, {"referenceID": 2, "context": "emotion), and dominance (or degree of control) based on the lexicons collected by Brysbaert et al. (2014) and Warriner et al. (2013).", "startOffset": 82, "endOffset": 133}, {"referenceID": 8, "context": "sider ROUGE (Lin, 2004), a recall oriented metric for summarization evaluation.", "startOffset": 12, "endOffset": 23}, {"referenceID": 13, "context": "In similar manner we use BLEU (Papineni et al., 2002), a precision oriented metric.", "startOffset": 30, "endOffset": 53}, {"referenceID": 3, "context": "We choose LambdaMART (Burges, 2010) for", "startOffset": 21, "endOffset": 35}, {"referenceID": 4, "context": "experiments, which is shown to be successful for many text ranking problems (Chapelle and Chang, 2011).", "startOffset": 76, "endOffset": 102}], "year": 2017, "abstractText": "We investigate the problem of sentence-level supporting argument detection from relevant documents for user-specified claims. A dataset containing claims and associated citation articles is collected from online debate website idebate.org. We then manually label sentence-level supporting arguments from the documents along with their types as STUDY, FACTUAL, OPINION, or REASONING. We further characterize arguments of different types, and explore whether leveraging type information can facilitate the supporting arguments detection task. Experimental results show that LambdaMART (Burges, 2010) ranker that uses features informed by argument types yields better performance than the same ranker trained without type information.", "creator": "LaTeX with hyperref package"}}}