{"id": "1705.00132", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Apr-2017", "title": "Online Learning with Expert Automata", "abstract": "We consider a general framework of online learning with expert advice where the regret is defined with respect to a competitor class defined by a weighted automaton over sequences of experts. Our framework covers several problems previously studied, in particular that of competing against k-shifting experts. We give a series of algorithms for this problem, including an automata-based algorithm extending weighted- majority and more efficient algorithms based on the notion of failure transitions. We further present efficient algorithms based on a compact approximation of the competitor automaton, in particular efficient n-gram models obtained by minimizing the Renyi divergence, and present an extensive study of the approximation properties of such models. We also extend our algorithms and results to the framework of sleeping experts. Finally, we describe the extension of our approximation methods to online convex optimization and a general mirror descent setting.", "histories": [["v1", "Sat, 29 Apr 2017 05:31:20 GMT  (238kb,D)", "http://arxiv.org/abs/1705.00132v1", null], ["v2", "Sat, 6 May 2017 18:05:25 GMT  (239kb,D)", "http://arxiv.org/abs/1705.00132v2", null], ["v3", "Sat, 13 May 2017 20:08:02 GMT  (239kb,D)", "http://arxiv.org/abs/1705.00132v3", null], ["v4", "Sun, 22 Oct 2017 05:24:43 GMT  (491kb,D)", "http://arxiv.org/abs/1705.00132v4", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mehryar mohri", "scott yang"], "accepted": false, "id": "1705.00132"}, "pdf": {"name": "1705.00132.pdf", "metadata": {"source": "CRF", "title": "Online Learning against Expert Automata", "authors": ["Mehryar Mohri", "Scott Yang"], "emails": [], "sections": [{"heading": null, "text": "We present a number of algorithms for this problem, including an automated algorithm that extends weighted majorities and more efficient algorithms based on the idea of error transitions, efficient algorithms based on a compact approximation of the competing automaton, in particular efficient n-gram models obtained by minimizing the Re'nyi divergence, and a comprehensive study of the approximation properties of such models. We also extend our algorithms and results beyond the scope of sleeping experts. Finally, we describe the extension of our approximation methods to online convex optimization and a general mirror descend setting."}, {"heading": "1 Introduction", "text": "This is an example of how people in the USA and other countries have behaved. (...) In this context, the algorithm has attracted a great deal of attention. (...) In each round, the loss of each expert becomes apparent. (...) The algorithm results in the expected loss of experts and experts. (...) The aim of the learner is to minimize his expected regret. (...) The loss of each expert becomes apparent. (...) The loss of each expert becomes apparent. (...) The algorithm results in the expected loss of experts and the dissemination of experts. (...) The aim of the learner is to minimize his expected regret, which is defined as the cumulative loss of the algorithm. (...) The loss of the algorithm results in the expected loss of experts. (...) The loss of experts and the dissemination of experts is minimized. (...) The regret is defined as the cumulative loss of the algorithm. (...)"}, {"heading": "2 Preliminaries", "text": "A weighted finite automaton (FFA) is also a finite automaton whose transitions, beginning and end states Q = Q = Q = FA also have some weights. For our purpose, the weights belong to the probabilities semiring (R + 1), +, 0, 1): 1 We assume that all automata are deministic, so that for each state q and each label a, there is for most a transition marked with q. For a FFA A, we denote its finite states, for IA QA its initial states, for FA QA its finite states, and for EA its finite transitions, which are elements of QA."}, {"heading": "3 Learning problem", "text": "We consider the prediction's setting to be too weak in many areas where the data is potentially uncontrolled and inaccurate. (D) We consider the prediction's prediction as a sequencial. (D) We consider the prediction's prediction as a sequencial. (D) We consider the prediction's prediction as a sequencial. (D) We consider it as a sequencial. (D) We can see the difference between the cumulative expected losses of learners and the best losses of learners. (D) \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. (D \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. (s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s."}, {"heading": "4 Na\u0131\u0308ve algorithm", "text": "A well-known algorithm for minimizing static regret in the prediction with expert recommendations is the weighted majority algorithm (Littlestone and Warmuth, 1994). The algorithm maintains a distribution over experts proportional to the exponential weight of the cumulative loss of experts. Specifically, we assume that we can define the paths accepted by CT by {S} Kj = 1. In each round, each path selects an expert and designs an algorithm that minimizes the unweighted and weighted regret. Specifically, we assume that we can define a weight distribution over the experts by using the formula."}, {"heading": "5 Automata operations", "text": "While PBWM reaches a sublinear limit for both weighted and unweighted regrets, it can be mathematically prohibitive, because each iteration requires a sum of the number of paths in the competitive set, which can be exponentially in the number of total rounds T. For example, the total number of k-moving experts is O ((((T \u2212 1 k) N (N \u2212 1) k)).To design mathematically efficient algorithms, we use the characteristics of the competitor-class automaton C. Note that each finite group of competitor paths can be represented by an automaton, but different automats accepting the same set can result in vastly different calculation costs. Our algorithms use several common operations for weighted automats: composition, shortest distance, and connection. Specifically, we design an incremental version of the shortest distance algorithm, which we call IncrementalShortecrorstance (SD)."}, {"heading": "5.1 Composition/intersection", "text": "Composition (or intersection) is an operation that combines two weighted machines into a new weighted q q | | result. The resulting machine accepts the set of strings accepted by both input machines. The weight assigned to each string by the resulting composition is the product of the weights assigned by the input machines: A1 \u0445 A2 (x) = A1 (x) A2 (x). A standardized and efficient method for the composition of two weighted machines is to pair matching transitions [Mohri, 2009]. Conditions of A1 \u0445 A2 are identified with pairs of states of A1 and A2: Q Q1 \u00b7 Q2 as well as the total states of output and end states. Transitions are achieved by matching pairs of transitions from each weighted machine and multiplying their weights following the result: (q1 a / w1 \u2192 Q1, q2 \u2032 \u2212 Q2)."}, {"heading": "5.2 Shortest-distance", "text": "The second operation we need is a \"short-distance\" calculation from one hand over the semicircle (R +, +, +, +, \u00d7, 0, 1), that is, we want to calculate it for any state q, \u03b1 [q] defined by: \u03b1 [q] = \u2211 \u03c0-P (IA, q) wA [\u03c0], where P (IA, q) is the set of paths from the initial states IA to q. For any acyclic automaton A, \u03b1 can be calculated in linear time using a general relaxation-based short-distance algorithm with a topological queue discipline [Mohri, 2009]. \u03b1 can also be calculated using other algorithms such as the Viterbi algorithm. In our context, of course, this short-distance algorithm can be modified to run gradually and be extended to the case of automata with error transitions (section 9)."}, {"heading": "5.3 Connection", "text": "It is possible that some of the states created by composition are inaccessible or inaccessible. A state q-Q is inaccessible if there is no path from I to q. A state q-Q is inaccessible if there is no path from q to F. Such states are called useless because they are not on acceptable paths. Connection (or trimming) is a linear age algorithm that removes these inaccessible states [Mohri, 2009]."}, {"heading": "6 Automata-based algorithm", "text": "We have the sum of the weight shifts that are performed by e. (...) We then have the weight shifts in C-ST, whose destination states form (...) using this lot. We calculate the flow of each edge e, which is the sum of the weight shifts in C-ST, whose destination we use. (...) We then calculate the flow of each edge e, which is the sum of the weight shifts in E-ST, which is the sum of the weight shifts in C-ST, whose destination we have. (...) We then calculate the flow of each edge e, which is the sum of the weight shifts that go through. (...) We have the sum of the weight shifts in C-ST, whose destinations we have. (...) We then calculate the flow of each edge e, which is the sum of the weight shifts that go through. (...) We have the sum of the weight shifts in C-ST, whose destinations we have."}, {"heading": "7 Approximation algorithms", "text": "The algorithm described in Section 6 was based on the exploitation of the characteristics of the competitor-class machine C. AWM was exactly in that it performed the same calculations as the naive algorithm PBWM. If the resulting machine is still large after composition, then the computing costs can still be prohibitive. In this section, we take a different approach and no longer limit ourselves to algorithms that perform exactly the same update as PBWM. Instead, we design algorithms to efficiently approximate the competitive set CT. An automaton that approaches CT compactly and closely can lead to an algorithm that is efficient and achieves a favorable regret."}, {"heading": "7.1 The effect of automata approximation on regret", "text": "We first analyze the approximate costs of such an algorithm as follows: Reg0T (A, C)."}, {"heading": "7.5 Model selection", "text": "The previous section introduced a method to learn a single n-gram model based on the competitor EG-CT. In practice, one is looking for an n-gram model that balances the trade-off between approximation error and calculation costs. Suppose we have a maximum pro-iteration calculation budget B. Therefore, we are looking for the most mathematically efficient n-gram model within our budget that does not contribute to an increase in regret. Suppose it is an n-gram model returned by PROD-EG. In episode 1, we can write F (pn) \u2212 GapTopt, n \u2264 F (p \u0445 n), where p \u0445 n is the optimal n-gram model that minimizes the target and GapTopt, n is the expression that quantifies the gap between PROD-EG and the optimal solution after executing the algorithm for pot iterations."}, {"heading": "8 Time-independent approximation of competitor automata", "text": "In this section, we will show how to approximate the distribution of individual T-shirts using a single approximation, the key being to approach the original automation C directly. Specifically, C is assumed to be a stochastic automation (so that its outgoing transition to 1 in each state), let pC define the distribution defined by C, and let P be a family of distributions that we use to approximate pC."}, {"heading": "9 Failure transition algorithm", "text": "In this section, we will introduce a technique to improve the computational cost of AWM by reducing the size of automation. To do this, we will use the term failure of transition (or transition). Transitions play a key role in the design of many efficient string matching and automatic algorithms, including egrep under UNIX. [Aho and Corasick, 1975, Knuth et al., 1977, Crochemore, 1986, Mohri, 1997].Let us be an icon that is unable to install automation."}, {"heading": "10 Composition of multiple \u03d5-automata", "text": "In fact, most of them are able to determine for themselves how they have behaved."}, {"heading": "11 Extension to sleeping experts", "text": "In many real-world applications, it may be natural for some experts to refrain from making predictions about some of the survey results. (For example, in a bag-of-words model for document classification, the presence of a feature or a subset of features in a document can be interpreted as an expert who is awake. (This extension of the standard forecast with expert advice is also known as a sleeping expert framework. (Friend et al.) Experts are told that they sleep when they are inactive and awake when they can be selected. (This framework differs from the 11: GENERAL-COMPOSITION algorithms) (Algorithm)."}, {"heading": "12 Extension to online convex optimization", "text": "The goal of the learner is to generalize regret against the families of the sequences. Specifically, this means that CT should be a closed subset, let pCT be a distribution over the CT and let uCT be the uniform distribution over the CT. Uniform distribution is well defined, since K is a compact set implying that KT is compact."}, {"heading": "12.1 OCO derivation of FIXED-SHARE", "text": "Suppose that we are back in the prediction with expert advice, so we can assume that this problem can always be solved. (This) = < lt, x >. Suppose that CT is the set of k-shifting experts and that pCT is the even distribution on the CT. As for the weighted majority algorithms, it is a mixture with a fixed vector: p (x) = (x, y) = p \u2212 n = 1 xi log (xi yi) is relative entropy. One way to ensure that it is not expansive is to be a mixture with a fixed vector: p (x) = (1 \u2212 z) x \u2212 t) x + p = x x x x x x x \u00b2 t = 1 x \u00b2 t for any problem. (0, 1) Conveexity of relative entropy results in it not being expansive."}, {"heading": "13 Conclusion", "text": "We studied a general framework of online learning against a competitive class represented by a weighted automaton and demonstrated that sublinear regrets guarantees can be achieved in this scenario. We gave a set of algorithms for this problem, including an automation-based algorithm that extends weighted majority problems whose computation costs in turn t depend on the total number of transitions that the states of the competing automaton reach at the time t, resulting in significant efficiency improvements. We used the term error transitions to provide a compact representation of the competing automaton or its intersection with the set of longitudinal strings, resulting in significant efficiency improvements, which required the introduction of new error-based compositions and short-range algorithms that may be of independent interest. We also gave a comprehensive study of algorithms based on a compact approximation of the competing automaton."}, {"heading": "14 Additional proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "14.1 Proof of Theorem 1", "text": "The proof. We will use a standardized argument based on the function. Let this argument be the potential defined by: Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp = Sp"}, {"heading": "14.2 Proof of Lemma 1", "text": "proof. We can calculate the following: \u2212 D (k + (1 / 2) T \u2212 1 (1 + 12k) T \u2212 1 logk T \u2212 1 (1 + 12k) k T \u2212 1 (1 + 12k) k T \u2212 1 (1 + 12k) k T \u2212 1 logk T \u2212 1 (1 + 12k) k T \u2212 1 + (1 \u2212 kT) log1 \u2212 kT \u2212 1 (1 + 12k) k T \u2212 1 (1 + 12k) k T \u2212 1 (1 + 12k) k \u2212 kT \u2212 1 \u2212 kT) kT (1 \u2212 kT \u2212 12k) kT (1 \u2212 kT) T (1 \u2212 k + 14k k T T \u2212 12k) T (1 \u2212 kT) T (1 \u2212 kT) T (1 \u2212 kT) T (1 \u2212 kT) T (1 \u2212 kT) \u2212 kT (1 \u2212 kT) T (1 \u2212 kT) \u2212 12k + 1 \u2212 kT (1 \u2212 kT) k + 14k k k T (T \u2212 kT) T (1 \u2212 kT)"}, {"heading": "14.3 Proof of Theorem 5", "text": "Proof: Consider the mirror map. This leads to the Bregman divergence: B-shaped (p, q) = m-shaped (p) = 1 pj (i) log (i) qj (i). Since any relative entropy is 1-strongly convex in relation to the l1 norm over a single simplex, the additivity of strong convexity implies that B-shaped is 1-strongly convex in relation to the l1 norm defined in the theorem statement. The update corresponds to the mirror parentage based on B-shaped: pt + 1 = argmin p-shaped (N) m < gt, p > + B-shaped (p, pt)."}, {"heading": "14.4 Proof of Theorem 14", "text": "Given any p, q, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p,"}], "references": [{"title": "A closer look at adaptive regret", "author": ["Dmitry Adamskiy", "Wouter M Koolen", "Alexey Chernov", "Vladimir Vovk"], "venue": "In International Conference on Algorithmic Learning Theory,", "citeRegEx": "Adamskiy et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Adamskiy et al\\.", "year": 2012}, {"title": "Efficient string matching: An aid to bibliographic search", "author": ["A.V. Aho", "M.J. Corasick"], "venue": "Communication of the Association for Computing Machinery,", "citeRegEx": "Aho and Corasick.,? \\Q1975\\E", "shortCiteRegEx": "Aho and Corasick.", "year": 1975}, {"title": "3-way composition of weighted finite-state transducers", "author": ["Cyril Allauzen", "Mehryar Mohri"], "venue": "In International Conference on Implementation and Application of Automata,", "citeRegEx": "Allauzen and Mohri.,? \\Q2008\\E", "shortCiteRegEx": "Allauzen and Mohri.", "year": 2008}, {"title": "Generalized algorithms for constructing statistical language models", "author": ["Cyril Allauzen", "Mehryar Mohri", "Brian Roark"], "venue": "In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume", "citeRegEx": "Allauzen et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Allauzen et al\\.", "year": 2003}, {"title": "Spectral learning of general weighted automata via constrained matrix completion", "author": ["Borja Balle", "Mehryar Mohri"], "venue": "In 26th Annual Conference on Neural Information Processing Systems", "citeRegEx": "Balle and Mohri.,? \\Q2012\\E", "shortCiteRegEx": "Balle and Mohri.", "year": 2012}, {"title": "On the Rademacher complexity of weighted automata", "author": ["Borja Balle", "Mehryar Mohri"], "venue": "In International Conference on Algorithmic Learning Theory,", "citeRegEx": "Balle and Mohri.,? \\Q2015\\E", "shortCiteRegEx": "Balle and Mohri.", "year": 2015}, {"title": "Stochastic multi-armed-bandit problem with non-stationary rewards", "author": ["Omar Besbes", "Yonatan Gur", "Assaf Zeevi"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Besbes et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Besbes et al\\.", "year": 2014}, {"title": "Non-stationary stochastic optimization", "author": ["Omar Besbes", "Yonatan Gur", "Assaf Zeevi"], "venue": "Operations Research,", "citeRegEx": "Besbes et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Besbes et al\\.", "year": 2015}, {"title": "Prediction, Learning, and Games", "author": ["Nicol\u00f2 Cesa-Bianchi", "G\u00e1bor Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "Improved second-order bounds for prediction with expert advice", "author": ["Nicol\u00f2 Cesa-Bianchi", "Yishay Mansour", "Gilles Stoltz"], "venue": "Machine Learning,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2007}, {"title": "Mirror descent meets fixed share (and feels no regret)", "author": ["Nicol\u00f2 Cesa-Bianchi", "Pierre Gaillard", "G\u00e1bor Lugosi", "Gilles Stoltz"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2012}, {"title": "An empirical study of smoothing techniques for language modeling", "author": ["Stanley Chen", "Joshua Goodman"], "venue": "Technical Report,", "citeRegEx": "Chen and Goodman.,? \\Q1998\\E", "shortCiteRegEx": "Chen and Goodman.", "year": 1998}, {"title": "Transductions and repetitions", "author": ["Maxime Crochemore"], "venue": "Theoretical Computer Science,", "citeRegEx": "Crochemore.,? \\Q1986\\E", "shortCiteRegEx": "Crochemore.", "year": 1986}, {"title": "Strongly adaptive online learning", "author": ["Amit Daniely", "Alon Gonen", "Shai Shalev-Shwartz"], "venue": "In Proceedings of The 32nd International Conference on Machine Learning,", "citeRegEx": "Daniely et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Daniely et al\\.", "year": 2015}, {"title": "Using and combining predictors that specialize", "author": ["Yoav Freund", "Robert E Schapire", "Yoram Singer", "Manfred K Warmuth"], "venue": "In Proceedings of the twenty-ninth annual ACM symposium on Theory of computing,", "citeRegEx": "Freund et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1997}, {"title": "Shifting regret, mirror descent, and matrices", "author": ["Andr\u00e1s Gy\u00f6rgy", "Csaba Szepesv\u00e1ri"], "venue": "In ICML,", "citeRegEx": "Gy\u00f6rgy and Szepesv\u00e1ri.,? \\Q2016\\E", "shortCiteRegEx": "Gy\u00f6rgy and Szepesv\u00e1ri.", "year": 2016}, {"title": "Efficient tracking of large classes of experts", "author": ["Andr\u00e1s Gyorgy", "Tam\u00e1s Linder", "G\u00e1bor Lugosi"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Gyorgy et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gyorgy et al\\.", "year": 2012}, {"title": "Online optimization in dynamic environments", "author": ["Eric C Hall", "Rebecca M Willett"], "venue": "arXiv preprint arXiv:1307.5944,", "citeRegEx": "Hall and Willett.,? \\Q2013\\E", "shortCiteRegEx": "Hall and Willett.", "year": 2013}, {"title": "Efficient learning algorithms for changing environments", "author": ["Elad Hazan", "Comandur Seshadhri"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Hazan and Seshadhri.,? \\Q2009\\E", "shortCiteRegEx": "Hazan and Seshadhri.", "year": 2009}, {"title": "Tracking the best expert", "author": ["Mark Herbster", "Manfred K Warmuth"], "venue": "Machine Learning,", "citeRegEx": "Herbster and Warmuth.,? \\Q1998\\E", "shortCiteRegEx": "Herbster and Warmuth.", "year": 1998}, {"title": "A spectral algorithm for learning hidden markov models", "author": ["Daniel Hsu", "Sham M Kakade", "Tong Zhang"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Hsu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2012}, {"title": "Online optimization: Competing with dynamic comparators", "author": ["Ali Jadbabaie", "Alexander Rakhlin", "Shahin Shahrampour", "Karthik Sridharan"], "venue": "In AISTATS,", "citeRegEx": "Jadbabaie et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jadbabaie et al\\.", "year": 2015}, {"title": "Interpolated estimation of markov source parameters from sparse data", "author": ["Frederick Jelinek", "Robert L. Mercer"], "venue": "In Proceedings of the Workshop on Pattern Recognition in Practice,", "citeRegEx": "Jelinek and Mercer.,? \\Q1980\\E", "shortCiteRegEx": "Jelinek and Mercer.", "year": 1980}, {"title": "Learning hurdles for sleeping experts", "author": ["Varun Kanade", "Thomas Steinke"], "venue": "ACM Transactions on Computation Theory (TOCT),", "citeRegEx": "Kanade and Steinke.,? \\Q2014\\E", "shortCiteRegEx": "Kanade and Steinke.", "year": 2014}, {"title": "Sleeping experts and bandits with stochastic action availability and adversarial rewards", "author": ["Varun Kanade", "HB McMahan", "Brent Bryan"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Kanade et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kanade et al\\.", "year": 2009}, {"title": "Estimation of probabilities from sparse data for the language model component of a speech recogniser", "author": ["Slava M. Katz"], "venue": "IEEE Transactions on Acoustic, Speech, and Signal Processing,", "citeRegEx": "Katz.,? \\Q1987\\E", "shortCiteRegEx": "Katz.", "year": 1987}, {"title": "Exponentiated gradient versus gradient descent for linear predictors", "author": ["Jyrki Kivinen", "Manfred K Warmuth"], "venue": "Information and Computation,", "citeRegEx": "Kivinen and Warmuth.,? \\Q1997\\E", "shortCiteRegEx": "Kivinen and Warmuth.", "year": 1997}, {"title": "Regret bounds for sleeping experts and bandits", "author": ["Robert Kleinberg", "Alexandru Niculescu-Mizil", "Yogeshwer Sharma"], "venue": "Machine learning,", "citeRegEx": "Kleinberg et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kleinberg et al\\.", "year": 2010}, {"title": "Fast pattern matching in strings", "author": ["D.E. Knuth", "J.H. Morris Jr.", "V.R. Pratt"], "venue": "SIAM Journal of Comput. Syst. Sci.,", "citeRegEx": "Knuth et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Knuth et al\\.", "year": 1977}, {"title": "Universal codes from switching strategies", "author": ["Wouter M Koolen", "Steven de Rooij"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Koolen and Rooij.,? \\Q2013\\E", "shortCiteRegEx": "Koolen and Rooij.", "year": 2013}, {"title": "The weighted majority algorithm", "author": ["Nick Littlestone", "Manfred K Warmuth"], "venue": "Information and computation,", "citeRegEx": "Littlestone and Warmuth.,? \\Q1994\\E", "shortCiteRegEx": "Littlestone and Warmuth.", "year": 1994}, {"title": "String-Matching with Automata", "author": ["Mehryar Mohri"], "venue": "Nordic Journal of Computing,", "citeRegEx": "Mohri.,? \\Q1997\\E", "shortCiteRegEx": "Mohri.", "year": 1997}, {"title": "Weighted automata algorithms. In Handbook of weighted automata, pages 213\u2013254", "author": ["Mehryar Mohri"], "venue": null, "citeRegEx": "Mohri.,? \\Q2009\\E", "shortCiteRegEx": "Mohri.", "year": 2009}, {"title": "Regular approximation of context-free grammars through transformation", "author": ["Mehryar Mohri", "Mark-Jan Nederhof"], "venue": "In Robustness in language and speech technology,", "citeRegEx": "Mohri and Nederhof.,? \\Q2001\\E", "shortCiteRegEx": "Mohri and Nederhof.", "year": 2001}, {"title": "Online optimization in dynamic environments: Improved regret rates for strongly convex problems", "author": ["Aryan Mokhtari", "Shahin Shahrampour", "Ali Jadbabaie", "Alejandro Ribeiro"], "venue": "In Decision and Control (CDC),", "citeRegEx": "Mokhtari et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mokhtari et al\\.", "year": 2016}, {"title": "Online learning of non-stationary sequences", "author": ["Claire Monteleoni", "Tommi S Jaakkola"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Monteleoni and Jaakkola.,? \\Q2003\\E", "shortCiteRegEx": "Monteleoni and Jaakkola.", "year": 2003}, {"title": "Practical experiments with regular approximation of context-free languages", "author": ["Mark-Jan Nederhof"], "venue": "Computational Linguistics,", "citeRegEx": "Nederhof.,? \\Q2000\\E", "shortCiteRegEx": "Nederhof.", "year": 2000}, {"title": "On structuring probabilistic dependences in stochastic language modeling", "author": ["Hermann Ney", "Ute Essen", "Reinhard Kneser"], "venue": "Computer Speech and Language,", "citeRegEx": "Ney et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Ney et al\\.", "year": 1994}, {"title": "Finite-state approximation of phrase structure grammars", "author": ["Fernando CN Pereira", "Rebecca N Wright"], "venue": "In Proceedings of the 29th annual meeting on Association for Computational Linguistics,", "citeRegEx": "Pereira and Wright.,? \\Q1991\\E", "shortCiteRegEx": "Pereira and Wright.", "year": 1991}, {"title": "The minimum consistent DFA problem cannot be approximated within any polynomial", "author": ["Leonard Pitt", "Manfred K Warmuth"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Pitt and Warmuth.,? \\Q1993\\E", "shortCiteRegEx": "Pitt and Warmuth.", "year": 1993}, {"title": "On measures of entropy and information", "author": ["Alfr\u00e9d R\u00e9nyi"], "venue": "In Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Contributions to the Theory of Statistics. The Regents of the University of California,", "citeRegEx": "R\u00e9nyi,? \\Q1961\\E", "shortCiteRegEx": "R\u00e9nyi", "year": 1961}, {"title": "On the probability of large deviations of random magnitudes", "author": ["Ivan Nikolaevich Sanov"], "venue": "Matematicheskii Sbornik,", "citeRegEx": "Sanov.,? \\Q1957\\E", "shortCiteRegEx": "Sanov.", "year": 1957}, {"title": "Distributed online optimization in dynamic environments using mirror descent", "author": ["Shahin Shahrampour", "Ali Jadbabaie"], "venue": "arXiv preprint arXiv:1609.02845,", "citeRegEx": "Shahrampour and Jadbabaie.,? \\Q2016\\E", "shortCiteRegEx": "Shahrampour and Jadbabaie.", "year": 2016}, {"title": "R\u00e9nyi divergence and kullback-leibler divergence", "author": ["Tim Van Erven", "Peter Harremos"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Erven and Harremos.,? \\Q2014\\E", "shortCiteRegEx": "Erven and Harremos.", "year": 2014}, {"title": "Derandomizing stochastic prediction strategies", "author": ["Vladimir Vovk"], "venue": "Machine Learning,", "citeRegEx": "Vovk.,? \\Q1999\\E", "shortCiteRegEx": "Vovk.", "year": 1999}, {"title": "Tracking the best expert in non-stationary stochastic environments", "author": ["Chen-Yu Wei", "Yi-Te Hong", "Chi-Jen Lu"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Wei et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wei et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 16, "context": "This work has subsequently been improved to account for broader expert classes [Gyorgy et al., 2012], to deal with unknown parameters [Monteleoni and Jaakkola, 2003], and has been further generalized [Cesa-Bianchi et al.", "startOffset": 79, "endOffset": 100}, {"referenceID": 35, "context": ", 2012], to deal with unknown parameters [Monteleoni and Jaakkola, 2003], and has been further generalized [Cesa-Bianchi et al.", "startOffset": 41, "endOffset": 72}, {"referenceID": 5, "context": "Within the online learning framework, the setting of prediction with expert advice has received widespread attention [Littlestone and Warmuth, 1994, Cesa-Bianchi and Lugosi, 2006, Cesa-Bianchi et al., 2007]. In this setting, the algorithm maintains a distribution over a set of experts, or selects an expert from an implicitly maintained distribution. At each round, the loss assigned to each expert is revealed. The algorithm incurs the expected loss over the experts and then updates her distribution on the set of experts. The objective of the learner is to minimize his expected regret, which is defined as the cumulative loss of the algorithm minus the cumulative loss of the best expert chosen in hindsight. However, this benchmark is only significant when the best expert is expected to perform well. When this is not the case, then the learner may still play poorly. As an example, it may be that no single baseball team has performed well over all seasons in the past few years. Instead, different teams may have dominated over different time periods. This has led to a definition of regret against the best sequence of experts with k shifts in the seminal work of Herbster and Warmuth [1998] on tracking the best expert.", "startOffset": 149, "endOffset": 1202}, {"referenceID": 5, "context": "Within the online learning framework, the setting of prediction with expert advice has received widespread attention [Littlestone and Warmuth, 1994, Cesa-Bianchi and Lugosi, 2006, Cesa-Bianchi et al., 2007]. In this setting, the algorithm maintains a distribution over a set of experts, or selects an expert from an implicitly maintained distribution. At each round, the loss assigned to each expert is revealed. The algorithm incurs the expected loss over the experts and then updates her distribution on the set of experts. The objective of the learner is to minimize his expected regret, which is defined as the cumulative loss of the algorithm minus the cumulative loss of the best expert chosen in hindsight. However, this benchmark is only significant when the best expert is expected to perform well. When this is not the case, then the learner may still play poorly. As an example, it may be that no single baseball team has performed well over all seasons in the past few years. Instead, different teams may have dominated over different time periods. This has led to a definition of regret against the best sequence of experts with k shifts in the seminal work of Herbster and Warmuth [1998] on tracking the best expert. The authors showed that there exists an efficient on-line learning algorithm for this setting with favorable regret guarantees. This work has subsequently been improved to account for broader expert classes [Gyorgy et al., 2012], to deal with unknown parameters [Monteleoni and Jaakkola, 2003], and has been further generalized [Cesa-Bianchi et al., 2012, Vovk, 1999]. Another approach for handling dynamic environments has consisted of designing algorithms that guarantee small regret over any subinterval during the course of play. This notion coined as adaptive regret by Hazan and Seshadhri [2009] has been subsequently strengthened and generalized [Daniely et al.", "startOffset": 149, "endOffset": 1833}, {"referenceID": 0, "context": ", 2015, Adamskiy et al., 2012]. Remarkably, it was shown by Adamskiy et al. [2012] that the algorithm designed by Herbster and Warmuth [1998] is also optimal for adaptive regret.", "startOffset": 8, "endOffset": 83}, {"referenceID": 0, "context": ", 2015, Adamskiy et al., 2012]. Remarkably, it was shown by Adamskiy et al. [2012] that the algorithm designed by Herbster and Warmuth [1998] is also optimal for adaptive regret.", "startOffset": 8, "endOffset": 142}, {"referenceID": 0, "context": ", 2015, Adamskiy et al., 2012]. Remarkably, it was shown by Adamskiy et al. [2012] that the algorithm designed by Herbster and Warmuth [1998] is also optimal for adaptive regret. Koolen and de Rooij [2013] described a Bayesian framework for online learning where the learner samples from a distribution of expert sequences and predicts according to the prediction of that expert sequence.", "startOffset": 8, "endOffset": 206}, {"referenceID": 17, "context": "Another assumes that the learner has access to a dynamical model that is able to capture the benchmark sequence [Hall and Willett, 2013].", "startOffset": 112, "endOffset": 136}, {"referenceID": 14, "context": "We then extend the results above to the sleeping expert setting [Freund et al., 1997], where the learner may not have access to advice from every expert at each round (Section 11).", "startOffset": 64, "endOffset": 85}, {"referenceID": 6, "context": ", 2015, Besbes et al., 2015]. Another assumes that the learner has access to a dynamical model that is able to capture the benchmark sequence [Hall and Willett, 2013]. Gy\u00f6rgy and Szepesv\u00e1ri [2016] reinterpreted the framework of Hall and Willett [2013] to recover and extend the results of Herbster and Warmuth [1998].", "startOffset": 8, "endOffset": 197}, {"referenceID": 6, "context": ", 2015, Besbes et al., 2015]. Another assumes that the learner has access to a dynamical model that is able to capture the benchmark sequence [Hall and Willett, 2013]. Gy\u00f6rgy and Szepesv\u00e1ri [2016] reinterpreted the framework of Hall and Willett [2013] to recover and extend the results of Herbster and Warmuth [1998].", "startOffset": 8, "endOffset": 252}, {"referenceID": 6, "context": ", 2015, Besbes et al., 2015]. Another assumes that the learner has access to a dynamical model that is able to capture the benchmark sequence [Hall and Willett, 2013]. Gy\u00f6rgy and Szepesv\u00e1ri [2016] reinterpreted the framework of Hall and Willett [2013] to recover and extend the results of Herbster and Warmuth [1998]. In this paper, we significantly generalize the framework just described and consider prediction with expert advice in a setting where the learner\u2019s cumulative loss is compared against that of sequences represented by an arbitrary weighted family of sequences.", "startOffset": 8, "endOffset": 317}, {"referenceID": 6, "context": ", 2015, Besbes et al., 2015]. Another assumes that the learner has access to a dynamical model that is able to capture the benchmark sequence [Hall and Willett, 2013]. Gy\u00f6rgy and Szepesv\u00e1ri [2016] reinterpreted the framework of Hall and Willett [2013] to recover and extend the results of Herbster and Warmuth [1998]. In this paper, we significantly generalize the framework just described and consider prediction with expert advice in a setting where the learner\u2019s cumulative loss is compared against that of sequences represented by an arbitrary weighted family of sequences. We model this family using a weighted finite automaton (WFA). This strictly generalizes the notion of k-shifting regret and extends it to the notion of regret against a WFA. Measuring regret against an automaton is both natural and flexible. In fact, it may often be sensible to learn the set of competitor sequences using data before competing against it. For instance, the competitor automaton could be a language model trained over best sequences of baseball teams in the past. Moreover, the competitor automaton could be learned and reset incrementally. After each epoch, we could choose to learn a new competitor model and seek to perform well against that. We show that not only it is possible to achieve favorable regret against a WFA but that there exist computationally efficient algorithms to achieve that. We give a series of algorithms for this problem. Our first algorithm (Section 6) is an automata-based algorithm extending weighted-majority and using automata operations such as composition and shortest-distance; its computational cost is exponentially better than that of a na\u0131\u0308ve method. We further present efficient algorithms based on a compact approximation of the competitor automaton (Section 7), in particular efficient n-gram models obtained by minimizing the R\u00e9nyi divergence, and present an extensive study of the approximation properties of such models. We also show how existing algorithms for minimizing k-shifting regret can be recovered by learning a Maximum-Likelihood bigram language model over the k-shifting competitor automaton. To the best of our knowledge, this is the first instance of recovering the algorithms of Herbster and Warmuth [1998] by way of solely focusing on minimizing the k-shifting regret.", "startOffset": 8, "endOffset": 2262}, {"referenceID": 32, "context": "In the probability semiring, the order of the terms in the sum does not matter, and the quantity is well defined [Mohri, 2009].", "startOffset": 113, "endOffset": 126}, {"referenceID": 19, "context": "Then, the (weighted or unweighted) regret of an algorithm A against Ck-shift coincides with the definition of k-shifting regret studied by Herbster and Warmuth [1998]:", "startOffset": 139, "endOffset": 167}, {"referenceID": 30, "context": "4 Na\u0131\u0308ve algorithm A well-known algorithm for minimizing static regret in the prediction with expert advice setting is the weighted majority algorithm [Littlestone and Warmuth, 1994].", "startOffset": 151, "endOffset": 182}, {"referenceID": 32, "context": "A standard and efficient method for composing two weighted automata is to pair up matching transitions [Mohri, 2009].", "startOffset": 103, "endOffset": 116}, {"referenceID": 32, "context": "For any acyclic automaton A, \u03b1 can be computed in linear time using a general relaxation-based shortest-distance algorithm with a topological queue discipline [Mohri, 2009].", "startOffset": 159, "endOffset": 172}, {"referenceID": 32, "context": "Connection (or trimming) is a linear-time algorithm that removes these non-accessible states [Mohri, 2009].", "startOffset": 93, "endOffset": 106}, {"referenceID": 32, "context": "Any probabilistic weighted automaton can be converted into a stochastic automaton using the weight-pushing algorithm [Mohri, 2009], which takes linear time and consists of a shortest-distance computation combined with a reweighting of the transition weights, initial weights, and final weights in a way that pushes the weights towards the initial states.", "startOffset": 117, "endOffset": 130}, {"referenceID": 3, "context": "obtained from the expected count of the n-gram in the paths of CT , where the expectation is taken over the probability distribution defined by CT and can be computed efficiently [Allauzen et al., 2003].", "startOffset": 179, "endOffset": 202}, {"referenceID": 3, "context": "obtained from the expected count of the n-gram in the paths of CT , where the expectation is taken over the probability distribution defined by CT and can be computed efficiently [Allauzen et al., 2003]. Maximum likelihood n-gram models can further benefit from \u03c6-conversion using the algorithms presented in Section 9. This can reduce the size of An and improve its computational efficiency without affecting its accuracy. As an example, we can compute the bigram approximation to the k-shifting automaton. Remarkably, this will coincide with the FIXED-SHARE algorithm of Herbster and Warmuth [1998]. Thus, we can view and motivate the design of FIXED-SHARE as a bigram approximation of the desired competitor automaton, that is the family of k-shifting sequences.", "startOffset": 180, "endOffset": 601}, {"referenceID": 41, "context": "Since each shift occurs with probability k T\u22121 , we can use Sanov\u2019s theorem [Sanov, 1957] to write the following bound:", "startOffset": 76, "endOffset": 89}, {"referenceID": 19, "context": "The computational cost of using \u03c6-AWM with this new \u03c6-automaton coincides with the one described originally in [Herbster and Warmuth, 1998].", "startOffset": 111, "endOffset": 139}, {"referenceID": 26, "context": "The problem can be solved using as an optimization algorithm an extension of the Exponentiated Gradient algorithm developed by Kivinen and Warmuth [1997], which we call PROD-EG.", "startOffset": 127, "endOffset": 154}, {"referenceID": 19, "context": "This is a factor of N better than that of AWM, and only a factor of k worse than the specific algorithm of Herbster and Warmuth [1998]. Using a bigram approximation of the k-shifting automaton composed with ST and then introducing converting it into a \u03c6-automaton, we obtain an algorithm that runs in O(N).", "startOffset": 107, "endOffset": 135}, {"referenceID": 32, "context": "As with finite automata, finite-state transducers can also be augmented with weights, and as with weighted finite automata, weighted finite-state transducers can be composed efficiently and on-demand [Mohri, 2009].", "startOffset": 200, "endOffset": 213}, {"referenceID": 2, "context": "The reason why redundant \u03c6-paths are generated by standard composition algorithms is similar to the reason why redundant -paths are generated during composition of automata without failure transitions [Allauzen and Mohri, 2008].", "startOffset": 201, "endOffset": 227}, {"referenceID": 2, "context": "However, we can improve upon this by extending the 3-way composition technique presented in [Allauzen and Mohri, 2008] to our \u03c6-automata setting.", "startOffset": 92, "endOffset": 118}, {"referenceID": 14, "context": "This extension of standard prediction with expert advice is also known as the sleeping experts framework [Freund et al., 1997].", "startOffset": 105, "endOffset": 126}, {"referenceID": 14, "context": "In [Freund et al., 1997], the comparison is made against the best fixed mixture of experts normalized at each round over the awake set: minu\u2208\u2206N \u2211T t=1 \u2211 i\u2208At uilt[i] \u2211 j\u2208At uj .", "startOffset": 3, "endOffset": 24}, {"referenceID": 14, "context": "This motivates the design of AWAKEPBWM, a path-based weighted majority algorithm that generalizes the algorithms in [Freund et al., 1997] to arbitrary families of expert sequences.", "startOffset": 116, "endOffset": 137}, {"referenceID": 17, "context": "The proof of this result follows along similar lines as the original result by [Hall and Willett, 2013].", "startOffset": 79, "endOffset": 103}, {"referenceID": 16, "context": "The proof of this result follows along similar lines as the original result by [Hall and Willett, 2013]. The major difference is that the authors in that work assume \u03a8 to be Lipschitz. This allows them to derive a slightly weaker but more interpretable bound. However, it is also an assumption that we specifically choose to avoid, since mirror descent algorithms including the EXPONENTIATED GRADIENT use mirror maps that are not Lipschitz. Hall and Willett [2013] also derive a bound for standard regret as opposed to regret against a distribution of sequences.", "startOffset": 80, "endOffset": 465}, {"referenceID": 15, "context": "Note that Gy\u00f6rgy and Szepesv\u00e1ri [2016] present the same algorithm but with a different analysis and upper bound.", "startOffset": 10, "endOffset": 39}, {"referenceID": 15, "context": "[Gy\u00f6rgy and Szepesv\u00e1ri, 2016]) which only showed that one could define \u03a6t in a way that mimics the FIXED-SHARE algorithm.", "startOffset": 0, "endOffset": 29}], "year": 2017, "abstractText": "We consider a general framework of online learning with expert advice where the regret is defined with respect to a competitor class defined by a weighted automaton over sequences of experts. Our framework covers several problems previously studied, in particular that of competing against k-shifting experts. We give a series of algorithms for this problem, including an automata-based algorithm extending weightedmajority and more efficient algorithms based on the notion of failure transitions. We further present efficient algorithms based on a compact approximation of the competitor automaton, in particular efficient n-gram models obtained by minimizing the R\u00e9nyi divergence, and present an extensive study of the approximation properties of such models. We also extend our algorithms and results to the framework of sleeping experts. Finally, we describe the extension of our approximation methods to online convex optimization and a general mirror descent setting.", "creator": "LaTeX with hyperref package"}}}