{"id": "1705.00335", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Apr-2017", "title": "Quantifying Mental Health from Social Media with Neural User Embeddings", "abstract": "Mental illnesses adversely affect a significant proportion of the population worldwide. However, the methods traditionally used for estimating and characterizing the prevalence of mental health conditions are time-consuming and expensive. Consequently, best-available estimates concerning the prevalence of mental health conditions are often years out of date. Automated approaches to supplement these survey methods with broad, aggregated information derived from social media content provides a potential means for near real-time estimates at scale. These may, in turn, provide grist for supporting, evaluating and iteratively improving upon public health programs and interventions.", "histories": [["v1", "Sun, 30 Apr 2017 16:12:28 GMT  (6879kb,D)", "http://arxiv.org/abs/1705.00335v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.SI", "authors": ["silvio amir", "glen coppersmith", "paula carvalho", "m\\'ario j silva", "byron c wallace"], "accepted": false, "id": "1705.00335"}, "pdf": {"name": "1705.00335.pdf", "metadata": {"source": "CRF", "title": "Quantifying Mental Health from Social Media with Neural User Embeddings Quantifying Mental Health from Social Media with Neural User Embeddings", "authors": ["Silvio Amir", "Glen Coppersmith", "M\u00e1rio J. Silva", "Byron C. Wallace"], "emails": ["samir@inesc-id.pt", "glen@qntfy.com", "pcc@inesc-id.pt", "mjs@inesc-id.pt", "b.wallace@northeastern.edu"], "sections": [{"heading": null, "text": "We propose a novel model for automated quantification of mental health status that incorporates user embeddings, based on recent work that explores methods of representative learning that trigger embeddings through the use of social media poststories. Such embeddings capture latent traits of individuals (e.g. political bias) and encode a soft notion of homophilia. In this paper, we investigate whether user embeddings learned from Twitter poststories encode information that correlates with the state of mental health. To this end, we evaluated user embeddings for a group of users known to be affected by depression and post-traumatic stress disorder (PTSD), and for a number of demographically matched \"control users.\" We then evaluated these embeddings in terms of: (i) their ability to capture homophilic relationships related to mental health status, and (ii) the performance of these predictive mental health models."}, {"heading": "1. Introduction", "text": "An estimate by the Centers for Disease Control in 2008 (CDC, 2010) suggests that 9% of US adults can meet the criteria for measuring mental health conditions; the collective impact of mental health conditions as measured by Daily Adjusted Life Years (DALYs) exceeds that of malaria, war, or injury; at the same time, mental health problems are often difficult to identify and thus treat; half of depressive cases go undetected, in part because of the heterogeneous and complex nature of the condition (Paykel et al, 1997)."}, {"heading": "2. Depression and PTSD on Twitter", "text": "In 2015, the CLPsych workshop held a joint task to promote progress in NLP technologies with potential for applications related to the analysis of mental health via social media (Mitchell et al., 2015; Coppersmith et al., 2015b). For this purpose, a data set was compiled that included users who publicly declared on Twitter that they were suffering from depression (327 users) or PTSD (246 users), and an equal number of randomly selected users as controls4. For each user in this data set, associated metadata and posthistory were also collected - up to the 3000 most recent tweets, depending on the limitation of the Twitter API. For more details on the structure and validation of the data see (Coppersmith et al., 2015b, 2014a, b).Participants were then asked to develop models to differentiate between users affected by mental illness based on their contributions and metadata Sen Sen Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-Sen-S@-@ Sen-Sen-S@-@ Sen-Sen-Si-Sen-Si-Si-Si-Si-Si-Si-Si-Si-system-Si-Si-Si-"}, {"heading": "3. Related Work", "text": "Most of the research in social media analysis has focused on deriving better models based on the representations of texts of individual users that are no longer available, both through manually designed features and through newer, representative learning approaches (Severyn and Moschitti, 2015; Astudillo et al., 2015). Nevertheless, it is crucial to understand the characteristics of users in communication, including information gathering (Yang et al., 2016), opinion forming (Bamman and Smith, 2015), and content recommendations (Yu et al., 2016)."}, {"heading": "4. Learning User Embeddings", "text": "The idea is to capture the relationships between users and the content (i.e., the words) they generate by optimizing the probability of sentences going back to their authors. The goal is to estimate the parameters of a user vector uj who maximizes the conditional probability: P (Cj | uj), P (wi), S logP (wi | uj).The goal is to estimate the parameters of a user vector uj who maximizes the conditional probability: P (Cj | uj), S logP (wi), P (wi _ uj), W (wi _ uj).s The goal is to estimate the parameters of a user vector uj who maximizes the conditional probability."}, {"heading": "5. User Embedding Analysis", "text": "In this section, we address our first research question by examining whether user embeddings have learned directly from social media data to encode information relevant to public health applications.Previous work has shown that these embeddings capture latent user aspects and a soft notion of \"homophobic.\" If some of these aspects correlate with mental health, then embeddings could be used to identify risk groups; for example, we could identify and characterize users who \"look\" like patients affected by depression as a consequence.6 The ability to do so would allow potentially scalable real-time assessments of the prevalence of mental health problems in certain populations.We estimated User2Vec embeddings from the data set described in Section 2 as a consequence.6 First, we have pre-edited tweets by: reducing their shortening; reducing repetitions to three repetitions at most; and replacing them with a user name and URI."}, {"heading": "5.1 Measuring Homophily", "text": "To investigate whether the induced user vectors capture homophilic relationships in relation to the state of mental health, we first projected the d-dimensional vectors into a two-dimensional space using t-Stochastic Neighborhood Embedding (TSNE) (Van der Maaten and Hinton, 2008). To better quantify this effect and allow for comparison of different user embedding models, we proceeded as follows: For each user in the corpus, we calculated the similarities to all other users (i.e., the cosmic similarity between their respective embedding), thereby generating a ranking of users in relation to the similarity to the \"query\" users. Intuitively, we hope that users in the same mental health categories are comparatively similar to other users, with the similarity between their respective embedding being most similar."}, {"heading": "6. Predicting Mental Health from Twitter Data", "text": "To answer our second research question, we examined user representations for their predictive power in downstream mental health analytics applications. Above, we showed that representations generated by user postings encode relevant signals about mental health. However, generic characteristics estimated from unattended tasks are suboptimal for downstream tasks (Astudillo et al., 2015). Neural networks, when finalized, can refine generic embedding to specific tasks by changing their parameters during supervised training (Collobert et al., 2011). However, given the modest size of the dataset, this strategy requires updating a large number of parameters, which is difficult when only small training datasets are available. The CLPsh dataset comprises 1094 tagged instances (after users with fewer than 100 tweets were discarded). Given the modest size of the dataset, we adopted the Astudillet al (2015) non-linear embedding approach to the Darkspace."}, {"heading": "6.1 Proposed Model", "text": "The NLSE model adapts generic embedding to specific applications by inserting linear projections into low-dimensional sub-spaces (\u03b2 \u00b7 2) while retaining the original embedding; the resulting sub-space embedding captures domain and task-specific aspects while retaining the rich information encoded by the original embedding. Formally, the embedding of a user matrix U \u0394Rd \u00b7 | U |, in which the column U [j] represents user-specific aspects, by factorizing the input as S \u00b7 U, where S-Rs \u00b7 d is a (learned) linear projection matrix, is crucial because it imposes a dimensionality reduction on the feature space, while eliminating noise and reducing the number of free parameters, making it easier to train the model with small datasets. This model resembles an introductory-oriented neural network with a single embedding layer."}, {"heading": "6.2 Experimental Setup", "text": "We evaluated embeddings induced with the User2Vec (u2v) and Paragraph2vec's PVdm and PV-dbow models (Section 5) as features in Logistic Regression (LR) and NLSE classifiers, which were compared with textual features based on: 1. bow: bag-of-words vectors with binary weights, x, 0, 1} | V |; 2. boe: bag-of-embeddings. We used Skip-Gram embeddings to build vectors, x = \u2211 w E [w], where E [w] \u0445Rd is the embedding of word w; 3. lda: bag-of-topics. We induced t = 100 topics using latent dirichlet location (Blei et al., 2003) to build vectors that specify vectors x, 1} t that are the topics present in user posts."}, {"heading": "6.3 Results", "text": "The classifiers were mainly evaluated in terms of the macro-average value F1. We also report on the results in relation to the binary value F1, where we only use the averages for the depression and Ptsd classes to better determine the ability of the models to distinguish between mentally ill patients, which are less common than the controls, but are the cases that matter most to us. The most important classification results are presented in Figure 3. First, it should be noted that the BOW represents a very strong baseline that essentially outperforms all other linear classifiers based on textual characteristics and user embeddings. One reason for this is that users with mental illness often talk about their conditions and that the arc model can easily link to such cues. In terms of user embeddings, we have found that PV embedding, despite its equivalence, performs much worse than the User2Vec, which shows that better embeddings can be achieved by trying to predict the usage of all the educated words."}, {"heading": "7. Conclusions", "text": "In this paper, we investigated whether embedding induced by user postings detects relevant signals for clinical applications. In particular, we compared different embedding methods of users in terms of their ability to capture homophilic relationships between users and their performance as traits in downstream models for predicting mental health. Analysis, which was conducted using a dataset of users with diagnoses of depression and PTSD and demographically matched controls, showed that these representations can actually detect mental health signals. This is consistent with previous results from the field of psychology that establish links between word use and mental status (Pennebaker et al., 2001). Interestingly, embedding generated without the knowledge of user labels detects similarities in relation to mental state. Furthermore, we have shown that these embedding can be customized - with a small amount of task-specific, characterized data - in order to provide more accurate, empirical health information to enhance these user-related phenomena."}, {"heading": "A. Measuring Homophily (continued)", "text": "B. Visualizing Embedding Subspace FeaturesThe NLSE induces task-specific representations by learning low-dimensional embedding. We take advantage of the fact that sigmoid nonlinearity (Eq. 3) projects all characteristic values into the range [0; 1] to map these values in color intensities in a heatmap. We then used the same sample to generate the diagrams in Section 5 (100 users per class), and plotted the representations learned by the model. The resulting diagram is Figure 6. We can find that certain characteristic groups are usually activated in certain classes. From this diagram we can see that the characteristics induced by the PV-DM model are more economical than the other models, which may explain why these characteristics can better capture user similarities. On the other hand, the characteristics that are generated by PV-DM and User2c appear to be similar in respective classes, but we also appear to be more similar in the differences between the respective classes, \"7."}], "references": [{"title": "Modelling context with user embeddings for sarcasm detection in social media", "author": ["Silvio Amir", "Byron C Wallace", "Hao Lyu", "Paula Carvalho M\u00e1rio J Silva"], "venue": "arXiv preprint arXiv:1607.00976,", "citeRegEx": "Amir et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Amir et al\\.", "year": 2016}, {"title": "Learning word representations from scarce and noisy data with embedding subspaces", "author": ["Ram\u00f3n Astudillo", "Silvio Amir", "Wang Ling", "Mario Silva", "Isabel Trancoso"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),", "citeRegEx": "Astudillo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Astudillo et al\\.", "year": 2015}, {"title": "Contextualized sarcasm detection on twitter", "author": ["David Bamman", "Noah A Smith"], "venue": "In Proceedings of the 9th International Conference on Web and Social Media,", "citeRegEx": "Bamman and Smith.,? \\Q2015\\E", "shortCiteRegEx": "Bamman and Smith.", "year": 2015}, {"title": "A neural probabilistic language model", "author": ["Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent", "Christian Janvin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Bengio et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2003}, {"title": "Deep learning. Book in preparation for MIT Press, 2015a. URL http://www.iro.umontreal.ca/~bengioy/dlbook", "author": ["Yoshua Bengio", "Ian J. Goodfellow", "Aaron Courville"], "venue": null, "citeRegEx": "Bengio et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2015}, {"title": "Latent dirichlet allocation", "author": ["David M Blei", "Andrew Y Ng", "Michael I Jordan"], "venue": "Journal of machine Learning research,", "citeRegEx": "Blei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Class-based n-gram models of natural language", "author": ["Peter F. Brown", "Peter V. Desouza", "Robert L. Mercer", "Vincent J. Della Pietra", "Jenifer C. Lai"], "venue": "Computational Linguistics,", "citeRegEx": "Brown et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1992}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Ethical issues in using twitter for public health surveillance and research: developing a taxonomy of ethical concepts from the research literature", "author": ["Mike Conway"], "venue": "Journal of medical Internet research,", "citeRegEx": "Conway.,? \\Q2014\\E", "shortCiteRegEx": "Conway.", "year": 2014}, {"title": "Quantifying mental health signals in Twitter", "author": ["Glen Coppersmith", "Mark Dredze", "Craig Harman"], "venue": "In Proceedings of the ACL Workshop on Computational Linguistics and Clinical Psychology,", "citeRegEx": "Coppersmith et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Coppersmith et al\\.", "year": 2014}, {"title": "Measuring post traumatic stress disorder in Twitter", "author": ["Glen Coppersmith", "Craig Harman", "Mark Dredze"], "venue": "In Proceedings of the 8th International AAAI Conference on Weblogs and Social Media (ICWSM),", "citeRegEx": "Coppersmith et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Coppersmith et al\\.", "year": 2014}, {"title": "From ADHD to SAD: Analyzing the language of mental health on Twitter through self-reported diagnoses", "author": ["Glen Coppersmith", "Mark Dredze", "Craig Harman", "Kristy Hollingshead"], "venue": "In Proceedings of the Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality,", "citeRegEx": "Coppersmith et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Coppersmith et al\\.", "year": 2015}, {"title": "CLPsych 2015 shared task: Depression and PTSD on Twitter", "author": ["Glen Coppersmith", "Mark Dredze", "Craig Harman", "Kristy Hollingshead", "Margaret Mitchell"], "venue": "In Proceedings of the Shared Task for the NAACL Workshop on Computational Linguistics and Clinical Psychology,", "citeRegEx": "Coppersmith et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Coppersmith et al\\.", "year": 2015}, {"title": "Exploratory data analysis of social media prior to a suicide attempt", "author": ["Glen Coppersmith", "Kim Ngo", "Ryan Leary", "Tony Wood"], "venue": "In Proceedings of the Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality,", "citeRegEx": "Coppersmith et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Coppersmith et al\\.", "year": 2016}, {"title": "Discovering shifts to suicidal ideation from mental health content in social media", "author": ["Munmun De Choudhury", "Emre Kiciman", "Mark Dredze", "Glen Coppersmith", "Mrinal Kumar"], "venue": "In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems,", "citeRegEx": "Choudhury et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Choudhury et al\\.", "year": 2016}, {"title": "A primer on neural network models for natural language processing", "author": ["Yoav Goldberg"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Goldberg.,? \\Q2016\\E", "shortCiteRegEx": "Goldberg.", "year": 2016}, {"title": "Distributed representations of sentences and documents", "author": ["Quoc V Le", "Tomas Mikolov"], "venue": "arXiv preprint arXiv:1405.4053,", "citeRegEx": "Le and Mikolov.,? \\Q2014\\E", "shortCiteRegEx": "Le and Mikolov.", "year": 2014}, {"title": "Learning multi-faceted representations of individuals from heterogeneous evidence using neural networks", "author": ["Jiwei Li", "Alan Ritter", "Dan Jurafsky"], "venue": "arXiv preprint arXiv:1510.05198,", "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Raichura. Best practices in social media: Utilizing a value matrix to assess social media\u2019s impact on health care", "author": ["Deirdre McCaughey", "Catherine Baumgardner", "Andrew Gaudes", "Dominique LaRochelle", "Kayla Jiaxin Wu", "Tejal"], "venue": "Social Science Computer Review,", "citeRegEx": "McCaughey et al\\.,? \\Q2014\\E", "shortCiteRegEx": "McCaughey et al\\.", "year": 2014}, {"title": "Ethical issues in using twitter for population-level depression monitoring: a qualitative study", "author": ["Jude Mikal", "Samantha Hurst", "Mike Conway"], "venue": "BMC medical ethics,", "citeRegEx": "Mikal et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mikal et al\\.", "year": 2016}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Proceedings of the Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality", "author": ["Margaret Mitchell", "Glen Coppersmith", "Kristy Hollingshead", "editors"], "venue": "North American Association for Computational Linguistics,", "citeRegEx": "Mitchell et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2015}, {"title": "You are what you tweet: Analyzing twitter for public health", "author": ["Michael J Paul", "Mark Dredze"], "venue": "Icwsm, 20:265\u2013272,", "citeRegEx": "Paul and Dredze.,? \\Q2011\\E", "shortCiteRegEx": "Paul and Dredze.", "year": 2011}, {"title": "The defeat depression campaign: psychiatry in the public arena", "author": ["ES Paykel", "A Tylee", "A Wright", "RG Priest"], "venue": "The American journal of psychiatry,", "citeRegEx": "Paykel et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Paykel et al\\.", "year": 1997}, {"title": "Screening twitter users for depression and ptsd with lexical decision lists", "author": ["Ted Pedersen"], "venue": "In Proceedings of the Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality,", "citeRegEx": "Pedersen.,? \\Q2015\\E", "shortCiteRegEx": "Pedersen.", "year": 2015}, {"title": "Linguistic inquiry and word count", "author": ["James W Pennebaker", "Martha E Francis", "Roger J Booth"], "venue": "Liwc", "citeRegEx": "Pennebaker et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Pennebaker et al\\.", "year": 2001}, {"title": "Mental illness detection at the world well-being project for the clpsych 2015 shared task", "author": ["Daniel Preotiuc-Pietro", "Maarten Sap", "H Andrew Schwartz", "LH Ungar"], "venue": "NAACL HLT 2015,", "citeRegEx": "Preotiuc.Pietro et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Preotiuc.Pietro et al\\.", "year": 2015}, {"title": "Sarcasm detection on twitter: A behavioral modeling approach", "author": ["Ashwin Rajadesingan", "Reza Zafarani", "Huan Liu"], "venue": "In Proceedings of the Eighth ACM International Conference on Web Search and Data Mining,", "citeRegEx": "Rajadesingan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rajadesingan et al\\.", "year": 2015}, {"title": "Software Framework for Topic Modelling with Large Corpora", "author": ["Radim \u0158eh\u030au\u0159ek", "Petr Sojka"], "venue": "In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks,", "citeRegEx": "\u0158eh\u030au\u0159ek and Sojka.,? \\Q2010\\E", "shortCiteRegEx": "\u0158eh\u030au\u0159ek and Sojka.", "year": 2010}, {"title": "Beyond lda: exploring supervised topic modeling for depression-related language in twitter", "author": ["Philip Resnik", "William Armstrong", "Leonardo Claudino", "Thang Nguyen", "Viet-An Nguyen", "Jordan Boyd-Graber"], "venue": "In Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality,", "citeRegEx": "Resnik et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Resnik et al\\.", "year": 2015}, {"title": "Learning representations by back-propagating errors", "author": ["David E Rumelhart", "Geoffrey E Hinton", "Ronald J Williams"], "venue": "Cognitive modeling,", "citeRegEx": "Rumelhart et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Rumelhart et al\\.", "year": 1988}, {"title": "Towards assessing changes in degree of depression through Facebook", "author": ["H. Andrew Schwartz", "Johannes Eichstaedt", "Margaret L. Kern", "Gregory Park", "Maarten Sap", "David Stillwell", "Michal Kosinski", "Lyle Ungar"], "venue": "In Proceedings of the ACL Workshop on Computational Linguistics and Clinical Psychology,", "citeRegEx": "Schwartz et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Schwartz et al\\.", "year": 2014}, {"title": "Twitter sentiment analysis with deep convolutional neural networks", "author": ["Aliaksei Severyn", "Alessandro Moschitti"], "venue": "In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "Severyn and Moschitti.,? \\Q2015\\E", "shortCiteRegEx": "Severyn and Moschitti.", "year": 2015}, {"title": "Contrastive estimation: Training log-linear models on unlabeled data", "author": ["Noah A Smith", "Jason Eisner"], "venue": "In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Smith and Eisner.,? \\Q2005\\E", "shortCiteRegEx": "Smith and Eisner.", "year": 2005}, {"title": "Visualizing data using t-sne", "author": ["Laurens Van der Maaten", "Geoffrey Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Maaten and Hinton.,? \\Q2008\\E", "shortCiteRegEx": "Maaten and Hinton.", "year": 2008}, {"title": "Toward socially-infused information extraction: Embedding authors, mentions, and entities", "author": ["Yi Yang", "Ming-Wei Chang", "Jacob Eisenstein"], "venue": "arXiv preprint arXiv:1609.08084,", "citeRegEx": "Yang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "User embedding for scholarly microblog recommendation", "author": ["Yang Yu", "Xiaojun Wan", "Xinjie Zhou"], "venue": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Yu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 23, "context": "For example, perhaps half of depressive cases go undetected, in part due to the heterogeneous and complex expression of this condition (Paykel et al., 1997).", "startOffset": 135, "endOffset": 156}, {"referenceID": 18, "context": "The internet may provide a comfortable medium for people to express their feelings anonymously and connect with health-care professionals (McCaughey et al., 2014) and others affected by similar conditions (De Choudhury et al.", "startOffset": 138, "endOffset": 162}, {"referenceID": 22, "context": "Prior work has demonstrated the potential of using social media to investigate mental health issues (Paul and Dredze, 2011), including depression (Schwartz et al.", "startOffset": 100, "endOffset": 123}, {"referenceID": 31, "context": "Prior work has demonstrated the potential of using social media to investigate mental health issues (Paul and Dredze, 2011), including depression (Schwartz et al., 2014), PTSD (Coppersmith et al.", "startOffset": 146, "endOffset": 169}, {"referenceID": 13, "context": ", 2014b) and suicidal ideation (Coppersmith et al., 2016; De Choudhury et al., 2016) in individuals.", "startOffset": 31, "endOffset": 84}, {"referenceID": 15, "context": ", predictive features) from data, freeing practitioners from the burden of manually designing and encoding task-specific features (Bengio et al., 2015a; Goldberg, 2016).", "startOffset": 130, "endOffset": 168}, {"referenceID": 3, "context": "Word embeddings in particular aim to implicitly encode latent word semantics (in the distributional sense), and can be learned in an unsupervised fashion by means of predictive models that exploit word co-occurrence statistics and other regularities in unlabeled corpora (Bengio et al., 2003).", "startOffset": 271, "endOffset": 292}, {"referenceID": 16, "context": "These models have been recently extended to infer representations for larger textual units (Le and Mikolov, 2014), and even user representations (Li et al.", "startOffset": 91, "endOffset": 113}, {"referenceID": 17, "context": "These models have been recently extended to infer representations for larger textual units (Le and Mikolov, 2014), and even user representations (Li et al., 2015; Amir et al., 2016).", "startOffset": 145, "endOffset": 181}, {"referenceID": 0, "context": "These models have been recently extended to infer representations for larger textual units (Le and Mikolov, 2014), and even user representations (Li et al., 2015; Amir et al., 2016).", "startOffset": 145, "endOffset": 181}, {"referenceID": 0, "context": "It has been shown that these user embeddings also capture latent user aspects and can be used in downstream applications, such as sarcasm detection (Amir et al., 2016) and content recommendation (Yu et al.", "startOffset": 148, "endOffset": 167}, {"referenceID": 36, "context": ", 2016) and content recommendation (Yu et al., 2016).", "startOffset": 35, "endOffset": 52}, {"referenceID": 21, "context": "In 2015, the CLPsych workshop held a shared task to foster progress in NLP technologies with potential for applications related to mental health analysis, over social media streams (Mitchell et al., 2015; Coppersmith et al., 2015b).", "startOffset": 181, "endOffset": 231}, {"referenceID": 24, "context": "The proposed systems were based on a wide range of approaches including: rule-based systems leveraging lexical decision lists (Pedersen, 2015), linear classifiers exploiting features based on word clusters and topic models (Preotiuc-Pietro et al.", "startOffset": 126, "endOffset": 142}, {"referenceID": 26, "context": "The proposed systems were based on a wide range of approaches including: rule-based systems leveraging lexical decision lists (Pedersen, 2015), linear classifiers exploiting features based on word clusters and topic models (Preotiuc-Pietro et al., 2015), supervised topic models (Resnik et al.", "startOffset": 223, "endOffset": 253}, {"referenceID": 29, "context": ", 2015), supervised topic models (Resnik et al., 2015) and systems exploiting character-level language models (Coppersmith et al.", "startOffset": 33, "endOffset": 54}, {"referenceID": 19, "context": "This data was collected according to the ethical protocol of ?, and follows the recommendations spelled out in Mikal et al. (2016).", "startOffset": 111, "endOffset": 131}, {"referenceID": 32, "context": "Most of the research in social media analysis has been concerned with deriving better models that operate on representations of the texts comprising individual users posts, both via manually crafted features and, more recently, representation learning approaches (Severyn and Moschitti, 2015; Astudillo et al., 2015).", "startOffset": 263, "endOffset": 316}, {"referenceID": 1, "context": "Most of the research in social media analysis has been concerned with deriving better models that operate on representations of the texts comprising individual users posts, both via manually crafted features and, more recently, representation learning approaches (Severyn and Moschitti, 2015; Astudillo et al., 2015).", "startOffset": 263, "endOffset": 316}, {"referenceID": 35, "context": "These include, information extraction (Yang et al., 2016), opinion mining (Tang et al.", "startOffset": 38, "endOffset": 57}, {"referenceID": 2, "context": ", 2015), sarcasm detection (Bamman and Smith, 2015) and content recommendation (Yu et al.", "startOffset": 27, "endOffset": 51}, {"referenceID": 36, "context": ", 2015), sarcasm detection (Bamman and Smith, 2015) and content recommendation (Yu et al., 2016).", "startOffset": 79, "endOffset": 96}, {"referenceID": 2, "context": "The most straightforward approach to induce user representations is by scrapping \u201cprofile\u201d information from social websites, to manually extract features based on social ties, demographic attributes, or posting habits (Bamman and Smith, 2015; Rajadesingan et al., 2015).", "startOffset": 218, "endOffset": 269}, {"referenceID": 27, "context": "The most straightforward approach to induce user representations is by scrapping \u201cprofile\u201d information from social websites, to manually extract features based on social ties, demographic attributes, or posting habits (Bamman and Smith, 2015; Rajadesingan et al., 2015).", "startOffset": 218, "endOffset": 269}, {"referenceID": 15, "context": "Neural Embedding Learning In recent years, models in NLP have moved from discrete word representations, based on scalars representing indices into a pre-defined vocabulary, towards distributed continuous vector word representations that encode latent semantics \u2014 these are usually referred as word embeddings (Goldberg, 2016).", "startOffset": 309, "endOffset": 325}, {"referenceID": 3, "context": "The general framework to learn unsupervised word embeddings involves associating words with parameter vectors, which are then optimized to be good predictors of other words that occur in the same contexts (Bengio et al., 2003).", "startOffset": 205, "endOffset": 226}, {"referenceID": 20, "context": "Skip-Gram (Mikolov et al., 2013), one of the most popular word embedding models, operationalizes this approach by sliding a window of a pre-specified size across the corpus.", "startOffset": 10, "endOffset": 32}, {"referenceID": 17, "context": "Recently proposed methods to learn user representations use essentially the same approach \u2014 associate users with parameter vectors, and optimize these to accurately predict observable attributes or the words used by said user in previous posts (Li et al., 2015; Amir et al., 2016; Yu et al., 2016).", "startOffset": 244, "endOffset": 297}, {"referenceID": 0, "context": "Recently proposed methods to learn user representations use essentially the same approach \u2014 associate users with parameter vectors, and optimize these to accurately predict observable attributes or the words used by said user in previous posts (Li et al., 2015; Amir et al., 2016; Yu et al., 2016).", "startOffset": 244, "endOffset": 297}, {"referenceID": 36, "context": "Recently proposed methods to learn user representations use essentially the same approach \u2014 associate users with parameter vectors, and optimize these to accurately predict observable attributes or the words used by said user in previous posts (Li et al., 2015; Amir et al., 2016; Yu et al., 2016).", "startOffset": 244, "endOffset": 297}, {"referenceID": 2, "context": "The general framework to learn unsupervised word embeddings involves associating words with parameter vectors, which are then optimized to be good predictors of other words that occur in the same contexts (Bengio et al., 2003). Skip-Gram (Mikolov et al., 2013), one of the most popular word embedding models, operationalizes this approach by sliding a window of a pre-specified size across the corpus. At each step, the center word is used to predict the probability of one of the surrounding words, sampled proportionally to the distance to the center word. Le and Mikolov (2014) later expanded this approach with two Paragraph2Vec models that also learn representations for paragraphs (or, more broadly, any sequence of words): (i) PV-dm, tries to predict the center word of the sliding window, given the surrounding words and the paragraph (i.", "startOffset": 206, "endOffset": 581}, {"referenceID": 0, "context": "by Amir et al. (2016), using only the previous posts from a user, were shown to capture latent user aspects (e.", "startOffset": 3, "endOffset": 22}, {"referenceID": 0, "context": "by Amir et al. (2016), using only the previous posts from a user, were shown to capture latent user aspects (e.g. political leanings) and a soft notion of \u2018homophily\u2019 \u2014 similar users were generally represented with similar vectors. Furthermore, these user representations were successfully used to improve a downstream model for sarcasm detection in tweets. Similarly, Yu et al. (2016) used user embeddings to improve a microblog recommendation system.", "startOffset": 3, "endOffset": 386}, {"referenceID": 0, "context": "To learn user embeddings, we adopted an approach similar to that recently proposed by Amir et al. (2016). The idea is to capture relations between users and the content (i.", "startOffset": 86, "endOffset": 105}, {"referenceID": 33, "context": "By learning to discriminate between observed positive examples and pseudo-negative examples, the model shifts probability mass to more plausible observations (Smith and Eisner, 2005).", "startOffset": 158, "endOffset": 182}, {"referenceID": 0, "context": "This formulation is a simplification of Amir et al. (2016) model.", "startOffset": 40, "endOffset": 59}, {"referenceID": 28, "context": "Next, we pre-trained a set of SkipGram word vectors from the task data and another large unlabeled Twitter corpus, using the Gensim7 python package (\u0158eh\u030au\u0159ek and Sojka, 2010).", "startOffset": 148, "endOffset": 174}, {"referenceID": 25, "context": "This aligns with prior work showing that one\u2019s choice of words can be indicative of psychological states and mental health (Pennebaker et al., 2001).", "startOffset": 123, "endOffset": 148}, {"referenceID": 1, "context": "But generic features estimated from unsupervised tasks are suboptimal for downstream tasks (Astudillo et al., 2015).", "startOffset": 91, "endOffset": 115}, {"referenceID": 7, "context": "Neural networks, when trained endto-end, can refine generic embeddings to specific tasks by modifying their parameters during supervised training (Collobert et al., 2011).", "startOffset": 146, "endOffset": 170}, {"referenceID": 1, "context": "But generic features estimated from unsupervised tasks are suboptimal for downstream tasks (Astudillo et al., 2015). Neural networks, when trained endto-end, can refine generic embeddings to specific tasks by modifying their parameters during supervised training (Collobert et al., 2011). However, this strategy requires updating a large number of parameters, which is difficult when only small training datasets are available. The CLPysch dataset comprises 1094 labeled instances (after discarding users with fewer than 100 tweets). Given the modest size of the dataset, we adopted the Astudillo et al. (2015) Non-Linear Subspace Embedding approach, (NLSE), which is able to adapt generic representations to specific tasks with scarce labeled data.", "startOffset": 92, "endOffset": 611}, {"referenceID": 30, "context": "Similar to feed-forward networks, we can use the backpropagation algorithm (Rumelhart et al., 1988) to jointly learn task-specific embeddings and the parameters for the classification layer.", "startOffset": 75, "endOffset": 99}, {"referenceID": 5, "context": "We induced t = 100 topics using Latent Dirichlet Allocation (Blei et al., 2003), to build vectors x \u2208 {0, 1}t indicating the topics present in user\u2019s posts;", "startOffset": 60, "endOffset": 79}, {"referenceID": 6, "context": "We induced k = 1000 Brown et al. (1992) word clusters, to build vectors x \u2208 {0, 1}k mapping words in a user\u2019s posts to their respective clusters;", "startOffset": 20, "endOffset": 40}, {"referenceID": 25, "context": "This is in agreement with prior results from the field of psychology, establishing connections between word usage and mental status (Pennebaker et al., 2001).", "startOffset": 132, "endOffset": 157}], "year": 2017, "abstractText": "Mental illnesses adversely affect a significant proportion of the population worldwide. However, the methods traditionally used for estimating and characterizing the prevalence of mental health conditions are time-consuming and expensive. Consequently, best-available estimates concerning the prevalence of mental health conditions are often years out of date. Automated approaches to supplement these survey methods with broad, aggregated information derived from social media content provides a potential means for near realtime estimates at scale. These may, in turn, provide grist for supporting, evaluating and iteratively improving upon public health programs and interventions. We propose a novel model for automated mental health status quantification that incorporates user embeddings. This builds upon recent work exploring representation learning methods that induce embeddings by leveraging social media post histories. Such embeddings capture latent characteristics of individuals (e.g., political leanings) and encode a soft notion of homophily. In this paper, we investigate whether user embeddings learned from twitter post histories encode information that correlates with mental health statuses. To this end, we estimated user embeddings for a set of users known to be affected by depression and post-traumatic stress disorder (PTSD), and for a set of demographically matched \u2018control\u2019 users. We then evaluated these embeddings with respect to: (i) their ability to capture homophilic relations with respect to mental health status; and (ii) the performance of downstream mental health prediction models based on these features. Our experimental results demonstrate that the user embeddings capture similarities between users with respect to mental conditions, and are predictive of mental health.", "creator": "LaTeX with hyperref package"}}}