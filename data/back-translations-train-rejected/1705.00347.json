{"id": "1705.00347", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Apr-2017", "title": "Scalable Twin Neural Networks for Classification of Unbalanced Data", "abstract": "Learning from large datasets has been a challenge irrespective of the Machine Learning approach used. Twin Support Vector Machines (TWSVMs) have proved to be an efficient alternative to Support Vector Machine (SVM) for learning from imbalanced datasets. However, the TWSVM is unsuitable for large datasets due to the matrix inversion operations required. In this paper, we discuss a Twin Neural Network for learning from large datasets that are unbalanced, while optimizing the feature map at the same time. Our results clearly demonstrate the generalization ability and scalability obtained by the Twin Neural Network on large unbalanced datasets.", "histories": [["v1", "Sun, 30 Apr 2017 17:25:45 GMT  (359kb,D)", "http://arxiv.org/abs/1705.00347v1", "16 pages, 6 figures, 12 tables"]], "COMMENTS": "16 pages, 6 figures, 12 tables", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["himanshu pant", "jayadeva", "sumit soman", "mayank sharma"], "accepted": false, "id": "1705.00347"}, "pdf": {"name": "1705.00347.pdf", "metadata": {"source": "CRF", "title": "Scalable Twin Neural Networks for Classification of Unbalanced Data", "authors": ["Himanshu Pant", "Mayank Sharma"], "emails": ["eez142368}@ee.iitd.ac.in"], "sections": [{"heading": null, "text": "Twin Support Vector Machines (TWSVMs) have proven to be an efficient alternative to the Support Vector Machine (SVM) to learn from unbalanced datasets. However, due to the matrix inversion operations required, the TWSVM is unsuitable for large datasets. In this article we discuss a Twin Neural Network to learn from unbalanced large datasets while optimizing the function board. Our results clearly show the generalization and scalability that the Twin Neural Network achieves on large unbalanced datasets. Keywords: Twin SVM, Neural Network, Unbalanced Datasets, Large Datasets"}, {"heading": "1. Introduction", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "2. The Twin Support Vector Machine", "text": "We start by motivating the TWSVM from the classic SVM formulation, based on the inability of SVMs to efficiently classify unbalanced datasets. Consider a binary classification dataset of N samples in the dimensions X = {x (1), x (2), x (N), x (i), x (i), x (1), x (1), x (1), x (1), x (1), x (1), x (2), x (2), x (2), x (2), x (2), x (2), x (x), x (2), x (2), x, x, x, x (2), x (2), x, x, x, x, x, x, x (2), x (2), 2 (2), x (2), x (2), x, x, x, x, x, x, x, x, x, x (2), x, x (2), x (2), x (2), x (2), x (2), x, x (2), x (2, x (2), x (2), x, x (2), x, x, x (2), x, x (2), x, x (2), x, x, x (2), x (2), x (2, x (2), x, x (2), x, x (2), x (2), x (2), x (2), x (2), x, x (2), x (2), x (2), x (2, x (2), x (2), x (2), x (2), x (2), x (2), x (2), x, x (2), x (2), x (2), x (2), x, x (2), x (2), x (2), x (2), x, x (2), x (2), x (2), x, x (2), x (2), x (2), x (2), x, x ("}, {"heading": "3. The Twin Neural Network Formulation", "text": "We consider a three-layered neural network to motivate the formulation of the Twin Neural Network (i) \u2212 b = b (b) (b) (Figure 1, the structure of which is described as follows. The input layer takes the training samples x (i), i = 1, 2,... \u2212 \u2212 n and transforms them into a space \u03c6 (\u00b7 b) by the neurons of the hidden layer. The last or initial level of this network learns a classifier in the trait space designated by bias (\u00b7) \u2212 \u2212 \u2212 n and the classifier hyperplane coefficients (weight vector w and bias b are used to predict a test sample. In the case of an unbalanced dataset, we propose the formulation of a Twin Neural Network in which two such networks are trained, the error functions of which are designated by E (+ 1) and E (\u2212 1)."}, {"heading": "4. Experiments and Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Results on UCI datasets", "text": "The Twin NN was tested on 20 benchmark datasets drawn from the UCI Reference Repository for Machine Learning [1], which included two class and multi-class datasets. Input characteristics were scaled to lie between -1 and 1, target values were kept at + 1 and -1 for each class, and a one-on-one approach was used for multi-class problems [3, pp. 182, 338], using as many baseline neurons as the number of classes to get these results, the number of neurons in the hidden layer and hyperparameters were optimized by using a grid search, and the K-Nearest Neighbor (KNN) imputation method was used to handle missing attribute values because it is robust against bias between classes in the datasets."}, {"heading": "4.2. Results on highly unbalanced datasets", "text": "The key advantage obtained by using the Twin NN is its better generalization for unbalanced datasets = four measurements. To establish this, we evaluate the Twin NN on several unbalanced datasets [9, 13, 6], which are summarized in Table 3. It can be noted here that the class imbalance in these datasets was introduced by treating the multi-class datasets as separate binary datasets. (N \u2212 1) \u00b7 M Each of these possible datasets was used as a \"GenN\" suffixed to the dataset names in Table 3, where N is the corresponding class w.r.t., which imbalance in the dataset was created. The method for calculating accuracy is used in Fig. 3.For evaluating the performance of the Twin NN on unbalanced datasets, we often use measurements other than measurements."}, {"heading": "4.3. Experiments on scalability", "text": "We analyze the scalability of the Twin NN on the Forest Covertype dataset described in Table 10. The dataset with generated imbalance has an imbalance ratio of 1: 211, with 44 numerical and 10 categorical attributes. Performance parameters for this case were presented in Table 11 for various training samples, and the corresponding training time was shown in Table 12. These are also shown in Fig 6. It is evident that the Twin NN is well scaled compared to the other methods and also trains in tractable time, with an increase in training samples. This determines the scalability of the Twin NN to unbalanced datasets."}, {"heading": "5. Conclusion and Future Work", "text": "This paper presented the Twin Neural Network, which provides a neural network training algorithm that minimizes the complexity of the machine in terms of the VC dimension and overcomes the scalability problem of the Twin SVM. It has been shown that the Twin NN performs better on multiple datasets, especially in the case of unbalanced datasets."}, {"heading": "Acknowledgements", "text": "The author would like to acknowledge the support of the Microsoft Chair Professor Project Grant (MI01158, IIT Delhi)."}], "references": [{"title": "Feed-forward neural networks", "author": ["George Bebis", "Michael Georgiopoulos"], "venue": "Potentials, IEEE,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1994}, {"title": "Pattern recognition and machine learning", "author": ["Christopher M Bishop"], "venue": "springer,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "A tutorial on support vector machines for pattern recognition", "author": ["Christopher JC Burges"], "venue": "Data mining and knowledge discovery,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1998}, {"title": "Libsvm: A library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Diversified ensemble classifiers for highly imbalanced data learning and their application in bioinformatics", "author": ["Zejin Ding"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "The use of ranks to avoid the assumption of normality implicit in the analysis of variance", "author": ["Milton Friedman"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1937}, {"title": "Twin Support Vector Machines for pattern classification", "author": ["Jayadeva", "R. Khemchandani", "S. Chandra"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Machine learning for the detection of oil spills in satellite radar images", "author": ["Miroslav Kubat", "Robert C Holte", "Stan Matwin"], "venue": "Machine learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "Statistical learning theory", "author": ["Vladimir N Vapnik"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "Individual comparisons by ranking methods", "author": ["Frank Wilcoxon"], "venue": "Biometrics bulletin,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1945}, {"title": "Comparative evaluation of pattern recognition techniques for detection of microcalcifications in mammography", "author": ["Kevin S Woods", "Chiristopher C Doss", "Kevin W Bowyer", "Jeffrey L Solka", "Carey E Priebe", "W Philip Kegelmeyer JR"], "venue": "International Journal of Pattern Recognition and Artificial Intelligence,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1993}], "referenceMentions": [{"referenceID": 2, "context": "However, the SVM may not be the optimal choice for a classifier as its complexity in terms of the VapnikChevronenkis (VC) dimension may be unbounded or infinite, as stated by Burges [4].", "startOffset": 182, "endOffset": 185}, {"referenceID": 6, "context": "The Twin SVM [8] (TWSVM) has been a derivative of the SVM (motivated by the Generalized Eigenvalue Proximal SVM - GEPSVM) which addresses the problem of class imbalance that arises in many practical applications, including multi-class scenarios.", "startOffset": 13, "endOffset": 16}, {"referenceID": 2, "context": "Drawing from Burges\u2019s tutorial [4], the VC dimension \u03b3 of a classifier with margin d \u2265 dmin is bounded by [10] \u03b3 \u2264 1 + min( R 2 dmin , n) (18)", "startOffset": 31, "endOffset": 34}, {"referenceID": 8, "context": "Drawing from Burges\u2019s tutorial [4], the VC dimension \u03b3 of a classifier with margin d \u2265 dmin is bounded by [10] \u03b3 \u2264 1 + min( R 2 dmin , n) (18)", "startOffset": 106, "endOffset": 110}, {"referenceID": 3, "context": "The accuracies were compared with the standard SVM [5], Twin SVM and Regularized Feed-Forward Neural Networks (RFNN) [2].", "startOffset": 51, "endOffset": 54}, {"referenceID": 0, "context": "The accuracies were compared with the standard SVM [5], Twin SVM and Regularized Feed-Forward Neural Networks (RFNN) [2].", "startOffset": 117, "endOffset": 120}, {"referenceID": 9, "context": "other approaches in terms of p-values determined using Wilcoxon\u2019s signed ranks test [12].", "startOffset": 84, "endOffset": 88}, {"referenceID": 5, "context": "To verify that the results on the UCI datasets are independent of the randomization due to the data distribution across folds, we also performed the Friedman\u2019s test [7].", "startOffset": 165, "endOffset": 168}, {"referenceID": 7, "context": "To establish this, we evaluate the Twin NN on several unbalanced datasets [9, 13, 6], which", "startOffset": 74, "endOffset": 84}, {"referenceID": 10, "context": "To establish this, we evaluate the Twin NN on several unbalanced datasets [9, 13, 6], which", "startOffset": 74, "endOffset": 84}, {"referenceID": 4, "context": "To establish this, we evaluate the Twin NN on several unbalanced datasets [9, 13, 6], which", "startOffset": 74, "endOffset": 84}], "year": 2017, "abstractText": "Learning from large datasets has been a challenge irrespective of the Machine Learning approach used. Twin Support Vector Machines (TWSVMs) have proved to be an efficient alternative to Support Vector Machine (SVM) for learning from imbalanced datasets. However, the TWSVM is unsuitable for large datasets due to the matrix inversion operations required. In this paper, we discuss a Twin Neural Network for learning from large datasets that are unbalanced, while optimizing the feature map at the same time. Our results clearly demonstrate the generalization ability and scalability obtained by the Twin Neural Network on large unbalanced datasets.", "creator": "LaTeX with hyperref package"}}}