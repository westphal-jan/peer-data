{"id": "1705.00534", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Apr-2017", "title": "Single image depth estimation by dilated deep residual convolutional neural network and soft-weight-sum inference", "abstract": "This paper proposes a new residual convolutional neural network (CNN) architecture for single image depth estimation. Compared with existing deep CNN based methods, our method achieves much better results with fewer training examples and model parameters. The advantages of our method come from the usage of dilated convolution, skip connection architecture and soft-weight-sum inference. Experimental evaluation on the NYU Depth V2 dataset shows that our method outperforms other state-of-the-art methods by a margin.", "histories": [["v1", "Thu, 27 Apr 2017 06:07:05 GMT  (1068kb,D)", "http://arxiv.org/abs/1705.00534v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["bo li", "yuchao dai", "huahui chen", "mingyi he"], "accepted": false, "id": "1705.00534"}, "pdf": {"name": "1705.00534.pdf", "metadata": {"source": "CRF", "title": "SINGLE IMAGE DEPTH ESTIMATION BY DILATED DEEP RESIDUAL CONVOLUTIONAL NEURAL NETWORK AND SOFT-WEIGHT-SUM INFERENCE", "authors": ["Bo Li", "Yuchao Dai", "Huahui Chen", "Mingyi He"], "emails": ["libo.npu@gmail.com"], "sections": [{"heading": "1. INTRODUCTION", "text": "Recently, considerable efforts have been made to apply a deep revolutionary neural network (CNN) to this problem, and excellent results have been achieved [1-5]. Li et al. [1] predicted the depth and surface characteristics of a color image by regressing to deep CNN characteristics in a patch-based framework. Liu et al. [2] proposed a combined CRF-CNN learning framework. Wang et al. [3] proposed a CNN architecture for common semantic labeling and depth prediction. Recent work has shown that the depth estimation problem could benefit from a better CNN architectural design. Eigen et al. [4] proposed a multi-scale architecture that first predicts a rough global output and then refines it using finely scaled local networks."}, {"heading": "2. NETWORK ARCHITECTURE", "text": "Our CNN architecture is illustrated in Fig. 1, in which the weights are initialized from a pre-trained 152 layers residual layer CNN [7]. The original network [7] was specifically designed for the problem of image classification. In this work, we transform it so that it is suitable for our depth estimation. First, we remove all layers that are fully connected to each other. In this way, we significantly reduce the number of model parameters, since more than 80% of the parameters lie in the layers that are fully connected to each other [4]. Although both [4] and [5] the layers are fully conserved for context information, our experiments show that it is unnecessary in our network for the use of dictated constellations. Second, we use the conditioned confusion that could expand the receptive field of neurons without increasing the parameters."}, {"heading": "3. SOFT-WEIGHT-SUM INFERENCE", "text": "We reformulate the depth estimation as a classification task by discretizing the depth value in the logspace as well as [5]. Specifically, we train our network with the multinomial logistic loss E = \u2212 1N \u2211 N n = 1 log (p n k) followed by softmaxpi = exp xi \u2211 mi \u2032 = 1 exp x i \u2032. Here, N is the number of training units, k is the corresponding designation of the sample n, m is the number of containers. A typical predicted point distribution is given in Fig. 2a, where the non-zero value is centralized. Fig is the confusion matrix on the test set, which represents a kind of diagonal dominant structure. In Table 1, we give the pixel-by-pixel accuracy and the relative error (Rel) with respect to the different number of discretization containers. These statistical results show that although the model cannot distinguish the detailed depth well, it nevertheless learns the right concept of depth."}, {"heading": "4. EXPERIMENTS", "text": "The raw dataset consists of 464 scenes recorded with a Microsoft Kinect, the official split consists of 249 training and 215 test scenes. The implementation of frames from each training sequence results in approximately 12k unique images. After offline augmentation, our dataset consists of approximately 48k RGB-D image pairs. Implementation Details: Our implementation is based on the CNN toolbox: caffe [9] with an NVIDIA Tizian X GPU. The proposed network is supported by the use of stochastic gradients with the batch size of 3 (This size is too small, so we average the gradient of 5 iterations for a back propagation), dynamics of 0.9, and weight decay of 0.004."}, {"heading": "5. CONCLUSION", "text": "A customized architecture of deep convolutionary neural networks is proposed for estimating the single image depth. We also propose soft weight sum inference instead of the hard threshold method. Experimental results show that our proposed method performs better than other state-of-the-art methods of the NYU Depth V2 dataset."}, {"heading": "6. REFERENCES", "text": "[1] Bo Li, Chunhua Shen, Yuchao Dai, A. van den Hengel, and Mingyi He, \"Depth and Superficial Normal Estimation of Monocular Images Using Regression to Deep Characteristics and Hierarchical Crfs,\" in: CVPR, June 2015, pp. 1119-1127. [2] Fayao Liu, Chunhua Shen, Guosheng Lin, and Ian Reid, \"Depth of Learning from Single Monocular Images Using Deep Constitutional Neural Fields,\" TPAMI, Volume 38, No. 10, pp. 2024-2039, 2016. [3] Peng Wang, Xiaohui Shen, Zhe Lin, Scott Cohen, and Alan L Yuille, \"Towards Unified Depth and Semantic Prediction from a Single Image, p. 38, pp. 7fenf., p. Janzog., pp. 2800-2809. [4] David Eigen and Rob Ziushmonus,\" Predicting, p. Yand surface, normal."}], "references": [{"title": "Depth and surface normal estimation from monocular images using regression on deep features and hierarchical crfs", "author": ["Bo Li", "Chunhua Shen", "Yuchao Dai", "A. van den Hengel", "Mingyi He"], "venue": "CVPR, jun 2015, pp. 1119\u2013 1127.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning depth from single monocular images using deep convolutional neural fields", "author": ["Fayao Liu", "Chunhua Shen", "Guosheng Lin", "Ian Reid"], "venue": "TPAMI, vol. 38, no. 10, pp. 2024\u20132039, 2016.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2024}, {"title": "Towards unified depth and semantic prediction from a single image", "author": ["Peng Wang", "Xiaohui Shen", "Zhe Lin", "Scott Cohen", "Brian Price", "Alan L Yuille"], "venue": "CVPR, 2015, pp. 2800\u20132809.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture", "author": ["David Eigen", "Rob Fergus"], "venue": "ICCV, 2015, pp. 2650\u2013 2658.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Estimating depth from monocular images as classification using deep fully convolutional residual networks", "author": ["Yuanzhouhan Cao", "Zifeng Wu", "Chunhua Shen"], "venue": "[Online]. Avaliable: https://arxiv.org/abs/1605.02305, 2016.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "Indoor segmentation and support inference from rgbd images", "author": ["Nathan Silberman", "Derek Hoiem", "Pushmeet Kohli", "Rob Fergus"], "venue": "ECCV, 2012, pp. 746\u2013760.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep residual learning for image recognition", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": "CVPR, 2016, pp. 770\u2013778.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "Multi-scale context aggregation by dilated convolutions", "author": ["Fisher Yu", "Vladlen Koltun"], "venue": "ICLR, 2016, pp. 1\u201310.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Yangqing Jia", "Evan Shelhamer", "Jeff Donahue", "Sergey Karayev", "Jonathan Long", "Ross Girshick", "Sergio Guadarrama", "Trevor Darrell"], "venue": "Proc. ACM Int. Conf. Multimedia, 2014, pp. 675\u2013678.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1\u20135].", "startOffset": 161, "endOffset": 166}, {"referenceID": 1, "context": "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1\u20135].", "startOffset": 161, "endOffset": 166}, {"referenceID": 2, "context": "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1\u20135].", "startOffset": 161, "endOffset": 166}, {"referenceID": 3, "context": "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1\u20135].", "startOffset": 161, "endOffset": 166}, {"referenceID": 4, "context": "Recently, there have been considerable efforts in applying deep convolutional neural network (CNN) to this problem and excellent performances have been achieved [1\u20135].", "startOffset": 161, "endOffset": 166}, {"referenceID": 0, "context": "[1] predicted the depth and surface normals from a color image by regression on deep CNN features in a patchbased framework.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] proposed a CRF-CNN combined learning framework.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] proposed a CNN architecture for joint semantic labeling and depth prediction.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] proposed a multi-scale architecture that first predicts a coarse global output and then refines it using finer-scale local networks.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] demonstrated that formulating depth estimation as a classification task is better than direct regression.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "At last, we conduct evaluations on widly used NYU Depth V2 dataset [6], and outperforms other state-of-the-art methods by a margin.", "startOffset": 67, "endOffset": 70}, {"referenceID": 6, "context": "1, in which the weights are initialized from a pre-trained 152 layers residual CNN [7].", "startOffset": 83, "endOffset": 86}, {"referenceID": 6, "context": "The original network [7] was specially designed for image classification problem.", "startOffset": 21, "endOffset": 24}, {"referenceID": 3, "context": "In this way, we greatly reduce the number of model parameters as more than 80% of the parameters are in the fully connect layers [4, 5].", "startOffset": 129, "endOffset": 135}, {"referenceID": 4, "context": "In this way, we greatly reduce the number of model parameters as more than 80% of the parameters are in the fully connect layers [4, 5].", "startOffset": 129, "endOffset": 135}, {"referenceID": 3, "context": "Although, both [4] and [5] preserved the fully connect layers for long range context information, our experiments show that it is unnecessary in our network for the usage of dilated convolution.", "startOffset": 15, "endOffset": 18}, {"referenceID": 4, "context": "Although, both [4] and [5] preserved the fully connect layers for long range context information, our experiments show that it is unnecessary in our network for the usage of dilated convolution.", "startOffset": 23, "endOffset": 26}, {"referenceID": 7, "context": "[8].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "The detail of the basic residual block could be refer to [7].", "startOffset": 57, "endOffset": 60}, {"referenceID": 4, "context": "We reformulate depth estimation as classification task by equally discretizing the depth value in log space as [5].", "startOffset": 111, "endOffset": 114}, {"referenceID": 5, "context": "We test our method on the widely used NYU V2 dataset [6].", "startOffset": 53, "endOffset": 56}, {"referenceID": 8, "context": "Implementation details: Our implementation is based on the CNN toolbox: caffe [9] with an NVIDIA Titian X GPU.", "startOffset": 78, "endOffset": 81}, {"referenceID": 6, "context": "initialized by the pre-trained model from [7].", "startOffset": 42, "endOffset": 45}, {"referenceID": 0, "context": "[1] 795 60M 62.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] 795 130M 65.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] 795 - 60.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] 240k 200M 76.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] 240k 350M 80.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1]", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Ours hard Ours soft", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "This paper proposes a new residual convolutional neural network (CNN) architecture for single image depth estimation. Compared with existing deep CNN based methods, our method achieves much better results with fewer training examples and model parameters. The advantages of our method come from the usage of dilated convolution, skip connection architecture and soft-weight-sum inference. Experimental evaluation on the NYU Depth V2 dataset shows that our method outperforms other state-of-the-art methods by a margin.", "creator": "LaTeX with hyperref package"}}}