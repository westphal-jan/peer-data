{"id": "1705.00561", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-May-2017", "title": "WebAPIRec: Recommending Web APIs to Software Projects via Personalized Ranking", "abstract": "Application programming interfaces (APIs) offer a plethora of functionalities for developers to reuse without reinventing the wheel. Identifying the appropriate APIs given a project requirement is critical for the success of a project, as many functionalities can be reused to achieve faster development. However, the massive number of APIs would often hinder the developers' ability to quickly find the right APIs. In this light, we propose a new, automated approach called WebAPIRec that takes as input a project profile and outputs a ranked list of {web} APIs that can be used to implement the project. At its heart, WebAPIRec employs a personalized ranking model that ranks web APIs specific (personalized) to a project. Based on the historical data of {web} API usages, WebAPIRec learns a model that minimizes the incorrect ordering of web APIs, i.e., when a used {web} API is ranked lower than an unused (or a not-yet-used) web API. We have evaluated our approach on a dataset comprising 9,883 web APIs and 4,315 web application projects from ProgrammableWeb with promising results. For 84.0% of the projects, WebAPIRec is able to successfully return correct APIs that are used to implement the projects in the top-5 positions. This is substantially better than the recommendations provided by ProgrammableWeb's native search functionality. WebAPIRec also outperforms McMillan et al.'s application search engine and popularity-based recommendation.", "histories": [["v1", "Mon, 1 May 2017 15:28:20 GMT  (335kb,D)", "http://arxiv.org/abs/1705.00561v1", "IEEE Transactions on Emerging Topics in Computational Intelligence, 2017"]], "COMMENTS": "IEEE Transactions on Emerging Topics in Computational Intelligence, 2017", "reviews": [], "SUBJECTS": "cs.IR cs.AI cs.SE", "authors": ["ferdian thung", "richard j oentaryo", "david lo", "yuan tian"], "accepted": false, "id": "1705.00561"}, "pdf": {"name": "1705.00561.pdf", "metadata": {"source": "CRF", "title": "WebAPIRec: Recommending Web APIs to Software Projects via Personalized Ranking", "authors": ["Ferdian Thung", "Richard J. Oentaryo", "David Lo", "Yuan Tian"], "emails": ["yuan.tian.2012}@smu.edu.sg"], "sections": [{"heading": null, "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they live."}, {"heading": "II. PRELIMINARIES", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. ProgrammableWeb Dataset", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to live, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they live."}, {"heading": "III. API RECOMMENDATION SYSTEM", "text": "The architecture of WebAPIRec is outlined in Figure 1. It takes as input: a new project profile, a set of API profiles and a set of past projects. From the new project profile and each API profile, WebAPIRec takes its textual descriptions and keywords. From each past project, WebAPIRec takes its textual descriptions, keywords and APIs that were used. WebAPIRec analyzes these inputs and eventually produces a ranking of APIs that are recommended for the target project. WebAPIRec has two operational phases: training phase and deployment phase. In the earlier phase, WebAPIRec takes as input a set of API profiles and a set of past projects that use them. It then learns a personalized ranking model ranking model (see Section IV), it takes as input the new project profile, a set of API profiles and a set of web profiles that use them."}, {"heading": "IV. PERSONALIZED RANKING", "text": "WebAPIRec presents the API recommendation problem as a personalized ranking task. Within the framework of this formulation, our goal is to provide a ranking of APIs that are specific (i.e. personalized) to each project. Specifically, we consider the setting in which WebAPIRec takes as input a set of training triples (p, a, a) in which p is a feature vector of a project, a feature vector of an API library used in p, and a \u2032 a feature vector of an API that is not used in p. Based on these training triples, a personalized ranking model learns how APIs are evaluated for a target project by sharing their feature vectors."}, {"heading": "A. Notation and Desiderata", "text": "Let P be the totality of all software projects and A the totality of all Web APIs. Accordingly, the task of recommendation is to complete a specific project p-P with an overall order > p of all APIs a-A. Essentially, a solid ranking > p requires several criteria: a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a \"a\" a) a) a) a) a) a) a) a) a) a \"p\" a \"a\" a) a) a) a) a \"a\" a \"a\" (3) a) a) a) a \"a) a) a) a) a) a) a) a) a\" p \"a\" a \"a\" a \"(3) a) a\" c \"a) a) a (i.e. a) a) a) a (a) a) a\" a) a \"a\" a) a) a) a) a \"a\" a \"a\" a \"a\" a \"a\" a \"c\" (5) - (3) a) c \"a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a (a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a) a (a) a) a) a) a) a) a) a) a (a) a) a) a) a) a) a) a) a) a) a) a (a) a) a) a) a) a) a (a) a) a) a) a) a) a (a) a) a) a) a) a) a) a) a) a) a) a (a) a) a) a (a) a) a) a) a) a) a) a ("}, {"heading": "B. Ranking Model", "text": "Our personalized ranking model calculates a compatibility score between a project p and an API a. Specifically, our model defines for each (p, a) pair the compatibility score f (p, a) as a weighted sum of J interaction characteristics: f (p, a) = J \u2211 j = 1 \u03b8jxj (p, a) (7), with each characteristic xj (p, a) quantifying a certain type of interaction between the project p and the API a, and \u03b8j being the weight parameter to be identified by the training method. More details about which characteristics we use in the recommendation task will be given later in Section V. After completing the training, we can calculate the score f (p \u2032, a) for a new project p \u2032 based on the identified weight parameters successj and feature prevj (p \u2032, a)."}, {"heading": "C. Loss Function Formulation", "text": "To solve the API recommendation task, we need to formulate the loss function that actually makes the training process of our ranking model more relevant. We define a loss function L (.) to evaluate the quality of the compatibility score f (p, a) and then find the optimal weight parameters that minimize L (p, a). As already mentioned, feature vectors with higher scores f (p, a) will actually be relevant (i.e., API a is actually used by project p), the loss should be small; otherwise, the loss should be large. In this work, we focus on a ranking loss function of the form L (y (a > p a), f (a > p a), where f (a > p a) should be a greater loss."}, {"heading": "D. Efficient Training", "text": "While the regulated loss R is strictly convex, the presence of a large number of API pairs (a, a) would cause high computational effort. In particular, a naive calculation of R (and its derivatives) would have the temporal complexity of O (n, a, D | 2) per iteration, which is square in relation to the number of training triples (p, a, a) in D. The key idea is to first rewrite the Hessian (i.e., the second derivative) of the loss function in relation to matrix vector product, and then use a special structure in the Hessian matrix for which some elements can be efficiently assembled via an order (i.e., second derivatives), whether the loss function is relevant in relation to matrix vector product or not."}, {"heading": "E. Ranking vs. Classification", "text": "Why should we use a ranking approach instead of a classification to solve the referral problem? In fact, one can use a classification method (e.g. the binary SVM classifier) to distinguish whether an API is relevant to a project or not. However, such an approach raises two main problems: First, the classification approach is based on the premise that APIs that are not used by a project are the negative instances (i.e., are not used by a project). In this case, the ranking approach models the preferability of APIs, i.e. if an API has been used by a project, 6 (i.e. a positive instance), we assume that the project either observes this API negatively or not (i.e. is not yet explored in a project), prefers instances."}, {"heading": "V. FEATURE ENGINEERING", "text": "In this section, we define attributes xj (p, a) that we use to train our personalized ranking model. We examine two sets of attributes: project attributes and API attributes."}, {"heading": "A. Project Features", "text": "To derive the characteristics of the project, we first find the top k projects whose profiles are most similar to the new project profile, and the keywords used in these top k projects are then used to measure the similarities between many projects. For two project profiles p1 and p2, we measure either the similarity of their textual descriptions or the similarity of their keywords. The detailed steps are as follows: i. similarity of the textual descriptions. To calculate the similarity between two textual descriptions, as mentioned in Section III, we first convert each textual description into a VSM feature vector, and then calculate the similarity between the two results."}, {"heading": "B. API Features", "text": "We compare profiles of different APIs with a new project profile. For each API, we calculate values that correspond to the similarity between the API profile and the new project profile. For an API a and a new project p \u00b2, we measure either the similarity of their textual descriptions or the similarity of their keywords. We consider these two similarity measures to be our API characteristics and list them in Table III. The detailed steps to calculate the similarity measures are as follows: i. Similarity of the textual descriptions. To calculate a similarity assessment between the textual descriptions of an API and a new project, we convert these textual descriptions into vectors of weights that follow similar steps when calculating the similarity of the textual descriptions between two projects in Section V-A1. We then calculate the cosmic similarity between the API and the new project characteristics as vectors."}, {"heading": "VI. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Dataset, Metrics, and Settings", "text": "In fact, most of them are able to survive on their own if they do not see themselves as able to survive on their own."}, {"heading": "B. Baseline Methods", "text": "We use the following baselines to evaluate our WebAPIRec approach: 1) Programmable Web Search Functionality. For this baseline, we type the query into the ProgrammableWeb search box and check whether the recommended APIs match the APIs that were actually used by the project. We consider three variants of this basic approach: The first variant only uses the project description (PWText), uses only the project keywords (i.e., tags) (PWKey) and both (PWText + Key). Note that we do not pre-process program input for Web input, as the developers would not do so either. In addition, ProgramableWeb could perform it internally. 2) Exemplary API. This is a customized version of McMillan et al.'s work [17]. They proposed a copy, a search engine for relevant applications, the Vlarity. In our work, we treat an API as an application and seek \"relevant applications.\""}, {"heading": "C. Key Results and Analysis", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "10% 0.756 0.818 0.618 0.610 0.540 0.673", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "20% 0.782 0.821 0.646 0.638 0.574 0.696", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "30% 0.802 0.842 0.662 0.653 0.588 0.713", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "40% 0.820 0.855 0.672 0.662 0.600 0.725", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "50% 0.831 0.865 0.680 0.671 0.608 0.734", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "60% 0.834 0.872 0.685 0.676 0.614 0.739", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "70% 0.835 0.876 0.688 0.679 0.617 0.741", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "80% 0.836 0.879 0.694 0.684 0.623 0.746", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "90% 0.840 0.880 0.697 0.687 0.626 0.750", "text": "To this end, we keep the same 10% of the data as our test set, but use different percentages of the data as a training set: 10%, 20%, 30%,..., 80%. By maintaining the same set of evaluation data, we ensure that the effects of the training size are comparable. For each percentage of the training data, we report the average performance. Table IX shows the effectiveness of WebAPIRec when we vary the training size. We note that the performance of our approach increases with the size of the training data. Furthermore, the direction of improvement between the different evaluation measures is always consistent, meaning that performance never decreases when we increase the training size. Furthermore, even if the size of the training data is only 10%, we can successfully recommend correct APIs in the top 5 positions for 75.5% of the training data."}, {"heading": "D. Threats to Validity", "text": "Threats to internal validity. It refers to experimental errors and distortions. Therefore, we have double-checked the accuracy of our code. However, there may be errors that we overlook. In addition, some APIs and projects are no longer in use in ProgrammableWeb. As mentioned in Section VI-A, we have cleaned up our record by removing these APIs and projects. We have also removed explicit mentions of API names from project descriptions. Another potential threat usually refers to project descriptions themselves. The descriptions are probably written after implementation and therefore may not reflect pre-implementation descriptions. Unfortunately, there is no public record that contains pre-implementation descriptions and APIs used."}, {"heading": "VII. RELATED WORK", "text": "It is not only a question of the way in which programs and programs are developed, but also of the way in which the \"naturalness\" of software is addressed, and of the proposed auto-completion by building a statistical language model. Kawaguchi et al. [12] and Lee et al. [15] developed tools that are able to detect code clones in real time, and these tools can also potentially be used for code auto-completions. [Chan et al.] suggested an approach to recommend API methods to recommend the textual phrases."}, {"heading": "VIII. CONCLUSION AND FUTURE WORK", "text": "We have proposed WebAPIRec, a recommendation system that uses a new project profile as input and recommends web APIs that are potentially relevant to the project. WebAPIRec achieves Hit @ 5, Hit @ 10, MAP @ 5, MAP @ 10, MAP and MRR of 0.840, 0.880, 0.697, 0.687, 0.626 and 0.750, respectively. WebAPIRec can therefore successfully recommend web APIs in top 5 positions for 84.0% of projects. We have compared WebAPIRec ProgrammableWeb's native search functionality, McMillan et al.'s application search engine [17] and popular-based recommendations. WebAPIRec is producing better and better web APIs as future work, we plan to analyze more APIs and more projects from additional data sources outside of ProgrammableWeb."}, {"heading": "ACKNOWLEDGMENT", "text": "This research was supported by the Singapore Ministry of Education (CEE) Academic Research Fund (AcRF) Tier 1 Grant."}], "references": [{"title": "Analysis of support vector machines", "author": ["S. Abe"], "venue": "Proceedings of the IEEE Workshop on Neural Networks for Signal Processing, 2002, pp. 89\u201398.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "An algorithm for the organization of information", "author": ["G.M. Adelson-Velsky", "E.M. Landis"], "venue": "Proceedings of the USSR Academy of Sciences, vol. 146, pp. 263\u2013266, 1962.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1962}, {"title": "Recommending relevant classes for bug reports using multi-objective search", "author": ["R. Almhana", "W. Mkaouer", "M. Kessentini", "A. Ouni"], "venue": "Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering. ACM, 2016, pp. 286\u2013295.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Improving identifier informativeness using part of speech information", "author": ["D. Binkley", "M. Hearn", "D. Lawrie"], "venue": "Proceedings of the Working Conference on Mining Software Repositories, 2011, pp. 203\u2013206.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "TnT: a statistical part-of-speech tagger", "author": ["T. Brants"], "venue": "Proceedings of the Conference on Applied Natural Language Processing, 2000, pp. 224\u2013 231.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2000}, {"title": "Improving IR-based traceability recovery via noun-based indexing of software artifacts", "author": ["G. Capobianco", "A.D. Lucia", "R. Oliveto", "A. Panichella", "S. Panichella"], "venue": "Journal of Software: Evolution and Process, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Searching connected API subgraph via text phrases", "author": ["W.-K. Chan", "H. Cheng", "D. Lo"], "venue": "Proceedings of the International Symposium on the Foundations of Software Engineering, 2012, p. 10.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Introduction to lattices and order", "author": ["B.A. Davey", "H.A. Priestley"], "venue": "Cambridge university press,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2002}, {"title": "Mining integration patterns of programmable ecosystem with social tags", "author": ["Y. Han", "S. Chen", "Z. Feng"], "venue": "Journal of Grid Computing, pp. 1\u201319, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "On the naturalness of software", "author": ["A. Hindle", "E.T. Barr", "Z. Su", "M. Gabel", "P.T. Devanbu"], "venue": "Proceedings of the International Conference on Software Engineering, 2012, pp. 837\u2013847.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Optimizing search engines using clickthrough data", "author": ["T. Joachims"], "venue": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2002, pp. 133\u2013142.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2002}, {"title": "SHINOBI: A tool for automatic code clone detection in the IDE", "author": ["S. Kawaguchi", "T. Yamashina", "H. Uwano", "K. Fushida", "Y. Kamei", "M. Nagura", "H. Iida"], "venue": "Proceedings of the Working Conference on Reverse Engineering, 2009, pp. 313\u2013314.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "A study on L2-loss (squared hinge-loss) multiclass SVM", "author": ["C.-P. Lee", "C.-J. Lin"], "venue": "Neural Computation, vol. 25, pp. 1302\u20131323, 2013.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Large-scale linear RankSVM", "author": ["\u2014\u2014"], "venue": "Neural Computation, vol. 26, no. 4, pp. 781\u2013817, 2014.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Instant code clone search", "author": ["M.-W. Lee", "J.-W. Roh", "S. won Hwang", "S. Kim"], "venue": "Proceedings of the International Symposium of the Foundations of Software Engineering, 2010, pp. 167\u2013176.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Exemplar: A source code search engine for finding highly relevant applications", "author": ["C. McMillan", "M. Grechanik", "D. Poshyvanyk", "C. Fu", "Q. Xie"], "venue": "IEEE Transactions on Software Engineering, vol. 38, no. 5, pp. 1069\u20131087, 2012.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in neural information processing systems, 2013, pp. 3111\u20133119.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "An algorithm for suffix stripping", "author": ["M.F. Porter"], "venue": "Readings in Information Retrieval, K. Sparck Jones and P. Willett, Eds., 1997, pp. 313\u2013316.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1997}, {"title": "An analysis of dependence on third-party libraries in open source and proprietary systems", "author": ["S. Raemaekers", "A. van Deursen", "J. Visser"], "venue": "Proceedings of the International Workshop on Software Quality and Maintainability, 2012.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Mining of massive datasets", "author": ["A. Rajaraman", "J.D. Ullman"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Retrieval from software libraries for bug localization: a comparative study of generic and composite text models", "author": ["S. Rao", "A.C. Kak"], "venue": "Proceedings of the Working Conference on Mining Software Repositories, 2011, pp. 43\u201352.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Improving code completion with program history", "author": ["R. Robbes", "M. Lanza"], "venue": "Automated Software Engineering, vol. 17, no. 2, pp. 181\u2013212, 2010.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Automatic generation of suggestions for program investigation", "author": ["M.P. Robillard"], "venue": "Proceedings of the International Symposium of the Foundations of Software Engineering, 2005, pp. 11\u201320.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2005}, {"title": "Detection of duplicate defect reports using natural language processing", "author": ["P. Runeson", "M. Alexandersson", "O. Nyholm"], "venue": "Proceedings of the International Conference on Software Engineering, 2007, pp. 499\u2013510.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "Improving bug localization using structured information retrieval", "author": ["R.K. Saha", "M. Lease", "S. Khurshid", "D.E. Perry"], "venue": "Proceedings of the International Conference on Automated Software Engineering, 2013, pp. 345\u2013355.  12", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Improvements in part-of-speech tagging with an application to german", "author": ["H. Schmid"], "venue": "Natural Language Processing Using Very Large Corpora, ser. Text, Speech and Language Processing, vol. 11. Kluwer Academic Publishers, 1999, pp. 13\u201326.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1999}, {"title": "Why so complicated? simple term filtering and weighting for location-based bug report assignment recommendation", "author": ["R. Shokripour", "J. Anvik", "Z.M. Kasirun", "S. Zamani"], "venue": "Proceedings of the Working Conference on Mining Software Repositories, 2013, pp. 2\u201311.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}, {"title": "A discriminative model approach for accurate duplicate bug report retrieval", "author": ["C. Sun", "D. Lo", "X. Wang", "J. Jiang", "S.-C. Khoo"], "venue": "Proceedings of the ACM/IEEE International Conference on Software Engineering, 2010, pp. 45\u201354.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Mining library migration graphs", "author": ["C. Teyton", "J.-R. Falleri", "X. Blanc"], "venue": "Proceedings of the Working Conference on Reverse Engineering, 2012, pp. 289\u2013298.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "Parseweb: a programmer assistant for reusing open source code on the web", "author": ["S. Thummalapenta", "T. Xie"], "venue": "Proceedings of the IEEE/ACM International Conference on Automated Software Engineering, 2007, pp. 204\u2013213.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}, {"title": "Automated library recommendation", "author": ["F. Thung", "D. Lo", "J.L. Lawall"], "venue": "Proceedings of the Working Conference on Reverse Engineering, 2013, pp. 182\u2013191.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatic recommendation of API methods from feature requests", "author": ["F. Thung", "S. Wang", "D. Lo", "J.L. Lawall"], "venue": "Proceedings of the IEEE/ACM International Conference on Automated Software Engineering, 2013, pp. 290\u2013300.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning to rank for bug report assignee recommendation", "author": ["Y. Tian", "D. Wijedasa", "D. Lo", "C. Le Gouesy"], "venue": "IEEE 24th International Conference on Program Comprehension (ICPC). IEEE, 2016, pp. 1\u2013 10.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2016}, {"title": "Featurerich part-of-speech tagging with a cyclic dependency network", "author": ["K. Toutanova", "D. Klein", "C.D. Manning", "Y. Singer"], "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology. Association for Computational Linguistics, 2003, pp. 173\u2013 180.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2003}, {"title": "Version history, similar report, and structure: Putting them together for improved bug localization", "author": ["S. Wang", "D. Lo"], "venue": "Proceedings of the International Conference on Program Comprehension, 2014, pp. 53\u201363.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2014}, {"title": "Modeling the mashup ecosystem: structure and growth", "author": ["M. Weiss", "G. Gangadharan"], "venue": "R&D Management, vol. 40, no. 1, pp. 40\u201349, 2010.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2010}, {"title": "Accurate developer recommendation for bug resolution", "author": ["X. Xia", "D. Lo", "X. Wang", "B. Zhou"], "venue": "20th working conference on Reverse engineering (WCRE). IEEE, 2013, pp. 72\u201381.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2013}, {"title": "Combining word embedding with information retrieval to recommend similar bug reports", "author": ["X. Yang", "D. Lo", "X. Xia", "L. Bao", "J. Sun"], "venue": "IEEE 27th International Software Reliability Engineering (ISSRE) Symposium on. IEEE, 2016, pp. 127\u2013137.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning to rank relevant files for bug reports using domain knowledge", "author": ["X. Ye", "R. Bunescu", "C. Liu"], "venue": "Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering. ACM, 2014, pp. 689\u2013699.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2014}, {"title": "Innovation in the programmable web: Characterizing the mashup ecosystem", "author": ["S. Yu", "C.J. Woodard"], "venue": "Proceedings of the International Conference on Service-Oriented Computing, 2009, pp. 136\u2013147.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 18, "context": "To aid their jobs, developers often use third party libraries that provide relevant functionalities through application programming interfaces (APIs) [20].", "startOffset": 150, "endOffset": 154}, {"referenceID": 39, "context": "Of course, some APIs are well known, but the majority of APIs do not enjoy such luxury [41].", "startOffset": 87, "endOffset": 91}, {"referenceID": 34, "context": "We evaluate the effectiveness of our approach in terms of Hit@N, MAP@N, MAP, and MRR, which are popular metrics for evaluating recommender systems [36], [22], [42], [26], [29], [25], [33].", "startOffset": 147, "endOffset": 151}, {"referenceID": 20, "context": "We evaluate the effectiveness of our approach in terms of Hit@N, MAP@N, MAP, and MRR, which are popular metrics for evaluating recommender systems [36], [22], [42], [26], [29], [25], [33].", "startOffset": 153, "endOffset": 157}, {"referenceID": 24, "context": "We evaluate the effectiveness of our approach in terms of Hit@N, MAP@N, MAP, and MRR, which are popular metrics for evaluating recommender systems [36], [22], [42], [26], [29], [25], [33].", "startOffset": 165, "endOffset": 169}, {"referenceID": 27, "context": "We evaluate the effectiveness of our approach in terms of Hit@N, MAP@N, MAP, and MRR, which are popular metrics for evaluating recommender systems [36], [22], [42], [26], [29], [25], [33].", "startOffset": 171, "endOffset": 175}, {"referenceID": 23, "context": "We evaluate the effectiveness of our approach in terms of Hit@N, MAP@N, MAP, and MRR, which are popular metrics for evaluating recommender systems [36], [22], [42], [26], [29], [25], [33].", "startOffset": 177, "endOffset": 181}, {"referenceID": 31, "context": "We evaluate the effectiveness of our approach in terms of Hit@N, MAP@N, MAP, and MRR, which are popular metrics for evaluating recommender systems [36], [22], [42], [26], [29], [25], [33].", "startOffset": 183, "endOffset": 187}, {"referenceID": 15, "context": "\u2019s application search engine [17] and popularity-based recommendation.", "startOffset": 29, "endOffset": 33}, {"referenceID": 25, "context": "advanced family of POS tagging algorithms is stochastic POS taggers, which consider the context of a word to decide its POS tag [27], [5], [35].", "startOffset": 128, "endOffset": 132}, {"referenceID": 4, "context": "advanced family of POS tagging algorithms is stochastic POS taggers, which consider the context of a word to decide its POS tag [27], [5], [35].", "startOffset": 134, "endOffset": 137}, {"referenceID": 33, "context": "advanced family of POS tagging algorithms is stochastic POS taggers, which consider the context of a word to decide its POS tag [27], [5], [35].", "startOffset": 139, "endOffset": 143}, {"referenceID": 33, "context": "In this work, we use the popular Stanford (stochastic) POS tagger [35], which has also been used in many software engineering studies, e.", "startOffset": 66, "endOffset": 70}, {"referenceID": 3, "context": ", [4].", "startOffset": 2, "endOffset": 5}, {"referenceID": 17, "context": "We use the Porter stemming method [19] to reduce each word to its stemmed form.", "startOffset": 34, "endOffset": 38}, {"referenceID": 19, "context": "In this work, we use the popular term frequency-inverse document frequency (tf-idf) scheme [21].", "startOffset": 91, "endOffset": 95}, {"referenceID": 5, "context": "These nouns carry more meaning than other kinds of words, as advocated in [6], [28].", "startOffset": 74, "endOffset": 77}, {"referenceID": 26, "context": "These nouns carry more meaning than other kinds of words, as advocated in [6], [28].", "startOffset": 79, "endOffset": 83}, {"referenceID": 7, "context": ", if a ranks higher than (or equal to) a\u2032 and a\u2032 ranks higher than (or equal to) a\u2032\u2032, then a ranks higher than (or equal to) a\u2032\u2032), respectively [8].", "startOffset": 144, "endOffset": 147}, {"referenceID": 13, "context": "As such, we can use second-order optimization methods (such as the Newton algorithm [14]) to train the model faster.", "startOffset": 84, "endOffset": 88}, {"referenceID": 10, "context": "It is also worth mentioning that the formulation of (12) can be viewed as a variant of the ranking support vector machine (RankSVM) [11].", "startOffset": 132, "endOffset": 136}, {"referenceID": 12, "context": "Taking the analogy to classification task, it has been previously studied [13] that using the squared hinge loss in SVM would yield better accuracy when \u03bb is large.", "startOffset": 74, "endOffset": 78}, {"referenceID": 10, "context": "The same argument applies to the ranking task, since RankSVM is ultimately equal to performing a binary classification on the pairwise feature differences \u2206xj = xj(p, a)\u2212 xj(p, a\u2032) [11].", "startOffset": 181, "endOffset": 185}, {"referenceID": 0, "context": "The reason is that the second derivative of R is always positive, that is, the Hessian matrix is positive definite [1].", "startOffset": 115, "endOffset": 118}, {"referenceID": 13, "context": "To mitigate this, we adopt an efficient truncated Newton method as described in [14].", "startOffset": 80, "endOffset": 84}, {"referenceID": 1, "context": "e, second derivatives) of the loss function in terms of matrix-vector product, and then exploit a special structure in the Hessian matrix for which some elements can be computed efficiently via an order-statistic tree [2].", "startOffset": 218, "endOffset": 221}, {"referenceID": 13, "context": "Full details can be found in [14], and are not included in this paper for brevity.", "startOffset": 29, "endOffset": 33}, {"referenceID": 34, "context": "These metrics have been used before in many previous studies [36], [22], [42], [26], [29], [25], [33], [16].", "startOffset": 61, "endOffset": 65}, {"referenceID": 20, "context": "These metrics have been used before in many previous studies [36], [22], [42], [26], [29], [25], [33], [16].", "startOffset": 67, "endOffset": 71}, {"referenceID": 24, "context": "These metrics have been used before in many previous studies [36], [22], [42], [26], [29], [25], [33], [16].", "startOffset": 79, "endOffset": 83}, {"referenceID": 27, "context": "These metrics have been used before in many previous studies [36], [22], [42], [26], [29], [25], [33], [16].", "startOffset": 85, "endOffset": 89}, {"referenceID": 23, "context": "These metrics have been used before in many previous studies [36], [22], [42], [26], [29], [25], [33], [16].", "startOffset": 91, "endOffset": 95}, {"referenceID": 31, "context": "These metrics have been used before in many previous studies [36], [22], [42], [26], [29], [25], [33], [16].", "startOffset": 97, "endOffset": 101}, {"referenceID": 15, "context": "\u2019s work [17].", "startOffset": 8, "endOffset": 12}, {"referenceID": 34, "context": "well-established in IR community and many past software engineering studies [36], [22], [42], [26], [29], [25], [33].", "startOffset": 76, "endOffset": 80}, {"referenceID": 20, "context": "well-established in IR community and many past software engineering studies [36], [22], [42], [26], [29], [25], [33].", "startOffset": 82, "endOffset": 86}, {"referenceID": 24, "context": "well-established in IR community and many past software engineering studies [36], [22], [42], [26], [29], [25], [33].", "startOffset": 94, "endOffset": 98}, {"referenceID": 27, "context": "well-established in IR community and many past software engineering studies [36], [22], [42], [26], [29], [25], [33].", "startOffset": 100, "endOffset": 104}, {"referenceID": 23, "context": "well-established in IR community and many past software engineering studies [36], [22], [42], [26], [29], [25], [33].", "startOffset": 106, "endOffset": 110}, {"referenceID": 31, "context": "well-established in IR community and many past software engineering studies [36], [22], [42], [26], [29], [25], [33].", "startOffset": 112, "endOffset": 116}, {"referenceID": 29, "context": "Thummalapenta and Xie [31] proposed an approach to recommend code snippet.", "startOffset": 22, "endOffset": 26}, {"referenceID": 21, "context": "Robbes and Lanza [23] proposed a technique that improves code auto-completion by using recorded program history.", "startOffset": 17, "endOffset": 21}, {"referenceID": 9, "context": "[10] investigated the \u201cnaturalness\u201d of software, and proposed a code auto-", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] and Lee et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] developed tools that are able to detect code clone in real time.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7] proposed an approach to recommend API methods given textual phrases.", "startOffset": 0, "endOffset": 3}, {"referenceID": 31, "context": "[33], who recommend API methods given a feature request.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[24] developed", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[30] proposed an approach that creates a library migration graph by analyzing library migrations performed by a large number of projects.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[32] devised an approach that takes as input APIs that a project uses and recommends additional relevant APIs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "Also, our work complements the work in [32], as developers can pick suitable APIs from our recommendation and put these APIs as input to the method in [32] to get additional recommendations.", "startOffset": 39, "endOffset": 43}, {"referenceID": 30, "context": "Also, our work complements the work in [32], as developers can pick suitable APIs from our recommendation and put these APIs as input to the method in [32] to get additional recommendations.", "startOffset": 151, "endOffset": 155}, {"referenceID": 8, "context": "There exist a number of studies on the ProgrammableWeb dataset [9], [37], [41].", "startOffset": 63, "endOffset": 66}, {"referenceID": 35, "context": "There exist a number of studies on the ProgrammableWeb dataset [9], [37], [41].", "startOffset": 68, "endOffset": 72}, {"referenceID": 39, "context": "There exist a number of studies on the ProgrammableWeb dataset [9], [37], [41].", "startOffset": 74, "endOffset": 78}, {"referenceID": 8, "context": "[9] analyzed whether or not networks created from APIs,", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "timization algorithm for bug localization [3].", "startOffset": 42, "endOffset": 45}, {"referenceID": 38, "context": "have defined 6 similarity functions between bug reports and source codes that encode project domain knowledge [40].", "startOffset": 110, "endOffset": 114}, {"referenceID": 32, "context": "use learning to rank approach to recommend developers for fixing issues described in bug reports [34].", "startOffset": 97, "endOffset": 101}, {"referenceID": 37, "context": "combine word embedding and traditional information retrieval approach to recommend similar bug reports [39].", "startOffset": 103, "endOffset": 107}, {"referenceID": 36, "context": "combine bug report and developer based analysis to recommend developers that should be assigned to a bug report [38].", "startOffset": 112, "endOffset": 116}, {"referenceID": 15, "context": "\u2019s application search engine [17], and popularity-based recommendation.", "startOffset": 29, "endOffset": 33}, {"referenceID": 16, "context": ", Word2Vec [18] ).", "startOffset": 11, "endOffset": 15}], "year": 2017, "abstractText": "Application programming interfaces (APIs) offer a plethora of functionalities for developers to reuse without reinventing the wheel. Identifying the appropriate APIs given a project requirement is critical for the success of a project, as many functionalities can be reused to achieve faster development. However, the massive number of APIs would often hinder the developers\u2019 ability to quickly find the right APIs. In this light, we propose a new, automated approach called WebAPIRec that takes as input a project profile and outputs a ranked list of web APIs that can be used to implement the project. At its heart, WebAPIRec employs a personalized ranking model that ranks web APIs specific (personalized) to a project. Based on the historical data of web API usages, WebAPIRec learns a model that minimizes the incorrect ordering of web APIs, i.e., when a used web API is ranked lower than an unused (or a not-yet-used) web API. We have evaluated our approach on a dataset comprising 9,883 web APIs and 4,315 web application projects from ProgrammableWeb with promising results. For 84.0% of the projects, WebAPIRec is able to successfully return correct APIs that are used to implement the projects in the top-5 positions. This is substantially better than the recommendations provided by ProgrammableWeb\u2019s native search functionality. WebAPIRec also outperforms McMillan et al.\u2019s application search engine and popularity-based recommendation.", "creator": "LaTeX with hyperref package"}}}