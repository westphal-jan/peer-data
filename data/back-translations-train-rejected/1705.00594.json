{"id": "1705.00594", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-May-2017", "title": "A System for Accessible Artificial Intelligence", "abstract": "While artificial intelligence (AI) has become widespread, many commercial AI systems are not yet accessible to individual researchers nor the general public due to the deep knowledge of the systems required to use them. We believe that AI has matured to the point where it should be an accessible technology for everyone. We present an ongoing project whose ultimate goal is to deliver an open source, user-friendly AI system that is specialized for machine learning analysis of complex data in the biomedical and health care domains. We discuss how genetic programming can aid in this endeavor, and highlight specific examples where genetic programming has automated machine learning analyses in previous projects.", "histories": [["v1", "Mon, 1 May 2017 17:11:48 GMT  (2999kb,D)", "http://arxiv.org/abs/1705.00594v1", "14 pages, 5 figures, submitted to Genetic Programming Theory and Practice 2017 workshop"], ["v2", "Thu, 10 Aug 2017 17:14:14 GMT  (2550kb,D)", "http://arxiv.org/abs/1705.00594v2", "14 pages, 5 figures, submitted to Genetic Programming Theory and Practice 2017 workshop"]], "COMMENTS": "14 pages, 5 figures, submitted to Genetic Programming Theory and Practice 2017 workshop", "reviews": [], "SUBJECTS": "cs.AI cs.HC cs.NE", "authors": ["randal s olson", "moshe sipper", "william la cava", "sharon tartarone", "steven vitale", "weixuan fu", "patryk orzechowski", "ryan j urbanowicz", "john h holmes", "jason h moore"], "accepted": false, "id": "1705.00594"}, "pdf": {"name": "1705.00594.pdf", "metadata": {"source": "CRF", "title": "A System for Accessible Artificial Intelligence", "authors": ["Randal S. Olson", "Moshe Sipper", "William La Cava", "Sharon Tartarone", "Steven Vitale", "Weixuan Fu", "John H. Holmes", "Jason H. Moore"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "A central objective of artificial intelligence (AI) is the use of hardware and software to solve complex problems in a way that is competitive with humans [9]. The practical implementation of this goal is that one can be entrusted with solving problems or carrying out actions that people do not have time for. Most of them can be summarized in the top-down approaches, perceptions being seen as a high-level phenomenon independent of the fact that it is an approach in which basic computer-aided building blocks exist, such as artificial neurons, which collectively lead to an \"emerge up.\""}, {"heading": "2 The Human Engine", "text": "The most important component of the proposed AI system is the user. Contrary to some claims that AI will replace the human user, we see humans as an integral part of the discovery process and as partners of AI. One way to view this partnership is with humans as drivers of the discovery process and AI as assistants of data science. Therefore, AI offers an additional set of hands in a modern data science discovery environment that could include human teammates with expertise in computer science, statistics and applied mathematics. We have previously proposed this idea of human-computer interaction that puts the human user at the epicenter [22]. This idea has also been explored from the perspective of the user or domain expert [16]. Langley [16] offers five key tips that are relevant for thinking about the relationship between humans and AI for data mining."}, {"heading": "3 The Human-Computer Interaction Engine", "text": "As described above, a key component of PennAI is the human-computer interaction. The first important feature is to make it easier for the user to start machine learning analytics directly by selecting a method and its parameter settings from an intuitive keyboard menu implemented over the Web using JavaScript. Users can start individual analyses or, in advanced mode, launch a grid search using multiple methods and parameter settings, the methods and controllers that track these analyses are described below. Figures 3 and 4 show mockups of our GUI to view and view data sets to analyze or start machine learning analyses on these datasets. Our JavaScript implementation is compatible with mobile devices, allowing the user to interact with the AI system from any Internet-connected device. PennAI's second key feature is the ability to turn AI on and off for automated analyses."}, {"heading": "4 The Machine Learning Engine", "text": "Our first application of PennAI is for machine learning data mining in the biomedical domain. Here we use an extensive open source library in Python called scikit-learn [28]. Scikit-learn offers peer review implementations of several common monitored and unmonitored machine learning algorithms, data preprocessing methods, feature engineering and selection methods, hyperparameter optimization procedures and much more. To simplify the algorithm selection process for PennAI users, we currently limit PennAI to six machine learning algorithms, preprocessors, etc., which we can select in Scikit-Learning by limiting the algorithm selection process for PennAI users to six machine learning algorithms that we believe handle the most monitored classification applications presented in Table 1."}, {"heading": "5 The Controller Engine", "text": "The Controller Engine acts as an interface between the supercomputer system and the user or AI. This component is hidden from the user, but allows the automatic start of jobs on a multi-CPU computer, computing cluster or cloud computing system. The controller must not only coordinate the start of jobs, but also track when they finish and store the results in the Graph Database Engine (as described below), which serves as the system's memory. For the Controller Engine, we chose an open source package called Future Gadget Lab (FGLab), which is available on GitHub1. FGLab functions as a server with single runs that are started as clients, called FGMachines. FGLab uses node.js to coordinate distributed jobs and uses MongoDB [3] as a backend database in the Graph Database Engine."}, {"heading": "6 The Graph Database Engine", "text": "Another key component of PennAI is a storage system that tracks every analysis that is performed on each data set. We keep track of the details of the machine learning method, parameter settings, the data set analyzed, and the results such as model, model error, and range under the receiver characteristic curve (AUC), all of which are stored in a JSON file that is stored in a NoSQL database of MongoDB. The advantage of using a NoSQL database is that new 1FGLab: https: / github.com / Kaixhin / FGLabdata elements can be added without creating tables and without strict formats. This flexibility is important for the rapidly changing landscape of machine learning. MongoDB can also function as a graph database linking the documents in a network according to common index conditions associated with the analysis and data. \"This feature facilitates the highest level of precision retrieval queries, such as the highest accuracy of each data base."}, {"heading": "6.1 Knowledge Base", "text": "The Graph Database Engine acts as PennAI's memory and provides the raw material for the AI to find out which methods and parameter settings work better than others on certain issues. Initial knowledge base consists of results from a previously published benchmark for scikit learning algorithms [24], in which 14 machine learning algorithms with full hyperparameter optimization were executed on a series of 165 monitored classification problems. Results are combined with meta-information about the data sets (e.g. number of features, number of instances, correlations between features, etc.) to create a mapping from the \"problem instance space,\" i.e. meta-characteristics of the data sets and model performance, to \"learning space,\" i.e. machine learning algorithms and their parameters, which data can then be modeled to extract rules that represent the knowledge used by the Artificial Intelligence Engine to perform knowledge analysis in the future."}, {"heading": "7 The Artificial Intelligence Engine", "text": "Each component described above provides the raw materials for the Artificial Intelligence Engine, which then 1) scans the graph database for results related to one or more sets of data, 2) performs statistical analysis and compares algorithms and their parameters, 3) combines facts and rules in an expert system to create new analysis recommendations, 4) delivers results to the user, and 5) automatically performs new analysis using suggestions from the expert system. The first function uses the search functions of the MongoDB graph database to identify relevant machine learning results in the form of JSON files. Any returned JSON files can be analyzed to extract the machine learning algorithm, parameters, and information about model performance. These results are summarized in a tab and performed statistical analysis to determine the best algorithm configurations for specific problem types, similar to how metalacquiring techniques [8] are advanced by a set of statistical rules that are made available to developers using a set of expert knowledge systems."}, {"heading": "8 The Visualization Engine", "text": "In order to foster the collaboration between humans and AI described above, visualization is critical; the user must be able to see individual machine learning models and outcomes, as well as higher-level results from statistical analysis across machine learning cycles. We extract visual results such as the curves and models for storage in the graph database, as shown in Figure 5. PennAI also generates heat maps and other visualizations that summarize the results of various machine learning methods and data sets. These higher-level visualizations help the user make decisions about new manual starting analyses and help him assess how well the PennAI wizard is doing. These images are linked to the data sets and results of the Graph Database Engine, making them easy to search."}, {"heading": "9 Discussion and Future Work", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "10 Acknowledgements", "text": "We thank Drs. Patryk Orzechowski and Ryan J. Urbanowicz for their helpful advice in the early stages of this project, which was generously funded by the Perelman School of Medicine and the University of Pennsylvania Health System of the University of Pennsylvania. Additional funding was provided by the National Institutes of Health: AI116794, DK112217, ES013508 and TR001878."}], "references": [{"title": "Bring your own learner: A cloud-based, data-parallel commons for machine learning", "author": ["I. Arnaldo", "K. Veeramachaneni", "A. Song", "U.M. O\u2019Reilly"], "venue": "IEEE Computational Intelligence Magazine", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Rule-based expert systems: the MYCIN experiments of the Stanford Heuristic Programming Project", "author": ["B. Buchanan", "E. Shortliffe"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1984}, {"title": "MongoDB: The Definitive Guide", "author": ["K. Chodorow", "M. Dirolf"], "venue": "1st edn. O\u2019Reilly Media, Inc", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Orange: Data mining toolbox in python", "author": ["J. Dem\u0161ar", "T. Curk", "A. Erjavec", "\u010crt Gorup", "T. Ho\u010devar", "M. Milutinovi\u010d", "M. Mo\u017eina", "M. Polajnar", "M. Toplak", "A. Stari\u010d", "M. \u0160tajdohar", "L. Umek", "L. \u017dagar", "J. \u017dbontar", "M. \u017ditnik", "B. Zupan"], "venue": "Journal of Machine Learning Research", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Introduction to \u201cThis is Watson", "author": ["D.A. Ferrucci"], "venue": "IBM Journal of Research and Development 56(3.4),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction", "author": ["T.J. Hastie", "R.J. Tibshirani", "J.H. Friedman"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Algorithm selection via meta-learning", "author": ["A. Kalousis"], "venue": "Ph.D. thesis, Universite de Geneve", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2002}, {"title": "Analyzing a decade of human-competitive (\u201chumie\u201d) winners: What can we learn", "author": ["K. Kannappan", "L. Spector", "M. Sipper", "T. Helmuth", "W. La Cava", "J. Wisdom", "O. Bernstein"], "venue": "Genetic Programming Theory and Practice XII,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Genetic programming: on the programming of computers by means of natural selection, vol", "author": ["J.R. Koza"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1992}, {"title": "Inference of compact nonlinear dynamic models by epigenetic local search", "author": ["W. La Cava", "K. Danai", "L. Spector"], "venue": "Engineering Applications of Artificial Intelligence 55,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Automatic identification of wind turbine models using evolutionary multiobjective optimization", "author": ["W. La Cava", "K. Danai", "L. Spector", "P. Fleming", "A. Wright", "M. Lackner"], "venue": "Renewable Energy 87,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "A general feature engineering wrapper for machine learning using -lexicase survival", "author": ["W. La Cava", "J. Moore"], "venue": "European Conference on Genetic Programming,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2017}, {"title": "Ensemble representation learning: an analysis of fitness and survival for wrapper-based genetic programming methods. In: GECCO \u201917", "author": ["W. La Cava", "J.H. Moore"], "venue": "Proceedings of the Conference on Genetic and Evolutionary Computation", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2017}, {"title": "Genetic programming representations for multi-dimensional feature learning in biomedical classification", "author": ["W. La Cava", "S. Silva", "L. Vanneschi", "L. Spector", "J. Moore"], "venue": "European Conference on the Applications of Evolutionary Computation,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2017}, {"title": "Lessons for the Computational Discovery of Scientific Knowledge", "author": ["P. Langley"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2002}, {"title": "Development and evaluation of an open-ended computational evolution system for the genetic analysis of susceptibility to common human diseases", "author": ["J.H. Moore", "P.C. Andrews", "N. Barney", "B.C. White"], "venue": "European Conference on Evolutionary Computation, Machine Learning and Data Mining in Bioinformatics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Identification of Novel Genetic Models of Glaucoma Using the \u201cEMERGENT", "author": ["J.H. Moore", "C.S. Greene", "D.P. Hill"], "venue": "Genetic Programming-Based Artificial Intelligence System,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Identification of novel genetic models of glaucoma using the emergent genetic programming-based artificial intelligence system", "author": ["J.H. Moore", "C.S. Greene", "D.P. Hill"], "venue": "Genetic Programming Theory and Practice XII,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Human- Computer Interaction in a Computational Evolution System for the Genetic Analysis of Cancer, pp. 153\u2013171", "author": ["J.H. Moore", "D.P. Hill", "J.M. Fisher", "N. Lavender", "L.C. Kidd"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Exploring Interestingness in a Computational Evolution System for the Genome-Wide Genetic Analysis of Alzheimer\u2019s Disease, pp. 31\u201345", "author": ["J.H. Moore", "D.P. Hill", "A. Saykin", "L. Shen"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Genome-wide genetic analysis using genetic programming: The critical need for expert knowledge", "author": ["J.H. Moore", "B.C. White"], "venue": "Genetic Programming Theory and Practice IV,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "Evaluation of a Tree-based Pipeline Optimization Tool for Automating Data Science", "author": ["R.S. Olson", "N. Bartley", "R.J. Urbanowicz", "J.H. Moore"], "venue": "In: GECCO 2016,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}, {"title": "Pmlb: A large benchmark suite for machine learning evaluation and comparison", "author": ["R.S. Olson", "W. La Cava", "P. Orzeshowski", "J.H. Urbanowicz Ryan J Moore"], "venue": "arXiv e-print", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2017}, {"title": "Identifying and Harnessing the Building Blocks of Machine Learning Pipelines for Sensible Initialization of a Data Science Automation Tool. arXiv e-print", "author": ["R.S. Olson", "J.H. Moore"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "TPOT: A Tree-based Pipeline Optimization Tool for Automating Machine Learning", "author": ["R.S. Olson", "J.H. Moore"], "venue": "JMLR 64,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2016}, {"title": "Applications of Evolutionary Computation: 19th European Conference, EvoApplications 2016, Porto, Portugal, March 30\u2013April 1, 2016, Proceedings, Part I, chap. Automating Biomedical Data Science Through Tree-Based Pipeline Optimization, pp. 123\u2013137", "author": ["R.S. Olson", "R.J. Urbanowicz", "P.C. Andrews", "N.A. Lavender", "L.C. Kidd", "J.H. Moore"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "Scikit-learn: Machine learning in Python", "author": ["F. Pedregosa", "G. Varoquaux", "A. Gramfort", "V. Michel", "B. Thirion", "O. Grisel", "M. Blondel", "P. Prettenhofer", "R. Weiss", "V Dubourg"], "venue": "Journal of Machine Learning Research", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2011}, {"title": "Design, observation, surprise! a test of emergence", "author": ["E.M. Ronald", "M. Sipper", "M.S. Capcarr\u00e8re"], "venue": "Artificial Life 5(3),", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1999}, {"title": "RECIPE: A Grammar-Based Framework for Automatically Evolving Classification Pipelines", "author": ["A.G. de S\u00e1", "W.J.G. Pinto", "L.O.V. Oliveira", "G.L. Pappa"], "venue": "European Conference on Genetic Programming,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2017}, {"title": "Multiclass classification through multidimensional clustering", "author": ["S. Silva", "L. Mu\u00f1oz", "L. Trujillo", "V. Ingalalli", "M. Castelli", "L. Vanneschi"], "venue": "Genetic Programming Theory and Practice XIII,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2016}, {"title": "From MEGATON to RAS- CAL: Surfing the parameter space of genetic programming (2017)", "author": ["M. Sipper", "W. Fu", "K. Ahuja", "J.H. Moore"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2017}, {"title": "Toward the automated analysis of complex diseases in genome-wide association studies using genetic programming", "author": ["A. Sohn", "R.S. Olson", "J.H. Moore"], "venue": "arXiv e-print", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2017}, {"title": "Classification of oncologic data with genetic programming", "author": ["L. Vanneschi", "F. Archetti", "M. Castelli", "I. Giordani"], "venue": "Journal of Artificial Evolution and Applications 2009,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2009}, {"title": "Multiple objective vector-based genetic programming using human-derived primitives", "author": ["J. Zutty", "D. Long", "H. Adams", "G. Bennett", "C. Baxter"], "venue": "Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2015}], "referenceMentions": [{"referenceID": 7, "context": "A central goal of artificial intelligence (AI) is to use computational hardware and software to solve complex problems in a human-competitive manner [9].", "startOffset": 149, "endOffset": 152}, {"referenceID": 27, "context": "Most AI methodologies can be grouped into top-down approaches, wherein cognition is viewed as a high-level phenomenon that is independent of the low-level details, or bottom-up approaches, which define basic computational building blocks such as artificial neurons that collectively give rise to \u201cemergent\u201d [29] intelligent behavior.", "startOffset": 307, "endOffset": 311}, {"referenceID": 8, "context": "However, the bottom-up has had some success owing to the availability of sophisticated algorithms such as genetic programming (GP) [10] and deep neural networks [6].", "startOffset": 131, "endOffset": 135}, {"referenceID": 7, "context": "This is particularly true today with abundant and inexpensive high-performance computing, leading to many human-competitive success stories [9].", "startOffset": 140, "endOffset": 143}, {"referenceID": 1, "context": "One of the early successes was the Mycin system, which was designed to predict the antibiotic that a patient with an infection should receive in the intensive care unit [2].", "startOffset": 169, "endOffset": 172}, {"referenceID": 4, "context": "Examples of modern AI successes include IBM\u2019s Watson, which beat the world champion of the game show Jeopardy [5].", "startOffset": 110, "endOffset": 113}, {"referenceID": 3, "context": "Democratization of AI will be important if we seek to integrate this exciting new technology into multiple different domains, as demonstrated by recent efforts such as Orange [4].", "startOffset": 175, "endOffset": 178}, {"referenceID": 20, "context": "We have previously suggested this idea of human-computer interaction that places the human user at the epicenter [22].", "startOffset": 113, "endOffset": 117}, {"referenceID": 14, "context": "This idea has also previously been explored from the point of view of the user or domain expert [16].", "startOffset": 96, "endOffset": 100}, {"referenceID": 14, "context": "Langley [16] provides five important tips that are relevant to thinking about the relationship humans have with AI for data mining using machine learning.", "startOffset": 8, "endOffset": 12}, {"referenceID": 14, "context": "Langley [16] further suggests that users want interactive discovery environments that help them understand their data while at the same time giving them control over the modeling process.", "startOffset": 8, "endOffset": 12}, {"referenceID": 26, "context": "Here, we make use of an extensive open-source machine learning library in Python called scikit-learn [28].", "startOffset": 101, "endOffset": 105}, {"referenceID": 5, "context": ", increasing n estimators) improves model performance but increases training time, whereas removing decision trees from the random forest decreases model performance but decreases training time [7].", "startOffset": 194, "endOffset": 197}, {"referenceID": 2, "context": "js to coordinate distributed jobs and uses MongoDB [3] as the backend database in the Graph Database Engine.", "startOffset": 51, "endOffset": 54}, {"referenceID": 22, "context": "The initial knowledge base consists of results from a previously published benchmark of scikit-learn algorithms [24], in which 14 machine learning algorithms were run with full hyperparameter optimization on a suite of 165 supervised classification problems.", "startOffset": 112, "endOffset": 116}, {"referenceID": 6, "context": "These results are collated in a tab-delimited file and a statistical analysis performed to determine the best algorithm configurations for certain problem types, similar to metalearning techniques [8].", "startOffset": 197, "endOffset": 200}, {"referenceID": 19, "context": ", [17\u2013 21, 34]).", "startOffset": 2, "endOffset": 14}, {"referenceID": 32, "context": ", [17\u2013 21, 34]).", "startOffset": 2, "endOffset": 14}, {"referenceID": 29, "context": "A GP system for classification based on multidimensional clustering [31] was recently demonstrated on biomedical classification problems [15] as a competitive alternative to traditional machine learning approaches.", "startOffset": 68, "endOffset": 72}, {"referenceID": 13, "context": "A GP system for classification based on multidimensional clustering [31] was recently demonstrated on biomedical classification problems [15] as a competitive alternative to traditional machine learning approaches.", "startOffset": 137, "endOffset": 141}, {"referenceID": 11, "context": "Recently GP has been proposed as a general feature engineering wrapper (FEW) in order to harness its feature learning capability to improve scikit-learn estimators, both for regression [13] and classification [14].", "startOffset": 185, "endOffset": 189}, {"referenceID": 12, "context": "Recently GP has been proposed as a general feature engineering wrapper (FEW) in order to harness its feature learning capability to improve scikit-learn estimators, both for regression [13] and classification [14].", "startOffset": 209, "endOffset": 213}, {"referenceID": 9, "context": "by local search [11] or Pareto optimization [12], are important options to include.", "startOffset": 16, "endOffset": 20}, {"referenceID": 10, "context": "by local search [11] or Pareto optimization [12], are important options to include.", "startOffset": 44, "endOffset": 48}, {"referenceID": 0, "context": "PennAI could then provide a \u201cbring your own learner\u201d type of service [1] to allow researchers to tackle complex data mining tasks with customized learning approaches, and incorporate the results into its knowledge base for improving future data science projects.", "startOffset": 69, "endOffset": 72}, {"referenceID": 28, "context": "Beyond using GP to perform the machine learning itself, recent work has shown that GP can also be harnessed to optimize a sequence of existing data analysis and machine learning operations on a dataset to maximize the predictive performance of the final machine learning model [30, 35].", "startOffset": 277, "endOffset": 285}, {"referenceID": 33, "context": "Beyond using GP to perform the machine learning itself, recent work has shown that GP can also be harnessed to optimize a sequence of existing data analysis and machine learning operations on a dataset to maximize the predictive performance of the final machine learning model [30, 35].", "startOffset": 277, "endOffset": 285}, {"referenceID": 23, "context": "For example, TPOT is an early prototype that uses GP to optimize a sequence of scikit-learn operations for both classification and regression problems [25\u201327], and has been shown to work quite well across a broad range of application domains ranging from epidemiological studies to image classification to time series prediction [23].", "startOffset": 151, "endOffset": 158}, {"referenceID": 24, "context": "For example, TPOT is an early prototype that uses GP to optimize a sequence of scikit-learn operations for both classification and regression problems [25\u201327], and has been shown to work quite well across a broad range of application domains ranging from epidemiological studies to image classification to time series prediction [23].", "startOffset": 151, "endOffset": 158}, {"referenceID": 25, "context": "For example, TPOT is an early prototype that uses GP to optimize a sequence of scikit-learn operations for both classification and regression problems [25\u201327], and has been shown to work quite well across a broad range of application domains ranging from epidemiological studies to image classification to time series prediction [23].", "startOffset": 151, "endOffset": 158}, {"referenceID": 21, "context": "For example, TPOT is an early prototype that uses GP to optimize a sequence of scikit-learn operations for both classification and regression problems [25\u201327], and has been shown to work quite well across a broad range of application domains ranging from epidemiological studies to image classification to time series prediction [23].", "startOffset": 329, "endOffset": 333}, {"referenceID": 31, "context": "As another example, the TPOT-MDR project [33] showed that TPOT can be specialized for genome-wide association studies (GWAS), and it outperforms several state-of-the-art modeling methods on both simulated and real-world GWAS problems because it considers a broad range of operations in with one another.", "startOffset": 41, "endOffset": 45}, {"referenceID": 30, "context": ", solve a given problem [32].", "startOffset": 24, "endOffset": 28}], "year": 2017, "abstractText": "While artificial intelligence (AI) has become widespread, many commercial AI systems are not yet accessible to individual researchers nor the general public due to the deep knowledge of the systems required to use them. We believe that AI has matured to the point where it should be an accessible technology for everyone. We present an ongoing project whose ultimate goal is to deliver an open-source, user-friendly AI system that is specialized for machine learning analysis of complex data in the biomedical and health care domains. We discuss how genetic programming can aid in this endeavor, and highlight specific examples where genetic programming has automated machine learning analyses in previous projects.", "creator": "LaTeX with hyperref package"}}}