{"id": "1705.01042", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-May-2017", "title": "Entity Linking with people entity on Wikipedia", "abstract": "This paper introduces a new model that uses named entity recognition, coreference resolution, and entity linking techniques, to approach the task of linking people entities on Wikipedia people pages to their corresponding Wikipedia pages if applicable. Our task is different from general and traditional entity linking because we are working in a limited domain, namely, people entities, and we are including pronouns as entities, whereas in the past, pronouns were never considered as entities in entity linking. We have built 2 models, both outperforms our baseline model significantly. The purpose of our project is to build a model that could be use to generate cleaner data for future entity linking tasks. Our contribution include a clean data set consisting of 50Wikipedia people pages, and 2 entity linking models, specifically tuned for this domain.", "histories": [["v1", "Tue, 2 May 2017 16:06:03 GMT  (2037kb,D)", "http://arxiv.org/abs/1705.01042v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["weiqian yan", "kanchan khurad"], "accepted": false, "id": "1705.01042"}, "pdf": {"name": "1705.01042.pdf", "metadata": {"source": "CRF", "title": "Entity linking with people entities on Wikipedia", "authors": ["Weiqian Yan", "Kanchan Khurad"], "emails": ["weiqian.yan@emory.edu", "kkhurad@emory.edu"], "sections": [{"heading": "1 Introduction", "text": "Linking entities is a developed and interesting field in research in the field of natural language processing. It has been designed to improve the performance of the information retrieval system, information aggregation and many other applications.One of the problems in the current linkage of research and teaching is the lack of data sets, and the available data sets are noisy to contribute to this lack, we have built a model that could be used to generate training data for linking tasks. The big difference between the conventional entity that systems and our model link is that our model recognizes the entities not only in a text, but also recognizes the pronouns that relate to those entities. We have manually commented Wikipedia pages to evaluate the performance of our model. We have limited our experiment to Wikipedia pages about people, and our model recognizes only the entities that address a particular person, the entities that include the pronouns that relate to those entities."}, {"heading": "2 Related Work", "text": "To our knowledge, this is the first time this task has been attempted, but there is related work for each component in our model, namely the so-called entity detection, nuclear resolution, and TagMe entity linking model.ar. Xiv: 170 5,01 042v 1 [cs.C L] 2M ay2 017 \u2022 We used Stanford's called entity detection at the mention stage of our model. Stanford's called entity detection is a linear chain of conditional random field model. The model is similar to the local + Viterbi model in [Finkel et al., 2005], but with additional distributional similarity characteristics. We use Stanford's NER to extract the names of all people in a Wikipedia page, but since we work on a limited domain, we have added command-based functions to the model. \u2022 We used Stanford's core resolution in the selection phase of our model to extract Wikipedia algorithms to link them to the Lee air resolution."}, {"heading": "3 Experiment", "text": "We have conducted experiments for each component of our system and our integrated systems. We consider it important to evaluate the performance of each component in our models to identify bottlenecks and propose future improvements, and we record recall, precision and F-1 values for all experiments in results."}, {"heading": "3.1 Data", "text": "Since this is the first time that someone has tried to do this specific task, we have not been able to find any existing data that we could use to evaluate our system. Therefore, we manually commented on 50 Wikipedia person pages, including people in sports, cooks, scientists, aristocrats, and so on. The structure of our evaluation record consists of four columns. In the first column for each of the Wikipedia pages in our test record, we have tokenized the texts so that each line of the first column contains a word / symbol, each line of the spread sheet represents a word or symbol, and in the following columns we have identified the nature of the token, i.e. if its entity or not. In the second column, we identify if the word is a person with a label \"Y\" (ordinary noun), in the third column we identify ourselves with a label \"Y\" if the word in the first column is a person and is identified in the second column."}, {"heading": "3.2 Approach", "text": "In this section we will present the baseline model we use and the models we build, the baseline model uses TagMe and the other model uses Wikipedia Search or TagMe. We will compare the performance of our model with the baseline model and report the score in the Results section."}, {"heading": "3.2.1 Baseline", "text": "The reason for this is that one aspect is a way in which people are able to determine themselves how they should behave, and how they should behave. (...) The second aspect is that people are able to determine themselves. (...) The third aspect is that people are able to determine themselves. (...) The third aspect is that they are able to determine themselves. (...) The third aspect is that people are able to determine themselves. (...) The third aspect is that people are able to determine themselves. (...) The third aspect is that they are able to determine themselves. (...) The third aspect is that they are able to determine themselves. \"(...) The third aspect is that they are able to determine themselves.\" The third aspect is that they are able to determine themselves. \"(...) The third aspect is that they are able to determine themselves.\""}, {"heading": "3.3 Results", "text": "Our model is an optimized version of the base model for mentioning detection part. We use the exact same components, with rule-based functions in our models. We have selected a limited domain, so we have made some assumptions about the data we have used to create the rule-based features. For the entity linkage we are experimenting with 2 different entity linkage mechanisms. We have performed experiments on every single component of our model compared to the base model, and also our integrated model compared to the base model. For all experiments we record recall, precision and F-1 values. The results are shown in the following table: NER Mention Detection Entity LinkingBaseline ModelP 89.6 92.2 51.7R 93.3 82.2 48.6 F 90.8 86.6 49.5Model (Wikipedia search) P 89.2 92.8 80.5R 95.3 97.0 85.9 F 91.6 94.7 Model 82.7 Tag7Me"}, {"heading": "P N/A N/A 71.9", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "R N/A N/A 80.3", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "F N/A N/A 75.5", "text": "In the table above, R stands for Recall, P for Precision and F for F1 Score. As we can see from the experiment results, our model has significantly improved performance compared to the base model. System with Wikipedia search as a linked entity has the best performance and reaches 82.7 in the F-1 score. The results we have achieved for our two models are significantly better than the base model in terms of precision, recall and F-1 score. NER in our model has good values in terms of both recall and precision, meaning that the model is able to pick up most of the person names mentioned in the Wikipedia page. Mention recognition is essentially person names and pronouns. The recovery and precision values for mentioning are very good. Therefore, our model is able to find the majority of potential mentions. For linking entities with Wikipedia search, while our model is good, Recall is not."}, {"heading": "3.4 Analysis", "text": "We analyzed the performance of our model on each sample of the test data set in Wikipedia and found the following: \u2022 The model has, in general, a better performance in modern people than old people. We think the reason for this is: In the past, there are very few first names for that person, so there are a lot of duplicate names. The only way to distinguish between these names are the titles, for example, Richard Woodville, First Earl of Rivers. It is only possible to find the right Wikipedia page for that person if his title Wikipedia is included. Including the title complicates the mention of the mention. There are several cases that should be considered for inclusion of titles. - Name of the + place: For example, Margarate of Anjou, where Anjou is a city to be found in the Wikipedia page with Wikipedia search, we have to find Margarate of Anjou, Margarate will not work because there are so many people on Wikipedia."}, {"heading": "4 Conclusion", "text": "Although there are entity-linkage systems that identify entities in a particular text, there are no entity-linkage systems that recognize pronouns as entities and link them to a Wikipedia page. Using such an entity-linkage system in information gathering and summarization should improve the overall functioning of these applications. Our contribution includes a clean dataset that consists of 50 examples of Wikipedia pages about humans and our models. We have commented 50 samples manually and linked them together for evaluation purposes. Our data cover a wide range of people, from modernity to antiquity, and cover multiple professions. Our model works better than previous successful models in NER, Coreference Resolution, and Entity Linking. Our model is an optimized version of the base model, and it is optimized and tuned for that particular area. This model would definitely help to create good datasets for educational purposes, by using this more clean linkage system for future work."}, {"heading": "5 Future Work", "text": "In fact, most people who are able to identify themselves are also able to identify themselves. Most of them are able to identify themselves. Most of them are able to identify themselves. Most of them are able to identify themselves. Most of them are not able to identify themselves. Most of them are not able to identify themselves. Most of them are able to identify themselves. Most of them are not able to identify themselves. Most of them are able to identify themselves. Most of them are able to identify themselves. Most of them are not able to identify themselves. Most of them are able to identify themselves. Most of them are able to identify themselves. Most of them are not able to identify themselves. Most of them are able to identify themselves."}], "references": [{"title": "Tagme: On-the-fly annotation of short text fragments (by wikipedia entities)", "author": ["Paolo Ferragina", "Ugo Scaiella"], "venue": null, "citeRegEx": "Ferragina and Scaiella.,? \\Q2010\\E", "shortCiteRegEx": "Ferragina and Scaiella.", "year": 2010}, {"title": "Incorporating non-local information into information extraction systems by gibbs sampling. roceedings of the 43nd Annual Meeting of the Association for Computational Linguistics", "author": ["Jenny Rose Finkel", "Trond Grenager", "Christopher Manning"], "venue": null, "citeRegEx": "Finkel et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Finkel et al\\.", "year": 2005}, {"title": "Stanford\u2019s multi-pass sieve coreference resolution system at the conll-2011", "author": ["Heeyoung Lee", "Yves Peirsman", "Angel Chang", "Nathanael Chambers", "Mihai Surdeanu", "Dan Jurafsky"], "venue": null, "citeRegEx": "Lee et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2011}, {"title": "A multi-pass sieve for coreference resolution", "author": ["Karthik Raghunathan", "Heeyoung Lee", "Sudarshan Rangarajan", "Nathanael Chambers", "Mihai Surdeanu", "Dan Jurafsky", "Christopher Manning"], "venue": null, "citeRegEx": "Raghunathan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Raghunathan et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 1, "context": "The model is similar to the baseline local+Viterbi model in [Finkel et al., 2005], but with added distributional similarity based", "startOffset": 60, "endOffset": 81}, {"referenceID": 3, "context": "] and [Raghunathan et al., 2010].", "startOffset": 6, "endOffset": 32}, {"referenceID": 0, "context": "It is introduced in [Ferragina and Scaiella, 2010] .", "startOffset": 20, "endOffset": 50}], "year": 2017, "abstractText": "This paper introduces a new model that uses named entity recognition, coreference resolution, and entity linking techniques, to approach the task of linking people entities on Wikipedia people pages to their corresponding Wikipedia pages if applicable. Our task is different from general and traditional entity linking because we are working in a limited domain, namely, people entities, and we are including pronouns as entities, whereas in the past, pronouns were never considered as entities in entity linking. We have built 2 models, both outperforms our baseline model significantly. The purpose of our project is to build a model that could be use to generate cleaner data for future entity linking tasks. Our contribution include a clean data set consisting of 50 Wikipedia people pages, and 2 entity linking models, specifically tuned for this domain.", "creator": "LaTeX with hyperref package"}}}