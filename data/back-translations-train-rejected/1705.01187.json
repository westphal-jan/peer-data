{"id": "1705.01187", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-May-2017", "title": "Towards Full Automated Drive in Urban Environments: A Demonstration in GoMentum Station, California", "abstract": "Each year, millions of motor vehicle traffic accidents all over the world cause a large number of fatalities, injuries and significant material loss. Automated Driving (AD) has potential to drastically reduce such accidents. In this work, we focus on the technical challenges that arise from AD in urban environments. We present the overall architecture of an AD system and describe in detail the perception and planning modules. The AD system, built on a modified Acura RLX, was demonstrated in a course in GoMentum Station in California. We demonstrated autonomous handling of 4 scenarios: traffic lights, cross-traffic at intersections, construction zones and pedestrians. The AD vehicle displayed safe behavior and performed consistently in repeated demonstrations with slight variations in conditions. Overall, we completed 44 runs, encompassing 110km of automated driving with only 3 cases where the driver intervened the control of the vehicle, mostly due to error in GPS positioning. Our demonstration showed that robust and consistent behavior in urban scenarios is possible, yet more investigation is necessary for full scale roll-out on public roads.", "histories": [["v1", "Tue, 2 May 2017 22:04:59 GMT  (2019kb,D)", "http://arxiv.org/abs/1705.01187v1", "Accepted to Intelligent Vehicles Conference (IV 2017)"]], "COMMENTS": "Accepted to Intelligent Vehicles Conference (IV 2017)", "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["akansel cosgun", "lichao ma", "jimmy chiu", "jiawei huang", "mahmut demir", "alexandre miranda anon", "thang lian", "hasan tafish", "samir al-stouhi"], "accepted": false, "id": "1705.01187"}, "pdf": {"name": "1705.01187.pdf", "metadata": {"source": "CRF", "title": "Towards Full Automated Drive in Urban Environments: A Demonstration in GoMentum Station, California", "authors": ["Akansel Cosgun", "Lichao Ma", "Jimmy Chiu", "Jiawei Huang", "Mahmut Demir", "Alexandre Miranda A\u00f1on", "Thang Lian", "Hasan Tafish", "Samir Al-Stouhi"], "emails": ["ACosgun@hra.com,", "MMa@hra.com,", "JChiu@hra.com,", "JHuang@hra.com,", "MDemir@hra.com,", "AMiranda@hra.com,", "TLian@hra.com", "HTafish@hra.com,", "SAlStouhi@hra.com"], "sections": [{"heading": null, "text": "According to the National Highway Traffic Safety Administration (NHTSA), there are more than 6 million accidents that have resulted in either personal injury and / or property damage, and the majority of reported crashes are a direct result of human error. Automated Drive (AD) has great potential to drastically reduce the number of accidents. In the last two decades, AD has shown great interest in the DARPA Grand and Urban Challenges [2]. Moreover, recent developments in artificial intelligence and machine learning have created a real possibility, with significant investment from automakers [4] and technology companies such as Google and Uber."}, {"heading": "III. SYSTEM OVERVIEW", "text": "The AD system includes several complex and interactive modules, and these modules can be divided into four groups, as shown in Figure 2: Sensors, Perception, Decision Making and Update.Sensor modules provide raw data for all other modules they request, with sensor-specific firmware. These modules include GPS / INS, cameras, LiDAR, V2X and other vehicle sensors. Map data is organized and served for each process that includes information from the map. Perception modules include location and detection / tracking modules, GPS data is pre-filtered, and data is backed up by localization modules. Multiple processes are used to detect and track objects, including traffic lights and vehicle detection, pedestrian and vehicle detection using computer modules."}, {"heading": "IV. PERCEPTION", "text": "In this section, we present modules for perceiving the environment. First, we describe our localization approach, which corrects lateral localization using road markings, then we present our vision and LiDAR-based pedestrian detection, followed by a radar-based vehicle tracking algorithm, then we describe our approach to obstacle detection to avoid, and finally, we discuss our use of V2P detection."}, {"heading": "A. Localization", "text": "This section describes the localization algorithm to improve lateral localization within the first-person lane. The fusion of L1-Global Positional Systems (GPS) with either inertial measurement units (IMU) or other proprioceptive sensors such as an odomoter with an Extended Kalman Filter (EKF) or Unscented Kalman Filter (UKF) is known to produce a smoother and more reliable assessment of the vehicle's pose [5] [6] than simple GPS. However, the accuracy is often insufficient for AD, especially in urban environments where GPS failures (trees, tunnels), multipath errors or distorted errors (ionospheric delay) are common. To address this problem, the researchers [8] [9] have shown that using digital maps of the lane markings in combination with a camera in front of the road."}, {"heading": "B. Pedestrian Detection & Tracking", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "D. Obstacle Detection", "text": "This year it is more than ever before in the history of the city."}, {"heading": "V. MOTION PLANNING AND CONTROL", "text": "In this section, we introduce modules related to decision-making. First, we describe our state machine, then the route planner, which is based on a graph search algorithm using nodes captured from the map. Then, we talk about behavior planning, in particular, how intersections and pedestrians are handled, and how all inputs are managed by the state machine. Then, we present our trajectory generation algorithm and conclude with a brief description of the controller."}, {"heading": "A. State Machine", "text": "We use a hierarchical state machine for level reasoning of events generated by the event handler. A visualization of the state machine is shown in Figure 4. The system has five main states: \u2022 NOT READY: state in which there is no destination \u2022 ROUTE PLAN: state in which there is no requirement to stop \u2022 STOP: state in which the car must come to a stop \u2022 ERROR: state in which the vehicle terminates its AD mode due to an error. The system starts in NOT READY state. When a user enters a destination, the state becomes ROUTE PLAN. When a plan is found, GO state is activated, the tractor scheduler is instructed to go into the current lane at a suitable speed. Every time the state machine receives an event, an evaluation is made to determine whether it raises the MUST STOP flag, PEDESTRIAN, TFL REINT or INT."}, {"heading": "B. Route Planning", "text": "We use a map that contains different levels of map information such as lane markings, roadsides, pedestrian zones, stop lines, etc. with high positioning accuracy. Depending on the application, information from different levels is used. For example, the lane markings are mainly used to navigate the vehicle, the roadways are used to filter out obstacles off the road, the stop line is used to trigger the INT event. After the map is loaded into memory, we create a directional graph consisting of lane markings, and then we use an A * search algorithm to search for a viable route for a specific start and destination position. After the route has been calculated, the Route Planning module publishes this global path to all other modules. The global path has index and 3D coordinates at each point, as well as the legal speed limit. Both index and 3D coordinates are used to locate the vehicle on the map and trigger corresponding events."}, {"heading": "C. Behavior Planning", "text": "In fact, most of them are able to play by the rules without having to play by the rules."}, {"heading": "D. Trajectory Planning", "text": "Rrf\u00fc ide eeisrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "VI. DEMONSTRATION", "text": "To test and highlight the functionality of the automated driving system, we have designed a demonstration route covering a variety of different scenarios that could occur in urban traffic. It was tested at GoMentum Station in Concord, California, on a section of road with signs, signals and road markings representative of California roads. Speed limits were set at a maximum of 35 km / h, with the vehicle calculating maximum speeds based on the specified speed limit and dynamic speed limits taking into account maximum lateral acceleration limits in the curves. For safety purposes, an engineer was present in the driver's seat during all tests to monitor the progress of the system and take control in the event of system anomalies. The total length of the demonstration route was 2.5 km and included a signaled four-lane intersection, a T-junction, two curved curves and a four-lane stop. Scenarios highlighting specific aspects and responses of the automated driving system are as follows:"}, {"heading": "A. Scenario 1: Intersection with Traffic Light", "text": "The AudiTT approaches a signposted four-lane intersection where the planned route is to turn right. Onboard cameras record the traffic light condition, which is initially green when entering the intersection. As there is a level crossing after the junction, the intersection is signposted and marked as \"No Turn On Red.\" As the AudiTT approaches, the \"Enter Intersection\" event is triggered and the FSM switches to the \"STOP\" state. If the AudiTT detects a transition to a red light, the \"TFL RED\" event is triggered. The AudiTT calculates the stop point at the intersection where the \"TFL GREEN\" event is waiting. As soon as the green light is detected, the \"TFL GREEN\" event is sent and the AudiTT returns to the \"GO\" state."}, {"heading": "B. Scenario 2: Turn Right with Cross-Traffic Present", "text": "The vehicle approaches a three-lane intersection with a stop sign and comes to a complete stop at the transition back to the STOP. When stopping, oncoming traffic is detected from the left and the first-person vehicle monitors the TTC to see if there is enough time to make a safe turn to the right in front of the oncoming vehicle. If this is not possible, the vehicle waits until there is a corresponding gap before returning to the GO state."}, {"heading": "C. Scenario 3: Navigating a Construction Zone", "text": "Part of the lane is blocked by construction poles, which make it impossible for the vehicle to follow the middle of the road without colliding with the cones. Laser scans detect the obstacle in the lane / road and the planner calculates whether there is enough space to safely circumvent the obstacle. If a workable solution is found, the vehicle moves smoothly sideways from the middle of the road to avoid the masts, and then returns to the middle of the road after the obstacle."}, {"heading": "D. Scenario 4: Stopping for Pedestrian", "text": "Using a variety of sensor modalities, we were able to demonstrate reactive stopping for both unlocked and fully locked pedestrians. Visual LiDAR sensor modality allows the vehicle to detect a pedestrian near the roadway and output a PEDESTRIAN event, resulting in a transition to STOP. From the detected position, a stopping point is calculated that allows the pedestrian to cross the road in front of the vehicle. In the V2P system, an additional panel van is parked at the roadside, completely blocking the pedestrian's view of the road. The vehicle receives the transmitted position of the pedestrian and determines that a stop is necessary. As soon as the vehicle comes to a complete stop, the pedestrian appears behind the truck in front of the vehicle. In both cases, the vehicle senses that the pedestrian has cleared the roadway (PED CLEAR) before returning to GO mode."}, {"heading": "E. Discussion", "text": "During our demonstration days, we completed 44 runs with 110 km of automated driving in three cases where the driver had to take control of the vehicle. In two cases, localization accuracy was temporarily reduced due to poor lane-marking detection combined with large GPS errors, resulting in an inaccuracy of the estimated position of the obstacles detected. In the third case, the driver had to intervene when the pedestrian position transmitted by the V2P system was inaccurate due to a GPS positioning error on the smartphone. While the vehicle was able to detect the pedestrian after appearing behind the truck, the driver overran the braking response of the automated system for safety reasons. During demonstrations and test drives, the automated driving system was able to respond appropriately to both sunny, cloudy, light fog and light rain. With some of the vision-based detection systems, detection areas were slightly reduced, but the vehicle was able to respond appropriately to each of the scenarios."}, {"heading": "VII. CONCLUSION AND FUTURE WORK", "text": "In this article, we presented an Acura RLX concept vehicle that is capable of successfully navigating urban scenarios autonomously, including smart handling of signposted intersections, pedestrian zones, and construction sites. We provided technical descriptions of the underlying modules, including localization, recognition / tracking, and planning that work together to enable intelligent behavior. In a demonstration at GoMentum Station in California, the automated drive vehicle completed 44 runs, with only three driver interventions during the 110 km. Our demonstration showed that robust and consistent AD behavior is possible in urban scenarios, but further studies are needed for the large-scale roll-out on public roads.As a future work, we plan to further improve the robustness of the system by addressing the issues that have led to driver intervention. We also want to test our AD capabilities on public roads, where the environment is more complex and dynamic."}], "references": [{"title": "Autonomous driving in urban environments: Boss and the urban challenge", "author": ["C. Urmson", "J. Anhalt", "D. Bagnell", "C. Baker", "R. Bittner", "M. Clark", "J. Dolan", "D. Duggins", "T. Galatali", "C. Geyer"], "venue": "Journal of Field Robotics, vol. 25, no. 8, pp. 425\u2013466, 2008.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Junior: The stanford entry in the urban challenge", "author": ["M. Montemerlo", "J. Becker", "S. Bhat", "H. Dahlkamp", "D. Dolgov", "S. Ettinger", "D. Haehnel", "T. Hilden", "G. Hoffmann", "B. Huhnke"], "venue": "Journal of field Robotics, vol. 25, no. 9, pp. 569\u2013597, 2008.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Making bertha drivean autonomous journey on a historic route", "author": ["J. Ziegler", "P. Bender", "M. Schreiber", "H. Lategahn", "T. Strauss", "C. Stiller", "T. Dang", "U. Franke", "N. Appenrodt", "C.G. Keller"], "venue": "IEEE Intelligent Transportation Systems Magazine, vol. 6, no. 2, pp. 8\u201320, 2014.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Autonomous vehicle positioning with gps in urban canyon environments", "author": ["Y. Cui", "S. Sam Ge"], "venue": "IEEE Transactions on Robotics and Automation, vol. 19, no. 1, pp. 15\u201325, 2003.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "Sigma-point kalman filters for integrated navigation", "author": ["R. van der Merwe", "A. Wan", "Eric"], "venue": "Proceedings of the 60th Annual Meeting of The Institute of Navigation (2004). ION, 2004, pp. 641\u2013654.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2004}, {"title": "Lane marking aided vehicle localization", "author": ["Z. Tao", "P. Bonnifait", "V. Frmont", "J. Ibaez-Guzman"], "venue": "16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013). IEEE, 2013, pp. 1509\u20131515.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Map-aided localization with lateral perception", "author": ["D. Gruyer", "R. Belaroussi", "M. Revilloud"], "venue": "2014 IEEE Intelligent Vehicles Symposium Proceedings. IEEE, 2014, pp. 674\u2013680.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Gps-bias correction for precise localization of autonomous vehicles", "author": ["K. Jo", "K. Chu", "M. Sunwoo"], "venue": "2013 IEEE Intelligent Vehicles Symposium (IV). IEEE, 2013, pp. 636\u2013641.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "System and method for providing laser camera fusion for identifying and tracking a traffic participant", "author": ["B. Heisele", "A. Ayvaci"], "venue": "U.S. Patent 14/876 907, Apr. 7, 2017.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2017}, {"title": "A direct scattering model for tracking vehicles with high-resolution radars", "author": ["C. Knill", "A. Scheel", "K. Dietmayer"], "venue": "Intelligent Vehicles Symposium (IV), 2016 IEEE. IEEE, 2016, pp. 298\u2013303.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Markov-based lane positioning using intervehicle communication", "author": ["T.-S. Dao", "K.Y.K. Leung", "C.M. Clark", "J.P. Huissoon"], "venue": "IEEE Transactions on Intelligent Transportation Systems, vol. 8, no. 4, pp. 641\u2013650, 2007.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2007}, {"title": "Belief state planning for navigating urban intersections", "author": ["M. Bouton", "A. Cosgun", "M.J. Kochenderfer"], "venue": "IEEE Intelligent Vehicles Symposium (IV), 2017.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2017}, {"title": "Implementation of the pure pursuit path tracking algorithm", "author": ["R.C. Coulter"], "venue": "DTIC Document, Tech. Rep., 1992.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1992}, {"title": "Adaptive motion planning for a mobile robot", "author": ["C. Gifre Oliveras"], "venue": "Master\u2019s thesis, Universitat Polit\u00e8cnica de Catalunya, 2012.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "After the successes at the DARPA Grand and Urban Challenges [2], [3], both academia and industry started showing more interest in AD.", "startOffset": 60, "endOffset": 63}, {"referenceID": 1, "context": "After the successes at the DARPA Grand and Urban Challenges [2], [3], both academia and industry started showing more interest in AD.", "startOffset": 65, "endOffset": 68}, {"referenceID": 2, "context": "with significant investment from automakers [4] and tech companies such as Google and Uber.", "startOffset": 44, "endOffset": 47}, {"referenceID": 3, "context": "The fusion of L1-Global Positional Systems (GPS) with either Inertial Measurement Units (IMU) or other proprioceptive sensors like an odomoter using an Extended Kalman Filter (EKF) or Unscented Kalman Filter (UKF) is known to produce a smoother and more reliable estimation of the pose of the vehicle [5] [6] than simple GPS.", "startOffset": 301, "endOffset": 304}, {"referenceID": 4, "context": "The fusion of L1-Global Positional Systems (GPS) with either Inertial Measurement Units (IMU) or other proprioceptive sensors like an odomoter using an Extended Kalman Filter (EKF) or Unscented Kalman Filter (UKF) is known to produce a smoother and more reliable estimation of the pose of the vehicle [5] [6] than simple GPS.", "startOffset": 305, "endOffset": 308}, {"referenceID": 5, "context": "In order to tackle this problem, researchers [7] [8] [9] have shown that using digital maps of the lane markings made a priori in combination with a camera facing the road can improve the lateral position estimation of the vehicle.", "startOffset": 45, "endOffset": 48}, {"referenceID": 6, "context": "In order to tackle this problem, researchers [7] [8] [9] have shown that using digital maps of the lane markings made a priori in combination with a camera facing the road can improve the lateral position estimation of the vehicle.", "startOffset": 49, "endOffset": 52}, {"referenceID": 7, "context": "In order to tackle this problem, researchers [7] [8] [9] have shown that using digital maps of the lane markings made a priori in combination with a camera facing the road can improve the lateral position estimation of the vehicle.", "startOffset": 53, "endOffset": 56}, {"referenceID": 8, "context": "The second stage is LiDAR association to estimate distance [10].", "startOffset": 59, "endOffset": 63}, {"referenceID": 9, "context": "We use the particle filter state and measurement models similar to the one presented in [11].", "startOffset": 88, "endOffset": 92}, {"referenceID": 10, "context": "V2X technology has great potential for future AD applications, such as collective perception for overcoming the on-board sensor limitations [12], infrastructure sensors for submitting traffic information and road conditions, as well as connected traffic lights for smooth handling of intersections.", "startOffset": 140, "endOffset": 144}, {"referenceID": 11, "context": "Our analysis on TTC performance and comparison with a machine-learning based approach can be found in [13].", "startOffset": 102, "endOffset": 106}, {"referenceID": 1, "context": "1) Path Planner: The path planner uses similar method described in [3] to generate several parallel paths around the main center path.", "startOffset": 67, "endOffset": 70}, {"referenceID": 12, "context": "ated and navigation starts, path planner uses pure pursuit algorithm[14] to constantly correct the ego vehicle motion according to the current pose.", "startOffset": 68, "endOffset": 72}, {"referenceID": 13, "context": "Moreover, the velocity planner plans a speed profile for look ahead distance, obstacle, and sub-goals from behaviour level using S-Curve algorithm[15].", "startOffset": 146, "endOffset": 150}], "year": 2017, "abstractText": "Each year, millions of motor vehicle traffic accidents all over the world cause a large number of fatalities, injuries and significant material loss. Automated Driving (AD) has potential to drastically reduce such accidents. In this work, we focus on the technical challenges that arise from AD in urban environments. We present the overall architecture of an AD system and describe in detail the perception and planning modules. The AD system, built on a modified Acura RLX, was demonstrated in a course in GoMentum Station in California. We demonstrated autonomous handling of 4 scenarios: traffic lights, cross-traffic at intersections, construction zones and pedestrians. The AD vehicle displayed safe behavior and performed consistently in repeated demonstrations with slight variations in conditions. Overall, we completed 44 runs, encompassing 110km of automated driving with only 3 cases where the driver intervened the control of the vehicle, mostly due to error in GPS positioning. Our demonstration showed that robust and consistent behavior in urban scenarios is possible, yet more investigation is necessary for full scale rollout on public roads.", "creator": "LaTeX with hyperref package"}}}