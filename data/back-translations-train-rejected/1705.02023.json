{"id": "1705.02023", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-May-2017", "title": "Senti17 at SemEval-2017 Task 4: Ten Convolutional Neural Network Voters for Tweet Polarity Classification", "abstract": "This paper presents Senti17 system which uses ten convolutional neural networks (ConvNet) to assign a sentiment label to a tweet. The network consists of a convolutional layer followed by a fully-connected layer and a Softmax on top. Ten instances of this network are initialized with the same word embeddings as inputs but with different initializations for the network weights. We combine the results of all instances by selecting the sentiment label given by the majority of the ten voters. This system is ranked fourth in SemEval-2017 Task4 over 38 systems with 67.4%", "histories": [["v1", "Thu, 4 May 2017 21:13:24 GMT  (191kb,D)", "http://arxiv.org/abs/1705.02023v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["hussam hamdan"], "accepted": false, "id": "1705.02023"}, "pdf": {"name": "1705.02023.pdf", "metadata": {"source": "CRF", "title": "Senti17 at SemEval-2017 Task 4: Ten Convolutional Neural Network Voters for Tweet Polarity Classification", "authors": ["Hussam Hamdan"], "emails": ["Hussam.Hamdan@lip6.fr"], "sections": [{"heading": null, "text": "This paper introduces the Senti17 system, which uses ten Convolutionary Neural Networks (ConvNet) to assign a sentimental label to a tweet. The network consists of a Convolutionary Layer followed by a fully connected layer and a Softmax Layer. Ten instances of this network are initialized with the same word embeddings as inputs, but with different initializations for network weights. We combine the results of all instances by selecting the sentimental label given by the majority of the ten voters. This system ranks fourth in SemEval-2017 Task4 among 38 systems with 67.4% average memory."}, {"heading": "1 Introduction", "text": "Polarity classification is the basic task of sentiment analysis, in which the polarity of a given text should be divided into three categories: positive, negative or neutral. In Twitter, where the tweet is short and written in informal language, this task requires more attention. SemEval has proposed the task of Message Polarity Classification in Twitter since 2013, the goal being to classify a tweet into one of the three polarity markers (Rosenthal et al., 2017).We can note that in 2013, 2014 and 2015 most of the best systems are based on a rich feature extraction process with a traditional classifier such as SVM (Mohammad et al., 2013) or logistic regression (Hamdan et al., 2015). Kim (2014) suggested using a revolutionary neural for sentence classification, fixing the size of the input set and linking its word system."}, {"heading": "2 System Architecture", "text": "The architecture of our Convolutionary Neural Network for the Classification of Emotions is shown in Fig. 1. Our network consists of a single Convolutionary Layer followed by Nonlinearity, Maximum Pooling, Dropout, Completely Interconnected Layer and a Soft Max Classification Layer. Here we describe this architecture:"}, {"heading": "2.1 Tweet Representation", "text": "First, we tokenize each tweet to get all the terms using HappyTokenizer1, which captures the words, emoticons and punctuations; then we replace each web link with the term url and each username with uuser; then we use Structured Skip-Gram embeddings (SSG) (Ling et al., 2015), which was compiled by (Amir et al., 2016) using 52 million tweets; each term in the tweet is replaced by its SSG embedding, which is a vector of the d dimensions; all term vectors are concatenated to form the input matrix, where the number of rows d and the number of columns is maxl: the maximum tweet length in the training dataset. This 2-dimensional matrix is the neural network input layer."}, {"heading": "2.2 Convolutional Layers", "text": "We connect the input matrix to different wave levels, each one a wave operation between the input matrix and a filter of size m x d. This is an elementary operation that creates f vectors of maxl-m + 1 dimension, where f is the number of filters or characteristic cards. This layer is to capture the common patterns among training tweets that are the same size as 1http: / / sentiment.christopherpotts.net / tokenizing.htmlfilter, but occur at each position of the tweet. To capture the common patterns of different sizes, we need to use more than one layer, so we have defined 8 different layers connected to the input matrix, with different filter sizes, but the same number of characteristic cards."}, {"heading": "2.3 Activation Layer", "text": "Each wave layer is typically followed by a non-linear activation function, the RELU level (Rectified Linear Unit) applies an elementary operation to change the negative numbers to 0. Output of a ReLU level is the same size as input, except that all negative values are removed. It speeds up the training and should provide more accurate results."}, {"heading": "2.4 Max-Pooling Layer", "text": "This layer reduces the output amount of the activation layer, for each vector it selects the maximum value. Different variations of the pooling layer can be used: average or k-max pooling."}, {"heading": "2.5 Dropout Layer", "text": "Dropout is used after max pooling to regulate the ConvNet and prevent overadjustment. It assumes that we will still get a reasonable classification even if some of the neurons fall. Dropout consists in randomly setting a fraction of the input units to 0 with each update during training time."}, {"heading": "2.6 Fully Conected Layer", "text": "After applying dropout, the results of all merged layers are concatenated into a completely connected layer. This layer performs a matrix multiplication between its weights and the input units. RELU nonlinearity is applied to the results of this layer."}, {"heading": "2.7 Softmax Layer", "text": "The output of the fully bonded layer is passed to a Softmax layer, which calculates the probability distribution across the labels to determine the most likely label for a tweet."}, {"heading": "3 Experiments and Results", "text": "For the training of the network, we used about 30,000 English tweets provided by SemEval organizers, and the 2016 test set, which includes 12,000 tweets as a development set. The 2017 test set is used to evaluate the system in the SemEval 2017 competition. For the implementation of our system, we used Python and Keras2.We set the network parameters as follows: SSG message size d is set to 200, the tweet maximum legnth maxl to 99. For Constitutional layers, we set the number of feature maps f to 50 and use 8 filter sizes (1,2,3,4,5,2,3,4). The p-value of the dropout layer is set to 0.3. We used the optimizer Nadam (Dozat, 2015) to update the weights of the network and the back-propogation algorithm to calculate the gradients. The batch size is set to 50, and the training data will be generated according to each iteration state."}, {"heading": "4 Conclusion", "text": "We presented our in-depth learning approach to Twitter Mood Analysis. To determine the polarity of a tweet, we used ten Convolutionary Neural Network Voters. Each voter was trained with the same training data, using the same word embedding but different initial weights. Results show that our system is competitive, ranking fourth in SemEval-2017 task 4-A."}], "references": [{"title": "INESC-ID at SemEval-2016 Task 4-A: Reducing the Problem of Out-of-Embedding Words", "author": ["Amir et al.2016] Silvio Amir", "Ramn Fernndez Astudillo", "Wang Ling", "Mrio J. Silva", "Isabel Trancoso"], "venue": "SemEval@NAACL-HLT", "citeRegEx": "Amir et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Amir et al\\.", "year": 2016}, {"title": "Webis: An Ensemble for Twitter Sentiment Detection", "author": ["Hagen et al.2015] Matthias Hagen", "Martin Potthast", "Michel Bchner", "Benno Stein"], "venue": null, "citeRegEx": "Hagen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hagen et al\\.", "year": 2015}, {"title": "Lsislif: Feature Extraction and Label Weighting for Sentiment Analysis in Twitter", "author": ["Hamdan et al.2015] Hussam Hamdan", "Patrice Bellot", "Frederic Bechet"], "venue": "In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval", "citeRegEx": "Hamdan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hamdan et al\\.", "year": 2015}, {"title": "SentiSys at SemEval-2016 Task 4: Feature-Based System for Sentiment Analysis in Twitter", "author": ["Hussam Hamdan"], "venue": "SemEval@NAACLHLT", "citeRegEx": "Hamdan.,? \\Q2016\\E", "shortCiteRegEx": "Hamdan.", "year": 2016}, {"title": "Convolutional Neural Networks for Sentence Classification. CoRR, abs/1408.5882", "author": ["Yoon Kim"], "venue": null, "citeRegEx": "Kim.,? \\Q2014\\E", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Two/Too Simple Adaptations of word2vec for Syntax Problems", "author": ["Ling et al.2015] Wang Ling", "Chris Dyer", "Alan Black", "Isabel Trancoso"], "venue": "In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics:", "citeRegEx": "Ling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "NRCCanada: Building the State-of-the-Art in Sentiment Analysis of Tweets", "author": ["Svetlana Kiritchenko", "Xiaodan Zhu"], "venue": "Proceedings of the International Workshop on Semantic Evaluation,", "citeRegEx": "Mohammad et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mohammad et al\\.", "year": 2013}, {"title": "SemEval-2017 Task 4: Sentiment Analysis in Twitter", "author": ["Noura Farra", "Preslav Nakov"], "venue": "In Proceedings of the 11th International Workshop on Semantic Evaluation,", "citeRegEx": "Rosenthal et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Rosenthal et al\\.", "year": 2017}, {"title": "UNITN: Training Deep Convolutional Neural Network for Twitter Sentiment Classification", "author": ["Severyn", "Moschitti2015] Aliaksei Severyn", "Alessandro Moschitti"], "venue": "In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval", "citeRegEx": "Severyn et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Severyn et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 7, "context": "SemEval has proposed the task of Message Polarity Classification in Twitter since 2013, the objective is to classify a tweet into one of the three polarity labels (Rosenthal et al., 2017).", "startOffset": 163, "endOffset": 187}, {"referenceID": 6, "context": "We can remark that in 2013, 2014 and 2015 most best systems were based on a rich feature extraction process with a traditional classifier such as SVM (Mohammad et al., 2013) or Logistic regression (Hamdan et al.", "startOffset": 150, "endOffset": 173}, {"referenceID": 2, "context": ", 2013) or Logistic regression (Hamdan et al., 2015).", "startOffset": 31, "endOffset": 52}, {"referenceID": 1, "context": "Severyn and Moschitti (2015) adapted the convolutional network proposed by Kim (2014) for sentiment analysis in Twitter, their system was ranked second in SemEval2015 while the first system (Hagen et al., 2015) combined four systems based on feature extraction and the third ranked system used logistic regression with different groups of features (Hamdan et al.", "startOffset": 190, "endOffset": 210}, {"referenceID": 2, "context": ", 2015) combined four systems based on feature extraction and the third ranked system used logistic regression with different groups of features (Hamdan et al., 2015).", "startOffset": 145, "endOffset": 166}, {"referenceID": 1, "context": ", 2013) or Logistic regression (Hamdan et al., 2015). In 2014, Kim (2014) proposed to use one convolutional neural network for sentence classification, he fixed the size of the input sentence and concatenated its word embeddings for representing the sentence, this architecture has been exploited in many later works.", "startOffset": 32, "endOffset": 74}, {"referenceID": 1, "context": ", 2013) or Logistic regression (Hamdan et al., 2015). In 2014, Kim (2014) proposed to use one convolutional neural network for sentence classification, he fixed the size of the input sentence and concatenated its word embeddings for representing the sentence, this architecture has been exploited in many later works. Severyn and Moschitti (2015) adapted the convolutional network proposed by Kim (2014) for sentiment analysis in Twitter, their system was ranked second in SemEval2015 while the first system (Hagen et al.", "startOffset": 32, "endOffset": 347}, {"referenceID": 1, "context": ", 2013) or Logistic regression (Hamdan et al., 2015). In 2014, Kim (2014) proposed to use one convolutional neural network for sentence classification, he fixed the size of the input sentence and concatenated its word embeddings for representing the sentence, this architecture has been exploited in many later works. Severyn and Moschitti (2015) adapted the convolutional network proposed by Kim (2014) for sentiment analysis in Twitter, their system was ranked second in SemEval2015 while the first system (Hagen et al.", "startOffset": 32, "endOffset": 404}, {"referenceID": 0, "context": "In 2016, we remark that the number of participations which use feature extraction systems were degraded, and the first four systems used Deep Learning, the majority used a convolutional network except the fourth one (Amir et al., 2016).", "startOffset": 216, "endOffset": 235}, {"referenceID": 3, "context": "Despite of that, using Deep Learning for sentiment analysis in Twitter has not yet shown a big improvement in comparison to feature extraction, the fifth and sixth systems (Hamdan, 2016) in 2016 which were built upon feature extraction process were only (3 and 3.", "startOffset": 172, "endOffset": 186}, {"referenceID": 4, "context": "This is inspired by Kim (2014), we just added a fully connected layer.", "startOffset": 20, "endOffset": 31}, {"referenceID": 5, "context": "Then, we used Structured Skip-Gram embeddings (SSG) (Ling et al., 2015) which was compiled by (Amir et al.", "startOffset": 52, "endOffset": 71}, {"referenceID": 0, "context": ", 2015) which was compiled by (Amir et al., 2016) using 52 million tweets.", "startOffset": 30, "endOffset": 49}], "year": 2017, "abstractText": "This paper presents Senti17 system which uses ten convolutional neural networks (ConvNet) to assign a sentiment label to a tweet. The network consists of a convolutional layer followed by a fully-connected layer and a Softmax on top. Ten instances of this network are initialized with the same word embeddings as inputs but with different initializations for the network weights. We combine the results of all instances by selecting the sentiment label given by the majority of the ten voters. This system is ranked fourth in SemEval-2017 Task4 over 38 systems with 67.4% average recall.", "creator": "LaTeX with hyperref package"}}}