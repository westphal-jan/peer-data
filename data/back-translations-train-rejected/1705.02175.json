{"id": "1705.02175", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2017", "title": "Distributed Online Learning of Event Definitions", "abstract": "Logic-based event recognition systems infer occurrences of events in time using a set of event definitions in the form of first-order rules. The Event Calculus is a temporal logic that has been used as a basis in event recognition applications, providing among others, direct connections to machine learning, via Inductive Logic Programming (ILP). OLED is a recently proposed ILP system that learns event definitions in the form of Event Calculus theories, in a single pass over a data stream. In this work we present a version of OLED that allows for distributed, online learning. We evaluate our approach on a benchmark activity recognition dataset and show that we can significantly reduce training times, exchanging minimal information between processing nodes.", "histories": [["v1", "Fri, 5 May 2017 11:40:11 GMT  (61kb,D)", "http://arxiv.org/abs/1705.02175v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["nikos katzouris", "alexander artikis", "georgios paliouras"], "accepted": false, "id": "1705.02175"}, "pdf": {"name": "1705.02175.pdf", "metadata": {"source": "CRF", "title": "Distributed Online Learning of Event Definitions", "authors": ["Nikos Katzouris", "Alexander Artikis", "Georgios Paliouras"], "emails": ["nkatz@iit.demokritos.gr", "a.artikis@iit.demokritos.gr", "paliourg@iit.demokritos.gr"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "2 Background and Running Example", "text": "Event Calculation (EC) [16] is a temporal logic for thinking about events and their effects. Its ontology consists of points of time (integer numbers); fluents, i.e. properties that have different values over time; and events, i.e. events in time that can alter the values of events. EC axioms include the Common Sense law of inertia, according to which fluents persist over time unless they are influenced by an event. We use a simplified version of EC that is sufficient for recognizing events [1]. The basic predicates and their domain-independent axioms are presented in Table 1. Axiom (1) states that a fluent F was initiated earlier."}, {"heading": "5 Experimental Evaluation", "text": "This year, it has come to the point that it only takes one year to get there, to get to the point where it goes to the next round."}, {"heading": "6 Related Work", "text": "In this section we mainly discuss distributed / parallel ILP algorithms, for which there is a considerable amount of work in the literature. A thorough review can be done in this area. (...) The parallel ILP algorithms use parallels in the three-dimensional axes. (...)"}, {"heading": "7 Conclusions and Future Work", "text": "We presented a distributed version of a recently proposed algorithm for learning complex event definitions online in the form of domain-specific axioms in the event calculator. We also presented an experimental evaluation of our approach using a benchmark activity detection dataset, which shows that we can significantly shorten training times. As a future work, we aim to evaluate our approach to larger datasets, in terms of in-situ, geographically distributed learning, as in the case of maritime surveillance. We also plan to eliminate the requirement that all processing nodes block their execution while waiting for answers during message transmission. Recognition. This work was funded by the H2020 project DATACRON."}], "references": [{"title": "An event calculus for event recognition", "author": ["Alexander Artikis", "Marek Sergot", "Georgios Paliouras"], "venue": "Knowledge and Data Engineering, IEEE Transactions on,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Top-down induction of first-order logical decision trees", "author": ["Hendrik Blockeel", "Luc De Raedt"], "venue": "Artificial intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1998}, {"title": "Scaling up inductive logic programming by learning from interpretations", "author": ["Hendrik Blockeel", "Luc De Raedt", "Nico Jacobs", "Bart Demoen"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "Logical and relational learning", "author": ["Luc De Raedt"], "venue": "Springer Science & Business Media,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Event processing in action", "author": ["Opher Etzion", "Peter Niblett"], "venue": "Manning Publications Co.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "Customisable multi-processor acceleration of inductive logic programming", "author": ["Andreas K Fidjeland", "Wayne Luk", "Stephen H Muggleton"], "venue": "Latest Advances in Inductive Logic Programming,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "A pipelined data-parallel algorithm for ILP", "author": ["Nuno A. Fonseca", "Fernando M.A. Silva", "V\u0131\u0301tor Santos Costa", "Rui Camacho"], "venue": "IEEE International Conference on Cluster Computing (CLUSTER", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2005}, {"title": "Parallel ilp for distributed-memory architectures", "author": ["Nuno A Fonseca", "Ashwin Srinivasan", "Fernando Silva", "Rui Camacho"], "venue": "Machine learning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Knowledge discovery from data streams", "author": ["Joao Gama"], "venue": "CRC Press,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Answer set solving in practice", "author": ["Martin Gebser", "Roland Kaminski", "Benjamin Kaufmann", "Torsten Schaub"], "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Accelerating the drug design process through parallel inductive logic programming data mining", "author": ["James H. Graham", "C. David Page Jr.", "Ahmed H. Kamal"], "venue": "IEEE Computer Society Bioinformatics Conference,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["Wassily Hoeffding"], "venue": "Journal of the American statistical association,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1963}, {"title": "Scalable relational learning for event recognition", "author": ["Nikos Katzouris"], "venue": "PhD Thesis, University of Athens,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2017}, {"title": "Incremental learning of event definitions with inductive logic programming", "author": ["Nikos Katzouris", "Alexander Artikis", "Georgios Paliouras"], "venue": "Machine Learning,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Online learning of event", "author": ["Nikos Katzouris", "Alexander Artikis", "Georgios Paliouras"], "venue": "definitions. TPLP,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "A logic-based calculus of events", "author": ["Robert Kowalski", "Marek Sergot"], "venue": "New Generation Computing,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1986}, {"title": "Yet another parallel hypothesis search for inverse entailment", "author": ["Hiroyuki Nishiyama", "Hayato Ohwada"], "venue": "In ILP,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Parallel execution for speeding up inductive logic programming systems", "author": ["Hayato Ohwada", "Fumio Mizoguchi"], "venue": "In International Conference on Discovery Science,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1999}, {"title": "Multi-relational pattern mining over data streams", "author": ["Andreia Silva", "Cl\u00e1udia Antunes"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Parallel and sequential algorithms for data mining using inductive logic", "author": ["David B Skillicorn", "Yu Wang"], "venue": "Knowledge and Information Systems,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2001}, {"title": "Relational models with streaming ilp", "author": ["Ashwin Srinivasan", "Michael Bain"], "venue": "In ILP,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Data and task parallelism in ilp using mapreduce", "author": ["Ashwin Srinivasan", "Tanveer A Faruquie", "Sachindra Joshi"], "venue": "Machine learning,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}], "referenceMentions": [{"referenceID": 4, "context": "Event recognition systems [5] process sequences of simple events, such as sensor data, and recognize complex events, i.", "startOffset": 26, "endOffset": 29}, {"referenceID": 15, "context": "The Event Calculus (EC) [16] has been used as the basis for event recognition systems [1], offering direct connections to machine learning, via Inductive Logic Programming (ILP) [4].", "startOffset": 24, "endOffset": 28}, {"referenceID": 0, "context": "The Event Calculus (EC) [16] has been used as the basis for event recognition systems [1], offering direct connections to machine learning, via Inductive Logic Programming (ILP) [4].", "startOffset": 86, "endOffset": 89}, {"referenceID": 3, "context": "The Event Calculus (EC) [16] has been used as the basis for event recognition systems [1], offering direct connections to machine learning, via Inductive Logic Programming (ILP) [4].", "startOffset": 178, "endOffset": 181}, {"referenceID": 8, "context": "Methods that learn from such streams typically build a decision model by a single pass over the input [9].", "startOffset": 102, "endOffset": 105}, {"referenceID": 14, "context": "OLED (Online Learning of Event Definitions) [15] is an ILP system that learns event definitions in the form of EC theories in a single pass over a relational data stream.", "startOffset": 44, "endOffset": 48}, {"referenceID": 11, "context": "Its single-pass strategy is based on the Hoeffding bound [12], a tool that allows to build decision models by estimating their quality on a small subset of the input.", "startOffset": 57, "endOffset": 61}, {"referenceID": 15, "context": "The Event Calculus (EC) [16] is a temporal logic for reasoning about events and their effects.", "startOffset": 24, "endOffset": 28}, {"referenceID": 0, "context": "We use a simplified version of the EC that has been shown to suffice for event recognition [1].", "startOffset": 91, "endOffset": 94}, {"referenceID": 2, "context": "In the Learning from Interpretations [3] ILP setting that we use in this work, each training example is an interpretation, i.", "startOffset": 37, "endOffset": 40}, {"referenceID": 9, "context": "Although different semantics are possible, in this work a \u201cmodel\u201d is a stable model [10].", "startOffset": 84, "endOffset": 88}, {"referenceID": 14, "context": "OLED [15] learns a theory by joining together independently-constructed clauses, each of which is learnt in an online fashion.", "startOffset": 5, "endOffset": 9}, {"referenceID": 11, "context": "OLED relies on the Hoeffding bound [12] to approximate the quality of a clause on the entire input using only a subset of the input.", "startOffset": 35, "endOffset": 39}, {"referenceID": 0, "context": "Given a random variable X with range in [0, 1] and an observed mean X of its values after n independent observations, the Hoeffding Bound states that, with probability 1 \u2212 \u03b4, the true mean X\u0302 of the variable lies in an interval (X \u2212 ,X + ), where = \u221a", "startOffset": 40, "endOffset": 46}, {"referenceID": 3, "context": "OLED learns a clause in a top-down fashion, by specializing it using literals from a bottom clause [4].", "startOffset": 99, "endOffset": 102}, {"referenceID": 1, "context": "by allowing to simultaneously try all specializations up to a given clause length, or by supporting user-defined, TILDE-like look-ahead specifications [2].", "startOffset": 151, "endOffset": 154}, {"referenceID": 14, "context": "Although different scoring functions may be plugged into OLED, in this work we use precision, to score initiation clauses, and recall, to score termination clauses, as in [15].", "startOffset": 171, "endOffset": 175}, {"referenceID": 14, "context": "We refer to [15] for more details on these features.", "startOffset": 12, "endOffset": 16}, {"referenceID": 13, "context": "An overview of existing approaches to learning theories in the Event Calculus with ILP may be found at [14,13] and a discussion on how OLED compares to such approaches may be found at [15,13].", "startOffset": 103, "endOffset": 110}, {"referenceID": 12, "context": "An overview of existing approaches to learning theories in the Event Calculus with ILP may be found at [14,13] and a discussion on how OLED compares to such approaches may be found at [15,13].", "startOffset": 103, "endOffset": 110}, {"referenceID": 14, "context": "An overview of existing approaches to learning theories in the Event Calculus with ILP may be found at [14,13] and a discussion on how OLED compares to such approaches may be found at [15,13].", "startOffset": 184, "endOffset": 191}, {"referenceID": 12, "context": "An overview of existing approaches to learning theories in the Event Calculus with ILP may be found at [14,13] and a discussion on how OLED compares to such approaches may be found at [15,13].", "startOffset": 184, "endOffset": 191}, {"referenceID": 7, "context": "A thorough review may be found in [8,22].", "startOffset": 34, "endOffset": 40}, {"referenceID": 21, "context": "A thorough review may be found in [8,22].", "startOffset": 34, "endOffset": 40}, {"referenceID": 7, "context": "main axes [8]: Searching through the hypothesis space in parallel (search parallelism); splitting the training data and learning from data subsets (data parallelism); and evaluating candidate clauses in parallel (evaluation/coverage parallelism).", "startOffset": 10, "endOffset": 13}, {"referenceID": 19, "context": "In [20] the authors present a a data-parallel version of a standard set-cover loop: Each processing node learns a fragment of the concept definition from a partition of the data, and then these fragments are exchanged between all nodes.", "startOffset": 3, "endOffset": 7}, {"referenceID": 19, "context": "Overall, the approach in [20] learns much faster that a sequential algorithm, achieving super-linear speed-ups.", "startOffset": 25, "endOffset": 29}, {"referenceID": 6, "context": "A similar approach is proposed in [7], where the training examples are split across multiple nodes and searched in parallel, while the best rules from each node are \u201cpipe-lined\u201d to all other nodes.", "startOffset": 34, "endOffset": 37}, {"referenceID": 21, "context": "In [22] the authors use a MapReduce-based framework to parallelize the operation of a classical set-cover ILP algorithm towards both evaluation-parallelism and searchparallelism.", "startOffset": 3, "endOffset": 7}, {"referenceID": 17, "context": "A similar approach for parallel exploration of independent hypotheses has been proposed in [18], while similar approaches towards parallel coverage tests have been proposed in [11,6].", "startOffset": 91, "endOffset": 95}, {"referenceID": 10, "context": "A similar approach for parallel exploration of independent hypotheses has been proposed in [18], while similar approaches towards parallel coverage tests have been proposed in [11,6].", "startOffset": 176, "endOffset": 182}, {"referenceID": 5, "context": "A similar approach for parallel exploration of independent hypotheses has been proposed in [18], while similar approaches towards parallel coverage tests have been proposed in [11,6].", "startOffset": 176, "endOffset": 182}, {"referenceID": 16, "context": "In [17], the approach of [22] was extended to a framework that is capable of self-regulating the workload of distributing learning costs across multiple nodes.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "In [17], the approach of [22] was extended to a framework that is capable of self-regulating the workload of distributing learning costs across multiple nodes.", "startOffset": 25, "endOffset": 29}, {"referenceID": 18, "context": "However, existing approaches are either oriented towards unsupervised tasks like frequent pattern discovery [19], or they rely on propositionalization techniques and off-the-self, online propositional learners [21].", "startOffset": 108, "endOffset": 112}, {"referenceID": 20, "context": "However, existing approaches are either oriented towards unsupervised tasks like frequent pattern discovery [19], or they rely on propositionalization techniques and off-the-self, online propositional learners [21].", "startOffset": 210, "endOffset": 214}], "year": 2017, "abstractText": "Logic-based event recognition systems infer occurrences of events in time using a set of event definitions in the form of first-order rules. The Event Calculus is a temporal logic that has been used as a basis in event recognition applications, providing among others, direct connections to machine learning, via Inductive Logic Programming (ILP). OLED is a recently proposed ILP system that learns event definitions in the form of Event Calculus theories, in a single pass over a data stream. In this work we present a version of OLED that allows for distributed, online learning. We evaluate our approach on a benchmark activity recognition dataset and show that we can significantly reduce training times, exchanging minimal information between processing nodes.", "creator": "LaTeX with hyperref package"}}}