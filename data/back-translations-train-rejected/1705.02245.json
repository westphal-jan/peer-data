{"id": "1705.02245", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2017", "title": "Data Readiness Levels", "abstract": "Application of models to data is fraught. Data-generating collaborators often only have a very basic understanding of the complications of collating, processing and curating data. Challenges include: poor data collection practices, missing values, inconvenient storage mechanisms, intellectual property, security and privacy. All these aspects obstruct the sharing and interconnection of data, and the eventual interpretation of data through machine learning or other approaches. In project reporting, a major challenge is in encapsulating these problems and enabling goals to be built around the processing of data. Project overruns can occur due to failure to account for the amount of time required to curate and collate. But to understand these failures we need to have a common language for assessing the readiness of a particular data set. This position paper proposes the use of data readiness levels: it gives a rough outline of three stages of data preparedness and speculates on how formalisation of these levels into a common language for data readiness could facilitate project management.", "histories": [["v1", "Fri, 5 May 2017 14:53:56 GMT  (17kb)", "http://arxiv.org/abs/1705.02245v1", null]], "reviews": [], "SUBJECTS": "cs.DB cs.AI cs.CY cs.LG", "authors": ["neil d lawrence"], "accepted": false, "id": "1705.02245"}, "pdf": {"name": "1705.02245.pdf", "metadata": {"source": "META", "title": "Data Readiness Levels", "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 5.02 245v 1 [cs.D B] 5M ay2 01 Application of models to data is tense. Data-generating collaborators often have only a very basic understanding of the complications of collecting, processing, and curating data. Challenges include: poor data collection practices, missing values, inconvenient storage mechanisms, intellectual property, security, and privacy. All of these impede data sharing and linking, and the eventual interpretation of data through machine learning or other approaches. A major challenge in project reporting is encapsulating these issues and enabling targets around data processing. Project overruns can occur because the time needed to curate and collect data is not taken into account. However, to understand these errors, we need a common language to assess the willingness of a particular dataset. This position paper suggests using data preparedness sketches for this stage of data preparation, such as a common layout for a common language management."}, {"heading": "1 Introduction", "text": "The universal formula of machine learning is data + model \u2192 predictionwith a high predictive quality that depends on both good models and high-quality data. In the academic world of machine learning, much of the focus is on the quality of the model. This focus arises because data usually comes from benchmarks or publicly available data sets, i.e. the performance of a task is improved by exercising control over the model. The greater connectivity of modern society and the apparent ease with which we digitize or record data place us in a certain position. We need to develop much more control over the quality of our data, whether in the way we collect it or how we comment on it. Currently, the academic or empirical study of modeling (e.g. supporting vector machines, neural networks, Gaussian processes) is important in training the graduates we produce, but approaches to understanding the quality of the data are less frequently used."}, {"heading": "2 Data Readiness Levels", "text": "This year it is so far that it will only take a few days until it will be so far, until it is so far again."}, {"heading": "2.1 Band C", "text": "Band C is about the accessibility of a data set. The lowest level of band C (call it C4) would represent the belief that the data could exist, but its existence has not even been verified. Signs that data is C4 could include statements such as \"The sales department should have a record of it.\" Or \"The data should be available because we set it in the software requirements.\" We could consider it as hearsay data. Data you have heard of as you say it is there. Problems with hearsay data could include \u2022 whether it is actually recorded \u2022 the format in which it is recorded (e.g. handwritten logbook, stored in PDF format or old machine formats) \u2022 Privacy or legal restrictions on the accessibility of the recorded data have eased ethical restrictions? \u2022 Restrictions of access based on topology (e.g. the data is distributed across a number of devices)."}, {"heading": "2.2 Band B", "text": "Volume B is about the fidelity and representation of the data. Now that they are loaded into the software, what is recorded is consistent with what is supposed to be recorded? How are missing values handled, what is their encoding? What is the noise characterization (for sensors) or for manual data are there data entry errors? Are any scientific units formulated correctly? Tukey's \"Exploration Data Analysis\" approach also fits into Volume B. Visualizations of the data should be done to visualize the data and ensure that decision makers who are unaware of the data can be involved in the analysis process. Decision makers (e.g. project managers or the customer) should begin to get a sense of the limitations of their data through appropriate visualization. As part of Volume B, the characteristics of the collection process that are not limited to data should be reviewed."}, {"heading": "2.3 Band A", "text": "Volume A is about data in context. Volume A is about the appropriateness of a given data set to answer a specific question or to be the subject of a particular analysis. The context needs to be defined. For example, OpenML [3] defines tasks related to data sets. A data set can only be considered in Volume A if a task has been defined. One task could be: \"Use the data to predict a user preference\" or \"Use this data to prove the effectiveness of a drug\" or \"Use this data to check the functioning of our rocket engine.\" Once data has been taken into account alongside a task and any remedies, the data is in A1 state. They are ready to be used in the given context, and they can be used to make predictions with the data. As A1 is data in context, it is possible that a data set A1 is a prediction for another (for example, the quote is only a prediction for the customer)."}, {"heading": "3 The Analysis Pipeline", "text": "Anyone conducting an analysis in Band A also needs to be familiar with the collection process in order to understand any distortions in data collection, and sharing information about decisions made in Band B and C. Sharing information about decisions made in Band C is also critical to achieving a good outcome.What happens when we merge two sets of data into a new set? Some assessment of data provision would still need to be made in relation to the new set, even if the other two sets have already been evaluated. Why? Well, for example, there can be ethical problems with combining the two sets of data. For example, medical data can be easily deanonymized when combined with other related sets of data, which would mean that some assessments would need to be done in Band C to see if it is ethically responsible to combine the two sets in the same analysis package."}, {"heading": "3.1 Potential Results", "text": "The idea of these levels is to increase the accountability of the process and make the nature of the data manifest. With existing data readiness levels, you can imagine conversations that include statements like this: Be careful, this department claims to have provided 10,000 records, but we estimate that only 25% of these records are available when C1 is ready. The cost of bringing the data to C1 would be prohibitive for this study alone, but the company-wide data review aims to view this data as C1 by the 3rd quarter of 2017, meaning that we can move forward and recruit the statisticians we need. The project failed because we had statistical expertise and then used it to bring the data set to C1 readiness, a task that would have been better accomplished by building our software engineering resources."}, {"heading": "4 Case Studies", "text": "This is difficult to answer quantitatively; a large-scale analysis of the scale of this problem requires metadata science, i.e. the study of data science itself by acquiring data on data science. This would be a very worthwhile undertaking. In the absence of quantitative information, we offer two anecdotal case studies below: The first deals with the problem of extracting data from a popular conference tape for machine learning."}, {"heading": "4.1 Proceedings of Machine Learning Research", "text": "The Proceedings of Machine Learning Research3 (PMLR) began in 2006. (as JMLR Workshop and Conference Proceedings) to be available a convenient way to publish machine learning conference procedures without the overhead of a conventional publisher. There are now 69 volumes of procedures published and planned. They contain more than 3,198 papers. The original website was curated manually to mimic the JMLR website, but since Volume 26 an automated Process Process Process Process Process Process Process Process Process Process Process Process Process Process Process Process Process Process Process Process Process Process Process, which relies on editors providing a ZIP file of PDFs and a bibliography reference file (see below as \"Bib Files\") specified author names, abstracts and titles were used."}, {"heading": "4.2 Data Wrangling Snafus", "text": "That is, the original source of information is often provided by the author. Many authors seemed to insert their abstractions from the PDFs of their papers into this software, which meant that the abstractions contained ligatures. A ligature is a single font unit like \"fi,\" which occurs when the previous letter merges with the second one. Many authors seemed to insert their abstractions from the PDFs of their papers into this software, which meant that the abstractions contained ligatures. A ligature is a single font unit like \"fi,\" which occurs when the previous letter merges with the second one. \u00df is an example of a ligature that eventually became a letter. Unfortunately, the ligatures were not inserted as Unicode, but as unbound characters that the Pythonyaml library could not read when presented as data."}, {"heading": "4.2.1 How Data Readiness Levels could have helped", "text": "This is one of the first projects I undertook after conceiving the Data Readiness Level, but in retrospect, I think I still didn't take the ideas seriously enough. Underestimating the time it would take to manually curate after the initial scraping of the data, I didn't put enough effort into robust code for dealing with ligatures and other unusual character codes. There were several moments when I should have revised my processing code afterwards, but because I was motivated by a desire to finish the project, especially given that I had greatly underestimated how long it would take, I decided to take it. An interesting question is how ideas from software development, such as agile development philosophies, could have helped make me more aware of these mistakes."}, {"heading": "4.3 Disease Monitoring in Uganda", "text": "The second case study refers to the work in collaboration with the University of Makerere and UN Global Pulse in Kampala, Uganda, on disease prediction [4]. Specifically, it was about understanding the spatial correlations of malaria projects in Uganda, and their interactions with other measures such as NDVI, precipitation, elevation differences, etc. Our efforts were a national effort, but at the same time our work was an international effort within the framework of the Malaria Atlas Project.4We constructed spatial models aimed at recognizing and exploiting the correlations between the different covariants. The work was carried out by two doctoral students of the theories, Martin from Kampala and Ricardo from the UK. Work in Kampala focused mainly on data collection and collation, in particular the interpretation of satellite images as NDVI, the alignment of precipitation and elevation plans."}, {"heading": "4.3.1 How Data Readiness Levels could have helped", "text": "Aware of the availability of data, we would have done three things: first, we would have better estimated how much time Martin would need to manipulate satellite imagery, etc.; second, we would have questioned the process by which the HMIS data was presented to us, and at what stage they are, and how they got there. These, by and large, are questions that sit in band C and B. Third, the awareness of the transition from band B to band A (data shifting into their context) would have allowed us to see that the question could evolve and respond more strongly to this outcome. Finally, this step was driven by the shift in cooperation from Makerere to the United Nations. Ricardo has continued his work in this area, and a focus of his new UCSF Global Health Research Group was to clean up existing data and make it available to other groups as spatial layers."}, {"heading": "5 Conclusion", "text": "The cost of data curation is often underestimated, and those who do the work in bands C and B are very often underestimated. Data delivery levels underscore the different skill levels required at each stage of the analysis, from software engineer to data cheer. Some consensus on these levels would help organizations (and their managers, financial controllers) quantify the value associated with data and allocate resources correctly to developing data sets that are robust and representative. Well-executed data analysis will lead to a good customer experience, but the same tokens badly waste resources and give a bad customer experience."}, {"heading": "A Exemplar Technology Readiness Levels", "text": "One example is paper studies on the basic properties of a technology. Examples are limited to analytical studies. Analytical and experimental critical functions and / or characteristic evidence of concepts for research and development are initiated, including analytical studies and laboratory studies for the physical validation of the individual elements of the technology, such as components that are not yet integrated and / or provide characteristic evidence for concepts."}], "references": [{"title": "Technology readiness levels demystified", "author": ["J. Banke"], "venue": "NASA, 2010.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Taking machine learning research online with OpenML", "author": ["J. Vanschoren", "J.N. Rijn", "B. Bischl"], "venue": "Proceedings of the 4th international workshop on big data, streams and heterogeneous source mining: Algorithms, systems, programming models and applications, 2015, vol. 41, pp. 1\u20134.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Technology readiness levels arose in NASA [2].", "startOffset": 42, "endOffset": 45}, {"referenceID": 1, "context": "via a data repository such as OpenML [3]).", "startOffset": 37, "endOffset": 40}, {"referenceID": 1, "context": "For example OpenML [3] defines tasks associated with data sets.", "startOffset": 19, "endOffset": 22}, {"referenceID": 0, "context": "[2] J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[3] J.", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "Application of models to data is fraught. Data-generating collaborators often only have a very basic understanding of the complications of collating, processing and curating data. Challenges include: poor data collection practices, missing values, inconvenient storage mechanisms, intellectual property, security and privacy. All these aspects obstruct the sharing and interconnection of data, and the eventual interpretation of data through machine learning or other approaches. In project reporting, a major challenge is in encapsulating these problems and enabling goals to be built around the processing of data. Project overruns can occur due to failure to account for the amount of time required to curate and collate. But to understand these failures we need to have a common language for assessing the readiness of a particular data set. This position paper proposes the use of data readiness levels: it gives a rough outline of three stages of data preparedness and speculates on how formalisation of these levels into a common language for data readiness could facilitate project management.", "creator": "LaTeX with hyperref package"}}}