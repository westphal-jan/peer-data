{"id": "1705.02314", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2017", "title": "Building Morphological Chains for Agglutinative Languages", "abstract": "In this paper, we build morphological chains for agglutinative languages by using a log-linear model for the morphological segmentation task. The model is based on the unsupervised morphological segmentation system called MorphoChains. We extend MorphoChains log linear model by expanding the candidate space recursively to cover more split points for agglutinative languages such as Turkish, whereas in the original model candidates are generated by considering only binary segmentation of each word. The results show that we improve the state-of-art Turkish scores by 12% having a F-measure of 72% and we improve the English scores by 3% having a F-measure of 74%. Eventually, the system outperforms both MorphoChains and other well-known unsupervised morphological segmentation systems. The results indicate that candidate generation plays an important role in such an unsupervised log-linear model that is learned using contrastive estimation with negative samples.", "histories": [["v1", "Fri, 5 May 2017 17:30:50 GMT  (291kb,D)", "http://arxiv.org/abs/1705.02314v1", "10 pages, accepted and presented at the CICLing 2017 (18th International Conference on Intelligent Text Processing and Computational Linguistics)"]], "COMMENTS": "10 pages, accepted and presented at the CICLing 2017 (18th International Conference on Intelligent Text Processing and Computational Linguistics)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["serkan ozen", "burcu can"], "accepted": false, "id": "1705.02314"}, "pdf": {"name": "1705.02314.pdf", "metadata": {"source": "CRF", "title": "Building Morphological Chains for Agglutinative Languages", "authors": ["Serkan Ozen", "Burcu Can"], "emails": ["serkan1ozen@gmail.com", "burcucan@cs.hacettepe.edu.tr"], "sections": [{"heading": null, "text": "Keywords: unattended learning, morphological segmentation, morphology, loglinear models, contrastive estimation"}, {"heading": "1 Introduction", "text": "In fact, it is as if most of us are able to abide by the rules we have imposed on ourselves. (...) It is not as if we are able to change the rules. (...) It is not as if we are able to change the rules. (...) It is as if we are able to change the rules. (...) It is as if we are able to change the rules. (...) It is as if we are able to change the rules. (...) It is as if we are able to change them. (...) It is as if we are able to change them. (...). (...) It is as if we are able to change them. (...)"}, {"heading": "2 Related Work", "text": "In fact, most of them will be able to play by the rules that they have set themselves, and they will be able to play by the rules that they have set themselves in order to play by the rules."}, {"heading": "3 Model", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Model Definition", "text": "In this thesis, we expand the MorphoChains [1] segmentation system, in which each word and its morphological roots are represented as a chain structure. In the morphological chain, each word appears in a parent-child relationship. Here, the path is the parent of walking; doable is the parent of the undoable, and do is the parent of the feasible. In the MorphoChains system, a log-linear model is used to extract the chain structure in an uncommented corpus. The model has a feature vector: W \u00b7 Z \u2192 Rd and a corresponding weight vector: Rd, where W denotes words and Z candidates. A candidate is a potential parent of a word. For example, the word doors has the following candidates: (door, suffix), (doo, suffix), (rs, prefix), (prefix, a parent of a word is a word."}, {"heading": "3.2 Features", "text": "The characteristics of the model are as follows: Semantic similarity is applied by the cosmic similarity of a word-parent pair. Cosmic similarity is calculated by using the word embeddings from word2vec [17]. The paper shows that morphologically related word-parent pairs tend to have high cosmic similarity. For example, (fly, fly) pairs will have higher cosmic similarity when compared with each other (fly, fly) and these favor fly as the parent of flying rather than having Flyi as the parent. Affixes are automatically generated as a list of the most common affixes in the corpus. To build the affixes list of affixes, each word is analyzed with a higher frequency than a manually set threshold."}, {"heading": "4 Improvements to the Model", "text": "The probability of the model for a given uncommented word list D is as follows: L (1), D), D (2), D (2), D (2), D (2), D (2), D (2), D (2), D (2), D (2), D (3), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (D, D, D, D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4), D (4, D (4), D (4), D (4), D (4, D (4), D (4), D (4), D (4), D (4, D (4), D (4), D (4), D (4), D (4), D (4), D (4, D (4), D (4), D (4), D (4, D (4), D (4), D (4, D (4), D (4, D (4), D (4), D (4"}, {"heading": "5 Results", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "6 Conclusion and Future Work", "text": "In this work, we expand the uncontrolled morphological segmentation system called MorphoChains [1]. We adopt the original log-linear model, which uses contrastive estimation with negative sampling, and aim to increase the observed space from which the probability mass is shifted. We increase the observed candidate space by creating candidates recursively, while in the original model candidates are generated by binary segmentation of each word. Therefore, for each word the number of candidates is equal to the number of letters in each word. Recursion provides candidates who extract the suffixes in the middle of the word, increasing the probability that these suffixes will be assigned. However, in the original model, only the probability of suffixes at the end of the words with their occurrence in the corpus is increased. We aim to try various optimization algorithms in the original log-linear model as a future target."}, {"heading": "Acknowledgments", "text": "This research is supported by the Turkish Science and Technology Council (TUBITAK) with project number EEEAG-115E464 and we thank TUBITAK for their financial support."}], "references": [{"title": "An unsupervised method for uncovering morphological chains", "author": ["K. Narasimhan", "R. Barzilay", "T. Jaakkola"], "venue": "Transactions of the Association for Computational Linguistics 3", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Finite state morphology and left to right phonology", "author": ["J. Hankamer"], "venue": "Proceedings of the West Coast Conference on Formal Linguistics. Volume 5.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1986}, {"title": "Morpho challenge 2010", "author": ["M. Kurimo", "K. Lagus", "S. Virpioja", "V. Turunen"], "venue": "http:// research.ics.tkk.fi/events/morphochallenge2010/", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Unsupervised learning of the morphology of a natural language", "author": ["J. Goldsmith"], "venue": "Computational Linguistics 27(2)", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2001}, {"title": "Unsupervised discovery of morphemes", "author": ["M. Creutz", "K. Lagus"], "venue": "Proceedings of the ACL02 workshop on morphological and phonological learning, Association for Computational Linguistics", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Inducing the morphological lexicon of a natural language from unannotated text", "author": ["M. Creutz", "K. Lagus"], "venue": "Proceedings of the International and Interdisciplinary Conference on Adaptive Knowledge Representation and Reasoning (AKRR05.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Interpolating between types and tokens by estimating power-law generators", "author": ["S. Goldwater", "M. Johnson", "T.L. Griffiths"], "venue": "Advances in Neural Information Processing Systems 18. MIT Press", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Generalized weighted Chinese restaurant processes for species sampling mixture models", "author": ["H. Ishwaran", "L.F. James"], "venue": "Statistica Sinica 13", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Unsupervised multilingual learning for morphological segmentation", "author": ["B. Snyder", "R. Barzilay"], "venue": "ACL.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "Modeling syntactic context improves morphological segmentation", "author": ["Y.K. Lee", "A. Haghighi", "R. Barzilay"], "venue": "Proceedings of the Fifteenth Conference on Computational Natural Language Learning, Association for Computational Linguistics", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning probabilistic paradigms for morphology in a latent class model", "author": ["E. Chan"], "venue": "Proceedings of the Eighth Meeting of the ACL Special Interest Group on Computational Phonology and Morphology, Association for Computational Linguistics", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Clustering morphological paradigms using syntactic categories", "author": ["B. Can", "S. Manandhar"], "venue": "Multilingual Information Access Evaluation I. Text Retrieval Experiments: 10th Workshop of the Cross-Language Evaluation Forum, CLEF 2009, Corfu, Greece, September 30 - October 2, 2009, Revised Selected Papers, Berlin, Heidelberg, Springer Berlin Heidelberg", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Inducing syntactic categories by context distribution clustering", "author": ["A. Clark"], "venue": "Proceedings of the 2nd Workshop on Learning Language in Logic and the 4th Conference on Computational Natural Language Learning - Volume 7. ConLL \u201900, Stroudsburg, PA, USA, Association for Computational Linguistics", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2000}, {"title": "Unsupervised morphological segmentation with loglinear models", "author": ["H. Poon", "C. Cherry", "K. Toutanova"], "venue": "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Association for Computational Linguistics", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "A joint model for word embedding and word morphology", "author": ["K. Cao", "M. Rei"], "venue": "CoRR abs/1606.02601", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Unsupervised morphology induction using word embedddings", "author": ["R. Soricut", "F. Och"], "venue": "Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, Association for Computational Linguistics", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Efficient estimation of word representations in vector space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "CoRR abs/1301.3781", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "The model is based on the unsupervised morphological segmentation system called MorphoChains [1].", "startOffset": 93, "endOffset": 96}, {"referenceID": 1, "context": "The number of different word forms can be theoretically infinite in agglutinative languages [2].", "startOffset": 92, "endOffset": 95}, {"referenceID": 0, "context": "In this paper, we propose an improvement to the MorphoChains segmentation system [1] by extending the candidate space used in contrastive estimation, thereby covering also agglutinative languages for multiple split points.", "startOffset": 81, "endOffset": 84}, {"referenceID": 2, "context": "We perform all experiments on publicly available Turkish, English and German datasets provided by Morpho Challenge 2010 [3].", "startOffset": 120, "endOffset": 123}, {"referenceID": 0, "context": "The evaluation method will be the same with the one used in MorphoChains segmentation system [1].", "startOffset": 93, "endOffset": 96}, {"referenceID": 3, "context": "One of the earliest works is Linguistica that is proposed by Goldsmith [4].", "startOffset": 71, "endOffset": 74}, {"referenceID": 4, "context": "Creutz and Lagus [5] introduce another well-known unsupervised morphological segmentation Morfessor Baseline, the first member of the Morfessor family.", "startOffset": 17, "endOffset": 20}, {"referenceID": 5, "context": "In another member of the same family, Creutz and Lagus [6], suggest", "startOffset": 55, "endOffset": 58}, {"referenceID": 6, "context": "[7] present a framework that generates power-laws by using word frequencies.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Pitman-Yor Process [8] (the two parameter extension of a Dirichlet Process) is used as a stochastic process in their framework.", "startOffset": 19, "endOffset": 22}, {"referenceID": 8, "context": "Snyder and Barzilay [9] use Dirichlet Process, the simplified version of the Pitman-Yor Process, to induce morpheme boundaries on a bilingual aligned corpus simultaneously by finding the cross-lingual morpheme relations.", "startOffset": 20, "endOffset": 23}, {"referenceID": 9, "context": "[10] address the connection between syntax and morphology in a statistical model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "Chan [11] applies Latent Dirichlet Allocation (LDA) to learn morphological paradigms as latent classes.", "startOffset": 5, "endOffset": 9}, {"referenceID": 11, "context": "Can and Manandhar [12] obtain syntactic categories from a context distributional clustering algorithm [13] and learn paradigms by using the the pairs of syntactic categories that have common stems.", "startOffset": 18, "endOffset": 22}, {"referenceID": 12, "context": "Can and Manandhar [12] obtain syntactic categories from a context distributional clustering algorithm [13] and learn paradigms by using the the pairs of syntactic categories that have common stems.", "startOffset": 102, "endOffset": 106}, {"referenceID": 13, "context": "[14] suggest using bi-gram morpheme contexts in a log linear model similar to the current study in this paper.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "Cao and Rei [15] propose a model where word embeddings and segmentation are learned simultaneously.", "startOffset": 12, "endOffset": 16}, {"referenceID": 15, "context": "Soricut and Och [16] learn the morphological transformations between words using a high dimensional vector space (i.", "startOffset": 16, "endOffset": 20}, {"referenceID": 16, "context": "In this paper, 200-dimensional neural word embeddings obtained from word2vec [17] are also used to capture semantic similarities between words that are derived from each other.", "startOffset": 77, "endOffset": 81}, {"referenceID": 0, "context": "In this paper, we extend the MorphoChains[1] segmentation system where each word and its morphological roots are represented as a chain structure.", "startOffset": 41, "endOffset": 44}, {"referenceID": 16, "context": "The cosine similarity is computed by using the word embeddings obtained from word2vec [17].", "startOffset": 86, "endOffset": 90}, {"referenceID": 2, "context": "We use the publicly available datasets provided by Morpho Challenge [3] for both training and testing.", "startOffset": 68, "endOffset": 71}, {"referenceID": 16, "context": "We also use large datasets for training the neural word embedding model, word2vec [17] in order to build the neural word embeddings for the semantic similarity feature.", "startOffset": 82, "endOffset": 86}, {"referenceID": 0, "context": "We compare our Turkish and English results with MorphoChains-O [1] (original MorphoChains system), Morfessor Baseline [5], Morfessor CatMAP [6] and Lee Segmenter [10].", "startOffset": 63, "endOffset": 66}, {"referenceID": 4, "context": "We compare our Turkish and English results with MorphoChains-O [1] (original MorphoChains system), Morfessor Baseline [5], Morfessor CatMAP [6] and Lee Segmenter [10].", "startOffset": 118, "endOffset": 121}, {"referenceID": 5, "context": "We compare our Turkish and English results with MorphoChains-O [1] (original MorphoChains system), Morfessor Baseline [5], Morfessor CatMAP [6] and Lee Segmenter [10].", "startOffset": 140, "endOffset": 143}, {"referenceID": 9, "context": "We compare our Turkish and English results with MorphoChains-O [1] (original MorphoChains system), Morfessor Baseline [5], Morfessor CatMAP [6] and Lee Segmenter [10].", "startOffset": 162, "endOffset": 166}, {"referenceID": 0, "context": "In this paper, we extend the unsupervised morphological segmentation system called MorphoChains [1].", "startOffset": 96, "endOffset": 99}], "year": 2017, "abstractText": "In this paper, we build morphological chains for agglutinative languages by using a log linear model for the morphological segmentation task. The model is based on the unsupervised morphological segmentation system called MorphoChains [1]. We extend MorphoChains log linear model by expanding the candidate space recursively to cover more split points for agglutinative languages such as Turkish, whereas in the original model candidates are generated by considering only binary segmentation of each word. The results show that we improve the state-of-art Turkish scores by 12% having a F-measure of 72% and we improve the English scores by 3% having a F-measure of 74%. Eventually, the system outperforms both MorphoChains and other well-known unsupervised morphological segmentation systems. The results indicate that candidate generation plays an important role in such an unsupervised log-linear model that is learned using contrastive estimation with negative samples.", "creator": "LaTeX with hyperref package"}}}