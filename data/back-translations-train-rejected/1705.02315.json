{"id": "1705.02315", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2017", "title": "ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases", "abstract": "The chest X-ray is one of the most commonly accessible radiological examinations for screening and diagnosis of many lung diseases. A tremendous number of X-ray imaging studies accompanied by radiological reports are accumulated and stored in many modern hospitals' Picture Archiving and Communication Systems (PACS). On the other side, it is still an open question how this type of hospital-size knowledge database containing invaluable imaging informatics (i.e., loosely labeled) can be used to facilitate the data-hungry deep learning paradigms in building truly large-scale high precision computer-aided diagnosis (CAD) systems.", "histories": [["v1", "Fri, 5 May 2017 17:31:12 GMT  (6954kb,D)", "http://arxiv.org/abs/1705.02315v1", "CVPR 2017 spotlight"], ["v2", "Fri, 19 May 2017 17:45:07 GMT  (7325kb,D)", "http://arxiv.org/abs/1705.02315v2", "CVPR 2017 spotlight;V1: CVPR submission+supplementary; V2: Statistics and benchmark results on published ChestX-ray14 dataset are updated in Appendix B"], ["v3", "Wed, 19 Jul 2017 19:12:50 GMT  (7573kb,D)", "http://arxiv.org/abs/1705.02315v3", "CVPR 2017 spotlight;V1: CVPR submission+supplementary; V2: Statistics and benchmark results on published ChestX-ray14 dataset are updated in Appendix B V3: Minor correction NOTE **** Dataset link will be updated soon for public access ****"], ["v4", "Wed, 27 Sep 2017 14:33:36 GMT  (7326kb,D)", "http://arxiv.org/abs/1705.02315v4", "CVPR 2017 spotlight;V1: CVPR submission+supplementary; V2: Statistics and benchmark results on published ChestX-ray14 dataset are updated in Appendix B V3: Minor correction V4: new data download link upated:this https URL"]], "COMMENTS": "CVPR 2017 spotlight", "reviews": [], "SUBJECTS": "cs.CV cs.CL", "authors": ["xiaosong wang", "yifan peng", "le lu", "zhiyong lu", "mohammadhadi bagheri", "ronald m summers"], "accepted": false, "id": "1705.02315"}, "pdf": {"name": "1705.02315.pdf", "metadata": {"source": "CRF", "title": "ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases", "authors": ["Xiaosong Wang", "Yifan Peng", "Zhiyong Lu", "Ronald M. Summers"], "emails": ["xiaosong.wang@nih.gov", "yifan.peng@nih.gov", "le.lu@nih.gov", "luzh@nih.gov", "mohammad.bagheri@nih.gov", "rms@nih.gov"], "sections": [{"heading": null, "text": "In this paper, we present a new chest X-ray database, \"ChestX-ray8,\" which contains 108,948 frontal x-rays of 32,717 unique patients with the eight image captions of the disease (each image may have multiple captions), from the associated radiological reports using natural language processing. Importantly, we show that these common thoracic diseases can be detected and even spatially localized using a uniform, poorly monitored framework for classifying and localizing images with multiple captions, validated using our proposed dataset. Although the initial quantitative results are reported to be promising, the deep revolutionary neural network based on \"chest X-rays\" (i.e. detecting and localizing common disease patterns trained only with image captions) remains a challenging task for fully automated, high-precision CAD systems."}, {"heading": "1 Introduction", "text": "In fact, it is so that most of them are able to survive themselves if they do not see themselves able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}, {"heading": "1.1 Related Work", "text": "Recently, efforts have been made to create open, annotated medical image databases [50, 52, 37, 36], with patient numbers ranging from a few hundred to two thousand. Specifically, for breast X-rays, the largest public dataset is OpenI [1], which contains 3,955 radiology reports from the Indiana Network for Patient Care and 7,470 related breast X-rays from hospitals picture1https: / / / console.cloud.google.com / storage / browser / gcs-public-data--nih / radiology _ 2017 / Chest _ X-Ray _ CVPR17, more details: https: / / www.cc.nih. gov / drd / summers.htmlarchiving and communication system (PACS). This database is used in [42] as a problem for generating captions, but without quantitative disease detection outcomes. Our newly proposed chest X-ray database for detection is larger than one order of magnitude [1]."}, {"heading": "2 Construction of Hospital-scale Chest X-ray Database", "text": "This year, it has come to the point where it only takes one year to get to the next round."}, {"heading": "2.2 Quality Control on Disease Labeling", "text": "In order to validate our method, we are conducting the following experiments: Since there are no gold standard labels for our dataset, we are alternatively using some existing commented corpora. Using the OpenI API [1], we receive a total of 3,851 unique radiology reports, in which each OpenI report is provided with its most important results / disease names by human commentators. [9] Given our focus on the eight diseases, a subset of OpenI reports and their human annotations are used as the gold standard for evaluating our method. Table 1 summarizes the statistics of the subset of OpenI [1, 20] reports. Table 2 shows the results of our method with OpenI measured in Precision (P), Recall (R) and F1 Score. Higher precision of 0.90, higher memory of 0.91 and higher F1 scores of 0.90 are achieved compared to the existing MetaMap labels (with NegEx enabled). For all diseases, our method achieves higher precision, in particular 0.90, a higher accuracy of 0.74 versus 0.74 and \"higher accuracy of 0.74.\""}, {"heading": "2.3 Processing Chest X-ray Images", "text": "Compared to the popular ImageNet classification problem, significantly smaller spatial dimensions of many diseases within the typical x-ray image dimensions of 3000 x 2000 pixels pose challenges to both the capacity of the computer hardware and the design of the deep learning paradigm. In ChestX-ray8, X-ray images are extracted directly from the DICOM file and resized as 1024 x 1024 bitmap images without significantly losing the detail content compared to image sizes of 512 x 512 in the OpenI dataset. Their intensity ranges are re-scaled using the standard window settings in the DICOM header files."}, {"heading": "2.4 Bounding Box for Pathologies", "text": "As part of the ChestX-ray8 database, a small number of pathology images are provided with hand-labeled Bounding Boxes (B-Boxes), which can serve as a basis for evaluating the disease localization performance. In addition, it could also be used for a one- or two-line learning situation [15] where only one or more samples are needed to initialize learning, and the system then develops on its own with more unlabeled data. We leave this as future work. In our labeling process, we first select 200 instances for each pathology (a total of 1,600 instances), consisting of 983 images. Specifying an image and a keyword for the disease, a certified radiologist identified only the corresponding disease instance in the image and labeled it with a B-Box. The B-Box is then output as an XML file. If an image contains multiple disease cases, each disease instance is labeled separately and stored in individual XML files. As the application of the ChestX-Box and the proposed disease localization is demonstrated in the ChestX-Box."}, {"heading": "3 Common Thoracic Disease Detection and Localization", "text": "Reading and diagnosing chest X-rays may be an entry-level task for radiologists, but in fact it is a complex thinking problem that often requires careful observation and good knowledge of anatomical principles, physiology, and pathology. Such factors increase the difficulty of developing a unified and automated technique for reading chest X-rays while taking into account all common thoracic diseases. As the main application of the ChestX-ray8 dataset, we present a unified, poorly monitored framework for image classification and pathology that can detect the presence of multiple pathologies and then generate bouncing boxes around the corresponding pathologies. In detail, we adapt Deep Convolutional Neural Network (DCNN) architectures for poorly monitored object localization, taking into account large image capacities, different multi-label CNN losses, and different pooling strategies."}, {"heading": "3.1 Unified DCNN Framework", "text": "It is the first time that one or more pathologies are presented in each X-ray image, and later we can identify them with activation and weight shifts from the network. We have addressed this problem by developing a multi-level DCNN classification model. (...) We have depicted the DCNN architecture that we have adapted with similarities to several previously poorly monitored object localization methods (31, 54, 12, 19). (...) We have depicted network surgery on the pre-formed models (with ImageNet [10, 39]), e.g. AlexNet [26], GoogLeNet [45], VGNet-16 [44], and ResNet-50 [17], omitting the complete layers and final classification layers. Instead, we insert a transition layer, a global pooling layer, and a loss layer at the end (after the last continuous layer)."}, {"heading": "3.2 Weakly-Supervised Pathology Localization", "text": "Global Pooling Layer and Prediction Layer: In our multi-label image classification network, the global pooling and prediction layer is designed to not only be part of the DCNN for classification, but also generate the pathology probability map, namely a heatmap. The location with a peak in the heatmap generally corresponds to the presence of disease patterns with a high probability. The upper part of Figure 4 shows the process of creating this heatmap. By performing a global pooling after the transition layer, the weights learned in the prediction layer can act as weights of spatial maps from the transition layer. The upper part of Figure 4 shows the process of weighted spatial activation maps for each disease class (with a size of S \u00d7 S \u00b7 C) by multiplying the activation layer from the transition layer (with a size of S \u00d7 S \u00d7 D) and the weights of the predensity layer (with an X)."}, {"heading": "4 Experiments", "text": "In the overall view, the number of people living in the USA is significantly higher than the number of people living in the USA. In the overall view of all people living in the USA, the number of people living in the USA is higher than the number of people living in the USA. In the overall view of all people living in the USA, the number of people living in the USA is higher than the number of people living in the USA. In the total population, there are 84,312 people living and working in the USA. In the overall view of all people living in the USA, the number of people living in the USA is higher than the number of people living in the USA."}, {"heading": "5 Conclusion", "text": "Building hospital-scale radiological image databases with computerized diagnostic performance scales has not been initiated to date. We are trying to build a comprehensive X-ray database that presents the realistic clinical and methodological challenges of dealing with at least tens of thousands of patients (something akin to \"ImageNet\" in nature images); we are also conducting extensive quantitative performance benchmarks on eight common thoracopathology classification systems and poorly monitored localization using the ChestX-ray8 database; the main goal is to initiate future efforts by promoting public datasets in this important area. Building truly comprehensive, fully automated, high-precision medical diagnostic systems remains an arduous task. ChestX-ray8 can enable the data-hungry paradigms of the deep regional network to create clinically meaningful applications, including shared disease patterns, disease correlation analyses, and automated reporting classes of disease X for future radiological reporting."}, {"heading": "A Appendix", "text": "In this paper we only look at the semantic types of diseases or syndromes and findings (namely \"dsyn\" and \"fndg\"). Table 5 shows the corresponding SNOMEDCT concepts relevant to the target diseases (these mappings are developed by searching for disease names in the UMLS R and by a Boardcertified radiologist.A.2 Rules of Negation / Uncertainty, but many text processing systems can handle the negation / Uncertainty detection problem, most of them exploit regular expressions on the text direct, and verified by a boardcertified radiologist.A.2"}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "The chest X-ray is one of the most commonly accessi-<lb>ble radiological examinations for screening and diagnosis<lb>of many lung diseases. A tremendous number of X-ray<lb>imaging studies accompanied by radiological reports are<lb>accumulated and stored in many modern hospitals\u2019 Pic-<lb>ture Archiving and Communication Systems (PACS). On<lb>the other side, it is still an open question how this type<lb>of hospital-size knowledge database containing invaluable<lb>imaging informatics (i.e., loosely labeled) can be used to fa-<lb>cilitate the data-hungry deep learning paradigms in build-<lb>ing truly large-scale high precision computer-aided diagno-<lb>sis (CAD) systems. In this paper, we present a new chest X-ray database,<lb>namely \u201cChestX-ray8\u201d, which comprises 108,948 frontal-<lb>view X-ray images of 32,717 unique patients with the text-<lb>mined eight disease image labels (where each image can<lb>have multi-labels), from the associated radiological reports<lb>using natural language processing. Importantly, we demon-<lb>strate that these commonly occurring thoracic diseases can<lb>be detected and even spatially-located via a unified weakly-<lb>supervised multi-label image classification and disease lo-<lb>calization framework, which is validated using our proposed<lb>dataset. Although the initial quantitative results are promis-<lb>ing as reported, deep convolutional neural network based<lb>\u201creading chest X-rays\u201d (i.e., recognizing and locating the<lb>common disease patterns trained with only image-level la-<lb>bels) remains a strenuous task for fully-automated high pre-<lb>cision CAD systems.", "creator": "LaTeX with hyperref package"}}}