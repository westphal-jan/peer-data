{"id": "1705.02476", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-May-2017", "title": "PANFIS++: A Generalized Approach to Evolving Learning", "abstract": "The concept of evolving intelligent system (EIS) provides an effective avenue for data stream mining because it is capable of coping with two prominent issues: online learning and rapidly changing environments. We note at least three uncharted territories of existing EISs: data uncertainty, temporal system dynamic, redundant data streams. This book chapter aims at delivering a concrete solution of this problem with the algorithmic development of a novel learning algorithm, namely PANFIS++. PANFIS++ is a generalized version of the PANFIS by putting forward three important components: 1) An online active learning scenario is developed to overcome redundant data streams. This module allows to actively select data streams for the training process, thereby expediting execution time and enhancing generalization performance, 2) PANFIS++ is built upon an interval type-2 fuzzy system environment, which incorporates the so-called footprint of uncertainty. This component provides a degree of tolerance for data uncertainty. 3) PANFIS++ is structured under a recurrent network architecture with a self-feedback loop. This is meant to tackle the temporal system dynamic. The efficacy of the PANFIS++ has been numerically validated through numerous real-world and synthetic case studies, where it delivers the highest predictive accuracy while retaining the lowest complexity.", "histories": [["v1", "Sat, 6 May 2017 12:02:15 GMT  (635kb)", "http://arxiv.org/abs/1705.02476v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["mahardhika pratama"], "accepted": false, "id": "1705.02476"}, "pdf": {"name": "1705.02476.pdf", "metadata": {"source": "CRF", "title": "PANFIS++: A Generalized Approach to Evolving Learning", "authors": ["Mahardhika Pratama"], "emails": [], "sections": [{"heading": null, "text": "This year, it is as far as ever in the history of the city, where it is as far as never before."}, {"heading": "III.C Parameter Learning Scenario of PANFIS++", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "IV.A An Appraisal of Residential Premise Price", "text": "This year, it is only a matter of time before we reach an agreement."}], "references": [{"title": "Data driven modeling based on dynamic parsimonious fuzzy neural", "author": ["M. Pratama", "M.J. Er", "X. Li", "R.J. Oentaryo", "E. Lughofer", "I. Arifin"], "venue": "network,\" Neurocomputing,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Learning in Non-Stationary Environments: Methods and Applications", "author": ["M. Sayed-Mouchaweh", "E. Lughofer"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Simpl_eTS: A simplified method for learning evolving Takagi-Sugeno fuzzy models,", "author": ["P.Angelov", "D. Filev"], "venue": "IEEE International Conference on Fuzzy Systems (FUZZ),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "An on-line self-constructing neural fuzzy inference network and its applications,", "author": ["C.F. Juang", "C.T. Lin"], "venue": "IEEE Transactions on Fuzzy Systems.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1998}, {"title": "DENFIS: dynamic evolving neural-fuzzy inference system and its application for time series prediction", "author": ["N. Kasabov", "Q. Song"], "venue": "IEEE Transactions on Fuzzy Systems .vol10 (2).pp. 144\u2013154. ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "An approach to online identification of Takagi-Sugeno fuzzy models,", "author": ["P.Angelov", "D. Filev"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B.vol", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "A self-evolving interval type-2 fuzzy neural network with online structure and parameter learning,", "author": ["C.F. Juang", "Y.W. Tsao"], "venue": "IEEE Transactions on Fuzzy Systems, vol. 16,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Recurrent Classifier based on An Incremental Meta-Cognitive-based Scaffolding Algorithm", "author": ["M.Pratama", "J.Lu", "S.Anavatti"], "venue": "IEEE Transactions on Fuzzy Systems, Vol.23(6),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "J", "author": ["M. Pratama"], "venue": "Lu, G.Zhang, \u201c Evolving Type-2 Fuzzy Classifier\u201d, online and in press, IEEE Transactions on Fuzzy Systems, Vol. 24(3), pp. 574-589, ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Generalized Smart Evolving Fuzzy Systems", "author": ["E. Lughofer", "C. Cernuda", "S. Kindermann", "M. Pratama"], "venue": "Evolving Systems, Vol 6(4), pp.269-292, ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Ronald R", "author": ["P. Angelov"], "venue": "Yager: A new type of simplified fuzzy rule-based system. International Journal of General Systems vol.41(2),pp. 163-185 ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "An incremental meta-cognitive-based scaffolding fuzzy neural network ", "author": ["M Pratama", "J Lu", "S Anavatti", "E Lughofer", "CP Lim"], "venue": "Vol. 171, pp. 89-105, ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "M-J", "author": ["M. Pratama"], "venue": "Er, S.G Anavatti., E, Lughofer., N, Wang., I, Arifin., \u201c A novel meta-cognitive-based scaffolding classifier to sequential non-stationary classification problems\u201d, In proceeding of 2014 International Conference on Fuzzy Systems, 369-376, ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Scaffolding type-2 classifier for incremental learning under concept drifts", "author": ["J Pratama", "E Lu", "G Lughofer", "S Zhang", "Anavatti"], "venue": "Neurocomputing, Vol. 191,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "A sequential learning algorithm for self-adaptive resource allocation network classifier,", "author": ["S. Suresh", "K. Dong", "H. Kim"], "venue": "Neurocomputing, 73(16),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "and C", "author": ["Y.Y. Lin", "J.Y. Chang"], "venue": "T. Lin, \u201cA TSK-type based self-evolving compensatory interval type-2 fuzzy neural network (TSCIT2FNN) and its applications,\u201d IEEE Transactions on Industrial Electronics., vol. 61, no. 1, pp. 447\u2013459, ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "A recurrent self-organizing neural fuzzy inference network,", "author": ["C.F. Juang", "C.T. Lin"], "venue": "IEEE Transactions on Neural Networks, vol.10,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1999}, {"title": "and C", "author": ["C.F. Juang", "Y.Y. Lin"], "venue": "C. Tu, \u201cA recurrent self-evolving fuzzy neural network with local feedbacks and its application to dynamic system processing,\u201d Fuzzy Sets and Systems, vol.161,no.19, ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "A TSK-type recurrent fuzzy network for dynamic systems processing by neural network and genetic algorithms,", "author": ["C.F. Juang"], "venue": "IEEE Transactions on Fuzzy Systems, vol.10,no.2,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2002}, {"title": "Identification and Prediction of Dynamic Systems Using an Interactively Recurrent Self-Evolving Fuzzy Neural Network", "author": ["Yang-Yin Lin", "Jyh-Yeong Chang", "Chin-Teng Lin"], "venue": "IEEE Transactions on Neural Networks and Learning Systems,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "PANFIS: A Novel Incremental Learning", "author": ["M. Pratama", "S. Anavatti", "P. Angelov", "E. Lughofer"], "venue": "IEEE Transactions on Neural Networks and Learning Systems, Vol.25, no.1, pp.55-68,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "A growing and pruning sequential learning algorithm of hyper basis function neural network for function approximation", "author": ["N. Vukovic", "Z. Miljkovic"], "venue": "Neural Networks,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "A growing and pruning method for radial basis function networks", "author": ["Bose", "R.P.J.C", "M. Bortman", "M Aladjem"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2009}, {"title": "Evolving Fuzzy Systems --- Methodologies, Advanced Concepts and Applications", "author": ["E. Lughofer"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2011}, {"title": "An Evolving Interval Type-2 Neurofuzzy Inference System and Its Metacognitive Sequential Learning Algorithm", "author": ["A.K. Das", "K. Subramanian", "S. Suresh"], "venue": "IEEE Transactions on Fuzzy Systems,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Active Learning with Drifting Streaming Data", "author": ["I. Zliobaite", "A. Bifet", "Pfahringer.B", "B. Holmes"], "venue": "IEEE Transactions on Neural Networks and Learning Systems,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2014}, {"title": "A fast approach for automatic generation of fuzzy rules by generalized dynamic fuzzy neural networks", "author": ["S.-Q. Wu", "M-J. Er", "Y. Gao"], "venue": "IEEE Transaction on Fuzzy System,Vol.9(4),pp.578\u2013594,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2003}, {"title": "The Bayesian ARTMAP,", "author": ["B. Vigdor", "B. Lerner"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2007}, {"title": "et al", "author": ["R.J. Oentaryo"], "venue": "\"Online probabilistic learning for fuzzy inference systems,\" Expert Systems with Applications, vol. 41, no. 11, pp. 5082-5096, ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2014}, {"title": "Dynamic fuzzy neural networks\u2014a novel approach to function approximation", "author": ["S. Wu", "M-J. Er"], "venue": "IEEE Transaction on Systems Man Cybernetics, part b: Cybernetics,vol.30,pp. 358\u2013364,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2000}, {"title": "ANFIS: Adaptive-network-based fuzzy inference system", "author": ["J.-S.R. Jang"], "venue": "IEEE Transaction on System. Man. Cybernetic, part b: cybernetics, vol. 23, pp. 665\u2013684,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1993}], "referenceMentions": [{"referenceID": 0, "context": "The problem of data streams is frequently encountered in the online time-critical applications, which calls for an efficient algorithm with low computational and storage requirement [1].", "startOffset": 182, "endOffset": 185}, {"referenceID": 1, "context": "Tool degradation and changing surface integrity also cause gradual concept drift [2].", "startOffset": 81, "endOffset": 84}, {"referenceID": 2, "context": "To this end, Evolving Intelligent System (EIS) has been proposed and features two prominent characteristics: open structure, online learning [3].", "startOffset": 141, "endOffset": 144}, {"referenceID": 2, "context": "This is capable of dealing with a possible infinite nature of data stream and satisfying a life-long learning requirement [3].", "startOffset": 122, "endOffset": 125}, {"referenceID": 3, "context": "The area of EIS was pioneered by Juang and Lin [4] with SONFIN, although the term \u201cEvolving\u201d has not been formalized until the development of DENFIS [5] and eTS [6].", "startOffset": 47, "endOffset": 50}, {"referenceID": 4, "context": "The area of EIS was pioneered by Juang and Lin [4] with SONFIN, although the term \u201cEvolving\u201d has not been formalized until the development of DENFIS [5] and eTS [6].", "startOffset": 149, "endOffset": 152}, {"referenceID": 5, "context": "The area of EIS was pioneered by Juang and Lin [4] with SONFIN, although the term \u201cEvolving\u201d has not been formalized until the development of DENFIS [5] and eTS [6].", "startOffset": 161, "endOffset": 164}, {"referenceID": 6, "context": "Since then the area of EIS has attracted various contributions [7] - [15].", "startOffset": 63, "endOffset": 66}, {"referenceID": 11, "context": "Since then the area of EIS has attracted various contributions [7] - [15].", "startOffset": 69, "endOffset": 73}, {"referenceID": 12, "context": "Although the concept of metacognitive learning incorporating the what-to-learn component aims at addressing redundant data streams [16][20], most of them are designed for classification problems, while a regression problem is an open issue.", "startOffset": 131, "endOffset": 135}, {"referenceID": 14, "context": "Although the concept of metacognitive learning incorporating the what-to-learn component aims at addressing redundant data streams [16][20], most of them are designed for classification problems, while a regression problem is an open issue.", "startOffset": 135, "endOffset": 139}, {"referenceID": 15, "context": "Some attempt has been devoted to actualise the evolving concept in the recurrent network structure and the interval-type 2 fuzzy system [21]-[25].", "startOffset": 136, "endOffset": 140}, {"referenceID": 19, "context": "Some attempt has been devoted to actualise the evolving concept in the recurrent network structure and the interval-type 2 fuzzy system [21]-[25].", "startOffset": 141, "endOffset": 145}, {"referenceID": 20, "context": "PANFIS++ presents an extended version of PANFIS [26], which is not only capable of mining data streams efficiently but also selecting", "startOffset": 48, "endOffset": 52}, {"referenceID": 15, "context": "Although the local recurrent connection has been put into perspective in [21], [22], the novelty of our work can be found in the rule layer of the PANFIS++, which features the interval type-2 multivariate Gaussian function with the intervalvalued centroids; 3) PANFIS++ realises a generalized interval type-2 Takagi-Sugeno-Kang (TSK) fuzzy rule.", "startOffset": 73, "endOffset": 77}, {"referenceID": 16, "context": "Although the local recurrent connection has been put into perspective in [21], [22], the novelty of our work can be found in the rule layer of the PANFIS++, which features the interval type-2 multivariate Gaussian function with the intervalvalued centroids; 3) PANFIS++ realises a generalized interval type-2 Takagi-Sugeno-Kang (TSK) fuzzy rule.", "startOffset": 79, "endOffset": 83}, {"referenceID": 6, "context": "The GT2DS is a generalized version of the T2DS method [7], which is designed under a strict condition of uniformly distributed training data.", "startOffset": 54, "endOffset": 57}, {"referenceID": 21, "context": "It adopts a strategy of [27], [28], which estimates a complex probability density function with the Gaussian Mixture Model (GMM).", "startOffset": 24, "endOffset": 28}, {"referenceID": 22, "context": "It adopts a strategy of [27], [28], which estimates a complex probability density function with the Gaussian Mixture Model (GMM).", "startOffset": 30, "endOffset": 34}, {"referenceID": 21, "context": "It is worth noting that [27], [28] are all designed for the type-1 fuzzy system; 5) PANFIS++ integrates the rule pruning scenario, which is capable of discarding an outdated rule \u2013 no longer relevant to current learning context and an inconsequential rule \u2013 plays little role during its lifespan.", "startOffset": 24, "endOffset": 28}, {"referenceID": 22, "context": "It is worth noting that [27], [28] are all designed for the type-1 fuzzy system; 5) PANFIS++ integrates the rule pruning scenario, which is capable of discarding an outdated rule \u2013 no longer relevant to current learning context and an inconsequential rule \u2013 plays little role during its lifespan.", "startOffset": 30, "endOffset": 34}, {"referenceID": 20, "context": "The radii of the fuzzy set are formulated as a distance between the centres to the cutting points of the ellipsoidal cluster [26] as follows:", "startOffset": 125, "endOffset": 129}, {"referenceID": 23, "context": "pool-based approach, which assumes all data are available in the pool for an iterative selection procedure [29].", "startOffset": 107, "endOffset": 111}, {"referenceID": 24, "context": "scenarios to mine data streams [30], [31].", "startOffset": 37, "endOffset": 41}, {"referenceID": 24, "context": "in [31] but it is still based on the hinge loss function, which is sensitive to the system\u2019s error.", "startOffset": 3, "endOffset": 7}, {"referenceID": 25, "context": "We set s as its default value [33] s=0.", "startOffset": 30, "endOffset": 34}, {"referenceID": 6, "context": "The original version of DQ method [7] is derived with the p-fold numerical integration, which is only suitable for a small input dimension.", "startOffset": 34, "endOffset": 37}, {"referenceID": 21, "context": "It is inspired by the works of [27], [28] taking advantage of the GMM as a probability density function to deal with a complex and irregular data distribution.", "startOffset": 31, "endOffset": 35}, {"referenceID": 22, "context": "It is inspired by the works of [27], [28] taking advantage of the GMM as a probability density function to deal with a complex and irregular data distribution.", "startOffset": 37, "endOffset": 41}, {"referenceID": 6, "context": "In light of the rule significance definition [7], the significance of interval-valued multivariate Gaussian function is defined as the Lu-norm of the error function weighted by the input density function.", "startOffset": 45, "endOffset": 48}, {"referenceID": 26, "context": "The initialization of the covariance matrix (16) has been proven mathematically to meet the \u03b5 \u2013 completeness condition [34].", "startOffset": 119, "endOffset": 123}, {"referenceID": 6, "context": "This rule growing condition differs from its predecessors [7], [27], [28], which are reliant on a user-defined threshold.", "startOffset": 58, "endOffset": 61}, {"referenceID": 21, "context": "This rule growing condition differs from its predecessors [7], [27], [28], which are reliant on a user-defined threshold.", "startOffset": 63, "endOffset": 67}, {"referenceID": 22, "context": "This rule growing condition differs from its predecessors [7], [27], [28], which are reliant on a user-defined threshold.", "startOffset": 69, "endOffset": 73}, {"referenceID": 27, "context": "There are several ways to choose the winning rule: the distance-based method, the Bayesian concept [35].", "startOffset": 99, "endOffset": 103}, {"referenceID": 27, "context": "It is not recounted here and interested reader is advised to go to [35] for further details of the Bayesian winning rule selection.", "startOffset": 67, "endOffset": 71}, {"referenceID": 27, "context": "generalized version of the gradient descent method [35].", "startOffset": 51, "endOffset": 55}, {"referenceID": 8, "context": "The PANFIS++ was compared against 10 prominent learning algorithms: eT2Class [9], Simp_eTS [3], eTS [6], BARTFIS [38], PANFIS [26], GENEFIS [11], DFNN [39], GDFNN [34], ANFIS [40] and benchmarked algorithms were compared against five evaluation criteria: predictive accuracy, fuzzy rule, input attribute, runtime, training sample, and network parameters.", "startOffset": 77, "endOffset": 80}, {"referenceID": 2, "context": "The PANFIS++ was compared against 10 prominent learning algorithms: eT2Class [9], Simp_eTS [3], eTS [6], BARTFIS [38], PANFIS [26], GENEFIS [11], DFNN [39], GDFNN [34], ANFIS [40] and benchmarked algorithms were compared against five evaluation criteria: predictive accuracy, fuzzy rule, input attribute, runtime, training sample, and network parameters.", "startOffset": 91, "endOffset": 94}, {"referenceID": 5, "context": "The PANFIS++ was compared against 10 prominent learning algorithms: eT2Class [9], Simp_eTS [3], eTS [6], BARTFIS [38], PANFIS [26], GENEFIS [11], DFNN [39], GDFNN [34], ANFIS [40] and benchmarked algorithms were compared against five evaluation criteria: predictive accuracy, fuzzy rule, input attribute, runtime, training sample, and network parameters.", "startOffset": 100, "endOffset": 103}, {"referenceID": 28, "context": "The PANFIS++ was compared against 10 prominent learning algorithms: eT2Class [9], Simp_eTS [3], eTS [6], BARTFIS [38], PANFIS [26], GENEFIS [11], DFNN [39], GDFNN [34], ANFIS [40] and benchmarked algorithms were compared against five evaluation criteria: predictive accuracy, fuzzy rule, input attribute, runtime, training sample, and network parameters.", "startOffset": 113, "endOffset": 117}, {"referenceID": 20, "context": "The PANFIS++ was compared against 10 prominent learning algorithms: eT2Class [9], Simp_eTS [3], eTS [6], BARTFIS [38], PANFIS [26], GENEFIS [11], DFNN [39], GDFNN [34], ANFIS [40] and benchmarked algorithms were compared against five evaluation criteria: predictive accuracy, fuzzy rule, input attribute, runtime, training sample, and network parameters.", "startOffset": 126, "endOffset": 130}, {"referenceID": 29, "context": "The PANFIS++ was compared against 10 prominent learning algorithms: eT2Class [9], Simp_eTS [3], eTS [6], BARTFIS [38], PANFIS [26], GENEFIS [11], DFNN [39], GDFNN [34], ANFIS [40] and benchmarked algorithms were compared against five evaluation criteria: predictive accuracy, fuzzy rule, input attribute, runtime, training sample, and network parameters.", "startOffset": 151, "endOffset": 155}, {"referenceID": 26, "context": "The PANFIS++ was compared against 10 prominent learning algorithms: eT2Class [9], Simp_eTS [3], eTS [6], BARTFIS [38], PANFIS [26], GENEFIS [11], DFNN [39], GDFNN [34], ANFIS [40] and benchmarked algorithms were compared against five evaluation criteria: predictive accuracy, fuzzy rule, input attribute, runtime, training sample, and network parameters.", "startOffset": 163, "endOffset": 167}, {"referenceID": 30, "context": "The PANFIS++ was compared against 10 prominent learning algorithms: eT2Class [9], Simp_eTS [3], eTS [6], BARTFIS [38], PANFIS [26], GENEFIS [11], DFNN [39], GDFNN [34], ANFIS [40] and benchmarked algorithms were compared against five evaluation criteria: predictive accuracy, fuzzy rule, input attribute, runtime, training sample, and network parameters.", "startOffset": 175, "endOffset": 179}, {"referenceID": 0, "context": "The predictive task was carried out using 12 time-domain features extracted from the force signal [1].", "startOffset": 98, "endOffset": 101}], "year": 2017, "abstractText": "Mahardhika Pratama Abstract \u2013 the concept of evolving intelligent system (EIS) provides an effective avenue for data stream mining because it is capable of coping with two prominent issues: online learning and rapidly changing environments. We note at least three uncharted territories of existing EISs: data uncertainty, temporal system dynamic, redundant data streams. This book chapter aims at delivering a concrete solution of this problem with the algorithmic development of a novel learning algorithm, namely PANFIS++. PANFIS++ is a generalized version of the PANFIS by putting forward three important components: 1) An online active learning scenario is developed to overcome redundant data streams. This module allows to actively select data streams for the training process, thereby expediting execution time and enhancing generalization performance; 2) PANFIS++ is built upon an interval type-2 fuzzy system environment, which incorporates the so-called footprint of uncertainty. This component provides a degree of tolerance for data uncertainty. 3) PANFIS++ is structured under a recurrent network architecture with a self-feedback loop. This is meant to tackle the temporal system dynamic. The efficacy of the PANFIS++ has been numerically validated through numerous real-world and synthetic case studies, where it delivers the highest predictive accuracy while retaining the lowest complexity.", "creator": "Microsoft\u00ae Word 2016"}}}