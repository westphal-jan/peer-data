{"id": "1705.02798", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-May-2017", "title": "Reinforced Mnemonic Reader for Machine Comprehension", "abstract": "Recently, several end-to-end neural models have been proposed for machine comprehension tasks. Typically, these models use attention mechanisms to capture the complicated interaction between the context and the query and then point the boundary of answer. To better point the correct answer, we introduce the Mnemonic Reader for machine comprehension tasks, which enhance the attention reader in two aspects. Firstly, we use a self-alignment attention to model the long-distance dependency among context words, and obtain query-aware and self-aware contextual representation for each word in the context. Second, we use a memory-based query-dependent pointer to predict the answer, which integrates both explicit and implicit query information, such as query category. Our experimental evaluations show that our model obtains the state-of-the-art result on the large-scale machine comprehension benchmarks SQuAD.", "histories": [["v1", "Mon, 8 May 2017 09:43:05 GMT  (967kb)", "http://arxiv.org/abs/1705.02798v1", "9 pages, 4 figures"], ["v2", "Mon, 31 Jul 2017 08:38:05 GMT  (657kb,D)", "http://arxiv.org/abs/1705.02798v2", "9 pages, 5 figures"], ["v3", "Tue, 5 Sep 2017 14:17:27 GMT  (666kb,D)", "http://arxiv.org/abs/1705.02798v3", "8 pages, 2 figures"]], "COMMENTS": "9 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["minghao hu", "yuxing peng", "xipeng qiu"], "accepted": false, "id": "1705.02798"}, "pdf": {"name": "1705.02798.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Minghao Hu", "Yuxing Peng", "Xipeng Qiu"], "emails": ["huminghao09@nudt.edu.cn", "pengyuxing@nudt.edu.cn", "xpqiu@fudan.edu.cn"], "sections": [{"heading": null, "text": "ar Xiv: 170 5.02 798v 1 [cs.C L] 8M ay2 017Recently, several end-to-end neural models have been proposed for machine understanding. Typically, these models use attention mechanisms to capture the intricate interaction between the context and the query and then draw the boundary of the answer. To better determine the correct answer, we introduce the machine understanding mnemonic reader, which improves the attention reader in two ways. First, we use self-directed attention to model the dependence between the context words over long distances and obtain a question-conscious and selectable contextual representation for each word in the context. Second, we use a memory-based query-dependent pointer to predict the answer that integrates both explicit and implicit query information, such as query categories. Our experimental evaluations show that our model of scale results for the AD are based on the state-of-the-scale machine understanding."}, {"heading": "1 Introduction", "text": "In fact, it is the case that most of them are able to abide by the rules that they have given themselves, that they have taken care of. (...) In fact, it is the case that they are able to abide by the rules. (...) In fact, it is the case that they are able to break the rules. (...) It is as if they are able to break the rules. (...) It is as if they are able to break the rules. (...) It is as if they are able to break the rules. \"(...)"}, {"heading": "2 Related Work", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "3 Model", "text": "Mnemonic Reader consists of four basic levels: input level, interactive alignment level, self-alignment level and mnemonic pointing level, which are shown in Figure 1 (a) below. Input level: The input level encodes each context and the corresponding query into a distributed vector space. Interactive alignment level: For a pair of encoded vector representations, the interactive alignment level retrieves information between them to create a query-conscious context representation. Self-alignment level: The self-alignment level aligns the question-conscious context against itself to further generate a self-conscious context representation."}, {"heading": "3.1 Input Layer", "text": "The input layer is responsible for mapping each word x to its corresponding word embedding xw, which is typically done by using pre-formed word vectors (Kim, 2014), which results in word embedding at a lower level. Each word embedding x is then represented by encoding its character-character sequence x-sequence with a Convolutionary Neural Network followed by maximum embedding over time (Kim, 2014). Each word embedding x is then presented as concatenating the character-level x-character sequence x-sequence x-sequence, which is called x = [xw, xc]. R d, where d is the overall dimension of word embedding and character embedding xc. Similar to BiDAF (Seo et al, 2017), word embedding of both the query and the context is further transformed by the Highway Network."}, {"heading": "3.2 Interactive Alignment Layer", "text": "The interactive alignment layer simultaneously takes care of the query and the context to capture the interaction between them, and finally generates a quantum conscious context representation D. Specifically, we first calculate an alignment matrix A-Rn \u00b7 m between the query and the context by Aij = qiT \u00b7 cj. The element Aij of the matrix A indicates the similarity between the i-th query word and the j-th context word. For each context word, we intend to find the most relevant query word by calculating a softaligned query vector and merging it with the context word. Let aj-R n denote the normalized attention distribution of the query for the j-th context word, and Q-R-2h the corresponding softly aligned query vectors."}, {"heading": "3.3 Self Alignment Layer", "text": "The self-alignment layer aligns the question-conscious context representation D-R2h \u00b7 m against itself in order to further synthesize contextual information between context words (Weissenborn et al., 2017). Merging information between context words makes it possible to model important contextual information close to the correct answer. Similar to the interactive alignment layer, we first calculate a self-alignment matrix B-Rm \u00b7 m for the context: Bij = 1 (i-6 = j) di T-dj (5), where Bij indicates the similarity between the ith context word and the j-th context word, and the diagonal of the alignment matrix B is set to zero if the word aligns with itself."}, {"heading": "3.4 Mnemonic Pointing Layer", "text": "Unlike the query-sensitive-pointing mechanisms, where the answer is a single token, complex QA tasks require a span of text as the final answer. The answer is usually by predicting the starting position of responses and then the end position, based on the implicit query representation: p (i, j, C) = ps (i, C), Q). (7) In addition, the explicit query category (i.e., who, where, and so on) is obviously a high-level abstraction of the expression of queries that provides additional clues for searching for the answer. (7) A \"query pair pays more attention to temporal information, while a\" query searches for spatial information to use the implicit and explicit information, we suggest a query-sensitive character mechanism to select a response."}, {"heading": "4 Evaluation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Experimental Configuration", "text": "We use the Stanford Question Answering Dataset (SQuAD) (Rajpurkar et al., 2016) to evaluate our model. In total, the SQuAD corpus contains more than 100k queries, which are commented manually by crowdsourced staff in 536 Wikipedia articles. The data set includes 90k query context tuples for training, 10k tuples for validation, and a large hidden test set. The answer to each query is a text segment from the corresponding context. Two metrics, Exact Match (EM) and F1 Score, are used to evaluate models. We use the Adam Optimizer (Kingma and Ba, 2014) for training with a minibatch size of 64 and an initial learning rate of 0.0006. We will halve the learning rate when we hit a bad epoch. A dropout rate (Srivastava et al., 2014) is used to avoid 0.2 word layers, one for all, and one for all."}, {"heading": "4.2 Overall Results", "text": "Table 1 shows the performance comparison of our models and other competing models on the official SQuAD ranking. Our single mnemonic reader achieves an EM value of 69.86% and an F1 value of 79.21%. Since SQuAD is a very competitive benchmark for machine understanding, we also build an ensemble model that consists of 14 individual models with the same architecture but initialized with different parameters. The response margin with the highest probability of all models is selected for each query. Our ensemble model improves the EM value to 73.67% and the F1 value to 81.69%, achieving competitive results on the official ranking."}, {"heading": "4.3 Ablation Results", "text": "To evaluate the individual contribution of each component of the model, we are conducting an ablation study of the SQuAD development group, shown in Table 2. Interactive alignment between context and query is most important for performance, as its decrease leads to a decrease of almost 5.5% on both metrics. This may be because similar semantics between query and context act as strong evidence for the correct response span. Self-alignment is responsible for about 2% of the performance deterioration, which clearly demonstrates the effectiveness of aligning context words against oneself. We suspect that self-alignment improves the flow of information with each word and alleviates the long-term dependency problem in long-term sequence such as context. To evaluate the performance of a mnemonic pointer layer, we are replacing the multi-hop query-sensitive response pointer with the standard time network (Vinyals et al., 2015), in which the self-conscious contextual representation of a query T in addition to the query summary of AD can be virtually replaced with a value-free AD."}, {"heading": "4.4 Result Analysis", "text": "In order to better understand the performance of the Mnemonic Reader, we first perform a quantitative analysis of the SQuAD development theorem. A natural point of interest is the analysis of how much the performance of the Mnemonic Reader improves through multi-hop reasoning, so we change the number of hops in the mnemonic pointing layer and compare their different performances, which is shown in Table 3. As we can see, the performance of both metrics is progressively increased as the number of hops increases. The model with 2 hops achieves the best performance, and the greater number of hops could potentially lead to an overadjustment of the training set, affecting performance. Next, we evaluate the performance of the F1 score divided by frequent query types shown in Figure 2. Here, we use the state-of-the-art BiDAF single model as a starting point. Mnemonic Reader comfortably exceeds the baseline in each query category."}, {"heading": "5 Conclusion", "text": "In this paper, we propose the Mnemonic Reader, an extended attention reader with mnemonic information such as self-confident display and multi-hop query-sensitive pointer. Experiments with the large-area SQuAD dataset showed that this mnemonic information leads to a significant improvement in performance. In the test dataset, our single model reaches an F1 value of 79.21%, while our ensemble model reaches an F1 value of 81.69%. For future work, we will introduce more useful mnemonic information to further expand the attention reader, such as general knowledge."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio."], "venue": "arXiv preprint arXiv:1409.0473 .", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "A thorough examination of the cnn/daily mail reading comprehension task", "author": ["Danqi Chen", "Jason Bolton", "Christopher D. Manning."], "venue": "Proceedings of ACL.", "citeRegEx": "Chen et al\\.,? 2016", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Reading wikipedia to answer opendomain questions", "author": ["Danqi Chen", "Adam Fisch", "Jason Weston", "Antoine Bordes."], "venue": "arXiv preprint arXiv:1704.00051 .", "citeRegEx": "Chen et al\\.,? 2017", "shortCiteRegEx": "Chen et al\\.", "year": 2017}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio."], "venue": "Proceedings of NIPS.", "citeRegEx": "Chung et al\\.,? 2014", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "Attention-overattention neural networks for reading comprehension", "author": ["Yiming Cui", "Zhipeng Chen", "Si Wei", "Shijin Wang", "Ting Liu", "Guoping Hu."], "venue": "arXiv preprint arXiv:1607.04423 .", "citeRegEx": "Cui et al\\.,? 2016", "shortCiteRegEx": "Cui et al\\.", "year": 2016}, {"title": "Gated-attention readers for text comprehension", "author": ["Bhuwan Dhingra", "Hanxiao Liu", "William W. Cohen", "Ruslan Salakhutdinov."], "venue": "arXiv preprint arXiv:1606.01549 .", "citeRegEx": "Dhingra et al\\.,? 2016", "shortCiteRegEx": "Dhingra et al\\.", "year": 2016}, {"title": "Ruminating reader: Reasoning with gated multi-hop attention", "author": ["Yichen Gong", "Samuel R. Bowman."], "venue": "arXiv preprint arXiv:1704.07415 .", "citeRegEx": "Gong and Bowman.,? 2017", "shortCiteRegEx": "Gong and Bowman.", "year": 2017}, {"title": "Deep learning", "author": ["Ian Goodfellow", "Yoshua Bengio", "Aaron Courville."], "venue": "MIT Press.", "citeRegEx": "Goodfellow et al\\.,? 2016", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2016}, {"title": "Teaching machines to read and comprehend", "author": ["Karl Moritz Hermann", "Tomas Kocisky", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom"], "venue": "Proceedings of NIPS", "citeRegEx": "Hermann et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2015}, {"title": "The goldilocks principle: Reading childrens books with explicit memory representations", "author": ["Felix Hill", "Antoine Bordes", "Sumit Chopra", "Jason Weston."], "venue": "Proceedings of ICLR.", "citeRegEx": "Hill et al\\.,? 2016", "shortCiteRegEx": "Hill et al\\.", "year": 2016}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "Jrgen Schmidhuber."], "venue": "Neural computation 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Text understanding with the attention sum reader network", "author": ["Rudolf Kadlec", "Martin Schmid", "Ondrej Bajgar", "Jan Kleindienst."], "venue": "Proceedings of ACL.", "citeRegEx": "Kadlec et al\\.,? 2016", "shortCiteRegEx": "Kadlec et al\\.", "year": 2016}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik P. Kingma", "Lei Jimmy Ba."], "venue": "CoRR, abs/1412.6980.", "citeRegEx": "Kingma and Ba.,? 2014", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Ask me anything: Dynamic memory networks for natural language processing ankit", "author": ["Ankit Kumar", "Peter Ondruska", "Mohit Iyyer", "James Bradbury", "Ishaan Gulrajani", "Victor Zhong", "Romain Paulus", "Richard Socher."], "venue": "CoRR, abs/1506.07285.", "citeRegEx": "Kumar et al\\.,? 2015", "shortCiteRegEx": "Kumar et al\\.", "year": 2015}, {"title": "Learning recurrent span representations for extractive question answering", "author": ["Kenton Lee", "Shimi Salant", "Tom Kwiatkowski", "Ankur Parikh", "Dipanjan Das", "Jonathan Berant."], "venue": "arXiv preprint arXiv:1611.01436 .", "citeRegEx": "Lee et al\\.,? 2016", "shortCiteRegEx": "Lee et al\\.", "year": 2016}, {"title": "Structural embedding of syntactic trees for machine comprehension", "author": ["Rui Liu", "Junjie Hu", "Wei Wei", "Zi Yang", "Eric Nyberg."], "venue": "arXiv preprint arXiv:1703.00572 .", "citeRegEx": "Liu et al\\.,? 2017", "shortCiteRegEx": "Liu et al\\.", "year": 2017}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Squad: 100,000+ questions for machine comprehension of text", "author": ["Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Rajpurkar et al\\.,? 2016", "shortCiteRegEx": "Rajpurkar et al\\.", "year": 2016}, {"title": "Mctest: A challenge dataset for the open-domainmachine comprehension of text", "author": ["Matthew Richardson", "Christopher JC Burges", "Erin Renshaw."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Richardson et al\\.,? 2013", "shortCiteRegEx": "Richardson et al\\.", "year": 2013}, {"title": "Bidirectional attention flow for machine comprehension", "author": ["Minjoon Seo", "Aniruddha Kembhavi", "Ali Farhadi", "Hananneh Hajishirzi."], "venue": "Proceedings of ICLR.", "citeRegEx": "Seo et al\\.,? 2017", "shortCiteRegEx": "Seo et al\\.", "year": 2017}, {"title": "Reasonet: Learning to stop reading in machine comprehension", "author": ["Yelong Shen", "Po-Sen Huang", "Jianfeng Gao", "Weizhu Chen."], "venue": "arXiv preprint arXiv:1609.05284 .", "citeRegEx": "Shen et al\\.,? 2016", "shortCiteRegEx": "Shen et al\\.", "year": 2016}, {"title": "Iterative alternating neural attention for machine reading", "author": ["Alessandro Sordonif", "Phillip Bachmanf", "Yoshua Bengiog."], "venue": "arXiv preprint arXiv:1606.02245 .", "citeRegEx": "Sordonif et al\\.,? 2016", "shortCiteRegEx": "Sordonif et al\\.", "year": 2016}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov."], "venue": "The Journal of Machine Learning Research pages 1929\u20131958.", "citeRegEx": "Srivastava et al\\.,? 2014", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Highway networks", "author": ["RupeshKumar Srivastava", "Klaus Greff", "Jurgen Schmidhuber."], "venue": "arXiv preprint arXiv:1505.00387 .", "citeRegEx": "Srivastava et al\\.,? 2015", "shortCiteRegEx": "Srivastava et al\\.", "year": 2015}, {"title": "End-to-end memory networks", "author": ["Sainbayar Sukhbaatar", "Arthur Szlam", "Jason Weston", "Rob Fergus."], "venue": "Proceedings of NIPS.", "citeRegEx": "Sukhbaatar et al\\.,? 2015", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2015}, {"title": "Pointer networks", "author": ["Oriol Vinyals", "Meire Fortunato", "Navdeep Jaitly."], "venue": "Proceedings of NIPS.", "citeRegEx": "Vinyals et al\\.,? 2015", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Machine comprehension using match-lstm and answer pointer", "author": ["Shuohang Wang", "Jing Jiang."], "venue": "Proceedings of ICLR.", "citeRegEx": "Wang and Jiang.,? 2017", "shortCiteRegEx": "Wang and Jiang.", "year": 2017}, {"title": "Multi-perspective context matching for machine comprehension", "author": ["Zhiguo Wang", "Haitao Mi", "Wael Hamza", "Radu Florian."], "venue": "arXiv preprint arXiv:1612.04211 .", "citeRegEx": "Wang et al\\.,? 2016", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Fastqa: A simple and efficient neural architecture for question answering", "author": ["Dirk Weissenborn", "Georg Wiese", "Laura Seiffe."], "venue": "arXiv preprint arXiv:1703.04816 .", "citeRegEx": "Weissenborn et al\\.,? 2017", "shortCiteRegEx": "Weissenborn et al\\.", "year": 2017}, {"title": "Dynamic coattention networks for question answering", "author": ["Caiming Xiong", "Victor Zhong", "Richard Socher."], "venue": "Proceedings of ICLR.", "citeRegEx": "Xiong et al\\.,? 2017", "shortCiteRegEx": "Xiong et al\\.", "year": 2017}, {"title": "Words or characters? fine-grained gating for reading comprehension", "author": ["Zhilin Yang", "Bhuwan Dhingra", "Ye Yuan", "Junjie Hu", "WilliamW. Cohen", "Ruslan Salakhutdinov."], "venue": "Proceedings of ICLR.", "citeRegEx": "Yang et al\\.,? 2017", "shortCiteRegEx": "Yang et al\\.", "year": 2017}, {"title": "End-to-end answer chunk extraction and ranking for reading comprehension", "author": ["Yang Yu", "Wei Zhang", "Kazi Hasan", "Mo Yu", "Bing Xiang", "Bowen Zhou."], "venue": "arXiv preprint arXiv:1610.09996 .", "citeRegEx": "Yu et al\\.,? 2016", "shortCiteRegEx": "Yu et al\\.", "year": 2016}, {"title": "Exploring question understanding and adaptation in neuralnetwork-based question answering", "author": ["Junbei Zhang", "Xiaodan Zhu", "Qian Chen", "Lirong Dai", "Si Wei", "Hui Jiang."], "venue": "arXiv preprint arXiv:1703.04617 .", "citeRegEx": "Zhang et al\\.,? 2017", "shortCiteRegEx": "Zhang et al\\.", "year": 2017}], "referenceMentions": [{"referenceID": 7, "context": "Benefiting from the rapid development of deep learning techniques (Goodfellow et al., 2016) and the large-scale benchmarks (Hermann et al.", "startOffset": 66, "endOffset": 91}, {"referenceID": 8, "context": ", 2016) and the large-scale benchmarks (Hermann et al., 2015; Hill et al., 2016; Rajpurkar et al., 2016), the endto-end neural based methods have achieved promising results on machine comprehension tasks.", "startOffset": 39, "endOffset": 104}, {"referenceID": 9, "context": ", 2016) and the large-scale benchmarks (Hermann et al., 2015; Hill et al., 2016; Rajpurkar et al., 2016), the endto-end neural based methods have achieved promising results on machine comprehension tasks.", "startOffset": 39, "endOffset": 104}, {"referenceID": 18, "context": ", 2016) and the large-scale benchmarks (Hermann et al., 2015; Hill et al., 2016; Rajpurkar et al., 2016), the endto-end neural based methods have achieved promising results on machine comprehension tasks.", "startOffset": 39, "endOffset": 104}, {"referenceID": 0, "context": "Among the existing methods, various attention mechanisms (Bahdanau et al., 2014) play a vital role to establish the interaction between the", "startOffset": 57, "endOffset": 80}, {"referenceID": 5, "context": "\u2022 In the interaction layer, the existing methods, such as Gated-Attention Reader (Dhingra et al., 2016), Multi-perspective Matching (Wang et al.", "startOffset": 81, "endOffset": 103}, {"referenceID": 28, "context": ", 2016), Multi-perspective Matching (Wang et al., 2016) and Dynamic Coattention Networks (Xiong et al.", "startOffset": 36, "endOffset": 55}, {"referenceID": 30, "context": ", 2016) and Dynamic Coattention Networks (Xiong et al., 2017), integrate the attentive information from query to construct the query-aware context representation.", "startOffset": 41, "endOffset": 61}, {"referenceID": 10, "context": "However, the existing models only adopt long short-term memory network (LSTM) (Hochreiter and Schmidhuber, 1997) or gated recurrent units (GRU) (Chung et al.", "startOffset": 78, "endOffset": 112}, {"referenceID": 3, "context": "However, the existing models only adopt long short-term memory network (LSTM) (Hochreiter and Schmidhuber, 1997) or gated recurrent units (GRU) (Chung et al., 2014) to model the contextual information of contexts, therefore they actually just model the local contextual information due to the long term dependency problem.", "startOffset": 144, "endOffset": 164}, {"referenceID": 26, "context": "\u2022 In the pointer layer, the pointer network (Vinyals et al., 2015) is used to predict the boundary of the answer.", "startOffset": 44, "endOffset": 66}, {"referenceID": 27, "context": "However, most of the existing methods, such as Answer Pointer (Wang and Jiang, 2017) and Ruminating Reader (Gong and Bowman, 2017), focus on the query-aware context representation and use query-independent pointer vector to select the answer boundary.", "startOffset": 62, "endOffset": 84}, {"referenceID": 6, "context": "However, most of the existing methods, such as Answer Pointer (Wang and Jiang, 2017) and Ruminating Reader (Gong and Bowman, 2017), focus on the query-aware context representation and use query-independent pointer vector to select the answer boundary.", "startOffset": 107, "endOffset": 130}, {"referenceID": 8, "context": "Later large cloze-style datasets such as CNN/DailyMail (Hermann et al., 2015) and Childrens Book Test (Hill et al.", "startOffset": 55, "endOffset": 77}, {"referenceID": 9, "context": ", 2015) and Childrens Book Test (Hill et al., 2016) were released, make it possible to solve RC tasks with deep neural architectures.", "startOffset": 32, "endOffset": 51}, {"referenceID": 18, "context": "The Stanford Question Answering Dataset (SQuAD) (Rajpurkar et al., 2016) is a more recently released dataset with over 100k queries-context pairs.", "startOffset": 48, "endOffset": 72}, {"referenceID": 16, "context": "Richardson et al. (2013) released the MCTest data which was too small to train end-to-end neural models.", "startOffset": 0, "endOffset": 25}, {"referenceID": 8, "context": "The most popular approach is using a single fix-sized query vector to attend to contexts, and the computed attention is then either used for fusing the context into a single vector (Hermann et al., 2015; Chen et al., 2016) or acting as a \u201dpointer\u201d (Vinyals et al.", "startOffset": 181, "endOffset": 222}, {"referenceID": 1, "context": "The most popular approach is using a single fix-sized query vector to attend to contexts, and the computed attention is then either used for fusing the context into a single vector (Hermann et al., 2015; Chen et al., 2016) or acting as a \u201dpointer\u201d (Vinyals et al.", "startOffset": 181, "endOffset": 222}, {"referenceID": 26, "context": ", 2016) or acting as a \u201dpointer\u201d (Vinyals et al., 2015) to indicate the position of the answer (Kadlec et al.", "startOffset": 33, "endOffset": 55}, {"referenceID": 11, "context": ", 2015) to indicate the position of the answer (Kadlec et al., 2016).", "startOffset": 47, "endOffset": 68}, {"referenceID": 1, "context": ", 2015; Chen et al., 2016) or acting as a \u201dpointer\u201d (Vinyals et al., 2015) to indicate the position of the answer (Kadlec et al., 2016). Sordonif et al. (2016) produces the query vector and document vector by computing the first-order attention twice, followed by a multi-hop iteration.", "startOffset": 8, "endOffset": 160}, {"referenceID": 20, "context": "BiDAF (Seo et al., 2017) computes both the context-to-query attention and the query-tocontext attention by using second-order attention.", "startOffset": 6, "endOffset": 24}, {"referenceID": 4, "context": "Cui et al. (2016) computes a query-level average attention based on the alignment matrix, which is then used to further compute a weighted sum of context-level attention.", "startOffset": 0, "endOffset": 18}, {"referenceID": 29, "context": "(Weissenborn et al., 2017; Zhang et al., 2017).", "startOffset": 0, "endOffset": 46}, {"referenceID": 33, "context": "(Weissenborn et al., 2017; Zhang et al., 2017).", "startOffset": 0, "endOffset": 46}, {"referenceID": 25, "context": "This is typically done by maintaining a memory state which incorporates the current information of reasoning with the previous information in the memory, called Memory Networks (Sukhbaatar et al., 2015; Kumar et al., 2015).", "startOffset": 177, "endOffset": 222}, {"referenceID": 14, "context": "This is typically done by maintaining a memory state which incorporates the current information of reasoning with the previous information in the memory, called Memory Networks (Sukhbaatar et al., 2015; Kumar et al., 2015).", "startOffset": 177, "endOffset": 222}, {"referenceID": 21, "context": "ReasoNet (Shen et al., 2016) combines the memory network with reinforcement learning to dynamically determine when to stop reading.", "startOffset": 9, "endOffset": 28}, {"referenceID": 30, "context": "Dynamic Coattention Networks (Xiong et al., 2017) utilizes a multi-hop pointing decoder to indicate the answer span iteratively.", "startOffset": 29, "endOffset": 49}, {"referenceID": 5, "context": "Dhingra et al. (2016) extends the attentionsum reader to multi-hop reasoning with a gating mechanism.", "startOffset": 0, "endOffset": 22}, {"referenceID": 12, "context": "At a more low-level granularity, the input layer also embeds each word x by encoding their character sequences with a convolutional neural network followed by max-pooling over time (Kim, 2014), resulting in a character-level embedding xc.", "startOffset": 181, "endOffset": 192}, {"referenceID": 20, "context": "Similar to BiDAF (Seo et al., 2017), word embeddings of both query and context are further transformed by the Highway Network (Srivastava et al.", "startOffset": 17, "endOffset": 35}, {"referenceID": 24, "context": ", 2017), word embeddings of both query and context are further transformed by the Highway Network (Srivastava et al., 2015), resulting in two word embedding matrices: XQ = [x q 1 , x q 2 , .", "startOffset": 98, "endOffset": 123}, {"referenceID": 10, "context": "In order to model the word sequence under its contextual information, we use a bidirectional long short-term memory network (BiLSTM) (Hochreiter and Schmidhuber, 1997) to encode both the context and the query as follows:", "startOffset": 133, "endOffset": 167}, {"referenceID": 29, "context": "Hence, it is hard to answer questions that require synthesizing information from different part of contexts (Weissenborn et al., 2017).", "startOffset": 108, "endOffset": 134}, {"referenceID": 33, "context": "To explicitly model the query category, we count the key word frequency of all queries and obtain top-9 most frequent query categories, which is similar in (Zhang et al., 2017): what, how, who, when, which, where, why, be, other, in which be stands for queries beginning with different forms of key word such as is, am and are.", "startOffset": 156, "endOffset": 176}, {"referenceID": 26, "context": "The probability distribution for the start position p(i) is computed by using a pointer network (Vinyals et al., 2015):", "startOffset": 96, "endOffset": 118}, {"referenceID": 18, "context": "Logistic Regression Baseline (Rajpurkar et al., 2016) 40.", "startOffset": 29, "endOffset": 53}, {"referenceID": 32, "context": "Dynamic Chunk Reader (Yu et al., 2016) 62.", "startOffset": 21, "endOffset": 38}, {"referenceID": 31, "context": "95 Fine-Grained Gating (Yang et al., 2017) 62.", "startOffset": 23, "endOffset": 42}, {"referenceID": 27, "context": "33 Match-LSTM with Ans-Ptr (Boundary) (Wang and Jiang, 2017) 67.", "startOffset": 38, "endOffset": 60}, {"referenceID": 15, "context": "02 RaSoR (Lee et al., 2016) 69.", "startOffset": 9, "endOffset": 27}, {"referenceID": 29, "context": "69 FastQAExt (Weissenborn et al., 2017) 70.", "startOffset": 13, "endOffset": 39}, {"referenceID": 2, "context": "Document Reader (Chen et al., 2017) 70.", "startOffset": 16, "endOffset": 35}, {"referenceID": 6, "context": "35 Ruminating Reader (Gong and Bowman, 2017) 70.", "startOffset": 21, "endOffset": 44}, {"referenceID": 33, "context": "45 jNet (Zhang et al., 2017) 70.", "startOffset": 8, "endOffset": 28}, {"referenceID": 30, "context": "82 Dynamic Coattention Networks (Xiong et al., 2017) 71.", "startOffset": 32, "endOffset": 52}, {"referenceID": 28, "context": "38 Multi-Perspective Matching (Wang et al., 2016) 73.", "startOffset": 30, "endOffset": 49}, {"referenceID": 20, "context": "26 BiDAF (Seo et al., 2017) 73.", "startOffset": 9, "endOffset": 27}, {"referenceID": 16, "context": "53 SEDT+BiDAF (Liu et al., 2017) 73.", "startOffset": 14, "endOffset": 32}, {"referenceID": 21, "context": "69 ReasoNet (Shen et al., 2016) 75.", "startOffset": 12, "endOffset": 31}, {"referenceID": 18, "context": "We use the Stanford Question Answering Dataset (SQuAD) (Rajpurkar et al., 2016) to evaluate our model.", "startOffset": 55, "endOffset": 79}, {"referenceID": 13, "context": "We use the Adam optimizer (Kingma and Ba, 2014) for training, with a minibatch size of 64 and an initial learning rate of 0.", "startOffset": 26, "endOffset": 47}, {"referenceID": 23, "context": "A dropout rate (Srivastava et al., 2014) of 0.", "startOffset": 15, "endOffset": 40}, {"referenceID": 17, "context": "Word embeddings are initialized with 100 dimensional Glove vectors (Pennington et al., 2014) and remain fixed during training, while the size of char embedding is set to be 10 and 100 1D filters are used for CNN.", "startOffset": 67, "endOffset": 92}, {"referenceID": 26, "context": "To evaluate the performance of mnemonic pointing layer, we replace the multi-hop query-sensitive answer pointer with the standard pointer network (Vinyals et al., 2015), where the self-aware context representation T alongside the query summary q\u0303 are fed into a feedforward neural network, outputting unnormalized probability distributions followed by the softmax function.", "startOffset": 146, "endOffset": 168}, {"referenceID": 29, "context": "Further ablation study shows that the simple exact match feature has positive effect on the overall performace, which has been demonstrated by Weissenborn et al.(2017). Finally, character embeddings have a notable influence on the perfor-", "startOffset": 143, "endOffset": 168}, {"referenceID": 20, "context": "mance which was already observed by Seo et al.(2017). We ran a simple statistics and found that 92.", "startOffset": 36, "endOffset": 53}], "year": 2017, "abstractText": "Recently, several end-to-end neural models have been proposed for machine comprehension tasks. Typically, these models use attention mechanisms to capture the complicated interaction between the context and the query and then point the boundary of answer. To better point the correct answer, we introduce the Mnemonic Reader for machine comprehension tasks, which enhance the attention reader in two aspects. Firstly, we use a self-alignment attention to model the long-distance dependency among context words, and obtain query-aware and selfaware contextual representation for each word in the context. Second, we use a memory-based query-dependent pointer to predict the answer, which integrates both explicit and implicit query information, such as query category. Our experimental evaluations show that our model obtains the state-of-the-art result on the large-scale machine comprehension benchmarks SQuAD.", "creator": "LaTeX with hyperref package"}}}