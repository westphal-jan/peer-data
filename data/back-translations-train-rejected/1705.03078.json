{"id": "1705.03078", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-May-2017", "title": "An Anthropic Argument against the Future Existence of Superintelligent Artificial Intelligence", "abstract": "This paper uses anthropic reasoning to argue for a reduced likelihood that superintelligent AI will come into existence in the future. To make this argument, a new principle is introduced: the Super-Strong Self-Sampling Assumption (SSSSA), building on the Self-Sampling Assumption (SSA) and the Strong Self-Sampling Assumption (SSSA). SSA uses as its sample the relevant observers, whereas SSSA goes further by using observer-moments. SSSSA goes further still and weights each sample proportionally, according to the size of a mind in cognitive terms. SSSSA is required for human observer-samples to be typical, given by how much non-human animals outnumber humans. Given SSSSA, the assumption that humans experience typical observer-samples relies on a future where superintelligent AI does not dominate, which in turn reduces the likelihood of it being created at all.", "histories": [["v1", "Mon, 8 May 2017 20:37:45 GMT  (77kb)", "http://arxiv.org/abs/1705.03078v1", "11 pages"]], "COMMENTS": "11 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["toby pereira"], "accepted": false, "id": "1705.03078"}, "pdf": {"name": "1705.03078.pdf", "metadata": {"source": "CRF", "title": "An Anthropic Argument against the Future Existence of Superintelligent Artificial Intelligence", "authors": ["Toby Pereira"], "emails": [], "sections": [{"heading": null, "text": "To make this argument, a new principle is introduced: the SuperStrong Self-Sampling Assumption (SSSSA), building on the Self-Sampling Assumption (SSA) and Strong Self-Sampling Assumption (SSSA). SSA uses the relevant observers as a sample, while SSSA goes further by using observer moments. SSSSA goes further and evaluates each sample proportionally, according to the size of a mind in cognitive terms. SSSSA is needed for human observer samples to be typical, as non-human animals outnumber humans. Given the assumption that humans experience typical observer samples, SSSSA relies on a future in which superintelligent AI does not dominate, which in turn reduces the likelihood that it will be created at all."}, {"heading": "1. Introduction to Anthropic Reasoning", "text": "The fact that we exist on Earth, a more life-friendly planet, may seem like a stroke of luck on the surface, but it could not really be otherwise. Likewise, all conscious observers must exist in a place compatible with their existence. So, if there is life at all in the universe, the fact that it will experience such a planet as a whole is inevitable. Likewise, we can only exist at a time in the universe and in Earth history if the conditions for life are right. So, if life can exist for only a small chunk of time, either on Earth or in the universe as a whole, we should not be surprised or happy that this time is not. But it is not just about absolutes - places and times where life can exist and cannot exist. Places and times can exist on a scale from very life-friendly to very life-hostile. As a hypothetical (and unrealistic) example, we could find out that there are several galaxies where life exists. But some could be more life-friendly than others."}, {"heading": "2. SSA, SSSA, SSSSA and Boltzmann Brains", "text": "This year, the time has come for us to find a solution that is capable, that we are able, that we are able to find a solution that is capable of us, that we are able to find a solution that is capable of us, that we are able to find a solution that is capable of us, that we are able to find a solution that is capable of us finding a solution, that we are able to find a solution that is capable of us finding a solution. \""}, {"heading": "3. Arguments against, and a Defence of, SSA, SSSA and SSSSA", "text": "It's not that we're in a situation where we're in a situation where we're able to survive ourselves, \"he said.\" But it's not that we're able to maneuver ourselves into such a situation, \"he said.\" But it's not that we're able to maneuver ourselves into such a situation. \""}, {"heading": "4. Superintelligent Artificial Intelligence and the Argument against its Future Existence", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "5. Attacks on Premise 1 \u2013 Simulations", "text": "In fact, it is the case that most of them are able to move to another world, in which they are able to move to another world, in which they are able to move to another world, in which they are able to move, in which they move, in which they move, in which they move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they are able to move, in which they live, in which they live, in which they live, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which"}, {"heading": "6. Attacks on Premise 2 \u2013 Chinese Room", "text": "This is an attack on premise 2: that the creation of a large number of AI + s would lead to them dominating the consciousness of people in space. John Searle's famous argument of Chinese space (e.g. 1980) is an attempt to show that no digital computer, however powerful, is conscious. Searle argues that anything digital computers do can lead to a deliberate manipulation of the brain, as is the case in our brains. Searle compares a computer to a person sitting in a room who is led through a hole. The person in the room does not understand Chinese, but he has instructions written in English and explains what to do with the Chinese lettering."}, {"heading": "7. Concluding Remarks", "text": "Nothing in this paper indicates that we categorically will not create super-intelligent artificial intelligence, but if we take the central argument seriously, we should ask ourselves questions about the likely future of the development of artificial intelligence. Nor does the argument itself provide us with any particular obstacle to the creation of super-intelligent artificial intelligence; it merely suggests that there may be such an obstacle. It may be that we will ultimately self-destruct, that it is much more difficult to create artificial intelligence than some people imagine, or anything else. But, to be clear, not only does this imply that humans on Earth are unlikely to create super-intelligent artificial intelligence, but that when we look at intelligent beings on the human level in the universe as a whole and in all other possibly existing universes, we should not expect enough of these races to develop super-intelligent artificial intelligence to dominate the Consciousness-Space Age. The point is that we should expect Earth to have a universal consciousness-like share of the entire space-time, if only it could be a reasonable one."}], "references": [{"title": "Anthropic Bias: Observation Selection Effects in Science", "author": ["N. Bostrom"], "venue": null, "citeRegEx": "Bostrom,? \\Q2002\\E", "shortCiteRegEx": "Bostrom", "year": 2002}, {"title": "Are you living in a computer simulation? Philosophical Quarterly, 53 (211), pp", "author": ["N. Bostrom"], "venue": "243-255.", "citeRegEx": "Bostrom,? 2003", "shortCiteRegEx": "Bostrom", "year": 2003}, {"title": "Why Boltzmann brains are bad", "author": ["S.M. Carroll"], "venue": "arXiv:1702.00850 [hep-th]", "citeRegEx": "Carroll,? 2017", "shortCiteRegEx": "Carroll", "year": 2017}, {"title": "The singularity: a philosophical analysis", "author": ["D.J. Chalmers"], "venue": "Journal of Consciousness Studies, 17, pp. 7-65.", "citeRegEx": "Chalmers,? 2010", "shortCiteRegEx": "Chalmers", "year": 2010}, {"title": "The End of the World: The Science and Ethics of Human Extinction", "author": ["J. Leslie"], "venue": "London: Routledge.", "citeRegEx": "Leslie,? 1996", "shortCiteRegEx": "Leslie", "year": 1996}, {"title": "From the phenomenology to the mechanisms of consciousness: integrated information theory 3.0", "author": ["M. Oizumi", "L. Albantakis", "G. Tononi"], "venue": "PLoS Computational Biology,", "citeRegEx": "Oizumi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Oizumi et al\\.", "year": 2014}, {"title": "Stuff and Consciousness: Connecting Matter and Mind", "author": ["T. Pereira"], "venue": "Rayne, UK: Toby Pereira.", "citeRegEx": "Pereira,? 2014", "shortCiteRegEx": "Pereira", "year": 2014}, {"title": "Minds, brains, and programs", "author": ["J.R. Searle"], "venue": "Behavioral and Brain Sciences, 3 (3), pp. 417-457.", "citeRegEx": "Searle,? 1980", "shortCiteRegEx": "Searle", "year": 1980}, {"title": "Phi: A Voyage from the Brain to the Soul", "author": ["G. Tononi"], "venue": "New York: Pantheon Books.", "citeRegEx": "Tononi,? 2012", "shortCiteRegEx": "Tononi", "year": 2012}], "referenceMentions": [{"referenceID": 2, "context": "See Carroll (2017) for a recent discussion of Boltzmann Brains in physics.", "startOffset": 4, "endOffset": 19}, {"referenceID": 8, "context": "Tononi (2012); Oizumi, Albantakis & Tononi (2014).", "startOffset": 0, "endOffset": 14}, {"referenceID": 8, "context": "Tononi (2012); Oizumi, Albantakis & Tononi (2014). In his book Phi: A Voyage from the Brain to the Soul, Tononi (ibid.", "startOffset": 0, "endOffset": 50}, {"referenceID": 3, "context": "David Chalmers (2010) defines AI++ as AI that dwarfs the intelligence of the most intelligent human by at least as much as this human\u2019s intelligence dwarfs that of a mouse, and it seems sensible to use the same terminology here.", "startOffset": 6, "endOffset": 22}, {"referenceID": 6, "context": "This argument is not generally accepted and I won\u2019t go into it in great detail here, although I discuss it in more detail in my book (Pereira, 2014).", "startOffset": 133, "endOffset": 148}], "year": 2017, "abstractText": "This paper uses anthropic reasoning to argue for a reduced likelihood that superintelligent AI will come into existence in the future. To make this argument, a new principle is introduced: the SuperStrong Self-Sampling Assumption (SSSSA), building on the Self-Sampling Assumption (SSA) and the Strong Self-Sampling Assumption (SSSA). SSA uses as its sample the relevant observers, whereas SSSA goes further by using observer-moments. SSSSA goes further still and weights each sample proportionally, according to the size of a mind in cognitive terms. SSSSA is required for human observer-samples to be typical, given by how much non-human animals outnumber humans. Given SSSSA, the assumption that humans experience typical observer-samples relies on a future where superintelligent AI does not dominate, which in turn reduces the likelihood of it being created at all.", "creator": "Writer"}}}