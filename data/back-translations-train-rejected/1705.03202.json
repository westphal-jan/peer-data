{"id": "1705.03202", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2017", "title": "Does William Shakespeare REALLY Write Hamlet? Knowledge Representation Learning with Confidence", "abstract": "Knowledge graphs (KGs) can provide significant relational information and have been widely utilized in various tasks. However, there may exist amounts of noises and conflicts in KGs, especially in those constructed automatically with less human supervision. To address this problem, we propose a novel confidence-aware knowledge representation learning framework (CKRL), which detects possible noises in KGs while learning knowledge representations with confidence simultaneously. Specifically, we introduce the triple confidence to conventional translation-based methods for knowledge representation learning. To make triple confidence more flexible and universal, we only utilize the internal structural information in KGs, and propose three kinds of triple confidences considering both local triple and global path information. We evaluate our models on knowledge graph noise detection, knowledge graph completion and triple classification. Experimental results demonstrate that our confidence-aware models achieve significant and consistent improvements on all tasks, which confirms the capability of our CKRL model in both noise detection and knowledge representation learning.", "histories": [["v1", "Tue, 9 May 2017 06:46:21 GMT  (214kb,D)", "http://arxiv.org/abs/1705.03202v1", "7 pages"]], "COMMENTS": "7 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ruobing xie", "zhiyuan liu", "maosong sun"], "accepted": false, "id": "1705.03202"}, "pdf": {"name": "1705.03202.pdf", "metadata": {"source": "CRF", "title": "Does William Shakespeare REALLY Write Hamlet? Knowledge Representation Learning with Confidence", "authors": ["Ruobing Xie", "Zhiyuan Liu", "Maosong Sun"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In this context, it should be noted that this is a very complex situation in which both sides are mutually supportive."}, {"heading": "2 Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Knowledge Graph Noise Detection", "text": "It seems inevitable that noises exist and can severely impair the acquisition of knowledge [Manago and Kodratoff, 1987], so that the recognition of noises is indispensable for the construction and application of knowledge. Most recognition of noises occurs in the creation of knowledge graphs. For example, YAGO2 extracts knowledge from Wikipedia under human supervision so that human judges are confronted with selected facts for which they have to judge the accuracy [Hoffart et al., 2013]. Wikidata also relies on crowdsourcing software where employees can reject or approve a statement [Pellissier Tanon et al., 2016]. DBpedia creates its assignments to Wikipedia Infoboxes through a worldwide crowd sourcing effort [Lehmann et al., 2015]. These recognition of noises in large KGGs are usually associated with enormous human efforts that are extremely labor-intensive and time consuming."}, {"heading": "2.2 Translation-based KRL Methods", "text": "TransE [Bordes et al., 2013] projects both units and relations into a continuous low-dimensional vector space and interprets relations as translation operations between head and tail units. (1) TransE can well balance effectiveness and efficiency compared to conventional methods, while the overly simplified translation assumption limits performance in dealing with complicated relationships. Some improved translation-based methods attempt to solve this problem with translations on relationship-specific hyperplanes [Wang et al., 2014], relation-specific entity projection [Lin et al., 2015b], and type-specific entity projection [Xie, Get], which are based on the assumption that all knowledge in conventional hyperplanes [Wang et al., 2014] is relation-specific entity projection."}, {"heading": "3 Methodology", "text": "Faced with a threefold fact (h, r, t), we consider the head and tail units h, t, E, and the relationship r, where E and R represent the entirety of the units and relationships. T represents the threefold training factors, including possible conflicts and noises. In order to detect possible noises in knowledge diagrams and obtain better representations of knowledge, we introduce a novel concept of threefold confidence for each threefold fact. Triple confidence describes the probability of threefold correctness, which could be measured using both internal structural information and external heterogeneous information."}, {"heading": "3.1 Confidence-aware KRL Framework", "text": "We try to detect sounds and learn better representations of knowledge taking into account triple confidence, focusing more on these tripartite combinations with high confidence. Following the translation-based framework, we design our confidence-based CRL energy function as follows: E (T) = \u2211 (h, r, t) \u0445 TE (h, r, t) \u00b7 C (h, r, t). (2) The confidence-based energy function can be divided into two parts: E (h, r, t) = | h + r \u2212 t | stands for the dissimilarity between head, relationship and tail, which is identical to that of TransE. A lower dissimilarity indicates that its corresponding tripartite composition might be better suited to the translation assumption. While we differ from conventional methods, we also introduce the triple trust C (h, r, t) as the second part of our energy function. A higher triple confidence implies that the tripartite knowledge can be considered as both tripartially believable and tripartially believable according to this trust structure."}, {"heading": "3.2 Objective Formalization", "text": "In this section, we present the detailed training objective of our model. Following TransE [Bordes et al., 2013], we formalize a margin-based score function with negative sampling as a training objective. This paired score function attempts to make the scores of positive triples higher than the negative triples. We have: L = \u2211 (h, r, t), (h, r, t), \"T\" max (0, \u03b3 + E (h, r, t) \u2212 E (h, r, t))) \u00b7 C (h, r, t), (3), where E (h, r, t) is the dissimilarity score of positive triples and E (h, r, t) is the negative triple."}, {"heading": "3.3 Local Triple Confidence", "text": "Since our CKRL framework follows the translation assumption that h + r't should perform well under the translation rule, it is easy to directly use the dissimilarity function to assess triple trust. Furthermore, in order to assess the promising results of conventional translation-based methods based on triple classification, we confirm that positive triples should match the translation rule. We assume that the more a triple matches the translation rule, the more convincingly this triple trust should be taken into account. To measure local triple trust during the training, we first assess the current conformity of each triple with the translation assumption. Inspired by the margin-based training strategy, we use the same pair function to calculate triple quality Q (h, r, t) as follows: Q (h, t) = \u2212 (g + E (h, t) \u2212 E (h \u2032, r, t \u2032)."}, {"heading": "3.4 Global Path Confidence", "text": "Local triple reliability is simple and effective, while mere concentration on the interior of triples is not able to use rich global structural information in knowledge diagrams. Relationship paths can provide rich global information as supporting evidence for triples. For example, given the relationship path (h, born in the city, e) and (e, in the nation, t), we can conclude with great confidence that (h, born in the nation, t). Therefore, we propose global path trust to consider multi-level relationship paths. We assume that a triplicate is considered more credible if it has more reliable paths that come semantically close to the corresponding relationship. In the following subsections, we first present how the reliability of the relationship path can be quantified at triple reliability, and then propose two strategies that measure the relationship between mantic similarities based on co-event information and learned knowledge representations."}, {"heading": "Relation Path Reliability", "text": "We assume that a relationship path should be considered more important if it exhibits more information flow from head to tail entity. Specifically, we follow the path constraint resource allocation (PCRA) [Lin et al., 2015a] to measure the relationship path reliability, and the key idea of PCRA is inspired by the resource allocation [Zhou et al., 2007], which assumes that there are certain resources associated with the head unit h, and that will flow through all relation paths. Finally, the amount of resources flowing through a specific path p to the tail entity t is considered as the relation path reliability of p (h, t).Formally, considering a path p = (r1, \u00b7 \u00b7, rl) and entity pair (h, t), the resource in h is considered to flow through l steps to t (l steps), since there are multiple paths, where there are \u2212 ri and \u2212 ri paths."}, {"heading": "Prior Path Confidence", "text": "We first introduce the previous path trust (PP), which uses the simultaneous occurrence of relationship and path to represent their dissimilarity. We assume that the more a relationship with a path occurs, the more likely it is that they represent similar semantic meanings. Formally, the quality of the i-th relationship path pair (r, pi) is written as follows: QPP (r, pi) = + (1 \u2212) P (r, pi) P (pi) P (pi), (pi) 8), where P (r, pi) represents the previous probability of r and pi occurrence, and P (pi) the previous probability of pi in KG. is a hyperparameter for smoothing the path. Therefore, the previous path trust (PP) is structured as follows: PP (h, r, t) is the previous probability of the pi path in KG."}, {"heading": "Adaptive Path Confidence", "text": "The previous path trust remains static during training, which is inflexible and may be severely constrained by existing noise and conflicts in KGs. To solve this problem, we propose the adaptive path security (AP), which could flexibly learn the qualities of relation path according to their learned embeddings. Following the translation assumption, we define a new relation path quality function of AP as follows: QAP (r, pi) = | r \u2212 pi | | r \u2212 (ri1 + \u00b7 + rik) | |. (10) Assuming that the embedding of the relationship should be similar to the embedding of the path, a lower QAP (r, pi) implies a more convincing relationship path pair. The adaptive path trust is then written as follows: AP (h, r, t) = denser than the embedding (h, pi, pi), pi \u00b7, triple (3), dynamic (P)."}, {"heading": "3.5 Optimization and Implementation Details", "text": "In training, all entity and relation embeddings can either be randomly initialized or pre-trained with TransE, with local triple security initialized as 1 for all triples. For those entities that do not have paths, we set their path-based trust directly as 0.path selection, which will have a significant impact on performance. As the number of paths increases exponentially with the increase in maximum path length, it is impractical to list all paths in kg. Furthermore, the path-based inference will be much weaker if the logical chain goes too far. Considering both effectiveness and efficiency, we limit the maximum length of paths to a maximum of 2 steps. Since relationships are oriented edges, we also consider these inverted relationships when we recognize relationship paths."}, {"heading": "4 Experiment", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Datasets", "text": "In this paper, we evaluate our confidence-based models based on FB15K [Bordes et al., 2013], which is a typical benchmark knowledge graph extracted from Freebase [Bollacker et al., 2008]. However, there are no explicitly designated sounds or conflicts in FB15K. Therefore, we generate new data sets with different probabilities of sounds based on FB15K to simulate the real knowledge graphs that are automatically constructed with less human annotations. Inspired by pre-processing in the evaluation task called triple classification, we construct negative triples using the same setting in [Socher et al., 2013]. Specifically, we randomly switch one of head or tail entities to form a negative triple (h, r, t) or (h, r, t) entity based on a positive triple (h, r, t)."}, {"heading": "4.2 Experimental Settings", "text": "In experiments, we evaluate our confidence-based CRL models with three different confidence combination strategies. CKRL (LT) represents the strategy that only takes into account local triple trust, CKRL (LT + PP) takes into account both local triple trust and previous path trust, while CKRL (LT + PP + AP) takes into account all three types of trust. We implement TransE [Bordes et al., 2013] as a starting point, since our CKRL framework is based on TransE, and it is not difficult for our confidence framework to be used in other advanced translation-based methods. We train our CKRL model using mini-batch SGD with the margin between {0.5, 1.0, 2.0}. We choose the general learning rate between {0.0005, 0.001, 0.002} specified in training. For local triple trust, we choose the GKRL controller {0.0001, 0.0001, 0.0001, 0.0001, and 0.0001 controller}."}, {"heading": "4.3 Knowledge Graph Noise Detection", "text": "In order to verify the ability of our CCRL models to distinguish between noises and conflicts in knowledge diagrams, we propose a new assessment task called Knowledge Graph Noise Detection, which aims to detect possible noises in knowledge diagrams by their triple values."}, {"heading": "Evaluation Protocol", "text": "Inspired by the triple classification evaluation metric in [Socher et al., 2013], we consider the energy function values E (h, r, t) = | | h + r \u2212 t | | as our triple values and then rate all triples in the training set according to these values. These triples with higher values are initially considered noise. We use precision / recall curves to show the performance."}, {"heading": "Experimental Results", "text": "Figure 2 shows the Knowledge Chart Noise Recognition results, which allow us to observe: (1) Our confidence-based CRL models perform best on all three data sets with different noise ratios. It confirms the ability of our CCRL models to model triple trust and detect noise and conflicts in knowledge diagrams. (2) CCRL (LT + PP + AP) exhibits significant and consistent improvements in noise detection compared to other confidence-based strategies. It indicates that adaptive path trust could provide more flexible and credible evidence for noise detection. In addition, CKRL (LT + PP + AP) achieves an impressive 84% of accuracy at different noise ratios when the recall is 10%, meaning that our models could be really helpful in the real detection of KGG noise. (3) CKLL (LAP + CT + PP) indicates that this power function may be more qualified than a local one, which also indicates that LPP + CT has a better performance than a local one."}, {"heading": "4.4 Knowledge Graph Completion", "text": "The completion of knowledge graphs is a classical evaluation task that focuses on the quality of knowledge representations [Bordes et al., 2012]. This task aims to complete a triple if one of head, tail or relation is missing, which can be considered an easy task to answer questions."}, {"heading": "Evaluation Protocol", "text": "In this paper, we mainly focus on predicting entities based on the translation assumption of h + r't. Following the same settings in [Bordes et al., 2013], we perform two metrics as our evaluation metrics: (1) the mean rank of the correct entities and (2) Hits @ 10, which indicates the proportion of correct answers ranked in the top 10. We also follow the different evaluation settings of \"Raw\" and \"Filter\" used in [Bordes et al., 2013]."}, {"heading": "Experimental Results", "text": "In Table 2 we show the results of the entity prediction with different noise ratios. We can observe the following: (1) All confidence-conscious SVL models are able to detect sounds in knowledge diagrams, but could also achieve good results in completing knowledge diagrams. (2) Comparing the evaluation results between different sets of data, we find that the improvements introduced by our confidence-conscious methods become more significant the higher the noise percentage in KGs. It suggests that sounds are harmful to the entity prediction, and on the other hand confirms that taking into account the threefold confidence in knowledge representation is crucial. (3) It seems that global path confidence has few contributions to the entity prediction. It could be due to the uncertainty and incompleteness of the path information caused by noise and limited path selection. In parameter analyses, we find that while the confidence prediction improves, this weight within the confidence prediction is affected."}, {"heading": "4.5 Triple Classification", "text": "The triple classification aims to predict whether or not a triple in the test set is correct, according to the dissimilarity function, which could be considered a binary classification task. Triple classification could also be considered an easier task for detecting sounds in the test set, as the sounds in the training set affect the construction of knowledge representations, while the negative triples generated in the test set do not."}, {"heading": "Evaluation Protocol", "text": "Since there are no explicit negative triples in existing knowledge graphs, we construct negative triples in the validation and test set according to the same protocol in [Socher et al., 2013]. We also assure that the number of generated negative triples should correspond to the number of positive triples. Classification is done as follows: We first learn different thresholds for each relationship, which are optimized for validation set by maximizing classification accuracy. In the classification, if the energy function | | h + r \u2212 t | < \u03b4r is rated three times positive and otherwise negative."}, {"heading": "Experimental Results", "text": "Table 3 shows the results of the triple classification. We can observe the following: (1) The CCRL models perform better on all data sets, and the improvements become more significant on higher levels of noise. They confirm that triple-trust learning recognition representations could also be helpful on the triple classification. (2) The advantages of trusting models over the initial situation in this task appear to be smaller than on noise detection. This is because the CCRL models focus more on the internal information of triples in the training set, while the improvements in triple classification can only come from better knowledge representations. Although CCRL models learn better knowledge representations, conventional models without trust can also achieve good results."}, {"heading": "5 Conclusion and Future Work", "text": "In this paper, we propose a novel CCRL model that aims to detect sounds in knowledge diagrams while learning knowledge representations. To make our models more flexible and universal, we only consider internal structural information in CGs to define local triple trust and global path trust. Experimental results suggest that our CCRL framework can capture both local and global structural information well to measure triple trust, which is essential for detecting noise in CGs and learning better knowledge representations. In the future, we will explore the following directions of research: (1) External information such as text information could provide complementary messages to assess triple trust. We will explore how to combine external heterogeneous information with internal structural information for better triple trust. (2) We will explore appropriate methods to combine our trusting framework with possible structural knowledge building, and combine it with structural knowledge building."}], "references": [{"title": "Dbpedia: A nucleus for a web of open data", "author": ["S\u00f6ren Auer", "Christian Bizer", "Georgi Kobilarov", "Jens Lehmann", "Richard Cyganiak", "Zachary Ives"], "venue": "The semantic web, pages 722\u2013735.", "citeRegEx": "Auer et al.. 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["Kurt Bollacker", "Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor"], "venue": "Proceedings of KDD, pages 1247\u20131250,", "citeRegEx": "Bollacker et al.. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "In Proceedings of AISTATS", "author": ["Antoine Bordes", "Xavier Glorot", "Jason Weston", "Yoshua Bengio. Joint learning of words", "meaning representations for open-text semantic parsing"], "venue": "pages 127\u2013135,", "citeRegEx": "Bordes et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "In Proceedings of NIPS", "author": ["Antoine Bordes", "Nicolas Usunier", "Alberto Garcia-Duran", "Jason Weston", "Oksana Yakhnenko. Translating embeddings for modeling multirelational data"], "venue": "pages 2787\u20132795,", "citeRegEx": "Bordes et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Knowledgebased systems", "author": ["Pasquale De Meo", "Emilio Ferrara", "Giacomo Fiumara", "Angela Ricciardello. A novel measure of edge centrality in social networks"], "venue": "30:136\u2013150,", "citeRegEx": "De Meo et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "In Proceedings of VLDB", "author": ["Zolt\u00e1n Gy\u00f6ngyi", "Hector GarciaMolina", "Jan Pedersen. Combating web spam with trustrank"], "venue": "pages 576\u2013587,", "citeRegEx": "Gy\u00f6ngyi et al.. 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "Towards vandalism detection in knowledge bases: Corpus construction and analysis", "author": ["Stefan Heindorf", "Martin Potthast", "Benno Stein", "Gregor Engels"], "venue": "Proceedings of SIGIR, pages 831\u2013834,", "citeRegEx": "Heindorf et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "In Proceedings of CIKM", "author": ["Stefan Heindorf", "Martin Potthast", "Benno Stein", "Gregor Engels. Vandalism detection in wikidata"], "venue": "pages 327\u2013336,", "citeRegEx": "Heindorf et al.. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Yago2: A spatially and temporally enhanced knowledge base from wikipedia", "author": ["Johannes Hoffart", "Fabian M Suchanek", "Klaus Berberich", "Gerhard Weikum"], "venue": "Artificial Intelligence, 194:28\u201361,", "citeRegEx": "Hoffart et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "In Proceedings of ISWC", "author": ["Denis Krompa\u00df", "Stephan Baier", "Volker Tresp. Type-constrained representation learning in knowledge graphs"], "venue": "pages 640\u2013 655.", "citeRegEx": "Krompa\u00df et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Dbpedia\u2013a large-scale, multilingual knowledge base extracted from wikipedia", "author": ["Lehmann et al", "2015] Jens Lehmann", "Robert Isele", "Max Jakob", "Anja Jentzsch", "Dimitris Kontokostas", "Pablo N Mendes", "Sebastian Hellmann", "Mohamed Morsey", "Patrick Van Kleef", "S\u00f6ren Auer"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "In Proceedings of EMNLP", "author": ["Yankai Lin", "Zhiyuan Liu", "Huanbo Luan", "Maosong Sun", "Siwei Rao", "Song Liu. Modeling relation paths for representation learning of knowledge bases"], "venue": "pages 705\u2013714,", "citeRegEx": "Lin et al.. 2015a", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning entity and relation embeddings for knowledge graph completion", "author": ["Yankai Lin", "Zhiyuan Liu", "Maosong Sun", "Yang Liu", "Xuan Zhu"], "venue": "Proceedings of AAAI,", "citeRegEx": "Lin et al.. 2015b", "shortCiteRegEx": null, "year": 2015}, {"title": "volume 1", "author": ["Yankai Lin", "Shiqi Shen", "Zhiyuan Liu", "Huanbo Luan", "Maosong Sun. Neural relation extraction with selective attention over instances. In Proceedings of ACL"], "venue": "pages 2124\u20132133,", "citeRegEx": "Lin et al.. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "In Proceedings of IJCAI", "author": ["Michel Manago", "Yves Kodratoff. Noise", "knowledge acquisition"], "venue": "pages 348\u2013354,", "citeRegEx": "Manago and Kodratoff. 1987", "shortCiteRegEx": null, "year": 1987}, {"title": "From freebase to wikidata: The great migration", "author": ["Thomas Pellissier Tanon", "Denny Vrande\u010di\u0107", "Sebastian Schaffert", "Thomas Steiner", "Lydia Pintscher"], "venue": "Proceedings of WWW, pages 1419\u20131428,", "citeRegEx": "Pellissier Tanon et al.. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "In Proceedings of NIPS", "author": ["Richard Socher", "Danqi Chen", "Christopher D Manning", "Andrew Ng. Reasoning with neural tensor networks for knowledge base completion"], "venue": "pages 926\u2013934,", "citeRegEx": "Socher et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "In Proceedings of AAAI", "author": ["Zhen Wang", "Jianwen Zhang", "Jianlin Feng", "Zheng Chen. Knowledge graph embedding by translating on hyperplanes"], "venue": "pages 1112\u20131119,", "citeRegEx": "Wang et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Representation learning of knowledge graphs with hierarchical types", "author": ["Ruobing Xie", "Zhiyuan Liu", "Maosong Sun"], "venue": "Proceedings of IJCAI,", "citeRegEx": "Xie et al.. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Physical Review E", "author": ["Tao Zhou", "Jie Ren", "Mat\u00fa\u0161 Medo", "YiCheng Zhang. Bipartite network projection", "personal recommendation"], "venue": "76(4):046115,", "citeRegEx": "Zhou et al.. 2007", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 1, "context": "There are existing amounts of widely-utilized large-scale knowledge graphs such as Freebase [Bollacker et al., 2008], DBpedia [Auer et al.", "startOffset": 92, "endOffset": 116}, {"referenceID": 0, "context": ", 2008], DBpedia [Auer et al., 2007] and other domain-specific KGs.", "startOffset": 17, "endOffset": 36}, {"referenceID": 13, "context": "For instance, the state-of-the-art relation extraction model on benchmark achieves only around 60% precision when the recall is 20% [Lin et al., 2016].", "startOffset": 132, "endOffset": 150}, {"referenceID": 7, "context": "Moreover, [Heindorf et al., 2016] focuses on vandalism detection in Wikidata, which also implies the existence and problems of noises in large-scale KGs.", "startOffset": 10, "endOffset": 33}, {"referenceID": 3, "context": "More specifically, the CKRL model follows the translationbased framework proposed by [Bordes et al., 2013], and learns knowledge representations with triple confidences.", "startOffset": 85, "endOffset": 106}, {"referenceID": 14, "context": "It seems to be inevitable that noises do exist and can strongly affect knowledge acquisition [Manago and Kodratoff, 1987], so that noise detection is essential in knowledge construction and knowledge application.", "startOffset": 93, "endOffset": 121}, {"referenceID": 8, "context": "For instance, YAGO2 extracts knowledge from Wikipedia with human supervision that human judges are presented with selected facts for which they have to assess the correctness [Hoffart et al., 2013].", "startOffset": 175, "endOffset": 197}, {"referenceID": 15, "context": "Wikidata also relies on a crowdsourced human curation software in which contributors can reject or approve a statement [Pellissier Tanon et al., 2016].", "startOffset": 119, "endOffset": 150}, {"referenceID": 6, "context": "As for automatical KG noise detection, a novel task named Wikidata vandalism, which aims to combat with deliberate destructions in knowledge graphs, has attracted wide attention [Heindorf et al., 2015].", "startOffset": 178, "endOffset": 201}, {"referenceID": 7, "context": "However, most existing methods on this task mainly concentrate on feature selection from contents, users, items and revisions [Heindorf et al., 2016], and thus are constrained with the completeness of external information.", "startOffset": 126, "endOffset": 149}, {"referenceID": 5, "context": "There are also some efforts working on judging importance on graphs for nodes [Gy\u00f6ngyi et al., 2004] or for edges [De Meo et al.", "startOffset": 78, "endOffset": 100}, {"referenceID": 4, "context": ", 2004] or for edges [De Meo et al., 2012], but few works concentrating on the confidence of each triple.", "startOffset": 21, "endOffset": 42}, {"referenceID": 3, "context": "TransE [Bordes et al., 2013] projects both entities and relations into a continuous low-dimensional vector space, interpreting relations as translating operations between head and tail entities.", "startOffset": 7, "endOffset": 28}, {"referenceID": 17, "context": "Some enhanced translation-based methods attempt to solve this problem with translations on relation-specific hyperplanes [Wang et al., 2014], relationspecific entity projection [Lin et al.", "startOffset": 121, "endOffset": 140}, {"referenceID": 12, "context": ", 2014], relationspecific entity projection [Lin et al., 2015b] and type-specific entity projection [Xie et al.", "startOffset": 44, "endOffset": 63}, {"referenceID": 18, "context": ", 2015b] and type-specific entity projection [Xie et al., 2016].", "startOffset": 45, "endOffset": 63}, {"referenceID": 11, "context": "[Lin et al., 2015a] extends TransE by encoding multistep relation path information into knowledge representation learning.", "startOffset": 0, "endOffset": 19}, {"referenceID": 3, "context": "Following TransE [Bordes et al., 2013], we formalize a margin-based score function with negative sampling as objective for training.", "startOffset": 17, "endOffset": 38}, {"referenceID": 11, "context": "Specifically, we follow the path-constraint resource allocation (PCRA) [Lin et al., 2015a] to measure the relation path reliability.", "startOffset": 71, "endOffset": 90}, {"referenceID": 19, "context": "The key idea of PCRA is inspired by resource allocation [Zhou et al., 2007], which supposes there are certain resources associated with head entity h, and will flow throughout the whole knowledge graph via all relation paths.", "startOffset": 56, "endOffset": 75}, {"referenceID": 3, "context": "In this paper, we evaluate our confidence-aware models based on FB15K [Bordes et al., 2013], which is a typical benchmark knowledge graph extracted from Freebase [Bollacker et al.", "startOffset": 70, "endOffset": 91}, {"referenceID": 1, "context": ", 2013], which is a typical benchmark knowledge graph extracted from Freebase [Bollacker et al., 2008].", "startOffset": 78, "endOffset": 102}, {"referenceID": 16, "context": "Inspired by the preprocessing in the evaluation task named triple classification, we construct negative triples following the same setting in [Socher et al., 2013].", "startOffset": 142, "endOffset": 163}, {"referenceID": 9, "context": "We can directly utilize entity type information in Freebase or follow the local closed-world assumption [Krompa\u00df et al., 2015] to collect entity constraint information.", "startOffset": 104, "endOffset": 126}, {"referenceID": 3, "context": "We implement TransE [Bordes et al., 2013] as baseline since our CKRL framework is based on TransE, and it is not difficult for our confidence framework to be utilized in other enhanced translation-based methods.", "startOffset": 20, "endOffset": 41}, {"referenceID": 16, "context": "Inspired by the evaluation metric of triple classification in [Socher et al., 2013], we consider the energy function scores E(h, r, t) = ||h+r\u2212t|| as our triple scores, and then rank all triples in training set according to these scores.", "startOffset": 62, "endOffset": 83}, {"referenceID": 2, "context": "Knowledge graph completion is a classical evaluation task that concentrates on the quality of knowledge representations [Bordes et al., 2012].", "startOffset": 120, "endOffset": 141}, {"referenceID": 3, "context": "Following the same settings in [Bordes et al., 2013], we conduct two measures as our evaluation metrics: (1) Mean Rank of correct entities, and (2) Hits@10 that indicates the proportion of correct answers ranked in top 10.", "startOffset": 31, "endOffset": 52}, {"referenceID": 3, "context": "different evaluation settings of \u201cRaw\u201d and \u201cFilter\u201d utilized in [Bordes et al., 2013].", "startOffset": 64, "endOffset": 85}, {"referenceID": 16, "context": "Since there are no explicit negative triples in existing knowledge graphs, we construct negative triples in validation and test set following the same protocol in [Socher et al., 2013].", "startOffset": 163, "endOffset": 184}], "year": 2017, "abstractText": "Knowledge graphs (KGs) can provide significant relational information and have been widely utilized in various tasks. However, there may exist amounts of noises and conflicts in KGs, especially in those constructed automatically with less human supervision. To address this problem, we propose a novel confidence-aware knowledge representation learning framework (CKRL), which detects possible noises in KGs while learning knowledge representations with confidence simultaneously. Specifically, we introduce the triple confidence to conventional translation-based methods for knowledge representation learning. To make triple confidence more flexible and universal, we only utilize the internal structural information in KGs, and propose three kinds of triple confidences considering both local triple and global path information. We evaluate our models on knowledge graph noise detection, knowledge graph completion and triple classification. Experimental results demonstrate that our confidence-aware models achieve significant and consistent improvements on all tasks, which confirms the capability of our CKRL model in both noise detection and knowledge representation learning.", "creator": "LaTeX with hyperref package"}}}