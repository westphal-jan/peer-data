{"id": "1705.03455", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-May-2017", "title": "Sequential Dialogue Context Modeling for Spoken Language Understanding", "abstract": "Conversational Language Understanding (CLU) is a key component of goal oriented dialogue systems that would parse user ut- terances into semantic frame representa- tions. Traditionally CLU does not utilize the dialogue history beyond the previous system turn and contextual ambiguities are resolved by the downstream components. In this paper, we explore novel approaches for modeling dialogue context in a re- current neural network (RNN) based lan- guage understanding system. We propose the Hierarchical Dialogue Encoder Net- work, that allows encoding context from the dialogue history in chronological or- der. We compare the performance of our proposed architecture with two context models, one that uses just the previous turn context and another that encodes dialogue context in a memory network, but loses the order of utterances in the dialogue his- tory. Experiments with a multi-domain di- alogue dataset demonstrate that the pro- posed architecture results in reduced se- mantic frame error rates.", "histories": [["v1", "Mon, 8 May 2017 20:57:30 GMT  (70kb,D)", "http://arxiv.org/abs/1705.03455v1", "8 + 2 pages"], ["v2", "Thu, 11 May 2017 00:21:13 GMT  (70kb,D)", "http://arxiv.org/abs/1705.03455v2", "8 + 2 pages, Updated 10/17: Updated typos in abstract"], ["v3", "Fri, 7 Jul 2017 21:35:02 GMT  (60kb,D)", "http://arxiv.org/abs/1705.03455v3", "8 + 2 pages, Updated 10/17: Updated typos in abstract, Updated 07/07: Updated Title, abstract and few minor changes"]], "COMMENTS": "8 + 2 pages", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.LG", "authors": ["ankur bapna", "gokhan tur", "dilek hakkani-tur", "larry heck"], "accepted": false, "id": "1705.03455"}, "pdf": {"name": "1705.03455.pdf", "metadata": {"source": "CRF", "title": "Improving Frame Semantic Parsing with Hierarchical Dialogue Encoders", "authors": ["Ankur Bapna", "Gokhan T\u00far", "Dilek Hakkani-T\u00far", "Larry Heck"], "emails": ["ankurbpn@google.com", "gokhant@google.com", "dilekh@google.com", "larryheck@google.com"], "sections": [{"heading": "1 Introduction", "text": "The ability to understand the utterances of the user and place them in a specific semantic situation (Tur and De Mori, 2011), which can then be processed by downstream diaspora system components, leads to a semantic framework for a restaurant reservation being shown in Figure 1. Since the complexity of the task is increased by a dialog system, there is a need for increased interaction between the user and the agent. For example, a restaurant reservation requires a name, a date and a number of people required for the reservation."}, {"heading": "2 Related Work", "text": "The task of understanding a user's expression is typically divided into 3 tasks: domain classification, intention classification and slot filling (Tur and De Mori, 2011). Most modern approaches to understanding conversation languages involve training machine learning models based on labeled training data (Young, 2002; Hahn et al., 2011; Wang et al., 2005 and others). More recently, approaches based on recurring neural networks (RNN) have proven to be highly successful in spoken language comprehension tasks (Mesnil et al., 2015; Hakkani-Tu \u00bc r et al., 2016; Kurata et al., 2016 and others). Parallel, joint modeling of tasks and addition of contextual signals show performance gains for multiple applications. Modelling domain, intention and slots in a common RNN model has led to a reduction in overall frame error rates (Hakkanu-Tu, et al)."}, {"heading": "3 Model Architecture", "text": "We compare the performance of 3 model architectures for encoding dialog contexts on a multi-domain dialog set. Let the dialog be a sequence of system and user utterances Dt = {u1, u2... ut} and, in due course, we will try to output the analysis of a user utterance ut. Let each utterance uk be a sequence of tokens given by {xk1, xk2... xknk}. We divide the model into 2 components, the context encoder that acts on Dt to create a vector representation of the dialog context denoted by ht = H (Dt), and the tagger that takes the dialog context that encodes ht and the current utterance ut as input, producing the domain, intention, and slot annotations as output."}, {"heading": "3.1 Context Encoder Architectures", "text": "In this section we describe the architectures of the context encoders used in our experiments. We compare the performance of 3 different architectures encoding different levels of the dialog context."}, {"heading": "3.1.1 Previous Utterance Encoder", "text": "This is the basic context encoder architecture. We feed the embedding corresponding to the tokens in the previous system statement, ut \u2212 1 = {xt \u2212 11, x t \u2212 1 2... x t \u2212 1 nt \u2212 1}, into a single bidirectional RNN (BiRNN) layer with gated recurrent unit (GRU) (Chung et al., 2014) cells and 128 dimensions (64 in each direction), the embedding is shared with the tagger. The final state of the context encoder GRU is used as a dialog context.ht = BiGRUc (ut \u2212 1) (1)."}, {"heading": "3.1.2 Memory Network", "text": "This architecture is identical to the approach described in (Chen et al., 2016). We encode all dialog context statements {u1, u2... ut \u2212 1} in memory vectors designated by a bi-directional GRU (BiGRU) encoder with 128 dimensions (64 in each direction). To add the temporal context to the dialog history utterances, we append special position markers to each utterance.mk = BiGRum (uk) for 0 \u2264 k \u2264 t \u2212 1 (2) We also encode the current utterance with another BiGRU encoder with 128 dimensions (64 in each direction), in a context vector designated with c, as in Equation 3. This is presented conceptually in Figure 2c = BiGRUc (ut) (3)."}, {"heading": "3.1.3 Hierarchical Dialogue Encoder Network", "text": "We extend the memory network architecture described above by adding a session encoder (Sordoni et al., 2015) that combines a common representation of the current encoding c, (Eq. 3) and the memory vectors {m1, m2... mt \u2212 1}, (Eq. 2) over time. We combine the context vector c with each memory vector mk, for 1 \u2264 k \u2264 nk, by connecting them together and passing them through a feed layer (FF) to generate 128-dimensional context encodings that are denoted by {g1, g2... gt \u2212 1} (Eq. 5).gk = Sigmoid (FF (mk, c)) for 0 \u2264 t \u2212 1 (5) Figure 4: Encoder Network Hierarchical Dialog Architecture. The feed networks share weights across all memory areas. These context encodings are encoded as token levels in the session encoder."}, {"heading": "3.2 Tagger Architecture", "text": "For all our experiments, we use a stacked BiRNN tagger to jointly model domain classification, intention classification and slot filling, similar to the approach described in (Hakkani-Tuer et al., 2016). We feed learned 256-dimensional embedding corresponding to the current expression into the tagger. The first RNN layer uses GRU cells with 256 dimensions (128 in each direction) as in Equation 7. The token embedding is fed into the token inputs of the first RNN layer to generate the token-level outputs o1 = {o11, o12... o1nt}.o1 = BiGRU1 (ut) (7) The second layer uses Long Short Term Memory (LSTM) (High Rider and Schmidhuber, 1997) to generate the token-level outputs o1 = {o12, Uo12} (second layer) Schmidhuber (1) (Long Tero.1)."}, {"heading": "4 Dataset", "text": "In recent years, we have repeatedly sought a solution that meets the needs of users. (i) The generation of user-agent interactions based on dialogues and slots is based on the interaction of a simulated user and a rules-based dialogue policy. (ii) The use of a crowdsourcing platform to elicit natural language expressions that correspond to the semantics of the generated interactions can be found in the appendix. The goal of the dialogical language understanding of our dialog system is to place each user in a frame-based semantics that can be processed by the downstream components. Tables describing the intentions and slots in the dataset can be found in the appendix."}, {"heading": "5 Dialogue Recombination", "text": "As described in the previous section, we train our models using a large set of dialog records from a single domain and a small set of dialogs from multiple domains. These models are then evaluated using a test set consisting of dialogs from multiple domains in which the user tries to fulfill multiple goals from multiple domains. The key idea behind the recombination approach is the conditional independence of sub-dialogs aimed at performing different tasks. To counteract this shift in data distribution, we use a dialog combining scheme to create dialogs from multiple domains. The key idea behind the recombination approach is conditional independence from sub-dialogs aimed at performing different tasks."}, {"heading": "6 Experiments", "text": "We compare the domain classification, intention classification and slot fill performance, as well as the overall error rates of the encoder decoder, storage network and hierarchical dialog encoder network on the data set described above. We trained all 3 models with RMSProp for 100,000 training steps with a batch size of 100. We started with a learning rate of 0.0003, which was reduced by a factor of 0.95 every 3000 steps. Grade standards were truncated if they exceeded an order of 2.5. We limit model vocabularies to include only tokens that occur more than 10 times in the training set to prevent overmatch to training set units. Digits were replaced by a special \"#\" token to allow for better generalization to invisible numbers. The dialog history was expanded to 40 expressions for batch processing. We report results with and without the combined data set in 3rd Table."}, {"heading": "7 Results", "text": "The encoder decoder model, trained only on the previous context, performs worst on almost all metrics, regardless of the presence of recombined data. This can be explained by poorer performance on dialog expressions, where only the previous context is insufficient to accurately identify the area, and in some cases the tents and slots of the utterance. The storage network is the most powerful model without recombined data, suggesting that the model is able to effectively encode additional context to improve performance on all tasks, even if only a small amount of multi-domain data is available. Without recombined data, the hierarchical dialog encoder network performs marginally worse than the storage network. This could be explained by overfitting the model into the context of a single domain that can be seen during the training, and by failing to effectively use the context in a multi-domain environment."}, {"heading": "8 Discussion and Conclusions", "text": "We observe that the Encoder Decoder (ED) and Hierarchical Dialogue Encoder Network (HDEN) are able to successfully identify the domain, intention and slots, while the Memory Network (MN) does not identify the movie name. If we look at the attention distributions, we find that the attention of the MN is very diffuse, with HDEN focusing on the last two settings that directly identify the domain and the presence of the movie slot in the user's final statement. ED is also able to identify the presence of a movie in the user's final statement from the previous settings context. Table 5 shows another example where the HDEN model performs both MN and ED."}], "references": [{"title": "Learning end-to-end goal-oriented dialog", "author": ["Antoine Bordes", "Jason Weston."], "venue": "arXiv preprint arXiv:1605.07683 .", "citeRegEx": "Bordes and Weston.,? 2016", "shortCiteRegEx": "Bordes and Weston.", "year": 2016}, {"title": "End-to-end memory networks with knowledge carryover for multi-turn spoken language understanding", "author": ["Y.-N. Chen", "D. Hakkani-T\u00fcr", "G. Tur", "J. Gao", "L. Deng."], "venue": "Proceedings of the Interspeech. San Francisco, CA.", "citeRegEx": "Chen et al\\.,? 2016", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1412.3555 .", "citeRegEx": "Chung et al\\.,? 2014", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "Zero-shot learning and clustering for semantic utterance classification", "author": ["Y. Dauphin", "G. Tur", "D. Hakkani-T\u00fcr", "L. Heck."], "venue": "Proceedings of the ICLR.", "citeRegEx": "Dauphin et al\\.,? 2014", "shortCiteRegEx": "Dauphin et al\\.", "year": 2014}, {"title": "End-to-end reinforcement learning of dialogue agents for information access", "author": ["Bhuwan Dhingra", "Lihong Li", "Xiujun Li", "Jianfeng Gao", "Yun-Nung Chen", "Faisal Ahmed", "Li Deng."], "venue": "arXiv preprint arXiv:1609.00777 .", "citeRegEx": "Dhingra et al\\.,? 2016", "shortCiteRegEx": "Dhingra et al\\.", "year": 2016}, {"title": "Focusing and description in natural language dialogues", "author": ["Barbara J Grosz."], "venue": "Technical report, DTIC Document.", "citeRegEx": "Grosz.,? 1979", "shortCiteRegEx": "Grosz.", "year": 1979}, {"title": "Comparing stochastic approaches to spoken language understanding in multiple languages", "author": ["S. Hahn", "M. Dinarelli", "C. Raymond", "F. Lefevre", "P. Lehnen", "R. De Mori", "A. Moschitti", "H. Ney", "G. Riccardi."], "venue": "IEEE Transactions on Audio, Speech,", "citeRegEx": "Hahn et al\\.,? 2011", "shortCiteRegEx": "Hahn et al\\.", "year": 2011}, {"title": "Multidomain joint semantic frame parsing using bidirectional RNN-LSTM", "author": ["D. Hakkani-T\u00fcr", "G. Tur", "A. Celikyilmaz", "Y.-N. Chen", "J. Gao", "L. Deng", "Y.-Y. Wang."], "venue": "Proceedings of the Interspeech. San Francisco, CA.", "citeRegEx": "Hakkani.T\u00fcr et al\\.,? 2016", "shortCiteRegEx": "Hakkani.T\u00fcr et al\\.", "year": 2016}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Data recombination for neural semantic parsing", "author": ["Robin Jia", "Percy Liang."], "venue": "arXiv preprint arXiv:1606.03622 .", "citeRegEx": "Jia and Liang.,? 2016", "shortCiteRegEx": "Jia and Liang.", "year": 2016}, {"title": "Leveraging sentence-level information with encoder LSTM for semantic slot filling", "author": ["G. Kurata", "B. Xiang", "B. Zhou", "M. Yu."], "venue": "Proceedings of the EMNLP. Austin, TX.", "citeRegEx": "Kurata et al\\.,? 2016", "shortCiteRegEx": "Kurata et al\\.", "year": 2016}, {"title": "Joint online spoken language understanding and language modeling with recurrent neural networks", "author": ["Bing Liu", "Ian Lane."], "venue": "CoRR abs/1609.01462. http://arxiv.org/abs/1609.01462.", "citeRegEx": "Liu and Lane.,? 2016", "shortCiteRegEx": "Liu and Lane.", "year": 2016}, {"title": "Agenda-based user simulation for bootstrapping a pomdp dialogue system", "author": ["Jost Schatzmann", "Blaise Thomson", "Karl Weilhammer", "Hui Ye", "Steve Young."], "venue": "Human Language Technologies 2007: The Conference of the North American Chapter of the", "citeRegEx": "Schatzmann et al\\.,? 2007", "shortCiteRegEx": "Schatzmann et al\\.", "year": 2007}, {"title": "Hierarchical neural network generative models for movie dialogues", "author": ["Iulian Vlad Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron C. Courville", "Joelle Pineau."], "venue": "CoRR abs/1507.04808. http://arxiv.org/abs/1507.04808.", "citeRegEx": "Serban et al\\.,? 2015", "shortCiteRegEx": "Serban et al\\.", "year": 2015}, {"title": "Interactive reinforcement learning for taskoriented dialogue management", "author": ["Pararth Shah", "Dilek Hakkani-T\u00fcr", "Larry Heck"], "venue": null, "citeRegEx": "Shah et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Shah et al\\.", "year": 2016}, {"title": "A hierarchical recurrent encoder-decoder for generative context-aware query suggestion", "author": ["Alessandro Sordoni", "Yoshua Bengio", "Hossein Vahabi", "Christina Lioma", "Jakob Grue Simonsen", "Jian-Yun Nie."], "venue": "Proceedings of the 24th", "citeRegEx": "Sordoni et al\\.,? 2015", "shortCiteRegEx": "Sordoni et al\\.", "year": 2015}, {"title": "Spoken language understanding: Systems for extracting semantic information from speech", "author": ["Gokhan Tur", "Renato De Mori."], "venue": "John Wiley & Sons.", "citeRegEx": "Tur and Mori.,? 2011", "shortCiteRegEx": "Tur and Mori.", "year": 2011}, {"title": "Spoken language understanding - an introduction to the statistical framework", "author": ["Y.-Y. Wang", "L. Deng", "A. Acero."], "venue": "IEEE Signal Processing Magazine 22(5):16\u201331.", "citeRegEx": "Wang et al\\.,? 2005", "shortCiteRegEx": "Wang et al\\.", "year": 2005}, {"title": "Memory networks", "author": ["Jason Weston", "Sumit Chopra", "Antoine Bordes."], "venue": "arXiv preprint arXiv:1410.3916 .", "citeRegEx": "Weston et al\\.,? 2014", "shortCiteRegEx": "Weston et al\\.", "year": 2014}, {"title": "Talking to machines (statistically speaking)", "author": ["S. Young."], "venue": "Proceedings of the ICSLP. Denver, CO.", "citeRegEx": "Young.,? 2002", "shortCiteRegEx": "Young.", "year": 2002}], "referenceMentions": [{"referenceID": 15, "context": "rent Encoder Decoders (HRED) (Sordoni et al., 2015), where we combine the query level encodings with a representation of the current utterance, before feeding it into the session level encoder.", "startOffset": 29, "endOffset": 51}, {"referenceID": 1, "context": "We compare the performance of this model to a RNN tagger injected with just the previous turn context and a single hop memory network that uses an attention weighted combination of the dialogue context (Chen et al., 2016; Weston et al., 2014).", "startOffset": 202, "endOffset": 242}, {"referenceID": 18, "context": "We compare the performance of this model to a RNN tagger injected with just the previous turn context and a single hop memory network that uses an attention weighted combination of the dialogue context (Chen et al., 2016; Weston et al., 2014).", "startOffset": 202, "endOffset": 242}, {"referenceID": 9, "context": "This is, in principle, a multi-turn extension of (Jia and Liang, 2016).", "startOffset": 49, "endOffset": 70}, {"referenceID": 7, "context": "Modeling domain, intent and slots in a joint RNN model was shown to result in reduction of overall frame error rates (Hakkani-T\u00fcr et al., 2016).", "startOffset": 117, "endOffset": 143}, {"referenceID": 11, "context": "Joint modeling of intent classification and language modeling showed promising improvements in intent recognition, especially in the presence of noisy speech recognition (Liu and Lane, 2016).", "startOffset": 170, "endOffset": 190}, {"referenceID": 1, "context": "Similarly, models incorporating more context from dialogue history (Chen et al., 2016) or semantic context from the frame (Dauphin et al.", "startOffset": 67, "endOffset": 86}, {"referenceID": 3, "context": ", 2016) or semantic context from the frame (Dauphin et al., 2014) have outperformed models without context and shown potential for greater generalization for spoken language understanding and related tasks.", "startOffset": 43, "endOffset": 65}, {"referenceID": 4, "context": "(Dhingra et al., 2016) show improved performance on an informational dialogue agent by incorporating knowledge base context into their dialogue system.", "startOffset": 0, "endOffset": 22}, {"referenceID": 0, "context": "Using dialogue context was shown to boost performance for end to end dialogue (Bordes and Weston, 2016) and next utterance prediction (Serban et al.", "startOffset": 78, "endOffset": 103}, {"referenceID": 13, "context": "Using dialogue context was shown to boost performance for end to end dialogue (Bordes and Weston, 2016) and next utterance prediction (Serban et al., 2015).", "startOffset": 134, "endOffset": 155}, {"referenceID": 2, "context": "x t\u22121 nt\u22121 }, into a single Bidirectional RNN (BiRNN) layer with Gated Recurrent Unit (GRU) (Chung et al., 2014) cells and 128 dimensions (64 in each direction).", "startOffset": 92, "endOffset": 112}, {"referenceID": 1, "context": "This architecture is identical to the approach described in (Chen et al., 2016).", "startOffset": 60, "endOffset": 79}, {"referenceID": 15, "context": "We enhance the memory network architecture described above by adding a session encoder (Sordoni et al., 2015) that temporally combines a joint representation of the current utterance encoding, c, (Eq.", "startOffset": 87, "endOffset": 109}, {"referenceID": 7, "context": "For all our experiments we use a stacked BiRNN tagger to jointly model domain classification, intent classification and slot-filling, similar to the approach described in (Hakkani-T\u00fcr et al., 2016).", "startOffset": 171, "endOffset": 197}, {"referenceID": 8, "context": "The second layer uses Long Short Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) cells with 256 dimensions (128 in both dimensions).", "startOffset": 52, "endOffset": 86}, {"referenceID": 12, "context": "We use a stochastic agenda-based user simulator (Schatzmann et al., 2007; Shah et al., 2016) for interplay with our rule based system policy.", "startOffset": 48, "endOffset": 92}, {"referenceID": 14, "context": "We use a stochastic agenda-based user simulator (Schatzmann et al., 2007; Shah et al., 2016) for interplay with our rule based system policy.", "startOffset": 48, "endOffset": 92}, {"referenceID": 9, "context": "Similar effects were observed by (Jia and Liang, 2016), where training with longer synthetic utterances resulted in improved performance on a simpler test set.", "startOffset": 33, "endOffset": 54}, {"referenceID": 5, "context": "This is usually the case in more natural goal oriented dialogues, where several tasks and sub tasks go in and out of the focus of the conversation (Grosz, 1979).", "startOffset": 147, "endOffset": 160}], "year": 2017, "abstractText": "Conversational Language Understanding (CLU) is a key component of goal oriented dialogue systems that would parse user utterances into semantic frame representations. Traditionally CLU does not utilize the dialogue history beyond the previous system turn and contextual ambiguities are resolved by the downstream components. In this paper, we explore novel approaches for modeling dialogue context in a recurrent neural network (RNN) based language understanding system. We propose the Hierarchical Dialogue Encoder Network, that allows encoding context from the dialogue history in chronological order. We compare the performance of our proposed architecture with two context models, one that uses just the previous turn context and another that encodes dialogue context in a memory network, but loses the order of utterances in the dialogue history. Experiments with a multi-domain dialogue dataset demonstrate that the proposed architecture results in reduced semantic frame error rates.", "creator": "LaTeX with hyperref package"}}}