{"id": "1705.03550", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2017", "title": "CORe50: a New Dataset and Benchmark for Continuous Object Recognition", "abstract": "Continuous/Lifelong learning of high-dimensional data streams is a challenging research problem. In fact, fully retraining models each time new data become available is infeasible, due to computational and storage issues, while na\\\"ive incremental strategies have been shown to suffer from catastrophic forgetting. In the context of real-world object recognition applications (e.g., robotic vision), where continuous learning is crucial, very few datasets and benchmarks are available to evaluate and compare emerging techniques. In this work we propose a new dataset and benchmark CORe50, specifically designed for continuous object recognition, and introduce baseline approaches for different continuous learning scenarios.", "histories": [["v1", "Tue, 9 May 2017 21:32:19 GMT  (3692kb,D)", "http://arxiv.org/abs/1705.03550v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG cs.RO", "authors": ["vincenzo lomonaco", "davide maltoni"], "accepted": false, "id": "1705.03550"}, "pdf": {"name": "1705.03550.pdf", "metadata": {"source": "CRF", "title": "CORe50: a New Dataset and Benchmark for Continuous Object Recognition", "authors": ["Vincenzo Lomonaco"], "emails": ["davide.maltoni}@unibo.it"], "sections": [{"heading": "1 Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2 Related Works", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "3 CORe50", "text": "In fact, most of them are able to determine for themselves what they want and what they want to do."}, {"heading": "4 Static Object Recognition Benchmark", "text": "Although designed for continuous learning, the CORe50 dataset can still be used as a medium-sized scale for object detection with a static evaluation protocol. High object variability and complex acquisition settings make the problem sufficiently difficult to solve even when learning is performed on the entire training data. In Table 2, we show the accuracy of two well-known CNN models (CaffeNet and VGG3) that are adapted to the medium size and trained in three different modalities using only RGB data (depth information will be used in future studies): 1. Mid-CNN from scratch: training a model from scratch. 2. Some sequences are slightly shorter than 300 frames because a few initial frames are needed to initialize the automatic motion sequence."}, {"heading": "5 Continuous Object Recognition Benchmark", "text": "For all continuous learning scenarios (NI, NC, NIC), we use the same test set consisting of sessions # 3, # 7 and # 10. The remaining 8 sessions are divided into lots and provided sequentially during the training. As the batch sequence can affect the final result, we calculate the average over 10 runs in which the lots are randomly shuffled. In addition, for each scenario, we provide the accuracy of the cumulative strategy (i.e. the current lot and the entire previous lot are used for training) as objective 4. We do not use the term upper limit because an intelligent sequential training approach could in principle exceed cumulative training. In the following sections, we report the results only for one task at object level (the most difficult), as both experiments lead to the analogous conclusions. Furthermore, the models in this study were trained only on the basis of RGB data (no depth information)."}, {"heading": "5.1 NI: New Instances", "text": "Since each session contains a sequence (about 300 frames) for each of the 50 objects, training a model in the first session 7 times (in the remaining 7 sessions) matches the NI scenario: all classes have been known since the first batch and successive batches provide new instances of these classes to refine and consolidate knowledge. A naive approach to this scenario simply continues the SGD training when new batches become available. In Figure 6, we compare the baseline and cumulative approaches. The accuracy gap between the na\u00efve and cumulative approach is quite modest here. In fact, forgetting can be tamed by carefully matching the learning rate and the number of iterations (premature abort) in this scenario, in which the model memory is regularly refreshed with new poses (scale, angle of view, appearance, lighting, etc.). Similar results have been reported for NORB, NILB, Big CON100, and Big Brother [16]."}, {"heading": "5.2 NC: New Classes", "text": "This year it is more than ever before in the history of the city."}, {"heading": "5.3 NIC: New Instances and Classes", "text": "In the third and final scenario, both new classes and instances are presented in each training part. This scenario is the closest to many real-world applications, where an agent continually learns new objects and refines knowledge of objects already discovered. In the NC scenario, the first part comprises 10 classes, and the subsequent 5 classes. However, only one training sequence per class is included in a batch, resulting in a double distribution scheme (i.e. classes and sequences).The total number of lots is 79. We maximized the categorical representation in the first batch, but left the composition and sequence of the 78 consecutive batches entirely random. The test set corresponds to the one in NI and NC scenarios.The CWR approach for this scenario needs to be slightly adjusted. The first time a new class copies its tw weights to cw, while the successive steps update cw as a weighted average, the accuracy for each class is shown in the current batch cw \u00b7 w [i]."}, {"heading": "6 Conclusion", "text": "Biological learning does not require storing perceptual data streams or cumulative processing of them; however, it effectively solves incremental learning tasks in which new object representations are continuously learned and consolidated and only the useless ones are forgotten. Artificial learning systems lack these skills and new research is needed to fill this gap. In this paper, we have introduced a new data set and associated benchmarks to support continuous learning studies in the context of object recognition. As argued by many researchers, our results also demonstrate that naive approaches such as incremental tuning cannot avoid catastrophic forgetting in complex real-world scenarios such as NC and NIC. When testing new approaches to CORe50, the most important indicator is not the absolute accuracy of certain scenarios, but the relative accuracy thereof. the corresponding cumulative approach can significantly reduce catastrophic forgetting in complex real-world scenarios such as NC and NIC. In fact, an absolute learning gap can easily exceed the full-scale accuracy of a modern model here."}, {"heading": "A Using pre-trained CNN with different input size", "text": "This year, it is more than ever in the history of the city, where it is so far that it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place."}], "references": [{"title": "YouTube-8M: A Large-Scale Video Classification Benchmark", "author": ["Sami Abu-El-Haija", "Nisarg Kothari", "Joonseok Lee", "Paul Natsev", "George Toderici", "Balakrishnan Varadarajan", "Sudheendra Vijayanarasimhan"], "venue": "arXiv preprint arXiv:1609.08675,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "iLab-20M: A Large-Scale Controlled Object Dataset to Investigate Deep Learning", "author": ["Ali Borji", "Saeed Izadi", "Laurent Itti"], "venue": "In International Conference of Computer Vision and Pattern Recogniton (CVPR),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Incremental Robot Learning of New Objects with Fixed Update Time", "author": ["Raffaello Camoriano", "Giulia Pasquale", "Carlo Ciliberto", "Lorenzo Natale", "Lorenzo Rosasco", "Giorgio Metta"], "venue": "arXiv preprint arXiv:1605.05045,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Return of the Devil in the Details: Delving Deep into Convolutional Nets", "author": ["Ken Chatfield", "Karen Simonyan", "Andrea Vedaldi", "Andrew Zisserman"], "venue": "Proceedings of the British Machine Vision Conference (BMVC),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "PathNet: Evolution Channels Gradient Descent in Super Neural Networks", "author": ["Chrisantha Fernando", "Dylan Banarse", "Charles Blundell", "Yori Zwols", "David Ha", "A Rusu", "Alexander Pritzel", "Daan Wierstra"], "venue": "arXiv preprint arXiv:1701.08734,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2017}, {"title": "The Big Brother Database : Evaluating Face Recognition in Smart Home Environments", "author": ["Annalisa Franco", "Dario Maio", "Davide Maltoni"], "venue": "In Advances in Biometrics: Third International Conference (ICB),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Active Long Term Memory Networks", "author": ["Tommaso Furlanello", "Jiaping Zhao", "Andrew M. Saxe", "Laurent Itti", "Bosco S. Tjan"], "venue": "arXiv preprint arXiv:1606.02355,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "The Amsterdam Library of Object Images", "author": ["Jan-Mark Geusebroek", "Gertjan J. Burghouts", "Arnold W.M. Smeulders"], "venue": "International Journal of Computer Vision,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks", "author": ["Ian J Goodfellow", "Mehdi Mirza", "Da Xiao", "Aaron Courville", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1312.6211,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1904}, {"title": "Overcoming catastrophic forgetting in neural networks", "author": ["James Kirkpatrick", "Razvan Pascanu", "Neil Rabinowitz", "Joel Veness", "Guillaume Desjardins", "Andrei A Rusu", "Kieran Milan", "John Quan", "Tiago Ramalho", "Agnieszka Grabska-Barwinska", "Demis Hassabis", "Claudia Clopath", "Dharshan Kumaran", "Raia Hadsell"], "venue": "In Proceedings of the National Academy of Sciences,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2017}, {"title": "Learning methods for generic object recognition with invariance to pose and lighting", "author": ["Yann. LeCun", "Fu Jie Huang", "Leon. Bottou"], "venue": "In Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2004}, {"title": "Learning without forgetting", "author": ["Zhizhong Li", "Derek Hoiem"], "venue": "In Computer Vision - ECCV 2016: 14th European Conference,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "Network In Network", "author": ["Min Lin", "Qiang Chen", "Shuicheng Yan"], "venue": "arXiv preprint arXiv:1312.4400,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Comparing Incremental Learning Strategies for Convolutional Neural Networks. In Artificial Neural Networks in Pattern Recognition: 7th IAPR TC3", "author": ["Vincenzo Lomonaco", "Davide Maltoni"], "venue": "Workshop (ANNPR 2016),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Semi-supervised Tuning from Temporal Coherence", "author": ["Davide Maltoni", "Vincenzo Lomonaco"], "venue": "In 2016 23rd International Conference on Pattern Recognition (ICPR),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Semi-supervised Tuning from Temporal Coherence", "author": ["Davide Maltoni", "Vincenzo Lomonaco"], "venue": "arXiv preprint arXiv:1511.03163,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "Columbia Object Image Library (COIL-100)", "author": ["Sameer A. Nene", "Shree K. Nayar", "Hiroshi Murase"], "venue": "Technical Report,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1996}, {"title": "Teaching iCub to recognize objects using deep Convolutional Neural Networks", "author": ["Giulia Pasquale", "Carlo Ciliberto", "Francesca Odone", "Lorenzo Rosasco", "Lorenzo Natale"], "venue": "In Proceedings of Workshop on Machine Learning for Interactive Systems,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Object Identification from Few Examples by Improving the Invariance of a Deep Convolutional Neural Network", "author": ["Giulia Pasquale", "Carlo Ciliberto", "Lorenzo Rosasco", "Lorenzo Natale"], "venue": "In 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "You Only Look Once: Unified, Real-Time Object Detection", "author": ["Joseph Redmon", "Santosh Divvala", "Ross Girshick", "Ali Farhadi"], "venue": "In CVPR 2016,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "author": ["Shaoqing Ren", "Kaiming He", "Ross Girshick", "Jian Sun"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2017}, {"title": "RGB-D Object Recognition and Pose Estimation based on Pre-trained Convolutional Neural Network Features", "author": ["Max Schwarz", "Hannes Schulz", "Sven Behnke"], "venue": "IEEE International Conference on Robotics and Automation (ICRA\u201915),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "BigBIRD: A Large-Scale 3D Database of Object Instances", "author": ["Arjun Singh", "James Sha", "Karthik S. Narayan", "Tudor Achim", "Pieter Abbeel"], "venue": "IEEE International Conference on Robotics and Automation (ICRA),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Compete to Compute", "author": ["Rupesh Kumar Srivastava", "Jonathan Masci", "Sohrob Kazerounian", "Faustino Gomez", "J\u00fcrgen Schmidhuber"], "venue": "Advances in neural information processing systems (NIPS),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Performance Assessment and Calibration of the Kinect 2.0 Time-of-Flight Range Camera for Use in Motion Capture Applications", "author": ["Jeremy Steward", "Derek Lichti", "Jacky Chow", "Reed Ferber", "Sean Osis", "Canada Key"], "venue": "In FIG Working Week", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "Encoder Based Lifelong Learning", "author": ["Amal Rannen Triki", "Rahaf Aljundi", "Mathew B. Blaschko", "Tinne Tuytelaars"], "venue": "arXiv preprint arXiv:1704.01920,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2017}], "referenceMentions": [{"referenceID": 15, "context": "move in front of the camera) is another key feature since temporal smoothness can be used to simplify object detection, improve classification accuracy and to address unsupervised scenarios [16] [17].", "startOffset": 190, "endOffset": 194}, {"referenceID": 16, "context": "move in front of the camera) is another key feature since temporal smoothness can be used to simplify object detection, improve classification accuracy and to address unsupervised scenarios [16] [17].", "startOffset": 195, "endOffset": 199}, {"referenceID": 14, "context": "Recent advances in transfer learning/tuning with deep neural networks have shown that using previously learned knowledge on similar tasks can be useful for solving new ones [15].", "startOffset": 173, "endOffset": 177}, {"referenceID": 12, "context": "Several interesting approaches have been proposed such as: Learning without Forgetting [13], Progressive Neural Networks [23], Active Long Term Memory Networks [7], Adaptive Convolutional Neural Network [29], PathNet [5], Incremental Regularized Least Squares [3], Elastic Weight Consolidation [11], Encoder-based Lifelong Learning [28], etc.", "startOffset": 87, "endOffset": 91}, {"referenceID": 6, "context": "Several interesting approaches have been proposed such as: Learning without Forgetting [13], Progressive Neural Networks [23], Active Long Term Memory Networks [7], Adaptive Convolutional Neural Network [29], PathNet [5], Incremental Regularized Least Squares [3], Elastic Weight Consolidation [11], Encoder-based Lifelong Learning [28], etc.", "startOffset": 160, "endOffset": 163}, {"referenceID": 4, "context": "Several interesting approaches have been proposed such as: Learning without Forgetting [13], Progressive Neural Networks [23], Active Long Term Memory Networks [7], Adaptive Convolutional Neural Network [29], PathNet [5], Incremental Regularized Least Squares [3], Elastic Weight Consolidation [11], Encoder-based Lifelong Learning [28], etc.", "startOffset": 217, "endOffset": 220}, {"referenceID": 2, "context": "Several interesting approaches have been proposed such as: Learning without Forgetting [13], Progressive Neural Networks [23], Active Long Term Memory Networks [7], Adaptive Convolutional Neural Network [29], PathNet [5], Incremental Regularized Least Squares [3], Elastic Weight Consolidation [11], Encoder-based Lifelong Learning [28], etc.", "startOffset": 260, "endOffset": 263}, {"referenceID": 10, "context": "Several interesting approaches have been proposed such as: Learning without Forgetting [13], Progressive Neural Networks [23], Active Long Term Memory Networks [7], Adaptive Convolutional Neural Network [29], PathNet [5], Incremental Regularized Least Squares [3], Elastic Weight Consolidation [11], Encoder-based Lifelong Learning [28], etc.", "startOffset": 294, "endOffset": 298}, {"referenceID": 26, "context": "Several interesting approaches have been proposed such as: Learning without Forgetting [13], Progressive Neural Networks [23], Active Long Term Memory Networks [7], Adaptive Convolutional Neural Network [29], PathNet [5], Incremental Regularized Least Squares [3], Elastic Weight Consolidation [11], Encoder-based Lifelong Learning [28], etc.", "startOffset": 332, "endOffset": 336}, {"referenceID": 12, "context": "Learning without Forgetting (LwF ) [13] and some of its evolutions [28] are also very interesting since they prove that enforcing the output stability helps to control forgetting and, at the same time, provides enough degrees of freedom to learn the new task(s).", "startOffset": 35, "endOffset": 39}, {"referenceID": 26, "context": "Learning without Forgetting (LwF ) [13] and some of its evolutions [28] are also very interesting since they prove that enforcing the output stability helps to control forgetting and, at the same time, provides enough degrees of freedom to learn the new task(s).", "startOffset": 67, "endOffset": 71}, {"referenceID": 8, "context": "For example, EWC classification tests have been carried out on permuted MNIST task [9] [26], where the new tasks to learn are obtained by scrambling the pixel positions in the MNIST dataset.", "startOffset": 83, "endOffset": 86}, {"referenceID": 24, "context": "For example, EWC classification tests have been carried out on permuted MNIST task [9] [26], where the new tasks to learn are obtained by scrambling the pixel positions in the MNIST dataset.", "startOffset": 87, "endOffset": 91}, {"referenceID": 12, "context": "Most of the experiments performed on LwF consider pairs of large datasets (selected from ImageNet, Pascal VOC, Places365-standard, Caltech-UCSD Birds-200-2011, MIT indoor scene classification, etc) and proves that a model trained on the first dataset can be further trained on the second one without forgetting the first task; even if LwF can deal with multiple new tasks, only a simple experiments is reported in [13] for multiple new tasks.", "startOffset": 414, "endOffset": 418}, {"referenceID": 11, "context": "NORB [12] 5 25 20 20* grayscale turntable no COIL-100 [18] - 100 20 54* RGB turntable no iLab-20M [2] 15 704 - RGB turntable no RGB-D [24] 51 300 - RGB-D turntable no BigBIRD [25] - 100 - RGB-D turntable no ALOI [8] - 1000 - RGB turntable no BigBrother [6] - 7 54 \u223c20 RGB wall cameras no iCubWorld28 [19] 7 28 4 \u223c150 RGB hand hold no iCubWorld-Transf [20] 15 150 6 \u223c150 RGB hand hold no CORe50 10 50 11 \u223c300 RGB-D hand hold yes (3)", "startOffset": 5, "endOffset": 9}, {"referenceID": 17, "context": "NORB [12] 5 25 20 20* grayscale turntable no COIL-100 [18] - 100 20 54* RGB turntable no iLab-20M [2] 15 704 - RGB turntable no RGB-D [24] 51 300 - RGB-D turntable no BigBIRD [25] - 100 - RGB-D turntable no ALOI [8] - 1000 - RGB turntable no BigBrother [6] - 7 54 \u223c20 RGB wall cameras no iCubWorld28 [19] 7 28 4 \u223c150 RGB hand hold no iCubWorld-Transf [20] 15 150 6 \u223c150 RGB hand hold no CORe50 10 50 11 \u223c300 RGB-D hand hold yes (3)", "startOffset": 54, "endOffset": 58}, {"referenceID": 1, "context": "NORB [12] 5 25 20 20* grayscale turntable no COIL-100 [18] - 100 20 54* RGB turntable no iLab-20M [2] 15 704 - RGB turntable no RGB-D [24] 51 300 - RGB-D turntable no BigBIRD [25] - 100 - RGB-D turntable no ALOI [8] - 1000 - RGB turntable no BigBrother [6] - 7 54 \u223c20 RGB wall cameras no iCubWorld28 [19] 7 28 4 \u223c150 RGB hand hold no iCubWorld-Transf [20] 15 150 6 \u223c150 RGB hand hold no CORe50 10 50 11 \u223c300 RGB-D hand hold yes (3)", "startOffset": 98, "endOffset": 101}, {"referenceID": 22, "context": "NORB [12] 5 25 20 20* grayscale turntable no COIL-100 [18] - 100 20 54* RGB turntable no iLab-20M [2] 15 704 - RGB turntable no RGB-D [24] 51 300 - RGB-D turntable no BigBIRD [25] - 100 - RGB-D turntable no ALOI [8] - 1000 - RGB turntable no BigBrother [6] - 7 54 \u223c20 RGB wall cameras no iCubWorld28 [19] 7 28 4 \u223c150 RGB hand hold no iCubWorld-Transf [20] 15 150 6 \u223c150 RGB hand hold no CORe50 10 50 11 \u223c300 RGB-D hand hold yes (3)", "startOffset": 134, "endOffset": 138}, {"referenceID": 23, "context": "NORB [12] 5 25 20 20* grayscale turntable no COIL-100 [18] - 100 20 54* RGB turntable no iLab-20M [2] 15 704 - RGB turntable no RGB-D [24] 51 300 - RGB-D turntable no BigBIRD [25] - 100 - RGB-D turntable no ALOI [8] - 1000 - RGB turntable no BigBrother [6] - 7 54 \u223c20 RGB wall cameras no iCubWorld28 [19] 7 28 4 \u223c150 RGB hand hold no iCubWorld-Transf [20] 15 150 6 \u223c150 RGB hand hold no CORe50 10 50 11 \u223c300 RGB-D hand hold yes (3)", "startOffset": 175, "endOffset": 179}, {"referenceID": 7, "context": "NORB [12] 5 25 20 20* grayscale turntable no COIL-100 [18] - 100 20 54* RGB turntable no iLab-20M [2] 15 704 - RGB turntable no RGB-D [24] 51 300 - RGB-D turntable no BigBIRD [25] - 100 - RGB-D turntable no ALOI [8] - 1000 - RGB turntable no BigBrother [6] - 7 54 \u223c20 RGB wall cameras no iCubWorld28 [19] 7 28 4 \u223c150 RGB hand hold no iCubWorld-Transf [20] 15 150 6 \u223c150 RGB hand hold no CORe50 10 50 11 \u223c300 RGB-D hand hold yes (3)", "startOffset": 212, "endOffset": 215}, {"referenceID": 5, "context": "NORB [12] 5 25 20 20* grayscale turntable no COIL-100 [18] - 100 20 54* RGB turntable no iLab-20M [2] 15 704 - RGB turntable no RGB-D [24] 51 300 - RGB-D turntable no BigBIRD [25] - 100 - RGB-D turntable no ALOI [8] - 1000 - RGB turntable no BigBrother [6] - 7 54 \u223c20 RGB wall cameras no iCubWorld28 [19] 7 28 4 \u223c150 RGB hand hold no iCubWorld-Transf [20] 15 150 6 \u223c150 RGB hand hold no CORe50 10 50 11 \u223c300 RGB-D hand hold yes (3)", "startOffset": 253, "endOffset": 256}, {"referenceID": 18, "context": "NORB [12] 5 25 20 20* grayscale turntable no COIL-100 [18] - 100 20 54* RGB turntable no iLab-20M [2] 15 704 - RGB turntable no RGB-D [24] 51 300 - RGB-D turntable no BigBIRD [25] - 100 - RGB-D turntable no ALOI [8] - 1000 - RGB turntable no BigBrother [6] - 7 54 \u223c20 RGB wall cameras no iCubWorld28 [19] 7 28 4 \u223c150 RGB hand hold no iCubWorld-Transf [20] 15 150 6 \u223c150 RGB hand hold no CORe50 10 50 11 \u223c300 RGB-D hand hold yes (3)", "startOffset": 300, "endOffset": 304}, {"referenceID": 19, "context": "NORB [12] 5 25 20 20* grayscale turntable no COIL-100 [18] - 100 20 54* RGB turntable no iLab-20M [2] 15 704 - RGB turntable no RGB-D [24] 51 300 - RGB-D turntable no BigBIRD [25] - 100 - RGB-D turntable no ALOI [8] - 1000 - RGB turntable no BigBrother [6] - 7 54 \u223c20 RGB wall cameras no iCubWorld28 [19] 7 28 4 \u223c150 RGB hand hold no iCubWorld-Transf [20] 15 150 6 \u223c150 RGB hand hold no CORe50 10 50 11 \u223c300 RGB-D hand hold yes (3)", "startOffset": 351, "endOffset": 355}, {"referenceID": 15, "context": "* Temporal coherent training/test sessions for NORB and COIL-100 have been defined in [16] and [17].", "startOffset": 86, "endOffset": 90}, {"referenceID": 16, "context": "* Temporal coherent training/test sessions for NORB and COIL-100 have been defined in [16] and [17].", "startOffset": 95, "endOffset": 99}, {"referenceID": 0, "context": "YouTube-8M [1] provides a huge number of videos acquired in difficult natural settings.", "startOffset": 11, "endOffset": 14}, {"referenceID": 15, "context": "For NORB and COIL-100 we defined in [16] a number of exploration sequences that turn the native static benchmarks into continuous learning tasks; [16] also reports supervised and semi-supervised accuracy for the NI scenario.", "startOffset": 36, "endOffset": 40}, {"referenceID": 15, "context": "For NORB and COIL-100 we defined in [16] a number of exploration sequences that turn the native static benchmarks into continuous learning tasks; [16] also reports supervised and semi-supervised accuracy for the NI scenario.", "startOffset": 146, "endOffset": 150}, {"referenceID": 14, "context": "BigBrother dataset (see [15] [6]) is an interesting incremental learning setup in the face recognition domain, but unfortunately the owner copyright does not allow the public diffusion of the dataset.", "startOffset": 24, "endOffset": 28}, {"referenceID": 5, "context": "BigBrother dataset (see [15] [6]) is an interesting incremental learning setup in the face recognition domain, but unfortunately the owner copyright does not allow the public diffusion of the dataset.", "startOffset": 29, "endOffset": 32}, {"referenceID": 18, "context": "Finally, the iCubWorld datasets ([19], [20]) have been acquired in a robotic vision context and are the closest ones to CORe50.", "startOffset": 33, "endOffset": 37}, {"referenceID": 19, "context": "Finally, the iCubWorld datasets ([19], [20]) have been acquired in a robotic vision context and are the closest ones to CORe50.", "startOffset": 39, "endOffset": 43}, {"referenceID": 25, "context": "0 sensor [27] delivering 300 RGB-D frames.", "startOffset": 9, "endOffset": 13}, {"referenceID": 21, "context": "in principle object detection inside the frame could be performed by a trained model like a Faster R-CNN [22] or Yolo [21]; however, since our main interest is continuous object recognition, at this stage we preferred to focus on object classification instead of the more complex and time demanding detection task.", "startOffset": 105, "endOffset": 109}, {"referenceID": 20, "context": "in principle object detection inside the frame could be performed by a trained model like a Faster R-CNN [22] or Yolo [21]; however, since our main interest is continuous object recognition, at this stage we preferred to focus on object classification instead of the more complex and time demanding detection task.", "startOffset": 118, "endOffset": 122}, {"referenceID": 3, "context": "We refer to the VGG-CNN-M model introduced in [4].", "startOffset": 46, "endOffset": 49}, {"referenceID": 15, "context": "Similar findings have been reported for NORB, COIL100 and BigBrother in the NI scenario [16] [15].", "startOffset": 88, "endOffset": 92}, {"referenceID": 14, "context": "Similar findings have been reported for NORB, COIL100 and BigBrother in the NI scenario [16] [15].", "startOffset": 93, "endOffset": 97}, {"referenceID": 12, "context": "In other words, cw can be seen as a sort of hippocampus where consolidated concepts are maintained, while tw as a short term working memory in the cortex used to learn new concepts without interfering with stable ones (see the interesting discussion in [13]).", "startOffset": 253, "endOffset": 257}, {"referenceID": 10, "context": "EWC [11] and LwF [13] [28] are interesting approaches in this direction, and we intend to test them on CORe50 in the near future.", "startOffset": 4, "endOffset": 8}, {"referenceID": 12, "context": "EWC [11] and LwF [13] [28] are interesting approaches in this direction, and we intend to test them on CORe50 in the near future.", "startOffset": 17, "endOffset": 21}, {"referenceID": 26, "context": "EWC [11] and LwF [13] [28] are interesting approaches in this direction, and we intend to test them on CORe50 in the near future.", "startOffset": 22, "endOffset": 26}], "year": 2017, "abstractText": "Continuous/Lifelong learning of high-dimensional data streams is a challenging research problem. In fact, fully retraining models each time new data become available is infeasible, due to computational and storage issues, while na\u00efve incremental strategies have been shown to suffer from catastrophic forgetting. In the context of real-world object recognition applications (e.g., robotic vision), where continuous learning is crucial, very few datasets and benchmarks are available to evaluate and compare emerging techniques. In this work we propose a new dataset and benchmark CORe50, specifically designed for continuous object recognition, and introduce baseline approaches for different continuous learning scenarios.", "creator": "LaTeX with hyperref package"}}}