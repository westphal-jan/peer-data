{"id": "1705.03595", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-May-2017", "title": "Collaborative Descriptors: Convolutional Maps for Preprocessing", "abstract": "The paper presents a novel concept for collaborative descriptors between deeply learned and hand-crafted features. To achieve this concept, we apply convolutional maps for pre-processing, namely the convovlutional maps are used as input of hand-crafted features. We recorded an increase in the performance rate of +17.06 % (multi-class object recognition) and +24.71 % (car detection) from grayscale input to convolutional maps. Although the framework is straight-forward, the concept should be inherited for an improved representation.", "histories": [["v1", "Wed, 10 May 2017 03:04:48 GMT  (2464kb)", "http://arxiv.org/abs/1705.03595v1", "CVPR 2017 Workshop Submission"]], "COMMENTS": "CVPR 2017 Workshop Submission", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["hirokatsu kataoka", "kaori abe", "akio nakamura", "yutaka satoh"], "accepted": false, "id": "1705.03595"}, "pdf": {"name": "1705.03595.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Hirokatsu Kataoka", "Yutaka Satoh", "Kaori Abe", "Akio Nakamura"], "emails": ["yu.satou}@aist.go.jp", "abe.keroko@aist.go.jp", "nkmr-a@cck.dendai.ac.jp"], "sections": [{"heading": null, "text": "ar Xiv: 170 5.03 595v 1 [cs.C V] 1The paper introduces a novel concept of collaborative descriptors between deeply learned and handmade features. To achieve this concept, we use convlutional maps for pre-processing, using the convoy maps as input of handmade features. We recorded an increase in performance of + 17.06% (object detection in several classes) and + 24.71% (vehicle detection) from grayscale input to convoy maps. Although the frame is manageable, the concept for improved display should be inherited."}, {"heading": "1. Introduction", "text": "Neural networks are computationally reflective of the architecture of the human brain. Recent architectures have been deepened to provide representations of objects at a higher level. In the field of computer vision in particular, deep Convolutionary Neural Networks (DCNN) are increasingly used for image recognition and object recognition. Representative deep models such as VGGNet [5] have been used in the field of computer vision.The use of Neural Networks and handmade functions is repeated in the field of computer vision (see Figure 1).The suggestive knowledge motivates us to study a sophisticated handcrafted feature according to the DCNN in the recent 3rd AI. We expect that the handcrafted feature should work together with deeply learned parameters as outstanding performance is associated with the automatic feature Learning.In the paper we present a novel concept for collaborative descriptors that work together with both DCNN and handcrafted features."}, {"heading": "2. Convolutional maps for preprocessing", "text": "Figure 2 shows the process of using folding maps as a preprocessor. We use handmade features, namely SIFT + BoW [2] and HLAC [4]. Given a folding map Mk with VGG [5] for kernel k, our goal is to extract a feature vector V from the map and define a classification map L as a function of SVM, L = fsvm (V). We use VGGNet to create folding maps. The second layer with maximum compaction is used as a folding map containing the 56 x 56 x 128 feature map. We can handle 128 maps with dimensions of 56 x 56 [pixels]. The patch and core sizes are suitable for balanced features ex-traction. We can obtain a folding map M conv and maxpooling mapMmp for entering kernel mapk below Y = MY = MY = 2 convection scription (M = xxm)."}, {"heading": "3. Results", "text": "Comparisons of the handmade features of conventional maps and grayscale images are therefore shown in Figure 3 and Table 1. We used a support vector engine (SVM) as a two- or multi-level classification. SIFT + BoW was used for the Caltech 101 dataset [3] because it is a kind of object categorization. According to Figure 3, the conventional maps allow a clear distinction between object classes. In the case of SIFT + BoW with conventional maps, the code word dictionary was divided across all 128 cores. The dimension of the vector was 1,000, even when using conventional maps. SIFT + BoW with conventional maps (rate: 58.28%) was + 17.06% better than the SIFT + BoW Dictionary for grayscale images (rate: 41.22%).The results show that the use of preprocess maps provides a perspective for the learning architecture."}, {"heading": "4. Conclusion", "text": "The paper presented a novel concept of collaborative descriptors that combine deep Convolutionary Neural Networks (DCNN) into handcrafted features. We assigned Convolutionary Maps as pre-processing. We recorded an increase in performance of + 17.06% and + 24.71% for the Caltech101 and UIUC vehicle data sets, respectively. In the future, we will need to adjust the parameters of Convolutionary Maps, Handcrafted Features and their integration. In this paper, only old-fashioned features and datasets were taken into account, but the use of Convolutionary Maps is likely to result in even greater performance improvements when used in conjunction with more complex features."}], "references": [{"title": "Learning to detect objects in images via a sparse, part-based representation", "author": ["S. Agarwal", "A. Awan", "D. Roth"], "venue": "IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "Visual categorization with bags of keypoints", "author": ["G. Csurka", "C.R. Dance", "L. Fan", "J. Willamowski", "C. Bray"], "venue": "ECCVW,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2004}, {"title": "Learning generative visual models from few training examples: an incremental bayesian approach tested on 101 object categories", "author": ["L. Fei-Fei", "R. Fergus", "P. Perona"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "A new scheme for practical flexible and intelligent vision systems", "author": ["N. Otsu", "T. Kurita"], "venue": "IAPR Workshop on Computer Vision,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1988}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "International Conference on Learning Representation (ICLR),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}], "referenceMentions": [{"referenceID": 4, "context": "Representative deep models such as VGGNet [5] have been proposed in the field of computer vision.", "startOffset": 42, "endOffset": 45}, {"referenceID": 1, "context": "We try to evaluate several hand-crafted features such as scale invariant feature transform (SIFT) and bag-of-words (BoW) [2] (object recognition) and higher-order local autocorrelation (HLAC) [4] (car detection).", "startOffset": 121, "endOffset": 124}, {"referenceID": 3, "context": "We try to evaluate several hand-crafted features such as scale invariant feature transform (SIFT) and bag-of-words (BoW) [2] (object recognition) and higher-order local autocorrelation (HLAC) [4] (car detection).", "startOffset": 192, "endOffset": 195}, {"referenceID": 1, "context": "We employ hand-crafted features, namely SIFT+BoW [2] and HLAC [4].", "startOffset": 49, "endOffset": 52}, {"referenceID": 3, "context": "We employ hand-crafted features, namely SIFT+BoW [2] and HLAC [4].", "startOffset": 62, "endOffset": 65}, {"referenceID": 4, "context": "Given a convolutional mapMk with VGG [5] for kernel k, our goal is to extract a feature vector V from the map and define a classification label L as a function of SVM, L = fsvm(V ).", "startOffset": 37, "endOffset": 40}, {"referenceID": 2, "context": "SIFT+BoW was employed for the Caltech 101 dataset [3], since it is a kind of object categorization.", "startOffset": 50, "endOffset": 53}, {"referenceID": 0, "context": "HLAC was applied to the UIUC cars dataset [1].", "startOffset": 42, "endOffset": 45}], "year": 2017, "abstractText": "The paper presents a novel concept for collaborative descriptors between deeply learned and hand-crafted features. To achieve this concept, we apply convolutional maps for pre-processing, namely the convovlutional maps are used as input of hand-crafted features. We recorded an increase in the performance rate of +17.06% (multiclass object recognition) and +24.71% (car detection) from grayscale input to convolutional maps. Although the framework is straight-forward, the concept should be inherited for an improved representation.", "creator": "LaTeX with hyperref package"}}}