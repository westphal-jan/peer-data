{"id": "1705.03802", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-May-2017", "title": "Analysing Data-To-Text Generation Benchmarks", "abstract": "Recently, several data-sets associating data to text have been created to train data-to-text surface realisers. It is unclear however to what extent the surface realisation task exercised by these data-sets is linguistically challenging. Do these data-sets provide enough variety to encourage the development of generic, high-quality data-to-text surface realisers ? In this paper, we argue that these data-sets have important drawbacks. We back up our claim using statistics, metrics and manual evaluation. We conclude by eliciting a set of criteria for the creation of a data-to-text benchmark which could help better support the development, evaluation and comparison of linguistically sophisticated data-to-text surface realisers.", "histories": [["v1", "Wed, 10 May 2017 14:42:54 GMT  (45kb,D)", "http://arxiv.org/abs/1705.03802v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["laura perez-beltrachini", "claire gardent"], "accepted": false, "id": "1705.03802"}, "pdf": {"name": "1705.03802.pdf", "metadata": {"source": "CRF", "title": "Analysing Data-To-Text Generation Benchmarks", "authors": ["Laura Perez-Beltrachini", "Claire Gardent"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Recently, several datasets linking data with text have been constructed and used to train mostly neural data units with text interface creators (Lebret et al., 2016). (Wen et al., 2016) Crowd sourcing text for dialogue activities in multiple areas (restaurant, laptop, car, and television). (Novikova et al., 2016) present a dataset created by crowd sourcing text and paraphrases from visually illustrated frames. In this paper, we examine the appropriateness of these datasets for training high precision, broad reach, and linguistically sophisticated interface realisers. We focus on the following questions: Lexical richness: Is the dataset lexically diverse? Domain-specific data can lead to highly repetitive text structures that support linguistic diversity due to a small number of lexical items."}, {"heading": "2 Datasets", "text": "We examine the three datasets proposed for the data text generation (Lebret et al., 2016), (Wen et al., 2015; Wen et al., 2016) and (Novikova and Rieser, 2016). (Lebret et al., 2016) s data-set (WIKIBIO) focusesar Xiv: 170 5.03 802v 1 [cs.C L] 10 May 2on biographies and associated Wikipedia infobox with the first sentence of the corresponding article in Wikipedia. Thus, in this dataset texts and data (infoboxes) were written by Wikipedia contributors. As the dataset is much larger than the other datasets and is not domain specific, we extract three subsets of them for a better comparison: two whose size is similar to the other datasets (WIKIBIO16317, WIKIBIO2647) and one that is specific in all biographies."}, {"heading": "3 Conclusion", "text": "Not surprisingly, our analysis shows that existing datasets have limitations (large proportion of simple sentences, lack of specific syntactical constructions, limited syntactic and semantic diversity, limited number of attributes and unique inputs, stereotyped text, etc.). On the positive side, it also highlights some key aspects to consider when creating a dataset for the development, evaluation and comparison of linguistically sophisticated user interfaces. Lexical richness can be increased by incorporating data from different domains, using a large number of different attributes and ensuring that the total number of different inputs is high. Wide and balanced syntactical coverage is difficult to achieve and probably requires input data of different sizes and shapes coming from different domains (biographical text, for example, has limited syntactical variability). Semantic appropriateness can be achieved almost perfectly through crowd sourcing, which also facilitates paraphrasing."}], "references": [{"title": "Developing a large semantically annotated corpus", "author": ["Johan Bos", "Kilian Evang", "Noortje Venhuizen"], "venue": "In LREC,", "citeRegEx": "Basile et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Basile et al\\.", "year": 2012}, {"title": "Head-Driven Statistical Models for Natural Language Parsing", "author": ["M. Collins"], "venue": "Ph.D. thesis,", "citeRegEx": "Collins.,? \\Q1999\\E", "shortCiteRegEx": "Collins.", "year": 1999}, {"title": "How complex is that sentence? a proposed revision of the rosenberg and abbeduto d-level scale", "author": ["Congzhou He", "Cati Brown", "Lorina Naci", "John Brown"], "venue": null, "citeRegEx": "Covington et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Covington et al\\.", "year": 2006}, {"title": "Neural text generation from structured data with application to the biography domain", "author": ["Lebret et al.2016] R\u00e9mi Lebret", "David Grangier", "Michael Auli"], "venue": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Lebret et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lebret et al\\.", "year": 2016}, {"title": "Automatic analysis of syntactic complexity in second language writing", "author": ["Xiaofei Lu"], "venue": "International Journal of Corpus Linguistics,", "citeRegEx": "Lu.,? \\Q2010\\E", "shortCiteRegEx": "Lu.", "year": 2010}, {"title": "The relationship of lexical richness to the quality of esl learners oral narratives", "author": ["Xiaofei Lu"], "venue": "The Modern Language Journal,", "citeRegEx": "Lu.,? \\Q2012\\E", "shortCiteRegEx": "Lu.", "year": 2012}, {"title": "The analogue challenge: Non aligned language generation", "author": ["Novikova", "Rieser2016] Jekaterina Novikova", "Verena Rieser"], "venue": "In The 9th International Natural Language Generation conference,", "citeRegEx": "Novikova et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Novikova et al\\.", "year": 2016}, {"title": "Crowd-sourcing nlg data: Pictures elicit better data", "author": ["Oliver Lemon", "Verena Rieser"], "venue": "In Proceedings of the 9th International Natural Language Generation conference,", "citeRegEx": "Novikova et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Novikova et al\\.", "year": 2016}, {"title": "Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104\u20133112", "author": ["Oriol Vinyals", "Quoc V Le"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Semantically conditioned lstm-based natural language generation for spoken dialogue systems. arXiv preprint arXiv:1508.01745", "author": ["Wen et al.2015] Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrksic", "Pei-Hao Su", "David Vandyke", "Steve Young"], "venue": null, "citeRegEx": "Wen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2015}, {"title": "Multi-domain neural network language generation for spoken dialogue systems. arXiv preprint arXiv:1603.01232", "author": ["Wen et al.2016] Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrksic", "Lina M Rojas-Barahona", "Pei-Hao Su", "David Vandyke", "Steve Young"], "venue": null, "citeRegEx": "Wen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 3, "context": "(Lebret et al., 2016) built a biography data-set using Wikipedia articles and infoboxes.", "startOffset": 0, "endOffset": 21}, {"referenceID": 10, "context": "(Wen et al., 2016) crowd sourced text for dialogue acts bearing on multiple", "startOffset": 0, "endOffset": 18}, {"referenceID": 6, "context": "(Novikova et al., 2016) present a data-set created by crowd sourcing text and paraphrases from image illustrated frames.", "startOffset": 0, "endOffset": 23}, {"referenceID": 3, "context": "We examine the three data-sets proposed for data-totext generation by (Lebret et al., 2016), (Wen et al.", "startOffset": 70, "endOffset": 91}, {"referenceID": 9, "context": ", 2016), (Wen et al., 2015; Wen et al., 2016) and (Novikova and Rieser, 2016).", "startOffset": 9, "endOffset": 45}, {"referenceID": 10, "context": ", 2016), (Wen et al., 2015; Wen et al., 2016) and (Novikova and Rieser, 2016).", "startOffset": 9, "endOffset": 45}, {"referenceID": 3, "context": "(Lebret et al., 2016)\u2019s data-set (WIKIBIO) focuses ar X iv :1 70 5.", "startOffset": 0, "endOffset": 21}, {"referenceID": 9, "context": "The other two data-sets were created manually with humans providing text for dialogue acts in the case of (Wen et al., 2015; Wen et al., 2016)\u2019s data-sets (RNNLGLaptop, RNNLGTV , RNNLGHotel, RNNLGRestaurant) and producing image descriptions in the case of (Novikova and Rieser, 2016)\u2019s data-set (IMAGEDESC).", "startOffset": 106, "endOffset": 142}, {"referenceID": 10, "context": "The other two data-sets were created manually with humans providing text for dialogue acts in the case of (Wen et al., 2015; Wen et al., 2016)\u2019s data-sets (RNNLGLaptop, RNNLGTV , RNNLGHotel, RNNLGRestaurant) and producing image descriptions in the case of (Novikova and Rieser, 2016)\u2019s data-set (IMAGEDESC).", "startOffset": 106, "endOffset": 142}, {"referenceID": 0, "context": "0, (Basile et al., 2012)) and covers different genres (e.", "startOffset": 3, "endOffset": 24}, {"referenceID": 5, "context": "the three data-sets support the training of lexically rich surface realisers, we used the Lexical Complexity Analyser developed by (Lu, 2012), a system designed to automate the measurement of various dimensions of lexical richness.", "startOffset": 131, "endOffset": 141}, {"referenceID": 4, "context": "the three data-sets, we use the system for automatic measurement of syntactic complexity developed by (Lu, 2010).", "startOffset": 102, "endOffset": 112}, {"referenceID": 1, "context": "Parses are obtained using Collins\u2019 constituent parser (Collins, 1999).", "startOffset": 54, "endOffset": 69}, {"referenceID": 4, "context": "2% (Lu, 2010).", "startOffset": 3, "endOffset": 13}, {"referenceID": 2, "context": "The system uses the revised D-Level Scale proposed by (Covington et al., 2006) which consists of the following eight levels: (0) simple sentences, including questions (1) infinitive or -ing complement", "startOffset": 54, "endOffset": 78}, {"referenceID": 8, "context": "Due to this mismatch, it cannot be used to train joint models for content selection and surface realisation with standard neural techniques (Sutskever et al., 2014).", "startOffset": 140, "endOffset": 164}], "year": 2017, "abstractText": "Recently, several data-sets associating data to text have been created to train data-to-text surface realisers. It is unclear however to what extent the surface realisation task exercised by these data-sets is linguistically challenging. Do these data-sets provide enough variety to encourage the development of generic, high-quality data-to-text surface realisers ? In this paper, we argue that these data-sets have important drawbacks. We back up our claim using statistics, metrics and manual evaluation. We conclude by eliciting a set of criteria for the creation of a data-to-text benchmark which could help better support the development, evaluation and comparison of linguistically sophisticated data-to-text surface realisers.", "creator": "LaTeX with hyperref package"}}}