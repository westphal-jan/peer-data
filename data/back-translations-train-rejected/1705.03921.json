{"id": "1705.03921", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-May-2017", "title": "Why & When Deep Learning Works: Looking Inside Deep Learnings", "abstract": "The Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI) has been heavily supporting Machine Learning and Deep Learning research from its foundation in 2012. We have asked six leading ICRI-CI Deep Learning researchers to address the challenge of \"Why &amp; When Deep Learning works\", with the goal of looking inside Deep Learning, providing insights on how deep networks function, and uncovering key observations on their expressiveness, limitations, and potential. The output of this challenge resulted in five papers that address different facets of deep learning. These different facets include a high-level understating of why and when deep networks work (and do not work), the impact of geometry on the expressiveness of deep networks, and making deep networks interpretable.", "histories": [["v1", "Wed, 10 May 2017 18:52:26 GMT  (254kb)", "http://arxiv.org/abs/1705.03921v1", "This paper is the preface part of the \"Why &amp; When Deep Learning works looking inside Deep Learning\" ICRI-CI paper bundle"]], "COMMENTS": "This paper is the preface part of the \"Why &amp; When Deep Learning works looking inside Deep Learning\" ICRI-CI paper bundle", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ronny ronen"], "accepted": false, "id": "1705.03921"}, "pdf": {"name": "1705.03921.pdf", "metadata": {"source": "CRF", "title": "Why & When Deep Learning Works: Looking Inside Deep Learning", "authors": ["Ronny Ronen"], "emails": ["ronny.ronen@intel.com"], "sections": [{"heading": null, "text": "In fact, the fact is that most of them are not able to follow the rules that they have imposed on themselves, and that they are able to understand the rules that they have imposed on themselves. In fact, the fact is that they are able to understand the rules that they have imposed on themselves."}], "references": [{"title": "Deep learning", "author": ["Ian Goodfellow", "Yoshua Bengio", "Aaron Courville"], "venue": "Deep learning. Nature,", "citeRegEx": "Goodfellow et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "(2015); Goodfellow et al. (2016)).", "startOffset": 8, "endOffset": 33}], "year": 2017, "abstractText": "In recent years, Deep Learning has emerged as the leading technology for accomplishing broad range of artificial intelligence tasks (LeCun et al. (2015); Goodfellow et al. (2016)). Deep learning is the state-of-the-art approach across many domains, including object recognition and identification, text understating and translation, question answering, and more. In addition, it is expected to play a key role in many new usages deemed almost impossible before, such as fully autonomous driving. While the ability of Deep Learning to solve complex problems has been demonstrated again and again, there is still a lot of mystery as to why it works, what is it really capable of accomplishing, and when it works (and when it does not). Such an understanding is important for both theoreticians and practitioners, in order to know how such methods can be utilized safely and in the best possible manner. An emerging body of work has sought to develop some insights in this direction, but much remains unknown. The general feeling is that Deep learning is still by and large \u201cblack magic\u201d we know it works, but we do not truly understand why. This lack of knowledge disturbs the scientists and are a cause for concern for developers would you let an autonomous car be driven by a system whose mechanisms and weak spots are not fully understood? The Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI) has been heavily supporting Machine Learning and Deep Learning research from its foundation in 2012. We have asked six leading ICRI-CI Deep Learning researchers to address the challenge of \u201cWhy & When Deep Learning works\u201d, with the goal of looking inside Deep Learning, providing insights on how deep networks function, and uncovering key observations on their expressiveness, limitations, and potential. The output of this challenge call was quite impressive, resulting in five papers that address different facets of deep learning. These papers summarize the researchers\u2019 ongoing recent work published in leading conferences and journals as well as new research results made especially for this compilations. These different facets include a high-level understating of why and when deep networks work (and do not work), the impact of geometry on the expressiveness of deep networks, and making deep networks interpretable.", "creator": "Microsoft\u00ae Word 2013"}}}