{"id": "1705.04187", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-May-2017", "title": "On the role of words in the network structure of texts: application to authorship attribution", "abstract": "Well-established automatic analyses of texts mainly consider frequencies of linguistic units, e.g. letters, words and bigrams, while methods based on co-occurrence networks consider the structure of texts regardless of the nodes label (i.e. the words semantics). In this paper, we reconcile these distinct viewpoints by introducing a generalized similarity measure to compare texts which accounts for both the network structure of texts and the role of individual words in the networks. We use the similarity measure for authorship attribution of three collections of books, each composed of 8 authors and 10 books per author. High accuracy rates were obtained with typical values from 90% to 98.75%, much higher than with the traditional the TF-IDF approach for the same collections. These accuracies are also higher than taking only the topology of networks into account. We conclude that the different properties of specific words on the macroscopic scale structure of a whole text are as relevant as their frequency of appearance; conversely, considering the identity of nodes brings further knowledge about a piece of text represented as a network.", "histories": [["v1", "Thu, 11 May 2017 14:00:10 GMT  (513kb,D)", "http://arxiv.org/abs/1705.04187v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.SI", "authors": ["camilo akimushkin", "diego r amancio", "osvaldo n oliveira jr"], "accepted": false, "id": "1705.04187"}, "pdf": {"name": "1705.04187.pdf", "metadata": {"source": "CRF", "title": "On the role of words in the network structure of texts: application to authorship attribution", "authors": ["Camilo Akimushkina", "Diego R. Amancio", "Osvaldo N. Oliveira Jr."], "emails": ["diego.raphael@gmail.com"], "sections": [{"heading": null, "text": "Established automatic analysis of texts mainly takes into account the frequency of linguistic units, such as letters, words and bigrams, while methods based on random networks take into account the structure of texts regardless of the node designation (i.e., word semantics).In this paper, we reconcile these different perspectives by introducing a general measure of similarity to compare texts, taking into account both the network structure of texts and the role of individual words in the networks.We use the measure of similarity to assign three collections of books, each consisting of 8 authors and 10 books per author. High accuracy rates have been achieved with typical values ranging from 90% to 98.75%, much higher than the traditional TF-IDF approach for the same collections. These accuracies are also higher than just the topology of networks. We conclude that the different properties of certain words on the macroscopic scale structure of an entire text are as relevant as their frequency."}, {"heading": "1. Introduction", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "2. Methods", "text": "The proposed methodology for completing the task of author assignment consists of four steps: i) building a co-occurence network for each text; ii) creating different distance matrices for the collection using the proposed similarity metrics (see below); iii) linking the different distance matrices with multidimensional scaling [32]; and iv) analyzing the resulting data using standard supervised learning algorithms [20], which are described in detail below. The model has been applied to three collections of 80 literary texts. Each collection contains 10 texts per author for 8 19th century authors, 22 of the 24 authors being native English speakers (details of the collections are included in the Supporting Information)."}, {"heading": "2.1. Network construction and characterization", "text": "Texts are used to construct networks with stop words such as articles and prepositions, which are removed, and lemmatization is used to reduce different forms to a common basic form. < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <"}, {"heading": "2.2. Similarity metrics", "text": "The novelty of this paper is to compare the words that represent the most relevant nodes in network topology, as opposed to previous approaches that only took into account the statistics of the topological indicators. [10] We considered the nodes that had the highest degree of andweenness to be the most relevant. As for the other metrics, namely the average shortest paths and intervals, we chose the nodes with the lowest values. We tested the largest shortest paths, but the results were not as good. Intermittence obeys a power law with a positive exponent. We suspect that two pieces of text will be similar if there is significant overlap in the words (nodes) that are relevant in both texts."}, {"heading": "2.3. Combining Distance Matrices", "text": "One strength of the approach is the ability to observe different aspects of the network structure at the same time. Each metric yields a different distance matrix; therefore, we can observe the similarity between texts on different scales. We now combine information from the different metrics to have useful data for the classification algorithms. In the second strategy, we have reduced the dimensionality of distance metrics with multi-dimensional scaling (MDS). In the first, we have simply used the totality of distance matrices for the different metrics, i.e. with distances as attributes. In the second strategy, we have reduced the dimensionality of distance metrics with the aim of capturing the highest similarities, while eliminating any unnecessary information that may harm the classification task. MDS is designed to map distances in positions in a space so that the distances between these positions are reproduced as well as possible."}, {"heading": "2.4. Data analysis", "text": "The final positions in the compound space are the attributes for the data analysis algorithms. The analysis is carried out using supervised learning algorithms of the main types currently used: tree-based J48; K-Nearest Neighbors (KNN); Naive Bayesian (NB) and Radial Base Function Network (RBFN). In all cases, a 10-fold cross-validation is performed and the parameters are set to their default values [20]. For KNN, the number of neighbors is set to three, which is the smallest odd non-trivial value. For RBFN, the number of clusters is set to eight, i.e. the number of authors. Authorship is also addressed using the standard TF-IDF model. Since TF-IDF provides a distance matrix, we also use MDS in this single matrix to apply the same classification algorithms to both approaches."}, {"heading": "3. Results and Discussion", "text": "The approach to pathogens is indeed very complex, so that most people are able to suffocate and suffocate themselves."}, {"heading": "4. Conclusions", "text": "We have introduced an approach that improves the representation of text with complex networks by taking into account the words that correspond to the nodes, using a similarity metric to compare two parts of text that take into account the presence of the most relevant words according to network metrics. Significantly, when the distance matrices obtained with the similarity metrics were used as input into machine learning algorithms, a high accuracy was achieved that reached 98.75% for one of the book collections. Significantly, the accuracy was significantly higher than with traditional methods based on TFIDF, and it was also higher than with other network approaches that did not take into account the label of the nodes. Also relevant is that performance was improved by reducing dimensionality with MDS, which is advantageous due to the lower computational costs.With regard to the limitations, it should be stressed that the current approach for very short texts (such as a summary of an article) is not likely to be useful for the individual distributions, and the other methods are not."}, {"heading": "Acknowledgments", "text": "This work was supported by CNPq (Brazil) and FAPESP (grants 2014 / 20830-0, 2013 / 14262-7 and 2016 / 19069-9)."}], "references": [{"title": "D", "author": ["T.C. Silva"], "venue": "R. Amancio, EPL (Europhysics Letters) 98 ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "L", "author": ["X. Zhong", "J. Liu", "Y. Gao"], "venue": "Wu, Physica A 466 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2017}, {"title": "H", "author": ["C.D. Manning", "P. Raghavan"], "venue": "Sch\u00fctze, et al., Introduction to information retrieval, volume 1, Cambridge university press Cambridge", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "I", "author": ["M.Z. Asghar", "A. Khan", "S. Ahmad", "M. Qasim"], "venue": "A. Khan, PLoS One 12 ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2017}, {"title": "O", "author": ["D.R. Amancio"], "venue": "N. Oliveira Jr., L. F. Costa, Journal of Informetrics 6 ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "L", "author": ["M.P. Viana", "D.R. Amancio"], "venue": "F. Costa, Journal of Informetrics 7 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Foundations and Trends in information Retrieval", "author": ["P. Juola"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Soc", "author": ["E. Stamatatos", "J. Am"], "venue": "Inf. Sci. Technol. 60 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "L", "author": ["D.R. Amancio", "E.G. Altmann", "O.N. Oliveira Jr"], "venue": "F. Costa, New Journal of Physics 13 ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "D", "author": ["O.V. Kukushkina", "A. Polikarpov"], "venue": "V. Khmelev, Problems of Information Transmission 37 ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2001}, {"title": "The psycho-biology of language", "author": ["G.K. Zipf"], "venue": "Houghton, Mifflin", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1935}, {"title": "R", "author": ["R. Ferrer-i Cancho"], "venue": "V. Sol\u00e9, Journal of Quantitative Linguistics 8 ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2001}, {"title": "L", "author": ["D.R. Amancio", "C.H. Comin", "D. Casanova", "G. Travieso", "O.M. Bruno", "F.A. Rodrigues"], "venue": "F. Costa, PLoS One 9 ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "M", "author": ["J. Zhang"], "venue": "Marsza  lek, S. Lazebnik, C. Schmid, International journal of computer vision 73 ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "D", "author": ["R. Clement"], "venue": "Sharp, Literary and linguistic computing 18 ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "F", "author": ["H. Baayen", "H. Van Halteren"], "venue": "Tweedie, Literary and Linguistic Computing 11 ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1996}, {"title": "H", "author": ["J. Cong"], "venue": "Liu, Physics of Life Reviews 11 ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Proceedings of the Royal Society of London", "author": ["S.N. Dorogovtsev", "J.F.F. Mendes"], "venue": "Series B: Biological Sciences 268 ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2001}, {"title": "A", "author": ["A. Mehri", "A.H. Darooneh"], "venue": "Shariati, Physica A 391 ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "O", "author": ["C. Akimushkin", "D.R. Amancio"], "venue": "N. Oliveira Jr., PLoS One 12 ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2017}, {"title": "Modern Multidimensional Scaling: Theory and Applications", "author": ["I. Borg", "P. Groenen"], "venue": "Springer", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2005}, {"title": "G", "author": ["B.B. Greene"], "venue": "M. Rubin, Automatic grammatical tagging of english", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1971}, {"title": "A", "author": ["M. Ortuno", "P. Carpena", "P. Bernaola-Galvn", "E. Muoz"], "venue": "M. Somoza, EPL (Europhysics Letters) 57 ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2002}, {"title": "A", "author": ["H. Van Halteren", "H. Baayen", "F. Tweedie", "M. Haverkort"], "venue": "Neijt, Journal of Quantitative Linguistics 12 ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "with text summarization, information retrieval methods, polarity analysis, citation analysis, and document classification [1, 2, 3, 4, 5, 6, 7].", "startOffset": 122, "endOffset": 143}, {"referenceID": 1, "context": "with text summarization, information retrieval methods, polarity analysis, citation analysis, and document classification [1, 2, 3, 4, 5, 6, 7].", "startOffset": 122, "endOffset": 143}, {"referenceID": 2, "context": "with text summarization, information retrieval methods, polarity analysis, citation analysis, and document classification [1, 2, 3, 4, 5, 6, 7].", "startOffset": 122, "endOffset": 143}, {"referenceID": 3, "context": "with text summarization, information retrieval methods, polarity analysis, citation analysis, and document classification [1, 2, 3, 4, 5, 6, 7].", "startOffset": 122, "endOffset": 143}, {"referenceID": 4, "context": "with text summarization, information retrieval methods, polarity analysis, citation analysis, and document classification [1, 2, 3, 4, 5, 6, 7].", "startOffset": 122, "endOffset": 143}, {"referenceID": 5, "context": "with text summarization, information retrieval methods, polarity analysis, citation analysis, and document classification [1, 2, 3, 4, 5, 6, 7].", "startOffset": 122, "endOffset": 143}, {"referenceID": 2, "context": "An essential step in many of these tasks is to compare pieces of texts, as in classification of texts into categories [4] and in search engines where typically a list of texts relevant to a given query is retrieved.", "startOffset": 118, "endOffset": 121}, {"referenceID": 6, "context": "A special case is the pairwise comparison, where one searches for similarities between pairs of texts, which is actually a typical subtask in the authorship attribution process [8].", "startOffset": 177, "endOffset": 180}, {"referenceID": 7, "context": "Automatic authorship attribution has been made with varied strategies [9], from the use of first-order statistics of linguistic elements to the processing of text represented as networks [10, 11].", "startOffset": 70, "endOffset": 73}, {"referenceID": 8, "context": "Automatic authorship attribution has been made with varied strategies [9], from the use of first-order statistics of linguistic elements to the processing of text represented as networks [10, 11].", "startOffset": 187, "endOffset": 195}, {"referenceID": 9, "context": "For example, the frequency of characters [12, 13], phonemes [14], and morphemes [15, 16] has been explored, with texts normally modelled as lists of individual words, i.", "startOffset": 80, "endOffset": 88}, {"referenceID": 10, "context": "Word frequencies, which follow Zipf\u2019s law [18, 19], can then be used straightforwardly as attributes in a machine learning scheme [20] or to further build specific similarity measures.", "startOffset": 42, "endOffset": 50}, {"referenceID": 11, "context": "Word frequencies, which follow Zipf\u2019s law [18, 19], can then be used straightforwardly as attributes in a machine learning scheme [20] or to further build specific similarity measures.", "startOffset": 42, "endOffset": 50}, {"referenceID": 12, "context": "Word frequencies, which follow Zipf\u2019s law [18, 19], can then be used straightforwardly as attributes in a machine learning scheme [20] or to further build specific similarity measures.", "startOffset": 130, "endOffset": 134}, {"referenceID": 2, "context": "These variations include the use of the term frequency-inverse document frequency (TF-IDF) statistic [21, 4], where lower relevance is assigned to words frequent in the document as well as in the whole collection.", "startOffset": 101, "endOffset": 108}, {"referenceID": 13, "context": "The model has also been modified to incorporate other kinds of data, such as in the bag-offeatures model used for image analysis [22].", "startOffset": 129, "endOffset": 133}, {"referenceID": 14, "context": ", groups of n adjacent words [23, 24], in an attempt to take syntactic information into account, since the BoW model disregards word ordering.", "startOffset": 29, "endOffset": 37}, {"referenceID": 15, "context": "are used for authorship attribution [25, 26].", "startOffset": 36, "endOffset": 44}, {"referenceID": 16, "context": "An alternative perspective has been developed in recent years from the discovery that language features may be best described by complex networks models [27].", "startOffset": 153, "endOffset": 157}, {"referenceID": 8, "context": "The structure of a text, for instance, can be mapped onto a co-occurrence network [10], which is characterized by power-law distributions [19, 28], and core-periphery structures [29].", "startOffset": 82, "endOffset": 86}, {"referenceID": 11, "context": "The structure of a text, for instance, can be mapped onto a co-occurrence network [10], which is characterized by power-law distributions [19, 28], and core-periphery structures [29].", "startOffset": 138, "endOffset": 146}, {"referenceID": 17, "context": "The structure of a text, for instance, can be mapped onto a co-occurrence network [10], which is characterized by power-law distributions [19, 28], and core-periphery structures [29].", "startOffset": 138, "endOffset": 146}, {"referenceID": 8, "context": "Even though the general features of these complex networks remain analogous for texts in the same language, the network representation can also be used for classification tasks, particularly for authorship attribution [10, 30, 31].", "startOffset": 218, "endOffset": 230}, {"referenceID": 18, "context": "Even though the general features of these complex networks remain analogous for texts in the same language, the network representation can also be used for classification tasks, particularly for authorship attribution [10, 30, 31].", "startOffset": 218, "endOffset": 230}, {"referenceID": 19, "context": "Even though the general features of these complex networks remain analogous for texts in the same language, the network representation can also be used for classification tasks, particularly for authorship attribution [10, 30, 31].", "startOffset": 218, "endOffset": 230}, {"referenceID": 20, "context": "The methodology proposed to address the authorship attribution task consists of four steps: i) construct a co-occurrence network for each text; ii) obtain various distance matrices for the collection using the proposed similarity metrics (see below); iii) join the various distance matrices with multi-dimensional scaling [32]; and iv) analyze the resulting data with standard supervised learning algorithms [20].", "startOffset": 322, "endOffset": 326}, {"referenceID": 12, "context": "The methodology proposed to address the authorship attribution task consists of four steps: i) construct a co-occurrence network for each text; ii) obtain various distance matrices for the collection using the proposed similarity metrics (see below); iii) join the various distance matrices with multi-dimensional scaling [32]; and iv) analyze the resulting data with standard supervised learning algorithms [20].", "startOffset": 408, "endOffset": 412}, {"referenceID": 21, "context": "Lemmatization is assisted by a part-of-speech tagger based on entropy maximization [33], in order to solve ambiguities in mapping words to their lemmatized form.", "startOffset": 83, "endOffset": 87}, {"referenceID": 22, "context": "This metric is useful to identify keywords in written texts, irrespectively of the word frequency [34].", "startOffset": 98, "endOffset": 102}, {"referenceID": 8, "context": "In text analysis, the betweenness can be interpreted as a measure to quantify the ability of a word to appear in restrict or wider contexts [10].", "startOffset": 140, "endOffset": 144}, {"referenceID": 22, "context": "bursty) words are the ones most related to the subject being approached [34].", "startOffset": 72, "endOffset": 76}, {"referenceID": 8, "context": "Similarity metrics The novelty introduced in this work is to compare the words representing the most relevant nodes in the network topology, in contrast to previous approaches where only the statistics of topological metrics were taken into account [10].", "startOffset": 249, "endOffset": 253}, {"referenceID": 2, "context": "It is worth noting that other similarity metrics could be used to compare two pairs of texts, but the dot product adopted here appears to be the most straightforward, as it is done in bag-of-words methods [4].", "startOffset": 205, "endOffset": 208}, {"referenceID": 12, "context": "For all cases 10-fold cross validation is applied and the parameters are set to their default values [20].", "startOffset": 101, "endOffset": 105}, {"referenceID": 19, "context": "Also worth noting is that the present approach outperforms a previous one where the topology of networks was taken without considering the labels of the nodes (words) [31], for which the accuracy rates for the second collection studied here were 63.", "startOffset": 167, "endOffset": 171}, {"referenceID": 23, "context": "As some authors have pointed out [36], it is likely that every person has a characteristic writing fingerprint owing to their particular way to learn a language.", "startOffset": 33, "endOffset": 37}], "year": 2017, "abstractText": "Well-established automatic analyses of texts mainly consider frequencies of linguistic units, e.g. letters, words and bigrams, while methods based on cooccurrence networks consider the structure of texts regardless of the nodes label (i.e. the words semantics). In this paper, we reconcile these distinct viewpoints by introducing a generalized similarity measure to compare texts which accounts for both the network structure of texts and the role of individual words in the networks. We use the similarity measure for authorship attribution of three collections of books, each composed of 8 authors and 10 books per author. High accuracy rates were obtained with typical values from 90% to 98.75%, much higher than with the traditional the TF-IDF approach for the same collections. These accuracies are also higher than taking only the topology of networks into account. We conclude that the different properties of specific words on the macroscopic scale structure of a whole text are as relevant as their frequency of appearance; conversely, considering the identity of nodes brings further knowledge about a piece of text represented as a network.", "creator": "LaTeX with hyperref package"}}}