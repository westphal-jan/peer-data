{"id": "1705.04282", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2017", "title": "Learning to see people like people", "abstract": "Humans make complex inferences on faces, ranging from objective properties (gender, ethnicity, expression, age, identity, etc) to subjective judgments (facial attractiveness, trustworthiness, sociability, friendliness, etc). While the objective aspects of face perception have been extensively studied, relatively fewer computational models have been developed for the social impressions of faces. Bridging this gap, we develop a method to predict human impressions of faces in 40 subjective social dimensions, using deep representations from state-of-the-art neural networks. We find that model performance grows as the human consensus on a face trait increases, and that model predictions outperform human groups in correlation with human averages. This illustrates the learnability of subjective social perception of faces, especially when there is high human consensus. Our system can be used to decide which photographs from a personal collection will make the best impression. The results are significant for the field of social robotics, demonstrating that robots can learn the subjective judgments defining the underlying fabric of human interaction.", "histories": [["v1", "Fri, 5 May 2017 05:47:15 GMT  (4744kb,D)", "http://arxiv.org/abs/1705.04282v1", "10 pages"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG", "authors": ["amanda song", "linjie li", "chad atalla", "garrison cottrell"], "accepted": false, "id": "1705.04282"}, "pdf": {"name": "1705.04282.pdf", "metadata": {"source": "CRF", "title": "Learning to see people like people", "authors": ["Amanda Song", "Linjie Li", "Chad Atalla", "Garrison Cottrell"], "emails": ["feijuejuanling@gmail.com", "li2477@purdue.edu", "catalla@ucsd.edu", "gary@ucsd.edu"], "sections": [{"heading": "1. Introduction", "text": "Recent developments in the field of social networks have led to enormous progress."}, {"heading": "2. Related work", "text": "The focus of our work is to derive as much social judgment information as possible from a facial image and predict the subjective impression of faces by learning from human group data. We review related work in terms of the visual characteristics they use, the datasets they select, the evaluation criteria they adopt, and the social attributes they research.Visual characteristics Since the early 1990s, psychologists have found that high-grade visual characteristics, such as the average of a face [14, 21] and the symmetry of facial expression they use, have developed various visual characteristics to predict social perceptions of faces, especially facial attractiveness. Yael et al. [5] used geometric ratios and distances between facial characteristics based on facial characteristics to build a prediction of attractiveness (0.65 correlation with human raters, facial database size = 184)."}, {"heading": "3. Method", "text": "In this section, we will first describe the data set used in our experiments, then present our method for predicting social perceptions of faces, and finally explain how to visualize the characteristics that contribute most to predicting social characteristics."}, {"heading": "3.1. Dataset", "text": "To predict how humans rate social characteristics of a face at a glance, we use the data set collected by Aude Oliva's group. [2] The data set consists of 2,222 images of faces taken from the 10k US Adult Face Database and commented on for 20 pairs of social attributes. Each attribute is rated on a scale of 1-9 (1 does not mean at all, 9 means extreme) and each image is rated by 15 subjects. We take the average rating of all rating agencies as a collective assessment of social characteristics for each fact.The 20 pairs of social characteristics are: (attractive, unattractive), (happy, unhappy), (friendly, unfriendly), (sociable, introverted), (friendly, mean), (calm, aggressive), (trustworthy, unreliable, untrustworthy), (responsible, irresponsible), (confident, unreliable), (unreliable, unreliable)."}, {"heading": "3.2. Regression Model for Social Attributes", "text": "We model these social values using a regression model. Our proposed algorithm is a burr regression model for features extracted from deep Convolutionary Neural Networks (CNN). Since CNN features are usually high-dimensional, we first perform Principal Component Analysis (PCA) on the extracted features of the training set to reduce dimensionality. PCA dimensionality is selected by cross-validation on a validation set, separated for each feature. PCA weights are stored and reused to fine-tune our CNN regression model."}, {"heading": "3.3. Feature Visualization", "text": "In an attempt to understand which characteristics are most helpful in predicting social attributes, we visualize the characteristics that CNN has extracted. In previous studies of feature visualization, two different methods have been proposed: dataset-centric methods [36, 38] and a network-centric method [36, 37]. The dataset-centric method we use is to display image fields from the training set that cause high activation of feature units, and to use the deconvolution method to highlight the image parts responsible for firing the important feature neurons [36, 38]. The network-centric approach is commonly used in classification networks. This method generates an image that is based on adapting the input by maximizing output category activation using gradient ascent, i.e., it is mainly a function of the network. [36, 37] The basic idea is to optimize the target neural image so that it can be highly activated."}, {"heading": "4. Experimental framework", "text": "In this section, we report on our experimental framework using 6 CNN-based regression models relating to two basic lines, human correlation between rating groups and a baseline model using geometric characteristics."}, {"heading": "4.1. Baseline I: Human Correlations", "text": "Since these social attributes are subjective perceptions that are evaluated by people, it is instructive to examine the extent to which people agree on these social judgments. We performed the following procedure for each attribute 50 times and then obtained the results: 1. For each face, we randomly divided the 15 raters into two groups of 7 and 8 (note: the ratings for each face will generally be different sentences).2. We calculate the average ratings of the two groups for each face, obtaining two vectors of 2,222 lengths (there are 2,222 faces in the data set).3. We calculate the correlation between the two vectors. The results are presented in the second column of Table 1. For each social attribute, the averaged correlation between human subgroups serves as an index for the consistency of evaluation."}, {"heading": "4.2. Baseline II: Regression on geometric features", "text": "Previous studies on the attractiveness of the face have found that attractiveness can be derived from the geometric proportions and configurations of a face [5, 10]. We suggest that other social attributes can also be derived from geometric characteristics. We calculate 29 geometric characteristics based on the definitions described in [16] and continue to extract a \"smoothing characteristic\" and skin color characteristics according to the procedure in [5, 10]. The \"smoothness\" of a face was evaluated by applying a canny edge detector to windows from the cheek-forehead area [5]. The more edges of edge detectors within the window are detected, the less smooth the skin is. The regions we have selected for calculating smoothness and skin color are highlighted in the right subplot of Figure 2). The \"skin color\" is extracted from the same window as \"smoothing\" that is converted by edge detectors within the window."}, {"heading": "4.3. CNN-based Regression Model", "text": "First, we compared six neural network architectures: (1) VGG16, (2) VGG-Face from the VGG networks of the Oxford Visual Geometry Groups [24], (3) AlexNet (CaffeNet's publicly available reference model) [13] (4) Inception by Google [26] (5) a Siamese flat-face neural network that we trained from the ground up: Face-SNN and (6) a state-of-the-art VGG-derived network trained for the Faces localization task: Face LandmarkNN. These comparisons were performed using the Caffe Deep Learning Framework [9]. To find the best CNN for predicting social attributes among all six networks, we first found the most powerful feature layers of each network (with the comb regression model) and then the results between networks to select the best network."}, {"heading": "5. Results", "text": "Surprisingly, we found that features from Conv5 2 layer of VGG16, which were trained for object classification, slightly outperformed AlexNet and Inception networks, while the three networks trained exclusively on faces, VGG-Face, FaceLandmarkNN and Face-SNN, did not perform as competitively as the other three for most social attributes. The most powerful VGG16 layer was conv5 2.We speculate that the reason for the relatively inferior performance of the face recognition networks is that they are either optimized to learn differences between faces that define identity or to learn the facial identification configurations, whereas for this task we are looking for similarities behind certain social characteristics that go beyond identity. The Landmark network should probably provide results that match the geometric characteristics but not match the characteristics we used in this model, whereas for this task we are looking for similarities behind certain social characteristics that go beyond identity."}, {"heading": "6. Feature Visualization", "text": "In this section, we will visualize the characteristics that are important for social perception. As an example, we will choose the attractiveness of the face. The same method can also be applied to the other social characteristics. To visualize the characteristics learned through our model, we will use the two methods described in Section 3.3."}, {"heading": "6.1. Data-centric Visualization", "text": "To identify visual features that stimulate attractiveness perception, we find the top 9 units of the highest impact on attractiveness in Conv5 2 as follows: (1) Activating a unit of Conv5 2, (2) the weight of that unit on the following fc pca layer, (3) the weight of the fc pca unit on the output unit. We then sort all the Conv5 2 units of the average products of the three terms and identify the top 9 neurons as the ones that contribute most to the output neuron for the corresponding social feature. Then, we use the method described in [36, 38] to find the top 9 input images that cause high activation in each of the top 9 Conv5 2 neurons. We also produce the deconvolutionary images by projecting each activation separately to the pixel pitch. Figure 3 captures the features that are important in predicting the attractiveness of a face."}, {"heading": "6.2. Network-centric Visualization", "text": "In Section 6.1, we have identified the top 9 units and their characteristic maps from the Con5-2 layer that maximum activates the attractiveness neuron. In this case, we use the Gradient Ascent method to optimize the input image that would activate a particular neuron in the network to a high degree. This method is also performed on the pre-trained VGG16 regression model, which is trained to predict attractiveness. Figure 4a shows the optimized image that corresponds to the output neuron of a random input image. Optimizing the input image for the output neuron of a regression model does not result in a particularly interpretative image, although it seems to emphasize the eyes. Our second approach is to optimize the input image in relation to the top 9 contributing neurons from the Conve5-2 layer that were identified in Section 6.1. Figure 4b presents 9 optimized images in relation to the corresponding top 9 contextual maps from the top 9-2 layer."}, {"heading": "7. Conclusion", "text": "In fact, most of them are able to play by the rules that they have established in recent years, and they are able to play by the rules that they have set themselves."}], "references": [{"title": "Relative ranking of facial attractiveness", "author": ["H. Altwaijry", "S. Belongie"], "venue": "In Applications of Computer Vision (WACV),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "The intrinsic memorability of face photographs", "author": ["W.A. Bainbridge", "P. Isola", "A. Oliva"], "venue": "Journal of Experimental Psychology: General,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Female facial aesthetics based on soft biometrics and photo-quality", "author": ["A. Dantcheva", "J. Dugelay"], "venue": "In Proceedings of ICME,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "High level describable attributes for predicting aesthetics and interestingness", "author": ["S. Dhar", "V. Ordonez", "T.L. Berg"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Facial attractiveness: Beauty and the machine", "author": ["Y. Eisenthal", "G. Dror", "E. Ruppin"], "venue": "Neural Computation,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "The robustness of learning about the trustworthiness of other people", "author": ["V. Falvello", "M. Vinson", "C. Ferrari", "A. Todorov"], "venue": "Social Cognition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Human (homo sapiens) facial attractiveness and sexual selection: the role of symmetry and averageness", "author": ["K. Grammer", "R. Thornhill"], "venue": "Journal of comparative psychology,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}, {"title": "Predicting facial beauty without landmarks", "author": ["D. Gray", "K. Yu", "W. Xu", "Y. Gong"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "arXiv preprint arXiv:1408.5093,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "A machine learning predictor of facial attractiveness revealing human-like psychophysical biases", "author": ["A. Kagian", "G. Dror", "T. Leyvand", "I. Meilijson", "D. Cohen-Or", "E. Ruppin"], "venue": "Vision research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Modifying the memorability of face photographs", "author": ["A. Khosla", "W.A. Bainbridge", "A. Torralba", "A. Oliva"], "venue": "In Computer Vision (ICCV),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Hipster wars: Discovering elements of fashion styles", "author": ["M.H. Kiapour", "K. Yamaguchi", "A.C. Berg", "T.L. Berg"], "venue": "In European conference on computer vision,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Attractive faces are only average", "author": ["J.H. Langlois", "L.A. Roggman"], "venue": "Psychological science,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1990}, {"title": "Computer analysis of face beauty: A survey", "author": ["A. Laurentini", "A. Bottino"], "venue": "Computer Vision and Image Understanding,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "The chicago face database: A free stimulus set of faces and norming data", "author": ["D.S. Ma", "J. Correll", "B. Wittenbrink"], "venue": "Behavior research methods,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Predicting first impressions with deep learning", "author": ["M. McCurrie", "F. Beletti", "L. Parzianello", "A. Westendorp", "S. Anthony", "W. Scheirer"], "venue": "arXiv preprint arXiv:1610.08119,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "The many faces of a neutral face: Head tilt and perception of dominance and emotion", "author": ["A. Mignault", "A. Chaudhuri"], "venue": "Journal of nonverbal behavior,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2003}, {"title": "The functional basis of  (a) Original input image  (b) Optimized image Figure 5: Visualization of the optimized image with a input face image: Figure 5a is the original face image before optimization. Figure 5b is produced by performing optimization with respect to the output unit. face evaluation", "author": ["N.N. Oosterhof", "A. Todorov"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Familiarity breeds attraction: Effects of exposure on the attractiveness of typical and distinctive faces. PERCEPTION-LONDON", "author": ["M. Peskin", "F.N. Newell"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2004}, {"title": "Fitting the mind to the world face adaptation and attractiveness aftereffects", "author": ["G. Rhodes", "L. Jeffery", "T.L. Watson", "C.W. Clifford", "K. Nakayama"], "venue": "Psychological science,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2003}, {"title": "Some like it hotvisual guidance for preference prediction", "author": ["R. Rothe", "R. Timofte", "L. Van Gool"], "venue": "arXiv preprint arXiv:1510.07867,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Facial attractiveness, symmetry and cues of good genes", "author": ["J.E. Scheib", "S.W. Gangestad", "R. Thornhill"], "venue": "Proceedings of the Royal Society of London. Series B: Biological Sciences,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1999}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "End-to-end people detection in crowded scenes", "author": ["R. Stewart", "M. Andriluka", "A.Y. Ng"], "venue": "In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Deepface: Closing the gap to human-level performance in face verification", "author": ["Y. Taigman", "M. Yang", "M. Ranzato", "L. Wolf"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "Facial attractiveness", "author": ["R. Thornhill", "S.W. Gangestad"], "venue": "Trends in cognitive sciences,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1999}, {"title": "Evaluating face trustworthiness: a model based approach", "author": ["A. Todorov", "S.G. Baron", "N.N. Oosterhof"], "venue": "Social cognitive and affective neuroscience,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}, {"title": "Validation of data-driven computational models of social perception", "author": ["A. Todorov", "R. Dotsch", "J.M. Porter", "N.N. Oosterhof", "V.B. Falvello"], "venue": "of faces. Emotion,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}, {"title": "Social judgments from faces", "author": ["A. Todorov", "P. Mende-Siedlecki", "R. Dotsch"], "venue": "Current opinion in neurobiology,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}, {"title": "Social attributions from faces: Determinants, consequences, accuracy, and functional significance", "author": ["A. Todorov", "C.Y. Olivola", "R. Dotsch", "P. Mende- Siedlecki"], "venue": "Psychology, 66(1):519,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}, {"title": "Understanding evaluation of faces on social dimensions", "author": ["A. Todorov", "C.P. Said", "A.D. Engell", "N.N. Oosterhof"], "venue": "Trends in cognitive sciences,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2008}, {"title": "Bikers are like tobacco shops, formal dressers are like suits: Recognizing urban tribes with caffe", "author": ["Y. Wang", "G.W. Cottrell"], "venue": "In 2015 IEEE Winter Conference on Applications of Computer Vision,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2015}, {"title": "First impressions making up your mind after a 100-ms exposure to a face", "author": ["J. Willis", "A. Todorov"], "venue": "Psychological science,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2006}, {"title": "Understanding neural networks through deep visualization", "author": ["J. Yosinski", "J. Clune", "A. Nguyen", "T. Fuchs", "H. Lipson"], "venue": "arXiv preprint arXiv:1506.06579,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2015}, {"title": "A deep neural net trained for person categorization develops both detailed local features and broad contextual specificities", "author": ["S. Yu", "K. Zipser"], "venue": "Journal of Vision,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2016}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "In European Conference on Computer Vision, pages 818\u2013833", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2014}, {"title": "Face alignment across large poses: A 3d solution", "author": ["X. Zhu", "Z. Lei", "X. Liu", "H. Shi", "S.Z. Li"], "venue": "arXiv preprint arXiv:1511.07212,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2015}], "referenceMentions": [{"referenceID": 26, "context": "Recent advances in deep convolutional networks have driven tremendous progress in a variety of challenging face processing tasks including face recognition[27], face alignment[39], and face detection[25].", "startOffset": 155, "endOffset": 159}, {"referenceID": 38, "context": "Recent advances in deep convolutional networks have driven tremendous progress in a variety of challenging face processing tasks including face recognition[27], face alignment[39], and face detection[25].", "startOffset": 175, "endOffset": 179}, {"referenceID": 24, "context": "Recent advances in deep convolutional networks have driven tremendous progress in a variety of challenging face processing tasks including face recognition[27], face alignment[39], and face detection[25].", "startOffset": 199, "endOffset": 203}, {"referenceID": 30, "context": "However, humans not only read objective properties from a face, such as gender, expression, race, age and identity, but also form subjective impressions of the social aspects of a face[31, 32], such as facial attractiveness[28], friendliness, trustworthiness[29], sociability, dominance[18], and typicality.", "startOffset": 184, "endOffset": 192}, {"referenceID": 31, "context": "However, humans not only read objective properties from a face, such as gender, expression, race, age and identity, but also form subjective impressions of the social aspects of a face[31, 32], such as facial attractiveness[28], friendliness, trustworthiness[29], sociability, dominance[18], and typicality.", "startOffset": 184, "endOffset": 192}, {"referenceID": 27, "context": "However, humans not only read objective properties from a face, such as gender, expression, race, age and identity, but also form subjective impressions of the social aspects of a face[31, 32], such as facial attractiveness[28], friendliness, trustworthiness[29], sociability, dominance[18], and typicality.", "startOffset": 223, "endOffset": 227}, {"referenceID": 28, "context": "However, humans not only read objective properties from a face, such as gender, expression, race, age and identity, but also form subjective impressions of the social aspects of a face[31, 32], such as facial attractiveness[28], friendliness, trustworthiness[29], sociability, dominance[18], and typicality.", "startOffset": 258, "endOffset": 262}, {"referenceID": 17, "context": "However, humans not only read objective properties from a face, such as gender, expression, race, age and identity, but also form subjective impressions of the social aspects of a face[31, 32], such as facial attractiveness[28], friendliness, trustworthiness[29], sociability, dominance[18], and typicality.", "startOffset": 286, "endOffset": 290}, {"referenceID": 18, "context": "Despite the relative less attention received by the social perception of faces, social judgment is an important part of people\u2019s daily interactions, and it has significant impact on social outcomes, ranging from electoral success to sentencing decisions[19, 35].", "startOffset": 253, "endOffset": 261}, {"referenceID": 34, "context": "Despite the relative less attention received by the social perception of faces, social judgment is an important part of people\u2019s daily interactions, and it has significant impact on social outcomes, ranging from electoral success to sentencing decisions[19, 35].", "startOffset": 253, "endOffset": 261}, {"referenceID": 26, "context": "Whereas current computer vision techniques exceed human abilities at recognizing a face and identifying the objective properties of a face [27, 25], awareness of human subjective judgments is important for social robotics theory-of-mind inferences.", "startOffset": 139, "endOffset": 147}, {"referenceID": 24, "context": "Whereas current computer vision techniques exceed human abilities at recognizing a face and identifying the objective properties of a face [27, 25], awareness of human subjective judgments is important for social robotics theory-of-mind inferences.", "startOffset": 139, "endOffset": 147}, {"referenceID": 31, "context": "Accurate predictions of social aspects of faces can help robots better understand how humans interact with and perceive each other, and can make a robot aware of inherent human biases, as these judgments rarely correspond to reality (except, perhaps, attractiveness) [32].", "startOffset": 267, "endOffset": 271}, {"referenceID": 32, "context": "We examine a list of 20 pairs of social features that are typically studied by social psychologists, and that are relevant to social interactions between people [33, 32, 19].", "startOffset": 161, "endOffset": 173}, {"referenceID": 31, "context": "We examine a list of 20 pairs of social features that are typically studied by social psychologists, and that are relevant to social interactions between people [33, 32, 19].", "startOffset": 161, "endOffset": 173}, {"referenceID": 18, "context": "We examine a list of 20 pairs of social features that are typically studied by social psychologists, and that are relevant to social interactions between people [33, 32, 19].", "startOffset": 161, "endOffset": 173}, {"referenceID": 6, "context": "Examples are attractiveness [7, 28, 5, 10, 8], trustworthiness [6, 29], sociability, aggressiveness [18], friendliness, kindness, happiness, familiarity [20], and memorability [2, 11]).", "startOffset": 28, "endOffset": 45}, {"referenceID": 27, "context": "Examples are attractiveness [7, 28, 5, 10, 8], trustworthiness [6, 29], sociability, aggressiveness [18], friendliness, kindness, happiness, familiarity [20], and memorability [2, 11]).", "startOffset": 28, "endOffset": 45}, {"referenceID": 4, "context": "Examples are attractiveness [7, 28, 5, 10, 8], trustworthiness [6, 29], sociability, aggressiveness [18], friendliness, kindness, happiness, familiarity [20], and memorability [2, 11]).", "startOffset": 28, "endOffset": 45}, {"referenceID": 9, "context": "Examples are attractiveness [7, 28, 5, 10, 8], trustworthiness [6, 29], sociability, aggressiveness [18], friendliness, kindness, happiness, familiarity [20], and memorability [2, 11]).", "startOffset": 28, "endOffset": 45}, {"referenceID": 7, "context": "Examples are attractiveness [7, 28, 5, 10, 8], trustworthiness [6, 29], sociability, aggressiveness [18], friendliness, kindness, happiness, familiarity [20], and memorability [2, 11]).", "startOffset": 28, "endOffset": 45}, {"referenceID": 5, "context": "Examples are attractiveness [7, 28, 5, 10, 8], trustworthiness [6, 29], sociability, aggressiveness [18], friendliness, kindness, happiness, familiarity [20], and memorability [2, 11]).", "startOffset": 63, "endOffset": 70}, {"referenceID": 28, "context": "Examples are attractiveness [7, 28, 5, 10, 8], trustworthiness [6, 29], sociability, aggressiveness [18], friendliness, kindness, happiness, familiarity [20], and memorability [2, 11]).", "startOffset": 63, "endOffset": 70}, {"referenceID": 17, "context": "Examples are attractiveness [7, 28, 5, 10, 8], trustworthiness [6, 29], sociability, aggressiveness [18], friendliness, kindness, happiness, familiarity [20], and memorability [2, 11]).", "startOffset": 100, "endOffset": 104}, {"referenceID": 19, "context": "Examples are attractiveness [7, 28, 5, 10, 8], trustworthiness [6, 29], sociability, aggressiveness [18], friendliness, kindness, happiness, familiarity [20], and memorability [2, 11]).", "startOffset": 153, "endOffset": 157}, {"referenceID": 1, "context": "Examples are attractiveness [7, 28, 5, 10, 8], trustworthiness [6, 29], sociability, aggressiveness [18], friendliness, kindness, happiness, familiarity [20], and memorability [2, 11]).", "startOffset": 176, "endOffset": 183}, {"referenceID": 10, "context": "Examples are attractiveness [7, 28, 5, 10, 8], trustworthiness [6, 29], sociability, aggressiveness [18], friendliness, kindness, happiness, familiarity [20], and memorability [2, 11]).", "startOffset": 176, "endOffset": 183}, {"referenceID": 5, "context": "Although social perceptions of faces are subjective, there is often a consensus among human raters in how they perceive facial attractiveness, trustworthiness and dominance[6, 5].", "startOffset": 172, "endOffset": 178}, {"referenceID": 4, "context": "Although social perceptions of faces are subjective, there is often a consensus among human raters in how they perceive facial attractiveness, trustworthiness and dominance[6, 5].", "startOffset": 172, "endOffset": 178}, {"referenceID": 13, "context": "Visual features Since the early 1990s, psychologists have identified that high level visual features, such as the averageness of a face[14, 21] and the symmetry of the face [23] can explain why certain faces look more attractive.", "startOffset": 135, "endOffset": 143}, {"referenceID": 20, "context": "Visual features Since the early 1990s, psychologists have identified that high level visual features, such as the averageness of a face[14, 21] and the symmetry of the face [23] can explain why certain faces look more attractive.", "startOffset": 135, "endOffset": 143}, {"referenceID": 22, "context": "Visual features Since the early 1990s, psychologists have identified that high level visual features, such as the averageness of a face[14, 21] and the symmetry of the face [23] can explain why certain faces look more attractive.", "startOffset": 173, "endOffset": 177}, {"referenceID": 4, "context": "[5] used geometric ratios and distances between facial features based on facial landmarks to build an attractiveness predictor (0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "End-to-end neural networks were applied to predict facial attractiveness in 2010[8] (correlation 0.", "startOffset": 80, "endOffset": 83}, {"referenceID": 9, "context": "Amit Kagian and his colleagues have used a combination of landmark-derived features along with global features to obtain a high correlation with human group averages on facial attractiveness [10](0.", "startOffset": 191, "endOffset": 195}, {"referenceID": 0, "context": "Traditional computer vision features such as SIFT, HoG, Gabor filters have been blended to predict the relative ranking of facial attractiveness in [1](rank order correlation 0.", "startOffset": 148, "endOffset": 151}, {"referenceID": 23, "context": "incorporate collaborative filtering techniques with visual features extracted from pretrained VGG networks[24] to achieve individual-level prediction of facial attractiveness[22](correlation 0.", "startOffset": 106, "endOffset": 110}, {"referenceID": 21, "context": "incorporate collaborative filtering techniques with visual features extracted from pretrained VGG networks[24] to achieve individual-level prediction of facial attractiveness[22](correlation 0.", "startOffset": 174, "endOffset": 178}, {"referenceID": 16, "context": "[17] build a model based on a pretrained VGG network to predict trustworthiness, dominance and IQ in faces (R values on trustworthiness, dominance and IQ are 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "Dataset Earlier studies employ datasets with relatively small numbers of faces (a few hundred) and most face datasets use young Caucasian faces only, as pointed out by [15].", "startOffset": 168, "endOffset": 172}, {"referenceID": 1, "context": "In contrast, the MIT dataset[2] we use contains 2,222 high quality color images that vary in ethnicity, gender, age and expression, with ratings on 40 attributes.", "startOffset": 28, "endOffset": 31}, {"referenceID": 21, "context": "io, an online dating website[22] and contains 13,000 face images, but that work focused on personalized prediction of facial attractiveness, rather than average ratings.", "startOffset": 28, "endOffset": 32}, {"referenceID": 16, "context": "com, contains 6,000 grayscale face images [17], and includes just three social features: dominance, IQ and trustworthiness.", "startOffset": 42, "endOffset": 46}, {"referenceID": 1, "context": "The most common way is to ask for a discrete rating, say from 1-9 [2], or 1-7 [5] from a number of raters, and then use the group average as the score for a face in the specified feature dimension (e.", "startOffset": 66, "endOffset": 69}, {"referenceID": 4, "context": "The most common way is to ask for a discrete rating, say from 1-9 [2], or 1-7 [5] from a number of raters, and then use the group average as the score for a face in the specified feature dimension (e.", "startOffset": 78, "endOffset": 81}, {"referenceID": 9, "context": "To compare model predictions with human ratings, Pearson correlation[10, 3], Spearman rank correlation[2] and R-squared values[17] are used, depending on the nature of the data.", "startOffset": 68, "endOffset": 75}, {"referenceID": 2, "context": "To compare model predictions with human ratings, Pearson correlation[10, 3], Spearman rank correlation[2] and R-squared values[17] are used, depending on the nature of the data.", "startOffset": 68, "endOffset": 75}, {"referenceID": 1, "context": "To compare model predictions with human ratings, Pearson correlation[10, 3], Spearman rank correlation[2] and R-squared values[17] are used, depending on the nature of the data.", "startOffset": 102, "endOffset": 105}, {"referenceID": 16, "context": "To compare model predictions with human ratings, Pearson correlation[10, 3], Spearman rank correlation[2] and R-squared values[17] are used, depending on the nature of the data.", "startOffset": 126, "endOffset": 130}, {"referenceID": 0, "context": "Prediction accuracy is measured using Kendall\u2019s Tau and the Gamma Test [1].", "startOffset": 71, "endOffset": 74}, {"referenceID": 21, "context": "[22], a person indicates his/ her preference by choosing to like or dislike another user\u2019s face photo.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] and Wang et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[34] find that the social styles of people (bikers vs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "(2011) show that the interestingness of an image can be quantified and predicted [4].", "startOffset": 81, "endOffset": 84}, {"referenceID": 1, "context": "(2013) prove that the memorability of a face image can be predicted and modified to make it more memorable [2].", "startOffset": 107, "endOffset": 110}, {"referenceID": 29, "context": "[30, 31, 32] used synthesized faces to study the perception of competence, dominance, extroversion, likeability, threat, trustworthiness and attractiveness in faces [29].", "startOffset": 0, "endOffset": 12}, {"referenceID": 30, "context": "[30, 31, 32] used synthesized faces to study the perception of competence, dominance, extroversion, likeability, threat, trustworthiness and attractiveness in faces [29].", "startOffset": 0, "endOffset": 12}, {"referenceID": 31, "context": "[30, 31, 32] used synthesized faces to study the perception of competence, dominance, extroversion, likeability, threat, trustworthiness and attractiveness in faces [29].", "startOffset": 0, "endOffset": 12}, {"referenceID": 28, "context": "[30, 31, 32] used synthesized faces to study the perception of competence, dominance, extroversion, likeability, threat, trustworthiness and attractiveness in faces [29].", "startOffset": 165, "endOffset": 169}, {"referenceID": 16, "context": "[17] have worked toward removing this limitation by using real human faces to make predictions of trustworthiness and dominance ratings.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] and Todorov.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "et al[29], most machine learning work on social perception of faces focuses on attractiveness prediction, leaving the prediction of other social perceptions largely unstudied.", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "(ii) As summarized by Laurentini et al[15] usually small datasets are used, with few variations on expression, gender, ethnicity and age.", "startOffset": 38, "endOffset": 42}, {"referenceID": 16, "context": "[17] and Todorov.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "et al[29].", "startOffset": 5, "endOffset": 9}, {"referenceID": 16, "context": "[17] predict three social features, dominance, trustworthiness, and IQ, whereas we look at 40 social features including trustworthiness, aggressiveness (a term close to their dominance), and intelligence (close to their IQ term), so our feature set can be considered to be a superset of theirs; and (3) we compared various feature extraction methods, including traditional geometric features and 6 neural networks pretrained for various tasks (face identification, face localization, object recognition).", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "To predict how human evaluate social traits of a face at a glance, we use the dataset collected by Aude Oliva\u2019s group [2].", "startOffset": 118, "endOffset": 121}, {"referenceID": 35, "context": "Two different methods were proposed in past feature visualization studies: dataset-centric methods [36, 38], and a network-centric method[36, 37].", "startOffset": 99, "endOffset": 107}, {"referenceID": 37, "context": "Two different methods were proposed in past feature visualization studies: dataset-centric methods [36, 38], and a network-centric method[36, 37].", "startOffset": 99, "endOffset": 107}, {"referenceID": 35, "context": "Two different methods were proposed in past feature visualization studies: dataset-centric methods [36, 38], and a network-centric method[36, 37].", "startOffset": 137, "endOffset": 145}, {"referenceID": 36, "context": "Two different methods were proposed in past feature visualization studies: dataset-centric methods [36, 38], and a network-centric method[36, 37].", "startOffset": 137, "endOffset": 145}, {"referenceID": 35, "context": "The dataset-centric method we employed is to display image patches from the training set that cause high activation for the feature units and use the deconvolution method to highlight the portions of the image that are responsible for firing the important feature neurons [36, 38].", "startOffset": 272, "endOffset": 280}, {"referenceID": 37, "context": "The dataset-centric method we employed is to display image patches from the training set that cause high activation for the feature units and use the deconvolution method to highlight the portions of the image that are responsible for firing the important feature neurons [36, 38].", "startOffset": 272, "endOffset": 280}, {"referenceID": 35, "context": "[36, 37].", "startOffset": 0, "endOffset": 8}, {"referenceID": 36, "context": "[36, 37].", "startOffset": 0, "endOffset": 8}, {"referenceID": 4, "context": "Past studies on facial attractiveness have found that attractiveness can be inferred from the geometric ratios and configurations of a face[5, 10].", "startOffset": 139, "endOffset": 146}, {"referenceID": 9, "context": "Past studies on facial attractiveness have found that attractiveness can be inferred from the geometric ratios and configurations of a face[5, 10].", "startOffset": 139, "endOffset": 146}, {"referenceID": 15, "context": "We compute 29 geometric features based on definitions described in [16] and further extract a \u201dsmoothness\u201d feature and skin color features according to the procedure in [5, 10].", "startOffset": 67, "endOffset": 71}, {"referenceID": 4, "context": "We compute 29 geometric features based on definitions described in [16] and further extract a \u201dsmoothness\u201d feature and skin color features according to the procedure in [5, 10].", "startOffset": 169, "endOffset": 176}, {"referenceID": 9, "context": "We compute 29 geometric features based on definitions described in [16] and further extract a \u201dsmoothness\u201d feature and skin color features according to the procedure in [5, 10].", "startOffset": 169, "endOffset": 176}, {"referenceID": 4, "context": "Canny edge detector to windows from the cheek/forehead area [5].", "startOffset": 60, "endOffset": 63}, {"referenceID": 23, "context": "We initially compared six neural network architectures: (1) VGG16, (2) VGG-Face from the Oxford Visual Geometry Groups VGG networks[24], (3) AlexNet (the publicly available CaffeNet reference model) [13] (4) Inception from Google [26] (5) a shallow face identification Siamese neural network that we trained from scratch: Face-SNN and (6) a state of the art VGG-derived network trained for the face landmark localization task: Face-LandmarkNN.", "startOffset": 131, "endOffset": 135}, {"referenceID": 12, "context": "We initially compared six neural network architectures: (1) VGG16, (2) VGG-Face from the Oxford Visual Geometry Groups VGG networks[24], (3) AlexNet (the publicly available CaffeNet reference model) [13] (4) Inception from Google [26] (5) a shallow face identification Siamese neural network that we trained from scratch: Face-SNN and (6) a state of the art VGG-derived network trained for the face landmark localization task: Face-LandmarkNN.", "startOffset": 199, "endOffset": 203}, {"referenceID": 25, "context": "We initially compared six neural network architectures: (1) VGG16, (2) VGG-Face from the Oxford Visual Geometry Groups VGG networks[24], (3) AlexNet (the publicly available CaffeNet reference model) [13] (4) Inception from Google [26] (5) a shallow face identification Siamese neural network that we trained from scratch: Face-SNN and (6) a state of the art VGG-derived network trained for the face landmark localization task: Face-LandmarkNN.", "startOffset": 230, "endOffset": 234}, {"referenceID": 8, "context": "These comparisons were performed with the Caffe deep learning framework [9].", "startOffset": 72, "endOffset": 75}, {"referenceID": 35, "context": "Then we employ the method described in [36, 38] to find top-9 input images that cause high activations in each of the top-9 conv5 2 neurons.", "startOffset": 39, "endOffset": 47}, {"referenceID": 37, "context": "Then we employ the method described in [36, 38] to find top-9 input images that cause high activations in each of the top-9 conv5 2 neurons.", "startOffset": 39, "endOffset": 47}, {"referenceID": 37, "context": "For conv5 2 layer, we show the top 9 activations of the top 9 neurons that maximally activate the attractiveness neuron across the training data, projected down to pixel space using the deconvolutional network approach [38] and their corresponding cropped image patches.", "startOffset": 219, "endOffset": 223}], "year": 2017, "abstractText": "The human perceptual system can make complex inferences on faces, ranging from the objective evaluations regarding gender, ethnicity, expression, age, identity, etc. to subjective judgments on facial attractiveness, trustworthiness, sociability, friendliness, etc. Whereas the objective aspects have been extensively studied, less attention has been paid to modeling the subjective perception of faces. Here, we adapt 6 state-of-the-art neural networks pretrained on various image tasks (object classification, face identification, face localization) to predict human ratings on 40 social judgments of faces in the 10k US Adult Face Database. Supervised ridge regression on PCA of the conv5 2 layer in VGG-16 network gives best predictions on the average human ratings. Human group agreement was evaluated by repeatedly randomly splitting the raters into two halves for each face, and calculating the Pearson correlation between the two sets of averaged ratings. Due to this methodology, the models correlations with the average human ratings can exceed this score. We find that 1) model performance grows as the consensus on a face trait increases, and 2) model correlations are always higher than human correlations with each other. These results illustrate the learnability of the subjective perception of faces, especially when there is consensus, and the striking versatility and transferability of representations learned for object recognition. This work has strong applications to social robotics, allowing robots to infer human judgments of each other.", "creator": "LaTeX with hyperref package"}}}