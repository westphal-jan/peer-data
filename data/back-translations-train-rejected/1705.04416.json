{"id": "1705.04416", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-May-2017", "title": "Evaluating vector-space models of analogy", "abstract": "Vector-space representations provide geometric tools for reasoning about the similarity of a set of objects and their relationships. Recent machine learning methods for deriving vector-space embeddings of words (e.g., word2vec) have achieved considerable success in natural language processing. These vector spaces have also been shown to exhibit a surprising capacity to capture verbal analogies, with similar results for natural images, giving new life to a classic model of analogies as parallelograms that was first proposed by cognitive scientists. We evaluate the parallelogram model of analogy as applied to modern word embeddings, providing a detailed analysis of the extent to which this approach captures human relational similarity judgments in a large benchmark dataset. We find that that some semantic relationships are better captured than others. We then provide evidence for deeper limitations of the parallelogram model based on the intrinsic geometric constraints of vector spaces, paralleling classic results for first-order similarity.", "histories": [["v1", "Fri, 12 May 2017 01:26:23 GMT  (471kb,D)", "http://arxiv.org/abs/1705.04416v1", "6 pages, 4 figures, To appear in the Proceedings of the 39th Annual Conference of the Cognitive Science Society"], ["v2", "Thu, 8 Jun 2017 20:52:12 GMT  (471kb,D)", "http://arxiv.org/abs/1705.04416v2", "6 pages, 4 figures, In the Proceedings of the 39th Annual Conference of the Cognitive Science Society"]], "COMMENTS": "6 pages, 4 figures, To appear in the Proceedings of the 39th Annual Conference of the Cognitive Science Society", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["dawn chen", "joshua c peterson", "thomas l griffiths"], "accepted": false, "id": "1705.04416"}, "pdf": {"name": "1705.04416.pdf", "metadata": {"source": "CRF", "title": "Evaluating vector-space models of analogy", "authors": ["Dawn Chen", "Joshua C. Peterson", "Thomas L. Griffiths"], "emails": ["(sdawnchen@gmail.com)", "(peterson.c.joshua@gmail.com)", "griffiths@berkeley.edu)"], "sections": [{"heading": "Introduction", "text": "In fact, it is as if most people are able to determine for themselves what they want and what they want to do. It is not as if they do it as if they would do it, but it is as if they would do it. It is as if they would do it, but it is as if they would do it, but it is as if they would do it. It is as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, as if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if they would do it, if it, if they would do it,"}, {"heading": "Relational Similarity", "text": "This year, it is only a matter of time before we reach an agreement."}, {"heading": "Violations of Geometric Constraints", "text": "We have to engage with certain geometric constraints, such as symmetry (the distance from x to y is the same as the distance from x to x) and the triangle inequality (if the distance between x and y is small and the distance between the evaluations is small, then the distance between x and z cannot be very large). The similarity between the two types used to measure the similarity between words is as great as the symmetry and analogy of the triangle inequality (Griffiths, Steyvers, Tenenbaum, 2007). But psychological representations of similarity do not always obey the theories (Tversky, 1977). The famous example of this is that people judge in a similar way to China, a violation of symmetry around them. (Griffiths, et al. (2007) we examined the word representations derived from Latent Semantic Analysis)."}, {"heading": "Conclusions", "text": "Our results provide a clearer picture of the usefulness of vector space models of analogy. The parallelogram model makes good predictions for human relational similarity judgments for some relationships, but is less suitable for others. Consider, for example, the pairs of words presented as vectors in Figure 2. Predictably, the SIMILAR relationship seems best represented by a short difference vector rather than by the direction of the difference vector. More generally, in more complex source and target analogies, both consist of many points in vector space, one could imagine many types of relationships between the two points.More difficult are the constraints of the geometric axioms. In our data sets, we found significant violations of two of these axioms that cannot be overcome by better embedding methods. In view of this, it would be interesting to follow the history of first-order models of similarity."}], "references": [{"title": "A taxonomy of semantic relations. In Cognitive and psychometric analysis of analogical problem solving (pp. 55\u201391)", "author": ["I.I. Bejar", "R. Chaffin", "S. Embretson"], "venue": null, "citeRegEx": "Bejar et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Bejar et al\\.", "year": 1991}, {"title": "Perception of timbral analogies", "author": ["D. Ehresman", "D.L. Wessel"], "venue": "Psychological review,", "citeRegEx": "Ehresman and Wessel,? \\Q1978\\E", "shortCiteRegEx": "Ehresman and Wessel", "year": 1978}, {"title": "Topics in semantic representation", "author": ["T.L. Griffiths", "M. Steyvers", "J.B. Tenenbaum"], "venue": "Psychological Review,", "citeRegEx": "Griffiths et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Griffiths et al\\.", "year": 2007}, {"title": "A solution to plato\u2019s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge", "author": ["T. K", "S.T. Dumais"], "venue": "Psychological Review,", "citeRegEx": "K. and Dumais,? \\Q1997\\E", "shortCiteRegEx": "K. and Dumais", "year": 1997}, {"title": "Bayesian analogy with relational transformations", "author": ["H. Lu", "D. Chen", "K.J. Holyoak"], "venue": "Psychological review,", "citeRegEx": "Lu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lu et al\\.", "year": 2012}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434", "author": ["A. 1543). Radford", "L. Metz", "S. Chintala"], "venue": null, "citeRegEx": "Radford et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Radford et al\\.", "year": 2015}, {"title": "Advances in neural information processing systems (pp. 1252\u20131260)", "author": ["analogy-making"], "venue": "Wiley Interdisciplinary Reviews: Cognitive Science,", "citeRegEx": "analogy.making.,? \\Q2015\\E", "shortCiteRegEx": "analogy.making.", "year": 2015}, {"title": "A model for analogical reasoning", "author": ["D.E. Rumelhart", "A.A. Abrahamson"], "venue": "Cognitive Psychology,", "citeRegEx": "Rumelhart and Abrahamson,? \\Q1973\\E", "shortCiteRegEx": "Rumelhart and Abrahamson", "year": 1973}], "referenceMentions": [{"referenceID": 7, "context": "An instantiation of this hypothesis is the parallelogram model of analogy (see Figure 1), first proposed by Rumelhart and Abrahamson (1973) over 40 years ago.", "startOffset": 108, "endOffset": 140}, {"referenceID": 2, "context": "Griffiths et al. (2007) examined the word representations derived by", "startOffset": 0, "endOffset": 24}, {"referenceID": 2, "context": "In light of this, it would be interesting to follow the history of models of first-order similarity in considering the use of featural representations (Tversky, 1977), exploring methods of measuring similarity in vector spaces that are no longer subject to the constraints imposed by the metric axioms (Krumhansl, 1978), or reformulating the problem as probabilistic inference (Griffiths et al., 2007).", "startOffset": 377, "endOffset": 401}], "year": 2017, "abstractText": "Vector-space representations provide geometric tools for reasoning about the similarity of a set of objects and their relationships. Recent machine learning methods for deriving vectorspace embeddings of words (e.g., word2vec) have achieved considerable success in natural language processing. These vector spaces have also been shown to exhibit a surprising capacity to capture verbal analogies, with similar results for natural images, giving new life to a classic model of analogies as parallelograms that was first proposed by cognitive scientists. We evaluate the parallelogram model of analogy as applied to modern word embeddings, providing a detailed analysis of the extent to which this approach captures human relational similarity judgments in a large benchmark dataset. We find that that some semantic relationships are better captured than others. We then provide evidence for deeper limitations of the parallelogram model based on the intrinsic geometric constraints of vector spaces, paralleling classic results for first-order similarity.", "creator": "LaTeX with hyperref package"}}}