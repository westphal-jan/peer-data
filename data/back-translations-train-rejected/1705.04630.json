{"id": "1705.04630", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-May-2017", "title": "Forecasting using incomplete models", "abstract": "We consider the task of forecasting an infinite sequence of future observation based on some number of past observations, where the probability measure generating the observations is \"suspected\" to satisfy one or more of a set of incomplete models, i.e. convex sets in the space of probability measures. This setting is in some sense intermediate between the realizable setting where the probability measure comes from some known set of probability measures (which can be addressed using e.g. Bayesian inference) and the unrealizable setting where the probability measure is completely arbitrary. We demonstrate a method of forecasting which guarantees that, whenever the true probability measure satisfies an incomplete model in a given countable set, the forecast converges to the same incomplete model in the (appropriately normalized) Kantorovich-Rubinstein metric. This is analogous to merging of opinions for Bayesian inference, except that convergence in the Kantorovich-Rubinstein metric is weaker than convergence in total variation.", "histories": [["v1", "Fri, 12 May 2017 15:38:57 GMT  (19kb)", "https://arxiv.org/abs/1705.04630v1", null], ["v2", "Fri, 28 Jul 2017 12:33:39 GMT  (23kb)", "http://arxiv.org/abs/1705.04630v2", "28 pages"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["vadim kosoy"], "accepted": false, "id": "1705.04630"}, "pdf": {"name": "1705.04630.pdf", "metadata": {"source": "CRF", "title": "Forecasting using incomplete models", "authors": ["Vadim Kosoy"], "emails": ["vadim.kosoy@intelligence.org"], "sections": [{"heading": null, "text": "Most of these methods assume that establishing a class H of models or \"hypotheses,\" each of which defines a probability measurement on the consequences of observations (and also conditional probability scales), and produce a forecast that fulfills at least one of two types of guarantees: \u2022 The guarantee is that the observations from some countries of the world will be sampled, then converges FH to an \"ideal\" forecast in some sense. \u2022 In the unrealizable setting is the guarantee that FH will become an \"ideal\" forecast."}], "references": [{"title": "Prediction, Learning, and Games", "author": ["Nicolo Cesa-Bianchi", "Gabor Lugosi"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Understanding Machine Learning: From Theory to Algorithms", "author": ["Shai Shalev-Shwartz", "Shai Ben-David"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Open problems in universal induction ", "author": ["Marcus Hutter"], "venue": "intelligence. Algorithms,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Merging of opinions with increasing information", "author": ["David Blackwell", "Lester Dubins"], "venue": "Ann. Math. Statist., 33(3):882\u2013886,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1962}, {"title": "Using and combining predictors that specialize", "author": ["Yoav Freund", "Robert E. Schapire", "Yoram Singer", "Manfred K. Warmuth"], "venue": "In Proceedings of the Twenty-ninth Annual ACM Symposium on Theory of Computing,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1997}, {"title": "Probability: Theory and Examples", "author": ["Rick Durrett"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Existence of maximal elements and equilibria in linear topological spaces", "author": ["Nicholas C. Yannelis", "N.D. Prabhakar"], "venue": "Journal of Mathematical Economics,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1983}], "referenceMentions": [{"referenceID": 0, "context": "[1] or Chapter 21 in [2]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[1] or Chapter 21 in [2]).", "startOffset": 21, "endOffset": 24}, {"referenceID": 2, "context": "o2k+1 = o2k, then whatever is the behavior of the even observations o2k, the property o2k+1 = o2k should asymptotically be assigned high probability by the forecast (this idea was discussed in [3] as \u201copen problem 4j\u201d).", "startOffset": 193, "endOffset": 196}, {"referenceID": 3, "context": "This convergence theorem can be regarded as an analogue for incomplete models of Bayesian merging of opinions (see [4]), and is our main result.", "startOffset": 115, "endOffset": 118}, {"referenceID": 4, "context": "= 1 (13) If we only cared about predicting the next observation (as opposed to producing a probability measure over the entire sequence), this example (and any other instance of Example 2, at least in the case On = O finite) would be a special case of the \u201csleeping experts\u201d setting in online learning (see [6]).", "startOffset": 307, "endOffset": 310}, {"referenceID": 3, "context": "Theorem 1 is formulated using the Kantorovich-Rubinstein metric, but instead we could have considered to total variation metric dTV, as in Bayesian merging of opinions [4].", "startOffset": 168, "endOffset": 171}, {"referenceID": 2, "context": "Finally, we think that the current work may have some bearing on the so-called \u201cgrain of truth\u201d problem (problem 5j in [3]).", "startOffset": 119, "endOffset": 122}, {"referenceID": 5, "context": "A Appendix: Some Useful Theorems The following variant of the Optional Stopping Theorem appears in [7] as Theorem 5.", "startOffset": 99, "endOffset": 102}, {"referenceID": 6, "context": "We also define the \u03c3-algebra FM \u2286 2 \u03a9 by FM := {A \u2286 X measurable | \u2200n \u2208 N : A \u2229M \u22121 (n) \u2208 Fn} (47) Then: E [ XN | FM ] \u2265 XM (48) The following variant of the Michael selection theorem appears in [8] as Theorem 3.", "startOffset": 195, "endOffset": 198}], "year": 2017, "abstractText": "We consider the task of forecasting an infinite sequence of future observations based on some number of past observations, where the probability measure generating the observations is \u201csuspected\u201d to satisfy one or more of a set of incomplete models, i.e. convex sets in the space of probability measures. This setting is in some sense intermediate between the realizable setting where the probability measure comes from some known set of probability measures (which can be addressed using e.g. Bayesian inference) and the unrealizable setting where the probability measure is completely arbitrary. We demonstrate a method of forecasting which guarantees that, whenever the true probability measure satisfies an incomplete model in a given countable set, the forecast converges to the same incomplete model in the (appropriately normalized) KantorovichRubinstein metric. This is analogous to merging of opinions for Bayesian inference, except that convergence in the Kantorovich-Rubinstein metric is weaker than convergence in total variation.", "creator": "LaTeX with hyperref package"}}}