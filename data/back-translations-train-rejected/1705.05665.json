{"id": "1705.05665", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2017", "title": "Learning Image Relations with Contrast Association Networks", "abstract": "Inferring the relations between two images is an important class of tasks in computer vision. Examples of such tasks include computing optical flow and stereo disparity. We treat the relation inference tasks as a machine learning problem and tackle it with neural networks. A key to the problem is learning a representation of relations. We propose a new neural network module, contrast association unit (CAU), which explicitly models the relations between two sets of input variables. Due to the non-negativity of the weights in CAU, we adopt a multiplicative update algorithm for learning these weights. Experiments show that neural networks with CAUs are more effective in learning five fundamental image transformations than conventional neural networks.", "histories": [["v1", "Tue, 16 May 2017 12:09:44 GMT  (201kb)", "http://arxiv.org/abs/1705.05665v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["yao lu", "zhirong yang", "juho kannala", "samuel kaski"], "accepted": false, "id": "1705.05665"}, "pdf": {"name": "1705.05665.pdf", "metadata": {"source": "CRF", "title": "Learning Image Relations with Contrast Association Networks", "authors": ["Yao Lu", "Zhirong Yang", "Juho Kannala", "Samuel Kaski"], "emails": ["yaolubrain@gmail.com"], "sections": [{"heading": null, "text": "ar Xiv: 170 5.05 665v 1 [cs.C V] 16 M"}, {"heading": "1 Introduction", "text": "A key to this success is that the neural networks provide a representation of appearance that is invariable for multiple image transformations such as small translation methods. Another important class of tasks in computer vision is the inference of relationships between two images. Two images can be related through object movement, camera movement, or environmental factors such as light changes. For these problems, instead of aiming at the invariance of appearance changes, we want to detect and estimate these changes. For example, in the face of two successive video frames, we want to derive the movement of each pixel from one image to another. Another example is two images taken by a moving robot, we want to derive the ego movement of the robot (visual odometry). The traditional approach to performing the relation of tasks is knowledge-based."}, {"heading": "2.1 Concatenation Units", "text": "(3) For this simple representation g (\u00b7) is solely responsible for learning the relations between a and b. Chain units were used in learning the optical flow [8] and the ego movement [2]."}, {"heading": "2.2 Bilinear Units", "text": "Bilinear units have already been proposed and developed [13, 31, 39]. They are defined as, for the k-th unit, hk = \u2211 ijWijkaibj = a TWkb, (4) where Wk are the parameters to be learned. A bilinear unit models the pair-by-pair multiplicative intersection between two groups of input variables. It corresponds to the inner product if Wk is the identity matrix and equivalent to the outer product, since (4) can be written as hk = vec (Wk) T vec (abT), where vec (\u00b7) means vectorization. Bilinear units have been used in [30, 35] for image transformations in the learning process."}, {"heading": "3 Contrast Association Units", "text": "We propose a new unit of relation, Contrast Association Unit (CAU), which associates two sets of input variables. CAU can be used as a weighted sum of mismatches between a and b. The non-negative constraint of weight matrices is essential, since the mismatches should not be negative to be cumulated. Otherwise, positive mismatches and negative mismatches would cancel each other out. Compared to concatenation and bilinear units, CAU have two advantages: (1), as the name suggests, CAUs model the contrast between two groups of variables such that R (a + c, b + c) = R (a, b), where c is a scalar applied to each element of a vector."}, {"heading": "3.1 Competition", "text": "A classic competition mechanism is the winner-take-all (WTA), defined as ash \u2032 k = {1, if hk = min (h), 0, otherwise. (6) WTA is of conceptual interest, as demonstrated in Section 3.2. WTA, however, is indistinguishable and discards too much information. In practice, we can use softmin competition, defined as ash \u2032 k = e \u2212 hk \u0445 i \u2212 hi. (7) In all our experiments, the addition of the softmin competition significantly improves the results of neural networks with CAUs."}, {"heading": "3.2 Example", "text": "To understand how neural networks interact with CAEs, consider a simple example of translation recognition. Leta = (c1, c2, c3, c4, c5), (8) b1 = (c2, c3, c4, c5, c6), (9) b2 = (c1, c2, c3, c4, c5), (10) b3 = (c0, c1, c3, c4), (11), where {ci} are arbitrary numbers. (1, 0, 1} the translation variable andb = b1, if z = 1, b2, if z = 1, b3, if z = 1. (12) Denote of D (a, b) is the matrix of the pair square differences of elements in a and b. 0, 1} the translation variable andb = b1, if z = 1, b2, b2 if z = 0, bote, b1, b3, b1, bb = 1, and b = 1, and b = 1, and b = 1."}, {"heading": "3.3 Low-rank Approximation", "text": "IfWk is large, we can approximate it as follows: letWk = ukv T k, where uk and vk are a series of non-negative matrices U and V, respectively. Then, the right side of (5) in the matrix form ash * = 12 [(V1) \u0445 U (a) 2 + (U1) \u0445 V (b) 2] \u2212 (Ua) \u0445 (Vb), (15) where 1 is a vector of ones, \u0445 is the elemental multiplication and (\u00b7) 2 is the elemental square. The derivative can be found in the appendix. To get CAU's higher ranks, we can apply sumpooling via h \u0445. That is, we divide h \u0445 into non-overlapping groups of equal size and sum the units in each group."}, {"heading": "4 Learning", "text": "To learn the non-negative weights in CAUs (Wk for full rank or U and V for rank one), conventional gradient descend-based algorithms are not suitable because the non-negativity of the weights cannot be maintained after each update. To solve the above problem, we use a multiplicative update algorithm for the non-negative weight matrices in a neural network that was originally used for non-negative factoring. [27] For a non-negative matrix W in a neural network and loss function E, we split the gradient into two positive parts E = negative weight matrices in a neural network that was originally used for non-negative factoring."}, {"heading": "5 Related Work", "text": "A classical model related to the proposed CAU is the energy model for motion detection [1] and stereodisparity [9]. Each unit of the energy model calculates the sum of the squares of two Gabor filter outputs. No learning is involved in the energy model. There are models that calculate the sum of the squares of learnable filter outputs, such as adaptive-subspace self-organized maps (ASSOM) [21] and independent sub-space analysis (ISA) [16]. Similar to CAU, ASSOM also has a competitive mechanism (WTA), but the goal of both ASSOM and ISA is to learn manifestations that are invariant in image transformations rather than our goal. There is a research line for learning relationships based on Boltzmann machines [30, 38, 15] whereas Boltzmann machines allow probable formulation of relation conclusions, the formation of Boltzmann machines is less likely than our goal. [30]"}, {"heading": "6 Experiments", "text": "We look at five basic image transformations for the relationship learning tasks. For image x, its transformed image y is synthetically generated using the transformation parameters of the basic truth (or relation variables) z. For each task, neural networks are trained in a supervised manner, with x and y being given as input and z as targets. In addition, we evaluate the models trained on synthetic data on real-world images with the transformation parameters of the basic truth. Below, we describe the details."}, {"heading": "6.1 Tasks", "text": "The five image transformations are: translation, rotation, scaling, affine transformation and projective transformation. They are called geometric transformations and can be unified as follows [11]. An image can be transformed (or distorted) by changing its coordinates. For each point of an image with homogeneous coordinates, the transformed point is p \u2032 = Hp with homographic matrixH = [h11 h12 h13 h21 h22 h22 h23 h31 h32 h33]. (19) The type of transformation depends on the parameterization of H. Note that translation, rotation and scaling are special cases of affinic transformation and affinic transformation. We list the parameterization in each task and the range of transformation parameters in the training data below in Table 1."}, {"heading": "6.2 Data", "text": "For each task and each image in CIFAR-10, we use an image transformation with z randomly from uniform distributions to obtain a pair of images. We then crop an image area of the size 11 x 11 in the center of each image of the pair. Repeat the process 10 times. In this process, we obtain a training set of the size 500,000 and a test set of the size 100,000 for the learning tasks in the relationship. In addition, we use a real dataset 2 with ground-level homographies to evaluate the trained models in consequent projective transformations. We sample 100,000 pairs of corresponding image fields of the size 11 x 11 in the first two gray-scaled frames of four image sequences (graffiti, wall, bark, and boot). Given the homography H between two whole images, the homography between two image fields of the size 11 x 11 x 11 in the first two gray-scaled frames corresponds to four image sequences (graffiti, wall, bark, and boot)."}, {"heading": "6.3 Models", "text": "We are testing three models of neural networks, each of which uses a different type of relation unit: concatenation, bilinear, and CAU. In all models, f (\u00b7) is the identity function, and g (\u00b7) is a multi-layer perceptron. We are referring to the three models of neural networks as concatenation (CTN), bilinear networks (BLN), and contrast association networks (CAN), respectively. In BLN and CAN, we are using an approximation of the two-layer units and low-level CAUs as described in Section 3.3. In BLN, we are applying l2 normalization, which works empirically better than Softmax (or Softmin), to the results of bilinear units. To test generality, we also experimented with the non-negative constraint of the two-layer units, but found that they work poorly and therefore discarded them. To ensure the fairness of comparison, all three models are designed to have essentially the same size in each task."}, {"heading": "6.4 Settings", "text": "The numerical range of each element of the vectors is normalized from [0, 255] to [\u2212 0.5, 0.5] by dividing 255 and then subtracting 0.5. This normalization greatly speeds up training. We use the Mean Square Error (MSE) as a loss function. We use the Multiplicative Update Algorithm (described in Section 4) for non-negative weights (U and V) and Adam [20] for unrestricted weights. For all models in all tasks, we use the same training hyperparameter setting. The initial learning rate is \u03b7 = 0.005 (Multiplicative Update) and \u03b1 = 0.005 (Adam), both multiplied by 0.95 per 500 minibatch updates. The size of each minibatch is 100. In total, there are 200,000 minibatch updates."}, {"heading": "6.5 Results", "text": "We use two measures of error to evaluate our results. \u2022 Parameter error. It is defined as the MSE between the soil truth transformation parameters z and the derived parameters z, i.e. it is difficult to compare the inference error between tasks because different tasks have different transformation parameters. \u2022 Transformation error. As shown in Figure 3, define four points with homogeneous coordinates1 = (0, 0, 1), p2 = (1, 0, 1), p4 = (0, 1, 1). Leave p \u00b2 i = Hpi the transformed point with the soil truth homography H and leave p \u00b2 pi = H \u00b2 pi the transformed point with the resulting transformation."}, {"heading": "7 Dicussion", "text": "In our current work, the experiments are limited to small image fields and simple image transformations. It is not clear how well CAUs work on whole images and more complex tasks. Future work includes the extension of CAUs to handle entire images and more complex tasks such as three-dimensional transformations. Appendix xRank-One Approximation of CAUSinceWk = ukv T k, we havehk = 12 \u0445 ijWijk (ai \u2212 bj) 2 (21) = 12 \u0445 ijWijk (a 2 i + b 2 j) \u2212 jWijkaibj (22) \u2212 jWijkaibj (12) [1TWTk (a) 2 + 1TWWk (b) 2 \u2212 uk \u2212 aTWkb (23) = 12 [1Tvku T k k (a) 2 + 1Tukv T k T k (b) \u2212 hDijWijk (a) 2 + 1Tukv T (b) \u2212 W \u00b2 T (b) \u2212 vv T (2), Dik (2 k) \u2212 W (k) \u2212 T (kk) \u2212 T (1k)."}], "references": [{"title": "Spatiotemporal energy models for the perception of motion", "author": ["E.H. Adelson", "J.R. Bergen"], "venue": "JOSA A,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1985}, {"title": "Learning to see by moving", "author": ["P. Agrawal", "J. Carreira", "J. Malik"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Exploiting semantic information and deep matching for optical flow", "author": ["M. Bai", "W. Luo", "K. Kundu", "R. Urtasun"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Cnn-based patch matching for optical flow with thresholded hinge loss", "author": ["C. Bailer", "K. Varanasi", "D. Stricker"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "A naturalistic open source movie for optical flow evaluation", "author": ["D.J. Butler", "J. Wulff", "G.B. Stanley", "M.J. Black"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Learning understandable neural networks with nonnegative weight constraints", "author": ["J. Chorowski", "J.M. Zurada"], "venue": "IEEE TNNLS,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Multi-column deep neural networks for image classification", "author": ["D. Ciresan", "U. Meier", "J. Schmidhuber"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Flownet: Learning optical flow with convolutional networks", "author": ["A. Dosovitskiy", "P. Fischer", "E. Ilg", "P. H\u00e4usser", "C. Haz\u0131rba\u015f", "V. Golkov", "P. van der Smagt", "D. Cremers", "T. Brox"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Neural encoding of binocular disparity: energy models, position shifts and phase shifts", "author": ["D.J. Fleet", "H. Wagner", "D.J. Heeger"], "venue": "Vision Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1996}, {"title": "A three-layer model of natural image statistics", "author": ["M.U. Gutmann", "A. Hyv\u00e4rinen"], "venue": "Journal of Physiology-Paris,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Multiple View Geometry in Computer Vision", "author": ["R. Hartley", "A. Zisserman"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "A parallel computation that assigns canonical object-based frames of reference", "author": ["G.F. Hinton"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1981}, {"title": "Determining optical flow", "author": ["B.K. Horn", "B.G. Schunck"], "venue": "Artificial Intelligence,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1981}, {"title": "Conditional high-order boltzmann machine: A supervised learning model for relation learning", "author": ["Y. Huang", "W. Wang", "L. Wang"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Emergence of phase-and shift-invariant features by decomposition of natural images into independent feature subspaces", "author": ["A. Hyv\u00e4rinen", "P. Hoyer"], "venue": "Neural Computation,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2000}, {"title": "Flownet 2.0: Evolution of optical flow estimation with deep networks", "author": ["E. Ilg", "N. Mayer", "T. Saikia", "M. Keuper", "A. Dosovitskiy", "T. Brox"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "Learning image representations tied to ego-motion", "author": ["D. Jayaraman", "K. Grauman"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Hadamard product for low-rank bilinear pooling", "author": ["J.-H. Kim", "K.-W. On", "J. Kim", "J.-W. Ha", "B.-T. Zhang"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2017}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "ICLR,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Emergence of invariant-feature detectors in the adaptive-subspace self-organizing map", "author": ["T. Kohonen"], "venue": "Biological Cybernetics,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1996}, {"title": "Unsupervised learning of depth and motion", "author": ["K. Konda", "R. Memisevic"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Learning visual odometry with a convolutional network", "author": ["K.R. Konda", "R. Memisevic"], "venue": "VISAPP,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky", "G. Hinton"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1998}, {"title": "Algorithms for non-negative matrix factorization", "author": ["D.D. Lee", "H.S. Seung"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2001}, {"title": "Efficient deep learning for stereo matching", "author": ["W. Luo", "A.G. Schwing", "R. Urtasun"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Learning to relate images", "author": ["R. Memisevic"], "venue": "IEEE TPAMI,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "Learning to represent spatial transformations with factored higher-order boltzmann machines", "author": ["R. Memisevic", "G.E. Hinton"], "venue": "Neural Computation,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2010}, {"title": "A neurobiological model of visual attention and invariant pattern recognition based on dynamic routing of information", "author": ["B.A. Olshausen", "C.H. Anderson", "D.C. Van Essen"], "venue": "Journal of Neuroscience,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1993}, {"title": "The curious robot: Learning visual representations via physical interactions", "author": ["L. Pinto", "D. Gandhi", "Y. Han", "Y.-L. Park", "A. Gupta"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2016}, {"title": "Sum-product networks: A new deep architecture", "author": ["H. Poon", "P. Domingos"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2011}, {"title": "Optical flow estimation using a spatial pyramid network", "author": ["A. Ranjan", "M.J. Black"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2016}, {"title": "Convolutional neural network architecture for geometric matching", "author": ["I. Rocco", "R. Arandjelovi\u0107", "J. Sivic"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2017}, {"title": "Mini-batch stochastic approaches for accelerated multiplicative updates in nonnegative matrix factorisation with beta-divergence", "author": ["R. Serizel", "S. Essid", "G. Richard"], "venue": "MLSP,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2016}, {"title": "Improved stereo matching with constant highway networks and reflective confidence learning", "author": ["A. Shaked", "L. Wolf"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2016}, {"title": "Modeling the joint density of two images under a variety of transformations", "author": ["J. Susskind", "G. Hinton", "R. Memisevic", "M. Pollefeys"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2011}, {"title": "Separating style and content with bilinear models", "author": ["J.B. Tenenbaum andW.T. Freeman"], "venue": "Neural Computation,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2000}, {"title": "Learning to extract motion from videos in convolutional neural networks", "author": ["D. Teney", "M. Hebert"], "venue": null, "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2016}, {"title": "Fully-trainable deep matching", "author": ["J. Thewlis", "S. Zheng", "P.H. Torr", "A. Vedaldi"], "venue": null, "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2016}, {"title": "Demon: Depth and motion network for learning monocular stereo", "author": ["B. Ummenhofer", "H. Zhou", "J. Uhrig", "N. Mayer", "E. Ilg", "A. Dosovitskiy", "T. Brox"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2016}, {"title": "Accurate optical flow via direct cost volume processing", "author": ["J. Xu", "R. Ranftl", "V. Koltun"], "venue": null, "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2017}, {"title": "Back to basics: Unsupervised learning of optical flow via brightness constancy and motion smoothness", "author": ["J.J. Yu", "A.W. Harley", "K.G. Derpanis"], "venue": null, "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2016}, {"title": "Learning to compare image patches via convolutional neural networks", "author": ["S. Zagoruyko", "N. Komodakis"], "venue": null, "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2015}, {"title": "Stereo matching by training a convolutional neural network to compare image patches", "author": ["J. Zbontar", "Y. LeCun"], "venue": "JMLR, 2016", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2016}], "referenceMentions": [{"referenceID": 25, "context": "Neural networks, especially convolutional neural network (CNN) [26], have been successfully applied in many computer vision tasks such as object recognition [7, 25].", "startOffset": 63, "endOffset": 67}, {"referenceID": 6, "context": "Neural networks, especially convolutional neural network (CNN) [26], have been successfully applied in many computer vision tasks such as object recognition [7, 25].", "startOffset": 157, "endOffset": 164}, {"referenceID": 24, "context": "Neural networks, especially convolutional neural network (CNN) [26], have been successfully applied in many computer vision tasks such as object recognition [7, 25].", "startOffset": 157, "endOffset": 164}, {"referenceID": 13, "context": "A classic example is the Horn-Schunck algorithm for computing optical flow [14].", "startOffset": 75, "endOffset": 79}, {"referenceID": 28, "context": "An alternative approach to solve the relation inference problem is learning-based [29].", "startOffset": 82, "endOffset": 86}, {"referenceID": 4, "context": "An example is the Sintel dataset for learning optical flow [5].", "startOffset": 59, "endOffset": 62}, {"referenceID": 7, "context": "Recently, the learning-based approach has been adopted to compute optical flow [8, 40, 3, 41, 34, 17], stereo disparity [28], camera motion [42] and visual odometry [23].", "startOffset": 79, "endOffset": 101}, {"referenceID": 39, "context": "Recently, the learning-based approach has been adopted to compute optical flow [8, 40, 3, 41, 34, 17], stereo disparity [28], camera motion [42] and visual odometry [23].", "startOffset": 79, "endOffset": 101}, {"referenceID": 2, "context": "Recently, the learning-based approach has been adopted to compute optical flow [8, 40, 3, 41, 34, 17], stereo disparity [28], camera motion [42] and visual odometry [23].", "startOffset": 79, "endOffset": 101}, {"referenceID": 40, "context": "Recently, the learning-based approach has been adopted to compute optical flow [8, 40, 3, 41, 34, 17], stereo disparity [28], camera motion [42] and visual odometry [23].", "startOffset": 79, "endOffset": 101}, {"referenceID": 33, "context": "Recently, the learning-based approach has been adopted to compute optical flow [8, 40, 3, 41, 34, 17], stereo disparity [28], camera motion [42] and visual odometry [23].", "startOffset": 79, "endOffset": 101}, {"referenceID": 16, "context": "Recently, the learning-based approach has been adopted to compute optical flow [8, 40, 3, 41, 34, 17], stereo disparity [28], camera motion [42] and visual odometry [23].", "startOffset": 79, "endOffset": 101}, {"referenceID": 27, "context": "Recently, the learning-based approach has been adopted to compute optical flow [8, 40, 3, 41, 34, 17], stereo disparity [28], camera motion [42] and visual odometry [23].", "startOffset": 120, "endOffset": 124}, {"referenceID": 41, "context": "Recently, the learning-based approach has been adopted to compute optical flow [8, 40, 3, 41, 34, 17], stereo disparity [28], camera motion [42] and visual odometry [23].", "startOffset": 140, "endOffset": 144}, {"referenceID": 22, "context": "Recently, the learning-based approach has been adopted to compute optical flow [8, 40, 3, 41, 34, 17], stereo disparity [28], camera motion [42] and visual odometry [23].", "startOffset": 165, "endOffset": 169}, {"referenceID": 1, "context": "Note that relation learning can also serve as supervision for learning appearance representation, as demonstrated in learning ego-motion [2, 18] and robot actions [32].", "startOffset": 137, "endOffset": 144}, {"referenceID": 17, "context": "Note that relation learning can also serve as supervision for learning appearance representation, as demonstrated in learning ego-motion [2, 18] and robot actions [32].", "startOffset": 137, "endOffset": 144}, {"referenceID": 31, "context": "Note that relation learning can also serve as supervision for learning appearance representation, as demonstrated in learning ego-motion [2, 18] and robot actions [32].", "startOffset": 163, "endOffset": 167}, {"referenceID": 44, "context": "Additionally, there are methods combining knowledge-based and learning-based approaches [45, 46, 37, 4, 43].", "startOffset": 88, "endOffset": 107}, {"referenceID": 45, "context": "Additionally, there are methods combining knowledge-based and learning-based approaches [45, 46, 37, 4, 43].", "startOffset": 88, "endOffset": 107}, {"referenceID": 36, "context": "Additionally, there are methods combining knowledge-based and learning-based approaches [45, 46, 37, 4, 43].", "startOffset": 88, "endOffset": 107}, {"referenceID": 3, "context": "Additionally, there are methods combining knowledge-based and learning-based approaches [45, 46, 37, 4, 43].", "startOffset": 88, "endOffset": 107}, {"referenceID": 42, "context": "Additionally, there are methods combining knowledge-based and learning-based approaches [45, 46, 37, 4, 43].", "startOffset": 88, "endOffset": 107}, {"referenceID": 29, "context": "Although a relation learning model can also be trained unsupervisedly [30, 22, 44], we restrict our discussion mainly to supervised learning.", "startOffset": 70, "endOffset": 82}, {"referenceID": 21, "context": "Although a relation learning model can also be trained unsupervisedly [30, 22, 44], we restrict our discussion mainly to supervised learning.", "startOffset": 70, "endOffset": 82}, {"referenceID": 43, "context": "Although a relation learning model can also be trained unsupervisedly [30, 22, 44], we restrict our discussion mainly to supervised learning.", "startOffset": 70, "endOffset": 82}, {"referenceID": 29, "context": "Figure 1: Neural network architecture for relation learning As illustrated in Figure 1, the general neural network architecture of many relation learning models [30, 8, 2] can be described as a = f(x), h = R(a,b), b = f(y), z = g(h), (2) where x and y are the inputs (images), z are the targets (relation variables), f(\u00b7) is the feature extraction units, R(\u00b7, \u00b7) is the relation units and g(\u00b7) is the readout units.", "startOffset": 161, "endOffset": 171}, {"referenceID": 7, "context": "Figure 1: Neural network architecture for relation learning As illustrated in Figure 1, the general neural network architecture of many relation learning models [30, 8, 2] can be described as a = f(x), h = R(a,b), b = f(y), z = g(h), (2) where x and y are the inputs (images), z are the targets (relation variables), f(\u00b7) is the feature extraction units, R(\u00b7, \u00b7) is the relation units and g(\u00b7) is the readout units.", "startOffset": 161, "endOffset": 171}, {"referenceID": 1, "context": "Figure 1: Neural network architecture for relation learning As illustrated in Figure 1, the general neural network architecture of many relation learning models [30, 8, 2] can be described as a = f(x), h = R(a,b), b = f(y), z = g(h), (2) where x and y are the inputs (images), z are the targets (relation variables), f(\u00b7) is the feature extraction units, R(\u00b7, \u00b7) is the relation units and g(\u00b7) is the readout units.", "startOffset": 161, "endOffset": 171}, {"referenceID": 29, "context": "For example, in [30], both f(\u00b7) and g(\u00b7) are the identity function.", "startOffset": 16, "endOffset": 20}, {"referenceID": 7, "context": "For another example, in the simple version of FlowNet [8], f(\u00b7) is the identity function and g(\u00b7) is a CNN while in the complex version, both f(\u00b7) and g(\u00b7) are CNNs.", "startOffset": 54, "endOffset": 57}, {"referenceID": 7, "context": "Concatenation units have been used in learning optical flow [8] and ego-motion [2].", "startOffset": 60, "endOffset": 63}, {"referenceID": 1, "context": "Concatenation units have been used in learning optical flow [8] and ego-motion [2].", "startOffset": 79, "endOffset": 82}, {"referenceID": 12, "context": "Bilinear units have been previously proposed and developed [13, 31, 39].", "startOffset": 59, "endOffset": 71}, {"referenceID": 30, "context": "Bilinear units have been previously proposed and developed [13, 31, 39].", "startOffset": 59, "endOffset": 71}, {"referenceID": 38, "context": "Bilinear units have been previously proposed and developed [13, 31, 39].", "startOffset": 59, "endOffset": 71}, {"referenceID": 29, "context": "Bilinear units have been used in learning image transformations in [30, 35].", "startOffset": 67, "endOffset": 75}, {"referenceID": 34, "context": "Bilinear units have been used in learning image transformations in [30, 35].", "startOffset": 67, "endOffset": 75}, {"referenceID": 26, "context": "[27].", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "Such use has been demonstrated in non-negative matrix factorization [36].", "startOffset": 68, "endOffset": 72}, {"referenceID": 0, "context": "A classic model related to the proposed CAU is the energy model for motion detection [1] and stereo disparity [9].", "startOffset": 85, "endOffset": 88}, {"referenceID": 8, "context": "A classic model related to the proposed CAU is the energy model for motion detection [1] and stereo disparity [9].", "startOffset": 110, "endOffset": 113}, {"referenceID": 20, "context": "There are models which compute the sum of squares of learnable filter outputs such as adaptive-subspace self-organized maps (ASSOM) [21] and independent subspace analysis (ISA) [16].", "startOffset": 132, "endOffset": 136}, {"referenceID": 15, "context": "There are models which compute the sum of squares of learnable filter outputs such as adaptive-subspace self-organized maps (ASSOM) [21] and independent subspace analysis (ISA) [16].", "startOffset": 177, "endOffset": 181}, {"referenceID": 29, "context": "There is a line of research on relation learning based on Boltzmann machines [30, 38, 15].", "startOffset": 77, "endOffset": 89}, {"referenceID": 37, "context": "There is a line of research on relation learning based on Boltzmann machines [30, 38, 15].", "startOffset": 77, "endOffset": 89}, {"referenceID": 14, "context": "There is a line of research on relation learning based on Boltzmann machines [30, 38, 15].", "startOffset": 77, "endOffset": 89}, {"referenceID": 32, "context": "Non-negative weights have appeared in sum-product networks [33], multi-layer perceptrons [6] and natural image statistics models [10].", "startOffset": 59, "endOffset": 63}, {"referenceID": 5, "context": "Non-negative weights have appeared in sum-product networks [33], multi-layer perceptrons [6] and natural image statistics models [10].", "startOffset": 89, "endOffset": 92}, {"referenceID": 9, "context": "Non-negative weights have appeared in sum-product networks [33], multi-layer perceptrons [6] and natural image statistics models [10].", "startOffset": 129, "endOffset": 133}, {"referenceID": 29, "context": "Our derivation of the low-rank approximation of CAUs follows from the low-rank approximation of bilinear units [30, 19].", "startOffset": 111, "endOffset": 119}, {"referenceID": 18, "context": "Our derivation of the low-rank approximation of CAUs follows from the low-rank approximation of bilinear units [30, 19].", "startOffset": 111, "endOffset": 119}, {"referenceID": 10, "context": "They are called geometric transformations and can be unified as follows [11].", "startOffset": 72, "endOffset": 76}, {"referenceID": 23, "context": "We generate training and testing image patches from the gray-scaled CIFAR-10 dataset [24].", "startOffset": 85, "endOffset": 89}, {"referenceID": 11, "context": "PReLU denotes the parametric ReLU activation function [12].", "startOffset": 54, "endOffset": 58}, {"referenceID": 19, "context": "We use the multiplicative update algorithm (described in Section 4) for non-negative weights (U andV) and Adam [20] for unconstrained weights.", "startOffset": 111, "endOffset": 115}], "year": 2017, "abstractText": "Inferring the relations between two images is an important class of tasks in computer vision. Examples of such tasks include computing optical flow and stereo disparity. We treat the relation inference tasks as a machine learning problem and tackle it with neural networks. A key to the problem is learning a representation of relations. We propose a new neural network module, contrast association unit (CAU), which explicitly models the relations between two sets of input variables. Due to the non-negativity of the weights in CAU, we adopt a multiplicative update algorithm for learning these weights. Experiments show that neural networks with CAUs are more effective in learning five fundamental image transformations than conventional neural networks.", "creator": "LaTeX with hyperref package"}}}