{"id": "1705.06000", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-May-2017", "title": "One Shot Joint Colocalization and Cosegmentation", "abstract": "This paper presents a novel framework in which image cosegmentation and colocalization are cast into a single optimization problem that integrates information from low level appearance cues with that of high level localization cues in a very weakly supervised manner. In contrast to multi-task learning paradigm that learns similar tasks using a shared representation, the proposed framework leverages two representations at different levels and simultaneously discriminates between foreground and background at the bounding box and superpixel level using discriminative clustering. We show empirically that constraining the two problems at different scales enables the transfer of semantic localization cues to improve cosegmentation output whereas local appearance based segmentation cues help colocalization. The unified framework outperforms strong baseline approaches, of learning the two problems separately, by a large margin on four benchmark datasets. Furthermore, it obtains competitive results compared to the state of the art for cosegmentation on two benchmark datasets and second best result for colocalization on Pascal VOC 2007.", "histories": [["v1", "Wed, 17 May 2017 04:18:19 GMT  (1271kb,D)", "http://arxiv.org/abs/1705.06000v1", "8 pages, Under Review"]], "COMMENTS": "8 pages, Under Review", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["abhishek sharma"], "accepted": false, "id": "1705.06000"}, "pdf": {"name": "1705.06000.pdf", "metadata": {"source": "CRF", "title": "One shot Joint Colocalization & Cosegmentation", "authors": ["Abhishek Sharma"], "emails": ["asharma@mpi-inf.mpg.de"], "sections": [{"heading": null, "text": "Index terms - discriminatory clustering, weak supervision, cosegmentation, collocalization, multi-task learning"}, {"heading": "1 INTRODUCTION", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "2 RELATED WORK", "text": "All of these approaches require the classification of objects in order to guide the process of segmentation. Ladicky et al. [4] used object detection as a higher-value potential in a CRF-based segmentation system, encouraging all pixels in the foreground of a detected object to share the same category as that of detection. [4] used object detection as an example of weak monitoring of semantic segmentation. Vicente et al. [11] introduced the idea of a bouncing field for cossegmentation in a monitored environment. Alternatively, segmentation cues were used to support detection [6], Parkhi et al. [6] used color models from predefined rectangles on cat and dog faces to do GrabCut [44] and to improve the predicted bouncing box to classify images [22] and to fictify CNN."}, {"heading": "3 JOINT COLOCALIZATION & COSEGMENTATION", "text": "Notation. We use italic Roman or Greek letters (e.g. x or \u03b3) for scalars, bold italic letters (e.g. y = (y1,..., yn) T) for vectors, and calligraphic letters (e.g. C) for matrices. We assume that we have m delimiters per image."}, {"heading": "3.1 Formulation for one Image", "text": "To get simplicity and clarity, we must first consider a single image, and a set of m-boxes per image, with a binary vector z in {0, 1} m, so that zi-boxes in [0, 1] n such boxes in [0, 1] n such boxes in [0, 1] n such boxes in [1, 1] n such boxes that yj = 1 as superpixel number j in {1,. n} is foreground and yj = 0 otherwise. We also calculate a standardized saliency map M (with values in [0, 1]) and define it as a collection of boxes. We define our optimization problem (especially linear constrains) via boxes and superpixel level. This requires an additional indexing of superpixels on boxes and so we consider the following boxes for the maintenance of boxes: We define our optimization problem (especially linear constrains) on boxes and superpixels."}, {"heading": "4 IMPLEMENTATION DETAILS", "text": "We will release the source code of our implementation at the time of publication. We will use superpixels obtained from the publicly available implementation of [16], which reduces the size of the matrix Ds, Ls, and allows us to optimize at the superpixel level. Using the publicly available implementation of [20], we will generate 20 Bounding Boxes for each image. We will use an unattended method of [13] to calculate the selectivity maps.Feature. Following [2], we will densely extract 4-pixel SIFT features and kernel them using chi-square spacing. For each Bounding Box, we will extract 4096 dimensional feature vectors using AlexNet [24].Hyperparameters Following [9], we will set \u00b5, the balancing scalar for box highlighting, to.001. To set \u03b1, we will follow [2] and set it to 01 for front objects with uneven colors and.0.001 respectively."}, {"heading": "5 EVALUATION OF JOINT FRAMEWORK", "text": "The aim of this section is twofold: firstly, we propose several baselines to help understand the individual contribution of various pointers to the optimization problem defined in Section 3.1; secondly, we confirm and demonstrate empirically that learning the two problems together significantly improves performance over individual learning."}, {"heading": "5.1 Cosegmentation Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1.1 Baseline Methods", "text": "In section 3.1 we make the following two changes to the cossegmentation framework of [2]: First, we add the Saliency Cues as a linear term sp to the framework of [2]. Second, we propose to optimize the objective function of [2] with a quadratic program (QP) solver, while it is optimized in [2] with a semi-definitive programming (SDP) solver [18]. In order to clarify the meaning of Saliency Cues and better understand the various optimization techniques, we propose the following basic methods: B1. The discriminatory clustering [1] is usually optimized with an SDP solver, since the semi-defined relaxations are strong and do not suffer from trivial solutions. To confirm this, we optimize the objective function of [2] with a quadratic program (QP) saliver and compare the results of SDP Saliver as an alix."}, {"heading": "5.1.2 Benchmark Datasets.", "text": "In fact, the fact is that we are able to assert ourselves, that we are able to establish ourselves in the world, \"he said."}, {"heading": "5.2 Colocalization Experiments", "text": "Evaluation Metrics. We perform collocalization experiments on PASCAL VOC 2007 [35]. We use two evaluation metrics to compare them with modern collocalization techniques: 1) The standard metric Intersection over union (IoU) for object recognition (intersection of the predicted Bounding Box Area and Groundtruth Bounding Box Area divided by the area of their association) 2) Correct Localization (CorLoc), an evaluation metric used in related work [9], [30] and defined as the percentage of images correctly localized according to the criterion IoU >.5."}, {"heading": "5.2.1 Baseline Methods", "text": "We analyze the individual components of our collocalization model by removing different terms from the objective function, and consider the following baselines: Sal. This baseline merely minimizes the highlighting term for boards without segmentation clues and selects the most prominent term in each image. This is important because it gives an approximate idea of which object classes are most prominent in the dataset. Sal + Disc. This baseline includes the highlighting and discrimination term for boxes without segmentation clues. TJLF14 Tang et al., TJLF14 [9] deals solely with collocalization without spatial support. It quantifies how much we gain in collocalization performance by using segmentation clues."}, {"heading": "5.2.2 Colocalization evaluation on Pascal VOC 2007", "text": "After the event, the results of the series of lectures will be presented, in which it is stated: \"We are able to achieve our goals.\" The series of lectures begins with the lectures of the speakers, who deal with the topic."}, {"heading": "6 CONCLUSION & FUTURE WORK", "text": "The proposed formulation is based on two different levels of visual representation and uses linear constraints as a means of unattended transmission of information implicit in these representations. Although we demonstrate the effectiveness of our approach with a variant of maximum margin clustering, the basic idea of knowledge transfer between tasks of varying granularity is general and can be incorporated within the framework of the restricted CNN [43]. Future work could also extend our model to include an image-video classifier, providing a single framework that classifies, localizes and segments common objects or actions in images or videos simultaneously."}, {"heading": "7 ACKNOWLEDGEMENT", "text": "This work started as a master thesis in the INRIA Willow team and was partially supported by ERC Advanced Grants VideoWorld and Allegro. Many thanks to Armand Joulin for many helpful discussions and comments on this work. The author also thanks anonymous reviewers for their comments."}, {"heading": "8 APPENDIX", "text": "Suppose the image contains 5 superpixels and the delimiter field 1, z1, z1 contains superpixels 1, 3, 4, while the delimiter field contains 2, z2, z2, superpixels 1, 2, 4, 4. Consequently, the delimiter box indexing is defined for the first suggestion z1 by x1 = (y1, y3, y4) T and for z2 by x2 = (y1, y2, y4) T. Vector x is obtained by concatenating x1 and x2. Then, vector x1 and vector y are correlated by an indicator S1, y3, S1 as follows: [x1] = y1y3 y4 y4 y4 = 1 0 0 0 0 0 0 0 0, y1 yx4, yx4 yxel."}], "references": [{"title": "DIFFRAC: a discriminative and flexible framework for clustering", "author": ["F. Bach", "Z. Harchaoui"], "venue": "Proc. Neural Info. Proc. Systems", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Discriminative clustering for image cosegmentation", "author": ["A. Joulin", "F. Bach", "J. Ponce"], "venue": "CVPR", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Multi-class cosegmentation", "author": ["A. Joulin", "F. Bach", "J. Ponce"], "venue": "CVPR", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "What where and how many? combining object detectors and crfs", "author": ["L. Ladicky", "P. Sturgess", "K. Alahari", "C. Russel", "P.H. Torr"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Object co-detection", "author": ["S.Y. Bao", "Y. Xiang", "S. Savarese"], "venue": "In ECCV ,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "The truth about cats and dogs", "author": ["O.M. Parkhi", "A. Vedaldi", "C. Jawahar", "A. Zisserman"], "venue": "ICCV", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Cosegmentation of image pairs by histogram matching - incorporating a global constraint into mrfs", "author": ["C. Rother", "V. Kolmogorov", "T. Minka", "A. Blake"], "venue": "CVPR", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Normalized cuts and image segmentation", "author": ["J. Shi", "J. Malik"], "venue": "PAMI, 22(8):888\u2013905", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2000}, {"title": "Co-localization in real-world images", "author": ["K. Tang", "A. Joulin", "L.-J. Li", "L. Fei-Fei"], "venue": "CVPR", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "A", "author": ["M. Rubinstein"], "venue": "Joulin J. Kopf C. Liu Unsupervised Joint Object Discovery and Segmentation in Internet Images In CVPR", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Unsupervised co-segmentation through region matching", "author": ["J. Rubio", "J. Serrat", "A. Lopez", "N. Paragios"], "venue": "In CVPR,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "J", "author": ["Q. Yan", "L. Xu"], "venue": "Shi and J. Jia Hierarchical Saliency Detection In CVPR", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "and L", "author": ["F. Wang", "Q. Huang"], "venue": "Guibas Image Co-Segmentation via Consistent Functional Maps In ICCV", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "TextonBoost: Joint Appearance, Shape and Context Modeling for Mulit-Class Object Recognition and Segmentation InECCV", "author": ["J. Shotton", "J. Winn", "C. Rother", "A. Criminisi"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "Quick shift and kernel methods for mode seeking InECCV", "author": ["A. Vedaldi", "S. Soatto"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Maximum margin clustering InNIPS", "author": ["L. Xu", "J. Neufeld", "B. Larson", "D. Schuurmans"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "Low rank optimization for semidefinite convex problems", "author": ["M. Journee", "F. Bach", "P.-A. Absil", "R. Sepulchre"], "venue": "In Technical Report,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Measuring the objectness of image windows", "author": ["B. Alexe", "T. Deselaers", "V. Ferrari"], "venue": "PAMI ,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Weakly supervised localization and learning with generic knowledge IJCV", "author": ["T. Deselaers", "B. Alexe", "V. Ferrari"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Simultaneous Detection and Segmentation", "author": ["B. Hariharan", "P. Arbel\u00e1ez", "R. Girshick", "J. Malik"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Learning to Segment Under Various Forms of Weak Supervision", "author": ["J. Xu", "A. Schwing", "R. Urtasun"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "G. Hinton"], "venue": "In NIPS ,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Learning Visual Features from Large Weakly Supervised Data", "author": ["A. Joulin", "L. Maaten", "A. Jabri", "N. Vasilache"], "venue": "In ECCV,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "Concurrent Object Recognition and Segmentation by Graph Partitioning", "author": ["S.X. Yu", "R. Gross", "J. Shi"], "venue": "In NIPS,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2003}, {"title": "Object Detection and Segmentation from Joint Embedding of Parts and Pixels", "author": ["M. Maire", "S.X. Yu", "P. Perona"], "venue": "In ICCV,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Object Co-Segmentation via Graph Optimized-Flexible Manifold Ranking", "author": ["R. Quan", "J. Han", "D. Zhang", "F. Nie"], "venue": "In CVPR, 2016 1,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Co-segmentation by Composition", "author": ["A. Faktor", "M. Irani"], "venue": "In ICCV,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "Unsupervised Object Discovery and Localization in the Wild: Part-based Matching with Bottom-up Region Proposals", "author": ["M. Cho", "S. Kwak", "C. Schmid", "J. Ponce"], "venue": "In CVPR,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "Image Co-localization by Mimicking a Good Detector\u2019s Confidence Score Distribution", "author": ["Y. Li", "L.Liu", "C. Shen", "A. van den Hengel"], "venue": "In ECCV,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2016}, {"title": "Return of the Devil in the Details: Delving Deep into Convolutional Nets", "author": ["K. Chatfield", "K. Simonyan", "A. Vedaldi", "A. Zisserman"], "venue": "In BMVC,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2014}, {"title": "Half-integrality based algorithms for cosegmentation of images", "author": ["L. Mukherjee", "V. Singh", "C.R. Dyer"], "venue": "In CVPR,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2009}, {"title": "Scale invariant cosegmentation for image groups", "author": ["L. Mukherjee", "V. Singh", "J. Peng"], "venue": "In CVPR,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2011}, {"title": "and A", "author": ["M. Everingham", "L. Van Gool", "C.K.I. Williams", "J. Winn"], "venue": "Zisserman The PASCAL Visual Object Classes Challenge 2007 ", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2007}, {"title": "Weakly Supervised Object Localization with Latent Category Learning", "author": ["C. Wang", "W. Ren", "K. Huang", "T. Tan"], "venue": "In ECCV,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2014}, {"title": "Scene recognition and weakly supervised object localization with deformable part-based models", "author": ["M. Pandey", "S. Lazebnik"], "venue": "In ICCV,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2011}, {"title": "Looking Beyond the Image: Unsupervised Learning for Object Saliency and Detection", "author": ["P. Siva", "C. Russell", "T. Xiang", "L. Agapito"], "venue": "In CVPR,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2013}, {"title": "Recognizing human actions from still images with latent poses", "author": ["W. Yang", "Y. Wang", "G. Mori"], "venue": "In CVPR,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2010}, {"title": "Deep Fragment Embeddings for Bidirectional Image Sentence Mapping", "author": ["A. Karpathy", "A. Joulin", "L. Fei-Fei"], "venue": "In NIPS,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2014}, {"title": "Algorithms and Applications for Multitask Learning", "author": ["R. Caruana"], "venue": "In ICML,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1996}, {"title": "Scalable Multitask Representation Learning for Scene Classification", "author": ["M. Lapin", "B. Schiele", "M. Hein"], "venue": "In CVPR,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2014}, {"title": "Constrained Convolutional Neural Networks for Weakly Supervised Segmentation", "author": ["D. Pathak", "P. Kr\u00e4henb\u00fchl", "T. Darrell"], "venue": "In ICCV,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2015}, {"title": "GrabCut: Interactive Foreground Extraction using Iterated Graph Cuts", "author": ["C. Rother", "V. Kolmogorov", "T. Minka", "A. Blake"], "venue": "In SIGGRAPH,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2004}, {"title": "Efficient Image and Video Colocalization with Frank-Wolfe Algorithm", "author": ["A. Joulin", "K. Tang", "L. Fei-Fei"], "venue": "In ECCV,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2014}, {"title": "Fully Convolutional Networks for Semantic Segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "In CVPR,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2015}], "referenceMentions": [{"referenceID": 37, "context": "Localizing and segmenting objects in an image is a fundamental problem in computer vision since it facilitates many high level vision tasks such as object recognition, action recognition [39], natural language description of images [40] to name a few.", "startOffset": 187, "endOffset": 191}, {"referenceID": 38, "context": "Localizing and segmenting objects in an image is a fundamental problem in computer vision since it facilitates many high level vision tasks such as object recognition, action recognition [39], natural language description of images [40] to name a few.", "startOffset": 232, "endOffset": 236}, {"referenceID": 38, "context": "Thus, any advancements in image segmentation and localization algorithm are automatically transferred to the performance of high level tasks [40].", "startOffset": 141, "endOffset": 145}, {"referenceID": 44, "context": "With the recent success of deep networks, supervised top down segmentation methods obtain impressive performance [46] by learning on pixel level labelled datasets.", "startOffset": 113, "endOffset": 117}, {"referenceID": 17, "context": "The same is true for object detection [19].", "startOffset": 38, "endOffset": 42}, {"referenceID": 23, "context": "However, the amount of annotations required to achieve pixel or bounding box labelled datasets is tremendous [25].", "startOffset": 109, "endOffset": 113}, {"referenceID": 9, "context": "Taking into account the cost of obtaining such annotations, recent work has explored the problem of weakly-supervised object discovery [10], [30], [36], [37].", "startOffset": 135, "endOffset": 139}, {"referenceID": 28, "context": "Taking into account the cost of obtaining such annotations, recent work has explored the problem of weakly-supervised object discovery [10], [30], [36], [37].", "startOffset": 141, "endOffset": 145}, {"referenceID": 34, "context": "Taking into account the cost of obtaining such annotations, recent work has explored the problem of weakly-supervised object discovery [10], [30], [36], [37].", "startOffset": 147, "endOffset": 151}, {"referenceID": 35, "context": "Taking into account the cost of obtaining such annotations, recent work has explored the problem of weakly-supervised object discovery [10], [30], [36], [37].", "startOffset": 153, "endOffset": 157}, {"referenceID": 36, "context": "The degree of supervision used in these problems varies from weak ( positive and negative image-level labels for a target class [38]), very weak ( image level labels e.", "startOffset": 128, "endOffset": 132}, {"referenceID": 8, "context": "colocalization [9], [21] and cosegmentation [2], [29], and null [30].", "startOffset": 15, "endOffset": 18}, {"referenceID": 19, "context": "colocalization [9], [21] and cosegmentation [2], [29], and null [30].", "startOffset": 20, "endOffset": 24}, {"referenceID": 1, "context": "colocalization [9], [21] and cosegmentation [2], [29], and null [30].", "startOffset": 44, "endOffset": 47}, {"referenceID": 27, "context": "colocalization [9], [21] and cosegmentation [2], [29], and null [30].", "startOffset": 49, "endOffset": 53}, {"referenceID": 28, "context": "colocalization [9], [21] and cosegmentation [2], [29], and null [30].", "startOffset": 64, "endOffset": 68}, {"referenceID": 3, "context": "Prior work in the supervised setting has used off-the-shelf object detectors to guide the segmentation process [4] and also used segmentation as an initial phase for detection.", "startOffset": 111, "endOffset": 114}, {"referenceID": 26, "context": "However, existing work for cosegmentation and colocalization either completely ignores these complimentary cues or use them in a two stage decision process, either as pre-processing step [28] or for post processing [31].", "startOffset": 187, "endOffset": 191}, {"referenceID": 29, "context": "However, existing work for cosegmentation and colocalization either completely ignores these complimentary cues or use them in a two stage decision process, either as pre-processing step [28] or for post processing [31].", "startOffset": 215, "endOffset": 219}, {"referenceID": 26, "context": "[28] refines the coarse localization heat map obtained by a VGG network [32] to improve cosegmentation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[28] refines the coarse localization heat map obtained by a VGG network [32] to improve cosegmentation.", "startOffset": 72, "endOffset": 76}, {"referenceID": 24, "context": "Our work, although similar in spirit to the prior work that embeds pixels and parts in a graph [26], [27], builds on the discriminative framework of [1], [17] which utilizes a more powerful top down maximum margin machinery in an unsupervised fashion.", "startOffset": 95, "endOffset": 99}, {"referenceID": 25, "context": "Our work, although similar in spirit to the prior work that embeds pixels and parts in a graph [26], [27], builds on the discriminative framework of [1], [17] which utilizes a more powerful top down maximum margin machinery in an unsupervised fashion.", "startOffset": 101, "endOffset": 105}, {"referenceID": 0, "context": "Our work, although similar in spirit to the prior work that embeds pixels and parts in a graph [26], [27], builds on the discriminative framework of [1], [17] which utilizes a more powerful top down maximum margin machinery in an unsupervised fashion.", "startOffset": 149, "endOffset": 152}, {"referenceID": 15, "context": "Our work, although similar in spirit to the prior work that embeds pixels and parts in a graph [26], [27], builds on the discriminative framework of [1], [17] which utilizes a more powerful top down maximum margin machinery in an unsupervised fashion.", "startOffset": 154, "endOffset": 158}, {"referenceID": 39, "context": "[41], [42] where two (or more) similar tasks are jointly learned using a shared representation, we instead leverage two representations at different scales and enable the transfer of information implicit in these representations during a one shot optimization scheme.", "startOffset": 0, "endOffset": 4}, {"referenceID": 40, "context": "[41], [42] where two (or more) similar tasks are jointly learned using a shared representation, we instead leverage two representations at different scales and enable the transfer of information implicit in these representations during a one shot optimization scheme.", "startOffset": 6, "endOffset": 10}, {"referenceID": 3, "context": "[4] used object detections as higher order potentials in a CRF-based segmentation system by encouraging all pixels in the foreground of a detected object to share the same category label as that of the detection.", "startOffset": 0, "endOffset": 3}, {"referenceID": 21, "context": "[23] also used bounding box as a weak supervision for semantic segmentation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "Alternatively, segmentation cues have been used before to help detection [6], [31].", "startOffset": 73, "endOffset": 76}, {"referenceID": 29, "context": "Alternatively, segmentation cues have been used before to help detection [6], [31].", "startOffset": 78, "endOffset": 82}, {"referenceID": 5, "context": "[6] uses color models from predefined rectangles on cat and dog faces to do GrabCut [44] and improve the predicted bounding box.", "startOffset": 0, "endOffset": 3}, {"referenceID": 42, "context": "[6] uses color models from predefined rectangles on cat and dog faces to do GrabCut [44] and improve the predicted bounding box.", "startOffset": 84, "endOffset": 88}, {"referenceID": 20, "context": "[22] used CNN to simultaneously detect and segment by classifying image regions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7] first introduced the idea of cosegmentation in a relatively simple setting where the same object lies in front of different backgrounds in a pair of images.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Since then, many work [2], [12], [14], [28], [33], [34] have been proposed to improve cosegmentation performance which can be broadly classified into discriminative and similarity based approaches.", "startOffset": 22, "endOffset": 25}, {"referenceID": 10, "context": "Since then, many work [2], [12], [14], [28], [33], [34] have been proposed to improve cosegmentation performance which can be broadly classified into discriminative and similarity based approaches.", "startOffset": 27, "endOffset": 31}, {"referenceID": 12, "context": "Since then, many work [2], [12], [14], [28], [33], [34] have been proposed to improve cosegmentation performance which can be broadly classified into discriminative and similarity based approaches.", "startOffset": 33, "endOffset": 37}, {"referenceID": 26, "context": "Since then, many work [2], [12], [14], [28], [33], [34] have been proposed to improve cosegmentation performance which can be broadly classified into discriminative and similarity based approaches.", "startOffset": 39, "endOffset": 43}, {"referenceID": 31, "context": "Since then, many work [2], [12], [14], [28], [33], [34] have been proposed to improve cosegmentation performance which can be broadly classified into discriminative and similarity based approaches.", "startOffset": 45, "endOffset": 49}, {"referenceID": 32, "context": "Since then, many work [2], [12], [14], [28], [33], [34] have been proposed to improve cosegmentation performance which can be broadly classified into discriminative and similarity based approaches.", "startOffset": 51, "endOffset": 55}, {"referenceID": 6, "context": "Similarity based approaches [7], [10], [11], [12] exploit the information of having common foreground across images and seek to segment it out by learning the foreground distribution or matching it across images [10], [29].", "startOffset": 28, "endOffset": 31}, {"referenceID": 9, "context": "Similarity based approaches [7], [10], [11], [12] exploit the information of having common foreground across images and seek to segment it out by learning the foreground distribution or matching it across images [10], [29].", "startOffset": 33, "endOffset": 37}, {"referenceID": 10, "context": "Similarity based approaches [7], [10], [11], [12] exploit the information of having common foreground across images and seek to segment it out by learning the foreground distribution or matching it across images [10], [29].", "startOffset": 45, "endOffset": 49}, {"referenceID": 9, "context": "Similarity based approaches [7], [10], [11], [12] exploit the information of having common foreground across images and seek to segment it out by learning the foreground distribution or matching it across images [10], [29].", "startOffset": 212, "endOffset": 216}, {"referenceID": 27, "context": "Similarity based approaches [7], [10], [11], [12] exploit the information of having common foreground across images and seek to segment it out by learning the foreground distribution or matching it across images [10], [29].", "startOffset": 218, "endOffset": 222}, {"referenceID": 27, "context": "For example, Faktor & Irani [29] propose to discover the co-occurring regions first, and then perform cosegmentation by mapping between the co-occurring regions across the different images.", "startOffset": 28, "endOffset": 32}, {"referenceID": 1, "context": "In contrast, discriminative techniques [2], [3] mainly rely on separating a set of images into most separable clusters while taking care of local spatial consistency.", "startOffset": 39, "endOffset": 42}, {"referenceID": 2, "context": "In contrast, discriminative techniques [2], [3] mainly rely on separating a set of images into most separable clusters while taking care of local spatial consistency.", "startOffset": 44, "endOffset": 47}, {"referenceID": 1, "context": "[2] leverages discriminative clustering [1] to segment out the most discriminative parts in a set of images.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[2] leverages discriminative clustering [1] to segment out the most discriminative parts in a set of images.", "startOffset": 40, "endOffset": 43}, {"referenceID": 8, "context": "Colocalization is a similar problem [9] where the aim is to localize the common object, given a set of images.", "startOffset": 36, "endOffset": 39}, {"referenceID": 4, "context": "For example, object codetection [5] is similar, but is given additional bounding boxes and correspondence annotations.", "startOffset": 32, "endOffset": 35}, {"referenceID": 19, "context": "[21] generated candidate bounding boxes and tried to select the correct box within each image using a conditional random field.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[30], in contrast, localizes the common object by matching common object parts.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2] and later extended for colocalization by Tang et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] & Joulin et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 43, "context": "[45].", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "We first briefly explain the two main components of the discriminative framework of [2].", "startOffset": 84, "endOffset": 87}, {"referenceID": 15, "context": "[17] first proposed the idea of using supervised classifier such as SVM to perform unsupervised clustering.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "When l is the square loss, [1] shows that the problem is equivalent to", "startOffset": 27, "endOffset": 30}, {"referenceID": 0, "context": "We refer to [1] for more details.", "startOffset": 12, "endOffset": 15}, {"referenceID": 7, "context": "similarity term yLy is based on the idea of normalised cut [8] that encourages nearby superpixels with similar appearance to have the same label.", "startOffset": 59, "endOffset": 62}, {"referenceID": 0, "context": "We also compute a normalized saliency map M (with values in [0, 1]), and define : s = \u2212log(M).", "startOffset": 60, "endOffset": 66}, {"referenceID": 1, "context": "The optimization problem becomes convex since all the matrix defined in equation(5)are positive semi-definite [2] and the constraints are linear.", "startOffset": 110, "endOffset": 113}, {"referenceID": 14, "context": "We use superpixels obtained from publicly available implementation of [16].", "startOffset": 70, "endOffset": 74}, {"referenceID": 18, "context": "Using the publicly available implementation of [20], we generate 20 bounding boxes for each image.", "startOffset": 47, "endOffset": 51}, {"referenceID": 11, "context": "We use unsupervised method of [13] to compute off the shelf saliency maps in our experiments.", "startOffset": 30, "endOffset": 34}, {"referenceID": 1, "context": "Following [2], we densely extract SIFT features at every 4 pixels and kernelize them using Chi-square distance.", "startOffset": 10, "endOffset": 13}, {"referenceID": 22, "context": "For each bounding box, we extract 4096 dimensional feature vector using AlexNet [24].", "startOffset": 80, "endOffset": 84}, {"referenceID": 8, "context": "Hyperparameters Following [9], we set \u03bc, the balancing scalar for box saliency, to .", "startOffset": 26, "endOffset": 29}, {"referenceID": 1, "context": "To set \u03b1, we follow [2] and set it \u03b1 = .", "startOffset": 20, "endOffset": 23}, {"referenceID": 1, "context": "1, we make the following two changes to the cosegmentation framework of [2]: First, we add the saliency cues as a linear term sp to the framework of [2].", "startOffset": 72, "endOffset": 75}, {"referenceID": 1, "context": "1, we make the following two changes to the cosegmentation framework of [2]: First, we add the saliency cues as a linear term sp to the framework of [2].", "startOffset": 149, "endOffset": 152}, {"referenceID": 1, "context": "Second, we propose to optimize the objective function of [2] with a quadratic program(QP) solver whereas in [2], it is optimized with a semi-definite programming (SDP) solver [18].", "startOffset": 57, "endOffset": 60}, {"referenceID": 1, "context": "Second, we propose to optimize the objective function of [2] with a quadratic program(QP) solver whereas in [2], it is optimized with a semi-definite programming (SDP) solver [18].", "startOffset": 108, "endOffset": 111}, {"referenceID": 16, "context": "Second, we propose to optimize the objective function of [2] with a quadratic program(QP) solver whereas in [2], it is optimized with a semi-definite programming (SDP) solver [18].", "startOffset": 175, "endOffset": 179}, {"referenceID": 0, "context": "Discriminative clustering [1] objective is usually optimized with a SDP solver as the semi-definite relaxations are strong and do not suffer from trivial solutions.", "startOffset": 26, "endOffset": 29}, {"referenceID": 1, "context": "To validate this, we optimize the objective function of [2] with a quadratic program (QP) solver and compare the results with the SDP solver of [18].", "startOffset": 56, "endOffset": 59}, {"referenceID": 16, "context": "To validate this, we optimize the objective function of [2] with a quadratic program (QP) solver and compare the results with the SDP solver of [18].", "startOffset": 144, "endOffset": 148}, {"referenceID": 13, "context": "4 as a rough measure of total foreground pixels in MSRC [15] and Object Discovery dataset [10].", "startOffset": 56, "endOffset": 60}, {"referenceID": 9, "context": "4 as a rough measure of total foreground pixels in MSRC [15] and Object Discovery dataset [10].", "startOffset": 90, "endOffset": 94}, {"referenceID": 1, "context": "new objective function of [2] that includes the saliency cues.", "startOffset": 26, "endOffset": 29}, {"referenceID": 1, "context": "In addition to the baselines proposed above and JBP10 [2], we compare our method with four state of the art approaches RJKL13 [10],WHG13 [14], FI13 [29] and QHZN16 [28].", "startOffset": 54, "endOffset": 57}, {"referenceID": 9, "context": "In addition to the baselines proposed above and JBP10 [2], we compare our method with four state of the art approaches RJKL13 [10],WHG13 [14], FI13 [29] and QHZN16 [28].", "startOffset": 126, "endOffset": 130}, {"referenceID": 12, "context": "In addition to the baselines proposed above and JBP10 [2], we compare our method with four state of the art approaches RJKL13 [10],WHG13 [14], FI13 [29] and QHZN16 [28].", "startOffset": 137, "endOffset": 141}, {"referenceID": 27, "context": "In addition to the baselines proposed above and JBP10 [2], we compare our method with four state of the art approaches RJKL13 [10],WHG13 [14], FI13 [29] and QHZN16 [28].", "startOffset": 148, "endOffset": 152}, {"referenceID": 26, "context": "In addition to the baselines proposed above and JBP10 [2], we compare our method with four state of the art approaches RJKL13 [10],WHG13 [14], FI13 [29] and QHZN16 [28].", "startOffset": 164, "endOffset": 168}, {"referenceID": 13, "context": "We evaluate the cosegmentation performance of our framework on three benchmark datasets: MSRC [15], Object Discovery dataset [10] and PASCAL-VOC 2010.", "startOffset": 94, "endOffset": 98}, {"referenceID": 9, "context": "We evaluate the cosegmentation performance of our framework on three benchmark datasets: MSRC [15], Object Discovery dataset [10] and PASCAL-VOC 2010.", "startOffset": 125, "endOffset": 129}, {"referenceID": 9, "context": "The Object Discovery dataset [10] was collected by downloading images from Internet for airplane, car and horse.", "startOffset": 29, "endOffset": 33}, {"referenceID": 27, "context": "Faktor & Irani [29] collected a subset of PASCAL-VOC 2010 dataset to evaluate the cosegmentation performance.", "startOffset": 15, "endOffset": 19}, {"referenceID": 1, "context": "Note that the results mentioned for JBP10 [2] are obtained by running their open source code and verified with the authors while for others, we simply cite their numbers from their paper.", "startOffset": 42, "endOffset": 45}, {"referenceID": 12, "context": "WHG13 [14] shows results on MSRC in two modes: supervised and unsupervised.", "startOffset": 6, "endOffset": 10}, {"referenceID": 26, "context": "For fair comparison with the state of the art [28] on Object Discovery dataset and PASCAL-VOC 2010, we report performance obtained by applying grab cut [44] based post processing on our output.", "startOffset": 46, "endOffset": 50}, {"referenceID": 42, "context": "For fair comparison with the state of the art [28] on Object Discovery dataset and PASCAL-VOC 2010, we report performance obtained by applying grab cut [44] based post processing on our output.", "startOffset": 152, "endOffset": 156}, {"referenceID": 1, "context": "MSRC Dataset In Table 2, we observe that the B1 is consistently outperformed by the SDP solver of JBP10 [2] on both datasets by an average margin of 5 % AP.", "startOffset": 104, "endOffset": 107}, {"referenceID": 1, "context": "However, B3 consistently improves the performance of JBP10 [2] by an average of 5 % AP.", "startOffset": 59, "endOffset": 62}, {"referenceID": 1, "context": "This shows that the objective function of [2], combined with saliency", "startOffset": 42, "endOffset": 45}, {"referenceID": 1, "context": "Compared to JBP10 [2], our framework improves the average precision on MSRC dataset by almost 14 %.", "startOffset": 18, "endOffset": 21}, {"referenceID": 9, "context": "Our results compete well with RJKL13 [10], on 6 out of 10 classes on MSRC dataset.", "startOffset": 37, "endOffset": 41}, {"referenceID": 1, "context": "We improve upon the result of JBP10 [2] by 14 % and consistent gains over the baselines demonstrate the robustness of the model using localization cues.", "startOffset": 36, "endOffset": 39}, {"referenceID": 26, "context": "We compare well with QHZN16 [28] on classes Car and Horse but worse on aeroplane class.", "startOffset": 28, "endOffset": 32}, {"referenceID": 27, "context": "Experiments on Pascal VOC 2010 As argued by Faktor & Irani [29], average precision metric is not reliable to evaluate cosegmentation algorithm on this subset as 90 % of overall image content lies in background.", "startOffset": 59, "endOffset": 63}, {"referenceID": 27, "context": "We compare with two state of the art approaches that have shown results on this dataset yet: FI13 [29] and QHZN16.", "startOffset": 98, "endOffset": 102}, {"referenceID": 27, "context": "We outperform FI13 [29] in both metrics but perform sightly worse than QHZN16 [28].", "startOffset": 19, "endOffset": 23}, {"referenceID": 26, "context": "We outperform FI13 [29] in both metrics but perform sightly worse than QHZN16 [28].", "startOffset": 78, "endOffset": 82}, {"referenceID": 33, "context": "We conduct colocalization experiments on PASCAL VOC 2007 [35].", "startOffset": 57, "endOffset": 61}, {"referenceID": 8, "context": "2) Correct Localization (CorLoc) metric, an evaluation metric used in related work [9], [30], and defined as the percentage of images correctly localized according to the criterion: IoU > .", "startOffset": 83, "endOffset": 86}, {"referenceID": 28, "context": "2) Correct Localization (CorLoc) metric, an evaluation metric used in related work [9], [30], and defined as the percentage of images correctly localized according to the criterion: IoU > .", "startOffset": 88, "endOffset": 92}, {"referenceID": 8, "context": ",TJLF14 [9] tackles colocalization alone without any segmentation spatial support.", "startOffset": 8, "endOffset": 11}, {"referenceID": 8, "context": "Following the experimental setup defined in [9], [21], [30], we evaluate our method on the PASCAL07-6x2 subset to compare to previous methods for co-localization.", "startOffset": 44, "endOffset": 47}, {"referenceID": 19, "context": "Following the experimental setup defined in [9], [21], [30], we evaluate our method on the PASCAL07-6x2 subset to compare to previous methods for co-localization.", "startOffset": 49, "endOffset": 53}, {"referenceID": 28, "context": "Following the experimental setup defined in [9], [21], [30], we evaluate our method on the PASCAL07-6x2 subset to compare to previous methods for co-localization.", "startOffset": 55, "endOffset": 59}, {"referenceID": 33, "context": "This subset consists of all images from 6 classes (aeroplane, bicycle, boat, bus, horse, and motorbike) of the PASCAL VOC 2007 [35].", "startOffset": 127, "endOffset": 131}, {"referenceID": 8, "context": "Our results outperforms TJLF14 [9] on most classes.", "startOffset": 31, "endOffset": 34}, {"referenceID": 28, "context": "To further support our argument quantitatively, we compare our results based on IoU metric with [30] on Pascal VOC 2007 in Table 5.", "startOffset": 96, "endOffset": 100}, {"referenceID": 28, "context": ", CSP15 [30], outperforms all approaches by a huge margin on CorLoc metric where it obtains an absolute score of 64.", "startOffset": 8, "endOffset": 12}, {"referenceID": 41, "context": "Although we demonstrate the effectiveness of our approach with a variant of maximum margin clustering, the key idea of transferring knowledge between tasks at different granularity is general and can be incorporated in the framework of constrained CNN [43].", "startOffset": 252, "endOffset": 256}], "year": 2017, "abstractText": "This paper presents a novel framework in which image cosegmentation and colocalization are cast into a single optimization problem that integrates information from low level appearance cues with that of high level localization cues in a very weakly supervised manner. In contrast to multi-task learning paradigm that learns similar tasks using a shared representation, the proposed framework leverages two representations at different levels and simultaneously discriminates between foreground and background at the bounding box and superpixel level using discriminative clustering. We show empirically that constraining the two problems at different scales enables the transfer of semantic localization cues to improve cosegmentation output whereas local appearance based segmentation cues help colocalization. The unified framework outperforms strong baseline approaches, of learning the two problems separately, by a large margin on four benchmark datasets. Furthermore, it obtains competitive results compared to the state of the art for cosegmentation on two benchmark datasets and second best result for colocalization on Pascal VOC 2007.", "creator": "LaTeX with hyperref package"}}}