{"id": "1705.07008", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-May-2017", "title": "A Lightweight Regression Method to Infer Psycholinguistic Properties for Brazilian Portuguese", "abstract": "Psycholinguistic properties of words have been used in various approaches to Natural Language Processing tasks, such as text simplification and readability assessment. Most of these properties are subjective, involving costly and time-consuming surveys to be gathered. Recent approaches use the limited datasets of psycholinguistic properties to extend them automatically to large lexicons. However, some of the resources used by such approaches are not available to most languages. This study presents a method to infer psycholinguistic properties for Brazilian Portuguese (BP) using regressors built with a light set of features usually available for less resourced languages: word length, frequency lists, lexical databases composed of school dictionaries and word embedding models. The correlations between the properties inferred are close to those obtained by related works. The resulting resource contains 26,874 words in BP annotated with concreteness, age of acquisition, imageability and subjective frequency.", "histories": [["v1", "Fri, 19 May 2017 14:17:31 GMT  (107kb)", "http://arxiv.org/abs/1705.07008v1", "Paper accepted for TSD2017"]], "COMMENTS": "Paper accepted for TSD2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["leandro b dos santos", "magali s duran", "nathan s hartmann", "arnaldo candido jr", "gustavo h paetzold", "sandra m aluisio"], "accepted": false, "id": "1705.07008"}, "pdf": {"name": "1705.07008.pdf", "metadata": {"source": "CRF", "title": "A Lightweight Regression Method to Infer Psycholinguistic Properties for Brazilian Portuguese", "authors": ["Leandro Borges dos Santos", "Magali Sanches Duran", "Nathan Siegle Hartmann", "Arnaldo Candido", "Gustavo Henrique Paetzold", "Sandra Maria Aluisio"], "emails": ["arnaldoc@utfpr.edu.br", "g.h.paetzold@sheffield.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 170 5.07 008v 1 [cs.C L] 19 Approaches to natural language processing, such as text simplification and readability evaluation. Most of these attributes are subjective and require costly and time-consuming surveys. Newer approaches use the limited sets of psycholinguistic characteristics to automatically extend them to large encyclopaedias. However, some of the resources used by such approaches are not available to most languages. This study provides a method to derive psycholinguistic characteristics for Brazilian Portuguese (BP) using regressors constructed with a set of characteristics normally available for less resource-intensive languages: word length, frequency lists, lexical databases composed of school dictionaries and dictionary embedding models.The correlations between the derived characteristics are closely comparable to those of related works. The resulting resource contains 26,874 subjective words in actionality, Brazilian verbs, Brazilian verbs, Brazilian verbs, Brazilian verbs, and Brazilian psychalic attributes."}, {"heading": "1 Introduction", "text": "In addition to frequency, form, and meaning, words have several other lesser-known characteristics, such as pictorial quality, concreteness, familiarity, subjective frequency, and age of acquisition (AoA), which are subjective psycholinguistic characteristics because they depend on the personal experiences individuals have had with these words. According to [15], word pictorial quality is the ease and speed with which a word evokes a mental image; concreteness is the degree to which words refer to objects, people, places, or things that can be experienced by the senses; experiential familiarity is the degree to which individuals know and use words in their everyday lives; subjective frequency is the estimate of the number of times a word is encountered in its written or spoken form, and AoA is the estimate of the age at which a word was learned. Psycholinguistic characteristics have been used in various approaches, such as for the lexical simplification of texts."}, {"heading": "2 Related Works", "text": "To the best of our knowledge, there are only two studies that suggest regression methods for automatically estimating the absence of psycholinguistic characteristics in the MRC database [4,12]. To solve the limitations resulting from the use of word databases with human ratings, [4] proposes a mathematical model for predicting word concreteness by using linear regression with word attributes from WordNet [3], latent semantic analysis (LSA), and the CELEX database [6] and using these attributes to simulate human ratings in the MRC database. Word Concreteness is one of the most important indices provided by CohMetrix, as understanding is facilitated by more concrete words. The lexical characteristics used were 19 lexical types from WordNet, 17 LSA dimensions, hypernymy information from WordNet, word frequencies from the CELEX database, word constellations from word perception (i.e. the number of words), and sense perception."}, {"heading": "3 A Lightweight Regression Method to Infer Psycholinguistic Properties of Words", "text": "The fact that the methods developed by [4] and [12] are based on large, scarce lexical resources such as WordNet led us to ask, \"Could we achieve a similar performance with simpler features that are readily available for most languages?\" Therefore, we decided to create our regressors using only word length, frequency lists, lexical databases of school dictionaries and word embedding models. A key difference between the strategy of [12] and ours is that they combine all the features to train a regressor, while we take a different approach. Although the simple combination of all the features is simple, it can lead to noise differentiation, as the features used strongly contrast (e.g. word embeddings and word length). Instead, we chose a more elegant solution called Multi-View Learning [19]."}, {"heading": "3.1 Adaptation of Databases with Psychological Norms for Portuguese Words", "text": "In Table 1, we present surveys with the subjective psycholinguistic characteristics of words focused in this study (concreteness, age of acquisition, imagery and subjective frequency), both for European Portuguese (EP) and for BP.If, on the one hand, manually produced resources meet the needs for which they were collected, on the other hand, they are very limited for the purposes of processing natural language due to their limited size. However, there is room to automatically convert subjective psycholinguistic characteristics for multiple words, using the existing ones. However, in order to achieve this goal, we must first rely on a set of words with values for each intended property. However, there is room to include EP resources in our set, as well as to combine different resources that contain values for the same property. To make EP resources usable for our study in BP, we made adjustments to the word lists. Most of them were in the orthography o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o as an example, o aco, o, o: o, o, o, o, o, o, o: o, o, o, o, o, o, o: o, o, o, o, o: o, o, o, o: o, o, o, o, o, o, o: o, o, o, o, o: o, o, o, o, o, o, o: o, o, o, o, o, o: o, o, o, o, o, o: o, o, o, o, o, o, o, o, o: o, o, o, o, o, o, o, o, o: o, o, o, o, o, o, o, o, o: o, o, o, o, o, o, o, o, o, o, o: o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o, o"}, {"heading": "3.2 Features", "text": "Our regressors use 10 features from multiple sources grouped into: (i) lexical (1-8); (ii) Skip-Gram word embeddings (9) [10]; and (iii) GloVe word embeddings (10) [13]: 1. Log of Frequency in SUBTLEX-pt-BR [16], which is a database of BP word embeddings based on more than 50 million words from film and television subtitles; 2. Log of Contextual Diversity in SUBTLEX-pt-BR, which is the number of subtitles that contain the word; 3. Log of Frequency in SubIMDb-PT [11]: This corpus was purposely extracted from subtitles, comedy and children's films and series; 4. Log of Frequency in the Written Language part of Corpus Brasileiings.s, a corpus of about 1 billion words out of 5,000 (Loquency of 6,000) words in 8,000 (Loquency of 6,000) words."}, {"heading": "3.3 Using Regression in a Multi-View Learning Approach", "text": "We used a linear regressor with L2 regularization, also known as Ridge regression or Tikhonov regression [6]. We chose this regression method based on the promising results reported by [12]. We trained three regressors in different trait ranges: lexical traits, skip-gram embedding, and GloVe embedding."}, {"heading": "4 Evaluation", "text": "We experimented with multiple dimensions of word embedding, but for space reasons, here are only the best results compared to IMb frequency: Skip-Gram and GloVe embedding with 300 word vector dimensions. We used 20x5-fold cross validation to perform our experiments. As valuation metrics, we used Mean Square Error (MSE), Spearmans (\u03c1), and Pearson's (r) correlation. For the MSE metric, a repeated measurement ANOVA with Dunnet post-test was used to compare the best properties with the others at the significance level of 0.05. Table 2 shows the evaluation results of our method. For subjective frequency, the best result was given by the combination of Lexical, Skip-gram, and GloVe embedding. For AoA, the best result was given by the combination of Lexical and GloVe embedding."}, {"heading": "5 Evaluating psycholinguistic features in readability prediction", "text": "In order to explore the use of psycholinguistic characteristics to predict the readability level of BP informative texts for early school years, we have identified a classifier with a corpus of 1,413 texts classified as easy to read. These texts were characterized by 2 linguists (0.914 weighted kappa) and the corpus distribution by grade level. We compared the use of our four psycholinguistic characteristics with 537 texts for 5th grade and 332 texts for 6th grade. We are still able to have a data set that is able to research the work. We compared the use of four psycholinguistic characteristics and six traditional readings: Flesch ReadingEase adapted to BP."}], "references": [{"title": "Computational analyses of multilevel discourse comprehension", "author": ["D.S.M. Arthur C. Graesser"], "venue": "Topics in Cognitive Science 3(2), 371\u201398", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Age-of-acquisition norms for a set of 1,749 portuguese words", "author": ["M.L. Cameirao", "S.G. Vicente"], "venue": "Behavior research methods 42(2), 474\u2013480", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Wordnet: An Electronic Lexical Database", "author": ["C. Fellbaum"], "venue": "MIT Press", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1998}, {"title": "Simulating human ratings on word concreteness", "author": ["S. Feng", "Z. Cai", "S.A. Crossley", "D.S. McNamara"], "venue": "FLAIRS Conference. AAAI Press", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Minidicion\u00e1rio contempor\u00e2neo da l\u0131\u0301ngua portuguesa", "author": ["P. Geiger"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Ridge regression: Biased estimation for nonorthogonal problems", "author": ["A.E. Hoerl", "R.W. Kennard"], "venue": "Technometrics 12(1), 55\u201367", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1970}, {"title": "Normas de concretude para 909 palavras da l\u0131\u0301ngua portuguesa", "author": ["G. Janczura", "G. Castilho", "N. Rocha", "T. van Erven", "T. Huang"], "venue": "Psicologia: Teoria e Pesquisa pp. 195\u2013204", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Estimated age of acquisition norms for 834 portuguese nouns and their relation with other psycholinguistic variables", "author": ["J.F. Marques", "F.L. Fonseca", "S. Morais", "I.A. Pinto"], "venue": "Behavior Research Methods pp. 439\u2013444", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Normas de imag\u00e9tica e concreteza para substantivos comuns", "author": ["J.F. Marques"], "venue": "Laborat\u00f3rio de Psicologia 3, 65\u201375", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "Efficient estimation of word representations in vector space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "Proceedings of ICLR 2013", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Collecting and exploring everyday language for predicting psycholinguistic properties of words", "author": ["G. Paetzold", "L. Specia"], "venue": "Proceedings of COLING 2016. pp. 1669\u20131679", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Inferring psycholinguistic properties of words", "author": ["G.H. Paetzold", "L. Specia"], "venue": "Proceedings of NAACL-HLT. pp. 435\u2013440", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Glove: Global vectors for word representation", "author": ["J. Pennington", "R. Socher", "C.D. Manning"], "venue": "EMNLP 2014. pp. 1532\u20131543", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Quantifying sentence complexity based on eye-tracking measures (2016)  Automatically Inferring Psycholinguistic Properties of Brazilian Portuguese", "author": ["A.D. Singh", "P. Mehta", "S. Husain", "R. Rajkumar"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "The minho word pool: Norms for imageability, concreteness, and subjective frequency for 3,800 portuguese words", "author": ["A.P. Soares", "A.S. Costa", "M. J", "M.H.M. Comesana"], "venue": "Behavior Research Methods", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "A 61 million word corpus of brazilian portuguese film subtitles as a resource for linguistic research", "author": ["K. Tang"], "venue": "UCL Work Pap Linguist 24, 208\u2013214", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Readability assessment for text simplification from analysing documents to identifying sentential simplifications", "author": ["S. Vajjala", "D. Meurers"], "venue": "Recent Advances in Automatic Readability Assessment and Text Simplification 165(2), 194\u2014-222", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Readability-based sentence ranking for evaluating text simplification", "author": ["S. Vajjala", "D. Meurers"], "venue": "CoRR abs/1603.06009", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "A survey on multi-view learning", "author": ["C. Xu", "D. Tao", "C. Xu"], "venue": "arXiv preprint: 1304.5634", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 14, "context": "According to [15], word imageability is the ease and speed with which a word evokes a mental image; concreteness is the degree to which words refer to objects, people, places, or things that can be experienced by the senses; experiential familiarity is the degree to which individuals know and use words in their everyday life; subjective frequency is the estimation of the number of times a word is encountered by individuals in its written or spoken form, and AoA is the estimation of the age at which a word was learned.", "startOffset": 13, "endOffset": 17}, {"referenceID": 11, "context": "Psycholinguistic properties have been used in various approaches, such as for Lexical Simplification [12], for Text Simplification at the sentence level, with the aim of reducing the difficulty of informative text for language learners [18], to predict the reading times (RTs) of each", "startOffset": 101, "endOffset": 105}, {"referenceID": 17, "context": "Psycholinguistic properties have been used in various approaches, such as for Lexical Simplification [12], for Text Simplification at the sentence level, with the aim of reducing the difficulty of informative text for language learners [18], to predict the reading times (RTs) of each", "startOffset": 236, "endOffset": 240}, {"referenceID": 13, "context": "word in a sentence to assess sentence complexity [14] and also to create robust text level readability models [17], which is also one of the purposes of this paper.", "startOffset": 49, "endOffset": 53}, {"referenceID": 16, "context": "word in a sentence to assess sentence complexity [14] and also to create robust text level readability models [17], which is also one of the purposes of this paper.", "startOffset": 110, "endOffset": 114}, {"referenceID": 1, "context": "Because of its inherent costs, the measurement of subjective psycholinguistic properties is usually used in the creation of datasets of limited size [2,7,8,15].", "startOffset": 149, "endOffset": 159}, {"referenceID": 6, "context": "Because of its inherent costs, the measurement of subjective psycholinguistic properties is usually used in the creation of datasets of limited size [2,7,8,15].", "startOffset": 149, "endOffset": 159}, {"referenceID": 7, "context": "Because of its inherent costs, the measurement of subjective psycholinguistic properties is usually used in the creation of datasets of limited size [2,7,8,15].", "startOffset": 149, "endOffset": 159}, {"referenceID": 14, "context": "Because of its inherent costs, the measurement of subjective psycholinguistic properties is usually used in the creation of datasets of limited size [2,7,8,15].", "startOffset": 149, "endOffset": 159}, {"referenceID": 11, "context": "As for the automatic inference, this work is strongly based on the results of [12] which proposed an automatic bootstrapping method for regression to populate the MRC Database.", "startOffset": 78, "endOffset": 82}, {"referenceID": 8, "context": "We explore here 3 research questions: (1) is it possible to achieve high Pearson and Spearman correlations values and low MSE values with a regression method using only word embedding features to infer the psycholinguistic properties for BP? (2) which size a database with psycholinguistic properties should have to be used in regression models? Does merging databases from different sources yield better correlation and lower MSE scores? (3) can the inferred values help in creating features that result in more reliable readability prediction models of BP texts for early school years (from 3rd to 6th grades)? Moreover, we assessed interrater reliability (Cronbach\u2019s alpha) between ratings generated by our method and the imageability and concreteness produced for 237 nouns by [9].", "startOffset": 781, "endOffset": 784}, {"referenceID": 3, "context": "To the best of our knowledge there are only two studies that propose regression methods to automatically estimate missing psycholinguistic properties in the MRC Database [4,12].", "startOffset": 170, "endOffset": 176}, {"referenceID": 11, "context": "To the best of our knowledge there are only two studies that propose regression methods to automatically estimate missing psycholinguistic properties in the MRC Database [4,12].", "startOffset": 170, "endOffset": 176}, {"referenceID": 3, "context": "In order to solve limitations resulting from using word databases with human ratings, [4] proposes a computational model to predict word concreteness, by using linear regression with word attributes fromWordNet [3], Latent Semantic Analysis (LSA) and the CELEX Database and use these attributes to simulate human ratings in the MRC database.", "startOffset": 86, "endOffset": 89}, {"referenceID": 2, "context": "In order to solve limitations resulting from using word databases with human ratings, [4] proposes a computational model to predict word concreteness, by using linear regression with word attributes fromWordNet [3], Latent Semantic Analysis (LSA) and the CELEX Database and use these attributes to simulate human ratings in the MRC database.", "startOffset": 211, "endOffset": 214}, {"referenceID": 11, "context": "[12] automatically estimate missing psycholinguistic properties in theMRCDatabase through a bootstrapping algorithm for regression.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "869 for concretness, which is better than the results of [4].", "startOffset": 57, "endOffset": 60}, {"referenceID": 3, "context": "The fact that the methods developed by [4] and [12] are based on a large, scarce lexical resources as WordNet, led us to raise the question \u201cCould we have a similar performance with a simpler set of features which are easily obtainable for most languages?\u201d.", "startOffset": 39, "endOffset": 42}, {"referenceID": 11, "context": "The fact that the methods developed by [4] and [12] are based on a large, scarce lexical resources as WordNet, led us to raise the question \u201cCould we have a similar performance with a simpler set of features which are easily obtainable for most languages?\u201d.", "startOffset": 47, "endOffset": 51}, {"referenceID": 11, "context": "One critical difference between the strategy of [12] and ours is that they concatenate all features to train a regressor, while we take a different approach.", "startOffset": 48, "endOffset": 52}, {"referenceID": 18, "context": "Instead, we adopted a more elegant solution, called Multi-View Learning [19].", "startOffset": 72, "endOffset": 76}, {"referenceID": 18, "context": "Here, the fusion stage is made by averaging the values predicted by the regressors [19].", "startOffset": 83, "endOffset": 87}, {"referenceID": 14, "context": "[15] 2,357 3,789 concreteness, imageability, subjective frequency EP 1-7", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2] 685 1,748 AoA EP 1-9", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] 719 909 concreteness BP 1-7", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] 110 834 AoA EP 1-7", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] 103 249 imageability, concreteness EP 1-7", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "In BP, we only have 909 words with concreteness values [7].", "startOffset": 55, "endOffset": 58}, {"referenceID": 14, "context": "We did this for concreteness, merging the list of [15], once adapted fo BP, with the one of [7], which was created for BP.", "startOffset": 50, "endOffset": 54}, {"referenceID": 6, "context": "We did this for concreteness, merging the list of [15], once adapted fo BP, with the one of [7], which was created for BP.", "startOffset": 92, "endOffset": 95}, {"referenceID": 1, "context": "However, in what concerns AoA, the two lists available, [2] and [8], rated concreteness using respectively a Likert scale of 7 and 9 points.", "startOffset": 56, "endOffset": 59}, {"referenceID": 7, "context": "However, in what concerns AoA, the two lists available, [2] and [8], rated concreteness using respectively a Likert scale of 7 and 9 points.", "startOffset": 64, "endOffset": 67}, {"referenceID": 9, "context": "Our regressors use 10 features from several sources, grouped in: (i) lexical (1-8); (ii) Skip-Gram word embeddings (9) [10]; and (iii) GloVe word embeddings (10) [13]:", "startOffset": 119, "endOffset": 123}, {"referenceID": 12, "context": "Our regressors use 10 features from several sources, grouped in: (i) lexical (1-8); (ii) Skip-Gram word embeddings (9) [10]; and (iii) GloVe word embeddings (10) [13]:", "startOffset": 162, "endOffset": 166}, {"referenceID": 15, "context": "Log of Frequency in SUBTLEX-pt-BR [16], which is a database of BP word frequencies based on more than 50 million words from film and television subtitles;", "startOffset": 34, "endOffset": 38}, {"referenceID": 10, "context": "Log of Frequency in SubIMDb-PT [11]: this corpus was extracted from subtitles of family, comedy and children movies and series;", "startOffset": 31, "endOffset": 35}, {"referenceID": 9, "context": "Word\u2019s raw embedding values of word embeddings models created using the SkipGram algorithm [10], with word vector sizes of 300, 600 and 1,000; 10.", "startOffset": 91, "endOffset": 95}, {"referenceID": 12, "context": "Word\u2019s raw embedding values of word embeddingsmodels created using the GloVe algorithm [13], with word vector sizes of 300, 600 and 1,000;", "startOffset": 87, "endOffset": 91}, {"referenceID": 0, "context": "Besides that, the logarithm of word frequency was used here because reading times are linearly related to the logarithm of word frequency, not to raw word frequencies [1].", "startOffset": 167, "endOffset": 170}, {"referenceID": 5, "context": "We used a linear least squares regressor with L2 regularization, which is also known as Ridge Regression or Tikhonov regularization [6].", "startOffset": 132, "endOffset": 135}, {"referenceID": 11, "context": "We choose this regression method due to the promising results reported by [12].", "startOffset": 74, "endOffset": 78}, {"referenceID": 7, "context": "The first has 765 words [8], the second has", "startOffset": 24, "endOffset": 27}, {"referenceID": 1, "context": "1717 words [2], and the third is composed by a merging of the first and the second converted into a 7-scale; the merging resulted in a database with 2368 different words, which is still small compared to the other 3 properties evaluated here.", "startOffset": 11, "endOffset": 14}, {"referenceID": 7, "context": "Properties compared OURS [8] [2] [15] [8] vs [15] [2] vs [15]", "startOffset": 25, "endOffset": 28}, {"referenceID": 1, "context": "Properties compared OURS [8] [2] [15] [8] vs [15] [2] vs [15]", "startOffset": 29, "endOffset": 32}, {"referenceID": 14, "context": "Properties compared OURS [8] [2] [15] [8] vs [15] [2] vs [15]", "startOffset": 33, "endOffset": 37}, {"referenceID": 7, "context": "Properties compared OURS [8] [2] [15] [8] vs [15] [2] vs [15]", "startOffset": 38, "endOffset": 41}, {"referenceID": 14, "context": "Properties compared OURS [8] [2] [15] [8] vs [15] [2] vs [15]", "startOffset": 45, "endOffset": 49}, {"referenceID": 1, "context": "Properties compared OURS [8] [2] [15] [8] vs [15] [2] vs [15]", "startOffset": 50, "endOffset": 53}, {"referenceID": 14, "context": "Properties compared OURS [8] [2] [15] [8] vs [15] [2] vs [15]", "startOffset": 57, "endOffset": 61}, {"referenceID": 8, "context": "We calculated alpha scores between our automatically produced imageability and concreteness properties and from those present in the psycholinguistic dataset of [9].", "startOffset": 161, "endOffset": 164}, {"referenceID": 14, "context": "820, which are similar to the values achieved by [15], and suggest that our features do, in fact, accurately capture the psycholinguistic properties being targeted.", "startOffset": 49, "endOffset": 53}, {"referenceID": 4, "context": "For this, we took profit of Minidicion\u00e1rio Caldas Aulete\u2019s entries [5] and their respective first grammatical cate-", "startOffset": 67, "endOffset": 70}, {"referenceID": 16, "context": "We are still in the annotation process to have a dataset similar in size to the work by [17].", "startOffset": 88, "endOffset": 92}, {"referenceID": 13, "context": "This results ratify the claims of [14], which state that (i) words with higher concreteness are easier to imagine, comprehend, and memorize and therefore help readability of texts, and (ii) age of acquisition has been shown to be helpful in predicting reading difficulty.", "startOffset": 34, "endOffset": 38}], "year": 2017, "abstractText": "Psycholinguistic properties of words have been used in various approaches to Natural Language Processing tasks, such as text simplification and readability assessment. Most of these properties are subjective, involving costly and time-consuming surveys to be gathered. Recent approaches use the limited datasets of psycholinguistic properties to extend them automatically to large lexicons. However, some of the resources used by such approaches are not available to most languages. This study presents a method to infer psycholinguistic properties for Brazilian Portuguese (BP) using regressors built with a light set of features usually available for less resourced languages: word length, frequency lists, lexical databases composed of school dictionaries and word embedding models. The correlations between the properties inferred are close to those obtained by related works. The resulting resource contains 26,874 words in BP annotated with concreteness, age of acquisition, imageability and subjective frequency.", "creator": "LaTeX with hyperref package"}}}