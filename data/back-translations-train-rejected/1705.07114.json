{"id": "1705.07114", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-May-2017", "title": "A Comparison of Reinforcement Learning Techniques for Fuzzy Cloud Auto-Scaling", "abstract": "A goal of cloud service management is to design self-adaptable auto-scaler to react to workload fluctuations and changing the resources assigned. The key problem is how and when to add/remove resources in order to meet agreed service-level agreements. Reducing application cost and guaranteeing service-level agreements (SLAs) are two critical factors of dynamic controller design. In this paper, we compare two dynamic learning strategies based on a fuzzy logic system, which learns and modifies fuzzy scaling rules at runtime. A self-adaptive fuzzy logic controller is combined with two reinforcement learning (RL) approaches: (i) Fuzzy SARSA learning (FSL) and (ii) Fuzzy Q-learning (FQL). As an off-policy approach, Q-learning learns independent of the policy currently followed, whereas SARSA as an on-policy always incorporates the actual agent's behavior and leads to faster learning. Both approaches are implemented and compared in their advantages and disadvantages, here in the OpenStack cloud platform. We demonstrate that both auto-scaling approaches can handle various load traffic situations, sudden and periodic, and delivering resources on demand while reducing operating costs and preventing SLA violations. The experimental results demonstrate that FSL and FQL have acceptable performance in terms of adjusted number of virtual machine targeted to optimize SLA compliance and response time.", "histories": [["v1", "Fri, 19 May 2017 17:56:42 GMT  (6104kb,D)", "http://arxiv.org/abs/1705.07114v1", null]], "reviews": [], "SUBJECTS": "cs.DC cs.AI", "authors": ["hamid arabnejad", "claus pahl", "pooyan jamshidi", "giovani estrada"], "accepted": false, "id": "1705.07114"}, "pdf": {"name": "1705.07114.pdf", "metadata": {"source": "CRF", "title": "A Comparison of Reinforcement Learning Techniques for Fuzzy Cloud Auto-Scaling", "authors": ["Hamid Arabnejad", "Claus Pahl", "Pooyan Jamshidi", "Giovani Estrada"], "emails": [], "sections": [{"heading": null, "text": "In fact, most of them will be able to move to a different world in which they are able to escape than to another world in which they are able to escape."}, {"heading": "II. BACKGROUND AND RELATED WORK", "text": "The goal of auto-scaling approaches is to dynamically capture and release resources while maintaining an acceptable QoS [19]. The auto-scaling process is usually represented and implemented by a control loop MAPE-K (Monitor, Analyze, Plan and Execute phases over a Knowledge Base) [12]. An auto-scaler is designed with a specific goal, relying on scaling capabilities of cloud providers or focusing on the structure of the target application. We can classify autoscale approaches based on usage theory and techniques:"}, {"heading": "A. Threshold-based rules", "text": "Threshold-based rules are the most popular approach offered by many platforms such as Amazon EC21, Microsoft Azure2, or OpenStack3. Conditions and rules in threshold approaches can be defined using one or more performance metrics, such as CPU usage, average response time, or request rate. Dutreilh et al. [6] investigate horizontal automatic scaling using threshold and reinforcement learning techniques. [9] The authors describe a lightweight approach that applies fine-grained scaling in addition to VM-level scaling to improve resource usage while reducing costs for cloud providers. Hasan et al. [10] extend the typical limits by two thresholds and add two thresholds parameters to scale decisions. Chieu et al. [4] suggest a simple strategy for dynamic scalability of PaaS and SaaS web applications based on the number of active sessions and scaling thresholds when all numbers are exceeded."}, {"heading": "B. Control theory", "text": "Control theory focuses on influencing the behavior of dynamic systems by monitoring output and comparing it to reference values. By means of input system feedback (difference between actual and desired output level), the controller attempts to align the actual output with the reference value. In automatic scaling, the reference parameter, i.e., an object, is be1http: / / aws.amazon.com / ec2 2http: / / azure.microsoft.com 3https: / / www.openstack.orgcontrolled, the target SLA value [15]. The system is the target platform and system output are parameters for evaluating system performance (response time or CPU load). Zhu and Agrawal [26] present a framework using proportional integral (PI) control combined with a reinforcement learning component to determine dynamic resources to minimize application costs."}, {"heading": "C. Time series analysis", "text": "Some prediction models, such as Autoregressive (AR), Moving Average (MA), and Autoregressive Moving Average (ARMA), focus on directly predicting future values, while other approaches, such as pattern matching and signal processing techniques, first attempt to identify patterns and then predict future values. Huang et al. [11] proposed a predictive model (for CPU and memory usage) that relies on double exponential smoothing to improve predictive accuracy for resource allocation. Mi et al. [20] used Brown's square exponential smoothing to predict future application loads alongside a genetic algorithm to find a near-optimal reconfiguration of virtual machines. By ARMA et al, Roy et al [23] presented a predictive resource allocation algorithm to minimize resource allocation costs and ensure net compliance with the prediction of the QoS-13 automated approach to prediction of QoS-13."}, {"heading": "D. Reinforcement learning (RL)", "text": "RL [24] is a learning process of an agent to act in order to maximize his rewards. The standard RL architecture is in Figure 1. The agent is defined as an auto-scaler, the action is scaled up / down, the object is the target application and the reward is the performance improvement after the application of the action. The goal of RL is how to select an action in response to a current state to maximize the reward. There are several ways to implement the learning process. Generally, RL approaches learn estimates of the initialized Q values Q (s, a) that map all system states to their best measures a. We initialize all Q (s, a) and during learning choose a measure that is based on greedy policies for states and apply it in the target platform. Then we observe the new states and reward r and update the Q value of the last state action pair Q (s, a) and while learning choose a measure based on the target platform and apply it to them."}, {"heading": "III. OPENSTACK ORCHESTRATION", "text": "It consists of interconnected components that control hardware pools of processing, storing and networking resources in a data center. Users manage it either via a web-based dashboard, command-line tools or a RESTful API. Figure 2 provides an overarching overview of OpenStack's core services. In OpenStack, Neutron is a system for managing networks and IP addresses. 2) Nova is the computing engine for deploying and managing virtual machines. 3) Glance supports the discovery, registration and delivery of hard drives and servers."}, {"heading": "IV. ON-POLICY AND OFF-POLICY RL AUTO-SCALING", "text": "[14] proposes an elasticity controller based on a fuzzy logic system. [14] The motivating factor for the use of fuzzy control systems is the fact that they make it easier to integrate umhumane knowledge in the form of fuzzy rules into the decision-making process, but also reduce government space. We extend the fuzzy controller in the form of a SARSAbased fuzzy reinforcement learning algorithm as an onpolicy learning approach, FSL, and describe this in detail. Subsequently, we have associated this with a Q-learning-based non-political learning approach, called FQL, by describing the differences."}, {"heading": "A. Reinforcement Learning (RL)", "text": "The learning process consists of two components: a) an agent (i.e., the auto-scaler) that performs actions and observes the results and the environment (i.e., the application) that is the target of the actions. In this scheme, the auto-scaler as an agent interacts with an environment by applying actions and receiving a response, i.e., the reward, from the environment. Each action is taken depending on the current state and other environmental parameters such as the input of workload or performance that puts the agent in a different state. According to the reward from the action quality system, the auto-scaler will learn the best scaling action through a study-and-eror.B. Fuzzy Reinforcement Learning (FRL) We expand fuzzy auto-scaling with two known RL strategies, namely Q-Learning and SARzzy SA with the proposed short-term QARzzy system."}, {"heading": "VI. EXPERIMENTAL COMPARISON", "text": "The experimental evaluation aims to demonstrate the effectiveness of two proposed approaches FQL and FSL, but also to look at differences. Furthermore, the cost improvement is demonstrated by proposed approaches for cloud providers."}, {"heading": "A. Experimental setup and benchmark", "text": "In our experiment, the two proposed approaches FQL and FSL were implemented as full working systems and tested on the OpenStack platform. As required parameters, the maximum and minimum number of VMs allowed to be available simultaneously were set to 5 and 1, respectively. Here, we considered a small number of VMs to demonstrate the effectiveness of our proposed approaches under heavy user demand traffic. However, a larger number of VMs can be applied to these parameters. [19] The term workload refers to the number of simultaneous arrival requests by users in due time. Workload is defined as the sequence of users accessing the target application by the auto-scaler. Application workload patterns can be categorized into three representative patterns [19]: (a) the predictable bursting pattern indicates the type of workload that periodic peaks and valleys are subject to, which are typical of services with seasonal trends or high-performance news computing (the FF), or event pattern."}, {"heading": "B. Comparison of effectiveness", "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}, {"heading": "C. Comparison of cost-effectiveness of scaling", "text": "Figures 12 and 13 show percentages of VMs used for all workload patterns. Approaches work on the current workload and relative response time of the system at the current time, increasing the number of available VMs (scaling) and decreasing the number of idle VMs (scale-down). Both FQL and FSL perform distributed case scaling and allocate a reasonable number of VMs according to workload. For different types of workload patterns, the average maximum number of VMs used by FQL and FSL algorithms during our experiment is 18.3% and 22.6%, respectively. This means that our approaches can meet QoS requirements with a smaller amount of resources, which improves resource usage for VM hosting applications."}, {"heading": "VII. CONCLUSION", "text": "We examined the horizontal scaling of cloud applications. Many commercial solutions use simple approaches such as threshold-based approaches. However, providing good thresholds for automatic scaling is challenging. Lately, machine learning approaches have been used to supplement and even replace expert knowledge to develop self-adaptive solutions that are able to respond to unpredictable workload fluctuations. We proposed a blurred rules-based system on which we compared two well-known RL approaches, leading to Fuzzy Q-Learning (FQL) and Fuzzy SARSA Learning (FSL). Both approaches can efficiently scale up and down cloud resources to meet the given QoS requirements while lowering the cost of the cloud provider by improving resource usage. However, differences also arise in the SARSA experiment, as the reward in each step of the open-source automated workload pattern has been successfully demonstrated by demonstrating the open-scale algorithm for both automated workload patterns."}, {"heading": "VIII. ACKNOWLEDGEMENT", "text": "This work was partially supported by IC4 (Irish Centre for Cloud Computing and Commerce), which is funded by EI and IDA."}], "references": [{"title": "Efficient provisioning of bursty scientific workloads on the cloud using adaptive elasticity control", "author": ["A. Ali-Eldin", "M. Kihl", "J. Tordsson", "E. Elmroth"], "venue": "In Workshop on Scientific Cloud Computing Date,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "An adaptive hybrid elasticity controller for cloud infrastructures", "author": ["A. Ali-Eldin", "J. Tordsson", "E. Elmroth"], "venue": "In Network Operations and Management Symposium (NOMS),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "An auto-scaling cloud controller using fuzzy q-learning - implementation in openstack", "author": ["H. Arabnejad", "P. Jamshidi", "G. Estrada", "N. El Ioini", "C. Pahl"], "venue": "In European Conf on Service-Oriented and Cloud Computing ESOCC 2016,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Dynamic scaling of web applications in a virtualized cloud computing environment", "author": ["T.C. Chieu", "A. Mohindra", "A.A. Karve", "A. Segal"], "venue": "In IEEE Intl Conf on e-Business Engineering,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Using reinforcement learning for autonomic resource allocation in clouds: towards a fully automated workflow", "author": ["X. Dutreilh", "S. Kirgizov", "O. Melekhova", "J. Malenfant", "N. Rivierre", "I. Truck"], "venue": "In International Conference on Autonomic and Autonomous Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "From data center resource allocation to control theory and back", "author": ["X. Dutreilh", "A. Moreau", "J. Malenfant", "N. Rivierre", "I. Truck"], "venue": "In IEEE 3rd International Conference on Cloud Computing,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "An agilityoriented and fuzziness-embedded semantic model for collaborative cloud service search, retrieval and recommendation", "author": ["D. Fang", "X. Liu", "I. Romdhani", "P. Jamshidi", "C. Pahl"], "venue": "Future Generation Computer Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Predictive elastic resource scaling for cloud systems", "author": ["Z. Gong", "X. Gu", "J. Wilkes"], "venue": "In Network and Service Management (CNSM),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Lightweight resource scaling for cloud applications", "author": ["R. Han", "L. Guo", "M.M. Ghanem", "Y. Guo"], "venue": "In 12th International Symposium on Cluster, Cloud and Grid Computing (CCGrid),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Integrated and autonomic cloud resource scaling", "author": ["M.Z. Hasan", "E. Magana", "A. Clemm", "L. Tucker", "S.L.D. Gudreddi"], "venue": "In Network Operations and Management Symposium (NOMS),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Resource prediction based on double exponential smoothing in cloud computing", "author": ["J. Huang", "C. Li", "J. Yu"], "venue": "In Intl Conf on Consumer Electronics, Communications and Networks,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "A survey of autonomic computing: Degrees, models, and applications", "author": ["M.C. Huebscher", "J.A. McCann"], "venue": "ACM Comp Surveys,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Empirical prediction for adaptive resource provisioning in the cloud", "author": ["S. Islam", "J. Keung", "K. Lee", "A. Liu"], "venue": "Future Generation Computer Systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Autonomic resource provisioning for cloud-based software", "author": ["P. Jamshidi", "A. Ahmad", "C. Pahl"], "venue": "In Proceedings of the 9th International Symposium on Software Engineering for Adaptive and self-Managing Systems (SEAMS),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Managing uncertainty in autonomic cloud elasticity controllers", "author": ["P. Jamshidi", "C. Pahl", "N.C. Mendona"], "venue": "IEEE Cloud Computing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Fuzzy self-learning controllers for elasticity management in dynamic cloud architectures", "author": ["P. Jamshidi", "A. Sharifloo", "C. Pahl", "H. Arabnejad", "A. Metzger", "G. Estrada"], "venue": "In International ACM Sigsoft Conference on the Quality of Software Architectures (QoSA),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Selflearning cloud controllers: Fuzzy q-learning for knowledge evolution", "author": ["P. Jamshidi", "A.M. Sharifloo", "C. Pahl", "A. Metzger", "G. Estrada"], "venue": "In International Conference on Cloud and Autonomic Computing,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Selfadaptive and self-configured cpu resource provisioning for virtualized servers using kalman filters", "author": ["E. Kalyvianaki", "TheT.mistoklis Charalambous", "S. Hand"], "venue": "In Proceedings of the 6th international conference on Autonomic computing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "A review of auto-scaling techniques for elastic applications in cloud environments", "author": ["T. Lorido-Botran", "J. Miguel-Alonso", "J. Lozano"], "venue": "Journal of Grid Computing,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Online selfreconfiguration with performance guarantee for energy-efficient largescale cloud computing data centers", "author": ["H. Mi", "H. Wang", "G. Yin", "Y. Zhou", "D. Shi", "L. Yuan"], "venue": "In Services Computing (SCC),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Automated control of multiple virtualized resources", "author": ["P. Padala", "K.-Y. Hou", "K.G. Shin", "X. Zhu", "M. Uysal", "Z. Wang", "S. Singhal", "A. Merchant"], "venue": "In ACM Europ Conf on Computer systems,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}, {"title": "Containerization and the paas cloud", "author": ["C. Pahl"], "venue": "IEEE Cloud Computing,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Efficient autoscaling in the cloud using predictive models for workload forecasting", "author": ["N. Roy", "A. Dubey", "A. Gokhale"], "venue": "In Intl Conf on Cloud Computing (CLOUD),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Reinforcement learning: An introduction", "author": ["R.S. Sutton", "A.G. Barto"], "venue": "MIT press Cambridge,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1998}, {"title": "A hybrid reinforcement learning approach to autonomic resource allocation", "author": ["G. Tesauro", "N.K. Jong", "R. Das", "M.N. Bennani"], "venue": "In IEEE Intl Conference on Autonomic Computing,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2006}, {"title": "Resource provisioning with budget constraints for adaptive applications in cloud environments", "author": ["Q. Zhu", "G. Agrawal"], "venue": "In ACM Intl Symp on High Performance Distributed Computing,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}], "referenceMentions": [{"referenceID": 18, "context": "Auto-scaling system is a process that automatically scales the number of resources and maintains an acceptable Quality of Service (QoS) [19].", "startOffset": 136, "endOffset": 140}, {"referenceID": 23, "context": "Recently, automatic decision-making approaches, such as reinforcement learning (RL) [24], have become more popular.", "startOffset": 84, "endOffset": 88}, {"referenceID": 16, "context": "Thus, we base our investigation on a fuzzy controller [17].", "startOffset": 54, "endOffset": 58}, {"referenceID": 13, "context": "This paper extend previous results [14], [16] as follows.", "startOffset": 35, "endOffset": 39}, {"referenceID": 15, "context": "This paper extend previous results [14], [16] as follows.", "startOffset": 41, "endOffset": 45}, {"referenceID": 18, "context": "The aim of auto-scaling approaches is to acquire and release resources dynamically while maintaining an acceptable QoS [19].", "startOffset": 119, "endOffset": 123}, {"referenceID": 11, "context": "The auto-scaling process is usually represented and implemented by a MAPE-K (Monitor, Analyze, Plan and Execute phases over a Knowledge base) control loop [12].", "startOffset": 155, "endOffset": 159}, {"referenceID": 5, "context": "[6] investigate horizontal auto-scaling using threshold-based and reinforcement learning techniques.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "In [9], the authors describe a lightweight approach that operates finegrained scaling at resource level in addition to the VMlevel scaling in order to improve resource utilization while reducing cloud provider costs.", "startOffset": 3, "endOffset": 6}, {"referenceID": 9, "context": "[10] extend the typical two threshold bound values and add two levels of threshold parameters in making scaling decisions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[4] propose a simple strategy for dynamic scalability of PaaS and SaaS web applications based on the number of active sessions and scaling the VMs numbers if all instances have active sessions exceed particular thresholds.", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "org controlled, is the targeted SLA value [15].", "startOffset": 42, "endOffset": 46}, {"referenceID": 25, "context": "Zhu and Agrawal [26] present a framework using Proportional-Integral (PI) control, combined with a reinforcement learning component in order to minimize application cost.", "startOffset": 16, "endOffset": 20}, {"referenceID": 1, "context": "[2], [1] propose two adaptive hybrid reactive/proactive controllers in order to support service elasticity by using the queueing theory to estimate the future load.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[2], [1] propose two adaptive hybrid reactive/proactive controllers in order to support service elasticity by using the queueing theory to estimate the future load.", "startOffset": 5, "endOffset": 8}, {"referenceID": 20, "context": "[21] propose a feedback resource control system that automatically adapts to dynamic workload changes to satisfy service level objectives.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] integrate a Kalman filter into feedback controllers that continuously detects CPU utilization and dynamically adjusts resource allocation in order to meet QoS objectives.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] proposed a prediction model (for CPU and memory utilization) based on double exponential smoothing to improve the forecasting accuracy for resource provision.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] used Browns quadratic exponential smoothing to predict the future application workloads alongside of a genetic algorithm to find a near optimal reconfiguration of virtual machines.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] presented a look-ahead resource allocation algorithm to minimizing the resource provisioning costs while guaranteeing the application QoS in the context of auto-scaling elastic clouds.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] proposed adaptive approach to reduce the risk of SLA violations by initializing VMs and perform their boot process before resource demands.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[8] used the Fast Fourier Transform to identify repeating patterns.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "The Major drawback relies on this category is the uncertainty of prediction accuracy that highly on target application, input workload pattern, the selected metric, the history window and prediction interval, as well as on the specific technique being used [19].", "startOffset": 257, "endOffset": 261}, {"referenceID": 23, "context": "RL [24] is learning process of an agent to act in order to maximize its rewards.", "startOffset": 3, "endOffset": 7}, {"referenceID": 23, "context": "Two well-known RL approaches are SARSA and Q-learning [24].", "startOffset": 54, "endOffset": 58}, {"referenceID": 4, "context": "[5] use an appropriate initialization of the Q-values to obtain a good policy from the start as well as convergence speedups to quicken the learning process for short convergence times.", "startOffset": 0, "endOffset": 3}, {"referenceID": 24, "context": "[25] propose a hybrid learning system by combining queuing network model and SARSA learning approach to make resource allocation decisions based on application workload and response time.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "In [14], an elasticity controller based on a fuzzy logic system is proposed.", "startOffset": 3, "endOffset": 7}, {"referenceID": 23, "context": "Reinforcement learning [24] is learning by trial and error to map situations to actions, which aims to maximize a numerical reward signal.", "startOffset": 23, "endOffset": 27}, {"referenceID": 13, "context": "Similar to [14], the membership functions, depicted in Figure 5, are triangular and trapezoidal.", "startOffset": 11, "endOffset": 15}, {"referenceID": 23, "context": "The combination of the fuzzy logic controller with SARSA [24] learning, called FSL, is explained in the following.", "startOffset": 57, "endOffset": 61}, {"referenceID": 23, "context": "-greedy is known as a standard exploration policy [24].", "startOffset": 50, "endOffset": 54}, {"referenceID": 6, "context": "In a fuzzy inference system, more rules can be taken and an action is composed of these rules [7].", "startOffset": 94, "endOffset": 97}, {"referenceID": 2, "context": "For the VM web-server instance type, we used a minimal Linux distribution: the cirros4 image was specifically designed for use as a test image on clouds such as OpenStack [3].", "startOffset": 171, "endOffset": 174}, {"referenceID": 18, "context": "Application workload patterns can be categorized in three representative patterns [19]: (a) the Predictable Bursting pattern indicates the type of workload that is subject to periodic peaks and valleys typical for services with seasonality trends or high performance computing, (b) the Variations pattern reflects applications such as News&Media, event registration or rapid fire sales, and (c) the ON&OFF pattern reflects applications such as analytics, bank/tax agencies and test environments.", "startOffset": 82, "endOffset": 86}, {"referenceID": 21, "context": "We plan to extend our approach in a number of ways: (i) extending FQL4KE to perform in environments which are partially observable, (ii) exploiting clustering approaches to learn the membership functions of the antecedents (in this work we assume they do not change once they specified, for enabling the dynamic change we will consider incremental clustering approaches) in fuzzy rules and (iii) look at other resource types such as containers [22].", "startOffset": 444, "endOffset": 448}], "year": 2017, "abstractText": "A goal of cloud service management is to design self-adaptable auto-scaler to react to workload fluctuations and changing the resources assigned. The key problem is how and when to add/remove resources in order to meet agreed servicelevel agreements. Reducing application cost and guaranteeing service-level agreements (SLAs) are two critical factors of dynamic controller design. In this paper, we compare two dynamic learning strategies based on a fuzzy logic system, which learns and modifies fuzzy scaling rules at runtime. A self-adaptive fuzzy logic controller is combined with two reinforcement learning (RL) approaches: (i) Fuzzy SARSA learning (FSL) and (ii) Fuzzy Q-learning (FQL). As an off-policy approach, Q-learning learns independent of the policy currently followed, whereas SARSA as an on-policy always incorporates the actual agent\u2019s behavior and leads to faster learning. Both approaches are implemented and compared in their advantages and disadvantages, here in the OpenStack cloud platform. We demonstrate that both autoscaling approaches can handle various load traffic situations, sudden and periodic, and delivering resources on demand while reducing operating costs and preventing SLA violations. The experimental results demonstrate that FSL and FQL have acceptable performance in terms of adjusted number of virtual machine targeted to optimize SLA compliance and response time. Keywords-Cloud Computing; Orchestration; Controller; Fuzzy Logic;Q-Learning; SARSA; OpenStack", "creator": "LaTeX with hyperref package"}}}