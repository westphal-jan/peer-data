{"id": "1705.07202", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-May-2017", "title": "Multi-Stage Variational Auto-Encoders for Coarse-to-Fine Image Generation", "abstract": "Variational auto-encoder (VAE) is a powerful unsupervised learning framework for image generation. One drawback of VAE is that it generates blurry images due to its Gaussianity assumption and thus L2 loss. To allow the generation of high quality images by VAE, we increase the capacity of decoder network by employing residual blocks and skip connections, which also enable efficient optimization. To overcome the limitation of L2 loss, we propose to generate images in a multi-stage manner from coarse to fine. In the simplest case, the proposed multi-stage VAE divides the decoder into two components in which the second component generates refined images based on the course images generated by the first component. Since the second component is independent of the VAE model, it can employ other loss functions beyond the L2 loss and different model architectures. The proposed framework can be easily generalized to contain more than two components. Experiment results on the MNIST and CelebA datasets demonstrate that the proposed multi-stage VAE can generate sharper images as compared to those from the original VAE.", "histories": [["v1", "Fri, 19 May 2017 21:51:30 GMT  (8140kb,D)", "http://arxiv.org/abs/1705.07202v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["lei cai", "hongyang gao", "shuiwang ji"], "accepted": false, "id": "1705.07202"}, "pdf": {"name": "1705.07202.pdf", "metadata": {"source": "CRF", "title": "Multi-Stage Variational Auto-Encoders for Coarse-to-Fine Image Generation", "authors": ["Lei Cai", "Hongyang Gao"], "emails": ["lei.cai@wsu.edu", "hongyang.gao@wsu.edu", "sji@eecs.wsu.edu"], "sections": [{"heading": "1 Introduction", "text": "In recent years, the number of those who are able to increase has multiplied."}, {"heading": "2 Multi-Stage Variational Auto-Encoder", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Variational Auto-Encoder", "text": "Variational Auto-Encoder (VAE) [11] is a generative model capable of capturing the probability distribution over high-dimensional datasets. To address this problem, we can learn a distribution model p\u03b81 (x), parameterized by \u03b81 (i) Ni = 1, and optimize the model by maximizing the log probability as follows: log p\u03b81 (X) = log p\u03b81 (1),..., x (N) \u2212 \u2212 p phenomenon1 (i)), to approximate the data distribution and to maximize the log probability as follows: log p\u03b81 (X) = log p\u03b81 (1),.,., x (N) \u2212 \u2212 p phenomenon1 (i), to optimize (i). (1) However, probability distributions in high-dimensional space are very difficult to model. Thus, a low-dimensional latable z is usually introduced."}, {"heading": "2.2 Deep Residual Variational Auto-Encoder", "text": "UAE has shown promising results in image generation tasks [4, 26, 14]. However, the images generated by UAE are deeper, caused by the \"2 loss,\" which is based on the assumption that the data follows a single Gaussian distribution. If samples in datasets have a multimodal distribution, UAE cannot produce images with sharp edges and fine details. In UAE, the images are generated by f\u03b81 (\u00b7). It is possible to produce better images by using more complex models for f\u03b81 (\u00b7). One solution is to use the auto-ressive model [19] [24] for the decoder function f\u03b81 (\u00b7). In the auto-ressive model, each pixel is conditioned to previously generated pixels. The auto-ressive model increases the dependence between pixels and produces images with fine fine fine fine details.However, because it needs to generate images pixel by pixel, the pre-ressive model of the other model is much lower than the generative model."}, {"heading": "2.3 Multi-Stage Variational Auto-Encoder", "text": "The results of the experiment in Section 3 show that we need to split the decoder network into two components step by step, where the first components form a network by adding residual blocks to the decoder network. However, the quality of the generated images improves with smaller and smaller margins. This saturation effect is no surprise as the network still generates \"2 loss\" and thus produces blurred images. On the other hand, it is natural to use a step-by-step method to generate high quality images. Especially in image generation, we can create a rough image with rough shapes and basic colors and then switch the rough image to high quality. In VAE, the decoder network is trained end-to-end, so we cannot control the process of image generation. To split the decoder network into two components step by step, where the first components produce an image."}, {"heading": "2.4 Connections with Super-Resolution", "text": "The basic idea of the second model is similar to the high-resolution residual network (SRResNet) [16]. In the multi-level UAE, we use a pixel-by-pixel loss function to restore the details between low-resolution images and high-resolution images. Minimizing pixel-by-pixel loss encourages the model to generate the average of plausible solutions, resulting in poor perception quality [4, 18]. A plausible loss function applied to high-resolution tasks is the combination of Euclidean distances in the margin and opposite losses. In fact, our multi-level VAE model can work with any plausible super-resolution model by replacing the function in the model and architecture (Lf2)."}, {"heading": "3 Experiments", "text": "In this section, we evaluate the deep residual and multi-level UAE on the MNIST and CelebA datasets and compare the quality of the generated images with the original UAE. Results show that the proposed multi-level UAE produces high-resolution images compared to the images generated by the original UAE and deep residual VAE."}, {"heading": "3.1 Settings", "text": "The size of each face image is 178 x 218. Most previous UAE work with this dataset cut the images to 64 x 64. To demonstrate the performance of our multi-level UAE in producing high resolution images, we cut the image to 128 x 128. We train three models for 200,000 iterations. The latent variable size of VAE is 512 for the dataset of 2e-4. The encoder model of VAE consists of four layers. Each layer consists of a folding layer with increment 1 followed by a folding layer with increment 2. The latent variable size of VAE is 512 for the dataset. The encoder network consists of four deconvolution layers. To produce high quality images, five residual blocks are used in the decoder network."}, {"heading": "3.2 Results and Analysis", "text": "Figures 4 and 5 provide some reconstructed images of different models. We can see that the deep remaining UAE can capture more detail than the original UAE by using more complex decoder networks. However, the images generated by the deep remaining UAE are still blurred due to the effect of \"2 loss. We also observe that the effect of\" 2 loss is largely overcome by using the multi-stage loss. The blurred region is clearer by the multi-stage refining process. These results show that the proposed multi-stage UAE goes beyond the bottleneck of increasing the capacity of the decoder network, effectively overcoming the blur effect caused by the \"2 losses. Figures 6 and 7 provide some reconstructed images and mean outputs of f1 (\u00b7) by the deep remaining UAE and multi-stage VAE residual images generated by the VAE process."}, {"heading": "4 Conclusion and Future Work", "text": "In this work, we propose a multi-level UAE that can produce higher quality images than the original UAE. The original UAE always generated blurry images due to the effect of \"2 loss. In order to produce high quality images, we propose to improve the decoder capacity by increasing the network depth and using residual blocks and skipping the connection. Although the deep remaining UAE can capture more detail, it still suffers from the effect of\" 2 loss and generates blurry images. To overcome the limitation of \"2 loss, we propose to produce images from coarse to fine. To achieve this goal, we use the decoder network to produce a rough image by using a\" 2 loss function and producing blurry images in the first stage."}, {"heading": "Acknowledgments", "text": "This work was supported in part by grants from the National Science Foundation IIS-1615035 and DBI1641223, as well as Washington State University. We thank NVIDIA Corporation for their support by donating the Tesla K40 GPU used for this research."}], "references": [{"title": "Deep generative stochastic networks trainable by backprop", "author": ["Yoshua Bengio", "Eric Laufer", "Guillaume Alain", "Jason Yosinski"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Variational lossy autoencoder", "author": ["Xi Chen", "Diederik P Kingma", "Tim Salimans", "Yan Duan", "Prafulla Dhariwal", "John Schulman", "Ilya Sutskever", "Pieter Abbeel"], "venue": "arXiv preprint arXiv:1611.02731,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Density estimation using real nvp", "author": ["Laurent Dinh", "Jascha Sohl-Dickstein", "Samy Bengio"], "venue": "arXiv preprint arXiv:1605.08803,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Generating images with perceptual similarity metrics based on deep networks", "author": ["Alexey Dosovitskiy", "Thomas Brox"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Pixelvae: A latent variable model for natural images", "author": ["Ishaan Gulrajani", "Kundan Kumar", "Faruk Ahmed", "Adrien Ali Taiga", "Francesco Visin", "David Vazquez", "Aaron Courville"], "venue": "arXiv preprint arXiv:1611.05013,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Deep residual learning for image recognition", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Learning and releaming in boltzmann machines", "author": ["Geoffrey E Hinton", "Terrence J Sejnowski"], "venue": "Parallel Distrilmted Processing,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1986}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["Sergey Ioffe", "Christian Szegedy"], "venue": "arXiv preprint arXiv:1502.03167,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Accurate image super-resolution using very deep convolutional networks", "author": ["Jiwon Kim", "Jung Kwon Lee", "Kyoung Mu Lee"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Improving variational autoencoders with inverse autoregressive flow", "author": ["Diederik P Kingma", "Tim Salimans", "Rafal Jozefowicz", "Xi Chen", "Ilya Sutskever", "Max Welling"], "venue": "In Advances In Neural Information Processing Systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Autoencoding beyond pixels using a learned similarity metric", "author": ["Anders Boesen Lindbo Larsen", "S\u00f8ren Kaae S\u00f8nderby", "Hugo Larochelle", "Ole Winther"], "venue": "In Proceedings of The 33rd International Conference on Machine Learning,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann LeCun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1998}, {"title": "Photo-realistic single image super-resolution using a generative adversarial network", "author": ["Christian Ledig", "Lucas Theis", "Ferenc Husz\u00e1r", "Jose Caballero", "Andrew Cunningham", "Alejandro Acosta", "Andrew Aitken", "Alykhan Tejani", "Johannes Totz", "Zehan Wang"], "venue": "arXiv preprint arXiv:1609.04802,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Deep learning face attributes in the wild", "author": ["Ziwei Liu", "Ping Luo", "Xiaogang Wang", "Xiaoou Tang"], "venue": "In Proceedings of International Conference on Computer Vision (ICCV),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Deep multi-scale video prediction beyond mean square error", "author": ["Michael Mathieu", "Camille Couprie", "Yann LeCun"], "venue": "arXiv preprint arXiv:1511.05440,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Pixel recurrent neural networks", "author": ["Aaron van den Oord", "Nal Kalchbrenner", "Koray Kavukcuoglu"], "venue": "arXiv preprint arXiv:1601.06759,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["Danilo Jimenez Rezende", "Shakir Mohamed", "Daan Wierstra"], "venue": "In Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Karen Simonyan", "Andrew Zisserman"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Going deeper with convolutions", "author": ["Christian Szegedy", "Wei Liu", "Yangqing Jia", "Pierre Sermanet", "Scott Reed", "Dragomir Anguelov", "Dumitru Erhan", "Vincent Vanhoucke", "Andrew Rabinovich"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Wavenet: A generative model for raw audio", "author": ["A\u00e4ron van den Oord", "Sander Dieleman", "Heiga Zen", "Karen Simonyan", "Oriol Vinyals", "Alex Graves", "Nal Kalchbrenner", "Andrew Senior", "Koray Kavukcuoglu"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}, {"title": "Conditional image generation with pixelcnn decoders", "author": ["Aaron van den Oord", "Nal Kalchbrenner", "Lasse Espeholt", "Oriol Vinyals", "Alex Graves"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "Stackgan: Text to photorealistic image synthesis with stacked generative adversarial networks", "author": ["Han Zhang", "Tao Xu", "Hongsheng Li", "Shaoting Zhang", "Xiaolei Huang", "Xiaogang Wang", "Dimitris Metaxas"], "venue": "arXiv preprint arXiv:1612.03242,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "Towards deeper understanding of variational autoencoding models", "author": ["Shengjia Zhao", "Jiaming Song", "Stefano Ermon"], "venue": "arXiv preprint arXiv:1702.08658,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2017}], "referenceMentions": [{"referenceID": 4, "context": "In recent years, progress in deep learning has promoted the development of generative models[5, 23, 3, 8, 1] that are able to capture the distributions of high-dimensional dataset and generate new samples.", "startOffset": 92, "endOffset": 108}, {"referenceID": 22, "context": "In recent years, progress in deep learning has promoted the development of generative models[5, 23, 3, 8, 1] that are able to capture the distributions of high-dimensional dataset and generate new samples.", "startOffset": 92, "endOffset": 108}, {"referenceID": 2, "context": "In recent years, progress in deep learning has promoted the development of generative models[5, 23, 3, 8, 1] that are able to capture the distributions of high-dimensional dataset and generate new samples.", "startOffset": 92, "endOffset": 108}, {"referenceID": 7, "context": "In recent years, progress in deep learning has promoted the development of generative models[5, 23, 3, 8, 1] that are able to capture the distributions of high-dimensional dataset and generate new samples.", "startOffset": 92, "endOffset": 108}, {"referenceID": 0, "context": "In recent years, progress in deep learning has promoted the development of generative models[5, 23, 3, 8, 1] that are able to capture the distributions of high-dimensional dataset and generate new samples.", "startOffset": 92, "endOffset": 108}, {"referenceID": 19, "context": "Variational auto-encoder (VAE)[20] is a powerful unsupervised learning framework for deep generative modeling.", "startOffset": 30, "endOffset": 34}, {"referenceID": 5, "context": "To make the VAE generate high quality images, some approaches have been proposed to improve the decoder network [6, 12, 2].", "startOffset": 112, "endOffset": 122}, {"referenceID": 11, "context": "To make the VAE generate high quality images, some approaches have been proposed to improve the decoder network [6, 12, 2].", "startOffset": 112, "endOffset": 122}, {"referenceID": 1, "context": "To make the VAE generate high quality images, some approaches have been proposed to improve the decoder network [6, 12, 2].", "startOffset": 112, "endOffset": 122}, {"referenceID": 14, "context": "Since the decoder network is usually implemented with convolutional neural networks (CNNs) [15], we can increase the network depth to improve the capacity of decoder networks as in [13, 21, 22].", "startOffset": 91, "endOffset": 95}, {"referenceID": 12, "context": "Since the decoder network is usually implemented with convolutional neural networks (CNNs) [15], we can increase the network depth to improve the capacity of decoder networks as in [13, 21, 22].", "startOffset": 181, "endOffset": 193}, {"referenceID": 20, "context": "Since the decoder network is usually implemented with convolutional neural networks (CNNs) [15], we can increase the network depth to improve the capacity of decoder networks as in [13, 21, 22].", "startOffset": 181, "endOffset": 193}, {"referenceID": 21, "context": "Since the decoder network is usually implemented with convolutional neural networks (CNNs) [15], we can increase the network depth to improve the capacity of decoder networks as in [13, 21, 22].", "startOffset": 181, "endOffset": 193}, {"referenceID": 9, "context": "Following this interpretation, we can employ any loss functions to refine the images in the super-resolution network[10], thereby overcoming the effect of `2 loss.", "startOffset": 116, "endOffset": 120}, {"referenceID": 10, "context": "1 Variational Auto-Encoder Variational auto-encoder (VAE) [11] is a generative model that is able to capture the probability distribution over high-dimensional datasets.", "startOffset": 58, "endOffset": 62}, {"referenceID": 10, "context": "It has been shown in [11] that the latent variable models can be optimized efficiently by maximizing a variational lower bound on the likelihood function as log p\u03b81(x) \u2265 Eq\u03c6(z|x)[log p\u03b81(x|z)]\u2212DKL[q\u03c6(z|x)|p\u03b81(z)] = \u2212LV AE , (2) where LV AE is the loss function we need to minimize in VAE, and q\u03c6(z|x) is an approximate representation of the intractable p\u03b81(z|x) parameterized by q\u03c6.", "startOffset": 21, "endOffset": 25}, {"referenceID": 12, "context": "where C is a constant, and f\u03b81(\u00b7) is computed by CNNs [13].", "startOffset": 54, "endOffset": 58}, {"referenceID": 3, "context": "2 Deep Residual Variational Auto-Encoder VAE has shown promising results in image generation tasks[4, 26, 14].", "startOffset": 98, "endOffset": 109}, {"referenceID": 25, "context": "2 Deep Residual Variational Auto-Encoder VAE has shown promising results in image generation tasks[4, 26, 14].", "startOffset": 98, "endOffset": 109}, {"referenceID": 13, "context": "2 Deep Residual Variational Auto-Encoder VAE has shown promising results in image generation tasks[4, 26, 14].", "startOffset": 98, "endOffset": 109}, {"referenceID": 18, "context": "One solution is to employ the autoregressive model [19][24] for decoder function f\u03b81(\u00b7).", "startOffset": 51, "endOffset": 55}, {"referenceID": 23, "context": "One solution is to employ the autoregressive model [19][24] for decoder function f\u03b81(\u00b7).", "startOffset": 55, "endOffset": 59}, {"referenceID": 20, "context": "Since the decoder of VAE is implemented with CNNs, a direct way to generate better images is to employ deeper networks, resulting in increased capacity of the decoder model [21].", "startOffset": 173, "endOffset": 177}, {"referenceID": 8, "context": "To efficiently train deep neural networks, the batch normalization method is proposed in Ioffe and Szegedy [9] by reducing internal covariate shift.", "startOffset": 107, "endOffset": 110}, {"referenceID": 6, "context": "[7], which employs the residual blocks and skip connection to back-propagate the gradients more efficiently in the network.", "startOffset": 0, "endOffset": 3}, {"referenceID": 24, "context": "The idea of tackling complex tasks in a multi-stage manner is also employed by Stack GAN [25].", "startOffset": 89, "endOffset": 93}, {"referenceID": 15, "context": "The key idea of the second model is similar to the super-resolution residual net (SRResNet) [16].", "startOffset": 92, "endOffset": 96}, {"referenceID": 3, "context": "Minimizing the pixel-wise loss encourages the model to generate the average of plausible solutions, thus leading to poor perceptual quality [4, 18].", "startOffset": 140, "endOffset": 147}, {"referenceID": 17, "context": "Minimizing the pixel-wise loss encourages the model to generate the average of plausible solutions, thus leading to poor perceptual quality [4, 18].", "startOffset": 140, "endOffset": 147}, {"referenceID": 16, "context": "1 Settings CelebA [17] is a large scale face dataset that contains 202, 599 face images.", "startOffset": 18, "endOffset": 22}, {"referenceID": 15, "context": "Following this interpretation, we plan to use other model architectures and loss functions commonly used for super-resolution, such as the adversarial loss [16].", "startOffset": 156, "endOffset": 160}], "year": 2017, "abstractText": "Variational auto-encoder (VAE) is a powerful unsupervised learning framework for image generation. One drawback of VAE is that it generates blurry images due to its Gaussianity assumption and thus `2 loss. To allow the generation of high quality images by VAE, we increase the capacity of decoder network by employing residual blocks and skip connections, which also enable efficient optimization. To overcome the limitation of `2 loss, we propose to generate images in a multi-stage manner from coarse to fine. In the simplest case, the proposed multi-stage VAE divides the decoder into two components in which the second component generates refined images based on the course images generated by the first component. Since the second component is independent of the VAE model, it can employ other loss functions beyond the `2 loss and different model architectures. The proposed framework can be easily generalized to contain more than two components. Experiment results on the MNIST and CelebA datasets demonstrate that the proposed multi-stage VAE can generate sharper images as compared to those from the original VAE.", "creator": "LaTeX with hyperref package"}}}