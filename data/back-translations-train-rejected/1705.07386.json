{"id": "1705.07386", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-May-2017", "title": "DeepMasterPrint: Generating Fingerprints for Presentation Attacks", "abstract": "We present two related methods for creating MasterPrints, synthetic fingerprints that a fingerprint verification system identifies as many different people. Both methods start with training a Generative Adversarial Network (GAN) on a set of real fingerprint images. The generator network is then used to search for images that can be recognized as multiple individuals. The first method uses evolutionary optimization in the space of latent variables, and the second uses gradient-based search. Our method is able to design a MasterPrint that a commercial fingerprint system matches to 22% of all users in a strict security setting, and 75% of all users at a looser security setting.", "histories": [["v1", "Sun, 21 May 2017 03:43:46 GMT  (994kb,D)", "http://arxiv.org/abs/1705.07386v1", null], ["v2", "Tue, 3 Oct 2017 21:51:38 GMT  (1003kb,D)", "http://arxiv.org/abs/1705.07386v2", "7 pages; added more domain context and references"]], "reviews": [], "SUBJECTS": "cs.CV cs.CR cs.LG", "authors": ["philip bontrager", "julian togelius", "nasir memon"], "accepted": false, "id": "1705.07386"}, "pdf": {"name": "1705.07386.pdf", "metadata": {"source": "CRF", "title": "DeepMasterPrint: Generating Fingerprints for Presentation Attacks", "authors": ["Philip Bontrager", "Julian Togelius", "Nasir Memon"], "emails": ["philipjb@nyu.edu", "julian@togelius.com", "memon@nyu.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, the number of persons who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "2 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Fingerprint presentation attacks", "text": "Recently, Roy et al. [12] investigated the vulnerability of fingerprint-based biometric systems, which have small sensors for authentication and therefore scan only part of the fingerprint, and found that these systems are highly susceptible to a type of presentation attack known as a \"wolf attack.\" [14] A \"wolf\" is a biometric sample, real or synthesized, that embodies the biometrics of multiple subjects. This type of attack does not require a biometric sample of an individual, but is used against unknown people with a certain probability of a successful attack. Small fingerprint scanners are too small to read the entire fingerprint, and therefore the system must authenticate itself on the cross-section of the finger read by the sensor. As it would be impractical to place your finger in the same way that these systems typically have multiple measurements."}, {"heading": "2.2 Image generation", "text": "Recently, there has been rapid progress in image generation through neural networks. Some of the most popular methods of image generation are Fully Visible Belief Networks (FVBN), Variational Autoencoders (UAE), and Generative Adversarial Networks (GAN) [6]. FVBNs such as PixelRNN produce pixel by pixel, similar to text generation, and may have a little noise in their output. VAEs, on the other hand, tend to produce very smooth results. Current GAN methods are perceived as the best results with fewer artifacts than FVBNs and sharper images than VAEs [6]. GANs learn to generate images in a semi-monitored manner. There are two parts to GAN; a generator and a discriminator. The generator is typically a neural network that takes an image more randomly than input and outputs. GAN is a neural network typically a neural network."}, {"heading": "3 Datasets", "text": "In this work, we model two types of fingerprint images: those scanned by rolled prints and those obtained by a capacitive sensor. Rolled fingerprints are generated by applying ink to the finger and rolling the finger on paper. Capacitive sensors record burr information based on where the finger contacts the sensor. Rolled images The rolled fingerprints are taken from the publicly available NIST Special Database 9 fingerprint dataset [15]. The dataset consists of all 10 fingerprints from 5,400 unique subjects. Each fingerprint is an 8-bit grayscale image. For each subject, the right thumbprint is selected as it is an ordinary finger used in authentication systems. The images are pre-processed by cutting the whitespace and then scanning down to 256 x 256 pixels. To obtain partial fingerprint samples, a random 128 x 128 region is selected each time."}, {"heading": "4 Methods", "text": "Our approach to creating a MasterPrint has two parts: (1) learning the prior distribution of fingerprint images and (2) finding the distribution for an image that meets the criteria of a wolf attack. To learn the prior distribution, we use the WGAN method described above to train a generator network. Our generators receive 100 random numbers as input and output a random fingerprint image. We learn the precursors of two different sets of data to test how resistant the results are to different types of fingerprint sensors. To search the previous distribution for a MasterPrint, we search through the 100 latent variables of the generators. We develop two separate techniques for searching in this latent space."}, {"heading": "4.1 Latent variable evolution", "text": "If there is access to the fingerprint verification system, MasterPrint can be optimized directly for this system. This can be achieved by including the fingerprint verification system as a black box fitness function in the optimization process. To scan the latent variables of the image generator for an input that will trigger an attack by the wolf, an evolutionary algorithm is a powerful technique. An evolutionary algorithm does not require gradients and is therefore ideal for black box optimization. For an evolutionary algorithm, a potentially optimal solution is presented as a vector. In this case, the vector represents the 100 inputs to the fingerprint generator. A fixed number of these proposed solutions are tested and evaluated, and the best are retained and mutated to form the next generation [5].In this paper, we use a specific evolutionary strategy called Covariance Matrix Adaption (CMA-ES)."}, {"heading": "4.2 Multi-label activation maximization", "text": "We use a Convolutionary Neural Network (CNN) as a proxy system. In order to use a CNN as a fingerprint verification system, it must be trained to classify fingerprints by subject. The advantage of using a CNN as a verification system is that it provides a gradient that can be used for optimization. Instead of using evolution to optimize the generator's latent variables, back propagation can be used. CNN is trained to input 128 x 128 partial fingerprint images. It has a corresponding output class for each subject in the data set. For a wolf attack, there must be a single input that activates all output of CNN. During optimization, we start with random latent variable values, for example, we use it to generate an image and calculate an output of CNN."}, {"heading": "5 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 WGAN fingerprints", "text": "The results of the training of the WGAN generator can be seen in Figure 1. In the right column are the generated images, in the left column are samples from the actual datasets. The image generator appears to have captured the basic structures in both instances. Figure 1a shows partial fingerprints for rolled fingerprints from the NIST dataset. If you look at the correct stack, it becomes clear that the generator has learned the general burr structure of a fingerprint. If you look more closely, there are certain areas that look blurred. Most likely due to the fact that the data is generated from random sections of the fingerprint, the generator had difficulty learning the more global forms of a fingerprint. From the visual inspection, it appears to have learned the texture. Some of the output looks very similar to the input datas.Figure 1b shows the results for the capacitive fingerprints. The results seem to be slightly better for this dataset."}, {"heading": "5.2 Latent variable evolution", "text": "This year it is more than ever before."}, {"heading": "5.3 Multi-label activation maximization", "text": "In fact, it is such that most people will be able to move to another world, in which they are able to move to another world, in which they are able to move to another world, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to"}, {"heading": "6 Conclusion", "text": "This paper presents two related methods for creating MasterPrints: partial fingerprints that can be used in presentation attacks on fingerprint authorization systems. Both methods begin by training a Waterstone GAN on a fingerprint record, and then search for latent variable values (\"inputs\") for the GAN generator that maximize the number of people with whom the output of the generator can match. The first method, which requires access to an external fingerprint recognition system, uses evolutionary computation to find the variable values. The second method trains a neural network to multiple classify the fingerprints and uses a gradient exit to find the latent variable values. The results of our methods are state-of-the-art, and unlike previous work, our method generates complete fingerprint images. Tests using three different CNN architectures and two different external fingerprint recognition systems show that the method is robust and not dependent on the artefact-based systems."}], "references": [{"title": "Began: Boundary equilibrium generative adversarial networks", "author": ["David Berthelot", "Tom Schumm", "Luke Metz"], "venue": "arXiv preprint arXiv:1703.10717,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2017}, {"title": "Learning fingerprint reconstruction: From minutiae to image", "author": ["Kai Cao", "Anil K Jain"], "venue": "IEEE Transactions on information forensics and security,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Introduction to evolutionary computing, volume 53", "author": ["Agoston E Eiben", "James E Smith"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Nips 2016 tutorial: Generative adversarial networks", "author": ["Ian Goodfellow"], "venue": "arXiv preprint arXiv:1701.00160,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "The cma evolution strategy: a comparing review", "author": ["Nikolaus Hansen"], "venue": "Towards a new evolutionary computation,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Completely derandomized self-adaptation in evolution strategies", "author": ["Nikolaus Hansen", "Andreas Ostermeier"], "venue": "Evolutionary computation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Deep residual learning for image recognition", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "A cross-device matching fingerprint database from multi-type sensors", "author": ["Xiaofei Jia", "Xin Yang", "Yali Zang", "Ning Zhang", "Jie Tian"], "venue": "In Pattern Recognition (ICPR),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Synthesizing the preferred inputs for neurons in neural networks via deep generator networks", "author": ["Anh Nguyen", "Alexey Dosovitskiy", "Jason Yosinski", "Thomas Brox", "Jeff Clune"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Masterprint: Exploring the vulnerability of partial fingerprint-based authentication systems", "author": ["Aditi Roy", "Nasir Memon", "Arun Ross"], "venue": "IEEE Transactions on Information Forensics and Security,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2017}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Karen Simonyan", "Andrew Zisserman"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Wolf attack probability: A new security measure in biometric authentication systems", "author": ["Masashi Une", "Akira Otsuka", "Hideki Imai"], "venue": "In International Conference on Biometrics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Nist special database 9, mated fingerprint card pairs", "author": ["Craig I Watson"], "venue": "National Institute of Standard and Technology", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1993}, {"title": "Energy-based generative adversarial network", "author": ["Junbo Zhao", "Michael Mathieu", "Yann LeCun"], "venue": "arXiv preprint arXiv:1609.03126,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}], "referenceMentions": [{"referenceID": 9, "context": "[12] studied the vulnerability of fingerprint-based biometric systems that have small sensors for authentication and therefore only scan part of the fingerprint.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "They found these systems are highly susceptible to a type of presentation attack that is known as a \u201cwolf attack\u201d [14].", "startOffset": 114, "endOffset": 118}, {"referenceID": 9, "context": "[12] showed that there exists synthetic fingerprints that can match for many fingerprints in a dataset.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "There is work to synthesize fingerprints from minutiae [4], but by working at the image level we can also optimize for systems that don\u2019t use minutiae, systems such as the iPhone [1].", "startOffset": 55, "endOffset": 58}, {"referenceID": 3, "context": "Some of the most popular methods for image generation are Fully Visible Belief Networks (FVBN), Variational Autoencoders (VAE), and Generative Adversarial Networks (GAN) [6].", "startOffset": 170, "endOffset": 173}, {"referenceID": 3, "context": "Current GAN methods are perceived to produce the best results with fewer artifacts than FVBNs and sharper images than VAEs [6].", "startOffset": 123, "endOffset": 126}, {"referenceID": 0, "context": "Other examples not used here are the Boundary Equilibrium GAN [3] and Energy Based GAN [16].", "startOffset": 62, "endOffset": 65}, {"referenceID": 13, "context": "Other examples not used here are the Boundary Equilibrium GAN [3] and Energy Based GAN [16].", "startOffset": 87, "endOffset": 91}, {"referenceID": 12, "context": "Rolled images The rolled fingerprints come from the publicly available NIST Special Database 9 fingerprint dataset [15].", "startOffset": 115, "endOffset": 119}, {"referenceID": 7, "context": "Capacitive images The capacitive fingerprint images come from the FingerPass DB7 dataset [10].", "startOffset": 89, "endOffset": 93}, {"referenceID": 9, "context": "in their MasterPrint paper [12].", "startOffset": 27, "endOffset": 31}, {"referenceID": 2, "context": "The best ones are kept and mutated to form the next generation [5].", "startOffset": 63, "endOffset": 66}, {"referenceID": 5, "context": "This knowledge allows the algorithm to intelligently guide mutations when many variables are highly correlated [8].", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "In this work we use Hansen\u2019s Python implementation of CMA-ES [7].", "startOffset": 61, "endOffset": 64}, {"referenceID": 9, "context": "[12].", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[11].", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "Our CNN architectures are the Residual Network (ResNet) that has achieved superhuman results on the ImageNet classification competition [9], the smaller, yet still powerful, VGG16 architecture [13], and a simple convolutional design with 3 convolutional layers and 3 fully connected layers on top.", "startOffset": 136, "endOffset": 139}, {"referenceID": 10, "context": "Our CNN architectures are the Residual Network (ResNet) that has achieved superhuman results on the ImageNet classification competition [9], the smaller, yet still powerful, VGG16 architecture [13], and a simple convolutional design with 3 convolutional layers and 3 fully connected layers on top.", "startOffset": 193, "endOffset": 197}, {"referenceID": 9, "context": "[12].", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "We present two related methods for creating MasterPrints, synthetic fingerprints that a fingerprint verification system identifies as many different people. Both methods start with training a Generative Adversarial Network (GAN) on a set of real fingerprint images. The generator network is then used to search for images that can be recognized as multiple individuals. The first method uses evolutionary optimization in the space of latent variables, and the second uses gradient-based search. Our method is able to design a MasterPrint that a commercial fingerprint system matches to 22% of all users in a strict security setting, and 75% of all users at a looser security setting.", "creator": "LaTeX with hyperref package"}}}