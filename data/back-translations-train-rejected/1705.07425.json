{"id": "1705.07425", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-May-2017", "title": "Learning Semantic Relatedness From Human Feedback Using Metric Learning", "abstract": "Assessing the degree of semantic relatedness between words is an important task with a variety of semantic applications, such as ontology learning for the Semantic Web, semantic search or query expansion. To accomplish this in an automated fashion, many relatedness measures have been proposed. However, most of these metrics only encode information contained in the underlying corpus and thus do not directly model human intuition. To solve this, we propose to utilize a metric learning approach to improve existing semantic relatedness measures by learning from additional information, such as explicit human feedback. For this, we argue to use word embeddings instead of traditional high-dimensional vector representations in order to leverage their semantic density and to reduce computational cost. We rigorously test our approach on several domains including tagging data as well as publicly available embeddings based on Wikipedia texts and navigation. Human feedback about semantic relatedness for learning and evaluation is extracted from publicly available datasets such as MEN or WS-353. We find that our method can significantly improve semantic relatedness measures by learning from additional information, such as explicit human feedback. For tagging data, we are the first to generate and study embeddings. Our results are of special interest for ontology and recommendation engineers, but also for any other researchers and practitioners of Semantic Web techniques.", "histories": [["v1", "Sun, 21 May 2017 10:16:49 GMT  (175kb,D)", "https://arxiv.org/abs/1705.07425v1", null], ["v2", "Wed, 24 May 2017 13:07:07 GMT  (175kb,D)", "http://arxiv.org/abs/1705.07425v2", "Under review at ISWC 2017"]], "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["thomas niebler", "martin becker", "christian p\\\"olitz", "reas hotho"], "accepted": false, "id": "1705.07425"}, "pdf": {"name": "1705.07425.pdf", "metadata": {"source": "CRF", "title": "Learning Semantic Relatedness from Human Feedback Using Metric Learning", "authors": ["Thomas Niebler", "Martin Becker", "Christian P\u00f6litz", "Andreas Hotho"], "emails": ["hotho}@informatik.uni-wuerzburg.de"], "sections": [{"heading": "1 Introduction", "text": "This year it is more than ever before."}, {"heading": "2 Metric Learning to Learn Semantic Relatedness", "text": "We then argue that the concepts of distance and semantic relativization are synonymous when we limit the setting to a transformed sphere of unity. Finally, we present our method of formulating human feedback as constraints on the metric learning algorithm we use. Figure 1 shows a sketch of the steps we take in our approach to semantic relativization (x \u2212 y) by learning metric, metric learning. To learn metric, metric learning, we must learn the distance, dM (x \u2212 y) TM (x \u2212 y) by finding a (symmetric, positive definition) matrix M. To this end, most algorithms expect a set of constraints. In this work, we apply the LSML algorithm that learns from a distance."}, {"heading": "3 Datasets", "text": "In this paper, use two different types of data sets to evaluate our metric approach to learning and to integrate user feedback in relation to metrics: domain data sets that contain a set of word vectors that represent the words used to calculate semantic relations, and human intuition data sets (HIDs) that we use to learn semantic relations and test our results. In the following, we first describe two domain data sets that contain tagging data from which we derive later tag embeddings. Then, we review two domain data sets that are Wikipedia-based and equipped with pre-formed word vectors. Finally, we present all human intuition data sets that contain human-assigned similarities with word pairs."}, {"heading": "3.1 Tagging Datasets to Derive Word Embeddings", "text": "In our thesis we examine data sets from two public social tagging systems. We use data from BibSonomy, which has a rather academic audience. The second data set is a subset of the Delicious social tagging system, where the audience is focused on design and technical topics. Each data set is limited to the top 10k tags to reduce noise. In addition, we only considered the tags of users who have marked at least 5 resources and only the resources that have been used at least 10 times. We also removed all invalid tags, e.g. that contain whitespaces or illegible symbols. BibSonomy social tagging system offers users the ability to collect bookmarks (links to websites) or references to scientific publications and comment with tags [3]. We use a freely available dump from BibSonomy, which tagged all data from 2006 to the end of 2015."}, {"heading": "3.2 Pre-trained Embedding Datasets Based on Wikipedia", "text": "To demonstrate the applicability of our approach to any type of word embedding, we also use two publicly available datasets of pre-formed vectors. Both are related to Wikipedia, which has repeatedly been shown to deliver high-quality semantic content [8, 13, 20, 23, 25].WikiGloVe. The authors of the GloVe embedding algorithm [21] have built several datasets of vector embedding on different text data and made them publicly available. [5] As it has been repeatedly demonstrated that the text content of Wikipedia articles can be used to calculate semantic relationships [13, 23] we use the vectors based on Wikipedia as a reference for word embedding generated from natural language. This dataset consists of 400,000 vectors with the dimension of 100. WikiNav."}, {"heading": "3.3 Human Intuition Datasets (HIDs)", "text": "As the gold standard for semantic kinship as perceived by humans, we use several sets of human-generated kinship values for word pairs, so-called human intuition datasets (HIDs). In the following, we will briefly describe all the HIDs used. Table 1 gives an overview of the size of the data set and the overlap, as well as the Spearman correlation for the comparable pairs for all embedding datasets. WS-353. The WordSimilarity-3537 datasets consist of 353 pairs of English words and names [12]. Each pair received a kinship value between 0.0 (no relation) and 10.0 (identical meaning) from 16 raters naming the assumed semantic kinship between two words."}, {"heading": "4 Experimental Setup and Results", "text": "In this section, we will conduct various experiments to demonstrate the usefulness of metric learning for learning semantic references. First, we will describe how we evaluate the quality of a learned semantic reference value, then we will examine the process of generating word embeddings from the marker of data and perform a qualitative evaluation. Finally, we will train several metrics in a number of areas taking into account different user feedback, investigate whether it is possible to transport trained semantic knowledge through different collections of user feedback, and finally, we will evaluate the robustness of the learned semantic references. We will publish our code to enable reproducibility of our experiments.10"}, {"heading": "4.1 Evaluating the Quality of Semantic Relatedness Measures", "text": "Most often, the quality of semantic kinship measures is judged by how well they fit into human intuition [13, 18, 25]. Human intuition is collected in Human Intuition Datasets (HID), as introduced in Section 3.3. The most common method of evaluating semantic kinship on such data sets is the Spearman rank correlation coefficient, which compares the order of precedence of word pairs given by a HID with the order of precedence implied by the semantic kinship measure. While there are other evaluation approaches such as analog matching [15, 18] or concept categorization [1], they do not fit our setting, because we only want to improve the measurement of kinship."}, {"heading": "4.2 Word Embeddings from Tagging Data", "text": "In fact, the majority of people who are able to see themselves in a position to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "4.3 Integrating Different Levels of User Intentions", "text": "In this section, we will examine how the amount of human feedback used for the training influences the quality of the semantic parameters learned. To this end, we will evaluate various training set parameters extracted from the HIDs on the various embedding sets (pre-trained or extracted by GloVe, cf., Section 3).For each HID, we will first randomly sample 20% of all collectable test data sets. We have collected 5 such test data sets. For each test set, we will take training sets of different sizes (10% - 100%) on which we will build a measurement, which will be evaluated on the 20% of previously collected test data. We will repeat the sampling training data sets and learn 25 times. Then, we will take the mean and standard deviation across all experiments. As a baseline, we will report the data relationship using the pure cosmic measurements."}, {"heading": "4.4 Transporting User Intentions", "text": "Previous experiments have shown that integrating a dedicated HID into a relation measurement leads to a higher consistency of measurement with human intuition. To translate different user intentions into different settings, we trained metrics on a complete HID and evaluated them on a different HID. For example, the training was performed using all WS-353 relationships, but the measurement was evaluated on the MEN HID. Hereby, we evaluate whether the knowledge learned is transferable from one term of semantic relativity (represented by a specific HID) to another. Results are given in Table 3. For each line, the header defines the dataset on which the measurement was trained, while the column header is the dataset on which the trained measurement was subsequently evaluated. In each cell, the first value denotes the Spearman correlation of the cosmic measurement with the human relation measurement."}, {"heading": "4.5 Robustness of the Learned Semantic Relatedness Measure", "text": "Here, we inject false semantic kinship information into our learning process. The goal is to show that i) incorrect ratings do not cause kinship measurements to collapse, which ultimately makes our approach robust for different users with different kinship intuitions, and ii) that the promising results of previous experiments are actually achieved by successfully injecting user feedback. The setup is the same as in the random sample experiment (Section 4.3), except that we randomly assign the kinship values of the training pairs. In this way, we evaluate valid human intuitions, but learn from false information. In Figure 4, we see that mixed kinship values have a negative impact on the learned metric kinship measurements, as expected. On BibSonomy embeddings, only the measures that were trained on the MEN datasets will lead to progressively worse results, while the measures that were trained on the Bib100 or WS-353 datasets will not have a major impact on both metric and metric kinship measurements."}, {"heading": "5 Discussion of the Results", "text": "This year, we will be able to go in search of a solution that will enable us to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position. \""}, {"heading": "6 Related Work", "text": "Below, we will highlight the most relevant work in these areas of metric learning as well as semantic relativization of learning algorithms. As we focus on adapting metric learning to semantic limitations, we have a brief overview of different types of metric learning algorithms that can either be divided into two classes to detect the type of limitations exploited. Xing et al. [31], the first class of metric learning algorithms uses left-based limitations, i.e. we have explicit information when two elements are either similar or dissimilar. Weinberger et al., as one of the first to suggest an approach to learning a distance metrically, [31] proposed extending the Euclidean metrically with a Mahalanomatrix M to improve kNN knowledge, presents."}, {"heading": "7 Conclusion", "text": "Our approach is scalable and fast in terms of constraints, yielding significantly improved results compared to the widely used cosinal metric, while delivering competitive results based on human assessment data sets. We argued for the use of word embedding instead of high-dimensional vector representations to mark data due to an improvement in its semantic content and its clear reduction in the computational complexity involved in learning a metric. Specifically, we demonstrated that we could use semantic coherence information from HIDs to assess semantic relationships more realistically, regardless of the underlying embedding of data sets. In addition, we were able to encode and transfer knowledge from one HID to another, sometimes with a very large increase in correlation to human intuition. In forming a metric of false information to assess the robustness of our approach, we argued that these results actually serve as a basis for measuring Q1S results."}], "references": [{"title": "Don\u2019t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors.", "author": ["Marco Baroni", "Gerorgiana Dinu", "German Kruszewski"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "A neural probabilistic language model.", "author": ["Yoshua Bengio"], "venue": "JMLR", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "The Social Bookmark and Publication Management System BibSonomy.", "author": ["Dominik Benz"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Knowledge-powered deep learning for word embedding.", "author": ["Jiang Bian", "Bin Gao", "Tie-Yan Liu"], "venue": "ECML/PKDD", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Multimodal Distributional Semantics.", "author": ["Elia Bruni", "Nam-Khanh Tran", "Marco Baroni"], "venue": "JAIR", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Semantic Grounding of Tag Relatedness in Social Bookmarking Systems.", "author": ["Ciro Cattuto"], "venue": "ISWC", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning.", "author": ["Ronan Collobert", "Jason Weston"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Extracting Semantics from Random Walks on Wikipedia: Comparing learning and counting methods.", "author": ["Alexander Dallmann"], "venue": "WikiWorkshop@ICWSM", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Information-theoretic metric learning.", "author": ["Jason V. Davis"], "venue": "In: ICML", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Indexing by latent semantic analysis.", "author": ["Scott Deerwester"], "venue": "Journal of the American Society for Information Science", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1990}, {"title": "Retrofitting Word Vectors to Semantic Lexicons.", "author": ["Manaal Faruqui"], "venue": "CoRR", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Placing Search in Context: the Concept Revisited.", "author": ["Lev Finkelstein"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2001}, {"title": "Computing semantic relatedness using Wikipedia-based explicit semantic analysis.", "author": ["Evgeniy Gabrilovich", "Shaul Markovitch"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "Large-scale Learning of Word Relatedness with Constraints.", "author": ["Guy Halawi"], "venue": "In: KDD", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Linguistic Regularities in Sparse and Explicit Word Representations.", "author": ["Omer Levy", "Yoav Goldberg", "Israel Ramat-Gan"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Metric Learning from Relative Comparisons by Minimizing Squared Residual.", "author": ["E.Y. Liu"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Evaluating Similarity Measures for Emergent Semantics of Social Tagging.", "author": ["Benjamin Markines"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Distributed Representations of Words and Phrases and their Compositionality.", "author": ["Tomas Mikolov"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Counter-fitting Word Vectors to Linguistic Constraints.", "author": ["Nikola Mrk\u0161i\u0107"], "venue": "HLT-NAACL", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Extracting Semantics from Unconstrained Navigation on Wikipedia.", "author": ["Thomas Niebler"], "venue": "KI - Ku\u0308nstliche Intelligenz", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Glove: Global Vectors for Word Representation.", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning"], "venue": "In: EMNLP. Vol", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Online and batch learning of generalized cosine similarities.", "author": ["Ali Mustafa Qamar", "Eric Gaussier"], "venue": "ICDM", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2009}, {"title": "A Word at a Time: Computing Word Relatedness Using Temporal Semantic Analysis.", "author": ["Kira Radinsky"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Learning a distance metric from relative comparisons.", "author": ["Matthew Schultz", "Thorsten Joachims"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2004}, {"title": "Computing Semantic Relatedness from Human Navigational Paths: A Case Study on Wikipedia.", "author": ["Philipp Singer"], "venue": "IJSWIS", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "LINE: Large-scale Information Network Embedding.", "author": ["Jian Tang"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "From Frequency to Meaning: Vector Space Models of Semantics.", "author": ["Peter D. Turney", "Patrick Pantel"], "venue": "In: J. Artif. Int. Res", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "Distance Metric Learning for Large Margin Nearest Neighbor Classification.", "author": ["Kilian Q. Weinberger", "Lawrence K. Saul"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2009}, {"title": "Wikispeedia: an online game for inferring semantic distances between concepts.", "author": ["Robert West", "Joelle Pineau", "Doina Precup"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2009}, {"title": "Distance metric learning with application to clustering with side-information.", "author": ["Eric P Xing"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2003}, {"title": "Improving Lexical Embeddings with Semantic Knowledge.", "author": ["Mo Yu", "Mark Dredze"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2014}, {"title": "Harnessing Folksonomies to Produce a Social Classification of Resources.", "author": ["Arkaitz Zubiaga"], "venue": "IEEE Trans. on Knowl. and Data Eng", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2013}], "referenceMentions": [{"referenceID": 5, "context": "Recent work has shown that semantic relatedness between words can successfully be extracted from a wide range of sources, such as tagging data [6, 17], Wikipedia article texts [13, 23] or Wikipedia navigation [20, 25].", "startOffset": 143, "endOffset": 150}, {"referenceID": 16, "context": "Recent work has shown that semantic relatedness between words can successfully be extracted from a wide range of sources, such as tagging data [6, 17], Wikipedia article texts [13, 23] or Wikipedia navigation [20, 25].", "startOffset": 143, "endOffset": 150}, {"referenceID": 12, "context": "Recent work has shown that semantic relatedness between words can successfully be extracted from a wide range of sources, such as tagging data [6, 17], Wikipedia article texts [13, 23] or Wikipedia navigation [20, 25].", "startOffset": 176, "endOffset": 184}, {"referenceID": 22, "context": "Recent work has shown that semantic relatedness between words can successfully be extracted from a wide range of sources, such as tagging data [6, 17], Wikipedia article texts [13, 23] or Wikipedia navigation [20, 25].", "startOffset": 176, "endOffset": 184}, {"referenceID": 19, "context": "Recent work has shown that semantic relatedness between words can successfully be extracted from a wide range of sources, such as tagging data [6, 17], Wikipedia article texts [13, 23] or Wikipedia navigation [20, 25].", "startOffset": 209, "endOffset": 217}, {"referenceID": 24, "context": "Recent work has shown that semantic relatedness between words can successfully be extracted from a wide range of sources, such as tagging data [6, 17], Wikipedia article texts [13, 23] or Wikipedia navigation [20, 25].", "startOffset": 209, "endOffset": 217}, {"referenceID": 26, "context": "In particular, such approaches usually encode semantic information of words in continuous word vectors [27].", "startOffset": 103, "endOffset": 107}, {"referenceID": 0, "context": ", low-dimensional, dense vector representations, which reduce the computational complexity of our metric learning approach and have been shown to outperform high-dimensional representations in measuring semantic relatedness [1].", "startOffset": 224, "endOffset": 227}, {"referenceID": 7, "context": "While word embedding approaches have been applied to several Wikipedia domains (texts or navigation) [8, 15, 21], we are, to the best of our knowledge, the first to derive tag embeddings and study the relationship between their dimensionality and their semantic expressiveness.", "startOffset": 101, "endOffset": 112}, {"referenceID": 14, "context": "While word embedding approaches have been applied to several Wikipedia domains (texts or navigation) [8, 15, 21], we are, to the best of our knowledge, the first to derive tag embeddings and study the relationship between their dimensionality and their semantic expressiveness.", "startOffset": 101, "endOffset": 112}, {"referenceID": 20, "context": "While word embedding approaches have been applied to several Wikipedia domains (texts or navigation) [8, 15, 21], we are, to the best of our knowledge, the first to derive tag embeddings and study the relationship between their dimensionality and their semantic expressiveness.", "startOffset": 101, "endOffset": 112}, {"referenceID": 15, "context": "In this work, we apply the LSML algorithm [16], which learns from relative distance constraints of the form C := {(x, x\u2032, y, y\u2032) : d(x, x\u2032) < d(y, y\u2032)} .", "startOffset": 42, "endOffset": 46}, {"referenceID": 4, "context": "As such relatedness scores are commonly collected in a crowdsourcing task [5, 12], they thus represent explicit human feedback.", "startOffset": 74, "endOffset": 81}, {"referenceID": 11, "context": "As such relatedness scores are commonly collected in a crowdsourcing task [5, 12], they thus represent explicit human feedback.", "startOffset": 74, "endOffset": 81}, {"referenceID": 2, "context": "The social tagging system BibSonomy provides users with the possibility to collect bookmarks (links to websites) or references to scientific publications and annotate them with tags [3].", "startOffset": 182, "endOffset": 185}, {"referenceID": 31, "context": "We use a freely available dataset from 2011 [33].", "startOffset": 44, "endOffset": 48}, {"referenceID": 7, "context": "Both are related to Wikipedia, which has been shown time after time to yield high quality semantic content [8, 13, 20, 23, 25].", "startOffset": 107, "endOffset": 126}, {"referenceID": 12, "context": "Both are related to Wikipedia, which has been shown time after time to yield high quality semantic content [8, 13, 20, 23, 25].", "startOffset": 107, "endOffset": 126}, {"referenceID": 19, "context": "Both are related to Wikipedia, which has been shown time after time to yield high quality semantic content [8, 13, 20, 23, 25].", "startOffset": 107, "endOffset": 126}, {"referenceID": 22, "context": "Both are related to Wikipedia, which has been shown time after time to yield high quality semantic content [8, 13, 20, 23, 25].", "startOffset": 107, "endOffset": 126}, {"referenceID": 24, "context": "Both are related to Wikipedia, which has been shown time after time to yield high quality semantic content [8, 13, 20, 23, 25].", "startOffset": 107, "endOffset": 126}, {"referenceID": 20, "context": "The authors of the GloVe embedding algorithm [21] trained several datasets of vector embeddings on various text data and made them publicly available.", "startOffset": 45, "endOffset": 49}, {"referenceID": 12, "context": "Because it has been demonstrated several times that the textual content of Wikipedia articles can be exploited to calculate semantic relatedness [13, 23], we use the vectors based on Wikipedia as a reference for word embeddings generated from natural language.", "startOffset": 145, "endOffset": 153}, {"referenceID": 22, "context": "Because it has been demonstrated several times that the textual content of Wikipedia articles can be exploited to calculate semantic relatedness [13, 23], we use the vectors based on Wikipedia as a reference for word embeddings generated from natural language.", "startOffset": 145, "endOffset": 153}, {"referenceID": 17, "context": "Wulczyn published a set of word embeddings generated from navigation data on the Wikipedia webpage [30] using Word2Vec [18].", "startOffset": 119, "endOffset": 123}, {"referenceID": 7, "context": "Word2Vec was originally intended to be applied on natural language text, though it can also be applied on navigational paths [8].", "startOffset": 125, "endOffset": 128}, {"referenceID": 19, "context": "It has been shown that exploiting human navigational paths as a source of semantic relatedness yields meaningful results [20, 25, 29].", "startOffset": 121, "endOffset": 133}, {"referenceID": 24, "context": "It has been shown that exploiting human navigational paths as a source of semantic relatedness yields meaningful results [20, 25, 29].", "startOffset": 121, "endOffset": 133}, {"referenceID": 28, "context": "It has been shown that exploiting human navigational paths as a source of semantic relatedness yields meaningful results [20, 25, 29].", "startOffset": 121, "endOffset": 133}, {"referenceID": 11, "context": "The WordSimilarity-353 dataset consists of 353 pairs of English words and names [12].", "startOffset": 80, "endOffset": 84}, {"referenceID": 4, "context": "The MEN Test Collection [5] contains 3,000 word pairs together with humanassigned similarity judgments, obtained by crowdsourcing using Amazon Mechanical Turk.", "startOffset": 24, "endOffset": 27}, {"referenceID": 12, "context": "Most of the time, the quality of semantic relatedness measures is assessed by how well it fits human intuition [13, 18, 25].", "startOffset": 111, "endOffset": 123}, {"referenceID": 17, "context": "Most of the time, the quality of semantic relatedness measures is assessed by how well it fits human intuition [13, 18, 25].", "startOffset": 111, "endOffset": 123}, {"referenceID": 24, "context": "Most of the time, the quality of semantic relatedness measures is assessed by how well it fits human intuition [13, 18, 25].", "startOffset": 111, "endOffset": 123}, {"referenceID": 14, "context": "While there exist other evaluation approaches like analogy matching [15, 18] or concept categorization [1], they do not fit our setting, because we exclusively want to improve measuring relatedness.", "startOffset": 68, "endOffset": 76}, {"referenceID": 17, "context": "While there exist other evaluation approaches like analogy matching [15, 18] or concept categorization [1], they do not fit our setting, because we exclusively want to improve measuring relatedness.", "startOffset": 68, "endOffset": 76}, {"referenceID": 0, "context": "While there exist other evaluation approaches like analogy matching [15, 18] or concept categorization [1], they do not fit our setting, because we exclusively want to improve measuring relatedness.", "startOffset": 103, "endOffset": 106}, {"referenceID": 5, "context": "However, vector representations of words extracted from tagging data are traditionally high-dimensional [6, 17], making metric learning in this domain infeasible due to a more than quadratic runtime with regard to the number of vector dimensions [16].", "startOffset": 104, "endOffset": 111}, {"referenceID": 16, "context": "However, vector representations of words extracted from tagging data are traditionally high-dimensional [6, 17], making metric learning in this domain infeasible due to a more than quadratic runtime with regard to the number of vector dimensions [16].", "startOffset": 104, "endOffset": 111}, {"referenceID": 15, "context": "However, vector representations of words extracted from tagging data are traditionally high-dimensional [6, 17], making metric learning in this domain infeasible due to a more than quadratic runtime with regard to the number of vector dimensions [16].", "startOffset": 246, "endOffset": 250}, {"referenceID": 0, "context": "Thus, similar to our Wikipedia examples we employ the notion of (low-dimensional) word embeddings which have been shown to outperform their high-dimensional counterparts in terms of correlation with human intuition of semantic relatedness [1].", "startOffset": 239, "endOffset": 242}, {"referenceID": 20, "context": "In this work, we apply the GloVe algorithm [21], which learns word embeddings from a word co-occurrence matrix.", "startOffset": 43, "endOffset": 47}, {"referenceID": 17, "context": "Other candidates are the well-known Word2Vec approach by [18] and the LINE algorithm [26].", "startOffset": 57, "endOffset": 61}, {"referenceID": 25, "context": "Other candidates are the well-known Word2Vec approach by [18] and the LINE algorithm [26].", "startOffset": 85, "endOffset": 89}, {"referenceID": 29, "context": "[31] proposed to parameterize the Euclidean metric with a Mahalanobis matrix M in order to improve kNN clusterings by incorporating side knowledge.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] presented the LMNN algorithm, which aims to improve kNN clustering by placing", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "The metric learning algorithm proposed in [9] makes use of quadruplets (x, x\u2032, y, y\u2032) and distance constraints u and l.", "startOffset": 42, "endOffset": 45}, {"referenceID": 21, "context": "Finally, Qamar and Gaussier [22] propose an algorithm to learn a generalized cosine measure to improve kNN classification.", "startOffset": 28, "endOffset": 32}, {"referenceID": 23, "context": "In [24], Schultz and Joachims propose an early distance metric learning approach based on Ranking Support Vector Machines.", "startOffset": 3, "endOffset": 7}, {"referenceID": 15, "context": "The algorithm proposed in [16] makes use of relative distance comparisons encoded in quadruplets (x, x\u2032, y, y\u2032), which encode relative comparisons d(x, x\u2032) < d(y, y\u2032) without a separation margin, in order to learn a metric.", "startOffset": 26, "endOffset": 30}, {"referenceID": 23, "context": "This is a more general approach than the one provided by [24], as it is easy to convert triplet constraints to quadruplet constraints, but not the other way round.", "startOffset": 57, "endOffset": 61}, {"referenceID": 1, "context": "Such methods train a model to predict a word from a given context [2, 7, 18, 26].", "startOffset": 66, "endOffset": 80}, {"referenceID": 6, "context": "Such methods train a model to predict a word from a given context [2, 7, 18, 26].", "startOffset": 66, "endOffset": 80}, {"referenceID": 17, "context": "Such methods train a model to predict a word from a given context [2, 7, 18, 26].", "startOffset": 66, "endOffset": 80}, {"referenceID": 25, "context": "Such methods train a model to predict a word from a given context [2, 7, 18, 26].", "startOffset": 66, "endOffset": 80}, {"referenceID": 9, "context": "Other embedding methods focus on factorizing a term-document matrix [10, 21].", "startOffset": 68, "endOffset": 76}, {"referenceID": 20, "context": "Other embedding methods focus on factorizing a term-document matrix [10, 21].", "startOffset": 68, "endOffset": 76}, {"referenceID": 0, "context": "Anyhow, [1] showed that all those methods generally exhibit a notably higher correlation with human intuition than the standard high-dimensional vector representations proposed by [27].", "startOffset": 8, "endOffset": 11}, {"referenceID": 26, "context": "Anyhow, [1] showed that all those methods generally exhibit a notably higher correlation with human intuition than the standard high-dimensional vector representations proposed by [27].", "startOffset": 180, "endOffset": 184}, {"referenceID": 13, "context": "Both [14] and [19] propose approaches to inject synonymy and, in the case of the latter, also antonymy constraints into semantic vector representations.", "startOffset": 5, "endOffset": 9}, {"referenceID": 18, "context": "Both [14] and [19] propose approaches to inject synonymy and, in the case of the latter, also antonymy constraints into semantic vector representations.", "startOffset": 14, "endOffset": 18}, {"referenceID": 10, "context": "[11] presented a method to fit the embedding vectors to the neighborhood defined by relations in semantic lexicons.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": ", [4, 32].", "startOffset": 2, "endOffset": 9}, {"referenceID": 30, "context": ", [4, 32].", "startOffset": 2, "endOffset": 9}], "year": 2017, "abstractText": "Assessing the degree of semantic relatedness between words is an important task with a variety of semantic applications, such as ontology learning for the Semantic Web, semantic search or query expansion. To accomplish this in an automated fashion, many relatedness measures have been proposed. However, most of these metrics only encode information contained in the underlying corpus and thus do not directly model human intuition. To solve this, we propose to utilize a metric learning approach to improve existing semantic relatedness measures by learning from additional information, such as explicit human feedback. For this, we argue to use word embeddings instead of traditional high-dimensional vector representations in order to leverage their semantic density and to reduce computational cost. We rigorously test our approach on several domains including tagging data as well as publicly available embeddings based on Wikipedia texts and navigation. Human feedback about semantic relatedness for learning and evaluation is extracted from publicly available datasets such as MEN or WS-353. We find that our method can significantly improve semantic relatedness measures by learning from additional information, such as explicit human feedback. For tagging data, we are the first to generate and study embeddings. Our results are of special interest for ontology and recommendation engineers, but also for any other researchers and practitioners of Semantic Web techniques.", "creator": "LaTeX with hyperref package"}}}