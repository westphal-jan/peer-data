{"id": "1705.07687", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2017", "title": "W2VLDA: Almost Unsupervised System for Aspect Based Sentiment Analysis", "abstract": "With the increase of online customer opinions in specialised websites and social networks, the necessity of automatic systems to help to organise and classify customer reviews by domain-specific aspect/categories and sentiment polarity is more important than ever. Supervised approaches to Aspect Based Sentiment Analysis obtain good results for the domain/language their are trained on, but having manually labelled data for training supervised systems for all domains and languages use to be very costly and time consuming. In this work we describe W2VLDA, an unsupervised system based on topic modelling, that combined with some other unsupervised methods and a minimal configuration, performs aspect/category classifiation, aspectterms/opinion-words separation and sentiment polarity classification for any given domain and language. We also evaluate the performance of the aspect and sentiment classification in the multilingual SemEval 2016 task 5 (ABSA) dataset. We show competitive results for several languages (English, Spanish, French and Dutch) and domains (hotels, restaurants, electronic-devices).", "histories": [["v1", "Mon, 22 May 2017 12:01:10 GMT  (326kb,D)", "https://arxiv.org/abs/1705.07687v1", null], ["v2", "Tue, 18 Jul 2017 07:36:48 GMT  (329kb,D)", "http://arxiv.org/abs/1705.07687v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["aitor garc\\'ia-pablos", "montse cuadros", "german rigau"], "accepted": false, "id": "1705.07687"}, "pdf": {"name": "1705.07687.pdf", "metadata": {"source": "CRF", "title": "W2VLDA: Almost Unsupervised System for Aspect Based Sentiment Analysis", "authors": ["Aitor Gar\u0107\u0131a-Pablosa", "Montse Cuadros", "German Rigau"], "emails": ["agarciap@vicomtech.org", "mcuadros@vicomtech.org", "german.rigau@ehu.eus"], "sections": [{"heading": null, "text": "With the increase in online customer reviews on specialized websites and social networks, the need for automated systems to organize and classify customer reviews by domain-specific aspects / categories and sentiment polarity is more important than ever. Supervised approaches to Aspect Based Sentiment Analysis achieve good results for the area / language in which they are trained, but manually labeled data to train monitored systems for all domains and languages is usually very costly and time consuming. In this work, we describe W2VLDA, an almost unattended system based on topic modeling that, in combination with some other uncontrolled methods and minimal configuration, performs aspect / category classification, Aspect / Opinion Word separation and sentiment polarity classification for each domain and language. We evaluate the performance of aspect and sentiment classification in the 2016 multilingual semester Task 5 (AB5). We show competitive results for Spanish, French, and non-Spanish (almost) restaurants."}, {"heading": "1. Introduction", "text": "In fact, it is such that most of them will be able to move into a different world, in which they are able to integrate themselves, in which they are able to live, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they are able to change the world, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live in which they live in which they live, in which they live in which they are able to integrate themselves, in which they are able to live, in which they are able to live, in which they are able, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live,"}, {"heading": "2. Related work", "text": "In fact, most of them will be able to move to another world, where they will be able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "3. System description", "text": "The main objective of the W2VLDA system is to simultaneously perform the three tasks (detection of aspects, opinions and their polarity) of Aspect Based Sentiment Analysis, i.e. classify pieces of text into a predefined set of domain aspects and classify their mood polarity as positive or negative. Furthermore, our system separates opinion words from aspect terms without requiring additional resources or supervision. At its core, the system consists of an LDA-based theme model, supplemented by additional variables, whereby biased subject modeling hyper parameters is based on continuous word embedding and combined with an unsupervised pre-defined classification model for separating aspect, term and opinion words."}, {"heading": "3.1. Topics and sentiment configuration", "text": "W2VLDA requires only a minimum domain aspect and a minimum polarity configuration per language and domain. The configuration consists of a single seed to define every desired domain aspect, plus a single generic positive seed word and a single generic negative seed word that applies to all domain aspects. This simple configuration is the only linguistic and domain-dependent information that W2VLDA 3 needs. Therefore, a simple translation of the seeds should be sufficient for the system to work for another language or domain, as long as each translated seed has an equivalent meaning and use in the target language. Table 1 shows an example of a domain aspect and a polarity configuration for the restaurant domain in multiple languages."}, {"heading": "3.2. Aspect-term and opinion-word separation", "text": "To achieve this separation without adding any language-dependent tool or resource, the system3A list of generic stopwords for each target language is also necessary to achieve better results. Brown clusters were used as unattended features in monitored part-of-speech tagging (Brown et al., 1992) to find examples of aspect terms and opinion terms and to learn a MaxEnt-based classification model. Brown clusters were used as unattended features in monitored part-of-speech tagging (Turian et al., 2010) and named entity recognition (Agerri and Rigau, 2016). Brown clusters are necessarily 4 domain-unlabeled corpus with no additional supervision and are used as features for the two words context windows."}, {"heading": "3.3. Combining everything in a topic model", "text": "The core of the system consists of an LDA-based theme model, extended to include the aspect terms / opinion division and the positive / negative separation for each topic. In addition, the aspect term / opinion division is guided by a lecturer classifier, as described in Section 3.2, while the topic and polarity modeling are guided by the bias of certain hyperparameters according to the given theme configuration. Figure 4 shows the proposed topic in plate notation and the generative history modeled by the algorithm. The generative hypothesis described by the model is the following: For each document d a distribution of topics, a default is made of a dirichlet distribution with parameters that is a vector with asymmetric themes for this document. Note that in this context, each document corresponds to individual sentences instead of complete texts. Then, a theme value is drawn for each word n:"}, {"heading": "4. Evaluation", "text": "We evaluate W2VLDA for the three different sub-tasks it performs: classification of topics (aspects), classification of sensations, and separation of aspects (aspects) and opinions. First, we compare W2VLDA with other LDA-based methods. Then, we evaluate W2VLDA in a multilingual ABSA dataset by comparing its performance classification of topics (aspects) and sensations with some monitored machine learning approaches trained on the basis of labeled data. We show results for multiple datasets and show how the system works for different languages and domains by simply changing the theme configuration, which consists of a single seed word per desired topic, language, and domain. For example, Table 2 shows some of the resulting words for multiple domains (restaurants and electronic devices), topics (food, service, ambience for restaurants, and electronic device warranty, design, and pricing) for English customer ratings, per topic, including the automatic separation and negative aspects."}, {"heading": "4.1. Resources and experimental setting", "text": "To evaluate W2VLDA, we use the following resources. To classify topics, we use the dataset of (Ganu et al., 2009), which contains restaurant ratings in English labeled with domain-related categories (e.g. food, personnel, ambience). To classify sensations, we use the Laptops and DIGITAL-SLR dataset (Jo and Oh, 2011), which consists of English ratings of electronic products with their corresponding 5-star ratings. To create the theme model and word embeddings, additional customer ratings were conducted on restaurants from some popular customer rating websites (Pontiki et al., 2016). Specifically, restaurant ratings show records labeled with domain-related categories and polarity for six languages. In order to calculate the theme model and word embeddings, we have automatically compiled additional customer ratings on restaurants from some popular customer rating websites. These non-domain literature consists of English, a few French restaurant ratings, and a few French restaurant ratings."}, {"heading": "4.2. Comparison with other LDA based approaches", "text": "First, we evaluate W2VLDA in a topic classification setting using the restaurant ratings dataset of (Ganu et al., 2009).This dataset contains several thousand reviews of restaurants, divided into several categories, but the authors report results only for the three main categories: Food, Ambience and Personnel. We compare W2VLDA with the results reported in (Zhao et al., 2010) for two LDA-based approaches, LocLDA (Brody and Elhadad, 2010) and ME-LDA (Zhao et al., 2010).LocLDA and ME-LDA are LDA-based approaches, and thus, unattended to. But the results reported in the experiment included some oversight as in Zhao et al. (2010).First, the authors calculated a topic model of 14 topics and topics. Then the authors examine each topic and manually insert a label according to their judgment."}, {"heading": "4.3. Multilingual evaluation on SemEval2016 dataset", "text": "In fact, it is so that most people who have been in the USA in recent years in the USA, in Europe, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA in the USA, in the USA, in the USA, in the USA, in the USA in the USA, in the USA, in the USA, in the USA in the USA, in the USA, in the USA in the USA, in the USA, in the USA in the USA, in the USA, in the USA, in the USA in the USA, in the USA, in the USA, in the USA in the USA, in the USA, in the USA, in the USA, in the USA in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the"}, {"heading": "NB 0.492 0.497 0.472 0.457", "text": "Similar to calculating a distortion for each word, only the configured seed words get a strong distortion for their respective topic or polarity.Table 9 shows the evaluation results for the domain aspects classification (food, service, ambience).Since the evaluation data sets for each domain aspect are not fully balanced (see Table 6), we perform the evaluation on several balanced subsets by random sampling of the basic data sets for each language. Each balanced subset contains 100 sentences from each domain aspect. We calculate the average and standard deviation of the results for each subset to generate five different subsets, and use these subsets to evaluate the baselines and W2VLDA. The results on each subset are obtained with the average accuracy that dies when applying a 10-fold cross-validation. We calculate the average and standard deviation of the results on each subset to perform a baseline statistical validation for all languages."}, {"heading": "NB 0.672 0.577 0.587 0.563", "text": "Limits on the amount of data required would be an interesting problem that we would allow for future research."}, {"heading": "4.4. Assessing the seed words impact", "text": "Since the proposed approach relies heavily on the seed words (i.e. seed words are the only source of monitoring to guide the algorithm to the desired destination), it is interesting to consider the impact of the different seed words and their combination.In the first experiment group, for each run we only change the seed words that define the domain aspects with the SemEval 2016 Restaurant Ratings Dataset and several combinations of seed words for each domain aspect and sensations polarities. In the first experiment group, for each run we only change the seed words that define the domain aspects. We use three different seed words for each domain aspect, in particular: food, chicken and burger for domain aspect FOOD; service, staff and waiters for domain aspect SERVICE; and ambience, atmosphere and de-cor for domain aspect AMBIENCE. We try different permutations and combinations of seed words, including pairs of seed words for each domain aspect, and finally the seed aspect together as well."}, {"heading": "4.5. Aspect-term/Opinion-word separation evaluation", "text": "Finally, we are experimenting with the separation of aspect terms and opinion words. As described in Section 3.2, W2VLDA models domain terms into separate word distributions: aspect terms or opinion words. To evaluate the accuracy of this separation, we are using Bing Liu's Polarity Dictionary for English (Hu and Liu, 2004). Since sentiment dictionaries contain words that carry a certain sensation, we are treating the words contained in this lexicon as basic truth for opinion words. In addition, we are using the golden aspect terms designated in the SemEval 2016 dataset as basic truth for aspect terms. The experiment now consists of running the W2VLDA again on the restaurant verification dataset and counting how often a word is classified as opinion word by the opinion words soil truth and how often each word should be classified as basic truth as reason / reason term. Then, the percentage of a certain word is automatically weighted in the general aspect."}, {"heading": "5. Conclusions and future work", "text": "In this document, we introduced W2VLDA for aspect classification, a system that performs aspect and sentiment classification almost without oversight and without the need for linguistic or domain-specific resources. To do this, the system combines various unattended approaches, such as word embedding or latent dirichlet allocation (LDA), to boot information from a domain-specific corpus. The only supervision required by the user is a single seed per desired aspect and polarity. Therefore, the system can be applied almost without customization to data sets of different languages and domains. The resulting topics and polarities are paired directly with the aspect names selected by the user at the outset, so that the results can be used to perform an Aspect Based Sentiment Analysis. In addition, the system attempts to automatically separate the terms of aspects and opinion words, providing clearer information and insights to the resulting domain aspects."}, {"heading": "Acknowledgements", "text": "This work was supported by Vicomtech-IK4 and the project TUNER - TIN2015-65308-C5-1-R (MINECO / FEDER, UE)."}], "references": [{"title": "Robust multilingual named entity recognition with shallow semi-supervised features", "author": ["R. Agerri", "G. Rigau"], "venue": "Artificial Intelligence, 238:63 \u2013 82.", "citeRegEx": "Agerri and Rigau,? 2016", "shortCiteRegEx": "Agerri and Rigau", "year": 2016}, {"title": "Joint multi-grain topic sentiment: Modeling semantic aspects for online reviews", "author": ["M.H. Alam", "W.J. Ryu", "S.K. Lee"], "venue": "Information Sciences, 339:206\u2013223. 26", "citeRegEx": "Alam et al\\.,? 2016", "shortCiteRegEx": "Alam et al\\.", "year": 2016}, {"title": "Enhancing deep learning sentiment analysis with ensemble techniques in social applications", "author": ["O. Araque", "I. Corcuera-Platas", "J.F. S\u00e1nchez-Rada", "C.A. Iglesias"], "venue": "Expert Systems with Applications, 77:236\u2013 246.", "citeRegEx": "Araque et al\\.,? 2017", "shortCiteRegEx": "Araque et al\\.", "year": 2017}, {"title": "Automatic labelling of topics with neural embeddings", "author": ["S. Bhatia", "J.H. Lau", "T. Baldwin"], "venue": "arXiv preprint arXiv:1612.05340.", "citeRegEx": "Bhatia et al\\.,? 2016", "shortCiteRegEx": "Bhatia et al\\.", "year": 2016}, {"title": "Building a sentiment summarizer for local service reviews", "author": ["S. Blair-Goldensohn", "K. Hannan", "R. McDonald", "T. Neylon", "G.A. Reis", "J. Reynar"], "venue": "WWW workshop on NLP in the information explosion era, volume 14, pages 339\u2013348.", "citeRegEx": "Blair.Goldensohn et al\\.,? 2008", "shortCiteRegEx": "Blair.Goldensohn et al\\.", "year": 2008}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "the Journal of machine Learning research, 3:993\u20131022.", "citeRegEx": "Blei et al\\.,? 2003", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "An unsupervised aspect-sentiment model for online reviews", "author": ["S. Brody", "N. Elhadad"], "venue": "The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, (June):804\u2013812.", "citeRegEx": "Brody and Elhadad,? 2010", "shortCiteRegEx": "Brody and Elhadad", "year": 2010}, {"title": "Class-based n-gram models of natural language", "author": ["P.F. Brown", "P.V. Desouza", "R.L. Mercer", "V.J.D. Pietra", "J.C. Lai"], "venue": "Computational linguistics, 18(4):467\u2013479.", "citeRegEx": "Brown et al\\.,? 1992", "shortCiteRegEx": "Brown et al\\.", "year": 1992}, {"title": "Improving sentiment analysis via sentence type classification using BiLSTM-CRF and CNN", "author": ["T. Chen", "R. Xu", "Y. He", "X. Wang"], "venue": "Expert Systems with Applications, 72:221\u2013230.", "citeRegEx": "Chen et al\\.,? 2017", "shortCiteRegEx": "Chen et al\\.", "year": 2017}, {"title": "Aspect extraction with automated prior knowledge learning", "author": ["Z. Chen", "A. Mukherjee", "B. Liu"], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 347\u2013358.", "citeRegEx": "Chen et al\\.,? 2014", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["R. Collobert", "J. Weston"], "venue": "Proceedings of the 25th international conference on Machine learning, pages 160\u2013167. ACM.", "citeRegEx": "Collobert and Weston,? 2008", "shortCiteRegEx": "Collobert and Weston", "year": 2008}, {"title": "Gaussian LDA for Topic Models with Word Embeddings", "author": ["R. Das", "M. Zaheer", "C. Dyer"], "venue": "Proceedings of the 53nd Annual Meeting of the Association for Computational Linguistics, pages 795\u2013804. 27", "citeRegEx": "Das et al\\.,? 2015", "shortCiteRegEx": "Das et al\\.", "year": 2015}, {"title": "Beyond the stars: Improving rating predictions using review text content", "author": ["G. Ganu", "N. Elhadad", "A. Marian"], "venue": "WebDB, volume 9, pages 1\u20136. Citeseer.", "citeRegEx": "Ganu et al\\.,? 2009", "shortCiteRegEx": "Ganu et al\\.", "year": 2009}, {"title": "Sentiment analysis leveraging emotions and word embeddings", "author": ["M. Giatsoglou", "M.G. Vozalis", "K. Diamantaras", "A. Vakali", "G. Sarigiannidis", "K.C. Chatzisavvas"], "venue": "Expert Systems with Applications, 69:214\u2013224.", "citeRegEx": "Giatsoglou et al\\.,? 2017", "shortCiteRegEx": "Giatsoglou et al\\.", "year": 2017}, {"title": "Finding scientific topics", "author": ["T.L. Griffiths", "M. Steyvers"], "venue": "Proceedings of the National Academy of Sciences, 101(suppl 1):5228\u20135235.", "citeRegEx": "Griffiths and Steyvers,? 2004", "shortCiteRegEx": "Griffiths and Steyvers", "year": 2004}, {"title": "Mining opinion features in customer reviews", "author": ["M. Hu", "B. Liu"], "venue": "AAAI, volume 4, pages 755\u2013760.", "citeRegEx": "Hu and Liu,? 2004", "shortCiteRegEx": "Hu and Liu", "year": 2004}, {"title": "Automatic construction of domain-specific sentiment lexicon based on constrained label propagation", "author": ["S. Huang", "Z. Niu", "C. Shi"], "venue": "Knowledge-Based Systems, 56:191\u2013200.", "citeRegEx": "Huang et al\\.,? 2014", "shortCiteRegEx": "Huang et al\\.", "year": 2014}, {"title": "Generating focused topic-specific sentiment lexicons", "author": ["V. Jijkoun", "M. de Rijke", "W. Weerkamp"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Jijkoun et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jijkoun et al\\.", "year": 2010}, {"title": "Aspect and sentiment unification model for online review analysis", "author": ["Y. Jo", "A.H. Oh"], "venue": "Proceedings of the fourth ACM international conference on Web search and data mining, pages 815\u2013824. ACM.", "citeRegEx": "Jo and Oh,? 2011", "shortCiteRegEx": "Jo and Oh", "year": 2011}, {"title": "A Hierarchical Aspect-Sentiment Model for Online Reviews", "author": ["S. Kim", "J. Zhang", "Z. Chen", "A. Oh", "S. Liu"], "venue": "Proceedings of the TwentySeventh AAAI Conference on Artificial Intelligence, pages 526\u2013533.", "citeRegEx": "Kim et al\\.,? 2013", "shortCiteRegEx": "Kim et al\\.", "year": 2013}, {"title": "Weakly supervised joint sentiment-topic detection from text", "author": ["C. Lin", "Y. He", "R. Everson", "S. R\u00fcger"], "venue": "IEEE Transactions on Knowledge and Data Engineering, 24:1134\u20131145.", "citeRegEx": "Lin et al\\.,? 2011", "shortCiteRegEx": "Lin et al\\.", "year": 2011}, {"title": "Joint Sentiment / Topic Model for Sentiment Analysis", "author": ["C. Lin", "N.P. Road", "E. Ex"], "venue": "Cikm, pages 375\u2013384.", "citeRegEx": "Lin et al\\.,? 2009", "shortCiteRegEx": "Lin et al\\.", "year": 2009}, {"title": "Sentiment analysis and opinion mining", "author": ["B. Liu"], "venue": "Synthesis Lectures on Human Language Technologies, 5(1):1\u2013167. 28", "citeRegEx": "Liu,? 2012", "shortCiteRegEx": "Liu", "year": 2012}, {"title": "Opinion target extraction using wordbased translation model", "author": ["K. Liu", "L. Xu", "J. Zhao"], "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, (July):1346\u20131356.", "citeRegEx": "Liu et al\\.,? 2012", "shortCiteRegEx": "Liu et al\\.", "year": 2012}, {"title": "Multi-aspect sentiment analysis with topic models", "author": ["B. Lu", "M. Ott", "C. Cardie", "B.K. Tsou"], "venue": "Proceedings - IEEE International Conference on Data Mining, ICDM, pages 81\u201388.", "citeRegEx": "Lu et al\\.,? 2011", "shortCiteRegEx": "Lu et al\\.", "year": 2011}, {"title": "Supervised topic models", "author": ["J.D. Mcauliffe", "D.M. Blei"], "venue": "Advances in neural information processing systems, pages 121\u2013128.", "citeRegEx": "Mcauliffe and Blei,? 2008", "shortCiteRegEx": "Mcauliffe and Blei", "year": 2008}, {"title": "Efficient Estimation of Word Representations in Vector Space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "arXiv preprint arXiv:1301.3781, pages 1\u201312.", "citeRegEx": "Mikolov et al\\.,? 2013a", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Linguistic regularities in continuous space word representations", "author": ["T. Mikolov", "Yih", "W.-t.", "G. Zweig"], "venue": "Proceedings of NAACL-HLT, pages 746\u2013751.", "citeRegEx": "Mikolov et al\\.,? 2013b", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "More than words: Social networks text mining for consumer brand sentiments", "author": ["M.M. Mostafa"], "venue": "Expert Systems with Applications, 40(10):4241\u20134251.", "citeRegEx": "Mostafa,? 2013", "shortCiteRegEx": "Mostafa", "year": 2013}, {"title": "Aspect extraction through semi-supervised modeling", "author": ["A. Mukherjee", "B. Liu"], "venue": "ACL \u201912 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, (July):339\u2013 348.", "citeRegEx": "Mukherjee and Liu,? 2012", "shortCiteRegEx": "Mukherjee and Liu", "year": 2012}, {"title": "Improving topic models with latent feature word representations", "author": ["D.Q. Nguyen", "R. Billingsley", "L. Du", "M. Johnson"], "venue": "Transactions of the Association for Computational Linguistics, 3:299\u2013313.", "citeRegEx": "Nguyen et al\\.,? 2015", "shortCiteRegEx": "Nguyen et al\\.", "year": 2015}, {"title": "Opinion mining and sentiment analysis", "author": ["B. Pang", "L. Lee"], "venue": "Foundations and trends in information retrieval, 2(1-2):1\u2013135.", "citeRegEx": "Pang and Lee,? 2008", "shortCiteRegEx": "Pang and Lee", "year": 2008}, {"title": "Semeval-2015 task 12: Aspect based sentiment analysis", "author": ["M. Pontiki", "D. Galanis", "H. Papageorgiou", "S. Manandhar", "I. Androutsopoulos"], "venue": "Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), Association for Computational Linguistics, Denver, Colorado, pages 486\u2013495.", "citeRegEx": "Pontiki et al\\.,? 2015", "shortCiteRegEx": "Pontiki et al\\.", "year": 2015}, {"title": "Semeval-2014 task 4: Aspect based sentiment analysis", "author": ["M. Pontiki", "D. Galanis", "J. Pavlopoulos", "H. Papageorgiou", "I. Androutsopoulos", "S. Manandhar"], "venue": "Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), Association for Computational Linguistics, Dublin, Ireland, pages 27\u201335.", "citeRegEx": "Pontiki et al\\.,? 2014", "shortCiteRegEx": "Pontiki et al\\.", "year": 2014}, {"title": "Extracting product features and opinions from reviews", "author": ["Popescu", "A.-M.", "O. Etzioni"], "venue": "Natural language processing and text mining, pages 9\u201328. Springer.", "citeRegEx": "Popescu et al\\.,? 2007", "shortCiteRegEx": "Popescu et al\\.", "year": 2007}, {"title": "Topic Modeling over Short Texts by Incorporating Word Embeddings", "author": ["J. Qiang", "P. Chen", "T. Wang", "X. Wu"], "venue": "arXiv preprint arXiv: 1609.08496v1, page 10.", "citeRegEx": "Qiang et al\\.,? 2016", "shortCiteRegEx": "Qiang et al\\.", "year": 2016}, {"title": "Opinion word expansion and target extraction through double propagation", "author": ["G. Qiu", "B. Liu", "J. Bu", "C. Chen"], "venue": "Computational linguistics, 37(1):9\u201327.", "citeRegEx": "Qiu et al\\.,? 2011", "shortCiteRegEx": "Qiu et al\\.", "year": 2011}, {"title": "Labeled LDA: A supervised topic model for credit attribution in multi-labeled corpora", "author": ["D. Ramage", "D. Hall", "R. Nallapati", "C.D. Manning"], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, pages 248\u2013256. Association for Computational Linguistics.", "citeRegEx": "Ramage et al\\.,? 2009", "shortCiteRegEx": "Ramage et al\\.", "year": 2009}, {"title": "Semi-supervised polarity lexicon induction", "author": ["D. Rao", "D. Ravichandran"], "venue": "Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 675\u2013682. Association for Computational Linguistics.", "citeRegEx": "Rao and Ravichandran,? 2009", "shortCiteRegEx": "Rao and Ravichandran", "year": 2009}, {"title": "Ultradense word embeddings by orthogonal transformation", "author": ["S. Rothe", "S. Ebert", "H. Sch\u00fctze"], "venue": "arXiv preprint arXiv:1602.07572.", "citeRegEx": "Rothe et al\\.,? 2016", "shortCiteRegEx": "Rothe et al\\.", "year": 2016}, {"title": "Learning Sentiment-Specific Word Embedding", "author": ["D. Tang", "F. Wei", "N. Yang", "M. Zhou", "T. Liu", "B. Qin"], "venue": "Acl, pages 1555\u20131565.", "citeRegEx": "Tang et al\\.,? 2014", "shortCiteRegEx": "Tang et al\\.", "year": 2014}, {"title": "Word representations: a simple and general method for semi-supervised learning", "author": ["J. Turian", "L. Ratinov", "Y. Bengio"], "venue": "Proceedings of the 48th annual meeting of the association for computational linguistics, pages 384\u2013394. Association for Computational Linguistics.", "citeRegEx": "Turian et al\\.,? 2010", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "Measuring praise and criticism: Inference of semantic orientation from association", "author": ["P.D. Turney", "M.L. Littman"], "venue": "ACM Transactions on Information Systems (TOIS), 21(4):315\u2013346.", "citeRegEx": "Turney and Littman,? 2003", "shortCiteRegEx": "Turney and Littman", "year": 2003}, {"title": "Phrase dependency parsing for opinion mining", "author": ["Y. Wu", "Q. Zhang", "X. Huang", "L. Wu"], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, volume 3, pages 1533\u2013 1541. Association for Computational Linguistics.", "citeRegEx": "Wu et al\\.,? 2009", "shortCiteRegEx": "Wu et al\\.", "year": 2009}, {"title": "Jointly Modeling Aspects and Opinions with a MaxEnt-LDA Hybrid", "author": ["W.X. Zhao", "J. Jiang", "H. Yan", "X. Li"], "venue": "Computational Linguistics, 16(October):56\u201365. 31", "citeRegEx": "Zhao et al\\.,? 2010", "shortCiteRegEx": "Zhao et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 31, "context": "Opinion Mining is a subfield of Natural Language Processing (NLP) that deals with the automatic analysis of opinions shared by humans in different contexts, like in customer reviews (Pang and Lee, 2008; Liu, 2012).", "startOffset": 182, "endOffset": 213}, {"referenceID": 22, "context": "Opinion Mining is a subfield of Natural Language Processing (NLP) that deals with the automatic analysis of opinions shared by humans in different contexts, like in customer reviews (Pang and Lee, 2008; Liu, 2012).", "startOffset": 182, "endOffset": 213}, {"referenceID": 8, "context": "This is the case of deep-learning based systems, that provide very good performance but require a significant amount of labelled data for training (Chen et al., 2017; Araque et al., 2017).", "startOffset": 147, "endOffset": 187}, {"referenceID": 2, "context": "This is the case of deep-learning based systems, that provide very good performance but require a significant amount of labelled data for training (Chen et al., 2017; Araque et al., 2017).", "startOffset": 147, "endOffset": 187}, {"referenceID": 20, "context": "On the other hand, weakly-supervised systems do not require labelled data for training, but they usually need some language specific resources, such as carefully curated lists of seed words or language dependent tools to preprocess the input (Lin et al., 2011; Jo and Oh, 2011; Kim et al., 2013).", "startOffset": 242, "endOffset": 295}, {"referenceID": 18, "context": "On the other hand, weakly-supervised systems do not require labelled data for training, but they usually need some language specific resources, such as carefully curated lists of seed words or language dependent tools to preprocess the input (Lin et al., 2011; Jo and Oh, 2011; Kim et al., 2013).", "startOffset": 242, "endOffset": 295}, {"referenceID": 19, "context": "On the other hand, weakly-supervised systems do not require labelled data for training, but they usually need some language specific resources, such as carefully curated lists of seed words or language dependent tools to preprocess the input (Lin et al., 2011; Jo and Oh, 2011; Kim et al., 2013).", "startOffset": 242, "endOffset": 295}, {"referenceID": 23, "context": "During the last decade the research community has addressed the problem of analysing user opinions, particularly focused on online customer reviews (Liu et al., 2012; Chen et al., 2014).", "startOffset": 148, "endOffset": 185}, {"referenceID": 9, "context": "During the last decade the research community has addressed the problem of analysing user opinions, particularly focused on online customer reviews (Liu et al., 2012; Chen et al., 2014).", "startOffset": 148, "endOffset": 185}, {"referenceID": 15, "context": "A common approach in the literature is to identify frequent nouns, lexical patterns, dependency relations applying supervised machine learning approaches (Hu and Liu, 2004; Popescu and Etzioni, 2007; Blair-Goldensohn et al., 2008; Wu et al., 2009; Qiu et al., 2011).", "startOffset": 154, "endOffset": 265}, {"referenceID": 4, "context": "A common approach in the literature is to identify frequent nouns, lexical patterns, dependency relations applying supervised machine learning approaches (Hu and Liu, 2004; Popescu and Etzioni, 2007; Blair-Goldensohn et al., 2008; Wu et al., 2009; Qiu et al., 2011).", "startOffset": 154, "endOffset": 265}, {"referenceID": 43, "context": "A common approach in the literature is to identify frequent nouns, lexical patterns, dependency relations applying supervised machine learning approaches (Hu and Liu, 2004; Popescu and Etzioni, 2007; Blair-Goldensohn et al., 2008; Wu et al., 2009; Qiu et al., 2011).", "startOffset": 154, "endOffset": 265}, {"referenceID": 36, "context": "A common approach in the literature is to identify frequent nouns, lexical patterns, dependency relations applying supervised machine learning approaches (Hu and Liu, 2004; Popescu and Etzioni, 2007; Blair-Goldensohn et al., 2008; Wu et al., 2009; Qiu et al., 2011).", "startOffset": 154, "endOffset": 265}, {"referenceID": 28, "context": "Some works focus on automatically deriving the most likely polarity for words, constructing a so-called sentiment lexicon (Mostafa, 2013).", "startOffset": 122, "endOffset": 137}, {"referenceID": 38, "context": "of bootstrapping or polarity propagation leveraging some base dictionaries and pre-existing linguistic resources (Rao and Ravichandran, 2009; Jijkoun et al., 2010; Huang et al., 2014).", "startOffset": 113, "endOffset": 183}, {"referenceID": 17, "context": "of bootstrapping or polarity propagation leveraging some base dictionaries and pre-existing linguistic resources (Rao and Ravichandran, 2009; Jijkoun et al., 2010; Huang et al., 2014).", "startOffset": 113, "endOffset": 183}, {"referenceID": 16, "context": "of bootstrapping or polarity propagation leveraging some base dictionaries and pre-existing linguistic resources (Rao and Ravichandran, 2009; Jijkoun et al., 2010; Huang et al., 2014).", "startOffset": 113, "endOffset": 183}, {"referenceID": 5, "context": "LDA is a generative model introduced by (Blei et al., 2003) that quickly gained popularity because it is an unsupervised, flexible and extensible technique to model documents.", "startOffset": 40, "endOffset": 59}, {"referenceID": 25, "context": "Due to its flexibility, LDA has been extended and combined with other approaches, obtaining topic models that improve the resulting topics or that model additional information (Mcauliffe and Blei, 2008; Ramage et al., 2009).", "startOffset": 176, "endOffset": 223}, {"referenceID": 37, "context": "Due to its flexibility, LDA has been extended and combined with other approaches, obtaining topic models that improve the resulting topics or that model additional information (Mcauliffe and Blei, 2008; Ramage et al., 2009).", "startOffset": 176, "endOffset": 223}, {"referenceID": 18, "context": "Topic models have been applied to Sentiment Analysis to jointly model topics and sentiment of words (Lin et al., 2009, 2011; Jo and Oh, 2011; Lu et al., 2011; Kim et al., 2013; Alam et al., 2016).", "startOffset": 100, "endOffset": 195}, {"referenceID": 24, "context": "Topic models have been applied to Sentiment Analysis to jointly model topics and sentiment of words (Lin et al., 2009, 2011; Jo and Oh, 2011; Lu et al., 2011; Kim et al., 2013; Alam et al., 2016).", "startOffset": 100, "endOffset": 195}, {"referenceID": 19, "context": "Topic models have been applied to Sentiment Analysis to jointly model topics and sentiment of words (Lin et al., 2009, 2011; Jo and Oh, 2011; Lu et al., 2011; Kim et al., 2013; Alam et al., 2016).", "startOffset": 100, "endOffset": 195}, {"referenceID": 1, "context": "Topic models have been applied to Sentiment Analysis to jointly model topics and sentiment of words (Lin et al., 2009, 2011; Jo and Oh, 2011; Lu et al., 2011; Kim et al., 2013; Alam et al., 2016).", "startOffset": 100, "endOffset": 195}, {"referenceID": 3, "context": "This task requires a manual inspection by an expert or a mapping calculation to an existing resource (Bhatia et al., 2016).", "startOffset": 101, "endOffset": 122}, {"referenceID": 26, "context": "Continuous word embeddings are known for capturing semantic regularities of words (Mikolov et al., 2013a; Collobert and Weston, 2008).", "startOffset": 82, "endOffset": 133}, {"referenceID": 10, "context": "Continuous word embeddings are known for capturing semantic regularities of words (Mikolov et al., 2013a; Collobert and Weston, 2008).", "startOffset": 82, "endOffset": 133}, {"referenceID": 11, "context": "Some works have made use of this fact to improve the resulting topics (Das et al., 2015; Nguyen et al., 2015; Qiang et al., 2016), but", "startOffset": 70, "endOffset": 129}, {"referenceID": 30, "context": "Some works have made use of this fact to improve the resulting topics (Das et al., 2015; Nguyen et al., 2015; Qiang et al., 2016), but", "startOffset": 70, "endOffset": 129}, {"referenceID": 35, "context": "Some works have made use of this fact to improve the resulting topics (Das et al., 2015; Nguyen et al., 2015; Qiang et al., 2016), but", "startOffset": 70, "endOffset": 129}, {"referenceID": 40, "context": "There are works that exploit word embeddings in a supervised machine learning setting to perform sentiment analysis (Tang et al., 2014; Giatsoglou et al., 2017).", "startOffset": 116, "endOffset": 160}, {"referenceID": 13, "context": "There are works that exploit word embeddings in a supervised machine learning setting to perform sentiment analysis (Tang et al., 2014; Giatsoglou et al., 2017).", "startOffset": 116, "endOffset": 160}, {"referenceID": 44, "context": "Some authors have also attempted an automatic aspect-term/opinionword separation within the topic modelling process (Zhao et al., 2010; Mukherjee and Liu, 2012).", "startOffset": 116, "endOffset": 160}, {"referenceID": 29, "context": "Some authors have also attempted an automatic aspect-term/opinionword separation within the topic modelling process (Zhao et al., 2010; Mukherjee and Liu, 2012).", "startOffset": 116, "endOffset": 160}, {"referenceID": 7, "context": "Instead, we apply Brown clustering (Brown et al., 1992) to a set of training instances from an unlabelled corpus in order to train an aspect-term/opinion-word classifier that is later integrated into the topic modelling process.", "startOffset": 35, "endOffset": 55}, {"referenceID": 12, "context": ", 2014; Giatsoglou et al., 2017). Some authors have also attempted an automatic aspect-term/opinionword separation within the topic modelling process (Zhao et al., 2010; Mukherjee and Liu, 2012). Aspect terms are the words that are used to speak about the aspect being evaluated (e.g. waiter or waitstaff when speaking about the service of a restaurant). On the other hand, opinion words express the sentiment about an aspect, such as attentive or terrible. The separation of these two kinds of words might be useful because it eases the interpretation of the resulting topics, and the sentiment classification can be focused on the opinion-words which are more likely to bear sentiment information. Zhao et al. (2010) attempted this separation training a supervised classifier on a small manually labelled dataset and using Part-of-Speech tagging.", "startOffset": 8, "endOffset": 719}, {"referenceID": 12, "context": ", 2014; Giatsoglou et al., 2017). Some authors have also attempted an automatic aspect-term/opinionword separation within the topic modelling process (Zhao et al., 2010; Mukherjee and Liu, 2012). Aspect terms are the words that are used to speak about the aspect being evaluated (e.g. waiter or waitstaff when speaking about the service of a restaurant). On the other hand, opinion words express the sentiment about an aspect, such as attentive or terrible. The separation of these two kinds of words might be useful because it eases the interpretation of the resulting topics, and the sentiment classification can be focused on the opinion-words which are more likely to bear sentiment information. Zhao et al. (2010) attempted this separation training a supervised classifier on a small manually labelled dataset and using Part-of-Speech tagging. Mukherjee and Liu (2012) elaborated on this idea trying a similar approach but substituting the manually labelled dataset with an existing lexicon of opinion words for English.", "startOffset": 8, "endOffset": 874}, {"referenceID": 7, "context": "uses Brown clusters (Brown et al., 1992) to model examples of aspect-terms and opinion-words and train a MaxEnt-based classification model.", "startOffset": 20, "endOffset": 40}, {"referenceID": 41, "context": "Brown clusters have been used as unsupervised features with good results in supervised Part-of-Speech tagging (Turian et al., 2010) and Named Entity Recognition (Agerri and Rigau, 2016).", "startOffset": 110, "endOffset": 131}, {"referenceID": 0, "context": ", 2010) and Named Entity Recognition (Agerri and Rigau, 2016).", "startOffset": 37, "endOffset": 61}, {"referenceID": 26, "context": "Such a dense vector representation of the words over a particular vocabulary, commonly referred as word embeddings, could be obtained using any distributional semantics approach, but in this work we stick to the well-known word2vec (Mikolov et al., 2013a).", "startOffset": 232, "endOffset": 255}, {"referenceID": 27, "context": "Word embeddings are a very popular way of representing words as the input for a variety of machine learning techniques and are known for encoding interesting syntactic and semantic properties (Mikolov et al., 2013b).", "startOffset": 192, "endOffset": 215}, {"referenceID": 14, "context": "The posterior inference of the model is obtained via Gibbs sampling (Griffiths and Steyvers, 2004).", "startOffset": 68, "endOffset": 98}, {"referenceID": 12, "context": "For topic classification we use the dataset from (Ganu et al., 2009) which contains restaurant reviews labelled with domain-related categories (e.", "startOffset": 49, "endOffset": 68}, {"referenceID": 18, "context": "For sentiment classification, we use the Laptops and DIGITAL-SLR dataset (Jo and Oh, 2011), consisting of English reviews of electronic products with their corresponding 5-star rating.", "startOffset": 73, "endOffset": 90}, {"referenceID": 14, "context": "3, which play a similar role to \u03b1 and \u03b2 in the original LDA, are set to the values commonly recommended in the literature (Griffiths and Steyvers, 2004): 50/T for \u03b1base and \u03b4base being T the number of topics, and 0.", "startOffset": 122, "endOffset": 152}, {"referenceID": 12, "context": "Comparison with other LDA based approaches First, we evaluate W2VLDA in a topic classification setting using the restaurant reviews dataset from (Ganu et al., 2009).", "startOffset": 145, "endOffset": 164}, {"referenceID": 44, "context": "We compare W2VLDA against the results reported in (Zhao et al., 2010) for two LDA-based approaches, LocLDA (Brody and Elhadad, 2010) and ME-LDA (Zhao et al.", "startOffset": 50, "endOffset": 69}, {"referenceID": 6, "context": ", 2010) for two LDA-based approaches, LocLDA (Brody and Elhadad, 2010) and ME-LDA (Zhao et al.", "startOffset": 45, "endOffset": 70}, {"referenceID": 44, "context": ", 2010) for two LDA-based approaches, LocLDA (Brody and Elhadad, 2010) and ME-LDA (Zhao et al., 2010).", "startOffset": 82, "endOffset": 101}, {"referenceID": 6, "context": ", 2010) for two LDA-based approaches, LocLDA (Brody and Elhadad, 2010) and ME-LDA (Zhao et al., 2010). LocLDA and ME-LDA are LDA-based approaches, and thus, unsupervised. But the results reported in the experiment involved some supervision as described in Zhao et al. (2010). First, the authors computed a topic model of 14 topics.", "startOffset": 46, "endOffset": 275}, {"referenceID": 20, "context": "We compare our polarity classification results with respect to those from JST (Lin et al., 2011), ASUM (Jo and Oh, 2011) and HASM (Kim et al.", "startOffset": 78, "endOffset": 96}, {"referenceID": 18, "context": ", 2011), ASUM (Jo and Oh, 2011) and HASM (Kim et al.", "startOffset": 14, "endOffset": 31}, {"referenceID": 19, "context": ", 2011), ASUM (Jo and Oh, 2011) and HASM (Kim et al., 2013).", "startOffset": 41, "endOffset": 59}, {"referenceID": 19, "context": "As explained at (Kim et al., 2013) two datasets are used, a small dataset containing 1000 reviews with 1 star rating (strong negative) and 1000 5 stars (strong positive), and a large dataset with additional 1000 reviews of 2 stars (negative) as well as 1000 reviews of 4 stars (positive).", "startOffset": 16, "endOffset": 34}, {"referenceID": 42, "context": "The baseline consists of a simple polarity seed word count, using the polarity seed words from (Turney and Littman, 2003), assigning to the sentence the polarity with the greatest proportion.", "startOffset": 95, "endOffset": 121}, {"referenceID": 15, "context": "In order to evaluate the accuracy of this words separation, we use Bing Liu\u2019s polarity lexicon for English (Hu and Liu, 2004).", "startOffset": 107, "endOffset": 125}, {"referenceID": 39, "context": "On the other hand, the are more specialised word embeddings related to sentiment analysis (Rothe et al., 2016), and it would be interesting to study if different word embeddings bring improvements to the method keeping a minimal supervision.", "startOffset": 90, "endOffset": 110}], "year": 2017, "abstractText": "With the increase of online customer opinions in specialised websites and social networks, the necessity of automatic systems to help to organise and classify customer reviews by domain-specific aspect/categories and sentiment polarity is more important than ever. Supervised approaches for Aspect Based Sentiment Analysis obtain good results for the domain/language they are trained on, but having manually labelled data for training supervised systems for all domains and languages is usually very costly and time consuming. In this work we describe W2VLDA, an almost unsupervised system based on topic modelling, that combined with some other unsupervised methods and a minimal configuration, performs aspect/category classification, aspectterms/opinion-words separation and sentiment polarity classification for any given domain and language. We evaluate the performance of the aspect and sentiment classification in the multilingual SemEval 2016 task 5 (ABSA) dataset. We show competitive results for several languages (English, Spanish, French and Dutch) and domains (hotels, restaurants, electronic devices).", "creator": "LaTeX with hyperref package"}}}