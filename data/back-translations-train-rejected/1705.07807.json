{"id": "1705.07807", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2017", "title": "Use Privacy in Data-Driven Systems: Theory and Experiments with Machine Learnt Programs", "abstract": "This paper presents an approach to formalizing and enforcing a class of use privacy properties in data-driven systems. In contrast to prior work, we focus on use restrictions on proxies (i.e. strong predictors) of protected information types. Our definition relates proxy use to intermediate computations that occur in a program, and identify two essential properties that characterize this behavior: 1) its result is strongly associated with the protected information type in question, and 2) it is likely to causally affect the final output of the program. For a specific instantiation of this definition, we present a program analysis technique that detects instances of proxy use in a model, and provides a witness that identifies which parts of the corresponding program exhibit the behavior. Recognizing that not all instances of proxy use of a protected information type are inappropriate, we make use of a normative judgment oracle that makes this inappropriateness determination for a given witness. Our repair algorithm uses the witness of an inappropriate proxy use to transform the model into one that provably does not exhibit proxy use, while avoiding changes that unduly affect classification accuracy. Using a corpus of social datasets, our evaluation shows that these algorithms are able to detect proxy use instances that would be difficult to find using existing techniques, and subsequently remove them while maintaining acceptable classification performance. Authors", "histories": [["v1", "Mon, 22 May 2017 15:28:43 GMT  (3567kb,D)", "https://arxiv.org/abs/1705.07807v1", null], ["v2", "Wed, 24 May 2017 03:46:13 GMT  (3567kb,D)", "http://arxiv.org/abs/1705.07807v2", "fixed typo in abstract"], ["v3", "Thu, 7 Sep 2017 06:36:33 GMT  (3604kb,D)", "http://arxiv.org/abs/1705.07807v3", "extended CCS 2017 camera-ready: several new discussions, and complexity results added to appendix"]], "reviews": [], "SUBJECTS": "cs.CR cs.LG", "authors": ["anupam datta", "matthew fredrikson", "gihyuk ko", "piotr mardziel", "shayak sen"], "accepted": false, "id": "1705.07807"}, "pdf": {"name": "1705.07807.pdf", "metadata": {"source": "META", "title": "Use Privacy in Data-Driven Systems", "authors": ["Anupam Datta", "Matt Fredrikson", "Gihyuk Ko", "Piotr Mardziel", "Shayak Sen"], "emails": ["permissions@acm.org."], "sections": [{"heading": null, "text": "CCS CONCEPTS \u2022 Security and Privacy \u2192 Privacy Protection; KEYWORDS Use Privacy"}, {"heading": "1 INTRODUCTION", "text": "In fact, we are able to move in a world in which we are in a world, in which we are in a world, in which we are in a world, in which we are in a world, in which we are in a world, in which we are in a world, in which we are in a world, in which we are in a world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are one world, in which we are in which we are one world, in which we are in which we are one world, in which we are in which we are one world, in which we are in which we are in which we are in which we are one world, in which we are in which we are in which we are in which we are in which we are one world, in which we are in which we are in which we are in which are in which we are one world, in which we are in which we are in which are in which we are one world, in which we are in which we are in which are in which we are in which are one world, in which we are in which are in which are in which are in which we are in which we are in which we are in which we are one world, in which we are in which are in which we are in which are in which we are in which we are in which we are in which we are in which we are one world, in which we are in which are in which we are in which we are in which we are in which are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which are in which we are in which are in"}, {"heading": "2 USE PRIVACY", "text": "We use the Target example described earlier in the paper to motivate our idea of the use of privacy. Historically, data collected in the context of the interaction between a retailer and a consumer cannot automatically lead to a flow of health information. In particular, prohibited information types (e.g. pregnancy status) can be derived from legitimate flows (e.g. purchase history). Thus, the privacy usage theory ensures that the data processing systems \"ignorance\" of protected information types (e.g. pregnancy status) and their proxies (e.g. purchase history) instead ensure that the use of protected information types is \"simulated\" by using data in legitimate flows (e.g. the use of privacy)."}, {"heading": "3 PROXY USE: A FORMAL DEFINITION", "text": "We now present an axiomatic formal definition of proxy usage in data-driven programs. Our definition of proxy usage of a protected type of information includes the decomposition of a program to find an interim calculation, the result of which has two properties: \u2022 Proxy: strong association with the protected type \u2022 Use: causal influence on the output of the programIn \u00a7 3.1, we present a sequence of examples to illustrate the challenge of identifying proxy usage in systems that work with data associated with a protected type of information. We will also compare our work with closely related work related to privacy and fairness. In \u00a7 3.2, we formalize the terms proxy and usage, as a precaution for definition. The definition itself is presented in \u00a7 3.3 and \u00a7 3.4. Finally, in \u00a7 3.5, we offer an axiomatic characterization of the concept of proxy usage that guides our definition decisions. We note that readers may be interested in detection and loss of continuity."}, {"heading": "3.1 Examples of Proxy Use", "text": "Prior to working on the detection of protected information types [15, 30, 44, 63] and the use of knowledge on the detection of pregnancies to eliminate inappropriate uses [30], the system was treated as a black box. Therefore, the detection was based either on experimental access to the black box [15, 44] or on observational data on its behavior [30, 63]. Using a number of examples motivated by the Target case, we motivate the need to look into the black box to detect the proxy benefit. Example 3.1. (Explicit application, Fig. 1a) A retailer explicitly uses the pregnancy status from prescription data to market baby products. This form of explicit use of a protected information type may, through existing black box experimental methods, cause an effect between inputs and outputs (e.g. Fig. 1a) A retailer's status to use these information types of explicit from available pharmacy images."}, {"heading": "3.2 Notation and Preliminaries", "text": "It is a question of whether and in what form people in the USA and in other parts of the world will still be able to recognise their identity and identity. (...) It is a question of whether and in what form they will be able to recognise their identity and identity. (...) It is a question of whether they are able to recognise their identity and identity. (...) It is a question of whether they are able to recognise their identity and identity. (...) It is a question of whether they are able to recognise their identity and identity. (...) It is a question of whether they are able to recognise their identity and identity. (...) It is a question of whether they are able to recognise their identity and whether they are able to recognise their identity. (...) It is a question of whether they are able to recognise themselves and whether they are able to recognise their identity and whether they are able to recognise their identity. (...)"}, {"heading": "3.3 Definition", "text": "In fact, it is so that it is pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-pseudo-p"}, {"heading": "3.4 A Quantitative Relaxation", "text": "Definition 6 is too strong in one sense and too weak in another. It requires that intermediate calculations must be perfectly correlated with a protected attribute, and that there is some input - though unlikely - in which the result of the intermediate calculation is relevant to the model. For practical purposes, we would like to quantify these two terms to provide a parameterized definition. Recognizing that neither perfect privacy nor perfect utility is practicable, quantitative definition provides a means of controlling privacy vs. commodity trading. We would like to measure how strong a random variable X is a proxy for a random variable Z. Recognizing the two key requirements of the earlier definition of a proxy: (i) association must capture equivalence and measure association in both directions."}, {"heading": "X and Z , the strength of a proxy is given by normalized mutual", "text": "This definition, however, is too strong, as it only requires a pair of values that can be changed. (X, Z) This definition is strict (X, Z) H (X, Z), where X is defined to be a \"proxy\" for Z, if d (X, Z), since we rely on precalculations to reduce the amortized runtime of the entire detection algorithm. Complexity as part of our detection algorithm is discussed in Appendix E.2.\u03b4-influential decomposition, since for a decomposition (p1, X, p2) we reduce the amortized runtime of the entire detection algorithm, influence is interference, which implies that it is x, x2, so that Jp2K (x, x1), Jp2K (x, x2) that we change the definition of Jp1, x2 are values ofp1 that for a givenx, the result of p2."}, {"heading": "3.5 Axiomatic Basis for Definition", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "4 DETECTING PROXY USE", "text": "In this section, we present an algorithm for identifying the proxy use of specified variables in a given machine learning model (Algorithm 1, Appendix B provides a more formal representation of the algorithm for the interested reader).The algorithm is program-oriented and directly follows the definition of proxy use in the previous section. We prove that the algorithm is complete in a strong sense - it identifies every instance of proxy use in the program (Theorem 3).We also describe three optimizations that accelerate the detection algorithm: Sample, Accessibility Analysis, and Contingency Tables."}, {"heading": "4.1 Environment Model", "text": "In fact, it is as if most people who are able to survive themselves, to survive themselves and to survive themselves, are not able to survive themselves. (...) In fact, it is as if they are able to survive themselves. (...) It is not as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is not as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves."}, {"heading": "4.2 Analyzing Proxy Use", "text": "In practice, this will almost always consist of an empirical sample, but for the sake of presentation, we explicitly simplify the distribution here. In Section E.2, we describe how the algorithm can produce estimates of empirical samplers; the algorithm proceeds by enumerating sub-expressions of the given program; for each sub-expression that appears in inp, ProxyDetect calculates the number of positions at which e appears; if e occurs several times, we consider all possible subsets of events as potential expressions 1. It then iterates over all combinations of these positions, creating a decomposition for each."}, {"heading": "5 REMOVING PROXY USE VIOLATIONS", "text": "In this section, we present a repair algorithm for eliminating violations of the model. Our approach consists of two parts: First, (algorithm 2) is the iterative discovery of proxy applications using the ProxyDetect method described in the previous section, and second, (algorithm 3) is the repair of violations found by the oracle. We describe these algorithms informally here, and Appendix C contains formal descriptions of these algorithms. The iterative detection method guarantees that the returned program is free of violations (algorithm 5). Our repair procedures operate on the pronunciation so that they can be applied to any model that can be written in the language. Furthermore, our violation algorithms do not require knowledge of the training algorithms that produced the model. Witnesses to the proxy use locate where violations occur in the program."}, {"heading": "6 EVALUATION", "text": "In this section, we evaluate empirically our definition and algorithms on multiple real data sets. In particular, we simulate a financial services application and demonstrate a typical workflow for a practitioner who uses our tools to detect and repair proxy use in decision trees and linear models (\u00a7 6.1). We emphasize that this workflow identifies more proxy applications via a basic process that simply removes functions associated with a protected information type. For three other simulated settings of real data sets - contraception advertising, student aid and credit advertising - we describe our results of interesting proxy applications and show how the results of our detection tool would allow to determine the appropriateness of proxy applications (\u00a7 6.2). In \u00a7 6.3, we evaluate the performance of our detection and repair algorithms and show that the runtime of our system scales is linear in the size of the model."}, {"heading": "6.1 Example Workflow", "text": "A financial services company would like to broaden its client base by identifying potential high-income clients. To do so, the company hires an analyst to create a forecasting model that uses age, profession, educational level and other socio-economic characteristics to predict whether a person currently has a \"high\" or \"low\" income. However, this practice is consistent with the use of analytics in the financial industry that take advantage of the fact that high-income individuals are more likely to buy financial products [70].Since demographic data is known to correlate to marital status [50], the data processor wants to ensure that the model used for income projections does not effectively derive the family status of individuals from other demographic variables that are explicitly used. In this context, based on deciding which clients might pursue out-of-marriage status, it is perceived as a violation of privacy as other socio-economic variables directly related to the interest and justification of different financial services we evaluate in this financial service scenario."}, {"heading": "6.2 Other Case Studies", "text": "We will now briefly discuss interesting examples of the use of proxy cards from other case studies showing how our framework supports the normative use of privacy judgments. Further details on these data sets and experiments can be found in Appendix D.1. Targeted advertising for contraceptives We are considering a scenario in which a data processor would like to show targeted advertising for contraceptives to women. We evaluated this scenario using data collected for the 1987 National Indonesia Study. Contraceptive Survey [1], which includes a number of socio-economic characteristics, including characteristics indicating whether the religious beliefs of the individual were Islam. A decision tree trained on this data collection illustrates an interesting case of potential use of privacy by the following proxy models for religion: ite (educ < 4; nchild \u2264 3 years < no, yes). This term predicts that women younger than 31 are associated with potential use of privacy by the following proxy models for religion: ite (educ < 4; nchild \u2264 3 years < no, yes). \"This term predicts that proxy models alone will not be associated with religion; < < < < < < n = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "6.3 Detection and Repair", "text": "For the rest of the section, we will focus on evaluating the performance and effectiveness of detection and repair algorithms. We will begin by examining the impact of the dataset and model size on detection algorithms. Here, the algorithm has been forced to calculate the association and influence variables for each gradient (usually the association can be skipped if the association is below the threshold), making it a worse gradient. Runtime for the random forest and decision-making is determined by several optimizations."}, {"heading": "7 RELATEDWORK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.1 Definition", "text": "In the literature of computer science, privacy is considered to be the ability to protect oneself from unwanted flows of information to an adversary, but much of the machinery developed in cryptography, such as encryption, anonymous communication, private computation, and database privacy, has been motivated by such a goal. Differential privacy [25] is one of the pillars of data analysis at the individual level, where one can share some information about a number of individuals, where any information gained by an adversary is not caused by the participation of an individual. However, none of these technologies extends to the important environment of data analysis at the individual level, where one would like to hide others with any background knowledge."}, {"heading": "7.2 Detection and Repair Models", "text": "Our detection algorithm works with a white box access to the predictive model. Weaker access assumptions are required before work. Access to observation data detection techniques that operate under an explicit usage definition typically require only experimental access to the system. This access allows the analyst to control some inputs into the system and observe relevant outcomes. The stronger white box access level allows us to disassemble the model and track an intermediate composition that is a proxy. Such traceability is not granted to the weaker access approach in the previous work. So we investigate another point in the space by dispensing with the weaker access requirements in order to gain the ability to track and repair proxy usage."}, {"heading": "8 DISCUSSION", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we are able to adapt to the needs of the people we need to meet them."}, {"heading": "9 CONCLUSION", "text": "We develop a theory of the use of privacy in data-driven systems. Clearly, our approach restricts not only the direct use of protected information types, but also their proxies (i.e. strong predictors), unless exceptions are allowed that are justified by ethical considerations.We formalize the use of proxies and present a program analysis technique to detect them in a model. Unlike previous work, our analysis is white-box. The additional access level allows our detection algorithm to provide a witness who localizes the use of a portion of the algorithm. Recognizing that not all cases of proxy use of a protected information type are inappropriate, our theory of using privacy relies on a normative judgment that makes this adequacy determination for a particular witness. If the use of proxy is deemed inappropriate, our repair algorithm uses the witness to transform that model into a sample that does not exhibit sample use."}, {"heading": "A PROOF OF THEOREM 1", "text": "Theorem 1. No definition of the use of powers of attorney can fulfill properties 1-4 at the same time. Proof by contradiction. Suppose that a definition of the use of powers of attorney fulfills all four properties. Let X, Y and Z be uniform random binary variables, so that Pr (Y = X-Z) = 1, but X, Y and Z are independent in pairs. By (explicit use of powers of attorney) the model (Y, Z) = Y Z has the use of Z. By (dummy) the model (Y, Z, X) = Y Z has the use of powers of attorney. Select f (x, z) = x-z has the use of powers of attorney. According to our previous assumption, Pr (Y = f (X, Z) = 1. Therefore, by (preprocessing) the model of its independence (Z, X) is the use of powers of attorney."}, {"heading": "B ALGORITHM FOR DETECTION", "text": "In this section we provide technical details about detection algorithms that have been excluded from the main part of the work. In particular, we define the decomposition used in the implementation, how machine learning models are translated into the term language, and how associative tests produce fake results due to sampling.B.1 Decomposition Before presenting the formal algorithm for detection, we must develop the notation for the exact designation of decompositions. Of course, decomposition follows from the subterm relationship to expressions. However, identical subterms can occur multiple times in an expression, care must be taken during substitution to distinguish between events. Therefore, we define the substitution positively where the subterm of the expression e = op. (e1, en) atAlgorithm 4 Detection for expression programs. Require: Association (d), Influence (ProxyDetect) Proxyct Process (X, P.)"}, {"heading": "C ALGORITHMS FOR REPAIR", "text": "We now provide a formal description of the repair algorithms informally described in the thesis. Algorithms 5 and 6 correspond to 2 and 3 respectively. C1 Optimal constant selection Since constant terms cannot be examples of the use of (long, long, long) proxies, there is freedom in their selection as substitutes for implicit subprograms. In algorithm 6, we select the replacement that optimizes a certain measure of the utility of the patched program. If the given program is constructed as a classifier, we define its usefulness as the prediction accuracy of the patched program on the dataset using 0-1 loss. Similarly, if the program were a regression model, v would correspond to the quadratic error."}, {"heading": "D OTHER EXPERIMENTS D.1 Details of Case Studies", "text": "The idea behind it is not new, but the idea behind it is not new: it is about how to get people to recognise their identity and identity, and how to get people to question their identity and identity, it is about how to get people to question their identity and identity, it is about how to get people to question their identity and identity, it is about how to get people to question their identity and identity, it is about how to get people to question their identity and identity, it is about how to get people to question their identity and identity, it is about how to get people to question their identity and identity."}, {"heading": "E COMPLEXITY", "text": "This year, it is only a matter of time before an agreement is reached."}], "references": [{"title": "Adscape: Harvesting and Analyzing Online Display Ads", "author": ["Paul Barford", "Igor Canadi", "Darja Krushevskaja", "Qiang Ma", "S. Muthukrishnan"], "venue": "In Proceedings of the 23rd International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Private Empirical Risk Minimization: Efficient Algorithms and Tight Error Bounds", "author": ["Raef Bassily", "Adam Smith", "Abhradeep Thakurta"], "venue": "In 55th IEEE Annual Symposium on Foundations of Computer Science,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Forecasts of Violence to Inform Sentencing Decisions", "author": ["Richard Berk", "Justin Bleich"], "venue": "Journal of Quantitative Criminology 30,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Forecasting Domestic Violence: A Machine Learning Approach to Help Inform Arraignment Decisions", "author": ["Richard A. Berk", "Susan B. Sorenson", "Geoffrey Barnes"], "venue": "Journal of Empirical Legal Studies 13,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Three naive Bayes approaches for discrimination-free classification", "author": ["Toon Calders", "Sicco Verwer"], "venue": "Data Mining and Knowledge Discovery 21,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Differentially Private Empirical Risk Minimization", "author": ["Kamalika Chaudhuri", "Claire Monteleoni", "Anand D. Sarwate"], "venue": "Journal of Machine Learning Research", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "A Decision Theoretic Approach to Targeted Advertising", "author": ["David Maxwell Chickering", "David Heckerman"], "venue": "In Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2000}, {"title": "Using data mining to predict secondary school student performance", "author": ["Paulo Cortez", "Alice Maria Goncalves Silva"], "venue": "Technical Report, Department of Computer Science,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Elements of information theory", "author": ["Thomas M Cover", "Joy A Thomas"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Use Privacy in Data-Driven Systems: Theory and Experiments with Machine Learnt Programs", "author": ["Anupam Datta", "Matthew Fredrikson", "Gihyuk Ko", "Piotr Mardziel", "Shayak Sen"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2017}, {"title": "Algorithmic Transparency via Quantitative Input Influence: Theory and Experiments with Learning Systems", "author": ["Anupam Datta", "Shayak Sen", "Yair Zick"], "venue": "In Proceedings of IEEE Symposium on Security & Privacy", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Automated Experiments on Ad Privacy Settings: A Tale of Opacity, Choice, and Discrimination", "author": ["A. Datta", "M.C. Tschantz"], "venue": "In Proceedings on Privacy Enhancing Technologies (PoPETs", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Automated Experiments on Ad Privacy Settings: A Tale of Opacity, Choice, and Discrimination", "author": ["Amit Datta", "Michael Carl Tschantz", "Anupam Datta"], "venue": "In Proceedings on Privacy Enhancing Technologies (PoPETs). De Gruyter Open", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "FTC\u2019s Julie Brill Tells Ad Tech Companies To Improve Privacy Protections", "author": ["Wendy Davis"], "venue": "http://www.mediapost.com/publications/article/ 259210/ftcs-julie-brill-tells-ad-tech-companies-to-impro.html Accessed Nov", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "The Scoring of America: How Secret Consumer Scores Threaten Your Privacy and Your Future", "author": ["Pam Dixon", "Robert Gellman"], "venue": "http://www.worldprivacyforum.org/wp-content/uploads/2014/04/WPF-", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "How Companies Learn Your Secrets", "author": ["Charles Duhigg"], "venue": "http:// www.nytimes.com/2012/02/19/magazine/shopping-habits.html (Accessed Aug", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Estimation of the Medians for Dependent Variables", "author": ["Olive Jean Dunn"], "venue": "The Annals of Mathematical Statistics 30,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1959}, {"title": "Differential Privacy. In Automata, Languages and Programming, 33rd International Colloquium, ICALP 2006, Venice, Italy", "author": ["Cynthia Dwork"], "venue": "July 10-14,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "Fairness Through Awareness", "author": ["Cynthia Dwork", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Richard Zemel"], "venue": "In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference (ITCS \u201912)", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "Fairness Through Awareness", "author": ["C. Dwork", "M. Hardt", "T. Pitassi", "O. Reingold", "R. Zemel"], "venue": "In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference (ITCS", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Calibrating Noise to Sensitivity in Private Data Analysis", "author": ["Cynthia Dwork", "Frank Mcsherry", "Kobbi Nissim", "Adam Smith"], "venue": "In Theory of Cryptography", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2006}, {"title": "Calibrating Noise to Sensitivity in Private Data Analysis", "author": ["Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith"], "venue": "In TCC", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2006}, {"title": "Web Privacy Measurement: Scientific principles, engineering platform, and new results. Manuscript posted at http: //randomwalker.info/publications/WebPrivacyMeasurement.pdf", "author": ["Steven Englehardt", "Christian Eubank", "Peter Zimmerman", "Dillon Reisman", "Arvind Narayanan"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "Certifying and Removing Disparate Impact", "author": ["Michael Feldman", "Sorelle A. Friedler", "John Moeller", "Carlos Scheidegger", "Suresh Venkatasubramanian"], "venue": "In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD \u201915)", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}, {"title": "Certifying and Removing Disparate Impact", "author": ["Michael Feldman", "Sorelle A. Friedler", "John Moeller", "Carlos Scheidegger", "Suresh Venkatasubramanian"], "venue": "In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "How Big Data is helping students graduate on time", "author": ["Nicole Freeling"], "venue": "https://www.universityofcalifornia.edu/news/how-big-data-helpingstudents-graduate-time (Accessed Nov", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2016}, {"title": "Predictive Modeling Applications in Actuarial Science", "author": ["Edward W. Frees", "Richard A. Derrig", "Glenn Meyers"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2014}, {"title": "Policy auditing over incomplete logs: theory, implementation and applications", "author": ["Deepak Garg", "Limin Jia", "Anupam Datta"], "venue": "In Proceedings of the ACM Conference on Computer and Communications Security (CCS)", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2011}, {"title": "A Comparative Analysis of Decision Trees Vis-a-vis Other Computational Data Mining Techniques in Automotive Insurance Fraud Detection", "author": ["Adrian Gepp", "J. Holton Wilson", "Kuldeep Kumar", "Sukanto Bhattacharya"], "venue": "Journal of Data Science 10,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "Challenges in Measuring Online Advertising Systems", "author": ["Saikat Guha", "Bin Cheng", "Paul Francis"], "venue": "In Proceedings of the 10th ACM SIGCOMM Conference on Internet Measurement (IMC \u201910)", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2010}, {"title": "Measuring Personalization of Web Search", "author": ["Aniko Hannak", "Piotr Sapiezynski", "Arash Molavi Kakhki", "Balachander Krishnamurthy", "David Lazer", "Alan Mislove", "Christo Wilson"], "venue": "In Proceedings of the 22nd International Conference on World Wide Web (WWW \u201913)", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2013}, {"title": "Measuring Price Discrimination and Steering on E-commerce Web Sites", "author": ["Aniko Hannak", "Gary Soeller", "David Lazer", "Alan Mislove", "Christo Wilson"], "venue": "In Proceedings of the 2014 Conference on Internet Measurement Conference (IMC \u201914)", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2014}, {"title": "Manual For the Revised Psychopathy Checklist", "author": ["Robert Hare"], "venue": "Multi-Health Systems", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2003}, {"title": "The Future of Big Data and Analytics in K-12 Education", "author": ["Benjamin Harold"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2016}, {"title": "Every Step You Fake: A Comparative Analysis of Fitness Tracker", "author": ["Andrew Hilts", "Christopher Parsons", "Jeffrey Knockel"], "venue": "Privacy and Security", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2016}, {"title": "Fairness-aware learning through regularization approach", "author": ["Toshihiro Kamishima", "Shotaro Akaho", "Jun Sakuma"], "venue": "In Proceedings of the Workshop on Privacy Aspects of Data Mining", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2011}, {"title": "XRay: Enhancing the Web\u2019s Transparency with Differential Correlation", "author": ["Mathias L\u00e9cuyer", "Guillaume Ducoffe", "Francis Lan", "Andrei Papancea", "Theofilos Petsios", "Riley Spahn", "Augustin Chaintreau", "Roxana Geambasu"], "venue": "In Proceedings of the 23rd USENIX Conference on Security Symposium (SEC\u201914)", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2014}, {"title": "Sunlight: Fine-grained Targeting Detection at Scale with Statistical Confidence", "author": ["Mathias Lecuyer", "Riley Spahn", "Yannis Spiliopolous", "Augustin Chaintreau", "Roxana Geambasu", "Daniel Hsu"], "venue": "In Proceedings of the 22Nd ACM SIGSAC Conference on Computer and Communications Security (CCS \u201915)", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2015}, {"title": "Interpretable classifiers using rules and Bayesian analysis: Building a better  stroke prediction model", "author": ["Benjamin Letham", "Cynthia Rudin", "Tyler H. McCormick", "David Madigan"], "venue": "Ann. Appl. Stat. 9,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2015}, {"title": "Making Public Information Secret", "author": ["Richard J. Lipton", "Kenneth W. Regan"], "venue": "https://rjlipton.wordpress.com/2016/05/20/making-public-informationsecret/ Accessed Aug", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2016}, {"title": "Dependence Makes You Vulnerable: Differential Privacy Under Dependent Tuples", "author": ["Changchang Liu", "Supriyo Chakraborty", "Prateek Mittal"], "venue": "In Network and Distributed System Security Symposium (NDSS). The Internet Society", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2016}, {"title": "k-NN As an Implementation of Situation Testing for Discrimination Discovery and Prevention", "author": ["Binh Thanh Luong", "Salvatore Ruggieri", "Franco Turini"], "venue": "In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2011}, {"title": "The Dark Side of Wearables", "author": ["Teena Maddox"], "venue": "http: //www.techrepublic.com/article/the-dark-side-of-wearables-how-theyresecretly-jeopardizing-your-security-and-privacy/ Accessed Nov", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2016}, {"title": "An Analysis of Us Household Socioeconomic Profiles Based on Marital Status and Gender", "author": ["Sumaria Mohan-Neill", "Indira Neill Hoch", "Meng li"], "venue": "Journal of Economics and Economic Education Research", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2014}, {"title": "Privacy in Context: Technology, Policy, and the Integrity of Social Life", "author": ["Helen Nissenbaum"], "venue": null, "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2009}, {"title": "A Value for n-Person Games. In Quantified: Biosensing Technologies in Everyday Life", "author": ["Helen Nissenbaum", "Heather Patterson"], "venue": null, "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2016}, {"title": "Screening for Pancreatic Adenocarcinoma Using Signals From Web Search Logs: Feasibility Study and Results", "author": ["John Paparrizos", "Ryen W. White", "Eric Horvitz"], "venue": "Journal of Oncology Practice 12,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2016}, {"title": "The Black Box Society: The Secret Algorithms That Control Money and Information", "author": ["Frank Pasquale"], "venue": null, "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2015}, {"title": "Bootstrapping Privacy Compliance in Big Data Systems", "author": ["Shayak Sen", "Saikat Guha", "Anupam Datta", "Sriram K. Rajamani", "Janice Tsai", "Jeannette M. Wing"], "venue": "In Proceedings of the 2014 IEEE Symposium on Security and Privacy (SP \u201914)", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2014}, {"title": "Recent Developments in Quantitative Information Flow (Invited Tutorial)", "author": ["Geoffrey Smith"], "venue": "In Proceedings of the 2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science (LICS) (LICS \u201915)", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2015}, {"title": "How do search engines respond when you Google \u2018suicide\u2019", "author": ["S.E. Smith"], "venue": "https://www.dailydot.com/via/germanwings-suicide-hotline/ Accessed May", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2015}, {"title": "A Taxonomy of Privacy", "author": ["Daniel J. Solove"], "venue": "University of Pennsylvania Law Review 154,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2006}, {"title": "Privacy Policy Guidance Memorandum: The Fair Information Practice Principles: Framework for Privacy Policy at the Department of Homeland Security. Memorandum Number: 2008-01", "author": ["Hugo Teufel III"], "venue": null, "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2008}, {"title": "Discovering Unwarranted Associations in Data-Driven Applications with the FairTest Testing Toolkit", "author": ["Florian Tram\u00e8r", "Vaggelis Atlidakis", "Roxana Geambasu", "Daniel J. Hsu", "Jean-Pierre Hubaux", "Mathias Humbert", "Ari Juels", "Huang Lin"], "venue": null, "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2015}, {"title": "Formalizing and Enforcing Purpose Restrictions in Privacy Policies", "author": ["Michael Carl Tschantz", "Anupam Datta", "Jeannette M. Wing"], "venue": "In Proceedings of the 2012 IEEE Symposium on Security and Privacy", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2012}, {"title": "Formalizing and Enforcing Purpose Restrictions in Privacy Policies", "author": ["Michael Carl Tschantz", "Anupam Datta", "Jeannette M. Wing"], "venue": "In IEEE Symposium on Security and Privacy, SP 2012,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2012}, {"title": "The Daily You: How the New Advertising Industry Is Defining Your Identity and Your Worth", "author": ["Joseph Turow"], "venue": null, "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2011}, {"title": "The Aisles Have Eyes: How Retailers Track Your Shopping, Strip Your Privacy, and Define", "author": ["J. Turow"], "venue": null, "citeRegEx": "67", "shortCiteRegEx": "67", "year": 2017}, {"title": "Crying wolf? On the price discrimination of online airline tickets", "author": ["Thomas Vissers", "Nick Nikiforakis", "Nataliia Bielova", "Wouter Joosen"], "venue": "In 7th Workshop on Hot Topics in Privacy Enhancing Technologies (HotPETs", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 2014}, {"title": "Business Intelligence and Predictive Analytics for Financial Services: The Untapped Potential of Soft Information. In Digits: Center for Digital Innovation, Technology, and Strategy \u201cResearch in Practice", "author": ["Siva Viswanathan"], "venue": "Paper Series. Robert H. Smith School of Business, University of Maryland", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 2010}, {"title": "Understanding what they do with what they know", "author": ["Craig E. Wills", "Can Tatar"], "venue": "In Proceedings of the 2012 ACMWorkshop on Privacy in the Electronic Society", "citeRegEx": "71", "shortCiteRegEx": "71", "year": 2012}], "referenceMentions": [{"referenceID": 51, "context": "Restrictions on information use occupy a central place in privacy regulations and legal frameworks [28, 54, 61, 62].", "startOffset": 99, "endOffset": 115}, {"referenceID": 52, "context": "Restrictions on information use occupy a central place in privacy regulations and legal frameworks [28, 54, 61, 62].", "startOffset": 99, "endOffset": 115}, {"referenceID": 12, "context": "3134097 information use can lead to violations of both privacy laws [68] and user expectations [16, 19], prompting calls for technology to assist with enforcement of use privacy requirements [53].", "startOffset": 95, "endOffset": 103}, {"referenceID": 15, "context": "3134097 information use can lead to violations of both privacy laws [68] and user expectations [16, 19], prompting calls for technology to assist with enforcement of use privacy requirements [53].", "startOffset": 95, "endOffset": 103}, {"referenceID": 47, "context": "In order to meet these regulatory imperatives and user expectations, companies dedicate resources toward compliance with privacy policies governing information use [53, 57].", "startOffset": 164, "endOffset": 172}, {"referenceID": 54, "context": "[64] for a survey).", "startOffset": 0, "endOffset": 4}, {"referenceID": 48, "context": "Such methods are beginning to see deployment in major technology companies like Microsoft [58].", "startOffset": 90, "endOffset": 94}, {"referenceID": 47, "context": "The increasing adoption of these systems in a wide range of sectors, including advertising, education, healthcare, employment, and credit, underscores the critical need to address use privacy concerns [53, 57].", "startOffset": 201, "endOffset": 209}, {"referenceID": 15, "context": "In 2012, the department store Target drew flak from privacy advocates and data subjects for using the shopping history of their customers to predict their pregnancy status and market baby items based on that information [19].", "startOffset": 220, "endOffset": 224}, {"referenceID": 12, "context": ", strong predictors) for health conditions\u2014for targeted advertising have been the basis for legal action and public concern from a privacy standpoint [16, 44, 68].", "startOffset": 150, "endOffset": 162}, {"referenceID": 37, "context": ", strong predictors) for health conditions\u2014for targeted advertising have been the basis for legal action and public concern from a privacy standpoint [16, 44, 68].", "startOffset": 150, "endOffset": 162}, {"referenceID": 34, "context": "Similar privacy concerns have been voiced about the use of personal information in the Internet of Things [40, 49, 52, 67].", "startOffset": 106, "endOffset": 122}, {"referenceID": 42, "context": "Similar privacy concerns have been voiced about the use of personal information in the Internet of Things [40, 49, 52, 67].", "startOffset": 106, "endOffset": 122}, {"referenceID": 45, "context": "Similar privacy concerns have been voiced about the use of personal information in the Internet of Things [40, 49, 52, 67].", "startOffset": 106, "endOffset": 122}, {"referenceID": 57, "context": "Similar privacy concerns have been voiced about the use of personal information in the Internet of Things [40, 49, 52, 67].", "startOffset": 106, "endOffset": 122}, {"referenceID": 13, "context": "Indeed there are calls for this form of privacy constraint [17, 46, 53, 68].", "startOffset": 59, "endOffset": 75}, {"referenceID": 39, "context": "Indeed there are calls for this form of privacy constraint [17, 46, 53, 68].", "startOffset": 59, "endOffset": 75}, {"referenceID": 20, "context": "This trusted data processor setting is similar to the one assumed in differential privacy [25].", "startOffset": 90, "endOffset": 94}, {"referenceID": 17, "context": ", their pregnancy status) [21].", "startOffset": 26, "endOffset": 30}, {"referenceID": 15, "context": "Even in practice, data processors often have access to detailed profiles of individuals and can infer sensitive information about them [19, 66].", "startOffset": 135, "endOffset": 143}, {"referenceID": 56, "context": "Even in practice, data processors often have access to detailed profiles of individuals and can infer sensitive information about them [19, 66].", "startOffset": 135, "endOffset": 143}, {"referenceID": 10, "context": "Instead we use a recently introduced causal influence measure [14] to quantitatively characterize influence.", "startOffset": 62, "endOffset": 66}, {"referenceID": 49, "context": "Closely related work The emphasis on restricting use of information by a system rather than the knowledge possessed by agents distinguishes our work from a large body of work in privacy (see Smith [59] for a survey).", "startOffset": 197, "endOffset": 201}, {"referenceID": 54, "context": "[64] for a survey and Lipton and Regan [46]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "[64] for a survey and Lipton and Regan [46]).", "startOffset": 39, "endOffset": 43}, {"referenceID": 0, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [2, 16, 27, 35\u201337, 43, 44, 47, 69, 71]); some of this work also examines associational effects [43, 44].", "startOffset": 161, "endOffset": 199}, {"referenceID": 12, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [2, 16, 27, 35\u201337, 43, 44, 47, 69, 71]); some of this work also examines associational effects [43, 44].", "startOffset": 161, "endOffset": 199}, {"referenceID": 22, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [2, 16, 27, 35\u201337, 43, 44, 47, 69, 71]); some of this work also examines associational effects [43, 44].", "startOffset": 161, "endOffset": 199}, {"referenceID": 29, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [2, 16, 27, 35\u201337, 43, 44, 47, 69, 71]); some of this work also examines associational effects [43, 44].", "startOffset": 161, "endOffset": 199}, {"referenceID": 30, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [2, 16, 27, 35\u201337, 43, 44, 47, 69, 71]); some of this work also examines associational effects [43, 44].", "startOffset": 161, "endOffset": 199}, {"referenceID": 31, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [2, 16, 27, 35\u201337, 43, 44, 47, 69, 71]); some of this work also examines associational effects [43, 44].", "startOffset": 161, "endOffset": 199}, {"referenceID": 36, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [2, 16, 27, 35\u201337, 43, 44, 47, 69, 71]); some of this work also examines associational effects [43, 44].", "startOffset": 161, "endOffset": 199}, {"referenceID": 37, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [2, 16, 27, 35\u201337, 43, 44, 47, 69, 71]); some of this work also examines associational effects [43, 44].", "startOffset": 161, "endOffset": 199}, {"referenceID": 40, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [2, 16, 27, 35\u201337, 43, 44, 47, 69, 71]); some of this work also examines associational effects [43, 44].", "startOffset": 161, "endOffset": 199}, {"referenceID": 58, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [2, 16, 27, 35\u201337, 43, 44, 47, 69, 71]); some of this work also examines associational effects [43, 44].", "startOffset": 161, "endOffset": 199}, {"referenceID": 60, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [2, 16, 27, 35\u201337, 43, 44, 47, 69, 71]); some of this work also examines associational effects [43, 44].", "startOffset": 161, "endOffset": 199}, {"referenceID": 36, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [2, 16, 27, 35\u201337, 43, 44, 47, 69, 71]); some of this work also examines associational effects [43, 44].", "startOffset": 256, "endOffset": 264}, {"referenceID": 37, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [2, 16, 27, 35\u201337, 43, 44, 47, 69, 71]); some of this work also examines associational effects [43, 44].", "startOffset": 256, "endOffset": 264}, {"referenceID": 20, "context": "In a setting similar to ours of a trusted data processor, differential privacy [25] protects against a different type of privacy harm.", "startOffset": 79, "endOffset": 83}, {"referenceID": 39, "context": "Lipton and Regan\u2019s notion of \u201ceffectively private\" captures the idea that a protected feature is not explicitly used to make decisions, but does not account for proxy use [46].", "startOffset": 171, "endOffset": 175}, {"referenceID": 18, "context": "Prior work on fairness has also recognized the importance of dealing with proxies in machine learning systems [22, 29, 63].", "startOffset": 110, "endOffset": 122}, {"referenceID": 23, "context": "Prior work on fairness has also recognized the importance of dealing with proxies in machine learning systems [22, 29, 63].", "startOffset": 110, "endOffset": 122}, {"referenceID": 53, "context": "Prior work on fairness has also recognized the importance of dealing with proxies in machine learning systems [22, 29, 63].", "startOffset": 110, "endOffset": 122}, {"referenceID": 44, "context": ", see Nissenbaum [51]) cannot be enforced because of possible statistical inferences.", "startOffset": 17, "endOffset": 21}, {"referenceID": 27, "context": "This form of separation exists also in some prior work on privacy [33] and fairness [23].", "startOffset": 66, "endOffset": 70}, {"referenceID": 19, "context": "This form of separation exists also in some prior work on privacy [33] and fairness [23].", "startOffset": 84, "endOffset": 88}, {"referenceID": 11, "context": "Prior work on detecting use of protected information types [15, 30, 44, 63] and leveraging knowledge of detection to eliminate inappropriate uses [30] have treated the system as a black-box.", "startOffset": 59, "endOffset": 75}, {"referenceID": 24, "context": "Prior work on detecting use of protected information types [15, 30, 44, 63] and leveraging knowledge of detection to eliminate inappropriate uses [30] have treated the system as a black-box.", "startOffset": 59, "endOffset": 75}, {"referenceID": 37, "context": "Prior work on detecting use of protected information types [15, 30, 44, 63] and leveraging knowledge of detection to eliminate inappropriate uses [30] have treated the system as a black-box.", "startOffset": 59, "endOffset": 75}, {"referenceID": 53, "context": "Prior work on detecting use of protected information types [15, 30, 44, 63] and leveraging knowledge of detection to eliminate inappropriate uses [30] have treated the system as a black-box.", "startOffset": 59, "endOffset": 75}, {"referenceID": 24, "context": "Prior work on detecting use of protected information types [15, 30, 44, 63] and leveraging knowledge of detection to eliminate inappropriate uses [30] have treated the system as a black-box.", "startOffset": 146, "endOffset": 150}, {"referenceID": 11, "context": "Detection relied either on experimental access to the black-box [15, 44] or observational data about its behavior [30, 63].", "startOffset": 64, "endOffset": 72}, {"referenceID": 37, "context": "Detection relied either on experimental access to the black-box [15, 44] or observational data about its behavior [30, 63].", "startOffset": 64, "endOffset": 72}, {"referenceID": 24, "context": "Detection relied either on experimental access to the black-box [15, 44] or observational data about its behavior [30, 63].", "startOffset": 114, "endOffset": 122}, {"referenceID": 53, "context": "Detection relied either on experimental access to the black-box [15, 44] or observational data about its behavior [30, 63].", "startOffset": 114, "endOffset": 122}, {"referenceID": 11, "context": ", see [15, 44]).", "startOffset": 6, "endOffset": 14}, {"referenceID": 37, "context": ", see [15, 44]).", "startOffset": 6, "endOffset": 14}, {"referenceID": 24, "context": "Existing methods (see [30, 63]) can detect such associations between protected information types and outcomes in observational data.", "startOffset": 22, "endOffset": 30}, {"referenceID": 53, "context": "Existing methods (see [30, 63]) can detect such associations between protected information types and outcomes in observational data.", "startOffset": 22, "endOffset": 30}, {"referenceID": 8, "context": "The variation of information metric dvar(X ,Z ) = H (X |Z ) + H (Z |X ) [12] is one measure that satisfies these two requirements.", "startOffset": 72, "endOffset": 76}, {"referenceID": 8, "context": "Interestingly, this measure is identical to normalized mutual information [12], a standard measure that has also been used in prior work in identifying associations in outcomes of machine learning models [63].", "startOffset": 74, "endOffset": 78}, {"referenceID": 53, "context": "Interestingly, this measure is identical to normalized mutual information [12], a standard measure that has also been used in prior work in identifying associations in outcomes of machine learning models [63].", "startOffset": 204, "endOffset": 208}, {"referenceID": 10, "context": "To measure influence, we quantify interference by using Quantitative Input Influence (QII), a causal measure of input influence introduced in [14].", "startOffset": 142, "endOffset": 146}, {"referenceID": 38, "context": "Note that these model types correspond to a range of commonlyused learning algorithms such as logistic regression, support vector machines [10], CART [6], and Bayesian rule lists [45].", "startOffset": 179, "endOffset": 183}, {"referenceID": 6, "context": "Also, these models represent a significant fraction of models used in practice in predictive systems that operate on personal information, ranging from advertising [9], psychopathy [38], criminal justice [4, 5], and actuarial sciences [32, 34].", "startOffset": 164, "endOffset": 167}, {"referenceID": 32, "context": "Also, these models represent a significant fraction of models used in practice in predictive systems that operate on personal information, ranging from advertising [9], psychopathy [38], criminal justice [4, 5], and actuarial sciences [32, 34].", "startOffset": 181, "endOffset": 185}, {"referenceID": 2, "context": "Also, these models represent a significant fraction of models used in practice in predictive systems that operate on personal information, ranging from advertising [9], psychopathy [38], criminal justice [4, 5], and actuarial sciences [32, 34].", "startOffset": 204, "endOffset": 210}, {"referenceID": 3, "context": "Also, these models represent a significant fraction of models used in practice in predictive systems that operate on personal information, ranging from advertising [9], psychopathy [38], criminal justice [4, 5], and actuarial sciences [32, 34].", "startOffset": 204, "endOffset": 210}, {"referenceID": 26, "context": "Also, these models represent a significant fraction of models used in practice in predictive systems that operate on personal information, ranging from advertising [9], psychopathy [38], criminal justice [4, 5], and actuarial sciences [32, 34].", "startOffset": 235, "endOffset": 243}, {"referenceID": 28, "context": "Also, these models represent a significant fraction of models used in practice in predictive systems that operate on personal information, ranging from advertising [9], psychopathy [38], criminal justice [4, 5], and actuarial sciences [32, 34].", "startOffset": 235, "endOffset": 243}, {"referenceID": 59, "context": "This practice is in line with the use of analytics in the financial industry that exploit the fact that high-income individuals are more likely to purchase financial products [70].", "startOffset": 175, "endOffset": 179}, {"referenceID": 43, "context": "Because demographic data is known to correlate with marital status [50], the data processor would like to ensure that the trained model used to make income predictions does not effectively infer individuals\u2019 marital status from the other demographic variables that are explicitly used.", "startOffset": 67, "endOffset": 71}, {"referenceID": 25, "context": "Student assistance A current trend in education is the use of predictive analytics to identify students who are likely to benefit from certain types of interventions [31, 39].", "startOffset": 166, "endOffset": 174}, {"referenceID": 33, "context": "Student assistance A current trend in education is the use of predictive analytics to identify students who are likely to benefit from certain types of interventions [31, 39].", "startOffset": 166, "endOffset": 174}, {"referenceID": 7, "context": "To evaluate this scenario, we trained a model on the UCI Student Alcohol Consumption dataset [11], with alcohol use as the sensitive feature.", "startOffset": 93, "endOffset": 97}, {"referenceID": 14, "context": "In this context, the use of health status for targeted advertising is a legitimate privacy concern [18].", "startOffset": 99, "endOffset": 103}, {"referenceID": 20, "context": "Differential privacy [25] is one of themain pillars of privacy research in the case of computations over data aggregated from a number of individuals, where any information gained by an adversary observing the computation is not caused by an individual\u2019s participation.", "startOffset": 21, "endOffset": 25}, {"referenceID": 17, "context": "This absence is with good reason, as in the general case it is impossible to prevent flows of knowledge from individual-level data, while preserving the utility of such data, in the presence of arbitrary inferences that may leverage the background knowledge of an adversary [21].", "startOffset": 274, "endOffset": 278}, {"referenceID": 54, "context": "[64] for a survey and Lipton and Regan [46]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "[64] for a survey and Lipton and Regan [46]).", "startOffset": 39, "endOffset": 43}, {"referenceID": 12, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [16, 44]; some of this work also examines associational effects [43, 44].", "startOffset": 161, "endOffset": 169}, {"referenceID": 37, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [16, 44]; some of this work also examines associational effects [43, 44].", "startOffset": 161, "endOffset": 169}, {"referenceID": 36, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [16, 44]; some of this work also examines associational effects [43, 44].", "startOffset": 225, "endOffset": 233}, {"referenceID": 37, "context": "Recent work on discovering personal data use by black-box web services focuses mostly on explicit use of protected information types by examining causal effects [16, 44]; some of this work also examines associational effects [43, 44].", "startOffset": 225, "endOffset": 233}, {"referenceID": 24, "context": "Access to observational data Detection techniques working under an associative use definition [30, 63] usually only require access to observational data about the behavior of the system.", "startOffset": 94, "endOffset": 102}, {"referenceID": 53, "context": "Access to observational data Detection techniques working under an associative use definition [30, 63] usually only require access to observational data about the behavior of the system.", "startOffset": 94, "endOffset": 102}, {"referenceID": 12, "context": "Access to black-box experimental data Detection techniques working under an explicit use definition of information use [16, 44] typically require experimental access to the system.", "startOffset": 119, "endOffset": 127}, {"referenceID": 37, "context": "Access to black-box experimental data Detection techniques working under an explicit use definition of information use [16, 44] typically require experimental access to the system.", "startOffset": 119, "endOffset": 127}, {"referenceID": 53, "context": "[63] solve an important orthogonal problem of efficiently identifying populations where associations may appear.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "Adjusting the training dataset is the most popular approach, including variations that relabel only the class attribute [48], modify entire instances while maintaining the original schema [30], and transform the dataset into another space of features [24, 72].", "startOffset": 120, "endOffset": 124}, {"referenceID": 24, "context": "Adjusting the training dataset is the most popular approach, including variations that relabel only the class attribute [48], modify entire instances while maintaining the original schema [30], and transform the dataset into another space of features [24, 72].", "startOffset": 188, "endOffset": 192}, {"referenceID": 4, "context": "Adjustments to Naive Bayes [7] and trainers amiable to regularization [42] are examples.", "startOffset": 27, "endOffset": 30}, {"referenceID": 35, "context": "Adjustments to Naive Bayes [7] and trainers amiable to regularization [42] are examples.", "startOffset": 70, "endOffset": 74}, {"referenceID": 1, "context": "Several techniques for producing differentially-private machine learning models modify trained models by perturbing coefficients [3, 8].", "startOffset": 129, "endOffset": 135}, {"referenceID": 5, "context": "Several techniques for producing differentially-private machine learning models modify trained models by perturbing coefficients [3, 8].", "startOffset": 129, "endOffset": 135}, {"referenceID": 21, "context": "Other differentially-private data analysis techniques [26] instead perturb the output by adding symmetric noise to the true results of statistical queries.", "startOffset": 54, "endOffset": 58}, {"referenceID": 55, "context": "Though it may seem ethically ambiguous to perform a protected inference in order to (discover and) prevent protected inferences, it is consistent with the view that privacy is a function of both information and the purpose for which that information is being used [65]3.", "startOffset": 264, "endOffset": 268}, {"referenceID": 50, "context": "Further, protected information has already been used by public and private entities in pursuit of social good: affirmative action requires the inference or explicit recording of minority membership, search engines need to infer suicide tendency in order to show suicide prevention information in their search results[60], health conditions can potentially be detected early from search logs of affected individuals [56].", "startOffset": 316, "endOffset": 320}, {"referenceID": 46, "context": "Further, protected information has already been used by public and private entities in pursuit of social good: affirmative action requires the inference or explicit recording of minority membership, search engines need to infer suicide tendency in order to show suicide prevention information in their search results[60], health conditions can potentially be detected early from search logs of affected individuals [56].", "startOffset": 415, "endOffset": 419}, {"referenceID": 48, "context": "[58]) that operate under similar requirements could be augmented with our methods.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "This paper presents an approach to formalizing and enforcing a class of use privacy properties in data-driven systems. In contrast to prior work, we focus on use restrictions on proxies (i.e. strong predictors) of protected information types. Our definition relates proxy use to intermediate computations that occur in a program, and identify two essential properties that characterize this behavior: 1) its result is strongly associated with the protected information type in question, and 2) it is likely to causally affect the final output of the program. For a specific instantiation of this definition, we present a program analysis technique that detects instances of proxy use in a model, and provides a witness that identifies which parts of the corresponding program exhibit the behavior. Recognizing that not all instances of proxy use of a protected information type are inappropriate, we make use of a normative judgment oracle that makes this inappropriateness determination for a given witness. Our repair algorithm uses the witness of an inappropriate proxy use to transform the model into one that provably does not exhibit proxy use, while avoiding changes that unduly affect classification accuracy. Using a corpus of social datasets, our evaluation shows that these algorithms are able to detect proxy use instances that would be difficult to find using existing techniques, and subsequently remove them while maintaining acceptable classification performance.", "creator": "LaTeX with hyperref package"}}}