{"id": "1705.07817", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2017", "title": "Sparse hierarchical interaction learning with epigraphical projection", "abstract": "This work focus on regression optimization problem with hierarchical interactions between variables, which is beyond the additive models in the traditional linear regression. We investigate two different fashions in the literature to deal with this problem: \"hierNet\" and structural-sparsity regularization, and study their connections, then we propose a primal-dual proximal algorithm based on epigraphical projection to optimize the learning problem. The experimental setting first highlight the improvement of the proposed procedure compare to state-of-the-art methods based on FISTA or ADMM and second we provide comparisons between the different hierarchical penalization. The experiments are conducted both on the synthetic and real data.", "histories": [["v1", "Mon, 22 May 2017 15:53:22 GMT  (919kb,D)", "https://arxiv.org/abs/1705.07817v1", null], ["v2", "Thu, 3 Aug 2017 15:05:53 GMT  (612kb,D)", "http://arxiv.org/abs/1705.07817v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mingyuan jiu", "nelly pustelnik", "stefan janaqi", "meriam chebre", "philippe ricoux"], "accepted": false, "id": "1705.07817"}, "pdf": {"name": "1705.07817.pdf", "metadata": {"source": "CRF", "title": "Sparse hierarchical interaction learning with epigraphical projection", "authors": ["Mingyuan Jiu", "Nelly Pustelnik", "Stefan Janaqi", "Meriam Chebre", "Philippe Ricoux"], "emails": ["iemyjiu@zzu.edu.cn.", "nelly.pustelnik@ens-", "stefan.janaqi@mines-ales.fr."], "sections": [{"heading": null, "text": "Index terms - regression learning, hierarchical interaction, primary dual algorithm, epigraphic projectionF"}, {"heading": "1 INTRODUCTION", "text": "The interaction between the characteristics is a million possible interactions that lead to a problem that in most cases can be overcome. [1] Graphical Lasso [3] is an efficient strategy to learn the interactions in the context of regression. [4], [5], [5], [6], [6], [6], [7], [7], [8], [8], [9], [10], [10], [11], [11], [11], \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \"\", \",\", \",\" \",\", \",\" \",\", \",\" \"\", \",\", \",\" \",\" \",\", \",\", \"\" \",\", \",\" \",\", \",\", \",\", \"\", \",\", \",\", \",\", \"\" \",\", \",\", \",\", \",\", \",\""}, {"heading": "2 EPIGRAPHICAL FORMULATION", "text": "Minimizing (1) with the regularization concept defined in Eq. (4) is difficult because it involves non-smooth convex functions and symmetries. (4) In [15], the authors reformulate the problem for r = 1 in the weak hierarchical formula using a proximal algorithm. (4) This reformulation helps in the interpretation and underscores that a decrease in the shrinkage of certain major effects and an increase in the shrinkage of certain interactions. Its second advantage is to help design the ADMM algorithm. The merit of this formulation is to split the problem up as a set of convex constraints, and it allows us to deal with them by jacking their projection onto convex."}, {"heading": "3 PRIMAL-DUAL PROXIMAL ALGORITHM", "text": "Proximal algorithms are derived from two main procedures, which allow for a miniature function based on two functions. (2) Proximal algorithms are derived from two main functions, which are based on two functions. (2) Proximal algorithms are derived from two main functions, which relate to two functions. (2) Proximal algorithms are derived from two main functions. (2) Proximal algorithms are derived from two main functions. (2) Proximal algorithms are derived from two main functions. (2) Proximal algorithms are derived from two main functions. (2) Proximal algorithms are derived from two main functions."}, {"heading": "3.2 New epigraphical projection", "text": "Proposal 2. Let u = (u (i) > Formalization + > Formalization (b) 1 \u2264 i \u2264 n. The projection of b (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n)"}, {"heading": "4 EXPERIMENTS", "text": "In this section we provide the comparative results of the two \"1\" and \"\u221e\" proposed approaches with the two most obvious state-of-the-art procedures, namely \"hierNet\" [1] and Jenatton's framework [15]. Comparisons are made between two types, comparisons in terms of convergence behaviour and in terms of the implementation of estimates."}, {"heading": "4.1 Simulated data", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1.1 Dataset", "text": "The data set is generated in accordance with [5]. It is initially composed of N main characteristics and N (N \u2212 1) / 2 interactions (due to symmetry). v denotes (v, \u044b), \u0445 RN \u00b7 RN \u00b7 N the truth generated according to strict hierarchy. v denotes a sparse vector in which the non-zero values are randomly assigned to randomly selected indexs. v (i) is randomly selected from the set {\u2212 5, \u2212 4,..., \u2212 1,.,.., 5}. Due to strong hierarchical constraints, the performance of \u0432 is evaluated only in those whose main effects are not zero. The values are randomly selected from the set {\u2212 10, \u2212 8,..., \u2212 2,.,., 8, 10}. The algorithmic performance is evaluated on the basis of two simulated data sets. The first feature consists of N = 30 characteristics. The first 10 main characteristics are not > 0.0 and the interaction ratio between the individual data sets (v = 30)."}, {"heading": "4.1.2 Comparison with [15] \u2013 r =\u221e and weak hierarchy", "text": "To allow a fair comparison with the work in [15], we first examine the performance of the proposed primary dual proximal algorithm (algorithm 2) when r = \u221e and in the configuration of weak hierarchy (no symmetry limitation is taken into account, i.e. C = RN \u00b7 N): \"Weak PD-.\" The algorithmic procedure designed in [15] is based on \"FISTA\" and is called \"Weak FISTA.\" Both are compared in two respects: the convergence of the objective function (5) and the convergence of iterations (i.e. the convergence of iterations [k] \u2212 w [+ \u221e]).The comparisons are shown in Figure 2 (for Dataset30345) and in Figure 3 (for Dataset100-030)."}, {"heading": "4.1.3 Comparison with [1] \u2013 r = 1 and strong hierarchy", "text": "Similar experiments are performed for r = 1 and strong hierarchy (i.e. C = S). The proposed algorithm (algorithm 3 with r = 1) is referred to in our experiments as \"Strong-PD- '1\" and compared with \"hierNet,\" whose iterations are derived from an ADMM scheme called \"Strong-ADM-' 1.\" The comparisons between these two schemes are shown in Figure 4 (for Dataset30-345) and Figure 5 (for Dataset100-030). Both are compared in three respects: the convergence of the objective function (5), the convergence of the iterates (i.e. the convergence of the iterates (i.e. w [+ \u221e])) and the distance to set S. The developments are shown in r.t iteration number and time. It is observed that: i) \"Strong-PD- 1\" and \"Strong-MADS-1\" are always the optimum solution of the M1."}, {"heading": "4.1.4 Discussion regarding the choice of r", "text": "From the above algorithmic comparisons, we have found that the proposed method provides an exact solution for either \"1\" or \"\u221e\" (like other algorithmic strategies), but faster and with the ability to include the fortification parameters without internal iterations. Therefore, in the following experiments, we focus on comparisons between weak / strong \"1 or\" \u221e using the proposed algorithm (\"weak-PD,\" \"weak-PD,\" 1, \"strong-PD,\" \"strong-PD,\" strong-PD \"1\"). We run 20 simulations and the average performance with the associated deviations are shown in Fig. 6 for different values of the regulation parameter \u03bb. Furthermore, the performance achieved by cross-validation Table 1.i) The good behavior of the strong hierarchy constraint appears clear for both sets. In fact, we remember that the data were created with strong hierarchy structure and we can clearly state that for both sets the performance of the strong hierarchy can be linked."}, {"heading": "4.2 Application to HIV Data", "text": "In this section, we apply the proposed algorithms to the HIV data set on susceptibility of the HIV-1 virus to six nucleoside reverse transcriptase inhibitors (NRTIs). This data set is collected by [27] and is used to model HIV-1 susceptibility to drugs, as HIV-1 viruses can become resistant to different subjects through genome mutations. In the data set, there are 639 subjects and 240 genomic sites. For each observation, the mutation status is recorded at each genomic site and six (log-) susceptibility reactions are also given. In this work, we focus on the predictive model for 3TC drugs."}, {"heading": "4.2.1 Reduced dataset", "text": "Followed by [5], we first work on a reduced data set above the containers of ten adjacent locations, rather than at all 240 genomic locations, which results from the fact that nearby genomes have similar effects to drug susceptibility and also lead to less sparse data. So, for the first set of experiments, we have N = 24. The value for each container is set to 1 if one of the genomes in that container mutates. The data set is randomly divided into two half-sentences for training and testing, as assumed by [1], [5]. We report on the average performance of MSE on the test set of 5 splits under different conditions for \"weak-PD,\" \"strong-PD\" 1 \"and\" strong-PD-D \"1.\" The average performance of MSE on the test set of 5 splits of Fig's visualization can be observed to be \"strong-PD\" normal \"and\" strong-PD-D-D. \""}, {"heading": "4.2.2 Full dataset", "text": "The average performance of MSE on the test set under four situations is shown in Fig. 7 (right). It is clear that a strong hierarchy achieves better results.3 It can be downloaded from https: / / hivdb.stanford.edu / pages / published analysis / genophenoPNAS2006 / performance than weak.The learned interactions and their property effects from \"Strong-PD-\" \u221e \"and\" Strong-PD '1 \"with the best \u03bb = 1 are shown in Fig. 9. It is found that both algorithms can detect that the 184th genomic location has the strongest effect. From the maximum strength and the sum of strength for each gene in Fig. 9 we can see the different properties for both algorithms."}, {"heading": "5 CONCLUSION", "text": "In this paper, we propose a primary-dual proximal algorithm based on epigraphic projection to optimize the sparse regression learning problem when setting hierarchical constraints between the main effects and the interactions. Four algorithms are derived (\"Weak-PD- '\u221e,\" \"Weak-PD' 1,\" \"Strong-PD- '\u221e,\" \"Strong-PD-' 1\") that make it possible to treat and compare correctly different configurations of the regulatory term (4). Compared to other state-of-the-art algorithms such as FISTA or ADMM, the proposed algorithm is more computationally efficient (find a solution that belongs to S, convergence with iterates is faster)."}], "references": [{"title": "A lasso for hierarchical interactions", "author": ["J. Bien", "J. Taylor", "R. Tibshirani"], "venue": "Annals of Statistics, vol. 41, no. 3, pp. 1111\u20131141, 2013.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "BRANE Cut: Biologically-related apriori network enhancement with graph cuts for gene regulatory network inference", "author": ["A. Pirayre", "C. Couprie", "F. Bidard", "L. Duval", "J.-C. Pesquet"], "venue": "BMC Bioinformatics, vol. 16, no. 1, 2015.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Sparse inverse covariance estimation with the graphical lasso", "author": ["J. Friedman", "T. Hastie", "R. Tibshirani"], "venue": "Biostatistics, vol. 9, no. 3, pp. 432\u2013441, 2008.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "The composite absolute penalties family for groupes and hierarchical variable selection", "author": ["P. Zhao", "G. Rocha", "B. Yu"], "venue": "The Annals of Statistics, vol. 37, no. 6A, pp. 3468\u20133497, 2009.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning interactions through hierarchical group-lasso regularization", "author": ["M. Lim", "T. Hastie"], "venue": "Journal of Computational and Graphical Statistics, vol. 24, pp. 627\u2013654, 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Group regularized estimation under structural hierarchy", "author": ["Y. She", "H. Jiang"], "venue": "Journal of the American Statistical Association, 2016.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "Use of the zero-norm with linear models and kernel methods", "author": ["J. Weston", "A. Elisseeff", "B. Scholkopf", "M. Tipping"], "venue": "Journal of Machine Learning Research, vol. 3, pp. 1439\u20131461, 2003.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Regression shrinkage and selection via the lasso", "author": ["R. Tibshirani"], "venue": "Journal of the Royal Statistical Society, Series B, vol. 58, pp. 267\u2013288, 1994.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1994}, {"title": "The F\u221e-norm support vector machine", "author": ["H. Zou", "M. Yuan"], "venue": "Statistica Sinica, vol. 18, pp. 379\u2013398, 2008.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Structured sparsity through convex optimization", "author": ["F. Bach", "R. Jenatton", "J. Mairal", "G. Obozinski"], "venue": "Statistical Science, vol. 27, no. 4, pp. 450\u2013468, 11 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Optimization with sparsity-inducing penalties", "author": ["\u2014\u2014"], "venue": "Foundations and Trends in Machine Learning, vol. 4, no. 1, pp. 1\u2013106, 2012.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Quadratic logistic discrimination", "author": ["J.A. Anderson"], "venue": "Biometrika, vol. 62, pp. 149\u2013154, 1975.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1975}, {"title": "Generalized linear and quadratic discriminant functions using robust  estimates", "author": ["H.R. Ronald", "D.B. James", "S.R. John", "V.H. Robert"], "venue": "Journal of the American Statistical Association, vol. 73, pp. 564\u2013568, 1978.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1978}, {"title": "Proximal methods for hierarchical sparse coding", "author": ["R. Jenatton", "J. Mairal", "G. Obozinski", "F. Bach"], "venue": "Journal of Machine Learning Research, vol. 12, pp. 2297\u20132334, 2011.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["A. Beck", "M. Teboulle"], "venue": "SIAM Journal on Imaging Sciences, vol. 2, no. 1, pp. 183\u2013202, 2009.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Nested iterative algorithms for convex constrained image recovery problem", "author": ["C. Chaux", "J.-C. Pesquet", "N. Pustelnik"], "venue": "SIAM Journal on Imaging Sciences, vol. 2, no. 2, pp. 730\u2013762, Jun. 2009.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Convex analysis and monotone operator theory in hilbert spaces", "author": ["H. Bauschke", "P. Combettes"], "venue": "Springer, New York, 2011.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "On the convergence of the iterates of the fast iterative shrinkage/thresholding algorithm", "author": ["A. Chambolle", "C. Dossal"], "venue": "Journal of Optimization Theory and Applications, vol. 166, no. 3, pp. 968\u2013982, Sep. 2015.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Split Bregman algorithm, Douglas-Rachford splitting and frame shrinkage", "author": ["S. Setzer"], "venue": "ch. Scale Space and Variational Methods in Computer Vision. SSVM 2009. Lecture Notes in Computer Science,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "A first-order primal-dual algorithm  JOURNAL OF  LTEX CLASS FILES, VOL. XX, NO. XX, XXXX  10 for convex problems with applications to imaging", "author": ["A. Chambolle", "T. Pock"], "venue": "Journal of Mathematical Imaging and Vision, vol. 40, no. 1, pp. 120\u2013145, 2011.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Playing with duality: an overview of recent primal-dual approaches for solving large-scale optimization problems", "author": ["N. Komodakis", "J.C. Pesquet"], "venue": "IEEE Signal Processing Magazine, vol. 32, no. 6, pp. 31\u201354, Nov 2015.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "A primal-dual splitting method for convex optimization involving Lipschitzian, proximable and linear composite terms", "author": ["L. Condat"], "venue": "Journal of Optimization Theory and Applications, vol. 158, no. 2, pp. 460\u2013479, 2013.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "A splitting algorithm for dual monotone inclusions involving cocoercive operators", "author": ["B.C. V\u0169"], "venue": "Advances in Computational Mathematics, vol. 38, no. 3, pp. 667\u2013681, Apr. 2013.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Epigraphical projection and proximal tools for solving constrained convex optimization problems", "author": ["G. Chierchia", "N. Pustelnik", "J.-C. Pesquet", "B. Pesquet-Popescu"], "venue": "Signal, Image and Video Processing, vol. 9, no. 8, pp. 1737\u20131749, 2015.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Efficient projections onto the l1-ball for learning in high dimensions.", "author": ["J.C. Duchi", "S.S.-S", "Shai", "Y. Singer", "T. Chandra"], "venue": "in ICML, ser. ACM International Conference Proceeding Series,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2008}, {"title": "Genotypic predictors of human immunodeficiency virus type 1 drug resistance", "author": ["S.-Y. Rhee", "J. Taylor", "G. Wadhera", "A. B-H", "D.L. Brutlag", "R.W. Shafer"], "venue": "Proceedings of the National Academy of Sciences, vol. 103, no. 46, pp. 17 355\u201317 360, 2006.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "L EARN interactions between features is of main interest in data processing such as for genomics [1], [2].", "startOffset": 97, "endOffset": 100}, {"referenceID": 1, "context": "L EARN interactions between features is of main interest in data processing such as for genomics [1], [2].", "startOffset": 102, "endOffset": 105}, {"referenceID": 2, "context": "Graphical Lasso [3] is an efficient strategy to obtain a graph of interactions from the inverse covariance matrix but its limitation is to not being adapted for a specific task such as regression, which is the core of this contribution.", "startOffset": 16, "endOffset": 19}, {"referenceID": 0, "context": "Several work have been dedicated to this subject in a recent literature [1], [4], [5], [6], [7].", "startOffset": 72, "endOffset": 75}, {"referenceID": 3, "context": "Several work have been dedicated to this subject in a recent literature [1], [4], [5], [6], [7].", "startOffset": 77, "endOffset": 80}, {"referenceID": 4, "context": "Several work have been dedicated to this subject in a recent literature [1], [4], [5], [6], [7].", "startOffset": 87, "endOffset": 90}, {"referenceID": 5, "context": "Several work have been dedicated to this subject in a recent literature [1], [4], [5], [6], [7].", "startOffset": 92, "endOffset": 95}, {"referenceID": 6, "context": "Various sparsity regularizations have been proposed and extensively studied in the additive model, for instance, involving `0-pseudo-norm [8], `1-norm [9], `\u221enorm [10], or structural sparsity norm [11].", "startOffset": 138, "endOffset": 141}, {"referenceID": 7, "context": "Various sparsity regularizations have been proposed and extensively studied in the additive model, for instance, involving `0-pseudo-norm [8], `1-norm [9], `\u221enorm [10], or structural sparsity norm [11].", "startOffset": 151, "endOffset": 154}, {"referenceID": 8, "context": "Various sparsity regularizations have been proposed and extensively studied in the additive model, for instance, involving `0-pseudo-norm [8], `1-norm [9], `\u221enorm [10], or structural sparsity norm [11].", "startOffset": 163, "endOffset": 167}, {"referenceID": 9, "context": "Various sparsity regularizations have been proposed and extensively studied in the additive model, for instance, involving `0-pseudo-norm [8], `1-norm [9], `\u221enorm [10], or structural sparsity norm [11].", "startOffset": 197, "endOffset": 201}, {"referenceID": 10, "context": "See [12] for an", "startOffset": 4, "endOffset": 8}, {"referenceID": 11, "context": "The idea to integrate quadratic interactions in the learning problem including discrimination task is not new, for example, discriminant quadratic learning [13], [14] learns the covariance matrix in the quadratic term to improve the discrimination ability.", "startOffset": 156, "endOffset": 160}, {"referenceID": 12, "context": "The idea to integrate quadratic interactions in the learning problem including discrimination task is not new, for example, discriminant quadratic learning [13], [14] learns the covariance matrix in the quadratic term to improve the discrimination ability.", "startOffset": 162, "endOffset": 166}, {"referenceID": 3, "context": "[4] and the following works [1], [5], [6], [7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[4] and the following works [1], [5], [6], [7].", "startOffset": 28, "endOffset": 31}, {"referenceID": 4, "context": "[4] and the following works [1], [5], [6], [7].", "startOffset": 38, "endOffset": 41}, {"referenceID": 5, "context": "[4] and the following works [1], [5], [6], [7].", "startOffset": 43, "endOffset": 46}, {"referenceID": 0, "context": "Two types of hierarchy constraints have been defined in \u201chierNet\u201d [1]: (i) weak hierarchy where the interactions happen (i.", "startOffset": 66, "endOffset": 69}, {"referenceID": 5, "context": "In [7], a more general framework is derived taking the form", "startOffset": 3, "endOffset": 6}, {"referenceID": 13, "context": "\u2022 [15] : z(\u00b7) = (\u00b7)>, q = {2,+\u221e}, \u2022 [1], [5] : z(\u00b7) = \u2016 \u00b7 \u20161 and q = +\u221e, \u2022 [7] : z(\u00b7) = (\u00b7)> and q = {2}.", "startOffset": 2, "endOffset": 6}, {"referenceID": 0, "context": "\u2022 [15] : z(\u00b7) = (\u00b7)>, q = {2,+\u221e}, \u2022 [1], [5] : z(\u00b7) = \u2016 \u00b7 \u20161 and q = +\u221e, \u2022 [7] : z(\u00b7) = (\u00b7)> and q = {2}.", "startOffset": 36, "endOffset": 39}, {"referenceID": 5, "context": "\u2022 [15] : z(\u00b7) = (\u00b7)>, q = {2,+\u221e}, \u2022 [1], [5] : z(\u00b7) = \u2016 \u00b7 \u20161 and q = +\u221e, \u2022 [7] : z(\u00b7) = (\u00b7)> and q = {2}.", "startOffset": 75, "endOffset": 78}, {"referenceID": 13, "context": "Note that [15] focus on weak hierarchy using C = RN\u00d7N .", "startOffset": 10, "endOffset": 14}, {"referenceID": 0, "context": "[1] is encountered under the name \u201chierNet\u201d, while [5] is named \u201cFAMILY\u201d and [7] is \u201cType-A GRESH\u201d.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[1] is encountered under the name \u201chierNet\u201d, while [5] is named \u201cFAMILY\u201d and [7] is \u201cType-A GRESH\u201d.", "startOffset": 77, "endOffset": 80}, {"referenceID": 0, "context": "The latent overlapping group lasso formulation of [1] is known as \u201cglinternet\u201d [6].", "startOffset": 50, "endOffset": 53}, {"referenceID": 4, "context": "The latent overlapping group lasso formulation of [1] is known as \u201cglinternet\u201d [6].", "startOffset": 79, "endOffset": 82}, {"referenceID": 13, "context": "In [15] and [7], the iterations are derived from FISTA [16].", "startOffset": 3, "endOffset": 7}, {"referenceID": 5, "context": "In [15] and [7], the iterations are derived from FISTA [16].", "startOffset": 12, "endOffset": 15}, {"referenceID": 14, "context": "In [15] and [7], the iterations are derived from FISTA [16].", "startOffset": 55, "endOffset": 59}, {"referenceID": 15, "context": "This procedure appears to be very efficient when C = RN\u00d7N while for C = S it requires inner iterations based on Dykstra algorithm that slower significantly the convergence [17].", "startOffset": 172, "endOffset": 176}, {"referenceID": 0, "context": "On the other hand, [1] and [5] resort to ADMM to deal with C = S.", "startOffset": 19, "endOffset": 22}, {"referenceID": 0, "context": "2 Following arguments provided in [1], Section 2 derives an equivalent writing of (4) using epigraphical formulation and recall the relationship with [15].", "startOffset": 34, "endOffset": 37}, {"referenceID": 13, "context": "2 Following arguments provided in [1], Section 2 derives an equivalent writing of (4) using epigraphical formulation and recall the relationship with [15].", "startOffset": 150, "endOffset": 154}, {"referenceID": 0, "context": "Section 4 evaluates the performance of the proposed strategy compared to FISTA and ADMM formulations proposed in [1], [15] both on synthetic data and real data.", "startOffset": 113, "endOffset": 116}, {"referenceID": 13, "context": "Section 4 evaluates the performance of the proposed strategy compared to FISTA and ADMM formulations proposed in [1], [15] both on synthetic data and real data.", "startOffset": 118, "endOffset": 122}, {"referenceID": 13, "context": "In [15], Jenatton et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "In [1], the authors reformulate (4) when r = 1 under an epigraphical formulation, which represents the problem as a set of hard constraints.", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "The proof follows arguments derived in [1] for the specific case r = 1.", "startOffset": 39, "endOffset": 42}, {"referenceID": 16, "context": "Proximal algorithms are derived from two main frameworks that are forward-backward scheme and Douglas-Rachford iterations (both being deduced from Krasnoselskii-Mann scheme) [18].", "startOffset": 174, "endOffset": 178}, {"referenceID": 14, "context": "FISTA can be presented as an accelerated version of forward-backward iterations [16], [19] while ADMM can be viewed as a Douglas-Rachford in the dual [20].", "startOffset": 80, "endOffset": 84}, {"referenceID": 17, "context": "FISTA can be presented as an accelerated version of forward-backward iterations [16], [19] while ADMM can be viewed as a Douglas-Rachford in the dual [20].", "startOffset": 86, "endOffset": 90}, {"referenceID": 18, "context": "FISTA can be presented as an accelerated version of forward-backward iterations [16], [19] while ADMM can be viewed as a Douglas-Rachford in the dual [20].", "startOffset": 150, "endOffset": 154}, {"referenceID": 15, "context": "When the criterion involves more than two functions, typically additional constraint such as the constraint S defined previously, most of the works derive an ADMM procedure or compute the proximity operator by mean of inner iterations which is known to often lead to an approximate solution even if global convergence can be obtained in specific cases [17].", "startOffset": 352, "endOffset": 356}, {"referenceID": 19, "context": "Another class of algorithmic procedures allowing to minimize a criterion with more that two functions, possibly including a differentiable function with a Lipschitz gradient, is the class of primal-dual proximal approaches [21], [22], [23], [24].", "startOffset": 223, "endOffset": 227}, {"referenceID": 20, "context": "Another class of algorithmic procedures allowing to minimize a criterion with more that two functions, possibly including a differentiable function with a Lipschitz gradient, is the class of primal-dual proximal approaches [21], [22], [23], [24].", "startOffset": 229, "endOffset": 233}, {"referenceID": 21, "context": "Another class of algorithmic procedures allowing to minimize a criterion with more that two functions, possibly including a differentiable function with a Lipschitz gradient, is the class of primal-dual proximal approaches [21], [22], [23], [24].", "startOffset": 235, "endOffset": 239}, {"referenceID": 22, "context": "Another class of algorithmic procedures allowing to minimize a criterion with more that two functions, possibly including a differentiable function with a Lipschitz gradient, is the class of primal-dual proximal approaches [21], [22], [23], [24].", "startOffset": 241, "endOffset": 245}, {"referenceID": 21, "context": "Several primal-dual proximal schemes have been derived but one of the most popular is based on forwardbackward iterations [23], [24] in order to estimate", "startOffset": 122, "endOffset": 126}, {"referenceID": 22, "context": "Several primal-dual proximal schemes have been derived but one of the most popular is based on forwardbackward iterations [23], [24] in order to estimate", "startOffset": 128, "endOffset": 132}, {"referenceID": 21, "context": "Additional technical assumptions can be found in [23][Theorem 3.", "startOffset": 49, "endOffset": 53}, {"referenceID": 16, "context": "The projection onto the positive orthant and on S have well known closed form expressions [18] that are: { PO(\u00b7) = max{0, \u00b7}, PS(\u0398) = \u0398+\u0398> 2 .", "startOffset": 90, "endOffset": 94}, {"referenceID": 23, "context": "The above result is obtained from arguments closed than the ones derived in [25] [Proposition 5] for an epigraphical constraint of the form { (\u03c9,u) \u2208 R \u00d7 R | max{\u03c41|u|, .", "startOffset": 76, "endOffset": 80}, {"referenceID": 24, "context": "(22) From similar arguments than in [26][Lemma 2] , \u00f1 is computed as (19) and thus", "startOffset": 36, "endOffset": 40}, {"referenceID": 24, "context": "Next we get the solution of PE1 from the ones of projection to E 1 according to [26][Lemma 3] and have the following proposition:", "startOffset": 80, "endOffset": 84}, {"referenceID": 24, "context": "This result can be directly derived from [26][Lemma 3] and the proof is therefore omitted here.", "startOffset": 41, "endOffset": 45}, {"referenceID": 0, "context": "In this section, we provide comparison results of both `1 and `\u221e proposed approaches with the two closest stateof-the-art procedures, that are \u201chierNet\u201d [1] and Jenatton\u2019s framework [15].", "startOffset": 153, "endOffset": 156}, {"referenceID": 13, "context": "In this section, we provide comparison results of both `1 and `\u221e proposed approaches with the two closest stateof-the-art procedures, that are \u201chierNet\u201d [1] and Jenatton\u2019s framework [15].", "startOffset": 182, "endOffset": 186}, {"referenceID": 13, "context": "2 Comparison with [15] \u2013 r =\u221e and weak hierarchy", "startOffset": 18, "endOffset": 22}, {"referenceID": 13, "context": "In order to provide fair comparison with the work in [15], we first investigate the performance of proposed primaldual proximal algorithm (Algorithm 2) when r = \u221e and in the configuration of weak hierarchy (no symmetry constraint is considered, i.", "startOffset": 53, "endOffset": 57}, {"referenceID": 13, "context": "The algorithmic procedure designed in [15] is based on \u201cFISTA\u201d and it will be named \u201cWeak-FISTA-`\u221e\u201d.", "startOffset": 38, "endOffset": 42}, {"referenceID": 0, "context": "3 Comparison with [1] \u2013 r = 1 and strong hierarchy Similar experiments are conducted for r = 1 and strong hierarchy (i.", "startOffset": 18, "endOffset": 21}, {"referenceID": 25, "context": "This dataset3 is collected by [27] and it is used to model HIV-1 susceptibility to the drugs because HIV-1 virus can become resistant through genome mutations for different subjects.", "startOffset": 30, "endOffset": 34}, {"referenceID": 0, "context": "The dataset is randomly split into two half sets for training and test respectively as adopted by [1], [5].", "startOffset": 98, "endOffset": 101}], "year": 2017, "abstractText": "This work focus on regression optimization problem with hierarchical interactions between variables, which is beyond the additive models in the traditional linear regression. We investigate more specifically two different fashions encountered in the literature to deal with this problem: \u201chierNet\u201d and structural-sparsity regularization, and study their connections. We propose a primal-dual proximal algorithm based on epigraphical projection to optimize a general formulation of this learning problem. The experimental setting first highlights the improvement of the proposed procedure compared to state-of-the-art methods based on fast iterative shrinkage-thresholding algorithm (i.e. FISTA) or alternating direction method of multipliers (i.e. ADMM) and second we provide fair comparisons between the different hierarchical penalizations. The experiments are conducted both on the synthetic and real data, and they clearly show that the proposed primal-dual proximal algorithm based on epigraphical projection is efficient and effective to solve and investigate the question of the hierarchical interaction learning problem.", "creator": "LaTeX with hyperref package"}}}