{"id": "1705.08049", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2017", "title": "Neural Network Memory Architectures for Autonomous Robot Navigation", "abstract": "This paper highlights the significance of including memory structures in neural networks when the latter are used to learn perception-action loops for autonomous robot navigation. Traditional navigation approaches rely on global maps of the environment to overcome cul-de-sacs and plan feasible motions. Yet, maintaining an accurate global map may be challenging in real-world settings. A possible way to mitigate this limitation is to use learning techniques that forgo hand-engineered map representations and infer appropriate control responses directly from sensed information. An important but unexplored aspect of such approaches is the effect of memory on their performance. This work is a first thorough study of memory structures for deep-neural-network-based robot navigation, and offers novel tools to train such networks from supervision and quantify their ability to generalize to unseen scenarios. We analyze the separation and generalization abilities of feedforward, long short-term memory, and differentiable neural computer networks. We introduce a new method to evaluate the generalization ability by estimating the VC-dimension of networks with a final linear readout layer. We validate that the VC estimates are good predictors of actual test performance. The reported method can be applied to deep learning problems beyond robotics.", "histories": [["v1", "Tue, 23 May 2017 00:58:20 GMT  (2726kb,D)", "http://arxiv.org/abs/1705.08049v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.LG", "authors": ["steven w chen", "nikolay atanasov", "arbaaz khan", "konstantinos karydis", "daniel d lee", "vijay kumar"], "accepted": false, "id": "1705.08049"}, "pdf": {"name": "1705.08049.pdf", "metadata": {"source": "CRF", "title": "Neural Network Memory Architectures for Autonomous Robot Navigation", "authors": ["Steven W. Chen", "Nikolay Atanasov", "Arbaaz Khan", "Konstantinos Karydis", "Daniel D. Lee", "Vijay Kumar"], "emails": ["kumar}@seas.upenn.edu"], "sections": [{"heading": null, "text": "This year, it has come to the point where there is only one person who is able to move around in order to explore the world."}, {"heading": "II. RELATED WORK", "text": "Tamar et al. developed Value Iteration Networks (VIN) that exceed regular Convolutionary Networks in planning-based sequential thinking [20]. However, this work only explored planning in known maps. However, Zhang et al. used Model Predictive Control (MPC) in the guided political search to train a neural network to navigate a quadrotor using lidar inputs [21]. Ross et al. used the Dataset Aggregation (DAgger) monitored learning algorithm to navigate in a dense forest environment using image inputs and concluded that the inclusion of memory could improve failures [22]. Existing work considers only convex obstacles and as a result they may have limited success in autonomous robot navigation in environments that contain complex obstacles such as scul-de-sacs."}, {"heading": "III. PROBLEM FORMULATION", "text": "The dynamics of the robot are defined by the Probability Density Function (pdf) (pdf).The robot perceives its environment through observations generated from a depth sensor (lidar, depth camera) whose model is1For example, the control room U for a differentiated drive robot in SE (2) can be a set of motion primitives parameterized by linear velocity and angular velocity."}, {"heading": "IV. MEMORY ARCHITECTURE", "text": "The idea behind this is that it is a matter of a way in which people are able to put themselves into the world, in which they are able to understand the world, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they, in which they live."}, {"heading": "V. ASYNCHRONOUS DAGGER", "text": "This section describes how we optimize the parameters of the networks that represent politics. (qt, ht; \u03b8) In sequential prediction problems, a common concern is the temporal dependence of the outputs on the previous input factors. (This correlation presents a problem in stochastic gradients, since the gradients estimated by the most recent steps may no longer be representative of the actual gradients. (Furthermore, the difference between state distributions between the expert and the learner is a common concern in sequential prediction problems.) A naive implementation of supervised learning will perform poorly, because the states and observations encountered by the expert will be different from those encountered by policy.) The DAggers address both of these problems. In each training session, current policy collects a number of new trajectories and aggregates them into a replay dataset."}, {"heading": "VI. GENERALIZATION ABILITY", "text": "The technique is based on the Maximum Margin Theory of Generalization of Vector Machines (SVM), which is calculated only on the basis of training data and can be used as an alternative to the test systems presented. Therefore, the architecture of most deep neural networks can be divided into two parts: a hierarchy of upstream layers followed by a single readout layer [38]. The neural network can be considered a perctron in the feature learned from the upstream layers. The architecture of the upstream neural networks contains effectively separated layers with a large margin that can easily classify the last linear readout layer. A specific form of the perctron, the SVM, can be used to evaluate the effectiveness of the neural network."}, {"heading": "VII. RESULTS AND ANALYSIS", "text": "Our experiments serve two purposes: (1) to determine the impact of integrating neural network storage architectures into robotic navigation and (2) to evaluate the predictability of our VC dimensions on empirical test errors. Our environment is a grid world of dead-end obstacles, and we test the ability of each network to interpolate and extrapolate obstacles of varying lengths."}, {"heading": "A. Cul-de-sac vs Parallel Walls", "text": "In the surroundings of the grid world, the state xt: = (xt, yt) T is the 2D position of the robot. The target is indicated by xgt: = (xgt, y g t) T. The robot can perform four actions (bottom, right, top, left) and moves a distance of 1 m with each step. The robot cannot rotate in its place and begins to orientate towards the target. The robot is equipped with a laser rangefinder, with a 360 \u00b0 field of view, which shows the relative distance to all perceived obstacles within its field of vision. At one point, the sensor measurement consists of NB = 144 laser beams with a maximum reach of 5 m, which report the distance to the nearest obstacle along the beam. The obstacle structure is either a sack or parallel wall (see fig. 1), which the robot cannot determine until it reaches the end of the obstacle. Neural networks learn to exploit specifics in the simulation design."}, {"heading": "B. Neural Networks", "text": "We evaluate four network architectures: FF, LSTM, DNC LSTM and the regularized DNC LSTM. The inputs in each step are the 144-dimensional LIDAR read zt and the 1-dimensional position with the heading atan2 (yt \u2212 ygt, xt \u2212 x g t), which represents the header of the target from the robot.The FF and LSTM networks have 3 layers of size 128 (fully connected), 128 (fully connected) and 128 (fully connected or LSTM).The DNC LSTM network has the same initial structure as the LSTM, in addition to a memory matrix and a fourth fully connected layer of size 128. The memory matrix is of size 128x32 and has 2 read heads and 1 write head. The original DNC architecture has two final fully connected layers (LDNM output and memory matrix output), which are combined."}, {"heading": "C. Training Implementation", "text": "The Asynchronous DAgger (Alg. 1) is used to train neural networks. In the case of feedback networks, the training batch size is 5. In the case of recursive networks, the backpropagation through time algorithm (BPTT) is truncated in 5 steps. We do not propagate the external DNC storage parameters over time. We use the RMSProp [45] algorithm with a learning rate of 10 \u2212 4 to calculate gradients."}, {"heading": "D. Results", "text": "We calculate three empirical measures of performance: (1) success rate; (2) classification accuracy; and (3) ratio of path lengths versus A *. Success rate measures how often the neural network reaches the target region; classification accuracy measures how often the neural network outputs the A * action; path length measures the quality of successful paths versus optimal A * paths; and we estimate the UK dimension of our neural networks by applying the method described in Section VI. Our navigation problem is a multi-level problem. However, we follow the strategy in [19] and present our results in a one-against-all binary classification framework. We estimate that this is a linear SVM penalty C = 1. Table II represents the training and VC dimensions of the measurements: The LSTM, DNC LSTM LSTM LSTM and regulated DNC all achieve near-perfect training accuracy."}, {"heading": "E. Discussion", "text": "Our empirical test results are consistent with the predictions of our method of estimating the VC dimension, suggesting that our method is a good indicator of generalization. One advantage of our method is that it has a clear measure of generalization. While a simple classification problem may have a clear measure of performance, in our sequential prediction problem we presented three measures of performance that all covered different behaviors of the network. It is unclear which is the most desirable and should be optimized. More importantly, only the data set for extrapolation was able to differentiate the models in our experiments. All memory models had the same performance in the interpolation data, highlighting the second advantage of our method. It is worth noting that the evaluation of generalization capability from empirical test sets depends on the choice of the training set and the test set, while our method of estimating the VC dimension is only dependent on the choice of the training set."}, {"heading": "VIII. CONCLUSION", "text": "Unlike traditional approaches to feedback motion planning, which rely on precise global maps, our approach can derive appropriate actions by using a neural network policy directly from information collected. We argued that the inclusion of memory in the network structure is essential to summarize past information and achieve good performance, measured by its ability to separate the right action from other decisions and generalize it to invisible environments. Finally, we proposed a new parallel training algorithm for the supervised learning of closed loop strategies in sequential prediction problems. Our analyses and results demonstrated the necessity and superiority of the inclusion of external memory in the Scul-depth environment. We also proposed a method for assessing the VC dimension of the last network layer (after all transformations of the upstream layer), which can be used as a precise measure of the generalization capability, depending only on the choice of the training set."}], "references": [{"title": "Exact robot navigation using artificial potential functions", "author": ["E. Rimon", "D. Koditschek"], "venue": "IEEE Transactions on Robotics and Automation, vol. 8, no. 5, pp. 501\u2013518, 1992.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1992}, {"title": "LQR-trees: Feedback Motion Planning via Sums-of-Squares Verification", "author": ["R. Tedrake", "I. Manchester", "M. Tobenkin", "J. Roberts"], "venue": "The International Journal of Robotics Research, vol. 29, no. 8, pp. 1038\u2013 1052, 2010.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "A formal basis for the heuristic determination of minimum cost paths", "author": ["P.E. Hart", "N.J. Nilsson", "B. Raphael"], "venue": "IEEE Transactions on Systems Science and Cybernetics, vol. 4, no. 2, pp. 100\u2013107, 1968.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1968}, {"title": "Anytime Dynamic A*: An Anytime, Replanning Algorithm.", "author": ["M. Likhachev", "D. Ferguson", "G. Gordon", "A. Stentz", "S. Thrun"], "venue": "ICAPS,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Rapidly-exploring random trees: A new tool for path planning", "author": ["S.M. Lavalle"], "venue": "Tech. Rep., 1998.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1998}, {"title": "Sampling-based algorithms for optimal motion planning", "author": ["S. Karaman", "E. Frazzoli"], "venue": "The International Journal of Robotics Research, vol. 30, no. 7, pp. 846\u2013894, 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Cross-Entropy Randomized Motion Planning", "author": ["M. Kobilarov"], "venue": "Robotics: Science and Systems (RSS), 2011.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Use of relaxation methods in samplingbased algorithms for optimal motion planning", "author": ["O. Arslan", "P. Tsiotras"], "venue": "IEEE Int. Conf. on Robotics and Automation (ICRA). IEEE, 2013, pp. 2421\u20132428.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Probabilistic roadmaps for path planning in high-dimensional configuration spaces", "author": ["L. Kavraki", "P. Svestka", "J.-C. Latombe", "M. Overmars"], "venue": "IEEE Transactions on Robotics and Automation, vol. 12, no. 4, pp. 566\u2013580, 1996.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1996}, {"title": "High speed navigation for quadrotors with limited onboard sensing", "author": ["S. Liu", "M. Watterson", "S. Tang", "V. Kumar"], "venue": "IEEE Int. Conf. on Robotics and Automation (ICRA), 2016, pp. 1484\u20131491.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Robotic mapping: A survey", "author": ["S. Thrun"], "venue": "Exploring Artificial Intelligence in the New Millenium, G. Lakemeyer and B. Nebel, Eds. Morgan Kaufmann, 2002.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2002}, {"title": "Temporal difference learning and td-gammon", "author": ["G. Tesauro"], "venue": "Commun. ACM, vol. 38, no. 3, pp. 58\u201368, 1995.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1995}, {"title": "Learning to plan for visibility in navigation of unknown environments", "author": ["C. Richter", "N. Roy"], "venue": "Intl. Symposium on Experimental Robotics, 2016.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "End-to-end training of deep visuomotor policies", "author": ["S. Levine", "C. Finn", "T. Darrell", "P. Abbeel"], "venue": "Journal of Machine Learning Research, vol. 17, no. 39, pp. 1\u201340, 2016.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "From perception to decision: A data-driven approach to end-toend motion planning for autonomous ground robots", "author": ["M. Pfeiffer", "M. Schaeuble", "J. Nieto", "R. Siegwart", "C. Cadena"], "venue": "arXiv preprint arXiv:1609.07910, 2016.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Cascade models of synaptically stored memories", "author": ["S. Fusi", "P.J. Drew", "L. Abbott"], "venue": "Neuron, vol. 45, no. 4, pp. 599\u2013611, 2005.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Memory traces in dynamical systems", "author": ["S. Ganguli", "D. Huh", "H. Sompolinsky"], "venue": "Proc. of the National Academy of Sciences, vol. 105, no. 48, pp. 18 970\u201318 975, 2008.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "On over-fitting in model selection and subsequent selection bias in performance evaluation", "author": ["G.C. Cawley", "N.L. Talbot"], "venue": "Journal of Machine Learning Research, vol. 11, no. Jul, pp. 2079\u20132107, 2010.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "The Nature of Statistical Learning Theory", "author": ["V.N. Vapnik"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1995}, {"title": "Value iteration networks", "author": ["A. Tamar", "Y. WU", "G. Thomas", "S. Levine", "P. Abbeel"], "venue": "Advances in Neural Information Processing Systems 29, 2016, pp. 2154\u20132162.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning Deep Control Policies for Autonomous Aerial Vehicles with MPC-Guided Policy Search", "author": ["T. Zhang", "G. Kahn", "S. Levine", "P. Abbeel"], "venue": "IEEE Int. Conf. on Robotics and Automation (ICRA), 2016.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning monocular reactive uav control in cluttered natural environments", "author": ["S. Ross", "N. Melik-Barkhudarov", "K.S. Shankar", "A. Wendel", "D. Dey", "A. Bagnell", "M. Hebert"], "venue": "IEEE Int. Conf. on Robotics and Automation (ICRA). IEEE, 2013, pp. 1765\u20131772.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Vision and learning for deliberative monocular cluttered flight", "author": ["D. Dey", "K.S. Shankar", "S. Zeng", "R. Mehta", "M.T. Agcayazi", "C. Eriksen", "S. Daftry", "M. Hebert", "J.A. Bagnell"], "venue": "Field and Service Robotics. Springer, 2016, pp. 391\u2013409.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2016}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Comput., vol. 9, no. 8, pp. 1735\u20131780, Nov. 1997.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1997}, {"title": "Memory-based control with recurrent neural networks", "author": ["N. Heess", "J.J. Hunt", "T.P. Lillicrap", "D. Silver"], "venue": "arXiv:1512.04455, 2015.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Asynchronous Methods for Deep Reinforcement Learning", "author": ["V. Mnih", "A. Puigdom\u00e8nech Badia", "M. Mirza", "A. Graves", "T. Lillicrap", "T. Harley", "D. Silver", "K. Kavukcuoglu"], "venue": "ArXiv e-print:1602.01783, 2016.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2016}, {"title": "Policy learning with continuous memory states for partially observed robotic control", "author": ["M. Zhang", "S. Levine", "Z. McCarthy", "C. Finn", "P. Abbeel"], "venue": "IEEE Int. Conf. on Robotics and Automation (ICRA), 2015.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Neural turing machines", "author": ["A. Graves", "G. Wayne", "I. Danihelka"], "venue": "CoRR, vol. abs/1410.5401, 2014.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "Scaling memory-augmented neural networks with sparse reads and writes", "author": ["J. Rae", "J.J. Hunt", "I. Danihelka", "T. Harley", "A.W. Senior", "G. Wayne", "A. Graves", "T. Lillicrap"], "venue": "Advances In Neural Information Processing Systems, 2016, pp. 3621\u20133629.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2016}, {"title": "Hybrid computing using a neural network with dynamic external memory", "author": ["A. Graves", "G. Wayne", "M. Reynolds", "T. Harley", "I. Danihelka", "A. Grabska-Barwi\u0144ska", "S. Colmenarejo", "E. Grefenstette", "T. Ramalho"], "venue": "Nature, vol. 538, no. 7626, pp. 471\u2013476, 2016.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2016}, {"title": "ARA*: Anytime A* with Provable Bounds on Sub-Optimality", "author": ["M. Likhachev", "G. Gordon", "S. Thrun"], "venue": "Advances in Neural Information Processing Systems (NIPS), 2004, pp. 767\u2013774.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2004}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, 2012, pp. 1097\u20131105.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2012}, {"title": "Guided policy search.", "author": ["S. Levine", "V. Koltun"], "venue": "in Intl. Conf. on Machine Learning,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2013}, {"title": "A reduction of imitation learning and structured prediction to no-regret online learning.", "author": ["S. Ross", "G.J. Gordon", "D. Bagnell"], "venue": "in AISTATS,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2011}, {"title": "Human-level control through deep reinforcement learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A. Rusu", "J. Veness", "M. Bellemare", "A. Graves", "M. Riedmiller", "A. Fidjeland", "G. Ostrovski", "S. Petersen", "C. Beattie", "I. Sadik", "A. Antonoglou", "H. King", "D. Kumaran", "D. Wierstar", "S. Legg", "D. Hassabis"], "venue": "Nature 518, 529-533, 2015.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2015}, {"title": "Linear readout of object manifolds", "author": ["S. Chung", "D.D. Lee", "H. Sompolinsky"], "venue": "Phys. Rev. E, vol. 93, p. 060301, 2016.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2016}, {"title": "Decision boundary focused neural network classifier", "author": ["S. Zhong", "J. Ghosh"], "venue": "Intelligent Engineering Systems Through Artificial Neural Networks, 2000.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2000}, {"title": "A gentle hessian for efficient gradient descent", "author": ["R. Collobert", "S. Bengio"], "venue": "Acoustics, Speech, and Signal Processing, 2004., vol. 5, 2004, pp. V\u2013517.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2004}, {"title": "Convolutional neural support vector machines: hybrid visual pattern classifiers for multi-robot systems", "author": ["J. Nagi", "G.A. Di Caro", "A. Giusti", "F. Nagi", "L.M. Gambardella"], "venue": "Machine Learning and Applications (ICMLA), vol. 1, 2012, pp. 27\u201332.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep learning using linear support vector machines", "author": ["Y. Tang"], "venue": "Workshop on Representational Learning, ICML, 2013.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2013}, {"title": "Quadratic programming in geometric optimization: Theory", "author": ["S. Schonherr"], "venue": "Implementation and Applications, 2002.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2002}, {"title": "Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude", "author": ["T. Tieleman", "G. Hinton"], "venue": "COURSERA: Neural networks for machine learning, vol. 4, no. 2, 2012.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": ", optimization-based [1], [2], search-based [3], [4], or sampling-based [5], [6], [7], [8], [9]).", "startOffset": 21, "endOffset": 24}, {"referenceID": 1, "context": ", optimization-based [1], [2], search-based [3], [4], or sampling-based [5], [6], [7], [8], [9]).", "startOffset": 26, "endOffset": 29}, {"referenceID": 2, "context": ", optimization-based [1], [2], search-based [3], [4], or sampling-based [5], [6], [7], [8], [9]).", "startOffset": 44, "endOffset": 47}, {"referenceID": 3, "context": ", optimization-based [1], [2], search-based [3], [4], or sampling-based [5], [6], [7], [8], [9]).", "startOffset": 49, "endOffset": 52}, {"referenceID": 4, "context": ", optimization-based [1], [2], search-based [3], [4], or sampling-based [5], [6], [7], [8], [9]).", "startOffset": 72, "endOffset": 75}, {"referenceID": 5, "context": ", optimization-based [1], [2], search-based [3], [4], or sampling-based [5], [6], [7], [8], [9]).", "startOffset": 77, "endOffset": 80}, {"referenceID": 6, "context": ", optimization-based [1], [2], search-based [3], [4], or sampling-based [5], [6], [7], [8], [9]).", "startOffset": 82, "endOffset": 85}, {"referenceID": 7, "context": ", optimization-based [1], [2], search-based [3], [4], or sampling-based [5], [6], [7], [8], [9]).", "startOffset": 87, "endOffset": 90}, {"referenceID": 8, "context": ", optimization-based [1], [2], search-based [3], [4], or sampling-based [5], [6], [7], [8], [9]).", "startOffset": 92, "endOffset": 95}, {"referenceID": 9, "context": "lenging due to localization drift, noisy features, environment changes and limited on-board computation [10], [11].", "startOffset": 104, "endOffset": 108}, {"referenceID": 10, "context": "lenging due to localization drift, noisy features, environment changes and limited on-board computation [10], [11].", "startOffset": 110, "endOffset": 114}, {"referenceID": 11, "context": "edu infeasible [12].", "startOffset": 15, "endOffset": 19}, {"referenceID": 12, "context": "Due to their representational power, neuralnetwork-based learning techniques have become increasingly of interest to the robotics community as a method to encode such perception-action policies or value functions [13], [14].", "startOffset": 213, "endOffset": 217}, {"referenceID": 13, "context": "Due to their representational power, neuralnetwork-based learning techniques have become increasingly of interest to the robotics community as a method to encode such perception-action policies or value functions [13], [14].", "startOffset": 219, "endOffset": 223}, {"referenceID": 14, "context": "Recent work has shown that neural networks can be used to navigate a wheeled robot in cluttered environments [15].", "startOffset": 109, "endOffset": 113}, {"referenceID": 15, "context": "Current network architectures are not well-suited for long-term sequential tasks [16], [17], which typically appear in robotics (e.", "startOffset": 81, "endOffset": 85}, {"referenceID": 16, "context": "Current network architectures are not well-suited for long-term sequential tasks [16], [17], which typically appear in robotics (e.", "startOffset": 87, "endOffset": 91}, {"referenceID": 17, "context": "the model-selection phase [18].", "startOffset": 26, "endOffset": 30}, {"referenceID": 18, "context": "\u2022 We estimate the Vapnik-Chervonenkis (VC) dimension [19] of the last layer of a neural network (after all upstream layer transformations) as a measure of the network generalization ability that depends only on the", "startOffset": 53, "endOffset": 57}, {"referenceID": 19, "context": "developed Value Iteration Networks (VIN) that outperform regular convolutional networks in planning-based sequential reasoning [20].", "startOffset": 127, "endOffset": 131}, {"referenceID": 20, "context": "Control (MPC) in guided policy search to train a neural network to navigate a quadrotor using lidar inputs [21].", "startOffset": 107, "endOffset": 111}, {"referenceID": 21, "context": "ory could improve failure cases [22].", "startOffset": 32, "endOffset": 36}, {"referenceID": 22, "context": "Existing works consider only convex obstacles, and as a result they may have limited success in autonomous robot navigation in environments which contain complex obstacles such as cul-de-sacs [23].", "startOffset": 192, "endOffset": 196}, {"referenceID": 23, "context": "method to incorporate memory in robotics learning problems are through Recurrent Neural Networks (RNN) such as the Long-Short Term Memory (LSTM) [24].", "startOffset": 145, "endOffset": 149}, {"referenceID": 24, "context": "demonstrate that recurrent neural networks are able to learn in partially-observable problems [25].", "startOffset": 94, "endOffset": 98}, {"referenceID": 25, "context": "Critic (A3C) algorithm and demonstrate improved performance over a feedforward network [26].", "startOffset": 87, "endOffset": 91}, {"referenceID": 26, "context": "argue that memory is necessary in partially-observed tasks, and augment the state space to include memory states [27].", "startOffset": 113, "endOffset": 117}, {"referenceID": 27, "context": "be used to simulate arbitrary procedures, learning the optimal network is not easy in practice [28].", "startOffset": 95, "endOffset": 99}, {"referenceID": 28, "context": "This observation inspired a new family of neural network architectures called Memory Augmented Neural Networks (MANN) which utilize an explicit memory matrix [29].", "startOffset": 158, "endOffset": 162}, {"referenceID": 29, "context": "improved performance over standard RNNs in tasks such as copying sequences and planning shortest paths [30].", "startOffset": 103, "endOffset": 107}, {"referenceID": 0, "context": "More precisely, we consider a finitehorizon discounted MDP defined by (I,U , T ,R, \u03b3), where \u03b3 \u2208 (0, 1] is a discount factor, I is the state space, U is the action space, T : I \u00d7 U \u00d7 I \u2192 [0, 1] is the transition function, and R : I \u00d7 U \u00d7 I \u2192 R is the reward function.", "startOffset": 187, "endOffset": 193}, {"referenceID": 30, "context": "In contrast, we consider learning a feasible policy by using the outputs of an A\u2217 path planner [31] for supervision.", "startOffset": 95, "endOffset": 99}, {"referenceID": 31, "context": "6] and ConvNets, have been very successful in various vision and robotic tasks [34][35].", "startOffset": 79, "endOffset": 83}, {"referenceID": 32, "context": "6] and ConvNets, have been very successful in various vision and robotic tasks [34][35].", "startOffset": 83, "endOffset": 87}, {"referenceID": 27, "context": "memory in neural network architectures was inspired by Turing Machines [28].", "startOffset": 71, "endOffset": 75}, {"referenceID": 33, "context": "states and observations encountered by the expert will be different than those encountered by the policy [36].", "startOffset": 105, "endOffset": 109}, {"referenceID": 33, "context": "The DAgger [36] algorithm addresses both of these problems.", "startOffset": 11, "endOffset": 15}, {"referenceID": 25, "context": "Asynchronous DAgger is inspired by the Asynchronous Advantage Actor Critic (A3C) algorithm [26], but differs since the A3C algorithm is an actor-critic reinforcement learning algorithm, while ours is a supervised sequential prediction", "startOffset": 91, "endOffset": 95}, {"referenceID": 29, "context": "2See [30] for details on the computations and memory matrix updates.", "startOffset": 5, "endOffset": 9}, {"referenceID": 34, "context": "algorithm, the original DAgger algorithm is analogous to the original Deep Q-Network (DQN) algorithm [37] in that both store an experience replay databank.", "startOffset": 101, "endOffset": 105}, {"referenceID": 35, "context": "by a single readout layer [38].", "startOffset": 26, "endOffset": 30}, {"referenceID": 36, "context": "Previous works have recognized the benefit of applying maximum margin SVMs to neural networks by using them as the final readout layer in tasks such as image recognition [39], [40], [41], [42].", "startOffset": 170, "endOffset": 174}, {"referenceID": 37, "context": "Previous works have recognized the benefit of applying maximum margin SVMs to neural networks by using them as the final readout layer in tasks such as image recognition [39], [40], [41], [42].", "startOffset": 176, "endOffset": 180}, {"referenceID": 38, "context": "Previous works have recognized the benefit of applying maximum margin SVMs to neural networks by using them as the final readout layer in tasks such as image recognition [39], [40], [41], [42].", "startOffset": 182, "endOffset": 186}, {"referenceID": 39, "context": "Previous works have recognized the benefit of applying maximum margin SVMs to neural networks by using them as the final readout layer in tasks such as image recognition [39], [40], [41], [42].", "startOffset": 188, "endOffset": 192}, {"referenceID": 18, "context": "\u03a8(qi, hi) for all i and |w0| is the norm of the optimal weights [19].", "startOffset": 64, "endOffset": 68}, {"referenceID": 40, "context": "The vector \u03a8\u2217 = \u2211n i=1 \u03a8(qi, hi)p \u2217 i is the center of the smallest enclosing sphere and the squared radius R is the negative value of the objective function at p\u2217 [44].", "startOffset": 164, "endOffset": 168}, {"referenceID": 18, "context": "3We refer the reader to [19] and [43] for in-depth details and proofs.", "startOffset": 24, "endOffset": 28}, {"referenceID": 26, "context": "of the system observed by [27], but is not desirable in our case because it does not actually test the network\u2019s ability to retain memory.", "startOffset": 26, "endOffset": 30}, {"referenceID": 41, "context": "We use the RMSProp [45] algorithm with a learning rate of 10\u22124 to calculate gradients.", "startOffset": 19, "endOffset": 23}, {"referenceID": 18, "context": "However, we follow the strategy in [19] and present our results in a one-vs-all binary classification framework.", "startOffset": 35, "endOffset": 39}], "year": 2017, "abstractText": "This paper highlights the significance of including memory structures in neural networks when the latter are used to learn perception-action loops for autonomous robot navigation. Traditional navigation approaches rely on global maps of the environment to overcome cul-de-sacs and plan feasible motions. Yet, maintaining an accurate global map may be challenging in real-world settings. A possible way to mitigate this limitation is to use learning techniques that forgo handengineered map representations and infer appropriate control responses directly from sensed information. An important but unexplored aspect of such approaches is the effect of memory on their performance. This work is a first thorough study of memory structures for deep-neural-network-based robot navigation, and offers novel tools to train such networks from supervision and quantify their ability to generalize to unseen scenarios. We analyze the separation and generalization abilities of feedforward, long short-term memory, and differentiable neural computer networks. We introduce a new method to evaluate the generalization ability by estimating the VC-dimension of networks with a final linear readout layer. We validate that the VC estimates are good predictors of actual test performance. The reported method can be applied to deep learning problems beyond robotics.", "creator": "LaTeX with hyperref package"}}}