{"id": "1705.08200", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2017", "title": "Logical Learning Through a Hybrid Neural Network with Auxiliary Inputs", "abstract": "The human reasoning process is seldom a one-way process from an input leading to an output. Instead, it often involves a systematic deduction by ruling out other possible outcomes as a self-checking mechanism. In this paper, we describe the design of a hybrid neural network for logical learning that is similar to the human reasoning through the introduction of an auxiliary input, namely the indicators, that act as the hints to suggest logical outcomes. We generate these indicators by digging into the hidden information buried underneath the original training data for direct or indirect suggestions. We used the MNIST data to demonstrate the design and use of these indicators in a convolutional neural network. We trained a series of such hybrid neural networks with variations of the indicators. Our results show that these hybrid neural networks are very robust in generating logical outcomes with inherently higher prediction accuracy than the direct use of the original input and output in apparent models. Such improved predictability with reassured logical confidence is obtained through the exhaustion of all possible indicators to rule out all illogical outcomes, which is not available in the apparent models. Our logical learning process can effectively cope with the unknown unknowns using a full exploitation of all existing knowledge available for learning. The design and implementation of the hints, namely the indicators, become an essential part of artificial intelligence for logical learning. We also introduce an ongoing application setup for this hybrid neural network in an autonomous grasping robot, namely as_DeepClaw, aiming at learning an optimized grasping pose through logical learning.", "histories": [["v1", "Tue, 23 May 2017 12:11:30 GMT  (4764kb)", "http://arxiv.org/abs/1705.08200v1", "11 pages, 9 figures, 4 tables"]], "COMMENTS": "11 pages, 9 figures, 4 tables", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["fang wan", "chaoyang song"], "accepted": false, "id": "1705.08200"}, "pdf": {"name": "1705.08200.pdf", "metadata": {"source": "CRF", "title": "Logical Learning Through a Hybrid Neural Network with Auxiliary Inputs", "authors": ["WAN Fang", "SONG Chaoyang"], "emails": ["sophie.fwan@gmail.com", "songcy@ieee.org"], "sections": [{"heading": null, "text": "ar Xiv: 170 5.08 200v 1 [cs.A I] 2 3M ay2 017The human thought process is rarely a one-sided process from an input that leads to an output. Instead, it often involves a systematic conclusion by excluding other possible outcomes as a self-control mechanism. In this essay, we describe the design of a hybrid neural network for logical learning that is similar to human thinking by introducing an auxiliary input, namely the indicators that serve as clues to logical outcomes. We create these indicators by digging into the hidden information that lies beneath the original training data for direct or indirect suggestions. We used the MNIST data to demonstrate the design and use of these indicators in a revolutionary neural network. We trained a number of such hybrid neural networks with variations in the indicators. Our results show that these hybrid neural networks are very robust when it comes to producing logical outcomes with an unpredictable part of a higher-than-logical prediction."}, {"heading": "1 Introduction 1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 The Design of a Hybrid Neural Network 3", "text": "2.1 Auxiliary input and new labels.... 3 2.2 New architecture for logical learning... 3 2.3 Customized MNIST data....... 5"}, {"heading": "3 Experiment Results and Discussions 7", "text": "3.1 Each indicator is a good indicator of logical thinking.............. 7 3.2 Logical complexity relates positively to confidence in a logical response....... 8 3.3 The logical result comes at the expense of general accuracy. 8 3.4 Meaningful indicators are not so good, and direct suggestions are not so bad."}, {"heading": "4 Logical Learning for the as DeepClaw 10", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5 Final Remarks and Future Work 10", "text": "\"Original research contribution of the Sustainable + Intelligent Robotics Group. Corresponding author."}, {"heading": "1. Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2. The Design of a Hybrid Neural Network", "text": "The introduction of clues is the core differentiation behind our proposed hybrid neural network, which aims at a series of direct or indirect suggestions that bridge the input data and output markers with a sensible decision. As these indicators are suggestions abstracted from the original output, revisiting the information embedded in these markers is crucial. Generally, the marked result usually corresponds to a comprehensive and complex question that is difficult to answer and therefore cannot be easily modeled based on existing knowledge. Although the final answer to the question can be formulated as a simple yes or no, the question could usually be broken down to further details for more specific investigations. For example, the question asked in Figure 1 can be 1) what the animal in general is and 2) what the breed of that animal in particular is."}, {"heading": "2.1. The Auxiliary Input and New Labels", "text": "In our hybrid neural network shown in Fig. 2, the original input is still used as the primary input XN = {x1, x2,..., xN}. In addition, we generate a number of additional inputs to the network, namely the indicators, by categorizing the original labels YM = {y1, y2,..., yM}. Since understanding these labels is not directly linked to the input, we can use this indirect knowledge, which is not represented in the previous information, to categorize these labels, which may be a meaningful process or a randomized process. The resulting indirect suggestions become indicators ZL = {z1, z2,..., zL}, which usually have a smaller dimension than the original labels (L < M), as a logical concept."}, {"heading": "2.2. New Architecture for Logical Learning", "text": "During the training process shown in Fig. 2, our resulting neural network uses a primary input xi and an auxiliary indicator zi to model a new set of marked output yi. This hybrid neural network is structurally different by adding an additional process that establishes a certain logical relationship to the original data. The advantage of the hybrid neural network is the full utilization of our existing understanding of the problem by designing meaningful indicators and establishing logical considerations. Later, we will also show that the training process can be further exploited by designing randomized indicators to reveal unknown correlations and reduce the data and logical uncertainty. Since our auxiliary indicators are artificial, we only get the same input data as in the apparent neural network to proceed with our prediction. Thus, for example, as shown in Fig. 3, when a new input is presented logically, our neural network can only be made hybrid if a hybrid indicatory result is derived from the beginning of 2017."}, {"heading": "2.3. The Adapted MNIST Data", "text": "This year, it has reached the point where it will be able to put itself at the top without being able to put itself at the top."}, {"heading": "3. Experiment Results and Discussions", "text": "We compare our models with the MNIST data using a Convolutionary Neural Network, which contains three Convolutionary Layers (588 \u00d7 200 and 200 \u00d7 10) and two fully interconnected layers. Benchmark model test accuracy is maximized to 98.91% after 10,000 training steps with training batch equal to 100. Accuracy can be further improved by [2] using more advanced techniques such as additional layers, batch normalization, dropouts and ReLu layers. All experiments with indicators listed in Table 1 are performed [3], and test results are reported in Table 3. The Logical Results column refers to the percentage of 10,000 MINIST test examples that pass the two rounds of logical checks. This self-testing metric results in two predictive accuracies of interest."}, {"heading": "3.1. Any indicator is a good indicator for logical reasoning", "text": "As shown in Table 3, all logical results are above 99% predictive accuracy, which is higher than the comparative accuracy of the apparent neural network model of 98.91%. Regardless of the indicator designs, our results suggested that trust is restored when a logical response is complete. This is a self-testing mechanism of the hybrid neural network that is not available in the apparent neural networks. Apparent neural networks only take over the direct information represented in the data, but ignore the logic behind the data, which is normally a thought process of human thought, rather than memorizing past events by brutal calculation. These new logic helps to deal with the uncertainties in future events. Our hybrid neural network uses a logical learning process by introducing the indicators of suggestive information. The ro-7 busy activity of the results shown in Table 3 shows the effectiveness of the proposed logical learning through the hyonal network as being marketed by human cases (these are 13 or 21 in the case of direct design)."}, {"heading": "3.2. Logical complexity positively relates to the confidence of a logical answer", "text": "As shown in Table 1, three levels of the concept are used to reflect different logical complexities in the design of the indicators. Those that are generated by chance partially represent a certain unknown relationship with the highest complexity, while the significant ones are easier for human comprehension. The number of indicators is also an important aspect to reflect the complexity of logical reasoning in our models. For example, each added indicator would increase the required training many times over as we traverse all indicators. Furthermore, the distribution of each indicator and the labels it proposes also includes a statistical influence that correlates with the distribution of the input data. Generally, we can divide these eight experiments into four groups, according to their logical complexity. As shown in Figure 7, a trend of growing logical accuracy is observed as the logical complexity increases, while the group with the least logical complexity increases, the group with the least logical complexity sharing the M14 contains the least of the original complexity."}, {"heading": "3.3. Logical result is at the cost of overall accuracy", "text": "While the logical result gives us a more confident answer when dealing with the unknown uncertainties of a new question, i.e. new input data, the predictive accuracy of the overall result provides us with an opportunity to compare the hybrid neural networks with the apparent horizontal ones. We also have the trend of the general prediction8Logical Learning Through a Hybrid Neural Network with Auxiliary Inputs (Wan & Song, 2017) accuracy of the above four experiment groups in Fig. 7. As the logical results become more accurate, a decreasing trend can be observed. In fact, the percentage of logical throughput shows a greater impact on the overall predictive accuracy in Fig. 7. This is caused by the fact that the decrease in logical throughput is about three times faster than the increase in logical accuracy. The following equation can be used to reflect such a shift in relation. OverallAccuracy = LogicalAccuracy \u00d7 LogicalPass (1)"}, {"heading": "3.4. Meaningful indicators are not that good, and direct suggestions are not that bad", "text": "Another observation concerns the conception of the indicators in terms of their significance and suggestive strength. However, if one compares cases 11, 12 and 21, one finds that the importance of the indicators shows only a slight increase in the predictive accuracy of the logical results from 99.17% to 99.21-99.24%. A probable explanation is that computers do not perceive such mathematical relationships much differently from the randomized ones, which are very different from humans. This partly reflects the underlying difference between man and machine, where such a small increase in understanding makes a significant difference in the autonomy of the mind. While designing these indicators, we deliberately tried to imitate the human use of references in an indirect way as it was introduced at the beginning of this paper. Of the eight normal experiments, only cases 14 and 24 direct 1-to-1 suggestions between the indicators and the labels contain a deviation. These two cases exceeded the other cases in terms of logical accuracy in total, all 923% refer to a logical accuracy with an average of 0.14."}, {"heading": "3.5. Special Design and Use of the Indicators", "text": "In fact, the majority of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to fight, to fight, to fight, to fight, to fight, to move, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move,"}, {"heading": "4. Logical Learning for the as DeepClaw", "text": "In this section, we will delve further into the application of logical learning by selecting the hybrid neural network for autonomous robotic grasping. [4] The robotic platform is set up as an arcade claw machine, i.e. as a DeepClaw, with more details described in a GitHub repository [4]. It is a universal six-axis robotic arm that performs grasping tasks with stuffed toys as targets, and a RGB-D camera as sensory input. Unlike previous research that used methods for autonomous robotic grasping, [5, 6, 7] we intend to apply logical learning using the hybrid neural network for training as a DeepClaw platform to grasp greed as a structurally simplified all-purpose grasp for greed greed as a structurally simplified all-purpose grasping, which we have implemented with a complete robotic system to grasp greed as the basis for the greed-grasping we intend to use as a structurally simplified all-purpose grasping platform for greed-grasping."}, {"heading": "5. Final Remarks and Future Work", "text": "In this paper, we propose the concept of logical learning through a hybrid neural network with an additional tool, namely indicators generated from the original labels, or even from the original input data. Given the same data, logical learning can always deliver results with a higher logical accuracy, supported by a range of normal and special indicators. We have comprehensively introduced the concept of indicators for logical learning with the hybrid neural network in its design and application, and we have also demonstrated the robustness of the proposed logical learning in a range of normal and specialized indicators."}, {"heading": "Acknowledgment", "text": "The authors would like to pay tribute to their daughter SONG Roumu for her growing learning skills that inspired this research, as well as to the following students who attended the Sustainable and Intelligent Robotics Group at Monash University, led by the corresponding author, who worked on the construction of the robot system as DeepClaw, including XIA Tian, HE Xiaoyi and DENG Yuntian."}], "references": [{"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Learn TensorFlow and deep learning, without a Ph.D., 2016", "author": ["M. G\u00f6rner"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2017}, {"title": "HybridNN: MNIST for Logical Learning with A Hybrid Neural Network, 2017", "author": ["F. Wan"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2017}, {"title": "DeepClaw: An Arcade Claw Robot for Logical Learning with A Hybrid Neural Network, 2017", "author": ["F. Wan", "C. Song"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2017}, {"title": "Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection, 2016", "author": ["S. Levine", "P. Pastor", "A. Krizhevsky", "D. Quillen"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Supersizing Self-supervision: Learning to Grasp from 50K Tries and 700 Robot Hours", "author": ["L. Pinto", "A. Gupta"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Deep learning for detecting robotic grasps", "author": ["I. Lenz", "H. Lee", "A. Saxena"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "The MNIST data is an extensive image collection of hand-written digits labeled from zero to nine, consisting of a training set of 60,000 examples and a test set of 10,000 examples [1].", "startOffset": 180, "endOffset": 183}, {"referenceID": 1, "context": "One can further improve the accuracy by referring to [2] using more advanced techniques such as more layers, batch normalization, dropout and ReLu layers.", "startOffset": 53, "endOffset": 56}, {"referenceID": 2, "context": "All experiments with indicators listed in Table 1 are conducted [3], and the testing results are reported in Table 3.", "startOffset": 64, "endOffset": 67}, {"referenceID": 3, "context": "as DeepClaw, with more details described on a GitHub repository [4].", "startOffset": 64, "endOffset": 67}, {"referenceID": 4, "context": "Different from previous research using deep learning methods for autonomous robotic grasping [5, 6, 7], we intend to apply the logical learning using the hybrid neural network for training with the as DeepClaw platform.", "startOffset": 93, "endOffset": 102}, {"referenceID": 5, "context": "Different from previous research using deep learning methods for autonomous robotic grasping [5, 6, 7], we intend to apply the logical learning using the hybrid neural network for training with the as DeepClaw platform.", "startOffset": 93, "endOffset": 102}, {"referenceID": 6, "context": "Different from previous research using deep learning methods for autonomous robotic grasping [5, 6, 7], we intend to apply the logical learning using the hybrid neural network for training with the as DeepClaw platform.", "startOffset": 93, "endOffset": 102}, {"referenceID": 4, "context": "An apparent neural network for this task would be similar to those described in [5, 6, 7].", "startOffset": 80, "endOffset": 89}, {"referenceID": 5, "context": "An apparent neural network for this task would be similar to those described in [5, 6, 7].", "startOffset": 80, "endOffset": 89}, {"referenceID": 6, "context": "An apparent neural network for this task would be similar to those described in [5, 6, 7].", "startOffset": 80, "endOffset": 89}], "year": 2017, "abstractText": "The human reasoning process is seldom a one-way process from an input leading to an output. Instead, it often involves a systematic deduction by ruling out other possible outcomes as a self-checking mechanism. In this paper, we describe the design of a hybrid neural network for logical learning that is similar to the human reasoning through the introduction of an auxiliary input, namely the indicators, that act as the hints to suggest logical outcomes. We generate these indicators by digging into the hidden information buried underneath the original training data for direct or indirect suggestions. We used the MNIST data to demonstrate the design and use of these indicators in a convolutional neural network. We trained a series of such hybrid neural networks with variations of the indicators. Our results show that these hybrid neural networks are very robust in generating logical outcomes with inherently higher prediction accuracy than the direct use of the original input and output in apparent models. Such improved predictability with reassured logical confidence is obtained through the exhaustion of all possible indicators to rule out all illogical outcomes, which is not available in the apparent models. Our logical learning process can effectively cope with the unknown unknowns using a full exploitation of all existing knowledge available for learning. The design and implementation of the hints, namely the indicators, become an essential part of artificial intelligence for logical learning. We also introduce an ongoing application setup for this hybrid neural network in an autonomous grasping robot, namely as DeepClaw, aiming at learning an optimized grasping pose through logical learning.", "creator": "LaTeX with hyperref package"}}}