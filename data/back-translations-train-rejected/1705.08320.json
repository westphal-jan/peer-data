{"id": "1705.08320", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2017", "title": "Explaining Transition Systems through Program Induction", "abstract": "Explaining and reasoning about processes which underlie observed black-box phenomena enables the discovery of causal mechanisms, derivation of suitable abstract representations and the formulation of more robust predictions. We propose to learn high level functional programs in order to represent abstract models which capture the invariant structure in the observed data. We introduce the $\\pi$-machine (program-induction machine) -- an architecture able to induce interpretable LISP-like programs from observed data traces. We propose an optimisation procedure for program learning based on backpropagation, gradient descent and A* search. We apply the proposed method to three problems: system identification of dynamical systems, explaining the behaviour of a DQN agent and learning by demonstration in a human-robot interaction scenario. Our experimental results show that the $\\pi$-machine can efficiently induce interpretable programs from individual data traces.", "histories": [["v1", "Tue, 23 May 2017 14:38:28 GMT  (876kb,D)", "http://arxiv.org/abs/1705.08320v1", "submitted to Neural Information Processing Systems 2017"]], "COMMENTS": "submitted to Neural Information Processing Systems 2017", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["svetlin penkov", "subramanian ramamoorthy"], "accepted": false, "id": "1705.08320"}, "pdf": {"name": "1705.08320.pdf", "metadata": {"source": "CRF", "title": "Explaining Transition Systems through Program Induction", "authors": ["Svetlin Penkov", "Subramanian Ramamoorthy"], "emails": ["sv.penkov@ed.ac.uk", "s.ramamoorthy@ed.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "Transition system learning has been a core concern within machine learning, with applications ranging from the system identification of dynamic systems Q [1] and the conclusion of human decision-making [2, 3] to the reverse engineering of the behavior of a device or computer program from observations and traces. [4] With the increasing use of these learned models in the inner loops of decision systems, e.g. in robotics and human-machine interfaces, it is necessary to ensure that these models are accurate behavioral predictors, but also that their causal mechanisms are exposed to the system designer in a more interpretative manner. There is also the need to explain the model in terms of counterfactual reasoning [5], what we expect the system to do when a particular variable is changed or removed, or model testing of longer-term characteristics, including safety and large variations in performance. We address these needs through a program based on explanability."}, {"heading": "2 Related work", "text": "The immense successes of deep neural networks based on learning systems and their rapid adoption in numerous real-world applications have renewed interest in the interpretability and explanability of learned models. [11, 12] Decision trees and probabilistic graphical models, however, are interpretable in that they impose strong structural constraints on models of observed data and allow for different types of queries, including introspective and counterfactual ones. In contrast, deeper learning models are usually trained \"by query\" and have numerous parameters that may be difficult to interpret. Zeiler and Fergus have introduced deconvolutionary networks to visualize the layers of conventional networks and provide a more intuitive understanding of why they work well. Similar approaches can be seen in [14, 15], in the context of autonomous driving. Zavy et al describes Semi-Agated Decision Process (AMDP)."}, {"heading": "3 Problem definition", "text": "Consider the labeled transition system, in which S is a non-empty group of states, A a non-empty group of actions, each of which is assigned to an execution track T by the recursive relation st + 1 = 1 (st, at)) for 1 \u2264 t \u2264 T. We are interested in inducing a LISP-like function program that, when executed by an abstract machine, is assigned to an execution track T, so that Tuttle and T are equivalent according to an input specification. We present the abstract machine as another labeled transit system whose properties (M, I, \u03b5) are determined for different actions, whereas M are the possible memory state variations, I is the group of supported statements, and vice versa."}, {"heading": "4 Method", "text": "The proposed program introduction procedure is based on two essential steps. First, we explain how a particular functional program can be optimized to minimize the loss L (\u03c1). Second, we explain how the space of possible program structures can be efficiently searched through the use of gradient information. An architectural overview of the \u03c0 machine can be found in Figure 1."}, {"heading": "4.1 Program optimisation", "text": "It is not only a matter of time, but also of the time in which the data is updated in relation to the execution of the individual parameters (reverse gear). A key observation for the development of the numerical machine is that computational graphs and functional programs are equivalent to describe the composition of the pure functions applied to the input data. For example, Figure 2 shows how a logistic regression can be classified and how a functional program is presented. Therefore, a functional program, a functional program can also be optimized by executing the program (forward pass), measuring the error signal and then updating the program (backward pass)."}, {"heading": "4.2 Structure search", "text": "We represent the space of possible program structures as a graph G = (TAST, E), where each node Ti, TAST (priority) is a valid program abstract syntax tree (AST). There is an edge from Ti to Tj if and only if Tj can be reached by replacing exactly one of the candidates in Ti with a subtree Ts of depth 1. The program induction procedure always starts with an empty program. Thus, we frame structure search as a pathfinding problem that can be solved by using A * search function. The total cost function we use is ftotal (p) = C (p) + L (p), where L (p) is the loss function defined in Equation (1) and C (p) is a function that measures the complexity of the program."}, {"heading": "5 Experimental results", "text": "To assess the effectiveness of the \u03c0 machine, we apply it to three different scenarios. First, we look at model learning for a physical system. We show that the \u03c0 machine successfully induces basic physical laws from observation data. Second, we show how a program can be induced to explain the behavior of policies learned from a DQN network. This experiment is based on our view that the basic learning based on neural networks and the explanatory layer play complementary roles. As is now widely known, there are numerous advantages in conducting end-to-end policy learning, such as DQN learning from raw video. After we have done this, there is also a need to explain the behavior of the learned policy in terms of custom properties of interest, hence as a program defined in terms of custom detectors, Dv. Finally, we apply the cipher to a learning-by-demonstration task that is explained in the physical behavior of manipulating the object."}, {"heading": "5.1 Physical systems", "text": "The transition dynamics of a dynamic system second order are described as x (t) = k1x (t) + k2x (t), where x (t) are the state of the system at the time t and k1, k2 are system coefficients. A diagram of these two systems is shown in Figure 3 (left). We set A = {accel (\u03b8)}, in which the authors show the learning of physical laws associated with classic mechanical systems, including the simple pendulum and linear oscillator. The observation trace for each system is created by simulating the dynamic for 1s at 100 Hz. We specify the effect errors function as \u03c3act = - Influence errors-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-Effect-"}, {"heading": "5.2 Deep Q-network", "text": "We look at the explanation of the behavior of a DQN trained to play the ATARI Pong game. However, we are interested in the question: how does the network control the position of the paddle to hit the ball when it is on the right side of the screen. A diagram of the experimental setup is shown in Figure 4 (left). The behavior of the DQN is observed during a single game. As the environment is deterministic, the state transition function that generates the traces of observation for this experiment is the political aspects that the DQN has learned. We would like to explain the behavior of the DQN in relation to the position of the opponent, the ball, and the DQN agent (i.e. not only in relation to RAM memory values, for example) that the political decisions that the DQN behavior has learned. We would like to explain the behavior of the DQN in relation to the position of the opponent, the ball, and the DQN agent (i.e. not only in relation to RAM memory values, for example) best."}, {"heading": "5.3 Learning by demonstration", "text": "The work in the collaborative human-robot interaction [10] suggests that a programmatic description of the task allows robots to better ground symbols in their physical instances and improve their perception skills. We are looking at a learning-by-demonstration scenario in which a person demonstrates how to build a tower in a virtual simulated 2D environment. A typical demonstration is shown in Figure 5 (left). Our goal is to learn a program that describes the demonstration in a way that could be used by the robot later on. We are interested in how a person moves the cubes throughout the demonstration. So we define A = {pick (\u03b8), location (\u03b8)} where it is a 2D location. We specify the action and length error functions as an action (a,.,.,.)........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"}, {"heading": "6 Discussion", "text": "The \u03c0 machine can be seen as a framework for the design of automatic network architectures [37, 38], since different models can be expressed as concise LISP-like programs (see Figure 2). Deep learning methods have been proposed to limit the search space of possible programs that pose the greatest challenge [29], but how they can be applied to more generic frameworks such as the \u03c0 machine is an open question. The specification of variable detectors not only addresses this problem, but allows the user to make targeted and informed queries about the observed data track. Such detectors can also be learned unattended from raw data [39, 15]."}, {"heading": "7 Conclusion", "text": "We propose a novel architecture, the \u03c0 machine, to generate LISP-like functional programs from observed data tracks through backpropagation, stochastic gradient descent, and A * search. Experimental results show that the \u03c0 machine can efficiently and successfully generate programs from short data tracks."}], "references": [{"title": "Distilling free-form natural laws from experimental data", "author": ["Michael Schmidt", "Hod Lipson"], "venue": "Science, 324(5923):81\u201385,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Foundations of Neuroeconomic Analysis", "author": ["Paul Glimcher"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Learning spatiotemporal graphs of human activities", "author": ["William Brendel", "Sinisa Todorovic"], "venue": "In Computer vision (ICCV),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Counterfactual reasoning and learning systems: the example of computational advertising", "author": ["L\u00e9on Bottou", "Jonas Peters", "Joaquin Quinonero Candela", "Denis Xavier Charles", "Max Chickering", "Elon Portugaly", "Dipankar Ray", "Patrice Y Simard", "Ed Snelson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Principles of Model Checking", "author": ["Christel Baier", "Joost-Pieter Katoen"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Human-level concept learning through probabilistic program induction", "author": ["Brenden M. Lake", "Ruslan Salakhutdinov", "Joshua B. Tenenbaum"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Neural turing machines", "author": ["Alex Graves", "Greg Wayne", "Ivo Danihelka"], "venue": "arXiv preprint arXiv:1410.5401,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Hybrid computing using a neural network with dynamic external", "author": ["Alex Graves", "Greg Wayne", "Malcolm Reynolds", "Tim Harley", "Ivo Danihelka", "Agnieszka Grabska- Barwi\u0144ska", "Sergio G\u00f3mez Colmenarejo", "Edward Grefenstette", "Tiago Ramalho", "John Agapiou"], "venue": "memory. Nature,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Physical symbol grounding and instance learning through demonstration and eye tracking", "author": ["Svetlin Penkov", "Alejandro Bordallo", "Subramanian Ramamoorthy"], "venue": "In Robotics and Automation,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2017}, {"title": "Interpretable classifiers using rules and bayesian analysis: Building a better stroke prediction model", "author": ["Benjamin Letham", "Cynthia Rudin", "Tyler H McCormick", "David Madigan"], "venue": "The Annals of Applied Statistics,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Scalable bayesian rule lists", "author": ["Hongyu Yang", "Cynthia Rudin", "Margo Seltzer"], "venue": "arXiv preprint arXiv:1602.08610,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Visualizing and understanding convolutional networks", "author": ["Matthew D Zeiler", "Rob Fergus"], "venue": "In European conference on computer vision,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Explaining how a deep neural network trained with end-to-end learning steers a car", "author": ["Mariusz Bojarski", "Philip Yeres", "Anna Choromanska", "Krzysztof Choromanski", "Bernhard Firner", "Lawrence Jackel", "Urs Muller"], "venue": "arXiv preprint arXiv:1704.07911,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2017}, {"title": "Interpretable learning for self-driving cars by visualizing causal attention", "author": ["Jinkyu Kim", "John Canny"], "venue": "arXiv preprint arXiv:1703.10631,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2017}, {"title": "Graying the black box: Understanding dqns", "author": ["Tom Zahavy", "Nir Ben-Zrihem", "Shie Mannor"], "venue": "arXiv preprint arXiv:1602.02658,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Rationalization: A neural machine translation approach to generating natural language explanations", "author": ["Brent Harrison", "Upol Ehsan", "Mark O Riedl"], "venue": "arXiv preprint arXiv:1702.07826,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2017}, {"title": "Generating visual explanations", "author": ["Lisa Anne Hendricks", "Zeynep Akata", "Marcus Rohrbach", "Jeff Donahue", "Bernt Schiele", "Trevor Darrell"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2016}, {"title": "Rationalizing neural predictions", "author": ["Tao Lei", "Regina Barzilay", "Tommi Jaakkola"], "venue": "arXiv preprint arXiv:1606.04155,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Why should i trust you?: Explaining the predictions of any classifier", "author": ["Marco Ribeiro", "Sameer Singh", "Carlos Guestrin"], "venue": "In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Algorithmic Program Debugging", "author": ["Ehud Y. Shapiro"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1983}, {"title": "Combinatorial sketching for finite programs", "author": ["Armando Solar-Lezama", "Liviu Tancau", "Rastislav Bodik", "Sanjit Seshia", "Vijay Saraswat"], "venue": "ACM SIGOPS Operating Systems Review,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Learning to transduce with unbounded memory", "author": ["Edward Grefenstette", "Karl Moritz Hermann", "Mustafa Suleyman", "Phil Blunsom"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Making neural programming architectures generalize via recursion", "author": ["Jonathon Cai", "Richard Shin", "Dawn Song"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2017}, {"title": "Program Induction by Rationale Generation:Learning to Solve and Explain Algebraic Word Problems", "author": ["Wang Ling", "Dani Yogatama", "Chris Dyer", "Phil Blunsom"], "venue": "arXiv preprint arXiv:1705.04146,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2017}, {"title": "Differentiable functional program interpreters", "author": ["John Kser", "Marc Brockschmidt", "Alexander Gaunt", "Daniel Tarlow"], "venue": "arXiv preprint arXiv:1611.01988v2,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2017}, {"title": "Robustfill: Neural program learning under noisy i/o", "author": ["Jacob Devlin", "Jonathan Uesato", "Surya Bhupatiraju", "Rishabh Singh", "Abdel-rahman Mohamed", "Pushmeet Kohli"], "venue": "arXiv preprint arXiv:1703.07469,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2017}, {"title": "Deepcoder: Learning to write programs", "author": ["Matej Balog", "Alexander L Gaunt", "Marc Brockschmidt", "Sebastian Nowozin", "Daniel Tarlow"], "venue": "arXiv preprint arXiv:1611.01989,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "A syntactic neural model for general-purpose code generation", "author": ["Pengcheng Yin", "Graham Neubig"], "venue": "arXiv preprint arXiv:1704.01696,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2017}, {"title": "Chainer: a next-generation open source framework for deep learning. In Proceedings of workshop on machine learning systems (LearningSys) in the twenty-ninth annual conference on neural information processing systems", "author": ["Seiya Tokui", "Kenta Oono", "Shohei Hido", "Justin Clayton"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Theano: A cpu and gpu math compiler in python", "author": ["James Bergstra", "Olivier Breuleux", "Fr\u00e9d\u00e9ric Bastien", "Pascal Lamblin", "Razvan Pascanu", "Guillaume Desjardins", "Joseph Turian", "David Warde-Farley", "Yoshua Bengio"], "venue": "In Proc. 9th Python in Science Conf,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2010}, {"title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems", "author": ["Mart\u00edn Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin"], "venue": "arXiv preprint arXiv:1603.04467,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2016}, {"title": "Autograd: Effortless gradients in numpy", "author": ["Dougal Maclaurin", "David Duvenaud", "Ryan P Adams"], "venue": "In ICML 2015 AutoML Workshop,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2015}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2011}, {"title": "Human-level control through deep reinforcement learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Andrei A Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves", "Martin Riedmiller", "Andreas K Fidjeland", "Georg Ostrovski"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2015}, {"title": "Neural architecture search with reinforcement learning", "author": ["Barret Zoph", "Quoc Le"], "venue": "In International Conference on Learning Representations (ICLR), April 2017", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2017}, {"title": "Deeparchitect: Automatically designing and training deep architectures", "author": ["Renato Negrinho", "Geoff Gordon"], "venue": "arXiv preprint arXiv:1704.08792,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2017}, {"title": "Towards deep symbolic reinforcement learning", "author": ["Marta Garnelo", "Kai Arulkumaran", "Murray Shanahan"], "venue": "arXiv preprint arXiv:1609.05518,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Learning models of transition systems has been a core concern within machine learning, with applications ranging from system identification of dynamical systems [1] and inference of human choice behaviour [2, 3] to reverse engineering the behaviour of a device or computer program from observations and traces [4].", "startOffset": 161, "endOffset": 164}, {"referenceID": 1, "context": "Learning models of transition systems has been a core concern within machine learning, with applications ranging from system identification of dynamical systems [1] and inference of human choice behaviour [2, 3] to reverse engineering the behaviour of a device or computer program from observations and traces [4].", "startOffset": 205, "endOffset": 211}, {"referenceID": 2, "context": "Learning models of transition systems has been a core concern within machine learning, with applications ranging from system identification of dynamical systems [1] and inference of human choice behaviour [2, 3] to reverse engineering the behaviour of a device or computer program from observations and traces [4].", "startOffset": 205, "endOffset": 211}, {"referenceID": 3, "context": "There is also the need to explain the model in terms of counterfactual reasoning [5], e.", "startOffset": 81, "endOffset": 84}, {"referenceID": 4, "context": ", what would we expect the system to do if a certain variable were changed or removed, or model checking [6] of longer term properties including safety and large deviations in performance.", "startOffset": 105, "endOffset": 108}, {"referenceID": 5, "context": "Recent works have demonstrated the usefulness of program representations in capturing human-like concepts [7].", "startOffset": 106, "endOffset": 109}, {"referenceID": 6, "context": "Inspired by differentiable neural computers [8, 9], the \u03c0-machine, as shown in Figure 1, is composed of a memory unit and a controller capable of learning programs from data by exploiting the scalability of stochastic gradient descent.", "startOffset": 44, "endOffset": 50}, {"referenceID": 7, "context": "Inspired by differentiable neural computers [8, 9], the \u03c0-machine, as shown in Figure 1, is composed of a memory unit and a controller capable of learning programs from data by exploiting the scalability of stochastic gradient descent.", "startOffset": 44, "endOffset": 50}, {"referenceID": 0, "context": "The learning procedure has access to relevant variables, but it does not have any other prior knowledge regarding physical laws which it has discovered in the same sense as in [1] although far more computationally tractably.", "startOffset": 176, "endOffset": 179}, {"referenceID": 8, "context": ", in natural language commands) in the embodied sensory signals that robots actually work with, as in [10].", "startOffset": 102, "endOffset": 106}, {"referenceID": 9, "context": "There is recognition that Bayesian rule lists [11, 12], decision trees and probabilistic graphical models are interpretable to the extent that they impose strong structural constraints on models of the observed data and allow for various types of queries, including introspective and counterfactual ones.", "startOffset": 46, "endOffset": 54}, {"referenceID": 10, "context": "There is recognition that Bayesian rule lists [11, 12], decision trees and probabilistic graphical models are interpretable to the extent that they impose strong structural constraints on models of the observed data and allow for various types of queries, including introspective and counterfactual ones.", "startOffset": 46, "endOffset": 54}, {"referenceID": 11, "context": "Zeiler and Fergus [13] introduced deconvolutional networks in order to visualise the layers of convolutional networks and provide a more intuitive understanding of why they perform well.", "startOffset": 18, "endOffset": 22}, {"referenceID": 12, "context": "Similar approaches can be seen in [14, 15], in the context of autonomous driving.", "startOffset": 34, "endOffset": 42}, {"referenceID": 13, "context": "Similar approaches can be seen in [14, 15], in the context of autonomous driving.", "startOffset": 34, "endOffset": 42}, {"referenceID": 14, "context": "[16] describe Semi-Aggregated Markov Decision Process (SAMDP) in order to analyse and understand the behaviour of a DQN based agent.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Methods for textual rationalisation of the predictions made by deep models have also been proposed [17\u201319].", "startOffset": 99, "endOffset": 106}, {"referenceID": 16, "context": "Methods for textual rationalisation of the predictions made by deep models have also been proposed [17\u201319].", "startOffset": 99, "endOffset": 106}, {"referenceID": 17, "context": "Methods for textual rationalisation of the predictions made by deep models have also been proposed [17\u201319].", "startOffset": 99, "endOffset": 106}, {"referenceID": 18, "context": "[20], who provide \u201ctextual or visual artefacts\u201d explaining the prediction of any classifier by treating it as a black-box.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "Similarly to the way in which [20] utilise local classifiers composed together to explain a more complex model, we present an approach to incrementally constructing functional programs that explain a complex transition system from more localised predicates of interest to the user.", "startOffset": 30, "endOffset": 34}, {"referenceID": 19, "context": "Following classic and pioneering work such as by Shapiro [21] who used inductive inference in a logic programming setting, others have developed methods based on a variety of methods ranging from SAT solvers [22] to genetic algorithms [1], which tend to scale poorly hence often become restricted to a narrow class of programs.", "startOffset": 57, "endOffset": 61}, {"referenceID": 20, "context": "Following classic and pioneering work such as by Shapiro [21] who used inductive inference in a logic programming setting, others have developed methods based on a variety of methods ranging from SAT solvers [22] to genetic algorithms [1], which tend to scale poorly hence often become restricted to a narrow class of programs.", "startOffset": 208, "endOffset": 212}, {"referenceID": 0, "context": "Following classic and pioneering work such as by Shapiro [21] who used inductive inference in a logic programming setting, others have developed methods based on a variety of methods ranging from SAT solvers [22] to genetic algorithms [1], which tend to scale poorly hence often become restricted to a narrow class of programs.", "startOffset": 235, "endOffset": 238}, {"referenceID": 6, "context": "These models can induce programs through stochastic gradient descent by optimising performance on input/output examples [8, 9, 23] or synthetic execution traces [24\u201326].", "startOffset": 120, "endOffset": 130}, {"referenceID": 7, "context": "These models can induce programs through stochastic gradient descent by optimising performance on input/output examples [8, 9, 23] or synthetic execution traces [24\u201326].", "startOffset": 120, "endOffset": 130}, {"referenceID": 21, "context": "These models can induce programs through stochastic gradient descent by optimising performance on input/output examples [8, 9, 23] or synthetic execution traces [24\u201326].", "startOffset": 120, "endOffset": 130}, {"referenceID": 22, "context": "These models can induce programs through stochastic gradient descent by optimising performance on input/output examples [8, 9, 23] or synthetic execution traces [24\u201326].", "startOffset": 161, "endOffset": 168}, {"referenceID": 23, "context": "These models can induce programs through stochastic gradient descent by optimising performance on input/output examples [8, 9, 23] or synthetic execution traces [24\u201326].", "startOffset": 161, "endOffset": 168}, {"referenceID": 24, "context": "Interestingly, paradigms from functional programming such as pure functions and immutable data structures have been shown to improve performance of neural interpreters [27].", "startOffset": 168, "endOffset": 172}, {"referenceID": 25, "context": "Usually, these types of approaches require large amounts of labelled data - either program input/output examples [28, 29] or input paired with the desired output program code [30].", "startOffset": 113, "endOffset": 121}, {"referenceID": 26, "context": "Usually, these types of approaches require large amounts of labelled data - either program input/output examples [28, 29] or input paired with the desired output program code [30].", "startOffset": 113, "endOffset": 121}, {"referenceID": 27, "context": "Usually, these types of approaches require large amounts of labelled data - either program input/output examples [28, 29] or input paired with the desired output program code [30].", "startOffset": 175, "endOffset": 179}, {"referenceID": 18, "context": "While these characteristics are of course related, we take a view similar to that of [20], arguing that it is possible to build from locally valid program fragments which provide useful insight into the black-box processes generating the data.", "startOffset": 85, "endOffset": 89}, {"referenceID": 28, "context": "Neural networks are naturally expressed as computational graphs which are the most fundamental abstraction in computational deep learning frameworks [31\u201333].", "startOffset": 149, "endOffset": 156}, {"referenceID": 29, "context": "Neural networks are naturally expressed as computational graphs which are the most fundamental abstraction in computational deep learning frameworks [31\u201333].", "startOffset": 149, "endOffset": 156}, {"referenceID": 30, "context": "Neural networks are naturally expressed as computational graphs which are the most fundamental abstraction in computational deep learning frameworks [31\u201333].", "startOffset": 149, "endOffset": 156}, {"referenceID": 31, "context": "The \u03c0-machine performs reverse-mode automatic differentiation, similarly to Autograd [34], by traversing the call trace \u03c7, and post-multiplying Jacobian matrices.", "startOffset": 85, "endOffset": 89}, {"referenceID": 32, "context": "Once the gradient \u2207pL(\u03c1) of the loss function with respect to each input parameter p \u2208 xp is calculated we utilise AdaGrad [35] to update the values of all parameters after each program execution.", "startOffset": 123, "endOffset": 127}, {"referenceID": 32, "context": "The temporary parameter ptemp is also updated with AdaGrad [35].", "startOffset": 59, "endOffset": 63}, {"referenceID": 8, "context": "The complexity function C(\u03c1) is the weighted sum of (i) maximum depth of the program AST; (ii) the number of free parameters; (iii) the number of variables used by the program; the weights of which we set to wC = [10, 5, 1].", "startOffset": 213, "endOffset": 223}, {"referenceID": 3, "context": "The complexity function C(\u03c1) is the weighted sum of (i) maximum depth of the program AST; (ii) the number of free parameters; (iii) the number of variables used by the program; the weights of which we set to wC = [10, 5, 1].", "startOffset": 213, "endOffset": 223}, {"referenceID": 0, "context": "The complexity function C(\u03c1) is the weighted sum of (i) maximum depth of the program AST; (ii) the number of free parameters; (iii) the number of variables used by the program; the weights of which we set to wC = [10, 5, 1].", "startOffset": 213, "endOffset": 223}, {"referenceID": 0, "context": "We have recreated an experiment described in Schmidt and Lipson [1], where the authors show the learning of physical laws associated with classical mechanical systems including the simple pendulum and linear oscillator.", "startOffset": 64, "endOffset": 67}, {"referenceID": 0, "context": "Schmidt and Lipson [1] achieve similar execution times, but distributed over 8 quad core computers (32 cores in total).", "startOffset": 19, "endOffset": 22}, {"referenceID": 33, "context": "3 [36].", "startOffset": 2, "endOffset": 6}, {"referenceID": 8, "context": "Work in collaborative human-robot interaction [10] suggests that programmatic description of the task enables robots to better ground symbols to their physical instances, improving their perceptual capabilities.", "startOffset": 46, "endOffset": 50}, {"referenceID": 34, "context": "The \u03c0-machine can be viewed as a framework for automatic network architecture design [37, 38], as different models can be expressed as concise LISP-like programs (see Figure 2).", "startOffset": 85, "endOffset": 93}, {"referenceID": 35, "context": "The \u03c0-machine can be viewed as a framework for automatic network architecture design [37, 38], as different models can be expressed as concise LISP-like programs (see Figure 2).", "startOffset": 85, "endOffset": 93}, {"referenceID": 26, "context": "Deep learning methods for limiting the search space of possible programs, which poses the greatest challenge, have been proposed [29], but how they can be applied to more generic frameworks such as the \u03c0-machine is an open question.", "startOffset": 129, "endOffset": 133}, {"referenceID": 36, "context": "Such detectors can also be learnt from raw data in an unsupervised fashion [39, 15].", "startOffset": 75, "endOffset": 83}, {"referenceID": 13, "context": "Such detectors can also be learnt from raw data in an unsupervised fashion [39, 15].", "startOffset": 75, "endOffset": 83}], "year": 2017, "abstractText": "Explaining and reasoning about processes which underlie observed black-box phenomena enables the discovery of causal mechanisms, derivation of suitable abstract representations and the formulation of more robust predictions. We propose to learn high level functional programs in order to represent abstract models which capture the invariant structure in the observed data. We introduce the \u03c0-machine (program-induction machine) \u2013 an architecture able to induce interpretable LISPlike programs from observed data traces. We propose an optimisation procedure for program learning based on backpropagation, gradient descent and A* search. We apply the proposed method to three problems: system identification of dynamical systems, explaining the behaviour of a DQN agent and learning by demonstration in a human-robot interaction scenario. Our experimental results show that the \u03c0machine can efficiently induce interpretable programs from individual data traces.", "creator": "LaTeX with hyperref package"}}}