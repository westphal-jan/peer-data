{"id": "1705.08504", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2017", "title": "Interpreting Blackbox Models via Model Extraction", "abstract": "Interpretability has become an important issue as machine learning is increasingly used to inform consequential decisions. We propose an approach for interpreting a blackbox model by extracting a decision tree that approximates the model. Our model extraction algorithm avoids overfitting by leveraging blackbox model access to actively sample new training points. We prove that as the number of samples goes to infinity, the decision tree learned using our algorithm converges to the exact greedy decision tree. In our evaluation, we use our algorithm to interpret random forests and neural nets trained on several datasets from the UCI Machine Learning Repository, as well as control policies learned for three classical reinforcement learning problems. We show that our algorithm improves over a baseline based on CART on every problem instance. Furthermore, we show how an interpretation generated by our approach can be used to understand and debug these models.", "histories": [["v1", "Tue, 23 May 2017 19:47:52 GMT  (35kb,D)", "http://arxiv.org/abs/1705.08504v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["osbert bastani", "carolyn kim", "hamsa bastani"], "accepted": false, "id": "1705.08504"}, "pdf": {"name": "1705.08504.pdf", "metadata": {"source": "CRF", "title": "Interpreting Blackbox Models via Model Extraction", "authors": ["Osbert Bastani", "Carolyn Kim", "Hamsa Bastani"], "emails": ["obastani@cs.stanford.edu", "ckim@cs.stanford.edu", "hsridhar@stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is not so that we would be able to behave in a way that is customary in the real world. (...) It is not so that we would be able to move in the real world. (...) It is not so that we would be able to move in the real world. (...) It is not so that we would be able to move in the real world. (...) It is not so that we would be able to live in the real world. (...) In the real world of the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the world in the world, in the world in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world in the real world, in the real world in the real world. (...) It is not so that we would be able to move in the real world, in the real world, in the real world, in the real world in the real world, in the real world in the real world, in the real world in the real world, in the real world in the real world, in the real world in the real world in the real world, in the real world in the real world in the real world, in the real world in the real world, in the real world in the real world in the real world, in the real world in the real world in the real world, in the real world in the real world in the real world, in the real world in the real world in the real world, in the real world in the real world in the real world, in the real world in the real world, in the real world in the real world in the real world, in the real world in the real world in the real world, in the real world, in the real world in the real world in the real world in the real world, in the real world in the real world, in the real world in the real world, in the real world in the real world in the real world in the real world, in the real world in the real world in the real world in the real world, in the real world in the real world in the real world"}, {"heading": "1.1 Related Work", "text": "A number of approaches have been proposed to improve interpretative capability, mostly in three directions: (i) learning interpretable models, (ii) providing explanations for individual model forecasts, and (iii) providing an overall interpretation of a model that is considered highly interpretable but often not applied in practice, producing sparse rule lists that resemble decision trees but are not greedy, enabling them to learn more precise models without sacrificing interpretative capability."}, {"heading": "2 Problem Formulation", "text": "Our algorithm learns axially oriented decision trees. We start by specifying the notation = Y = function (more axially oriented constraint is a constraint C = (xi \u2264 t), where i-d] and t-R. General constraints can be formed from existing constraints using negations \u00ac C, conjunctions C1-C2 and disjunctions C1-C2. The practicable set of C is F (C) = {x-X | x satisfies C}. A decision tree T is a binary tree. Each internal node N = (NL, NR, C) of T has a left child node NL and a right child node NR and is labeled with an axially oriented constraint C = (xi \u2264 t). Each leaf node N = (y) of T is associated with a designation y-x-x. We use NT to name the root node of T."}, {"heading": "3 Decision Tree Extraction Algorithm", "text": "Our algorithm is greedy, both in terms of scalability and because it naturally fits the interpretability, since more relevant features are higher up in the tree. First, we describe the input distribution P that our data generation algorithm constructs; then, we describe the exact greedy decision tree T *, in which all decisions are made exactly according to the distribution P (though greedy); note that we cannot construct T * because we treat f as a black box; finally, we describe how our algorithm estimates T \u0445 using i.i.d. samples from P. In Section 4, we show how the estimated tree converges asymptotically to T *."}, {"heading": "3.1 Input Distribution", "text": "Our algorithm constructs a distribution P over X by adapting a mixture of axis-oriented Gaussian distributions to the training data using expectation maximization. It has parameters? Rk, which define a categorical distribution via [K], and parameters?"}, {"heading": "3.2 Exact Greedy Decision Tree", "text": "We describe the exact greedy decision tree of size k, which is very similar to CART [11]. It is initialized to a tree with a single leaf node, where y is the majority name according to P. With each iteration, a leaf node N = (y) in the current tree is replaced by an internal node N \u00b2 = (NL, NR, C), where NL = (yL) and NR = (yR) are leaf nodes, and C = (xi \u00b2) in the current tree, where (i \u00b2, t \u00b2) = arg max i \u00b2 (d), t \u00b2 R (i, t), where the gainG (i, t) = gain (f, CN \u00b2 (xi \u00b2 t) + gain (f, CN \u00b2) = gain (xi > t) \u2212 gain (f, CN) (1) = Prain (f, C) = \u2212 y \u00b2 Princip (P \u00b2) = gain (x \u00b2) = gain (G) or gain (G \u00b2)."}, {"heading": "3.3 Estimated Greedy Decision Tree", "text": "Considering that our algorithm constructs a greedy decision tree in the same way as the construction of the exact greedy decision tree, except that (1) and (3) are calculated from n i.i.d. samples; these estimates are made from a separate set of i.i.d. samples to ensure the impartiality of the tree parameters. Next, we describe how our algorithm samples x \u00b2 P | C, where C is a conjunction of axis-aligned constraints: C = (xi1 \u2264 t1)... samples (xik \u2264 tk)."}, {"heading": "4 Theoretical Guarantees", "text": "We show that our decision tree extraction has no effect on the exact tree or approximate tree, which is much larger than the tree itself. (A related result is [20], but their analysis is limited to discrete characteristics, for which the convergence is much easier to analyze. (We start by describing our assumptions. (First, we make mild assumptions about the distribution P. \") To satisfy these assumptions, we can set the Gaussian mixture models used by our algorithms to X.\" (X) We assume that exact assumptions about the distribution P \"(x) = 0 exist for the exact distribution of the trees. (To satisfy these assumptions, we can set the Gaussian mixture models to X.\") = {x \"Rd.\" Rd \"xmax.\" xmax, \"for some xmax\" R. Intuitively, for relatively large xmax. \"This modification should not affect the tree itself, nor the exact tree."}, {"heading": "5 Evaluation", "text": "We implement our algorithm based on scikit-learn [14] and evaluate it in two ways. First, we show that it exceeds a baseline using CART [11], a popular algorithm for learning decision trees. Second, we show how extracted decision trees can be used to understand and debug models."}, {"heading": "5.1 Comparison to Baseline Decision Tree Extraction Algorithm", "text": "First, we compare our algorithms with a baseline.dataset. We examine two applications for classifying GSE. First, we interpret supervised learning models. We train both a random forest and a neural network on a number of classification and regression tasks, primarily from the UCI Machine Learning Repository [7]. We randomly divide each dataset into 70% training sets and 30% testing sets; all results will be over 10 splits.We estimate a Gaussian mixing model P with the training set, with 50 components for smaller datasets (< 200 samples), and K = 100 components for larger datasets. Then we extract a decision tree of size for most k = 31 (i.e. we show how our results will vary later) from the model f to P, using n = 2000 samples for estimation (1) and (3)."}, {"heading": "5.2 Examples of Use Cases", "text": "It is a question of the extent to which people are able to outdo themselves, and the question to what extent they are able to outdo themselves, and the question to what extent they are able to outdo themselves. (...) It is a question to what extent they are able to outdo themselves. (...) It is a question to what extent people are able to outdo themselves. (...) It is a question to what extent they are able to outdo themselves. (...) It is a question to what extent they are able to outdo themselves. (...) It is a question to what extent they are able to outdo themselves. \"(...)"}, {"heading": "6 Conclusions", "text": "We have proposed an approach to interpreting black box models based on the extraction of decision trees, and have shown how they can be used to interpret random forests, neural networks, and control policies. Important guidelines for future work include the development of model extraction algorithms using more meaningful input distributions, and the development of new methods to gain insights from the extracted decision trees."}, {"heading": "A Proofs of Main Results", "text": "In this section we give proofs for theorem 1 and conclusion 1."}, {"heading": "A.1 Proof of Main Lemmas", "text": "In essence, these are the inductive steps that are necessary to prove our main results. The function p is dependent on one parameter n-n; in applications of this problem, p-value is an estimate of p (x) and p-value (x), which is calculated by our algorithm on n-random samples. Let's assume that for each x-value probability x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-"}, {"heading": "A.2 Proof of Theorem 1", "text": "We assume that a sufficient number of samples are taken for each of these nodes, so that the estimates of the following information with a probability of at least 1 \u2212 4k (d + m) are correct (where m = | Y |): \u2022 For each of these nodes, the dimension i [d] is determined along the branch. \u2022 For each of these nodes, the marking i [d] is selected along the branch. \u2022 For each of these nodes, the marking y is assigned. \u2022 First, we describe how to ensure that the optimal dimension i [d] is selected along the branch."}, {"heading": "A.3 Proof of Corollary 1", "text": "We show that for the claimed value of n, the decision tree T extracted by our algorithm is (, \u03b4) exact. According to the proof of Thereom 1, it is sufficient to show that for each node N in T *,..., x (n) [, pN \u2212 p] (N), 1 \u2264 2k with a probability of at least \u03b4 \u00b2, orPrx \u00b2 P [CN] \u2264 \u03b3 = k. Consider the inequality Prx (1),..., x (n) [, pN \u2212 p, N], 1 \u0438. \"Let us remember that at the root N = NT, this inequality applies to all subsequent weights."}, {"heading": "A.4 Gap for Random Forests", "text": "We briefly discuss why intuitively axis-aligned random forests should fulfill the premise of episode 1. In particular, we note that axis-aligned random forests are piecemeal constant and also the parts are axis-aligned. Therefore, the label frequencies Prx \u0445 P [f (x) = y | C] are piecemeal linear, so that the gain in (1) is square. As we have shown in term 1, we can extract a square root from the gain without affecting our theoretical results, in which case the gain becomes nearly linear again. Another problem is that we integrate against p (x) and the presence of the weighting term Prx \u0445 P [C]. However, as long as p (x) is fairly uniform, its effect on the gain is fairly negligible, so we expect the premise to be fulfilled."}, {"heading": "B Proofs of Technical Lemmas", "text": "In this section we will demonstrate the technical shortcomings required for our proofs of Lemma 2, Theorem 1 and Conclusion 1."}, {"heading": "B.1 Proof of Existence of a Gap", "text": "Let g: R \u2192 [0, 1] be a continuous function with limited support, and assume that its global maximization \u043a = arg max t-R g (t) is unique, then for each \"> 0\" there is such a \"g\" constraint that g (\", g\") is smooth. Let tmax be a constraint on the support of g, i.e., g (t) = 0 if | t | > tmax. Let \"> 0 be arbitrary, and let letA\" = \"t\" R | | t | \u2264 tmax \"and\" F (t) \u2212 F (t). Note that A \"is a compact set so that g reaches its maximum A, i.e. t.\" = arg max t \"A\" g \"g\" (t), followed by the result for \"g\" (t) \u2212 g \"(t) 2 > 0,0,2 that we divide by definition 2."}, {"heading": "B.2 Bound on Intrinsic Error", "text": "The following problem allows us to narrow down the intrinsic error depending on the fact that the distributions have probability density functions that are limited by the L1 norm. Lemma 3. Let X Rd, and let P and P be distributions over X, and let p (x) and p (x) be unnormalized probability density functions for P and P that satisfy the p-p-p-1 values. Let \u03b2: X-R \u2192 [0, 1] be any function and letg (t) = B (x, t) \u00b7 p (x) dxg (t) = B (x, t) \u00b7 p-p (x) dx.Then we have a g-g-p-p (x)."}, {"heading": "B.3 Bound on Estimation Error", "text": "The following problem allows us to define the error of estimation in terms of the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the number of points, the points, the number of the points, the points, the points of the points, the points of the points, the points of the points, the points of the points, the points of the points, the points of the points of the points, the points of the points of the points, the points of the points of the points, the points of the points of the points, the points of the points of the points, the points of the points, the points of the points of the points of the points, the points of the points of the points of the points, the points of the points of the points of the points, the points of the points of the points of the points, the points of the points of the points of the points of the points, the points of the points of the points of the points, the points of the points of the points of the points of the points of the points of the points, the points of the points of the points of the points, the points of the points of the points of the points of the points of the points of the points of the points, the points of the points of the points of the points of the points of the points, the points of the points of the points of the points of the points of the points of the points of the points, the points of the points of the points of the points of the points of the points, the points of the points of the points of the points of the points of the points of the points, the points of the points of the points of the points of the points of the points of the points of the points of"}, {"heading": "B.4 Bound on Error of Maximizers", "text": "Lemma 5. Let P be a probability distribution over R, and let F (t) be a cumulative distribution function for P. Let us suppose that g: R \u2192 R according to P is incomplete, and h: R \u2192 R suffices that g (t) h = arg max t (t) h h (t) h (t) h (t) h (t).Then we have | F (t) \u2212 F (t) g (t) h (t).Proof. By definition of the L (t) standard we have g (t) g (t) g (t) h (t) \u04452h (t) \u2212 g (t) \u04322. The combination of these two results in g (t) \u2212 g (t \u00b2 h)."}, {"heading": "B.5 Bound on Error of Probabiliy Density Functions", "text": "The following Lemma allows us to bind the L1 error of the estimated probability density function. Lemma 6. Let X allow Rd, P and P distributions over X, and let p (x) and p (x) be unnormalized probability density functions for P and P, or satisfactory p \u2212 p. Let i [d], Pi be the boundary distribution of P along dimension i, let Fi be an unnormalized cumulative distribution function for Pi, and let t, t \u2212 R be satisfactory | Fi (t) \u2212 Fi (t) \u2212 Fi (t) | \u2264. \"Let i [d], and let p \u2212 p (x) = p (x) \u00b7 I [xi \u2264 t] p (x)."}], "references": [{"title": "Learning certifiably optimal rule lists for categorical data", "author": ["Elaine Angelino", "Nicholas Larus-Stone", "Daniel Alabi", "Margo Seltzer", "Cynthia Rudin"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2017}, {"title": "Do deep nets really need to be deep? In Advances in neural information processing", "author": ["Jimmy Ba", "Rich Caruana"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Neuronlike adaptive elements that can solve difficult learning control problems", "author": ["Andrew G Barto", "Richard S Sutton", "Charles W Anderson"], "venue": "IEEE transactions on systems, man, and cybernetics,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1983}, {"title": "Classification and regression trees", "author": ["Leo Breiman", "Jerome Friedman", "Charles J Stone", "Richard A Olshen"], "venue": "CRC press,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1984}, {"title": "API design for machine learning software: experiences from the scikit-learn project", "author": ["Lars Buitinck", "Gilles Louppe", "Mathieu Blondel", "Fabian Pedregosa", "Andreas Mueller", "Olivier Grisel", "Vlad Niculae", "Peter Prettenhofer", "Alexandre Gramfort", "Jaques Grobler", "Robert Layton", "Jake VanderPlas", "Arnaud Joly", "Brian Holt", "Ga\u00ebl Varoquaux"], "venue": "In ECML PKDD Workshop: Languages for Data Mining and Machine Learning,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Intelligible models for classification and regression", "author": ["Rich Caruana", "Yin Lou", "Johannes Gehrke"], "venue": "In Proceedings of the 23rd ACM SIGKDD Conference on Knowledge Discovery and Data Mining. Citeseer,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission", "author": ["Rich Caruana", "Yin Lou", "Johannes Gehrke", "Paul Koch", "Marc Sturm", "Noemie Elhadad"], "venue": "In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Using data mining to predict secondary school student", "author": ["Paulo Cortez", "Alice Maria Gon\u00e7alves Silva"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Interpreting tree ensembles with intrees", "author": ["Houtao Deng"], "venue": "arXiv preprint arXiv:1408.5456,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Algorithm aversion: People erroneously avoid algorithms after seeing them err", "author": ["Berkeley J Dietvorst", "Joseph P Simmons", "Cade Massey"], "venue": "Journal of Experimental Psychology: General,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Mining high-speed data streams", "author": ["Pedro Domingos", "Geoff Hulten"], "venue": "In Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2000}, {"title": "A roadmap for a rigorous science of interpretability", "author": ["Finale Doshi-Velez", "Been Kim"], "venue": "arXiv preprint arXiv:1702.08608,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2017}, {"title": "Fairness through awareness", "author": ["Cynthia Dwork", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Richard Zemel"], "venue": "In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "An extendible package for data exploration, classification and correlation", "author": ["M Forina"], "venue": "Institute of Pharmaceutical and Food Analisys and Technologies, Via Brigata Salerno,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1991}, {"title": "Greedy function approximation: a gradient boosting machine", "author": ["Jerome H Friedman"], "venue": "Annals of statistics,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2001}, {"title": "Learning differential diagnosis of erythemato-squamous diseases using voting feature intervals", "author": ["H Altay G\u00fcvenir", "G\u00fcl\u015fen Demir\u00f6z", "Nilsel Ilter"], "venue": "Artificial intelligence in medicine,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1998}, {"title": "Equality of opportunity in supervised learning", "author": ["Moritz Hardt", "Eric Price", "Nati Srebro"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2016}, {"title": "Simple rules for complex decisions", "author": ["Jongbin Jung", "Connor Concannon", "Ravi Shroff", "Sharad Goel", "Daniel G Goldstein"], "venue": "arXiv preprint arXiv:1702.04690,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2017}, {"title": "Human decisions and machine predictions", "author": ["Jon Kleinberg", "Himabindu Lakkaraju", "Jure Leskovec", "Jens Ludwig", "Sendhil Mullainathan"], "venue": "Technical report, National Bureau of Economic Research,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2017}, {"title": "Understanding black-box predictions via influence functions", "author": ["P.W. Koh", "P. Liang"], "venue": "arXiv preprint arXiv:1703.04730,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2017}, {"title": "Machine learning for medical diagnosis: history, state of the art and perspective", "author": ["Igor Kononenko"], "venue": "Artificial Intelligence in medicine,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2001}, {"title": "Interpretable classifiers using rules and bayesian analysis: Building a better stroke prediction model", "author": ["Benjamin Letham", "Cynthia Rudin", "Tyler H McCormick", "David Madigan"], "venue": "The Annals of Applied Statistics,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "An unexpected unity among methods for interpreting model predictions", "author": ["Scott Lundberg", "Su-In Lee"], "venue": "arXiv preprint arXiv:1611.07478,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2016}, {"title": "Efficient Memory-based Learning for Robot Control", "author": ["Andrew William Moore"], "venue": "PhD thesis, University of Cambridge,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1990}, {"title": "Discrimination-aware data mining", "author": ["Dino Pedreshi", "Salvatore Ruggieri", "Franco Turini"], "venue": "In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2008}, {"title": "Combining instance-based and model-based learning", "author": ["J Ross Quinlan"], "venue": "In Proceedings of the Tenth International Conference on Machine Learning,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1993}, {"title": "Why should i trust you?: Explaining the predictions of any classifier", "author": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "venue": "In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2016}, {"title": "Algorithms for interpretable machine learning", "author": ["Cynthia Rudin"], "venue": "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2014}, {"title": "Not just a black box: Learning important features through propagating activation differences", "author": ["Avanti Shrikumar", "Peyton Greenside", "Anna Shcherbina", "Anshul Kundaje"], "venue": "arXiv preprint arXiv:1605.01713,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2016}, {"title": "Prostate specific antigen in the diagnosis and treatment of adenocarcinoma of the prostate. ii. radical prostatectomy treated patients", "author": ["Thomas A Stamey", "John N Kabalin", "John E McNeal", "Iain M Johnstone", "Fuad Freiha", "Elise A Redwine", "Norman Yang"], "venue": "The Journal of urology,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1989}, {"title": "Reinforcement learning: An introduction, volume 1", "author": ["Richard S Sutton", "Andrew G Barto"], "venue": "MIT press Cambridge,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1998}, {"title": "Collision avoidance for unmanned aircraft using markov decision processes", "author": ["Selim Temizer", "Mykel Kochenderfer", "Leslie Kaelbling", "Tomas Lozano-P\u00e9rez", "James Kuchar"], "venue": "In AIAA guidance, navigation, and control conference,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2010}, {"title": "Supersparse linear integer models for optimized medical scoring systems", "author": ["Berk Ustun", "Cynthia Rudin"], "venue": "Machine Learning,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2016}, {"title": "Mediboost: a patient stratification tool for interpretable decision making in the era of precision medicine", "author": ["Gilmer Valdes", "Jos\u00e9 Marcio Luna", "Eric Eaton", "Charles B Simone"], "venue": "Scientific Reports,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2016}, {"title": "Seeing the forest through the trees", "author": ["Anneleen Van Assche", "Hendrik Blockeel"], "venue": "In International Conference on Inductive Logic Programming,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2007}, {"title": "Genesim: genetic extraction of a single, interpretable model", "author": ["Gilles Vandewiele", "Olivier Janssens", "Femke Ongenae", "Filip De Turck", "Sofie Van Hoecke"], "venue": "arXiv preprint arXiv:1611.05722,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2016}], "referenceMentions": [{"referenceID": 20, "context": "Recent advances in machine learning have revolutionized our ability to use data to inform critical decisions, such as medical diagnosis [30, 16, 44], bail decisions for defendants [28, 27] and the design of aircraft collision avoidance systems [42].", "startOffset": 136, "endOffset": 148}, {"referenceID": 6, "context": "Recent advances in machine learning have revolutionized our ability to use data to inform critical decisions, such as medical diagnosis [30, 16, 44], bail decisions for defendants [28, 27] and the design of aircraft collision avoidance systems [42].", "startOffset": 136, "endOffset": 148}, {"referenceID": 33, "context": "Recent advances in machine learning have revolutionized our ability to use data to inform critical decisions, such as medical diagnosis [30, 16, 44], bail decisions for defendants [28, 27] and the design of aircraft collision avoidance systems [42].", "startOffset": 136, "endOffset": 148}, {"referenceID": 18, "context": "Recent advances in machine learning have revolutionized our ability to use data to inform critical decisions, such as medical diagnosis [30, 16, 44], bail decisions for defendants [28, 27] and the design of aircraft collision avoidance systems [42].", "startOffset": 180, "endOffset": 188}, {"referenceID": 17, "context": "Recent advances in machine learning have revolutionized our ability to use data to inform critical decisions, such as medical diagnosis [30, 16, 44], bail decisions for defendants [28, 27] and the design of aircraft collision avoidance systems [42].", "startOffset": 180, "endOffset": 188}, {"referenceID": 31, "context": "Recent advances in machine learning have revolutionized our ability to use data to inform critical decisions, such as medical diagnosis [30, 16, 44], bail decisions for defendants [28, 27] and the design of aircraft collision avoidance systems [42].", "startOffset": 244, "endOffset": 248}, {"referenceID": 6, "context": ", inability to distinguish causal effects from correlations) [34, 16], fairness (i.", "startOffset": 61, "endOffset": 69}, {"referenceID": 12, "context": ", internalizing prejudices present in training data) [22, 26], and algorithm aversion (i.", "startOffset": 53, "endOffset": 61}, {"referenceID": 16, "context": ", internalizing prejudices present in training data) [22, 26], and algorithm aversion (i.", "startOffset": 53, "endOffset": 61}, {"referenceID": 9, "context": ", lack of trust by end users) [19].", "startOffset": 30, "endOffset": 34}, {"referenceID": 27, "context": "Interpretability is a promising approach to address these challenges [38, 21]\u2014in particular, we can help human users diagnose issues and verify correctness of machine learning models by providing insight into the model\u2019s reasoning [43, 8, 37, 31, 29].", "startOffset": 69, "endOffset": 77}, {"referenceID": 11, "context": "Interpretability is a promising approach to address these challenges [38, 21]\u2014in particular, we can help human users diagnose issues and verify correctness of machine learning models by providing insight into the model\u2019s reasoning [43, 8, 37, 31, 29].", "startOffset": 69, "endOffset": 77}, {"referenceID": 32, "context": "Interpretability is a promising approach to address these challenges [38, 21]\u2014in particular, we can help human users diagnose issues and verify correctness of machine learning models by providing insight into the model\u2019s reasoning [43, 8, 37, 31, 29].", "startOffset": 231, "endOffset": 250}, {"referenceID": 0, "context": "Interpretability is a promising approach to address these challenges [38, 21]\u2014in particular, we can help human users diagnose issues and verify correctness of machine learning models by providing insight into the model\u2019s reasoning [43, 8, 37, 31, 29].", "startOffset": 231, "endOffset": 250}, {"referenceID": 26, "context": "Interpretability is a promising approach to address these challenges [38, 21]\u2014in particular, we can help human users diagnose issues and verify correctness of machine learning models by providing insight into the model\u2019s reasoning [43, 8, 37, 31, 29].", "startOffset": 231, "endOffset": 250}, {"referenceID": 21, "context": "Interpretability is a promising approach to address these challenges [38, 21]\u2014in particular, we can help human users diagnose issues and verify correctness of machine learning models by providing insight into the model\u2019s reasoning [43, 8, 37, 31, 29].", "startOffset": 231, "endOffset": 250}, {"referenceID": 19, "context": "Interpretability is a promising approach to address these challenges [38, 21]\u2014in particular, we can help human users diagnose issues and verify correctness of machine learning models by providing insight into the model\u2019s reasoning [43, 8, 37, 31, 29].", "startOffset": 231, "endOffset": 250}, {"referenceID": 24, "context": "Omitting the feature might not suffice to avoid prejudice, since the model could reconstruct that feature from other features [35].", "startOffset": 126, "endOffset": 130}, {"referenceID": 11, "context": ", how model predictions are affected by changing the prejudiced feature [21].", "startOffset": 72, "endOffset": 76}, {"referenceID": 21, "context": "In this paper, we take T to be a decision tree, which has been established as highly interpretable [31, 37, 8].", "startOffset": 99, "endOffset": 110}, {"referenceID": 26, "context": "In this paper, we take T to be a decision tree, which has been established as highly interpretable [31, 37, 8].", "startOffset": 99, "endOffset": 110}, {"referenceID": 0, "context": "In this paper, we take T to be a decision tree, which has been established as highly interpretable [31, 37, 8].", "startOffset": 99, "endOffset": 110}, {"referenceID": 34, "context": "Previous model extraction approaches have focused on interpreting specific families of models such as random forests [45, 18, 46], enabling them to leverage domain-specific knowledge about the internal structure of the model.", "startOffset": 117, "endOffset": 129}, {"referenceID": 8, "context": "Previous model extraction approaches have focused on interpreting specific families of models such as random forests [45, 18, 46], enabling them to leverage domain-specific knowledge about the internal structure of the model.", "startOffset": 117, "endOffset": 129}, {"referenceID": 35, "context": "Previous model extraction approaches have focused on interpreting specific families of models such as random forests [45, 18, 46], enabling them to leverage domain-specific knowledge about the internal structure of the model.", "startOffset": 117, "endOffset": 129}, {"referenceID": 1, "context": "The key challenge to learning accurate decision trees is that they often overfit and obtain poor performance, whereas complex models such as random forests and deep neural nets are better regularized [9].", "startOffset": 200, "endOffset": 203}, {"referenceID": 3, "context": "We show that our active learning approach substantially improves over using CART [11], a standard decision tree learning algorithm.", "startOffset": 81, "endOffset": 85}, {"referenceID": 3, "context": "CART [11] is considered highly interpretable, but its accuracy is often lacking in practice; [31, 8] tackle this concern by producing sparse rule lists that resemble decision trees yet are non-greedy, thus enabling them to learn more accurate models without sacrificing interpretability.", "startOffset": 5, "endOffset": 9}, {"referenceID": 21, "context": "CART [11] is considered highly interpretable, but its accuracy is often lacking in practice; [31, 8] tackle this concern by producing sparse rule lists that resemble decision trees yet are non-greedy, thus enabling them to learn more accurate models without sacrificing interpretability.", "startOffset": 93, "endOffset": 100}, {"referenceID": 0, "context": "CART [11] is considered highly interpretable, but its accuracy is often lacking in practice; [31, 8] tackle this concern by producing sparse rule lists that resemble decision trees yet are non-greedy, thus enabling them to learn more accurate models without sacrificing interpretability.", "startOffset": 93, "endOffset": 100}, {"referenceID": 32, "context": "Alternatively, [43] proposes supersparse linear integer models, which are sparse linear models where the coefficients are integer valued, thus resembling risk-scoring systems constructed manually by humans for applications such as medical diagnosis or criminal rescidivism.", "startOffset": 15, "endOffset": 19}, {"referenceID": 17, "context": "This approach is extended by [27] for classification problems with binary features.", "startOffset": 29, "endOffset": 33}, {"referenceID": 5, "context": "Finally, [15] propose generalized additive models, which are linear combinations of arbitrarily complex single-feature models, as interpretable models.", "startOffset": 9, "endOffset": 13}, {"referenceID": 26, "context": "For instance, given a new test point x, [37] generates an interpretation for the prediction f(x) by fitting a simple model locally around x and using this simple model to explain the prediction.", "startOffset": 40, "endOffset": 44}, {"referenceID": 22, "context": "Similarly, [32] uses the Shapley value to determine the most influential features for a given prediction.", "startOffset": 11, "endOffset": 15}, {"referenceID": 14, "context": ", random forests) [24].", "startOffset": 18, "endOffset": 22}, {"referenceID": 28, "context": "Similarly, [39] proposes a method for computing influence scores for features in deep neural nets.", "startOffset": 11, "endOffset": 15}, {"referenceID": 3, "context": "2 Exact Greedy Decision Tree We describe the exact greedy decision tree T \u2217 of size k, which closely mirrors CART [11].", "startOffset": 114, "endOffset": 118}, {"referenceID": 10, "context": "A related result is [20], but their analysis is limited to discrete features, for which convergence is much easier to analyze.", "startOffset": 20, "endOffset": 24}, {"referenceID": 4, "context": "We implement our algorithm on top of scikit-learn [14], and evaluate it in two ways.", "startOffset": 50, "endOffset": 54}, {"referenceID": 3, "context": "First, we show that it outperforms a baseline that uses CART [11], a popular decision tree learning algorithm.", "startOffset": 61, "endOffset": 65}, {"referenceID": 29, "context": "945 prostate cancer [40] classify 97 9 random forest 0.", "startOffset": 20, "endOffset": 24}, {"referenceID": 15, "context": "818 dermatology [25] classify 366 34 random forest 0.", "startOffset": 16, "endOffset": 20}, {"referenceID": 13, "context": "967 wine origin [23] classify 178 13 random forest 0.", "startOffset": 16, "endOffset": 20}, {"referenceID": 25, "context": "890 auto mpg [36] regress 398 8 random forest 8.", "startOffset": 13, "endOffset": 17}, {"referenceID": 7, "context": "51 student grade [17] regress 382 33 random forest 4.", "startOffset": 17, "endOffset": 21}, {"referenceID": 29, "context": "949 prostate cancer [40] classify 97 9 neural net 0.", "startOffset": 20, "endOffset": 24}, {"referenceID": 15, "context": "820 dermatology [25] classify 366 34 neural net 0.", "startOffset": 16, "endOffset": 20}, {"referenceID": 13, "context": "964 wine origin [23] classify 178 13 neural net 0.", "startOffset": 16, "endOffset": 20}, {"referenceID": 25, "context": "905 auto mpg [36] regress 398 8 neural net 13.", "startOffset": 13, "endOffset": 17}, {"referenceID": 7, "context": "59 student grade [17] regress 382 33 neural net 6.", "startOffset": 17, "endOffset": 21}, {"referenceID": 2, "context": "10 cartpole [10] reinforce 100 4 control policy 200.", "startOffset": 12, "endOffset": 16}, {"referenceID": 23, "context": "8% mountain car [33] reinforce 100 2 control policy -140.", "startOffset": 16, "endOffset": 20}, {"referenceID": 30, "context": "The cartpole and mountain car control policies are learned using Q-learning [41].", "startOffset": 76, "endOffset": 80}, {"referenceID": 2, "context": "For the cartpole (discrete actions) [2, 10], the learner uses a discretized state space (7 bins per dimension) [1], and for the mountain car (discrete actions) [4, 33], it approximates the Q-function with a linear model over RBF features [3].", "startOffset": 36, "endOffset": 43}, {"referenceID": 23, "context": "For the cartpole (discrete actions) [2, 10], the learner uses a discretized state space (7 bins per dimension) [1], and for the mountain car (discrete actions) [4, 33], it approximates the Q-function with a linear model over RBF features [3].", "startOffset": 160, "endOffset": 167}, {"referenceID": 0, "context": "[8] Elaine Angelino, Nicholas Larus-Stone, Daniel Alabi, Margo Seltzer, and Cynthia Rudin.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[9] Jimmy Ba and Rich Caruana.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[10] Andrew G Barto, Richard S Sutton, and Charles W Anderson.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[11] Leo Breiman, Jerome Friedman, Charles J Stone, and Richard A Olshen.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[14] Lars Buitinck, Gilles Louppe, Mathieu Blondel, Fabian Pedregosa, Andreas Mueller, Olivier Grisel, Vlad Niculae, Peter Prettenhofer, Alexandre Gramfort, Jaques Grobler, Robert Layton, Jake VanderPlas, Arnaud Joly, Brian Holt, and Ga\u00ebl Varoquaux.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[15] Rich Caruana, Yin Lou, and Johannes Gehrke.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[16] Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, and Noemie Elhadad.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[17] Paulo Cortez and Alice Maria Gon\u00e7alves Silva.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[18] Houtao Deng.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[19] Berkeley J Dietvorst, Joseph P Simmons, and Cade Massey.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[20] Pedro Domingos and Geoff Hulten.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[21] Finale Doshi-Velez and Been Kim.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[22] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[23] M Forina et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[24] Jerome H Friedman.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[25] H Altay G\u00fcvenir, G\u00fcl\u015fen Demir\u00f6z, and Nilsel Ilter.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[26] Moritz Hardt, Eric Price, Nati Srebro, et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[27] Jongbin Jung, Connor Concannon, Ravi Shroff, Sharad Goel, and Daniel G Goldstein.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[28] Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, and Sendhil Mullainathan.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[29] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[30] Igor Kononenko.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[31] Benjamin Letham, Cynthia Rudin, Tyler H McCormick, David Madigan, et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[32] Scott Lundberg and Su-In Lee.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[33] Andrew William Moore.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[35] Dino Pedreshi, Salvatore Ruggieri, and Franco Turini.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[36] J Ross Quinlan.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[37] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[38] Cynthia Rudin.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[39] Avanti Shrikumar, Peyton Greenside, Anna Shcherbina, and Anshul Kundaje.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[40] Thomas A Stamey, John N Kabalin, John E McNeal, Iain M Johnstone, Fuad Freiha, Elise A Redwine, and Norman Yang.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[41] Richard S Sutton and Andrew G Barto.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[42] Selim Temizer, Mykel Kochenderfer, Leslie Kaelbling, Tomas Lozano-P\u00e9rez, and James Kuchar.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[43] Berk Ustun and Cynthia Rudin.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[44] Gilmer Valdes, Jos\u00e9 Marcio Luna, Eric Eaton, Charles B Simone, et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[45] Anneleen Van Assche and Hendrik Blockeel.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "[46] Gilles Vandewiele, Olivier Janssens, Femke Ongenae, Filip De Turck, and Sofie Van Hoecke.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "Interpretability has become an important issue as machine learning is increasingly used to inform consequential decisions. We propose an approach for interpreting a blackbox model by extracting a decision tree that approximates the model. Our model extraction algorithm avoids overfitting by leveraging blackbox model access to actively sample new training points. We prove that as the number of samples goes to infinity, the decision tree learned using our algorithm converges to the exact greedy decision tree. In our evaluation, we use our algorithm to interpret random forests and neural nets trained on several datasets from the UCI Machine Learning Repository, as well as control policies learned for three classical reinforcement learning problems. We show that our algorithm improves over a baseline based on CART on every problem instance. Furthermore, we show how an interpretation generated by our approach can be used to understand and debug these models.", "creator": "LaTeX with hyperref package"}}}