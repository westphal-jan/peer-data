{"id": "1705.08807", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-May-2017", "title": "When Will AI Exceed Human Performance? Evidence from AI Experts", "abstract": "Advances in artificial intelligence (AI) will transform modern life by reshaping transportation, health, science, finance, and the military. To adapt public policy, we need to better anticipate these advances. Here we report the results from a large survey of machine learning researchers on their beliefs about progress in AI. Researchers predict AI will outperform humans in many activities in the next ten years, such as translating languages (by 2024), writing high-school essays (by 2026), driving a truck (by 2027), working in retail (by 2031), writing a bestselling book (by 2049), and working as a surgeon (by 2053). Researchers believe there is a 50% chance of AI outperforming humans in all tasks in 45 years and of automating all human jobs in 120 years, with Asian respondents expecting these dates much sooner than North Americans. These results will inform discussion amongst researchers and policymakers about anticipating and managing trends in AI.", "histories": [["v1", "Wed, 24 May 2017 15:00:20 GMT  (744kb,D)", "http://arxiv.org/abs/1705.08807v1", null], ["v2", "Tue, 30 May 2017 21:36:40 GMT  (744kb,D)", "http://arxiv.org/abs/1705.08807v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CY", "authors": ["katja grace", "john salvatier", "allan dafoe", "baobao zhang", "owain evans"], "accepted": false, "id": "1705.08807"}, "pdf": {"name": "1705.08807.pdf", "metadata": {"source": "CRF", "title": "When Will AI Exceed Human Performance? Evidence from AI Experts", "authors": ["Katja Grace", "John Salvatier", "Allan Dafoe", "Baobao Zhang", "Owain Evans"], "emails": [], "sections": [{"heading": "Introduction", "text": "Advances in artificial intelligence (AI) will have a massive social impact, and self-driving technologies could replace millions of jobs in the automotive industry over the next decade. Besides potential unemployment, the transition will bring new challenges, such as rebuilding infrastructure, protecting vehicle cybersecurity, and adapting laws and regulations [5]. New challenges for both AI developers and policy makers will also arise from applications in law enforcement, military technology, and marketing [6]. Predicting transformative AI accurately would be invaluable to prepare for these challenges. Multiple sources provide objective evidence for future advances in AI: trends in hardware [7], task performance [8], and labor automation [9]. The predictions of AI experts provide crucial additional information. We ask a larger and more representative sample of AI experts than any previous study [10, 11]. Our questions concern the timing of advances in artificial intelligence (including various types of AI) and the practical effects of jobs."}, {"heading": "Survey Method", "text": "Our survey population consisted of researchers who participated in the NIPS and ICML 2015 conferences (two of the most important places for peer review research in machine learning), and a total of 352 researchers responded to our survey invitation (21% of the 1,634 authors we contacted), asking questions about the timing of specific AI skills (e.g., laundry folding, language translation), occupational superiority (e.g., truck driver, surgeon), human superiority in all tasks, and the social impact of advanced AI. See Survey Content for details."}, {"heading": "Time Until Machines Outperform Humans", "text": "Our survey used the following definition: \"High-level Machine Intelligence\" (HLMI) is achieved when machines without tools can perform any task better and more cost-effectively than human work.ar Xiv: 170 5.08 807v 1 [cs.A I] 2 4M ay2 017Each individual respondent estimated the likelihood of HLMI arriving in future years. Looking at the mean for each individual, the overall forecast showed a 50% chance of HLMI occurring within 45 years, and a 10% chance of it occurring within 9 years. Figure 1 shows the likely predictions for a random subset of individuals as well as the mean forecasts. There are large differences between subjects: Figure 3 shows that Asian respondents expect HLMI in 30 years, while North Americans expect it in 74 years."}, {"heading": "Intelligence Explosion, Outcomes, AI Safety", "text": "The prospects for progress in this area are very high."}, {"heading": "Was our sample representative?", "text": "We tried to mitigate this effect by making the survey short (12 minutes) and confidential and not mentioning the content or objectives of the survey in our invitation e-mail. Our response rate was 21%. To investigate possible non-response distortions, we collected demographic data for both our respondents (n = 406) and for a random sample (n = 399) of NIPS / ICML researchers who did not respond. Results are shown in Table S3. Differences between groups in citation number, seniority, gender and country of origin are small. Although we cannot rule out that non-response distortions may occur due to unmeasured variables, we can rule out a large distortion based on the demographic variables we measured. Our demographic data also show that our respondents included many highly cited researchers (mainly in machine learning, but also in computer science and neuroscience) and from 43 countries (compared to a total of 52% of all academic work)."}, {"heading": "Discussion", "text": "Why do AI experts believe they can predict advances in artificial intelligence? In the field of political science, a long-term study found that experts were worse at predicting policy outcomes than crude statistical extrapolations [13]. Advances in artificial intelligence based on scientific breakthroughs may seem inherently more difficult to predict, but there are reasons for optimism. While individual breakthroughs are unpredictable, longer-term advances in research and development in many areas (including computer hardware, genomics, solar energy) have been impressively regular [14]. Such regularity is also evident in trends [8] in AI performance in problem solving, gaming, and computer vision, and could be exploited by AI experts in their predictions. After all, it is well known that aggregating individual predictions can lead to big improvements over predictions by a random person [15]. Further work could use our data to make optimized predictions."}, {"heading": "Survey Content", "text": "We developed questions through a series of interviews with machine learning researchers. Our survey questions were as follows: 1. Three sets of questions that elicit HLMI predictions through different framings: asking directly about HLMI, about the automatability of all human occupations, and asking about recent advances in AI from which we may extrapolate; 2. Three questions about the likelihood of an \"intelligence explosion\"; 3. A question about the welfare impact of HLMI.4. A series of questions about the impact of different inputs on AI research (e.g. hardware advances); 5. Questions about disagreements regarding AI timeline and \"AI security\"; 6. Questions about when AI milestones will be reached."}, {"heading": "Elicitation of Beliefs", "text": "Many of our questions ask the question of when an event occurs. For prediction tasks, ideal Bayesian agents provide a cumulative distribution function (CDF) for the cumulative probability of the event from time to time. When we extract points from respondents \"CDFs, we formulate questions in two different ways, which we call\" fixed probability \"and\" fixed years. \"Fixed probability questions ask the question of up to which year an event has a cumulative probability of p% (for 10%, 50%, 90%). Fixed-year questions ask the cumulative probability of the event by year y (for y = 10, 25, 50). The former framing has been used in recent surveys of HLMI timelines; the latter framing is used in the psychological literature to predict [16, 17]. With a limited questionnaire budget, the two framings will try different points on the CDF; otherwise, they are not logically equivalent."}, {"heading": "Statistics", "text": "For each timeline probability question (see Figures 1 and 2), we calculated an overall distribution by adjusting a gamma CDF to the responses of each individual and then taking the mix distribution of all individuals. Report medians and quantiles were calculated using this summary distribution.Confidence intervals were generated by bootstrapping (clusters of respondents with 10,000 drawings) and displaying the 95% interval for the estimated probabilities of each year.Time-in-field comparisons and citation comparisons between respondents and non-respondents (Table S3) were performed using two-sided t-tests, the region and gender proportions were performed using two-sided proportion.The significance test for the effect of the region on the HLMI date (Table S2) was performed using robust linear regression using the R function rlm from the MASS package to achieve regression and then the.robance test function from the fsbumisc package."}, {"heading": "Supplementary Figures", "text": "(a) Top 4 Undergraduate Land HLMI CDFsChina (n = 36) France (n = 16) India (n = 20) United States (n = 53) 0.000.250.751,000 25 50 75 100 Years from 2016Pr obab ility of H LMITop 4 Undergrad Land HLMI CDFs (b) Time in Field Quantile HLMI CDFsQ [1] (n = 57) Q [n = 55) Q [4] (n = 48) 0.000.751,000 25 100 Years from 2016Pr obab ility of H LMITime in Field Quarterns HLMMMI (n = 40) Q (n = 55) Q (n = 48) Q (n = 48) Q (n = 48) Q (n = 48).50.751,100 Years from 2016Pr obab."}, {"heading": "Supplementary Tables", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "S1: Automation Predictions by Researcher Region", "text": "The definition of \"full automation\" is given above (p. 1). For the \"NA / Asia Gap,\" we subtract the Asian from the North American median estimates. Table S1: Median estimate (in years from 2016) for human job automation by region of the Undergraduate InstitutionQuestion Europe N. America NA / Asia Gap Full Automation 130.8 168.6 104.2 + 64.4 Retail Merchant 13.2 10.6 10.2 + 0.4 Truck Driver 46.4 41.0 31.4 + 9.6 Surgeon 18.8 20.2 10.0 + 10.2 AI Researchers 80.0 123.6 109.0 + 14.6"}, {"heading": "S2: Regression of HLMI Prediction on Demographic Features", "text": "We standardized the entries and regressed the protocol of the median years to HLMI for the respondents by sex, citation protocol, seniority (i.e. number of years since the beginning of the doctorate), question (\"fixed-probability\" vs. \"fixed-years\") and region in which the individual was a student. We used a robust linear regression.Table S2: Robust linear regression for single HLMI predictive sterm Estimate SE t-statistic p-value F - statistic (Intercept) 3,65038 0,17320 21,07635 0.00000 458,0979 Gender = \"female\" -0.25473 0,39445 -0,64578 0,55320 0.3529552 log (citation _ count) -0.10303 0.13286 -0.77546 0,44722 0.5802456 Seniority (years) 0.09651 0.13090 0.73728 -0.6460.329 _ fixed _"}, {"heading": "S3: Demographics of Respondents vs. Non-respondents", "text": "There were (n = 406) respondents and (n = 399) non-respondents. Non-respondents were randomly selected from all NIPS / ICML authors who did not respond to our survey invitation. Subjects with missing data for the region of the university or for the gender are grouped in \"NA.\" Missing data for citations and seniority are ignored in the arithmetic average. Statistical tests are explained in section \"Statistics\" above. Table S3: Demographic differences between respondents and non-respondents RegionShare non-respondents proportional p-test p-rating Asia 0,305 0,343 0,283 Europe 0,271 0,236 0,284 Middle East 0.071 0,721 North America 0,254 0,221 0,307 Other 0.015 0.013 1,000 NA 0.084 0,125 0.070Gender proportions p-test p-value female 0,054 0,100 0.020 male 0,919 0,842 0.0027 0,005 4000,005 40,000,005"}, {"heading": "S4: Survey responses on AI progress, intelligence explosions, and AI Safety", "text": "Stuart Russell's argument, referred to in one of the questions below, can be found at http: / / edge.org / conversation / the-myth-of-ai # 26015.Extremely good Overall good Neutral Total bad Extremely bad (e.g. human extinction) Chance HLMI has positive or negative long-term effects on mankind (mean answers) 20% 25% 20% 10% 5% 10% Chance 50% Chance 90% Chance 90% Time to \"complete automation of work\" 50 years 100 200 yearsFirst half (deceleration) About equally good the second half (acceleration) Progress faster in the 1st or 2nd half of your career? 11% 24% 65% 2 years after chance global technological progress increases dramatically after HLMI 20% 80% Quite probable (81-100%) Probably (61-80%) Probably (61-80%) About yourself (41-60%) Unlikelihood (21-40%) Probability that the probability is low, that the probability is low, that the probability is low."}, {"heading": "S5: Description of AI Milestones", "text": "In fact, most of them are able to survive on their own."}, {"heading": "Acknowledgments", "text": "We thank Connor Flexman for collecting demographic information, Nick Bostrom for inspiring this work, and Michael Webb and Andreas Stuhlm\u00fcller for helpful comments. We thank the Future of Humanity Institute (Oxford), the Future of Life Institute, and the Open Philanthropy Project for supporting this work."}], "references": [{"title": "One hundred year study on artificial intelligence: Report of the 2015-2016 study panel", "author": ["Peter Stone", "Rodney Brooks", "Erik Brynjolfsson", "Ryan Calo", "Oren Etzioni", "Greg Hager", "Julia Hirschberg", "Shivaram Kalyanakrishnan", "Ece Kamar", "Sarit Kraus"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "The Master Algorithm : How the Quest for the Ultimate Learning Machine Will Remake", "author": ["Pedro Domingos"], "venue": "Our World. Basic Books,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Superintelligence: Paths, Dangers, Strategies", "author": ["Nick Bostrom"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies", "author": ["Erik Brynjolfsson", "Andrew McAfee"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Robotics and the lessons of cyberlaw", "author": ["Ryan Calo"], "venue": "California Law Review,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Self-driving cars: Disruptive or incremental", "author": ["Tao Jiang", "Srdjan Petrovic", "Uma Ayyer", "Anand Tolani", "Sajid Husain"], "venue": "Applied Innovation Review,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Two centuries of productivity growth in computing", "author": ["William D. Nordhaus"], "venue": "The Journal of Economic History,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Algorithmic progress in six domains", "author": ["Katja Grace"], "venue": "Technical report, Machine Intelligence Research Institute,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Race Against the Machine: How the Digital Revolution Is Accelerating Innovation, Driving Productivity, and Irreversibly Transforming Employment and the Economy", "author": ["Erik Brynjolfsson", "Andrew McAfee"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "How long until human-level ai? results from an expert assessment", "author": ["Seth D. Baum", "Ben Goertzel", "Ted G. Goertzel"], "venue": "Technological Forecasting and Social Change,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Speculations concerning the first ultraintelligent machine", "author": ["Irving John Good"], "venue": "Advances in computers,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1966}, {"title": "Expert political judgment: How good is it? How can we know", "author": ["Philip Tetlock"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "How predictable is technological progress", "author": ["J Doyne Farmer", "Fran\u00e7ois Lafond"], "venue": "Research Policy,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "The good judgment project: A large scale test", "author": ["Lyle Ungar", "Barb Mellors", "Ville Satop\u00e4\u00e4", "Jon Baron", "Phil Tetlock", "Jaime Ramos", "Sam Swift"], "venue": "Technical report, Association for the Advancement of Artificial Intelligence Technical Report,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Eliciting and modeling probability forecasts of continuous quantities", "author": ["Joe W. Tidwell", "Thomas S. Wallsten", "Don A. Moore"], "venue": "Paper presented at the 27th Annual Conference of Society for Judgement and Decision Making,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Abstract Advances in artificial intelligence (AI) will transform modern life by reshaping transportation, health, science, finance, and the military [1, 2, 3].", "startOffset": 149, "endOffset": 158}, {"referenceID": 1, "context": "Abstract Advances in artificial intelligence (AI) will transform modern life by reshaping transportation, health, science, finance, and the military [1, 2, 3].", "startOffset": 149, "endOffset": 158}, {"referenceID": 2, "context": "Abstract Advances in artificial intelligence (AI) will transform modern life by reshaping transportation, health, science, finance, and the military [1, 2, 3].", "startOffset": 149, "endOffset": 158}, {"referenceID": 3, "context": "To adapt public policy, we need to better anticipate these advances [4, 5].", "startOffset": 68, "endOffset": 74}, {"referenceID": 4, "context": "To adapt public policy, we need to better anticipate these advances [4, 5].", "startOffset": 68, "endOffset": 74}, {"referenceID": 4, "context": "In addition to possible unemployment, the transition will bring new challenges, such as rebuilding infrastructure, protecting vehicle cyber-security, and adapting laws and regulations [5].", "startOffset": 184, "endOffset": 187}, {"referenceID": 5, "context": "New challenges, both for AI developers and policy-makers, will also arise from applications in law enforcement, military technology, and marketing [6].", "startOffset": 147, "endOffset": 150}, {"referenceID": 6, "context": "Several sources provide objective evidence about future AI advances: trends in computing hardware [7], task performance [8], and the automation of labor [9].", "startOffset": 98, "endOffset": 101}, {"referenceID": 7, "context": "Several sources provide objective evidence about future AI advances: trends in computing hardware [7], task performance [8], and the automation of labor [9].", "startOffset": 120, "endOffset": 123}, {"referenceID": 8, "context": "Several sources provide objective evidence about future AI advances: trends in computing hardware [7], task performance [8], and the automation of labor [9].", "startOffset": 153, "endOffset": 156}, {"referenceID": 9, "context": "We survey a larger and more representative sample of AI experts than any study to date [10, 11].", "startOffset": 87, "endOffset": 95}, {"referenceID": 2, "context": "Some authors have argued that once HLMI is achieved, AI systems will quickly become vastly superior to humans in all tasks [3, 12].", "startOffset": 123, "endOffset": 130}, {"referenceID": 10, "context": "Some authors have argued that once HLMI is achieved, AI systems will quickly become vastly superior to humans in all tasks [3, 12].", "startOffset": 123, "endOffset": 130}, {"referenceID": 11, "context": "Why think AI experts have any ability to foresee AI progress? In the domain of political science, a long-term study found that experts were worse than crude statistical extrapolations at predicting political outcomes [13].", "startOffset": 217, "endOffset": 221}, {"referenceID": 12, "context": "While individual breakthroughs are unpredictable, longer term progress in R&D for many domains (including computer hardware, genomics, solar energy) has been impressively regular [14].", "startOffset": 179, "endOffset": 183}, {"referenceID": 7, "context": "Such regularity is also displayed by trends [8] in AI performance in SAT problem solving, games-playing, and computer vision and could be exploited by AI experts in their predictions.", "startOffset": 44, "endOffset": 47}, {"referenceID": 13, "context": "Finally, it is well established that aggregating individual predictions can lead to big improvements over the predictions of a random individual [15].", "startOffset": 145, "endOffset": 149}, {"referenceID": 0, "context": "[1] Peter Stone, Rodney Brooks, Erik Brynjolfsson, Ryan Calo, Oren Etzioni, Greg Hager, Julia Hirschberg, Shivaram Kalyanakrishnan, Ece Kamar, Sarit Kraus, et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] Pedro Domingos.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Nick Bostrom.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Erik Brynjolfsson and Andrew McAfee.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Ryan Calo.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Tao Jiang, Srdjan Petrovic, Uma Ayyer, Anand Tolani, and Sajid Husain.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] William D.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Katja Grace.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] Erik Brynjolfsson and Andrew McAfee.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Seth D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[12] Irving John Good.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[13] Philip Tetlock.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[14] J Doyne Farmer and Fran\u00e7ois Lafond.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[15] Lyle Ungar, Barb Mellors, Ville Satop\u00e4\u00e4, Jon Baron, Phil Tetlock, Jaime Ramos, and Sam Swift.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16] Joe W.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "Our goal in defining \u201chigh-level machine intelligence\u201d (HLMI) was to capture the widely-discussed notions of \u201chuman-level AI\u201d or \u201cgeneral AI\u201d (which contrasts with \u201cnarrow AI\u201d) [3].", "startOffset": 177, "endOffset": 180}, {"referenceID": 14, "context": "The former framing was used in recent surveys of HLMI timelines; the latter framing is used in the psychological literature on forecasting [16, 17].", "startOffset": 139, "endOffset": 147}, {"referenceID": 14, "context": "Differences in these two framings have previously been documented in the forecasting literature [16, 17] but there is no clear guidance on which framing leads to more accurate predictions.", "startOffset": 96, "endOffset": 104}, {"referenceID": 0, "context": "Q[1] (n=57) Q[2] (n=40)", "startOffset": 1, "endOffset": 4}, {"referenceID": 1, "context": "Q[1] (n=57) Q[2] (n=40)", "startOffset": 13, "endOffset": 16}, {"referenceID": 2, "context": "Q[3] (n=55) Q[4] (n=48)", "startOffset": 1, "endOffset": 4}, {"referenceID": 3, "context": "Q[3] (n=55) Q[4] (n=48)", "startOffset": 13, "endOffset": 16}, {"referenceID": 0, "context": "Q[1] (n=53) Q[2] (n=57)", "startOffset": 1, "endOffset": 4}, {"referenceID": 1, "context": "Q[1] (n=53) Q[2] (n=57)", "startOffset": 13, "endOffset": 16}, {"referenceID": 2, "context": "Q[3] (n=65) Q[4] (n=49)", "startOffset": 1, "endOffset": 4}, {"referenceID": 3, "context": "Q[3] (n=65) Q[4] (n=49)", "startOffset": 13, "endOffset": 16}, {"referenceID": 0, "context": "Currently, deep networks often need hundreds of examples in classification tasks[1], but there has been work on one-shot learning for both classification[2] and generative tasks[3].", "startOffset": 80, "endOffset": 83}, {"referenceID": 1, "context": "Currently, deep networks often need hundreds of examples in classification tasks[1], but there has been work on one-shot learning for both classification[2] and generative tasks[3].", "startOffset": 153, "endOffset": 156}, {"referenceID": 2, "context": "Currently, deep networks often need hundreds of examples in classification tasks[1], but there has been work on one-shot learning for both classification[2] and generative tasks[3].", "startOffset": 177, "endOffset": 180}, {"referenceID": 0, "context": "[1] Lake et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Building Machines That Learn and Think Like People [2] Koch (2015) Siamese Neural Networks for One-Shot Image Recognition [3] Rezende et al.", "startOffset": 51, "endOffset": 54}, {"referenceID": 2, "context": "Building Machines That Learn and Think Like People [2] Koch (2015) Siamese Neural Networks for One-Shot Image Recognition [3] Rezende et al.", "startOffset": 122, "endOffset": 125}, {"referenceID": 0, "context": "For reference, DeepMind\u2019s AlphaGo has probably played a hundred million games of self-play, while Lee Sedol has probably played 50,000 games in his life[1].", "startOffset": 152, "endOffset": 155}, {"referenceID": 0, "context": "[1] Lake et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "This includes games like Frostbite, which require planning to achieve sub-goals and have posed problems for deep Q-networks[1][2].", "startOffset": 123, "endOffset": 126}, {"referenceID": 1, "context": "This includes games like Frostbite, which require planning to achieve sub-goals and have posed problems for deep Q-networks[1][2].", "startOffset": 126, "endOffset": 129}, {"referenceID": 0, "context": "[1] Mnih et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] Lake et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "For context, the original Atari playing deep Q-network outperforms professional game testers on 47% of games[1], but used hundreds of hours of play to train[2].", "startOffset": 108, "endOffset": 111}, {"referenceID": 1, "context": "For context, the original Atari playing deep Q-network outperforms professional game testers on 47% of games[1], but used hundreds of hours of play to train[2].", "startOffset": 156, "endOffset": 159}, {"referenceID": 0, "context": "[1] Mnih et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] Lake et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "For context, Fu 2016[1] successfully joins single large LEGO pieces using model based reinforcement learning and online adaptation.", "startOffset": 20, "endOffset": 23}, {"referenceID": 0, "context": "[1] Fu et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "Learn to Sort Big Numbers Without Solution Form Learn to efficiently sort lists of numbers much larger than in any training set used, the way Neural GPUs can do for addition[1], but without being given the form of the solution.", "startOffset": 173, "endOffset": 176}, {"referenceID": 1, "context": "For context, Neural Turing Machines have not been able to do this[2], but Neural Programmer-Interpreters[3] have been able to do this by training on stack traces (which contain a lot of information about the form of the solution).", "startOffset": 65, "endOffset": 68}, {"referenceID": 2, "context": "For context, Neural Turing Machines have not been able to do this[2], but Neural Programmer-Interpreters[3] have been able to do this by training on stack traces (which contain a lot of information about the form of the solution).", "startOffset": 104, "endOffset": 107}, {"referenceID": 0, "context": "[1] Kaiser & Sutskever (2015).", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Neural GPUs Learn Algorithms [2] Zaremba & Sutskever (2015).", "startOffset": 29, "endOffset": 32}, {"referenceID": 2, "context": "Reinforcement Learning Neural Turing Machines [3] Reed & de Freitas (2015).", "startOffset": 46, "endOffset": 49}], "year": 2017, "abstractText": "Advances in artificial intelligence (AI) will transform modern life by reshaping transportation, health, science, finance, and the military [1, 2, 3]. To adapt public policy, we need to better anticipate these advances [4, 5]. Here we report the results from a large survey of machine learning researchers on their beliefs about progress in AI. Researchers predict AI will outperform humans in many activities in the next ten years, such as translating languages (by 2024), writing high-school essays (by 2026), driving a truck (by 2027), working in retail (by 2031), writing a bestselling book (by 2049), and working as a surgeon (by 2053). Researchers believe there is a 50% chance of AI outperforming humans in all tasks in 45 years and of automating all human jobs in 120 years, with Asian respondents expecting these dates much sooner than North Americans. These results will inform discussion amongst researchers and policymakers about anticipating and managing trends in AI.", "creator": "LaTeX with hyperref package"}}}