{"id": "1705.08828", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-May-2017", "title": "Deep Investigation of Cross-Language Plagiarism Detection Methods", "abstract": "This paper is a deep investigation of cross-language plagiarism detection methods on a new recently introduced open dataset, which contains parallel and comparable collections of documents with multiple characteristics (different genres, languages and sizes of texts). We investigate cross-language plagiarism detection methods for 6 language pairs on 2 granularities of text units in order to draw robust conclusions on the best methods while deeply analyzing correlations across document styles and languages.", "histories": [["v1", "Wed, 24 May 2017 15:50:47 GMT  (2421kb,D)", "http://arxiv.org/abs/1705.08828v1", "Accepted to BUCC (10th Workshop on Building and Using Comparable Corpora) colocated with ACL 2017"]], "COMMENTS": "Accepted to BUCC (10th Workshop on Building and Using Comparable Corpora) colocated with ACL 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jeremy ferrero", "laurent besacier", "didier schwab", "frederic agnes"], "accepted": false, "id": "1705.08828"}, "pdf": {"name": "1705.08828.pdf", "metadata": {"source": "CRF", "title": "Deep Investigation of Cross-Language Plagiarism Detection Methods", "authors": ["J\u00e9r\u00e9my Ferrero", "Laurent Besacier"], "emails": ["jeremy.ferrero@imag.fr", "laurent.besacier@imag.fr", "didier.schwab@imag.fr", "frederic@compilatio.net"], "sections": [{"heading": "1 Introduction", "text": "Plagiarism is a very significant problem nowadays, especially in higher education institutions. In a monolingual context, this problem is fairly well addressed by several recent research studies (Potthast et al., 2014). Nevertheless, the expansion of the Internet, which facilitates access to documents around the world and to increasingly efficient (freely available) machine translation tools, is helping to spread plagiarism in other languages. Plagiarism in other languages means plagiarism through translation, i.e. a text was translated (manually or automatically) while it was being translated. The challenge in recognizing this type of plagiarism is that the suspicious document is no longer in the same language of its source. In this relatively new field of research, no systematic evaluation is made of the main methods that relate to multiple language pairs, for different text granularities and for different text genres."}, {"heading": "2 Dataset", "text": "The reference dataset used in our study is the new dataset 2 recently introduced by Ferrero et al. (2016), specifically designed for a rigorous evaluation of translingual text similarity; the different characteristics of the dataset are summarized in Table 1, while Table 2 represents the number of aligned units by subcorpus and granularity. Specifically, the characteristics of the dataset are as follows: \u2022 it is multilingual: it contains French, English and Spanish texts; \u2022 it contains information on linguistic alignment in different granularities: document level, sentence level and piece level; \u2022 it is based on both parallel and comparable corpora (mixture of Wikipedia, scientific conference contributions, Amazon product reviews, Europarl and JRC); \u2022 it contains both human and machine translated texts; \u2022 it contains different percentages of designated units; \u2022 part of it has been obscured (in order to establish the font similarity, Europara and the rest of the RC)."}, {"heading": "3 Overview of State-of-the-Art Methods", "text": "There is no way2https: / / github.com / FerreroJeremy / Cross-Language-Datasetof knowledge why texts are similar and thus to assimilate this similarity to plagiarism.At the moment, there is no way2https: / / github.com / Cross-Language-Datasetof the same message or not. Figure 1 presents a taxonomy of Potthast et al al al. (2011), enriched by the study of Danilova (2013), of the different cross-language plagiarism detection methods grouped by class of approaches or not."}, {"heading": "4 Evaluation Protocol", "text": "We use the same evaluation protocol as in the work of Ferrero et al. (2016). We create a distance matrix of the size N xM with M = 1,000 and N = | S |, where S is the weighted subcorpus. Each textual unit of S is compared with itself (since it is a cross-lingual similarity detection, each source language unit is compared with its corresponding unit in the target language) and with M -1 other units randomly selected from S. The same unit can be selected several times. Subsequently, for each comparison performed, a matching score is obtained that leads to the distance matrix. To find the threshold that results in the best F1 score, the F1 score is used as a harmonious means of precision and memory. Precision is defined as the percentage of relevant matrices (similar linguistic units) that is determined taking into account all matrices found. Recall the percentage of relevant matrices that are retrieved from all relevant matrices, using a particular method."}, {"heading": "5 Investigation of Cross-Language Similarity Performances", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Across Language Pairs", "text": "Table 3 summarizes the performance of all methods on all sub-corpora of a method in a particular language pair. As a preliminary remark, however, CL-C3G and CL-ESA produce the same results for a particular language pair (same performance when we reverse both source and target languages).Another remark we can make is that the methods are consistent across language pairs: the best performing methods are largely the same regardless of which language pair is considered. This is confirmed by the calculation of the Pearson correlation between the performance of different language pairs, from Table 3 and reported in Table 4. Table 4 shows the Pearson correlations between the different language pairs of the aggregate results of all methods at the language level. This result is interesting because some of these methods depend on the availability of lexical resources whose quality is across languages \u2192 FR \u2192"}, {"heading": "5.2 Detailed Analysis for English-French", "text": "For this reason, we are now proposing a detailed analysis for different sub-corpora, for the English-French language pair - at chunk and sentence level only. Providing these results for all language pairs and granularities would take up too much space. Furthermore, we also include these state-of-the-art methods on the dataset of Spanish-English Cross-lingual Semantic Textual Similarity task of SemEval-2016 (Agirre et al., 2016) and SemEval-2017 (Cer et al., 2017), and propose a flatter but equally rigorous analysis. However, all these results are also made available as complementary material on our paper website. Table 8 shows the performance of the methods on the EN \u2192 FR partial corporation porporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporpor"}, {"heading": "6 Conclusion", "text": "Our results have shown a common behavior of methods across different language pairs. We have found strong correlations between languages, but also between the text units considered, which means that if one method is more effective than another for a sufficiently large data set, it will be more effective in each other case. Also, if one method is efficient for a particular language pair, it will be equally efficient for another language pair, as long as there are sufficient lexical resources available for those languages. Furthermore, we have examined the behavior of the methods based on the different text types for a particular language pair: English-French. We have found strong correlations between text types, which means that one method could be optimized for a particular corpus and applied efficiently to another corpus. Finally, we have shown that methods behave different behavior in clustering match and non-match units, even if they appear similar in performance."}], "references": [{"title": "SemEval-2016 Task 1: Semantic Textual Similarity, Monolingual and CrossLingual Evaluation", "author": ["Janyce Wiebe."], "venue": "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval 2016). San Diego, CA, USA, pages 497\u2013511.", "citeRegEx": "Wiebe.,? 2016", "shortCiteRegEx": "Wiebe.", "year": 2016}, {"title": "FBK HLTMT at SemEval-2016 Task 1: Cross-lingual semantic similarity measurement using quality estimation features and compositional bilingual word", "author": ["Duygu Ataman", "Jose G.C. de Souza", "Marco Turchi", "Matteo Negri"], "venue": null, "citeRegEx": "Ataman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ataman et al\\.", "year": 2016}, {"title": "On Cross-lingual Plagiarism Analysis using a Statistical Model", "author": ["Alberto Barr\u00f3n-Cede\u00f1o", "Paolo Rosso", "David Pinto", "Alfons Juan."], "venue": "Benno Stein and Efstathios Stamatatos and Moshe Koppel, editor, Proceedings of the ECAI\u201908 PAN Workshop:", "citeRegEx": "Barr\u00f3n.Cede\u00f1o et al\\.,? 2008", "shortCiteRegEx": "Barr\u00f3n.Cede\u00f1o et al\\.", "year": 2008}, {"title": "The Mathematics of Statistical Machine Translation: Parameter Estimation", "author": ["Peter F. Brown", "Vincent J. Della Pietra", "Stephen A. Della Pietra", "Robert L. Mercer."], "venue": "Computational Linguistics 19(2):263\u2013311.", "citeRegEx": "Brown et al\\.,? 1993", "shortCiteRegEx": "Brown et al\\.", "year": 1993}, {"title": "UWB at SemEval-2016 Task 1: Semantic textual similarity using lexical, syntactic, and semantic information", "author": ["Tomas Brychcin", "Lukas Svoboda."], "venue": "Proceedings of the 10th International Workshop on Semantic Evaluation (Se-", "citeRegEx": "Brychcin and Svoboda.,? 2016", "shortCiteRegEx": "Brychcin and Svoboda.", "year": 2016}, {"title": "Semeval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation", "author": ["Daniel Cer", "Mona Diab", "Eneko Agirre", "Inigo LopezGazpio", "Lucia Specia."], "venue": "Proceedings of the 11th International Workshop on Semantic Eval-", "citeRegEx": "Cer et al\\.,? 2017", "shortCiteRegEx": "Cer et al\\.", "year": 2017}, {"title": "Wit: Web inventory of transcribed and translated talks", "author": ["Mauro Cettolo", "Christian Girardi", "Marcello Federico."], "venue": "Proceedings of the 16 Conference of the European Association for Machine Translation (EAMT). pages 261\u2013268.", "citeRegEx": "Cettolo et al\\.,? 2012", "shortCiteRegEx": "Cettolo et al\\.", "year": 2012}, {"title": "Cross-Language Plagiarism Detection Methods", "author": ["Vera Danilova."], "venue": "Galia Angelova, Kalina Bontcheva, and Ruslan Mitkov, editors, Proceedings of the Student Research Workshop associated with RANLP 2013. Hissar, Bulgaria, Recent Advances", "citeRegEx": "Danilova.,? 2013", "shortCiteRegEx": "Danilova.", "year": 2013}, {"title": "A Multilingual, Multi-style and Multi-granularity Dataset for Cross-language Textual Similarity Detection", "author": ["J\u00e9r\u00e9my Ferrero", "Fr\u00e9d\u00e9ric Agn\u00e8s", "Laurent Besacier", "Didier Schwab."], "venue": "Proceedings of the Tenth International Conference on Language Re-", "citeRegEx": "Ferrero et al\\.,? 2016", "shortCiteRegEx": "Ferrero et al\\.", "year": 2016}, {"title": "Computing Semantic Relatedness using Wikipediabased Explicit Semantic Analysis", "author": ["Evgeniy Gabrilovich", "Shaul Markovitch."], "venue": "Proceedings of the 20th International Joint Conference on Artifical Intelligence (IJCAI\u201907). Morgan Kaufmann Publish-", "citeRegEx": "Gabrilovich and Markovitch.,? 2007", "shortCiteRegEx": "Gabrilovich and Markovitch.", "year": 2007}, {"title": "The distribution of the flora in the alpine zone", "author": ["Paul Jaccard."], "venue": "New Phytologist 11(2):37\u201350. https://doi.org/10.1111/j.14698137.1912.tb05611.x.", "citeRegEx": "Jaccard.,? 1912", "shortCiteRegEx": "Jaccard.", "year": 1912}, {"title": "CNRC at SemEval-2016 Task 1: Experiments in crosslingual semantic textual similarity", "author": ["Chi-kiu Lo", "Cyril Goutte", "Michel Simard."], "venue": "Proceedings of the 10th International Workshop on Semantic Evaluation (Se-", "citeRegEx": "Lo et al\\.,? 2016", "shortCiteRegEx": "Lo et al\\.", "year": 2016}, {"title": "Character N-Gram Tokenization for European Language Text Retrieval", "author": ["Paul Mcnamee", "James Mayfield."], "venue": "Information Retrieval Proceedings 7(12):73\u201397.", "citeRegEx": "Mcnamee and Mayfield.,? 2004", "shortCiteRegEx": "Mcnamee and Mayfield.", "year": 2004}, {"title": "External and Intrinsic Plagiarism Detection Using a Cross-Lingual Retrieval and Segmentation System - Lab Report for PAN at CLEF 2010", "author": ["Markus Muhr", "Roman Kern", "Mario Zechner", "Michael Granitzer."], "venue": "Martin Braschler, Donna Har-", "citeRegEx": "Muhr et al\\.,? 2010", "shortCiteRegEx": "Muhr et al\\.", "year": 2010}, {"title": "A New Approach for Searching Translated Plagiarism", "author": ["M\u00e0t\u00e9 Pataki."], "venue": "Proceedings of the 5th International Plagiarism Conference. Newcastle, UK, pages 49\u201364.", "citeRegEx": "Pataki.,? 2012", "shortCiteRegEx": "Pataki.", "year": 2012}, {"title": "A Statistical Approach to Crosslingual Natural Language Tasks", "author": ["David Pinto", "Jorge Civera", "Alfons Juan", "Paolo Rosso", "Alberto Barr\u00f3n-Cede\u00f1o."], "venue": "Journal of Algorithms 64(1):51\u201360. https://doi.org/10.1016/j.jalgor.2009.02.005.", "citeRegEx": "Pinto et al\\.,? 2009", "shortCiteRegEx": "Pinto et al\\.", "year": 2009}, {"title": "Cross-Language Plagiarism Detection", "author": ["Martin Potthast", "Alberto Barr\u00f3n-Cede\u00f1o", "Benno Stein", "Paolo Rosso."], "venue": "Language Resources and Evaluation 45(1):45\u201362. https://doi.org/10.1007/s10579009-9114-z.", "citeRegEx": "Potthast et al\\.,? 2011", "shortCiteRegEx": "Potthast et al\\.", "year": 2011}, {"title": "Overview of the 6th International Competition on Plagiarism Detection", "author": ["Benno Stein."], "venue": "PAN at CLEF 2014. Sheffield, UK, pages 845\u2013876.", "citeRegEx": "Stein.,? 2014", "shortCiteRegEx": "Stein.", "year": 2014}, {"title": "A Wikipedia-Based Multilingual Retrieval Model", "author": ["Martin Potthast", "Benno Stein", "Maik Anderka."], "venue": "30th European Conference on IR Research (ECIR\u201908). Springer, Glasgow, Scotland, volume 4956 of LNCS of Lecture Notes in Computer", "citeRegEx": "Potthast et al\\.,? 2008", "shortCiteRegEx": "Potthast et al\\.", "year": 2008}, {"title": "Automatic Identification of Document Translations in Large Multilingual Document Collections", "author": ["Bruno Pouliquen", "Ralf Steinberger", "Camelia Ignat."], "venue": "Proceedings of the International Conference Recent Advances in Natural Language Processing", "citeRegEx": "Pouliquen et al\\.,? 2003", "shortCiteRegEx": "Pouliquen et al\\.", "year": 2003}, {"title": "DBnary: Wiktionary as a Lemon-Based Multilingual Lexical Resource in RDF", "author": ["Gilles S\u00e9rasset."], "venue": "Semantic Web Journal (special issue on Multilingual Linked Open Data) 6(4):355\u2013361. https://doi.org/10.3233/SW-140147.", "citeRegEx": "S\u00e9rasset.,? 2015", "shortCiteRegEx": "S\u00e9rasset.", "year": 2015}, {"title": "DLS@CU: Sentence similarity from word alignment and semantic vector composition", "author": ["Md Arafat Sultan", "Steven Bethard", "Tamara Sumner."], "venue": "Proceedings of the 9th International Workshop on Semantic Evaluation (Se-", "citeRegEx": "Sultan et al\\.,? 2015", "shortCiteRegEx": "Sultan et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "The evaluation dataset used (Ferrero et al., 2016) allows us to run a large amount of experiments and analyses.", "startOffset": 28, "endOffset": 50}, {"referenceID": 8, "context": "The reference dataset used during our study is the new dataset2 recently introduced by Ferrero et al. (2016). The dataset was specially designed for a", "startOffset": 87, "endOffset": 109}, {"referenceID": 15, "context": "Figure 1 presents a taxonomy of Potthast et al. (2011), enriched by the study of Danilova (2013), of the different cross-language plagiarism detection methods grouped by class of approaches.", "startOffset": 32, "endOffset": 55}, {"referenceID": 7, "context": "(2011), enriched by the study of Danilova (2013), of the different cross-language plagiarism detection methods grouped by class of approaches.", "startOffset": 33, "endOffset": 49}, {"referenceID": 12, "context": "Cross-Language Character N-Gram (CL-CnG) is based on Mcnamee and Mayfield (2004) model.", "startOffset": 53, "endOffset": 81}, {"referenceID": 12, "context": "Cross-Language Character N-Gram (CL-CnG) is based on Mcnamee and Mayfield (2004) model. We use the CL-C3G Potthast et al. (2011)\u2019s implementation.", "startOffset": 53, "endOffset": 129}, {"referenceID": 20, "context": "For that, we use a linked lexical resource called DBNary (S\u00e9rasset, 2015).", "startOffset": 57, "endOffset": 73}, {"referenceID": 10, "context": "After, we use the Jaccard distance (Jaccard, 1912) with fuzzy matching between two bag-ofwords to measure the similarity between two sentences.", "startOffset": 35, "endOffset": 50}, {"referenceID": 2, "context": "Cross-Language Alignment-based Similarity Analysis (CL-ASA) was introduced for the first time by Barr\u00f3n-Cede\u00f1o et al. (2008) and developed subsequently by Pinto et al.", "startOffset": 97, "endOffset": 125}, {"referenceID": 2, "context": "Cross-Language Alignment-based Similarity Analysis (CL-ASA) was introduced for the first time by Barr\u00f3n-Cede\u00f1o et al. (2008) and developed subsequently by Pinto et al. (2009). The model aims to determinate how a textual unit is potentially the translation of another textual unit using bilingual unigram dictionary which contains translations pairs (and their probabilities) extracted from a parallel corpus.", "startOffset": 97, "endOffset": 175}, {"referenceID": 8, "context": "Table 1: Characteristics of the dataset (Ferrero et al., 2016) for each sub-corpus.", "startOffset": 40, "endOffset": 62}, {"referenceID": 13, "context": "MT-Based Models Translation + Monolingual Analysis (Muhr et al., 2010) Comparable Corpora-Based Models CL-KGA, CL-ESA (Potthast et al.", "startOffset": 51, "endOffset": 70}, {"referenceID": 18, "context": ", 2010) Comparable Corpora-Based Models CL-KGA, CL-ESA (Potthast et al., 2008) Parallel Corpora-Based Models CL-ASA (Pinto et al.", "startOffset": 55, "endOffset": 78}, {"referenceID": 15, "context": ", 2008) Parallel Corpora-Based Models CL-ASA (Pinto et al., 2009), CL-LSI, CL-KCCA Dictionary-Based Models CL-VSM, CL-CTS (Pataki, 2012) Syntax-Based Models Length Model (Pouliquen et al.", "startOffset": 45, "endOffset": 65}, {"referenceID": 14, "context": ", 2009), CL-LSI, CL-KCCA Dictionary-Based Models CL-VSM, CL-CTS (Pataki, 2012) Syntax-Based Models Length Model (Pouliquen et al.", "startOffset": 64, "endOffset": 78}, {"referenceID": 19, "context": ", 2009), CL-LSI, CL-KCCA Dictionary-Based Models CL-VSM, CL-CTS (Pataki, 2012) Syntax-Based Models Length Model (Pouliquen et al., 2003), CL-CnG (Potthast et al.", "startOffset": 112, "endOffset": 136}, {"referenceID": 16, "context": ", 2003), CL-CnG (Potthast et al., 2011), Cognateness", "startOffset": 16, "endOffset": 39}, {"referenceID": 15, "context": "Figure 1: Taxonomy of Potthast et al. (2011), enriched by the study of Danilova (2013), of different approaches for cross-language similarity detection.", "startOffset": 22, "endOffset": 45}, {"referenceID": 7, "context": "(2011), enriched by the study of Danilova (2013), of different approaches for cross-language similarity detection.", "startOffset": 33, "endOffset": 49}, {"referenceID": 3, "context": "(Brown et al., 1993) on the concatenation of TED4 (Cettolo et al.", "startOffset": 0, "endOffset": 20}, {"referenceID": 6, "context": ", 1993) on the concatenation of TED4 (Cettolo et al., 2012) and News5 parallel corpora.", "startOffset": 37, "endOffset": 59}, {"referenceID": 3, "context": "(Brown et al., 1993) on the concatenation of TED4 (Cettolo et al., 2012) and News5 parallel corpora. We reuse the implementation of Pinto et al. (2009) that proposed a formula that factored the alignment function.", "startOffset": 1, "endOffset": 152}, {"referenceID": 9, "context": "Cross-Language Explicit Semantic Analysis (CL-ESA) is based on the explicit semantic analysis model introduced for the first time by Gabrilovich and Markovitch (2007), which represents the meaning of a document by a vector based on the vocabulary derived from Wikipedia, to find a document within a corpus.", "startOffset": 133, "endOffset": 167}, {"referenceID": 9, "context": "Cross-Language Explicit Semantic Analysis (CL-ESA) is based on the explicit semantic analysis model introduced for the first time by Gabrilovich and Markovitch (2007), which represents the meaning of a document by a vector based on the vocabulary derived from Wikipedia, to find a document within a corpus. It was reused by Potthast et al. (2008) in the context of cross-language", "startOffset": 133, "endOffset": 347}, {"referenceID": 20, "context": "We use DBNary (S\u00e9rasset, 2015) to get the translations.", "startOffset": 14, "endOffset": 30}, {"referenceID": 13, "context": "We use the Muhr et al. (2010)\u2019s implementation which consists in replacing each word of one text by its most likely translations in the language of the other text, leading to a bags-of-words.", "startOffset": 11, "endOffset": 30}, {"referenceID": 10, "context": "lingual semantic similarity, but 4 teams tried to use learned vector representations (on words or sentences) combined with machine translation confidence (for instance the submission of Lo et al. (2016) or Ataman et al.", "startOffset": 186, "endOffset": 203}, {"referenceID": 1, "context": "(2016) or Ataman et al. (2016)).", "startOffset": 10, "endOffset": 31}, {"referenceID": 4, "context": "that achieved the best performance (Brychcin and Svoboda, 2016) was a supervised system built on a word alignment-based method proposed by Sultan et al.", "startOffset": 35, "endOffset": 63}, {"referenceID": 4, "context": "that achieved the best performance (Brychcin and Svoboda, 2016) was a supervised system built on a word alignment-based method proposed by Sultan et al. (2015). This very recent method is, however, not evaluated in this paper.", "startOffset": 36, "endOffset": 160}, {"referenceID": 5, "context": ", 2016) and SemEval-2017 (Cer et al., 2017), and propose a shallower but equally rigorous analysis.", "startOffset": 25, "endOffset": 43}, {"referenceID": 8, "context": "We built a data subset by concatenating some documents of the previously presented dataset (Ferrero et al., 2016).", "startOffset": 91, "endOffset": 113}, {"referenceID": 19, "context": "(b) Distribution histogram (fingerprint) of the Length Model of Pouliquen et al. (2003).", "startOffset": 64, "endOffset": 88}], "year": 2017, "abstractText": "This paper is a deep investigation of cross-language plagiarism detection methods on a new recently introduced open dataset, which contains parallel and comparable collections of documents with multiple characteristics (different genres, languages and sizes of texts). We investigate cross-language plagiarism detection methods for 6 language pairs on 2 granularities of text units in order to draw robust conclusions on the best methods while deeply analyzing correlations across document styles and languages.", "creator": "LaTeX with hyperref package"}}}