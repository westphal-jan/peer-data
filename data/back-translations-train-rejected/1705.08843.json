{"id": "1705.08843", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-May-2017", "title": "Parsing with CYK over Distributed Representations: \"Classical\" Syntactic Parsing in the Novel Era of Neural Networks", "abstract": "Syntactic parsing is a key task in natural language processing which has been dominated by symbolic, grammar-based syntactic parsers. Neural networks, with their distributed representations, are challenging these methods.", "histories": [["v1", "Wed, 24 May 2017 16:22:13 GMT  (135kb,D)", "http://arxiv.org/abs/1705.08843v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["fabio massimo zanzotto", "giordano cristini"], "accepted": false, "id": "1705.08843"}, "pdf": {"name": "1705.08843.pdf", "metadata": {"source": "CRF", "title": "Parsing with CYK over Distributed Representations: \u201cClassical\u201d Syntactic Parsing in the Novel Era of Neural Networks", "authors": ["Fabio Massimo Zanzotto"], "emails": ["fabio.massimo.zanzotto@uniroma2.it", "giordano.cristini@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people who are able to move are able to move, to move, to move and to move, to move, to move, to move, to move, to move and to move, to move, to move and to move, to move, to move, to move, to move, to move and to move, to move, to move, to move and to move, to move, to move and to move, to move, to move and to move, to move, to move and to move."}, {"heading": "2 Related Work and Notation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 What should represented in a \u201cdistributed\u2019 way in a classical CYK algorithm?", "text": "Although the CYK algorithm is a \"classic,\" simple parsing algorithm for context-free grammars, here is a brief description to share a common notation and clear statements about our objectives. CYK algorithm is a parsing algorithm based on dynamic programming that analyzes sentences by applying the grammar rules R in Chomsky Normal Form (CNF) and storing partial calculations in a two-dimensional table P. CNF is a special form for context-free grammars in which rules are binary rules A \u2192 BC and standard rules A \u2192 \u03b1 in which A, B and C are not terminal symbols and represent the terminal symbols P. The two-dimensional table P represents partial calculations in the recognition of sequences s = s1. sn. Cells P [0, i] in row 0 contain elements si of the input sequence cell."}, {"heading": "2.2 Distributed Representations with Holographic Reduced Representations", "text": "The holographic reduced representations (HRR) [8] are distributed representations that lend themselves well to our goal of representing the two-dimensional tables P of the CYK algorithm and the functioning of the selection of their cells P [i, j]. Indeed, symbols and structures in tables P can be encoded and decoded. Below, we present the operations we use and an iconic way to represent their properties. The iconic metaphor is based on Tetris-like pieces. The starting point of a distributed representation is how symbols can be encoded in vectors."}, {"heading": "3 The CYK algorithm on Distributed Representations", "text": "The distributed CYK algorithm (D-CYK) is our version of the distributed representation CYK algorithm. Like the traditional CYK algorithm, this algorithm recognizes whether or not a sequence is s in a language defined by a Chomsky Normal Form grammar with a set of rules R. However, unlike the traditional CYK algorithm, Table P and Rules R are represented with matrices in a distributed representation, and the rules are applied using matrix algebras. In the following, we describe how our D-CYK will encode: (1) Table P in a matrix P; (2) preterminal rules in a matrix R; and (3) binary rules in matrices RA, one for each symbol A. Such encoding enables a CYK algorithm based on matrix algebra."}, {"heading": "3.1 Encoding the Table P", "text": "Table P of the CYK algorithm can be considered a collection of triples (i, j, e). If there is more than one symbol ek in a cell P (i, j), the collection of triples can contain more elements with the same i and j and with another symbol ek, i.e. triples like (i, j, ek). In view of the revised Holographic Reduced representation we use (see Section 2.2), table P can be represented as a sum of the elements P [j, i, e] which contain the sum of the representations of each symbol in a cell. To illustrate the idea, table P of the running example is displayed in the tetris-like notation in Fig. 1, which according to the pieces in Fig. 2. The distribution of the P symbol in the previous table P [i, e] is displayed in the selected position 1."}, {"heading": "3.2 Encoding and Using Unary Rules", "text": "The CYK algorithm uses simple rules to fill cells P [1, j] in the first row by using the input in cells P [0, j] in line 0 (see algorithm 1). Therefore, the distributed representation of these simple rules should assume a representation of line 0 in distributed representation P, i.e., this distributed representation of the simple rules should form the matrix representing the first row: P \u2032 = 1 D 1 D 1 D 1 3 Eby Using the matrix that encodes the initial sequence: P = 0 1 a 0 2 a 0 3 bOur D-CYK algorithm multiplies the distributed rule R [A] with matrix P when the initial sequence is encoded: P = 0 1 a 0 a 0 a 0 a 0 3 bOur D-CYK algorithm is multiplied."}, {"heading": "P := P + [1]\u2295[i]\u2295[A]\u2295\u03c3(R[A][i] [0] P)", "text": "algorithm 2 CYK _ basic (sequence s, distributed unariy rules R) gives P = \u2211 i [0] [i], [wi], [wi], [i], [i], [i], [i], [i], [i], [i], [i], [i], [i], [i], [i], [i], [i], [i], [a], [b], i.e.: R [D] = a R [E] =, the application of CYK _ basic using the running example in Fig. 1 and the Tetris-like representation. The two preterminal rules are presented as R [D] = [a] and R [E] = [b], i.e.: R [E] = a R [E] = bin the Tetris-like form. Considering the input sequence aab, the matrix is represented as: P = 0, the matrix 0 = the sec = the rib, the rip = 0, the rip = 1, the D = 1, the D = 1."}, {"heading": "3.2.1 Encoding Binary Rules", "text": "To fully define our D-CYK, we describe here how to encode binary rules in such a way that these rules can be triggered by the representation of Table P with matrix algebra. We then define the second part of the algorithm, i.e., CYK _ binary. The driving idea is to use a representation of the rules that yields a near-identity matrix I when applied to matrix P when specific rules fire. This allows the insertion of new symbols in P.algorithm 3 CKY _ binary (P, rules RA for each A) yields P for i [2.. n] dofor i [1.. n \u2212 i + 1)] for the use of new symbols in P.algorithm 3 CKY _ binary (P, rules RA for each A) yields P for i [2.. n] dofor the use of the matrix [1.. (n \u2212 i + 1)] for the use of new symbols in P.1 for A (PRj = 1) (PRj) (PRj = 1 for PA PRj] PRJ (PRj] is for PRj) (PRj = 1)."}, {"heading": "4 Experiments", "text": "The aim of these experiments is to show that the distributed CYK algorithm behaves like the original CYK algorithm. To this end, we do not need huge data sets, but small, well-defined sentences derived from fixed grammars as defined in the following sections."}, {"heading": "4.1 Experimental Set-up", "text": "We experimented with three different grammars that contained an increasing number of rules. < > Grammars > Grammars > Grammars are: (1) M1 grammar with 10 non-terminals, with 4 binary rules and an average of 10 simple rules for each non-terminal. (2) M2 grammar is M1 grammar with an average of 100 simple rules for each non-terminal. And finally, (3) ML grammar, which is always based on M1 with more than 300 simple rules for each end.Given the grammar above, the sentences were prepared randomly. We used 3 sentences of 50 random sentences derived from the grammar above. Since we want to understand whether D-CYK is able to reproduce the calculation of the original CYK."}, {"heading": "4.2 Results", "text": "The results are really encouraging because they show that the f1 measure increases with the size of the matrix. This is mainly due to an improvement in the precision of the cell symbols, since the cell symbol retrieval is essentially stable. The larger the dimension, the more precise D-CYK becomes in replicating the original matrix. Instead, the size of the grammar is a big problem. In fact, the precision of the algorithm is influenced by the number of rules, while the retrieval across the three different grammars is essentially similar. These results confirm that it is possible to transfer a traditional algorithm to a version defined on distributed representations."}, {"heading": "5 Conclusions and Future Work", "text": "These days, the dominance of symbolic grammatical syntactic parsers for natural language has been successfully challenged by neural networks based on distributed representations, and years of results and understanding can be lost. We proposed D-CYK, a distributed version of CYK, a classic parsing algorithm. Experiments show that D-CYK can perform the same task as the original CYK in this new environment. Neural networks are an enormous opportunity to develop new solutions for familiar tasks. Our solution opens a path to innovative possibilities: the revival of symbolic methods in neural networks. In fact, our model is the first step towards defining the \"fully distributed CYK algorithm,\" which builds trees in distributed representations during computation. In addition, it can promote the definition of recurring layers of CYK-informed neural networks."}], "references": [{"title": "Shift-Reduce CCG Parsing using Neural Network Models", "author": ["Bharat Ram Ambati", "Tejaswini Deoskar", "Mark Steedman"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Programming Languages and Their Compilers: Preliminary Notes", "author": ["John Cocke"], "venue": "Courant Institute of Mathematical Sciences,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1969}, {"title": "An Efficient Context-free Parsing Algorithm", "author": ["Jay Earley"], "venue": "Commun. ACM,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1970}, {"title": "Extensions of Lipschitz mappings into a Hilbert space", "author": ["William B Johnson", "Joram Lindenstrauss"], "venue": "Contemporary mathematics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1984}, {"title": "An efficient recognition and syntax-analysis algorithm for context-free languages", "author": ["Tadao Kasami"], "venue": "Technical report,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1965}, {"title": "On the translation of languages from left to right", "author": ["Donald E. Knuth"], "venue": "Information and Control,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1965}, {"title": "A Neural Network Shift-Reduce Parser", "author": ["Marshall R Mayberry", "Risto Miikkulainen"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1997}, {"title": "Holographic Reduced Representations", "author": ["Tony A. Plate"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1995}, {"title": "An Introduction to Random Indexing", "author": ["Magnus Sahlgren"], "venue": "Proceedings of the Methods and Applications of Semantic Indexing Workshop at the 7th International Conference on Terminology and Knowledge Engineering,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Grammar as a Foreign Language", "author": ["Oriol Vinyals", "Lukasz Kaiser", "Terry Koo", "Slav Petrov", "Ilya Sutskever", "Geoffrey Hinton"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Recognition and parsing of context-free languages in time n3", "author": ["Daniel H. Younger"], "venue": "Information and Control,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1967}, {"title": "Transducing Sentences to Syntactic Feature Vectors: an Alternative Way to \"Parse\"? In Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality, pages 40\u201349", "author": ["Fabio Massimo Zanzotto", "Lorenzo Dell\u2019Arciprete"], "venue": "Sofia, Bulgaria,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}], "referenceMentions": [{"referenceID": 1, "context": "The Cocke-Younger-Kasami algorithm (CYK) [2, 12, 5], the Early algorithm [3] and the Shift-Reduce parsing algorithm [6] have fostered many constituency-based and dependency-based parsers.", "startOffset": 41, "endOffset": 51}, {"referenceID": 10, "context": "The Cocke-Younger-Kasami algorithm (CYK) [2, 12, 5], the Early algorithm [3] and the Shift-Reduce parsing algorithm [6] have fostered many constituency-based and dependency-based parsers.", "startOffset": 41, "endOffset": 51}, {"referenceID": 4, "context": "The Cocke-Younger-Kasami algorithm (CYK) [2, 12, 5], the Early algorithm [3] and the Shift-Reduce parsing algorithm [6] have fostered many constituency-based and dependency-based parsers.", "startOffset": 41, "endOffset": 51}, {"referenceID": 2, "context": "The Cocke-Younger-Kasami algorithm (CYK) [2, 12, 5], the Early algorithm [3] and the Shift-Reduce parsing algorithm [6] have fostered many constituency-based and dependency-based parsers.", "startOffset": 73, "endOffset": 76}, {"referenceID": 5, "context": "The Cocke-Younger-Kasami algorithm (CYK) [2, 12, 5], the Early algorithm [3] and the Shift-Reduce parsing algorithm [6] have fostered many constituency-based and dependency-based parsers.", "startOffset": 116, "endOffset": 119}, {"referenceID": 6, "context": "Fast and accurate dependency-based parsers have been designed on top of the shift-reduce algorithm where decisions are taken with discriminative models such as Support Vector Machines or some more complex neural networks [7, 1].", "startOffset": 221, "endOffset": 227}, {"referenceID": 0, "context": "Fast and accurate dependency-based parsers have been designed on top of the shift-reduce algorithm where decisions are taken with discriminative models such as Support Vector Machines or some more complex neural networks [7, 1].", "startOffset": 221, "endOffset": 227}, {"referenceID": 9, "context": "In a first line of research [11], parsing is seen as a translation task: the source language is a natural language and the target language are syntactic interpretations.", "startOffset": 28, "endOffset": 32}, {"referenceID": 11, "context": "In the second line of research [13, 10], both sentences and trees are represented in distributed vectors and neutral networks learn a way to map sentence vectors to tree vectors.", "startOffset": 31, "endOffset": 39}, {"referenceID": 11, "context": "not accurate enough to have an impact on final tasks [13].", "startOffset": 53, "endOffset": 57}, {"referenceID": 0, "context": "The cell P [1, 1] contains D as the cell P [0, 1] contains a and the unary rule D \u2192 a is in the grammar.", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "The cell P [1, 1] contains D as the cell P [0, 1] contains a and the unary rule D \u2192 a is in the grammar.", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "The cell P [1, 1] contains D as the cell P [0, 1] contains a and the unary rule D \u2192 a is in the grammar.", "startOffset": 43, "endOffset": 49}, {"referenceID": 2, "context": "Moreover, for example, the cell P [3, 1] contains S as P [1, 1] contains D, P [2, 2] contains S and S \u2192 DS is in the grammar rules.", "startOffset": 34, "endOffset": 40}, {"referenceID": 0, "context": "Moreover, for example, the cell P [3, 1] contains S as P [1, 1] contains D, P [2, 2] contains S and S \u2192 DS is in the grammar rules.", "startOffset": 34, "endOffset": 40}, {"referenceID": 0, "context": "Moreover, for example, the cell P [3, 1] contains S as P [1, 1] contains D, P [2, 2] contains S and S \u2192 DS is in the grammar rules.", "startOffset": 57, "endOffset": 63}, {"referenceID": 0, "context": "Moreover, for example, the cell P [3, 1] contains S as P [1, 1] contains D, P [2, 2] contains S and S \u2192 DS is in the grammar rules.", "startOffset": 57, "endOffset": 63}, {"referenceID": 1, "context": "Moreover, for example, the cell P [3, 1] contains S as P [1, 1] contains D, P [2, 2] contains S and S \u2192 DS is in the grammar rules.", "startOffset": 78, "endOffset": 84}, {"referenceID": 1, "context": "Moreover, for example, the cell P [3, 1] contains S as P [1, 1] contains D, P [2, 2] contains S and S \u2192 DS is in the grammar rules.", "startOffset": 78, "endOffset": 84}, {"referenceID": 2, "context": "The sequence aab is recognized by the grammar with rules R as P [3, 1] contains S.", "startOffset": 64, "endOffset": 70}, {"referenceID": 0, "context": "The sequence aab is recognized by the grammar with rules R as P [3, 1] contains S.", "startOffset": 64, "endOffset": 70}, {"referenceID": 7, "context": "Holographic reduced representations (HRR) [8] are distributed representations well-suited for our aim of representing the 2-dimensional tables P of the CYK algorithm and the operation of selecting the content of its cells P [i, j].", "startOffset": 42, "endOffset": 45}, {"referenceID": 7, "context": "Moreover, by using holographic reduced representations [8] along with vector shuffling, it is possible to represent multiple symbolic structures in distributed representations.", "startOffset": 55, "endOffset": 58}, {"referenceID": 3, "context": "These vectors are used as basis vectors for the Johnson-Lindenstrauss Tranform [4] as well as for random indexing [9].", "startOffset": 79, "endOffset": 82}, {"referenceID": 8, "context": "These vectors are used as basis vectors for the Johnson-Lindenstrauss Tranform [4] as well as for random indexing [9].", "startOffset": 114, "endOffset": 117}, {"referenceID": 7, "context": "The two operations [a]\u2295 and [a] are strictly linked to (1) the circular convolution and its inverse, the circular correlation, used to encode and decode flat structures [8]; (2) the shuffled circular convolution [?] used to encode syntactic trees.", "startOffset": 169, "endOffset": 172}, {"referenceID": 8, "context": "A similar technique has been used for word sequences [9].", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "numbers symbols Separator [0]\u2295 [1]\u2295 [2]\u2295 [a]\u2295 [b]\u2295 [D]\u2295 [E]\u2295 [S]\u2295 [Sep]\u2295", "startOffset": 31, "endOffset": 34}, {"referenceID": 1, "context": "numbers symbols Separator [0]\u2295 [1]\u2295 [2]\u2295 [a]\u2295 [b]\u2295 [D]\u2295 [E]\u2295 [S]\u2295 [Sep]\u2295", "startOffset": 36, "endOffset": 39}, {"referenceID": 1, "context": "1 can be selected using the matrix [2] [1] represented in Tetris-like pieces as 2 1 .", "startOffset": 35, "endOffset": 38}, {"referenceID": 0, "context": "1 can be selected using the matrix [2] [1] represented in Tetris-like pieces as 2 1 .", "startOffset": 39, "endOffset": 42}, {"referenceID": 0, "context": "Hence, the distributed representation of these unary rules should take a representation of the row 0 in the distributed representation P, that is, \u2211 j [0] [j][sj ] \u2295 and add the distributed representation of the first row \u2211 j [1] [j][Aj ] \u2295.", "startOffset": 226, "endOffset": 229}, {"referenceID": 0, "context": "Then, the operation P := P + [1]\u2295[i]\u2295[A]\u2295\u03c3(R[A][i] [0] P) adds a non-zero element to the matrix P only if rules for A are matched in P .", "startOffset": 29, "endOffset": 32}, {"referenceID": 0, "context": "n] do for A \u2208 preterminals do P := P + [1]\u2295[i]\u2295[A]\u2295\u03c3(R[A][i] [0] P)", "startOffset": 39, "endOffset": 42}], "year": 2017, "abstractText": "Syntactic parsing is a key task in natural language processing which has been dominated by symbolic, grammar-based syntactic parsers. Neural networks, with their distributed representations, are challenging these methods. In this paper, we want to show that existing parsing algorithms can cross the border and be defined over distributed representations. We then define D-CYK: a version of the traditional CYK algorithm defined over distributed representations. Our D-CYK operates as the original CYK but uses matrix multiplications. These operations are compatible with traditional neural networks. Experiments show that D-CYK approximates the original CYK. By showing that CYK can be performed on distributed representations, our D-CYK opens the possibility of defining recurrent layers of CYK-informed neural networks.", "creator": "LaTeX with hyperref package"}}}