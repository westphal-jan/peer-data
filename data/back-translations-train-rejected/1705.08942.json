{"id": "1705.08942", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-May-2017", "title": "Joint PoS Tagging and Stemming for Agglutinative Languages", "abstract": "The number of word forms in agglutinative languages is theoretically infinite and this variety in word forms introduces sparsity in many natural language processing tasks. Part-of-speech tagging (PoS tagging) is one of these tasks that often suffers from sparsity. In this paper, we present an unsupervised Bayesian model using Hidden Markov Models (HMMs) for joint PoS tagging and stemming for agglutinative languages. We use stemming to reduce sparsity in PoS tagging. Two tasks are jointly performed to provide a mutual benefit in both tasks. Our results show that joint POS tagging and stemming improves PoS tagging scores. We present results for Turkish and Finnish as agglutinative languages and English as a morphologically poor language.", "histories": [["v1", "Wed, 24 May 2017 19:44:35 GMT  (314kb,D)", "http://arxiv.org/abs/1705.08942v1", "12 pages with 3 figures, accepted and presented at the CICLING 2017 - 18th International Conference on Intelligent Text Processing and Computational Linguistics"]], "COMMENTS": "12 pages with 3 figures, accepted and presented at the CICLING 2017 - 18th International Conference on Intelligent Text Processing and Computational Linguistics", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["necva b\\\"ol\\\"uc\\\"u", "burcu can"], "accepted": false, "id": "1705.08942"}, "pdf": {"name": "1705.08942.pdf", "metadata": {"source": "CRF", "title": "Joint PoS Tagging and Stemming for Agglutinative Languages", "authors": ["Burcu Can"], "emails": ["necva@cs.hacettepe.edu.tr", "burcu@cs.hacettepe.edu.tr"], "sections": [{"heading": null, "text": "Theoretically infinite, and this diversity of word forms results in thrift in many tasks for processing natural language. PoStagging is one of these tasks, which often suffers from rarity. In this paper, we present an unattended Bayesian model that uses Hidden Markov Models (HMMs) for joint PoS tagging and descent for agglutinative languages. We use descent to reduce the scarcity of PoS tagging. Two tasks are performed together to provide mutual benefit in both tasks. Our results show that joint POS tagging and descent improve PoS tagging values. Wepresent results for Turkish and Finnish as agglutinative languages and English as a morphologically poor language. Keywords: unattended learning, part-of-speech tagging (PoS tagging), descent, Bayesian learning, hidden Markov models (HMM)"}, {"heading": "1 Introduction", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "3 Model & Algorithm", "text": "It is not even clear whether it is a pure \"yes\" or a \"no.\" \"Yes,\" \"No,\" \"No,\" \"No,\" \"No,\" \"No,\" \"No,\" \"No,\" \"No,\" \"No,\" \"No,\" \"No,\" \"No,\" \"No,\" \"No,\" \"No,\" \"No,\" \"\" No, \"\" \"No,\" \"\" No, \"\" \"\" \",\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \",\" \"\" \"\" \"\" \"\" \",\" \"\" \"\" \"\" \"\" \"\" \",\" \"\" \"\" \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \"\" \"\" \",\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \",\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \",\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \",\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\""}, {"heading": "4 Inference", "text": "We use Gibbs sampling [8] for the conclusion of the model. t is drawn from the posterior distribution (t | w,) (w | t,) (t | s,) (t | s,) (t | s,) (t | t,) (t |) (t |) (t | s) (t | s, m, (s | t,) (m | t,) (t |) (t |) in the stem / suffix-based model. In the word-based Bayesian HMM model, all tags are randomly initialized at the beginning of the inference. Then, the tag of each word is scanned from the posterior distribution of the model specified in Eq.5. This process repeats until the system converges.In the root and stem-based / suffix-based model, all tags are randomly initialized and each word from the posterior distribution of each word or word is divided into equations."}, {"heading": "5 Experiments & Results", "text": "The results of this study are based on the fact that most people are able to identify themselves. - The first 12K and 24K terms from the WSJ Penn Treebank [15]. - The first 12K and 24k terms from the FinnTreeBank corpus, which includes the three tag sets from the universal tagset [23], which deal with the question of whether the three tagsets are from the universal tagset. - The new Turkish, English and Finnish tagsets are listed in Table 1 and Table 2. - The size of the tagsets is 12 in all three languages. We have each model with four settings of parameters that we have assigned."}, {"heading": "6 Conclusion & Future Work", "text": "In this paper, we expand the Bayesian HMM model [10] for joint learning of PoS tags and stems in a completely uncontrolled framework. Our model reduces sparseness by using stems and suffixes instead of words in an HMM model. Results show that the use of stems and suffixes instead of words surpasses a simple word-based Bayesian HMM model for particularly agglutinative languages such as Turkish and Finnish. Although English has a poor morphology, English PoS tagging results are also better when the stems are used instead of words. Although our Turkish ancestry results lag far behind other comparative models, our Finnish ancestry results are equivalent to other models. We strive to use other features (such as semantic features) in our model to capture the semantic similarity between the stems and their derivative forms rather than having to deal with future word forms."}, {"heading": "Acknowledgments", "text": "This research is supported by the Turkish Science and Technology Council (TUBITAK) under project number EEAG-115E464."}], "references": [{"title": "An efficient mechanism for stemming and tagging: the case of Greek language", "author": ["G. Adam", "K. Asimakis", "C. Bouras", "V. Poulopoulos"], "venue": "International Conference on Knowledge-Based and Intelligent Information and Engineering Systems. pp. 389\u2013397. Springer", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "Unsupervised part-of-speech tagging employing efficient graph clustering", "author": ["C. Biemann"], "venue": "Proceedings of the 21st international conference on computational linguistics and 44th annual meeting of the association for computational linguistics: student research workshop. pp. 7\u201312. Association for Computational Linguistics", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Tnt: a statistical part-of-speech tagger", "author": ["T. Brants"], "venue": "Proceedings of the sixth conference on Applied natural language processing. pp. 224\u2013231. Association for Computational Linguistics", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2000}, {"title": "Class-based n-gram models of natural language", "author": ["P.F. Brown", "P.V. deSouza", "R.L. Mercer", "V.J.D. Pietra", "J.C. Lai"], "venue": "Computational Linguistics 18(4), 467\u2013479", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1992}, {"title": "Hps: High precision stemmer", "author": ["T. Brychc\u00edn", "M. Konop\u00edk"], "venue": "Information Processing & Management 51(1), 68\u201391", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Inducing syntactic categories by context distribution clustering", "author": ["A. Clark"], "venue": "Proceedings of the 2nd workshop on Learning Language in Logic and the 4th Conference on Computational Natural Language Learning-Volume 7. pp. 91\u201394. Association for Computational Linguistics", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2000}, {"title": "A comparison of Bayesian estimators for unsupervised hidden Markov model PoS taggers", "author": ["J. Gao", "M. Johnson"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing. pp. 344\u2013352. Association for Computational Linguistics", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images", "author": ["S. Geman", "D. Geman"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (6), 721\u2013741", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1984}, {"title": "Unsupervised learning of the morphology of a natural language", "author": ["J. Goldsmith"], "venue": "Computational linguistics 27(2), 153\u2013198", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2001}, {"title": "A fully Bayesian approach to unsupervised part-ofspeech tagging", "author": ["S. Goldwater", "T. Griffiths"], "venue": "Annual meeting-association for computational linguistics. vol. 45, p. 744. Citeseer", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Morfessor FlatCat: An HMMbased method for unsupervised and semi-supervised learning of morphology", "author": ["S.A. Gr\u00f6nroos", "S. Virpioja", "P. Smit", "M. Kurimo"], "venue": "COLING. pp. 1177\u20131185", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Finite state morphology and left to right phonology", "author": ["J. Hankamer"], "venue": "Proceedings of the West Coast Conference on Formal Linguistics. vol. 5, pp. 41\u201352", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1986}, {"title": "Why doesn\u2019t EM find good HMM PoS-taggers? In: EMNLP-CoNLL", "author": ["M. Johnson"], "venue": "pp. 296\u2013305", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Development of a stemming algorithm", "author": ["J.B. Lovins"], "venue": "Mechanical Translation and Computational Linguistics 11", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1968}, {"title": "Building a large annotated corpus of English: The Penn Treebank", "author": ["M.P. Marcus", "M.A. Marcinkiewicz", "B. Santorini"], "venue": "Computational linguistics 19(2), 313\u2013330", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1993}, {"title": "Single n-gram stemming", "author": ["J. Mayfield", "P. McNamee"], "venue": "Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval. pp. 415\u2013416. ACM", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2003}, {"title": "A novel method for stemmer generation based on hidden Markov models", "author": ["M. Melucci", "N. Orio"], "venue": "Proceedings of the Twelfth International Conference on Information and Knowledge Management. pp. 131\u2013138. ACM", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "Tagging English text with a probabilistic model", "author": ["B. Merialdo"], "venue": "Computational Linguistics 20(2), 155\u2013171", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1994}, {"title": "Maulik: An effective stemmer for Hindi language", "author": ["U. Mishra", "C. Prakash"], "venue": "International Journal on Computer Science and Engineering 4(5), 711", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Building a Turkish treebank", "author": ["K. Oflazer", "B. Say", "D.Z. Hakkani-T\u00fcr", "G. T\u00fcr"], "venue": "Treebanks, pp. 261\u2013277. Springer", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2003}, {"title": "Gras: An effective and efficient stemming algorithm for information retrieval", "author": ["J.H. Paik", "M. Mitra", "S.K. Parui", "K. J\u00e4rvelin"], "venue": "ACM Transactions on Information Systems (TOIS) 29(4), 19", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "A novel corpus-based stemming algorithm using co-occurrence statistics", "author": ["J.H. Paik", "D. Pal", "S.K. Parui"], "venue": "Proceedings of the 34th international ACM SIGIR Conference on Research and Development in Information Retrieval. pp. 863\u2013872. ACM", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "A universal part-of-speech tagset", "author": ["S. Petrov", "D. Das", "R. McDonald"], "venue": "arXiv preprint arXiv:1104.2086", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Hybrid stemmer for Gujarati", "author": ["P.P.K. Popat", "P. Bhattacharyya"], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics. pp. 51\u201355", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "An algorithm for suffix stripping", "author": ["M.F. Porter"], "venue": "Program 14(3), 130\u2013137", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1980}, {"title": "Snowball: A language for stemming algorithms", "author": ["M.F. Porter"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2001}, {"title": "V-measure: A conditional entropy-based external cluster evaluation measure", "author": ["A. Rosenberg", "J. Hirschberg"], "venue": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. vol. 7, pp. 410\u2013420", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2007}, {"title": "Part-of-speech induction from scratch", "author": ["H. Sch\u00fctze"], "venue": "Proceedings of the 31st Annual Meeting on Association for Computational Linguistics. pp. 251\u2013258. Association for Computational Linguistics", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1993}, {"title": "Unsupervised multilingual learning for PoS tagging", "author": ["B. Snyder", "T. Naseem", "J. Eisenstein", "R. Barzilay"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing. pp. 1041\u20131050. Association for Computational Linguistics", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}, {"title": "The infinite HMM for unsupervised PoS tagging", "author": ["J. Van Gael", "A. Vlachos", "Z. Ghahramani"], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2-Volume 2. pp. 678\u2013687. Association for Computational Linguistics", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "Corpus-based stemming using cooccurrence of word variants", "author": ["J. Xu", "W.B. Croft"], "venue": "ACM Transactions on Information Systems (TOIS) 16(1), 61\u201381", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1998}], "referenceMentions": [{"referenceID": 11, "context": "Hankamer [12] claims that the number of various word forms in an agglutinative language like Turkish is theoretically infinite.", "startOffset": 9, "endOffset": 13}, {"referenceID": 3, "context": "[4] introduce a class-based n-gram model that learns either syntactic or semantic classes of words depending on the adopted language model; Sch\u00fctze [28] classifies the vector representation of words using neural networks to learn syntactic categories; Clark [6] proposes a probabilistic context distributional clustering to cluster words occurring in similar contexts, thereby having similar syntactic features.", "startOffset": 0, "endOffset": 3}, {"referenceID": 27, "context": "[4] introduce a class-based n-gram model that learns either syntactic or semantic classes of words depending on the adopted language model; Sch\u00fctze [28] classifies the vector representation of words using neural networks to learn syntactic categories; Clark [6] proposes a probabilistic context distributional clustering to cluster words occurring in similar contexts, thereby having similar syntactic features.", "startOffset": 148, "endOffset": 152}, {"referenceID": 5, "context": "[4] introduce a class-based n-gram model that learns either syntactic or semantic classes of words depending on the adopted language model; Sch\u00fctze [28] classifies the vector representation of words using neural networks to learn syntactic categories; Clark [6] proposes a probabilistic context distributional clustering to cluster words occurring in similar contexts, thereby having similar syntactic features.", "startOffset": 258, "endOffset": 261}, {"referenceID": 1, "context": "Bienmann [2] introduces a graph clustering algorithm as a PoS tagger.", "startOffset": 9, "endOffset": 12}, {"referenceID": 17, "context": "HMM-based PoS tagging models go back to Merialdo [18].", "startOffset": 49, "endOffset": 53}, {"referenceID": 2, "context": "Trigrams\u2019n\u2019Tags (TnT) [3] is another statistical PoS tagger that uses a second order Markov Model with also maximum likelihood estimation.", "startOffset": 22, "endOffset": 25}, {"referenceID": 12, "context": "Two tasks are jointly performed to provide a mutual benefit in bJohnson [13] compares the estimators used in HMM PoS taggers.", "startOffset": 72, "endOffset": 76}, {"referenceID": 6, "context": "[7] also compare different Bayesian estimators for HMM PoS taggers.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "Goldwater and Griffiths [10] adopt Bayesian learning in HMMs.", "startOffset": 24, "endOffset": 28}, {"referenceID": 29, "context": "[30] and Synder et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] introduce infinite HMMs that are non-parametric Bayesian where the number of states is not set and the states can grow with data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "The oldest stemmers are rule-based [14,25,26].", "startOffset": 35, "endOffset": 45}, {"referenceID": 24, "context": "The oldest stemmers are rule-based [14,25,26].", "startOffset": 35, "endOffset": 45}, {"referenceID": 25, "context": "The oldest stemmers are rule-based [14,25,26].", "startOffset": 35, "endOffset": 45}, {"referenceID": 30, "context": "One of the earliest statistical stemmers is developed by Xu and Croft [31].", "startOffset": 70, "endOffset": 74}, {"referenceID": 15, "context": "Mayfield and McNamee [16] propose a language independent n-gram stemmer.", "startOffset": 21, "endOffset": 25}, {"referenceID": 16, "context": "[17] implement a HMM-based stemmer using ML estimate to select the most likely stem and suffix based on the substring frequencies obtained from a corpus.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "Linguistica [9], although being an unsupervised morphological segmentation system, is also used as a stemmer.", "startOffset": 12, "endOffset": 15}, {"referenceID": 20, "context": "[21] that groups words to find suffix pairs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Another unsupervised stemmer of the same authors [22] use co-occurence statistics of words to find the common prefixes.", "startOffset": 49, "endOffset": 53}, {"referenceID": 4, "context": "HPS [5] is one of the recent unsupervised stemmers that exploits lexical and semantic information to prepare large-scale training data in the first state, and use a maximum entropy classifier in the second stage by using the training data obtained from the first stage.", "startOffset": 4, "endOffset": 7}, {"referenceID": 23, "context": "[24] propose a hybrid stemmer for Gujarati that combines statistical and rule-based models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "MAULIK [19] introduce another hybrid stemmer that combines the rule-based stemmers.", "startOffset": 7, "endOffset": 11}, {"referenceID": 0, "context": "[1] apply PoS tagging and then use a rule-based stemmer to strip off the suffix from the word based on its tag in a pipelineframework.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "We define a joint PoS tagger and stemmer that extends the fully Bayesian PoS tagger by Goldwater and Griffiths [10].", "startOffset": 111, "endOffset": 115}, {"referenceID": 9, "context": "The word-based Bayesian HMM model (Goldwater and Griffiths [10]) for PoS tagging is defined as follows (see Fig.", "startOffset": 59, "endOffset": 63}, {"referenceID": 9, "context": "We extend the basic HMM model for PoS tagging introduced by Goldwater and Griffiths [10] by replacing the word emissions with stem emissions in order to reduce the emission sparsity, thereby mitigating the size of the out-of-vocabulary words.", "startOffset": 84, "endOffset": 88}, {"referenceID": 7, "context": "We use Gibbs sampling [8] for the inference of the model.", "startOffset": 22, "endOffset": 25}, {"referenceID": 19, "context": "\u2013 Turkish: METU-Sabanc\u0131 Turkish Treebank [20] that consists of 53751 word tokens.", "startOffset": 41, "endOffset": 45}, {"referenceID": 14, "context": "\u2013 English: The first 12K and 24K words from the WSJ Penn Treebank [15].", "startOffset": 66, "endOffset": 70}, {"referenceID": 22, "context": "We mapped the three tagsets to the Universal tagset [23] that involves 12 categories.", "startOffset": 52, "endOffset": 56}, {"referenceID": 4, "context": "We compare our stemming results obtained from the stem-based Bayesian HMM (Bayesian S-HMM) and stem/suffix-based HMM (Bayesian SM-HMM) with HPS [5] and FlatCat [11].", "startOffset": 144, "endOffset": 147}, {"referenceID": 10, "context": "We compare our stemming results obtained from the stem-based Bayesian HMM (Bayesian S-HMM) and stem/suffix-based HMM (Bayesian SM-HMM) with HPS [5] and FlatCat [11].", "startOffset": 160, "endOffset": 164}, {"referenceID": 4, "context": "Model Metu Finn 12K Finn 24K HPS 3 [5] 53.", "startOffset": 35, "endOffset": 38}, {"referenceID": 10, "context": "04 Morfessor FlatCat [11] 52.", "startOffset": 21, "endOffset": 25}, {"referenceID": 3, "context": "58 Brown Clustering 4 [4] 54.", "startOffset": 22, "endOffset": 25}, {"referenceID": 26, "context": "We evaluate PoS tagging results with many-to-one accuracy and variation of information (VI) measure [27].", "startOffset": 100, "endOffset": 104}, {"referenceID": 3, "context": "The overall PoS tagging results show that our stem-based and stem/suffixbased Bayesian models outperform both Brown Clustering [4] and word-based Bayesian HMM model [10] for three languages according to both many-to-one measure and VI measure.", "startOffset": 127, "endOffset": 130}, {"referenceID": 9, "context": "The overall PoS tagging results show that our stem-based and stem/suffixbased Bayesian models outperform both Brown Clustering [4] and word-based Bayesian HMM model [10] for three languages according to both many-to-one measure and VI measure.", "startOffset": 165, "endOffset": 169}, {"referenceID": 3, "context": "17 Brown Clustering 4 [4] 53.", "startOffset": 22, "endOffset": 25}, {"referenceID": 3, "context": "14 Brown Clustering 4 [4] 44.", "startOffset": 22, "endOffset": 25}, {"referenceID": 9, "context": "In this paper, we extend the Bayesian HMM model [10] for joint learning of PoS tags and stems in a fully unsupervised framework.", "startOffset": 48, "endOffset": 52}], "year": 2017, "abstractText": "The number of word forms in agglutinative languages is theoretically infinite and this variety in word forms introduces sparsity in many natural language processing tasks. Part-of-speech tagging (PoS tagging) is one of these tasks that often suffers from sparsity. In this paper, we present an unsupervised Bayesian model using Hidden Markov Models (HMMs) for joint PoS tagging and stemming for agglutinative languages. We use stemming to reduce sparsity in PoS tagging. Two tasks are jointly performed to provide a mutual benefit in both tasks. Our results show that joint POS tagging and stemming improves PoS tagging scores. We present results for Turkish and Finnish as agglutinative languages and English as a morphologically poor language.", "creator": "LaTeX with hyperref package"}}}