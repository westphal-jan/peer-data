{"id": "1705.09021", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-May-2017", "title": "Learning to Pour", "abstract": "Pouring is a simple task people perform daily. It is the second most frequently executed motion in cooking scenarios, after pick-and-place. We present a pouring trajectory generation approach, which uses force feedback from the cup to determine the future velocity of pouring. The approach uses recurrent neural networks as its building blocks. We collected the pouring demonstrations which we used for training. To test our approach in simulation, we also created and trained a force estimation system. The simulated experiments show that the system is able to generalize to single unseen element of the pouring characteristics.", "histories": [["v1", "Thu, 25 May 2017 01:54:58 GMT  (3917kb,D)", "http://arxiv.org/abs/1705.09021v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.LG", "authors": ["yongqiang huang", "yu sun"], "accepted": false, "id": "1705.09021"}, "pdf": {"name": "1705.09021.pdf", "metadata": {"source": "CRF", "title": "Learning to Pour", "authors": ["Yongqiang Huang", "Yu Sun"], "emails": ["yongqiang@mail.usf.edu,", "yusun@cse.usf.edu"], "sections": [{"heading": null, "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "II. METHODOLOGY FOR POURING TRAJECTORY GENERATION", "text": "In this section, we describe in detail our system for creating a casting path based on long-term short-term memory. To explain why we choose RNN as a building block, we examine the basics of traditional RNN and a particular structure, long-term memory, before describing the system."}, {"heading": "A. Recurrent Neural Network", "text": "The idea is in Eq. (1), where the text comes from the previous and the current step. (1) In the theory that deals with the past issue, RNN takes into account the entire history of the given inputs when it comes to implementing actions, and is therefore inherently suitable for handling sequential data. (1) The traditional RNG is hard to bear. (1)"}, {"heading": "B. Generating Pouring Trajectory", "text": "The data of the experiment i are represented by (s\u00f6n1... Ti, f1... Ti, z) (i), where \u03b81... Ti is the order of the chalice rotation, Ti is the order of the order, f1... Ti is the order of the felt force, and z represents static data that characterize the process. To simplify, we assume that we are all one-dimensional. We refer to the system that predicts the speed of the rotation as a plane. Actual velocity is calculated by calculating the order of the order."}, {"heading": "III. DATA PREPARATION AND TRAINING", "text": "The equipment for data acquisition includes six different cups, ten different containers, an ATI mini40 force and torque (FT) sensor and a Polhemus Patriot motion tracker. We refer to the pour-from container as a cup and the pour-to container as a container. All cups are mutually different and so all containers (fx, fy, fz, \u03c4x, \u03c4y, \u03c4y, \u03c4z) are at 1KHz. The motion tracker records (x, y, z, yaw, pitch, roll) at 60Hz. The cup, the force sensor and the motion tracker are connected by 3D printed adapters, shown in Fig. 4. The materials to be cast include water, beans and ice. We obtain the empty reading by holding an empty cup in a level position, taking 500 FT samples (which take 0.5 seconds) and then taking the average."}, {"heading": "A. Training Force Estimation", "text": "In order to carry out our approach to the simulation, we must have force feedback after we arrive at a new rotation. Real force feedback is not applicable in the simulation; the movement of the liquid during the casting process forms a complex dynamic system and is analytically difficult to calculate. So, in order to receive force feedback, we decide to generate the force ourselves. To this end, we learn from the data the mapping relationship of rotation angles to force, and then use the learned model to estimate the force corresponding to the current rotation. We refer to the system that estimates the perceived force from the rotation as frc, represented as (left) in Fig. 2. At step t, frc [\u03b8t, z] > takes as input and produces estimated force f: t: ht = LSTM ([participt, z] >) >) [frfrfrfrfc = fc (ht) (20) The loss is defined with the help of Euclidean: Lc = 1b = > i = 1 = n = 1."}, {"heading": "IV. EXPERIMENT ON GENERALIZATION", "text": "We evaluate the generalization capability of our approach and see if it can generate flow movements in invisible situations. Considering a test sequence, we extract \u03b81 and z and generate a sequence using algae. 2. The evaluation is done in simulations. We test the system with invisible 1) cups, 2) containers, 3) material, 4) cups and containers, 5) containers and materials, 6) cups and containers and material A. Achievement assessment We evaluate the generalization capability of the casting system by means of Dynamic Time Distortion (DTW) [36], which is the minimum normalized distance between two trajectors.We provide a series of test sequences that include an element that cannot be seen during the training, and see if the system is able to adapt to the changes. Let the test sequences {xi} mi = 1. We first calculate the distance between each test sequence {xj and a histogram} (is {xj = hxi)."}, {"heading": "B. Results", "text": "The results for the seven cases of invisible elements of the pouring properties are in Figures 5 to 11. A generalisation to cups or containers or material alone is successful because the mating histograms are similar (Figures 5, 6 and 7). A generalisation to cups and containers (Fig. 8) and containers and material (Fig. 9) can be considered successful due to the similarity in the concentration of the short distances, despite the difference to medium to high-quality distance parts, which occupy only a small part of all distances. A generalisation to cups and material fails just as to cups and containers and materials, as in Fig. 10 and Fig. 11. Only 8 test sequences are available for cups and containers and material, which may partially contribute to the difference between the two histograms. Fig. 7. A generalisation to an invisible material Fig. 8. A generalisation to an invisible container and material and material and Fig. 11."}, {"heading": "V. DISCUSSION", "text": "The system successfully generalises when either a cup, container or material changes, and stumbles when changes are made to more than one element. As the overall size of the data does not change as more (invisible elements) are left out for testing, the less is available for training. Thus, the system accepts weaker training and then faces more challenging challenges. The observed results of the deterioration in performance as generalisation difficulties increase are expected. We have begun to evaluate the system on an industrial robot equipped with a force sensor. The evaluation is yet to be completed. Future work includes the completion of the evaluation on the industrial robot, the development of a quantitative measure measuring the degree of success of a trajectory produced, the modification of the architecture to emphasise the role of initial force and the learning of final force."}], "references": [{"title": "Robot Programming by Demonstration", "author": ["A. Billard", "S. Calinon", "R. Dillmann", "S. Schaal"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Functional object-oriented network for manipulation learning", "author": ["D. Paulius", "Y. Huang", "R. Milton", "W.D. Buchanan", "J. Sam", "Y. Sun"], "venue": "2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Oct 2016, pp. 2655\u20132662.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Dynamical movement primitives: Learning attractor models for motor behaviors", "author": ["A. Ijspeert", "J. Nakanishi", "H. Hoffmann", "P. Pastor", "S. Schaal"], "venue": "Neural Computation, vol. 25, no. 2, pp. 328\u2013373, 2 2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Movement imitation with nonlinear dynamical systems in humanoid robots", "author": ["A.J. Ijspeert", "J. Nakanishi", "S. Schaal"], "venue": "Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292), vol. 2, 2002, pp. 1398\u20131403.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2002}, {"title": "Movement templates for learning of hitting and batting", "author": ["J. Kober", "K. Mlling", "O. Krmer", "C.H. Lampert", "B. Schlkopf", "J. Peters"], "venue": "2010 IEEE International Conference on Robotics and Automation, May 2010, pp. 853\u2013858.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Movement planning and imitation by shaping nonlinear attractors", "author": ["S. Schaal"], "venue": "Proceedings of the 12th Yale Workshop on Adaptive and Learning Systems, Yale University, New Haven, CT, 2003. [Online]. Available: http://www-clmc.usc.edu/publications/ S/schaal-YWALS2003.pdf", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Learning from demonstration and adaptation of biped locomotion", "author": ["J. Nakanishi", "J. Morimoto", "G. Endo", "G. Cheng", "S. Schaal", "M. Kawato"], "venue": "vol. 47, no. 2-3, pp. 79\u201391, 2004. [Online]. Available: http://www-clmc.usc.edu/publications/N/nakanishi-RAS2004.pdf", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Constructive incremental learning from only local information", "author": ["S. Schaal", "C.G. Atkeson"], "venue": "Neural Comput., vol. 10, no. 8, pp. 2047\u2013 2084, Nov. 1998.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1998}, {"title": "Interaction primitives for human-robot cooperation tasks", "author": ["H.B. Amor", "G. Neumann", "S. Kamthe", "O. Kroemer", "J. Peters"], "venue": "2014 IEEE International Conference on Robotics and Automation (ICRA), May 2014, pp. 2831\u20132837.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning multiple collaborative tasks with a mixture of interaction primitives", "author": ["M. Ewerton", "G. Neumann", "R. Lioutikov", "H.B. Amor", "J. Peters", "G. Maeda"], "venue": "2015 IEEE International Conference on Robotics and Automation (ICRA), May 2015, pp. 1535\u20131542.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Robot Programming by Demonstration: A Probabilistic Approach", "author": ["S. Calinon"], "venue": "EPFL/CRC Press,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Maximum likelihood from incomplete data via the em algorithm", "author": ["A.P. Dempster", "N.M. Laird", "D.B. Rubin"], "venue": "JOURNAL OF THE ROYAL STATISTICAL SOCIETY, SERIES B, vol. 39, no. 1, pp. 1\u201338, 1977.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1977}, {"title": "A probabilistic programming by demonstration framework handling skill constraints in joint space and task space", "author": ["S. Calinon", "A. Billard"], "venue": "Proc. IEEE/RSJ Intl Conf. on Intelligent Robots and Systems (IROS), September 2008, pp. 367\u2013372.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "Statistical dynamical systems for skills acquisition in humanoids", "author": ["S. Calinon", "Z. Li", "T. Alizadeh", "N.G. Tsagarakis", "D.G. Caldwell"], "venue": "2012 12th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2012), Nov 2012, pp. 323\u2013329.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Handling of multiple constraints and motion alternatives in a robot programming by demonstration framework", "author": ["S. Calinon", "F. D\u2019halluin", "D.G. Caldwell", "A.G. Billard"], "venue": "2009 9th IEEE-RAS International Conference on Humanoid Robots, Dec 2009, pp. 582\u2013588.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Movement primitives, principal component analysis, and the efficient generation of natural motions", "author": ["B. Lim", "S. Ra", "F.C. Park"], "venue": "Proceedings of the 2005 IEEE International Conference on Robotics and Automation, April 2005, pp. 4630\u20134635.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Interactive generation of human animation with deformable motion models", "author": ["J. Min", "Y.-L. Chen", "J. Chai"], "venue": "ACM Trans. Graph., vol. 29, no. 1, pp. 9:1\u20139:12, Dec. 2009. [Online]. Available: http://doi.acm.org/10.1145/1640443.1640452", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Functional Data Analysis with R and Matlab", "author": ["J.O. Ramsay", "G. Hooker", "S. Graves"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Generating manipulation trajectory using motion harmonics", "author": ["Y. Huang", "Y. Sun"], "venue": "2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Sept 2015, pp. 4949\u20134954.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Modeling Dynamic System by Recurrent Neural Network with State Variables", "author": ["M. Han", "Z. Shi", "W. Wang"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2004}, {"title": "Synthesis of recurrent neural networks for dynamical system simulation", "author": ["A.P. Trischler", "G.M. DEleuterio"], "venue": "Neural Networks, vol. 80, pp. 67 \u2013 78, 2016. [Online]. Available: //www.sciencedirect. com/science/article/pii/S0893608016300314", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Generating sequences with recurrent neural networks", "author": ["A. Graves"], "venue": "CoRR, vol. abs/1308.0850, 2013. [Online]. Available: http://arxiv.org/ abs/1308.0850", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Drawing and recognizing chinese characters with recurrent neural network", "author": ["X. Zhang", "F. Yin", "Y. Zhang", "C. Liu", "Y. Bengio"], "venue": "CoRR, vol. abs/1606.06539, 2016. [Online]. Available: http://arxiv.org/abs/ 1606.06539", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2016}, {"title": "Recurrent network models for human dynamics", "author": ["K. Fragkiadaki", "S. Levine", "P. Felsen", "J. Malik"], "venue": "Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), ser. ICCV \u201915. Washington, DC, USA: IEEE Computer Society, 2015, pp. 4346\u2013 4354. [Online]. Available: http://dx.doi.org/10.1109/ICCV.2015.494", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Backpropagation through time: what it does and how to do it", "author": ["P.J. Werbos"], "venue": "Proceedings of the IEEE, vol. 78, no. 10, pp. 1550\u20131560, Oct 1990.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1990}, {"title": "Learning long-term dependencies with gradient descent is difficult", "author": ["Y. Bengio", "P. Simard", "P. Frasconi"], "venue": "Trans. Neur. Netw., vol. 5, no. 2, pp. 157\u2013166, Mar. 1994. [Online]. Available: http://dx.doi.org/10.1109/72.279181", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1994}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1997}, {"title": "Recurrent neural network regularization", "author": ["W. Zaremba", "I. Sutskever", "O. Vinyals"], "venue": "CoRR, vol. abs/1409.2329, 2014. [Online]. Available: http://arxiv.org/abs/1409.2329", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["A. Karpathy", "F. Li"], "venue": "CoRR, vol. abs/1412.2306, 2014. [Online]. Available: http://arxiv.org/abs/1412.2306", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "Sequence to sequence - video to text", "author": ["S. Venugopalan", "M. Rohrbach", "J. Donahue", "R.J. Mooney", "T. Darrell", "K. Saenko"], "venue": "CoRR, vol. abs/1505.00487, 2015. [Online]. Available: http://arxiv.org/abs/1505.00487", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "DRAW: A recurrent neural network for image generation", "author": ["K. Gregor", "I. Danihelka", "A. Graves", "D. Wierstra"], "venue": "CoRR, vol. abs/1502.04623, 2015. [Online]. Available: http://arxiv.org/abs/1502. 04623", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "CoRR, vol. abs/1409.3215, 2014. [Online]. Available: http://arxiv.org/abs/1409.3215", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning phrase representations using RNN encoderdecoder for statistical machine translation", "author": ["K. Cho", "B. van Merrienboer", "\u00c7. G\u00fcl\u00e7ehre", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": "CoRR, vol. abs/1406.1078, 2014. [Online]. Available: http://arxiv.org/abs/1406.1078", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning to execute", "author": ["W. Zaremba", "I. Sutskever"], "venue": "CoRR, vol. abs/1410.4615, 2014. [Online]. Available: http://arxiv.org/abs/1410. 4615", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["D.P. Kingma", "J. Ba"], "venue": "CoRR, vol. abs/1412.6980, 2014. [Online]. Available: http://arxiv.org/abs/1412.6980", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}, {"title": "Dynamic programming algorithm optimization for spoken word recognition", "author": ["H. Sakoe", "S. Chiba"], "venue": "IEEE Transactions on Acoustics, Speech, and Signal Processing, vol. 26, no. 1, pp. 43\u201349, Feb 1978.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1978}], "referenceMentions": [{"referenceID": 0, "context": "To make robots more widely useful, researchers have been trying to help robots learn a task and generalize to different situations, to which the approach of teaching robots by providing examples has received considerable attention, known as programming by demonstration (PbD) [1].", "startOffset": 276, "endOffset": 279}, {"referenceID": 1, "context": "It is the second most frequently executed motion in cooking scenarios after pick-and-place [2].", "startOffset": 91, "endOffset": 94}, {"referenceID": 2, "context": "One popular framework for motion trajectory generation is dynamical movement primitives (DMP) [3].", "startOffset": 94, "endOffset": 97}, {"referenceID": 3, "context": "DMP is a stable non-linear dynamical system, and is capable of modeling discrete movement such as swinging a tennis racket [4], playing table tennis [5] as well as rhythmic movement such as drumming [6] and walking [7].", "startOffset": 123, "endOffset": 126}, {"referenceID": 4, "context": "DMP is a stable non-linear dynamical system, and is capable of modeling discrete movement such as swinging a tennis racket [4], playing table tennis [5] as well as rhythmic movement such as drumming [6] and walking [7].", "startOffset": 149, "endOffset": 152}, {"referenceID": 5, "context": "DMP is a stable non-linear dynamical system, and is capable of modeling discrete movement such as swinging a tennis racket [4], playing table tennis [5] as well as rhythmic movement such as drumming [6] and walking [7].", "startOffset": 199, "endOffset": 202}, {"referenceID": 6, "context": "DMP is a stable non-linear dynamical system, and is capable of modeling discrete movement such as swinging a tennis racket [4], playing table tennis [5] as well as rhythmic movement such as drumming [6] and walking [7].", "startOffset": 215, "endOffset": 218}, {"referenceID": 7, "context": "The parameters that represent the forcing function can be learned from human demonstrations using locally weighted regression [8] or other regression methods.", "startOffset": 126, "endOffset": 129}, {"referenceID": 8, "context": "Based on DMP, [9] introduced interactive primitives for two-agent collaborative tasks.", "startOffset": 14, "endOffset": 17}, {"referenceID": 9, "context": "[10] extends [9] by using a Gaussian mixture of interactive primitives.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[10] extends [9] by using a Gaussian mixture of interactive primitives.", "startOffset": 13, "endOffset": 16}, {"referenceID": 10, "context": "Another approach for motion generation is based on Gaussian mixture model (GMM) and Gaussian mixture regression (GMR) [11].", "startOffset": 118, "endOffset": 122}, {"referenceID": 11, "context": "The parameters of GMM can be learned using the ExpectationMaximization algorithm [12].", "startOffset": 81, "endOffset": 85}, {"referenceID": 12, "context": "The approach can be applied to both world and joint space to consider the trade-off of variations in difference spaces and thus achieves a more accurate control [13].", "startOffset": 161, "endOffset": 165}, {"referenceID": 13, "context": "Also, task-parameterized GMM models a movement using multiple candidate frames of reference, and thus enables more detailed motion production [14].", "startOffset": 142, "endOffset": 146}, {"referenceID": 14, "context": "In comparison, the approach can be extended to model a dynamical system which produces a trajectory step by step [15].", "startOffset": 113, "endOffset": 117}, {"referenceID": 15, "context": "Known as a dimension reduction technique used on the dimentionality axis of the data, PCA can be used on the time axis of motion trajectories instead to retrieve geometric variations [16].", "startOffset": 183, "endOffset": 187}, {"referenceID": 16, "context": "Besides, PCA can also be applied to find variations in how the motion progresses in time, which, combined with the variations in geometry enables generating motions with more flexibility [17].", "startOffset": 187, "endOffset": 191}, {"referenceID": 17, "context": "Functional PCA (fPCA) extends PCA by introducing continuous-time basis functions and treating trajectories as functions instead of collections of points [18].", "startOffset": 153, "endOffset": 157}, {"referenceID": 18, "context": "[19] applies fPCA for producing trajectories of gross motion such as answering phone and punching, and for making the trajectories avoid obstacles with the guidance of quality via points.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2] uses fPCA for ar X iv :1 70 5.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "Similar to DMP [3] and GMR based approach [15], RNN is also capable of modeling general dynamical systems [20], [21].", "startOffset": 15, "endOffset": 18}, {"referenceID": 14, "context": "Similar to DMP [3] and GMR based approach [15], RNN is also capable of modeling general dynamical systems [20], [21].", "startOffset": 42, "endOffset": 46}, {"referenceID": 19, "context": "Similar to DMP [3] and GMR based approach [15], RNN is also capable of modeling general dynamical systems [20], [21].", "startOffset": 106, "endOffset": 110}, {"referenceID": 20, "context": "Similar to DMP [3] and GMR based approach [15], RNN is also capable of modeling general dynamical systems [20], [21].", "startOffset": 112, "endOffset": 116}, {"referenceID": 21, "context": "For example, [22] generates English hand writing trajectories by predicting the location offset of the tip of the pen and the end of a stroke.", "startOffset": 13, "endOffset": 17}, {"referenceID": 22, "context": "[23] applies a similar strategy to generate Chinese characters.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] generates motion capture trajectories by directly predicting the joint angle vector for the next time step.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "The weight W and bias b can be learned using Backpropagation Through Time [25].", "startOffset": 74, "endOffset": 78}, {"referenceID": 25, "context": "(1) is difficult to train and has vanishing gradients problem, and therefore is inadequate for problems involving long-term dependency [26], [27].", "startOffset": 135, "endOffset": 139}, {"referenceID": 26, "context": "(1) is difficult to train and has vanishing gradients problem, and therefore is inadequate for problems involving long-term dependency [26], [27].", "startOffset": 141, "endOffset": 145}, {"referenceID": 26, "context": "Long short-term memory (LSTM) is a specific RNN design that overcomes the vanishing gradient problem [27].", "startOffset": 101, "endOffset": 105}, {"referenceID": 27, "context": "Mechanism inside an LSTM unit, Zaremba\u2019s version [28]", "startOffset": 49, "endOffset": 53}, {"referenceID": 27, "context": "by [28]:", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "LSTM has been proven successful for sequential generation applications including generating hand written characters [22], [23], captioning images [29] and videos [30], drawing images [31], translating natural languages [32], [33], and executing computer programs [34].", "startOffset": 116, "endOffset": 120}, {"referenceID": 22, "context": "LSTM has been proven successful for sequential generation applications including generating hand written characters [22], [23], captioning images [29] and videos [30], drawing images [31], translating natural languages [32], [33], and executing computer programs [34].", "startOffset": 122, "endOffset": 126}, {"referenceID": 28, "context": "LSTM has been proven successful for sequential generation applications including generating hand written characters [22], [23], captioning images [29] and videos [30], drawing images [31], translating natural languages [32], [33], and executing computer programs [34].", "startOffset": 146, "endOffset": 150}, {"referenceID": 29, "context": "LSTM has been proven successful for sequential generation applications including generating hand written characters [22], [23], captioning images [29] and videos [30], drawing images [31], translating natural languages [32], [33], and executing computer programs [34].", "startOffset": 162, "endOffset": 166}, {"referenceID": 30, "context": "LSTM has been proven successful for sequential generation applications including generating hand written characters [22], [23], captioning images [29] and videos [30], drawing images [31], translating natural languages [32], [33], and executing computer programs [34].", "startOffset": 183, "endOffset": 187}, {"referenceID": 31, "context": "LSTM has been proven successful for sequential generation applications including generating hand written characters [22], [23], captioning images [29] and videos [30], drawing images [31], translating natural languages [32], [33], and executing computer programs [34].", "startOffset": 219, "endOffset": 223}, {"referenceID": 32, "context": "LSTM has been proven successful for sequential generation applications including generating hand written characters [22], [23], captioning images [29] and videos [30], drawing images [31], translating natural languages [32], [33], and executing computer programs [34].", "startOffset": 225, "endOffset": 229}, {"referenceID": 33, "context": "LSTM has been proven successful for sequential generation applications including generating hand written characters [22], [23], captioning images [29] and videos [30], drawing images [31], translating natural languages [32], [33], and executing computer programs [34].", "startOffset": 263, "endOffset": 267}, {"referenceID": 34, "context": "We train using the Adam optimizer [35] and set the learning rate to 0.", "startOffset": 34, "endOffset": 38}, {"referenceID": 35, "context": "We evaluate the generalization ability of the pouring system using dynamic time warping (DTW) [36], which gives the minimum normalized distance between two trajectories.", "startOffset": 94, "endOffset": 98}], "year": 2017, "abstractText": "Pouring is a simple task people perform daily. It is the second most frequently executed motion in cooking scenarios, after pick-and-place. We present a pouring trajectory generation approach, which uses force feedback from the cup to determine the future velocity of pouring. The approach uses recurrent neural networks as its building blocks. We collected the pouring demonstrations which we used for training. To test our approach in simulation, we also created and trained a force estimation system. The simulated experiments show that the system is able to generalize to single unseen element of the pouring characteristics.", "creator": "LaTeX with hyperref package"}}}