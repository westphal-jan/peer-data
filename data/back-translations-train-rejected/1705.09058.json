{"id": "1705.09058", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-May-2017", "title": "An Empirical Analysis of Approximation Algorithms for the Euclidean Traveling Salesman Problem", "abstract": "With applications to many disciplines, the traveling salesman problem (TSP) is a classical computer science optimization problem with applications to industrial engineering, theoretical computer science, bioinformatics, and several other disciplines. In recent years, there have been a plethora of novel approaches for approximate solutions ranging from simplistic greedy to cooperative distributed algorithms derived from artificial intelligence. In this paper, we perform an evaluation and analysis of cornerstone algorithms for the Euclidean TSP. We evaluate greedy, 2-opt, and genetic algorithms. We use several datasets as input for the algorithms including a small dataset, a mediumsized dataset representing cities in the United States, and a synthetic dataset consisting of 200 cities to test algorithm scalability. We discover that the greedy and 2-opt algorithms efficiently calculate solutions for smaller datasets. Genetic algorithm has the best performance for optimality for medium to large datasets, but generally have longer runtime. Our implementations is public available.", "histories": [["v1", "Thu, 25 May 2017 06:21:39 GMT  (513kb,D)", "http://arxiv.org/abs/1705.09058v1", "4 pages, 5 figures"]], "COMMENTS": "4 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["yihui he", "ming xiang"], "accepted": false, "id": "1705.09058"}, "pdf": {"name": "1705.09058.pdf", "metadata": {"source": "CRF", "title": "An Empirical Analysis of Approximation Algorithms for the Euclidean Traveling Salesman Problem", "authors": ["Yihui He", "Ming Xiang"], "emails": ["heyihui@stu.xjtu.edu.cn", "mxiang@mail.xjtu.edu.cn"], "sections": [{"heading": "1. Introduction", "text": "The problem of the moving salesman (TSP), known as NP-hard, was first formulated in 1930 and is one of the most frequently investigated optimization problems to date [8]. The problem is this: Given a list of cities and a distance between each pair of cities, you will find the shortest possible route that visits each city exactly once and returns to the original city. TSP has broad applications, including: shortest path for lasers to model microprocessors and delivery logistics for postal services, to name a few. TSP is an area of active research. In fact, several variants have been derived from the original TSP. In this paper, we focus on the Euclidean TSP. In the Euclidean TSP, the vertices correspond to points in a d-dimensional section 1https: / / github.com / yihui-he / TSPspace, and the cost function is the Euclidean distance. That is, the Euclidean distance between two cities x = (x2, x2..."}, {"heading": "2. Background", "text": "An example TSP is shown in Figure 1. Input is a collection of cities in two-dimensional space. Input can be presented as a distance matrix for each pair of cities or as a list of points that indicate the coordinates of each city. In the latter method, distances are calculated using Euclidean geometry. A less than optimal tour is shown in sub-Figure (b). Although not shown in the figure, each edge will have a non-negative edge weight that indicates the distance between two nodes or cities. However, due to the computational complexity of the TSP, it may be necessary to approximate the optimal solution. The optimal tour is shown in sub-Figure (c). On small graphs, it may be possible to perform an exhaustive search to obtain the optimal solution. However, as the number of cities increases, the solution space, problem complexity and runtime increase."}, {"heading": "3. Algorithms", "text": "We now come to a discussion of the algorithms used in our evaluation. First, in Section 3.1 we describe an upper limit for TSP. Traditional greedy and 2-opt approaches are discussed in Section 3.2 and Section 3.3. Finally, we discuss the genetic algorithm in Section 3.4."}, {"heading": "3.1. Random Path", "text": "Finding the worst TSP case is as difficult as finding the best one. Therefore, we consistently create a random path for all available edges and use this as the upper limit of the optimal path benchmark for all other algorithms."}, {"heading": "3.2. Greedy Algorithm", "text": "The greedy heuristics are based on the Kruskals algorithm to give an approximate solution to the TSP [11]. The algorithm forms a tour of the shortest path and can only be constructed if: The edges of the tour must not form a cycle unless the selected number of edges corresponds to the number of corners in the diagram. The selected edge (before being attached to the tour) does not increase the degree of a node by more than 2. The algorithm continues to select the next most cost-effective edge and adds it to the tour. This process repeats until all corners can be reached by the tour. The result is a minimum stress tree and is a solution for the TSP. The run time for the algorithm is 2% (O) of the rule."}, {"heading": "3.3. 2opt Algorithm", "text": "Optimization is a simple local search algorithm first proposed by Croes in 1958 for the solution of the TSP. [5] The basic idea behind this is to choose a route that crosses itself and sort it so that it does not. A full local search with 2-opt compares any possible valid combination of the swapping mechanism, and this technique can be applied to the problem of the vendor driving, as well as many related problems, including the vehicle route problem (VRP) and the capitalized VRP, which requires minor changes to the algorithm. This is the mechanism by which the 2-opt swap manipulates a given route: 1. Route [1] to the route [i-1] and adds it to set up a new route [i]. Route [i] to the route [k] and add it in reverse order to the new route."}, {"heading": "3.4. Genetic Algorithm", "text": "Genetic algorithms (GA) are search heuristics that attempt to mimic natural selection for many problems in optimization and artificial intelligence. [6] In a genetic algorithm, a population of candidate solutions is developed over time in the direction of better solutions. These developments generally occur through mutations, randomization and recombination. However, we define a fitness function to distinguish between better and worse solutions. Solutions or individuals with higher fitness levels are more likely to survive over time. The final solution is found when the population converges within a certain threshold to a solution. However, great care must be taken to avoid being caught by local optimists. We will now apply a genetic algorithm to the TSP [3]. We define a fitness function F as the length of the tour. Provided we have an order of cities A = x1, x2,... xn where n is the number of cities, the number of populations, not the number of fitness points (the distance between the number of fitness x and the duration of the TSP = 1). (The distance between the fitness x and the time of the TSP = 1 is not worth the number of the population \u2212 1)."}, {"heading": "4. Experiment", "text": "To test the scalability of the algorithms, we have generated a synthetic dataset with 200 cities. In all dataset names, the numerical digits represent the number of cities in the dataset. The datasets are as follows: P15, ATT48, and R200. All datasets except R200 can be found online [4, 14]. The datasets ATT48 and SGB128 represent real data consisting of locations of cities in the United States. A visual representation of the ATT48 dataset at the 2D level is shown in Figure 2. Not all datasets show a known optimal route. In this case, we use random path algorithms to derive an upper limit of the optimal route."}, {"heading": "4.1. Random Dataset", "text": "The R200 dataset was created by plotting 200 random, uniformly distributed points (x, y) in R2 with (x, y) and (0, 4000). Consequently, all distances fulfill the triangular inequality and this dataset can be classified as a Euclidean TSP dataset. The runtime for generating the dataset is O (n). The output is a list of all cities represented as (x, y) points."}, {"heading": "4.2. Comparison", "text": "As we can see in Figure 3, the greedy algorithm is the most efficient. In Figure 4, we can see that most algorithms return dataseta solutions similar to the optimal one for small data sets and get worse for larger datasets. In terms of runtime (Figure 3), the best algorithm is greedy algorithm. However, in terms of the optimal route length of the solution, the best algorithm is GA. This is in line with our expectations and alludes to the fact that different heuristics are better suited to different situations.As shown in Figure 4, the genetic algorithm behaves relatively consistently compared to the 2-opt and greedy algorithms across all datasets. Highlighting in Figure 3, the runtime of genetics is almost linear, suggesting that for larger datasets, when runtime is a concern, the genetic algorithm should be used. Figure 4 further shows that the genetic algorithm is a smaller percent over the optimal value of the other datasets that we can derive better from the larger datasets."}, {"heading": "5. Conclusion", "text": "The literature suggests that the best algorithms focus on iteration and convergence to find optimal routes - something genetic algorithms are trying to achieve. Recent studies include the use of adaptive Markov Chain Monte Carlo algorithms [13]. Many of these algorithms extend the Metropolis algorithm [9], a simulated glowing algorithm that attempts to mimic randomness with particles as temperature variants. This supports our conclusion that algorithms inspired by artificial intelligence work well to find solutions for the TSP. However, these algorithms may not be suitable when warranty is required. In this paper, we have examined several key variants of public intelligence that are well aligned with the genetic solution."}], "references": [{"title": "Polynomial time approximation schemes for euclidean tsp and other geometric problems", "author": ["S. Arora"], "venue": "In Foundations of Computer Science,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1996}, {"title": "Genetic algorithms and the traveling salesman problem", "author": ["K. Bryant", "A. Benjamin"], "venue": "Department of Mathematics, Harvey Mudd College,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2000}, {"title": "Data for the traveling salesperson problem, 2011. http://people.sc.fsu.edu/ jburkardt/datasets/tsp/tsp.html", "author": ["J. Burkardt"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "A method for solving traveling-salesman problems", "author": ["G.A. Croes"], "venue": "Operations research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1958}, {"title": "Genetic algorithms for the traveling salesman problem", "author": ["J. Grefenstette", "R. Gopal", "B. Rosmaita", "D. Van Gucht"], "venue": "In Proceedings of the first International Conference on Genetic Algorithms and their Applications,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1985}, {"title": "The traveling salesman problem: a guided tour of combinatorial optimization", "author": ["A. Hoffman", "J. Wolfe", "R. Garfinkel", "D. Johnson", "C. Papadimitriou", "P. Gilmore", "E. Lawler", "D. Shmoys", "R. Karp", "J. Steele"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1986}, {"title": "Schema analysis of the traveling salesman problem using genetic algorithms", "author": ["A. Homaifar", "S. Guan", "G.E. Liepins"], "venue": "Complex Systems,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1992}, {"title": "Improved largestep markov chain variants for the symmetric tsp", "author": ["I. Hong", "A.B. Kahng", "B.-R. Moon"], "venue": "Journal of Heuristics,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1997}, {"title": "Comparison of tsp algorithms. Project for Models in Facilities", "author": ["B.-I. Kim", "J.-I. Shim", "M. Zhang"], "venue": "Planning and Materials Handling,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1998}, {"title": "frac {13}{9}-approximation for graphic tsp", "author": ["M. Mucha"], "venue": "Theory of computing systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "An adaptive markov chain monte carlo algorithm for tsp", "author": ["F. Qiu", "J. Zhang", "H. Yan"], "venue": "In Computer Science and Software Engineering,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "An analysis of several heuristics for the traveling salesman problem", "author": ["D.J. Rosenkrantz", "R.E. Stearns", "P.M. Lewis", "II"], "venue": "SIAM journal on computing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1977}], "referenceMentions": [{"referenceID": 5, "context": "Known to be NP-hard, the traveling salesman problem (TSP) was first formulated in 1930 and is one of the most studied optimization problems to date [8].", "startOffset": 148, "endOffset": 151}, {"referenceID": 8, "context": "The greedy heuristic is based on Kruskals algorithm to give an approximate solution to the TSP [11].", "startOffset": 95, "endOffset": 99}, {"referenceID": 11, "context": "The runtime for the greedy algorithm is O(nlog(n)) and generally returns a solution within 15-20% of the HeldKarp lower bound [15].", "startOffset": 126, "endOffset": 130}, {"referenceID": 3, "context": "In optimization, 2-opt is a simple local search algorithm first proposed by Croes in 1958 for solving the TSP [5].", "startOffset": 110, "endOffset": 113}, {"referenceID": 0, "context": "take route[1] to route[i-1] and add them in order to new route", "startOffset": 10, "endOffset": 13}, {"referenceID": 4, "context": "Genetic algorithms (GA) are search heuristics that attempt to mimic natural selection for many problems in optimization and artificial intelligence [6].", "startOffset": 148, "endOffset": 151}, {"referenceID": 1, "context": "We will now apply a genetic algorithm to the TSP [3].", "startOffset": 49, "endOffset": 52}, {"referenceID": 6, "context": "The best genetic algorithms can find solutions within 2% of the optimal tour for certain graphs [9].", "startOffset": 96, "endOffset": 99}, {"referenceID": 2, "context": "All datasets except R200 can be found online [4, 14].", "startOffset": 45, "endOffset": 52}, {"referenceID": 7, "context": "For example, the Large Step Markov Chain [10] relies on Markov chains to find convergence of many paths to form a global optimum and several papers cite Markov Chains as the best known solution to TSP.", "startOffset": 41, "endOffset": 45}, {"referenceID": 10, "context": "Recent studies include using adaptive Markov Chain Monte Carlo algorithms [13].", "startOffset": 74, "endOffset": 78}, {"referenceID": 6, "context": "Many of these extend the Metropolis algorithm [9], a simulated annealing algorithm which attempts to mimic randomness with particles as the temperature varies.", "startOffset": 46, "endOffset": 49}], "year": 2017, "abstractText": "With applications to many disciplines, the traveling salesman problem (TSP) is a classical computer science optimization problem with applications to industrial engineering, theoretical computer science, bioinformatics, and several other disciplines [2]. In recent years, there have been a plethora of novel approaches for approximate solutions ranging from simplistic greedy to cooperative distributed algorithms derived from artificial intelligence. In this paper, we perform an evaluation and analysis of cornerstone algorithms for the Euclidean TSP. We evaluate greedy, 2opt, and genetic algorithms. We use several datasets as input for the algorithms including a small dataset, a mediumsized dataset representing cities in the United States, and a synthetic dataset consisting of 200 cities to test algorithm scalability. We discover that the greedy and 2-opt algorithms efficiently calculate solutions for smaller datasets. Genetic algorithm has the best performance for optimality for medium to large datasets, but generally have longer runtime. Our implementations is public available 1.", "creator": "LaTeX with hyperref package"}}}