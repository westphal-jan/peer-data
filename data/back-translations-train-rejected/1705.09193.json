{"id": "1705.09193", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-May-2017", "title": "Classification of Quantitative Light-Induced Fluorescence Images Using Convolutional Neural Network", "abstract": "Images are an important data source for diagnosis and treatment of oral diseases. The manual classification of images may lead to misdiagnosis or mistreatment due to subjective errors. In this paper an image classification model based on Convolutional Neural Network is applied to Quantitative Light-induced Fluorescence images. The deep neural network outperforms other state of the art shallow classification models in predicting labels derived from three different dental plaque assessment scores. The model directly benefits from multi-channel representation of the images resulting in improved performance when, besides the Red colour channel, additional Green and Blue colour channels are used.", "histories": [["v1", "Thu, 25 May 2017 14:21:40 GMT  (434kb)", "http://arxiv.org/abs/1705.09193v1", "Full version of ICANN 2017 submission"]], "COMMENTS": "Full version of ICANN 2017 submission", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["sultan imangaliyev", "monique h van der veen", "catherine m c volgenant", "bruno g loos", "bart j f keijser", "wim crielaard", "evgeni levin"], "accepted": false, "id": "1705.09193"}, "pdf": {"name": "1705.09193.pdf", "metadata": {"source": "CRF", "title": "Classification of Quantitative Light-Induced Fluorescence Images Using Convolutional Neural Network", "authors": ["Sultan Imangaliyev", "Monique H. van der Veen", "Catherine M. C. Volgenant", "Bruno G. Loos", "Bart J. F. Keijser", "Wim Crielaard", "Evgeni Levin"], "emails": ["s.imangaliyev@vumc.nl"], "sections": [{"heading": null, "text": "ar Xiv: 170 5.09 193v 1 [cs.C V] 2Keywords: Deep Learning, Convolutional Neural Networks, Bioinformatics, Quantitative Light-Induced Fluorescence"}, {"heading": "1 Introduction", "text": "Diagnosis and therapy in many fields of medicine, including dentistry, are nowadays largely dependent on technological advances in biomedical imaging. One of the challenges in diagnosing dental patients in daily practice is assessing their plaque. A novel way to look at this plaque is to use a quantitative light-induced fluorescence camera (QLF). When the QLF camera is used, some plaque fluoresces fluoresce red, which is considered an indication of the pathogenicity of the plaque [18]. In this work, we apply a deep artificial neural network to QLF images to create a predictive classification model in which the class division is based on the level of corresponding authority. Red fluorescent plaque disclosed in such images. Although both intraexaminers and interviewers require the reliability of manual assessment of QLF images, these images may be large and expensive [19]."}, {"heading": "2 Materials and Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Convolutional Neural Networks", "text": "Many of the modern deep-learning models use very deep architectures to achieve superhuman performance in solving object-recognition problems [15,17]. One of these architectures is a novel ultra-deep residual learning network (ResNet) [4]. This architecture can be implemented by adding so-called \"shortcut connections\" [5], which skip one or more layers. They perform a mapping so that their results are added to the outputs of the stacked layers. The entire network can be trained and implemented by using common libraries without modifying the solvers, whereby neither additional parameters nor computational complexity are added. ResNet and many other architectures [7,12] use a revolutionary operator when extracting useful function mappings for the image classification task. Generally, the discrete convolution of the image I-K-R-l-l-l-l-filter (2h1 + 1 \u00d7 1) \u00d7 2l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l (2l + 2 + 2) (2l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l, l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l, l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-l-"}, {"heading": "2.2 Dataset", "text": "The analyzed 427 QLF images were acquired during a clinical intervention study [18] at the Academic Centre for Dentistry Amsterdam and translated into a combined dataset of three color channels, each with 216 x 324 raw pixel intensity values. A total of three different experiments were conducted with labels derived from plaque scoring systems such as Red Fluorescent Plaque Percentage (RF-PP) [18], Red Fluorescent modified Quigley-Hein Index (RF-mQH) [19] and modified Sdisease-Loe Plaque Index (mSLP) [20]."}, {"heading": "2.3 Experimental Setup", "text": "The CNN model was implemented using an NVIDIA GeForce GTX Titan X Graphics Processing Unit (GPU) using the Theano package [1]. To compare the influence of different color channels, three dataset compositions were tested, which are only red, red with green, or full RGB representations. To compare CNN performance with the performance of the other models, experiments were conducted with various flat classification models implemented in the Scikitlearn package [14], such as Logistic Regression (LR), Support Vector Machines Classifier with Gaussian Kernel (SVMC-K), Support Vector Machines Classifier with Linear Kernel (SVMC-L), Gaussian Nave Bayes Classifier (GNB), Gradient Boosting Classifier (GBC), K-Neighbors Classifier (KNC), and Random Forest Classifier (RFC). All of these models were evaluated by means of a quantum, the hyper-parameter of which was evaluated by means of an evaluation of these models."}, {"heading": "3 Results and Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Model Performance Evaluation", "text": "However, the results of the experiments for RF-PP, RF-mQH and mSLP labels are shown in Figure 1, Figure 2 and Figure 3, respectively. As shown in Figure 1, most models in the experiment with the RF-PP label have perfect classification performance on the training data set, but poor performance on the test data set. Furthermore, the results suggest that using only the red channel results in relatively good and comparable performance between both SVM models and logistical regression. Adding the green and especially blue channels improves the performance of CNN compared to the other models. As a result, the best model (CNN) yielded a 0.76 \u00b1 0.05 F1 value on the test set and a 0.89 \u00b1 0.11 F1 value on the training set.Similar to the experiment with RF-PP labels, the results in Figure 2 and Figure 3 show the advantages of CNN over the other models, especially after adding the green channel F1 label."}, {"heading": "3.2 Advantages of the Deep Learning Model", "text": "The results of the predictive performance evaluation of the models clearly show the advantage of the CNN model over the other models. In general, the predictive performance of the model on hitherto invisible data, i.e. its generalization, can be improved if certain a priori information about the problem is included in the choice of model architecture [11]. In the case of images, domain information about the problem can be used by a model if such a model is able to learn spatial information between the pixels of an image. This property is embedded explicitly in the CNN model by means of a discrete folding operation [10]. In the case of QLF images, for example, the model can learn the intensity of the red color associated with plaque, or the sharpness of the edges between gingiva and teeth, as well as between teeth. Classification results shown in Figures 1, 2, 3 indicate the robustness of CNN images, which, despite the variability of the image, contain overlapping information, are therefore unique to the three persons, and therefore the others are unique to the three models."}, {"heading": "3.3 Influence of Multi-channel Representation", "text": "In the experiments with the RF-mQH and mSLP labels, the CNN model resulted in an improvement in performance over the other classification models when all three color channels were used. Furthermore, the standard deviation in training performance tends to be narrower than when the model is used only on the Red Channel, especially for GBC, LR, and both SVMC models. Generally, the red-green ratio of pixel values is used to identify the red fluorescent plaque. Therefore, previous work on QLF images [13,9] used the red-green ratio of pixel intensities rather than using only the pixel intensity values of the Red Channel. The Green Channel helps to distinguish plaque from gingiva because they have slightly different pixel values in the Green Channel of the RGB display."}, {"heading": "4 Conclusion", "text": "In this study, we used the CNN model for automatic classification of red fluorescent plaque. Comparison with several other state-of-the-art, flat classification methods clearly demonstrated the advantage of the CNN model in achieving greater predictive power. This was possible because the CNN model learns invariant trait representations directly from raw pixel intensity values without constructing handcrafted traits. We expect deep learning from red fluorescent plaque can help dentists perform efficient fluorescent plaque assessments, thereby contributing to improved oral health for patients."}], "references": [{"title": "Theano: Deep learning on GPUs with Python", "author": ["J. Bergstra", "F. Bastien", "O. Breuleux", "P. Lamblin", "R. Pascanu", "O. Delalleau", "G. Desjardins", "D. Warde-Farley", "I. Goodfellow", "A Bergeron"], "venue": "NIPS 2011, BigLearning Workshop, Granada, Spain", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "DeepPainter: Painter classification using deep convolutional autoencoders", "author": ["O.E. David", "N.S. Netanyahu"], "venue": "International Conference on Artificial Neural Networks. pp. 20\u201328. Springer", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Dermatologist-level classification of skin cancer with deep neural networks", "author": ["A. Esteva", "B. Kuprel", "R.A. Novoa", "J. Ko", "S.M. Swetter", "H.M. Blau", "S. Thrun"], "venue": "Nature 542(7639), 115\u2013118", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2017}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 770\u2013778", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Identity mappings in deep residual networks", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "European Conference on Computer Vision. pp. 630\u2013645. Springer", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep learning for classification of dental plaque images", "author": ["S. Imangaliyev", "M.H. van der Veen", "C.M. Volgenant", "B.J. Keijser", "W. Crielaard", "E. Levin"], "venue": "International Workshop on Machine Learning, Optimization and Big Data. pp. 407\u2013410. Springer", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "What is the best multistage architecture for object recognition? In: Computer Vision, 2009 IEEE 12th International Conference on", "author": ["K. Jarrett", "K. Kavukcuoglu", "M. Ranzato", "Y. LeCun"], "venue": "pp. 2146\u20132153. IEEE", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Dental plaque quantification using cellular neural network-based image segmentation", "author": ["J. Kang", "X. Li", "Q. Luan", "J. Liu", "L. Min"], "venue": "Intelligent computing in signal processing and pattern recognition, pp. 797\u2013802. Springer", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Monitoring the maturation process of a dental microcosm biofilm using the Quantitative Light-induced Fluorescencedigital (QLF-D)", "author": ["Y.S. Kim", "E.S. Lee", "H.K. Kwon", "B.I. Kim"], "venue": "Journal of dentistry 42(6), 691\u2013696", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep learning", "author": ["Y. LeCun", "Y. Bengio", "G. Hinton"], "venue": "Nature 521(7553), 436\u2013444", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Neural computation 1(4), 541\u2013551", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1989}, {"title": "Convolutional networks and applications in vision", "author": ["Y. LeCun", "K. Kavukcuoglu", "C Farabet"], "venue": "ISCAS. pp. 253\u2013256", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Association between the cariogenicity of a dental microcosm biofilm and its red fluorescence detected by Quantitative Light-induced Fluorescence-Digital (QLF-D)", "author": ["E.S. Lee", "S.M. Kang", "H.Y. Ko", "H.K. Kwon", "B.I. Kim"], "venue": "Journal of dentistry 41(12), 1264\u20131270", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Scikit-learn: Machine learning in Python", "author": ["F. Pedregosa", "G. Varoquaux", "A. Gramfort", "V. Michel", "B. Thirion", "O. Grisel", "M. Blondel", "P. Prettenhofer", "R. Weiss", "V Dubourg"], "venue": "Journal of Machine Learning Research 12, 2825\u20132830", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "arXiv preprint arXiv:1409.1556", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "A systematic analysis of performance measures for classification tasks", "author": ["M. Sokolova", "G. Lapalme"], "venue": "Information Processing & Management 45(4), 427\u2013437", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 1\u20139", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Dynamics of red fluorescent dental plaque during experimental gingivitis - a cohort study", "author": ["M.H. van der Veen", "C.M. Volgenant", "B.J. Keijser", "J.B. ten Cate", "W. Crielaard"], "venue": "Journal of dentistry 48, 71\u201376", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Comparison of red autofluorescing plaque and disclosed plaque - a cross-sectional study", "author": ["C.M. Volgenant", "M.F. y Mostajo", "N.A. Rosema", "F.A. van der Weijden", "J.B. ten Cate", "M.H. van der Veen"], "venue": "Clinical oral investigations 20(9), 2551\u20132558", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "A comparative study of electric toothbrushes for the effectiveness of plaque removal in relation to toothbrushing duration", "author": ["G. Weijden", "M. Timmerman", "A. Nijboer", "M. Lie", "U. Velden"], "venue": "Journal of clinical periodontology 20(7), 476\u2013481", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1993}], "referenceMentions": [{"referenceID": 17, "context": "When the QLF-camera is used some dental plaque fluoresces red, which is suggested to be an indication for the pathogenicity of the dental plaque [18].", "startOffset": 145, "endOffset": 149}, {"referenceID": 18, "context": "Although both intraexaminer and inter-examiner reliability of manual assessment of QLF-images are shown to be high [19], this may become expensive and laborious if the number of images is large.", "startOffset": 115, "endOffset": 119}, {"referenceID": 8, "context": "They require that the images must have been captured under the fixed circumstances such as camera geometry, focal distance and ambient light conditions [9], which is hard to achieve under clinical settings.", "startOffset": 152, "endOffset": 155}, {"referenceID": 9, "context": "The problem mentioned above could be solved by the use of Deep Learning models, because descriptive features can be learnt directly from raw data representations [10] being insensitive to ambient conditions and natural image variability.", "startOffset": 162, "endOffset": 166}, {"referenceID": 6, "context": "Since images have a special two-dimensional structure, a group of Deep Learning methods called Convolutional Neural Network (CNN) explicitly uses the advantages of such a representation [7,12].", "startOffset": 186, "endOffset": 192}, {"referenceID": 11, "context": "Since images have a special two-dimensional structure, a group of Deep Learning methods called Convolutional Neural Network (CNN) explicitly uses the advantages of such a representation [7,12].", "startOffset": 186, "endOffset": 192}, {"referenceID": 1, "context": "Applications of CNN may include both non-biological [2] and biological images [3].", "startOffset": 52, "endOffset": 55}, {"referenceID": 2, "context": "Applications of CNN may include both non-biological [2] and biological images [3].", "startOffset": 78, "endOffset": 81}, {"referenceID": 17, "context": "The aim of this paper is to describe the novel application of CNN to QLFimages obtained during clinical intervention study [18].", "startOffset": 123, "endOffset": 127}, {"referenceID": 5, "context": "Previous studies on this topic either focused on only a single plaque scoring system without providing detailed analysis of results [6] or used small dataset of different images and different network architecture [8].", "startOffset": 132, "endOffset": 135}, {"referenceID": 7, "context": "Previous studies on this topic either focused on only a single plaque scoring system without providing detailed analysis of results [6] or used small dataset of different images and different network architecture [8].", "startOffset": 213, "endOffset": 216}, {"referenceID": 14, "context": "Many of the modern deep learning models utilize very deep architectures to achieve superhuman performance in solving object recognition problems [15,17].", "startOffset": 145, "endOffset": 152}, {"referenceID": 16, "context": "Many of the modern deep learning models utilize very deep architectures to achieve superhuman performance in solving object recognition problems [15,17].", "startOffset": 145, "endOffset": 152}, {"referenceID": 3, "context": "One of such architectures is a novel ultra-deep residual learning network (ResNet) [4].", "startOffset": 83, "endOffset": 86}, {"referenceID": 4, "context": "This architecture can be implemented by adding so called \u2019shortcut connections\u2019 [5] which skip one or more layers.", "startOffset": 80, "endOffset": 83}, {"referenceID": 6, "context": "ResNet and many other architectures [7,12] use convolutional operator in extracting useful feature mappings in image classification task.", "startOffset": 36, "endOffset": 42}, {"referenceID": 11, "context": "ResNet and many other architectures [7,12] use convolutional operator in extracting useful feature mappings in image classification task.", "startOffset": 36, "endOffset": 42}, {"referenceID": 11, "context": "where B (l) i is a bias matrix and K (l) i,j is the filter of size (2h (l) 1 + 1)\u00d7 (2h (l) 2 + 1) connecting the j feature map in layer (l\u2212 1) with the i feature map in layer l [12].", "startOffset": 177, "endOffset": 181}, {"referenceID": 17, "context": "The analyzed 427 QLF-images were taken during a clinical intervention study [18] which was conducted at the Academic Centre for Dentistry Amsterdam.", "startOffset": 76, "endOffset": 80}, {"referenceID": 17, "context": "In total, three different experiments were performed on labels derived from plaque scoring systems such as Red Fluorescent Plaque Percentage (RF-PP) [18], Red Fluorescent modified Quigley-Hein index (RF-mQH) [19] and modified Sillness-Loe Plaque index (mSLP) [20].", "startOffset": 149, "endOffset": 153}, {"referenceID": 18, "context": "In total, three different experiments were performed on labels derived from plaque scoring systems such as Red Fluorescent Plaque Percentage (RF-PP) [18], Red Fluorescent modified Quigley-Hein index (RF-mQH) [19] and modified Sillness-Loe Plaque index (mSLP) [20].", "startOffset": 208, "endOffset": 212}, {"referenceID": 19, "context": "In total, three different experiments were performed on labels derived from plaque scoring systems such as Red Fluorescent Plaque Percentage (RF-PP) [18], Red Fluorescent modified Quigley-Hein index (RF-mQH) [19] and modified Sillness-Loe Plaque index (mSLP) [20].", "startOffset": 259, "endOffset": 263}, {"referenceID": 0, "context": "The CNN model was implemented on an NVIDIA GeForce GTX Titan X Graphics Processing Unit (GPU) using the Theano package [1].", "startOffset": 119, "endOffset": 122}, {"referenceID": 13, "context": "To compare the CNN performance with the performance of the other models, experiments were performed using various shallow classification models implemented in the Scikitlearn package [14] such as Logistic Regression (LR), Support Vector Machines Classifier with Gaussian Kernel (SVMC-K), Support Vector Machines Classifier with Linear Kernel (SVMC-L), Gaussian Nave Bayes Classifier (GNB), Gradient Boosting Classifier (GBC), K-Neighbors Classifier (KNC), and Random Forest Classifier (RFC).", "startOffset": 183, "endOffset": 187}, {"referenceID": 15, "context": "The predictive performance of the models was assessed by calculating the F1-score [16].", "startOffset": 82, "endOffset": 86}, {"referenceID": 10, "context": ", its generalization can be improved if certain a priori information about the problem is added into the choice of the model architecture [11].", "startOffset": 138, "endOffset": 142}, {"referenceID": 9, "context": "This property is explicitly embedded into the CNN model via a discrete convolution operation [10].", "startOffset": 93, "endOffset": 97}, {"referenceID": 12, "context": "Therefore, previous work performed on QLF-images [13,9] used the Red over Green pixel intensities\u2019 ratio instead of using the Red channel\u2019s pixel intensity values only.", "startOffset": 49, "endOffset": 55}, {"referenceID": 8, "context": "Therefore, previous work performed on QLF-images [13,9] used the Red over Green pixel intensities\u2019 ratio instead of using the Red channel\u2019s pixel intensity values only.", "startOffset": 49, "endOffset": 55}], "year": 2017, "abstractText": "Images are an important data source for diagnosis and treatment of oral diseases. The manual classification of images may lead to misdiagnosis or mistreatment due to subjective errors. In this paper an image classification model based on Convolutional Neural Network is applied to Quantitative Light-induced Fluorescence images. The deep neural network outperforms other state of the art shallow classification models in predicting labels derived from three different dental plaque assessment scores. The model directly benefits from multi-channel representation of the images resulting in improved performance when, besides the Red colour channel, additional Green and Blue colour channels are used.", "creator": "LaTeX with hyperref package"}}}