{"id": "1705.09222", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2017", "title": "Towards a Knowledge Graph based Speech Interface", "abstract": "Applications which use human speech as an input require a speech interface with high recognition accuracy. The words or phrases in the recognised text are annotated with a machine-understandable meaning and linked to knowledge graphs for further processing by the target application. These semantic annotations of recognised words can be represented as a subject-predicate-object triples which collectively form a graph often referred to as a knowledge graph. This type of knowledge representation facilitates to use speech interfaces with any spoken input application, since the information is represented in logical, semantic form, retrieving and storing can be followed using any web standard query languages. In this work, we develop a methodology for linking speech input to knowledge graphs and study the impact of recognition errors in the overall process. We show that for a corpus with lower WER, the annotation and linking of entities to the DBpedia knowledge graph is considerable. DBpedia Spotlight, a tool to interlink text documents with the linked open data is used to link the speech recognition output to the DBpedia knowledge graph. Such a knowledge-based speech recognition interface is useful for applications such as question answering or spoken dialog systems.", "histories": [["v1", "Tue, 23 May 2017 17:54:32 GMT  (560kb,D)", "http://arxiv.org/abs/1705.09222v1", "Under Review in International Workshop on Grounding Language Understanding, Satellite of Interspeech 2017"]], "COMMENTS": "Under Review in International Workshop on Grounding Language Understanding, Satellite of Interspeech 2017", "reviews": [], "SUBJECTS": "cs.HC cs.CL", "authors": ["ashwini jaya kumar", "s\\\"oren auer", "christoph schmidt", "joachim k\\\"ohler"], "accepted": false, "id": "1705.09222"}, "pdf": {"name": "1705.09222.pdf", "metadata": {"source": "CRF", "title": "Towards a Knowledge Graph based Speech Interface", "authors": ["Ashwini Jaya Kumar", "S\u00f6ren Auer", "Christoph Schmidt", "Joachim K\u00f6hler"], "emails": ["ashwini.jaya.kumar@iais.fraunhofer.de", "soeren.auer@iais.fraunhofer.de", "christoph.andreas.schmidt@iais.fraunhofer.de", "joachim.koehler@iais.fraunhofer.de"], "sections": [{"heading": null, "text": "Language interface with high recognition accuracy. The words or phrases in the recognized text are commented with a machine-comprehensible meaning and linked to knowledge diagrams for further processing by the target application. This type of knowledge representation facilitates the use of language interfaces with any spoken input application, since the information is presented in logical, semantic form. Retrieval and storage can be followed with any web standard query languages. In this thesis we develop a methodology for linking speech input with knowledge diagrams and investigate the effects of recognition errors on the overall process. We show that for a corpus with a lower WHO, the annotation and linking of units with the knowledge diagram of DBpedia is considerable. DBpedia Spotlight, a tool for linking text documents with the associated open data, is used to link the speech recognition output with the knowledge diagram of the language recognition system solved questions for Dpedia."}, {"heading": "1. Introduction", "text": "A language barrier that is able to understand the language of people is indeed a problem that affects not only people, but also people who are able to understand and understand the language of people. In fact, it is the case that people are able to understand and understand the language of people. In fact, it is the case that people who are able to understand the language of people do not understand the language of people. In fact, it is the case that people are able to understand the language of the people who speak it."}, {"heading": "2. Motivation", "text": "It is very difficult to train a detector for all entities in a particular language. Recognition of entities is an important factor in applications such as answering questions and spoken dialog systems. Mostly, the detector is designed to replace an unrecognized word within a given context with a similar-sounding word. In the case of two entities, predicting a third entity is simple if the combination of these three entities represents a triple in a knowledge diagram. Let's take a sentence of three entities when a false entity is replaced in the speech recognition process and this is replaced by the more appropriate entity present in Thear Xiv: 170 5.09 222v 1 [cs.H C] May 23, 201 7Knowledge diagram intuitively reduces the recognition errors. A connection in the underlying knowledge diagram between entities associated with words in a sentence provides evidence for the probability of the connection between these words and the capital of the intuition <"}, {"heading": "3. Linking Speech to Knowledge Graphs", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "4. Implementation", "text": "Entity annotation must be performed in such a way that textual entity references are linked to the triples in a knowledge diagram. To this end, we use DBpedia Spotlight [2]. DBpedia Spotlight is a tool for linking text documents to knowledge diagrams that allows the knowledge embedded in the documents to be used for relevant applications. It automatically comments on the text documents and links them to DBpedia entities (identified via URIs). Details for recognizing the phrase in a sentence, candidate selection, discambiguity and configuration are presented in [2]. DBpedia Spotlight calculates results such as prominence, topic relevance and contextual ambiguity. Prominence calculates how often a resource is mentioned in Wikipedia. A term called support is used for prominence and priority score for normalized discrepancy in the software DBpedia Spotlight."}, {"heading": "5. Experimental Evaluation", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "6. Related Work", "text": "In [11] a framework for labeling the BBC program archive is proposed that uses DBpedia as the source of tag identifiers, using speech recognition, word processing, and concept marking techniques, which have shown positive signs of the boot-stressing process of linking archived content. In [12], the information presented in the knowledge diagram is used to improve the performance of a statistical dependency saver. [13], the work focuses on the recognition of relationships such as coordination and apposition. Apposition is a relationship between two adjacent noun phrases and coordination between nouns that contain two or more elements of the same kind. In [13], information about entities encoded in FreeBase is used for the extraction of relationships. FreeBase noble types are simple atomic labels that indicate what the entity is noteworthy for, and thus serve as a useful source of information. [14] Textual data are used both for the three-way relationship extraction from the knowledge base."}, {"heading": "7. Conclusion", "text": "A language interface to speech-as-input applications involves recognizing and interpreting the spoken utterance. A knowledge-diagram-based language interface system is discussed that can be used for any speech-as-input application. We presented a method for linking speech input to a knowledge diagram. Speech recognition, which is the first step of linking, tends to make mistakes and its performance is important for the success of the overall performance of the application for which it was designed. In this work, we examined the effects of recognition errors on the linking process of speech input with a knowledge diagram. We consider this work to be the first step in a larger research agenda. In particular, exploring the use of semantic information from knowledge diagrams to improve recognition accuracy is a highly promising research direction."}, {"heading": "8. Acknowledgements", "text": "Parts of this work were funded under the European Union's Horizon 2020 research and innovation programme as part of the Marie Sklodowska-Curie funding agreement 642795 (WDAqua project)."}, {"heading": "9. References", "text": "[1] S. Auer, J. Lehmann, A. N. Ngomo, and A. Zaveri Jakob, \"Introductionto linked data and its lifecycle on the web,\" in Reasoning Web. Semantic Technologies for Intelligent Data Access - 9th International Summer School 2013, Mannheim, Germany, July 30 - August 2, 2013. Proceedings, ser. Lecture Notes in Computer Science, S. Rudolph, G. Gottlob, I. Horrocks, and F. van Harmelen, Eds., vol. 8067. Springer, 2013, pp. 1-90. [Online]. Available: http: / / dx.doi.org Notes in Computer Science / 10.1007 / 978-342-39784-4. [2] P. N. Mendes, M. Jakob, A. Garc\u0131 \"a-Silva, and C. Bizer,\" Dbpedia-Spotlight on the web of documents, \"Shedding light on the web of documents, in Proceedings of the 7th International ser Systems."}], "references": [{"title": "Introduction to linked data and its lifecycle on the web", "author": ["S. Auer", "J. Lehmann", "A.N. Ngomo", "A. Zaveri"], "venue": "Reasoning Web. Semantic Technologies for Intelligent Data Access - 9th International Summer School 2013, Mannheim, Germany, July 30 - August 2, 2013. Proceedings, ser. Lecture Notes in Computer Science, S. Rudolph, G. Gottlob, I. Horrocks, and F. van Harmelen, Eds., vol. 8067. Springer, 2013, pp. 1\u201390. [Online]. Available: http://dx.doi.org/10.1007/978-3-642-39784-4 1", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Dbpedia spotlight: Shedding light on the web of documents", "author": ["P.N. Mendes", "M. Jakob", "A. Garc\u0131\u0301a-Silva", "C. Bizer"], "venue": "Proceedings of the 7th International Conference on Semantic Systems, ser. I-Semantics \u201911. New York, NY, USA: ACM, 2011, pp. 1\u20138. [Online]. Available: http://doi.acm.org/10.1145/ 2063518.2063519", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "A dialogue with linked data: Voice-based access to market data in the sahel", "author": ["V. de Boer", "N.B. Gyan", "A. Bon", "W. Tuyp", "C. van Aart", "H. Akkermans"], "venue": "Semantic Web, vol. 6, no. 1, pp. 23\u2013 33, 2015.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "A neural knowledge language model", "author": ["S. Ahn", "H. Choi", "T. P\u00e4rnamaa", "Y. Bengio"], "venue": "arXiv preprint arXiv:1608.00318, 2016.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Using a knowledge graph and query click logs for unsupervised learning of relation detection", "author": ["D. Hakkani-Tur", "L. Heck", "G. Tur"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on. IEEE, 2013, pp. 8327\u20138331.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Rapidly building domain-specific entity-centric language models using semantic web knowledge sources", "author": ["M. Akbacak", "D. Hakkani-T\u00fcr", "G. Tur"], "venue": "Fifteenth Annual Conference of the International Speech Communication Association, 2014.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Exploiting the semantic web for unsupervised spoken language understanding", "author": ["L. Heck", "D. Hakkani-Tur"], "venue": "Spoken Language Technology Workshop (SLT), 2012 IEEE. IEEE, 2012, pp. 228\u2013233.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Dbpedia - A large-scale, multilingual knowledge base extracted from wikipedia", "author": ["J. Lehmann", "R. Isele", "M. Jakob", "A. Jentzsch", "D. Kontokostas", "P.N. Mendes", "S. Hellmann", "M. Morsey", "P. van Kleef", "S. Auer", "C. Bizer"], "venue": "Semantic Web, vol. 6, no. 2, pp. 167\u2013195, 2015. [Online]. Available: http://dx.doi.org/10.3233/SW-140134", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "The kaldi speech recognition toolkit", "author": ["D. Povey", "A. Ghoshal", "G. Boulianne", "L. Burget", "O. Glembek", "N. Goel", "M. Hannemann", "P. Motlicek", "Y. Qian", "P. Schwarz"], "venue": "IEEE 2011 workshop on automatic speech recognition and understanding, no. EPFL- CONF-192584. IEEE Signal Processing Society, 2011.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Automated interlinking of speech radio archives", "author": ["Y. Raimond", "C. Lowis"], "venue": "In proceedings of the Linked Data on the Web Workshop (LDOW), World Wide Web conference,, 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Projecting the knowledge graph to syntactic parsing.", "author": ["A. Gesmundo", "K. Hall"], "venue": "EACL,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Using entity information from a knowledge base to improve relation extraction", "author": ["L. Du", "A. Kumar", "M. Johnson", "M. Ciaramita"], "venue": "Proceedings of the 13th annual workshop of The Australasian Language Technology Association, 2015.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Connecting language and knowledge bases with embedding models for relation extraction", "author": ["J. Weston", "A. Bordes", "O. Yakhnenko", "N. Usunier"], "venue": "arXiv preprint arXiv:1307.7973, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Based on RDF, the Linked Data paradigm [1] aims at connecting related data on the Web by reusing and referring to existing data and schema elements using the respective IRI/URI identifiers.", "startOffset": 39, "endOffset": 42}, {"referenceID": 1, "context": "Linking text to LOD increases the discoverability of information [2] in the context of the spoken utterance.", "startOffset": 65, "endOffset": 68}, {"referenceID": 2, "context": "For spoken response, [3] shows how Linked Data can be used for a voice-based mobile phone application.", "startOffset": 21, "endOffset": 24}, {"referenceID": 3, "context": "Using a knowledge graph for natural language processing, in particular, for language modeling is introduced in [4].", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "However, some initial recent efforts to use a knowledge graph for language understanding are presented in [5, 6, 7].", "startOffset": 106, "endOffset": 115}, {"referenceID": 5, "context": "However, some initial recent efforts to use a knowledge graph for language understanding are presented in [5, 6, 7].", "startOffset": 106, "endOffset": 115}, {"referenceID": 6, "context": "However, some initial recent efforts to use a knowledge graph for language understanding are presented in [5, 6, 7].", "startOffset": 106, "endOffset": 115}, {"referenceID": 7, "context": "One of the most commonly used knowledge graphs is DBpedia [8], which represents statements extracted from Wikipedia.", "startOffset": 58, "endOffset": 61}, {"referenceID": 1, "context": "We are using DBpedia Spotlight [2] for that purpose.", "startOffset": 31, "endOffset": 34}, {"referenceID": 1, "context": "Details on spotting the phrase in a sentence, candidate selection, disambiguation and configuration are presented in [2].", "startOffset": 117, "endOffset": 120}, {"referenceID": 8, "context": "We are using the Wall Street Journal (LDC93S6A and LDC94S13A) and the TED-LIUM corpus for training and evaluation of the ASR performance, and the Kaldi [9] toolkit for development.", "startOffset": 152, "endOffset": 155}, {"referenceID": 9, "context": "In [11], a framework to tag the BBC programme archive using DBpedia as a source of tag identifiers is proposed.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "In [12], the information presented in the knowledge graph is used to improve the performance of a statistical dependency Figure 5: Histogram of topic pertinence score obtained from", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "In [13] the information about entities encoded in FreeBase notable types is used for relation extraction.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "[14] uses both labeled text data and triples from the knowledge base for relation extraction.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "Applications which use human speech as an input require a speech interface with high recognition accuracy. The words or phrases in the recognised text are annotated with a machineunderstandable meaning and linked to knowledge graphs for further processing by the target application. This type of knowledge representation facilitates to use speech interfaces with any spoken input application, since the information is represented in logical, semantic form., retrieving and storing can be followed using any web standard query languages. In this work, we develop a methodology for linking speech input to knowledge graphs and study the impact of recognition errors in the overall process. We show that for a corpus with lower WER, the annotation and linking of entities to the DBpedia knowledge graph is considerable. DBpedia Spotlight, a tool to interlink text documents with the linked open data is used to link the speech recognition output to the DBpedia knowledge graph. Such a knowledge-based speech recognition interface is useful for applications such as question answering or spoken dialog systems.", "creator": "LaTeX with hyperref package"}}}