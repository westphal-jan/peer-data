{"id": "1705.09515", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-May-2017", "title": "ASR error management for improving spoken language understanding", "abstract": "This paper addresses the problem of automatic speech recognition (ASR) error detection and their use for improving spoken language understanding (SLU) systems. In this study, the SLU task consists in automatically extracting, from ASR transcriptions , semantic concepts and concept/values pairs in a e.g touristic information system. An approach is proposed for enriching the set of semantic labels with error specific labels and by using a recently proposed neural approach based on word embeddings to compute well calibrated ASR confidence measures. Experimental results are reported showing that it is possible to decrease significantly the Concept/Value Error Rate with a state of the art system, outperforming previously published results performance on the same experimental data. It also shown that combining an SLU approach based on conditional random fields with a neural encoder/decoder attention based architecture , it is possible to effectively identifying confidence islands and uncertain semantic output segments useful for deciding appropriate error handling actions by the dialogue manager strategy .", "histories": [["v1", "Fri, 26 May 2017 10:34:24 GMT  (56kb,D)", "http://arxiv.org/abs/1705.09515v1", "Interspeech 2017, Aug 2017, Stockholm, Sweden. 2017"]], "COMMENTS": "Interspeech 2017, Aug 2017, Stockholm, Sweden. 2017", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.NE", "authors": ["edwin simonnet", "sahar ghannay", "nathalie camelin", "yannick est\\`eve", "renato de mori"], "accepted": false, "id": "1705.09515"}, "pdf": {"name": "1705.09515.pdf", "metadata": {"source": "CRF", "title": "ASR error management for improving spoken language understanding", "authors": ["Edwin Simonnet", "Sahar Ghannay", "Nathalie Camelin", "Yannick Est\u00e8ve", "Renato De Mori"], "emails": ["firstname.lastname@univ-lemans.fr,", "rdemori@cs.mcgill.ca"], "sections": [{"heading": "1. Introduction", "text": "Despite impressive research efforts and recent results, semantic interpretation systems still make mistakes. Some of the problems that text and language have in common are: difficulties in mentioning the localization of the concept, ambiguities contained in localized mentions, shortcomings in identifying sufficient contextual constraints to resolve interpretive ambiguities. Additional problems arise from the interaction between a language understanding (SLU) and an error-prone automatic speech recognition system (ASR). ASR errors can affect the mention of a concept, the value of a concept instance. Furthermore, the hypothesis of concepts and values depends, among other things, on the context in which their mention is located. Context errors can therefore also introduce errors in concept mentioning the location and hypothesis. The focus of this paper is on the introduction of appropriate ASR confidence measures to locate ASR word errors that impair SLU performance."}, {"heading": "2. Related work", "text": "SLU systems are error-prone, some of which are caused by certain types of ASR errors. In general, ASR errors are reduced by estimating model parameters by minimizing the expected word error rate. [2] The effects of word errors can be controlled by assigning a single sentence hypothesis to Word Confidence Measures. [3] Methods for constructing confidence traits to improve the quality of a semantic confidence measurement are proposed. Confidence calibration methods are based on the maximum entropy model with distribution constraints, the conventional artificial neural network, and the deep faith network (DBN), the latter two methods showing marginally superior performance but higher computational complexity compared to the former. More recently [4] new functions and bi-directional recursive neural networks (RNN) are proposed for ASR error detection. Most SU systems are tested in [5] hypotheses."}, {"heading": "3. ASR error detection and confidence measure", "text": "Two different confidence measures are used for error detection: The first is the word posterior probability, which is calculated using confusing networks, as described in [2]; the second is a variant of a new approach introduced in [13, 14]; the latter is calculated using a multi-stream multi-layer perceptron (MS-MLP) architecture, fed by various heterogeneous confidence characteristics, among which are the most relevant for SLU word embedding of the target and its neighbors, length of the current word, language model backoff behavior, part of the language (POS) tags, syntactical dependency markers, and word governors. However, other features, such as prosodic features and acoustic word embedding, which could also be used in [15] and [14], were not taken into account in the experiments described in this paper."}, {"heading": "4. SLU features and architectures", "text": "Two basic SLU architectures are considered experiments on the MEDIA corpus (described in subsection 5.1): The first is based on an encoder / decoder recursive neural architecture with an attention mechanism (NN-EDA) similar to the mechanism for machine translation proposed in [12]; the second is based on conditional random fields (CRF - [17]); both architectures build their training model on the same characteristics encoded with continuous values in the first and discrete values in the second."}, {"heading": "4.1. Set of Features", "text": "Word characteristics, including those defined to facilitate the assignment of a word to a semantic content, are defined as follows: \u2022 the word itself \u2022 its predefined semantic categories, which belong to: - MEDIA-specific categories: such as street names, city names or hotel names, lists of furnishings, type of food,... e.g.: Paris CITY - more general categories: such as numbers, days, months,... e.g.: FIGURE for thirty-three. \u2022 a set of syntactic characteristics: the MACAON tool [18] is applied to the entire round to obtain for each word its following keywords: the lemma, the POS tag, its word governor and its relationship to the current word. \u2022 a set of morphological characteristics: the 1-to-4 first letter Ngrams, the 1-4 letter-last ngrams of the word, and a binary attribute indicating whether the first letter ASS is a trust ASS (the two)."}, {"heading": "4.2. Neural EDA system", "text": "The proposed RNN encoder decoder architecture with an attention-based mechanism (NN-EDA) is inspired by a machine translation architecture and is presented in Figure 2. Concept tagging is considered a translation problem from words (source language) to semantic concept tags (target language) This bi-directional RNN encoder is based on gated recurrent units (GRU) and calculates for each word wi from the input sequence w1,..., wI. This comment is the concatenation of the appropriate hidden layer state and the hidden layer state, each gained by the front RNN and the backward RNN. Each comment contains the summaries of the dialog contexts preceding each preceding a preceding and following word. The sequence of annotations h1,..., hI is used by the decoder to calculate a net context based on a figure 2."}, {"heading": "4.3. CRF system", "text": "Previous experiments described in [1] have shown that the best semantic annotation performance was achieved on manual and automatic transcriptions of the MEDIA corpus with CRF systems. More recently, this architecture has been compared to the popular bi-directional RNN (bi-RNN).The result was that CRF systems outperform a bi-directional architecture on the MEDIA corpus, while Bi-RNN on the ATIS [20] corpus.This is probably explained by the fact that MEDIA contains semantic content that is more difficult to disamb and CRFs allow complex contexts to be exploited more effectively. To improve the comparison with the best SLU system proposed in [1], the Wapiti toolkit has been used [21]. However, the range of input functions used in this paper is different."}, {"heading": "5. Experimental setup and results", "text": "Experiments were carried out with the MEDIA corpus as in [1]. For comparison, the results of their best comprehensibility2https: / / gforge.inria.fr / projects / discretize4crf / system are given as baseline in this paper. However, since the WHO of the ASR used in this paper is lower (23.5%) than that used in this paper, strict conclusions can only be drawn from comparisons between the various SLU components presented in this paper."}, {"heading": "5.1. The MEDIA corpus", "text": "The MEDIA corpus was collected within the framework of the French Media / Evalda project [22] and deals with the procurement of tourism services. It contains three sets of telephone-human-computer dialogues, namely: a training set (TRAIN) with approximately 17.7k sentences, a development set (DEV) with 1.3k sentences and a valuation set (TEST) with 3.5 k sentences. The corpus was commented manually with semantic concepts, which are characterized by a label and their value. Other types of semantic comments (such as mode or specifier) are not considered in this essay to be compatible with the experimental results provided in [1]. Comments also associate a sequence of words with the concepts. These sequences must be considered as estimates of localized concept references. Evaluations are carried out with the DEV and TEST sentences and report concept error rates (CER) only for concept labels and concept error rates (CER)."}, {"heading": "5.2. LIUM ASR system dedicated to MEDIA", "text": "For these experiments, a variant of the ASR system developed by LIUM, which won the last evaluation campaign for the French language [23], was used. This system is based on the Kaldi voice recognition toolkit [25] and ESTER2 [26] corpora, which is responsible for about 100 hours of speech; the TV program ETAPE corpus [27], which is responsible for about 30 hours of speech; the TV program REPERE corpus, which is responsible for about 35 hours of speech; the TV program ETAPE corpus [27], which is responsible for about 30 hours of speech; the TV program REPERE train corpus, which is responsible for about 30 hours of speech and other LIUM broadcast data for about 300 hours of speech."}, {"heading": "23.7% 23.4% 23.6%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.3. Results", "text": "The best results of this kind are usually obtained in the form of X-rays, which are able to analyze the results of X-rays."}, {"heading": "6. Conclusions", "text": "Two variants of two SLU architectures, each based on CRFs and NN-EDA, were considered. Using the MEDIA corpus, they were compared to the CRF corpus, which is considered to be the baseline and yielded the best results among seven different approaches, as reported in [1]. Nevertheless, the main novelties of the proposed SLU architectures appeared to be useful in combination with the CRF architectures, showing that the interaction between the ASR and SLU components is beneficial. Furthermore, all architectures show that most errors concern concepts whose mention consists of short, confusing sequences of words that remain ambiguous, even if they can be localized. These concept types are particularly difficult to recognize manually, which indicates that the task itself is a difficult one to interpret."}, {"heading": "7. References", "text": "In fact, most people are able to understand themselves and what they are doing. [1] S. Hahn, M. Dinarelli, C. Lefevre, P. Lehnen, R. De Mori, A. Moschitti, H. Ney, and G. Riccardi, \"Comparing stochastic approach to spoken understanding in multiple languages,\" IEEE Transactions on Audio, Speech, and Language Processing, vol. 6, pp.1569-1583, 2011. [2] L. Mangu, E. A. Stolcke, Finding consensus in speech recognition: word error minimization and other applications of confusion networks, \"Computer Speech and Language Processing, vol. 14, no."}], "references": [{"title": "Comparing stochastic approaches to spoken language understanding in multiple languages", "author": ["S. Hahn", "M. Dinarelli", "C. Raymond", "F. Lefevre", "P. Lehnen", "R. De Mori", "A. Moschitti", "H. Ney", "G. Riccardi"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 19, no. 6, pp. 1569\u20131583, 2011.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Finding consensus in speech recognition: word error minimization and other applications of confusion networks", "author": ["L. Mangu", "E. Brill", "A. Stolcke"], "venue": "Computer Speech & Language, vol. 14, no. 4, pp. 373\u2013400, 2000.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2000}, {"title": "Calibration of confidence measures in speech recognition", "author": ["D. Yu", "J. Li", "L. Deng"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 19, no. 8, pp. 2461\u20132473, 2011.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Asr error detection and recognition rate estimation using deep bidirectional recurrent neural networks", "author": ["A. Ogawa", "T. Hori"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on. IEEE, 2015, pp. 4370\u20134374.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Spoken language understanding: Systems for extracting semantic information from speech", "author": ["G. Tur", "R. De Mori"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Using recurrent neural networks for slot filling in spoken language understanding", "author": ["G. Mesnil", "Y. Dauphin", "K. Yao", "Y. Bengio", "L. Deng", "D. Hakkani- Tur", "X. He", "L. Heck", "G. Tur", "D. Yu"], "venue": "IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP), vol. 23, no. 3, pp. 530\u2013539, 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Multi-domain joint semantic frame parsing using bi-directional rnn-lstm", "author": ["D. Hakkani-T\u00fcr", "G. Tur", "A. Celikyilmaz", "Y.-N. Chen", "J. Gao", "L. Deng", "Y.-Y. Wang"], "venue": "Proceedings of The 17th Annual Meeting of the International Speech Communication Association, 2016.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "Transforming dependency structures to logical forms for semantic parsing", "author": ["S. Reddy", "O. T\u00e4ckstr\u00f6m", "M. Collins", "T. Kwiatkowski", "D. Das", "M. Steedman", "M. Lapata"], "venue": "Transactions of the Association for Computational Linguistics, vol. 4, pp. 127\u2013140, 2016.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Dependency-based convolutional neural networks for sentence embedding", "author": ["M. Ma", "L. Huang", "B. Xiang", "B. Zhou"], "venue": "The 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing. Association for Computational Linguistics, 2015.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Syntax or semantics? knowledge-guided joint semantic frame parsing", "author": ["Y.-N. Chen", "D. Hakanni-T\u00fcr", "G. Tur", "A. Celikyilmaz", "J. Guo", "L. Deng"], "venue": "IEEE Workshop on Spoken Language Technology (SLT 2016), San Diego, USA, 2016.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Exploring the use of attention-based recurrent neural networks for spoken language understanding", "author": ["E. Simonnet", "N. Camelin", "P. Deleglise", "Y. Esteve"], "venue": "NIPS, 2015.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["K. Cho", "B. van Merrienboer", "C. Gulcehre", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": "EMNLP, 2014.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Word embeddings combination and neural networks for robustness in asr error detection", "author": ["S. Ghannay", "Y. Esteve", "N. Camelin"], "venue": "Signal Processing Conference (EUSIPCO), 2015 23rd European. Nice, France: IEEE, 2015, pp. 1671\u20131675.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Acoustic word embeddings for asr error detection", "author": ["S. Ghannay", "Y. Esteve", "N. Camelin"], "venue": "Interspeech 2016, pp. 1330\u20131334, 2016.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Combining continuous word representation and prosodic features for asr error prediction", "author": ["S. Ghannay", "Y. Est\u00e8ve", "N. Camelin", "C. Dutrey", "F. Santiago", "M. Adda-Decker"], "venue": "International Conference on Statistical Language and Speech Processing. Springer, 2015, pp. 84\u201395.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Word embedding evaluation and combination", "author": ["S. Ghannay", "B. Favre", "Y. Esteve", "N. Camelin"], "venue": "of the Language Resources and Evaluation Conference (LREC 2016), Portoroz (Slovenia), 2016, pp. 23\u201328.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. Lafferty", "A. McCallum", "F. Pereira"], "venue": "Proceedings of the eighteenth international conference on machine learning, ICML, vol. 1, 2001, pp. 282\u2013289.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2001}, {"title": "Macaon : Une chane linguistique pour le traitement de graphes de mots", "author": ["A. Nasr", "F. Bchet", "J.-F. Rey"], "venue": "Traitement Automatique des Langues Naturelles - session de dmonstrations, Montral, 2010.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Is it time to switch to word embedding and recurrent neural networks for spoken language understanding?", "author": ["V. Vukotic", "C. Raymond", "G. Gravier"], "venue": "InterSpeech,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "The atis spoken language systems pilot corpus", "author": ["C.T. Hemphill", "J.J. Godfrey", "G.R. Doddington"], "venue": "Proceedings of the DARPA speech and natural language workshop, 1990, pp. 96\u2013 101.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1990}, {"title": "Practical very large scale CRFs", "author": ["T. Lavergne", "O. Capp\u00e9", "F. Yvon"], "venue": "Proceedings the 48th Annual Meeting of the Association for Computational Linguistics (ACL). Association for Computational Linguistics, July 2010, pp. 504\u2013513. [Online]. Available: http://www.aclweb.org/anthology/P10-1052", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Semantic annotation of the french media dialog corpus", "author": ["H. Bonneau-Maynard", "S. Rosset", "C. Ayache", "A. Kuhn", "D. Mostefa"], "venue": "Ninth European Conference on Speech Communication and Technology, 2005.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2005}, {"title": "LIUM and CRIM ASR system combination for the REPERE evaluation campaign", "author": ["A. Rousseau", "G. Boulianne", "P. Del\u00e9glise", "Y. Est\u00e8ve", "V. Gupta", "S. Meignier"], "venue": "International Conference on Text, Speech, and Dialogue. Springer, 2014, pp. 441\u2013448.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "The kaldi speech recognition toolkit", "author": ["D. Povey", "A. Ghoshal", "G. Boulianne", "L. Burget", "O. Glembek", "N. Goel", "M. Hannemann", "P. Motlicek", "Y. Qian", "P. Schwarz"], "venue": "IEEE 2011 workshop on automatic speech recognition and understanding, no. EPFL- CONF-192584. IEEE Signal Processing Society, 2011.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Corpus description of the Ester evaluation campaign for the rich transcription of French broadcast news", "author": ["S. Galliano", "E. Geoffrois", "G. Gravier", "J. f. Bonastre", "D. Mostefa", "K. Choukri"], "venue": "5th international Conference on Language Resources and Evaluation (LREC), 2006, pp. 315\u2013320.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2006}, {"title": "The Ester 2 evaluation campaign for the rich transcription of french radio broadcasts", "author": ["S. Galliano", "G. Gravier", "L. Chaubard"], "venue": "Interspeech, 2009.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "The ETAPE corpus for the evaluation of speechbased TV content processing in the French language", "author": ["G. Gravier", "G. Adda", "N. Paulsson", "M. Carr\u00e9", "A. Giraudel", "O. Galibert"], "venue": "Eighth International Conference on Language Resources and Evaluation (LREC), Istanbul, Turkey, 2012, pp. 114\u2013118.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "A post-processing system to yield reduced word error rates: Recognizer output voting error reduction (rover)", "author": ["J.G. Fiscus"], "venue": "Automatic Speech Recognition and Understanding, 1997. Proceedings., 1997 IEEE Workshop on. IEEE, 1997, pp. 347\u2013354.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1997}], "referenceMentions": [{"referenceID": 0, "context": "3% with respect to a baseline described in [1] not using these features and based only on CRFs.", "startOffset": 43, "endOffset": 46}, {"referenceID": 1, "context": "In general, ASR errors are reduced by estimating model parameters by minimizing the expected word error rate [2].", "startOffset": 109, "endOffset": 112}, {"referenceID": 2, "context": "In [3] methods are proposed for constructing confidence features for improving the quality of a semantic confidence measure.", "startOffset": 3, "endOffset": 6}, {"referenceID": 3, "context": "More recently [4], new features and bidirectional recurrent neural networks (RNN) have been proposed for ASR error detection.", "startOffset": 14, "endOffset": 17}, {"referenceID": 4, "context": "Most SLU systems reviewed in [5] generate hypotheses of semantic frame slot tags expressed in a spoken sentence analyzed by an ASR system.", "startOffset": 29, "endOffset": 32}, {"referenceID": 5, "context": "The use of deep neural networks (DNN) appeared in more recent systems as described in [6].", "startOffset": 86, "endOffset": 89}, {"referenceID": 6, "context": "Bidirectional RNNs with long-short term memory (LSTM) have been used for semantic frame slot tagging [7].", "startOffset": 101, "endOffset": 104}, {"referenceID": 7, "context": "In [8], LSTMs have been proposed with a mechanism of attention for parsing text sentences to logical forms.", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": "Following [9], in [10] a convolutional neural network (CNN) is proposed for encoding the representation of knowledge expressed in a spoken sentence.", "startOffset": 10, "endOffset": 13}, {"referenceID": 9, "context": "Following [9], in [10] a convolutional neural network (CNN) is proposed for encoding the representation of knowledge expressed in a spoken sentence.", "startOffset": 18, "endOffset": 22}, {"referenceID": 10, "context": "The first one, based an encoder with bidirectional gated recurrent units (GRU) used for machine translation [11], integrates context information with an attention based decoder as in [12].", "startOffset": 108, "endOffset": 112}, {"referenceID": 11, "context": "The first one, based an encoder with bidirectional gated recurrent units (GRU) used for machine translation [11], integrates context information with an attention based decoder as in [12].", "startOffset": 183, "endOffset": 187}, {"referenceID": 0, "context": "The second one integrates context information in the same architecture used in [1] based on conditional random fields (CRF).", "startOffset": 79, "endOffset": 82}, {"referenceID": 1, "context": "The first one is the word posterior probability computed with confusion networks as described in [2].", "startOffset": 97, "endOffset": 100}, {"referenceID": 12, "context": "The other one is a variant of a new approach, introduced in [13, 14].", "startOffset": 60, "endOffset": 68}, {"referenceID": 13, "context": "The other one is a variant of a new approach, introduced in [13, 14].", "startOffset": 60, "endOffset": 68}, {"referenceID": 14, "context": "Other features, such as prosodic features and acoustic word embeddings described in [15] and [14] could also be used but were not considered in the experiments described in this paper.", "startOffset": 84, "endOffset": 88}, {"referenceID": 13, "context": "Other features, such as prosodic features and acoustic word embeddings described in [15] and [14] could also be used but were not considered in the experiments described in this paper.", "startOffset": 93, "endOffset": 97}, {"referenceID": 15, "context": "A particular attention was carried on the word embeddings computation, which is the result of a combination of different well known word embeddings (CBOW, Skip-gram, GloVe) made through the use of a neural auto-encoder in order to improve the performances of this ASR error detection system [16].", "startOffset": 291, "endOffset": 295}, {"referenceID": 14, "context": "Experiments have shown that this is a calibrated confidence measure more effective than word posterior probability when comparison is based on the Normalized Cross Entropy (NCE) [15], which measures the information contribution provided by confidence knowledge.", "startOffset": 178, "endOffset": 182}, {"referenceID": 11, "context": "The first one is an encoder/decoder recurrent neural architecture with a mechanism of attention (NN-EDA) similar to the one used for machine translation proposed in [12].", "startOffset": 165, "endOffset": 169}, {"referenceID": 16, "context": "The second one is based on conditional random fields (CRF - [17]).", "startOffset": 60, "endOffset": 64}, {"referenceID": 17, "context": "\u2022 a set of syntactic features: the MACAON tool [18] is applied to the whole turn in order to obtain for each word its following tags: the lemma, the POS tag, its word governor and its relation with the current word.", "startOffset": 47, "endOffset": 51}, {"referenceID": 10, "context": "A more detailled description of recurent neural networks and attention based ones can be found in [11].", "startOffset": 98, "endOffset": 102}, {"referenceID": 0, "context": "Past experiments described in [1] have shown that the best semantic annotation performance on manual and automatic transcriptions of the MEDIA corpus were obtained with CRF systems.", "startOffset": 30, "endOffset": 33}, {"referenceID": 18, "context": "More recently in [19], this architecture has been compared to popular bi-directionnal RNN (bi-RNN).", "startOffset": 17, "endOffset": 21}, {"referenceID": 19, "context": "The results was that CRF systems outperform a bi-RNN architecture on the MEDIA corpus, while better results were observed by bi-RNN on the ATIS [20] corpus.", "startOffset": 144, "endOffset": 148}, {"referenceID": 0, "context": "For the sake of comparison with the best SLU system proposed in [1], the Wapiti toolkit was used [21].", "startOffset": 64, "endOffset": 67}, {"referenceID": 20, "context": "For the sake of comparison with the best SLU system proposed in [1], the Wapiti toolkit was used [21].", "startOffset": 97, "endOffset": 101}, {"referenceID": 0, "context": "Nevertheless, the set of input features used by the system proposed in this paper is different from the one used in [1].", "startOffset": 116, "endOffset": 119}, {"referenceID": 0, "context": "Experiments were carried with the MEDIA corpus as in [1].", "startOffset": 53, "endOffset": 56}, {"referenceID": 21, "context": "The MEDIA corpus was collected in the French Media/Evalda project [22] and deals with negotiation of tourist services.", "startOffset": 66, "endOffset": 70}, {"referenceID": 0, "context": "Other types of semantic annotations (such as mode or specifiers) are not considered in this paper to be consistent with the experimental results provided in [1].", "startOffset": 157, "endOffset": 160}, {"referenceID": 22, "context": "For these experiments, a variant of the ASR system developed by LIUM that won the last evaluation campaign on French language has been used [23].", "startOffset": 140, "endOffset": 144}, {"referenceID": 23, "context": "This system is based on the Kaldi speech recognition toolkit [24].", "startOffset": 61, "endOffset": 65}, {"referenceID": 24, "context": "The training set used to estimate the DNN (Deep Neural Networks) acoustic models parameters consists of 145,781 speech segments from several sources: the radiophonic broadcast ESTER [25] and ESTER2 [26] corpora, which accounts for about 100 hours of speech each; the TV broadcast ETAPE corpus [27], accounting for about 30 hours of speech; the TV broadcast REPERE train corpus, accounting for about 35 hours of speech and other LIUM radio and TV broadcast data for about 300 hours of speech.", "startOffset": 182, "endOffset": 186}, {"referenceID": 25, "context": "The training set used to estimate the DNN (Deep Neural Networks) acoustic models parameters consists of 145,781 speech segments from several sources: the radiophonic broadcast ESTER [25] and ESTER2 [26] corpora, which accounts for about 100 hours of speech each; the TV broadcast ETAPE corpus [27], accounting for about 30 hours of speech; the TV broadcast REPERE train corpus, accounting for about 35 hours of speech and other LIUM radio and TV broadcast data for about 300 hours of speech.", "startOffset": 198, "endOffset": 202}, {"referenceID": 26, "context": "The training set used to estimate the DNN (Deep Neural Networks) acoustic models parameters consists of 145,781 speech segments from several sources: the radiophonic broadcast ESTER [25] and ESTER2 [26] corpora, which accounts for about 100 hours of speech each; the TV broadcast ETAPE corpus [27], accounting for about 30 hours of speech; the TV broadcast REPERE train corpus, accounting for about 35 hours of speech and other LIUM radio and TV broadcast data for about 300 hours of speech.", "startOffset": 293, "endOffset": 297}, {"referenceID": 27, "context": "The results are reported in Table 6 and compared with the ROVER [28] combination applied to the six SLU systems described in [1].", "startOffset": 64, "endOffset": 68}, {"referenceID": 0, "context": "The results are reported in Table 6 and compared with the ROVER [28] combination applied to the six SLU systems described in [1].", "startOffset": 125, "endOffset": 128}, {"referenceID": 0, "context": "Using the MEDIA corpus, they were compared with the CRF SLU, considered as baseline that provided the best results among seven different approaches as reported in [1].", "startOffset": 163, "endOffset": 166}], "year": 2017, "abstractText": "This paper addresses the problem of automatic speech recognition (ASR) error detection and their use for improving spoken language understanding (SLU) systems. In this study, the SLU task consists in automatically extracting, from ASR transcriptions, semantic concepts and concept/values pairs in a e.g touristic information system. An approach is proposed for enriching the set of semantic labels with error specific labels and by using a recently proposed neural approach based on word embeddings to compute well calibrated ASR confidence measures. Experimental results are reported showing that it is possible to decrease significantly the Concept/Value Error Rate with a state of the art system, outperforming previously published results performance on the same experimental data. It also shown that combining an SLU approach based on conditional random fields with a neural encoder/decoder attention based architecture, it is possible to effectively identifying confidence islands and uncertain semantic output segments useful for deciding appropriate error handling actions by the dialogue manager strategy.", "creator": "LaTeX with hyperref package"}}}