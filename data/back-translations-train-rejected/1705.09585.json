{"id": "1705.09585", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-May-2017", "title": "Detecting and Explaining Crisis", "abstract": "Individuals on social media may reveal themselves to be in various states of crisis (e.g. suicide, self-harm, abuse, or eating disorders). Detecting crisis from social media text automatically and accurately can have profound consequences. However, detecting a general state of crisis without explaining why has limited applications. An explanation in this context is a coherent, concise subset of the text that rationalizes the crisis detection. We explore several methods to detect and explain crisis using a combination of neural and non-neural techniques. We evaluate these techniques on a unique data set obtained from Koko, an anonymous emotional support network available through various messaging applications. We annotate a small subset of the samples labeled with crisis with corresponding explanations. Our best technique significantly outperforms the baseline for detection and explanation.", "histories": [["v1", "Fri, 26 May 2017 13:44:54 GMT  (120kb,D)", "http://arxiv.org/abs/1705.09585v1", "Accepted at CLPsych, ACL workshop. 8 pages, 5 figures"]], "COMMENTS": "Accepted at CLPsych, ACL workshop. 8 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["rohan kshirsagar", "robert morris", "sam bowman"], "accepted": false, "id": "1705.09585"}, "pdf": {"name": "1705.09585.pdf", "metadata": {"source": "CRF", "title": "Detecting and Explaining Crisis", "authors": ["Rohan Kshirsagar", "Robert Morris", "Samuel R. Bowman"], "emails": ["rmk2161@columbia.edu", "rob@itskoko.com", "bowman@nyu.edu"], "sections": [{"heading": null, "text": "An explanation in this context is a coherent, concise subset of the text that streamlines crisis detection. We examine various methods of detecting and explaining crises using a combination of neural and non-neural techniques. We evaluate these techniques using a unique dataset from Koko, an anonymous emotional support network available through various messaging applications. We comment on a small subset of samples labeled with appropriate explanations. Our best technique clearly exceeds the baseline for detection and explanation."}, {"heading": "1 Introduction", "text": "(...). (...). (...). (...). (...). (...). (...). (...). (...). (...). It is indeed the case that one is able to change the rules. (...). (...). In fact, it is the case that one is able to change the rules. (...). (...). It is not the case that one is able to change the rules. (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (It. (...). (...). (...).). (...). (It. (...). (...). (It. (...).). (...). (...). (...). (It. (...). (It.). (It.)."}, {"heading": "2 Related Work", "text": "The goal of their work was to significantly improve the suicide rate of researchers in clinical systems. They have tweets that preceded suicide attempts, they have artificially balanced those tweets by using data from random users that are considered neurotypical, and they recognize that this data is contaminated by users who are also trying to commit suicide. They train simple, linear classifications that promise to recognize these suicidal users and discuss how difficult it is to realize this technology. In our work, we try to detect and explain these phenomena, but they are not limited to suicides that are significantly larger and not artificially balanced. However, we do not use the records of suicide rates as a signal when we evaluate them. (2016) we operate on a filtered subset of mental health data to determine whether a mention of suicide rates is confirmed or negated."}, {"heading": "3 Methods", "text": "Our training set consists of N examples {Xi, Y i} Ni = 1, where the input Xi is a sequence of characters w1, w2,..., wT and the output Y i is a binary crisis indicator."}, {"heading": "3.1 Word Embeddings", "text": "We use reference GloVe embeddings trained on Twitter data (Pennington et al., 2014). We have used the 200-dimensional embeddings for all our experiments so that every word wt is mapped to xt-R200. We refer to the complete embedded sequence as x1: T."}, {"heading": "3.2 Recurrent Neural Networks", "text": "A recursive neural network (RNN) extends to a traditional neural network to encode a sequence of vectors, x1: T, recursively into a sequence of hidden states. In particular, we encode the sequence using a gated recurrent unit (GRU; Cho et al., 2014) RNN. The GRU uses an update gate zt and a reset gate rt, which is used to compute the next hidden state htht = (1 \u2212 zt) ht \u2212 1 + zth \u0441t zt = \u03c3 (Wzxt + Uzht \u2212 1) h \u0445t = tanh (Wxt + U (rt ht \u2212 1)) rt = \u03c3 (Wrxt + Urht \u2212 1)."}, {"heading": "3.3 Attention over Words", "text": "We use the unconditional attention mechanism used by Yang et al. (2016) to classify documents. ut = tanh (Wwh bi t + bw) \u03b1t = exput \u2211 t exputd = \u2211 t \u03b1thtThe attention mechanism serves two purposes. d functions as a context-dependent document representation that can be fed into a downstream model component for detection. In addition, the score vector u1: N can be used to explain our explanation, which will be expanded in a following paragraph. Optionally, we encode the document by using the last hidden state of a single upstream GRU, without the reverse GRU and attention mechanism. Both encoding schemes are evaluated in our experiments."}, {"heading": "3.4 Training Objective", "text": "The final encoding of each sample, d, is fed into a sigmoid layer with a node to determine the likelihood of a crisis. We minimize the target of logistical losses during the training. l (y, p) = \u2212 ylog (p) \u2212 (1 \u2212 y) log (1 \u2212 p), where y is the true value and p is the output of the logistics output layer."}, {"heading": "3.5 Seeding the Explanations", "text": "We do this by building a subset of words that \"seed\" the explanation generating function. The explanation generating function is set during testing on all seed techniques, allowing expandability by modularizing the seed function using a relevant model. The seed function is intended to give a set of tokens from the input that affects the prediction most, so sews the first stitches of the explanation. For the task of detecting crisis, descriptive content words, such as adjectives, nouns and verbs, are desirable compared to stopwords or punctuation. We test three techniques of sowing words for a specific input: (1) using orders of magnitude activated coefficients in a logistical regression model. This acts as our baseline. (2) Using the distribution of attention from us from our neural model. (3) Using LIME, the words can generate a prediction for each model."}, {"heading": "3.6 Explanation Generation Algorithm", "text": "We use a novel algorithm for generating explanations, which depends on seeds from a separately developed seed module. The algorithm acts on the input text and k-explanatory seeds. It works as follows: First, the sentence of meaning is identified by taking the sentence with the most seeds. Then, the identified sentence is analyzed with a dependency parser (Honnibal and Johnson, 2015) and traversed by the root to find the highest seed in the sentence. If the highest seed is not a verb and not the head of the entire sentence, we then traverse the head node of the seed. Then, the subtree set of the highest seed is used to explain. Since the parse is projective, the subtree is necessarily a contiguous sequence of tokens."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Training Data", "text": "Koko has an anonymous peer-to-peer therapy network based on a clinical trial at MIT (Morris et al., 2015), which is made available via chatbots on various social media platforms such as Facebook, Kik and Tumblr. They have provided us with our training data through a research partnership. Posts on the platform typically come from users who experience negative thoughts and need some form of emotional support. Each post is on average 3.1 sentences long, with a standard deviation of 1.7 sentences. The training set consists of approximately 106,000 binary marked posts (crisis or not), and their data has been commented on by crowdworkers for crisis situations. During the comments, they have received clear instructions consisting of crises, examples, common mistakes and helpful tips. These instructions have been revised over several passes of small stacks of data to improve the interannotator agreement."}, {"heading": "4.2 Explanation data", "text": "We have selected a number of 1242 marked contributions as a test set, of which 200 are called Crisis. We will comment on the 200 crisis examples with their respective declarations. A statement is a sentence or clause in the contribution that most identifies the basic idea behind the crisis label. In choosing the statement, we strive to make it precise, coherent and concise."}, {"heading": "4.3 Model Configuration and Training", "text": "We do not fine-tune the pre-trained GloVe embeddings, but learn a simple embedding transformation matrix that intervenes between the embeddings and the RNNs. We use 200-dimensional embeddings and 100-dimensional forward and backward-facing GRUs (giving 200-dimensional contextual representations). We apply an L2 penalty to attention output by using \u03bb =.0001. We fill each input to 150 words. We train with RMSprop with a learning rate of.001 and a batch size of 256. We add dropout with a drop of 0.1 in the last shift before we detect the overmatch. We determine the drop-out rate, the batch size and the input length empirically by random hyperparameter search and calculate the attention penalty for the human rating. We use the best test from the 10% of the epoch selected from the training (without the validation of the data)."}, {"heading": "5 Results and Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Detection Evaluation", "text": "The neural models perform significantly better than the logistics model in terms of detection accuracy (Table 1), with the best neural model achieving a value of 0.80 F1 for crisis detection, compared to 0.66 for the logistics model. The neural attention model achieves a value of 0.76 F1, which is still significantly better than the linear baseline. The best model does not have a penultimate attention layer, but a single forward-facing GRU layer."}, {"heading": "5.2 Attention Visualization", "text": "First, we confirm that the attention mechanism produces distributions that correspond to our expectations by visualizing attention using a thermal imaging camera, matching each normalized attention weight with the corresponding symbol in the input. First, we found that the attention distribution exhibits very low entropy and places the majority of the probability in a single symbol of the input. We punished low entropy outputs with an L2 penalty controlled by a \u03bb parameter. We did not further adjust it to improve the evaluation of the explanation, although we expect that this could improve performance. Figure 1 shows the attention performance for two crisis samples. In the first sample, we see that attention focuses on the final sentence and is not fully focused on one word. Predictably, \"i cut myself\" brings the highest weight in the attention distribution. The second visualization shows singular attention on the word \"suicide\" and thus clearly puts less importance on the rest of the input."}, {"heading": "5.3 Qualitative Explanation Results", "text": "Interestingly, all the techniques gave rise to several high-quality explanations. We examined about 20 samples and for each one at least one of the seeding functions contained the correct explanation. Surprisingly, the logistical baseline performed quite well in this characteristic. In Table 2, we show an example where all the techniques achieved the same result, probably due to the predictive power of the expression \"kill me me me me.\" In many cases, the generated explanation contained more text than is necessary to accurately capture the gold explanation; the second example (Table 2) shows this in the neural + attention technique, which could indicate the need for improvement in the explanation technique; the third example shows a difficult case where the majority of the text is background information and only the last word of the input is contained in the gold explanation. We see that both neural models and logistics + LIME are successful in capturing approximately the correct explanation."}, {"heading": "5.4 Quantitative Explanation Results", "text": "We evaluate the generated explanations using ROUGE-1 and ROUGE-2 (Lin, 2004), which measure the overlapping units (unigrams or bigrams) of the generated text and reference texts. In tables 3 and 4, the average ROUGE and ROUGE-2 values for the generated explanations for each model and seed strategy are listed. By a wide margin, neuronal classification 1 in conjunction with the LIME seed function beats the rest of the models. In the ROUGE-2 evaluation, it beats the next-best average F1 value by 10 points, and in the ROUGE-1 evaluation, it beats the next-best average F1 by 12 points. Since LIME directly determines which input influences the prediction most, while attention does so only indirectly, this result makes sense. However, the LIME seed function is the slowest approach we consider in order to generate an explanation. The neural attention focused on the IGE, as opposed to this one, is the logic based on the IGE."}, {"heading": "6 Conclusion", "text": "In this paper, we present and compare explanation-oriented methods for identifying crises in so-1. We use the RNN with attention in this result. The forward-looking RNN in conjunction with LIME showed nearly identical ROUGE performance. We adopt a modular approach to generating explanations and use neural techniques that significantly exceed our baseline. The best models presented are both effective at detecting and generating explanations that resemble those of human annotators. We find this exciting for two reasons: In the field of crisis identification, successes in explaining help build the confidence in trained models needed to use them in such a sensitive context. Furthermore, we expect our techniques to be able to further generalize text classification. In future experiments, we hope to explore the human evaluation of the generated explanations as an indicator of confidence in the model, to examine compression-based explanatory approaches (blank, al, richer textures, and architectures)."}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers and Kareem Kouddous for their feedback. Bowman thanks for the support of a Google Faculty Research Award and gifts from Tencent Holdings and NVIDIA Corporation. We thank Koko for providing a unique dataset for this research."}], "references": [{"title": "Self-harm: key facts", "author": ["Philip Timms Jim Bolton Anthony Bateman."], "venue": "[Online; accessed 6-April2017].", "citeRegEx": "Bateman.,? 2014", "shortCiteRegEx": "Bateman.", "year": 2014}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1409.0473 .", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart Van Merri\u00ebnboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio."], "venue": "arXiv preprint", "citeRegEx": "Cho et al\\.,? 2014", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Real-time topic models for crisis counseling", "author": ["Karthik Dinakar", "Allison JB Chaney", "Henry Lieberman", "David M Blei."], "venue": "Twentieth ACM Conference on Knowledge Discovery and Data Mining, Data Science for the Social Good Workshop.", "citeRegEx": "Dinakar et al\\.,? 2014", "shortCiteRegEx": "Dinakar et al\\.", "year": 2014}, {"title": "Dont let notes be misunderstood: A negation detection method for assessing risk of suicide in mental health records", "author": ["George Gkotsis", "Sumithra Velupillai", "Anika Oellrich", "Harry Dean", "Maria Liakata", "Rina Dutta"], "venue": null, "citeRegEx": "Gkotsis et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gkotsis et al\\.", "year": 2016}, {"title": "An improved non-monotonic transition system for dependency parsing", "author": ["Matthew Honnibal", "Mark Johnson."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational", "citeRegEx": "Honnibal and Johnson.,? 2015", "shortCiteRegEx": "Honnibal and Johnson.", "year": 2015}, {"title": "The epidemiology and phenomenology of non-suicidal self-injurious behavior among adolescents: A critical review of the literature", "author": ["Colleen M Jacobson", "Madelyn Gould."], "venue": "Archives of Suicide Research 11(2):129\u2013147.", "citeRegEx": "Jacobson and Gould.,? 2007", "shortCiteRegEx": "Jacobson and Gould.", "year": 2007}, {"title": "Prevalence of and risk factors for lifetime suicide attempts in the national comorbidity survey", "author": ["Ronald C Kessler", "Guilherme Borges", "Ellen E Walters."], "venue": "Archives of general psychiatry 56(7):617\u2013626.", "citeRegEx": "Kessler et al\\.,? 1999", "shortCiteRegEx": "Kessler et al\\.", "year": 1999}, {"title": "Applied predictive modeling, volume 26", "author": ["Max Kuhn", "Kjell Johnson."], "venue": "Springer.", "citeRegEx": "Kuhn and Johnson.,? 2013", "shortCiteRegEx": "Kuhn and Johnson.", "year": 2013}, {"title": "Detecting distressed and non-distressed affect states in short forum texts", "author": ["Michael Thaul Lehrman", "Cecilia Ovesdotter Alm", "Rub\u00e9n A Proano."], "venue": "Proceedings of the Second Workshop on Language in Social Media. Association for Computational Lin-", "citeRegEx": "Lehrman et al\\.,? 2012", "shortCiteRegEx": "Lehrman et al\\.", "year": 2012}, {"title": "Rationalizing neural predictions", "author": ["Tao Lei", "Regina Barzilay", "Tommi Jaakkola."], "venue": "arXiv preprint arXiv:1606.04155 .", "citeRegEx": "Lei et al\\.,? 2016", "shortCiteRegEx": "Lei et al\\.", "year": 2016}, {"title": "Rouge: A package for automatic evaluation of summaries", "author": ["Chin-Yew Lin."], "venue": "Text summarization branches out: Proceedings of the ACL-04 workshop. Barcelona, Spain, volume 8.", "citeRegEx": "Lin.,? 2004", "shortCiteRegEx": "Lin.", "year": 2004}, {"title": "Efficacy of a webbased, crowdsourced peer-to-peer cognitive reappraisal platform for depression: Randomized controlled trial", "author": ["Robert R Morris", "Stephen M Schueller", "Rosalind W Picard."], "venue": "Journal of medical Internet research", "citeRegEx": "Morris et al\\.,? 2015", "shortCiteRegEx": "Morris et al\\.", "year": 2015}, {"title": "Towards automatically classifying depressive symptoms from twitter data for population health", "author": ["Danielle Mowery", "Albert Park", "Mike Conway", "Craig Bryan."], "venue": "Proceedings of the Workshop on Computational Modeling of Peoples Opinions, Per-", "citeRegEx": "Mowery et al\\.,? 2016", "shortCiteRegEx": "Mowery et al\\.", "year": 2016}, {"title": "Domestic violence national statistics", "author": ["NCADV."], "venue": "[Online; accessed 6-April-2017]. http://ncadv.org/images/Domestic Violence.pdf.", "citeRegEx": "NCADV.,? 2015", "shortCiteRegEx": "NCADV.", "year": 2015}, {"title": "Detecting suicidality on twitter. Internet Interventions 2(2):183\u2013188", "author": ["Bridianne O\u2019Dea", "Stephen Wan", "Philip J Batterham", "Alison L Calear", "Cecile Paris", "Helen Christensen"], "venue": null, "citeRegEx": "O.Dea et al\\.,? \\Q2015\\E", "shortCiteRegEx": "O.Dea et al\\.", "year": 2015}, {"title": "Linguistic inquiry and word count: Liwc 2001", "author": ["James W Pennebaker", "Martha E Francis", "Roger J Booth."], "venue": "Mahway: Lawrence Erlbaum Associates 71(2001):2001.", "citeRegEx": "Pennebaker et al\\.,? 2001", "shortCiteRegEx": "Pennebaker et al\\.", "year": 2001}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning."], "venue": "Empirical Methods in Natural Language Processing (EMNLP). pages 1532\u2013 1543. http://www.aclweb.org/anthology/D14-1162.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Why should i trust you?: Explaining the predictions of any classifier", "author": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin."], "venue": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM,", "citeRegEx": "Ribeiro et al\\.,? 2016", "shortCiteRegEx": "Ribeiro et al\\.", "year": 2016}, {"title": "Reasoning about entailment with neural attention", "author": ["Tim Rockt\u00e4schel", "Edward Grefenstette", "Karl Moritz Hermann", "Tom\u00e1\u0161 Ko\u010disk\u1ef3", "Phil Blunsom."], "venue": "arXiv preprint arXiv:1509.06664 .", "citeRegEx": "Rockt\u00e4schel et al\\.,? 2015", "shortCiteRegEx": "Rockt\u00e4schel et al\\.", "year": 2015}, {"title": "Toward macro-insights for suicide prevention: Analyzing fine-grained distress", "author": ["O Alm"], "venue": null, "citeRegEx": "Tong et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tong et al\\.", "year": 2014}, {"title": "Mental health suicide data", "author": ["WHO."], "venue": "[Online; accessed 6-April-2017].", "citeRegEx": "WHO.,? 2016", "shortCiteRegEx": "WHO.", "year": 2016}, {"title": "Language signals preceding suicide attempts", "author": ["Anthony Wood", "Jessica Shiffman", "Ryan Leary", "Glen Coppersmith."], "venue": "CHI 2016 Computing and Mental Health Workshop, San Jose, CA.", "citeRegEx": "Wood et al\\.,? 2016", "shortCiteRegEx": "Wood et al\\.", "year": 2016}, {"title": "Hierarchical attention networks for document classification", "author": ["Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alex Smola", "Eduard Hovy."], "venue": "Proceedings of NAACL-HLT . pages 1480\u20131489.", "citeRegEx": "Yang et al\\.,? 2016", "shortCiteRegEx": "Yang et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 21, "context": "Approximately one person dies by suicide every 40 seconds (WHO, 2016).", "startOffset": 58, "endOffset": 69}, {"referenceID": 21, "context": "5 % of all deaths, and is the second leading cause of death among young adults (WHO, 2016).", "startOffset": 79, "endOffset": 90}, {"referenceID": 21, "context": "There are indications that for each adult who dies of suicide there may have been more than 20 others attempting suicide (WHO, 2016).", "startOffset": 121, "endOffset": 132}, {"referenceID": 6, "context": "13 to 23% of adolescents engage in self-injury at some point (Jacobson and Gould, 2007).", "startOffset": 61, "endOffset": 87}, {"referenceID": 14, "context": "In the United States, about 7 million females and 1 million males suffer from eating disorders annually (Simon, 2013) and an average of 20 people are physically abused by intimate partners every minute (NCADV, 2015).", "startOffset": 202, "endOffset": 215}, {"referenceID": 7, "context": "a plan; 72% of those who report making a suicide plan actually make an attempt (Kessler et al., 1999).", "startOffset": 79, "endOffset": 101}, {"referenceID": 3, "context": "Finally, in human-in-the-loop crisis systems, the human responder can better sift through information if the factors of crisis were visually highlighted through automated means (Dinakar et al., 2014).", "startOffset": 177, "endOffset": 199}, {"referenceID": 8, "context": "With the rise of complex neural models in classification tasks, we\u2019ve seen gains in accuracy at the cost of transparency and interpretability (Kuhn and Johnson, 2013).", "startOffset": 142, "endOffset": 166}, {"referenceID": 19, "context": "Detecting Crisis Wood et al. (2016) identify 125 Twitter users who publicly state their suicide attempt online on a specific date and have tweets preceding the suicide attempt.", "startOffset": 17, "endOffset": 36}, {"referenceID": 4, "context": "Gkotsis et al. (2016) operate on a filtered subset of mental health records to determine whether a mention of suicide is affirmed or negated.", "startOffset": 0, "endOffset": 22}, {"referenceID": 16, "context": "and LIWC sadness scores (Pennebaker et al., 2001) to filter 2.", "startOffset": 24, "endOffset": 49}, {"referenceID": 1, "context": "Interpretable Neural Networks In the past few years, neural attention mechanisms over words (Bahdanau et al., 2014) have led to improvements in performance and interpretability in a range of tasks, such as translation (Bahdanau) and natural language inference (Rockt\u00e4schel et al.", "startOffset": 92, "endOffset": 115}, {"referenceID": 19, "context": ", 2014) have led to improvements in performance and interpretability in a range of tasks, such as translation (Bahdanau) and natural language inference (Rockt\u00e4schel et al., 2015).", "startOffset": 152, "endOffset": 178}, {"referenceID": 18, "context": "In another work with similar goals, Ribeiro et al. (2016) introduce a model agnostic framework for intepretability, LIME, that learns an interpretable", "startOffset": 36, "endOffset": 58}, {"referenceID": 17, "context": "We use reference GloVe embeddings trained on Twitter data (Pennington et al., 2014).", "startOffset": 58, "endOffset": 83}, {"referenceID": 2, "context": "In particular, we encode the sequence using a gated recurrent unit (GRU; Cho et al., 2014) RNN.", "startOffset": 67, "endOffset": 90}, {"referenceID": 23, "context": "We employ the unconditional attention mechanism used to do document classification employed by Yang et al. (2016).", "startOffset": 95, "endOffset": 114}, {"referenceID": 12, "context": "Koko has an anonymous peer-to-peer therapy network based on an clinical trial at MIT (Morris et al., 2015), which is made available through chatbots on a variety of social media platforms including Facebook, Kik, and Tumblr.", "startOffset": 85, "endOffset": 106}, {"referenceID": 20, "context": "sample of distress (Tong et al., 2014).", "startOffset": 19, "endOffset": 38}, {"referenceID": 5, "context": "We tokenize the data using Spacy (Honnibal and Johnson, 2015).", "startOffset": 33, "endOffset": 61}, {"referenceID": 11, "context": "We evaluate the generated explanations using ROUGE-1 and ROUGE-2 (Lin, 2004), which measure the overlapping units (unigrams and bigrams respectively) of the generated text and reference texts.", "startOffset": 65, "endOffset": 76}, {"referenceID": 10, "context": "In the future experiments, we hope to explore human evaluation of the generated explanations as an indicator of trust in the model, to investigate compression-based approaches to explanation (Lei et al., 2016), and to consider richer ar-", "startOffset": 191, "endOffset": 209}], "year": 2017, "abstractText": "Individuals on social media may reveal themselves to be in various states of crisis (e.g. suicide, self-harm, abuse, or eating disorders). Detecting crisis from social media text automatically and accurately can have profound consequences. However, detecting a general state of crisis without explaining why has limited applications. An explanation in this context is a coherent, concise subset of the text that rationalizes the crisis detection. We explore several methods to detect and explain crisis using a combination of neural and non-neural techniques. We evaluate these techniques on a unique data set obtained from Koko, an anonymous emotional support network available through various messaging applications. We annotate a small subset of the samples labeled with crisis with corresponding explanations. Our best technique significantly outperforms the baseline for detection and explanation.", "creator": "LaTeX with hyperref package"}}}