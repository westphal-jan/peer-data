{"id": "1705.10030", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-May-2017", "title": "Supervised Complementary Entity Recognition with Augmented Key-value Pairs of Knowledge", "abstract": "Extracting opinion targets is an important task in sentiment analysis on product reviews and complementary entities (products) are one important type of opinion targets that may work together with the reviewed product. In this paper, we address the problem of Complementary Entity Recognition (CER) as a supervised sequence labeling with the capability of expanding domain knowledge as key-value pairs from unlabeled reviews, by automatically learning and enhancing knowledge-based features. We use Conditional Random Field (CRF) as the base learner and augment CRF with knowledge-based features (called the Knowledge-based CRF or KCRF for short). We conduct experiments to show that KCRF effectively improves the performance of supervised CER task.", "histories": [["v1", "Mon, 29 May 2017 03:45:25 GMT  (22kb)", "http://arxiv.org/abs/1705.10030v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["hu xu", "lei shu", "philip s yu"], "accepted": false, "id": "1705.10030"}, "pdf": {"name": "1705.10030.pdf", "metadata": {"source": "CRF", "title": "Supervised Complementary Entity Recognition with Augmented Key-value Pairs of Knowledge", "authors": ["Hu Xu", "Lei Shu", "Philip S. Yu"], "emails": ["psyu}@uic.edu"], "sections": [{"heading": null, "text": "ar Xiv: 170 5.10 030v 1 [cs.C L] 29 May 201 7Complementary Entity Recognition (CER) Sentiment Analysis of Product Reviews and Complementary Units (Products) is an important type of opinion goal that can work with the reviewed product. In this paper, we address the problem of Complementary Entity Recognition (CER) as monitored sequence labeling with the ability to expand domain knowledge as key pairs of unlabeled ratings by automatically learning and improving knowledge-based attributes. We use Conditional Random Field (CRF) as a learning basis and expand CRF with knowledge-based attributes (KCRF or KCRF for short). We conduct experiments to show that KCRF effectively improves the performance of the monitored CER task."}, {"heading": "1 Introduction", "text": "In fact, it is the case that most people who are able to know themselves and understand how they have behaved have to behave. (...) It is not as if they are able to outwit themselves. (...) It is as if they are able to outwit themselves. (...) It is as if they are able to outwit themselves. (...) It is as if they are able to outwit themselves. (...) It is as if they are able to outwit themselves. (...) It is as if they are able to outwit themselves. (...) It is as if they are able to outwit themselves. (...) It is as if they are able to outwit themselves. (...) It is as if they do it, as if they do it, as if they do it, as if they do it, as if they do it, as if they do it, as if they do it, as if they do it, if they do it, as if they do it."}, {"heading": "2 Preliminaries", "text": "The fact is that we see ourselves as being able to be in a position, and that we are able, we will be able to be in a position, we will be able to be in a position, we will be able to be in a position, we will be able to put ourselves in a position, we will be able to put ourselves in a position, we will be able to put ourselves in a position, we will be able to put ourselves in a position, we will be in a position, we will be in a position. \""}, {"heading": "3 Pre-training", "text": "It is important to get useful knowledge types and reliable knowledge values, as some knowledge types may not support the prediction task and incorrect knowledge values. Fortunately, a trained CRF model can tell us which properties are more useful for predicting and need to be augmented with knowledge. (The basic idea is to perform a traditional CRF training with primitive characteristics and select knowledge based on the weights of primitive characteristics of the trained CRF model. (Let x \u00b2 n use a feature vector of the n word in an input sequence for pre-training.) We use r \u00b2 R to index primitive characteristics so x \u00b2 n, r = 1 means the n-th word has a primitive characteristic (e.g. WORD = \"telephone\" or (DEP, nmod: mit, VBZ))."}, {"heading": "4 Knowledge-based Training", "text": "We train KCRF on the basis of knowledge-based characteristics in this section. A knowledge-based characteristic simply indicates whether a characteristic found in an example with a specific knowledge type has some values found in the current knowledge base (or KB). We use xn to designate the attribute vectors with knowledge-based characteristics for the n-word, and use d-D to designate a knowledge-based attribute indexed by d in xn. (5) For example, if ([DEP, nmod: with, VBZ], \"works,\" and the n-word has knowledge with type kd and the initial value v found in KB, the word \"telephone\" has a dependency relationship knowledge-based attribute with type k = [DEP, nmod: with, VBZ] and a current word-based attribute k = WBZ and the attribute \"preference\" for the skills of KF and KCRF. \""}, {"heading": "5 Knowledge Expansion", "text": "We assume that target units in the same category share similar knowledge. In this context, it is crucial to ensure the quality of the extended knowledge, as it is very easy to have harmful knowledge from blank evaluations without human supervision. In order to obtain a reliable prediction for the n-word, we marginalize other positions via y1: N, except for n such as: p (yn | x; \u03bb c) = \u2211 y1 \u00b7 \u00b7 \u2211 yn \u2212 1 \u0445 yn + 1 \u00b7 \u00b7 \u00b7 \u2211 yNp (y1: N | x; \u03bb c). (6) When a day reaches the maximum probability greater than a threshold: maxto (yn = to | x; \u03bb c) = \u2211 yNp (yNp: n; x; x)."}, {"heading": "6 Experimental Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Dataset", "text": "We use the dataset 1 of (Xu et al., 2016b), which includes 7 products. We take 50% of the evaluations of the first 4 products as training data for all methods that require supervised training. Similar to (Xu et al., 2016b), the remaining evaluations of the first 4 products (for the in-domain test) and all evaluations of the last 3 products (for the out-of-domain test) are test data. Similar to (Xu et al., 2016b) we also randomly select 6000 unlabeled1 https: / / www.cs.uic.edu / \u02dc hxu / Algorithm 1: Knowledge ExpansionInput: (c, KB), with KB = {KBto | to-T}, U = {u1, U |} Output: (c, KB), with updated KB1 do 2 do-KBendsionInput: (c, KB), with KBendsionInput: (c, KBto-T}, U = todo-todo-to-todo-todo-todo-todo-todo-todo-todo-todo-to-todo-todo-todo-todo-n-todo-todo-todo-todo-to-todo-todo-todo-todo-todo-todo-todo-to-todo-todo-todo-todo-todo-todo-todo-n-todo-todo-todo-todo-todo-to-todo-todo-todo-todo-todo-todo-todo-todo-todo-todo-to-todo-todo-todo-todo-todo-todo-todo-todo-todo-to-todo-todo-todo-todo-todo-todo-todo-todo-todo-todo-todo-todo-to-todo-todo-todo-todo-todo-todo-todo-todo-todo-todo-todo-todo-todo-to"}, {"heading": "6.2 Compared Methods", "text": "We use CRFSuite2 as the basic implementation of CRF. CRF (-) DR: This is a very simple CRF with no dependency relationships as attributes to show that dependency relationships are useful attributes. We use the following attributes: current word, POS tags, 4 nearby words and POS tags on the left and right, number of digits and whether the current word has a slash. CRF: This is the baseline with dependency relationships as attributes. It is also the same learner as in the KCRF.2http: / / www.chokkan.org / software / crfsuite / CRF-Init pretraining step: This baseline uses the trained KCRF and the initial KB directly to test data without expanding knowledge on unmarked data. KCRF: This is the proposed method that uses trained KCRF and initial KB to expand knowledge on unmarked evaluations under the same category as the 8 percent we have most extending the target."}, {"heading": "6.3 Evaluation Methods", "text": "We count true positive tp, false positive fp, and false negative fn. For each set, a recognized complementary entity contained in the commented complementary entities for that set is considered a count for the tp; a recognized complementary entity not found contributes a count to the fp; each commented complementary entity that cannot be recognized contributes a count to the fn. Then we calculate precision P, recall R, and F1 score F1 based on tp, fp, and fn."}, {"heading": "6.4 Result Analysis", "text": "CRF-Init performs better than CRF on most products, suggesting that knowledge-based attributes are better than primitive attributes in general. However, we note that KCRF sacrifices its precision to achieve a higher level of recall, so how to further ensure that enhanced knowledge is of high quality to maintain high precision is still an open problem. KCRF's performance does not decline significantly on the last 3 products, although we do not have training data for these products. This is because KCRF can use blank data to expand knowledge of the last 3 products regardless of the knowledge of the first 4 products. A catchy example is that \"work\" can be a common verb knowledge that is present in the training data for some verb-related knowledge types."}, {"heading": "7 Conclusion", "text": "In this paper, we propose a supervised Complementary Entity Recognition (CER) method called KCRF. KCRF can automatically identify knowledge-based attributes and augment knowledge as a key pair of many unlabeled assessments. Experiments show that enhanced knowledge is useful to improve prediction performance, especially for products without training data."}], "references": [{"title": "A review", "author": ["Nguyen Bach", "Sameer Badaskar"], "venue": null, "citeRegEx": "Bach and Badaskar.,? \\Q2007\\E", "shortCiteRegEx": "Bach and Badaskar.", "year": 2007}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["John Lafferty", "Andrew McCallum", "Fernando CN Pereira."], "venue": "Proceedings of the Eighteenth International Conference on Machine Learning (ICML", "citeRegEx": "Lafferty et al\\.,? 2001", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Sentiment Analysis: Mining Opinions, Sentiments, and Emotions", "author": ["Bing Liu."], "venue": "Cambridge University Press.", "citeRegEx": "Liu.,? 2015", "shortCiteRegEx": "Liu.", "year": 2015}, {"title": "Inferring networks of substitutable and complementary products", "author": ["J.J. McAuley", "R. Pandey", "J. Leskovec."], "venue": "KDD.", "citeRegEx": "McAuley et al\\.,? 2015", "shortCiteRegEx": "McAuley et al\\.", "year": 2015}, {"title": "Thumbs up?: sentiment classification using machine learning techniques", "author": ["Bo Pang", "Lillian Lee", "Shivakumar Vaithyanathan."], "venue": "Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10. Association for", "citeRegEx": "Pang et al\\.,? 2002", "shortCiteRegEx": "Pang et al\\.", "year": 2002}, {"title": "Extracting product features and opinions from reviews", "author": ["Ana-Maria Popescu", "Orena Etzioni."], "venue": "Natural language processing and text mining, Springer, pages 9\u201328.", "citeRegEx": "Popescu and Etzioni.,? 2007", "shortCiteRegEx": "Popescu and Etzioni.", "year": 2007}, {"title": "Supervised opinion aspect extraction by exploiting past extraction results", "author": ["Lei Shu", "Bing Liu", "Hu Xu", "Annice Kim."], "venue": "arXiv preprint arXiv:1612.07940 .", "citeRegEx": "Shu et al\\.,? 2016", "shortCiteRegEx": "Shu et al\\.", "year": 2016}, {"title": "Lifelong learning crf for supervised aspect extraction", "author": ["Lei Shu", "Hu Xu", "Bing Liu."], "venue": "arXiv preprint arXiv:1705.00251 .", "citeRegEx": "Shu et al\\.,? 2017", "shortCiteRegEx": "Shu et al\\.", "year": 2017}, {"title": "Mining compatible/incompatible entities from question and answering via yes/no answer classification using distant label expansion", "author": ["Hu Xu", "Lei Shu", "Jingyuan Zhang", "Philip S Yu."], "venue": "arXiv preprint arXiv:1612.04499 .", "citeRegEx": "Xu et al\\.,? 2016a", "shortCiteRegEx": "Xu et al\\.", "year": 2016}, {"title": "Cer: Complementary entity recognition via knowledge expansion on large unlabeled product reviews", "author": ["Hu Xu", "Sihong Xie", "Lei Shu", "Philip S. Yu."], "venue": "Proceedings of IEEE International Conference on Big Data.", "citeRegEx": "Xu et al\\.,? 2016b", "shortCiteRegEx": "Xu et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 4, "context": "Aspect extraction (or opinion target extraction) is an important task in sentiment analysis (Pang et al., 2002) on product reviews (Hu and Liu, 2004; Popescu and Etzioni, 2007; Liu, 2015).", "startOffset": 92, "endOffset": 111}, {"referenceID": 5, "context": ", 2002) on product reviews (Hu and Liu, 2004; Popescu and Etzioni, 2007; Liu, 2015).", "startOffset": 27, "endOffset": 83}, {"referenceID": 2, "context": ", 2002) on product reviews (Hu and Liu, 2004; Popescu and Etzioni, 2007; Liu, 2015).", "startOffset": 27, "endOffset": 83}, {"referenceID": 1, "context": "A traditional supervised method like Conditional Random Field (CRF) (Lafferty et al., 2001) may have good precision on such extraction yet suffer from low recall due to unseen context words appear in the test data but not in the training data.", "startOffset": 68, "endOffset": 91}, {"referenceID": 9, "context": "To solve this problem, instead of using supervised method, (Xu et al., 2016b) uses an unsupervised method by leveraging manually-crafted high precision dependency rules (Bach and Badaskar, 2007; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Joshi and Penstein-Ros\u00e9, 2009) to expand (bootstrap) context words as knowledge on a large amount of unlabeled data and combine those context words with another set of manually-crafted high recall dependency rules for CER.", "startOffset": 59, "endOffset": 77}, {"referenceID": 0, "context": ", 2016b) uses an unsupervised method by leveraging manually-crafted high precision dependency rules (Bach and Badaskar, 2007; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Joshi and Penstein-Ros\u00e9, 2009) to expand (bootstrap) context words as knowledge on a large amount of unlabeled data and combine those context words with another set of manually-crafted high recall dependency rules for CER.", "startOffset": 100, "endOffset": 210}, {"referenceID": 9, "context": "We use the dataset from (Xu et al., 2016b), which includes 7 products.", "startOffset": 24, "endOffset": 42}, {"referenceID": 9, "context": "Similar to (Xu et al., 2016b), we also randomly select 6000 unlabeled", "startOffset": 11, "endOffset": 29}, {"referenceID": 3, "context": "reviews for each category from (McAuley et al., 2015) and use them as unlabeled reviews to expand knowledge.", "startOffset": 31, "endOffset": 53}], "year": 2017, "abstractText": "Extracting opinion targets is an important task in sentiment analysis on product reviews and complementary entities (products) are one important type of opinion targets that may work together with the reviewed product. In this paper, we address the problem of Complementary Entity Recognition (CER) as a supervised sequence labeling with the capability of expanding domain knowledge as key-value pairs from unlabeled reviews, by automatically learning and enhancing knowledgebased features. We use Conditional Random Field (CRF) as the base learner and augment CRF with knowledge-based features (called the Knowledge-based CRF or KCRF for short). We conduct experiments to show that KCRF effectively improves the performance of supervised CER task.", "creator": "LaTeX with hyperref package"}}}