{"id": "1705.10130", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-May-2017", "title": "An Automatic Contextual Analysis and Clustering Classifiers Ensemble approach to Sentiment Analysis", "abstract": "Products reviews are one of the major resources to determine the public sentiment. The existing literature on reviews sentiment analysis mainly utilizes supervised paradigm, which needs labeled data to be trained on and suffers from domain-dependency. This article addresses these issues by describes a completely automatic approach for sentiment analysis based on unsupervised ensemble learning. The method consists of two phases. The first phase is contextual analysis, which has five processes, namely (1) data preparation; (2) spelling correction; (3) intensifier handling; (4) negation handling and (5) contrast handling. The second phase comprises the unsupervised learning approach, which is an ensemble of clustering classifiers using a majority voting mechanism with different weight schemes. The base classifier of the ensemble method is a modified k-means algorithm. The base classifier is modified by extracting initial centroids from the feature set via using SentWordNet (SWN). We also introduce new sentiment analysis problems of Australian airlines and home builders which offer potential benchmark problems in the sentiment analysis field. Our experiments on datasets from different domains show that contextual analysis and the ensemble phases improve the clustering performance in term of accuracy, stability and generalization ability.", "histories": [["v1", "Mon, 29 May 2017 11:37:58 GMT  (609kb,D)", "http://arxiv.org/abs/1705.10130v1", "This article is submitted to a journal"]], "COMMENTS": "This article is submitted to a journal", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["murtadha talib al-sharuee", "fei liu", "mahardhika pratama"], "accepted": false, "id": "1705.10130"}, "pdf": {"name": "1705.10130.pdf", "metadata": {"source": "CRF", "title": "An Automatic Contextual Analysis and Clustering Classifiers Ensemble approach to Sentiment Analysis", "authors": ["Murtadha Talib AL-Sharuee", "Fei Liu", "Mahardhika Pratama"], "emails": ["al-sharuee.m@students.latrobe.edu.au"], "sections": [{"heading": null, "text": "Product assessments are one of the most important resources for determining public mood. Existing assessment mood analysis literature mainly uses a monitored paradigm that requires labeled data to be trained on and suffers from domain dependence.This article addresses these issues by describing a fully automated approach to mood analysis based on unattended ensemble learning, which consists of two phases: the first phase consists of context analysis, which includes five processes, namely (1) data preparation; (2) spelling correction; (3) intensification treatment; (4) negation treatment and (5) contrast treatment. The second phase includes the uncontrolled learning approach, a combination of cluster classifiers using a majority selection mechanism with different weight schemes. The basic classifier of the ensemble method is a modified k-mean algorithm. The base classifier is modified by including an initial set of centrification problems to improve ensemble stability and flight stability."}, {"heading": "1. Introduction", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "2. Related work", "text": "Mood analysis research has taken on various lines of research, such as lexicon-based methods and machine learning, involving several techniques. Important areas of research are discussed below."}, {"heading": "2.1. Lexicon-based methods", "text": "These methods are considered symbolic approaches because they are simply based on the appearance of the terms in a lexicon. Where documents are usually classified by aggregating sentiment polarity values from a lexicon, the proposed lexicon methods differ in the lexicon used or generated. Manually generated lexicon such as MaxDiff [20], MPQA [53] and General Inquirer [44] contain comparatively fewer terms and usually each word is associated with a SentiWordNet (SWN) [12]. Manual labeling or scouring of terms is subject to the judgment of commentators, which can be contradictory and may be unequal in terms of accuracy from word to word. In the case of automatically generated lexicon [21], such as SentiWordNet (SWN) [12], the number of terms is generally high and generally no human involvement is required. Thus, we use this lexicon in the proposed method as shown in section 3."}, {"heading": "2.2. Contextual analysis methods", "text": "Contextual analysis methods typically address common linguistic structures such as negation and contrast, also known as sentiment shifters [28], sentiment modifiers [32], polarity shifters [56, 25], and valence shifters [45, 37]. These linguistic expressions can be recognized by some explicit references to such negative terms. To achieve greater accuracy, many studies have trained the use of contextual rules as a preceding step followed by a machine learning methodology. In [56], a rules-based method is proposed to recognize text used to train a component classifier of an ensemble method. Furthermore, another component classifier has been trained on processed reviews, where the negations have been removed and an antonym-based dictionary has been used to replace the negated terms. The dictionary was created using a weighted logic probability ratio (LALR) to address the algorithms proposed within the algorithm."}, {"heading": "2.3. Supervised machine learning algorithms", "text": "A well-known study by Pang et al. [34], which conducted experiments with three monitored machine algorithms, NB, ME and SVM, is considered a cornerstone in this area. As Pang and Lee and many other researchers report, SVM generally leads to higher accuracy compared to other classic data mining approaches. In later work, more complex monitored learning algorithms were proposed to address natural language complexity, such as ensemble algorithms [57, 56, 51] where certain mechanisms can be used to combine results from multiple classifiers and vector space models that can increase accuracy. However, most of them consisted of monitored learners who need to be trained on marked data, i.e. suffer from the domain dependency problem and are not normally able to deal effectively with completely invisible data."}, {"heading": "2.4. Clustering-based approaches", "text": "An approach to sentiment analysis using the k-mean cluster algorithm was introduced by Li and Liu [24]. Their solution to k-mean instability is to apply a tuning mechanism in which a tuning by multiple results of k-means determines the group affiliation of a document, so this approach can also be considered a method of ensemble learning. Using the TF-IDF weighting method with adjective and adverb characteristics effectively increases the accuracy rate by more than 15%. WordNet was used to improve performance by obtaining the term, which resulted in an increase in the accuracy rate. However, the approach is based on a random centrifugal selection that can affect its stability and performance. The method is also based on experimentally selected seeds for group identification, which means that the seeds must be selected each time new data is processed."}, {"heading": "3. An Automatic Contextual Analysis and Clustering Classifiers Ensemble (ACACCE)", "text": "In this section, we present the two phases of ACACCE (Figure 1) for classifying product ratings: The first phase is the data preparation and context analysis phase, in which steps are taken to automatically generate and purify the text, followed by processing common speech phenomena such as amplifiers, negations and contrast; the second phase is an uncontrolled cluster classifier ensemble in which k-means is a basic classifier."}, {"heading": "3.1. An Automatic Contextual Analysis", "text": "Context analysis is the first phase of ACACCE, which includes five automatic and consecutive processes for preparing reviews and managing common language forms. SWN has been effectively used to create specialized dictionaries for some of these processes, which include (1) data preparation, (2) spell checking, (3) intensification of dictionary handling, (4) denial and (5) contrast treatment."}, {"heading": "3.1.1. Data Preparation", "text": "Speech Recognition. The first step of the algorithm is language recognition using a recognition language tool implemented by Cybozu Labs1. The library uses a Naive Bayesian Classifier and is reported to achieve an accuracy of over 99% for 53 languages. Speech recognition is taken into account because we are interested in classifying ratings written exclusively in English, and it is likely that processed online text will contain ratings written in languages other than English. 1http: / / labs.cybozu.co.jp / en / Data Clearance. This step enables automatic data sharing, which is important when processing online text into lines. The processing method is role-based and involves eliminating duplicate ratings and XML tags. It also includes processing each check into separate, unseparated tokens and sentences, which leads to more accurate recognition of sentence boundaries and tokenization in the following processes."}, {"heading": "3.1.2. Spelling Correction", "text": "Spellchecking plays an important role in ACACCE, as misspelled terms cannot be processed in the analysis that follows, which uses tools such as a POS tagger and dictionaries such as the Antonym dictionary. Therefore, correcting as many misspelled terms as possible can significantly increase performance, especially if there are a large number of misspelled adjectives and adverbs, as these parts of the speech will be features of the unattended classification. Correcting misspelled words is addressed with two dictionaries, one being a general dictionary, according to which a specialized dictionary from SWN 2 is used to correct the adjectives and adverbs in reviews."}, {"heading": "3.1.3. Intensifier Handling", "text": "A more intense is usually an adverb in a sentence. A more intense quantifies the strength of an adjective. In the sentence \"the performance was extremely successful,\" for example, \"extreme\" is a more intense one that shifts the mood from positive to extremely positive. More intense are frequent and effective mood shifts that address this type of polarity shift and improve the performance of the algorithm. We treat more intense by using a synonym dictionary generated from SWN. The dictionary contains all the adjectives and adverbs in SWN, where each synonym pair is selected independently of its semantic meaning to be of the same or close to the mood scale. We focus on adjectives and adverbs because they form the characteristic of the clustering phase. A predefined list of intensities is defined and used in the process to identify the intensifiers."}, {"heading": "3.1.4. Negation Handling", "text": "Another common explicit form of language is negation. Where the polarity of terms in a negative statement can be shifted to the opposite polarity, the word \"not\" shifts the polarity of the statement of \"I did not like the film.\" To identify negative statements, we use a predefined list of negative terms such as \"not\" and \"never.\" To then process the negation, we build an antagonist dictionary to replace adjectives and adverbs that follow negation terms with their opposing sentiment words. In the above example, therefore, after the negation term is removed, the word \"like\" could turn into \"hate.\" A similar approach was proposed in [56], but our method differs in that it uses only positive / negative adverbs and adverbs, and we also used SWN to build the dictionary. The dictionary is a list of polar terms that were extracted from SWN."}, {"heading": "3.1.5. Contrast Handling", "text": "Contrast is another commonly used linguistic structure in English. If a sentence contains a contrasting term, it will contain a clause that concludes the author's opinion, on which one focuses in order to determine the sensation of the sentence. For example, in the sentence \"It is a classic film, but unfortunately a cynic\" the general feeling is expressed in the part that follows the contrasting word \"but,\" which \"unfortunately is a cynic.\" To identify the contrast in a document, a list of predefined contrasting terms such as \"but\" and \"however\" was identified. Then, each sentence is processed separately in each review that contains a contrasting term. Let S = {w1, w2,... wm} be the sentence that contains contrasting terms, and C = {c1, c2,... cn} denotes the amount of contrasting terms. All words wj of the recalled part are removed and words remain in the closing part."}, {"heading": "3.2. Clustering Classifiers Ensemble", "text": "Ensemble learning is an effective technique, especially when the desired data is complex and can be presented in many forms. Although ensemble learning imposes a higher complexity than a singleton classifier, it is able to generate a model of high diversity, which increases the power of generalization. Therefore, we have used this technique with several vector space models, each model representing the data set in a unique weight scheme. The ensemble component classifier is k-Means, a well-known uncontrolled cluster algorithm. All documents are represented by their feelings expressing words such as adjectives and adverbs [5]."}, {"heading": "3.2.1. k-means algorithm", "text": "The component classifier of the proposed ensemble method is the k mean algorithm. It is a statistical and conventional cluster mean with hard limits in which the produced clusters are of unshared instances. It is a simple, flat, hard and polythetic cluster algorithm, with a predefined number of clusters. Several researchers have contributed to the design of the algorithm for different disciplines. The algorithm is suitable for our experiments because (1) k mean is uncontrolled cluster algorithm therefore it is suitable for a domain independent method. (2) kmeans always wants to agree with a small number of iterations [1], which we also observe experimentally (see Table 3 and 4). The low iteration number is also a result of a proper centering selection. (3) Although predefined cluster number and hard cluster formation can be regarded as disadvantages of k mean, it is appropriate for the method ACACnegative because ACCE means and ACCE only two."}, {"heading": "3.2.2. SentiWordNet", "text": "The Specialized Mood Lexicon SentiWordNet 1.0 (SWN) = 3] is an automatically generated lexicon in which three scores (positive, negative and objective) are assigned to each synset of WordNet. We use SWN to perform a contextual analysis and determine the characteristics of the polarities that make up the initial k-mean centroids. The scores measure the strength of the term polarity by assigning a value to each of the three classes in which the sum of these values is equal to 1.0, and each class has a partial value based on the strength of the three emotions called up. A committee of eight ternary semi-monitored classifiers was used to build this lexicon \u2212 in this thesis, the improved version SentiWordNet 3.0 [3] is used, which is based on WordNet 3.0, the updated version of WordNet 3.0, which is based on WordNet 3.0, the updated version of WordNet, in the Wordom Net, to improve the score, where the marginal score was used alongside the ficator."}, {"heading": "3.2.3. Initial centroids", "text": "The initial selection of k mean centroids is an important factor in the formation of the final clusters, therefore the process and outcome of clustering to some extent depends on the first iteration in which the initial centroids are selected [55]. The selection of the first centroids appears to be the main factor influencing the number of iterations and convergence of the algorithm. Random selection, in the standard k mean, can lead to poor performance because in the process of binary classification, for example, these two randomly selected points may be of the same class, which will lead to inaccurate clustering based on similarity. Some suggestions have been introduced to solve this problem, such as k mean + + [1] selecting the distanced random points, where the probability of selecting each of these points is proportional to their overall potential contribution. However, a selection of the initial non-informative points or outlier points, which are unrelated and unsimilar to other fictional documents, may reduce the accuracy of the classification."}, {"heading": "3.2.4. Vector space models", "text": "The vector-space model is a commonly used representation in word processing, where the terms characteristics and documents are observations. A variety of matrix representations have been studied to obtain the most accurate results. With the proposed system it is possible to experiment with 24 vector-space models, which represent different representations of the individual datasets in a comparably short time. This is mainly because it is an unmonitored system, and the use of k-means, which are located in a reduction of the computational complexity of the method. To build different VSMs, two matrices are generated, namely the presence of matrix and the use of the frequency matrix."}, {"heading": "3.2.5. Neutral term and feature reduction", "text": "Neutral terms can be considered redundant characteristics for our experiment, since we are interested in only two classes, positive and negative, and it is assumed that no sentiment polarity can be expressed by the neutral characteristics. Therefore, feature reduction can be carried out by eliminating the neutral terms. It should be carefully considered before using other methods of feature selection after the removal of the neutral characteristics, as this can lead to an inaccurate accumulation of short documents in the vector with high sparsity."}, {"heading": "3.2.6. Cluster interpretations", "text": "The k-mean algorithm requires an interpretation strategy when processing data from the real world, since no labels are provided to interpret the acquired groups. In [24], group polarity is assessed on the basis of the distribution of seeds with fixed polarity in the clusters, and their solidity has been experimentally proven by observing 100 cluster results, with 22 documents always correctly classified. Despite the low possibility of incorrectly classifying these seeds, which is 10 \u2212 z, where z is the number of positive / negative seeds, this low possibility is likely to be altered when there is a modification of the data set size or when another data set is used. In ACACACCE, the two seeds used as initial centrifuges show the polarity of the clusters, and the assumption is that a positive cluster appears where the positive cluster and a negative cluster is where the negative cluster appears, where the negative appears, where the negative seeds of the single polarity may be described as the classification of the documents based on this one of the negative polarity."}, {"heading": "3.2.7. Ensemble Learning", "text": "Ensemble learning (Figure 3) is a combination of several classifiers in order to achieve higher accuracy. It can combine learners of the same type, for example, by dropping and promoting ensemble methods [52, 50]. It can also be an ensemble of different types of classifiers [9]. The idea is that ensemble algorithms proposed for sensory analysis are largely monitored if the component classifiers are diverse and precise [51, 48, 26, 14] They differ in the learning and feature selection level of the base classifiers and in their basic classification combination methods. The idea is that ensemble algorithms can be more accurate compared to a single classifier if the component classifiers are diverse and precise [16]. A precise classifier, also referred to as a weak classifier, according to Schapire [10, 41] is a classifier whose performance will be improved by ensemble systems, because it is more likely to solve ensemble problems, because it is easier to combine ensemble learning with performance."}, {"heading": "3.2.8. Ensemble of clustering classifiers algorithm", "text": "The ensemble algorithm is as follows: algorithm 4 preprocessing and the ensemble cluster classifiers algorithm INPUT: A corpus D of m number of documents {d1, d2,..., dm} OUTPUT: Assign a positive or negative label to each document. (i = 1, 2,.., m) Preprocessing: 1: for all documents do dj. D 2: for each word do wi-dj 3: tag wi with part of language tagging tj 4: if tj = a OR tj = = r, a and r donate adjective and adverb then 5: Hold wi 6: Adverb to F, F is the characteristics set 7: otherwise 8: Remove wi 9: end if10: end if10: end for 11: end for cluster: 12: end for cluster."}, {"heading": "3.2.9. Computational complexity analysis", "text": "If the complexity of the k mean is O (g (nkt), where n is the instances of the dataset, k is the number of clusters, and t is the number of iterations, then the computational complexity of ACACACCE is O (mg (nkt)). The complexity of the ensemble methods is largely linear in terms of the number of component classifiers m, and it largely depends on the complexity of the base learner. In addition, the computational cost of cosinal distance, which is the similarity measurement of the base classifiers, depends on the vector length. Therefore, the performance reduction may slightly improve performance."}, {"heading": "4. Experiments and analysis", "text": "To evaluate the method, we conduct experiments with different assessment data sets (see Table 2). Normally, when using machine learning algorithms for evaluation, an experimental data set is divided into training and test sections. In ACACCE, the entire data set is used for evaluation, as it is an unattended method. Positive / negative labels that accompany each document are used to construct a confusion matrix. As we are interested in both negative and positive classes, the evaluation is done by calculating the accuracy [31, 18]. Equation (7) is a mathematical expression for calculating acuity based on the confusion matrix and seed position. In addition to accuracy, we also calculate precision, recall, and F measure [31]. Accuracy = a + ba + b + c + d (7) ACACACCE is implemented with Java 8 and Netfians IDE 8.0.2."}, {"heading": "4.1. Datasets", "text": "The cross-domain performance of ACACCE is evaluated by collecting and experimenting with two sets of data, which are Australian Airlines and HomeBuilders Review datasets. We also conduct experiments with film datasets and multi-domain datasets [6] (see Table 2)."}, {"heading": "4.1.1. Airlines and HomeBuilders datasets", "text": "A publicly available online review is collected by www.productreview.com.au, an Australian consumer opinion site, where each review is associated with one of five rating categories (excellent, good, ok, bad and terrible), allowing us to select reviews with excellent and good ratings as positive instances, while reviews with bad and terrible ratings as negative instances. Airline record. To compile this record, 1500 reviews are collected randomly from four Australian airlines that were written between September 2006 and January 2017. The assessments of this record relate to 14 construction companies in Australia that were compiled between January 2009 and January 2017."}, {"heading": "4.1.2. Movie and multi-domain datasets", "text": "The film evaluation dataset of [33], which is the extended version of the dataset of Pang et al. [34], is a well-known dataset in the field of sentiment analysis and has been used in many research studies. It is widely believed that film evaluations are difficult to classify in comparison with other product evaluations [7, 54] because many aspects are likely to be discussed and different polarities can be used. The wide variety of films can make this task even more difficult due to the number of topics discussed in the reviews, such as the plot of the film, the actors and the location of the film. It is also likely to contain unbalanced samples of different lengths, which can also cause difficulties in analyzing short documentaries. [6] The multi-domain dataset [6] is a benchmark dataset created by Blitzer et al. [6] using evaluations of various products from Amazon.com."}, {"heading": "4.2. First phase of ACACCE", "text": "The following is a detailed analysis of each method of the first phase. Figure (4) shows the effects of the contextual analysis phase on the accuracy at which the accuracy rate of applying the contextual analysis methods has increased by an average of 3.01 percent. Data preparation: Figure 5 shows a slight improvement in the accuracy of preparing the data compared to applying the ensemble method to raw data. This step is significant for the following procedures and also for the second phase because it improves the process of tokenization and sentence boundary recognition. Spelling correction: Spelling correction with dictionaries has a positive effect on the result because it supports the processing and extraction of as many adjectives and adverbs as possible in the following steps. When processing raw online text, there is a need for data preparation and spelling correction because it is very likely that the text contains misspelled terms. Intensive data processing: An improvement in the common processing phase is due to the sharpening of the data phase."}, {"heading": "4.3. Second phase of ACACCE", "text": "This year, it is more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, in which it is a country, in which it is a country, in which it is a country and in which it is a country, in which it is a country and in which it is a country."}, {"heading": "4.4. Discussion", "text": "This year, it is at an all-time high in the history of the European Union."}, {"heading": "5. Conclusions", "text": "In this article, we have discussed a fully automatic, unsupervised method of machine learning for sentiment analysis, which combines automatic context analysis and an ensemble of grouping classifiers. Unsupervised learning and reliability are the features that distinguish the proposed ensemble algorithm from other work in literature. ACACCE's reliability results from the combination of the context analysis phase and ensemble learning methodology. It is an unattended algorithm with competitive accuracy, and then a domain-independent classification algorithm. ACACCE solves the problem of data annotation, which is an expensive process.As a future work, we will consider multi-class classification based on sentiment strength. Improvements can also be achieved by considering deeper contextual analyses and using other weighting schemes or even other machine learning approaches."}], "references": [{"title": "k-means++: The advantages of careful seeding", "author": ["D. Arthur", "S. Vassilvitskii"], "venue": "Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms. Society for Industrial and Applied Mathematics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "A near-optimal initial seed value selection in k-means means algorithm using a genetic algorithm", "author": ["G.P. Babu", "M.N. Murty"], "venue": "Pattern Recognition Letters", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1993}, {"title": "SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining", "author": ["S. Baccianella", "A. Esuli", "F. Sebastiani"], "venue": "Language Resources and Evaluation Conference LREC", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Detecting implicit expressions of affect in text using EmotiNet and its extensions", "author": ["A. Balahur", "J.M. Hermida", "A. Montoyo", "R. Mu\u00f1oz"], "venue": "Data & Knowledge Engineering", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Sentiment analysis: Adjectives and adverbs are better than adjectives alone", "author": ["F. Benamara", "C. Cesarano", "A. Picariello", "D.R. Recupero", "V.S. Subrahmanian"], "venue": "The International AAAI Conference on Web and Social Media ICWSM. Citeseer", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification", "author": ["J. Blitzer", "M. Dredze", "F. Pereira"], "venue": "Annual Meeting of the Association of Computational Linguistics", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Movie review mining: A comparison between supervised and unsupervised classification approaches", "author": ["P. Chaovalit", "L. Zhou"], "venue": "Proceedings of the 38th Annual Hawaii International Conference on System Sciences HICSS. IEEE,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2005}, {"title": "Search engines: Information retrieval in practice", "author": ["W.B. Croft", "D. Metzler", "T. Strohman"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Tweet sentiment analysis with classifier ensembles", "author": ["N.F. da Silva", "E.R. Hruschka"], "venue": "Decision Support Systems", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Ensemble methods in machine learning. In: Multiple classifier systems", "author": ["T.G. Dietterich"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "User-level twitter sentiment analysis with a hybrid approach", "author": ["M.J. Er", "F. Liu", "N. Wang", "Y. Zhang", "M. Pratama"], "venue": "In: International Symposium on Neural Networks. Springer,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "SentiWordNet: A publicly available lexical resource for opinion mining", "author": ["A. Esuli", "F. Sebastiani"], "venue": "Proceedings of Language Resources and Evaluation LREC", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "Techniques and applications for sentiment analysis", "author": ["R. Feldman"], "venue": "Communications of the ACM", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Expressive signals in social media languages to improve polarity detection", "author": ["E. Fersini", "E. Messina", "F. Pozzi"], "venue": "Information Processing & Management", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Why do urban legends go viral", "author": ["M. Guerini", "C. Strapparava"], "venue": "Information Processing & Management", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Neural network ensembles. IEEE transactions on pattern analysis and machine intelligence", "author": ["L.K. Hansen", "P. Salamon"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1990}, {"title": "Predicting the semantic orientation of adjectives. In: Proceedings of the 35th annual meeting of the association for computational linguistics and eighth conference of the European chapter of the association for computational linguistics", "author": ["V. Hatzivassiloglou", "K.R. McKeown"], "venue": "Association for Computational Linguistics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1997}, {"title": "Comparing partitions", "author": ["L. Hubert", "P. Arabie"], "venue": "Journal of classification", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1985}, {"title": "Taking sides: User classification for informal online political discourse", "author": ["Y. Kato", "S. Kurohashi", "K. Inui", "R. Malouf", "T. Mullen"], "venue": "Internet Research", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Sentiment analysis of short informal texts", "author": ["S. Kiritchenko", "X. Zhu", "S.M. Mohammad"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Inducing the contextual and prior polarity of nouns from the induced polarity preference of verbs", "author": ["M. Klenner", "S. Petrakis"], "venue": "Data & Knowledge Engineering", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "A genetic algorithm that exchanges neighboring centers for k-means clustering", "author": ["M. Laszlo", "S. Mukherjee"], "venue": "Pattern Recognition Letters", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "Simultaneous feature selection and clustering using mixture models. IEEE transactions on pattern analysis and machine intelligence", "author": ["M.H. Law", "M.A. Figueiredo", "A.K. Jain"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}, {"title": "Application of a clustering method on sentiment analysis", "author": ["G. Li", "F. Liu"], "venue": "Journal of Information Science", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Sentiment classification and polarity shifting", "author": ["S. Li", "S.Y.M. Lee", "Y. Chen", "Huang", "C.-R", "G. Zhou"], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics. Association for Computational Linguistics,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2010}, {"title": "Heterogeneous ensemble learning for chinese sentiment classification", "author": ["W. Li", "W. Wang", "Y. Chen"], "venue": "Journal of Information and Computational Science", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Text-based emotion classification using emotion cause extraction", "author": ["W. Li", "H. Xu"], "venue": "Expert Systems with Applications", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "Sentiment analysis and opinion mining", "author": ["B. Liu"], "venue": "Synthesis lectures on human language technologies", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "A comparison study of clustering models for online review sentiment analysis. In: Web-Age Information Management WAIM", "author": ["B. Ma", "H. Yuan", "Q. Wei"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "A general framework for subjective information extraction from unstructured english text", "author": ["H. Mangassarian", "H. Artail"], "venue": "Data & Knowledge Engineering", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2007}, {"title": "Contextual sentiment analysis for social media genres", "author": ["A. Muhammad", "N. Wiratunga", "R. Lothian"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2016}, {"title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["B. Pang", "L. Lee"], "venue": "Proceedings of the 42nd annual meeting on Association for Computational Linguistics. Association for Computational Linguistics,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2004}, {"title": "Thumbs up?: sentiment classification using machine learning techniques. In: Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10", "author": ["B. Pang", "L. Lee", "S. Vaithyanathan"], "venue": "Association for Computational Linguistics,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2002}, {"title": "Estimating reputation polarity on microblog posts", "author": ["Peetz", "M.-H", "M. de Rijke", "R. Kaptein"], "venue": "Information Processing & Management", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2015}, {"title": "Sentiment analysis of suicide notes: A shared task. Biomedical informatics insights 5 (Suppl", "author": ["J.P. Pestian", "P. Matykiewicz", "M. Linn-Gust", "B. South", "O. Uzuner", "J. Wiebe", "K.B. Cohen", "J. Hurdle", "C. Brew"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2012}, {"title": "Contextual valence shifters. In: Computing attitude and affect in text: Theory and applications", "author": ["L. Polanyi", "A. Zaenen"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2006}, {"title": "Mining subjective knowledge from customer reviews: A specific case of irony detection", "author": ["A. Reyes", "P. Rosso"], "venue": "Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis. Association for Computational Linguistics,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2011}, {"title": "From humor recognition to irony detection: The figurative language of social media", "author": ["A. Reyes", "P. Rosso", "D. Buscaldi"], "venue": "Data & Knowledge Engineering", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2012}, {"title": "The smart retrieval system-experiments in automatic document processing", "author": ["G. Salton"], "venue": null, "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1971}, {"title": "The strength of weak learnability", "author": ["R.E. Schapire"], "venue": "Machine learning", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1990}, {"title": "Sops: stock prediction using web sentiment", "author": ["V. Sehgal", "C. Song"], "venue": "Proceedings of the International Conference on Data Mining Workshops ICDMW", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2007}, {"title": "Stream-based active learning for sentiment analysis in the financial domain", "author": ["J. Smailovi\u0107", "M. Gr\u010dar", "N. Lavra\u010d", "M. \u017dnidar\u0161i\u010d"], "venue": "Information Sciences", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2014}, {"title": "The general inquirer: A computer approach to content analysis", "author": ["P.J. Stone", "D.C. Dunphy", "M.S. Smith"], "venue": null, "citeRegEx": "44", "shortCiteRegEx": "44", "year": 1966}, {"title": "Lexicon-based methods for sentiment analysis", "author": ["M. Taboada", "J. Brooke", "M. Tofiloski", "K. Voll", "M. Stede"], "venue": "Computational linguistics", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2011}, {"title": "Enriching the knowledge sources used in a maximum entropy part-of-speech tagger", "author": ["K. Toutanova", "C.D. Manning"], "venue": "Association for Computational Linguistics,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2000}, {"title": "Extraction and clustering of arguing expressions in contentious text", "author": ["A. Trabelsi", "O.R. Z\u00e4\u0131ane"], "venue": "Data & Knowledge Engineering", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2015}, {"title": "Movie review classification based on a multiple classifier. In: Proceedings of the annual meetings of the Pacific Asia conference on language, information and computation (PACLIC)", "author": ["K. Tsutsumi", "K. Shimada", "T. Endo"], "venue": null, "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2007}, {"title": "Predicting elections with twitter: What 140 characters reveal about political sentiment", "author": ["A. Tumasjan", "T.O. Sprenger", "P.G. Sandner", "I.M. Welpe"], "venue": null, "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2010}, {"title": "Sentiment classification: The contribution of ensemble learning", "author": ["G. Wang", "J. Sun", "J. Ma", "K. Xu", "J. Gu"], "venue": "Decision support systems", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2014}, {"title": "Pos-rs: A random subspace method for sentiment classification based on part-of-speech analysis", "author": ["G. Wang", "Z. Zhang", "J. Sun", "S. Yang", "C.A. Larson"], "venue": "Information Processing & Management", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2015}, {"title": "Sentiment mining using ensemble classification models. In: Innovations and advances in computer sciences and engineering", "author": ["M. Whitehead", "L. Yaeger"], "venue": null, "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2010}, {"title": "Recognizing contextual polarity in phraselevel sentiment analysis. In: Proceedings of the conference on human language technology and empirical methods in natural language processing", "author": ["T. Wilson", "J. Wiebe", "P. Hoffmann"], "venue": "Association for Computational Linguistics,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2005}, {"title": "Youtube movie reviews: Sentiment analysis in an audio-visual context", "author": ["M. Wollmer", "F. Weninger", "T. Knaup", "B. Schuller", "C. Sun", "K. Sagae", "Morency", "L.-P"], "venue": "Intelligent Systems,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2013}, {"title": "Top 10 algorithms in data mining", "author": ["X. Wu", "V. Kumar", "J.R. Quinlan", "J. Ghosh", "Q. Yang", "H. Motoda", "G.J. McLachlan", "A. Ng", "B. Liu", "Philip", "S. Y"], "venue": "Knowledge and information systems", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2008}, {"title": "Polarity shift detection, elimination and ensemble: A three-stage model for document-level sentiment analysis", "author": ["R. Xia", "F. Xu", "J. Yu", "Y. Qi", "E. Cambria"], "venue": "Information Processing & Management", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2016}, {"title": "Ensemble of feature sets and classification algorithms for sentiment classification", "author": ["R. Xia", "C. Zong", "S. Li"], "venue": "Information Sciences", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2011}, {"title": "Enhancing k-means clustering algorithm with improved initial center", "author": ["M. Yedla", "S.R. Pathakota", "T. Srinivasa"], "venue": "International Journal of computer science and information technologies", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2010}, {"title": "A new feature selection method for gaussian mixture clustering", "author": ["H. Zeng", "Cheung", "Y.-M"], "venue": "Pattern Recognition", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2009}, {"title": "Cross-domain sentiment classification via topical correspondence transfer", "author": ["G. Zhou", "Y. Zhou", "X. Guo", "X. Tu", "T. He"], "venue": "Neurocomputing 159,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2015}], "referenceMentions": [{"referenceID": 47, "context": "Many diverse domains and applications can benefit from SA, including those in the political [49, 19] linguistic [15] medical and social issues [36] and financial [35, 43, 42] domains.", "startOffset": 92, "endOffset": 100}, {"referenceID": 18, "context": "Many diverse domains and applications can benefit from SA, including those in the political [49, 19] linguistic [15] medical and social issues [36] and financial [35, 43, 42] domains.", "startOffset": 92, "endOffset": 100}, {"referenceID": 14, "context": "Many diverse domains and applications can benefit from SA, including those in the political [49, 19] linguistic [15] medical and social issues [36] and financial [35, 43, 42] domains.", "startOffset": 112, "endOffset": 116}, {"referenceID": 34, "context": "Many diverse domains and applications can benefit from SA, including those in the political [49, 19] linguistic [15] medical and social issues [36] and financial [35, 43, 42] domains.", "startOffset": 143, "endOffset": 147}, {"referenceID": 33, "context": "Many diverse domains and applications can benefit from SA, including those in the political [49, 19] linguistic [15] medical and social issues [36] and financial [35, 43, 42] domains.", "startOffset": 162, "endOffset": 174}, {"referenceID": 41, "context": "Many diverse domains and applications can benefit from SA, including those in the political [49, 19] linguistic [15] medical and social issues [36] and financial [35, 43, 42] domains.", "startOffset": 162, "endOffset": 174}, {"referenceID": 40, "context": "Many diverse domains and applications can benefit from SA, including those in the political [49, 19] linguistic [15] medical and social issues [36] and financial [35, 43, 42] domains.", "startOffset": 162, "endOffset": 174}, {"referenceID": 26, "context": "Thus a considerable attention has been drawn to SA and closely-related research directions such as emotion detection [27, 4], subjectivity analysis [30], irony detection [39, 38], and contention texts analysis [47].", "startOffset": 117, "endOffset": 124}, {"referenceID": 3, "context": "Thus a considerable attention has been drawn to SA and closely-related research directions such as emotion detection [27, 4], subjectivity analysis [30], irony detection [39, 38], and contention texts analysis [47].", "startOffset": 117, "endOffset": 124}, {"referenceID": 29, "context": "Thus a considerable attention has been drawn to SA and closely-related research directions such as emotion detection [27, 4], subjectivity analysis [30], irony detection [39, 38], and contention texts analysis [47].", "startOffset": 148, "endOffset": 152}, {"referenceID": 37, "context": "Thus a considerable attention has been drawn to SA and closely-related research directions such as emotion detection [27, 4], subjectivity analysis [30], irony detection [39, 38], and contention texts analysis [47].", "startOffset": 170, "endOffset": 178}, {"referenceID": 36, "context": "Thus a considerable attention has been drawn to SA and closely-related research directions such as emotion detection [27, 4], subjectivity analysis [30], irony detection [39, 38], and contention texts analysis [47].", "startOffset": 170, "endOffset": 178}, {"referenceID": 45, "context": "Thus a considerable attention has been drawn to SA and closely-related research directions such as emotion detection [27, 4], subjectivity analysis [30], irony detection [39, 38], and contention texts analysis [47].", "startOffset": 210, "endOffset": 214}, {"referenceID": 12, "context": "over 7,000 research works [13].", "startOffset": 26, "endOffset": 30}, {"referenceID": 19, "context": "Manually generated lexicons such as MaxDiff [20], MPQA [53] and General Inquirer [44] contain comparably less terms and usually a sentiment score or label is associated with each word.", "startOffset": 44, "endOffset": 48}, {"referenceID": 51, "context": "Manually generated lexicons such as MaxDiff [20], MPQA [53] and General Inquirer [44] contain comparably less terms and usually a sentiment score or label is associated with each word.", "startOffset": 55, "endOffset": 59}, {"referenceID": 42, "context": "Manually generated lexicons such as MaxDiff [20], MPQA [53] and General Inquirer [44] contain comparably less terms and usually a sentiment score or label is associated with each word.", "startOffset": 81, "endOffset": 85}, {"referenceID": 20, "context": "For automatically generated lexicons [21], such as SentiWordNet (SWN)[12], the number of terms is usually high and generally no human participation is required.", "startOffset": 37, "endOffset": 41}, {"referenceID": 11, "context": "For automatically generated lexicons [21], such as SentiWordNet (SWN)[12], the number of terms is usually high and generally no human participation is required.", "startOffset": 69, "endOffset": 73}, {"referenceID": 16, "context": "One of the earliest work was the lexicon-based method by Hatzivassiloglou and McKeown [17], where adjectives conjoined by \u201dand\u201d or \u201dbut\u201d were used to build a lexicon, then clustering a graph that was produced by using the generated lexicon.", "startOffset": 86, "endOffset": 90}, {"referenceID": 43, "context": "Recent studies [45, 11] have combined a lexicon-based approach with other techniques such as linguistic rules and neural networks.", "startOffset": 15, "endOffset": 23}, {"referenceID": 10, "context": "Recent studies [45, 11] have combined a lexicon-based approach with other techniques such as linguistic rules and neural networks.", "startOffset": 15, "endOffset": 23}, {"referenceID": 27, "context": "Contextual analysis methods are usually addressing common linguistic structures such as negation and contrast, which also were referred to as sentiment shifters [28], sentiment modifiers [32], polarity shifters [56, 25] and valence shifter [45, 37].", "startOffset": 161, "endOffset": 165}, {"referenceID": 30, "context": "Contextual analysis methods are usually addressing common linguistic structures such as negation and contrast, which also were referred to as sentiment shifters [28], sentiment modifiers [32], polarity shifters [56, 25] and valence shifter [45, 37].", "startOffset": 187, "endOffset": 191}, {"referenceID": 54, "context": "Contextual analysis methods are usually addressing common linguistic structures such as negation and contrast, which also were referred to as sentiment shifters [28], sentiment modifiers [32], polarity shifters [56, 25] and valence shifter [45, 37].", "startOffset": 211, "endOffset": 219}, {"referenceID": 24, "context": "Contextual analysis methods are usually addressing common linguistic structures such as negation and contrast, which also were referred to as sentiment shifters [28], sentiment modifiers [32], polarity shifters [56, 25] and valence shifter [45, 37].", "startOffset": 211, "endOffset": 219}, {"referenceID": 43, "context": "Contextual analysis methods are usually addressing common linguistic structures such as negation and contrast, which also were referred to as sentiment shifters [28], sentiment modifiers [32], polarity shifters [56, 25] and valence shifter [45, 37].", "startOffset": 240, "endOffset": 248}, {"referenceID": 35, "context": "Contextual analysis methods are usually addressing common linguistic structures such as negation and contrast, which also were referred to as sentiment shifters [28], sentiment modifiers [32], polarity shifters [56, 25] and valence shifter [45, 37].", "startOffset": 240, "endOffset": 248}, {"referenceID": 54, "context": "In [56], a rule-based method is proposed to detect text contains a negation and contrast, which was used to train a component classifier of an ensemble method.", "startOffset": 3, "endOffset": 7}, {"referenceID": 43, "context": "In order to tackle the ambiguity of the contextual linguistic structures some studies [45, 37, 32] proposed lexicon and rule-based methods.", "startOffset": 86, "endOffset": 98}, {"referenceID": 35, "context": "In order to tackle the ambiguity of the contextual linguistic structures some studies [45, 37, 32] proposed lexicon and rule-based methods.", "startOffset": 86, "endOffset": 98}, {"referenceID": 30, "context": "In order to tackle the ambiguity of the contextual linguistic structures some studies [45, 37, 32] proposed lexicon and rule-based methods.", "startOffset": 86, "endOffset": 98}, {"referenceID": 32, "context": "[34], who conducted experiments using three supervised machine algorithms, NB, ME and SVM, is considered a cornerstone work in this field.", "startOffset": 0, "endOffset": 4}, {"referenceID": 55, "context": "In the later work more complex supervised learning algorithms were suggested to address the natural language complexity, such as ensemble algorithms [57, 56, 51] where certain mechanisms can be used to combine results of several classifiers and vector space models, which can increase the accuracy rate.", "startOffset": 149, "endOffset": 161}, {"referenceID": 54, "context": "In the later work more complex supervised learning algorithms were suggested to address the natural language complexity, such as ensemble algorithms [57, 56, 51] where certain mechanisms can be used to combine results of several classifiers and vector space models, which can increase the accuracy rate.", "startOffset": 149, "endOffset": 161}, {"referenceID": 49, "context": "In the later work more complex supervised learning algorithms were suggested to address the natural language complexity, such as ensemble algorithms [57, 56, 51] where certain mechanisms can be used to combine results of several classifiers and vector space models, which can increase the accuracy rate.", "startOffset": 149, "endOffset": 161}, {"referenceID": 58, "context": "However most of them were composed of supervised learners whcih need to be trained on labeled data, thus sufferings from the domain dependency problem and usually can not deal effectively with completely unseen data [60].", "startOffset": 216, "endOffset": 220}, {"referenceID": 23, "context": "A sentiment analysis approach, which leverages the k-means clustering algorithm, was introduced by Li and Liu [24].", "startOffset": 110, "endOffset": 114}, {"referenceID": 28, "context": "In [29], a comparative study was conducted on several clustering algorithms and with different weights.", "startOffset": 3, "endOffset": 7}, {"referenceID": 28, "context": "[29] shows the impact of some weight schemas, and they report that k-means results in higher accuracy on average.", "startOffset": 0, "endOffset": 4}, {"referenceID": 54, "context": "A similar approach was suggested in [56], however, our method differs in that it processes positive/negative adjectives and adverbs only and also, we used SWN to build the dictionary.", "startOffset": 36, "endOffset": 40}, {"referenceID": 4, "context": "All the documents are represented by their sentiment expressing words such as adjectives and adverbs [5].", "startOffset": 101, "endOffset": 104}, {"referenceID": 0, "context": "(2) kmeans will always converge with a low number of iterations [1], which we also observe experimentally (Refer to Table 3 and 4).", "startOffset": 64, "endOffset": 67}, {"referenceID": 53, "context": "The default k-means is initiated by selecting k random centroids (vectors) from a given dataset [55].", "startOffset": 96, "endOffset": 100}, {"referenceID": 11, "context": "0 (SWN) [12] is an automatically generated lexicon in which three scores (positive, negative and objective) are assigned to each synset from WordNet.", "startOffset": 8, "endOffset": 12}, {"referenceID": 2, "context": "0 [3] is used which is based on WordNet 3.", "startOffset": 2, "endOffset": 5}, {"referenceID": 2, "context": "An improvement of over 19% was reported [3] when using the updated version.", "startOffset": 40, "endOffset": 43}, {"referenceID": 53, "context": "The initial selection of k-means centroids is an important factor in forming the final clusters, hence the process and outcome of clustering to a certain degree depends on the first iteration where the initial centroids are selected [55].", "startOffset": 233, "endOffset": 237}, {"referenceID": 0, "context": "Some suggestions were introduced to address this problem such as k-means++ [1] which selects distanced random points where the probability of choosing each of these points is proportional to its overall potential contribution.", "startOffset": 75, "endOffset": 78}, {"referenceID": 21, "context": "Other studies suggest genetic algorithms to address this issue [22, 2].", "startOffset": 63, "endOffset": 70}, {"referenceID": 1, "context": "Other studies suggest genetic algorithms to address this issue [22, 2].", "startOffset": 63, "endOffset": 70}, {"referenceID": 23, "context": "In [24], several results of k-means runs were combined using a voting mechanism, however, their method still based on a stochastic initialization and it does not completely eliminate the instability problem.", "startOffset": 3, "endOffset": 7}, {"referenceID": 7, "context": "Term normalization (TN) [8].", "startOffset": 24, "endOffset": 27}, {"referenceID": 7, "context": "Term frequencyinverse document frequency (TF-IDF) [8].", "startOffset": 50, "endOffset": 53}, {"referenceID": 23, "context": "In [24], group polarity is judged based on the distribution of solid polarity documents in the clusters, and its solidity has been proven experimentally by observing 100 clustering results, where 22 documents were always correctly classified.", "startOffset": 3, "endOffset": 7}, {"referenceID": 23, "context": "To examine the possibility if a classifier labels the positive seed as a negative instance, and the negative seed as a positive instance, we compared our method with Li and Liu [24]\u2019s method, which is based on the confusion matrix.", "startOffset": 177, "endOffset": 181}, {"referenceID": 23, "context": "In the confusion matrix (refer to Table 1), where a, b, c, and d are the number of documents therefore, in [24], if (b + c) > (a + d), Cluster 1", "startOffset": 107, "endOffset": 111}, {"referenceID": 50, "context": "It can combine learners of the same type, for example, bagging and boosting ensemble methods [52, 50].", "startOffset": 93, "endOffset": 101}, {"referenceID": 48, "context": "It can combine learners of the same type, for example, bagging and boosting ensemble methods [52, 50].", "startOffset": 93, "endOffset": 101}, {"referenceID": 8, "context": "It can also be an ensemble of different types of classifiers [9].", "startOffset": 61, "endOffset": 64}, {"referenceID": 49, "context": "The ensemble algorithms that have been proposed for sentiment analysis are mostly supervised algorithms [51, 48, 26, 14].", "startOffset": 104, "endOffset": 120}, {"referenceID": 46, "context": "The ensemble algorithms that have been proposed for sentiment analysis are mostly supervised algorithms [51, 48, 26, 14].", "startOffset": 104, "endOffset": 120}, {"referenceID": 25, "context": "The ensemble algorithms that have been proposed for sentiment analysis are mostly supervised algorithms [51, 48, 26, 14].", "startOffset": 104, "endOffset": 120}, {"referenceID": 13, "context": "The ensemble algorithms that have been proposed for sentiment analysis are mostly supervised algorithms [51, 48, 26, 14].", "startOffset": 104, "endOffset": 120}, {"referenceID": 15, "context": "The idea is that ensemble can be more accurate compared to a single classifier if the component classifiers are diverse and accurate [16].", "startOffset": 133, "endOffset": 137}, {"referenceID": 39, "context": "An accurate classifier, also referred to as a weak classifier by Schapire [41], according to [10, 41] is a classifier which its performance is better than random guessing.", "startOffset": 74, "endOffset": 78}, {"referenceID": 9, "context": "An accurate classifier, also referred to as a weak classifier by Schapire [41], according to [10, 41] is a classifier which its performance is better than random guessing.", "startOffset": 93, "endOffset": 101}, {"referenceID": 39, "context": "An accurate classifier, also referred to as a weak classifier by Schapire [41], according to [10, 41] is a classifier which its performance is better than random guessing.", "startOffset": 93, "endOffset": 101}, {"referenceID": 9, "context": "It can also solve the overfitting problem, avoiding potential computational failure such as stacking in local optima and solving complex problems which might be too difficult to solve using a single classifier [10].", "startOffset": 210, "endOffset": 214}, {"referenceID": 17, "context": "As we are interested in both negative and positive classes, the evaluation is done by calculating the accuracy [31, 18].", "startOffset": 111, "endOffset": 119}, {"referenceID": 5, "context": "We also conduct experiments on movie dataset and multi-domain datasets [6] (refer to Table 2).", "startOffset": 71, "endOffset": 74}, {"referenceID": 31, "context": "The movie review dataset by [33], which is the enhanced version of Pang et al.", "startOffset": 28, "endOffset": 32}, {"referenceID": 32, "context": "[34]\u2019s dataset, is a well-known dataset in the field of sentiment analysis and has been used in many research studies.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "It is widely believed that movie reviews are difficult documents to classify compared to other product reviews [7, 54].", "startOffset": 111, "endOffset": 118}, {"referenceID": 52, "context": "It is widely believed that movie reviews are difficult documents to classify compared to other product reviews [7, 54].", "startOffset": 111, "endOffset": 118}, {"referenceID": 5, "context": "The multi-domain dataset [6] is a benchmark dataset which was constructed by Blitzer et al.", "startOffset": 25, "endOffset": 28}, {"referenceID": 5, "context": "[6] using reviews on different products taken from Amazon.", "startOffset": 0, "endOffset": 3}, {"referenceID": 31, "context": "au HomeBuilders 1100 1100 Movie [33] 1000 1000 http://www.", "startOffset": 32, "endOffset": 36}, {"referenceID": 5, "context": "com Kitchen [6] 1000 1000 Apparel [6] 1000 1000 https://www.", "startOffset": 12, "endOffset": 15}, {"referenceID": 5, "context": "com Kitchen [6] 1000 1000 Apparel [6] 1000 1000 https://www.", "startOffset": 34, "endOffset": 37}, {"referenceID": 5, "context": "com Toys&Games [6] 1000 1000 Baby [6] 900 900", "startOffset": 15, "endOffset": 18}, {"referenceID": 5, "context": "com Toys&Games [6] 1000 1000 Baby [6] 900 900", "startOffset": 34, "endOffset": 37}, {"referenceID": 44, "context": "For extracting adjectives and adverbs we use Stanford part-of-speech tagger [46].", "startOffset": 76, "endOffset": 80}, {"referenceID": 38, "context": "This model was proposed for the information retrieval system [40].", "startOffset": 61, "endOffset": 65}, {"referenceID": 22, "context": "learning process [23, 59].", "startOffset": 17, "endOffset": 25}, {"referenceID": 57, "context": "learning process [23, 59].", "startOffset": 17, "endOffset": 25}, {"referenceID": 23, "context": "We also report results of a clustering based method by Li and Liu [24] on a sample of movie review dataset.", "startOffset": 66, "endOffset": 70}, {"referenceID": 23, "context": "Table 5: Evaluation Datasets ACACCE SVM RF J48 NB MNB Clustering [24] Baseline AirLines 83.", "startOffset": 65, "endOffset": 69}, {"referenceID": 23, "context": "an unsupervised method by Li and Liu [24] which is due to the contextual analysis phase, using initial polar seeds and utilize a diverse weight schemes.", "startOffset": 37, "endOffset": 41}, {"referenceID": 23, "context": "Unlike Li and Lius method proposed in [24], this study proposes more robust and reliable method because every run on the same data the algorithm guarantees the same performance and outcome which is due to the nonstochastic centroids initialization.", "startOffset": 38, "endOffset": 42}, {"referenceID": 4, "context": "This study supports what have been suggested in previous research [5] that adjectives and adverbs are the most informative parts of speech in term of sentiment analysis.", "startOffset": 66, "endOffset": 69}, {"referenceID": 15, "context": "Increasing the number of diverse and accurate classifiers slightly enhances the algorithm accuracy, and this is supporting what have been stated in [16].", "startOffset": 148, "endOffset": 152}, {"referenceID": 21, "context": "Selecting initial points for k-means is crucial and it was a research topic for some studies [22, 2, 58].", "startOffset": 93, "endOffset": 104}, {"referenceID": 1, "context": "Selecting initial points for k-means is crucial and it was a research topic for some studies [22, 2, 58].", "startOffset": 93, "endOffset": 104}, {"referenceID": 56, "context": "Selecting initial points for k-means is crucial and it was a research topic for some studies [22, 2, 58].", "startOffset": 93, "endOffset": 104}], "year": 2017, "abstractText": "Products reviews are one of the major resources to determine the public sentiment. The existing literature on reviews sentiment analysis mainly utilizes supervised paradigm, which needs labeled data to be trained on and suffers from domain-dependency. This article addresses these issues by describes a completely automatic approach for sentiment analysis based on unsupervised ensemble learning. The method consists of two phases. The first phase is contextual analysis, which has five processes, namely (1) data preparation; (2) spelling correction; (3) intensifier handling; (4) negation handling and (5) contrast handling. The second phase comprises the unsupervised learning approach, which is an ensemble of clustering classifiers using a majority voting mechanism with different weight schemes. The base classifier of the ensemble method is a modified k-means algorithm. The base classifier is modified by extracting initial centroids from the feature set via using SentWordNet (SWN). We also introduce new sentiment analysis problems of Australian airlines and home builders which offer potential benchmark problems in the sentiment analysis field. Our experiments on datasets from different domains show that contextual analysis and the ensemble phases improve the clustering performance in term of accuracy, stability and generalization ability.", "creator": "LaTeX with hyperref package"}}}