{"id": "1705.10308", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-May-2017", "title": "Learning Belief Network Structure From Data under Causal Insufficiency", "abstract": "Though a belief network (a representation of the joint probability distribution, see [3]) and a causal network (a representation of causal relationships [14]) are intended to mean different things, they are closely related. Both assume an underlying dag (directed acyclic graph) structure of relations among variables and if Markov condition and faithfulness condition [15] are met, then a causal network is in fact a belief network. The difference comes to appearance when we recover belief network and causal network structure from data.", "histories": [["v1", "Mon, 29 May 2017 17:58:13 GMT  (17kb)", "http://arxiv.org/abs/1705.10308v1", "A short version of this paper appeared in [Klopotek:94m] M.A. K{\\l}opotek: Learning Belief Network Structure From Data under Causal Insufficiency. [in:] F. Bergadano, L.DeRaed Eds.: Machine Learning ECML-94 , Proc. 13th European Conference on Machine Learning, Catania, Italy, 6-8 April 1994, Lecture Notes in Artificial Intelligence 784, Springer-Verlag, 1994, pp. 379-382"]], "COMMENTS": "A short version of this paper appeared in [Klopotek:94m] M.A. K{\\l}opotek: Learning Belief Network Structure From Data under Causal Insufficiency. [in:] F. Bergadano, L.DeRaed Eds.: Machine Learning ECML-94 , Proc. 13th European Conference on Machine Learning, Catania, Italy, 6-8 April 1994, Lecture Notes in Artificial Intelligence 784, Springer-Verlag, 1994, pp. 379-382", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["mieczys{\\l}aw k{\\l}opotek"], "accepted": false, "id": "1705.10308"}, "pdf": {"name": "1705.10308.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["klopotek@ipipan.waw.pl"], "sections": [{"heading": null, "text": "ar Xiv: 170 5.10 308v 1 [cs.A I] 2 9M ay2 017"}, {"heading": "Learning Belief Network Structure", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "From Data under Causal Insufficiency", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Mieczys law A. K lopotek", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Institute of Computer Science, Polish Academy of Sciences", "text": "E-Mail: klopotek @ ipipan.waw.pl"}, {"heading": "1 Introduction", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "2 Causal Inference Algorithm", "text": "In the following, we recall the Causal Inference (CI) algorithm of Spirtes > > Glymour and Scheme [15] along with a basic notation used therein. Essentially, the CI algorithm partially restores the structure of an inclusive path diagram. If a directed acyclic graph G contains the group of hidden nodes Vh and visible nodes Vs representing a causal network CN, a path between nodes A and B belonging to Vs is represented as a path in graph G in such a way that the only visible nodes on the path (except A and B) are those where edges of the path meet and there is a directed path in G from such a node to either A or B. An inclusive path for G is such a graph via Vs in which the nodes A and B are connected by a path in G, connected by a path in G, and then connected by a path in G, and B by a direct border."}, {"heading": "The Causal Inference (CI) Algorithm:", "text": "Input: Empirical Common Probability DistributionOutput: Partly including path chart \u03c0.A > D > D *, there is a complete undirected graph Q set on the vertex V.B), if A and B are separated from V by a subset S, remove the edge between A and B and write down sin sepset (A, B) and sepset (B, A).C) Let F be the graph resulting from step B. Align each edge o-o. For each triplicate A, B, Cso that the pair A, B and the pair B, C in F are adjacent, but the pair A, C in F is not adjacent, orient (C) A * - * - * B * - * C as A-A < - C as A- > B < \u2212 C as A < \u2212 C as A < \u2212 C, if and only if B is in sepset."}, {"heading": "3 From CI Output to Belief Network", "text": "Let us imagine that we have received a partially inclusive pathgraph from the CI, and we want to find a faith network that represents the common probability distribution from it. Consider the following algorithm:"}, {"heading": "CI-to-BN Algorithm", "text": "This year, it is more than ever before in the history of the city in which we find ourselves."}, {"heading": "4 Summary and Outlook", "text": "In this paper, an algorithm for restoring the network structure of faith from data was presented and demonstrated to be correct. It is essentially based on exploiting the result of the well-known cochlear implant algorithm of Spirtes, Glymour and Appearance [15]. The edges of the sub-path graph, which is not aligned by the cochlear implant, are aimed at forming a directed acyclic graph. The contribution of this paper is to show that such an edge orientation always exists without the need for the addition of hidden auxiliary variables and that this therefore covers all dependencies and dependencies of the intrinsic graph, including the path chart. The CI-to-BN algorithm will have exactly the same deficiencies as the cochlection algorithm, i.e. it is tractable only for a small number of edges. It will be an interesting task to examine the possibility of such an adaptation of the CI-to-BN algorithm."}], "references": [{"title": "MUNIN - a causal probabilistic network for interpretation of electromyographic findings", "author": ["S. Andreassen", "M. Woldbye", "B. Falck", "S.K. Andersen"], "venue": "Proc. of the Tenth International Joint Conference on AI,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1987}, {"title": "A Bayesian method for the induction of probabilistic networks from data, Machine Learning", "author": ["G.F. Cooper", "E. Herskovits"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1992}, {"title": "d-Separation: From theorems to algorithms, M.Henrion, R.D.Shachter, L.N.Kamal, J.F.Lemmer (Eds): Uncertainty in Artificial Intelligence", "author": ["D. Geiger", "T Verma", "J. Pearl"], "venue": "Elsevier Science Publishers B.V. (North-Holland),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1990}, {"title": "Discovering causal structure, New York", "author": ["C. Glymour", "R. Scheines", "P. Spirtes", "K. Kelley"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1987}, {"title": "Latent variables, causal models and overidentifying constraints", "author": ["C. Glymour", "P. Spirtes"], "venue": "Journal of Econometrics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1988}, {"title": "Learning probabilities in causal trees from incomplete databases", "author": ["J.L. Golmard", "A. Mallet"], "venue": "Proc. of the IJCAI Workshop on Knowledge Discovery in Databases (Detroit M.I.),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1989}, {"title": "Minimum error tree decomposition", "author": ["L. Liu", "D.C. Wilkins", "X. Ying", "Z. Bian"], "venue": "Proc. of the Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1990}, {"title": "Fusion, propagation and structuring in belief networks", "author": ["J. Pearl"], "venue": "Artificial Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1986}, {"title": "Probabilistic Reasoning in Intelligent Systems:Networks of Plausible Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1988}, {"title": "A theory of inferred causation,, [in:] Principles of Knowledge Representation and Reasoning", "author": ["J. Pearl", "T. Verma"], "venue": "Proc. of the Second International Conference,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1991}, {"title": "Evidence absorption and propagation through evidence reversals", "author": ["R.D. Shachter"], "venue": "Uncertainty in Artificial Intelligence", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1990}, {"title": "Axioms for probability and belief-function propagation", "author": ["P.P. Shenoy", "G. Shafer"], "venue": "eds: Uncertainty in Artificial Intelligence 4, (Elsevier Science Publishers B.V. (North Holland),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1990}, {"title": "Simulation studies of the reliability of computer-aided model specification using TETRAD II, EQS and LISREL programs", "author": ["P. Spirtes", "C. Glymour", "R. Scheines"], "venue": "Sociological Methods and Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1990}, {"title": "Causality from probability, in: G.McKee ed.: Evolving knowledge in natural and artificial intelligence (London", "author": ["P. Spirtes", "C. Glymour", "R. Scheines"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1990}, {"title": "Causation, Prediction and Search", "author": ["P. Spirtes", "C. Glymour", "R. Scheines"], "venue": "Lecture Notes in Statistics", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1993}, {"title": "Equivalence and synthesis of causal models", "author": ["T. Verma", "J. Pearl"], "venue": "Proc. 6th Conference on Uncertainty in AI,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1990}], "referenceMentions": [{"referenceID": 0, "context": "knowledge base of the MUNIM system [1] , ALARM network [2] etc.", "startOffset": 35, "endOffset": 38}, {"referenceID": 1, "context": "knowledge base of the MUNIM system [1] , ALARM network [2] etc.", "startOffset": 55, "endOffset": 58}, {"referenceID": 8, "context": "[9], [11], [12].", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "[9], [11], [12].", "startOffset": 5, "endOffset": 9}, {"referenceID": 11, "context": "[9], [11], [12].", "startOffset": 11, "endOffset": 15}, {"referenceID": 2, "context": "stochastic) relationships in various domains: statistics, philosophy, artificial intelligence [3], [14].", "startOffset": 94, "endOffset": 97}, {"referenceID": 13, "context": "stochastic) relationships in various domains: statistics, philosophy, artificial intelligence [3], [14].", "startOffset": 99, "endOffset": 103}, {"referenceID": 2, "context": "Though a belief network (a representation of the joint probability distribution, see [3]) and a causal network (a representation of causal relationships [14]) are intended to mean different things, they are closely related.", "startOffset": 85, "endOffset": 88}, {"referenceID": 13, "context": "Though a belief network (a representation of the joint probability distribution, see [3]) and a causal network (a representation of causal relationships [14]) are intended to mean different things, they are closely related.", "startOffset": 153, "endOffset": 157}, {"referenceID": 14, "context": "Both assume an underlying dag (directed acyclic graph) structure of relations among variables and if Markov condition and faithfulness condition [15] are met, then a causal network is in fact a belief network.", "startOffset": 145, "endOffset": 149}, {"referenceID": 14, "context": "A causal network structure may be impossible to recover completely from data as not all directions of causal links may be uniquely determined [15].", "startOffset": 142, "endOffset": 146}, {"referenceID": 15, "context": "K lOPOTEK significant influence variables are not omitted from observation), then there exists the possibility to identify the family of belief networks a causal network belongs to [16].", "startOffset": 181, "endOffset": 185}, {"referenceID": 14, "context": "Regrettably, to our knowledge, a similar result is not directly known for causally insufficient sets of variables (that is when significant influence variables are hidden) - \u201dStatistical indistinguishability is less well understood when graphs can contain variables representing unmeasured common causes\u201d ([15], p.", "startOffset": 306, "endOffset": 310}, {"referenceID": 7, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 5, "endOffset": 8}, {"referenceID": 6, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 10, "endOffset": 13}, {"referenceID": 1, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 15, "endOffset": 18}, {"referenceID": 9, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 41, "endOffset": 45}, {"referenceID": 13, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 47, "endOffset": 51}, {"referenceID": 14, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 53, "endOffset": 57}, {"referenceID": 3, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 59, "endOffset": 62}, {"referenceID": 4, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 64, "endOffset": 67}, {"referenceID": 12, "context": "[8], [6], [7], [2]) and causal networks ([10], [14], [15], [4], [5]), as well as in traditional statistics (see [13] for a comparative study of LISREL and EQS techniques).", "startOffset": 112, "endOffset": 116}, {"referenceID": 1, "context": "The algorithm of [2] recovers the most probable location of a hidden variable.", "startOffset": 17, "endOffset": 20}, {"referenceID": 14, "context": "Whereas the CI algorithm of [15] recovers exact locations of common causes, but clearly not all of them.", "startOffset": 28, "endOffset": 32}, {"referenceID": 14, "context": "2 Causal Inference Algorithm Below we remind the Causal Inference (CI) algorithm of Spirtes, Glymour and Scheines [15] together with some basic notation used therein.", "startOffset": 114, "endOffset": 118}, {"referenceID": 2, "context": "Now, when orienting edges according to CI-to-BN algorithm, we can make two types of errors:(a) introduce a path which is not active (in terminology of [3]) in BN, but is actually active in FHD, and (b) introduce a path which is active (in terminology of [3]) in BN, but is actually not active (blocked) in FHD.", "startOffset": 151, "endOffset": 154}, {"referenceID": 2, "context": "Now, when orienting edges according to CI-to-BN algorithm, we can make two types of errors:(a) introduce a path which is not active (in terminology of [3]) in BN, but is actually active in FHD, and (b) introduce a path which is active (in terminology of [3]) in BN, but is actually not active (blocked) in FHD.", "startOffset": 254, "endOffset": 257}, {"referenceID": 14, "context": "It relies essentially on exploitation of the result of the known CI algorithm of Spirtes, Glymour and Scheines [15].", "startOffset": 111, "endOffset": 115}, {"referenceID": 14, "context": "It will be interesting task to examine the possibility of such an adaptation of the Fast CI algorithm [15].", "startOffset": 102, "endOffset": 106}, {"referenceID": 14, "context": "It may not be trivial as the product of CI differs from that of FCI [15].", "startOffset": 68, "endOffset": 72}], "year": 2017, "abstractText": null, "creator": "dvips(k) 5.996 Copyright 2016 Radical Eye Software"}}}