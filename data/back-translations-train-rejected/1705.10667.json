{"id": "1705.10667", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-May-2017", "title": "Domain Adaptation with Randomized Multilinear Adversarial Networks", "abstract": "Adversarial learning has been successfully embedded into deep networks to learn transferable features for domain adaptation, which reduce distribution discrepancy between the source and target domains and improve generalization performance. Prior domain adversarial adaptation methods could not align complex multimode distributions since the discriminative structures and inter-layer interactions across multiple domain-specific layers have not been exploited for distribution alignment. In this paper, we present randomized multilinear adversarial networks (RMAN), which exploit multiple feature layers and the classifier layer based on a randomized multilinear adversary to enable both deep and discriminative adversarial adaptation. The learning can be performed by stochastic gradient descent with the gradients computed by back-propagation in linear-time. Experiments demonstrate that our models exceed the state-of-the-art results on standard domain adaptation datasets.", "histories": [["v1", "Fri, 26 May 2017 00:50:36 GMT  (1220kb,D)", "http://arxiv.org/abs/1705.10667v1", "arXiv admin note: text overlap witharXiv:1605.06636"]], "COMMENTS": "arXiv admin note: text overlap witharXiv:1605.06636", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mingsheng long", "zhangjie cao", "jianmin wang", "michael i jordan"], "accepted": false, "id": "1705.10667"}, "pdf": {"name": "1705.10667.pdf", "metadata": {"source": "CRF", "title": "Domain Adaptation with Randomized Multilinear Adversarial Networks", "authors": ["Mingsheng Long", "Zhangjie Cao", "Jianmin Wang", "Michael I. Jordan"], "emails": ["mingsheng@tsinghua.edu.cn,", "jimwang@tsinghua.edu.cn,", "caozhangjie14@gmail.com", "jordan@berkeley.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them will be able to abide by the rules that they have imposed on themselves, and they will be able to understand the rules that they have imposed on themselves."}, {"heading": "2 Related Work", "text": "Transfer Learning [29] generalizes a learner in different areas of different data distributions [37, 28, 8, 11, 41] who is widely used in computer vision [33, 14, 12, 17] and natural language processing [6, 10]. Deep networks learn abstract representations that unravel the explanatory factors of the variations behind the data [4] and extract transferable factors underlying different populations [10, 27] that can only reduce but not eliminate discrepancies between domains [40]. Recent work on deep domain adaptation embedded domain adaptation modules into deep networks to increase transfer performance [38, 9, 39, 22, 23]. These methods mainly reduce data shifts in marginal distributions. Adversary learning has been researched for generative modeling. Generative Adversarial Networks (GAN) [13] form two networks in a two-player game: one generator that distinguishes between the data distribution and the discriminator that generates."}, {"heading": "3 Randomized Multilinear Adversarial Networks", "text": "This year, it has come to the point where there is only one person who is able to move without being able to play by the rules."}, {"heading": "3.1 Randomized Multilinear Adversary", "text": "In fact, most of them are able to survive on their own if they do not play by the rules they have imposed on themselves."}, {"heading": "3.2 Randomized Multilinear Adversarial Networks", "text": "The properties in the lower layers are safely transferable and do not require adjustment of distribution [40]. To reduce the discrepancy in the common distributions L, we collectively minimize (1) the CNN error (1) with respect to the source network F (x), (2) minimize the error of the opponent (6) with respect to the domain discriminator D (z) and (3) maximize the error of the opponent (6) with respect to the source network F (x), (2) minimize the error of the opponent (6) with respect to the domain discriminator D (z) and (3) maximize the error of the opponent (6) with respect to the source network F (x). This results in the optimization problem for learning multilinear adversarial adversarial networks (RMAN): min F1ns with respect to i = 1 J (F (si) with respect to the source network F (i)."}, {"heading": "4 Experiments", "text": "We will evaluate the randomised multilinear adversary networks using various modern transfer learning and deep learning methods. The codes, data sets and configurations will be available online."}, {"heading": "4.1 Setup", "text": "[33] is a standard visual domain adaptation benchmark consisting of 4,652 images and 31 categories collected from three different domains: Amazon (A), which contains images downloaded from amazon.com, Webcam (W), and DSLR (D), each containing images taken from web cameras and digital SLR cameras in different environments. We evaluate all methods used across three transfer tasks. [22, 39, 23] ImageCLEF-DA1 is a benchmark dataset for ImageCLEF 2014 domain adaptation challenge, organized by selecting the 12 common categories shared by the following three public datasets, each considered as a domain: Caltech-256 (C), ImageNet ILSVRC 2012 (I), and Pascal VOC 2012."}, {"heading": "4.2 Results", "text": "The classification in the list of countries in which most of them live, in the category of countries in which most of them live, falls into the category of countries in which most of them live. In the category of countries in which most of them live, these are countries in which most of them live. In the category of countries in which most of them live, the countries in which most of them live are very different. In the category of countries in which most of them live, the countries in which most of them live are very different."}, {"heading": "4.3 Analysis", "text": "In fact, it is so that most of them are able to survive themselves if they do not see themselves able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. \"(...) Most of them are not able to survive themselves.\" (...)"}, {"heading": "5 Conclusion", "text": "Unlike previous hostile adaptation methods, which only correspond to the marginal distributions of traits across domains and may be trapped by the difficulty of multimode breakdown, the proposed approach further exploits the discriminatory structures to allow fine-grained distribution, and the discrepancy between the common distribution of trait layers and classification layer can be calculated by a new randomized multilinear adversary. Experiments confirmed the effectiveness of the proposed approach."}, {"heading": "6 Appendix: Proof of Theorem 1", "text": ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"}], "references": [{"title": "Towards principled methods for training generative adversarial networks", "author": ["M. Arjovsky", "L. Bottou"], "venue": "ICLR,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2017}, {"title": "Wasserstein gan", "author": ["M. Arjovsky", "S. Chintala", "L. Bottou"], "venue": "arXiv preprint arXiv:1701.07875,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2017}, {"title": "A theory of learning from different domains", "author": ["S. Ben-David", "J. Blitzer", "K. Crammer", "A. Kulesza", "F. Pereira", "J.W. Vaughan"], "venue": "Machine Learning, 79(1-2):151\u2013175,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Representation learning: A review and new perspectives", "author": ["Y. Bengio", "A. Courville", "P. Vincent"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 35(8):1798\u20131828,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Mode regularized generative adversarial networks", "author": ["T. Che", "Y. Li", "A.P. Jacob", "Y. Bengio", "W. Li"], "venue": "ICLR,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2017}, {"title": "Natural language processing (almost) from scratch", "author": ["R. Collobert", "J. Weston", "L. Bottou", "M. Karlen", "K. Kavukcuoglu", "P. Kuksa"], "venue": "Journal of Machine Learning Research (JMLR), 12:2493\u20132537,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Decaf: A deep convolutional activation feature for generic visual recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Domain transfer multiple kernel learning", "author": ["L. Duan", "I.W. Tsang", "D. Xu"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 34(3):465\u2013479,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Unsupervised domain adaptation by backpropagation", "author": ["Y. Ganin", "V. Lempitsky"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Domain adaptation for large-scale sentiment classification: A deep learning approach", "author": ["X. Glorot", "A. Bordes", "Y. Bengio"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Connecting the dots with landmarks: Discriminatively learning domaininvariant features for unsupervised domain adaptation", "author": ["B. Gong", "K. Grauman", "F. Sha"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Geodesic flow kernel for unsupervised domain adaptation", "author": ["B. Gong", "Y. Shi", "F. Sha", "K. Grauman"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Domain adaptation for object recognition: An unsupervised approach", "author": ["R. Gopalan", "R. Li", "R. Chellappa"], "venue": "IEEE International Conference on Computer Vision (ICCV),", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "A kernel two-sample test", "author": ["A. Gretton", "K. Borgwardt", "M. Rasch", "B. Sch\u00f6lkopf", "A. Smola"], "venue": "Journal of Machine Learning Research (JMLR), 13:723\u2013773,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "LSDA: Large scale detection through adaptation", "author": ["J. Hoffman", "S. Guadarrama", "E. Tzeng", "R. Hu", "J. Donahue", "R. Girshick", "T. Darrell", "K. Saenko"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Correcting sample selection bias by unlabeled data", "author": ["J. Huang", "A.J. Smola", "A. Gretton", "K.M. Borgwardt", "B. Sch\u00f6lkopf"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "MM,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Random feature maps for dot product kernels", "author": ["P. Kar", "H. Karnick"], "venue": "AISTATS, volume 22, pages 583\u2013591,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning transferable features with deep adaptation networks", "author": ["M. Long", "Y. Cao", "J. Wang", "M.I. Jordan"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Unsupervised domain adaptation with residual transfer networks", "author": ["M. Long", "H. Zhu", "J. Wang", "M.I. Jordan"], "venue": "Advances in Neural Information Processing Systems (NIPS), pages 136\u2013144,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2016}, {"title": "Domain adaptation: Learning bounds and algorithms", "author": ["Y. Mansour", "M. Mohri", "A. Rostamizadeh"], "venue": "Conference on Computational Learning Theory (COLT),", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "Unrolled generative adversarial networks", "author": ["L. Metz", "B. Poole", "D. Pfau", "J. Sohl-Dickstein"], "venue": "ICLR,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2017}, {"title": "Conditional generative adversarial nets", "author": ["M. Mirza", "S. Osindero"], "venue": "arXiv preprint arXiv:1411.1784,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning and transferring mid-level image representations using convolutional neural networks", "author": ["M. Oquab", "L. Bottou", "I. Laptev", "J. Sivic"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Domain adaptation via transfer component analysis", "author": ["S.J. Pan", "I.W. Tsang", "J.T. Kwok", "Q. Yang"], "venue": "IEEE Transactions on Neural Networks (TNN), 22(2):199\u2013210,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "IEEE Transactions on Knowledge and Data Engineering (TKDE), 22(10):1345\u20131359,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Dataset shift in machine learning", "author": ["J. Quionero-Candela", "M. Sugiyama", "A. Schwaighofer", "N.D. Lawrence"], "venue": "The MIT Press,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "Random features for large-scale kernel machines", "author": ["A. Rahimi", "B. Recht"], "venue": "Advances in neural information processing systems, pages 1177\u20131184,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2008}, {"title": "Adapting visual category models to new domains", "author": ["K. Saenko", "B. Kulis", "M. Fritz", "T. Darrell"], "venue": "European Conference on Computer Vision (ECCV),", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "Hilbert space embeddings of hidden markov models", "author": ["L. Song", "B. Boots", "S.M. Siddiqi", "G.J. Gordon", "A. Smola"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Robust low rank kernel embeddings of multivariate distributions", "author": ["L. Song", "B. Dai"], "venue": "Advances in Neural Information Processing Systems (NIPS), pages 3228\u20133236,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Hilbert space embeddings of conditional distributions with applications to dynamical systems", "author": ["L. Song", "J. Huang", "A. Smola", "K. Fukumizu"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2009}, {"title": "Direct importance estimation with model selection and its application to covariate shift adaptation", "author": ["M. Sugiyama", "S. Nakajima", "H. Kashima", "P.V. Buenau", "M. Kawanabe"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2008}, {"title": "Deep domain confusion: Maximizing for domain invariance", "author": ["E. Tzeng", "J. Hoffman", "N. Zhang", "K. Saenko", "T. Darrell"], "venue": "CoRR, abs/1412.3474,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2014}, {"title": "Simultaneous deep transfer across domains and tasks", "author": ["E. Tzeng", "J. Hoffman", "N. Zhang", "K. Saenko", "T. Darrell"], "venue": "IEEE International Conference on Computer Vision (ICCV),", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}, {"title": "How transferable are features in deep neural networks", "author": ["J. Yosinski", "J. Clune", "Y. Bengio", "H. Lipson"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2014}, {"title": "Domain adaptation under target and conditional shift", "author": ["K. Zhang", "B. Sch\u00f6lkopf", "K. Muandet", "Z. Wang"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "Cross validation framework to choose amongst models and datasets for transfer learning", "author": ["E. Zhong", "W. Fan", "Q. Yang", "O. Verscheure", "J. Ren"], "venue": "ECML/PKDD, pages 547\u2013562. Springer,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 29, "context": "However, this learning paradigm suffers from the shift in data distributions across different domains, which poses a major obstacle in adapting learning models for a target task [30, 29].", "startOffset": 178, "endOffset": 186}, {"referenceID": 28, "context": "However, this learning paradigm suffers from the shift in data distributions across different domains, which poses a major obstacle in adapting learning models for a target task [30, 29].", "startOffset": 178, "endOffset": 186}, {"referenceID": 28, "context": "Learning a discriminative model that reduces the dataset shift between training and test distributions is known as transfer learning or domain adaptation [29].", "startOffset": 154, "endOffset": 158}, {"referenceID": 17, "context": "Previous shallow transfer learning methods either bridge the source and target domains by learning invariant feature representations or estimating instance importance without using target labels [18, 28, 11].", "startOffset": 195, "endOffset": 207}, {"referenceID": 27, "context": "Previous shallow transfer learning methods either bridge the source and target domains by learning invariant feature representations or estimating instance importance without using target labels [18, 28, 11].", "startOffset": 195, "endOffset": 207}, {"referenceID": 10, "context": "Previous shallow transfer learning methods either bridge the source and target domains by learning invariant feature representations or estimating instance importance without using target labels [18, 28, 11].", "startOffset": 195, "endOffset": 207}, {"referenceID": 36, "context": "Recent deep transfer learning methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning, which can simultaneously disentangle the explanatory factors of variations behind data and match the marginal data distributions across domains [38, 22, 9, 39, 23].", "startOffset": 313, "endOffset": 332}, {"referenceID": 21, "context": "Recent deep transfer learning methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning, which can simultaneously disentangle the explanatory factors of variations behind data and match the marginal data distributions across domains [38, 22, 9, 39, 23].", "startOffset": 313, "endOffset": 332}, {"referenceID": 8, "context": "Recent deep transfer learning methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning, which can simultaneously disentangle the explanatory factors of variations behind data and match the marginal data distributions across domains [38, 22, 9, 39, 23].", "startOffset": 313, "endOffset": 332}, {"referenceID": 37, "context": "Recent deep transfer learning methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning, which can simultaneously disentangle the explanatory factors of variations behind data and match the marginal data distributions across domains [38, 22, 9, 39, 23].", "startOffset": 313, "endOffset": 332}, {"referenceID": 22, "context": "Recent deep transfer learning methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning, which can simultaneously disentangle the explanatory factors of variations behind data and match the marginal data distributions across domains [38, 22, 9, 39, 23].", "startOffset": 313, "endOffset": 332}, {"referenceID": 8, "context": "Adversarial adaptation methods [9, 39] are the top-performing architectures for domain adaptation.", "startOffset": 31, "endOffset": 38}, {"referenceID": 37, "context": "Adversarial adaptation methods [9, 39] are the top-performing architectures for domain adaptation.", "startOffset": 31, "endOffset": 38}, {"referenceID": 12, "context": "These methods work similarly as generative adversarial networks [13]: a domain discriminator is learned by minimizing the classification error of distinguishing the source from the target, while a deep network learns transferable representations which are indistinguishable by the domain discriminator.", "startOffset": 64, "endOffset": 68}, {"referenceID": 12, "context": "adversarial networks [13, 2].", "startOffset": 21, "endOffset": 28}, {"referenceID": 1, "context": "adversarial networks [13, 2].", "startOffset": 21, "endOffset": 28}, {"referenceID": 38, "context": "Second, the dataset shifts may linger in multiple domain-specific higher layers [40], and adversarial adaptation of a particular layer is not sufficient to close the domain shifts.", "startOffset": 80, "endOffset": 84}, {"referenceID": 8, "context": "This paper presents Randomized Multilinear Adversarial Networks (RMAN), which largely extends the ability of deep adversarial adaptation [9] to align the joint distributions of multiple domain-specific layers across domains for unsupervised domain adaptation.", "startOffset": 137, "endOffset": 140}, {"referenceID": 28, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 18, "endOffset": 22}, {"referenceID": 35, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 102, "endOffset": 121}, {"referenceID": 27, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 102, "endOffset": 121}, {"referenceID": 7, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 102, "endOffset": 121}, {"referenceID": 10, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 102, "endOffset": 121}, {"referenceID": 39, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 102, "endOffset": 121}, {"referenceID": 31, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 166, "endOffset": 182}, {"referenceID": 13, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 166, "endOffset": 182}, {"referenceID": 11, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 166, "endOffset": 182}, {"referenceID": 16, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 166, "endOffset": 182}, {"referenceID": 5, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 215, "endOffset": 222}, {"referenceID": 9, "context": "Transfer learning [29] generalizes a learner across different domains of different data distributions [37, 28, 8, 11, 41], which is widely applied in computer vision [33, 14, 12, 17] and natural language processing [6, 10].", "startOffset": 215, "endOffset": 222}, {"referenceID": 3, "context": "Deep networks learn abstract representations that disentangle the explanatory factors of variations behind data [4] and extract transferable factors underlying different populations [10, 27], which can only reduce, but not remove, the cross-domain discrepancy [40].", "startOffset": 112, "endOffset": 115}, {"referenceID": 9, "context": "Deep networks learn abstract representations that disentangle the explanatory factors of variations behind data [4] and extract transferable factors underlying different populations [10, 27], which can only reduce, but not remove, the cross-domain discrepancy [40].", "startOffset": 182, "endOffset": 190}, {"referenceID": 26, "context": "Deep networks learn abstract representations that disentangle the explanatory factors of variations behind data [4] and extract transferable factors underlying different populations [10, 27], which can only reduce, but not remove, the cross-domain discrepancy [40].", "startOffset": 182, "endOffset": 190}, {"referenceID": 38, "context": "Deep networks learn abstract representations that disentangle the explanatory factors of variations behind data [4] and extract transferable factors underlying different populations [10, 27], which can only reduce, but not remove, the cross-domain discrepancy [40].", "startOffset": 260, "endOffset": 264}, {"referenceID": 36, "context": "Recent work on deep domain adaptation embeds domain-adaptation modules into deep network to boost transfer performance [38, 9, 39, 22, 23].", "startOffset": 119, "endOffset": 138}, {"referenceID": 8, "context": "Recent work on deep domain adaptation embeds domain-adaptation modules into deep network to boost transfer performance [38, 9, 39, 22, 23].", "startOffset": 119, "endOffset": 138}, {"referenceID": 37, "context": "Recent work on deep domain adaptation embeds domain-adaptation modules into deep network to boost transfer performance [38, 9, 39, 22, 23].", "startOffset": 119, "endOffset": 138}, {"referenceID": 21, "context": "Recent work on deep domain adaptation embeds domain-adaptation modules into deep network to boost transfer performance [38, 9, 39, 22, 23].", "startOffset": 119, "endOffset": 138}, {"referenceID": 22, "context": "Recent work on deep domain adaptation embeds domain-adaptation modules into deep network to boost transfer performance [38, 9, 39, 22, 23].", "startOffset": 119, "endOffset": 138}, {"referenceID": 12, "context": "Generative Adversarial Networks (GAN) [13] constitute two networks in a two-player game: a generator that captures data distribution and a discriminator that distinguishes between generated samples and ground truth data.", "startOffset": 38, "endOffset": 42}, {"referenceID": 1, "context": "ease training [2, 1], avoid mode collapse [26, 5, 25].", "startOffset": 14, "endOffset": 20}, {"referenceID": 0, "context": "ease training [2, 1], avoid mode collapse [26, 5, 25].", "startOffset": 14, "endOffset": 20}, {"referenceID": 25, "context": "ease training [2, 1], avoid mode collapse [26, 5, 25].", "startOffset": 42, "endOffset": 53}, {"referenceID": 4, "context": "ease training [2, 1], avoid mode collapse [26, 5, 25].", "startOffset": 42, "endOffset": 53}, {"referenceID": 24, "context": "ease training [2, 1], avoid mode collapse [26, 5, 25].", "startOffset": 42, "endOffset": 53}, {"referenceID": 3, "context": "Deep networks [4] can learn more transferable representations than traditional hand-crafted features [27, 40].", "startOffset": 14, "endOffset": 17}, {"referenceID": 26, "context": "Deep networks [4] can learn more transferable representations than traditional hand-crafted features [27, 40].", "startOffset": 101, "endOffset": 109}, {"referenceID": 38, "context": "Deep networks [4] can learn more transferable representations than traditional hand-crafted features [27, 40].", "startOffset": 101, "endOffset": 109}, {"referenceID": 8, "context": "The favorable transferability of deep features leads to several state of the art deep transfer learning methods [9, 39, 22, 23].", "startOffset": 112, "endOffset": 127}, {"referenceID": 37, "context": "The favorable transferability of deep features leads to several state of the art deep transfer learning methods [9, 39, 22, 23].", "startOffset": 112, "endOffset": 127}, {"referenceID": 21, "context": "The favorable transferability of deep features leads to several state of the art deep transfer learning methods [9, 39, 22, 23].", "startOffset": 112, "endOffset": 127}, {"referenceID": 22, "context": "The favorable transferability of deep features leads to several state of the art deep transfer learning methods [9, 39, 22, 23].", "startOffset": 112, "endOffset": 127}, {"referenceID": 20, "context": "AlexNet [21] and ResNet [16], to novel randomized multilinear adversarial networks (RMANs) as shown in Figure 1.", "startOffset": 8, "endOffset": 12}, {"referenceID": 15, "context": "AlexNet [21] and ResNet [16], to novel randomized multilinear adversarial networks (RMANs) as shown in Figure 1.", "startOffset": 24, "endOffset": 28}, {"referenceID": 38, "context": "Based on the quantification study of feature transferability in deep convolutional networks [40], convolutional layers can learn generic features that are transferable across domains [40].", "startOffset": 92, "endOffset": 96}, {"referenceID": 38, "context": "Based on the quantification study of feature transferability in deep convolutional networks [40], convolutional layers can learn generic features that are transferable across domains [40].", "startOffset": 183, "endOffset": 187}, {"referenceID": 38, "context": "However, the literature findings also reveal that the deep features can reduce, but not remove, the cross-domain distribution discrepancy [40, 22, 23].", "startOffset": 138, "endOffset": 150}, {"referenceID": 21, "context": "However, the literature findings also reveal that the deep features can reduce, but not remove, the cross-domain distribution discrepancy [40, 22, 23].", "startOffset": 138, "endOffset": 150}, {"referenceID": 22, "context": "However, the literature findings also reveal that the deep features can reduce, but not remove, the cross-domain distribution discrepancy [40, 22, 23].", "startOffset": 138, "endOffset": 150}, {"referenceID": 38, "context": "The deep features in CNNs eventually transition from general to specific along the network, and the transferability of features and classifiers decreases when the cross-domain discrepancy increases [40].", "startOffset": 198, "endOffset": 202}, {"referenceID": 20, "context": "Taking AlexNet [21] as an example, the activations in the higher fully-connected layers L = {fc6, fc7, fc8} are not safely transferable for domain adaptation [40].", "startOffset": 15, "endOffset": 19}, {"referenceID": 38, "context": "Taking AlexNet [21] as an example, the activations in the higher fully-connected layers L = {fc6, fc7, fc8} are not safely transferable for domain adaptation [40].", "startOffset": 158, "endOffset": 162}, {"referenceID": 2, "context": "Many existing methods address transfer learning by bounding the target error with the source error plus a discrepancy between the marginal distributions P (X) and Q(X) of the source and target domains [3].", "startOffset": 201, "endOffset": 204}, {"referenceID": 14, "context": "A rich line of work is based on the Maximum Mean Discrepancy (MMD) [15], a kernel two-sample test statistic, which measures the discrepancy in marginal distributions P (X) andQ(X) [38, 22, 23].", "startOffset": 67, "endOffset": 71}, {"referenceID": 36, "context": "A rich line of work is based on the Maximum Mean Discrepancy (MMD) [15], a kernel two-sample test statistic, which measures the discrepancy in marginal distributions P (X) andQ(X) [38, 22, 23].", "startOffset": 180, "endOffset": 192}, {"referenceID": 21, "context": "A rich line of work is based on the Maximum Mean Discrepancy (MMD) [15], a kernel two-sample test statistic, which measures the discrepancy in marginal distributions P (X) andQ(X) [38, 22, 23].", "startOffset": 180, "endOffset": 192}, {"referenceID": 22, "context": "A rich line of work is based on the Maximum Mean Discrepancy (MMD) [15], a kernel two-sample test statistic, which measures the discrepancy in marginal distributions P (X) andQ(X) [38, 22, 23].", "startOffset": 180, "endOffset": 192}, {"referenceID": 12, "context": "Recently, motivated by the success of generative adversarial networks [13], domain adversarial adaptation has been proposed [9, 39] to measure the discrepancy in distributions P (X) and Q(X) by a domain discriminator.", "startOffset": 70, "endOffset": 74}, {"referenceID": 8, "context": "Recently, motivated by the success of generative adversarial networks [13], domain adversarial adaptation has been proposed [9, 39] to measure the discrepancy in distributions P (X) and Q(X) by a domain discriminator.", "startOffset": 124, "endOffset": 131}, {"referenceID": 37, "context": "Recently, motivated by the success of generative adversarial networks [13], domain adversarial adaptation has been proposed [9, 39] to measure the discrepancy in distributions P (X) and Q(X) by a domain discriminator.", "startOffset": 124, "endOffset": 131}, {"referenceID": 8, "context": "It has been shown by [9] that the the error functional of the domain discriminator is well corresponded to the distribution discrepancy used to bound the target risk in the theory of domain adaptation [3, 24].", "startOffset": 21, "endOffset": 24}, {"referenceID": 2, "context": "It has been shown by [9] that the the error functional of the domain discriminator is well corresponded to the distribution discrepancy used to bound the target risk in the theory of domain adaptation [3, 24].", "startOffset": 201, "endOffset": 208}, {"referenceID": 23, "context": "It has been shown by [9] that the the error functional of the domain discriminator is well corresponded to the distribution discrepancy used to bound the target risk in the theory of domain adaptation [3, 24].", "startOffset": 201, "endOffset": 208}, {"referenceID": 12, "context": "Mode collapse [13, 2] has been a well-known difficulty in adversarial learning, which says that when the distribution is multimode, there is the risk that different modes cannot be matched across domains.", "startOffset": 14, "endOffset": 21}, {"referenceID": 1, "context": "Mode collapse [13, 2] has been a well-known difficulty in adversarial learning, which says that when the distribution is multimode, there is the risk that different modes cannot be matched across domains.", "startOffset": 14, "endOffset": 21}, {"referenceID": 25, "context": ",Zt|L|) instead of the marginal distributions P (X) and Q(X), the discriminative information conveyed in the classifier layer Z|L| may reveal the multimode structure [26], which can further enable multimode adversarial adaptation.", "startOffset": 166, "endOffset": 170}, {"referenceID": 22, "context": "In this paper, we follow [23] and adopt the tensor product between activations of multiple layers L to perform lossless multilinear fusion, i.", "startOffset": 25, "endOffset": 29}, {"referenceID": 34, "context": "Tensor product of infinite-dimensional nonlinear feature maps has been successfully applied to embed joint/conditional distributions into reproducing kernel Hilbert spaces (RKHSs) [36, 34, 35] due to its great capability of capturing the full interactions between different sets of random variables.", "startOffset": 180, "endOffset": 192}, {"referenceID": 32, "context": "Tensor product of infinite-dimensional nonlinear feature maps has been successfully applied to embed joint/conditional distributions into reproducing kernel Hilbert spaces (RKHSs) [36, 34, 35] due to its great capability of capturing the full interactions between different sets of random variables.", "startOffset": 180, "endOffset": 192}, {"referenceID": 33, "context": "Tensor product of infinite-dimensional nonlinear feature maps has been successfully applied to embed joint/conditional distributions into reproducing kernel Hilbert spaces (RKHSs) [36, 34, 35] due to its great capability of capturing the full interactions between different sets of random variables.", "startOffset": 180, "endOffset": 192}, {"referenceID": 30, "context": "This paper addresses the dimension explosion of multilinear fusion by randomized methods [31, 20].", "startOffset": 89, "endOffset": 97}, {"referenceID": 19, "context": "This paper addresses the dimension explosion of multilinear fusion by randomized methods [31, 20].", "startOffset": 89, "endOffset": 97}, {"referenceID": 8, "context": "Following the idea of domain adversarial adaptation [9, 39], we train a domain discriminator network D to discriminate the joint distributions P (Z, .", "startOffset": 52, "endOffset": 59}, {"referenceID": 37, "context": "Following the idea of domain adversarial adaptation [9, 39], we train a domain discriminator network D to discriminate the joint distributions P (Z, .", "startOffset": 52, "endOffset": 59}, {"referenceID": 8, "context": "Remark: The randomized multilinear adversary (6) differs from previous domain adversarial adaptation methods [9, 39] based on ordinal adversary in that, for the activations Z in each layer ` \u2208 L, the randomized multilinear operation puts non-uniform weights reflecting the influence of other variables in other layers L\\`.", "startOffset": 109, "endOffset": 116}, {"referenceID": 37, "context": "Remark: The randomized multilinear adversary (6) differs from previous domain adversarial adaptation methods [9, 39] based on ordinal adversary in that, for the activations Z in each layer ` \u2208 L, the randomized multilinear operation puts non-uniform weights reflecting the influence of other variables in other layers L\\`.", "startOffset": 109, "endOffset": 116}, {"referenceID": 38, "context": "The features in lower layers are safely transferable and will not need distribution adaptation [40].", "startOffset": 95, "endOffset": 99}, {"referenceID": 8, "context": "Remark: The RMAN models improve existing domain adversarial adaptation methods [9, 39] by jointly adapting multiple layers (in particular, the classifier layer is jointly included for adaptation), which potentially circumvents the mode collapse difficulty during adversarial training by incorporating discriminative information to the adversary.", "startOffset": 79, "endOffset": 86}, {"referenceID": 37, "context": "Remark: The RMAN models improve existing domain adversarial adaptation methods [9, 39] by jointly adapting multiple layers (in particular, the classifier layer is jointly included for adaptation), which potentially circumvents the mode collapse difficulty during adversarial training by incorporating discriminative information to the adversary.", "startOffset": 79, "endOffset": 86}, {"referenceID": 21, "context": "The RMAN models also improve existing deep adaptation methods [22, 23] by randomized multilinear fusion of multiple domain-specific layers, which removes cumbersome layer-wise hyper-parameters in [22] and tackles dimension explosion difficulty in [23].", "startOffset": 62, "endOffset": 70}, {"referenceID": 22, "context": "The RMAN models also improve existing deep adaptation methods [22, 23] by randomized multilinear fusion of multiple domain-specific layers, which removes cumbersome layer-wise hyper-parameters in [22] and tackles dimension explosion difficulty in [23].", "startOffset": 62, "endOffset": 70}, {"referenceID": 21, "context": "The RMAN models also improve existing deep adaptation methods [22, 23] by randomized multilinear fusion of multiple domain-specific layers, which removes cumbersome layer-wise hyper-parameters in [22] and tackles dimension explosion difficulty in [23].", "startOffset": 196, "endOffset": 200}, {"referenceID": 22, "context": "The RMAN models also improve existing deep adaptation methods [22, 23] by randomized multilinear fusion of multiple domain-specific layers, which removes cumbersome layer-wise hyper-parameters in [22] and tackles dimension explosion difficulty in [23].", "startOffset": 247, "endOffset": 251}, {"referenceID": 31, "context": "Office-31 [33] is a standard benchmark for visual domain adaptation, comprising 4,652 images and 31 categories collected from three distinct domains: Amazon (A), which contains images downloaded from amazon.", "startOffset": 10, "endOffset": 14}, {"referenceID": 36, "context": "We evaluate all methods across three transfer tasks A\u2192W, D\u2192W and W\u2192D, which are widely used by previous deep transfer learning methods [38, 9], and another three transfer tasks A\u2192 D, D\u2192 A and W\u2192 A as used in [22, 39, 23].", "startOffset": 135, "endOffset": 142}, {"referenceID": 8, "context": "We evaluate all methods across three transfer tasks A\u2192W, D\u2192W and W\u2192D, which are widely used by previous deep transfer learning methods [38, 9], and another three transfer tasks A\u2192 D, D\u2192 A and W\u2192 A as used in [22, 39, 23].", "startOffset": 135, "endOffset": 142}, {"referenceID": 21, "context": "We evaluate all methods across three transfer tasks A\u2192W, D\u2192W and W\u2192D, which are widely used by previous deep transfer learning methods [38, 9], and another three transfer tasks A\u2192 D, D\u2192 A and W\u2192 A as used in [22, 39, 23].", "startOffset": 208, "endOffset": 220}, {"referenceID": 37, "context": "We evaluate all methods across three transfer tasks A\u2192W, D\u2192W and W\u2192D, which are widely used by previous deep transfer learning methods [38, 9], and another three transfer tasks A\u2192 D, D\u2192 A and W\u2192 A as used in [22, 39, 23].", "startOffset": 208, "endOffset": 220}, {"referenceID": 22, "context": "We evaluate all methods across three transfer tasks A\u2192W, D\u2192W and W\u2192D, which are widely used by previous deep transfer learning methods [38, 9], and another three transfer tasks A\u2192 D, D\u2192 A and W\u2192 A as used in [22, 39, 23].", "startOffset": 208, "endOffset": 220}, {"referenceID": 27, "context": "We compare the proposed randomized multilinear adversarial network (RMAN) with both shallow and deep transfer learning methods: Transfer Component Analysis (TCA) [28], Geodesic Flow Kernel (GFK) [12], Deep Domain Confusion (DDC) [38], Deep Adaptation Network (DAN) [22], Residual Transfer Network (RTN) [23], and Reverse Gradient (RevGrad) [9].", "startOffset": 162, "endOffset": 166}, {"referenceID": 11, "context": "We compare the proposed randomized multilinear adversarial network (RMAN) with both shallow and deep transfer learning methods: Transfer Component Analysis (TCA) [28], Geodesic Flow Kernel (GFK) [12], Deep Domain Confusion (DDC) [38], Deep Adaptation Network (DAN) [22], Residual Transfer Network (RTN) [23], and Reverse Gradient (RevGrad) [9].", "startOffset": 195, "endOffset": 199}, {"referenceID": 36, "context": "We compare the proposed randomized multilinear adversarial network (RMAN) with both shallow and deep transfer learning methods: Transfer Component Analysis (TCA) [28], Geodesic Flow Kernel (GFK) [12], Deep Domain Confusion (DDC) [38], Deep Adaptation Network (DAN) [22], Residual Transfer Network (RTN) [23], and Reverse Gradient (RevGrad) [9].", "startOffset": 229, "endOffset": 233}, {"referenceID": 21, "context": "We compare the proposed randomized multilinear adversarial network (RMAN) with both shallow and deep transfer learning methods: Transfer Component Analysis (TCA) [28], Geodesic Flow Kernel (GFK) [12], Deep Domain Confusion (DDC) [38], Deep Adaptation Network (DAN) [22], Residual Transfer Network (RTN) [23], and Reverse Gradient (RevGrad) [9].", "startOffset": 265, "endOffset": 269}, {"referenceID": 22, "context": "We compare the proposed randomized multilinear adversarial network (RMAN) with both shallow and deep transfer learning methods: Transfer Component Analysis (TCA) [28], Geodesic Flow Kernel (GFK) [12], Deep Domain Confusion (DDC) [38], Deep Adaptation Network (DAN) [22], Residual Transfer Network (RTN) [23], and Reverse Gradient (RevGrad) [9].", "startOffset": 303, "endOffset": 307}, {"referenceID": 8, "context": "We compare the proposed randomized multilinear adversarial network (RMAN) with both shallow and deep transfer learning methods: Transfer Component Analysis (TCA) [28], Geodesic Flow Kernel (GFK) [12], Deep Domain Confusion (DDC) [38], Deep Adaptation Network (DAN) [22], Residual Transfer Network (RTN) [23], and Reverse Gradient (RevGrad) [9].", "startOffset": 340, "endOffset": 343}, {"referenceID": 15, "context": "RTN jointly learns transferable features and adapts different source and target classifiers via deep residual learning [16].", "startOffset": 119, "endOffset": 123}, {"referenceID": 12, "context": "RevGrad enables domain adversarial learning [13] by adapting a single layer of deep networks, which matches the source and target domains by making them indistinguishable for a domain discriminator.", "startOffset": 44, "endOffset": 48}, {"referenceID": 21, "context": "We follow standard evaluation protocols for unsupervised domain adaptation [22, 9].", "startOffset": 75, "endOffset": 82}, {"referenceID": 8, "context": "We follow standard evaluation protocols for unsupervised domain adaptation [22, 9].", "startOffset": 75, "endOffset": 82}, {"referenceID": 40, "context": "For all baseline methods, we either follow their original model selection procedures, or conduct transfer cross-validation [42] if their model selection strategies are not specified.", "startOffset": 123, "endOffset": 127}, {"referenceID": 40, "context": "We also adopt transfer cross-validation [42] to select parameter \u03bb for the RMAN models.", "startOffset": 40, "endOffset": 44}, {"referenceID": 14, "context": "median trick [15, 22].", "startOffset": 13, "endOffset": 21}, {"referenceID": 21, "context": "median trick [15, 22].", "startOffset": 13, "endOffset": 21}, {"referenceID": 20, "context": "We examine the influence of deep representations for domain adaptation by exploring AlexNet [21] and ResNet [16] as base architectures for learning deep representations.", "startOffset": 92, "endOffset": 96}, {"referenceID": 15, "context": "We examine the influence of deep representations for domain adaptation by exploring AlexNet [21] and ResNet [16] as base architectures for learning deep representations.", "startOffset": 108, "endOffset": 112}, {"referenceID": 6, "context": "For shallow methods, we follow DeCAF [7] and use as deep representations the activations of the fc7 (AlexNet) and pool5 (ResNet) layers.", "startOffset": 37, "endOffset": 40}, {"referenceID": 18, "context": "We implement all deep methods based on the Caffe [19] framework, and fine-tune from AlexNet [21] and ResNet [16] models pre-trained on the ImageNet dataset [32].", "startOffset": 49, "endOffset": 53}, {"referenceID": 20, "context": "We implement all deep methods based on the Caffe [19] framework, and fine-tune from AlexNet [21] and ResNet [16] models pre-trained on the ImageNet dataset [32].", "startOffset": 92, "endOffset": 96}, {"referenceID": 15, "context": "We implement all deep methods based on the Caffe [19] framework, and fine-tune from AlexNet [21] and ResNet [16] models pre-trained on the ImageNet dataset [32].", "startOffset": 108, "endOffset": 112}, {"referenceID": 8, "context": "9 and the learning rate strategy implemented in RevGrad [9]: the learning rate is not selected by a grid search due to high computational cost\u2014it is adjusted during SGD using these formulas: \u03b7p = \u03b70 (1+\u03b1p) , where p is the training progress linearly changing from 0 to 1, \u03b70 = 0.", "startOffset": 56, "endOffset": 59}, {"referenceID": 8, "context": "To suppress noisy activations at the early stages of training, instead of fixing parameter \u03bb, we gradually change it by multiplying 2 1+exp(\u2212\u03b4p) \u2212 1, where \u03b4 = 10 [9].", "startOffset": 163, "endOffset": 166}, {"referenceID": 20, "context": "Table 1: Accuracy (%) on Office-31 for unsupervised domain adaptation (AlexNet and ResNet) Method A\u2192W D\u2192W W\u2192 D A\u2192 D D\u2192 A W\u2192 A Avg AlexNet [21] 60.", "startOffset": 138, "endOffset": 142}, {"referenceID": 27, "context": "8 TCA [28] 59.", "startOffset": 6, "endOffset": 10}, {"referenceID": 11, "context": "8 GFK [12] 58.", "startOffset": 6, "endOffset": 10}, {"referenceID": 36, "context": "7 DDC [38] 61.", "startOffset": 6, "endOffset": 10}, {"referenceID": 21, "context": "3 DAN [22] 68.", "startOffset": 6, "endOffset": 10}, {"referenceID": 22, "context": "7 RTN [23] 73.", "startOffset": 6, "endOffset": 10}, {"referenceID": 8, "context": "7 RevGrad [9] 73.", "startOffset": 10, "endOffset": 13}, {"referenceID": 15, "context": "0 ResNet [16] 68.", "startOffset": 9, "endOffset": 13}, {"referenceID": 27, "context": "1 TCA [28] 74.", "startOffset": 6, "endOffset": 10}, {"referenceID": 11, "context": "3 GFK [12] 74.", "startOffset": 6, "endOffset": 10}, {"referenceID": 36, "context": "8 DDC [38] 75.", "startOffset": 6, "endOffset": 10}, {"referenceID": 21, "context": "7 DAN [22] 83.", "startOffset": 6, "endOffset": 10}, {"referenceID": 22, "context": "3 RTN [23] 84.", "startOffset": 6, "endOffset": 10}, {"referenceID": 8, "context": "6 RevGrad [9] 82.", "startOffset": 10, "endOffset": 13}, {"referenceID": 21, "context": "For fair comparison, the results of DAN [22], RTN [23], and RevGrad [9] are directly reported from their original papers.", "startOffset": 40, "endOffset": 44}, {"referenceID": 22, "context": "For fair comparison, the results of DAN [22], RTN [23], and RevGrad [9] are directly reported from their original papers.", "startOffset": 50, "endOffset": 54}, {"referenceID": 8, "context": "For fair comparison, the results of DAN [22], RTN [23], and RevGrad [9] are directly reported from their original papers.", "startOffset": 68, "endOffset": 71}, {"referenceID": 20, "context": "Table 2: Accuracy (%) on ImageCLEF-DA for unsupervised domain adaptation (AlexNet and ResNet) Method I\u2192 P P\u2192 I I\u2192 C C\u2192 I C\u2192 P P\u2192 C Avg AlexNet [21] 66.", "startOffset": 143, "endOffset": 147}, {"referenceID": 21, "context": "9 DAN [22] 67.", "startOffset": 6, "endOffset": 10}, {"referenceID": 22, "context": "9 RTN [23] 67.", "startOffset": 6, "endOffset": 10}, {"referenceID": 8, "context": "4 RevGrad [9] 66.", "startOffset": 10, "endOffset": 13}, {"referenceID": 15, "context": "4 ResNet [16] 74.", "startOffset": 9, "endOffset": 13}, {"referenceID": 21, "context": "7 DAN [22] 75.", "startOffset": 6, "endOffset": 10}, {"referenceID": 22, "context": "3 RTN [23] 75.", "startOffset": 6, "endOffset": 10}, {"referenceID": 8, "context": "9 RevGrad [9] 75.", "startOffset": 10, "endOffset": 13}, {"referenceID": 31, "context": "and target domains are substantially different, and produce comparable classification accuracies on easy transfer tasks, D\u2192W and W\u2192 D, where the source and target domains are similar [33].", "startOffset": 183, "endOffset": 187}, {"referenceID": 38, "context": "This confirms the current practice that deep networks, even the extremely deep ones (ResNet), can learn abstract feature representations that only reduce but not remove the cross-domain discrepancy [40].", "startOffset": 198, "endOffset": 202}, {"referenceID": 21, "context": "Although both RMAN and DAN [22] adapt multiple domain-specific layers, the improvement from DAN to RMAN is crucial for domain adaptation: DAN imposes multiple MMD penalties, each independently reducing the distribution shift in a single layer; RMAN enables domain adaptation by making the source and target domains indistinguishable for a domain discriminator under the randomized multilinear fusion of deep features and classifier predictions in multiple layers, which can essentially reduce the dataset shift in the joint distributions of multiple task-specific layers.", "startOffset": 27, "endOffset": 31}, {"referenceID": 6, "context": "using t-SNE embeddings [7].", "startOffset": 23, "endOffset": 26}, {"referenceID": 2, "context": "Distribution Discrepancy: The domain adaptation theory [3, 24] suggests A-distance as a measure of cross-domain discrepancy, which, together with the source risk, will bound the target risk.", "startOffset": 55, "endOffset": 62}, {"referenceID": 23, "context": "Distribution Discrepancy: The domain adaptation theory [3, 24] suggests A-distance as a measure of cross-domain discrepancy, which, together with the source risk, will bound the target risk.", "startOffset": 55, "endOffset": 62}], "year": 2017, "abstractText": "Adversarial learning has been successfully embedded into deep networks to learn transferable features for domain adaptation, which reduce distribution discrepancy between the source and target domains and improve generalization performance. Prior domain adversarial adaptation methods could not align complex multimode distributions since the discriminative structures and inter-layer interactions across multiple domain-specific layers have not been exploited for distribution alignment. In this paper, we present randomized multilinear adversarial networks (RMAN), which exploit multiple feature layers and the classifier layer based on a randomized multilinear adversary to enable both deep and discriminative adversarial adaptation. The learning can be performed by stochastic gradient descent with the gradients computed by back-propagation in linear-time. Experiments demonstrate that our models exceed the state-of-the-art results on standard domain adaptation datasets.", "creator": "LaTeX with hyperref package"}}}