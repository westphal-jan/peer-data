{"id": "1705.10898", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-May-2017", "title": "Towards Learned Clauses Database Reduction Strategies Based on Dominance Relationship", "abstract": "Clause Learning is one of the most important components of a conflict driven clause learning (CDCL) SAT solver that is effective on industrial instances. Since the number of learned clauses is proved to be exponential in the worse case, it is necessary to identify the most relevant clauses to maintain and delete the irrelevant ones. As reported in the literature, several learned clauses deletion strategies have been proposed. However the diversity in both the number of clauses to be removed at each step of reduction and the results obtained with each strategy creates confusion to determine which criterion is better. Thus, the problem to select which learned clauses are to be removed during the search step remains very challenging. In this paper, we propose a novel approach to identify the most relevant learned clauses without favoring or excluding any of the proposed measures, but by adopting the notion of dominance relationship among those measures. Our approach bypasses the problem of the diversity of results and reaches a compromise between the assessments of these measures. Furthermore, the proposed approach also avoids another non-trivial problem which is the amount of clauses to be deleted at each reduction of the learned clause database.", "histories": [["v1", "Wed, 31 May 2017 00:05:26 GMT  (369kb)", "http://arxiv.org/abs/1705.10898v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jerry lonlac", "engelbert mephu nguifo"], "accepted": false, "id": "1705.10898"}, "pdf": {"name": "1705.10898.pdf", "metadata": {"source": "CRF", "title": "Towards Learned Clauses Database Reduction Strategies Based on Dominance Relationship", "authors": ["Jerry Lonlac", "Engelbert Mephu Nguifo"], "emails": ["nguifo}@uca.fr"], "sections": [{"heading": null, "text": "ar Xiv: 170 5.10 898v 1 [cs.A I] 3 1M ay"}, {"heading": "1 Introduction", "text": "It is only a matter of time before it will happen, until it will happen."}, {"heading": "2 On the learned clauses database management strategies", "text": "This year it has come to the point where it is a reactionary, reactionary and reactionary party that is able to complain, that it is able to complain, that it is able to complain, that it is able to put itself at the top."}, {"heading": "3 Detecting undominated learned Clauses", "text": "We now present our learned clauses, which are based on a dominant relationship. We first motivate this approach with a simple example and then propose an algorithm that makes it possible to identify the relevant clauses with some technical details."}, {"heading": "3.1 Motivating example", "text": "Let us consider the following relevant strategies: LBD [2], SIZE (which consider the short size clause relevant) and the relevant use of measures by minisat [11], which we here refer to as CVSIDS. Let us assume that in the database of scholarly clauses we include clauses c1, c2 and c3 with: - SIZE (c1) = 8, LBD (c1) = 3, CV SIDS (c1) = 1e 100; - SIZE (c2) = 6, LBD (c2) = 5, CV SIDS (c2) = 1e 200; - SIZE (c3) = 5, LBD (c3) = 4, CV SIDS (c3) = 1e 300. The question we ask is this: Which is relevant? In [2] the authors consider clause c1, which has the least LBD measure relevant as a preference for the author, as opposed to the 11."}, {"heading": "3.2 Formalization", "text": "During the search for the solution of the problem, we learn a set of clauses stored in the learned clauses that are defined in the relevant measures. (\"It\") \"(\" It \")\" (\"It\") \"(\" It \")\" (\"It\") \"(\" It \")\" (\"It\") \"(\" It \")\" (\"It\") \"(\" It \")\" (\"It\") \"(\" It \")\" (\"It\") \"(\" It \")\" (\")\" (\")\" (\")\" (\")\" (\")\" (\") (\") (\") (\") (\") (\") (\") (\" (\") (\") (\") (\" (\") (\") (\"(\") (\") (\" (\") (\") (\"(\") (\")"}, {"heading": "3.3 Algorithm", "text": "In this section, we propose an algorithm that makes it possible to discover relevant learned clauses by using dominance relationships. Algorithm 1 describes the general scheme of a learned clauses deletion strategy (reduceDB), which first sorts the set of learned clauses according to the defined criterion and then deletes half of the learned clauses. In fact, this algorithm takes a learned clauses database of size n and gives a learned clauses database of size n / 2. This algorithm differs from our approach, which first searches the learned clause with the lowest degree of compromise (referred to as the reference clause) and then removes all learned clauses it dominates. Algorithm 2 represents our learned clauses solution strategy. It is important to note that the clauses whose size (number of literals) and the LBD clause are considered less equivalent, not considered to be taught."}, {"heading": "4 Experiments", "text": "For our experiments, we use three relevant metrics for the dominance relationship to assess the efficiency of our approach. Note that the user can combine several other metrics. We use SIZE [12], LBD [2], and CV SIDS [11] metrics, all of which have been proven effective in the literature [11, 2, 15]. It is possible to apply more relevant metrics, but it should be noted that by adding a metric to M, the number of relevant clauses learned can be reduced or increased. The decrease can be explained by the fact that one learned clause can be dominant in relation to \u2032 a set of metrics M \u2032 and can be undominated in relation to M \u2032, such as when two learned clauses c and c \u2032 are undominated in relation to M, there is the possibility that one of them dominates the other by dominating a metric M \u2032 and the increase can be explained by the fact that the increase can be explained by a clause learned in relation to M."}, {"heading": "4.1 Number of solved instances and CPU time", "text": "This year it is more than ever before in the history of the city."}, {"heading": "4.2 Common solved instances", "text": "In Table 4, the overlap between two relevant metrics indicates the number of common instances solved by each metric. For example, LBD and SIZE solved 219 cases together, while 234 cases are solved by LBD and DegComp. To get more details, Table 5 indicates the number of instances solved jointly with each of the aggregated metrics. Specifically, the number of common instances solved with one, two, three, or four metrics is less than the number of common instances solved with our approach. To get more details, Table 5 indicates the number of instances solved jointly by the relevant metrics considered. In this table, we can find that 1, 1, 5, and 5 are the number of cases solved by LBD or CV SIDS, SIZE, and DegDS alone, while 44 cases are not solved by any of them."}, {"heading": "4.3 Combined measures", "text": "Table 6 shows the number of cases solved with our dominance approach and the measurements used in the dominance relationship. This table shows that the number of cases solved with two (instead of three) measurements in the dominance relationship is always lower than the number of cases solved with three measurements (248)."}, {"heading": "4.4 Percentage of deleted clauses", "text": "Throughout the life of the nuclear power stations, the number of nuclear power stations operating in the last five years is many times higher than the number of nuclear power stations operating in the same period."}, {"heading": "5 Conclusion and Future Works", "text": "We have shown that the idea of the dominance relationship between relevant metrics is a good way to benefit from each metric, and this approach is not hampered by the plethora of relevant metrics that have been the subject of several papers. The proposed approach avoids another non-trivial problem, namely the number of learned metrics that need to be deleted at each step of the learned metrics. Experimental results show that the utilization of the dominance relationship improves the performance of the CDCL-SAT solver, at least on the SAT-RACE 2015. In the case of the SAT competition, we still need to find a good dominance relationship. Also, the instance categories could be an issue to be explored.To our knowledge, this is the first time that dominance relationships are used in the area of satisfaction to improve the performance of a CDCL-SAT solver."}, {"heading": "Acknowledgements", "text": "The authors would like to thank the Auvergne-Rho-Alpes region and the European Union for their financial support through the European Regional Development Fund (ERDF), CRIL (Lens Computer Science Research Lab) for providing the computer server and the authors of Glucose Solver for providing the source code of their solver."}], "references": [{"title": "Using community structure to detect relevant learnt clauses", "author": ["Carlos Ans\u00f3tegui", "Jes\u00fas Gir\u00e1ldez-Cru", "Jordi Levy", "Laurent Simon"], "venue": "SAT", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Predicting learnt clauses quality in modern sat solvers", "author": ["G. Audemard", "L. Simon"], "venue": "In IJCAI\u201909,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "On freezing and reactivating learnt clauses", "author": ["Gilles Audemard", "Jean-Marie Lagniez", "Bertrand Mazure", "Lakhdar Sais"], "venue": "In SAT\u20192011,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "A complexity analysis of spacebounded learning algorithms for the constraint satisfaction problem", "author": ["Roberto J. Bayardo", "Daniel P. Miranker"], "venue": "Proceedings of the Thirteenth National Conference on Artificial Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1996}, {"title": "Using CSP look-back techniques to solve real-world SAT instances", "author": ["Roberto J. Bayardo", "Jr.", "Robert C. Schrag"], "venue": "In AAAI,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1997}, {"title": "Lingeling and friends entering the sat challenge", "author": ["A. Biere"], "venue": "Proceedings of SAT Challenge 2012: Solver and Benchmark Descriptions,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "The skyline operator", "author": ["Stephan B\u00f6rzs\u00f6nyi", "Donald Kossmann", "Konrad Stocker"], "venue": "In Proceedings of the 17th International Conference on Data Engineering, April", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2001}, {"title": "Mining undominated association rules through interestingness measures", "author": ["Slim Bouker", "Rabie Saidi", "Sadok Ben Yahia", "Engelbert Mephu Nguifo"], "venue": "International Journal on Artificial Intelligence Tools,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "A machine program for theorem-proving", "author": ["Martin Davis", "Gearge Logemann", "Donald W. Loveland"], "venue": "Communications of the ACM,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1962}, {"title": "Effective preprocessing in sat through variable and clause elimination", "author": ["Niklas E\u00e9n", "Armin Biere"], "venue": "In SAT\u201905,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "An extensible sat-solver", "author": ["Niklas E\u00e9n", "Niklas S\u00f6rensson"], "venue": "SAT", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "Berkmin: A fast and robust sat-solver", "author": ["Eugene Goldberg", "Yakov Novikov"], "venue": "Discrete Applied Mathematics,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Boosting combinatorial search through randomization", "author": ["Carla P. Gomes", "Bart Selman", "Henry A. Kautz"], "venue": "In AAAI/IAAI,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Diversification by clauses deletion strategies in portfolio parallel SAT solving", "author": ["Long Guo", "S\u00e4\u0131d Jabbour", "Jerry Lonlac", "Lakhdar Sais"], "venue": "ICTAI", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Revisiting the learned clauses database reduction strategies", "author": ["S\u00e4\u0131d Jabbour", "Jerry Lonlac", "Lakhdar Sais", "Yakoub Salhi"], "venue": "CoRR, abs/1402.1956,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Empirical study of the anatomy of modern sat solvers", "author": ["Hadi Katebi", "Karem A. Sakallah", "Jo\u00e3o P. Marques Silva"], "venue": "SAT", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Chaff: Engineering an efficient sat solver", "author": ["Matthew W. Moskewicz", "Conor F. Madigan", "Ying Zhao", "Lintao Zhang", "Sharad Malik"], "venue": "In 38th Design Automation Conference", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2001}, {"title": "On the power of clause-learning sat solvers with restarts", "author": ["Knot Pipatsrisawat", "Adnan Darwiche"], "venue": "In (CP\u201909),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Grasp - a new search algorithm for satisfiability", "author": ["Jo\u00e3o P. Marques Silva", "Karem A. Sakallah"], "venue": "In International Conference on Computer-Aided Design (ICCAD\u201996),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1996}, {"title": "GRASP: A search algorithm for propositional satisfiability", "author": ["Jo\u00e3o P. Marques Silva", "Karem A. Sakallah"], "venue": "IEEE Trans. Computers,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1999}, {"title": "Mining dominant patterns in the sky", "author": ["Arnaud Soulet", "Chedy R\u00e4\u0131ssi", "Marc Plantevit", "Bruno Cr\u00e9milleux"], "venue": "ICDM", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "No free lunch theorems for optimization", "author": ["David Wolpert", "William G. Macready"], "venue": "IEEE Trans. Evolutionary Computation,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1997}], "referenceMentions": [{"referenceID": 16, "context": "These solvers, often called modern SAT solvers [17, 11] or CDCL (Conflict Driven Clause Learning) SAT solvers have been shown to be very efficient at solving real-world SAT instances.", "startOffset": 47, "endOffset": 55}, {"referenceID": 10, "context": "These solvers, often called modern SAT solvers [17, 11] or CDCL (Conflict Driven Clause Learning) SAT solvers have been shown to be very efficient at solving real-world SAT instances.", "startOffset": 47, "endOffset": 55}, {"referenceID": 8, "context": "They are built by integrating four major components to the classical (DPLL) procedure [9]: lazy data structures [17], activity-based variable selection heuristics (VSIDS-like) [17], restart policies [13], and clause learning [20, 17].", "startOffset": 86, "endOffset": 89}, {"referenceID": 16, "context": "They are built by integrating four major components to the classical (DPLL) procedure [9]: lazy data structures [17], activity-based variable selection heuristics (VSIDS-like) [17], restart policies [13], and clause learning [20, 17].", "startOffset": 112, "endOffset": 116}, {"referenceID": 16, "context": "They are built by integrating four major components to the classical (DPLL) procedure [9]: lazy data structures [17], activity-based variable selection heuristics (VSIDS-like) [17], restart policies [13], and clause learning [20, 17].", "startOffset": 176, "endOffset": 180}, {"referenceID": 12, "context": "They are built by integrating four major components to the classical (DPLL) procedure [9]: lazy data structures [17], activity-based variable selection heuristics (VSIDS-like) [17], restart policies [13], and clause learning [20, 17].", "startOffset": 199, "endOffset": 203}, {"referenceID": 19, "context": "They are built by integrating four major components to the classical (DPLL) procedure [9]: lazy data structures [17], activity-based variable selection heuristics (VSIDS-like) [17], restart policies [13], and clause learning [20, 17].", "startOffset": 225, "endOffset": 233}, {"referenceID": 16, "context": "They are built by integrating four major components to the classical (DPLL) procedure [9]: lazy data structures [17], activity-based variable selection heuristics (VSIDS-like) [17], restart policies [13], and clause learning [20, 17].", "startOffset": 225, "endOffset": 233}, {"referenceID": 15, "context": "Although a nice combination of these components contributes to improve the efficiency of modern SAT solvers [16], clause learning is known as the most important component [18].", "startOffset": 108, "endOffset": 112}, {"referenceID": 17, "context": "Although a nice combination of these components contributes to improve the efficiency of modern SAT solvers [16], clause learning is known as the most important component [18].", "startOffset": 171, "endOffset": 175}, {"referenceID": 18, "context": "Clause learning, also known in the literature as Conflict Driven Clause Learning (CDCL), refers now to the most known and used First (UIP) learning scheme, first integrated in the SAT solver Grasp [19] and efficiently implemented in zChaff [17].", "startOffset": 197, "endOffset": 201}, {"referenceID": 16, "context": "Clause learning, also known in the literature as Conflict Driven Clause Learning (CDCL), refers now to the most known and used First (UIP) learning scheme, first integrated in the SAT solver Grasp [19] and efficiently implemented in zChaff [17].", "startOffset": 240, "endOffset": 244}, {"referenceID": 16, "context": "Managing the learned clauses database was the subject of several studies [17, 19, 11, 2, 3, 14].", "startOffset": 73, "endOffset": 95}, {"referenceID": 18, "context": "Managing the learned clauses database was the subject of several studies [17, 19, 11, 2, 3, 14].", "startOffset": 73, "endOffset": 95}, {"referenceID": 10, "context": "Managing the learned clauses database was the subject of several studies [17, 19, 11, 2, 3, 14].", "startOffset": 73, "endOffset": 95}, {"referenceID": 1, "context": "Managing the learned clauses database was the subject of several studies [17, 19, 11, 2, 3, 14].", "startOffset": 73, "endOffset": 95}, {"referenceID": 2, "context": "Managing the learned clauses database was the subject of several studies [17, 19, 11, 2, 3, 14].", "startOffset": 73, "endOffset": 95}, {"referenceID": 13, "context": "Managing the learned clauses database was the subject of several studies [17, 19, 11, 2, 3, 14].", "startOffset": 73, "endOffset": 95}, {"referenceID": 6, "context": "To this end, we integrate into the SAT process the idea of skyline queries [7], dominant patterns [21], undominated association rules [8] in order to learn clauses in a threshold-free manner.", "startOffset": 75, "endOffset": 78}, {"referenceID": 20, "context": "To this end, we integrate into the SAT process the idea of skyline queries [7], dominant patterns [21], undominated association rules [8] in order to learn clauses in a threshold-free manner.", "startOffset": 98, "endOffset": 102}, {"referenceID": 7, "context": "To this end, we integrate into the SAT process the idea of skyline queries [7], dominant patterns [21], undominated association rules [8] in order to learn clauses in a threshold-free manner.", "startOffset": 134, "endOffset": 137}, {"referenceID": 10, "context": "The most popular CDCL SAT solver Minisat [11] considers as relevant the clauses the most involved in recent conflict analysis and removes the learned clauses whose involvement in recent conflict analysis is marginal.", "startOffset": 41, "endOffset": 45}, {"referenceID": 1, "context": "Another strategy called LBD for Literal Block Distance was proposed in [2].", "startOffset": 71, "endOffset": 74}, {"referenceID": 5, "context": "LBD based measure is also exploited by most of the best state-of-the-art SAT solver (Glucose, Lingeling [6]) and whose efficiency has been proved empirically.", "startOffset": 104, "endOffset": 107}, {"referenceID": 2, "context": "In [3], a new dynamic management policy of the learned clauses database is proposed.", "startOffset": 3, "endOffset": 6}, {"referenceID": 13, "context": "In [14], a new criterion to quantify the relevance of a clause using its backtrack level called BTL for BackTrack Level was proposed.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "More recently, several other learned clauses database strategies were proposed in [15, 1].", "startOffset": 82, "endOffset": 89}, {"referenceID": 0, "context": "More recently, several other learned clauses database strategies were proposed in [15, 1].", "startOffset": 82, "endOffset": 89}, {"referenceID": 14, "context": "In [15], the authors explore a number of variations of learned clause database reduction strategies, and the performance of the different extensions of Minisat solver integrating their strategies is evaluated on the instances of the SAT competitions 2013/2014 and compared against other state-of-the-art SAT solvers (Glucose, Lingeling) as well as against default Minisat.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "From the performances obtained in [15], the authors have shown that size-bounded learning strategies proposed more than fifteenth years ago [19, 4, 5] is not over and remains a good measure to predict the quality of learned clauses.", "startOffset": 34, "endOffset": 38}, {"referenceID": 18, "context": "From the performances obtained in [15], the authors have shown that size-bounded learning strategies proposed more than fifteenth years ago [19, 4, 5] is not over and remains a good measure to predict the quality of learned clauses.", "startOffset": 140, "endOffset": 150}, {"referenceID": 3, "context": "From the performances obtained in [15], the authors have shown that size-bounded learning strategies proposed more than fifteenth years ago [19, 4, 5] is not over and remains a good measure to predict the quality of learned clauses.", "startOffset": 140, "endOffset": 150}, {"referenceID": 4, "context": "From the performances obtained in [15], the authors have shown that size-bounded learning strategies proposed more than fifteenth years ago [19, 4, 5] is not over and remains a good measure to predict the quality of learned clauses.", "startOffset": 140, "endOffset": 150}, {"referenceID": 10, "context": "This study opens many discussions about the learned clauses database strategies and raises questions about the effectiveness proclaimed by other strategies of the state-of-the-art [11, 2].", "startOffset": 180, "endOffset": 187}, {"referenceID": 1, "context": "This study opens many discussions about the learned clauses database strategies and raises questions about the effectiveness proclaimed by other strategies of the state-of-the-art [11, 2].", "startOffset": 180, "endOffset": 187}, {"referenceID": 0, "context": "In [1], the authors use the com-", "startOffset": 3, "endOffset": 6}, {"referenceID": 10, "context": "For example, the CDCL SAT solver Minisat [11] and Glucose [2] delete half of the learned clauses at each cleaning.", "startOffset": 41, "endOffset": 45}, {"referenceID": 1, "context": "For example, the CDCL SAT solver Minisat [11] and Glucose [2] delete half of the learned clauses at each cleaning.", "startOffset": 58, "endOffset": 61}, {"referenceID": 1, "context": "Let us consider the following relevant strategies: LBD [2], SIZE (which consider as relevant the clause of the short size) and the relevant measure use by minisat [11] that we denote here CVSIDS.", "startOffset": 55, "endOffset": 58}, {"referenceID": 10, "context": "Let us consider the following relevant strategies: LBD [2], SIZE (which consider as relevant the clause of the short size) and the relevant measure use by minisat [11] that we denote here CVSIDS.", "startOffset": 163, "endOffset": 167}, {"referenceID": 1, "context": "The question we ask is the following: which one is relevant? In [2], the authors consider the clause c1 which has the most smallest LBD measure as the most", "startOffset": 64, "endOffset": 67}, {"referenceID": 14, "context": "In contrast, the authors of [15] and [12] prefer the clause c3 while the preference of the authors of Minisat [11] leads to the clause c3.", "startOffset": 28, "endOffset": 32}, {"referenceID": 11, "context": "In contrast, the authors of [15] and [12] prefer the clause c3 while the preference of the authors of Minisat [11] leads to the clause c3.", "startOffset": 37, "endOffset": 41}, {"referenceID": 10, "context": "In contrast, the authors of [15] and [12] prefer the clause c3 while the preference of the authors of Minisat [11] leads to the clause c3.", "startOffset": 110, "endOffset": 114}, {"referenceID": 10, "context": "For example the values of the learned clauses relevant measures in [11] are very high, in exponential order while the values of the relevant measures in [2] are smallest ones.", "startOffset": 67, "endOffset": 71}, {"referenceID": 1, "context": "For example the values of the learned clauses relevant measures in [11] are very high, in exponential order while the values of the relevant measures in [2] are smallest ones.", "startOffset": 153, "endOffset": 156}, {"referenceID": 0, "context": "In our case here, we choose to normalize all the measures in the interval [0, 1].", "startOffset": 74, "endOffset": 80}, {"referenceID": 0, "context": "clause c must be normalized into m\u0302(c) within [0, 1].", "startOffset": 46, "endOffset": 52}, {"referenceID": 11, "context": "We use SIZE [12], LBD [2] and CV SIDS [11] measures.", "startOffset": 12, "endOffset": 16}, {"referenceID": 1, "context": "We use SIZE [12], LBD [2] and CV SIDS [11] measures.", "startOffset": 22, "endOffset": 25}, {"referenceID": 10, "context": "We use SIZE [12], LBD [2] and CV SIDS [11] measures.", "startOffset": 38, "endOffset": 42}, {"referenceID": 10, "context": "All these measures have been proved effective in the literature [11, 2, 15].", "startOffset": 64, "endOffset": 75}, {"referenceID": 1, "context": "All these measures have been proved effective in the literature [11, 2, 15].", "startOffset": 64, "endOffset": 75}, {"referenceID": 14, "context": "All these measures have been proved effective in the literature [11, 2, 15].", "startOffset": 64, "endOffset": 75}, {"referenceID": 9, "context": "All the instances are preprocessed by SatElite [10] before running the SAT solver.", "startOffset": 47, "endOffset": 51}, {"referenceID": 21, "context": "This outcome gives credit to the NO FREE Lunch theorem [22].", "startOffset": 55, "endOffset": 59}, {"referenceID": 12, "context": "Other key components of modern CDCL SAT solver such as the restart policies [13] and the activity-based variable selection heuristics [17] also have an influence on the resolution time.", "startOffset": 76, "endOffset": 80}, {"referenceID": 16, "context": "Other key components of modern CDCL SAT solver such as the restart policies [13] and the activity-based variable selection heuristics [17] also have an influence on the resolution time.", "startOffset": 134, "endOffset": 138}], "year": 2017, "abstractText": "Clause Learning is one of the most important components of a conflict driven clause learning (CDCL) SAT solver that is effective on industrial instances. Since the number of learned clauses is proved to be exponential in the worse case, it is necessary to identify the most relevant clauses to maintain and delete the irrelevant ones. As reported in the literature, several learned clauses deletion strategies have been proposed. However the diversity in both the number of clauses to be removed at each step of reduction and the results obtained with each strategy creates confusion to determine which criterion is better. Thus, the problem to select which learned clauses are to be removed during the search step remains very challenging. In this paper, we propose a novel approach to identify the most relevant learned clauses without favoring or excluding any of the proposed measures, but by adopting the notion of dominance relationship among those measures. Our approach bypasses the problem of the diversity of results and reaches a compromise between the assessments of these measures. Furthermore, the proposed approach also avoids another non-trivial problem which is the amount of clauses to be deleted at each reduction of the learned clause database.", "creator": "gnuplot 4.6 patchlevel 4"}}}