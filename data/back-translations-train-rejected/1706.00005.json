{"id": "1706.00005", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-May-2017", "title": "Machine Learning Based Crackle Detection in Lung Sounds", "abstract": "The stethoscope is a well-known and widely available diagnostic instrument. In recent years, many innovative solutions for recording and viewing sounds from a stethoscope have become available. However, to fully utilize such devices, there is a need for an automated approach for detecting abnormal lung sounds, which is better than the existing methods that typically have been developed and evaluated using a small and non-diverse dataset.", "histories": [["v1", "Wed, 31 May 2017 16:24:28 GMT  (1365kb)", "http://arxiv.org/abs/1706.00005v1", null]], "reviews": [], "SUBJECTS": "cs.SD cs.LG", "authors": ["morten gr{\\o}nnesby", "juan carlos aviles solis", "einar holsb{\\o}", "hasse melbye", "lars ailo bongo"], "accepted": false, "id": "1706.00005"}, "pdf": {"name": "1706.00005.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Morten Gr\u00f8nnesby", "Juan Carlos Aviles Solis", "Einar Holsb\u00f8", "Hasse Melbye", "Lars Ailo Bongo"], "emails": ["larsab@cs.uit.no;"], "sections": [{"heading": "1 Introduction", "text": "The kelthoscope is a well-known and widely available diagnostic tool. Health professionals routinely use it to hear for abnormal noises in the lungs to make a diagnosis. Although pulmonary auscultation is a very old technique, new technological advances in hardware, acoustics and digital sound analysis and classification are new possibilities that need to be explored further, reflected in the many new commercial solutions for detecting and viewing sounds from a stethoscope, such as the Bluetooth solution for smartphones from Eko Devices (https: / / ekodevices.com /), and the MIT Mobile Stethoscope. However, these solutions do not have automated approaches for detecting abnormal noises Noises in lung devices and phones that can be easily integrated with smart and telephones. Crackles are short, non-musical noises that are most commonly heard during lung disease [these are non-musical noises]."}, {"heading": "2 Methods", "text": "Our approach provides automatic crackling detection and annotation in a user environment that is easily accessible to healthcare professionals and other users. A user records sounds using a stethoscope with a microphone and then uploads them to our server for classification and comment. The results are presented in a web application that provides an interactive visualization for the end user. In addition, the results are exported as Excel or comma separated tabular text files. We use supervised learning to classify sounds either as crackling or as normal (non-crackling). Such a machine learning method can classify large data sets without the intervention of a human expert. Our supervised approach requires prior knowledge in the form of a pre-classified training set with crackling and normal noises. We select crackling specific features using noises from a large reference database of expert-classified recordings from the lungs."}, {"heading": "2.1 Data acquisition", "text": "We used a sample of audio files from adults participating in the Troms\u00f87 study, which is an epidemiological prospective study of health conditions and chronic diseases. To determine the validity of pulmonary auscultation as a diagnostic method, we recorded pulmonary sounds with an electret microphone (MKE 2-eW Gold, Sennheiser electronic GmbH & Co. KG) inserted 10 cm from the chest into the tube of a stethoscope, the microphone was set to a sensitivity of -12 dB to reduce crackling artifacts. We used a cardiological stethoscope (Littman Cardiology II, 3M Corporation) for the first 300 people and another model (Littman Classic II SE, 3M Corporation) for the remaining participants. The reason for the change in the stethoscope was better performance in terms of reduced low frequency noise. The audio files were recorded in the Wave format of 100 after we had recorded the Sampling wav (4.00z)."}, {"heading": "2.2 Expert classified reference database", "text": "We have started to create a reference database for lung noises. Recordings are classified on two levels: First, two observers independently classified each recording using Adobe Audition 5.0 to hear the lung noises and inspect spectrogram visualizations (Figure 1). The classification scheme had the following variables: 1. Abnormal sound 2. Inspirational whooping cough 3. Expiratory whooping cough 4. Inspirational crackle 5. Other abnormal sound 6. Unclassifiable If there were discrepancies in the first step, the recordings were discussed in a meeting between the two observers and a third lung noise expert. Finally, after discussion, a final decision was reached, in some cases after the vote. This data set is multi-level, so that a sound file can contain both cracking and whooping cough. At the time of writing, we classified 8784 files, of which 333 (3.8%) crackle."}, {"heading": "2.3 Manually created training sets with crackle and normal windows", "text": "To train the classifier, we used the first 209 crackling files that were classified as either inspiring or expiratory crackling, and the noises that were already classified as crackling were drawn as waveforms in Adobe Audition 5.0, and then one of the authors visually identified crackling in the waveform, and the latter confirmed this by listening to the selected part of the file. Although the actual windows were not verified by other experts, the entire recording was evaluated and validated by at least two experts, so we believe that most of them are actual crackling, and for each crackling we record the approximate start and end times. In total, we used 175 crackling as a training set, and we randomly selected 208 pieces that do not contain crackling files from the same 209 crackling files, which are normal noises."}, {"heading": "2.4 Preprocessing: split file into windows", "text": "We initially divided the files into 92ms windows (Figure 2). Each 92ms window contains 4096 samples, with windows overlapping to 50%. Overlapping ensures that crackling is not split between two windows. Window size allows abnormal sounds to be traced back to their location with acceptable accuracy. Dividing the audio into windows also limits the amount of data that is analyzed at a time, making it easier for a machine learning algorithm to find patterns. Finally, using a fixed window as a data point ensures that a data point is not misclassified due to a lack of standardized data length and shape. 175 crackle windows and the 208 normal windows are stored as one-dimensional arrays containing 4096 32-bit floating point numbers. Windowing occurs at analysis time, so that window size and overlaps can be changed without (manually) generating a new training set containing 4096 32-bit floating point numbers, thus not improving the usage of a filter below 24mm."}, {"heading": "2.5 Preprocessing: feature selection", "text": "In order to select the relevant features for building a model of crackers, we examined several approaches. Our goal is to find a functionality that provides both high precision and high recall, which requires ignoring background noise and other additive sounds such as the tube of the stethoscope that sound like cracking. We describe and evaluate in detail the best approach: a 5-dimensional vector of features of the time and frequency domain. Two more complex approaches are discussed in Section 4.1."}, {"heading": "2.5.1 5-dimensional feature vector", "text": "We obtained the best results for a 5-dimensional vector with four characteristics from the time domain {variance, range, sum of the simple moving average (coarse), sum of the simple moving average (fine)} and a characteristic from the frequency domain {spectrum mean}. These are scaled to standardize each characteristic category across training observations. The advantage of using simple summary statistical characteristics is that they can easily be related to the actual data. The disadvantage is that a lot of information is lost by using simple characteristics. We believe that the characteristics of the time domain work well due to their short-lived explosiveness. All characteristics of the time domain are calculated for the 92ms windows. Variance is a measure of the spread of a distribution. It is the average of square deviations from the mean. Folding windows have a higher variance than normal windows due to their explosive nature, and squared errors are naturally sensitive to outliers, but more variations can occur in terms of frequency."}, {"heading": "2.6 Classifiers", "text": "We examined three classifiers for the 5-dimensional characteristic vector: SVM [23], KNN [24] and AdaBoost [25] (Decision Trees)."}, {"heading": "2.6.1 Support Vector Machines (SVM)", "text": "The SVM separates our two classes, cracks and normal windows, by a hyperplane that maximizes the separation between the observations of the two classes. The shape of the hyperplane is determined by a core function. We obtained the highest classification accuracy with the Radial Base Function Kernel. We find the positive constant C that controls the influence or cost of a misclassification by using grid search that adjusts different values for C to different classifiers and then selects the highest quality classifier."}, {"heading": "2.6.2 K-Nearest Neighbor (KNN)", "text": "The K-nearest Neighbors (KNN) method is a non-parametric, lazy method that makes no assumptions about the structure of the underlying data and does not require a training step. Classification of an invisible data point is determined by the tightest training observations in the attribute space. We selected k using grid search. We found that a small k (between 2-4) has distinct boundaries between two classes that, as in our case, have small margins. We found that Euclidean distance performs best for our data. We also evaluated dynamic time warping because it can work better for signals that differ in time and speed, such as crackle. However, for our 5-dimensional summary feature vectors, dynamic time warping does not work better than euclidean distance. In addition, it significantly increases the classification time."}, {"heading": "2.6.3 Adaptive Boosting and Decision Trees", "text": "Adaptive Boosting or AdaBoost is a meta-classifier that uses a collection of classifiers of the same type. Individual classifiers do not need to perform excessively if their prediction is better than random guesses (error rate less than 0.5).The idea is to iteratively train classifiers that focus on the observations where earlier classifiers were wrong by weighting these misclassified observations more than the correctly classified observations. The result of the algorithm is a weighted sum of all classifiers. Each classifier is weighted based on its error rate."}, {"heading": "2.7 Server implementation", "text": "The server is implemented in Python 2.7 and uses Scikit Learn [26]. Due to its flexibility and ease of use, we use Python and Sklearn. The server is portable across different operating systems. Our pipeline is one-thread. Due to the short execution time of both the training and the classification, we have omitted optimized libraries or parallel execution."}, {"heading": "2.8 Evaluation methodology", "text": "Each of the features was tested by running a turn validation cycle 100 times and then determining the average of the F1 value over all cycles. The turn validation cycle is performed on the training set, consisting of 175 crackle windows and 208 normal windows. Each cycle splits the training set into 70% training, which is used to match training parameters and grid search parameters, and 30% validation. We report on precision (positive predictive value), recall (true positive rate), and F-1 (harmonic mean between the two previous measurements). To measure the performance of our server, we used cProfiler for Python 2.7.9 on Windows 10 Pro 64-bit on a computer running Intel Core-i5-4570 with four 2.90GHz cores and 6GB DRAM."}, {"heading": "3 Results", "text": "Our evaluation results provide answers to the following three questions: 1. How well can each of the five features separately be separated between crackling and normal windows? 2. Which classifier works best for our feature vectors? 3. What is the speed of our server during training and classification?"}, {"heading": "3.1 Feature selection", "text": "A single characteristic is therefore not good enough, but it is better than a random guess. It should therefore be possible to combine these characteristics to obtain a better separation in a higher dimensional space. Figure 4 shows the separation between normal and crackling classes. While there is a separation between classes, there is also overlap. This is also reflected in the classification results (linear SVM in Table 1), where we get a high precision, but a low memory due to the overlap of characteristics that are not linearly separable."}, {"heading": "3.2 Classifiers", "text": "SVM performs best in the cross-validation cycle using all characteristics (Table 1). We looked for a grid for each cycle and found that a basic radial function core with a C parameter between 1000 and 2000 performs best. All classifiers performed better than a dummy classifier using a stratified sampling strategy, meaning that the dummy classifier selects classes proportional to the size of the two classes."}, {"heading": "3.3 Server speed-performance", "text": "We trained the classifier in 1.44 seconds, including sequential raster searches of 64 SVM parameter combinations (192 fits), and with the trained model we classified 319 windows in 1.08 seconds, so the model can be used to classify cracks in an interactive tool."}, {"heading": "4 Discussion", "text": "We found that a simple 5-dimensional trait worked best with an SVM classifier. We also evaluated other methods of extracting traits, including classifiers for these [27], [28]. The accuracy and reliability of our system is better than in studies of health workers [29] - [32] (although health workers are more accurate than in [29] - [32] using our (unpublished) data. In the future, we plan to compare the performance of our system with the classifications of human experts using our entire (large) data set."}, {"heading": "4.1 Negative results: alternative feature extraction methods and classifiers", "text": "In previous work [27], we evaluated two alternative methods of feature extraction for our data, but they did not perform as well as the simpler 5-dimensional feature described and evaluated above."}, {"heading": "4.1.1 Short-Time Fourier Transformation (STFT)", "text": "We have tried to use the STFT spectrogram directly in an SVM classifier, but many dimensions remain after a STFT. Therefore, we only use STFT as a pre-processing step to calculate the spectrum mean of a window. One of the disadvantages of the STFT is the fixed window size, which means that there is a trade-off between good time resolution or good frequency resolution."}, {"heading": "4.1.2 Discrete Wavelet Transform", "text": "Discrete wavelet decomposition (DWT) is an alternative to STFT. While STFT uses fixed-size windows, discrete wavelet transformation varies the window size according to frequency. Higher frequencies have smaller windows, while lower frequencies have larger windows. This gives higher frequencies better time resolution and lower frequencies better frequency resolution. In crackling, location and duration can be an important factor, especially when reporting and visualizing analysis results."}, {"heading": "4.1.3 Spectral Flux", "text": "Spectral flux is a measure of how quickly a signal changes over time. Spectral flux is calculated by comparing a sliding window with the previous window over a normalized waveform. We use the Euclidean distance between the two windows. While spectral flux can be useful in detecting insertion, measuring spectral flux contains very little information. We believe it can be useful in detecting possible crack candidates within a larger audio file, less useful as a feature in crack classification."}, {"heading": "4.1.4 Mel Frequency Ceptrsal Coefficients", "text": "Mel Frequency Cepstral Coefficient (MFCC) feature extraction is widely used in speech and music detection [33]. MFCC significantly reduces the dimensionality of training data, but is designed and used for speech detection. Crackle detection is a short, explosive, non-musical sound. MFCC represents the spectral shell of the signal, which is good for detecting linguistic characteristics, but crackle does not comply with these characteristics."}, {"heading": "4.1.5 Spectrogram Image Analysis", "text": "An alternative approach to detecting crackle is to convert the sound signal into a spectrogram and then apply image analysis techniques. [34] classifies crackle by extracting features from the elliptical pattern of a crackle in a spectrogram. We tried to replicate the results by calculating the spectrogram of a signal using the Short Time Fourier Transform (STFT) and then using histogram compensation to increase the contrast of the spectrogram. We also used thresholds to normalize each value to either 0 or 1. Although we were able to replicate the spectrogram processing techniques, we could not accurately detect the elliptical structure of the crackle in our spectrograms. We believe this is due to the fact that our normal sounds have similar elliptical patterns that are indistinguishable from crackle."}, {"heading": "4.1.6 Summary", "text": "These alternative approaches to feature engineering yielded useful classification results, but not as good as the simpler 5-dimensional vector. We believe that key challenges to detecting crackling sounds recorded in a clinical setting (or in other settings such as home monitoring) are low signal-to-noise ratios, crackling noise artifacts, and irregular loudness. Therefore, pre-processing methods that reduce the impact of noise, and better techniques to locate potential abnormal sounds in larger audio files, such as finding potential crackers of about 20 ms within a 15-second audio file, are just as important as feature engineering."}, {"heading": "4.2 Improvements for per file and per person crackle detection", "text": "The methods cannot be applied directly to classify individual files and persons as normal or with cracking, for three reasons: firstly, our lung sound recordings are about 15 seconds long and therefore have about 300 windows (92ms, 50% overlap); our methods do not have the specificity to prevent at least one false positive being detected among these windows; secondly, we have not taken into account the natural class imbalance; only about 5% of the recordings in our reference database (and thus the population) have cracking; training and evaluation on a synthetically balanced dataset leads to a higher false positive rate, as it leads to a natural overestimation of the previous likelihood of cracking; this is essentially a compromise between false positive rate and sensitivity, as it can be difficult to increase one without increasing the other in unbalanced datasets; thirdly, even healthy people can have some crackers."}, {"heading": "4.3 Applications for our approach", "text": "Healthcare workers routinely hear pulmonary noises through stethoscopes during general examinations or when patients indicate breathing difficulties. Such pulmonary auscultations are an important method for physicians when making decisions about treatment and referral for ultrasound or MRI. However, auscultation is a subjective method and improper treatment and referrals cause increased time and money. Training physicians is a challenging task due to differences in perceptions of sound and the lack of common terminology, even though the latter are more focused for lung experts. These challenges require better training tools and a gold standard for abnormal lung noises is urgently needed. Training physicians with such instruments would help them make a more accurate diagnosis and decision on a treatment and referral process. Our approach can be used in training tools to automatically detect and highlight crackle in waveforms and spectrograms (similar to [37]). Similar visualizations are also possible as auxiliary devices for use in a smartphone, and finally, the use of a blood monitor for lung disease."}, {"heading": "4.4 Conclusion and future work", "text": "We have presented a machine learning approach to detecting crackling sounds recorded with a stethoscope as part of a large health study. Several methods of feature extraction and classifiers performed best with 209 files from a data set of 36054 sound recordings. A simple 5-dimensional vector and an SVM with a radial base function kernel performed best. We achieved an accuracy of 86% and an 84% recall for classifying a crackle in a window, which is more accurate than in studies of health professionals. The low-dimensional feature vector makes the SVM very fast. We plan to check if our methods work well for lung sound recordings collected with other stethoscopes, microphones and recording environments. We therefore believe that the approach is well suited for training physicians and use on smartphones."}, {"heading": "5 Acknowledgments", "text": "Anne H. Davidsen and Raimonda B. Einarsen for help with the classification of recorded files and Hans Pasterkamp for help with the classification of difficult cases."}, {"heading": "6 Conflict of interest statement", "text": "The five authors have a commercial license for the approach described and evaluated in this paper. LAB is co-founder of a company that offers tools for lung sound analysis."}, {"heading": "7 Human rights statement", "text": "The Troms\u00f8 study was approved by the Norwegian Data Supervisory Authority and the Regional Ethics Commission of Northern Norway (REK). Only the sound files and variables classifying the sounds were used, and identification of the participants was not possible."}, {"heading": "8 References", "text": "[1] D. Chamberlain, J. Mofor, R. Fletcher, and R. Kodgule WHO, \"Mobile Stethoscope and signalprocessing algorithms for pulmonary screening and diagnostics,\" in 2015 IEEE Global Humanitarian Technology Conference (GHTC), 2015, pp. 385-392, [2] A. Bohadana, G. Izbicki, and S. S. Kraman, \"Fundamentals of Lung Auscultation 2012,\" N. Engl. J. Med., vol. 370, no., pp. 744-751, February 2014. [3] A. F. Members et al., \"ESC Guidelines for the Diagnostics and Treatment of Acute and Chronic Heart Failure 2012,\" Eur. Heart J., vol. 33, no. 1787-1847, Jul. 2012. [4] Holleman DR, Jr., and Simel DL. \"Does the clinical examination predict airflow limitation?,\" vol."}], "references": [{"title": "Mobile stethoscope and signal processing algorithms for pulmonary screening and diagnostics", "author": ["D. Chamberlain", "J. Mofor", "R. Fletcher", "R. Kodgule"], "venue": "2015 IEEE Global Humanitarian Technology Conference (GHTC), 2015, pp. 385\u2013392.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Fundamentals of Lung Auscultation", "author": ["A. Bohadana", "G. Izbicki", "S.S. Kraman"], "venue": "N. Engl. J. Med., vol. 370, no. 8, pp. 744\u2013751, Feb. 2014.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "ESC Guidelines for the diagnosis and treatment of acute and chronic heart failure 2012", "author": ["A.F. Members"], "venue": "Eur. Heart J., vol. 33, no. 14, pp. 1787\u20131847, Jul. 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1847}, {"title": "Does the clinical examination predict airflow limitation", "author": ["DR Holleman", "Jr", "DL Simel"], "venue": "JAMA, vol. 273, no. 4, pp. 313\u2013319, Jan. 1995.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1995}, {"title": "Does this patient have community-acquired pneumonia?: Diagnosing pneumonia by history and physical examination", "author": ["JP Metlay", "WN Kapoor", "MJ Fine"], "venue": "JAMA, vol. 278, no. 17, pp. 1440\u20131445, Nov. 1997.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1997}, {"title": "Epidemiology of Heart Failure", "author": ["V.L. Roger"], "venue": "Circ. Res., vol. 113, no. 6, pp. 646\u2013659, Aug. 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Computerised Analysis of Telemonitored Respiratory Sounds for Predicting Acute Exacerbations of COPD", "author": ["M.A. Fernandez-Granero", "D. Sanchez-Morillo", "A. Leon-Jimenez"], "venue": "Sensors, vol. 15, no. 10, pp. 26978\u201326996, Oct. 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Computerized respiratory sounds: a comparison between patients with stable and exacerbated COPD", "author": ["C. J\u00e1come", "A. Oliveira", "A. Marques"], "venue": "Clin. Respir. J., Oct. 2015.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Effect of PEEP on breath sound power spectra in experimental lung injury", "author": ["J. R\u00e4s\u00e4nen", "M.E. Nemergut", "N. Gavriely"], "venue": "Intensive Care Med. Exp., vol. 2, Oct. 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Computerized lung sound analysis as diagnostic aid for the detection of abnormal lung sounds: A systematic review and meta-analysis", "author": ["A. Gurung", "C.G. Scrafford", "J.M. Tielsch", "O.S. Levine", "W. Checkley"], "venue": "Respir. Med., vol. 105, no. 9, pp. 1396\u20131403, Sep. 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Automatic Crackle Detection Algorithm Based on Fractal Dimension and Box Filtering", "author": ["C. Pinho", "A. Oliveira", "C. J\u00e1come", "J. Rodrigues", "A. Marques"], "venue": "Procedia Comput. Sci., vol. 64, pp. 705\u2013712, Jan. 2015.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Multi-algorithm respiratory crackle detection", "author": ["Jo\u00e3o Quintas", "Guilherme Campos", "Alda Marques"], "venue": "6th International Conference on Health Informatics (HEALTHINF), 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Pulmonary crackle detection using time\u2013frequency and time\u2013scale analysis", "author": ["G. Serbes", "C.O. Sakar", "Y.P. Kahya", "N. Aydin"], "venue": "Digit. Signal Process., vol. 23, no. 3, pp. 1012\u2013 1021, May 2013.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Classification of Asthmatic Breath Sounds by Using Wavelet Transforms and Neural Networks", "author": ["F.Z. G\u00f6\u011f\u00fc\u015f", "B. Karl\u0131k", "G. Harman"], "venue": "Int. J. Signal Process. Syst., vol. 3, no. 2, 2014.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Computerized analysis of respiratory sounds during COPD exacerbations", "author": ["D. S\u00e1nchez Morillo", "S. Astorga Moreno", "M.\u00c1. Fern\u00e1ndez Granero", "A. Le\u00f3n Jim\u00e9nez"], "venue": "Comput. Biol. Med., vol. 43, no. 7, pp. 914\u2013921, Aug. 2013.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatic Wheezing Detection Based on Signal Processing of Spectrogram and Back-Propagation Neural Network", "author": ["B.-S. Lin", "H.-D. Wu", "S.-J. Chen"], "venue": "J. Healthc. Eng., vol. 6, no. 4, pp. 649\u2013672, 2015.  13", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Combining Neural Network and Genetic Algorithm for Prediction of Lung Sounds", "author": ["\u0130. G\u00fcler", "H. Polat", "U. Erg\u00fcn"], "venue": "J. Med. Syst., vol. 29, no. 3, pp. 217\u2013231, Jun. 2005.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2005}, {"title": "The Microsoft 2016 Conversational Speech Recognition System", "author": ["W. Xiong"], "venue": "ArXiv160903528 Cs, Sep. 2016.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep Convolutional Neural Networks and Data Augmentation for Acoustic Event Detection", "author": ["N. Takahashi", "M. Gygli", "B. Pfister", "L. Van Gool"], "venue": "ArXiv160407160 Cs, Apr. 2016.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "On the Theory of Filter Amplifiers", "author": ["S. Butterworth"], "venue": "Wirel. Eng., vol. 7, 1930.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1930}, {"title": "Estimation of Dependences Based on Empirical Data: Springer Series in Statistics", "author": ["V. Vapnik"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1982}, {"title": "Nearest Neighbor (NN) Norms: nn pattern classification techniques", "author": ["B. Dasarathy"], "venue": "IEEE Computer Society Press,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1991}, {"title": "A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "J Comput Syst Sci, vol. 55, no. 1, pp. 119\u2013139, Aug. 1997.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1997}, {"title": "Scikit-learn: Machine Learning in Python", "author": ["F. Pedregosa"], "venue": "J Mach Learn Res, vol. 12, pp. 2825\u20132830, Nov. 2011.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2011}, {"title": "Pulmonary Crackle Detection Using Signal Processing and Machine Learning", "author": ["Morten Gr\u00f8nnesby"], "venue": "Capstone Project, University of Troms\u00f8, 2015.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Automated Lung Sound Analysis", "author": ["Morten Gr\u00f8nnesby"], "venue": "Master Thesis in Computer Science, University of Troms\u00f8, 2016.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2016}, {"title": "Accuracy and reliability of physiotherapists in the interpretation of tape-recorded lung sounds", "author": ["S. Allingame", "T. Williams", "S. Jenkins", "B. Tucker"], "venue": "Aust. J. Physiother., vol. 41, no. 3, pp. 179\u2013184, Jan. 1995.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1995}, {"title": "Observer variability in the pulmonary examination", "author": ["C.D. Mulrow"], "venue": "J. Gen. Intern. Med., vol. 1, no. 6, pp. 364\u2013367, Dec. 1986.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1986}, {"title": "Validity and reliability of acoustic analysis of respiratory sounds in infants", "author": ["H.E. Elphick", "G.A. Lancaster", "A. Solis", "A. Majumdar", "R. Gupta", "R.L. Smyth"], "venue": "Arch. Dis. Child., vol. 89, no. 11, pp. 1059\u20131063, Nov. 2004.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2004}, {"title": "Observer agreement, chest auscultation, and crackles in asbestos-exposed workers", "author": ["P. Workum", "E.A. DelBono", "S.K. Holford", "R.L. Murphy"], "venue": "Chest, vol. 89, no. 1, pp. 27\u201329, Jan. 1986.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1986}, {"title": "Mel Frequency Cepstral Coefficients for Music Modeling", "author": ["B. Logan"], "venue": "International Symposium on Music Information Retrieval, 2000.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2000}, {"title": "The detection of crackles based on mathematical morphology in spectrogram analysis", "author": ["K. Zhang", "X. Wang", "F. Han", "H. Zhao"], "venue": "Technol. Health Care Off. J. Eur. Soc. Eng. Med., vol. 23 Suppl 2, pp. S489\u2013494, 2015.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "Remarks on Some Nonparametric Estimates of a Density Function", "author": ["M. Rosenblatt"], "venue": "Ann. Math. Stat., vol. 27, no. 3, pp. 832\u2013837, Sep. 1956.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1956}, {"title": "On Estimation of a Probability Density Function and Mode", "author": ["E. Parzen"], "venue": "Ann. Math. Stat., vol. 33, no. 3, pp. 1065\u20131076, Sep. 1962.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1962}, {"title": "Computerised Lung Auscultation \u2013 Sound Software (CLASS)", "author": ["J. Semedo"], "venue": "Procedia Comput.  Sci., vol. 64, pp. 697\u2013704, Jan. 2015.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "com/), and the MIT mobile stethoscope [1].", "startOffset": 38, "endOffset": 41}, {"referenceID": 1, "context": "Crackles are short, explosive nonmusical sounds heard mostly during inspiration [2].", "startOffset": 80, "endOffset": 83}, {"referenceID": 2, "context": "In these diseases, the presence of crackles helps to stablish a diagnosis [3]\u2013[5].", "startOffset": 74, "endOffset": 77}, {"referenceID": 4, "context": "In these diseases, the presence of crackles helps to stablish a diagnosis [3]\u2013[5].", "startOffset": 78, "endOffset": 81}, {"referenceID": 5, "context": "Recent reports [7] state that 23 million people worldwide have a diagnosis of heart failure.", "startOffset": 15, "endOffset": 18}, {"referenceID": 6, "context": "In addition, lung sounds have the ability to reflect rapid changes, and are therefore useful in evaluating treatment responses, home monitoring, and maybe predicting exacerbations of disease [8]\u2013[10].", "startOffset": 191, "endOffset": 194}, {"referenceID": 8, "context": "In addition, lung sounds have the ability to reflect rapid changes, and are therefore useful in evaluating treatment responses, home monitoring, and maybe predicting exacerbations of disease [8]\u2013[10].", "startOffset": 195, "endOffset": 199}, {"referenceID": 9, "context": "Current approaches for automatic detection of crackles in lung sounds have shown promise and they have achieved high specificity and sensitivity for test data ([11] provides a review, CORSA [12] recommends standard for terms and techniques).", "startOffset": 160, "endOffset": 164}, {"referenceID": 10, "context": "Most are rule based [13], [14], and hence detect crackles using a set of predefined parameters that have been extracted from a small set of sample audio files using signal processing techniques.", "startOffset": 20, "endOffset": 24}, {"referenceID": 11, "context": "Most are rule based [13], [14], and hence detect crackles using a set of predefined parameters that have been extracted from a small set of sample audio files using signal processing techniques.", "startOffset": 26, "endOffset": 30}, {"referenceID": 12, "context": "Recently several machine learning based approaches, based on for example SVMs and Neural Networks [15]\u2013[19] have been introduced.", "startOffset": 98, "endOffset": 102}, {"referenceID": 16, "context": "Recently several machine learning based approaches, based on for example SVMs and Neural Networks [15]\u2013[19] have been introduced.", "startOffset": 103, "endOffset": 107}, {"referenceID": 17, "context": "Machine learning based classification such as automatic speech recognition [20] and automatic acoustic event detection [21] is a very active research field with widely used solutions.", "startOffset": 75, "endOffset": 79}, {"referenceID": 18, "context": "Machine learning based classification such as automatic speech recognition [20] and automatic acoustic event detection [21] is a very active research field with widely used solutions.", "startOffset": 119, "endOffset": 123}, {"referenceID": 19, "context": "We considered using a Butterworth bandpass filter [22] to remove frequencies above 2400 Hz and below 50 Hz since these do not contain crackle sounds.", "startOffset": 50, "endOffset": 54}, {"referenceID": 20, "context": "We evaluated three classifiers for the 5-dimensional feature vector: SVM [23], KNN [24], and AdaBoost [25] (Decision Trees).", "startOffset": 73, "endOffset": 77}, {"referenceID": 21, "context": "We evaluated three classifiers for the 5-dimensional feature vector: SVM [23], KNN [24], and AdaBoost [25] (Decision Trees).", "startOffset": 83, "endOffset": 87}, {"referenceID": 22, "context": "We evaluated three classifiers for the 5-dimensional feature vector: SVM [23], KNN [24], and AdaBoost [25] (Decision Trees).", "startOffset": 102, "endOffset": 106}, {"referenceID": 23, "context": "7 using Scikit Learn [26].", "startOffset": 21, "endOffset": 25}, {"referenceID": 24, "context": "We have also evaluated other feature extraction methods, including classifiers for these [27], [28].", "startOffset": 89, "endOffset": 93}, {"referenceID": 25, "context": "We have also evaluated other feature extraction methods, including classifiers for these [27], [28].", "startOffset": 95, "endOffset": 99}, {"referenceID": 26, "context": "The accuracy and reliability of our system is better than found in studies of health personnel [29]\u2013[32] (although health personnel have higher accuracy than reported in [29]\u2013[32] using our data (unpublished)).", "startOffset": 95, "endOffset": 99}, {"referenceID": 29, "context": "The accuracy and reliability of our system is better than found in studies of health personnel [29]\u2013[32] (although health personnel have higher accuracy than reported in [29]\u2013[32] using our data (unpublished)).", "startOffset": 100, "endOffset": 104}, {"referenceID": 26, "context": "The accuracy and reliability of our system is better than found in studies of health personnel [29]\u2013[32] (although health personnel have higher accuracy than reported in [29]\u2013[32] using our data (unpublished)).", "startOffset": 170, "endOffset": 174}, {"referenceID": 29, "context": "The accuracy and reliability of our system is better than found in studies of health personnel [29]\u2013[32] (although health personnel have higher accuracy than reported in [29]\u2013[32] using our data (unpublished)).", "startOffset": 175, "endOffset": 179}, {"referenceID": 24, "context": "In earlier work [27] we evaluated two alternative feature extraction methods for our data.", "startOffset": 16, "endOffset": 20}, {"referenceID": 30, "context": "4 Mel Frequency Ceptrsal Coefficients Mel Frequency Cepstral Coefficients (MFCC) feature extraction is widely used in speech and music recognition [33].", "startOffset": 147, "endOffset": 151}, {"referenceID": 31, "context": "In [34], crackles are classified by extracting features from the elliptical pattern of a crackle in a spectrogram.", "startOffset": 3, "endOffset": 7}, {"referenceID": 31, "context": "We did not have the data used in [34], so we could not do a direct comparison, so we could check if this was since we used STFT instead of the bio22 wavelet decomposition used in [34].", "startOffset": 33, "endOffset": 37}, {"referenceID": 31, "context": "We did not have the data used in [34], so we could not do a direct comparison, so we could check if this was since we used STFT instead of the bio22 wavelet decomposition used in [34].", "startOffset": 179, "endOffset": 183}, {"referenceID": 32, "context": "Using Parzen Windows (Kernel Density Estimation) [35], [36] to estimate the probability density function of a part of the signal, and then comparing the different estimates to find breathing phases.", "startOffset": 49, "endOffset": 53}, {"referenceID": 33, "context": "Using Parzen Windows (Kernel Density Estimation) [35], [36] to estimate the probability density function of a part of the signal, and then comparing the different estimates to find breathing phases.", "startOffset": 55, "endOffset": 59}, {"referenceID": 34, "context": "Our approach can be used in training tools to automatically detect and highlight crackles in waveforms and spectrograms (similar to [37]).", "startOffset": 132, "endOffset": 136}], "year": 2017, "abstractText": "Background and Objective: The stethoscope is a well-known and widely available diagnostic instrument. In recent years, many innovative solutions for recording and viewing sounds from a stethoscope have become available. However, to fully utilize such devices, there is a need for an automated approach for detecting abnormal lung sounds, which is better than the existing methods that typically have been developed and evaluated using a small and non-diverse dataset. Methods: We propose a machine learning based approach for detecting crackles in lung sounds recorded using a stethoscope in a large health survey. Our method is trained and evaluated using 209 files with crackles classified by expert listeners. Our analysis pipeline is based on features extracted from small windows in audio files. We evaluated several feature extraction methods and classifiers. We evaluated the pipeline using a training set of 175 crackle windows and 208 normal windows. We did 100 cycles of cross validation where we shuffled training sets between cycles. For all the division between training and evaluation was 70%-30%. Results: We found and evaluated a 5-dimenstional vector with four features from the time domain and one from the spectrum domain. We evaluated several classifiers and found SVM with a Radial Basis Function Kernel to perform best for our 5-dimensional feature vector. Our approach had a precision of 86% and recall of 84% for classifying a crackle in a window, which is more accurate than found in studies of health personnel. The low-dimensional feature vector makes the SVM very fast. The model can be trained on a regular computer in 1.44 seconds, and 319 crackles can be classified in 1.08 seconds. Conclusions: Our approach detects and visualizes individual crackles in recorded audio files. It is accurate, fast, and has low resource requirements. The approach is therefore well suited for deployment on smart devices and phones or as a web application. It can be used to train health personnel or as part of a smartphone application for Bluetooth stethoscopes.", "creator": "PScript5.dll Version 5.2.2"}}}