{"id": "1706.00046", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-May-2017", "title": "Learning Time-Efficient Deep Architectures with Budgeted Super Networks", "abstract": "Learning neural network architectures is a way to discover new highly predictive models. We propose to focus on this problem from a different perspective where the goal is to discover architectures efficient in terms of both prediction quality and computation cost, e.g time in milliseconds, number of operations... For instance, our approach is able to solve the following task: find the best neural network architecture (in a very large set of possible architectures) able to predict well in less than 100 milliseconds on my mobile phone.", "histories": [["v1", "Wed, 31 May 2017 18:34:50 GMT  (520kb,D)", "http://arxiv.org/abs/1706.00046v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["tom veniat", "ludovic denoyer"], "accepted": false, "id": "1706.00046"}, "pdf": {"name": "1706.00046.pdf", "metadata": {"source": "CRF", "title": "Learning Time-Efficient Deep Architectures with Budgeted Super Networks", "authors": ["Tom Veniat"], "emails": ["tom.veniat@lip6.fr,", "ludovic.denoyer@lip6.fr"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is the case that most people who are able are able to determine for themselves what they want and what they do not want."}, {"heading": "2 Related Work", "text": "For example, it is the case for classification in [2, 24] on the basis of reinforcement learning techniques, in [19] on the basis of gating mechanisms, in [24] on the basis of evolutionary algorithms, or even in [4] on the basis of RL and evolutionary techniques. A major difference to our approach is that these models are guided only by the final predictability of the network. For example, in [24], a neural architecture controller can suggest a \"child\" who can then be trained and evaluated before trying a new architecture, and the process continues iteratively until a good architecture is achieved."}, {"heading": "3 Super Networks", "text": "We look at the classic supervised learning problem defined by an input space X and an output space Y. In the following, input and output spaces are related to multidimensional, real evaluated spaces (vectors, matrices, or larger tensors).The training set is called asD = {(x1, y1),..., (x ', y')}, where every single part of the network is X, yi, and \"the number of monitored examples.\" Finally, we look at a model f: X \u2192 Y that predicts a certain input. We first describe a family of models called Super Networks (S-Network) 1, since our contribution, presented in Section 4, will be a (stochastic) extension of that model. The principle of Super Networks is not new, and the same ideas have already been suggested in literature, e.g. Deep Sequential Neural Networks [2], Neural Fabrics [4], or even PathNet [4]."}, {"heading": "4 Learning Time-efficient architectures", "text": "Our main idea is the following: We now consider that the structure E of the S-network (E, \u03b8) does not describe a single neural network architecture, but a series of possible architectures. In fact, each subgraph of E (subset of edges) corresponds to an S-network. A subgraph of edges is called H E, where H corresponds to a binary matrix that is responsible for selecting the edges in E, designating the Hadamard product between H and E. Our goal will therefore be to identify the best matrix H in such a way that the corresponding S-network (H E, \u03b8) will be an efficient network both in terms of predictive quality and computing speed. The next sections are organized as follows: (i) First, we formalize this problem as a combinatorial problem in which we want to discover the best matrix H in the set of all possible binary matrices of size N \u00d7 N. Since this optimization problem is insolvable, we propose a new model element called the super-family."}, {"heading": "4.1 Budgeted Architectures Learning", "text": "Let us consider H as a binary matrix of the size N \u00d7 N. Let us consider C (H E) as special costs (R + the calculation cost2, which are associated with the calculation of the S-network (H E, \u03b8) and can be of different nature (see section 5). Let us also define C as the maximum cost that the user would grant to the desired model. For example, if the problem of learning a model with a calculation time of less than 200 ms is solved, then C is equal to 200ms. In this article we propose to focus on a soft version of the problem, which is described as follows: H \u0445, \u03b8 = arg min H, \u03b81 '\u2211 i (f (xi, H E, \u03b8), yi) under constraints: C (H E)."}, {"heading": "4.2 Stochastic Super Networks", "text": "Now we consider given a certain architectureE the following stochastic model - called Stochastic Super Network (SS network) - which calculates a prediction in two steps: (i) first, a sub-graph H is captured on the basis of a distribution with parameters. This process is defined as follows: \"H.\" (ii) The final prediction is made using this sub-graph, i.e. by calculating f (x, H E, \u03b8). \"This inference algorithm is described in Algorithm 1.\" (ii) The final prediction is thus defined by a triplet (E, E) and is learned both at a training level. \"(H\" D \").\" (H \"D\"): \"D\" (i): \"D.\" (i): \"D.\" (f \"H E\"): \"D.\" (D). \"D.\" (D.): \"D.\" (D). \"(D.).\" D. \"(D.\" D. \"). (D.\" D. \"(D.).\" D. \"(D.\" D. \").\" (D. \"D.\" (D. \").\" D. \"(D.\" D. \").\" (D."}, {"heading": "4.3 Learning Algorithm", "text": "We consider a general case in which the cost function C (H E) is unknown and can only be observed at the end of the calculation of the model via an input x, e.g. the computation time in seconds. Note that in this case, stochastic costs are also included, where the cost is a random variable caused by a certain network latency during the distributed calculation. We now describe the case in which C is deterministic, its extension to stochastic values being simple (see supplementary material). Let us call D (x, y, \u03b8, E, H) the quality of the model (H E, \u03b8) to a given training pair (x, y): D (x, y, \u03b8, E, H) = (f (x, H E, prognostics), y), max (0, C (H E) \u2212 C (H) \u2212 C) \u2212 C) (5) We propose to use a REINFORCE-inspired algorithm as in [2, 1] for learning."}, {"heading": "5 Experiments", "text": "This year, it has come to the point that it will be able to retaliate, \"he said.\" We've never lost so much time, \"he said.\" We've never gotten as far as this year, \"he said."}, {"heading": "5.1 Image Classification", "text": "MNIST: Table 1 presents the results of MNIST with the cost of time compared to the cost of time. On the other hand, our model is able to achieve an error rate of 0.43%. These two results show the ability of GNI to find different cost structures."}, {"heading": "5.2 Image Segmentation", "text": "We also conduct experiments to solve the problem of image segmentation. Note that in this case, the model calculates a map of the pixel probabilities, with the output layer now at the top right position of the CNF matrix. Therefore, it is more difficult to reduce the total cost. On the Part Labels dataset, we are able to learn a BSN model with a flop gain of 40%. In this task, forcing the model to increase the flop gain by reducing the value of C to inconsistent models. At a flop gain of 40%, BSN achieves a failure rate of 4.57%, which can be compared to the error of 4.94% for the entire model. Due to its cutting process, the P-CNF model is unable to produce consistent architectures if the desired flop gain is greater than 20%. Even at 20%, its error rate is higher than our (5.5%). The Smart CNF achieves significantly higher error rate than the flop task, but with a higher price, the higher CNF achieves the flop gain."}, {"heading": "6 Conclusion and Perspectives", "text": "The experiments in the field of computer vision show the effectiveness of our approach. Its main advantage is that BSN can be used for any computational cost (computation time, number of operations, additional time generated by a certain network latency,..). It can also be used with costs of other kinds, such as memory consumption, which have not been investigated in this paper. This work opens up many research directions. One direction is to evaluate the ability of this model to support the inherent costs over a large distributed cluster, thus finding efficient architectures on large clusters. A second long-term direction is to investigate whether this model could be adapted to shorten the training time (instead of the test computation time). This could be done, for example, by meta learning approach."}, {"heading": "Supplementary Material", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Model Selection Protocol", "text": "As explained in the article, the selection of the model is made by learning many different models, calculating the Pareto front of the accuracy / cost curve on the validation set, and then reporting the performance achieved on the test set. This is illustrated in the following illustration, in which many different models are reported (blue circles) and the corresponding performance on the test (red crosses). The line corresponds to the front achieved on the test models, using this front side to create the results table presented in the article."}, {"heading": "Demonstration of Proposition 1", "text": "Consider the stochastic optimization problem defined in Eq.4. The scheme of evidence is as follows: \u2022 First, we lower the value of Eq.4 by the optimal value of Eq.3 \u2022 Then we show that this lower limit can be reached by certain values of the Equation and the Equation of God. Otherwise, the solution of Eq.4 is equivalent to the solution of Eq.3. Let us specify: B (H E) all H matrices that can be sampled according to Eq.4. The objective function of Eq.4 can be written as follows: EH (B, E, TB, KA) \u2212 C) (9) Given the value of the equation, we call the proposed solution supp (E) all H matrices that can be sampled according to the equation."}, {"heading": "Additional Architecture Details", "text": "As shown in Figure 1, this architecture extends over two axes: the first axis represents the different layers L of the mesh, while the second axis corresponds to different scales S. The first scale is the size of the input images, each successive scale being reduced by a factor of 2 and corresponding to the last scale corresponding to a single scale. Each layer (l \u2212 1, s + 1) in this fabric derives its input from three different layers of the preceding scale: one with a finer scale (l \u2212 1, s \u2212 1), one with the same scale (l \u2212 1, s + 1) and one with a coarser scale (l \u2212 1, s + 1). The first and last columns are the only ones with vertical connections within the same scale (as shown in Figure 1) and one with a coarser scale (l \u2212 1, s + 1)."}, {"heading": "Additional Learning Details", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Datasets", "text": "The MNIST dataset consists of 70k images with 28x28 pixels, which have a single handwritten digit between 0 and 9. The training set contains 60k training samples and the test set contains 10k samples. We use the standard split of 50k training samples and 10k validation samples from the training set. Each image is initially filled with zeros of 36x36 images before we apply a random 32x32 image section to obtain the final resolution. The images are in the range [-1,1].CIFAR10. The CIFAR10 dataset consists of 50k training images and 10k test images with 10 classes. We split the training set according to the standard, i.e. 45k training samples and 5k validation samples. We use two data augmentation techniques: filling the image to 36x36 pixels, before splitting a random cut-out of the 32x32 images and 25x1.1 samples each."}], "references": [{"title": "Conditional computation in neural networks for faster models", "author": ["Emmanuel Bengio", "Pierre-Luc Bacon", "Joelle Pineau", "Doina Precup"], "venue": "CoRR, abs/1511.06297,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Sharp Models on Dull Hardware: Fast and Accurate Neural Machine Translation", "author": ["Jacob Devlin"], "venue": "Decoding on the CPU,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2017}, {"title": "Pathnet: Evolution channels gradient descent in super neural networks", "author": ["Chrisantha Fernando", "Dylan Banarse", "Charles Blundell", "Yori Zwols", "David Ha", "Andrei A. Rusu", "Alexander Pritzel", "Daan Wierstra"], "venue": "CoRR, abs/1701.08734,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2017}, {"title": "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding", "author": ["Song Han", "Huizi Mao", "William J Dally"], "venue": "In International Conference on Learning Representations (ICLR\u201916 best paper award),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Second order derivatives for network pruning: Optimal brain surgeon", "author": ["Babak Hassibi", "David G. Stork"], "venue": "In Advances in Neural Information Processing Systems 5, [NIPS Conference],", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1993}, {"title": "Deep residual learning for image recognition", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": "CoRR, abs/1512.03385,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Augmenting CRFs with Boltzmann machine shape priors for image labeling", "author": ["Andrew Kae", "Kihyuk Sohn", "Honglak Lee", "Erik Learned-Miller"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Learning multiple layers of features from tiny images", "author": ["Alex Krizhevsky"], "venue": "Technical report,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "In Intelligent Signal Processing,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2001}, {"title": "Dynamic deep neural networks: Optimizing accuracy-efficiency trade-offs by selective", "author": ["Lanlan Liu", "Jia Deng"], "venue": "execution. CoRR,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2017}, {"title": "Multi-objective convolutional learning for face labeling", "author": ["Sifei Liu", "Jimei Yang", "Chang Huang", "Ming-Hsuan Yang"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Deciding how to decide: Dynamic routing in artificial neural networks", "author": ["Mason McGill", "Pietro Perona"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2017}, {"title": "Large-scale evolution of image", "author": ["Esteban Real", "Sherry Moore", "Andrew Selle", "Saurabh Saxena", "Yutaka Leon Suematsu", "Quoc V. Le", "Alex Kurakin"], "venue": "classifiers. CoRR,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2017}, {"title": "Efficient reinforcement learning through evolving neural network topologies", "author": ["Kenneth O. Stanley", "Risto Miikkulainen"], "venue": "In GECCO 2002: Proceedings of the Genetic and Evolutionary Computation Conference,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2002}, {"title": "Improving the speed of neural networks on cpus", "author": ["Vincent Vanhoucke", "Andrew Senior", "Mark Z. Mao"], "venue": "In Deep Learning and Unsupervised Feature Learning Workshop,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Regularization of neural networks using dropconnect", "author": ["Li Wan", "Matthew D. Zeiler", "Sixin Zhang", "Yann LeCun", "Rob Fergus"], "venue": "In ICML (3),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Neural architecture search with reinforcement learning", "author": ["Barret Zoph", "Quoc V. Le"], "venue": "CoRR, abs/1611.01578,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}], "referenceMentions": [{"referenceID": 5, "context": "For instance, in computer vision, this has lead to particularly well-known models like GoogleNet [21] or ResNet [8].", "startOffset": 112, "endOffset": 115}, {"referenceID": 13, "context": "Different algorithms have been proposed including evolutionary methods [20, 16, 17] or reinforcement learning-based approaches [24].", "startOffset": 71, "endOffset": 83}, {"referenceID": 12, "context": "Different algorithms have been proposed including evolutionary methods [20, 16, 17] or reinforcement learning-based approaches [24].", "startOffset": 71, "endOffset": 83}, {"referenceID": 16, "context": "Different algorithms have been proposed including evolutionary methods [20, 16, 17] or reinforcement learning-based approaches [24].", "startOffset": 127, "endOffset": 131}, {"referenceID": 0, "context": "This task has been recently targeted by different models [1, 15, 12], with different learning techniques.", "startOffset": 57, "endOffset": 68}, {"referenceID": 11, "context": "This task has been recently targeted by different models [1, 15, 12], with different learning techniques.", "startOffset": 57, "endOffset": 68}, {"referenceID": 9, "context": "This task has been recently targeted by different models [1, 15, 12], with different learning techniques.", "startOffset": 57, "endOffset": 68}, {"referenceID": 16, "context": "This is the case for example for classification in [2, 24] based on Reinforcement learning techniques, in [19] based on gating mechanisms, in [17] based on evolutionary algorithms or even in [4] based on both RL and evolutionary techniques.", "startOffset": 51, "endOffset": 58}, {"referenceID": 12, "context": "This is the case for example for classification in [2, 24] based on Reinforcement learning techniques, in [19] based on gating mechanisms, in [17] based on evolutionary algorithms or even in [4] based on both RL and evolutionary techniques.", "startOffset": 142, "endOffset": 146}, {"referenceID": 2, "context": "This is the case for example for classification in [2, 24] based on Reinforcement learning techniques, in [19] based on gating mechanisms, in [17] based on evolutionary algorithms or even in [4] based on both RL and evolutionary techniques.", "startOffset": 191, "endOffset": 194}, {"referenceID": 16, "context": "For example in [24], a controller neural net can propose a \u201cchild\u201d model architecture, which can then be trained and evaluated before trying a new architecture.", "startOffset": 15, "endOffset": 19}, {"referenceID": 4, "context": "The oldest approach is certainly the Optimal Brain Surgeon [7] which removes weights in a classical neural network architecture.", "startOffset": 59, "endOffset": 62}, {"referenceID": 14, "context": "The problem of network compression can also be seen as a way to speedup a particular architecture, for example by using quantization of the weights of the network [22].", "startOffset": 163, "endOffset": 167}, {"referenceID": 3, "context": "Pruning and quantization techniques can also be combined [6] to obtain impressive performances.", "startOffset": 57, "endOffset": 60}, {"referenceID": 1, "context": "For example [3] combines algorithmic optimizations and architecture improvements to speed up the response time of a network while keeping high accuracy.", "startOffset": 12, "endOffset": 15}, {"referenceID": 0, "context": "For example, the model proposed in [1] can be seen as an extension of dropout where the probability of sampling neurons is conditioned on currently processed input (conditional computation).", "startOffset": 35, "endOffset": 38}, {"referenceID": 11, "context": "In the same vein, the model proposed in [15] aims at learning routes in Super networks.", "startOffset": 40, "endOffset": 44}, {"referenceID": 2, "context": "g Deep Sequential Neural Networks [2], Neural Fabrics [18], or even PathNet [4] \u2013 and for different tasks.", "startOffset": 76, "endOffset": 79}, {"referenceID": 2, "context": "The name Super Network comes from [4] which presents an architecture close to ours.", "startOffset": 34, "endOffset": 37}, {"referenceID": 11, "context": "While previous works make assumptions on the structure of the cost function [15], our approach does not rely on any constraint concerning C(H E) except the fact that this cost can be measured during training.", "startOffset": 76, "endOffset": 80}, {"referenceID": 0, "context": "We propose to use a REINFORCE-inspired algorithm as in [2, 1] for learning.", "startOffset": 55, "endOffset": 61}, {"referenceID": 8, "context": "We propose to focus on two tasks: Image classification using MNIST and CIFAR-10 [11, 10] and Image Segmentation using the Part Labels dataset [9].", "startOffset": 80, "endOffset": 88}, {"referenceID": 7, "context": "We propose to focus on two tasks: Image classification using MNIST and CIFAR-10 [11, 10] and Image Segmentation using the Part Labels dataset [9].", "startOffset": 80, "endOffset": 88}, {"referenceID": 6, "context": "We propose to focus on two tasks: Image classification using MNIST and CIFAR-10 [11, 10] and Image Segmentation using the Part Labels dataset [9].", "startOffset": 142, "endOffset": 145}, {"referenceID": 15, "context": "[23] 0 % 9.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "al [13] 0 % 4.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "Images are normalized in the range [-1,1].", "startOffset": 35, "endOffset": 41}, {"referenceID": 0, "context": "Images are then normalized in the range [-1,1].", "startOffset": 40, "endOffset": 46}, {"referenceID": 0, "context": "Images are zero padded from 250x250 to 256x256 and horizontally flipped before being normalized in the range [-1,1].", "startOffset": 109, "endOffset": 115}], "year": 2017, "abstractText": "Learning neural network architectures is a way to discover new highly predictive models. We propose to focus on this problem from a different perspective where the goal is to discover architectures efficient in terms of both prediction quality and computation cost, e.g time in milliseconds, number of operations... For instance, our approach is able to solve the following task: find the best neural network architecture (in a very large set of possible architectures) able to predict well in less than 100 milliseconds on my mobile phone. Our contribution is based on a new family of models called Budgeted Super Networks that are learned using reinforcement-learning inspired techniques applied to a budgeted learning objective function which includes the computation cost during disk/memory operations at inference. We present a set of experiments on computer vision problems and show the ability of our method to discover efficient architectures in terms of both predictive quality and computation time.", "creator": "LaTeX with hyperref package"}}}