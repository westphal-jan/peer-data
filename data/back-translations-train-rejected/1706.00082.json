{"id": "1706.00082", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-May-2017", "title": "Megapixel Size Image Creation using Generative Adversarial Networks", "abstract": "Since its appearance, Generative Adversarial Networks (GANs) have received a lot of interest in the AI community. In image generation several projects showed how GANs are able to generate photorealistic images but the results so far did not look adequate for the quality standard of visual media production industry. We present an optimized image generation process based on a Deep Convolutional Generative Adversarial Networks (DCGANs), in order to create photorealistic high-resolution images (up to 1024x1024 pixels). Furthermore, the system was fed with a limited dataset of images, less than two thousand images. All these results give more clue about future exploitation of GANs in Computer Graphics and Visual Effects.", "histories": [["v1", "Wed, 31 May 2017 20:43:19 GMT  (4135kb,D)", "http://arxiv.org/abs/1706.00082v1", "3 pages, 4 figures"]], "COMMENTS": "3 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.CV cs.GR cs.LG", "authors": ["marco marchesi"], "accepted": false, "id": "1706.00082"}, "pdf": {"name": "1706.00082.pdf", "metadata": {"source": "CRF", "title": "Megapixel Size Image Creation using Generative Adversarial Networks", "authors": ["Marco Marchesi"], "emails": ["marco.marchesi@happyfinish.com"], "sections": [{"heading": null, "text": "Since its release, Generative Adversarial Networks (GANs) [2] have generated much interest in the AI community. In image generation, several projects have shown how GANs are capable of producing photorealistic images, but the results so far have not been sufficient to meet the quality standards of the visual media production industry. We present an optimized image generation process based on a Deep Convolutional Generative Adversarial Network (DCGANs) to produce photorealistic high-resolution images (up to 1024x1024 pixels), and have fed the system with a limited dataset of less than two thousand images, all of which provide more insight into the future use of GANs in computer graphics and visual effects."}, {"heading": "1 Introduction", "text": "Generative Adversarial Networks consist of two competing neural networks. One, the generator G (z), generates images from a latent space z of evenly distributed random numbers, while the discriminator D (x) must assess the images he receives as fake or real. We train G (z) with the aim of deceiving D (x) with fake images and minimizing log 1 \u2212 D (G (z). To do this, G (z) must learn to produce images that are as photo-realistic as possible. On the contrary, the training is still challenging and efforts are being made to prevent both networks from failing. Several improvements have been introduced since the first GAN model. One of the first techniques was minibatch discrimination, which reduces the likelihood that generator D (the generator) will work faster [4] or convergence [5]."}, {"heading": "2 The model", "text": "The model we used is a DCGAN [3] implemented with Google TensorFlow, with a variable batch size depending on the size of the images we wanted to achieve. To train the discriminator, we tested two slightly different sets of data (1807 and 1796 images), composed of women's faces from magazines and social media. In fact, the goal of this project was to produce an image summarizing how new mothers are misrepresented by the media in the UK. To do this, we faced some challenges: \u2022 The data set was limited to less than 2k images compared to those used in research, so the system had to learn as much as possible from the limited amount of data. In addition, 70% of the images in the dataset were smaller than 512x512px, so the system had to access Xiv: 170 6.00 082v 1 [cs.C V] 31 Mlearn most from upscaled images, inferring the high resolution from the larger images, and we traced the NX system to a limited size VIX."}, {"heading": "3 Training Process", "text": "We created images in different sizes, starting from 192x192px to 1024x1024px (Fig.3). The egapixel size was first produced as long as the highest image size for GANs was 512px in width [6]. In short, we applied the following optimizations: 1. To prevent generator and discriminator from drifting apart, we applied an additional step to update generator and discriminator alternately every 50 steps. Thus, the loss for both networks (loss (D) < 1 and loss (G) < 3) fluctuated in a limited interval, but never deviated in any image size. 2. To generate the samples, we limited the interval of the even distribution of random inputs, for example, this solution significantly reduced the artifacts, as Fig.4. showed."}, {"heading": "4 Conclusion and Future Work", "text": "We briefly outlined the optimization process that was performed on a DCGAN model to produce larger photorealistic images with a limited dataset. We reached the size of 1024x1024px, nearly four times the previous research, and limited the artifacts to use the image in a creative process for a commercial campaign. We want to test whether our improvements are applicable to each dataset. We aim to reduce memory requirements for GANs, exploit the parallelism of the GPU, and apply new convergence criteria to GANs to produce even larger photorealistic images. Additional conditional probabilities will allow us to make more extensive use of GANs in other areas of computer graphics, such as animation and visual effects."}, {"heading": "Acknowledgement", "text": "This research was part of a commercial project funded by MHPC."}], "references": [{"title": "BE- GAN: Boundary Equilibrium Generative Adversarial Networks", "author": ["D. Berthelot", "T. Schumm", "L. Metz"], "venue": "ArXiv e-prints,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2017}, {"title": "Generative Adversarial Networks", "author": ["I.J. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["A. Radford", "L. Metz", "S. Chintala"], "venue": "CoRR, abs/1511.06434", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Improved techniques for training gans", "author": ["T. Salimans", "I.J. Goodfellow", "W. Zaremba", "V. Cheung", "A. Radford", "X. Chen"], "venue": "Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain, pages 2226\u20132234", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Energybased generative adversarial network", "author": ["J.J. Zhao", "M. Mathieu", "Y. LeCun"], "venue": "CoRR, abs/1609.03126", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "Unpaired image-to-image translation using cycle-consistent adversarial networks", "author": ["J. Zhu", "T. Park", "P. Isola", "A.A. Efros"], "venue": "CoRR, abs/1703.10593", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2017}], "referenceMentions": [{"referenceID": 1, "context": "Since its appearance, Generative Adversarial Networks (GANs) [2] have received a lot of interest in the AI community.", "startOffset": 61, "endOffset": 64}, {"referenceID": 3, "context": "One of the first techniques was the minibatch discrimination that reduces the chance for the generator to collapse [4].", "startOffset": 115, "endOffset": 118}, {"referenceID": 4, "context": "Other techniques aim to find a faster convergence, modeling the discriminator D(x) as an energy function [5] or introducing new loss definitions [1].", "startOffset": 105, "endOffset": 108}, {"referenceID": 0, "context": "Other techniques aim to find a faster convergence, modeling the discriminator D(x) as an energy function [5] or introducing new loss definitions [1].", "startOffset": 145, "endOffset": 148}, {"referenceID": 2, "context": "The model we used is a DCGAN [3], implemented with Google TensorFlow, with a variable batch size depending of the size of the images we wanted to achieve.", "startOffset": 29, "endOffset": 32}, {"referenceID": 5, "context": "megapixel size has been produced for the first time, as long as the highest image size for GANs so far was 512px in width [6].", "startOffset": 122, "endOffset": 125}], "year": 2017, "abstractText": "Since its appearance, Generative Adversarial Networks (GANs) [2] have received a lot of interest in the AI community. In image generation several projects showed how GANs are able to generate photorealistic images but the results so far didn\u2019t look adequate for the quality standard of visual media production industry. We present an optimized image generation process based on a Deep Convolutional Generative Adversarial Networks (DCGANs), in order to create photorealistic high-resolution images (up to 1024x1024 pixels). Furthermore, the system was fed with a limited dataset of images, less than two thousand images. All these results give more clue about future exploitation of GANs in Computer Graphics and Visual Effects.", "creator": "LaTeX with hyperref package"}}}