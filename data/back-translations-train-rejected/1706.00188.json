{"id": "1706.00188", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2017", "title": "Deep Learning for Hate Speech Detection in Tweets", "abstract": "Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. The complexity of the natural language constructs makes this task very challenging. We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity. Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by ~18 F1 points.", "histories": [["v1", "Thu, 1 Jun 2017 07:25:22 GMT  (25kb,D)", "http://arxiv.org/abs/1706.00188v1", "In Proceedings of ACM WWW'17 Companion, Perth, Western Australia, Apr 2017 (WWW'17), 2 pages"]], "COMMENTS": "In Proceedings of ACM WWW'17 Companion, Perth, Western Australia, Apr 2017 (WWW'17), 2 pages", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["pinkesh badjatiya", "shashank gupta", "manish gupta", "vasudeva varma"], "accepted": false, "id": "1706.00188"}, "pdf": {"name": "1706.00188.pdf", "metadata": {"source": "CRF", "title": "Deep Learning for Hate Speech Detection in Tweets", "authors": ["Pinkesh Badjatiya", "Shashank Gupta", "Manish Gupta", "Vasudeva Varma"], "emails": ["shashank.gupta}@research.iiit.ac.in,", "gmanish@microsoft.com,", "vv@iiit.ac.in"], "sections": [{"heading": "1. INTRODUCTION", "text": "With the massive increase in social interactions on online social networks, there has also been an increase in hate-filled activities that exploit such infrastructure. On Twitter, hate-filled tweets are those that contain offensive statements that target individuals (cyber-bullying, a politician, a celebrity, a product) or specific groups (a country, LGBT, a duvet, a gender, an organization, etc.). Detection of such hate-filled statements is important for analyzing the public mood of a group of users toward another group, and for discouraging related folding activities. It is also useful to filter tweets before recommending content, or to learn AI chat bots from tweets. The manual way to filter hate-filled tweets is not scalable, motivates researchers to identify automated ways. In this work, we focus on the problem of classifying a tweet as racist, sexist, or a natural hate complex of two different forms of expression due to the different nature of the two forms of language constructed."}, {"heading": "2. PROPOSED APPROACH", "text": "In all of these methods, an embedding is generated for a tweet, which is used as a feature representation with a classifier. Baseline Methods: As a baseline method, we experiment with three broad representations. (1) Char n-gramms: It is the state-of-the-art method [6] that uses characters n-grammes to detect hate speech. (2) TF-IDF: TF-IDF are typical features used for text classification. (3) BoWV: Bag of Words Vector approach uses the average of the word (GloVe) embeddings to represent a sentence. We experiment with several classifiers for both the TF-IDF and the BoWV approaches. Proposed methods: We examine three neural network architectures for the task described below. For each of the three methods, we initialize the word embeddings with either bells or bells."}, {"heading": "3. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Dataset and Experimental Settings", "text": "We experimented with a data set of 16K commented tweets provided by the authors of [6], of which 3383 were labeled as sexist, 1972 as racist and the rest as neither sexist nor racist. We used the GloVe [5] pre-trained word embeddings for embedding methods. GloVe embeddings2 were trained on a large Tweet corpus (2B tweets, 27B tokens, 1.2m vocabulary, unpacked), we experimented with multiple word embeddings for our task, we observed similar results with different sizes, and due to space constraints we report results with embedding size = 200. We performed 10-fold cross validation and calculated weighted macro accuracy, memory and F1 values. We used \"adam\" for CNN and LSTM and \"RMS-Prop\" for FastText as our optimizer."}, {"heading": "3.2 Results and Analysis", "text": "Table 1 shows the results of various methods for detecting hate speech. Part A shows results for base embedding methods. Part B and C focus on the proposed methods, where Part B contains only methods that use neural networks, while Part C uses average embedded words learned from DNNs as characteristics for GBDTs. We experimented with mul-2http: / / nlp.stanford.edu / projects / glove / 3https: / / github.com / pinkeshbadjatiya / twitter-hatespeechtiple classifiers, but mostly report the results only for GBDTs, due to space constraints. As the table shows, our proposed methods in Part B are significantly better than the base methods in Part A. Among base methods, the word-TF-IDF method is better than the letter-n-gram method. Under Part B methods, CNN has achieved better results than LSTM methods, which are better than text."}, {"heading": "4. CONCLUSIONS", "text": "In this paper, we investigated the use of deep neural network architectures to detect hate speech and found that they significantly exceed existing methods. Embedding deep neural network models in combination with gradient-enhanced decision trees resulted in the best accuracy values. In the future, we plan to investigate the role of user network functions in the task."}, {"heading": "5. REFERENCES", "text": "[1] N. Djuric, J. Zhou, R. Morris, M. Grbovic, V. Radosavljevic, and N. Bhamidipati. Hate Speech Detection with Comment Embeddings. In WWW, pp. 29-30, 2015. [2] A. Joulin, E. Grave, P. Bojanowski, and T. Mikolov. Bag of Tricks for Efficient Text Classification. arXiv preprint arXiv: 1607.01759, 2016. [3] Y. Kim. Convolutional Neural Networks for Sentence Classification. In EMNLP, pp. 1746-1751, 2014. [4] C. Nobata, J. Tetreault, A. Thomas, Y. Mehdad, and Y. Chang. Abusive Language Detection in Online User Content. In WWW, pp. 145-153, 2016. [5] J. Pennington, R. Socher, and C. D. Manning. GloVe: Global Vectors for Online User Content."}], "references": [{"title": "Hate Speech Detection with Comment Embeddings", "author": ["N. Djuric", "J. Zhou", "R. Morris", "M. Grbovic", "V. Radosavljevic", "N. Bhamidipati"], "venue": "In WWW,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Bag of Tricks for Efficient Text Classification", "author": ["A. Joulin", "E. Grave", "P. Bojanowski", "T. Mikolov"], "venue": "arXiv preprint arXiv:1607.01759,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Convolutional Neural Networks for Sentence Classification", "author": ["Y. Kim"], "venue": "In EMNLP, pages 1746\u20131751,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Abusive Language Detection in Online User Content", "author": ["C. Nobata", "J. Tetreault", "A. Thomas", "Y. Mehdad", "Y. Chang"], "venue": "In WWW,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "GloVe: Global Vectors for Word Representation", "author": ["J. Pennington", "R. Socher", "C.D. Manning"], "venue": "In EMNLP,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter", "author": ["Z. Waseem", "D. Hovy"], "venue": "In NAACL-HLT,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}], "referenceMentions": [{"referenceID": 5, "context": "Most of the earlier work revolves either around manual feature extraction [6] or use representation learning methods followed by a linear classifier [1, 4].", "startOffset": 74, "endOffset": 77}, {"referenceID": 0, "context": "Most of the earlier work revolves either around manual feature extraction [6] or use representation learning methods followed by a linear classifier [1, 4].", "startOffset": 149, "endOffset": 155}, {"referenceID": 3, "context": "Most of the earlier work revolves either around manual feature extraction [6] or use representation learning methods followed by a linear classifier [1, 4].", "startOffset": 149, "endOffset": 155}, {"referenceID": 5, "context": "As baselines, we compare with feature spaces comprising of char n-grams [6], TF-IDF vectors, and Bag of Words vectors (BoWV).", "startOffset": 72, "endOffset": 75}, {"referenceID": 5, "context": "(1) Char n-grams: It is the state-ofthe-art method [6] which uses character n-grams for hate speech detection.", "startOffset": 51, "endOffset": 54}, {"referenceID": 2, "context": "al [3]\u2019s work on using CNNs for sentiment classification, we leverage CNNs for hate speech detection.", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "We use the same settings for the CNN as described in [3].", "startOffset": 53, "endOffset": 56}, {"referenceID": 5, "context": "Part A: Baselines Char n-gram+Logistic Regression [6] 0.", "startOffset": 50, "endOffset": 53}, {"referenceID": 1, "context": "(3) FastText: FastText [2] represents a document by average of word vectors similar to the BoWV model, but allows update of word vectors through Back-propagation during training as opposed to the static word representation in the BoWV model, allowing the model to fine-tune the word representations according to the task.", "startOffset": 23, "endOffset": 26}, {"referenceID": 5, "context": "We experimented with a dataset of 16K annotated tweets made available by the authors of [6].", "startOffset": 88, "endOffset": 91}, {"referenceID": 4, "context": "For the embedding based methods, we used the GloVe [5] pre-trained word embeddings.", "startOffset": 51, "endOffset": 54}], "year": 2017, "abstractText": "Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. The complexity of the natural language constructs makes this task very challenging. We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity. Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by \u223c18 F1 points.", "creator": "LaTeX with hyperref package"}}}