{"id": "1706.00245", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2017", "title": "Polish Read Speech Corpus for Speech Tools and Services", "abstract": "This paper describes the speech processing activities conducted at the Polish consortium of the CLARIN project. The purpose of this segment of the project was to develop specific tools that would allow for automatic and semi-automatic processing of large quantities of acoustic speech data. The tools include the following: grapheme-to-phoneme conversion, speech-to-text alignment, voice activity detection, speaker diarization, keyword spotting and automatic speech transcription. Furthermore, in order to develop these tools, a large high-quality studio speech corpus was recorded and released under an open license, to encourage development in the area of Polish speech research. Another purpose of the corpus was to serve as a reference for studies in phonetics and pronunciation. All the tools and resources were released on the the Polish CLARIN website. This paper discusses the current status and future plans for the project.", "histories": [["v1", "Thu, 1 Jun 2017 10:27:07 GMT  (561kb,D)", "http://arxiv.org/abs/1706.00245v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["danijel kor\\v{z}inek", "krzysztof marasek", "{\\l}ukasz brocki", "krzysztof wo{\\l}k"], "accepted": false, "id": "1706.00245"}, "pdf": {"name": "1706.00245.pdf", "metadata": {"source": "CRF", "title": "Polish Read Speech Corpus for Speech Tools and Services", "authors": ["Danijel Kor\u017einek"], "emails": ["(danijel@pja.edu.pl", "kmarasek@pja.edu.pl", "lucas@pja.edu.pl", "kwolk)@pja.edu.pl"], "sections": [{"heading": "1 Introduction", "text": "Much of the data used in the humanities and social sciences (HSS) is stored in the form of audio recordings, such as radio and television programs, interviews, public speeches (e.g. parliament, public events), lectures, films, literary readings, and other voice recordings. These data contain valuable information from many aspects of HSS research, including both the linguistic (with emphasis on vocabulary and pronunciation) and sociological (emphasis on speakers) viewpoints. During our project, we met many scientists who have shown interest in processing either existing data and corpora, or who would like to process recordings (e.g. interviews) they wanted to make in the future. The main problem with processing acoustic data is that it is more expensive and time consuming than, for example, traditional textual data. It requires both the know-how and many efforts to achieve comparable results."}, {"heading": "2 Speech Tools", "text": "One of the earliest decisions during the project was the release of all tools in the form of web services and not downloadable applications. This has many advantages: ease of use (no installation required), better support, stable environment and performance. However, there are also some disadvantages: higher effort on the part of the consortium, increased response time when many people use the platform, problems in releasing sensitive data. Most of these were done individually and by releasing the source code of the tools for ambitious individuals.The main website at http: / / mowa.clarin-pl.eu was divided into three sections: voice corpora downloads, graph-to-phoneme conversion (G2P) and the rest of the language processing tools. The reason for removing the G2P from the rest of the tools is that it uses a different set of modalities (i.e. text-to-text) from the remaining tools (audio and optional text to text)."}, {"heading": "2.1 Grapheme-to-phoneme conversion", "text": "This tool enables the conversion of text written in orthographic (i.e. written) form into its phonetic (i.e. spoken) form. It is one of the primary steps in any process involving speech data, but can also serve as a tool outside the context of acoustic speech processing. It is created using a rules-based system. It accepts any form of text even though it does not perform text normalization (it does not automatically augment numbers, dates or abbreviations). The tool is completely rules-based and contains a list of exceptions for names, foreign and other atypical words. A statistical system based on the Sequitur tool (Bisani and Ney, 2008) is also available, but based on available data it does not exceed the rules-based system in any way. The tool can generate both word lists (with multiple pronunciation) and a canonical transcription of text, while several improvements are planned for the future of this tool."}, {"heading": "2.2 Speech-to-text alignment", "text": "Language alignment is one of the most useful tools available. It is used to align a sequence of words to the provided audio recording of speech. It can be understood simply as the automatic generation of a set of time codes if both the audio and its transcription are known. It is a very useful tool because it can be used to easily look up specific events in large groups of recordings. It also allows to calculate statistics relating to the duration and other features of individual language happenings.The tool was created based on the SailAlign concept (Katsamanis et al., 2011) to efficiently work with long audio files. The machine is constructed around the Kaldi toolkit (Povey et al., 2011), just like most tools in this paper, but the main workflow is managed with a set of libraries written in Java. The alignment is generated both at the word level and at the textual level of the tool currently available in a phoneme file."}, {"heading": "2.3 Voice activity detection", "text": "Voice Activity Detection (VAD) is often found as a pre-processing step of many speech processing tools. Its purpose is to isolate portions of audio that contain speech from those that contain other types of acoustic events, such as silence, noise or music. Apart from the above-mentioned use as a pre-processing step, it can also be useful as an indexing tool for large volumes of audio. This tool is completely language and domain independent, although it can fail with very loud data. This tool was designed with an artificial neural network-based classifier that performs VAD online. Non-speech data is further analyzed by using an SVM classifier to try to classify types of noise. This last step has not been very thoroughly developed and works, depending on the data, rather poorly, but given the proper use case and training data, it could be modified to make it work better for projects already known as VAD and more likely to work."}, {"heading": "2.4 Speaker diarization", "text": "This tool is used to segment a large audio file into parts spoken by individual speakers. There are several types of speaker-related segmentation strategies that can be performed: speaker replacement detection only recognizes the segments in which different speakers speak, speaker diarization additionally explains which segments belong to the same speaker, and speaker identification accurately detects who the speaker is in each segment (e.g. by its name). Our tool only works with the second algorithm. It is mainly useful for adapting different tools and models to individual speakers, but some researchers have mentioned that they would like to use it for other analyses that require speaker segmentation. Our tool is based on the LIUM toolkit (Meignier and Merlin, 2010) and just like the previous one it is completely language independent. Other toolkits have also been tested during the project (e.g. SUT (Huibrets 2006, but seemed to work best)."}, {"heading": "2.5 Keyword spotting", "text": "Often, an exact transcription of audio material is not necessary because we are only interested in individual words that occur in the text. Keyword spotting (KWS) is a process that records an audio file with a list of keywords and creates a list of their occurrences in the audio file. Our system is based on the Kaldi toolkit, but is also expanded to support an open vocabulary scenario. Given the limited vocabulary size of the language model, it would be impossible to predict all the words that people can look for. Therefore, our system uses a combination of words and syllables so that when a word needs to be found from the vocabulary, we use its syllable representation instead. This makes the tool sometimes more useful than the full language transcription, because it can handle words that lie outside the vocabulary (OOV), but is more prone to errors if a word from the vocabulary is found, its word must still be found, its syllable transcription is relative to the other word (where the word is very phonetic)."}, {"heading": "2.6 Automatic speech transcription", "text": "This tool uses an automatic speech recognition system (ASR) (based on the Kaldi toolkit) to generate a probable orthographic transliteration of the Polish language audio recording. Originally, this tool was not intended for inclusion in the project, but was added due to the overwhelming interest in the second part of the project. The current system uses our Euronews radio message detection model (Marasek et al., 2014) and for it to be useful for other types of recording, it needs to be adapted to the appropriate area. For more details on the architecture developed, see Section 3.1 below."}, {"heading": "3 Speech Corpus", "text": "Most of the tools mentioned in the previous section require a large set of high-quality recordings, which are usually expensive to produce, and even if such data can be purchased from third parties, they are usually very expensive and out of reach for most researchers. Prior to our work, there was no free, high-quality, large vocabulary Polish-language audio corpus. Our goal was to create such a corpus and release it on an open license for both commercial and non-commercial use. The corpus was recorded in a studio environment with two microphones: a high-quality studio microphone and a typical consumer audio headset. The corpus consists of 317 speakers recorded in 554 sessions, with each session consisting of 20 read sentences and 10 phonetically rich words. The size of the audio part of the corpus is approximately 56 hours, with a studio consisting of 361 small-sized telephone systems with a 661word corpus."}, {"heading": "3.1 Baseline speech recognition system", "text": "Given that the main purpose of preparing the Corpus was to develop language tools, it seemed to deliver the Corpus in a form that makes it easy to use such a tool. As most of the tools mentioned in the previous chapter rely on the Kaldi speech recognition system, a policy program for developing such a tool that can change anything has been designed, and the main idea is to have all the tools in one folder, with a main script from start to finish."}, {"heading": "4 Applications", "text": "Some projects have already used our tools and resources for their own purposes; our language alignment tool was used by a consortium partner to further comment on the corpora on their Spokes platform (Pezik, 2015); the studio language corpus was used in an essay by a Czech research team (Nouza et al., 2015); we also managed to collaborate with a team from the Institute of Applied Linguistics at the University of Warsaw on their project entitled \"Respeaking - the process, competences and quality\" (project code NCN - OPUS6 -2013 / 11 / B / HS2 / 02762); and finally, one of the most interested groups was sociologists interested in the automatic transliteration of sociological interviews; we managed to obtain several hours of recordings from a group of researchers from the Cardinal Wyszyn-ski University in Warsaw."}, {"heading": "5 Future plans", "text": "As the project is extended for a further two years, several improvements are planned, with a focus on developing working speech recognition solutions for the above areas. To achieve this, certain tools such as G2P conversion including text normalization and possibly other modules such as speaker diarization and VAD will need to be improved, but the biggest improvements will be in the speech recognition engine itself. Many experiments are planned, including various customization techniques, Deep Neural Network for Acoustic Modeling (Vu et al., 2014), Recurrent Neural Networks for Language Modeling (Mikolov et al., 2013). No new corpora will be recorded, although much data will need to be collected to adapt the tools to their respective domains. It is unclear whether all the data will be released to other researchers due to legal concerns. Our primary intention will be to improve the services available on our website and make the trained models and tools available free of charge so that they can be used for other purposes that are necessary."}, {"heading": "6 Acknowledgments", "text": "The activities described in this article were financed by the Clarin PL project, which was partially supported by infrastructure acquired under the Heterogeneous Computation Cloud project, which is financed by the Mazovian Regional Operational Programme."}], "references": [{"title": "Joint-sequence models for grapheme-tophoneme conversion", "author": ["Bisani", "Ney2008] Maximilian Bisani", "Hermann Ney"], "venue": "Speech Communication,", "citeRegEx": "Bisani et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bisani et al\\.", "year": 2008}, {"title": "Praat, a system for doing phonetics by computer", "author": ["Boersma"], "venue": "Glot international,", "citeRegEx": "Boersma and Boersma,? \\Q2002\\E", "shortCiteRegEx": "Boersma and Boersma", "year": 2002}, {"title": "Multiple model text normalization for the polish language", "author": ["Brocki et al.2012] \u0141ukasz Brocki", "Krzysztof Marasek", "Danijel Kor\u017einek"], "venue": "In International Symposium on Methodologies for Intelligent Systems,", "citeRegEx": "Brocki et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Brocki et al\\.", "year": 2012}, {"title": "Multi-level annotation in the emu speech database management system", "author": ["Cassidy", "Harrington2001] Steve Cassidy", "Jonathan Harrington"], "venue": "Speech Communication,", "citeRegEx": "Cassidy et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Cassidy et al\\.", "year": 2001}, {"title": "Sailalign: Robust long speech-text alignment", "author": ["Matthew Black", "Panayiotis G Georgiou", "Louis Goldstein", "S Narayanan"], "venue": "In Proc. of Workshop on New Tools and Methods for Very-Large Scale Phonetics Research", "citeRegEx": "Katsamanis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Katsamanis et al\\.", "year": 2011}, {"title": "P\u00c3\u0171rner. 2016. Bas speech science web services - an update of current developments", "author": ["Kisler et al.2016] Thomas Kisler", "Uwe Reichel", "Florian Schiel", "Christoph Draxler", "Bernhard Jackl", "Nina"], "venue": "In Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016),", "citeRegEx": "Kisler et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kisler et al\\.", "year": 2016}, {"title": "Avatech\u00e2\u0102\u0162automated annotation through audio and video analysis", "author": ["Eric Auer", "Oliver Schreer", "Stefano Masneri", "Daniel Schneider", "Sebastian Tsch\u00f6pe"], "venue": "In LREC 2012: 8th International Conference on Language Resources and Evaluation,", "citeRegEx": "Lenkiewicz et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lenkiewicz et al\\.", "year": 2012}, {"title": "Spoken language translation for polish. Forum Acousticum", "author": ["Krzysztof Wo\u0142k", "Danijel Kor\u017einek", "\u0141ukasz Brocki", "Ryszard Gubrynowicz"], "venue": null, "citeRegEx": "Marasek et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marasek et al\\.", "year": 2014}, {"title": "Lium spkdiarization: an open source toolkit for diarization", "author": ["Meignier", "Merlin2010] Sylvain Meignier", "Teva Merlin"], "venue": "In CMU SPUD Workshop,", "citeRegEx": "Meignier et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Meignier et al\\.", "year": 2010}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Cross-lingual adaptation of broadcast transcription system to polish language using public data sources. In 7th Language & Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics, Poland, pages 181\u2013185", "author": ["Nouza et al.2015] Jan Nouza", "Petr Cerva", "Radek Safarik"], "venue": null, "citeRegEx": "Nouza et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nouza et al\\.", "year": 2015}, {"title": "Spokes-a search and exploration service for conversational corpus data", "author": ["Piotr Pezik"], "venue": "In Selected Papers from the CLARIN 2014 Conference, October 24-25,", "citeRegEx": "Pezik.,? \\Q2015\\E", "shortCiteRegEx": "Pezik.", "year": 2015}, {"title": "The kaldi speech recognition toolkit", "author": ["Povey et al.2011] Daniel Povey", "Arnab Ghoshal", "Gilles Boulianne", "Lukas Burget", "Ondrej Glembek", "Nagendra Goel", "Mirko Hannemann", "Petr Motlicek", "Yanmin Qian", "Petr Schwarz", "Jan Silovsky", "Georg Stemmer", "Karel Vesely"], "venue": "In IEEE 2011 Workshop on Automatic Speech Recognition and Understanding", "citeRegEx": "Povey et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Povey et al\\.", "year": 2011}, {"title": "Multilingual deep neural network based acoustic modeling for rapid language adaptation", "author": ["Vu et al.2014] Ngoc Thang Vu", "David Imseng", "Daniel Povey", "Petr Motlicek", "Tanja Schultz", "Herv\u00e9 Bourlard"], "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Vu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Vu et al\\.", "year": 2014}, {"title": "Introducing a web application for labeling, visualizing speech and correcting derived speech signals", "author": ["Winkelmann", "Raess2014] Raphael Winkelmann", "Georg Raess"], "venue": "In LREC,", "citeRegEx": "Winkelmann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Winkelmann et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 5, "context": "Similar efforts in other Clarin consortia already exist, like WebMAUS (Kisler et al., 2016) speech segmentation services at LMU, AVATech (Lenkiewicz et al.", "startOffset": 70, "endOffset": 91}, {"referenceID": 6, "context": ", 2016) speech segmentation services at LMU, AVATech (Lenkiewicz et al., 2012) by Max Planck Institute and Fraunhofer Institute which provide video and audio processing services including speech segmentation, VAD and speaker diarization, and TTNWW (CLARIN-NL, 2013) which includes speech transcription services for Dutch.", "startOffset": 53, "endOffset": 78}, {"referenceID": 2, "context": "This work is already in progress as of writing this paper (Brocki et al., 2012).", "startOffset": 58, "endOffset": 79}, {"referenceID": 4, "context": "The tool was created, based on the SailAlign (Katsamanis et al., 2011) concept, in order to work efficiently with long audio files.", "startOffset": 45, "endOffset": 70}, {"referenceID": 12, "context": "The engine is constructed around the Kaldi toolkit (Povey et al., 2011), just like most of the tools in this paper, but the main work-flow is managed using a set of libraries written in Java.", "startOffset": 51, "endOffset": 71}, {"referenceID": 7, "context": "The current system uses our Euronews model for recognizing broadcast news (Marasek et al., 2014) and in order for it to be useful for other types of recordings, it has to be adapted to the proper domain.", "startOffset": 74, "endOffset": 96}, {"referenceID": 11, "context": "Our speech alignment tool was used by a consortium partner in order to further annotate the corpora on their Spokes platform (Pezik, 2015).", "startOffset": 125, "endOffset": 138}, {"referenceID": 10, "context": "The studio speech corpus was used in a paper by a Czech research team (Nouza et al., 2015).", "startOffset": 70, "endOffset": 90}, {"referenceID": 13, "context": "Many experiments are planned, including various adaptation techniques, Deep Neural Network for acoustic modeling (Vu et al., 2014), Recurrent Neural Networks for language modeling (Mikolov et al.", "startOffset": 113, "endOffset": 130}, {"referenceID": 9, "context": ", 2014), Recurrent Neural Networks for language modeling (Mikolov et al., 2013).", "startOffset": 57, "endOffset": 79}], "year": 2017, "abstractText": "This paper describes the speech processing activities conducted at the Polish consortium of the CLARIN project. The purpose of this segment of the project was to develop specific tools that would allow for automatic and semi-automatic processing of large quantities of acoustic speech data. The tools include the following: grapheme-to-phoneme conversion, speech-to-text alignment, voice activity detection, speaker diarization, keyword spotting and automatic speech transcription. Furthermore, in order to develop these tools, a large high-quality studio speech corpus was recorded and released under an open license, to encourage development in the area of Polish speech research. Another purpose of the corpus was to serve as a reference for studies in phonetics and pronunciation. All the tools and resources were released on the the Polish CLARIN website. This paper discusses the current status and future plans for the project.", "creator": "LaTeX with hyperref package"}}}