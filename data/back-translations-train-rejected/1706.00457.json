{"id": "1706.00457", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2017", "title": "NMTPY: A Flexible Toolkit for Advanced Neural Machine Translation Systems", "abstract": "In this paper, we present nmtpy, a flexible Python toolkit based on Theano for training Neural Machine Translation and other neural sequence-to-sequence architectures. nmtpy decouples the specification of a network from the training and inference utilities to simplify the addition of a new architecture and reduce the amount of boilerplate code to be written. nmtpy has been used for LIUM's top-ranked submissions to WMT Multimodal Machine Translation and News Translation tasks in 2016 and 2017.", "histories": [["v1", "Thu, 1 Jun 2017 18:57:39 GMT  (638kb,D)", "http://arxiv.org/abs/1706.00457v1", "10 pages, 3 figures"]], "COMMENTS": "10 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ozan caglayan", "mercedes garc\\'ia-mart\\'inez", "adrien bardet", "walid aransa", "fethi bougares", "lo\\\"ic barrault"], "accepted": false, "id": "1706.00457"}, "pdf": {"name": "1706.00457.pdf", "metadata": {"source": "CRF", "title": "NMTPY: A FLEXIBLE TOOLKIT FOR ADVANCED NEURAL MACHINE TRANSLATION SYSTEMS", "authors": ["Ozan Caglayan", "Mercedes Garc\u00eda-Mart\u00ednez", "Adrien Bardet", "Walid Aransa", "Fethi Bougares", "Lo\u00efc Barrault"], "emails": [], "sections": [{"heading": "1 OVERVIEW", "text": "nmtpy is a refactored, extended and Python 3 only version of dl4mt-tutorial 1, a Theano (Theano Development Team, 2016) implementation of attentive Neural Machine Translation (NMT) (Bahdanau et al., 2014).Development of the nmtpy project, which was open-sourced2 under the MIT license in March 2017, began in March 2016 as an attempt to adapt dl4mt-tutorial to multimodal translation models. Adding a new model is now as simple as deriving it from an abstract base class to complement a set of basic methods and (optionally) implementing a custom data iterator. The training and inference tools are as model agnostic as possible so that they can be used for various sequence generation networks such as multimodal NMT and image captions, to name a few."}, {"heading": "2 WORKFLOW", "text": "Figure 1 describes the general workflow of a training course. An experiment in nmtpy is described with a configuration file (Appendix A) to ensure reusability and reproducibility; a training experiment can be started simply by passing this configuration file to nmt-train, which builds the environment and starts the training. nmt-train automatically selects a free GPU, sets the seed for all random number generators, and finally creates a model _ type option instance. Architecture-specific steps such as data loading, weight initialization, and graph construction are delegated to the model instance. The corresponding log file and model checkpoints are named to reflect the experiment options set by the configuration file (example: model _ type-e < embdim > -r < rnndim > - < opt > _ < lrate >...)."}, {"heading": "2.1 ADDING NEW ARCHITECTURES", "text": "New architectures can be defined by creating a new file under nmtpy / models / using a copy of an existing architecture and changing the following predefined methods: \u2022 _ _ init _ _ (): Instantiates a model. Keyword arguments can be used to add architecture-specific options that are automatically collected by nmt-train from the configuration file. \u2022 init _ params (): Initializes the layers and weights. \u2022 build (): Defines the theano computation graph to be used during the training. \u2022 build _ sampler (): Defines the theano computation graph to be used during the beam search. This is generally very similar to build (), but with sequential RNN steps and unmasked tensors. \u2022 load _ valid _ data (): Loads the validation data for the perplexity computation. \u2022 load _ data (): Loads the training data."}, {"heading": "2.2 BUILDING BLOCKS", "text": "In this section we present the currently available components and features of nmtpy that can be used to design your architecture."}, {"heading": "3 ARCHITECTURES", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 NMT", "text": "The standard NMT architecture (Attention) is based on the original dl4mt tutorial implementation, which differs from Bahdanau et al. (2014) in the following main aspects: \u2022 CGRU decoder, which consists of two GRU layers intertwined with attention mechanism. \u2022 The hidden state of the decoder is initialized with a nonlinear transformation applied to the bi-directional encoder state, as opposed to the last bi-directional encoder state. \u2022 The hidden layer before the Softmax operation is removed. Furthermore, nmtpy provides the following configurable options for this NMT: \u2022 layer _ norm Enables / disables layer normalization for bi-directional GRU encoder. \u2022 init _ cgru Allows the initialization of CGRU with all zeros instead of the middle encoder state. \u2022 n _ encoding the number of additional CROctu encoder encoders for the soft GRU encoder state."}, {"heading": "3.2 FACTORED NMT", "text": "Factored NMT (FNMT) is an extension of NMT that is capable of generating two output symbols. The architecture of such a model is illustrated in Figure 2. Unlike multi-task architectures, FNMT output shares the same repetition and output symbols are generated synchronously.Two FNMT variants, which differ in the way they handle the output layer, are currently available: \u2022 attention _ factors: The lemma and factor embedding are linked to a single feedback embedding. \u2022 attention _ factors _ seplogits: The output path for lemmats and factors is separated by different pressoftmax transformations applied for specialization. FNMT with Lemmata and linguistic factors has been successfully used for IWSLT '16 English \u2192 French (Garc\u00eda-Mart\u00edneal \u2192 2016, Letter \u2192 17K English and MT evaluation languages."}, {"heading": "3.3 MULTIMODAL NMT & CAPTIONING", "text": "We provide multiple multimodal architectures (Caglayan et al., 2016a; b) where the probability of a target word depends on source set representations and Convolutionary image features (Figure 3). Specifically, these architectures expand the monomodal CGRU into a multimodal one where the attention mechanism can be divided or separated between input modalities. A late merging of the visited context vectors occurs either by summing or concatenating the modality-specific representations. Our attentive multimodal system for generating multilingual image descriptions of WMT '16 Multimodal Machine Translation exceeded the base architecture (Elliott et al., 2015) by + 1.1 METEOR and + 3.4 BLEU and took first place among the multimodal submissions (Specia et al., 2016)."}, {"heading": "3.4 LANGUAGE MODELING", "text": "A GRU-based language model architecture (rnnlm) is available in the repository, which can mainly be used with nmt-test-lm to achieve language model valuations.3FNMT currently uses a special nmt-translate-factors utility, although it is likely to be merged in the near future.4http: / / matrix.statmt.org / Decoder with Multimodal AttentionTextual EncoderImageVisual Encoder (CNN) In the review as a conference paper for ICLR 2016CNN, children sit in a classroom + RNSchoolchildren sit n in a classroomFigure 1: An illustration of the multilingual multimodal language model shows that image descriptions are generated by combining features from the source and target languages multimodal language models. The dashed lines denote variants of the model: Removing CNN features from a source model would generate language conditioning that only have vectors."}, {"heading": "2 MODELS", "text": "Our multilingual image description models are models for generating neural sequences, with additional input from either visual or linguistic modalities, or both. We present a series of models of increasing complexity to demonstrate their compositional character, starting with a neural sequence model, through words, to the complete model with image and source attributes. See Figure 2 for a representation of the model architecture."}, {"heading": "2.1 RECURRENT LANGUAGE MODEL (LM)", "text": "The core of our model is a recursive neural network model of word sequences, i.e. a neural language model (LM) (Mikolov et al., 2010). The model is trained to predict the next word in the sequence, given the current sequence seen so far. At each time step i for the input sequence w0... n, the input word wi, which is represented as a hot vector over the vocabulary, is embedded in a high-dimensional continuous vector using the learned embedding matrix Woe (Eqn 1). A nonlinear function f is applied to the embedding of words in combination with the previous hidden state to generate the hidden state hi (Eqn 2). At the output level, the next word oi is predicted via the Softmax function via the 2Feature MapsAnnotation VectorsSource wordsFigure 3: The multimodal Caglaet (2016b)."}, {"heading": "3.5 IMAGE CAPTIONING", "text": "A GRU-based implementation of the Show, Attend and Tell architecture (Xu t al., 2015), which learns to create a natural language description by paying gentle attention to revolutionary image features, is available under th nam i g2t. This architecture is used as the base system for the Multilingual Image Description Generation track of WMT '17 Multimodal Machine Translation shared task."}, {"heading": "4 TOOLS", "text": "In this section we present the translation and absorption programs nmt-translate and nmt-rescore."}, {"heading": "4.1 NMT-TRANSLATE", "text": "nmt-translate is responsible for decoding the translation using the beam search method defined by the NMT architecture. This standard beam search supports the decoding of single and total contexts for both monomodal and multimodal translation models. When a g ven architecture re-implements the beam search method in its class, it is used unreliable.Since the number of CPUs in a single machine is 2-4x higher than the number of GPUs and we reserve the GPUs mainly for training, nmt-translate uses CPU staff for maximum efficiency. Specifically, each worker rec ives a m del in tan (or i st nces in the assembling) and performs the beam search for samples, which he continuously retrieves from a common queue. This queue is filled by the r process mast using the rator provided by the modeler."}, {"heading": "4.2 NMT-RESCORE", "text": "A file with the 1-best plain text or n-best hypotheses can be rescored with nmt-rescore using either a single or an entire set of models. Since the rescoring file of a given hypothesis simply means the negative5http: / / www.statmt.org / wmt17 / multimodal-task.html 6This is achieved by setting X _ NUM _ THREADS = 1 environment variable, where X is one of OPENBLAS, OMP, MKL depending on the number of installed.log probabilities that it will be used based on the source set, nmt-rescore uses a single GPU to efficiently calculate the values in batch mode. See Appendix B for examples."}, {"heading": "5 CONCLUSION", "text": "We introduced nmtpy, an open source sequence-to-sequence framework based on dl4mt tutorial that has been refined in many ways to facilitate the task of integrating new architectures, and the toolkit has been used internally within our team for tasks ranging from monomodal, multimodal and factorized NMT to captions and voice modeling to contribute to world-class submissions in campaigns such as IWSLT and WMT."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work was supported by the French research agency ANR as part of the CHIST-ERA M2CR project under contract number ANR-15-CHR2-0006-017."}, {"heading": "A CONFIGURATION FILE EXAMPLE", "text": "# Options in this section are used by nmt-train [training] model _ type: attention # Model type without.py patience: 20 # early-stopping patience valid _ freq: 1000 # Compute metrics each 1000 updates valid _ metric: meteor # Use meteor during validations valid _ start: 2 # Start validations after 2nd epoch valid _ beam: 3 # Decode with beam size 3 valid _ njobs: 16 # Use 16 processes for beam-search valid _ save _ hyp: True # Save validation hypotheses decay _ c: 1e-5 # L2 regularization factor clip _ c: 5 # Gradient clip threshold seed: 1235 # Seed for numpy and Theano RNG save _ best _ n: 2 # keep 2 best models on-disk device _ id: auto # Pick 1st GPU snapshot _ freq: 10000 # Save a resumeable snapshot _ c: 1 # Betrapshot... po gr type _ save value # Early type attention # 5 # Betrid: Searching for a valid value # valid: 2nd valid: # betrapshot value # it: # betrp _ value at the value at the beginning of a valid: 1."}, {"heading": "B USAGE EXAMPLES", "text": "# Start an experiment with a different architecture $nmt-train -c wmt-en-en.conf # Start an experiment with a different architecture $nmt-train -c wmt-en-en.conf \"model _ type: my _ amazing _ nmt\" # Change dimensions $nmt-train -c wmt-en-en.conf \"rnn _ dim: 500\" \"\" embedding _ dim: 300 \"# Force specific GPU device $nmt-train -c wmt-en-en.conf\" device _ id: gpu5 'Listing 1: Example usage pattern for nmt-train. # Decode on 30 CPUs with beam size 10, compute BLEU / METEOR # Language for METEOR is set through source file suffix (.en) $nmt-translate-translate -S-30 -m best _ model.npz -S val.kval.bpe.en -kcore\\ toktok.tok.de -outtok.resources.tok.de -us.de-"}, {"heading": "C DESCRIPTION OF THE PROVIDED TOOLS", "text": "nmt-build-dict Generates.pkl vocabulary files from a preprocessed corpus. A single / combined vocabulary for two or more languages can be extracted from a model overview using -s flag.nmt-extract to extract any weights that can be used further than pre-trained weights of a new experiment or analyzed using visualization techniques (especially for embedding). nmt-coco-metrics A standalone tool that can be calculated using -s flag multiple references BLEU, METEOR, CIDE-r (Vedantam et al., 2015) and ROUGE-L (Lin, 2004) can be given using MSCOCO evaluation tools (Chen et al., 2015). Multiple systems can be given with -s flag to generate a table of results. nmt-bpe- (learn, apply) Copy of subword 8 (subnbrich et) can be used with -s flag to generate a table of results."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1409.0473,", "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Does multimodality help human and machine for translation and image captioning", "author": ["Ozan Caglayan", "Walid Aransa", "Yaxing Wang", "Marc Masana", "Mercedes Garc\u00eda-Mart\u00ednez", "Fethi Bougares", "Lo\u00efc Barrault", "Joost van de Weijer"], "venue": "In Proceedings of the First Conference on Machine Translation,", "citeRegEx": "Caglayan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Caglayan et al\\.", "year": 2016}, {"title": "Multimodal attention for neural machine translation", "author": ["Ozan Caglayan", "Lo\u00efc Barrault", "Fethi Bougares"], "venue": "arXiv preprint arXiv:1609.03976,", "citeRegEx": "Caglayan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Caglayan et al\\.", "year": 2016}, {"title": "Microsoft coco captions: Data collection and evaluation", "author": ["Xinlei Chen", "Hao Fang", "Tsung-Yi Lin", "Ramakrishna Vedantam", "Saurabh Gupta", "Piotr Doll\u00e1r", "C Lawrence Zitnick"], "venue": "server. arXiv preprint arXiv:1504.00325,", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "\u00c7aglar G\u00fcl\u00e7ehre", "KyungHyun Cho", "Yoshua Bengio"], "venue": "CoRR, abs/1412.3555,", "citeRegEx": "Chung et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "Multi-language image description with neural sequence models", "author": ["Desmond Elliott", "Stella Frank", "Eva Hasler"], "venue": "CoRR, abs/1510.04709,", "citeRegEx": "Elliott et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Elliott et al\\.", "year": 2015}, {"title": "Conditional gated recurrent unit with attention mechanism", "author": ["Orhan Firat", "Kyunghyun Cho"], "venue": null, "citeRegEx": "Firat and Cho.,? \\Q2016\\E", "shortCiteRegEx": "Firat and Cho.", "year": 2016}, {"title": "Factored neural machine translation architectures", "author": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"], "venue": "In Proceedings of the International Workshop on Spoken Language Translation,", "citeRegEx": "Garc\u00eda.Mart\u00ednez et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Garc\u00eda.Mart\u00ednez et al\\.", "year": 2016}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["Xavier Glorot", "Yoshua Bengio"], "venue": "Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS\u201910). Society for Artificial Intelligence and Statistics,", "citeRegEx": "Glorot and Bengio.,? \\Q2010\\E", "shortCiteRegEx": "Glorot and Bengio.", "year": 2010}, {"title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": "In Computer Vision (ICCV),", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Tying word vectors and word classifiers: A loss framework for language modeling", "author": ["Hakan Inan", "Khashayar Khosravi", "Richard Socher"], "venue": "arXiv preprint arXiv:1611.01462,", "citeRegEx": "Inan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Inan et al\\.", "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma and Ba.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Meteor: an automatic metric for mt evaluation with high levels of correlation with human judgments", "author": ["Alon Lavie", "Abhaya Agarwal"], "venue": "In Proceedings of the Second Workshop on Statistical Machine Translation,", "citeRegEx": "Lavie and Agarwal.,? \\Q2007\\E", "shortCiteRegEx": "Lavie and Agarwal.", "year": 2007}, {"title": "Rouge: A package for automatic evaluation of summaries", "author": ["Chin-Yew Lin"], "venue": "Text Summarization Branches Out: Proceedings of the ACL-04 Workshop,", "citeRegEx": "Lin.,? \\Q2004\\E", "shortCiteRegEx": "Lin.", "year": 2004}, {"title": "Adding gradient noise improves learning for very deep networks", "author": ["Arvind Neelakantan", "Luke Vilnis", "Quoc V Le", "Ilya Sutskever", "Lukasz Kaiser", "Karol Kurach", "James Martens"], "venue": "arXiv preprint arXiv:1511.06807,", "citeRegEx": "Neelakantan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2015}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu"], "venue": "In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "On the difficulty of training recurrent neural networks", "author": ["Razvan Pascanu", "Tomas Mikolov", "Yoshua Bengio"], "venue": "In Proceedings of The 30th International Conference on Machine Learning,", "citeRegEx": "Pascanu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Pascanu et al\\.", "year": 2013}, {"title": "Using the output embedding to improve language models", "author": ["Ofir Press", "Lior Wolf"], "venue": "arXiv preprint arXiv:1608.05859,", "citeRegEx": "Press and Wolf.,? \\Q2016\\E", "shortCiteRegEx": "Press and Wolf.", "year": 2016}, {"title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "author": ["Andrew M Saxe", "James L McClelland", "Surya Ganguli"], "venue": "arXiv preprint arXiv:1312.6120,", "citeRegEx": "Saxe et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Saxe et al\\.", "year": 2013}, {"title": "A joint dependency model of morphological and syntactic structure for statistical machine translation", "author": ["Rico Sennrich", "Barry Haddow"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Sennrich and Haddow.,? \\Q2015\\E", "shortCiteRegEx": "Sennrich and Haddow.", "year": 2015}, {"title": "Neural machine translation of rare words with subword units. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "author": ["Rico Sennrich", "Barry Haddow", "Alexandra Birch"], "venue": null, "citeRegEx": "Sennrich et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sennrich et al\\.", "year": 2016}, {"title": "Nematus: a Toolkit for Neural Machine Translation, pp. 65\u201368", "author": ["Rico Sennrich", "Orhan Firat", "Kyunghyun Cho", "Alexandra Birch-Mayne", "Barry Haddow", "Julian Hitschler", "Marcin Junczys-Dowmunt", "Samuel L\u00e4ubli", "Antonio Miceli Barone", "Jozef Mokry", "Maria Nadejde"], "venue": "Association for Computational Linguistics (ACL),", "citeRegEx": "Sennrich et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Sennrich et al\\.", "year": 2017}, {"title": "A shared task on multimodal machine translation and crosslingual image description", "author": ["Lucia Specia", "Stella Frank", "Khalil Sima\u2019an", "Desmond Elliott"], "venue": "In Proceedings of the First Conference on Machine Translation,", "citeRegEx": "Specia et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Specia et al\\.", "year": 2016}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey E Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q1929\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 1929}, {"title": "Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude", "author": ["Tijmen Tieleman", "Geoffrey Hinton"], "venue": "COURSERA: Neural networks for machine learning,", "citeRegEx": "Tieleman and Hinton.,? \\Q2012\\E", "shortCiteRegEx": "Tieleman and Hinton.", "year": 2012}, {"title": "Cider: Consensus-based image description evaluation", "author": ["Ramakrishna Vedantam", "C Lawrence Zitnick", "Devi Parikh"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Vedantam et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vedantam et al\\.", "year": 2015}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["Kelvin Xu", "Jimmy Ba", "Ryan Kiros", "Kyunghyun Cho", "Aaron Courville", "Ruslan Salakhudinov", "Rich Zemel", "Yoshua Bengio"], "venue": "In Proceedings of The 32nd International Conference on Machine Learning,", "citeRegEx": "Xu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Adadelta: an adaptive learning rate method", "author": ["Matthew D Zeiler"], "venue": "arXiv preprint arXiv:1212.5701,", "citeRegEx": "Zeiler.,? \\Q2012\\E", "shortCiteRegEx": "Zeiler.", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "1 OVERVIEW nmtpy is a refactored, extended and Python 3 only version of dl4mt-tutorial 1, a Theano (Theano Development Team, 2016) implementation of attentive Neural Machine Translation (NMT) (Bahdanau et al., 2014).", "startOffset": 192, "endOffset": 215}, {"referenceID": 21, "context": "This flexibility and the rich set of provided architectures (Section 3) is what differentiates nmtpy from Nematus (Sennrich et al., 2017) another NMT software derived from dl4mt-tutorial.", "startOffset": 114, "endOffset": 137}, {"referenceID": 27, "context": "Training nmtpy provides Theano implementations of stochastic gradient descent (SGD) and its adaptive variants RMSProp (Tieleman & Hinton, 2012), Adadelta (Zeiler, 2012) and Adam (Kingma & Ba, 2014) to optimize the weights of the trained network.", "startOffset": 154, "endOffset": 168}, {"referenceID": 14, "context": "A preliminary support for gradient noise (Neelakantan et al., 2015) is available for Adam.", "startOffset": 41, "endOffset": 67}, {"referenceID": 16, "context": "Gradient norm clipping (Pascanu et al., 2013) is enabled by default with a threshold of 5 to avoid exploding gradients.", "startOffset": 23, "endOffset": 45}, {"referenceID": 9, "context": "Initialization The weight initialization is governed by the weight_init option and supports Xavier (Glorot & Bengio, 2010) and He (He et al., 2015) initialization methods besides orthogonal (Saxe et al.", "startOffset": 130, "endOffset": 147}, {"referenceID": 18, "context": ", 2015) initialization methods besides orthogonal (Saxe et al., 2013) and random normal.", "startOffset": 50, "endOffset": 69}, {"referenceID": 4, "context": ", 2015) \u2022 Gated Recurrent Unit (GRU) (Chung et al., 2014) \u2022 Conditional GRU (CGRU) (Firat & Cho, 2016) \u2022 Multimodal CGRU (Caglayan et al.", "startOffset": 37, "endOffset": 57}, {"referenceID": 20, "context": "Currently available filters are bpe and compound for cleaning subword BPE (Sennrich et al., 2016) and German compound-splitting (Sennrich & Haddow, 2015) respectively.", "startOffset": 74, "endOffset": 97}, {"referenceID": 15, "context": "\u2022 bleu: Wrapper around Moses multi-bleu BLEU (Papineni et al., 2002) \u2022 bleu_v13a: A Python reimplementation of Moses mteval-v13a.", "startOffset": 45, "endOffset": 68}, {"referenceID": 0, "context": "The default NMT architecture (attention) is based on the original dl4mt-tutorial implementation which differs from Bahdanau et al. (2014) in the following major aspects:", "startOffset": 115, "endOffset": 138}, {"referenceID": 10, "context": "\u2022 tied_emb Allows sharing feedback embeddings and output embeddings (2way) or all embeddings in the network (3way) (Inan et al., 2016; Press & Wolf, 2016).", "startOffset": 115, "endOffset": 154}, {"referenceID": 7, "context": "FNMT with lemmas and linguistic factors has been successfully used for IWSLT\u201916 English\u2192French (Garc\u00eda-Mart\u00ednez et al., 2016) and WMT\u2019174 English\u2192Latvian and English\u2192Czech evaluation campaigns.", "startOffset": 95, "endOffset": 125}, {"referenceID": 5, "context": "Our attentive multimodal system for Multilingual Image Description Generation track of WMT\u201916 Multimodal Machine Translation surpassed the baseline architecture (Elliott et al., 2015) by +1.", "startOffset": 161, "endOffset": 183}, {"referenceID": 22, "context": "4 BLEU and ranked first among multimodal submissions (Specia et al., 2016).", "startOffset": 53, "endOffset": 74}], "year": 2017, "abstractText": "In this paper, we present nmtpy, a flexible Python toolkit based on Theano for training Neural Machine Translation and other neural sequence-to-sequence architectures. nmtpy decouples the specification of a network from the training and inference utilities to simplify the addition of a new architecture and reduce the amount of boilerplate code to be written. nmtpy has been used for LIUM\u2019s topranked submissions to WMT Multimodal Machine Translation and News Translation tasks in 2016 and 2017. 1 OVERVIEW nmtpy is a refactored, extended and Python 3 only version of dl4mt-tutorial 1, a Theano (Theano Development Team, 2016) implementation of attentive Neural Machine Translation (NMT) (Bahdanau et al., 2014). The development of nmtpy project which has been open-sourced2 under MIT license in March 2017, started in March 2016 as an effort to adapt dl4mt-tutorial to multimodal translation models. nmtpy has now become a powerful toolkit where adding a new model is as simple as deriving from an abstract base class to fill in a set of fundamental methods and (optionally) implementing a custom data iterator. The training and inference utilities are as model-agnostic as possible allowing one to use them for different sequence generation networks such as multimodal NMT and image captioning to name a few. This flexibility and the rich set of provided architectures (Section 3) is what differentiates nmtpy from Nematus (Sennrich et al., 2017) another NMT software derived from dl4mt-tutorial.", "creator": "LaTeX with hyperref package"}}}