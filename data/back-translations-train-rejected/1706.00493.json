{"id": "1706.00493", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2017", "title": "Personalized Pancreatic Tumor Growth Prediction via Group Learning", "abstract": "Tumor growth prediction, a highly challenging task, has long been viewed as a mathematical modeling problem, where the tumor growth pattern is personalized based on imaging and clinical data of a target patient. Though mathematical models yield promising results, their prediction accuracy may be limited by the absence of population trend data and personalized clinical characteristics. In this paper, we propose a statistical group learning approach to predict the tumor growth pattern that incorporates both the population trend and personalized data, in order to discover high-level features from multimodal imaging data. A deep convolutional neural network approach is developed to model the voxel-wise spatio-temporal tumor progression. The deep features are combined with the time intervals and the clinical factors to feed a process of feature selection. Our predictive model is pretrained on a group data set and personalized on the target patient data to estimate the future spatio-temporal progression of the patient's tumor. Multimodal imaging data at multiple time points are used in the learning, personalization and inference stages. Our method achieves a Dice coefficient of 86.8% +- 3.6% and RVD of 7.9% +- 5.4% on a pancreatic tumor data set, outperforming the DSC of 84.4% +- 4.0% and RVD 13.9% +- 9.8% obtained by a previous state-of-the-art model-based method.", "histories": [["v1", "Thu, 1 Jun 2017 20:57:53 GMT  (284kb,D)", "http://arxiv.org/abs/1706.00493v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["ling zhang", "le lu", "ronald m summers", "electron kebebew", "jianhua yao"], "accepted": false, "id": "1706.00493"}, "pdf": {"name": "1706.00493.pdf", "metadata": {"source": "CRF", "title": "Personalized Pancreatic Tumor Growth Prediction via Group Learning", "authors": ["Ling Zhang", "Le Lu", "Ronald M. Summers", "Electron Kebebew", "Jianhua Yao"], "emails": ["ling.zhang3@nih.gov"], "sections": [{"heading": "1 Introduction", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "2 Group Learning Approach for Tumor Growth Prediction", "text": "In the longitudinal pancreatic tumour data studied in this paper, each patient has multimodal imaging data (Dual Phase Contrast-Enhanced CT and FDG-PET) and clinical records at three points of time over a period of 3 \u2212 4 years. We are designing an imaging data set in Fig. 2. Imaging data from various modalities recorded at different points of time are first recorded, then the tumours are segmented. Intracellular volume fractions (ICVF) and standardised image values (SUV) [9] are also calculated. In the training and personalisation phase, all voxel-wise ConvNet and orbased features, time intervals and clinical factors are extracted from any pair of two points of time (time1 / time2 and time2 / time3) from the group data (patient 1 - patient n) and the pair of timeame1 / timemeter-based data."}, {"heading": "2.1 Image Processing and Patch Extraction", "text": "In order to determine the spatial and temporal relationship of tumor growth along different time points, the image data sets of patients with multiple models are acquired on the basis of mutual information and the image data are aligned at different times in the tumor center [9]. Subsequently, three types of information related to tumor properties are extracted from the multimodal images and pre-processed as a three-channel image that can be fed into ConvNets. Image-specific pre-processing steps include the following: (1) SUV values from PET images are enlarged by 100, followed by an intersection window [100 2600] and then transformed linearly into [0 255]. (2) ICVF vallues are enlarged by 100 (range between [0 100]); and (3) tumor mask / boundary is achieved by a specified algorithm [9]."}, {"heading": "2.2 Learning a Voxel-Wise Deep Representation", "text": "We use AlexNet [7] as our network architecture. AlexNet contains five convolutionary (Conv1 \u2212 Conv5), three pools (Pool1, Pool2, Pool5), and two fully connected levels (fc6 \u2212 fc7). This network is trained from scratch at all times (Time1 / Time2 and Time2 / Time3) from the group dataset. Training is completed after a pre-defined number of eras in which the model with the least loss of validation is selected as the final network. The resulting ConvNet is then used to extract the superior representation of voxels / patches. This is achieved by feeding the three-channel SUV ICVFmask image fields into the customized ConvNet model, where the FC and output layers can be treated as the learned deep features. Considering that the high-dimensional deep image features of the FCmask are directly superimposed on the final layer - the number of tumor layers - and the number of tumors tend to increase."}, {"heading": "2.3 Learning a Predictive Model with Multi-Source Features", "text": "In this context, the number of tumours has fallen by more than a third in the last ten years. (1) The number of tumours has doubled in the last ten years. (2) The number of tumours has doubled in the last ten years. (3) The number of tumours has multiplied in the last ten years. (3) The number of tumours has doubled in the last ten years. (4) The number of tumours has doubled in the last ten years. (4) The number of tumours has doubled in the last ten years. (4) The number of tumours has doubled in the last ten years. (4) The number of tumours has multiplied in the last ten years."}, {"heading": "3 Experiments and Results", "text": "These tumors are not treated until they reach a diameter of 3 cm, which is the size threshold for the treatment of this particular disease. Accordingly, the average age, height and weight of the patients at date 1 were 48.6 \u00b1 13.9 years, 1.70 \u00b1 0.13 meters and 88.1 \u00b1 16.7 kg. The time interval between two points of time is 418 \u00b1 142 days (mean \u00b1 hour). This data set is derived from [9].The ConvNet is formed over 30 epochs. The initial learning rate is 0.001, and is reduced by a factor of 10 in every tenth epoch. Weight loss and dynamics are set to 0.0005 and 0.9. A failure ratio of 0.5 is used to regulate the fc6 and fc7 layers."}, {"heading": "4 Conclusion", "text": "In this paper, we have shown that our statistical learning method for groups that incorporate tumor growth patterns from a population trend and a particular patient, deep image confidence characteristics, as well as time intervals and clinical factors into a robust predictive model is an effective approach to predicting tumor growth. Experimental results confirm the relevance of tumor and patient-specific characteristics to predict the spatio-temporal progression of pancreatic tumors. The proposed method surpasses a state-of-the-art model-based method [9], but does not take into account crucial tumor biomechanical properties such as the measurement of the biomechanical load on tissue. We plan to incorporate such information into future work where we will combine in-depth learning and model-based methods to design an even more comprehensive and robust predictive model."}], "references": [{"title": "LIBSVM: a library for support vector machines", "author": ["C.C. Chang", "C.J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST) 2(3), 27", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Realistic simulation of the 3D growth of brain tumors in MR images coupling diffusion with biomechanical deformation", "author": ["O. Clatz", "M. Sermesant", "P.Y. Bondiau", "H. Delingette", "S.K. Warfield", "G. Malandain", "N. Ayache"], "venue": "TMI 24(10), 1334\u20131346", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique", "author": ["H. Greenspan", "B. van Ginneken", "R.M. Summers"], "venue": "TMI 35(5), 1153\u20131159", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Gene selection for cancer classification using support vector machines", "author": ["I. Guyon", "J. Weston", "S. Barnhill", "V. Vapnik"], "venue": "Machine Learning 46(1-3), 389\u2013422", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2002}, {"title": "Modeling glioma growth and mass effect in 3D MR images of the brain", "author": ["C. Hogea", "C. Davatzikos", "G. Biros"], "venue": "MICCAI. pp. 642\u2013650", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Caffe: An open source convolutional architecture for fast feature embedding", "author": ["Y. Jia"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS. pp. 1097\u20131105", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning a classification-based glioma growth model using MRI data", "author": ["M. Morris", "R. Greiner", "J. Sander", "A. Murtha", "M. Schmidt"], "venue": "Journal of Computers 1(7), 21\u201331", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Pancreatic tumor growth prediction with elastic-growth decomposition, image-derived motion, and FDMFEM coupling", "author": ["K.C.L. Wong", "R.M. Summers", "E. Kebebew", "J. Yao"], "venue": "TMI 36(1), 111\u2013123", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2017}, {"title": "Imaging biomarker discovery for lung cancer survival prediction", "author": ["J. Yao", "S. Wang", "X. Zhu", "J. Huang"], "venue": "MICCAI. pp. 649\u2013657. Springer", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 8, "context": "To choose between nonoperative or surgical treatments, and to better manage the treatment planning, it is crucial to accurately predict the patient-specific spatio-temporal progression of pancreatic tumors [9].", "startOffset": 206, "endOffset": 209}, {"referenceID": 1, "context": "It has long been viewed as a mathematical modeling problem [2,5,9].", "startOffset": 59, "endOffset": 66}, {"referenceID": 4, "context": "It has long been viewed as a mathematical modeling problem [2,5,9].", "startOffset": 59, "endOffset": 66}, {"referenceID": 8, "context": "It has long been viewed as a mathematical modeling problem [2,5,9].", "startOffset": 59, "endOffset": 66}, {"referenceID": 1, "context": "Some previous tumor growth models [2,5,9] are derived from two or more longitudinal imaging studies of a specific patient over time.", "startOffset": 34, "endOffset": 41}, {"referenceID": 4, "context": "Some previous tumor growth models [2,5,9] are derived from two or more longitudinal imaging studies of a specific patient over time.", "startOffset": 34, "endOffset": 41}, {"referenceID": 8, "context": "Some previous tumor growth models [2,5,9] are derived from two or more longitudinal imaging studies of a specific patient over time.", "startOffset": 34, "endOffset": 41}, {"referenceID": 7, "context": "The only pioneer study in this direction [8] attempts to model the glioma growth patterns in a classification-based framework.", "startOffset": 41, "endOffset": 44}, {"referenceID": 6, "context": "Representation learning, which automatically learns intricate discriminative information from raw data, has been popularized by deep learning techniques, namely deep convolutional neural networks (ConvNets) [7].", "startOffset": 207, "endOffset": 210}, {"referenceID": 2, "context": "ConvNets have significantly improved quantitative performance on a variety of medical imaging applications [3].", "startOffset": 107, "endOffset": 110}, {"referenceID": 9, "context": "The ConvNets have been used in prediction of future status of image level - disease outcomes, such as survival prediction of lung cancer patients [10].", "startOffset": 146, "endOffset": 150}, {"referenceID": 3, "context": "[4], regularized with prior knowledge.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "Our proposed group learning method is compared with a state-of-the-art model-based method [9] on a pancreatic tumor growth dataset, and attains both superior accuracy and efficiency.", "startOffset": 90, "endOffset": 93}, {"referenceID": 8, "context": "Intracellular volume fraction (ICVF) and standardized uptake value (SUV) [9] are also computed.", "startOffset": 73, "endOffset": 76}, {"referenceID": 8, "context": "To establish the spatio-temporal relationship of tumor growth along different time points, the multi-model patient imaging datasets are registered using mutual information, and imaging data at different time points are aligned at the tumor center [9].", "startOffset": 247, "endOffset": 250}, {"referenceID": 8, "context": "ues are magnified by 100 (range between [0 100]); and (3) tumor mask/boundary is obtained by a level set algorithm [9].", "startOffset": 115, "endOffset": 118}, {"referenceID": 6, "context": "To improve the training accuracy and convergence rate of the ConvNet [7], we balance the class distribution of the training set by proportionally under-sampling the nontumor negative patches.", "startOffset": 69, "endOffset": 72}, {"referenceID": 6, "context": "We use AlexNet [7] as our network architecture.", "startOffset": 15, "endOffset": 18}, {"referenceID": 3, "context": "The SVM RFE technique [4] is adopted to find the most informative features during the process of model training & personalization.", "startOffset": 22, "endOffset": 25}, {"referenceID": 8, "context": "Reflecting the significance of image-based features for assessing the growth of tumor [9], the two deep features are found to be always selected by the SVM RFE model selection.", "startOffset": 86, "endOffset": 89}, {"referenceID": 8, "context": "As in [9], the tumor growth zone is set as a bounding box surrounding the tumor, parametrized with the pixel distances Nx, Ny, and Nz to the tumor surface in the x, y, and z directions, respectively.", "startOffset": 6, "endOffset": 9}, {"referenceID": 8, "context": "This dataset is obtained from [9].", "startOffset": 30, "endOffset": 33}, {"referenceID": 5, "context": "AlexNet is run on the Caffe platform [6], using a NVIDIA GeForce GTX TITAN Z GPU with 12 GB of memory.", "startOffset": 37, "endOffset": 40}, {"referenceID": 0, "context": "The SVM (LIBSVM library [1]) with linear kernel (C = 1) is used for both SVM RFE feature selection and SVM classifier training.", "startOffset": 24, "endOffset": 27}, {"referenceID": 8, "context": "2% Model-Based Prediction [9] Recall: 73.", "startOffset": 26, "endOffset": 29}, {"referenceID": 8, "context": "Comparison of the proposed learning based tumor growth prediction to a stateof-the-art model-based prediction [9].", "startOffset": 110, "endOffset": 113}, {"referenceID": 8, "context": "We evaluate the proposed method using a leave-one-out cross-validation, which not only facilitates comparison with the state-of-the-art model-based method [9] (tumor status at time1 and time2 already known, predict time3), but more importantly enables learning both population trend and patient-specific tumor growth patterns.", "startOffset": 155, "endOffset": 158}, {"referenceID": 8, "context": "The prediction performance is evaluated using measurements at the third time point by four metrics: recall, precision, Dice coefficient, and RVD (as defined in [9]).", "startOffset": 160, "endOffset": 163}, {"referenceID": 8, "context": "Performance comparison of our method with the model-based method (EGIM framework [9]) on testing set.", "startOffset": 81, "endOffset": 84}, {"referenceID": 8, "context": "[9] 83.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "8%), than the model-based method [9], and thus is far more effective in future tumor volume prediction.", "startOffset": 33, "endOffset": 36}, {"referenceID": 8, "context": "The model-based approach in [9] requires \u223c 24 hrs for model personalization and \u223c 21 s for simulation per patient, while our method merely requires 3.", "startOffset": 28, "endOffset": 31}, {"referenceID": 8, "context": "The proposed method outperforms a state-of-the-art model-based method [9].", "startOffset": 70, "endOffset": 73}], "year": 2017, "abstractText": "Tumor growth prediction, a highly challenging task, has long been viewed as a mathematical modeling problem, where the tumor growth pattern is personalized based on imaging and clinical data of a target patient. Though mathematical models yield promising results, their prediction accuracy may be limited by the absence of population trend data and personalized clinical characteristics. In this paper, we propose a statistical group learning approach to predict the tumor growth pattern that incorporates both the population trend and personalized data, in order to discover high-level features from multimodal imaging data. A deep convolutional neural network approach is developed to model the voxel-wise spatio-temporal tumor progression. The deep features are combined with the time intervals and the clinical factors to feed a process of feature selection. Our predictive model is pretrained on a group data set and personalized on the target patient data to estimate the future spatio-temporal progression of the patient\u2019s tumor. Multimodal imaging data at multiple time points are used in the learning, personalization and inference stages. Our method achieves a Dice coefficient of 86.8% \u00b1 3.6% and RVD of 7.9% \u00b1 5.4% on a pancreatic tumor data set, outperforming the DSC of 84.4%\u00b14.0% and RVD 13.9%\u00b19.8% obtained by a previous state-of-the-art model-based method.", "creator": "LaTeX with hyperref package"}}}