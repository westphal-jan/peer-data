{"id": "1706.00712", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2017", "title": "Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning?", "abstract": "Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: \\emph{Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch?} To address this question, we considered 4 distinct medical imaging applications in 3 specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from 3 different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pre-trained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that (1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; (2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; (3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and (4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data.", "histories": [["v1", "Fri, 2 Jun 2017 15:04:43 GMT  (4806kb,D)", "http://arxiv.org/abs/1706.00712v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["nima tajbakhsh", "jae y shin", "suryakanth r gurudu", "r todd hurst", "christopher b kendall", "michael b gotway", "jianming liang"], "accepted": false, "id": "1706.00712"}, "pdf": {"name": "1706.00712.pdf", "metadata": {"source": "CRF", "title": "Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning?", "authors": ["Nima Tajbakhsh", "Jae Y. Shin", "Suryakanth R. Gurudu", "R. Todd Hurst", "Christopher B. Kendall", "Michael B. Gotway", "Jianming Liang"], "emails": ["ming.Liang}@asu.edu)."], "sections": [{"heading": null, "text": "Index Terms - carotid intima-media thickness; computer-aided detection; convolutional neural networks; deep learning; finetuning; medical image analysis; polyp detection; pulmonary embolism detection; video quality assessment.A accepted version of N. Kajbakhsh, J. Y. Shin, S. Gurudu, R. T. Hurst, C. B. Kendall, M. B. Gotway, and J. Liang. \"Convolutional neural networks for medical image analysis: Full training or fine tuning.\" IEEE Transactions on Medical Imaging. 35 (5): 1299-1312, 2016I. INTRODUCTIONConvolutional neural networks (CNNs) have been used in the field of computer vision for decades [1]. However, its true value had not been discovered to the ImageNet competition in 2012, a success that brought about a revolution through the efficient use of graphics processing units (GPUs), rectified units, jathrouzation."}, {"heading": "II. RELATED WORKS", "text": "However, the applications of CNNs in medical image analysis are not limited to recent years, when they were used for computer-aided detection of microcalcifications in digital mammography [13], [14] and computer-aided detection of lung nodes in CT data sets [15]. With the revival of CNNs due to the development of powerful GPU computing systems, medical imaging literature has witnessed a new generation of computer-aided detection systems showing superior performance. Examples include automatic polyp detection in colonoscopy videos [16] [17], computer-aided detection of pulmonary embolism (PE) in databases. Automatic detection of mitotic cells in histopathological images [19], computer-aided detection of lymph node videos [20], and computer-aided detection of anatomy detection in CT images."}, {"heading": "III. CONTRIBUTIONS", "text": "This approach differentiates our work from [28] - [30], which downloaded the features from the fully interconnected layers of a pre-trained CNN and then trained a separate pattern classifier. Our approach is also different from [31] - [33], where the entire pre-trained CNN was fine-tuned. \u2022 We have analyzed how the availability of training samples influences the choice between pre-trained CNNs and from-trained CNNs. To our knowledge, this issue has not yet been systematically addressed in the medical imaging literature. \u2022 We have compared the performance of pre-trained CNNs not only with manual approaches, but also with CNNs trained from the ground up using medical imaging data. This analysis contrasts with [28], [29] which provided limited performance comparisons between pre-trained CNNs, but also with different medical treatment approaches that are based from the ground up."}, {"heading": "IV. CONVOLUTIONAL NEURAL NETWORKS (CNNS)", "text": "To detect local structures, each node in a volume layer is connected to only a small subset of spatially connected neurons in the input image channels. To enable the search for the same local feature in the input channels, the 3 connecting weights are divided between the nodes in the volume layers. Each set of common weights is referred to as the kernel or folding core in the input image channels. Thus, a volume layer with n-cores, n-cores learns to detect the same local features whose strength is visible across the input images in the resulting n-characteristic maps. To reduce the complexity of compression and achieve a hierarchical set of image attributes, each sequence of folding layers is followed by a common layer of the miniature layer, a workflow reminiscent of simple and complex cells in the primary visual cortex [37]."}, {"heading": "V. FINE-TUNING", "text": "The weight update in Eq. 2 begins with a series of randomly initialized weight layers that we have joined except for the layer. Specifically, before the start of the training phase, the weights in each revolutionary layer of a CNN are initialized by values randomly sampled from a normal distribution with a zero and small standard deviation. However, taking into account the large number of weight layers in a CNN and the limited availability of the marked data, there may be an undesirable local minimum for the cost function. Alternatively, the weights of the conventional layers can be initialized with the weight layers of a pre-trained CNN with the same architecture. The pre-trained weight layers are generated with the same architecture. The pre-trained weight layers of another application. Training a CNN from a set of pre-trained weight layers is called finetuning and is successfully used in multiple applications [10]. Fine-tuning starts with copying the weights we wish to a network to transfer from one of the pretrained layers to another."}, {"heading": "A. Polyp detection", "text": "In fact, most of them are able to survive on their own."}, {"heading": "B. Pulmonary embolism detection", "text": "In fact, most of them will be able to move to another world, in which they are able to move, and in which they are able to change the world."}, {"heading": "C. Colonoscopy frame classification", "text": "We have an important role to play in the objective quality assessment of colonoscopy procedures based on local and non-informative approaches. Typically, a colonoscopy video contains a large number of non-informative images with poor colon visualization, which are not suitable for measuring the quality of a colonoscopy procedure or performing therapeutic interventions. The greater the proportion of non-informative images in a video, the lower the quality of the colon visualization, and the lower the quality of image processing. Therefore, the quality of a colonoscopy procedure can be measured by monitoring the quality of the captured images. Such quality evaluation can be used during live procedures to limit high-quality examinations."}, {"heading": "VII. DISCUSSION", "text": "Indeed, there are a number of reasons why people in the US are unable to thrive."}, {"heading": "VIII. CONCLUSION", "text": "Our extensive experiments, based on 4 different medical imaging applications from 3 different imaging modalities, have shown that deeply refined CNNs are useful for medical image analysis, as they perform both fully trained CNNs and outperform the latter when limited training data is available. Our results are important because they show that knowledge transfer from natural images to medical images is possible, although the relatively large difference between source and target databases suggests that such an application may not be possible. We have also observed that the level of fine-tuning required varied from application to application. Specifically for PE detection, we can achieve performance saturation after fine-tuning the late, fully dovetailed layers; for colonoscopy frame classification, we have achieved the highest performance by fine-tuning the late and middle layers; for pre-detection, we can achieve optimal saturation by learning the available layers and appropriate segmentation layers."}], "references": [{"title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position", "author": ["K. Fukushima"], "venue": "Biological cybernetics, vol. 36, no. 4, pp. 193\u2013202, 1980.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1980}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, vol. 86, no. 11, pp. 2278\u20132324, 1998.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1998}, {"title": "Deep learning", "author": ["Y. LeCun", "Y. Bengio", "G. Hinton"], "venue": "Nature, vol. 521, no. 7553, pp. 436\u2013444, 2015.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "arXiv preprint arXiv:1409.4842, 2014.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "arXiv preprint arXiv:1409.1556, 2014.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "Computer Vision\u2013ECCV 2014. Springer, 2014, pp. 818\u2013833.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Understanding deep architectures using a recursive convolutional network", "author": ["D. Eigen", "J. Rolfe", "R. Fergus", "Y. LeCun"], "venue": "arXiv preprint arXiv:1312.1847, 2013.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1847}, {"title": "The difficulty of training deep architectures and the effect of unsupervised pre-training", "author": ["D. Erhan", "P.-A. Manzagol", "Y. Bengio", "S. Bengio", "P. Vincent"], "venue": "International Conference on artificial intelligence and statistics, 2009, pp. 153\u2013160.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "CNN features off-the-shelf: an astounding baseline for recognition", "author": ["A.S. Razavian", "H. Azizpour", "J. Sullivan", "S. Carlsson"], "venue": "Computer Vision and Pattern Recognition Workshops (CVPRW), 2014 IEEE Conference on. IEEE, 2014, pp. 512\u2013519.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "From generic to specific deep representations for visual recognition", "author": ["H. Azizpour", "A.S. Razavian", "J. Sullivan", "A. Maki", "S. Carlsson"], "venue": "arXiv preprint arXiv:1406.5774, 2014.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Do deep features generalize from everyday objects to remote sensing and aerial scenes domains?", "author": ["O. Penatti", "K. Nogueira", "J. Santos"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Computerized detection of clustered microcalcifications in digital mammograms using a shift-invariant artificial neural network", "author": ["W. Zhang", "K. Doi", "M.L. Giger", "Y. Wu", "R.M. Nishikawa", "R.A. Schmidt"], "venue": "Medical Physics, vol. 21, no. 4, pp. 517\u2013524, 1994.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1994}, {"title": "Computer-aided detection of mammographic microcalcifications: Pattern recognition with an artificial neural network", "author": ["H.-P. Chan", "S.-C.B. Lo", "B. Sahiner", "K.L. Lam", "M.A. Helvie"], "venue": "Medical Physics, vol. 22, no. 10, pp. 1555\u20131567, 1995.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1995}, {"title": "Artificial convolution neural network techniques and applications for lung nodule detection", "author": ["S.-C.B. Lo", "S.-L. Lou", "J.-S. Lin", "M.T. Freedman", "M.V. Chien", "S.K. Mun"], "venue": "Medical Imaging, IEEE Transactions on, vol. 14, no. 4, pp. 711\u2013718, 1995.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1995}, {"title": "A comprehensive computeraided polyp detection system for colonoscopy videos", "author": ["N. Tajbakhsh", "S.R. Gurudu", "J. Liang"], "venue": "Information Processing in Medical Imaging. Springer, 2015, pp. 327\u2013338.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Automatic polyp detection in colonoscopy videos using an ensemble of convolutional neural networks", "author": ["\u2014\u2014"], "venue": "Biomedical Imaging (ISBI), 2015 IEEE 12th International Symposium on. IEEE, 2015, pp. 79\u201383.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Computer-aided pulmonary embolism detection using a novel vessel-aligned multi-planar image representation and convolutional neural networks", "author": ["N. Tajbakhsh", "J. Liang"], "venue": "Medical Image Computing and Computer-Assisted Intervention MICCAI 2015, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Mitosis detection in breast cancer histology images with deep neural networks", "author": ["D.C. Cire\u015fan", "A. Giusti", "L.M. Gambardella", "J. Schmidhuber"], "venue": "Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI 2013. Springer, 2013, pp. 411\u2013418.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "A new 2.5d representation for lymph node detection using random sets of deep convolutional neural network observations", "author": ["H. Roth", "L. Lu", "A. Seff", "K. Cherry", "J. Hoffman", "S. Wang", "J. Liu", "E. Turkbey", "R. Summers"], "venue": "Medical Image Computing and Computer-Assisted Intervention MICCAI 2014, ser. Lecture Notes in Computer Science, P. Golland, N. Hata, C. Barillot, J. Hornegger, and R. Howe, Eds. Springer International Publishing, 2014, vol. 8673, pp. 520\u2013527.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "3d deep learning for efficient and robust landmark detection in volumetric data", "author": ["Y. Zheng", "D. Liu", "B. Georgescu", "H. Nguyen", "D. Comaniciu"], "venue": "Medical Image Computing and Computer-Assisted Intervention MICCAI 2015, 2015.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Automating carotid intima-media thickness video interpretation with convolutional neural networks", "author": ["J.Y. Shin", "N. Tajbakhsh", "R.T. Hurst", "C.B. Kendall", "J. Liang"], "venue": "to appear in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep convolutional networks for pancreas segmentation in ct imaging", "author": ["H.R. Roth", "A. Farag", "L. Lu", "E.B. Turkbey", "R.M. Summers"], "venue": "SPIE Medical Imaging. International Society for Optics and Photonics, 2015, pp. 94 131G\u201394 131G.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Brain tumor segmentation with deep neural networks", "author": ["M. Havaei", "A. Davy", "D. Warde-Farley", "A. Biard", "A. Courville", "Y. Bengio", "C. Pal", "P.-M. Jodoin", "H. Larochelle"], "venue": "arXiv preprint arXiv:1505.03540, 2015.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep convolutional neural networks for multi-modality isointense infant brain image segmentation", "author": ["W. Zhang", "R. Li", "H. Deng", "L. Wang", "W. Lin", "S. Ji", "D. Shen"], "venue": "NeuroImage, vol. 108, pp. 214\u2013224, 2015.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep neural networks segment neuronal membranes in electron microscopy images", "author": ["D. Ciresan", "A. Giusti", "L.M. Gambardella", "J. Schmidhuber"], "venue": "Advances in Neural Information Processing Systems 25, F. Pereira, C. Burges, L. Bottou, and K. Weinberger, Eds. Curran Associates, Inc., 2012, pp. 2843\u20132851.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep feature learning for knee cartilage segmentation using a triplanar convolutional neural network", "author": ["A. Prasoon", "K. Petersen", "C. Igel", "F. Lauze", "E. Dam", "M. Nielsen"], "venue": "Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI 2013. Springer, 2013, pp. 246\u2013253.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep learning with non-medical training used for chest pathology identification", "author": ["Y. Bar", "I. Diamant", "L. Wolf", "H. Greenspan"], "venue": "SPIE Medical Imaging. International Society for Optics and Photonics, 2015, pp. 94 140V\u201394 140V.  14", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Off-the-shelf convolutional neural network features for pulmonary nodule detection in computed tomography scans", "author": ["B. van Ginneken", "A.A. Setio", "C. Jacobs", "F. Ciompi"], "venue": "Biomedical Imaging (ISBI), 2015 IEEE 12th International Symposium on, April 2015, pp. 286\u2013289.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Convolutional neural networks for mammography mass lesion classification", "author": ["J. Arevalo", "F. Gonzalez", "R. Ramos-Pollan", "J. Oliveira", "M. Guevara Lopez"], "venue": "Engineering in Medicine and Biology Society (EMBC), 2015 37th Annual International Conference of the IEEE, Aug 2015, pp. 797\u2013800.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Unsupervised pre-training across image domains improves lung tissue classification", "author": ["T. Schlegl", "J. Ofner", "G. Langs"], "venue": "Medical Computer Vision: Algorithms for Big Data. Springer, 2014, pp. 82\u201393.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "Standard plane localization in fetal ultrasound via domain transferred deep neural networks", "author": ["H. Chen", "D. Ni", "J. Qin", "S. Li", "X. Yang", "T. Wang", "P.A. Heng"], "venue": "Biomedical and Health Informatics, IEEE Journal of, vol. 19, no. 5, pp. 1627\u20131636, Sept 2015.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Unregistered multiview mammogram analysis with pre-trained deep learning models", "author": ["G. Carneiro", "J. Nascimento", "A. Bradley"], "venue": "Medical Image Computing and Computer-Assisted Intervention MICCAI 2015, ser. Lecture Notes in Computer Science, N. Navab, J. Hornegger, W. M. Wells, and A. F. Frangi, Eds. Springer International Publishing, 2015, vol. 9351, pp. 652\u2013660. [Online]. Available: http://dx.doi.org/10.1007/978-3-319-24574-4 78", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2015}, {"title": "Interleaved text/image deep mining on a very large-scale radiology database", "author": ["H.-C. Shin", "L. Lu", "L. Kim", "A. Seff", "J. Yao", "R.M. Summers"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 1090\u20131099.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "Holistic classification of ct attenuation patterns for interstitial lung diseases via deep convolutional neural networks", "author": ["M. Gao", "U. Bagci", "L. Lu", "A. Wu", "M. Buty", "H.-C. Shin", "H. Roth", "G.Z. Papadakis", "A. Depeursinge", "R.M. Summers"], "venue": "the 1st Workshop on Deep Learning in Medical Image Analysis, International Conference on Medical Image Computing and Computer Assisted Intervention, at MICCAI-DLMIA\u201915, 2015.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2015}, {"title": "Fine-tuned convolutional neural nets for cardiac mri acquisition plane recognition", "author": ["J. Margeta", "A. Criminisi", "R. Cabrera Lozoya", "D.C. Lee", "N. Ayache"], "venue": "Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization, pp. 1\u201311, 2015.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2015}, {"title": "Receptive fields of single neurones in the cat\u2019s striate cortex", "author": ["D.H. Hubel", "T.N. Wiesel"], "venue": "The Journal of physiology, vol. 148, no. 3, pp. 574\u2013591, 1959.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1959}, {"title": "Maximum likelihood fitting of FROC curves under an initial-detectionand-candidate-analysis model", "author": ["D.C. Edwards", "M.A. Kupinski", "C.E. Metz", "R.M. Nishikawa"], "venue": "Medical physics, vol. 29, no. 12, pp. 2861\u20132870, 2002.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2002}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "arXiv preprint arXiv:1408.5093, 2014.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2014}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["X. Glorot", "Y. Bengio"], "venue": "International conference on artificial intelligence and statistics, 2010, pp. 249\u2013256.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}, {"title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv preprint arXiv:1502.01852, 2015.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1852}, {"title": "Automated polyp detection in colonoscopy videos using shape and context information", "author": ["N. Tajbakhsh", "S. Gurudu", "J. Liang"], "venue": "Medical Imaging, IEEE Transactions on, vol. PP, no. 99, pp. 1\u20131, 2015.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2015}, {"title": "Analysis of colorectal cancer occurrence during surveillance colonoscopy in the dietary polyp prevention trial", "author": ["A. Pabby", "R.E. Schoen", "J.L. Weissfeld", "R. Burt", "J.W. Kikendall", "P. Lance", "M. Shike", "E. Lanza", "A. Schatzkin"], "venue": "Gastrointest Endosc, vol. 61, no. 3, pp. 385\u201391, 2005.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2005}, {"title": "Polyp miss rate determined by tandem colonoscopy: a systematic review", "author": ["J. van Rijn", "J. Reitsma", "J. Stoker", "P. Bossuyt", "S. van Deventer", "E. Dekker"], "venue": "American Journal of Gastroenterology, vol. 101, no. 2, pp. 343\u2013350, 2006.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2006}, {"title": "Ct colonography versus colonoscopy for the detection of advanced neoplasia", "author": ["D.H. Kim", "P.J. Pickhardt", "A.J. Taylor", "W.K. Leung", "T.C. Winter", "J.L. Hinshaw", "D.V. Gopal", "M. Reichelderfer", "R.H. Hsu", "P.R. Pfau"], "venue": "N Engl J Med, vol. 357, no. 14, pp. 1403\u201312, 2007.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2007}, {"title": "Miss rate for colorectal neoplastic polyps: a prospective multicenter study of backto-back video colonoscopies.", "author": ["D. Heresbach", "T. Barrioz", "M. Lapalus", "D. Coumaros", "P. Bauret", "P. Potier", "D. Sautereau", "C. Bousti\u00e8re", "J. Grimaud", "C. Barth\u00e9l\u00e9my"], "venue": "Endoscopy, vol. 40,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2008}, {"title": "Factors influencing the miss rate of polyps in a back-to-back colonoscopy study", "author": ["A. Leufkens", "M. van Oijen", "F. Vleggaar", "P. Siersema"], "venue": "Endoscopy, vol. 44, no. 05, pp. 470\u2013475, 2012.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2012}, {"title": "Outcomes of colorectal cancer in the united states: no change in survival", "author": ["L. Rabeneck", "H. El-Serag", "J. Davila", "R. Sandler"], "venue": "The American journal of gastroenterology,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 1986}, {"title": "Computer-aided tumor detection in endoscopic video using color wavelet features", "author": ["S.A. Karkanis", "D.K. Iakovidis", "D.E. Maroulis", "D.A. Karras", "M. Tzivras"], "venue": "Information Technology in Biomedicine, IEEE Transactions on, vol. 7, no. 3, pp. 141\u2013152, 2003.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2003}, {"title": "A comparative study of texture features for the discrimination of gastric polyps in endoscopic video", "author": ["D.K. Iakovidis", "D.E. Maroulis", "S.A. Karkanis", "A. Brokos"], "venue": "Computer-Based Medical Systems, 2005. Proceedings. 18th IEEE Symposium on. IEEE, 2005, pp. 575\u2013580.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2005}, {"title": "Color and position versus texture features for endoscopic polyp detection", "author": ["L.A. Alexandre", "N. Nobre", "J. Casteleiro"], "venue": "BioMedical Engineering and Informatics, 2008. BMEI 2008. International Conference on, vol. 2. IEEE, 2008, pp. 38\u201342.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2008}, {"title": "Polyp detection in colonoscopy video using elliptical shape feature", "author": ["S. Hwang", "J. Oh", "W. Tavanapong", "J. Wong", "P. de Groen"], "venue": "Image Processing, 2007. ICIP 2007. IEEE International Conference on, vol. 2, 2007, pp. II\u2013465\u2013II\u2013468.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2007}, {"title": "Towards automatic polyp detection with a polyp appearance model", "author": ["J. Bernal", "J. Snchez", "F. Vilario"], "venue": "Pattern Recognition, vol. 45, no. 9, pp. 3166\u20133182, 2012.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2012}, {"title": "Impact of image preprocessing methods on polyp localization in colonoscopy frames", "author": ["J. Bernal", "J. S\u00e1nchez", "F. Vilarino"], "venue": "Engineering in Medicine and Biology Society (EMBC), 2013 35th Annual International Conference of the IEEE. IEEE, 2013, pp. 7350\u20137354.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2013}, {"title": "Partbased multi-derivative edge cross-section profiles for polyp detection in colonoscopy", "author": ["Y. Wang", "W. Tavanapong", "J. Wong", "J. Oh", "P. de Groen"], "venue": "Biomedical and Health Informatics, IEEE Journal of, vol. PP, no. 99, pp. 1\u20131, 2013.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2013}, {"title": "A colon video analysis framework for polyp detection", "author": ["S.Y. Park", "D. Sargent", "I. Spofford", "K. Vosburgh", "Y. A-Rahim"], "venue": "Biomedical Engineering, IEEE Transactions on, vol. 59, no. 5, pp. 1408\u20131418, 2012.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2012}, {"title": "A classification-enhanced vote accumulation scheme for detecting colonic polyps", "author": ["N. Tajbakhsh", "S. Gurudu", "J. Liang"], "venue": "Abdominal Imaging. Computation and Clinical Applications, ser. Lecture Notes in Computer Science, 2013, vol. 8198, pp. 53\u201362.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatic polyp detection from learned boundaries", "author": ["N. Tajbakhsh", "C. Chi", "S.R. Gurudu", "J. Liang"], "venue": "Biomedical Imaging (ISBI), 2014 IEEE 10th International Symposium on, 2014.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2014}, {"title": "Automatic polyp detection using global geometric constraints and local intensity variation patterns", "author": ["N. Tajbakhsh", "S.R. Gurudu", "J. Liang"], "venue": "Medical Image Computing and Computer-Assisted Intervention\u2013 MICCAI 2014. Springer, 2014, pp. 179\u2013187.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2014}, {"title": "Computer aided detection of pulmonary embolism with tobogganing and multiple instance classification in CT pulmonary angiography", "author": ["J. Liang", "J. Bi"], "venue": "Information Processing in Medical Imaging. Springer, 2007, pp. 630\u2013641.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2007}, {"title": "The mortality of untreated pulmonary embolism in emergency department patients.", "author": ["K.K. Calder", "M. Herbert", "S.O. Henderson"], "venue": "Annals of emergency medicine,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2005}, {"title": "Challenges, controversies, and hot topics in pulmonary embolism imaging", "author": ["G. Sadigh", "A.M. Kelly", "P. Cronin"], "venue": "American Journal of Roentgenology, vol. 196, no. 3, 2011. [Online]. Available: http://dx.doi.org/10.2214/AJR.10.5830", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2011}, {"title": "Toboggan contrast enhancement for contrast segmentation", "author": ["J. Fairfield"], "venue": "Pattern Recognition, 1990. Proceedings., 10th International Conference on, vol. 1. IEEE, 1990, pp. 712\u2013716.", "citeRegEx": "63", "shortCiteRegEx": null, "year": 1990}, {"title": "Textural features for image classification", "author": ["R.M. Haralick", "K. Shanmugam", "I.H. Dinstein"], "venue": "Systems, Man and Cybernetics, IEEE Transactions on, no. 6, pp. 610\u2013621, 1973.", "citeRegEx": "64", "shortCiteRegEx": null, "year": 1973}, {"title": "Automatic assessment of image informativeness in colonoscopy", "author": ["N. Tajbakhsh", "C. Chi", "H. Sharma", "Q. Wu", "S.R. Gurudu", "J. Liang"], "venue": "Abdominal Imaging. Computational and Clinical Applications. Springer, 2014, pp. 151\u2013158.", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2014}, {"title": "Indistinct frame detection in colonoscopy videos", "author": ["M. Arnold", "A. Ghosh", "G. Lacey", "S. Patchett", "H. Mulcahy"], "venue": "Machine Vision and Image Processing Conference, 2009. IMVIP\u201909. 13th International. IEEE, 2009, pp. 47\u201352.", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2009}, {"title": "Informative frame classification for endoscopy video", "author": ["J. Oh", "S. Hwang", "J. Lee", "W. Tavanapong", "J. Wong", "P.C. de Groen"], "venue": "Medical Image Analysis, vol. 11, no. 2, pp. 110\u2013127, 2007.  15", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2007}, {"title": "Fully automatic segmentation of ultrasound common carotid artery images based on machine learning", "author": ["R.-M. Mench\u00f3n-Lara", "J.-L. Sancho-G\u00f3mez"], "venue": "Neurocomputing, vol. 151, pp. 161\u2013167, 2015.", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2015}, {"title": "Automatic evaluation of carotid intima-media thickness in ultrasounds using machine learning", "author": ["R.-M. Mench\u00f3n-Lara", "M.-C. Bastida-Jumilla", "A. Gonz\u00e1lez-L\u00f3pez", "J.L. Sancho-G\u00f3mez"], "venue": "Natural and Artificial Computation in Engineering and Medical Applications. Springer, 2013, pp. 241\u2013249.", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2013}, {"title": "Segmentation of the common carotid intima-media complex in ultrasound images using active contours", "author": ["S. Petroudi", "C. Loizou", "M. Pantziaris", "C. Pattichis"], "venue": "Biomedical Engineering, IEEE Transactions on, vol. 59, no. 11, pp. 3060\u20133069, 2012.", "citeRegEx": "70", "shortCiteRegEx": null, "year": 2012}, {"title": "Ultrasound intima\u2013 media segmentation using hough transform and dual snake model", "author": ["X. Xu", "Y. Zhou", "X. Cheng", "E. Song", "G. Li"], "venue": "Computerized Medical Imaging and Graphics, vol. 36, no. 3, pp. 248\u2013 258, 2012.", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2012}, {"title": "United snakes", "author": ["J. Liang", "T. McInerney", "D. Terzopoulos"], "venue": "Medical image analysis, vol. 10, no. 2, pp. 215\u2013233, 2006.", "citeRegEx": "72", "shortCiteRegEx": null, "year": 2006}, {"title": "Ecg-based frame selection and curvaturebased roi detection for measuring carotid intima-media thickness", "author": ["H. Sharma", "R.G. Golla", "Y. Zhang", "C.B. Kendall", "R.T. Hurst", "N. Tajbakhsh", "J. Liang"], "venue": "SPIE Medical Imaging. International Society for Optics and Photonics, 2014, pp. 904 016\u2013904 016.", "citeRegEx": "73", "shortCiteRegEx": null, "year": 2014}, {"title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "author": ["H. Lee", "R. Grosse", "R. Ranganath", "A.Y. Ng"], "venue": "Proceedings of the 26th Annual International Conference on Machine Learning. ACM, 2009, pp. 609\u2013616.", "citeRegEx": "74", "shortCiteRegEx": null, "year": 2009}, {"title": "Convolutional neural networks for speech recognition", "author": ["O. Abdel-Hamid", "A.-r. Mohamed", "H. Jiang", "L. Deng", "G. Penn", "D. Yu"], "venue": "Audio, Speech, and Language Processing, IEEE/ACM Transactions on, vol. 22, no. 10, pp. 1533\u20131545, 2014.", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Convolutional neural networks (CNNs) have been used in the field of computer vision for decades [1]\u2013[3].", "startOffset": 96, "endOffset": 99}, {"referenceID": 2, "context": "Convolutional neural networks (CNNs) have been used in the field of computer vision for decades [1]\u2013[3].", "startOffset": 100, "endOffset": 103}, {"referenceID": 2, "context": "However, their true value had not been discovered until the ImageNet competition in 2012, a success that brought about a revolution through the efficient use of graphics processing units (GPUs), rectified linear units, new dropout regularization, and effective data augmentation [3].", "startOffset": 279, "endOffset": 282}, {"referenceID": 3, "context": "The main power of a CNN lies in its deep architecture [5]\u2013[8], which allows for extracting a set of discriminating features at multiple levels of abstraction.", "startOffset": 54, "endOffset": 57}, {"referenceID": 6, "context": "The main power of a CNN lies in its deep architecture [5]\u2013[8], which allows for extracting a set of discriminating features at multiple levels of abstraction.", "startOffset": 58, "endOffset": 61}, {"referenceID": 7, "context": "However, training a deep CNN from scratch (or full training) is not without complications [9].", "startOffset": 90, "endOffset": 93}, {"referenceID": 8, "context": "The pre-trained models have been applied successfully to various computer vision tasks as a feature generator or as a baseline for transfer learning [10]\u2013[12].", "startOffset": 149, "endOffset": 153}, {"referenceID": 10, "context": "The pre-trained models have been applied successfully to various computer vision tasks as a feature generator or as a baseline for transfer learning [10]\u2013[12].", "startOffset": 154, "endOffset": 158}, {"referenceID": 11, "context": "Applications of CNNs in medical image analysis can be traced to the 1990s, when they were used for computeraided detection of microcalcifications in digital mammography [13], [14] and computer-aided detection of lung nodules in CT datasets [15].", "startOffset": 169, "endOffset": 173}, {"referenceID": 12, "context": "Applications of CNNs in medical image analysis can be traced to the 1990s, when they were used for computeraided detection of microcalcifications in digital mammography [13], [14] and computer-aided detection of lung nodules in CT datasets [15].", "startOffset": 175, "endOffset": 179}, {"referenceID": 13, "context": "Applications of CNNs in medical image analysis can be traced to the 1990s, when they were used for computeraided detection of microcalcifications in digital mammography [13], [14] and computer-aided detection of lung nodules in CT datasets [15].", "startOffset": 240, "endOffset": 244}, {"referenceID": 14, "context": "Examples include automatic polyp detection in colonoscopy videos [16] [17], computer-aided detection of pulmonary embolism (PE) in CT datasets [18], automatic detection of mitotic cells in histopathology images [19], computer-aided detection of lymph nodes in CT images [20], and computer-aided anatomy detection in CT volumes [21].", "startOffset": 65, "endOffset": 69}, {"referenceID": 15, "context": "Examples include automatic polyp detection in colonoscopy videos [16] [17], computer-aided detection of pulmonary embolism (PE) in CT datasets [18], automatic detection of mitotic cells in histopathology images [19], computer-aided detection of lymph nodes in CT images [20], and computer-aided anatomy detection in CT volumes [21].", "startOffset": 70, "endOffset": 74}, {"referenceID": 16, "context": "Examples include automatic polyp detection in colonoscopy videos [16] [17], computer-aided detection of pulmonary embolism (PE) in CT datasets [18], automatic detection of mitotic cells in histopathology images [19], computer-aided detection of lymph nodes in CT images [20], and computer-aided anatomy detection in CT volumes [21].", "startOffset": 143, "endOffset": 147}, {"referenceID": 17, "context": "Examples include automatic polyp detection in colonoscopy videos [16] [17], computer-aided detection of pulmonary embolism (PE) in CT datasets [18], automatic detection of mitotic cells in histopathology images [19], computer-aided detection of lymph nodes in CT images [20], and computer-aided anatomy detection in CT volumes [21].", "startOffset": 211, "endOffset": 215}, {"referenceID": 18, "context": "Examples include automatic polyp detection in colonoscopy videos [16] [17], computer-aided detection of pulmonary embolism (PE) in CT datasets [18], automatic detection of mitotic cells in histopathology images [19], computer-aided detection of lymph nodes in CT images [20], and computer-aided anatomy detection in CT volumes [21].", "startOffset": 270, "endOffset": 274}, {"referenceID": 19, "context": "Examples include automatic polyp detection in colonoscopy videos [16] [17], computer-aided detection of pulmonary embolism (PE) in CT datasets [18], automatic detection of mitotic cells in histopathology images [19], computer-aided detection of lymph nodes in CT images [20], and computer-aided anatomy detection in CT volumes [21].", "startOffset": 327, "endOffset": 331}, {"referenceID": 20, "context": "CNNs have recently been used for carotid intima-media thickness measurement in ultrasound images [22], pancreas segmentation in CT images [23], brain tumor segmentation in magnetic resonance imaging (MRI) scans [24], multimodality isointense infant brain image segmentation [25], neuronal membrane segmentation in electron microscopy images [26], and knee cartilage segmentation in MRI scans [27].", "startOffset": 97, "endOffset": 101}, {"referenceID": 21, "context": "CNNs have recently been used for carotid intima-media thickness measurement in ultrasound images [22], pancreas segmentation in CT images [23], brain tumor segmentation in magnetic resonance imaging (MRI) scans [24], multimodality isointense infant brain image segmentation [25], neuronal membrane segmentation in electron microscopy images [26], and knee cartilage segmentation in MRI scans [27].", "startOffset": 138, "endOffset": 142}, {"referenceID": 22, "context": "CNNs have recently been used for carotid intima-media thickness measurement in ultrasound images [22], pancreas segmentation in CT images [23], brain tumor segmentation in magnetic resonance imaging (MRI) scans [24], multimodality isointense infant brain image segmentation [25], neuronal membrane segmentation in electron microscopy images [26], and knee cartilage segmentation in MRI scans [27].", "startOffset": 211, "endOffset": 215}, {"referenceID": 23, "context": "CNNs have recently been used for carotid intima-media thickness measurement in ultrasound images [22], pancreas segmentation in CT images [23], brain tumor segmentation in magnetic resonance imaging (MRI) scans [24], multimodality isointense infant brain image segmentation [25], neuronal membrane segmentation in electron microscopy images [26], and knee cartilage segmentation in MRI scans [27].", "startOffset": 274, "endOffset": 278}, {"referenceID": 24, "context": "CNNs have recently been used for carotid intima-media thickness measurement in ultrasound images [22], pancreas segmentation in CT images [23], brain tumor segmentation in magnetic resonance imaging (MRI) scans [24], multimodality isointense infant brain image segmentation [25], neuronal membrane segmentation in electron microscopy images [26], and knee cartilage segmentation in MRI scans [27].", "startOffset": 341, "endOffset": 345}, {"referenceID": 25, "context": "CNNs have recently been used for carotid intima-media thickness measurement in ultrasound images [22], pancreas segmentation in CT images [23], brain tumor segmentation in magnetic resonance imaging (MRI) scans [24], multimodality isointense infant brain image segmentation [25], neuronal membrane segmentation in electron microscopy images [26], and knee cartilage segmentation in MRI scans [27].", "startOffset": 392, "endOffset": 396}, {"referenceID": 9, "context": "[11] suggests that the success of knowledge transfer depends on the distance, or dissimilarity, between the database on which a CNN is trained and the database to which the knowledge is to be transferred.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "The first group [28]\u2013[30] consists of works wherein a pre-trained CNN is used as a feature generator.", "startOffset": 16, "endOffset": 20}, {"referenceID": 28, "context": "The first group [28]\u2013[30] consists of works wherein a pre-trained CNN is used as a feature generator.", "startOffset": 21, "endOffset": 25}, {"referenceID": 26, "context": "For instance, in [28], pre-trained CNNs were used as a feature generator for chest pathology identification.", "startOffset": 17, "endOffset": 21}, {"referenceID": 27, "context": "A similar study [29] by Ginneken et al.", "startOffset": 16, "endOffset": 20}, {"referenceID": 29, "context": "The second group [31]\u2013[36] consists of works wherein a pre-trained CNN is adapted to the application at hand.", "startOffset": 17, "endOffset": 21}, {"referenceID": 34, "context": "The second group [31]\u2013[36] consists of works wherein a pre-trained CNN is adapted to the application at hand.", "startOffset": 22, "endOffset": 26}, {"referenceID": 31, "context": "For instance, in [33], the fully connected layers of a pre-trained CNN were replaced with a new logistic layer, and then the labeled data were used to train only the appended layer while keeping the rest of the network the same.", "startOffset": 17, "endOffset": 21}, {"referenceID": 30, "context": "[32] suggested the use of a fine-tuned pre-trained CNN for localizing standard planes in ultrasound images.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "In [35], the authors fine-tuned all layers of a pre-trained CNN for automatic classification of interstitial lung diseases.", "startOffset": 3, "endOffset": 7}, {"referenceID": 32, "context": "[34] used fine-tuned pre-trained CNNs to automatically map medical images to document-level topics, document-level sub-topics, and sentence-level topics.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "In [36], fine-tuned pre-trained CNNs were used to automatically retrieve missing or noisy cardiac acquisition plane information from magnetic resonance imaging and predict the five most common cardiac views.", "startOffset": 3, "endOffset": 7}, {"referenceID": 29, "context": "[31] considered the fine-tuning of an unsupervised network.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "This approach distinguishes our work from [28]\u2013[30], which downloaded the features from the fully connected layers of a pre-trained CNN and then trained a separate pattern classifier.", "startOffset": 42, "endOffset": 46}, {"referenceID": 28, "context": "This approach distinguishes our work from [28]\u2013[30], which downloaded the features from the fully connected layers of a pre-trained CNN and then trained a separate pattern classifier.", "startOffset": 47, "endOffset": 51}, {"referenceID": 29, "context": "Our approach also differs from [31]\u2013[33] wherein the entire pre-trained CNN underwent fine-tuning.", "startOffset": 31, "endOffset": 35}, {"referenceID": 31, "context": "Our approach also differs from [31]\u2013[33] wherein the entire pre-trained CNN underwent fine-tuning.", "startOffset": 36, "endOffset": 40}, {"referenceID": 26, "context": "This analysis is in contrast to [28], [29], who provided only limited performance comparisons between pre-trained CNNs and handcrafted approaches.", "startOffset": 32, "endOffset": 36}, {"referenceID": 27, "context": "This analysis is in contrast to [28], [29], who provided only limited performance comparisons between pre-trained CNNs and handcrafted approaches.", "startOffset": 38, "endOffset": 42}, {"referenceID": 35, "context": "To reduce computational complexity and achieve a hierarchical set of image features, each sequence of convolution layers is followed by a pooling layer, a workflow reminiscent of simple and complex cells in the primary visual cortex [37].", "startOffset": 233, "endOffset": 237}, {"referenceID": 8, "context": "Training a CNN from a set of pre-trained weights is called finetuning and has been used successfully in several applications [10]\u2013[12].", "startOffset": 125, "endOffset": 129}, {"referenceID": 10, "context": "Training a CNN from a set of pre-trained weights is called finetuning and has been used successfully in several applications [10]\u2013[12].", "startOffset": 130, "endOffset": 134}, {"referenceID": 8, "context": "We would like to note that the suggested fine-tuning scheme differs from [10], [12] wherein the network remains the same and serves as a feature generator, and also differs from [11] wherein the entire network undergoes fine-tuning at once.", "startOffset": 73, "endOffset": 77}, {"referenceID": 10, "context": "We would like to note that the suggested fine-tuning scheme differs from [10], [12] wherein the network remains the same and serves as a feature generator, and also differs from [11] wherein the entire network undergoes fine-tuning at once.", "startOffset": 79, "endOffset": 83}, {"referenceID": 9, "context": "We would like to note that the suggested fine-tuning scheme differs from [10], [12] wherein the network remains the same and serves as a feature generator, and also differs from [11] wherein the entire network undergoes fine-tuning at once.", "startOffset": 178, "endOffset": 182}, {"referenceID": 36, "context": "to 95% confidence intervals for both ROC and FROC curves according to the method suggested in [38].", "startOffset": 94, "endOffset": 98}, {"referenceID": 37, "context": "We used the Caffe library [39] for both training and finetuning CNNs.", "startOffset": 26, "endOffset": 30}, {"referenceID": 38, "context": "We also experimented with other initialization techniques such as those suggested in [40] and [41], but we observed no significant performance gain after convergence, even though we noticed varying speed of convergence using these initialization techniques.", "startOffset": 85, "endOffset": 89}, {"referenceID": 39, "context": "We also experimented with other initialization techniques such as those suggested in [40] and [41], but we observed no significant performance gain after convergence, even though we noticed varying speed of convergence using these initialization techniques.", "startOffset": 94, "endOffset": 98}, {"referenceID": 41, "context": "Polyp miss-rates are estimated to be about 4% to 12% [43]\u2013 [46]; however, a more recent clinical study [47] is suggestive that this misdetection rate may be as high as 25%.", "startOffset": 53, "endOffset": 57}, {"referenceID": 44, "context": "Polyp miss-rates are estimated to be about 4% to 12% [43]\u2013 [46]; however, a more recent clinical study [47] is suggestive that this misdetection rate may be as high as 25%.", "startOffset": 59, "endOffset": 63}, {"referenceID": 45, "context": "Polyp miss-rates are estimated to be about 4% to 12% [43]\u2013 [46]; however, a more recent clinical study [47] is suggestive that this misdetection rate may be as high as 25%.", "startOffset": 103, "endOffset": 107}, {"referenceID": 46, "context": "Missed polyps can lead to the late diagnosis of colon cancer with an associated decreased survival rate of less than 10% for metastatic colon cancer [48].", "startOffset": 149, "endOffset": 153}, {"referenceID": 47, "context": "The early systems [49]\u2013[51] relied on polyp color and texture for detection.", "startOffset": 18, "endOffset": 22}, {"referenceID": 49, "context": "The early systems [49]\u2013[51] relied on polyp color and texture for detection.", "startOffset": 23, "endOffset": 27}, {"referenceID": 50, "context": "More recent systems [52]\u2013[56] relied on temporal information and shape information to enhance polyp detection.", "startOffset": 20, "endOffset": 24}, {"referenceID": 54, "context": "More recent systems [52]\u2013[56] relied on temporal information and shape information to enhance polyp detection.", "startOffset": 25, "endOffset": 29}, {"referenceID": 55, "context": "In our previous works [57]\u2013[59], culminated in [42], we attempted to overcome the limitation of approaches based solely on polyp shape.", "startOffset": 22, "endOffset": 26}, {"referenceID": 57, "context": "In our previous works [57]\u2013[59], culminated in [42], we attempted to overcome the limitation of approaches based solely on polyp shape.", "startOffset": 27, "endOffset": 31}, {"referenceID": 40, "context": "In our previous works [57]\u2013[59], culminated in [42], we attempted to overcome the limitation of approaches based solely on polyp shape.", "startOffset": 47, "endOffset": 51}, {"referenceID": 40, "context": "We applied our handcrafted approach [42] to the training and test frames to obtain a set of polyp candidates with the corresponding bounding boxes.", "startOffset": 36, "endOffset": 40}, {"referenceID": 40, "context": "(a) Comparison between incremental fine-tuning, training from scratch, and a handcrafted approach [42].", "startOffset": 98, "endOffset": 102}, {"referenceID": 59, "context": "The mortality rate of untreated PE may approach 30% [61], but it decreases to as low as 2% with early diagnosis and appropriate treatment [62].", "startOffset": 52, "endOffset": 56}, {"referenceID": 60, "context": "The mortality rate of untreated PE may approach 30% [61], but it decreases to as low as 2% with early diagnosis and appropriate treatment [62].", "startOffset": 138, "endOffset": 142}, {"referenceID": 58, "context": "(a) Comparison between incremental fine-tuning, training from scratch, and a handcrafted approach [60].", "startOffset": 98, "endOffset": 102}, {"referenceID": 58, "context": "We based our experiments on the PE candidates generated by our previous work [60] and the image representation that we suggested for PE in our recently published study [18].", "startOffset": 77, "endOffset": 81}, {"referenceID": 16, "context": "We based our experiments on the PE candidates generated by our previous work [60] and the image representation that we suggested for PE in our recently published study [18].", "startOffset": 168, "endOffset": 172}, {"referenceID": 61, "context": "Our candidate generation method is an improved version of the tobogganing algorithm [63] that aims to find an embolus as a dark region surrounded by a brighter background.", "startOffset": 84, "endOffset": 88}, {"referenceID": 58, "context": "For performance comparison, we used a handcrafted approach [60], which is arguably one of the most, if not the most, accurate PE CAD system.", "startOffset": 59, "endOffset": 63}, {"referenceID": 58, "context": "The handcrafted approach utilizes the same candidate generation method [60], but uses vessel-based features along with Haralick [64] and waveletbased features for PE characterization, and finally uses a multiinstance classifier for candidate classification.", "startOffset": 71, "endOffset": 75}, {"referenceID": 62, "context": "The handcrafted approach utilizes the same candidate generation method [60], but uses vessel-based features along with Haralick [64] and waveletbased features for PE characterization, and finally uses a multiinstance classifier for candidate classification.", "startOffset": 128, "endOffset": 132}, {"referenceID": 63, "context": "In our previous work [65], we suggested a handcrafted approach based on local and global features that were pooled from the image reconstruction error.", "startOffset": 21, "endOffset": 25}, {"referenceID": 64, "context": "We showed that our handcrafted approach outperformed the other major methods [66], [67] for quality assessment in colonoscopy videos.", "startOffset": 77, "endOffset": 81}, {"referenceID": 65, "context": "We showed that our handcrafted approach outperformed the other major methods [66], [67] for quality assessment in colonoscopy videos.", "startOffset": 83, "endOffset": 87}, {"referenceID": 63, "context": "(a) Comparison between incremental fine-tuning, training from scratch, and a handcrafted approach [65].", "startOffset": 98, "endOffset": 102}, {"referenceID": 66, "context": "Therefore, several methods [68]\u2013 [71] have been developed to allow automatic CIMT image interpretation.", "startOffset": 27, "endOffset": 31}, {"referenceID": 69, "context": "Therefore, several methods [68]\u2013 [71] have been developed to allow automatic CIMT image interpretation.", "startOffset": 33, "endOffset": 37}, {"referenceID": 70, "context": "To smooth the boundaries, we used 2 active contour models (snakes) [72], one for the lumen-intima interface and one for the media-adventitia interface.", "startOffset": 67, "endOffset": 71}, {"referenceID": 71, "context": "For both interfaces, holding all the layers fixed except the last layer (FT: only fc8) resulted in the lowest performance, which was comparable to that of the handcrafted approach [73].", "startOffset": 180, "endOffset": 184}, {"referenceID": 38, "context": "For a thorough comparison, we used 3 different techniques to initialize the weights of the fully trained CNNs: 1) a method commonly known as Xavier, which was suggested in [40], 2) a revised version of Xavier called MSRA, which was suggested in [41], and a basic random initialization method based on Gaussian distributions.", "startOffset": 172, "endOffset": 176}, {"referenceID": 39, "context": "For a thorough comparison, we used 3 different techniques to initialize the weights of the fully trained CNNs: 1) a method commonly known as Xavier, which was suggested in [40], 2) a revised version of Xavier called MSRA, which was suggested in [41], and a basic random initialization method based on Gaussian distributions.", "startOffset": 245, "endOffset": 249}, {"referenceID": 72, "context": "However, a pre-trained unsupervised model such as those obtained by restricted Boltzmann machines (RBMs) or convolutional RBMs [74] could also be considered, even though the availability of ImageNet database with millions of labeled images from 1000 semantic classes may make the use of a pre-trained supervised model a natural choice for fine-tuning.", "startOffset": 127, "endOffset": 131}, {"referenceID": 73, "context": "For instance, finetuning of an unsupervised model was used in [75] for acoustic", "startOffset": 62, "endOffset": 66}], "year": 2017, "abstractText": "Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch? To address this question, we considered 4 distinct medical imaging applications in 3 specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from 3 different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pretrained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that (1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; (2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; (3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and (4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data.", "creator": "LaTeX with hyperref package"}}}