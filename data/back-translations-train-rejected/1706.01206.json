{"id": "1706.01206", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2017", "title": "One-step and Two-step Classification for Abusive Language Detection on Twitter", "abstract": "Automatic abusive language detection is a difficult but important task for online social media. Our research explores a two-step approach of performing classification on abusive language and then classifying into specific types and compares it with one-step approach of doing one multi-class classification for detecting sexist and racist languages. With a public English Twitter corpus of 20 thousand tweets in the type of sexism and racism, our approach shows a promising performance of 0.827 F-measure by using HybridCNN in one-step and 0.824 F-measure by using logistic regression in two-steps.", "histories": [["v1", "Mon, 5 Jun 2017 06:20:23 GMT  (286kb)", "http://arxiv.org/abs/1706.01206v1", "ALW1: 1st Workshop on Abusive Language Online to be held at the annual meeting of the Association of Computational Linguistics (ACL) 2017 (Vancouver, Canada), August 4th, 2017"]], "COMMENTS": "ALW1: 1st Workshop on Abusive Language Online to be held at the annual meeting of the Association of Computational Linguistics (ACL) 2017 (Vancouver, Canada), August 4th, 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ji ho park", "pascale fung"], "accepted": false, "id": "1706.01206"}, "pdf": {"name": "1706.01206.pdf", "metadata": {"source": "CRF", "title": "One-step and Two-step Classification for Abusive Language Detection on Twitter", "authors": ["Ji Ho Park"], "emails": ["jhpark@connect.ust.hk,", "pascale@ece.ust.hk"], "sections": [{"heading": null, "text": "Automatic detection of abusive language is a difficult but important task for online social media. Our research examines a two-step approach to classification of abusive language and classification into specific species and compares it to a one-step approach to detecting sexist and racist languages through a multi-step classification. With a public Twitter corpus of 20,000 tweets in the sexism and racism type, our approach shows a promising performance of 0.827 Fmeasure, using hybrid CNN in one step and 0.824 F-Measure through logistic regression in two steps."}, {"heading": "1 Introduction", "text": "The fight against abusive language on the Internet is becoming increasingly important in a world where social media on the Internet plays a significant role in shaping people's minds (Perse and Lambe, 2016). However, it is difficult for large social media companies such as Twitter to address this problem (Meyer, 2016) because the enormous number of posts cannot be communicated solely with human resources. Warner and Hirschberg (2012) and Burnap and Williams (2015) are one of the early studies to use machine learning-based classifiers to detect abusive language. Djuric et al. (2015) integrated word embedding (Mikolov et al., 2013). Nobata et al. (2016) combined predefined language elements and word embedding to train a regression model. Waseem (2016) used logistical regression with n-grammes and user-specific features such as gender and location. Davidson et al. (2017) conducted a deeper investigation into different types of abusive language through the Internet."}, {"heading": "2 Methodology", "text": "We propose to implement three CNN-based models to classify sexist and racist offensive language: CharCNN, WordCNN, and HybridCNN. The main difference between these models is whether the input functions are characters, words, or both. Key components are the convective layers, which each calculate a one-dimensional folding over the previous input with multiple filter sizes and large feature cards. Having different filter sizes is the same as viewing a set of different windows at the same time. Maxpooling is performed after folding to capture the feature that is most relevant to the output."}, {"heading": "2.1 CharCNN", "text": "CharCNN is a modification of the Convolutionary Network at character level in (Zhang et al. 2015). Each character in the initial set is initially converted into a uniform encoding of 70 characters, including 26 English letters, 10 digits, 33 additional characters and a line break (punctuation and special characters). All other non-standard characters are removed. Zhang et al. (2015) uses 7 layers of coils and max pooling layers, 2 fully connected layers and 1 Softmax layer, but we also have a flat version with 2 coils and maxpooling layers, 1 fully connected layer and 1 Softmax layer with suspensions designed as our data set is relatively small to prevent overadjustment."}, {"heading": "2.2 WordCNN", "text": "WordCNN is a CNN static version proposed by Kim (2014). The input sentence is first segmented into words and converted into a 300-dimensional embedding of word2vec, trained on 100 billion words of Google News (Mikolov et al., 2013). Embedding pre-trained vectors is a widely used method to improve performance, especially when using a relatively small data set. As our data set is small, we use embedding as untraceable. We also suggest segmenting some unspoken phrases. As Twitter tweets often contain hashtags such as # womenagainstfeminism and # feminismisawful, we use a word segment library (Segaran and Hammerbacher, 2009) to capture more words."}, {"heading": "2.3 HybridCNN", "text": "We design HybridCNN, a variant of WordCNN, because WordCNN has the restriction to use only word characteristics as input. Abusive language often includes words deliberately or mistakenly misspelled and invented words such as # feminazi. Therefore, since CharCNN and WordCNN do not use letter and word input at the same time, we design HybridCNN to experiment with whether the model can capture features from both input levels. HybridCNN has two input channels. Each channel is fed into sinuous layers with three filter windows of different sizes. Output of the folding is merged into a vector after 1-max pooling, and the vector is then fed into the last Softmax layer to perform a classification (see Figure 1)."}, {"heading": "3 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Datasets", "text": "We used the two English Twitter records (Waseem and Hovy, 2016; Waseem, 2016), which were published as undivided tasks for the 1st Workshop on Abusive Language Online (ALW1). They included tweets with sexist and racist comments. Waseem and Hovy (2016) compiled a list of criteria based on critical racial theory and had the corpus commented on by an expert. First, we linked the two records into one and then divided them into three records for a one-step and two-step classification (Table 1). One-step data set is a segmentation for a multi-level classification. For a two-step classification, we merged the labels sexism and racism into an abusive label. Finally, we created another data set with abusive languages to experiment with a second classification to distinguish between \"sexism\" and \"racism,\" as the instance is classified as \"abusive.\""}, {"heading": "3.2 Training and Evaluation", "text": "We performed two classification experiments: 1. Recognition of \"none,\" \"sexist\" and \"racist\" language (in one step) 2. Recognition of \"abusive language,\" then further classification into \"sexist\" or \"racist\" (in two steps) The purpose of these experiments was to see if dividing the problem area in two steps makes the detection more effective. We trained the models using a stochastic gradient drop in the mini-batch with AdamOptimizer (Kingma and Ba, 2014). For more efficient training in an unbalanced dataset, we sampled the mini-batch with a size of 32 with equal distribution for all labels. Training continued until the loss of the evaluation quantity stopped decreasing. All results are average results of a 10-fold cross-validation. As an evaluation metric, we used F1 values with precision and Recall score, and in 2016 weighted values to exclude the overall value of the classification from the F1 (the reason for this imbalance of the classification)."}, {"heading": "3.3 Hyperparameters", "text": "For hyperparameter setting, we evaluated the validation set. These are the hyperparameters used for the evaluation. \u2022 CharCNN: Flat model with 1024 feature units for folding layers with filter size 4, max pooling size 3 and L2 regularization constant 1 and 2048 units for the fully connected layer \u2022 WordCNN: folding layers with 3 filters with size [1,2,3] and feature map size 50, max pooling and L2 regularization constant 1 \u2022 Hybrid CNN: For the character input channel folding layers with 3 filters with size [3,4,5] and for word input channels, 3 filters with size [1,2,3] Both channels had feature map size 50, max pooling and L2 regularization constant 1."}, {"heading": "4 Result and Discussions", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 One-step Classification", "text": "The results of the single-tier multi-class classification are shown in the upper part of Table 2. Our newly proposed hybrid CNN performs best, improving on the WordCNN result. We expected the additional character input channel to improve performance. We assumed that CharCNN performs worse than WordCNN because the dataset for the character-based model is too small to independently capture word-like characteristics."}, {"heading": "4.2 Two-step Classification", "text": "The two-step approach, which combines two binary classifiers, shows comparable results with a single-step approach. The results of combining the two are shown in the lower part of Table 3.The combination of two logistic regression classifiers in the two-step approach shows about as good results as a single-step hybrid CNN approach and outperforms the single-step logistic regression classifier by more than 10 F1 points. This is surprising, since logistic regression has fewer characteristics underlying it than the HybridCNN. In addition, HybridCNN performs best in the first step of recognizing abusive language and logistic regression in the second step of classifying racism and sexism than the mere use of HybridCNN.Table 4 shows the results of abusive language classification. HybridCNN also performs best in recognizing abusive language, followed by WordCNN and logistic regression.Table 5 shows the results of classifying sexism and racism given that they are abusive."}, {"heading": "5 Conclusion and Future work", "text": "We have explored a two-step approach to combine two classifications - one to classify abusive language, and one to classify a particular type of sexist and racist comment, as the language is abusive. Using many different machine classification methods, including our proposed hybrid CNN methods, we are showing the potential in the two-step approach, which is simply a multi-level classification."}, {"heading": "Acknowledgements", "text": "This work is partly funded by CERG16214415 of the Hong Kong Research Grants Council and ITS170 of the Innovation and Technology Commission."}], "references": [{"title": "Deep learning for hate speech detection in tweets", "author": ["P. Badjatiya", "S. Gupta", "M. Gupta", "V. Varma"], "venue": "Proceedings of the 26th International Conference on World Wide Web Companion,", "citeRegEx": "Badjatiya et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Badjatiya et al\\.", "year": 2017}, {"title": "Hate speech detection with comment embeddings", "author": ["N. Djuric", "J. Zhou", "R. Morris", "M. Grbovic", "V. Radosavljevic", "N. Bhamidipati"], "venue": "Proceedings of the 24th International Conference on World Wide Web,", "citeRegEx": "Djuric et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Djuric et al\\.", "year": 2015}, {"title": "Bag of tricks for efficient text classification", "author": ["A. Joulin", "E. Grave", "P. Bojanowski", "T. Mikolov"], "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume", "citeRegEx": "Joulin et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Joulin et al\\.", "year": 2016}, {"title": "Convolutional neural networks for sentence classification", "author": ["Y. Kim"], "venue": "Proceedings of EMNLP.,", "citeRegEx": "Kim,? \\Q2014\\E", "shortCiteRegEx": "Kim", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "Proceedings of the 3rd International Conference on Learning Representations (ICLR)", "citeRegEx": "Kingma and Ba,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba", "year": 2014}, {"title": "Convolutional networks and applications in vision. Circuits and Systems (ISCAS)", "author": ["Y. LeCun", "K. Kavukcuoglu", "C. Farabet"], "venue": "Proceedings of 2010 IEEE International Symposium on,", "citeRegEx": "LeCun et al\\.,? \\Q2010\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 2010}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Abusive language detection in online user content", "author": ["C. Nobata", "J. Tetreault", "A. Thomas", "Y. Mehdad", "Y. Chang"], "venue": "Proceedings of the 25th International Conference on World Wide Web,", "citeRegEx": "Nobata et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nobata et al\\.", "year": 2016}, {"title": "Media effects and society", "author": ["E.M. Perse", "J. Lambe"], "venue": null, "citeRegEx": "Perse and Lambe,? \\Q2016\\E", "shortCiteRegEx": "Perse and Lambe", "year": 2016}, {"title": "Measuring the reliability of hate speech annotations: The case of the european refugee crisis", "author": ["B. Ross", "M. Rist", "G. Carbonell", "B. Cabrera", "N. Kurowsky", "M. Wojatzki"], "venue": "In Proceedings of the Workshop on Natural Language", "citeRegEx": "Ross et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Ross et al\\.", "year": 2017}, {"title": "A survey on hate speech detection using natural language processing", "author": ["A. Schmidt", "M. Wiegand"], "venue": "Socialnlp 2017,", "citeRegEx": "Schmidt and Wiegand,? \\Q2017\\E", "shortCiteRegEx": "Schmidt and Wiegand", "year": 2017}, {"title": "Beautiful data: The stories behind elegant data solutions \" O'Reilly Media, Inc.", "author": ["T. Segaran", "J. Hammerbacher"], "venue": null, "citeRegEx": "Segaran and Hammerbacher,? \\Q2009\\E", "shortCiteRegEx": "Segaran and Hammerbacher", "year": 2009}, {"title": "Harnessing twitter\" big data\" for automatic emotion identification", "author": ["W. Wang", "L. Chen", "K. Thirunarayan", "A.P. Sheth"], "venue": "Privacy, Security, Risk and Trust (PASSAT),", "citeRegEx": "Wang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2012}, {"title": "Detecting hate speech on the world wide web", "author": ["W. Warner", "J. Hirschberg"], "venue": "Proceedings of the Second Workshop on Language in Social Media,", "citeRegEx": "Warner and Hirschberg,? \\Q2012\\E", "shortCiteRegEx": "Warner and Hirschberg", "year": 2012}, {"title": "Are you a racist or am I seeing things? annotator influence on hate speech detection on twitter", "author": ["Z. Waseem"], "venue": "Proceedings of the 1st Workshop on Natural Language Processing and Computational Social Science,", "citeRegEx": "Waseem,? \\Q2016\\E", "shortCiteRegEx": "Waseem", "year": 2016}, {"title": "Hateful symbols or hateful people? predictive features for hate speech detection on twitter", "author": ["Z. Waseem", "D. Hovy"], "venue": "Proceedings of NAACL-HLT,", "citeRegEx": "Waseem and Hovy,? \\Q2016\\E", "shortCiteRegEx": "Waseem and Hovy", "year": 2016}, {"title": "Characterlevel convolutional networks for text classification", "author": ["X. Zhang", "J. Zhao", "Y. LeCun"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Zhang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "Fighting abusive language online is becoming more and more important in a world where online social media plays a significant role in shaping people\u2019s minds (Perse and Lambe, 2016).", "startOffset": 157, "endOffset": 180}, {"referenceID": 6, "context": ", (2015) incorporated representation word embeddings (Mikolov et al., 2013).", "startOffset": 53, "endOffset": 75}, {"referenceID": 15, "context": "2016) and lack of context (Waseem and Hovy, 2016; Schmidt & Wiegand, 2017).", "startOffset": 26, "endOffset": 74}, {"referenceID": 14, "context": "This makes it harder for non-experts to annotate without having a certain amount of domain knowledge (Waseem, 2016).", "startOffset": 101, "endOffset": 115}, {"referenceID": 4, "context": "Fighting abusive language online is becoming more and more important in a world where online social media plays a significant role in shaping people\u2019s minds (Perse and Lambe, 2016). Nevertheless, major social media companies like Twitter find it difficult to tackle this problem (Meyer, 2016), as the huge number of posts cannot be mediated with only human resources. Warner and Hirschberg (2012) and Burnap and Williams (2015) are one of the early researches to use machine learning based classifiers for detecting abusive language.", "startOffset": 158, "endOffset": 397}, {"referenceID": 4, "context": "Fighting abusive language online is becoming more and more important in a world where online social media plays a significant role in shaping people\u2019s minds (Perse and Lambe, 2016). Nevertheless, major social media companies like Twitter find it difficult to tackle this problem (Meyer, 2016), as the huge number of posts cannot be mediated with only human resources. Warner and Hirschberg (2012) and Burnap and Williams (2015) are one of the early researches to use machine learning based classifiers for detecting abusive language.", "startOffset": 158, "endOffset": 428}, {"referenceID": 0, "context": "Djuric et al., (2015) incorporated representation word embeddings (Mikolov et al.", "startOffset": 0, "endOffset": 22}, {"referenceID": 0, "context": "Djuric et al., (2015) incorporated representation word embeddings (Mikolov et al., 2013). Nobata et al. (2016) combined pre-defined language elements and word embedding to train a regression model.", "startOffset": 0, "endOffset": 111}, {"referenceID": 0, "context": "Djuric et al., (2015) incorporated representation word embeddings (Mikolov et al., 2013). Nobata et al. (2016) combined pre-defined language elements and word embedding to train a regression model. Waseem (2016) used logistic regression with n-grams and user-specific features such as gender and location.", "startOffset": 0, "endOffset": 212}, {"referenceID": 0, "context": "Djuric et al., (2015) incorporated representation word embeddings (Mikolov et al., 2013). Nobata et al. (2016) combined pre-defined language elements and word embedding to train a regression model. Waseem (2016) used logistic regression with n-grams and user-specific features such as gender and location. Davidson et al. (2017) conducted a deeper investigation on different types of abusive language.", "startOffset": 0, "endOffset": 329}, {"referenceID": 0, "context": "Badjatiya et al. (2017) experimented with deep learning-based models using ensemble gradient boost classifiers to perform multi-class classification on sexist and racist language.", "startOffset": 0, "endOffset": 24}, {"referenceID": 16, "context": "CharCNN is a modification of the character-level convolutional network in (Zhang et al. 2015).", "startOffset": 74, "endOffset": 93}, {"referenceID": 16, "context": "CharCNN is a modification of the character-level convolutional network in (Zhang et al. 2015). Each character in the input sentence is first transformed into a one-hot encoding of 70 characters, including 26 English letters, 10 digits, 33 other characters, and a newline character (punctuations and special characters). All other non-standard characters are removed. Zhang et al. (2015) uses 7 layers of convolutions and max-pooling layers, 2 fully-connected layers, and 1 softmax layer, but we also designed a shallow version with 2 convolutions and maxpooling layers, 1 fully-connected layers, and 1 softmax layers with dropout, due to the relatively small size of our dataset to prevent overfitting.", "startOffset": 75, "endOffset": 387}, {"referenceID": 6, "context": "The input sentence is first segmented into words and converted into a 300-dimensional embedding word2vec trained on 100 billion words from Google News (Mikolov et al., 2013).", "startOffset": 151, "endOffset": 173}, {"referenceID": 11, "context": "Since the Twitter tweets often contain hashtags such as #womenagainstfeminism and #feminismisawful we use a wordsegment library (Segaran and Hammerbacher, 2009) to capture more words.", "startOffset": 128, "endOffset": 160}, {"referenceID": 3, "context": "WordCNN is a CNN-static version proposed by Kim (2014). The input sentence is first segmented into words and converted into a 300-dimensional embedding word2vec trained on 100 billion words from Google News (Mikolov et al.", "startOffset": 44, "endOffset": 55}, {"referenceID": 15, "context": "We used the two English Twitter Datasets (Waseem and Hovy, 2016; Waseem, 2016) published as unshared tasks for the 1 Workshop on Abusive Language Online(ALW1).", "startOffset": 41, "endOffset": 78}, {"referenceID": 14, "context": "We used the two English Twitter Datasets (Waseem and Hovy, 2016; Waseem, 2016) published as unshared tasks for the 1 Workshop on Abusive Language Online(ALW1).", "startOffset": 41, "endOffset": 78}, {"referenceID": 14, "context": "We used the two English Twitter Datasets (Waseem and Hovy, 2016; Waseem, 2016) published as unshared tasks for the 1 Workshop on Abusive Language Online(ALW1). It contains tweets with sexist and racist comments. Waseem and Hovy (2016) created a list of criteria based on a critical race theory and let an expert annotate the corpus.", "startOffset": 42, "endOffset": 235}, {"referenceID": 4, "context": "We trained the models using mini-batch stochastic gradient descent with AdamOptimizer (Kingma and Ba, 2014).", "startOffset": 86, "endOffset": 107}, {"referenceID": 2, "context": "As baseline, we used the character n-gram logistic regression classifier (indicated as LR on Table 2-4) from Waseem and Hovy (2016), Support Vector Machines (SVM) classifier, and FastText (Joulin et al., 2016) that uses average bag-of-words representations to classify sentences.", "startOffset": 188, "endOffset": 209}, {"referenceID": 0, "context": "It was the second best single model on the same dataset after CNN (Badjatiya et al., 2017).", "startOffset": 66, "endOffset": 90}, {"referenceID": 2, "context": "We trained the models using mini-batch stochastic gradient descent with AdamOptimizer (Kingma and Ba, 2014). For more efficient training in an unbalanced dataset, the mini-batch with a size of 32 had been sampled with equal distribution for all labels. The training continued until the evaluation set loss did not decrease any longer. All the results are average results of 10-fold cross validation. As evaluation metric, we used F1 scores with precision and recall score and weighted averaged the scores to consider the imbalance of the labels. For this reason, total average F1 might not between average precision and recall. As baseline, we used the character n-gram logistic regression classifier (indicated as LR on Table 2-4) from Waseem and Hovy (2016), Support Vector Machines (SVM) classifier, and FastText (Joulin et al.", "startOffset": 87, "endOffset": 760}], "year": 2017, "abstractText": "Automatic abusive language detection is a difficult but important task for online social media. Our research explores a twostep approach of performing classification on abusive language and then classifying into specific types and compares it with one-step approach of doing one multi-class classification for detecting sexist and racist languages. With a public English Twitter corpus of 20 thousand tweets in the type of sexism and racism, our approach shows a promising performance of 0.827 Fmeasure by using HybridCNN in one-step and 0.824 F-measure by using logistic regression in two-steps.", "creator": "Word"}}}