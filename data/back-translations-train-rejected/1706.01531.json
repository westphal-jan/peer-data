{"id": "1706.01531", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2017", "title": "Progressive Boosting for Class Imbalance", "abstract": "Pattern recognition applications often suffer from skewed data distributions between classes, which may vary during operations w.r.t. the design data. Two-class classification systems designed using skewed data tend to recognize the majority class better than the minority class of interest. Several data-level techniques have been proposed to alleviate this issue by up-sampling minority samples or under-sampling majority samples. However, some informative samples may be neglected by random under-sampling and adding synthetic positive samples through up-sampling adds to training complexity. In this paper, a new ensemble learning algorithm called Progressive Boosting (PBoost) is proposed that progressively inserts uncorrelated groups of samples into a Boosting procedure to avoid loss of information while generating a diverse pool of classifiers. Base classifiers in this ensemble are generated from one iteration to the next, using subsets from a validation set that grows gradually in size and imbalance. Consequently, PBoost is more robust to unknown and variable levels of skew in operational data, and has lower computation complexity than Boosting ensembles in literature. In PBoost, a new loss factor is proposed to avoid bias of performance towards the negative class. Using this loss factor, the weight update of samples and classifier contribution in final predictions are set based on the ability to recognize both classes. Using the proposed loss factor instead of standard accuracy can avoid biasing performance in any Boosting ensemble. The proposed approach was validated and compared using synthetic data, videos from the FIA dataset that emulates face re-identification applications, and KEEL collection of datasets. Results show that PBoost can outperform state of the art techniques in terms of both accuracy and complexity over different levels of imbalance and overlap between classes.", "histories": [["v1", "Mon, 5 Jun 2017 20:32:55 GMT  (1488kb,D)", "http://arxiv.org/abs/1706.01531v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["roghayeh soleymani", "eric granger", "giorgio fumera"], "accepted": false, "id": "1706.01531"}, "pdf": {"name": "1706.01531.pdf", "metadata": {"source": "CRF", "title": "Progressive Boosting for Class Imbalance", "authors": ["Roghayeh Soleymania", "Eric Grangera", "Giorgio Fumerab"], "emails": ["rSoleymani@livia.etsmtl.ca", "Eric.Granger@etsmtl.ca", "Fumera@diee.unica.it"], "sections": [{"heading": null, "text": "In practice, pattern recognition applications often suffer from unbalanced data distributions between classes, which may vary during operations, such as the design data. Two-class classification systems designed with unbalanced data tend to better detect the majority of the (negative) class, while the interest class (positive class) often has the lower number of samples. Multiple data-level classification techniques have been proposed to alleviate this problem, with classification ensembles containing balanced data being designed by stamping positive samples or subsampling negative samples. However, some informative samples can be neglected by random substituting and synthetic positive samples are added by stamping, increasing training complexity. In this paper, a new ensemble algorithm called Progressive Boosting (PBoost) is suggested that unrelated groups of samples are inserted into a boosting pool, thereby avoiding the loss of classification information during the process."}, {"heading": "1. Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2. Boosting Ensemble Learning for Class Imbalance", "text": "Learning imbalanced data has been addressed in the literature through data-level, algorithm-level and cost-sensitive techniques. Ensemble learning methods use one or a combination of the above techniques [4] to deal with imbalances. Ensembles can then offer greater accuracy and robustness than a single classification system by combining different classification problems [9]. Boosting is a common static ensemble learning algorithm initiated with AdaBoost [8] and assigned to AdaBoost.M1 (for 2-class problems) and AdaBoost.M2 (for multi-class problems) to effectively foster a weak learner who is marginally better than random rates into a stronger ensemble.M1 (Algo.1) samples are mapped to indicate their importance. These weights guide the learning process so that the basic classifiers in the ensemble focus are focused on the correct classification of more important samples."}, {"heading": "2.1. Data-Level Methods:", "text": "In fact, you have to be able to put yourself in another world, in which you can put yourself in another world, in which you have to put yourself in another world, in which you have to put yourself in another world, in which you have to put yourself in another world, in which you have to put yourself in another world, in which you have to put yourself in another world, in which you have to put yourself in another world, in which you have to put yourself in another world, in which you feel put back in another world."}, {"heading": "2.2. Algorithm-Level Methods:", "text": "In the literature, this problem is avoided at the algorithm level using two types of techniques; those that use two different cost factors for misclassification, one for positive and another for negative classes, and those that handle this problem without using cost factors. Cost-sensitive approaches to cost increase, including AdaCost [17], COD [18] and AdaC [19], are usually defined as other cost factors for misclassification into the loss function or the weight update formula of AdaBoost.M2.Given \u00b5i as a cost factor for the sample xi, in AdaCost [17], two cost adjustment functions for the axle sample are defined + = \u2212 0.5\u00b5i + 0.5\u00b5i + 0.5\u00b5i and the weight update formula of AdaBoost.M2i as a cost factor for the sample xi, in AdaCost [17], two cost adjustment functions for the axle bite class are defined."}, {"heading": "2.3. Performance Measures for Imbalanced Data Classification", "text": "The trade-off between true positive rate (TPR) and false positive rate (FPR) for different operating environments (\u03b2 = \u03b2 samples can be traced with a Receiver-Operating Characteristic (ROC) curve. ROC curves are often used to compare the performance of classifiers; this curve can also be summarized in a global scalar metric; range taking into account the ROC curve (AUC samples): another range taking into account the operational curve (AUC samples). (20) G averages give an equal weighting of the efficiency of classifiers in the correct classification of both classes. ROC space does not adequately reflect the effects of imbalances [26], as large variations in the number of incorrectly classified negative classes (FP) results can be masked in a small change in the FPR."}, {"heading": "3. Progressive Boosting for Learning Ensembles from Imbalanced Data:", "text": "The Progressive Boosting (PBoost) learning method is proposed to maintain a high level of performance over a number of imbalances and complexity levels in the operations. It follows a static approach and learns ensembles based on a combination of subsamples and free adaptations of ensemble lessons. In any case, part of this temporary group is used to form a type that contains the most important samples plus samples from the new partition. These partitions are incorporated into a temporary design that is progressively used as learning progressions. In any case, a subset of this temporary group is used to form a type."}, {"heading": "4. Experimental Methodology", "text": "In our experiments, the proposed PBoost ensemble learning method is evaluated and compared with AdaBoost.M1 [9], as well as a state-of-the-art method from each family of data-level approaches reviewed in Section 2, including SMOTEBoost [10], RUSBoost [14], and RB-Boost [16]. Data sets used for the experiments include: (1) a set of synthetic 2D datasets in which the degree of skew and intersection between classes is controllable; (2) the Face In Action (FIA) video database [31], which simulates a passport verification scenario in facial recognition; (3) a set of 21 real problems from the KEEL dataset repository [32]. The rest of this section presents the data sets used in the experiments, followed by the experimental and evaluation protocols."}, {"heading": "4.1. Datasets", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1.1. Synthetic Dataset", "text": "The performance of classification systems may vary at different levels of overlap and skew between classes in education and test data = j = j = 1. Therefore, in our synthetic data experiments, different synthetic data sets with different overlap and skew are generated and used to compare classification systems.The data is generated to emulate both the binarization of a multi-class classification problem when the classification strategy is one against all and binary classification problems where there is no prior knowledge of optimal partitions.Samples of both positive and negative classes are generated in groups of samples distributed in a normal distribution.The samples from a normal distribution are considered as a positive class and all other samples are considered as a negative class and all other samples are considered as a negative classes.To generate the 2D synthetic data, M + = 100 positive class samples are generated with a normal distribution, as N (+, + 00, + +) and a mean distribution (where + 1)."}, {"heading": "4.1.2. Face Re-Identification Dataset", "text": "Table 1: Settings used for data generation. D1 D3: 50 1: 50 1: 20 1: 20 \u03b4 0.2 0.2 0.4 0.6 0.8 1 00.60.81Negative Cluster Centers Positive Overlap: a) D1,0 0.2 0.4 0.6 0.8 100.2 0.2 0.2 0.4 0.4 0.8 0.40.80.60.81 (c).Examples of synthetic training data generated for 34 experiments."}, {"heading": "4.1.3. KEEL Collection", "text": "KEEL (Knowledge Extraction based on Evolutionary Learning) is an open source software to support data management and the designer of experiments. [32] The KEEL data collection contains several sets of data for binary classification problems with different numbers of samples, attributes and imbalances. In this paper, the first group of this collection 2 is used for experiments. In this group, the slant of the data sets varies between 1: 9 and 1: 129. The experiments for this collection are carried out using a stratified 2 x 5 cross-validation strategy. Therefore, the slopes of education, validation and test sets are the same. 1The ROIs of each individual in the FIA data sets are already grouped into trajectories. 2 (http: / / www.KEEL.es / dataset.php)"}, {"heading": "4.2. Experimental Protocol", "text": "In fact, most of them are able to survive on their own, and they are able to survive on their own if they are not able to survive on their own. Most of them are able to survive on their own, and most of them are able to survive on their own."}, {"heading": "4.3. Evaluation Protocol", "text": "The question that has arisen in recent years is whether and in what form the individual countries will be able to remedy their deficits. (...) The question is only whether and in what way the individual countries are able to get a grip on their deficits. (...) The question is whether and in what way they will get a grip on the deficits. (...) The question is whether and in what form the deficits in the individual countries of the EU can be brought under control. (...) The question is whether the deficits in the individual countries of the euro zone will be brought under control. (...) The question is whether the deficits in the individual countries of the euro zone will be brought under control. (...) The question is whether the deficits in the individual countries of the EU will be brought under control. (...) The question is whether the deficits in the individual countries will be revealed. (...) The question is whether the deficits in the individual countries will be revealed."}, {"heading": "5. Results and Discussion", "text": "The performance of the proposed and state-of-the-art ensemble learning methods is analyzed using synthetic and video data in 4 parts: (1) accuracy and robustness across different levels of overlap and imbalance between design and test data and the use of the proposed loss factor; (2) the performance of RUSBoost with and without progressive partitioning; (3) the combined effects of progressive partitioning and the proposed loss factor; (4) the computational complexity of design and testing."}, {"heading": "5.1. Results of Experiments with Synthetic Data", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1.1. Impact of proposed loss factor", "text": "The performance of the baseline boosting ensembles: AdaBoost, SMOTEBoost, RUS\u03b2-Boost, and RB-Boost are compared in Table 4 \u03b2 for different settings. In addition, F\u03b2 is used to optimize the calculation of loss factors in these ensembles. However, given a specified threshold of test data, the performance of all boosting ensembles decreases in terms of the number of test data and AUPR as an overlap between positive and negative classes. This decrease in performance is more significant if the test data is unbalanced compared to the case in which the test data is balanced. In our experiments, changes in the skew level of test data are unbalanced in different numbers of incorrectly classified negative samples and no change in the number of correctly classified positive samples. Therefore, even for the same level of overlaps, the performance of all ensembles is degraded, both in terms of F-measure and AUPR during testing."}, {"heading": "5.1.2. Impact of progressive partitioning in RUSBoost", "text": "In this section, progressive partitioning is integrated into the RUS without applying F-measure to calculate the loss factor. Table 6 states that the robustness of the RUS significantly improves after using this method of sampling. In fact, using all samples for training by partitioning avoids information loss and can improve classification accuracy. Furthermore, validation at different imbalance levels of the data increases robustness against fluctuations in the imbalance level of the test data. PRUS and PCUSi perform significantly better than RUS in both F-measure and AUPR, especially in D2 and D3. Partitioning these data sets using PCUSi and substituting random random sampling is more effective to improve the performance of RUS."}, {"heading": "5.1.3. Impact of progressive partitioning and loss factor combined", "text": "In this section, progressive partitioning and the proposed loss factor are integrated into the RUS algorithm, resulting in PRUS-F, PCUS-F, and PCUSi-F. Across all areas of skew and overlap in Table 7, PCUSi-F outperforms other classification systems, and PRUS-F takes second place, especially when the imbalance in the test data is higher. Combining F measurement and progressive partitioning is more effective at increasing performance and robustness compared to using each system independently, as accuracy and robustness to improve the imbalance occur simultaneously and not separately during the learning process. If the negative class a priori (CUSi) is partitioned, PBoost performs significantly better than when general partitioning techniques (RUS and CUS) are used."}, {"heading": "5.2. Results of Experiments with Video Data", "text": "Similar to synthetic data sets, the results of the experiments on video data sets are presented in three parts, evaluating the effects of the following factors: (1) use of the proposed loss factor on the performance of Baseline Boosting Ensembles, (2) integration of progressive partitioning in RUS, and (3) use of the proposed loss factor and progressive partitioning compared to baseline and state-of-the-art boosting ensembles. Table 8 indicates that the performance level of all ensembles is lower when the skew level of training data is higher, despite the fact that the imbalance of training data is lower, the data used to test the classifiers contain samples from some individuals not included in the training data. Use of the proposed loss factor improves the performance of Ada, RUS, and SMT in terms of F measures and has no impact on RB performance in most cases of skew between classes in training and test data."}, {"heading": "5.3. Results of Experiments with KEEL Collection", "text": "The second column of the table shows the imbalance of training and test data in each dataset, ranging from 1: 9 to 1: 29. In this table, the best values for each dataset are bold and the second best values are italics to indicate the first and second best classifier, respectively. In terms of F measurement, PCUS has one of the two highest values for 17 datasets, RB one of the two highest values for 15 datasets and PRUS one of the two highest values for 13 datasets. RB is the best classifier for 14 datasets, while PCUS and PRUS are the best values for 5 and 7 datasets, respectively. In terms of AUPR, PCUS and RB have one of the two highest values for 17 datasets, and PRUS have one of the two highest values for 8 datasets."}, {"heading": "5.4. Computational Complexity", "text": "In this section, the time complexity is required to design and test the proposed and baseline boosting ensembles. Although the training time and storage costs of these ensembles are compared, the number of training samples is counted and their validation time and storage costs are considered, the number of validation samples and the number of support vectors of the base classifiers are considered. Figure 9 shows the results obtained with data set D2 in our experiments. The number of training and validation samples, the average number of support vectors and the total number of core function ratings (nSV \u00b7 nval) is shown in Figure 9 (a) - (d) to estimate and compare the design time of the proposed and baseline boosting ensembles. To compare the complexity of these classification systems during the O (nSV) test with a probe sample x, we compared the total number of support vectors in these ensembles SMM groups."}, {"heading": "5.5. Summary of Results", "text": "Summarizing the results for synthetic, video, and KEEL data sets, we observed that: 1. Using the proposed loss factor calculation can reduce distortion of performance in increasing ensembles and increase accuracy; 2. Partitioning improves the performance of RUS in all cases, both in terms of accuracy and robustness to the point of imbalance; 3. AdaBoost has often failed because the training environment was generated by Algo in step 2.i; 3. Integrating both the partitioning and the proposed loss factor exceeds state-of-the-art boosting ensembles by relying on the choice of partitioning technology for each dataset as follows: (a) Using synthetic data, PCUSi-F outperforms all systems in terms of F measurement and AUPR."}, {"heading": "6. Conclusion", "text": "In this paper, a new boosting ensemble algorithm called PBoost is proposed to correct an imbalance based on the idea of modifying RUSBoost by (1) majority-class subsamples using partitional techniques, (2) validating classifiers on a growing validation subgroup, and (3) using a more appropriate calculation of the loss factor. Partitions gradually enter the boosting process to design classifiers over iterations in order to avoid information loss and maintain diversity between them. Validating base classifiers on a growing number of negative samples makes the PBoost ensembles more robust to possible skew levels of data during operation in addition to lowering computational complexity. The new loss factor defined in this boosting ensemble treats the bias of performance over negative classes and directs the boosting process in a more effective direction, with the goal of correctly classifying both classes for a different data class."}, {"heading": "Acknowledgement", "text": "This work was supported in part by the Natural Sciences and Engineering Research Council of Canada and Mitacs."}], "references": [{"title": "An overview of ensemble methods for binary classifiers in multi-class problems: Experimental study on one-vs-one and one-vs-all schemes", "author": ["M. Galar", "A. Fern\u00e1ndez", "E. Barrenechea", "H. Bustince", "F. Herrera"], "venue": "Pattern Recognition 44 (8) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Multiclass imbalance problems: Analysis and potential solutions", "author": ["S. Wang", "X. Yao"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics) 42 (4) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning from imbalanced data", "author": ["H. He", "E.A. Garcia"], "venue": "Knowledge and Data Engineering, IEEE Transactions on 21 (9) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "A review on ensembles for the class imbalance problem: bagging", "author": ["M. Galar", "A. Fernandez", "E. Barrenechea", "H. Bustince", "F. Herrera"], "venue": "boosting-, and hybrid-based approaches, Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on 42 (4) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Skew-sensitive boolean combination for adaptive ensembles\u2013an application to face recognition in video surveillance", "author": ["P.V. Radtke", "E. Granger", "R. Sabourin", "D.O. Gorodnichy"], "venue": "Information Fusion 20 ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Adaptive skew-sensitive ensembles for face recognition in video surveillance", "author": ["M. De-la Torre", "E. Granger", "R. Sabourin", "D.O. Gorodnichy"], "venue": "Pattern Recognition 48 (11) ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Classifier ensembles with trajectory under-sampling for face re-identification", "author": ["R. Soleymani", "E. Granger", "G. Fumera"], "venue": "in: Proceedings of the International Conference on Pattern Recognition Applications and Methods-Volume 1, SCITEPRESS- Science and Technology Publications, Lda", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "A desicion-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "in: Computational learning theory, Springer", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1995}, {"title": "R", "author": ["Y. Freund"], "venue": "E. Schapire, et al., Experiments with a new boosting algorithm, in: Machine Learning and Applications, 1996. ICMLA\u201996 International Conference on", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1996}, {"title": "Smoteboost: Improving prediction of the minority class in boosting", "author": ["N.V. Chawla", "A. Lazarevic", "L.O. Hall", "K.W. Bowyer"], "venue": "in: European Conference on Principles of Data Mining and Knowledge Discovery, Springer", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2003}, {"title": "Msmote: improving classification performance when training data is imbalanced", "author": ["S. Hu", "Y. Liang", "L. Ma", "Y. He"], "venue": "in: Proceedings of the 2009 Second International Workshop on Computer Science and Engineering, Vol. 2, Citeseer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Cost-weighted boosting with jittering and over/under-sampling: Jous-boost", "author": ["D. Mease", "A. Wyner", "A. Buja"], "venue": "J. Machine Learning Research 8 ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning from imbalanced data sets with boosting and data generation: the databoost-im approach", "author": ["H. Guo", "H.L. Viktor"], "venue": "ACM SIGKDD Explorations Newsletter 6 (1) ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "Rusboost: A hybrid approach to alleviating class imbalance", "author": ["C. Seiffert", "T.M. Khoshgoftaar", "J. Van Hulse", "A. Napolitano"], "venue": "Systems, Man and Cybernetics, Part A: Systems and Humans, IEEE Transactions on 40 (1) ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Eusboost: Enhancing ensembles for highly imbalanced data-sets by evolutionary undersampling", "author": ["M. Galar", "A. Fern\u00e1ndez", "E. Barrenechea", "F. Herrera"], "venue": "Pattern Recognition 46 (12) ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Random balance: Ensembles of variable priors classifiers for imbalanced data, Knowledge-Based Systems", "author": ["J.F. D\u0131\u0301ez-Pastor", "J.J. Rodr\u0131\u0301guez", "C. Garc\u0131\u0301a-Osorio", "L.I. Kuncheva"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Adacost: misclassification cost-sensitive boosting", "author": ["W. Fan", "S.J. Stolfo", "J. Zhang", "P.K. Chan"], "venue": "in: Machine Learning and Applications, 1999. ICMLA\u201999 International Conference on", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1999}, {"title": "A comparative study of cost-sensitive boosting algorithms", "author": ["K.M. Ting"], "venue": "in: Machine Learning and Applications, 2000. International Conference on, Citeseer", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2000}, {"title": "Cost-sensitive boosting for classification of imbalanced data", "author": ["Y. Sun", "M.S. Kamel", "A.K. Wong", "Y. Wang"], "venue": "Pattern Recognition 40 (12) ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Evaluating boosting algorithms to classify rare classes: Comparison and improvements", "author": ["M.V. Joshi", "V. Kumar", "R.C. Agarwal"], "venue": "in: Data Mining, 2001. ICDM 2001, Proceedings IEEE International Conference on, IEEE", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2001}, {"title": "Geometric mean based boosting algorithm with over-sampling to resolve data imbalance problem for bankruptcy prediction", "author": ["M.-J. Kim", "D.-K. Kang", "H.B. Kim"], "venue": "Expert Systems with Applications 42 (3) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Ensemble-based classifiers", "author": ["L. Rokach"], "venue": "Artificial Intelligence Review 33 (1-2) ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "Evolutionary undersampling for classification with imbalanced datasets: Proposals and taxonomy, Evolutionary computation", "author": ["S. Garc\u0131\u0301a", "F. Herrera"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "On predicting rare classes with svm ensembles in scene classification", "author": ["R. Yan", "Y. Liu", "R. Jin", "A. Hauptmann"], "venue": "in: Acoustics, Speech, and Signal Processing, 2003. Proceedings.(ICASSP\u201903). 2003 IEEE International Conference on, Vol. 3, IEEE", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "Constructing support vector machine ensemble with segmentation for imbalanced datasets", "author": ["Q. Li", "B. Yang", "Y. Li", "N. Deng", "L. Jing"], "venue": "Neural Computing and Applications 22 (1) ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "An introduction to roc analysis", "author": ["T. Fawcett"], "venue": "Pattern recognition letters 27 (8) ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2006}, {"title": "Theoretical analysis of a performance measure for imbalanced data", "author": ["V. Garc\u0131a", "R. Mollineda", "J. S\u00e1nchez"], "venue": "in: Proceedings of the 20th International Conference on Pattern Recognition (ICPR10)", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "A unified view of performance metrics: translating threshold choice into expected classification loss", "author": ["J. Hern\u00e1ndez-Orallo", "P. Flach", "C. Ferri"], "venue": "Journal of Machine Learning Research 13 (Oct) ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "Precision-recall-gain curves: Pr analysis done right", "author": ["P. Flach", "M. Kull"], "venue": "in: Advances in Neural Information Processing Systems", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Survey of clustering algorithms", "author": ["R. Xu", "D. Wunsch"], "venue": "IEEE Transactions on neural networks 16 (3) ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2005}, {"title": "The cmu face in action (fia) database", "author": ["R. Goh", "L. Liu", "X. Liu", "T. Chen"], "venue": "in: Analysis and Modelling of Faces and Gestures", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2005}, {"title": "S", "author": ["J. Alcal\u00e1", "A. Fern\u00e1ndez", "J. Luengo", "J. Derrac"], "venue": "Garc\u0131\u0301a, L. S\u00e1nchez, F. Herrera, Keel data-mining software tool: Data set repository, integration of algorithms and experimental analysis framework, Journal of Multiple-Valued Logic and Soft Computing 17 (2-3) ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2010}, {"title": "Partially-supervised learning from facial trajectories for face recognition in video surveillance", "author": ["M. De-la Torre", "E. Granger", "P.V. Radtke", "R. Sabourin", "D.O. Gorodnichy"], "venue": "Information Fusion 24 ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2015}, {"title": "Adaptive ensembles for face recognition in changing video surveillance environments", "author": ["C. Pagano", "E. Granger", "R. Sabourin", "G.L. Marcialis", "F. Roli"], "venue": "Information Sciences 286 ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2014}, {"title": "A nonlinear mapping for data structure analysis", "author": ["J.W. Sammon"], "venue": "IEEE Transactions on computers 100 (5) ", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1969}, {"title": "Rapid object detection using a boosted cascade of simple features", "author": ["P. Viola", "M. Jones"], "venue": "in: Computer Vision and Pattern Recognition, 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on, Vol. 1, IEEE", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2001}, {"title": "Multiresolution gray-scale and rotation invariant texture classification with local binary patterns", "author": ["T. Ojala", "M. Pietikainen", "T. Maenpaa"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on 24 (7) ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2002}, {"title": "Libsvm: a library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST) 2 (3) ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2011}, {"title": "Adaboost with svm-based component classifiers", "author": ["X. Li", "L. Wang", "E. Sung"], "venue": "Engineering Applications of Artificial Intelligence 21 (5) ", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2008}, {"title": "S", "author": ["V. L\u00f3pez", "A. Fern\u00e1ndez"], "venue": "Garc\u0131\u0301a, V. Palade, F. Herrera, An insight into classification with imbalanced data: Empirical results and current trends on using data intrinsic characteristics, Information Sciences 250 ", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "Optimal thresholding of classifiers to maximize f1 measure", "author": ["Z.C. Lipton", "C. Elkan", "B. Naryanaswamy"], "venue": "in: Joint European Conference on Machine Learning and Knowledge Discovery in Databases, Springer", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "classification problems using one-vs-all strategy when samples from one class are compared against all samples from all other classes [1, 2].", "startOffset": 134, "endOffset": 140}, {"referenceID": 1, "context": "classification problems using one-vs-all strategy when samples from one class are compared against all samples from all other classes [1, 2].", "startOffset": 134, "endOffset": 140}, {"referenceID": 2, "context": "Several approaches have been proposed in literature to design ensembles of classifiers using imbalanced data [3, 4].", "startOffset": 109, "endOffset": 115}, {"referenceID": 3, "context": "Several approaches have been proposed in literature to design ensembles of classifiers using imbalanced data [3, 4].", "startOffset": 109, "endOffset": 115}, {"referenceID": 4, "context": "Dynamic ensembles allow to adapt the selection and fusion of base classifiers during operations based on the estimated level of skew [5, 6].", "startOffset": 133, "endOffset": 139}, {"referenceID": 5, "context": "Dynamic ensembles allow to adapt the selection and fusion of base classifiers during operations based on the estimated level of skew [5, 6].", "startOffset": 133, "endOffset": 139}, {"referenceID": 4, "context": "For example, in [5, 6] authors design base classifiers for a range of different levels of imbalance.", "startOffset": 16, "endOffset": 22}, {"referenceID": 5, "context": "For example, in [5, 6] authors design base classifiers for a range of different levels of imbalance.", "startOffset": 16, "endOffset": 22}, {"referenceID": 6, "context": "In contrast, using a static approach, the range of possible imbalance levels can be accounted for during design by training base classifiers on data subsets with different imbalance levels [7].", "startOffset": 189, "endOffset": 192}, {"referenceID": 7, "context": "Boosting [8, 9] is a common static ensemble method that has been modified in several ways to learn from imbalanced data (see a review by Galar et al.", "startOffset": 9, "endOffset": 15}, {"referenceID": 8, "context": "Boosting [8, 9] is a common static ensemble method that has been modified in several ways to learn from imbalanced data (see a review by Galar et al.", "startOffset": 9, "endOffset": 15}, {"referenceID": 3, "context": "[4]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "In data-level Boosting approaches, training data is rebalanced by up-sampling positive class, under-sampling negative class, or using both up-sampling and under-sampling[10, 11, 12, 13, 14, 15, 16].", "startOffset": 169, "endOffset": 197}, {"referenceID": 10, "context": "In data-level Boosting approaches, training data is rebalanced by up-sampling positive class, under-sampling negative class, or using both up-sampling and under-sampling[10, 11, 12, 13, 14, 15, 16].", "startOffset": 169, "endOffset": 197}, {"referenceID": 11, "context": "In data-level Boosting approaches, training data is rebalanced by up-sampling positive class, under-sampling negative class, or using both up-sampling and under-sampling[10, 11, 12, 13, 14, 15, 16].", "startOffset": 169, "endOffset": 197}, {"referenceID": 12, "context": "In data-level Boosting approaches, training data is rebalanced by up-sampling positive class, under-sampling negative class, or using both up-sampling and under-sampling[10, 11, 12, 13, 14, 15, 16].", "startOffset": 169, "endOffset": 197}, {"referenceID": 13, "context": "In data-level Boosting approaches, training data is rebalanced by up-sampling positive class, under-sampling negative class, or using both up-sampling and under-sampling[10, 11, 12, 13, 14, 15, 16].", "startOffset": 169, "endOffset": 197}, {"referenceID": 14, "context": "In data-level Boosting approaches, training data is rebalanced by up-sampling positive class, under-sampling negative class, or using both up-sampling and under-sampling[10, 11, 12, 13, 14, 15, 16].", "startOffset": 169, "endOffset": 197}, {"referenceID": 15, "context": "In data-level Boosting approaches, training data is rebalanced by up-sampling positive class, under-sampling negative class, or using both up-sampling and under-sampling[10, 11, 12, 13, 14, 15, 16].", "startOffset": 169, "endOffset": 197}, {"referenceID": 9, "context": "Up-sampling methods like SMOTEBoost [10] are often more accurate, but they are computationally complex.", "startOffset": 36, "endOffset": 40}, {"referenceID": 13, "context": "contrast, random under-sampling (RUS) [14] is more computationally efficient, but suffers from information loss.", "startOffset": 38, "endOffset": 42}, {"referenceID": 16, "context": "This issue can be avoided by adopting a cost-sensitive approach [17, 18, 19], that defines different misclassification costs for different classes and integrates these cost factors into Boosting learning process.", "startOffset": 64, "endOffset": 76}, {"referenceID": 17, "context": "This issue can be avoided by adopting a cost-sensitive approach [17, 18, 19], that defines different misclassification costs for different classes and integrates these cost factors into Boosting learning process.", "startOffset": 64, "endOffset": 76}, {"referenceID": 18, "context": "This issue can be avoided by adopting a cost-sensitive approach [17, 18, 19], that defines different misclassification costs for different classes and integrates these cost factors into Boosting learning process.", "startOffset": 64, "endOffset": 76}, {"referenceID": 19, "context": "In contrast, cost-free techniques modify learning algorithms by enhancing loss factor calculation without considering cost factors [20, 21].", "startOffset": 131, "endOffset": 139}, {"referenceID": 20, "context": "In contrast, cost-free techniques modify learning algorithms by enhancing loss factor calculation without considering cost factors [20, 21].", "startOffset": 131, "endOffset": 139}, {"referenceID": 3, "context": "Ensemble learning methods exploit one or a combination of aforementioned techniques [4] to handle imbalance.", "startOffset": 84, "endOffset": 87}, {"referenceID": 21, "context": "Classifier ensembles can provide higher accuracy and robustness than a single classifier system by combining diverse classifiers [22].", "startOffset": 129, "endOffset": 133}, {"referenceID": 7, "context": "Boosting is a common static ensemble learning algorithm initiated with AdaBoost [8] and improved in AdaBoost.", "startOffset": 80, "endOffset": 83}, {"referenceID": 8, "context": "problems) [9] to effectively promote a weak learner that performs slightly better than random guessing into a", "startOffset": 10, "endOffset": 13}, {"referenceID": 9, "context": "A popular up-sampling Boosting approach is SMOTEBoost [10] that", "startOffset": 54, "endOffset": 58}, {"referenceID": 10, "context": "MSMOTEBoost [11] use modified", "startOffset": 12, "endOffset": 16}, {"referenceID": 11, "context": "Jous-Boost [12] oversample the positive class by duplicating it, instead of creating new samples, and introduce perturbation (jittering) to this data in order to avoid overfitting.", "startOffset": 11, "endOffset": 15}, {"referenceID": 12, "context": "DataBoost-IM [13] oversample difficult samples from both classes and integrates it into AdaBoost.", "startOffset": 13, "endOffset": 17}, {"referenceID": 13, "context": "In under-sampling Boosting category, RUSBoost [14] integrates random under-sampling (RUS) into AdaBoost.", "startOffset": 46, "endOffset": 50}, {"referenceID": 14, "context": "The sample selection paradigm in RUSBoost is managed in EUSBoost [15] to create less correlated subsets using evolutionary prototype selection [23].", "startOffset": 65, "endOffset": 69}, {"referenceID": 22, "context": "The sample selection paradigm in RUSBoost is managed in EUSBoost [15] to create less correlated subsets using evolutionary prototype selection [23].", "startOffset": 143, "endOffset": 147}, {"referenceID": 15, "context": "Some researchers combine SMOTE and RUS in AdaBoost to achieve greater diversity and avoid loss of information as in Random Balance Boosting (RB-Boost) [16].", "startOffset": 151, "endOffset": 155}, {"referenceID": 6, "context": "In partitional approaches [7, 24, 25] bootstraps are selected without replacement either randomly [24], by clustering [25] or based on a prior knowledge from the application (like trajectories in video surveillance applications such as face re-identification [7]).", "startOffset": 26, "endOffset": 37}, {"referenceID": 23, "context": "In partitional approaches [7, 24, 25] bootstraps are selected without replacement either randomly [24], by clustering [25] or based on a prior knowledge from the application (like trajectories in video surveillance applications such as face re-identification [7]).", "startOffset": 26, "endOffset": 37}, {"referenceID": 24, "context": "In partitional approaches [7, 24, 25] bootstraps are selected without replacement either randomly [24], by clustering [25] or based on a prior knowledge from the application (like trajectories in video surveillance applications such as face re-identification [7]).", "startOffset": 26, "endOffset": 37}, {"referenceID": 23, "context": "In partitional approaches [7, 24, 25] bootstraps are selected without replacement either randomly [24], by clustering [25] or based on a prior knowledge from the application (like trajectories in video surveillance applications such as face re-identification [7]).", "startOffset": 98, "endOffset": 102}, {"referenceID": 24, "context": "In partitional approaches [7, 24, 25] bootstraps are selected without replacement either randomly [24], by clustering [25] or based on a prior knowledge from the application (like trajectories in video surveillance applications such as face re-identification [7]).", "startOffset": 118, "endOffset": 122}, {"referenceID": 6, "context": "In partitional approaches [7, 24, 25] bootstraps are selected without replacement either randomly [24], by clustering [25] or based on a prior knowledge from the application (like trajectories in video surveillance applications such as face re-identification [7]).", "startOffset": 259, "endOffset": 262}, {"referenceID": 23, "context": "[24] the negative data is randomly decomposed into a number of subsets and each subset, combined with the positive samples, is used to train a classifier.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] partition negative data by clustering it using k-means in the feature space and then create an ensemble from the classifiers trained on each negative cluster and the positive samples.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "In [7], partitioning negative class is done by selecting samples from a set of trajectories that are formed based on the tracking information, as found in several video surveillance applications like face re-identification.", "startOffset": 3, "endOffset": 6}, {"referenceID": 16, "context": "Cost-sensitive Boosting methods including AdaCost [17], CSB [18] and AdaC [19], embed different misclassification cost factors into loss function or weight update formula of AdaBoost.", "startOffset": 50, "endOffset": 54}, {"referenceID": 17, "context": "Cost-sensitive Boosting methods including AdaCost [17], CSB [18] and AdaC [19], embed different misclassification cost factors into loss function or weight update formula of AdaBoost.", "startOffset": 60, "endOffset": 64}, {"referenceID": 18, "context": "Cost-sensitive Boosting methods including AdaCost [17], CSB [18] and AdaC [19], embed different misclassification cost factors into loss function or weight update formula of AdaBoost.", "startOffset": 74, "endOffset": 78}, {"referenceID": 16, "context": "Given \u03bci as the cost factor of sample xi, in AdaCost [17], two cost adjustment functions are defined for each sample as \u03c6+ =\u22120.", "startOffset": 53, "endOffset": 57}, {"referenceID": 17, "context": "CSB [18] introduce two different cost factors for positive and negative classes as \u03bc+ = 1 and \u03bc\u2212 \u2265 1, respectively.", "startOffset": 4, "endOffset": 8}, {"referenceID": 18, "context": "In AdaC1, 2, 3 [19] cost factors are embedded into the weight update formula in three different ways.", "startOffset": 15, "endOffset": 19}, {"referenceID": 19, "context": "In RareBoost [20], two different \u03b1s are defined for positive and negative classes as:", "startOffset": 13, "endOffset": 17}, {"referenceID": 20, "context": "[21] also define two different \u03b1es for positive and negative classes as:", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "ROC space does not adequately reflect the impact of imbalance [26] on performance because big variations in the number of misclassified negative class (FP) results in a small change in FPR, especially if a small increase in TPR can mask it.", "startOffset": 62, "endOffset": 66}, {"referenceID": 26, "context": "Some authors define variants of the existing performance metrics by accounting for \u03c0 [27, 28, 29].", "startOffset": 85, "endOffset": 97}, {"referenceID": 27, "context": "Some authors define variants of the existing performance metrics by accounting for \u03c0 [27, 28, 29].", "startOffset": 85, "endOffset": 97}, {"referenceID": 28, "context": "Some authors define variants of the existing performance metrics by accounting for \u03c0 [27, 28, 29].", "startOffset": 85, "endOffset": 97}, {"referenceID": 27, "context": "ple, in [28], the authors define a measure of expected accuracy in terms of AUC as \u03c0(1\u2212\u03c0)(2AUC\u22121)+1/2, and precision-recall gain (PRG) curve [29] normalize precision and recall in terms of \u03c0 as:", "startOffset": 8, "endOffset": 12}, {"referenceID": 28, "context": "ple, in [28], the authors define a measure of expected accuracy in terms of AUC as \u03c0(1\u2212\u03c0)(2AUC\u22121)+1/2, and precision-recall gain (PRG) curve [29] normalize precision and recall in terms of \u03c0 as:", "startOffset": 141, "endOffset": 145}, {"referenceID": 26, "context": "Masking the effect of imbalance in performance metrics as done in [27, 28, 29] can misguide the learning process of Boosting ensembles and bias the performance towards negative class.", "startOffset": 66, "endOffset": 78}, {"referenceID": 27, "context": "Masking the effect of imbalance in performance metrics as done in [27, 28, 29] can misguide the learning process of Boosting ensembles and bias the performance towards negative class.", "startOffset": 66, "endOffset": 78}, {"referenceID": 28, "context": "Masking the effect of imbalance in performance metrics as done in [27, 28, 29] can misguide the learning process of Boosting ensembles and bias the performance towards negative class.", "startOffset": 66, "endOffset": 78}, {"referenceID": 29, "context": "There are several possible ways to partition the negative samples into disjoint subsets in literature [30] e.", "startOffset": 102, "endOffset": 106}, {"referenceID": 23, "context": "Two partitioning techniques have been used in literature to partition data to learn ensembles from imbalanced data: Random Under-Sampling without replacement (we call RUSwR in this paper) [24] , and Cluster Under-Sampling (CUS) [25].", "startOffset": 188, "endOffset": 192}, {"referenceID": 24, "context": "Two partitioning techniques have been used in literature to partition data to learn ensembles from imbalanced data: Random Under-Sampling without replacement (we call RUSwR in this paper) [24] , and Cluster Under-Sampling (CUS) [25].", "startOffset": 228, "endOffset": 232}, {"referenceID": 6, "context": "For example, Trajectory Under-Sampling (TUS) is applicable in video surveillance applications where samples captured for a same individual are regrouped into a trajectory [7].", "startOffset": 171, "endOffset": 174}, {"referenceID": 28, "context": "When F\u03b2-measure is used as the evaluation metric, the base classifier to beat is the one that predicts everything as positive [29].", "startOffset": 126, "endOffset": 130}, {"referenceID": 8, "context": "M1 [9], and one state of the art method from each family of the data-level approaches reviewed in Section", "startOffset": 3, "endOffset": 6}, {"referenceID": 9, "context": "2 including SMOTEBoost [10], RUSBoost [14], and RB-Boost [16].", "startOffset": 23, "endOffset": 27}, {"referenceID": 13, "context": "2 including SMOTEBoost [10], RUSBoost [14], and RB-Boost [16].", "startOffset": 38, "endOffset": 42}, {"referenceID": 15, "context": "2 including SMOTEBoost [10], RUSBoost [14], and RB-Boost [16].", "startOffset": 57, "endOffset": 61}, {"referenceID": 30, "context": "The datasets that are used for the experiments include: (1) A set of synthetic 2D data sets in which the level of skew and overlap between classes are controllable, (2) the Face In Action (FIA) video database [31] that emulates a passport checking scenario in face re-identification application, (3) a set of 21 real-world problems from the KEEL dataset repository [32].", "startOffset": 209, "endOffset": 213}, {"referenceID": 31, "context": "The datasets that are used for the experiments include: (1) A set of synthetic 2D data sets in which the level of skew and overlap between classes are controllable, (2) the Face In Action (FIA) video database [31] that emulates a passport checking scenario in face re-identification application, (3) a set of 21 real-world problems from the KEEL dataset repository [32].", "startOffset": 365, "endOffset": 369}, {"referenceID": 0, "context": "To generate the 2D synthetic data, M+ = 100 positive class samples are generated with a normal distribution as N(m+,\u03c3+), where m+ = (0,0) and \u03c3+ = [1 0 0 1 ] indicate the mean and covariance matrix of this distribution, respectively.", "startOffset": 147, "endOffset": 157}, {"referenceID": 0, "context": "To generate the 2D synthetic data, M+ = 100 positive class samples are generated with a normal distribution as N(m+,\u03c3+), where m+ = (0,0) and \u03c3+ = [1 0 0 1 ] indicate the mean and covariance matrix of this distribution, respectively.", "startOffset": 147, "endOffset": 157}, {"referenceID": 32, "context": "[33, 34, 7].", "startOffset": 0, "endOffset": 11}, {"referenceID": 33, "context": "[33, 34, 7].", "startOffset": 0, "endOffset": 11}, {"referenceID": 6, "context": "[33, 34, 7].", "startOffset": 0, "endOffset": 11}, {"referenceID": 30, "context": "FIA video database [31] contains video sequences that emulate a passport checking scenario.", "startOffset": 19, "endOffset": 23}, {"referenceID": 35, "context": "ROIs are converted to gray-scale and rescaled to 70\u00d7 70 pixels using Viola Jones algorithm [36] from this video.", "startOffset": 91, "endOffset": 95}, {"referenceID": 34, "context": "Figure 5: Examples of 2D mapping of LBP feature vectors belonging to 8 individuals using Sammon mapping [35] on the left, and examples of 70 \u00d7 70 pixels ROIs in a trajectory captures with camera 3, during session one for ID010 with their frame numbers on the right.", "startOffset": 104, "endOffset": 108}, {"referenceID": 36, "context": "Binary Patterns (LBP) [37] histograms have been extracted as features.", "startOffset": 22, "endOffset": 26}, {"referenceID": 31, "context": "KEEL (Knowledge Extraction based on Evolutionary Learning) tool is an open source software that supports data management and a designer of experiments [32].", "startOffset": 151, "endOffset": 155}, {"referenceID": 37, "context": "We use SVM with RBF kernel [38] as the base classifier where K(x\u2032,x\u2032\u2032) = exp{\u2212\u2016x\u2032\u2212x\u2032\u2032\u20162/2\u03ba2}.", "startOffset": 27, "endOffset": 31}, {"referenceID": 38, "context": "The kernel parameter \u03ba is set as the average of the mean minimum distance between any two training samples and the scatter radius of the training samples in the input space [39].", "startOffset": 173, "endOffset": 177}, {"referenceID": 37, "context": "We used the LibSVM implementation of [38].", "startOffset": 37, "endOffset": 41}, {"referenceID": 39, "context": "In experiments with synthetic data, the overlap level between positive and negative classes are also varied because the issue of imbalance is related to the level of overlap between classes [41].", "startOffset": 190, "endOffset": 194}, {"referenceID": 8, "context": "Abbreviation Sampling method Boosting Ensemble Loss factor Data Ada: Resampling with replacement AdaBoost [9] Weighted accuracy Synthetic, Video, KEEL Ada-F: Resampling with replacement Modified AdaBoost [9] Proposed F-measure Synthetic, Video SMT: Synthetic minority over-sampling technique (SMOTE) SMOTEBoost [10] Weighted accuracy Synthetic, Video, KEEL SMT-F Synthetic minority over-sampling technique(SMOTE) Modified SMOTEBoost [10] Proposed F-measure Synthetic, Video RUS: Random under-sampling with replacement (RUS) RUSBoost [14] Weighted accuracy Synthetic, Video, KEEL RUS-F: Random under-sampling with replacement (RUS) Modified RUSBoost [14] Proposed F-measure Synthetic, Video RB: Combination of up-sampling (SMOTE) and under-sampling (RUS) RB-Boost [16] Weighted accuracy Synthetic, Video, KEEL RB-F: Combination of up-sampling (SMOTE) and under-sampling (RUS) Modified RB-Boost [16] Proposed F-measure Synthetic, Video PRUS: Random under-sampling without replacement (RUSwR) Progressive Boosting Weighted accuracy Synthetic, Video PRUS-F: Random under-sampling without replacement (RUSwR) Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUS: Selecting clusters found by k-means Progressive Boosting Weighted accuracy Synthetic, Video PCUS-F: Selecting clusters found by k-means Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUSi: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Weighted accuracy Synthetic PCUSi-F: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Proposed F-measure Synthetic PTUS: Selecting trajectories in video dataset Progressive Boosting Weighted accuracy Video PTUS-F: Selecting trajectories in video dataset Progressive Boosting Proposed F-measure Video", "startOffset": 106, "endOffset": 109}, {"referenceID": 8, "context": "Abbreviation Sampling method Boosting Ensemble Loss factor Data Ada: Resampling with replacement AdaBoost [9] Weighted accuracy Synthetic, Video, KEEL Ada-F: Resampling with replacement Modified AdaBoost [9] Proposed F-measure Synthetic, Video SMT: Synthetic minority over-sampling technique (SMOTE) SMOTEBoost [10] Weighted accuracy Synthetic, Video, KEEL SMT-F Synthetic minority over-sampling technique(SMOTE) Modified SMOTEBoost [10] Proposed F-measure Synthetic, Video RUS: Random under-sampling with replacement (RUS) RUSBoost [14] Weighted accuracy Synthetic, Video, KEEL RUS-F: Random under-sampling with replacement (RUS) Modified RUSBoost [14] Proposed F-measure Synthetic, Video RB: Combination of up-sampling (SMOTE) and under-sampling (RUS) RB-Boost [16] Weighted accuracy Synthetic, Video, KEEL RB-F: Combination of up-sampling (SMOTE) and under-sampling (RUS) Modified RB-Boost [16] Proposed F-measure Synthetic, Video PRUS: Random under-sampling without replacement (RUSwR) Progressive Boosting Weighted accuracy Synthetic, Video PRUS-F: Random under-sampling without replacement (RUSwR) Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUS: Selecting clusters found by k-means Progressive Boosting Weighted accuracy Synthetic, Video PCUS-F: Selecting clusters found by k-means Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUSi: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Weighted accuracy Synthetic PCUSi-F: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Proposed F-measure Synthetic PTUS: Selecting trajectories in video dataset Progressive Boosting Weighted accuracy Video PTUS-F: Selecting trajectories in video dataset Progressive Boosting Proposed F-measure Video", "startOffset": 204, "endOffset": 207}, {"referenceID": 9, "context": "Abbreviation Sampling method Boosting Ensemble Loss factor Data Ada: Resampling with replacement AdaBoost [9] Weighted accuracy Synthetic, Video, KEEL Ada-F: Resampling with replacement Modified AdaBoost [9] Proposed F-measure Synthetic, Video SMT: Synthetic minority over-sampling technique (SMOTE) SMOTEBoost [10] Weighted accuracy Synthetic, Video, KEEL SMT-F Synthetic minority over-sampling technique(SMOTE) Modified SMOTEBoost [10] Proposed F-measure Synthetic, Video RUS: Random under-sampling with replacement (RUS) RUSBoost [14] Weighted accuracy Synthetic, Video, KEEL RUS-F: Random under-sampling with replacement (RUS) Modified RUSBoost [14] Proposed F-measure Synthetic, Video RB: Combination of up-sampling (SMOTE) and under-sampling (RUS) RB-Boost [16] Weighted accuracy Synthetic, Video, KEEL RB-F: Combination of up-sampling (SMOTE) and under-sampling (RUS) Modified RB-Boost [16] Proposed F-measure Synthetic, Video PRUS: Random under-sampling without replacement (RUSwR) Progressive Boosting Weighted accuracy Synthetic, Video PRUS-F: Random under-sampling without replacement (RUSwR) Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUS: Selecting clusters found by k-means Progressive Boosting Weighted accuracy Synthetic, Video PCUS-F: Selecting clusters found by k-means Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUSi: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Weighted accuracy Synthetic PCUSi-F: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Proposed F-measure Synthetic PTUS: Selecting trajectories in video dataset Progressive Boosting Weighted accuracy Video PTUS-F: Selecting trajectories in video dataset Progressive Boosting Proposed F-measure Video", "startOffset": 311, "endOffset": 315}, {"referenceID": 9, "context": "Abbreviation Sampling method Boosting Ensemble Loss factor Data Ada: Resampling with replacement AdaBoost [9] Weighted accuracy Synthetic, Video, KEEL Ada-F: Resampling with replacement Modified AdaBoost [9] Proposed F-measure Synthetic, Video SMT: Synthetic minority over-sampling technique (SMOTE) SMOTEBoost [10] Weighted accuracy Synthetic, Video, KEEL SMT-F Synthetic minority over-sampling technique(SMOTE) Modified SMOTEBoost [10] Proposed F-measure Synthetic, Video RUS: Random under-sampling with replacement (RUS) RUSBoost [14] Weighted accuracy Synthetic, Video, KEEL RUS-F: Random under-sampling with replacement (RUS) Modified RUSBoost [14] Proposed F-measure Synthetic, Video RB: Combination of up-sampling (SMOTE) and under-sampling (RUS) RB-Boost [16] Weighted accuracy Synthetic, Video, KEEL RB-F: Combination of up-sampling (SMOTE) and under-sampling (RUS) Modified RB-Boost [16] Proposed F-measure Synthetic, Video PRUS: Random under-sampling without replacement (RUSwR) Progressive Boosting Weighted accuracy Synthetic, Video PRUS-F: Random under-sampling without replacement (RUSwR) Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUS: Selecting clusters found by k-means Progressive Boosting Weighted accuracy Synthetic, Video PCUS-F: Selecting clusters found by k-means Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUSi: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Weighted accuracy Synthetic PCUSi-F: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Proposed F-measure Synthetic PTUS: Selecting trajectories in video dataset Progressive Boosting Weighted accuracy Video PTUS-F: Selecting trajectories in video dataset Progressive Boosting Proposed F-measure Video", "startOffset": 433, "endOffset": 437}, {"referenceID": 13, "context": "Abbreviation Sampling method Boosting Ensemble Loss factor Data Ada: Resampling with replacement AdaBoost [9] Weighted accuracy Synthetic, Video, KEEL Ada-F: Resampling with replacement Modified AdaBoost [9] Proposed F-measure Synthetic, Video SMT: Synthetic minority over-sampling technique (SMOTE) SMOTEBoost [10] Weighted accuracy Synthetic, Video, KEEL SMT-F Synthetic minority over-sampling technique(SMOTE) Modified SMOTEBoost [10] Proposed F-measure Synthetic, Video RUS: Random under-sampling with replacement (RUS) RUSBoost [14] Weighted accuracy Synthetic, Video, KEEL RUS-F: Random under-sampling with replacement (RUS) Modified RUSBoost [14] Proposed F-measure Synthetic, Video RB: Combination of up-sampling (SMOTE) and under-sampling (RUS) RB-Boost [16] Weighted accuracy Synthetic, Video, KEEL RB-F: Combination of up-sampling (SMOTE) and under-sampling (RUS) Modified RB-Boost [16] Proposed F-measure Synthetic, Video PRUS: Random under-sampling without replacement (RUSwR) Progressive Boosting Weighted accuracy Synthetic, Video PRUS-F: Random under-sampling without replacement (RUSwR) Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUS: Selecting clusters found by k-means Progressive Boosting Weighted accuracy Synthetic, Video PCUS-F: Selecting clusters found by k-means Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUSi: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Weighted accuracy Synthetic PCUSi-F: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Proposed F-measure Synthetic PTUS: Selecting trajectories in video dataset Progressive Boosting Weighted accuracy Video PTUS-F: Selecting trajectories in video dataset Progressive Boosting Proposed F-measure Video", "startOffset": 533, "endOffset": 537}, {"referenceID": 13, "context": "Abbreviation Sampling method Boosting Ensemble Loss factor Data Ada: Resampling with replacement AdaBoost [9] Weighted accuracy Synthetic, Video, KEEL Ada-F: Resampling with replacement Modified AdaBoost [9] Proposed F-measure Synthetic, Video SMT: Synthetic minority over-sampling technique (SMOTE) SMOTEBoost [10] Weighted accuracy Synthetic, Video, KEEL SMT-F Synthetic minority over-sampling technique(SMOTE) Modified SMOTEBoost [10] Proposed F-measure Synthetic, Video RUS: Random under-sampling with replacement (RUS) RUSBoost [14] Weighted accuracy Synthetic, Video, KEEL RUS-F: Random under-sampling with replacement (RUS) Modified RUSBoost [14] Proposed F-measure Synthetic, Video RB: Combination of up-sampling (SMOTE) and under-sampling (RUS) RB-Boost [16] Weighted accuracy Synthetic, Video, KEEL RB-F: Combination of up-sampling (SMOTE) and under-sampling (RUS) Modified RB-Boost [16] Proposed F-measure Synthetic, Video PRUS: Random under-sampling without replacement (RUSwR) Progressive Boosting Weighted accuracy Synthetic, Video PRUS-F: Random under-sampling without replacement (RUSwR) Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUS: Selecting clusters found by k-means Progressive Boosting Weighted accuracy Synthetic, Video PCUS-F: Selecting clusters found by k-means Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUSi: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Weighted accuracy Synthetic PCUSi-F: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Proposed F-measure Synthetic PTUS: Selecting trajectories in video dataset Progressive Boosting Weighted accuracy Video PTUS-F: Selecting trajectories in video dataset Progressive Boosting Proposed F-measure Video", "startOffset": 649, "endOffset": 653}, {"referenceID": 15, "context": "Abbreviation Sampling method Boosting Ensemble Loss factor Data Ada: Resampling with replacement AdaBoost [9] Weighted accuracy Synthetic, Video, KEEL Ada-F: Resampling with replacement Modified AdaBoost [9] Proposed F-measure Synthetic, Video SMT: Synthetic minority over-sampling technique (SMOTE) SMOTEBoost [10] Weighted accuracy Synthetic, Video, KEEL SMT-F Synthetic minority over-sampling technique(SMOTE) Modified SMOTEBoost [10] Proposed F-measure Synthetic, Video RUS: Random under-sampling with replacement (RUS) RUSBoost [14] Weighted accuracy Synthetic, Video, KEEL RUS-F: Random under-sampling with replacement (RUS) Modified RUSBoost [14] Proposed F-measure Synthetic, Video RB: Combination of up-sampling (SMOTE) and under-sampling (RUS) RB-Boost [16] Weighted accuracy Synthetic, Video, KEEL RB-F: Combination of up-sampling (SMOTE) and under-sampling (RUS) Modified RB-Boost [16] Proposed F-measure Synthetic, Video PRUS: Random under-sampling without replacement (RUSwR) Progressive Boosting Weighted accuracy Synthetic, Video PRUS-F: Random under-sampling without replacement (RUSwR) Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUS: Selecting clusters found by k-means Progressive Boosting Weighted accuracy Synthetic, Video PCUS-F: Selecting clusters found by k-means Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUSi: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Weighted accuracy Synthetic PCUSi-F: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Proposed F-measure Synthetic PTUS: Selecting trajectories in video dataset Progressive Boosting Weighted accuracy Video PTUS-F: Selecting trajectories in video dataset Progressive Boosting Proposed F-measure Video", "startOffset": 763, "endOffset": 767}, {"referenceID": 15, "context": "Abbreviation Sampling method Boosting Ensemble Loss factor Data Ada: Resampling with replacement AdaBoost [9] Weighted accuracy Synthetic, Video, KEEL Ada-F: Resampling with replacement Modified AdaBoost [9] Proposed F-measure Synthetic, Video SMT: Synthetic minority over-sampling technique (SMOTE) SMOTEBoost [10] Weighted accuracy Synthetic, Video, KEEL SMT-F Synthetic minority over-sampling technique(SMOTE) Modified SMOTEBoost [10] Proposed F-measure Synthetic, Video RUS: Random under-sampling with replacement (RUS) RUSBoost [14] Weighted accuracy Synthetic, Video, KEEL RUS-F: Random under-sampling with replacement (RUS) Modified RUSBoost [14] Proposed F-measure Synthetic, Video RB: Combination of up-sampling (SMOTE) and under-sampling (RUS) RB-Boost [16] Weighted accuracy Synthetic, Video, KEEL RB-F: Combination of up-sampling (SMOTE) and under-sampling (RUS) Modified RB-Boost [16] Proposed F-measure Synthetic, Video PRUS: Random under-sampling without replacement (RUSwR) Progressive Boosting Weighted accuracy Synthetic, Video PRUS-F: Random under-sampling without replacement (RUSwR) Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUS: Selecting clusters found by k-means Progressive Boosting Weighted accuracy Synthetic, Video PCUS-F: Selecting clusters found by k-means Progressive Boosting Proposed F-measure Synthetic, Video, KEEL PCUSi: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Weighted accuracy Synthetic PCUSi-F: Selecting ideal clusters generated in synthetic dataset Progressive Boosting Proposed F-measure Synthetic PTUS: Selecting trajectories in video dataset Progressive Boosting Weighted accuracy Video PTUS-F: Selecting trajectories in video dataset Progressive Boosting Proposed F-measure Video", "startOffset": 893, "endOffset": 897}, {"referenceID": 27, "context": "ing condition or based on operating conditions: the cost proportions or skew levels [28].", "startOffset": 84, "endOffset": 88}, {"referenceID": 27, "context": "The performance metrics that can be maximized to set the decision threshold are accuracy, Brier score, AUC, expected cost and F-measure [28, 42].", "startOffset": 136, "endOffset": 144}, {"referenceID": 40, "context": "The performance metrics that can be maximized to set the decision threshold are accuracy, Brier score, AUC, expected cost and F-measure [28, 42].", "startOffset": 136, "endOffset": 144}, {"referenceID": 37, "context": "The computational complexity of SVM implemented in LibSVM is evaluated in [38], as O(ntrd) per iteration I, where ntr is the training set size, and d is the number of features.", "startOffset": 74, "endOffset": 78}], "year": 2017, "abstractText": "In practice, pattern recognition applications often suffer from imbalanced data distributions between classes, which may vary during operations w.r.t. the design data. Two-class classification systems designed using imbalanced data tend to recognize the majority (negative) class better, while the class of interest (positive class) often has the smaller number of samples. Several data-level techniques have been proposed to alleviate this issue, where classifier ensembles are designed with balanced data subsets by up-sampling positive samples or under-sampling negative samples. However, some informative samples may be neglected by random under-sampling and adding synthetic positive samples through up-sampling adds to training complexity. In this paper, a new ensemble learning algorithm called Progressive Boosting (PBoost) is proposed that progressively inserts uncorrelated groups of samples into a Boosting procedure to avoid loosing information while generating a diverse pool of classifiers. Base classifiers in this ensemble are generated from one iteration to the next, using subsets from a validation set that grows gradually in size and imbalance. Consequently, PBoost is more robust when the operational data may have unknown and variable levels of skew. In addition, the computation complexity of PBoost is lower than Boosting ensembles in literature that use under-sampling for learning from imbalanced data because not all of the base classifiers are validated on all negative samples. In PBoost algorithm, a new loss factor is proposed to avoid bias of performance towards the negative class. Using this loss factor, the weight update of samples and classifier contribution in final predictions are set based on the ability to recognize both classes. Using the proposed loss factor instead of standard accuracy can avoid biasing performance in any Boosting ensemble. The proposed approach was validated and compared using synthetic data, videos from the Faces In Action dataset that emulates face re-identification applications, and KEEL collection of datasets. Results show that PBoost can outperform state of the art techniques in terms of both accuracy and complexity over different levels of imbalance and overlap between classes.", "creator": "LaTeX with hyperref package"}}}