{"id": "1706.01663", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jun-2017", "title": "Learning Pairwise Disjoint Simple Languages from Positive Examples", "abstract": "A classical problem in grammatical inference is to identify a deterministic finite automaton (DFA) from a set of positive and negative examples. In this paper, we address the related - yet seemingly novel - problem of identifying a set of DFAs from examples that belong to different unknown simple regular languages. We propose two methods based on compression for clustering the observed positive examples. We apply our methods to a set of print jobs submitted to large industrial printers.", "histories": [["v1", "Tue, 6 Jun 2017 09:03:17 GMT  (292kb,D)", "http://arxiv.org/abs/1706.01663v1", "This paper has been accepted at the Learning and Automata (LearnAut) Workshop, LICS 2017 (Reykjavik, Iceland)"]], "COMMENTS": "This paper has been accepted at the Learning and Automata (LearnAut) Workshop, LICS 2017 (Reykjavik, Iceland)", "reviews": [], "SUBJECTS": "cs.LG cs.FL", "authors": ["alexis linard", "rick smetsers", "frits vaandrager", "umar waqas", "joost van pinxten", "sicco verwer"], "accepted": false, "id": "1706.01663"}, "pdf": {"name": "1706.01663.pdf", "metadata": {"source": "CRF", "title": "Learning Pairwise Disjoint Simple Languages from Positive Examples", "authors": ["Alexis Linard", "Rick Smetsers", "Frits Vaandrager", "Umar Waqas", "Joost van Pinxten", "Sicco Verwer"], "emails": ["f.vaandrager}@cs.ru.nl", "j.h.h.v.pinxten}@tue.nl", "s.e.verwer@tudelft.nl"], "sections": [{"heading": null, "text": "I. INTRODUCTIONA The classic problem in grammatical reasoning is to find, i.e. learn, a regular language from a set of examples of that language. If this sentence is divided into positive examples (which belong to the language) and negative examples (which do not belong to the language), the problem is typically solved by searching for the smallest deterministic finite automata (DFA) that accept the positive examples and reject the negative ones. If there are enough examples, algorithms exist that correctly learn the unknown language from these examples [1]. However, this is not necessarily the case if only positive examples are available. We consider a framework in which positive examples from several regular languages can be observed, but it is not clear to which of these languages the examples belong. Furthermore, it is known that each example belongs to exactly one of these languages, i.e. that the languages are fragmented. As a result, the positive examples for one language are negative examples for the other languages."}, {"heading": "II. PRELIMINARIES", "text": "A string is a finite sequence of Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A = A"}, {"heading": "III. CLUSTERING BY COMPRESSION", "text": "We assume that each string in L or L can be fully described in the respective regular languages in which each string belongs to the language, together with the multiplicities of repetitions. We now consider proper normal compression in L or L. We assume that we would reduce any string in L or L in the respective regular languages. (We assume that every string in L or L belongs in the respective regular languages.) We assume that we would reduce proper normal compression in L or L into the respective regular language. (We assume that every string in L or L belongs in the respective regular language.) We assume that we would reduce proper normal compression in L or L into the respective regular language. (We assume that every string in L or L belongs in the respective regular language.) We assume that we would reduce proper normal compression in L or L into the respective regular language."}, {"heading": "IV. TANDEM REPEATS", "text": "Another approach is to choose a simple language, then it is only a number that we assume can only be a number. (...) We have to ask ourselves whether we can understand such a language at all. (...) We have to understand it. (...) We have to understand it. (...) We have to understand it. (...) We have to understand it. (...) We have to understand it. (...) We have to understand it. (...) We have to understand it. (...) We have to understand it. (...) We have to understand it. (...) We have to understand it. (...) We have to understand it. (...) We have to understand it. (...) We have to understand it. (...) We have to understand it. (...) We have to understand it. (...) (...) We have to understand it. (...) (...) We have to understand it. (...)"}, {"heading": "VI. CONCLUSION AND FURTHER WORK", "text": "The results obtained in our industrial case study indicate that these methods are applicable in practice. Nevertheless, we recognize that the success of our methods is related to the simplicity of the languages we learn. Therefore, in future work, we aim to formally define a language class for which our methods work."}, {"heading": "ACKNOWLEDGMENTS", "text": "We thank Lou Somers and Patrick Vestjens1 for providing industrial datasets and for the expertise required for the case study. This research is supported by the Dutch Technology Foundation (STW) under the Robust CPS program (Project 12693) and the Netherlands Organization for Scientific Research (NWO) project on Learning Extended State Machine for Malware Analysis (LEMMA, Project 628.001.009)."}], "references": [{"title": "Language identification in the limit", "author": ["E.M. Gold"], "venue": "Information and Control, vol. 10, no. 5, pp. 447 \u2013 474, 1967. [Online]. Available: http://dx.doi.org/10.1016/S0019-9958(67)91165-5", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1967}, {"title": "Finite automata and their decision problems", "author": ["M.O. Rabin", "D. Scott"], "venue": "IBM journal of research and development, vol. 3, no. 2, pp. 114\u2013125, 1959.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1959}, {"title": "Linear time algorithms for finding and representing all the tandem repeats in a string", "author": ["D. Gusfield", "J. Stoye"], "venue": "Journal of Computer and System Sciences, vol. 69, no. 4, pp. 525\u2013546, 2004.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2004}, {"title": "Clustering by compression", "author": ["R. Cilibrasi", "P.M. Vit\u00e1nyi"], "venue": "IEEE Transactions on Information theory, vol. 51, no. 4, pp. 1523\u20131545, 2005.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "Grammatical inference: learning automata and grammars", "author": ["C. de la Higuera"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "An optimal algorithm for computing the repetitions in a word", "author": ["M. Crochemore"], "venue": "Information Processing Letters, vol. 12, no. 5, pp. 244\u2013250, 1981.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1981}, {"title": "Optimal off-line detection of repetitions in a string", "author": ["A. Apostolico", "F.P. Preparata"], "venue": "Theoretical Computer Science, vol. 22, no. 3, pp. 297\u2013315, 1983.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1983}, {"title": "An o (n log n) algorithm for finding all repetitions in a string", "author": ["M.G. Main", "R.J. Lorentz"], "venue": "Journal of Algorithms, vol. 5, no. 3, pp. 422\u2013432, 1984.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1984}, {"title": "A fast estimator of performance with respect to the design parameters of self re-entrant flowshops", "author": ["U. Waqas", "M. Geilen", "S. Stuijk", "J. v. Pinxten", "T. Basten", "L. Somers", "H. Corporaal"], "venue": "Euromicro Conference on Digital System Design, Aug 2016, pp. 215\u2013221. 1{lou.somers,patrick.vestjens}@oce.com", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Provided with sufficiently many examples, there exist algorithms that will correctly learn the unknown language from these examples [1].", "startOffset": 132, "endOffset": 135}, {"referenceID": 1, "context": "pumped) to produce a new example that is also in that language [2].", "startOffset": 63, "endOffset": 66}, {"referenceID": 2, "context": "Efficient algorithms can be used for finding such possible decompositions [3].", "startOffset": 74, "endOffset": 77}, {"referenceID": 1, "context": "c) The pumping lemma: The pumping lemma [2] states that all sufficiently long strings of a regular language contain an infix that may be pumped, i.", "startOffset": 40, "endOffset": 43}, {"referenceID": 3, "context": "The NCD for two strings x, y is defined in [5] as follows.", "startOffset": 43, "endOffset": 46}, {"referenceID": 4, "context": "the corresponding language Lx (for example, by using state merging [6]), using all strings clustered in Cx as positive examples, and all strings in \u22c3 y Cy : y 6= x as negative examples.", "startOffset": 67, "endOffset": 70}, {"referenceID": 2, "context": "There exist algorithms that can detect tandem repeats in a string [3], [7], [8], [9].", "startOffset": 66, "endOffset": 69}, {"referenceID": 5, "context": "There exist algorithms that can detect tandem repeats in a string [3], [7], [8], [9].", "startOffset": 71, "endOffset": 74}, {"referenceID": 6, "context": "There exist algorithms that can detect tandem repeats in a string [3], [7], [8], [9].", "startOffset": 76, "endOffset": 79}, {"referenceID": 7, "context": "There exist algorithms that can detect tandem repeats in a string [3], [7], [8], [9].", "startOffset": 81, "endOffset": 84}, {"referenceID": 8, "context": "Recent work [10] focused on the impact of design parameters of an industrial printer on its productivity.", "startOffset": 12, "endOffset": 16}], "year": 2017, "abstractText": "A classical problem in grammatical inference is to identify a deterministic finite automaton (DFA) from a set of positive and negative examples. In this paper, we address the related \u2013 yet seemingly novel \u2013 problem of identifying a set of DFAs from examples that belong to different unknown simple regular languages. We propose two methods based on compression for clustering the observed positive examples. We apply our methods to a set of print jobs submitted to large industrial printers.", "creator": "LaTeX with hyperref package"}}}