{"id": "1706.02179", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jun-2017", "title": "Learning to Represent Mechanics via Long-term Extrapolation and Interpolation", "abstract": "While the basic laws of Newtonian mechanics are well understood, explaining a physical scenario still requires manually modeling the problem with suitable equations and associated parameters. In order to adopt such models for artificial intelligence, researchers have handcrafted the relevant states, and then used neural networks to learn the state transitions using simulation runs as training data. Unfortunately, such approaches can be unsuitable for modeling complex real-world scenarios, where manually authoring relevant state spaces tend to be challenging. In this work, we investigate if neural networks can implicitly learn physical states of real-world mechanical processes only based on visual data, and thus enable long-term physical extrapolation. We develop a recurrent neural network architecture for this task and also characterize resultant uncertainties in the form of evolving variance estimates. We evaluate our setup to extrapolate motion of a rolling ball on bowl of varying shape and orientation using only images as input, and report competitive results with approaches that assume access to internal physics models and parameters.", "histories": [["v1", "Tue, 6 Jun 2017 15:45:48 GMT  (2326kb,D)", "https://arxiv.org/abs/1706.02179v1", "arXiv admin note: text overlap witharXiv:1703.00247"], ["v2", "Thu, 8 Jun 2017 09:31:22 GMT  (2322kb,D)", "http://arxiv.org/abs/1706.02179v2", "arXiv admin note: text overlap witharXiv:1703.00247"]], "COMMENTS": "arXiv admin note: text overlap witharXiv:1703.00247", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["s\\'ebastien ehrhardt", "aron monszpart", "rea vedaldi", "niloy mitra"], "accepted": false, "id": "1706.02179"}, "pdf": {"name": "1706.02179.pdf", "metadata": {"source": "META", "title": "Learning to Represent Mechanics via Long-term Extrapolation and Interpolation", "authors": ["S\u00e9bastien Ehrhardt", "Aron Monszpart", "Andrea Vedaldi", "Niloy Mitra"], "emails": ["vedaldi}@robots.ox.ac.uk", "n.mitra}@cs.ucl.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "This year, the time has come for us to be able to go in search of a solution that is capable, that we are able, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution."}, {"heading": "2 Related work", "text": "This year, we will be able to take the lead without having to try to find a solution."}, {"heading": "3 Method", "text": "In this section, we can propose a new neural network model (see Figure 1) that performs predictions in physical systems. Let's be a vector of physical measurements, like the position of an object whose motion we would like to track. Physical systems fulfill a Markov state in which there is a physical vector, so there is a physical vector that cannot be predicted by means of transition p (ht) and observation p (yht), as the state in the next step ht + 1 = f (ht) depends only on the current value of the state. Uncertainty in the model can be predicted by means of transition p (ht + 1) and observation p (yht), which leads to a hidden Markov model. Approaches such as NPE [5] begin with a handmade definition of the state ht. For example, to model a scenario with two colliding balls, one can choose the position and velcity of each case."}, {"heading": "4 Experimental setup", "text": "In our experimental setup (fig. 2), we look at a sphere rolling within a 3D (bowl) surface. If the bowl is a hemisphere, we refer to the setup as a \"bowl\" and, more generally, as an \"ellipse\" (see Table 1).We use p = (px, py, pz) to mark a point in 3D space or a vector (direction).The camera center is placed in a place (0, 0, cz), and looks along a vector (0, \u2212 1) with orthographic projections so that the point (px, pz) is projected onto a point (px, py).We model the bowl as the bottom half of an ellipsoid given by x2 / a2 + y2 + (z \u2212 1)."}, {"heading": "5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Baselines", "text": "In both cases, we adapt two first and second degree polynomials to the screen space coordinates of the first T = 10 frames, which are not calculated but are given as inputs. Note that the ability to observe the first 10 frames is a great advantage over networks that only see the first T0 = 4 frames. NPE. NPE [5] was trained with available online code. We used the same training method as in [5]. NPE + + additionally takes angular and angular velocities as parameters and also predicts angular velocity. In the case of the elliptical shell, both the scaling and the rotation angle of the shell are given as input to the networks. In this case, NPE's methods will estimate the states over the network.While the aforementioned methods derive the physical world properties from our raw models, we then interpret the physical observation of the underlying worlds."}, {"heading": "5.2 Results", "text": "It is only a matter of time before we do this in an (8, 8, 512) analog model of all layers up to an (8, 8, 512) analog loss of two layers (with 256 and 512 layers), size 3, step 1, and extent 1, which is eavesdropped by a ReLU layer. The transition network (st) uses a simple chain of two layers of convolution (with 256 and 512 layers of size 3), the network is initialized by being eavesdropped by a ReLU layer. It is initialized by sampling from a Gaussian distribution.Training uses a batch size of 50 positions (and 40 positions)."}, {"heading": "6 Conclusions", "text": "In this work, we explored the possibility of abstracting the knowledge of physics by means of a single neural network with a recurring architecture for long-term predictions. Unlike other simultaneous approaches, we do not integrate physical quantities, but encode the states implicitly in a characteristic vector that we can spread over time. Our experiments with synthetic simulations show that we can still make reasonable predictions without requiring an explicit encoding of the state space. Moreover, they are also able to estimate a distribution over such parameters in order to take into account uncertainties in predictions. By maintaining the same architecture, we also show that we were able to eliminate motion ambiguities by showing the network its desired end states. However, the internal state propagation mechanism is still limited by its ability to make accurate long-term predictions outside of the observed regimes. In the future, we will endeavor to make our models more robust to allow us to observe the next steps by placing them in the regiments we are observing."}], "references": [{"title": "TensorFlow: Large-scale machine learning on heterogeneous systems", "author": ["Abadi"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Learning to Poke by Poking: Experiential Learning of Intuitive Physics", "author": ["Pulkit Agrawal", "Ashvin V Nair", "Pieter Abbeel", "Jitendra Malik", "Sergey Levine"], "venue": "In Proc. NIPS,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Interaction networks for learning about objects, relations and physics", "author": ["Peter Battaglia", "Razvan Pascanu", "Matthew Lai", "Danilo Jimenez Rezende"], "venue": "In Proc. NIPS,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Simulation as an engine of physical scene understanding", "author": ["Peter W Battaglia", "Jessica B Hamrick", "Joshua B Tenenbaum"], "venue": "PNAS, 110(45):18327\u201318332,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "A compositional object-based approach to learning physical dynamics", "author": ["Michael B Chang", "Tomer Ullman", "Antonio Torralba", "Joshua B Tenenbaum"], "venue": "arXiv preprint arXiv:1612.00341,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Dynamic filter networks", "author": ["Bert De Brabandere", "Xu Jia", "Tinne Tuytelaars", "Luc Van Gool"], "venue": "In Proc. NIPS,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Learning to perform physics experiments via deep reinforcement learning", "author": ["Misha Denil", "Pulkit Agrawal", "Tejas D Kulkarni", "Tom Erez", "Peter Battaglia", "Nando de Freitas"], "venue": "Deep Reinforcement Learning Workshop,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Learning visual predictive models of physics for playing billiards", "author": ["Katerina Fragkiadaki", "Pulkit Agrawal", "Sergey Levine", "Jitendra Malik"], "venue": "arXiv preprint arXiv:1511.07404,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Inferring mass in complex scenes by mental", "author": ["J.B. Hamrick", "P.W. Battaglia", "T.L. Griffiths", "J.B. Tenenbaum"], "venue": "simulation. Cognition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Deep residual learning for image recognition", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": "In IEEE CVPR,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural Comput.,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1997}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": "In Proc. NIPS,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Datadriven fluid simulations using regression forests", "author": ["Ladick\u00fd", "Jeong", "SoHyeon", "Barbara Solenthaler", "Marc Pollefeys", "Markus Gross"], "venue": "ACM Trans. on Graphics (TOG),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Learning physical intuition of block towers by example", "author": ["Adam Lerer", "Sam Gross", "Rob Fergus"], "venue": "arXiv preprint arXiv:1603.01312,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Visual stability prediction and its application to manipulation", "author": ["Wenbin Li", "Ale\u0161 Leonardis", "Mario Fritz"], "venue": "arXiv preprint arXiv:1609.04861,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "SMASH: Physics-guided Reconstruction of Collisions from Videos", "author": ["Aron Monszpart", "Nils Thuerey", "Niloy Mitra"], "venue": "ACM Trans. on Graphics (TOG),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Newtonian scene understanding: Unfolding the dynamics of objects in static images", "author": ["Roozbeh Mottaghi", "Hessam Bagherinezhad", "Mohammad Rastegari", "Ali Farhadi"], "venue": "In IEEE CVPR,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "Predicting deeper into the future of semantic segmentation", "author": ["Natalia Neverova", "Pauline Luc", "Camille Couprie", "Jakob Verbeek", "Yann LeCun"], "venue": "arXiv preprint arXiv:1703.07684,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2017}, {"title": "Deep tracking: Seeing beyond seeing using recurrent neural networks", "author": ["Peter Ondruska", "Ingmar Posner"], "venue": "In Proc. AAAI,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "The predictron: End-to-end learning and planning", "author": ["David Silver", "Hado van Hasselt", "Matteo Hessel", "Tom Schaul", "Arthur Guez", "Tim Harley", "Gabriel Dulac-Arnold", "David Reichert", "Neil Rabinowitz", "Andr\u00e9 Barreto", "Thomas Degris"], "venue": "CoRR, abs/1612.08810,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Label-free supervision of neural networks with physics and domain knowledge", "author": ["Russell Stewart", "Stefano Ermon"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "Lecture 6.5\u2014RMSProp: Divide the gradient by a running average of its recent magnitude", "author": ["T. Tieleman", "G. Hinton"], "venue": "COURSERA: Neural Networks for Machine Learning,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Accelerating Eulerian Fluid Simulation With Convolutional Networks", "author": ["J. Tompson", "K. Schlachter", "P. Sprechmann", "K. Perlin"], "venue": "ArXiv e-print", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "Physics 101: Learning physical object properties from unlabeled videos", "author": ["Jiajun Wu", "Joseph J Lim", "Hongyi Zhang", "Joshua B Tenenbaum", "William T Freeman"], "venue": "In Proc. BMVC,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "Galileo: Perceiving physical object properties by integrating a physics engine with deep learning", "author": ["Jiajun Wu", "Ilker Yildirim", "Joseph J Lim", "Bill Freeman", "Josh Tenenbaum"], "venue": "In Proc. NIPS,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks", "author": ["Tianfan Xue", "Jiajun Wu", "Katherine L Bouman", "William T Freeman"], "venue": "In Proc. NIPS,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}], "referenceMentions": [{"referenceID": 8, "context": "However, the nature of the mental models used to perform such predictions remains unclear and is still actively researched [9].", "startOffset": 123, "endOffset": 126}, {"referenceID": 4, "context": "As a notable example, the recent Neural Physics Engine (NPE) [5] uses a neural network to learn the state transition function of mechanical systems.", "startOffset": 61, "endOffset": 64}, {"referenceID": 3, "context": "To the best of our knowledge [4] was the first approach to tackle intuitive physics with the aim to answer a set of intuitive questions (e.", "startOffset": 29, "endOffset": 32}, {"referenceID": 16, "context": "More recently [17] also used static images and a graphics rendering engine (Blender) to predict movements and directions of forces from a single RGB image.", "startOffset": 14, "endOffset": 18}, {"referenceID": 11, "context": ", [12, 10]), they used a convolutional architecture to understand dynamics and forces acting behind the scenes from a static image and produced a \u201cmost likely motion\" rendered from a graphics engine.", "startOffset": 2, "endOffset": 10}, {"referenceID": 9, "context": ", [12, 10]), they used a convolutional architecture to understand dynamics and forces acting behind the scenes from a static image and produced a \u201cmost likely motion\" rendered from a graphics engine.", "startOffset": 2, "endOffset": 10}, {"referenceID": 13, "context": "In a different framework, [14] and [15] also used the power of deep learning to extract an abstract representation of the concept of stability of block towers purely from images.", "startOffset": 26, "endOffset": 30}, {"referenceID": 14, "context": "In a different framework, [14] and [15] also used the power of deep learning to extract an abstract representation of the concept of stability of block towers purely from images.", "startOffset": 35, "endOffset": 39}, {"referenceID": 1, "context": "Other approaches such as [2] or [7] also attempted to learn intuitive physics of objects through manipulation.", "startOffset": 25, "endOffset": 28}, {"referenceID": 6, "context": "Other approaches such as [2] or [7] also attempted to learn intuitive physics of objects through manipulation.", "startOffset": 32, "endOffset": 35}, {"referenceID": 10, "context": "While most successful techniques used LSTM-s [11], recent approaches show that propagation can also be done using a single crossconvolution kernel.", "startOffset": 45, "endOffset": 49}, {"referenceID": 26, "context": "The idea was further developed in [27] in order to generate a next possible image frame from a single static input image.", "startOffset": 34, "endOffset": 38}, {"referenceID": 5, "context": "The concept has been shown to have promising performance regarding longer term predictions on the moving MNIST dataset in [6].", "startOffset": 122, "endOffset": 125}, {"referenceID": 18, "context": "The work of [19] also shows that an internal hidden state can be propagated through time using a simple deep recurrent architecture.", "startOffset": 12, "endOffset": 16}, {"referenceID": 17, "context": "Adversarial losses have also been used in [18] which shows good results in video segmentation.", "startOffset": 42, "endOffset": 46}, {"referenceID": 26, "context": "In the future we also aim to experiment with approaches inspired by [27].", "startOffset": 68, "endOffset": 72}, {"referenceID": 25, "context": "The works of [26] and its extension [25] propose methods to learn physical properties of scenes and objects.", "startOffset": 13, "endOffset": 17}, {"referenceID": 24, "context": "The works of [26] and its extension [25] propose methods to learn physical properties of scenes and objects.", "startOffset": 36, "endOffset": 40}, {"referenceID": 25, "context": "However, in [26] the MCMC sampling based approach assumes the complete knowledge of the physical equations to estimate the correct physical parameters.", "startOffset": 12, "endOffset": 16}, {"referenceID": 24, "context": "In [25] deep learning has been used more extensively to replace the MCMC based sampling but this work also employs an explicit encoding and computation of physical laws to regress the output of their tracker.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "[22] also used physical laws to predict the movement of a pillow from unlabelled data though their approach was only applied to a fixed number of frames.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "In another related approach [8] attempted to build an internal representation of the physical world.", "startOffset": 28, "endOffset": 31}, {"referenceID": 2, "context": "[3] and [5] were able to produce accurate estimations of the next state of the world.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[3] and [5] were able to produce accurate estimations of the next state of the world.", "startOffset": 8, "endOffset": 11}, {"referenceID": 4, "context": "Although the results look plausible and promising, reported results show in [5] that accurate long-term predictions are still difficult.", "startOffset": 76, "endOffset": 79}, {"referenceID": 19, "context": "Note, that their process is an iterative one as opposed to ours, which propagates an internal state of the world through time similarly to [20].", "startOffset": 139, "endOffset": 143}, {"referenceID": 23, "context": "Other approaches also focused on learning to generate realistic future scenarios ([24] and [13]), or inferring collision parameters from monocular videos [16].", "startOffset": 82, "endOffset": 86}, {"referenceID": 12, "context": "Other approaches also focused on learning to generate realistic future scenarios ([24] and [13]), or inferring collision parameters from monocular videos [16].", "startOffset": 91, "endOffset": 95}, {"referenceID": 15, "context": "Other approaches also focused on learning to generate realistic future scenarios ([24] and [13]), or inferring collision parameters from monocular videos [16].", "startOffset": 154, "endOffset": 158}, {"referenceID": 2, "context": "Note also that in [3] an energy-based loss has been used.", "startOffset": 18, "endOffset": 21}, {"referenceID": 4, "context": "Approaches such as NPE [5] start from an handcrafted definition of the state ht.", "startOffset": 23, "endOffset": 26}, {"referenceID": 4, "context": "In practice, the authors of [5] suggest that it is often easier to predict a rate of change \u2206t for some of the physical parameters (e.", "startOffset": 28, "endOffset": 31}, {"referenceID": 4, "context": "While these approaches have several advantages [5], there are several limitations too.", "startOffset": 47, "endOffset": 50}, {"referenceID": 7, "context": "Finally, the initial value of the state h0 must be known in order to initialize the predictor, whereas in many applications one would like to start from sensory inputs xt such as images of the physical system [8].", "startOffset": 209, "endOffset": 212}, {"referenceID": 7, "context": "In order to build this encoder, we follow [8] and concatenate the RGB channels of the T0 images in a single Hi\u00d7Wi\u00d7 3T0.", "startOffset": 42, "endOffset": 45}, {"referenceID": 4, "context": "We set its initial velocity v by first sampling vx, vy uniformly in the range [5, 10], assigning each of vx, vy a random sign, and then projecting vector (vx, vy, 0) so that the resulting velocity vector is tangential to the underlying supporting bowl.", "startOffset": 78, "endOffset": 85}, {"referenceID": 9, "context": "We set its initial velocity v by first sampling vx, vy uniformly in the range [5, 10], assigning each of vx, vy a random sign, and then projecting vector (vx, vy, 0) so that the resulting velocity vector is tangential to the underlying supporting bowl.", "startOffset": 78, "endOffset": 85}, {"referenceID": 4, "context": "NPE [5] training was done using available online code.", "startOffset": 4, "endOffset": 7}, {"referenceID": 4, "context": "We used the same training procedure as reported in [5].", "startOffset": 51, "endOffset": 54}, {"referenceID": 20, "context": "The encoder network \u03c6enc is obtained by taking the ImageNet-pretrained VGG16 network [21] and retaining the layers up to conv5 (for an input image of size (Hi,Wi) = (128, 128, 3) this results in a (8, 8, 512) state tensor st).", "startOffset": 85, "endOffset": 89}, {"referenceID": 22, "context": "Training uses a batch size of 50 using the first 20 or 40 positions (and angular velocity when explicitly mentioned) of each video sequence using RMSProp [23].", "startOffset": 154, "endOffset": 158}, {"referenceID": 0, "context": "In all our experiments we used Tensorflow [1] r0.", "startOffset": 42, "endOffset": 45}], "year": 2017, "abstractText": "While the basic laws of Newtonian mechanics are well understood, explaining a physical scenario still requires manually modeling the problem with suitable equations and associated parameters. In order to adopt such models for artificial intelligence, researchers have handcrafted the relevant states, and then used neural networks to learn the state transitions using simulation runs as training data. Unfortunately, such approaches can be unsuitable for modeling complex real-world scenarios, where manually authoring relevant state spaces tend to be challenging. In this work, we investigate if neural networks can implicitly learn physical states of real-world mechanical processes only based on visual data, and thus enable longterm physical extrapolation. We develop a recurrent neural network architecture for this task and also characterize resultant uncertainties in the form of evolving variance estimates. We evaluate our setup to extrapolate motion of a rolling ball on bowl of varying shape and orientation using only images as input, and report competitive results with approaches that assume access to internal physics models and parameters.", "creator": "LaTeX with hyperref package"}}}