{"id": "1706.02209", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2017", "title": "Improving Max-Sum through Decimation to Solve Loopy Distributed Constraint Optimization Problems", "abstract": "In the context of solving large distributed constraint optimization problems (DCOP), belief-propagation and approximate inference algorithms are candidates of choice. However, in general, when the factor graph is very loopy (i.e. cyclic), these solution methods suffer from bad performance, due to non-convergence and many exchanged messages. As to improve performances of the Max-Sum inference algorithm when solving loopy constraint optimization problems, we propose here to take inspiration from the belief-propagation-guided dec-imation used to solve sparse random graphs (k-satisfiability). We propose the novel DeciMaxSum method, which is parameterized in terms of policies to decide when to trigger decimation, which variables to decimate, and which values to assign to decimated variables. Based on an empirical evaluation on a classical BP benchmark (the Ising model), some of these combinations of policies exhibit better performance than state-of-the-art competitors.", "histories": [["v1", "Wed, 7 Jun 2017 14:29:23 GMT  (532kb,D)", "http://arxiv.org/abs/1706.02209v1", null]], "reviews": [], "SUBJECTS": "cs.MA cs.AI", "authors": ["jes\\'us cerquides", "r\\'emi emonet", "gauthier picard", "juan a rodr\\'iguez-aguilar"], "accepted": false, "id": "1706.02209"}, "pdf": {"name": "1706.02209.pdf", "metadata": {"source": "CRF", "title": "Improving Max-Sum through Decimation to Solve Loopy Distributed Constraint Optimization Problems", "authors": ["J. Cerquides", "R. Emonet", "J.A. Rodriquez-Aguilar"], "emails": ["cerquide@iiia.csic.es", "jar@iiia.csic.es", "remi.emonet@univ-st-etienne.fr", "picard@emse.fr"], "sections": [{"heading": "1 Introduction", "text": "This year, it is more than ever in the history of the city, where it is so far that it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place."}, {"heading": "2 Background", "text": "This section explains the DCOP framework and some related belief propagation algorithms from the literature are discussed in terms of mechanisms for handling cycles in constraint diagrams."}, {"heading": "2.1 Disributed Constraint Optimization Problems", "text": "One way to model the problem of coordination between intelligent objects is to formalize the problem as a distributed problem."}, {"heading": "2.2 From Belief-Propagation to Max-Sum", "text": "It is a potentially distributed algorithm for performing inferences to graphical models and can work on factor diagrams that represent a product of M factors [7]: F (x) = Max AD m = 1 fm (Xm). However, the sum product algorithm provides efficient local message delivery to calculate the boundary functions of all variables simultaneously. the boundary function, zn (xn) describes the total dependence of the global function F (x) on variable xn: zn (xn) = {x \u2032}, n \u2032 6 = n F (Xn \u2032).BP works iteratively propagating messages mi \u2192 j (tables associating margins to each value of variables) along the edges of the factor graph. If the factor graph is a tree, BP algorithm calculates the exact margins and convergences in a certain number of steps depending on the diameter of the graph."}, {"heading": "2.3 BP-guided Decimation", "text": "In this paper, we propose to take inspiration from work in computer physics [13] to cope with cyclicality in the DCOP. It is noteworthy that [5] the concept of decimation was introduced in satisfaction with limitations, especially in k satisfaction, where variables are binary, xi, xi, {0, 1}, and any constraint requires k to deviate from a specific satisfaction of the variable.The authors proposed a class of algorithms, namely a message-conditioned decimation procedure consisting of the iteration of the following steps: (1) Run a message delivery algorithm, such as BP; (2) use the result to select a variable index i and a value x, which is i for the corresponding variable; (3) replace the satisfaction problem with that achieved by fixing x factors."}, {"heading": "2.4 State of a Factor Graph Representation", "text": "The previous BP-based algorithm works on factor graphs that represent the problem. \"Operates\" means that the algorithms create a data structure that represents the factor graph that evolves over time: thresholds change, variables disappear, messages are sent / received, etc. Usually, the logical representation of a factor graph is a composition of nodes connected to each other depending on the connectivity of the graph. Each such node has a state in which some useful values are stored.Definition 3. The current state FGt at the time t of a factor graph FG = < X, C, E > is the composition of all the current states of the data structures used by the BP-based algorithm to operate on the associated factor graph, including the limits zi, messages mi \u2192 j, the set of decimated variable U, and other algorithm-specific data. We can take into account that many factor states can exist for a given problem."}, {"heading": "3.1 Principles", "text": "The main idea is to expand the decimation algorithms of [11] to define a basic decimation policy in which other, already existing algorithms can be summarized. (i) The question of the way in which the decimation and the distribution mechanisms of the different types of distribution mechanisms can be summarized in a certain way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way. (i)"}, {"heading": "3.3 Triggering Decimation (\u0398 criterion)", "text": "In fact, it is so that it is a way in which people are able to survive themselves. (...) In fact, it is so that they are able to survive themselves. (...) In fact, it is so that they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) () () () () () () () (() () () () () () () () () () () () () () () () () () () () () () () () () () () () () (()) () () () () () () () () () () () () () () () () () ()) () () () () () () () () () () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () (() () () () () () (() () () () () (() () () () (() () () ((() (() (() (() () () (() ((() (() () ((() (() () (() ((() (() (() () () ((() () ((() ((() (() (() ((()) ((((()) ((((())) ((((()) (((("}, {"heading": "3.4 Deciding the Subset of Variables to Decimate (\u03a6 and \u03a5 criteria)", "text": "In such a case, the selection of variables in the infinite loop, in which the whole spectrum of variables can be discussed, is only possible if it selects the only variable for decimation in the totality of the undecimated variables (cf. line 5 in algorithm 1). (cf. line 5 in algorithm 1) Here, the criterion of the variables is specified as follows: \"All\" def = X\\ U (6) However, this selection can be discussed in the totality of variables when local decimation, such as the decimation of variables in the infinite loop, is applied."}, {"heading": "3.5 Deciding the Values to Assign To Decimated Variables (\u039b criterion)", "text": "Now that variables have been selected to be decimated, the question is, \"What values should be assigned?\" Normally, in BP-based algorithms, the easiest way to assign values to variables after propagation is to assign values with maximum limit (or benefit). [12] Such a criterion is used for inferences: max _ marginal (xi, s) def = argmaxd Di zi (xi) (d) (13) While politics is deterministic, in [11] the choice of the value is a random choice in which the limits are used as a probability distribution: sample _ marginal (xi, s) def = sample (zi (xi)) (14) Once again, these are just a few examples of policies that exploit BP, and many more can easily be given."}, {"heading": "4 Experiments", "text": "In this section we evaluate the performance of different combinations of decimation policies in DeciMaxSum using a classical optimization model (Ising model) versus the classical Max-Sum [3] and its extension Max-Sum _ AD _ VP [20], which we have implemented in our own framework."}, {"heading": "4.1 Ising Model", "text": "Since we are interested in evaluating our algorithms for strong dependencies between the values of the variables, we evaluate them using the Ising model, which is a widely used benchmark in statistical physics. [4] We use the same settings here as [18]. Constraint diagrams are rectangular grids in which each binary variable xi is connected to its four nearest neighbors (with ring-shaped links connecting opposite sides of the grid) and is limited by a uniform costri. The weight of each binary constraint is determined by first sampling a value \u0445ij from a uniform distribution U [\u2212 \u03b2, \u03b2] and then Rij (xi, xj) = {\u0432ij if xi = xj \u2212 \u0445ij otherwiseThe \u03b2 parameter controls the average strength of the interactions. In our experiments, we set \u03b2 to 1.6. The weight for each non-constraint ri is determined by sampling a uniform distribution U \u2212 05, then by 0.05, then by 0.05, and then by 0.05."}, {"heading": "4.2 Results and Analysis", "text": "In this section, we analyze the results of different DeciMaxSum combinations for solving square problems with page sizes from 10 to 20 (e.g. 100 to 400 variables). We have implemented the following combinations: - 11 DeciMaxSum instances with different decimation policies based on the following criteria: \u2022 trigger policies (criterion for maximum size): \u2022 convergence (of equation 2, convergent size); \u2022 filter policies (of equation 4, connoted 2-periodic, 3-periodic, 5-periodic, 10-periodic, 20-periodic, and 100-periodic size); \u2022 budget-based frequency (of equation 4, connoted periodicity); \u2022 filter policies (of equation 4, connoted frequency): Those who select the entire set of variables as potential variables that can be decimated (i.e., all of equation 6, conversed periodicity); \u2022 5 (conversion of 20, condensed frequency): (conversion of 20, total number of 20, condensed number of 20, condensed number of 20, condensed frequency of 5, measures: \u2022 (condensed)."}, {"heading": "5 Conclusions", "text": "In this paper, we have explored how to expand the Max Sum method for solving distributed constraint problems in the optimization of power grids by drawing inspiration from the decimation mechanisms used to solve k satisfaction problems through faith propagation. We propose a parametric method, namely DeciMaxSum, which can be set up with different decimation policies that specify when decimation should be triggered, which variables must be decimated, and which value should be assigned to decimated variables. In this paper, we propose a library of such policies that can be combined to produce different versions of DeciMaxSum. Our empirical results on various benchmarks show that some combinations of decimation policies outperform the classic Max Sum and its extension Max-Sum _ AD _ VP, especially the design to handle loops. DeciMaxSum provides better quality solutions in a number of message decentralizations."}], "references": [{"title": "A tutorial on optimization formulti-agent systems", "author": ["J. Cerquides", "A. Farinelli", "P. Meseguer", "S.D. Ramchurn"], "venue": "The Computer Journal 57(6),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Designing a marketplace for the trading and distribution of energy in the smart grid", "author": ["J. Cerquides", "G. Picard", "J. Rodr\u00edguez-Aguilar"], "venue": "International Conference on Autonomous Agents and Multiagent Systems (AAMAS). pp. 1285\u20131293. International Foundation for Autonomous Agents and Multiagent Systems", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Decentralised coordination of low-power embedded devices using the max-sum algorithm", "author": ["A. Farinelli", "A. Rogers", "A. Petcu", "N.R. Jennings"], "venue": "In: International Conference on Autonomous Agents and Multiagent Systems", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Convergent tree-reweighted message passing for energy minimization", "author": ["V. Kolmogorov"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 28(10), 1568\u20131583", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Gibbs states and the set of solutions of random constraint satisfaction problems", "author": ["F. Krzakala", "A. Montanari", "F. Ricci-Tersenghi", "G. Semerjian", "L. Zdeborova"], "venue": "Proceedings of the National Academy of Science 104, 10318\u201310323", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Disributed Algorithms", "author": ["N. Lynch"], "venue": "Morgan Kaufmann", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1996}, {"title": "Information Theory, Inference and Learning Algorithms", "author": ["D.J.C. Mackay"], "venue": "Cambridge University Press, first edition edn.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "Distributed algorithms for dcop: A graphical-game-based approach", "author": ["R. Maheswaran", "J. Pearce", "M. Tambe"], "venue": "Proceedings of the 17th International Conference on Parallel and Distributed Computing Systems (PDCS), San Francisco, CA. pp. 432\u2013 439", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "ADOPT: Asynchronous Distributed Constraint Optimization with Quality Guarantees", "author": ["P.J. Modi", "W. Shen", "M. Tambe", "M. Yokoo"], "venue": "Artificial Intelligence 161(2), 149\u2013180", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "ADOPT: Asynchronous distributed constraint optimization with quality guarantees", "author": ["P. Modi", "W. Shen", "M. Tambe", "M. Yokoo"], "venue": "Artificial Intelligence Journal", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Solving constraint satisfaction problems through belief propagationguided decimation", "author": ["A. Montanari", "F. Ricci-Tersenghi", "G. Semerjian"], "venue": "CoRR abs/0709.1667", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "libDAI: A free and open source C++ library for discrete approximate inference in graphical models", "author": ["J.M. Mooij"], "venue": "Journal of Machine Learning Research", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Information, Physics, and Computation", "author": ["M. M\u00e9zard", "A. Montanari"], "venue": "Oxford University Press", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Decreasing-rate pruning optimizes the construction of efficient and robust distributed networks", "author": ["S. Navlakha", "A.L. Barth", "Z. Bar-Joseph"], "venue": "PLOSComputational Biology 11(7),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "A scalable method for multiagent constraint optimization", "author": ["A. Petcu", "B. Faltings"], "venue": "International Joint Conference on Artificial Intelligence (IJCAI\u201905). pp. 266\u2013271", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2005}, {"title": "Bounded approximate decentralised coordination via the max-sum algorithm", "author": ["A. Rogers", "A. Farinelli", "R. Stranders", "N. Jennings"], "venue": "Artificial Intelligence 175(2),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Using message-passing DCOP algorithms to solve energy-efficient smart environment configuration problems", "author": ["P. Rust", "G. Picard", "F. Ramparany"], "venue": "International Joint Conference on Artificial Intelligence (IJCAI). AAAI Press", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Divide and coordinate: solving dcops by agreement", "author": ["M. Vinyals", "M. Pujol", "J. Rodr\u00edguez-Aguilar", "J. Cerquides"], "venue": "International Joint Conference on Autonomous Agents and Multi-Agent Systems (AAMAS\u201910). pp. 149\u2013156. IFAAMAS, Canada", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Constructing a unifying theory of dynamic programming dcop algorithms via the generalized distributive law. Autonomous Agents and Multi-Agent Systems", "author": ["M. Vinyals", "J. Rodriguez-Aguilar", "J. Cerquides"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Max/min-sum distributed constraint optimization through value propagation on an alternating DAG", "author": ["R. Zivan", "H. Peled"], "venue": "International Conference on Autonomous Agents and Multiagent Systems,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}], "referenceMentions": [{"referenceID": 9, "context": "Indeed, complete methods, like ADOPT or DPOP, suffer exponential computation and/or communication cost in general settings [10,15].", "startOffset": 123, "endOffset": 130}, {"referenceID": 14, "context": "Indeed, complete methods, like ADOPT or DPOP, suffer exponential computation and/or communication cost in general settings [10,15].", "startOffset": 123, "endOffset": 130}, {"referenceID": 0, "context": "As a consequence, in some large settings, approximate methods are better candidates, as evidenced by the extensive literature on the subject (see [1] for a complete review).", "startOffset": 146, "endOffset": 149}, {"referenceID": 2, "context": "Among the aforementioned methods, inference-based ones, like Max-Sum [3] and its extensions like [16], have demonstrated good performance even on loopy settings.", "startOffset": 69, "endOffset": 72}, {"referenceID": 15, "context": "Among the aforementioned methods, inference-based ones, like Max-Sum [3] and its extensions like [16], have demonstrated good performance even on loopy settings.", "startOffset": 97, "endOffset": 101}, {"referenceID": 12, "context": "Decimation is a method inspired by statistical physics, and applied in belief-propagation, which consists in fixing the value of a variable, using the marginal values as the decision criteria to select the variable to decimate [13].", "startOffset": 227, "endOffset": 231}, {"referenceID": 10, "context": "In [11], decimation has been used in the constraint satisfaction framework, for solving centralized k-satisfiability problems [11].", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "In [11], decimation has been used in the constraint satisfaction framework, for solving centralized k-satisfiability problems [11].", "startOffset": 126, "endOffset": 130}, {"referenceID": 19, "context": "Other works proposed Max-Sum_AD_VP as to improve Max-Sum performance on loopy graphs [20].", "startOffset": 85, "endOffset": 89}, {"referenceID": 0, "context": "As highlighted in [1], DCOPs have been widely studied and applied in many reference domains, and have many interesting features: (i) strong focus on decentralized approaches where agents negotiate a joint solution through local message exchange; (ii) solution techniques exploit the structure of the domain (by encoding this into constraints) to tackle hard computational problems; (iii) there is a wide choice of solutions for DCOPs ranging from complete algorithms to suboptimal algorithms.", "startOffset": 18, "endOffset": 21}, {"referenceID": 8, "context": "On the one hand, complete algorithms like ADOPT and its extensions [9], or inference algorithms like DPOP [15] or ActionGDL [19], are optimal, but mainly suffer from expensive memory (e.", "startOffset": 67, "endOffset": 70}, {"referenceID": 14, "context": "On the one hand, complete algorithms like ADOPT and its extensions [9], or inference algorithms like DPOP [15] or ActionGDL [19], are optimal, but mainly suffer from expensive memory (e.", "startOffset": 106, "endOffset": 110}, {"referenceID": 18, "context": "On the one hand, complete algorithms like ADOPT and its extensions [9], or inference algorithms like DPOP [15] or ActionGDL [19], are optimal, but mainly suffer from expensive memory (e.", "startOffset": 124, "endOffset": 128}, {"referenceID": 2, "context": "On the other hand, approximate algorithms like Max-Sum [3] or MGM [8] have the great advantage of being fast with a limited memory print and communication load, but losing optimality in some settings \u2013e.", "startOffset": 55, "endOffset": 58}, {"referenceID": 7, "context": "On the other hand, approximate algorithms like Max-Sum [3] or MGM [8] have the great advantage of being fast with a limited memory print and communication load, but losing optimality in some settings \u2013e.", "startOffset": 66, "endOffset": 69}, {"referenceID": 6, "context": "sum-product message passing method, is a potentially distributed algorithm for performing inference on graphical models, and can operate on factor graphs representing a product of M factors [7]: F (x) = \u220fM m=1 fm(Xm) .", "startOffset": 190, "endOffset": 193}, {"referenceID": 6, "context": "When the factor graph is a tree, BP algorithm computes the exact marginals and converge in a finite number a steps depending on the diameter of the graph [7].", "startOffset": 154, "endOffset": 157}, {"referenceID": 2, "context": "Built as a derivative of max-product, Max-Sum is an approximate algorithm to solve DCOP [3].", "startOffset": 88, "endOffset": 91}, {"referenceID": 10, "context": "Algorithm 1: The BP-guided decimation algorithm from [11]", "startOffset": 53, "endOffset": 57}, {"referenceID": 2, "context": "In fact, on cyclic settings [3] identify the following behaviors: (i) agents converge to fixed states that represent either the optimal solution, or a solution close to the optimal, and the propagation of messages ceases; (ii) agents converge as above, but the messages continue to change slightly at each update, and thus continue to be propagated around the network; (iii) neither the agents\u2019 preferred states, nor the messages converge and both display cyclic behavior.", "startOffset": 28, "endOffset": 31}, {"referenceID": 19, "context": "As to improve Max-Sum performance on cyclic graphs, [20] proposed two extensions to Max-Sum: (i) Max-Sum_AD which operates Max-Sum on a directed acyclic graph built from the factor graph, and alternates direction at a fixed rate (a parameter of the algorithm); (ii) MaxSum_AD_VP which operates Max-Sum_AD and propagates current values of variables when sending Max-Sum messages so that factors receiving the value only consider this value instead of the whole domain of the variable.", "startOffset": 52, "endOffset": 56}, {"referenceID": 12, "context": "In this paper, we propose to take inspiration from work done in computational physics [13], as to cope with cyclicity in DCOP.", "startOffset": 86, "endOffset": 90}, {"referenceID": 4, "context": "Notably, [5] introduced the notion of decimation in constraint satisfaction, especially k-satisfiability, where variables are binary, xi \u2208 {0, 1}, and each constraint requires k of the variables to be different from a specific k-uple.", "startOffset": 9, "endOffset": 12}, {"referenceID": 10, "context": "The BP-guided decimation procedure is shown in Algorithm 1, whose performances are analysed in [11,13].", "startOffset": 95, "endOffset": 102}, {"referenceID": 12, "context": "The BP-guided decimation procedure is shown in Algorithm 1, whose performances are analysed in [11,13].", "startOffset": 95, "endOffset": 102}, {"referenceID": 10, "context": "Second, while in the seminal work of [11], this procedure is used to solve satisfiability problems, the approach can easily be implemented to cope with optimization problems.", "startOffset": 37, "endOffset": 41}, {"referenceID": 11, "context": "For instance, the inference library libDAI proposes an implementation of decimation for discrete approximate inference in graphical models [12], which was amongst the three winners of the UAI 2010 Approximate Inference Challenge5.", "startOffset": 139, "endOffset": 143}, {"referenceID": 10, "context": "The main idea is to extend the BP-guided decimation algorithm from [11] in order to define a more general framework, in which other BP-based existing algorithms could fit.", "startOffset": 67, "endOffset": 71}, {"referenceID": 10, "context": "By doing so, we result in the classical BP-guided decimation algorithm from [11] .", "startOffset": 76, "endOffset": 80}, {"referenceID": 10, "context": "In the original approach proposed by [11], decimation is triggered once BP has converged.", "startOffset": 37, "endOffset": 41}, {"referenceID": 5, "context": "This means no process is enabled to perform any locally controlled action and there are no messages in the channels [6].", "startOffset": 116, "endOffset": 119}, {"referenceID": 5, "context": "Algorithms like DijkstraScholten can detects such global state by implementing a send/receive network algorithm, based on the same graph than FG [6].", "startOffset": 145, "endOffset": 148}, {"referenceID": 19, "context": "Due to the Max-Sum behavior on loopy factor graphs, convergence may not be reached [20].", "startOffset": 83, "endOffset": 87}, {"referenceID": 2, "context": "sensor networks [3], internet-of-things [17]), waiting convergence is not affordable.", "startOffset": 16, "endOffset": 19}, {"referenceID": 16, "context": "sensor networks [3], internet-of-things [17]), waiting convergence is not affordable.", "startOffset": 40, "endOffset": 44}, {"referenceID": 13, "context": "faster at the beginning, and lower at the end, as observed in neural circuits in the brain [14]).", "startOffset": 91, "endOffset": 95}, {"referenceID": 10, "context": "Now our system has detected decimation should be triggered, the following question is \u201cwhich variables to decimate?\u201d In [11], the variable is chosen randomly in a uniform manner, while in [12], the variable with a the maximum entropy over its marginal values (the most determined variable) is selected.", "startOffset": 120, "endOffset": 124}, {"referenceID": 11, "context": "Now our system has detected decimation should be triggered, the following question is \u201cwhich variables to decimate?\u201d In [11], the variable is chosen randomly in a uniform manner, while in [12], the variable with a the maximum entropy over its marginal values (the most determined variable) is selected.", "startOffset": 188, "endOffset": 192}, {"referenceID": 10, "context": "From which subset choosing the candidate variables to decimate? Both [11] and [12] select the only variable to decimate amongst the whole set of non-decimated variables (cf.", "startOffset": 69, "endOffset": 73}, {"referenceID": 11, "context": "From which subset choosing the candidate variables to decimate? Both [11] and [12] select the only variable to decimate amongst the whole set of non-decimated variables (cf.", "startOffset": 78, "endOffset": 82}, {"referenceID": 10, "context": "In [11], it is fully random: it does not depends on the current state of the variables.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "U [0, 1]).", "startOffset": 2, "endOffset": 8}, {"referenceID": 11, "context": "In [12], the variable with the maximal entropy over its marginal values is selected.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "In [11] and [12], decimation only concerns all the variables, from which only one will be chosen.", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "In [11] and [12], decimation only concerns all the variables, from which only one will be chosen.", "startOffset": 12, "endOffset": 16}, {"referenceID": 5, "context": "), like the one used for quiescence detection, to propagate election messages [6].", "startOffset": 78, "endOffset": 81}, {"referenceID": 11, "context": "[12] is using such a criterion for inference:", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "While, the policy is deterministic, in [11] the choice of the value is a random choice using the marginal values as a probability distribution:", "startOffset": 39, "endOffset": 43}, {"referenceID": 2, "context": "In this section we evaluate the performance of different combinations of decimation policies in DeciMaxSum, on a classical optimization model (Ising model), against classical Max-Sum [3] and its extension Max-Sum_AD_VP [20], we have implemented in our own framework.", "startOffset": 183, "endOffset": 186}, {"referenceID": 19, "context": "In this section we evaluate the performance of different combinations of decimation policies in DeciMaxSum, on a classical optimization model (Ising model), against classical Max-Sum [3] and its extension Max-Sum_AD_VP [20], we have implemented in our own framework.", "startOffset": 219, "endOffset": 223}, {"referenceID": 3, "context": "Since we are interested in evaluating our algorithms in the presence of strong dependencies among the values of variables, we evaluate them on Ising model which is a widely used benchmark in statistical physics [4].", "startOffset": 211, "endOffset": 214}, {"referenceID": 17, "context": "We use here the same settings than [18].", "startOffset": 35, "endOffset": 39}, {"referenceID": 2, "context": "\u03a6all from equation 6), \u2022 perform policies (\u03a5 criterion): \u2217 \u03a5max_rand (from equation 8, noted random), \u2217 \u03a5max_entropy (from equation 9, noted max_entropy), \u2022 assignment policies (\u039b criterion): \u2217 deterministic \u039bmax_marginal (from equation 13, noted deterministic), \u2217 sampled \u039bsample_marginal (from equation 14, noted sampling), \u2013 MaxSum, as defined in [3], \u2013 MaxSum_AD, as defined in [20], \u2013 MaxSum_AD_VP, as defined in [20], \u2013 Montanari-Decimation, as defined in [11], \u2013 Mooij-Decimation, as defined in [12].", "startOffset": 350, "endOffset": 353}, {"referenceID": 19, "context": "\u03a6all from equation 6), \u2022 perform policies (\u03a5 criterion): \u2217 \u03a5max_rand (from equation 8, noted random), \u2217 \u03a5max_entropy (from equation 9, noted max_entropy), \u2022 assignment policies (\u039b criterion): \u2217 deterministic \u039bmax_marginal (from equation 13, noted deterministic), \u2217 sampled \u039bsample_marginal (from equation 14, noted sampling), \u2013 MaxSum, as defined in [3], \u2013 MaxSum_AD, as defined in [20], \u2013 MaxSum_AD_VP, as defined in [20], \u2013 Montanari-Decimation, as defined in [11], \u2013 Mooij-Decimation, as defined in [12].", "startOffset": 382, "endOffset": 386}, {"referenceID": 19, "context": "\u03a6all from equation 6), \u2022 perform policies (\u03a5 criterion): \u2217 \u03a5max_rand (from equation 8, noted random), \u2217 \u03a5max_entropy (from equation 9, noted max_entropy), \u2022 assignment policies (\u039b criterion): \u2217 deterministic \u039bmax_marginal (from equation 13, noted deterministic), \u2217 sampled \u039bsample_marginal (from equation 14, noted sampling), \u2013 MaxSum, as defined in [3], \u2013 MaxSum_AD, as defined in [20], \u2013 MaxSum_AD_VP, as defined in [20], \u2013 Montanari-Decimation, as defined in [11], \u2013 Mooij-Decimation, as defined in [12].", "startOffset": 418, "endOffset": 422}, {"referenceID": 10, "context": "\u03a6all from equation 6), \u2022 perform policies (\u03a5 criterion): \u2217 \u03a5max_rand (from equation 8, noted random), \u2217 \u03a5max_entropy (from equation 9, noted max_entropy), \u2022 assignment policies (\u039b criterion): \u2217 deterministic \u039bmax_marginal (from equation 13, noted deterministic), \u2217 sampled \u039bsample_marginal (from equation 14, noted sampling), \u2013 MaxSum, as defined in [3], \u2013 MaxSum_AD, as defined in [20], \u2013 MaxSum_AD_VP, as defined in [20], \u2013 Montanari-Decimation, as defined in [11], \u2013 Mooij-Decimation, as defined in [12].", "startOffset": 462, "endOffset": 466}, {"referenceID": 11, "context": "\u03a6all from equation 6), \u2022 perform policies (\u03a5 criterion): \u2217 \u03a5max_rand (from equation 8, noted random), \u2217 \u03a5max_entropy (from equation 9, noted max_entropy), \u2022 assignment policies (\u039b criterion): \u2217 deterministic \u039bmax_marginal (from equation 13, noted deterministic), \u2217 sampled \u039bsample_marginal (from equation 14, noted sampling), \u2013 MaxSum, as defined in [3], \u2013 MaxSum_AD, as defined in [20], \u2013 MaxSum_AD_VP, as defined in [20], \u2013 Montanari-Decimation, as defined in [11], \u2013 Mooij-Decimation, as defined in [12].", "startOffset": 502, "endOffset": 506}, {"referenceID": 16, "context": "DeciMaxSum on real world applications, with strong loopy nature, like the coordination of smart objects in IoT [17] or decentralized energy markets in the smart grid [2].", "startOffset": 111, "endOffset": 115}, {"referenceID": 1, "context": "DeciMaxSum on real world applications, with strong loopy nature, like the coordination of smart objects in IoT [17] or decentralized energy markets in the smart grid [2].", "startOffset": 166, "endOffset": 169}], "year": 2017, "abstractText": "In the context of solving large distributed constraint optimization problems (DCOP), belief-propagation and approximate inference algorithms are candidates of choice. However, in general, when the factor graph is very loopy (i.e. cyclic), these solution methods suffer from bad performance, due to non-convergence and many exchanged messages. As to improve performances of the Max-Sum inference algorithm when solving loopy constraint optimization problems, we propose here to take inspiration from the belief-propagation-guided decimation used to solve sparse random graphs (k-satisfiability). We propose the novel DeciMaxSum method, which is parameterized in terms of policies to decide when to trigger decimation, which variables to decimate, and which values to assign to decimated variables. Based on an empirical evaluation on a classical BP benchmark (the Ising model), some of these combinations of policies exhibit better performance than state-of-the-art competitors.", "creator": "LaTeX with hyperref package"}}}