{"id": "1706.02248", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2017", "title": "Comparative Analysis of Open Source Frameworks for Machine Learning with Use Case in Single-Threaded and Multi-Threaded Modes", "abstract": "The basic features of some of the most versatile and popular open source frameworks for machine learning (TensorFlow, Deep Learning4j, and H2O) are considered and compared. Their comparative analysis was performed and conclusions were made as to the advantages and disadvantages of these platforms. The performance tests for the de facto standard MNIST data set were carried out on H2O framework for deep learning algorithms designed for CPU and GPU platforms for single-threaded and multithreaded modes of operation.", "histories": [["v1", "Wed, 7 Jun 2017 16:41:21 GMT  (410kb)", "http://arxiv.org/abs/1706.02248v1", "4 pages, 6 figures, 4 tables; XIIth International Scientific and Technical Conference on Computer Sciences and Information Technologies (CSIT 2017), Lviv, Ukraine"]], "COMMENTS": "4 pages, 6 figures, 4 tables; XIIth International Scientific and Technical Conference on Computer Sciences and Information Technologies (CSIT 2017), Lviv, Ukraine", "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.DC", "authors": ["yuriy kochura", "sergii stirenko", "anis rojbi", "oleg alienin", "michail novotarskiy", "yuri gordienko"], "accepted": false, "id": "1706.02248"}, "pdf": {"name": "1706.02248.pdf", "metadata": {"source": "CRF", "title": "Comparative Analysis of Open Source Frameworks for Machine Learning with Use Case in Single- Threaded and Multi-Threaded Modes", "authors": ["Yuriy Kochura", "Sergii Stirenko", "Anis Rojbi", "Oleg Alienin", "Michail Novotarskiy", "Yuri Gordienko"], "emails": ["iuriy.kochura@gmail.com"], "sections": [{"heading": null, "text": "The performance tests for the de facto standard MNIST dataset were conducted on the H2O framework for deep learning algorithms designed for CPU and GPU platforms for single-thread and multi-threaded modes. Keywords - Machine Learning; TensorFlow; Deep Learning4j; H2O; MNIST; Multicore CPU; GPUI Nowadays, Machine Learning (ML) has developed many areas such as pedestrian detection, embedding visualization, speech recognition, acoustic modelling in language, classification of videos, etc."}, {"heading": "A. Deep Learning4j", "text": "Deep Learning4j (DL4J) is the open source deep learning library written for Java and Scala that can be integrated with Hadoop and Spark [2]. It is designed for use on distributed GPUs and CPUs platforms and offers the ability to work with any n-dimensional arrays (also known as tensors) and the use of CPU and GPU resources. Unlike many other frameworks, DL4J separates the optimization algorithm from the updater algorithm, allowing flexibility in trying to find a combination that is best suited to data and problems."}, {"heading": "B. TensorFlow", "text": "TensorFlow is an open source numerical computing software library originally developed by researchers and engineers working on the Google Brain team within Google's Machine Intelligence [3] research organization to perform machine learning and deep neural network exploration, which is the successor to DistBelief, the distributed neural network formation system that Google has been using since 2011. TensorFlow works on a large scale and in heterogeneous environments, using data flow diagrams to represent computation, common state, and operations that mutate that state. It maps the nodes of a data flow diagram across many machines in a cluster and within a machine across multiple computer devices, including multi-core CPUs, general-purpose GPUs, and custom ASICs known as Tensor Processing Units (TPUs)."}, {"heading": "C. H2O", "text": "The H2O software is based on Java, Python and R with the purpose of optimizing machine learning for big data [4]. It is offered as an open source platform with the following characteristics: Big Data Friendly means that you can use all your data in real time for better predictions with H2O's fast parallel processing capacities distributed in memory. For production use, a developer does not have to worry about variation in the development platform and production environment. H2O models can be used and used like any standard Java object once created. H2O models are compiled in POJO (Plain Old Java Files) or a MOJO (Model Object Optimized) format that can be easily embedded in any Java environment. The beauty of H2O is that its algorithms can be used by different categories of end users, business analysts and statisticians (who are not familiar with its web-based languages)."}, {"heading": "D. Comparative Analysis", "text": "From an end-user perspective, several aspects of these frameworks are not specified, but proposed as an additional barrier in the water barrier. Apart from performance and maturity, the open source frameworks could be attractive and useful if they have broad language and operating system support (see Table I), all of which are characterized by a fairly wide range of supported languages and operating systems, but nowadays it is not enough in terms of the rapid development of parallel and distributed computer systems such as clusters and, in particular, GPGPU computing. In this context, TensorFlow has clear notifications about the preconditions for NVIDIA GPPU cards that should have CUDA Compute Capability (CC) 3.0 or higher. Like DL4J, this is not clear because developers only have general support for NVIDIA GPGPU cards from GeForce GTX to Titan and Tesla, which have different CC types from 2.0 to 3.5."}], "references": [{"title": "Data Mining: Practical machine learning tools and techniques", "author": ["I.H. Witten", "E. Frank", "M.A. Hall", "C.J. Pal"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "TensorFlow: A system for large-scale machine learning", "author": ["M Abadi"], "venue": "12th USENIX Symposium on Operating Systems Design and Implementation (OSDI", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Deep Learning with H2O. H2O", "author": ["A. Candel", "V. Parmar", "E. LeDell", "A. Arora"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "DCI bridge: Executing WS-PGRADE workflows in distributed computing infrastructures. Science Gateways for Distributed Computing Infrastructures (pp. 51-67)", "author": ["M Kozlovszky"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Software review: the KNIME workflow environment and its applications in Genetic Programming and machine learning", "author": ["S. O\u2019Hagan", "D.B. Kell"], "venue": "Genetic Programming and Evolvable Machines,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "IMP Science Gateway: from the Portal to the Hub of Virtual Experimental Labs in e-Science and Multiscale Courses in e-Learning", "author": ["Y Gordienko"], "venue": "Concurrency and Computation: Practice and Experience,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Quantum chemical meta-workflows in MoSGrid", "author": ["S Herres-Pawlis"], "venue": "Concurrency and Computation: Practice and Experience,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "VO-compliant workflows and science gateways", "author": ["G Castelli"], "venue": "Astronomy and Computing,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "User-driven Intelligent Interface on the Basis of Multimodal Augmented Reality and Brain-Computer Interaction for People with Functional Disabilities, arXiv:1704.05915", "author": ["S.Stirenko"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2017}, {"title": "Augmented Coaching Ecosystem for Nonobtrusive Adaptive Personalized Elderly Care on the Basis of Cloud- Fog-Dew Computing Paradigm", "author": ["Yu.Gordienko"], "venue": "Proc. IEEE 40th Int. Conv. Inform. and Communic. Technology, Electronics and Microelectronics (MIPRO)", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2017}, {"title": "Software Frameworks for Deep Learning at Scale", "author": ["James Fox", "Yiming Zou", "Judy Qiu"], "venue": "Internal Indiana University Technical Report", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "The MNIST database of handwritten digits", "author": ["Y. LeCun", "C. Cortes", "C.J. Burges"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1998}, {"title": "Deep Learning Benchmark Use Case for TensorFlow, Caffe, and mxnet", "author": ["Yu.Kochura"], "venue": "Proc. 9th Int. Conf. Communication and Information Technologies", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2017}, {"title": "Deep Learning for Fatigue Estimation on the Basis of Multimodal Human-Machine Interactions", "author": ["Yu.Kochura"], "venue": "Proc. XXIX IUPAP Conference in Computational Physics", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2017}], "referenceMentions": [{"referenceID": 0, "context": "This success is related to the invention and application of more sophisticated machine learning models and the development of software platforms that enable the easy use of large amounts of computational resources for training such models [1].", "startOffset": 239, "endOffset": 242}, {"referenceID": 1, "context": "TensorFlow is an open source software library for numerical computation was originally developed by researchers and engineers working on the Google Brain Team within Google\u2019s Machine Intelligence research organization [3] for the purposes of conducting machine learning and deep neural networks research.", "startOffset": 218, "endOffset": 221}, {"referenceID": 2, "context": "H2O software is built on Java, Python, and R with a purpose to optimize machine learning for Big Data [4].", "startOffset": 102, "endOffset": 105}, {"referenceID": 3, "context": "The examples of their implementations (like WSPGRADE/gUSE [5], KNIME [6], etc.", "startOffset": 58, "endOffset": 61}, {"referenceID": 4, "context": "The examples of their implementations (like WSPGRADE/gUSE [5], KNIME [6], etc.", "startOffset": 69, "endOffset": 72}, {"referenceID": 5, "context": ") and applications in physics [7], chemistry [8], astronomy [9], brain-computing [10], eHealth [11] can be found elsewhere.", "startOffset": 30, "endOffset": 33}, {"referenceID": 6, "context": ") and applications in physics [7], chemistry [8], astronomy [9], brain-computing [10], eHealth [11] can be found elsewhere.", "startOffset": 45, "endOffset": 48}, {"referenceID": 7, "context": ") and applications in physics [7], chemistry [8], astronomy [9], brain-computing [10], eHealth [11] can be found elsewhere.", "startOffset": 60, "endOffset": 63}, {"referenceID": 8, "context": ") and applications in physics [7], chemistry [8], astronomy [9], brain-computing [10], eHealth [11] can be found elsewhere.", "startOffset": 81, "endOffset": 85}, {"referenceID": 9, "context": ") and applications in physics [7], chemistry [8], astronomy [9], brain-computing [10], eHealth [11] can be found elsewhere.", "startOffset": 95, "endOffset": 99}, {"referenceID": 10, "context": "The performance of the mentioned frameworks was a topic of many investigations performed by developers of these frameworks and independent end users [12].", "startOffset": 149, "endOffset": 153}, {"referenceID": 11, "context": "1) from the publicly available MNIST data set for machine learning methods [14].", "startOffset": 75, "endOffset": 79}, {"referenceID": 12, "context": "The influence of many other aspects like nature of data (for example, sparsity level and sparsity pattern), number of hidden layers and their sizes should be taken into account for the better comparative analysis, but these aspects were out of scope of the current work and will be published separately elsewhere [15,16].", "startOffset": 313, "endOffset": 320}, {"referenceID": 13, "context": "The influence of many other aspects like nature of data (for example, sparsity level and sparsity pattern), number of hidden layers and their sizes should be taken into account for the better comparative analysis, but these aspects were out of scope of the current work and will be published separately elsewhere [15,16].", "startOffset": 313, "endOffset": 320}], "year": 2017, "abstractText": "The basic features of some of the most versatile and popular open source frameworks for machine learning (TensorFlow, Deep Learning4j, and H2O) are considered and compared. Their comparative analysis was performed and conclusions were made as to the advantages and disadvantages of these platforms. The performance tests for the de facto standard MNIST data set were carried out on H2O framework for deep learning algorithms designed for CPU and GPU platforms for single-threaded and multithreaded modes of operation. Keywords\u2014machine learning; deep learning; TensorFlow; Deep Learning4j; H2O; MNIST; multicore CPU; GPU.", "creator": "Microsoft\u00ae Office Word 2007"}}}