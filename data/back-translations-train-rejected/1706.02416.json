{"id": "1706.02416", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2017", "title": "Generalized Value Iteration Networks: Life Beyond Lattices", "abstract": "In this paper, we introduce a generalized value iteration network (GVIN), which is an end-to-end neural network planning module. GVIN emulates the value iteration algorithm by using a novel graph convolution operator, which enables GVIN to learn and plan on irregular spatial graphs. We propose three novel differentiable kernels as graph convolution operators and show that the embedding based kernel achieves the best performance. We further propose episodic Q-learning, an improvement upon traditional n-step Q-learning that stabilizes training for networks that contain a planning module. Lastly, we evaluate GVIN on planning problems in 2D mazes, irregular graphs, and real-world street networks, showing that GVIN generalizes well for both arbitrary graphs and unseen graphs of larger scale and outperforms a naive generalization of VIN (discretizing a spatial graph into a 2D image).", "histories": [["v1", "Thu, 8 Jun 2017 00:04:05 GMT  (3121kb,D)", "http://arxiv.org/abs/1706.02416v1", "14 pages, conference"], ["v2", "Thu, 26 Oct 2017 15:23:18 GMT  (2969kb,D)", "http://arxiv.org/abs/1706.02416v2", "14 pages, conference"]], "COMMENTS": "14 pages, conference", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["sufeng niu", "siheng chen", "hanyu guo", "colin targonski", "melissa c smith", "jelena kova\\v{c}evi\\'c"], "accepted": false, "id": "1706.02416"}, "pdf": {"name": "1706.02416.pdf", "metadata": {"source": "CRF", "title": "Generalized Value Iteration Networks: Life Beyond Lattices", "authors": ["Sufeng Niu", "Siheng Chen", "Hanyu Guo", "Jelena Kova\u010devi\u0107"], "emails": ["sniu@g.clemson.edu", "sihengc@andrew.cmu.edu", "hanyug@g.clemson.edu", "ctargon@g.clemson.edu", "smithmc@clemson.edu", "jelenak@cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "2 Background", "text": "We consider an environment defined as an MDP that involves a number of states taking a number of measures that require a number of actions, a reward function Rs, a, and a number of transition probabilities Ps, s, a, the likelihood of switching from the current state s to the next state s, but requiring an action a. The objective of an MDP is to find a policy that maximizes the expected return (accumulated rewards) Rt = 0 \u03b3krt + k, where rt + k is the immediate reward on the (t + k) th timestamp and \u03b3 th timestamp (0, 1) is the discount rate. A policy is the likelihood of taking action when taking action in a state s. The value of a state s under a policy approach s, v\u03c0s, is the expected return when starting in s and following systems; that is, it is the optimal return in and following systems."}, {"heading": "3 Methodology", "text": "In this section, we propose a new model-based DRL framework, GVIN, which uses a generic graph with a start node and a target as input and output for the designed path. GVIN's overarching goal is to learn an underlying MDP that summarizes the optimal planning policy for arbitrary graphs. This requires GVIN to acquire general knowledge about planning that is structure and transition invariant and does not depend on a particular graph structure. A key component of an MDP is the transition matrix needed to solve the Bellman equation. To train a general transition matrix that works for arbitrary graphs, similar to the VIN, we parameterize the transition matrix using graph-based core functions. Each graph-based core function represents a unique action pattern."}, {"heading": "3.1 Framework", "text": "Entering GVIN includes a graph with a start node and a target node."}, {"heading": "3.2 Graph Convolution", "text": "In the original VIN, the inputs are images, and the corresponding G is a 2D grid graph whose nodes are pixels. Each node has the same local structure, sits on a grid, and connects via edges to its immediate adjacent eight nodes. In this case, it is easy to get a structural and translation invariant operator, since all images have the same 2D grid structure. In this regular case, GVIN works like VIN when we set G as a 2D grid graph and consider each wP (a) as a coefficient of a 3 x 3 filter; in other words, VIN is a special case of GVIN when the underlying graph is a 2D grid. However, in irregular graphs, nodes can have different local structures, making it difficult to get a structure and translation invariant operators who transfer knowledge from one kernel to another."}, {"heading": "3.3 Training via Reinforcement Learning", "text": "The difference between episodic Q-Learning and n-step Q-Learning is that the n-step Q-Learning has a fixed episode duration and updates the training weights according to n steps; whereas in episodic Q-Learning, each episode ends until the agent reaches the target or the maximum step threshold, and we update the training weights according to n steps. During the experiments, we found that for both regular and irregular charts, the strategy planned by the original Q-Learning is constantly changing and does not converge due to the frequent updates. Similar to the Monte Carlo algorithms [22], episodic Q-Learning initially selects actions based on its exploration policy until we reach the goal. Afterwards, we accumulate the gradients throughout the episode and then update the training weights, allowing the agent to use a stable plan to complete an entire episode. This simple change significantly improves performance (see section 4.1)."}, {"heading": "4 Experimental Results", "text": "In this section, we evaluate the proposed method using three types of diagrams: 2D labyrinths, synthesized irregular diagrams, and real road networks. First, we check whether the proposed GVIN is comparable to the original VIN for 2D labyrinths that have a regular grid structure. Next, we show that the proposed GVIN automatically learns the concepts of direction and distance in synthesized irregular diagrams through the learning environment for reinforcement (without using floor-level labels). Finally, we use the pre-trained GVIN model to plan paths for the Minnesota and Manhattan road network. Further parameter settings for experiments are listed in Additional Materials 6.4."}, {"heading": "4.1 Revisting 2D Mazes", "text": "This year, the number of job-related redundancies has increased many times over previous years."}, {"heading": "4.2 Exploring Irregular Graphs", "text": "We look at four comparisons in the following areas: \"We have the ability to adjust ourselves to the needs of people,\" he says, \"we have the ability to adjust ourselves to the needs of our fellow human beings.\" (\"We are not afraid.\") \"We do not know what we should do.\" (\"We do not know what we should do.\") \"We do not know what we should do.\" (\"We do not know what we should do.\") \"(\" We do not know what we should do. \")\" (\"We do not know what we should do.\") \"We do not know what we should do.\" (\"We do not know.\") \"(\" We do not know what we should do. \"(\" We do not know. \")\" (\"We do.\" (\"We do.\") \"(\" We do. \"(\" We do. \")\" (\"We do.\" (\"We do not know.\") \"(\" We do. \"(\" We do. \")\" (\"We do.\" We do. \"(\" We do not know. \")\" We do. \"(\" We do. \"We know.\" (\"We know.\" We do. \").\" We know. \"We know.\" We do. \"(\" We do. \"We know.\" We do. \"We do.\" We do. \"(\" We know. \"We do.\"). \"We do.\" We do. \"(\" We know. \"We do.\" We do. \"(\" We do not know. \"We do.\"). \"We do.\" (\"We do.\" We do. \"We do not know.\" We do. \"(\" We do. \").\" We do. \"(\" We do not know. (\"We do not know.\" We do. \"). (\" We do. (\"We do.\" We do not know. \"). (\" We do. (\"We do.\" We do. \"). (\" We do. (\"We do not know.\" We do. \").\" We do. (\"We do. (\" We do not know. \"We do.\"). (\"We do.\""}, {"heading": "4.3 Validating Real Road Networks", "text": "To demonstrate the generalizability of GVIN, we evaluate two real-world maps: the Minnesota Highway Maps, which contain 2642 nodes for intersections and 6606 edges for roads, and the New York City Street Map, which contains 5069 nodes for intersections and 13368 edges for roads. We use the same models that are trained with the embedded kernel on the diagrams with | V | = 100 and | V | = 10 nodes, and separately use episodic Q-learning in Section 4.2. We normalize the data coordinates between 0 and 1 and set the repeat parameter toK = 200. We randomly select starting points and targets 1,000 times. We use the A * algorithm as the baseline. Table 4 shows that both | V | = 100 and | V | = 10 generate well on large-scale data."}, {"heading": "5 Conclusions", "text": "We have introduced GVIN, a differentiated, novel planning module that enables both regular and irregular chart navigation and impressive generalization of scale. We have also introduced episodic Qlearning, an algorithm for stabilizing the training process of neural networks that includes a planning module. In future work, we intend to explore broader applications and approaches to encode the edge weight information into the network."}, {"heading": "6 Appendix", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Computational Complexity", "text": "In the test phase, the computational complexities of (1), (3) and (4) are O (| V |), O (| E |) and O (| V |). For a spatial graph, the number of edges is usually proportional to the number of nodes; therefore, the computational complexity is O (| V | + K (| E | + | V |)), which is scalable to huge graphs. 6.2 Episodic Q-LearningWe highlight the differences between episodic Q-Learning and the original n-Step Q-Learning in blue, including the initial expected return, the termination condition and the timing of the update of the gradation: 0 Episodic Q-LearningWe highlight the differences between episodic Q-Learning and the original N-Learning in blue, including the gradation: 0 gradation: 1 gradation and the timing of the upgrade of the gradation: 1 Episodic Q-Learning 1 input sequence: G = 4: G = G = 7: G = G: G = 4: G = 7: G = 7"}, {"heading": "20: T = T + 1", "text": "21: to T > Tmax"}, {"heading": "6.3 Graph-based Kernel Functions", "text": "When facing several streets at an intersection, it is easy to select the one whose direction points to the destination. We aim to use the directional kernel to grasp the edge direction and parameterize the graph convolution. (i, j) th element in the graph convolution operator represents the probability of following the edge from i to j; that is, Pi, j = Ai, j \u00b7 L \"is the direction of the edge connection between the two nodes. (i, j) th element in the graph convolution operator (1 + cos) d (1 + cos) 2) t, where the kernel coefficient is, it is the direction of the edge connection between the ith and the thejth nodes that can be compiled by embedding the Xi-R2 and Xj-R2."}, {"heading": "6.4 Experiments Settings", "text": "Our implementation is based on tensor flow with a GPU-enabled platform. All experiments use the standards-centered RMSProp algorithm as an optimizer with learning rate \u03b7 = 0.001 [24]. All amplifier experiments use a discount of \u03b3 = 0.99, the RMSProp decay factor of \u03b1 = 0.999 and the exploration rate glowed linearly from 0.2 to 0.001 during the first 200 epochs."}, {"heading": "6.4.1 2D Mazes", "text": "Parameter Settings. The experiments are structured as follows: To pre-process the input data, we use the same two-layer CNN matrix for both VIN and GVIN, with the first layer comprising 150 cores of size 3 x 3 and the second layer a kernel of size 3 x 3. The transition probability matrix is parameterized by 10 folding cores of size 3 x 3 both in VIN and in GVIN. In GVIN, we use the directional nuclear-based method as shown in equations 5 and 6, and we set \"= 8 to represent the eight reference directions. We consider two approaches to initialize the directions:\" In the direction-conscious approach, we fix \"as [0, \u03c0 / 4, \u03c0 / 2,..., 7\u03c0 / 4]. In the direction-unconscious approach, we lay\" to be weights and train them by backpropagation."}, {"heading": "6.4.2 Irregular Graphs", "text": "We evaluate our proposed methods in Section 3.2 for the irregular domain. Our experimental domain consists of N = 10000 irregular graphs in which each graph contains 100 nodes. For each node in the graph, we also define the coordinates that its spatial position is between 0 and 1. The data set is divided into 7672 graphs for training and 1428 graphs for testing. In addition, we specify the number of reference graphs consisting of 100 nodes and 42857 graphs for testing and 7143 graphs for testing."}, {"heading": "6.5 Minnesota and NYC Sample Planning", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "In this paper, we introduce a generalized value iteration network (GVIN), which<lb>is an end-to-end neural network planning module. GVIN emulates the value<lb>iteration algorithm by using a novel graph convolution operator, which enables<lb>GVIN to learn and plan on irregular spatial graphs. We propose three novel<lb>differentiable kernels as graph convolution operators and show that the embedding-<lb>based kernel achieves the best performance. We further propose episodic Q-<lb>learning, an improvement upon traditional n-stepQ-learning that stabilizes training<lb>for networks that contain a planning module. Lastly, we evaluate GVIN on planning<lb>problems in 2D mazes, irregular graphs, and real-world street networks, showing<lb>that GVIN generalizes well for both arbitrary graphs and unseen graphs of larger<lb>scale and outperforms a naive generalization of VIN (discretizing a spatial graph<lb>into a 2D image).", "creator": "LaTeX with hyperref package"}}}