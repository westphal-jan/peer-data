{"id": "1706.02427", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2017", "title": "Content-Based Table Retrieval for Web Queries", "abstract": "Understanding the connections between unstructured text and semi-structured table is an important yet neglected problem in natural language processing. In this work, we focus on content-based table retrieval. Given a query, the task is to find the most relevant table from a collection of tables. Further progress towards improving this area requires powerful models of semantic matching and richer training and evaluation resources. To remedy this, we present a ranking based approach, and implement both carefully designed features and neural network architectures to measure the relevance between a query and the content of a table. Furthermore, we release an open-domain dataset that includes 21,113 web queries for 273,816 tables. We conduct comprehensive experiments on both real world and synthetic datasets. Results verify the effectiveness of our approach and present the challenges for this task.", "histories": [["v1", "Thu, 8 Jun 2017 02:03:32 GMT  (381kb,D)", "http://arxiv.org/abs/1706.02427v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["zhao yan", "duyu tang", "nan duan", "junwei bao", "yuanhua lv", "ming zhou", "zhoujun li"], "accepted": false, "id": "1706.02427"}, "pdf": {"name": "1706.02427.pdf", "metadata": {"source": "CRF", "title": "Content-Based Table Retrieval for Web Queries", "authors": ["Zhao Yan", "Duyu Tang", "Nan Duan", "Junwei Bao", "Yuanhua Lv", "Ming Zhou", "Zhoujun Li"], "emails": ["lizj}@buaa.edu.cn", "baojunwei001@gmail.com", "mingzhou}@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, the fact is that most of them are able to move to another world in which they are able to integrate and in which they are able to find themselves."}, {"heading": "2 Task Definition", "text": "Given a query q and a collection of tables T = {t1,..., tN}, the purpose of the table search is to find a table ti, which is for q.Typically, a query q is a natural-language expression consisting of a list of words, such as \"cities of the Netherlands.\" A table t is a set of data elements arranged by vertical columns and horizontal rows. Formally, we define a table as triple t = {headers, cells, captions}, which consists of three aspects. A table could have several headers, each of which indicates the property of a column and could be used to identify a column.A table could have several cells, each of which is a unit in which a row and a column intersect. A table could have a heading, which is typically an explanatory text about the table. Figure 1 gives an example to illustrate various aspects of a table.It is helpful to point out that tables intersect from a web column and a row."}, {"heading": "3 Approach Overview", "text": "In this section we give an overview of the proposed approach. In order to build a system with high efficiency, we divide the task into two cascaded modules, including the search for candidate tables and the ranking list. The search for candidate tables aims to find a small set of tables, e.g. 50 or 100. These candidate tables are further used in the ranking list, which uses more complex functions to measure the relevance between a query and a table. In the following subsections, we describe the workflow of the search for candidate tables and the ranking list. The detailed description of the features is described in the next section."}, {"heading": "3.1 Candidate Table Retrieval", "text": "To ensure the efficiency of the search process, we calculate the similarity between table and query with Okapi BM25 (Robertson et al., 1995), which is mathematically efficient and has been successfully used to query information. Specifically, we represent a query as a vocabulary and represent the plaintext table composed of the words of caption and header. In the face of a query q = x1, x2,..., xn, a table t and the whole query T, the BM25 value of query q and table t is calculated as follows. BM25 (q, t) = n \u2211 i = 1 idf (xi, t) tf (xi, t) \u00b7 (k1 + 1) tf (xi, T) + k1 (1 \u2212 b + b | t | avgtl), where tf (idxi) = 1 idf (xi), the word in verse (xi, t), the frequency in verse (xi), and the frequency (1) is in sequence (1) and (1)."}, {"heading": "3.2 Table Ranking", "text": "The goal of the ranking is to classify a short list of candidate tables by measuring the relevance between a query and a table. We develop a property-based approach and an approach for neural networks, both of which effectively take into account the structure of the table. Details of the characteristics are described in the next section. We use each characteristic to calculate a relevance value that represents the similarity between a query and a table from any perspective. We then use LambdaMART (Burges, 2010), a successful algorithm for solving the ranking problem in the real world, to determine the final ranking value of each table.2 The basic idea of LambdaMART is that it constructs a forest of decision trees, and its output is a linear combination of the results of decision tree trees. Each binary branch of a decision tree sets a threshold that applies to a single characteristic, and each leaf node is a real value specifically calculated for a forest value (where tri = N pairs wi wi)."}, {"heading": "4 Matching between Query and Table", "text": "Measuring the relevance between a query and a table is of great importance for retrieving tables. In this section, we present carefully designed features and neural network architectures for matching between a query and a table."}, {"heading": "4.1 Matching with Designed Features", "text": "We carefully design a set of characteristics that are matched with the length of q and ta. (D) We design two word matching characteristics fwmt and fmwq. (D) We design two word matching characteristics fwmt and fwmq. (D) We design two word matching characteristics fwmt and fmwq. (D) We have a large amount of word overlaps. (D) We present each aspect as a word sequence in this part. (D) We design two word matching characteristics fwmt and fwmq. (D) We design two word matching characteristics fwmt and ta if they have a large amount of word overlaps. (D) We design two word matching characteristics fwmt and fwmq. (D) We design two word matching characteristics fwmt and ta if they have a large amount of word overlaps."}, {"heading": "4.2 Matching with Neural Networks", "text": "We present neural network models that adapt to a table, taking into account various aspects such as headers, cells, and captions. (We develop different strategies for measuring the relevance between a query and a table from different perspectives.) In this subsection, we first describe the model for calculating the query results, and then introduce the method that measures the relevance between a query and each aspect. (We use recurrent neural networks (RNN) to map a query of the variable length of a vector. To avoid the problem of gradient disappearance, we use gated recurrent unit (GRU) (Cho et al, 2014) as the basic unit of calculation."}, {"heading": "5 Experiment", "text": "We describe the experimental framework and analyze the results in this section."}, {"heading": "5.1 Dataset and Setting", "text": "We introduce WebQueryTable, an open domain dataset consisting of query table pairs. We use search logs from a commercial search engine to get a list of queries that could potentially be answered by web tables. Each query in query logs is paired with a list of web pages, ordered by the number of user clicks for the query. We select the tables that have occurred in the top ranking web page and ask comments if a table is relevant to a query or not. In this way, we get 21,113 query table pairs that focus on the number of user clicks for the query. In the real scenario of table retrievers, a system is required to find a table from a huge collection of tables. 3We also implemented a ranking-based loss function based on max. (0 \u2212 five, q) + five, but it resulted in a worse than the negative logging probability in our creation."}, {"heading": "5.2 Results on WebQueryTable", "text": "We compare the different characteristics for the ranking of each table. An intuitive baseline is to represent a table as a dead end that represents a query with dead ends of words, and calculates their similarity to cosine similarities. Therefore, we use the BM25 result that is retrieved from the candidate list. Results from Table 2 show that the neural networks function similarly to the designed characteristics and perform better than the BM25 baseline. These results reflect the need to consider the table structure for table retrieval. In addition, we can find that the combination of functions and neural networks leads to better performance than the BM25 baseline. We find the table structure for table retrieval. We can find that the combination of designed characteristics and neural networks achieve further improvements to which we achieve."}, {"heading": "5.3 Results on WikiTableQuestions", "text": "We implement two baselines, partly inspired by Venetis et al. (2011), which show the effectiveness of the semantic relationship between query and table header. We implement a CDSSM approach (Shen et al., 2014) to match between a table header and a query. We train the model by minimizing the cross-entropy error, where the basic truth is the header of the answer. Results are given in Table 4. We can find that designed features work similarly to neural networks, and both of them perform better than BM25 and column-grounding baseline. Combine designed features and neural networks are further improved. We also examine the effects of various aspects on the WikiTableons questionnaires. Results are given in Table 5."}, {"heading": "6 Related Work", "text": "Our work relates to the fields of the database and natural language processing. There are several works in the database community aimed at finding related tables from keyword queries. A representative work is given by Cafarella et al. (2008), which considers table search as a specific case of document search task and presents a table with its surrounding text and page title. Limaye et al. (2010) use YAGO ontology to comment on tables with column and relationship labels. Venetis et al. (2011) go a step further and use labels and relationships extracted from the web. Pimplikar and Sarawagi (2012) focus on the queries describing table columns, and retrieve tables based on column mapping. There are also table-related studies such as searching related tables from a table (Das Sarma et al., 2012), assembling a table from the list of web tables (Gupta and Sarawi) with table structure (2009 and Gupta)."}, {"heading": "7 Conclusion", "text": "In this paper, we provide an empirical study of content-based retrieval of tables for web queries. We implement a function-based approach and a neural networking approach, and publish a new dataset consisting of web queries and web tables. We conduct extensive experiments on two datasets. Results not only confirm the effectiveness of our approach, but also present future challenges for content-based retrieval of tables."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "International Conference on Learning Representations (ICLR) .", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Applying webtables in practice", "author": ["Sreeram Balakrishnan", "Alon Y Halevy", "Boulos Harb", "Hongrae Lee", "Jayant Madhavan", "Afshin Rostamizadeh", "Warren Shen", "Kenneth Wilder", "Fei Wu", "Cong Yu."], "venue": "Proceedings of Conference on Innovative Data", "citeRegEx": "Balakrishnan et al\\.,? 2015", "shortCiteRegEx": "Balakrishnan et al\\.", "year": 2015}, {"title": "From ranknet to lambdarank to lambdamart: An overview", "author": ["Christopher JC Burges."], "venue": "Microsoft Research Technical Report MSR-TR-2010-82 11(23581):81.", "citeRegEx": "Burges.,? 2010", "shortCiteRegEx": "Burges.", "year": 2010}, {"title": "Webtables: exploring the power of tables on the web", "author": ["Michael J Cafarella", "Alon Halevy", "Daisy Zhe Wang", "Eugene Wu", "Yang Zhang."], "venue": "Proceedings of the VLDB Endowment 1(1):538\u2013549.", "citeRegEx": "Cafarella et al\\.,? 2008", "shortCiteRegEx": "Cafarella et al\\.", "year": 2008}, {"title": "Learning phrase representations using rnn encoder\u2013decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio."], "venue": "Proceedings of", "citeRegEx": "Cho et al\\.,? 2014", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1412.3555 .", "citeRegEx": "Chung et al\\.,? 2014", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "Finding related tables", "author": ["Anish Das Sarma", "Lujun Fang", "Nitin Gupta", "Alon Halevy", "Hongrae Lee", "Fei Wu", "Reynold Xin", "Cong Yu."], "venue": "Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data. ACM, pages", "citeRegEx": "Sarma et al\\.,? 2012", "shortCiteRegEx": "Sarma et al\\.", "year": 2012}, {"title": "Paraphrase-driven learning for open question answering", "author": ["Anthony Fader", "Luke Zettlemoyer", "Oren Etzioni."], "venue": "Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL).", "citeRegEx": "Fader et al\\.,? 2013", "shortCiteRegEx": "Fader et al\\.", "year": 2013}, {"title": "Towards domain-independent information extraction from web tables", "author": ["Wolfgang Gatterbauer", "Paul Bohunsky", "Marcus Herzog", "Bernhard Kr\u00fcpl", "Bernhard Pollak."], "venue": "Proceedings of the 16th international conference on World Wide Web (WWW).", "citeRegEx": "Gatterbauer et al\\.,? 2007", "shortCiteRegEx": "Gatterbauer et al\\.", "year": 2007}, {"title": "Answering table augmentation queries from unstructured lists on the web", "author": ["Rahul Gupta", "Sunita Sarawagi."], "venue": "Proceedings of the VLDB Endowment 2(1):289\u2013300.", "citeRegEx": "Gupta and Sarawagi.,? 2009", "shortCiteRegEx": "Gupta and Sarawagi.", "year": 2009}, {"title": "Statistical phrase-based translation", "author": ["Philipp Koehn", "Franz Josef Och", "Daniel Marcu."], "venue": "Proceedings of Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-", "citeRegEx": "Koehn et al\\.,? 2003", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Neural text generation from structured data with application to the biography domain", "author": ["R\u00e9mi Lebret", "David Grangier", "Michael Auli."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language (EMNLP).", "citeRegEx": "Lebret et al\\.,? 2016", "shortCiteRegEx": "Lebret et al\\.", "year": 2016}, {"title": "Annotating and searching web tables using entities, types and relationships", "author": ["Girija Limaye", "Sunita Sarawagi", "Soumen Chakrabarti."], "venue": "Proceedings of the VLDB Endowment 3(1-2):1338\u2013 1347.", "citeRegEx": "Limaye et al\\.,? 2010", "shortCiteRegEx": "Limaye et al\\.", "year": 2010}, {"title": "What to talk about and how? selective generation using lstms with coarse-to-fine alignment", "author": ["Hongyuan Mei", "Mohit Bansal", "Matthew R. Walter."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Associ-", "citeRegEx": "Mei et al\\.,? 2016", "shortCiteRegEx": "Mei et al\\.", "year": 2016}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in neural information processing systems (NIPS). pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Neural programmer: Inducing latent programs with gradient descent", "author": ["Arvind Neelakantan", "Quoc V Le", "Ilya Sutskever."], "venue": "arXiv preprint arXiv:1511.04834 .", "citeRegEx": "Neelakantan et al\\.,? 2015", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2015}, {"title": "Compositional semantic parsing on semi-structured tables", "author": ["Panupong Pasupat", "Percy Liang."], "venue": "Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL) .", "citeRegEx": "Pasupat and Liang.,? 2015", "shortCiteRegEx": "Pasupat and Liang.", "year": 2015}, {"title": "Answering table queries on the web using column keywords", "author": ["Rakesh Pimplikar", "Sunita Sarawagi."], "venue": "Proceedings of the VLDB Endowment 5(10):908\u2013 919.", "citeRegEx": "Pimplikar and Sarawagi.,? 2012", "shortCiteRegEx": "Pimplikar and Sarawagi.", "year": 2012}, {"title": "Generating factoid questions with recurrent neural networks: The 30m factoid question-answer corpus", "author": ["Iulian Vlad Serban", "Alberto Garc\u0131\u0301a-Dur\u00e1n", "Caglar Gulcehre", "Sungjin Ahn", "Sarath Chandar", "Aaron Courville", "Yoshua Bengio"], "venue": null, "citeRegEx": "Serban et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Serban et al\\.", "year": 2016}, {"title": "A latent semantic model with convolutional-pooling structure for information retrieval", "author": ["Yelong Shen", "Xiaodong He", "Jianfeng Gao", "Li Deng", "Gr\u00e9goire Mesnil."], "venue": "Proceedings of the Conference on Information and Knowledge Management (CIKM). pages", "citeRegEx": "Shen et al\\.,? 2014", "shortCiteRegEx": "Shen et al\\.", "year": 2014}, {"title": "End-to-end memory networks", "author": ["Sainbayar Sukhbaatar", "Arthur Szlam", "Jason Weston", "Rob Fergus."], "venue": "Advances in Neural Information Processing Systems (NIPS). pages 2431\u20132439.", "citeRegEx": "Sukhbaatar et al\\.,? 2015", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2015}, {"title": "Recovering semantics of tables on the web", "author": ["Petros Venetis", "Alon Halevy", "Jayant Madhavan", "Marius Pa\u015fca", "Warren Shen", "Fei Wu", "Gengxin Miao", "Chung Wu."], "venue": "Proceedings of the VLDB Endowment 4(9):528\u2013538.", "citeRegEx": "Venetis et al\\.,? 2011", "shortCiteRegEx": "Venetis et al\\.", "year": 2011}, {"title": "Order matters: Sequence to sequence for sets", "author": ["Oriol Vinyals", "Samy Bengio", "Manjunath Kudlur."], "venue": "arXiv preprint arXiv:1511.06391 .", "citeRegEx": "Vinyals et al\\.,? 2015", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Simple statistical gradientfollowing algorithms for connectionist reinforcement learning", "author": ["Ronald J Williams."], "venue": "Machine learning 8(3-4):229\u2013256.", "citeRegEx": "Williams.,? 1992", "shortCiteRegEx": "Williams.", "year": 1992}, {"title": "Neural generative question answering", "author": ["Jun Yin", "Xin Jiang", "Zhengdong Lu", "Lifeng Shang", "Hang Li", "Xiaoming Li."], "venue": "arXiv preprint arXiv:1512.01337 .", "citeRegEx": "Yin et al\\.,? 2015a", "shortCiteRegEx": "Yin et al\\.", "year": 2015}, {"title": "Neural enquirer: Learning to query tables with natural language", "author": ["Pengcheng Yin", "Zhengdong Lu", "Hang Li", "Ben Kao."], "venue": "arXiv preprint arXiv:1512.00965 .", "citeRegEx": "Yin et al\\.,? 2015b", "shortCiteRegEx": "Yin et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 16, "context": "On the other hand, the retrieved table could be used as the input for question answering (Pasupat and Liang, 2015).", "startOffset": 89, "endOffset": 114}, {"referenceID": 3, "context": "Unlike existing studies in database community (Cafarella et al., 2008; Balakrishnan et al., 2015) that utilize surrounding text of a table or pagerank score of a web page, we focus on making a thorough exploration of table content in this work.", "startOffset": 46, "endOffset": 97}, {"referenceID": 1, "context": "Unlike existing studies in database community (Cafarella et al., 2008; Balakrishnan et al., 2015) that utilize surrounding text of a table or pagerank score of a web page, we focus on making a thorough exploration of table content in this work.", "startOffset": 46, "endOffset": 97}, {"referenceID": 16, "context": "We conduct comprehensive experiments on two datasets, a real world dataset introduced by us, and a synthetic dataset WikiTableQuestions (Pasupat and Liang, 2015) which has been widely used for table-based question answering.", "startOffset": 136, "endOffset": 161}, {"referenceID": 2, "context": "Afterwards, we use LambdaMART (Burges, 2010), a successful algorithm for solving real world ranking problem, to get the final ranking score of each table.", "startOffset": 30, "endOffset": 44}, {"referenceID": 10, "context": "We use an existing SMT approach (Koehn et al., 2003) to extract a phrase table PT from a bilingual corpus.", "startOffset": 32, "endOffset": 52}, {"referenceID": 19, "context": "We use CDSSM (Shen et al., 2014), which has been successfully applied in text retrieval.", "startOffset": 13, "endOffset": 32}, {"referenceID": 7, "context": "We train model parameters on WikiAnswers dataset (Fader et al., 2013), which contains almost 12M question-similar question pairs.", "startOffset": 49, "endOffset": 69}, {"referenceID": 7, "context": "We train model parameters on WikiAnswers dataset (Fader et al., 2013), which contains almost 12M question-similar question pairs. In addition, since vector average is an intuitive way to compute sentence vector and does not induce additional parameters, we calculate another relevance score by representing a query and a table aspect with element-wise vector average. We use a publicly available word embedding which is released by Mikolov et al. (2013).", "startOffset": 50, "endOffset": 454}, {"referenceID": 4, "context": "To avoid the problem of gradient vanishing, we use gated recurrent unit (GRU) (Cho et al., 2014) as the basic computation unit, which adaptively forgets the history and remembers the input, and has proven to be effective in sequence modeling (Chung et al.", "startOffset": 78, "endOffset": 96}, {"referenceID": 5, "context": ", 2014) as the basic computation unit, which adaptively forgets the history and remembers the input, and has proven to be effective in sequence modeling (Chung et al., 2014).", "startOffset": 153, "endOffset": 173}, {"referenceID": 22, "context": "An important property of a table is that randomly exchanging two rows or tow columns will not change the meaning of a table (Vinyals et al., 2015).", "startOffset": 124, "endOffset": 146}, {"referenceID": 0, "context": "Afterwards, a query-specific header vector is obtained through weighted average (Bahdanau et al., 2015; Sukhbaatar et al., 2015), namely vheader = \u2211k i=1 \u03b1imi, where \u03b1i \u2208 [0, 1] is the weight of mi calculated as below and \u2211 i \u03b1i = 1.", "startOffset": 80, "endOffset": 128}, {"referenceID": 20, "context": "Afterwards, a query-specific header vector is obtained through weighted average (Bahdanau et al., 2015; Sukhbaatar et al., 2015), namely vheader = \u2211k i=1 \u03b1imi, where \u03b1i \u2208 [0, 1] is the weight of mi calculated as below and \u2211 i \u03b1i = 1.", "startOffset": 80, "endOffset": 128}, {"referenceID": 25, "context": "Similar techniques have been successfully applied in table-based question answering (Yin et al., 2015b; Neelakantan et al., 2015).", "startOffset": 84, "endOffset": 129}, {"referenceID": 15, "context": "Similar techniques have been successfully applied in table-based question answering (Yin et al., 2015b; Neelakantan et al., 2015).", "startOffset": 84, "endOffset": 129}, {"referenceID": 16, "context": "We also conduct a synthetic experiment for table retrieval on WikiTableQuestions (Pasupat and Liang, 2015), which is a widely used dataset for table-based question answering.", "startOffset": 81, "endOffset": 106}, {"referenceID": 21, "context": "The second baseline is header grounding, which is partly inspired by Venetis et al. (2011) who show the effectiveness of the semantic relationship between query and table header.", "startOffset": 69, "endOffset": 91}, {"referenceID": 19, "context": "CDSSM (Shen et al., 2014) approach to match between a table header and a query.", "startOffset": 6, "endOffset": 25}, {"referenceID": 9, "context": ", 2012), assembling a table from list in web page (Gupta and Sarawagi, 2009) and extracting tables using tabular structure from web page (Gatterbauer et al.", "startOffset": 50, "endOffset": 76}, {"referenceID": 8, "context": ", 2012), assembling a table from list in web page (Gupta and Sarawagi, 2009) and extracting tables using tabular structure from web page (Gatterbauer et al., 2007).", "startOffset": 137, "endOffset": 163}, {"referenceID": 3, "context": "A representative work is given by Cafarella et al. (2008), which considers table search as a special case of document search task and represent a table with its surrounding text and page title.", "startOffset": 34, "endOffset": 58}, {"referenceID": 3, "context": "A representative work is given by Cafarella et al. (2008), which considers table search as a special case of document search task and represent a table with its surrounding text and page title. Limaye et al. (2010) use YAGO ontology to annotate tables with column and relationship labels.", "startOffset": 34, "endOffset": 215}, {"referenceID": 3, "context": "A representative work is given by Cafarella et al. (2008), which considers table search as a special case of document search task and represent a table with its surrounding text and page title. Limaye et al. (2010) use YAGO ontology to annotate tables with column and relationship labels. Venetis et al. (2011) go one step further and use labels and relationships extracted from the web.", "startOffset": 34, "endOffset": 311}, {"referenceID": 3, "context": "A representative work is given by Cafarella et al. (2008), which considers table search as a special case of document search task and represent a table with its surrounding text and page title. Limaye et al. (2010) use YAGO ontology to annotate tables with column and relationship labels. Venetis et al. (2011) go one step further and use labels and relationships extracted from the web. Pimplikar and Sarawagi (2012) focus on the queries that describe table columns, and retrieve tables based on column mapping.", "startOffset": 34, "endOffset": 418}, {"referenceID": 13, "context": "For example, Neelakantan et al. (2015); Yin et al.", "startOffset": 13, "endOffset": 39}, {"referenceID": 13, "context": "For example, Neelakantan et al. (2015); Yin et al. (2015b) develop neural operator on the basis of table representation and apply the model to question answering.", "startOffset": 13, "endOffset": 59}, {"referenceID": 13, "context": "For example, Neelakantan et al. (2015); Yin et al. (2015b) develop neural operator on the basis of table representation and apply the model to question answering. Yin et al. (2015a) introduce a KB-enhanced sequenceto-sequence approach that generates natural language answers to simple factoid questions based on facts from KB.", "startOffset": 13, "endOffset": 182}, {"referenceID": 12, "context": "Mei et al. (2016) develop a LSTM based recurrent neural network to generate natural language weather forecast and sportscasting commentary from database records.", "startOffset": 0, "endOffset": 18}, {"referenceID": 12, "context": "Mei et al. (2016) develop a LSTM based recurrent neural network to generate natural language weather forecast and sportscasting commentary from database records. Serban et al. (2016) introduce a recurrent neural network approach, which takes fact representation as input and generates factoid question from a fact from Freebase.", "startOffset": 0, "endOffset": 183}, {"referenceID": 11, "context": "Lebret et al. (2016) presented an neural language model that generates biographical sentences from Wikipedia infobox.", "startOffset": 0, "endOffset": 21}, {"referenceID": 0, "context": "Our neural network approach relates to the recent advances of attention mechanism and reasoning over external memory in artificial intelligence (Bahdanau et al., 2015; Sukhbaatar et al., 2015; Graves et al., 2016).", "startOffset": 144, "endOffset": 213}, {"referenceID": 20, "context": "Our neural network approach relates to the recent advances of attention mechanism and reasoning over external memory in artificial intelligence (Bahdanau et al., 2015; Sukhbaatar et al., 2015; Graves et al., 2016).", "startOffset": 144, "endOffset": 213}, {"referenceID": 23, "context": "The memory could be addressed by a \u201csoft\u201d attention mechanism trainable by standard backpropagation methods or a \u201chard\u201d attention mechanism trainable by REINFORCE (Williams, 1992).", "startOffset": 163, "endOffset": 179}, {"referenceID": 0, "context": "In this work, we use the soft attention mechanism, which could be easily optimized and has been successfully applied in nlp tasks (Bahdanau et al., 2015; Sukhbaatar et al., 2015).", "startOffset": 130, "endOffset": 178}, {"referenceID": 20, "context": "In this work, we use the soft attention mechanism, which could be easily optimized and has been successfully applied in nlp tasks (Bahdanau et al., 2015; Sukhbaatar et al., 2015).", "startOffset": 130, "endOffset": 178}], "year": 2017, "abstractText": "Understanding the connections between unstructured text and semi-structured table is an important yet neglected problem in natural language processing. In this work, we focus on content-based table retrieval. Given a query, the task is to find the most relevant table from a collection of tables. Further progress towards improving this area requires powerful models of semantic matching and richer training and evaluation resources. To remedy this, we present a ranking based approach, and implement both carefully designed features and neural network architectures to measure the relevance between a query and the content of a table. Furthermore, we release an open-domain dataset that includes 21,113 web queries for 273,816 tables. We conduct comprehensive experiments on both real world and synthetic datasets. Results verify the effectiveness of our approach and present the challenges for this task.", "creator": "LaTeX with hyperref package"}}}