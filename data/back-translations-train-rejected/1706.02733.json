{"id": "1706.02733", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2017", "title": "Climbing a shaky ladder: Better adaptive risk estimation", "abstract": "We revisit the \\emph{leaderboard problem} introduced by Blum and Hardt (2015) in an effort to reduce overfitting in machine learning benchmarks. We show that a randomized version of their Ladder algorithm achieves leaderboard error O(1/n^{0.4}) compared with the previous best rate of O(1/n^{1/3}).", "histories": [["v1", "Thu, 8 Jun 2017 18:48:38 GMT  (57kb,D)", "http://arxiv.org/abs/1706.02733v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["moritz hardt"], "accepted": false, "id": "1706.02733"}, "pdf": {"name": "1706.02733.pdf", "metadata": {"source": "CRF", "title": "Climbing a shaky ladder: Better adaptive risk estimation", "authors": ["Moritz Hardt"], "emails": [], "sections": [{"heading": null, "text": "Without proving that our algorithm is optimal, we point to a major obstacle to further progress. In particular, any improvement in our upper limit would lead to asymptotic improvements in the general adaptive estimation framework that have remained elusive in recent years. This link also leads directly to lower limits for certain classes of algorithms. In particular, we show a new attack on the ranking algorithm that distinguishes both theoretically and empirically between our algorithm and previous ranking algorithms."}, {"heading": "1 Introduction", "text": "This feedback loop has become the de facto experimental paradigm in machine learning. Worryingly, the analyst uses the holdout in a sequential and adaptive way, creating dependencies between the model to be evaluated and the holdout data. It is the lack of independence between the model and the holdout data that overrides classical confidence limits for the holdout setting, an insight that has been articulated in a succession of papers on what is now called adaptive data analysis [DFH + 1, HU, DFH + 2]. In general terms, adaptive data analysis can be seen as an interaction between an algorithm that holds the sample and an analyst who repeatedly asks questions about the data, such as \"What is the loss of this model on the underlying population?\""}, {"heading": "1.1 Our contributions", "text": "We narrow the gap between the existing upper and lower limits. Our first result is a randomized variant of the conductor algorithm called the Shaky Ladder, which has the ranking error O (1 / n0.4). (1 / n0.4) The first result is a random variant of the conductor algorithm. (1 / 2) The Shaky Ladder is highly likely to achieve a ranking errorO (log (k) 2 / 5 log (kn) 1 / 5n2 / 5). The algorithm is based on noise analysis in addition to differential privacy, in particular the so-called sparse vector technique described in [DR]. We combine this analysis with a strong adaptive generalization for differential privacy, where it is important to use the recently improved limit of Bassily et al. [BNS +] The former limit due to Dwork et al. [DFH + 1] would not be enough to achieve an improvement over the ranking error."}, {"heading": "1.2 Preliminaries", "text": "Let X be a data domain and Y be a finite series of class identifiers, e.g. X = Rd and Y = {0,1}. A loss function is a figure \": Y \u00b7 Y \u2192 [0,1] and a model is a figure f: X \u2192 Y. A default error function is the 0 / 1 loss, which is defined as\" 01 (y, y \") = 1 if y, y\" and 0 otherwise. In this paper we assume that it is a loss function with limited range. We assume that we have a sample S = {(x1, y1),. (xn, yn)} drawn by an unknown distribution D over X \u00d7 Y. The risk of a model f is its expected loss on the unknown distribution RD (f) def = E (x, y)."}, {"heading": "2 The Shaky Ladder algorithm", "text": "\"We are introducing an algorithm called the Shaky Ladder, which achieves small scale accuracy, the algorithm is very simple, it compares the empirical risk of the function with the previously lowest empirical risk plus some perturbations. If the estimate is below the previous best value, it releases the estimate plus noise and updates the best estimate. Importantly, we know an upper limit for the total number of environments. We are introducing a new parameter \u03b2 > 0 for the failure probability of our algorithm. For the purpose of our analysis, we fix the parameters as follows:"}, {"heading": "Pr {G} > 1\u2212O(k\u03b4/\u03b5)\u2212 \u03b2 > 1\u2212O(\u03b2) .", "text": "Here we used the definition of \u03b4 and the fact that \u03b5 > 1 / n.Starting from the condition that G occurs, we can connect our parameter settings from Eq.2 to check whether lberr (R1,..., Rk) 6 18\u03b5 \u221a B + \u03bb + 2L 6O (log (k / \u03b2) 2 / 5 log (kn / \u03b2) 1 / 5n2 / 5).By recalculating \u03b2 to eliminate the constant before the error probability limit, the limit claimed in the theorem is determined."}, {"heading": "3 Connection to general adaptive estimation", "text": "In the general adaptive estimation setting, the adaptive analyst selects a sequence of limited functions g1,.., gk: X \u2192 [0,1] commonly referred to as queries. The algorithm must select estimates a1,.., ak in an online manner that each estimate is close to population expectation ED gk. We refer to algorithms in this setting as general adaptive estimators to distinguish them from ranking algorithms that we have examined earlier. The following definition of accuracy is common in literacy 3.1. We say that a general adaptive estimator is B (\u03b1, \u03b2) -precise on n samples and k-questions if for each distribution over X, given n samples from the distribution and adaptively selected queries g1,., gk: X \u2192 the algorithms B give estimates a1,., ak."}, {"heading": "3.1 Lower bounds for faithful algorithms", "text": "In this section, we prove to be a lower risk of a natural class of ranking algorithms that we call faithful. It includes both algorithms proposed by Blum and Hardt, which proceed from the ladder and the parameter-free ladder algorithm. - Both of these algorithms are deterministic, but the class of faithful algorithms also includes many natural randomization schemes. - Definition: A ranking algorithm is applicable if a sample S is the size n for each adaptively chosen sequence of models f1,., fk its estimates (R1,., Rk) satisfaction with probability 2 / 3 for all 1 < t < Rt \u2212 1, we also have an exact sequence of models f1,. - In words, those who update the algorithms, i.e., Rt < Rt \u2212 1, the new estimate is likely to be close to the empirical risk of the model."}, {"heading": "4 Experiments with a shifted majority attack", "text": "The attack implicit in Corollary 3.12 corresponds to what we will call the postponed majority problem. To understand the idea, we briefly review the boosting attack of [BH]. In this procedure, the analyst first asks k random queries (thought to be vectors in {0,1} n, a binary label for every point in the holdout group), and then selects those that have errors (0 / 1 loss) less than 1 / 2. Note that the expected loss is 1 / 2. Among these selected queries, the analyst calculates a coordinated majority vote, resulting in a final output vector y. [0,1} n Ladum and Hardt observed that this output vector expected an error 1 / 2 \u2212. Regarding the true holdout labels y [0,1} n. Despite the fact that the vector setup is a slight simplification of the actual formal framework, we have replaced this idea by random vectors."}, {"heading": "5 Conclusion and open problems", "text": "We saw a new algorithm with the ranking error O (n \u2212 0.4). This upper limit is strictly between the two more natural limits O (n \u2212 1 / 3) and O (n \u2212 1 / 2). If the experience of online and bandit learning is any guide, the new upper limit may indicate that there is hope of achieving the narrower error rate O (n \u2212 1 / 2). This possibility is also supported by the fact that the majority attack we saw in Section 4 is quite sensitive to noise of the order O (n \u2212 1 / 2), which leads us to suspect that O (n \u2212 1 / 2) may actually be the right answer. However, given our connection between the general setting of the adaptive estimate and ranking error, such a guess can now be disproved by stronger lower limits for the general adjustment setting. It is unclear whether more complex lower limit techniques based on fingerprint query, such as those used in the [HSU] could be used to lower the number of [U] s."}, {"heading": "Acknowledgments", "text": "Many thanks to Avrim Blum, Yair Carmon, Roy Frostig and Tomer Koren for their insightful observations and suggestions at various stages of this work."}, {"heading": "A Anti-concentration inequality for the Binomial distribution", "text": "Say A.1. Let's say 0 < \u03b5 6 1 / \u221a m. Then Pr {Binomial (m, 1 / 2 + \u03b5) > m / 2} > 1 2 + 3 (\u221a m\u03b5) \u2212 O (1 / \u221a m).Proof. Set p = 1 / 2 + \u03b5 and q = 1 \u2212 P. On the one hand, the Berry-Esseen theorem for the given upper limit implies the normal approximation Pr {N (m, 1 / 2 + \u03b5) > m / 2} > Pr {N (mp, mpq) > mp \u2212 \u03b5m} \u2212 O (1 / \u221a m) for the given upper limit. On the other hand, Pr {N (mp, mpq) > mp \u2212 \u03b5m} = Pr {N (0, pq) > \u2212 \u03b5 \u00b2 m} > 1 2 + 3 (\u03b5, mpq) m >"}, {"heading": "B Reference implementation for majority attack", "text": "For definition, we include a reference implementation of the majority attack used in our experiments.1 numpy was imported as np 2 3 def majority _ attack (n, k, sigma = None): 4 \"\" Run majority attack and report resulting bias \"\" 5 hidden _ vector = 2.0 * np.random.randint (0, 2, n) - 1.0 6 queries = 2.0 * np.random.randint (0, 2, (k, n)) - 1.0 7 answers = queries.dot (hidden _ vector) / n 8 if sigma: 9 answers + = np.random.normal (0, sigma, k) 10 positive = queries [answers > 0.,:] 11 negative = queries [answers < = 0.,:] 12 weighted = np.vstack ([positive, -1.0 * negative])) 13 weighted = weighted d.T.dot (n.pones (final) (14 k =.none)."}], "references": [{"title": "The Ladder: A reliable leaderboard for machine learning competitions", "author": ["BH] Avrim Blum", "Moritz Hardt"], "venue": "In Proc. 32nd ICML,", "citeRegEx": "Blum and Hardt.,? \\Q2015\\E", "shortCiteRegEx": "Blum and Hardt.", "year": 2015}, {"title": "Algorithmic stability for adaptive data analysis", "author": ["BNS+] Raef Bassily", "Kobbi Nissim", "Adam D. Smith", "Thomas Steinke", "Uri Stemmer", "Jonathan Ullman"], "venue": "In Proc. 48th STOC,", "citeRegEx": "Bassily et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bassily et al\\.", "year": 2016}, {"title": "Preserving validity in adaptive data analysis", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth"], "venue": "In Proc. 47th STOC,", "citeRegEx": "Dwork et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2015}, {"title": "The reusable holdout: Preserving validity in adaptive data analysis", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth"], "venue": null, "citeRegEx": "Dwork et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2015}, {"title": "The algorithmic foundations of differential privacy", "author": ["Cynthia Dwork", "Aaron Roth"], "venue": "Foundations and Trends in Theoretical Computer Science,", "citeRegEx": "Dwork and Roth.,? \\Q2014\\E", "shortCiteRegEx": "Dwork and Roth.", "year": 2014}, {"title": "Preventing false discovery in interactive data analysis is hard", "author": ["HU] Moritz Hardt", "Jonathan Ullman"], "venue": "In Proc. 55th FOCS,", "citeRegEx": "Hardt and Ullman.,? \\Q2014\\E", "shortCiteRegEx": "Hardt and Ullman.", "year": 2014}, {"title": "Reducing overfitting in challenge-based competitions", "author": ["Elias Chaibub Neto", "Bruce R Hoff", "Chris Bare", "Brian M Bot", "Thomas Yu", "Lara Magravite", "Andrew D Trister", "Thea Norman", "Pablo Meyer", "Julio Saez-Rodrigues", "James C Costello", "Justin Guinney", "Gustavo Stolovitzky"], "venue": null, "citeRegEx": "Neto et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Neto et al\\.", "year": 2016}, {"title": "Interactive fingerprinting codes and the hardness of preventing false discovery", "author": ["SU] Thomas Steinke", "Jonathan Ullman"], "venue": "CoRR, abs/1410.1228,", "citeRegEx": "Steinke and Ullman.,? \\Q2014\\E", "shortCiteRegEx": "Steinke and Ullman.", "year": 2014}, {"title": "A minimax theory for adaptive data analysis", "author": ["WLF] Yu-Xiang Wang", "Jing Lei", "Stephen E. Fienberg"], "venue": "CoRR, abs/1602.04287,", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Abstract We revisit the leaderboard problem introduced by Blum and Hardt (2015) in an effort to reduce overfitting in machine learning benchmarks.", "startOffset": 58, "endOffset": 80}], "year": 2017, "abstractText": "We revisit the leaderboard problem introduced by Blum and Hardt (2015) in an effort to reduce overfitting in machine learning benchmarks. We show that a randomized version of their Ladder algorithm achieves leaderboard error O(1/n0.4) compared with the previous best rate of O(1/n1/3). Short of proving that our algorithm is optimal, we point out a major obstacle toward further progress. Specifically, any improvement to our upper bound would lead to asymptotic improvements in the general adaptive estimation setting as have remained elusive in recent years. This connection also directly leads to lower bounds for specific classes of algorithms. In particular, we exhibit a new attack on the leaderboard algorithm that both theoretically and empirically distinguishes between our algorithm and previous leaderboard algorithms.", "creator": "LaTeX with hyperref package"}}}