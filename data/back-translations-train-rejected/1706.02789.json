{"id": "1706.02789", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2017", "title": "On the Development of Intelligent Agents for MOBA Games", "abstract": "Multiplayer Online Battle Arena (MOBA) is one of the most played game genres nowadays. With the increasing growth of this genre, it becomes necessary to develop effective intelligent agents to play alongside or against human players. In this paper we address the problem of agent development for MOBA games. We implement a two-layered architecture agent that handles both navigation and game mechanics. This architecture relies on the use of Influence Maps, a widely used approach for tactical analysis. Several experiments were performed using {\\em League of Legends} as a testbed, and show promising results in this highly dynamic real-time context.", "histories": [["v1", "Thu, 8 Jun 2017 23:20:34 GMT  (1089kb,D)", "http://arxiv.org/abs/1706.02789v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["victor do nascimento silva", "luiz chaimowicz"], "accepted": false, "id": "1706.02789"}, "pdf": {"name": "1706.02789.pdf", "metadata": {"source": "CRF", "title": "On the Development of Intelligent Agents for MOBA Games", "authors": ["Victor do Nascimento", "Luiz Chaimowicz"], "emails": ["vnsilva@dcc.ufmg.br", "chaimo@dcc.ufmg.br"], "sections": [{"heading": null, "text": "Multiplayer Online Battle Arena (MOBA) is now one of the most widely played game genres. As this genre grows, it becomes necessary to develop effective intelligent agents that can play alongside or against human players. In this article, we address the problem of agent development for MOBA games. We implement a two-layer architecture agent that controls both navigation and game mechanics, based on the use of Influence Maps, a widely used approach to tactical analysis. Several experiments have been conducted using League of Legends as a testbed and show promising results in this highly dynamic real-time context. Tags: Multiplayer Online Battle Arena, Influence Maps, TacticsAuthor's Contact: {vnsilva, chaimo} @ dcc.ufmg.br"}, {"heading": "1 Introduction", "text": "The development of motion systems is still a challenge for the game, especially when dealing with competitive and combat scenarios."}, {"heading": "2 Background", "text": "Research in games requires the collection of information about the domain to be used as a guide for the research and experiments to be developed. A game consists of a set of rules during its implementation as well as profit or loss criteria. Therefore, understanding these characteristics is crucial for the implementation of agents, data and results. In this section we present considerable knowledge about techniques used in our research. In addition, we present the characteristics of the MOBA domain."}, {"heading": "2.1 Influence Maps and Potential Fields", "text": "The most common method is to dissect the playing card into pieces and try to perform some kind of feature analysis in these parts [Millington and Funge 2012]. The static and dynamic analysis of the environment can help us behave in an intelligent way. Also, the problem of coordination of agents in a tactical way is not new. From the work of [Reynolds 1987] we can observe the necessity of environmental analysis when we consider the environment and other agents when we move in a flock. Potential Fields (PF), a technique that originated in the field of robotics, attempts to perform such analyses as are presented by the drivers."}, {"heading": "2.2 MOBA Games", "text": "In recent years, the popularity of real-time strategy has grown considerably, creating a community of players interested in producing new content for such games, commonly referred to as Modders, after the acronym for modifiers that refer to alternative game modes as modifications or \"mods,\" among whom there was Aeon of Strife (AoS), the first MOBA like the game that emerged as the Starcraft Model. After the popularity of AoS, modders used the Warcraft III engine to create a similar game mode and name, it was Defense of the Ancients (AoS). DotA's cards became popular among players, and there were many versions around them. Their playing style was widely known that every other game that was referred to as \"DotA like Game.\" The term MOBA was first observed in 2009 with the debut title League of Legends, which Riot Games used to describe their game."}, {"heading": "2.3 MOBA agents", "text": "In fact, most of them will be able to play by the rules they have set themselves in order to play by the rules."}, {"heading": "2.4 League of Legends", "text": "In fact, most people who are able, are able, are able to protect themselves, are able to save themselves, and they are not able to save themselves."}, {"heading": "3 Agent Architecture", "text": "The use of a heterogeneous agent architecture seems to be reliable for the MOBA domain. Due to the manifold tasks such as construction, navigation, collaboration and combat, it is possible to use the heterogeneous architecture to implement a multitasking agent. Our agent connects to LoL through the use of sensors that collect data about the world. The agent can also send actions to the hero that he can perform by modifying the game environment with its actors, e.g. attack.League of Legends has an application programming interface called Bot of Legends (BoL). BoL retrieves information about the game and performs the same actions as the players. This tool is very similar to the Brood War API, which is used predominantly in Starcraft research. Both tools have the same premise: they collect information available to the players, and merely execute actions that are available to the players. The agent consists of two layers: navigation and micromanagement, which is our primary way to develop the agent, and the agent could be implemented in a MOBA way."}, {"heading": "3.1 Navigation Layer", "text": "The basis of our agent is the modeling of the collected information to valuable information that can be used by all levels. Thus, we have inserted a series of handwritten knowledge and data in real time. Furthermore, we model the collected and handwritten data using a grid-formatted impact map. A visual representation of our model is shown in Figure 2. The impact map feeds the navigation layer that uses a case-based argumentation system (CBR). This layer searches for the best points taking into account the terrain, dynamic and static characteristics from the domain. The impact map uses a layer with the aim to improve the performance of the agent. IM models the knowledge of all actors involved in the MOBA domain. We use mathematical functions to create a single value base for the weight of individuals, whereby a 2D grid with deceptive values is generated. The IM models the knowledge of all actors involved in the MOBA domain."}, {"heading": "3.1.1 Enemy Towers", "text": "When we analyze the towers, we generally see that they can assume two states: idle or aggressive. At idle, the tower does not take any action, but checks if there are enemies within its range that can be attacked. As soon as an enemy enters the tower area, it is attacked. In addition, a tower can only attack one enemy at a time and does not cause Area Effects (AoE). Once the tower selects a target, it will not change unless it comes first in the preferences list. In some MOBAs, such as Dota or Dota2, the tower prefers the next enemy, so players try to stay after their crawls."}, {"heading": "3.1.2 Enemy Creeps", "text": "Enemy creeps are the main resource collection approach for agents and players. Each time a player kills an enemy creeper, the player receives gold and experience. Therefore, there must be a careful analysis of these components, as they can change the game. Correct positioning around these units allows the agent to execute the last hit, and since these units are highly dynamic, they must be observed most constantly. In calculating the creep impact, we use the logic proposed by [Hagelba \u00fcck and Johansson 2008a]: Movement and Micromanagement. In this section, we discuss motion analysis; micromanagement is discussed further in Section 3.1.To calculate the influence of enemy creep movements, we use the logic proposed by [Hagelba \u00fcck and Johansson 2008a], by keeping the enemy as far away as possible, but still keeping him within hero range. Likewise, as discussed in the Enemy Tower section, we must take into account resolution losses by making a plateau possible in our warfare."}, {"heading": "3.1.3 Ally Towers", "text": "When weighing towers, we find that it is very defensive to be within the reach of one's own team towers, but for this defense to be effective, the agent should be in a safe area. For example, the agent should be within the reach of an allied tower and out of the reach of enemy heroes. However, the safe area is very difficult to abstract due3Farming is the action of collecting resources by executing last hits in enemy or neutral crawls. Another point to keep in mind is that the player should avoid collisions with towers, as this could lead to time wasted navigation. In addition, there are champions in various MOBAs that can take advantage of the hero's proximity to the tower. We then developed an influence equation for allied towers based on these characteristics. The equation provides the tower with a linear decay of influence, whereby its best places are in its vicinity and the worst are far from the tower. In order to avoid the collision between a specific tower and a player being trapped by a specific tower's distance from the max and by a specific tower's distance."}, {"heading": "3.1.4 Heroes", "text": "Heroes are the most dynamic units in the MOBA gameplay, they can generally move faster than reptiles and also execute spells and attacks. These units require more attention when performing tactical analyses in the MOBA area, as they have the high potential to change the tactical landscape of the game. We navigate heavily based on our allied heroes and try to avoid enemy damage. In our early research phase, we implemented the sphere of influence based on the heroes \"self-attack range. This proved to be a poor choice for two main reasons: (a) melee heroes have a small range, but they can cast spells and continue to do damage, and (b) there are heroes who have a smaller range but a high spell range. Therefore, we had to compile a handwritten knowledge database of all 126 heroes in League of Legends. This database informed our agent of the distance that can be considered the current hero range, and in addition to the highly dynamic spells we collect over real-time, it will allow the agents to greatly influence the highly-fiber information it."}, {"heading": "3.2 Combining influences", "text": "It is necessary to combine these influences in order to shift them to the underlying plane."}, {"heading": "3.3 Micromanagement Layer", "text": "In addition to a movement layer, it is necessary to implement a layer that is responsible for coordinating the abilities and attacks of the hero. In our approach, where we want to develop a generic technique, we do not focus on skills, but first on simple car attacks. In the next sections, we will discuss the techniques used in the micromanagement layer."}, {"heading": "3.3.1 Orbwalking and Kiting", "text": "A very useful mechanism in game scenarios is meeting and running, especially when the coordinated unit has a higher range than the enemy unit, this is called kiting. Human players very often perform this type of mechanism aimed at maximizing the damage inflicted on enemies in both RTS and MOBA games. In addition, this is an essential technique for damage-based carriers and for any agent aiming to farm in MOBA. There is an algorithm called Orbwalker, which is responsible for informing when it is possible to attack or move, very similar to the approach presented by [Uriarte and Ontan in 2012]. However, the orbwalking algorithm does not perform tactical analysis; therefore, another scenario analysis is necessary when the attack and escape mechanics are executed. In our approach, we have not implemented the kiting algorithm as proposed by Uriarte [in 2012 and 2012]."}, {"heading": "3.3.2 Target Selection", "text": "The problem of target selection is an open challenge in most strategic games, including RTS and MOBA. The work of [Hagelba \ufffd ck and Johansson 2008a] deals with this problem at a very early tactical approach. Later, [Uriarte and Ontan, o \"n 2012] discuss this problem in great detail by assigning tactical values for each enemy based on their distance, manually assigned tactical threat, and DPS. They show that it is an essential part of tactical behavior to select the right enemy for an attack. [Liu et al. 2014] presents an automatic approach to target selection using genetic algorithms. However, their concept of target selection, while still tactical, shows a different concept from [Uriarte and Ontan, o\" n 2012]. Instead of using tactical values or DPS, they only look at the health points of each nearby enemy for target selection. In our approach, we collect data and combine them with negotiable content by analyzing the target selection unit."}, {"heading": "4 Empirical Evaluation", "text": "To evaluate our approach, we conducted three League of Legends experiments: The first experiment tests the effectiveness of our agent by testing whether he is able to win in a scenario where he plays alone; the second, we test the efficiency of this agent by measuring his performance in terms of resource collection; and the third, we test the agent's performance in a match against human players. These experiments and their results will be discussed in the next sub-sections."}, {"heading": "4.1 Experiment 1: Winning alone in MOBA", "text": "In this experiment, we run the agent in a scenario in which he finds himself in a match without allies or enemy heroes. This experiment shows the effectiveness of the agent and the success of the sequence of steps that are presented to win in a MOBA game. Our starting point is the work of [Willich 2015], but we were not able to replicate the authoring experiments, because the code is not available. In addition, the author uses HoN as the game domain, while in this work we use LoL as a testbed.For this experiment, we use a map on which there is only one track. In [Willich 2015], the author uses a similar approach, although they use a three-track map, but consider only one. We performed 20 games with a hero who was randomly selected from the LoL master pool. Our agent was able to win all the games. In addition, our agent always showed a KDA factor of 0, which means that he never died and had no error, which we monitored for the 22.5 minutes of the local time the agent was able to win."}, {"heading": "4.2 Experiment 2: Resource Collection", "text": "Resource collection in the MOBA differs from RTS in that it is carried out by killing enemy or neutral reptiles, champions and structures. Furthermore, it is important to maximize resource collection. In this test, we first perform our approach without the \u03c6 variable, which represents the health of reptiles. Then, we compare the performance of the collected resources with the approach with \u03c6. In the MOBA community, there is common sense that the best farm evaluation, as it is carried out by professional players, is to hit last 10 creep movements per minute, we use this sense as a starting point. we first performed 10 matches with the agent using the \u03c6 variable to improve positioning and resource collection, then 10 matches without using the \u03c6 variable. The tests were carried out under the same conditions of Experiment 1, a single-track map without enemy heroes. Our experiments with the health factor show an average of 92.24% efficiency in agriculture (see table 1, which is able to collect resources efficiently)."}, {"heading": "4.3 Experiment 3: Evaluation Against Human Players", "text": "In this mode, the card has only one track and all heroes are randomly selected for players who have the chance to swap them between allies during the Hero Selection Phase. This mode also offers more gold at the start of the fight and the heroes start at level three instead of level one. We have conducted 10 fights in ARAM Mode for evaluation and collected the Hero Performance and Gains / Losses from our Agent. We observe that when playing melee characters, performance is greatly affected and performs much worse than when playing combat heroes. The hero shows a high number of deaths when playing melee masters. In ranking champions, he shows low mortality levels but not a high number of kills. In melee as well as melee combat, our Agent shows a high number of assists, showing that he helps other players obtain kills. Despite the support characteristics, it is not possible to say that he behaves cooperatively in a combat game, behaves fastest in melee combat, or in a way that our Agent is able, or in a manner that is most similar to that of assistants."}, {"heading": "5 Conclusion and Future Work", "text": "In this work, we have presented an approach for tactical analysis and knowledge modelling in real-time scenarios, using influence maps as a promising approach. We implemented the game agent using a heterogeneous architecture consisting of two levels: navigation and micromanagement. Furthermore, our approach shows that it is possible and necessary to strongly link these levels, as illustrated by the parameters that combine movement and micromanagement towards resource collection. We also show that simple features, such as a health factor, can significantly increase the agent's performance. In addition, further tactical research is required in the MOBA area to behave well against humans. Finally, by combining heterogeneous controls, we have achieved kiting behavior. In previous research, this behavior required a dedicated module.One problem that can be addressed in future work is the competition of the current agent against human players."}, {"heading": "6 Acknowledgements", "text": "We would like to thank the BoL community, in particular Bilbao and Kenect, who supported us in developing the BoL environment, and the reviewers who provided insightful feedback and corrections to our article, which was supported by CAPES, CNPq and FAPEMIG."}], "references": [{"title": "Gamebots: A 3d virtual world test-bed for multi-agent research", "author": ["R. ADOBBATI", "A.N. MARSHALL", "A. SCHOLER", "S. TEJADA", "G.A. KAMINKA", "S. SCHAFFER", "C. SOLLITTO"], "venue": "Proceedings of the second international workshop on Infrastructure for Agents, MAS, and Scalable MAS, vol. 5, Montreal,", "citeRegEx": "ADOBBATI et al\\.,? 2001", "shortCiteRegEx": "ADOBBATI et al\\.", "year": 2001}, {"title": "Generating an attribute space for analyzing balance in single unit rts game combat", "author": ["S. BANGAY", "O. MAKIN"], "venue": "Computational Intelligence and Games (CIG), 2014 IEEE Conference on, IEEE, 1\u20138.", "citeRegEx": "BANGAY and MAKIN,? 2014", "shortCiteRegEx": "BANGAY and MAKIN", "year": 2014}, {"title": "Lay of the land: Smarter ai through influence maps", "author": ["A. CHAMPANDARD", "K. DILL", "D. ISLA"], "venue": "Game developers conference, vol. 2011.", "citeRegEx": "CHAMPANDARD et al\\.,? 2011", "shortCiteRegEx": "CHAMPANDARD et al\\.", "year": 2011}, {"title": "Winning the 2k bot prize with a long-term memory database using sqlite", "author": ["J. COTHRAN"], "venue": "Available on AiGameDev. com at http://aigamedev. com/open/articles/sqlite-bot.", "citeRegEx": "COTHRAN,? 2009", "shortCiteRegEx": "COTHRAN", "year": 2009}, {"title": "Most played games: May 2015 the witcher debuts, world of warcraft stumbles, June. http://caas.raptr.com/most-played-games-may-2015-thewitcher-debuts-world-of-warcraft-stumbles/ Raptr.com[Online; posted 26-June-2015", "author": ["A. DIAMARANAN"], "venue": null, "citeRegEx": "DIAMARANAN,? \\Q2015\\E", "shortCiteRegEx": "DIAMARANAN", "year": 2015}, {"title": "Skill-based differences in spatio-temporal team behaviour in defence of the ancients 2 (dota 2)", "author": ["A. DRACHEN", "M. YANCEY", "J. MAGUIRE", "D. CHU", "I.Y. WANG", "T. MAHLMANN", "M. SCHUBERT", "D. KLABAJAN"], "venue": "Games Media Entertainment (GEM), 2014 IEEE, IEEE, 1\u20138.", "citeRegEx": "DRACHEN et al\\.,? 2014", "shortCiteRegEx": "DRACHEN et al\\.", "year": 2014}, {"title": "From generative to conventional play: Moba and league of legends", "author": ["S. FERRARI"], "venue": "Proceedings of DiGRA 2013: DeFragging Game Studies, vol. 1, 1\u201317.", "citeRegEx": "FERRARI,? 2013", "shortCiteRegEx": "FERRARI", "year": 2013}, {"title": "The rise of potential fields in real time strategy bots", "author": ["J. HAGELB\u00c4CK", "S.J. JOHANSSON"], "venue": "AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment.", "citeRegEx": "HAGELB\u00c4CK and JOHANSSON,? 2008", "shortCiteRegEx": "HAGELB\u00c4CK and JOHANSSON", "year": 2008}, {"title": "Using multiagent potential fields in real-time strategy games", "author": ["J. HAGELB\u00c4CK", "S.J. JOHANSSON"], "venue": "Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems-Volume 2, International Foundation for Autonomous Agents and Multiagent Systems, 631\u2013638.", "citeRegEx": "HAGELB\u00c4CK and JOHANSSON,? 2008", "shortCiteRegEx": "HAGELB\u00c4CK and JOHANSSON", "year": 2008}, {"title": "Real-time obstacle avoidance for manipulators and mobile robots", "author": ["O. KHATIB"], "venue": "The international journal of robotics research 5, 1, 90\u201398.", "citeRegEx": "KHATIB,? 1986", "shortCiteRegEx": "KHATIB", "year": 1986}, {"title": "Evolving effective micro behaviors in rts game", "author": ["S. LIU", "S.J. LOUIS", "C. BALLINGER"], "venue": "Computational Intelligence and Games (CIG), 2014 IEEE Conference on, IEEE, 1\u20138.", "citeRegEx": "LIU et al\\.,? 2014", "shortCiteRegEx": "LIU et al\\.", "year": 2014}, {"title": "Artificial intelligence for games", "author": ["I. MILLINGTON", "J. FUNGE"], "venue": "CRC Press.", "citeRegEx": "MILLINGTON and FUNGE,? 2012", "shortCiteRegEx": "MILLINGTON and FUNGE", "year": 2012}, {"title": "General trends in multiplayer online games", "author": ["M. NOSRATI", "R. KARIMI", "M. HARIRI"], "venue": "World Applied Programming", "citeRegEx": "NOSRATI et al\\.,? 2013", "shortCiteRegEx": "NOSRATI et al\\.", "year": 2013}, {"title": "A survey of real-time strategy game ai research and competition in starcraft", "author": ["S. ONTAN\u00d3N", "G. SYNNAEVE", "A. URIARTE", "F. RICHOUX", "D. CHURCHILL", "M. PREUSS"], "venue": "Computational Intelligence and AI in Games, IEEE Transactions on 5, 4, 293\u2013311.", "citeRegEx": "ONTAN\u00d3N et al\\.,? 2013", "shortCiteRegEx": "ONTAN\u00d3N et al\\.", "year": 2013}, {"title": "On successful team formation: Statistical analysis of a multiplayer online game", "author": ["N. POBIEDINA", "J. NEIDHARDT", "M.D.C. CALATRAVA MORENO", "L. GRAD-GYENGE", "H. WERTHNER"], "venue": "Business Informatics (CBI), 2013 IEEE 15th Conference on, IEEE, 55\u201362.", "citeRegEx": "POBIEDINA et al\\.,? 2013", "shortCiteRegEx": "POBIEDINA et al\\.", "year": 2013}, {"title": "Flocks, herds and schools: A distributed behavioral model", "author": ["C.W. REYNOLDS"], "venue": "ACM Siggraph Computer Graphics, vol. 21, ACM, 25\u201334.", "citeRegEx": "REYNOLDS,? 1987", "shortCiteRegEx": "REYNOLDS", "year": 1987}, {"title": "Steering behaviors for autonomous characters", "author": ["C.W. REYNOLDS"], "venue": "Game developers conference, vol. 1999, 763\u2013782.", "citeRegEx": "REYNOLDS,? 1999", "shortCiteRegEx": "REYNOLDS", "year": 1999}, {"title": "Mining tracks of competitive video games", "author": ["F. RIOULT", "M\u00c9TIVIER", "J.-P.", "B. HELLEU", "N. SCELLES", "C. DURAND"], "venue": "AASRI Procedia 8, 82\u201387.", "citeRegEx": "RIOULT et al\\.,? 2014", "shortCiteRegEx": "RIOULT et al\\.", "year": 2014}, {"title": "Predicting army combat outcomes in starcraft", "author": ["M. STANESCU", "S.P. HERNANDEZ", "G. ERICKSON", "R. GREINER", "M. BURO"], "venue": "AIIDE.", "citeRegEx": "STANESCU et al\\.,? 2013", "shortCiteRegEx": "STANESCU et al\\.", "year": 2013}, {"title": "Evolving swarm intelligence for task allocation in a real time strategy game", "author": ["A.R. TAVARES", "H. AZP\u00daRUA", "L. CHAIMOWICZ"], "venue": "Computer Games and Digital Entertainment (SBGAMES), 2014 Brazilian Symposium on, IEEE, 99\u2013108.", "citeRegEx": "TAVARES et al\\.,? 2014", "shortCiteRegEx": "TAVARES et al\\.", "year": 2014}, {"title": "Influence mapping", "author": ["P. TOZOUR"], "venue": "Game programming gems 2, 287\u2013297.", "citeRegEx": "TOZOUR,? 2001", "shortCiteRegEx": "TOZOUR", "year": 2001}, {"title": "Kiting in rts games using influence maps", "author": ["A. URIARTE", "S. ONTA\u00d1\u00d3N"], "venue": "Eighth AAAI Artificial Intelligence and Interactive Digital Entertainment Conference.", "citeRegEx": "URIARTE and ONTA\u00d1\u00d3N,? 2012", "shortCiteRegEx": "URIARTE and ONTA\u00d1\u00d3N", "year": 2012}, {"title": "Building human-level ai for real-time strategy games", "author": ["B.G. WEBER", "M. MATEAS", "A. JHALA"], "venue": "AAAI Fall Symposium: Advances in Cognitive Systems, vol. 11, 01.", "citeRegEx": "WEBER et al\\.,? 2011", "shortCiteRegEx": "WEBER et al\\.", "year": 2011}, {"title": "Reinforcement Learning for Heroes of Newerth", "author": ["J. WILLICH"], "venue": "Bachelor thesis, Technische Universitat Darmstadt.", "citeRegEx": "WILLICH,? 2015", "shortCiteRegEx": "WILLICH", "year": 2015}, {"title": "Identifying patterns in combat that are predictive of success in MOBA games", "author": ["P. YANG", "B. HARRISON", "D.L. ROBERTS"], "venue": "Proceedings of Foundations of Digital Games.", "citeRegEx": "YANG et al\\.,? 2014", "shortCiteRegEx": "YANG et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Having a limited environment that can reproduce almost all characteristics of the real world helps the research to perform reliable tests [Adobbati et al. 2001].", "startOffset": 138, "endOffset": 160}, {"referenceID": 11, "context": "The most common technique is to divide the game map into chunks and try to perform some kind of feature analysis in these chunks [Millington and Funge 2012].", "startOffset": 129, "endOffset": 156}, {"referenceID": 15, "context": "From the work of [Reynolds 1987][Reynolds 1999], we can observe the necessity of environment analysis when driving agents.", "startOffset": 17, "endOffset": 32}, {"referenceID": 16, "context": "From the work of [Reynolds 1987][Reynolds 1999], we can observe the necessity of environment analysis when driving agents.", "startOffset": 32, "endOffset": 47}, {"referenceID": 9, "context": "Potential Fields (PF), a technique originally from Robotics area, tries to do such analyses, as presented by [Khatib 1986] in his approach for real-time obstacle avoidance and agent driving.", "startOffset": 109, "endOffset": 122}, {"referenceID": 11, "context": "In games, Influence Maps (IM) is one the main methods applied for tactical analysis of the features in a map [Millington and Funge 2012].", "startOffset": 109, "endOffset": 136}, {"referenceID": 20, "context": "A general definition of influence maps is presented in [Tozour 2001], which discusses its main concepts and advantages.", "startOffset": 55, "endOffset": 68}, {"referenceID": 9, "context": "But, in spite of having the same name of the technique used in robotics [Khatib 1986], the work of [Hagelb\u00e4ck and Johansson 2008b] divides the map in a grid, placing values over this grid that can be attractive or repulsive.", "startOffset": 72, "endOffset": 85}, {"referenceID": 2, "context": "Moreover, it turns IM into a versatile technique, as it can be used for both prediction and/or historical information just by performing parameter tuning [Champandard et al. 2011].", "startOffset": 154, "endOffset": 179}, {"referenceID": 19, "context": "The similarity of this kind of games to real-world problems is probably one of the main reasons for such research, as the solutions to these problems may be applied to various real-world scenarios [Tavares et al. 2014].", "startOffset": 197, "endOffset": 218}, {"referenceID": 3, "context": "This kind of agent is especially popular a in First Person Shooter (FPS) scenario, such as the 2kbotprize competition [Cothran 2009].", "startOffset": 118, "endOffset": 132}, {"referenceID": 22, "context": "The work presented by [Weber et al. 2011] develops an human-behaving agent for Starcraft.", "startOffset": 22, "endOffset": 41}, {"referenceID": 18, "context": "In general tactical analysis, we find the work of [Stanescu et al. 2013], in which the combat outcome is discussed in Starcraft.", "startOffset": 50, "endOffset": 72}, {"referenceID": 1, "context": "In the field of knowledge extraction and analysis, there is the work of [Bangay and Makin 2014], where the attributes are analysed in a RTS game and a framework for balance analysis is proposed.", "startOffset": 72, "endOffset": 95}, {"referenceID": 12, "context": "The works of [Nosrati et al. 2013] and [Rioult et al.", "startOffset": 13, "endOffset": 34}, {"referenceID": 17, "context": "2013] and [Rioult et al. 2014], for example, present a brief analysis of MOBA games, limited to features and specific characteristics.", "startOffset": 10, "endOffset": 30}, {"referenceID": 6, "context": "In the work of [Ferrari 2013] we find a deep analysis of League of Legends, discussed by various aspects like Game Design, e-Sport and basic MOBA characteristics.", "startOffset": 15, "endOffset": 29}, {"referenceID": 5, "context": "When analysing the gameplay and player abilities, is possible to find the work of [Drachen et al. 2014], where the spatio-temporal skill of players is analyzed, focused in data visualization and game-", "startOffset": 82, "endOffset": 103}, {"referenceID": 24, "context": "In the same research field, there is the work of [Yang et al. 2014] where, using Dota2 matches log, the team-fights are analysed and used to learn patterns.", "startOffset": 49, "endOffset": 67}, {"referenceID": 14, "context": "The work of [Pobiedina et al. 2013] performs a quantitative analysis of logs collected from Dota2, analyzing the relation between team formation and victories.", "startOffset": 12, "endOffset": 35}, {"referenceID": 23, "context": "Finally, the work of [Willich 2015], from our knowledge, is the only published work that addresses the problem of creating an agent for MOBA.", "startOffset": 21, "endOffset": 35}, {"referenceID": 20, "context": "As most games dedicates a few computation for AI, it is crucial to have cheap processing in this area [Tozour 2001].", "startOffset": 102, "endOffset": 115}, {"referenceID": 20, "context": "The initial propose of [Tozour 2001] is to store various influence map layers and then put them together.", "startOffset": 23, "endOffset": 36}, {"referenceID": 2, "context": "Moreover [Champandard et al. 2011] discusses that if an additional buffer is not used for influence mapping the values can be scattered in a non-desirable way.", "startOffset": 9, "endOffset": 34}, {"referenceID": 10, "context": "The work of [Liu et al. 2014] presents an automatic target selection approach using Genetic Algorithms.", "startOffset": 12, "endOffset": 29}, {"referenceID": 23, "context": "Our baseline is the work of [Willich 2015], however we were not capable of replicating the author experiments, as code is not available.", "startOffset": 28, "endOffset": 42}, {"referenceID": 23, "context": "In [Willich 2015] the author uses a similar approach, although they use a three-lane map but considers just one.", "startOffset": 3, "endOffset": 17}, {"referenceID": 19, "context": "Applying approaches of distributing tasks in games, like the presented in [Tavares et al. 2014], looks very promising when applied to the MOBA context, as this game genre is strongly oriented to player roles [Yang et al.", "startOffset": 74, "endOffset": 95}, {"referenceID": 24, "context": "2014], looks very promising when applied to the MOBA context, as this game genre is strongly oriented to player roles [Yang et al. 2014].", "startOffset": 118, "endOffset": 136}], "year": 2017, "abstractText": "Multiplayer Online Battle Arena (MOBA) is one of the most played game genres nowadays. With the increasing growth of this genre, it becomes necessary to develop effective intelligent agents to play alongside or against human players. In this paper we address the problem of agent development for MOBA games. We implement a two-layered architecture agent that handles both navigation and game mechanics. This architecture relies on the use of Influence Maps, a widely used approach for tactical analysis. Several experiments were performed using League of Legends as a testbed, and show promising results in this highly dynamic real-time context.", "creator": "LaTeX with hyperref package"}}}