{"id": "1706.02794", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2017", "title": "Rapid Randomized Restarts for Multi-Agent Path Finding Solvers", "abstract": "Multi-Agent Path Finding (MAPF) is an NP-hard problem well studied in artificial intelligence and robotics. It has many real-world applications for which existing MAPF solvers use various heuristics. However, these solvers are deterministic and perform poorly on \"hard\" instances typically characterized by many agents interfering with each other in a small region. In this paper, we enhance MAPF solvers with randomization and observe that they exhibit heavy-tailed distributions of runtimes on hard instances. This leads us to develop simple rapid randomized restart (RRR) strategies with the intuition that, given a hard instance, multiple short runs have a better chance of solving it compared to one long run. We validate this intuition through experiments and show that our RRR strategies indeed boost the performance of state-of-the-art MAPF solvers such as iECBS and M*.", "histories": [["v1", "Thu, 8 Jun 2017 23:31:01 GMT  (224kb,D)", "http://arxiv.org/abs/1706.02794v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["liron cohen", "glenn wagner", "t k satish kumar", "howie choset", "sven koenig"], "accepted": false, "id": "1706.02794"}, "pdf": {"name": "1706.02794.pdf", "metadata": {"source": "CRF", "title": "Rapid Randomized Restarts for Multi-Agent Path Finding Solvers", "authors": ["Liron Cohen", "Glenn Wagner", "T.K. Satish Kumar", "Howie Choset", "Sven Koenig"], "emails": [], "sections": [{"heading": "INTRODUCTION", "text": "In the face of an environment and agents with assigned starting and finishing points, the problem of multi-agent path finding (MAPF) is a problem that involves finding collision-free paths for all agents from their start to their destination, which includes some criteria such as CBS and the sum of distances traveled. However, the solution to the MAPF problem has many applications, including improving traffic at interfaces, formation control, warehouse applications and assembly planning. A comprehensive list of applications with references can be found in (LaValle 2006). In Artificial Intelligence (AI), the MAPF problem is examined with the following simplistic Assumptions. In the face of a directed or undirected graph and a number of agents with unique starting and finishing routines, the MAPF problem is to find collision-free paths for all agents from their respective starting points. Agents can also wait for the solution in the unit time."}, {"heading": "BACKGROUND", "text": "The MAPF problem is formally defined as follows: We will have a direct or undirected diagram G = (V, E) and a set of ofK agents 1,., K. Each agent j has a unique starting vertex sj, V and a unique collision. At each step, each agent can either move to an adjacent vertex or wait at its current vertex, both at a cost. A solution to a MAPF instance is a series of feasible paths, a path {sj0,., sj, sjTj, sjTj + 1,.} for each agent j that each agent j, each agent j, so that no two paths collide. A path for agent j is feasible if and only if 1) he is the agent j, that is, sjTj, syTj, syTj at the beginning of the starting vertex."}, {"heading": "RANDOMIZED MAPF SOLVERS", "text": "In fact, it is the case that most of us are able to put ourselves in another world, in which they do not find themselves in another world, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they cannot find themselves, in which they do not find themselves, in which they want to live themselves, in which they want to live themselves, in which they do not want to live themselves, in which they live in which they do not find themselves, in which they do not find themselves, in which they do not want to live, in which they want to live, in which they want to live, in which they do not want to live, in which they live in which they live, in which they do not want to live, in which they live in fear, in which they do not want to live in fear, in which they do not want to live in fear, in which they do not want to live in fear, in which they do not want to live in fear, in which they do not want to live in fear, in which they do not want to live in fear, in which they do not want to live in fear, in which they do not want to live in fear, in which they do not want to live in fear, in which they do not want to live in fear, in which they do not want to live in fear, in which they do not want to live in fear, in which they do not want to live in which they do not live in fear, in which they do not want to live in which they do not live in fear, in which they do not want to live in fear, in which they do not live in which they do not want to live in which they do not want to live in which they do not live in fear, in which they do not want to live in which they do not live in fear, in which they do not live in which they do not live in which they do not want to live in which they do not live in which they do not want to live in which they do not live in which they do not live in which they do not live in which they do not want to live in which they do not live in which they do not live in which they do not find themselves, in which they do not find themselves, in which they do not live in which"}, {"heading": "RRR STRATEGIES", "text": "In fact, it is such that most of them are in a position to enter another world, in which they enter another world, in which they enter another world, in which they enter another world, in which they enter another world, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in them, in which they, in which they, in them, in which they, in them, in which they, in them, in which they, in them, in which they, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in which they, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in them, in which they, in which, in them, in them, in them, in them, in which, in them, in them, in them, in them, in which, in them, in them, in them, in them, in them, in them"}, {"heading": "EXPERIMENTAL RESULTS", "text": "This year it is so far that it will be able to erenie.n the aforementioned lcihsrcnlrVo"}, {"heading": "CONCLUSIONS", "text": "MAPF is a well-studied problem in AI and robotics with many applications in the real world. In this paper, we recognized the deterministic nature of existing state-of-the-art MAPF solvers such as M * and iECBS, resulting in their poor performance on hard instances. We developed randomized versions of these solvers to investigate their ability to implement RRR strategies, and randomized versions of these solvers replaced arbitrary with random choices in the search process. In one case, the runtimes of these solvers exhibited cumbersome distributions, which were exploited using RRR strategies with the intuition that in the face of a hard instance, multiple short circuits have a better chance of solving them than in the long run. We confirmed this intuition through experiments in a Kiva-like domain and demonstrated that our RRR strategies increased the success rates of M * and iECBS. In future work, we intend to use randomness in additional ways to validate and validate them."}], "references": [{"title": "Suboptimal variants of the conflict-based search algorithm for the multi-agent pathfinding problem", "author": ["Barer"], "venue": "In Proceedings of the 7th Annual Symposium on Combinatorial Search", "citeRegEx": "Barer,? \\Q2014\\E", "shortCiteRegEx": "Barer", "year": 2014}, {"title": "Improved boundedsuboptimal multi-agent path finding solvers", "author": ["Cohen"], "venue": "In Proceedings of the 25th International Joint Conference on Artificial Intelligence", "citeRegEx": "Cohen,? \\Q2016\\E", "shortCiteRegEx": "Cohen", "year": 2016}, {"title": "Feasibility study: Using highways for bounded-suboptimal multi-agent path finding", "author": ["Uras Cohen", "L. Koenig 2015] Cohen", "T. Uras", "S. Koenig"], "venue": "In Proceedings of the 8th Annual Symposium on Combinatorial Search", "citeRegEx": "Cohen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 2015}, {"title": "Heavy-tailed phenomena in satisfiability and constraint satisfaction problems", "author": ["Gomes"], "venue": "Journal of Automated Reasoning", "citeRegEx": "Gomes,? \\Q2000\\E", "shortCiteRegEx": "Gomes", "year": 2000}, {"title": "Multiagent path finding with kinematic contraints", "author": ["Hoenig"], "venue": "In Proceedings of the 26th International Conference on Automated Planning and Scheduling", "citeRegEx": "Hoenig,? \\Q2016\\E", "shortCiteRegEx": "Hoenig", "year": 2016}, {"title": "Overview: Generalizations of multiagent path finding to real-world scenarios", "author": ["Ma"], "venue": "In Proceedings of the 25th International Joint Conference on Artificial In-", "citeRegEx": "Ma,? \\Q2016\\E", "shortCiteRegEx": "Ma", "year": 2016}, {"title": "Studies in semi-admissible heuristics", "author": ["Pearl", "J. Kim 1982] Pearl", "J.H. Kim"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "citeRegEx": "Pearl et al\\.,? \\Q1982\\E", "shortCiteRegEx": "Pearl et al\\.", "year": 1982}, {"title": "E-graphs: Bootstrapping planning", "author": ["Phillips"], "venue": null, "citeRegEx": "Phillips,? \\Q2012\\E", "shortCiteRegEx": "Phillips", "year": 2012}, {"title": "Conflict-based search for optimal multi-agent pathfinding", "author": ["Sharon"], "venue": "Artificial Intelligence", "citeRegEx": "Sharon,? \\Q2015\\E", "shortCiteRegEx": "Sharon", "year": 2015}, {"title": "Structure and intractability of optimal multi-robot path planning on graphs", "author": ["Yu", "J. LaValle 2013] Yu", "S.M. LaValle"], "venue": "In Proceedings of the 27th AAAI Conference on Artificial Intelligence", "citeRegEx": "Yu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2013}], "referenceMentions": [], "year": 2017, "abstractText": "Multi-Agent Path Finding (MAPF) is an NP-hard problem well studied in artificial intelligence and robotics. It has many real-world applications for which existing MAPF solvers use various heuristics. However, these solvers are deterministic and perform poorly on \u201chard\u201d instances typically characterized by many agents interfering with each other in a small region. In this paper, we enhance MAPF solvers with randomization and observe that they exhibit heavy-tailed distributions of runtimes on hard instances. This leads us to develop simple rapid randomized restart (RRR) strategies with the intuition that, given a hard instance, multiple short runs have a better chance of solving it compared to one long run. We validate this intuition through experiments and show that our RRR strategies indeed boost the performance of state-ofthe-art MAPF solvers such as iECBS and M*.", "creator": "LaTeX with hyperref package"}}}