{"id": "1706.02861", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2017", "title": "Assigning personality/identity to a chatting machine for coherent conversation generation", "abstract": "Endowing a chatbot with personality or an identity is quite challenging but critical to deliver more realistic and natural conversations. In this paper, we address the issue of generating responses that are coherent to a pre-specified agent profile. We design a model consisting of three modules: a profile detector to decide whether a post should be responded using the profile and which key should be addressed, a bidirectional decoder to generate responses forward and backward starting from a selected profile value, and a position detector that predicts a word position from which decoding should start given a selected profile value. We show that general conversation data from social media can be used to generate profile-coherent responses. Manual and automatic evaluation shows that our model can deliver more coherent, natural, and diversified responses.", "histories": [["v1", "Fri, 9 Jun 2017 08:13:21 GMT  (329kb,D)", "https://arxiv.org/abs/1706.02861v1", null], ["v2", "Mon, 12 Jun 2017 06:17:45 GMT  (0kb,I)", "http://arxiv.org/abs/1706.02861v2", "an error on author information"], ["v3", "Wed, 21 Jun 2017 07:40:57 GMT  (330kb,D)", "http://arxiv.org/abs/1706.02861v3", "an error on author information"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["qiao qian", "minlie huang", "haizhou zhao", "jingfang xu", "xiaoyan zhu"], "accepted": false, "id": "1706.02861"}, "pdf": {"name": "1706.02861.pdf", "metadata": {"source": "CRF", "title": "Assigning Personality/Identity to a Chatting Machine for Coherent Conversation Generation", "authors": ["Qiao Qian", "Minlie Huang", "Haizhou Zhao", "Jingfang Xu", "Xiaoyan Zhu"], "emails": ["qianqiaodecember29@126.com,", "aihuang@tsinghua.edu.cn,", "zhaohaizhou@sogou-inc.com,", "xujingfang@sogou-inc.com,", "zxy-dcs@tsinghua.edu.cn"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "2 Related Work", "text": "This work can be categorized into task-oriented (Young et al., 2013; Wen et al., 2016; Bordes and Weston, 2016) or chat-based personality processes. Recently, researchers have found that social data such as Twitter / Weibo posts and responses (Ritter et al., 2011; Shang et al., 2015) and movie dialogues can be used to learn and generate spoken personality processes.Large-scale conversation generations with social media data were first proposed in (Ritter et al., 2011) and were greatly enhanced by applying sequence-to-sequence models (Sutskever et al., 2014; Vinyals et al., 2015; Sordoni et al., 2015; Serban et al., 2015, 2016; Serban et al., 2015, 2016) by focusing on sequence-to-sequence models (Sutskever et al., 2014; Vinyals and Le, 2015; Sordoni et al., 2016; Serban et al., 2016; Serban et al., 2015, 2015, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,"}, {"heading": "3 Model", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Task Definition", "text": "The task can be formally defined as follows: In view of a contribution x = x1x2 \u00b7 \u00b7 \u00b7 xn and an agent profile defined as a set of key-value pairs, the task aims to generate an answer y = y1y2 \u00b7 \u00b7 \u00b7 \u00b7 ym consistent with the agent profile. The generation process can be briefly described as follows: P (y | x, {< ki, vi >}) = P (z = 0 | x) \u00b7 P fr (y | x) + P (z = 1 | x) \u00b7 P bi (y | x, {< ki, vi >}) (1), where P (z | x) is the probability of using the agent profile x specified by the profile detector; P fr (y | x) = \u0441mt = 1P fr (yt | y < t, x)."}, {"heading": "3.2 Overview", "text": "Our model works as follows (see Figure 1): In a post, the profile detector will predict whether the agent profile should be used. Otherwise, a generic seq2seq decoder will be used to generate the response; otherwise, the profile detector will continue to select a suitable profile key. Based on the selected profile value, the bidirectional decoder will generate a forward and backward response. To better train the bidirectional decoder (see Figure 2), the position detector addresses the discrepancy problem between training and the test by predicting a word position from which decoding should begin based on the selected profile value. Note that the position detector does not participate in the generation during the test."}, {"heading": "3.3 Encoder", "text": "The encoder aims to encode a contribution to a vector representation. In a contribution x = x1x2 \u00b7 \u00b7 \u00b7 xn, the hidden states of the contribution h = (h1, h2, \u00b7 \u00b7 \u00b7, hn) are determined by a gated recurrent unit (GRU) (Chung et al., 2014) as follows: ht = GRU (ht \u2212 1, xt) (2), where xt is the embedding of the t-th word."}, {"heading": "3.4 Profile Detector", "text": "The profile detector has two roles: firstly, to determine whether the post should be answered with the agent profile, and secondly, to select a specific profile < key, value > to be addressed in the decoder. The first role of the profile detector is defined by the probability P (z | x) (z = 0, 1}), where z = 1 means that the agent profile should be used. If the post is \"how old is your father,\" the probability is calculated as follows: P (z | h) = P (z | h) = \"how old are you,\" P (z = 1 | x) \u2248 1. P (z | x) is a binary classifier trained on monitored data. Formally, the probability is calculated as follows: P (z | h) = P (z | h) = \"how old are you,\" P (W = 1 | x) \u2248 \"(3), where Wp\" key \"is\" the key \"j\" and \"the sum\" of all hh. \""}, {"heading": "3.5 The Bidirectional Decoder", "text": "This decoder aims to generate a response that specifies a profile value. Inspired by (Mou et al., 2016), we design a bidirectional decoder that consists of a backward decoder and a forward decoder, but with the crucial difference that a position detector is used to predict a start decoding position. Suppose a generated response is y = (yb, v, yf) = (yb1, \u00b7 \u00b7, y f + 1, \u00b7, y f m), where v (f) is a selected profile value. Suppose the bidirectional decoder generates yb in a backward direction and yf forward. The backward decoder (P b) generates yb from the given profile value v, \u00b7 f f f f f m), where v (f) is a selected profile value."}, {"heading": "3.6 Position Detector", "text": "The position detector is designed to provide more monitoring to the bidirectional decoder used only during training. < > As mentioned earlier, the bidirectional decoder assumes a profile value to generate the entire sequence in the test phase. < - In our training data set, however, the profile values are rarely mentioned in the answers. - In other words, although we have a training instance (x, y, < k, v >), the value (v) cannot occur in y at all. Therefore, the bidirectional decoder is not aware of which word the decoder should start from. This leads to the discrepancy between training and test: During training, the decoder of the decoder of the decoder is not aware of the starting position, but during the test."}, {"heading": "3.7 Loss Function and Training", "text": "Two loss functions are defined: one on the generation probability and the other on the profile detector. The first loss is defined as: L1 (\u03b8, D (c), D (x, y))) = \u2212 \u2211 (x, y) \u2022 D (c).D (pr) logP (y | x, {< ki, vi >}) = \u2212 preservation (x, y).D (c) logP fr (y | x) \u2212 preservation (pr) logP bi (y | x, v) (10) 2The number indicates the position of each word.The first term is the negative log probability of observing D (c) and the second term for D (pr).p is a word in y whose position is predicted by the position detector during the training. D (pr) consists of pairs in which a mail is related to a profile key and whose response gives a meaningful response to the mail."}, {"heading": "4 Experiment", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Data Preparation", "text": "We prepare several data sets: Weibo Dataset (WD) - D: We collect 9, 697, 651 post-response pairs from Weibo. The data set is used for training P fr (y | x) and P bi (y | x, v) in the early stages and 7,000 pairs are used for validation to make an early stop. Profile Binary Subset (PB - D (pb), D): We extract 76, 930 pairs from WD for 6 profiles ({name, gender, age, city, weight, constellation}) with about 200 regular expression patterns. The data set is commented by 13 annotators. Each pair is manually labeled positive when a post asks for a profile value and the answer is a logical response to the post or negative. This data set is used to train the binary data collector (P (z | x)."}, {"heading": "4.2 Human Evaluation", "text": "At the session level, we evaluate the models in terms of consistency and diversity to justify performance in the real conversation environment. We name our Identity-Coherent Conversation Machine (ICCM) model and compare it with several baselines: Seq2Seq: a general sequence to the sequence model (Sutskever et al., 2014). Seq2Seq + Profile Value (+ PV): If the profile detector decides to use a profile value (P (z | x) > 0.5), the answer is simply the value of the key determined by the profile detector (see Eq4); otherwise, a general seq2seq decoder is used."}, {"heading": "4.2.1 Post-level Evaluation", "text": "To make a post-level assessment, we use 600 posts from MD, 50 positive / negative posts for each key. Each post is forwarded to all models to get the corresponding answers. Thus, each post has 5 responses and these responses are randomly shuffled and then submitted to two curators. Post-response pairs are commented on using the following metrics, based on a 1 / 0 scoring scheme: naturalness (Nat.) measures the frequency and grammar of an answer. Too short responses are judged to be a lack of naturalness. Logic measures whether the answer is a logical response to a post. For example, a logical response for a post could be \"how old you are,\" \"I'm 3 years old\" or \"I don't know.\" Correctness (Cor.) measures whether the answer provides a correct response to a post that gives the profile."}, {"heading": "4.2.2 Session-level Evaluation", "text": "In order to be able to compare these models in real conversation sessions, we randomly generate sessions based on MD. In this way, 240 sessions are generated, and each button has 40 sessions. The sessions are checked manually using the following metrics: Consistency measures whether there are conflicting answers in relation to the given profile. Result 1 shows that all three answers are consistent with the profile and otherwise 0. Diversity measures the linguistic diversity of the three answers in a session. Result 1 shows that the linguistic patterns and formulations are different between two of them, and evaluates 0 otherwise. Results are shown in Table 6 and we show some session examples in Table 5.We can clearly see the following observations: 1) Our model is remarkably better than all baselines."}, {"heading": "4.3 Automatic Evaluation", "text": "We also present the results of the automatic evaluation of the profile and position detector."}, {"heading": "4.3.1 Profile Detection", "text": "The profile detector is evaluated from two points of view: whether a profile should be used or not (P (z = 1 | x)), and whether a profile key is correctly selected. Note that the prediction of the selection of profile keys is cascaded to that of P (z = 1 | x). Classifiers are trained on Weibo social data. Results in Table 7 show that the profile detector achieves relatively good accuracy. However, the classifiers show a notable decrease when testing the manual data set (two lines compared: MD (600) vs. PB (3000)), showing the difference between Weibo social data and real human conversations."}, {"heading": "4.3.2 Position Detection", "text": "As already mentioned, the position detector plays a key role in improving the naturalness, logic and correctness of the answers (see ICCM vs. ICCM-pos in Table 4) as well as the consistency and variety of conversation sessions (see Table 6). Therefore, it is necessary to evaluate the performance of this module separately.We sample 200 post-response pairs of PR for each key (a total of 1200 pairs) and then manually note down the optimal position from which the decoding should begin. Results are in Table 8. The position for most keys can be accurately estimated, while the prediction for the name is poor. This is because the value of the key is rare in our body and the embedding of such values is not fully trained. Nevertheless, the results are better than a random word picking strategy (ICCM vs. ICCM-pos)."}, {"heading": "4.4 Extensibility", "text": "The effectiveness of our model is checked using six profile keys, but a lot of manual work is required. We will show the expandability of the model using four additional keys: hobby, idol, specialty and user. Firstly, for the 4 keys we extract 16, 332 post response pairs from the WD with 79 handmade patterns and each pair is noisily assigned to one of the keys with these patterns. These new pairs, along with the old pairs on the six pairs, are used to retrain the model. Secondly, we construct a test record consisting of 400 items, 50 positive and 50 negative man-written items for each key. Answers from our model and Seq2Seq are obtained and evaluated afterward.The manual work only exists when making the 79 patterns. The results show that our model exhibits a relative decline of 10% on the new buttons in terms of logic and correctness and remains unchanged in naturality.Nevertheless, our model is still much better than the natural 2q model, as it does not have a natural line."}, {"heading": "5 Conclusion and Future Work", "text": "Our work is a very small step towards equipping a chatbot with its own personality, which is an important question for a chatbot to pass the Turing test. There are many future directions: Conversational style: We have shown that general conversation data can be used to generate profile-coherent responses; can a conversation style consistent with a chatbot's personality be modelled without stylistic dialogue data? Conversational styles such as talking like young girls or old adults and introverts or extroverts are an interesting direction. Semantic reasoning: Giving a chatbot personality / identity raises the question of semantic thinking; however, when the user asks, \"Are you married?\" or \"Do you play basketball for women?,\" this eminently sensible, five-year-old answer knowledge requires a coherent answer."}, {"heading": "A Statistics for Profile Binary Dataset", "text": "We extract 76,930 pairs of WD for 6 profile keys ({name, gender, age, city, weight, constellation}) with about 200 handmade patterns, and then they are commented on positively or negatively. A positive post asks for a profile key of the chatbot and its response gives a meaningful response, such as \"Could you tell me your age,\" while a negative post for each profile key is irrelevant, such as \"Guess how old I am.\" The statistic of the dataset is in Table 10.B Implementation detailsIn our experiments, the encoder and the attentive decoder have all 4 layers of GRUs with a 512-dimensional hidden state. The dimension of the word embedding is set to 100. Vocabulary size is limited to 40,000. Word embedding is performed on an unlabeled corpus (about 60,000, 000Weibo pairs) by word2vec factor, and the other parameters are pretrained by 12- 3."}], "references": [{"title": "Conversational contextual cues: The case of personalization and history for response ranking", "author": ["Rami Al-Rfou", "Marc Pickett", "Javier Snaider", "Yunhsuan Sung", "Brian Strope", "Ray Kurzweil."], "venue": "arXiv preprint arXiv:1606.00372 .", "citeRegEx": "Al.Rfou et al\\.,? 2016", "shortCiteRegEx": "Al.Rfou et al\\.", "year": 2016}, {"title": "Learning end-to-end goal-oriented dialog", "author": ["Antoine Bordes", "Jason Weston."], "venue": "arXiv preprint arXiv:1605.07683 .", "citeRegEx": "Bordes and Weston.,? 2016", "shortCiteRegEx": "Bordes and Weston.", "year": 2016}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1412.3555 .", "citeRegEx": "Chung et al\\.,? 2014", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "A very brief measure of the big-five personality domains", "author": ["Samuel D Gosling", "Peter J Rentfrow", "William B Swann."], "venue": "Journal of Research in personality 37(6):504\u2013528.", "citeRegEx": "Gosling et al\\.,? 2003", "shortCiteRegEx": "Gosling et al\\.", "year": 2003}, {"title": "Incorporating copying mechanism in sequence-to-sequence learning", "author": ["Jiatao Gu", "Zhengdong Lu", "Hang Li", "Victor OK Li."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Gu et al\\.,? 2016", "shortCiteRegEx": "Gu et al\\.", "year": 2016}, {"title": "Pointing the unknown words", "author": ["Caglar Gulcehre", "Sungjin Ahn", "Ramesh Nallapati", "Bowen Zhou", "Yoshua Bengio."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational.", "citeRegEx": "Gulcehre et al\\.,? 2016", "shortCiteRegEx": "Gulcehre et al\\.", "year": 2016}, {"title": "A diversity-promoting objective function for neural conversation models", "author": ["Michel Galley Chris Brockett Jianfeng Gao Bill Dolan Jiwei Li."], "venue": "The 2016 Conference of the North American Chapter of the Association. pages 110\u2013119.", "citeRegEx": "Li.,? 2016", "shortCiteRegEx": "Li.", "year": 2016}, {"title": "A persona-based neural conversation model", "author": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Li et al\\.,? 2016", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Automatic recognition of personality in conversation", "author": ["Fran\u00e7ois Mairesse", "Marilyn Walker."], "venue": "Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers. Association for Computational Lin-", "citeRegEx": "Mairesse and Walker.,? 2006", "shortCiteRegEx": "Mairesse and Walker.", "year": 2006}, {"title": "Personage: Personality generation for dialogue", "author": ["Fran\u00e7ois Mairesse", "Marilyn Walker."], "venue": "Annual Meeting-Association For Computational Linguistics. page 496.", "citeRegEx": "Mairesse and Walker.,? 2007", "shortCiteRegEx": "Mairesse and Walker.", "year": 2007}, {"title": "Using linguistic cues for the automatic recognition of personality in conversation and text", "author": ["Fran\u00e7ois Mairesse", "Marilyn A Walker", "Matthias R Mehl", "Roger K Moore."], "venue": "Journal of artificial intelligence research pages 457\u2013500.", "citeRegEx": "Mairesse et al\\.,? 2007", "shortCiteRegEx": "Mairesse et al\\.", "year": 2007}, {"title": "Sequence to backward and forward sequences: A content-introducing approach", "author": ["Lili Mou", "Yiping Song", "Rui Yan", "Ge Li", "Lu Zhang", "Zhi Jin"], "venue": null, "citeRegEx": "Mou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mou et al\\.", "year": 2016}, {"title": "Toward an adequate taxonomy of personality attributes: Replicated factor structure in peer nomination personality ratings", "author": ["Warren T Norman."], "venue": "The Journal of Abnormal and Social Psychology 66(6):574.", "citeRegEx": "Norman.,? 1963", "shortCiteRegEx": "Norman.", "year": 1963}, {"title": "Data-driven response generation in social media", "author": ["Alan Ritter", "Colin Cherry", "William B Dolan."], "venue": "Proceedings of the conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, pages 583\u2013593.", "citeRegEx": "Ritter et al\\.,? 2011", "shortCiteRegEx": "Ritter et al\\.", "year": 2011}, {"title": "Building end-to-end dialogue systems using generative hierarchical neural network models", "author": ["Iulian V Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron Courville", "Joelle Pineau."], "venue": "Proceedings of the 30th AAAI Conference on Artificial Intelligence.", "citeRegEx": "Serban et al\\.,? 2016", "shortCiteRegEx": "Serban et al\\.", "year": 2016}, {"title": "Hierarchical neural network generative models for movie dialogues", "author": ["Iulian Vlad Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron C. Courville", "Joelle Pineau."], "venue": "CoRR abs/1507.04808.", "citeRegEx": "Serban et al\\.,? 2015", "shortCiteRegEx": "Serban et al\\.", "year": 2015}, {"title": "Neural responding machine for short-text conversation", "author": ["Lifeng Shang", "Zhengdong Lu", "Hang Li."], "venue": "Proceedings of the Association for Computational Linguistics. pages 1577\u20131586.", "citeRegEx": "Shang et al\\.,? 2015", "shortCiteRegEx": "Shang et al\\.", "year": 2015}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["Alessandro Sordoni", "Michel Galley", "Michael Auli", "Chris Brockett", "Yangfeng Ji", "Margaret Mitchell", "Jian-Yun Nie", "Jianfeng Gao", "Bill Dolan."], "venue": "The 2015", "citeRegEx": "Sordoni et al\\.,? 2015", "shortCiteRegEx": "Sordoni et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."], "venue": "Advances in Neural Information Processing Systems. pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Computing machinery and intelligence", "author": ["Alan M Turing."], "venue": "Mind 59(236):433\u2013460.", "citeRegEx": "Turing.,? 1950", "shortCiteRegEx": "Turing.", "year": 1950}, {"title": "A neural conversational model", "author": ["Oriol Vinyals", "Quoc Le."], "venue": "arXiv preprint arXiv:1506.05869 .", "citeRegEx": "Vinyals and Le.,? 2015", "shortCiteRegEx": "Vinyals and Le.", "year": 2015}, {"title": "Improving linguistic style: social and affective bases for agent personality", "author": ["Marilyn A. Walker", "Janet E. Cahn", "Stephen J. Whittaker."], "venue": "In: Mller, J. (Ed.), Proceedings of Autonomous Agents.", "citeRegEx": "Walker et al\\.,? 1997", "shortCiteRegEx": "Walker et al\\.", "year": 1997}, {"title": "An annotated corpus of film dialogue for learning and characterizing character style", "author": ["Marilyn A Walker", "Grace I Lin", "Jennifer Sawyer."], "venue": "LREC. pages 1373\u20131378.", "citeRegEx": "Walker et al\\.,? 2012", "shortCiteRegEx": "Walker et al\\.", "year": 2012}, {"title": "A networkbased end-to-end trainable task-oriented dialogue system", "author": ["Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrksic", "Lina M Rojas-Barahona", "Pei-Hao Su", "Stefan Ultes", "David Vandyke", "Steve Young."], "venue": "arXiv preprint arXiv:1604.04562 .", "citeRegEx": "Wen et al\\.,? 2016", "shortCiteRegEx": "Wen et al\\.", "year": 2016}, {"title": "Topic aware neural response generation", "author": ["Chen Xing", "Wei Wu", "Yu Wu", "Jie Liu", "Yalou Huang", "Ming Zhou", "Wei-Ying Ma."], "venue": "Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence.", "citeRegEx": "Xing et al\\.,? 2017", "shortCiteRegEx": "Xing et al\\.", "year": 2017}, {"title": "Neural generative question answering", "author": ["Jun Yin", "Xin Jiang", "Zhengdong Lu", "Lifeng Shang", "Hang Li", "Xiaoming Li."], "venue": "Proceedings of the TwentyFifth International Joint Conference on Artificial Intelligence. pages 2972\u20132978.", "citeRegEx": "Yin et al\\.,? 2015", "shortCiteRegEx": "Yin et al\\.", "year": 2015}, {"title": "Pomdp-based statistical spoken dialog systems: A review", "author": ["Steve Young", "Milica Ga\u0161i\u0107", "Blaise Thomson", "Jason D Williams."], "venue": "Proceedings of the IEEE 101(5):1160\u20131179.", "citeRegEx": "Young et al\\.,? 2013", "shortCiteRegEx": "Young et al\\.", "year": 2013}, {"title": "Strategy and policy learning for nontask-oriented conversational systems", "author": ["Zhou Yu", "Ziyu Xu", "Alan W Black", "Alex I Rudnicky."], "venue": "17th Annual Meeting of the Special Interest Group on Discourse and Dialogue. page 404.", "citeRegEx": "Yu et al\\.,? 2016", "shortCiteRegEx": "Yu et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 19, "context": "Generating human-level conversations by machine has been a long-term goal of AI since the Turing Test (Turing, 1950).", "startOffset": 102, "endOffset": 116}, {"referenceID": 20, "context": "However, as argued by (Vinyals and Le, 2015), the current conversation generation models are still unable to deliver realistic conversations to pass the Test.", "startOffset": 22, "endOffset": 44}, {"referenceID": 12, "context": "Though personality is a well-defined concept in psychology (Norman, 1963; Gosling et al., 2003), while in this paper, the personality of a chatbot refers to the character that the bot plays or performs during conversational interactions.", "startOffset": 59, "endOffset": 95}, {"referenceID": 3, "context": "Though personality is a well-defined concept in psychology (Norman, 1963; Gosling et al., 2003), while in this paper, the personality of a chatbot refers to the character that the bot plays or performs during conversational interactions.", "startOffset": 59, "endOffset": 95}, {"referenceID": 21, "context": "In this scenario, personality can be viewed as a composite of the identity (the background and profile) that a chatbot is endowed with, linguistic style that an agent exhibits during interactions (Walker et al., 1997), and many more explicit and implicit cues that may portray character.", "startOffset": 196, "endOffset": 217}, {"referenceID": 27, "context": "The motivation is also verified by (Yu et al., 2016) which reports that users ask for much personal information of a chatbot in human-machine interaction.", "startOffset": 35, "endOffset": 52}, {"referenceID": 7, "context": "The recent work dealing with personality in large-scale conversation generation can be seen in (Li et al., 2016) where speaker-specific conversation style is learned by user embedding.", "startOffset": 95, "endOffset": 112}, {"referenceID": 0, "context": "Another work which models user personalization can be seen in (Al-Rfou et al., 2016), with a similar technique of user embedding.", "startOffset": 62, "endOffset": 84}, {"referenceID": 26, "context": "These works can be categorized into task-oriented (Young et al., 2013; Wen et al., 2016; Bordes and Weston, 2016) or chat-based.", "startOffset": 50, "endOffset": 113}, {"referenceID": 23, "context": "These works can be categorized into task-oriented (Young et al., 2013; Wen et al., 2016; Bordes and Weston, 2016) or chat-based.", "startOffset": 50, "endOffset": 113}, {"referenceID": 1, "context": "These works can be categorized into task-oriented (Young et al., 2013; Wen et al., 2016; Bordes and Weston, 2016) or chat-based.", "startOffset": 50, "endOffset": 113}, {"referenceID": 13, "context": "Recently, researchers found that social data such as Twitter/Weibo posts and replies (Ritter et al., 2011; Shang et al., 2015), and movie dialogues can be used to learn and generate spoken language.", "startOffset": 85, "endOffset": 126}, {"referenceID": 16, "context": "Recently, researchers found that social data such as Twitter/Weibo posts and replies (Ritter et al., 2011; Shang et al., 2015), and movie dialogues can be used to learn and generate spoken language.", "startOffset": 85, "endOffset": 126}, {"referenceID": 13, "context": "Large-scale conversation generation with social media data was firstly proposed in (Ritter et al., 2011) and has been greatly advanced by applying sequence-to-sequence models (Sutskever et al.", "startOffset": 83, "endOffset": 104}, {"referenceID": 18, "context": ", 2011) and has been greatly advanced by applying sequence-to-sequence models (Sutskever et al., 2014; Vinyals and Le, 2015; Sordoni et al., 2015; Shang et al., 2015; Serban et al., 2015, 2016).", "startOffset": 78, "endOffset": 193}, {"referenceID": 20, "context": ", 2011) and has been greatly advanced by applying sequence-to-sequence models (Sutskever et al., 2014; Vinyals and Le, 2015; Sordoni et al., 2015; Shang et al., 2015; Serban et al., 2015, 2016).", "startOffset": 78, "endOffset": 193}, {"referenceID": 17, "context": ", 2011) and has been greatly advanced by applying sequence-to-sequence models (Sutskever et al., 2014; Vinyals and Le, 2015; Sordoni et al., 2015; Shang et al., 2015; Serban et al., 2015, 2016).", "startOffset": 78, "endOffset": 193}, {"referenceID": 16, "context": ", 2011) and has been greatly advanced by applying sequence-to-sequence models (Sutskever et al., 2014; Vinyals and Le, 2015; Sordoni et al., 2015; Shang et al., 2015; Serban et al., 2015, 2016).", "startOffset": 78, "endOffset": 193}, {"referenceID": 4, "context": "These works include: dealing with unknown words (Gu et al., 2016; Gulcehre et al., 2016), avoiding universal responses (Jiwei Li, 2016), generating more diverse and meaningful responses (Xing et al.", "startOffset": 48, "endOffset": 88}, {"referenceID": 5, "context": "These works include: dealing with unknown words (Gu et al., 2016; Gulcehre et al., 2016), avoiding universal responses (Jiwei Li, 2016), generating more diverse and meaningful responses (Xing et al.", "startOffset": 48, "endOffset": 88}, {"referenceID": 24, "context": ", 2016), avoiding universal responses (Jiwei Li, 2016), generating more diverse and meaningful responses (Xing et al., 2017; Mou et al., 2016), and many more.", "startOffset": 105, "endOffset": 142}, {"referenceID": 11, "context": ", 2016), avoiding universal responses (Jiwei Li, 2016), generating more diverse and meaningful responses (Xing et al., 2017; Mou et al., 2016), and many more.", "startOffset": 105, "endOffset": 142}, {"referenceID": 20, "context": "As argued by (Vinyals and Le, 2015), it\u2019s still quite impossible for current chatbots to pass the Turing Test, while one of the reasons is the lack of a coherent personality.", "startOffset": 13, "endOffset": 35}, {"referenceID": 12, "context": "Though personality has been well defined in psychology (Norman, 1963), it is implicit, subtle, and challenging to formally define in statistical language generation.", "startOffset": 55, "endOffset": 69}, {"referenceID": 8, "context": "Linguistic style can be an indicator of personality (Mairesse and Walker, 2006; Mairesse et al., 2007), and conversation can be clues for personality recognition (Walker et al.", "startOffset": 52, "endOffset": 102}, {"referenceID": 10, "context": "Linguistic style can be an indicator of personality (Mairesse and Walker, 2006; Mairesse et al., 2007), and conversation can be clues for personality recognition (Walker et al.", "startOffset": 52, "endOffset": 102}, {"referenceID": 9, "context": "In reverse, spoken language can be generated in accordance to particular personality (Mairesse and Walker, 2007).", "startOffset": 85, "endOffset": 112}, {"referenceID": 7, "context": "A first attempt to model persona can be seen in (Li et al., 2016) where the authors proposed to learn speaker-specific conversation style by user embedding.", "startOffset": 48, "endOffset": 65}, {"referenceID": 7, "context": "Our work differs from this work significantly: our task is to endow the chatbot with a fixed personality while (Li et al., 2016) learns personalized conversational styles.", "startOffset": 111, "endOffset": 128}, {"referenceID": 7, "context": "Further, (Li et al., 2016) requires many dialogue data from each user while our work has no such requirement.", "startOffset": 9, "endOffset": 26}, {"referenceID": 25, "context": "Another related work is generative question answering (GenQA) (Yin et al., 2015) which generates a response containing an answer extracted from a knowledge base (KB).", "startOffset": 62, "endOffset": 80}, {"referenceID": 18, "context": "where P (z|x) is the probability of using the agent profile given post x, which is computed by the Profile Detector; P fr(y|x) = \u220fm t=1P (yt|y<t,x) is given by a general forward decoder, the same as (Sutskever et al., 2014), and P bi(y|x, {< ki, vi >}) is given by a Bidirectional Decoder which will be described later.", "startOffset": 199, "endOffset": 223}, {"referenceID": 2, "context": "Given a post x = x1x2 \u00b7 \u00b7 \u00b7xn, the hidden states of the post h = (h1, h2, \u00b7 \u00b7 \u00b7, hn) are obtained by a gated recurrent unit (GRU) (Chung et al., 2014), as follows:", "startOffset": 130, "endOffset": 150}, {"referenceID": 11, "context": "Inspired by (Mou et al., 2016), we design a bidirectional decoder which consists of a backward decoder and forward decoder, but with a key difference that a position detector is employed to predict a start decoding position.", "startOffset": 12, "endOffset": 30}, {"referenceID": 4, "context": "This issue makes our work differ substantially from previous approaches where supervision is directly observable either between post and response (Gu et al., 2016) or between response and knowledge base (Yin et al.", "startOffset": 146, "endOffset": 163}, {"referenceID": 25, "context": ", 2016) or between response and knowledge base (Yin et al., 2015).", "startOffset": 47, "endOffset": 65}, {"referenceID": 11, "context": "Experiments also show that the position detector contributes much to the performance improvement than a random position picking strategy (Mou et al., 2016).", "startOffset": 137, "endOffset": 155}, {"referenceID": 18, "context": "We name our model Identity-Coherent Conversation Machine (ICCM) and compare it with several baselines: Seq2Seq: a general sequence to sequence model (Sutskever et al., 2014).", "startOffset": 149, "endOffset": 173}, {"referenceID": 11, "context": "ICCM-Pos: Instead of using a predicted position obtained by the position detector to start the decoding process, the bidirectional decoder in this setting randomly picks a word in a response during training, the same as (Mou et al., 2016).", "startOffset": 220, "endOffset": 238}], "year": 2017, "abstractText": "Endowing a chatbot with personality or an identity is quite challenging but critical to deliver more realistic and natural conversations. In this paper, we address the issue of generating responses that are coherent to a pre-specified agent profile. We design a model consisting of three modules: a profile detector to decide whether a post should be responded using the profile and which key should be addressed, a bidirectional decoder to generate responses forward and backward starting from a selected profile value, and a position detector that predicts a word position from which decoding should start given a selected profile value. We show that general conversation data from social media can be used to generate profile-coherent responses. Manual and automatic evaluation shows that our model can deliver more coherent, natural, and diversified responses.", "creator": "LaTeX with hyperref package"}}}