{"id": "1706.02883", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2017", "title": "Overview of the NLPCC 2017 Shared Task: Chinese News Headline Categorization", "abstract": "In this paper, we give an overview for the shared task at the CCF Conference on Natural Language Processing \\&amp; Chinese Computing (NLPCC 2017): Chinese News Headline Categorization. The dataset of this shared task consists 18 classes, 12,000 short texts along with corresponded labels for each class. The dataset and example code can be accessed at", "histories": [["v1", "Fri, 9 Jun 2017 10:17:24 GMT  (48kb,D)", "http://arxiv.org/abs/1706.02883v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["xipeng qiu", "jingjing gong", "xuanjing huang"], "accepted": false, "id": "1706.02883"}, "pdf": {"name": "1706.02883.pdf", "metadata": {"source": "CRF", "title": "Overview of the NLPCC 2017 Shared Task: Chinese News Headline Categorization", "authors": ["Xipeng Qiu", "Jingjing Gong", "Xuanjing Huang"], "emails": ["xjhuang}@fudan.edu.cn"], "sections": [{"heading": "1 Task Definition", "text": "This task aims to evaluate the automatic classification techniques for very short texts, i.e. Chinese news headlines. Each news headline (i.e. news titles) must be divided into one or more predefined categories. As the Internet and social media rise, text data on the Web is growing exponentially. Getting a person to analyze all this data is impractical, while machine learning techniques are perfectly suited for this kind of assignment. after all, the human brain's capacity for long and unapparent phenomena is too limited and valuable. Formally, the task is defined as follows: In the face of a news headline x = (x1, x2,..., xn), where xj represents the jth word in x, the goal is to find its possible category or label c \u0441C. More specifically, we need to find a function to predict which category x belongs to.c * = arg max c * c (x) (function c), where the parameter is (1)."}, {"heading": "2 Data", "text": "We have collected news headlines (titles) from several Chinese news websites, such as Toutiao, Sina, etc. In total, there are 18 categories. The detailed information for each category is in Table 1. All sentences are provided using the Python segmentation tool jieba. Some examples from the training data set are shown in Table 2.Length Figure 1 that most titles have a character count of less than 40, with an average of 21.05. The word length of the title set is even shorter, most of them less than 20 with an average of 12.07. The data set is published on github https: / / / github.com / FudanNLP / nlpcc2017 _ news _ headline _ categorization along with code that implements three basic models."}, {"heading": "3 Evaluation", "text": "We use macro-averaged accuracy, retrieval and formula 1 to assess performance. Macro average is defined as: Macro average = 1m m \u2211 i = 1 \u03c1iAnd Micro Avg. is defined as: Micro average = 1N m \u2211 i = 1 wi\u03c1iar Xiv: 170 6.02 883v 1 [cs.C L] 9J un2 017Table 2: Samples from the data set. The first column is category and the second column is news headline. Figure 1: The blue line is the statistical character length, and the blue line is the word length. Category average: Characters Avg. Font size 156000 22.06 13.08 dev. 36000 22.05 13.09 Test 36000 22.05 13.08 Table 3: Statistical information of the dataset. Where m indicates the number of the class, in the case of this data set the accuracy of the respective category is given with the number of test examples in the overall category N."}, {"heading": "4 Baseline Implementations", "text": "As a branch of machine learning, deep learning (DL) has gained a lot of attention in recent years due to its outstanding performance in several areas such as Computer Vision and Natural Language Processing. We have implemented some basic DL models such as Neural Bag Words (NBoW), Convolutionary Neural Networks (CNN) [Kim, 2014], and Long-Term Memory Network (LSTM) [Hochreiter and Schmidhuber, 1997]. Empirically, 2 gigabytes of GPU memory should suffice for most models, if not a smaller number."}, {"heading": "5 Participants Submitted Results", "text": "Participants Macro P Macro R Macro F Accu.P1 0.833 0.783 0.829 0.830 0.829 P2 0.828 0.825 0.826 0.825 P3 0.818 0.814 0.816 0.814 P4 0.816 0.809 0.813 0.809 P5 0.812 0.809 0.809 711 0.807 0.809 0.804 0.806 0.802 0.802 0.802 P9 0.803 0.800 0.802 0.800 P10 0.805 0.800 P10 0.800 P11 0.799 0.798 0.798 0.797 0.795 0.796 0.795 P13 0.793 0.791 0.789 P14 0.744 791 0.766 0.789 P14 0.790 0.789 P15 0.792 0.787 0.789 0.789 P16 0.789 0.786 0.70.70.783 0.717 783 0.778 778 775 Participants."}, {"heading": "6 Conclusion", "text": "Since machine learning techniques such as deep learning require large amounts of data, we have collected a significant amount of news headlines and contributed to the research community."}], "references": [{"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber", "1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim"], "venue": "arXiv preprint arXiv:1408.5882,", "citeRegEx": "Kim.,? \\Q2014\\E", "shortCiteRegEx": "Kim.", "year": 2014}], "referenceMentions": [{"referenceID": 1, "context": "We have implemented some basic DL models such as neural bag-of-words (NBoW), convolutional neural networks (CNN) [Kim, 2014] and Long short-term memory network (LSTM) [Hochreiter and Schmidhuber, 1997].", "startOffset": 113, "endOffset": 124}], "year": 2017, "abstractText": "In this paper, we give an overview for the shared task at the CCF Conference on Natural Language Processing & Chinese Computing (NLPCC 2017): Chinese News Headline Categorization. The dataset of this shared task consists 18 classes, 12,000 short texts along with corresponded labels for each class. The dataset and example code can be accessed at https://github.com/FudanNLP/ nlpcc2017_news_headline_categorization.", "creator": "LaTeX with hyperref package"}}}