{"id": "1706.03021", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2017", "title": "Ethical Artificial Intelligence - An Open Question", "abstract": "Artificial Intelligence (AI) is an effective science which employs strong enough approaches, methods, and techniques to solve unsolvable real world based problems. Because of its unstoppable rise towards the future, there are also some discussions about its ethics and safety. Shaping an AI friendly environment for people and a people friendly environment for AI can be a possible answer for finding a shared context of values for both humans and robots. In this context, objective of this paper is to address the ethical issues of AI and explore the moral dilemmas that arise from ethical algorithms, from pre set or acquired values. In addition, the paper will also focus on the subject of AI safety. As general, the paper will briefly analyze the concerns and potential solutions to solving the ethical issues presented and increase readers awareness on AI safety as another related research interest.", "histories": [["v1", "Tue, 16 May 2017 20:57:36 GMT  (683kb)", "http://arxiv.org/abs/1706.03021v1", "13 pages, 3 figures"]], "COMMENTS": "13 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.AI cs.CY", "authors": ["alice pavaloiu", "utku kose"], "accepted": false, "id": "1706.03021"}, "pdf": {"name": "1706.03021.pdf", "metadata": {"source": "CRF", "title": "Ethical Artificial Intelligence - An Open Question", "authors": ["Alice Pavaloiu"], "emails": ["ada.staicu@gmail.com", "utku.kose@usak.edu.tr"], "sections": [{"heading": "1. INTRODUCTION", "text": "In this context, it should be noted that this is one of the greatest challenges in the history of the European Union."}, {"heading": "2. ETHICAL AI \u2013 CONCERNS", "text": "Nick Bostrom (2015) underlined the importance of developing an AI that would not pose a threat to humanity or its evolution. Even if the creation of AI would already prove challenging and the creation of a human-friendly AGI would prove even more difficult, it is recommended to first address the second challenge. Preventive measures must be taken to ensure the safety of AI where uncontrolled, unintended side effects of uncontrolled innovation may occur. Regardless of the desire for an off switch or undo button, the reversibility of a sequence of actions cannot currently be ruled out. Consequently, Nadella (2017) recommended simulations in real, controlled environments to capture unpredictable behavior and prevent any major crisis. Future implications must be considered not only by ethics committees or research departments, but also by government, industry, international institutions and organizations in the earliest stages. The culture of responsibility must be developed at the global level to maintain an AI-friendly environment and its development."}, {"heading": "2.1. Moral Dilemmas Based On Pre-Set or Acquired Values", "text": "In fact, it is so that most people are able to determine for themselves what they want and what they want. (...) In fact, it is so that people are able to determine for themselves what they want. (...) It is not so that people are able to determine for themselves what they want. (...) It is so that people are able to determine for themselves what they want. (...) \"\" It is so that people are able to determine for themselves what they want. (...) \"(...)\" (...). \"(...)\" (...). \"(...)\" (... \").\" (...) \"(...\"). \"(...)\" (). \"(...\"). \"(...\") \"(...\"). \"(\"). \"(...\"). \"(...\" (...). \"(\"). \"(\"). \"(...\" (...). \"(\")."}, {"heading": "2.2. Other Drawbacks of Pre-Set Values", "text": "One drawback illustrated by Russell and Norvig (2010) is that engineers, through direct imparting of values, can omit or disregard an aspect that would later create a loop and lead to system failure. Most basic common sense guidelines can often be overlooked by engineers in designing the system, which can lead to significant errors in its modus operandi once used. AI can fail in ways that people do not expect in ordinary tasks due to differences in thinking patterns. A colossal ethical problem has been raised in terms of functional errors in autonomous weapons. What are the effects of a mistake in terms of lethal fully autonomous weapons? Due to a human factor error at the level of programming, either ignoring a fundamental rule or taking it for granted, it could have irreversible effects and long-term consequences in terms of autonomous weapons, i.e. unintentionally starting a war. Nevertheless, good programming does not imply good judgment in warfare."}, {"heading": "2.3. Other Drawbacks of Acquired Values", "text": "The advantages of acquired values are the higher quality AI decisions that are consistent with people's choices, and the similarity in judgement can lead to fewer errors and better alignment of values. However, there are several disadvantages. An ethical problem that has led to controversy is based on subjectivity and hidden bias. Tufekci (2016) illustrates the troublesome situation in which AI must make subjective decisions based on its increasing predictive power by answering unanswered questions. An example of a recruitment algorithm was given. Due to the high precision in prediction, an AI system can infer the likelihood of depression before symptoms arise. It could predict the likelihood of a candidate for pregnancy or choose a more aggressive person who fits into the corporate culture."}, {"heading": "2.4. Employment Shift - Economic Disparity - Wealth Distribution", "text": "According to an Oxford University study (2016), 47% of existing jobs will have to be replaced by automation, while 69% of existing jobs in China and 75% of jobs in India will be replaced in the future. European Commission (2016) forecasts that 90% of jobs will be replaced by basic digital skills. In addition to causing a shift in employment, the new revolution will also widen the wealth gap and lead to economic disparity. A highly controversial solution is the Universal Basic Income, which would act as a buffer. A classic example is the following analogy. With Roomba's arrival, the time spent on cleaning will not decrease, but remain constant."}, {"heading": "3. SOLUTIONS TO ETHICAL ISSUES", "text": "This year, it has come to the point where we will be able to go in search of a solution that is capable, that we are able, that we are able to find a solution that is capable of us, that we are able, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution."}, {"heading": "4. AI SAFETY AS AN IMPORTANT FACE OF THE MADELLION", "text": "Taking ethical AI into account, various rapidly growing research interests have been raised in connection with the possibility of harmful effects of artificial intelligence, which are generally based on fears about the creation of uncontrolled, not very well-educated or \"very well-educated\" artificial intelligence capable of causing dangerous or harmful effects on human life and the existence of humans or living organisms. This research interest, which is called the \"butterfly effect,\" is often structured to achieve the best artificial intelligence systems that are friendly to humans. As artificial intelligence is a creation of humanity, it is always assumed that such a creation can address humanity's faults, which ultimately show the \"butterfly effect,\" while solving important ethical problems in the real world. If the related literature is examined, it can be seen that the concept of artificial security technology has already been proposed (Yampolskiy, 2013). Here Yampskiy argues that systems are safe (2013)."}, {"heading": "5. CONCLUSIONS AND FUTURE WORK", "text": "AI can solve the intractable problems. Humans must be part of their development so that AI can help increase human ingenuity and create a culture based on cooperation. There is no consensus on societal norms or on the ethical principles that AI should currently follow. Until ethics becomes a critical component of human behavior, there is not a very good answer to AI safety. But nowadays, there is also a remarkable interest in ensuring the safety of AI. Creating a human-friendly environment and a human-friendly environment for AI can be a possible answer to finding a common value context for both humans and robots. The process of teaching machines to be more human can have a positive impact on humans and make people more human. From now on, humanity has the chance to realign their values accordingly, to change and improve their ethical behavior, and to rethink their contribution to society on a deeper level."}, {"heading": "5.1. Further Subjects to be Focused on", "text": "The topics of privacy, liability, rules and regulations, human rights and robotic rights, super intelligence and security interests in the field of artificial intelligence, such as specific (i.e. interruptible, ignorant) agents, rationality, correctability and reverse learning, were not dealt with in detail in this research paper due to the breadth of the topic chosen. On the other hand, the paper was not prepared on technical details for particularly security-oriented problems in the field of artificial intelligence. In this context, the research of \"agents\" is an important research method that should be taken into account. Finally, after the references section, an additional reading (extended bibliography) was given to give interested readers the opportunity to deal more specifically with other theoretical and applied topics."}, {"heading": "5.2. Future Works", "text": "In this sense, some future applied work is planned, including the provision of prototypes of some designed ethical models of intelligent agents, and additional theories that can be introduced through applied approaches will be introduced in the accompanying literature in the next reports."}], "references": [{"title": "Artificial intelligence as a positive and negative factor in global risk", "author": ["E. Yudkowsky"], "venue": "Global Catastrophic Risks,", "citeRegEx": "Yudkowsky,? \\Q2008\\E", "shortCiteRegEx": "Yudkowsky", "year": 2008}, {"title": "Moral Machines and the Threat of Ethical Nihilism. Robot ethics: The ethical and social implications of robotics", "author": ["A. Belloni", "A. Berger", "O. Boissier", "G. Bonnet", "G. Bourgne", "P.A. Chardel", "B. Mermet"], "venue": null, "citeRegEx": "Belloni et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Belloni et al\\.", "year": 2011}, {"title": "Ethical Artificial Intelligence - An Open Question", "author": ["A. Pavaloiu", "Kose", "N.U. Bostrom"], "venue": "Future of Life Institute. Retrieved", "citeRegEx": "Pavaloiu et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Pavaloiu et al\\.", "year": 2017}, {"title": "The ethics of artificial intelligence. The Cambridge Handbook of Artificial Intelligence, 316-334", "author": ["N. Bostrom", "E. Yudkowsky"], "venue": null, "citeRegEx": "Bostrom and Yudkowsky,? \\Q2014\\E", "shortCiteRegEx": "Bostrom and Yudkowsky", "year": 2014}, {"title": "Is It Morally Acceptable for A System to Lie to Persuade Me", "author": ["M. Guerini", "F. Pianesi", "O. Stock"], "venue": "Conference on Artificial Intelligence. Retrieved", "citeRegEx": "Guerini et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Guerini et al\\.", "year": 2017}, {"title": "On Keeping Secrets: Intelligent Agents and the Ethics of Information Hiding", "author": ["A. Hunter"], "venue": "In Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence. Retrieved", "citeRegEx": "Hunter,? \\Q2015\\E", "shortCiteRegEx": "Hunter", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Furthermore, the interest of future of AI and some connected interests like singularity (Goertzel, 2007; Kurzweil, 2005) and existential risk (Bostrom, 2002; Yudkowsky, 2008) are also other important factors shaping the whole literature of AI and its ethical \u2013 safe \u2013 future sides.", "startOffset": 142, "endOffset": 174}], "year": 2017, "abstractText": "Artificial Intelligence (AI) is an effective science which employs strong enough approaches, methods, and techniques to solve unsolvable real-world based problems. Because of its unstoppable rise towards the future, there are also some discussions about its ethics and safety. Shaping an AI-friendly environment for people and a people-friendly environment for AI can be a possible answer for finding a shared context of values for both humans and robots. In this context, objective of this paper is to address the ethical issues of AI and explore the moral dilemmas that arise from ethical algorithms, from pre-set or acquired values. In addition, the paper will also focus on the subject of AI safety. As general, the paper will briefly analyze the concerns and potential solutions to solving the ethical issues presented and increase readers\u2019 awareness on AI safety as another related research interest.", "creator": "Microsoft\u00ae Word 2016"}}}