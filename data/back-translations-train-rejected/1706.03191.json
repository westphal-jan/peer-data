{"id": "1706.03191", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2017", "title": "Classification of Questions and Learning Outcome Statements (LOS) Into Blooms Taxonomy (BT) By Similarity Measurements Towards Extracting Of Learning Outcome from Learning Material", "abstract": "Blooms Taxonomy (BT) have been used to classify the objectives of learning outcome by dividing the learning into three different domains; the cognitive domain, the effective domain and the psychomotor domain. In this paper, we are introducing a new approach to classify the questions and learning outcome statements (LOS) into Blooms taxonomy (BT) and to verify BT verb lists, which are being cited and used by academicians to write questions and (LOS). An experiment was designed to investigate the semantic relationship between the action verbs used in both questions and LOS to obtain more accurate classification of the levels of BT. A sample of 775 different action verbs collected from different universities allows us to measure an accurate and clear-cut cognitive level for the action verb. It is worth mentioning that natural language processing techniques were used to develop our rules as to induce the questions into chunks in order to extract the action verbs. Our proposed solution was able to classify the action verb into a precise level of the cognitive domain. We, on our side, have tested and evaluated our proposed solution using confusion matrix. The results of evaluation tests yielded 97% for the macro average of precision and 90% for F1. Thus, the outcome of the research suggests that it is crucial to analyse and verify the action verbs cited and used by academicians to write LOS and classify their questions based on blooms taxonomy in order to obtain a definite and more accurate classification.", "histories": [["v1", "Sat, 10 Jun 2017 07:02:57 GMT  (356kb)", "http://arxiv.org/abs/1706.03191v1", "12 pages, 5 figures, 2 tables, Journal paper"]], "COMMENTS": "12 pages, 5 figures, 2 tables, Journal paper", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["shadi diab", "badie sartawi"], "accepted": false, "id": "1706.03191"}, "pdf": {"name": "1706.03191.pdf", "metadata": {"source": "CRF", "title": "CLASSIFICATION OF QUESTIONS AND LEARNING OUTCOME STATEMENTS (LOS) INTO BLOOM\u2019S TAXONOMY (BT) BY SIMILARITY MEASUREMENTS TOWARDS EXTRACTING OF LEARNING OUTCOME FROM LEARNING MATERIAL", "authors": ["Shadi Diab", "Badie Sartawi"], "emails": [], "sections": [{"heading": null, "text": "DOI: 10.5121 / ijmit.2017.9201 1Blooms Taxonomy (BT) was used to classify the learning objectives by dividing learning into three distinct areas: the cognitive area, the effective area and the psychomotor area. In this work, we introduce a new approach to classify the questions and learning outcome statements (LOS) in Blooms Taxonomy (BT) and verify BT verbs lists, which are quoted by academics and used for writing questions and (LOS). An experiment was developed to investigate the semantic relationship between the actionverbs used in both questions and LOS in order to obtain a more accurate classification of BT levels. A sample of 775 different actionverbs collected by different universities allows us to find an accurate and clearly defined cognitive level for the actionverbs used in both questions and LOS. It is worth noting that natural language processing techniques were used to extract the 97% of the questions in order to more precisely adhere to the answers to the questions."}, {"heading": "90% for F1. Thus, the outcome of the research suggests that it is crucial to analyse and verify the action verbs cited and used by academicians to write LOS and classify their questions based on blooms taxonomy in order to obtain a definite and more accurate classification.", "text": "KEYWORDSLearning outcomes; processing natural language, similarity measurement; classification of questions"}, {"heading": "1. INTRODUCTION", "text": "The new international trends in education show a shift in the approach towards a \"student approach,\" which in turn focuses on what is expected of students at the end of the learning process."}, {"heading": "2. LITERATURE AND RELATED WORK", "text": "This year, it has reached the point where it is only half as much as it is half."}, {"heading": "3. SEMANTIC SIMILARITY MEASUREMENT", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Semantic Similarity", "text": "Semantic similarity has long been a matter of concern in artificial intelligence, psychology and cognitive science. In recent years, measurements based on WordNet have shown their capabilities and caused great concern [18]. Researchers have used semantic affinity metrics to perform the task of decoding the meaning of words [19]. Semantic similarity measurements can generally be divided into four categories: on the basis of distance similarity between two concepts; on the basis of information that the two concepts share; on the properties of the concepts; and on a combination of the previous options [20]."}, {"heading": "3.2 Wordnet", "text": "WordNet is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into groups of synonyms (synsets). Synsets are linked by conceptual-semantic and lexical relationships. It comprises 82115 nouns, 13767 verbs, 18156 adjectives, 3621 adverbs [21]. The similarity metric of Wu and Palmer (Wu and Palmer, 1994) measures semantic similarity by the depth of the two concepts in the WordNet taxonomy [22]. However, there are some important distinctions: First, WordNet not only links word forms with letter strings, but also specific sense of words. As a result, words found in close proximity to each other on the network are semantically disambiguated. Second, WordNet denotes the semantic relationships between words, whereas groupings of words in a thesaurus do not explicitly follow the pattern of similarity."}, {"heading": "4. RESEARCH\u2019S METHODOLOGY", "text": "In our research, we focused on the verbs of action that should be used to write questions and LOS at the cognitive level by analyzing the questions and LOS. We observed that the categorization of verbs of action may occur at different levels of the cognitive area, so that you can find the verb at knowledge, application, understanding or analysis levels. This classification depends on the understanding of the verbs of action that are classified by domain experts. Academics would manually classify the question at taxonomy level based on their styles [11]. In our research, we will answer the following questions: How can we divide the question and LOS into one or more levels of the cognitive area by applying semantic similarity measurements? Does our proposed approach apply to the two remaining areas of BT? Will mantic similarity between the question and the LOS help improve action trajectories?"}, {"heading": "5. COLLECTING DATA FROM DOMAIN EXPERTS", "text": "We have observed that many universities around the world have created guides and publications for their teachers to help them write questions and LOS based on BT. The guides that classify the action verb are used as a reference for classifying the action verbs in BT. Assuming that teachers use guides and supporting publications from their schools and universities to write questions and LOS, we have collected 605 different action verbs that describe the cognitive abilities at each level of websites at different universities [24] [25] [26] [27]. In order to get more accurate and precise data, we filtered and modified the data lists by collecting the verbs that overlap with three or four lists (threshold 75-100%). In addition, we have added verbs that overlap with two resources when and only when they do not conflict with other lists (threshold 50%). The result was a new dataset containing 77 different action verbs distributed over the six cognitive levels of the BT."}, {"heading": "6. STRUCTURAL INDUCTION OF THE QUESTION", "text": "Structural induction can be defined as the process of extracting structural information using machine learning techniques and the patterns found for classifying the questions. [29] This allows us to take over some parts of the question and leave the others for further processing. Our experiment aims to extract the actionable verb of the question by using structural induction. Using the question starters collected from [28], we were able to extract the verbs of action of the questions during the implementation of the following steps: splitting the questions into individual lines, tokenization, lemmatization, POS tagging, partial parser on grammar, recognition of the level of knowledge of the cognitive domain based on the starters of the question: Q: How would you explain informatics on a five-year-old verbs of action on the question?"}, {"heading": "7. THE PROPOSED ACTION VERBS CLASSIFICATION ALGORITHM", "text": "Different verbs can be used to demonstrate different levels of learning, for example: the basic level of learning outcomes requires that learners are able to define, retrieve, describe, explain or discuss [2]. Furthermore, the verb is considered to be the centre, fulcrum and fulcrum of a learning outcome statement. We should note that verbs refer to events, not to states; events are specific actions [3]. Therefore, our proposed solution relies on the classification of the verbs of action of the questions or LOS to classify the whole question or LOS into a more precise level. The following definitions and steps describe our algorithm: BTD (Bloom's Taxonomy Dimensions) = [C, A, P] where the cognitive, affective and psychomotor domains are each at the level of LOS."}, {"heading": "8. ACTION VERBS CLASSIFICATION ALGORITHM (AVCA)", "text": "For the sake of simplicity, it should be noted that our algorithm and implementation are applied to the cognitive domain, while the data (verbs) represent the cognitive domain, which represent other domains, but with other verbs, in addition, our algorithm can accept all input data in the form of verbs, regardless of whether they are related to cognitive, affective or psychomotor verbs, the proposed algorithm measures the similarity between verb groups and steps as follows: (pseudo-code): AVCA algorithm (VQ [0... M], CL [1... N], Maxsim [1... 6], Maxsim [1... M], and the list of verb-sim algorithms in the cognitive domain CL, where CL = [LCL1...] and the total set of similarity values / / input: list of action verbs containing questions or LOS, VQ [1], VM-Q [... and Vsib]."}, {"heading": "9. EXPERIMENT AND ANALYSIS", "text": "Our classification algorithm applied the constructed verbal lists of questions and LOS to calculate the maximum similarity for each level of the cognitive range. Then, it compares the maximum similarities to nominate (the larger) one and only one level as the exact level for the classified verb. Our experiment was built on the collected data from [24] [25] [26] [27]. Such data was created to assist academics in writing questions and LOS, we observed the following behaviors and cases: Identical similarity occurs when the synsets of the action verbs have a similarity value with one or more verbs in the lists of the cognitive range. Thus, Figure 2 shows that the verb compile has a similarity value with the verb that can be rolled up at the synthesis level. We can conclude that the verb compile is much closer to the synthesis level than the drama of the other level."}, {"heading": "10. ENHANCEMENT OF THE ACTION VERBS LIST", "text": "All verbs were tested against each verb in our collected data [24] [25] [26] [27]. We found that our proposed algorithm could improve the correctness of categorization based on cognitive blood taxonomy from an average of 71% to 97%. However, our algorithm found that (34%) in turn decreased the proportion of misclassified verbs from 34% to 8%. The improvised average was 97% for both data sets as a result of applying a threshold of \u2265 50% as evidence from our source data."}, {"heading": "11. EVALUATION AND RESULTS", "text": "We evaluated our algorithm to measure performance and the results we achieved. We used a confusion matrix, which is often used to describe the performance of the classification model [33], to measure the following values: \u2022 True Positives (TP) is the number of correctly predicted positive values. We count the number of cases in which the result of the classification is wrong and the actual verb is also indifferent. (Both of our predicted results and the actual verb are not at the correct level.) \u2022 False Positives (FP) are the number of cases in which the result of the classification is wrong."}, {"heading": "12. CONCLUSION", "text": "In this paper, we introduced the classification problem of the questions and the LOS into the blood taxonomy, exploring the rules-based approach to introduce the most important part of the question. Such parts, including the action verb of the question, lead us to measure the exact level of the action verb in the cognitive area. We also conducted an analysis of the currently used action verb lists as a guide for academics and proposed a new method to measure the relationship between these verbs, the verb of the question and the learning outcome statements (LOS). We also adapted similarity measurements to ensure a precise classification of such verbs by two methods; taking advantage of the maximum similarity and calculating the total similarity range for each six of the cognitive hierarchy. We confirmed and proved that our proposed solution will transform the classified action verbs into more precise levels. Later, we evaluated our proposed method by incorporating the benchmarked cognitive macrix and a very high pregnitive list of all the pre-cognitive questions."}, {"heading": "13. FUTURE WORK", "text": "In order to automatically convert the whole question to LOS, a thorough syntax analysis is required. Furthermore, the analysis of numbers such as images, graphs and tables to construct LOS, which represents the goals behind such numbers, is very important for constructing LOS from learning material."}], "references": [{"title": "Writing and using learning outcomes: a practical guide, Page 18, Cork: University", "author": ["Declan Kennedy"], "venue": "College Cork,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Repository services for outcome-based learning", "author": ["Totschnig", "Michael"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "The Use of Questions in Teaching", "author": ["M.D. Gall"], "venue": "American Educational Research Association, vol. 40, no. 5, pp. 707-721, 1970.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1970}, {"title": "Learning Question Classifiers", "author": ["Li", "Roth"], "venue": "Illinois USA: 19th International Conference on Compuatational Linguistics (COLING)", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2002}, {"title": "Automatic Applying Bloom's Taxonomy to Classify and Analysis the cognition level of english questions items, Taiwan", "author": ["Wen-Chih Chang", "Ming-Shun Chung"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Automatic extraction of prerequisites and learning outcome from learning material, India", "author": ["Sonal Jain", "Jyoti Pareek"], "venue": "Inderscience Enterprises Ltd.,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "A Rule-based Approach in Bloom\u2019s Taxonomy Question Classification through Natural Language, Malaysia", "author": ["Syahidah Haris", "Nazila Omar"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Question Classification Using Syntactic And Rule Based Approach", "author": ["Payal Biswas"], "venue": "New Delhi: International Conference on Advances in Computing,Communications and Informatics (ICACCI),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Question Classification using Support Vector Machines, Singapore", "author": ["Dell Zhang"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "Two Level Question Classification Based on SVM and Question Semantic Similarity, Beijing", "author": ["Jibin Fu"], "venue": "China: International Conference on Electronic Computer Technology,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Automatic Classification Of Questions Into Bloom's Cognitive Levels Using Support Vector Machines, Najran: Researchgate", "author": ["Anwar Ali Yahya", "Addin Osman"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "An automatic classifer for exam questions with wordnet and cosine, International Journal of Emerging Technologies in Learning (iJET", "author": ["J K"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "A Review of Semantic Similarity Measures in WordNet", "author": ["Lingling Meng"], "venue": "International Journal of Hybrid Information Technology, vol. 6, no. 1, p. 1, 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Using Measures of Semantic Relatedness for Word Sense Disambiguation", "author": ["Siddharth Patwardhan"], "venue": "Springer, p. 241\u2013257, 2003.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2003}, {"title": "Semantic Similarity Methods in WordNet and Their Application to Information Retrieval on the Web", "author": ["G.V. e. al"], "venue": "ACM New York, NY, USA \u00a92005, pp. 10-16, 2005.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2005}, {"title": "WordNet - A Lexical Database for English", "author": ["G.A. Miller"], "venue": "Communications of the ACM, vol. 38, no. 11, pp. 39-41, 2005. International Journal of Managing Information Technology (IJMIT) Vol.9, No.2, May 2017 12", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2005}, {"title": "Measuring the Semantic Similarity of Texts", "author": ["C.C. a. R. Mihalcea"], "venue": "University of North Texas: University of North Texas,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "VERB SEMANTICS AND LEXICAL SELECTION", "author": ["Z.W. a. M. Palmer"], "venue": "In Proceedings of the 32nd Annual Meeting of the Associations for Computational Linguistics, Las Cruces, New Mexico,, 1994.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1994}, {"title": "Bloom's Taxonomy of Cognitive Skills with Action Verb List Source", "author": ["Virginia.ED"], "venue": "University of Verginia, 20 2 2017. [Online]. Available: http://avillage.web.virginia.edu/iaas/assess/resources/verblist.pdf. [Accessed 20 2 2017].", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2017}, {"title": "Bloom's Taxonomy", "author": ["U.O.C. Florida"], "venue": "University of Central Florida, 20 2 2017. [Online]. Available: http://www.fctl.ucf.edu/teachingandlearningresources/coursedesign/bloomstaxonomy/. [Accessed 20 2 2017].", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2017}, {"title": "Bloom\u2019s Taxonomy Action Verbs", "author": ["M.S. University"], "venue": "Missouri State University, 20 2 2017. [Online]. Available: https://www.missouristate.edu/assets/fctl/Blooms_Taxonomy_Action_Verbs.pdf. [Accessed 20 2 2017].", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2017}, {"title": "Bloom's Taxonomy Verbs", "author": ["C.A. College"], "venue": "Central Arizona College, 20 2 2017. [Online]. Available: http://www.centralaz.edu/Documents/class/Bloom's%20Taxonomy%20Verbs%20Web.pdf. [Accessed 20 2 2017].", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2017}, {"title": "http://www.bloomstaxonomy.org", "author": ["F. Kugelman"], "venue": "6 2 2017. [Online]. Available: http://www.bloomstaxonomy.org/BloomsTaxonomyquestions.pdf. [Accessed 06 02 2017].", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2017}, {"title": "Question classification by structure induction", "author": ["Zaanen"], "venue": "IJCAI'05 Proceedings of the 19th international joint conference on Artificial intelligence, Edinburgh, Scotland , 2005.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2005}, {"title": "The Language and Syntax of Learning Outcomes Statements", "author": ["C. Adelman"], "venue": "National Institute for Learning Outcomes Assessment,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "Bloom\u2019s Taxonomy Action Verbs", "author": ["Fresnostate university"], "venue": "[Online]. Available: http://www.fresnostate.edu/academics/oie/documents/assesments/Blooms%20Level.pdf. [Accessed 4 3 2017].", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2017}, {"title": "Simple guide to confusion matrix terminology", "author": ["K. Markham"], "venue": "dataschool, [Online]. Available: http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/. [Accessed 07 03 2017].", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2017}], "referenceMentions": [{"referenceID": 0, "context": "Statements called intended learning outcomes, commonly shortened to learning outcomes, are being used to express what the students are expected to be able to do at the end of the learning period [1].", "startOffset": 195, "endOffset": 198}, {"referenceID": 1, "context": "2 outcome definitions they can link to their courses [3].", "startOffset": 53, "endOffset": 56}, {"referenceID": 2, "context": "It is a truism for educators that questions play an important role in teaching [6].", "startOffset": 79, "endOffset": 82}, {"referenceID": 0, "context": ", 1956) has become widely used throughout the world to assist in the preparation of evaluation materials [1].", "startOffset": 105, "endOffset": 108}, {"referenceID": 3, "context": "In [8] they classified learning questions through a machine learning approach, and learned a hierarchical classifier guided by a layered semantic hierarchy of answer types.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "Keywords database matching with the verb of the question method has been developed, piloted and tested for automatic Bloom's taxonomy analysis, that matches all levels of cognitive domain of bloom [9], the results have shown that the knowledge level achieved 75% correct match in comparison with the expert\u2019s results.", "startOffset": 197, "endOffset": 200}, {"referenceID": 5, "context": "[10] They proposed natural language processing-based automatic concept extraction and outlines rule-based approach for separation of prerequisite concepts and learning outcomes covered in learning document, by their manual creation of domain ontology.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[11] They also proposed rule-based approach to analyse and classify written examination questions through natural language processing for computer programming subjects, the rules were developed using the syntactic structure of each question to apply the pattern of each question to the cognitive level of bloom.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[13] researchers have taken data of Li and Roth in [8] to classify the questions into three broad categoris instead of 6 course grain and and 50 fine grained categories.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[13] researchers have taken data of Li and Roth in [8] to classify the questions into three broad categoris instead of 6 course grain and and 50 fine grained categories.", "startOffset": 51, "endOffset": 54}, {"referenceID": 8, "context": "[14] They also classified questions with different five machine learning algorithms: Nearest Neighbours (NN); Na\u00efve Bayes (NB); Decision Tree (DT); Sparse Network of Winnows (SNoW); and Support Vector Machines (SVM).", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[15] They proposed two Level Question Classification based on SVM and Question Semantic Similarity in computer service & support domain, their results showed that question classification dramatically improves when complementing the domain ontology knowledge with questionspecific domain concepts.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[16] They also explored the effectiveness of support vector machines (SVMs) to classify questions, their evaluation showed the micro was 87.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Most of these researchers used huge amount of data and domain ontology to run their experiments, including the need to domain-experts to evaluate the performance, we consider [17] is the most related research to our approach.", "startOffset": 175, "endOffset": 179}, {"referenceID": 12, "context": "In recent years, the measures based on WordNet have shown its capabilities and attracted great concern [18].", "startOffset": 103, "endOffset": 107}, {"referenceID": 13, "context": "Researchers used measure of semantic relatedness to perform the task of word sense disambiguation [19].", "startOffset": 98, "endOffset": 102}, {"referenceID": 14, "context": "Semantic similarity measures can be generally partitioned based on four grounds: based on the distance similarity between two concepts; based on information the two concepts share; based on the properties of the concepts; and based on a combination of the previous options [20].", "startOffset": 273, "endOffset": 277}, {"referenceID": 15, "context": "It includes 82115 nouns, 13767 verbs, 18156 adjectives, 3621 adverbs [21].", "startOffset": 69, "endOffset": 73}, {"referenceID": 16, "context": "The Wu and Palmer (Wu and Palmer, 1994) similarity metric measures semantic similarity through the depth of the two concepts in the WordNet taxonomy [22].", "startOffset": 149, "endOffset": 153}, {"referenceID": 16, "context": "4 whereas the groupings of words in a thesaurus does not follow any explicit pattern other than meaning similarity [22].", "startOffset": 115, "endOffset": 119}, {"referenceID": 17, "context": "Wu-Palmer representation scheme does not only take care of the semantic-syntactic correspondence, but it also provides similarity measures for the system for the performance of inexact matches based on verb meanings [23].", "startOffset": 216, "endOffset": 220}, {"referenceID": 6, "context": "Academicians would manually classify the question into taxonomy level based on their styles [11].", "startOffset": 92, "endOffset": 96}, {"referenceID": 18, "context": "By assuming that the teachers use guides and supportive publications of their schools and universities in order to write questions and LOS, We collected 605 different action verbs that describe the cognitive skills in each level from websites of different universities [24] [25] [26] [27].", "startOffset": 269, "endOffset": 273}, {"referenceID": 19, "context": "By assuming that the teachers use guides and supportive publications of their schools and universities in order to write questions and LOS, We collected 605 different action verbs that describe the cognitive skills in each level from websites of different universities [24] [25] [26] [27].", "startOffset": 274, "endOffset": 278}, {"referenceID": 20, "context": "By assuming that the teachers use guides and supportive publications of their schools and universities in order to write questions and LOS, We collected 605 different action verbs that describe the cognitive skills in each level from websites of different universities [24] [25] [26] [27].", "startOffset": 279, "endOffset": 283}, {"referenceID": 21, "context": "By assuming that the teachers use guides and supportive publications of their schools and universities in order to write questions and LOS, We collected 605 different action verbs that describe the cognitive skills in each level from websites of different universities [24] [25] [26] [27].", "startOffset": 284, "endOffset": 288}, {"referenceID": 22, "context": "Moreover, questions starters from [28], which organize the starters of questions that cover each level of the cognitive domain of BT, has been collected.", "startOffset": 34, "endOffset": 38}, {"referenceID": 23, "context": "Structural induction may be defined as the process of extracting structural information using machine learning techniques and the patterns found may use to classify the questions [29].", "startOffset": 179, "endOffset": 183}, {"referenceID": 22, "context": "Using the questions starters collected from [28], we were able to extract the action verb of the questions throughout implementing the following steps:", "startOffset": 44, "endOffset": 48}, {"referenceID": 22, "context": "For example, running partial parsing over manually built in grammar to detect the knowledge level of the cognitive domain based on starters of [28]: Q: How would you explain computer science to a five-year-old? Steps will return the chunked tree labelled with \"KNOW\" as in Figure 1, while the main action verb explain refers to the knowledge level of BT", "startOffset": 143, "endOffset": 147}, {"referenceID": 24, "context": "We should note that verbs refer to events, not to states; events are specific actions [30].", "startOffset": 86, "endOffset": 90}, {"referenceID": 18, "context": "Our experiment was built based on the collected data from [24] [25] [26] [27].", "startOffset": 58, "endOffset": 62}, {"referenceID": 19, "context": "Our experiment was built based on the collected data from [24] [25] [26] [27].", "startOffset": 63, "endOffset": 67}, {"referenceID": 20, "context": "Our experiment was built based on the collected data from [24] [25] [26] [27].", "startOffset": 68, "endOffset": 72}, {"referenceID": 21, "context": "Our experiment was built based on the collected data from [24] [25] [26] [27].", "startOffset": 73, "endOffset": 77}, {"referenceID": 25, "context": "We validate our proposed algorithm on new data sets of action verbs collected from different resources from [31] [32].", "startOffset": 113, "endOffset": 117}, {"referenceID": 18, "context": "All verbs were tested against each verb in our collected data [24] [25] [26] [27].", "startOffset": 62, "endOffset": 66}, {"referenceID": 19, "context": "All verbs were tested against each verb in our collected data [24] [25] [26] [27].", "startOffset": 67, "endOffset": 71}, {"referenceID": 20, "context": "All verbs were tested against each verb in our collected data [24] [25] [26] [27].", "startOffset": 72, "endOffset": 76}, {"referenceID": 21, "context": "All verbs were tested against each verb in our collected data [24] [25] [26] [27].", "startOffset": 77, "endOffset": 81}, {"referenceID": 26, "context": "We used confusion matrix, which is often used to describe the performance of classification model [33] in order to measure the following values:", "startOffset": 98, "endOffset": 102}, {"referenceID": 25, "context": "Evaluation of our algorithm was based on unseen data collected from [31] [32].", "startOffset": 73, "endOffset": 77}, {"referenceID": 18, "context": "Moreover, a threshold of \u2265 50% used to measure the actual level of each verb in [24] [25] [26] [27].", "startOffset": 80, "endOffset": 84}, {"referenceID": 19, "context": "Moreover, a threshold of \u2265 50% used to measure the actual level of each verb in [24] [25] [26] [27].", "startOffset": 85, "endOffset": 89}, {"referenceID": 20, "context": "Moreover, a threshold of \u2265 50% used to measure the actual level of each verb in [24] [25] [26] [27].", "startOffset": 90, "endOffset": 94}, {"referenceID": 21, "context": "Moreover, a threshold of \u2265 50% used to measure the actual level of each verb in [24] [25] [26] [27].", "startOffset": 95, "endOffset": 99}, {"referenceID": 26, "context": "\u2022 Accuracy: The simplest metric that can be used for evaluation; it measures the percentage of inputs in the test set that the classifier correctly labeled [33].", "startOffset": 156, "endOffset": 160}, {"referenceID": 26, "context": "it also can be measured by calculating TP+TN/TP+FP+FN+TN [34] \u2022 Precision: Indicates how many of our items that we identified were relevant and can be measured by calculating TP/ (TP+FP) [33].", "startOffset": 187, "endOffset": 191}, {"referenceID": 26, "context": "\u2022 Recall: Indicates how many of the relevant items that we identified, and measured by TP/ (TP+FN) [33].", "startOffset": 99, "endOffset": 103}, {"referenceID": 26, "context": "F1 is defined to be the harmonic mean of the precision and recall and measured as follow: (2 \u00d7 Precision \u00d7 Recall)/ (Precision Recall) [33].", "startOffset": 135, "endOffset": 139}, {"referenceID": 25, "context": "The obtained results after processing the test sets in [31] and [32] are summarized in table 1 and table 2.", "startOffset": 64, "endOffset": 68}], "year": 2017, "abstractText": "Bloom\u2019s Taxonomy (BT) have been used to classify the objectives of learning outcome by dividing the learning into three different domains; the cognitive domain, the effective domain and the psychomotor domain. In this paper, we are introducing a new approach to classify the questions and learning outcome statements (LOS) into Blooms taxonomy (BT) and to verify BT verb lists, which are being cited and used by academicians to write questions and (LOS). An experiment was designed to investigate the semantic relationship between the action verbs used in both questions and LOS to obtain more accurate classification of the levels of BT. A sample of 775 different action verbs collected from different universities allows us to measure an accurate and clear-cut cognitive level for the action verb. It is worth mentioning that natural language processing techniques were used to develop our rules as to induce the questions into chunks in order to extract the action verbs. Our proposed solution was able to classify the action verb into a precise level of the cognitive domain. We, on our side, have tested and evaluated our proposed solution using confusion matrix. The results of evaluation tests yielded 97% for the macro average of precision and 90% for F1. Thus, the outcome of the research suggests that it is crucial to analyse and verify the action verbs cited and used by academicians to write LOS and classify their questions based on blooms taxonomy in order to obtain a definite and more accurate classification.", "creator": "PScript5.dll Version 5.2.2"}}}