{"id": "1706.03661", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jun-2017", "title": "DAC-h3: A Proactive Robot Cognitive Architecture to Acquire and Express Knowledge About the World and the Self", "abstract": "This paper introduces a cognitive architecture for a humanoid robot to engage in a proactive, mixed-initiative exploration and manipulation of its environment, where the initiative can originate from both the human and the robot. The framework, based on a biologically-grounded theory of the brain and mind, integrates a reactive interaction engine, a number of state-of-the art perceptual and motor learning algorithms, as well as planning abilities and an autobiographical memory. The architecture as a whole drives the robot behavior to solve the symbol grounding problem, acquire language capabilities, execute goal-oriented behavior, and express a verbal narrative of its own experience in the world. We validate our approach in a human-robot interaction experiment with the iCub humanoid robot, showing that the proposed cognitive architecture can be applied in real time within a realistic scenario.", "histories": [["v1", "Mon, 12 Jun 2017 14:39:43 GMT  (6780kb,D)", "http://arxiv.org/abs/1706.03661v1", "In revision in IEEE Transactions on Cognitive and Developmental Systems"], ["v2", "Mon, 18 Sep 2017 22:22:15 GMT  (3899kb,D)", "http://arxiv.org/abs/1706.03661v2", "Preprint version; final version available atthis http URLIEEE Transactions on Cognitive and Developmental Systems (Accepted) DOI: 10.1109/TCDS.2017.2754143"]], "COMMENTS": "In revision in IEEE Transactions on Cognitive and Developmental Systems", "reviews": [], "SUBJECTS": "cs.AI cs.RO", "authors": ["cl\\'ement moulin-frier", "tobias fischer", "maxime petit", "gr\\'egoire pointeau", "jordi-ysard puigbo", "ugo pattacini", "sock ching low", "daniel camilleri", "phuong nguyen", "matej hoffmann", "hyung jin chang", "martina zambelli", "anne-laure mealier", "reas damianou", "giorgio metta", "tony j prescott", "yiannis demiris", "peter ford dominey", "paul f m j verschure"], "accepted": false, "id": "1706.03661"}, "pdf": {"name": "1706.03661.pdf", "metadata": {"source": "CRF", "title": "DAC-h3: A Proactive Robot Cognitive Architecture to Acquire and Express Knowledge About the World and the Self", "authors": ["Cl\u00e9ment Moulin-Frier", "Tobias Fischer", "Maxime Petit", "Gr\u00e9goire Pointeau", "Jordi-Ysard Puigbo", "Ugo Pattacini", "Sock Ching Low", "Daniel Camilleri", "Phuong Nguyen", "Matej Hoffmann", "Hyung Jin Chang", "Martina Zambelli", "Anne-Laure Mealier", "Andreas Damianou", "Giorgio Metta", "Tony J. Prescott", "Yiannis Demiris", "Peter Ford Dominey", "Paul F. M. J. Verschure"], "emails": [], "sections": [{"heading": null, "text": "In fact, most people who are able to understand themselves and their environment are not able to understand themselves. In fact, it is that they are able to understand the world and what they are doing. In fact, most people who are able to understand themselves and their environment are not able to understand themselves."}, {"heading": "II. RELATED WORKS AND PRINCIPLES OF THE PROPOSED ARCHITECTURE", "text": "In this section, we discuss related work on each of the topics related to the characteristics of the proposed cognitive architecture. These characteristics are: (A) a biologically based cognitive architecture that ensures autonomy, learning and goal-oriented behavior; (B) the ability to resolve the Stability Pact by acquiring symbols based on physical interaction with the (social) environment; (C) proactivity as a method for improving HRI and self-monitoring of knowledge acquisition; (D) goal-oriented behavior supported by the learned symbol; and (E) autobiographical memory expressed through verbal narration."}, {"heading": "A. Functionally-driven vs. biologically-inspired approaches in social robotics", "text": "The conception of socially interactive robots is based on two main approaches [19]. On the one hand, functionally conceived approaches are based on methods of reverse engineering, assuming that a deep understanding of the functioning of the mind is not a prerequisite for the conception of socially competent robots (e.g. [20], [21], [22]). On the other hand, biologically inspired robots are based on natural and social science theories and expect two main advantages of limiting cognitive models by biological knowledge: the better comprehensibility of robots for humans, since they are based on similar principles, and the provision of an efficient experimental yardstick from which the underlying theories can be compared, tested and refined (e.g. [23], [24]). The proposed cognitive architecture DAC-h3 uses both methods and is based on an established biologically based cognitive architecture of the brain and mind (the DAC theory shown below), which is adapted for the HRI domain."}, {"heading": "B. Cognitive architectures and the SGP", "text": "In fact, most of them are not able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "C. Solving the SGP", "text": "Other contributions focused on grounding a lexicon of the physical interaction of a robot with its environment. Since the pioneering paradigm of \"language games\" proposed in [42], a series of multi-agent models have been proposed that show how certain characteristics of language can self-organize from repeated dyadic interactions between actors of a population (e.g. [43], [44]). In the field of HRI, contributions have focused on acquiring lexicon by transferring sensorimotor and linguistic information from the interaction between a teacher and a learner through imitation [45], action [46], [47] or active exploration [48]. In all of these contributions, the solution of the SGP requires the integration of multimodal information about units of the outside world (physical SGP) with linguistic labels acquired or negotiated through interaction with social peers (social SGP). In the proposed DAC-h3 architecture, active actions with the body objects are represented either by physical entities or by SGP."}, {"heading": "D. Autonomous exploration and proactive behavior in HRI", "text": "In this case, the robot must solve the reference indeterminity problem described by Quine [12], where the robot speaker must filter out the external concept to which a human speaker refers. However, acquiring symbols through interaction with other actors is not just a unidirectional process of information exchange between a teacher and a learner. Autonomous exploration and proactive behavior enable robots to take the initiative and interact with humans."}, {"heading": "E. Language learning, autobiographical memory and narrative expression", "text": "The cognitive architecture of iTalk [53] focuses on modeling the emergence of language by learning about the embodiment of the robot, learning from others, and learning linguistic skills. Cangelosi et al. [54] suggest that action, interaction, and language should be viewed together as they evolve in parallel, and one influences the others. Antunes et al. [55] assume that language is already learned, and address the problem that linguistic inputs typically do not have one-to-one mapping of actions. They propose to argue and plan on three different levels (low robot perception and execution of intermediate actions, goal formulation, and execution of plans) in order to interpret human instructions, [56] propose a system to recognize novel objects using language skills in a single setting."}, {"heading": "III. THE DAC-H3 COGNITIVE ARCHITECTURE", "text": "In this section, the DAC-h3 architecture is presented in detail, which provides an instantiation of the DAC architecture for interacting with human robots.The proposed architecture provides a general framework for the development of autonomous robots that act proactively to 1) maintain social interaction with humans, 2) the association of multimodal knowledge with their environment to bootstrapping, which further enrich the interaction through goal-oriented action plans, and 3) express a verbal narrative, enabling the principled organization of various functional modules into a biologically based cognitive architecture.In DAC-h3, the somatic layer consists of a humanoid iCub robot equipped with advanced motor and sensory capabilities for interacting with humans and objects. The reactive layer ensures the autonomy of the robot through drive reduction mechanisms that implement proactive behavior in order to acquire and express knowledge of the current scene."}, {"heading": "A. Somatic layer", "text": "The somatic layer corresponds to the physical embodiment of the system. We use the iCub robot, an open-source humanoid platform designed for research into cognitive robotics [4]. The iCub is a 104 cm humanoid robot with 53 degrees of freedom (DOF). It has two dexterous hands, each with 19 underactivated joints and 9 DOF. The robot is equipped with cameras in its moving eyes that allow stereo vision, and tactile sensors in the fingertips, palms, arms and torsos. The iCub is complemented by an external RGB-D camera above the robot head for agent detection and skeletal tracking. Finally, an external microphone and loudspeakers are used for speech recognition and synthesis respectively. The somatic layer also contains the physiological needs of the robot that will drive its reactive behavior, as described in the following section on the reactive layer."}, {"heading": "B. Reactive layer", "text": "In fact, most of them will be able to put themselves in a situation where they are able to put themselves at the centre, where they are able to do so."}, {"heading": "C. Adaptive layer", "text": "The adaptive level overlooks the acquisition of a state space of agent-environment interaction by binding visual, tactile, motor and linguistic representations of entities. It integrates functional modules to maintain an internal representation of the current scene, visually categorizing entities, the recognition and perception of body parts, the extraction of linguistic terms from human language, and the learning of associations between multimodal representations. They are grouped into three structural modules, which are described below: perceptions, associations, and choice of action (see Figure 1). Perceptions: The object recognition module [67] is used to learn the categorization of objects directly from the visual information provided by the iCub eyes. It provides a complete chain to address the problem of object recognition of the real world by coding the images with recourse to the most recent in-depth revolutionary networks, coherent and supportive application of a classification."}, {"heading": "D. Contextual layer", "text": "This year it is so far that it will only be a matter of time before an agreement is reached."}, {"heading": "E. Layer Synergy", "text": "The overall system described in this section therefore integrates several state-of-the-art algorithms for cognitive robotics and integrates them into a structured cognitive architecture based on the principles of DAC Theory. This enables complex control of the iCub robot, which interacts proactively with humans through mechanisms for reducing drive in the reactive layer, enabling adaptive learning of multimodal representations of entities in the adaptive layer. These representations form the basis of episodic memory for goal-oriented behavior through planning in the contextual layer. Lifelong interaction of the robot with humans continuously feeds an autobiographical memory capable of retrieving past experiences from the requirement and verbally expressing them in a narrative."}, {"heading": "IV. EXPERIMENTAL RESULTS", "text": "This section confirms the cognitive architecture described in the previous section in a real demonstration with an iCub humanoid robot that interacts with objects and a human. First, we describe the experimental setup, then the autonomous and goal-oriented capabilities provided to the robot. Finally, we analyze the course of the scenario in detail. The code for reproducing this experiment on each iCub robot is available open source on GitHub at https: / / github.com / robotology / wysiwyd. It consists of all the modules implemented in either C + + or Python in the last section, and relies on the YARP middleware [60] to define their connections and ensure their parallel execution in real time."}, {"heading": "A. Experimental setup", "text": "We are looking at a HRI scenario where the iCub and a human face each other with a table in the middle and objects are placed on the screen; the interface of the table is divided into three distinct areas, as shown in Figure 2: 1, an area that can only be reached by the iCub (I), 2) an area that can only be reached by a human (H), and 3) an area that can be reached by both actors (S for Shared). The behaviors available to the iCub are the following: \u2022 \"Obtaining missing information about a unit,\" which is described in more detail in Section IV-B1. \u2022 \"Print the knowledge acquired,\" which is described in more detail in Section IV-B2. \u2022 \"Move an object on the table\" by either moving it from Region I to S, or pulling it from Region S to I, or pulling it from Region S to I. \"These behaviors are as follows:\" The behaviors used when viewing the robot are implemented during two behaviors. \""}, {"heading": "B. Autonomous behavior", "text": "In fact, most of them will be able to play by the rules."}, {"heading": "C. Goal-oriented behavior", "text": "In fact, most of them will be able to survive on their own."}, {"heading": "D. Scenario Progression", "text": "That is the question, whether it is a political project or not."}, {"heading": "V. CONCLUSION AND FUTURE WORKS", "text": "In fact, most of them are able to play by the rules that they have imposed on themselves, and they are able to play by the rules that they have imposed on themselves."}, {"heading": "ACKNOWLEDGMENT", "text": "The research that led to these results was funded by the European Research Council under the Seventh Framework Programme of the European Union (FP / 2007-2013) / ERC Grant Agreement n. FP7-ICT-612139 (What You Say Is What You Did project)."}], "references": [{"title": "The symbol grounding problem", "author": ["S. Harnad"], "venue": "Physica D: Nonlinear Phenomena, vol. 42, no. 1, pp. 335 \u2013 346, 1990.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1990}, {"title": "An introduction to the anchoring problem", "author": ["S. Coradeschi", "A. Saffiotti"], "venue": "Robotics and Autonomous Systems, vol. 43, no. 2\u20133, pp. 85 \u2013 96, 2003.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "Symbol emergence in robotics: a survey", "author": ["T. Taniguchi", "T. Nagai", "T. Nakamura", "N. Iwahashi", "T. Ogata", "H. Asoh"], "venue": "Advanced Robotics, vol. 30, no. 11-12, pp. 706\u2013728, 2016.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "The iCub humanoid robot: An open-systems platform for research in cognitive development", "author": ["G. Metta", "L. Natale", "F. Nori", "G. Sandini", "D. Vernon", "L. Fadiga", "C. Von Hofsten", "K. Rosander", "M. Lopes", "J. Santos-Victor"], "venue": "Neural Networks, vol. 23, no. 8, pp. 1125\u20131134, 2010.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Cooperative human robot interaction systems: IV. Communication of shared plans with Na\u00efve humans using gaze and speech", "author": ["S. Lall\u00e9e", "K. Hamann", "J. Steinwender", "F. Warneken", "U. Martienz", "H. Barron-Gonzales", "U. Pattacini", "I. Gori", "M. Petit", "G. Metta"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems, 2013, pp. 129\u2013136.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Towards a platform-independent cooperative human robot interaction system: III an architecture for learning and executing actions and shared plans", "author": ["S. Lall\u00e9e", "U. Pattacini", "S. Lemaignan", "A. Lenz", "C. Melhuish", "L. Natale", "S. Skachek", "K. Hamann", "J. Steinwender", "E.A. Sisbot"], "venue": "IEEE Transactions on Autonomous Mental Development, vol. 4, no. 3, pp. 239\u2013253, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "The coordinating role of language in real-time multimodal learning of cooperative tasks", "author": ["M. Petit", "S. Lall\u00e9e", "J.-D. Boucher", "G. Pointeau", "P. Cheminade", "D. Ognibene", "E. Chinellato", "U. Pattacini", "I. Gori", "U. Martinez-Hernandez"], "venue": "IEEE Transactions on Autonomous Mental Development, vol. 5, no. 1, pp. 3\u201317, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning and reproduction of gestures by imitation", "author": ["S. Calinon", "F. D\u2019halluin", "E.L. Sauser", "D.G. Caldwell", "A.G. Billard"], "venue": "IEEE Robotics & Automation Magazine, vol. 17, no. 2, pp. 44\u201354, 2010.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "The robot in the crib: A developmental analysis of imitation skills in infants and robots", "author": ["Y. Demiris", "A. Meltzoff"], "venue": "Infant and Child Development, vol. 17, no. 1, pp. 43\u201353, 2008.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "Is imitation learning the route to humanoid robots?", "author": ["S. Schaal"], "venue": "Trends in cognitive sciences,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1999}, {"title": "Learning motor skills from partially observed movements executed at different speeds", "author": ["M. Ewerton", "G. Maeda", "J. Peters", "G. Neumann"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems, 2015, pp. 456\u2013463.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Social symbol grounding and language evolution", "author": ["P. Vogt", "F. Divina"], "venue": "Interaction Studies, vol. 8, no. 1, pp. 31\u201352, 2007.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "The grounding and sharing of symbols", "author": ["A. Cangelosi"], "venue": "Pragmatics & Cognition, vol. 14, no. 2, pp. 275\u2013285, 2006.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}, {"title": "On the human interaction engine", "author": ["S.C. Levinson"], "venue": "Wenner-Gren Foundation for Anthropological Research, Symposium 134. Berg, 2006, pp. 39\u201369.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Twelve-month-olds point to share attention and interest", "author": ["U. Liszkowski", "M. Carpenter", "A. Henning", "T. Striano", "M. Tomasello"], "venue": "Developmental science, vol. 7, no. 3, pp. 297\u2013307, 2004.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}, {"title": "A theory of human curiosity", "author": ["D.E. Berlyne"], "venue": "British Journal of Psychology. General Section, vol. 45, no. 3, pp. 180\u2013191, 1954.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1954}, {"title": "Understanding and sharing intentions: The origins of cultural cognition", "author": ["M. Tomasello", "M. Carpenter", "J. Call", "T. Behne", "H. Moll"], "venue": "Behavioral and brain sciences, vol. 28, no. 05, pp. 675\u2013691, 2005.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "A survey of socially interactive robots", "author": ["T. Fong", "I. Nourbakhsh", "K. Dautenhahn"], "venue": "Robotics and Autonomous Systems, vol. 42, no. 3, pp. 143\u2013166, 2003.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2003}, {"title": "Towards robotic assistants in nursing homes: Challenges and results", "author": ["J. Pineau", "M. Montemerlo", "M. Pollack", "N. Roy", "S. Thrun"], "venue": "Robotics and autonomous systems, vol. 42, no. 3, pp. 271\u2013281, 2003.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2003}, {"title": "An affective mobile robot educator with a full-time job", "author": ["I.R. Nourbakhsh", "J. Bobenage", "S. Grange", "R. Lutz", "R. Meyer", "A. Soto"], "venue": "Artificial Intelligence, vol. 114, no. 1, pp. 95\u2013124, 1999.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1999}, {"title": "Autonomous learning in humanoid robotics through mental imagery", "author": ["A.G. Di Nuovo", "D. Marocco", "S. Di Nuovo", "A. Cangelosi"], "venue": "Neural Networks, vol. 41, pp. 147\u2013155, 2013.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Humanoid robots: a new kind of tool", "author": ["B. Adams", "C. Breazeal", "R.A. Brooks", "B. Scassellati"], "venue": "IEEE Intelligent Systems and their Applications, vol. 15, no. 4, pp. 25\u201331, 2000.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2000}, {"title": "Bringing up robots or\u2014the psychology of socially intelligent robots: From theory to implementation", "author": ["K. Dautenhahn", "A. Billard"], "venue": "Proceedings of the Conference on Autonomous Agents, 1999, pp. 366\u2013367.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1999}, {"title": "Unified theories of cognition", "author": ["A. Newell"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1990}, {"title": "Report on a general problemsolving program", "author": ["A. Newell", "J.C. Shaw", "H.A. Simon"], "venue": "IFIP Congress, pp. 256\u2013264, 1959.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1959}, {"title": "SOAR: An architecture for general intelligence", "author": ["J.E. Laird", "A. Newell", "P.S. Rosenbloom"], "venue": "Artificial Intelligence, vol. 33, no. 1, pp. 1\u201364, 1987.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1987}, {"title": "Intelligence without representation", "author": ["R.A. Brooks"], "venue": "Artificial Intelligence, vol. 47, no. 1-3, pp. 139\u2013159, 1991.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1991}, {"title": "A robust layered control system for a mobile robot", "author": ["R. Brooks"], "venue": "IEEE Journal on Robotics and Automation, vol. 2, no. 1, pp. 14\u201323, 1986.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1986}, {"title": "On the utilization of social animals as a model for social robotics", "author": ["\u00c1. Mikl\u00f3si", "M. G\u00e1csi"], "venue": "Frontiers in Psychology, vol. 3, no. 75, pp. 1\u201310, 2012.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2012}, {"title": "Socially intelligent robots: dimensions of human-robot interaction.", "author": ["K. Dautenhahn"], "venue": "Philosophical transactions of the Royal Society of London. Series B, Biological sciences,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2007}, {"title": "Theories of Theories of Mind", "author": ["P. Carruthers", "P.K. Smith"], "venue": "Australasian Journal of Philosophy, vol. 76, 1998.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1998}, {"title": "The interactive brain hypothesis", "author": ["E. Di Paolo", "H. De Jaegher"], "venue": "Frontiers in Human Neuroscience, vol. 6, no. 163, pp. 1\u201316, 2012.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2012}, {"title": "Symbol emergence in robotics for long-term human-robot collaboration", "author": ["T. Taniguchi"], "venue": "IFAC Symposium on Analysis, Design, and Evaluation of Human-Machine Systems, 2016, pp. 144 \u2013 149.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2016}, {"title": "Investigating models of social development using a humanoid robot", "author": ["B. Scassellati"], "venue": "Proceedings of the IEEE International Joint Conference on Neural Networks, 2003, pp. 2704\u20132709.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2003}, {"title": "Combining deliberation, reactivity, and motivation in the context of a behavior-based robot architecture", "author": ["A. Stoytchev", "R. Arkin"], "venue": "Proceedings of the IEEE International Symposium on Computational Intelligence in Robotics and Automation, 2001, pp. 290\u2013295.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2001}, {"title": "A Biologically Inspired Architecture for an Autonomous and Social Robot", "author": ["M. Malfaz", "\u00c1. Castro-Gonzalez", "R. Barber", "M.A. Salichs"], "venue": "IEEE Transactions on Autonomous Mental Development, vol. 3, no. 3, pp. 232\u2013246, 2011.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2011}, {"title": "Environmentally mediated synergy between perception and behaviour in mobile robots", "author": ["P.F.M.J. Verschure", "T. Voegtlin", "R.J. Douglas"], "venue": "Nature, vol. 425, no. 6958, pp. 620\u2013624, 2003.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2003}, {"title": "The why, what, where, when and how of goal-directed choice: neuronal and computational principles", "author": ["P.F.M.J. Verschure", "C.M.A. Pennartz", "G. Pezzulo"], "venue": "Philosophical Transactions of the Royal Society B: Biological Sciences, vol. 369, no. 1655, pp. 1\u201314, 2014.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2014}, {"title": "Towards selfcontrolled robots through distributed adaptive control", "author": ["J.-Y. Puigb\u00f2", "C. Moulin-Frier", "P.F. Verschure"], "venue": "Biomimetic and Biohybrid Systems, 2016, pp. 490\u2013497.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2016}, {"title": "The synthetic modeling of language origins", "author": ["L. Steels"], "venue": "Evolution of Communication, vol. 1, no. 1, pp. 1\u201334, 1997.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1997}, {"title": "Semiotic schemata: Selection units for linguistic cultural evolution", "author": ["F. Kaplan"], "venue": "Proceedings of the International Conference on Artificial Life, 2000, pp. 372\u2013381.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2000}, {"title": "COSMO (\u201cCommunicating about Objects using Sensory-Motor Operations\u201d): a Bayesian modeling framework for studying speech communication and the emergence of phonological systems", "author": ["C. Moulin-Frier", "J. Diard", "J.-L. Schwartz", "P. Bessi\u00e8re"], "venue": "Journal of Phonetics, vol. 53, pp. 5\u201341, 2015.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2015}, {"title": "Grounding communication in autonomous robots: an experimental study", "author": ["A. Billard", "K. Dautenhahn"], "venue": "Robotics and Autonomous Systems, vol. 24, no. 1, pp. 71\u201379, 1998.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 1998}, {"title": "Language acquisition and symbol grounding transfer with neural networks and cognitive robots", "author": ["A. Cangelosi", "E. Hourdakis", "V. Tikhanoff"], "venue": "IEEE International Joint Conference on Neural Network Proceedings, 2006, pp. 1576\u20131582.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2006}, {"title": "Grounding action words in the sensorimotor interaction with the world: experiments with a simulated iCub humanoid robot", "author": ["D. Marocco", "A. Cangelosi", "K. Fischer", "T. Belpaeme"], "venue": "Frontiers in Neurorobotics, vol. 4, no. 7, pp. 1\u201315, 2010.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2010}, {"title": "Object learning through active exploration", "author": ["S. Ivaldi", "S. Nguyen", "N. Lyubova", "A. Droniou", "V. Padois", "D. Filliat", "P.-Y. Oudeyer", "O. Sigaud"], "venue": "IEEE Transactions on Autonomous Mental Development, vol. 6, no. 1, pp. 56\u201372, 2013.  C. Moulin-Frier, T. Fischer et al.: DAC-h3: A Proactive Robot Cognitive Architecture  15", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2013}, {"title": "Intrinsic motivation systems for autonomous mental development", "author": ["P.-Y. Oudeyer", "F. Kaplan", "V.V. Hafner"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 11, no. 2, pp. 265\u2013286, 2007.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2007}, {"title": "Infant-like social interactions between a robot and a human caregiver", "author": ["C. Breazeal", "B. Scassellati"], "venue": "Adaptive Behavior, vol. 8, no. 1, pp. 49\u201374, 2000.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2000}, {"title": "A novel approach to proactive human-robot cooperation", "author": ["O.C. Schrempf", "U.D. Hanebeck", "A.J. Schmid", "H. Worn"], "venue": "IEEE International Workshop on Robot and Human Interactive Communication, 2005, pp. 555\u2013560.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2005}, {"title": "The curious robot - structuring interactive robot learning", "author": ["I. Lutkebohle", "J. Peltason", "L. Schillingmann", "B. Wrede", "S. Wachsmuth", "C. Elbrechter", "R. Haschke"], "venue": "IEEE International Conference on Robotics and Automation, 2009, pp. 4156\u20134162.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2009}, {"title": "The italk project: A developmental robotics approach to the study of individual, social, and linguistic learning", "author": ["F. Broz", "C.L. Nehaniv", "T. Belpaeme", "A. Bisio", "K. Dautenhahn", "L. Fadiga", "T. Ferrauto", "K. Fischer", "F. F\u00f6rster", "O. Gigliotta"], "venue": "Topics in cognitive science, vol. 6, no. 3, pp. 534\u2013544, 2014.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2014}, {"title": "Integration of action and language knowledge: A roadmap for developmental robotics", "author": ["A. Cangelosi"], "venue": "IEEE Transactions on Autonomous Mental Development, vol. 2, no. 3, pp. 167\u2013195, 2010.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2010}, {"title": "From human instructions to robot actions: Formulation of goals, affordances and probabilistic planning", "author": ["A. Antunes", "L. Jamone", "G. Saponaro", "A. Bernardino", "R. Ventura"], "venue": "IEEE International Conference on Robotics and Automation, 2016, pp. 5449\u20135454.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning to Recognize Novel Objects in One Shot through Human-Robot Interactions in Natural Language Dialogues", "author": ["E.A. Krause", "M. Zillich", "T.E. Williams", "M. Scheutz"], "venue": "AAAI Conference on Artificial Intelligence, 2014, pp. 2796\u20132802.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2014}, {"title": "I know what I did last summer: Autobiographic memory in synthetic characters", "author": ["J. Dias", "W.C. Ho", "T. Vogt", "N. Beeckman", "A. Paiva", "E. Andr\u00e9"], "venue": "International Conference on Affective Computing and Intelligent Interaction, 2007, pp. 606\u2013617.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2007}, {"title": "Towards an episodic memory for companion dialogue", "author": ["G. Sieber", "B. Krenn"], "venue": "International Conference on Intelligent Virtual Agents, J. Allbeck, N. Badler, T. Bickmore, C. Pelachaud, and A. Safonova, Eds., 2010, pp. 322\u2013328.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2010}, {"title": "Views from within a narrative: Evaluating long-term human\u2013robot interaction in a naturalistic environment using open-ended scenarios", "author": ["D.S. Syrdal", "K. Dautenhahn", "K.L. Koay", "W.C. Ho"], "venue": "Cognitive Computation, vol. 6, no. 4, pp. 741\u2013759, 2014.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2014}, {"title": "Towards long-lived robot genes", "author": ["P. Fitzpatrick", "G. Metta", "L. Natale"], "venue": "Robotics and Autonomous systems, vol. 56, no. 1, pp. 29\u201345, 2008.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2008}, {"title": "Allostatic control for robot behavior regulation: a comparative rodent-robot study", "author": ["M. Sanchez-Fibla", "U. Bernardet", "E. Wasserman", "T. Pelc", "M. Mintz", "J.C. Jackson", "C. Lansink", "C. Pennartz", "P.F. Verschure"], "venue": "Advances in Complex Systems, vol. 13, no. 3, pp. 377\u2013403, 2010.", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2010}, {"title": "Allostatic control for robot behaviour regulation: An extension to path planning", "author": ["M.S. Fibla", "U. Bernardet", "P.F. Verschure"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems, 2010, pp. 1935\u20131942.", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2010}, {"title": "An experimental evaluation of a novel minimum-jerk cartesian controller for humanoid robots", "author": ["U. Pattacini", "F. Nori", "L. Natale", "G. Metta"], "venue": "The IEEE/RSJ International Conference on Intelligent Robots and Systems, 2010, pp. 1668\u20131674.", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2010}, {"title": "The Design of the iCub Humanoid Robot", "author": ["A. Parmiggiani", "M. Maggiali", "L. Natale", "F. Nori", "A. Schmitz", "N. Tsagarakis", "J.S. Victor", "F. Becci", "G. Sandini", "G. Metta"], "venue": "International Journal of Humanoid Robotics, vol. 9, no. 4, 2012.", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2012}, {"title": "How? Why? What? Where? When? Who? Grounding Ontology in the Actions of a Situated Social Agent", "author": ["S. Lallee", "P.F. Verschure"], "venue": "Robotics, vol. 4, no. 2, pp. 169\u2013193, 2015.", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2015}, {"title": "The influence of behavioral complexity on robot perception", "author": ["V. Vouloutsi", "K. Grechuta", "S. Lall\u00e9e", "P.F. Verschure"], "venue": "Conference on Biomimetic and Biohybrid Systems, 2014, pp. 332\u2013343.", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2014}, {"title": "Object identification from few examples by improving the invariance of a deep convolutional neural network", "author": ["G. Pasquale", "C. Ciliberto", "L. Rosasco", "L. Natale"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems, 2016.", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2016}, {"title": "Real-time parallel processing of grammat-  ical structure in the fronto-striatal system: a recurrent network simulation study using reservoir computing", "author": ["X. Hinaut", "P.F. Dominey"], "venue": "PloS one, vol. 8, no. 2, pp. 1\u201318, 2013.", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2013}, {"title": "Exploring the acquisition and production of grammatical constructions through humanrobot interaction with echo state networks", "author": ["X. Hinaut", "M. Petit", "G. Pointeau", "P.F. Dominey"], "venue": "Frontiers in Neurorobotics, vol. 8, no. 16, pp. 1\u201317, 2015.", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2015}, {"title": "Construals of meaning: The role of attention in robotic language production", "author": ["A.-L. Mealier", "G. Pointeau", "P. Gardenfors", "P.-F. Dominey"], "venue": "Interaction Studies, vol. 17, no. 1, pp. 41\u201369, 2016.", "citeRegEx": "70", "shortCiteRegEx": null, "year": 2016}, {"title": "Constructions: A construction grammar approach to argument structure", "author": ["A.E. Goldberg"], "venue": null, "citeRegEx": "71", "shortCiteRegEx": "71", "year": 1995}, {"title": "Towards anchoring self-learned representations to those of other agents", "author": ["M. Zambelli", "T. Fischer", "M. Petit", "H.J. Chang", "A. Cully", "Y. Demiris"], "venue": "Workshop on Bio-inspired Social robot Learning in Home Scenarios at IEEE/RSJ International Conference on Intelligent Robots and Systems, 2016.", "citeRegEx": "72", "shortCiteRegEx": null, "year": 2016}, {"title": "Online Multimodal Ensemble Learning using Self-learnt Sensorimotor Representations", "author": ["M. Zambelli", "Y. Demiris"], "venue": "IEEE Transactions on Cognitive and Developmental Systems, 2016 (accepted).", "citeRegEx": "73", "shortCiteRegEx": null, "year": 2016}, {"title": "Adaptive nonlinear system identification with echo state networks", "author": ["H. Jaeger"], "venue": "Advances in Neural Information Processing Systems, 2002, pp. 593\u2013600.", "citeRegEx": "74", "shortCiteRegEx": null, "year": 2002}, {"title": "Spatio-temporal learning with the Online Finite and Infinite Echo-state Gaussian processes", "author": ["H. Soh", "Y. Demiris"], "venue": "IEEE Transactions on Neural Networks and Learning Systems, vol. 26, no. 3, pp. 522\u2013536, 2015.", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2015}, {"title": "Fast and efficient incremental learning for high-dimensional movement systems", "author": ["S. Vijayakumar", "S. Schaal"], "venue": "IEEE International Conference on Robotics and Automation, 2000, pp. 1894\u20131899.", "citeRegEx": "76", "shortCiteRegEx": null, "year": 2000}, {"title": "Unsupervised learning of complex articulated kinematic structures combining motion and skeleton information", "author": ["H.J. Chang", "Y. Demiris"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 3138\u20133146.", "citeRegEx": "77", "shortCiteRegEx": null, "year": 2015}, {"title": "Kinematic structure correspondences via hypergraph matching", "author": ["H.J. Chang", "T. Fischer", "M. Petit", "M. Zambelli", "Y. Demiris"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 4216\u20134225.", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2016}, {"title": "Markerless Perspective Taking for Humanoid Robots in Unconstrained Environments", "author": ["T. Fischer", "Y. Demiris"], "venue": "IEEE International Conference on Robotics and Automation, 2016, pp. 3309\u20133316.", "citeRegEx": "79", "shortCiteRegEx": null, "year": 2016}, {"title": "Two kinds of visual perspective taking", "author": ["P. Michelon", "J.M. Zacks"], "venue": "Perception & Psychophysics, vol. 68, no. 2, pp. 327\u2013337, 2006.", "citeRegEx": "80", "shortCiteRegEx": null, "year": 2006}, {"title": "A future of living machines?: International trends and prospects in biomimetic and biohybrid systems", "author": ["T.J. Prescott", "N. Lepora", "P.F.M.J. Vershure"], "venue": "Proceedings of the SPIE 9055, Bioinspiration, Biometrics and Bioreplication, 2014.", "citeRegEx": "81", "shortCiteRegEx": null, "year": 2014}, {"title": "Formal minds and biological brains II: From the mirage of intelligence to a science and engineering of consciousness", "author": ["P. Verschure"], "venue": "IEEE Intelligent Systems Trends and Controversies, 2013, pp. 33\u201336.", "citeRegEx": "82", "shortCiteRegEx": null, "year": 2013}, {"title": "Successive Developmental Levels of Autobiographical Memory for Learning Through Social Interaction", "author": ["G. Pointeau", "M. Petit", "P.F. Dominey"], "venue": "IEEE Transactions on Autonomous Mental Development, vol. 6, no. 3, pp. 200\u2013212, Sep. 2014.", "citeRegEx": "83", "shortCiteRegEx": null, "year": 2014}, {"title": "Lifelong Augmentation of Multi- Modal Streaming Autobiographical Memories", "author": ["M. Petit", "T. Fischer", "Y. Demiris"], "venue": "IEEE Transactions on Cognitive and Developmental Systems, vol. 8, no. 3, pp. 201\u2013213, 2016.", "citeRegEx": "84", "shortCiteRegEx": null, "year": 2016}, {"title": "Towards the emergence of procedural memories from lifelong multi-modal streaming memories for cognitive robots", "author": ["M. Petit", "T. Fischer", "Y. Demiris"], "venue": "Workshop on Machine Learning Methods for High-Level Cognitive Capabilities in Robotics at IEEE/RSJ International Conference on Intelligent Robots and Systems, 2016.", "citeRegEx": "85", "shortCiteRegEx": null, "year": 2016}, {"title": "A top-down approach for a synthetic autobiographical memory system", "author": ["A. Damianou", "C.H. Ek", "L. Boorman", "N.D. Lawrence", "T.J. Prescott"], "venue": "Biomimetic and Biohybrid Systems, 2015, pp. 280\u2013292.", "citeRegEx": "86", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep gaussian processes.", "author": ["A.C. Damianou", "N.D. Lawrence"], "venue": "Artificial Intelligence and Statistics Conference,", "citeRegEx": "87", "shortCiteRegEx": "87", "year": 2013}, {"title": "iCub Visual Memory Inspector: Visualising the iCub\u2019s Thoughts", "author": ["D. Camilleri", "A. Damianou", "H. Jackson", "N. Lawrence", "T. Prescott"], "venue": "Conference on Biomimetic and Biohybrid Systems, 2016, pp. 48\u201357.", "citeRegEx": "88", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "THE so-called Symbol Grounding Problem (SGP, [1], [2], [3]) refers to how a cognitive agent forms an internal and unified representation of an external word referent from the continuous flow of low-level sensorimotor data generated by its interaction with the environment.", "startOffset": 45, "endOffset": 48}, {"referenceID": 1, "context": "THE so-called Symbol Grounding Problem (SGP, [1], [2], [3]) refers to how a cognitive agent forms an internal and unified representation of an external word referent from the continuous flow of low-level sensorimotor data generated by its interaction with the environment.", "startOffset": 50, "endOffset": 53}, {"referenceID": 2, "context": "THE so-called Symbol Grounding Problem (SGP, [1], [2], [3]) refers to how a cognitive agent forms an internal and unified representation of an external word referent from the continuous flow of low-level sensorimotor data generated by its interaction with the environment.", "startOffset": 55, "endOffset": 58}, {"referenceID": 3, "context": "focus on solving the SGP in the context of human-robot interaction (HRI), where a humanoid iCub robot [4] acquires and expresses knowledge about the world by interacting with a human partner.", "startOffset": 102, "endOffset": 105}, {"referenceID": 11, "context": ", visual, tactile, motor)? This is referred to as the Physical SGP [?], [13].", "startOffset": 72, "endOffset": 76}, {"referenceID": 11, "context": "rimotor interactions between two (or more) agents? This is referred to as the Social SGP [13], [14].", "startOffset": 89, "endOffset": 93}, {"referenceID": 12, "context": "rimotor interactions between two (or more) agents? This is referred to as the Social SGP [13], [14].", "startOffset": 95, "endOffset": 99}, {"referenceID": 13, "context": "This is referred to by Levinson [15] as the human interaction engine: a set of capabilities including looking at objects of interest and interaction partners, pointing to these entities [16], curiosity", "startOffset": 32, "endOffset": 36}, {"referenceID": 14, "context": "This is referred to by Levinson [15] as the human interaction engine: a set of capabilities including looking at objects of interest and interaction partners, pointing to these entities [16], curiosity", "startOffset": 186, "endOffset": 190}, {"referenceID": 15, "context": "as a desire to acquire knowledge [17], as well as showing, telling and sharing of knowledge with others [16], [18].", "startOffset": 33, "endOffset": 37}, {"referenceID": 14, "context": "as a desire to acquire knowledge [17], as well as showing, telling and sharing of knowledge with others [16], [18].", "startOffset": 104, "endOffset": 108}, {"referenceID": 16, "context": "as a desire to acquire knowledge [17], as well as showing, telling and sharing of knowledge with others [16], [18].", "startOffset": 110, "endOffset": 114}, {"referenceID": 17, "context": "Conceiving socially interactive robots relies on two main approaches [19].", "startOffset": 69, "endOffset": 73}, {"referenceID": 18, "context": "[20], [21], [22]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20], [21], [22]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 20, "context": "[20], [21], [22]).", "startOffset": 12, "endOffset": 16}, {"referenceID": 21, "context": "[23], [24]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23], [24]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 23, "context": "Another distinction in approaches for conceiving social robots, which is of particular relevance for addressing the SGP, reflects an historical distinction from the more general field of cognitive architectures (or unified theories of cognition [25]).", "startOffset": 245, "endOffset": 249}, {"referenceID": 24, "context": "Problem Solver [26] to Soar [27] or ACT-R [28]).", "startOffset": 15, "endOffset": 19}, {"referenceID": 25, "context": "Problem Solver [26] to Soar [27] or ACT-R [28]).", "startOffset": 28, "endOffset": 32}, {"referenceID": 26, "context": "This is typically the case in behavior-based robotics [29], emphasizing lower-level sensory-motor control loops as a starting point of behavioral complexity as in the Subsumption architecture [30].", "startOffset": 54, "endOffset": 58}, {"referenceID": 27, "context": "This is typically the case in behavior-based robotics [29], emphasizing lower-level sensory-motor control loops as a starting point of behavioral complexity as in the Subsumption architecture [30].", "startOffset": 192, "endOffset": 196}, {"referenceID": 26, "context": "essary component of cognition (referred as intelligence without representation in [29]).", "startOffset": 82, "endOffset": 86}, {"referenceID": 28, "context": "Interestingly, this distinction between top-down representation-based and bottom-up behavior-based approaches still holds in the domain of social robotics [31], [32].", "startOffset": 155, "endOffset": 159}, {"referenceID": 29, "context": "Interestingly, this distinction between top-down representation-based and bottom-up behavior-based approaches still holds in the domain of social robotics [31], [32].", "startOffset": 161, "endOffset": 165}, {"referenceID": 30, "context": "[33]), whereas bottom-up behavior-based approaches emphasize the role of embodiment and reactive control to enable the dynamic coupling of agents [34].", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[33]), whereas bottom-up behavior-based approaches emphasize the role of embodiment and reactive control to enable the dynamic coupling of agents [34].", "startOffset": 146, "endOffset": 150}, {"referenceID": 32, "context": "system at the macro level and a physical system consisting of communicating and collaborating agents at the micro level [35].", "startOffset": 120, "endOffset": 124}, {"referenceID": 35, "context": "[38], [37], [36], [?]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[38], [37], [36], [?]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 33, "context": "[38], [37], [36], [?]).", "startOffset": 12, "endOffset": 16}, {"referenceID": 33, "context": "In [36], an architecture called", "startOffset": 3, "endOffset": 7}, {"referenceID": 34, "context": "In [37] or [38], the architecture combines deliberative planning, reactive control, and motivational drives", "startOffset": 3, "endOffset": 7}, {"referenceID": 35, "context": "In [37] or [38], the architecture combines deliberative planning, reactive control, and motivational drives", "startOffset": 11, "endOffset": 15}, {"referenceID": 36, "context": "In this paper, we adopt the principles of the Distributed Adaptive Control theory of the mind and the brain (DAC, [39], [40]).", "startOffset": 114, "endOffset": 118}, {"referenceID": 37, "context": "In this paper, we adopt the principles of the Distributed Adaptive Control theory of the mind and the brain (DAC, [39], [40]).", "startOffset": 120, "endOffset": 124}, {"referenceID": 38, "context": "This reactive interaction with the environment drives the dynamics of the whole architecture [41], bootstrapping learning processes for solving the physical SGP (the adaptive layer) and the acquisition of higher-level cognitive representations such as abstract goal selection, memory and planning (the contextual layer).", "startOffset": 93, "endOffset": 97}, {"referenceID": 39, "context": "Since the pioneering paradigm of \u201clanguage games\u201d proposed in [42], a number of multi-agent models have been proposed showing how particular properties of language", "startOffset": 62, "endOffset": 66}, {"referenceID": 40, "context": "[43], [44]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "[43], [44]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 42, "context": "In the domain of HRI, contributions have focused on lexicon acquisition through the transfer of sensorimotor and linguistic information from the interaction between a teacher and a learner through imitation [45], action [46], [47] or active exploration [48].", "startOffset": 207, "endOffset": 211}, {"referenceID": 43, "context": "In the domain of HRI, contributions have focused on lexicon acquisition through the transfer of sensorimotor and linguistic information from the interaction between a teacher and a learner through imitation [45], action [46], [47] or active exploration [48].", "startOffset": 220, "endOffset": 224}, {"referenceID": 44, "context": "In the domain of HRI, contributions have focused on lexicon acquisition through the transfer of sensorimotor and linguistic information from the interaction between a teacher and a learner through imitation [45], action [46], [47] or active exploration [48].", "startOffset": 226, "endOffset": 230}, {"referenceID": 45, "context": "In the domain of HRI, contributions have focused on lexicon acquisition through the transfer of sensorimotor and linguistic information from the interaction between a teacher and a learner through imitation [45], action [46], [47] or active exploration [48].", "startOffset": 253, "endOffset": 257}, {"referenceID": 4, "context": "Significant progress has been made in allowing robots to interact with humans, for example in learning shared plans [5], [6], [7], learning to imitate actions [8], [9], [10], and learning motor skills [11] that could be used for engaging in joint activities.", "startOffset": 116, "endOffset": 119}, {"referenceID": 5, "context": "Significant progress has been made in allowing robots to interact with humans, for example in learning shared plans [5], [6], [7], learning to imitate actions [8], [9], [10], and learning motor skills [11] that could be used for engaging in joint activities.", "startOffset": 121, "endOffset": 124}, {"referenceID": 6, "context": "Significant progress has been made in allowing robots to interact with humans, for example in learning shared plans [5], [6], [7], learning to imitate actions [8], [9], [10], and learning motor skills [11] that could be used for engaging in joint activities.", "startOffset": 126, "endOffset": 129}, {"referenceID": 7, "context": "Significant progress has been made in allowing robots to interact with humans, for example in learning shared plans [5], [6], [7], learning to imitate actions [8], [9], [10], and learning motor skills [11] that could be used for engaging in joint activities.", "startOffset": 159, "endOffset": 162}, {"referenceID": 8, "context": "Significant progress has been made in allowing robots to interact with humans, for example in learning shared plans [5], [6], [7], learning to imitate actions [8], [9], [10], and learning motor skills [11] that could be used for engaging in joint activities.", "startOffset": 164, "endOffset": 167}, {"referenceID": 9, "context": "Significant progress has been made in allowing robots to interact with humans, for example in learning shared plans [5], [6], [7], learning to imitate actions [8], [9], [10], and learning motor skills [11] that could be used for engaging in joint activities.", "startOffset": 169, "endOffset": 173}, {"referenceID": 10, "context": "Significant progress has been made in allowing robots to interact with humans, for example in learning shared plans [5], [6], [7], learning to imitate actions [8], [9], [10], and learning motor skills [11] that could be used for engaging in joint activities.", "startOffset": 201, "endOffset": 205}, {"referenceID": 13, "context": "acquiring symbols by interacting with other agents is not only an unidirectional process of information transfer between a teacher and learner [15].", "startOffset": 143, "endOffset": 147}, {"referenceID": 46, "context": "Autonomous exploration and proactive behavior allow robots to take the initiative in exploring their environment [49]", "startOffset": 113, "endOffset": 117}, {"referenceID": 47, "context": "and interacting with people [50].", "startOffset": 28, "endOffset": 32}, {"referenceID": 45, "context": "In [48], it is shown how a combination of social guidance and intrinsic motivation improve the learning of object visual categories in HRI.", "startOffset": 3, "endOffset": 7}, {"referenceID": 48, "context": "In [51], planning conflicts due to the uncertainty of the detected human\u2019s intention are", "startOffset": 3, "endOffset": 7}, {"referenceID": 49, "context": "In [52], the task", "startOffset": 3, "endOffset": 7}, {"referenceID": 50, "context": "The cognitive architecture of iTalk [53] focuses on modeling the emergence of language by learning about the robot\u2019s embodiment, learning from others, as well as", "startOffset": 36, "endOffset": 40}, {"referenceID": 51, "context": "[54] propose that action, interaction and language should be considered together as they develop in parallel, and one influences the others.", "startOffset": 0, "endOffset": 4}, {"referenceID": 52, "context": "[55] assume that language is already learned, and address the issue that linguistic input typically", "startOffset": 0, "endOffset": 4}, {"referenceID": 53, "context": "Similarly, [56] proposes a system to recognize novel objects using language", "startOffset": 11, "endOffset": 15}, {"referenceID": 54, "context": "Various works investigate the expression of past events by developing narratives based on acquired autobiographical memories [57], [58], [59].", "startOffset": 125, "endOffset": 129}, {"referenceID": 55, "context": "Various works investigate the expression of past events by developing narratives based on acquired autobiographical memories [57], [58], [59].", "startOffset": 131, "endOffset": 135}, {"referenceID": 56, "context": "Various works investigate the expression of past events by developing narratives based on acquired autobiographical memories [57], [58], [59].", "startOffset": 137, "endOffset": 141}, {"referenceID": 56, "context": "In [59], a user study is presented which suggests that a robot\u2019s narrative allows humans to get an insight to long term human-robot interaction from the robot\u2019s perspective.", "startOffset": 3, "endOffset": 7}, {"referenceID": 55, "context": "The method in [58] takes user preferences into", "startOffset": 14, "endOffset": 18}, {"referenceID": 57, "context": "In the next section, we describe how the above features are implemented in a coherent cognitive architecture relying on functional modules which are implemented as YARP [60]", "startOffset": 169, "endOffset": 173}, {"referenceID": 3, "context": "We use the iCub robot, an open source humanoid platform developed for research in cognitive robotics [4].", "startOffset": 101, "endOffset": 104}, {"referenceID": 13, "context": "As described by Levinson [15], a part of the human interaction engine is a set of capabilities that", "startOffset": 25, "endOffset": 29}, {"referenceID": 58, "context": "Such possible conflicts can be solved through the concept of an allostatic controller [61], [62], defined as a set of simple homeostatic control loops and dealing with their scheduling to ensure an efficient global regulation of the internal state", "startOffset": 86, "endOffset": 90}, {"referenceID": 59, "context": "Such possible conflicts can be solved through the concept of an allostatic controller [61], [62], defined as a set of simple homeostatic control loops and dealing with their scheduling to ensure an efficient global regulation of the internal state", "startOffset": 92, "endOffset": 96}, {"referenceID": 60, "context": "Motor actions are realized through the action rendering engine (ARE [63]) functional module, executing complex actions (e.", "startOffset": 68, "endOffset": 72}, {"referenceID": 60, "context": "The whole trajectory gets decomposed in multiple trajectories via points whose intermediate movements are resolved by means of a non-linear constraints optimization, and then performed by a multi-referential operational controller as described in [63].", "startOffset": 247, "endOffset": 251}, {"referenceID": 61, "context": "Festival1, Acapela2) by synchronizing the produced utterance from a string with the LEDs of the iCub\u2019s mouth, producing lips movements to realize a more vivid interaction [64].", "startOffset": 171, "endOffset": 175}, {"referenceID": 62, "context": "The positive influence of such a drive regulation mechanism on the acceptance of the HRI by naive users has been demonstrated in previous papers [65], [66].", "startOffset": 145, "endOffset": 149}, {"referenceID": 63, "context": "The positive influence of such a drive regulation mechanism on the acceptance of the HRI by naive users has been demonstrated in previous papers [65], [66].", "startOffset": 151, "endOffset": 155}, {"referenceID": 64, "context": "1) Perceptions: The object recognition functional module [67] is used to learn the categorization of objects directly from the visual information given by the iCub eyes.", "startOffset": 57, "endOffset": 61}, {"referenceID": 65, "context": "These models (comprehension and production of narrative discourse) are recurrent neuronal networks based on reservoir computing [68], [69], [70].", "startOffset": 128, "endOffset": 132}, {"referenceID": 66, "context": "These models (comprehension and production of narrative discourse) are recurrent neuronal networks based on reservoir computing [68], [69], [70].", "startOffset": 134, "endOffset": 138}, {"referenceID": 67, "context": "These models (comprehension and production of narrative discourse) are recurrent neuronal networks based on reservoir computing [68], [69], [70].", "startOffset": 140, "endOffset": 144}, {"referenceID": 68, "context": "It receives a sentence and produces the representation of the corresponding meaning, which is based on the theory of Goldberg [71] who proposes a tight correspondence between the structure of perceptual events that are basic to human experience, and constructions for the cor-", "startOffset": 126, "endOffset": 130}, {"referenceID": 83, "context": "association, as defined by experimental psychologists and neuroscientists [86].", "startOffset": 74, "endOffset": 78}, {"referenceID": 84, "context": "The functionality in SSM draws inspiration from the role of the hippocampus by fusing multiple sensory input streams and representing them in a latent feature space, which emerges as Deep Gaussian Processes [87] are used as the underlying technology.", "startOffset": 207, "endOffset": 211}, {"referenceID": 85, "context": "capable of imagining novel inputs or reconstructing previously encountered inputs and sending the corresponding generated sensory data which allows for the replay of memories using the visual memory inspector [88].", "startOffset": 209, "endOffset": 213}, {"referenceID": 62, "context": "Those unified representations are formed in the objects properties collector (OPC), a functional module storing all information associated with a particular entity at the present moment in a proto-language format as detailed in [65].", "startOffset": 228, "endOffset": 232}, {"referenceID": 69, "context": "the developmental robot itself (instead of external entities as above), to acquire motor capabilities or to learn the links between motor joints and skin sensors of its body [72].", "startOffset": 174, "endOffset": 178}, {"referenceID": 70, "context": "means of an online heterogeneous ensemble of predictors [73].", "startOffset": 56, "endOffset": 60}, {"referenceID": 71, "context": "The ensemble includes echo-state networks [74], online echo state Gaussian processes [75] and locally weighted projection regression models [76].", "startOffset": 42, "endOffset": 46}, {"referenceID": 72, "context": "The ensemble includes echo-state networks [74], online echo state Gaussian processes [75] and locally weighted projection regression models [76].", "startOffset": 85, "endOffset": 89}, {"referenceID": 73, "context": "The ensemble includes echo-state networks [74], online echo state Gaussian processes [75] and locally weighted projection regression models [76].", "startOffset": 140, "endOffset": 144}, {"referenceID": 74, "context": "The kinematic structure learning functional module [77],", "startOffset": 51, "endOffset": 55}, {"referenceID": 75, "context": "[78] estimates an articulated kinematic structure of arbitrary objects (including the robot\u2019s body parts, and humans) using local feature point trajectories extracted from the visual input videos of the iCub eye cameras.", "startOffset": 0, "endOffset": 4}, {"referenceID": 74, "context": "ulated kinematic structures [77], we also allow the iCub to anchor two objects\u2019 kinematic structure joints by observing their movements [78].", "startOffset": 28, "endOffset": 32}, {"referenceID": 75, "context": "ulated kinematic structures [77], we also allow the iCub to anchor two objects\u2019 kinematic structure joints by observing their movements [78].", "startOffset": 136, "endOffset": 140}, {"referenceID": 76, "context": "Finally, the perspective taking functional module [79] enables the robot to reason about the state of the world from the partner\u2019s perspective.", "startOffset": 50, "endOffset": 54}, {"referenceID": 77, "context": "Interestingly, it was proposed that there are two separate processes involved in perspective taking depending on the difficulty of the task [80].", "startOffset": 140, "endOffset": 144}, {"referenceID": 62, "context": "1) Episodic Memory: The episodic memory relies on advanced functions of the object property collector (OPC) to store and associate information about entities in a uniform format based on the interrogative words \u201cwho\u201d, \u201cwhat\u201d, \u201cwhere\u201d, \u201cwhen\u201d, \u201cwhy\u201d and \u201chow\u201d called an H5W data structure [65].", "startOffset": 288, "endOffset": 292}, {"referenceID": 78, "context": "H5W have been argued to be the main questions any conscious being must answer in order to survive in the world [81], [82].", "startOffset": 111, "endOffset": 115}, {"referenceID": 79, "context": "H5W have been argued to be the main questions any conscious being must answer in order to survive in the world [81], [82].", "startOffset": 117, "endOffset": 121}, {"referenceID": 80, "context": "3) Autobiographical Memory: The autobiographical memory (ABM [83], [84], [85]) collects long term information", "startOffset": 61, "endOffset": 65}, {"referenceID": 81, "context": "3) Autobiographical Memory: The autobiographical memory (ABM [83], [84], [85]) collects long term information", "startOffset": 67, "endOffset": 71}, {"referenceID": 82, "context": "3) Autobiographical Memory: The autobiographical memory (ABM [83], [84], [85]) collects long term information", "startOffset": 73, "endOffset": 77}, {"referenceID": 80, "context": "long term memory situated in the medial temporal lobe, and the distinction between facts and events [83], [84].", "startOffset": 100, "endOffset": 104}, {"referenceID": 81, "context": "long term memory situated in the medial temporal lobe, and the distinction between facts and events [83], [84].", "startOffset": 106, "endOffset": 110}, {"referenceID": 82, "context": "learning from motor babbling or imitation) [85].", "startOffset": 43, "endOffset": 47}, {"referenceID": 67, "context": "The iCub then formats each story using an IGARF graph (for Initial Goal Action Result Final) according to the different states, actions and results of actions encountered [70].", "startOffset": 171, "endOffset": 175}, {"referenceID": 57, "context": "It consists of all modules described in the last section implemented in either C++ or Python, and relies on the YARP middleware [60] for defining their connections and ensuring their parallel execution in real-time.", "startOffset": 128, "endOffset": 132}, {"referenceID": 67, "context": "The language reservoir handler will decompose the words in the narrative discourse in 3 categories: the discourse function words (DFW) which direct the discourse from one sentence to the other, the open class words (OCW) which correspond to the meaningful words in terms of vocabulary of the sentence, and the closed class words (CCW) which have a grammatical function in the sentence (see [70]).", "startOffset": 390, "endOffset": 394}], "year": 2017, "abstractText": "This paper introduces a cognitive architecture for a humanoid robot to engage in a proactive, mixed-initiative exploration and manipulation of its environment, where the initiative can originate from both the human and the robot. The framework, based on a biologically-grounded theory of the brain and mind, integrates a reactive interaction engine, a number of state-of-the art perceptual and motor learning algorithms, as well as planning abilities and an autobiographical memory. The architecture as a whole drives the robot behavior to solve the symbol grounding problem, acquire language capabilities, execute goal-oriented behavior, and express a verbal narrative of its own experience in the world. We validate our approach in a human-robot interaction experiment with the iCub humanoid robot, showing that the proposed cognitive architecture can be applied in real time within a realistic scenario.", "creator": "LaTeX with hyperref package"}}}