{"id": "1706.03912", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2017", "title": "SEP-Nets: Small and Effective Pattern Networks", "abstract": "While going deeper has been witnessed to improve the performance of convolutional neural networks (CNN), going smaller for CNN has received increasing attention recently due to its attractiveness for mobile/embedded applications. It remains an active and important topic how to design a small network while retaining the performance of large and deep CNNs (e.g., Inception Nets, ResNets). Albeit there are already intensive studies on compressing the size of CNNs, the considerable drop of performance is still a key concern in many designs. This paper addresses this concern with several new contributions. First, we propose a simple yet powerful method for compressing the size of deep CNNs based on parameter binarization. The striking difference from most previous work on parameter binarization/quantization lies at different treatments of $1\\times 1$ convolutions and $k\\times k$ convolutions ($k&gt;1$), where we only binarize $k\\times k$ convolutions into binary patterns. The resulting networks are referred to as pattern networks. By doing this, we show that previous deep CNNs such as GoogLeNet and Inception-type Nets can be compressed dramatically with marginal drop in performance. Second, in light of the different functionalities of $1\\times 1$ (data projection/transformation) and $k\\times k$ convolutions (pattern extraction), we propose a new block structure codenamed the pattern residual block that adds transformed feature maps generated by $1\\times 1$ convolutions to the pattern feature maps generated by $k\\times k$ convolutions, based on which we design a small network with $\\sim 1$ million parameters. Combining with our parameter binarization, we achieve better performance on ImageNet than using similar sized networks including recently released Google MobileNets.", "histories": [["v1", "Tue, 13 Jun 2017 06:07:26 GMT  (663kb,D)", "http://arxiv.org/abs/1706.03912v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["zhe li", "xiaoyu wang", "xutao lv", "tianbao yang"], "accepted": false, "id": "1706.03912"}, "pdf": {"name": "1706.03912.pdf", "metadata": {"source": "CRF", "title": "SEP-Nets: Small and Effective Pattern Networks", "authors": ["Zhe Li", "Xiaoyu Wang", "Xutao Lv", "Tianbao Yang"], "emails": ["zhe-li-1@uiowa.edu", "tianbao-yang@uiowa.edu", "fanghuaxue@gmail.com", "xutao.lv@snap.com"], "sections": [{"heading": "1. Introduction", "text": "In fact, it is such that most of them will be able to move into a different world, in which they are able to move, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "2. Related Work", "text": "In this section we will briefly refer to the development of modern network structures and techniques for reducing network sizes."}, {"heading": "3. Our Approach", "text": "In this section, we present the key components of the designed SEP network: Pattern Binarization and Pattern Residual Block. It is noteworthy that these two techniques are in their own interest and could be used in the design of other small neural network structures. Following these techniques, we present the detailed architecture of the designed SEP network."}, {"heading": "3.1. Pattern Binarization", "text": "Since fully connected layers have been removed in modern deep CNNs (including Inception Nets, ResNets), we are only looking at parameterized revolutionary layers here. We will take the following simple procedure to obtain a compressed network from any successful network structures, including our later described SEP network: \u2022 Step 1: Train a complete neural network such as GoogLeNet, ResNet and SEP-Net from scratch. \u2022 Step 2: Binarize k \u00b7 k (k > 1) Convolutionary filters in the well-tracted neural network model. \u2022 Step 3: Fine-tune the scaling factors of all binary k \u00b7 k filters and the floating point representations of all 1 \u2212 1 \u00b7 1 filters by backpropagating on the same dataset.The various treatments of 1 \u00d7 1 filters and k filters are characterized by their complementary roles in CNNs. k \u00b7 k \u00b7 k filters serve as spatial pattern extraction / characteristic scaling during we."}, {"heading": "3.2. Pattern Residual Block and the Architecture of", "text": "We can use this technique to reduce the size of the previous deep CNNs (e.g. GoogLeNets, Inception Nets and ResNets). To solve this problem, we propose a new design of a small and effective network (SEP-Net). Pattern Residual Block. We first describe the building block of our design - a novel block code name Residual Block (PRB). As shown in Figure 2, the PRB consists of 1 \u00d7 1 convolutions and k \u00d7 k convolutions (especially k = 3) running in parallel and their function boards together."}, {"heading": "4. Experiment", "text": "In this section, we will first present experimental results on CIFAR-10 [20] and ImageNet datasets [5] to justify that pattern binarization could drastically reduce the effective number of parameters and fine-tune other parameters of the binarized network with fixed binarized patterns to achieve performance comparable to the original neural network models. We will then show that the designed SEP-Net structure could achieve better or comparable performance on ImageNet than the use of similarly large networks as recently released Google MobileNets. We will conduct all experiments with the open library Caffe [18]."}, {"heading": "4.1. CIFAR-10", "text": "First, we conduct experiments on the CIFAR-10 dataset [20], which has 50,000 training images and 10,000 test images. Each image belongs to one of 10 classes and has a 32x32 RGB format in the original dataset. Thedata is pre-processed by Global Contrast Normalization (GCN) and ZCA Whitening [9] and is also supplemented by 4 pixels on each side of the image. In the training phase, the 32x32 cut is randomly sampled from the filled image, while in the test phase we test only on the original image. We start the learning rate of 0.1 and divide by 10 at the iteration of 32k and 48k and the maximum number of iterations is 64K. Dynamic is 0.9 and the weight drop is 0.0001. We train on a GPU with mini-batch SGD with a size of 256. We report on the test accuracy of the original paper and neural network models we have trained from the ground up."}, {"heading": "4.2. ImageNet", "text": "We conduct experiments on the ImageNet 2012 classification dataset [5], which has 1.28 million training images and 50k validation images. Each image belongs to one of 1000 classes. We apply the same pattern binarization method used to ResNet on CIFAR-10 experiment to GoogLeNet [34] and our custom inception net (referred to as C-InceptionNet), which removes all mathematically expensive 5 \u00d7 5 convolutionary cores. For training GoogLeNet we take the learning strategy from Caffe's website and the learning rate follows a polynomial decay with the initial learning rate which is 0.1, impulse term 0.9 and weight decay 0.0002."}, {"heading": "4.3. Comparison with The-State-Of-Art", "text": "Finally, we compare the proposed SEP-Net with the SqueezeNet and the recently released MobileNet in terms of model size and classification accuracy. We present the performance of several variations of our SEP-Net architectures: SEP-Net-R, SEP-Net-B, SEP-Net-BQ. Here, SEP-Net-R is our SEP-Net with raw filters. SEP-Net-B refers to SEP-Net with pattern binarization. SEP-Net-BQ quantifies all other parameters further to 8 bits. As shown in Table 6, we have trained two extremely small SEP-Nets that are suitable for mobile / embedded devices. One model has 1.3 million parameters while the other one has 1.7 million parameters. The two SEP-Nets share the same neural network structure as Figure 4. The difference between the two SEP-Nets is: (1) in the SEP-Net with 1.7M parameters, the last configuration layer uses a factor of net-4 net-3MB."}, {"heading": "5. Conclusion", "text": "In this paper, we consider neural network operations to be 1 \u00d7 1 data transformation and k \u00d7 k extraction of abstract patterns. By converting k \u00d7 k folding cores into binary patterns, we have significantly reduced the model size and computational costs of modern neural network architectures such as InceptionNets and ResNets without sacrificing network performance. Our binarization approach is extremely simple compared to previous literature. We also proposed a small network architecture that includes sample residue blocks that use binarized patterns to extract features, and 1 \u00d7 1 transformation to calculate pattern residues. The resulting precise neural network is small and effective compared to recent advances in compact neural network design. The effectiveness of our approach is intensively demonstrated using the CIFAR-10 dataset and the ImageNet dataset. We hope that our study will inspire the community to develop a more advanced architectural pattern."}, {"heading": "6. Appendix", "text": "We present the total neural network structures for the designed SEP network with 1.7 million parameters in Table 7 and SEP network with fewer parameters in Table 8."}], "references": [{"title": "Deep learning with low precision by half-wave gaussian quantization", "author": ["Z. Cai", "X. He", "J. Sun", "N. Vasconcelos"], "venue": "arXiv preprint arXiv:1702.00953,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2017}, {"title": "Compressing neural networks with the hashing trick", "author": ["W. Chen", "J. Wilson", "S. Tyree", "K. Weinberger", "Y. Chen"], "venue": "ICML,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Binaryconnect: Training deep neural networks with binary weights during propagations", "author": ["M. Courbariaux", "Y. Bengio", "J.-P. David"], "venue": "NIPS,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1", "author": ["M. Courbariaux", "I. Hubara", "D. Soudry", "R. El-Yaniv", "Y. Bengio"], "venue": "arXiv preprint arXiv:1602.02830,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Imagenet: a large-scale hierachical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "L. Li", "K. Li", "L. Fei-Fei"], "venue": "CVPR,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Devnet: A deep event network for multimedia event detection and evidence recounting", "author": ["C. Gan", "N. Wang", "Y. Yang", "D.-Y. Yeung", "A.G. Hauptmann"], "venue": "CVPR,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Fast r-cnn", "author": ["R. Girshick"], "venue": "ICCV,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "CVPR,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Maxout networks", "author": ["I.J. Goodfellow", "D. Warde-Farley", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "arXiv preprint arXiv:1302.4389,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding", "author": ["S. Han", "H. Mao", "W.J. Dally"], "venue": "arXiv preprint arXiv:1510.00149,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "A deep neural network compression pipeline: Pruning, quantization, huffman encoding", "author": ["S. Han", "H. Mao", "W.J. Dally"], "venue": "arXiv preprint arXiv:1510.00149, 10,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning both weights and connections for efficient neural network", "author": ["S. Han", "J. Pool", "J. Tran", "W. Dally"], "venue": "NIPS,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Mask r-cnn", "author": ["K. He", "G. Gkioxari", "P. Doll\u00e1r", "R. Girshick"], "venue": "arXiv preprint arXiv:1703.06870,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2017}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "CVPR,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Mobilenets: Efficient convolutional neural networks for mobile vision applications", "author": ["A.G. Howard", "M. Zhu", "B. Chen", "D. Kalenichenko", "W. Wang", "T. Weyand", "M. Andreetto", "H. Adam"], "venue": "arXiv preprint arXiv:1704.04861,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2017}, {"title": "Binarized neural networks", "author": ["I. Hubara", "M. Courbariaux", "D. Soudry", "R. El-Yaniv", "Y. Bengio"], "venue": "Advances in Neural Information Processing Systems, pages 4107\u20134115,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Squeezenet: Alexnet-level accuracy with 50x fewer parameters and\u00a1 0.5 mb model size", "author": ["F.N. Iandola", "S. Han", "M.W. Moskewicz", "K. Ashraf", "W.J. Dally", "K. Keutzer"], "venue": "arXiv preprint arXiv:1602.07360,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "arXiv preprint arXiv:1408.5093,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Local binary convolutional neural networks", "author": ["F. Juefei-Xu", "V.N. Boddeti", "M. Savvides"], "venue": "arXiv preprint arXiv:1608.06049,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky", "G. Hinton"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G. Hinton"], "venue": "NIPS,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Ternary weight networks", "author": ["F. Li", "B. Zhang", "B. Liu"], "venue": "arXiv preprint arXiv:1605.04711,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "Overcoming challenges in fixed point training of deep convolutional networks", "author": ["D.D. Lin", "S.S. Talathi"], "venue": "arXiv preprint arXiv:1607.02241,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2016}, {"title": "Network in network", "author": ["M. Lin", "Q. Chen", "S. Yan"], "venue": "arXiv preprint arXiv:1312.4400,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Neural networks with few multiplications", "author": ["Z. Lin", "M. Courbariaux", "R. Memisevic", "Y. Bengio"], "venue": "arXiv preprint arXiv:1510.03009,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "CVPR,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Ternary neural networks with fine-grained quantization", "author": ["N. Mellempudi", "A. Kundu", "D. Mudigere", "D. Das", "B. Kaul", "P. Dubey"], "venue": "arXiv preprint arXiv:1705.01462,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2017}, {"title": "Recurrent neural networks with limited numerical precision", "author": ["J. Ott", "Z. Lin", "Y. Zhang", "S.-C. Liu", "Y. Bengio"], "venue": "arXiv preprint arXiv:1608.06902,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2016}, {"title": "Xnornet: Imagenet classification using binary convolutional neural networks", "author": ["M. Rastegari", "V. Ordonez", "J. Redmon", "A. Farhadi"], "venue": "ECCV. Springer,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2016}, {"title": "Faster r-cnn: Towards real-time object detection with region proposal networks", "author": ["S. Ren", "K. He", "R. Girshick", "J. Sun"], "venue": "NIPS,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "author": ["P. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus", "Y. LeCun"], "venue": "arXiv preprint arXiv:1312.6229,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "ICLR,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Fast image gradients using binary feature convolutions", "author": ["P.-L. St-Charles", "G.-A. Bilodeau", "R. Bergevin"], "venue": "CVPR,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2016}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "CVPR,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "Deeppose: Human pose estimation via deep neural networks", "author": ["A. Toshev", "C. Szegedy"], "venue": "CVPR,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}, {"title": "Haar features for facs au recognition", "author": ["J. Whitehill", "C.W. Omlin"], "venue": "Automatic Face and Gesture Recognition, 2006. FGR 2006. 7th International Conference on, pages 5\u2013 pp. IEEE,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2006}, {"title": "Efficient non-oblivious randomized reduction for risk minimization with improved excess risk guarantee", "author": ["Y. Xu", "H. Yang", "L. Zhang", "T. Yang"], "venue": "arXiv preprint arXiv:1612.01663,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2016}, {"title": "A discriminative cnn video representation for event detection", "author": ["Z. Xu", "Y. Yang", "A.G. Hauptmann"], "venue": "CVPR,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2015}, {"title": "Training ternary neural networks with exact proximal operator", "author": ["P. Yin", "S. Zhang", "J. Xin", "Y. Qi"], "venue": "arXiv preprint arXiv:1612.06052,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2016}, {"title": "Exploiting image-trained cnn architectures for unconstrained video classification", "author": ["S. Zha", "F. Luisier", "W. Andrews", "N. Srivastava", "R. Salakhutdinov"], "venue": "arXiv preprint arXiv:1503.04144,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2015}, {"title": "Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients", "author": ["S. Zhou", "Y. Wu", "Z. Ni", "X. Zhou", "H. Wen", "Y. Zou"], "venue": "arXiv preprint arXiv:1606.06160,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 20, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 143, "endOffset": 159}, {"referenceID": 31, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 143, "endOffset": 159}, {"referenceID": 33, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 143, "endOffset": 159}, {"referenceID": 13, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 143, "endOffset": 159}, {"referenceID": 7, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 178, "endOffset": 192}, {"referenceID": 30, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 178, "endOffset": 192}, {"referenceID": 6, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 178, "endOffset": 192}, {"referenceID": 29, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 178, "endOffset": 192}, {"referenceID": 25, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 207, "endOffset": 215}, {"referenceID": 12, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 207, "endOffset": 215}, {"referenceID": 37, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 232, "endOffset": 243}, {"referenceID": 39, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 232, "endOffset": 243}, {"referenceID": 5, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 232, "endOffset": 243}, {"referenceID": 34, "context": "Deep convolutional neural networks have already achieved tremendous success on a variety of computer vision tasks such as image classification [21, 32, 34, 14], object detection [8, 31, 7, 30], segmentation [26, 13], video analysis [38, 40, 6], human pose estimation [35] among many others.", "startOffset": 267, "endOffset": 271}, {"referenceID": 20, "context": "The performance on these different tasks are dramatically boosted by sophisticated neural network structures such as AlexNet [21], NIN (Network In Network) [24], VGG-Net [32], Inception Network [34], and ResNet [14].", "startOffset": 125, "endOffset": 129}, {"referenceID": 23, "context": "The performance on these different tasks are dramatically boosted by sophisticated neural network structures such as AlexNet [21], NIN (Network In Network) [24], VGG-Net [32], Inception Network [34], and ResNet [14].", "startOffset": 156, "endOffset": 160}, {"referenceID": 31, "context": "The performance on these different tasks are dramatically boosted by sophisticated neural network structures such as AlexNet [21], NIN (Network In Network) [24], VGG-Net [32], Inception Network [34], and ResNet [14].", "startOffset": 170, "endOffset": 174}, {"referenceID": 33, "context": "The performance on these different tasks are dramatically boosted by sophisticated neural network structures such as AlexNet [21], NIN (Network In Network) [24], VGG-Net [32], Inception Network [34], and ResNet [14].", "startOffset": 194, "endOffset": 198}, {"referenceID": 13, "context": "The performance on these different tasks are dramatically boosted by sophisticated neural network structures such as AlexNet [21], NIN (Network In Network) [24], VGG-Net [32], Inception Network [34], and ResNet [14].", "startOffset": 211, "endOffset": 215}, {"referenceID": 16, "context": "However, FPGAs often have less than 10MB of on-chip memory and no off-chip memory or storage [17].", "startOffset": 93, "endOffset": 97}, {"referenceID": 0, "context": "To further reduce the model size, various compressing techniques have been introduced to deep CNNs, including parameter quantization, binarization, sharing, pruning, hashing, Huffman coding, etc [1, 4, 11, 12, 2, 16, 3, 29, 28, 41, 23].", "startOffset": 195, "endOffset": 235}, {"referenceID": 3, "context": "To further reduce the model size, various compressing techniques have been introduced to deep CNNs, including parameter quantization, binarization, sharing, pruning, hashing, Huffman coding, etc [1, 4, 11, 12, 2, 16, 3, 29, 28, 41, 23].", "startOffset": 195, "endOffset": 235}, {"referenceID": 10, "context": "To further reduce the model size, various compressing techniques have been introduced to deep CNNs, including parameter quantization, binarization, sharing, pruning, hashing, Huffman coding, etc [1, 4, 11, 12, 2, 16, 3, 29, 28, 41, 23].", "startOffset": 195, "endOffset": 235}, {"referenceID": 11, "context": "To further reduce the model size, various compressing techniques have been introduced to deep CNNs, including parameter quantization, binarization, sharing, pruning, hashing, Huffman coding, etc [1, 4, 11, 12, 2, 16, 3, 29, 28, 41, 23].", "startOffset": 195, "endOffset": 235}, {"referenceID": 1, "context": "To further reduce the model size, various compressing techniques have been introduced to deep CNNs, including parameter quantization, binarization, sharing, pruning, hashing, Huffman coding, etc [1, 4, 11, 12, 2, 16, 3, 29, 28, 41, 23].", "startOffset": 195, "endOffset": 235}, {"referenceID": 15, "context": "To further reduce the model size, various compressing techniques have been introduced to deep CNNs, including parameter quantization, binarization, sharing, pruning, hashing, Huffman coding, etc [1, 4, 11, 12, 2, 16, 3, 29, 28, 41, 23].", "startOffset": 195, "endOffset": 235}, {"referenceID": 2, "context": "To further reduce the model size, various compressing techniques have been introduced to deep CNNs, including parameter quantization, binarization, sharing, pruning, hashing, Huffman coding, etc [1, 4, 11, 12, 2, 16, 3, 29, 28, 41, 23].", "startOffset": 195, "endOffset": 235}, {"referenceID": 28, "context": "To further reduce the model size, various compressing techniques have been introduced to deep CNNs, including parameter quantization, binarization, sharing, pruning, hashing, Huffman coding, etc [1, 4, 11, 12, 2, 16, 3, 29, 28, 41, 23].", "startOffset": 195, "endOffset": 235}, {"referenceID": 27, "context": "To further reduce the model size, various compressing techniques have been introduced to deep CNNs, including parameter quantization, binarization, sharing, pruning, hashing, Huffman coding, etc [1, 4, 11, 12, 2, 16, 3, 29, 28, 41, 23].", "startOffset": 195, "endOffset": 235}, {"referenceID": 40, "context": "To further reduce the model size, various compressing techniques have been introduced to deep CNNs, including parameter quantization, binarization, sharing, pruning, hashing, Huffman coding, etc [1, 4, 11, 12, 2, 16, 3, 29, 28, 41, 23].", "startOffset": 195, "endOffset": 235}, {"referenceID": 22, "context": "To further reduce the model size, various compressing techniques have been introduced to deep CNNs, including parameter quantization, binarization, sharing, pruning, hashing, Huffman coding, etc [1, 4, 11, 12, 2, 16, 3, 29, 28, 41, 23].", "startOffset": 195, "endOffset": 235}, {"referenceID": 16, "context": "There also emerge few studies recently attempting to design small and compact networks, including the SqueezeNets [17] and the MobileNets [15].", "startOffset": 114, "endOffset": 118}, {"referenceID": 14, "context": "There also emerge few studies recently attempting to design small and compact networks, including the SqueezeNets [17] and the MobileNets [15].", "startOffset": 138, "endOffset": 142}, {"referenceID": 16, "context": "For example, the authors of [17] have designed an extremely small network with less than 0.", "startOffset": 28, "endOffset": 32}, {"referenceID": 35, "context": "In addition, many works in computer vision have used binary convolutions to extracted features from images [36, 33], while sparse projection has been reported with performance drop compared with dense projection [37].", "startOffset": 107, "endOffset": 115}, {"referenceID": 32, "context": "In addition, many works in computer vision have used binary convolutions to extracted features from images [36, 33], while sparse projection has been reported with performance drop compared with dense projection [37].", "startOffset": 107, "endOffset": 115}, {"referenceID": 36, "context": "In addition, many works in computer vision have used binary convolutions to extracted features from images [36, 33], while sparse projection has been reported with performance drop compared with dense projection [37].", "startOffset": 212, "endOffset": 216}, {"referenceID": 23, "context": "Since introduced in [24], the 1 \u00d7 1 convolutions have been extensively used in modern networks such as Inception Nets and ResNets, which can reduce the number of parameters comparing with large convolutional kernels.", "startOffset": 20, "endOffset": 24}, {"referenceID": 9, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 29, "endOffset": 37}, {"referenceID": 11, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 29, "endOffset": 37}, {"referenceID": 15, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 59, "endOffset": 70}, {"referenceID": 2, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 59, "endOffset": 70}, {"referenceID": 28, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 59, "endOffset": 70}, {"referenceID": 27, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 93, "endOffset": 113}, {"referenceID": 38, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 93, "endOffset": 113}, {"referenceID": 26, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 93, "endOffset": 113}, {"referenceID": 21, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 93, "endOffset": 113}, {"referenceID": 24, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 93, "endOffset": 113}, {"referenceID": 3, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 135, "endOffset": 141}, {"referenceID": 0, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 135, "endOffset": 141}, {"referenceID": 23, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 183, "endOffset": 191}, {"referenceID": 16, "context": "These include weight pruning [10, 12], weight binarization [16, 3, 29], weight ternarization [28, 39, 27, 22, 25], weight quantization [4, 1] and designing small and compact networks [24, 17].", "startOffset": 183, "endOffset": 191}, {"referenceID": 15, "context": "There are several differences between the proposed weight binarization and previous work on weight binarization [16].", "startOffset": 112, "endOffset": 116}, {"referenceID": 2, "context": ", BinaryConnect [3], Binarized Neural Networks [16], XNORNets [29].", "startOffset": 16, "endOffset": 19}, {"referenceID": 15, "context": ", BinaryConnect [3], Binarized Neural Networks [16], XNORNets [29].", "startOffset": 47, "endOffset": 51}, {"referenceID": 28, "context": ", BinaryConnect [3], Binarized Neural Networks [16], XNORNets [29].", "startOffset": 62, "endOffset": 66}, {"referenceID": 18, "context": "[19] exploited the local binary convolutional operators in deep CNNs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "The SqueezeNet explored several strategies to reduce the number of parameters including (i) replacing k \u00d7 k convolutions (k > 1) by 1 \u00d7 1 convolutions; (ii) decreasing the number of input channels to 3\u00d7 3 filters; and (iii) postponing the down sampling to late layers in the network [17].", "startOffset": 283, "endOffset": 287}, {"referenceID": 14, "context": "The MobileNets approximate the standard k \u00d7 k (k > 1) convolutions by depth-wise convolutions and 1 \u00d7 1 convolutions, and also introduce two hyper-parameters to balance between latency and accuracy [15].", "startOffset": 198, "endOffset": 202}, {"referenceID": 16, "context": "The optimal solutions have been studied in [17].", "startOffset": 43, "endOffset": 47}, {"referenceID": 33, "context": "To quantitatively understand the effect of binarizing 1 \u00d7 1 filters and k \u00d7 k filters, we first train a fully GoogLeNet [34], which is composed of 1 \u00d7 1, 3 \u00d7 3 and 5 \u00d7 5 convolutions filters.", "startOffset": 120, "endOffset": 124}, {"referenceID": 20, "context": "To further reduce the model size, we adopt group convolution [21] in our architecture.", "startOffset": 61, "endOffset": 65}, {"referenceID": 14, "context": "It is notable that if we set the number of groups equal to the number of input channels, it degenerates to depth-wise convolutions as used in Google\u2019s MobileNets [15].", "startOffset": 162, "endOffset": 166}, {"referenceID": 19, "context": "In this section, we first present experimental results on CIFAR-10 [20] and ImageNet dataset [5] to justify that pattern binarization could reduce the effective number of parameters dramatically and fine-tuning other parameters of the binarized network with fixed binarized pattern could achieve comparable performance to that of the original neural network models.", "startOffset": 67, "endOffset": 71}, {"referenceID": 4, "context": "In this section, we first present experimental results on CIFAR-10 [20] and ImageNet dataset [5] to justify that pattern binarization could reduce the effective number of parameters dramatically and fine-tuning other parameters of the binarized network with fixed binarized pattern could achieve comparable performance to that of the original neural network models.", "startOffset": 93, "endOffset": 96}, {"referenceID": 17, "context": "We conduct all experiments using Caffe [18] open sourced library.", "startOffset": 39, "endOffset": 43}, {"referenceID": 19, "context": "We first conduct experiments on the CIFAR-10 dataset [20], which has 50,000 training images and 10,000 test images.", "startOffset": 53, "endOffset": 57}, {"referenceID": 8, "context": "The data is preprocessed by Global Contrast Normalization (GCN) and ZCA whitening [9] and also padded by 4 pixels on each side of image.", "startOffset": 82, "endOffset": 85}, {"referenceID": 13, "context": "We apply pattern binarization to several recent successful network structures: ResNet-20, ResNet-32, ResNet-44, ResNet-56 [14].", "startOffset": 122, "endOffset": 126}, {"referenceID": 4, "context": "ImageNet We also carry out experiments on the ImageNet 2012 classification data set [5], which has 1.", "startOffset": 84, "endOffset": 87}, {"referenceID": 33, "context": "We apply the same pattern binarization procedure used to ResNet on CIFAR-10 experiment to GoogLeNet [34] and our customized Inception-net (denoted as C-InceptionNet) that removes all computationally expensive 5\u00d7 5 convolutional kernels .", "startOffset": 100, "endOffset": 104}, {"referenceID": 20, "context": "We present comparison results including test performance on Refined model using multicrop [21] in Table 4, from which we could see: i) for C-InceptionNet, the performance of the Refined model is competitive to the full model, just 0.", "startOffset": 90, "endOffset": 94}], "year": 2017, "abstractText": "While going deeper has been witnessed to improve the performance of convolutional neural networks (CNN), going smaller for CNN has received increasing attention recently due to its attractiveness for mobile/embedded applications. It remains an active and important topic how to design a small network while retaining the performance of large and deep CNNs (e.g., Inception Nets, ResNets). Albeit there are already intensive studies on compressing the size of CNNs, the considerable drop of performance is still a key concern in many designs. This paper addresses this concern with several new contributions. First, we propose a simple yet powerful method for compressing the size of deep CNNs based on parameter binarization. The striking difference from most previous work on parameter binarization/quantization lies at different treatments of 1\u00d7 1 convolutions and k\u00d7k convolutions (k > 1), where we only binarize k \u00d7 k convolutions into binary patterns. The resulting networks are referred to as pattern networks. By doing this, we show that previous deep CNNs such as GoogLeNet and Inception-type Nets can be compressed dramatically with marginal drop in performance. Second, in light of the different functionalities of 1\u00d71 (data projection/transformation) and k \u00d7 k convolutions (pattern extraction), we propose a new block structure codenamed the pattern residual block that adds transformed feature maps generated by 1\u00d71 convolutions to the pattern feature maps generated by k \u00d7 k convolutions, based on which we design a small network with \u223c 1 million parameters. Combining with our parameter binarization, we achieve better performance on ImageNet than using similar sized networks including recently released Google MobileNets.", "creator": "LaTeX with hyperref package"}}}