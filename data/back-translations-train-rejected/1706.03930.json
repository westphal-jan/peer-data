{"id": "1706.03930", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2017", "title": "Item Difficulty-Based Label Aggregation Models for Crowdsourcing", "abstract": "A large amount of labeled data is required for supervised learning. However, labeling by domain experts is expensive and time-consuming. A low cost and high efficiency way to obtain large training datasets is to aggregate noisy labels collected from non-professional crowds. Prior works have proposed confusion matrices to evaluate the reliability of workers. In this paper, we redefine the structure of the confusion matrices and propose two Bayesian Network based methods which utilize item difficulty in label aggregation. We assume that labels are generated by a probability distribution over confusion matrices, item difficulties, labels and true labels. We use Markov chain Monte Carlo method to generate samples from the posterior distribution of model parameters and then infer the results. To avoid bad local optima, we design a method to preliminarily predict the difficulty of each item and initialize the model parameters. We also introduce how to improve the scalability of our model. Empirical results show that our methods consistently outperform state-of-the-art methods.", "histories": [["v1", "Tue, 13 Jun 2017 07:28:26 GMT  (129kb)", "http://arxiv.org/abs/1706.03930v1", null], ["v2", "Wed, 5 Jul 2017 07:28:14 GMT  (2431kb)", "http://arxiv.org/abs/1706.03930v2", null], ["v3", "Tue, 3 Oct 2017 09:18:04 GMT  (78kb)", "http://arxiv.org/abs/1706.03930v3", null]], "reviews": [], "SUBJECTS": "cs.AI cs.HC cs.LG", "authors": ["chi hong"], "accepted": false, "id": "1706.03930"}, "pdf": {"name": "1706.03930.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["hc15@mails.tsinghua.edu.cn"], "sections": [{"heading": null, "text": "ar Xiv: 170 6.03 930v 1 [cs.A I] 1 3Ju n20 17monitored learning. However, labeling by specialists is costly and time consuming. A cost-effective and highly efficient method to obtain large training data sets is the aggregation of sound labels collected by laymen. Previous work has suggested confusion matrices to evaluate the reliability of workers. In this essay, we redefine the structure of the confusion matrices and propose two methods based on the Bajian network that take advantage of the difficulty of label aggregation. We assume that labels are generated by a probability distribution of confusion matrices, item difficulties, labels and true labels. We use the Markov chain Monte Carlo method to generate patterns from the downstream distribution of model parameters and derive the results from it. In order to avoid poor local optimizations, we also design a model parameter to improve each one, and we also implement a consistent method to improve each one."}, {"heading": "1. Introduction", "text": "In fact, this data cannot be used directly for modeling, it should be labeled first. It is expensive and time consuming to employ domain experts who split large amounts of data into small pieces and distribute these small label tasks to workers. [5] However, these non-professional workers can provide noisy labels. Each worker's accuracy may be lower than expected. To improve accuracy, it is important to infect the noisy labels and infect the true labels."}, {"heading": "2. Related Work", "text": "Raykar et al. [9] proposed the two-coin binary identification model, which can be regarded as a variation of the confusion matrix, in which the labels produced by the workers are used directly for learning, and the authors used a minimax entropy method to estimate the distributions and derive the true markings from them. Kim and Ghahramani [10] used the confusion matrix to define their Bayesian classifier combination model (BCC), which is a Bayesian extension of the Dawid and Skene method. Venanzi et al. [12] extended the BCC model and proposed the CommunityBCC model, which groups workers into communities. Workers belonging to the same community have similar confusion matrices."}, {"heading": "3. Preliminary", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Notation", "text": "In the aggregation problem, we consider that there are K-workers and I-articles. In each task, the workers must label an article. Li, k is the label of article i, which is labeled by worker k, where Li, k-1,..., C}. C is the number of classes. L is a collection of all the labels collected. Note that each worker may only label part of the record, if worker k has not labeled the item i, then Li, k = None. Ti is the true label of article i and T = {T1,..., TI} contains all the true labels."}, {"heading": "3.2. Majority Voting", "text": "Majority voting is a simple and straightforward method for aggregating labels. For each element i, the most common answer is selected as the true labeling Ti. This can be represented as follows: Ti = argmax l,..., C} K \u2211 k = 1I (Li, k = l) (1), where I (\u00b7) is the indicator function that assumes the value 1 if the predicate is true, and 0 otherwise. Majority voting is easy to implement and can normally produce a high-quality aggregation result, although it only looks at each element independently. In recent years, several papers have expanded this method [19], [20]."}, {"heading": "4. Methods", "text": "Lately, there are many works [9], [10], [15], [21] that use this kind of confusion matrix to evaluate a worker's abilities and create their own models.As mentioned in Section 1, these models do not take into account the characteristics of label tasks, such as the difficulties of items. In these models, the confusion matrix correlates only with the difficulty level. It is somewhat unreasonable. Therefore, we try to predict and use the item difficulty information in label aggregation. In our models, we use two indexes for the confusion matrix, one is worker and the other is difficulty level IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii"}, {"heading": "4.1. Item Difficulty-Based Label Aggregation Model", "text": "In our model, each element i correlates with a degree of difficulty Qi = \u03b2 = \u03b2 = \u03b2 = Q = \u03b2 (\u03b2 = 1), where H is the number of degrees of difficulty. We determine an independent probable confusion matrix \u03c0 (k, h) for each worker-difficulty pair (k, h). Let us consider point i with true denomination Ti (1,..., C) and degree of difficulty Qi, we leave p (Li, k, Qi) Ti, Li, k. That is, let us consider point i with true denomination Ti, k, which was generated by worker k for item i, has a multinomial distribution with parameters. (k) Ti: Li, k: Multinomial (k) Multinomial distribution (k, Qi) Ti). (2) Each worker generates his own denominations Li, k: labels for different items are independent and identically distributed. Thus we can obtain: c, Q, Q = K, Q = Q."}, {"heading": "4.2. Fixed-IDBLA Model", "text": "In the dataset, there may be some very simple items and some very difficult items. We assume that each worker labels the simple items at a high correct rate and labels the difficult items at a very low correct rate. On the basis of this assumption, we propose the fixed IDBLA model, which is a variation of IDBLA. The factor graph for this model is shown in Figure 2. In the fixed IDBLA note: \"K, H \u2212 1) for simple items and fixed items (k, H) for difficult items where k,..., K}. The collection (k, H \u2212 1) and \u03c0 (k, H) are presented as:\" t \"(k, H \u2212 1) = 1 \u2212 1 \u2212 H \u2212 1.\" The location C \u2212 1 \u2212 1 \u2212 1.. \"We.. The location C \u2212 1...................... We assume C \u2212 1.\""}, {"heading": "4.3. Parameter Initialization", "text": "In many crowdsourcing methods, such as BCC [10], DSEM [8], CrowdSVM [19] and DiagCov [13], the unknown, true labels are initialized by majority decisions to avoid bad local optimizations.In our models, we have introduced the concept of item difficulty. Both parameters T and Q must be initialized. We manage to design a low overhead method to initialize them. Instead of making a precise prediction, we only make a preliminary prediction of the true item and difficulty levels Q to avoid bad local optimizations in nonconvex optimization.In reality, the labels of truth on the ground are unknown. So, we use majority decisions to initialize T, and approach T as a collection of item and difficulty levels. Based on T, we calculate the correct rate Rk for each worker k: Rk = 1 (Tk = I, Tk = Li)."}, {"heading": "5. Experiments", "text": "IDBLA and Fixed-IDBLA are compared with three state-of-the-art algorithms: Majority Voting, DS-EM and BCC. In our experiments we use three real crowdsourcing datasets and one synthetic dataset. In the following we present our experiments in detail and evaluate the effectiveness of our models."}, {"heading": "5.1. Datasets", "text": "The four sets of data are shown in Table 1. They have different sizes and characteristics. We introduce them in the following paragraphs: 5.1.1. Heart Disease Diagnosis. We have the heart disease cases [22] and the corresponding basic truth labels from the UC Irvine machine learning repository website. Each instance contains attributes such as age, gender, maximum heart rate achieved, etc. We removed the basic truth labels and asked 12 medical students to label the instances in their leisure time. These students voluntarily offer the labels without payment. They have different levels of competence about heart disease diagnosis. For each instance, we do not care about the type of heart disease, we only look at whether the patient has heart disease. Each student does not have to label all the instances of heart disease 87 and there are another 150 instances for health. There are 237 instances for which we have a total of 852 labels. The average accuracy of the students is 68.59%. The student who was labeled the most instances with 813 279 instances."}, {"heading": "5.2. Baselines", "text": "In this section, we will simply present DS-EM and BCC.5.2.1. DS-EM [8]. DS-EM [8] is a classic generative approach. It also assumes that the worker performs consistent performance in various marking tasks and designates the probability of items as class c if the true identification of the item is t. DS-EM uses an Expectation Maximization Algorithm (EM) to obtain maximum probability estimates of items and T.E steps: Estimation of T by using: p (Ti = t | L, E} and t {1, C}. DS-EM uses an Expectation Maximization Algorithm (EM) to obtain maximum probability estimates of items and T.E steps: Estimation of T by using: p (Ti = t | L, E) and T steps: maximum confusion of items (Ti = t)."}, {"heading": "5.3. Setups", "text": "The majority voting is carried out according to the introduction in Section 3.3. If there are several most common classes for the point, the majority voting algorithm will randomly select one of them. To avoid bad local optimism, DS-EM and BCC use majority votes to initialize the unknown true names. For the BCC, the hyperparameters are set as described in Kim's work. Model parameters are also initialized according to the paper's description. For the IDBLA model, T (h) t, \u03b3\u03b1c and \u03b3\u03b2h are all set as 1.0, meaning that the distributions of \u03c0 (k, h) t, and \u00df have data priors.As described in Section 4.3, T is initialized by majority voting. It is initialized by the result of the counting of T, \u03b1c = \u0421\u0430\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441sist of the list of the list of the I"}, {"heading": "5.4. Experimental Results", "text": "In this section we compare the accuracy of our methods and the three baseline methods. We also show the iteration processes of BCC, IDBLA and Fixed-IDBLA. In Section 5.4.3, the negative log probability is used to evaluate the fairness of the experiments. In Section 5.4.4, we will further investigate our methods. We use a PC with Intel Core i5 2.6GHz CPU and 8GB RAM for our experiments. To guarantee the fairness of the experiments, we use uninformed priors in all methods. We use majority voting to initialize parameters in all methods. All graphical models use the same inference algorithm. Gibbs sampling is able to perform conclusions in our experiments. Each method has the same input data format for fair comparisons. 5.4.1. Accuracies of methods we use accuracy to evaluate the performance of each method."}, {"heading": "6. Extension", "text": "In Section 5, the conclusion is made with Gibbs sampling. Sampling methods are mathematically sophisticated. Gibbs sampling is not able to solve the problem of scalability. Fortunately, lately, the GPU has been using variable inference to speed up sampling [23]. We can also use variative inference [24], [25] to solve the problem of scalability. In this section, we will briefly introduce how to apply variable inference to our IDBLA model. We assume that q factoring: q (T, Q, Phillips, \u03b1, \u03b1, \u03b2 | L, \u00b5) can be done using a simpler distribution q (T, Q, \u03c0, \u03b1, Maximillimeter)."}, {"heading": "7. Conclusion", "text": "Each difficulty pair is associated with a confusion matrix; the model finds the values of the confusion matrices and other latent variables in the learning process and uses them further to derive the true terms from them. We also define a variation model of the IDBLA, which assumes that there are some very simple and some very difficult items. We call this variation model Fixed-IDBLA. We design a method for predicting the difficulty of each item provisionally; the predictive results are used to initialize the latent parameters in IDBLA and Fixed-IDBLA. Initialization is important for the performance of our models. The experiments are performed on three real data sets and one synthetic dataset. These datasets have different characteristics, as shown in Section 5.1. Empirical results show that our methods are effective."}], "references": [{"title": "and C", "author": ["S. Ertekin", "H. Hirsh"], "venue": "Rudin, Approximating the wisdom of the crowd", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning to predict from crowdsourced data", "author": ["W. Bi", "L. Wang", "J.T. Kwok", "Z. Tu"], "venue": "UAI", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Combining human and machine intelligence in large-scale crowdsourcing", "author": ["E. Kamar", "S. Hacker", "E. Horvitz"], "venue": "Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems-Volume 1. International Foundation for Autonomous Agents and Multiagent Systems", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "The multidimensional wisdom of crowds", "author": ["P. Welinder", "S. Branson", "S.J. Belongie", "P. Perona"], "venue": "NIPS, vol. 23", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Whose vote should count more: Optimal integration of labels from labelers of unknown expertise, in Advances in neural information processing", "author": ["J. Whitehill", "T.-f. Wu", "J. Bergsma", "J.R. Movellan", "P.L. Ruvolo"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Learning from the wisdom of crowds by minimax entropy", "author": ["D. Zhou", "S. Basu", "Y. Mao", "J.C. Platt"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Cheap and fastbut is it good?: evaluating non-expert annotations for natural language tasks", "author": ["R. Snow", "B. OConnor", "D. Jurafsky", "A.Y. Ng"], "venue": "Proceedings of the conference on empirical methods in natural language processing. Association for Computational Linguistics", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Maximum likelihood estimation of observer error-rates using the em algorithm", "author": ["A.P. Dawid", "A.M. Skene"], "venue": "Applied statistics, pp. 2028", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1979}, {"title": "Learning from crowds", "author": ["V.C. Raykar", "S. Yu", "L.H. Zhao", "G.H. Valadez", "C. Florin", "L. Bogoni", "L. Moy"], "venue": "Journal of Machine Learning Research, vol. 11, no. Apr, pp. 12971322", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Bayesian classifier combination", "author": ["H.-C. Kim", "Z. Ghahramani"], "venue": "AISTATS", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Identifying and accounting for task-dependent bias in crowdsourcing", "author": ["E. Kamar", "A. Kapoor", "E. Horvitz"], "venue": "Third AAAI Conference on Human Computation and Crowdsourcing", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Community-based bayesian aggregation models for crowdsourcing", "author": ["M. Venanzi", "J. Guiver", "G. Kazai", "P. Kohli", "M. Shokouhi"], "venue": "Proceedings of the 23rd international conference on World wide web. ACM", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "A correlated worker model for grouped", "author": ["A.T. Nguyen", "B.C. Wallace", "M. Lease"], "venue": "imbalanced and multitask data, in Proceedings of The Conference on Uncertainty in Artificial Intelligence (UAI)", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Crowdsourcing via tensor augmentation and completion", "author": ["Y. Zhou", "J. He"], "venue": "Proceedings of the Twenty- Fifth International Joint Conference on Artificial Intelligence. AAAI Press", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Variational inference for crowdsourcing", "author": ["Q. Liu", "J. Peng", "A.T. Ihler"], "venue": "Advances in neural information  processing systems", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Training deep neural nets to aggregate crowdsourced responses", "author": ["A. Gaunt", "D. Borsa", "Y. Bachrach"], "venue": "Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence. AUAI Press", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Iterative learning for reliable crowdsourcing systems", "author": ["D.R. Karger", "S. Oh", "D. Shah"], "venue": "Advances in neural information processing systems", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Efficient crowdsourcing of unknown experts using bounded multi-armed bandits", "author": ["L. Tran-Thanh", "S. Stein", "A. Rogers", "N.R. Jennings"], "venue": "Artificial Intelligence, vol. 214, pp. 89111", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Max-margin majority voting for learning from crowds", "author": ["T. Tian", "J. Zhu"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Error rate bounds and iterative weighted majority voting for crowdsourcing", "author": ["H. Li", "B. Yu"], "venue": "arXiv preprint arXiv:1411.4086", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Spectral methods meet em: A provably optimal algorithm for crowdsourcing", "author": ["Y. Zhang", "X. Chen", "D. Zhou", "M.I. Jordan"], "venue": "Advances in neural information processing systems", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Heart disease data set", "author": ["A. Janosi", "W. Steinbrunn", "M. Pfisterer", "R. Detrano"], "venue": "https://archive.ics.uci.edu/ml/datasets/Heart+Disease", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1988}, {"title": "Saberlda: Sparsity-aware learning of topic models on gpus", "author": ["K. Li", "J. Chen", "W. Chen", "J. Zhu"], "venue": "International Conference on Architectural Support for Programming Languages and Operating Systems (ASP- LOS), pp. 497509", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2017}, {"title": "M", "author": ["M.J. Wainwright"], "venue": "I. Jordan et al., Graphical models, exponential families, and variational inference, Foundations and Trends R in Machine Learning, vol. 1, no. 12, pp. 1305", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "Journal of machine Learning research, vol. 3, no. Jan, pp. 9931022", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "Recently, crowdsourcing has become a cheap and efficient way to make large training datasets [1], [2], [3], [4].", "startOffset": 93, "endOffset": 96}, {"referenceID": 1, "context": "Recently, crowdsourcing has become a cheap and efficient way to make large training datasets [1], [2], [3], [4].", "startOffset": 98, "endOffset": 101}, {"referenceID": 2, "context": "Recently, crowdsourcing has become a cheap and efficient way to make large training datasets [1], [2], [3], [4].", "startOffset": 103, "endOffset": 106}, {"referenceID": 3, "context": "Recently, crowdsourcing has become a cheap and efficient way to make large training datasets [1], [2], [3], [4].", "startOffset": 108, "endOffset": 111}, {"referenceID": 4, "context": "Online platforms such as Crowdflower and Amazon Mechanical Turk can split large dataset into small parts and distribute these small labeling tasks to workers [5].", "startOffset": 158, "endOffset": 161}, {"referenceID": 5, "context": "In most cases, it has significantly better performance than single workers [6], [7].", "startOffset": 75, "endOffset": 78}, {"referenceID": 6, "context": "In most cases, it has significantly better performance than single workers [6], [7].", "startOffset": 80, "endOffset": 83}, {"referenceID": 7, "context": "Dawid and Skene [8] associated each worker with a confusion matrix which can evaluate the reliabilities and potential biases of the workers.", "startOffset": 16, "endOffset": 19}, {"referenceID": 8, "context": "In recent years, there are many works which also use confusion matrices to build label aggregation models [9], [9], [10], [10], [11].", "startOffset": 106, "endOffset": 109}, {"referenceID": 8, "context": "In recent years, there are many works which also use confusion matrices to build label aggregation models [9], [9], [10], [10], [11].", "startOffset": 111, "endOffset": 114}, {"referenceID": 9, "context": "In recent years, there are many works which also use confusion matrices to build label aggregation models [9], [9], [10], [10], [11].", "startOffset": 116, "endOffset": 120}, {"referenceID": 9, "context": "In recent years, there are many works which also use confusion matrices to build label aggregation models [9], [9], [10], [10], [11].", "startOffset": 122, "endOffset": 126}, {"referenceID": 10, "context": "In recent years, there are many works which also use confusion matrices to build label aggregation models [9], [9], [10], [10], [11].", "startOffset": 128, "endOffset": 132}, {"referenceID": 8, "context": "[9] proposed the two two-coin model for binary labeling tasks, which can be seen as a variation of the confusion matrix.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "In Minimax Conditional Entropy (MMCE) [6], each worker-item pair is related to a independent distribution.", "startOffset": 38, "endOffset": 41}, {"referenceID": 9, "context": "Kim and Ghahramani [10] used the confusion matrix to define their Bayesian Classifier Combination (BCC) model which is a Bayesian extension of Dawid and Skene\u2019s method.", "startOffset": 19, "endOffset": 23}, {"referenceID": 11, "context": "[12] extended the BCC model and proposed the CommunityBCC model, which groups workers into communities.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] also proposed a graphical model based approach for crowdsourcing.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "Zhou and He [14] proposed a approach which based on tensor augmentation and completion for crowdsourcing.", "startOffset": 12, "endOffset": 16}, {"referenceID": 4, "context": "The GLAD model [5] is based on parameters which represent the expertise of workers and difficulties of items.", "startOffset": 15, "endOffset": 18}, {"referenceID": 14, "context": "[15] also used a single parameter to describe the reliability of a worker.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] trained a deep neural network for label aggregation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] put different weights on workers in their model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "In recent years, Multi-Armed Bandits based method [18] has been proposed for crowdsourcing.", "startOffset": 50, "endOffset": 54}, {"referenceID": 18, "context": "Recent years, there are several works have extended this method [19], [20].", "startOffset": 64, "endOffset": 68}, {"referenceID": 19, "context": "Recent years, there are several works have extended this method [19], [20].", "startOffset": 70, "endOffset": 74}, {"referenceID": 7, "context": "Methods Dawid and Skene\u2019s method [8] associates each worker k with a probabilistic confusion matrix \u03c6.", "startOffset": 33, "endOffset": 36}, {"referenceID": 8, "context": "Recently, there are many works [9], [10], [15], [21] use this kind of confusion matrix to evaluate the ability of a worker, and build their own models.", "startOffset": 31, "endOffset": 34}, {"referenceID": 9, "context": "Recently, there are many works [9], [10], [15], [21] use this kind of confusion matrix to evaluate the ability of a worker, and build their own models.", "startOffset": 36, "endOffset": 40}, {"referenceID": 14, "context": "Recently, there are many works [9], [10], [15], [21] use this kind of confusion matrix to evaluate the ability of a worker, and build their own models.", "startOffset": 42, "endOffset": 46}, {"referenceID": 20, "context": "Recently, there are many works [9], [10], [15], [21] use this kind of confusion matrix to evaluate the ability of a worker, and build their own models.", "startOffset": 48, "endOffset": 52}, {"referenceID": 9, "context": "Parameter Initialization In many crowdsourcing methods, such as BCC [10], DSEM [8], CrowdSVM [19], and DiagCov [13], the unknown true labels are initialized by majority voting to avoid bad local optima.", "startOffset": 68, "endOffset": 72}, {"referenceID": 7, "context": "Parameter Initialization In many crowdsourcing methods, such as BCC [10], DSEM [8], CrowdSVM [19], and DiagCov [13], the unknown true labels are initialized by majority voting to avoid bad local optima.", "startOffset": 79, "endOffset": 82}, {"referenceID": 18, "context": "Parameter Initialization In many crowdsourcing methods, such as BCC [10], DSEM [8], CrowdSVM [19], and DiagCov [13], the unknown true labels are initialized by majority voting to avoid bad local optima.", "startOffset": 93, "endOffset": 97}, {"referenceID": 12, "context": "Parameter Initialization In many crowdsourcing methods, such as BCC [10], DSEM [8], CrowdSVM [19], and DiagCov [13], the unknown true labels are initialized by majority voting to avoid bad local optima.", "startOffset": 111, "endOffset": 115}, {"referenceID": 4, "context": "This idea is inspired by GLAD [5] which can simultaneously infer the true labels of items, the abilities of workers and the difficulties of items.", "startOffset": 30, "endOffset": 33}, {"referenceID": 21, "context": "We got the heart disease instances [22] and the corresponding ground truth labels from the UC Irvine machine learning repository website.", "startOffset": 35, "endOffset": 39}, {"referenceID": 5, "context": "TheWeb Search [6] dataset is about web search relevance judgment.", "startOffset": 14, "endOffset": 17}, {"referenceID": 6, "context": "RTE [7] contains 8000 binary labels for 800 documents.", "startOffset": 4, "endOffset": 7}, {"referenceID": 7, "context": "DS-EM [8] is a classic generative approach.", "startOffset": 6, "endOffset": 9}, {"referenceID": 9, "context": "We implemented the method according to Kim\u2019s paper [10] which uses Gibbs sampling and rejection sampling to infer the unknown model parameters.", "startOffset": 51, "endOffset": 55}, {"referenceID": 22, "context": "Fortunately, in recently GPU has been used to accelerate sampling [23].", "startOffset": 66, "endOffset": 70}, {"referenceID": 23, "context": "We also can use variational inference [24], [25] to solve the problem of scalability.", "startOffset": 38, "endOffset": 42}, {"referenceID": 24, "context": "We also can use variational inference [24], [25] to solve the problem of scalability.", "startOffset": 44, "endOffset": 48}], "year": 2017, "abstractText": "A large amount of labeled data is required for supervised learning. However, labeling by domain experts is expensive and time-consuming. A low cost and high efficiency way to obtain large training datasets is to aggregate noisy labels collected from non-professional crowds. Prior works have proposed confusion matrices to evaluate the reliability of workers. In this paper, we redefine the structure of the confusion matrices and propose two Bayesian Network based methods which utilize item difficulty in label aggregation. We assume that labels are generated by a probability distribution over confusion matrices, item difficulties, labels and true labels. We use Markov chain Monte Carlo method to generate samples from the posterior distribution of model parameters and then infer the results. To avoid bad local optima, we design a method to preliminarily predict the difficulty of each item and initialize the model parameters. We also introduce how to improve the scalability of our model. Empirical results show that our methods consistently outperform state-of-the-art methods.", "creator": "LaTeX with hyperref package"}}}