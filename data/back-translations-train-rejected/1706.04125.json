{"id": "1706.04125", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2017", "title": "Online Learning for Structured Loss Spaces", "abstract": "We consider prediction with expert advice when the loss vectors are assumed to lie in a set described by the sum of atomic norm balls. We derive a regret bound for a general version of the online mirror descent (OMD) algorithm that uses a combination of regularizers, each adapted to the constituent atomic norms. The general result recovers standard OMD regret bounds, and yields regret bounds for new structured settings where the loss vectors are (i) noisy versions of points from a low-rank subspace, (ii) sparse vectors corrupted with noise, and (iii) sparse perturbations of low-rank vectors. For the problem of online learning with structured losses, we also show lower bounds on regret in terms of rank and sparsity of the source set of the loss vectors, which implies lower bounds for the above additive loss settings as well.", "histories": [["v1", "Tue, 13 Jun 2017 15:31:22 GMT  (26kb)", "http://arxiv.org/abs/1706.04125v1", "23 pages"]], "COMMENTS": "23 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["siddharth barman", "aditya gopalan", "aadirupa saha"], "accepted": false, "id": "1706.04125"}, "pdf": {"name": "1706.04125.pdf", "metadata": {"source": "CRF", "title": "Online Learning for Structured Loss Spaces", "authors": ["Siddharth Barman", "Aditya Gopalan", "Aadirupa Saha"], "emails": ["barman@csa.iisc.ernet.in", "aditya@ece.iisc.ernet.in", "aadirupa.saha@csa.iisc.ernet.in"], "sections": [{"heading": null, "text": "ar Xiv: 170 6.04 125v 1 [cs.L G] June 13, 2017We look at predictions with expert advice when it is assumed that the loss vectors are in a sentence described by the sum of the atomic standard balls. We derive a regret for a general version of the Online Mirror Descent (OMD) algorithm that uses a combination of regulators, each of which is adapted to the constituent atomic norms. The general result retracts default OMD repentance limits and results in repentance limits for new structured environments where the loss vectors are (i) loud versions of dots from a subspace subordinate to them, (ii) sparse vectors corrupted by noise, and (iii) sparse interference from low-level vectors. For the problem of online learning with structured losses, we also show lower limits of regret in terms of rank and low quantum value added to the losses mentioned above, which implies lower losses for the losses."}, {"heading": "1 Introduction", "text": "This is a real problem that we seek to minimize in relation to a sequence of loss functions that are initially unknown but which have been causally revealed. Specifically, it seeks to achieve a low regret for each sequence of loss sequences, relative to the best single decision point line in Hindsight. Online learning theory has now yielded flexible and elegant algorithmic techniques that have been proven to enjoy sublinear regret over the time horizon of games. Regret bounds for online learning algorithms typically hold over inputs (loss function sequences) that have little or no structure, such as predicting with experts expecting exponentially weighted predictions that the Cesa-Bianchi and Lugosi, 2006] will achieve an expected regret for (loss function sequences) that have little or no structure."}, {"heading": "2 Notation and Preliminaries", "text": "For a vector, xi denotes the ith component of x. The p-norm of x is defined as \"x-p\" = \"i = 1 | xi | p) 1 / p, 0 \u2264 p <. Write\" x-p \": = maxni = 1 | xi | and\" x-i | xi 6 = 0. \"If\" i-xi \"is a norm defined on a closed convex series of\" Rn, \"then its corresponding dual norm is defined as\" p-norm \"= sup x-ig:\" x-u, \"where\" i xiui \"is the default inner product in Euclidean space. It follows that the dual of the standard p-norm (p-1) is the q norm, where\" q \"is the conjugate of\" i, \"where\" i-xiui \"is the default product in Euclidean space.\""}, {"heading": "2.1 Atomic Norm and its Dual [Chandrasekaran et al., 2012]", "text": "Next, we define the concept of an atomic standard along with its dual. These concepts will provide us with a uniform framework for coping with structured loss dreams and will be used extensively in the work. Let A'Rn be a proposition that is convex, compact and centrally symmetrical in origin (i.e., a dual of the atomic standard caused by A if it is a dual). The atomic standard induced by quantity A is defined as | x | | A: = inf {t > 0 | x-tA}, for example x-R. The dual of the atomic standard induced by A becomes the supporting function of A [Boyd and Vandenberghe, 2004]; formally, | x | | A: = sup {x.z | z-A}, for x-R. For example, if the dual standard is the convex shell of all unity standard-sparse vectors, i.e., A: = conv =.ei (= \u00b1 z)."}, {"heading": "2.2 Problem setup", "text": "We view the online learning problem of learning with the expert opinion of a collection of experts (Cesa-Bianchi and Lugosi, 2006) as a problem we do not know. (D) We view the online learning problem of learning with the expert opinion (D) as a problem in which the learner selects an expert from a distribution who defies the expert opinion whose advice must be followed. (D) The learners suffer an expected loss of EEs (D) = 1 pt (i) pt (i) lt (i).When the game is played for a total number of T-rounds, the learner's goal is to minimize the expected cumulative regrets as follows: E (D) pt = 1 pt (i) lt (i).When the game is played for a total number of T-rounds, the learner's goal is to minimize the expected cumulative regrets defined as: E (D)."}, {"heading": "2.3 Online Mirror Descent", "text": "In this section we give a brief introduction to Online Mirror Reflection (OMD) (OMD). (Shalev-Shwartz, 2012a), which is a subgrading descent method for online optimization with an appropriately chosen regulator (see, e.g., Beck and Teboulle [2003]). Before detailing the algorithms, we will recall a few relevant definitions: Definition 1. Bregman divergence. Let's define a convex set, and f: R be a strict convex set, and differentifunction. Then the Bregman divergence associated with f, denoted by Bf: 1, is defined asBf (u, v)."}, {"heading": "3 Online Mirror Descent for Structured Losses", "text": "This section shows that in the case of specific structured loss spaces, the instantiation of the OMD algorithm - if the standard is chosen correctly - leads to improved loss guarantees (bound above the standard O (\u221a 2T lnN). Evidence for these results appears in Appendix B.1. Sparse loss space: L = {l \u00b2 2 q, where q = ln s \u00b2 0 = s \u00b2, s \u00b2 s \u00b2 2, as regulation parameters. Thenusing q-norm, R (x) = x \u00b2 2q = (sp. N = 1 (x q i) 2 q, where q = ln s \u00b2 ln s \u00b2 s \u00b2 s \u00b2 s \u00b2 - 1, s \u00b2 2, as regulation parameter we get, RegretT \u2264 2 \u00b0 ln (s + 1) T.2."}, {"heading": "4 Online Learning for Additive Loss Spaces", "text": "We now present a key result of this work, which enables us to obtain new regret limits from old times. In particular, we will develop a framework which provides an appropriate regulation method for losses from old times. (...) We will choose an appropriate regulatory framework for losses from old times, in which there are two central regret values. (...) L1, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2, L2 L2, L2, L2 L2, L2, L2, L2 L2, L2 L2, L2 L2, L2, L2 L2, L2, L2 L2."}, {"heading": "4.1 Proof of Theorem 4", "text": "Before we further deepen the theorem, we will list the following useful lemmas: \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" A, \"A,\" \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" \"A,\" A, \"A,\" A, \"\" A, \"A,\" A, \"A,\" \"A,\" A, \"\" A, \"A,\" A, \"A,\" A, \"A,\" \"A,\" A, \"A,\" A, \"\" A, \"A,\" A, \"\" A, \"A,\" A, \"A,\" A, \"\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"\" A, \"A,\" A, \"\" A, \"A,\" A, \"A,\" A, \"\" A, \"A,\" A, \"\" A, \"A,\" A, \"A,\" A, \"\" A, \"A,\" A, \"\" A, \"A,\" A, \"A,\" \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"\" A, A,"}, {"heading": "4.2 Applications of Theorem 4", "text": "In this section we will derive novel remorse limits for additive loss dreams (L = L1 + L2), with the individual components (L1 and L2) being the loss dreams taken into account in Section 3. These results are derived by applying Theorem 4; details of the proofs appear in Appendix C. Corollary 10 (Noisy Low Rank). Suppose L1 = {l] N | l = Uv} is a d rank loss space (1 \u2264 d \u2264 lnN) affected by noisy losses L2 = {l \u00b2 (0, 1] N | l \u00b2 s \u00b2 n \u00b2 s loss space (0, 1] N = L1 + L2 - with regulator R (x) = x Hx + Hx = Hx = Hx = Hx = Hx = 22 and learning rate Hx = lulle = 1 (16d + lulle) T - is the upper edge as a consequence."}, {"heading": "5 Lower Bounds", "text": "In this section, we will derive lower learning effects for online learning. (...) First, we will deduce the lower limit for a general learning-learning-effect-learning-effect-learning-effect-learning-effect-learning-effect-learning-learn-effect-learning-effect-learning-effect-learning-effect-learning-effect-learning-effect-learning-effect-learning-effect-learning-effect-more-efficient-effect-learning-effect-learning-effect-more-efficient-effect-learning-effect-more-effective-effect-learning-effect-more-effective-effect-learning-effect-more-efficient-effect-learning-effect-more-effective-effect-learning-effect-effect-more-more-efficient-effect-learning-effect-effect-more-more-efficient-effect-learning-effect"}, {"heading": "6 Conclusion", "text": "In this paper, we have developed a theoretical framework for online learning with structured losses, namely the broad class of problems with additive loss dreams. The framework leads both to algorithms generalizing the standard descent of online mirrors, and to new limits of regret for relevant settings such as loud + sparse, loud + low, and sparse + low. Furthermore, we have derived lower limits - i.e. basic limits - for regretting a variety of online learning problems with structured loss dreams. Given these results, narrowing the gap between the upper and lower limit for structured loss dreams is a natural, open problem. Another relevant strand of research is to investigate attitudes in which the learner knows that the loss dream is structured but does not know the exact instantiation of the loss dream, for example, the losses may be disturbances of vectors from a low-dimensional sub-space, but, primarily, the learning algorithm may not know the underlying problem."}, {"heading": "A Proof of Theorem 3", "text": "Theorem 3 (OMD) Reue bound (Theorem 5.2), Bubeck (2011), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR, BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR, BR), BR (BR, BR), BR (BR, BR, BR), BR (BR, BR, BR), BR (BR, BR, BR), BR (BR, BR, BR), BR (BR, BR), BR (BR, BR), BR (BR, BR), BR (BR, BR), BR (BR, BR), BR (BR, BR), BR (BR, BR), BR (BR), BR (BR, BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR), BR (BR (BR), BR (BR), BR (BR), BR (BR), BR (BR (BR), BR (BR), BR (BR (BR), BR (BR), BR (BR (BR), BR (BR), BR (BR (BR), BR (BR), BR (BR (BR), BR (BR), BR (BR (BR), BR (BR), BR (BR (BR), BR (BR), BR (BR (BR, BR), BR (BR), BR (BR), BR (BR), BR (BR (BR, BR), BR (BR), BR (BR), BR (BR), BR (BR, BR), BR (BR (BR), BR (BR), BR (BR, BR), BR (BR), BR (BR, BR), BR (BR), BR (BR, BR"}, {"heading": "B Proofs from Section 3", "text": "1. Sparse loss room: L = {l \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 ln (N + 1) Consider the standard \u00b7 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s"}, {"heading": "C Proofs from Section 4.2", "text": "The proofs given in this section are based on the results in section B, which determine the guarantees of the OMD algorithm for specific structured loss dreams. (note.) Supposed, L1 = = = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = + 1 = 1 = 1 = 1 = 1 = 1 = 1 = + 1 = 1 = 1 = 1 = + 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = + 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2, 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2, 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2, 2 = 2 = 2 = 2 = 2 = 2 = 2, 2 = 2 = 2 = 2 = 2 = 2, 2 = 2 = 2 = 2 = 2 = 2."}, {"heading": "D Proofs from Section 5", "text": "This section provides a simple generalization of a subset of results by Ben-David et al. [2009] for online learning of binary hypotheses classes. [2009] for online learning of binary hypotheses classes. [2009] for online learning of binary hypotheses. [2009] for online learning of binary hypotheses. [2009] for online learning of binary hypotheses. [2009] for online learning of binary hypotheses. [2009] for online learning of binary hypotheses. [2009] for binary hypotheses. [2009] for binary hypotheses. [2009] for binary hypotheses. [2009] for binary hypotheses. [2009] for binary hypotheses. [2009] for binary hypotheses. [2009] for binary hypotheses. [2009] for binary hypotheses. [2009] for binary hypotheses."}, {"heading": "E Tight Examples for Theorem 4", "text": "In this section we present examples in which the regret guarantee of theorem 4 is essentially narrow, that is, we present the loss dreams L1 and L2 in such a way that the OMD algorithm obtained via theorem 4 is a duly optimal regret guarantee for the additive loss range L = L1 + L2. Composition of the lower ranks: LetL1 = {l = 0, 1] N | l = U1v} and L2 = [0, 1] N | l = U2v} are loss dreams of rank d1 and d2, respectively (i.e., the rank of the matrices U1 and U2 are respectively d1 and d2). Here (d1 + d2) \u2264 lnN. Considering the regulator R (x) = x (H1 + H2 = IN + U1, and H2 = R2U2 = high)."}], "references": [{"title": "Agnostic online learning", "author": ["Shai Ben-David", "D\u00e1vid P\u00e1l", "Shai Shalev-Shwartz"], "venue": "In COLT,", "citeRegEx": "Ben.David et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Ben.David et al\\.", "year": 2003}, {"title": "Introduction to online optimization", "author": ["NY York"], "venue": "Lecture Notes, Princeton University,", "citeRegEx": "York,? \\Q2004\\E", "shortCiteRegEx": "York", "year": 2004}, {"title": "Online learning with low rank experts", "author": ["Elad Hazan", "Tomer Koren", "Roi Livni", "Yishay Mansour"], "venue": null, "citeRegEx": "Hazan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2010}, {"title": "Online learning and online convex optimization", "author": ["Shai Shalev-Shwartz"], "venue": "Found. Trends Mach. Learn.,", "citeRegEx": "Shalev.Shwartz.,? \\Q2012\\E", "shortCiteRegEx": "Shalev.Shwartz.", "year": 2012}], "referenceMentions": [{"referenceID": 2, "context": "Hazan et al. [2016] show that the learner can limit her regret to O( \u221a dT ) when each loss vector comes from a d-dimensional subspace of RN .", "startOffset": 0, "endOffset": 20}, {"referenceID": 2, "context": "Specializing this result for a variety of loss function sets recovers standard OMD regret guarantees for strongly convex regularizers [Shalev-Shwartz, 2012b], and subsumes a result of Hazan et al. [2016] for the online low-rank problem.", "startOffset": 184, "endOffset": 204}, {"referenceID": 2, "context": "Specializing this result for a variety of loss function sets recovers standard OMD regret guarantees for strongly convex regularizers [Shalev-Shwartz, 2012b], and subsumes a result of Hazan et al. [2016] for the online low-rank problem. But more importantly, this allows us to obtain \u201cnew results from old\u201d\u2014regret guarantees for settings such as noisy low rank (where losses are perturbations from a low-dimensional subspace), noisy sparse (where losses are perturbations of sparse vectors), and sparse low-rank (where losses are sparse perturbations from a low-dimensional subspace); see Tables 1 and 2. Another contribution of this work is to show lower bounds on regret for the online learning problem with structured losses. We derive a generic lower bound on regret, for any algorithm for the prediction with experts problem, using structured (in terms of sparsity and dimension) loss vectors. This result allows us to derive regret lower bounds in a variety of individual and additive loss space settings including sparse, noisy, low rank, noisy low-rank, and noisy sparse losses. Related work. The work that is perhaps closest in spirit to ours is that of Hazan et al. [2016], who study the best experts problem when the loss vectors all come from a low-dimensional subspace of the ambient space.", "startOffset": 184, "endOffset": 1183}, {"referenceID": 2, "context": "Low-rank loss space: L = {l \u2208 [0, 1]N | l = Uv }, where the rank of matrix U \u2208 RN\u00d7d is equal to d \u2208 [N ] and vector v \u2208 Rd (as mentioned previously, such loss vectors were considered by Hazan et al. [2016]).", "startOffset": 186, "endOffset": 206}, {"referenceID": 3, "context": "In this section, we give a brief introduction to the Online Mirror Descent (OMD) algorithm [Bubeck, 2011; Shalev-Shwartz, 2012a], which is a subgradient descent based method for online convex optimization with a suitably chosen regularizer. A reader well-versed with the analysis of OMD may skip to the statement of Theorem 3 and proceed to Section 3. OMD generalizes the basic mirror descent algorithm used for offline optimization problems (see, e.g., Beck and Teboulle [2003]).", "startOffset": 106, "endOffset": 479}, {"referenceID": 3, "context": ", Shalev-Shwartz [2012a] and Bubeck [2011]) Let \u03a9 \u2208 Rn be a convex set, and f : \u03a9\u2192R be a differentiable function.", "startOffset": 2, "endOffset": 25}, {"referenceID": 3, "context": ", Shalev-Shwartz [2012a] and Bubeck [2011]) Let \u03a9 \u2208 Rn be a convex set, and f : \u03a9\u2192R be a differentiable function.", "startOffset": 2, "endOffset": 43}, {"referenceID": 0, "context": "The proof of this theorem appears in Appendix D and is based on a lower-bound result of Ben-David et al. [2009] for online learning of binary hypotheses classes in terms of its Littlestone\u2019s dimension.", "startOffset": 88, "endOffset": 112}, {"referenceID": 2, "context": "Note that Theorem 13 (with parameter V = d, s = 1) recovers the lower bound for low rank loss spaces as established by Hazan et al. [2016]: given 1 \u2264 d \u2264 lnN and any online learning algorithm, there exists a sequence of d-rank loss vectors l1, l2, .", "startOffset": 119, "endOffset": 139}, {"referenceID": 2, "context": "The result of Hazan et al. [2016] address the noiseless version of this problem.", "startOffset": 14, "endOffset": 34}], "year": 2017, "abstractText": "We consider prediction with expert advice when the loss vectors are assumed to lie in a set described by the sum of atomic norm balls. We derive a regret bound for a general version of the online mirror descent (OMD) algorithm that uses a combination of regularizers, each adapted to the constituent atomic norms. The general result recovers standard OMD regret bounds, and yields regret bounds for new structured settings where the loss vectors are (i) noisy versions of points from a low-rank subspace, (ii) sparse vectors corrupted with noise, and (iii) sparse perturbations of low-rank vectors. For the problem of online learning with structured losses, we also show lower bounds on regret in terms of rank and sparsity of the source set of the loss vectors, which implies lower bounds for the above additive loss settings as well.", "creator": "LaTeX with hyperref package"}}}