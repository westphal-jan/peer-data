{"id": "1706.04825", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2017", "title": "Towards Grounding Conceptual Spaces in Neural Representations", "abstract": "The highly influential framework of conceptual spaces provides a geometric way of representing knowledge. It aims at bridging the gap between symbolic and subsymbolic processing. Instances are represented by points in a high-dimensional space and concepts are represented by convex regions in this space. In this paper, we present our approach towards grounding the dimensions of a conceptual space in latent spaces learned by an InfoGAN from unlabeled data.", "histories": [["v1", "Thu, 15 Jun 2017 11:59:06 GMT  (203kb,D)", "http://arxiv.org/abs/1706.04825v1", "accepted at NeSy 2017"]], "COMMENTS": "accepted at NeSy 2017", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["lucas bechberger", "kai-uwe k\\\"uhnberger"], "accepted": false, "id": "1706.04825"}, "pdf": {"name": "1706.04825.pdf", "metadata": {"source": "CRF", "title": "Towards Grounding Conceptual Spaces in Neural Representations", "authors": ["Lucas Bechberger", "Kai-Uwe K\u00fchnberger"], "emails": ["lucas.bechberger@uni-osnabrueck.de,", "kai-uwe.kuehnberger@uni-osnabrueck.de"], "sections": [{"heading": "1 Introduction", "text": "The cognitive framework of conceptual spaces [13,14] attempts to bridge the gap between symbolic and subsymbolic AI by proposing a conceptual layer based on geometric representations. A conceptual space is a high-dimensional space spanned by a number of high-quality dimensions that represent interpretable characteristics. Convex regions in this space correspond to concepts. [10,12,20] Abstract symbols, by linking with concepts, can be established in a conceptual space whose dimensions are based on subsymbolic representations; the framework of conceptual spaces has been highly influential in cognitive science and cognitive linguistics over the last 15 years. [10,12,20] It has also triggered considerable research in various sub-areas of artificial intelligence that can be learned from robotics and computer vision [4,5,6] via the semantic network and ontology of integration [1,9] to plausible frameworks from these frameworks, [8,19] although the means of presenting these concepts can not be taken into account."}, {"heading": "2 Conceptual Spaces", "text": "A conceptual space [13] is a high-dimensional space spanned by so-called \"quality dimensions.\" Each of these dimensions represents an interpretable way in which two stimuli can be judged to be similar or different. Examples of quality dimensions are temperature, weight, time, pitch and hue. A domain is a series of dimensions that inherently belong together. Different modes of perception (such as color, shape or taste) are represented by different domains; the color domain, for example, consists of the three dimensions of hue, saturation and brightness; the distance within a domain is measured by euclidean metric; the entire conceptual space is defined as a product space of all dimensions; the distance within the entire conceptual space is measured by the Manhattan metric of intradomain-wide distances; the similarity of two points in a conceptual space is inversely linked to their distance - the two dimensions closer to each other are, for example, \"in red space,\" is referred to as \"during the dog.\""}, {"heading": "3 Representation Learning with InfoGAN", "text": "In the last few years, it has been shown that the number of people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to"}, {"heading": "4 Using Representation Learning to Ground Domains", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "5 An Illustrative Example", "text": "Figure 2 illustrates a simplified example of our presented overall system. Here, we look at only two areas: Color can be represented by the HSB space with the three dimensions hue, saturation and brightness. This is an example of a hard coded domain. However, the representation of the form domain must be learned. The concept of an apple can be described by the \"red\" region in the color domain and the \"round\" region in the shape domain. The concept of a banana can be represented by a set of shapes. Let's consider two example concepts: The concept of an apple can be described by the labeling of a region in the color domain, and the concept of a banana by the representation."}, {"heading": "6 Conclusion and Future Work", "text": "In this paper, we outline how neural representations can be used to ground the areas of a conceptual space in perception, which is particularly useful in areas such as form, where it is difficult to create a dimensional representation. We argued that the latent representations learned through an InfoGAN have suitable properties to be combined with the conceptual space framework. In future work, we will implement the proposed idea by giving the area of simple 2D forms a neural foundation. In addition, we will develop a cluster algorithm to discover and update conceptual representations in a conceptual space.7"}], "references": [{"title": "Conceptual Space Markup Language (CSML): Towards the Cognitive Semantic Web", "author": ["Benjamin Adams", "Martin Raubal"], "venue": "IEEE International Conference on Semantic Computing,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Representation Learning: A Review and New Perspectives", "author": ["Y. Bengio", "A. Courville", "P. Vincent"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "ShapeNet: An Information-Rich 3D Model Repository", "author": ["Angel X. Chang", "Thomas Funkhouser", "Leonidas Guibas", "Pat Hanrahan", "Qixing Huang", "Zimo Li", "Silvio Savarese", "Manolis Savva", "Shuran Song", "Hao Su", "Jianxiong Xiao", "Li Yi", "Fisher Yu"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Anchoring by Imitation Learning in Conceptual Spaces", "author": ["Antonio Chella", "Haris Dindo", "Ignazio Infantino"], "venue": "AI*IA 2005: Advances in Artificial Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Conceptual Spaces for Computer Vision Representations", "author": ["Antonio Chella", "Marcello Frixione", "Salvatore Gaglio"], "venue": "Artificial Intelligence Review,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Anchoring Symbols to Conceptual Spaces: The Case of Dynamic Scenarios", "author": ["Antonio Chella", "Marcello Frixione", "Salvatore Gaglio"], "venue": "Robotics and Autonomous Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets", "author": ["Xi Chen", "Yan Duan", "Rein Houthooft", "John Schulman", "Ilya Sutskever", "Pieter Abbeel"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Inducing Semantic Relations from Conceptual Spaces: A Data-Driven Approach to Plausible Reasoning", "author": ["Joaqun Derrac", "Steven Schockaert"], "venue": "Artificial Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Exploiting Conceptual Spaces for Ontology Integration. In Data Integration Through Semantic Technology (DIST2008) Workshop at 3rd Asian Semantic Web Conference (ASWC", "author": ["Stefan Dietze", "John Domingue"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Vagueness: A Conceptual Spaces Approach", "author": ["Igor Douven", "Lieven Decock", "Richard Dietz", "Paul \u00c9gr\u00e9"], "venue": "Journal of Philosophical Logic,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Generative Multi-Adversarial Networks", "author": ["Ishan Durugkar", "Ian Gemp", "Sridhar Mahadevan"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Representing Part-Whole Relations in Conceptual Spaces", "author": ["Sandro R. Fiorini", "Peter G\u00e4rdenfors", "Mara Abel"], "venue": "Cognitive Processing,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Conceptual Spaces: The Geometry of Thought", "author": ["Peter G\u00e4rdenfors"], "venue": "MIT press,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2000}, {"title": "The Geometry of Meaning: Semantics Based on Conceptual Spaces", "author": ["Peter G\u00e4rdenfors"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Deep Learning", "author": ["Ian Goodfellow", "Yoshua Bengio", "Aaron Courville"], "venue": "http://www.deeplearningbook.org", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Generative Adversarial Networks", "author": ["Ian J. Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David WardeFarley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "The Symbol Grounding Problem", "author": ["Stevan Harnad"], "venue": "Physica D: Nonlinear Phenomena,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1990}, {"title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks", "author": ["Alec Radford", "Luke Metz", "Soumith Chintala"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Interpolation and Extrapolation in Conceptual Spaces: A Case Study in the Music Domain", "author": ["Steven Schockaert", "Henri Prade"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Event Structure, Conceptual Spaces and the Semantics of Verbs", "author": ["Massimo Warglien", "Peter G\u00e4rdenfors", "Matthijs Westera"], "venue": "Theoretical Linguistics,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Learning a Probabilistic Latent Space of Object Shapes via 3D GenerativeAdversarial Modeling", "author": ["Jiajun Wu", "Chengkai Zhang", "Tianfan Xue", "Bill Freeman", "Josh Tenenbaum"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Energy-based Generative Adversarial Network", "author": ["Junbo Zhao", "Michael Mathieu", "Yann LeCun"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "Unpaired Imageto-Image Translation using Cycle-Consistent Adversarial Networks", "author": ["Jun-Yan Zhu", "Taesung Park", "Phillip Isola", "Alexei A. Efros"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2017}], "referenceMentions": [{"referenceID": 12, "context": "The cognitive framework of conceptual spaces [13,14] attempts to bridge the gap between symbolic and subsymbolic AI by proposing an intermediate conceptual layer based on geometric representations.", "startOffset": 45, "endOffset": 52}, {"referenceID": 13, "context": "The cognitive framework of conceptual spaces [13,14] attempts to bridge the gap between symbolic and subsymbolic AI by proposing an intermediate conceptual layer based on geometric representations.", "startOffset": 45, "endOffset": 52}, {"referenceID": 9, "context": "The framework of conceptual spaces has been highly influential in the last 15 years within cognitive science and cognitive linguistics [10,12,20].", "startOffset": 135, "endOffset": 145}, {"referenceID": 11, "context": "The framework of conceptual spaces has been highly influential in the last 15 years within cognitive science and cognitive linguistics [10,12,20].", "startOffset": 135, "endOffset": 145}, {"referenceID": 19, "context": "The framework of conceptual spaces has been highly influential in the last 15 years within cognitive science and cognitive linguistics [10,12,20].", "startOffset": 135, "endOffset": 145}, {"referenceID": 3, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 133, "endOffset": 140}, {"referenceID": 4, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 133, "endOffset": 140}, {"referenceID": 5, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 133, "endOffset": 140}, {"referenceID": 0, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 188, "endOffset": 193}, {"referenceID": 8, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 188, "endOffset": 193}, {"referenceID": 7, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 217, "endOffset": 223}, {"referenceID": 18, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 217, "endOffset": 223}, {"referenceID": 6, "context": "We propose that latent spaces learned by an InfoGAN [7] (a special class of Generative Adversarial Networks [16]) can serve as domains in the conceptual spaces framework.", "startOffset": 52, "endOffset": 55}, {"referenceID": 15, "context": "We propose that latent spaces learned by an InfoGAN [7] (a special class of Generative Adversarial Networks [16]) can serve as domains in the conceptual spaces framework.", "startOffset": 108, "endOffset": 112}, {"referenceID": 12, "context": "A conceptual space [13] is a high-dimensional space spanned by so-called \u201cquality dimensions\u201d.", "startOffset": 19, "endOffset": 23}, {"referenceID": 16, "context": "If the dimensions of a conceptual space are based on perception and if regions in this space are linked to abstract symbols, this framework can be used for symbol grounding [17].", "startOffset": 173, "endOffset": 177}, {"referenceID": 1, "context": "[2] provide a thorough overview of different approaches in the representation learning area.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "We will focus our discussion here on one specific approach that is particularly fitting to our proposal, namely InfoGAN [7].", "startOffset": 120, "endOffset": 123}, {"referenceID": 15, "context": "InfoGAN is an extension of the GAN (Generative Adversarial Networks) framework [16] which has been applied to a variety of problems (e.", "startOffset": 79, "endOffset": 83}, {"referenceID": 10, "context": ", [11,18,21,22,23]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 17, "context": ", [11,18,21,22,23]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 20, "context": ", [11,18,21,22,23]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 21, "context": ", [11,18,21,22,23]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 22, "context": ", [11,18,21,22,23]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 6, "context": "[7] have extended the original framework by introducing latent variables: In the InfoGAN framework (shown in the right part of Figure 1), the generator receives an additional input vector.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] found that the individual latent variables have an interpretable meaning.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] and [15, Ch.", "startOffset": 0, "endOffset": 3}, {"referenceID": 17, "context": "[18] found that linear interpolations between points in the latent space of a GAN correspond to a meaningful \u201cmorph\u201d between generated images in the input space.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "For a more thorough experiment, one could for instance use ShapeNet [3], a data base of over 50,000 3D models for more than 50 categories of objects.", "startOffset": 68, "endOffset": 71}], "year": 2017, "abstractText": "The highly influential framework of conceptual spaces provides a geometric way of representing knowledge. It aims at bridging the gap between symbolic and subsymbolic processing. Instances are represented by points in a high-dimensional space and concepts are represented by convex regions in this space. In this paper, we present our approach towards grounding the dimensions of a conceptual space in latent spaces learned by an InfoGAN from unlabeled data.", "creator": "LaTeX with hyperref package"}}}