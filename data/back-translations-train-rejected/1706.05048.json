{"id": "1706.05048", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2017", "title": "A new look at clustering through the lens of deep convolutional neural networks", "abstract": "Classification and clustering have been studied separately in machine learning and computer vision. Inspired by the recent success of deep learning models in solving various vision problems (e.g., object recognition, semantic segmentation) and the fact that humans serve as the gold standard in assessing clustering algorithms, here, we advocate for a unified treatment of the two problems and suggest that hierarchical frameworks that progressively build complex patterns on top of the simpler ones (e.g., convolutional neural networks) offer a promising solution. We do not dwell much on the learning mechanisms in these frameworks as they are still a matter of debate, with respect to biological constraints. Instead, we emphasize on the compositionality of the real world structures and objects. In particular, we show that CNNs, trained end to end using back propagation with noisy labels, are able to cluster data points belonging to several overlapping shapes, and do so much better than the state of the art algorithms. The main takeaway lesson from our study is that mechanisms of human vision, particularly the hierarchal organization of the visual ventral stream should be taken into account in clustering algorithms (e.g., for learning representations in an unsupervised manner or with minimum supervision) to reach human level clustering performance. This, by no means, suggests that other methods do not hold merits. For example, methods relying on pairwise affinities (e.g., spectral clustering) have been very successful in many cases but still fail in some cases (e.g., overlapping clusters).", "histories": [["v1", "Thu, 15 Jun 2017 19:10:50 GMT  (2081kb,D)", "http://arxiv.org/abs/1706.05048v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["ali borji", "aysegul dundar"], "accepted": false, "id": "1706.05048"}, "pdf": {"name": "1706.05048.pdf", "metadata": {"source": "CRF", "title": "A new look at clustering through the lens of deep convolutional neural networks", "authors": ["Ali Borji", "Aysegul Dundar"], "emails": ["aborji@crcv.ucf.edu", "adundar@purdue.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we are able, that we are able, that we are able, that we are able."}, {"heading": "2 Related Work", "text": "This is a typical example of partitional methods used in practice to minimize the sum of squared errors between data points and their nearest cluster centers. Some commonly used algorithms include spectral clustering [13, 44], expectation maximization (EM) [18], meanshift [15], and non-negative factorization (NMF). Density-based algorithms, a class of partitional methods, classify regions that are heavily populated with data. Some examples include DBSCAN [21], TICS [2], and networks [FS49]."}, {"heading": "3 Model Description", "text": "We are motivated by three observations: First, CNNs have been very successful in a variety of visual problems such as semantic segmentation, edge recognition, and recognition; second, CNNs learn representations through multiple stages of nonlinear processing, similar to how the cortex adapts to represent the visual world [62]; and, similarly to other biological models of the visual cortex (e.g. HMAX [53]), these models capture aspects of the organization of the visual ventral stream; third, cluster methods are often evaluated on the basis of human perception that motivates biologically inspired solutions.Our strategy has parallels to recent work on the use of CNNs for semantic segmentation, but a key difference is that cluster identities (class labels) do not matter here. For example, if there is a triangle and a circle in the image, shape labels may be anything, as long as clusters are correctly separated. Unlike previous work, we use nettings to measure the depth of a cluster by means of distance."}, {"heading": "3.1 The network architecture", "text": "Figure 1 shows the proposed deep network architecture based on the U-Net [50], an encoder decoder with skip connections. Input is a binary image with a single channel, also represented in Figure 2. Input is transmitted to five stacks [folding, winding, pooling] modules, followed by five stacks of decoder modules [folding, folding, upsampling]. Skip connections from mirrored layers in the encoder are transmitted to decoder stacks. Such skip connections recover the spatial image information that may have been lost through successive folding and pooling operations in the encoder. Finally, three 1 \u00d7 1 filters are applied to collapse the folding cards into three channels, which can group three objects (one channel per cluster). Each folding layer in the decoder module has 16 filters and is followed by a ReLU layer, with the exception of the last point of the activation module, which is used to generate the signature module."}, {"heading": "3.2 Training procedure and ground truth", "text": "To implement our model, we use the Keras [12] platform. We use 128 x 128 binary images as input (see Figure 2). The corresponding ground truth map for each input is generated as follows: The dots belonging to the uppermost cluster are labeled 0, in the image descending, dots belonging to the next cluster are labeled 1, etc. This process repeats until all clusters are labeled. Thus, the labels are independent of the object shapes. This distinguishes our training program from classification and segmentation methods, in which each object is always assigned the exact same label. Note that our main concern here is to separate the objects from each other rather than classify them correctly. Nevertheless, as we will show later, the network is able to successfully cluster objects of the same shape. We use the mean square error loss and train the network with the Adam Optimizer [31]. Batch size is set to 16 learning rate and 0.001."}, {"heading": "4 Experimental Evaluation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Synthetic data", "text": "Here we explain the process of generating the synthetic images to train our model.Geometric shape stimuli are parameterized using several variables, including S = {circle, ring, square, square, bar}, O = {1,.., m}, D = [200 300], and SC = [10 30]. They indicate in the order the set of possible shapes, the set of possible number of objects to place in the image, the interval of point densities for an object, and the interval of possible object scales. To create an image, a number k \u00b2 O, which indicates the number of objects, is drawn randomly, and the following is repeated k times. Random density and scales are selected for clusters; the cluster is randomly rotated, specifying the order of possible object scales."}, {"heading": "4.2 Evaluation metric", "text": "Since our purpose is to cluster, not classify, a prediction score is not useful to evaluate performance. Instead, we define an intuitive, simple evaluation score as follows: n points in the image form a binary matrix of size n2, in which each element indicates whether two points belong to the same cluster or not. A similar matrix is created for predicting each model. Note that the order of the points is maintained when these matrices are built, and then the hamming distance between the basic truth matrix and the prediction matrix is calculated, which determines the fraction of the cases in which they do not match (i.e. the error rate)."}, {"heading": "4.3 Benchmark algorithms", "text": "We have used the following cluster methods as benchmark algorithms: k-Means (KM) [40], minimizes the sum of square errors between the data points and their nearest cluster centers. It is a simple and widely used method. Fuzzy C-Means (FCM) has soft labels that belong to more than one cluster with different membership degrees. Spectral Clustering. We deal with two spectral cluster algorithms. These algorithms lead to a spectral analysis of the matrix of point-to-point similarities rather than finding an explicit model of memberships."}, {"heading": "4.4 Experiments", "text": "The first five experiments aim to assess the performance of the proposed method in terms of benchmark algorithms; the last three experiments test the robustness of the proposed method; in our first experiment, we produce images with 2 objects randomly selected from 5 shapes; form parameters are drawn randomly from all possible decisions; we use the network that was trained in our first experiment, which focuses on the ability of cluster heterogeneity to produce results; in the second experiment, we create 200 test images with 2 objects of the same form type (one of the five shapes); we use the network that was trained in our first experiment, which focuses on the ability of cluster shapes that are very similar to each other; this case is important because CNNs are known to be very good at generalizing; and in the third experiment, we produce images with 3 objects that are randomly selected."}, {"heading": "4.5 Results and discussion", "text": "The results of the first five experiments show that CNN all models in all experiments with a large margin of 0.704 0.721 0.721 0.714 0.714 (i.e., about 7% improvement over the second best in Experiment 1). This large margin indicates that even the best optimization of the compared algorithms is not able to compete with the proposed CNN models. All other models lead over the same thing. Table 1: Quantitative comparison of the different clustering algorithms. The best example is in each experiment shows the mean and the second series shows the standard deviation. Model CNN kM NJW MS MS CFSExp 1 0.916 0.850 0.816 0.816 0.816 0.805 0.748 0.131 0.173 0.165 Exp in each experiment."}, {"heading": "5 Conclusion", "text": "We argue that deep neural networks, especially CNNs, hold great promise for data clusters, and our results show that CNNs can handle complex and locked clusters much better than other algorithms, meaning that a learning mechanism that is unattended or with minimal supervision seems inevitable to capture complex cluster shapes. While our formulation is not always consistent, our work is different from semantic segmentation and instance segmentation. We have used mean square loss to train the network, and it may be possible to define other loss functions to make the network more efficient and even work with weaker labels."}], "references": [{"title": "Data clustering: algorithms and applications", "author": ["Charu C Aggarwal", "Chandan K Reddy"], "venue": "Chapman and Hall/CRC,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Optics: ordering points to identify the clustering structure", "author": ["Mihael Ankerst", "Markus M Breunig", "Hans-Peter Kriegel", "J\u00f6rg Sander"], "venue": "In ACM Sigmod record,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "Learning spectral clustering", "author": ["Francis R Bach", "Michael I Jordan"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Pattern recognition with fuzzy objective function algorithms", "author": ["James C Bezdek"], "venue": "Springer Science & Business Media,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Learning to segment", "author": ["Eran Borenstein", "Shimon Ullman"], "venue": "Vision-ECCV", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "State-of-the-art in visual attention modeling", "author": ["Ali Borji", "Laurent Itti"], "venue": "IEEE transactions on pattern analysis and machine intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Human vs. computer in scene and object recognition", "author": ["Ali Borji", "Laurent Itti"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Quantitative analysis of human-model agreement in visual saliency modeling: A comparative study", "author": ["Ali Borji", "Dicky N Sihite", "Laurent Itti"], "venue": "IEEE Transactions on Image Processing,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Artmap: Supervised real-time learning and classification of nonstationary data by a self-organizing neural network", "author": ["Gail A Carpenter", "Stephen Grossberg", "John H Reynolds"], "venue": "Neural networks,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1991}, {"title": "Deep learning with nonparametric clustering", "author": ["Gang Chen"], "venue": "arXiv preprint arXiv:1501.03084,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Semantic image segmentation with deep convolutional nets and fully connected crfs", "author": ["Liang-Chieh Chen", "George Papandreou", "Iasonas Kokkinos", "Kevin Murphy", "Alan L Yuille"], "venue": "In ICLR,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Spectral graph theory, volume 92", "author": ["Fan RK Chung"], "venue": "American Mathematical Soc.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1997}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Mean shift: A robust approach toward feature space analysis", "author": ["Dorin Comaniciu", "Peter Meer"], "venue": "IEEE Transactions on pattern analysis and machine intelligence,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2002}, {"title": "Neural networks and neuroscience-inspired computer vision", "author": ["David Daniel Cox", "Thomas Dean"], "venue": "Current Biology,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition", "author": ["George E Dahl", "Dong Yu", "Li Deng", "Alex Acero"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Maximum likelihood from incomplete data via the em algorithm. Journal of the royal statistical society", "author": ["Arthur P Dempster", "Nan M Laird", "Donald B Rubin"], "venue": "Series B (methodological),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1977}, {"title": "Untangling invariant object recognition", "author": ["James J DiCarlo", "David D Cox"], "venue": "Trends in cognitive sciences,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "A fuzzy relative of the isodata process and its use in detecting compact well-separated", "author": ["Joseph C Dunn"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1973}, {"title": "A density-based algorithm for discovering clusters in large spatial databases with noise", "author": ["Martin Ester", "Hans-Peter Kriegel", "J\u00f6rg Sander", "Xiaowei Xu"], "venue": "In Kdd,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1996}, {"title": "The pascal visual object classes (voc) challenge", "author": ["Mark Everingham", "Luc Van Gool", "Christopher KI Williams", "John Winn", "Andrew Zisserman"], "venue": "International journal of computer vision,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "Neocognitron: A self-organizing neural network model for a mechanism of visual pattern recognition", "author": ["Kunihiko Fukushima", "Sei Miyake"], "venue": "In Competition and cooperation in neural nets,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1982}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Towards end-to-end speech recognition with recurrent neural networks", "author": ["Alex Graves", "Navdeep Jaitly"], "venue": "In ICML,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Deep residual learning for image recognition", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2016}, {"title": "Deep clustering: Discriminative embeddings for segmentation and separation", "author": ["John R Hershey", "Zhuo Chen", "Jonathan Le Roux", "Shinji Watanabe"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "Neural network-based clustering using pairwise constraints", "author": ["Yen-Chang Hsu", "Zsolt Kira"], "venue": "arXiv preprint arXiv:1511.06321,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}, {"title": "Natural Image Statistics: A Probabilistic Approach to Early Computational Vision., volume 39", "author": ["Aapo Hyv\u00e4rinen", "Jarmo Hurri", "Patrick O Hoyer"], "venue": "Springer Science & Business Media,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2009}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": "In NIPS,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann LeCun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1998}, {"title": "Algorithms for non-negative matrix factorization", "author": ["Daniel D Lee", "H Sebastian Seung"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2001}, {"title": "End-to-end training of deep visuomotor policies", "author": ["Sergey Levine", "Chelsea Finn", "Trevor Darrell", "Pieter Abbeel"], "venue": "arXiv preprint arXiv:1504.00702,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2015}, {"title": "Microsoft coco: Common objects in context", "author": ["Tsung-Yi Lin", "Michael Maire", "Serge Belongie", "James Hays", "Pietro Perona", "Deva Ramanan", "Piotr Doll\u00e1r", "C Lawrence Zitnick"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2014}, {"title": "Least squares quantization in pcm", "author": ["Stuart Lloyd"], "venue": "IEEE transactions on information theory,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1982}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["Jonathan Long", "Evan Shelhamer", "Trevor Darrell"], "venue": "In CVPR,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2015}, {"title": "Unsupervised learning of visual features through spike timing dependent plasticity", "author": ["Timoth\u00e9e Masquelier", "Simon J Thorpe"], "venue": "PLoS Comput Biol,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2007}, {"title": "Human-level control through deep reinforcement learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Andrei A Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves", "Martin Riedmiller", "Andreas K Fidjeland", "Georg Ostrovski"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2015}, {"title": "On spectral clustering: Analysis and an algorithm", "author": ["Andrew Y Ng", "Michael I Jordan", "Yair Weiss"], "venue": "In NIPS,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2001}, {"title": "On spectral clustering: Analysis and an algorithm", "author": ["Andrew Y Ng", "Michael I Jordan", "Yair Weiss"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2002}, {"title": "Learning to segment object candidates", "author": ["Pedro O Pinheiro", "Ronan Collobert", "Piotr Dollar"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2015}, {"title": "Learning to refine object segments", "author": ["Pedro O Pinheiro", "Tsung-Yi Lin", "Ronan Collobert", "Piotr Doll\u00e1r"], "venue": "In ECCV,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2016}, {"title": "Figure/ground assignment in natural images", "author": ["Xiaofeng Ren", "Charless C Fowlkes", "Jitendra Malik"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2006}, {"title": "Clustering by fast search and find of density", "author": ["Alex Rodriguez", "Alessandro Laio"], "venue": "peaks. Science,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2014}, {"title": "U-net: Convolutional networks for biomedical image segmentation", "author": ["Olaf Ronneberger", "Philipp Fischer", "Thomas Brox"], "venue": "In International Conference on Medical Image Computing and Computer-Assisted Intervention,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2015}, {"title": "Density-based clustering in spatial databases: The algorithm gdbscan and its applications", "author": ["J\u00f6rg Sander", "Martin Ester", "Hans-Peter Kriegel", "Xiaowei Xu"], "venue": "Data mining and knowledge discovery,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 1998}, {"title": "A feedforward architecture accounts for rapid categorization", "author": ["Thomas Serre", "Aude Oliva", "Tomaso Poggio"], "venue": "Proceedings of the national academy of sciences,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2007}, {"title": "Robust object recognition with cortex-like mechanisms", "author": ["Thomas Serre", "Lior Wolf", "Stanley Bileschi", "Maximilian Riesenhuber", "Tomaso Poggio"], "venue": "IEEE transactions on pattern analysis and machine intelligence,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2007}, {"title": "Normalized cuts and image segmentation", "author": ["Jianbo Shi", "Jitendra Malik"], "venue": "IEEE Transactions on pattern analysis and machine intelligence,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2000}, {"title": "Mastering the game of go with deep neural networks and tree", "author": ["David Silver", "Aja Huang", "Chris J Maddison", "Arthur Guez", "Laurent Sifre", "George Van Den Driessche", "Julian Schrittwieser", "Ioannis Antonoglou", "Veda Panneershelvam", "Marc Lanctot"], "venue": "search. Nature,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2016}, {"title": "Auto-encoder based data clustering", "author": ["Chunfeng Song", "Feng Liu", "Yongzhen Huang", "Liang Wang", "Tieniu Tan"], "venue": "In Iberoamerican Congress on Pattern Recognition,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2013}, {"title": "Bottom-up deep learning using the hebbian principle, 2016", "author": ["Aseem Wadhwa", "Upamanyu Madhow"], "venue": null, "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2016}, {"title": "Doc: Deep occlusion recovering from a single image", "author": ["Peng Wang", "Alan Yuille"], "venue": "arXiv preprint arXiv:1511.06457,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2015}, {"title": "Learning a task-specific deep architecture for clustering", "author": ["Zhangyang Wang", "Shiyu Chang", "Jiayu Zhou", "Meng Wang", "Thomas S Huang"], "venue": "In Proceedings of the 2016 SIAM International Conference on Data Mining,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2016}, {"title": "Unsupervised deep embedding for clustering analysis", "author": ["Junyuan Xie", "Ross Girshick", "Ali Farhadi"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2016}, {"title": "Performance-optimized hierarchical models predict neural responses in higher visual cortex", "author": ["Daniel LK Yamins", "Ha Hong", "Charles F Cadieu", "Ethan A Solomon", "Darren Seibert", "James J DiCarlo"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2014}, {"title": "Border ownership from intracortical interactions in visual area", "author": ["Li Zhaoping"], "venue": "v2. Neuron,", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2005}, {"title": "Conditional random fields as recurrent neural networks", "author": ["Shuai Zheng", "Sadeep Jayasumana", "Bernardino Romera-Paredes", "Vibhav Vineet", "Zhizhong Su", "Dalong Du", "Chang Huang", "Philip HS Torr"], "venue": "In ICCV,", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2015}, {"title": "Coding of border ownership in monkey visual cortex", "author": ["Hong Zhou", "Howard S Friedman", "R\u00fcdiger Von Der Heydt"], "venue": "Journal of Neuroscience,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2000}], "referenceMentions": [{"referenceID": 0, "context": "Despite the introduction of thousands of clustering algorithms in the past [1], some challenges still remain.", "startOffset": 75, "endOffset": 78}, {"referenceID": 29, "context": "They have been proven successful in several domains including computer vision [34], natural language \u2217Equal contribution ar X iv :1 70 6.", "startOffset": 78, "endOffset": 82}, {"referenceID": 12, "context": "processing [14], and speech recognition [17] for tasks such as scene and object classification [34, 26], pixel-level labeling for image segmentation [41, 64], modeling attention [6, 8], image generation [24], robot arm control [38], speech recognition [25], playing Atari games [43] and beating the Go champion [55].", "startOffset": 11, "endOffset": 15}, {"referenceID": 15, "context": "processing [14], and speech recognition [17] for tasks such as scene and object classification [34, 26], pixel-level labeling for image segmentation [41, 64], modeling attention [6, 8], image generation [24], robot arm control [38], speech recognition [25], playing Atari games [43] and beating the Go champion [55].", "startOffset": 40, "endOffset": 44}, {"referenceID": 29, "context": "processing [14], and speech recognition [17] for tasks such as scene and object classification [34, 26], pixel-level labeling for image segmentation [41, 64], modeling attention [6, 8], image generation [24], robot arm control [38], speech recognition [25], playing Atari games [43] and beating the Go champion [55].", "startOffset": 95, "endOffset": 103}, {"referenceID": 24, "context": "processing [14], and speech recognition [17] for tasks such as scene and object classification [34, 26], pixel-level labeling for image segmentation [41, 64], modeling attention [6, 8], image generation [24], robot arm control [38], speech recognition [25], playing Atari games [43] and beating the Go champion [55].", "startOffset": 95, "endOffset": 103}, {"referenceID": 35, "context": "processing [14], and speech recognition [17] for tasks such as scene and object classification [34, 26], pixel-level labeling for image segmentation [41, 64], modeling attention [6, 8], image generation [24], robot arm control [38], speech recognition [25], playing Atari games [43] and beating the Go champion [55].", "startOffset": 149, "endOffset": 157}, {"referenceID": 57, "context": "processing [14], and speech recognition [17] for tasks such as scene and object classification [34, 26], pixel-level labeling for image segmentation [41, 64], modeling attention [6, 8], image generation [24], robot arm control [38], speech recognition [25], playing Atari games [43] and beating the Go champion [55].", "startOffset": 149, "endOffset": 157}, {"referenceID": 5, "context": "processing [14], and speech recognition [17] for tasks such as scene and object classification [34, 26], pixel-level labeling for image segmentation [41, 64], modeling attention [6, 8], image generation [24], robot arm control [38], speech recognition [25], playing Atari games [43] and beating the Go champion [55].", "startOffset": 178, "endOffset": 184}, {"referenceID": 7, "context": "processing [14], and speech recognition [17] for tasks such as scene and object classification [34, 26], pixel-level labeling for image segmentation [41, 64], modeling attention [6, 8], image generation [24], robot arm control [38], speech recognition [25], playing Atari games [43] and beating the Go champion [55].", "startOffset": 178, "endOffset": 184}, {"referenceID": 22, "context": "processing [14], and speech recognition [17] for tasks such as scene and object classification [34, 26], pixel-level labeling for image segmentation [41, 64], modeling attention [6, 8], image generation [24], robot arm control [38], speech recognition [25], playing Atari games [43] and beating the Go champion [55].", "startOffset": 203, "endOffset": 207}, {"referenceID": 32, "context": "processing [14], and speech recognition [17] for tasks such as scene and object classification [34, 26], pixel-level labeling for image segmentation [41, 64], modeling attention [6, 8], image generation [24], robot arm control [38], speech recognition [25], playing Atari games [43] and beating the Go champion [55].", "startOffset": 227, "endOffset": 231}, {"referenceID": 23, "context": "processing [14], and speech recognition [17] for tasks such as scene and object classification [34, 26], pixel-level labeling for image segmentation [41, 64], modeling attention [6, 8], image generation [24], robot arm control [38], speech recognition [25], playing Atari games [43] and beating the Go champion [55].", "startOffset": 252, "endOffset": 256}, {"referenceID": 37, "context": "processing [14], and speech recognition [17] for tasks such as scene and object classification [34, 26], pixel-level labeling for image segmentation [41, 64], modeling attention [6, 8], image generation [24], robot arm control [38], speech recognition [25], playing Atari games [43] and beating the Go champion [55].", "startOffset": 278, "endOffset": 282}, {"referenceID": 49, "context": "processing [14], and speech recognition [17] for tasks such as scene and object classification [34, 26], pixel-level labeling for image segmentation [41, 64], modeling attention [6, 8], image generation [24], robot arm control [38], speech recognition [25], playing Atari games [43] and beating the Go champion [55].", "startOffset": 311, "endOffset": 315}, {"referenceID": 21, "context": "Deep Convolutional Neural Networks (CNNs) [23, 35] have been particularly successful over vision problems.", "startOffset": 42, "endOffset": 50}, {"referenceID": 30, "context": "Deep Convolutional Neural Networks (CNNs) [23, 35] have been particularly successful over vision problems.", "startOffset": 42, "endOffset": 50}, {"referenceID": 27, "context": "One reason is that nearby pixels in natural scenes are highly correlated [30].", "startOffset": 73, "endOffset": 77}, {"referenceID": 2, "context": ", [3, 5, 47]), for example for tuning parameters (e.", "startOffset": 2, "endOffset": 12}, {"referenceID": 4, "context": ", [3, 5, 47]), for example for tuning parameters (e.", "startOffset": 2, "endOffset": 12}, {"referenceID": 41, "context": ", [3, 5, 47]), for example for tuning parameters (e.", "startOffset": 2, "endOffset": 12}, {"referenceID": 2, "context": ", [3]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 26, "context": ", [29, 27, 60]).", "startOffset": 2, "endOffset": 14}, {"referenceID": 25, "context": ", [29, 27, 60]).", "startOffset": 2, "endOffset": 14}, {"referenceID": 53, "context": ", [29, 27, 60]).", "startOffset": 2, "endOffset": 14}, {"referenceID": 44, "context": "Our method builds on the fully convolutional network literature, in particular, recent work on edge detection and semantic segmentation which utilize multi-scale local and non-local cues [50].", "startOffset": 187, "endOffset": 191}, {"referenceID": 46, "context": "We are also strongly inspired by the works showing the high resemblance between human vision mechanisms and CNNs from behavioral, electrophysiological, and computational aspects [52, 62, 53, 19, 35, 34, 26, 7].", "startOffset": 178, "endOffset": 209}, {"referenceID": 55, "context": "We are also strongly inspired by the works showing the high resemblance between human vision mechanisms and CNNs from behavioral, electrophysiological, and computational aspects [52, 62, 53, 19, 35, 34, 26, 7].", "startOffset": 178, "endOffset": 209}, {"referenceID": 47, "context": "We are also strongly inspired by the works showing the high resemblance between human vision mechanisms and CNNs from behavioral, electrophysiological, and computational aspects [52, 62, 53, 19, 35, 34, 26, 7].", "startOffset": 178, "endOffset": 209}, {"referenceID": 17, "context": "We are also strongly inspired by the works showing the high resemblance between human vision mechanisms and CNNs from behavioral, electrophysiological, and computational aspects [52, 62, 53, 19, 35, 34, 26, 7].", "startOffset": 178, "endOffset": 209}, {"referenceID": 30, "context": "We are also strongly inspired by the works showing the high resemblance between human vision mechanisms and CNNs from behavioral, electrophysiological, and computational aspects [52, 62, 53, 19, 35, 34, 26, 7].", "startOffset": 178, "endOffset": 209}, {"referenceID": 29, "context": "We are also strongly inspired by the works showing the high resemblance between human vision mechanisms and CNNs from behavioral, electrophysiological, and computational aspects [52, 62, 53, 19, 35, 34, 26, 7].", "startOffset": 178, "endOffset": 209}, {"referenceID": 24, "context": "We are also strongly inspired by the works showing the high resemblance between human vision mechanisms and CNNs from behavioral, electrophysiological, and computational aspects [52, 62, 53, 19, 35, 34, 26, 7].", "startOffset": 178, "endOffset": 209}, {"referenceID": 6, "context": "We are also strongly inspired by the works showing the high resemblance between human vision mechanisms and CNNs from behavioral, electrophysiological, and computational aspects [52, 62, 53, 19, 35, 34, 26, 7].", "startOffset": 178, "endOffset": 209}, {"referenceID": 0, "context": "Clustering approaches can be broadly classified into hierarchical and partitional types [1].", "startOffset": 88, "endOffset": 91}, {"referenceID": 34, "context": "A classic example of partitional methods is the k-means [40] algorithm which minimizes the sum of squared errors between data points and their nearest cluster centers.", "startOffset": 56, "endOffset": 60}, {"referenceID": 11, "context": "Some frequently used algorithms include spectral clustering [13, 44], expectation maximization (EM) [18], Meanshift [15], and non-negative matrix factorization (NMF) [37].", "startOffset": 60, "endOffset": 68}, {"referenceID": 38, "context": "Some frequently used algorithms include spectral clustering [13, 44], expectation maximization (EM) [18], Meanshift [15], and non-negative matrix factorization (NMF) [37].", "startOffset": 60, "endOffset": 68}, {"referenceID": 16, "context": "Some frequently used algorithms include spectral clustering [13, 44], expectation maximization (EM) [18], Meanshift [15], and non-negative matrix factorization (NMF) [37].", "startOffset": 100, "endOffset": 104}, {"referenceID": 13, "context": "Some frequently used algorithms include spectral clustering [13, 44], expectation maximization (EM) [18], Meanshift [15], and non-negative matrix factorization (NMF) [37].", "startOffset": 116, "endOffset": 120}, {"referenceID": 31, "context": "Some frequently used algorithms include spectral clustering [13, 44], expectation maximization (EM) [18], Meanshift [15], and non-negative matrix factorization (NMF) [37].", "startOffset": 166, "endOffset": 170}, {"referenceID": 19, "context": "Some examples include DBSCAN [21], GDBSCAN [51], OPTICS [2], and CFSFDP [49].", "startOffset": 29, "endOffset": 33}, {"referenceID": 45, "context": "Some examples include DBSCAN [21], GDBSCAN [51], OPTICS [2], and CFSFDP [49].", "startOffset": 43, "endOffset": 47}, {"referenceID": 1, "context": "Some examples include DBSCAN [21], GDBSCAN [51], OPTICS [2], and CFSFDP [49].", "startOffset": 56, "endOffset": 59}, {"referenceID": 43, "context": "Some examples include DBSCAN [21], GDBSCAN [51], OPTICS [2], and CFSFDP [49].", "startOffset": 72, "endOffset": 76}, {"referenceID": 8, "context": ", ARTMAP [9] and SOM [33]).", "startOffset": 9, "endOffset": 12}, {"referenceID": 58, "context": ", [65, 63]) and computer vision.", "startOffset": 2, "endOffset": 10}, {"referenceID": 56, "context": ", [65, 63]) and computer vision.", "startOffset": 2, "endOffset": 10}, {"referenceID": 44, "context": "Figure 1: U-Net architecture [50] adopted in this work.", "startOffset": 29, "endOffset": 33}, {"referenceID": 42, "context": "Research in computer vision on detecting occlusion relations in natural images was stimulated by the construction of the BSDS border ownership dataset [48].", "startOffset": 151, "endOffset": 155}, {"referenceID": 52, "context": ", [59]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 20, "context": "However, in spite of such challenges, the techniques based on deep learning demonstrate impressive performance in the standard benchmark datasets such as PASCAL VOC [22] or MS COCO [39].", "startOffset": 165, "endOffset": 169}, {"referenceID": 33, "context": "However, in spite of such challenges, the techniques based on deep learning demonstrate impressive performance in the standard benchmark datasets such as PASCAL VOC [22] or MS COCO [39].", "startOffset": 181, "endOffset": 185}, {"referenceID": 35, "context": ", [41, 11, 46]).", "startOffset": 2, "endOffset": 14}, {"referenceID": 10, "context": ", [41, 11, 46]).", "startOffset": 2, "endOffset": 14}, {"referenceID": 40, "context": ", [41, 11, 46]).", "startOffset": 2, "endOffset": 14}, {"referenceID": 26, "context": "Hsu and Kira [29] utilized pairwise constraints to train a neural network to perform clustering.", "startOffset": 13, "endOffset": 17}, {"referenceID": 9, "context": "In [10], deep belief networks [28] were used for non-parametric clustering.", "startOffset": 3, "endOffset": 7}, {"referenceID": 53, "context": "[60] proposed a task-specific deep architecture for clustering based on sparse coding.", "startOffset": 0, "endOffset": 4}, {"referenceID": 54, "context": "[61] proposed an approach for image clustering.", "startOffset": 0, "endOffset": 4}, {"referenceID": 50, "context": "[56] defined a new objective function by considering the reconstruction error from an auto-encoder network and restricting the distance in the learned space between data and their corresponding cluster centers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[27] proposed a deep clustering approach to solving acoustic source separation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10] explored the possibility of employing deep learning in graph clustering.", "startOffset": 0, "endOffset": 4}, {"referenceID": 55, "context": "Second, CNNs learn representations through several stages of non-linear processing, akin to how the cortex adapts to represent the visual world [62].", "startOffset": 144, "endOffset": 148}, {"referenceID": 47, "context": ", HMAX [53]), these models capture aspects of the organization of the visual ventral stream.", "startOffset": 7, "endOffset": 11}, {"referenceID": 44, "context": "Figure 1 shows the proposed deep network architecture which is based on the U-Net [50]; an encoderdecoder with skip connections.", "startOffset": 82, "endOffset": 86}, {"referenceID": 28, "context": "We use the mean squared error loss and train the network with the Adam optimizer [31].", "startOffset": 81, "endOffset": 85}, {"referenceID": 9, "context": ",m}, D = [200 300], and SC = [10 30].", "startOffset": 29, "endOffset": 36}, {"referenceID": 27, "context": ",m}, D = [200 300], and SC = [10 30].", "startOffset": 29, "endOffset": 36}, {"referenceID": 18, "context": "To randomly generate a Gaussian Mixture Density distribution, a 2D mean vector M = [x y] is randomly sampled (x, y \u2208 [20 100]).", "startOffset": 117, "endOffset": 125}, {"referenceID": 0, "context": "A random matrix A = [a b; c d] is generated with elements in [0 1].", "startOffset": 61, "endOffset": 66}, {"referenceID": 34, "context": "We used the following clustering methods as the benchmark algorithms: k-Means (KM) [40], minimizes the sum of squared errors between data points and their nearest cluster centers.", "startOffset": 83, "endOffset": 87}, {"referenceID": 18, "context": "Fuzzy C-Means (FCM) [20, 4] assigns soft labels to data points meaning that each data point can belong to more than one cluster with different degrees of membership.", "startOffset": 20, "endOffset": 27}, {"referenceID": 3, "context": "Fuzzy C-Means (FCM) [20, 4] assigns soft labels to data points meaning that each data point can belong to more than one cluster with different degrees of membership.", "startOffset": 20, "endOffset": 27}, {"referenceID": 48, "context": "The first one is the Normalized Cut (NC) proposed by Shi and Malik [54].", "startOffset": 67, "endOffset": 71}, {"referenceID": 39, "context": "The second algorithm, known as Ng-Jordan-Weiss (NJW) [45] is a simple and significant example of spectral clustering which analysis the eigenvectors of the Laplacian of the similarity matrix.", "startOffset": 53, "endOffset": 57}, {"referenceID": 13, "context": "Mean shift (MS) [15] iteratively seeks the modes of a density function from discrete samples of that function.", "startOffset": 16, "endOffset": 20}, {"referenceID": 43, "context": "Clustering by fast search and find of density peaks (CFSFDP) [49] method seeks the modes or peaks of a distribution.", "startOffset": 61, "endOffset": 65}], "year": 2017, "abstractText": "Classification and clustering have been studied separately in machine learning and computer vision. Inspired by the recent success of deep learning models in solving various vision problems (e.g., object recognition, semantic segmentation) and the fact that humans serve as the gold standard in assessing clustering algorithms, here, we advocate for a unified treatment of the two problems and suggest that hierarchical frameworks that progressively build complex patterns on top of the simpler ones (e.g., convolutional neural networks) offer a promising solution. We do not dwell much on the learning mechanisms in these frameworks as they are still a matter of debate, with respect to biological constraints. Instead, we emphasize on the compositionality of the real world structures and objects. In particular, we show that CNNs, trained end to end using back propagation with noisy labels, are able to cluster data points belonging to several overlapping shapes, and do so much better than the state of the art algorithms. The main takeaway lesson from our study is that mechanisms of human vision, particularly the hierarchal organization of the visual ventral stream should be taken into account in clustering algorithms (e.g., for learning representations in an unsupervised manner or with minimum supervision) to reach human level clustering performance. This, by no means, suggests that other methods do not hold merits. For example, methods relying on pairwise affinities (e.g., spectral clustering) have been very successful in many cases but still fail in some cases (e.g., overlapping clusters).", "creator": "LaTeX with hyperref package"}}}