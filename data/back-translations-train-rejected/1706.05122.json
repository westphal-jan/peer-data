{"id": "1706.05122", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2017", "title": "Bib2vec: An Embedding-based Search System for Bibliographic Information", "abstract": "We propose a novel embedding model that represents relationships among several elements in bibliographic information with high representation ability and flexibility. Based on this model, we present a novel search system that shows the relationships among the elements in the ACL Anthology Reference Corpus. The evaluation results show that our model can achieve a high prediction ability and produce reasonable search results.", "histories": [["v1", "Fri, 16 Jun 2017 00:53:28 GMT  (630kb)", "http://arxiv.org/abs/1706.05122v1", "EACL2017 extended version"], ["v2", "Tue, 17 Oct 2017 16:33:20 GMT  (1107kb)", "http://arxiv.org/abs/1706.05122v2", "EACL2017 extended version. The demonstration is available atthis http URL"]], "COMMENTS": "EACL2017 extended version", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.IR", "authors": ["takuma yoneda", "koki mori", "makoto miwa", "yutaka sasaki"], "accepted": false, "id": "1706.05122"}, "pdf": {"name": "1706.05122.pdf", "metadata": {"source": "CRF", "title": "Bib2vec: An Embedding-based Search System for Bibliographic Information", "authors": ["Takuma Yoneda", "Koki Mori Makoto Miwa", "Yutaka Sasaki"], "emails": ["sd14084@toyota-ti.ac.jp", "sd15435@toyota-ti.ac.jp", "makoto-miwa@toyota-ti.ac.jp", "yutaka.sasaki@toyota-ti.ac.jp"], "sections": [{"heading": null, "text": "ar Xiv: 170 6.05 122v 1 [cs.C L] 16. Jun 2017We propose a novel embedding model that represents relationships between multiple elements in bibliographic information with high representation and flexibility. Based on this model, we present a novel search system that shows the relationships between the elements in the ACLAnthology Reference Corpus. The evaluation results show that our model can achieve a high predictive power and provide reasonable search results."}, {"heading": "1 Introduction", "text": "Modelling relationships between multiple types of information, such as nodes in information networks, has aroused great interest in natural language processing (NLP) and data mining (DM), as they can uncover hidden information in data. Topic models such as the Author-Theme Model (Rosen-Zvi et al., 2004) have been extensively studied to depict relationships between these types of information. However, these models require considerable effort to integrate new types, and are not well scalable in increasing the number of types, as they explicitly model relationships between types in the generational process. Word representation models, such as Skipgram and continuous bag-of-word models (Mikolov et al., 2013), have achieved great success in the NLP. They have been widely used to represent texts, but recent studies have begun to use these methods to represent other types of information, such as authors or papers in citation networks (Tal et al., 2015, we suggest a new relationship between several)."}, {"heading": "2 Related work", "text": "Most previous studies modeling multiple elements in bibliographic information are based on theme models such as the author-theme model (Rosen-Zvi et al., 2004). Although the models work reasonably well, they show comparatively little flexibility and scalability, since they explicitly model the generation process. Our model uses word-based models instead of theme models. Some previous studies embedded vectors in the elements, including the embedding of large information networks (Line) (Tang et al., 2015) in each node in the information network. Line treats individual information types and prepares a network for each element separately. In contrast, our model treats all types of information at the same time."}, {"heading": "3 Method", "text": "We propose a new method for displaying bibliographic information by embedding vectors in elements based on the Skip-gram and the CBOWmodel."}, {"heading": "3.1 Task definition", "text": "We assume that the bibliographic dataset has the following structure: The dataset consists of bibliographic information from essays. Each work consists of several categories. Categories are divided into two groups: a text category \u0442 (e.g. Title and Abstract1) and non-textual categories \u03a6 (e.g. Authors and References). Figure 1 illustrates an example structure of bibliographic information from an essay. Each category has one or more elements; the text category usually has many elements, while a non-textual category has a few elements (e.g. Authors are not many for a work)."}, {"heading": "3.2 Proposed model", "text": "Our model focuses on a target element and predicts a context element from the target element. We only use the elements in non-textual categories as contexts to reduce computational costs. Figure 1 shows the case when we use an element in a non-textual category as a target. We describe our probability model as a context element e j O representing all elements in the category as CBOW. Figure 1 illustrates the case when we consider the averaged vector of all elements in the textual category as a target. We describe our probability model as a context element e j O representing all elements in the category as CBOW. We define two d-dimensional vectors that represent it as a target and context. We describe our probability model as a context element e j O of a target e i i i i I in a particular paper."}, {"heading": "3.3 Predicting related elements", "text": "We calculate the uppermost k elements associated with a query element by calculating their similarities with the query element. We calculate the similarities with one of three similarity scales: the linear function in Equation (1), the point product, and the cosine distance."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Evaluation settings", "text": "We built our dataset from the ACL Anthology Reference Corpus version 20160301 (Bird et al., 2008). Statistics of the dataset and our model settings are in Table 1. For preprocessing, we deleted commas and dots sticking to the word tails, and removed non-alphabetical words such as numbers and brackets from abstracts and titles. We then reduced the words and phrases using the word2phrase tool. We prepared five categories: author, paper ID, reference, year and text. The author consists of the list of authors without distinguishing the order of authors. Paper ID is a unique identifier assigned to each paper, and this imitates the paragraph vector model (Le and Mikolov, 2014). The reference includes the paper IDs of the reference works in this dataset. Although the IDs are divided into paper ID and reference works, we do not assign the IDs to the same vectors as they represent different categories."}, {"heading": "4.2 Evaluation", "text": "We also compared some of the results of our model with those of the Author Theme Model. Our method models elements in several categories and allows us to estimate the relationships between the elements with high flexibility, but this 2 https: / / github.com / tmikolov / word2vecmakes the evaluation complex. As it is difficult to evaluate all possible combinations of inputs and targets, we focused on the relationships between authors and other categories. We prepared a evaluation data set that has to evaluate an author from other elements. We removed one (not unknown) author from each paper in the evaluation group to ask the system to predict the distant author taking into account all other elements of the paper. In order to select a correct author from all the authors, it can be incredibly difficult, so we prepared 10 selection candidates. To evaluate the effectiveness of our model, we compared the accuracy on this data set with logistic regression. As a result, if we used our model, we got 2.000 results of our model, we got 74.43 accuracy."}, {"heading": "4.3 Discussion", "text": "Furthermore, we used the averaged vector for the text category, so we do not consider the meaning of each word. Our model could ignore the interdependence between elements because we used skip grams. To solve these problems, we plan to include attention (Ling et al., 2015) so that the model can pay more attention to certain elements that are important for predicting other elements. We also found that some elements have multiple aspects. Words that are distributed across several different tasks in NLP can model this by embedding multiple vectors (Neelakantan et al., 2014)."}, {"heading": "5 Conclusions", "text": "This paper proposed a novel embedding method that represents several elements in bibliographic information with high representation and flexibility, and presented a system that can search for relationships between the elements in bibliographic information. Experimental results in Table 2 show that our model can predict relative words or similar authors favorably. We plan to extend our model to include further modifications, such as the inclusion of attention and the embedding of multiple vectors in an element. As this model has a high flexibility and scalability, it can be applied not only to essays, but also to a variety of bibliographic information in wide ranges."}, {"heading": "Acknowledgments", "text": "We would like to thank the anonymous reviewer for helpful comments and suggestions."}], "references": [{"title": "The ACL anthology reference corpus: A reference dataset for bib", "author": ["Bird et al.2008] Steven Bird", "Robert Dale", "Bonnie J. Dorr", "Bryan R. Gibson", "Mark Thomas Joseph", "MinYen Kan", "Dongwon Lee", "Brett Powley", "Dragomir R. Radev", "Yee Fan Tan"], "venue": null, "citeRegEx": "Bird et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bird et al\\.", "year": 2008}, {"title": "Noise-contrastive estimation: A new estimation principle for unnormalized statistical models", "author": ["Gutmann", "Hyv\u00e4rinen2010] Michael Gutmann", "Aapo Hyv\u00e4rinen"], "venue": "In AISTATS,", "citeRegEx": "Gutmann et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gutmann et al\\.", "year": 2010}, {"title": "Not all contexts are created equal: Better word representations with variable attention", "author": ["Black", "Isabel Trancoso", "Chu-Cheng Lin."], "venue": "EMNLP, pages 1367\u20131372.", "citeRegEx": "Black et al\\.,? 2015", "shortCiteRegEx": "Black et al\\.", "year": 2015}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S. Corrado", "Jeff Dean"], "venue": "In NIPS,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Efficient non-parametric estimation of multiple embeddings per word in vector space", "author": ["Jeevan Shankar", "Alexandre Passos", "Andrew McCallum"], "venue": null, "citeRegEx": "Neelakantan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2014}, {"title": "The author-topic model for authors and documents", "author": ["Thomas L. Griffiths", "Mark Steyvers", "Padhraic Smyth"], "venue": "In UAI,", "citeRegEx": "Rosen.Zvi et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Rosen.Zvi et al\\.", "year": 2004}, {"title": "A utility model of authors in the scientific community", "author": ["Sim et al.2015] Yanchuan Sim", "Bryan R. Routledge", "Noah A. Smith"], "venue": "In EMNLP,", "citeRegEx": "Sim et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sim et al\\.", "year": 2015}, {"title": "LINE: large-scale information network embedding", "author": ["Tang et al.2015] Jian Tang", "Meng Qu", "Mingzhe Wang", "Ming Zhang", "Jun Yan", "Qiaozhu Mei"], "venue": "In WWW,", "citeRegEx": "Tang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 5, "context": "Topic models such as author-topic model (Rosen-Zvi et al., 2004) have been widely studied to represent relationships among these types of information.", "startOffset": 40, "endOffset": 64}, {"referenceID": 3, "context": "Word representation models, such as skipgram and continuous bag-of-word (CBOW) models (Mikolov et al., 2013), have made a great success in NLP.", "startOffset": 86, "endOffset": 108}, {"referenceID": 7, "context": ", authors or papers in citation networks (Tang et al., 2015).", "startOffset": 41, "endOffset": 60}, {"referenceID": 0, "context": "We built a novel search system that enables to search for authors and words related to other authors based on the model using the ACL Anthology Reference Corpus (Bird et al., 2008).", "startOffset": 161, "endOffset": 180}, {"referenceID": 5, "context": "Most of previous studies on modeling several elements in bibliographic information have been based on topic models such as author-topic model (Rosen-Zvi et al., 2004).", "startOffset": 142, "endOffset": 166}, {"referenceID": 7, "context": "Among them, large-scale information network embedding (LINE) (Tang et al., 2015) embedded a vector to each node in information network.", "startOffset": 61, "endOffset": 80}, {"referenceID": 0, "context": "20160301 (Bird et al., 2008).", "startOffset": 9, "endOffset": 28}, {"referenceID": 6, "context": "In the rightmost two columns, we manually picked up words and authors belonging to a certain topic described in Sim et al. (2015) that can be considered to correspond to the input author.", "startOffset": 112, "endOffset": 130}, {"referenceID": 4, "context": "be able to model this by embedding multiple vectors (Neelakantan et al., 2014).", "startOffset": 52, "endOffset": 78}], "year": 2017, "abstractText": "We propose a novel embedding model that represents relationships among several elements in bibliographic information with high representation ability and flexibility. Based on this model, we present a novel search system that shows the relationships among the elements in the ACLAnthology Reference Corpus. The evaluation results show that our model can achieve a high prediction ability and produce reasonable search results.", "creator": "LaTeX with hyperref package"}}}