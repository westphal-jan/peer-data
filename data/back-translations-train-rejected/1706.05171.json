{"id": "1706.05171", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2017", "title": "Improving Scalability of Inductive Logic Programming via Pruning and Best-Effort Optimisation", "abstract": "Inductive Logic Programming (ILP) combines rule-based and statistical artificial intelligence methods, by learning a hypothesis comprising a set of rules given background knowledge and constraints for the search space. We focus on extending the XHAIL algorithm for ILP which is based on Answer Set Programming and we evaluate our extensions using the Natural Language Processing application of sentence chunking. With respect to processing natural language, ILP can cater for the constant change in how we use language on a daily basis. At the same time, ILP does not require huge amounts of training examples such as other statistical methods and produces interpretable results, that means a set of rules, which can be analysed and tweaked if necessary. As contributions we extend XHAIL with (i) a pruning mechanism within the hypothesis generalisation algorithm which enables learning from larger datasets, (ii) a better usage of modern solver technology using recently developed optimisation methods, and (iii) a time budget that permits the usage of suboptimal results. We evaluate these improvements on the task of sentence chunking using three datasets from a recent SemEval competition. Results show that our improvements allow for learning on bigger datasets with results that are of similar quality to state-of-the-art systems on the same task. Moreover, we compare the hypotheses obtained on datasets to gain insights on the structure of each dataset.", "histories": [["v1", "Fri, 16 Jun 2017 08:02:55 GMT  (34kb)", "http://arxiv.org/abs/1706.05171v1", "24 pages, preprint of article accepted at Expert Systems With Applications"]], "COMMENTS": "24 pages, preprint of article accepted at Expert Systems With Applications", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["mishal kazmi", "peter sch\\\"uller", "y\\\"ucel sayg{\\i}n"], "accepted": false, "id": "1706.05171"}, "pdf": {"name": "1706.05171.pdf", "metadata": {"source": "CRF", "title": "Improving Scalability of Inductive Logic Programming via Pruning and Best-Effort Optimisation", "authors": ["Mishal Kazmi", "Peter Sch\u00fcller"], "emails": ["mishalkazmi@sabanciuniv.edu", "ysaygin@sabanciuniv.edu", "peter.schuller@marmara.edu.tr", "schueller.p@gmail.com"], "sections": [{"heading": null, "text": "ar Xiv: 170 6.05 171v 1 [cs.A I]"}, {"heading": "1 Introduction", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2 Background", "text": "Next, we introduce logic programming and base it on this inductive logic programming."}, {"heading": "2.1 Logic Programming", "text": "A logic program theory usually includes an alphabet (variable, constant, quantifier, etc), vocabulary, logical symbols, a set of axioms, and sequential rules (Lloyd, 2012). A logic programming system consists of two parts: logic and control. Logic describes what kind of problem needs to be solved and how this problem can be solved. An ideal of logic programming is that it must be purely declarative. The popular prolog (Clocksin and Mellish, 2003) evaluates rules by resolution, which makes the result of a prolog program dependent on the order of its rules and the order of its rules."}, {"heading": "2.2 Inductive Logic Programming", "text": "Processing natural language based on handmade rules is impractical as human language is constantly evolving, in part due to the human creativity of language use, an example of which was recently noted on British highways, where they advised drivers: \"Don't Pok\u00e9mon Go and drive.\" However, Pok\u00e9mon Go is used informally as a verb here, although it was introduced only a few weeks before the character was put up. To produce robust systems, it is necessary to use statistical language models, which are often pure machine learning (ML) estimators with no rule components (Manning and Sch\u00fctze, 1999). ML methods work very well in practice, but they usually offer no way to explain why a particular prediction was made because they represent the knowledge learned in large matrices of real numbers. Some popular classifiers used for processing natural language are Naive Bayes, Decision Trees, Neural Networks, and Support Vector Machines (SVMs)."}, {"heading": "3 Related Work", "text": "Inductive Logical Programming (Muggleton, 1991) is a rather multidisciplinary field, which mainly covers areas such as computer science, artificial intelligence and bioinformatics, and the research carried out in ILP has been strongly influenced by machine learning (ML), artificial intelligence (AI) and relational databases. A number of studies (Gulwani et al., 2015; Kitzelmann, 2009; Muggleton et al., 2012) mention the systems and applications of ILP in interdisciplinary areas. We next give related work from ILP in general and then focus on ILP applied in the field of Natural Language Processing (NLP). The foundations of ILP can be demonstrated in the research of Plotkin (Plotggkin, 1971), Shapiro (Shapiro, 1983) and Sammut and Banerji (Sammut and Banerji, 1986)."}, {"heading": "3.1 ASP-based ILP Systems", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "3.2 ILP and NLP", "text": "From the point of view of the NLP, it is hoped that it will be able to strike a balance between these two alternatives to large-scale but shallow analysis; the ILP should establish a better relationship between the scope and depth of analysis (Muggleton, 1999); the ILP has been successfully applied to the field of NLP; it has not only been shown to be more accurate than other ML approaches, but also to be able to translate accurate sentences into deductive databases (Law et al., 2014)."}, {"heading": "4 Extending XHAIL algorithm and system", "text": "Initially, we intended to use the latest ILP systems (ILASP2 or ILED part) in our work - AIS part satisfies flies. However, preliminary experiments with ILASP2 showed a lack of scalability (memory usage) even for only 100 sentences due to the adverse search space hypothesis. Furthermore, experiments with ILED contained several problematic cornerstones in the ILED algorithm that led to empty hypotheses in the processing of examples that contradict each other (which cannot be avoided in real NLP data). While we tried to fix these problems in the algorithm, other problems in the ILED implementation came to light. After consulting the authors of (Mitra and Baral, 2016) we learned that they had the same problems and used XHAIL, we also decided to rely on XHAIL for our research, as it is the most robust tool for our task in comparison to the other modules of AIHL, and although we discovered that XHAIL is capable of several disadvantages."}, {"heading": "4.1 Kernel Pruning according to Support", "text": "Therefore, the mathematically most expensive part of the search in XHAIL is induction. Each non-basic rule in K is rewritten into a combination of several guesses, a guess for the rule, and an additional guess for each body atom. We have also observed that some non-basic rules in K are generalizations of many different ground rules in K, while some non-basic rules correspond to only one instance in K. In the following, we say that the support of r in K is the number of ground rules in K that are transformed into the generalization module of XHAIL (see Figure 1). The higher the support, the more examples can be covered by this rule, and the more likely that rule or part of it will be included in the optimal hypothesis. Therefore, we modified the XHAIL algorithm as follows."}, {"heading": "4.2 Unsat-core based and Best-effort Optimisation", "text": "We have observed that ASP search in XHAIL abduction and induction components progresses very slowly from a suboptimal to an optimal solution. XHAIL integrates version 3 of Gringo (Gebser et al., 2011) and Clasp (Gebser et al., 2012b), both of which are fairly outdated. Specifically, Clasp in this version does not support three important improvements found for ASP optimization: (i) unsat core optimization (Andres et al., 2012), (ii) stratification for obtaining suboptimal response sets (Alviano et al., 2015b; Ans\u00f3tegui et al., 2013), and (iiiii) unsat core shrinkage (Alviano and Dodaro, 2016). Method (i) sells the classical industry and bound search method that progresses from the worst to the better solutions."}, {"heading": "4.3 Other Improvements", "text": "We made two minor technical contributions to XHAIL. A practically effective improvement to XHAIL concerns K \u2032. As seen in Example 3, there are three rules in K \u2032 that correspond to a modular variable renaming. XHAIL contains canonization algorithms to avoid such situations, based on hash body elements of rules. However, we found that these algorithms are not effective for cases with more than one variable and for cases with more than one body atom, because XHAIL (i) uses a defined data structure that maintains an order over elements, (ii) the defined data structure is sensitive to insertion sequence, and (iii) the hashing of the set is dependent on the order of being canonical. We have made this canonization algorithm applicable to a much broader range of cases by changing the data type of rulers in XHAIL to a set that maintains a solution depending on the value of the elements added."}, {"heading": "5 Chunking with ILP", "text": "Chunking (Tjong Kim Sang and Buchholz, 2000) or shallow parsing is the identification of short phrases such as nouns or prepositional phrases, which are usually heavily based on Part of Speech (POS) keywords. POS only provides information about the token type, i.e. whether words are nouns, verbs, adjectives, etc., and chunking derives a flat phrase structure from this, in our case a single layer of chunks. Our framework for chunking consists of three main parts, as shown in Figure 2. Pre-processing is done using the Stanford CoreNLP tool, from which we obtain the facts that are added to XHAIL's background knowledge or used with a hypothesis to predict the chunks of an input."}, {"heading": "5.1 Preprocessing", "text": "Using a flat parser (Bohnet et al., 2013), we obtain the dependency relationships for the sentences. Our ASP representation contains atoms of the following form: 9 \u2022 pos (P, T) representing this token T, has the POS tag P, \u2022 form (T, text) representing this token T, has the surface form Text, \u2022 head (T1, T2) and rel (R, T) representing this token T2, depends on the token T1 with the dependency relationship R. Example 6 (continued). Figure 3a shows the result of preprocessing performed on sentence (5), which is a set of ASP facts. We use Penn Treebank POS tags as provided by Stanford CoreNLP. To form valid ASP constant terms from POS tags, we put \"c _\" in front of them, replace special characters such as ROPOS characters (we will generate PRS-P4 tags)."}, {"heading": "5.2 Background Knowledge and Mode Bias", "text": "We define which POS tags can exist in Postype / 1 predicate and which tokens exist in Token / 1 predicate. In addition, we provide for each token the POS tag of its successor Token in Nextpos / 2.Mode bias conditions that restrict the search space for generating hypotheses. Hypothesis rules contain as head atoms of form split (T) 10, indicating that a chunk ends at Token T and a new chunk begins at Token T + 1. The argument of the predicate split / 1 in the head is of type Token.The body of the hypotheses rules can contain Pos / 2 and Nextpos / 2, with the first argument being a constant of type Postype (which is defined in Figure 3b) and the second argument being a variable of type Tokens. Therefore, this mode searches for rules to define chunk splits based on POS tools, the next POS mode will not be used consciously."}, {"heading": "5.3 Learning with ILP", "text": "Figure 3d shows rules that recognize gold standard chunks, and # example instructions that define for XHAIL which atoms must be appropriate to include an example. These rules, with Goodchunk / 1 in mind, define what a good (i.e. gold standard) chunk is in each example, based on where in the training data a split occurs in a chunk to help in learning a hypothesis about the chunk. Note that negation is only present in these rules, although we could apply it elsewhere in the background knowledge. XHAIL is then able to learn a hypothesis based on background knowledge, mode bias, and examples."}, {"heading": "5.4 Chunking with ASP using Learned Hypothesis", "text": "The hypothesis generated by XHAIL can then be used together with the background knowledge given in Figure 3b and with the pre-processed input of a new set. Evaluation of all these rules results in a series of split points in the set corresponding to a predicted chunking of the input set. Example 7. For sentence (5) with token indices 1,..., 9, a response set containing the atoms {split (6), split (7)} and no other atoms for predicate split / 1 results in the chunking shown in (6)."}, {"heading": "6 Evaluation and Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Datasets", "text": "We use the SemEval 2016 iSTS Task 2 datasets (Agirre et al., 2016), which contained two separate files with pairs of sentences. Three different datasets were provided: Headlines, Images and Answers students. The Headlines dataset was mined by various news sources by European Media Monitor. The Images dataset was a collection of captions extracted from the Flickr dataset (Rashtchian et al., 2010). The Answers-Students Corpus consists of student interactions with the BEETLE II tutorial dialog system, which is an intelligent tutorial engine that teaches students basic electricity and electronics questions. Below, we will name S1 and S2 pairs of sentences in these datasets. Regarding the size of the SemEval Training dataset, we are unsure that the datasets contain larger and picture datasets containing 756 and 750 pairs each."}, {"heading": "6.2 Scoring", "text": "We use difflib.SequenceMatcher in Python to compare the sentences obtained from learning in ILP with the gold standard sentences. From the comparisons obtained in this way, we calculate precision, recall and F1 score as follows. Precision = No. of Matched SequencesNo. of ILP-Learned ChunksRecall = No. of Matched SequencesNo. of Gold ChunksScore = 2 \u00d7 Precision \u00d7 RecallPrecision + RecallTo investigate the effectiveness of our mode bias in learning a hypothesis that can correctly classify the data set, we perform cross-validations (see above) and measure the accuracy of all hypotheses used in cross-validation on the testset.Due to the differences in S1 / S2 portions of data sets, the results are evaluated separately for S1 and S2."}, {"heading": "6.3 Experimental Methodology", "text": "This year it has come to the point that it has never come as far as this year, \"he said in an interview with the German Press Agency.\" We have never lost as much time as this year, \"he said.\" But we are not there yet, \"he said.\" We are not there yet, \"he said."}, {"heading": "6.4 Results", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "6.5 Discussion", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "7 Conclusion and Future Work", "text": "Dre rf\u00fc nde nlrrfEe\u00fceegnln in red nlrfEe\u00fceegnr rf\u00fc ide nlrfEe\u00fceegnrrrrrln rf\u00fc eiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiiuiuiuiuiuiuiuiuiuiiuiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii"}, {"heading": "Acknowledgments", "text": "This research was supported by the Turkish Council of Science and Technology (TUBITAK) [grant number 114E777] and the Pakistan Higher Education Commission (HEC). We are grateful to Carmine Dodaro for supporting us on the WASP solver."}], "references": [{"title": "Parsing by chunks", "author": ["S.P. Abney"], "venue": "Principle-based parsing, pages 257\u2013278.", "citeRegEx": "Abney,? 1991", "shortCiteRegEx": "Abney", "year": 1991}, {"title": "SemEval-2016 task 2: Interpretable Semantic Textual Similarity", "author": ["E. Agirre", "A. Gonzalez-Agirre", "I. Lopez-Gazpio", "M. Maritxalar", "G. Rigau", "L. Uria"], "venue": "Proceedings of SemEval, pages 512\u2013524.", "citeRegEx": "Agirre et al\\.,? 2016", "shortCiteRegEx": "Agirre et al\\.", "year": 2016}, {"title": "Anytime answer set optimization via unsatisfiable core shrinking", "author": ["M. Alviano", "C. Dodaro"], "venue": "Theory and Practice of Logic Programming, 16(5-6):533\u2013551.", "citeRegEx": "Alviano and Dodaro,? 2016", "shortCiteRegEx": "Alviano and Dodaro", "year": 2016}, {"title": "WASP: A native ASP solver based on constraint learning", "author": ["M. Alviano", "C. Dodaro", "W. Faber", "N. Leone", "F. Ricca"], "venue": "Logic Programming and Nonmonotonic Reasoning, pages 54\u201366.", "citeRegEx": "Alviano et al\\.,? 2013", "shortCiteRegEx": "Alviano et al\\.", "year": 2013}, {"title": "Advances in WASP", "author": ["M. Alviano", "C. Dodaro", "N. Leone", "F. Ricca"], "venue": "Logic Programming and Nonmonotonic Reasoning , pages 40\u201354.", "citeRegEx": "Alviano et al\\.,? 2015a", "shortCiteRegEx": "Alviano et al\\.", "year": 2015}, {"title": "Optimum stable model search: algorithms and implementation", "author": ["M. Alviano", "C. Dodaro", "J. Marques-Silva", "F. Ricca"], "venue": "Journal of Logic and Computation, page exv061.", "citeRegEx": "Alviano et al\\.,? 2015b", "shortCiteRegEx": "Alviano et al\\.", "year": 2015}, {"title": "Unsatisfiability-based optimization in clasp", "author": ["B. Andres", "B. Kaufmann", "O. Matheis", "T. Schaub"], "venue": "International Conference on Logic Programming, Technical Communications, pages 212\u2013221.", "citeRegEx": "Andres et al\\.,? 2012", "shortCiteRegEx": "Andres et al\\.", "year": 2012}, {"title": "SAT-based MaxSAT algorithms", "author": ["C. Ans\u00f3tegui", "M.L. Bonet", "J. Levy"], "venue": "Artificial Intelligence, 196:77\u2013105.", "citeRegEx": "Ans\u00f3tegui et al\\.,? 2013", "shortCiteRegEx": "Ans\u00f3tegui et al\\.", "year": 2013}, {"title": "DTSim at SemEval-2016 task 2: Interpreting Similarity of Texts Based on Automated Chunking, Chunk Alignment and Semantic Relation Prediction", "author": ["R. Banjade", "N. Maharjan", "N.B. Niraula", "V. Rus"], "venue": "Proceedings of SemEval, pages 809\u2013813.", "citeRegEx": "Banjade et al\\.,? 2016", "shortCiteRegEx": "Banjade et al\\.", "year": 2016}, {"title": "Joint morphological and syntactic analysis for richly inflected languages", "author": ["B. Bohnet", "J. Nivre", "I. Boguslavsky", "R. Farkas", "F. Ginter", "J. Haji\u010d"], "venue": "Transactions of the Association for Computational Linguistics, 1:415\u2013428.", "citeRegEx": "Bohnet et al\\.,? 2013", "shortCiteRegEx": "Bohnet et al\\.", "year": 2013}, {"title": "XHAIL (Version 4c5e0b8) [System for eXtended Hybrid Abductive Inductive Learning", "author": ["S. Bragaglia", "P. Sch\u00fcller"], "venue": "Retrieved from https://github.com/knowlp/XHAIL.", "citeRegEx": "Bragaglia and Sch\u00fcller,? 2016", "shortCiteRegEx": "Bragaglia and Sch\u00fcller", "year": 2016}, {"title": "Answer set programming at a glance", "author": ["G. Brewka", "T. Eiter", "M. Truszczy\u0144ski"], "venue": "Communications of the ACM, 54(12):92\u2013103.", "citeRegEx": "Brewka et al\\.,? 2011", "shortCiteRegEx": "Brewka et al\\.", "year": 2011}, {"title": "ASP-Core-2 Input language format. Technical report, ASP Standardization Working Group", "author": ["T. Schaub"], "venue": null, "citeRegEx": "Schaub,? \\Q2012\\E", "shortCiteRegEx": "Schaub", "year": 2012}, {"title": "Programming in PROLOG", "author": ["W. Clocksin", "C.S. Mellish"], "venue": "Springer Science & Business Media.", "citeRegEx": "Clocksin and Mellish,? 2003", "shortCiteRegEx": "Clocksin and Mellish", "year": 2003}, {"title": "Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms", "author": ["M. Collins"], "venue": "Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10, pages 1\u20138. Association for Computational Linguistics.", "citeRegEx": "Collins,? 2002", "shortCiteRegEx": "Collins", "year": 2002}, {"title": "Constructing biological knowledge bases by extracting information from text sources", "author": ["M. Craven", "J. Kumlien"], "venue": "International Conference on Intelligent Systems for Molecular Biology (ISMB), pages 77\u201386.", "citeRegEx": "Craven and Kumlien,? 1999", "shortCiteRegEx": "Craven and Kumlien", "year": 1999}, {"title": "Integrating probabilistic and logical reasoning", "author": ["J. Cussens"], "venue": "Foundations of Bayesianism, pages 241\u2013260.", "citeRegEx": "Cussens,? 2001a", "shortCiteRegEx": "Cussens", "year": 2001}, {"title": "Parameter estimation in stochastic logic programs", "author": ["J. Cussens"], "venue": "Machine Learning, 44(3):245\u2013 271.", "citeRegEx": "Cussens,? 2001b", "shortCiteRegEx": "Cussens", "year": 2001}, {"title": "Mbt: A memory-based part of speech tagger-generator", "author": ["W. Daelemans", "J. Zavrel", "P. Berck", "S. Gillis"], "venue": "arXiv preprint cmp-lg/9607012.", "citeRegEx": "Daelemans et al\\.,? 1996", "shortCiteRegEx": "Daelemans et al\\.", "year": 1996}, {"title": "Logical settings for concept-learning", "author": ["L. De Raedt"], "venue": "Artificial Intelligence, 95(1):187\u2013201.", "citeRegEx": "Raedt,? 1997", "shortCiteRegEx": "Raedt", "year": 1997}, {"title": "Probabilistic inductive logic programming", "author": ["L. De Raedt", "K. Kersting"], "venue": "Probabilistic Inductive Logic Programming, pages 1\u201327.", "citeRegEx": "Raedt and Kersting,? 2008", "shortCiteRegEx": "Raedt and Kersting", "year": 2008}, {"title": "Inductive learning algorithms and representations for text categorization", "author": ["S. Dumais", "J. Platt", "D. Heckerman", "M. Sahami"], "venue": "Proceedings of the Seventh International Conference on Information and Knowledge Management, pages 148\u2013155.", "citeRegEx": "Dumais et al\\.,? 1998", "shortCiteRegEx": "Dumais et al\\.", "year": 1998}, {"title": "Bootstrap Methods for Standard Errors, Confidence Intervals, and Other Measures of Statistical Accuracy", "author": ["B. Efron", "R. Tibshirani"], "venue": "Statistical Science, 1(1):54\u201375.", "citeRegEx": "Efron and Tibshirani,? 1986", "shortCiteRegEx": "Efron and Tibshirani", "year": 1986}, {"title": "Applications of Answer Set Programming", "author": ["E. Erdem", "M. Gelfond", "N. Leone"], "venue": "AI Magazine, 37(3):53\u201368.", "citeRegEx": "Erdem et al\\.,? 2016", "shortCiteRegEx": "Erdem et al\\.", "year": 2016}, {"title": "A user\u2019s guide to gringo, clasp, clingo, and iclingo", "author": ["M. Gebser", "R. Kaminski", "B. Kaufmann", "M. Ostrowski", "T. Schaub", "S. Thiele"], "venue": "Technical report, University of Potsdam.", "citeRegEx": "Gebser et al\\.,? 2008", "shortCiteRegEx": "Gebser et al\\.", "year": 2008}, {"title": "Answer set solving in practice", "author": ["M. Gebser", "R. Kaminski", "B. Kaufmann", "T. Schaub"], "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning, 6(3):1\u2013238.", "citeRegEx": "Gebser et al\\.,? 2012a", "shortCiteRegEx": "Gebser et al\\.", "year": 2012}, {"title": "Advances in gringo series 3", "author": ["M. Gebser", "R. Kaminski", "A. K\u00f6nig", "T. Schaub"], "venue": "International Conference on Logic Programming and Non-monotonic Reasoning, pages 345\u2013351.", "citeRegEx": "Gebser et al\\.,? 2011", "shortCiteRegEx": "Gebser et al\\.", "year": 2011}, {"title": "Conflict-driven answer set solving: From theory to practice", "author": ["M. Gebser", "B. Kaufmann", "T. Schaub"], "venue": "Artificial Intelligence, 187:52\u201389.", "citeRegEx": "Gebser et al\\.,? 2012b", "shortCiteRegEx": "Gebser et al\\.", "year": 2012}, {"title": "The Stable Model Semantics for Logic Programming", "author": ["M. Gelfond", "V. Lifschitz"], "venue": "International Conference and Symposium on Logic Programming, pages 1070\u20131080.", "citeRegEx": "Gelfond and Lifschitz,? 1988", "shortCiteRegEx": "Gelfond and Lifschitz", "year": 1988}, {"title": "Inductive programming meets the real world", "author": ["S. Gulwani", "J. Hernandez-Orallo", "E. Kitzelmann", "S.H. Muggleton", "U. Schmid", "B. Zorn"], "venue": "Communications of the ACM, 58(11):90\u201399.", "citeRegEx": "Gulwani et al\\.,? 2015", "shortCiteRegEx": "Gulwani et al\\.", "year": 2015}, {"title": "Abductive Logic Programming", "author": ["A.C. Kakas", "R.A. Kowalski", "F. Toni"], "venue": "Journal of Logic and Computation, 2(6):719\u2013770.", "citeRegEx": "Kakas et al\\.,? 1992", "shortCiteRegEx": "Kakas et al\\.", "year": 1992}, {"title": "Incremental learning of event definitions with inductive logic programming", "author": ["N. Katzouris", "A. Artikis", "G. Paliouras"], "venue": "Machine Learning, 100(2-3):555\u2013585.", "citeRegEx": "Katzouris et al\\.,? 2015", "shortCiteRegEx": "Katzouris et al\\.", "year": 2015}, {"title": "Inspire at SemEval-2016 task 2: Interpretable semantic textual similarity alignment based on answer set programming", "author": ["M. Kazmi", "P. Sch\u00fcller"], "venue": "Proceedings of SemEval, pages 1109\u20131115.", "citeRegEx": "Kazmi and Sch\u00fcller,? 2016", "shortCiteRegEx": "Kazmi and Sch\u00fcller", "year": 2016}, {"title": "Functional genomic hypothesis generation and experimentation by a robot scientist", "author": ["R.D. King", "K.E. Whelan", "F.M. Jones", "P.G.K. Reiser", "C.H. Bryant", "S.H. Muggleton", "D.B. Kell", "S.G. Oliver"], "venue": "Nature, 427(6971):247\u2013252.", "citeRegEx": "King et al\\.,? 2004", "shortCiteRegEx": "King et al\\.", "year": 2004}, {"title": "Inductive programming: A survey of program synthesis techniques", "author": ["E. Kitzelmann"], "venue": "International Workshop on Approaches and Applications of Inductive Programming, pages 50\u201373.", "citeRegEx": "Kitzelmann,? 2009", "shortCiteRegEx": "Kitzelmann", "year": 2009}, {"title": "Inductive learning of answer set programs", "author": ["M. Law", "A. Russo", "K. Broda"], "venue": "European Workshop on Logics in Artificial Intelligence, pages 311\u2013325.", "citeRegEx": "Law et al\\.,? 2014", "shortCiteRegEx": "Law et al\\.", "year": 2014}, {"title": "Learning weak constraints in answer set programming", "author": ["M. Law", "A. Russo", "K. Broda"], "venue": "Theory and Practice of Logic Programming, 15(4-5):511\u2013525.", "citeRegEx": "Law et al\\.,? 2015", "shortCiteRegEx": "Law et al\\.", "year": 2015}, {"title": "Answer set programming and plan generation", "author": ["V. Lifschitz"], "venue": "Artificial Intelligence, 138(1-2):39\u201354.", "citeRegEx": "Lifschitz,? 2002", "shortCiteRegEx": "Lifschitz", "year": 2002}, {"title": "Foundations of logic programming", "author": ["J.W. Lloyd"], "venue": "Springer Science & Business Media.", "citeRegEx": "Lloyd,? 2012", "shortCiteRegEx": "Lloyd", "year": 2012}, {"title": "FBK-HLT-NLP at SemEval-2016 task 2: A multitask, deep learning approach for interpretable semantic textual similarity", "author": ["S. Magnolini", "A. Feltracco", "B. Magnini"], "venue": "Proceedings of SemEval, pages 783\u2013789.", "citeRegEx": "Magnolini et al\\.,? 2016", "shortCiteRegEx": "Magnolini et al\\.", "year": 2016}, {"title": "Foundations of statistical natural language processing (Vol", "author": ["C.D. Manning", "H. Sch\u00fctze"], "venue": "999). Cambridge:MIT Press.", "citeRegEx": "Manning and Sch\u00fctze,? 1999", "shortCiteRegEx": "Manning and Sch\u00fctze", "year": 1999}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["C.D. Manning", "M. Surdeanu", "J. Bauer", "J.R. Finkel", "S. Bethard", "D. McClosky"], "venue": "ACL System Demonstrations, pages 55\u201360.", "citeRegEx": "Manning et al\\.,? 2014", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Addressing a question answering challenge by combining statistical methods with inductive rule learning and reasoning", "author": ["A. Mitra", "C. Baral"], "venue": "Association for the Advancement of Artificial Intelligence, pages 2779\u20132785.", "citeRegEx": "Mitra and Baral,? 2016", "shortCiteRegEx": "Mitra and Baral", "year": 2016}, {"title": "Inductive logic programming for natural language processing", "author": ["R.J. Mooney"], "venue": "Inductive Logic Programming, pages 1\u201322.", "citeRegEx": "Mooney,? 1996", "shortCiteRegEx": "Mooney", "year": 1996}, {"title": "Inductive logic programming", "author": ["S. Muggleton"], "venue": "New generation computing, 8(4):295\u2013318.", "citeRegEx": "Muggleton,? 1991", "shortCiteRegEx": "Muggleton", "year": 1991}, {"title": "Inverse entailment and Progol", "author": ["S. Muggleton"], "venue": "New generation computing, 13(3-4):245\u2013286.", "citeRegEx": "Muggleton,? 1995", "shortCiteRegEx": "Muggleton", "year": 1995}, {"title": "Inductive logic programming: issues, results and the challenge of learning language in logic", "author": ["S. Muggleton"], "venue": "Artificial Intelligence, 114(1-2):283\u2013296.", "citeRegEx": "Muggleton,? 1999", "shortCiteRegEx": "Muggleton", "year": 1999}, {"title": "Learning structure and parameters of stochastic logic programs", "author": ["S. Muggleton"], "venue": "International Conference on Inductive Logic Programming, pages 198\u2013206.", "citeRegEx": "Muggleton,? 2002", "shortCiteRegEx": "Muggleton", "year": 2002}, {"title": "Machine invention of first-order predicates by inverting resolution", "author": ["S. Muggleton", "W. Buntine"], "venue": "Proceedings of the Fifth International Conference on Machine Learning, pages 339\u2013352.", "citeRegEx": "Muggleton and Buntine,? 1992", "shortCiteRegEx": "Muggleton and Buntine", "year": 1992}, {"title": "Inductive logic programming: Theory and methods", "author": ["S. Muggleton", "L. De Raedt"], "venue": "The Journal of Logic Programming, 19:629\u2013679.", "citeRegEx": "Muggleton and Raedt,? 1994", "shortCiteRegEx": "Muggleton and Raedt", "year": 1994}, {"title": "ILP turns 20", "author": ["S. Muggleton", "L. De Raedt", "D. Poole", "I. Bratko", "P. Flach", "K. Inoue", "A. Srinivasan"], "venue": "Machine Learning, 86(1):3\u201323.", "citeRegEx": "Muggleton et al\\.,? 2012", "shortCiteRegEx": "Muggleton et al\\.", "year": 2012}, {"title": "Stochastic logic programs", "author": ["S Muggleton"], "venue": "Advances in Inductive Logic Programming, 32:254\u2013264.", "citeRegEx": "Muggleton,? 1996", "shortCiteRegEx": "Muggleton", "year": 1996}, {"title": "Efficient induction of logic programs", "author": ["S. Muggleton", "C Feng"], "venue": "The Turing Institute", "citeRegEx": "Muggleton and Feng,? \\Q1990\\E", "shortCiteRegEx": "Muggleton and Feng", "year": 1990}, {"title": "Meta-interpretive learning: application to grammatical inference", "author": ["S.H. Muggleton", "D. Lin", "N. Pahlavi", "A. Tamaddoni-Nezhad"], "venue": "Machine Learning, 94(1):25\u201349.", "citeRegEx": "Muggleton et al\\.,? 2014", "shortCiteRegEx": "Muggleton et al\\.", "year": 2014}, {"title": "A note on inductive generalization", "author": ["G.D. Plotkin"], "venue": "Machine intelligence, 5(1):153\u2013163.", "citeRegEx": "Plotkin,? 1970", "shortCiteRegEx": "Plotkin", "year": 1970}, {"title": "A further note on inductive generalization", "author": ["G.D. Plotkin"], "venue": "Machine intelligence, 6:101\u2013124.", "citeRegEx": "Plotkin,? 1971", "shortCiteRegEx": "Plotkin", "year": 1971}, {"title": "Learning logical definitions from relations", "author": ["J.R. Quinlan"], "venue": "Machine Learning, 5(3):239\u2013266.", "citeRegEx": "Quinlan,? 1990", "shortCiteRegEx": "Quinlan", "year": 1990}, {"title": "Collecting image annotations using Amazon\u2019s Mechanical Turk", "author": ["C. Rashtchian", "P. Young", "M. Hodosh", "J. Hockenmaier"], "venue": "Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon\u2019s Mechanical Turk, pages 139\u2013147.", "citeRegEx": "Rashtchian et al\\.,? 2010", "shortCiteRegEx": "Rashtchian et al\\.", "year": 2010}, {"title": "Nonmonotonic abductive inductive learning", "author": ["O. Ray"], "venue": "Journal of Applied Logic, 7(3):329\u2013340.", "citeRegEx": "Ray,? 2009", "shortCiteRegEx": "Ray", "year": 2009}, {"title": "Learning concepts by asking questions", "author": ["C. Sammut", "R.B. Banerji"], "venue": "Machine Learning: An artificial intelligence approach, 2:167\u2013192.", "citeRegEx": "Sammut and Banerji,? 1986", "shortCiteRegEx": "Sammut and Banerji", "year": 1986}, {"title": "Generative modeling with failure in PRISM", "author": ["T. Sato", "Y. Kameya", "Zhou", "N.-F."], "venue": "International Joint Conference on Artificial Intelligence, pages 847\u2013852.", "citeRegEx": "Sato et al\\.,? 2005", "shortCiteRegEx": "Sato et al\\.", "year": 2005}, {"title": "Flexible Combinatory Categorial Grammar Parsing using the CYK Algorithm and Answer Set Programming", "author": ["P. Sch\u00fcller"], "venue": "International Conference on Logic Programming and Non-monotonic Reasoning, pages 499\u2013511.", "citeRegEx": "Sch\u00fcller,? 2013", "shortCiteRegEx": "Sch\u00fcller", "year": 2013}, {"title": "Tackling Winograd Schemas by Formalizing Relevance Theory in Knowledge Graphs", "author": ["P. Sch\u00fcller"], "venue": "International Conference on Principles of Knowledge Representation and Reasoning (KR), pages 358\u2013367. AAAI Press.", "citeRegEx": "Sch\u00fcller,? 2014", "shortCiteRegEx": "Sch\u00fcller", "year": 2014}, {"title": "Modeling Variations of First-Order Horn Abduction in Answer Set Programming", "author": ["P. Sch\u00fcller"], "venue": "Fundamenta Informaticae, 149:159\u2013207.", "citeRegEx": "Sch\u00fcller,? 2016", "shortCiteRegEx": "Sch\u00fcller", "year": 2016}, {"title": "Answer Set Programming via Controlled Natural Language Processing", "author": ["R. Schwitter"], "venue": "Controlled Natural Language, pages 26\u201343.", "citeRegEx": "Schwitter,? 2012", "shortCiteRegEx": "Schwitter", "year": 2012}, {"title": "Algorithmic program debugging", "author": ["E.Y. Shapiro"], "venue": "MIT press.", "citeRegEx": "Shapiro,? 1983", "shortCiteRegEx": "Shapiro", "year": 1983}, {"title": "Towards addressing the winograd schema challenge - Building and using a semantic parser and a knowledge hunting module", "author": ["A. Sharma", "N.H. Vo", "S. Aditya", "C. Baral"], "venue": "International Joint Conference on Artificial Intelligence (IJCAI), pages 1319\u20131325.", "citeRegEx": "Sharma et al\\.,? 2015", "shortCiteRegEx": "Sharma et al\\.", "year": 2015}, {"title": "Using multiple clause constructors in inductive logic programming for semantic parsing", "author": ["L.R. Tang", "R.J. Mooney"], "venue": "European Conference on Machine Learning, pages 466\u2013477.", "citeRegEx": "Tang and Mooney,? 2001", "shortCiteRegEx": "Tang and Mooney", "year": 2001}, {"title": "IISCNLP at SemEval-2016 task 2: Interpretable STS with ILP based Multiple Chunk Aligner", "author": ["L. Tekumalla", "S. Jat"], "venue": "Proceedings of SemEval, pages 790\u2013795.", "citeRegEx": "Tekumalla and Jat,? 2016", "shortCiteRegEx": "Tekumalla and Jat", "year": 2016}, {"title": "Introduction to the CoNLL-2000 shared task: Chunking", "author": ["E.F. Tjong Kim Sang", "S. Buchholz"], "venue": "Workshop on Learning Language in Logic and Conference on Computational Natural Language Learning, pages 127\u2013132.", "citeRegEx": "Sang and Buchholz,? 2000", "shortCiteRegEx": "Sang and Buchholz", "year": 2000}, {"title": "Completing logic programs by inverse resolution", "author": ["R. Wirth"], "venue": "European Working Session on Learning, pages 239\u2013250.", "citeRegEx": "Wirth,? 1989", "shortCiteRegEx": "Wirth", "year": 1989}, {"title": "Learning to parse database queries using inductive logic programming", "author": ["J.M. Zelle", "R.J. Mooney"], "venue": "Proceedings of the National Conference on Artificial Intelligence, pages 1050\u20131055.", "citeRegEx": "Zelle and Mooney,? 1996", "shortCiteRegEx": "Zelle and Mooney", "year": 1996}, {"title": "Combining top-down and bottom-up techniques in inductive logic programming", "author": ["J.M. Zelle", "R.J. Mooney", "J.B. Konvisser"], "venue": "Proceedings of the Eleventh International Conference on Machine Learning, pages 343\u2013351.", "citeRegEx": "Zelle et al\\.,? 1994", "shortCiteRegEx": "Zelle et al\\.", "year": 1994}], "referenceMentions": [{"referenceID": 58, "context": "In our experiments on sentence chunking (Tjong Kim Sang and Buchholz, 2000) we encountered several problems with state-of-the-art ASP-based ILP systems XHAIL (Ray, 2009), ILED", "startOffset": 158, "endOffset": 169}, {"referenceID": 31, "context": "(Katzouris et al., 2015), and ILASP2 (Law et al.", "startOffset": 0, "endOffset": 24}, {"referenceID": 36, "context": ", 2015), and ILASP2 (Law et al., 2015).", "startOffset": 20, "endOffset": 38}, {"referenceID": 6, "context": "\u2022 We extend XHAIL with best-effort optimisation using the newest ASP optimisation technology of unsat-core optimisation (Andres et al., 2012) with stratification (Alviano et al.", "startOffset": 120, "endOffset": 141}, {"referenceID": 5, "context": ", 2012) with stratification (Alviano et al., 2015b; Ans\u00f3tegui et al., 2013) and core shrinking (Alviano and Dodaro, 2016) using the WASP2 (Alviano et al.", "startOffset": 28, "endOffset": 75}, {"referenceID": 7, "context": ", 2012) with stratification (Alviano et al., 2015b; Ans\u00f3tegui et al., 2013) and core shrinking (Alviano and Dodaro, 2016) using the WASP2 (Alviano et al.", "startOffset": 28, "endOffset": 75}, {"referenceID": 2, "context": ", 2013) and core shrinking (Alviano and Dodaro, 2016) using the WASP2 (Alviano et al.", "startOffset": 27, "endOffset": 53}, {"referenceID": 26, "context": ", 2013, 2015a) solver and the Gringo (Gebser et al., 2011) grounder.", "startOffset": 37, "endOffset": 58}, {"referenceID": 41, "context": "\u2022 We describe a framework for chunking with ILP, based on preprocessing with Stanford Core NLP (Manning et al., 2014) tools.", "startOffset": 95, "endOffset": 117}, {"referenceID": 1, "context": "\u2022 We experimentally analyse the relationship between the pruning parameter, number of training examples, and prediction score on the sentence chunking (Tjong Kim Sang and Buchholz, 2000) subtask of iSTS at SemEval 2016 (Agirre et al., 2016).", "startOffset": 219, "endOffset": 240}, {"referenceID": 10, "context": "Our extensions and modifications of the XHAIL software are available in a public fork of the official XHAIL Git repository (Bragaglia and Sch\u00fcller, 2016).", "startOffset": 123, "endOffset": 153}, {"referenceID": 38, "context": "A logic programs theory normally comprises of an alphabet (variable, constant, quantifier, etc), vocabulary, logical symbols, a set of axioms and inference rules (Lloyd, 2012).", "startOffset": 162, "endOffset": 175}, {"referenceID": 13, "context": "The popular Prolog (Clocksin and Mellish, 2003) system evaluates rules using resolution, which makes the result of a Prolog program depending on the order of its rules and on the order of the bodies of its rules.", "startOffset": 19, "endOffset": 47}, {"referenceID": 11, "context": "Answer Set Programming (ASP) (Brewka et al., 2011; Gebser et al., 2012a) is a more recent logic programming formalism, featuring more declarativity than Prolog by defining semantics based on Herbrand models (Gelfond and Lifschitz, 1988).", "startOffset": 29, "endOffset": 72}, {"referenceID": 25, "context": "Answer Set Programming (ASP) (Brewka et al., 2011; Gebser et al., 2012a) is a more recent logic programming formalism, featuring more declarativity than Prolog by defining semantics based on Herbrand models (Gelfond and Lifschitz, 1988).", "startOffset": 29, "endOffset": 72}, {"referenceID": 28, "context": ", 2012a) is a more recent logic programming formalism, featuring more declarativity than Prolog by defining semantics based on Herbrand models (Gelfond and Lifschitz, 1988).", "startOffset": 143, "endOffset": 172}, {"referenceID": 37, "context": "Most ASP programs follow the Generate-Define-Test structure (Lifschitz, 2002) to (i) generate a space of potential solutions, (ii) define auxiliary concepts, and (iii) test to invalidate solutions using constraints or incurring a cost on non-preferred solutions.", "startOffset": 60, "endOffset": 77}, {"referenceID": 42, "context": "ASP has been applied to several problems related to Natural Language Processing, see for example (Mitra and Baral, 2016; Sch\u00fcller, 2013, 2014, 2016; Schwitter, 2012; Sharma et al., 2015).", "startOffset": 97, "endOffset": 186}, {"referenceID": 64, "context": "ASP has been applied to several problems related to Natural Language Processing, see for example (Mitra and Baral, 2016; Sch\u00fcller, 2013, 2014, 2016; Schwitter, 2012; Sharma et al., 2015).", "startOffset": 97, "endOffset": 186}, {"referenceID": 66, "context": "ASP has been applied to several problems related to Natural Language Processing, see for example (Mitra and Baral, 2016; Sch\u00fcller, 2013, 2014, 2016; Schwitter, 2012; Sharma et al., 2015).", "startOffset": 97, "endOffset": 186}, {"referenceID": 23, "context": "An overview of applications of ASP in general can be found in (Erdem et al., 2016).", "startOffset": 62, "endOffset": 82}, {"referenceID": 40, "context": "These models are often pure Machine Learning (ML) estimators without any rule components (Manning and Sch\u00fctze, 1999).", "startOffset": 89, "endOffset": 116}, {"referenceID": 21, "context": "Some popular classifiers used for processing natural language include Naive Bayes, Decision Trees, Neural Networks, and Support Vector Machines (SVMs) (Dumais et al., 1998).", "startOffset": 151, "endOffset": 172}, {"referenceID": 58, "context": "Consider the following example ILP instance (M,E,B) (Ray, 2009).", "startOffset": 52, "endOffset": 63}, {"referenceID": 29, "context": "Quite a few surveys (Gulwani et al., 2015; Kitzelmann, 2009; Muggleton et al., 2012) mention about the systems and applications of ILP in interdisciplinary areas.", "startOffset": 20, "endOffset": 84}, {"referenceID": 34, "context": "Quite a few surveys (Gulwani et al., 2015; Kitzelmann, 2009; Muggleton et al., 2012) mention about the systems and applications of ILP in interdisciplinary areas.", "startOffset": 20, "endOffset": 84}, {"referenceID": 50, "context": "Quite a few surveys (Gulwani et al., 2015; Kitzelmann, 2009; Muggleton et al., 2012) mention about the systems and applications of ILP in interdisciplinary areas.", "startOffset": 20, "endOffset": 84}, {"referenceID": 65, "context": "The foundations of ILP can be found in research by Plotkin (Plotkin, 1970, 1971), Shapiro (Shapiro, 1983) and Sammut and Banerji (Sammut and Banerji, 1986).", "startOffset": 90, "endOffset": 105}, {"referenceID": 59, "context": "The foundations of ILP can be found in research by Plotkin (Plotkin, 1970, 1971), Shapiro (Shapiro, 1983) and Sammut and Banerji (Sammut and Banerji, 1986).", "startOffset": 129, "endOffset": 155}, {"referenceID": 44, "context": "The founding paper of Muggleton (Muggleton, 1991) led to the launch of the first international workshop on ILP.", "startOffset": 32, "endOffset": 49}, {"referenceID": 45, "context": "At the beginning, ILP was associated with the introduction of foundational theoretical concepts which included Inverse Resolution (Muggleton, 1995; Muggleton and Buntine, 1992) and Predicate Invention (Muggleton, 1991; Muggleton and Buntine, 1992).", "startOffset": 130, "endOffset": 176}, {"referenceID": 48, "context": "At the beginning, ILP was associated with the introduction of foundational theoretical concepts which included Inverse Resolution (Muggleton, 1995; Muggleton and Buntine, 1992) and Predicate Invention (Muggleton, 1991; Muggleton and Buntine, 1992).", "startOffset": 130, "endOffset": 176}, {"referenceID": 44, "context": "At the beginning, ILP was associated with the introduction of foundational theoretical concepts which included Inverse Resolution (Muggleton, 1995; Muggleton and Buntine, 1992) and Predicate Invention (Muggleton, 1991; Muggleton and Buntine, 1992).", "startOffset": 201, "endOffset": 247}, {"referenceID": 48, "context": "At the beginning, ILP was associated with the introduction of foundational theoretical concepts which included Inverse Resolution (Muggleton, 1995; Muggleton and Buntine, 1992) and Predicate Invention (Muggleton, 1991; Muggleton and Buntine, 1992).", "startOffset": 201, "endOffset": 247}, {"referenceID": 56, "context": "A number of ILP systems were developed along with learning about the theoretical concepts of ILP such as FOIL (Quinlan, 1990) and Golem (Muggleton et al.", "startOffset": 110, "endOffset": 125}, {"referenceID": 45, "context": "The widely-used ILP system Progol (Muggleton, 1995) introduced a new logically-based approach to refinement graph search of the hypothesis space based on inverting the entailment relation.", "startOffset": 34, "endOffset": 51}, {"referenceID": 43, "context": "Integrating bottom-up and top-down searches, incorporating predicate invention, eliminating the need for explicit negative examples and allowing restricted use of cuts helps in solving these issues (Mooney, 1996).", "startOffset": 198, "endOffset": 212}, {"referenceID": 16, "context": "Probabilistic ILP (PILP) also gained popularity (Cussens, 2001a; De Raedt and Kersting, 2008; Muggleton et al., 1996), its Prolog-based systems such as PRISM (Sato et al.", "startOffset": 48, "endOffset": 117}, {"referenceID": 60, "context": ", 1996), its Prolog-based systems such as PRISM (Sato et al., 2005) and FAM (Cussens, 2001b) separate the actual learning of the logic program from the probabilistic parameters estimation of the individual clauses.", "startOffset": 48, "endOffset": 67}, {"referenceID": 17, "context": ", 2005) and FAM (Cussens, 2001b) separate the actual learning of the logic program from the probabilistic parameters estimation of the individual clauses.", "startOffset": 16, "endOffset": 32}, {"referenceID": 47, "context": "However in practice, learning the structure and parameters of probabilistic logic representation simultaneously has proven to be a challenge (Muggleton, 2002).", "startOffset": 141, "endOffset": 158}, {"referenceID": 53, "context": "Meta-interpretive learning (MIL) (Muggleton et al., 2014) is a recent ILP method which learns recursive definitions using Prolog and ASP-based declarative representations.", "startOffset": 33, "endOffset": 57}, {"referenceID": 58, "context": "The eXtended Hybrid Abductive Inductive Learning system (XHAIL) is an ILP approach based on ASP that generalises techniques of language and search bias from Horn clauses to normal logic programs with full usage of NAF (Ray, 2009).", "startOffset": 218, "endOffset": 229}, {"referenceID": 30, "context": "Like its predecessor system Hybrid Abductive Inductive Learning (HAIL) which operated on Horn clauses, XHAIL is based on Abductive Logic Programming (ALP) (Kakas et al., 1992), we give more details on XHAIL in Section 4.", "startOffset": 155, "endOffset": 175}, {"referenceID": 31, "context": "The Incremental Learning of Event Definitions (ILED) algorithm (Katzouris et al., 2015) relies on Abductive-Inductive learning and comprises of a scalable clause refinement methodology based on a compressive summarization of clause coverage in a stream of examples.", "startOffset": 63, "endOffset": 87}, {"referenceID": 35, "context": "The Inductive Learning of Answer Set Programs approach (ILASP) is an extension of the notion of learning from answer sets (Law et al., 2014).", "startOffset": 122, "endOffset": 140}, {"referenceID": 36, "context": "ILASP2 (Law et al., 2015) extends the hypothesis space of ILASP with choice rules and weak constraints.", "startOffset": 7, "endOffset": 25}, {"referenceID": 46, "context": "ILP should produce a better ratio between breadth of coverage and depth of analysis (Muggleton, 1999).", "startOffset": 84, "endOffset": 101}, {"referenceID": 35, "context": "ILP has been applied to the field of NLP successfully; it has not only been shown to have higher accuracies than various other ML approaches in learning the past tense of English but also shown to be capable of learning accurate grammars which translate sentences into deductive database queries (Law et al., 2014).", "startOffset": 296, "endOffset": 314}, {"referenceID": 70, "context": "Except for one early application (Wirth, 1989) no application of ILP methods surfaced until the system CHILL (Mooney, 1996) was developed which learned a shift-reduce parser in Prolog from a training corpus of sentences paired with the desired parses by learning control rules and uses ILP to learn control strategies within this framework.", "startOffset": 33, "endOffset": 46}, {"referenceID": 43, "context": "Except for one early application (Wirth, 1989) no application of ILP methods surfaced until the system CHILL (Mooney, 1996) was developed which learned a shift-reduce parser in Prolog from a training corpus of sentences paired with the desired parses by learning control rules and uses ILP to learn control strategies within this framework.", "startOffset": 109, "endOffset": 123}, {"referenceID": 71, "context": "CHILL was also used for parsing database queries to automate the construction of a natural language interface (Zelle and Mooney, 1996) and helped in demonstrating its ability to learn semantic mappings as well.", "startOffset": 110, "endOffset": 134}, {"referenceID": 72, "context": "An extension of CHILL, CHILLIN (Zelle et al., 1994) was used along with an extension of FOIL, mFOIL (Tang and Mooney, 2001) for semantic parsing.", "startOffset": 31, "endOffset": 51}, {"referenceID": 67, "context": ", 1994) was used along with an extension of FOIL, mFOIL (Tang and Mooney, 2001) for semantic parsing.", "startOffset": 56, "endOffset": 79}, {"referenceID": 36, "context": "ASP expresses preferences through weak constraints and may also contain weak constraints or optimisation statements which impose an ordering on the answer sets (Law et al., 2015).", "startOffset": 160, "endOffset": 178}, {"referenceID": 42, "context": "The system of Mitra and Baral (Mitra and Baral, 2016) uses ASP as primary knowledge representation and reasoning language to address the task of Question Answering.", "startOffset": 30, "endOffset": 53}, {"referenceID": 42, "context": "After consulting the authors of (Mitra and Baral, 2016) we learned that they had the same issues and used XHAIL, therefore we also opted to base our research on XHAIL due to it being the most robust tool for our task in comparison to the others.", "startOffset": 32, "endOffset": 55}, {"referenceID": 30, "context": "Initially the examples E plus background knowledge B are transformed into a theory of Abductive Logic Programming (Kakas et al., 1992).", "startOffset": 114, "endOffset": 134}, {"referenceID": 26, "context": "XHAIL integrates version 3 of Gringo (Gebser et al., 2011) and Clasp (Gebser et al.", "startOffset": 37, "endOffset": 58}, {"referenceID": 27, "context": ", 2011) and Clasp (Gebser et al., 2012b) which are both quite outdated.", "startOffset": 18, "endOffset": 40}, {"referenceID": 6, "context": "In particular Clasp in this version does not support three important improvements that have been found for ASP optimisation: (i) unsat-core optimisation (Andres et al., 2012), (ii) stratification for obtaining suboptimal answer sets (Alviano et al.", "startOffset": 153, "endOffset": 174}, {"referenceID": 5, "context": ", 2012), (ii) stratification for obtaining suboptimal answer sets (Alviano et al., 2015b; Ans\u00f3tegui et al., 2013), and (iii) unsat-core shrinking (Alviano and Dodaro, 2016).", "startOffset": 66, "endOffset": 113}, {"referenceID": 7, "context": ", 2012), (ii) stratification for obtaining suboptimal answer sets (Alviano et al., 2015b; Ans\u00f3tegui et al., 2013), and (iii) unsat-core shrinking (Alviano and Dodaro, 2016).", "startOffset": 66, "endOffset": 113}, {"referenceID": 2, "context": ", 2013), and (iii) unsat-core shrinking (Alviano and Dodaro, 2016).", "startOffset": 40, "endOffset": 66}, {"referenceID": 24, "context": "We predict chunks using our learned hypothesis and facts from preprocessing, using the Clingo (Gebser et al., 2008) ASP solver.", "startOffset": 94, "endOffset": 115}, {"referenceID": 1, "context": "An example sentence in the SemEval iSTS dataset (Agirre et al., 2016) is as follows.", "startOffset": 48, "endOffset": 69}, {"referenceID": 41, "context": "Stanford CoreNLP tools (Manning et al., 2014) are used for tokenisations and POS-tagging of the input.", "startOffset": 23, "endOffset": 45}, {"referenceID": 9, "context": "Using a shallow parser (Bohnet et al., 2013) we obtain the dependency relations for the sentences.", "startOffset": 23, "endOffset": 44}, {"referenceID": 1, "context": "We are using the datasets from the SemEval 2016 iSTS Task 2 (Agirre et al., 2016), which included two separate files containing sentence pairs.", "startOffset": 60, "endOffset": 81}, {"referenceID": 57, "context": "The Images dataset was a collection of captions obtained from the Flickr dataset (Rashtchian et al., 2010).", "startOffset": 81, "endOffset": 106}, {"referenceID": 26, "context": "5 (Gebser et al., 2011) and we use WASP version 2 (Git hash a44a95) (Alviano et al.", "startOffset": 2, "endOffset": 23}, {"referenceID": 4, "context": ", 2011) and we use WASP version 2 (Git hash a44a95) (Alviano et al., 2015a) configured to use unsat-core optimisation with disjunctive core partitioning, core trimming, a budget of 30 seconds for computing the first answer set and for shrinking unsatisfiable cores with progressive shrinking strategy.", "startOffset": 52, "endOffset": 75}, {"referenceID": 22, "context": "There are even more powerful methods for proving significance of results such as bootstrap sampling (Efron and Tibshirani, 1986), however these methods require markedly higher computational effort in experiments and our experiments already show significance with the t-test.", "startOffset": 100, "endOffset": 128}, {"referenceID": 1, "context": "State-of-the-art comparison Table 2 shows a comparison of our results with the baseline and the three best systems from the chunking subtask of Task 2 from SemEval2016 Task2 (Agirre et al., 2016): DTSim (Banjade et al.", "startOffset": 174, "endOffset": 195}, {"referenceID": 8, "context": ", 2016): DTSim (Banjade et al., 2016), FBK-HLT-NLP (Magnolini et al.", "startOffset": 15, "endOffset": 37}, {"referenceID": 39, "context": ", 2016), FBK-HLT-NLP (Magnolini et al., 2016) and runs 1 and 2 of IISCNLP (Tekumalla and Jat, 2016).", "startOffset": 21, "endOffset": 45}, {"referenceID": 68, "context": ", 2016) and runs 1 and 2 of IISCNLP (Tekumalla and Jat, 2016).", "startOffset": 36, "endOffset": 61}, {"referenceID": 32, "context": "We also compare with results of our own system \u2018Inspire-Manual\u2019 (Kazmi and Sch\u00fcller, 2016).", "startOffset": 64, "endOffset": 90}, {"referenceID": 14, "context": "\u2022 The baseline makes use of the automatic probabilistic chunker from the IXA-pipeline which provides Perceptron models (Collins, 2002) for chunking and is trained on CONLL2000 corpora and corrected manually,", "startOffset": 119, "endOffset": 134}, {"referenceID": 18, "context": "\u2022 FBK-HLT-NLP obtains chunks using a Python implementation of MBSP chunker which uses a Memory-based part-of-speech tagger generator (Daelemans et al., 1996),", "startOffset": 133, "endOffset": 157}, {"referenceID": 0, "context": "\u2022 Inspire-Manual (our previous system) makes use of manually set chunking rules (Abney, 1991) using ASP (Kazmi and Sch\u00fcller, 2016).", "startOffset": 80, "endOffset": 93}, {"referenceID": 32, "context": "\u2022 Inspire-Manual (our previous system) makes use of manually set chunking rules (Abney, 1991) using ASP (Kazmi and Sch\u00fcller, 2016).", "startOffset": 104, "endOffset": 130}, {"referenceID": 29, "context": "However, in other application domains such as learning to interpret input data from user examples (Gulwani et al., 2015), a perfect fit to the input data might be desired and required.", "startOffset": 98, "endOffset": 120}, {"referenceID": 67, "context": "Note that pruning examples to learn from inconsistent data as done by Tang and Mooney (Tang and Mooney, 2001) is not necessary for our approach.", "startOffset": 86, "endOffset": 109}, {"referenceID": 67, "context": "ILP has been applied to a variety of NLP and other problems such as parsing (Tang and Mooney, 2001; Zelle and Mooney, 1996), automatic construction of biological knowledge bases from scientific abstracts (Craven and Kumlien, 1999), automatic scientific discovery (King et al.", "startOffset": 76, "endOffset": 123}, {"referenceID": 71, "context": "ILP has been applied to a variety of NLP and other problems such as parsing (Tang and Mooney, 2001; Zelle and Mooney, 1996), automatic construction of biological knowledge bases from scientific abstracts (Craven and Kumlien, 1999), automatic scientific discovery (King et al.", "startOffset": 76, "endOffset": 123}, {"referenceID": 15, "context": "ILP has been applied to a variety of NLP and other problems such as parsing (Tang and Mooney, 2001; Zelle and Mooney, 1996), automatic construction of biological knowledge bases from scientific abstracts (Craven and Kumlien, 1999), automatic scientific discovery (King et al.", "startOffset": 204, "endOffset": 230}, {"referenceID": 33, "context": "ILP has been applied to a variety of NLP and other problems such as parsing (Tang and Mooney, 2001; Zelle and Mooney, 1996), automatic construction of biological knowledge bases from scientific abstracts (Craven and Kumlien, 1999), automatic scientific discovery (King et al., 2004), and in Microsoft Excel Gulwani et al.", "startOffset": 263, "endOffset": 282}, {"referenceID": 15, "context": "ILP has been applied to a variety of NLP and other problems such as parsing (Tang and Mooney, 2001; Zelle and Mooney, 1996), automatic construction of biological knowledge bases from scientific abstracts (Craven and Kumlien, 1999), automatic scientific discovery (King et al., 2004), and in Microsoft Excel Gulwani et al. (2015) where users can specify data extraction rules using examples.", "startOffset": 205, "endOffset": 329}, {"referenceID": 10, "context": "We provide the modified XHAIL system in a public repository fork (Bragaglia and Sch\u00fcller, 2016).", "startOffset": 65, "endOffset": 95}], "year": 2017, "abstractText": "Inductive Logic Programming (ILP) combines rule-based and statistical artificial intelligence methods, by learning a hypothesis comprising a set of rules given background knowledge and constraints for the search space. We focus on extending the XHAIL algorithm for ILP which is based on Answer Set Programming and we evaluate our extensions using the Natural Language Processing application of sentence chunking. With respect to processing natural language, ILP can cater for the constant change in how we use language on a daily basis. At the same time, ILP does not require huge amounts of training examples such as other statistical methods and produces interpretable results, that means a set of rules, which can be analysed and tweaked if necessary. As contributions we extend XHAIL with (i) a pruning mechanism within the hypothesis generalisation algorithm which enables learning from larger datasets, (ii) a better usage of modern solver technology using recently developed optimisation methods, and (iii) a time budget that permits the usage of suboptimal results. We evaluate these improvements on the task of sentence chunking using three datasets from a recent SemEval competition. Results show that our improvements allow for learning on bigger datasets with results that are of similar quality to state-of-the-art systems on the same task. Moreover, we compare the hypotheses obtained on datasets to gain insights on the structure of each dataset.", "creator": "LaTeX with hyperref package"}}}