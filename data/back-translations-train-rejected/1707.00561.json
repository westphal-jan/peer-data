{"id": "1707.00561", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2017", "title": "Identifying hazardousness of sewer pipeline gas mixture using classification methods: a comparative study", "abstract": "In this work, we formulated a real-world problem related to sewer pipeline gas detection using the classification-based approaches. The primary goal of this work was to identify the hazardousness of sewer pipeline to offer safe and non-hazardous access to sewer pipeline workers so that the human fatalities, which occurs due to the toxic exposure of sewer gas components, can be avoided. The dataset acquired through laboratory tests, experiments, and various literature sources was organized to design a predictive model that was able to identify/classify hazardous and non-hazardous situation of sewer pipeline. To design such prediction model, several classification algorithms were used and their performances were evaluated and compared, both empirically and statistically, over the collected dataset. In addition, the performances of several ensemble methods were analyzed to understand the extent of improvement offered by these methods. The result of this comprehensive study showed that the instance-based learning algorithm performed better than many other algorithms such as multilayer perceptron, radial basis function network, support vector machine, reduced pruning tree. Similarly, it was observed that multi-scheme ensemble approach enhanced the performance of base predictors.", "histories": [["v1", "Tue, 16 May 2017 08:57:46 GMT  (1221kb,D)", "http://arxiv.org/abs/1707.00561v1", null]], "reviews": [], "SUBJECTS": "cs.NE cs.AI", "authors": ["varun kumar ojha", "paramartha dutta", "atal chaudhuri"], "accepted": false, "id": "1707.00561"}, "pdf": {"name": "1707.00561.pdf", "metadata": {"source": "CRF", "title": "Identifying Hazardousness of Sewer-Pipeline Gas-Mixture using Classification Methods A Comparative Study", "authors": ["Varun Kumar Ojha", "Atal Chaudhuri"], "emails": ["varun.kumar.ojha@vsb.cz", "paramartha.dutta@gmail.com", "atalc23@gmail.com"], "sections": [{"heading": null, "text": "V. K. Ojha IT4Innovations, VS-B Ostrava University of Technology, Ostrava, Czech Republic and Faculty of Computer Science & Systems Sciences, University of Jadavpur, Calcutta, India Email: varun.kumar.ojha @ vsb.czP. Dutta Faculty of Computer Science & Systems Sciences, University of Visva-Bharati, India Email: paramartha.dutta @ gmail.comA Chaudhuri Faculty of Computer Science & Engineering, University of Jadavpur, Kolkata, India Email: atalc23 @ gmail.com Neural Computing and Applications DOI: 10.1007 / s00521-016-2443-0ar Xiv: 170 7.00 561v 1 [cs.N E] 16 May 201 7Keywords Sewer Gas Detection \u00b7 Neural Network \u00b7 Classification \u00b7 KS-Test"}, {"heading": "1 Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2 Methodology", "text": "This year, it has come to the point where it will be able to take the lead, \"he said.\" We've never lost so much time as this year, \"he said.\" We've never lost so much time, \"he said.\" We've never lost so much time, \"he said.\" We've never lost so much time, \"he said.\" We've never lost so much time, \"he said."}, {"heading": "2.3.1 Network Based Classifiers", "text": "Multilayer Perceptron (MLP) is a computational model that mimics the human brain and learns from the environment, i.e. from data. In our work, we used three-layer MLP, in which layers are input layer, hidden layer, and output layer [38]. Radial Base Function Network (RBF) is a special class of MLP, in which inputs are mapped to a hidden layer consisting of a basic radial function that performs the nonlinear mapping of the input to a hidden layer [39]. Support Vector Machine (SVM) is a supervised learning computer model that maps input to a high-dimensional feature space using a kernel trick. Therefore, nonlinear separable patterns in the input space are classified linearly on a high-dimensional feature space [40]."}, {"heading": "2.3.2 Tree Based Classifiers", "text": "Reduced pruning tree (REP) is a tree-based classification method in which a tree-like structure is developed to predict the target class based on the input variables [41,42]. Specifically, the leaves of the tree provide the decision of the class based on the combination of the input characteristics represented by the branches of the tree. REP tree is a decision tree in which the size of the tree is reduced by the cutting of inefficient branches [43]. The Naive Bayes tree (NBT) is a special class of decision trees in which the leaf nodes of the decision tree providing the decision on the class are replaced by a Naive Bayes classifier which decides the class designation based on the characteristics and the threshold learned [44]. Logistic Model Trees (LMT) are similar to NBT, which perform the conversion of leaves of a decision tree into a logistic regression node."}, {"heading": "2.3.3 Rule Based Classifiers", "text": "Decision Table (DT) is a simple representation of the data in a tabular system in which the decision is made on the basis of the matching characteristics or searched in a decision table. If the search succeeds, the majority class name is returned, otherwise, the majority class name of the entire data set is returned as a decision for unlabeled data [48].PART is a rule-based classification method based on sub-decision trees that generate a list of rules that are then used to predict unknown data instances. Rules are created on the basis of the sub-decision tree, which divides data sets into subsets until the entire data set is exhausted to form nodes and leaf nodes of the tree [49].Majority predictor (Zero R) is the simplest possible form of the classification method. It is based on the majority name into a data set. Simply put, it always says the majority class."}, {"heading": "2.3.4 Instance Based Classifiers", "text": "Instance-Based Learning (IBK) provides the concept description, which is the primary output of an IBK algorithm. It is a function that maps an instance to a category (class name). The concept description function is updated based on a training process that includes two functions: similarity and classification. The similarity function calculates the similarity between the training instances and the pre-stored instances and returns a numerical value. Subsequently, the classification function returns class names to the instances based on the results of the similarity function. Accordingly, the concept description is updated [50].K * (K Star) is an instance-based learner that uses an entropy-based similarity matching function to search / match test instances with the learned instances [51].Locally weighted learning (LWL). In locally weighted learning, the prediction models may be created at local points in a dataset or a specific point, rather than an entire model for the data set."}, {"heading": "2.3.5 Ensemble Methods", "text": "In this paper, we have tried to use different prediction methods for interaction. In order for an ensemble to perform well, we have to consider two things: the accuracy of the predictors and the diversity among the predictors. [54] For example, bagging gets diversity by bootstrapping dataset, AddBoost combines several weak predictors, Random Subspace gets diversity by splitting the trait space, Random Committee gets diversity by creating predictors using different random seeds, and Rotation Wald gets diversity by splitting and extracting trait analyses. Similarly, we combine multiple predictors in multi-scheme and choice scheme to maintain diversity. Here, we describe the ensemble methods as consequences.Bagging creates multiple copies of the same predictor. Each copy of the predictor learns a different replica of the learning set that is created from the complete training set by combining the boot method with plurality decision."}, {"heading": "3 Experimental Framework and Results", "text": "The second objective of the experiment was to obtain results for the analysis of classifiers (predictors). Accordingly, the results of the classifiers were collected. Table 3 represents the parameter setting of the selected classifiers. To evaluate the classifiers, we repeated our experiments 10 times. Finally, the results were compared on an empirical and statistical basis (Kolmogorov-Smirnov test) evaluation. We used WEKA [61] and MATLAB tools for the purpose of our experiments. We organized the experimental results into three parts, as presented in Table 4. The first part in the table describes the categorical performance of the classifiers. Hence, the performance of the category of classifiers was evaluated."}, {"heading": "4 Discussions", "text": "This year, the time has come for such a process to take place in the first half of the year, in which such a process takes place."}, {"heading": "5 Conclusion", "text": "In this paper, we investigated a real problem related to classification, simplifying the approach by offering a binary solution to the problem. We investigated the problem related to detecting the hazardousness of a sewer pipe environment. This is a very critical problem because it is related to the safety of the people who must operate under the toxic environment of the sewer pipe environment. Normally, a sewer pipe environment contains a mixture of toxic gases. Therefore, we collected samples from sewer pipes from different locations. We then examined these samples to identify data samples for our experiments. Finally, we prepared a large data set by using gas sensor responses from laboratory tests, literature and scaled the reactions of the collected gas sensors to form a dataset in which non-hazardous samples were labeled with 0 and hazardous samples were labeled with 1. Finally, we applied 21 different classifiers over the identified dataset and their empirical and statistical performance."}], "references": [{"title": "the insidious foe\u201d\u2013sewer gas,", "author": ["J. Whorton"], "venue": "Western Journal of Medicine, vol. 175,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "Sewer gases in the home,", "author": ["N. Gromicko"], "venue": "http://www.nachi.org/sewer-gaseshome.html", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Deaths in the drains,", "author": ["T. Hindu"], "venue": "http://www.thehindu.com/opinion/oped/deaths-in-the-drains/article5868090.ece?homepage=true., Accessed on 15 Dec", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Dying in the gutters,", "author": ["S. Anand"], "venue": "Tehelka Magazine,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Provide safety gear to sewer workers who enter manholes, says court,", "author": ["T. Hindu"], "venue": "http://www.thehindu.com/todays-paper/tp-national/provide-safety-gear-tosewer-workers-who-enter-manholes-says-court/article2228688.ece, Accessed on", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "No free lunch theorems for optimization,", "author": ["D.H. Wolpert", "W.G. Macready"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1997}, {"title": "A mixed gas sensor system based on thin film saw sensor array and neural network,", "author": ["J. Li"], "venue": "Proceedings of the Twelfth Southern Biomedical Engineering Conference,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1993}, {"title": "On the design issue of intelligent electronic nose system,", "author": ["A. Srivastava", "S. Srivastava", "K. Shukla"], "venue": "Proceedings of IEEE International Conference on Industrial Technology 2000.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2000}, {"title": "Multicomponent gas mixture analysis using a single tin oxide sensor and dynamic pattern recognition,", "author": ["E. Llobet", "R. Ionescu", "S. Al-Khalifa", "J. Brezmes", "X. Vilanova", "X. Correig", "N. Barsan", "J.W. Gardner"], "venue": "IEEE Sensors Journal,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2001}, {"title": "Micro gas sensor array with neural network for recognizing combustible leakage gases,", "author": ["D.-S. Lee", "S.-W. Ban", "M. Lee", "D.-D. Lee"], "venue": "IEEE Sensors Journal,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "A spiking neural network for gas discrimination using a tin oxide sensor array,", "author": ["M. Ambard", "B. Guo", "D. Martinez", "A. Bermak"], "venue": "IEEE International Symposium on Electronic Design, Test and Applications. IEEE,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Dibi, \u201cA novel neural network-based technique for smart gas sensors operating in a dynamic environment,", "author": ["Z.H. Baha"], "venue": "Sensors, vol. 9,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Application of electronic nose in gas mixture quantitative detection,", "author": ["W. Pan", "N. Li", "P. Liu"], "venue": "IEEE International Conference on Network Infrastructure and Digital Content. IEEE,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Knowledge-based genetic algorithms data fusion and its application in mine mixed-gas detection,", "author": ["Q. Zhang", "H. Li", "Z. Tang"], "venue": "Chinese Control and Decision Conference (CCDC). IEEE,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "The estimation of hazardous gas release rate using optical sensor and neural network,", "author": ["W. So", "J. Koo", "D. Shin", "E.S. Yoon"], "venue": "Computer Aided Chemical Engineering,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Performance analysis of neuro genetic algorithm applied on detecting proportion of components in manhole gas mixture,", "author": ["V.K. Ojha", "P. Dutta", "H. Saha"], "venue": "International Journal of Artificial Intelligence \\& Applications,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "Performance analysis of neuro swarm optimization algorithm applied on detecting proportion of components in manhole gas mixture,", "author": ["V.K. Ojha", "P. Dutta"], "venue": "Artificial Intelligence Research,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Convergence analysis of backpropagation algorithm for designing an intelligent system for sensing manhole gases,", "author": ["V.K. Ojha", "P. Dutta", "A. Chaudhuri", "H. Saha"], "venue": "Hybrid Soft Computing Approaches. Springer India,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "Conjugate gradient trained neural network for intelligent sensing of manhole gases to avoid human fatality,", "author": ["P. Dutta", "V.K. Ojha"], "venue": "Advances in Secure Computing, Internet Services, and Applications. IGI Global,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Understating continuous ant colony optimization for neural network training: A case study on intelligent sensing of manhole gas components,", "author": ["V.K. Ojha", "P. Dutta", "A. Chaudhuri", "H. Saha"], "venue": "International Journal of Hybrid Intelligent Systems,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2016}, {"title": "Sensor array for manhole gas analysis,", "author": ["S. Ghosh", "A. Roy", "S. Singh", "H. Saha", "V.K. Ojha", "P. Dutta"], "venue": "in 1st International Symposium on Physics and Technology of Sensors (ISPTS). IEEE,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "Portable sensor array system for intelligent recognizer of manhole gas,", "author": ["S. Ghosh", "H. Saha", "C. RoyChaudhuri", "V.K. Ojha", "P. Dutta"], "venue": "Sixth International Conference on Sensing Technology (ICST)", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "Sensitivity to NO2 and cross-sensitivity analysis to NH3, ethanol and humidity of carbon nanotubes thin film prepared by PECVD,", "author": ["C. Cantalini", "L. Valentini", "I. Armentano", "L. Lozzi", "J. Kenny", "S. Santucci"], "venue": "Sensors and Actuators B: Chemical,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2003}, {"title": "Development of a micromachined hazardous gas sensor array,", "author": ["K.D. Mitzner", "J. Sternhagen", "D.W. Galipeau"], "venue": "Sensors and Actuators B: Chemical,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2003}, {"title": "Exposure limits related to air quality and risk assessment,", "author": ["K.J. Donham"], "venue": "Iowa Concentrated Animal Feeding Operations Air Quality Study,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2002}, {"title": "Human health effects from exposure to low-level concentrations of hydrogen sulfide,", "author": ["S. Simonton"], "venue": "Occupational Health & Safety,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2007}, {"title": "New insight into panic attacks: Carbon dioxide is the culprit,", "author": ["G. Shilpa"], "venue": "Journal of Young Investigators,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2007}, {"title": "Twenty questions and answers about the ozone layer: 2010 update,", "author": ["D.W. Fahey", "M.I. Hegglin"], "venue": "Scientific assessment of ozone depletion,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2010}, {"title": "Predicting the future: A connectionist approach,", "author": ["A.S. Weigend", "B.A. Huberman", "D.E. Rumelhart"], "venue": "International journal of neural systems,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 1990}, {"title": "Multivariable functional interpolation and adaptive networks,", "author": ["D. Lowe", "D. Broomhead"], "venue": "Complex System,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 1988}, {"title": "Classification and regression trees,", "author": ["L. Olshen", "C.J. Stone"], "venue": "Wadsworth International Group,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1984}, {"title": "5: programs for machine learning", "author": ["J.R. Quinlan"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2014}, {"title": "The effects of pruning methods on the predictive accuracy of induced decision trees,", "author": ["F. Esposito", "D. Malerba", "G. Semeraro", "V. Tamma"], "venue": "Applied Stochastic Models in Business and Industry,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1999}, {"title": "A comparative study of reduced error pruning method in decision tree algorithms,", "author": ["W.N.H.W. Mohamed", "M.N.M. Salleh", "A.H. Omar"], "venue": "IEEE International Conference on Control System, Computing and Engineering (ICCSCE),", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2012}, {"title": "Estimation of the probability of an event as a function of several independent variables,", "author": ["S.H. Walker", "D.B. Duncan"], "venue": "Biometrika, vol", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 1967}, {"title": "The regression analysis of binary sequences,", "author": ["D.R. Cox"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological), pp", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 1958}, {"title": "Logistic model trees,", "author": ["N. Landwehr", "M. Hall", "E. Frank"], "venue": "Machine Learning,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2005}, {"title": "The power of decision tables,", "author": ["R. Kohavi"], "venue": "Machine Learning: ECML-95. Springer,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 1995}, {"title": "Generating accurate rule sets without global optimization,", "author": ["E. Frank", "I.H. Witten"], "venue": null, "citeRegEx": "49", "shortCiteRegEx": "49", "year": 1998}, {"title": "Instance-based learning algorithms,", "author": ["D.W. Aha", "D. Kibler", "M.K. Albert"], "venue": "Machine learning,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 1991}, {"title": "K*: An instance-based learner using an entropic distance measure,", "author": ["J.G. Cleary", "L.E. Trigg"], "venue": "Proceedings of the 12th International Conference on Machine learning,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 1995}, {"title": "Locally weighted naive bayes,", "author": ["E. Frank", "M. Hall", "B. Pfahringer"], "venue": "Proceedings of the Nineteenth conference on Uncertainty in Artificial Intelligence. Morgan Kaufmann Publishers Inc.,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2002}, {"title": "Locally weighted learning,", "author": ["C.G. Atkeson", "A.W. Moore", "S. Schaal"], "venue": "Artificial Intelligence Review,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 1997}, {"title": "Ensemble based systems in decision making,", "author": ["R. Polikar"], "venue": "IEEE Circuits and Systems Magazine,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2006}, {"title": "Bagging predictors,", "author": ["L. Breiman"], "venue": "Machine learning,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 1996}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting,", "author": ["Y. Freund", "R.E. Schapire"], "venue": "Journal of computer and system sciences,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 1997}, {"title": "The random subspace method for constructing decision forests,", "author": ["T.K. Ho"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 1998}, {"title": "Combining pattern classifiers: methods and algorithms", "author": ["L.I. Kuncheva"], "venue": null, "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": ", [1,2,3].", "startOffset": 2, "endOffset": 9}, {"referenceID": 1, "context": ", [1,2,3].", "startOffset": 2, "endOffset": 9}, {"referenceID": 2, "context": "Following this, an alarming number of human fatalities are reported each year by the newspapers and the other agencies [4,5,6].", "startOffset": 119, "endOffset": 126}, {"referenceID": 3, "context": "Following this, an alarming number of human fatalities are reported each year by the newspapers and the other agencies [4,5,6].", "startOffset": 119, "endOffset": 126}, {"referenceID": 4, "context": "In a judgment to a civil appeal number 5322 of 2011, the Supreme Court of India stated, \u201cthe State and its agencies/instrumentalities cannot absolve themselves of the responsibility to put in place effective mechanism for ensuring safety of the workers employed for maintaining and cleaning the sewage system [7].", "startOffset": 309, "endOffset": 312}, {"referenceID": 5, "context": "However, we must consider the \u201cNo-free-lunch theorem\u201d that suggests that some algorithms perform better on some problem and some on another [10].", "startOffset": 140, "endOffset": 144}, {"referenceID": 6, "context": "[11] reported a noticeable research work on the development and design of an electronic nose (E-NOSE) and gas detection system, where a neural network", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[12,13] proposed a design of intelligent ENOSE system using backpropagation (BP) and neuro-genetic approach.", "startOffset": 0, "endOffset": 7}, {"referenceID": 8, "context": "[14] presented a pattern recognition approach, based on the wallet transformation for gas mixture analysis using single tin-oxide sensor.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[15] illustrated uses of micro gas sensor array (GSA) combined with NN for recognizing combustible leakage gases.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[16] have demonstrated use of NN for gas discrimination using a tin-oxide GSA for the gases H2, CO and CH4.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "In [17], authors have illustrated a NN-based technique for developing a gas sensory system for sensing gases in a dynamic environment.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "[18] have shown several applications of E-NOSE.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[20] developed a knowledge-based genetic algorithm for detecting mixed gas in mines.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[21] proposed a system for estimation of hazardous gas release rate using optical sensor and NN-based technique.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[22, 23,24,25,26,27] offered a few methods such as neuro-genetic, neuro-swarm, ant-colony-based, neuro-simulated annealing, etc.", "startOffset": 0, "endOffset": 20}, {"referenceID": 16, "context": "[22, 23,24,25,26,27] offered a few methods such as neuro-genetic, neuro-swarm, ant-colony-based, neuro-simulated annealing, etc.", "startOffset": 0, "endOffset": 20}, {"referenceID": 17, "context": "[22, 23,24,25,26,27] offered a few methods such as neuro-genetic, neuro-swarm, ant-colony-based, neuro-simulated annealing, etc.", "startOffset": 0, "endOffset": 20}, {"referenceID": 18, "context": "[22, 23,24,25,26,27] offered a few methods such as neuro-genetic, neuro-swarm, ant-colony-based, neuro-simulated annealing, etc.", "startOffset": 0, "endOffset": 20}, {"referenceID": 19, "context": "[22, 23,24,25,26,27] offered a few methods such as neuro-genetic, neuro-swarm, ant-colony-based, neuro-simulated annealing, etc.", "startOffset": 0, "endOffset": 20}, {"referenceID": 20, "context": "Here, the fabricated and installed sensors were MiCS - 4514, MQ - 7, MQ - 136, MQ - 135, and MQ - 4 for gases NO2, CO, H2S, NH3, and CH4, respectively [28,29].", "startOffset": 151, "endOffset": 158}, {"referenceID": 21, "context": "Here, the fabricated and installed sensors were MiCS - 4514, MQ - 7, MQ - 136, MQ - 135, and MQ - 4 for gases NO2, CO, H2S, NH3, and CH4, respectively [28,29].", "startOffset": 151, "endOffset": 158}, {"referenceID": 22, "context": "The gas sensors used were sensitive to not only their target gases, but they were sensitive also to other gases in the gas-mixture [30,31].", "startOffset": 131, "endOffset": 138}, {"referenceID": 23, "context": "The gas sensors used were sensitive to not only their target gases, but they were sensitive also to other gases in the gas-mixture [30,31].", "startOffset": 131, "endOffset": 138}, {"referenceID": 13, "context": "25 - 5], [20 - 1000], [1 - 100], [10 - 300] and [300 - 10000] of the gases NO2, CO, H2S, NH3, and CH4, respectively.", "startOffset": 9, "endOffset": 20}, {"referenceID": 0, "context": "25 - 5], [20 - 1000], [1 - 100], [10 - 300] and [300 - 10000] of the gases NO2, CO, H2S, NH3, and CH4, respectively.", "startOffset": 22, "endOffset": 31}, {"referenceID": 5, "context": "25 - 5], [20 - 1000], [1 - 100], [10 - 300] and [300 - 10000] of the gases NO2, CO, H2S, NH3, and CH4, respectively.", "startOffset": 33, "endOffset": 43}, {"referenceID": 20, "context": "2 Laboratory-scale gas sensor array (GSA) [28,29]", "startOffset": 42, "endOffset": 49}, {"referenceID": 21, "context": "2 Laboratory-scale gas sensor array (GSA) [28,29]", "startOffset": 42, "endOffset": 49}, {"referenceID": 24, "context": "The safety limits of the manhole gases are as follows: safety limit of NH3 is between 25 ppm and 40 ppm [33], CO is in between 35 ppm and 100 ppm [34], H2S is in between 50 ppm and 100 ppm [35], CO2 is in between 5000 ppm and 8000 ppm [36] and CH4 is in between 5000 ppm and 10000 ppm [37].", "startOffset": 104, "endOffset": 108}, {"referenceID": 25, "context": "The safety limits of the manhole gases are as follows: safety limit of NH3 is between 25 ppm and 40 ppm [33], CO is in between 35 ppm and 100 ppm [34], H2S is in between 50 ppm and 100 ppm [35], CO2 is in between 5000 ppm and 8000 ppm [36] and CH4 is in between 5000 ppm and 10000 ppm [37].", "startOffset": 189, "endOffset": 193}, {"referenceID": 26, "context": "The safety limits of the manhole gases are as follows: safety limit of NH3 is between 25 ppm and 40 ppm [33], CO is in between 35 ppm and 100 ppm [34], H2S is in between 50 ppm and 100 ppm [35], CO2 is in between 5000 ppm and 8000 ppm [36] and CH4 is in between 5000 ppm and 10000 ppm [37].", "startOffset": 235, "endOffset": 239}, {"referenceID": 27, "context": "The safety limits of the manhole gases are as follows: safety limit of NH3 is between 25 ppm and 40 ppm [33], CO is in between 35 ppm and 100 ppm [34], H2S is in between 50 ppm and 100 ppm [35], CO2 is in between 5000 ppm and 8000 ppm [36] and CH4 is in between 5000 ppm and 10000 ppm [37].", "startOffset": 285, "endOffset": 289}, {"referenceID": 28, "context": "In our work, we used threelayered MLP, where layers are input layer, hidden layer, and output layer [38].", "startOffset": 100, "endOffset": 104}, {"referenceID": 29, "context": "Radial Basis Function Network (RBF) is a special class of MLP, where inputs are mapped onto a hidden layer that consists of radial basis function, which does the non-linear mapping of input to a hidden layer [39].", "startOffset": 208, "endOffset": 212}, {"referenceID": 30, "context": "Reduced pruning tree (REP) is a tree based classifier method, where a treelike structure is designed for predicting target class based on the input variables [41,42].", "startOffset": 158, "endOffset": 165}, {"referenceID": 31, "context": "Reduced pruning tree (REP) is a tree based classifier method, where a treelike structure is designed for predicting target class based on the input variables [41,42].", "startOffset": 158, "endOffset": 165}, {"referenceID": 32, "context": "REP tree is a decision tree, where the tree size is reduced by pruning inefficient branches [43].", "startOffset": 92, "endOffset": 96}, {"referenceID": 33, "context": "Naive Bayes tree (NBT) is a special class of decision tree, where the leaf nodes of decision tree that offer decision on the class is replaced by a Naive Bayes classifier, which decides the class label, based on the features and learned threshold [44].", "startOffset": 247, "endOffset": 251}, {"referenceID": 34, "context": "A logistic regression maps independent variables to categorical dependent variables using a logistic function [45,46].", "startOffset": 110, "endOffset": 117}, {"referenceID": 35, "context": "A logistic regression maps independent variables to categorical dependent variables using a logistic function [45,46].", "startOffset": 110, "endOffset": 117}, {"referenceID": 36, "context": "Hence, LMT is a simple idea, where nodes of a decision/classification tree are replaced by logistic regression model [47].", "startOffset": 117, "endOffset": 121}, {"referenceID": 37, "context": "On a successful search, the majority class label is returned, otherwise the majority class label of the entire dataset is returned as a decision for an unlabeled data [48].", "startOffset": 167, "endOffset": 171}, {"referenceID": 38, "context": "The rules are generated based on the partial decision tree, which splits dataset into subsets until the entire dataset gets exhausted to form nodes and leaf nodes of the tree [49].", "startOffset": 175, "endOffset": 179}, {"referenceID": 39, "context": "Accordingly, the concept description is updated [50].", "startOffset": 48, "endOffset": 52}, {"referenceID": 40, "context": "K\u2217 (K Star) is an instance-based learner that uses an entropy-based similarity matching function for searching/matching test instances to the learned instances [51].", "startOffset": 160, "endOffset": 164}, {"referenceID": 41, "context": "In this case, we use Decision Stamp, which is a single level decision tree model for prediction [52,53].", "startOffset": 96, "endOffset": 103}, {"referenceID": 42, "context": "In this case, we use Decision Stamp, which is a single level decision tree model for prediction [52,53].", "startOffset": 96, "endOffset": 103}, {"referenceID": 43, "context": "For an ensemble to perform well, we need to take into account two things which are accuracy of predictors and diversity among the predictors [54].", "startOffset": 141, "endOffset": 145}, {"referenceID": 44, "context": "Finally, the predictor\u2019s decision is combined using plurality voting method [55].", "startOffset": 76, "endOffset": 80}, {"referenceID": 45, "context": "Adaptive Boosting (AdaBoost) is an ensemble technique that combines several weak predictors and inaccurate rules to create an accurate predictor [56].", "startOffset": 145, "endOffset": 149}, {"referenceID": 46, "context": "Finally, the decision of each constructed predictors are combined using voting method [57].", "startOffset": 86, "endOffset": 90}, {"referenceID": 47, "context": "The voting scheme combines probability distribution of several chosen predictors/classifiers (or predictors available in a bag for making ensemble) using majority voting combination method [60].", "startOffset": 189, "endOffset": 193}, {"referenceID": 47, "context": "The multi-scheme ensemble approach uses a bag of predictors and selects the output class by selecting a predictor from the bag of predictors based on cross-validation performance of the predictors [60].", "startOffset": 197, "endOffset": 201}], "year": 2017, "abstractText": "In this work, we formulated a real-world problem related to sewerpipeline gas detection using the classification-based approaches. The primary goal of this work was to identify the hazardousness of sewer-pipeline to offer safe and non-hazardous access to sewer-pipeline workers so that the human fatalities, which occurs due to the toxic exposure of sewer gas components, can be avoided. The dataset acquired through laboratory tests, experiments, and various literature-sources were organized to design a predictive model that was able to identify/classify hazardous and non-hazardous situation of sewer-pipeline. To design such prediction model, several classification algorithms were used and their performances were evaluated and compared, both empirically and statistically, over the collected dataset. In addition, the performances of several ensemble methods were analyzed to understand the extent of improvement offered by these methods. The result of this comprehensive study showed that the instance-based-learning algorithm performed better than many other algorithms such as multi-layer perceptron, radial basis function network, support vector machine, reduced pruning tree, etc. Similarly, it was observed that multi-scheme ensemble approach enhanced the performance of base predictors. V. K. Ojha IT4Innovations, V\u0160B Technical University of Ostrava, Ostrava, Czech Republic and Dept. of Computer Science & Engineering, Jadavpur University, Kolkata, India E-mail: varun.kumar.ojha@vsb.cz P. Dutta Dept. of Computer & System Sciences, Visva-Bharati University, India E-mail: paramartha.dutta@gmail.com A Chaudhuri Dept. of Computer Science & Engineering, Jadavpur University, Kolkata, India E-mail: atalc23@gmail.com Neural Computing and Applications DOI: 10.1007/s00521-016-2443-0 ar X iv :1 70 7. 00 56 1v 1 [ cs .N E ] 1 6 M ay 2 01 7 2 Varun Kumar Ojha et al.", "creator": "LaTeX with hyperref package"}}}