{"id": "1708.04033", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Aug-2017", "title": "Deep Reinforcement Learning for High Precision Assembly Tasks", "abstract": "High precision assembly of mechanical parts requires accuracy exceeding the robot precision. Conventional part mating methods used in the current manufacturing requires tedious tuning of numerous parameters before deployment. We show how the robot can successfully perform a tight clearance peg-in-hole task through training a recurrent neural network with reinforcement learning. In addition to saving the manual effort, the proposed technique also shows robustness against position and angle errors for the peg-in-hole task. The neural network learns to take the optimal action by observing the robot sensors to estimate the system state. The advantages of our proposed method is validated experimentally on a 7-axis articulated robot arm.", "histories": [["v1", "Mon, 14 Aug 2017 08:32:30 GMT  (802kb,D)", "http://arxiv.org/abs/1708.04033v1", "Conference: Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Vancouver, Canada, September 24-28, 2017. Video:this https URL"], ["v2", "Fri, 22 Sep 2017 01:34:42 GMT  (802kb,D)", "http://arxiv.org/abs/1708.04033v2", "Conference: Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Vancouver, Canada, September 24-28, 2017. Video:this https URL"]], "COMMENTS": "Conference: Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Vancouver, Canada, September 24-28, 2017. Video:this https URL", "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["tadanobu inoue", "giovanni de magistris", "asim munawar", "tsuyoshi yokoya", "ryuki tachibana"], "accepted": false, "id": "1708.04033"}, "pdf": {"name": "1708.04033.pdf", "metadata": {"source": "CRF", "title": "Deep Reinforcement Learning for High Precision Assembly Tasks", "authors": ["Tadanobu Inoue", "Giovanni De Magistris", "Asim Munawar", "Tsuyoshi Yokoya", "Ryuki Tachibana"], "emails": ["ryuki}@jp.ibm.com", "Tsuyoshi.Yokoya@yaskawa.co.jp"], "sections": [{"heading": null, "text": "I. INTRODUCTIONIndustrial robots are increasingly being installed in various industries to handle advanced manufacturing methods and high-precision assembly tasks. The classic programming method is to teach the robot to perform industrial assembly tasks by defining key positions and movements using a control panel called \"Teach Pendant.\" Another common method is offline programming or simulation. This method can usually be tedious and time-consuming, but it can take longer than online programming, including the time needed to develop the simulation and testing on the robot. It is quite difficult to depict the real world, including environmental variations, with 100% accuracy in the simulation model. Therefore, this offline method is not sufficient for some industrial applications such as precision machining and flexible material handling."}, {"heading": "II. PROBLEM FORMULATION", "text": "A high-precision cylindrical pin-in-hole is chosen as the target task for force-controlled robot assembly. This task can be roughly divided into two main phases [4]: \u2022 Search: The robot places the pin-centre within the passage area of the borehole \u2022 Insert: The robot adjusts the orientation of the pin in relation to the orientation of the borehole and pushes the pin to the desired position. In this thesis, we study and learn these two phases separately."}, {"heading": "A. Search Phase", "text": "Although industrial robots have achieved a good level of accuracy, it is difficult to set peg and hole to a few tens of microns of precision by using a positioner. Visual Servoing isar Xiv: 170 8.04 033v 1 [cs.R O] 14 August 201 7also impractical due to the limited resolution of cameras or internal parts that are locked during assembly, for example in the case of cross-linking gears and splines in transmission. In this paper we use a common 6-axis force-torque sensor to learn the hole position in relation to the arrow position. Newman et al. [5] calculate the moments of sensors and interpret the current position of the path by mapping the moments to positions. Sharma et al. [4] use depth profile in addition to the rolling and pitch data to interpret the current position of the path. Although these approaches are shown in the simulation, it is difficult to generalize them for the world."}, {"heading": "III. REINFORCEMENT LEARNING WITH LONG SHORT TERM MEMORY", "text": "In this section we explain the RL algorithm to locate the hole. < < < < <"}, {"heading": "IV. EXPERIMENTS", "text": "The proposed capabilities are evaluated by using a 7-axis robotic arm. A 6-axis force-torque sensor and a gripper are connected to the final effect of the robot (Fig. 5 (a)). The nominal load of the force-torque sensor is 200 N for the force and 4 N m for the moment. The resolution of the force is 0.024 N. The gripper is designed to capture cylindrical cones with a diameter between 34 and 36 mm. In this paper we assume that the peg is already detected and in contact with the perforated plate. As shown in Figure 5, a 1D goniometer step is placed on the base plate to adjust the angle of this plate to the ground."}, {"heading": "A. Search Phase", "text": "In fact, it is such that it is a matter of a way in which it is about a way in which people are able to put themselves in the world, in which they are able to integrate themselves, and in which they are able to put themselves in the world, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they are able to put themselves in the world, in which they live, in which they are able to integrate themselves, and in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they"}, {"heading": "C. Results", "text": "In order to demonstrate the robustness of the proposed technique, we conduct experiments with pegs at different distances. We also perform tests with inclined perforated plates using a 1D goniometer step under the plate, the results of which are shown in the accompanying video (see https: / / youtu.be / b2pC78rBGH4). We perform the peg-in-hole task 100 times after learning to show the time performance of the learning method: \u2022 Case A: 3 mm initial offset, 10 micrometer distance and 0 percent inclined angle \u2022 Case B: 1 millimeter initial offset, 20 micrometer distance and 1.6 millimeter inclined angle Fig. 10 shows histograms of the execution time in two cases via search, insertion and total time. Fig. 10 (a) shows the distribution of the execution time over a larger area and is shifted further to the right than Fig. 10 (d). If the inclination angle is greater, the execution time is increased as the execution time must be extended for the implementation time."}, {"heading": "V. CONCLUSIONS AND FUTURE WORK", "text": "There are industrial adaptation operations that require very high precision. Classical robot programming techniques require a long set-up time to adjust the parameters due to the variations in the environment. In this paper, we propose an easy-to-implement approach to precise pig-in-hole tasks and validate their effectiveness by using a 7-axis articulated robot arm. Results show robustness to positioning and angular errors for a suitable task. In this paper, the high-precision adaptation task for each configuration is learned through online learning. In future work, we will collect experimental information from multiple robots in different configurations and upload it to a cloud server. A more general model will be learned on the cloud by using this data pool in stacks. We want to generalize the model so that it can handle different materials, robot manipulators, introduction angles and even different shapes."}, {"heading": "ACKNOWLEDGMENT", "text": "We are very grateful to Masaru Adachi at the Tsukuba Research Laboratory, Yaskawa Electric Corporation, Japan, for his helpful support of this work."}], "references": [{"title": "Reinforcement learning in robotics: A survey", "author": ["J. Kober", "J.A. Bagnell", "J. Peters"], "venue": "International Journal of Robotic Research, vol.32, no.11, pp.12381274", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large- Scale Data Collection", "author": ["S. Levine", "P. Pastor", "A. Krizhevsky", "D. Quillen"], "venue": "International Symposium on Experimental Robotics (ISER)", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours", "author": ["L. Pinto", "A. Gupta"], "venue": "IEEE International Conference on Robotics and Automation (ICRA)", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Intelligent and Environment- Independent Peg-In-Hole Search Strategies", "author": ["K. Sharma", "V. Shirwalkar", "P.K. Pal"], "venue": "International Conference on Control, Automation, Robotics and Embedded Systems (CARE)", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Interpretation of Force and Moment Signals for Compliant Peg-in-Hole Assembly", "author": ["W.S. Newman", "Y. Zhao", "Y.H. Pao"], "venue": "IEEE International Conference on Robotics and Automation", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "6D Frictional Contact for Rigid Bodies", "author": ["C. Bouchard", "M. Nesme", "M. Tournier", "B. Wang", "F. Faure", "P.G. Kry"], "venue": "Proceedings of Graphics Interface", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning Reactive Admittance Control", "author": ["V. Gullapalli", "R.A. Grupen", "A.G. Barto"], "venue": "IEEE International Conference on Robotics and Automation", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1992}, {"title": "A Neural Network Based Flexible Assembly Controller", "author": ["M.D. Majors", "R.J. Richards"], "venue": "Fourth International Conference on Artificial Neural Networks", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1995}, {"title": "Active Peg-in-hole of Chamferless Parts using Force/Moment Sensor", "author": ["I.W. Kim", "D.J. Lim", "K.I. Kim"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1999}, {"title": "Autonomous Alignment of Peg and Hole by Force/Torque Measurement for Robotic Assembly", "author": ["T. Tang", "H.C. Lin", "Y. Zhao", "W. Chen", "M. Tomizuka"], "venue": "IEEE International Conference on Automation Science and Engineering (CASE)", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Playing Atari with Deep Reinforcement Learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A. Graves", "I. Antonoglou", "D. Wierstra", "M. Riedmiller"], "venue": "NIPS Deep Learning Workshop", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Reinforcement Learning with Long Short-Term Memory", "author": ["B. Bakker"], "venue": "14th International Conference Neural Information Processing Systems (NIPS)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2001}, {"title": "Asynchronous Methods for Deep Reinforcement Learning", "author": ["V. Mnih", "A.P. Badia", "M. Mirza", "A. Graves", "T.P. Lillicrap", "T. Harley", "D. Silver", "K. Kavukcuoglu"], "venue": "International Conference on Machine Learning", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Continuous control with deep reinforcement learning", "author": ["T.P. Lillicrap", "J.J. Hunt", "A. Pritzel", "N. Heess", "T. Erez", "Y. Tassa", "D. Silver", "D. Wierstra"], "venue": "arXiv:1509.02971", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "For such systems, reinforcement learning (RL) algorithms can be utilized to enable a robot to learn new skills through trial and error using a process that mimics the way humans learn [1].", "startOffset": 184, "endOffset": 187}, {"referenceID": 1, "context": "Recent studies have shown the importance of RL for robotic grasping task using cameras and encoders [2][3], but none of these methods can be applied directly to high precision industrial applications.", "startOffset": 100, "endOffset": 103}, {"referenceID": 2, "context": "Recent studies have shown the importance of RL for robotic grasping task using cameras and encoders [2][3], but none of these methods can be applied directly to high precision industrial applications.", "startOffset": 103, "endOffset": 106}, {"referenceID": 3, "context": "This task can be broadly divided into two main phases [4]: \u2022 Search: the robot places the peg center within the clearance region of the hole center \u2022 Insertion: the robot adjusts the orientation of the peg with respect to the hole orientation and pushes the peg to the desired position In this paper, we study and learn these two phases separately.", "startOffset": 54, "endOffset": 57}, {"referenceID": 4, "context": "[5] calculate the moments from sensors and interprets the current position of the peg by mapping the moments onto positions.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] utilize depth profile in addition to roll and pitch data to interpret the current position of the peg.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "In the real case, it is very difficult to obtain a precise model of the physical interaction between two objects and calculate the moments caused by the contact forces and friction [6].", "startOffset": 181, "endOffset": 184}, {"referenceID": 6, "context": "[7] use associative reinforcement learning methods for learning the robot control.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Majors and Richards [8] use a neural network based approach.", "startOffset": 20, "endOffset": 23}, {"referenceID": 8, "context": "[9] propose the insertion algorithm which can recover from tilted mode without resetting the task to the initial state.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] propose an autonomous alignment method by force and moment measurement before insertion phase based on a three-point contact model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "\u03b8 \u2190 \u03b8 + \u03b1 ( r + \u03b3maxa\u2032 Q\u03b8(s ,a)\u2212Q\u03b8(s,a) ) \u2207\u03b8Q\u03b8(s,a) (11) As shown in [11], we store the data for all previous episodes of the agent experiences to a memory pool P with maximum size Preplay in a FIFO manner (Algorithm 1).", "startOffset": 69, "endOffset": 73}, {"referenceID": 10, "context": "Unlike [11], we use multiple long short-term memory (LSTM) layers to approximate the Q-function.", "startOffset": 7, "endOffset": 11}, {"referenceID": 11, "context": "LSTM can achieve good performance for complex tasks where part of the environment\u2019s state is hidden from the agent [12].", "startOffset": 115, "endOffset": 119}, {"referenceID": 12, "context": "As an obvious next step, we will analyze the difference between this approach and continuous space learning techniques such as A3C [14] and DDPG [15].", "startOffset": 131, "endOffset": 135}, {"referenceID": 13, "context": "As an obvious next step, we will analyze the difference between this approach and continuous space learning techniques such as A3C [14] and DDPG [15].", "startOffset": 145, "endOffset": 149}], "year": 2017, "abstractText": "High precision assembly of mechanical parts requires accuracy exceeding the robot precision. Conventional part mating methods used in the current manufacturing requires tedious tuning of numerous parameters before deployment. We show how the robot can successfully perform a tight clearance peg-in-hole task through training a recurrent neural network with reinforcement learning. In addition to saving the manual effort, the proposed technique also shows robustness against position and angle errors for the peg-in-hole task. The neural network learns to take the optimal action by observing the robot sensors to estimate the system state. The advantages of our proposed method is validated experimentally on a 7-axis articulated robot arm.", "creator": "LaTeX with hyperref package"}}}