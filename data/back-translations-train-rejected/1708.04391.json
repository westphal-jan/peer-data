{"id": "1708.04391", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Aug-2017", "title": "Learning body-affordances to simplify action spaces", "abstract": "Controlling embodied agents with many actuated degrees of freedom is a challenging task. We propose a method that can discover and interpolate between context dependent high-level actions or body-affordances. These provide an abstract, low-dimensional interface indexing high-dimensional and time- extended action policies. Our method is related to recent ap- proaches in the machine learning literature but is conceptually simpler and easier to implement. More specifically our method requires the choice of a n-dimensional target sensor space that is endowed with a distance metric. The method then learns an also n-dimensional embedding of possibly reactive body-affordances that spread as far as possible throughout the target sensor space.", "histories": [["v1", "Tue, 15 Aug 2017 04:07:57 GMT  (372kb,D)", "http://arxiv.org/abs/1708.04391v1", "4 pages, 4 figures"]], "COMMENTS": "4 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.AI cs.RO", "authors": ["nicholas guttenberg", "martin biehl", "ryota kanai"], "accepted": false, "id": "1708.04391"}, "pdf": {"name": "1708.04391.pdf", "metadata": {"source": "CRF", "title": "Learning body-affordances to simplify action spaces", "authors": ["Nicholas Guttenberg", "Martin Biehl", "Ryota Kanai"], "emails": ["ngutten@gmail.com,", "martin@araya.org,", "kanair@araya.org"], "sections": [{"heading": null, "text": "In fact, we are able to set out in search of a solution that will enable us to move to another world."}, {"heading": "II. METHOD", "text": "This consists of defining a distance between the results in a particular target (sub-) space, in which we use an explicit time horizon h to determine the point at which a sensor state is considered a result, but this could be generalized to variable time horizons by selecting an explicit prediction of dimensionality and coordinating the representation used to construct a control space to contain the learned body affordances. In our cases, we select a limited n-dimensional cubic grid in which we explicitly select the dimensionality and representation we use to contain the learned body affordances. In our cases, we reliably perform a regular grid of outcomes SG (seear Xiv: 170 8.04 391v 1)."}, {"heading": "III. RELATED WORK", "text": "While the three above-mentioned intuitions are relatively simple, they are also closely related to the theoretically principled approach of selecting body affordances to maximize empowerment [3]. Empowerment is the channel capacity from actions (here the body affordances) to future sensor values. However, it is maximized when the variability (more precisely the entropy) of the future sensors is high and the body affordances can reliably determine them (conditional entropy of sensor values in relation to body affordances). Empowerment has been used more directly to derive body affordances (under other names). Ultimately, their work uses a method in which options are implicitly defined in terms of the results. However, they comment that an intermediately learned hidden layering could be used to represent bodies in order to obtain a low-dimensional option / affordance space."}, {"heading": "IV. EXPERIMENTS", "text": "We use Bullet Physics Engine [8] as an environmental simulator and implement our networks in Pytorch [9]. Code for our experiments can be found at https: / / github.com / arayabrain / AffordanceMapping."}, {"heading": "A. Reaching task", "text": "In fact, the fact is that most of them are able to move to another world in which they are able to find themselves."}, {"heading": "B. Closed loop control: hexapod", "text": "The hexapod has three hinged joints per leg, each of which is controlled by a target angle. As we deal specifically with locomotion, we give the model a sinusoidal clock signal and ask the actions to determine the phase angle and amplitude of how this clock signal is applied to each joint. The robot has its center of gravity of mass position and orientation and joint angles as sensor inputs and delivers 36 actions at 5 times during a run. We reduce this 180-dimensional political space to a 2 DOF space of body affordability by using the final center of gravity of mass as target space ST. We find that iterative training predictors and applicants are more important to keep the predictor accurate compared to the controller. We also find that body affordable space can be very discontinuous due to collisions of the feet with the ground. < To increase the actual activity, we add the activity and increase the activity of each hexapod, and the activity of each hexapod is active when the leg is controlled by three joints >."}, {"heading": "V. CONCLUSION", "text": "We have proposed and tested a method for the dimensional reduction of action spaces, learning closed-loop controllers that provide a low-dimensional interface to higher control. We have been able to construct 2 DOF interfaces for both, 8 DOFs of a robot arm and a time-extended hexapod action space with 180 DOF. In the case of the hexapod, the learned control room extended to the discovery of locomotive gaits, allowing the robot to reach different points on the plane. Furthermore, the control rooms generated by this method tend to be smooth and interpolatable. In the future, we would like to evaluate the effect that the use of these intermediate controllers has on the rate of reinforcement learning at a higher level, in order to directly test whether this solves problems of sparse rewards or not. Furthermore, we would like to see if it is possible to impose the requirement of a distance metric on the result space, while the guarantee will maintain full coverage over the optical space."}], "references": [{"title": "Central pattern generators for locomotion control in animals and robots: A review", "author": ["A.J. Ijspeert"], "venue": "Neural Networks, vol. 21, no. 4, pp. 642\u2013653, May 2008. [Online]. Available: http://www.sciencedirect.com/ science/article/pii/S0893608008000804", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning", "author": ["R.S. Sutton", "D. Precup", "S. Singh"], "venue": "Artificial intelligence, vol. 112, no. 1-2, pp. 181\u2013211, 1999.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1999}, {"title": "Empowerment: A universal agent-centric measure of control", "author": ["A.S. Klyubin", "D. Polani", "C.L. Nehaniv"], "venue": "Evolutionary Computation, 2005. The 2005 IEEE Congress on, vol. 1. IEEE, 2005, pp. 128\u2013135. [Online]. Available: http://ieeexplore.ieee.org/abstract/document/1554676/", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "Variational Intrinsic Control", "author": ["K. Gregor", "D.J. Rezende", "D. Wierstra"], "venue": "arXiv:1611.07507 [cs], Nov. 2016, arXiv: 1611.07507. [Online]. Available: http://arxiv.org/abs/1611.07507", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Impoverished Empowerment: Meaningful Action Sequence Generation through Bandwidth Limitation", "author": ["T. Anthony", "D. Polani", "C.L. Nehaniv"], "venue": "Advances in Artificial Life. Darwin Meets von Neumann, ser. Lecture Notes in Computer Science. Springer, Berlin, Heidelberg, Sep. 2009, pp. 294\u2013301. [Online]. Available: https://link.springer.com/chapter/10. 1007/978-3-642-21314-4 37", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "General Self-Motivation and Strategy Identification: Case Studies Based on Sokoban and Pac-Man", "author": ["\u2014\u2014"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, vol. 6, no. 1, pp. 1\u201317, Mar. 2014.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Independently Controllable Features", "author": ["V. Thomas", "J. Pondard", "E. Bengio", "M. Sarfati", "P. Beaudoin", "M.-J. Meurs", "J. Pineau", "D. Precup", "Y. Bengio"], "venue": "arXiv:1708.01289 [cs, stat], Aug. 2017, arXiv: 1708.01289. [Online]. Available: http://arxiv.org/abs/1708.01289", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2017}], "referenceMentions": [{"referenceID": 0, "context": "These often perform dimensional reduction by means of central pattern generators (CPG) [1].", "startOffset": 87, "endOffset": 90}, {"referenceID": 1, "context": "In the option framework [2] time-extended policies called options are derived and then added to the choice of possible (elementary) actions.", "startOffset": 24, "endOffset": 27}, {"referenceID": 2, "context": "While the three intuitions mentioned above are reasonably straightforward, they are also closely related to the more theoretically principled approach of selecting the body-affordances so that they maximise empowerment [3].", "startOffset": 219, "endOffset": 222}, {"referenceID": 3, "context": "Empowerment has been used more directly in order to derive body-affordances (under a different name) in [4].", "startOffset": 104, "endOffset": 107}, {"referenceID": 4, "context": "Earlier work that also uses empowerment to find options are [5], [6].", "startOffset": 60, "endOffset": 63}, {"referenceID": 5, "context": "Earlier work that also uses empowerment to find options are [5], [6].", "startOffset": 65, "endOffset": 68}, {"referenceID": 6, "context": "Another interesting and successful approach to dimensional reduction [7] focuses more on finding policies that independently control", "startOffset": 69, "endOffset": 72}], "year": 2017, "abstractText": "Controlling embodied agents with many actuated degrees of freedom is a challenging task. We propose a method that can discover and interpolate between context dependent high-level actions or body-affordances. These provide an abstract, low-dimensional interface indexing high-dimensional and timeextended action policies. Our method is related to recent approaches in the machine learning literature but is conceptually simpler and easier to implement. More specifically our method requires the choice of a n-dimensional target sensor space that is endowed with a distance metric. The method then learns an also n-dimensional embedding of possibly reactive body-affordances that spread as far as possible throughout the target sensor space.", "creator": "LaTeX with hyperref package"}}}