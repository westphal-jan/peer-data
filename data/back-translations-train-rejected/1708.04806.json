{"id": "1708.04806", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Aug-2017", "title": "New Ideas for Brain Modelling 4", "abstract": "This paper continues the research that considers a new cognitive model. In particular, it considers the neural binding structure of an earlier paper. To help with this, the paper describes some new methods in the areas of image processing and high-level behaviour simulation. The work is all based on earlier research by the author and the new additions are intended to fit in with the overall design. For image processing, a grid-like structure is used with 'full linking'. Each cell in the classifier grid stores a list of all other cells it gets associated with and this is used as the learned image that new input is compared to. For the behaviour metric, a new prediction equation is suggested, as part of a simulation, that uses feedback and history to dynamically determine its course of action. While the new methods are from widely different topics, both can be compared with the binary-analog type of interface that is the main focus of the paper. It is suggested that the simplest of linking between a tree and ensemble can explain neural binding and variable signal strengths.", "histories": [["v1", "Wed, 16 Aug 2017 08:32:03 GMT  (1007kb)", "http://arxiv.org/abs/1708.04806v1", null], ["v2", "Wed, 27 Sep 2017 13:41:41 GMT  (1019kb)", "http://arxiv.org/abs/1708.04806v2", "Some new information and equation corrections"]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["kieran greer"], "accepted": false, "id": "1708.04806"}, "pdf": {"name": "1708.04806.pdf", "metadata": {"source": "CRF", "title": "New Ideas for Brain Modelling 4", "authors": ["Kieran Greer"], "emails": [], "sections": [{"heading": null, "text": "To help with this, the paper describes some new methods in the areas of image processing and high-level behavioral simulation. All work is based on the author's previous research and the new additions are intended to fit into the overall design. A grid-like structure with \"complete linkage\" is used for image processing. Each cell in the classification grid stores a list of all the other cells it is associated with, and this is used as a learned image to compare new inputs to. In the context of a simulation, a new predictive equation is proposed for behavior measurement, which dynamically determines its course of action by means of feedback and history. While the new methods come from very different topics, both can be compared with the binary-analog type of interface that is at the center of the paper. It is suggested that the simplest linkage between a tree and an ensemble can explain the neural binding and variable signal strengths. Keywords: image cluster, image-binary, cognitive, cognitive."}, {"heading": "1 Introduction", "text": "This paper continues the research that considers a new cognitive model, most recently updated in [8]. In particular, it looks at Figure 4 of this paper and how it could be useful in practice. To support this, the paper describes some new methods in the areas of image processing and high-level behavioral simulation. The work is all based on the author's previous research and the new additions are intended to fit into the overall design. A grid-like structure with \"complete linkage,\" if you like, is used for image processing. Each cell in the classification grid stores a list of all the other cells to which it is associated, and this is used as a learned image to compare new inputs. For behavioral measurement, a new predictive equation is proposed, as part of a simulation that uses feedback and history to dynamically determine its current state and action sequence. While the new methods come from very different topics, both can be analogous to the paper-type interface of the interface concept that is being compared."}, {"heading": "2 Image Processing", "text": "An initial investigation of the new theory can be attempted with image recognition. Images are represented by a 2-D grid, with a black cell meaning that a pixel is present and a white cell meaning that it is empty. A classifier uses the same grid-like structure where all cells are linked together. The author has this structure before in [8] and it is a kind of entropy classifier. He tries to reduce the error overall and is not so concerned about minimizing individual associations. The paper [7] describes a classifier that is perhaps more visible in nature. It also uses a complete linking of the method in which each cell has its own weights."}, {"heading": "3 Related Work", "text": "The concept tree [11] of section 5 has previously been compared with the Markov models [5] and is very similar to them, including the construction rule that can be implicit in a Markov model. In this section, a new feedback loop is described if the comparison of the Markov model also looks like a finite state machine. [22] is an overview of this, noting that there are many different types that obey different rules. While the concept tree is a static structure for storing knowledge, adding control structures such as feedback makes it possible to consider it for state changes as well. An earlier paper on control theory [23] put forward some interesting equations that may be similar to those in this paper. For example, Equation 1 there looks like the image-success ratio and Equation 7 is a probability relationship test that also tries to maximize within some kind of sequences."}, {"heading": "3.1 Cognitive Models", "text": "Hawkins and Blakeslee [16] describe how a region of the cortex could function (p. 57), and they note that an input signal is chosen from a higher level, in which a higher-quality pattern set wins and turns off the other groups. They also explicitly state that the higher level chooses to \"match\" its label better than the other patterns, and they may try to return their own image as an input signal and the best one there should match the input signal. The theory they state is that a region learns when it can be important and can then become partially active, as part of a memory or a prediction, so this is a kind of reasoning to override previous scenarios, even if they have not yet occurred in the current situation. This may then be further reinforced by specific instance values, making it the real decision. The following quote is also interesting: \"Every moment in your waking life is such that each region of your neoctex is propelled by a series of unanticipated columns of the above-observed ones, always propelled by two unmatched ones below."}, {"heading": "3.2 Neural Binding", "text": "There is a lot of research and philosophy on the idea of neural bonding. At its most basic point, this means that neural ensembles that together represent the concept mentioned need to be answered. Questions such as \"Why do we not confuse a red circle and a blue square with a blue circle and a red square\" [4] include the idea of consciousness and how the brain is able to be coherent, but while there are many theories, there are not many very specific results for the bonding mechanism itself. Some cognitive models for the real brain include temporal logic or predicate rules [4] to explain how variables can be linked and reasoning can be achieved, including the flow of information in both directions and so that the basic circuits of this and earlier papers are not too extravagant."}, {"heading": "4 Cognitive Behaviour", "text": "An earlier paper introduced a series of equations based on the collective behavioral research of [6], proposing a set of characteristics for modelling the stigmatic behavior of very simple animals, such as ants. They proposed using coordination, cooperation, deliberation, and collaboration as follows: \u2022 Coordination - is the appropriate organization in space and time of the tasks required to solve a given problem. \u2022 Cooperation - occurs when individuals perform a task together that cannot be accomplished by a single individual. \u2022 Balancing - refers to mechanisms that occur when a colony faces multiple opportunities. These mechanisms result in a collective choice for at least one of the possibilities. \u2022 Cooperation - means that different activities are performed simultaneously by groups of specialized individuals. They note that these are not mutually exclusive, but jointly contribute to fulfilling the different tasks of the colony."}, {"heading": "4.1 Problem Modelling", "text": "Modeling is based on the types of behavior that are used to solve the problem, using the same type definitions both to model the problem and to simulate its execution. Agents are defined by types of agents where an agent type can execute a certain set of behaviors. So, if the same type of behavior is to be performed at different levels of success; with static values, this would require different behavior definitions, or with dynamic ones, the value can change through an equation."}, {"heading": "4.2 Behaviour Equations", "text": "The problem Success Likelihood (PSL) is the summed up result of the behavioral values and estimates how well the problem can be solved. The upper part of the PSL value, represented in Equation 1, evaluates the average agent complexity (ECs) as it has just been described. In modeling, this is measured for all behavioral instances (Bs) that are part of the problem behavior (PBS), which cannot be greater than the optimal problem complexity value (PC) of 1.0. The problem complexity is a factor of how intelligent the agents must be to solve it. Since all ratings are standardized in a static specification, the maximum value that the problem complexity can have can be 1.0. If all behaviors are perfect, they also add up to 1. The probability of success of the problem can therefore be defined as follows: PSL = Eq."}, {"heading": "4.2.1 Individual Parameters", "text": "The individual capabilities of a behavior can be modeled as follows: ECs = Eq. 2Is = Eq. 3The agent or unit complexity (ECs) for behavior s is a factor of its ability to execute the associated behavioral characteristics of intelligence and collective abilities. Agent intelligence (Is) is a factor of its ability (BAs) and flexibility (BFs) capabilities for the specified behavior."}, {"heading": "4.2.2 Team Work", "text": "The collective or team work skills (COLs) of a behavior are modeled as follows: COLs = Eq. 4COMs = Eq. 5The collective skills of the behavioral agent are his ability to cooperate with other agents (COPs), to coordinate his actions with them (CORs) and to communicate with them (COMs), normalized. The communication skills of the agent for behavior include his ability to send a signal to another agent (SOs) and also his ability to receive a signal from another agent (SIs)."}, {"heading": "4.3 Prediction Operation for the Metric", "text": "In the simulation of the problem, the complexity value may change, and the probability of success may then become an individual assessment based on their knowledge and understanding of the environment. This can be defined by the subset of behaviors that the agent has either performed or interacted with by other actors. For a smarter response, the prediction can lead to an operation that goes beyond previous events before choosing a behavior to use in the current situation. It could be a reflection function based on the history of previous and / or possible decisions. For example, Eq.3 of the section defines intelligence as a combination of skills and flexibility."}, {"heading": "4.4 Intelligent Simulation Equations", "text": "A smarter version of the measurement variable for a simulation could therefore look like this: PSL = Eq. 7where the predictive equation can replace the complexity of the unit and the two parts of flexibility, and the prediction is modelled as in Equation 6 by the agent's decision plus his response to an answer. Dynamic problem complexity can be measured as in Equation 8 and is essentially a fraction of all behaviours the agent knows about. Depending on how this is measured, multiplication might be more appropriate for the PSL. However, if I \"know\" only 1 behaviour, for example, then I can solve this more easily based on my own knowledge than if I have to deal with several known behaviours."}, {"heading": "4.5 Testing", "text": "Since there has been no opportunity to test the new prediction equation or its feedback algorithm, this paper presents only the theory of this equation and the relationship of the theory to the other work. However, an example described next should help to show how it would work in practice."}, {"heading": "4.5.1 Worked Example", "text": "Consider the following scenario: An agent is in a situation S1. The agent is modeled with behaviors B1 to B5 and the world is modeled with behaviors B1 to B10. The agent is previously confronted with the same scenario S1 and has tried to determine the following behavior with related events in order to deal with it: Event B3 was tried at a time t3 and led to a reaction R8. Event B4 was tried at a time t2 and led to a reaction R6. Based on this, the behavior B4 is selected again, which leads to the equation: Pr = B4s1 + (1xB4 \u00b7 R6 / 2) + (1xB3 \u00b7 R8 / 3) The scene is interactive, with another agent being able to respond. The other agent also knows the scenario and responds with a behavior B10. This proves unfavorable to the agent and reduces its overall evaluation by the equation: Pr = B4\u00b7 S101 and SR1 is now required."}, {"heading": "5 Concept Base and Concept Trees", "text": "The paper [14] describes the idea of a \"concept base,\" which was later developed into a \"concept tree\" [11] [10]. In the paper, the concept base uses stigmery or basic reinforcement learning and stores concepts with optional instance values in the form: [A1, Va1] [B1, Vb1] [C1, Vc1]... are attributes of X"}, {"heading": "In this equation, A, B or C is the concept type, where in this case it could be a behaviour type. Va1,", "text": "It is as if it is a reactionary company that finds itself able to pay its debts without being able to pay its debts."}, {"heading": "6 Binary-Analog Interface in the Cognitive Model", "text": "It is, as it is, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place and a place, a place and a place, a place and a place, a place and a place, a place and a place, a place and a place, a place and a place, a place and a place, a place, a place, a place, a place and a place, a place and a place, a place, a place and a place, a place and a place, a place and a place, a place and a place, a place and a place, a place and a place, a place and a place, a place and a place, a place and a place, a place, a place and a place, a place, a place and a place, a place, a place and a place, a place, a place, a place and a place, a place, a place, a place and a place, a place, a place, a place and a place, a place, a place, a place, a place, a place and a place, a place, a place, a place, a place, a place and a place, a place, a place, a place, a place and a place, a place, a place, a place, a place and a place, a place, a place, a place and a place, a place, a place, a place and a place, a place, a place, a place and a place, a place, a place and a place, a place, a place, a place, a place and a place, a place, a place, a place, a place, a place and a place, a place, a place, a place, a place, a place, a place, a place and a place, a place, a place, a place, a place, a place and a place, a place, a place, a place, a place, a place, a place and a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place"}, {"heading": "7 Conclusions", "text": "This has led to some interesting results, both in the areas of image processing and at a higher level. It has also helped to think about the synchronization problems of neural binding over time, and how individual parts can be recombined into a more coherent whole. Behavioral decisions are based on the current state of the agent, his abilities, and also his memory. Negative feedback can be modelled as inhibitors, with the inhibitors being used as real structural units and not just to suppress a signal. They can be associated with a specific response, but can still be dynamic because the context determines when they burn."}], "references": [{"title": "Acquiring Visibly Intelligent Behavior with Example- Guided Neuroevolution", "author": ["B.D. Bryant", "R. Miikkulainen"], "venue": "In Proceedings of the Twenty-Second National Conference on Artificial Intelligence", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Neural Mechanisms of Binding in the Hippocampus and Neocortex: Insights from Computational Models", "author": ["D.M. Cer", "R.C. O'Reilly"], "venue": "Handbook of binding and memory: Perspectives from cognitive neuroscience,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Character recognition in natural images", "author": ["T.E. de Campos", "B.R. Babu", "M. Varma"], "venue": "In Proceedings of the International Conference on Computer Vision Theory and Applications (VISAPP),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "The Neural Binding Problem(s)", "author": ["J. Feldman"], "venue": "Cognitive neurodynamics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Markov models for pattern recognition: from theory to applications", "author": ["G.A. Fink"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "The biological principles of swarm intelligence", "author": ["S. Garnier", "J. Gautrais", "G. Theraulaz"], "venue": "Swarm Intelligence", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "A Single-Pass Classifier for Categorical Data, Special Issue on: IJCSysE Recent Advances in Evolutionary and Natural Computing Practice and Applications", "author": ["K. Greer"], "venue": "Int. J. Computational Systems Engineering, Inderscience,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2017}, {"title": "New Ideas for Brain Modelling 3, available on arXiv at https://arxiv.org/abs/1612.00369", "author": ["K. Greer"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "New Ideas for Brain Modelling, IOSR", "author": ["K. Greer"], "venue": "Journal of Engineering (IOSRJEN),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Adding Context to Concept Trees, available on arXiv at http://arxiv.org/abs/1606.05597", "author": ["K. Greer"], "venue": "DCS", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Concept Trees: Building Dynamic Concepts from Semi-Structured Data using Nature-Inspired Methods", "author": ["K. Greer"], "venue": "Studies in Fuzziness and Soft Computing, Springer- Verlag, Germany,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "A Metric for Modelling and Measuring Complex Behavioural Systems, IOSR", "author": ["K. Greer"], "venue": "Journal of Engineering (IOSRJEN),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Turing: Then, Now and Still Key, in: X-S. Yang (eds.), Artificial Intelligence, Evolutionary Computation and Metaheuristics (AIECM) - Turing 2012", "author": ["K. Greer"], "venue": "Studies in Computational Intelligence,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Symbolic Neural Networks for Clustering Higher-Level Concepts", "author": ["K. Greer"], "venue": "NAUN International Journal of Computers, Issue 3,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Benchmarks, Test Beds, Controlled Experimentation, and the Design of Agent Architectures, AI Magazine", "author": ["S. Hanks", "M.E. Pollack", "P.R. Cohen"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1993}, {"title": "Tutorial on agent-based modelling and simulation, Journal of Simulation, Operational Research Society Ltd. 2010;4:151\u2013162", "author": ["C.M. Macal", "M.J. North"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Introducing the TILEWORLD: Experimentally Evaluating Agent Architectures", "author": ["M. Pollack", "M. Ringuette"], "venue": "In Proceedings of the Eighth National Conference on Artificial Intelligence,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1990}, {"title": "Crossmodal binding through neural coherence: implications for multisensory processing", "author": ["D. Senkowski", "T.R. Schneider", "J.J. Foxe", "A.K. Engel"], "venue": "Trends in Neurosciences,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Probabilistic Finite-State Machines-Part I", "author": ["E. Vidal", "F. Thollard", "C. de la Higuera", "F. Casacuberta", "R.C. Carrasco"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "Some aspects of the theory of statistical control schemes", "author": ["E. Yashchin"], "venue": "IBM J. Res. Develop.,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1987}], "referenceMentions": [{"referenceID": 7, "context": "This paper continues the research that considers a new cognitive model, last updated in [8].", "startOffset": 88, "endOffset": 91}, {"referenceID": 7, "context": "The author has used this structure before in [8] and it is a type of entropy classifier.", "startOffset": 45, "endOffset": 48}, {"referenceID": 6, "context": "The paper [7] describes a classifier that is maybe more visual in nature.", "startOffset": 10, "endOffset": 13}, {"referenceID": 6, "context": "The author\u2019s own papers that are quoted [7]-[14] are all relevant to the research of this paper.", "startOffset": 40, "endOffset": 43}, {"referenceID": 13, "context": "The author\u2019s own papers that are quoted [7]-[14] are all relevant to the research of this paper.", "startOffset": 44, "endOffset": 48}, {"referenceID": 10, "context": "The Concept Tree [11] of section 5 has previously been compared to Markov Models [5] and is very similar to them, including the construction rule that can be implicit in a Markov Model.", "startOffset": 17, "endOffset": 21}, {"referenceID": 4, "context": "The Concept Tree [11] of section 5 has previously been compared to Markov Models [5] and is very similar to them, including the construction rule that can be implicit in a Markov Model.", "startOffset": 81, "endOffset": 84}, {"referenceID": 18, "context": "The paper [22] is a survey of these and notes that there are many different types that obey different rules.", "startOffset": 10, "endOffset": 14}, {"referenceID": 19, "context": "An earlier paper on control theory [23] posts some interesting equations that are maybe similar to ones in this paper.", "startOffset": 35, "endOffset": 39}, {"referenceID": 11, "context": "The earlier paper [12] notes some references, including [1][15][18] and [19].", "startOffset": 18, "endOffset": 22}, {"referenceID": 0, "context": "The earlier paper [12] notes some references, including [1][15][18] and [19].", "startOffset": 56, "endOffset": 59}, {"referenceID": 14, "context": "The earlier paper [12] notes some references, including [1][15][18] and [19].", "startOffset": 59, "endOffset": 63}, {"referenceID": 15, "context": "The earlier paper [12] notes some references, including [1][15][18] and [19].", "startOffset": 63, "endOffset": 67}, {"referenceID": 16, "context": "The earlier paper [12] notes some references, including [1][15][18] and [19].", "startOffset": 72, "endOffset": 76}, {"referenceID": 17, "context": "The paper [20] introduces the idea of temporal synchrony and synchronised oscillatory activity as important for multisensory perception.", "startOffset": 10, "endOffset": 14}, {"referenceID": 2, "context": "The image processing of section 2 has already been tried in [3], where they tested the full dataset.", "startOffset": 60, "endOffset": 63}, {"referenceID": 3, "context": "For example, questions like \u2018why don\u2019t we confuse a red circle and a blue square with a blue circle and a red square\u2019 [4] need to be answered.", "startOffset": 118, "endOffset": 121}, {"referenceID": 3, "context": "Some cognitive models for the real brain include temporal logic or predicate calculus rules [4] to explain how variables can bind with each other and reasoning can be obtained.", "startOffset": 92, "endOffset": 95}, {"referenceID": 1, "context": "The paper [2] describes a theory that is quite similar.", "startOffset": 10, "endOffset": 13}, {"referenceID": 5, "context": "An earlier paper introduced a set of equations that were based on the collective behaviour research of [6].", "startOffset": 103, "endOffset": 106}, {"referenceID": 11, "context": "This led to a set of equations by the author [12] for modelling these types of entity.", "startOffset": 45, "endOffset": 49}, {"referenceID": 11, "context": "The behaviour metric was tested in [12].", "startOffset": 35, "endOffset": 39}, {"referenceID": 13, "context": "The paper [14] described the idea of a \u2018Concept Base\u2019 that was later developed into a \u2018Concept Tree\u2019 [11][10].", "startOffset": 10, "endOffset": 14}, {"referenceID": 10, "context": "The paper [14] described the idea of a \u2018Concept Base\u2019 that was later developed into a \u2018Concept Tree\u2019 [11][10].", "startOffset": 101, "endOffset": 105}, {"referenceID": 9, "context": "The paper [14] described the idea of a \u2018Concept Base\u2019 that was later developed into a \u2018Concept Tree\u2019 [11][10].", "startOffset": 105, "endOffset": 109}, {"referenceID": 13, "context": "Therefore, definite structure can be added to the initial behaviour set, even as part of the symbolic neural network [14].", "startOffset": 117, "endOffset": 121}, {"referenceID": 7, "context": "The image-processing model of section 2 fits quite well with the cognitive model of the earlier research and the neuron binding, figure 4 in [8], in particular.", "startOffset": 141, "endOffset": 144}, {"referenceID": 3, "context": "The question like \u2018why don\u2019t we confuse a red circle and a blue square with a blue circle and a red square\u2019 [4] could be answered if red or blue are base concepts in one tree and circle or square in another and they then also cross-reference each other.", "startOffset": 108, "endOffset": 111}, {"referenceID": 10, "context": "This is already part of the concept trees research [11], where a leaf node in one tree links to a base node in another tree.", "startOffset": 51, "endOffset": 55}, {"referenceID": 12, "context": "Interestingly though, this linking process would fit with the lowest level of the original cognitive model [13].", "startOffset": 107, "endOffset": 111}, {"referenceID": 7, "context": "This paper has mostly looked at the figure 4 \u2018binary-analog\u2019 structure of [8] and considered where it might be useful.", "startOffset": 74, "endOffset": 77}, {"referenceID": 7, "context": "Although, as suggested in [8], some sort of residual effect could create an extending tree structure from experience, even though it would still be a process of removing nodes and links.", "startOffset": 26, "endOffset": 29}], "year": 2017, "abstractText": "This paper continues the research that considers a new cognitive model. In particular, it considers the neural binding structure of an earlier paper. To help with this, the paper describes some new methods in the areas of image processing and high-level behaviour simulation. The work is all based on earlier research by the author and the new additions are intended to fit in with the overall design. For image processing, a grid-like structure is used with \u2018full linking\u2019. Each cell in the classifier grid stores a list of all other cells it gets associated with and this is used as the learned image that new input is compared to. For the behaviour metric, a new prediction equation is suggested, as part of a simulation, that uses feedback and history to dynamically determine its course of action. While the new methods are from widely different topics, both can be compared with the binary-analog type of interface that is the main focus of the paper. It is suggested that the simplest of linking between a tree and ensemble can explain neural binding and variable signal strengths.", "creator": "Microsoft\u00ae Word 2016"}}}