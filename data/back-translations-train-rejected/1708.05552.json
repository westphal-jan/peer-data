{"id": "1708.05552", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Aug-2017", "title": "Practical Network Blocks Design with Q-Learning", "abstract": "Convolutional neural network provides an end-to-end solution to train many computer vision tasks and has gained great successes. However, the design of network architectures usually relies heavily on expert knowledge and is hand-crafted. In this paper, we provide a solution to automatically and efficiently design high performance network architectures. To reduce the search space of network design, we focus on constructing network blocks, which can be stacked to generate the whole network. Blocks are generated through an agent, which is trained with Q-learning to maximize the expected accuracy of the searching blocks on the learning task. Distributed asynchronous framework and early stop strategy are used to accelerate the training process. Our experimental results demonstrate that the network architectures designed by our approach perform competitively compared with hand-crafted state-of-the-art networks. We trained the Q-learning on CIFAR-100, and evaluated on CIFAR10 and ImageNet, the designed block structure achieved 3.60% error on CIFAR-10 and competitive result on ImageNet. The Q-learning process can be efficiently trained only on 32 GPUs in 3 days.", "histories": [["v1", "Fri, 18 Aug 2017 10:12:43 GMT  (2715kb,D)", "http://arxiv.org/abs/1708.05552v1", "11 pages, 8 figures"]], "COMMENTS": "11 pages, 8 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["zhao zhong", "junjie yan", "cheng-lin liu"], "accepted": false, "id": "1708.05552"}, "pdf": {"name": "1708.05552.pdf", "metadata": {"source": "CRF", "title": "Practical Network Blocks Design with Q-Learning", "authors": ["Zhao Zhong", "Junjie Yan", "Cheng-Lin"], "emails": ["liucl}@nlpr.ia.ac.cn,", "yanjunjie@sensetime.com"], "sections": [{"heading": "Introduction", "text": "In fact, most of them are able to survive on their own without being able to afford it."}, {"heading": "Related Work", "text": "In early research on the automation of neural network architectures, most work relies on genetic algorithms or other evolutionary algorithms that may well be classified (Schaffer, Whitley, and Eshelman 1992; Stanley and Miikkulainen 2002; Stanley, D'Ambrosio, and Gauci 2009; Suganuma, Shirakawa, and Nagao 2017).There are some other works that focus on the automatic selection of network architectures (Saxena and Verbeek 2016; Domhan, Springenberg, and Hutter 2015; Miconi 2016).These works may find suitable network architectures, but are not competitive compared to handcrafted networks. Recent work MetaQNN et al. 2016 and Neural Architecture Search (Zoph and Le 2016) with Reinforcement Learning report surprisingly good results and may provide state-of-the-art networks."}, {"heading": "The Proposed Method", "text": "Our method is based on Q-Learning, which consists of one agent, states and a series of actions per state. The agent creates block structure by selecting the action with the highest value in each state. In our work, the state represents the current layer in the block, and action represents the next layer of the selected agent. The last action in the block is always end layer. Each state or action is defined as a tuple of structure codes, e.g. {layer number, layer type, core size, connection1, connection2} in our framework. The training environment receives the network architecture sampled by the agent and then trains the network on target data sets and backwards validation accuracy as a reward for the agent for updating. With finite iteration, the agent can obtain an optimal strategy for generating block structures."}, {"heading": "Distributed Asynchronous Framework", "text": "The first problem we have encountered is that it is very time consuming to complete the search process, usually it takes more than a week. Most of the time is spent in the training environment, so we consider the use of multi-machine to speed up the training. Original MetaQNN has only sampled one network architecture at a time for an update, but we need many networks to be trained in parallel for multi-machine framework, so we have scanned 64 network codes as a minibatch, and when the stack is ready, the agent updates the structure codes 64 times in a row. In our work we propose a distributed asynchronous frame and a minibatch strategy to speed up the learning of the agent. The agent has a stack of structure codes at a time and stores in a list controller, N-child environments share the structure codes. Any environment that is trained in parallel, and when the minibatch is ready, to create this minibatch type of backup controller results in another way to update the strategy."}, {"heading": "Block Design", "text": "Powerful networks such as ResNet and Inception have short-circuit connections or multi-level connections in their block, it is more complex than pure networks. Unlike MetaQNN, our structure codes contain connection parameters that can execute the complexity of neural networks like modern models. Our block structure codes are summarized in Table 1, they should contain less than the number of layers: folding, maximum pooling, identity, element addition and conception. Only the computational layers have the parameters of the core size. The connection parameters mean that the layer is less than the layer."}, {"heading": "Training Speed Up", "text": "Time is the biggest problem in this work as said above. With distributed asynchronous frames, we can train the agent on multi-machine and multi-GPUs, but we have limited computing resources with only 32 GPUs for this experiment. Child Environment take a lot of time to train until convergence, but what we need is a reward to be good or bad block instead of the exact result. Figure 4: Top 100 blocks search result on CIFAR-10 with ReLU and batch normalization layer code. The yellow line represents the early stop result and the blue line is the train to convergence result. The red line is the redefined reward according to formula 1. To deal with the problems, we propose an early stop strategy to speed up the training process. Each child trains the network for a fixed 12 epochs on CIFAR100 dataset during the search for architecture."}, {"heading": "Experiments and Results", "text": "In this section, we describe our experiments with BlockQNN using the framework and search space described above to generate a good block structure. All search experiments are performed on the basis of CIFAR-100 Dataset for the classification network. The agent was trained with the help of experience replay and epsilon-greedy strategies. We can obtain several candidate block structures generated by agents after the search. In our work, we select the top 100 architectures to train the convergence on CIFAR-10 to verify the best architecture. We call them Block-QNN-A and Block-QNN-B. With the block structure, we can easily construct the network we need to decide the repetition times of the blocks. In the subsection, we will show the repetition times of the blocks, verify the experiments and transfer experiments on ImageNet."}, {"heading": "Block Searching Analysis", "text": "Figure 7 shows the mean prediction of early-stop accuracy over 64 models (each minibatch) for CIFAR-100 search experiments. After random exploration, early-stop accuracy begins to grow slowly and eventually converges. The mean accuracy of models at the random exploration stage is 56%, and at Epsilon = 0.1 last time, the mean accuracy is close to 65%. As Figure 7 shows, the top models are all in the final stages of the Q-learning process. It proves that our framework is learning the way to create better block structures rather than randomly searching many models."}, {"heading": "Experiment on CIFAR", "text": "The CIFAR-10 dataset consists of 60000 32x32 color images in 10 classes, with 6000 frames per class. There are 50,000 training frames and 10,000 test frames. We use the common data enlargement process, which randomly crops 32x32 patches from padded images of 40x40 size and applies random horizontal flips for training. All models use the SGD Optimizer with pulse rate set to 0.9 and weight decay set to 0.0005. We start with a learning rate of 0.1 and train the models for 300 epochs, reducing the learning rate in the 150th and 225th epochs. The stack size is set to 128 and all weights were initialized with the MSRA initialization (Er et al. 2015). For the CIFAR-10 task, we set N = 4. After the top 100 models trained to convergence, we can find some good block structures."}, {"heading": "Experiment on ImageNet", "text": "We have learned the block structure from CIFAR-10 to CIFS-10. Weight fragmentation is immense. We start with a learning rate of 0.1 and share it with the 30th and 60th epochs. For training, we use an augmentation that happens to have 224x224 patches from one sketchy picture to another."}, {"heading": "Acknowledgments", "text": "The authors thank Yucong Zhou, Wei Wu, Boyang Deng, Xu-Yao Zhang and many others at SenseTime Research for discussions and feedback within this work."}], "references": [{"title": "M", "author": ["M. Andrychowicz", "M. Denil", "S. Gomez", "Hoffman"], "venue": "W.; Pfau, D.; Schaul, T.; and de Freitas, N.", "citeRegEx": "Andrychowicz et al. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Designing neural network architectures using reinforcement learning", "author": ["Baker"], "venue": "arXiv preprint arXiv:1611.02167", "citeRegEx": "Baker,? \\Q2016\\E", "shortCiteRegEx": "Baker", "year": 2016}, {"title": "J", "author": ["Bergstra"], "venue": "S.; Bardenet, R.; Bengio, Y.; and K\u00e9gl, B.", "citeRegEx": "Bergstra et al. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "P", "author": ["L. Bertinetto", "J. Valmadre", "J.F. Henriques", "A. Vedaldi", "Torr"], "venue": "H.", "citeRegEx": "Bertinetto et al. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "A", "author": ["L.-C. Chen", "G. Papandreou", "I. Kokkinos", "K. Murphy", "Yuille"], "venue": "L.", "citeRegEx": "Chen et al. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Q", "author": ["J. Dean", "G. Corrado", "R. Monga", "K. Chen", "M. Devin", "M. Mao", "A. Senior", "P. Tucker", "K. Yang", "Le"], "venue": "V.; et al. 2012. Large scale distributed deep networks. In Advances in neural information processing systems, 1223\u2013", "citeRegEx": "Dean et al. 2012", "shortCiteRegEx": null, "year": 1231}, {"title": "L", "author": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li", "Fei-Fei"], "venue": "2009. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR", "citeRegEx": "Deng et al. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "J", "author": ["Domhan, T.", "Springenberg"], "venue": "T.; and Hutter, F.", "citeRegEx": "Domhan. Springenberg. and Hutter 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "and Sun", "author": ["K. He"], "venue": "J.", "citeRegEx": "He and Sun 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "J", "author": ["K. He", "X. Zhang", "S. Ren", "Sun"], "venue": "2015. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In Proceedings of the IEEE international conference on computer vision, 1026\u2013", "citeRegEx": "He et al. 2015", "shortCiteRegEx": null, "year": 1034}, {"title": "2016a. Deep residual learning for image recognition", "author": ["He"], "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,", "citeRegEx": "He,? \\Q2016\\E", "shortCiteRegEx": "He", "year": 2016}, {"title": "2016b. Identity mappings in deep residual networks", "author": ["He"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "He,? \\Q2016\\E", "shortCiteRegEx": "He", "year": 2016}, {"title": "P", "author": ["S. Hochreiter", "A.S. Younger", "Conwell"], "venue": "R.", "citeRegEx": "Hochreiter. Younger. and Conwell 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "K", "author": ["G. Huang", "Z. Liu", "Weinberger"], "venue": "Q.; and van der Maaten, L.", "citeRegEx": "Huang et al. 2017", "shortCiteRegEx": null, "year": 2017}, {"title": "and Szegedy", "author": ["S. Ioffe"], "venue": "C.", "citeRegEx": "Ioffe and Szegedy 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "and Ba", "author": ["D. Kingma"], "venue": "J.", "citeRegEx": "Kingma and Ba 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "and Hinton", "author": ["A. Krizhevsky"], "venue": "G.", "citeRegEx": "Krizhevsky and Hinton 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "G", "author": ["A. Krizhevsky", "I. Sutskever", "Hinton"], "venue": "E.", "citeRegEx": "Krizhevsky. Sutskever. and Hinton 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "L", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "Jackel"], "venue": "D.", "citeRegEx": "LeCun et al. 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "D", "author": ["M. Li", "L. Zhou", "Z. Yang", "A. Li", "F. Xia", "Andersen"], "venue": "G.; and Smola, A.", "citeRegEx": "Li et al. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Reinforcement learning for robots using neural networks", "author": ["Lin", "L.-J"], "venue": "Technical report,", "citeRegEx": "Lin and L..J.,? \\Q1993\\E", "shortCiteRegEx": "Lin and L..J.", "year": 1993}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["Shelhamer Long", "J. Darrell 2015] Long", "E. Shelhamer", "T. Darrell"], "venue": "In Proc. IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Long et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Long et al\\.", "year": 2015}, {"title": "A", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "Fidjeland"], "venue": "K.; Ostrovski, G.; et al.", "citeRegEx": "Mnih et al. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "and Han", "author": ["H. Nam"], "venue": "B.", "citeRegEx": "Nam and Han 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing", "author": ["Ren"], "venue": null, "citeRegEx": "Ren,? \\Q2015\\E", "shortCiteRegEx": "Ren", "year": 2015}, {"title": "and Verbeek", "author": ["S. Saxena"], "venue": "J.", "citeRegEx": "Saxena and Verbeek 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "1992", "author": ["J.D. Schaffer", "D. Whitley", "L. J Eshelman"], "venue": "Combinations of genetic algorithms and neural networks: A survey of the state of the art. In Combinations of Genetic Algorithms and Neural Networks,", "citeRegEx": "Schaffer. Whitley. and Eshelman 1992", "shortCiteRegEx": null, "year": 1992}, {"title": "and Zisserman", "author": ["K. Simonyan"], "venue": "A.", "citeRegEx": "Simonyan and Zisserman 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "J", "author": ["Springenberg"], "venue": "T.; Dosovitskiy, A.; Brox, T.; and Riedmiller, M.", "citeRegEx": "Springenberg et al. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "R", "author": ["Srivastava"], "venue": "K.; Greff, K.; and Schmidhuber, J.", "citeRegEx": "Srivastava. Greff. and Schmidhuber 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "and Miikkulainen", "author": ["K.O. Stanley"], "venue": "R.", "citeRegEx": "Stanley and Miikkulainen 2002", "shortCiteRegEx": null, "year": 2002}, {"title": "K", "author": ["Stanley"], "venue": "O.; D\u2019Ambrosio, D. B.; and Gauci, J.", "citeRegEx": "Stanley. D.Ambrosio. and Gauci 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "A genetic programming approach to designing convolutional neural network architectures. arXiv preprint arXiv:1704.00764", "author": ["Shirakawa Suganuma", "M. Nagao 2017] Suganuma", "S. Shirakawa", "T. Nagao"], "venue": null, "citeRegEx": "Suganuma et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Suganuma et al\\.", "year": 2017}, {"title": "2015a. Going deeper with convolutions", "author": ["Szegedy"], "venue": "In Proc. IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Szegedy,? \\Q2015\\E", "shortCiteRegEx": "Szegedy", "year": 2015}, {"title": "Rethinking the inception architecture for computer", "author": ["Szegedy"], "venue": null, "citeRegEx": "Szegedy,? \\Q2015\\E", "shortCiteRegEx": "Szegedy", "year": 2015}, {"title": "and Drissi", "author": ["R. Vilalta"], "venue": "Y.", "citeRegEx": "Vilalta and Drissi 2002", "shortCiteRegEx": null, "year": 2002}, {"title": "and Dayan", "author": ["C.J. Watkins"], "venue": "P.", "citeRegEx": "Watkins and Dayan 1992", "shortCiteRegEx": null, "year": 1992}, {"title": "C", "author": ["Watkins", "C. J"], "venue": "H.", "citeRegEx": "Watkins 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "Aggregated residual transformations for deep neural networks. arXiv preprint arXiv:1611.05431", "author": ["Xie"], "venue": null, "citeRegEx": "Xie,? \\Q2016\\E", "shortCiteRegEx": "Xie", "year": 2016}, {"title": "and Komodakis", "author": ["S. Zagoruyko"], "venue": "N.", "citeRegEx": "Zagoruyko and Komodakis 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Q", "author": ["B. Zoph", "Le"], "venue": "V.", "citeRegEx": "Zoph and Le 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Q", "author": ["B. Zoph", "V. Vasudevan", "J. Shlens", "Le"], "venue": "V.", "citeRegEx": "Zoph et al. 2017", "shortCiteRegEx": null, "year": 2017}], "referenceMentions": [], "year": 2017, "abstractText": "Convolutional neural network provides an end-to-end solution to train many computer vision tasks and has gained great successes. However, the design of network architectures usually relies heavily on expert knowledge and is hand-crafted. In this paper, we provide a solution to automatically and efficiently design high performance network architectures. To reduce the search space of network design, we focus on constructing network blocks, which can be stacked to generate the whole network. Blocks are generated through an agent, which is trained with Q-learning to maximize the expected accuracy of the searching blocks on the learning task. Distributed asynchronous framework and early stop strategy are used to accelerate the training process. Our experimental results demonstrate that the network architectures designed by our approach perform competitively compared with handcrafted state-of-the-art networks. We trained the Q-learning on CIFAR-100, and evaluated on CIFAR10 and ImageNet, the designed block structure achieved 3.60% error on CIFAR10 and competitive result on ImageNet. The Q-learning process can be efficiently trained only on 32 GPUs in 3 days.", "creator": "LaTeX with hyperref package"}}}