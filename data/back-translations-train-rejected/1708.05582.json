{"id": "1708.05582", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Aug-2017", "title": "Agree to Disagree: Improving Disagreement Detection with Dual GRUs", "abstract": "This paper presents models for detecting agreement/disagreement in online discussions. In this work we show that by using a Siamese inspired architecture to encode the discussions, we no longer need to rely on hand-crafted features to exploit the meta thread structure. We evaluate our model on existing online discussion corpora - ABCD, IAC and AWTP. Experimental results on ABCD dataset show that by fusing lexical and word embedding features, our model achieves the state of the art performance of 0.804 average F1 score. We also show that the model trained on ABCD dataset performs competitively on relatively smaller annotated datasets (IAC and AWTP).", "histories": [["v1", "Fri, 18 Aug 2017 12:34:11 GMT  (765kb,D)", "http://arxiv.org/abs/1708.05582v1", "In Proc. 7th Affective Computing and Intelligent Interaction (ACII'17), San Antonio, TX, USA, Oct. 23-26, 2017"]], "COMMENTS": "In Proc. 7th Affective Computing and Intelligent Interaction (ACII'17), San Antonio, TX, USA, Oct. 23-26, 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["sushant hiray", "venkatesh duppada"], "accepted": false, "id": "1708.05582"}, "pdf": {"name": "1708.05582.pdf", "metadata": {"source": "CRF", "title": "Agree to Disagree: Improving Disagreement Detection with Dual GRUs", "authors": ["Sushant Hiray", "Venkatesh Duppada"], "emails": ["sushant.hiray@seernet.io,", "venkatesh.duppada@seernet.io"], "sections": [{"heading": "1. Introduction", "text": "The rise of various discussion forums and social media sites has given people a lot of opportunities to express their opinions. As several people participate in a particular discussion, participants often agree or disagree with the views presented by others. Taking into account the agreement and disagreement (referred to as (dis) agreement) helps to detect the presence of disagreements, the ideological stance of participants [1], and untangle beliefs that shape opinion in general. This can also be useful for detecting the presence of (dis) agreements in online discussions between two posts, analyzing the quote and response (Q-R pairs [6]) in order to predict trends in the stock markets. Within this framework, the same neural network code is applied to two input sentences that are elaborated individually, so that both sentences are coded in sentence vectors in the same hierarchy."}, {"heading": "2. Related Work", "text": ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"}, {"heading": "3. Data", "text": "In this thesis, we focus on the 3-way classification (agreement / disagreement / none) between quota response pairs (Q-R) for three previously existing in-domain records. These are described in the following subsections."}, {"heading": "3.1. Agreement by Create Debaters (ABCD)", "text": "The ABCD corpus [16] is curated by Create Debate website1, where users can start a debate by asking a question. Although the site can support both open and multi-page debates, the corpus only includes the pro-counter debates. The corpus is commented as follows: The page label corresponding to each post (answer) determines whether the user agrees with the previous post (quote) or not. If the authors of both posts are different, they agree if the page captions are the same or otherwise do not match. If the authors of both posts are the same, it is marked as none, since it implies that it is in continuation of the previous post (quote). Furthermore, the first post in a debate is usually set the premise of the debate so that it has no page associated with it. Therefore, all Q-R are marked with the quote as none. Table 1 shows examples of Q-R pairs for each label type."}, {"heading": "3.2. Agreement in Wikipedia Talk Pages (AWTP)", "text": "AWTP [23] is formatted in the same way as ABCD. Post-reply pairs are commented on manually with their (dis-) consent attitude, and additional mode information indicates the way in which agreement or disagreement is expressed. AWTP's data source consists mainly of Wikipedia talk pages and LiveJournal posts. Table 2 provides additional statistics for the corpus.1. http: / / www.createdebate.com /"}, {"heading": "3.3. Internet Argument Corpus (IAC)", "text": "The Internet Argument Corpus (IAC) [6] is a collection of corpora for research in political debates on Internet forums. It consists of \u0445 11,000 discussions, \u0445 390,000 posts and some \u0445 73,000,000 words. It includes topic comments, response characteristics and viewpoints. The 4forum posts were commented on with the help of Mechanical Turk. Commentators were given a Q-R pair and they indicated the degree of (dis) agreement on a scale of [-5, 5]. However, not all posts were commented on in a thread for (dis) agreement and approximately 6000 valid Q-R pairs were extracted. In accordance with previous work of this corpus [15], [16], [18] we converted the scalar values into corresponding (dis) agreement as follows: [-5, -1] is marked as agreement, [-1, 1] is marked as none, [1, 5] is marked as agreement with each other if several commentators have not combined in the same post."}, {"heading": "4. Feature Extraction", "text": "In this section we will briefly mention the features experimented in this work."}, {"heading": "4.1. Word Vectors", "text": "Recently, distributed word representations [24] (word2vec [25], GloVe [26]) have proven to be promising in many NLP tasks and are the driver for the success of deep learning in NLP [27]. Word vectors encode semantics in low dimensional space and can be efficiently used for various NLP tasks [28] [29]. For this task of (dis-) agreement classification, we use GloVe embedding of 300 dimensions trained on Common Crawl with 840 billion tokens and 2.2 million vocabularies."}, {"heading": "4.2. Lexicons", "text": "We used affects, feelings, emotions, opinion lexicons for feature extraction because in many of the online discussion forums people tend to argue with emotions and opinions on a particular topic in order to convey their attitude or belief. Using these effects will help us to classify whether an answer (dis) matches the quote or not. Prior to working [14] with these lexicon, they have shown that they deliver good results. Among lexical characteristics, we have used the following ratings. + / -EffectWordNet [30] Word lists are manually rated for value with an integer between -5 (Negative Sentiment) and + 5 (Positive Sentiment). Bing Liu [31] Opinion lexicon extract Opinion to customer reviews. + / -EffectWordNet [32] by MPQA group are sense level lexicons. The NRC Affect Intensity [33] lexicons offer opinion lexicons, lexicons, lexicons to customer reviews, lexicons to customer reviews."}, {"heading": "5. System Description", "text": "The task of classifying (dis-) matches from the Q-R pair falls into a much broader category of modeling sentence pairs. Many NLP tasks such as natural language inferences, text sequences, answer selection, paraphrase identification, etc., involve modeling a sentence pair so that it performs well in a given task or multitude of such tasks [41]. For this task, we used an architecture inspired by the Siamese network [5] and the Stanford Natural Language Inference Model [42] with identical networks encoding Q-R pairs. For each Q-R pair, we extract two sets of features. Firstly, GloVe word embedding is fed to gated recurrent units [43] to create a sentence embedding. Secondly, a lexical feature vector is extracted from each text, as mentioned in subsection 4.2. Both sentence embeddings from our Q-architecture are then linked together to form a lexical feature vector, as shown in subsection 4.2."}, {"heading": "5.1. System Parameters", "text": "We used Relu Nonlinearity, Dropout [44] for regularization, and Batch Normalization [45] to accelerate training. The network was optimized with an adam [46] optimizer with a learning rate of 0.001. We have plotted the sequence length of Q-R pairs in Figure 2 to better estimate the maximum sequence length for the GRU layer. The average sequence length of quotes and answers is 46.28 and 64.935, respectively. The effect of the maximum sequence length of text input on GRUs is calculated and can be found in Section 6. We used Keras [47] Deep Learning Framework to train our models."}, {"heading": "6. Experiments", "text": "In this section, we evaluate our model based on the classification of 3-way agreements. The general settings of the model were defined in subsection 5.1. In the following subsections, we will examine the variants of our model and compare our model with the current models of benchmark datasets in section 3."}, {"heading": "6.1. Features Used", "text": "We implemented three variants of the architecture: Only lexical features are used, only GloVe embeddings are used, and finally, where both are used. As is obvious and hypothetical, the model trained with lexical and word embeddings yielded the best results. Interestingly, if the model uses only the lexicographs, it surpasses the previous best model, which indicates the meaning of lexical features. However, the use of only lexical features suffers from all the disadvantages of any sack-of-words model. This is primarily because it cannot encode the temporal nature of the language. At this point, gated recurrent units or generally recursive neural networks come into play. GRUs can successfully encode the temporal nature. By merging both the GRU-encoded embeddings and the lexicographs, we reached the state of the art by comparing the results of the ABCD dataset with the prior best model 16 [3]."}, {"heading": "6.2. Maximum Input Sequence Length", "text": "In Table 4, we examine the effects of varying the maximum input sequence length. The results highlight some interesting findings. As these are discussion posts, the average post size is larger than a few sentences, so if we increase the maximum sequence length, the increase in performance is justified. However, as soon as we increase the size after a certain threshold, many input sequences must be filled with zeros, resulting in a drop in performance."}, {"heading": "6.3. Transfer Learning", "text": "Recently, with the availability of huge amounts of data, a new paradigm of machine learning has come into play, called Transfer Learning [48]. Transfer Learning is improving learning in a new task by transferring knowledge from a related task that has already been learned. At this point, we have applied transfer learning techniques to smaller datasets and achieved competitive results. Tables 5 and 6 incorporate the results of various model architectures that have been studied to test the effectiveness of transferring learning from ABCD datasets to the smaller annotated datasets IAC and AWTP. Variants studied are as follows: Direct, with the model trained on the ABCD (referred to as a pre-trained model) being tested directly on the smaller dataset. Tuning: the model is seeded with the weights of the pre-trained model and trained with the smaller dataset. Transfer: The last 2 layers of the pre-trained model are removed and replaced by new 100-size layers and the model is trained on the smaller datasets."}, {"heading": "7. Error Analysis", "text": "This way of capturing Q-R pairs is not perfect and suffers from the following problems: people may be on the same / other side of the debate, but may disagree / agree on some points (example 1 in table 7), because the pages represent the topic level and not the post or sentence level, extra-thematic social chatter in the debate forum (example 2 in table 7), etc. Our analysis found that the error in the classification was in fact a case of mislabeling in some cases."}, {"heading": "8. Conclusion", "text": "We have trained a deep neural network merging lexical and word vector-based characteristics to achieve state-of-the-art results in classifying the largest ever available classification dataset (ABCD corpus) in 3-way agreements (DIS). We have shown that we no longer need to rely on handmade characteristics to use the meta-thread structure. We have also demonstrated the benefits of transferring learning from pre-trained models to large companies to achieve competitive results on small domain datasets. To date, research for classifying (DIS) agreements has not been moving at a pace comparable to some other NLP tasks, mainly due to the unavailability of large standard datasets. Although ABCD datasets are large enough, they suffer from many problems because they use naturally occurring labels. We plan to improve the ABCD dataset by performing semi-supervised labels on hand-annotated datasets."}], "references": [{"title": "Recognizing stances in online debates", "author": ["S. Somasundaran", "J. Wiebe"], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1-Volume 1. Association for Computational Linguistics, 2009, pp. 226\u2013234.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Detecting subgroups in online discussions by modeling positive and negative relations among participants", "author": ["A. Hassan", "A. Abu-Jbara", "D. Radev"], "venue": "Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning. Association for Computational Linguistics, 2012, pp. 59\u201370.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Subgroup detection in ideological discussions", "author": ["A. Abu-Jbara", "M. Diab", "P. Dasigi", "D. Radev"], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers- Volume 1. Association for Computational Linguistics, 2012, pp. 399\u2013409.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Twitter mood predicts the stock market", "author": ["J. Bollen", "H. Mao", "X. Zeng"], "venue": "Journal of computational science, vol. 2, no. 1, pp. 1\u20138, 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Signature verification using a\u201d siamese\u201d time delay neural network", "author": ["J. Bromley", "I. Guyon", "Y. LeCun", "E. S\u00e4ckinger", "R. Shah"], "venue": "Advances in Neural Information Processing Systems, 1994, pp. 737\u2013 744.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1994}, {"title": "A corpus for research on deliberation and debate.", "author": ["M.A. Walker", "J.E.F. Tree", "P. Anand", "R. Abbott", "J. King"], "venue": "in LREC,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Detection of agreement vs. disagreement in meetings: Training with unlabeled data", "author": ["D. Hillard", "M. Ostendorf", "E. Shriberg"], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: companion volume of the Proceedings of HLT-NAACL 2003\u2013short papers-Volume 2. Association for Computational Linguistics, 2003, pp. 34\u201336.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "Identifying agreement and disagreement in conversational speech: Use of bayesian networks to model pragmatic dependencies", "author": ["M. Galley", "K. McKeown", "J. Hirschberg", "E. Shriberg"], "venue": "Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics. Association for Computational Linguistics, 2004, p. 669.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Agreement/disagreement classification: Exploiting unlabeled data using contrast classifiers", "author": ["S. Hahn", "R. Ladner", "M. Ostendorf"], "venue": "Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers. Association for Computational Linguistics, 2006, pp. 53\u201356.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "The icsi meeting corpus", "author": ["A. Janin", "D. Baron", "J. Edwards", "D. Ellis", "D. Gelbart", "N. Morgan", "B. Peskin", "T. Pfau", "E. Shriberg", "A. Stolcke"], "venue": "Acoustics, Speech, and Signal Processing, 2003. Proceedings.(ICASSP\u201903). 2003 IEEE International Conference on, vol. 1. IEEE, 2003, pp. I\u2013I.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2003}, {"title": "Agreement detection in multiparty conversation", "author": ["S. Germesin", "T. Wilson"], "venue": "Proceedings of the 2009 international conference on Multimodal interfaces. ACM, 2009, pp. 7\u201314.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "The ami meeting corpus", "author": ["I. McCowan", "J. Carletta", "W. Kraaij", "S. Ashby", "S. Bourban", "M. Flynn", "M. Guillemot", "T. Hain", "J. Kadlec", "V. Karaiskos"], "venue": "Proceedings of the 5th International Conference on Methods and Techniques in Behavioral Research, vol. 88, 2005.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Detection of agreement and disagreement in broadcast conversations", "author": ["W. Wang", "S. Yaman", "K. Precoda", "C. Richey", "G. Raymond"], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2. Association for Computational Linguistics, 2011, pp. 374\u2013378.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Unifying local and global agreement and disagreement classification in online debates", "author": ["J. Yin", "P. Thomas", "N. Narang", "C. Paris"], "venue": "Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis. Association for Computational Linguistics, 2012, pp. 61\u201369.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "How can you say such things?!?: Recognizing disagreement in informal political argument", "author": ["R. Abbott", "M. Walker", "P. Anand", "J.E. Fox Tree", "R. Bowmani", "J. King"], "venue": "Proceedings of the Workshop on Languages in Social Media. Association for Computational Linguistics, 2011, pp. 2\u201311.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "I couldn\u2019t agree more: The role of conversational structure in agreement and disagreement detection in online discussions.", "author": ["S. Rosenthal", "K. McKeown"], "venue": "in SIGDIAL Conference,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Improving agreement and disagreement identification in online discussions with a socially-tuned sentiment lexicon", "author": ["L. Wang", "C. Cardie"], "venue": "arXiv preprint arXiv:1606.05706, 2016.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Topic independent identification of agreement and disagreement in social media dialogue", "author": ["A. Misra", "M.A. Walker"], "venue": "Conference of the Special Interest Group on Discourse and Dialogue, 2013, p. 920.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatic detection of arguments in legal texts", "author": ["M.-F. Moens", "E. Boiy", "R.M. Palau", "C. Reed"], "venue": "Proceedings of the 11th international conference on Artificial intelligence and law. ACM, 2007, pp. 225\u2013230.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Argumentation mining: the detection, classification and structure of arguments in text", "author": ["R.M. Palau", "M.-F. Moens"], "venue": "Proceedings of the 12th international conference on artificial intelligence and law. ACM, 2009, pp. 98\u2013107.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Back up your stance: Recognizing arguments in online discussions.", "author": ["F. Boltuzic", "J. Snajder"], "venue": "in ArgMining@ ACL,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Stance and sentiment in tweets", "author": ["S.M. Mohammad", "P. Sobhani", "S. Kiritchenko"], "venue": "ACM Transactions on Internet Technology (TOIT), vol. 17, no. 3, p. 26, 2017.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2017}, {"title": "Annotating agreement and disagreement in threaded discussion.", "author": ["J. Andreas", "S. Rosenthal", "K. McKeown"], "venue": "LREC,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Word representations: a simple and general method for semi-supervised learning", "author": ["J. Turian", "L. Ratinov", "Y. Bengio"], "venue": "Proceedings of the 48th annual meeting of the association for computational linguistics. Association for Computational Linguistics, 2010, pp. 384\u2013394.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in neural information processing systems, 2013, pp. 3111\u20133119.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Glove: Global vectors for word representation.", "author": ["J. Pennington", "R. Socher", "C.D. Manning"], "venue": "in EMNLP, vol", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["A. Karpathy", "L. Fei-Fei"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 3128\u2013 3137.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Improving distributional similarity with lessons learned from word embeddings", "author": ["O. Levy", "Y. Goldberg", "I. Dagan"], "venue": "Transactions of the Association for Computational Linguistics, vol. 3, pp. 211\u2013225, 2015.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "A new anew: Evaluation of a word list for sentiment analysis in microblogs", "author": ["F.\u00c5. Nielsen"], "venue": "arXiv preprint arXiv:1103.2903, 2011.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "Mining and summarizing customer reviews", "author": ["M. Hu", "B. Liu"], "venue": "Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2004, pp. 168\u2013177.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2004}, {"title": "+/-effectwordnet: Sense-level lexicon acquisition for opinion inference.", "author": ["Y. Choi", "J. Wiebe"], "venue": "in EMNLP,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2014}, {"title": "Word affect intensities", "author": ["S.M. Mohammad"], "venue": "arXiv preprint arXiv:1704.08798, 2017.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2017}, {"title": "Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon", "author": ["S.M. Mohammad", "P.D. Turney"], "venue": "Proceedings of the NAACL HLT 2010 workshop on computational approaches to analysis and generation of emotion in text. Association for Computational Linguistics, 2010, pp. 26\u201334.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Determining word\u2013emotion associations from tweets by multi-label classification", "author": ["F. Bravo-Marquez", "E. Frank", "S.M. Mohammad", "B. Pfahringer"], "venue": "WI\u201916. IEEE Computer Society, 2016, pp. 536\u2013 539.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2016}, {"title": "Using hashtags to capture fine emotion categories from tweets", "author": ["S.M. Mohammad", "S. Kiritchenko"], "venue": "Computational Intelligence, vol. 31, no. 2, pp. 301\u2013326, 2015.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2015}, {"title": "Nrc-canada: Building the state-of-the-art in sentiment analysis of tweets", "author": ["S.M. Mohammad", "S. Kiritchenko", "X. Zhu"], "venue": "arXiv preprint arXiv:1308.6242, 2013.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2013}, {"title": "Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining.", "author": ["S. Baccianella", "A. Esuli", "F. Sebastiani"], "venue": "in LREC,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2010}, {"title": "The psychological meaning of words: Liwc and computerized text analysis methods", "author": ["Y.R. Tausczik", "J.W. Pennebaker"], "venue": "Journal of language and social psychology, vol. 29, no. 1, pp. 24\u201354, 2010.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2010}, {"title": "Seernet at emoint-2017: Tweet emotion intensity estimator", "author": ["V. Duppada", "S. Hiray"], "venue": "Proceedings of the Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis (WASSA), Copenhagen, Denmark, 2017.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2017}, {"title": "Abcnn: Attention-based convolutional neural network for modeling sentence pairs", "author": ["W. Yin", "H. Sch\u00fctze", "B. Xiang", "B. Zhou"], "venue": "arXiv preprint arXiv:1512.05193, 2015.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2015}, {"title": "A large annotated corpus for learning natural language inference", "author": ["S.R. Bowman", "G. Angeli", "C. Potts", "C.D. Manning"], "venue": "arXiv preprint arXiv:1508.05326, 2015.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2015}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["J. Chung", "C. Gulcehre", "K. Cho", "Y. Bengio"], "venue": "arXiv preprint arXiv:1412.3555, 2014.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2014}, {"title": "Dropout: a simple way to prevent neural networks from overfitting.", "author": ["N. Srivastava", "G.E. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2014}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "International Conference on Machine Learning, 2015, pp. 448\u2013456.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2015}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "arXiv preprint arXiv:1412.6980, 2014.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "Keras", "author": ["F. Chollet"], "venue": "https://github.com/fchollet/keras, 2015.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2015}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "IEEE Transactions on knowledge and data engineering, vol. 22, no. 10, pp. 1345\u20131359, 2010.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2010}, {"title": "Bilateral multi-perspective matching for natural language sentences", "author": ["Z. Wang", "W. Hamza", "R. Florian"], "venue": "arXiv preprint arXiv:1702.03814, 2017.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2017}], "referenceMentions": [{"referenceID": 0, "context": "Mining the agreement and disagreement (denoted (dis)agreement) signals helps detect presence of disputes, ideological stance of the participants [1] and unravel beliefs shaping the opinion in general.", "startOffset": 145, "endOffset": 148}, {"referenceID": 1, "context": "This can further be useful for detecting subgroups [2] [3], analyzing how well a new product is being received or analyzing the mood to predict the trends on stock markets [4].", "startOffset": 51, "endOffset": 54}, {"referenceID": 2, "context": "This can further be useful for detecting subgroups [2] [3], analyzing how well a new product is being received or analyzing the mood to predict the trends on stock markets [4].", "startOffset": 55, "endOffset": 58}, {"referenceID": 3, "context": "This can further be useful for detecting subgroups [2] [3], analyzing how well a new product is being received or analyzing the mood to predict the trends on stock markets [4].", "startOffset": 172, "endOffset": 175}, {"referenceID": 4, "context": "In this work, we explore a Siamese [5] inspired deep neural network to detect the presence of (dis)agreement in online discussions between two posts, the quote and the response (Q-R pairs [6]).", "startOffset": 35, "endOffset": 38}, {"referenceID": 5, "context": "In this work, we explore a Siamese [5] inspired deep neural network to detect the presence of (dis)agreement in online discussions between two posts, the quote and the response (Q-R pairs [6]).", "startOffset": 188, "endOffset": 191}, {"referenceID": 6, "context": "[7], [8], [9] used spurt level agreement annotations from the ICSI corpus [10].", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[7], [8], [9] used spurt level agreement annotations from the ICSI corpus [10].", "startOffset": 5, "endOffset": 8}, {"referenceID": 8, "context": "[7], [8], [9] used spurt level agreement annotations from the ICSI corpus [10].", "startOffset": 10, "endOffset": 13}, {"referenceID": 9, "context": "[7], [8], [9] used spurt level agreement annotations from the ICSI corpus [10].", "startOffset": 74, "endOffset": 78}, {"referenceID": 10, "context": "[11] presents detection of agreements in multi-party conversations using the AMI meeting corpus [12].", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[11] presents detection of agreements in multi-party conversations using the AMI meeting corpus [12].", "startOffset": 96, "endOffset": 100}, {"referenceID": 12, "context": "[13] presents a conditional random field based approach for detecting agreement/disagreement between speakers in English broadcast conversations Recently, researchers have turned their attention towards (dis)agreement detection in online discussions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] used various sentiment, emotional and durational features to detect local and global (dis)agreement in discussion forums.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] performed (dis)agreement on annotated posts from the Internet Argument Corpus (IAC) [6].", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[15] performed (dis)agreement on annotated posts from the Internet Argument Corpus (IAC) [6].", "startOffset": 89, "endOffset": 92}, {"referenceID": 15, "context": "Quite recently, [16] proposed a 3-way classification by exploiting meta-thread structures and accommodation between participants.", "startOffset": 16, "endOffset": 20}, {"referenceID": 16, "context": "[17] proposed (dis)agreement detection with an isotonic Conditional Random Fields (isotonic CRF) based sequential model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] proposed features motivated by theoretical predictions to perform (dis)agreement detection.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "Stance detection is the task of identifying whether the author of the text is in favor or against or neutral towards a target, while argument mining focuses on tasks like automatic extraction of arguments from free text, argument proposition classification and argumentative parsing [19] [20].", "startOffset": 283, "endOffset": 287}, {"referenceID": 19, "context": "Stance detection is the task of identifying whether the author of the text is in favor or against or neutral towards a target, while argument mining focuses on tasks like automatic extraction of arguments from free text, argument proposition classification and argumentative parsing [19] [20].", "startOffset": 288, "endOffset": 292}, {"referenceID": 20, "context": "Recently there are studies on how people back up their stances when arguing where comments are classified as either attacking or supporting a set of pre-defined arguments [21].", "startOffset": 171, "endOffset": 175}, {"referenceID": 20, "context": "These tasks (stance detection, argument mining) are not independent but have some common features because of which they are benefited by common building blocks like sentiment detection, textual entailment and sentence similarity [21] [22].", "startOffset": 229, "endOffset": 233}, {"referenceID": 21, "context": "These tasks (stance detection, argument mining) are not independent but have some common features because of which they are benefited by common building blocks like sentiment detection, textual entailment and sentence similarity [21] [22].", "startOffset": 234, "endOffset": 238}, {"referenceID": 15, "context": "The ABCD corpus [16] was curated from Create Debate website1 where users can start a debate by asking a question.", "startOffset": 16, "endOffset": 20}, {"referenceID": 22, "context": "AWTP [23] is formatted in the same way as ABCD.", "startOffset": 5, "endOffset": 9}, {"referenceID": 5, "context": "The Internet Argument Corpus (IAC) [6] is a collection of corpora for research in political debate on internet forums.", "startOffset": 35, "endOffset": 38}, {"referenceID": 4, "context": "The annotators were provided with a Q-R pair and they indicated the level of (dis)agreement on a scale of [-5, 5].", "startOffset": 106, "endOffset": 113}, {"referenceID": 14, "context": "In accordance with prior work of this corpus [15], [16], [18], we converted the scalar values into corresponding (dis)agreement as follows: [-5, -1] is tagged as disagreement, [-1, 1] is tagged as none, [1, 5] is tagged as agreement.", "startOffset": 45, "endOffset": 49}, {"referenceID": 15, "context": "In accordance with prior work of this corpus [15], [16], [18], we converted the scalar values into corresponding (dis)agreement as follows: [-5, -1] is tagged as disagreement, [-1, 1] is tagged as none, [1, 5] is tagged as agreement.", "startOffset": 51, "endOffset": 55}, {"referenceID": 17, "context": "In accordance with prior work of this corpus [15], [16], [18], we converted the scalar values into corresponding (dis)agreement as follows: [-5, -1] is tagged as disagreement, [-1, 1] is tagged as none, [1, 5] is tagged as agreement.", "startOffset": 57, "endOffset": 61}, {"referenceID": 0, "context": "In accordance with prior work of this corpus [15], [16], [18], we converted the scalar values into corresponding (dis)agreement as follows: [-5, -1] is tagged as disagreement, [-1, 1] is tagged as none, [1, 5] is tagged as agreement.", "startOffset": 176, "endOffset": 183}, {"referenceID": 0, "context": "In accordance with prior work of this corpus [15], [16], [18], we converted the scalar values into corresponding (dis)agreement as follows: [-5, -1] is tagged as disagreement, [-1, 1] is tagged as none, [1, 5] is tagged as agreement.", "startOffset": 203, "endOffset": 209}, {"referenceID": 4, "context": "In accordance with prior work of this corpus [15], [16], [18], we converted the scalar values into corresponding (dis)agreement as follows: [-5, -1] is tagged as disagreement, [-1, 1] is tagged as none, [1, 5] is tagged as agreement.", "startOffset": 203, "endOffset": 209}, {"referenceID": 23, "context": "In the recent times distributed representations of words [24] (word2vec [25], GloVe [26]) has shown promise in many NLP tasks and is the driver for success of deep learning in NLP [27].", "startOffset": 57, "endOffset": 61}, {"referenceID": 24, "context": "In the recent times distributed representations of words [24] (word2vec [25], GloVe [26]) has shown promise in many NLP tasks and is the driver for success of deep learning in NLP [27].", "startOffset": 72, "endOffset": 76}, {"referenceID": 25, "context": "In the recent times distributed representations of words [24] (word2vec [25], GloVe [26]) has shown promise in many NLP tasks and is the driver for success of deep learning in NLP [27].", "startOffset": 84, "endOffset": 88}, {"referenceID": 26, "context": "In the recent times distributed representations of words [24] (word2vec [25], GloVe [26]) has shown promise in many NLP tasks and is the driver for success of deep learning in NLP [27].", "startOffset": 180, "endOffset": 184}, {"referenceID": 27, "context": "Word vectors encode semantics in low dimensional space and can be used efficiently for various NLP tasks [28] [29].", "startOffset": 110, "endOffset": 114}, {"referenceID": 13, "context": "Prior work [14] using these lexicons have shown them to give good results.", "startOffset": 11, "endOffset": 15}, {"referenceID": 28, "context": "AFINN [30] word list are manually rated for valence with an integer between -5 (Negative Sentiment) and +5 (Positive Sentiment).", "startOffset": 6, "endOffset": 10}, {"referenceID": 29, "context": "Bing Liu [31] opinion lexicon extract opinion on customer reviews.", "startOffset": 9, "endOffset": 13}, {"referenceID": 30, "context": "+/-EffectWordNet [32] by MPQA group are sense level lexicons.", "startOffset": 17, "endOffset": 21}, {"referenceID": 31, "context": "The NRC Affect Intensity [33] lexicons provide real valued affect intensity.", "startOffset": 25, "endOffset": 29}, {"referenceID": 32, "context": "NRC Word-Emotion Association Lexicon [34] contains 8 sense level associations (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and 2 sentiment level associations (negative and positive).", "startOffset": 37, "endOffset": 41}, {"referenceID": 33, "context": "Expanded NRC WordEmotion Association Lexicon [35] expands the NRC wordemotion association lexicon for twitter specific language.", "startOffset": 45, "endOffset": 49}, {"referenceID": 34, "context": "NRC Hashtag Emotion Lexicon [36] contains emotion word associations computed on emotion labeled twitter corpus via Hashtags.", "startOffset": 28, "endOffset": 32}, {"referenceID": 35, "context": "NRC Hashtag Sentiment Lexicon and Sentiment140 Lexicon [37] contains sentiment word associations computed on twitter corpus via Hashtags and Emoticons.", "startOffset": 55, "endOffset": 59}, {"referenceID": 36, "context": "SentiWordNet [38] assigns to each synset of WordNet three sentiment scores: positivity, negativity, objectivity.", "startOffset": 13, "endOffset": 17}, {"referenceID": 37, "context": "The Linguistic Inquiry Word Count (LIWC) [39] categorizes the words we use in everyday language to reveal our thoughts, feelings, personality, and motivations.", "startOffset": 41, "endOffset": 45}, {"referenceID": 38, "context": "The lexicon feature extractor was inspired from [40].", "startOffset": 48, "endOffset": 52}, {"referenceID": 39, "context": "A lot of NLP tasks like natural language inference, textual entailment, answer selection, paraphrase identification etc involve modelling a pair of sentences so that they perform well on a particular task or multitude of such tasks [41].", "startOffset": 232, "endOffset": 236}, {"referenceID": 4, "context": "For this task we used an architecture which is inspired by Siamese network [5] and Stanford Natural Language Inference model [42] with identical networks encoding Q-R pair.", "startOffset": 75, "endOffset": 78}, {"referenceID": 40, "context": "For this task we used an architecture which is inspired by Siamese network [5] and Stanford Natural Language Inference model [42] with identical networks encoding Q-R pair.", "startOffset": 125, "endOffset": 129}, {"referenceID": 41, "context": "First, GloVe word embeddings are fed to Gated Recurrent Units [43] to create a sentence embedding.", "startOffset": 62, "endOffset": 66}, {"referenceID": 42, "context": "We have used relu non-linearity, dropout [44] for regularization and batch normalization [45] for accelerating training.", "startOffset": 41, "endOffset": 45}, {"referenceID": 43, "context": "We have used relu non-linearity, dropout [44] for regularization and batch normalization [45] for accelerating training.", "startOffset": 89, "endOffset": 93}, {"referenceID": 44, "context": "The network is optimized with adam [46] optimizer with learning rate of 0.", "startOffset": 35, "endOffset": 39}, {"referenceID": 45, "context": "We used keras [47] deep learning framework to train our models.", "startOffset": 14, "endOffset": 18}, {"referenceID": 15, "context": "Thus, by fusing both the GRU encoded embeddings and the lexicons, we achieved the state of the art results on the ABCD dataset by beating the previous best model\u2019s [16] average F1 score with margin of 4% percentage.", "startOffset": 164, "endOffset": 168}, {"referenceID": 15, "context": "System Precision Recall Weighted F1 Score SOTA [16] 0.", "startOffset": 47, "endOffset": 51}, {"referenceID": 46, "context": "In the recent times, with the availability of huge amount of data a new paradigm in machine learning called Transfer Learning [48] has come into play.", "startOffset": 126, "endOffset": 130}, {"referenceID": 15, "context": "Model Precision Recall Weighted F1 Score SOTA [16] 0.", "startOffset": 46, "endOffset": 50}, {"referenceID": 15, "context": "Model Precision Recall Weighted F1 Score SOTA [16] 0.", "startOffset": 46, "endOffset": 50}, {"referenceID": 39, "context": "With the availability of a large standard dataset for (dis)agreement classification, we can try various recent advanced state of the art architectures for modelling sentences pairs [41], [49] to further improve the performance.", "startOffset": 181, "endOffset": 185}, {"referenceID": 47, "context": "With the availability of a large standard dataset for (dis)agreement classification, we can try various recent advanced state of the art architectures for modelling sentences pairs [41], [49] to further improve the performance.", "startOffset": 187, "endOffset": 191}], "year": 2017, "abstractText": "This paper presents models for detecting agreement/disagreement in online discussions. In this work we show that by using a Siamese inspired architecture to encode the discussions, we no longer need to rely on hand-crafted features to exploit the meta thread structure. We evaluate our model on existing online discussion corpora ABCD, IAC and AWTP. Experimental results on ABCD dataset show that by fusing lexical and word embedding features, our model achieves the state of the art performance of 0.804 average F1 score. We also show that the model trained on ABCD dataset performs competitively on relatively smaller annotated datasets (IAC and", "creator": "LaTeX with hyperref package"}}}