{"id": "1708.06185", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Aug-2017", "title": "Seernet at EmoInt-2017: Tweet Emotion Intensity Estimator", "abstract": "The paper describes experiments on estimating emotion intensity in tweets using a generalized regressor system. The system combines lexical, syntactic and pre-trained word embedding features, trains them on general regressors and finally combines the best performing models to create an ensemble. The proposed system stood 3rd out of 22 systems in the leaderboard of WASSA-2017 Shared Task on Emotion Intensity.", "histories": [["v1", "Mon, 21 Aug 2017 12:30:48 GMT  (245kb,D)", "http://arxiv.org/abs/1708.06185v1", "In Proceedings of the EMNLP 2017 Workshop on Computational Approaches to Subjectivity, Sentiment, and Social Media (WASSA), September 2017, Copenhagen, Denmark"]], "COMMENTS": "In Proceedings of the EMNLP 2017 Workshop on Computational Approaches to Subjectivity, Sentiment, and Social Media (WASSA), September 2017, Copenhagen, Denmark", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["venkatesh duppada", "sushant hiray"], "accepted": false, "id": "1708.06185"}, "pdf": {"name": "1708.06185.pdf", "metadata": {"source": "CRF", "title": "Seernet at EmoInt-2017: Tweet Emotion Intensity Estimator", "authors": ["Venkatesh Duppada"], "emails": ["sushant.hiray}@seernet.io"], "sections": [{"heading": "1 Introduction", "text": "It is estimated that almost 500 million tweets are sent per day1. Twitter data is particularly interesting because of its particular nature, where people send messages in short sentences using hashtags, emoticons, emojis, etc. In addition, each tweet has metadata such as location and language used by the sender. It is difficult to analyze this data because the tweets may be grammatically incorrect and users tend to use informal and slang words all the time. Therefore, this poses an interesting problem for NLP researchers. Any progress in using this rich and varied data can help to understand and analyze information about a person, an event, a product, an organization, or a country as a whole. Many notable uses of the twitter can be found here.In addition to the similar lines, The Task 1 of WASSA2017 (Mohammad and Bravo-Marquez, 2017c) describe this problem of emotion intensity / system: htexplorely / Sweets."}, {"heading": "2 System Description", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Preprocessing", "text": "Tweets are processed using Tweetokenize Tool3. Twitter-specific features are replaced as follows: username handles to USERNAME, phone numbers to PHONENUMBER, numbers to NUMBER, URLs to URLs and times to TIME. A continuous sequence of emojis is split into individual tokens. Finally, all tokens are converted to lowercase letters."}, {"heading": "2.2 Feature Extraction", "text": "On the other hand, the semantic meaning of words, sentences and documents using \"low dimensional vectors\" (Mikolov et al., 2013) instead of \"hot encoding vectors which are sparse and high dimensional.\" Finally, there are traditional NLP features such as Word N-grams, letter N-grams and word clusters that are known to be different tasksks.Based on these observations, the function extraction step is implemented as a union of different independent features."}, {"heading": "2.3 Regression", "text": "The Dev dataset (Mohammad and BravoMarquez, 2017b) in the competition was small, so the Tensile and Dev datasets were merged to perform a 10-fold cross-validation, one model was trained at each fold, and the predictions were col-6http: / / www.cs.cmu.edu / \u02dc ark / TweetNLP / lected on the remaining dataset. Predictions are averaged across all folds to generalize the solution and prevent overmatch. As described in Section 2.2, different combinations of feature extractors were used. After feature extraction, the data were then passed to various regressors that support Vector regression, AdaBoost, RandomForestRegressor, and Bagging Regressor of sklearn (Pedregosa et al., 2011). Finally, the most powerful models selected showed the lowest error in the evaluation metric coefficient and ranking correlation, Pearson's Rank Correlation."}, {"heading": "2.4 Parameter Optimization", "text": "In order to find the optimal parameter values for the EmoInt system, scikit-Learn carried out an extensive grid search across all subsets of the training set (shuffled), using a layered 10-fold cross-validation and the optimization of the Pearson correlation value. Best results of the cross-validation were obtained using AdaBoost meta-regressor with base regressor as XGBoost (Chen and Guestrin, 2016) with 1000 estimators and 0.1 learning rate. Experiments and analyses of the results will be presented in the next section."}, {"heading": "3 Results and Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Experimental Results", "text": "As described in Section 2.2, various syntax functions were used, namely: Part-of-Speech tags, brown clusters of the TweetNLP project, but they did not perform well in cross-validation, so they were deleted from the final system. While the grid search is performed as mentioned in Section 2.4, while all lexicon-based functions remain the same, the choice of combination of emoji vectors and word vectors is varied to minimize the metric of cross-validation. Table 1 describes the results for experiments performed with different combinations of word vectors. Emoji embeddings (Eisner et al., 2016) provide better results than pure GloVe and Edinburgh embeddings. Embeddings in Edinburgh exceed GloVe embeddings in the Joy and Sadness category, but lag behind in the Anger and Fear categories. The official submission consisted of the most powerful model for each emotion category. This system took 3rd place for the entire test data set, and the second place for each subset was increased by 0.5, with the intensity of each note."}, {"heading": "3.2 Feature Importance", "text": "The relative importance of the characteristics can be judged by the relative depth of the characteristic used as a decision node in the tree. Characteristics used at the top of the tree contribute to the final predictive decision of a larger proportion of the input samples. Therefore, the expected proportion of the samples to which they contribute can be used as an estimate of the relative importance of the characteristics. By averaging the measurement over several randomly selected trees, the variance of the estimate can be reduced and used as a measure of the relative importance of the characteristics. Figure 2 shows diagrams of the feature meaning for each emotion to derive which characteristics play the most important role in the identification of emotional intensity in tweets. + / EffectWordNet (Choi and Wiebe, 2014), NRC Hashtag Sentiment Lexicon, Sentiment140 Lexicon (Mohammad et al., 2013) and NRC Hashtag Emotion Lexicon (Mohammad and Kiritko, 2015) play the most important role."}, {"heading": "3.3 System Limitations", "text": "Table 2 analyzes when the system performs best and worst for each emotion. Since the features used are largely lexicon-based, the system has difficulty capturing the general mood, and it results in amplified or disappearing intensity signals. For example, the system has difficulty understanding sarcastic tweets, for example, in the third tweet of anger expressed by the user, but the general sentence does not imply fear. A similar pattern is found in the fourth example of anger and in the third example of joy. The system also has difficulty understanding sarcastic tweets, for example, in the third tweet of anger used by the user but used most of the time in a positive sense, and therefore the system has done a bad job in predicting intensity. The system also fails to understand sentences with deeper emotions and feelings that the person with little context can understand. For example, the tweet in example in example in example in example in example in example in example in example in example in example in example in example in example in example in 4 of sadness, the post-people can understand it."}, {"heading": "4 Future Work & Conclusion", "text": "The paper examines the effectiveness of different affective lexicons word embedding to estimate the emotional intensity in tweets. A lightweight, easy-to-use Affect Computing Framework (EmoInt) to facilitate experimentation with various lexicon functions for text tasks is open source. It provides plug-and-play access to various feature extractors and handy scripts for creating ensembles. Few problems explained in the analysis section can be solved with the help of sentence embeddings that take into account context information. Functions used in the system are generic enough to use them in other affective computing tasks on social media text, not just tweet data. Another interesting feature of lexicon-based systems is their good runtime performance during prediction that future work to measure the performance of the system may prove crucial for use in a real environment."}, {"heading": "Acknowledgement", "text": "We would like to thank the organizers of the WASSA-2017 Shared Task on Emotion Intensity for providing the data, guidelines and timely support."}], "references": [{"title": "Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining", "author": ["Stefano Baccianella", "Andrea Esuli", "Fabrizio Sebastiani"], "venue": "In LREC", "citeRegEx": "Baccianella et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Baccianella et al\\.", "year": 2010}, {"title": "Determining word\u2013emotion associations from tweets by multilabel classification", "author": ["Felipe Bravo-Marquez", "Eibe Frank", "Saif M Mohammad", "Bernhard Pfahringer."], "venue": "WI\u201916. IEEE Computer Society, pages 536\u2013539.", "citeRegEx": "Bravo.Marquez et al\\.,? 2016", "shortCiteRegEx": "Bravo.Marquez et al\\.", "year": 2016}, {"title": "From unlabelled tweets to twitterspecific opinion words", "author": ["Felipe Bravo-Marquez", "Eibe Frank", "Bernhard Pfahringer."], "venue": "Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM,", "citeRegEx": "Bravo.Marquez et al\\.,? 2015", "shortCiteRegEx": "Bravo.Marquez et al\\.", "year": 2015}, {"title": "Class-based n-gram models of natural language", "author": ["Peter F Brown", "Peter V Desouza", "Robert L Mercer", "Vincent J Della Pietra", "Jenifer C Lai."], "venue": "Computational linguistics 18(4):467\u2013479.", "citeRegEx": "Brown et al\\.,? 1992", "shortCiteRegEx": "Brown et al\\.", "year": 1992}, {"title": "Xgboost: A scalable tree boosting system", "author": ["Tianqi Chen", "Carlos Guestrin."], "venue": "Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, pages 785\u2013794.", "citeRegEx": "Chen and Guestrin.,? 2016", "shortCiteRegEx": "Chen and Guestrin.", "year": 2016}, {"title": "+/effectwordnet: Sense-level lexicon acquisition for opinion inference", "author": ["Yoonjung Choi", "Janyce Wiebe."], "venue": "EMNLP. pages 1181\u20131191.", "citeRegEx": "Choi and Wiebe.,? 2014", "shortCiteRegEx": "Choi and Wiebe.", "year": 2014}, {"title": "emoji2vec: Learning emoji representations from their description", "author": ["Ben Eisner", "Tim Rockt\u00e4schel", "Isabelle Augenstein", "Matko Bo\u0161njak", "Sebastian Riedel."], "venue": "arXiv preprint arXiv:1609.08359 .", "citeRegEx": "Eisner et al\\.,? 2016", "shortCiteRegEx": "Eisner et al\\.", "year": 2016}, {"title": "Mining and summarizing customer reviews", "author": ["Minqing Hu", "Bing Liu."], "venue": "Proceedings of the tenth", "citeRegEx": "Hu and Liu.,? 2004", "shortCiteRegEx": "Hu and Liu.", "year": 2004}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in neural information processing systems. pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Word affect intensities", "author": ["Saif M Mohammad."], "venue": "arXiv preprint arXiv:1704.08798 .", "citeRegEx": "Mohammad.,? 2017", "shortCiteRegEx": "Mohammad.", "year": 2017}, {"title": "Emotion intensities in tweets", "author": ["Saif M. Mohammad", "Felipe Bravo-Marquez"], "venue": null, "citeRegEx": "Mohammad and Bravo.Marquez.,? \\Q2017\\E", "shortCiteRegEx": "Mohammad and Bravo.Marquez.", "year": 2017}, {"title": "Emotion intensities in tweets", "author": ["Saif M. Mohammad", "Felipe Bravo-Marquez."], "venue": "Proceedings of the sixth joint conference on lexical and computational semantics (*Sem). Vancouver, Canada.", "citeRegEx": "Mohammad and Bravo.Marquez.,? 2017b", "shortCiteRegEx": "Mohammad and Bravo.Marquez.", "year": 2017}, {"title": "Wassa-2017 shared task on emotion intensity", "author": ["Saif M. Mohammad", "Felipe Bravo-Marquez."], "venue": "EMNLP 2017 Workshop on Computational Approaches to Subjectivity, Sentiment, and Social Media (WASSA), Copenhagen, Denmark.", "citeRegEx": "Mohammad and Bravo.Marquez.,? 2017c", "shortCiteRegEx": "Mohammad and Bravo.Marquez.", "year": 2017}, {"title": "Using hashtags to capture fine emotion categories from tweets", "author": ["Saif M Mohammad", "Svetlana Kiritchenko."], "venue": "Computational Intelligence 31(2):301\u2013326.", "citeRegEx": "Mohammad and Kiritchenko.,? 2015", "shortCiteRegEx": "Mohammad and Kiritchenko.", "year": 2015}, {"title": "Nrc-canada: Building the stateof-the-art in sentiment analysis of tweets", "author": ["Saif M Mohammad", "Svetlana Kiritchenko", "Xiaodan Zhu."], "venue": "arXiv preprint arXiv:1308.6242 .", "citeRegEx": "Mohammad et al\\.,? 2013", "shortCiteRegEx": "Mohammad et al\\.", "year": 2013}, {"title": "Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon", "author": ["Saif M Mohammad", "Peter D Turney."], "venue": "Proceedings of the NAACL HLT 2010 workshop on computational approaches to analysis and gen-", "citeRegEx": "Mohammad and Turney.,? 2010", "shortCiteRegEx": "Mohammad and Turney.", "year": 2010}, {"title": "A new anew: Evaluation of a word list for sentiment analysis in microblogs", "author": ["Finn \u00c5rup Nielsen."], "venue": "arXiv preprint arXiv:1103.2903 .", "citeRegEx": "Nielsen.,? 2011", "shortCiteRegEx": "Nielsen.", "year": 2011}, {"title": "Improved part-of-speech tagging for online conversational text with word", "author": ["Olutobi Owoputi", "Brendan O\u2019Connor", "Chris Dyer", "Kevin Gimpel", "Nathan Schneider", "Noah A Smith"], "venue": null, "citeRegEx": "Owoputi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Owoputi et al\\.", "year": 2013}, {"title": "Scikit-learn: Machine learning", "author": ["F. Pedregosa", "G. Varoquaux", "A. Gramfort", "V. Michel", "B. Thirion", "O. Grisel", "M. Blondel", "P. Prettenhofer", "R. Weiss", "V. Dubourg", "J. Vanderplas", "A. Passos", "D. Cournapeau", "M. Brucher", "M. Perrot", "E. Duchesnay"], "venue": null, "citeRegEx": "Pedregosa et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Pedregosa et al\\.", "year": 2011}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "EMNLP. volume 14, pages 1532\u2013 1543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "The edinburgh twitter corpus", "author": ["Sasa Petrovic", "Miles Osborne", "Victor Lavrenko."], "venue": "Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media. pages 25\u201326.", "citeRegEx": "Petrovic et al\\.,? 2010", "shortCiteRegEx": "Petrovic et al\\.", "year": 2010}, {"title": "Sentiment strength detection in short informal text", "author": ["Mike Thelwall", "Kevan Buckley", "Georgios Paltoglou", "Di Cai", "Arvid Kappas."], "venue": "Journal of the American Society for Information Science and Technology 61(12):2544\u20132558.", "citeRegEx": "Thelwall et al\\.,? 2010", "shortCiteRegEx": "Thelwall et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 12, "context": "Along the similar lines, The Task 1 of WASSA2017 (Mohammad and Bravo-Marquez, 2017c) poses a problem of finding emotion intensity of", "startOffset": 49, "endOffset": 84}, {"referenceID": 8, "context": "and compactly represented using low dimensional vectors (Mikolov et al., 2013) instead of one hot encoding vectors which are sparse and high dimensional.", "startOffset": 56, "endOffset": 78}, {"referenceID": 16, "context": "Lexicon Features: AFINN (Nielsen, 2011) word list are manually rated for valence with an integer between -5 (Negative Sentiment) and +5 (Positive Sentiment).", "startOffset": 24, "endOffset": 39}, {"referenceID": 7, "context": "Bing Liu (Hu and Liu, 2004) opinion lexicon extract opinion on customer reviews.", "startOffset": 9, "endOffset": 27}, {"referenceID": 5, "context": "+/-EffectWordNet (Choi and Wiebe, 2014) by MPQA group are sense level lexicons.", "startOffset": 17, "endOffset": 39}, {"referenceID": 9, "context": "The NRC Affect Intensity (Mohammad, 2017) lexicons provide real valued affect intensity.", "startOffset": 25, "endOffset": 41}, {"referenceID": 15, "context": "NRC Word-Emotion Association Lexicon (Mohammad and Turney, 2010) contains 8 sense level associations (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and 2 sentiment level associations (negative and positive).", "startOffset": 37, "endOffset": 64}, {"referenceID": 13, "context": "NRC Hashtag Emotion Lexicon (Mohammad and Kiritchenko, 2015) contains emotion word associations computed on emotion labeled twitter corpus via Hashtags.", "startOffset": 28, "endOffset": 60}, {"referenceID": 14, "context": "NRC Hashtag Sentiment Lexicon and Sentiment140 Lexicon (Mohammad et al., 2013) contains sentiment word associations computed on twitter corpus via Hashtags and Emoticons.", "startOffset": 55, "endOffset": 78}, {"referenceID": 0, "context": "SentiWordNet (Baccianella et al., 2010) assigns to each synset of WordNet", "startOffset": 13, "endOffset": 39}, {"referenceID": 21, "context": "In addition to these, SentiStrength (Thelwall et al., 2010) application which estimates the strength of positive and negative sentiment from tweets is also added.", "startOffset": 36, "endOffset": 59}, {"referenceID": 19, "context": "GloVe (Pennington et al., 2014) is an unsupervised learning algorithm for obtaining vector representations for words.", "startOffset": 6, "endOffset": 31}, {"referenceID": 2, "context": "Edinburgh embeddings (Bravo-Marquez et al., 2015) are obtained by training skip-gram model on Edinburgh corpus (Petrovic et al.", "startOffset": 21, "endOffset": 49}, {"referenceID": 20, "context": ", 2015) are obtained by training skip-gram model on Edinburgh corpus (Petrovic et al., 2010).", "startOffset": 69, "endOffset": 92}, {"referenceID": 6, "context": "Since tweets are abundant with emojis, Emoji embeddings (Eisner et al., 2016) which are learned from the emoji descriptions have been used.", "startOffset": 56, "endOffset": 77}, {"referenceID": 17, "context": "Syntactic Features: Syntax specific features such as Word N-grams, Part-Of-Speech N-grams (Owoputi et al., 2013), Brown Cluster N-grams (Brown et al.", "startOffset": 90, "endOffset": 112}, {"referenceID": 3, "context": ", 2013), Brown Cluster N-grams (Brown et al., 1992) obtained using TweetNLP 6 project have been integrated into the system.", "startOffset": 31, "endOffset": 51}, {"referenceID": 18, "context": "After performing feature extraction, the data was then passed to various regressors Support Vector Regression, AdaBoost, RandomForestRegressor, and, BaggingRegressor of sklearn (Pedregosa et al., 2011).", "startOffset": 177, "endOffset": 201}, {"referenceID": 4, "context": "Best cross-validation results were obtained using AdaBoost meta regressor with base regressor as XGBoost (Chen and Guestrin, 2016) with 1000 estimators and 0.", "startOffset": 105, "endOffset": 130}, {"referenceID": 6, "context": "Emoji embeddings (Eisner et al., 2016) give better results than using plain GloVe and Edinburgh embeddings.", "startOffset": 17, "endOffset": 38}, {"referenceID": 5, "context": "+/-EffectWordNet (Choi and Wiebe, 2014), NRC Hashtag Sentiment Lexicon, Sentiment140 Lexicon (Mohammad et al.", "startOffset": 17, "endOffset": 39}, {"referenceID": 14, "context": "+/-EffectWordNet (Choi and Wiebe, 2014), NRC Hashtag Sentiment Lexicon, Sentiment140 Lexicon (Mohammad et al., 2013) and NRC Hashtag Emotion Lexicon (Mohammad and Kiritchenko, 2015) are playing the most important role.", "startOffset": 93, "endOffset": 116}, {"referenceID": 13, "context": ", 2013) and NRC Hashtag Emotion Lexicon (Mohammad and Kiritchenko, 2015) are playing the most important role.", "startOffset": 40, "endOffset": 72}], "year": 2017, "abstractText": "The paper describes experiments on estimating emotion intensity in tweets using a generalized regressor system. The system combines lexical, syntactic and pretrained word embedding features, trains them on general regressors and finally combines the best performing models to create an ensemble. The proposed system stood 3rd out of 22 systems in the leaderboard of WASSA-2017 Shared Task on Emotion Intensity.", "creator": "LaTeX with hyperref package"}}}