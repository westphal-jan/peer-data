{"id": "1708.06850", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Aug-2017", "title": "Learning Deep Neural Network Representations for Koopman Operators of Nonlinear Dynamical Systems", "abstract": "The Koopman operator has recently garnered much attention for its value in dynamical systems analysis and data-driven model discovery. However, its application has been hindered by the computational complexity of extended dynamic mode decomposition; this requires a combinatorially large basis set to adequately describe many nonlinear systems of interest, e.g. cyber-physical infrastructure systems, biological networks, social systems, and fluid dynamics. Often the dictionaries generated for these problems are manually curated, requiring domain-specific knowledge and painstaking tuning. In this paper we introduce a deep learning framework for learning Koopman operators of nonlinear dynamical systems. We show that this novel method automatically selects efficient deep dictionaries, outperforming state-of-the-art methods. We benchmark this method on partially observed nonlinear systems, including the glycolytic oscillator and show it is able to predict quantitatively 100 steps into the future, using only a single timepoint, and qualitative oscillatory behavior 400 steps into the future.", "histories": [["v1", "Tue, 22 Aug 2017 23:32:19 GMT  (6231kb,D)", "http://arxiv.org/abs/1708.06850v1", "16 pages, 5 figures"]], "COMMENTS": "16 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["enoch yeung", "soumya kundu", "nathan hodas"], "accepted": false, "id": "1708.06850"}, "pdf": {"name": "1708.06850.pdf", "metadata": {"source": "CRF", "title": "Learning Deep Neural Network Representations for Koopman Operators of Nonlinear Dynamical Systems", "authors": ["Enoch Yeung"], "emails": ["enoch.yeung@pnnl.gov", "soumya.kundu@pnnl.gov", "nathan.hodas@pnnl.gov"], "sections": [{"heading": null, "text": "The Koopman operator has lately received a lot of attention for its value in analyzing dynamic systems and data-driven model discovery, but its application has been hampered by the computational complexity of advanced dynamic mode decomposition, which requires a combinatorial large base to adequately describe many nonlinear systems of interest, such as cyber-physical infrastructure systems, biological networks, social systems, and flow dynamics. Frequently, the dictionaries generated for these problems are manually curated, requiring industry-specific knowledge and careful tuning. In this paper, we present a deep learning framework for coopman operators of nonlinear dynamic systems, and show that this novel method automatically selects efficient deep dictionaries, surpassing the state of the art. We measure this method against partially observed nonlinear systems, including the glycolytic oscillator, and show that it is capable of predicting the 100-step, quantitatively predicting the only 870 steps in the future."}, {"heading": "1 Introduction", "text": "This year, it has come to the point where there is only one person who is able to transform into another person, in order to find another person who is able to transform into another person."}, {"heading": "2 Deep Dynamic Mode Decomposition for Koopman Operator Learning", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Extended Dynamic Mode Decomposition", "text": "We consider a discrete time nonlinear dynamic system of form Consider a discrete time system of form xn + 1 = f (xn) yk = h (xn) (1), where f-Rn is continuously differentiable and h-Rp is continuously differentiatable. Function f is the state-space model and function h-maps current state values xk. (2), where it is an observable function, where m-Rp defines the elevated space of the observable. In theory, it must belong to a space of the observable. (yk) It is a space of the observable. (yk) is a space of the observable."}, {"heading": "2.2 Deep Dynamic Mode Decomposition", "text": "The advantage of using deep neural networks is that they have a rich expressivity [10, 11], but can be automatically formed and extended to extremely large networks [12]. With each additional level, the number of new nonlinear functions can grow combinatorial, but only with a linear increase in model parameters. We set up the deep coopman learning problem as a consequence. Define the deep dictionary asDNN = Native Operator (7), where the number of new nonlinear functions grows combinatorial, but only with a linear increase in model parameters. Define the deep dictionary operator learning problem as a consequence. Define the deep dictionary asDNN = Native Operator (7), where the number of nonlinear functions is combinatory. The coopman operator problem is similar to that of extended dynamic composition: min coopman mode decomposition."}, {"heading": "3 Experimental Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 The Emergence of Koopman Basis Functions During Training", "text": "This year it has come to the point where it will be able to take the lead, \"he said in an interview with the German Press Agency.\" We have never lost as much time as this year, \"he said,\" but we are not yet able to do it. \""}, {"heading": "3.2 Learning A Koopman Operator for the Glycolysis Pathway", "text": "The ultimate measure of whether a Koopman operator has been learned successfully or not is whether the operator is able to predict several points into the future, using only a single root point in time. Any small amount of error in the Koopman operator estimate will spread and spill over itself. Furthermore, the ultimate challenge is to learn the Koopman operator in a nonlinear system for which there is no known carleman linearization or coopman invariant subspaces. The glycolysis pathway is a fundamental pathway to metabolism in biology. We use the standard model introduced in [15], a nonlinear seven-step model with Michaelis set dynamics. It results in the following image: dS1 dt = J0 \u2212 k1S1S6 + (S6 / K1) q, dS2 dt = S1S1S1S1S6 + 1 \u2212 S1 \u2212 S1 (S1 \u2212 Sdt = 7 \u2212 4 \u2212 Sdt \u2212 4 \u2212 Sdt = 4 \u2212 Sdt \u2212 4 \u2212 Sdt \u2212 4 \u2212 4 \u2212 Sdt \u2212 4 \u2212 S1 \u2212 Sdt \u2212 4 \u2212 Sdt \u2212 4 \u2212 4 \u2212 Sdt \u2212 4 \u2212 S1 \u2212 Sdt \u2212 4 \u2212 4 \u2212 Sdt \u2212 4 \u2212 Sdt \u2212 4dt \u2212 S3dt = 7 \u2212 4 \u2212 S3dt \u2212 S1 \u2212 S1 \u2212 Sdt \u2212 S1 \u2212 Sdt \u2212 7 \u2212 S1 \u2212 Sdt \u2212 7 \u2212 S1 \u2212 Sdt \u2212 3dt = 7 \u2212 S1 \u2212 3dt = 7 \u2212 S1 \u2212 S1 \u2212 Sdt \u2212 S1 \u2212 4 \u2212 Sdt \u2212 4 \u2212 Sdt \u2212 3dt = 7 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 Sdt = 7 \u2212 3dt = 7 \u2212 S1 \u2212 3dt = 7 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 7 \u2212 Sdt = 7 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 3dt = 7 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 7 \u2212 S1 \u2212 S1 \u2212 7 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S"}, {"heading": "3.3 Learning Koopman Operators on Power Systems", "text": "There are several time scales of dynamics involved in power systems; transient dynamics represent the fastest of all time scales. However, transient instability often leads to instability at frequency and voltage levels, which can lead to cascading power outages. Transient dynamic models are often calibrated, but small variations in parameters and real-time state uncertainty are often unknown. However, measurement data for rotor velocity and angle are often available, which motivates the use of data-driven methods to discover real-time relationships between flow variables and swing dynamics. Furthermore, the discovery of a coopman operator from data allows the direct application of linear planning methods that have traditionally been approached using brute force simulations."}, {"heading": "4 Conclusion", "text": "Our automated dictionary approach, enabled by deep learning, improves the performance of the Koopman operator for longer-term predictions. We compared it to the current state of the art, advanced decomposition of dynamic mode, and demonstrated that the deep Koopman operator performs relatively well in many cases in multi-stage prediction tasks. Our results suggest that the deep Koopman operator is a complementary and promising alternative to advanced dynamic mode decomposition approaches for data-driven modeling problems of complex nonlinear systems."}], "references": [{"title": "Hamiltonian systems and transformation in Hilbert space", "author": ["B.O. Koopman"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1931}, {"title": "A data-driven approximation of the koopman operator: Extending dynamic mode decomposition", "author": ["M.O. Williams", "I.G. Kevrekidis", "C.W. Rowley"], "venue": "Journal of Nonlinear Science,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Discovering governing equations from data by sparse identification of nonlinear dynamical systems", "author": ["S.L. Brunton", "J.L. Proctor", "J.N. Kutz"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Dynamic mode decomposition with control", "author": ["J.L. Proctor", "S.L. Brunton", "J.N. Kutz"], "venue": "SIAM Journal on Applied Dynamical Systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Extended dynamic mode decomposition with dictionary learning: a data-driven adaptive spectral decomposition of the Koopman operator. arXiv preprint arXiv:1707.00225", "author": ["Q. Li", "F. Dietrich", "E.M. Bollt", "I.G. Kevrekidis"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2017}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980", "author": ["D. Kingma", "J. Ba"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["N. Srivastava", "G.E. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "Journal of machine learning research,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "On the expressive power of deep neural networks. arXiv preprint arXiv:1606.05336", "author": ["M. Raghu", "B. Poole", "J. Kleinberg", "S. Ganguli", "J. Sohl-Dickstein"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "On the expressive power of deep architectures.", "author": ["Bengio", "Yoshua", "Olivier Delalleau"], "venue": "International Conference on Algorithmic Learning Theory. Springer Berlin Heidelberg,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Better Mixing via Deep Representations", "author": ["Y. Bengio", "G. Mesnil", "Y. Dauphin", "S. Rifai"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Nonlinear dynamical systems and Carleman linearization", "author": ["K. Kowalski", "W.H. Steeb"], "venue": "World Scientific", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1991}, {"title": "Necessary and sufficient conditions for dynamical structure reconstruction of LTI networks", "author": ["J. Gona\u0327lves", "S. Warnick"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Efficient inference of parsimonious phenomenological models of cellular dynamics using S-systems and alternating regression", "author": ["B.C. Daniels", "I. Nemenman"], "venue": "PloS one,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Power system stability and control", "author": ["P. Kundur"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1994}, {"title": "Power system transient stability analysis using the transient energy function method", "author": ["Fouad", "Abdel-Azia", "Vijay Vittal"], "venue": "Pearson Education,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1991}, {"title": "Massive contingency analysis with high performance computing", "author": ["Z. Huang", "Y. Chen", "Nieplocha", "July"], "venue": "In Power & Energy Society General Meeting,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "Nonlinear Koopman modes and coherency identification of coupled swing dynamics", "author": ["Y. Susuki", "I. Mezic"], "venue": "IEEE Transactions on Power Systems,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Nonlinear Koopman modes and a precursor to power system swing instabilities", "author": ["Y. Susuki", "I. Mezic"], "venue": "IEEE Transactions on Power Systems,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Global stability analysis using the eigenfunctions of the Koopman operator", "author": ["A. Mauroy", "I. Mezi"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Koopman published a paper showing that the evolution of any set of observables on a dynamical system can be expressed through the action of an infinite dimensional linear operator, the Koopman operator [1].", "startOffset": 202, "endOffset": 205}, {"referenceID": 1, "context": "For this reason, the Koopman operator has gained attention as an effective tool for data-driven model discovery [2, 3, 4].", "startOffset": 112, "endOffset": 121}, {"referenceID": 2, "context": "For this reason, the Koopman operator has gained attention as an effective tool for data-driven model discovery [2, 3, 4].", "startOffset": 112, "endOffset": 121}, {"referenceID": 3, "context": "For this reason, the Koopman operator has gained attention as an effective tool for data-driven model discovery [2, 3, 4].", "startOffset": 112, "endOffset": 121}, {"referenceID": 1, "context": "In extended dynamic mode decomposition, the idea is to lift the set of system observables from its native vector space into a higher dimensional space, usually through a nonlinear transformation [2].", "startOffset": 195, "endOffset": 198}, {"referenceID": 4, "context": "The ideas in this paper are complementary to the recent work presented in [5].", "startOffset": 74, "endOffset": 77}, {"referenceID": 4, "context": "In [5], the authors consider a 3-layer neural network with fixed depth and tanh activation functions to learn the dynamics of the Duffing oscillator and Kuramoto-Sivahinsky system.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "AdaGrad [6], ADAM [7] with hiearchical dropout [8] for network regularization.", "startOffset": 8, "endOffset": 11}, {"referenceID": 6, "context": "AdaGrad [6], ADAM [7] with hiearchical dropout [8] for network regularization.", "startOffset": 18, "endOffset": 21}, {"referenceID": 7, "context": "AdaGrad [6], ADAM [7] with hiearchical dropout [8] for network regularization.", "startOffset": 47, "endOffset": 50}, {"referenceID": 8, "context": "The advantage of employing deep neural networks is that they have rich expressivity [10, 11], can be trained automatically, and scale to extremely large networks [12].", "startOffset": 84, "endOffset": 92}, {"referenceID": 9, "context": "The advantage of employing deep neural networks is that they have rich expressivity [10, 11], can be trained automatically, and scale to extremely large networks [12].", "startOffset": 84, "endOffset": 92}, {"referenceID": 10, "context": "The advantage of employing deep neural networks is that they have rich expressivity [10, 11], can be trained automatically, and scale to extremely large networks [12].", "startOffset": 162, "endOffset": 166}, {"referenceID": 11, "context": "In reality, unless the system can be Carleman linearized [13], it is difficult to ascertain the complete dictionary.", "startOffset": 57, "endOffset": 61}, {"referenceID": 12, "context": "For discrete time linear systems, a closed form expression for the Koopman operator exists, called the dynamical structure function [14].", "startOffset": 132, "endOffset": 136}, {"referenceID": 13, "context": "We use the standard model introduced in [15], a seven state nonlinear model with Michaelis-Menten dynamics.", "startOffset": 40, "endOffset": 44}, {"referenceID": 14, "context": "Our next example is a multi-machine power systems network [16].", "startOffset": 58, "endOffset": 62}, {"referenceID": 15, "context": "In addition, discovering a Koopman operator from data enables direct application of linear analysis methods for contingency planning [18], which has traditionally been addressed using brute-force simulation studies [19].", "startOffset": 133, "endOffset": 137}, {"referenceID": 16, "context": "In addition, discovering a Koopman operator from data enables direct application of linear analysis methods for contingency planning [18], which has traditionally been addressed using brute-force simulation studies [19].", "startOffset": 215, "endOffset": 219}, {"referenceID": 17, "context": "The system has 39 buses and 10 generators; it is a classical model system that has been well studied in the context of coherency and spectral modes, especially using the Koopman operator [20].", "startOffset": 187, "endOffset": 191}, {"referenceID": 18, "context": "For a more detailed exposition on the relationships between spectral stability of a data-driven Koopman operator and that of the underlying system, we refer the reader to [21, 22].", "startOffset": 171, "endOffset": 179}, {"referenceID": 19, "context": "For a more detailed exposition on the relationships between spectral stability of a data-driven Koopman operator and that of the underlying system, we refer the reader to [21, 22].", "startOffset": 171, "endOffset": 179}, {"referenceID": 1, "context": "For extended dynamic mode decomposition, we used Legendre basis polynomials [2], using L1 regularization to find the best scoring Koopman operator (in terms of 1-step prediction training error).", "startOffset": 76, "endOffset": 79}, {"referenceID": 1, "context": "Our choice of Legendre polynomials was based on the recommendations of [2].", "startOffset": 71, "endOffset": 74}, {"referenceID": 4, "context": "showed that a shallow 3-layer neural network with Tikhonov regularization using the tanh activation function, can also learn oscillatory dynamics for the Duffing oscillator [5].", "startOffset": 173, "endOffset": 176}], "year": 2017, "abstractText": "The Koopman operator has recently garnered much attention for its value in dynamical systems analysis and data-driven model discovery. However, its application has been hindered by the computational complexity of extended dynamic mode decomposition; this requires a combinatorially large basis set to adequately describe many nonlinear systems of interest, e.g. cyber-physical infrastructure systems, biological networks, social systems, and fluid dynamics. Often the dictionaries generated for these problems are manually curated, requiring domain-specific knowledge and painstaking tuning. In this paper we introduce a deep learning framework for learning Koopman operators of nonlinear dynamical systems. We show that this novel method automatically selects efficient deep dictionaries, outperforming stateof-the-art methods. We benchmark this method on partially observed nonlinear systems, including the glycolytic oscillator and show it is able to predict quantitatively 100 steps into the future, using only a single timepoint, and qualitative oscillatory behavior 400 steps into the future. ar X iv :1 70 8. 06 85 0v 1 [ cs .L G ] 2 2 A ug 2 01 7", "creator": "LaTeX with hyperref package"}}}