{"id": "1708.07038", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Aug-2017", "title": "Non-linear Convolution Filters for CNN-based Learning", "abstract": "During the last years, Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in image classification. Their architectures have largely drawn inspiration by models of the primate visual system. However, while recent research results of neuroscience prove the existence of non-linear operations in the response of complex visual cells, little effort has been devoted to extend the convolution technique to non-linear forms. Typical convolutional layers are linear systems, hence their expressiveness is limited. To overcome this, various non-linearities have been used as activation functions inside CNNs, while also many pooling strategies have been applied. We address the issue of developing a convolution method in the context of a computational model of the visual cortex, exploring quadratic forms through the Volterra kernels. Such forms, constituting a more rich function space, are used as approximations of the response profile of visual cells. Our proposed second-order convolution is tested on CIFAR-10 and CIFAR-100. We show that a network which combines linear and non-linear filters in its convolutional layers, can outperform networks that use standard linear filters with the same architecture, yielding results competitive with the state-of-the-art on these datasets.", "histories": [["v1", "Wed, 23 Aug 2017 15:07:35 GMT  (440kb,D)", "http://arxiv.org/abs/1708.07038v1", "9 pages, 5 figures, code link, ICCV 2017"]], "COMMENTS": "9 pages, 5 figures, code link, ICCV 2017", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["georgios zoumpourlis", "alexandros doumanoglou", "nicholas vretos", "petros daras"], "accepted": false, "id": "1708.07038"}, "pdf": {"name": "1708.07038.pdf", "metadata": {"source": "CRF", "title": "Non-linear Convolution Filters for CNN-based Learning", "authors": ["Georgios Zoumpourlis", "Alexandros Doumanoglou", "Nicholas Vretos", "Petros Daras"], "emails": ["daras}@iti.gr"], "sections": [{"heading": "1. Introduction", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "2. Related Work", "text": "In fact, most people who work for equality between women and men are not aware of themselves and their rights. \"I don't think it's as if,\" she says, \"but it's as if,\" she says. \"But I don't think it's as if.\" \"I think it's as if,\" she says, \"but it's as if.\" \"It's not as if.\" \"But it's as if.\" \"It's as if.\" \"It's as if.\" \"It's as if.\" It's as if. \"It's as if.\" It's as if. \"It's as if.\" It's as if. \"It's like.\" It's like. \"It's like.\" It's like. \"It's like.\" It's like. \"It's like.\" It's like. \"It's like.\" It's like. \""}, {"heading": "3. Proposed Method", "text": "The proposed method, as already mentioned, uses the Volterra core theory to provide means of utilizing the nonlinear operations that take place in a receptive field. So far, and to the best of our knowledge, nonlinearities have mainly been exploited through activation functions and pooling operations between different layers of CNNs. Nevertheless, such nonlinearities can be an approach to encode internal processes of the visual system, but not those that exist in a receptive area. Our method follows the typical workflow of a CNN by stringing together layers of different purposes (folding, pooling, activation function, batch normalization, dropout, full linkage, etc.), while a nonlinear convolutionary layer can be inserted into virtually all existing architectures."}, {"heading": "3.1. Volterra-based convolution", "text": "The Volterra series model is a sequence of approximate values for continuous functions designed to represent the input-output relationship of nonlinear dynamic systems using a polynomial functional expansion. Their equations can be composed by terms of infinite orders, but practical implementations based on them use truncated versions, with the terms up to a certain order r.In a similar manner to linear convolution, Volterra-based convolution uses cores to filter the input data. The firstborn Volterra kernel contains the coefficients of the linear part of the filter. The second-order kernel represents the coefficients of square interactions between two input elements. Generally, the core of the r-th order represents the weights that nonlinear interactions between input elements have on the response. In the field of computer vision, Volterra cores were previously used in [17] for face recognition, which is used as nonlinear approximations."}, {"heading": "3.2. Forward pass", "text": "For our proposed convolution, we have adopted a secondary Volterra series. In view of an input field containing I-IRkh \u00b7 kw with n elements (n = kh \u00b7 kw) redesigned as vector x-IRn: x = [x1 x2 \u00b7 \u00b7 xn] T (1), the input-output function of a linear filter is: y (x) = n \u00b2 i = 1 (wi1xi) + b (2), where wei1 \u00b7 n are the weights of the linear terms of the convolution, contained in a vector w1, and b is the bias. In our approach, this function is extended in the following square form: y (x) = n \u00b2 square form i = 1 (wi1xi) + n \u00b2 square form of the confrontation i = i (wi, j2 xixj) + b (3), where wi, j2 are the weights of the second terms of the filter."}, {"heading": "3.3. Backward pass", "text": "The derivation of the equations for the reverse trajectory of the Volterra-based folding is done by adapting the classical backpropagation scheme to the above-mentioned input function of (3). To calculate the weights of the Volterra cores, we must calculate the gradients of the output of the layer y (x) taking into account the weights wei1 and w i, j 2. To propagate the error, we must calculate the gradients of the layer y (x) taking into account the inputs xi. The mathematical equations of the backpropagation are as follows: W y, W, W, W, W, W, J and Y, xi are the terms used to optimize the weight parameters of our Volterra-based volume layer and minimize the network loss: W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W"}, {"heading": "4. Quadratic convolution filter implementation", "text": "In order to experiment with the non-linear folding filters, we used the scientific frame Torch7, while we used the Kernel S for weight calculation. Volterra-based convolution was implemented as a module with the CUDA backend for the Neural Network (cunn) Package of Torch7. The writing of a module in Torch7 essentially consists of the implementation of the forward traverse module (3) and the calculation of the gradient of the module (XI E-W-E-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z"}, {"heading": "5. Experiments", "text": "We measure the performance of our proposed Volterra-based folding using two benchmark datasets: CIFAR-10 and CIFAR-100 [15], conducting our experiments on a PC with Intel i7-5820K CPU, 64GB RAM and Nvidia Titan X GPU. Volterra-based folding layer was implemented in Torch7. First we describe the setup, then we show a quantitative analysis of parameters, classification errors and traction loss for the proposed method."}, {"heading": "5.1. CNN architecture selection", "text": "As explained in Section 4, we limit ourselves to testing such filters only in the first revolutionary layer of a CNN model. We choose the modern architecture of Wide ResNet [34], which mainly consists of a revolutionary layer, followed by 3 revolutionary groups and a classifier. If d is the depth of such a network, each revolutionary layer contains N = (d \u2212 4) / 6 revolutionary blocks. In one group, the number of filters of each revolutionary layer is controlled by the distribution factor k. In our architecture, we follow the above rules, making three changes: a) we add a batch normalization layer to the beginning of the network b) we change the number of the first revolutionary layer to the output channels that are non-revolutionary."}, {"heading": "5.2. Experimental setup", "text": "In all our experiments we use Stochastic Gradient Descent (SGD) with a pulse of 0.9 and Cross-Entropyloss with a batch size of 128 to train our network for 220 epochs. Dropout is set to 0.3 and the weight initialization is done as in [10]. The learning rate and weight loss strategy used in the experiments is illustrated in Table 2. In CIFAR-10 and CIFAR-100, the data preprocessing operation applied to both the traction and test data, we subtract the channel means and then divide them by channel standard deviations calculated on the pull. We use moderate data augmentation, using horizontal flipping with a 50% probability and reflection padding of 4 pixels on each image side, taking a random section of the size 32 x 32."}, {"heading": "5.3. CIFAR-10 and CIFAR-100", "text": "CIFAR-10 and CIFAR-100 datasets contain 60,000 32 x 32 RGB images of common object categories (e.g. animals, vehicles, etc.) where the traction set has 50,000 images and the test set has 10,000 images. CIFAR-10 has 10 classes and CIFAR-100 100 100 100 100 classes. All classes have the same number of traction and test samples. In CIFAR-10, our Volterra-based Wide ResNet provides a test error of 3.51%, which is an improvement over the error of 3.62% we obtained with the base model by specifying the state of the art on this dataset. In CIFAR-100, our Volterra-based Wide ResNet provides a test error of 18.24%, which is an improvement over the error of 18.29% we received with the base model. Our results on CIFAR-100 are only exceeded by Volterra due to the enormous number of parameters their model uses."}, {"heading": "5.4. Weight visualization", "text": "To get an insight into the properties of nonlinear filters, we visualize their weights in a simple but efficient way. For the linear term, the process is simple. For the second-order term, taking into account the weights w2 of each filter, we can create n weight vectors Qi, Qi = [wi12, w i2,..., w in 2]. By transforming each of these vectors Qi into a kh \u00b7 kw matrix, we can see the weights corresponding to the interactions between xi and all elements of the receptive field. Figure 4 shows the weights of the linear term and the interactions captured by a second-order filter 3 \u00d7 3, allowing us to examine their contribution to the answer. Another problem is the values corresponding to the weights of the nonlinear terms."}, {"heading": "5.5. Response profiles", "text": "According to the methodology of [2], we use a series of Volterra-based filters of a Wide ResNet trained on CIFAR100 to partially characterize their response profiles. In view of the weights w1, w2 of a filter, we calculate its optimal stimulus xo and the optimal stimulus of its linear term xl under the condition that its norms are the same. Then, we calculate four responses, as described in Table 4, and plot them in Figure 5. Comparing the different responses, we can conclude that the properties of a linear filter with weights w1 can vary greatly when extended to a second-order Volterra shape by adding a weightset w2 with square contributions. The reaction of a Volterra-based filter is significantly different from the reaction of its first-order terms, proving that second-order interactions significantly contribute to the functionality of a square filter with square contributions."}, {"heading": "6. Conclusion", "text": "The study of CNN architectures optimized for the use of nonlinear folding filters is an open problem for the biologically inspired computer vision. Questions such as \"What is the ideal ratio between linear and nonlinear filters in each folding layer?\" and \"What properties predominate in the response profiles of nonlinear filters at each level?\" are of great importance in bringing light to this previously unexplored category of filters. Any conclusion about the properties present in this group of square filters carries the risk of being distorted by the dataset used to obtain and observe them, because the visual response profiles of the nonlinear filters trained in the experiments are limited by the natural statistics of each dataset, just as it happens with the sensory system of primates adapting to its environment. Based on the linear neuroscience research results that do not support the concept of nonlinear filters, the existence of the non-linear cells suggested by the filters in their surroundings does not exist."}, {"heading": "Acknowledgment", "text": "The research that led to these results was supported by the EU-funded FORENSOR project (GA 653355)."}], "references": [{"title": "Quadratic polynomials learn better image features", "author": ["J. Bergstra", "G. Desjardins", "P. Lamblin", "Y. Bengio"], "venue": "Technical report, Technical Report 1337, D\u00e9partement d\u2019Informatique et de Recherche Op\u00e9rationnelle, Universit\u00e9 de Montr\u00e9al", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "On the analysis and interpretation of inhomogeneous quadratic forms as receptive fields", "author": ["P. Berkes", "L. Wiskott"], "venue": "Neural computation, 18(8):1868\u20131895", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "High Performance Convolutional Neural Networks for Document Processing", "author": ["K. Chellapilla", "S. Puri", "P. Simard"], "venue": "In Tenth International Workshop on Frontiers in Handwriting Recognition, La Baule (France),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Steerable cnns", "author": ["T.S. Cohen", "M. Welling"], "venue": "CoRR, abs/1612.08498", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Torch7: A Matlab-like Environment for Machine Learning", "author": ["R. Collobert", "K. Kavukcuoglu", "C. Farabet"], "venue": "BigLearn, NIPS Workshop", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Advances in neural information processing systems 2", "author": ["Y.L. Cun", "B. Boser", "J.S. Denker", "R.E. Howard", "W. Habbard", "L.D. Jackel", "D. Henderson"], "venue": "chapter Handwritten Digit Recognition with a Back-propagation Network, pages 396\u2013 404. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1990}, {"title": "Stimulus optimisation in primary visual cortex", "author": ["P. F\u00f6ldi\u00e1k"], "venue": "Neurocomputing, 3840:1217 \u2013 1222", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2001}, {"title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position", "author": ["K. Fukushima"], "venue": "36(4):193\u2013202", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1980}, {"title": "Deep pyramidal residual networks", "author": ["D. Han", "J. Kim", "J. Kim"], "venue": "CoRR, abs/1610.02915", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "CoRR, abs/1512.03385", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Identity Mappings in Deep Residual Networks", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "pages 630\u2013645. Springer International Publishing, Cham", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep networks with stochastic depth", "author": ["G. Huang", "Y. Sun", "Z. Liu", "D. Sedra", "K.Q. Weinberger"], "venue": "CoRR, abs/1603.09382", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Receptive fields, binocular interaction and functional architecture in the cat\u2019s visual cortex", "author": ["D.H. Hubel", "T.N. Wiesel"], "venue": "The Journal of physiology,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1962}, {"title": "Improving training of deep neural networks via singular value bounding", "author": ["K. Jia"], "venue": "CoRR, abs/1611.06013", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "Technical report", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Delugenets: Deep networks with massive and flexible cross-layer information inflows", "author": ["J. Kuen", "X. Kong", "G. Wang"], "venue": "CoRR, abs/1611.05552", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Volterrafaces: Discriminant analysis using volterra kernels", "author": ["R. Kumar", "A. Banerjee", "B.C. Vemuri"], "venue": "Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 150\u2013155. IEEE", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Deeplysupervised nets", "author": ["C. Lee", "S. Xie", "P.W. Gallagher", "Z. Zhang", "Z. Tu"], "venue": "Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics, AISTATS 2015, San Diego, California, USA, May 9-12, 2015", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Recurrent convolutional neural network for object recognition", "author": ["M. Liang", "X. Hu"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Network in network", "author": ["M. Lin", "Q. Chen", "S. Yan"], "venue": "International Conference on Learning Representations", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Mathematical description of the responses of simple cortical cells", "author": ["S. Mar\u0109elja"], "venue": "Journal of the Optical Society of America, 70(11):1297\u20131300", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1980}, {"title": "Interpretable sparse high-order boltzmann machines", "author": ["M.R. Min", "X. Ning", "C. Cheng", "M. Gerstein"], "venue": "AISTATS", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Spatial summation in the receptive fields of simple cells in the cat\u2019s striate cortex", "author": ["J.A. Movshon", "I.D. Thompson", "D.J. Tolhurst"], "venue": "The Journal of physiology, 283:53", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1978}, {"title": "Highly Selective Receptive Fields in Mouse Visual Cortex", "author": ["C.M. Niell", "M.P. Stryker"], "venue": "Journal of Neuroscience,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2008}, {"title": "Estimating nonlinear receptive fields from natural images", "author": ["J. Rapela", "J.M. Mendel", "N.M. Grzywacz"], "venue": "Journal of Vision, 6(4):11", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2006}, {"title": "Regularizing cnns with locally constrained decorrelations", "author": ["P. Rodr\u0131\u0301guez", "J. Gonz\u00e0lez", "G. Cucurull", "J.M. Gonfaus", "F.X. Roca"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1967}, {"title": "Imagenet large scale visual recognition challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein", "A.C. Berg", "L. Fei-Fei"], "venue": "International Journal of Computer Vision, 115(3):211\u2013252", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning symmetry groups with hidden units: Beyond the perceptron", "author": ["T.J. Sejnowski", "P.K. Kienker", "G.E. Hinton"], "venue": "Physica D: Nonlinear Phenomena, 22(1-3):260\u2013275", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1986}, {"title": "Striving for simplicity: The all convolutional net", "author": ["J. Springenberg", "A. Dosovitskiy", "T. Brox", "M. Riedmiller"], "venue": "ICLR (workshop track)", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S.E. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "CoRR, abs/1409.4842", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "The two-dimensional spatial structure of nonlinear subunits in the receptive fields of complex cells", "author": ["R.G. Szulborski", "L.A. Palmer"], "venue": "Vision Research, 30(2):249\u2013254", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1990}, {"title": "Theory of Functionals and of Integral and Integro-Differential Equations", "author": ["V. Volterra"], "venue": "Dover Publications", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2005}, {"title": "Aggregated residual transformations for deep neural networks", "author": ["S. Xie", "R.B. Girshick", "P. Doll\u00e1r", "Z. Tu", "K. He"], "venue": "CoRR, abs/1611.05431", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2016}, {"title": "Wide residual networks", "author": ["S. Zagoruyko", "N. Komodakis"], "venue": "BMVC", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2016}, {"title": "Oriented response networks", "author": ["Y. Zhou", "Q. Ye", "Q. Qiu", "J. Jiao"], "venue": "CoRR, abs/1701.01833", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2017}], "referenceMentions": [{"referenceID": 12, "context": "Their architectures have largely drawn inspiration by models of the primate visual system, as the one described by Hubel and Wiesel [13].", "startOffset": 132, "endOffset": 136}, {"referenceID": 24, "context": "Due to their linear nature, they lack the ability of expressing possible non-linearities that may actually appear in the response of complex cells in the primary visual cortex [25].", "startOffset": 176, "endOffset": 180}, {"referenceID": 30, "context": "Little effort has been devoted to explore new computational models that extend the convolution technique to non-linear forms, taking advantage of the research results of neuroscience, that prove the existence of nonlinear operations in the response of visual cells [31][24].", "startOffset": 265, "endOffset": 269}, {"referenceID": 23, "context": "Little effort has been devoted to explore new computational models that extend the convolution technique to non-linear forms, taking advantage of the research results of neuroscience, that prove the existence of nonlinear operations in the response of visual cells [31][24].", "startOffset": 269, "endOffset": 273}, {"referenceID": 31, "context": "In this work, we study the possibility of adopting an alternative convolution scheme to increase the learning capacity of CNNs by applying Volterra\u2019s theory [32], which has been used to study non-linear physiological systems, adapting it to the spatial domain.", "startOffset": 157, "endOffset": 161}, {"referenceID": 4, "context": "non-linear convolutional layer\u2019s module in Torch71[5]", "startOffset": 50, "endOffset": 53}, {"referenceID": 7, "context": "One of the first biologically-inspired neural networks, was Fukushima\u2019s Neocognitron [8], which was the predecessor of CNN, as it was introduced by LeCun et al.", "startOffset": 85, "endOffset": 88}, {"referenceID": 5, "context": "in [6].", "startOffset": 3, "endOffset": 6}, {"referenceID": 20, "context": "This category of filters can model quite accurately the properties of simple cells found in the primary visual cortex (V1) [21].", "startOffset": 123, "endOffset": 127}, {"referenceID": 6, "context": "Finding the optimal spatial stimuli [7] for simple cells is a process based on the spatial arrangement of their excitatory and inhibitory regions [23].", "startOffset": 36, "endOffset": 39}, {"referenceID": 22, "context": "Finding the optimal spatial stimuli [7] for simple cells is a process based on the spatial arrangement of their excitatory and inhibitory regions [23].", "startOffset": 146, "endOffset": 150}, {"referenceID": 9, "context": "[10] proposed Residual Networks (ResNets), which have shortcut connections parallel to their normal convolutional layers, as a solution to the problems of vanishing/exploding gradient and hard optimization when increasing the model\u2019s parameters (i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "Zagoruyko & Komodakis [34] showed that wide ResNets can outperform ResNets with hundrends of layers, shifting the interest to increasing the number of each layer\u2019s filters.", "startOffset": 22, "endOffset": 26}, {"referenceID": 26, "context": "Apart from ResNets, very low error rates have also been achieved in the ImageNet Challenge [27] by methods that used their convolutional layers in new ways, enhancing their representation ability.", "startOffset": 91, "endOffset": 95}, {"referenceID": 19, "context": "[20] proposed \u201cNetwork in Network (NIN)\u201d, as a remedy to the low level of abstraction that typical filters present.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[30] introduced a new level of organization in the form of the \u201cInception module\u201d, which uses filters of variable sizes to capture different visual patterns of different sizes, and approximates the optimal sparse structure.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[33] proposed a way to exploit the split-transform-merge strategy of \u201cInception\u201d models, performing a set of transformations, each on a lowdimensional embedding, whose outputs are aggregated by summation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "The authors of [19], based on the abundancy of recurrent synapses in the brain, proposed the use of a recurrent neural network for image classification.", "startOffset": 15, "endOffset": 19}, {"referenceID": 27, "context": "In [28], a Boltzmann learning algorithm is proposed, where feature interactions are used to turn hidden units into higher-order feature detectors.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "In [22], an efficient method to apply such learning algorithms on higher-order Boltzmann Machines was proposed, making them computationally tractable for real problems.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "In [1], Bergstra et al.", "startOffset": 3, "endOffset": 6}, {"referenceID": 1, "context": "In [2], an attempt is made to analyze and interpret quadratic forms as receptive fields.", "startOffset": 3, "endOffset": 6}, {"referenceID": 16, "context": "In the field of computer vision, Volterra kernels have been previously used in [17] for face recognition, serving effectively as approximations of non-linear functionals.", "startOffset": 79, "endOffset": 83}, {"referenceID": 2, "context": "To implement the forward pass in CUDA, we used the standard im2col [3] pattern to unfold data patches into columns, followed by a matrix multiplication with the Volterra-based filter weights.", "startOffset": 67, "endOffset": 70}, {"referenceID": 14, "context": "We measure the performance of our proposed Volterrabased convolution on two benchmark datasets: CIFAR-10 and CIFAR-100 [15], running our experiments on a PC equipped with Intel i7-5820K CPU, 64GB RAM and Nvidia Titan X GPU.", "startOffset": 119, "endOffset": 123}, {"referenceID": 33, "context": "We choose the modern architecture of Wide ResNet [34], which mainly consists of a convolutional layer, followed by 3 convolutional groups and a classifier.", "startOffset": 49, "endOffset": 53}, {"referenceID": 9, "context": "3 and weight initialization is done as in [10].", "startOffset": 42, "endOffset": 46}, {"referenceID": 19, "context": "NIN [20] 8.", "startOffset": 4, "endOffset": 8}, {"referenceID": 17, "context": "DSN [18] 3 7.", "startOffset": 4, "endOffset": 8}, {"referenceID": 28, "context": "All-CNN [29] 9 1.", "startOffset": 8, "endOffset": 12}, {"referenceID": 11, "context": "ResNet with Stochastic Depth [12] 110 1.", "startOffset": 29, "endOffset": 33}, {"referenceID": 10, "context": "pre-act Resnet [11] 1001 10.", "startOffset": 15, "endOffset": 19}, {"referenceID": 33, "context": "Wide ResNet [34] 40 55.", "startOffset": 12, "endOffset": 16}, {"referenceID": 8, "context": "PyramidNet [9] 110 28.", "startOffset": 11, "endOffset": 14}, {"referenceID": 15, "context": "Wide-DelugeNet [16] 146 20.", "startOffset": 15, "endOffset": 19}, {"referenceID": 25, "context": "OrthoReg on Wide ResNet [26] 28 3.", "startOffset": 24, "endOffset": 28}, {"referenceID": 3, "context": "Steerable CNNs [4] 14 9.", "startOffset": 15, "endOffset": 18}, {"referenceID": 32, "context": "ResNeXt [33] 29 68.", "startOffset": 8, "endOffset": 12}, {"referenceID": 13, "context": "Wide ResNet with Singular Value Bounding [14] 28 36.", "startOffset": 41, "endOffset": 45}, {"referenceID": 34, "context": "Oriented Response Net [35] 28 18.", "startOffset": 22, "endOffset": 26}, {"referenceID": 32, "context": "Our results on CIFAR-100 are outperformed only by [33], due to the huge number of parameters their model makes use of.", "startOffset": 50, "endOffset": 54}, {"referenceID": 1, "context": "Following the methodology of [2], we use a set of Volterra-based filters of a Wide ResNet trained on CIFAR100, to partly characterize their response profiles.", "startOffset": 29, "endOffset": 32}], "year": 2017, "abstractText": "During the last years, Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in image classification. Their architectures have largely drawn inspiration by models of the primate visual system. However, while recent research results of neuroscience prove the existence of non-linear operations in the response of complex visual cells, little effort has been devoted to extend the convolution technique to non-linear forms. Typical convolutional layers are linear systems, hence their expressiveness is limited. To overcome this, various non-linearities have been used as activation functions inside CNNs, while also many pooling strategies have been applied. We address the issue of developing a convolution method in the context of a computational model of the visual cortex, exploring quadratic forms through the Volterra kernels. Such forms, constituting a more rich function space, are used as approximations of the response profile of visual cells. Our proposed second-order convolution is tested on CIFAR-10 and CIFAR-100. We show that a network which combines linear and non-linear filters in its convolutional layers, can outperform networks that use standard linear filters with the same architecture, yielding results competitive with the state-of-the-art on these datasets.", "creator": "LaTeX with hyperref package"}}}