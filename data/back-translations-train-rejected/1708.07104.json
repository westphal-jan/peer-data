{"id": "1708.07104", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Aug-2017", "title": "Automatic Detection of Fake News", "abstract": "The proliferation of misleading information in everyday access media outlets such as social media feeds, news blogs, and online newspapers have made it challenging to identify trustworthy news sources, thus increasing the need for computational tools able to provide insights into the reliability of online content. In this paper, we focus on the automatic identification of fake content in online news. Our contribution is twofold. First, we introduce two novel datasets for the task of fake news detection, covering seven different news domains. We describe the collection, annotation, and validation process in detail and present several exploratory analysis on the identification of linguistic differences in fake and legitimate news content. Second, we conduct a set of learning experiments to build accurate fake news detectors. In addition, we provide comparative analyses of the automatic and manual identification of fake news.", "histories": [["v1", "Wed, 23 Aug 2017 17:12:03 GMT  (28kb)", "http://arxiv.org/abs/1708.07104v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ver\\'onica p\\'erez-rosas", "bennett kleinberg", "alexandra lefevre", "rada mihalcea"], "accepted": false, "id": "1708.07104"}, "pdf": {"name": "1708.07104.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Alexandra Lefevre", "Rada Mihalcea"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 170 8.07 104v 1 [cs.C L] 23 Aug 201 7tion in everyday access media such as social media feeds, news blogs and online newspapers have made it difficult to identify trustworthy news sources, increasing the need for computing tools that can provide insights into the reliability of online content. In this post, we focus on the automatic identification of fake content in online news. Our contribution is twofold. First, we present two new sets of data for the task of detecting fake news covering seven different news areas. We describe in detail the collection, annotation and validation process and present several exploratory analyses to identify linguistic differences in fake and legitimate news content. Second, we conduct a series of learning experiments to build accurate fake news detectors. In addition, we offer comparative analyses for automatic and manual identification of fake news."}, {"heading": "1 Introduction", "text": "The detection of fake news has lately aroused a growing interest of the general public and of researchers as the prevalence of misinformation increases online, especially in media such as social media feeds, news blogs and online newspapers. Thus, a recent report by Jumpshot Tech Blog1 found that references to Facebook account for 50% of total traffic to fake news websites and 20% of total traffic to reputable websites. Since the majority of adults in the U.S. - 62% - receive news on social media (Jeffrey and Elisa, 2016), include g1https: / www.jumpshot.com / data-facebooks-fake-newproblemm / is able to identify fake content in online sources, it is an urgent need to incorporate computational approaches for the detection of fake news into satirical news sources such as \"The Onion\" and fact-checking sites such as \"politiFact\" and \"Snopes.\" However, the use of these sources, for example, we can include satirical facts in fact-based analysis."}, {"heading": "2 Related Work", "text": "To date, there are three important lines of research on the automated classification of real and fake news articles. First, on a conceptual level, a distinction has been made between \"three types of fake news\" (Rubin et al., 2015): serious products (i.e. news about false and non-existent events or information such as celebrity gossip and gossip), false information (i.e. the provision of false information about, for example, social media with the intention of being picked up by traditional news websites) and satire (i.e. humorous news articles that mimic real news but contain irony and absurdity). Here, we focus on the first category, serious production, in the two domains of general news (in six different categories), as well as on attempts to distinguish satire from real news."}, {"heading": "3 Fake News Datasets", "text": "As previously pointed out, the data sets used in previous work have either relied on satirical news (e.g. \"The Onion\"), which also causes confusion, such as humor or irony; or they have used fact-check websites (e.g. \"politiFact\" or \"Snopes\"), which typically focus on only one domain (generally politics). Therefore, we have decided to create two new data sets of fake news covering multiple news areas and specifically modelling the deceptive ownership of fake news without major confusion. One data set is collected through crowdsourcing and covers six news areas; the second data set is sourced directly from the web and covers fake news from celebrities. In building a fake news dataset, we complied with the nine requirements of a fake news corpus proposed by (Rubin et al., 2016)."}, {"heading": "3.1 Building a Crowdsourced Dataset", "text": "In fact, it is the case that most of them will be able to play by the rules that they have established over the past five years, and that they will be able to play by the rules, \"he said.\" But it is not the first time that they will be able to change the rules. \"He added,\" It is not the first time that they are able to change the rules, and it is not the first time that they are able to play by the rules. \""}, {"heading": "3.2 Building a Web Dataset", "text": "We collected a second dataset of fake news from web sources following similar guidelines as in the previous dataset Husston Couple Celebrities. This time, however, we aimed to identify fake content that naturally occurs on the web. We chose to collect news from public figures as they are often the target of rumor, hoax and fake reporting. We focused primarily on celebrities (actors, singers, socialists and politicians) and our sources include online magazines such as Entertainment Weekly, People Magazine, RadarOnline, among other tabloid and entertainment-oriented publications. The data was collected in pairs, with one article being legitimate and the other fake. To determine whether a given celebrity message was legitimate or not, the claims made in the article were evaluated using gossip check sites such as \"GossipCop.com\" and were cross-referenced with information from other sources, with one article being legitimate news and the other articles we want to focus on."}, {"heading": "4 Linguistic Features", "text": "In fact, most people who are able to survive themselves are not able to survive themselves, \"he told the German Press Agency in an interview with\" Frankfurter Allgemeine Zeitung \"(Friday).\" I don't think we will be able to put the world in order, \"he said.\" But I don't think we will be able to put the world in order. \"He added,\" I don't think we will be able to put the world in order. \""}, {"heading": "5 Computational Models for Fake News Detection", "text": "We are conducting several experiments with different characteristics."}, {"heading": "6 Human Performance", "text": "To determine a human baseline for the task of identifying fake news, we conducted a study to evaluate the human ability to detect fake news on the two sets of data developed. We created a comment interface that showed a commentator either a fake news article or a legitimate news article, and asked him to assess his credibility. Overall, the commentators read less than 5% of the messages in advance, which we considered a negligible break point. Two commentators called the messages in each set of data. In both cases, the news articles were presented in random order to avoid fake news distortion. Annotators rated 480 and 200 messages for the FakeNewsAMT and celebrity records. Annotators received no financial reward, and we consider their assessments honest because they voluntarily participated in these human comment preferences. Annotators rated the 480 and 200 messages for the FakeNewsAMT records or celebrity records."}, {"heading": "7 Further Insights", "text": "Our experiments point to important differences in fake news content compared to legitimate news content. In particular, we observe that classifiers based on the semantic information encoded in the LIWC lexicon consistently perform well in all areas. To gain further insights into the semantic classes associated with fake news and legitimate content, we evaluate which classes exhibit significant differences between the two groups of news. To compare both types of content, we subtract the average percentage of words in each LIWC category from their corresponding values in the legitimate news set. Therefore, a positive result indicates an association between a LIWC class and legitimate content, and a negative result indicates an association between a LIWC class and fake content. The results for the FakeNewsAMT and celebrity data are shown in Figures 3 and 4, respectively, which are significant (the differences are shown in 0.5)."}, {"heading": "8 Conclusions", "text": "In this paper, we focused on the task of automatically identifying fake news. We introduced two new fake news datasets, one that was crowdsourced and covers six news areas, and another that comes from the Internet of Celebrities. We developed classification models based on a combination of lexical, syntactic, and semantic information, as well as functions that represent the properties of text readability. Our most powerful models achieved accuracies comparable to the human ability to detect counterfeit content."}], "references": [{"title": "Language of lies in prison: Linguistic classification of prisoners\u2019 truthful and deceptive natural language", "author": ["Gary D Bond", "Adrienne Y Lee."], "venue": "Applied Cognitive Psychology 19(3):313\u2013329.", "citeRegEx": "Bond and Lee.,? 2005", "shortCiteRegEx": "Bond and Lee.", "year": 2005}, {"title": "Language style matching in writing: synchrony in essays, correspondence, and poetry", "author": ["Molly E Ireland", "James W Pennebaker."], "venue": "Journal of personality and social psychology 99(3):549.", "citeRegEx": "Ireland and Pennebaker.,? 2010", "shortCiteRegEx": "Ireland and Pennebaker.", "year": 2010}, {"title": "News use across social media platforms 2016", "author": ["Gottfried Jeffrey", "Shearer Elisa."], "venue": "Pew Research Center Reports. http://www.journalism.org/2016/05/26/news-use-across-social-media-platforms-2016/.", "citeRegEx": "Jeffrey and Elisa.,? 2016", "shortCiteRegEx": "Jeffrey and Elisa.", "year": 2016}, {"title": "Accurate unlexicalized parsing", "author": ["Dan Klein", "Christopher D. Manning."], "venue": "Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1. Association for Computational Linguistics, Strouds-", "citeRegEx": "Klein and Manning.,? 2003", "shortCiteRegEx": "Klein and Manning.", "year": 2003}, {"title": "e1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien", "author": ["David Meyer", "Evgenia Dimitriadou", "Kurt Hornik", "Andreas Weingessel", "Friedrich Leisch."], "venue": "R package version 1.6-7.", "citeRegEx": "Meyer et al\\.,? 2015", "shortCiteRegEx": "Meyer et al\\.", "year": 2015}, {"title": "Making computers laugh: Investigations in automatic humor recognition", "author": ["Rada Mihalcea", "Carlo Strapparava."], "venue": "Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing. Associa-", "citeRegEx": "Mihalcea and Strapparava.,? 2005", "shortCiteRegEx": "Mihalcea and Strapparava.", "year": 2005}, {"title": "Lying words: Predicting deception from linguistic styles", "author": ["M. Newman", "J. Pennebaker", "D. Berry", "J. Richards."], "venue": "Personality and Social Psychology Bulletin 29.", "citeRegEx": "Newman et al\\.,? 2003", "shortCiteRegEx": "Newman et al\\.", "year": 2003}, {"title": "Negative deceptive opinion spam", "author": ["Myle Ott", "Claire Cardie", "Jeffrey T Hancock."], "venue": "HLT-NAACL. pages 497\u2013501.", "citeRegEx": "Ott et al\\.,? 2013", "shortCiteRegEx": "Ott et al\\.", "year": 2013}, {"title": "Finding deceptive opinion spam by any stretch of the imagination", "author": ["Myle Ott", "Yejin Choi", "Claire Cardie", "Jeffrey Hancock."], "venue": "Proceedings of the 49th AnnualMeeting of the Association for Computational Linguistics: Human Language Technolo-", "citeRegEx": "Ott et al\\.,? 2011a", "shortCiteRegEx": "Ott et al\\.", "year": 2011}, {"title": "Finding deceptive opinion spam by any stretch of the imagination", "author": ["Myle Ott", "Yejin Choi", "Claire Cardie", "Jeffrey T. Hancock."], "venue": "Proceedings of the 49th Annual Meet-", "citeRegEx": "Ott et al\\.,? 2011b", "shortCiteRegEx": "Ott et al\\.", "year": 2011}, {"title": "The development and psychometric properties of liwc2015", "author": ["James W Pennebaker", "Ryan L Boyd", "Kayla Jordan", "Kate Blackburn."], "venue": "Technical report.", "citeRegEx": "Pennebaker et al\\.,? 2015", "shortCiteRegEx": "Pennebaker et al\\.", "year": 2015}, {"title": "Experiments in open domain deception detection", "author": ["Ver\u00f3nica P\u00e9rez-Rosas", "Rada Mihalcea."], "venue": "Proceedings of the 2015 Conference on", "citeRegEx": "P\u00e9rez.Rosas and Mihalcea.,? 2015", "shortCiteRegEx": "P\u00e9rez.Rosas and Mihalcea.", "year": 2015}, {"title": "A stylometric inquiry into hyperpartisan and fake news", "author": ["Martin Potthast", "Johannes Kiesel", "Kevin Reinartz", "Janek Bevendorff", "Benno Stein"], "venue": null, "citeRegEx": "Potthast et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Potthast et al\\.", "year": 2017}, {"title": "Modality effects in deception detection and applications in automatic deception-detection", "author": ["T. Qin", "J.K. Burgoon", "J.P. Blair", "J.F. Nunamaker."], "venue": "Proceedings of the 38th Hawaii International Conference on System Sciences.", "citeRegEx": "Qin et al\\.,? 2005", "shortCiteRegEx": "Qin et al\\.", "year": 2005}, {"title": "R: A Language and Environment for Statistical Computing", "author": ["R Core Team."], "venue": "R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/.", "citeRegEx": "Team.,? 2016", "shortCiteRegEx": "Team.", "year": 2016}, {"title": "Deception detection for news: Three types of fakes", "author": ["Victoria L. Rubin", "Yimin Chen", "Niall J. Conroy."], "venue": "Proceedings of the Association for Information Science and Technology 52(1):1\u20134.", "citeRegEx": "Rubin et al\\.,? 2015", "shortCiteRegEx": "Rubin et al\\.", "year": 2015}, {"title": "Fake news or truth? using satirical cues to detect potentially misleading news", "author": ["Victoria L Rubin", "Niall J Conroy", "Yimin Chen", "Sarah Cornwell."], "venue": "Proceedings of NAACL-HLT. pages 7\u201317.", "citeRegEx": "Rubin et al\\.,? 2016", "shortCiteRegEx": "Rubin et al\\.", "year": 2016}, {"title": "The language of deceivers: Linguistic features of crowdfunding scams", "author": ["Wafa Shafqat", "Seunghun Lee", "Sehrish Malik", "Hyun-chul Kim."], "venue": "Proceedings of the 25th International Conference Companion on World Wide Web. International World", "citeRegEx": "Shafqat et al\\.,? 2016", "shortCiteRegEx": "Shafqat et al\\.", "year": 2016}, {"title": "Reading between the lines: linguistic cues to deception in online dating profiles", "author": ["C. Toma", "J. Hancock."], "venue": "Proceedings of the 2010 ACM conference on Computer supported cooperative work. ACM, New York, NY, USA, CSCW \u201910, pages 5\u20138.", "citeRegEx": "Toma and Hancock.,? 2010", "shortCiteRegEx": "Toma and Hancock.", "year": 2010}, {"title": "Computational irony: A survey and new perspectives", "author": ["Byron C Wallace."], "venue": "Artificial Intelligence Review 43(4):467\u2013483.", "citeRegEx": "Wallace.,? 2015", "shortCiteRegEx": "Wallace.", "year": 2015}, {"title": "Warrants and deception in computer mediated communication", "author": ["D. Warkentin", "M. Woodworth", "J. Hancock", "N. Cormier."], "venue": "Proceedings of", "citeRegEx": "Warkentin et al\\.,? 2010", "shortCiteRegEx": "Warkentin et al\\.", "year": 2010}, {"title": "Detecting click fraud in pay-per-click streams of online advertising networks", "author": ["Linfeng Zhang", "Yong Guan."], "venue": "Distributed Computing Systems, 2008. ICDCS\u201908. The 28th International Conference on. IEEE, pages 77\u201384.", "citeRegEx": "Zhang and Guan.,? 2008", "shortCiteRegEx": "Zhang and Guan.", "year": 2008}], "referenceMentions": [{"referenceID": 2, "context": "adults \u201362%\u2013 gets news on social media (Jeffrey and Elisa, 2016), being", "startOffset": 39, "endOffset": 64}, {"referenceID": 5, "context": "This is particularly the case for satirical news from \u201cThe Onion\u201d, which has been used in the past to explore other text properties such as humor (Mihalcea and Strapparava, 2005) and irony (Wallace, 2015).", "startOffset": 146, "endOffset": 178}, {"referenceID": 19, "context": "This is particularly the case for satirical news from \u201cThe Onion\u201d, which has been used in the past to explore other text properties such as humor (Mihalcea and Strapparava, 2005) and irony (Wallace, 2015).", "startOffset": 189, "endOffset": 204}, {"referenceID": 15, "context": "First, on a conceptual level, a distinction has been made between \u2019three types of fake news\u2019 (Rubin et al., 2015): serious fabrications (i.", "startOffset": 93, "endOffset": 113}, {"referenceID": 16, "context": "Second, attempts to differentiate satire from real news yielded promising results (Rubin et al., 2016).", "startOffset": 82, "endOffset": 102}, {"referenceID": 12, "context": "writing-style) approach has been proposed for the identification of fake and genuine news articles (Potthast et al., 2017).", "startOffset": 99, "endOffset": 122}, {"referenceID": 12, "context": "The dataset used by (Potthast et al., 2017) consisted of 1,627 news articles that were obtainable from the original Buzzfeed dataset, including 299 fake news articles.", "startOffset": 20, "endOffset": 43}, {"referenceID": 20, "context": "com/BuzzFeedNews/2016-10-facebookfact-check vertising, online dating, and crowdfounding platforms (Warkentin et al., 2010; Ott et al., 2011a; Zhang and Guan, 2008; Toma and Hancock, 2010; Shafqat et al., 2016).", "startOffset": 98, "endOffset": 209}, {"referenceID": 8, "context": "com/BuzzFeedNews/2016-10-facebookfact-check vertising, online dating, and crowdfounding platforms (Warkentin et al., 2010; Ott et al., 2011a; Zhang and Guan, 2008; Toma and Hancock, 2010; Shafqat et al., 2016).", "startOffset": 98, "endOffset": 209}, {"referenceID": 21, "context": "com/BuzzFeedNews/2016-10-facebookfact-check vertising, online dating, and crowdfounding platforms (Warkentin et al., 2010; Ott et al., 2011a; Zhang and Guan, 2008; Toma and Hancock, 2010; Shafqat et al., 2016).", "startOffset": 98, "endOffset": 209}, {"referenceID": 18, "context": "com/BuzzFeedNews/2016-10-facebookfact-check vertising, online dating, and crowdfounding platforms (Warkentin et al., 2010; Ott et al., 2011a; Zhang and Guan, 2008; Toma and Hancock, 2010; Shafqat et al., 2016).", "startOffset": 98, "endOffset": 209}, {"referenceID": 17, "context": "com/BuzzFeedNews/2016-10-facebookfact-check vertising, online dating, and crowdfounding platforms (Warkentin et al., 2010; Ott et al., 2011a; Zhang and Guan, 2008; Toma and Hancock, 2010; Shafqat et al., 2016).", "startOffset": 98, "endOffset": 209}, {"referenceID": 6, "context": "Linguistic clues such as self references or positive and negative words have been used to profile true tellers from liars (Newman et al., 2003).", "startOffset": 122, "endOffset": 143}, {"referenceID": 13, "context": "Other work has focused on analyzing the number of words, sentences, self references, affect, spatial and temporal information associated with deceptive content (Qin et al., 2005).", "startOffset": 160, "endOffset": 178}, {"referenceID": 17, "context": "Expressivity, informality, diversity and non-immediacy have also been explored to identify deceitful behaviors (Shafqat et al., 2016).", "startOffset": 111, "endOffset": 133}, {"referenceID": 16, "context": "In building a fake news dataset, we adhered to the nine requirements of a fake news corpus proposed by (Rubin et al., 2016).", "startOffset": 103, "endOffset": 123}, {"referenceID": 9, "context": "To generate fake versions of the news in the legitimate news dataset, we make use of crowdsourcing via Amazon Mechanical Turk, which has been successfully used in the past for collecting deception data on several domains, including opinion reviews (Ott et al., 2011b), and controversial topics such as abortion and death penalty (P\u00e9rez-Rosas and Mihalcea, 2015).", "startOffset": 248, "endOffset": 267}, {"referenceID": 11, "context": ", 2011b), and controversial topics such as abortion and death penalty (P\u00e9rez-Rosas and Mihalcea, 2015).", "startOffset": 70, "endOffset": 102}, {"referenceID": 1, "context": "Interestingly, we observed that AMT workers succeeded in mimicking the reporting style from the original news, which may be partly explained by typical verbal mirroring behaviors with drive individuals to produce utterances that match the grammatical structure of sentences they have recently read (Ireland and Pennebaker, 2010).", "startOffset": 298, "endOffset": 328}, {"referenceID": 16, "context": "Previous work on fake news detection (Rubin et al., 2016) as well as on opinion spam (Ott et al.", "startOffset": 37, "endOffset": 57}, {"referenceID": 9, "context": ", 2016) as well as on opinion spam (Ott et al., 2011b) suggests that the use of punctuation might be useful to differentiate deceptive from truthful texts.", "startOffset": 35, "endOffset": 54}, {"referenceID": 10, "context": "1 2015) (Pennebaker et al., 2015).", "startOffset": 8, "endOffset": 33}, {"referenceID": 0, "context": ", 2011b, 2013); prisoners\u2019 lies (Bond and Lee, 2005)).", "startOffset": 32, "endOffset": 52}, {"referenceID": 16, "context": "The feature sets linguistic processes and punctuation correspond to the \u2019grammar\u2019 and punctuation feature set, respectively, in (Rubin et al., 2016) tent features such as the number of characters, complex words, long words, number of syllables, word types, and number of paragraphs, among others content features.", "startOffset": 128, "endOffset": 148}, {"referenceID": 3, "context": "Finally, we extract a set of features derived production rules based on context free grammars (CFG) trees using the Stanford Parser (Klein and Manning, 2003).", "startOffset": 132, "endOffset": 157}, {"referenceID": 4, "context": ", 2016) and e1071 packages (Meyer et al., 2015).", "startOffset": 27, "endOffset": 47}], "year": 2017, "abstractText": "The proliferation of misleading information in everyday access media outlets such as social media feeds, news blogs, and online newspapers have made it challenging to identify trustworthy news sources, thus increasing the need for computational tools able to provide insights into the reliability of online content. In this paper, we focus on the automatic identification of fake content in online news. Our contribution is twofold. First, we introduce two novel datasets for the task of fake news detection, covering seven different news domains. We describe the collection, annotation, and validation process in detail and present several exploratory analysis on the identification of linguistic differences in fake and legitimate news content. Second, we conduct a set of learning experiments to build accurate fake news detectors. In addition, we provide comparative analyses of the automatic and manual identification of fake news.", "creator": "LaTeX with hyperref package"}}}