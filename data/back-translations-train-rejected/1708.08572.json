{"id": "1708.08572", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Aug-2017", "title": "Really? Well. Apparently Bootstrapping Improves the Performance of Sarcasm and Nastiness Classifiers for Online Dialogue", "abstract": "More and more of the information on the web is dialogic, from Facebook newsfeeds, to forum conversations, to comment threads on news articles. In contrast to traditional, monologic Natural Language Processing resources such as news, highly social dialogue is frequent in social media, making it a challenging context for NLP. This paper tests a bootstrapping method, originally proposed in a monologic domain, to train classifiers to identify two different types of subjective language in dialogue: sarcasm and nastiness. We explore two methods of developing linguistic indicators to be used in a first level classifier aimed at maximizing precision at the expense of recall. The best performing classifier for the first phase achieves 54% precision and 38% recall for sarcastic utterances. We then use general syntactic patterns from previous work to create more general sarcasm indicators, improving precision to 62% and recall to 52%. To further test the generality of the method, we then apply it to bootstrapping a classifier for nastiness dialogic acts. Our first phase, using crowdsourced nasty indicators, achieves 58% precision and 49% recall, which increases to 75% precision and 62% recall when we bootstrap over the first level with generalized syntactic patterns.", "histories": [["v1", "Tue, 29 Aug 2017 02:05:14 GMT  (234kb,D)", "http://arxiv.org/abs/1708.08572v1", "Workshop on Language Analysis in Social Media (LASM 2013), at the North American Chapter of the Association for Computational Linguistics (NAACL 2013)"]], "COMMENTS": "Workshop on Language Analysis in Social Media (LASM 2013), at the North American Chapter of the Association for Computational Linguistics (NAACL 2013)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["stephanie lukin", "marilyn walker"], "accepted": false, "id": "1708.08572"}, "pdf": {"name": "1708.08572.pdf", "metadata": {"source": "CRF", "title": "Really? Well. Apparently Bootstrapping Improves the Performance of Sarcasm and Nastiness Classifiers for Online Dialogue", "authors": ["Stephanie Lukin", "Marilyn Walker"], "emails": ["slukin@soe.ucsc.edu", "maw@soe.ucsc.edu"], "sections": [{"heading": "1 Introduction", "text": "Unlike traditional monological methods, which rely on resources such as news, a highly unpleasant dialogue is very common on social media, as depicted in the snippets in Fig. 1 from the publicly available Internet Argument Corpus (IAC). 1 Like Q1 and R1, the snippets are often sarcastic, e.g. if I have a child, I will be sure to leave it in the woods, as it seems to be able to take care of itself. 1 Like Q1 and R1, the snippets are often sarcastic, i.e. they can know everything by commenting on the genetic falsehood left and right (R3 in Fig. 1) Also the frequent use of dialogues specific discourses, e.g. the use of R1 in R1 and R1."}, {"heading": "2 Previous Work", "text": "IAC offers labels for sarcasm and meanness collected with Mechanical Turk on Q / R pairs such as the one in Fig. 1. Seven Turks per Q / R pair answered a binary comment question for sarcasm Is the respondent having sarcasm? (0.1) and a scalar comment question for meanness Is the respondent trying to be nice or is his attitude quite unpleasant? (-5 evil.. 5 nice) We chose phrases from IAC Table 1 with sarcasm averages above 0.5 and unpleasant averages below -1 and nice above 1. Fig. 1 included examples of meanness and sarcasm values. Previous work on automatic sarcasm identification focused on Twitter using the # sarcasm (Gonza-lez-Iba-n structures below-ez et al., 2011) and # irony (Reyes et al., 2012) labels and a combined variety of sarcasm and smileys."}, {"heading": "3 Method Overview", "text": "Our method for classifying interests with high precision (R W call this \"wn ocabary\") uses R & W's model adapted to our data as illustrated for sarcasm in Fig. 2. The general idea of the method is to find reliable terms and then generalize them. The top of Fig. 2 determines whether input to the method is used as an uncommented part of the opinion dialogues to illustrate the long-term goal of building a large corpus of the phenomenon without human annotation. Although the classification is done as uncommented text, we first need statements that are already referred to as sarcasm to train it. Table 1 specifies how we break down the annotations to the annotations in IAC for our various experiments. The left circle of Fig. 2 reflects the assumption that there is Sarcasm or Nasty Cues that can identify the category of interest with high precision."}, {"heading": "4 Sarcasm and Nastiness Cues", "text": "Since there is no prior \"Known Sarcastic Vocabulary,\" we are testing two different methods for discovering lexical keywords on sarcasm and meanness, and experimenting with combinations of keywords that could yield a highly precise classifier (Gianfortoni et al., 2011). The first method uses \u03c72 to measure whether a word or phrase statistically indicates sarcasm (meanness) in the developmental phrases referred to as \"MT exp dev\" (Table 1). This method seems a priori reasonable, because it is likely that if you have a sufficiently large number of expressions designated as sarcasm, you will automatically learn a number of reliable keywords for sarcasm. The second method introduces a step of human remark. We ask Turks to identify sarcastic (evil) indicators in utterances (the open QuestigeO1) from the development set \"MT exp dev\" (Table 1)."}, {"heading": "4.1 Results from Indicator Cues", "text": "It is well known that sarcasm is highly variable in its form, and in some cases depends on the context of its interpretation (Sperber and Wilson, 1981; Gibbs, 2000; Bryant and Fox Tree, 2002).We conducted an initial pilot study of 100 of the 617 sarcastic utterances in the development group \"MT exp dev\" to see if this was necessarily the case in our dialogues. (Snow et al., 2008) We measure the quality of the annotations on common NLP tasks by comparing them to a gold standard. Pearson's correlation coefficient shows that very few mechanical annotations were needed in our dialogues to beat the gold standard data, often less than 5. Since our sarcasm task has no gold standard data, we ask 100 annotators to participate in the pilot project. Fig. 3 plots the average interannotator match (ITA) as a function of the number of annotations that are calculated using annotators, which are required for 40 + annotators and more data."}, {"heading": "5 High-Precision Classifiers", "text": "We follow similar guidelines to train HP Sarcasm and Nasty Classifiers. To test the open question O1, we use a development set called \"HP Train\" (Table 1) to test three methods of measuring the \"quality\" of an indicator that could serve as a high-precision keyword: (1) interannotator agreement based on annotators consensus from Mechanical Turk, on the assumption that the number of annotators selecting a cue indicates its strength and reliability (IA characteristics); (2) percent sarcastic (evil) and frequency statistics in the HP Train Dataset as R & W characteristics (percent characteristics); and (3) the queues that select a threshold indicating its strength and reliability. & ARcastic (us) and frequency statistics that we classify as R & W characteristics."}, {"heading": "5.1 Results from High Precision Classifiers", "text": "The HP Sarcasm and Nasty Classifiers were trained on the three feature sets with the following parameters: IA features we exhaust all combinations of \u03b2 = [.70,.75,.80,.85,.90,.95, 1.00], \u03b1 = [.35,.40,.45,.50,.55,.60,.65,.7], and \u03b81 = [2, 4, 6, 8, 10]; for the percent features and \u03c72 features we exhaust again \u03b81 = [2, 4, 6, 8, 10] and \u03b82 = [.55,.60,.65,.70,.75,.80,.85,.90,.95, 1.00]. Tables 4 and 5 show a subset of experiments with each feature set. We want to select parameters that maximize precision without sacrificing too much memory."}, {"heading": "6 Extraction Patterns", "text": "The template < subj > active verb < dobj > matches where a subject is followed by an active verb and a direct object. However, these matches are not limited to exact surface matches, since the required HP classifiers, such as this pattern, would match the phrase \"have a problem.\" Table 10 in the appendix contains examples from IAC that match the instantiated template patterns and a direct object. An excerpt from the front row in Table 10 \"It is quite strange to meet someone at this time and age who lacks any knowledge of the mechanism of adjustment, as it was declared 150 years ago\" corresponds to < subtly > pattern Q. \""}, {"heading": "6.1 Results from Pattern Classifier", "text": "The Pattern Classifiers classify an expression as Sarcastic (Nasty) if at least two patterns are present and are above the thresholds \u03b81 and \u03b82, which exhausts all combinations of \u03b81 = [2, 4, 6, 8, 10] and \u03b82 = [.55,.60,.65,.70,.75,.85,.90,.95, 1.00]. Counterclasses are predicted if the expression contains less than two patterns. Exhaustive classifications are first made using the expressions in the development group \"PE eval.\" Fig. 4 shows the precision and recall of precision and matching for success1 = [2, 10] and all values of the Sarcasm development group eval. \"As memory increases, precision decreases. By including patterns that appear only 2 times, we get a better memory. Restricting phenomena 1 to 10 yields fewer patterns and lower recall8 shows different results for the parameters."}, {"heading": "7 Discussion and Future Work", "text": "In this first phase we are dealing with a very complex system, in which the question is to what extent it is a system in which people must put themselves and themselves at the centre. (...) In the second half of the last decade we are dealing with a system in which people are able to understand the world. (...) In the third half of the last decade we are dealing with a system in which people are able to understand the world. (...) We have not understood the world. (...) We have not understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it. (...) We have understood it."}, {"heading": "8 Appendix A. Instances of Learned", "text": ""}], "references": [{"title": "Clues for detecting", "author": ["Carvalho et al.2009] P. Carvalho", "L. Sarmento", "M.J. Silva", "E. de Oliveira"], "venue": null, "citeRegEx": "Carvalho et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Carvalho et al\\.", "year": 2009}, {"title": "Semi-supervised recognition of sarcastic sentences in twitter and amazon", "author": ["Davidov et al.2010] D. Davidov", "O. Tsur", "A. Rappoport"], "venue": "In Proc. of the Fourteenth Conference on Computational Natural Language Learning,", "citeRegEx": "Davidov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Davidov et al\\.", "year": 2010}, {"title": "Reactions to irony in discourse: Evidence for the least disruption principle", "author": ["S. Attardo", "D. Boxer"], "venue": "Journal of Pragmatics,", "citeRegEx": "Eisterhold et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Eisterhold et al\\.", "year": 2006}, {"title": "Irony and sarcasm: Corpus generation and analysis using crowdsourcing", "author": ["E. Filatova"], "venue": "In Language Resources and Evaluation Conference,", "citeRegEx": "Filatova.,? \\Q2012\\E", "shortCiteRegEx": "Filatova.", "year": 2012}, {"title": "Modeling of stylistic variation in social media with stretchy patterns", "author": ["D. Adamson", "C.P. Ros\u00e9"], "venue": "In Proc. of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties,", "citeRegEx": "Gianfortoni et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gianfortoni et al\\.", "year": 2011}, {"title": "Irony in talk among friends", "author": ["R.W. Gibbs"], "venue": "Metaphor and Symbol,", "citeRegEx": "Gibbs.,? \\Q2000\\E", "shortCiteRegEx": "Gibbs.", "year": 2000}, {"title": "Identifying sarcasm in twitter: a closer look", "author": ["S. Muresan", "N. Wacholder"], "venue": "In Proc. of the 49th Annual Meeting of the ACL: Human Language Technologies: short papers,", "citeRegEx": "Gonz\u00e1lez.Ib\u00e1\u00f1ez et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gonz\u00e1lez.Ib\u00e1\u00f1ez et al\\.", "year": 2011}, {"title": "Offensive language detection using multi-level classification", "author": ["Razavi et al.2010] A. Razavi", "D. Inkpen", "S. Uritsky", "S. Matwin"], "venue": "Advances in Artificial Intelligence,", "citeRegEx": "Razavi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Razavi et al\\.", "year": 2010}, {"title": "Mining subjective knowledge from customer reviews: a specific case of irony detection", "author": ["Reyes", "Rosso2011] A. Reyes", "P. Rosso"], "venue": "In Proc. of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis (WASSA 2.011),", "citeRegEx": "Reyes et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Reyes et al\\.", "year": 2011}, {"title": "From humor recognition to irony detection: The figurative language of social media", "author": ["Reyes et al.2012] A. Reyes", "P. Rosso", "D. Buscaldi"], "venue": "Data & Knowledge Engineering", "citeRegEx": "Reyes et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Reyes et al\\.", "year": 2012}, {"title": "Learning extraction patterns for subjective expres", "author": ["Riloff", "Wiebe2003] E. Riloff", "J. Wiebe"], "venue": null, "citeRegEx": "Riloff et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Riloff et al\\.", "year": 2003}, {"title": "Cheap and fast\u2014but is it good?: evaluating non-expert annotations for natural language tasks", "author": ["Snow et al.2008] R. Snow", "B. O\u2019Conner", "D. Jurafsky", "A.Y. Ng"], "venue": "In Proc. of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Snow et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Snow et al\\.", "year": 2008}, {"title": "Automatic identification of personal insults on social news sites", "author": ["Sood et al.2011] S.O. Sood", "E.F. Churchill", "J. Antin"], "venue": "Journal of the American Society for Information Science and Technology", "citeRegEx": "Sood et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sood et al\\.", "year": 2011}, {"title": "Irony and the use-mention distinction", "author": ["Sperber", "Wilson1981] Dan Sperber", "Deidre Wilson"], "venue": "Radical Pragmatics,", "citeRegEx": "Sperber et al\\.,? \\Q1981\\E", "shortCiteRegEx": "Sperber et al\\.", "year": 1981}, {"title": "Smokey: Automatic recognition of hostile messages", "author": ["E. Spertus"], "venue": "In Proc. of the National Conference on Artificial Intelligence,", "citeRegEx": "Spertus.,? \\Q1997\\E", "shortCiteRegEx": "Spertus.", "year": 1997}, {"title": "A bootstrapping method for learning semantic lexicons using extraction pattern contexts", "author": ["Thelen", "Riloff2002] M. Thelen", "E. Riloff"], "venue": "In Proc. of the ACL-02 conference on Empirical methods in natural language processing-Volume", "citeRegEx": "Thelen et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Thelen et al\\.", "year": 2002}, {"title": "Icwsm\u2013a great catchy name: Semi-supervised recognition of sarcastic sentences in online product reviews", "author": ["Tsur et al.2010] O. Tsur", "D. Davidov", "A. Rappoport"], "venue": "In Proc. of the fourth international AAAI conference on weblogs and social media,", "citeRegEx": "Tsur et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Tsur et al\\.", "year": 2010}, {"title": "A corpus for research on deliberation and debate", "author": ["Pranav Anand", "Robert Abbott", "Jean E. Fox Tree"], "venue": "In Language Resources and Evaluation Conference,", "citeRegEx": "Walker et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Walker et al\\.", "year": 2012}, {"title": "Development and use of a goldstandard data set for subjectivity classifications", "author": ["Wiebe et al.1999] J.M. Wiebe", "R.F. Bruce", "T.P. O\u2019Hara"], "venue": "In Proc. of the 37th annual meeting of the Association for Computational Linguistics,", "citeRegEx": "Wiebe et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Wiebe et al\\.", "year": 1999}, {"title": "Recognizing and organizing opinions expressed in the world press. In Working Notes-New Directions in Question Answering", "author": ["Wiebe et al.2003] J. Wiebe", "E. Breck", "C. Buckley", "C. Cardie", "P. Davis", "B. Fraser", "D. Litman", "D. Pierce", "E. Riloff", "T. Wilson"], "venue": null, "citeRegEx": "Wiebe et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Wiebe et al\\.", "year": 2003}, {"title": "Opinionfinder: A system for subjectivity analysis", "author": ["Wilson et al.2005] T. Wilson", "P. Hoffmann", "S. Somasundaran", "J. Kessler", "J. Wiebe", "Y. Choi", "C. Cardie", "E. Riloff", "S. Patwardhan"], "venue": "In Proc. of HLT/EMNLP on Interactive Demonstrations,", "citeRegEx": "Wilson et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Wilson et al\\.", "year": 2005}, {"title": "Detecting offensive tweets", "author": ["Xiang et al.2012] G. Xiang", "B. Fan", "L. Wang", "J. Hong", "C. Rose"], "venue": null, "citeRegEx": "Xiang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Xiang et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 6, "context": "Previous work on the automatic identification of sarcasm has focused on Twitter using the #sarcasm (Gonz\u00e1lez-Ib\u00e1\u00f1ez et al., 2011) and #irony (Reyes et al.", "startOffset": 99, "endOffset": 129}, {"referenceID": 9, "context": ", 2011) and #irony (Reyes et al., 2012) tags and a combined variety of tags and smileys (Davidov et al.", "startOffset": 19, "endOffset": 39}, {"referenceID": 1, "context": ", 2012) tags and a combined variety of tags and smileys (Davidov et al., 2010).", "startOffset": 56, "endOffset": 78}, {"referenceID": 16, "context": "Another popular domain examines Amazon product reviews looking for irony (Reyes and Rosso, 2011), sarcasm (Tsur et al., 2010), and a corpus collection for sarcasm (Filatova, 2012).", "startOffset": 106, "endOffset": 125}, {"referenceID": 3, "context": ", 2010), and a corpus collection for sarcasm (Filatova, 2012).", "startOffset": 45, "endOffset": 61}, {"referenceID": 0, "context": "(Carvalho et al., 2009) looks for irony in comments in online newpapers which can have a thread-like structure.", "startOffset": 0, "endOffset": 23}, {"referenceID": 14, "context": "Previous work includes identifying flames in emails (Spertus, 1997) and other messaging interfaces (Razavi et al.", "startOffset": 52, "endOffset": 67}, {"referenceID": 7, "context": "Previous work includes identifying flames in emails (Spertus, 1997) and other messaging interfaces (Razavi et al., 2010), identifying insults in Twitter (Xiang et al.", "startOffset": 99, "endOffset": 120}, {"referenceID": 21, "context": ", 2010), identifying insults in Twitter (Xiang et al., 2012), as well as comments from new sites (Sood et al.", "startOffset": 40, "endOffset": 60}, {"referenceID": 12, "context": ", 2012), as well as comments from new sites (Sood et al., 2011).", "startOffset": 44, "endOffset": 63}, {"referenceID": 20, "context": "R&W did not need to develop a \u201cKnown Subjective Vocabulary\u201d because previous work provided one (Wilson et al., 2005; Wiebe et al., 1999; Wiebe et al., 2003).", "startOffset": 95, "endOffset": 156}, {"referenceID": 18, "context": "R&W did not need to develop a \u201cKnown Subjective Vocabulary\u201d because previous work provided one (Wilson et al., 2005; Wiebe et al., 1999; Wiebe et al., 2003).", "startOffset": 95, "endOffset": 156}, {"referenceID": 19, "context": "R&W did not need to develop a \u201cKnown Subjective Vocabulary\u201d because previous work provided one (Wilson et al., 2005; Wiebe et al., 1999; Wiebe et al., 2003).", "startOffset": 95, "endOffset": 156}, {"referenceID": 5, "context": "Second, sarcasm is exhibited by a wide range of different forms and with different dialogue strategies such as jocularity, understatement and hyberbole (Gibbs, 2000; Eisterhold et al., 2006; Bryant and Fox Tree, 2002; Filatova, 2012).", "startOffset": 152, "endOffset": 233}, {"referenceID": 2, "context": "Second, sarcasm is exhibited by a wide range of different forms and with different dialogue strategies such as jocularity, understatement and hyberbole (Gibbs, 2000; Eisterhold et al., 2006; Bryant and Fox Tree, 2002; Filatova, 2012).", "startOffset": 152, "endOffset": 233}, {"referenceID": 3, "context": "Second, sarcasm is exhibited by a wide range of different forms and with different dialogue strategies such as jocularity, understatement and hyberbole (Gibbs, 2000; Eisterhold et al., 2006; Bryant and Fox Tree, 2002; Filatova, 2012).", "startOffset": 152, "endOffset": 233}, {"referenceID": 4, "context": "Because there is no prior \u201cKnown Sarcastic Vocabulary\u201d we pilot two different methods for discovering lexical cues to sarcasm and nastiness, and experiment with combinations of cues that could yield a high precision classifier (Gianfortoni et al., 2011).", "startOffset": 227, "endOffset": 253}, {"referenceID": 3, "context": "This crowdsourcing method is similar to (Filatova, 2012), but where their data is monologic, ours is dialogic.", "startOffset": 40, "endOffset": 56}, {"referenceID": 5, "context": "Sarcasm is known to be highly variable in form, and to depend, in some cases, on context for its interpretation (Sperber and Wilson, 1981; Gibbs, 2000; Bryant and Fox Tree, 2002).", "startOffset": 112, "endOffset": 178}, {"referenceID": 11, "context": "(Snow et al., 2008) measures the quality of Mechanical Turk annotations on common NLP tasks by comparing them to a gold standard.", "startOffset": 0, "endOffset": 19}, {"referenceID": 3, "context": "Our crowdsourcing method is similar to (Filatova, 2012).", "startOffset": 39, "endOffset": 55}, {"referenceID": 5, "context": "Previous work claims that recognition of sarcasm (1) depends on knowledge of the speaker, (2) world knowledge, or (3) use of context (Gibbs, 2000; Eisterhold et al., 2006; Bryant and Fox Tree, 2002; Carvalho et al., 2009).", "startOffset": 133, "endOffset": 221}, {"referenceID": 2, "context": "Previous work claims that recognition of sarcasm (1) depends on knowledge of the speaker, (2) world knowledge, or (3) use of context (Gibbs, 2000; Eisterhold et al., 2006; Bryant and Fox Tree, 2002; Carvalho et al., 2009).", "startOffset": 133, "endOffset": 221}, {"referenceID": 0, "context": "Previous work claims that recognition of sarcasm (1) depends on knowledge of the speaker, (2) world knowledge, or (3) use of context (Gibbs, 2000; Eisterhold et al., 2006; Bryant and Fox Tree, 2002; Carvalho et al., 2009).", "startOffset": 133, "endOffset": 221}], "year": 2017, "abstractText": "More and more of the information on the web is dialogic, from Facebook newsfeeds, to forum conversations, to comment threads on news articles. In contrast to traditional, monologic Natural Language Processing resources such as news, highly social dialogue is frequent in social media, making it a challenging context for NLP. This paper tests a bootstrapping method, originally proposed in a monologic domain, to train classifiers to identify two different types of subjective language in dialogue: sarcasm and nastiness. We explore two methods of developing linguistic indicators to be used in a first level classifier aimed at maximizing precision at the expense of recall. The best performing classifier for the first phase achieves 54% precision and 38% recall for sarcastic utterances. We then use general syntactic patterns from previous work to create more general sarcasm indicators, improving precision to 62% and recall to 52%. To further test the generality of the method, we then apply it to bootstrapping a classifier for nastiness dialogic acts. Our first phase, using crowdsourced nasty indicators, achieves 58% precision and 49% recall, which increases to 75% precision and 62% recall when we bootstrap over the first level with generalized syntactic patterns.", "creator": "LaTeX with hyperref package"}}}