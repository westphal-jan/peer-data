{"id": "1708.09025", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Aug-2017", "title": "Unsupervised Terminological Ontology Learning based on Hierarchical Topic Modeling", "abstract": "In this paper, we present hierarchical relationbased latent Dirichlet allocation (hrLDA), a data-driven hierarchical topic model for extracting terminological ontologies from a large number of heterogeneous documents. In contrast to traditional topic models, hrLDA relies on noun phrases instead of unigrams, considers syntax and document structures, and enriches topic hierarchies with topic relations. Through a series of experiments, we demonstrate the superiority of hrLDA over existing topic models, especially for building hierarchies. Furthermore, we illustrate the robustness of hrLDA in the settings of noisy data sets, which are likely to occur in many practical scenarios. Our ontology evaluation results show that ontologies extracted from hrLDA are very competitive with the ontologies created by domain experts.", "histories": [["v1", "Tue, 29 Aug 2017 21:04:11 GMT  (1614kb,D)", "http://arxiv.org/abs/1708.09025v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.LG", "authors": ["xiaofeng zhu", "diego klabjan", "patrick bless"], "accepted": false, "id": "1708.09025"}, "pdf": {"name": "1708.09025.pdf", "metadata": {"source": "CRF", "title": "Unsupervised Terminological Ontology Learning based on Hierarchical Topic Modeling", "authors": ["Xiaofeng Zhu", "Diego Klabjan", "Patrick N Bless"], "emails": ["xiaofengzhu2013@u.northwestern.edu", "d-klabjan@northwestern.edu", "patrick.n.bless@intel.com"], "sections": [{"heading": null, "text": "In fact, most of them are able to survive on their own, and they see themselves able to survive on their own, \"he said in an interview with The New York Times."}, {"heading": "II. BACKGROUND", "text": "In this section, we present our main base model, hierarchical latent dirichlet allocation (hLDA), several Chinese DDA tables (hLDA) and some of their extensions. We start with the components of hLDA - latent dirichlet allocation (LDA) and the Chinese restaurant theme (CRP) - and then explain why hLDA needs improvements in both building hierarchies and drawing theme paths. LDA is a three-level Bayesian model in which each document is a mixture of several topics, and each topic is a distribution across words. Due to the lack of defining information, LDA is unable to distinguish different instances that contain the same substantive words (e.g. \"I trimmed my polished topics\" and \"I have just hammered many rosty nails\"). Furthermore, in LDA, all words are likely to be independent and equally important. This is problematic because different words and phrases in the theme generation should be different."}, {"heading": "III. HIERARCHICAL RELATION-BASED LATENT DIRICHLET ALLOCATION", "text": "The main problem that we address in this section is the unattended generation of terminological ontologies. The basic concept of hrLDA is this: when people create a document, they first select several topics, then they select some noun phrases as topics for each topic. Next, they invent relationship triplets for each topic to describe that topic or its relationship to other subjects. Finally, they associate the subject phrases and relation triplets with sentences using reasonable grammar. The main topic is usually described with the most important relation triplets. Sentences in a paragraph, especially adjacent sentences, probably express the same topic.We start by describing the process of reconstructing LDA, then we explain the relationship extraction from heterogeneous documents. Next, we propose an improved method of topic partitioning via CRP. Finally, we show how to build topic hierarchies that bind to extracted relation triplets."}, {"heading": "A. Relation-based Latent Dirichlet Allocation", "text": "An atomic sentence (see module T in figure 2) is a sentence that contains only one subject (S), one object (O) and one verb (V) between the subject and the object. For each atomic sentence, whose object is also a noun phrase, there are at least two relationship triplets (e.g.: \"The tiger who gave the excellent speech is a relation to triplets: (tiger, speech, to be given by tiger) and (tiger, to be, more beautiful). In contrast, a complex sentence can be divided into several atomic sentences."}, {"heading": "B. Relation Triplet Extraction", "text": "The extraction of relation triplets is the essential step of hrLDA and at the same time the key process for converting a hierarchical theme tree into an ontology structure. In general, there are two types of relation triplets: \u2022 subject-predicate-object relationships, e.g. New York is the largest city in the United States (New York, be it the largest city in the United States); \u2022 subject-predicate-object relationships, e.g. Queen Elizabeth \u21d2. A special type of relation triplets can be extracted from presentation documents, e.g. those written in PowerPoint using document structures. Normally, lines in a slide are not complete sentences, which means that language parses do not work. Indents and bullet types, however, usually express inclusion relationships between adjacent lines as they are written in PowerPoint."}, {"heading": "C. Acquaintance Chinese Restaurant Process", "text": "As mentioned in Section 2, CRP always assigns the highest probability to the largest table, which assumes that customers are more likely to sit at the table that has the largest number of customers. (This ignores the social reality that a person is more likely to choose the table in which their closest friend sits, although the table also includes unknown people who are actually friends of friends. (Similar to human-written documents, adjacent sentences usually describe the same topics.) We consider a restaurant table as a topic and a person seated at one of the tables as a noun phrase. To punish the largest topic and assign high probabilities to adjacent noun phrases that are in the same topics, we introduce an improved partitioning method, Acquaintance Chinese Restaurant Process (ACRP).The ultimate goals of ACRP are to estimate the number of topics for rLDA and set the initial topic distribution for LDA."}, {"heading": "D. Nested Acquaintance Chinese Restaurant Process", "text": "The procedure for extending ACRP to hierarchies is essential for why hrLDA has trumped the hLDA level. (We have not managed to break through the hLDA level.) Instead of a predefined tree depth of L, there may be several ways in which the hLDA level addresses each topic it revolves around. (We do not need to leave the hLDA level.) In practice, we do not associate phrases with the root phrases as it does the entire vocabulary. An inner node of a theme tree contains a selected topic that represents a topic that may have multiple sub-topics. (The root node is visited by all phrases.) We define a hashmap document as the key and the current sheet nodes of the document. (We have a selected topic that contains a selected topic.) A sheet node contains an unedited formulation (We define the document as a sheet key and a current document hashmap."}, {"heading": "IV. EMPIRICAL RESULTS", "text": "A. ImplementationWe used the Apache poi library to parse texts from pdfs, Word documents, and presentation files; the MALLET toolbox [30] to implement LDA, optimized LDA [31], and hLDA; the Apache Jena library to add relationships, properties, and members to hierarchical theme trees; and Stanford Protege1 to illustrate extracted ontologies. We provide our code and data 2. We used the same empirical hyper-parameter setting (i.e. \u03b1 = 1, \u03b7 = 0.1, and \u03b3 = 0.01) in all of our experiments. We then demonstrate the evaluation results from two aspects: topic hierarchy and ontology rule."}, {"heading": "B. Hierarchy Evaluation", "text": "In this section, we present the evaluation results of hrLDA tested against optimized LDA, hLDA, and phrase hLDA (i.e., hLDA based on noun phrases), as well as ontological examples that have extracted hrLDA theme text data from the real world. The entire corpus that we have generated contains 349,362 characters (after removing stop words and cleaning) and is composed of articles about semiconductor packaging. It includes 84 presentation files, articles from 1,782 Wikipedia pages, and 3,000 research papers published in the IEEE conference procedures over the last decade. To see the performance in data sets of different scales, we also used a smaller Corpus Wiki that has collected the articles from the Wikipedia pages. We extract a single theme tree that uses each of the four models; hrLDA becomes rLDA, and phrase LDA becomes Perrase-based Phrase-LDA-based Lxx10."}, {"heading": "C. Gold Standard-based Ontology Evaluation", "text": "The visualization of a concrete ontology on the semiconductor packaging domain HL DA DA Pacific Scores is illustrated in Figure 10. For example, Topic Packaging contains topic-related circuit packaging, and Topic Label jedec is associated with relationship HL (jedec, short for, Joint Electronon Device Engineering Council).We use KB-LDA, phrase hLDA, and LDA + GSHL as our basic methods and compare ontologies extracted from hrLDA, KB-LDA, phrase hLDA, and LDA + GSHL with DBpedia ontologies. We use precision, recall, and F measurement for this ontology evaluation. A true positive case is an ontology rule that can be found in an extracted ontology, phrase hLDA, phrase hLDA, and LDA + GSHL with DBpedia ontologies ontologies. We use precision, recall, and F evaluation for this ontology."}, {"heading": "V. CONCLUDING REMARKS", "text": "In this paper, we have proposed a completely unsupervised model, hrLDA, for learning terminological ontology. hrLDA is a domain-independent and self-learning model, which means that it is very promising for learning ontologies in new domains, and thus significant time and effort in ontology acquisition. hrLDA has been compared with popular topic models to interpret how our algorithm learns meaningful hierarchies. By incorporating syntax and document structures, hrLDA is able to extract more descriptive topics. In addition, hrLDA removes the constraints on tree depth and the limited number of topic paths. In addition, ACRP allows hrLDA to create more reasonable topics and faster in Gibbs Sampling. We have also compared hrLDA with several unsupervised ontology models and demonstrated that hrLDA is not applicable terminology ontologies from data that can be readily ascertained by LDA."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work was supported in part by Intel Corporation, Semiconductor Research Corporation (SRC), and we thank Professor Goce Trajcevski of Northwestern University for his insightful suggestions and discussions. This work was done in part using the resource Protege, which is supported by the GM10331601 grant from the National Institute of General Medical Sciences of the United States National Institutes of Health."}], "references": [{"title": "Wordnet: a lexical database for english", "author": ["G.A. Miller"], "venue": "Communications of the ACM, vol. 38, no. 11, pp. 39\u201341, 1995.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1995}, {"title": "Dbpedia: A nucleus for a web of open data", "author": ["S. Auer", "C. Bizer", "G. Kobilarov", "J. Lehmann", "R. Cyganiak", "Z. Ives"], "venue": "Proceedings of the 6th International Semantic Web Conference. Springer, 2007, pp. 722\u2013735.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Yago: A core of semantic knowledge", "author": ["F.M. Suchanek", "G. Kasneci", "G. Weikum"], "venue": "Proceedings of the 16th international conference on World Wide Web, 2007, pp. 697\u2013 706.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["K. Bollacker", "C. Evans", "P. Paritosh", "T. Sturge", "J. Taylor"], "venue": "Proceedings of the 2008 ACM SIGMOD international conference on Management of data, 2008, pp. 1247\u20131250.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Toward an architecture for neverending language learning", "author": ["A. Carlson", "J. Betteridge", "B. Kisiel", "B. Settles", "E.R. Hruschka", "T.M. Mitchell"], "venue": "AAAI, 2010.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Deepdive: Webscale knowledge-base construction using statistical learning and inference", "author": ["F. Niu", "C. Zhang", "C. R\u00e9", "J.W. Shavlik"], "venue": "VLDS, vol. 12, pp. 25\u201328, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Domain cartridge: Unsupervised framework for shallow domain ontology construction from corpus", "author": ["S. Mukherjee", "J. Ajmera", "S. Joshi"], "venue": "Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management. ACM, 2014, pp. 929\u2013938.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Knowledge vault: A web-scale approach to probabilistic knowledge fusion", "author": ["X.L. Dong", "E. Gabrilovich", "G. Heitz", "W. Horn", "N. Lao", "K. Murphy", "T. Strohmann", "S. Sun", "W. Zhang"], "venue": "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014, pp. 601\u2013610.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Largescale knowledge base completion: Inferring via grounding network sampling over selected instances", "author": ["Z. Wei", "J. Zhao", "K. Liu", "Z. Qi", "Z. Sun", "G. Tian"], "venue": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, ser. CIKM \u201915. ACM, 2015, pp. 1331\u20131340.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Inducing space dirichlet process mixture largemargin entity relationshipinference in knowledge bases", "author": ["S.P. Chatzis"], "venue": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 2015, pp. 1311\u20131320.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Neighborhood mixture model for knowledge base completion", "author": ["D.Q. Nguyen", "K. Sirts", "L. Qu", "M. Johnson"], "venue": "arXiv preprint arXiv:1606.06461, 2016.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "JOURNAL of Machine Learning Research, vol. 3, pp. 993\u20131022, 2003.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Data-driven approach for ontology learning", "author": ["I. Ocampo-Guzman", "I. Lopez-Arevalo", "V. Sosa-Sosa"], "venue": "Electrical Engineering, Computing Science and Automatic Control, CCE, 2009 6th International Conference on. IEEE, 2009, pp. 1\u20136.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Probabilistic topic models for learning terminological ontologies", "author": ["W. Wei", "P. Barnaghi", "A. Bargiela"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 22, no. 7, pp. 1028\u20131040, 2010.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "An ontology term extracting method based on latent dirichlet allocation", "author": ["Y. Jing", "W. Junli", "Z. Xiaodong"], "venue": "Multimedia Information Networking and Security (MINES), 2012 Fourth International Conference on. IEEE, 2012, pp. 366\u2013369.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Tree labeled lda: A hierarchical model for web summaries", "author": ["A. Slutsky", "X. Hu", "Y. An"], "venue": "Big Data, 2013 IEEE International Conference on. IEEE, 2013, pp. 134\u2013140.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Terminological ontology learning and population using latent dirichlet allocation", "author": ["F. Colace", "M. De Santo", "L. Greco", "F. Amato", "V. Moscato", "A. Picariello"], "venue": "Journal of Visual Languages & Computing, vol. 25, no. 6, pp. 818\u2013826, 2014.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Kb-lda: Jointly learning a knowledge base of hierarchy, relations, and facts", "author": ["D. Movshovitz-Attias", "W.W. Cohen"], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, 2015, pp. 1449\u20131459.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Grounding topic models with knowledge bases", "author": ["Z. Hu", "G. Luo", "M. Sachan", "E. Xing", "Z. Nie"], "venue": "Proceedings of the 24th International Joint Conference on Artificial Intelligence, 2016.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "Hierarchical topic models and the nested chinese restaurant process", "author": ["D.M. Blei", "T.L. Griffiths", "M.I. Jordan", "J.B. Tenenbaum"], "venue": "Advances in Neural Information Processing Systems 16. MIT Press, 2004, p. 17.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}, {"title": "The nested chinese restaurant process and bayesian nonparametric inference of topic hierarchies", "author": ["D.M. Blei", "T.L. Griffiths", "M.I. Jordan"], "venue": "Journal of the ACM (JACM), vol. 57, no. 2, p. 7, 2010.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Distance dependent chinese restaurant processes", "author": ["D.M. Blei", "P.I. Frazier"], "venue": "The Journal of Machine Learning Research, vol. 12, pp. 2461\u20132488, 2011.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Nested chinese restaurant franchise process: Applications to user tracking and document modeling", "author": ["A. Ahmed", "L. Hong", "A.J. Smola"], "venue": "ICML (3), 2013, pp. 1426\u20131434.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Nested hierarchical dirichlet processes", "author": ["J. Paisley", "C. Wang", "D.M. Blei", "M.I. Jordan"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 37, no. 2, pp. 256\u2013270, 2015.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["C.D. Manning", "M. Surdeanu", "J. Bauer", "J. Finkel", "S.J. Bethard.", "D. McClosky"], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 2014, pp. 55\u201360.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Open language learning for information extraction", "author": ["Mausam", "M. Schmitz", "R. Bart", "S. Soderland", "O. Etzioni"], "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, 2012, pp. 524\u2013534.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2012}, {"title": "Finding scientific topics", "author": ["T.L. Griffiths", "M. Steyvers"], "venue": "Proceedings of the National Academy of Sciences, vol. 101, no. suppl 1, pp. 5228\u20135235, 2004.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2004}, {"title": "A bootstrapping method for learning semantic lexicons using extraction pattern contexts", "author": ["M. Thelen", "E. Riloff"], "venue": "Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10. Association for Computational Linguistics, 2002, pp. 214\u2013221.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2002}, {"title": "Large-scale learning of relation-extraction rules with distant supervision from the web", "author": ["S. Krause", "H. Li", "H. Uszkoreit", "F. Xu"], "venue": "The Semantic WebISWC 2012, pp. 263\u2013278, 2012.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "Mallet: A machine learning for language toolkit", "author": ["A.K. McCallum"], "venue": "2002, http://mallet.cs.umass.edu.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2002}, {"title": "On smoothing and inference for topic models", "author": ["A. Asuncion", "M. Welling", "P. Smyth", "Y.W. Teh"], "venue": "Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, pp. 27\u201334, 2009.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "A methodology for ontology evaluation using topic models", "author": ["A. Gangopadhyay", "M. Molek", "Y. Yesha", "M. Brady", "Y. Yesha"], "venue": "Intelligent Networking and Collaborative Systems (INCoS), 2012 4th International Conference on. IEEE, 2012, pp. 390\u2013395.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "Using natural language to integrate, evaluate, and optimize extracted knowledge bases", "author": ["D. Downey", "C.S. Bhagavatula", "A. Yates"], "venue": "Proceedings of the 2013 workshop on Automated knowledge base construction. ACM, 2013, pp. 61\u201366.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Although researchers have made significant progress on knowledge acquisition and have proposed many ontologies, for instance, WordNet [1], DBpedia [2], YAGO [3], Freebase, [4] Nell [5], DeepDive [6], Domain Cartridge [7], Knowledge Vault [8], INS-ES [9], iDLER [10], and TransE-NMM [11], current ontology construction methods still rely heavily on manual parsing and existing knowledge bases.", "startOffset": 134, "endOffset": 137}, {"referenceID": 1, "context": "Although researchers have made significant progress on knowledge acquisition and have proposed many ontologies, for instance, WordNet [1], DBpedia [2], YAGO [3], Freebase, [4] Nell [5], DeepDive [6], Domain Cartridge [7], Knowledge Vault [8], INS-ES [9], iDLER [10], and TransE-NMM [11], current ontology construction methods still rely heavily on manual parsing and existing knowledge bases.", "startOffset": 147, "endOffset": 150}, {"referenceID": 2, "context": "Although researchers have made significant progress on knowledge acquisition and have proposed many ontologies, for instance, WordNet [1], DBpedia [2], YAGO [3], Freebase, [4] Nell [5], DeepDive [6], Domain Cartridge [7], Knowledge Vault [8], INS-ES [9], iDLER [10], and TransE-NMM [11], current ontology construction methods still rely heavily on manual parsing and existing knowledge bases.", "startOffset": 157, "endOffset": 160}, {"referenceID": 3, "context": "Although researchers have made significant progress on knowledge acquisition and have proposed many ontologies, for instance, WordNet [1], DBpedia [2], YAGO [3], Freebase, [4] Nell [5], DeepDive [6], Domain Cartridge [7], Knowledge Vault [8], INS-ES [9], iDLER [10], and TransE-NMM [11], current ontology construction methods still rely heavily on manual parsing and existing knowledge bases.", "startOffset": 172, "endOffset": 175}, {"referenceID": 4, "context": "Although researchers have made significant progress on knowledge acquisition and have proposed many ontologies, for instance, WordNet [1], DBpedia [2], YAGO [3], Freebase, [4] Nell [5], DeepDive [6], Domain Cartridge [7], Knowledge Vault [8], INS-ES [9], iDLER [10], and TransE-NMM [11], current ontology construction methods still rely heavily on manual parsing and existing knowledge bases.", "startOffset": 181, "endOffset": 184}, {"referenceID": 5, "context": "Although researchers have made significant progress on knowledge acquisition and have proposed many ontologies, for instance, WordNet [1], DBpedia [2], YAGO [3], Freebase, [4] Nell [5], DeepDive [6], Domain Cartridge [7], Knowledge Vault [8], INS-ES [9], iDLER [10], and TransE-NMM [11], current ontology construction methods still rely heavily on manual parsing and existing knowledge bases.", "startOffset": 195, "endOffset": 198}, {"referenceID": 6, "context": "Although researchers have made significant progress on knowledge acquisition and have proposed many ontologies, for instance, WordNet [1], DBpedia [2], YAGO [3], Freebase, [4] Nell [5], DeepDive [6], Domain Cartridge [7], Knowledge Vault [8], INS-ES [9], iDLER [10], and TransE-NMM [11], current ontology construction methods still rely heavily on manual parsing and existing knowledge bases.", "startOffset": 217, "endOffset": 220}, {"referenceID": 7, "context": "Although researchers have made significant progress on knowledge acquisition and have proposed many ontologies, for instance, WordNet [1], DBpedia [2], YAGO [3], Freebase, [4] Nell [5], DeepDive [6], Domain Cartridge [7], Knowledge Vault [8], INS-ES [9], iDLER [10], and TransE-NMM [11], current ontology construction methods still rely heavily on manual parsing and existing knowledge bases.", "startOffset": 238, "endOffset": 241}, {"referenceID": 8, "context": "Although researchers have made significant progress on knowledge acquisition and have proposed many ontologies, for instance, WordNet [1], DBpedia [2], YAGO [3], Freebase, [4] Nell [5], DeepDive [6], Domain Cartridge [7], Knowledge Vault [8], INS-ES [9], iDLER [10], and TransE-NMM [11], current ontology construction methods still rely heavily on manual parsing and existing knowledge bases.", "startOffset": 250, "endOffset": 253}, {"referenceID": 9, "context": "Although researchers have made significant progress on knowledge acquisition and have proposed many ontologies, for instance, WordNet [1], DBpedia [2], YAGO [3], Freebase, [4] Nell [5], DeepDive [6], Domain Cartridge [7], Knowledge Vault [8], INS-ES [9], iDLER [10], and TransE-NMM [11], current ontology construction methods still rely heavily on manual parsing and existing knowledge bases.", "startOffset": 261, "endOffset": 265}, {"referenceID": 10, "context": "Although researchers have made significant progress on knowledge acquisition and have proposed many ontologies, for instance, WordNet [1], DBpedia [2], YAGO [3], Freebase, [4] Nell [5], DeepDive [6], Domain Cartridge [7], Knowledge Vault [8], INS-ES [9], iDLER [10], and TransE-NMM [11], current ontology construction methods still rely heavily on manual parsing and existing knowledge bases.", "startOffset": 282, "endOffset": 286}, {"referenceID": 11, "context": "The classical topic model, latent Dirichlet allocation (LDA) [12], simplifies a document as a bag of its words and describes a topic as a distribution", "startOffset": 61, "endOffset": 65}, {"referenceID": 12, "context": "Prior research [13], [14], [15], [16], [17], [18], [19] has shown that LDA-based approaches are adequate for (terminological) ontology learning.", "startOffset": 15, "endOffset": 19}, {"referenceID": 13, "context": "Prior research [13], [14], [15], [16], [17], [18], [19] has shown that LDA-based approaches are adequate for (terminological) ontology learning.", "startOffset": 21, "endOffset": 25}, {"referenceID": 14, "context": "Prior research [13], [14], [15], [16], [17], [18], [19] has shown that LDA-based approaches are adequate for (terminological) ontology learning.", "startOffset": 27, "endOffset": 31}, {"referenceID": 15, "context": "Prior research [13], [14], [15], [16], [17], [18], [19] has shown that LDA-based approaches are adequate for (terminological) ontology learning.", "startOffset": 33, "endOffset": 37}, {"referenceID": 16, "context": "Prior research [13], [14], [15], [16], [17], [18], [19] has shown that LDA-based approaches are adequate for (terminological) ontology learning.", "startOffset": 39, "endOffset": 43}, {"referenceID": 17, "context": "Prior research [13], [14], [15], [16], [17], [18], [19] has shown that LDA-based approaches are adequate for (terminological) ontology learning.", "startOffset": 45, "endOffset": 49}, {"referenceID": 18, "context": "Prior research [13], [14], [15], [16], [17], [18], [19] has shown that LDA-based approaches are adequate for (terminological) ontology learning.", "startOffset": 51, "endOffset": 55}, {"referenceID": 13, "context": "Among models not using unigrams, LDA-based Global Similarity Hierarchy Learning (LDA+GSHL) [14] only extracts a subset of relations: \u201cbroader\u201d and \u201crelated\u201d relations.", "startOffset": 91, "endOffset": 95}, {"referenceID": 17, "context": "In addition, the topic hierarchies of KB-LDA [18] rely on hypernym-hyponym ar X iv :1 70 8.", "startOffset": 45, "endOffset": 49}, {"referenceID": 19, "context": "Regarding the third objective, we adapt and improve the hierarchical latent Dirichlet allocation (hLDA) model [20], [21].", "startOffset": 110, "endOffset": 114}, {"referenceID": 20, "context": "Regarding the third objective, we adapt and improve the hierarchical latent Dirichlet allocation (hLDA) model [20], [21].", "startOffset": 116, "endOffset": 120}, {"referenceID": 21, "context": "The theory of distance-dependent CRP was formerly proposed by David Blei [22].", "startOffset": 73, "endOffset": 77}, {"referenceID": 22, "context": "the fact that the single path was changed to multiple paths in some extensions of hLDA - the nested Chinese restaurant franchise processes [23] and the nested hierarchical Dirichlet Processes [24], - this topic path drawing strategy puts words from different domains into one topic when input data are mixed with topics from multiple domains.", "startOffset": 139, "endOffset": 143}, {"referenceID": 23, "context": "the fact that the single path was changed to multiple paths in some extensions of hLDA - the nested Chinese restaurant franchise processes [23] and the nested hierarchical Dirichlet Processes [24], - this topic path drawing strategy puts words from different domains into one topic when input data are mixed with topics from multiple domains.", "startOffset": 192, "endOffset": 196}, {"referenceID": 24, "context": "using a language parser such as the Stanford NLP parser [25] and Ollie [26].", "startOffset": 56, "endOffset": 60}, {"referenceID": 25, "context": "using a language parser such as the Stanford NLP parser [25] and Ollie [26].", "startOffset": 71, "endOffset": 75}, {"referenceID": 0, "context": "Normalize the (k + 1) probabilities to guarantee they are each in the range of [0, 1] and their sum is equal to 1.", "startOffset": 79, "endOffset": 85}, {"referenceID": 26, "context": "We use collapsed Gibbs sampling [27] for inference from posterior distribution P (Z|T, \u03b1, \u03b7) based on Equation 1.", "startOffset": 32, "endOffset": 36}, {"referenceID": 27, "context": "process [28].", "startOffset": 8, "endOffset": 12}, {"referenceID": 28, "context": "By assembling all subject and object pairs, we can build an undirected graph with the objects and the subjects constituting the nodes of the graph [29].", "startOffset": 147, "endOffset": 151}, {"referenceID": 29, "context": "We utilized the Apache poi library to parse texts from pdfs, word documents and presentation files; the MALLET toolbox [30] for the implementations of LDA, optimized LDA [31] and hLDA; the Apache Jena library to add relations, properties and members to hierarchical topic trees; and Stanford Protege1 for illustrating extracted ontologies.", "startOffset": 119, "endOffset": 123}, {"referenceID": 30, "context": "We utilized the Apache poi library to parse texts from pdfs, word documents and presentation files; the MALLET toolbox [30] for the implementations of LDA, optimized LDA [31] and hLDA; the Apache Jena library to add relations, properties and members to hierarchical topic trees; and Stanford Protege1 for illustrating extracted ontologies.", "startOffset": 170, "endOffset": 174}, {"referenceID": 31, "context": "We have tested the average perplexity and running time performance of ten independent runs on each of the four models [32], [33].", "startOffset": 118, "endOffset": 122}, {"referenceID": 32, "context": "We have tested the average perplexity and running time performance of ten independent runs on each of the four models [32], [33].", "startOffset": 124, "endOffset": 128}], "year": 2017, "abstractText": "In this paper, we present hierarchical relationbased latent Dirichlet allocation (hrLDA), a data-driven hierarchical topic model for extracting terminological ontologies from a large number of heterogeneous documents. In contrast to traditional topic models, hrLDA relies on noun phrases instead of unigrams, considers syntax and document structures, and enriches topic hierarchies with topic relations. Through a series of experiments, we demonstrate the superiority of hrLDA over existing topic models, especially for building hierarchies. Furthermore, we illustrate the robustness of hrLDA in the settings of noisy data sets, which are likely to occur in many practical scenarios. Our ontology evaluation results show that ontologies extracted from hrLDA are very competitive with the ontologies created by domain experts. Keywords-terminological ontology; ontology learning; hierarchical topic modeling; knowledge acquisition", "creator": "LaTeX with hyperref package"}}}