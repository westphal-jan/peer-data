{"id": "1708.09121", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Aug-2017", "title": "Interpretable Categorization of Heterogeneous Time Series Data", "abstract": "The explanation of heterogeneous multivariate time series data is a central problem in many applications. The problem requires two major data mining challenges to be addressed simultaneously: Learning models that are human-interpretable and mining of heterogeneous multivariate time series data. The intersection of these two areas is not adequately explored in the existing literature. To address this gap, we propose grammar-based decision trees and an algorithm for learning them. Grammar-based decision tree extends decision trees with a grammar framework. Logical expressions, derived from context-free grammar, are used for branching in place of simple thresholds on attributes. The added expressivity enables support for a wide range of data types while retaining the interpretability of decision trees. By choosing a grammar based on temporal logic, we show that grammar-based decision trees can be used for the interpretable classification of high-dimensional and heterogeneous time series data. In addition to classification, we show how grammar-based decision trees can also be used for categorization, which is a combination of clustering and generating interpretable explanations for each cluster. We apply grammar-based decision trees to analyze the classic Australian Sign Language dataset as well as categorize and explain near mid-air collisions to support the development of a prototype aircraft collision avoidance system.", "histories": [["v1", "Wed, 30 Aug 2017 05:21:26 GMT  (5015kb,D)", "http://arxiv.org/abs/1708.09121v1", "10 pages, 7 figures"]], "COMMENTS": "10 pages, 7 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ritchie lee", "mykel j kochenderfer", "ole j mengshoel", "joshua silbermann"], "accepted": false, "id": "1708.09121"}, "pdf": {"name": "1708.09121.pdf", "metadata": {"source": "CRF", "title": "Interpretable Categorization of Heterogeneous Time Series Data", "authors": ["Ritchie Lee", "Mykel J. Kochenderfer", "Ole J. Mengshoel", "Joshua Silbermann"], "emails": ["ole.mengshoel}@sv.cmu.edu", "mykel@stanford.edu", "joshua.silbermann@jhuapl.edu"], "sections": [{"heading": null, "text": "In fact, most of them are able to move to another world, in which they can move to another world."}, {"heading": "II. RELATED WORK", "text": "The authors are not aware that this is a purely formal matter, but a purely formal matter."}, {"heading": "III. PRELIMINARIES", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Notation and Terminology", "text": "A multidimensional time series dataset D consists of m datasets, where each dataset is a two-dimensional matrix of n attributes in T time steps. A trace of an attribute xi is called ~ xi and is a vector of length T that represents the time series of this attribute. A label is associated with each dataset. Logic and comparison operators may receive broadcast semantics. For example, the comparison operator in ~ xi < c compares each element of ~ xi with c and returns a vector of the same size as ~ xi. Similarly, the logical operator in ~ xi-xj works elementary. The time operators F and G are ultimately and global, respectively. Finally, true if any value in the input vector is true. Global returns true if all values in the input vector are true."}, {"heading": "B. Context-Free Grammar", "text": "A context-free grammar (CFG) defines a set of rules that determine how expressions in a formal language are to be formed, such as linear time logic (LTL) [34]. Grammar defines the syntax of the language as well as a direct means of generating valid expressions. A CFG G G is defined by a quadruple (N, T, P, S), where \u2022 N is a set of non-terminal symbols that can be replaced by other symbols, \u2022 T is a set of terminal symbols that appear in the final expression generated by grammar, \u2022 P is a set of productions that are rules for replacing a non-terminal symbol with other non-terminal or terminal symbols, and \u2022 S is the start symbol, which is a special non-terminal symbol that serves as the initial expression of a derivative."}, {"heading": "C. Grammar-Based Expression Search", "text": "The formulation is extremely general, based on the flexibility and expressivity of grammars and the arbitrary choice of fitness function. Due to this generality, the GBES approach has been applied to a wide range of applications, including image and signal processing, modeling of medical and economic data, and industrial process control. A number of GBES algorithms have been proposed in the literature. We review four of these algorithms in the following sections. Monte Carlo is a simple algorithm that generates expressions by repeatedly selecting nonterminals and applies random substitutions. Substitutions are selected from all available options."}, {"heading": "IV. GRAMMAR-BASED DECISION TREES", "text": "Grammar-based Decision Tree (GBDT) extends decision trees by a grammatical framework to allow general logical expressions to be used as branching rules in a decision tree. Context-free grammar (CFG) limits the range of logical expressions. In this paper, we look at grammars based on temporal logic to classify high-dimensional and heterogeneous time series data. Grammar can be easily adapted to the characteristics of the data or the application."}, {"heading": "A. Prediction and Categorization", "text": "As in a traditional decision tree, the logical expressions are organized as nodes in a tree in which each child branch corresponds to a result of the parent expression. Class identification is performed in the traditional way. Starting from the root of the tree, we will recursively evaluate each logical expression. The result of the expression includes which child branch to follow and the process continues. When a leaf node is reached, the most frequently seen class identifier in the training data is returned to that leaf node. Predictions of previously seen and unseen data can be made in this manner. An additional benefit of using a decision tree structure is the ability to extract categorization from the model at no extra cost. Categorization can be helpful to build intuition and explain data. A GBDT can be used to categorize data by considering each leaf node of the tree as a separate category."}, {"heading": "B. Grammars for Heterogeneous Time Series", "text": "The ideal grammar should produce expressions that can be interpreted and tailored to the application and that support the attribute types present in the dataset. This section aims to provide the user with design suggestions to achieve these objectives, and the exact details of the grammar depend on the specific needs of the user. In the GBDT framework, expressions are evaluated based on a dataset and generate a Boolean output. The symbols of the expression can refer to fields of the dataset, constants or functions. We adopt a subset of linear time logic (LTL), a formal logic with temporal operators commonly used in the analysis of time series data. [34] We have found grammars similar to those shown in Figure 1 to be particularly effective for heterogeneous time series data. Grammar produces expressions that incorporate Boolean, categorical and retyped data types, which are well-known, and intuitive expressions."}, {"heading": "C. Natural Language Descriptions", "text": "In fact, the fact is that most of them are able to survive themselves, and that they are able to survive themselves, \"he told the German Press Agency in an interview with\" Welt am Sonntag \":\" I don't think we will be able to change the world. \""}, {"heading": "A. Fitness Function", "text": "We evaluate the desirability or suitability of an expression on the basis of two competing objectives. On the one hand, we want expressions that split the data so that the resulting clusters have the same basic truth class names. Splitters that produce high homogeneity tend to produce flatter trees and thus shorter global expressions on leaf nodes. In addition, they produce classifiers with better predictable accuracy when the maximum tree depth is limited. To quantify the homogeneity, we use the Gini impurity metric, which follows the classification and regression tree frame (CART) [9]. On the other hand, we want to promote interpretability by minimizing the length and complexity of the expression. Shorter and simpler expressions are generally easier to interpret. We use the number of nodes in the derivative tree as a proxy for the complexity of an expression IR. The two objectives become linear to a single WIG = (WWWWI = WWI) IWI = WWI = WWI = WI = WI combined WI)."}, {"heading": "B. Computational Complexity", "text": "The arithmetically most expensive part of GBDT is the evaluation of the suitability of an expression, since it involves visiting every data set in the data set and then computing statistics. Furthermore, GBES requires a large number of expression evaluations to optimize the decision expression at each decision node. The deeper the tree, the more nodes that need to be optimized. However, the deeper the tree gets, the smaller the nodes become. In fact, the number of decision nodes grows exponentially with the tree depth, the number of data sets that need to be evaluated at each level remains constant (the size of the data set). Overall, the computational complexity of the GBDT induction is O (| D | \u00b7 NGBES \u00b7 d), where | D | is the number of data sets in the data set, NGBES the number of evaluations used in GBES, and d the depth of the decision tree."}, {"heading": "VI. AUSTRALIAN SIGN LANGUAGE", "text": "The data comes from participants wearing instrumentalized gloves that contain all the features and the following operators: F, G, D, D, < < < p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p"}, {"heading": "VII. COLLISION AVOIDANCE APPLICATION", "text": "The Airborne Collision Avoidance System (ACAS X) monitors the airspace of an aircraft and warns the pilot when a conflict is detected. A Resolution Advisory (RA) is issued to help the pilot resolve the conflict, for example by instructing the pilot to climb at 1,500 feet per minute. The Collision Avoidance System can revise an RA during the encounter. The pilot delays five seconds before responding to an initial RA and three seconds before responding to subsequent RAs [3]. We use GBDT to analyze simulated aircraft experiments to discover the most predictive properties of near-air collisions (NMACs) and to categorize encounters according to these characteristics. The results of our study are used to help the ACAS X development team better organize and understand the NMACs and influence development."}, {"heading": "A. Dataset", "text": "We analyze a dataset containing simulation logs from an aircraft deployment simulator in which an encounter between two aircraft in the air is modeled [3]. Components of the simulator include sensors, pilot response, aircraft dynamics, and a development prototype of ACAS X. The dataset contains 10,000 encounters with 863 NMACs and 9137 non-NMACs. The class imbalance is due to the rarity of NMACs and the difficulty in generating NMAC encounters. We provide the GBDT with the entire dataset so that the algorithm can learn from a larger set of examples. Each encounter has 38 attributes collected at 1 Hz for 50 time steps. Attributes include numerical, categorical, and boolean types. Attributes include the state of the aircraft, the pilot commands AC, and the state and output of the aircraft collision avoidance system."}, {"heading": "B. Grammar", "text": "We created a custom CFG for the ACAS X dataset based on the grammar shown in Figure 1. We include temporal logic operators, which are ultimately F and global G; elementary logical operators, which include conjunction, disjunction, negation, and implicit operations = \u21d2; comparison operators smaller than < smaller than >, larger than >, larger than or equal to \u2265 and equal =; mathematical functions absolute value | x |, difference \u2212 and character; and arithmetic counter count (which gives the number of true values in a Boolean vector). In addition to dividing attributes by data types, ACAS X grammar further divides attributes by their physical representations. This is because attributes can be compared with constant values that have an appropriate scale and resolution."}, {"heading": "C. Comparison of Induction Algorithms", "text": "We study the performance of GBDT when used in conjunction with Monte Carlo, Monte Carlo Tree Search (MCTS), Grammar Evolution (GE), and GP as subroutines. We evaluate algorithms based on classification performance and interpretability of the produced models1) Classification performance: We evaluate the classification performance of the models on the ACAS-X dataset and report on accuracy, precision, recall, and F1 score. A decision tree can always achieve perfect classification performance on a training set that has a sufficient number of divisions. However, large and deep trees are more difficult to interpret than smaller ones. These experiments limit the maximum tree depth to four. We consider various metrics to quantify the interpretation of the models. These metrics aim to capture the size and complexity of the different parts of the model."}, {"heading": "D. Categorizing Aircraft Encounters", "text": "This year, it has come to the point where it only takes one year to get to the next round."}, {"heading": "VIII. CONCLUSION", "text": "To further improve interpretability, we demonstrated a method for automatically generating English sentences by providing a map of sub-expressions on sentence fragments. We applied GBDT to categorize an aircraft database and demonstrated that the method produces interpretable and insightful categories. Our approach not only breaks a data set into similar groups, but also explains the relevant properties of each group. Our GBDT tool is used to help the ACAS X team automate large NMAC records and discover their relevant properties. The source code for GBDT and the experiments in this paper are available online [42]."}], "references": [{"title": "The traffic alert and collision avoidance system", "author": ["J.K. Kuchar", "A.C. Drumm"], "venue": "Lincoln Laboratory Journal, vol. 16, no. 2, pp. 277\u2013296, 2007.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Nextgeneration airborne collision avoidance system", "author": ["M.J. Kochenderfer", "J.E. Holland", "J.P. Chryssanthacopoulos"], "venue": "Lincoln Laboratory Journal, vol. 19, no. 1, pp. 17\u201333, 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Adaptive stress testing of airborne collision avoidance systems", "author": ["R. Lee", "M.J. Kochenderfer", "O.J. Mengshoel", "G.P. Brat", "M.P. Owen"], "venue": "Digital Avionics Systems Conference (DASC), Prague, Czech Republic, 2015.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Simple means to improve the interpretability of regression coefficients", "author": ["H. Schielzeth"], "venue": "Methods in Ecology and Evolution, vol. 1, no. 2, pp. 103\u2013113, 2010.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Intelligible models for classification and regression", "author": ["Y. Lou", "R. Caruana", "J. Gehrke"], "venue": "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2012, pp. 150\u2013158.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "The bayesian case model: A generative approach for case-based reasoning and prototype classification", "author": ["B. Kim", "C. Rudin", "J.A. Shah"], "venue": "Advances in Neural Information Processing Systems, 2014, pp. 1952\u2013 1960.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Scalable causal learning for predicting adverse events in smart buildings", "author": ["A. Basak", "O. Mengshoel", "S. Hosein", "R. Martin"], "venue": "Workshops at the Thirtieth AAAI Conference on Artificial Intelligence, 2016.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Induction of decision trees", "author": ["J.R. Quinlan"], "venue": "Machine Learning, vol. 1, no. 1, pp. 81\u2013106, 1986.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1986}, {"title": "Learning decision lists", "author": ["R.L. Rivest"], "venue": "Machine Learning, vol. 2, no. 3, pp. 229\u2013246, 1987.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1987}, {"title": "Interpretable decision sets: A joint framework for description and prediction", "author": ["H. Lakkaraju", "S. Bach", "J. Leskovec"], "venue": "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), 2016.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Orc: Ordered rules for classification a discrete optimization approach to associative classification", "author": ["D. Bertsimas", "A. Chang", "C. Rudin"], "venue": "2011.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Interpretable classifiers using rules and bayesian analysis: Building a better stroke prediction model", "author": ["B. Letham", "C. Rudin", "T.H. McCormick", "D. Madigan"], "venue": "Annals of Applied Statistics, vol. 9, no. 3, pp. 1350\u20131371, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "A survey on the application of genetic programming to classification", "author": ["P.G. Espejo", "S. Ventura", "F. Herrera"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C, vol. 40, no. 2, pp. 121\u2013144, 2010.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Genetic Programming: On the Programming of Computers by Means of Natural Selection", "author": ["J.R. Koza"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1992}, {"title": "A study on efficient generation of decision trees using genetic programming", "author": ["T. Tanigawa", "Q. Zhao"], "venue": "Conference on Genetic and Evolutionary Computation. Morgan Kaufmann, 2000, pp. 1047\u20131052.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2000}, {"title": "Using grammar based genetic programming for data mining of medical knowledge", "author": ["P.S. Ngan", "M.L. Wong", "K.S. Leung", "J.C. Cheng"], "venue": "Genetic Programming, pp. 254\u2013259, 1998.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1998}, {"title": "Gpdti: A genetic programming decision tree induction method to find epistatic effects in common complex diseases", "author": ["J.K. Estrada-Gil", "J.C. Fern\u00e1ndez-L\u00f3pez", "E. Hern\u00e1ndez-Lemus", "I. Silva- Zolezzi", "A. Hidalgo-Miranda", "G. Jim\u00e9nez-S\u00e1nchez", "E.E. Vallejo- Clemente"], "venue": "Bioinformatics, vol. 23, no. 13, pp. i167\u2013i174, 2007.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Grammatically-based genetic programming", "author": ["P.A. Whigham"], "venue": "Workshop on Genetic Programming: From Theory to Real-World Applications, no. 3, 1995, pp. 33\u201341.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1995}, {"title": "Grammar-based genetic programming: A survey", "author": ["R.I. Mckay", "N.X. Hoai", "P.A. Whigham", "Y. Shan", "M. O\u2019Neill"], "venue": "Genetic Programming and Evolvable Machines, vol. 11, no. 3-4, pp. 365\u2013396, 2010.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "A comparison of classification accuracy of four genetic programming-evolved intelligent structures", "author": ["A. Tsakonas"], "venue": "Information Sciences, vol. 176, no. 6, pp. 691\u2013724, 2006.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Inverse entailment and progol", "author": ["S. Muggleton"], "venue": "New Generation Computing, vol. 13, no. 3-4, pp. 245\u2013286, 1995.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1995}, {"title": "Ilp turns 20", "author": ["S. Muggleton", "L. De Raedt", "D. Poole", "I. Bratko", "P. Flach", "K. Inoue", "A. Srinivasan"], "venue": "Machine Learning, vol. 86, no. 1, pp. 3\u201323, 2012.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Temporal classification: Extending the classification paradigm to multivariate time series", "author": ["M.W. Kadous"], "venue": "Ph.D. dissertation, The University of New South Wales, 2002.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2002}, {"title": "The great time series classification bake off: A review and experimental evaluation of recent algorithmic advances", "author": ["A. Bagnall", "J. Lines", "A. Bostrom", "J. Large", "E. Keogh"], "venue": "Data Mining and Knowledge Discovery, vol. 31, no. 3, pp. 606\u2013660, 2017. [Online]. Available: http://dx.doi.org/10.1007/s10618-016-0483-9", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2017}, {"title": "Convolutional neural networks for human activity recognition using mobile sensors", "author": ["M. Zeng", "L.T. Nguyen", "B. Yu", "O.J. Mengshoel", "J. Zhu", "P. Wu", "J. Zhang"], "venue": "Mobile Computing, Applications and Services (MobiCASE), 2014 6th International Conference on. IEEE, 2014, pp. 197\u2013205.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Time series shapelets: A novel technique that allows accurate, interpretable and fast classification", "author": ["L. Ye", "E. Keogh"], "venue": "Data Mining and Knowledge Discovery, vol. 22, no. 1, pp. 149\u2013182, 2011.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "Sax-vsm: Interpretable time series classification using sax and vector space model", "author": ["P. Senin", "S. Malinchik"], "venue": "Data Mining (ICDM). IEEE, 2013, pp. 1175\u20131180.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Discovery of meaningful rules in time series", "author": ["M. Shokoohi-Yekta", "Y. Chen", "B. Campana", "B. Hu", "J. Zakaria", "E. Keogh"], "venue": "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2015, pp. 1085\u20131094.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Logical-shapelets: An expressive primitive for time series classification", "author": ["A. Mueen", "E. Keogh", "N. Young"], "venue": "Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2011, pp. 1154\u20131162.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "Data Mining using Grammar Based Genetic Programming and Applications", "author": ["M.L. Wong", "K.S. Leung"], "venue": "Springer Science & Business Media,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2006}, {"title": "Grammatical evolution decision trees for detecting gene-gene interactions", "author": ["A.A. Motsinger-Reif", "S. Deodhar", "S.J. Winham", "N.E. Hardison"], "venue": "BioData mining, vol. 3, no. 1, p. 8, 2010.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "On the temporal analysis of fairness", "author": ["D.M. Gabbay", "A. Pnueli", "S. Shelah", "J. Stavi"], "venue": "ACM Symposium on Principles of Programming Languages, 1980, pp. 163\u2013173.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1980}, {"title": "Bandit based Monte-Carlo planning", "author": ["L. Kocsis", "C. Szepesv\u00e1ri"], "venue": "European Conference on Machine Learning (ECML), 2006, pp. 282\u2013 293.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2006}, {"title": "A survey of Monte Carlo tree search methods", "author": ["C.B. Browne", "E. Powley", "D. Whitehouse", "S.M. Lucas", "P.I. Cowling", "P. Rohlfshagen", "S. Tavener", "D. Perez", "S. Samothrakis", "S. Colton"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, vol. 4, no. 1, pp. 1\u201343, 2012.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}, {"title": "Reinforcement Learning: An Introduction", "author": ["R.S. Sutton", "A.G. Barto"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 1998}, {"title": "Monte-carlo expression discovery", "author": ["T. Cazenave"], "venue": "International Journal on Artificial Intelligence Tools, vol. 22, no. 01, p. 1250035, 2013.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2013}, {"title": "Grammatical evolution", "author": ["M. O\u2019Neil", "C. Ryan"], "venue": "Grammatical Evolution. Springer, 2003, pp. 33\u201347.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2003}, {"title": "UCI machine learning repository", "author": ["M. Lichman"], "venue": "2013. [Online]. Available: http://archive.ics.uci.edu/ml", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "Grammar-based decision trees (gbdts) julia package", "author": ["R. Lee"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2017}], "referenceMentions": [{"referenceID": 0, "context": "Their operation have played a crucial role in the high level of safety in the national airspace [1].", "startOffset": 96, "endOffset": 99}, {"referenceID": 1, "context": "collision risk while simultaneously reducing the number of unnecessary alerts [2].", "startOffset": 78, "endOffset": 81}, {"referenceID": 2, "context": "Efficient algorithms have been developed to generate large datasets of NMAC and non-NMAC instances in simulation [3].", "startOffset": 113, "endOffset": 116}, {"referenceID": 7, "context": "on attributes, such as (x1 < 2) [9][10].", "startOffset": 35, "endOffset": 39}, {"referenceID": 37, "context": "To validate our approach, we apply GBDT on the classic Australian Sign Language dataset from the UC Irvine (UCI) machine learning repository [41] and show that the generated explanations are reasonable.", "startOffset": 141, "endOffset": 145}, {"referenceID": 3, "context": "Regression models [4], generalized additive models [5][6], and Bayesian case models [7] have", "startOffset": 18, "endOffset": 21}, {"referenceID": 4, "context": "Regression models [4], generalized additive models [5][6], and Bayesian case models [7] have", "startOffset": 54, "endOffset": 57}, {"referenceID": 5, "context": "Regression models [4], generalized additive models [5][6], and Bayesian case models [7] have", "startOffset": 84, "endOffset": 87}, {"referenceID": 6, "context": "Bayesian networks have also been used for prediction and data understanding [8].", "startOffset": 76, "endOffset": 79}, {"referenceID": 7, "context": "Rule-based models, such as decision trees [9][10], decision lists [11], and decision sets [12], are easy to understand be-", "startOffset": 45, "endOffset": 49}, {"referenceID": 8, "context": "Rule-based models, such as decision trees [9][10], decision lists [11], and decision sets [12], are easy to understand be-", "startOffset": 66, "endOffset": 70}, {"referenceID": 9, "context": "Rule-based models, such as decision trees [9][10], decision lists [11], and decision sets [12], are easy to understand be-", "startOffset": 90, "endOffset": 94}, {"referenceID": 10, "context": "Efficient algorithms have been proposed for inducing these models by first using associative rule mining (ARM) to mine a set of interesting rules from the data, then optimizing over combinations of these rules to induce classifiers [13][14][12].", "startOffset": 232, "endOffset": 236}, {"referenceID": 11, "context": "Efficient algorithms have been proposed for inducing these models by first using associative rule mining (ARM) to mine a set of interesting rules from the data, then optimizing over combinations of these rules to induce classifiers [13][14][12].", "startOffset": 236, "endOffset": 240}, {"referenceID": 9, "context": "Efficient algorithms have been proposed for inducing these models by first using associative rule mining (ARM) to mine a set of interesting rules from the data, then optimizing over combinations of these rules to induce classifiers [13][14][12].", "startOffset": 240, "endOffset": 244}, {"referenceID": 12, "context": "Genetic programming (GP) has been studied extensively for classification problems [15].", "startOffset": 82, "endOffset": 86}, {"referenceID": 13, "context": "GP is particularly well-suited to evolve tree structures [16][17].", "startOffset": 57, "endOffset": 61}, {"referenceID": 14, "context": "GP is particularly well-suited to evolve tree structures [16][17].", "startOffset": 61, "endOffset": 65}, {"referenceID": 15, "context": "A number of studies have used GP to evolve interpretable models for analyzing medical datasets [18][19].", "startOffset": 95, "endOffset": 99}, {"referenceID": 16, "context": "A number of studies have used GP to evolve interpretable models for analyzing medical datasets [18][19].", "startOffset": 99, "endOffset": 103}, {"referenceID": 17, "context": "Grammar-guided genetic programming (GGGP) uses a grammar to guide the evolution of genetic programs [20][21].", "startOffset": 100, "endOffset": 104}, {"referenceID": 18, "context": "Grammar-guided genetic programming (GGGP) uses a grammar to guide the evolution of genetic programs [20][21].", "startOffset": 104, "endOffset": 108}, {"referenceID": 19, "context": "A variety of classification structures, including decision trees, have been evolved using GGGP [22].", "startOffset": 95, "endOffset": 99}, {"referenceID": 20, "context": "Inductive logic programming (ILP) uses logic programming to find a set of logical implications (Horn clauses) that best explains the data given a set of known facts [23][24].", "startOffset": 165, "endOffset": 169}, {"referenceID": 21, "context": "Inductive logic programming (ILP) uses logic programming to find a set of logical implications (Horn clauses) that best explains the data given a set of known facts [23][24].", "startOffset": 169, "endOffset": 173}, {"referenceID": 22, "context": "Time series analysis has focused on dynamic time warping, hidden Markov models, dictionary-based approaches, and recurrent neural networks [25][26][27].", "startOffset": 139, "endOffset": 143}, {"referenceID": 23, "context": "Time series analysis has focused on dynamic time warping, hidden Markov models, dictionary-based approaches, and recurrent neural networks [25][26][27].", "startOffset": 143, "endOffset": 147}, {"referenceID": 24, "context": "Time series analysis has focused on dynamic time warping, hidden Markov models, dictionary-based approaches, and recurrent neural networks [25][26][27].", "startOffset": 147, "endOffset": 151}, {"referenceID": 25, "context": "Shapelets [28] and subsequence search [29] have been proposed for univariate time series classification.", "startOffset": 10, "endOffset": 14}, {"referenceID": 26, "context": "Shapelets [28] and subsequence search [29] have been proposed for univariate time series classification.", "startOffset": 38, "endOffset": 42}, {"referenceID": 27, "context": "Implication rules [30] and simple logical combinations of shapelets [31] have been proposed to extend the shapelets approach.", "startOffset": 18, "endOffset": 22}, {"referenceID": 28, "context": "Implication rules [30] and simple logical combinations of shapelets [31] have been proposed to extend the shapelets approach.", "startOffset": 68, "endOffset": 72}, {"referenceID": 29, "context": "The combination of decision trees and GGGP has been proposed in the past [32][33].", "startOffset": 73, "endOffset": 77}, {"referenceID": 30, "context": "The combination of decision trees and GGGP has been proposed in the past [32][33].", "startOffset": 77, "endOffset": 81}, {"referenceID": 31, "context": "A context-free grammar (CFG) defines a set of rules that govern how to form expressions in a formal language, such as linear temporal logic (LTL) [34].", "startOffset": 146, "endOffset": 150}, {"referenceID": 18, "context": "Grammar-based expression search (GBES) is the problem of finding expressions from a grammar that minimize a given fitness function [21].", "startOffset": 131, "endOffset": 135}, {"referenceID": 32, "context": "2) Monte Carlo Tree Search: Monte Carlo tree search (MCTS) is a heuristic search algorithm that is used to optimize certain sequential decision-making problems [36][37].", "startOffset": 160, "endOffset": 164}, {"referenceID": 33, "context": "2) Monte Carlo Tree Search: Monte Carlo tree search (MCTS) is a heuristic search algorithm that is used to optimize certain sequential decision-making problems [36][37].", "startOffset": 164, "endOffset": 168}, {"referenceID": 34, "context": "MCTS is based on reinforcement learning, the idea of improving behavior through experience and interaction with an environment [38].", "startOffset": 127, "endOffset": 131}, {"referenceID": 35, "context": "Expression search is formulated as a sequential decisionmaking problem by transforming the decisions in the derivation tree so that they occur in sequential order, for example, by assuming depth-first traversal order [39].", "startOffset": 217, "endOffset": 221}, {"referenceID": 35, "context": "MCTS is then applied to optimize the resulting sequential decision-making problem [39].", "startOffset": 82, "endOffset": 86}, {"referenceID": 36, "context": "3) Grammatical Evolution: Grammatical evolution (GE) [40] is a GGGP algorithm that is based on a sequential representation of the derivation tree.", "startOffset": 53, "endOffset": 57}, {"referenceID": 17, "context": "4) Genetic Programming: Genetic programming (GP) is an evolutionary algorithm for optimizing trees [20].", "startOffset": 99, "endOffset": 103}, {"referenceID": 31, "context": "formal logic with temporal operators often used in the analysis of time-series data [34].", "startOffset": 84, "endOffset": 88}, {"referenceID": 37, "context": "To test our approach, we analyze the classic Australian Sign Language (\u201cAuslan\u201d) dataset from the UC Irvine (UCI) repository [41][25].", "startOffset": 125, "endOffset": 129}, {"referenceID": 22, "context": "To test our approach, we analyze the classic Australian Sign Language (\u201cAuslan\u201d) dataset from the UC Irvine (UCI) repository [41][25].", "startOffset": 129, "endOffset": 133}, {"referenceID": 2, "context": "The pilot delays for five seconds before responding to an initial RA and three seconds before responding to subsequent RAs [3].", "startOffset": 123, "endOffset": 126}, {"referenceID": 2, "context": "We analyze a dataset that contains simulation logs from an aircraft encounter simulator modeling a two-aircraft mid-air encounter [3].", "startOffset": 130, "endOffset": 133}, {"referenceID": 38, "context": "The source code for GBDT and the experiments in this paper are available online [42].", "startOffset": 80, "endOffset": 84}], "year": 2017, "abstractText": "The explanation of heterogeneous multivariate time series data is a central problem in many applications. The problem requires two major data mining challenges to be addressed simultaneously: Learning models that are humaninterpretable and mining of heterogeneous multivariate time series data. The intersection of these two areas is not adequately explored in the existing literature. To address this gap, we propose grammar-based decision trees and an algorithm for learning them. Grammar-based decision tree extends decision trees with a grammar framework. Logical expressions, derived from context-free grammar, are used for branching in place of simple thresholds on attributes. The added expressivity enables support for a wide range of data types while retaining the interpretability of decision trees. By choosing a grammar based on temporal logic, we show that grammar-based decision trees can be used for the interpretable classification of high-dimensional and heterogeneous time series data. In addition to classification, we show how grammar-based decision trees can also be used for categorization, which is a combination of clustering and generating interpretable explanations for each cluster. We apply grammar-based decision trees to analyze the classic Australian Sign Language dataset as well as categorize and explain near midair collisions to support the development of a prototype aircraft collision avoidance system.", "creator": "LaTeX with hyperref package"}}}