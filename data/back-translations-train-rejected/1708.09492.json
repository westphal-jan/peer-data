{"id": "1708.09492", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Aug-2017", "title": "Automatically Generating Commit Messages from Diffs using Neural Machine Translation", "abstract": "Commit messages are a valuable resource in comprehension of software evolution, since they provide a record of changes such as feature additions and bug repairs. Unfortunately, programmers often neglect to write good commit messages. Different techniques have been proposed to help programmers by automatically writing these messages. These techniques are effective at describing what changed, but are often verbose and lack context for understanding the rationale behind a change. In contrast, humans write messages that are short and summarize the high level rationale. In this paper, we adapt Neural Machine Translation (NMT) to automatically \"translate\" diffs into commit messages. We trained an NMT algorithm using a corpus of diffs and human-written commit messages from the top 1k Github projects. We designed a filter to help ensure that we only trained the algorithm on higher-quality commit messages. Our evaluation uncovered a pattern in which the messages we generate tend to be either very high or very low quality. Therefore, we created a quality-assurance filter to detect cases in which we are unable to produce good messages, and return a warning instead.", "histories": [["v1", "Wed, 30 Aug 2017 22:26:48 GMT  (1143kb,D)", "http://arxiv.org/abs/1708.09492v1", "Preprint version. Accepted in ASE 2017, the 32nd IEEE/ACM International Conference on Automated Software Engineering"]], "COMMENTS": "Preprint version. Accepted in ASE 2017, the 32nd IEEE/ACM International Conference on Automated Software Engineering", "reviews": [], "SUBJECTS": "cs.SE cs.CL", "authors": ["siyuan jiang", "ameer armaly", "collin mcmillan"], "accepted": false, "id": "1708.09492"}, "pdf": {"name": "1708.09492.pdf", "metadata": {"source": "CRF", "title": "Automatically Generating Commit Messages from Diffs using Neural Machine Translation", "authors": ["Siyuan Jiang", "Ameer Armaly", "Collin McMillan"], "emails": ["cmc}@nd.edu"], "sections": [{"heading": null, "text": "This year, it is time for us to set out to find a solution that paves the way for the future, to pave the way for the future."}, {"heading": "A. The Problem", "text": "This short-term pressure leads programmers to neglect commit messages, like other types of documentation [11], [36], [44], [12], [24]. Buse et al. [7] point out that programmers use commit messages for two reasons: 1) to summarize what has changed, and 2) to briefly explain why the change was necessary. To date, research in commit creation has focused exclusively on what. In this paper, we try to answer why commit message-generation techniques produce relatively long messages that contain details, such as the methods that have been added, or the number of files that change (which information). Although useful, these techniques are a complement to new commits, not a substitute for high-level commits, why information that people write, such as \"Add support for 9-inch tablet screens.\" Usually, this high level of human judgment requires that we create a similar pattern that we believe is commonly used."}, {"heading": "B. Paper Overview", "text": "Figure 1 shows an overview of our work. We have divided the work into three segments: In Part A (Section IV), we present our approach to filtering commit message patterns for verb / direct objects (VDO), and we train an NMT algorithm to generate messages with this pattern. V-DO filtering was introduced because a large percentage of messages in the repositories we downloaded were of very low quality, and we had to make sure that we trained the NMT algorithm only with examples that fit an acceptable pattern. Then, we trained an NMT algorithm on the pairs of diffs and commit messages where the messages followed the V-DO pattern. In Part B (Sections V and VI), we evaluated the quality of the commit generated by the algorithm using an automated method and a human study involving 2 doctoral students and 18 professional programmers. We find that while there are a significant number of positive results, there are also significant numbers of significant results."}, {"heading": "II. RELATED WORK", "text": "We divide the work involved into three categories: 1) the work that generates commit messages; 2) the work that summarizes the source code; and 3) the work that applies deep learning algorithms to software development."}, {"heading": "A. Commit Message Generation Techniques", "text": "The first group uses code changes from a commit as input and summarizes the changes to generate the commit message. For example, Buse et al. have developed DeltaDoc, which extracts path predicates from modified commands and follows a set of predefined rules to compile a summary [7]. Similarly, Linares-Va \ufffd squez et al. have developed ChangeScribe, which extracts changes between two abstract syntax trees and summarizes the changes based on predefined rules [32]. In addition to the first group, the second group is based on related software documents. For example, Le et al. have developed RCLinker, which links a bug report with the commit message associated with the commit message [31]. Rastkar and Murphy have proposed combining several related documents for commits [43]."}, {"heading": "B. Source Code Summarization", "text": "Source code summary techniques generate descriptions of parts of the source code. The algorithms of the techniques can be customized to generate summaries for changes during transmissions. Source code summaries can be divided into two groups: extractive and abstract. Extractive Summary extracts relevant parts of the source code and uses the relevant parts as a summary [16]. Abstractive Summary includes information that is not explicitly included in the source code. For example, Sridhara et al. has designed a Natural Language Generation System (NLG) to generate summaries of Java methods [50]. First, the NLG system finds important statements of a Java method. Second, the system uses a text generation algorithm to translate a statement into a natural language description. This algorithm has pre-defined text templates for different types of statements, such as return instructions and assignment instructions. Second, the system uses a text generation algorithm to translate a statement into a natural language description. This algorithm has NLG marked text templates for different types of instructions, such as return instructions and assignment instructions."}, {"heading": "C. Deep Learning in Software Engineering", "text": "Deep learning algorithms automatically learn to represent software artifacts. For example, traditional approaches to code cloning detection define the representation of code fragments (some techniques use token sequences to represent code [25]; others use graphs [29], [9]). In contrast, the deep learning approach introduced by White et al. [53] learns to represent code automatically. Similarly, deep learning algorithms are introduced in error localization [30], software traceability [15], and code suggestions [54]. Our technique is similar to the work of Gu et al. [14] in that both our and their techniques use Neural Machine Translation (NMT). Gu et al. use NMT to translate natural language queries to API method sequences."}, {"heading": "III. BACKGROUND", "text": "The first section is about empirical studies of commit messages that motivate us to make short descriptions of commits; the second subsection is about RNN encoder decoders, a popular Neural Network Translation model that is an important background to the third subsection; and the third subsection is about the attentive RNN encoder decoder used in our work."}, {"heading": "A. Commit Messages", "text": "Our work is motivated by the results of the studies by Buse et al. [7] and Jiang and McMillan [23]. Results of the two studies suggest three things: First, commit messages are ubiquitous and desirable. Buse et al. examined 1k commits from five mature software projects and found that 99.1% of the commits do not contain blank messages. Jiang and McMillan collected more than 2M commit messages from 1k projects. Second, commit messages are brief. In Buse et al. \"s study, the average size of the 991 non-blank commit messages is 1.1 lines. Likewise, the study by Jiang and McMillan shows that 82% of commit messages contain only one sentence. Third, commit messages contain different types of information, not just summaries of code changes. Buse et al. analyzed 375 commit messages manually and found that the messages are not just about what changes are made, but why."}, {"heading": "B. RNN Encoder-Decoder Model", "text": "Neural Machine Translation (NMT) is a neural network that describes the translation process from a source-language sequence x = (x1,..., xn) into a target-language sequence y = (y1,..., yn) with a conditional probability p (y | x) [5], [35]. As a promising deep learning model, RNN encoder decoders have been used to address other software engineering tasks [14], [5].RNN encoder decoders have two recursive neural networks (RNNNs). An RNN is used to transform source-language sequences into vector representations. This RNN is called an encoder."}, {"heading": "C. Attentional RNN Encoder-Decoder and Nematus", "text": "Bahdanau et al. introduced the attentive RNN encoder decoder, which introduces attention mechanism to deal with long source sequences [6]. We use this mechanism in our work because our source sequences, which differ, are much longer than natural speech sentences. The attention mechanism includes several modifications of both the encoder and the decoder, which we describe in the following paragraph.1) Encoder: The encoder in the attentive model is a bidirectional RNN that has two RNNNs: forward and backward. The two RNNNs have the same architecture. The forward RNN works in the same way as the forward encoder decoder model (Figure 2), which reads the source sequence x as it is ordered, from x1 to xT. The forward RNN generates a sequence of hidden states (h \u2192 \u2212 reverse) and reverse RNN = reverse Nhi = reverse."}, {"heading": "IV. APPROACH", "text": "This section describes our approach, including the preparation of the data sets and the NMT training procedure. This section corresponds to Part A in the paper chart Figure 1 and is described in detail in Figure 4."}, {"heading": "A. Preparing a Data Set for NMT", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "B. NMT Training and Testing", "text": "In this section, we describe how to create an NMT model for generating commit messages.1) Model: We used Nematus [47] in our work because it is robust, easy to use, and produced the best systems for seven translation directions (see Section III-C) in the common translation task [49]. Nematus is based on Theano [52] and implements the attention of the encoder decoder (see Section III-C) with several implementation differences. Training Setting: We rent the training setting that Sennrich et al. It was used to produce the best translation systems in the WMT."}, {"heading": "V. EVALUATION USING AN AUTOMATIC METRIC", "text": "In this section, we evaluate the messages generated from our approach described in the last section. Our goal is to assess the similarity between the messages generated and the reference messages in the test set. This section corresponds to Part B in the paper chart Figure 1. Note that this assessment differs from the experiment with human evaluators described in Section VI, which is also part of \"Part B.\" In this section, we ask: RQ1 Compared to the messages generated by a baseline, are the messages generated by the NMT model more or less similar to the reference messages? RQ2 Are the messages generated by the NMT model more or less similar to the reference messages when the V-DO filter is activated or deactivated? We ask RQ1 to evaluate the NMT model compared to a baseline that we describe in the following subsection."}, {"heading": "A. Baseline: MOSES", "text": "We used MOSES [28] as the starting point in RQ1. MOSES is a popular statistical software for machine translation that is often used as the starting line for evaluating machine translation systems [8], [27]. For example, Iyer et al used MOSES as the starting line when evaluating code NN [22]. In order to use MOSESfor translating diffs in commit messages, we trained a 3 gram language model using KenLM [18], [19] which is the same method used in the study by Iyer et al. [22]. We did not use code NN as the starting line because in our pilot study execution of code NN [22] did not yield comparable results for generating commit messages. One possible reason for this is that code NN source sequences and diffs are not suitable for parsing."}, {"heading": "B. Similarity Metric: BLEU", "text": "BLEU [41] is often used to measure the similarity between two sentences when evaluating machine translation systems [26], [34], [33]. Furthermore, BLEU is recommended to evaluate an entire test sentence instead of a sentence [41]. BLEU's calculation requires modified n-gram precision. For each n, the modified n-gram precision is calculated by: pn = (gen, ref), (ngram), (ngram), (ngram), (gen, ref), (ngram), (ngram), (ngram), (ngram), (ngram), (ngram), (ngram), (9), where test is the set of pairs of the generated test messages and the reference messages in the test sentence; gen is the set of unique n-grams in a generated message; Cntclip is the set of equation (9); BLN is the number of the occurrences of an EU gram and the quantity of the gram generated in the message (the message); and N is the unique message in the message (the message) generated."}, {"heading": "C. RQ1: Compared to the Baseline", "text": "The first two lines in Table I list the BLEU values of MOSES and the NMT model we have built in Section IV-B, which we call NMT1. The BLEU value of our model is 31.92, while the BLEU value of MOSES is 3.63, so that according to the BLEU metric, the messages generated by the NMT model are more similar to the reference messages than the messages generated by the baseline. A major reason that the attention-oriented NMT model outperforms MOSES is that MOSES cannot handle very long source sequences with short target sequences well. In particular, MOSES depends on the reference messages that differ from Giza + + [40] for word alignments between source and target sequences, andGiza + + becomes very inefficient when a source sequence is 9 times longer than the short target sequences."}, {"heading": "D. RQ2: Impact of V-DO Filter", "text": "In this section, we compare NMT1 and NMT2 to see the effects of V-DO filters."}, {"heading": "VI. HUMAN EVALUATION", "text": "In this section, we ask human experts to evaluate the messages generated using the NMT model described in Section IV. In Section V, we evaluate our model using the automatic measurement variable BLEU. Our human study complements the evaluation BLEU uses in two ways. First, while BLEU is a widely used measurement that allows us to compare our model with others and provide reproducibility, BLEU is not recommended to evaluate individual sentences [41]. Our human study can show how our model affects individual messages. Second, BLEU calculates the textual similarity between the messages generated and the reference messages, while the human study can evaluate semantic similarity. In this study, we recruited 20 participants for 30 minutes each to evaluate the similarity in a survey. Two participants are computer science doctoral students and 18 participants are professional programmers with 2 to 14 years of experience. In the rest of this subsection, we describe our survey design, the course of the survey and the results."}, {"heading": "A. Survey Design", "text": "We present our survey on the first page as follows: \"This survey asks you to compare two commit messages by their meaning, you can select a score between 0 and 7, where 0 means there is no similarity, and 7 means two messages are identical.\" We allowed participants to search the Internet for unknown concepts, then we gave three scoring examples with recommended scores of 6, 3 and 1. Due to the spatial limitation, we present only the first example in Figure 7 (all other examples are available in our online appendix, Section XI), then each page has a pair of messages on the remaining pages of the survey, and we asked participants to rate the similarity by meaning. Note that participants do not know who / what generated the messages, and the order of messages on each page is decided at random. At the end of the page there is an optional text field where participants can enter their reasoning."}, {"heading": "B. Survey Procedure", "text": "First, the pairs of generated / referenced messages are randomly ranked in a list, then a survey is conducted for each participant: TimingExample 1 of 3 message 1: \"Add X to readme\" message 2: \"edit readme\" Recommended rating: 6Explanation: The two messages have only one word in common, \"readme.\" But the two messages are very similar in meaning because \"Add\" is a kind of \"edit.\" These page timer metrics are not shown to the recipient. First Click 5,301 seconds Last Click 97,921 seconds Page Submit 0 seconds Click Count 6 clicksClose Preview Restart Survey Place Bookmark (optional) Justification: These page timer metrics are not shown to the recipient.First Click Last Click 27,478 seconds Last Page Submit 0 seconds Click Count 3 clicks < < > Close Preview Restart Place Bookmark (optional) Justification: These page metrics are not shown to the recipient."}, {"heading": "C. Results", "text": "Figure 9 shows the distribution of the median values of the semantic similarity of the generated / reference messages. To be conservative, we round the median. For example, if a generated message has two values, 1 and 2, and the median is 1.5, we round the median to 1. Overall, 983 generated commit messages have values from the participants. Zero and seven are the two most common values. There are 248 messages rated 0 and 234 messages 7, showing that the performance of our model tends to be good or bad."}, {"heading": "VII. QUALITY ASSURANCE FILTER", "text": "Based on the results of our study with human evaluators (Section VI), we propose a quality assurance filter (QA filter) to automatically detect the differences for which the NMT model does not generate good commit messages. By building this filter, we examine whether it is possible to automatically detect the cases where our NMT model does not work well. In this section, we describe the method of our filter, how we evaluate the filter and the performance of the filter. This section corresponds to Part C in the paper summary Figure 1."}, {"heading": "A. QA Filter", "text": "Our method of QA filter consists of three steps. Firstly, we have prepared the gold set. We used the evaluated messages and the corresponding differences in the human study as our gold set. For each comparison and the corresponding generated message, there is a score that we obtained in the human study (Figure 9), which indicates whether the generated message is comparable to the reference message (i.e. the actual message written by man) for comparison. To be conservative, we designated the differences that have scores of zero or one as \"bad\" and all other differences as not \"bad.\" Secondly, we extracted the characteristics of the differences. We used the term frequency / inverse document frequency (tf / idf) for each word in a diff as characteristics. Tf / idf is commonly used in machine learning for word processing [17], which is calculated based on the frequency of a word in a diff and whether the word in a diff is used to create a SVM (finally, we have a diff in a data set)."}, {"heading": "B. Cross-Validation Evaluation", "text": "Figure 10 illustrates our 10-fold cross-validation process. We mixed the gold set first and divided the gold set into 10 folds. For each fold, we trained one SVM model on the other 9 folds and tested the SVM model on one fold. In the end, we got the test results for each fold. Figure 11 shows the predictions of all folds. In terms of detecting diffusers for which the NMT model will generate \"bad\" messages, the QS filter has a precision of 44.9% and a reminder value of 43.8%. Furthermore, in this assessment, the QS filter has reduced 44% of the \"bad\" messages at the expense of 11% of the \"good\" messages."}, {"heading": "VIII. EXAMPLE RESULT", "text": "Table III shows a representative example of a generated message that has been highly rated by human experts. It includes the generated and reference messages, three evaluations made by three participants and the corresponding comparison. In this example, the reference message refers to replacing a call to a function called deactivate () with a call to a function called close (). For a human reader, this results from the difference: a call to disable () is removed and a call to close () is added. The NMT algorithm also picked up on this change and generated the text \"Close instead of mCursor.Deactivate.\""}, {"heading": "IX. THREATS TO VALIDITY", "text": "One threat to validity is that our approach is only tried on Java projects in Git repositories, so they may not be representative of all commits. However, Java is a popular programming language [3], [1], [2] that is used in a large number of projects. In the future, we will expand our approach to other programming languages. Another threat to validity is the quality of commit messages. We collected actual man-made commit messages from Github and used V-DO filters to get a series of relatively high-quality commit messages. However, the humanely written messages may not contain all the useful information that should be included in a commit message. However, our goal in this essay is to work on commit messages that can be learned from the history of the commit repositories. Further improvements to humanly written messages fall outside the scope of this paper. Another threat to validity is in the human study that we cannot evaluate with the limited number of participants."}, {"heading": "X. DISCUSSION AND CONCLUSION", "text": "The key is to bring this paper up to date in order to find short-term solutions."}, {"heading": "XI. REPRODUCIBILITY", "text": "Our records, scripts and results are available at: https: / / sjiang1.github.io / commit /"}, {"heading": "XII. ACKNOWLEDGMENTS", "text": "This work has been partially supported by NSF CCF1452959 and CNS-1510329 grants, as well as the Office of Naval Research N000141410037. All opinions, findings and conclusions expressed here are the authors and do not necessarily reflect the views of the sponsors."}], "references": [{"title": "Replicating parser behavior using neural machine translation", "author": ["C.V. Alexandru", "S. Panichella", "H.C. Gall"], "venue": "IEEE 25th International Conference on Program Comprehension (ICPC),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2017}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "CoRR, abs/1409.0473,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Automatically documenting program changes", "author": ["R.P. Buse", "W.R. Weimer"], "venue": "In Proceedings of the IEEE/ACM International Conference on Automated Software Engineering,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Findings of the 2011 workshop on statistical machine translation", "author": ["C. Callison-Burch", "P. Koehn", "C. Monz", "O.F. Zaidan"], "venue": "In Proceedings of the Sixth Workshop on Statistical Machine Translation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Achieving accuracy and scalability simultaneously in detecting application clones on android markets", "author": ["K. Chen", "P. Liu", "Y. Zhang"], "venue": "In Proceedings of the 36th International Conference on Software Engineering,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Learning phrase representations using rnn encoder\u2013decoder for statistical machine translation", "author": ["K. Cho", "B. van Merrienboer", "C. Gulcehre", "D. Bahdanau", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Boa: A language and infrastructure for analyzing ultra-large-scale software repositories", "author": ["R. Dyer", "H.A. Nguyen", "H. Rajan", "T.N. Nguyen"], "venue": "In 2013 35th International Conference on Software Engineering (ICSE),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Do code and comments coevolve? on the relation between source code and comment changes", "author": ["B. Fluri", "M. Wursch", "H.C. Gall"], "venue": "In Proceedings of the 14th Working Conference on Reverse Engineering,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Deep learning", "author": ["I. Goodfellow", "Y. Bengio", "A. Courville"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "Deep api learning", "author": ["X. Gu", "H. Zhang", "D. Zhang", "S. Kim"], "venue": "In Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Semantically enhanced software traceability using deep learning techniques", "author": ["J. Guo", "J. Cheng", "J. Cleland-Huang"], "venue": "In Proceedings of the 2017 International Conference on Software Engineering,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2017}, {"title": "On the use of automated text summarization techniques for summarizing source code", "author": ["S. Haiduc", "J. Aponte", "L. Moreno", "A. Marcus"], "venue": "In Proceedings of the 2010 17th Working Conference on Reverse Engineering,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "On the use of automated text summarization techniques for summarizing source code", "author": ["S. Haiduc", "J. Aponte", "L. Moreno", "A. Marcus"], "venue": "In 2010 17th Working Conference on Reverse Engineering,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Kenlm: Faster and smaller language model queries", "author": ["K. Heafield"], "venue": "In Proceedings of the Sixth Workshop on Statistical Machine Translation,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Scalable modified Kneser-Ney language model estimation", "author": ["K. Heafield", "I. Pouzyrevsky", "J.H. Clark", "P. Koehn"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "On the naturalness of software", "author": ["A. Hindle", "E.T. Barr", "Z. Su", "M. Gabel", "P. Devanbu"], "venue": "In Proceedings of the 2012 International Conference on Software Engineering,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1997}, {"title": "Summarizing source code using a neural attention model. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "author": ["S. Iyer", "I. Konstas", "A. Cheung", "L. Zettlemoyer"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "Towards automatic generation of short summaries of commits", "author": ["S. Jiang", "C. McMillan"], "venue": "IEEE 25th International Conference on Program Comprehension (ICPC),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2017}, {"title": "A survey of documentation practice within corrective maintenance", "author": ["M. Kajko-Mattsson"], "venue": "Empirical Softw. Engg.,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2005}, {"title": "Ccfinder: a multilinguistic token-based code clone detection system for large scale source code", "author": ["T. Kamiya", "S. Kusumoto", "K. Inoue"], "venue": "IEEE Transactions on Software Engineering,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2002}, {"title": "Factored translation models", "author": ["P. Koehn", "H. Hoang"], "venue": "In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2007}, {"title": "Moses: Open source toolkit for statistical machine translation", "author": ["P. Koehn", "H. Hoang", "A. Birch", "C. Callison-Burch", "M. Federico", "N. Bertoldi", "B. Cowan", "W. Shen", "C. Moran", "R. Zens"], "venue": "In Proceedings of the 45th annual meeting of the ACL on interactive poster and demonstration sessions,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2007}, {"title": "Identifying similar code with program dependence graphs", "author": ["J. Krinke"], "venue": "In Proceedings Eighth Working Conference on Reverse Engineering,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2001}, {"title": "Combining deep learning with information retrieval to localize buggy files for bug reports (n)", "author": ["A.N. Lam", "A.T. Nguyen", "H.A. Nguyen", "T.N. Nguyen"], "venue": "In 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE),", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "Rclinker: Automated linking of issue reports and commits leveraging rich contextual information", "author": ["T.D.B. Le", "M. Linares-Vasquez", "D. Lo", "D. Poshyvanyk"], "venue": "IEEE 23rd ICPC,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Changescribe: A tool for automatically generating commit messages", "author": ["M. Linares-V\u00e1squez", "L.F. Cort\u00e9s-Coy", "J. Aponte", "D. Poshyvanyk"], "venue": "In 2015 IEEE/ACM 37th IEEE ICSE,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}, {"title": "Latent predictor networks for code generation. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "author": ["W. Ling", "P. Blunsom", "E. Grefenstette", "K.M. Hermann", "T. Ko\u010disk\u00fd", "F. Wang", "A. Senior"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2016}, {"title": "Achieving open vocabulary neural machine translation with hybrid word-character models", "author": ["M. Luong", "C.D. Manning"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2016}, {"title": "Effective approaches to attention-based neural machine translation", "author": ["M. Luong", "H. Pham", "C.D. Manning"], "venue": "CoRR, abs/1508.04025,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2015}, {"title": "Can development work describe itself", "author": ["W. Maalej", "H.J. Happel"], "venue": "In 2010 7th IEEE Working Conference on Mining Software Repositories (MSR", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2010}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["C.D. Manning", "M. Surdeanu", "J. Bauer", "J. Finkel", "S.J. Bethard", "D. McClosky"], "venue": "In Association for Computational Linguistics (ACL) System Demonstrations,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2014}, {"title": "Identifying reasons for software changes using historic databases", "author": ["A. Mockus", "L.G. Votta"], "venue": "In Proceedings 2000 International Conference on Software Maintenance,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2000}, {"title": "ARENA: An approach for the automated generation of release notes", "author": ["L. Moreno", "G. Bavota", "M.D. Penta", "R. Oliveto", "A. Marcus", "G. Canfora"], "venue": "IEEE Transactions on Software Engineering,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2017}, {"title": "A systematic comparison of various statistical alignment models", "author": ["F.J. Och", "H. Ney"], "venue": "Computational Linguistics,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2003}, {"title": "Bleu: A method for automatic evaluation of machine translation", "author": ["K. Papineni", "S. Roukos", "T. Ward", "W.-J. Zhu"], "venue": "In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2002}, {"title": "A syntactic neural model for general-purpose code generation", "author": ["G.N. Pengcheng Yin"], "venue": "In Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2017}, {"title": "Why did this code change", "author": ["S. Rastkar", "G.C. Murphy"], "venue": "In Proceedings of the 2013 ICSE,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2013}, {"title": "How do professional developers comprehend software", "author": ["T. Roehm", "R. Tiarks", "R. Koschke", "W. Maalej"], "venue": "In Proceedings of the 2012 International Conference on Software Engineering,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2012}, {"title": "The cross-entropy method: a unified approach to combinatorial optimization, Monte-Carlo simulation and machine learning", "author": ["R.Y. Rubinstein", "D.P. Kroese"], "venue": "Springer Science & Business Media,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2013}, {"title": "Nadejde. Nematus: a toolkit for neural machine translation", "author": ["R. Sennrich", "O. Firat", "K. Cho", "A. Birch", "B. Haddow", "J. Hitschler", "M. Junczys-Dowmunt", "S. L\u201daubli", "A.V. Miceli Barone", "J. Mokry"], "venue": "In Proceedings of the Software Demonstrations of the 15th Conference of  the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2017}, {"title": "Nadejde. Nematus: a Toolkit for Neural Machine Translation", "author": ["R. Sennrich", "O. Firat", "K. Cho", "A. Birch", "B. Haddow", "J. Hitschler", "M. Junczys-Dowmunt", "S. L\u00e4ubli", "A.V. Miceli Barone", "J. Mokry"], "venue": "In Proceedings of the Demonstrations at the 15th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2017}, {"title": "Linguistic input features improve neural machine", "author": ["R. Sennrich", "B. Haddow"], "venue": "translation. CoRR,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2016}, {"title": "Edinburgh neural machine translation systems for", "author": ["R. Sennrich", "B. Haddow", "A. Birch"], "venue": "WMT 16. CoRR,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2016}, {"title": "Towards automatically generating summary comments for java methods", "author": ["G. Sridhara", "E. Hill", "D. Muppaneni", "L. Pollock", "K. Vijay-Shanker"], "venue": "In Proceedings of the IEEE/ACM international conference on Automated software engineering,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2010}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2014}, {"title": "Deep learning code fragments for code clone detection", "author": ["M. White", "M. Tufano", "C. Vendome", "D. Poshyvanyk"], "venue": "In Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2016}, {"title": "Toward deep learning software repositories", "author": ["M. White", "C. Vendome", "M. Linares-Vasquez", "D. Poshyvanyk"], "venue": "In 2015 IEEE/ACM 12th Working Conference on Mining Software Repositories,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2015}, {"title": "Adadelta: an adaptive learning rate method", "author": ["M.D. Zeiler"], "venue": "arXiv preprint arXiv:1212.5701,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2012}], "referenceMentions": [{"referenceID": 2, "context": "They serve a valuable purpose in comprehension of software evolution, and act as a record of feature additions and bug repairs [7].", "startOffset": 127, "endOffset": 130}, {"referenceID": 6, "context": "Unfortunately, programmers sometimes neglect commit messages [11], [36], likely due to the same time and market pressures that have been reported to affect many types of documentation [44], [12], [24].", "startOffset": 61, "endOffset": 65}, {"referenceID": 30, "context": "Unfortunately, programmers sometimes neglect commit messages [11], [36], likely due to the same time and market pressures that have been reported to affect many types of documentation [44], [12], [24].", "startOffset": 67, "endOffset": 71}, {"referenceID": 38, "context": "Unfortunately, programmers sometimes neglect commit messages [11], [36], likely due to the same time and market pressures that have been reported to affect many types of documentation [44], [12], [24].", "startOffset": 184, "endOffset": 188}, {"referenceID": 7, "context": "Unfortunately, programmers sometimes neglect commit messages [11], [36], likely due to the same time and market pressures that have been reported to affect many types of documentation [44], [12], [24].", "startOffset": 190, "endOffset": 194}, {"referenceID": 19, "context": "Unfortunately, programmers sometimes neglect commit messages [11], [36], likely due to the same time and market pressures that have been reported to affect many types of documentation [44], [12], [24].", "startOffset": 196, "endOffset": 200}, {"referenceID": 2, "context": "[7] describe DeltaDoc, a tool that summarizes what changed in the control flow of a program between code versions.", "startOffset": 0, "endOffset": 3}, {"referenceID": 26, "context": "[32] built ChangeScribe, which summarizes changes such as method additions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "Current approaches are effective at summarizing what changed and where, but do not answer the question why [7].", "startOffset": 107, "endOffset": 110}, {"referenceID": 32, "context": "[38] observed, many commit messages are similar and can be broadly categorized as related to bug repair, feature additions, etc.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "\u201d) [23].", "startOffset": 3, "endOffset": 7}, {"referenceID": 15, "context": "Our view is in line with the hypothesis of \u201cnaturalness\u201d of software [20], that software artifacts follow patterns that can be learned from sufficiently large datasets.", "startOffset": 69, "endOffset": 73}, {"referenceID": 43, "context": "The datasets required are enormous by typical software engineering research standards, involving up to tens of millions of pairs of sentences [49], [34].", "startOffset": 142, "endOffset": 146}, {"referenceID": 28, "context": "The datasets required are enormous by typical software engineering research standards, involving up to tens of millions of pairs of sentences [49], [34].", "startOffset": 148, "endOffset": 152}, {"referenceID": 6, "context": "While we were able to obtain quite large datasets (over 2M commits), we encountered many commit messages that were gibberish or very low quality (a problem others have observed [11], [36]), which if left in the training data could be reflected in the NMT\u2019s output.", "startOffset": 177, "endOffset": 181}, {"referenceID": 30, "context": "While we were able to obtain quite large datasets (over 2M commits), we encountered many commit messages that were gibberish or very low quality (a problem others have observed [11], [36]), which if left in the training data could be reflected in the NMT\u2019s output.", "startOffset": 183, "endOffset": 187}, {"referenceID": 6, "context": "These short term pressures lead programmers to neglect writing commit messages, like other types of documentation [11], [36], [44], [12], [24].", "startOffset": 114, "endOffset": 118}, {"referenceID": 30, "context": "These short term pressures lead programmers to neglect writing commit messages, like other types of documentation [11], [36], [44], [12], [24].", "startOffset": 120, "endOffset": 124}, {"referenceID": 38, "context": "These short term pressures lead programmers to neglect writing commit messages, like other types of documentation [11], [36], [44], [12], [24].", "startOffset": 126, "endOffset": 130}, {"referenceID": 7, "context": "These short term pressures lead programmers to neglect writing commit messages, like other types of documentation [11], [36], [44], [12], [24].", "startOffset": 132, "endOffset": 136}, {"referenceID": 19, "context": "These short term pressures lead programmers to neglect writing commit messages, like other types of documentation [11], [36], [44], [12], [24].", "startOffset": 138, "endOffset": 142}, {"referenceID": 2, "context": "[7] point out that programmers use commit messages for two reasons: 1) to summarize what changed, and 2) to briefly explain why the change was necessary.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "have built DeltaDoc, which extracts path predicates of changed statements, and follows a set of predefined rules to generate a summary [7].", "startOffset": 135, "endOffset": 138}, {"referenceID": 26, "context": "have built ChangeScribe, which extracts changes between two Abstract Syntax Trees and summarizes the changes based on predefined rules [32].", "startOffset": 135, "endOffset": 139}, {"referenceID": 25, "context": "have built RCLinker, which links a bug report to the corresponding commit message [31].", "startOffset": 82, "endOffset": 86}, {"referenceID": 37, "context": "Rastkar and Murphy have proposed to summarize multiple related documents for commits [43].", "startOffset": 85, "endOffset": 89}, {"referenceID": 33, "context": "have built ARENA, which summarizes changes and finds related issues to generate release notes [39].", "startOffset": 94, "endOffset": 98}, {"referenceID": 11, "context": "Extractive summarization extracts relevant parts of source code and uses the relevant parts as a summary [16].", "startOffset": 105, "endOffset": 109}, {"referenceID": 44, "context": "has designed a Natural Language Generation (NLG) system to create summaries of Java methods [50].", "startOffset": 92, "endOffset": 96}, {"referenceID": 17, "context": "have built Code-NN, which uses an Neural Machine Translation (NMT) algorithm to summarize code snippets [22].", "startOffset": 104, "endOffset": 108}, {"referenceID": 20, "context": "For example, to detect code clones, traditional approaches predefine the representations of code fragments (some techniques use token sequences to represent code [25]; others use graphs [29], [9]).", "startOffset": 162, "endOffset": 166}, {"referenceID": 23, "context": "For example, to detect code clones, traditional approaches predefine the representations of code fragments (some techniques use token sequences to represent code [25]; others use graphs [29], [9]).", "startOffset": 186, "endOffset": 190}, {"referenceID": 4, "context": "For example, to detect code clones, traditional approaches predefine the representations of code fragments (some techniques use token sequences to represent code [25]; others use graphs [29], [9]).", "startOffset": 192, "endOffset": 195}, {"referenceID": 46, "context": "[53] learns the representations of code automatically.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "Similarly, deep learning algorithms are introduced in bug localization [30], software traceability [15], and code suggestions [54].", "startOffset": 71, "endOffset": 75}, {"referenceID": 10, "context": "Similarly, deep learning algorithms are introduced in bug localization [30], software traceability [15], and code suggestions [54].", "startOffset": 99, "endOffset": 103}, {"referenceID": 47, "context": "Similarly, deep learning algorithms are introduced in bug localization [30], software traceability [15], and code suggestions [54].", "startOffset": 126, "endOffset": 130}, {"referenceID": 9, "context": "[14], because both our and their techniques use Neural Machine Translation (NMT).", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "use NMT to translate natural language queries to API method sequences [14].", "startOffset": 70, "endOffset": 74}, {"referenceID": 27, "context": "Similarly, several code generation techniques use NMT to translate natural language to programming language [33], [42].", "startOffset": 108, "endOffset": 112}, {"referenceID": 36, "context": "Similarly, several code generation techniques use NMT to translate natural language to programming language [33], [42].", "startOffset": 114, "endOffset": 118}, {"referenceID": 0, "context": "[5], which investigates the suitability of NMT for program comprehension.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[7] and by Jiang and McMillan [23].", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[7] and by Jiang and McMillan [23].", "startOffset": 30, "endOffset": 34}, {"referenceID": 0, "context": ", yn) with the conditional probability p(y|x) [5], [35].", "startOffset": 46, "endOffset": 49}, {"referenceID": 29, "context": ", yn) with the conditional probability p(y|x) [5], [35].", "startOffset": 51, "endOffset": 55}, {"referenceID": 5, "context": "introduced RNN Encoder-Decoder as an NMT model [10], which is commonly used and can produce state of the art translation performance [49], [34].", "startOffset": 47, "endOffset": 51}, {"referenceID": 43, "context": "introduced RNN Encoder-Decoder as an NMT model [10], which is commonly used and can produce state of the art translation performance [49], [34].", "startOffset": 133, "endOffset": 137}, {"referenceID": 28, "context": "introduced RNN Encoder-Decoder as an NMT model [10], which is commonly used and can produce state of the art translation performance [49], [34].", "startOffset": 139, "endOffset": 143}, {"referenceID": 9, "context": "As a promising deep learning model, RNN Encoder-Decoder has been used in addressing other software engineering tasks [14], [5].", "startOffset": 117, "endOffset": 121}, {"referenceID": 0, "context": "As a promising deep learning model, RNN Encoder-Decoder has been used in addressing other software engineering tasks [14], [5].", "startOffset": 123, "endOffset": 126}, {"referenceID": 16, "context": "Two common options for f are long short-term memory (LSTM) [21] and the gated recurrent unit (GRU) [10] (due to space limit, we do not describe these two unit types in detail here).", "startOffset": 59, "endOffset": 63}, {"referenceID": 5, "context": "Two common options for f are long short-term memory (LSTM) [21] and the gated recurrent unit (GRU) [10] (due to space limit, we do not describe these two unit types in detail here).", "startOffset": 99, "endOffset": 103}, {"referenceID": 1, "context": "use GRU [6] and Sutskever et al.", "startOffset": 8, "endOffset": 11}, {"referenceID": 45, "context": "use LSTM [51].", "startOffset": 9, "endOffset": 13}, {"referenceID": 1, "context": "introduced the attentional RNN EncoderDecoder, in which attention mechanism is introduced to deal with long source sequences [6].", "startOffset": 125, "endOffset": 128}, {"referenceID": 18, "context": "We used the commit data set provided by Jiang and McMillan [23], which contains 2M commits.", "startOffset": 59, "endOffset": 63}, {"referenceID": 9, "context": "used the first sentences of the API comments as their target sequences [14].", "startOffset": 71, "endOffset": 75}, {"referenceID": 18, "context": "Third, we removed merge and rollback commits (the same practice done by Jiang and McMillan [23]).", "startOffset": 91, "endOffset": 95}, {"referenceID": 1, "context": "A maximum sequence length for both source and target sequences need to be set for an RNN Encoder-Decoder [6], [46].", "startOffset": 105, "endOffset": 108}, {"referenceID": 40, "context": "A maximum sequence length for both source and target sequences need to be set for an RNN Encoder-Decoder [6], [46].", "startOffset": 110, "endOffset": 114}, {"referenceID": 1, "context": "Since NMT is for translating natural language sentences, maximum sequence lengths for both source and target sequences are often set between 50 to 100 [6], [46].", "startOffset": 151, "endOffset": 154}, {"referenceID": 40, "context": "Since NMT is for translating natural language sentences, maximum sequence lengths for both source and target sequences are often set between 50 to 100 [6], [46].", "startOffset": 156, "endOffset": 160}, {"referenceID": 18, "context": "We chose this pattern because a previous study shows that 47% of commit messages follow this pattern [23].", "startOffset": 101, "endOffset": 105}, {"referenceID": 31, "context": "To find the pattern, we used a Natural Language Processing (NLP) tool, Stanford CoreNLP [37], to annotate the sentences with grammar dependencies.", "startOffset": 88, "endOffset": 92}, {"referenceID": 28, "context": "Additionally, the vocabulary size of 50k is often used by other NMT models [34].", "startOffset": 75, "endOffset": 79}, {"referenceID": 41, "context": "1) Model: We used Nematus [47] in our work because it is robust, easy to use, and produced best constrained systems for seven translation directions (e.", "startOffset": 26, "endOffset": 30}, {"referenceID": 43, "context": ") in WMT 2016 shared news translation task [49].", "startOffset": 43, "endOffset": 47}, {"referenceID": 41, "context": "Nematus is based on Theano [52], and implements the attentional RNN encoder-decoder (see Section III-C) with several implementation differences [47].", "startOffset": 144, "endOffset": 148}, {"referenceID": 43, "context": "used to produce the best translation systems in WMT 2016 [49].", "startOffset": 57, "endOffset": 61}, {"referenceID": 39, "context": "The training goal is cross-entropy minimization [45].", "startOffset": 48, "endOffset": 52}, {"referenceID": 48, "context": "The learning algorithm is stochastic gradient descent (SGD) with Adadelta [55], which automatically adapts the learning rate.", "startOffset": 74, "endOffset": 78}, {"referenceID": 35, "context": "The model is validated every 10k minibatches by BLEU [41], which is a commonly used similarity metric for machine translation.", "startOffset": 53, "endOffset": 57}, {"referenceID": 41, "context": "The maximum number of epochs is 5k; the maximum number of minibatches is 10M; and early stopping is used [47].", "startOffset": 105, "endOffset": 109}, {"referenceID": 28, "context": "We note that we followed the standard evaluation procedure for NMT and used a test set of 3k [34], [48], [10].", "startOffset": 93, "endOffset": 97}, {"referenceID": 42, "context": "We note that we followed the standard evaluation procedure for NMT and used a test set of 3k [34], [48], [10].", "startOffset": 99, "endOffset": 103}, {"referenceID": 5, "context": "We note that we followed the standard evaluation procedure for NMT and used a test set of 3k [34], [48], [10].", "startOffset": 105, "endOffset": 109}, {"referenceID": 22, "context": "We used MOSES [28] as the baseline in RQ1.", "startOffset": 14, "endOffset": 18}, {"referenceID": 3, "context": "MOSES is a popular statistical machine translation software, which is often used as a baseline in evaluating machine translation systems [8], [27].", "startOffset": 137, "endOffset": 140}, {"referenceID": 21, "context": "MOSES is a popular statistical machine translation software, which is often used as a baseline in evaluating machine translation systems [8], [27].", "startOffset": 142, "endOffset": 146}, {"referenceID": 17, "context": "used MOSES as a baseline when they evaluated Code-NN [22].", "startOffset": 53, "endOffset": 57}, {"referenceID": 13, "context": "To run MOSES for translating diffs to commit messages, we trained a 3gram language model using KenLM [18], [19], which is the same procedure in the study of Iyer et al.", "startOffset": 101, "endOffset": 105}, {"referenceID": 14, "context": "To run MOSES for translating diffs to commit messages, we trained a 3gram language model using KenLM [18], [19], which is the same procedure in the study of Iyer et al.", "startOffset": 107, "endOffset": 111}, {"referenceID": 17, "context": "[22].", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "We did not use Code-NN as a baseline, because, in our pilot study of running Code-NN [22] to generate commit messages, CodeNN did not generate comparable results.", "startOffset": 85, "endOffset": 89}, {"referenceID": 35, "context": "BLEU [41] is widely used to measure the similarity between two sentences in evaluation of machine translation systems [26], [34], [33].", "startOffset": 5, "endOffset": 9}, {"referenceID": 28, "context": "BLEU [41] is widely used to measure the similarity between two sentences in evaluation of machine translation systems [26], [34], [33].", "startOffset": 124, "endOffset": 128}, {"referenceID": 27, "context": "BLEU [41] is widely used to measure the similarity between two sentences in evaluation of machine translation systems [26], [34], [33].", "startOffset": 130, "endOffset": 134}, {"referenceID": 35, "context": "Additionally, BLEU is recommended for assessing an entire test set instead of a sentence [41].", "startOffset": 89, "endOffset": 93}, {"referenceID": 42, "context": "The default value of N is 4, which is used in our evaluation and is commonly used in other evaluations [26], [48], [34], [22], [33], [14].", "startOffset": 109, "endOffset": 113}, {"referenceID": 28, "context": "The default value of N is 4, which is used in our evaluation and is commonly used in other evaluations [26], [48], [34], [22], [33], [14].", "startOffset": 115, "endOffset": 119}, {"referenceID": 17, "context": "The default value of N is 4, which is used in our evaluation and is commonly used in other evaluations [26], [48], [34], [22], [33], [14].", "startOffset": 121, "endOffset": 125}, {"referenceID": 27, "context": "The default value of N is 4, which is used in our evaluation and is commonly used in other evaluations [26], [48], [34], [22], [33], [14].", "startOffset": 127, "endOffset": 131}, {"referenceID": 9, "context": "The default value of N is 4, which is used in our evaluation and is commonly used in other evaluations [26], [48], [34], [22], [33], [14].", "startOffset": 133, "endOffset": 137}, {"referenceID": 34, "context": "Particularly, MOSES depends on Giza++ [40] for word alignments between source and target sequences, and", "startOffset": 38, "endOffset": 42}, {"referenceID": 35, "context": "First, although BLEU is a widely used metric that enables us to compare our model with others and to deliver reproducibility, BLEU is not recommended for evaluating individual sentences [41].", "startOffset": 186, "endOffset": 190}, {"referenceID": 12, "context": "Tf/idf is widely used in machine learning for text processing [17], which is computed based on the frequency of a word in a diff and whether the word is common in the other diffs.", "startOffset": 62, "endOffset": 66}, {"referenceID": 32, "context": ", [38], [23]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 18, "context": ", [38], [23]).", "startOffset": 8, "endOffset": 12}, {"referenceID": 8, "context": "While creating these new insights from the data is currently beyond the power of existing neural network-based machine learning (a problem observed across application domains [13]), at a minimum we would like to return a warning message to the programmer to indicate that we are unable to generate a message, rather than return a low quality message.", "startOffset": 175, "endOffset": 179}], "year": 2017, "abstractText": "Commit messages are a valuable resource in comprehension of software evolution, since they provide a record of changes such as feature additions and bug repairs. Unfortunately, programmers often neglect to write good commit messages. Different techniques have been proposed to help programmers by automatically writing these messages. These techniques are effective at describing what changed, but are often verbose and lack context for understanding the rationale behind a change. In contrast, humans write messages that are short and summarize the high level rationale. In this paper, we adapt Neural Machine Translation (NMT) to automatically \u201ctranslate\u201d diffs into commit messages. We trained an NMT algorithm using a corpus of diffs and human-written commit messages from the top 1k Github projects. We designed a filter to help ensure that we only trained the algorithm on higher-quality commit messages. Our evaluation uncovered a pattern in which the messages we generate tend to be either very high or very low quality. Therefore, we created a quality-assurance filter to detect cases in which we are unable to produce good messages, and return a warning instead.", "creator": "LaTeX with hyperref package"}}}