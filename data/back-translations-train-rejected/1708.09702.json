{"id": "1708.09702", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Aug-2017", "title": "Human and Machine Judgements for Russian Semantic Relatedness", "abstract": "Semantic relatedness of terms represents similarity of meaning by a numerical score. On the one hand, humans easily make judgments about semantic relatedness. On the other hand, this kind of information is useful in language processing systems. While semantic relatedness has been extensively studied for English using numerous language resources, such as associative norms, human judgments, and datasets generated from lexical databases, no evaluation resources of this kind have been available for Russian to date. Our contribution addresses this problem. We present five language resources of different scale and purpose for Russian semantic relatedness, each being a list of triples (word_i, word_j, relatedness_ij). Four of them are designed for evaluation of systems for computing semantic relatedness, complementing each other in terms of the semantic relation type they represent. These benchmarks were used to organize a shared task on Russian semantic relatedness, which attracted 19 teams. We use one of the best approaches identified in this competition to generate the fifth high-coverage resource, the first open distributional thesaurus of Russian. Multiple evaluations of this thesaurus, including a large-scale crowdsourcing study involving native speakers, indicate its high accuracy.", "histories": [["v1", "Thu, 31 Aug 2017 13:33:04 GMT  (568kb,D)", "http://arxiv.org/abs/1708.09702v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["alexander panchenko", "dmitry ustalov", "nikolay arefyev", "denis paperno", "natalia konstantinova", "natalia loukachevitch", "chris biemann"], "accepted": false, "id": "1708.09702"}, "pdf": {"name": "1708.09702.pdf", "metadata": {"source": "CRF", "title": "Human and Machine Judgements for Russian Semantic Relatedness", "authors": ["Alexander Panchenko", "Dmitry Ustalov", "Nikolay Arefyev", "Denis Paperno", "Natalia Konstantinova", "Natalia Loukachevitch", "Chris Biemann"], "emails": ["panchenko@lt.informatik.tu-darmstadt.de", "biem@lt.informatik.tu-darmstadt.de", "dmitry.ustalov@urfu.ru", "louk_nat@mail.ru", "denis.paperno@unitn.it", "n.konstantinova@wlv.ac.uk"], "sections": [{"heading": null, "text": "Keywords: semantic similarity \u00b7 semantic kinship \u00b7 evaluation \u00b7 distribution thesaurus \u00b7 crowdsourcing \u00b7 language resources"}, {"heading": "1 Introduction", "text": "Se's tis, \"he said."}, {"heading": "2 Related Work", "text": "There are three main approaches to evaluating semantic relationships: the use of human judgments on word pairs, the use of semantic relationships from lexical-semantic resources such as WordNet [10], and the use of data from cognitive word association experiments. We have created three evaluation datasets for Russian, each based on one of these principles, to allow a comprehensive comparison of relationship models."}, {"heading": "2.1 Datasets Based on Human Judgements about Word Pairs", "text": "However, the HJ datasets presented in Section 3.1 belong to this group of assessment datasets. 51 people rated the pairs on a scale of 0 to 4 for their similarity. Later, Miller and Charles replicated the Rubenstein and Goodenough experiment by achieving similar results on a subset of 30 noun pairs, using 10 words from the high level (between 3 and 4), 10 from the middle level (between 1 and 3), and 10 from the lower level of semantic diversity."}, {"heading": "2.2 Datasets Based on Lexical-Semantic Resources", "text": "Another set of evaluation data sets evaluates semantic kinship values in relation to relationships described in lexical-semantic resources such as WordNet. The RT dataset presented in Section 3.2 belongs to this group of evaluation data sets. Baroni and Lenci [25] emphasized that semantically related words differ in the nature of the relationship between them, so they created the BLESS dataset, which contained tuples of the form (wj, wj, type). Types of relationships included co-hyponyms, hypernyms, meronyms, attributes (relationship between a noun and an adjective expressing its attribute), event (relationship between a noun and a verb referring to actions or events). BLESS also contains for each target word a number of random words that have been verified to make semantically no connection with that word."}, {"heading": "2.3 Datasets Based on Human Word Association Experiments", "text": "The third strain of research assesses the ability of current automated systems to simulate the results of human word association experiments. Assessment tasks based on associative relationships originally attracted the attention of psychologists such as Griffiths and Steyvers. [29] Such a task was organised as part of the Cogalex workshop [30]. Participants were given lists of five words (e.g. \"circus,\" \"funny,\" \"nose,\" \"fool\" and \"coco\") and told to select the word most closely related to them all. In this particular case, the word \"clown\" is the expected answer. 2000 sentences of five input words were provided to participants as a training set along with the expected target words (associative answers). The test data set contained a further 2000 sentences of five input words. The training and test data sets were both derived from the Edinburgh Associative Thesaurus (EAT) [31]."}, {"heading": "3 Human Judgements about Semantic Relatedness", "text": "In this section we describe three sets of data for the evaluation of Russian semantic kinship measures. These data sets were tested as part of the joint task RUssian Semantic Similarity Evaluation (RUSSE) [32]. [8] Each participant had to calculate similarities between a collection of word pairs. Subsequently, each submission was evaluated against the three benchmarks listed below, each representing a subset of the entered word pairs."}, {"heading": "3.1 HJ: Human Judgements of Word Pairs", "text": "Description of dataset: The HY dataset is an association of three widely used benchmarks for English: RG, MC and WordSim353, see [14, 33-35, 35, 36] inter8 http: / / russe.nlpub.rualia. The dataset contains 398 pairs of words translated into Russian and commented on by native speakers. In addition to the complete dataset, we also provide separate parts, the MC, RG and WordSim353. To collect human judgments, an in-house crowdsourcing system was used. We set up a special section on the RUSSE website and asked volunteers on Facebook and Twitter to participate in the experiment. Each annotator was assigned an assignment consisting of 15 randomly selected pairs of the 398 pairs of words, and was asked to rate the assignment of the individual datasets on the following scale: 0 - unrelated datasets, 1 - weak assignment, 2 - reliability, high assignment of the individual datassignments, 3 - high reliability of the individual datassignments, and 3 - high reliability of the individual datassignments."}, {"heading": "3.2 RT: Synonyms and Hypernyms", "text": "Description of the dataset. This dataset follows the structure of the BLESS dataset [25]. Each target word has the same number of related and unrelated source words. The dataset contains 9 548 relationships to 1 008 nouns (see Table 2). Half of these relationships are synonyms and hypernyms from the thesaurus Ruthes-lite [37], and half of them are unrelated words. To create negative pairs, we used the automatic method described in Panchenko et al. [32]. We filtered out false negative relationships to 1 008 source words using human annotators. Each negative relationship in this subset was commented by at least two annotators: Master students of an NLP course, native speakers of Russia. As a result, we provide a dataset with 9 548 relationships to 1 008 source words, each having the same number of negative random relationships and positive (synonymer or hyperlateral) relationships."}, {"heading": "3.3 AE: Cognitive Associations", "text": "Description of the dataset. The structure of this dataset is the same as the structure of the RT dataset: Each source word has the same number of related and unrelated target words. The difference is that related pairs of words from this dataset were taken from a Russian web-based associative experiment.10 In the experiment, users were asked to respond to an input-stimulus source word, e.g.: man \u2192 woman, time \u2192 money, etc. The strength of the association in this experiment is quantified by the number of respondents providing the same stimulus reaction pair. Associative thesauri typically contain a mixture of synonyms, hyponyms, meronyms, and other types, making relationships asymmetrical. To build this dataset, we selected targets with the highest association with the stimulus in Sociation.org data. As with the other datasets, we used only single substances, other word relationships, and other types, resulting in asymmetrical relationships."}, {"heading": "4 Machine Judgements about Semantic Relatedness", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 MJ: Machine Judgements of Word Pairs", "text": "Description of the dataset. This dataset contains 12,886 word pairs of 1,519 source words originating from HJ, RT and AE datasets. Only 398 word pairs from the HJ dataset have continuous results, while the other pairs originating from RT and AE datasets have binary affiliation values. However, for the training, 10 mappings from the soziation.org database were evaluated in July 2014.and for evaluation purposes that it is desirable to have continuous mappings because they distinguish between shades of affiliation. Nevertheless, the manual annotation of a large number of pairs is problematic: the largest datasets of this kind available to date contain the MEN, 3 000 word pairs. The unique feature of the MJ dataset is that it is simultaneously large-scale, like BLESS, and has accurate continuous results, like WordSim-353.To estimate continuous mappings with high reliability, without judgement."}, {"heading": "4.2 RDT: Russian Distributional Thesaurus", "text": "This resource, thanks to its coverage of 932,896 target words, can be used directly in NLP systems. To build the distributional thesaurus model, we used the Skip-gram model [38], which was trained on a 12.9 billion word collection of Russian texts derived from the digital library lib.rus.rus.ec. According to the results of the joint task in Russian semantic relativization [32,39], this approach has in the top 5 among 105 submissions, which dataset different order depending on the evaluation."}, {"heading": "5 Conclusion", "text": "In this paper, we introduced five new Russian language resources that can be used to train and evaluate semantic kinship measures; 11 annotation guidelines are available at http: / / crowd.russe.nlpub.ru. 12 http: / / mtsar.nlpub.org and to create NLP applications that require semantic kinship; these resources were used to perform a large-scale evaluation of 105 submissions in a joint task on semantic kinship with Russian native speakers; one of the best systems identified in this evaluation campaign was used to generate the first open Russian distribution thesaurus; and the manual evaluation of this thesaurus, based on a large-scale crowdsourcing with native speakers, showed a precision of 0.94 on the top-10 similar words. All of the introduced resources are available for download.13 Finally, the methodology for Loubootype Foundation's database-related constructions were supported by BR Foundation. \""}], "references": [{"title": "Evaluating WordNet-based Measures of Lexical Semantic Relatedness", "author": ["A. Budanitsky", "G. Hirst"], "venue": "Computational Linguistics 32(1)", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Measures of semantic similarity and relatedness in the biomedical domain", "author": ["T. Pedersen", "S.V. Pakhomov", "S. Patwardhan", "C.G. Chute"], "venue": "Journal of Biomedical Informatics 40(3)", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Computing Semantic Relatedness Using Wikipedia-based Explicit Semantic Analysis", "author": ["E. Gabrilovich", "S. Markovitch"], "venue": "Proceedings of the 20th International Joint Conference on Artifical Intelligence. IJCAI\u201907, Morgan Kaufmann Publishers Inc.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "An ontology-based measure to compute semantic similarity in biomedicine", "author": ["M. Batet", "D. S\u00e1nchez", "A. Valls"], "venue": "Journal of Biomedical Informatics 44(1)", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "UKP: Computing Semantic Textual Similarity by Combining Multiple Content Similarity Measures", "author": ["D. B\u00e4r", "C. Biemann", "I. Gurevych", "T. Zesch"], "venue": "Proceedings of the First Joint Conference on Lexical and Computational Semantics - Volume 1: Proceedings of the Main Conference and the Shared Task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation. SemEval \u201912, Association for Computational Linguistics", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Text Relatedness Based on a Word Thesaurus", "author": ["G. Tsatsaronis", "I. Varlamis", "M. Vazirgiannis"], "venue": "Journal of Artificial Intelligence Research 37(1)", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Using Measures of Semantic Relatedness for Word Sense Disambiguation", "author": ["S. Patwardhan", "S. Banerjee", "T. Pedersen"], "venue": "Proceedings of the 4th International Conference on Computational Linguistics and Intelligent Text Processing. Springer Berlin Heidelberg", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "Query Expansion with ConceptNet and WordNet: An Intrinsic Comparison", "author": ["M.H. Hsu", "M.F. Tsai", "H.H. Chen"], "venue": "Information Retrieval Technology: Third Asia Information Retrieval Symposium, AIRS 2006, Singapore, October 16-18, 2006. Proceedings. Springer Berlin Heidelberg", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Similarity Measures for Semantic Relation Extraction", "author": ["A. Panchenko"], "venue": "PhD thesis, UCLouvain", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "WordNet: A Lexical Database for English", "author": ["G.A. Miller"], "venue": "Communications of the ACM 38(11)", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1995}, {"title": "Contextual correlates of synonymy", "author": ["H. Rubenstein", "J.B. Goodenough"], "venue": "Communications of the ACM 8(10)", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1965}, {"title": "Contextual correlates of semantic similarity", "author": ["G.A. Miller", "W.G. Charles"], "venue": "Language and Cognitive Processes 6(1)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1991}, {"title": "Placing Search in Context: The Concept Revisited", "author": ["L. Finkelstein", "E. Gabrilovich", "Y. Matias", "E. Rivlin", "Z. Solan", "G. Wolfman", "E. Ruppin"], "venue": "Proceedings of the 10th International Conference on World Wide Web. WWW \u201901, ACM", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "A Study on Similarity and Relatedness Using Distributional and WordNet-based Approaches", "author": ["E. Agirre", "E. Alfonseca", "K. Hall", "J. Kravalova", "M. Pa\u015fca", "A. Soroa"], "venue": "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics. NAACL \u201909, Association for Computational Linguistics", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Using the Structure of a Conceptual Network in Computing Semantic Relatedness", "author": ["I. Gurevych"], "venue": "Natural Language Processing \u2013 IJCNLP 2005: Second International Joint Conference, Jeju Island, Korea, October 11-13, 2005. Proceedings. Springer Berlin Heidelberg", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2005}, {"title": "Cross-lingual Semantic Relatedness Using Encyclopedic Knowledge", "author": ["S. Hassan", "R. Mihalcea"], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3 - Volume 3. EMNLP \u201909, Association for Computational Linguistics", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "What implementation and translation teach us: the case of semantic similarity measures in wordnets", "author": ["M. Postma", "P. Vossen"], "venue": "Proceedings of the Seventh Global Wordnet Conference.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Semeval-2012 task 4: Evaluating chinese word similarity", "author": ["P. Jin", "Y. Wu"], "venue": "Proceedings of the First Joint Conference on Lexical and Computational Semantics - Volume 1: Proceedings of the Main Conference and the Shared Task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation. SemEval \u201912, Association for Computational Linguistics", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Verb Similarity on the Taxonomy of WordNet", "author": ["D. Yang", "D.M.W. Powers"], "venue": "Proceedings of the Third International WordNet Conference \u2014 GWC 2006, Masaryk University", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "To Exhibit is not to Loiter: A Multilingual, SenseDisambiguated Wiktionary for Measuring Verb Similarity", "author": ["C.M. Meyer", "I. Gurevych"], "venue": "Proceedings of COLING 2012: Technical Papers, The COLING 2012 Organizing Committee", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "SimLex-999: Evaluating Semantic Models With (Genuine) Similarity Estimation", "author": ["F. Hill", "R. Reichart", "A. Korhonen"], "venue": "Computational Linguistics 41(4)", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Multimodal Distributional Semantics", "author": ["E. Bruni", "N.K. Tran", "M. Baroni"], "venue": "Journal of Artificial Intelligence Research 49(1)", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Introducing and evaluating ukWaC, a very large Web-derived corpus of English", "author": ["A. Ferraresi", "E. Zanchetta", "S. Bernardini", "M. Baroni"], "venue": "Proceedings of the 4th Web as Corpus Workshop (WAC-4): Can we beat Google?", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2008}, {"title": "Community Evaluation and Exchange of Word Vectors at wordvectors.org. In: Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations", "author": ["M. Faruqui", "C. Dyer"], "venue": "Association for Computational Linguistics", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "How We BLESSed Distributional Semantic Evaluation", "author": ["M. Baroni", "A. Lenci"], "venue": "Proceedings of the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics. GEMS \u201911, Association for Computational Linguistics", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "Mining for Meaning: The Extraction of Lexicosemantic Knowledge from Text", "author": ["T. Van de Cruys"], "venue": "PhD thesis, University of Groningen", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "Text: Now in 2D! a framework for lexical expansion with contextual similarity", "author": ["C. Biemann", "M. Riedl"], "venue": "Journal of Language Modelling 1(1)", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "The Word-Space Model: Using distributional analysis to represent syntagmatic and paradigmatic relations between words in high-dimensional vector spaces", "author": ["M. Sahlgren"], "venue": "PhD thesis, Stockholm University", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2006}, {"title": "Prediction and Semantic Association", "author": ["T.L. Griffiths", "M. Steyvers"], "venue": "Advances in Neural Information Processing Systems 15. MIT Press", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2003}, {"title": "The CogALex-IV Shared Task on the Lexical Access Problem", "author": ["R. Rapp", "M. Zock"], "venue": "Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon (CogALex), Association for Computational Linguistics and Dublin City University", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "An associative thesaurus of English and its computer analysis", "author": ["G.R. Kiss", "C. Armstrong", "R. Milroy", "J. Piper"], "venue": "The Computer and Literary Studies. Edinburgh University Press", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1973}, {"title": "RUSSE: The First Workshop on Russian Semantic Similarity", "author": ["A. Panchenko", "N.V. Loukachevitch", "D. Ustalov", "D. Paperno", "C.M. Meyer", "N. Konstantinova"], "venue": "Computational Linguistics and Intellectual Technologies: papers from the Annual conference \u201cDialogue\u201d. Volume 2. RGGU", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Using Information Content to Evaluate Semantic Similarity in a Taxonomy", "author": ["P. Resnik"], "venue": "Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 1. IJCAI\u201995, Morgan Kaufmann Publishers Inc.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1995}, {"title": "An Information-Theoretic Definition of Similarity", "author": ["D. Lin"], "venue": "Proceedings of the Fifteenth International Conference on Machine Learning. ICML \u201998, Morgan Kaufmann Publishers Inc.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1998}, {"title": "Using WordNet-based Context Vectors to Estimate the Semantic Relatedness of Concepts", "author": ["S. Patwardhan", "T. Pedersen"], "venue": "Proceedings of the Workshop on Making Sense of Sense: Bringing Psycholinguistics and Computational Linguistics Together, Association for Computational Linguistics", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2006}, {"title": "Using Wiktionary for Computing Semantic Relatedness", "author": ["T. Zesch", "C. M\u00fcller", "I. Gurevych"], "venue": "Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 2. AAAI\u201908, AAAI Press", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2008}, {"title": "RuThes-Lite, a publicly available version of Thesaurus of Russian language RuThes", "author": ["N.V. Loukachevitch", "B.V. Dobrov", "I.I. Chetviorkin"], "venue": "Computational Linguistics and Intellectual Technologies: papers from the Annual conference \u201cDialogue\u201d, RGGU", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2014}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in Neural Information Processing Systems 26. Curran Associates, Inc.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2013}, {"title": "Evaluating Three Corpus-Based Semantic Similarity Systems for Russian", "author": ["N. Arefyev", "A. Panchenko", "A. Lukanin", "O. Lesota", "P. Romanov"], "venue": "Computational Linguistics and Intellectual Technologies: papers from the Annual conference \u201cDialogue\u201d. Volume 2. RGGU", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}, {"title": "The Impact of Different Vector Space Models and Supplementary Techniques on Russian Semantic Similarity Task", "author": ["K.A. Lopukhin", "A.A. Lopukhina", "G.V. Nosyrev"], "venue": "Computational Linguistics and Intellectual Technologies: Papers from the Annual conference \u201cDialogue\u201d. Volume 2. RGGU", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2015}, {"title": "Morphological Analyzer and Generator for Russian and Ukrainian Languages", "author": ["M. Korobov"], "venue": "Analysis of Images, Social Networks and Texts: 4th International Conference, AIST 2015, Revised Selected Papers. Springer International Publishing", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2015}, {"title": "A Crowdsourcing Engine for Mechanized Labor", "author": ["D. Ustalov"], "venue": "Proceedings of the Institute for System Programming 27(3)", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Semantic relatedness and semantic similarity have been extensively studied in psychology and computational linguistics, see [1\u20134] inter alia.", "startOffset": 124, "endOffset": 129}, {"referenceID": 1, "context": "Semantic relatedness and semantic similarity have been extensively studied in psychology and computational linguistics, see [1\u20134] inter alia.", "startOffset": 124, "endOffset": 129}, {"referenceID": 2, "context": "Semantic relatedness and semantic similarity have been extensively studied in psychology and computational linguistics, see [1\u20134] inter alia.", "startOffset": 124, "endOffset": 129}, {"referenceID": 3, "context": "Semantic relatedness and semantic similarity have been extensively studied in psychology and computational linguistics, see [1\u20134] inter alia.", "startOffset": 124, "endOffset": 129}, {"referenceID": 4, "context": "Semantic relatedness is an important building block of NLP techniques, such as text similarity [5, 6], word sense disambiguation [7], query expansion [8] and some others [9].", "startOffset": 95, "endOffset": 101}, {"referenceID": 5, "context": "Semantic relatedness is an important building block of NLP techniques, such as text similarity [5, 6], word sense disambiguation [7], query expansion [8] and some others [9].", "startOffset": 95, "endOffset": 101}, {"referenceID": 6, "context": "Semantic relatedness is an important building block of NLP techniques, such as text similarity [5, 6], word sense disambiguation [7], query expansion [8] and some others [9].", "startOffset": 129, "endOffset": 132}, {"referenceID": 7, "context": "Semantic relatedness is an important building block of NLP techniques, such as text similarity [5, 6], word sense disambiguation [7], query expansion [8] and some others [9].", "startOffset": 150, "endOffset": 153}, {"referenceID": 8, "context": "Semantic relatedness is an important building block of NLP techniques, such as text similarity [5, 6], word sense disambiguation [7], query expansion [8] and some others [9].", "startOffset": 170, "endOffset": 173}, {"referenceID": 9, "context": "There are three main approaches to evaluating semantic relatedness: using human judgements about word pairs, using semantic relations from lexical-semantic resources, such as WordNet [10], and using data from cognitive word association experiments.", "startOffset": 183, "endOffset": 187}, {"referenceID": 10, "context": "Research on relatedness starts from the pioneering work of Rubenstein and Goodenough [11], where they aggregated human judgments on the relatedness of 65 noun pairs into the RG dataset.", "startOffset": 85, "endOffset": 89}, {"referenceID": 11, "context": "Later, Miller and Charles [12] replicated the experiment of Rubenstein and Goodenough, obtaining similar results on a subset of 30 noun pairs.", "startOffset": 26, "endOffset": 30}, {"referenceID": 12, "context": "[13] as the WordSim353 dataset.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] subdivided the WordSim353 dataset into two subsets: the WordSim353 similarity set and the WordSim353 relatedness set.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "Gurevych translated the RG and MC datasets into German [15]; Hassan and Mihalcea translated them into Spanish, Arabic and Romanian [16]; Postma and Vossen [17] translated the datasets into Dutch; Jin and Wu [18] presented a shared task for Chinese semantic similarity, where the authors translated the WordSim353 dataset.", "startOffset": 55, "endOffset": 59}, {"referenceID": 15, "context": "Gurevych translated the RG and MC datasets into German [15]; Hassan and Mihalcea translated them into Spanish, Arabic and Romanian [16]; Postma and Vossen [17] translated the datasets into Dutch; Jin and Wu [18] presented a shared task for Chinese semantic similarity, where the authors translated the WordSim353 dataset.", "startOffset": 131, "endOffset": 135}, {"referenceID": 16, "context": "Gurevych translated the RG and MC datasets into German [15]; Hassan and Mihalcea translated them into Spanish, Arabic and Romanian [16]; Postma and Vossen [17] translated the datasets into Dutch; Jin and Wu [18] presented a shared task for Chinese semantic similarity, where the authors translated the WordSim353 dataset.", "startOffset": 155, "endOffset": 159}, {"referenceID": 17, "context": "Gurevych translated the RG and MC datasets into German [15]; Hassan and Mihalcea translated them into Spanish, Arabic and Romanian [16]; Postma and Vossen [17] translated the datasets into Dutch; Jin and Wu [18] presented a shared task for Chinese semantic similarity, where the authors translated the WordSim353 dataset.", "startOffset": 207, "endOffset": 211}, {"referenceID": 18, "context": "Yang and Powers [19] proposed a dataset specifically for measuring verb similarity, which was later translated into German by Meyer and Gurevych [20].", "startOffset": 16, "endOffset": 20}, {"referenceID": 19, "context": "Yang and Powers [19] proposed a dataset specifically for measuring verb similarity, which was later translated into German by Meyer and Gurevych [20].", "startOffset": 145, "endOffset": 149}, {"referenceID": 15, "context": "Hassan and Mihalcea [16] and Postma and Vossen [17] used three stages to translation pairs: (1) disambiguation of the English word forms; (2) translation for each word; (3) ensuring that translations are in the same class of relative frequency as the English source word.", "startOffset": 20, "endOffset": 24}, {"referenceID": 16, "context": "Hassan and Mihalcea [16] and Postma and Vossen [17] used three stages to translation pairs: (1) disambiguation of the English word forms; (2) translation for each word; (3) ensuring that translations are in the same class of relative frequency as the English source word.", "startOffset": 47, "endOffset": 51}, {"referenceID": 20, "context": "[21], focusing specifically on similarity and not relatedness.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "The creators of the MEN dataset [22] went even further, annotating via crowdsourcing 3 000 word pairs sampled from the ukWaC corpus [23].", "startOffset": 32, "endOffset": 36}, {"referenceID": 22, "context": "The creators of the MEN dataset [22] went even further, annotating via crowdsourcing 3 000 word pairs sampled from the ukWaC corpus [23].", "startOffset": 132, "endOffset": 136}, {"referenceID": 23, "context": "A comprehensive list of datasets for evaluation of English semantic relatedness, featuring 12 collections, was gathered by Faruqui and Dyer [24].", "startOffset": 140, "endOffset": 144}, {"referenceID": 24, "context": "Baroni and Lenci [25] stressed that semantically related words differ in the type of relation between them, so they generated the BLESS dataset containing tuples of the form (wj , wj , type).", "startOffset": 17, "endOffset": 21}, {"referenceID": 25, "context": "Van de Cruys [26] used Dutch WordNet to evaluate distributional similarity measures.", "startOffset": 13, "endOffset": 17}, {"referenceID": 26, "context": "Biemann and Riedl [27] follow a similar approach based on the English WordNet to assess quality of their distributional semantics framework.", "startOffset": 18, "endOffset": 22}, {"referenceID": 27, "context": "Finally, Sahlgren [28] evaluated distributional lexical similarity measures comparing them to manually-crafted thesauri, but also associative norms, such as those described in the following section.", "startOffset": 18, "endOffset": 22}, {"referenceID": 28, "context": "Evaluation tasks based on associative relations originally captured attention of psychologists, such as Griffiths and Steyvers [29].", "startOffset": 127, "endOffset": 131}, {"referenceID": 29, "context": "One such task was organized in the framework of the Cogalex workshop [30].", "startOffset": 69, "endOffset": 73}, {"referenceID": 30, "context": "The training and the test datasets were both derived from the Edinburgh Associative Thesaurus (EAT) [31].", "startOffset": 100, "endOffset": 104}, {"referenceID": 31, "context": "The datasets were tested in the framework of the shared task on RUssian Semantic Similarity Evaluation (RUSSE) [32].", "startOffset": 111, "endOffset": 115}, {"referenceID": 13, "context": "The HJ dataset is a union of three widely used benchmarks for English: RG, MC and WordSim353, see [14, 33\u201335, 35, 36] inter", "startOffset": 98, "endOffset": 117}, {"referenceID": 32, "context": "The HJ dataset is a union of three widely used benchmarks for English: RG, MC and WordSim353, see [14, 33\u201335, 35, 36] inter", "startOffset": 98, "endOffset": 117}, {"referenceID": 33, "context": "The HJ dataset is a union of three widely used benchmarks for English: RG, MC and WordSim353, see [14, 33\u201335, 35, 36] inter", "startOffset": 98, "endOffset": 117}, {"referenceID": 34, "context": "The HJ dataset is a union of three widely used benchmarks for English: RG, MC and WordSim353, see [14, 33\u201335, 35, 36] inter", "startOffset": 98, "endOffset": 117}, {"referenceID": 34, "context": "The HJ dataset is a union of three widely used benchmarks for English: RG, MC and WordSim353, see [14, 33\u201335, 35, 36] inter", "startOffset": 98, "endOffset": 117}, {"referenceID": 35, "context": "The HJ dataset is a union of three widely used benchmarks for English: RG, MC and WordSim353, see [14, 33\u201335, 35, 36] inter", "startOffset": 98, "endOffset": 117}, {"referenceID": 0, "context": "The scores included in the HJ dataset are average human ratings scaled to the [0, 1] range.", "startOffset": 78, "endOffset": 84}, {"referenceID": 24, "context": "This dataset follows the structure of the BLESS dataset [25].", "startOffset": 56, "endOffset": 60}, {"referenceID": 36, "context": "Half of these relations are synonyms and hypernyms from the RuThes-lite thesaurus [37] and half of them are unrelated words.", "startOffset": 82, "endOffset": 86}, {"referenceID": 31, "context": "[32].", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "See Table 4 and [32] for examples.", "startOffset": 16, "endOffset": 20}, {"referenceID": 37, "context": "In order to build the distributional thesaurus, we used the Skip-gram model [38] trained on a 12.", "startOffset": 76, "endOffset": 80}, {"referenceID": 31, "context": "According to the results of the shared task on Russian semantic relatedness [32,39], this approach scored in the top 5 among 105 submissions, obtaining different ranks depending on the evaluation dataset.", "startOffset": 76, "endOffset": 83}, {"referenceID": 38, "context": "According to the results of the shared task on Russian semantic relatedness [32,39], this approach scored in the top 5 among 105 submissions, obtaining different ranks depending on the evaluation dataset.", "startOffset": 76, "endOffset": 83}, {"referenceID": 39, "context": "[40] who used extra linguistic resources, such as dictionaries.", "startOffset": 0, "endOffset": 4}, {"referenceID": 38, "context": "Following our prior experiments [39], we selected the following parameters of the model: minimal word frequency \u2013 5, number of dimensions in a word vector \u2013 500, three or five iterations of the learning algorithm over the input corpus, context window size of 1, 2, 3, 5, 7 and 10 words.", "startOffset": 32, "endOffset": 36}, {"referenceID": 40, "context": "In addition to the raw tokens we provide a lemmatized version based on the PyMorphy2 morphological analyzer [41].", "startOffset": 108, "endOffset": 112}, {"referenceID": 41, "context": "11 In this experiment, we used an open source crowdsourcing engine [42].", "startOffset": 67, "endOffset": 71}, {"referenceID": 39, "context": "5-rt-3 [40] \u2013 0.", "startOffset": 7, "endOffset": 11}, {"referenceID": 31, "context": "975 \u2013 \u2013 \u2013 \u2013 9-ae-9 [32] \u2013 0.", "startOffset": 19, "endOffset": 23}, {"referenceID": 31, "context": "952 \u2013 \u2013 \u2013 \u2013 9-ae-6 [32] \u2013 0.", "startOffset": 19, "endOffset": 23}, {"referenceID": 31, "context": "965 \u2013 \u2013 \u2013 \u2013 17-rt-1 [32] \u2013 0.", "startOffset": 20, "endOffset": 24}], "year": 2017, "abstractText": "Semantic relatedness of terms represents similarity of meaning by a numerical score. On the one hand, humans easily make judgements about semantic relatedness. On the other hand, this kind of information is useful in language processing systems. While semantic relatedness has been extensively studied for English using numerous language resources, such as associative norms, human judgements and datasets generated from lexical databases, no evaluation resources of this kind have been available for Russian to date. Our contribution addresses this problem. We present five language resources of different scale and purpose for Russian semantic relatedness, each being a list of triples (wordi,wordj , similarityij). Four of them are designed for evaluation of systems for computing semantic relatedness, complementing each other in terms of the semantic relation type they represent. These benchmarks were used to organise a shared task on Russian semantic relatedness, which attracted 19 teams. We use one of the best approaches identified in this competition to generate the fifth high-coverage resource, the first open distributional thesaurus of Russian. Multiple evaluations of this thesaurus, including a large-scale crowdsourcing study involving native speakers, indicate its high accuracy.", "creator": "LaTeX with hyperref package"}}}