{"id": "1709.00029", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Aug-2017", "title": "EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification", "abstract": "In this paper, we address the challenge of land use and land cover classification using remote sensing satellite images. For this challenging task, we use the openly and freely accessible Sentinel-2 satellite images provided within the scope of the Earth observation program Copernicus. The key contributions are as follows. We present a novel dataset based on satellite images covering 13 different spectral bands and consisting of 10 classes with in total 27,000 labeled images. We evaluate state-of-the-art deep Convolutional Neural Network (CNNs) on this novel dataset with its different spectral bands. We also evaluate deep CNNs on existing remote sensing datasets and compare the obtained results. With the proposed novel dataset, we achieved an overall classification accuracy of 98.57%. The classification system resulting from the proposed research opens a gate towards a number of Earth observation applications. We demonstrate how the classification system can be used for detecting land use or land cover changes and how it can assist in improving geographical maps.", "histories": [["v1", "Thu, 31 Aug 2017 18:19:10 GMT  (6256kb,D)", "http://arxiv.org/abs/1709.00029v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["patrick helber", "benjamin bischke", "reas dengel", "damian borth"], "accepted": false, "id": "1709.00029"}, "pdf": {"name": "1709.00029.pdf", "metadata": {"source": "CRF", "title": "EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification", "authors": ["Patrick Helber", "Benjamin Bischke", "Andreas Dengel", "Damian Borth"], "emails": ["Damian.Borth}@dfki.de"], "sections": [{"heading": null, "text": "Keywords Remote sensing, Earth observation, satellite images, satellite image classification, land use classification, land cover classification, dataset, machine learning, deep learning, Deep Convolutional Neural Network"}, {"heading": "1. INTRODUCTION", "text": "We are currently on the verge of public and continuous access to satellite imaging data for Earth observation. Government programs such as ESA's Copernicus and NASA's Landsat are making significant efforts to make such data freely available for commercial and non-commercial purposes, with the intention of fostering innovation and entrepreneurship. Access to such data must lead to applications in the fields of agriculture, disaster management, climate change, urban development or environmental monitoring. In order to make full use of the data for the aforementioned domains, initial satellite imagery must be processed and transformed into structured semantics. One such basic semantics is land use and land coverage classification [1, 3, 5]. The goal of land use and land coverage classification is to automatically provide labels that describe the physical land type or the way a land area is used (e.g. residential, industrial)."}, {"heading": "2. RELATED WORK", "text": "In this section we give an overview of previous research results in the field of land use and land coverage classification. In this context, we present data sets consisting of aerial photographs as well as data sets consisting of satellite images. Furthermore, we present current methods of land use and land coverage classification."}, {"heading": "2.1 Classification Datasets", "text": "The progress of the classification in the field of remote sensing has been hampered mainly by the lack of reliable, ground-level data sets. [29] The data set consists of 21 land use and land cover classes. Each class has 100 images and the pixels contained therein with a spatial resolution of about 30 cm per pixel. All images are embedded in the RGB color space and have been covered by the land use classes. [29] The class has 100 images and the included pixels with a spatial resolution of about 30 cm per pixel."}, {"heading": "2.2 Land Use and Land Cover Classification", "text": "While CNNs are an established classification method [13], primarily with impressive results on the challenges of image classification [12, 21, 23], deep CNNs have become a common and popular image classification method. In image classification by remote sensing, various methods of feature extraction and classification (e.g. Random Forest) were evaluated on the introduced datasets. Yang et al. evaluated bag words and spatial expansion approaches on the UCM dataset [29]. Basu et al. examined deep belief networks, basic CNNs and stacked denoizing autoencoders on the SAT6 dataset [1]. Basu et al. also provided a separate framework for the land coverage classes introduced in the SAT-6 dataset, which extracted functions from input images, normalized the extracted characteristics and used the normalized characteristics as input for a deep belief network."}, {"heading": "3. DATASET ACQUISITION", "text": "This year it is as far as it has ever been until the next round."}, {"heading": "3.1 Satellite Image Acquisition", "text": "We downloaded satellite images taken by the Sentinel-2A satellite over Amazon S38. We selected satellite images associated with the cities in the European City Atlas 9. Covered cities are spread across the following 30 countries: Austria, Belgium, Bulgaria, Cyprus, Czech Republic, Denmark, Estonia, Finland, France, Germany, Greece, Hungary, Iceland, Ireland, Italy, Latvia, Lithuania, Luxembourg, Malta, Netherlands, Norway, Poland, Portugal, Romania, Slovakia, Slovenia, Spain, Sweden, Switzerland and the United Kingdom. To increase the chance of obtaining valuable fields of view, we chose low-cloud satellite images. In addition to the ability to create a cloud mask, ESA offers a cloud value for each satellite image, which provides a quick solution to select images with a small percentage of clouds covering the landscape scene. Our goal was to include as many countries as possible to cover the high-class variety of variants."}, {"heading": "3.2 Dataset Creation", "text": "The amount of satellite data available is enormous (the two-satellite constellation offers about 1.6TB). Unfortunately, even this amount of data is limited due to the lack of ground reference values. We have achieved the observation that existing benchmark datasets are not sufficient for the intended applications with Sentinel-2 satellite images, and the goal of making this open and free satellite data available for various Earth observation applications with a labeled dataset. The dataset consists of 10 different classes of 3000 images per class. In total, the dataset has 64 x 64 pixels."}, {"heading": "4. DATASET BENCHMARKING", "text": "As shown in previous work [6, 15, 17, 19], deep CNNs have shown that they surpass all previous approaches to classifying land use and land cover. Accordingly, we are using the state-of-the-art deep CNN models GoogleNet [25] and ResNet-50 [9, 10] to classify the introduced datasets. These networks developed through innovations such as the foundation module [25, 26, 24, 14] and the residual unit [9, 10]. For the proposed EuroSAT dataset, we are also examining the performance of the 13 spectral bands in terms of the classification task. In this context, the classification performance is evaluated on the basis of single tape images and images based on common band combinations."}, {"heading": "4.1 Comparative Evaluation", "text": "In order to train and evaluate deep CNNs on the proposed new and established existing datasets, we divided the data for each dataset into an 80: 20 training and test set. We made sure that the split was applied in class. While the red, green and blue bands are covered by almost all aerial or satellite classification datasets, the proposed EuroSAT dataset consists of 13 spectral bands. For the comparative evaluation, we calculated images in the RGB color space by combining the bands red (B04), green (B03) and blue (B02). For the respective dataset, we used GoogLeNet and ResNet 50 CNN models that were pre-trained on the ILSVRC 2012 dataset for image classification. [21] In all evaluations, we first trained the last shift with a learning rate of 0.01. Then we refined the entire network with a low learning rate between 0.0001 and 0.0001 percent."}, {"heading": "4.2 Band Evaluation", "text": "To investigate the performance of deep CNNs using single-band images as well as the usual combinations of short-wave infrared and color-infrared bands, we used the pre-formed ResNet-50 with a fixed training test split to compare the performance of the different spectral bands. To evaluate single-band images, we used images consisting of information from a single spectral band. We examined all spectral bands, including bands not intended for land surveillance. Interestingly, bands with a lower spatial resolution were extrapolated to 10 meters per pixel using cubic spline interpolation [8]. Figure 9 shows a comparison of the performance of the spectral band, showing that the red, green and blue bands outperform all other bands. Interestingly, the bands with a lower spatial resolution are red rim 1 (B05) and the short-wave infrared 2 (B12) with an original spatial resolution of just 20 meters per pixel, the color combinations of the two infrared bands we examined in the 10 GB resolution are below."}, {"heading": "5. APPLICATIONS", "text": "The open and freely accessible satellite images offer a wide range of applications. In this section, we show that the novel data set published with this paper goes beyond purely scientific classification, but also has implications for real-world applications. The classification result, with an overall accuracy of 98.57%, paves the way for these applications. We show applications in the field of land use and detection of changes in land cover, as well as how the proposed research can help keep geographical maps up to date."}, {"heading": "5.1 Land Use and Land Cover Change Detection", "text": "Since the two-satellite constellation will scan the Earth's land surface for about the next decade in a repetitive cycle of five days, a trained classifier can be used to monitor the land surface and detect changes in land use or land cover. To demonstrate land use and detection of changes in land cover, we selected images from the same spatial region, but from different times. With the trained classifier, we examined 64x64 image regions. A change occurred when the classifier provided different classification results in fields recorded from the same spatial region 64x64. Below, we show three examples of spotted changes. In the first example shown in Figure 10, the classifier recognized that the land had changed in the marked area. The left image was taken in December 2015 near Shanghai, China, showing an area classified as industrial. The right image was acquired in December 2016 and shows that the same industrial area was destroyed in December 2016."}, {"heading": "5.2 Assistance in Mapping", "text": "While a 64 x 64 field classification system does not allow for finely graded segmentation or mapping, it can not only detect changes, as shown in the previous examples, but also facilitate the updating of maps, which is extremely helpful for crowd-sourced maps such as OpenStreetMap (OSM); a possible system could verify already marked areas, identify mispositioned areas, or make large-scale markings; as shown in Figure 13, the industrial areas shown on the current satellite image on the left are almost completely covered in the corresponding OSM mapping; the current satellite image on the right also shows industrial areas; however, much of the industrial areas in the map is not covered; and due to the high temporal availability of Sentinel-2 satellite images in the future, the proposed research can be used with the published dataset to create systems that help keep maps up-to-date."}, {"heading": "6. CONCLUSIONS", "text": "To obtain this dataset, we used the open and freely available Sentinel-2 images provided by the Copernicus Earth Observation Program. The proposed dataset consists of 10 classes covering 13 different spectral bands with a total of 27,000 marked images. We evaluated state-of-the-art deep CNNs on this novel dataset. We also evaluated deep CNNs on existing remote sensing datasets and compared the results obtained. For the novel dataset, we examined performance on the basis of different spectral bands. As a result of this evaluation, the RGB band combination exceeded all single-band images as well as the shortwave infrared and color-infrared band combination of the map with an overall classification accuracy of 98.57%. For the existing datasets, we achieved an improvement in the technical surfaces and exceeded the results of extensive satellite research."}, {"heading": "7. ACKNOWLEDGMENTS", "text": "This work was partly funded by the BMBF project Multimedia Opinion Mining (MOM: 01WI15002). The authors thank NVIDIA for its support within the framework of the NVIDIA AI Lab program."}, {"heading": "8. REFERENCES", "text": "[1] S. Basu, S. Ganguly, S. Mukhopadhyay, R. DiBiano, M. Karki, and R. Nemani. Deepsat: a learning framework for satellite imagery. In Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems, page 37. ACM, 2015. [2] B. Bischke, P. Bhardwaj, A. Gautam, P. Helber, D. Borth, and A. Dengel. Contextual Enrichment of Remote-Sensed Events in Social Multimedia and Satellite Imagery using Deep Neural Networks. In MediaEval, 2017."}], "references": [{"title": "Deepsat: a learning framework for satellite imagery", "author": ["S. Basu", "S. Ganguly", "S. Mukhopadhyay", "R. DiBiano", "M. Karki", "R. Nemani"], "venue": "Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems, page 37. ACM,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Detection of Flooding Events in Social Multimedia and Satellite Imagery using Deep Neural Networks", "author": ["B. Bischke", "P. Bhardwaj", "A. Gautam", "P. Helber", "D. Borth", "A. Dengel"], "venue": "MediaEval,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2017}, {"title": "Contextual Enrichment of Remote-Sensed Events with Social Media Streams", "author": ["B. Bischke", "D. Borth", "C. Schulze", "A. Dengel"], "venue": "Proceedings of the 2016 ACM on Multimedia Conference, pages 1077\u20131081. ACM,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Multi-Task Learning for Segmentation of Buildings Footprints with Deep Neural Networks", "author": ["B. Bischke", "P. Helber", "J. Folz", "D. Borth", "A. Dengel"], "venue": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2018}, {"title": "The Multimedia Satellite Task: Emergency Response for Flooding Events", "author": ["B. Bischke", "P. Helber", "C. Schulze", "V. Srinivasan", "D. Borth"], "venue": "MediaEval,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2017}, {"title": "Land use classification in remote sensing  images by convolutional neural networks", "author": ["M. Castelluccio", "G. Poggi", "C. Sansone", "L. Verdoliva"], "venue": "arXiv preprint arXiv:1508.00092,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Remote sensing image scene classification: Benchmark and state of the art", "author": ["G. Cheng", "J. Han", "X. Lu"], "venue": "Proceedings of the IEEE,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2017}, {"title": "A practical guide to splines, volume 27", "author": ["C. De Boor", "C. De Boor", "E.-U. Math\u00e9maticien", "C. De Boor", "C. De Boor"], "venue": "Springer-Verlag New York,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1978}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770\u2013778,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Identity mappings in deep residual networks", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "European Conference on Computer Vision, pages 630\u2013645. Springer,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Semantic segmentation of small objects and modeling of uncertainty in urban remote sensing images using deep convolutional neural networks", "author": ["M. Kampffmeyer", "A.-B. Salberg", "R. Jenssen"], "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, June", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, pages 1097\u20131105,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Neural computation, 1(4):541\u2013551,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1989}, {"title": "Network in network", "author": ["M. Lin", "Q. Chen", "S. Yan"], "venue": "arXiv preprint arXiv:1312.4400,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Multiview deep learning for land-use classification", "author": ["F.P. Luus", "B.P. Salmon", "F. van den Bergh", "B. Maharaj"], "venue": "IEEE Geoscience and Remote Sensing Letters,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Satellite imagery classification based on deep convolution network", "author": ["Z. Ma", "Z. Wang", "C. Liu", "X. Liu"], "venue": " World Academy of Science, Engineering and Technology, International Journal of Computer, Electrical, Automation, Control and Information Engineering, 10(6):1113\u20131117,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep learning earth observation classification using imagenet pretrained networks", "author": ["D. Marmanis", "M. Datcu", "T. Esch", "U. Stilla"], "venue": "IEEE Geoscience and Remote Sensing Letters, 13(1):105\u2013109,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Large-scale deep learning on the yfcc100m dataset", "author": ["K. Ni", "R. Pearce", "K. Boakye", "B. Van Essen", "D. Borth", "B. Chen", "E. Wang"], "venue": "arXiv preprint arXiv:1502.03409,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Towards better exploiting convolutional neural networks for remote sensing scene classification", "author": ["K. Nogueira", "O.A. Penatti", "J.A. dos Santos"], "venue": "Pattern Recognition,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2017}, {"title": "Do deep features generalize from everyday objects to remote sensing and aerial scenes domains", "author": ["O.A. Penatti", "K. Nogueira", "J.A. dos Santos"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "ImageNet Large Scale Visual Recognition Challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein", "A.C. Berg", "L. Fei-Fei"], "venue": "International Journal of Computer Vision (IJCV), 115(3):211\u2013252,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "High-resolution satellite scene classification using a sparse coding based multiple feature combination", "author": ["G. Sheng", "W. Yang", "T. Xu", "H. Sun"], "venue": "International journal of remote sensing, 33(8):2395\u20132412,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Inception-v4, inception-resnet and the impact of residual connections on learning", "author": ["C. Szegedy", "S. Ioffe", "V. Vanhoucke", "A. Alemi"], "venue": "arXiv preprint arXiv:1602.07261,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1\u20139,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Rethinking the inception architecture for computer vision", "author": ["C. Szegedy", "V. Vanhoucke", "S. Ioffe", "J. Shlens", "Z. Wojna"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2818\u20132826,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2016}, {"title": "Aid: A benchmark dataset for performance evaluation of aerial scene classification", "author": ["G.-S. Xia", "J. Hu", "F. Hu", "B. Shi", "X. Bai", "Y. Zhong", "L. Zhang"], "venue": "arXiv preprint arXiv:1608.05167,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2016}, {"title": "Structural high-resolution satellite image indexing", "author": ["G.-S. Xia", "W. Yang", "J. Delon", "Y. Gousseau", "H. Sun", "H. M\u00e2\u0131tre"], "venue": "ISPRS TC VII Symposium-100 Years ISPRS, volume 38, pages 298\u2013303,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Bag-of-visual-words and spatial extensions for land-use classification", "author": ["Y. Yang", "S. Newsam"], "venue": "Proceedings of the 18th SIGSPATIAL international conference on advances in geographic information  systems, pages 270\u2013279. ACM,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Feature significance-based multibag-of-visual-words model for remote sensing image scene classification", "author": ["L. Zhao", "P. Tang", "L. Huo"], "venue": "Journal of Applied Remote Sensing, 10(3):035004\u2013035004,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 1, "context": "With access to such data, applications in the domains of agriculture, disaster recovery, climate change, urban development, or environmental monitoring can be realized [2, 3, 5].", "startOffset": 168, "endOffset": 177}, {"referenceID": 2, "context": "With access to such data, applications in the domains of agriculture, disaster recovery, climate change, urban development, or environmental monitoring can be realized [2, 3, 5].", "startOffset": 168, "endOffset": 177}, {"referenceID": 4, "context": "With access to such data, applications in the domains of agriculture, disaster recovery, climate change, urban development, or environmental monitoring can be realized [2, 3, 5].", "startOffset": 168, "endOffset": 177}, {"referenceID": 0, "context": "One type of such fundamental semantics is Land Use and Land Cover Classification [1, 29].", "startOffset": 81, "endOffset": 88}, {"referenceID": 28, "context": "One type of such fundamental semantics is Land Use and Land Cover Classification [1, 29].", "startOffset": 81, "endOffset": 88}, {"referenceID": 20, "context": "of high-quality datasets with a suitable set of classes [21].", "startOffset": 56, "endOffset": 60}, {"referenceID": 11, "context": "In particular when considering the recent success of deep Convolutional Neural Networks (CNN) [12], it is crucial to have large quantities of training data available to train such a network.", "startOffset": 94, "endOffset": 98}, {"referenceID": 17, "context": "lished EuroSAT dataset, which can be used similar to [18] as a basis for large-scale training of deep learning networks for satellite images.", "startOffset": 53, "endOffset": 57}, {"referenceID": 5, "context": "A popular and intensively researched [6, 19, 20, 27, 29] remote sensing image classification dataset known as UC Merced Land Use Dataset (UCM) was introduced by Yang et al.", "startOffset": 37, "endOffset": 56}, {"referenceID": 18, "context": "A popular and intensively researched [6, 19, 20, 27, 29] remote sensing image classification dataset known as UC Merced Land Use Dataset (UCM) was introduced by Yang et al.", "startOffset": 37, "endOffset": 56}, {"referenceID": 19, "context": "A popular and intensively researched [6, 19, 20, 27, 29] remote sensing image classification dataset known as UC Merced Land Use Dataset (UCM) was introduced by Yang et al.", "startOffset": 37, "endOffset": 56}, {"referenceID": 26, "context": "A popular and intensively researched [6, 19, 20, 27, 29] remote sensing image classification dataset known as UC Merced Land Use Dataset (UCM) was introduced by Yang et al.", "startOffset": 37, "endOffset": 56}, {"referenceID": 28, "context": "A popular and intensively researched [6, 19, 20, 27, 29] remote sensing image classification dataset known as UC Merced Land Use Dataset (UCM) was introduced by Yang et al.", "startOffset": 37, "endOffset": 56}, {"referenceID": 28, "context": "[29].", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Trying to enhance the dataset situation, various researchers used non-freely usable Google Earth images to manually create novel datasets [22, 27, 28, 30].", "startOffset": 138, "endOffset": 154}, {"referenceID": 26, "context": "Trying to enhance the dataset situation, various researchers used non-freely usable Google Earth images to manually create novel datasets [22, 27, 28, 30].", "startOffset": 138, "endOffset": 154}, {"referenceID": 27, "context": "Trying to enhance the dataset situation, various researchers used non-freely usable Google Earth images to manually create novel datasets [22, 27, 28, 30].", "startOffset": 138, "endOffset": 154}, {"referenceID": 29, "context": "Trying to enhance the dataset situation, various researchers used non-freely usable Google Earth images to manually create novel datasets [22, 27, 28, 30].", "startOffset": 138, "endOffset": 154}, {"referenceID": 19, "context": "[20] and Basu et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 19, "context": "Based on these images, [20] introduced the Brazillian Coffee Scene dataset (BCS).", "startOffset": 23, "endOffset": 27}, {"referenceID": 0, "context": "[1] introduced the SAT-6 dataset relying on aerial images.", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "While CNNs are an established classification method [13], primarily with the impressive results on image classification challenges [12, 21, 23], deep CNNs became a common and popular image classification method.", "startOffset": 52, "endOffset": 56}, {"referenceID": 11, "context": "While CNNs are an established classification method [13], primarily with the impressive results on image classification challenges [12, 21, 23], deep CNNs became a common and popular image classification method.", "startOffset": 131, "endOffset": 143}, {"referenceID": 20, "context": "While CNNs are an established classification method [13], primarily with the impressive results on image classification challenges [12, 21, 23], deep CNNs became a common and popular image classification method.", "startOffset": 131, "endOffset": 143}, {"referenceID": 22, "context": "While CNNs are an established classification method [13], primarily with the impressive results on image classification challenges [12, 21, 23], deep CNNs became a common and popular image classification method.", "startOffset": 131, "endOffset": 143}, {"referenceID": 28, "context": "evaluated bag-ofvisual-words and spatial extension approaches on the UCM dataset [29].", "startOffset": 81, "endOffset": 85}, {"referenceID": 0, "context": "investigated deep belief networks, basic CNNs and stacked denoising autoencoders on the SAT6 dataset [1].", "startOffset": 101, "endOffset": 104}, {"referenceID": 19, "context": "evaluated deep CNNs on the UCM and BCS dataset [20].", "startOffset": 47, "endOffset": 51}, {"referenceID": 5, "context": "In the context of deep learning, the used deep CNNs have been trained from scratch or fine-tuned by using a pretrained network [6, 19, 7, 16].", "startOffset": 127, "endOffset": 141}, {"referenceID": 18, "context": "In the context of deep learning, the used deep CNNs have been trained from scratch or fine-tuned by using a pretrained network [6, 19, 7, 16].", "startOffset": 127, "endOffset": 141}, {"referenceID": 6, "context": "In the context of deep learning, the used deep CNNs have been trained from scratch or fine-tuned by using a pretrained network [6, 19, 7, 16].", "startOffset": 127, "endOffset": 141}, {"referenceID": 15, "context": "In the context of deep learning, the used deep CNNs have been trained from scratch or fine-tuned by using a pretrained network [6, 19, 7, 16].", "startOffset": 127, "endOffset": 141}, {"referenceID": 20, "context": "Mainly, the networks were pretrained on the dataset from the ILSVRC-2012 image classification challenge [21].", "startOffset": 104, "endOffset": 108}, {"referenceID": 16, "context": "However, the features generalized well and therefore these pretrained networks proved to be suitable for remote sensing image classification [17].", "startOffset": 141, "endOffset": 145}, {"referenceID": 5, "context": "The examined works show that deep CNNs outperform all previous state-of-the-art approaches on the introduced datasets [6, 17, 15, 27].", "startOffset": 118, "endOffset": 133}, {"referenceID": 16, "context": "The examined works show that deep CNNs outperform all previous state-of-the-art approaches on the introduced datasets [6, 17, 15, 27].", "startOffset": 118, "endOffset": 133}, {"referenceID": 14, "context": "The examined works show that deep CNNs outperform all previous state-of-the-art approaches on the introduced datasets [6, 17, 15, 27].", "startOffset": 118, "endOffset": 133}, {"referenceID": 26, "context": "The examined works show that deep CNNs outperform all previous state-of-the-art approaches on the introduced datasets [6, 17, 15, 27].", "startOffset": 118, "endOffset": 133}, {"referenceID": 0, "context": ", NAIP used in [1]).", "startOffset": 15, "endOffset": 18}, {"referenceID": 20, "context": "Both CNNs have been pretrained on the image classification dataset ILSVRC-2012 [21].", "startOffset": 79, "endOffset": 83}, {"referenceID": 5, "context": "As shown in previous work [6, 15, 17, 19], deep CNNs have demonstrated to outperform all previous approaches on land use and land cover classification datasets.", "startOffset": 26, "endOffset": 41}, {"referenceID": 14, "context": "As shown in previous work [6, 15, 17, 19], deep CNNs have demonstrated to outperform all previous approaches on land use and land cover classification datasets.", "startOffset": 26, "endOffset": 41}, {"referenceID": 16, "context": "As shown in previous work [6, 15, 17, 19], deep CNNs have demonstrated to outperform all previous approaches on land use and land cover classification datasets.", "startOffset": 26, "endOffset": 41}, {"referenceID": 18, "context": "As shown in previous work [6, 15, 17, 19], deep CNNs have demonstrated to outperform all previous approaches on land use and land cover classification datasets.", "startOffset": 26, "endOffset": 41}, {"referenceID": 24, "context": "Accordingly, we use the state-of-the-art deep CNN models GoogleNet [25] and ResNet-50 [9, 10] for the classification of the introduced datasets.", "startOffset": 67, "endOffset": 71}, {"referenceID": 8, "context": "Accordingly, we use the state-of-the-art deep CNN models GoogleNet [25] and ResNet-50 [9, 10] for the classification of the introduced datasets.", "startOffset": 86, "endOffset": 93}, {"referenceID": 9, "context": "Accordingly, we use the state-of-the-art deep CNN models GoogleNet [25] and ResNet-50 [9, 10] for the classification of the introduced datasets.", "startOffset": 86, "endOffset": 93}, {"referenceID": 24, "context": "These networks evolved by innovations such as the inception module [25, 26, 24, 14] and the residual unit [9, 10].", "startOffset": 67, "endOffset": 83}, {"referenceID": 25, "context": "These networks evolved by innovations such as the inception module [25, 26, 24, 14] and the residual unit [9, 10].", "startOffset": 67, "endOffset": 83}, {"referenceID": 23, "context": "These networks evolved by innovations such as the inception module [25, 26, 24, 14] and the residual unit [9, 10].", "startOffset": 67, "endOffset": 83}, {"referenceID": 13, "context": "These networks evolved by innovations such as the inception module [25, 26, 24, 14] and the residual unit [9, 10].", "startOffset": 67, "endOffset": 83}, {"referenceID": 8, "context": "These networks evolved by innovations such as the inception module [25, 26, 24, 14] and the residual unit [9, 10].", "startOffset": 106, "endOffset": 113}, {"referenceID": 9, "context": "These networks evolved by innovations such as the inception module [25, 26, 24, 14] and the residual unit [9, 10].", "startOffset": 106, "endOffset": 113}, {"referenceID": 20, "context": "[21].", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "The deep CNNs achieve state-of-the-art results on the UCM dataset and outperform previous results on the other three presented datasets by about 2-4% (AID, SAT-6, BCS) [6, 19, 22].", "startOffset": 168, "endOffset": 179}, {"referenceID": 18, "context": "The deep CNNs achieve state-of-the-art results on the UCM dataset and outperform previous results on the other three presented datasets by about 2-4% (AID, SAT-6, BCS) [6, 19, 22].", "startOffset": 168, "endOffset": 179}, {"referenceID": 21, "context": "The deep CNNs achieve state-of-the-art results on the UCM dataset and outperform previous results on the other three presented datasets by about 2-4% (AID, SAT-6, BCS) [6, 19, 22].", "startOffset": 168, "endOffset": 179}, {"referenceID": 7, "context": "Bands with a lower spatial resolution have been upsampled to 10 meters per pixel using cubic-spline interpolation [8].", "startOffset": 114, "endOffset": 117}, {"referenceID": 3, "context": "A detailed analysis of the respective land area can then be provided using highresolution satellite images and an advanced segmentation approach [4, 11].", "startOffset": 145, "endOffset": 152}, {"referenceID": 10, "context": "A detailed analysis of the respective land area can then be provided using highresolution satellite images and an advanced segmentation approach [4, 11].", "startOffset": 145, "endOffset": 152}], "year": 2017, "abstractText": "In this paper, we address the challenge of land use and land cover classification using remote sensing satellite images. For this challenging task, we use the openly and freely accessible Sentinel-2 satellite images provided within the scope of the Earth observation program Copernicus. The key contributions are as follows. We present a novel dataset based on satellite images covering 13 different spectral bands and consisting of 10 classes with in total 27,000 labeled images. We evaluate state-of-the-art deep Convolutional Neural Network (CNNs) on this novel dataset with its different spectral bands. We also evaluate deep CNNs on existing remote sensing datasets and compare the obtained results. With the proposed novel dataset, we achieved an overall classification accuracy of 98.57%. The classification system resulting from the proposed research opens a gate towards a number of Earth observation applications. We demonstrate how the classification system can be used for detecting land use or land cover changes and how it can assist in improving geographical maps.", "creator": "LaTeX with hyperref package"}}}