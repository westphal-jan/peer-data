{"id": "1709.00300", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Sep-2017", "title": "Telepath: Understanding Users from a Human Vision Perspective in Large-Scale Recommender Systems", "abstract": "Designing an e-commerce recommender system that serves hundreds of millions of active users is a daunting challenge. Ranking strategy as the key module needs to be more carefully designed. We find two key factors that affect users' behaviors: attractive item content and compatibility with users' interests. To extract these factors, a ranking model needs to understand users from a human vision perspective. This paper proposes Telepath, a vision-based architecture that simulates the human vision system to extract the key visual signals that attract users to a displayed item and generate vision activations and simulates cerebral cortex to understand users' interest based on the captured activations from browsed items. Telepath is a combination of CNN, RNN and DNN. In practice, the Telepath model has been launched to JD's online recommender system and advertising system. For one of the major item recommendation blocks on the JD app, CTR, GMV and orders have increased 1.59%, 8.16% and 8.71% respectively. For several major advertising publishers of JD DSP, CTR, GMV and ROI have increased 6.58%, 61.72% and 65.57% respectively by the first launch, and further increased 2.95%, 41.75% and 41.37% respectively by the second launch.", "histories": [["v1", "Fri, 1 Sep 2017 13:29:36 GMT  (1901kb)", "http://arxiv.org/abs/1709.00300v1", "8 pages, 11 figures, 1 table"], ["v2", "Mon, 4 Sep 2017 16:06:57 GMT  (1901kb)", "http://arxiv.org/abs/1709.00300v2", "8 pages, 11 figures, 1 table"]], "COMMENTS": "8 pages, 11 figures, 1 table", "reviews": [], "SUBJECTS": "cs.IR cs.CV cs.LG", "authors": ["yu wang", "jixing xu", "aohan wu", "mantian li", "yang he", "jinghe hu", "weipeng p yan"], "accepted": false, "id": "1709.00300"}, "pdf": {"name": "1709.00300.pdf", "metadata": {"source": "CRF", "title": "Telepath: Understanding Users from a Human Vision Perspective in Large-Scale Recommender Systems", "authors": ["Yu Wang", "Jixing Xu", "Aohan Wu", "Mantian Li", "Yang He", "Jinghe Hu", "Weipeng P. Yan"], "emails": ["paul.yan}@jd.com"], "sections": [{"heading": null, "text": "In fact, most people who stand up for people's rights are not aware of themselves and their rights."}, {"heading": "Architecture Design", "text": "JD's referral system is illustrated in Figure 1. There are two key modules: the call module and the ranking module. When a user visits the JD website or app, the recommendation server is triggered and the call module is asked to fetch candidate elements. Then, the ranking module is called to predict a ranking score for each candidate. Finally, the top K elements are selected to be displayed to the user. Ranking is the focus of this work, but telepath can also be used in the call module to trigger other suitable elements. As an extension, we will discuss it in future work. Figure 2 provides a Telepath flowchart that consists of three modules: vision extraction, interest understanding and scoring."}, {"heading": "Input data", "text": "The visual content that the user captures is images and descriptive texts of displayed objects. The images are generally more attractive to the user, so we focus on images in this recycle bin. To speed up the training, we scale each image to a size of 100 x 100. Each scaled image is converted into an RGB 3 channel matrix. Visual content is captured from the user's point of view. However, there are other useful information that can help improve accuracy. One is demographic data such as age, gender, geolocation, user profile tags, etc., which is the previous information about the user. The other is information about the object itself, such as item identification, category ID, category ID, etc. These two category features can help to obtain statistics about users and objects, for example, different preferences between men and women or women (popular and old places)."}, {"heading": "Vision Extraction Module", "text": "The extraction module is designed to simulate the user's vision system in order to extract the key signals that attract the user to the displayed objects, and then generate vision activations that are presented as dense vectors for subsequent processing. Traditional item-to-vector methods have two main deficiencies: the cold-start problem and the limited expressiveness. These methods (Cheng et al. 2016; Covington et al. 2016) point each element to a vector by the common way in which each element is assigned to an initialized density vector and these vectors are then corrected by a certain optimization method, e.g. by stochastic gradient descent. It is undeniable that these methods can obtain high-quality vector representations for high-frequency objects. However, there is a cold-start problem. For low-frequency objects and new objects, it is difficult to get qualitative chances to correct these representations because these objects are not enough."}, {"heading": "Interest Understanding Module", "text": "As mentioned in the introduction, visual signals attract people by generating activations in the cortex, and then these activations are gradually understood and stored by the cortex and eventually form interests. The collected elements are those that have attracted the user in the recent past, which is feedback about the user's potential interest. So, based on the activations captured by the visual content of the collected objects, the interest in understanding the user is able to simulate the cortex in order to understand the user's perspective. To this end, there are two important tasks: understanding the user's interest (i.e. conscious interest and subconscious interest) and extracting the user's personal preferences (i.e. color, pattern, material, etc.) when the most searched objects are red, then we can conclude that the user's purchasing interest is \"rock\" and the color preferences of the subconscious interest. \""}, {"heading": "Scoring Module", "text": "The Scoring Module performs the role of decision-making, which is used to simulate the decision-making functionality of the cerebral cortex to predict the final ranking of an item based on the recorded activations of the displayed candidate, the user's extracted vectors of interest, and the additional prior information about the user and object. An intuitive exploration is the calculation of the matching quality between the user's vectors of interest and the item's sectionalizations. The interest vectors and sectionalizations are both based on the visual content that the user captures, which can be seen as an understanding of the user's perspective. In addition, in a typical e-commerce scenario, active users bring in huge amounts of click log data every day. With this large amount of log data, the Scoring Module can retrieve very useful statistics from indicators and their cross-product transformations."}, {"heading": "Experiments", "text": "In this section, we first discuss visualizing the visualizations of user article and interest vectors, and then discuss some offline experiment results. Finally, we give the online experiment results obtained in two of JD's main recommendation scenarios through A / B. The A / B test platform is similar (Tang et al. 2010).First, we specify some hyperparameter configurations. In the DCNN subnetwork, a drop-out rate of 0.5 is applied in all layers to avoid overmatching, the impulse for the updating gradient is set to 0.9, and the weight drop to 0.0005 for regulation. We use a global learning rate of 0.01 for all layers that are degraded by a factor of 0.1 after each 100K step, with a mini-batch size of 64. Instead of a non-synchronous ensemble training, we use a common training method by using all parts of the gradient in the FT1 output at the same time."}, {"heading": "Visualization", "text": "For our article visualization experiment, we randomly selected six categories: watch, cell phone, down jacket, beach shoes, milk powder and biscuits. For each category, we can randomly select about 10,000 items. Figure 3 shows the visualization of vision activations by t-SNE, in which the dots with the same color correspond to the same category. We can clearly see the shiny property of each category. However, we can also find a crossing area between milk powder and cookies, although they still have clear cluster trends. The reasons we derive are as follows: First, through common training, the telepath model is trained to match the user's clicks, rather than a multi-class classification task. Second, there are many items in e-commerce that belong to different categories, but have similar background colors or textures."}, {"heading": "Offline Experiments", "text": "In the first group, the baseline is the traditional item-to-vector method implemented by Wide & Deep Learning (Cheng et al. 2016) and Telepath uses only vision extraction module and interest-understanding module (i.e. the left part of Figure 2). This group is to validate that the proposed vision extraction is traditional item-to-vector and the proposed interest-understanding is more effective than cross-product transformations of DNN. To this end, the baseline uses only items as features, and Telepath uses only images of items as features. To formulate the better performance of an inverse item-to-vector relationship, we have a better understanding than cross-product transformations of DNN."}, {"heading": "Online Experiments", "text": "The first is the recommendation Block X in the JD app. Block X is very important for JD because it is visited billions of times a day and JD has to stop billions of recommendations accordingly. The second is online advertising at JD DSP's publishers Y. Publisher Y are several of JD's most important partners in the DSP business. The daily recommended ads that JD makes for users that also reach the scale of hundreds of millions of millions of users. The second is online advertising at JD DSP's publishers Y. Publisher Y are several of JD DSP's most important partners in the DSP business. The daily recommended ads that JD makes for users also attract the scale of hundreds of millions of millions of users. For in-store advertising recommendations, we pay more attention to the improvements in CTR, GMV and ROI (GMV / revenue)."}, {"heading": "Future Work", "text": "For the visual content captured by the user, this essay focuses on the images of the objects, but the description text is also an important visual content from which the user can obtain additional information such as size, weight, etc. Therefore, a future goal is to add a text understanding to the text extraction module. In order to simulate that people understand text and extract important text signals, we plan to use a DCNN network similar to Table 1 to process the character level of the one-hot-coded matrix of the text. In addition to the description texts of the displayed objects, we also plan to take into account the historical query texts of the user in order to better understand their interest.The key method in this essay is to understand the user from the perspective of the user. This method can also be applied to the call module. The call module is intended to trigger more candidates that attract the user in order to help the user increase the ranking of the suggested elements in the method."}, {"heading": "Conclusion", "text": "This paper proposes Telepath, a vision-based intelligent ranking paradigm that understands users from the perspective of human vision to address the two key factors above that influence user behavior. Telepath uses a DCNN to simulate the user's visual system, to extract the key signals that attract the user and generate sectivation, and a combination of RNN and DNN to simulate the cerebral cortex to understand and memorize users \"interests and preferences. To the best of our knowledge, such a ranking paradigm has not been proposed in previous work. In practice, Telepath has achieved significant improvements in online recommendations and ad business for JD, demonstrating its ability to better understand users."}], "references": [{"title": "Mastering the game of go with deep neural networks and tree search", "author": ["D. Silver", "A. Huang", "C.J. Maddison", "A. Guez", "L. Sifre", "G. Van Den Driessche", "J. Schrittwieser", "I. Antonoglou", "V. Panneershelvam", "M. Lanctot"], "venue": null, "citeRegEx": "Silver et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Silver et al\\.", "year": 2016}, {"title": "Unconscious transfer of meaning to brands", "author": ["M. Galli", "G. Gorn"], "venue": "Journal of Consumer Psychology 21(3): 215-225.", "citeRegEx": "Galli and Gorn,? 2011", "shortCiteRegEx": "Galli and Gorn", "year": 2011}, {"title": "Making memories: brain activity", "author": ["J.B. Brewer", "Z. Zhao", "J.E. Desmond", "G.H. Glover", "J.D. Gabrieli"], "venue": null, "citeRegEx": "Brewer et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Brewer et al\\.", "year": 1998}, {"title": "Attention during natural vision warps semantic representation across the human brain", "author": ["T. \u00c7ukur", "S. Nishimoto", "A.G. Huth", "J.L. Gallant"], "venue": "Nature neuroscience 16(6): 763-770.", "citeRegEx": "\u00c7ukur et al\\.,? 2013", "shortCiteRegEx": "\u00c7ukur et al\\.", "year": 2013}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "Vanhoucke V", "A. Rabinovich"], "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition, 1-9.", "citeRegEx": "Szegedy et al\\.,? 2015", "shortCiteRegEx": "Szegedy et al\\.", "year": 2015}, {"title": "Rethinking the inception architecture for computer vision", "author": ["C. Szegedy", "V. Vanhoucke", "S. Ioffe", "J. Shlens", "Z. Wojna"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2818-2826.", "citeRegEx": "Szegedy et al\\.,? 2016", "shortCiteRegEx": "Szegedy et al\\.", "year": 2016}, {"title": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning", "author": ["C. Szegedy", "S. Ioffe", "V. Vanhoucke", "A.A. Alemi"], "venue": "AAAI, 4278-4284.", "citeRegEx": "Szegedy et al\\.,? 2017", "shortCiteRegEx": "Szegedy et al\\.", "year": 2017}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Advances in neural information processing systems, 3104-3112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "arXiv preprint arXiv:1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Deep neural networks for youtube recommendations", "author": ["P. Covington", "J. Adams", "E. Sargin"], "venue": "Proceedings of the 10th ACM Conference on Recommender Systems, 191-198.", "citeRegEx": "Covington et al\\.,? 2016", "shortCiteRegEx": "Covington et al\\.", "year": 2016}, {"title": "Factorizing personalized markov chains for next-basket recommendation", "author": ["S. Rendle", "C. Freudenthaler", "L. Schmidt-Thieme"], "venue": "Proceedings of the 19th international conference on World wide web, 811-820.", "citeRegEx": "Rendle et al\\.,? 2010", "shortCiteRegEx": "Rendle et al\\.", "year": 2010}, {"title": "Content-based recommender systems: State of the art and trends", "author": ["P. Lops", "M. De Gemmis", "G. Semeraro"], "venue": "Recommender systems handbook, 73-105.", "citeRegEx": "Lops et al\\.,? 2011", "shortCiteRegEx": "Lops et al\\.", "year": 2011}, {"title": "Learning to rank: from pairwise approach to listwise approach", "author": ["Z. Cao", "T. Qin", "T.Y. Liu", "M.F. Tsai", "H. Li"], "venue": "Proceedings of the 24th international conference on Machine learning, 129-136.", "citeRegEx": "Cao et al\\.,? 2007", "shortCiteRegEx": "Cao et al\\.", "year": 2007}, {"title": "Query-level loss functions for information retrieval", "author": ["T. Qin", "X.D. Zhang", "M.F. Tsai", "D.S. Wang", "T.Y. Liu", "H. Li"], "venue": "Information Processing & Management, 44(2): 838-855.", "citeRegEx": "Qin et al\\.,? 2008", "shortCiteRegEx": "Qin et al\\.", "year": 2008}, {"title": "Learning to rank for information retrieval", "author": ["T.Y. Liu"], "venue": "Foundations and Trends in Information Retrieval, 3(3): 225-331.", "citeRegEx": "Liu,? 2009", "shortCiteRegEx": "Liu", "year": 2009}, {"title": "Personal recommendation using deep recurrent neural networks in NetEase", "author": ["S. Wu", "W. Ren", "C. Yu", "G. Chen", "D. Zhang", "J. Zhu"], "venue": "IEEE, International Conference on Data Engineering, 1218-1229.", "citeRegEx": "Wu et al\\.,? 2016", "shortCiteRegEx": "Wu et al\\.", "year": 2016}, {"title": "Collaborative Recurrent Neural Networks for Dynamic Recommender Systems", "author": ["Y.J. Ko", "L. Maystre", "M. Grossglauser"], "venue": null, "citeRegEx": "Ko et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ko et al\\.", "year": 2016}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "International Conference on Neural Information Processing Systems, 1097-1105.", "citeRegEx": "Krizhevsky et al\\.,? 2012", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Deep Residual Learning for Image Recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "Computer Vision and Pattern Recognition, 770-778.", "citeRegEx": "He et al\\.,? 2016", "shortCiteRegEx": "He et al\\.", "year": 2016}, {"title": "Overlap- ping experiment infrastructure: More, better, faster experimenta-tion", "author": ["D. Tang", "A. Agarwal", "D. O\u2019Brien", "M. Meyer"], "venue": "In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Tang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2010}, {"title": "LADDER: A Human-Level Bidding Agent for Large-Scale Real-Time Online Auctions", "author": ["Y. Wang", "J. Liu", "Y. Liu", "J. Hao", "Y. He", "J. Hu", "W. Yan", "M. Li"], "venue": "arXiv preprint arXiv: 1708.05565.", "citeRegEx": "Wang et al\\.,? 2017", "shortCiteRegEx": "Wang et al\\.", "year": 2017}, {"title": "Effects of subconscious and conscious emotions on human cue\u2013reward association learning", "author": ["N. Watanabe", "M. Haruno"], "venue": "Scientific reports, 5.", "citeRegEx": "Watanabe and Haruno,? 2015", "shortCiteRegEx": "Watanabe and Haruno", "year": 2015}, {"title": "Deepface: Closing the gap to human-level performance in face verification", "author": ["Y. Taigman", "M. Yang", "M.A. Ranzato", "L. Wolf"], "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition, 1701-1708.", "citeRegEx": "Taigman et al\\.,? 2014", "shortCiteRegEx": "Taigman et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 2, "context": "(Brewer et al. 1998; \u00c7ukur et al. 2013) found that humans are good at finding contents of interest from complex, colored photographs, and the way that the visual signals captured from contents of interest attract humans is through activations in the cerebral cortex.", "startOffset": 0, "endOffset": 39}, {"referenceID": 3, "context": "(Brewer et al. 1998; \u00c7ukur et al. 2013) found that humans are good at finding contents of interest from complex, colored photographs, and the way that the visual signals captured from contents of interest attract humans is through activations in the cerebral cortex.", "startOffset": 0, "endOffset": 39}, {"referenceID": 0, "context": "(Silver et al. 2016; Taigman et al. 2014) showed that deep learning can reach human level performance in certain domains of application.", "startOffset": 0, "endOffset": 41}, {"referenceID": 22, "context": "(Silver et al. 2016; Taigman et al. 2014) showed that deep learning can reach human level performance in certain domains of application.", "startOffset": 0, "endOffset": 41}, {"referenceID": 20, "context": "For several major advertising publishers of JD DSP (Wang et al. 2017), the CTR, GMV and ROI (return on investment) increased 6.", "startOffset": 51, "endOffset": 69}, {"referenceID": 9, "context": "These methods (Cheng et al. 2016; Covington et al. 2016) map each item to a vector through the common way, which is assigning each item an initialized dense vector and then correcting these vectors with large scale training data by a certain optimization method, e.", "startOffset": 14, "endOffset": 56}, {"referenceID": 5, "context": "Fortunately, driven by the success of work (Szegedy et al. 2016), we can design a better DCNN architecture to process visual inputs as close as possible to a human vision system.", "startOffset": 43, "endOffset": 64}, {"referenceID": 5, "context": "Our Blocks 1-3 are similar to the Figures 5-7 in (Szegedy et al. 2016), but we apply a kernel of 5\u00d75 instead of the original kernel of 3\u00d73 and an average pooling of 3\u00d73.", "startOffset": 49, "endOffset": 70}, {"referenceID": 19, "context": "The A/B test platform is similar to (Tang et al. 2010).", "startOffset": 36, "endOffset": 54}, {"referenceID": 12, "context": "As the key module in recommender systems, ranking strategy is the key to improving recommending performance, which is often based on learning-to-rank (Cao et al. 2007; Qin et al. 2008; Liu 2009) that emerges from late 1990s.", "startOffset": 150, "endOffset": 194}, {"referenceID": 13, "context": "As the key module in recommender systems, ranking strategy is the key to improving recommending performance, which is often based on learning-to-rank (Cao et al. 2007; Qin et al. 2008; Liu 2009) that emerges from late 1990s.", "startOffset": 150, "endOffset": 194}, {"referenceID": 14, "context": "As the key module in recommender systems, ranking strategy is the key to improving recommending performance, which is often based on learning-to-rank (Cao et al. 2007; Qin et al. 2008; Liu 2009) that emerges from late 1990s.", "startOffset": 150, "endOffset": 194}, {"referenceID": 15, "context": "In language models, RNNs have achieved great success, especially for sequence to sequence tasks, which has inspired researchers to apply RNNs in recommender systems (Wu et al. 2016; Ko, Maystre and Grossglauser 2016).", "startOffset": 165, "endOffset": 216}, {"referenceID": 5, "context": "In computer vision, DCNNs have reached high accuracy in image classification and object recognition tasks (Krizhevsky, Sutskever, and Hinton 2012; Szegedy et al. 2016).", "startOffset": 106, "endOffset": 167}, {"referenceID": 18, "context": "Deep residual networks (He et al. 2016) have been used to reduce the difficulty of training deeper models through skipping one or more layers.", "startOffset": 23, "endOffset": 39}, {"referenceID": 6, "context": "This makes it possible to train deeper and wider networks (Szegedy et al. 2017).", "startOffset": 58, "endOffset": 79}], "year": 2017, "abstractText": "Designing an e-commerce recommender system that serves hundreds of millions of active users is a daunting challenge. Ranking strategy as the key module needs to be more carefully designed. We find two key factors that affect users\u2019 behaviors: attractive item content and compatibility with users\u2019 interests. To extract these factors, a ranking model needs to understand users from a human vision perspective. This paper proposes Telepath, a vision-based architecture that simulates the human vision system to extract the key visual signals that attract users to a displayed item and generate vision activations and simulates cerebral cortex to understand users\u2019 interest based on the captured activations from browsed items. Telepath is a combination of CNN, RNN and DNN. In practice, the Telepath model has been launched to JD\u2019s online recommender system and advertising system. For one of the major item recommendation blocks on the JD app, CTR, GMV and orders have increased 1.59%, 8.16% and 8.71% respectively. For several major advertising publishers of JD DSP, CTR, GMV and ROI have increased 6.58%, 61.72% and 65.57% respectively by the first launch, and further increased 2.95%, 41.75% and 41.37% respectively by the second launch.", "creator": null}}}