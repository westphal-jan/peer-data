{"id": "1709.00489", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Sep-2017", "title": "Arc-Standard Spinal Parsing with Stack-LSTMs", "abstract": "We present a neural transition-based parser for spinal trees, a dependency representation of constituent trees. The parser uses Stack-LSTMs that compose constituent nodes with dependency-based derivations. In experiments, we show that this model adapts to different styles of dependency relations, but this choice has little effect for predicting constituent structure, suggesting that LSTMs induce useful states by themselves.", "histories": [["v1", "Fri, 1 Sep 2017 21:38:28 GMT  (41kb)", "http://arxiv.org/abs/1709.00489v1", "IWPT 2017"]], "COMMENTS": "IWPT 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["miguel ballesteros", "xavier carreras"], "accepted": false, "id": "1709.00489"}, "pdf": {"name": "1709.00489.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["miguel.ballesteros@ibm.com", "xavier.carreras@naverlabs.com"], "sections": [{"heading": null, "text": "ar Xiv: 170 9.00 489v 1 [cs.C L] 1S ep2 017parser for spinal trees, a dependency representation of constituent trees. The parser uses stack LSTMs that form constituent nodes with dependency-based derivatives. In experiments we show that this model adapts to different types of dependency relationships, but this choice has little impact on predicting the constituent structure, suggesting that LSTMs themselves produce useful states."}, {"heading": "1 Introduction", "text": "There is a clear trend in neural transition systems for parsing sentences in dependency trees (Titov and Henderson, 2007; Chen and Manning, 2014; Dyer et al., 2015; Andor et al., 2016) and constituent trees (Henderson, 2004; Vinyals et al., 2014; Watanabe and Sumita, 2015; Dyer et al., 2016; Cross and Huang, 2016b). These transition systems use relatively simple operating systems to capture non-local phenomena in a derivative and rely on the ability of neural networks to derive and disseminate hidden structures through the derivative, in contrast to factoralized linear models that explicitly use non-local information to capture non-local phenomena in a derivative. In this paper, we present a transitional system for parsing sentences into spinal trees, a kind of syntactic tree that explicitly represents dependence and constituent structure."}, {"heading": "2 Spinal Trees", "text": "Spine dependence is a binary relationship between a node of the head spine and a dependent spine. In this paper we look at projective spine trees. Figure 1 shows a constituency tree from Penn Treebank together with two spine trees that use alternative head identities: The spine tree in 1b uses Stanford dependencies (De Marneffe et al., 2006), while the spine tree in 1c uses the most left word of a constituency tree as its head. It is direct to map a constituency tree with head comments on a spine tree and a spine tree into a constituency or dependency tree."}, {"heading": "3 Arc-Standard Spinal Parsing", "text": "We use the Transition System of Cross and Huang (2016a), which is the Arc Standard System of Nivre (2004) for parsing constituencies in a headdriven way, i.e. spinal parsing. We describe it here for completeness. The parsing state is a tuple < \u03b2, \u03c3, \u03b4 >, where \u03b2 is a buffer of input marks to be processed; \u03c3 is a stack of buffers i on the stack, and \u03b4 is a series of spinal dependencies. The operations are the following: \u2022 Shift: < i: \u03b2, \u03c3, \u03b4: i,. Move the first symbol of the stack i to the stack, i consists of a single token. \u2022 Node (n): < \u03b2: s, \u043c > <. < \u03b2, \u03c3: s."}, {"heading": "4 Spinal Stack-LSTMs", "text": "Dyer et al. (2015) introduced a standard arc parser that uses stack LSTMs, an extension of LSTMs (Hochreiter and Schmidhuber, 1997) for transition-based systems that maintain an embedding for each element in the stack.2. Our model is based on the same architecture, with the addition of the node (s) action. The state of our algorithm depicted in Section 3 is represented by the contents of the STACK, the BUFFER, and a list of the history of actions with stack LSTMs. This state representation is then used to predict the next action to be taken. Composition: When the parser predicts a left arc () or right arc (), we compose the vector representation of the head and dependent elements; this corresponds to what is represented by Dyer et al al al. (2015)."}, {"heading": "5 Related Work", "text": "Collins (1997) first proposed head-driven derivatives for parsing the components, which is the key idea for parsing the spine, and later Carreras et al. (2008) developed a graphics-based parser of higher order for this representation. Transition systems for parsing the spine are not new. Ballesteros and Carreras (2015) presented a standard arc system that identifies dependencies with component nodes and builds up the spine tree in post-processing. Hayashi et al. (2016) and Hayashi and Nagata (2016) presented a standard arc-shaped system that assigns a full spine to the shift operation, while our incremental spine builds up and does not depend on a fixed set of full spine. Our method differs from shift-reducing components (Henderson, 2003; Sagae and Lavie, 2005; Zhu et al., 2013; Watabe and Sumita, 2015) by extending it to the vertebral particles."}, {"heading": "6 Experiments", "text": "We are experimenting with stack-LSTM spinal models that have been trained with different types of head rules. Our goal is to test how the head identities that define the derivative sequence interact with the ability of stack-LSTMs to disseminate latent information beyond the local framework of each action. We are using Penn Treebank (Marcus et al., 1993) with standard splitters. We are starting with the formation of four spinal models that define the spinal rules: 4 \u2022 Leftmost heads as in Figure 1c. \u2022 Stanford Dependencies (SD) (De Marneffe et al., 2006), as in Figure1b. \u2022 Yamada and Matsumoto heads (Yamada and Matsumoto heads, 2003). Table 1 presents constituencies and dependencies at the development level. The model with the most heads works best."}, {"heading": "7 Conclusions", "text": "We presented a neural model based on StackLSTMs for spine parsing, which uses a simple extension of arc-standard transition parsing that adds components to the dependency derivation. Our experiments suggest that stack LSTMs can find a useful internal structure within the components, and that the parser could work better without providing linguistically derived keywords. Overall, our spinal neural method is simple, efficient, and very accurate, and could prove useful for modelling components of trees with dependency relationships."}], "references": [{"title": "Globally normalized transition-based neural networks", "author": ["Daniel Andor", "Chris Alberti", "David Weiss", "Aliaksei Severyn", "Alessandro Presta", "Kuzman Ganchev", "Slav Petrov", "Michael Collins."], "venue": "Proceedings of the 54th Annual Meeting of the", "citeRegEx": "Andor et al\\.,? 2016", "shortCiteRegEx": "Andor et al\\.", "year": 2016}, {"title": "Transition-based spinal parsing", "author": ["Miguel Ballesteros", "Xavier Carreras."], "venue": "Proceedings of the Nineteenth Conference on Computational Natural Language Learning. Association for Computational Linguistics, pages 289\u2013299.", "citeRegEx": "Ballesteros and Carreras.,? 2015", "shortCiteRegEx": "Ballesteros and Carreras.", "year": 2015}, {"title": "Greedy transition-based dependency parsing with stack lstms", "author": ["Miguel Ballesteros", "Chris Dyer", "Yoav Goldberg", "Noah Smith."], "venue": "Computational Linguistics 43(2).", "citeRegEx": "Ballesteros et al\\.,? 2017", "shortCiteRegEx": "Ballesteros et al\\.", "year": 2017}, {"title": "Training with exploration improves a greedy stack lstm parser", "author": ["Dyer", "Noah A. Smith."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Lin-", "citeRegEx": "Dyer and Smith.,? 2016", "shortCiteRegEx": "Dyer and Smith.", "year": 2016}, {"title": "Organizing Committee, chapter TAG, Dynamic Programming, and the Perceptron", "author": ["Xavier Carreras", "Michael Collins", "Terry Koo"], "venue": "Proceedings of the Twelfth Conference on Computational Natural Language Learning,", "citeRegEx": "Carreras et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Carreras et al\\.", "year": 2008}, {"title": "A fast and accurate dependency parser using neural networks", "author": ["Danqi Chen", "Christopher Manning."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computa-", "citeRegEx": "Chen and Manning.,? 2014", "shortCiteRegEx": "Chen and Manning.", "year": 2014}, {"title": "Parsing as language modeling", "author": ["Do Kook Choe", "Eugene Charniak."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Austin, Texas, pages 2331\u20132336.", "citeRegEx": "Choe and Charniak.,? 2016a", "shortCiteRegEx": "Choe and Charniak.", "year": 2016}, {"title": "Parsing as language modeling", "author": ["Kook Do Choe", "Eugene Charniak."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, pages 2331\u20132336.", "citeRegEx": "Choe and Charniak.,? 2016b", "shortCiteRegEx": "Choe and Charniak.", "year": 2016}, {"title": "Incremental parsing with minimal features using bi-directional lstm", "author": ["James Cross", "Liang Huang."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Association", "citeRegEx": "Cross and Huang.,? 2016a", "shortCiteRegEx": "Cross and Huang.", "year": 2016}, {"title": "Span-based constituency parsing with a structure-label system and provably optimal dynamic oracles", "author": ["James Cross", "Liang Huang."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, pages", "citeRegEx": "Cross and Huang.,? 2016b", "shortCiteRegEx": "Cross and Huang.", "year": 2016}, {"title": "Generating typed dependency parses from phrase structure parses", "author": ["Marie-Catherine De Marneffe", "Bill MacCartney", "Christopher D Manning"], "venue": "In Proceedings of LREC. Genoa,", "citeRegEx": "Marneffe et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2006}, {"title": "Transition-based dependency parsing with stack long short-term memory", "author": ["Chris Dyer", "Miguel Ballesteros", "Wang Ling", "Austin Matthews", "Noah A. Smith."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguis-", "citeRegEx": "Dyer et al\\.,? 2015", "shortCiteRegEx": "Dyer et al\\.", "year": 2015}, {"title": "Recurrent neural network grammars", "author": ["Chris Dyer", "Adhiguna Kuncoro", "Miguel Ballesteros", "Noah A. Smith."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Com-", "citeRegEx": "Dyer et al\\.,? 2016", "shortCiteRegEx": "Dyer et al\\.", "year": 2016}, {"title": "Parsing as reduction", "author": ["Daniel Fern\u00e1ndez-Gonz\u00e1lez", "T. Andr\u00e9 F. Martins."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language", "citeRegEx": "Fern\u00e1ndez.Gonz\u00e1lez and Martins.,? 2015", "shortCiteRegEx": "Fern\u00e1ndez.Gonz\u00e1lez and Martins.", "year": 2015}, {"title": "Proceedings of the Workshop on Parsing German, Association for Computational Linguistics, chapter A Dependency-Driven Parser for German Dependency and Constituency Representations, pages 47\u201354", "author": ["Johan Hall", "Joakim Nivre"], "venue": null, "citeRegEx": "Hall and Nivre.,? \\Q2008\\E", "shortCiteRegEx": "Hall and Nivre.", "year": 2008}, {"title": "University of Tartu, Estonia, chapter A Hybrid Constituency", "author": ["Johan Hall", "Joakim Nivre", "Jens Nilsson"], "venue": "Proceedings of the 16th Nordic Conference of Computational Linguistics (NODALIDA", "citeRegEx": "Hall et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hall et al\\.", "year": 2007}, {"title": "Empty element recovery by spinal parser operations", "author": ["Katsuhiko Hayashi", "Masaaki Nagata."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Association", "citeRegEx": "Hayashi and Nagata.,? 2016", "shortCiteRegEx": "Hayashi and Nagata.", "year": 2016}, {"title": "Shift-reduce spinal tag parsing with dynamic programming", "author": ["Katsuhiko Hayashi", "Jun Suzuki", "Masaaki Nagata."], "venue": "Transactions of the Japanese Society for Artificial Intelligence 31(2).", "citeRegEx": "Hayashi et al\\.,? 2016", "shortCiteRegEx": "Hayashi et al\\.", "year": 2016}, {"title": "Inducing history representations for broad coverage statistical parsing", "author": ["James Henderson."], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Vol-", "citeRegEx": "Henderson.,? 2003", "shortCiteRegEx": "Henderson.", "year": 2003}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural Computation 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Simple and accurate dependency parsing using bidirectional lstm feature representations", "author": ["Eliyahu Kiperwasser", "Yoav Goldberg."], "venue": "Transactions of the Association for Computational Linguistics 4:313\u2013327. https://transacl.org/ojs/index.php/tacl/article/view/885.", "citeRegEx": "Kiperwasser and Goldberg.,? 2016", "shortCiteRegEx": "Kiperwasser and Goldberg.", "year": 2016}, {"title": "What do recurrent neural network grammars learn about syntax", "author": ["Adhiguna Kuncoro", "Miguel Ballesteros", "Lingpeng Kong", "Chris Dyer", "Graham Neubig", "Noah A. Smith"], "venue": "In Proceedings of the 15th Conference", "citeRegEx": "Kuncoro et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Kuncoro et al\\.", "year": 2017}, {"title": "Distilling an ensemble of greedy dependency parsers into one mst parser", "author": ["Adhiguna Kuncoro", "Miguel Ballesteros", "Lingpeng Kong", "Chris Dyer", "Noah A. Smith."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Pro-", "citeRegEx": "Kuncoro et al\\.,? 2016", "shortCiteRegEx": "Kuncoro et al\\.", "year": 2016}, {"title": "Shift-reduce constituent parsing with neural lookahead features", "author": ["Jiangming Liu", "Yue Zhang."], "venue": "Transactions of the Association of Computational Linguistics 5:45\u201358. http://aclanthology.coli.uni-saarland.de/pdf/Q/Q17/Q17-1004.pdf.", "citeRegEx": "Liu and Zhang.,? 2017", "shortCiteRegEx": "Liu and Zhang.", "year": 2017}, {"title": "Building a Large Annotated Corpus of English: The Penn Treebank", "author": ["Mitchell P. Marcus", "Beatrice Santorini", "Mary A. Marcinkiewicz."], "venue": "Computational Linguistics 19(2):313\u2013330.", "citeRegEx": "Marcus et al\\.,? 1993", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "Incrementality in deterministic dependency parsing", "author": ["Joakim Nivre."], "venue": "Frank Keller, Stephen Clark, Matthew Crocker, and Mark Steedman, editors, Proceedings of the ACL Workshop Incremental Parsing: Bringing Engineering and Cognition To-", "citeRegEx": "Nivre.,? 2004", "shortCiteRegEx": "Nivre.", "year": 2004}, {"title": "Algorithms for deterministic incremental dependency parsing", "author": ["Joakim Nivre."], "venue": "Computational Linguistics 34(4):513\u2013553.", "citeRegEx": "Nivre.,? 2008", "shortCiteRegEx": "Nivre.", "year": 2008}, {"title": "A classifier-based parser with linear run-time complexity", "author": ["Kenji Sagae", "Alon Lavie."], "venue": "Proceedings of the Ninth International Workshop on Parsing Technology. Association for Computational Linguistics, Van-", "citeRegEx": "Sagae and Lavie.,? 2005", "shortCiteRegEx": "Sagae and Lavie.", "year": 2005}, {"title": "A latent variable model for generative dependency parsing", "author": ["Ivan Titov", "James Henderson."], "venue": "Proceedings of the Tenth International Conference on Parsing Technologies. Association for Computational Linguistics,", "citeRegEx": "Titov and Henderson.,? 2007", "shortCiteRegEx": "Titov and Henderson.", "year": 2007}, {"title": "Grammar as a foreign language", "author": ["Oriol Vinyals", "Lukasz Kaiser", "Terry Koo", "Slav Petrov", "Ilya Sutskever", "Geoffrey E. Hinton."], "venue": "CoRR abs/1412.7449. http://arxiv.org/abs/1412.7449.", "citeRegEx": "Vinyals et al\\.,? 2014", "shortCiteRegEx": "Vinyals et al\\.", "year": 2014}, {"title": "Transition-based neural constituent parsing", "author": ["Taro Watanabe", "Eiichiro Sumita."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference", "citeRegEx": "Watanabe and Sumita.,? 2015", "shortCiteRegEx": "Watanabe and Sumita.", "year": 2015}, {"title": "Statistical dependency analysis with support vector machines", "author": ["Hiroyasu Yamada", "Yuji Matsumoto."], "venue": "Proceedings of IWPT. volume 3, pages 195\u2013206.", "citeRegEx": "Yamada and Matsumoto.,? 2003", "shortCiteRegEx": "Yamada and Matsumoto.", "year": 2003}, {"title": "Fast and accurate shift-reduce constituent parsing", "author": ["Muhua Zhu", "Yue Zhang", "Wenliang Chen", "Min Zhang", "Jingbo Zhu."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume", "citeRegEx": "Zhu et al\\.,? 2013", "shortCiteRegEx": "Zhu et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 28, "context": "There is a clear trend in neural transition systems for parsing sentences into dependency trees (Titov and Henderson, 2007; Chen and Manning, 2014; Dyer et al., 2015; Andor et al., 2016) and constituent trees (Henderson, 2004; Vinyals et al.", "startOffset": 96, "endOffset": 186}, {"referenceID": 5, "context": "There is a clear trend in neural transition systems for parsing sentences into dependency trees (Titov and Henderson, 2007; Chen and Manning, 2014; Dyer et al., 2015; Andor et al., 2016) and constituent trees (Henderson, 2004; Vinyals et al.", "startOffset": 96, "endOffset": 186}, {"referenceID": 11, "context": "There is a clear trend in neural transition systems for parsing sentences into dependency trees (Titov and Henderson, 2007; Chen and Manning, 2014; Dyer et al., 2015; Andor et al., 2016) and constituent trees (Henderson, 2004; Vinyals et al.", "startOffset": 96, "endOffset": 186}, {"referenceID": 0, "context": "There is a clear trend in neural transition systems for parsing sentences into dependency trees (Titov and Henderson, 2007; Chen and Manning, 2014; Dyer et al., 2015; Andor et al., 2016) and constituent trees (Henderson, 2004; Vinyals et al.", "startOffset": 96, "endOffset": 186}, {"referenceID": 29, "context": ", 2016) and constituent trees (Henderson, 2004; Vinyals et al., 2014; Watanabe and Sumita, 2015; Dyer et al., 2016; Cross and Huang, 2016b).", "startOffset": 30, "endOffset": 139}, {"referenceID": 30, "context": ", 2016) and constituent trees (Henderson, 2004; Vinyals et al., 2014; Watanabe and Sumita, 2015; Dyer et al., 2016; Cross and Huang, 2016b).", "startOffset": 30, "endOffset": 139}, {"referenceID": 12, "context": ", 2016) and constituent trees (Henderson, 2004; Vinyals et al., 2014; Watanabe and Sumita, 2015; Dyer et al., 2016; Cross and Huang, 2016b).", "startOffset": 30, "endOffset": 139}, {"referenceID": 9, "context": ", 2016) and constituent trees (Henderson, 2004; Vinyals et al., 2014; Watanabe and Sumita, 2015; Dyer et al., 2016; Cross and Huang, 2016b).", "startOffset": 30, "endOffset": 139}, {"referenceID": 25, "context": "To parse sentences, we use the extension by Cross and Huang (2016a) of the arc-standard system for dependency parsing (Nivre, 2004).", "startOffset": 118, "endOffset": 131}, {"referenceID": 18, "context": "This parsing system generalizes shift-reduce methods (Henderson, 2003; Sagae and Lavie, 2005; Zhu et al., 2013; Watanabe and Sumita, 2015) to be sensitive to constituent heads, as opposed to, for example, parse a constituent from left to right.", "startOffset": 53, "endOffset": 138}, {"referenceID": 27, "context": "This parsing system generalizes shift-reduce methods (Henderson, 2003; Sagae and Lavie, 2005; Zhu et al., 2013; Watanabe and Sumita, 2015) to be sensitive to constituent heads, as opposed to, for example, parse a constituent from left to right.", "startOffset": 53, "endOffset": 138}, {"referenceID": 32, "context": "This parsing system generalizes shift-reduce methods (Henderson, 2003; Sagae and Lavie, 2005; Zhu et al., 2013; Watanabe and Sumita, 2015) to be sensitive to constituent heads, as opposed to, for example, parse a constituent from left to right.", "startOffset": 53, "endOffset": 138}, {"referenceID": 30, "context": "This parsing system generalizes shift-reduce methods (Henderson, 2003; Sagae and Lavie, 2005; Zhu et al., 2013; Watanabe and Sumita, 2015) to be sensitive to constituent heads, as opposed to, for example, parse a constituent from left to right.", "startOffset": 53, "endOffset": 138}, {"referenceID": 4, "context": "representation is inherent in head-driven models (Collins, 1997) and was used by Carreras et al. (2008) with a higher-order factored model.", "startOffset": 81, "endOffset": 104}, {"referenceID": 4, "context": "representation is inherent in head-driven models (Collins, 1997) and was used by Carreras et al. (2008) with a higher-order factored model. We extend the Stack-LSTMs by Dyer et al. (2015) from dependency to spinal parsing, by augmenting the composition operations to include constituent information in the form of spines.", "startOffset": 81, "endOffset": 188}, {"referenceID": 4, "context": "representation is inherent in head-driven models (Collins, 1997) and was used by Carreras et al. (2008) with a higher-order factored model. We extend the Stack-LSTMs by Dyer et al. (2015) from dependency to spinal parsing, by augmenting the composition operations to include constituent information in the form of spines. To parse sentences, we use the extension by Cross and Huang (2016a) of the arc-standard system for dependency parsing (Nivre, 2004).", "startOffset": 81, "endOffset": 390}, {"referenceID": 10, "context": "In experiments on the Penn Treebank, we look at how sensitive our method is to different styles of dependency relations, and show that spinal models based on leftmost or rightmost heads are as good or better than models using linguistic dependency relations such as Stanford Dependencies (De Marneffe et al., 2006) or those by Yamada and Matsumoto (2003). This suggests that Stack-LSTMs figure out effective ways of modeling non-local phenomena within constituents.", "startOffset": 292, "endOffset": 355}, {"referenceID": 8, "context": "We use the transition system by Cross and Huang (2016a), which extends the arc-standard system by Nivre (2004) for constituency parsing in a headdriven way, i.", "startOffset": 32, "endOffset": 56}, {"referenceID": 8, "context": "We use the transition system by Cross and Huang (2016a), which extends the arc-standard system by Nivre (2004) for constituency parsing in a headdriven way, i.", "startOffset": 32, "endOffset": 111}, {"referenceID": 26, "context": "This transition system is correct and sound with respect to the class of projective spinal trees, in the same way as the arc-standard system is for projective dependency trees (Nivre, 2008).", "startOffset": 176, "endOffset": 189}, {"referenceID": 19, "context": "(2015) presented an arc-standard parser that uses Stack-LSTMs, an extension of LSTMs (Hochreiter and Schmidhuber, 1997) for transition-based systems that maintains an embedding for each element in the stack.", "startOffset": 85, "endOffset": 119}, {"referenceID": 11, "context": "pose the vector representation of the head and dependent elements; this is equivalent to what it is presented by Dyer et al. (2015). The", "startOffset": 113, "endOffset": 132}, {"referenceID": 11, "context": "Set to 10 in our experiments We refer interested readers to (Dyer et al., 2015; Ballesteros et al., 2017).", "startOffset": 60, "endOffset": 105}, {"referenceID": 2, "context": "Set to 10 in our experiments We refer interested readers to (Dyer et al., 2015; Ballesteros et al., 2017).", "startOffset": 60, "endOffset": 105}, {"referenceID": 21, "context": "As shown by Kuncoro et al. (2017) composition is an essential component in this kind of parsing models.", "startOffset": 12, "endOffset": 34}, {"referenceID": 3, "context": "Collins (1997) first proposed head-driven derivations for constituent parsing, which is the key idea for spinal parsing, and later Carreras et al. (2008) came up with a higher-order graphbased parser for this representation.", "startOffset": 131, "endOffset": 154}, {"referenceID": 1, "context": "Ballesteros and Carreras (2015) presented an arceager system that labels dependencies with", "startOffset": 0, "endOffset": 32}, {"referenceID": 16, "context": "Hayashi et al. (2016) and Hayashi and Nagata (2016) presented a bottomup arc-standard system that assigns a full spine", "startOffset": 0, "endOffset": 22}, {"referenceID": 16, "context": "(2016) and Hayashi and Nagata (2016) presented a bottomup arc-standard system that assigns a full spine", "startOffset": 11, "endOffset": 37}, {"referenceID": 18, "context": "Our method is different from shift-reduce constituent parsers (Henderson, 2003; Sagae and Lavie, 2005; Zhu et al., 2013; Watanabe and Sumita, 2015) in that it is headdriven.", "startOffset": 62, "endOffset": 147}, {"referenceID": 27, "context": "Our method is different from shift-reduce constituent parsers (Henderson, 2003; Sagae and Lavie, 2005; Zhu et al., 2013; Watanabe and Sumita, 2015) in that it is headdriven.", "startOffset": 62, "endOffset": 147}, {"referenceID": 32, "context": "Our method is different from shift-reduce constituent parsers (Henderson, 2003; Sagae and Lavie, 2005; Zhu et al., 2013; Watanabe and Sumita, 2015) in that it is headdriven.", "startOffset": 62, "endOffset": 147}, {"referenceID": 30, "context": "Our method is different from shift-reduce constituent parsers (Henderson, 2003; Sagae and Lavie, 2005; Zhu et al., 2013; Watanabe and Sumita, 2015) in that it is headdriven.", "startOffset": 62, "endOffset": 147}, {"referenceID": 8, "context": "Cross and Huang (2016a) extended the arc-standard system to constituency parsing, which in fact corresponds to spinal parsing.", "startOffset": 0, "endOffset": 24}, {"referenceID": 15, "context": "Finally, dependency parsers have been extended to constituency parsing by encoding the additional structure in the dependency labels, in different ways (Hall et al., 2007; Hall and Nivre, 2008; Fern\u00e1ndez-Gonz\u00e1lez and Martins, 2015).", "startOffset": 152, "endOffset": 231}, {"referenceID": 14, "context": "Finally, dependency parsers have been extended to constituency parsing by encoding the additional structure in the dependency labels, in different ways (Hall et al., 2007; Hall and Nivre, 2008; Fern\u00e1ndez-Gonz\u00e1lez and Martins, 2015).", "startOffset": 152, "endOffset": 231}, {"referenceID": 13, "context": "Finally, dependency parsers have been extended to constituency parsing by encoding the additional structure in the dependency labels, in different ways (Hall et al., 2007; Hall and Nivre, 2008; Fern\u00e1ndez-Gonz\u00e1lez and Martins, 2015).", "startOffset": 152, "endOffset": 231}, {"referenceID": 24, "context": "We use the Penn Treebank (Marcus et al., 1993) with standard splits.", "startOffset": 25, "endOffset": 46}, {"referenceID": 31, "context": "\u2022 Yamada and Matsumoto heads (YM) (Yamada and Matsumoto, 2003).", "startOffset": 34, "endOffset": 62}, {"referenceID": 11, "context": "We use the the same POS tags as Dyer et al. (2015). It is simple to obtain a spinal tree given a constituency tree and a corresponding dependency tree.", "startOffset": 32, "endOffset": 51}, {"referenceID": 5, "context": "As shown in Table 2 our model is competitive compared to the best parsers; the generative parsers by Choe and Charniak (2016b), Dyer et al.", "startOffset": 101, "endOffset": 127}, {"referenceID": 5, "context": "As shown in Table 2 our model is competitive compared to the best parsers; the generative parsers by Choe and Charniak (2016b), Dyer et al. (2016) and Kuncoro et al.", "startOffset": 101, "endOffset": 147}, {"referenceID": 5, "context": "As shown in Table 2 our model is competitive compared to the best parsers; the generative parsers by Choe and Charniak (2016b), Dyer et al. (2016) and Kuncoro et al. (2017) are better than the rest, but compared to the rest our parser is at the same level or better.", "startOffset": 101, "endOffset": 173}, {"referenceID": 1, "context": "The most similar system is by Ballesteros and Carreras (2015) and our parser significantly improves the performance.", "startOffset": 30, "endOffset": 62}, {"referenceID": 17, "context": "model is worse than the ones that train with exploration as Kiperwasser and Goldberg (2016) and Ballesteros et al.", "startOffset": 60, "endOffset": 92}, {"referenceID": 2, "context": "model is worse than the ones that train with exploration as Kiperwasser and Goldberg (2016) and Ballesteros et al. (2016), but it slightly improves the parser by Dyer et al.", "startOffset": 96, "endOffset": 122}, {"referenceID": 2, "context": "model is worse than the ones that train with exploration as Kiperwasser and Goldberg (2016) and Ballesteros et al. (2016), but it slightly improves the parser by Dyer et al. (2015) with static training.", "startOffset": 96, "endOffset": 181}, {"referenceID": 8, "context": "1 Cross and Huang (2016a) 93.", "startOffset": 2, "endOffset": 26}, {"referenceID": 6, "context": "5 Choe and Charniak (2016a)* (Semi-sup) 95.", "startOffset": 2, "endOffset": 28}, {"referenceID": 6, "context": "5 Choe and Charniak (2016a)* (Semi-sup) 95.9 Kuncoro et al. (2017)* (Generative) 95.", "startOffset": 2, "endOffset": 67}], "year": 2017, "abstractText": "We present a neural transition-based parser for spinal trees, a dependency representation of constituent trees. The parser uses Stack-LSTMs that compose constituent nodes with dependency-based derivations. In experiments, we show that this model adapts to different styles of dependency relations, but this choice has little effect for predicting constituent structure, suggesting that LSTMs induce useful states by themselves.", "creator": "LaTeX with hyperref package"}}}