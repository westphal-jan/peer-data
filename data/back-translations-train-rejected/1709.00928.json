{"id": "1709.00928", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Sep-2017", "title": "Automation of Android Applications Testing Using Machine Learning Activities Classification", "abstract": "Mobile applications are being used every day by more than half of the world's population to perform a great variety of tasks. With the increasingly widespread usage of these applications, the need arises for efficient techniques to test them. Many frameworks allow automating the process of application testing, however existing frameworks mainly rely on the application developer for providing testing scripts for each developed application, thus preventing reuse of these tests for similar applications. In this paper, we present a novel approach for the automation of testing Android applications by leveraging machine learning techniques and reusing popular test scenarios. We discuss and demonstrate the potential benefits of our approach in an empirical study where we show that our developed testing tool, based on the proposed approach, outperforms standard methods in realistic settings.", "histories": [["v1", "Mon, 4 Sep 2017 12:52:36 GMT  (1089kb,D)", "http://arxiv.org/abs/1709.00928v1", null]], "reviews": [], "SUBJECTS": "cs.SE cs.AI", "authors": ["ariel rosenfeld", "odaya kardashov", "orel zang"], "accepted": false, "id": "1709.00928"}, "pdf": {"name": "1709.00928.pdf", "metadata": {"source": "CRF", "title": "Automation of Android Applications Testing Using Machine Learning Activities Classification", "authors": ["Ariel Rosenfeld", "Odaya Kardashov", "Orel Zang"], "emails": ["arielros1@gmail.com"], "sections": [{"heading": null, "text": "Tags: Android Application Testing, Mobile Testing Automation, Activities Classification"}, {"heading": "1 Introduction", "text": "In fact, most of us will be able to play by the rules we have set ourselves."}, {"heading": "2 Related Work", "text": "In fact, it is the case that one is able to put oneself at the top of society."}, {"heading": "3 Approach", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Motivation for Activities Classification", "text": "The key element of our approach stems from the difference between testing desktop and mobile applications. While desktop applications come in an infinite number of shapes and forms, the structural scope of mobile applications is naturally more limited [19]. An Android application is essentially a series of different screens connected to each other by user interface buttons. The official Android development guide defines each of these screens as \"activity\" 6, which is a single window in the application. An Android activity is a group of different user interface elements from the Android Development Kit that are organized in a hierarchical structure. While these elements vary in their specific purposes, we can categorize them into two main groups: 1) elements that are directly visible to the user on the screen and allow him to interact with them by hand gestures, such as clickable buttons, lists of elements that can be scrolled up and down, and text fields that are more directly visible to the user; 2) elements that are more visible to the user, rather than to the other classes, which can be learned from."}, {"heading": "3.2 A Study of Activities Types", "text": "In fact, most of them are able to survive on their own."}, {"heading": "3.3 Building the Features Vector", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "3.4 Constructing a Dataset", "text": "To create a dataset to train and test our classifier, as described in Section 3.5, we had to obtain a large number of activities from Android applications and extract and label functions. Extracting the features of an activity is a difficult task, as many elements of an activity are invisible and cannot be identified just by observing the activity display on the device. To solve this problem, we use the TestProject Elements Spy tool, which allows developers to scan and inspect the elements of the user interface of an Android activity. We have implemented an automated script that extracts the features of a particular Android application, as defined in Section 3.3, using the ElementsSpy tool and stores them in the dataset file in a text format. Although the extraction of the features has been automated, building a dataset of activities was still a long process, as it took a significant amount of time to connect to the Appium to extract the functions and load the device."}, {"heading": "3.5 The Classifier", "text": "To train our classifier, we performed a 10-fold classification process with different classification algorithms on our data set, while measuring the accuracy of each of them. Table 1 shows an accuracy averaged by predicting activity types using different classification models: as we can see from Table 1, we managed to achieve a high classification accuracy of 86.25% using the instance-based KStar classifier [26], while other classical methods such as decision trees or multi-layered perceptrons had an average accuracy of only 77%. Our preferred model for this work is KStar. KStar uses an entropic distance measurement as a similarity function to determine which of the training instances are most similar to the test instance. We conducted a grid search of the possible k-parameter values and found that k = 20 produced the best results.In addition, we use a selection function that we use to evaluate the information in the order of 27 characteristics. \""}, {"heading": "4 Empirical Evaluation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Experimental Design", "text": "The Android Application Monkey [10] was selected as a representative of the current tools, as it is one of the most commonly used tools to test Android applications [9]. This is due to the fact that it is part of the Android developer toolkit. In order to demonstrate the limitations of the current tools, as well as to show that our approach of activity classification by machine learning can overcome these limitations, we designed a novel experiment that focuses on applications, logical bugs. These bugs refer to the logic of the application, which means adverse behavior in the functionality of the application, as opposed to real-time application crashes caused by rough exceptions in the code. We used 2 new open source Android applications for the experiment. These applications have not been used so far in this study. Applications generally go through rigorous testing before they are uploaded into the application memory. Therefore, in order to realistically plant an existing wide variety of artificial bugs, we discussed in addition to the existing email. \""}, {"heading": "4.2 Results", "text": "Figures 3 and 4 present the results of the experiment. In their investigation, we can see three important trends: 1) ACAT was able to correctly classify the 3 invisible activities. 2) ACAT was able to detect all \"planted\" errors, while the Android monkey did not detect any. Furthermore, ACAT was able to detect a logical error (a user can send an email with an invalid address of the recipient) that was already part of the original version of the application without manipulating the code. In the rest of the original activities, it correctly declared that there were no logical errors. 3) The Android monkey was able to detect a crash in real time that was not detected by ACAT. ACAT also produces a report, which can be seen in Figure 2."}, {"heading": "5 Discussion", "text": "Our results described in Section 4.2 show an interesting phenomenon. While the Android monkey was unable to detect a single logical error, ACAT discovered all the various errors that were implemented in the source code of the applications, as well as an error that already existed in the original code. This contributes to our approach to classifying our activities, which allows this add-on to derive a list of activity-based tests to investigate the expected behavior of the activity. These tests can only be performed in the right context that can be interpreted with this proposed approach to machine learning. In addition, our experiment shows another underlying idea behind our approach. Instead of testing an application as a whole, as previous work as described in Section 2 has done, it might be better, or at least provide some benefit, to consider each activity in the application as a self-unit with specific desired functions."}, {"heading": "6 Conclusions", "text": "This paper introduces a novel approach to testing Android applications using machine learning. Using such techniques allowed us to classify each of the application activities into a specific type, which in turn allowed us to test different expected behaviors of the different screens. Furthermore, we tested our add-on on on different applications, demonstrating its advantage over the popular Android application tool - the Android Monkey. Our add-on, which we called ACAT, shows that it finds more logical errors in an application than just crashes in real time, which opens the possibility to develop more complex testing tools. We are currently working with TestProject to integrate the ACAT add-on into the TestProject framework and use its database of thousands of mobile application patterns. The ACAT add-on will be available through the TestProject add-on store."}], "references": [{"title": "Alemerien, \u201cMobile software testing: Thoughts, strategies, challenges, and experimental study,", "author": ["M. Akour", "A.A. Al-Zyoud", "B. Falah", "S. Bouriat"], "venue": "International Journal of Advanced Computer Science and Applications,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Remote mobile test system: a mobile phone cloud for application testing,", "author": ["J.-f. Huang", "Y.-z. Gong"], "venue": "Cloud Computing Technology and Science (CloudCom),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Automating GUI testing for Android applications,", "author": ["C. Hu", "I. Neamtiu"], "venue": "Proceedings of the 6th International Workshop on Automation of Software Test,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Characterizing failures in mobile oses: A case study with Android and Symbian,", "author": ["A.K. Maji", "K. Hao", "S. Sultana", "S. Bagchi"], "venue": "in Software Reliability Engineering (ISSRE),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Mobile application testing: a tutorial,", "author": ["J. Gao", "X. Bai", "W.-T. Tsai", "T. Uehara"], "venue": "Computer, vol. 47,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Automated test input generation for Android: Are we there yet?,", "author": ["S.R. Choudhary", "A. Gorla", "A. Orso"], "venue": "Automated Software Engineering (ASE),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Dynodroid: An input generation system for Android apps,", "author": ["A. Machiry", "R. Tahiliani", "M. Naik"], "venue": "Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Droidfuzzer: Fuzzing the Android apps with intent-filter tag,", "author": ["H. Ye", "S. Cheng", "L. Zhang", "F. Jiang"], "venue": "Proceedings of International Conference on Advances in Mobile Computing & Multimedia,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Using GUI ripping for automated testing of Android applications,", "author": ["D. Amalfitano", "A.R. Fasolino", "P. Tramontana", "S. De Carmine", "A.M. Memon"], "venue": "Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Targeted and depth-first exploration for systematic testing of Android apps,", "author": ["T. Azim", "I. Neamtiu"], "venue": "in ACM SIGPLAN Notices,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Guided GUI testing of Android apps with minimal restart and approximate learning,", "author": ["W. Choi", "G. Necula", "K. Sen"], "venue": "in ACM SIGPLAN Notices,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Sapienz: Multi-objective automated testing for android applications,", "author": ["K. Mao", "M. Harman", "Y. Jia"], "venue": "Proceedings of the 25th International Symposium on Software Testing and Analysis,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Evodroid: Segmented evolutionary testing of Android apps,", "author": ["R. Mahmood", "N. Mirzaei", "S. Malek"], "venue": "Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Automated concolic testing of smartphone apps,", "author": ["S. Anand", "M. Naik", "M.J. Harrold", "H. Yang"], "venue": "Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Survey on multiclass classification methods,", "author": ["M. Aly"], "venue": "Neural Networks,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2005}, {"title": "K*: An instance-based learner using an entropic distance measure,", "author": ["J.G. Cleary", "L.E. Trigg"], "venue": "Proceedings of the 12th International Conference on Machine learning,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1995}, {"title": "Comparative study of attribute selection using gain ratio and correlation based feature selection,", "author": ["A.G. Karegowda", "A. Manjunath", "M. Jayaram"], "venue": "International Journal of Information Technology and Knowledge Management,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "These applications have completely changed the way we handle everyday activities, communicate with each other and perform many tasks [3].", "startOffset": 133, "endOffset": 136}, {"referenceID": 1, "context": "The large fragmentation of the Android market, as well as the diverse set of scenarios in which a mobile application can be used, make testing new applications an expensive, time-consuming and complex process [4,3].", "startOffset": 209, "endOffset": 214}, {"referenceID": 0, "context": "The large fragmentation of the Android market, as well as the diverse set of scenarios in which a mobile application can be used, make testing new applications an expensive, time-consuming and complex process [4,3].", "startOffset": 209, "endOffset": 214}, {"referenceID": 2, "context": "Unfortunately, mobile applications are proving to be bugs-prone mainly due to developers\u2019 unfamiliarity with mobile platforms [5].", "startOffset": 126, "endOffset": 129}, {"referenceID": 3, "context": "[6] has found that mobile applications tend to significant amount of defects and bugs.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "use automated tools for their testings [7].", "startOffset": 39, "endOffset": 42}, {"referenceID": 2, "context": "[5] has discovered that many of the mobile application bugs are unique and tend to be different from the ones presented in traditional desktop applications, mainly due to the inherent difference in architecture and development methodologies.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "The need for efficient mobile application testing methods has yielded many testing automation frameworks, including tools like Appium, Selendroid and Robotium, to name a few (a recent survey is available at [7]).", "startOffset": 207, "endOffset": 210}, {"referenceID": 5, "context": "In this paper, as with most of recent papers in the field, we focus on the Android platform [9].", "startOffset": 92, "endOffset": 95}, {"referenceID": 5, "context": "[9], which has conducted a comprehensive overview of the main existing Android applications testing tools that have been proposed and developed in academic papers, we can categorize each of these tools into one of three approaches:", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "In this category we can find tools like Monkey [10], Dynodroid [11] and DroidFuzzer [12].", "startOffset": 63, "endOffset": 67}, {"referenceID": 7, "context": "In this category we can find tools like Monkey [10], Dynodroid [11] and DroidFuzzer [12].", "startOffset": 84, "endOffset": 88}, {"referenceID": 8, "context": "In this category we can find tools like GUIRipper [13], AE-DepthFirst [14] and Swifthand [15], which uses machine learning techniques to learn a model of the application\u2019s GUI and guide the generation of user input sequences based on this model.", "startOffset": 50, "endOffset": 54}, {"referenceID": 9, "context": "In this category we can find tools like GUIRipper [13], AE-DepthFirst [14] and Swifthand [15], which uses machine learning techniques to learn a model of the application\u2019s GUI and guide the generation of user input sequences based on this model.", "startOffset": 70, "endOffset": 74}, {"referenceID": 10, "context": "In this category we can find tools like GUIRipper [13], AE-DepthFirst [14] and Swifthand [15], which uses machine learning techniques to learn a model of the application\u2019s GUI and guide the generation of user input sequences based on this model.", "startOffset": 89, "endOffset": 93}, {"referenceID": 11, "context": "In this category we can find tools like Sapienz [16], EvoDroid [17], A E-Targeted [14] and ACTEve [18].", "startOffset": 48, "endOffset": 52}, {"referenceID": 12, "context": "In this category we can find tools like Sapienz [16], EvoDroid [17], A E-Targeted [14] and ACTEve [18].", "startOffset": 63, "endOffset": 67}, {"referenceID": 9, "context": "In this category we can find tools like Sapienz [16], EvoDroid [17], A E-Targeted [14] and ACTEve [18].", "startOffset": 82, "endOffset": 86}, {"referenceID": 13, "context": "In this category we can find tools like Sapienz [16], EvoDroid [17], A E-Targeted [14] and ACTEve [18].", "startOffset": 98, "endOffset": 102}, {"referenceID": 5, "context": "Nevertheless, they all share a common prominent limitation: these approaches aim to find only technical bugs and defects in the application, meaning real-time application crashes which are caused by uncaught exceptions thrown in the code [9].", "startOffset": 238, "endOffset": 241}, {"referenceID": 2, "context": "[5] present an empirical study of common Android bugs.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[9] points out this problem as a future research direction, saying that allowing tools to explore the application in presence of login forms and similar complex inputs, which may be hard to generate randomly or by means of systematic techniques, will help explore new behaviors.", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "The problem can be naturally translated into a Multiclass classification problem [21], which is a common branch of machine learning.", "startOffset": 81, "endOffset": 85}, {"referenceID": 15, "context": "As we can see from Table 1, using the instance-based KStar classifier [26] we have managed to achieve a high classification accuracy of 86.", "startOffset": 70, "endOffset": 74}, {"referenceID": 16, "context": "based feature selection [27], which evaluates the \u201cworth\u201d of a feature by measuring the information gain with respect to the class.", "startOffset": 24, "endOffset": 28}, {"referenceID": 5, "context": "The Android Application Monkey [10] was chosen as the representative of present tools, considering it being one of the most frequently used tool to test Android applications [9].", "startOffset": 174, "endOffset": 177}], "year": 2017, "abstractText": "Mobile applications are being used every day by more than half of the world\u2019s population to perform a great variety of tasks. With the increasingly widespread usage of these applications, the need arises for efficient techniques to test them. Many frameworks allow automating the process of application testing, however existing frameworks mainly rely on the application developer for providing testing scripts for each developed application, thus preventing reuse of these tests for similar applications. In this paper, we present a novel approach for the automation of testing Android applications by leveraging machine learning techniques and reusing popular test scenarios. We discuss and demonstrate the potential benefits of our approach in an empirical study where we show that our developed testing tool, based on the proposed approach, outperforms standard methods in realistic settings.", "creator": "LaTeX with hyperref package"}}}