{"id": "1709.01073", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Sep-2017", "title": "Predicting Remaining Useful Life using Time Series Embeddings based on Recurrent Neural Networks", "abstract": "We consider the problem of estimating the remaining useful life (RUL) of a system or a machine from sensor data. Many approaches for RUL estimation based on sensor data make assumptions about how machines degrade. Additionally, sensor data from machines is noisy and often suffers from missing values in many practical settings. We propose Embed-RUL: a novel approach for RUL estimation from sensor data that does not rely on any degradation-trend assumptions, is robust to noise, and handles missing values. Embed-RUL utilizes a sequence-to-sequence model based on Recurrent Neural Networks (RNNs) to generate embeddings for multivariate time series subsequences. The embeddings for normal and degraded machines tend to be different, and are therefore found to be useful for RUL estimation. We show that the embeddings capture the overall pattern in the time series while filtering out the noise, so that the embeddings of two machines with similar operational behavior are close to each other, even when their sensor readings have significant and varying levels of noise content. We perform experiments on publicly available turbofan engine dataset and a proprietary real-world dataset, and demonstrate that Embed-RUL outperforms the previously reported state-of-the-art on several metrics.", "histories": [["v1", "Mon, 4 Sep 2017 12:15:44 GMT  (920kb,D)", "http://arxiv.org/abs/1709.01073v1", "Presented at 2nd ML for PHM Workshop at SIGKDD 2017, Halifax, Canada"], ["v2", "Fri, 6 Oct 2017 10:42:52 GMT  (892kb,D)", "http://arxiv.org/abs/1709.01073v2", "Presented at 2nd ML for PHM Workshop at SIGKDD 2017, Halifax, Canada"]], "COMMENTS": "Presented at 2nd ML for PHM Workshop at SIGKDD 2017, Halifax, Canada", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["narendhar gugulothu", "vishnu tv", "pankaj malhotra", "lovekesh vig", "puneet agarwal", "gautam shroff"], "accepted": false, "id": "1709.01073"}, "pdf": {"name": "1709.01073.pdf", "metadata": {"source": "META", "title": "Predicting Remaining Useful Life using Time Series Embeddings based on Recurrent Neural NetworksCopyright \u00a9 2017 Tata Consultancy Services Ltd. ", "authors": ["Narendhar Gugulothu", "Pankaj Malhotra", "Lovekesh Vig", "Puneet Agarwal", "Gautam Shro"], "emails": ["narendhar.g@tcs.com", "vishnu.tv@tcs.com", "malhotra.pankaj@tcs.com", "lovekesh.vig@tcs.com", "puneet.a@tcs.com", "gautam.shro@tcs.com"], "sections": [{"heading": null, "text": "KEYWORDS Recurrent Neural Networks, Remaining Useful Life, Embeddings, Multivariate Time Series Representations, Machine Health MonitoringACM Reference format: Narendhar Gugulothu, Vishnu TV, Pankaj Malhotra, Lovekesh Vig, Puneet Agarwal, Gautam Shro. 2017. Predicting Remaining Useful Life using Time Series Embeddings based on Recurrent Neural Networks1. In Proceedings of 2nd ML for PHM Workshop at Special Interest Group on Knowledge Discovery and Data Mining, Canada, August 2017 (SIGKDD), 10 pages. DOI: 10.1145 / nnnnnnnnnn"}, {"heading": "1 INTRODUCTION", "text": "This year it is more than ever before."}, {"heading": "2 RELATEDWORK", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "3 BACKGROUND", "text": "Many data-based approaches are used to estimate the health of a machine from sensor data using a health index (HI) (e.g. [34, 45]). The trend of the HI curve over time, known as the HI curve, is then used to estimate the RUL of the test instance by comparing it with the trends of failed instances. Generally, the HI curve of a test instance is compared with the HI curves of several failed instances, and the weighted average of the obtained RUL estimates from the failed instances is used to obtain the internal RUL estimate (see Section 4.3 for details). In Section 3.1, we introduce a simple approach to the HI estimate that maps the current sensor values to HI. Next, we introduce existing HI estimation techniques that use RNs to capture the temporal pa values, and an approach to measurements in Section 3.2."}, {"heading": "3.1 Degradation trend assumption based HI estimation", "text": "Consider an HI curve H = [h1, h2,.., hT], where 0 \u2264 ht \u2264 1, t = 1, 2,.., T. If a machine is healthy, ht = 1 and if a machine is about to fail or threatens to fail, ht = 0. e multiple sensor measurements xt-Rn at the time t can be used to get an estimate h-t for the actual HI value ht. One way to get this mapping is via a linear regression model: h-t = f\u03b8 (xt) = \u03b8T xt + \u03b80, where \u03b8-Rn and \u03b80-R. e parameters are estimated by minimizing \u0432 T = 1 (h-t \u2212 ht) 2, where the target HI curve can be assumed to follow an exponential degradation trend (e.g. [45])."}, {"heading": "3.2 RNNs for Machine Health Monitoring", "text": "We have the idea behind the use of RNNs for health monitoring by detecting the number of hidden units of the system by detecting the complex temporal and instantaneous dependencies between sensor series (12, 23, 26). Autocoders were used to detect interesting structures in the data by means of regulation, e.g. by adding limitations on the number of hidden units of the autocoder [29], or by adding noise to the input and formation of the network to reconstruct a denozed version of the input [44]. The key idea behind such autocoders is that the hidden representation obtains the underlying important pa."}, {"heading": "4 RUL ESTIMATION USING EMBEDDINGS", "text": "We consider a scenario in which sensor measurements are available over the operating life of one or more instances of a machine or component. We define the number of instances according to I. For an instance i-I, we consider a multi-sensor time series x (i) = {x (i) 1, x (i) 2, \u00b7, x (i) T (i)}, where T (i) is the length of the time series, x (i) t-Rn is a ndimensional vector corresponding to the measurements of the n-sensors at the time t. For a failed instance i, the length T (i) corresponds to the total service life (from beginning to end of life), while for a currently operating instance, the length T (i) corresponds to the elapsed service life up to the last available sensor value. Typically, if T (i) is large, we divide the time series into windows (partial sequences) of the winding series w."}, {"heading": "4.1 Obtaining Embeddings using RNN Encoder-Decoder", "text": "We introduce RNN encoder decoders (RNN-ED) networks based on sequence-to-sequence (seq2seq) learning frames. Generally, a seq2seq model consists of a pair of multi-layer RNNNs that are trained together: an RNN encoder and a RNN decoder. Figure 3 shows how the encoder decoder pairs work for a sample time series (i) t, given by concatenating the hidden state vectors from all levels in the encoder, s.t. z = [z) t (i) t, z (i) t, z (i)."}, {"heading": "4.2 Obtaining HI Curves using Embeddings", "text": "Here we describe how the embedding of time series sequences is used to estimate the condition of machines. As the RNN encoder captures the important embedding in the time series subsequences, the embedding obtained in this way can be used to distinguish between normal and degraded regions in the data. We maintain a series of embedding, Znorm, that correspond to the time series subsequences of the normal behavior of all instances in I. While a machine is working, its health deteriorates over time and the corresponding embedding in the subsequences tends to differ from those in Znorm. Therefore, we estimate the HI for a subsequence as follows: h (i) t = min (Hz (i) t \u2212 z \u00b2 2), year (5) e HI curve for an instance that I obtain from the HI estimate, is always given by h (i) = {h (i) w + 1,."}, {"heading": "4.3 RUL Estimation using HI Curves", "text": "We use the same approach to estimate RUL using the HI curve as in [24]. We present it here for the sake of completeness. To estimate the RUL for a test instance, the HI curve h (i) must be compared with the HI curves in H. e The initial state of a traction instance and a test instance need not be the same. We therefore allow a time delay tD when comparing the HI curve of the test instance and the traction instance.e Similarity between the HI curves of the test instance i) and a traction instance i (I) for a time delay tD is indicated by: s (i), i), i, tD) = exp (\u2212 1T (i) T (i), k (i) k \u2212 h (i) k \u2212 h (i) k (i) k + tD) 2 / \u03bb) (6) (I)."}, {"heading": "5 EXPERIMENTAL EVALUATION", "text": "We evaluate our proposed approach to RUL estimation using two sets of data: i) a publicly available C-MAPSS Turbofan Engine dataset [38], ii) a proprietary real pump dataset. We use Tensorow [1] libraries to implement the various RNN models. We present the details of the datasets in Section 5.1. In Section 5.2, we show that the results for embedding distance-based approaches to RUL estimation can be compared favorably with previously reported results using reconstruction error-based approaches [24] on the drive dataset as well as on the real pump dataset. We also evaluate the robustness of embedding distances and reconstruction error-based approaches by measuring the effect of additive random Gaussian noise in the sensor values for RUL estimation in Section 5.3."}, {"heading": "5.1 Datasets Description", "text": "We use the rst dataset of the four simulated turbofan engine datasets from the NASA Ames Prognostics Data Repository [38]. is dataset contains time series of measurements for 24 sensors for 100 train thresholds (train threshold FD001.txt) of the turbofan engine from the beginning of usage to the end of life. There are 100 test instances for which the time series before failure are truncated, the instances are currently operational and their RUL needs must be estimated (test FD001.txt). e actual RUL for the test instances are listed in RUL FD001.tx. Notably, each engine instance has an initial level of wear that the initial HI of each instance is likely to be (implied potential usefulness in Section 4.3).We select 80 train instances to train the models."}, {"heading": "5.2 Embeddings for RUL Estimation", "text": "We follow similar evaluation protocols as they are used in [24]. To our knowledge, the reconstruction error based on model, LR-ED2, reported the best performance for the RUL estimate on the engine dataset in terms of actuality score = 3. We compare the variants of the embedding distance based approach and reconstruction error based approach. We refer to the HI curve obtained using the suggested embedding distance based on approach as HIe -10 \u2212 \u2212 the best performance using the HI curve obtained variants of the embedding error based on approach in [24] as HIr. We refer to the reconstruction error based on LSTM-ED, LR-ED2 models used in [24] as Recon-RUL, Recon-LR2, and Recon-LR2, respectively. We compare the following models based on RNs for the RUL estimation task: \u2022 Embed-RUL Von-RUL: We compare this performance."}, {"heading": "5.3 Robustness of Embeddings to Noise", "text": "We evaluate the robustness of Embed-RUL and Recon-RUL for the RUL estimation by adding Gaussian noise to the sensor values. e Sensor measurement x (i) t for a test instance at any time t is corrupted by additive Gaussian noise to obtain a loud version x \"(i) t s.t. x\" (i) t | x (i) t \u0445 N (x (i) t, \u03c32I). Table 1 shows the effect of noise on performance for both motor and pump datasets. For both datasets, the standard deviation of the MSE values over the resulting noise level for Embed-RUL is much lower compared to Recon-RUL. The embedding of distance-based models is more robust compared to noise compared to reconstruction fault models. We also have a similar behavior for the motor dataset in relation to the time value (S: 841 for Embed-RUL)."}, {"heading": "6 DISCUSSION", "text": "We have proposed an approach to health monitoring by estimating the health index and remaining useful life (RUL). e The proposed approach is able to deal with several practical challenges in data-driven RUL estimation. e RNN encoder decoders (RNN-ED) are trained in an unattended manner to capture mixed-dimensional representations or embedding to capture machine behavior. e The health of a machine is then estimated by comparing the most recent embedding to the existing embedding that corresponds to normal behavior. e We found that our approach with RNN-ED-based embedding spacings is better than the previously known best approach with RNN-ED-based reconstruction errors on the engine dataset. e suggested approach also delivers better results on the real pump dataset. We have also shown that embedding distances based on UL is robust compared to noise estimates."}, {"heading": "A PERFORMANCE METRICS", "text": "We measure the performance of our models in terms of the Timeliness Score (S), Accuracy (A), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), False Positive Rate (FPR) and False Negative Rate (FNR), as in Equations 8-11. In a test example, the performance of a model is measured by the following yardsticks: S = N; i; 1 (exp (i) \u2212 R (i) between the estimated RUL (R (i) and the actual RUL (R (i). e Timeliness Score S is used to measure the performance of a model: S = N; i) = 1 (exp (i)."}, {"heading": "B BENCHMARKS ON TURBOFAN ENGINE DATASET", "text": "Below we offer a comparison of some approaches to the RUL estimate of the engine data set (Test FD001.txt): 3In [24] 4Data set referred to as MAPE1, which was simulated under similar conditions 5In contrast to this method, where the parameters of the test set are tuned to obtain the maximum S, we learn the parameters of the model using a validation set and still get a similar performance in relation to S."}], "references": [{"title": "Early Detection of Combustion Instabilities using Deep Convolutional Selective Autoencoders on Hi-speed Flame Video", "author": ["Adedotun Akintayo", "Kin Gwn Lore", "Soumalya Sarkar", "Soumik Sarkar"], "venue": "CoRR abs/1603.07839", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Deep convolutional neural network based regression approach for estimation of remaining useful life", "author": ["Giduthuri Sateesh Babu", "Peilin Zhao", "Xiao-Li Li"], "venue": "In International Conference on Database Systems for Advanced Applications", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Comparison of sensors and methodologies for e\u0082ective prognostics on railway turnout systems", "author": ["Fatih Camci", "Omer Faruk Eker", "Saim Ba\u015fkan", "Savas Konur"], "venue": "Proceedings of the Institution of Mechanical Engineers, Part F: Journal of Rail and Rapid Transit 230,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Recurrent neural networks for multivariate time series with missing values", "author": ["Zhengping Che", "Sanjay Purushotham", "Kyunghyun Cho", "David Sontag", "Yan Liu"], "venue": "arXiv preprint arXiv:1606.01865", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart Van Merri\u00ebnboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "NIST/SEMATECH e-handbook of statistical methods", "author": ["Carroll Croarkin", "Paul Tobias"], "venue": "NIST/SEMATECH", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Internet of things in industries: A survey", "author": ["Li Da Xu", "Wu He", "Shancang Li"], "venue": "IEEE Transactions on industrial informatics 10,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Semi-supervised sequence learning", "author": ["Andrew M Dai", "\u008boc V Le"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "A similarity-based prognostics approach for remaining useful life prediction", "author": ["\u00d6mer Faruk Eker", "Faith Camci", "Ian K Jennions"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Multivariate Industrial Time Series with Cyber-A\u008aack Simulation: Fault Detection Using an LSTM-based Predictive Data Model. NIPS Time Series Workshop 2016", "author": ["Pavel Filonov", "Andrey Lavrentyev", "Artem Vorontsov"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["Alan Graves", "Abdel-rahman Mohamed", "Geo\u0082rey Hinton"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Recurrent neural networks for remaining useful life estimation", "author": ["Felix O Heimes"], "venue": "In Prognostics and Health Management,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation 9,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1997}, {"title": "Ensemble of data-driven prognostic algorithms for robust prediction of remaining useful life", "author": ["Chao Hu", "Byeng D Youn", "Pingfeng Wang", "Joung Taek Yoon"], "venue": "Reliability Engineering & System Safety", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Direct Remaining Useful Life Estimation Based on Support Vector Regression", "author": ["Racha Khelif", "Brigi\u008ae Chebel-Morello", "Simon Malinowski", "Emna Laajili", "Farhat Fnaiech", "Noureddine Zerhouni"], "venue": "IEEE Transactions on Industrial Electronics 64,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2017}, {"title": "A Framework of Comnbining Deep Learning and Survival Analysis for Asset Health Management", "author": ["Linxia Liao", "Hyung-il Ahn"], "venue": "1st ACM SIGKDDWorkshop on ML for PHM", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Visualizing data using t-SNE", "author": ["Laurens van der Maaten", "Geo\u0082rey Hinton"], "venue": "Journal of Machine Learning Research 9,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "Performing Diagnostics and Prognostics On Simulated Engine Failures Using Neural Networks", "author": ["Owen B Macmann", "Timothy M Seitz", "Alireza R Behbahani", "Kelly Cohen"], "venue": "In 52nd AIAA/SAE/ASEE Joint Propulsion Conference", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "Multi-Sensor Prognostics using an Unsupervised Health Index based on LSTM Encoder-Decoder", "author": ["Pankaj Malhotra", "Vishnu TV", "Anusha Ramakrishnan", "Gaurangi Anand", "Lovekesh Vig", "Puneet Agarwal", "Gautam Shro"], "venue": "1st ACM SIGKDD Workshop on ML for PHM. arXiv preprint arXiv:1608.06154", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "TimeNet: Pre-trained deep recurrent neural network for time series classi\u0080cation", "author": ["Pankaj Malhotra", "Vishnu TV", "Lovekesh Vig", "Puneet Agarwal", "Gautam Shro"], "venue": "In 25th European Symposium on Arti\u0080cial Neural Networks, Computational Intelligence and Machine Learning", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2017}, {"title": "Long Short Term Memory Networks for Anomaly Detection in Time Series", "author": ["Pankaj Malhotra", "Lovekesh Vig", "Gautam Shro", "Puneet Agarwal"], "venue": "In ESANN, 23rd European Symposium on Arti\u0080cial Neural Networks, Computational Intelligence and Machine Learning", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Data-driven prognostic method based on Bayesian approaches for direct remaining useful life prediction", "author": ["Ahmed Mosallam", "Kamal Medjaher", "Noureddine Zerhouni"], "venue": "Journal of Intelligent Manufacturing", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "Component based data-driven prognostics for complex systems: Methodology and applications", "author": ["A Mosallam", "K Medjaher", "N Zerhouni"], "venue": "In Reliability Systems Engineering (ICRSE),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}, {"title": "Sparse autoencoder", "author": ["Andrew Ng"], "venue": "CS294A Lecture notes", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2011}, {"title": "A naive Bayes model for robust remaining useful life prediction of lithium-ion ba\u008aery", "author": ["Selina SY Ng", "Yinjiao Xing", "Kwok L Tsui"], "venue": "Applied Energy", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2014}, {"title": "A modi\u0080ed echo state network based remaining useful life estimation approach", "author": ["Yu Peng", "Hong Wang", "Jianmin Wang", "Datong Liu", "Xiyuan Peng"], "venue": "In IEEE Conference on Prognostics and Health Management (PHM),", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2012}, {"title": "Dropout improves recurrent neural networks for handwriting recognition", "author": ["Vu Pham", "\u008c\u00e9odore Bluche", "Christopher Kermorvant", "J\u00e9r\u00f4me Louradour"], "venue": "In Frontiers in Handwriting Recognition (ICFHR),", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2014}, {"title": "Robust performance degradation assessment methods for enhanced rolling element bearing prognostics", "author": ["Hai Qiu", "Jay Lee", "Jing Lin", "Gang Yu"], "venue": "Advanced Engineering Informatics 17,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2003}, {"title": "Investigating computational geometry for failure prognostics", "author": ["Emmanuel Ramasso"], "venue": "International Journal of Prognostics and Health Management 5,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2014}, {"title": "Joint prediction of continuous and discrete states in time-series based on belief functions", "author": ["Emmanuel Ramasso", "Michele Rombaut", "Noureddine Zerhouni"], "venue": "Cybernetics, IEEE Transactions on 43,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2013}, {"title": "Applying Deep Learning for Prognostic Health Monitoring of Aerospace and Building Systems", "author": ["Kishore K Reddy", "Vivek Venugopalan", "Michael J Giering"], "venue": "1st ACM SIGKDD Workshop on ML for PHM", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2016}, {"title": "Metrics for evaluating performance of prognostic techniques", "author": ["Abhinav Saxena", "Jose Celaya", "Edward Balaban", "Kai Goebel", "Bhaskar Saha", "Sankalita Saha", "Mark Schwabacher"], "venue": "In Prognostics and health management,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2008}, {"title": "Turbofan Engine Degradation Simulation Data Set", "author": ["A Saxena", "K Goebel"], "venue": "NASA Ames Prognostics Data Repository", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2008}, {"title": "Damage propagation modeling for aircra\u0089 engine run-to-failure simulation", "author": ["Abhinav Saxena", "Kai Goebel", "Don Simon", "Neil Eklund"], "venue": "In Prognostics and Health Management,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2008}, {"title": "Remaining useful life estimation\u2013A review on the statistical data driven approaches", "author": ["Xiao-Sheng Si", "Wenbin Wang", "Chang-Hua Hu", "Dong-Hua Zhou"], "venue": "European journal of operational research 213,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2011}, {"title": "Dropout: a simple way to prevent neural networks from over\u0080\u008aing", "author": ["Nitish Srivastava", "Geo\u0082rey E Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "venue": "Journal of Machine Learning Research 15,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2014}, {"title": "Unsupervised learning of video representations using lstms", "author": ["Nitish Srivastava", "Elman Mansimov", "Ruslan Salakhudinov"], "venue": "In International Conference on Machine Learning", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "\u008boc V Le"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2014}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["Pascal Vincent", "Hugo Larochelle", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "venue": "In Proceedings of the 25th international conference on Machine learning", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2008}, {"title": "A similarity-based prognostics approach for remaining useful life estimation of engineered systems", "author": ["Tianyi Wang", "Jianbo Yu", "David Siegel", "Jay Lee"], "venue": "In Prognostics and Health Management,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2008}, {"title": "On accurate and reliable anomaly detection for gas turbine combustors: A deep learning approach", "author": ["Weizhong Yan", "Lijie Yu"], "venue": "In Proceedings of the Annual Conference of the Prognostics and Health Management Society", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2015}, {"title": "Machine health monitoring with LSTM networks", "author": ["Rui Zhao", "Jinjiang Wang", "Ruqiang Yan", "Kezhi Mao"], "venue": "In Sensing Technology (ICST),", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2016}, {"title": "Deep Learning and Its Applications to Machine Health Monitoring: A Survey", "author": ["Rui Zhao", "Ruqiang Yan", "Zhenghua Chen", "Kezhi Mao", "Peng Wang", "Robert X Gao"], "venue": null, "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2016}], "referenceMentions": [{"referenceID": 19, "context": "We perform experiments on publicly available turbofan engine dataset and a proprietary real-world dataset, and demonstrate that Embed-RUL outperforms the previously reported [24] state-of-the-art on several metrics.", "startOffset": 174, "endOffset": 178}, {"referenceID": 7, "context": "It is quite common in the current era of the \u2018Industrial Internet of \u008cings\u2019 [9] for a large number of sensors to be installed for monitoring the operational behavior of machines.", "startOffset": 76, "endOffset": 79}, {"referenceID": 3, "context": ", exponential degradation [5, 8, 34, 39, 45].", "startOffset": 26, "endOffset": 44}, {"referenceID": 6, "context": ", exponential degradation [5, 8, 34, 39, 45].", "startOffset": 26, "endOffset": 44}, {"referenceID": 29, "context": ", exponential degradation [5, 8, 34, 39, 45].", "startOffset": 26, "endOffset": 44}, {"referenceID": 34, "context": ", exponential degradation [5, 8, 34, 39, 45].", "startOffset": 26, "endOffset": 44}, {"referenceID": 40, "context": ", exponential degradation [5, 8, 34, 39, 45].", "startOffset": 26, "endOffset": 44}, {"referenceID": 19, "context": "\u2022 Our approach compares favorably to previous benchmarks for RUL estimation [24] on the turbofan engine dataset [38] as well as on a real-world pump dataset (refer Section 5.", "startOffset": 76, "endOffset": 80}, {"referenceID": 33, "context": "\u2022 Our approach compares favorably to previous benchmarks for RUL estimation [24] on the turbofan engine dataset [38] as well as on a real-world pump dataset (refer Section 5.", "startOffset": 112, "endOffset": 116}, {"referenceID": 35, "context": "A review of these approaches can be found in [40].", "startOffset": 45, "endOffset": 49}, {"referenceID": 9, "context": "[11, 19] propose estimating RUL directly by calculating the similarity between the sensors without deriving any health estimates.", "startOffset": 0, "endOffset": 8}, {"referenceID": 15, "context": "Similarly, Support Vector Regression [18], RNNs [14], Deep Convolutional Neural Networks [3] have been proposed to estimate the RUL directly by modeling the relations among the sensors without estimating the health of the machines.", "startOffset": 37, "endOffset": 41}, {"referenceID": 12, "context": "Similarly, Support Vector Regression [18], RNNs [14], Deep Convolutional Neural Networks [3] have been proposed to estimate the RUL directly by modeling the relations among the sensors without estimating the health of the machines.", "startOffset": 48, "endOffset": 52}, {"referenceID": 1, "context": "Similarly, Support Vector Regression [18], RNNs [14], Deep Convolutional Neural Networks [3] have been proposed to estimate the RUL directly by modeling the relations among the sensors without estimating the health of the machines.", "startOffset": 89, "endOffset": 92}, {"referenceID": 28, "context": "Robust RUL Estimation: Wavelet \u0080lters have been proposed to handle noise for robust performance degradation assessment in [33].", "startOffset": 122, "endOffset": 126}, {"referenceID": 14, "context": "In [16], ensemble of models is used to ensure that predictions are robust.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "Long Short Term Memory (LSTM) [15] based encoders trained using encoder-decoder framework have been proposed to learn representations of video sequences [42].", "startOffset": 30, "endOffset": 34}, {"referenceID": 37, "context": "Long Short Term Memory (LSTM) [15] based encoders trained using encoder-decoder framework have been proposed to learn representations of video sequences [42].", "startOffset": 153, "endOffset": 157}, {"referenceID": 8, "context": "Pre-trained LSTM Encoder based on autoencoders are used to initialize networks for classi\u0080cation tasks and are shown to achieve improved performance [10] for text applications.", "startOffset": 149, "endOffset": 153}, {"referenceID": 5, "context": "Gated Recurrent Units (GRUs) [7] based encoder named Timenet [25] has been recently proposed to obtain embeddings for time series from several domains.", "startOffset": 29, "endOffset": 32}, {"referenceID": 20, "context": "Gated Recurrent Units (GRUs) [7] based encoder named Timenet [25] has been recently proposed to obtain embeddings for time series from several domains.", "startOffset": 61, "endOffset": 65}, {"referenceID": 41, "context": "Stacked denoising autoencoders have been used to learn hierarchical features from sensor data in [46].", "startOffset": 97, "endOffset": 101}, {"referenceID": 43, "context": "Many of these architectures and applications of deep learning to machine health monitoring have been surveyed in [48].", "startOffset": 113, "endOffset": 117}, {"referenceID": 0, "context": "An end-to-end convolutional selective autoencoder for early detection and monitoring of combustion instabilites in high speed \u0083ame video frames was proposed in [2].", "startOffset": 160, "endOffset": 163}, {"referenceID": 16, "context": "A combination of deep learning and survival analysis for asset health management has been proposed in [20] using sequential data by stacking a LSTM layer, a feed forward layer and a survival model layer to arrive at the asset failure probability.", "startOffset": 102, "endOffset": 106}, {"referenceID": 31, "context": "Deep belief networks and autoencoders have been used for health monitoring of aerospace and building systems in [36].", "startOffset": 112, "endOffset": 116}, {"referenceID": 42, "context": "Predicting milling machine tool wear from sensor data has been proposed using deep LSTM networks in [47].", "startOffset": 100, "endOffset": 104}, {"referenceID": 29, "context": ", [34, 45]).", "startOffset": 2, "endOffset": 10}, {"referenceID": 40, "context": ", [34, 45]).", "startOffset": 2, "endOffset": 10}, {"referenceID": 40, "context": ", [45]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 5, "context": "RNNs, especially those based on LSTM units or GRUs have been successfully used to achieve state-of-the-art results on sequence modeling tasks such as machine translation [7] and speech recognition [13].", "startOffset": 170, "endOffset": 173}, {"referenceID": 11, "context": "RNNs, especially those based on LSTM units or GRUs have been successfully used to achieve state-of-the-art results on sequence modeling tasks such as machine translation [7] and speech recognition [13].", "startOffset": 197, "endOffset": 201}, {"referenceID": 10, "context": "health monitoring from multi-sensor time series data [12, 23, 26].", "startOffset": 53, "endOffset": 65}, {"referenceID": 21, "context": "health monitoring from multi-sensor time series data [12, 23, 26].", "startOffset": 53, "endOffset": 65}, {"referenceID": 24, "context": "in the data by means of regularization such as by adding constraints on the number of hidden units of the autoencoder [29], or by adding noise to the input and training the network to reconstruct a denoised version of the input [44].", "startOffset": 118, "endOffset": 122}, {"referenceID": 39, "context": "in the data by means of regularization such as by adding constraints on the number of hidden units of the autoencoder [29], or by adding noise to the input and training the network to reconstruct a denoised version of the input [44].", "startOffset": 228, "endOffset": 232}, {"referenceID": 19, "context": "RNN autoencoders have been shown to be useful for RUL estimation [24] in which the RNN-based model learns to capture the behavior of a machine by learning to reconstruct multivariate time series corresponding to normal behavior in an unsupervised manner.", "startOffset": 65, "endOffset": 69}, {"referenceID": 2, "context": "We propose to learn robust \u0080xed-dimensional representations for multi-sensor time series data via sequence-to-sequence [4, 43] autoencoders based on RNNs.", "startOffset": 119, "endOffset": 126}, {"referenceID": 38, "context": "We propose to learn robust \u0080xed-dimensional representations for multi-sensor time series data via sequence-to-sequence [4, 43] autoencoders based on RNNs.", "startOffset": 119, "endOffset": 126}, {"referenceID": 5, "context": "We use Gated Recurrent Units [7] in the hidden layers of sequence-to-sequence autoencoder.", "startOffset": 29, "endOffset": 32}, {"referenceID": 27, "context": "Dropout is used for regularization [32, 41] and is applied only to the non-recurrent connections, ensuring information \u0083ow across timesteps.", "startOffset": 35, "endOffset": 43}, {"referenceID": 36, "context": "Dropout is used for regularization [32, 41] and is applied only to the non-recurrent connections, ensuring information \u0083ow across timesteps.", "startOffset": 35, "endOffset": 43}, {"referenceID": 19, "context": "2Unlike the proposed approach, Recon-RUL [24] uses time series subsequences only from normal operation of the machine.", "startOffset": 41, "endOffset": 45}, {"referenceID": 19, "context": "\u008cis input is the output of the decoder RNN at the previous time step, as used in [24].", "startOffset": 81, "endOffset": 85}, {"referenceID": 20, "context": "\u008cis approach of learning robust embeddings or representations for time series has been shown to be useful for time series classi\u0080cation in [25].", "startOffset": 139, "endOffset": 143}, {"referenceID": 4, "context": "We include masking and delta vectors as additional inputs to the RNN-ED at each time instant, (as in [6]).", "startOffset": 101, "endOffset": 104}, {"referenceID": 19, "context": "We use the same approach for estimating RUL from the HI curve as in [24].", "startOffset": 68, "endOffset": 72}, {"referenceID": 33, "context": "We evaluate our proposed approach for RUL estimation on two datasets: i) a publicly available C-MAPSS Turbofan Engine dataset [38], ii) a proprietary real-world pump dataset.", "startOffset": 126, "endOffset": 130}, {"referenceID": 19, "context": "2, we show that the results for embedding distance based approaches for RUL estimation compare favorably to the previously reported results using reconstruction error based approaches [24] on the engine dataset , as well as on the real-world pump dataset.", "startOffset": 184, "endOffset": 188}, {"referenceID": 33, "context": "We use the \u0080rst dataset from the four simulated turbofan engine datasets from the NASA Ames Prognostics Data Repository [38].", "startOffset": 120, "endOffset": 124}, {"referenceID": 32, "context": "A description of the performance metrics used for evaluation (taken from [37]) is provided in Appendix A.", "startOffset": 73, "endOffset": 77}, {"referenceID": 19, "context": "We follow similar evaluation protocol as used in [24].", "startOffset": 49, "endOffset": 53}, {"referenceID": 19, "context": "2), and the HI curve obtained using the reconstrcution error based approach in [24] as HIr .", "startOffset": 79, "endOffset": 83}, {"referenceID": 19, "context": "Here, we refer the reconstruction error based LSTM-ED, LR-ED1 and LR-ED2 models reported in [24], as Recon-RUL, Recon-LR1, and Recon-LR2, respectively.", "startOffset": 92, "endOffset": 96}, {"referenceID": 12, "context": ") is directly used to predict RUL (similar to [14])", "startOffset": 46, "endOffset": 50}, {"referenceID": 34, "context": "We use \u03c41=13, \u03c42=10 as proposed in [39] for this dataset (refer Equations 8-11 in Appendix A).", "startOffset": 35, "endOffset": 39}, {"referenceID": 17, "context": "We use t-SNE [21] to map the embeddings to 2-D space.", "startOffset": 13, "endOffset": 17}], "year": 2017, "abstractText": "We consider the problem of estimating the remaining useful life (RUL) of a system or a machine from sensor data. Many approaches for RUL estimation based on sensor data make assumptions about how machines degrade. Additionally, sensor data from machines is noisy and o\u0089en su\u0082ers from missing values in many practical se\u008aings. We propose Embed-RUL: a novel approach for RUL estimation from sensor data that does not rely on any degradation-trend assumptions, is robust to noise, and handles missing values. EmbedRUL utilizes a sequence-to-sequence model based on Recurrent Neural Networks (RNNs) to generate embeddings for multivariate time series subsequences. \u008ce embeddings for normal and degraded machines tend to be di\u0082erent, and are therefore found to be useful for RUL estimation. We show that the embeddings capture the overall pa\u008aern in the time series while \u0080ltering out the noise, so that the embeddings of two machines with similar operational behavior are close to each other, even when their sensor readings have signi\u0080cant and varying levels of noise content. We perform experiments on publicly available turbofan engine dataset and a proprietary real-world dataset, and demonstrate that Embed-RUL outperforms the previously reported [24] state-of-the-art on several metrics.", "creator": "LaTeX with hyperref package"}}}