{"id": "1709.01186", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Sep-2017", "title": "Learning Neural Word Salience Scores", "abstract": "Measuring the salience of a word is an essential step in numerous NLP tasks. Heuristic approaches such as tfidf have been used so far to estimate the salience of words. We propose \\emph{Neural Word Salience} (NWS) scores, unlike heuristics, are learnt from a corpus. Specifically, we learn word salience scores such that, using pre-trained word embeddings as the input, can accurately predict the words that appear in a sentence, given the words that appear in the sentences preceding or succeeding that sentence. Experimental results on sentence similarity prediction show that the learnt word salience scores perform comparably or better than some of the state-of-the-art approaches for representing sentences on benchmark datasets for sentence similarity, while using only a fraction of the training and prediction times required by prior methods. Moreover, our NWS scores positively correlate with psycholinguistic measures such as concreteness, and imageability implying a close connection to the salience as perceived by humans.", "histories": [["v1", "Mon, 4 Sep 2017 22:52:59 GMT  (154kb,D)", "http://arxiv.org/abs/1709.01186v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["krasen samardzhiev", "andrew gargett", "danushka bollegala"], "accepted": false, "id": "1709.01186"}, "pdf": {"name": "1709.01186.pdf", "metadata": {"source": "CRF", "title": "Learning Neural Word Salience Scores", "authors": ["Krasen Samardzhiev", "Andrew Gargett"], "emails": ["krasensam@gmail.com", "andrew.gargett@stfc.ac.uk", "danushka@liverpool.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "2 Related Work", "text": "This year it is more than ever before."}, {"heading": "3 Neural Word Salience Scores", "text": "We consider a vocabulary V of the words W-V, in which we make a judgment about ourselves. (...) We assume that we will be able to understand the terms W (...) and S (...) and S (...), that we will understand the terms W (...) and S (...) in the terms W (...) and S (...) and S (...) in the terms W (...) and S (...) and S (...) in the terms W (...) and S (...) and S (...) and S (...) in the terms W. (...) and S (...) and S (...) in the terms W (...) and S (...) and S (...) in the terms S (...) and S (...), S (...), S (...), S (...) and S (...) and S (...) and S (...) in the terms S (... and S (...) and S (...)."}, {"heading": "4 Experiments", "text": "We use the Toronto books corpus3 as a training dataset. This corpus contains 81 million sets of 11,038 books and has been used as a training dataset in several previous work on embedding sentences. We convert all sentences into lowercase letters and tokenises using the Python NLTK4 punctuation stokenizer. Beyond tokenization, no further pre-processing is required. The proposed method is implemented with TensorFlow5 and executed on an NVIDIA Tesla K40c 2880 GPU. Source code is submitted as a supplement and published on paper after adoption."}, {"heading": "4.1 Measuring Semantic Textual Similarity", "text": "It is difficult to evaluate the accuracy of the word validity scores by direct manual verification. In addition, there are no datasets in which human annotators have manually evaluated words for their validity. Therefore, we resort to extrinsic assessments, in which we first (1) embed the sentences for a given sentence with recited words and calculate the NWS scores using the proposed method. Next, we measure the semantic textual similarity between two sentences by the cosmic similarity between the corresponding sentence embeddings. Finally, we calculate the correlation between human similarities for sentence pairs in benchmark datasets for STS and the similarity by the above method. If there is a high degree of correlation between the sentence similarities using the NWS2It is theoretically possible that two non-adjacent sentences may be similar, but the probability of this event is small and certainly ignored."}, {"heading": "4.2 Correlation with Psycholinguistic Scores", "text": "Before working in psycholinguistics, it is shown that there is a close link between the emotions that a person feels and the words he reads in a text. Valence (the pleasantness of the stimulus), arousal (the density of emotions evoked by the stimulus) and dominance (the degree of control exerted by the stimulus) contribute to how the meaning of words affects human psychology, and often refer to the affective meaning of words. [28] They show that by using SGNS embedding as features in a kNearest Neighbour Classifier, it is possible to express the affective meanings of words precisely too extrapolitically. Furthermore, the psycholinguistic properties of words such as concreteness (how \"tangible\" the word refers to) and imagery (the intensity with which a word is characterized) are evident."}, {"heading": "5 Conclusion", "text": "We proposed a method for learning Neural Word Salience scores from a sentence corpus, without manual data comments. To evaluate the learned Salience scores, we calculated sentence embeddings as a linearly weighted sum compared to pre-trained word embeddings. Our experimental results show that the proposed NWS scores exceed the basic methods, previously proposed word alience scores, and sentence embeddings methods on a series of benchmark data sets selected from past SemEval STS tasks. In addition, the NWS scores show interesting correlations with the perceived meaning of words indicated by the concreteness and pictorial quality of psycholinguistic evaluations."}], "references": [{"title": "Fine-grained analysis of sentence embeddings using auxiliary prediction tasks", "author": ["Y. Adi", "E. Kermany", "Y. Belinkov", "O. Lavi", "Y. Goldberg"], "venue": "arXiv", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Semeval-2015 task 2: Semantic textual similarity", "author": ["E. Agirre", "C. Banea", "C. Cardie", "D. Cer", "M. Diab", "A. Gonzalez-Agirre", "W. Guo", "I. Lopez- Gazpio", "M. Martxalar", "R. Mihalcea", "G. Rigau", "L. Uria", "J.M. Wiebe"], "venue": "english, spanish and pilot on interpretability. In Proc. of SemEval, pages 252 \u2013 263", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Semeval-2014 task 10: Multilingual semantic textual similarity", "author": ["E. Agirre", "C. Banea", "C. Cardie", "D. Cer", "M. Diab", "A. Gonzalez-Agirre", "W. Guo", "R. Mihalcea", "G. Rigau", "J. Weibe"], "venue": "Proc. of the 8th International Workshop on Semantic Evaluation (SemEval), pages 81\u201391", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Semeval-2012 task 6: A pilot on semantic textual similarity", "author": ["E. Agirre", "D. Cer", "M. Diab", "A. Gonzalez-Agirre"], "venue": "Proc. of the first Joint Conference on Lexical and Computational Semantics (*SEM), pages 385 \u2013 393", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "shared task: Semantic textual similarity", "author": ["E. Agirre", "D. Cer", "M. Diab", "A. Gonzalez-Agirre", "W. Guo"], "venue": "Proc. of the Second Joint Conference on Lexical and Computational Semantics (*SEM):, pages 32\u201343", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "When and why are log-linear models self-normalizing? In Proc", "author": ["J. Andreas", "D. Klein"], "venue": "of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 244\u2013249", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "A simple but tough-to-beat baseline for sentence embeddings", "author": ["S. Arora", "Y. Liang", "T. Ma"], "venue": "Proc. of International Conference on Learning Representations (ICLR)", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2017}, {"title": "A comparison of vector-based representations for semantic composition", "author": ["W. Blacoe", "M. Lapata"], "venue": "Proc. of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 546\u2013556", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Websim: A web-based semantic similarity measure", "author": ["D. Bollegala", "Y. Matsuo", "M. Ishizuka"], "venue": "Proc. of 21st Annual Conference of the Japanese Society of Artitificial Intelligence, pages 757 \u2013 766", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "Www sits the sat: Measuring relational similarity on the web", "author": ["D. Bollegala", "Y. Matsuo", "M. Ishizuka"], "venue": "Proc. of ECAI\u201908, pages 333\u2013337", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "A machine learning approach to sentence ordering for multidocument summarization and its evaluation", "author": ["D. Bollegala", "N. Okazaki", "M. Ishizuka"], "venue": "Proc. of International Joint Conferences in Natural Language Processing, pages 624 \u2013 635. Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "A preference learning approach to sentence ordering for multi-document summarization", "author": ["D. Bollegala", "N. Okazaki", "M. Ishizuka"], "venue": "Information Sciences, 217:78 \u2013 95", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Indexing by latent semantic analysis", "author": ["S. Deerwester", "S.T. Dumais", "G.W. Furnas", "T.K. Landauer", "R. Harshman"], "venue": "JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE, 41(6):391\u2013407", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1990}, {"title": "Cross-language latent relational search: Mapping knowledge across languages", "author": ["N.T. Duc", "D. Bollegala", "M. Ishizuka"], "venue": "Proc. of the Twenty-Fifth AAAI Conference on Artificial Intelligence, pages 1237 \u2013 1242", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "Object-based saliency as a predictor of attention in visual tasks", "author": ["M. Dziemianko", "A. Clarke", "F. Keller"], "venue": "Proc. of the 35thth Annual Conference of the Cognitive Science Society, pages 2237\u20132242", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Frequency distribution of the values of the correlation coefficient in samples of an indefinitely large population", "author": ["R.A. Fisher"], "venue": "Biometrika, 10(4):507\u2013521", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1915}, {"title": "Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics", "author": ["M.U. Gutmann", "A. Hyv\u00e4rinen"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Modeling human reading with neural attention", "author": ["M. Hahn", "F. Keller"], "venue": "Proc. of Empirical Methods in Natural Language Processing (EMNLP), pages 85\u201395", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "Pairwise word interaction modeling with deep neural networks for semantic similarity measurement", "author": ["H. He", "J. Lin"], "venue": "Proc. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 937\u2013948", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}, {"title": "A semi-supervised approach to improve classification of infrequent discourse relations using feature vector extension", "author": ["H. Hernault", "D. Bollegala", "M. Ishizuka"], "venue": "Empirical Methods in Natural Language Processing, pages 399 \u2013 409", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "A sequential model for discourse segmentation", "author": ["H. Hernault", "D. Bollegala", "M. Ishizuka"], "venue": "International Conference on Intelligence Text Processing and Computational Linguistics (CICLing), pages 315 \u2013 326", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning disributed representations of sentences from unlabelled data", "author": ["F. Hill", "K. Cho", "A. Korhonen"], "venue": "Proc. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1367\u20131377", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2016}, {"title": "Text categorization with support vector machines: Learning with many relevant features", "author": ["T. Joachims"], "venue": "Proc. of the European Conference on Machine Learning (ECML), pages 137\u2013142", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1998}, {"title": "A statistical interpretation of term specificity and its application in retrieval", "author": ["K.S. Jones"], "venue": "Journal of Documentation, 28:11\u201321", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1972}, {"title": "and M", "author": ["T. Kenter", "A. Borisov"], "venue": "de Rijke. Siamese cbow: Optimizing word embeddings for sentence representations. In Proc, of the Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 941\u2013951", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2016}, {"title": "Skipthought vectors", "author": ["R. Kiros", "Y. Zhu", "R. Salakhutdinov", "R.S. Zemel", "A. Torralba", "R. Urtasun", "S. Fidler"], "venue": "Proc. of Advances in Neural Information Processing Systems (NIPS), pages 3276\u20133284", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "How useful are corpus-based methods for extrapolating psycholinguistic variables? The Quarterly Journal of Experimental Pscychology", "author": ["P. Mandera", "E. Keuleers", "M. Brysbaret"], "venue": "68(8):1623\u20131642", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Vector-based models of semantic composition", "author": ["J. Mitchell", "M. Lapata"], "venue": "Proc. of Annual Meeting of the Association for Computational Linguistics, pages 236 \u2013 244", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}, {"title": "An adaptive differential evolution algorithm", "author": ["N. Noman", "D. Bollegala", "H. Iba"], "venue": "Proc. of IEEE Congress on Evolutionary Computation (CEC), pages 2229\u20132236", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "Inferring psycholinguistic properties of words", "author": ["G.H. Paetzold", "L. Specia"], "venue": "Proc. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 435\u2013440", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2016}, {"title": "Overview of the okapi projects", "author": ["S.E. Robertson"], "venue": "Journal of Documentation, 53(1):3 \u2013 7", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1997}, {"title": "Introduction to Modern Information Retreival", "author": ["G. Salton", "C. Buckley"], "venue": "McGraw-Hill Book Company", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1983}, {"title": "Semi-supervised recursive autoencoders for predicting sentiment distributions", "author": ["R. Socher", "J. Pennington", "E.H. Huang", "A.Y. Ng", "C.D. Manning"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2011}, {"title": "Literal and metaphorical sense identification through concrete and abstract context", "author": ["P.D. Turney", "Y. Neuman", "D. Assaf", "Y. Cohen"], "venue": "Proc. of Empirical Methods in Natural Language Processing (EMNLP), pages 27 \u2013 31", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2011}, {"title": "Cse: Conceptutal sentence embeddings based on attention model", "author": ["Y. Wang", "H. Huang", "C. Feng", "Q. Zhou", "J. Gu", "X. Gao"], "venue": "Proc. of Annual Meeting of the Association for Computational Linguistics, pages 505\u2013515", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2016}, {"title": "Norms of valence", "author": ["A.B. Warriner", "V. Kuperman", "M. Brysbaret"], "venue": "arousal, and dominance for 13,915 enlish lemmas. Behavior Research Methods, 45(4):1191\u20131207", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2013}, {"title": "Towards universal paraphrastic sentence embeddings", "author": ["J. Wieting", "M. Bansal", "K. Gimpel", "K. Livescu"], "venue": "Proc. of International Conference on Learning Representations (ICLR)", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2016}, {"title": "Abcnn: Attention-based convolutional neural network for modeling sentence pairs", "author": ["W. Yin", "H. Sch\u00fctze", "B. Xiang", "B. Zhou"], "venue": "Transactions of Association for Computational Linguistics, pages 259\u2013272", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 32, "context": "have limited contributions towards the overall meaning of a document and are often filtered out as stop words in information retrieval systems [33].", "startOffset": 143, "endOffset": 147}, {"referenceID": 6, "context": "If we can accurately compute the salience of words, then we can develop better representations of texts that can be used in downstream NLP tasks such as similarity measurement [7] or text (e.", "startOffset": 176, "endOffset": 179}, {"referenceID": 33, "context": "sentiment, entailment) classification [34].", "startOffset": 38, "endOffset": 42}, {"referenceID": 24, "context": "As described later in section 2, existing methods for detecting word salience can be classified into two groups: (a) lexicon-based filtering methods such as stop word lists, or (b) word frequency-based heuristics such as the popular term-frequency inverse document frequency (tfidf) [25] measure and its variants.", "startOffset": 283, "endOffset": 287}, {"referenceID": 22, "context": "This design choice differentiates our work from previously proposed sentence embedding learning methods that jointly learn word embeddings as well as sentence embeddings [23, 27, 26].", "startOffset": 170, "endOffset": 182}, {"referenceID": 26, "context": "This design choice differentiates our work from previously proposed sentence embedding learning methods that jointly learn word embeddings as well as sentence embeddings [23, 27, 26].", "startOffset": 170, "endOffset": 182}, {"referenceID": 25, "context": "This design choice differentiates our work from previously proposed sentence embedding learning methods that jointly learn word embeddings as well as sentence embeddings [23, 27, 26].", "startOffset": 170, "endOffset": 182}, {"referenceID": 3, "context": "We use the NWS scores to compute sentence embeddings and measure the similarity between two sentences using 18 benchmark datasets for semantic textual similarity in past SemEval tasks [4].", "startOffset": 184, "endOffset": 187}, {"referenceID": 32, "context": "Word salience scores have long been studied in the information retrieval community [33].", "startOffset": 83, "endOffset": 87}, {"referenceID": 31, "context": "Word salience scores based on term frequency, document frequency, and document length have been proposed such as tfidf and BM25 [32].", "startOffset": 128, "endOffset": 132}, {"referenceID": 7, "context": "Consequently, compositional approaches for computing sentence-level semantic representations from word-level semantic representations have used numerous linear algebraic operators such as vector addition, element-wise multiplication, multiplying by a matrix or a tensor [8, 29].", "startOffset": 270, "endOffset": 277}, {"referenceID": 28, "context": "Consequently, compositional approaches for computing sentence-level semantic representations from word-level semantic representations have used numerous linear algebraic operators such as vector addition, element-wise multiplication, multiplying by a matrix or a tensor [8, 29].", "startOffset": 270, "endOffset": 277}, {"referenceID": 26, "context": "For example, skip-thought vectors [27] use bi-directional LSTMs to predict the words in the order they appear in the previous and next sentences given the current sentence.", "startOffset": 34, "endOffset": 38}, {"referenceID": 6, "context": "Although skip-thought vectors have shown superior performances in supervised tasks, its performance on unsupervised tasks has been sub-optimal [7].", "startOffset": 143, "endOffset": 146}, {"referenceID": 22, "context": "FastSent [23] was proposed as an alternative lightweight approach for sentence embedding where a softmax objective is optimised to predict the occurrences of words in the next and the previous sentences, ignoring the ordering of the words in the sentence.", "startOffset": 9, "endOffset": 13}, {"referenceID": 6, "context": "For example, [7] proposed a method to find the optimal weights for combining word embeddings when creating sentence embeddings using unigram probabilities, by maximising the likelihood of the occurrences of words in a corpus.", "startOffset": 13, "endOffset": 16}, {"referenceID": 25, "context": "Siamese CBOW [26] learns word embeddings such that we can accurately compute sentence embeddings by averaging the word embeddings.", "startOffset": 13, "endOffset": 17}, {"referenceID": 0, "context": "Although averaging is an order insensitive operator, [1] empirically showed that it can accurately predict the content and word order in sentences.", "startOffset": 53, "endOffset": 56}, {"referenceID": 18, "context": "Instead of considering all words equally for sentence embedding purposes, attention-based models [19, 39, 36] learn the amount of weight (attention) we must assign to each word in a given context.", "startOffset": 97, "endOffset": 109}, {"referenceID": 38, "context": "Instead of considering all words equally for sentence embedding purposes, attention-based models [19, 39, 36] learn the amount of weight (attention) we must assign to each word in a given context.", "startOffset": 97, "endOffset": 109}, {"referenceID": 35, "context": "Instead of considering all words equally for sentence embedding purposes, attention-based models [19, 39, 36] learn the amount of weight (attention) we must assign to each word in a given context.", "startOffset": 97, "endOffset": 109}, {"referenceID": 19, "context": "However, unlike sentence embedding learning methods that do not learn word salience scores [20, 39] , our goal in this paper is to learn word salience scores and not sentence embeddings.", "startOffset": 91, "endOffset": 99}, {"referenceID": 38, "context": "However, unlike sentence embedding learning methods that do not learn word salience scores [20, 39] , our goal in this paper is to learn word salience scores and not sentence embeddings.", "startOffset": 91, "endOffset": 99}, {"referenceID": 25, "context": "Moreover, our work differs from Siamese CBOW [26] in that we do not learn word embeddings but take pretrained word embeddings as the input for learning word salience scores.", "startOffset": 45, "endOffset": 49}, {"referenceID": 6, "context": "NWS scores we learn in this paper are also different from the salience scores learnt by [7] because they do not constrain their word salience scores such that they can be used to predict the words that occur in adjacent sentences.", "startOffset": 88, "endOffset": 91}, {"referenceID": 5, "context": "Ideally, the normalisation term in the denominator in the softmax must be taken over all the sentences Sk in the corpus [6].", "startOffset": 120, "endOffset": 123}, {"referenceID": 17, "context": "Therefore, following noise-contrastive estimation [18], we approximate the normalisation term using a randomly sampled set of K sentences, where K is typically less than 10.", "startOffset": 50, "endOffset": 54}, {"referenceID": 14, "context": "01 and subsequently scheduled by AdaGrad [15].", "startOffset": 41, "endOffset": 45}, {"referenceID": 3, "context": "As shown in Table 1, we use 18 benchmark datasets from SemEval STS tasks from years 2012 [4], 2013 [5], 2014 [3], and 2015 [2].", "startOffset": 89, "endOffset": 92}, {"referenceID": 4, "context": "As shown in Table 1, we use 18 benchmark datasets from SemEval STS tasks from years 2012 [4], 2013 [5], 2014 [3], and 2015 [2].", "startOffset": 99, "endOffset": 102}, {"referenceID": 2, "context": "As shown in Table 1, we use 18 benchmark datasets from SemEval STS tasks from years 2012 [4], 2013 [5], 2014 [3], and 2015 [2].", "startOffset": 109, "endOffset": 112}, {"referenceID": 1, "context": "As shown in Table 1, we use 18 benchmark datasets from SemEval STS tasks from years 2012 [4], 2013 [5], 2014 [3], and 2015 [2].", "startOffset": 123, "endOffset": 126}, {"referenceID": 16, "context": "We use the Fisher transformation [17] to test for the statistical significance of Pearson correlation coefficients.", "startOffset": 33, "endOffset": 37}, {"referenceID": 23, "context": "Following the success of Inverse Document Frequency (IDF) in filtering out high frequent words in text classification tasks [24], we define Inverse Sentence Frequency (ISF) of a word as the reciprocal of the number of sentences in which that word appears in a corpus.", "startOffset": 124, "endOffset": 128}, {"referenceID": 6, "context": "SMOOTH is the unigram probabilitybased smoothing method proposed by [7].", "startOffset": 68, "endOffset": 71}, {"referenceID": 26, "context": "7 For reference purposes we show the level of performance we would obtain if we had used sentence embedding methods such as, skip-thought [27], and SiameseCBOW [26].", "startOffset": 138, "endOffset": 142}, {"referenceID": 25, "context": "7 For reference purposes we show the level of performance we would obtain if we had used sentence embedding methods such as, skip-thought [27], and SiameseCBOW [26].", "startOffset": 160, "endOffset": 164}, {"referenceID": 26, "context": "Because [27] did not report results for skip-thought on all 18 benchmark datasets used here, we report the re-evaluation of skip-thought on all 18 benchmark datasets by [38].", "startOffset": 8, "endOffset": 12}, {"referenceID": 37, "context": "Because [27] did not report results for skip-thought on all 18 benchmark datasets used here, we report the re-evaluation of skip-thought on all 18 benchmark datasets by [38].", "startOffset": 169, "endOffset": 173}, {"referenceID": 27, "context": "[28] show that by using SGNS embeddings as features in a kNearest Neighbour classifier, it is possible to accurately extrapolate the affective meanings of words.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "Moreover, perceived psycholinguistic properties of words such as concreteness (how \u201cpalpable\u201d the object the word refers to) and imageability (the intensity with which a word arouses images) have been successfully predicted using word embeddings [35, 31].", "startOffset": 246, "endOffset": 254}, {"referenceID": 30, "context": "Moreover, perceived psycholinguistic properties of words such as concreteness (how \u201cpalpable\u201d the object the word refers to) and imageability (the intensity with which a word arouses images) have been successfully predicted using word embeddings [35, 31].", "startOffset": 246, "endOffset": 254}, {"referenceID": 34, "context": "For example, [35] used the cosine similarity between word embeddings obtained via Latent Semantic Analysis (LSA) [13] to predict the concreteness and imageability ratings of words.", "startOffset": 13, "endOffset": 17}, {"referenceID": 12, "context": "For example, [35] used the cosine similarity between word embeddings obtained via Latent Semantic Analysis (LSA) [13] to predict the concreteness and imageability ratings of words.", "startOffset": 113, "endOffset": 117}, {"referenceID": 15, "context": "On the other hand, prior work studying the relationship between human reading patterns using eyetracking devices show that there exist a high positive correlation between word salience and reading times [16, 19].", "startOffset": 203, "endOffset": 211}, {"referenceID": 18, "context": "On the other hand, prior work studying the relationship between human reading patterns using eyetracking devices show that there exist a high positive correlation between word salience and reading times [16, 19].", "startOffset": 203, "endOffset": 211}, {"referenceID": 36, "context": "[37], which contains valence, arousal, and dominance ratings collected via crowd sourcing for 13,915 words.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "Measuring the salience of a word is an essential step in numerous NLP tasks. Heuristic approaches such as tfidf have been used so far to estimate the salience of words. We propose Neural Word Salience (NWS) scores, unlike heuristics, are learnt from a corpus. Specifically, we learn word salience scores such that, using pre-trained word embeddings as the input, can accurately predict the words that appear in a sentence, given the words that appear in the sentences preceding or succeeding that sentence. Experimental results on sentence similarity prediction show that the learnt word salience scores perform comparably or better than some of the state-of-the-art approaches for representing sentences on benchmark datasets for sentence similarity, while using only a fraction of the training and prediction times required by prior methods. Moreover, our NWS scores positively correlate with psycholinguistic measures such as concreteness, and imageability implying a close connection to the salience as perceived by humans.", "creator": "LaTeX with hyperref package"}}}