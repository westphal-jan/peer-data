{"id": "1709.01188", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Sep-2017", "title": "Storytelling Agents with Personality and Adaptivity", "abstract": "We explore the expression of personality and adaptivity through the gestures of virtual agents in a storytelling task. We conduct two experiments using four different dialogic stories. We manipulate agent personality on the extraversion scale, whether the agents adapt to one another in their gestural performance and agent gender. Our results show that subjects are able to perceive the intended variation in extraversion between different virtual agents, independently of the story they are telling and the gender of the agent. A second study shows that subjects also prefer adaptive to nonadaptive virtual agents.", "histories": [["v1", "Mon, 4 Sep 2017 23:06:05 GMT  (1857kb,D)", "http://arxiv.org/abs/1709.01188v1", "Related dataset:this https URL"]], "COMMENTS": "Related dataset:this https URL", "reviews": [], "SUBJECTS": "cs.HC cs.CL", "authors": ["zhichao hu", "marilyn a walker", "michael neff", "jean e fox tree"], "accepted": false, "id": "1709.01188"}, "pdf": {"name": "1709.01188.pdf", "metadata": {"source": "CRF", "title": "Storytelling Agents with Personality and Adaptivity", "authors": ["A. Walker", "Zhichao Hu", "Marilyn A. Walker", "Michael Neff"], "emails": ["zhu@ucsc.edu", "mawalker@ucsc.edu", "foxtree@ucsc.edu", "mpneff@ucdavis.edu"], "sections": [{"heading": null, "text": "Keywords: personality, gesture generation and variation, gesture adaptation, storytelling, collaborative storytelling"}, {"heading": "1 Introduction", "text": "This means that people are able to decide for themselves what they want and what they don't want."}, {"heading": "2 Story Dialog Corpus", "text": "In fact, most of them are able to determine for themselves what they want and what they want."}, {"heading": "4 Experimental Results", "text": "In fact, most of them will be able to move to a different world in which they are able to escape than to a different world in which they live."}, {"heading": "5 Discussion and Future Work", "text": "To our knowledge, this is the first time that it has been shown that subjects perceive differences in the gesticularity of agents when telling a story, and that adaptive gestural behavior is perceived positively during storytelling. We use natural personal narratives that are implemented dialogically so that two IVAs tell the story together. It is obvious that the ability to adapt is an important part of being more human. Attempts have been made to integrate language adaptations within the natural language generation [32] and research has shown that human characters positively perceive linguistic adaptations [33]. However, this is the first experiment to show a positive effect for controlled adaptations. Reviews on gesture generation have largely focused on iconic gesture generation. Bergmann and Kopp [34] present a model that allows virtual agents to automatically select the content and determine the form of coordinated language and iconic gestures derived from gestures."}], "references": [{"title": "The trait construct in lay and professional psychology", "author": ["R.E. Nisbett"], "venue": "Retrospections on social psychology,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1980}, {"title": "Personality in its natural habitat: Manifestations and implicit folk theories of personality in daily life", "author": ["M.R. Mehl", "S.D. Gosling", "J.W. Pennebaker"], "venue": "Journal of Personality and Social Psychology,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Toward an adequate taxonomy of personality attributes: Replicated factor structure in peer nomination personality rating", "author": ["W.T. Norman"], "venue": "Journal of Abnormal and Social Psychology,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1963}, {"title": "The comforting presence of relational agents", "author": ["T. Bickmore", "D. Schulman"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Implementing expressive gesture synthesis for embodied conversational agents", "author": ["B. Hartmann", "M. Mancini", "C. Pelachaud"], "venue": "In Proc. Gesture Workshop 2005,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Synthesizing multimodal utterances for conversational agents", "author": ["S. Kopp", "I. Wachsmuth"], "venue": "Computer Animation and Virtual Worlds,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Smartbody: Behavior realization for embodied conversational agents", "author": ["M. Thiebaux", "A. Marshall", "S. Marsella", "M. Kallman"], "venue": "In Proc. of 7th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "EMBR\u2013A Realtime Animation Engine for Interactive Embodied Agents", "author": ["A. Heloir", "M. Kipp"], "venue": "In Intelligent Virtual Agents", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Integrating models of personality and emotions into lifelike characters", "author": ["E. Andr\u00e9", "M. Klesen", "P. Gebhard", "S. Allen", "T. Rist"], "venue": "In Proc. of the Workshop on Affect in Interactions - Towards a new Generation of Interfaces,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1999}, {"title": "Embodied conversational agents on a common ground. From brows to trust: evaluating embodied conversational agents, chapter 2, pages 27\u201366", "author": ["Z. Ruttkay", "C. Dormann", "H. Noot"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "How \u201creal\u201d are computer personalities?: Psychological responses to personality types in human-computer interaction", "author": ["Y. Moon", "C. Nass"], "venue": "Communication Research,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1996}, {"title": "Investigating culture-related aspects of behavior for virtual characters", "author": ["B. Endra\u00df", "E. Andr\u00e9", "M. Rehm", "Y.I. Nakano"], "venue": "Autonomous Agents and Multi-Agent Systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Design of a virtual human presenter. Center for Human Modeling and Simulation, page", "author": ["T. Noma", "N.I. Badler", "L. Zhao"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2000}, {"title": "User robot personality matching and assistive robot behavior adaptation for post-stroke rehabilitation therapy", "author": ["A. Tapus", "C. Tapus", "M.J. Mataric"], "venue": "Intelligent Service Robotics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "The politeness effect: Pedagogical agents and learning gains", "author": ["N. Wang", "W.L. Johnson", "R.E. Mayer", "P. Rizzo", "E. Shaw", "H. Collins"], "venue": "Frontiers in AI and Applications,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "Controlling user perceptions of linguistic style: Trainable generation of personality traits", "author": ["F. Mairesse", "M.A. Walker"], "venue": "Computational Linguistics,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Evaluating the effect of gesture and language on personality perception in conversational agents", "author": ["M. Neff", "Y. Wang", "R. Abbott", "M. Walker"], "venue": "In IVA,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Bossy or wimpy: expressing social dominance by combining gaze and linguistic behaviors", "author": ["N. Bee", "C. Pollock", "E. Andr\u00e9", "M. Walker"], "venue": "In Intelligent Virtual Agents,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Dont scratch! selfadaptors reflect emotional stability", "author": ["M. Neff", "N. Toothman", "R. Bowmani", "J.E. Fox Tree", "Walker M. A"], "venue": "In IVA,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Listening in on monologues and dialogues", "author": ["J.E. Fox Tree"], "venue": "Discourse Processes,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1999}, {"title": "Seeing and hearing double: The influence of mimicry in speech and gesture on observers", "author": ["F. Parrill", "I. Kimbara"], "venue": "Journal of Nonverbal Behavior,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "Digital chameleons: Automatic assimilation of nonverbal gestures in immersive virtual environments", "author": ["J.N. Bailenson", "N. Yee"], "venue": "Psychological Science,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "Addressee backchannels steer narrative development", "author": ["J. Tolins", "J.E. Fox Tree"], "venue": "Journal of Pragmatics,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Channeling identity: A study of storytelling in conversations between introverted and extraverted friends", "author": ["A. Thorne", "N. Korobov", "E.M. Morgan"], "venue": "Journal of research in personality,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}, {"title": "Identifying personal stories in millions of weblog entries", "author": ["A. Gordon", "R. Swanson"], "venue": "In 3rd Int. Conference on Weblogs and Social Media,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "Movement phase in signs and co-speech gestures, and their transcriptions by human coders", "author": ["S. KIita", "I. Van Gijn", "H. Van Der Hulst"], "venue": "In Proc. of the Int. Gesture Workshop on Gesture and Sign Language in Human-Computer Interaction, Springer-Verlag,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1998}, {"title": "The influence of prosody on the requirements for gesture-text alignment", "author": ["Y. Wang", "M. Neff"], "venue": "In IVA,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "Augmenting gesture animation with motion capture data to provide full-body engagement", "author": ["P. Luo", "M. Kipp", "M. Neff"], "venue": "In IVA,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2009}, {"title": "A very brief measure of the big five personality domains", "author": ["S.D. Gosling", "P.J. Rentfrow", "W.B. Swann"], "venue": "Journal of Research in Personality,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2003}, {"title": "Judging iva personality using an open-ended question", "author": ["K. Liu", "J. Tolins", "J.E. Fox Tree", "M. Walker", "M. Neff"], "venue": "In IVA,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}, {"title": "An alignment-capable microplanner for natural language generation", "author": ["H. Buschmeier", "K. Bergmann", "S. Kopp"], "venue": "In Proc. of the 12th European Workshop on Natural Language Generation,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2009}, {"title": "Entrainment in pedestrian direction giving: How many kinds of entrainment", "author": ["Z. Hu", "G. Halberg", "C. Jimenez", "M. Walker"], "venue": "IWSDS,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2014}, {"title": "Increasing the expressiveness of virtual agents: autonomous generation of speech and gesture for spatial description tasks", "author": ["K. Bergmann", "S. Kopp"], "venue": "In Proc. of The 8th Int. Conference on Autonomous Agents and Multiagent Systems-Volume", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2009}, {"title": "Wip/ppp: Automatic generation of personalized multimedia presentations", "author": ["E. Andr\u00e9", "J. M\u00fcller", "T. Rist"], "venue": "In Proc. of the fourth ACM international conference on Multimedia,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1997}, {"title": "Beat: the behavior expression animation toolkit", "author": ["J. Cassell", "H.H. Vilhj\u00e1lmsson", "T. Bickmore"], "venue": "In Life-Like Characters,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2004}, {"title": "Gesture modeling and animation based on a probabilistic re-creation of speaker style", "author": ["M. Neff", "M. Kipp", "I. Albrecht", "H.P. Seidel"], "venue": "In ACM Transactions on Graphics (TOG). ACM,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2008}, {"title": "Creating rapport with virtual agents", "author": ["J. Gratch", "N. Wang", "J. Gerten", "E. Fast", "R. Duffy"], "venue": "In IVA,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "However, when interacting with or observing others, people make inferences that generalize from specific, observed behaviors to explanations for those behaviors in terms of dispositional traits [1].", "startOffset": 194, "endOffset": 197}, {"referenceID": 1, "context": "One theory that attempts to account for such inferences is the Big Five theory of personality, which posits that consistent patterns in the way individuals behave, feel, and think across different situations, can be described in terms of trait adjectives, such as sociable, shy, trustworthy, disorganized or imaginative [2,3].", "startOffset": 320, "endOffset": 325}, {"referenceID": 2, "context": "One theory that attempts to account for such inferences is the Big Five theory of personality, which posits that consistent patterns in the way individuals behave, feel, and think across different situations, can be described in terms of trait adjectives, such as sociable, shy, trustworthy, disorganized or imaginative [2,3].", "startOffset": 320, "endOffset": 325}, {"referenceID": 3, "context": "Previous work suggests both that personality traits are real, and that they are useful as a basis for models for Intelligent Virtual Agents (IVAs) for a range of applications [4,5,6,7,8].", "startOffset": 175, "endOffset": 186}, {"referenceID": 4, "context": "Previous work suggests both that personality traits are real, and that they are useful as a basis for models for Intelligent Virtual Agents (IVAs) for a range of applications [4,5,6,7,8].", "startOffset": 175, "endOffset": 186}, {"referenceID": 5, "context": "Previous work suggests both that personality traits are real, and that they are useful as a basis for models for Intelligent Virtual Agents (IVAs) for a range of applications [4,5,6,7,8].", "startOffset": 175, "endOffset": 186}, {"referenceID": 6, "context": "Previous work suggests both that personality traits are real, and that they are useful as a basis for models for Intelligent Virtual Agents (IVAs) for a range of applications [4,5,6,7,8].", "startOffset": 175, "endOffset": 186}, {"referenceID": 7, "context": "Previous work suggests both that personality traits are real, and that they are useful as a basis for models for Intelligent Virtual Agents (IVAs) for a range of applications [4,5,6,7,8].", "startOffset": 175, "endOffset": 186}, {"referenceID": 8, "context": "Many findings about how people perceive other humans appear to carry over to their perceptions of IVAs [9,10,11,12,13].", "startOffset": 103, "endOffset": 118}, {"referenceID": 9, "context": "Many findings about how people perceive other humans appear to carry over to their perceptions of IVAs [9,10,11,12,13].", "startOffset": 103, "endOffset": 118}, {"referenceID": 10, "context": "Many findings about how people perceive other humans appear to carry over to their perceptions of IVAs [9,10,11,12,13].", "startOffset": 103, "endOffset": 118}, {"referenceID": 11, "context": "Many findings about how people perceive other humans appear to carry over to their perceptions of IVAs [9,10,11,12,13].", "startOffset": 103, "endOffset": 118}, {"referenceID": 12, "context": "Many findings about how people perceive other humans appear to carry over to their perceptions of IVAs [9,10,11,12,13].", "startOffset": 103, "endOffset": 118}, {"referenceID": 13, "context": "Research suggests that human users are more engaged and thus learn more when interacting with characters endowed with personality and emotions, and that a character\u2019s personality, surprisingly, affects users\u2019 perceptions of the system\u2019s competence [14,15].", "startOffset": 248, "endOffset": 255}, {"referenceID": 14, "context": "Research suggests that human users are more engaged and thus learn more when interacting with characters endowed with personality and emotions, and that a character\u2019s personality, surprisingly, affects users\u2019 perceptions of the system\u2019s competence [14,15].", "startOffset": 248, "endOffset": 255}, {"referenceID": 15, "context": "Recent experiments show that the Big Five theory is a useful basis for multi-modal integration of nonverbal and linguistic behavior, and that automatically generated variations in personality are perceived as intended [16,17,18,19].", "startOffset": 218, "endOffset": 231}, {"referenceID": 16, "context": "Recent experiments show that the Big Five theory is a useful basis for multi-modal integration of nonverbal and linguistic behavior, and that automatically generated variations in personality are perceived as intended [16,17,18,19].", "startOffset": 218, "endOffset": 231}, {"referenceID": 17, "context": "Recent experiments show that the Big Five theory is a useful basis for multi-modal integration of nonverbal and linguistic behavior, and that automatically generated variations in personality are perceived as intended [16,17,18,19].", "startOffset": 218, "endOffset": 231}, {"referenceID": 18, "context": "Recent experiments show that the Big Five theory is a useful basis for multi-modal integration of nonverbal and linguistic behavior, and that automatically generated variations in personality are perceived as intended [16,17,18,19].", "startOffset": 218, "endOffset": 231}, {"referenceID": 19, "context": "Conversants dynamically adapt to their conversational partner, both in conversation and when telling stories, and using both verbal and nonverbal features [20,21,22,23,24], inter alia.", "startOffset": 155, "endOffset": 171}, {"referenceID": 20, "context": "Conversants dynamically adapt to their conversational partner, both in conversation and when telling stories, and using both verbal and nonverbal features [20,21,22,23,24], inter alia.", "startOffset": 155, "endOffset": 171}, {"referenceID": 21, "context": "Conversants dynamically adapt to their conversational partner, both in conversation and when telling stories, and using both verbal and nonverbal features [20,21,22,23,24], inter alia.", "startOffset": 155, "endOffset": 171}, {"referenceID": 22, "context": "Conversants dynamically adapt to their conversational partner, both in conversation and when telling stories, and using both verbal and nonverbal features [20,21,22,23,24], inter alia.", "startOffset": 155, "endOffset": 171}, {"referenceID": 23, "context": "Conversants dynamically adapt to their conversational partner, both in conversation and when telling stories, and using both verbal and nonverbal features [20,21,22,23,24], inter alia.", "startOffset": 155, "endOffset": 171}, {"referenceID": 21, "context": "There is also evidence that people prefer IVAs that align with human behavior, such as by mimicking head movements [22] or speech style [11].", "startOffset": 115, "endOffset": 119}, {"referenceID": 10, "context": "There is also evidence that people prefer IVAs that align with human behavior, such as by mimicking head movements [22] or speech style [11].", "startOffset": 136, "endOffset": 140}, {"referenceID": 10, "context": "A human\u2019s attraction to an IVA is increased when the IVA adapts its personality to the human over time rather than maintaining a consistently similar personality [11].", "startOffset": 162, "endOffset": 166}, {"referenceID": 24, "context": "Our stories come from weblogs of personal narratives [25] whose content has been regenerated as dialogues to support story co-telling.", "startOffset": 53, "endOffset": 57}, {"referenceID": 23, "context": "Our aim is to mimic the finding that storytelling in the wild is naturally conversational [24], and that the style of oral storytelling among friends varies depending on their personalities [24].", "startOffset": 90, "endOffset": 94}, {"referenceID": 23, "context": "Our aim is to mimic the finding that storytelling in the wild is naturally conversational [24], and that the style of oral storytelling among friends varies depending on their personalities [24].", "startOffset": 190, "endOffset": 194}, {"referenceID": 16, "context": "\u2019s work on the impact of extraversion on gesture in IVAs [17], as shown in Table 1, and select parameters to depict both introverted and extraverted IVAs by varying gesture amplitude, direction, rate and speed.", "startOffset": 57, "endOffset": 61}, {"referenceID": 25, "context": "2 illustrates how every gesture can be generated to include up to 4 phases [26]:", "startOffset": 75, "endOffset": 79}, {"referenceID": 26, "context": "Research has shown that people prefer gestures occurring earlier than the accompanying speech [27].", "startOffset": 94, "endOffset": 98}, {"referenceID": 27, "context": "movements [29] and head rotation movements for both agents.", "startOffset": 10, "endOffset": 14}, {"referenceID": 28, "context": "We conducted a between-subjects experiment on Mechanical Turk where we first ask Turkers to answer the TIPI [30] personality survey for themselves, and then answer it for only one of the agents in the video, after watching the video as many times as they like.", "startOffset": 108, "endOffset": 112}, {"referenceID": 15, "context": "Since previous work suggests that personality is perceived for an agent along all Big Five dimensions whether it is designed to be manifest or not [16,31], we also conducted a two-way ANOVA by story and agent intended personality for the other 4 traits.", "startOffset": 147, "endOffset": 154}, {"referenceID": 29, "context": "Since previous work suggests that personality is perceived for an agent along all Big Five dimensions whether it is designed to be manifest or not [16,31], we also conducted a two-way ANOVA by story and agent intended personality for the other 4 traits.", "startOffset": 147, "endOffset": 154}, {"referenceID": 30, "context": "There are attempts to integrate language adaptation within natural language generation [32] and research has shown that human bystanders perceive linguistic adaptation positively [33].", "startOffset": 87, "endOffset": 91}, {"referenceID": 31, "context": "There are attempts to integrate language adaptation within natural language generation [32] and research has shown that human bystanders perceive linguistic adaptation positively [33].", "startOffset": 179, "endOffset": 183}, {"referenceID": 32, "context": "For example, Bergmann and Kopp [34] present a model that allows virtual agents to automatically select the content and derive the form of coordinated language and iconic gestures.", "startOffset": 31, "endOffset": 35}, {"referenceID": 27, "context": "[29] also presents an effective algorithm for adding full body postural movement to animation sequences of arm gestures.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "Text-to-gesture systems, such as VHP [13], may have a limited number of gestures (only 7 in this case) and limited gesture placement options, but the alignment of speech content and gestures are more accurate.", "startOffset": 37, "endOffset": 41}, {"referenceID": 33, "context": "Concept-to-gesture systems such as PPP [35], AC and BEAT [36] defines general rules for gesture insertion based on linguistic components.", "startOffset": 39, "endOffset": 43}, {"referenceID": 34, "context": "Concept-to-gesture systems such as PPP [35], AC and BEAT [36] defines general rules for gesture insertion based on linguistic components.", "startOffset": 57, "endOffset": 61}, {"referenceID": 35, "context": "An alternative approach learns a personalized statistical model that predicts a gesture given the text to be spoken and a model that captures an individual\u2019s gesturing preferences [37].", "startOffset": 180, "endOffset": 184}, {"referenceID": 36, "context": "Gratch investigates creating rapport with virtual agents using gesture adaptation mainly focused on head gestures and posture shifts (while ours focused on hand gestures), and used real human movements as control [38].", "startOffset": 213, "endOffset": 217}, {"referenceID": 11, "context": "[12].", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "We explore the expression of personality and adaptivity through the gestures of virtual agents in a storytelling task. We conduct two experiments using four different dialogic stories. We manipulate agent personality on the extraversion scale, whether the agents adapt to one another in their gestural performance and agent gender. Our results show that subjects are able to perceive the intended variation in extraversion between different virtual agents, independently of the story they are telling and the gender of the agent. A second study shows that subjects also prefer adaptive to nonadaptive virtual agents.", "creator": "LaTeX with hyperref package"}}}