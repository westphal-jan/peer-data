{"id": "1709.01887", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Sep-2017", "title": "Measuring the Similarity of Sentential Arguments in Dialog", "abstract": "When people converse about social or political topics, similar arguments are often paraphrased by different speakers, across many different conversations. Debate websites produce curated summaries of arguments on such topics; these summaries typically consist of lists of sentences that represent frequently paraphrased propositions, or labels capturing the essence of one particular aspect of an argument, e.g. Morality or Second Amendment. We call these frequently paraphrased propositions ARGUMENT FACETS. Like these curated sites, our goal is to induce and identify argument facets across multiple conversations, and produce summaries. However, we aim to do this automatically. We frame the problem as consisting of two steps: we first extract sentences that express an argument from raw social media dialogs, and then rank the extracted arguments in terms of their similarity to one another. Sets of similar arguments are used to represent argument facets. We show here that we can predict ARGUMENT FACET SIMILARITY with a correlation averaging 0.63 compared to a human topline averaging 0.68 over three debate topics, easily beating several reasonable baselines.", "histories": [["v1", "Wed, 6 Sep 2017 17:15:49 GMT  (343kb,D)", "http://arxiv.org/abs/1709.01887v1", "Measuring the Similarity of Sentential Arguments in Dialog, by Misra, Amita and Ecker, Brian and Walker, Marilyn A, 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages={276}, year={2016} The dataset is available atthis https URL"]], "COMMENTS": "Measuring the Similarity of Sentential Arguments in Dialog, by Misra, Amita and Ecker, Brian and Walker, Marilyn A, 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages={276}, year={2016} The dataset is available atthis https URL", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["amita misra", "brian ecker", "marilyn a walker"], "accepted": false, "id": "1709.01887"}, "pdf": {"name": "1709.01887.pdf", "metadata": {"source": "META", "title": "Measuring the Similarity of Sentential Arguments in Dialog", "authors": ["Amita Misra", "Brian Ecker", "Marilyn A. Walker"], "emails": ["amitamisra@soe.ucsc.edu", "becker@soe.ucsc.edu", "maw@soe.ucsc.edu"], "sections": [{"heading": null, "text": "Reports of the conference SIGDIAL 2016, pp. 276-287, Los Angeles, USA, 13-15 September 2016. c \u00a9 2016 Association for Computational Linguistics"}, {"heading": "1 Introduction", "text": "When people talk about social or political issues, similar arguments are often described by different speakers, whom we address in many different constellations. Thus, for example, it is necessary that the individual sentences S1 to S6 produce different linguistic realizations of the same reasoning, namely that criminals have guns even if possession of firearms is illegal. Debate sites such as Idebate and ProCon produce curated summaries of gun control arguments, as well as many other topics. 12 These summaries typically consist of lists, e.g. Fig. 2 lists eight different aspects of gun control from Idebate. Such manually curated summaries identify different linguistic realizations of the same argument in order to induce a number of common, repeated aspects of the arguments, which we call ARGUMENT FACETS."}, {"heading": "2 Corpora and Problem Definition", "text": "Many existing websites summarize the frequent and repeated facets of arguments on current issues, which are implemented in different linguistic ways, in many different social media and discussion forums. For example, Fig. 2 illustrates the eight facets of gun control on IDebate. Fig. 3 illustrates a different kind of summary, for the topic of capital punishment, from ProCon, where the facets of arguments are referred to as the \"Top Ten Pros and Cons\" and given terms such as morality, constitutionality and race. See Fig. 3. The bottom of Fig. 3 shows how each facet is then elaborated by a paragraph for their pro and con pages: due to the space, we only show the summary for the morality facet here. These summaries are curated, so both the AQ and the AFS group would be made available as a group."}, {"heading": "2.1 Argument Quality Data", "text": "We expected all the sentences for all entries in each topic to first create a large corpus of topicsorted sentences, then many sample samples. See Table 1.We started with the argument Quality (AQ) re-gressor from Swanson et al. (2015), which gives a score to each sentence, intended to reflect how easily the speaker's reasoning can be understood without any context. Easily understandable sentences are believed to be primary candidates for producing extractive summaries. (2015), the commentators rated AQ with a continuous slider that ranges from hard (0.0) to easy to interpret (1.0). We have summarized the mechanical task for elicit's new training data for AQ as in Table 1. Fig. 8 in the appendix shows the HIT we have used to collect new AQ labels for sentences, as described below.We expected the application of Swanson's AQ regressor to our \"sample from the box.\""}, {"heading": "2.2 Argument Facet Similarity Data", "text": "This year, it is more than ever before in the history of the city, in which it has come as far as never before in the history of the city."}, {"heading": "3 Argument Facet Similarity", "text": "Based on the data collected above, we defined a supervised machine learning experiment with AFS as our dependent variable. We developed a series of baselines using commercially available tools. The features are grouped together and discussed in detail below."}, {"heading": "3.1 Feature Sets", "text": "It is possible that our primary baseline is a selection of dates for the relations between the two countries. \"We have a very good idea,\" he says, \"but we don't have enough time yet.\" \"We don't have enough time yet,\" he says, \"but we have more time.\" \"We have more time,\" he says, \"we have more time.\" \"We have more time.\" \"\" We have more time. \"\" \"We have more time.\" \"\" We have more time. \"\" \"\" We have more time. \"\" \"\" \"We have more time.\" \"\" \"\" We have more time. \"\" \"\" We have more time. \"\" \"We have more time.\" \"\" \"We have more time.\" \"\" \"We have more time.\" \"\" We have more time. \"\" We have more time. \"We have more time.\" We have more time. \"We have.\" We have more time...... \"We have more time....\" We have more time. \""}, {"heading": "3.2 Machine Learning Regression Results", "text": "This year, we will be able to move into a new world, in which we will be able to create a new world, in which we will be able to create a new world, in which we will be able to create a new world, in which we will be able to create a new world, \"he said."}, {"heading": "3.3 Analysis and Discussion", "text": "This year, it is only a matter of time before we reach an agreement."}, {"heading": "4 Related Work", "text": "There are many reasoning theories that could apply to our task (Jackson and Jacobs, 1980; Reed and Rowe, 2004; Walton et al., 2008; Gilbert, 1997; Toulmin, 1958; Dung, 1995), but a definition of the reasoning structure may not work for every NLP task. Arguments in social media are often informal and do not necessarily follow logical rules or reasoning schemes (Staff and Gurevych, 2014; Peldszus and Stede, 2013; Ghosh et al., 2014; Goudas et al., 2014; Cabrio and Villata, 2012). Furthermore, text segments that are argumentative must first be identified, as in our Task1. Habernal and Gurevych (2016) train a classifier to recognize text segments that are argumentative but predict much."}, {"heading": "5 Conclusion and Future Work", "text": "We present a method of assessing facet similarity in online debates using a combination of hand-crafted and unsupervised features with an average correlation of 0.63 compared to a human top line with an average of 0.68. Our approach differs from similar work showing the \"reasons\" underlying a speaker, because our models are based on the belief that it is not possible to define a finite set of discrete facets for an issue. A qualitative analysis of our findings, illustrated by Table 4, suggests that treating facet discoveries as a similarity problem is productive, i.e. the study of certain couples suggests facets about legal and financial benefits for same-sex couples, the assertion that the death penalty does affect murder rates, and a claim that \"Congress\" does not have the explicit, outlined power to pass gun restriction laws."}, {"heading": "Acknowledgments", "text": "This work was supported by NSF CISE RI 1302668. Thanks to Keshav Mathur and the three anonymous reviewers for helpful comments."}, {"heading": "A Appendix", "text": "Figure 8 shows the definitions in our argument Quality HIT. Figure 9 shows the relationship between predicted AQ score and notes on the quality of arguments in the gold standard. Figure 10 provides our definition of FACET and instructions on AFS note. This is repeated here from (Misra et al., 2015) for the convenience of the reader."}], "references": [{"title": "Internet argument corpus 2.0: An sql schema for dialogic social media and the corpora to go with it", "author": ["Robert Abbott", "Brian Ecker", "Pranav Anand", "Marilyn Walker"], "venue": "In Language Resources and Evaluation Conference,", "citeRegEx": "Abbott et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Abbott et al\\.", "year": 2016}, {"title": "Semeval-2012 task 6: A pilot on semantic textual similarity", "author": ["Eneko Agirre", "Mona Diab", "Daniel Cer", "Aitor Gonzalez-Agirre."], "venue": "Proc. of the First Joint Conference on Lexical and Computational Semantics, volume 1, pages 385\u2013393.", "citeRegEx": "Agirre et al\\.,? 2012", "shortCiteRegEx": "Agirre et al\\.", "year": 2012}, {"title": "Sem 2013 shared task: Semantic textual similarity, including a pilot on typed-similarity", "author": ["Eneko Agirre", "Daniel Cer", "Mona Diab", "Aitor GonzalezAgirre", "Weiwei Guo."], "venue": "In* SEM 2013: The Second Joint Conference on Lexical and Computational Se-", "citeRegEx": "Agirre et al\\.,? 2013", "shortCiteRegEx": "Agirre et al\\.", "year": 2013}, {"title": "Identifying justifications in written dialogs", "author": ["Oram Biran", "Owen Rambow."], "venue": "2011 Fifth IEEE International Conference on Semantic Computing (ICSC), pages 162\u2013168.", "citeRegEx": "Biran and Rambow.,? 2011", "shortCiteRegEx": "Biran and Rambow.", "year": 2011}, {"title": "Back up your stance: Recognizing arguments in online discussions", "author": ["Filip Boltuzic", "Jan \u0160najder."], "venue": "Proc. of the First Workshop on Argumentation Mining, pages 49\u201358.", "citeRegEx": "Boltuzic and \u0160najder.,? 2014", "shortCiteRegEx": "Boltuzic and \u0160najder.", "year": 2014}, {"title": "Identifying prominent arguments in online debates using semantic textual similarity", "author": ["Filip Boltuzic", "Jan \u0160najder."], "venue": "Proc. of the Second Workshop on Argumentation Mining.", "citeRegEx": "Boltuzic and \u0160najder.,? 2015", "shortCiteRegEx": "Boltuzic and \u0160najder.", "year": 2015}, {"title": "Combining textual entailment and argumentation theory for supporting online debates interactions", "author": ["Elena Cabrio", "Serena Villata."], "venue": "Proc. of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages", "citeRegEx": "Cabrio and Villata.,? 2012", "shortCiteRegEx": "Cabrio and Villata.", "year": 2012}, {"title": "Recognizing arguing subjectivity and argument tags", "author": ["Alexander Conrad", "Janyce Wiebe"], "venue": "In Proc. of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics,", "citeRegEx": "Conrad and Wiebe,? \\Q2012\\E", "shortCiteRegEx": "Conrad and Wiebe", "year": 2012}, {"title": "Automatically constructing a corpus of sentential paraphrases", "author": ["William B Dolan", "Chris Brockett."], "venue": "Proc. of IWP.", "citeRegEx": "Dolan and Brockett.,? 2005", "shortCiteRegEx": "Dolan and Brockett.", "year": 2005}, {"title": "On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games* 1", "author": ["P.M. Dung."], "venue": "Artificial intelligence, 77(2):321\u2013357.", "citeRegEx": "Dung.,? 1995", "shortCiteRegEx": "Dung.", "year": 1995}, {"title": "Analyzing argumentative discourse units in online interactions", "author": ["Debanjan Ghosh", "Smaranda Muresan", "Nina Wacholder", "Mark Aakhus", "Matthew Mitsui."], "venue": "ACL 2014, page 39.", "citeRegEx": "Ghosh et al\\.,? 2014", "shortCiteRegEx": "Ghosh et al\\.", "year": 2014}, {"title": "Coalescent argumentation", "author": ["Michael A. Gilbert"], "venue": null, "citeRegEx": "Gilbert.,? \\Q1997\\E", "shortCiteRegEx": "Gilbert.", "year": 1997}, {"title": "Argument extraction from news, blogs, and social media", "author": ["Theodosis Goudas", "Christos Louizos", "Georgios Petasis", "Vangelis Karkaletsis."], "venue": "Artificial Intelligence: Methods and Applications, pages 287\u2013299. Springer.", "citeRegEx": "Goudas et al\\.,? 2014", "shortCiteRegEx": "Goudas et al\\.", "year": 2014}, {"title": "Exploiting debate portals for semi-supervised argumentation mining in user-generated web discourse", "author": ["Ivan Habernal", "Iryna Gurevych."], "venue": "Proc. of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages", "citeRegEx": "Habernal and Gurevych.,? 2015", "shortCiteRegEx": "Habernal and Gurevych.", "year": 2015}, {"title": "Argumentation mining in user-generated web discourse", "author": ["Ivan Habernal", "Iryna Gurevych."], "venue": "CoRR, abs/1601.02403.", "citeRegEx": "Habernal and Gurevych.,? 2016", "shortCiteRegEx": "Habernal and Gurevych.", "year": 2016}, {"title": "Argumentation mining on the web from information seeking perspective", "author": ["Ivan Habernal", "Judith Eckle-Kohler", "Iryna Gurevych."], "venue": "Proc. of the Workshop on Frontiers and Connections between Argumentation Theory and Natural Language Pro-", "citeRegEx": "Habernal et al\\.,? 2014", "shortCiteRegEx": "Habernal et al\\.", "year": 2014}, {"title": "Umbc ebiquitycore: Semantic textual similarity systems", "author": ["Lushan Han", "Abhay Kashyap", "Tim Finin", "James Mayfield", "Jonathan Weese."], "venue": "Proceedings of the Second Joint Conference on Lexical and Computational Semantics, pages 44\u201352.", "citeRegEx": "Han et al\\.,? 2013", "shortCiteRegEx": "Han et al\\.", "year": 2013}, {"title": "Frame semantics for stance classification", "author": ["Kazi Saidul Hasan", "Vincent Ng."], "venue": "CoNLL, pages 124\u2013132.", "citeRegEx": "Hasan and Ng.,? 2013", "shortCiteRegEx": "Hasan and Ng.", "year": 2013}, {"title": "Why are you taking this stance? identifying and classifying reasons in ideological debates", "author": ["Kazi Saidul Hasan", "Vincent Ng."], "venue": "Proc. of the Conference on Empirical Methods in Natural Language Processing.", "citeRegEx": "Hasan and Ng.,? 2014", "shortCiteRegEx": "Hasan and Ng.", "year": 2014}, {"title": "Structure of conversational argument: Pragmatic bases for the enthymeme", "author": ["Sally Jackson", "Scott Jacobs."], "venue": "Quarterly Journal of Speech, 66(3):251\u2013265.", "citeRegEx": "Jackson and Jacobs.,? 1980", "shortCiteRegEx": "Jackson and Jacobs.", "year": 1980}, {"title": "Generalizing dependency features for opinion mining", "author": ["M. Joshi", "C. Penstein-Ros\u00e9."], "venue": "Proc. of the ACL-IJCNLP 2009 Conference Short Papers, pages 313\u2013316.", "citeRegEx": "Joshi and Penstein.Ros\u00e9.,? 2009", "shortCiteRegEx": "Joshi and Penstein.Ros\u00e9.", "year": 2009}, {"title": "The meteor metric for automatic evaluation of machine translation", "author": ["Alon Lavie", "Michael J. Denkowski."], "venue": "Machine Translation, 23(2-3):105\u2013115, September.", "citeRegEx": "Lavie and Denkowski.,? 2009", "shortCiteRegEx": "Lavie and Denkowski.", "year": 2009}, {"title": "Distributed representations of sentences and documents", "author": ["Quoc Le", "Tomas Mikolov."], "venue": "Tony Jebara and Eric P. Xing, editors, Proc. of the 31st International Conference on Machine Learning (ICML14), pages 1188\u20131196.", "citeRegEx": "Le and Mikolov.,? 2014", "shortCiteRegEx": "Le and Mikolov.", "year": 2014}, {"title": "Visualizing and understanding neural models in nlp", "author": ["Jiwei Li", "Xinlei Chen", "Eduard Hovy", "Dan Jurafsky."], "venue": "arXiv preprint arXiv:1506.01066.", "citeRegEx": "Li et al\\.,? 2015", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Rouge: A package for automatic evaluation of summaries rouge: A package for automatic evaluation of summaries", "author": ["C.-Y. Lin."], "venue": "Proc. of the Workshop on Text Summarization Branches Out (WAS 2004).", "citeRegEx": "Lin.,? 2004", "shortCiteRegEx": "Lin.", "year": 2004}, {"title": "Re-examining machine translation metrics for paraphrase identification", "author": ["Nitin Madnani", "Joel Tetreault", "Martin Chodorow."], "venue": "Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics:", "citeRegEx": "Madnani et al\\.,? 2012", "shortCiteRegEx": "Madnani et al\\.", "year": 2012}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky."], "venue": "Proc. of 52nd Annual Meeting of the Association for Computational Lin-", "citeRegEx": "Manning et al\\.,? 2014", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Corpus-based and knowledge-based measures of text semantic similarity", "author": ["Rada Mihalcea", "Courtney Corley", "Carlo Strapparava."], "venue": "AAAI, volume 6, pages 775\u2013780.", "citeRegEx": "Mihalcea et al\\.,? 2006", "shortCiteRegEx": "Mihalcea et al\\.", "year": 2006}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in Neural Information Processing Systems, pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Using summarization to discover argument facets in dialog", "author": ["Amita Misra", "Pranav Anand", "Jean E. Fox Tree", "Marilyn Walker."], "venue": "Proc. of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human", "citeRegEx": "Misra et al\\.,? 2015", "shortCiteRegEx": "Misra et al\\.", "year": 2015}, {"title": "Argumentation mining in parliamentary discourse", "author": ["Nona Naderi", "Graeme Hirst."], "venue": "CMNA 2015: 15th workshop on Computational Models of Natural Argument.", "citeRegEx": "Naderi and Hirst.,? 2015", "shortCiteRegEx": "Naderi and Hirst.", "year": 2015}, {"title": "Evaluating content selection in summarization: The pyramid method", "author": ["Ani Nenkova", "Rebecca Passonneau."], "venue": "Proc. of Joint Annual Meeting of Human Language Technology and the North American chapter of the Association for Computational", "citeRegEx": "Nenkova and Passonneau.,? 2004", "shortCiteRegEx": "Nenkova and Passonneau.", "year": 2004}, {"title": "Ranking the annotators: An agreement study on argumentation structure", "author": ["Andreas Peldszus", "Manfred Stede."], "venue": "Proc. of the 7th linguistic annotation workshop and interoperability with discourse, pages 196\u2013204.", "citeRegEx": "Peldszus and Stede.,? 2013", "shortCiteRegEx": "Peldszus and Stede.", "year": 2013}, {"title": "LIWC: Linguistic Inquiry and Word Count", "author": ["James W. Pennebaker", "L.E. Francis", "R.J. Booth"], "venue": null, "citeRegEx": "Pennebaker et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Pennebaker et al\\.", "year": 2001}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "EMNLP, volume 14, pages 1532\u2013 1543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Araucaria: Software for argument analysis, diagramming and representation", "author": ["Chris Reed", "Glenn Rowe."], "venue": "International Journal on Artificial Intelligence Tools, 13(04):961\u2013979.", "citeRegEx": "Reed and Rowe.,? 2004", "shortCiteRegEx": "Reed and Rowe.", "year": 2004}, {"title": "Software Framework for Topic Modelling with Large Corpora", "author": ["Radim \u0158eh\u016f\u0159ek", "Petr Sojka."], "venue": "Proc. of the LREC 2010 Workshop on New Challenges for NLP Frameworks, pages 45\u201350.", "citeRegEx": "\u0158eh\u016f\u0159ek and Sojka.,? 2010", "shortCiteRegEx": "\u0158eh\u016f\u0159ek and Sojka.", "year": 2010}, {"title": "Fluency, adequacy, or HTER? Exploring different human judgments with a tunable MT metric", "author": ["Matthew Snover", "Nitin Madnani", "Bonnie Dorr", "Richard Schwartz."], "venue": "Proceedings of the Fourth Workshop on Statistical Machine Translation, pages", "citeRegEx": "Snover et al\\.,? 2009", "shortCiteRegEx": "Snover et al\\.", "year": 2009}, {"title": "Recognizing stances in online debates", "author": ["Swapna Somasundaran", "Janyce Wiebe."], "venue": "Proc. of the 47th Annual Meeting of the ACL, pages 226\u2013234.", "citeRegEx": "Somasundaran and Wiebe.,? 2009", "shortCiteRegEx": "Somasundaran and Wiebe.", "year": 2009}, {"title": "Annotating argument components and relations in persuasive essays", "author": ["Christian Stab", "Iryna Gurevych."], "venue": "Proc. of the 25th International Conference on Computational Linguistics (COLING 2014), pages 1501\u20131510.", "citeRegEx": "Stab and Gurevych.,? 2014", "shortCiteRegEx": "Stab and Gurevych.", "year": 2014}, {"title": "Argument mining: Extracting arguments from online dialogue", "author": ["Reid Swanson", "Brian Ecker", "Marilyn Walker."], "venue": "Proc. of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 217\u2013226.", "citeRegEx": "Swanson et al\\.,? 2015", "shortCiteRegEx": "Swanson et al\\.", "year": 2015}, {"title": "The Uses of Argument", "author": ["Stephen E. Toulmin."], "venue": "Cambridge University Press.", "citeRegEx": "Toulmin.,? 1958", "shortCiteRegEx": "Toulmin.", "year": 1958}, {"title": "Argumentation Schemes", "author": ["Douglas Walton", "Chris Reed", "Fabrizio Macagno."], "venue": "Cambridge University Press.", "citeRegEx": "Walton et al\\.,? 2008", "shortCiteRegEx": "Walton et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "0 corpus of online dialogs (Abbott et al., 2016).", "startOffset": 27, "endOffset": 48}, {"referenceID": 29, "context": "extends our previous work which frames our goal as consisting of two tasks (Misra et al., 2015; Swanson et al., 2015).", "startOffset": 75, "endOffset": 117}, {"referenceID": 40, "context": "extends our previous work which frames our goal as consisting of two tasks (Misra et al., 2015; Swanson et al., 2015).", "startOffset": 75, "endOffset": 117}, {"referenceID": 40, "context": "Our previous work on Argument Extraction achieved good results, (Swanson et al., 2015), and is extended here (Sec.", "startOffset": 64, "endOffset": 86}, {"referenceID": 18, "context": "tences using these facets, and trains a classifier to return a facet label (Conrad et al., 2012; Hasan and Ng, 2014; Boltuzic and \u0160najder, 2014; Naderi and Hirst, 2015), inter alia.", "startOffset": 75, "endOffset": 168}, {"referenceID": 4, "context": "tences using these facets, and trains a classifier to return a facet label (Conrad et al., 2012; Hasan and Ng, 2014; Boltuzic and \u0160najder, 2014; Naderi and Hirst, 2015), inter alia.", "startOffset": 75, "endOffset": 168}, {"referenceID": 30, "context": "tences using these facets, and trains a classifier to return a facet label (Conrad et al., 2012; Hasan and Ng, 2014; Boltuzic and \u0160najder, 2014; Naderi and Hirst, 2015), inter alia.", "startOffset": 75, "endOffset": 168}, {"referenceID": 29, "context": "In our previous work on AFS, we developed an AFS regressor for predicting the similarity of human-generated labels for summaries of dialogic arguments (Misra et al., 2015).", "startOffset": 151, "endOffset": 171}, {"referenceID": 31, "context": "We collected 5 human summaries of each dialog, and then used the Pyramid tool and scheme to annotate sentences from these summaries as contributors to (paraphrases of) a particular facet (Nenkova and Passonneau, 2004).", "startOffset": 187, "endOffset": 217}, {"referenceID": 0, "context": "0 (Abbott et al., 2016).", "startOffset": 2, "endOffset": 23}, {"referenceID": 40, "context": "gressor from Swanson et al. (2015), which gives a score to each sentence.", "startOffset": 13, "endOffset": 35}, {"referenceID": 40, "context": "gressor from Swanson et al. (2015), which gives a score to each sentence. The AQ score is intended to reflect how easily the speaker\u2019s argument can be understood from the sentence without any context. Easily understandable sentences are assumed to be prime candidates for producing extractive summaries. In Swanson et al. (2015), the annotators rated AQ using a continuous slider ranging from hard (0.", "startOffset": 13, "endOffset": 329}, {"referenceID": 40, "context": "As noted above, the sample in Swanson et al. (2015) was filtered using PMI, and PMI contributes to AQ.", "startOffset": 30, "endOffset": 52}, {"referenceID": 8, "context": ", 2013; Dolan and Brockett, 2005; Mihalcea et al., 2006). STS measures the degree of semantic similarity between a pair of sentences with values that range from 0 to 5. Inspired by the scale used for STS, we first define what a facet is, and then define the values of the AFS scale as shown in Fig. 10 in the appendix (repeated from Misra et al. (2015) for convenience).", "startOffset": 8, "endOffset": 353}, {"referenceID": 13, "context": "Related work has primarily used entailment or semantic equivalence to define argument similarity (Habernal and Gurevych, 2015; Boltuzic and \u0160najder, 2015; Boltuzic and \u0160najder, 2015; Habernal et al., 2014).", "startOffset": 97, "endOffset": 205}, {"referenceID": 5, "context": "Related work has primarily used entailment or semantic equivalence to define argument similarity (Habernal and Gurevych, 2015; Boltuzic and \u0160najder, 2015; Boltuzic and \u0160najder, 2015; Habernal et al., 2014).", "startOffset": 97, "endOffset": 205}, {"referenceID": 5, "context": "Related work has primarily used entailment or semantic equivalence to define argument similarity (Habernal and Gurevych, 2015; Boltuzic and \u0160najder, 2015; Boltuzic and \u0160najder, 2015; Habernal et al., 2014).", "startOffset": 97, "endOffset": 205}, {"referenceID": 15, "context": "Related work has primarily used entailment or semantic equivalence to define argument similarity (Habernal and Gurevych, 2015; Boltuzic and \u0160najder, 2015; Boltuzic and \u0160najder, 2015; Habernal et al., 2014).", "startOffset": 97, "endOffset": 205}, {"referenceID": 16, "context": "We therefore used UMBC STS (Han et al., 2013) to score all potential pairs.", "startOffset": 27, "endOffset": 45}, {"referenceID": 24, "context": "Rouge is a family of metrics for comparing the similarity of two summaries (Lin, 2004), which measures overlapping units such as continuous and skip ngrams, common subsequences, and word pairs.", "startOffset": 75, "endOffset": 86}, {"referenceID": 1, "context": "We consider STS, a measure of the semantic similarity of two texts (Agirre et al., 2012), as another baseline, using the UMBC STS tool.", "startOffset": 67, "endOffset": 88}, {"referenceID": 28, "context": "Word embeddings from word2vec (Mikolov et al., 2013) are popular for expressing semantic relationships between words, but using word embeddings to express entire sentences often requires some compromises.", "startOffset": 30, "endOffset": 52}, {"referenceID": 13, "context": "Previous work on argument mining has developed methods using word2vec that are effective for clustering similar arguments (Habernal and Gurevych, 2015; Boltuzic and \u0160najder, 2015) Other research creates embeddings at the sen-", "startOffset": 122, "endOffset": 179}, {"referenceID": 5, "context": "Previous work on argument mining has developed methods using word2vec that are effective for clustering similar arguments (Habernal and Gurevych, 2015; Boltuzic and \u0160najder, 2015) Other research creates embeddings at the sen-", "startOffset": 122, "endOffset": 179}, {"referenceID": 22, "context": "tence level using more advanced techniques such as Paragraph Vectors (Le and Mikolov, 2014).", "startOffset": 69, "endOffset": 91}, {"referenceID": 36, "context": "We also create our own 300-dimensional embeddings for our dialogic domain using the Gensim library (\u0158eh\u016f\u0159ek and Sojka, 2010), with default settings, and a very large corpus of user-generated dialogic content.", "startOffset": 99, "endOffset": 124}, {"referenceID": 33, "context": "ful in previous work (Pennebaker et al., 2001; Somasundaran and Wiebe, 2009; Hasan and Ng, 2013).", "startOffset": 21, "endOffset": 96}, {"referenceID": 38, "context": "ful in previous work (Pennebaker et al., 2001; Somasundaran and Wiebe, 2009; Hasan and Ng, 2013).", "startOffset": 21, "endOffset": 96}, {"referenceID": 17, "context": "ful in previous work (Pennebaker et al., 2001; Somasundaran and Wiebe, 2009; Hasan and Ng, 2013).", "startOffset": 21, "endOffset": 96}, {"referenceID": 20, "context": "We create partially generalized LIWC dependency features and count overlap normalized by sentence length across pairs, building on previous work (Joshi and Penstein-Ros\u00e9, 2009).", "startOffset": 145, "endOffset": 176}, {"referenceID": 26, "context": "Stanford dependency features (Manning et al., 2014) are generalized by leaving one dependency element lexicalized, replacing the other word in the dependency relation with its LIWC category and by removing the actual dependency type (nsubj, dobj,", "startOffset": 29, "endOffset": 51}, {"referenceID": 13, "context": "Although it is common to translate word embeddings into single features or reduced feature sets for similarity through the use of clustering (Habernal and Gurevych, 2015) or cosine similarity (Boltuzic and \u0160najder, 2015), we show that it", "startOffset": 141, "endOffset": 170}, {"referenceID": 5, "context": "Although it is common to translate word embeddings into single features or reduced feature sets for similarity through the use of clustering (Habernal and Gurevych, 2015) or cosine similarity (Boltuzic and \u0160najder, 2015), we show that it", "startOffset": 192, "endOffset": 220}, {"referenceID": 23, "context": "For sentiment classification, Li et al. (2015) find that \u201ctoo large a dimensionality leads many dimensions to be non-functional .", "startOffset": 30, "endOffset": 47}, {"referenceID": 19, "context": "There are many theories of argumentation that might be applicable for our task (Jackson and Jacobs, 1980; Reed and Rowe, 2004; Walton et al., 2008; Gilbert, 1997; Toulmin, 1958; Dung, 1995), but one definition of argument structure may not work for every NLP task.", "startOffset": 79, "endOffset": 189}, {"referenceID": 35, "context": "There are many theories of argumentation that might be applicable for our task (Jackson and Jacobs, 1980; Reed and Rowe, 2004; Walton et al., 2008; Gilbert, 1997; Toulmin, 1958; Dung, 1995), but one definition of argument structure may not work for every NLP task.", "startOffset": 79, "endOffset": 189}, {"referenceID": 42, "context": "There are many theories of argumentation that might be applicable for our task (Jackson and Jacobs, 1980; Reed and Rowe, 2004; Walton et al., 2008; Gilbert, 1997; Toulmin, 1958; Dung, 1995), but one definition of argument structure may not work for every NLP task.", "startOffset": 79, "endOffset": 189}, {"referenceID": 11, "context": "There are many theories of argumentation that might be applicable for our task (Jackson and Jacobs, 1980; Reed and Rowe, 2004; Walton et al., 2008; Gilbert, 1997; Toulmin, 1958; Dung, 1995), but one definition of argument structure may not work for every NLP task.", "startOffset": 79, "endOffset": 189}, {"referenceID": 41, "context": "There are many theories of argumentation that might be applicable for our task (Jackson and Jacobs, 1980; Reed and Rowe, 2004; Walton et al., 2008; Gilbert, 1997; Toulmin, 1958; Dung, 1995), but one definition of argument structure may not work for every NLP task.", "startOffset": 79, "endOffset": 189}, {"referenceID": 9, "context": "There are many theories of argumentation that might be applicable for our task (Jackson and Jacobs, 1980; Reed and Rowe, 2004; Walton et al., 2008; Gilbert, 1997; Toulmin, 1958; Dung, 1995), but one definition of argument structure may not work for every NLP task.", "startOffset": 79, "endOffset": 189}, {"referenceID": 39, "context": "are often informal, and do not necessarily follow logical rules or schemas of argumentation (Stab and Gurevych, 2014; Peldszus and Stede, 2013; Ghosh et al., 2014; Habernal et al., 2014; Goudas et al., 2014; Cabrio and Villata, 2012).", "startOffset": 92, "endOffset": 233}, {"referenceID": 32, "context": "are often informal, and do not necessarily follow logical rules or schemas of argumentation (Stab and Gurevych, 2014; Peldszus and Stede, 2013; Ghosh et al., 2014; Habernal et al., 2014; Goudas et al., 2014; Cabrio and Villata, 2012).", "startOffset": 92, "endOffset": 233}, {"referenceID": 10, "context": "are often informal, and do not necessarily follow logical rules or schemas of argumentation (Stab and Gurevych, 2014; Peldszus and Stede, 2013; Ghosh et al., 2014; Habernal et al., 2014; Goudas et al., 2014; Cabrio and Villata, 2012).", "startOffset": 92, "endOffset": 233}, {"referenceID": 15, "context": "are often informal, and do not necessarily follow logical rules or schemas of argumentation (Stab and Gurevych, 2014; Peldszus and Stede, 2013; Ghosh et al., 2014; Habernal et al., 2014; Goudas et al., 2014; Cabrio and Villata, 2012).", "startOffset": 92, "endOffset": 233}, {"referenceID": 12, "context": "are often informal, and do not necessarily follow logical rules or schemas of argumentation (Stab and Gurevych, 2014; Peldszus and Stede, 2013; Ghosh et al., 2014; Habernal et al., 2014; Goudas et al., 2014; Cabrio and Villata, 2012).", "startOffset": 92, "endOffset": 233}, {"referenceID": 6, "context": "are often informal, and do not necessarily follow logical rules or schemas of argumentation (Stab and Gurevych, 2014; Peldszus and Stede, 2013; Ghosh et al., 2014; Habernal et al., 2014; Goudas et al., 2014; Cabrio and Villata, 2012).", "startOffset": 92, "endOffset": 233}, {"referenceID": 6, "context": ", 2014; Cabrio and Villata, 2012). Moreover, in social media, segments of text that are argumentative must first be identified, as in our Task1. Habernal and Gurevych (2016) train a classifier to recognize text segments that are argumentative, but much previous work does Task1 manually.", "startOffset": 8, "endOffset": 174}, {"referenceID": 6, "context": ", 2014; Cabrio and Villata, 2012). Moreover, in social media, segments of text that are argumentative must first be identified, as in our Task1. Habernal and Gurevych (2016) train a classifier to recognize text segments that are argumentative, but much previous work does Task1 manually. Goudas et al. (2014) annotate 16,000 sentences from social media documents and con-", "startOffset": 8, "endOffset": 309}, {"referenceID": 14, "context": "Hasan and Ng (2014) also manually identify argumentative sentences, while Boltuzic and \u0160najder (2014) treat the whole post as argumentative, after manually removing \u201cspam\u201d posts.", "startOffset": 0, "endOffset": 20}, {"referenceID": 3, "context": "Hasan and Ng (2014) also manually identify argumentative sentences, while Boltuzic and \u0160najder (2014) treat the whole post as argumentative, after manually removing \u201cspam\u201d posts.", "startOffset": 74, "endOffset": 102}, {"referenceID": 3, "context": "Biran and Rambow (2011) automatically identify justifications as a structural component of an argument.", "startOffset": 0, "endOffset": 24}, {"referenceID": 18, "context": "are functionally similar to our facets as discussed above (Conrad et al., 2012; Hasan and Ng, 2014; Boltuzic and \u0160najder, 2014; Naderi and Hirst, 2015).", "startOffset": 58, "endOffset": 151}, {"referenceID": 4, "context": "are functionally similar to our facets as discussed above (Conrad et al., 2012; Hasan and Ng, 2014; Boltuzic and \u0160najder, 2014; Naderi and Hirst, 2015).", "startOffset": 58, "endOffset": 151}, {"referenceID": 30, "context": "are functionally similar to our facets as discussed above (Conrad et al., 2012; Hasan and Ng, 2014; Boltuzic and \u0160najder, 2014; Naderi and Hirst, 2015).", "startOffset": 58, "endOffset": 151}, {"referenceID": 4, "context": ", 2012; Hasan and Ng, 2014; Boltuzic and \u0160najder, 2014; Naderi and Hirst, 2015). For example, Fig. 2 lists facets A1 to A8 for Gun Control from the IDebate website; Boltuzic and \u0160najder (2015) use this list to label posts.", "startOffset": 28, "endOffset": 193}, {"referenceID": 25, "context": "Previous work shows that metrics used for evaluating machine translation quality perform well on paraphrase recognition tasks (Madnani et al., 2012).", "startOffset": 126, "endOffset": 148}, {"referenceID": 37, "context": "In our experiments, ROUGE performed very well, suggesting that other machine translation metrics such as Terp and Meteor may be useful (Snover et al., 2009; Lavie and Denkowski, 2009).", "startOffset": 135, "endOffset": 183}, {"referenceID": 21, "context": "In our experiments, ROUGE performed very well, suggesting that other machine translation metrics such as Terp and Meteor may be useful (Snover et al., 2009; Lavie and Denkowski, 2009).", "startOffset": 135, "endOffset": 183}, {"referenceID": 13, "context": "Habernal and Gurevych (2015) apply clustering in argument mining by averaging word embeddings from posts and sentences from debate portals, clustering the resulting averaged vectors, and then computing distance measures from clusters to unseen sentences (\u201cclassification units\u201d)", "startOffset": 0, "endOffset": 29}, {"referenceID": 4, "context": "Cosine similarity between weighted and summed vector representations is also a common approach, and Boltuzic and \u0160najder (2015) show word2vec cosine similarity beats bag-ofwords and STS baselines when used with clustering for argument identification.", "startOffset": 100, "endOffset": 128}], "year": 2017, "abstractText": "When people converse about social or political topics, similar arguments are often paraphrased by different speakers, across many different conversations. Debate websites produce curated summaries of arguments on such topics; these summaries typically consist of lists of sentences that represent frequently paraphrased propositions, or labels capturing the essence of one particular aspect of an argument, e.g. Morality or Second Amendment. We call these frequently paraphrased propositions ARGUMENT FACETS. Like these curated sites, our goal is to induce and identify argument facets across multiple conversations, and produce summaries. However, we aim to do this automatically. We frame the problem as consisting of two steps: we first extract sentences that express an argument from raw social media dialogs, and then rank the extracted arguments in terms of their similarity to one another. Sets of similar arguments are used to represent argument facets. We show here that we can predict ARGUMENT FACET SIMILARITY with a correlation averaging 0.63 compared to a human topline averaging 0.68 over three debate topics, easily beating several reasonable baselines.", "creator": "LaTeX with hyperref package"}}}