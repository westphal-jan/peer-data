{"id": "1709.01953", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Sep-2017", "title": "Implicit Regularization in Deep Learning", "abstract": "In an attempt to better understand generalization in deep learning, we study several possible explanations. We show that implicit regularization induced by the optimization method is playing a key role in generalization and success of deep learning models. Motivated by this view, we study how different complexity measures can ensure generalization and explain how optimization algorithms can implicitly regularize complexity measures. We empirically investigate the ability of these measures to explain different observed phenomena in deep learning. We further study the invariances in neural networks, suggest complexity measures and optimization algorithms that have similar invariances to those in neural networks and evaluate them on a number of learning tasks.", "histories": [["v1", "Wed, 6 Sep 2017 18:12:04 GMT  (4563kb,D)", "http://arxiv.org/abs/1709.01953v1", "PhD Thesis"], ["v2", "Fri, 8 Sep 2017 03:27:06 GMT  (4563kb,D)", "http://arxiv.org/abs/1709.01953v2", "PhD Thesis"]], "COMMENTS": "PhD Thesis", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["behnam neyshabur"], "accepted": false, "id": "1709.01953"}, "pdf": {"name": "1709.01953.pdf", "metadata": {"source": "CRF", "title": "Implicit Regularization in Deep Learning", "authors": ["Behnam Neyshabur", "Yury Makarychev", "Ruslan Salakhutdinov", "Gregory Shakhnarovich"], "emails": [], "sections": [{"heading": null, "text": "This year it has come to be a reactionary, reactionary, reactionary and reactionary party."}, {"heading": "1 Introduction 12", "text": "1.1 Main contributions.................................. 13"}, {"heading": "2 Preliminaries 15", "text": "2.1 The Statistical Learning Framework.............. 152.2 Advanced Neural Networks with Common Weight......... 16I Implicit Regularization and Generalization 18"}, {"heading": "3 Generalization and Capacity Control 19", "text": "3.1 VC Dimension: A Cardinality-Based Arguments........ 193.2 Norms and Margins: Counting real-world functions........ 203.3 Robustness: Lipschitz continuity in terms of input....... 213.4 PAC-Bayesian framework: sharpness in terms of parameters... 22"}, {"heading": "4 On the Role of Implicit Regularization in Generalization 25", "text": "4.1 Network size and generalization................. 264.2 A matrix factorization analogy....................."}, {"heading": "5 Norm-based Capacity Control 31", "text": "5.1 Group Standard Regularization................................. 325.2 Per Unit and Path Regularization.................... 365.3 General Regularization....................................................................................................................................................................................."}, {"heading": "6 Sharpness/PAC-Bayes Generalization Bounds 52", "text": "6.1 Spectral normalized margin limits.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "7 Empirical Investigation 63", "text": "7.1 Complexity Measures.................................. 637.2 Experiments...................... 647.3 Real Labels Vs. Random Labels......................................................."}, {"heading": "II Geometry of Optimization and Generalization 69", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8 Invariances 70", "text": "8.1 Invariances in feedback and feedback networks...... 708.2 Understanding of invariances........................................ 728.3 Evidence..............................................."}, {"heading": "9 Path-Normalization for Feedforward and Recurrent Neural Networks 80", "text": "........................................................................................"}, {"heading": "10 Experiments on Path-SGD 87", "text": "10.1 Experiments on fully networked feedback networks...... 8710.2 Experiments on recurrent neural networks........... 90"}, {"heading": "11 Data-Dependent Path Normalization 93", "text": "The answer to this question is: \"There is no answer to this question.\" The answer to this question is: \"There is no answer to this question.\" The answer: \"There is no answer to this question.\" The answer: \"There is no answer to this question.\" The answer: \"There is no answer to this question.\" The answer: \"There is no answer to this question.\" The answer: \"There is no answer to this question.\" The answer: \"There is no answer to this question.\" The answer: \"There is no answer to this question.\" The answer: \"There is no answer to this question.\" The answer: \"There is no answer to this question.\" The answer: \"There is no answer to this question.\""}, {"heading": "2.1 The Statistical Learning Framework", "text": "In this section we briefly review the statistical learning framework. Further details on the formal model can be found in Shalev-Shwartz and Ben-David (8). (xm, ym) of m training points in X \u00b7 Y that are independently and identically distributed (i.e.) according to an unknown distribution D. For simplicity, we will focus on the task of classification, where the goal of the learner is to generate a predictor f: X \u2192 Y with minimal expected errors in samples derived from the distribution D: LD (f) = P (x) sp = y] (2.1.1) Since the learner has no access to the distribution D, he cannot evaluate or minimize the expected loss. (f) However, an estimate of the expected loss of a predictor f can be obtained."}, {"heading": "2.2 Feedforward Neural Networks with Shared Weights", "text": "We define a \"forward\" network by a tripartite relationship (G, w, \u03c3) where G = (V, E) is a direct acyclic diagram of the number of nodes V corresponding to the units V and V in the network, including special input nodes Vin-V with no incoming edges and special output nodes Vout-V without outgoing edges, w: E \u2192 R is the weighting associated with the edges and which has an activation function. Feedforward network (G, w, p) calculates the function fG, w, p: Rnin \u2192 Rnout for a given input vector x Rnin as follows: R \u2192 R is an activation function whose output hv is the corresponding coordinate of x 1.; for all internal nodes except the input and output nodes the output value is defined according to forward propagation: hv (u \u2192 v)."}, {"heading": "3.1 VC Dimension: A Cardinality-Based Arguments", "text": "Consider a finite model of class F < 1, we can say that with a probability of more than 3.1 we can use the averaged independent random variables and the expected error of the excluded value of the training error. Therefore, we can use Hoeffding's inequality upper limits of generalization errors with high probability: P [L) -L (f) -L (f) -L (f) -L (f) -L (f) -L (f) -L (f) -L (f) -L we must ensure that all predictors in F have low generalization errors that exceed model class F (f) -L (f) -L) -L (f) -L (f) -L (f) -L (f) -L (f) -L (f) -L (f) -L (f) -L (f) -2) -mt2 (3,1,2)."}, {"heading": "3.2 Norms and Margins: Counting Real-Valued Functions", "text": "The model classes we learn are often functions with real-evaluated results, and for each task we use a different loss and prediction method based on the predicted values. For example, for binary20 classification, the threshold of only real-evaluated results is chosen as the predicted label. As the model class has real results, we cannot directly use the VC dimension here. Instead, we can use a similar concept called the Subgraph VC dimension, which is similar to the VC dimension, where the difference is that we count the number of different behaviors with a given margin. In the binary case, we can use yf (x) for some margin units. There are various techniques that combine the Subgraph VC dimension with the Radex dimension, where the difference is that we calculate the number of different behaviors with a given margin."}, {"heading": "3.3 Robustness: Lipschitz Continuity with Respect to Input", "text": "Some of the measurements / standards also control the Lipschitz constant of the model class in terms of its input, such as capacity based on (3,2,4). Is capacity control achieved by limiting it to the Lipschitz constant? Is limiting the Lipschitz constant alone sufficient for generalization? To answer these questions and to understand the capacity control in the sense of Lipschitz continuity more comprehensively, we are examining the relevant guarantees here. In view of an input space X and metricM, a function f: X \u2192 R in a metric space (X, M) is referred to as the Lipschitz function when there is a constant CM constant, so that | f (x) \u2212 f (y) | CMM (x, y). Luxburg and Bousquet [29] investigated the capacity of functions with a limited Lipschitz constant in the metric space (X), M, the constant of the M (M), the constant of the Lipschitz (X)."}, {"heading": "3.4 PAC-Bayesian Framework: Sharpness with Respect to Parameters", "text": "The notion of sharpness as one of two relevant yardsticks was recently proposed by Keskar and al. [13] This corresponds to a variety of clues in terms of the mutual influences on the parameter space. [13] We have the notion of sharpness as a generalization. [14] We have the notion of sharpness as one of two relevant yardsticks. [14] We have the notion of sharpness as one of two relevant yardsticks in terms of the expected sharpness in the context of the PAC-Bayesian framework and the ability to control sharpness. [14] We have the notion of sharpness as one of two relevant terms and need to be balanced with other yardsticks such as the norm. [16] We have the notion of the expected sharpness in the context of the PAC-Bayesian framework."}, {"heading": "On the Role of Implicit Regularization", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we are able, that we are able, that we are able, and that we are able, that we are able, that we are able, to be able, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in the position we are in."}, {"heading": "4.1 Network Size and Generalization", "text": "We look at the formation of a feedback network by finding the weights that minimize the training error. Specifically, we will consider a fully connected feedback network with a hidden layer that includes H. The weights we have learned by increasing the network size H will inevitably decrease. Initially, the verification error could decrease as the approximation error is reduced, and the network is better able to capture the targets. However, as the size continues to increase, we lose our capacity control and generalization capability, and should start reviewing. This is the classic approximation estimate of trading behavior. However, consider the results shown in Figure 4.1, where we have trained networks to increase the size of the MNIST and CIFAR-10 datasets."}, {"heading": "4.2 A Matrix Factorization Analogy", "text": "This year, it has reached the stage where it will be able to put itself at the forefront in order to embark on the path to the future."}, {"heading": "5.1 Group Norm Regularization", "text": "Given the weight grouping that flows into each edge of the mesh, we will use the following q = q = q q (q = q = q) (q = q) (q = q) (q = q) (q = q) (q = q) (q = q) (q) (q) (q / p) (5.1.1) Here and elsewhere we allow q = p) with the usual conventions that (q) 1 / q = sup zi and 1 / q = 0 if they occur in other contexts. If q = q = p) the group regulator (9.1.1) imposes a regulation per unit where we restrict the norm of the incoming weight classes of each unit individually, and if q = p is the regulator (9.1.1) a \"total\" weight regulator that restricts the total norm of all weight classes in the system. E.g. if q = p = p, we pay the sum of all the weights in the mesh."}, {"heading": "5.1.1 Generalization and Capacity", "text": "To understand the effect of the standard on sample complexity, we have the Rademacher complexity of classes Fd, Hp, q, q. We remember that the Rademacher complexity is a measurement of the capacity of a model class on a given sample, which can be used to limit the difference between empirical and expected errors and thus the excess generalization error of empirical risk minimization (see, for example, [47] for a complete treatment, and Section 5.5.1 for the exact definitions we use). In particular, the Rademacher complexity is typically so pronounced that it corresponds to an example complexity of O (C / 2), where m is the sample size and C is the effective measurement of the capacity of the model class. Theorem 3. For all d, q \u00b2 1, each other p < and all other propositions S = x1,."}, {"heading": "5.1.2 Tightness", "text": "Next, we examine the density of the complexity bound in Theorem 3 and show that if 1 / p + 1 / q = q = q = q = q = 1 unit (1 / 2) the dependence on the width H is indeed unavoidable. We show not only that the limit of Rademacher complexity is narrow, but also that the implicit limit of sample complexity is narrow for binary classification with a border over binary inputs. To do this, we show how we can break the m = 2nin points {\u00b1 1} nin a network of small group norms: Theorem 5. For each p, q \u00b2 1 (and 1 / p) p \u00b2 s \u00b2 size and each depth d = 2 that m = 2nin points {\u00b1 1} nin a network can be fragmented."}, {"heading": "5.1.3 Convexity", "text": "We refer to the convexity of the functions in Fdp, q independent of a specific representation. If we consider a possible 35 regulated empirical risk minimization problem on the side of weights, the goal (empirical risk) would never be a convex function of weights (for depth d \u2265 2), even if the regularizer is convex in w (which it is always for p, q \u2265 1). But if we do not bind the width of the network and instead rely solely on the magnitude control, we will see that the resulting model class and indeed the complexity quantity in w can be convex (in terms of the convex combinations of functions, not weights). Theorem 6. For each d, p, q \u2265 1 such convex that 1q \u2264 1d \u2212 1 (1 \u2212 1p), q (f) we are in terms of the convex combinations of functions, not weights."}, {"heading": "5.2 Per-Unit and Path Regularization", "text": "In this section we will focus on the specific case of q1 e2, i.e. if we do not comply with the norm of incoming weight proportions of the individual units (1) (1). (1) We will deal with regulation in a different way (2). (2) We will now deal with a specific form of RELU activation and discuss its equivalence to per-unit regulation. (2) We will discuss its equivalence to per-unit regulation. (2) We will look at the sum of all the paths that lead from the starting nodes to the starting nodes. (3) We will present and discuss the product of weight requirements along the way (3). (4) e2) e2 e2 e2 e2 e2 e2 e."}, {"heading": "5.3 Overall Regularization", "text": "In this section, we will focus on \"general\" p-regularization corresponding to the choice q = p, i.e., if we apply the general (vectorized) norm of all weight classes in the system: p (w) = (p) = (p) 1 / p.Capacity For p \u2264 2, Corollary 4 provides a generalization guarantee that is independent of width - we can conclude that if we use weight decay (Total '2 regularization), there is no need to limit ourselves to networks of limited size (as long as the corresponding dual norm of inputs is limited). However, in Section 5.1.2, we saw that regularization with d-3 layers degenerates and leads to infinite capacity classes if we restrict p > 2. In any case, even if we restrict the overall norm 1-norm, the complexity explicitly increases with degeneration."}, {"heading": "5.4 Depth Independent Regularization", "text": "But we already know that we cannot rely only on a limitation to the group norm when the depth is infinite, as we know from Theorem 5 that sample complexity in terms of sample complexity inevitably increases exponentially with depth: if we allow arbitrarily deep graphs that we can shrink to zero without changing the scale of the calculated function, as we know from Theorem 5, we will necessarily increase sample complexity exponentially with depth."}, {"heading": "5.5 Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.5.1 Rademacher Complexities", "text": "The sample based Rademacher Complexity of a class F of function mapping from X to R in relation to a set S = {x1,.., xm} is defined as: Rm (F) = E [2). [3] Sample based Rademacher Complexity. [4] Sample based Rademacher Complexity. [5] Sample based Rademacher Complexity. [5] Sample based Rademacher Complexity. [6] Sample based Rademacher Complexity. [6] Sample. [6] Sample based Rademacher. [6] Sample based Rademacher. [7] Sample. [7] Sample. [7] Sample. [7] Sample. [7] Sample. Sample based Rademacher. [7] Sample. [7] Sample."}, {"heading": "5.5.2 Proof that \u03c8dp,q(w) is a semi-norm in Fd", "text": "The proof consists of three parts. Initially, we show that the level, the fdp, q, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p,"}, {"heading": "5.5.3 Path Regularization", "text": "\"We have a network in which we build a network, with which we build a network, in which we build such a network.\" \"We,\" he says, \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"\" We. \"\" \"We.\" \"\" \"We.\" \"\" \"\" We. \"\" \"\" We. \"\" \"\" \"We.\" \"\" \"We.\" \"\" \"We.\" \"\" \"We.\" \"\" \"We.\". \"\" We. \".\" \"We.\" \"\" We. \"\" \"We.\". \"We.\" \"We.\" \"We.\" We. \"\" We. \"We.\" \"We..\" We. \"\" We. \"\" We. \"\" We. \"\" We. \"We.\" \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" \"We.\" We. \"We.\" We. \"\" We. \"We.\" \"\" We. \"\" We. \"\" We. \"\" \"\" We. \"\" \"We.\" \"\" \"\" \"We.\""}, {"heading": "5.5.4 Hardness of Learning Neural Networks", "text": "Daniely et al. [11] show in theorem 5.4 and in section 7.2, which are subject to the strict random CSP assumption, that for each k = \u03c9 (1) the model class of the intersection of homogeneous hemispheres over half \u2212 1} n with norms in {\u00b1 1} is not efficiently (even improperly) learnable PAC 1. Furthermore, for each > 0, [55] this hardness result, which is subject to the intractability of Q (n1,5in), we can conclude -one-time shortest vector task for k = n in.If it is not possible to efficiently learn PAC intersections of hemispheres (even improperly), we can conclude that it is also not possible to efficiently learn PAC any model class that can represent such an intersection. In theory 24 we show that intersections of homogeneous hemispheres can be realized with a unit x."}, {"heading": "5.6 Discussion", "text": "We have presented a general framework for standards-based capacity control for feed nets and analysed when standards-based control is sufficient and to what extent capacity depends on other parameters; in particular, we have shown that at depth d > 2 networks, per unit control with p > 1 and general regularisation with p > 2 are not sufficient to ensure capacity control without control of network size, in contrast to linear models where with each p < \u221e we have only a weak dependence on dimensionality, and double-layer networks where per unit p > 2 is also sufficient for capacity control; we also have generalisation guarantees for the most natural form of regularisation, i.e. \"2 regularisation, and have shown that even with such a control we still have an exponential dependence on size, and double-layer networks where per unit p > 2 is sufficient for capacity control."}, {"heading": "6.1 Spectrally-Normalized Margin Bounds", "text": "As we discussed in Section 3.4, understanding the sharpness of the network is the key step in achieving a generalization associated with PAC-Bayes frames. The following problem shows that the sharpness can be limited by the product of the spectral standard of the network."}, {"heading": "6.2 Generalization Bound based on Expected Sharpness", "text": "We have shown how sharpness could allow us to generalize, because it can lead to lower values than the expected sharpness of a network with ReLU activations. Such conditions serve as useful guidance to investigate what leads a convergence optimization method to less sharp optimizations. Contrary to existing generalization limits, our sharpness can cause the network to have a high sharpness. Condition C1 below, such weak interaction (cancellations) also prevents a high sharpness when the number of activations is exponential in the perturbations, even for small perturbations. Condition C2 avoids such extreme situations when an inactive node with large weights becomes active."}, {"heading": "6.3 Supporting Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.3.1 Supporting Lemma", "text": "Let A, B n1 x n2 and n3 x n4 matrices and u be a n2 x n3 random Gaussian matrix with uij x N (0 x n). Then, E [2 x A, u x B, F] \u2264 3 x A, F x B, F, Proof. By Jensen's inequality, E [3 x A, u x B, F] 2 x E [4 x A, u x B, 2F] = E [5 x B, 2F] = E [5 x A, kl AikuklBlj2 = 5 x kl A2ikE [u2kl] B2lj = 8 x A, 2F x B, 2F."}, {"heading": "6.3.2 Conditions in Theorem 27", "text": "In this section, we compare the conditions in Theorem 27 of a learned network with those of its random initialization. We trained a 10-layer feedback network with 1000 hidden units in each layer of the MNIST dataset. Figures 6.2, 6.3, and 6.4 compare conditions C1, C2, and C3 for learned weights with those of the random initialization. Interestingly, we observe that the network with learned weights is very similar to its random initialization in terms of these conditions."}, {"heading": "6.4 Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.4.1 Proof of Lemma 25", "text": "Let us prove that the above inequality, together with (1 + 1d) d \u2264 e, proves the statement of the problem. the introductory basis clearly applies to each i = 0 = | x \u2212 x | 2 = 0. For each i + 1 we have the following: 56% i + 1 = 0% (Wi + 1 + Ui + 1) p \u2264 e (f iw + u (x)) \u2212 Wi + 1p (f iw (x)) p iw (f iw (x) p iw (x) p iw (x) p iw (x) p iw (c) p iw (c) p iw (c) p iw (c) p iw (c) p iw (c) p iw (c) p iw (c c c c c c c) p (c) p iw (c c c) w (c c w (c) iw (c w w (c) ip (w w w w w ip (c) p) p (p) p (p) p ip (p) p ip (p) p iw (c) p (c c c c c) iw (c c) w (c c) w (c) w (c) w (c w (c) w (c w (c) w (c) w (c w (c) w w (c w (c) w w w (c) p (w w) p (w w w ip) p (p (w w w) p (p) p (p) p ip (p) p (p) p (p (p) p iw) p iw (w) p iw (w c c c c c c c c) p (c c c c c) p iw (c c c c) p (w c c c) p (w (w c) p (w c c c) p iw (w w w (w (w w w w w w (w w w w w w w) p) p (p (p) p (p) p (p) p (p (p) p (p) p iw (p) p iw w w w w (p (p) p (p) p iw (p iw"}, {"heading": "6.4.2 Proof of Lemma 28", "text": "The proof: Definition g'W \u2212 i \u2212 j \u2212 i, i \u2212 i, i \u2212 i, i \u2212 i, i \u2212 i, i \u2212 i, i \u2212 i, i = i, i = i, i = i, i (W + u, i), x \u2212 Wd (W \u2212 d \u2212 1i = 1DiWi), x \u2212 F (W \u2212 i, i), x \u2212 F (W \u2212 j, i \u2212 i, i), x \u2212 F (W \u2212 j, i \u2212 i), x \u2212 F (W \u2212 j, i \u2212 i, i), x \u2212 F (W \u2212 j \u2212 i, i \u2212 i), x \u2212 F (W \u2212 i, i \u2212 i), x \u2212 F (W \u2212 f \u2212 i, i \u2212 i), x \u2212 W (W \u2212 f \u2212 i, i \u2212 i \u2212 W, i \u2212 ix), x (W \u2212 ix), W \u2212 ix (W \u2212 ix), i \u2212 \u2212."}, {"heading": "6.4.3 Proof of Lemma 29", "text": "Prove this dilemma by remembering that D-i is the diagonal matrix of 0's and 1's that corresponds to the disturbed network activation pattern fW + u (x). Let 1E denote the indicator function, i.e. 1 if event E is true, 0 otherwise. We also use fkW (x) to denote the network at level k, in particular fkW (x) = digit k i = digit 1 < (W) 1 \u2212 D1, x > 1 = digit 1 < (W + u) 1 < (W) 1, i > digit 1 < W1, x > digit 1 < (W) 1 < (W) 1, x > 2 < < < < < < (u) 1, x > digit 1 < (W) 1 < (W) 1 < x, 1 < (W) < < < < < < < < < < < (W) 1, 1 < < < < < < < < < (W) 1, 1 < < < (W) 1, 1 < (W) < 1, 1) < < (W) 1, 1 < (W) < (W) 1, 1, 1 < (W) < (W), 1) < 1, 1, 1 < (W) < < 1, 1, 1) < (W (W), 1, 1) < (W, 1) < (W, 1, 1) <"}, {"heading": "7.1 Complexity Measures", "text": "In this sense, it is only logical that we should be able to go in search of the causes of the crisis. (...) In this sense, it is also necessary to get a grip on the causes of the crisis. (...) In this sense, it is necessary to get a grip on the causes of the crisis. (...) In this sense, it is necessary to get a grip on the causes of the crisis. (...) In this sense, it is also necessary to get a grip on the causes of the crisis. (...) We have to get a grip on the causes of the crisis. (...) We have to get a grip on them. \"(...) We have to get a grip on the causes of the crisis.\" (...) \"We have to get a grip on them.\""}, {"heading": "7.2 Experiments Settings", "text": "In the experiment with different network sizes, we will also train a double-layer perceptron with ReLU activation and varying numbers of hidden units without batch normalization or dropout. In the rest of the experiments, we will train a modified version of the VGG architecture [59] with the configuration 2 \u00b7 [64, 3, 1], 2 \u00b7 [128, 3, 1], 2 \u00b7 [256, 3, 1], 2 \u00d7 [512, 3, 1], where we will drop the batch normalization before ReLU1We have dropped the term that only depends on the norm of input, the limits based on \"2-path norm and spectral norm,\" which we derive directly from the \"1-path norm and\" 2-norm. \"Without further weighting conditions, the exponential dependence on depth is narrow, but the 4d dependence may be loose [58]."}, {"heading": "7.3 True Labels Vs. Random Labels", "text": "In fact, it is the case that you are able to hide in the way that you see yourself able to put yourself at the top."}, {"heading": "7.4 Different Global Minima", "text": "To verify this characteristic, we can calculate each measure based on several different global minimums and see if lower values of the measurement imply a lower generalization error. However, to find different global minimums for the loss of training, we design an experiment in which we force the optimization methods to converge to different global minimums with different generalization capabilities by forming a confusion set that includes samples with random labels.66 optimization is performed for the loss containing examples from both the confusion set and the training set.Since deep learning models have a very high capacity, optimization through the union of the confusion set and training set generally leads to a point with zero errors over both confusion and training sets, thus a global minimum for the training set.We randomly choose a subset of CIFAR10 data sets with 10,000 data points as the training set, and our goal is to find networks that point zero errors over both confusion and training sets, which will multiply the confusion, but which we assign the different capabilities to the multiplication."}, {"heading": "7.5 Increasing Network Size", "text": "This year it is more than ever before."}, {"heading": "8.1 Invariances in Feedforward and Recurrent Neural Networks", "text": "Since our real object of interest is the function f, not the identity of the network, it would be advantageous if the optimization depended only on such transformations and would not be \"distracted.\" It is therefore helpful to examine the transformations that will not change the function of the network and whose performance will not be affected by such transformations. We say that a class of neural networks is invariant to achieve a transformation T if for each parameter setting p and its associated weights are not changed. Similarly, we say that an update rule A is invariant to T if for each p and its associated conversion w, fA (T).70 invariances are defined as different mappings from the parameter space to the same functions."}, {"heading": "8.2 Understanding Invariances", "text": "The aim of this section is also to discuss whether it is an inevitable transformation that can only take place in a limited framework. (This means that we will eliminate the need for a non-trivial initialization.) Thus, if we characterize the whole variety of transformations to which the model is invariant, we must first point out that an invariance can be composed. If a network G is invariant to transformations T1 and T2, it is also inevitable in its composition. (This means that an invariance can be composed.) If a network G is invariant to transformations T2, it is also invariant to its composition T2."}, {"heading": "8.2.1 Path-based characterization of the network", "text": "A major challenge in exploring degrees of freedom (8.2.3) is the fact that the Jacobian unit (x) / MP w depends on both parameters (x). In this section, we will first separate the two dependencies by defining the sum of all the directed paths from each starting node to each starting node as follows: fw (x), head (p) is the first node of path p, gp (x) takes 1 if all the rectified linear units along the path p are active and zero are different, and it is the set of all the directed paths from each starting node to v, head (p) is the first node of path p, gp (x) takes 1 if all the rectified linear units along the path p are active and zero are different, and endp (w) E (p) is the product of the weights along the path p; E (p) denotes the channels that appear along the path p."}, {"heading": "8.2.2 Combinatorial characterization of the rank of path Jacobian", "text": "Finally, we show that the rank of the path Jacobian matrix J (w) is determined purely combinatively by the graph G. The proof is in Section 8.3.Theorem 33. The rank of the path Jacobian matrix J (w) is generally equal to the number of parameters | E | minus the number of internal nodes of the mesh (except for a subset of the parameter space with zero Lebesgue dimension). Note that the dimension of the space spanned by the node-wise recalculation is generally equal to the number of internal nodes (node-wise recalculation). Therefore, the node-wise recalculation p is the only kind of invariance for a fixed-architecture ReLU network G, if dim (Span (x): x \u00b2 R | Vin |): x = x \u00b2 wameths [wameths wamex] does not have two [wameths wameths wamex] wameths [wameths wamex] wamex [wameths wamex] wameth-wise [wameth] wameth-only] wameth-wise [wameths wameth-wamex] wameth-only has two in [wameths wameths wameth-wamex] wameth-wise [wameth-wameth-wamex]."}, {"heading": "8.3 Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8.3.1 Proof of Theorem 31", "text": "First, we show that each RNN is invariable to T\u03b1 by induction on layers and time steps. More precisely, we prove that for each 0 \u2264 t \u2264 T and 1 \u2264 i < d, ~ hit (T\u03b1 (~ W)) [j] = \u03b1ij ~ hit (~ W) [j] = hit (~ W) [j] [j] = 1, if we assume that the statement is true for t = t \u00b2, then it also applies to t = t \u00b2 (T\u03b1 (~ W) [j] = \u03b1ij ~ hit (~ W) [j] = 0.Furthermore, we show that for i = 1, if we assume that the statement is true for t = t \u00b2, then it also applies for t = t \u00b2 (~ W)."}, {"heading": "8.3.2 Proof of Theorem 32", "text": "The proof: First, we see that (8,2,5) is true because (8,2) x [head (p)]) e-E = Jv (w) > \u00b7 \u03c6v (x).Therefore, (8,3) any vector of the form (x) [v] v (w) > \u00b7 v (x): v [v] v = J (w) > \u00b7 chip (x) = J (w) > \u00b7 chip (x): x [v] v | Vin |). (8,3) Consequently, any vector of the form (x) [v] v [v] v [v] v] v for a fixed input says x = J (w) > \u00b7 chip (x): x (x): x \u00b2 R | Vin |). (8,3) Each vector of the form (x) [v] v \u00b2 E for a fixed input x (v) lies in the span of the row vectors of the path of jacobic J (x)."}, {"heading": "8.3.3 Proof of Theorem 33", "text": "ieD rf\u00fc ide rf\u00fc ide nlrf\u00fc eeisn-eaeaJnlrsrdteeaJnlrh-eaeaJnlrh-eaJngr-eaJnlrsrteeaeaeoHnr-eaJnln-eaJngr-eaJnlrh-eaJnlrsrteeeoiaeeeSrlhc-nlrsrf\u00fc-eSrlrrteeoiaeoeSrlhc-nlrsrteeoiaeoi.nlpnlpnlrteeoS"}, {"heading": "9.1 Path-regularizer", "text": "We do not consider the generic group of regulators in Equation (9,1,1) to be very useful. (u) We consider the generic group of regulators in Equation (9,1,1). (u) As we discussed earlier, two simple cases of the above group standard (2,2) are very effective in RELU networks. (u) Another form of regulation that proves to be very effective in RELU networks is the maximum norm regularization, which is the maximum across all units of the norm from the incoming edge to Unit2 [67, 68]. The maximum norm corresponds to the \"per unit\" of regulation if we put q2 = \"per unit\" in Equation (9,1,1) and can be written in the following form (for q1 = 2). (u) The maximum norm of regulation corresponds to the \"per unit.\""}, {"heading": "9.2 Path-SGD for Feedforward Networks", "text": "Formally, for a network without common weights, where the parameters are the weights themselves, the diagonal square approach of the path controller to the current iteration w (t): \"2net (w (t) + 0\" 2net (w (t)) + 0 \"2net (w (t))),\" w \"(w) + 12\" w > diag (w (t)))) \"w\" (9.2) \"w\" (9.2) using the corresponding square standard w \u2212 w \u00b2 2net (w (t) + 0 \"w) = 1 2\" E \u00b2 E \u00b2 w2e \"(we \u2212 w \u00b2 e) 2\" (we \u2212 w \u00b2 e), \"we \u00b2 e\" 2 \"(we), which is an approximate downward step as: w (t + 1) = min\" L (w), w \u2212 w (t) + 0 \"c\" t \"t.\""}, {"heading": "9.3 Extending to Networks with Shared Weights", "text": "If the networks have split weights, the path regulator is a function of the parameters p = 3,2 (3,2) The square approximation should also be performed with respect to the iterate p (t) instead of p (t), which results from the following update rule: p (t + 1) = min p (p), p (t), p (p), p (p), p (p), p (t), p (t), p (p), p (p), p (p), p (p), p (p), p (p), p (t), p (p), p (p), p (p), p (t), p (t), p (t), p (t), p (t), p (p), p), p (p)."}, {"heading": "9.3.1 Simple and Efficient Computations", "text": "We show how to calculate using a grid of the same architecture but with square weights: Theorem 36. For each network N (G, \u03c0, p), we consider N (G, \u03c0, p), where for each i, p, i = p2i. We define the function g: R | Vin | \u2192 R to be the sum of the outputs of this network: g (x) = Vout | i = 1 f ~ p (x) [i]. Then we can define the function g: R | Vin | R to calculate the sum of the outputs of this network, as follows: p is the total number of outputs (1) (p) = 1 f ~ pg (2) i (~ p) = minimum of outputs (u \u2192 v), (u \u00b2 v \u00b2 v \u00b2) the total number of outputs p: p is the total number of outputs p: 1)."}, {"heading": "9.4 Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9.4.1 Proof of Lemma 34", "text": "x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "9.4.2 Proof of Theorem 35", "text": "The only difference is that some of them are now interconnected in such a way that shared weights have the same value after transformation. First, since the network is invariant for transformation, the following statement applies by induction similar to Theorem 31, but in the opposite direction: each of them is now bound in such a way that shared weights have the same value after transformation. First, since the network is invariant for transformation, the following statement by induction is similar to Theorem 31, but in the opposite direction: each of them is bound in a different direction."}, {"heading": "9.4.3 Proof of Theorem 36", "text": "First, it should be noted that based on the definitions in the theorem statement, for any node (v = 1), any node (v = 2), any node (v = 2), any node (v = 2), any node (v = 2), any node (v = 1), the corresponding node (p), and therefore g (1), is nothing other than the product of the square weights along the path except the weights corresponding to the edge e: ~ 1e), any node (v = 6 = (v = 1), the node (v = 1), which can be split into a path from the edge e and a path from the edge e to the exit. Therefore, for each edge e we can calculate the number corresponding to the node e (v = 6 = (v = 1), the node that go through e and the nodes (1), the v (1), the v = 1, the v (1), the v (v = 1, the (1), the nodes v = 1, the (v = 1), the (v = 1), the (v = 1), the (v = 1, the (v), the (v = 1), the (v = 1), the nodes (v = 1, the (v = 1), the (v = 1)."}, {"heading": "10.1 Experiments on Fully Connected Feedforward Networks", "text": "We compare 2-Path SGD to two commonly used deep learning optimization methods, SGD and AdaGrad. We conduct our experiments on four common benchmark datasets: the standard MNIST dataset of handwritten digits [70]; CIFAR-10 and CIFAR-100 datasets of tiny images of natural scenarios [71]; and Street View House Numbers (SVHN) datasets, which contain color images of house numbers collected by Google Street View [72]. Details of the datasets are given in Table 10.1.In all our experiments we have feed-forward networks with two hidden layers, each containing 4000 hidden units. We used mini-batches of size 100 and increments of crop, where an integer between 0 and 10. We choose what we choose for each dataset, we have set validation errors through validation (10,000 points are selected randomly during the first training)."}, {"heading": "10.2 Experiments on Recurrent Neural Networks", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10.2.1 The Contribution of the Second Term", "text": "In this section, we examine the meaning of the second term and show that the contribution of the second term to the update rule is negligible, at least in our experiments. To compare the two terms \u0432 (1) and \u0432 (2), we train a single-layer RNN with H = 200 hidden units for the task of word-level modeling at Penn Treebank (PTB) Corpus [74]. Fig. 10.3 shows that the performance of the first term is more significant and therefore we can ignore the performance of the second term. To better understand the meaning of the two terms, we have significantly exceeded the ratio of the two norms and the SGD. This results in Fig. 10.3 that the first term is more significant and that we can ignore the second term."}, {"heading": "10.2.2 Addition problem", "text": "This year, we will be able to go in search of a solution that will enable us, that will enable us, that will enable us, that will enable us, that will enable us, that will enable us, that will enable us, that will enable us, that will enable us, that will enable us, that will enable us, that will enable us, that will enable us, that will enable us to put ourselves in the position we are in."}, {"heading": "10.2.3 Language Modeling Tasks", "text": "In fact, it is such that it is a way in which people are able to survive themselves, and in which people are able to survive themselves. \"(S. S. S. S. S. S., S. S. S., S. S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S., S.,"}, {"heading": "11.1 A Unified Framework", "text": "We define a complexity measurement on each node as follows: \u03b3v (w) = \u221a w > \u2192 vRvw \u2192 v (11.1.1) 94where Rv is a positive semidefinitive matrix that could also depend on the calculations that flow into v, and records both the complexity of the nodes that flow into v and their interactions. We consider several options for Rv, which are also summarized in Table 1.A, and also ignore the effects of activation (since the activation pattern depends on the input distribution) and the dependencies between the different paths in the network. Intuitively, with this choice of Rv, the measurement of \"potentiality\" (w) variability or instability at the node. Another option is to introduce variability between different paths in the network."}, {"heading": "11.2 DD-Path Normalization: A Batch Normalization Approach", "text": "In this context, an optimization method is discussed that is based on securing all internal nodes that are based on the respective networks. (That is, the complexity of all internal nodes is \"normalized,\" and any scaling occurs only at the source nodes.) We show that the variance of the nodes is normalized throughout the training. (This means that the variance of the outputs is normalized throughout the training.) Considering an incoming network as a graph, for each node, the batch normalization architecture has as parameters an unnormalized weight vector and two additional scalars cv, bv-R specifies scaling and shifting."}, {"heading": "11.3 DD-Path-SGD: A Steepest Descent Approach", "text": "To do this, we must first remember the strong link between geometry, regulation and optimisation (that is, it takes a step in the direction in which the regulator maximises the improvement of the objective while being small in relation to the Euclidean standard of the step.) The step can also be considered a regularised optimisation of the linear approximation given by the gradient, where the regulator Euclidean standard is coupled to the Euclidean standard."}, {"heading": "11.4 Node-wise invariance", "text": "In this section, we show that DDP-SGD is invariant for nodal rescaling, while DDP normalization does not have favorable invariance characteristics."}, {"heading": "11.4.1 DDP-SGD on feedforward networks", "text": "To see if DDP-SGD is also invariant to such a recalculation, we consider a recalculated w \u2032 = T (w), where T is a recalculation by p at the node v. Let w + specify the weights after one step of the DDP-SGD. To determine the invariance for recalculation of the node, we must show that w \u2032 + = T (w +). For the outgoing weights of v we have: w \u2032 + v \u2192 j = \u03c1wv \u2192 j (w). For the incoming weights of v \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 j (w) x x x x x x x x (wv \u00b2 j) p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p."}, {"heading": "11.4.2 SGD on DDP-Normalized networks", "text": "Since DDP-normalized networks are the repair of feedback-forward networks, their invariances are different. As operations in DDP-normalized networks are based on W-shaped networks, we should examine the invariances for W-shaped networks. In this case, the invariances are given by scaling the incoming weights into a node, 100dh for an internal node v and scaling \u03c1 > 0: T (w-shaped) k-v (w-shaped N in (v)), while all other weights remain unchanged. DDP-normalized networks are invariant for the above transformation because the output of each node is normalized. However, the SGD update rule is not invariant for this transformation: T (w-shaped) + k-shaped v-shaped v-shaped v-shaped v-shaped v-shaped v-shaped v-shaped v-shaped v-shaped v-shaped v-shaped (w-shaped)."}, {"heading": "11.5 Supporting Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "11.5.1 Implementation of DDP-Normalization", "text": "Considering a series of data points, variance and gradients to be estimated, the stochastic gradients for the weight w (weights in the DDP normalized network) can then be calculated using the chain rule: \u2202 L-value w-value (v = 1 N-value) v = 1 N-value L-value z (i) vh (i) n in (v) \u2212 1 n-value j = 1 h (j) n in (v) \u2212 z-value (i) v 2v-value 2v-value v (v) v (11.5.1) v-value L-value v (i) v-value z (i) v \u2212 1 n-value j = 1 L-value z (j) v-value z (i) v-value z (i) v-value z (v) v-value z (i) v-value z (n) v (i) v-value) v (n-value) v (1) v-value) v-v (n) (1) v-v (n)."}, {"heading": "11.5.2 Implementation of DDP-SGD", "text": "In order to calculate the second derivatives, we can first calculate the first derivatives. Re-propagation can be done by z2u and z (i) u, but this makes it difficult to find the second derivatives. Instead, we propagate the loss by z2u = (u) z2netto z2u (u) z2netto z2u (i) u2: z2netto z2u = (1 \u2212) z2netto z2u = (u) z2netto z2u (u) z2netto z2u (u) z2netto z2u = (u) z2 (u) z2 z2 z2 (z2) z2 z2 zu (zu) z2 zu (zu) z2 zu (zu) zu (zu) z2 zu (zu) z2 (zu) z2 zu (zu) z2 (zu) z2 (zu) zu (z2 (zu) z2 (zu) z2 (zu) z2 (zu (zu) z2 (zu) z2 (zu) z2 (zu (u) z2 (zu) z2 (zu) z2 (zu (u) z2 (zu) z2 (zu) z2 (zu) z2 (zu) z2 (zu (zu) z2 (zu) z2 (zu) z2 (zu) z2 (zu) z2 (zu) z2 (zu) z2 (zu) z2 (zu) z2 (zu) z2 (zu) z2 (zu) z2 (z2 (zu)."}, {"heading": "11.5.3 Natural Gradient", "text": "The natural gradient algorithm [87] achieves invariance by applying the inversion of the q q information matrix F (w (t) on the current parameter w (t) to the negative gradient direction as follows: w (t) Implications Implications implicit (t) + Implications (natural), where 0 (natural) = Argmin 0 (R | E | - Implications L (w (t)), 0 (t) Implications 0 (s) = 0 (t) + 0 (natural) = Argmin 0 (R | E). (11,5,9) Here F (w) is the Fisher information matrix at point w and is defined in terms of the probability view of the feedforward neural network model, which we describe in more detail, that we solve the x distribution problems and feed the last layer of the network into a softmax layer, which determines the probability of the given candidate classes."}], "references": [{"title": "Deep learning in neural networks: An overview", "author": ["J. Schmidhuber"], "venue": "Neural Networks,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Geoffrey E Hinton", "Simon Osindero", "Yee-Whye Teh"], "venue": "Neural computation,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Greedy layer-wise training of deep networks", "author": ["Yoshua Bengio", "Pascal Lamblin", "Dan Popovici", "Hugo Larochelle"], "venue": "Advances in neural information processing systems,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Multilayer feedforward networks are universal approximators", "author": ["Kurt Hornik", "Maxwell Stinchcombe", "Halbert White"], "venue": "Neural networks,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1989}, {"title": "Introduction to the Theory of Computation", "author": ["Michael Sipser"], "venue": "Thomson Course Technology,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Neural network learning: Theoretical foundations", "author": ["Martin Anthony", "Peter L. Bartlett"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Understanding Machine Learning: From Theory to Algorithms", "author": ["Shai Shalev-Shwartz", "Shai Ben-David"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "The sample complexity of pattern classification with neural networks: the size of the weights is more important than the size of the network", "author": ["Peter L. Bartlett"], "venue": "IEEE transactions on information theory,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "Cryptographic hardness for learning intersections of halfspaces", "author": [], "venue": "In Foundations of Computer Science,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "From average case complexity to improper learning", "author": ["Amit Daniely", "Nati Linial", "Shai Shalev-Shwartz"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Entropy-sgd: Biasing gradient descent into wide valleys", "author": ["Pratik Chaudhari", "Anna Choromanska", "Stefano Soatto", "Yann LeCun"], "venue": "arXiv preprint arXiv:1611.01838,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "On large-batch training for deep learning: Generalization gap and sharp minima", "author": ["Nitish Shirish Keskar", "Dheevatsa Mudigere", "Jorge Nocedal", "Mikhail Smelyanskiy", "Ping Tak Peter Tang"], "venue": "arXiv preprint arXiv:1609.04836,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "Path-SGD: Path-normalized optimization in deep neural networks", "author": ["Behnam Neyshabur", "Ruslan Salakhutdinov", "Nathan Srebro"], "venue": "In Advanced in Neural Information Processsing Systems (NIPS),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["Vinod Nair", "Geoffrey E Hinton"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Deep sparse rectifier", "author": ["Xavier Glorot Antoine Bordes", "Yoshua Bengio"], "venue": "networks. AISTATS,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "On rectified linear units for speech processing", "author": ["M.D. Zeiler", "M. Ranzato", "R. Monga", "M. Mao", "K. Yang", "Q.V. Le", "P. Nguyen", "A. Senior", "V. Vanhoucke", "J. Dean", "G.E. Hinton"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "On the uniform convergence of relative frequencies of events to their probabilities", "author": ["Vladimir N Vapnik", "A Ya Chervonenkis"], "venue": "Theory of Probability & Its Applications,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1971}, {"title": "Neural network learning: Theoretical foundations", "author": ["Martin Anthony", "Peter L Bartlett"], "venue": "cambridge university press,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "The sample complexity of pattern classification with neural networks: the size of the weights is more important than the size of the network", "author": ["Peter L Bartlett"], "venue": "IEEE transactions on Information Theory,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1998}, {"title": "Almost linear vc dimension bounds for piecewise polynomial networks", "author": ["Peter L Bartlett", "Vitaly Maiorov", "Ron Meir"], "venue": "Neural computation,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1998}, {"title": "Understanding machine learning: From theory to algorithms", "author": ["Shai Shalev-Shwartz", "Shai Ben-David"], "venue": "Cambridge university press,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "The impact of the nonlinearity on the VC-dimension of a deep network", "author": ["P.L. Bartlett"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2017}, {"title": "Nearly-tight vc-dimension bounds for piecewise linear neural networks", "author": ["Nick Harvey", "Chris Liaw", "Abbas Mehrabian"], "venue": "arXiv preprint arXiv:1703.02930,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2017}, {"title": "Understanding deep learning requires rethinking generalization", "author": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2017}, {"title": "In search of the real inductive bias: On the role of implicit regularization in deep learning", "author": ["Behnam Neyshabur", "Ryota Tomioka", "Nathan Srebro"], "venue": "Proceeding of the International Conference on Learning Representations workshop track,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "Rademacher and gaussian complexities: Risk bounds and structural results", "author": ["Peter L Bartlett", "Shahar Mendelson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2002}, {"title": "Distance-based classification with lipschitz functions", "author": ["Ulrike von Luxburg", "Olivier Bousquet"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2004}, {"title": "Robustness and generalization", "author": ["Huan Xu", "Shie Mannor"], "venue": "Machine learning,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Generalization error of invariant classifiers", "author": ["Jure Sokolic", "Raja Giryes", "Guillermo Sapiro", "Miguel RD Rodrigues"], "venue": "arXiv preprint arXiv:1610.04574,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2016}, {"title": "Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data", "author": ["Gintare Karolina Dziugaite", "Daniel M Roy"], "venue": "arXiv preprint arXiv:1703.11008,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2017}, {"title": "Some PAC-Bayesian theorems", "author": ["David A McAllester"], "venue": "In Proceedings of the eleventh annual conference on Computational learning theory,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1998}, {"title": "PAC-Bayesian model averaging", "author": ["David A McAllester"], "venue": "In Proceedings of the twelfth annual conference on Computational learning theory,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1999}, {"title": "Simplified pac-bayesian margin bounds", "author": ["David McAllester"], "venue": "Lecture notes in computer science,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2003}, {"title": "Pac-bayes & margins", "author": ["John Langford", "John Shawe-Taylor"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2003}, {"title": "not) bounding the true error", "author": ["John Langford", "Rich Caruana"], "venue": "In Proceedings of the 14th International Conference on Neural Information Processing Systems: Natural and Synthetic,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2001}, {"title": "Maximum-margin matrix factorization", "author": ["Nathan Srebro", "Jason Rennie", "Tommi S. Jaakkola"], "venue": "Advances in neural information processing systems,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2004}, {"title": "A rank minimization heuristic with application to minimum order system approximation", "author": ["Maryam Fazel", "Haitham Hindi", "Stephen P. Boyd"], "venue": "Proceedings of American Control Conference,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2001}, {"title": "Computational enhancements in low-rank semidefinite programming", "author": ["Samuel Burer", "Changhui Choi"], "venue": "Optimization Methods and Software,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2006}, {"title": "Weighted low-rank approximations", "author": ["Nathan Srebro", "Tommi S. Jaakkola"], "venue": "ICML, pages 720\u2013727,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2003}, {"title": "Implicit regularization in matrix factorization", "author": ["Suriya Gunasekar", "Blake Woodworth", "Srinadh Bhojanapalli", "Behnam Neyshabur", "Nathan Srebro"], "venue": "arXiv preprint arXiv:1705.09280,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2017}, {"title": "Fast maximum margin matrix factorization for collaborative prediction", "author": ["Jasson DM Rennie", "Nathan Srebro"], "venue": "In Proceedings of the 22nd international conference on Machine learning,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2005}, {"title": "Collaborative filtering in a non-uniform world: Learning with the weighted trace norm", "author": ["Nathan Srebro", "Ruslan Salakhutdinov"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2010}, {"title": "Convex neural networks. Advances in neural information processing", "author": ["Yoshua Bengio", "Nicolas L. Roux", "Pascal Vincent", "Olivier Delalleau", "Patrice Marcotte"], "venue": null, "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2005}, {"title": "Spectrally-normalized margin bounds for neural networks", "author": ["Peter Bartlett", "Dylan J Foster", "Matus Telgarsky"], "venue": "arXiv preprint arXiv:1706.08498,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2017}, {"title": "Rademacher and gaussian complexities: Risk bounds and structural results", "author": ["Peter L. Bartlett", "Shahar Mendelson"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2003}, {"title": "Empirical margin distributions and bounding the generalization error of combined classifiers", "author": ["Vladimir Koltchinskii", "Dmitry Panchenko"], "venue": "Annals of Statistics,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2002}, {"title": "Breaking the curse of dimensionality with convex neural networks", "author": ["Francis Bach"], "venue": "Technical report,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2014}, {"title": "Kernel methods for deep learning", "author": ["Youngmin Cho", "Lawrence K. Saul"], "venue": "Advances in neural information processing systems,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2009}, {"title": "Efficient agnostic learning of neural networks with bounded fan-in", "author": ["Wee Sun Lee", "Peter L Bartlett", "Robert C Williamson"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 1996}, {"title": "On the complexity of linear prediction: Risk bounds, margin bounds, and regularization", "author": ["Sham M Kakade", "Karthik Sridharan", "AmbujTewari"], "venue": "Advances in neural information processing systems,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2009}, {"title": "A new perspective on learning linear separators with large lqlp margins", "author": ["Maria-Florina Balcan", "Christopher Berlind"], "venue": "Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2014}, {"title": "The best constants in the khintchine inequality", "author": ["Uffe Haagerup"], "venue": "Studia Mathematica,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 1981}, {"title": "Cryptographic hardness for learning intersections of halfspaces", "author": ["Adam R Klivans", "Alexander A Sherstov"], "venue": null, "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2006}, {"title": "On the computational efficiency of training neural networks", "author": ["Roi Livni", "Shai Shalev-Shwartz", "Ohad Shamir"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2014}, {"title": "User-friendly tail bounds for sums of random matrices", "author": ["Joel A Tropp"], "venue": "Foundations of computational mathematics,", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2012}, {"title": "Norm-based capacity control in neural networks", "author": ["Behnam Neyshabur", "Ryota Tomioka", "Nathan Srebro"], "venue": "In Proceeding of the 28th Conference on Learning Theory (COLT),", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2015}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Karen Simonyan", "Andrew Zisserman"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2014}, {"title": "Data-dependent path normalization in neural networks", "author": ["Behnam Neyshabur", "Ryota Tomioka", "Ruslan Salakhutdinov", "Nathan Srebro"], "venue": "In the International Conference on Learning Representations,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2016}, {"title": "On the universality of online mirror descent", "author": ["Nathan Srebro", "Karthik Sridharan", "Ambuj Tewari"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2011}, {"title": "Riemannian metrics for neural networks ii: recurrent networks and learning symbolic data sequences", "author": ["Yann Ollivier"], "venue": "Information and Inference, page iav007,", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2015}, {"title": "Data-dependent path normalization in neural networks", "author": ["Behnam Neyshabur", "Ryota Tomioka", "Ruslan Salakhutdinov", "Nathan Srebro"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2016}, {"title": "Path-normalized optimization of recurrent neural networks with relu activations", "author": ["Behnam Neyshabur", "Yuhuai Wu", "Ruslan Salakhutdinov", "Nathan Srebro"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2016}, {"title": "Norm-based capacity control in neural networks", "author": ["Behnam Neyshabur", "Ryota Tomioka", "Nathan Srebro"], "venue": "In The 28th Conference on Learning Theory,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2015}, {"title": "Rank, trace-norm and max-norm", "author": ["Nathan Srebro", "Adi Shraibman"], "venue": "In Learning Theory,", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2005}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 1929}, {"title": "Path-sgd: Path-normalized optimization in deep neural networks", "author": ["Behnam Neyshabur", "Ruslan R Salakhutdinov", "Nati Srebro"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 2015}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann LeCun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 1998}, {"title": "Learning multiple layers of features from tiny images", "author": ["Alex Krizhevsky", "Geoffrey Hinton"], "venue": "Computer Science Department,", "citeRegEx": "71", "shortCiteRegEx": "71", "year": 2009}, {"title": "Reading digits in natural images with unsupervised feature learning", "author": ["Yuval Netzer", "Tao Wang", "Adam Coates", "Alessandro Bissacco", "Bo Wu", "Andrew Y Ng"], "venue": "In NIPS workshop on deep learning and unsupervised feature learning,", "citeRegEx": "72", "shortCiteRegEx": "72", "year": 2011}, {"title": "In search of the real inductive bias: On the role of implicit regularization in deep learning", "author": ["Behnam Neyshabur", "Ryota Tomioka", "Nathan Srebro"], "venue": "International Conference on Learning Representations (ICLR) workshop track,", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 2015}, {"title": "Building a large annotated corpus of english: The penn treebank", "author": ["Mitchell P Marcus", "Mary Ann Marcinkiewicz", "Beatrice Santorini"], "venue": "Computational linguistics,", "citeRegEx": "74", "shortCiteRegEx": "74", "year": 1993}, {"title": "The vanishing gradient problem during learning recurrent neural nets and problem solutions", "author": ["Sepp Hochreiter"], "venue": "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems,", "citeRegEx": "75", "shortCiteRegEx": "75", "year": 1998}, {"title": "Learning long-term dependencies with gradient descent is difficult", "author": ["Yoshua Bengio", "Patrice Simard", "Paolo Frasconi"], "venue": "Neural Networks, IEEE Transactions on,", "citeRegEx": "76", "shortCiteRegEx": "76", "year": 1994}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "77", "shortCiteRegEx": "77", "year": 1997}, {"title": "A simple way to initialize recurrent networks of rectified linear units", "author": ["Quoc V Le", "Navdeep Jaitly", "Geoffrey E Hinton"], "venue": "arXiv preprint arXiv:1504.00941,", "citeRegEx": "78", "shortCiteRegEx": "78", "year": 2015}, {"title": "Unitary evolution recurrent neural networks", "author": ["Martin Arjovsky", "Amar Shah", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1511.06464,", "citeRegEx": "79", "shortCiteRegEx": "79", "year": 2015}, {"title": "Improving performance of recurrent neural network with relu nonlinearity", "author": ["Sachin S. Talathi", "Aniket Vartak"], "venue": "In the International Conference on Learning Representations workshop track,", "citeRegEx": "80", "shortCiteRegEx": "80", "year": 2014}, {"title": "Regularization and nonlinearities for neural language models: when are they needed", "author": ["Marius Pachitariu", "Maneesh Sahani"], "venue": "arXiv preprint arXiv:1301.5650,", "citeRegEx": "81", "shortCiteRegEx": "81", "year": 2013}, {"title": "Subword language modeling with neural networks", "author": ["Tom\u00e1\u0161 Mikolov", "Ilya Sutskever", "Anoop Deoras", "Hai-Son Le", "Stefan Kombrink", "J Cernocky"], "venue": "(http://www.fit.vutbr.cz/ imikolov/rnnlm/char.pdf),", "citeRegEx": "82", "shortCiteRegEx": "82", "year": 2012}, {"title": "Regularizing RNNs by stabilizing activations", "author": ["David Krueger", "Roland Memisevic"], "venue": "In Proceeding of the International Conference on Learning Representations,", "citeRegEx": "83", "shortCiteRegEx": "83", "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "In Proceeding of the International Conference on Learning Representations,", "citeRegEx": "84", "shortCiteRegEx": "84", "year": 2015}, {"title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "author": ["Andrew M Saxe", "James L McClelland", "Surya Ganguli"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "85", "shortCiteRegEx": "85", "year": 2014}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["Sergey Ioffe", "Christian Szegedy"], "venue": "In ICML,", "citeRegEx": "86", "shortCiteRegEx": "86", "year": 2015}, {"title": "Natural gradient works efficiently in learning", "author": ["Shun-Ichi Amari"], "venue": "Neural computation,", "citeRegEx": "87", "shortCiteRegEx": "87", "year": 1998}, {"title": "Efficient backprop. In Neural Networks, Tricks of the Trade, Lecture Notes in Computer Science LNCS 1524", "author": ["Yann Le Cun", "L\u00e9on Bottou", "Genevieve B. Orr", "Klaus-Robert M\u00fcller"], "venue": null, "citeRegEx": "88", "shortCiteRegEx": "88", "year": 1998}, {"title": "Exploring strategies for training deep neural networks", "author": ["Hugo Larochelle", "Yoshua Bengio", "J\u00e9r\u00f4me Louradour", "Pascal Lamblin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "89", "shortCiteRegEx": "89", "year": 2009}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["Xavier Glorot", "Yoshua Bengio"], "venue": "In AISTATS,", "citeRegEx": "90", "shortCiteRegEx": "90", "year": 2010}, {"title": "On the importance of initialization and momentum in deep learning", "author": ["Ilya Sutskever", "James Martens", "George Dahl", "Geoffrey Hinton"], "venue": "In ICML,", "citeRegEx": "91", "shortCiteRegEx": "91", "year": 2013}, {"title": "Scaling up natural gradient by sparsely factorizing the inverse Fisher matrix", "author": ["Roger Grosse", "Ruslan Salakhudinov"], "venue": "In ICML,", "citeRegEx": "92", "shortCiteRegEx": "92", "year": 2015}, {"title": "Optimizing neural networks with Kronecker-factored approximate curvature", "author": ["James Martens", "Roger Grosse"], "venue": "In ICML,", "citeRegEx": "93", "shortCiteRegEx": "93", "year": 2015}, {"title": "Revisiting natural gradient for deep networks", "author": ["Razvan Pascanu", "Yoshua Bengio"], "venue": "In ICLR,", "citeRegEx": "95", "shortCiteRegEx": "95", "year": 2014}, {"title": "Deep learning via hessian-free optimization", "author": ["James Martens"], "venue": "In ICML,", "citeRegEx": "96", "shortCiteRegEx": "96", "year": 2010}, {"title": "Krylov subspace descent for deep learning", "author": ["Oriol Vinyals", "Daniel Povey"], "venue": "In ICML,", "citeRegEx": "97", "shortCiteRegEx": "97", "year": 2011}, {"title": "Topmoumoute online natural gradient algorithm", "author": ["Nicolas L Roux", "Pierre-Antoine Manzagol", "Yoshua Bengio"], "venue": "In NIPS,", "citeRegEx": "98", "shortCiteRegEx": "98", "year": 2008}, {"title": "Neural networks-tricks of the trade", "author": ["Yann LeCun", "Leon Bottou", "Genevieve B Orr", "Klaus-Robert Muller"], "venue": "Springer Lecture Notes in Computer Sciences,", "citeRegEx": "99", "shortCiteRegEx": "99", "year": 1998}, {"title": "Lecun. No more pesky learning rates", "author": ["Tom Schaul", "Sixin Zhang", "Yann"], "venue": "In ICML,", "citeRegEx": "100", "shortCiteRegEx": "100", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "The terms \u201cneural networks\u201d and \u201cdeep learning\u201d are often used interchangeably as many modern deep learning models are slight modifications of different types of neural networks suggested originally around 1950-2000 [1].", "startOffset": 216, "endOffset": 219}, {"referenceID": 1, "context": "Interest in deep learning was revived around 2006 [2, 3] and since then, it has had enormous practical successes in different areas [4].", "startOffset": 50, "endOffset": 56}, {"referenceID": 2, "context": "Interest in deep learning was revived around 2006 [2, 3] and since then, it has had enormous practical successes in different areas [4].", "startOffset": 50, "endOffset": 56}, {"referenceID": 3, "context": "Universal approximation theorem states that for any given precision, feed-forward networks with a single hidden layer containing a finite number of hidden units can approximate any continuous function [5].", "startOffset": 201, "endOffset": 204}, {"referenceID": 5, "context": "With hard-threshold activations, the VC-dimension, and hence sample complexity, of the class of functions realizable with a feed-forward network is equal, up to logarithmic factors, to the number of edges in the network [7, 8], corresponding to the number of parameters.", "startOffset": 220, "endOffset": 226}, {"referenceID": 6, "context": "With hard-threshold activations, the VC-dimension, and hence sample complexity, of the class of functions realizable with a feed-forward network is equal, up to logarithmic factors, to the number of edges in the network [7, 8], corresponding to the number of parameters.", "startOffset": 220, "endOffset": 226}, {"referenceID": 8, "context": "That is, even for binary classification using a network with a single hidden layer and a logarithmic (in the input size) number of hidden units, and even if we know the true targets are exactly captured by such a small network, there is likely no efficient algorithm that can ensure error better than 1/2 [10, 11]\u2014not if the algorithm tries to fit such a network, not even if it tries to fit a much larger 1Using weights with very high precision and vastly different magnitudes it is possible to shatter a number of points quadratic in the number of edges when activations such as the sigmoid, ramp or hinge are used [8, Chapter 20.", "startOffset": 305, "endOffset": 313}, {"referenceID": 9, "context": "That is, even for binary classification using a network with a single hidden layer and a logarithmic (in the input size) number of hidden units, and even if we know the true targets are exactly captured by such a small network, there is likely no efficient algorithm that can ensure error better than 1/2 [10, 11]\u2014not if the algorithm tries to fit such a network, not even if it tries to fit a much larger 1Using weights with very high precision and vastly different magnitudes it is possible to shatter a number of points quadratic in the number of edges when activations such as the sigmoid, ramp or hinge are used [8, Chapter 20.", "startOffset": 305, "endOffset": 313}, {"referenceID": 7, "context": "But even with such activations, the VC dimension can still be bounded by the size and depth [9, 7, 8].", "startOffset": 92, "endOffset": 101}, {"referenceID": 5, "context": "But even with such activations, the VC dimension can still be bounded by the size and depth [9, 7, 8].", "startOffset": 92, "endOffset": 101}, {"referenceID": 6, "context": "But even with such activations, the VC dimension can still be bounded by the size and depth [9, 7, 8].", "startOffset": 92, "endOffset": 101}, {"referenceID": 10, "context": "Different algorithmic choices for optimization such as the initialization, update rule, learning rate, and stopping condition, will lead to different global minima with different generalization behavior [12, 13, 14].", "startOffset": 203, "endOffset": 215}, {"referenceID": 11, "context": "Different algorithmic choices for optimization such as the initialization, update rule, learning rate, and stopping condition, will lead to different global minima with different generalization behavior [12, 13, 14].", "startOffset": 203, "endOffset": 215}, {"referenceID": 12, "context": "Different algorithmic choices for optimization such as the initialization, update rule, learning rate, and stopping condition, will lead to different global minima with different generalization behavior [12, 13, 14].", "startOffset": 203, "endOffset": 215}, {"referenceID": 6, "context": "More details on the formal model can be found in Shalev-Shwartz and Ben-David [8].", "startOffset": 78, "endOffset": 81}, {"referenceID": 13, "context": "We will focus mostly on the hinge, or RELU (REctified Linear Unit) activation, which is currently in popular use [15, 16, 17], \u03c3RELU(z) = [z]+ = max(z, 0).", "startOffset": 113, "endOffset": 125}, {"referenceID": 14, "context": "We will focus mostly on the hinge, or RELU (REctified Linear Unit) activation, which is currently in popular use [15, 16, 17], \u03c3RELU(z) = [z]+ = max(z, 0).", "startOffset": 113, "endOffset": 125}, {"referenceID": 15, "context": "We will focus mostly on the hinge, or RELU (REctified Linear Unit) activation, which is currently in popular use [15, 16, 17], \u03c3RELU(z) = [z]+ = max(z, 0).", "startOffset": 113, "endOffset": 125}, {"referenceID": 16, "context": "The following generalization bound then holds with probability 1\u2212 \u03b4 [18, 19]:", "startOffset": 68, "endOffset": 76}, {"referenceID": 17, "context": "Feedforward Networks The VC dimension of feedforward networks can also be bounded in terms of the number of parameters nparam[20, 21, 22, 23].", "startOffset": 125, "endOffset": 141}, {"referenceID": 18, "context": "Feedforward Networks The VC dimension of feedforward networks can also be bounded in terms of the number of parameters nparam[20, 21, 22, 23].", "startOffset": 125, "endOffset": 141}, {"referenceID": 19, "context": "Feedforward Networks The VC dimension of feedforward networks can also be bounded in terms of the number of parameters nparam[20, 21, 22, 23].", "startOffset": 125, "endOffset": 141}, {"referenceID": 20, "context": "Feedforward Networks The VC dimension of feedforward networks can also be bounded in terms of the number of parameters nparam[20, 21, 22, 23].", "startOffset": 125, "endOffset": 141}, {"referenceID": 21, "context": "In particular, Bartlett [24] and Harvey et al.", "startOffset": 24, "endOffset": 28}, {"referenceID": 22, "context": "[25], following Bartlett et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[22], give the following tight (up to logarithmic factors) bound on the VC dimension and hence capacity of feedforward networks with ReLU activations: VC-dim = \u00d5(d \u2217 nparam) (3.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "Neural networks used in practice often have significantly more parameters than samples, and indeed can perfectly fit even random labels, obviously without generalizing [26].", "startOffset": 168, "endOffset": 172}, {"referenceID": 24, "context": "Moreover, measuring complexity in terms of number of parameters cannot explain the reduction in generalization error as the number of hidden units increase [27].", "startOffset": 156, "endOffset": 160}, {"referenceID": 25, "context": "Feedforward Networks [28] proved that the Rademacher complexity of fully connected feedforward networks on set S can be bounded based on the `1 norm of the weights of hidden units in each layer as follows: Rm(F) \u2264 \u221a 4d ln (nin) \u220fd i=1 \u2016Wi\u2016 2 1,\u221emaxx\u2208S \u2016x\u2016\u221e m (3.", "startOffset": 21, "endOffset": 25}, {"referenceID": 25, "context": "4) where \u2016Wi\u20161,\u221e is the maximum over hidden units in layer i of the `1 norm of incoming weights to the hidden unit [28].", "startOffset": 115, "endOffset": 119}, {"referenceID": 26, "context": "Luxburg and Bousquet [29] studied the capacity of functions with bounded Lipschitz constant on metric space (X ,M) with a finite diameter diamM(X ) = supx,y\u2208XM(x, y) and showed that the capacity is proportional to ( CM \u03b3 )n diamM(X ) where \u03b3 is the margin.", "startOffset": 21, "endOffset": 25}, {"referenceID": 27, "context": "Another related approach is through algorithmic robustness as suggested by Xu and Mannor [30].", "startOffset": 89, "endOffset": 93}, {"referenceID": 27, "context": "1) Xu and Mannor [30] showed the capacity of a model class whose models are K-robust scales as K.", "startOffset": 17, "endOffset": 21}, {"referenceID": 27, "context": "Feedforward Networks Returning to our original question, theC`\u221e andC`2 Lipschitz constants of the network can be bounded by \u220fd i=1 \u2016Wi\u20161,\u221e (hence `1-path norm) and \u220fd i=1 \u2016Wi\u20162, respectively [30, 31].", "startOffset": 191, "endOffset": 199}, {"referenceID": 28, "context": "Feedforward Networks Returning to our original question, theC`\u221e andC`2 Lipschitz constants of the network can be bounded by \u220fd i=1 \u2016Wi\u20161,\u221e (hence `1-path norm) and \u220fd i=1 \u2016Wi\u20162, respectively [30, 31].", "startOffset": 191, "endOffset": 199}, {"referenceID": 11, "context": "[13] and corresponds to robustness to adversarial perturbations on the parameter space: \u03b6\u03b1(W) = max|ui|\u2264\u03b1(|wi|+1) L\u0302(fw+u)\u2212 L\u0302(fw) 1 + L\u0302(fw) ' max |ui|\u2264\u03b1(|wi|+1) L\u0302(fw+u)\u2212 L\u0302(fw), (3.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "This connection between sharpness and the PAC-Bayes framework was also recently noted by Dziugaite and Roy [32].", "startOffset": 107, "endOffset": 111}, {"referenceID": 30, "context": "The PAC-Bayesian framework [33, 34] provides guarantees on the expected error of a randomized predictor (hypothesis), drawn from a distribution denoted Q and sometimes referred to as a \u201cposterior\u201d (although it need not be the Bayesian posterior), that depends on the training data.", "startOffset": 27, "endOffset": 35}, {"referenceID": 31, "context": "The PAC-Bayesian framework [33, 34] provides guarantees on the expected error of a randomized predictor (hypothesis), drawn from a distribution denoted Q and sometimes referred to as a \u201cposterior\u201d (although it need not be the Bayesian posterior), that depends on the training data.", "startOffset": 27, "endOffset": 35}, {"referenceID": 27, "context": "Then, given a \u201cprior\u201d distribution P over the hypothesis that is independent of the training data, with probability at least 1\u2212 \u03b4 over the draw of the training data, the expected error 1Xu and Mannor [30] have defined the robustness as a property of learning algorithm given the model class and the training set.", "startOffset": 200, "endOffset": 204}, {"referenceID": 32, "context": "of fw+u can be bounded as follows [35]: Eu [L(fw+u)] \u2264 Eu [ L\u0302(fw+u) ] + \u221a Eu [ L\u0302(fw+u) ] K +K (3.", "startOffset": 34, "endOffset": 38}, {"referenceID": 33, "context": "The proof of the lemma uses similar ideas as in the proof for the case of linear separators, discussed by Langford and Shawe-Taylor [36] and McAllester [35].", "startOffset": 132, "endOffset": 136}, {"referenceID": 32, "context": "The proof of the lemma uses similar ideas as in the proof for the case of linear separators, discussed by Langford and Shawe-Taylor [36] and McAllester [35].", "startOffset": 152, "endOffset": 156}, {"referenceID": 29, "context": "Feedforward Networks This connection between sharpness and the PAC-Bayesian framework was also recently noticed by Dziugaite and Roy [32], who optimize the PAC-Bayes generalization bound over a family of multivariate Gaussian distributions, extending the work of Langford and Caruana [37].", "startOffset": 133, "endOffset": 137}, {"referenceID": 34, "context": "Feedforward Networks This connection between sharpness and the PAC-Bayesian framework was also recently noticed by Dziugaite and Roy [32], who optimize the PAC-Bayes generalization bound over a family of multivariate Gaussian distributions, extending the work of Langford and Caruana [37].", "startOffset": 284, "endOffset": 288}, {"referenceID": 8, "context": "That is, even for binary classification using a network with a single hidden layer and a logarithmic (in the input size) number of hidden units, and even if we know the true targets are exactly captured by such a small network, there is likely no efficient algorithm that can ensure error better than 1/2 [10, 11]\u2014not if the algorithm tries to fit such a network, not even if it tries to fit a much larger network, and in fact no matter how the algorithm represents predictors.", "startOffset": 305, "endOffset": 313}, {"referenceID": 9, "context": "That is, even for binary classification using a network with a single hidden layer and a logarithmic (in the input size) number of hidden units, and even if we know the true targets are exactly captured by such a small network, there is likely no efficient algorithm that can ensure error better than 1/2 [10, 11]\u2014not if the algorithm tries to fit such a network, not even if it tries to fit a much larger network, and in fact no matter how the algorithm represents predictors.", "startOffset": 305, "endOffset": 313}, {"referenceID": 35, "context": "For example, constraining the Frobenius norm of U and V corresponds to using the trace-norm as an inductive bias [38]:", "startOffset": 113, "endOffset": 117}, {"referenceID": 36, "context": "Unlike the rank, the trace-norm (as well as other factorization norms) is convex, and leads to tractable learning problems [39, 38].", "startOffset": 123, "endOffset": 131}, {"referenceID": 35, "context": "Unlike the rank, the trace-norm (as well as other factorization norms) is convex, and leads to tractable learning problems [39, 38].", "startOffset": 123, "endOffset": 131}, {"referenceID": 37, "context": "by a local search over the weights of the network), if the dimensionality is high enough and the norm is regularized, we can ensure convergence to a global minima [40].", "startOffset": 163, "endOffset": 167}, {"referenceID": 38, "context": "This is in stark contrast to the dimensionality-constrained low-rank situation, where the limiting factor is the number of hidden units, and local minima are abundant [41].", "startOffset": 167, "endOffset": 171}, {"referenceID": 39, "context": "[42] provided empirical and theoretical evidence on the implicit regularization of gradient descent for matrix factorization.", "startOffset": 0, "endOffset": 4}, {"referenceID": 40, "context": ", a very successful approach for training low trace-norm models, and other infinite-dimensional bounded-norm factorization models, is to approximate them using a finite dimensional representation [43, 44].", "startOffset": 196, "endOffset": 204}, {"referenceID": 41, "context": ", a very successful approach for training low trace-norm models, and other infinite-dimensional bounded-norm factorization models, is to approximate them using a finite dimensional representation [43, 44].", "startOffset": 196, "endOffset": 204}, {"referenceID": 42, "context": "In particular, we show how per-unit regularization is equivalent to a novel path-based regularizer and how overall `2 regularization for two-layer networks is equivalent to so-called \u201cconvex neural networks\u201d [45].", "startOffset": 208, "endOffset": 212}, {"referenceID": 43, "context": "[46] have shown a generalization bound based on the product of spectral norm of the layers using covering numbers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 44, "context": ", [47] for a complete treatment, and Section 5.", "startOffset": 2, "endOffset": 6}, {"referenceID": 7, "context": "Per-unit `1-regularization was studied by [9, 48, 47] who showed generalization guarantees.", "startOffset": 42, "endOffset": 53}, {"referenceID": 45, "context": "Per-unit `1-regularization was studied by [9, 48, 47] who showed generalization guarantees.", "startOffset": 42, "endOffset": 53}, {"referenceID": 44, "context": "Per-unit `1-regularization was studied by [9, 48, 47] who showed generalization guarantees.", "startOffset": 42, "endOffset": 53}, {"referenceID": 46, "context": "A two-layer network of this form with RELU activation was also considered by [49], who studied its approximation ability and suggested heuristics for learning it.", "startOffset": 77, "endOffset": 81}, {"referenceID": 47, "context": "Per-unit `2 regularization in a two-layer network was considered by [50], who showed it is equivalent to using a specific kernel.", "startOffset": 68, "endOffset": 72}, {"referenceID": 47, "context": "Furthermore, the kernel view of [50] allows obtaining size-independent generalization bound for two-layer networks with bounded per-unit `2 norm (i.", "startOffset": 32, "endOffset": 36}, {"referenceID": 48, "context": "Indeed, one can consider functional-gradient or boosting-type strategies for learning a predictor in the class [51].", "startOffset": 111, "endOffset": 115}, {"referenceID": 46, "context": "However, as Bach [49] points out, this is not so easy as it requires finding the best fit for a target with a RELU unit, which is not easy.", "startOffset": 17, "endOffset": 21}, {"referenceID": 9, "context": "Subject to the the strong random CSP assumptions in [11], it is not possible to efficiently PAC learn (even improperly) functions {\u00b11}nin \u2192 {\u00b11} realizable with unit margin by F2 1,\u221e when \u03c81,\u221e = \u03c9(nin) (e.", "startOffset": 52, "endOffset": 56}, {"referenceID": 42, "context": "Convex Neural Nets [45] over inputs in Rin are two-layer networks with a fixed infinite hidden layer consisting of all units with weights w \u2208 G for some base class G \u2208 Rin , and a second `1-regularized layer.", "startOffset": 19, "endOffset": 23}, {"referenceID": 9, "context": "Subject to the the strong random CSP assumptions in [11], it is not possible to efficiently PAC learn (even improperly) functions {\u00b11}nin \u2192 {\u00b11} realizable with unit margin by F2 p,p when \u03bcp,p = \u03c9(n 1 p in ).", "startOffset": 52, "endOffset": 56}, {"referenceID": 49, "context": "The upper bounds presented here are particularly similar to generalization bounds in [52] and [53].", "startOffset": 85, "endOffset": 89}, {"referenceID": 50, "context": "The upper bounds presented here are particularly similar to generalization bounds in [52] and [53].", "startOffset": 94, "endOffset": 98}, {"referenceID": 51, "context": "The sharp value of the constant Cp was found by Haagerup [54] but for our analysis, it is enough to note that if p \u2265 1 we have Cp \u2264 \u221ap.", "startOffset": 57, "endOffset": 61}, {"referenceID": 9, "context": "[11] show in Theorem 5.", "startOffset": 0, "endOffset": 4}, {"referenceID": 52, "context": "Furthermore, for any > 0, [55] prove this hardness result subject to intractability of Q\u0303(n in )-unique shortest vector problem for k = n in.", "startOffset": 26, "endOffset": 30}, {"referenceID": 53, "context": "The proof is by a construction that is similar to the one in [56].", "startOffset": 61, "endOffset": 65}, {"referenceID": 54, "context": "The following inequality holds on the spectral norm of Ui [57]: PUi\u223cN(0,\u03c3q) [\u2016Ui\u20162 > t] \u2264 2he\u2212t /2h\u03c3 q .", "startOffset": 58, "endOffset": 62}, {"referenceID": 25, "context": "Unlike existing generalization bounds [28, 58, 29, 30, 31], our sharpness based bound does not suffer from exponential dependence on depth.", "startOffset": 38, "endOffset": 58}, {"referenceID": 55, "context": "Unlike existing generalization bounds [28, 58, 29, 30, 31], our sharpness based bound does not suffer from exponential dependence on depth.", "startOffset": 38, "endOffset": 58}, {"referenceID": 26, "context": "Unlike existing generalization bounds [28, 58, 29, 30, 31], our sharpness based bound does not suffer from exponential dependence on depth.", "startOffset": 38, "endOffset": 58}, {"referenceID": 27, "context": "Unlike existing generalization bounds [28, 58, 29, 30, 31], our sharpness based bound does not suffer from exponential dependence on depth.", "startOffset": 38, "endOffset": 58}, {"referenceID": 28, "context": "Unlike existing generalization bounds [28, 58, 29, 30, 31], our sharpness based bound does not suffer from exponential dependence on depth.", "startOffset": 38, "endOffset": 58}, {"referenceID": 55, "context": "The norm-based measures we investigate in this work and their corresponding capacity bounds are as follows 1: \u2022 `2 norm with capacity proportional to 1 \u03b32 margin \u220fd i=1 4 \u2016Wi\u2016 2 F [58].", "startOffset": 180, "endOffset": 184}, {"referenceID": 25, "context": "\u2022 `1-path norm with capacity proportional to 1 \u03b32 margin (\u2211 j\u2208 \u220fd k=0[hk] \u2223\u2223\u2223\u220fdi=1 2Wi[ji, ji\u22121]\u2223\u2223\u2223)2[28, 58].", "startOffset": 101, "endOffset": 109}, {"referenceID": 55, "context": "\u2022 `1-path norm with capacity proportional to 1 \u03b32 margin (\u2211 j\u2208 \u220fd k=0[hk] \u2223\u2223\u2223\u220fdi=1 2Wi[ji, ji\u22121]\u2223\u2223\u2223)2[28, 58].", "startOffset": 101, "endOffset": 109}, {"referenceID": 56, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 84, "endOffset": 88}, {"referenceID": 61, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 116, "endOffset": 129}, {"referenceID": 2, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 116, "endOffset": 129}, {"referenceID": 2, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 116, "endOffset": 129}, {"referenceID": 0, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 116, "endOffset": 129}, {"referenceID": 2, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 135, "endOffset": 149}, {"referenceID": 2, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 135, "endOffset": 149}, {"referenceID": 0, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 135, "endOffset": 149}, {"referenceID": 2, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 155, "endOffset": 169}, {"referenceID": 2, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 155, "endOffset": 169}, {"referenceID": 0, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 155, "endOffset": 169}, {"referenceID": 2, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 175, "endOffset": 189}, {"referenceID": 2, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 175, "endOffset": 189}, {"referenceID": 0, "context": "In the rest of the experiments, we train a modified version of the VGG architecture [59] with the configuration 2 \u00d7 [64, 3, 3, 1], 2 \u00d7 [128, 3, 3, 1], 2 \u00d7 [256, 3, 3, 1], 2 \u00d7 [512, 3, 3, 1] where we add Batch Normalization before ReLU 1We have dropped the term that only depend on the norm of the input.", "startOffset": 175, "endOffset": 189}, {"referenceID": 55, "context": "Without further conditions on weights, exponential dependence on depth is tight but the 4d dependence might be loose [58].", "startOffset": 117, "endOffset": 121}, {"referenceID": 57, "context": "When calculating norms on a network with a Batch Normalization layer, we reparametrize the network to one that represents the exact same function without Batch Normalization as suggested in [60].", "startOffset": 190, "endOffset": 194}, {"referenceID": 11, "context": "We calculate the sharpness, as suggested in [13] - for each parameter wi we bound the magnitude of perturbation by \u03b1(|wi|+ 1) for \u03b1 = 5.", "startOffset": 44, "endOffset": 48}, {"referenceID": 29, "context": "As discussed earlier, Dziugaite and Roy [32] numerically optimize the overall PAC-Bayes generalization bound over a family of multivariate Gaussian distributions (different choices of perturbations and priors).", "startOffset": 40, "endOffset": 44}, {"referenceID": 29, "context": "2), nor in the more refined bound used by Dziugaite and Roy [32], we prefer shying away from numerically optimizing the balance between sharpness and the KL-divergence.", "startOffset": 60, "endOffset": 64}, {"referenceID": 11, "context": "[13] where the perturbation for parameter wi has magnitude 5.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[27] where a fully connected feedforward network is trained on MNIST dataset with varying number of hidden units and we check the values of different complexity measures on each of the learned networks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 58, "context": "There is therefore also a strong link between regularization for optimization and regularization for learning: optimization may provide implicit regularization in terms of its corresponding geometry, and for ideal optimization performance the optimization geometry should be aligned with inductive bias driving the learning [61].", "startOffset": 324, "endOffset": 328}, {"referenceID": 59, "context": "Invariances have also been studied as different mappings from the parameter space to the same function space [62] while we define the transformation as a mapping inside a fixed parameter space.", "startOffset": 109, "endOffset": 113}, {"referenceID": 60, "context": "A very important invariance in feedforward networks is node-wise rescaling [63].", "startOffset": 75, "endOffset": 79}, {"referenceID": 61, "context": "We have discussed the complete characterize all feasible node-wise invariances of RNNs in [64].", "startOffset": 90, "endOffset": 94}, {"referenceID": 59, "context": "Note that this is different than the invariances studied in [62], in that they study algorithms that are invariant to reparametrizations of the same model but we look at transformations within the the parameter space that preserve the function in the model.", "startOffset": 60, "endOffset": 64}, {"referenceID": 0, "context": "and \u03c6(x)> = [ g1(x)x[1] g2(x)x[2] g3(x)x[1] g4(x)x[2] g5(x)x[1] g6(x)x[2] g7(x)x[1] g8(x)x[2] ] .", "startOffset": 20, "endOffset": 23}, {"referenceID": 1, "context": "and \u03c6(x)> = [ g1(x)x[1] g2(x)x[2] g3(x)x[1] g4(x)x[2] g5(x)x[1] g6(x)x[2] g7(x)x[1] g8(x)x[2] ] .", "startOffset": 30, "endOffset": 33}, {"referenceID": 0, "context": "and \u03c6(x)> = [ g1(x)x[1] g2(x)x[2] g3(x)x[1] g4(x)x[2] g5(x)x[1] g6(x)x[2] g7(x)x[1] g8(x)x[2] ] .", "startOffset": 40, "endOffset": 43}, {"referenceID": 1, "context": "and \u03c6(x)> = [ g1(x)x[1] g2(x)x[2] g3(x)x[1] g4(x)x[2] g5(x)x[1] g6(x)x[2] g7(x)x[1] g8(x)x[2] ] .", "startOffset": 50, "endOffset": 53}, {"referenceID": 0, "context": "and \u03c6(x)> = [ g1(x)x[1] g2(x)x[2] g3(x)x[1] g4(x)x[2] g5(x)x[1] g6(x)x[2] g7(x)x[1] g8(x)x[2] ] .", "startOffset": 60, "endOffset": 63}, {"referenceID": 1, "context": "and \u03c6(x)> = [ g1(x)x[1] g2(x)x[2] g3(x)x[1] g4(x)x[2] g5(x)x[1] g6(x)x[2] g7(x)x[1] g8(x)x[2] ] .", "startOffset": 70, "endOffset": 73}, {"referenceID": 0, "context": "and \u03c6(x)> = [ g1(x)x[1] g2(x)x[2] g3(x)x[1] g4(x)x[2] g5(x)x[1] g6(x)x[2] g7(x)x[1] g8(x)x[2] ] .", "startOffset": 80, "endOffset": 83}, {"referenceID": 1, "context": "and \u03c6(x)> = [ g1(x)x[1] g2(x)x[2] g3(x)x[1] g4(x)x[2] g5(x)x[1] g6(x)x[2] g7(x)x[1] g8(x)x[2] ] .", "startOffset": 90, "endOffset": 93}, {"referenceID": 64, "context": "Another form of regularization that is shown to be very effective in RELU networks is the max-norm regularization, which is the maximum over all units of norm of incoming edge to the unit2 [67, 68].", "startOffset": 189, "endOffset": 197}, {"referenceID": 64, "context": "In these cases, per-unit `2 regularization has shown to be very effective [68].", "startOffset": 74, "endOffset": 78}, {"referenceID": 62, "context": "1The path-norm which we define is a norm on functions, not on weights, but as we prefer not getting into this technical discussion here, we use the term \u201cnorm\u201d very loosely to indicate some measure of magnitude [65].", "startOffset": 211, "endOffset": 215}, {"referenceID": 63, "context": "2This definition of max-norm is a bit different than the one used in the context of matrix factorization [66].", "startOffset": 105, "endOffset": 109}, {"referenceID": 62, "context": "Surprisingly, for a feed-forward network, the minimum `2 per-unit regularizer among all rescaling equivalent networks can be calculated in close form and we call it the path-regularizer [65, 69].", "startOffset": 186, "endOffset": 194}, {"referenceID": 65, "context": "Surprisingly, for a feed-forward network, the minimum `2 per-unit regularizer among all rescaling equivalent networks can be calculated in close form and we call it the path-regularizer [65, 69].", "startOffset": 186, "endOffset": 194}, {"referenceID": 65, "context": "The stochastic version that uses a subset of training examples to estimate \u2202L \u2202wu\u2192v (w ) is called PathSGD [69].", "startOffset": 107, "endOffset": 111}, {"referenceID": 66, "context": "We conduct our experiments on four common benchmark datasets: the standard MNIST dataset of handwritten digits [70]; CIFAR-10 and CIFAR-100 datasets of tiny images of natural scenes [71]; and Street View House Numbers (SVHN) dataset containing color images of house numbers collected by Google Street View [72].", "startOffset": 111, "endOffset": 115}, {"referenceID": 67, "context": "We conduct our experiments on four common benchmark datasets: the standard MNIST dataset of handwritten digits [70]; CIFAR-10 and CIFAR-100 datasets of tiny images of natural scenes [71]; and Street View House Numbers (SVHN) dataset containing color images of house numbers collected by Google Street View [72].", "startOffset": 182, "endOffset": 186}, {"referenceID": 68, "context": "We conduct our experiments on four common benchmark datasets: the standard MNIST dataset of handwritten digits [70]; CIFAR-10 and CIFAR-100 datasets of tiny images of natural scenes [71]; and Street View House Numbers (SVHN) dataset containing color images of house numbers collected by Google Street View [72].", "startOffset": 306, "endOffset": 310}, {"referenceID": 65, "context": "Please see [69] for a more complete set of experimental results.", "startOffset": 11, "endOffset": 15}, {"referenceID": 69, "context": "This view is similar to observations in [73] on the role of implicit regularization in deep learning.", "startOffset": 40, "endOffset": 44}, {"referenceID": 65, "context": "This can be better analyzed by looking at the plots for more number of epochs which we have provided in [69].", "startOffset": 104, "endOffset": 108}, {"referenceID": 70, "context": "To compare the two terms \u03ba and \u03ba, we train a single layer RNN with H = 200 hidden units for the task of word-level language modeling on Penn Treebank (PTB) Corpus [74].", "startOffset": 163, "endOffset": 167}, {"referenceID": 71, "context": "Training Recurrent Neural Networks is known to be hard for modeling long-term dependencies due to the gradient vanishing/exploding problem [75, 76].", "startOffset": 139, "endOffset": 147}, {"referenceID": 72, "context": "Training Recurrent Neural Networks is known to be hard for modeling long-term dependencies due to the gradient vanishing/exploding problem [75, 76].", "startOffset": 139, "endOffset": 147}, {"referenceID": 73, "context": "Addition Problem: The addition problem was introduced in [77].", "startOffset": 57, "endOffset": 61}, {"referenceID": 0, "context": "Here, each input consists of two sequences of length T , one of which includes numbers sampled from the uniform distribution with range [0, 1] and the other sequence serves as a mask which is filled with zeros except for two entries.", "startOffset": 136, "endOffset": 142}, {"referenceID": 74, "context": "Sequential MNIST: In sequential MNIST, each digit image is reshaped into a sequence of length 784, turning the digit classification task into sequence classification with long-term dependencies [78, 79].", "startOffset": 194, "endOffset": 202}, {"referenceID": 75, "context": "Sequential MNIST: In sequential MNIST, each digit image is reshaped into a sequence of length 784, turning the digit classification task into sequence classification with long-term dependencies [78, 79].", "startOffset": 194, "endOffset": 202}, {"referenceID": 74, "context": "For both tasks, we closely follow the experimental protocol in [78].", "startOffset": 63, "endOffset": 67}, {"referenceID": 74, "context": "Adding Adding Adding 100 400 750 sMNIST IRNN [78] 0 16.", "startOffset": 45, "endOffset": 49}, {"referenceID": 75, "context": "0 uRNN [79] 0 3 16.", "startOffset": 7, "endOffset": 11}, {"referenceID": 75, "context": "9 LSTM [79] 0 2 16.", "startOffset": 7, "endOffset": 11}, {"referenceID": 76, "context": "8 np-RNN[80] 0 2 >2 3.", "startOffset": 8, "endOffset": 12}, {"referenceID": 77, "context": "PTB text8 RNN+smoothReLU [81] - 1.", "startOffset": 25, "endOffset": 29}, {"referenceID": 78, "context": "55 HF-MRNN [82] 1.", "startOffset": 11, "endOffset": 15}, {"referenceID": 79, "context": "54 RNN-ReLU[83] 1.", "startOffset": 11, "endOffset": 15}, {"referenceID": 79, "context": "65 RNN-tanh[83] 1.", "startOffset": 11, "endOffset": 15}, {"referenceID": 79, "context": "55 TRec,\u03b2 = 500[83] 1.", "startOffset": 15, "endOffset": 19}, {"referenceID": 74, "context": "We also train an RNN of the same size with identity initialization, as was proposed in [78], using SGD as our baseline model, referred to as IRNN.", "startOffset": 87, "endOffset": 91}, {"referenceID": 75, "context": "Similar to [79], we found the IRNN to be fairly unstable (with SGD optimization typically diverging).", "startOffset": 11, "endOffset": 15}, {"referenceID": 74, "context": "We also compare RNN-Path with the previously published results, including identity initialized RNN [78] (IRNN), unitary RNN [79] (uRNN), and np-RNN1 introduced by [80].", "startOffset": 99, "endOffset": 103}, {"referenceID": 75, "context": "We also compare RNN-Path with the previously published results, including identity initialized RNN [78] (IRNN), unitary RNN [79] (uRNN), and np-RNN1 introduced by [80].", "startOffset": 124, "endOffset": 128}, {"referenceID": 76, "context": "We also compare RNN-Path with the previously published results, including identity initialized RNN [78] (IRNN), unitary RNN [79] (uRNN), and np-RNN1 introduced by [80].", "startOffset": 163, "endOffset": 167}, {"referenceID": 79, "context": "PTB-c: We performed experiments on a tokenized Penn Treebank Corpus, following the experimental protocol of [83].", "startOffset": 108, "endOffset": 112}, {"referenceID": 78, "context": "We follow the data partition of [82], where each training sequence has a length of 180.", "startOffset": 32, "endOffset": 36}, {"referenceID": 80, "context": "Instead, we use Adam optimizer [84] to help speed up the training, where we simply use the path-SGD gradient as input to the Adam optimizer.", "startOffset": 31, "endOffset": 35}, {"referenceID": 81, "context": "For LSTMs, we use orthogonal initialization [85] for the recurrent matrices and uniform[\u22120.", "startOffset": 44, "endOffset": 48}, {"referenceID": 79, "context": "We also compare our results to an RNN that uses hidden activation regularizer [83] (TRec,\u03b2 = 500), Multiplicative RNNs trained by Hessian Free methods [82] (HF-MRNN), and an RNN with smooth version of ReLU [81].", "startOffset": 78, "endOffset": 82}, {"referenceID": 78, "context": "We also compare our results to an RNN that uses hidden activation regularizer [83] (TRec,\u03b2 = 500), Multiplicative RNNs trained by Hessian Free methods [82] (HF-MRNN), and an RNN with smooth version of ReLU [81].", "startOffset": 151, "endOffset": 155}, {"referenceID": 77, "context": "We also compare our results to an RNN that uses hidden activation regularizer [83] (TRec,\u03b2 = 500), Multiplicative RNNs trained by Hessian Free methods [82] (HF-MRNN), and an RNN with smooth version of ReLU [81].", "startOffset": 206, "endOffset": 210}, {"referenceID": 12, "context": "In this chapter, we focus on two efficient alternative optimization approaches proposed recently for feed-forward neural networks that are based on intuitions about parametrization, normalization and the geometry of parameter space: Path-SGD [14] was derived as steepest descent algorithm with respect to particular regularizer (the `2-path regularizer, i.", "startOffset": 242, "endOffset": 246}, {"referenceID": 55, "context": "the sum over all paths in the network of the squared product over all weights in the path [58]) and is invariant to weight reparametrization.", "startOffset": 90, "endOffset": 94}, {"referenceID": 82, "context": "Batch-normalization [86] was derived by adding normalization layers in the network as a way of controlling the variance of the input each unit receives in a data-dependent fashion.", "startOffset": 20, "endOffset": 24}, {"referenceID": 83, "context": "Our unified framework and study of in invariances also allows us to relate the different optimization approaches to Natural Gradients [87].", "startOffset": 134, "endOffset": 138}, {"referenceID": 84, "context": "Related Works There has been an ongoing effort for better understanding of the optimization in deep networks and several heuristics have been suggested to improve the training [88, 89, 90, 91].", "startOffset": 176, "endOffset": 192}, {"referenceID": 85, "context": "Related Works There has been an ongoing effort for better understanding of the optimization in deep networks and several heuristics have been suggested to improve the training [88, 89, 90, 91].", "startOffset": 176, "endOffset": 192}, {"referenceID": 86, "context": "Related Works There has been an ongoing effort for better understanding of the optimization in deep networks and several heuristics have been suggested to improve the training [88, 89, 90, 91].", "startOffset": 176, "endOffset": 192}, {"referenceID": 87, "context": "Related Works There has been an ongoing effort for better understanding of the optimization in deep networks and several heuristics have been suggested to improve the training [88, 89, 90, 91].", "startOffset": 176, "endOffset": 192}, {"referenceID": 83, "context": "Natural gradient algorithm [87] is known to have a very strong invariance property; it is not only invariant to reparametrization, but also to the choice of network architecture.", "startOffset": 27, "endOffset": 31}, {"referenceID": 88, "context": "However it is known to be computationally demanding and thus many approximations have been proposed [92, 93, 94].", "startOffset": 100, "endOffset": 112}, {"referenceID": 89, "context": "However it is known to be computationally demanding and thus many approximations have been proposed [92, 93, 94].", "startOffset": 100, "endOffset": 112}, {"referenceID": 90, "context": "[95] also discuss the connections between Natural Gradients and some of the other proposed methods for training neural networks, namely Hessian-Free Optimization [96], Krylov Subspace Descent [97] and TONGA [98].", "startOffset": 0, "endOffset": 4}, {"referenceID": 91, "context": "[95] also discuss the connections between Natural Gradients and some of the other proposed methods for training neural networks, namely Hessian-Free Optimization [96], Krylov Subspace Descent [97] and TONGA [98].", "startOffset": 162, "endOffset": 166}, {"referenceID": 92, "context": "[95] also discuss the connections between Natural Gradients and some of the other proposed methods for training neural networks, namely Hessian-Free Optimization [96], Krylov Subspace Descent [97] and TONGA [98].", "startOffset": 192, "endOffset": 196}, {"referenceID": 93, "context": "[95] also discuss the connections between Natural Gradients and some of the other proposed methods for training neural networks, namely Hessian-Free Optimization [96], Krylov Subspace Descent [97] and TONGA [98].", "startOffset": 207, "endOffset": 211}, {"referenceID": 59, "context": "[62] also recently studied the issue of invariance and proposed computationally efficient approximations and alternatives to natural gradient.", "startOffset": 0, "endOffset": 4}, {"referenceID": 59, "context": "To alleviate this cost, [62] also proposed quasi-diagonal approximations which avoid the quadratic dependence but they are only invariant to affine transformations of activation functions.", "startOffset": 24, "endOffset": 28}, {"referenceID": 59, "context": "In particular, ignoring the non-diagonal terms related to the biases in quasi-diagonal natural gradient suggested in [62], it is then equivalent to diagonal Natural Gradient which is itself equivalent to special case of DDP-SGD when Rv is the second moment (see Table 11.", "startOffset": 117, "endOffset": 121}, {"referenceID": 55, "context": "For Rv = diag ( \u03b3 N in(v) ) , this complexity measure agrees with the `2-Path-regularizer as introduced by [58].", "startOffset": 107, "endOffset": 111}, {"referenceID": 55, "context": "But, unlike this max-norm measure, the path-regularizer does not depend on the rebalancing and is invariant to node rescalings [58].", "startOffset": 127, "endOffset": 131}, {"referenceID": 82, "context": "We show that with a choice of Rv = Cov ( hN in(v)) ) , this is essentially equivalent to Batch Normalization [86].", "startOffset": 109, "endOffset": 113}, {"referenceID": 82, "context": "Batch-Normalization [86] was suggested as an alternate architecture, with special \u201cnormalization\u201d layers, that ensure the variance of node outputs are normalized throughout training.", "startOffset": 20, "endOffset": 24}, {"referenceID": 12, "context": "For the choice Rv = diag(\u03b3 N in(v)), we have that \u03b3 2 net is the Path-norm and we recover Path-SGD [14].", "startOffset": 99, "endOffset": 103}, {"referenceID": 94, "context": "Using diagonal approximation of Fisher information matrix to normalize the gradient values has been suggested before as a computationally tractable alternative to the full Natural Gradient [99, 100].", "startOffset": 189, "endOffset": 198}, {"referenceID": 95, "context": "Using diagonal approximation of Fisher information matrix to normalize the gradient values has been suggested before as a computationally tractable alternative to the full Natural Gradient [99, 100].", "startOffset": 189, "endOffset": 198}, {"referenceID": 59, "context": "[62] also suggested a \u201cquasi-diagonal\" approximations that includes, in addition to the diagonal, also some non-diagonal terms corresponding to the relationship between the bias term and every other incoming weight into a unit.", "startOffset": 0, "endOffset": 4}, {"referenceID": 83, "context": "The natural gradient algorithm [87] achieves invariance by applying the inverse of the Fisher information matrix F (w) at the current parameter w to the negative gradient direction as follows: w = w + \u03b7\u2206,", "startOffset": 31, "endOffset": 35}], "year": 2017, "abstractText": "In an attempt to better understand generalization in deep learning, we study several possible explanations. We show that implicit regularization induced by the optimization method is playing a key role in generalization and success of deep learning models. Motivated by this view, we study how different complexity measures can ensure generalization and explain how optimization algorithms can implicitly regularize complexity measures. We empirically investigate the ability of these measures to explain different observed phenomena in deep learning. We further study the invariances in neural networks, suggest complexity measures and optimization algorithms that have similar invariances to those in neural networks and evaluate them on a number of learning tasks. Thesis Advisor: Nathan Srebro Title: Professor", "creator": "LaTeX with hyperref package"}}}