{"id": "1709.02291", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2017", "title": "Basic Filters for Convolutional Neural Networks: Training or Design?", "abstract": "When convolutional neural networks are used to tackle learning problems based on time series, e.g., audio data, raw one-dimensional data are commonly pre-processed to obtain spectrogram or mel-spectrogram coefficients, which are then used as input to the actual neural network. In this contribution, we investigate, both theoretically and experimentally, the influence of this pre-processing step on the network's performance and pose the question, whether replacing it by applying adaptive or learned filters directly to the raw data, can improve learning success. The theoretical results show that approximately reproducing mel-spectrogram coefficients by applying adaptive filters and subsequent time-averaging is in principle possible. On the other hand, extensive experimental work leads to the conclusion, that the invariance induced by mel-spectrogram coefficients is both desirable and hard to infer by the learning process. Thus, the results achieved by adaptive end-to-end learning approaches are close to but slightly worse than results achieved by state-of-the-art reference architectures using standard input coefficients derived from the spectrogram.", "histories": [["v1", "Thu, 7 Sep 2017 14:51:37 GMT  (282kb,D)", "http://arxiv.org/abs/1709.02291v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.IR", "authors": ["monika doerfler", "thomas grill", "roswitha bammer", "arthur flexer"], "accepted": false, "id": "1709.02291"}, "pdf": {"name": "1709.02291.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["monika.doerfler@univie.ac.at"], "sections": [{"heading": "1 Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2 Time-Frequency concepts", "text": "The Fourier transformation of a function f-H, for some Hilbertspace H, is denoted by F-1 (f). We use the normalization F-1 (f-2) (\u03c9) = E-R f (t) e2\u03c0i\u03c9tdt and denote its inversion by F-1 (f-1 (t) = E-R f-2. For x-R, the translation or time shift operator of a function f is defined as Txf (t) = F (t-x). To get local information about the frequency spectrum, we define the modulation or frequency shift operator of a function f as the short-term Fourier transformation (STFT) of a function f in relation to a window g 6 = 0 < where f, g-H, Vasgf (b-b), Vask (b-b) (b-t) (k-g) (k-b) = f (f-2) can be introduced."}, {"heading": "3 The structure of CNNs", "text": "The basic, modular structure of CNNs has often been described, see e.g. [10]. At this point we will give a formal statement about the specific architecture used in the experiments in this essay. This architecture has been successfully applied to several MIR tasks and seems to have a prototype character for audio applications, cf. [11]. The most basic building block in a general neural network can be asxn + 1 = \u03c3 (Anxn + bn), where xn in the nth layer is the data vector or the array in the nth layer is a linear operator, bn is a vector of distortion in the nth layer, and nonlinearity is applied componently.Note that in each layer the array xn may have a different dimension. In the case of revolutionary layers of CNNs, matrix A now has a specific structure for the evolutionary layers, i.e. it is an arbiter of the first layer and a dependence of the third layer respectively."}, {"heading": "3.1 The CNN with Spectrogram Input", "text": "The standard methods for audio signals are based on a spectrogram, either in its raw form or after pre-processing such as the calculation of the MEL spectrogram, which we will look at in detail in Section 4. In most MIR tasks, the inputs are derived from rather short snippets, that is, about 2 to 4 seconds of sound. Taking into account a sampling rate of 22050 Hz, a window size of 2048 samples and a time shift parameter of 512 samples, i.e. the resulting spectrogram (which contains only positive frequencies) is of size M \u00b7 N = 1024 x 130, where the latter is the time dimension."}, {"heading": "3.2 Modifying the input matrix", "text": "As mentioned in the previous section, the spectrogram of audio is often pre-processed in order to reduce dimensionality on the one hand and to obtain a spectral representation that better reflects both human perception and the characteristics of speech and music on the other. Furthermore, the authors pointed out in [1] that the use of the mel spectrogram instead of the spectrogram usually guarantees better stability in terms of frequency shifts or, more generally, deformations of the original audio signals than the use of spectrograms. However, given the appropriate choice of network architecture, comparable results can normally be obtained either with the spectrogram or the mel spectrogram, i.e. the inventory introduced by mel averaging can also be learned. In other respects, the omission of the frequency averaging formation provided by the mel spectrogram leads to an increase in the number of weights to be learned."}, {"heading": "4 The mel-spectrogram and basic filters", "text": "In this section we take a detailed look at the mel spectrogram. This representation is derived from the classical spectrogram (weighted averaging of absolute values squared by the STFT) and can undoubtedly be called the most important feature used in speech and audio processing, along with MFCCs derived directly from it. The number of filters used varies between 80 filters between 80 Hz and 16 kHz [11] and 128 [5] or more. To better understand the relationship between the result of mel averaging and FFT-based analysis with flexible windows, we observe the following: denote the input signal through f-filters, the window function for generating the spectrogram through g-filters by the CN and the CN filters.. K, where K is the selected number of filters. We can then write the mel spectrogram asMSg (f) (b)."}, {"heading": "4.1 Examples", "text": "In this section we show some examples of filters calculated h\u03bd to obtain the MSg coefficients MSg (f) by averaging time. We consider Hann windows, which are the standard selection in audio processing, also when calculating the Mel spectrogram coefficients and their approximation in Section 5. Starting from a Hann window g, we calculate adaptive filters h\u03bd for the first 50 containers of the Mel scale. Figure 1 shows the ambiguity functions Vgg, Vh\u03bdh\u03bd and the weighted ambiguity functions Vgg \u00b7 F \u2212 1 (evaluated), Vh\u03bd \u00b7 F ($\u03bd) (evaluated), which corresponds to 2587.6 Hz. In Figure 2, the upper diagram shows the original Hann and three adjusted windows, which narrow with increasing MEL number, to realize the MEL averaging by adjustment in the domain."}, {"heading": "5 Experiments on Singing Voice Detection", "text": "Proposition 4.2 shows that coefficients with mel characteristics (and other related nonlinear scales) can be closely approximated by applying appropriately selected filters directly to the raw audio data, enabling a subsequent time-averaging step. Now, we are interested in investigating whether the theoretical results can be applied to typical real-world problems that have already been successfully treated with CNNs. We are motivated by the fact that state-of-the-art results for multiple MIR problems are based on Mel spectrogram coefficients that have certain desirable inventory and stability characteristics, especially due to the module, they are immutable for translation and, due to the frequency averaging, point stability to certain deformations such as timewarping, cf. [1] Generally, however, the required inventory and stability in terms of deformations of data properties and learning task will depend on the network, cf. [17] Therefore, we begin predicting a problem that we will inevitably follow by filtering the question for time."}, {"heading": "5.1 Data", "text": "In the cited publication, a CNN was set to maximum predictive accuracy, both in the absence and in the presence of various forms of data amplification. Experiments were conducted using a non-public dataset of 188 30-second audio snippets from an online music store (\"In-House A\" dataset) covering a very wide range of genres and origins. We used a quintuple cross-validation, for each iteration 150 files for training purposes, the remaining 38 for evaluation. Audio was subsampled at a sampling rate of 22.05 kHz and mixed down to mono. Precalculated mel spectrograms were calculated using a STFT with Hann windows, an image length of 1024 and a hop size of 315 samples (yield 70 frames per second)."}, {"heading": "5.2 CNN training procedure and architecture", "text": "In fact, most of them are able to surpass themselves, most of them are not able to surpass themselves, most of them are able to surpass themselves, most of them are able to surpass themselves, most of them are not able to surpass themselves, most of them are able to surpass themselves, most of them are able to surpass themselves, most of them are able to surpass themselves, most of them are able to surpass themselves, most of them are able to surpass themselves, most of them are able to surpass themselves, most of them are able to surpass themselves."}, {"heading": "5.3 Experimental setup", "text": "In the following, we compare the behaviour of the CNNs applied to the STFT spectra with the characteristics resulting from the audio signal using Gabor filter banks of the following orders of magnitude. The core value corresponds to the lowest frequency bandwidth (50 Hz) and is reduced to the bandwidth requirements of the frequency scale, which refers to the highest bandwidth of 7740 Hz. Ad-hoc calculation is also performed on the lowest frequency bandwidth (50 Hz)."}, {"heading": "5.4 Experimental results", "text": "Figure 4 shows the results of our CNN experiments on the problem of voice recording. For our evaluations, we switched from the simple error measurement with the \"optimal\" (in the sense of maximum accuracy) threshold per experiment to the more informative \"range via the ROC curve\" measure (AOC), which converts classification errors for all possible thresholds into a measurement variable. A lower measurement indicates a better result. Leftmost, the reference architecture with the large network is displayed. To the right of this, there are two groups of experiments: for the \"small-two\" and \"small-one\" networks, each containing an experiment for the STFT baseline (\"STFT ad-hoc\"), one for a fixed width of the time averaged (\"Gabor fixed-width\") and variable width of the experiments: experiments containing either uniform or individual average width of the networks, each one experiment. Each group contains an experiment for the STFT hoc base line, which we are averaged (\"STFT\") for the STad architecture."}, {"heading": "5.4.1 Adapting the mel-filters", "text": "As discussed in the previous section, experiments have shown that coefficients calculated through the use of filters that directly reflect the frequency resolution of the mel scale are unable to improve or even achieve the results obtained through the use of mel spectrogram coefficients. Taking into account the adjustment of the frequency resolution itself, the results deteriorated even further. We therefore assume that calculating frequency averaged coefficients from pre-calculated spectrograms is beneficial at least for the learning task we are focusing on, thus enabling the grid to adjust the frequency filters used in the average step described in (4). In fact, this approach could reproduce the reference results and achieve a small but significant improvement in performance when adaptability is introduced."}, {"heading": "6 Discussion and Perspectives", "text": "In this article, we asked and answered two questions regarding the use of alternative time-frequency representations for learning problems related to music information. < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < &"}], "references": [{"title": "Deep scattering spectrum", "author": ["J. And\u00e9n", "S. Mallat"], "venue": "IEEE Transactions on Signal Processing, 62(16):4114\u20134128", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Theory", "author": ["P. Balazs", "M. D\u00f6rfler", "F. Jaillet", "N. Holighaus", "G.A. Velasco"], "venue": "implementation and applications of nonstationary Gabor frames. J. Comput. Appl. Math., 236(6):1481\u20131496", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Adapted and adaptive linear time-frequency representations: a synthesis point of view", "author": ["P. Balazs", "M. D\u00f6rfler", "M. Kowalski", "B. Torr\u00e9sani"], "venue": "IEEE Signal Processing Magazine, 30(6):20\u201331", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Invariance and Stability of Gabor Scattering for Music Signals", "author": ["R. Bammer", "M. D\u00f6rfler"], "venue": "Proceedings of SAMPTA 2017, http://arxiv.org/abs/1706.08818", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2017}, {"title": "End-to-end learning for music audio", "author": ["S. Dieleman", "B. Schrauwen"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Inside the Spectrogram: Convolutional Neural Networks in Audio Processing", "author": ["M. D\u00f6rfler", "R. Bammer", "T. Grill"], "venue": "Proceedings of SAMPTA 2017. SALSA", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2017}, {"title": "Representation of operators in the time-frequency domain and generalized Gabor multipliers", "author": ["M. D\u00f6rfler", "B. Torr\u00e9sani"], "venue": "J. Fourier Anal. Appl., 16(2):261\u2013293", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Quantization of TF lattice-invariant operators on elementary LCA groups", "author": ["H.G. Feichtinger", "W. Kozek"], "venue": "H. G. Feichtinger and T. Strohmer, editors, Gabor analysis and algorithms, Appl. Numer. Harmon. Anal., pages 233\u2013266. Birkh\u00e4user Boston", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1998}, {"title": "A first survey of Gabor multipliers", "author": ["H.G. Feichtinger", "K. Nowak"], "venue": "H. G. Feichtinger and T. Strohmer, editors, Advances in Gabor Analysis, Appl. Numer. Harmon. Anal., pages 99\u2013128. Birkh\u00e4user", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "Deep Learning", "author": ["I. Goodfellow", "Y. Bengio", "A. Courville"], "venue": "MIT Press", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Music Boundary Detection Using Neural Networks on Combined Features and Two-Level Annotations", "author": ["T. Grill", "J. Schl\u00fcter"], "venue": "Proceedings of the 16th International Society for Music Information Retrieval Conference ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep convolutional neural networks on cartoon functions", "author": ["P. Grohs", "T. Wiatowski", "H. B\u00f6lcskei"], "venue": "In Proc. of IEEE International Symposium on Information Theory (ISIT),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "A framework for invertible", "author": ["N. Holighaus", "M. D\u00f6rfler", "G.A. Velasco", "T. Grill"], "venue": "real-time constant-Q transforms. IEEE Trans. Audio Speech Lang. Process., 21(4):775 \u2013785", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Adam: A method for stochastic optimization", "author": ["D.P. Kingma", "J. Ba"], "venue": "Proceedings of the 3rd International Conference on Learning Representations (ICLR)", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, 86(11):2278 \u2013 2324", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1998}, {"title": "Group Invariant Scattering", "author": ["S. Mallat"], "venue": "Comm. Pure Appl. Math., 65(10):1331\u20131398", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Understanding deep convolutional networks", "author": ["S. Mallat"], "venue": "Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences, 374", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2065}, {"title": "Exploring Data Augmentation for Improved Singing Voice Detection with Neural Networks", "author": ["J. Schl\u00fcter", "T. Grill"], "venue": "Proceedings of the 16th International Society for Music Information Retrieval Conference ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Energy propagation in deep convolutional neural networks", "author": ["T. Wiatowski", "P. Grohs", "H. B\u00f6lcskei"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2017}, {"title": "Discrete deep feature extraction: A theory and new architectures", "author": ["T. Wiatowski", "M. Tschannen", "A. Stani", "P. Grohs", "H. B\u00f6lcskei"], "venue": "Proc. of International Conference on Machine Learning ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 14, "context": "Convolutional neural networks, first introduced in learning tasks for image data [15], have revolutionized state-of-the-art results in many machine learning (ML) problems.", "startOffset": 81, "endOffset": 85}, {"referenceID": 4, "context": ", acting on raw audio without any pre-processing, has not been able to outperform models based on linear-frequency spectrogram or mel-spectrogram input [5].", "startOffset": 152, "endOffset": 155}, {"referenceID": 0, "context": "[1]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "Note that the similarity of mel-spectrogram coefficients to the result of time-averaging wavelet coefficients has already been observed in [1], without giving a precise formulation of the connection.", "startOffset": 139, "endOffset": 142}, {"referenceID": 6, "context": "[7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": ", [10].", "startOffset": 2, "endOffset": 6}, {"referenceID": 10, "context": "[11].", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Note that is has been observed in [16, 19] that in the context of scattering networks, most of the input signal\u2019s energy is contained in the output of the first two convolutional layers.", "startOffset": 34, "endOffset": 42}, {"referenceID": 18, "context": "Note that is has been observed in [16, 19] that in the context of scattering networks, most of the input signal\u2019s energy is contained in the output of the first two convolutional layers.", "startOffset": 34, "endOffset": 42}, {"referenceID": 0, "context": "Additionally, the authors in [1] pointed out that using mel-spectrogram instead of the spectrogram guarantees improved stability with respect to frequency shifts or, more generally, deformations of the original audio signals, than the usage of spectrograms.", "startOffset": 29, "endOffset": 32}, {"referenceID": 10, "context": "The number of mel-filters used varies between 80 filters between 80 Hz and 16 kHz [11] and 128 [5] or more.", "startOffset": 82, "endOffset": 86}, {"referenceID": 4, "context": "The number of mel-filters used varies between 80 filters between 80 Hz and 16 kHz [11] and 128 [5] or more.", "startOffset": 95, "endOffset": 98}, {"referenceID": 0, "context": "And\u00e9n and Mallat showed in [1], that the mel-spectrogram can be approximated by time-averaging the absolute values squared of a wavelet transform.", "startOffset": 27, "endOffset": 30}, {"referenceID": 1, "context": "Note that the resulting transform may be interpreted as a nonstationary Gabor transform, compare [2, 3, 13, 6].", "startOffset": 97, "endOffset": 110}, {"referenceID": 2, "context": "Note that the resulting transform may be interpreted as a nonstationary Gabor transform, compare [2, 3, 13, 6].", "startOffset": 97, "endOffset": 110}, {"referenceID": 12, "context": "Note that the resulting transform may be interpreted as a nonstationary Gabor transform, compare [2, 3, 13, 6].", "startOffset": 97, "endOffset": 110}, {"referenceID": 5, "context": "Note that the resulting transform may be interpreted as a nonstationary Gabor transform, compare [2, 3, 13, 6].", "startOffset": 97, "endOffset": 110}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "[17].", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "1 Data We investigate the effects of learning filters directly on raw audio by revisiting the problem of singing voice detection [18] we have studied before.", "startOffset": 129, "endOffset": 133}, {"referenceID": 17, "context": "2 CNN training procedure and architecture The training procedure used in our experiments is slightly different than in the reference publication [18].", "startOffset": 145, "endOffset": 149}, {"referenceID": 13, "context": "Updates to the network weights are computed using the ADAM update rule [14] with an initial learning rate of 0.", "startOffset": 71, "endOffset": 75}, {"referenceID": 17, "context": "The architecture used in [18] has a total number of 1.", "startOffset": 25, "endOffset": 29}, {"referenceID": 17, "context": "The reference implementation in [18] uses pre-computed spectrograms, with a normalization globally on the the training set and eventual padding performed also on the spectrogram.", "startOffset": 32, "endOffset": 36}, {"referenceID": 5, "context": "preliminary work in [6], both regarding the network\u2019s expressivity and the performance of the learning process.", "startOffset": 20, "endOffset": 23}, {"referenceID": 19, "context": "Finally, the propagation and alleviation of approximation errors will be investigated relying on existing results on stability of CNNs, compare [20, 4, 12].", "startOffset": 144, "endOffset": 155}, {"referenceID": 3, "context": "Finally, the propagation and alleviation of approximation errors will be investigated relying on existing results on stability of CNNs, compare [20, 4, 12].", "startOffset": 144, "endOffset": 155}, {"referenceID": 11, "context": "Finally, the propagation and alleviation of approximation errors will be investigated relying on existing results on stability of CNNs, compare [20, 4, 12].", "startOffset": 144, "endOffset": 155}, {"referenceID": 8, "context": "[9], on any given function in the sense of a bilinear form.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Indeed, as shown in [8], every operator H can equally be written by means of its spreading function \u03b7H as", "startOffset": 20, "endOffset": 23}, {"referenceID": 6, "context": "We note that two operators H1, H2 are equal if and only if their spreading functions coincide, see [7, 8] for details.", "startOffset": 99, "endOffset": 105}, {"referenceID": 7, "context": "We note that two operators H1, H2 are equal if and only if their spreading functions coincide, see [7, 8] for details.", "startOffset": 99, "endOffset": 105}, {"referenceID": 6, "context": "As shown in [7], a Gabor multiplier\u2019s spreading function \u03b7 g \u03b1,m is given by", "startOffset": 12, "endOffset": 15}], "year": 2017, "abstractText": "When convolutional neural networks are used to tackle learning problems based on time series, e.g., audio data, raw one-dimensional data are commonly preprocessed to obtain spectrogram or mel-spectrogram coefficients, which are then used as input to the actual neural network. In this contribution, we investigate, both theoretically and experimentally, the influence of this pre-processing step on the network\u2019s performance and pose the question, whether replacing it by applying adaptive or learned filters directly to the raw data, can improve learning success. The theoretical results show that approximately reproducing mel-spectrogram coefficients by applying adaptive filters and subsequent time-averaging is in principle possible. On the other hand, extensive experimental work leads to the conclusion, that the invariance induced by mel-spectrogram coefficients is both desirable and hard to infer by the learning process. Thus, the results achieved by adaptive end-to-end learning approaches are close to but slightly worse than results achieved by state-of-the-art reference architectures using standard input coefficients derived from the spectrogram.", "creator": "LaTeX with hyperref package"}}}