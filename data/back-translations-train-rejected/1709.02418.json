{"id": "1709.02418", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2017", "title": "How Does Knowledge of the AUC Constrain the Set of Possible Ground-truth Labelings?", "abstract": "Recent work on privacy-preserving machine learning has considered how data-mining competitions such as Kaggle could potentially be \"hacked\", either intentionally or inadvertently, by using information from an oracle that reports a classifier's accuracy on the test set. For binary classification tasks in particular, one of the most common accuracy metrics is the Area Under the ROC Curve (AUC), and in this paper we explore the mathematical structure of how the AUC is computed from an n-vector of real-valued \"guesses\" with respect to the ground-truth labels. We show how knowledge of a classifier's AUC on the test set can constrain the set of possible ground-truth labelings, and we derive an algorithm both to compute the exact number of such labelings and to enumerate efficiently over them. Finally, we provide empirical evidence that, surprisingly, the number of compatible labelings can actually decrease as n grows, until a test set-dependent threshold is reached.", "histories": [["v1", "Thu, 7 Sep 2017 19:30:57 GMT  (82kb,D)", "http://arxiv.org/abs/1709.02418v1", null], ["v2", "Mon, 11 Sep 2017 15:11:28 GMT  (82kb,D)", "http://arxiv.org/abs/1709.02418v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jacob whitehill"], "accepted": false, "id": "1709.02418"}, "pdf": {"name": "1709.02418.pdf", "metadata": {"source": "CRF", "title": "How Does Knowledge of the AUC Constrain the Set of Possible Ground-truth Labelings?", "authors": ["Jacob Whitehill"], "emails": ["jrwhitehill@wpi.edu"], "sections": [{"heading": "1 Introduction and Related Work", "text": "Data contests such as Kaggle and KDDCup can accelerate progress in many areas of application by providing standardized data sets and a fair basis for comparing multiple algorithmic approaches, but their usefulness will decrease if the integrity of rankings is called into question, either due to intentional or accidental overfulfillment of test data. Recent research on data-preserving machine learning methods (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information about the accuracy of a participant's guesses is returned to the participant by an oracle, information about the true labels of the test data can be disseminated. Such guesses are often provided by the contest organizers themselves. For example, in the 2017 Intel & MobileODT Cervical Cancer Screening competition1 hosted by Kaggle, each participant can submit them / his guesses up to 5 times a day."}, {"heading": "2 Notation and Assumptions", "text": "Let y = (y1,..., yn), (0, 1) n be the true binary names of n test examples, and let y = (y,..., y), (n), (n), (n) be the index sets of the examples of the participant designated as 1 or 0, respectively. Let L1 (y) = {i: yi = 1} and L0 (y) = {i: yi = 0} represent the index sets of the examples designated as 1 or 0, respectively. Similarly, let us define n1 (y) = | L1 (y) | and n0 (y) = | the number of examples designated as 1 or 0 in y."}, {"heading": "3 AUC Accuracy Metric", "text": "The AUC has two mathematically equivalent definitions (Tyler and Chen, 2000; Agarwal et al., 2005): (1) The AUC is the only way in which the AUC indicates the actual positive rate in the intervals [0, 1]. (2) The AUC represents the fractions of the test examples - one labeled and one labeled - in which the classifiers can correctly identify the positively described example based on the classifier output. (2) The AUC represents the fractions of the test examples - one labeled as 0 and one labeled. (1) The AUC can identify the positive positive rate in the intervals of possible false positive rates in the intervals. (2) Since we assume that all the AUC tests are distinctive, then the AUC can be labeled as: 1n01."}, {"heading": "4.1 Summing over all possible n1", "text": "Based on Theorem 1, we can calculate the number v (n0, n1, d) of the binary vectors of length n = n0 + n1 so that n1 of the entries is labeled with 1 and for h (y, y) = d. Remember that the AUC can be calculated by dividing the number of misclassified pairs by the total number of sample pairs n0n1. Thus, to calculate the total number w (n, c) of binary vectors of length n, for which AUC (y, y) = c is calculated, we must first determine the set N1 of possible values for n1, and then the sum v (n0, n1, d) of each value in N1 and the corresponding value. Suppose that the oracle specifies an AUC of c = p / q, where p / q is a reduced fraction, because c represents the fraction of all sample pairs - one of each class - which can be determined by the actual pairs of q = 1."}, {"heading": "5 Recursion Relation", "text": "We can derive from this a recursion reference for v (n0, n1, d) as follows: v = = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0: 0 = 0 = 0: 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0: 0 = 0 = 0: 0 = 0: 0 = 0: 0 = 0 = 0: 0 = 0: 0 = 0: 0 = 0 = 0: 0 = 0: 0 = 0: 0 = 0 = 0: 0 = 0: 0 = 0: 0 = 0: 0 = 0: 0 = 0: 0 = 0 = 0: 0 = 0: 0 = 0: 0 = 0: 0 = 0: 0 = 0: 0 = 0: 0 = 0 = 0: 0: 0 = 0: 0 = 0: 0 = 0: 0 = 0: 0 = 0: 0 = 0: 0: 0 = 0 = 0: 0 = 0: 0: 0 = 0 = 0: 0 = 0 = 0: 0: 0 = 0: 0 = 0: 0 = 0 = 0: 0 = 0: 0 = 0: 0: 0 = 0 = 0 = 0: 0: 0 = 0 = 0: 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0: 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0: 0 = 0: 0 = 0 = 0 = 0: 0: 0 = 0 = 0 = 0: 0 = 0 = 0: 0: 0: 0 = 0: 0 = 0: 0 = 0 ="}, {"heading": "7 Summary & Future Work", "text": "We have studied the mathematical structure of how the accuracy metrics of the Area Under the Receiver Operating Characteristics Curve (AUC) are calculated from the binary vector of ground truth labels and a real vector of conjectures. In particular, we have derived an efficient recursive algorithm that allows us to count the exact number of binary vectors for which the AUC of a fixed vector of conjectures represents a certain value c; we have also derived a constructive algorithm that enumerates all these binary vectors. In future work, it would be interesting to investigate whether and how knowledge of the possible ground truth labels could be used to improve an existing vector of conjectures; a simple mechanism has been proposed by Whitehill (2016), but it is practicable only for tiny datasets. Furthermore, it would be useful to investigate how several subsequent oracle queries could be used to work the set of possible truths and labels faster."}], "references": [{"title": "Generalization bounds for the area under the ROC curve", "author": ["S. Agarwal", "T. Graepel", "R. Herbrich", "S. Har-Peled", "D. Roth"], "venue": "Journal of Machine Learning Research, 393\u2013425.", "citeRegEx": "Agarwal et al\\.,? 2005", "shortCiteRegEx": "Agarwal et al\\.", "year": 2005}, {"title": "The ladder: A reliable leaderboard for machine learning competitions", "author": ["A. Blum", "M. Hardt"], "venue": "arXiv preprint arXiv:1502.04585.", "citeRegEx": "Blum and Hardt,? 2015", "shortCiteRegEx": "Blum and Hardt", "year": 2015}, {"title": "A learning theory approach to noninteractive database privacy", "author": ["A. Blum", "K. Ligett", "A. Roth"], "venue": "Journal of the ACM (JACM) 60(2):12.", "citeRegEx": "Blum et al\\.,? 2013", "shortCiteRegEx": "Blum et al\\.", "year": 2013}, {"title": "Privacy-preserving logistic regression", "author": ["K. Chaudhuri", "C. Monteleoni"], "venue": "Advances in Neural Information Processing Systems, 289\u2013296.", "citeRegEx": "Chaudhuri and Monteleoni,? 2009", "shortCiteRegEx": "Chaudhuri and Monteleoni", "year": 2009}, {"title": "Preserving statistical validity in adaptive data analysis", "author": ["C. Dwork", "V. Feldman", "M. Hardt", "T. Pitassi", "O. Reingold", "A.L. Roth"], "venue": "Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing, 117\u2013126. ACM.", "citeRegEx": "Dwork et al\\.,? 2015", "shortCiteRegEx": "Dwork et al\\.", "year": 2015}, {"title": "Differential privacy", "author": ["C. Dwork"], "venue": "van Tilborg, H., and Jajodia, S., eds., Encyclopedia of Cryptography and Security. Springer US. 338\u2013340.", "citeRegEx": "Dwork,? 2011", "shortCiteRegEx": "Dwork", "year": 2011}, {"title": "Preventing false discovery in interactive data analysis is hard", "author": ["M. Hardt", "J. Ullman"], "venue": "Foundations of Computer Science (FOCS), 2014 IEEE 55th Annual Symposium on, 454\u2013463. IEEE.", "citeRegEx": "Hardt and Ullman,? 2014", "shortCiteRegEx": "Hardt and Ullman", "year": 2014}, {"title": "An examination of data confidentiality and disclosure issues related to publication of empirical roc curves", "author": ["G.J. Matthews", "O. Harel"], "venue": "Academic radiology 20(7):889\u2013896.", "citeRegEx": "Matthews and Harel,? 2013", "shortCiteRegEx": "Matthews and Harel", "year": 2013}, {"title": "Differentially private algorithms for empirical machine learning", "author": ["B. Stoddard", "Y. Chen", "A. Machanavajjhala"], "venue": "CoRR abs/1411.5428.", "citeRegEx": "Stoddard et al\\.,? 2014", "shortCiteRegEx": "Stoddard et al\\.", "year": 2014}, {"title": "Signal detection theory in the 2AFC paradigm: attention, channel uncertainty and probability summation", "author": ["C. Tyler", "Chen", "C.-C."], "venue": "Vision Research 40(22):3121\u20133144.", "citeRegEx": "Tyler et al\\.,? 2000", "shortCiteRegEx": "Tyler et al\\.", "year": 2000}, {"title": "Exploiting an oracle that reports AUC scores in machine learning contests", "author": ["J. Whitehill"], "venue": "AAAI, 1345\u20131351.", "citeRegEx": "Whitehill,? 2016", "shortCiteRegEx": "Whitehill", "year": 2016}, {"title": "Toward a better understanding of leaderboard", "author": ["W. Zheng"], "venue": "arXiv preprint arXiv:1510.03349.", "citeRegEx": "Zheng,? 2015", "shortCiteRegEx": "Zheng", "year": 2015}], "referenceMentions": [{"referenceID": 1, "context": "Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016).", "startOffset": 268, "endOffset": 344}, {"referenceID": 6, "context": "Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016).", "startOffset": 268, "endOffset": 344}, {"referenceID": 11, "context": "Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016).", "startOffset": 268, "endOffset": 344}, {"referenceID": 10, "context": "Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016).", "startOffset": 268, "endOffset": 344}, {"referenceID": 10, "context": "Recent research on privacy-preserving machine learning (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information on the accuracy of a contestant\u2019s guesses, returned to the contestant by an oracle, can divulge information about the test data\u2019s true labels.", "startOffset": 55, "endOffset": 107}, {"referenceID": 1, "context": "Recent research on privacy-preserving machine learning (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information on the accuracy of a contestant\u2019s guesses, returned to the contestant by an oracle, can divulge information about the test data\u2019s true labels.", "startOffset": 55, "endOffset": 107}, {"referenceID": 11, "context": "Recent research on privacy-preserving machine learning (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information on the accuracy of a contestant\u2019s guesses, returned to the contestant by an oracle, can divulge information about the test data\u2019s true labels.", "startOffset": 55, "endOffset": 107}, {"referenceID": 1, "context": "Recent research on privacy-preserving machine learning (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information on the accuracy of a contestant\u2019s guesses, returned to the contestant by an oracle, can divulge information about the test data\u2019s true labels. Such oracles are often provided by the organizers of the competition themselves. For example, in the 2017 Intel & MobileODT Cervical Cancer Screening competition1 hosted by Kaggle, every contestant can submit her/his guesses up to 5 times per day, and for each submission the oracle returns the log-loss of the guesses with respect to the ground-truth values of the entire 512-element test set. The contestant can use the accuracy information to improve (hopefully) the classifier design and then re-submit. AUC: For binary classification problems, one of the most commonly used accuracy metrics is the Area Under the Receiver Operating Characteristics Curve (AUC). In contrast to other accuracy metrics such as log-loss and 0/1 loss, which can be computed as the sum of example-wise losses over each example in the test set, the AUC statistic is computed over all possible pairs of test examples, such that each pair contains one example from each class. In a recent paper, Whitehill (2016) showed that an oracle that provides contestants with information on the AUC of their guesses can inadvertently divulge information on the ground-truth labels of the test examples.", "startOffset": 73, "endOffset": 1269}, {"referenceID": 4, "context": "Related work: Over the past few years there has been growing theoretical and practical interest in the statistical validity of scientific results that are obtained from adaptive data analyses, in which the results of one experiment inform the design of the next (Dwork et al., 2015; Hardt and Ullman, 2014).", "startOffset": 262, "endOffset": 306}, {"referenceID": 6, "context": "Related work: Over the past few years there has been growing theoretical and practical interest in the statistical validity of scientific results that are obtained from adaptive data analyses, in which the results of one experiment inform the design of the next (Dwork et al., 2015; Hardt and Ullman, 2014).", "startOffset": 262, "endOffset": 306}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015).", "startOffset": 238, "endOffset": 273}, {"referenceID": 11, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015).", "startOffset": 238, "endOffset": 273}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution.", "startOffset": 239, "endOffset": 312}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset.", "startOffset": 239, "endOffset": 882}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset.", "startOffset": 239, "endOffset": 915}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset.", "startOffset": 239, "endOffset": 946}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. The AUC statistic, in particular, has been investigated in the context of privacy: Stoddard, Chen, and Machanavajjhala (2014) proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics.", "startOffset": 239, "endOffset": 1223}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. The AUC statistic, in particular, has been investigated in the context of privacy: Stoddard, Chen, and Machanavajjhala (2014) proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics. Matthews and Harel (2013) showed how an attacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an empirical ROC curve, i.", "startOffset": 239, "endOffset": 1337}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. The AUC statistic, in particular, has been investigated in the context of privacy: Stoddard, Chen, and Machanavajjhala (2014) proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics. Matthews and Harel (2013) showed how an attacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an empirical ROC curve, i.e., a set of classifier thresholds and corresponding true positive and false positive rates. The prior work most similar to ours is by Whitehill (2016). They showed a weak form of lower bound on the number of possible binary ground-truth vectors y \u2208 {0, 1} for which the contestant\u2019s guesses \u0177 achieve any fixed AUC c.", "startOffset": 239, "endOffset": 1640}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. The AUC statistic, in particular, has been investigated in the context of privacy: Stoddard, Chen, and Machanavajjhala (2014) proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics. Matthews and Harel (2013) showed how an attacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an empirical ROC curve, i.e., a set of classifier thresholds and corresponding true positive and false positive rates. The prior work most similar to ours is by Whitehill (2016). They showed a weak form of lower bound on the number of possible binary ground-truth vectors y \u2208 {0, 1} for which the contestant\u2019s guesses \u0177 achieve any fixed AUC c. Specifically, for every AUC value c = p/q \u2208 (0, 1), there exists an infinite sequence of dataset sizes (n = 4q, 8q, 12q, . . .) such that the number of satisfying ground-truth vectors y \u2208 {0, 1} grows exponentially in n. However, this result does not preclude the possibility that there might be certain pathological cases \u2013 combinations of p, q, n0, and n1 \u2013 for which the number of satisfying ground-truth vectors is actually much smaller. Conceivably, there might be values of n that lie between integer multiples of 4q for which the number of satisfying solutions is small. Moreover, the lower bound in Whitehill (2016) applies only to datasets that contain at least 4q examples and says nothing about smaller (but possibly still substantial) datasets.", "startOffset": 239, "endOffset": 2431}, {"referenceID": 0, "context": "The AUC has two mathematically equivalent definitions (Tyler and Chen, 2000; Agarwal et al., 2005): (1) the AUC is the Area under the Receiver Operating Characteristics (ROC) curve, which plots the true positive rate against the false positive rate of a classifier on some test set.", "startOffset": 54, "endOffset": 98}, {"referenceID": 10, "context": "Moreover, the recursive algorithm above can also be used constructively (though with large space costs) to compute the set of all binary vectors y of length n, of which n1 are 1, such that h(y, \u0177) = d for any d; conceivably, this could be useful for performing some kind of attack that uses the set of all compatible binary ground-truth vectors to improve the contestant\u2019s accuracy (Whitehill, 2016).", "startOffset": 382, "endOffset": 399}, {"referenceID": 10, "context": ", as part of some algorithmic attack to maximize performance within a datamining competition (Whitehill, 2016).", "startOffset": 93, "endOffset": 110}], "year": 2017, "abstractText": "Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016). For binary classification tasks in particular, one of the most common accuracy metrics is the Area Under the ROC Curve (AUC), and in this paper we explore the mathematical structure of how the AUC is computed from an n-vector of real-valued \u201cguesses\u201d with respect to the ground-truth labels. We show how knowledge of a classifier\u2019s AUC on the test set can constrain the set of possible ground-truth labelings, and we derive an algorithm both to compute the exact number of such labelings and to enumerate efficiently over them. Finally, we provide empirical evidence that, surprisingly, the number of compatible labelings can actually decrease as n grows, until a test set-dependent threshold is reached.", "creator": "LaTeX with hyperref package"}}}