{"id": "1709.02759", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2017", "title": "Semantic Preserving Embeddings for Generalized Graphs", "abstract": "A new approach to the study of Generalized Graphs as semantic data structures using machine learning techniques is presented. We show how vector representations maintaining semantic characteristics of the original data can be obtained from a given graph using neural encoding architectures and considering the topological properties of the graph. Semantic features of these new representations are tested by using some machine learning tasks and new directions on efficient link discovery, entitity retrieval and long distance query methodologies on large relational datasets are investigated using real datasets.", "histories": [["v1", "Thu, 7 Sep 2017 10:58:37 GMT  (1118kb,D)", "http://arxiv.org/abs/1709.02759v1", "Multi-lingual Paper. Main language: English. Additional Language: Spanish. 15 Figures. English: 28 pages. Spanish: 32 pages"]], "COMMENTS": "Multi-lingual Paper. Main language: English. Additional Language: Spanish. 15 Figures. English: 28 pages. Spanish: 32 pages", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["pedro almagro-blanco", "fernando sancho-caparrini"], "accepted": false, "id": "1709.02759"}, "pdf": {"name": "1709.02759.pdf", "metadata": {"source": "CRF", "title": "Semantic Preserving Embeddings for Generalized Graphs", "authors": ["Fernando Sancho-Caparrini"], "emails": [], "sections": [{"heading": null, "text": "Semantic Preserving Embedings for GeneralizedGraphsPedro Almagro-Blanco and Fernando Sancho-Caparrini11. September 2017"}, {"heading": "1 Introduction", "text": "In this thesis, we present a new approach to the treatment of property graphs by using neural encoding techniques derived from machine learning. Specifically, we will deal with the problem of embedding property graphs in vector spaces. In the course of this essay, we will use the term embedding as an operation that allows us to consider a mathematical structure, X, within another structure, Y, through a function, f: X \u2192 Y. We are interested in embedding that is able to capture within the properties of a vector space (distance, linearity, clusters, etc.) the interesting characteristics of the graph. In this way, we can interpret that the semantic verification associated with the relationship, by embedding the nodes of the graph in points of a vector space, can hold edges with the same type of graph in the same vectors. In this way, we can determine the link semantic that is captured by the relationship between the graph and the ification."}, {"heading": "2 Previous Definitions", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Generalized Graphs", "text": "The definition of the generalized graph that we present below unifies various graph definitions that can be found in the literature, and allows us to have a general framework to support the data structures necessary for our proposal. For more information on generalized graphs, see [1].ar Xiv: 170 9.02 759v 1 [cs.A I] 7 September 201 7Definition 1. A generalized graph is a tuple G = (V, E, \u00b5), where: \u2022 V and E are sentences, each designated as a set of nodes and edges of G. \u2022 \u00b5 is a relationship (usually functional, but not necessarily) that associates each node or edge in the graph with a set of properties, that is, \u00b5: (V, E) \u00d7 R \u2192 S, where R represents the set of possible keys for available properties, and S the set of possible values associated with possible edges."}, {"heading": "2.2 Encoding Neural Networks", "text": "In this section, we will get to know this type of network from a different perspective, using it in a way that is fundamental to the new results. Thus, if we try to achieve a function using a feedback network, then we can interpret the hidden layers that arise between the input and output layers. Thus, if we try to assume a function using a feedback network, then we will interpret the parameters of the network so that a hidden layer contains the information needed to calculate the function."}, {"heading": "3 Related Works", "text": "The application of neural encoders to texts has yielded very interesting results. 2013, T. Mikolov et al. [16] presents two new architectures, under the generic name word2vec, to learn vector representations of words that attempt to minimize arithmetic complexity while maintaining the grammatical properties present in the texts from which they are extracted: Continuous bag-of-words (CBOW) and Skip-gram. In this task, the context of a word in a text is defined as a set of words that appear in adjacent positions to it. The two architectures presented in [16] consist of artificial neural networks with 3 layers: an input layer, a hidden layer (coding layer), and an output layer, but they differ in the objective function they attempt to approximate. On the one hand, neural encoders with BOCW architecture obtain the context of a word as it and the output they attempt to predict."}, {"heading": "4 Generalized Graph Embeddings", "text": "The chosen architecture for our neural encoders is CBOW because, despite its simplicity and low computing costs, there are good results that capture both syntactic and semantic relationships. (In a first approximation and to assess the extent to which the semantic structure given by the edges is obtained, we will make a projection on the vector space that uses only the set of nodes, V). In this way, according to the analogy offered by the word2vec algorithm, a set of properties of the graph and the associated properties values, S.A context, C, associated with a node n-V, is obtained by randomly selecting a number of adjacent nodes to n and their properties (selection of elements from N (n), regardless of the edges they connect and the type of property."}, {"heading": "5 Empirical Evaluation", "text": "Let us perform some empirical evaluations of our method with two differentiated objectives: 1. To analyze that the obtained vector representations maintain semantic properties of the original graphs. 2. To perform classification and discovery tasks using the resulting embedding. We will say that an embedding respects the semantics of a property graph if it is possible from the new representation to obtain the types associated with nodes and edges even though they were not present during the embedding process. The type of each node or edge is determined by a key component. To perform this verification, the different embedding that we calculate will not receive information about types of nodes or edges in the original graph (formally, they will not receive information about their different properties).Therefore, contexts associated with nodes of the graph will be used to create the inequality of the training set (by selecting random numbers)."}, {"heading": "5.1 Implementation details and experiments", "text": "Python was selected as the programming language to perform the experimental evaluation 2. Implementation of Gensim toolkit 3 (version 0.12.4) into the CBOW architecture was used. Furthermore, Neo4j 4 was used as the persistence system.Each embedding experiment was repeated ten times, achieving a standard deviation of less than 2% in type prediction experiments. In the case of entity retrieval tasks, this deviation is limited by 8% and in the case of obtaining the target nodes of a typed path by 8.9%. Machine learning models are used to learn from the new data representations arek-NN, Random Forest and Neural Networks. For general classification tests, and unless otherwise specified, k-NN was used with k = 3 as the base comparison model."}, {"heading": "5.2 Datasets", "text": "The aforementioned cerebral consecrated cerebral consecrated cerebral consecrated cerebral consecrated cerebral consecrated csrcsrc\u00fcehlc\u00fceBnlrc\u00fcehlcsrc\u00fcehlcsrc\u00fcehlcsrc\u00fcehlc\u00fceBnln in the cerebral consecrated c\u00fcehnc\u00fcehnc\u00fcehncos ni rde cerebral consecrated csrc\u00fcehnlc\u00fceos cehros, cehros cehros, cehros cehros, cehros cehros, cehros cehros cehros, cehros cehros, cehrnos cehrnos, cehnllllllc\u00fcecos cehros cehnos, cehrcehnos cehrcehnos cehrcehnos, cehrcehnoscehnos cehrcehnos cehrcehno cehros, cehnehros cehnehnehros cehros cehnehnehrcehros cehnehnoso cehrcehno cehnehros cehnehros cehros cehnehnehnehnehros cehros cehnehnehros cehros cehnehnehnoso cehnehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnoscehnosceh"}, {"heading": "5.3 Node Types Prediction", "text": "The fact is that we are able to hide, in the way that we are able to, in the way that we are able to, in the way that we are able to, in the way that we are able to, in the way that we are able to, in the way that we are able to, in the way that we are able to, in the way that we are able to, in the way that we are able to, in the way that we are able to, in the way that we are able to, in the way that we are able to, in the way that we are able to, in the way that we are able to, in the way that we are able to, in the way that we are able to."}, {"heading": "5.3.1 Using other prediction models", "text": "Once the parameters of the embedding shown in Table 1 are set, we compare the predictive capacity with some other classification methods of the same task. Specifically, we compare the results of k-NN with those obtained by Random Forest and Feedforward Neural Networks. Figure 12 shows the results obtained. (a) Shows the variation in the results of k-NN as a function of k. (b) shows results obtained as a function of the number of trees that Random Forest uses as later machine learning. Finally, (c) shows the results of the neural network when the number of neurons in the hidden layer is modified. Furthermore, we show averaged confusion matrices after conducting 10 experiments using the optimal parameters given above and k-NN: WordNet (Table 2), TMDb (Table 3) and ICH (Table 7). These matrices capture the semantic similarities between, for example, the TOR and TOR, because they are notoriously similar to each other."}, {"heading": "5.4 Edge Types Prediction", "text": "The second experiment aims to determine the quality of embedding in the prediction tasks of edge types.Figure 13 shows a two-dimensional projection from a randomly selected set of edges of the TMDb dataset. It can be observed that genre edges do not form a single cluster, but a collection of peripheral edges that correspond to the values of action, comedy, drama, documentary, horror, and crime, and exhibit different semantic behavior with respect to other edge types. This could indicate that genre may not form a semantically unique edge type, and that its behavior reflects some heterogeneity in design decisions when constructing the original database model. Here, this type of analysis shows unique characteristics that make it suitable to be used as an additional normalizer for databases that also cover semantic and not just structural information. Figure 14 shows the results of prediction of edge type using the N percentage of the prediction method that can be obtained."}, {"heading": "5.4.1 Using other prediction models", "text": "The results show that the embedding detects similarities between different edge types. In the case of EICH, edge types related to geospatial information show an overlapping behavior with LENGUA-type edges, because there is a correlation between the languages and the territories in which they are spoken. WordNet shows a similar behavior between hypernym and hyponim types. In the case of TMDb, as expected, DIRECTED edges can be confused with LENGUA-type edges, as these edges are due to the overlap between ACTOR and DIRECTOR nodes. Experimental results show that for the analyzed data types and with the proposed prediction method, no absolute edge results can be taken into account."}, {"heading": "5.5 Entity Retrieval", "text": "To show the goodness and usefulness of our embedding in other prediction tasks, we will try to restore missing relationships. Let's look at a subset of edges, E \u2032 E, belonging to the original graph G, and consider the subgraph G \u2032 = (V, E\\ E \u2032, \u03c4, \u00b5) used to learn an embedding \u03c0. We will try to obtain the target node associated with each edge in E \u2032. This task is known as entity retrieval [6].To obtain the target node of the missing relationships, we will use the representative vector of the edge type (e) that was eliminated before the embedding process, we will try to obtain t from the edge (e) and s, the protity retrival [6].To obtain the target node of the missing relationships, we will use the representative vector of the edge type that we define as: definition 3."}, {"heading": "5.6 Typed Paths Prediction", "text": "Finally, we will show the possibilities offered by a generalized graph. 2.) We will introduce a technique to obtain the target node of a given type of path, with the type of path and source node of the same.A typed path being a sequence of node and edge types corresponding to a path in the graph (in some context these typed paths are called transversals): Definition 5. A typed path of a generalized graph G = (V, E, \u00b5) is a sequence of node and edge types corresponding to a path in the graph (in some context these types are called transversals): Definition 5. A typed path of a generalized graph G = (t1, E, \u00b5) is a sequenceT = t1 \u2192 t2 \u2192 t2 \u2192. rq \u2192 tq \u2192 The types of the two types are called transversals, where ti (V) and ri-typed paths of each of the typed G.We will generalize the G.6."}, {"heading": "6 Conclusions and Future Work", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "Acknowledgement", "text": "We thank the \"Instituto Nacional de Patrimonio Cultural\" of Ecuador for providing information on Ecuador's intangible cultural heritage. This work has been partially supported by the Excellence Project TIC-6064 of the Junta de Andaluc'\u0131a and TIN2013-41086-P of the Spanish Ministry of Economy and Competitiveness (co-financed with FEDER funds) and by the Department of Research and Graduate Studies of the Central University of Ecuador."}, {"heading": "2. Definiciones Previas", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Grafos Generalizados", "text": "It is not the first time that the European Commission has considered the question of whether it is in a position to take the measures proposed by the European Commission in order to reduce the impact of climate change on the global economy. (...) It is not the first time that the European Commission has dealt with the question of how to deal with the effects of climate change on the global economy. (...) Nor is it the first time that the European Commission has been able to limit the impact of climate change on the global economy. (...) It is not the first time that the European Commission has dealt with the question of how to deal with the effects of climate change on the global economy. (...) It is not the first time that the European Commission has considered itself capable of combating climate change. (...) It is not the first time that the European Commission has taken such measures. (...)"}, {"heading": "2.2. Redes Neuronales Codificadoras", "text": "El uso \"s habitual de las redes neuronales es es feedforward ha sido como ma\" quinas de ca \u0301 lculo, pero en esta seccio \"n presentamos un uso que sera\" (y ha sido) de fundamentalen Importancia para los nuevos resultados que que que que se han obtenido con ellas.Obse \"de la realos os os os os os de ellas.obse\" de la realos os os os de ellas.obs \"de la realitos de la realitos\" de la realitos \"de la realitos de la realitos os os os os os os de ellas.obs\" It is not as if it is a way, how it is a way. \""}, {"heading": "3. Trabajos Relacionados", "text": "It is a question of whether this is a political system, a system in which the interests of the people are put centre stage. (...) It is a system in which the interests of the people are put centre stage. (...) It is a system in which the interests of the people are put centre stage. (...) It is a system in which the interests of the people are put centre stage. (...) It is a system in which the interests of the people are put centre stage. (...) It is a system in which the interests of the people are put centre stage. (...) It is a system in which the interests of the people are put centre stage. (...) It is a system in which the interests of the people are put centre stage. (...) It is a system in which the interests of the people are put centre stage. (...) It is a system in which the interests of the people are put centre stage. (...)"}, {"heading": "4. Inmersiones de Grafos con Propiedades", "text": "Entre las opciones barajadas, la arquitectura selectura seleccionada para los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los without los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los"}, {"heading": "5.1. Detalles de la implementacio\u0301n y experimentos", "text": "Se ha elegido Python como lenguaje de programacio \u00b2 n para llevar a cabo la evaluacio \u00b2 n contracio sen \u00b2 alada2. Para la implementation acio \u00b2 n de la arquitectura CBOW se ha utilizado el conjunto de herramientas Gensim3 (versio \u00b2 n 0.12.4). Adema \u00b2 s, se ha utilizado Neo4j4 como sistema de persistencia para los grafos con propiedades analizados.Cada experimento de inmersio \u00b2 n, con para \u00b2 metros prefijados, se ha repetido 10 veces, valor que experimentalmente ha mostrado una desviacio \u00b2 n esta \u0445 ndar en los resultados con la prediccio \u00b2 n de los tipos lo y aristas inferior al 2%."}, {"heading": "5.2. Datasets", "text": "\"It's not that we can't agree on a solution,\" he said. \"But it's not that we can't agree on a solution.\" \"It's not that we can agree on a solution.\" \"It's not that we can agree on a solution.\" \"It's not that we can agree on a solution.\" \"It's not that we have to agree on a solution.\" \"It's not that we can agree on a solution.\" \"It's not that we have to agree on a solution.\" \"It's not that we have to agree on a solution.\" \"\" It's not that we can agree on a solution. \"\""}, {"heading": "5.3. Prediccio\u0301n de Tipos de Nodos", "text": "In recent years, it has become clear that it is not only a question of what the future of humanity is, but also of what the future of humanity is and what the future of humanity is. (...) It is clear that we have to take care of the future of humanity. (...) It is not that we have to take care of the future of humanity. (...) It is that we have to take care of the future of humanity. (...) It is that we have to take care of the future of humanity. (...) It is not that we have to take care of the future of humanity. (...) It is that we have to take care of the future of humanity. (...) It is that we have to take care of the future of humanity. \""}, {"heading": "5.3.1. Comparacio\u0301n con otros modelos de prediccio\u0301n", "text": "Una vez fijados los para \u0301 metros de la inmersio \u0301 n que proporciona la Tabla 1, procedemos a comparar la capacidad predictiva con algunos me \"todos automa\" ticos de clasificacio \"n sobre la misma representacio\" n. Concretamente, compararemos estos resultados con los obtenidos a trave \u0301 s de redes neuronal feedforward y Random Forest.En la Figura 12 se muestran los resultados obtenidos. La gra civifica estos estos estos (a) muestra la variacio \"n de los resultados proporcionados por os por.\" NN cuando var un el valor k; en (b) se muestran los tados obtenios obtenidos."}, {"heading": "5.4. Prediccio\u0301n de Tipos de Aristas", "text": "\"It is a question of time before agreement is reached,\" he said. \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" \"It is a question of credibility.\" It is a question of credibility. \"It is a question of credibility.\" It is a question of credibility. \""}, {"heading": "5.4.1. Comparacio\u0301n con otros modelos de prediccio\u0301n", "text": "Siguiendo la misma metodolog \u0301 a que para los tipos de nodos, la Figura 15 muestra los resultados obtenidos por los tres me'todos de clasificacios os os os usos os os os os os os os os os os os os os os os os os os usos os os os os os os os os os os os os os os os os os os os los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los los"}, {"heading": "5.5. Entity Retrieval", "text": "It is a question of whether this is a collecting society or not. (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (...) (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (...) It is about a collecting society. (... It is about a collecting society."}, {"heading": "5.6. Inmersio\u0301n de caminos tipados", "text": "\"It's not that we can't agree on a solution,\" he said. \"But it's not that we can agree on a solution.\" \"It's not that we can agree on a solution.\" \"It's not that we can agree on a solution.\" \"It's not that we can agree on a solution.\" \"It's not that we have to agree on a solution.\" \"It's not that we have to agree on a solution.\" \"It's not that we have to agree on a solution.\" \"It's not that we have to agree on a solution.\" \"\" It's not that we can agree on a solution. \"\" It's not that we have to agree on a solution. \"\" \"It's not that we have to agree on a solution.\" \""}, {"heading": "6. Conclusiones y Trabajo Futuro", "text": "\"It's not the first time we've found ourselves in a situation where we're in a situation where we're no longer able to help ourselves,\" he said. \"But it's not the first time we've found ourselves in a situation where we're in a situation where we're no longer able to help ourselves.\" He added, \"It's not the first time we've found ourselves in a situation where we're no longer able to help ourselves.\""}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "In this work we present a new approach to the treatment of property graphs using neural encoding techniques derived from machine learning. Specifically, we will deal with the problem of embedding property graphs in vector spaces. Throughout this paper we will use the term embedding as an operation that allows to consider a mathematical structure, X, inside another structure Y , through a function, f : X \u2192 Y . We are interested on embeddings capable of capturing, within the characteristics of a vector space (distance, linearity, clustering, etc.), the interesting features of the graph. For example, it would be interesting to get embeddings that, when projecting the nodes of the graph into points of a vector space, keep edges with the same type of the graph into the same vectors. In this way, we can interpret that the semantic associated to the relation has been captured by the embedding. Another option is to check if the embedding verifies clustering properties with respect to the types of nodes, types of edges, properties, or some of the metrics that can be measured on the graph. Subsequently, we will use these good embedding features to try to obtain prediction / classification / discovery tools on the original graph. This paper is structured as follows: we will start by giving some preliminary definitions necessary for the presentation of our proposal and a brief introduction to the use of artificial neural networks as encoding machines. After this review, we will present our embedding proposal based on neural encoders, and we will verify if the topological and semantic characteristics of the original graph have been maintained in the new representation. After evaluating the properties of the new representation, it will be used to carry out machine learning and discovery tasks on real databases. Finally, we will present some conclusions and future work proposals that have arisen during the implementation of this work.", "creator": "LaTeX with hyperref package"}}}