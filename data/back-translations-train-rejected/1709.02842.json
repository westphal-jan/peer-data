{"id": "1709.02842", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2017", "title": "Combining LSTM and Latent Topic Modeling for Mortality Prediction", "abstract": "There is a great need for technologies that can predict the mortality of patients in intensive care units with both high accuracy and accountability. We present joint end-to-end neural network architectures that combine long short-term memory (LSTM) and a latent topic model to simultaneously train a classifier for mortality prediction and learn latent topics indicative of mortality from textual clinical notes. For topic interpretability, the topic modeling layer has been carefully designed as a single-layer network with constraints inspired by LDA. Experiments on the MIMIC-III dataset show that our models significantly outperform prior models that are based on LDA topics in mortality prediction. However, we achieve limited success with our method for interpreting topics from the trained models by looking at the neural network weights.", "histories": [["v1", "Fri, 8 Sep 2017 19:30:09 GMT  (888kb,D)", "http://arxiv.org/abs/1709.02842v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yohan jo", "lisa lee", "shruti palaskar"], "accepted": false, "id": "1709.02842"}, "pdf": {"name": "1709.02842.pdf", "metadata": {"source": "META", "title": "Combining LSTM and Latent Topic Modeling for Mortality Prediction ", "authors": ["Yohan Jo", "Lisa Lee", "Shruti Palaskar"], "emails": ["YOHANJ@CS.CMU.EDU", "LSLEE@CS.CMU.EDU", "SPALASKA@CS.CMU.EDU"], "sections": [{"heading": "1. Introduction", "text": "Many ICUs suffer from a shortage of nurses and physicians to care for patients in critical situations. As caregivers inevitably prioritize patients based on the severity of their illnesses, it is imperative to use patient data - gathered from laboratory tests and clinical notes - to determine the most efficient ICU resource allocation; the problem of predicting mortality involves several challenges. (1) Mortality predictions require the use of time series data, where a progressive analysis of patients \"conditions is preferred in order to perform a cross-sectional analysis, whereas previous work carried out time series analysis of clinical notes (Jo & Rose, 2015; Grnarova et al.)"}, {"heading": "2. Background & Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Clinical Outcome Prediction", "text": "The three most important types of clinical data used to predict clinical outcomes are textual annotations (Ghassemi et al., 2014; Jo & Rose \u0301, 2015; Grnarova et al., 2016), re-evaluated measurements (e.g. laboratory / physiological measurements) (Lipton et al., 2015), and categorical measurements (e.g. medical codes).Textual clinical notes contain qualitative information that cannot be found in numerical measurements, such as insights from nurses and physicians, as well as social context (e.g. relationships with family and friends).Clinicalar Xiv: 170 942v 1 [cs.C L] 817notes were considered helpful for long-term predictions, but not for predicting predictions, but for short-term predictions, but not so much for short-term predictions as short-term predictions (Jo & Rose)."}, {"heading": "2.2. Neural Network for Topic Modeling", "text": "Our goal is to design a neural network architecture in which the top layer is LSTM for predicting mortality, and the bottom layer feeds the LSTM at all times with a latent topic distribution learned from clinical notes. In thissection, we review previous work on modeling topic distributions using neural networks. One of the simplest and earliest approaches is a restricted Boltzmann machine (Srivastava et al., 2013; Hinton & Salakhutdinov, 2009). However, the activation probability of each hidden node is a sigmoid function based on a weighted sum of the frequency of individual words. Therefore, a hidden node can be interpreted as a latent topic associated with each word. Inspired by these models, a deep sigmoid belief network was proposed to learn topic distributions in a superordinated manner."}, {"heading": "3. Methods", "text": "Our task is to create a classifier to predict the mortality of a patent, since his / her clinical notes have been written to date (Figure 1). Throughout the report, we define points of time as 12-hour periods of a patient's timeline from the time of admission (e.g., point 1 is the first 12 hours, point 2 is the next 12 hours, etc.) (Ghassemi et al., 2014). For each patient, we aggregate all notes at any time t into a word representation text that sums up 1. In this section, we present each of our models (see Figure 2 for an overview). First, we present and compare two basic LDA models to analyze the benefits of using LSTM over linear SVM to capture long-term dependencies (Section 3.1). Then, we present three end-to-end models that jointly learn topic models and mortality predictions (Section 3.2)."}, {"heading": "3.1. LDA baselines", "text": "Here we present two basic methods that use LDA that have been used to derive topic distributions in textual clinical notes. Note that these models are not a common model of topic modeling and mortality prediction, since they use a separate LDA model to train topics.SVM + LDA is the model proposed by Ghassemi et al. (2014). This model builds a linear SVM for each point in time that predicts a patient's mortality based on clinical notes written up to that time.To get the input for the classifier for time t, we first calculate the topic distribution of each note using LDA and then aggregate all topic distributions up to a point in time t, simply by defining the distribution vectors of themes.LSTM + LDA replaces the linear SVM with LSTM, which allows us to evaluate the ability of the STM to predict the time dependencies for STDA = STH (In contrast to STD = STD)."}, {"heading": "3.2. Joint Models", "text": "In fact, we are able to move in a direction in which we are able to move, to move, to move in a direction in which we are able to move, \"he said."}, {"heading": "4. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Evaluation Metrics", "text": "According to Ghassemi et al. (2014; 2016), we evaluate our model using three tasks to predict mortality: hospital mortality, 30 days after discharge, and 1 year after discharge. These three tasks cover both short-term and long-term mortality. We measure accuracy using the Area Under ROC Curve (AUC) measure (Rakotomamonjy, 2004), which measures how well a trained classifier distinguishes between positive and negative entities."}, {"heading": "4.2. Data and Preprocessing", "text": "We use the MIMIC III dataset, which contains data on patients admitted to intensive care units of a large hospital (Johnson et al., 2016); in preparing the data, we have followed the work of Ghassemi et al. (2014) as closely as possible because their attitudes are widespread (Jo & Rose \u0301, 2015; Grnarova et al., 2016); we have also excluded patients younger than 18 years of age; these patients (mostly infants) exhibit very different trajectories from adult patients (Jo & Rose \u0301, 2015); we have used all textual clinical notes except for outlet totals because they explicitly mention the patient's outcomes; we randomly divide patients into training, validation, and test kits at a ratio of 6: 2: 2. As the classes are heavily biased toward negative (i.e. survival), the negative instances are # nified in the training set so that negative predictions make up no more than 70% of the training set."}, {"heading": "4.3. Models and Parameters", "text": "The costs C and the weight w for the positive class (\"died\") in libsvm are examined in a grid of C = {2 \u2212 5, 2 \u2212 3, 2 \u2212 1, 21, 23, 25, 27, 29, 211, 213, 215} and w = {1, 3, 5, 7, 9} and matched to the validation group. Weight for the negative class (\"survived\") is 1. The network configuration of our models is summarized in Table 2. Batch size is 10, the number of training steps is 100,000 and the learning rate is 0.001. As in the SVM, we have examined various false negative costs (equation 1) CFN = {20, 21, 22, 23} and selected the optimal value based on the validation level."}, {"heading": "5. Results", "text": "We evaluate our models both in terms of mortality prediction (Section 5.1) and in terms of the quality of the topics learned (Section 5.2 and 5.3)."}, {"heading": "5.1. Mortality Prediction Accuracy", "text": "The common models LSTM + E (+ T) (+ D) outperform LDA baselines in all three mortality forecasting tasks by about + 4% (hospital), + 2% (30days), + 7% (1 year) on average. LSTM-based approaches show a lower loss of accuracy over time than SVM + LDA baselines, especially in inpatient forecasting. One of the reasons for the drop in performance of SVM + LDA is that patients who have died or been discharged at a particular time are excluded from the training set (Ghassemi et al., 2014). According to the hospital forecast, LSTM seems to be able to alleviate this problem. We suspect that the way we define our cost function - the average time wasted during previous hospitalizations - contributes to higher costs for further classification of patients."}, {"heading": "5.2. Topic Interpretation", "text": "In fact, it is the case that most of them are able to survive themselves if they do not put themselves in a position to survive themselves, and that they are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...)"}, {"heading": "5.3. Topic Quality", "text": "We analyzed the quality of the learned topics by analyzing the t-SNE diagrams of the latent document vectors in Fig. 5. We focused on the documents in the blue box in the left pane and examined whether these documents are tightly grouped in the diagrams LSTM + E (middle pane) and LSTM + E + D (right pane). LSTM + E + D seems to produce a more similar cluster than LSTM + E, and therefore LSTM + E + D could perform better than LSTM + E + D in relation to the first method. Note that we did not observe a significant difference in the quality of the topic clusters learned by LSTM + E + D compared to LSTM + E + T + D, so we omitted the plot for LSTM + E + T + D."}, {"heading": "6. Conclusion", "text": "This year it is more than ever before."}], "references": [{"title": "A novel neural topic model and its supervised extension", "author": ["Cao", "Ziqiang", "Li", "Sujian", "Liu", "Yang", "Wenjie", "Ji", "Heng"], "venue": "In Proceedings of the TwentyNinth AAAI Conference on Artificial Intelligence, January 25-30,", "citeRegEx": "Cao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cao et al\\.", "year": 2015}, {"title": "Scalable noise mining in longterm electrocardiographic time-series to predict death following heart attacks", "author": ["C C Chia", "Z. Syed"], "venue": "In Proceedings of the 20th ACM SIGKDD international ", "citeRegEx": "Chia and Syed,? \\Q2014\\E", "shortCiteRegEx": "Chia and Syed", "year": 2014}, {"title": "Computationally Generated Cardiac Biomarkers: Heart Rate Patterns to Predict Death Following Coronary Attacks", "author": ["Chia", "Chih-chun", "Syed", "Zeeshan"], "venue": "In Proceedings of the 2011 SIAM International Conference on Data Mining,", "citeRegEx": "Chia et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chia et al\\.", "year": 2011}, {"title": "Hierarchical multiscale recurrent neural networks", "author": ["Chung", "Junyoung", "Ahn", "Sungjin", "Bengio", "Yoshua"], "venue": "CoRR, abs/1609.01704,", "citeRegEx": "Chung et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chung et al\\.", "year": 2016}, {"title": "Topicrnn: A recurrent neural network with long-range semantic dependency", "author": ["Dieng", "Adji B", "Wang", "Chong", "Gao", "Jianfeng", "Paisley", "John William"], "venue": "CoRR, abs/1611.01702,", "citeRegEx": "Dieng et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dieng et al\\.", "year": 2016}, {"title": "Neural Document Embeddings for Intensive Care Patient Mortality Prediction", "author": ["Grnarova", "Paulina", "Schmidt", "Florian", "Hyland", "Stephanie L", "Eickhoff", "Carsten"], "venue": "cs.CL,", "citeRegEx": "Grnarova et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Grnarova et al\\.", "year": 2016}, {"title": "Modeling perspective using adaptor grammars", "author": ["Hardisty", "Eric", "Boyd-Graber", "Jordan", "Resnik", "Philip"], "venue": "EMNLP \u201910: Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Hardisty et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hardisty et al\\.", "year": 2010}, {"title": "Time Series Analysis of Nursing Notes for Mortality Prediction via a State Transition Topic Model", "author": ["Jo", "Yohan", "Ros\u00e9", "Carolyn Penstein"], "venue": "Proceedings of the 24th ACM International Conference on Information and Knowledge Management,", "citeRegEx": "Jo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jo et al\\.", "year": 2015}, {"title": "MIMIC-III, a freely accessible critical care database", "author": ["Johnson", "Alistair E W", "Pollard", "Tom J", "Shen", "Lu", "Lehman", "Li-wei H", "Feng", "Mengling", "Ghassemi", "Mohammad", "Moody", "Benjamin", "Szolovits", "Peter", "Anthony Celi", "Leo", "Mark", "Roger G"], "venue": null, "citeRegEx": "Johnson et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2016}, {"title": "Learning to Diagnose with LSTM Recurrent Neural Networks", "author": ["Lipton", "Zachary C", "Kale", "David C", "Elkan", "Charles", "Wetzell", "Randall"], "venue": null, "citeRegEx": "Lipton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lipton et al\\.", "year": 2015}, {"title": "Optimizing Area Under Roc Curve with SVMs", "author": ["Rakotomamonjy", "Alain"], "venue": "The 1st workshop on ROC analysis in artificial intelligence,", "citeRegEx": "Rakotomamonjy and Alain.,? \\Q2004\\E", "shortCiteRegEx": "Rakotomamonjy and Alain.", "year": 2004}, {"title": "Modeling Documents with Deep Boltzmann Machines", "author": ["Srivastava", "Nitish", "Salakhutdinov", "Ruslan R", "Hinton", "Geoffrey E"], "venue": null, "citeRegEx": "Srivastava et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2013}, {"title": "Topic modeling: beyond bag-of-words", "author": ["H. Wallach"], "venue": "Proceedings of the 23rd international conference on ", "citeRegEx": "Wallach,? \\Q2006\\E", "shortCiteRegEx": "Wallach", "year": 2006}, {"title": "Online Latent Dirichlet Allocation with Infinite Vocabulary", "author": ["Zhai", "Ke", "Boyd-Graber", "Jordan L"], "venue": "Proceedings of the 30th International Conference on Ma- chine Learning,", "citeRegEx": "Zhai et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhai et al\\.", "year": 2013}, {"title": "Learning from LDA using deep neural networks", "author": ["Zhang", "Dongxu", "Luo", "Tianyi", "Wang", "Dong"], "venue": "In Natural Language Understanding and Intelligent Applications 5th CCF Conference on Natural Language Processing and Chinese Computing,", "citeRegEx": "Zhang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 5, "context": "While prior work has conducted time series analysis of clinical notes (Jo & Ros\u00e9, 2015; Grnarova et al., 2016) and other measurements (Lipton et al.", "startOffset": 70, "endOffset": 110}, {"referenceID": 9, "context": ", 2016) and other measurements (Lipton et al., 2015) for predicting mortality/diagnoses, there is no standard methodology that yields high accuracy in mortality prediction.", "startOffset": 31, "endOffset": 52}, {"referenceID": 5, "context": "neural network techniques have demonstrated promising performance in prediction tasks (Grnarova et al., 2016; Lipton et al., 2015), they often lack interpretability and suffer from data sparsity (e.", "startOffset": 86, "endOffset": 130}, {"referenceID": 9, "context": "neural network techniques have demonstrated promising performance in prediction tasks (Grnarova et al., 2016; Lipton et al., 2015), they often lack interpretability and suffer from data sparsity (e.", "startOffset": 86, "endOffset": 130}, {"referenceID": 5, "context": "The three main types of clinical data that have been used for clinical outcome prediction are textual notes (Ghassemi et al., 2014; Jo & Ros\u00e9, 2015; Grnarova et al., 2016), realvalued measurements (e.", "startOffset": 108, "endOffset": 171}, {"referenceID": 9, "context": ", laboratory/physiologic measurements) (Lipton et al., 2015), and categorical measurements (e.", "startOffset": 39, "endOffset": 60}, {"referenceID": 5, "context": "Recently, a joint model of LSTM and convolutional neural network (CNN) was used to predict mortality and found phrases that are highly related to mortality (Grnarova et al., 2016).", "startOffset": 156, "endOffset": 179}, {"referenceID": 9, "context": ", blood pressure, blood oxygen saturation) were resampled to an hourly rate by taking the mean value and then put into an LSTM for prediction (Lipton et al., 2015).", "startOffset": 142, "endOffset": 163}, {"referenceID": 1, "context": "For real-valued time series measurements, Chia and Syed (2014) predicted mortality using the variability of ECG signals for each patient measured by dynamic time warping between every pair of consecutive heart beats.", "startOffset": 42, "endOffset": 63}, {"referenceID": 1, "context": "For real-valued time series measurements, Chia and Syed (2014) predicted mortality using the variability of ECG signals for each patient measured by dynamic time warping between every pair of consecutive heart beats. Chia and Syed (2013) also used time series heart rate patterns for mortality prediction, by binning each heart rate (per minute), clustering subsequences of the bins, and choosing clusters that are indicative of mortality and survival respectively.", "startOffset": 42, "endOffset": 238}, {"referenceID": 11, "context": "One of the simplest and earliest approaches is a restricted Boltzmann machine (Srivastava et al., 2013; Hinton & Salakhutdinov, 2009).", "startOffset": 78, "endOffset": 133}, {"referenceID": 14, "context": "Inspired by these models, a deep sigmoid belief network has been proposed to learn topic distributions in a supervised way given a bag-of-words, and there has been an attempt to interpret the hidden layers (Zhang et al., 2016).", "startOffset": 206, "endOffset": 226}, {"referenceID": 4, "context": "In a more recent model, TopicRNN, the topic distribution of text is assumed to be drawn from a normal distribution whose mean and variance are computed from the input BoW using a neural network (Dieng et al., 2016).", "startOffset": 194, "endOffset": 214}, {"referenceID": 6, "context": "Topics learned by the above models are based on unigrams, but general n-grams may capture better topics for some tasks, as shown in (Zhai & Boyd-Graber, 2013; Hardisty et al., 2010; Wallach, 2006).", "startOffset": 132, "endOffset": 196}, {"referenceID": 12, "context": "Topics learned by the above models are based on unigrams, but general n-grams may capture better topics for some tasks, as shown in (Zhai & Boyd-Graber, 2013; Hardisty et al., 2010; Wallach, 2006).", "startOffset": 132, "endOffset": 196}, {"referenceID": 0, "context": "A neural network model has been proposed that learns the association between an arbitrary n-gram and topics (Cao et al., 2015).", "startOffset": 108, "endOffset": 126}, {"referenceID": 3, "context": "Recently, hierarchical LSTM has been proposed (Chung et al., 2016).", "startOffset": 46, "endOffset": 66}, {"referenceID": 8, "context": "We use the MIMIC-III dataset which contains data about patients admitted to critical care units at a large tertiary care hospital (Johnson et al., 2016).", "startOffset": 130, "endOffset": 152}, {"referenceID": 5, "context": "(2014)\u2019s work as closely as we could, as their setting has been widely used (Jo & Ros\u00e9, 2015; Grnarova et al., 2016).", "startOffset": 76, "endOffset": 116}, {"referenceID": 7, "context": "We use the MIMIC-III dataset which contains data about patients admitted to critical care units at a large tertiary care hospital (Johnson et al., 2016). For data preparation, we followed Ghassemi et al. (2014)\u2019s work as closely as we could, as their setting has been widely used (Jo & Ros\u00e9, 2015; Grnarova et al.", "startOffset": 131, "endOffset": 211}], "year": 2017, "abstractText": "There is a great need for technologies that can predict the mortality of patients in intensive care units with both high accuracy and accountability. We present joint end-to-end neural network architectures that combine long short-term memory (LSTM) and a latent topic model to simultaneously train a classifier for mortality prediction and learn latent topics indicative of mortality from textual clinical notes. For topic interpretability, the topic modeling layer has been carefully designed as a single-layer network with constraints inspired by LDA. Experiments on the MIMIC-III dataset show that our models significantly outperform prior models that are based on LDA topics in mortality prediction. However, we achieve limited success with our method for interpreting topics from the trained models by looking at the neural network weights.", "creator": "LaTeX with hyperref package"}}}