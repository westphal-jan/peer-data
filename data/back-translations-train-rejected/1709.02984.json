{"id": "1709.02984", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Sep-2017", "title": "Sentiment Polarity Detection for Software Development", "abstract": "The role of sentiment analysis is increasingly emerging to study software developers' emotions by mining crowd-generated content within social software engineering tools. However, off-the-shelf sentiment analysis tools have been trained on non-technical domains and general-purpose social media, thus resulting in misclassifications of technical jargon and problem reports. Here, we present Senti4SD, a classifier specifically trained to support sentiment analysis in developers' communication channels. Senti4SD is trained and validated using a gold standard of Stack Overflow questions, answers, and comments manually annotated for sentiment polarity. It exploits a suite of both lexicon- and keyword-based features, as well as semantic features based on word embedding. With respect to a mainstream off-the-shelf tool, which we use as a baseline, Senti4SD reduces the misclassifications of neutral and positive posts as emotionally negative. To encourage replications, we release a lab package including the classifier, the word embedding space, and the gold standard with annotation guidelines.", "histories": [["v1", "Sat, 9 Sep 2017 17:28:10 GMT  (2157kb)", "http://arxiv.org/abs/1709.02984v1", null], ["v2", "Mon, 25 Sep 2017 14:37:55 GMT  (2157kb)", "http://arxiv.org/abs/1709.02984v2", "Cite as: Calefato, F., Lanubile, F., Maiorano, F., Novielli N. Empir Software Eng (2017).this https URLFull-text view-only version here:this http URL, Empir Software Eng (2017)"]], "reviews": [], "SUBJECTS": "cs.SE cs.CL", "authors": ["fabio calefato", "filippo lanubile", "federico maiorano", "nicole novielli"], "accepted": false, "id": "1709.02984"}, "pdf": {"name": "1709.02984.pdf", "metadata": {"source": "CRF", "title": "Sentiment Polarity Detection for Software Development", "authors": ["Fabio Calefato", "Filippo Lanubile", "Federico Maiorano", "Nicole Novielli"], "emails": ["nicole.novielli}@uniba.it,", "f.maiorano2@studenti.uniba.it"], "sections": [{"heading": null, "text": "Senti4SD is a classifier specially trained to support mood analysis in developers \"communication channels. Senti4SD is trained and validated against a gold standard of stack overflow questions, answers and comments, which is commented manually for mood polarity. Senti4SD uses a range of both lexico- and keyword-based features, as well as semantic features based on word embedding. In terms of a standard tool that we use as a starting point, Senti4SD reduces the shifts from neutral and positive contributions to emotionally negative. To promote replication, we publish a laboratory package that includes the classifier, the word embedding space and the gold standard with annotation guidelines."}, {"heading": "1. Introduction", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "2. Research Methods", "text": "Our research uses a mixture of qualitative and quantitative methods, including manual encoding of text data to build a gold standard on emotion polarity in software development, natural language processing techniques for feature extraction from stack overflow texts, and machine learning for the formation of our emotion polarity classification. Fig. 1 summarizes the process we followed in the current study. The complete process is in four sequential phases.1 The complete laboratory package, including Senti4SD, the DSM, and the gold standard, is available for download at https: / / github.com / collab-uniba / Senti4SDIn Phase 1, we identified the theoretical framework of the current study and chose the emotion model to include in our annotation (see Section 3.1). The first issue is the taxonomy of emotions and their mapping with polarity. As the second issue, we defined the coding guidelines to be incorporated into the annotation guidelines."}, {"heading": "3. Background", "text": "In fact, it is the case that you are able to go in search of a solution that is capable of finding a solution that is capable of finding a solution."}, {"heading": "4. Dataset: A Gold Standard for Emotion Polarity in Software Development", "text": "This year, it has come to the point where it will be able to take the lead without being able to take the lead."}, {"heading": "5. Emotion Polarity Classifier: Feature Description and System Setup", "text": "This year, it will be able to come out on top, \"he said in an interview with\" Welt am Sonntag, \"in which he discussed the\" world \"and the\" world. \""}, {"heading": "6. Evaluation", "text": "We used the training to find the optimal parameter setting for our classifier (see Section 5.4).The final model was trained throughout the training set using the optimal configuration and then evaluated on the test set to assess the degree to which the trained model is able to generalize polarity grading on invisible new data from the Heldout Test (see Section 5.4).The final model was trained throughout the training program using the optimal configuration and then evaluated on the test set. After training Senti4SD, we evaluated the model learned on the stack overflow test. TABLE 8 reports on the performance achieved in terms of recall, precision and F measurement for each class.The total performance is calculated as an aggregated metric (Sebastiani 2002)."}, {"heading": "7. Discussion", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "8. Threats to Validity", "text": "This year, it is only a matter of time before it is ready, until it is ready, until it can enter into force."}, {"heading": "9. Related Work", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "10. Conclusions", "text": "We have introduced Senti4SD, a sentiment polarity classifier for the artifacts of software developers. The classifier is trained and tested on a gold standard of over 4K posts derived from stack overflow and commented manually with emotion polarity. The gold standard is publicly available for further studies of emotion awareness in software engineering. We also publish the annotation guidelines to encourage the community to expand and further validate our data set by replicating the annotation experiment. Senti4SD's semantic properties are calculated on the basis of a distributional semantic model that uses word embedding. We have built the DSM by running word2vec on a collection of over 20 million documents from stack overflow, giving us word vectors representative of the developer's communication style. The DSM is released, with the replication kit, for use in future research."}, {"heading": "Acknowledgments", "text": "This work is partly supported by the project \"EmoQuest - Investigating the Role of Emotions in Online Question & Answer Sites,\" which is funded by the Italian Ministry of Education, University and Research (MIUR) under the programme \"Scientific Independence of Young Researchers\" (SIR).The computational work was carried out with the IT resources provided by two projects, ReCaS and PRISMA, which were funded by MIUR under the programme \"PON R & C 2007-2013.\" We thank Pierpaolo Basile for insightful discussions and helpful comments, as well as the commentators who participated in the gold standard building."}, {"heading": "Appendix A: Coding Guidelines", "text": "In fact, it's as if you're able to outdo yourself, and that you're able to outdo yourself, \"he said.\" But it's not as if, \"he said.\" But it's as if, \"he said.\" It's not as if, \"he said.\" It's as if, \"he said.\" But it's as if, \"he said.\" But it's as if, \"he said.\" It's as if, \"he said.\" It's as if. \""}], "references": [{"title": "Discovering value from community activity on focused question", "author": ["A Anderson", "D Huttenlocher", "J Kleinberg", "J Leskovec"], "venue": null, "citeRegEx": "Anderson et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Anderson et al\\.", "year": 2012}, {"title": "Answering questions about unanswered questions of stack", "author": ["M Asaduzzaman", "AS Mashiyat", "CK Roy", "KA Schneider"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Don\u2019t count, predict! a systematic comparison of context-counting", "author": ["M Baroni", "G Dinu", "G Kruszewski"], "venue": "USA, MSR", "citeRegEx": "Baroni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "What are developers talking about? an analysis of topics and trends in stack", "author": ["A Barua", "SW Thomas", "AE Hassan"], "venue": null, "citeRegEx": "Barua et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Barua et al\\.", "year": 2014}, {"title": "Uniba: Sentiment analysis of English tweets combining micro-blogging, lexicon and semantic", "author": ["P Basile", "N Novielli"], "venue": null, "citeRegEx": "Basile and Novielli,? \\Q2015\\E", "shortCiteRegEx": "Basile and Novielli", "year": 2015}, {"title": "A neural probabilistic language model", "author": ["Y Bengio", "R Ducharme", "P Vincent", "C Janvin"], "venue": "Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015),", "citeRegEx": "Bengio et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2003}, {"title": "Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit", "author": ["London", "pp 23\u201344 Cohen J"], "venue": null, "citeRegEx": "London et al\\.,? \\Q1968\\E", "shortCiteRegEx": "London et al\\.", "year": 1968}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask", "author": ["R Bulletin Collobert", "J Weston"], "venue": null, "citeRegEx": "Collobert and Weston,? \\Q2008\\E", "shortCiteRegEx": "Collobert and Weston", "year": 2008}, {"title": "A computational approach to politeness with", "author": ["C Danescu-Niculescu-Mizil", "M Sudhof", "D Jurafsky", "J Leskovec", "C Potts"], "venue": null, "citeRegEx": "Danescu.Niculescu.Mizil et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Danescu.Niculescu.Mizil et al\\.", "year": 2013}, {"title": "The Association for Computer Linguistics, pp 250\u2013259", "author": ["A De Lucia", "F Fasano", "R Oliveto", "G Tortora"], "venue": "Ekman P", "citeRegEx": "Lucia et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Lucia et al\\.", "year": 1999}, {"title": "Liblinear: A library for large linear classification", "author": ["RE Fan", "KW Chang", "CJ Hsieh", "XR Wang", "CJ Lin"], "venue": "Trans Softw Eng Methodol", "citeRegEx": "Fan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2012}, {"title": "Exploring causes of frustration for software developers. In CHASE, pages 115\u2013116", "author": ["D Ford", "C Parnin"], "venue": null, "citeRegEx": "Ford and Parnin,? \\Q2015\\E", "shortCiteRegEx": "Ford and Parnin", "year": 2015}, {"title": "Unhappy Developers: Bad for Themselves, Bad for Process", "author": ["D NIER.2017.18 Graziotin", "F Fagerholm", "X Wang", "P Abrahamsson"], "venue": null, "citeRegEx": "Graziotin et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Graziotin et al\\.", "year": 2017}, {"title": "Towards emotional awareness in software development", "author": ["E Guzman", "B Bruegge"], "venue": "teams. In: Proceedings of the 2013", "citeRegEx": "Guzman and Bruegge,? \\Q2013\\E", "shortCiteRegEx": "Guzman and Bruegge", "year": 2013}, {"title": "Sentiment analysis of commit comments in Github: An empirical study", "author": ["E Guzman", "D Azocar", "Y Li"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "2016) A needle in a haystack: What do twitter users say about software", "author": ["E Guzman", "R Alkadhi", "N Seyff"], "venue": null, "citeRegEx": "Guzman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Guzman et al\\.", "year": 2016}, {"title": "Learning from Imbalanced Data", "author": ["H He", "EA Garcia"], "venue": "Engineering Conference (RE),", "citeRegEx": "He and Garcia,? \\Q2016\\E", "shortCiteRegEx": "He and Garcia", "year": 2016}, {"title": "Using rhetorical structure in sentiment analysis", "author": ["A Hogenboom", "F Frasincar", "F de Jong", "U Kaymak"], "venue": null, "citeRegEx": "Hogenboom et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hogenboom et al\\.", "year": 2015}, {"title": "Choosing your weapons: On sentiment analysis tools for software engineering", "author": ["R Jongeling", "S Datta", "A Serebrenik"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "A large- scale sentiment analysis for Yahoo! answers", "author": ["BB Cambazoglu", "I Weber", "H Ferhatosmanoglu"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Emotion and adaptation", "author": ["R Lazarus"], "venue": "PSYCHOLOGICAL", "citeRegEx": "Lazarus,? \\Q1991\\E", "shortCiteRegEx": "Lazarus", "year": 1991}, {"title": "On the automatic classification of app reviews", "author": ["Z Kurtanovic", "H Nabil", "C Stanik"], "venue": "Requirements Engineering", "citeRegEx": "Maalej et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Maalej et al\\.", "year": 2016}, {"title": "The Stanford CoreNLP natural language", "author": ["CD Manning", "M Surdeanu", "J Bauer", "J Finkel", "SJ Bethard", "D McClosky"], "venue": null, "citeRegEx": "Manning et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Mining valence, arousal, and dominance: Possibilities", "author": ["Demonstrations", "M pp 55\u201360 M\u00e4ntyl\u00e4", "B Adams", "G Destefanis", "D Graziotin", "M Ortu"], "venue": null, "citeRegEx": "Demonstrations et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Demonstrations et al\\.", "year": 2016}, {"title": "Bootstrapping a lexicon for emotional arousal in software", "author": ["MV M\u00e4ntyl\u00e4", "N Novielli", "F Lanubile", "M Claes", "M Kuutila"], "venue": null, "citeRegEx": "M\u00e4ntyl\u00e4 et al\\.,? \\Q2017\\E", "shortCiteRegEx": "M\u00e4ntyl\u00e4 et al\\.", "year": 2017}, {"title": "Efficient estimation of word representations in vector space", "author": ["T Mikolov", "K Chen", "G Corrado", "J Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2017}, {"title": "Distributed representations of words and phrases", "author": ["T Mikolov", "I Sutskever", "K Chen", "GS Corrado", "J Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "NRC-Canada: Building the state-of-the-art in sentiment analysis of tweets", "author": ["Measurement H (Ed) Emotion", "SM Elsevier Mohammad", "S Kiritchenko", "X Zhu"], "venue": null, "citeRegEx": "Emotion et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Emotion et al\\.", "year": 2013}, {"title": "Stuck and frustrated or in flow and happy: sensing developers' emotions and progress", "author": ["SC M\u00fcller", "T Fritz"], "venue": "CoRR abs/1308.6242,", "citeRegEx": "M\u00fcller and Fritz,? \\Q2015\\E", "shortCiteRegEx": "M\u00fcller and Fritz", "year": 2015}, {"title": "Towards discovering the role of emotions in Stack Overflow", "author": ["N Novielli", "F Calefato", "F Lanubile"], "venue": null, "citeRegEx": "Novielli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Novielli et al\\.", "year": 2014}, {"title": "The challenges of sentiment detection in the social programmer ecosystem", "author": ["F Calefato", "F Lanubile"], "venue": null, "citeRegEx": "Novielli et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Novielli et al\\.", "year": 2015}, {"title": "Are bullies more productive?: Empirical study", "author": ["M Ortu", "B Adams", "G Destefanis", "P Tourani", "M Marchesi", "R Tonelli"], "venue": null, "citeRegEx": "Ortu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ortu et al\\.", "year": 2015}, {"title": "Opinion mining and sentiment anal- ysis", "author": ["NY York"], "venue": "Found Trends Inf Retr 2(1-2):1\u2013135,", "citeRegEx": "York,? \\Q2008\\E", "shortCiteRegEx": "York", "year": 2008}, {"title": "Linguistic Inquiry and Word Count: LIWC", "author": ["J Evolution Pennebaker", "M Francis"], "venue": "Erlbaum Publishers,", "citeRegEx": "Pennebaker and Francis,? \\Q2001\\E", "shortCiteRegEx": "Pennebaker and Francis", "year": 2001}, {"title": "Recommending insightful comments for source code using crowdsourced", "author": ["MM Rahman", "CK Roy", "I Keivanloo"], "venue": null, "citeRegEx": "Rahman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rahman et al\\.", "year": 2015}, {"title": "A circumplex model of affect. Journal of personality and social psychology", "author": ["H Saif", "M Fernandez", "Y He", "H Alani"], "venue": "DOI 10.1109/SCAM.2015.7335404 Russell J", "citeRegEx": "Saif et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Saif et al\\.", "year": 2015}, {"title": "Emotions in everyday life: Probability of oc- currence, risk", "author": ["(ELRA) Association", "Reykjavik", "K Iceland Scherer", "T Wranik", "J Sangsue", "V Tran", "U Scherer"], "venue": null, "citeRegEx": "Association et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Association et al\\.", "year": 2004}, {"title": "Emotion knowledge: Further exploration of a prototype approach", "author": ["York NY", "P USA Shaver", "J Schwartz", "D Kirson", "C O\u2019Connor"], "venue": null, "citeRegEx": "NY et al\\.,? \\Q1987\\E", "shortCiteRegEx": "NY et al\\.", "year": 1987}, {"title": "Analyzing developer sentiment in commit logs", "author": ["V Sinha", "A Lazar", "B Sharif"], "venue": "Proceedings of the 13th International", "citeRegEx": "Sinha et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sinha et al\\.", "year": 2016}, {"title": "Recursive deep models for semantic", "author": ["R Socher", "A Perelygin", "J Wu", "J Chuang", "CD Manning", "AY Ng", "C Potts"], "venue": "Artificial Intelligence", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "The general inquirer: A computer approach to content analysis", "author": ["PJ 1083\u20131086 Stone", "DC Dunphy", "MS Smith", "DM Ogilvie"], "venue": null, "citeRegEx": "Stone et al\\.,? \\Q1966\\E", "shortCiteRegEx": "Stone et al\\.", "year": 1966}, {"title": "Sentiment strength detection for the social web", "author": ["Cambridge", "M MA: The MIT Press. Thelwall", "K Buckley", "G Paltoglou"], "venue": "J Am Soc Inf Sci Technol", "citeRegEx": "Cambridge et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cambridge et al\\.", "year": 2012}, {"title": "Sewordsim: Software-specific word similarity database", "author": ["Y Tian", "D Lo", "J Lawall"], "venue": "Companion Proceedings of the 36th", "citeRegEx": "Tian et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tian et al\\.", "year": 2014}, {"title": "Pattern-based emotion classification on social media", "author": ["E Tromp", "M Pechenizkiy"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}], "referenceMentions": [{"referenceID": 34, "context": "Recent studies suggest approaches for enhancing software development, maintenance, and evolution by applying sentiment analysis on Stack Overflow (Rahman et al. 2015), app reviews (Maalej et al.", "startOffset": 146, "endOffset": 166}, {"referenceID": 21, "context": "2015), app reviews (Maalej et al. 2016), and tweets containing comments on software applications (Guzman et al.", "startOffset": 19, "endOffset": 39}, {"referenceID": 15, "context": "2016), and tweets containing comments on software applications (Guzman et al. 2016).", "startOffset": 63, "endOffset": 83}, {"referenceID": 39, "context": "2015), empirical software engineering studies have exploited off-the-shelf sentiment analysis tools that have been trained on non-software engineering documents, such as movie reviews (Socher et al. 2013), or posts crawled from general-purpose social media, such as Twitter and YouTube (Thelwall et al.", "startOffset": 184, "endOffset": 204}, {"referenceID": 13, "context": "2014, Guzman and Bruegge 2013, Sinha et al.2016), Jira (M\u00e4ntyl\u00e4 et al. 2016, Ortu et al. 2015), and Stack Overflow (Calefato et al. 2015, Novielli et al. 2015). With a notable few exceptions (Blaz and Becker 2016, Panichella et al. 2015), empirical software engineering studies have exploited off-the-shelf sentiment analysis tools that have been trained on non-software engineering documents, such as movie reviews (Socher et al. 2013), or posts crawled from general-purpose social media, such as Twitter and YouTube (Thelwall et al. 2012). Jongeling et al. (2017) show how the choice of the sentiment analysis tool may impact the conclusion validity of empirical studies by performing a benchmarking study on seven datasets, including discussions and comments from Stack Overflow and issue trackers.", "startOffset": 6, "endOffset": 566}, {"referenceID": 4, "context": "We propose a sentiment analysis classifier, named Senti4SD, which exploits a suite of lexicon-based, keyword-based, and semantic features (Basile and Novielli 2015) for appropriately dealing with the domain-dependent use of a lexicon.", "startOffset": 138, "endOffset": 164}, {"referenceID": 26, "context": "Specifically, we used word2vec (Mikolov et al. 2013) to build a Distributional Semantic Model (DSM) where words are represented as high-dimensional vectors.", "startOffset": 31, "endOffset": 52}, {"referenceID": 22, "context": "It is particularly the case of bug reports or problem descriptions (Blaz and Becker 2016, Novielli et al. 2015). Novielli et al. (2015) show how sentences like \u201cWhat is the best way to kill a critical process\u201d or \u201cI am missing a parenthesis but I don\u2019t know where\u201d are erroneously classified as negative because both \u2018to kill\u2019 and \u2018missing\u2019 hold a negative polarity in the SentiStrength lexicon.", "startOffset": 90, "endOffset": 136}, {"referenceID": 20, "context": "Lazarus (1991) describes nine negative (anger, fright, anxiety, guilt, shame, sadness, envy, jealousy, and disgust) and seven positive (happiness, pride, relief, love, hope, compassion, and gratitude) emotions, with their appraisal patterns: positive emotions are triggered if the situation experienced is congruent with an individual goal, otherwise negative emotions are prompted.", "startOffset": 0, "endOffset": 15}, {"referenceID": 20, "context": "Lazarus (1991) describes nine negative (anger, fright, anxiety, guilt, shame, sadness, envy, jealousy, and disgust) and seven positive (happiness, pride, relief, love, hope, compassion, and gratitude) emotions, with their appraisal patterns: positive emotions are triggered if the situation experienced is congruent with an individual goal, otherwise negative emotions are prompted. Shaver et al. (1987) defined a tree-structured hierarchical classification of emotions.", "startOffset": 0, "endOffset": 404}, {"referenceID": 2, "context": "Such methods are usually referred in the literature as context-counting approaches (Baroni et al. 2014).", "startOffset": 83, "endOffset": 103}, {"referenceID": 2, "context": "For this reason, they are usually referred to as context-predicting approaches (Baroni et al. 2014).", "startOffset": 79, "endOffset": 99}, {"referenceID": 2, "context": "Furthermore, they outperform traditional context-counting approaches on standard lexical semantics benchmarks (Baroni et al. 2014).", "startOffset": 110, "endOffset": 130}, {"referenceID": 2, "context": "Such methods are usually referred in the literature as context-counting approaches (Baroni et al. 2014). Recently, neural network-based approaches have been proposed (Bengio et al. 2003, Collobert and Weston 2008, Mikolov et al. 2013a) for learning distributed representation of words as continuous vectors. These approaches, also known as word embedding (Levy and Goldberg 2014), learn the vectors that maximize the probability of the contexts in which the target word appears. For this reason, they are usually referred to as context-predicting approaches (Baroni et al. 2014). In our study, we leverage the approach defined by Milokov et al. (2013). They developed two models for implementing context-predicting approaches: (1) the Continuous Bag-of-Words (CBOW) model predicts the target word by considering the previous and following n words in a symmetrical context window; (2) the Skip-gram model predicts the surrounding words based on the target word.", "startOffset": 84, "endOffset": 652}, {"referenceID": 30, "context": "In a previous study (Novielli et al. 2015), we found that stronger expressions of emotions are usually detected in comments rather than in question or answers.", "startOffset": 20, "endOffset": 42}, {"referenceID": 40, "context": "Furthermore, it incorporates sentiment scores from other linguistic resources that were previously validated in the scope of empirical research in sentiment analysis (Stone et al., 1966) and psycholinguistics (Pennebaker and Francis, 2001).", "startOffset": 166, "endOffset": 186}, {"referenceID": 33, "context": ", 1966) and psycholinguistics (Pennebaker and Francis, 2001).", "startOffset": 30, "endOffset": 60}, {"referenceID": 4, "context": "Other than including n-grams, we designed features able to capture aspects of micro-blogging, such as the use of uppercase and elongated words used as intensifiers, the presence of positive and negative emoticons, and the occurrence of slang expression of laughter (Basile and Novielli 2015).", "startOffset": 265, "endOffset": 291}, {"referenceID": 26, "context": "The semantic features are computed on a DSM built on Stack Overflow data, using the CBOW architecture implemented by word2vec (Mikolov et al. 2013), as depicted in Fig.", "startOffset": 126, "endOffset": 147}, {"referenceID": 22, "context": "Before extracting all features, we performed tokenization using the Stanford NLP suite (Manning et al. 2014).", "startOffset": 87, "endOffset": 108}, {"referenceID": 26, "context": "defined by the sample input parameter) are down-sampled to increase the effective context window considered for vector prediction (Mikolov et al. 2013).", "startOffset": 130, "endOffset": 151}, {"referenceID": 4, "context": "Consistently with previous research (Basile and Novielli 2015), we maintained the default Fig.", "startOffset": 36, "endOffset": 62}, {"referenceID": 30, "context": "The performance of SentiStrength on our test set (see TABLES 8 and 9) confirms previous findings about its negative bias in the software engineering domain (Novielli et al. 2015).", "startOffset": 156, "endOffset": 178}, {"referenceID": 11, "context": ", learning a new language or solving tasks with high reasoning complexity) (Ford and Parnin, 2015), as well as in their daily programming tasks (M\u00fcller and Fritz 2015).", "startOffset": 75, "endOffset": 98}, {"referenceID": 28, "context": ", learning a new language or solving tasks with high reasoning complexity) (Ford and Parnin, 2015), as well as in their daily programming tasks (M\u00fcller and Fritz 2015).", "startOffset": 144, "endOffset": 167}, {"referenceID": 10, "context": "(Denning 2012, Ford and Parnin, 2015, Graziotin et al. 2017). When implementing a sentiment classifier, deciding whether to optimize by precision or by recall is not a trivial decision, which depends on the application scenario. Early detection of negative sentiment towards self, such as frustration, could be useful to design tools for supporting developers experiencing cognitive difficulties (i.e., learning a new language or solving tasks with high reasoning complexity) (Ford and Parnin, 2015), as well as in their daily programming tasks (M\u00fcller and Fritz 2015). In such a scenario, a monitoring tool might suggest the intervention of an expert or provide a link to further material and documentation to support the developer. However, a sentiment analysis tool with high recall and low precision for negative sentiment as SentiStrength would produce several false positives, causing undesired, erroneous interruptions that are detrimental to developers' productivity and focus. In such cases, being able to reduce the number of false positives for negative sentiment becomes crucial and Senti4SD should be preferred to SentiStrength, due to its higher precision. Similarly, timely detection of negative sentiment towards peers, such as anger and hostility (Gachechiladze et al 2017), might be exploited for detecting code of conduct violations (Tromp and Pechenizkiy 2015) or enhancing effective community management. For example, sentiment analysis may support GitHub users who want to be notified of heated conversation and lock them before flame wars break out. In scenarios that involve human intervention to guide the contributors\u2019 behavior towards a constructive pattern, it might be desirable to optimize negative sentiment detection by recall, thus choosing to leverage SentiStrength higher sensitivity to negative emotions. Conversely, if automatic filtering of offensive comments or conversation is envisaged, it becomes important to optimize by precision by using Senti4SD, to avoid banning neutral conversations. Finally, sentiment analysis is now regarded as a technique also useful for mining large software repositories, e.g., to understand the role of sentiment in security discussions (Pletea et al. 2014) and commits in GitHub (Guzman et al. 2014). In such scenarios, a sentiment classifier specifically trained and validated in the software engineering domain allows controlling for threats to validity due to inappropriate instrumentation, as argued by Jongeling et al (2017). Contribution of features.", "startOffset": 15, "endOffset": 2504}, {"referenceID": 30, "context": "Being able to identify harsh comments towards technical matters could be useful in detecting particularly challenging questions that have not been exhaustively answered (Novielli et al. 2015), which is a goal addressed by current research on effective knowledge-sharing (Anderson et al.", "startOffset": 169, "endOffset": 191}, {"referenceID": 0, "context": "2015), which is a goal addressed by current research on effective knowledge-sharing (Anderson et al. 2012).", "startOffset": 84, "endOffset": 106}, {"referenceID": 0, "context": "2015), which is a goal addressed by current research on effective knowledge-sharing (Anderson et al. 2012). Similarly, detecting negative attitude towards the interlocutor could allow the community moderators to guide users towards appropriate interaction patterns. This is an open problem in the Stack Overflow community, as users complain about harsh comments coming from expert contributors (Meta 2017), which may impair successful question-answering (Asaduzzaman et al. 2013). The release of our gold standard complements the effort of Ortu et al. (2016) who recently released a dataset of 2,000 issue comments and 4,000 sentences written by developers, collected by mining the repositories of four open source ecosystems, namely Apache, Spring, JBoss, and CodeHaus.", "startOffset": 85, "endOffset": 559}, {"referenceID": 0, "context": "2015), which is a goal addressed by current research on effective knowledge-sharing (Anderson et al. 2012). Similarly, detecting negative attitude towards the interlocutor could allow the community moderators to guide users towards appropriate interaction patterns. This is an open problem in the Stack Overflow community, as users complain about harsh comments coming from expert contributors (Meta 2017), which may impair successful question-answering (Asaduzzaman et al. 2013). The release of our gold standard complements the effort of Ortu et al. (2016) who recently released a dataset of 2,000 issue comments and 4,000 sentences written by developers, collected by mining the repositories of four open source ecosystems, namely Apache, Spring, JBoss, and CodeHaus. Their dataset is annotated using the basic emotion labels in the framework by Shaver et al. (1987) that we also adopt in the present study.", "startOffset": 85, "endOffset": 870}, {"referenceID": 8, "context": "Their approach exploits SVM using a suite of features based on the SentiStrength output, the politeness score (Danescu-Niculescu-Mizil et al. 2013), and the presence of affective words derived from WordNetAffect (Strapparava and Valitutti 2004).", "startOffset": 110, "endOffset": 147}, {"referenceID": 23, "context": "M\u00e4ntyl\u00e4 et al. (2016) investigated the potential of mining developers\u2019 emotions in issue-tracking systems to prevent loss of productivity and burnout.", "startOffset": 0, "endOffset": 22}, {"referenceID": 23, "context": "M\u00e4ntyl\u00e4 et al. (2016) investigated the potential of mining developers\u2019 emotions in issue-tracking systems to prevent loss of productivity and burnout. They measured the emotions in issue comments in terms of VAD metrics, that is, scores for the Valence (i.e., the affect polarity), Arousal (i.e., the affect intensity), and Dominance (i.e., the sensation of being in control of a situation). To estimate VAD scores, they adopted the same lexicon-based approach implemented by SentiStrength, using a VAD lexicon of over 13K English words developed by psychology research. However, given the lack of a gold standard for VAD, they were not able to provide any evaluation of their approach to emotion mining. Ortu et al. (2015) presented an empirical study on the correlation of emotions and issue-fixing time in the Apache issuetracking system.", "startOffset": 0, "endOffset": 724}, {"referenceID": 23, "context": "M\u00e4ntyl\u00e4 et al. (2016) investigated the potential of mining developers\u2019 emotions in issue-tracking systems to prevent loss of productivity and burnout. They measured the emotions in issue comments in terms of VAD metrics, that is, scores for the Valence (i.e., the affect polarity), Arousal (i.e., the affect intensity), and Dominance (i.e., the sensation of being in control of a situation). To estimate VAD scores, they adopted the same lexicon-based approach implemented by SentiStrength, using a VAD lexicon of over 13K English words developed by psychology research. However, given the lack of a gold standard for VAD, they were not able to provide any evaluation of their approach to emotion mining. Ortu et al. (2015) presented an empirical study on the correlation of emotions and issue-fixing time in the Apache issuetracking system. They measure the emotion polarity in issue comments using SentiStrength. As for discrete emotion labels, they developed their own classifier for detecting the presence of four basic emotions framework by the Shaver et al. (1987), namely anger, joy, sadness, and love.", "startOffset": 0, "endOffset": 1071}, {"referenceID": 8, "context": "Their approach exploits SVM using a suite of features based on the SentiStrength output, the politeness score (Danescu-Niculescu-Mizil et al. 2013), and the presence of affective words derived from WordNetAffect (Strapparava and Valitutti 2004). The classifier is evaluated on a gold standard of 4,000 sentences, obtaining an F-measure score ranging from .74 for anger to .82 for sadness. At the time of writing, the classifier is not yet available for research purposes. Blaz and Becker (2016) developed a polarity classifier for IT tickets.", "startOffset": 111, "endOffset": 495}, {"referenceID": 4, "context": ", for unsupervised speech-act recognition in telephone conversations (Novielli and Strapparava 2013) and for sentiment analysis in micro-blogging (Basile and Novielli 2015).", "startOffset": 146, "endOffset": 172}, {"referenceID": 3, "context": "Traditional, contextcounting approaches to distributional semantics have already been used, including Latent Dirichlet Allocation for topic modeling in Stack Overflow (Barua et al. 2014) and Latent Semantic Analysis for recovering traceability links in software artifact (De Lucia et al.", "startOffset": 167, "endOffset": 186}, {"referenceID": 2, "context": "Traditional, contextcounting approaches to distributional semantics have already been used, including Latent Dirichlet Allocation for topic modeling in Stack Overflow (Barua et al. 2014) and Latent Semantic Analysis for recovering traceability links in software artifact (De Lucia et al. 2007). Tian et al. (2014) recently proposed the use of pointwise mutual information to represents word similarity in a high-dimensional space.", "startOffset": 168, "endOffset": 314}, {"referenceID": 2, "context": "2013a) \u2013 and provides more effective vector representation of words (Baroni et al. 2014, Mikolov et al. 2013b). Thus, in our study, we adopt word embedding for building our distributional semantic model. Ye et al. (2016) already exploited word embedding for enhancing information retrieval in software engineering.", "startOffset": 69, "endOffset": 221}], "year": 2017, "abstractText": "The role of sentiment analysis is increasingly emerging to study software developers\u2019 emotions by mining crowdgenerated content within social software engineering tools. However, off-the-shelf sentiment analysis tools have been trained on non-technical domains and general-purpose social media, thus resulting in misclassifications of technical jargon and problem reports. Here, we present Senti4SD, a classifier specifically trained to support sentiment analysis in developers\u2019 communication channels. Senti4SD is trained and validated using a gold standard of Stack Overflow questions, answers, and comments manually annotated for sentiment polarity. It exploits a suite of both lexiconand keyword-based features, as well as semantic features based on word embedding. With respect to a mainstream off-the-shelf tool, which we use as a baseline, Senti4SD reduces the misclassifications of neutral and positive posts as emotionally negative. To encourage replications, we release a lab package including the classifier, the word embedding space, and the gold standard with annotation guidelines.", "creator": "Word"}}}