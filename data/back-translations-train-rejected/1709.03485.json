{"id": "1709.03485", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Sep-2017", "title": "NiftyNet: a deep-learning platform for medical imaging", "abstract": "Medical image analysis and computer-assisted intervention problems are increasingly being addressed with deep-learning-based solutions. This has resulted is substantial duplication of effort and incompatible infrastructure across many research groups. This work presents the open-source NiftyNet platform for deep learning in medical imaging. The ambition of NiftyNet is to accelerate and simplify the development of these solutions, and to provide a common mechanism for disseminating research outputs for the community to use, adapt and build upon. This TensorFlow-based infrastructure provides a complete modular deep learning pipeline for a range of medical imaging applications including segmentation, regression, image generation and representation learning applications with data loading, data augmentation, network architectures, loss functions and evaluation metrics that are tailored to, and take advantage of, the idiosyncracies of medical image analysis and computer-assisted interventions.", "histories": [["v1", "Mon, 11 Sep 2017 17:42:10 GMT  (1370kb,D)", "http://arxiv.org/abs/1709.03485v1", "Wenqi Li and Eli Gibson contributed equally to this work. 22 pages, 4 figures"], ["v2", "Mon, 16 Oct 2017 13:46:31 GMT  (1599kb,D)", "http://arxiv.org/abs/1709.03485v2", "Wenqi Li and Eli Gibson contributed equally to this work. M. Jorge Cardoso and Tom Vercauteren contributed equally to this work. 26 pages, 6 figures; Update includes additional applications, updated author list and formatting for journal submission"]], "COMMENTS": "Wenqi Li and Eli Gibson contributed equally to this work. 22 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["eli gibson", "wenqi li", "carole sudre", "lucas fidon", "dzoshkun shakir", "guotai wang", "zach eaton-rosen", "robert gray", "tom doel", "yipeng hu", "tom whyntie", "parashkev nachev", "dean c barratt", "s\\'ebastien ourselin", "m jorge cardoso", "tom vercauteren"], "accepted": false, "id": "1709.03485"}, "pdf": {"name": "1709.03485.pdf", "metadata": {"source": "CRF", "title": "NiftyNet: a deep-learning platform for medical imaging", "authors": ["Eli Gibson", "Wenqi Lia", "Carole Sudre", "Lucas Fidon", "Dzoshkun Shakir", "Guotai Wang", "Zach Eaton-Rosen", "Robert Gray", "Tom Doel", "Yipeng Hu", "Tom Whyntie", "Parashkev Nachev", "Dean C. Barratt", "S\u00e9bastien Ourselin", "M. Jorge Cardoso", "Tom Vercauteren"], "emails": ["wenqi.li@ucl.ac.uk"], "sections": [{"heading": null, "text": "Medical imaging analysis and computerized intervention problems are increasingly being addressed with deep learning-based solutions, resulting in significant duplication of effort and incompatible infrastructure across many research groups. NiftyNet's open source platform for deep learning in medical imaging, NiftyNet, aims to accelerate and simplify the development of these solutions and provide a shared mechanism for disseminating research results to the community to use, adapt and build on. NiftyNet's TensorFlow-based infrastructure provides a complete modular deep learning pipeline for a range of medical imaging applications, including segmentation, regression, image generation and imaging learning applications with data loading, data augmentation, network architectures, loss capabilities, and evaluation metrics tailored to and leveraging the specifics of medical imaging applications."}, {"heading": "1. Introduction", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "2. Background", "text": "Early efforts included the development of medical image processing file formats (e.g. ACR-NEMA (1985), Analyze 7.5 (1986), DICOM (1992) MINC (1992), and NIfTI (2001)). Tools to solve common challenges such as registration (e.g. NiftyReg et al., 2010), ANTs (Avants et al., 2011) and elastix (Klein et al., 2010), segmentation (e.g. NiftySeg et al., 2012), and biomechanical modeling (e.g. Johnsen et al., 2015) are available for use as part of image analysis. Pipelines for specific research applications such as FSL (Smith et al., 2004) for functional MRI analysis and freesurfer (Fischl al., 1999)."}, {"heading": "3. Typical deep learning pipeline", "text": "Deep learning takes over the typical machine learning pipeline, which consists of three phases: model selection (selecting and adapting a model to training data), model evaluation (measuring model performance based on test data), and model distribution (sharing the model with a wider population).Within these simple phases, there is considerable complexity, as shown in Figure 1. The most obvious complexity lies in the implementation of the network under investigation. Deep-neural networks generally use simple functions, but combine them into complex hierarchies; researchers must implement the network under test as well as previous networks (often incompletely specified) for comparison. However, further infrastructure is needed to train, evaluate, and distribute these networks. Data sets must be correctly isolated to avoid biassoric evaluations, taking into account sometimes complex data correlations, and the data must be scanned, loaded, and passed on to the network in different ways, depending on the phase of the pipeline."}, {"heading": "4. Design considerations for deep learning in medical imaging", "text": "Medical image analysis differs from other areas where deep learning is applied due to the characteristics of the data itself and the applications in which it is used. In this section, we present the domain-specific requirements that drive the design of NiftyNet."}, {"heading": "4.1. Data availability", "text": "Capturing, annotating, and distributing medical imaging data comes at a higher cost than many computer imaging tasks, and for many medical imaging modalities, creating an image is costly. Commenting images for many applications requires a high level of expertise from physicians with limited time. Furthermore, sharing data between institutions, let alone internationally, is logistically and legally difficult. Although current tools such as DeepIGeoS (Wang et al., 2017b) for semi-automatic annotation and GIFT Cloud (Doel et al., 2017) for data sharing are beginning to break down these barriers, typical datasets remain small. Using smaller datasets increases the importance of data extraction, regulation, and cross-validation to prevent overmatching."}, {"heading": "4.2. Data dimensionality and size", "text": "Many medical images, including MRI, CT, PET and SPECT, capture volumetric images. Longitudinal (multiple images taken over time) images are typical of interventional environments and are clinically useful for measuring organ function (e.g. blood ejection fraction in cardiac imaging) and disease progression (e.g. cortical dilution in neurodegenerative diseases), while capturing high-resolution data in multiple dimensions is often necessary to detect small but clinically important anatomy and pathology, and the combination of these factors results in large data sizes for each sample that affect computer and storage costs. To meet this challenge, various strategies are used in many networks. Many networks are designed to use partial images: 2D sections sampled along an axis of 3D images (multiple Zhou et al, 2016), 3D subvolumes (al, Li et, 2017, Wang 7b, conmalization)."}, {"heading": "4.3. Data formatting", "text": "To support the higher dimensions of medical image data, special formats have been introduced (e.g. DICOM, NIfTI, Analyze) that often also store metadata that is critical for image interpretation, including spatial information (anatomical orientation and voxel anisotropy), patient information (demographics and identifiers), and capture information (modality types and scanner parameters).These medical imaging-specific data formats are generally not supported by existing deep learning frameworks that require a custom infrastructure to load images."}, {"heading": "4.4. Data properties", "text": "Medical images are obtained under controlled conditions, enabling more predictable data distribution. In many modalities, images are calibrated so that spatial relationships and image intensities are mapped directly to physical quantities and are inherently normalized between subjects. In a given clinical workflow, the image content is typically consistent, potentially allowing the characterization of plausible intensity and spatial variations for data expansion. However, some clinical applications present additional challenges. As small image features can be of great clinical importance and some pathology is very rare but life-threatening, medical image analysis must deal with large class imbalances that motivate specialized loss functions and segregation metrics (e.g. metric assessment)."}, {"heading": "5. NiftyNet: a platform for deep learning in medical imaging", "text": "The NiftyNet platform aims to expand the current deep learning infrastructure to address the ideosyncracies of medical imaging described in Section 4 and lower the barrier to adoption of this technology in medical imaging applications. NiftyNet is based on the TensorFlow library, which provides the tools to define computational pipelines and efficiently execute them on hardware resources, but does not provide specific functionality for processing medical images or high-level interfaces for common medical image analysis tasks. NiftyNet provides a high-level deep learning pipeline with components optimized for medical imaging applications (data loading, sampling and augmentation, networks, loss functions, evaluations and a model zoo) and specific interfaces for medical image segmentation, classification, regression, imaging and learning applications."}, {"heading": "5.1. Design goals", "text": "The design of NiftyNet follows several key principles that support a number of key requirements: \u2022 enable research in one aspect of the deep learning pipeline without the need to recreate the other parts; \u2022 be easy to use for common use cases but flexible enough for complex use cases; \u2022 support built-in TensorFlow functions (parallel processing, visualization) by default; \u2022 support best practices (data expansion, record separation) by default; \u2022 support model distribution and customization."}, {"heading": "5.2. System overview", "text": "The NiftyNet Application Driver defines the common structure of all applications and is responsible for instantiating the data analysis pipeline and distributing the calculation across the available computing resources. The NiftyNet Application classes encapsulate standard analysis pipelines for various medical image analysis applications by connecting four components: a reader to load data from files, a sampler to generate suitable samples for processing, a network to process the input, and an output handler (consisting of the loss and optimizer during training and an aggregator during inference and evaluation).The sampler includes subcomponents for data augmentation. The network includes sub-components representing individual network blocks or larger conceptual units. These components are detailed in the following sections. As a concrete illustration, an instantiation of the segmentation application could use the following modules."}, {"heading": "5.2.1. Component details: ApplicationDriver class", "text": "The NiftyNet ApplicationDriver defines the common structure for all NiftyNet pipelines. It is responsible for instantiating the data and application objects and distributing the workload across all computing resources (possibly including multiple CPUs and GPUs), as well as handling variable initialization, variable storage, and recovery and logging. Implemented as a template design pattern (Gamma et al., 1994), the ApplicationDriver delegates application-specific functionality for separating application classes. The ApplicationDriver can be configured from the command line or programmatically using a human-readable configuration file. This file contains the definitions of the data sets and any settings that differ from the errors. When the ApplicationDriver stores its progress, the complete configuration (including default parameters) is also stored so that the analysis pipeline can be restored to perform a training or sharing model."}, {"heading": "5.2.2. Component details: Application class", "text": "Medical image analysis covers a wide range of tasks for different parts of the preclinical and clinical workflow: segmentation, classification, recognition, registration, reconstruction, enhancement, model representation and generation. Different applications use different types of inputs and outputs, different networks and different evaluation metrics; however, there is a common structure and functionality between these applications supported by NiftyNet. NiftyNet currently supports \u2022 image segmentation, \u2022 image regression, \u2022 image representation (via auto-encoder applications) and \u2022 image generation (via auto-encoder and generative adaptive networks), and it is modular designed to support the addition of new application types by encapsulating typical application workflows into application classes. The application class defines the required data interface for the network and loss, facilitating the instantiation of suitable network types by connecting the network sampler and the application to specify the output, the network weight, the mobile phone sampler and the application."}, {"heading": "5.2.3. Component details: Networks and Layers", "text": "The complex composition of simple functions that make up a deep learning architecture is simplified in typical networks by the repeated reuse of conceptual blocks. In NiftyNet, these conceptual blocks can be represented by encapsulated layer classes or inline with TensorFlow's scoping system. Composite layers and even entire networks can be constructed as simple compositions of NiftyNet layers and TensorFlow operations. This supports the reuse of existing networks by clearly delimiting conceptual code blocks that can be reused and assigning names to corresponding sets of variables that can be reused in other networks (see Section 5.2.8 for details). This also enables automatic support for visualization of the network graph as a hierarchy at different levels of detail using the TensorBoard visualizer (Mane \u0301 et al., 2015), as shown in Figure 2."}, {"heading": "5.2.4. Component details: data loading", "text": "For simple use, NiftyNet can automatically identify corresponding images in a dataset by searching a specific file path and matching user-specific patterns into filenames, but it also allows explicitly comma-separated value files for more complex dataset structures (e.g. cross-validation studies). Medical file input and output is already supported in several existing Python libraries, although each library supports different format sets. To provide a wide range of formats, NiftyNet uses nibabel (Brett et al., 2016) as its core dependency, but can rely on other libraries (e.g. SimpleITK (Lowekamp et al., 2013) if they are installed and a file format is not supported by nibabel."}, {"heading": "5.2.5. Component details: Samplers and output handlers", "text": "To handle the breadth of applications in medical image analysis and computerized interventions, NiftyNet offers flexibility in mapping from an input data set to data packets that need to be processed, and from the data processed to useful results, the former being encapsulated in sampler classes, and the latter being encapsulated in output handlers. Because sampling and output handling are closely linked and depend on the action performed (i.e. training, inference, or evaluation), the instantiation of appropriate samplers and output handlers is delegated to the application class. Samplers generate a sequence of packets with appropriate data for processing. Each package contains all the data needed for an independent compilation (e.g. one step of descent during training), including images, labels, classifications, notes, or other data needed for processing."}, {"heading": "5.2.6. Component details: data normalization and augmentation", "text": "Data normalization and augmentation are two approaches to compensate for small training datasets in medical image analysis, where the training dataset is too sparse to represent variability in image distribution. Data augmentation reduces data set variability by transforming input in such a way that it exhibits certain invariant characteristics, such as fixed intensity histograms or moments (mean and variance).Data augmentation artificially increases the variability of the training dataset by introducing random perturbations during training, such as random spatial transformations or adding random image noise. In NiftyNet, data augmentation and normalization are implemented as level classes applied in the sampler, as plausible data transformations vary depending on the application. Some of these layers, such as histonormalization of histogram, are currently dependent on the rotation data layers and flip data calculators, before the program starts."}, {"heading": "5.2.7. Component details: data evaluation", "text": "The summary and comparison of the performance of image analysis pipelines are typically based on standardized descriptive metrics and error metrics as surrogates for performance. As individual metrics are sensitive to different aspects of performance, several metrics are reported together. Reference implementations of these metrics reduce the implementation burden and avoid implementation inconsistencies. NiftyNet currently supports the calculation of descriptive and error metrics for segmentation. Descriptive statistics include spatial metrics (e.g. volume, surface / volume ratio, compactness) and intensity metrics (e.g. mean, quartile, skew of intensity). Error metrics compressed in reference segmentation include overlap metrics (cubes and Jaccard values; vox sensitivity, specificity, and house averages, and house averages)."}, {"heading": "5.2.8. Component details: model zoo for network reusability", "text": "To support the reuse of network architectures and trained models, many deep-learning platforms support a database of existing networks with trained and untrained network features in a standardized format known as a model zoo. Trained networks can be used directly (as part of a workflow or for performance comparisons) \u2022 fine-tuned for different data distributions (e.g. images of another hospital) or to initialize networks for other applications (i.e. transfer learning).Trained networks or conceptual blocks can be used within new networks.NiftyNet provides multiple mechanisms to support the distribution and reuse of networks and conceptual blocks.Trained NiftyNet networks can be directly restored with configuration options.Trained networks developed outside of NiftyNet can be adapted to NiftyNet by encapsulating the network within a network class derived from TrainleLayer. Extended weights can be reloaded from within a NiftyNet."}, {"heading": "5.3. Platform processes", "text": "In addition to implementing shared functionality, NiftyNet development has implemented good software development processes to support the ease of use, robustness, and longevity of the platform, as well as the creation of a vibrant community. NiftyNet supports easy installation using the niftynet pip installation command, and provides multiple analysis pipelines directly via command line interfaces. Examples demonstrating the platform in multiple use cases are included in the repository to lower the learning curve. NiftyNet repository uses continuous integration with a database of system and unit tests to mitigate the risks of errors and code-breaking changes. NiftyNet releases will follow the semantic versioning 2.0 standard (Preston-Werner, 2015) to ensure clear communication on backward compatibility."}, {"heading": "6. Illustrative applications and results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1. Abdominal organ segmentation", "text": "Segmentation of anatomy and pathology on medical images can support image-driven interventional workflows by allowing visualization of hidden anatomy and pathology during surgical navigation. This example, based on a simplified version of (Gibson et al., 2017a), illustrates the use of NiftyNet to segment a dense V network segmentation network that is important for pancreatobiliary interventions: the gastrointestinal tract (esophagus, stomach, and duodenum), the pancreas, and anatomical boundary organs (liver, left kidney, spleen, and stomach).The data used to train the network included 90 abdominal CT scans with manual segmentation from two publicly available datasets (Landman et al., 2015; Roth et al., 2016), with additional manual segmentation performed in our center."}, {"heading": "6.2. Ultrasound simulation using generative adversarial networks", "text": "Conditional GANs have shown promising results for generating plausible photographic images. (Mirza and Osindero, 2014) Recent work on spatial GANs (Hu et al., 2017) suggests that conditional GANs, rather than costly physical ultrasonic phantoms used for training, could provide software-based simulation, illustrating the porting of a pre-formed ultrasonic simulation network to NiftyNet for inclusion in the NiftyNet model zoo. Originally, the network was trained outside the NiftyNet platform, as described in (Hu et al., 2017). In short, a conditional GAN network was trained to produce ultrasonic images of specific views of a fetal phantom, using 26,000 frames of ultrasonic parameter analysis."}, {"heading": "7. Platform availability", "text": "The NiftyNet platform is available at http: / / niftynet.io /. Source code can be retrieved from the Git repository or installed as a Python library using pip install niftynet. NiftyNet is licensed under an open source Apache 2.0 license (https: / / www.apache.org / licenses / LICENSE-2.0), and the NiftyNet consortium welcomes contributions to the platform and is seeking new community members to join the consortium."}, {"heading": "8. Future direction", "text": "The active NiftyNet development roadmap focuses on three key areas: new application types, a larger model zoo, and more advanced experimental design. NiftyNet currently supports image segmentation, regression, generation, and representative learning applications. Future applications under development include image classification, registration, and enhancement (e.g. high-resolution), as well as pathological detection. The current NiftyNet model zoo contains a small number of models to demonstrate the principle; expanding the model zoo to include state-of-the-art models for common tasks and public challenges (e.g. brain tumor segmentation (BRaTS) (Menze et al., 2015; Wang et al., 2017a)); and models trained on large datasets for transfer learning will be critical to accelerating research with NiftyNet. Finally, NiftyNet currently supports a simplified machine learning pipeline that trains a single network of models, but for selecting and partioners."}, {"heading": "9. Summary of contributions/conclusions", "text": "This paper presents the open source NiftyNet platform for deep learning in medical imaging. Our modular implementation of the typical machine imaging learning pipeline enables researchers to focus on their specific innovations while leveraging the work of others for the remaining pipeline. NiftyNet platform provides implementations for data loading, data expansion, network architectures, loss capabilities and evaluation metrics tailored to the specifics of medical image analysis and computational interventions, enabling researchers to quickly develop deep learning solutions for segmentation, regression, image generation and learning applications for imaging or expand the platform to new applications."}, {"heading": "Acknowledgements", "text": "The authors would like to express their appreciation to all who have contributed to the NiftyNet platform, which has been developed by Wellcome / EPSRC [203145Z / 16 / Z, WT101957, NS / A000027 / 1]; Wellcome [106882 / Z / 15 / Z, WT103709]; the Department of Health and Wellcome Trust [HICF-T4-275, WT 97914]; EPSRC [EP / M020533 / 1, EP / K503745 / 1, EP / L016478 / 1]; the National Institute for Health Research University College London Hospitals Biomedical Research Centre (NIHR BRC UCLH / UCL High Impact Initiative); Cancer Research UK (CRUK) [C28070 / A19985]; the Royal Society [RG160569]; a UCL Overseas Research Scholarship and a UCL Graduate Research Scholarship."}], "references": [{"title": "TensorFlow: Large-scale machine learning on heterogeneous distributed systems. White paper arXiv:1603.04467v2", "author": ["V. Vasudevan", "F. Viegas", "O. Vinyals", "P. Warden", "M. Wattenberg", "M. Wicke", "Y. Yu", "X. Zheng"], "venue": null, "citeRegEx": "Vasudevan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Vasudevan et al\\.", "year": 2016}, {"title": "A reproducible evaluation of ANTs similarity metric performance in brain image registration", "author": ["B.B. Avants", "N.J. Tustison", "G. Song", "P.A. Cook", "A. Klein", "J.C. Gee"], "venue": null, "citeRegEx": "Avants et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Avants et al\\.", "year": 2011}, {"title": "2016. Layer normalization arXiv:1607.06450v1", "author": ["J.L. Ba", "J.R. Kiros", "G.E. Hinton"], "venue": null, "citeRegEx": "Ba et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ba et al\\.", "year": 2016}, {"title": "Theano: new features and speed improvements; 2012, in: Proceedings of Deep Learning and Unsupervised Feature Learning NIPS\u201912 Workshop", "author": ["F. Bastien", "P. Lamblin", "R. Pascanu", "J. Bergstra", "I.J. Goodfellow", "A. Bergeron", "N. Bouchard", "Y. Bengio"], "venue": null, "citeRegEx": "Bastien et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bastien et al\\.", "year": 2012}, {"title": "NiftySeg: opensource software for medical image segmentation, label fusion and cortical thickness estimation, in: ISBI Workshop on Open Source Medical Image Analysis Software", "author": ["M. Cardoso", "M. Clarkson", "M. Modat", "S. Ourselin"], "venue": null, "citeRegEx": "Cardoso et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cardoso et al\\.", "year": 2012}, {"title": "cuDNN: Efficient primitives for deep learning arXiv:1410.0759v3", "author": ["S. Chetlur", "C. Woolley", "P. Vandermersch", "J. Cohen", "J. Tran", "B. Catanzaro", "E. Shelhamer"], "venue": null, "citeRegEx": "Chetlur et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chetlur et al\\.", "year": 2014}, {"title": "3D U-net: learning dense volumetric segmentation from sparse annotation, in: MICCAI", "author": ["\u00d6. \u00c7i\u00e7ek", "A. Abdulkadir", "S.S. Lienkamp", "T. Brox", "O. Ronneberger"], "venue": null, "citeRegEx": "\u00c7i\u00e7ek et al\\.,? \\Q2016\\E", "shortCiteRegEx": "\u00c7i\u00e7ek et al\\.", "year": 2016}, {"title": "The NifTK software platform for image-guided interventions: platform overview and NiftyLink messaging. nternational", "author": ["M.J. Clarkson", "G. Zombori", "S. Thompson", "J. Totz", "Y. Song", "M. Espak", "S. Johnsen", "D. Hawkes", "S. Ourselin"], "venue": "Journal for Computer Assisted Radiology and Surgery", "citeRegEx": "Clarkson et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Clarkson et al\\.", "year": 2015}, {"title": "Torch7: A MATLAB-like environment for machine learning, in: Proceedings of Big Learning 2011: NIPS\u201911", "author": ["R. Collobert", "K. Kavukcuoglu", "C. Farabet"], "venue": "Workshop on Algorithms,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Cortical surface-based analysis: I. segmentation and surface reconstruction", "author": ["A.M. Dale", "B. Fischl", "M.I. Sereno"], "venue": null, "citeRegEx": "Dale et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Dale et al\\.", "year": 1999}, {"title": "Gift-cloud: A data sharing and collaboration platform for medical imaging research", "author": ["T. Doel", "D.I. Shakir", "R. Pratt", "M. Aertsen", "J. Moggridge", "E. Bellon", "A.L. David", "J. Deprest", "T. Vercauteren", "S. Ourselin"], "venue": "Computer Methods and Programs in Biomedicine", "citeRegEx": "Doel et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Doel et al\\.", "year": 2017}, {"title": "TensorLayer: A versatile library for efficient deep learning development", "author": ["H. Dong", "A. Supratak", "L. Mai", "F. Liu", "A. Oehmichen", "S. Yu", "Y. Guo"], "venue": "ACM Multimedia URL: http://tensorlayer.org", "citeRegEx": "Dong et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Dong et al\\.", "year": 2017}, {"title": "Generalised Wasserstein Dice score for imbalanced multi-class segmentation using holistic convolutional networks. Preprint arXiv:1707.00478", "author": ["L. Fidon", "W. Li", "L.C. Garcia-Peraza-Herrera", "J. Ekanayake", "N. Kitchen", "S. Ourselin", "T. Vercauteren"], "venue": null, "citeRegEx": "Fidon et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Fidon et al\\.", "year": 2017}, {"title": "Cortical surface-based analysis: II: inflation, flattening, and a surface-based coordinate system", "author": ["B. Fischl", "M.I. Sereno", "A.M. Dale"], "venue": null, "citeRegEx": "Fischl et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Fischl et al\\.", "year": 1999}, {"title": "Design patterns: elements of reusable object-oriented software", "author": ["E. Gamma", "J. Vlissides", "R. Johnson", "R. Helm"], "venue": null, "citeRegEx": "Gamma et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Gamma et al\\.", "year": 1994}, {"title": "Toolnet: Holistically-nested real-time segmentation of robotic surgical tools. arXiv:1706.08126v2", "author": ["L.C. Garcia-Peraza-Herrera", "W. Li", "L. Fidon", "C. Gruijthuijsen", "A. Devreker", "G. Attilakos", "J. Deprest", "E.V. Poorten", "D. Stoyanov", "T. Vercauteren", "S. Ourselin"], "venue": null, "citeRegEx": "Garcia.Peraza.Herrera et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Garcia.Peraza.Herrera et al\\.", "year": 2017}, {"title": "Automatic multi-organ segmentation on abdominal CT with dense v-networks", "author": ["E. Gibson", "F. Giganti", "Y. Hu", "E. Bonmati", "S. Bandula", "K. Gurusamy", "B. Davidson", "S.P. Pereira", "M.J. Clarkson", "D.C. Barratt"], "venue": "IEEE Transactions on Medical Imaging Submitted", "citeRegEx": "Gibson et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Gibson et al\\.", "year": 2017}, {"title": "Towards image-guided pancreas and biliary endoscopy: automatic multi-organ segmentation on abdominal CT with dense dilated networks", "author": ["E. Gibson", "F. Giganti", "Y. Hu", "E. Bonmati", "S. Bandula", "K. Gurusamy", "B.R. Davidson", "S.P. Pereira", "M.J. Clarkson", "D.C. Barratt"], "venue": "in: Proceedings of the 20th International Conference on Medical Image Computing and Computer", "citeRegEx": "Gibson et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Gibson et al\\.", "year": 2017}, {"title": "Deep residual networks for automatic segmentation of laparoscopic videos of the liver", "author": ["E. Gibson", "M.R. Robu", "S. Thompson", "P.E. Edwards", "C. Schneider", "K. Gurusamy", "B. Davidson", "D.J. Hawkes", "D.C. Barratt", "M.J. Clarkson"], "venue": "in: Proceedings of the SPIE, Medical Imaging", "citeRegEx": "Gibson et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Gibson et al\\.", "year": 2017}, {"title": "Nips 2016 tutorial: Generative adversarial networks arXiv:1701.00160v4", "author": ["I. Goodfellow"], "venue": null, "citeRegEx": "Goodfellow,? \\Q2016\\E", "shortCiteRegEx": "Goodfellow", "year": 2016}, {"title": "Freehand ultrasound image simulation with spatially-conditioned generative adversarial networks, in: Proceedings of MICCAI\u201917 Workshop on Reconstruction and Analysis of Moving Body Organs (RAMBO\u201917)", "author": ["Y. Hu", "E. Gibson", "L.L. Lee", "W. Xie", "D.C. Barratt", "T. Vercauteren", "J.A. Noble"], "venue": null, "citeRegEx": "Hu et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2017}, {"title": "Batch renormalization: Towards reducing minibatch dependence in batch-normalized models arXiv:1702.03275v2", "author": ["S. Ioffe"], "venue": null, "citeRegEx": "Ioffe,? \\Q2017\\E", "shortCiteRegEx": "Ioffe", "year": 2017}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "in: Proceedings of the 22nd ACM International Conference on Multimedia (ACMMM\u201914),", "citeRegEx": "Jia et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jia et al\\.", "year": 2014}, {"title": "NiftySim: A GPU-based nonlinear finite element package for simulation of soft tissue", "author": ["S.F. Johnsen", "Z.A. Taylor", "M.J. Clarkson", "J. Hipwell", "M. Modat", "B. Eiben", "L. Han", "Y. Hu", "T. Mertzanidou", "D.J. Hawkes", "S. Ourselin"], "venue": "biomechanics. nternational Journal for Computer Assisted Radiology and Surgery", "citeRegEx": "Johnsen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Johnsen et al\\.", "year": 2015}, {"title": "Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation", "author": ["K. Kamnitsas", "C. Ledig", "V.F. Newcombe", "J.P. Simpson", "A.D. Kane", "D.K. Menon", "D. Rueckert", "B. Glocker"], "venue": "Medical Image Analysis", "citeRegEx": "Kamnitsas et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Kamnitsas et al\\.", "year": 2017}, {"title": "Elastix: a toolbox for intensity-based medical image registration", "author": ["S. Klein", "M. Staring", "K. Murphy", "M.A. Viergever", "J.P. Pluim"], "venue": "IEEE Transactions on Medical Imaging", "citeRegEx": "Klein et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Klein et al\\.", "year": 2010}, {"title": "Multi-atlas labeling beyond the cranial vault. URL: https://www.synapse. org/#!Synapse:syn3193805, doi:10.7303/syn3193805", "author": ["B. Landman", "Z. Xu", "J.E. Igelsias", "M. Styner", "T.R. Langerak", "A. Klein"], "venue": null, "citeRegEx": "Landman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Landman et al\\.", "year": 2015}, {"title": "On the compactness, efficiency, and representation of 3D convolutional networks: Brain parcellation as a pretext", "author": ["W. Li", "G. Wang", "L. Fidon", "S. Ourselin", "M.J. Cardoso", "T. Vercauteren"], "venue": "Proceedings of Information Processing in Medical Imaging", "citeRegEx": "Li et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Li et al\\.", "year": 2017}, {"title": "A survey on deep learning in medical image analysis", "author": ["G. Litjens", "T. Kooi", "B.E. Bejnordi", "A.A.A. Setio", "F. Ciompi", "M. Ghafoorian", "van der Laak", "J.A.W.M", "B. van Ginneken", "C.I. Snchez"], "venue": "Preprint arXiv:1702.05747v1", "citeRegEx": "Litjens et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Litjens et al\\.", "year": 2017}, {"title": "Artificial convolution neural network techniques and applications for lung nodule detection", "author": ["S.C. Lo", "S.L. Lou", "J.S. Lin", "M.T. Freedman", "M.V. Chien", "S.K. Mun"], "venue": "IEEE Transactions on Medical Imaging", "citeRegEx": "Lo et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Lo et al\\.", "year": 1995}, {"title": "The design of simpleitk. Frontiers in neuroinformatics", "author": ["B.C. Lowekamp", "D.T. Chen", "L. Ib\u00e1\u00f1ez", "D. Blezek"], "venue": null, "citeRegEx": "Lowekamp et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lowekamp et al\\.", "year": 2013}, {"title": "TensorBoard: TensorFlow\u2019s visualization toolkit. https: //github.com/tensorflow/tensorboard", "author": ["D Man\u00e9"], "venue": null, "citeRegEx": "Man\u00e9,? \\Q2015\\E", "shortCiteRegEx": "Man\u00e9", "year": 2015}, {"title": "DeepInfer: Open-source deep learning deployment toolkit for image-guided therapy, in: Proceedings of the SPIE, Medical Imaging 2017", "author": ["A. Mehrtash", "M. Pesteie", "J. Hetherington", "P.A. Behringer", "T. Kapur", "W.M. Wells III", "R. Rohling", "A. Fedorov", "P. Abolmaesumi"], "venue": "NIH Public Access", "citeRegEx": "Mehrtash et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Mehrtash et al\\.", "year": 2017}, {"title": "The multimodal brain tumor image segmentation benchmark (BraTS)", "author": ["B.H. Menze", "A. Jakab", "S. Bauer", "J. Kalpathy-Cramer", "K. Farahani", "J. Kirby", "Y. Burren", "N. Porz", "J. Slotboom", "R Wiest"], "venue": "IEEE Transactions on Medical Imaging", "citeRegEx": "Menze et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Menze et al\\.", "year": 2015}, {"title": "V-Net: Fully convolutional neural networks for volumetric medical image segmentation", "author": ["F. Milletari", "N. Navab", "S.A. Ahmadi"], "venue": "in: Proceedings of the Fourth International Conference on 3D Vision (3DV\u201916),", "citeRegEx": "Milletari et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Milletari et al\\.", "year": 2016}, {"title": "Conditional generative adversarial nets arXiv:1411.1784", "author": ["M. Mirza", "S. Osindero"], "venue": null, "citeRegEx": "Mirza and Osindero,? \\Q2014\\E", "shortCiteRegEx": "Mirza and Osindero", "year": 2014}, {"title": "Fast free-form deformation using graphics processing units", "author": ["M. Modat", "G.R. Ridgway", "Z.A. Taylor", "M. Lehmann", "J. Barnes", "D.J. Hawkes", "N.C. Fox", "S. Ourselin"], "venue": "Computer Methods and Programs in Biomedicine", "citeRegEx": "Modat et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Modat et al\\.", "year": 2010}, {"title": "The Medical Imaging Interaction Toolkit: challenges and advances", "author": ["M. Nolden", "S. Zelzer", "A. Seitel", "D. Wald", "M. M\u00fcller", "A.M. Franz", "D. Maleike", "M. Fangerau", "M. Baumhauer", "L. Maier-Hein", "K.H. Maier-Hein", "H.P. Meinzer", "I. Wolf"], "venue": "nternational Journal for Computer Assisted Radiology and Surgery", "citeRegEx": "Nolden et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Nolden et al\\.", "year": 2013}, {"title": "The NA-MIC kit: ITK, VTK, pipelines, grids and 3D Slicer as an open platform for the medical image computing community", "author": ["S. Pieper", "B. Lorensen", "W. Schroeder", "R. Kikinis"], "venue": "in: Proceedings of the IEEE International Symposium on Biomedical Imaging: From Nano to Macro (ISBI\u201906),", "citeRegEx": "Pieper et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Pieper et al\\.", "year": 2006}, {"title": "Semantic versioning", "author": ["T. Preston-Werner"], "venue": "Technical Report. URL: http: //semver.org/", "citeRegEx": "Preston.Werner,? \\Q2015\\E", "shortCiteRegEx": "Preston.Werner", "year": 2015}, {"title": "Data from TCIA Pancreas-CT", "author": ["H.R. Roth", "A. Farag", "E.B. Turkbey", "L. Lu", "J. Liu", "R.M. Summers"], "venue": null, "citeRegEx": "Roth et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Roth et al\\.", "year": 2016}, {"title": "A new 2.5d representation for lymph node detection using random sets of deep convolutional neural network observations, in: MICCAI. doi:10.1007/978-3-319-10404-1_65", "author": ["H.R. Roth", "L. Lu", "A. Seff", "K.M. Cherry", "J. Hoffman", "S. Wang", "J. Liu", "E. Turkbey", "R.M. Summers"], "venue": null, "citeRegEx": "Roth et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Roth et al\\.", "year": 2014}, {"title": "Weight normalization: A simple reparameterization to accelerate training of deep neural networks arXiv:1602.07868v3", "author": ["T. Salimans", "D.P. Kingma"], "venue": null, "citeRegEx": "Salimans and Kingma,? \\Q2016\\E", "shortCiteRegEx": "Salimans and Kingma", "year": 2016}, {"title": "CNTK: Microsoft\u2019s open-source deep-learning toolkit", "author": ["F. Seide", "A. Agarwal"], "venue": "in: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Seide and Agarwal,? \\Q2016\\E", "shortCiteRegEx": "Seide and Agarwal", "year": 2016}, {"title": "Deep learning in medical image analysis", "author": ["D. Shen", "G. Wu", "H.I. Suk"], "venue": "Annual Review of Biomedical Engineering", "citeRegEx": "Shen et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Shen et al\\.", "year": 2017}, {"title": "Advances in functional and structural MR image analysis and implementation as FSL", "author": ["S.M. Smith", "M. Jenkinson", "M.W. Woolrich", "C.F. Beckmann", "T.E. Behrens", "H. Johansen-Berg", "P.R. Bannister", "M. De Luca", "I. Drobnjak", "Flitney", "D.E"], "venue": "Neuroimage 23,", "citeRegEx": "Smith et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Smith et al\\.", "year": 2004}, {"title": "Generalised Dice overlap as a deep learning loss function for highly unbalanced segmentationsn, in: Proceedings of MICCAI\u201917 Workshop on Deep Learning in Medical Image Analysis (DLMIA\u201917)", "author": ["C.H. Sudre", "W. Li", "T. Vercauteren", "S. Ourselin", "M.J. Cardoso"], "venue": null, "citeRegEx": "Sudre et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Sudre et al\\.", "year": 2017}, {"title": "MatConvNet \u2013 convolutional neural networks for MATLAB, in: ACMM", "author": ["A. Vedaldi", "K. Lenc"], "venue": null, "citeRegEx": "Vedaldi and Lenc,? \\Q2015\\E", "shortCiteRegEx": "Vedaldi and Lenc", "year": 2015}, {"title": "Automatic brain tumor segmentation using cascaded anisotropic convolutional neural networks", "author": ["G. Wang", "W. Li", "S. Ourselin", "T. Vercauteren"], "venue": "Preprint arXiv:1709.00382", "citeRegEx": "Wang et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2017}, {"title": "2017b. Deepigeos: A deep interactive geodesic framework for medical image segmentation. Preprint arXiv:1707.00652v1", "author": ["G. Wang", "M.A. Zuluaga", "W. Li", "R. Pratt", "P.A. Patel", "M. Aertsen", "T. Doel", "A.L. David", "J. Deprest", "S. Ourselin", "T. Vercauteren"], "venue": null, "citeRegEx": "Wang et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2017}, {"title": "Threedimensional CT image segmentation by combining 2D fully convolutional network with 3D majority voting", "author": ["X. Zhou", "T. Ito", "R. Takayama", "S. Wang", "T. Hara", "H. Fujita"], "venue": "in: LABELS2016,", "citeRegEx": "Zhou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 29, "context": "Although the first use of neural networks for medical image analysis dates back more than twenty years (Lo et al., 1995), their usage has increased by orders of magnitude in the last five years.", "startOffset": 103, "endOffset": 120}, {"referenceID": 44, "context": "Recent reviews (Shen et al., 2017; Litjens et al., 2017) have highlighted that deep learning has been applied to a wide range of medical image analysis tasks (segmentation, classification, detection, registration, image reconstruction, enhancement, etc.", "startOffset": 15, "endOffset": 56}, {"referenceID": 28, "context": "Recent reviews (Shen et al., 2017; Litjens et al., 2017) have highlighted that deep learning has been applied to a wide range of medical image analysis tasks (segmentation, classification, detection, registration, image reconstruction, enhancement, etc.", "startOffset": 15, "endOffset": 56}, {"referenceID": 36, "context": "NiftyReg (Modat et al., 2010), ANTs (Avants et al.", "startOffset": 9, "endOffset": 29}, {"referenceID": 1, "context": ", 2010), ANTs (Avants et al., 2011) and elastix (Klein et al.", "startOffset": 14, "endOffset": 35}, {"referenceID": 25, "context": ", 2011) and elastix (Klein et al., 2010)), segmentation (e.", "startOffset": 20, "endOffset": 40}, {"referenceID": 4, "context": "NiftySeg (Cardoso et al., 2012)), and biomechanical modeling (e.", "startOffset": 9, "endOffset": 31}, {"referenceID": 23, "context": "(Johnsen et al., 2015)) are available for use as part of image analysis pipelines.", "startOffset": 0, "endOffset": 22}, {"referenceID": 45, "context": "Pipelines for specific research applications such as FSL (Smith et al., 2004) for functional MRI analysis and Freesurfer (Fischl et al.", "startOffset": 57, "endOffset": 77}, {"referenceID": 13, "context": ", 2004) for functional MRI analysis and Freesurfer (Fischl et al., 1999; Dale et al., 1999) for structural neuroimaging have reached widespread use.", "startOffset": 51, "endOffset": 91}, {"referenceID": 9, "context": ", 2004) for functional MRI analysis and Freesurfer (Fischl et al., 1999; Dale et al., 1999) for structural neuroimaging have reached widespread use.", "startOffset": 51, "endOffset": 91}, {"referenceID": 38, "context": "More general toolkits offering standardized implementations of algorithms (VTK and ITK (Pieper et al., 2006)) and application frameworks (NifTK (Clarkson et al.", "startOffset": 87, "endOffset": 108}, {"referenceID": 7, "context": ", 2006)) and application frameworks (NifTK (Clarkson et al., 2015), MITK (Nolden et al.", "startOffset": 43, "endOffset": 66}, {"referenceID": 37, "context": ", 2015), MITK (Nolden et al., 2013) and 3D Slicer (Pieper et al.", "startOffset": 14, "endOffset": 35}, {"referenceID": 38, "context": ", 2013) and 3D Slicer (Pieper et al., 2006)) enable others to build their own pipelines.", "startOffset": 22, "endOffset": 43}, {"referenceID": 3, "context": ", 2016), Theano (Bastien et al., 2012), Caffe (Jia et al.", "startOffset": 16, "endOffset": 38}, {"referenceID": 22, "context": ", 2012), Caffe (Jia et al., 2014), Torch (Collobert et al.", "startOffset": 15, "endOffset": 33}, {"referenceID": 8, "context": ", 2014), Torch (Collobert et al., 2011), CNTK (Seide and Agarwal, 2016), and MatConvNet (Vedaldi and Lenc, 2015).", "startOffset": 15, "endOffset": 39}, {"referenceID": 43, "context": ", 2011), CNTK (Seide and Agarwal, 2016), and MatConvNet (Vedaldi and Lenc, 2015).", "startOffset": 14, "endOffset": 39}, {"referenceID": 47, "context": ", 2011), CNTK (Seide and Agarwal, 2016), and MatConvNet (Vedaldi and Lenc, 2015).", "startOffset": 56, "endOffset": 80}, {"referenceID": 11, "context": ", 2015), and TensorLayer (Dong et al., 2017) for TensorFlow and Lasagne (Dieleman et al.", "startOffset": 25, "endOffset": 44}, {"referenceID": 7, "context": "NifTK (Clarkson et al., 2015; Gibson et al., 2017c) and Slicer3D (via the DeepInfer (Mehrtash et al.", "startOffset": 6, "endOffset": 51}, {"referenceID": 32, "context": ", 2017c) and Slicer3D (via the DeepInfer (Mehrtash et al., 2017) plugin) provide infrastructure for distribution of trained deep learning pipelines.", "startOffset": 41, "endOffset": 64}, {"referenceID": 10, "context": ", 2017b) for semi-automated annotation and GIFT-Cloud (Doel et al., 2017) for data sharing are beginning to reduce these barriers, typical data sets remain small.", "startOffset": 54, "endOffset": 73}, {"referenceID": 50, "context": "Many networks are designed to use partial images: 2D slices sampled along one axis from 3D images (Zhou et al., 2016), 3D subvolumes (Li et al.", "startOffset": 98, "endOffset": 117}, {"referenceID": 27, "context": ", 2016), 3D subvolumes (Li et al., 2017), anisotropic convolution Wang et al.", "startOffset": 23, "endOffset": 40}, {"referenceID": 41, "context": "(2017a), or combinations of subvolumes along multiple axes (Roth et al., 2014).", "startOffset": 59, "endOffset": 78}, {"referenceID": 34, "context": "Other networks use multi-scale representations allowing deeper and wider networks on lower resolution representations (Milletari et al., 2016; Kamnitsas et al., 2017).", "startOffset": 118, "endOffset": 166}, {"referenceID": 24, "context": "Other networks use multi-scale representations allowing deeper and wider networks on lower resolution representations (Milletari et al., 2016; Kamnitsas et al., 2017).", "startOffset": 118, "endOffset": 166}, {"referenceID": 21, "context": "Smaller batch sizes can reduce the memory cost, but rely on different weight normalization functions such as batch renormalization (Ioffe, 2017), weight normalization (Salimans and Kingma, 2016) or layer normalization (Ba et al.", "startOffset": 131, "endOffset": 144}, {"referenceID": 42, "context": "Smaller batch sizes can reduce the memory cost, but rely on different weight normalization functions such as batch renormalization (Ioffe, 2017), weight normalization (Salimans and Kingma, 2016) or layer normalization (Ba et al.", "startOffset": 167, "endOffset": 194}, {"referenceID": 2, "context": "Smaller batch sizes can reduce the memory cost, but rely on different weight normalization functions such as batch renormalization (Ioffe, 2017), weight normalization (Salimans and Kingma, 2016) or layer normalization (Ba et al., 2016).", "startOffset": 218, "endOffset": 235}, {"referenceID": 21, "context": ", 2016), 3D subvolumes (Li et al., 2017), anisotropic convolution Wang et al. (2017a), or combinations of subvolumes along multiple axes (Roth et al.", "startOffset": 24, "endOffset": 86}, {"referenceID": 34, "context": "Because small image features can have large clinical importance, and because some pathology is very rare but life-threatening, medical image analysis must deal with large class imbalances, motivating special loss functions (Milletari et al., 2016; Fidon et al., 2017; Sudre et al., 2017).", "startOffset": 223, "endOffset": 287}, {"referenceID": 12, "context": "Because small image features can have large clinical importance, and because some pathology is very rare but life-threatening, medical image analysis must deal with large class imbalances, motivating special loss functions (Milletari et al., 2016; Fidon et al., 2017; Sudre et al., 2017).", "startOffset": 223, "endOffset": 287}, {"referenceID": 46, "context": "Because small image features can have large clinical importance, and because some pathology is very rare but life-threatening, medical image analysis must deal with large class imbalances, motivating special loss functions (Milletari et al., 2016; Fidon et al., 2017; Sudre et al., 2017).", "startOffset": 223, "endOffset": 287}, {"referenceID": 15, "context": ", (Gibson et al., 2017c; Garcia-Peraza-Herrera et al., 2017)) where analysis results are used in real time have additional constraints on analysis latency.", "startOffset": 2, "endOffset": 60}, {"referenceID": 14, "context": "Implemented as a template design pattern (Gamma et al., 1994), the ApplicationDriver delegates application-specific functionality to separate Application classes.", "startOffset": 41, "endOffset": 61}, {"referenceID": 30, "context": "SimpleITK (Lowekamp et al., 2013) if they are installed and a file format is not supported by nibabel.", "startOffset": 10, "endOffset": 33}, {"referenceID": 6, "context": ", unet (\u00c7i\u00e7ek et al., 2016) and vnet (Milletari et al.", "startOffset": 7, "endOffset": 27}, {"referenceID": 34, "context": ", 2016) and vnet (Milletari et al., 2016) for segmentation), as well as trained networks for some tasks (e.", "startOffset": 17, "endOffset": 41}, {"referenceID": 20, "context": ", 2017a) for brain tumor segmentation and simulator gan (Hu et al., 2017) for generating ultrasound images).", "startOffset": 56, "endOffset": 73}, {"referenceID": 39, "context": "0 standard (Preston-Werner, 2015) to ensure clear communication about backwards compatibility.", "startOffset": 11, "endOffset": 33}, {"referenceID": 26, "context": "The data used to train the network comprised 90 abdominal CT with manual segmentations from two publicly available data sets (Landman et al., 2015; Roth et al., 2016), with additional manual segmentations performed at our centre.", "startOffset": 125, "endOffset": 166}, {"referenceID": 40, "context": "The data used to train the network comprised 90 abdominal CT with manual segmentations from two publicly available data sets (Landman et al., 2015; Roth et al., 2016), with additional manual segmentations performed at our centre.", "startOffset": 125, "endOffset": 166}, {"referenceID": 35, "context": "(Mirza and Osindero, 2014) Recent work on spatially-conditioned GANs (Hu et al.", "startOffset": 0, "endOffset": 26}, {"referenceID": 20, "context": "(Mirza and Osindero, 2014) Recent work on spatially-conditioned GANs (Hu et al., 2017) suggests that conditional GANs could enable software-based simulation in place of costly physical ultrasound phantoms used for training.", "startOffset": 69, "endOffset": 86}, {"referenceID": 20, "context": "The network was originally trained outside of the NiftyNet platform as described in (Hu et al., 2017).", "startOffset": 84, "endOffset": 101}, {"referenceID": 19, "context": "The second shows a sharp transition in the interpolation, suggesting the presence of mode collapse, a common issue in GANs (Goodfellow, 2016).", "startOffset": 123, "endOffset": 141}, {"referenceID": 33, "context": "brain tumor segmentation (BRaTS) (Menze et al., 2015; Wang et al., 2017a)); and models trained on large data sets for transfer learning will be critical to accelerating research with NiftyNet.", "startOffset": 33, "endOffset": 73}], "year": 2017, "abstractText": "Medical image analysis and computer-assisted intervention problems are increasingly being addressed with deep-learning-based solutions. This has resulted is substantial duplication of effort and incompatible infrastructure across many research groups. This work presents the open-source NiftyNet platform for deep learning in medical imaging. The ambition of NiftyNet is to accelerate and simplify the development of these solutions, and to provide a common mechanism for disseminating research outputs for the community to use, adapt and build upon. This TensorFlow-based infrastructure provides a complete modular deep learning pipeline for a range of medical imaging applications including segmentation, regression, image generation and representation learning applications with data loading, data augmentation, network architectures, loss functions and evaluation metrics that are tailored to, and take advantage of, the idiosyncracies of medical image analysis and computer-assisted interventions.", "creator": "LaTeX with hyperref package"}}}