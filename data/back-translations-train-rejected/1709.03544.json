{"id": "1709.03544", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Sep-2017", "title": "KnowNER: Incremental Multilingual Knowledge in Named Entity Recognition", "abstract": "KnowNER is a multilingual Named Entity Recognition (NER) system that leverages different degrees of external knowledge. A novel modular framework divides the knowledge into four categories according to the depth of knowledge they convey. Each category consists of a set of features automatically generated from different information sources (such as a knowledge-base, a list of names or document-specific semantic annotations) and is used to train a conditional random field (CRF). Since those information sources are usually multilingual, KnowNER can be easily trained for a wide range of languages. In this paper, we show that the incorporation of deeper knowledge systematically boosts accuracy and compare KnowNER with state-of-the-art NER approaches across three languages (i.e., English, German and Spanish) performing amongst state-of-the art systems in all of them.", "histories": [["v1", "Mon, 11 Sep 2017 18:54:15 GMT  (929kb,D)", "http://arxiv.org/abs/1709.03544v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["dominic seyler", "tatiana dembelova", "luciano del corro", "johannes hoffart", "gerhard weikum"], "accepted": false, "id": "1709.03544"}, "pdf": {"name": "1709.03544.pdf", "metadata": {"source": "META", "title": "KnowNER: Incremental Multilingual Knowledge in Named Entity Recognition", "authors": ["Dominic Seyler", "Tatiana Dembelova", "Luciano Del Corro", "Johannes Hoffart", "Gerhard Weikum"], "emails": ["dseyler2@illinois.edu", "tdembelo@mpi-inf.mpg.de", "corrogg@mpi-inf.mpg.de", "jhoffart@mpi-inf.mpg.de", "weikum@mpi-inf.mpg.de"], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, most of them are able to decide for themselves what they want."}, {"heading": "2 THE NAMED ENTITY RECOGNITION TASK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Task Definition", "text": "The task involves two challenges: (i) finding the span of text of a named entity name and (ii) annotating each named entity with a type; the first challenge requires identifying tokens that relate to designated entities; a designated entity may consist of several tokens (\"United States\"), and a designated entity may be embedded in another designated entity (\"United States Supreme Court\"); and the second challenge requires a deeper semantic understanding (e.g. understand that \"Jimmy Page\" is not just a designated entity, but specifically a person); although the zero usually relates to both tasks, some applications can only rely on the first one (e.g. NED)."}, {"heading": "2.2 A linear chain CRF model", "text": "Previous work [5, 9, 14, 16, 18, 19] has demonstrated the effectiveness of CRFs [11] for the NER task. We implemented KnowNER as a linear chain similar to CRF [5]. The underlying idea is to use NER as a sequence model with a bidirectional flow. CRF represents the probability of a hidden state sequence (i.e., token labels) taking into account a number of observations. In a linear chain CRF, the probability of a token being as a designated entity depends on a number of observations, including the labeling of its neighboring neighbors. For a more detailed description of the model, see Finkel et al., 2005."}, {"heading": "3 KNOWLEDGE AUGMENTED NER", "text": "Here we describe the knowledge categories that function as modules in our system. We define four: agnostic (A), name-based, KB-based and entity-based, each containing an increasing amount of external knowledge. A category consists of the attributes summarized in Tab. 1."}, {"heading": "3.1 Knowledge Agnostic", "text": "This category includes the so-called \"local\" characteristics, which are characterized by the fact that they can be extracted directly from the text without external knowledge. These characteristics are largely lexical, syntactic or linguistic in nature and have been well studied in the literature. We implement most of the characteristics described in Finkel et al. [5] and Zhang and Johnson. [24] namely: (1) the current word and the words in a window of size 2; (2) word forms of the current word and the words in a window of size 2; (3) POS tags in a window of size 2; (4) prefixes (length three and four) and suffixes (length one to four); (5) the presence of the current word in a window of size 4; (6) the beginning of the sentence."}, {"heading": "3.2 Name-Based Knowledge", "text": "In this category, knowledge is extracted from a list of named entity names. To the best of our knowledge, these attributes have not yet been used. We extracted a list of all names from YAGO [21] (30.85 million for the languages in which we trained) and created the following characteristics: Frequent Mention of Tokens. Reflecting the frequency of a given token in a list of entity names. We tokenized the list to calculate frequencies. The function assigns a weight to each token character in the text corresponding to its normalized frequency. The intuition is that some words such as \"John\" or \"Organization\" can be indicative of a named entity and therefore carry a high weight. The top 5 tokens we found in English were \"County,\" \"School,\" \"\" and \"District.\""}, {"heading": "3.3 Knowledge-Base-Based Knowledge", "text": "In fact, it is such that most people are in a position to go into another world, in which they are able to move, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in fact, in fact, in fact, in fact, are able to move, are able to move, in which they are able to"}, {"heading": "3.4 Entity-Based Knowledge", "text": "The idea is to exploit the inherent association between NER and NED. Previous work has shown that the flow of information between the two tasks produces significant improvements in the performance of NERs [14, 18]. In comparison, this module requires more (computing and knowledge) resources than the previous ones. It takes a first run of NED to generate document-specific characteristics based on the uniquely named units. The generated characteristics will be in a second run of NER.Following Radford et al. [18], after the first run of NED, we create a series of document-specific gazetteers derived from the designated units. The idea is that this information will help in the second round to find new designated units that will be overlooked in the first round. Let's take the phrase: \"Three-quarters of the citizens of the European Union working in the UK will not meet the current visa requirements for non-EU workers if the UK leaves the EU- or we can imagine the EU- first round of the bloc.\""}, {"heading": "4 EVALUATION", "text": "In this section we analyse the impact of external knowledge (paragraph 4.2) and compare KnowNER with current approaches (paragraph 4.1) for three languages: English, German and Spanish."}, {"heading": "4.1 Experimental Setup", "text": "In fact, most of them will be able to move to another world in which they will be able to integrate."}, {"heading": "4.2 Incremental Knowledge", "text": "Here we analyze the effects of external knowledge on the system. Our detailed analysis is specific to the English language on the CoNLLL2003e and MUC-7 datasets. Results show a marked improvement when deeper knowledge about datasets and entity types is used. Figure 1a shows the effect of span detection in each category. Although it decreases slightly for the name-based category, it recovers quickly when deeper knowledge is added. The effect is similar for both datasets. In terms of mention-based metrics, Figure 1b shows the effect of different knowledge categories for the menu-based metric. In all cases, adding knowledge leads to a boost in performance. The effect is particularly strong for the MUC-7 test, which has a general increase of almost 10 F1 points. In both cases, the greatest thrust is registered when the KB-based characteristics are added. However, the downloading substance2 may suggest that some of the downloading stub in the CoNLLLLL2003e and MUC-7 datasets."}, {"heading": "4.3 Comparative Performance", "text": "The results for KnowNER correspond to a setting in which all categories of knowledge are used when using the gold standard for the enterprise-based step (as in Radford at al. [18]) or the AIDA system for the enterprise-based knowledge category.Tab.6 shows detailed results for one of the latest versions of Finkel et al. [5] (Stanford NER 3.6.0), probably the most widely used NER system to date that outperforms KnowNER. To the best of our knowledge, Germany is one of the most powerful systems for the German language to date on CoNL2003g. Tab. 7 presents the results for KnowNER compared to the most modern systems. Tab. 8 presents detailed results for each named entity. The biggest boost compared to the results generated in Germany for the entity undertaken Tab. 7 presents the results for Tab systems that generate more points than Tab systems based on Tab-9 that are generated in Spanish."}, {"heading": "5 RELATEDWORK", "text": "In fact, most of them are able to determine for themselves what they want and what they want."}, {"heading": "6 CONCLUSION", "text": "We introduced KnowNER, a multilingual system that explicitly encodes different levels of external knowledge for NER. KnowNER's framework defines four categories of knowledge, each of which contains deeper external knowledge. Our experimental study shows that KnowNER performs across languages within state-of-the-art NER systems. It also shows that increasing the level of external knowledge encoded in the system significantly increases the performance of NER."}], "references": [{"title": "MUC-7 named entity task definition", "author": ["Nancy Chinchor", "Patricia Robinson"], "venue": "In Proceedings of MUC-7", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1997}, {"title": "Named Entity Recognition with Bidirectional LSTM-CNNs. TACL", "author": ["Jason Chiu", "Eric Nichols"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Boosting Named Entity Recognition with Neural Character Embeddings", "author": ["C\u00edcero Nogueira dos Santos", "Victor Guimar\u00e3es"], "venue": "Proceedings of the Fifth Named Entity Workshop", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "A Joint Model for Entity Analysis: Coreference, Typing, and Linking", "author": ["Greg Durrett", "Dan Klein"], "venue": "TACL", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling", "author": ["Jenny Rose Finkel", "Trond Grenager", "Christopher D. Manning"], "venue": "In Proceedings of ACL", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Named Entity Recognition through Classifier Combination", "author": ["Radu Florian", "Abraham Ittycheriah", "Hongyan Jing", "Tong Zhang"], "venue": "In Proceedings of CoNLL", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "Multilingual Language Processing From Bytes", "author": ["Dan Gillick", "Cliff Brunk", "Oriol Vinyals", "Amarnag Subramanya"], "venue": "In Proceedings of NAACL", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Robust Disambiguation of Named Entities in Text", "author": ["Johannes Hoffart", "Mohamed Amir Yosef", "Ilaria Bordino", "Hagen F\u00fcrstenau", "Manfred Pinkal", "Marc Spaniol", "Bilyana Taneva", "Stefan Thater", "Gerhard Weikum"], "venue": "Proceedings of EMNLP", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Exploiting Wikipedia as External Knowledge for Named Entity Recognition", "author": ["Kazama Jun\u2019ichi", "Kentaro Torisawa"], "venue": "In Proceedings of EMNLP-CoNLL", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Named Entity Recognition with Character-Level Models", "author": ["Dan Klein", "Joseph Smarr", "HuyNguyen", "Christopher D.Manning"], "venue": "In Proceedings of CoNLL", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2003}, {"title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data", "author": ["John D. Lafferty", "Andrew McCallum", "Fernando C.N. Pereira"], "venue": "In Proceedings of ICML", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2001}, {"title": "Neural Architectures for Named Entity Recognition", "author": ["Guillaume Lample", "Miguel Ballesteros", "Sandeep Subramanian", "Kazuya Kawakami", "Chris Dyer"], "venue": "In Proceedings of NAACL", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Phrase Clustering for Discriminative Learning", "author": ["Dekang Lin", "Xiaoyun Wu"], "venue": "In Proceedings of ACL", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Joint Entity Recognition and Disambiguation", "author": ["Gang Luo", "Xiaojiang Huang", "Chin-Yew Lin", "Zaiqing Nie"], "venue": "In Proceedings of EMNLP", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "CRFsuite: a fast implementation of Conditional Random Fields (CRFs)", "author": ["Naoaki Okazaki"], "venue": "http://www.chokkan.org/software/crfsuite/", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Lexicon Infused Phrase Embeddings for Named Entity Resolution", "author": ["Alexandre Passos", "Vineet Kumar", "Andrew McCallum"], "venue": "In Proceedings of CoNLL", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Combining labeled and unlabeled data with word-class distribution learning", "author": ["Yanjun Qi", "Ronan Collobert", "Pavel P. Kuksa", "Koray Kavukcuoglu", "Jason Weston"], "venue": "In Proceedings of CIKM", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Named entity recognition with document-specific KB tag gazetteers", "author": ["Will Radford", "Xavier Carreras", "James Henderson"], "venue": "In Proceedings of EMNLP", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Design Challenges and Misconceptions in Named Entity Recognition", "author": ["Lev-Arie Ratinov", "Dan Roth"], "venue": "In Proceedings of CoNLL", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "Introduction to the CoNLL- 2003 Shared Task: Language-Independent Named Entity Recognition", "author": ["Erik F. Tjong Kim Sang", "Fien De Meulder"], "venue": "In Proceedings of CoNLL", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2003}, {"title": "Yago: a core of semantic knowledge", "author": ["Fabian M. Suchanek", "Gjergji Kasneci", "Gerhard Weikum"], "venue": "In Proceedings of WWW", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "Introduction to the CoNLL-2002 Shared Task: Language-independent Named Entity Recognition", "author": ["Erik F. Tjong Kim Sang"], "venue": "In Proceedings of CoNLL", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2002}, {"title": "Multi-Task Cross-Lingual Sequence Tagging from Scratch", "author": ["Zhilin Yang", "Ruslan Salakhutdinov", "William W. Cohen"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}, {"title": "A Robust Risk Minimization based Named Entity Recognition System", "author": ["Tong Zhang", "David Johnson"], "venue": "In Proceedings of CoNLL", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}], "referenceMentions": [{"referenceID": 4, "context": "KnowNER implements a linear chain CRF, which was proven to work well for the NER task [5].", "startOffset": 86, "endOffset": 89}, {"referenceID": 4, "context": "These features correspond to the standard lexico-syntactic features extensively used in literature [5].", "startOffset": 99, "endOffset": 102}, {"referenceID": 18, "context": "[19], we use gazetteers that associate named entity names with types.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "We generate them in an automatic way from YAGO [21], a multilingual KB.", "startOffset": 47, "endOffset": 51}, {"referenceID": 17, "context": "Previous work [18] builds on this idea, using disambiguated entities ar X iv :1 70 9.", "startOffset": 14, "endOffset": 18}, {"referenceID": 7, "context": "We follow this approach but, in addition, we evaluate our system in a real world scenario using AIDA [8], a state-of-the-art entity-linking system.", "startOffset": 101, "endOffset": 104}, {"referenceID": 4, "context": "Previous work [5, 9, 14, 16, 18, 19] proved the effectiveness of CRFs [11] for the NER task.", "startOffset": 14, "endOffset": 36}, {"referenceID": 8, "context": "Previous work [5, 9, 14, 16, 18, 19] proved the effectiveness of CRFs [11] for the NER task.", "startOffset": 14, "endOffset": 36}, {"referenceID": 13, "context": "Previous work [5, 9, 14, 16, 18, 19] proved the effectiveness of CRFs [11] for the NER task.", "startOffset": 14, "endOffset": 36}, {"referenceID": 15, "context": "Previous work [5, 9, 14, 16, 18, 19] proved the effectiveness of CRFs [11] for the NER task.", "startOffset": 14, "endOffset": 36}, {"referenceID": 17, "context": "Previous work [5, 9, 14, 16, 18, 19] proved the effectiveness of CRFs [11] for the NER task.", "startOffset": 14, "endOffset": 36}, {"referenceID": 18, "context": "Previous work [5, 9, 14, 16, 18, 19] proved the effectiveness of CRFs [11] for the NER task.", "startOffset": 14, "endOffset": 36}, {"referenceID": 10, "context": "Previous work [5, 9, 14, 16, 18, 19] proved the effectiveness of CRFs [11] for the NER task.", "startOffset": 70, "endOffset": 74}, {"referenceID": 4, "context": "We implemented KnowNER as a linear chain CRF similar to [5].", "startOffset": 56, "endOffset": 59}, {"referenceID": 4, "context": "[5] and Zhang and Johnson.", "startOffset": 0, "endOffset": 3}, {"referenceID": 23, "context": "[24], namely: (1) The current word and words in a window of size 2 ; (2) Word shapes of the current word and words in a window of size 2; (3) POS tags in a window of size 2; (4) Prefixes (length three and four) and Suffixes (length one to four); (5) Presence of the current word in a window of size 4; (6) Beginning of sentence.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "We extracted a list of all names from YAGO [21] (30.", "startOffset": 43, "endOffset": 47}, {"referenceID": 13, "context": "These dictionaries have been successfully used in the past [14, 16, 18].", "startOffset": 59, "endOffset": 71}, {"referenceID": 15, "context": "These dictionaries have been successfully used in the past [14, 16, 18].", "startOffset": 59, "endOffset": 71}, {"referenceID": 17, "context": "These dictionaries have been successfully used in the past [14, 16, 18].", "startOffset": 59, "endOffset": 71}, {"referenceID": 18, "context": "This idea is implemented using the BILOU (Begin, Inside, Last, Outside, Unit) encoding [19], which tags each token with respect to the position in which it occurs (e.", "startOffset": 87, "endOffset": 91}, {"referenceID": 13, "context": "Previous work showed that the flow of information between the two tasks generates significant improvements in NER performance [14, 18].", "startOffset": 126, "endOffset": 134}, {"referenceID": 17, "context": "Previous work showed that the flow of information between the two tasks generates significant improvements in NER performance [14, 18].", "startOffset": 126, "endOffset": 134}, {"referenceID": 17, "context": "[18], after the first run of NED, we create a set of document-specific gazetteers derived from the named entities found.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "The CRF was trained using CRF-suite [15] with the Limited-memory Broyden-Fletcher-Goldfarb-Shanno algorithm and L1 regularization (coeff.", "startOffset": 36, "endOffset": 40}, {"referenceID": 17, "context": "[18] uses the gold standard named entity annotations for the Entity-based features and was used to analyze the impact of knowledge into the NER task, and (ii) KnowNERaida which runs AIDA to produce the Entity-based features and was used across all languages to compare with other available NER systems.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "By Sang and Meulder [20], it is a collection of English Reuter\u2019s newswireswith named entitymentions annotatedwith types (i.", "startOffset": 20, "endOffset": 24}, {"referenceID": 0, "context": "A set of New York Times articles (in English) [1] designed for NED and NER.", "startOffset": 46, "endOffset": 49}, {"referenceID": 19, "context": "A German dataset also by Sang and Meulder [20], similar to CoNLL2003e the named entities are classified according to four types (i.", "startOffset": 42, "endOffset": 46}, {"referenceID": 21, "context": "By Tjong Kim Sang [22], it is a collection of news wire articles in Spanish made available by the Spanish EFE News Agency.", "startOffset": 18, "endOffset": 22}, {"referenceID": 17, "context": "[18]) or using the AIDA system for the entity-based knowledge category.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] (Stanford NER 3.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "Well developed work has established a clear direction towards the use of CRFs [11] with systems achieving high", "startOffset": 78, "endOffset": 82}, {"referenceID": 1, "context": "Chiu and Nichols [2] 91.", "startOffset": 17, "endOffset": 20}, {"referenceID": 13, "context": "[14] 91.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] 91.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] 90.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] 90.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "Lin and Wu [13] 90.", "startOffset": 11, "endOffset": 15}, {"referenceID": 18, "context": "Ratinov and Roth [19] 90.", "startOffset": 17, "endOffset": 21}, {"referenceID": 17, "context": "[18] 89.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] 86.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "[12] 78.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7] 76.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "[17] 75.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] 85.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] 85.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7] 82.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "dos Santos and Guimar\u00e3es [3] 82.", "startOffset": 25, "endOffset": 28}, {"referenceID": 4, "context": "relative performance [5, 9, 14, 16, 18, 19].", "startOffset": 21, "endOffset": 43}, {"referenceID": 8, "context": "relative performance [5, 9, 14, 16, 18, 19].", "startOffset": 21, "endOffset": 43}, {"referenceID": 13, "context": "relative performance [5, 9, 14, 16, 18, 19].", "startOffset": 21, "endOffset": 43}, {"referenceID": 15, "context": "relative performance [5, 9, 14, 16, 18, 19].", "startOffset": 21, "endOffset": 43}, {"referenceID": 17, "context": "relative performance [5, 9, 14, 16, 18, 19].", "startOffset": 21, "endOffset": 43}, {"referenceID": 18, "context": "relative performance [5, 9, 14, 16, 18, 19].", "startOffset": 21, "endOffset": 43}, {"referenceID": 1, "context": "A new line, focused on neural networks methods [2, 3, 7, 12, 23, 23].", "startOffset": 47, "endOffset": 68}, {"referenceID": 2, "context": "A new line, focused on neural networks methods [2, 3, 7, 12, 23, 23].", "startOffset": 47, "endOffset": 68}, {"referenceID": 6, "context": "A new line, focused on neural networks methods [2, 3, 7, 12, 23, 23].", "startOffset": 47, "endOffset": 68}, {"referenceID": 11, "context": "A new line, focused on neural networks methods [2, 3, 7, 12, 23, 23].", "startOffset": 47, "endOffset": 68}, {"referenceID": 22, "context": "A new line, focused on neural networks methods [2, 3, 7, 12, 23, 23].", "startOffset": 47, "endOffset": 68}, {"referenceID": 22, "context": "A new line, focused on neural networks methods [2, 3, 7, 12, 23, 23].", "startOffset": 47, "endOffset": 68}, {"referenceID": 1, "context": "Chiu and Nichols [2], for instance, the best NER system for English to date implemented a hybrid bidirectional LSTM-CNNwhose inputs are tokens, word and character embeddings, and a set of gazetteers with type encodings.", "startOffset": 17, "endOffset": 20}, {"referenceID": 4, "context": "Among the CRF methods, early work has focused on purely agnostic systems [5, 10].", "startOffset": 73, "endOffset": 80}, {"referenceID": 9, "context": "Among the CRF methods, early work has focused on purely agnostic systems [5, 10].", "startOffset": 73, "endOffset": 80}, {"referenceID": 9, "context": "[10] presents a system addressing the importance of substring features, an idea that we also capture in our agnostic model via prefixes and suffixes.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] is one of the most popular agnostic systems.", "startOffset": 0, "endOffset": 3}, {"referenceID": 23, "context": "paper plus prefixes and suffixes used in Zhang and Johnson [24].", "startOffset": 59, "endOffset": 63}, {"referenceID": 4, "context": "[5] in our English experiments.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "Previous work has already regarded NER as a knowledge intensive task [6, 9, 13, 14, 16, 18, 19, 24].", "startOffset": 69, "endOffset": 99}, {"referenceID": 8, "context": "Previous work has already regarded NER as a knowledge intensive task [6, 9, 13, 14, 16, 18, 19, 24].", "startOffset": 69, "endOffset": 99}, {"referenceID": 12, "context": "Previous work has already regarded NER as a knowledge intensive task [6, 9, 13, 14, 16, 18, 19, 24].", "startOffset": 69, "endOffset": 99}, {"referenceID": 13, "context": "Previous work has already regarded NER as a knowledge intensive task [6, 9, 13, 14, 16, 18, 19, 24].", "startOffset": 69, "endOffset": 99}, {"referenceID": 15, "context": "Previous work has already regarded NER as a knowledge intensive task [6, 9, 13, 14, 16, 18, 19, 24].", "startOffset": 69, "endOffset": 99}, {"referenceID": 17, "context": "Previous work has already regarded NER as a knowledge intensive task [6, 9, 13, 14, 16, 18, 19, 24].", "startOffset": 69, "endOffset": 99}, {"referenceID": 18, "context": "Previous work has already regarded NER as a knowledge intensive task [6, 9, 13, 14, 16, 18, 19, 24].", "startOffset": 69, "endOffset": 99}, {"referenceID": 23, "context": "Previous work has already regarded NER as a knowledge intensive task [6, 9, 13, 14, 16, 18, 19, 24].", "startOffset": 69, "endOffset": 99}, {"referenceID": 5, "context": "Most of these works incorporate background knowledge in the form of entity-type gazetteers [6, 9, 16, 19, 24].", "startOffset": 91, "endOffset": 109}, {"referenceID": 8, "context": "Most of these works incorporate background knowledge in the form of entity-type gazetteers [6, 9, 16, 19, 24].", "startOffset": 91, "endOffset": 109}, {"referenceID": 15, "context": "Most of these works incorporate background knowledge in the form of entity-type gazetteers [6, 9, 16, 19, 24].", "startOffset": 91, "endOffset": 109}, {"referenceID": 18, "context": "Most of these works incorporate background knowledge in the form of entity-type gazetteers [6, 9, 16, 19, 24].", "startOffset": 91, "endOffset": 109}, {"referenceID": 23, "context": "Most of these works incorporate background knowledge in the form of entity-type gazetteers [6, 9, 16, 19, 24].", "startOffset": 91, "endOffset": 109}, {"referenceID": 18, "context": "Ratinov and Roth [19] used 30 gazetteers mostly extracted from Wikipedia, thereby generating big boosts in performance.", "startOffset": 17, "endOffset": 21}, {"referenceID": 13, "context": "These gazetteers have been successfully reused by other systems [14, 16, 18].", "startOffset": 64, "endOffset": 76}, {"referenceID": 15, "context": "These gazetteers have been successfully reused by other systems [14, 16, 18].", "startOffset": 64, "endOffset": 76}, {"referenceID": 17, "context": "These gazetteers have been successfully reused by other systems [14, 16, 18].", "startOffset": 64, "endOffset": 76}, {"referenceID": 13, "context": "[14] used a total of 655 gazetteers including those from Ratinov and Roth [19].", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[14] used a total of 655 gazetteers including those from Ratinov and Roth [19].", "startOffset": 74, "endOffset": 78}, {"referenceID": 8, "context": "Finally, Kazama and Torisawa [9] was one of the first works to extract type information from Wikipedia.", "startOffset": 29, "endOffset": 32}, {"referenceID": 3, "context": "The association between NER and NED has been successfully exploited by recent work [4, 14, 18] as a means to boost NER performance.", "startOffset": 83, "endOffset": 94}, {"referenceID": 13, "context": "The association between NER and NED has been successfully exploited by recent work [4, 14, 18] as a means to boost NER performance.", "startOffset": 83, "endOffset": 94}, {"referenceID": 17, "context": "The association between NER and NED has been successfully exploited by recent work [4, 14, 18] as a means to boost NER performance.", "startOffset": 83, "endOffset": 94}, {"referenceID": 17, "context": "[18] uses a two-step approach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] present a joint model for named entity recognition and disambiguation, as a CRF with a topology for joint optimization.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "Regarding multilinguality, recent work has focused on methods to handle NER across a wide set of languages [7, 12, 23].", "startOffset": 107, "endOffset": 118}, {"referenceID": 11, "context": "Regarding multilinguality, recent work has focused on methods to handle NER across a wide set of languages [7, 12, 23].", "startOffset": 107, "endOffset": 118}, {"referenceID": 22, "context": "Regarding multilinguality, recent work has focused on methods to handle NER across a wide set of languages [7, 12, 23].", "startOffset": 107, "endOffset": 118}, {"referenceID": 22, "context": "[23], one of the best systems across languages, implements a hierarchical recurrent neural network for joint POS tagging, chunking and NER, implemented on top of a CRF layer to do the labelling.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "KnowNER is a multilingual Named Entity Recognition (NER) system that leverages different degrees of external knowledge. A novel modular framework divides the knowledge into four categories according to the depth of knowledge they convey. Each category consists of a set of features automatically generated from different information sources (such as a knowledge-base, a list of names or document-specific semantic annotations) and is used to train a conditional random field (CRF). Since those information sources are usually multilingual, KnowNER can be easily trained for a wide range of languages. In this paper, we show that the incorporation of deeper knowledge systematically boosts accuracy and compare KnowNER with state-of-the-art NER approaches across three languages (i.e., English, German and Spanish) performing amongst state-of-the art systems in all of them.", "creator": "LaTeX with hyperref package"}}}