{"id": "1709.05743", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Sep-2017", "title": "Towards Building a Knowledge Base of Monetary Transactions from a News Collection", "abstract": "We address the problem of extracting structured representations of economic events from a large corpus of news articles, using a combination of natural language processing and machine learning techniques. The developed techniques allow for semi-automatic population of a financial knowledge base, which, in turn, may be used to support a range of data mining and exploration tasks. The key challenge we face in this domain is that the same event is often reported multiple times, with varying correctness of details. We address this challenge by first collecting all information pertinent to a given event from the entire corpus, then considering all possible representations of the event, and finally, using a supervised learning method, to rank these representations by the associated confidence scores. A main innovative element of our approach is that it jointly extracts and stores all attributes of the event as a single representation (quintuple). Using a purpose-built test set we demonstrate that our supervised learning approach can achieve 25% improvement in F1-score over baseline methods that consider the earliest, the latest or the most frequent reporting of the event.", "histories": [["v1", "Mon, 18 Sep 2017 02:09:08 GMT  (825kb)", "http://arxiv.org/abs/1709.05743v1", "Proceedings of the 17th ACM/IEEE-CS Joint Conference on Digital Libraries (JCDL '17), 2017"]], "COMMENTS": "Proceedings of the 17th ACM/IEEE-CS Joint Conference on Digital Libraries (JCDL '17), 2017", "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["jan r benetka", "krisztian balog", "kjetil n{\\o}rv{\\aa}g"], "accepted": false, "id": "1709.05743"}, "pdf": {"name": "1709.05743.pdf", "metadata": {"source": "CRF", "title": "Towards Building a Knowledge Base of Monetary Transactions from a News Collection", "authors": ["Jan R. Benetka", "Krisztian Balog", "Kjetil N\u00f8rv\u00e5g"], "emails": ["benetka@idi.ntnu.no", "krisztian.balog@uis.no", "kjetil.norvag@idi.ntnu.no"], "sections": [{"heading": null, "text": "This year is the highest in the history of the country."}, {"heading": "II. RELATED WORK", "text": "In fact, it is the case that you will be able to be in a position without being able to play by the rules."}, {"heading": "III. REPRESENTING ECONOMIC EVENTS", "text": "Before proceeding with the description of our extraction pipeline, we will present the ontology we have developed for conceptual2https: / / www.crunchbase.com / organization of economic events. Our starting point is the REA (Resource, Event, Agent) model [17], which is often used as a basic model for describing business-related concepts; it is briefly presented in Section III-A. To capture finer-grained semantic distinctions about financial transactions, we will add a hierarchy of economic event types to REA in Section III-B."}, {"heading": "A. REA", "text": "REA has evolved from a framework for accounting systems to one of the standard models in the business area. The main concepts of this model are resources (e.g. services or money), events (e.g. transactions) and agents (e.g. companies or persons). Economic events are processes in which economic resources change hands. It is assumed that there are always two events within a business activity: one that increases the value of the agent's resources and another that decreases the value of another resource owned by the agent."}, {"heading": "B. Ontology of Economic Events", "text": "In this project we deal with a wide range of economic events (i.e., predicates) with subtle semantic differences (e.g. gross profit), while at the same time aiming to organize economic events in a hierarchical manner (e.g. we get \u2192 gross profit); subsequent processes can then select the granularity with which to process the information. Currently, there is no ontology that would allow such a detailed presentation of financial activities. To fill this gap, we propose the Ontology of Economic Events (OEE), an extension of the REA; see Figure 2 for a graphical overview."}, {"heading": "IV. EXTRACTING ECONOMIC EVENTS", "text": "Our goal is to extract structured information about economic events from unstructured text (in our case, a large news3We would like to point out that predicates can be used from all levels of hierarchy, not just from the leaf nodes. Of course, more predictive predicates should be preferred over less specific ones. Archive) An economic event, as understood in this work, is a unique quintuple: (< subject >, < predicate >, < object >, monetary value, date) where subjects and objects are unique entity identifiers, predicates come from a purposeful ontology of money transactions, and monetary values and data are normalized letters. Our extraction process consists of several steps organized in a pipeline architecture, as shown in Fig. 3. We will cover the first two steps, semantic annotations (Step 1) and event identification (Step 2), described in Step 3 and Step 3."}, {"heading": "A. Semantic Annotations", "text": "The first step of our pipeline is responsible for the semantic annotation of texts using natural language processing techniques: we recognize financial events, entities, monetary values and data. We operate at the sentence level; sentences serve as provenance information for the extracted information. Another pragmatic reason for using sentences is that they can be presented as short summaries on the user interface, as shown in the figure. We generate annotations in a sequential order; sentences that exclude the required piece of information (i.e., monetary value, financial event or entities) from subsequent processing steps. Some of the components in the pipeline have several possible configurations; these are evaluated in the sect. VII-A. (a) Monetary Value RecognitionEach sentence is tested for the presence of its monetary value. We define monetary value as a tuple consisting of a numerical value and a currency (e.g. \"$1,000 or\" two billion \")."}, {"heading": "B. Event Identification", "text": "The second step of our pipeline is responsible for identifying events and summarizing sentences that discuss the same economic event. We use subject, predicate, object triples to uniquely identify events: e = (s, p, o).5 Subject and object are unique identifiers from the entity repository. Our entity repository is constructed in such a way that the mapping of surface shapes of the detected entities to unique identifiers is unambiguous (see Section VI-B. We consider predicates to be equivalent as long as they have a common ancestor on the second hierarchy level; we use the same conditions in our experimental evaluation (see Section VI-D)."}, {"heading": "V. CREATING STRUCTURED REPRESENTATIONS OF ECONOMIC EVENTS", "text": "Up to this point, we have identified economic events in sentences, along with their participants (object and subject) and attributes (monetary value and date). Furthermore, we have found that this identifier enables a single economic event with the given predicate between the two companies; this is not currently an issue in our data set. It could easily be generalized by including the date in the event identification as well. Grouped sentences corresponding to the same event simply need to create for each event a fivefold representing that event. At first glance, this may seem like a simple exercise, but there may be several sentences describing the same event (see Table I for an example). The matter is further complicated by the fact that even in a single sentence, several financial values or dates may be present, leading to several possible interpretations. We approach this problem in two phases. First, we form one or more fivefold representing the event (Section V-A)."}, {"heading": "A. Generating Candidate Quintuples", "text": "In such cases, a quintuple is generated for each possible combination of attributes. Formally, e should be an event, and Se should be the set of annotated sentences describing that event. Note that s, p, and o contain the same information across all sentences in Se: subject (s), predicate (p), object (o), release date (dx), explicit dates (Dx), and monetary values (Vx). Also, note that s, p, and o are the same due to the functioning of the sentence grouping (cf. section IV-B). Also, note that Dx could be an empty set, while Vx always has at least one element. Then, let us again specify the set of possible structured representations for event e: Re = {(s, p, o, v, d) | x-Se, v-Vx, d-Dx} For sentences without explicit mention of the publication date, d-Dx is used (dx) for the content (dx)."}, {"heading": "B. Selecting a Single Quintuple", "text": "At the end of the processing pipeline, each event e can be represented by a single quintuple. For events with multiple possible representations (i.e., where | Re | > 1), we need a mechanism to select the quintuple r that best describes the given economic transaction. We present three basic methods and a supervised learning approach. (a) Initial reporting on the eventOur first baseline selects the first reporting of the event e: r \u043c = argmin dx. (s, p, o, v, d) | v, Vx, d, Dx, {dx}} (1) If there are multiple financial values and data available in the sentence with the earliest release date, they are randomly selected. (b) Final reporting on eventOne could argue that the most recent report is probably the most accurate. Our second base method implements this intuition by taking into account the latest reporting of the event."}, {"heading": "VI. EXPERIMENTAL SETUP", "text": "The problem we are dealing with in this paper is the automatic extraction of economic events from unstructured text. This is a limited and specialized task of information extraction for which there are no standardized evaluation resources to date. Next, we describe the text corpus that serves as input data (Section VI-A), the entity repository (Section VI-B), the test collection (Section VI-C), and our evaluation methodology (Section VI-D)."}, {"heading": "A. Text Corpus", "text": "We use the New York Times Annotated Corpus (NYTC) 6 as an input text collection. This record contains over 1.8 million news articles spanning 20 years, beginning in 1987. Besides its scope, a big advantage of the corpus lies in the annotations, which are both automatically generated and manually assigned and enclosed with a subset of articles. As part of this work, we use the following annotations as features in our monitored learning step (see Section V-B): publication date, (online) descriptors, and word counting. We have analyzed all NYTC documents that have yielded 2.1 million sentences with a monetary value, of which 383K sentences describe an economic event."}, {"heading": "B. Entity Repository", "text": "We use an entity repository composed of three sources: DBpedia, Freebase and CrunchBase. From DBpedia and Freebase, we only include entities that are of the type of organization. CrunchBase contains only companies (over 160K), so we look at them all. Some organization names can be expressed in many ways, making their identification a non-trivial task (e.g. \"The Times,\" \"New York Times,\" \"NYT\"). However, the above knowledge bases only contain the official organization names and their unique identifiers. Therefore, in addition to the known surface shapes, we create additional name variations using a series of heuristics similar to those described in [1]. Finally, we group URIs and surface shapes that refer to the same entity and assign each entity a unique identification. Our entity repository contains 989K unique entities, 1.35M unique surface shapes, and DM II."}, {"heading": "C. Test Collection", "text": "We have compiled a test collection by capitalizing on what is already available in CrunchBase. We have selected 30 CrunchBase target companies that are known to have participated in financial transactions during the period covered by the NYTC. Importantly, the gold standard to compare with is not CrunchBase, but what could potentially be extracted from the text corpus (by a human). Therefore, CrunchBase6https: / / catalog.ldc.upenn.edu / LDC2008T19Transactions are checked for their presence at the NYTC; transactions that are not included in the CrunchBase, but are covered by the NYTC are added to the truth. For each target company, we have extracted all fines from the NYTC mentioning the specified company, and manually grouped sets by event. Subsequently, judgments were reviewed individually and each event is considered to be a set of supporting truth, the basic set of this sentence."}, {"heading": "D. Evaluation Methodology", "text": "The first part of the evaluation (Section VII-A) focuses on the correct identification of economic events. To designate an instance as correct, both the entities involved and the nature of the relationship must agree with the basic truth. In comparing predicates, we considered them to be equivalent if they had a common ancestor at the second level of the hierarchy. In the second phase of the evaluation (Section VII-B), the extraction of the attributes of economic events is examined. We consider two settings: (1) strict, whereby the financial value and the event date must coincide exactly, and (2) relaxed, where a certain tolerance is allowed, in particular only that part of the date is taken into account and a 10% difference in monetary values is allowed."}, {"heading": "VII. EVALUATING EVENT EXTRACTION", "text": "The evaluation is divided into two main steps: (1) event identification, which takes into account the extent to which subject-predicate object triples are successfully identified (Section VII-A), and (2) event extraction, which focuses on the end-to-end task of creating structured representations of economic events including their attributes (Section VII-B)."}, {"heading": "A. Economic Event Identification", "text": "We compare different configurations of our NLP pipeline (in Section IV). Specifically, we have control over the following options: (1) whether noun predicates are also used for event recognition (Y) or only verbs (N); (2) whether semantic roles for monetary value and date (Y) are enforced or not (N); (3) whether units must have descriptions (Y) or not (N). Table III presents the results. For reasons of space, we do not include all possible combinations, but all options \"from\" or \"in\" (line 1 vs. 5) and all but one option \"on\" (line 2-4). We observe that both the addition of noun predicates (NP) and the loose handling of semantic roles (SRL) increase the number of extracted quinttuples and events while decreasing precision."}, {"heading": "N N N 170 268 0.26 0.39 0.31", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "B. Economic Event Extraction", "text": "The second step of the evaluation focuses on the extraction of event attributes, i.e. financial value and date. We will point out that the extraction mechanism is the same for all methods, but they differ in the way a single structured description of the event is selected (five times) (see Section V-B. Basic methods always choose the earliest / latest information; the monitored method tries to learn how to select the best fivefold from annotated data; it can also choose not to return a fivefold for a particular event. We use leave-one-out cross-validation, i.e. all but one company use the remaining information for training and testing; this is repeated for all companies in the test set.Table IV reports the results only for extracting events (columns 2-4) and also for extracting attributes (columns 2-4) and for extracting attributes, using both tight and relaxed evaluation (column 5)."}, {"heading": "VIII. ANALYSIS", "text": "This section provides further analysis of the data and results. In particular, we review the scope of our ontology and the frequency of predicates, measure the importance of individual traits, and examine some successes and failures more closely."}, {"heading": "A. Ontology", "text": "The nature of each economic event is defined by a predicate in the ontology of the OEE. To evaluate the scope of ontology, we have compiled a list of the most common verbs from the 2.1 million monetary sentences of the NYTC, examined the 200 most important verbs manually and classified 81 of them as affordable. 84% of these financial verbs fall under our ontology. We have also measured the frequency of the different predicates in the NYTC. Figure 4 shows the predicates ordered by the number of occurrences up to the first three levels of the OEE. The most common predicate of the second level, payment, is mentioned in over 66K sentences. The average number of sentences per transaction type from our ontology is 2,339."}, {"heading": "B. Features", "text": "Table V lists our characteristics ordered by their Gini meaning. Characteristics that take into account information from all quintuples for the given event are particularly useful (number of dates and ratio of values), as are global predicate statistics (Pred frequency). The most important linguistic feature is whether monetary values are in the correct semantic argument (correct fin argument); semantic roles seem to be far less decisive for data (correct temp argument). Articles and sentence length are among the strongest characteristics."}, {"heading": "C. Successes and Failures", "text": "Our dataset contains 24 such events; the number of quintuples for these events ranges from 2 to 17. The results for these events, when evaluated calmly, are as follows: the earliest baseline fails in 4 cases, the youngest baseline fails in 5 cases, while the supervised learning approach was flawed in only one case. Table VI shows a concrete example where the same event is reported multiple times, and the supervised learning method was able to identify the correct five-fold."}, {"heading": "IX. CONCLUSIONS", "text": "We have introduced a natural language processing pipeline for semantic annotation of text. In order to create a single structured representation for each economic event, we have applied a supervised learning approach and developed a number of innovative features. Using a dedicated test collection, we have shown that our approach is superior to two intuitive baselines, i.e. the earliest and latest published information, and a 25% improvement in the Formula 1 score. Our work represents an important step towards the automated construction of domain-specific knowledge databases. Although the system may not yet have reached the level of performance required for fully automated operation, it could help human editors in their tasks by ranking verifiable structured recordings in an order.The next direction for future work is to consider multiple text sources, not just a single newspaper."}], "references": [{"title": "Rule based synonyms for entity extraction from noisy text", "author": ["R. Ananthanarayanan", "V. Chenthamarakshan", "P.M. Deshpande", "R. Krishnapuram"], "venue": "Proc. of AND,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Gene ontology: Tool for the unification of biology", "author": ["M. Ashburner"], "venue": "Nature Genetics, 25:25\u201329,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2000}, {"title": "Cumulative citation recommendation: Classification vs", "author": ["K. Balog", "H. Ramampiaro"], "venue": "ranking. In Proc. of SIGIR,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Multi-step classification approaches to cumulative citation recommendation", "author": ["K. Balog", "H. Ramampiaro", "N. Takhirov", "K. N\u00f8rv\u00e5g"], "venue": "Proc. of OAIR,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Multilingual semantic role labeling", "author": ["A. Bj\u00f6rkelund", "L. Hafdell", "P. Nugues"], "venue": "Proc. of CoNLL,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Time will tell: Temporal linking of news stories", "author": ["T. B\u00f6gel", "M. Gertz"], "venue": "Proc. of JCDL,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Random forests", "author": ["L. Breiman"], "venue": "Machine Learning, 45(1): 5\u201332, Oct.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2001}, {"title": "Toward an architecture for neverending language learning", "author": ["A. Carlson", "J. Betteridge", "B. Kisiel", "B. Settles", "E.R.H. Jr.", "T.M. Mitchell"], "venue": "In Proc. of AAAI,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "SUTime: a library for recognizing and normalizing time expressions", "author": ["A.X. Chang", "C.D. Manning"], "venue": "Proc.  of LREC,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Text Processing with GATE", "author": ["H. Cunningham", "D. Maynard", "K. Bontcheva", "V. Tablan", "N. Aswani", "I. Roberts", "G. Gorrell", "A. Funk", "A. Roberts", "D. Damljanovic", "T. Heitz", "M.A. Greenwood", "H. Saggion", "J. Petrak", "Y. Li", "W. Peters"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "YAGO2: a spatially and temporally enhanced knowledge base from Wikipedia", "author": ["J. Hoffart", "F.M. Suchanek", "K. Berberich", "G. Weikum"], "venue": "Artificial Intelligence, 194:28\u201361,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Semanticsbased information extraction for detecting economic events", "author": ["A. Hogenboom", "F. Hogenboom", "F. Frasincar", "K. Schouten", "O. van der Meer"], "venue": "Multimedia Tools and Applications,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "An overview of event extraction from text", "author": ["F. Hogenboom", "F. Frasincar", "U. Kaymak", "F. de Jong"], "venue": "In Proc. of DeRiVE,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Model-Driven Design Using Business Patterns", "author": ["P. Hruby"], "venue": "Springer,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}, {"title": "Knowledge base population: Successful approaches and challenges", "author": ["H. Ji", "R. Grishman"], "venue": "Proc. of ACL, pages 1148\u20131158,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "DBpedia - a large-scale, multilingual knowledge base extracted from Wikipedia", "author": ["J. Lehmann", "R. Isele", "M. Jakob", "A. Jentzsch", "D. Kontokostas", "P. Mendes", "S. Hellmann", "M. Morsey", "P. van Kleef", "S. Auer", "C. Bizer"], "venue": "Semantic Web Journal,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "The REA accounting model: A generalized framework for accounting systems in a shared data environment", "author": ["W.E. McCarthy"], "venue": "Accounting Review, 57(3):554,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1982}, {"title": "Entity linking and retrieval for semantic search", "author": ["E. Meij", "K. Balog", "D. Odijk"], "venue": "Proc. of WSDM,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "The NomBank project: An interim report", "author": ["A. Meyers", "R. Reeves", "C. Macleod", "R. Szekely", "V. Zielinska", "B. Young", "R. Grishman"], "venue": "Proc. of the HLT-NAACL Workshop on Frontiers in Corpus Annotation,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2004}, {"title": "Wordnet: A lexical database for english", "author": ["G.A. Miller"], "venue": "Communications of the ACM, 38(11):39\u201341,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1995}, {"title": "XBRL: impacts, issues and future research directions", "author": ["N. M\u00fcller-Wickop", "M. Schultz", "M. N\u00fcttgens"], "venue": "Proc. of FinanceCom,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "An automated framework for incorporating news into stock trading strategies", "author": ["V. Nuij", "V. Milea", "F. Hogenboom", "F. Frasincar", "U. Kaymak"], "venue": "IEEE TKDE, 26(4): 823\u2013835,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "The proposition bank: An annotated corpus of semantic roles", "author": ["M. Palmer", "D. Gildea", "P. Kingsbury"], "venue": "Comp. Linguistics, 31(1):71\u2013106,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2005}, {"title": "Theory and Applications of Ontology: Philosophical Perspectives", "author": ["R. Poli", "J. Seibt"], "venue": "Springer,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "The music ontology", "author": ["Y. Raimond", "S.A. Abdallah", "M.B. Sandler", "F. Giasson"], "venue": "Proc. of ISMIR,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "Information extraction", "author": ["S. Sarawagi"], "venue": "Foundations and Trends in Databases, 1(3):261\u2013377,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2008}, {"title": "Knowledge Representation: Logical, Philosophical, and Computational Foundations", "author": ["J.F. Sowa"], "venue": "Brooks/Cole,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1999}, {"title": "Event-centric search and exploration in document collections", "author": ["J. Str\u00f6tgen", "M. Gertz"], "venue": "Proc. of JCDL,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "YAGO: a large ontology from Wikipedia and WordNet", "author": ["F.M. Suchanek", "G. Kasneci", "G. Weikum"], "venue": "Web Semantics, 6(3):203\u2013217,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}, {"title": "Real-time news event extraction for global crisis monitoring", "author": ["H. Tanev", "J. Piskorski", "M. Atkinson"], "venue": "Proc. of NLDB,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2008}, {"title": "NewsReader: recording history from daily news streams", "author": ["P. Vossen", "G. Rigau", "L. Serafini", "P. Stouten", "F. Irving", "W.V. Hage"], "venue": "Proc. of LREC,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "Temporal knowledge for timely intelligence", "author": ["G. Weikum", "S. Bedathur", "R. Schenkel"], "venue": "Proc. of BIRTE,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2011}, {"title": "TOB: timely ontologies for business relations", "author": ["Q. Zhang", "F.M. Suchanek", "L. Yue", "G. Weikum"], "venue": "Proc. of WebDB,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 25, "context": "Event extraction is a specialized branch of information extraction [26] that has attracted a lot of attention in recent years.", "startOffset": 67, "endOffset": 71}, {"referenceID": 29, "context": "Automated extraction techniques play a crucial role in aiding humans in knowledge-intensive activities in various domains, including global crisis monitoring [30], and algorithmic trading [22].", "startOffset": 158, "endOffset": 162}, {"referenceID": 21, "context": "Automated extraction techniques play a crucial role in aiding humans in knowledge-intensive activities in various domains, including global crisis monitoring [30], and algorithmic trading [22].", "startOffset": 188, "endOffset": 192}, {"referenceID": 12, "context": "The main approaches and implementations of event extraction from text are well summarized in [13].", "startOffset": 93, "endOffset": 97}, {"referenceID": 11, "context": "[12] present a semantic-based pipeline for the detection of economic events (SPEED).", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[31] describe the NewsReader project and the design of a system aiming at representing events in news streams in a knowledge graph.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "Given the chronological nature of news, the temporal dimension is a common perspective for event exploration [6].", "startOffset": 109, "endOffset": 112}, {"referenceID": 27, "context": "Str\u00f6tgen and Gertz [28] combine time and location for deriving events, however, compared to our work, they do not consider multiple reporting of the same event.", "startOffset": 19, "endOffset": 23}, {"referenceID": 1, "context": ", biology [2], music [25], or law [24].", "startOffset": 10, "endOffset": 13}, {"referenceID": 24, "context": ", biology [2], music [25], or law [24].", "startOffset": 21, "endOffset": 25}, {"referenceID": 23, "context": ", biology [2], music [25], or law [24].", "startOffset": 34, "endOffset": 38}, {"referenceID": 16, "context": "The Resource Event Agent (REA) ontology, based on the model developed by [17], represents economic events in an organization from an accounting perspective.", "startOffset": 73, "endOffset": 77}, {"referenceID": 26, "context": "This model was further analyzed from the ontological perspective using Sowa\u2019s conceptual terminology [27] and is widely used since, either in its core form or in extended versions.", "startOffset": 101, "endOffset": 105}, {"referenceID": 32, "context": "The Timely Ontologies for Business Relations (TOB) framework [33] focuses on business relations and extends the well-known YAGO ontology [29] with a means to represent underspecified time intervals.", "startOffset": 61, "endOffset": 65}, {"referenceID": 28, "context": "The Timely Ontologies for Business Relations (TOB) framework [33] focuses on business relations and extends the well-known YAGO ontology [29] with a means to represent underspecified time intervals.", "startOffset": 137, "endOffset": 141}, {"referenceID": 20, "context": "XBRL (eXtensible Business Reporting Language) is a markup language, with provided taxonomies, that is nowadays widely used by some of the world\u2019s largest economies [21].", "startOffset": 164, "endOffset": 168}, {"referenceID": 17, "context": "Knowledge bases, containing rich semantic knowledge about entities, their properties, and relationships, have become great assets for many applications, including semantic search [18] and business intelligence [32].", "startOffset": 179, "endOffset": 183}, {"referenceID": 31, "context": "Knowledge bases, containing rich semantic knowledge about entities, their properties, and relationships, have become great assets for many applications, including semantic search [18] and business intelligence [32].", "startOffset": 210, "endOffset": 214}, {"referenceID": 7, "context": ", [8, 11, 15, 4, 3].", "startOffset": 2, "endOffset": 19}, {"referenceID": 10, "context": ", [8, 11, 15, 4, 3].", "startOffset": 2, "endOffset": 19}, {"referenceID": 14, "context": ", [8, 11, 15, 4, 3].", "startOffset": 2, "endOffset": 19}, {"referenceID": 3, "context": ", [8, 11, 15, 4, 3].", "startOffset": 2, "endOffset": 19}, {"referenceID": 2, "context": ", [8, 11, 15, 4, 3].", "startOffset": 2, "endOffset": 19}, {"referenceID": 15, "context": "General-purpose knowledge bases, such as DBpedia [16], Freebase, or YAGO [29], cover thousands of business entities; however, they contain limited information regarding financial transactions.", "startOffset": 49, "endOffset": 53}, {"referenceID": 28, "context": "General-purpose knowledge bases, such as DBpedia [16], Freebase, or YAGO [29], cover thousands of business entities; however, they contain limited information regarding financial transactions.", "startOffset": 73, "endOffset": 77}, {"referenceID": 16, "context": "Our starting point is the REA (Resource, Event, Agent) model [17] that is often used as a foundational model for describing business-related concepts; it is briefly introduced in Sect.", "startOffset": 61, "endOffset": 65}, {"referenceID": 19, "context": "OEE is created using a semi-supervised method that starts with a set of seed verbs and then expands them using the WordNet lexical ontology [20].", "startOffset": 140, "endOffset": 144}, {"referenceID": 13, "context": "Following Hruby [14], we differentiate between two major economic event types: events increasing and decreasing the value of agent\u2019s resources.", "startOffset": 16, "endOffset": 20}, {"referenceID": 9, "context": "Beyond recognition, value and currency normalization are also performed in this step using an extended Numbers Tagger in GATE [10].", "startOffset": 126, "endOffset": 130}, {"referenceID": 19, "context": "III) which starts with a set of seed verbs and then expands them using the WordNet lexical ontology [20].", "startOffset": 100, "endOffset": 104}, {"referenceID": 22, "context": "For each of the predicates, the corresponding semantic frame set from PropBank [23] is extracted.", "startOffset": 79, "endOffset": 83}, {"referenceID": 18, "context": "We do so by leveraging the NomBank dataset [19]; each noun in NomBank, provided it originates from a verb, contains an identifier of its source (verb counterpart) in PropBank.", "startOffset": 43, "endOffset": 47}, {"referenceID": 14, "context": "Despite being a naive way of resolving ambiguity, this technique works well in practice [15].", "startOffset": 88, "endOffset": 92}, {"referenceID": 8, "context": ", \u2018two days ago\u2019) temporal expressions within the sentence are annotated and normalized by the Stanford Temporal Tagger (SUTime) [9].", "startOffset": 129, "endOffset": 132}, {"referenceID": 4, "context": "[5].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "Specifically, we use the Random Forests algorithm [7], given its robustness and good empirical performance across a wide range of application domains.", "startOffset": 50, "endOffset": 53}, {"referenceID": 0, "context": "Therefore, on top of the known surface forms, we generate additional name variants using a set of heuristics, similar to those described in [1].", "startOffset": 140, "endOffset": 143}], "year": 2017, "abstractText": "We address the problem of extracting structured representations of economic events from a large corpus of news articles, using a combination of natural language processing and machine learning techniques. The developed techniques allow for semi-automatic population of a financial knowledge base, which, in turn, may be used to support a range of data mining and exploration tasks. The key challenge we face in this domain is that the same event is often reported multiple times, with varying correctness of details. We address this challenge by first collecting all information pertinent to a given event from the entire corpus, then considering all possible representations of the event, and finally, using a supervised learning method, to rank these representations by the associated confidence scores. A main innovative element of our approach is that it jointly extracts and stores all attributes of the event as a single representation (quintuple). Using a purpose-built test set we demonstrate that our supervised learning approach can achieve 25% improvement in F1-score over baseline methods that consider the earliest, the latest or the most frequent reporting of the event.", "creator": "LaTeX with hyperref package"}}}