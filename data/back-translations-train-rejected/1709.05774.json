{"id": "1709.05774", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Sep-2017", "title": "Direction-Aware Semi-Dense SLAM", "abstract": "To aide simultaneous localization and mapping (SLAM), future perception systems will incorporate forms of scene understanding. In a step towards fully integrated probabilistic geometric scene understanding, localization and mapping we propose the first direction-aware semi-dense SLAM system. It jointly infers the directional Stata Center World (SCW) segmentation and a surfel-based semi-dense map while performing real-time camera tracking. The joint SCW map model connects a scene-wide Bayesian nonparametric Dirichlet Process von-Mises-Fisher mixture model (DP-vMF) prior on surfel orientations with the local surfel locations via a conditional random field (CRF). Camera tracking leverages the SCW segmentation to improve efficiency via guided observation selection. Results demonstrate improved SLAM accuracy and tracking efficiency at state of the art performance.", "histories": [["v1", "Mon, 18 Sep 2017 04:49:40 GMT  (2510kb,D)", "http://arxiv.org/abs/1709.05774v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["julian straub", "randi cabezas", "john leonard", "john w fisher iii"], "accepted": false, "id": "1709.05774"}, "pdf": {"name": "1709.05774.pdf", "metadata": {"source": "CRF", "title": "Direction-Aware Semi-Dense SLAM", "authors": ["Julian Straub", "Randi Cabezas", "John Leonard", "John W. Fisher"], "emails": [], "sections": [{"heading": null, "text": "Future perception systems in applications such as autonomous cars, autonomous robots, or augmented reality will integrate scene understanding into purely geometric localization and mapping, which is likely to improve both simultaneous localization and mapping (SLAM), provide a basis for overarching thinking about the scene, and provide richer information for human operators. In current systems, scene understanding is used in two ways: (1) to improve the operation of the 3D perception system, and (2) to provide additional information for superordinate inferences or a human operator. We argue that only systems in the first class actually \"understand\" aspects of the scene because they are able to use inferred concepts to improve their other inferential tasks (i.e., localization and mapping). The number of systems that fall into this class is still small."}, {"heading": "1. Related Work", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "2. Direction-Aware Semi-Dense SLAM", "text": "We define directional SLAM as considerations of the common distribution of a world map m, the trajectory of the perception system and the directed segmentation of z given observations x. Specifically, we represent the map as a series of surfaces [21, 48, 17]. Surfaces are localized planes with position pi, orientation ni, color Ii and radius ri. For notational clarity, we leave si = {pi, ni, Ii, ri} all properties of the surface i. SCW segmentation is expressed by surface labels {zi}. The world is observed by an RGB-D camera in which the surfaces {Tt} are indexed, with t the pose being indexed when receiving the tth camera image. From the RGBD image we get point observations xp, normal surface observations xn, and surface color Ic. We collect all observations of the tth frame in variable xt = xc, xp} Ip."}, {"heading": "3. Direction-aware Camera Pose Estimation", "text": "For each observed RGBD frame, we run the iterative narrowest point (ICP) algorithm to find a local optimum of the camera perspective and data association between the observations and the global map. Optimizing the camera perspective results in a projected data association A that results in maximizing the negative log probability of the camera: T? = arg minT (3) fp2pl (T) + \u03bbIfphoto (T) (5) fp2pl = [1] p-2pl, i [2] nTi (Tx p i \u2212 pi) p (6) fphoto = [1] p-2I] p (T) pi))). \u2212 Ii (7), where a 3D dot is projected into the image space. Note: While we use the familiar notation for surfel properties (here ni, pi), estimates projected in practice."}, {"heading": "4. Directional Segmentation", "text": "In the framework of the Stata Center World model, we assume that the normal distribution of the surface of Surfel exhibits characteristic patterns of low entropy, as used in related work by Straub and al. [45, 43, 44]. Similar to [43], we capture the notion of the Stata Center World model that the normal distribution of the surface of Surfel consists of a variable, unknown number of clusters by a Dirichlet method of von-Mises-Fisher mixing model. Following [36], we perform the spatial smoothness of the Stata Center World model by assuming a Markov random field (MRF) over the segmentation z, which means uniform labeling across a number of adjacent surfaces of Surfel i. From a generative point of view, this model initially assumes a numerically infinite amount of MRF weights and the distribution of MRF-MisesFisher."}, {"heading": "5. Direction-aware Mapping", "text": "We use another Markov random field over adjacent surfaces to express a local planarity assumption over points in the same directional segment. MRF combines scenewide directional segmentation with local spatial properties. MRF potential, which encompasses the local planarity, is achieved by symmetrizing the well-known point-to-level distance function used in the implementation of ICP [38]: exp (\u2212 1zizj 2\u03c32pl (\u30fb nTi (pj \u2212 pi) \u0445 22 + \u0435nTj (pi \u2212 pj) \u0445 22))))). (14) While the point-to-level cost function punishes the deviation of a point outside the plane, the MRF potential applied here can be considered a product of two Gausser with a deviation from the plane over the respective other surf position."}, {"heading": "5.1. Observation Models for Mapping", "text": "The observation covariances are calculated using a realistic depth camera model [34] and include the linearized camera in the viewing angles of Oi N (x p j; T \u2212 1 t pi, p, j). (15) The observation covariances are calculated using a realistic depth camera model [34] and include the linearized camera in the viewing angles of Oi N (x p j; T \u2212 1 t pi, p, j). The observation covariances are calculated using a realistic depth camera model."}, {"heading": "6. Sampling-based Inference over SCW Map", "text": "We now turn to the public to describe how we respond to the common SCW card models that have given us observations. (xn, Ic) Derivative Camera Tt. (n) Because segmentation entails an unforeseen distribution, we rely on Gibb's sampling model, which depends on the actual distribution in the limitation of sampling distributions. (n) Below, we provide details of the sampling distributions before detailing how the sampler distributions are used to inform camera distributions. (n) Sampling Normals ni Via Bayes' Law, the conditional distribution of the surf direction ni, p (ni xnj) p, z), is proportional top (ni xnj) p."}, {"heading": "6.1. Estimates Computed from the Samples", "text": "We use the Gibbs sampler samples to approximate the mean values and variances of surf locations and orientations. In practice, since the boundary distributions p (pi) or p (ni) are largely focused on a single mode, the estimates converge quickly. In our experiments of the order of ten samples, we estimate the mean p (i) and the variance of the surf site using the cumulative statistics p (i) Si (p) j (p) j (p) j (p) p (p) p (p) i (p) p (i i i i i i i i (p) p (i) p (i) p (p) (p) (p) (p) (p) (p) i (p) (p) (p) (p) (p) (p) (p) (p) (p) (p) p (p) (p) p (p) (p) p (p) (p) p (p) (p) (p) (p) (p) (p) (p) (p) (p) (p) (p) (p) (p) (p) (p) (p) (p) (p) (p) p) (p) (p) (p) p (p) (p) p (p) (p) p (p) (p) p (p) (p) (p) p (p) (p) p (p (p) (p) (p) p (p (p) (p) p (p)."}, {"heading": "7. Implementation", "text": "In practice, we are using a multi-thread system as illustrated in Fig. 2 for the proposed approach; the five most important threads are (1) real-time data acquisition, camera tracking and observation thread, (2) a thread of the nearest neighbourhood diagram, and (3-5) three Gibbs sample threads. Camera tracking uses RGBD frames and the most likely estimate of segmentation and surf map to derive the current camera position T. To handle fast motion, we perform photometric rotation anticipation through [27] from image pyramid plane 3 down to 1. For the same reason, we are adding directional ICP samples from pyramid planes 1 to 0. The observation algorithm adds new surfaces by evenly scanning previously unobserved surfaces with an inclination to surfaces with an inclination to high-gradient surfaces."}, {"heading": "8. Evaluation and Results", "text": "The following are the proposed guidelines for the reconstruction of the limbs in relation to the limbs of the limbs of the limbs of the limbs of the limbs of the limbs of the limbs of the limbs of the limbs of the limbs of the limbs of the limbs of the limbs of the limbs of the limbs of the limbs of the limbs of the limbs."}, {"heading": "9. Conclusion", "text": "We have introduced the first direction-aware semi-dense SLAM system that collectively deduces directional segmentation, surf-based map, and camera position, and its sense of direction manifests itself in the fact that it can use directional segmentation for its other tasks. Gibbssampling-based deduction of Bayesia's complex non-parametric segmentation and map model in a real-time reconstruction system has not yet been demonstrated, and the flexibility of Gibbs sampling provides exciting possibilities for deduplicating more complex and detailed environmental models, as well as access to samples from the back to reflect on uncertainties that are not possible with the commonly used fashion search methods."}], "references": [{"title": "Fast and accurate computation of surface normals from range images", "author": ["H. Badino", "D. Huber", "Y. Park", "T. Kanade"], "venue": "ICRA, pages 3084\u20133091.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Semantic structure from motion with points, regions, and objects", "author": ["S.Y. Bao", "M. Bagra", "Y.-W. Chao", "S. Savarese"], "venue": "CVPR, pages 2703\u20132710.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Semantic structure from motion", "author": ["S.Y. Bao", "S. Savarese"], "venue": "CVPR, pages 2025\u20132032.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "An antipodally symmetric distribution on the sphere", "author": ["C. Bingham"], "venue": "The Annals of Statistics, 2(6):1201\u20131225,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1974}, {"title": "Ferguson distributions via p\u00f3lya urn schemes", "author": ["D. Blackwell", "J.B. MacQueen"], "venue": "The Annals of Statistics, pages 353\u2013 355,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1973}, {"title": "Vanishing points and three-dimensional lines from omni-directional video", "author": ["M. Bosse", "R. Rikoski", "J. Leonard", "S. Teller"], "venue": "The Visual Computer, 19(6):417\u2013430,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Products and convolutions of Gaussian probability density functions", "author": ["P. Bromiley"], "venue": "Technical Report Tina Memo No. 2003-003,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "Semantically- Aware Aerial Reconstruction from Multi-Modal Data", "author": ["R. Cabezas", "J. Straub", "J.W. Fisher III"], "venue": "ICCV,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Explaining the gibbs sampler", "author": ["G. Casella", "E. George"], "venue": "The American Statistician, 46(3):167\u2013174,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1992}, {"title": "Towards simultaneous recognition, localization and mapping for hand-held and wearable cameras", "author": ["R.O. Castle", "D. Gawley", "G. Klein", "D.W. Murray"], "venue": "ICRA,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Mathematical Methods of Statistics, volume 9", "author": ["H. Cram\u00e9r"], "venue": "Princeton University Press,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "BundleFusion: Real-time Globally Consistent 3D Reconstruction using On-the-fly Surface Re-integration TOG, 2017", "author": ["A. Dai", "M. Nie\u00dfner", "M. Zollh\u00f6fer", "S. Izadi", "C. Theobalt"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2017}, {"title": "Real-time simultaneous localisation and mapping with a single camera", "author": ["A.J. Davison"], "venue": "ICCV,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2003}, {"title": "Fast image-based tracking by selective pixel integration", "author": ["F. Dellaert", "R. Collins"], "venue": "Proceedings of the ICCV Workshop on Frame-Rate Vision,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1999}, {"title": "LSD-SLAM: Largescale direct monocular SLAM", "author": ["J. Engel", "T. Sch\u00f6ps", "D. Cremers"], "venue": "ECCV,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Joint detection, tracking and mapping by semantic bundle adjustment", "author": ["N. Fioraio", "L. Di Stefano"], "venue": "CVPR,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "A surface-growing approach to multi-view stereo reconstruction", "author": ["M. Habbecke", "L. Kobbelt"], "venue": "CVPR,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2007}, {"title": "A benchmark for RGB-D visual odometry, 3D reconstruction and SLAM", "author": ["A. Handa", "T. Whelan", "J. McDonald", "A.J. Davison"], "venue": "ICRA,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Analyzing hogwild parallel Gaussian Gibbs sampling", "author": ["M. Johnson", "J. Saunderson", "A. Willsky"], "venue": "NIPS,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Simultaneous localization and mapping with infinite planes", "author": ["M. Kaess"], "venue": "ICRA,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Real-time 3D reconstruction in dynamic scenes using point-based fusion", "author": ["M. Keller", "D. Lefloch", "M. Lambers", "S. Izadi", "T. Weyrich", "A. Kolb"], "venue": "International Conference on 3DTV-Conference,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Dense visual SLAM for RGB-D cameras", "author": ["C. Kerl", "J. Sturm", "D. Cremers"], "venue": "IROS,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Robust odometry estimation for RGB-D cameras", "author": ["C. Kerl", "J. Sturm", "D. Cremers"], "venue": "ICRA,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "3D scene understanding by voxel-CRF", "author": ["B.-s. Kim", "P. Kohli", "S. Savarese"], "venue": "In ICCV,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2013}, {"title": "Parallel tracking and mapping on a camera phone", "author": ["G. Klein", "D. Murray"], "venue": "ISMAR,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "Joint semantic segmentation and 3D reconstruction from monocular video", "author": ["A. Kundu", "Y. Li", "F. Dellaert", "F. Li", "J.M. Rehg"], "venue": "ECCV,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Real-time spherical mosaicing using whole image alignment", "author": ["S. Lovegrove", "A.J. Davison"], "venue": "ECCV,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "CPA-SLAM: Consistent plane-model alignment for direct RGB-D SLAM", "author": ["L. Ma", "C. Kerl", "J. Stueckler", "D. Cremers"], "venue": "ICRA,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2016}, {"title": "ORB- SLAM: a versatile and accurate monocular SLAM system", "author": ["R. Mur-Artal", "J.M.M. Montiel", "J.D. Tardos"], "venue": "Transactions on Robotics, 31(5):1147\u20131163,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Indoor segmentation and support inference from RGBD images", "author": ["P.K. Nathan Silberman", "Derek Hoiem", "R. Fergus"], "venue": "In ECCV,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Markov chain sampling methods for Dirichlet process mixture models", "author": ["R. Neal"], "venue": "Journal of computational and graphical statistics, 9(2):249\u2013265,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2000}, {"title": "Kinectfusion: Real-time dense surface mapping and tracking", "author": ["R.A. Newcombe", "A.J. Davison", "S. Izadi", "P. Kohli", "O. Hilliges", "J. Shotton", "D. Molyneaux", "S. Hodges", "D. Kim", "A. Fitzgibbon"], "venue": "ISMAR,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2011}, {"title": "DTAM: Dense tracking and mapping in real-time", "author": ["R.A. Newcombe", "S.J. Lovegrove", "A.J. Davison"], "venue": "ICCV,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2011}, {"title": "Modeling Kinect sensor noise for improved 3D reconstruction and tracking", "author": ["C.V. Nguyen", "S. Izadi", "D. Lovell"], "venue": "3DIMPVT,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2012}, {"title": "A Bayesian analysis of directional data using the von Mises-Fisher distribution", "author": ["G. Nunez-Antonio", "E. Guti\u00e9rrez-Pena"], "venue": "Communications in StatisticsSimulation and Computation R  \u00a9, 34(4):989\u2013999,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2005}, {"title": "Smooth image segmentation by nonparametric Bayesian inference", "author": ["P. Orbanz", "J. Buhmann"], "venue": "ECCV,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2006}, {"title": "Accurate on-line 3D occupancy grids using Manhattan world constraints", "author": ["B. Peasley", "S. Birchfield", "A. Cunningham", "F. Dellaert"], "venue": "IROS,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}, {"title": "Efficient variants of the ICP algorithm", "author": ["S. Rusinkiewicz", "M. Levoy"], "venue": "International Conference on 3-D Digital Imaging and Modeling,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2001}, {"title": "Dense planar SLAM", "author": ["R.F. Salas-Moreno", "B. Glocken", "P.H. Kelly", "A.J. Davison"], "venue": "ISMAR,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2014}, {"title": "SLAM++: Simultaneous localisation and mapping at the level of objects", "author": ["R.F. Salas-Moreno", "R.A. Newcombe", "H. Strasdat", "P.H. Kelly", "A.J. Davison"], "venue": "CVPR,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2013}, {"title": "Generalized-ICP", "author": ["A. Segal", "D. Haehnel", "S. Thrun"], "venue": "RSS,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2009}, {"title": "Nonparametric Directional Perception", "author": ["J. Straub"], "venue": "PhD thesis, Massachusetts Institute of Technology,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2017}, {"title": "Smallvariance nonparametric clustering on the hypersphere", "author": ["J. Straub", "T. Campbell", "J.P. How", "J.W. Fisher III"], "venue": "CVPR,", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2015}, {"title": "A dirichlet process mixture model for spherical data", "author": ["J. Straub", "J. Chang", "O. Freifeld", "J.W. Fisher III"], "venue": "AISTATS,", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2015}, {"title": "The Manhattan frame model \u2013 Manhattan world inference in the space of surface normals", "author": ["J. Straub", "G. Rosman", "O. Freifeld", "J.J. Leonard", "J.W. Fisher III"], "venue": "TPAMI,", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2017}, {"title": "A benchmark for the evaluation of RGB-D SLAM systems", "author": ["J. Sturm", "N. Engelhard", "F. Endres", "W. Burgard", "D. Cremers"], "venue": "IROS,", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2012}, {"title": "Computer generation of distributions on the msphere", "author": ["G. Ulrich"], "venue": "Applied Statistics, pages 158\u2013163,", "citeRegEx": "47", "shortCiteRegEx": null, "year": 1984}, {"title": "In-hand scanning with online loop closure", "author": ["T. Weise", "T. Wismer", "B. Leibe", "L. Van Gool"], "venue": "ICCV Workshops,", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2009}, {"title": "Kintinuous: Spatially extended kinectfusion", "author": ["T. Whelan", "M. Kaess", "M. Fallon", "H. Johannsson", "J. Leonard", "J. McDonald"], "venue": null, "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2012}, {"title": "Elasticfusion: Real-time dense SLAM and light source estimation", "author": ["T. Whelan", "R.F. Salas-Moreno", "B. Glocker", "A.J. Davison", "S. Leutenegger"], "venue": "IJRR, pages 1697\u20131716,", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2016}, {"title": "Sun3D: A database of big spaces reconstructed using SFM and object labels", "author": ["J. Xiao", "A. Owens", "A. Torralba"], "venue": "ICCV,", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 9, "context": "In order to improve 3D reconstruction and localization via scene understanding most approaches rely on geometric scene priors such as planarity [10, 39, 20, 28], the Manhattan World [37] (MW) or the Stata Center World [6] (SCW) assumption.", "startOffset": 144, "endOffset": 160}, {"referenceID": 38, "context": "In order to improve 3D reconstruction and localization via scene understanding most approaches rely on geometric scene priors such as planarity [10, 39, 20, 28], the Manhattan World [37] (MW) or the Stata Center World [6] (SCW) assumption.", "startOffset": 144, "endOffset": 160}, {"referenceID": 19, "context": "In order to improve 3D reconstruction and localization via scene understanding most approaches rely on geometric scene priors such as planarity [10, 39, 20, 28], the Manhattan World [37] (MW) or the Stata Center World [6] (SCW) assumption.", "startOffset": 144, "endOffset": 160}, {"referenceID": 27, "context": "In order to improve 3D reconstruction and localization via scene understanding most approaches rely on geometric scene priors such as planarity [10, 39, 20, 28], the Manhattan World [37] (MW) or the Stata Center World [6] (SCW) assumption.", "startOffset": 144, "endOffset": 160}, {"referenceID": 36, "context": "In order to improve 3D reconstruction and localization via scene understanding most approaches rely on geometric scene priors such as planarity [10, 39, 20, 28], the Manhattan World [37] (MW) or the Stata Center World [6] (SCW) assumption.", "startOffset": 182, "endOffset": 186}, {"referenceID": 5, "context": "In order to improve 3D reconstruction and localization via scene understanding most approaches rely on geometric scene priors such as planarity [10, 39, 20, 28], the Manhattan World [37] (MW) or the Stata Center World [6] (SCW) assumption.", "startOffset": 218, "endOffset": 221}, {"referenceID": 42, "context": "As shown in [43, 44], the directional clustering of a scene\u2019s surface normals under the Stata Center World implies a segmentation that captures scene-wide regularities of the environment [45] as can be seen in the segmentation in Fig.", "startOffset": 12, "endOffset": 20}, {"referenceID": 43, "context": "As shown in [43, 44], the directional clustering of a scene\u2019s surface normals under the Stata Center World implies a segmentation that captures scene-wide regularities of the environment [45] as can be seen in the segmentation in Fig.", "startOffset": 12, "endOffset": 20}, {"referenceID": 44, "context": "As shown in [43, 44], the directional clustering of a scene\u2019s surface normals under the Stata Center World implies a segmentation that captures scene-wide regularities of the environment [45] as can be seen in the segmentation in Fig.", "startOffset": 187, "endOffset": 191}, {"referenceID": 12, "context": "Among the wealth of recent 3D SLAM systems [13, 25, 33, 32, 49, 50, 29, 15, 12], there are only few who", "startOffset": 43, "endOffset": 79}, {"referenceID": 24, "context": "Among the wealth of recent 3D SLAM systems [13, 25, 33, 32, 49, 50, 29, 15, 12], there are only few who", "startOffset": 43, "endOffset": 79}, {"referenceID": 32, "context": "Among the wealth of recent 3D SLAM systems [13, 25, 33, 32, 49, 50, 29, 15, 12], there are only few who", "startOffset": 43, "endOffset": 79}, {"referenceID": 31, "context": "Among the wealth of recent 3D SLAM systems [13, 25, 33, 32, 49, 50, 29, 15, 12], there are only few who", "startOffset": 43, "endOffset": 79}, {"referenceID": 48, "context": "Among the wealth of recent 3D SLAM systems [13, 25, 33, 32, 49, 50, 29, 15, 12], there are only few who", "startOffset": 43, "endOffset": 79}, {"referenceID": 49, "context": "Among the wealth of recent 3D SLAM systems [13, 25, 33, 32, 49, 50, 29, 15, 12], there are only few who", "startOffset": 43, "endOffset": 79}, {"referenceID": 28, "context": "Among the wealth of recent 3D SLAM systems [13, 25, 33, 32, 49, 50, 29, 15, 12], there are only few who", "startOffset": 43, "endOffset": 79}, {"referenceID": 14, "context": "Among the wealth of recent 3D SLAM systems [13, 25, 33, 32, 49, 50, 29, 15, 12], there are only few who", "startOffset": 43, "endOffset": 79}, {"referenceID": 11, "context": "Among the wealth of recent 3D SLAM systems [13, 25, 33, 32, 49, 50, 29, 15, 12], there are only few who", "startOffset": 43, "endOffset": 79}, {"referenceID": 9, "context": "[10] are among the visual SLAM systems to incorporate planar geometry.", "startOffset": 0, "endOffset": 4}, {"referenceID": 38, "context": "[39] integrate plane segmentation into the tracking and reconstruction pipeline of a dense surfel-based reconstruction system.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "Kaess [20] explores a plane-based SLAM formulation wherein the map directly consists of infinite planes which are being jointly optimized with the camera pose in a smoothing and mapping (SAM).", "startOffset": 6, "endOffset": 10}, {"referenceID": 27, "context": "[28] demonstrate joint inference over a key-frame-based map and a plane segmentation of the environment.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "Furthermore sampling-based inference allows soft associations to directions that can be refined and corrected whereas all but the EM-based CPA-SLAM [28] make hard assignments to specific planes that are not revisited [10, 39, 20].", "startOffset": 148, "endOffset": 152}, {"referenceID": 9, "context": "Furthermore sampling-based inference allows soft associations to directions that can be refined and corrected whereas all but the EM-based CPA-SLAM [28] make hard assignments to specific planes that are not revisited [10, 39, 20].", "startOffset": 217, "endOffset": 229}, {"referenceID": 38, "context": "Furthermore sampling-based inference allows soft associations to directions that can be refined and corrected whereas all but the EM-based CPA-SLAM [28] make hard assignments to specific planes that are not revisited [10, 39, 20].", "startOffset": 217, "endOffset": 229}, {"referenceID": 19, "context": "Furthermore sampling-based inference allows soft associations to directions that can be refined and corrected whereas all but the EM-based CPA-SLAM [28] make hard assignments to specific planes that are not revisited [10, 39, 20].", "startOffset": 217, "endOffset": 229}, {"referenceID": 36, "context": "[37] who use the Manhattan World assumption to impose global constraints on the 2D trajectory of a robot.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[6] essentially use the SCW assumption in the image space via vanishing point (VP) detection.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3, 2] jointly estimate object and region segmentation of a sparse point cloud in the batch structure from motion framework.", "startOffset": 0, "endOffset": 6}, {"referenceID": 1, "context": "[3, 2] jointly estimate object and region segmentation of a sparse point cloud in the batch structure from motion framework.", "startOffset": 0, "endOffset": 6}, {"referenceID": 15, "context": "[16] jointly perform incremental object detection, mapping and camera pose estimation in what they call semantic bundle adjustment.", "startOffset": 0, "endOffset": 4}, {"referenceID": 50, "context": "[51] show how enforcing semantic label consistency in a 3D reconstruction system leads to better 3D reconstruction by decreasing drift and correcting loop closures.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] jointly use dense image segmentation and the raw RGB image captured from a single camera to infer the camera trajectory and, using a conditional random field (CRF) defined over an occupancy grid, a semantic 3D reconstruction.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] use a voxelbased world representation and, for a given RGBD image, Sensor", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "[40] are the first to demonstrate a SLAM system that utilizes dense 3D object models as beacons for camera tracking and map representation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[8] use a mixture-model over scene features (appearance, surface normals and semantic observations) as a prior-probability model to discover and encourage scene-wide structure.", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "Concretely, we represent the map as a set of surfels [21, 48, 17].", "startOffset": 53, "endOffset": 65}, {"referenceID": 47, "context": "Concretely, we represent the map as a set of surfels [21, 48, 17].", "startOffset": 53, "endOffset": 65}, {"referenceID": 16, "context": "Concretely, we represent the map as a set of surfels [21, 48, 17].", "startOffset": 53, "endOffset": 65}, {"referenceID": 29, "context": "The plots summarize statistics over all of the scenes in the NYU v2 dataset [30].", "startOffset": 76, "endOffset": 80}, {"referenceID": 20, "context": "Instead of aiming to represent all surfaces in the environment densely, as in related work [21, 48, 17], we sample the surfaces of the environment sparsely with a bias towards high intensity gradient areas for two reasons: (1) a sparse sampling of environment surface captures the majority of surfaces and scene structure, (2) a bias towards high intensity gradient areas captures visually salient regions for camera tracking [15].", "startOffset": 91, "endOffset": 103}, {"referenceID": 47, "context": "Instead of aiming to represent all surfaces in the environment densely, as in related work [21, 48, 17], we sample the surfaces of the environment sparsely with a bias towards high intensity gradient areas for two reasons: (1) a sparse sampling of environment surface captures the majority of surfaces and scene structure, (2) a bias towards high intensity gradient areas captures visually salient regions for camera tracking [15].", "startOffset": 91, "endOffset": 103}, {"referenceID": 16, "context": "Instead of aiming to represent all surfaces in the environment densely, as in related work [21, 48, 17], we sample the surfaces of the environment sparsely with a bias towards high intensity gradient areas for two reasons: (1) a sparse sampling of environment surface captures the majority of surfaces and scene structure, (2) a bias towards high intensity gradient areas captures visually salient regions for camera tracking [15].", "startOffset": 91, "endOffset": 103}, {"referenceID": 14, "context": "Instead of aiming to represent all surfaces in the environment densely, as in related work [21, 48, 17], we sample the surfaces of the environment sparsely with a bias towards high intensity gradient areas for two reasons: (1) a sparse sampling of environment surface captures the majority of surfaces and scene structure, (2) a bias towards high intensity gradient areas captures visually salient regions for camera tracking [15].", "startOffset": 426, "endOffset": 430}, {"referenceID": 29, "context": "3 across all 1449 scenes of the NYU v2 dataset [30].", "startOffset": 47, "endOffset": 51}, {"referenceID": 49, "context": "This cost function combines a point-to-plane (p2pl) and a photometric (photo) cost as employed by [50].", "startOffset": 98, "endOffset": 102}, {"referenceID": 40, "context": "The probabilistic interpretation was developed in [41] and an extension to include a photometric term is straight forward [23].", "startOffset": 50, "endOffset": 54}, {"referenceID": 22, "context": "The probabilistic interpretation was developed in [41] and an extension to include a photometric term is straight forward [23].", "startOffset": 122, "endOffset": 126}, {"referenceID": 21, "context": "[22] the term JJ is the Fisher information matrix of the estimator.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "The variance of the estimate can be lower-bound by the Fisher information matrix using the Cramer-Rao bound [11].", "startOffset": 108, "endOffset": 112}, {"referenceID": 13, "context": "[14], the proposed ICP variant selectively integrates informative observations which decreases the number of necessary observations in practice and thus speeds up camera tracking.", "startOffset": 0, "endOffset": 4}, {"referenceID": 44, "context": "[45, 43, 44].", "startOffset": 0, "endOffset": 12}, {"referenceID": 42, "context": "[45, 43, 44].", "startOffset": 0, "endOffset": 12}, {"referenceID": 43, "context": "[45, 43, 44].", "startOffset": 0, "endOffset": 12}, {"referenceID": 42, "context": "Similar to [43], we capture the notion of the Stata Center World model, that the surfel surface normal distribution consists of some variable, unknown number of clusters by a Dirichlet process von-Mises-Fisher mixture model.", "startOffset": 11, "endOffset": 15}, {"referenceID": 35, "context": "Following the proposal of [36], we impose spatial smoothness of the Stata Center World segmentation by assuming a Markov random field (MRF) over the segmentation z that encourages uniform labeling inside a set Ni of neighboring surfels of surfel i.", "startOffset": 26, "endOffset": 30}, {"referenceID": 34, "context": "To define the base measure, we utilize the conjugate prior for the von-Mises-Fisher distribution which in general is only known up to proportionality [35]:", "startOffset": 150, "endOffset": 154}, {"referenceID": 37, "context": "The MRF potential \u03a8 ij(pi, ni, pj , nj , z) that encapsulates local planarity is obtained by symmetrizing the well known point-to-plane distance function used in implementations of ICP [38]:", "startOffset": 185, "endOffset": 189}, {"referenceID": 31, "context": "Associations between RGB-D observations and map surfels are established using projective data association [32].", "startOffset": 106, "endOffset": 110}, {"referenceID": 33, "context": "The observation covariances \u03a3p,j are computed according to a realistic depth camera noise model [34] and incorporate the linearized camera pose uncertainty:", "startOffset": 96, "endOffset": 100}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 33, "context": "A more detailed model could be obtained with a controlled experiment similar to [34].", "startOffset": 80, "endOffset": 84}, {"referenceID": 3, "context": "This distribution has the form of a Bingham distribution [4].", "startOffset": 57, "endOffset": 60}, {"referenceID": 46, "context": "An efficient method for sampling from a von-Mises-Fisher distribution is outlined in [47].", "startOffset": 85, "endOffset": 89}, {"referenceID": 4, "context": "Sampling Directional Segmentation Labels zi We use the Chinese restaurant process (CRP) representation of the Dirichlet process [5, 31] since it lends itself to straightforward sampling-based inference.", "startOffset": 128, "endOffset": 135}, {"referenceID": 30, "context": "Sampling Directional Segmentation Labels zi We use the Chinese restaurant process (CRP) representation of the Dirichlet process [5, 31] since it lends itself to straightforward sampling-based inference.", "startOffset": 128, "endOffset": 135}, {"referenceID": 41, "context": "3 [42])", "startOffset": 2, "endOffset": 6}, {"referenceID": 6, "context": "Since the individual distributions are all Gaussian the posterior over surfel location pi is also Gaussian [7] with the following mean and variance:", "startOffset": 107, "endOffset": 110}, {"referenceID": 8, "context": "Via the law of large numbers and by the construction of the Gibbs sampler this approach will in the limit converge to the true means and variances [9].", "startOffset": 147, "endOffset": 150}, {"referenceID": 26, "context": "To be able to deal with fast motions we perform photometric rotational pre-alignment [27] from image pyramid level 3 down to 1.", "startOffset": 85, "endOffset": 89}, {"referenceID": 14, "context": "areas similar to [15].", "startOffset": 17, "endOffset": 21}, {"referenceID": 18, "context": "There exists only preliminary research on parallel Gibbs sampling under the name Hogwild Gibbs sampling [19] and it is unclear if there are theoretical guarantees.", "startOffset": 104, "endOffset": 108}, {"referenceID": 45, "context": "Figure 8: Thread timings (left) and surfel (middle) and sample count (right) statistics for the directional SLAM system running on the fr2 xyz dataset [46].", "startOffset": 151, "endOffset": 155}, {"referenceID": 45, "context": "Figure 9: Comparison of the absolute trajectory error (ATE) in meters as defined in [46] of different SLAM systems for different synthetic datasets from the benchmark dataset by Handa et al.", "startOffset": 84, "endOffset": 88}, {"referenceID": 17, "context": "[18] (kt0-2) and the TUM indoor dataset [46].", "startOffset": 0, "endOffset": 4}, {"referenceID": 45, "context": "[18] (kt0-2) and the TUM indoor dataset [46].", "startOffset": 40, "endOffset": 44}, {"referenceID": 45, "context": "fr2 xyz dataset [46] displayed in Fig.", "startOffset": 16, "endOffset": 20}, {"referenceID": 45, "context": "Camera Tracking Accuracy Comparison We use the TUM indoor dataset [46] and the synthetic dataset by Handa et al.", "startOffset": 66, "endOffset": 70}, {"referenceID": 17, "context": "[18] to evaluate the camera tracking accuracy against groundtruth via the absolute trajectory error (ATE) [46] and compare our system to related 3D SLAM systems in Fig.", "startOffset": 0, "endOffset": 4}, {"referenceID": 45, "context": "[18] to evaluate the camera tracking accuracy against groundtruth via the absolute trajectory error (ATE) [46] and compare our system to related 3D SLAM systems in Fig.", "startOffset": 106, "endOffset": 110}], "year": 2017, "abstractText": "To aide simultaneous localization and mapping (SLAM), future perception systems will incorporate forms of scene understanding. In a step towards fully integrated probabilistic geometric scene understanding, localization and mapping we propose the first direction-aware semi-dense SLAM system. It jointly infers the directional Stata Center World (SCW) segmentation and a surfel-based semi-dense map while performing real-time camera tracking. The joint SCW map model connects a scene-wide Bayesian nonparametric Dirichlet Process von-Mises-Fisher mixture model (DP-vMF) prior on surfel orientations with the local surfel locations via a conditional random field (CRF). Camera tracking leverages the SCW segmentation to improve efficiency via guided observation selection. Results demonstrate improved SLAM accuracy and tracking efficiency at state of the art performance. Future perception systems in applications such as autonomous cars, autonomous robots, or augmented reality will integrate scene understanding into the purely geometric localization and mapping task. This is likely to improve both simultaneous localization and mapping (SLAM), provide a basis for higher-level reasoning about the scene, and richer information for human operators. In current systems scene understanding is used in two ways: (1) to improve the operation of the 3D perception system and (2) to provide additional information for higher-level inference or a human operator. We argue that only systems in the first class actually \u201cunderstand\u201d aspects of the scene because they are able to use inferred concepts to improve on their other inferential tasks (i.e. localization and mapping). The number of systems that fall into this class is still small. In order to improve 3D reconstruction and localization via scene understanding most approaches rely on geometric scene priors such as planarity [10, 39, 20, 28], the Manhattan World [37] (MW) or the Stata Center World [6] (SCW) assumption. The assumption of planarity is a local assumption that cannot explain the connection between disparate scene parts like all the parallel planes in typical man-made environments. Such connections can be captured and explained by global assumptions such as the MW and the SCW assumption. Because the MW assumption is limited Figure 1: We propose the first direction-aware semi-dense SLAM system. Based on the Stata Center World assumption the system jointly infers a directional segmentation (right) and a semi-dense surfel-based map (left) in real-time. to very specific environments, we instead explore the flexible Stata Center World model to improve 3D reconstruction and camera tracking. As shown in [43, 44], the directional clustering of a scene\u2019s surface normals under the Stata Center World implies a segmentation that captures scene-wide regularities of the environment [45] as can be seen in the segmentation in Fig. 1. Based on the SCW scene prior, we propose the first semi-dense nonparametric direction-aware SLAM system. It performs joint inference over the Bayesian nonparametric SCW scene segmentation and the world map using Gibbssampling without precluding real-time operation. To connect the scene-wide Stata Center World model with local surface properties we model the assumption that nearby areas in the same directional segment are likely planar using a CRF. We demonstrate experimentally that using the directional segmentation improves SLAM accuracy and camera tracking efficiency via guided observation selection.", "creator": "LaTeX with hyperref package"}}}