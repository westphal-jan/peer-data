{"id": "1709.05825", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Sep-2017", "title": "Relational Marginal Problems: Theory and Estimation", "abstract": "In the propositional setting, the marginal problem is to find a (maximum-entropy) distribution that has some given marginals. We study this problem in a relational setting and make the following contributions. First, we compare two different notions of relational marginals. Second, we show a duality between the resulting relational marginal problems and the maximum likelihood estimation of the parameters of relational models, which generalizes a well-known duality from the propositional setting. Third, by exploiting the relational marginal formulation, we present a statistically sound method to learn the parameters of relational models that will be applied in settings where the number of constants differs between the training and test data. Furthermore, based on a relational generalization of marginal polytopes, we characterize cases where the standard estimators based on feature's number of true groundings needs to be adjusted and we quantitatively characterize the consequences of these adjustments. Fourth, we prove bounds on expected errors of the estimated parameters, which allows us to lower-bound, among other things, the effective sample size of relational training data.", "histories": [["v1", "Mon, 18 Sep 2017 09:10:27 GMT  (32kb)", "http://arxiv.org/abs/1709.05825v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ondrej kuzelka", "yuyi wang", "jesse davis", "steven schockaert"], "accepted": false, "id": "1709.05825"}, "pdf": {"name": "1709.05825.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Yuyi Wang", "Jesse Davis", "Steven Schockaert"], "emails": ["KuzelkaO@cardiff.ac.uk", "yuwang@ethz.ch", "jesse.davis@cs.kuleuven.be", "SchockaertS1@cardiff.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 170 9.05 825v 1 [cs.A I] 1 8Se p20 17"}, {"heading": "Introduction", "text": "This year, it has come to the point where there is only one occasion when there is a scandal, in which there is a scandal."}, {"heading": "Preliminaries", "text": "This paper considers a non-functional logic of the first order language L, which is composed of a series of constants Const =, variables Var = and predicates Rel = i Reli, with Reli containing the predicates of Artigkeit i. We start from an untyped language and use the domain size to refer to the constant. A letter is an atom or its negation. A proposition is a disjunction of words. We use Vars (\u03b1) to name the variables that appear in a formula \u03b1. Formula \u03b10 is called Grounding \u03b1 if \u03b10 can be achieved by replacing each variable in \u03b1 with a constant. A formula is called closed if all variables are bound by a quantifier."}, {"heading": "Two Types of Relational Marginals", "text": "Typically, parameters for a statistical relationship model are estimated on the basis of a single example of a relationship structure consisting of a large set of basic atoms A. Intuitively, the goal is to learn a probability distribution of such a relationship structure. The challenge is to estimate the distribution on the basis of a single example. A solution is based on the assumption that the relationship structure has repetitive regularities. Subsequently, statistics on these regularities can be calculated for small substructures of the train example and used to construct a distribution over large relationship structures. Therefore, the next question is how to construct the fragments and calculate statistics from them. Next, we will discuss two possible possibilities, which we will call Model A and Model B."}, {"heading": "Model A", "text": "The first approach to the construction of fragments is from (Kuz, Davis, and Schockaert 2017). Examples of the constants from the given example (A, C) are repeatedly presented, and a formula for the formula 1 (local example) is then created. However, let us consider a local example of the distribution of constants to take into account the fact that each fragment will contain different constants, which is achieved by using the term local distribution. Let us consider a local example of the distribution of width k as a pair. (A, {S}), where each fragment contains a set of soil atoms containing only constants from the concept of local distribution. (k) For an example. (A, C) and S C, let us write a set of local examples of the distribution of width."}, {"heading": "Model B", "text": "The second approach is to consider random substitutions, which is in the spirit of existing work (Bacchus et al. 1992; Schulte et al. 2014). Here, the statistics we collect about them are defined as follows. Definition 3 (probability of formulas under model B). Let the probability Q = (A, C) be a global example and \u03b1 be a universally quantified formula. Let the probability Q (\u03b1) of formula \u03b1 under model B be defined as an even distribution of injective substitutions from the specified formula \u03b1 = {\u03d1 | \u03d1: vars (\u03b1) \u2192 C and \u03d1 is injective}. Then the probability Q (\u03b1) of formula \u03b1 under model B is defined as a quantity."}, {"heading": "Max-Entropy Models", "text": "In this section we will show how to calculate models of predetermined relational marginals according to Model A and Model B. Definition 4 (model of relational marginals). Let us have a set of pairs \u03a6 = {(\u03b11, \u03b81),.., (\u03b1h, \u03b8h)} of relational marginals where \u03b1i is a closed formula and \u03b8i [0; 1]. Let us be a set of hard rules. We will say that a probability distribution P (\u041ai) over worlds satisfying the hard rules of \u03a60 is a width-k model of \u0438 iff Pk (\u03b1i) = \u03b8i (Qk (\u03b1i) = \u03b8i for all (\u03b1i, \u041ai) \u0432\u0438\u0441\u0441\u0441\u0441\u0441\u0441\u0442\u0438\u0439. We will use standard duality arguments from convex optimization (Boyd and Vandenberghe 2004), which will essentially follow (Singh and Vishnoi 2014). The results will turn out to be in both cases as family models exponential and the Native."}, {"heading": "Model A", "text": "Let C be a set of constants, A be the set of all atoms over C based on some given language of first order, and let Ck be the set of all k element subsets of C. Next, let us be a set of relational marginalities, and \u03a60 be a set of hard constraints, i.e. formulas that look like that when we satisfy the hard constraints (i.e. those for which there is no upper limit), let us assume that there is at least one distribution formula that is a model of inequality and meets the following positivity condition: P \u00b2 (1) > 0 for all cases satisfying the hard constraints (i.e. those for which there is no upper limit)."}, {"heading": "Model B", "text": "As with Model A, we can construct a convex optimization problem to obtain a maximum entropy distribution with the given relational marginals under Model B. To obtain the constraints imposed by the marginals, we can replace the summation of subsets of constants in C in (2) with a summation of substitutions from (1), the whereabouts of i being defined as in Definition 3, which imposes the following series of constraints on all (2): \"Summing of subsets of constants in C,\" \"Summing of substitutions from (C, 0),\" Definition 1 \"(9), using essentially the same reasoning as with Model A, we arrive at the following form of probability distribution in Model C (3), where the probability distribution in Model I is identical."}, {"heading": "Realizability", "text": "This is a problem if we want to estimate the relational marginals in any way discussed in the previous section, if the distribution of the data and the distribution we want to model have the same domain size. In this section we will show how to obtain relational marginals for each domain size. Accomplishing this requires1It has been shown (Poole et al. 2012) that the setting with proper formulas is equivalent in general MLNs.or The consistency of the relational marginal estimators with a weaker idea."}, {"heading": "Relational Marginal Polytopes", "text": "In this section we define another important concept called relational marginal polytopes, which will be used in the next section where we will deal with estimation errors. Definition 6 (Relational marginal polytopes for model A. Let k, m \u00b2 N and \u03a6 = {\u03b11,.., \u03b1l} be a set of formulas and \u03a60 be a set of hard rules. Let C = {1,.., m \u00b2 and Ck be the set of size-k subsets of C. Then the relational marginal polytopes of width and cardinality m w.r.t. the hard rules of \u03a60 is the convex shell of the set {(\u03b11,.) | Ck |,., # k (\u03b1l,.) a marginal polytope of the model k."}, {"heading": "Estimation", "text": "In this section, we present error limits for estimating the relational margins that would otherwise be feasible. We start with the definition of the learning environment. (Sure, we need some assumptions about the training and test data and their relationship (otherwise, one could always come up with an attitude in which the error can be arbitrarily large). However, to stay close to realistic settings, we assume that there are some large global examples that are not available and that represent the basic truth. That's what we essentially want to estimate for a given formula A, k (\u03b1), but we do not have access to the entire estimates. Imagine, for example, that the human gene regulatory network or Facebook is a process that uniformly displays pattern m subsets of CI, and that we have access to such a sample CI and also to the models produced."}, {"heading": "Related Work", "text": "The relational marginals of Model A have recently been introduced (Kuz elka, Davis, and Schockaert 2017), but they have only been studied in a possibilistic environment that differs significantly from the probable maximum entropy setting that we considered. However, the idea of using random substitutions (Model B) dates back to (Bacchus et al. 1992), which are, however, considered only as unreliable predicates. Schulte et al. (2014) used the semantics of random substitutions to define a Bayesian relational network model for population statistics, but their model is not based on any underlying soil model, and it is unclear whether the distributions are always feasible through a soil model. In the more limited setting of exponential random graph models (ERGMs, Chatterjee, and Diakonis 2013), a similar duality based on density of previously established homophorms has been established."}, {"heading": "Conclusions", "text": "Interestingly, this perspective allows learning a model applicable to data sets whose domain sizes differ from those of training data. We established a relational counterpart to the classical duality between boundary problems with maximum probability and maximum entropy, and then showed how to estimate and adjust the marginal parameters to ensure their feasibility. We also supplemented these results by setting limits on the expected errors of estimates in a reasonable learning environment. We believe that this setting, due to the simplicity and transparency of the learning environment we introduced, could play a similar role for SRL to the standard i.i.d. The statistical learning environment plays a role in learning in meaningful areas (Vapnik 1995), that is, as an idealized setting that is suitable for theoretical studies but is not too far removed from the settings found in reality. Nevertheless, it would be possible to expand the learning environment so realistically that it would likely replace the specific structure with one that is less complex."}, {"heading": "Appendix: Duality", "text": "In this section, we will prove the duality resulting from the main text. First, let us remember the placement and the notations. Let C be a set of constants, let A be the set of all atoms over C based on any given first order language, and let Ck be the set of all k element subsets of C. Let us also assume that there is at least one distribution P that is a model of quantity and meets the positivity condition: P \u00b2) > 0 for all quantities that satisfy the hard conditions. Sup {Pump: This problem can satisfy the quantity of quantity P \u00b2 and the quantity of quantity."}, {"heading": "Appendix: Proofs", "text": "In this section, we give evidence for the propositions from the main text. Proposal 2. Let P (B) be a distribution on the domain size n and k (n) be an integer. Let's leave the propositions from the main text. (A) Let P (c) be a distribution on the domain size n and k (c) be a distribution on the distribution P (c). (A) Let P (n) be a closed formula. (S) - (n) - 1 is an unbiased estimate of Pk (n).Proof. We have: E [p) - (n) - (n) - (n) - (n) - (n) - (S) - (S) - (S) - (S) - (S) - (S) - (S). (S) - (S) - (S)."}], "references": [{"title": "1992", "author": ["F. Bacchus", "A.J. Grove", "D. Koller", "J. Y Halpern"], "venue": "From statistics to beliefs. In Proceedings of the 10th National Conference on Artificial Intelligence. San Jose, CA, July 12-16,", "citeRegEx": "Bacchus et al. 1992", "shortCiteRegEx": null, "year": 1992}, {"title": "and Vandenberghe", "author": ["S. Boyd"], "venue": "L.", "citeRegEx": "Boyd and Vandenberghe 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "and Diaconis", "author": ["S. Chatterjee"], "venue": "P.", "citeRegEx": "Chatterjee and Diaconis 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "and Taskar", "author": ["L. Getoor"], "venue": "B.", "citeRegEx": "Getoor and Taskar 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "Induction of interpretable possibilistic logic theories from relational data", "author": ["Davis Ku\u017eelka", "O. Schockaert 2017] Ku\u017eelka", "J. Davis", "S. Schockaert"], "venue": "In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence,", "citeRegEx": "Ku\u017eelka et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Ku\u017eelka et al\\.", "year": 2017}, {"title": "and Sen", "author": ["H. Nandi"], "venue": "P.", "citeRegEx": "Nandi and Sen 1963", "shortCiteRegEx": null, "year": 1963}, {"title": "Aggregation and population growth: The relational logistic regression and markov logic cases", "author": ["Poole"], "venue": "In 2nd International Workshop on Statistical Relational AI (StarAI", "citeRegEx": "Poole,? \\Q2012\\E", "shortCiteRegEx": "Poole", "year": 2012}, {"title": "and Domingos", "author": ["M. Richardson"], "venue": "P.", "citeRegEx": "Richardson and Domingos 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "A", "author": ["O. Schulte", "H. Khosravi", "Kirkpatrick"], "venue": "E.; Gao, T.; and Zhu, Y.", "citeRegEx": "Schulte et al. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "and Rinaldo", "author": ["C.R. Shalizi"], "venue": "A.", "citeRegEx": "Shalizi and Rinaldo 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "N", "author": ["M. Singh", "Vishnoi"], "venue": "K.", "citeRegEx": "Singh and Vishnoi 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Lifted generative learning of markov logic networks. Machine Learning 103(1):27\u201355", "author": ["Van Haaren"], "venue": null, "citeRegEx": "Haaren,? \\Q2016\\E", "shortCiteRegEx": "Haaren", "year": 2016}, {"title": "V", "author": ["Vapnik"], "venue": "N.", "citeRegEx": "Vapnik 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "M", "author": ["M.J. Wainwright", "Jordan"], "venue": "I.", "citeRegEx": "Wainwright and Jordan 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "and Neville", "author": ["R. Xiang"], "venue": "J.", "citeRegEx": "Xiang and Neville 2011", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [], "year": 2017, "abstractText": "In the propositional setting, the marginal problem is to find a (maximum-entropy) distribution that has some given marginals. We study this problem in a relational setting and make the following contributions. First, we compare two different notions of relational marginals. Second, we show a duality between the resulting relational marginal problems and the maximum likelihood estimation of the parameters of relational models, which generalizes a well-known duality from the propositional setting. Third, by exploiting the relational marginal formulation, we present a statistically sound method to learn the parameters of relational models that will be applied in settings where the number of constants differs between the training and test data. Furthermore, based on a relational generalization ofmarginal polytopes, we characterize cases where the standard estimators based on feature\u2019s number of true groundings needs to be adjusted and we quantitatively characterize the consequences of these adjustments. Fourth, we prove bounds on expected errors of the estimated parameters, which allows us to lower-bound, among other things, the effective sample size of relational training data.", "creator": "LaTeX with hyperref package"}}}