{"id": "1006.4474", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jun-2010", "title": "sTeX+ - a System for Flexible Formalization of Linked Data", "abstract": "We introduce the sTeX + system, a user-driven enhancement of sTeX - a semantic extension of LaTeX that enables high-quality PDF documents for (proofreading) reading and printing, as well as semantic XML / OMDoc documents for web or post-processing. sTeX was originally designed as an invasive, semantic front-end to the creation of XML documents. sTeX was used here as a formalization tool in a case study for software engineering. In order to handle modular pre-semantic vocabularies and relationships, we upgraded it to sTeX + as part of a participatory design process. sTeX + presents a toolchain that begins with an sTeX + editor and ultimately serves as XHTML + RDFa linked data via an OMDoc-enabled, versioned XML database. As a result, all structural information requests are preserved to enable structural anesis.", "histories": [["v1", "Wed, 23 Jun 2010 11:27:19 GMT  (484kb,D)", "http://arxiv.org/abs/1006.4474v1", "I-SEMANTICS 2010, September 1-3, 2010, Graz, Austria"]], "COMMENTS": "I-SEMANTICS 2010, September 1-3, 2010, Graz, Austria", "reviews": [], "SUBJECTS": "cs.SE cs.AI", "authors": ["andrea kohlhase", "michael kohlhase", "christoph lange"], "accepted": false, "id": "1006.4474"}, "pdf": {"name": "1006.4474.pdf", "metadata": {"source": "CRF", "title": "STEX+ \u2013 a System for Flexible Formalization of Linked Data", "authors": ["Andrea Kohlhase", "Michael Kohlhase", "Christoph Lange"], "emails": ["Andrea.Kohlhase@dfki.de", "m.kohlhase@jacobs-", "ch.lange@jacobs-"], "sections": [{"heading": "Categories and Subject Descriptors", "text": "D.2.1 [Software Engineering]: Requirements/Specifications\u2014Languages; I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods\u2014Representation languages; I.7.2 [Document and Text Processing]: Document Preparation"}, {"heading": "General Terms", "text": "Documentation, Human Factors, Languages, Management"}, {"heading": "Keywords", "text": "formalization, LATEX, Linked Data, software engineering, semantic authoring, annotation, metadata, RDFa, vocabularies, ontologies"}, {"heading": "1. INTRODUCTION", "text": "An important issue in the Semantic Web community was and still is the \u201cAuthoring Problem\u201d: How can we convince people not only to use semantic technologies, but also prepare them for creating semantic documents (in a broad sense)?\nI-SEMANTICS 2010, September 1\u20133, 2010, Graz, Austria\nHere, we were interested in formalizing a collection of LATEX documents into a set of files in the OMDoc format, an XML vocabulary specialized for managing mathematical information, and further on to Linked Data for interactive browsing and querying on the Semantic Web.\nConcretely, the object of our study was the collection of documents created in the course of the 3-year project \u201cSicherungskomponente fu\u0308r Autonome Mobile Systeme (SAMS)\u201d at the German Research Center for Artificial Intelligence (DFKI). SAMS built a software safety component for autonomous mobile service robots developed and certified it as SIL-3 standard compliant (see [13]). Certification required the software development to follow the V-model (figure 1) and to be based on a verification of certain safety properties in the proof checker Isabelle [33]. The V-model mandates e. g. that relevant document fragments get justified and linked to corresponding fragments in other members of the document collection in an iterative refinement process (the arms of the \u2018V\u2019 from the upper left over the bottom to the upper right and in-between in figure 1).\nSystem development with respect to this regime results in a highly interconnected collection of design documents, certification documents, code, formal specifications, and formal proofs. This collection of documents \u201cSAMSDocs\u201d [35] make up the basis of a case study in the context of the FormalSafe project [12] at DFKI Bremen, where they serve as a basis for research on machine-supported change management, information retrieval, and document interaction. In this paper, we report on the formalization project of the collection of LATEX documents in SAMSDocs (that we will without further ado also abbreviate with SAMSDocs).\nar X\niv :1\n00 6.\n44 74\nv1 [\ncs .S\nE ]\n2 3\nJu n\n20 10\nNot surprisingly, the interplay between the fields Semantic Web and Human-Computer Interaction played an important role as the \u201cAuthoring Problem\u201d of the first is often tackled via methods of the second. One such approach is that of \u201cinvasive technology\u201d [21] with the basic idea that from a user\u2019s perspective, semantic authoring and general editing are the same, so why not offer semantic functionalities as an extension of well-known editing systems, thereby \u2018invading\u2019 the existent ones. We started with LATEX not only because a good portion of our case study was written in it, but also as LATEX constitutes the state-of-the art authoring solution for many scientific/technical/mathematical document collections. Despite its text-based nature it is widely considered the most efficient tool for the task. Therefore, we used the invasive OMDoc frontend for LATEX documents called STEX [26]. In the formalization process its conceptual usability weaknesses (for the task) were identified and within a participatory design process it evolved into the invasive formalization tool STEX+.\nIn section 2, we will present the STEX system, especially its realization of Linked Data creation. Then we describe in section 3 the formalization process of SAMSDocs with STEX, our challenges, and our (pre-)solutions. In section 4 we report the enhancements of STEX realized in and for the case study to STEX+. Having STEX+ documents with Linked Data and ontological markup, we describe (potential) services and their implementation design in section 5. Section 6 summarizes related work, and section 7 concludes the paper.\n2. STEX: OBJ.-ORIENTED LATEX MARKUP STEX [26, 37] is an extension of the LATEX language that is geared towards marking up the semantic structure underlying a document. The main concept in STEX is that of a \u201csemantic macro\u201d, i. e., a TEX command sequence S that represents a meaningful (mathematical) concept C: the TEX formatter will expand S to the presentation of C. For instance, the command sequence \\positiveReals (from listing 1) is a semantic macro that represents a mathematical symbol \u2014 the set R+ of positive real numbers. While the use of semantic macros is generally considered a good markup practice for scientific documents (e. g., because they allow to adapt notation by macro redefinition and thus increase reusability), regular TEX/LATEX does not offer any infrastructural support for this. STEX does just this by adopting a semantic, \u2018object-oriented\u2019 approach to semantic macros by grouping them into \u201cmodules\u201d, which are linked by an \u201cimports\u201d relation. To get a better intuition, consider\nListing 1: An STEX Module for Real Numbers \\begin{module}[id=reals] \\importmodule[../background/sets]{sets} \\symdef{Reals}{\\mathbb{R}} \\symdef{greater}[2]{#1>#2}\n5 \\symdef{positiveReals}{\\Reals^+} \\begin{definition}[id=posreals.def, title=Positive Real Numbers] $\\defeq\\positiveReals\n{\\setst{\\inset{x}\\Reals}{\\greater{x}0}}$ 10 \\end{definition}\n... \\end{module}\nwhich would be formatted to\nDefinition 2.1 (Positive Real Numbers): R+ := {x \u2208 R | x > 0}\nHere, STEX\u2019s \\symdef macro \u2013 invasive by to its deliberate resemblance of (La)TEX\u2019s \\def and \\newcommand \u2013 generates a respective semantic macro, for instance the \\positiveReals with representation R+. Note the symbol inheritance scheme of STEX: The markup in the module reals has access to semantic macros \\setst (\u201cset such that\u201d) and \\inset (set membership) from the module sets that was imported by the document \\importmodule directive from the ../background/sets.tex. Furthermore, it has access to the \\defeq (definitional equality) that was in turn imported by the module sets.\nFrom this example we can already see an organizational advantage of STEX over LATEX: we can define the (semantic) macros close to where the corresponding concepts are defined, and we can (recursively) import mathematical modules. But the main advantage of markup in STEX is that it can be transformed to XML via the LATEXML system [32]: Listing 2 shows the OMDoc [25] representation generated from the STEX sources in listing 1. OMDoc is a semanticsoriented representation format for mathematical knowledge that extends the formula markup formats OpenMath [7] and MathML [2] to a document markup format.\nListing 2: An XML Version of Listing 1 <theory xml:id=\"reals\"> <imports from=\"../background/sets.omdoc#sets\"/> <symbol xml:id=\"Reals\"/> <notation>\n5 <prototype><OMS cd=\"reals\" name=\"Reals\"/></prototype> <rendering><m:mo>R</m:mo></rendering>\n</notation> <symbol xml:id=\"greater\"/><notation>. . .</notation> <symbol xml:id=\"positiveReals\"/><notation>. . .</notation> 10 <definition xml:id=\"posreals.def\" for=\"positiveReals\"> <meta property=\"dc:title\">Positive Real Numbers</meta> <OMOBJ> <OMA> <OMS cd=\"mathtalk\" name=\"defeq\"/> 15 <OMS cd=\"reals\" name=\"positiveReals\"/> <OMA>\n<OMS cd=\"sets\" name=\"setst\"/> <OMA> <OMS cd=\"sets\" name=\"inset\"/>\n20 <OMV name=\"x\"/> <OMS cd=\"reals\" name=\"reals\"/> </OMA> <OMA> <OMS cd=\"reals\" name=\"greater\"/> 25 <OMV name=\"x\"/> <OMI>0</OMI>\n</OMA> </OMA>\n</OMA> 30 </OMOBJ>\n</definition> . . .\n</theory>\nOne thing that jumps out from the XML in this listing is that it incorporates all the information from the STEX markup that was invisible in the PDF produced by formatting it with TEX.\nOMDoc itself has been used as a storage and exchange format for automated theorem provers, software verification systems, e-learning software, and other applications [25, chap-\nter 26], but due to its focus on semantic structures, it is not intended to be consumed by human readers. The Java-based JOMDoc [19] library uses the notation elements to generate human-readable XHTML+MathML from OMDoc. Figure 2 shows the result of rendering the document from listing 2 in a MathML-aware browser. In contrast to the PDF output we can directly create from STEX, XHTML+MathML allows for interactivity. In particular, our JOBAD JavaScript framework enables modular interactive services in rendered XHTML+MathML documents [14]. These services utilize the semantic structures of mathematical formulae. In our rendered documents, each formula in human-readable Presentation MathML carries the original semantic OpenMath representation of the formula, as shown in listing 2, as a hidden annotation.\nClient-side JOBAD services, which exclusively rely on annotations given inside a document, have already been implemented for folding and unfolding subterms of formulae and for controlling the display of redundant brackets in complex formulae. The symbol definition lookup service, shown in figure 2, interacts with a server backend: It traverses the links to symbol and their corresponding definition elements that are established by the OMS elements in OpenMath \u2013 for example, <OMS cd=\"sets\" name=\"inset\"/> encodes the URI ../background/sets.omdoc#inset \u2013 and retrieves the document at that URI as XHTML+MathML.1 JOBAD\u2019s ability to integrate an arbitrary number of services, which can talk to different server backends and which are enabled depending on the context, i. e., the semantic structure of the part of a mathematical formula that the user has selected, turns our rendered mathematical documents into powerful mashups [28]. On any symbol, for example, definition lookup is enabled. On any expression where a number is multiplied with a special symbol representing a unit of measurement, a unit conversion client that talks to a remote unit conversion web service is enabled. The JOBAD architecture has been designed without depending on a particular backend; for most of our services we are using the extensible XML-aware database TNTBase [39, 40, 11], which has special support for OMDoc and integrates the JOMDoc rendering library.\n1This is the MathML way of representing Linked Data. In section 5, we describe how we have now extended this feature to cover RDFa Linked Data."}, {"heading": "3. FORMALIZATION WITH STEX TOWARDS", "text": "STEX+ In this section we describe the process of formalizing the SAMSDocs collection of LATEX documents created in the course of the SAMS project with the STEX system. We use the user\u2019s perspective to point to the requirements for STEX+ that evolved in this process.\nAs we all know all too well: Formalizing is never easily done. In our project we had the additional challenge of doing it without corruption of the PDF layout that was produced with LATEX. Here, STEX fits well, as it generates PDF and transforms to XML. In figure 3 we can see the general course of action:\ni) we identified document fragments (\u201cobjects\u201d) that constitute a coherent, meaningful unit like the state of a document \u201crd.\u201d or its description \u201cready for certification\u201d, then\nii) we translated it into the STEX format, realizing for example that \u201crd.\u201d is a recurring symbol and \u201cready for certification\u201dits definition (therefore designing the SAMSDocs macro \u201cSDdef\u201d), and finally\niii) we polished these macros in the STEX specific sty-files so that the PDF layout remained as before and the generated XML represented the intended logical structure, for instance the use of the OMDoc XML elements symbol and definition.\nNote that definitions are common objects in mathematical documents, therefore STEX naturally provides a definition environment. So why didn\u2019t we use that? Because the document model of OMDoc, which we obtain by transforming STEX using LATEXML, does not allow definitions in tables, as the former are stand-alone objects from an ontological perspective. If one authors a formal document, this view is taken, so no problem arises, but if one formalizes an existing document, layout and cognitive side-conditions have to be taken into account. We therefore realized that we could not simply add basic STEX markup to the LATEX source yielding formal objects, we rather needed to add pre-formal markup in the formalization process (we speak of (semantic) preloading).\nWhenever project-wide (semantic) layout schemes were discovered, that were frequently used, we extended the macro set of STEX suitably (enabling preloading\u201cproject structures\u201d[22], i. e. project-induced ones which is quite different from \u201cdocument [layout] structures\u201d [ibid.], e. g. by subsections that is supported by STEX core features, see DCMsubsection in figure 3). The table layout for example was often used for lists of symbol definitions. So we created the SDTab-def environment which can host as many SDdef commands as wanted (see fig. 3). This increased the efficiency of the formalizing process tremendously.\nAnother difference between authoring and semantic preloading consisted in the order of the formalization steps. While the order of the first typically consists of \u201cchunking\u201d (i. e., building up structure e. g. by setting up theories),\u201cspotting\u201d (i. e., coining objects), and\u201crelating\u201d(i. e., making relationships between objects or structures explicit), the order of the second is made up of spotting, then relating or chunk-\ning. The last two were done simultaneously, because STEX offers a very handy inheritance scheme for symbol macros \u2014 as long as the chunks are in order, which could be sensibly done for some but not for all at this stage in the formalization process. Generally, many \u2018guiding\u2019 services of STEX, that STEX considered to be features, turned out to be too rigid.\nAs a consequence we heavily used very light annotations at the beginning: It was sufficient to identify a certain document fragment and to mark it with a referencable ID like \u201cstate-doc-rd\u201d. Shortly afterwards, we realized that some more basic markup was necessary, since we wanted to formalize our knowledge of types/categories of these objects and their conceptual belonging. For this we developed a set of \u201cad-hoc semantification macros\u201d with named attributes like SDobject[id], SDmore[id,cat,for], SDisa[id,cat,for,follows,theory,imports,tab], or SDreferences[id,file,refid]2. The \u2018more\u2019 functionality provided by SDmore was required due to logically contiguous objects that were interspersed in a document. With this set we preloaded \u201cobject structures\u201d [ibid.], i.e. object-induced ones. Note that the ad-hoc semantification macros enabled the formalizer to develop her own metadata vocabulary.\nAs soon as the document boundaries went down, we realized that an object had many occurrences in several of the documents in the SAMSDocs collection. For example, first\n2We use subsets of a general attributes set for all of our STEX extensions to lower the learning curve for the use of the markup macros.\nan object was introduced as a high-level concept in the contract, then it was specified in another document, refined in a detailed specification, implemented in the code, reviewed at some stage, and so on until it was finally described in the manual. Thus, we had to preload \u201ccollection structures\u201d [ibid.] as well, which consisted in the development process model, the V-model as seen in figure 1. Here, we built our personal V-model macros, e. g. SemVMrefines, SemVMimplements, or SemVMdescribesUse.\nAdditionally, we created an STEX extension especially suited for preloading\u201corganizational structures\u201d[ibid.]. This is considered different from project structures as organizational markup is very probable to be reusable for other projects with the same organizational structures. For example, SAMS used a document version management as well as a document review history, so that environments VMchangelist, VMcertification with corresponding list entry macros VMchange, VMcertified were built. Another example is the processing state of a document, which can be marked up easily by using the VMdocstate macro as seen in figure 4.\nWe noted that the necessary formalization depth of some documents was naturally deeper than others. For example, it didn\u2019t seem sensible to formalize the contract too much, as it was created as a high-level communication document, whereas the detailed specification needed a lot of formalization. The manual had an interesting mixed state of formality and informality, as it was again geared towards communication, but it needed to be very precise. In conclusion we note that the mathematical content of the documents (i. e., the mathematical objects and their relations) was only one of the knowledge sources that needed to be formalized and\nmarked up. In the course of the formalization it has become apparent that the knowledge in such complex collections is multi-dimensional (cf. [22] for an in-depth analysis). Thus, the requirements for extending STEX to STEX+ were (i) to generate XML output that preserves the semantics annotated in the preloading phase, (ii) and to take into account the multi-dimensionality of our ad-hoc semantification macros in a way that technically enables browsing and querying. These requirements were satisfied by enabling the generation of RDFa from our annotations and making them accessible to Linked Data services, as we will describe in the following sections.\n4. STEX+: A METADATA-EXTENSION OF STEX All the arrows in figure 1 are examples of relations between document fragments in the SAMSDocs corpus that needed to be made explicit in addition to the mathematical relations that STEX had originally supported; the revision histories of documents and the social networks of their authors constitute further dimensions of knowledge. For situations like these, we had incorporated RDFa [1] as a flexible metadata framework into the OMDoc format [31]. In the course of this case study, the RDFa integration was revised and extended and will become part of the upcoming OMDoc version 1.3 [27]. The main idea for this integration is to realize that any concrete document markup format can only treat a certain set of objects and their relations via its respective native markup infrastructure. All other objects and relations can be added via RDFa annotations to the host language \u2013 assuming the latter is XML-based.\nIt is crucial to realize that, for machine support, the metadata objects and relations are given a machine-processable meaning via suitable ontologies. Moreover, ontologies are just special cases of (mathematical) theories, which import appropriate theories for the logical background, e. g. description logic, and whose symbols are the entities (class, properties, individuals) of ontologies. Thus, STEX and OMDoc can play a dual role for Linked Data in documents with mathematical content. They can be used as markup formats for the documents and at the same time as the markup formats for the ontologies. We have explored this correspondence\nfor OMDoc in previous work and implemented a translation between OMDoc and OWL [31, 30].\nTo understand our contribution, note that we can view LATEX and STEX as frameworks for defining domain-specific vocabularies in classes and packages; LATEX is used for layout aspects, and STEX can additionally handle the semantic aspects of the vocabularies. STEX uses this approach to define special markup e. g. for definitions (see lines 10 to 31 in listing 2). Note that to define STEX markup functionality like the definition environment, we have to provide a LATEX environment definition (so that the formatting via LATEX works) and a LATEXML binding (to specify the XML transformation for the definition environment). As the OMDoc vocabulary is finite and fixed, STEX can (and does) supply special LATEX macros and environments and their LATEXML bindings. But the situation is different for the flexible, RDFa-based metadata extension in OMDoc 1.3 we mentioned above, with a potentially infinite supply of vocabularies. At the start of the SAMSDocs preloading effort, STEX already supported a common subset of metadata vocabularies. For instance the Dublin Core title metadata element in line 11 of listing 2 is the transformation result of using the KeyVal [9] pair title=. . . in the optional argument of the definition environment.\nFor the SAMSDocs case study we started in the same way by adding a package with LATEXML bindings to STEX. The \\VMdocstate macro shown in the \u201cSTEX\u201d box of figure 4 allowed us to annotate a document with its processing state. This is transformed to an RDFa-annotated omdoc root element, as shown in the \u201cOMDoc\u201d box underneath and in the black, solid parts of the RDF graph in figure 5. We can already see that the STEX extension for SAMSDocs exactly consists in a domain-specific metadata vocabulary extension, and that using the custom vocabulary hides markup complexity from the author. Again, SAMSDocs only needed a finite vocabulary extension, so this approach was feasible, but of restricted applicability, since developing the SAMSDocs package for STEX required insights into STEX internals and LATEXML bindings. Thus this extension approach lacks the flexible user-extensibility that would be needed to scale up further.\nTo enable user-extensibility, we add a new declaration form \\keydef to the core STEX functionality (yielding STEX+) \u2014 like \\symdef in that it is inherited via the module imports relation, only that it defines a KeyVal key instead of a semantic macro. To understand its application, we rationally reconstruct the v:hasState relation from the example in the OMDoc box of figure 4. To do this, we use STEX to create a metadata vocabulary for document states: we create a certification module, which defines the hasState metadata relation and adds it to the KeyVal keys of the document environment. The metalanguage macro is a variant of importmodule that imports the meta language, i. e., the language in which the meaning of the new symbols is expressed; here we use OWL.\nListing 3: A Metadata Ontology for Certification \\begin{module}[id=certification] \\metalanguage[../background/owl]{owl} \\keydef{document}{hasState}\n\\symdef{state-doc-rd}[1]{rd. #1} 5 \\symdef{tuev}{\\text{T\\\"UV}} \\begin{definition}[for=hasState] A document {\\definiendum[hasState]{has state}} $x$, iff the project manager decrees it so. \\end{definition}\n10 \\begin{definition}[for=state-doc-rd] A document has state \\definiendum[state-doc-rd]{rd. $x$}, iff it has been submitted to $x$ for certification. \\end{definition} \\begin{definition}[for=tuev,hasState=$\\statedocrd\\tuev$] 15 The $\\tuev$ (Technischer \\\"Uberwachungsverein) is a well-known certification agency in Germany.\n\\end{definition} \\end{module}\nIn this paper, we focus on using STEX+ as a language for defining lightweight vocabularies. Note, however, that \u201cheavyweight\u201d formal semantics can be added to vocabulary terms in the same way as has been shown for mathematical symbols in listing 1. Similarly as the \u201creal numbers\u201d module relies on an STEX module that introduces set theory, the certification ontology relies on an STEX module that introduces the OWL language. Such an OWL ontology that has been written in STEX+ can be translated to one of the widely supported serializations of OWL via two paths: (i) In the original workflow, the STEX+ source is translated to OMDoc. Thanks to their modularity and literal programming capabilities, the STEX+ or OMDoc representation allows for an expressive documentation of OWL ontologies. But, as OMDoc is not universally understood on the Semantic Web, we have implemented a translation of OWL ontologies encoded and documented in OMDoc to the standard RDF/XML representation [31]. (ii) Alternatively to this previously existing translation via OMDoc as an intermediate representation, we are working on a direct STEX+ to OWL transformation. Simply using our experimental owl2onto class [23] instead of the omdoc class from STEX in the LATEX preamble will cause LATEXML to generate OWL \u2013 here in the direct OWL XML serialization \u2013 instead of OMDoc from a subset of the STEX+ markup.\nListing 4: Annotating a Document with Certification Metadata \\importmodule[../ontologies/cert]{certification}\n2\\begin{document}[hasState=$\\statedocrd{\\tuev}$] ... \\end{document}\nLet us now see how to use a vocabulary: If we import the certification metadata module, we can write to generate RDFa annotations that correspond to the (red) dotted arrow in figure 5. Note that in the state of formalization shown in figure 4, the SAMSDocs-specific RDF vocabulary still has a pre-semantic structure. With the STEX+ we can express that the processing state is actually intended to be a symbol in a metadata theory, not just some semantic object in some file. In listing 3 we use the \\symdef directive to generate the symbol state-doc-rd and \\keydef to generate a metadata relation hasState that is expressed by a key of the same name, which is added to the document environment. When processed by LATEXML, \\keydef takes care of generating correct URIs for the metadata relations and their target resources, resulting in an RDFa output syntactically similar to figure 4. In conclusion, we note that\nSTEX+ allows us to rationally recreate the effect we previously achieved with the custom \\VMdocstate and \\SD referencesNoObj macros. Note that we did not have to extend the LATEXML bindings at all for this extension. Thus, STEX+ gives us a generic TEX\u2192RDFa translation, which works for arbitrary vocabularies.3\n5. STEX+ DOCUMENTS AS LINKED DATA The translation of classical STEX to OMDoc and further to XHTML+MathML (see section 2), which results in a Linked Data like markup for mathematical symbols, enables interactive services in mathematical formulae. Now that STEX+ supports formalization with arbitrary metadata (cf. section 4), it should additionally be possible to utilize these metadata for services. Both types of annotation complement each other: A practical STEX+ document, like many of the SAMSDocs, would combine elements from listing 4 with those from listing 1 and consequently rely on services for both types of semantic structures.\nThe JOBAD service architecture (see section 2) gives uniform access to common queries in the document browsing user interface. In the SAMSDocs scenario this might be a query for all persons who have worked on the current document. This can directly be answered from the metadata of the revision log. Another typical query would consist in asking for all parts of a specification that have to be recertified. Answering this query involves revision logs (for finding documents that have changed since the last certification), collection structures (V-model dependencies of changed parts), and mathematical structures (logical dependencies). In [22] we have elaborated on such SAMSDocs queries from the point of view of their stakeholders (like engineers, project managers, certifiers), particularly exploring the multi-dimensionality of the formal structures. For example, a project manager may find a substitute for an employee E, who has implemented a specification, by tracing back a link from the documentation of the implementation to the specification document and finding out, from the metadata of that document, who has recently been working on it. Here, we will summarize the extensions made to our system architecture to enable these services.\nAs a first step, we made the JOMDoc renderer preserve the RDFa metadata from the OMDoc documents, now gener-\n3Our experimental rdfameta package [24] extends this to arbitrary LATEX documents: It redefines common LATEX commands (e. g. the sectioning macros) so that they include optional KeyVal arguments that can be extended by \\keydef commands. With this metadata extension, we can add RDFa metadata to any existing LATEX.\nating XHTML+MathML+RDFa. Additionally, the mathematical structures (those that are above the formula level) had to be preserved in the rendered output. Even though OMDoc uses native non-RDFa markup for these structures, we can also represent these in RDF, exploiting the OMDoc ontology (see [29, 11] for more information). Existing JOBAD services recognized mathematical formulae in XHTML presentations of OMDoc documents by their semantic structure (e. g. whether they use previously defined symbols or units of measurement). Similarly, new services can now recognize from the RDFa annotations whether a chunk of an XHTML document is, e. g., an implementation of a specification fragment, and by which user requirement that is induced. Compared to the previously existing definition lookup service, the principle of retrieving content from a target URI and displaying it in a popup remained the same \u2013 the URIs are just provided by different annotations.\nSecondly, we have extended the folding of subterms of mathematical formulae to higher-level structures, such as requirements or steps of structured proofs. We have implemented this using the rdfQuery JavaScript library [38], which parses all RDFa annotations of a document into a local triple store that can be queried using SPARQL-like JavaScript functions. On the server side, we have extended TNTBase [39], our versioned database backend and web server/application framework to accept commits of STEX+ documents, automatically convert them to OMDoc, and then serve OMDoc, XHTML+MathML+RDFa, and, optionally, RDF/XML, according to the Linked Data best practices [17].\nEven the pre-semantic annotations like the ones shown in figure 4 afford interactive services: A generic reference can already be utilized for lookup and navigation. Providing additional information in the instance document or in the ontology (e. g. the knowledge about the target of a reference being a symbol or a processing state) allows for making the service user interface more specific and enables the display of more relevant related information. For the generic presemantic\u201creferences\u201d relation, the list of all semantic objects that it relates to each other would be too large for being usable, as there is no obvious way of ranking or filtering the link targets. But once more specific link types are used, such as the \u201chas state\u201d link, that information can be used to display a list of documents grouped by state.\nQueries across documents cannot be answered using the above-mentioned rdfQuery: client side queries require a combination of querying a local triple store and crawling links. In our setup, we have experimented with SQUIN [16], a frontend to the Semantic Web Client library [4], which gives access to Linked Data via a simple HTTP frontend at very low integration costs: If the server provides standard-compliant Linked Data, then the client simply has to access the URL of the SQUIN server, providing a SPARQL query as a parameter. An alternative would have been AJAR library, a part of the Tabulator Linked Data browser [3], which implements the same functionality in JavaScript. In our test setup, SQUIN acted as a proxy between the client-side JavaScript code and our Linked Data. While a Linked Data crawler is most flexible when data are distributed across many servers (e. g. when an OMDoc document links to DBpedia), its query answering capabilities are only as good as\nthe Linked Data being served. For example, if the RDF(a) does not contain back-links (like links from a mathematical theory to the theories it imports and to the theories by which it is imported), then an AJAR- or SQUIN-powered client cannot query links in both directions. Moreover, the performance of such a solution is limited, as it requires memory for the local triple store as well processor time for query answering on the client side. Therefore, in the SAMSDocs setting, where the queries are currently limited to a document collection on a single server, the best solution is storing the triples on that same server, and making them accessible via a standard query interface. Concretely, we make a SPARQL endpoint powered by the Virtuoso triple store [34] available as an extension to TNTBase [11]. In a larger Software Engineering scenario (like a document collection of a company with multiple departments) a combination with a Linked Data crawler, as offered by the Sponger extension to Virtuoso in an integrated server-side fashion, may have advantages: if all these departments publish their document collections as Linked Data in the company intranet (see for instance [36] for the topicality of this example), crawling these may reveal previously unknown connections, e. g. colleagues dealing with structurally similar problems who could lend advice. Note that local vocabularies resulting from adhoc semantification need not be a barrier to knowledge exchange: Linked Data practices recommend connecting occurrences of semantically equivalent resources in different data sets by owl:sameAs. Alternatively, if it turns out that one department uses a\u201cbetter\u201dvocabulary for their data, the STEX+ metadata extensions make it easy to adopt it: all we have to do is to change the STEX+ bindings or \\keydefs.4"}, {"heading": "6. RELATED WORK", "text": "We have presented STEX+ as an extension of the LATEX language for both authoring Linked Data vocabularies and annotating semantic documents with them. Thus, it is obviously related to other semantic extensions of LATEX. But, when considering STEX+ as a text- and macro-based frontend to OWL and RDFa, it can also be compared to other ontology/vocabulary authoring and document annotation frontends, including such with graphical user interfaces.\nSALT [15] also allows for annotating semantic relations in LATEX documents and exporting them as Linked Data. SALT is restricted to a fixed set of rhetorical and bibliographical relations, plus the metadata fields of widely used document classes like LNCS, both of which it embeds as RDF annotations in the generated PDF, whereas STEX+ allows for (re)using arbitrary relations plus defining custom ones. The target format of STEX+ is RDFa inside the generated OMDoc and XHTML+MathML. We have concentrated on that target, since it supports dynamic interactions via our\n4Reuse of vocabularies is not limited by traditional restrictions of TEX, which has a single global namespace for macros, and where no two keys passed to a command or environment may have the same name. STEX groups symbols into modules; STEX+ does the same for keys. When two symbols or keys that have the same local name relatively to their module are imported into another module M , there are facilities for giving them distinct names for usage inside M . For example, when there is already a key name, but the name property from the FOAF ontology should also be reused, we can set up a qualified import of the latter, e. g. as FOAFname.\nJOBAD system. An export of the metadata relations to XMP annotations embedded in PDF should be possible with the technology employed in SALT; we leave this to future work.\nSOBOLEO [6] is a lightweight graphical user interface for creating and editing vocabularies/ontologies in OWL based on Web 2.0 tagging approaches. In [5], the authors evaluate its usage along their \u201cOntology Maturing Process Model\u201d, in which they confirm the succeeding phases \u201cemergence of ideas\u201d, \u201cconsolidation in communities\u201d, \u201cformalization\u201d, and \u201caxiomatization\u201d in an ontology engineering process. Our observed phases of spotting, relating and chunking essentially correspond, as the \u201cemergence of ideas\u201d period did not apply (the documents were already created). Interestingly, the \u201cconsolidation in communities\u201d phase does not only have to be thought of as a development time: We found it reified in SAMSDocs like the V-model relations. loomp is an example of a WYSIWYG editor for annotating HTML documents with terms from vocabularies, yielding RDFa [18]. GUI tools traditionally separate the task of vocabulary creation from document annotation; this also holds for SOBOLEO (responsible for the former task) and loomp (responsible for the latter). STEX+, on the other hand, gives access to both tasks via the same interface: TEX macros, which are once declared, and once used \u2013 possibly even in the same source file."}, {"heading": "7. CONCLUSION AND FUTURE WORK", "text": "We reported on a formalization case study, where we use the STEX format, a document formatting system and specification platform for semantic, mathematical vocabularies, on a document corpus from Software Engineering. To cope with the the multi-dimensional semantic structure implicit in the document collection, we extended STEX into a markup platform for semi-formal ontologies and Linked Data called STEX+ (in our case semi-formal documents with RDFabased metadata annotations).\nThe key observation from our case study is that if we use STEX+ as a human- and document-oriented frontend for Linked Data documents, we can approach the formalization of semi-formal document collections as a process of \u201cdocument and ontology co-development\u201d, where (in our case preexisting) documents are semantically preloaded with interand intra-document relations, whose meaning is given by (project-specific or general, reusable) metadata ontologies. As we have seen in section 3, preloading documents and developing metadata ontologies in a joint frontend format reduces formalization barriers. For instance, we often have to elaborate informal document fragments into metadata vocabularies; see the discussion about the \u201crd.\u201d document state.\nFor practical applicability of the STEX+ approach, machine support for authoring and managing STEX document collections is crucial. As a client-side counterpart to the integrated repository and Linked Data publishing solution provided by TNTBase [11], we are currently developing an integrated collection authoring environment STEXIDE for STEX on the basis of the Eclipse framework [20]. We expect that extending STEXIDE to operationalize the STEX+ functionality presented in this paper will turn it into an IDE for document\ncollection and ontology co-development that will enable authors to cope with the complexities of dealing with large collections of semi-formalized documents. On the other hand, we expect the modular STEXIDE system to be a good basis for deploying supportive services in a flexible document collection environment.\nWe conjecture that the STEX+ based workflow for document and ontology co-development can be extended to arbitrary Linked Data applications.\nAcknowledgments. The authors gratefully acknowledge the careful work of Christoph Lu\u0308th, Holger Ta\u0308ubig, and Dennis Walter that went into preparing the SAMS document collection, which is the basis of this paper. Moreover, we like to thank the members of the FormalSafe project for valuable discussions."}, {"heading": "8. REFERENCES", "text": "[1] B. Adida and M. Birbeck. RDFa Primer. W3C\nWorking Group Note, World Wide Web Consortium (W3C), Oct. 2008.\n[2] R. Ausbrooks, S. Buswell, D. Carlisle, G. Chavchanidze, S. Dalmas, S. Devitt, A. Diaz, S. Dooley, R. Hunter, P. Ion, M. Kohlhase, A. Lazrek, P. Libbrecht, B. Miller, R. Miner, M. Sargent, B. Smith, N. Soiffer, R. Sutor, and S. Watt. Mathematical Markup Language (MathML) version 3.0. W3C Candidate Recommendation of 15 December 2009, World Wide Web Consortium, 2009.\n[3] T. Berners-Lee, Y. Chen, L. Chilton, D. Connolly, R. Dhanaraj, J. Hollenbach, A. Lerer, and D. Sheets. Tabulator: Exploring and analyzing linked data on the semantic web. In Proceedings of the The 3rd\nInternational Semantic Web User Interaction Workshop (SWUI06), Nov. 2006.\n[4] C. Bizer, T. Gau\u00df, R. Cyganiak, and O. Hartig. Semantic web client library. http://www4.wiwiss. fu-berlin.de/bizer/ng4j/semwebclient/, seen Feb. 2010.\n[5] S. Braun, A. Schmidt, A. Walter, and V. Zacharias. Using the ontology maturing process model for searching, managing and retrieving resources with semantic technologies. In R. Meersman and Z. Tari, editors, OTM 2008, Part II, number 5332 in LNCS, pages 1567\u20131577. Springer-Verlag, 2008.\n[6] S. Braun and V. Zacharias. SOBOLEO \u2013 a repository for living ontologies. In M. d\u2019Aquin, A. Garc\u0301\u0131a Castro, C. Lange, and K. Viljanen, editors, 1st Workshop on Ontology Repositories and Editors, CEUR Workshop Proceedings, Hersonissos, Greece, May 2010.\n[7] S. Buswell, O. Caprotti, D. P. Carlisle, M. C. Dewar, M. Gaetano, and M. Kohlhase. The Open Math standard, version 2.0. Technical report, The Open Math Society, 2004.\n[8] J. Carette, L. Dixon, C. Sacerdoti Coen, and S. M. Watt, editors. MKM/Calculemus 2009 Proceedings, number 5625 in LNAI. Springer Verlag, July 2009.\n[9] D. Carlisle. The keyval package. The Comprehensive TEX Archive Network, 1999. Part of the TEX distribution.\n[10] Intelligent Computer Mathematics, number 6167 in LNAI. Springer Verlag, 2010. in press.\n[11] C. David, M. Kohlhase, C. Lange, F. Rabe, N. Zhiltsov, and V. Zholudev. Publishing math lecture notes as linked data. In L. Aroyo, G. Antoniou, E. Hyvo\u0308nen, A. ten Teije, H. Stuckenschmidt, L. Cabral, and T. Tudorache, editors, ESWC, number 6089 in Lecture Notes in Computer Science, pages 370\u2013375. Springer, June 2010.\n[12] FormalSafe. http://www.dfki.de/sks/formalsafe/, 2008. seen March 2010.\n[13] U. Frese, D. Hausmann, C. Lu\u0308th, H. Ta\u0308ubig, and D. Walter. The importance of being formal. In H. Hungar, editor, International Workshop on the Certification of Safety-Critical Software Controlled Systems SafeCert\u201908, volume 238 of Electronic Notes in Theoretical Computer Science, pages 57\u201370, Sept. 2008.\n[14] J. Giceva, C. Lange, and F. Rabe. Integrating web services into active mathematical documents. In Carette et al. [8], pages 279\u2013293.\n[15] T. Groza, S. Handschuh, K. Mo\u0308ller, and S. Decker. SALT \u2013 semantically annotated LATEX for scientific publications. In E. Franconi, M. Kifer, and W. May, editors, ESWC, number 4519 in Lecture Notes in Computer Science, pages 518\u2013532. Springer, 2007.\n[16] O. Hartig and J. Sequeda. SQUIN \u2013 query the web of linked data. http://squin.sourceforge.net, seen Feb. 2010.\n[17] T. Heath et al. Linked data \u2013 connect distributed data across the web \u2013 guides and tutorials. http: //linkeddata.org/guides-and-tutorials, seen Feb. 2010.\n[18] R. Heese, M. Luczak-Ro\u0308sch, R. Oldakowski, O. Streibel, and A. Paschke. One click annotation. In T. Tudorache, G. Correndo, N. Noy, H. Alani, and M. Greaves, editors, Proceedings of the Workshop on Collaborative Construction, Management and Linking of Structured Knowledge (CK2009), number 514 in CEUR Workshop Proceedings, 2009.\n[19] JOMDoc project \u2014 Java library for OMDoc documents. http://jomdoc.omdoc.org, 2010. seen Feb.\n[20] C. Jucovschi and M. Kohlhase. sTeXIDE: An integrated development environment for sTeX collections. In CICM10 [10]. in press.\n[21] A. Kohlhase. Overcoming Proprietary Hurdles: CPoint as Invasive Editor. In F. de Vries, G. Attwell, R. Elferink, and A. To\u0308dt, editors, Open Source for Education in Europe: Research and Practise, pages 51\u201356, Heerlen, The Netherlands, Nov. 2005. Open Universiteit Nederland, Open Universiteit Nederland. Proceedings at http://hdl.handle.net/1820/483.\n[22] A. Kohlhase, M. Kohlhase, and C. Lange. Dimensions of formality: A case study for MKM in software engineering. In CICM10 [10]. http://arxiv.org/abs/1004.5071.\n[23] M. Kohlhase. owl2onto.cls: Marking up OWL2 Ontologies in sTeX. https://svn.kwarc.info/repos/stex/trunk/\nsty/owl2onto/owl2onto.pdf. [24] M. Kohlhase. RDFa metadata in LATEX.\nhttps://svn.kwarc.info/repos/stex/trunk/ sty/rdfmeta/rdfmeta.pdf.\n[25] M. Kohlhase. OMDoc \u2013 An open markup format for mathematical documents [Version 1.2]. Number 4180 in LNAI. Springer Verlag, Aug. 2006. [26] M. Kohlhase. Using LATEX as a semantic markup format. Mathematics in Computer Science, 2(2):279\u2013304, 2008.\n[27] M. Kohlhase. An open markup format for mathematical documents OMDoc [version 1.3]. Draft Specification, 2010.\n[28] M. Kohlhase, J. Giceva, C. Lange, and V. Zholudev. JOBAD \u2013 interactive mathematical documents. In B. Endres-Niggemeyer, V. Zacharias, and P. Hitzler, editors, AI Mashup Challenge 2009, KI Conference, Sept. 2009.\n[29] C. Lange. The OMDoc document ontology. web page at http: //kwarc.info/projects/docOnto/omdoc.html, 2010. seen 3/2010.\n[30] C. Lange. Semantic Web Collaboration on Semiformal Mathematical Knowledge. PhD thesis, Jacobs University Bremen, 2010. submission expected in spring 2010.\n[31] C. Lange and M. Kohlhase. A mathematical approach to ontology authoring and documentation. In Carette et al. [8], pages 389\u2013404. [32] B. Miller. LaTeXML: A LATEX to XML converter. Web Manual at http://dlmf.nist.gov/LaTeXML/, seen May 2010.\n[33] T. Nipkow, L. C. Paulson, and M. Wenzel. Isabelle/HOL \u2014 A Proof Assistant for Higher-Order Logic. Number 2283 in LNCS. Springer, 2002.\n[34] OpenLink Software. OpenLink universal integration middleware \u2013 Virtuoso product family. web page at http://virtuoso.openlinksw.com.\n[35] SAMS. SAMSDocs: The document collection of the SAMS project, 2009. http://www.sams-projekt.de.\n[36] F.-P. Servant. Linking enterprise data. In C. Bizer, T. Heath, K. Idehen, and T. Berners-Lee, editors, Linked Data on the Web (LDOW 2008), number 369 in CEUR Workshop Proceedings, Apr. 2008.\n[37] Semantic Markup for LaTeX, seen July 2009. available at http://kwarc.info/projects/stex/.\n[38] J. Tennison et al. rdfQuery \u2013 RDF processing in your browser. http://code.google.com/p/rdfquery/, seen Feb. 2010.\n[39] V. Zholudev and M. Kohlhase. TNTBase: a versioned storage for XML. In Proceedings of Balisage: The Markup Conference 2009, Balisage Series on Markup Technologies. Mulberry Technologies, Inc., 2009. available at http: //kwarc.info/vzholudev/pubs/balisage.pdf.\n[40] V. Zholudev, M. Kohlhase, and F. Rabe. A [insert xml format] database for [insert cool application]. In Proceedings of XML Prague 2010, 2010."}], "references": [{"title": "RDFa Primer", "author": ["B. Adida", "M. Birbeck"], "venue": "W3C Working Group Note, World Wide Web Consortium (W3C), Oct.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Mathematical Markup Language (MathML) version 3.0", "author": ["R. Ausbrooks", "S. Buswell", "D. Carlisle", "G. Chavchanidze", "S. Dalmas", "S. Devitt", "A. Diaz", "S. Dooley", "R. Hunter", "P. Ion", "M. Kohlhase", "A. Lazrek", "P. Libbrecht", "B. Miller", "R. Miner", "M. Sargent", "B. Smith", "N. Soiffer", "R. Sutor", "S. Watt"], "venue": "W3C Candidate Recommendation of", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Tabulator: Exploring and analyzing linked data on the semantic web", "author": ["T. Berners-Lee", "Y. Chen", "L. Chilton", "D. Connolly", "R. Dhanaraj", "J. Hollenbach", "A. Lerer", "D. Sheets"], "venue": "Proceedings of the The 3 International Semantic Web User Interaction Workshop (SWUI06), Nov.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Semantic web client library", "author": ["C. Bizer", "T. Gau\u00df", "R. Cyganiak", "O. Hartig"], "venue": "http://www4.wiwiss. fu-berlin.de/bizer/ng4j/semwebclient/, seen Feb.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Using the ontology maturing process model for searching, managing and retrieving resources with semantic technologies", "author": ["S. Braun", "A. Schmidt", "A. Walter", "V. Zacharias"], "venue": "R. Meersman and Z. Tari, editors, OTM 2008, Part II, number 5332 in LNCS, pages 1567\u20131577. Springer-Verlag,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "SOBOLEO \u2013 a repository for living ontologies", "author": ["S. Braun", "V. Zacharias"], "venue": "M. d\u2019Aquin, A. Gar\u0107\u0131a Castro, C. Lange, and K. Viljanen, editors, 1 Workshop on Ontology Repositories and Editors, CEUR Workshop Proceedings, Hersonissos, Greece, May", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "The Open Math standard, version 2.0", "author": ["S. Buswell", "O. Caprotti", "D.P. Carlisle", "M.C. Dewar", "M. Gaetano", "M. Kohlhase"], "venue": "Technical report, The Open Math Society,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "MKM/Calculemus 2009 Proceedings, number 5625 in LNAI", "author": ["J. Carette", "L. Dixon", "C. Sacerdoti Coen", "S.M. Watt", "editors"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "The keyval package", "author": ["D. Carlisle"], "venue": "The Comprehensive TEX Archive Network,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1999}, {"title": "Publishing math lecture notes as linked data", "author": ["C. David", "M. Kohlhase", "C. Lange", "F. Rabe", "N. Zhiltsov", "V. Zholudev"], "venue": "L. Aroyo, G. Antoniou, E. Hyv\u00f6nen, A. ten Teije, H. Stuckenschmidt, L. Cabral, and T. Tudorache, editors, ESWC, number 6089 in Lecture Notes in Computer Science, pages 370\u2013375. Springer, June", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "The importance of being formal", "author": ["U. Frese", "D. Hausmann", "C. L\u00fcth", "H. T\u00e4ubig", "D. Walter"], "venue": "H. Hungar, editor, International Workshop on the Certification of Safety-Critical Software Controlled Systems SafeCert\u201908, volume 238 of Electronic Notes in Theoretical Computer Science, pages 57\u201370, Sept.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "SALT \u2013 semantically annotated  LTEX for scientific publications", "author": ["T. Groza", "S. Handschuh", "K. M\u00f6ller", "S. Decker"], "venue": "E. Franconi, M. Kifer, and W. May, editors, ESWC, number 4519 in Lecture Notes in Computer Science, pages 518\u2013532. Springer,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2007}, {"title": "SQUIN \u2013 query the web of linked data", "author": ["O. Hartig", "J. Sequeda"], "venue": "http://squin.sourceforge.net, seen Feb.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Linked data \u2013 connect distributed data across the web \u2013 guides and tutorials", "author": ["T. Heath"], "venue": "http: //linkeddata.org/guides-and-tutorials,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "One click annotation", "author": ["R. Heese", "M. Luczak-R\u00f6sch", "R. Oldakowski", "O. Streibel", "A. Paschke"], "venue": "T. Tudorache, G. Correndo, N. Noy, H. Alani, and M. Greaves, editors, Proceedings of the Workshop on Collaborative Construction, Management and Linking of Structured Knowledge (CK2009), number 514 in CEUR Workshop Proceedings,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Overcoming Proprietary Hurdles: CPoint as Invasive Editor", "author": ["A. Kohlhase"], "venue": "F. de Vries, G. Attwell, R. Elferink, and A. T\u00f6dt, editors, Open Source for Education in Europe: Research and Practise, pages 51\u201356, Heerlen, The Netherlands, Nov.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2005}, {"title": "OMDoc \u2013 An open markup format for mathematical documents [Version 1.2]. Number 4180 in LNAI", "author": ["M. Kohlhase"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2006}, {"title": "Using  LTEX as a semantic markup format", "author": ["M. Kohlhase"], "venue": "Mathematics in Computer Science, 2(2):279\u2013304,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2008}, {"title": "An open markup format for mathematical documents OMDoc [version 1.3", "author": ["M. Kohlhase"], "venue": "Draft Specification,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "JOBAD \u2013 interactive mathematical documents", "author": ["M. Kohlhase", "J. Giceva", "C. Lange", "V. Zholudev"], "venue": "B. Endres-Niggemeyer, V. Zacharias, and P. Hitzler, editors, AI Mashup Challenge 2009, KI Conference, Sept.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "The OMDoc document ontology", "author": ["C. Lange"], "venue": "web page at http: //kwarc.info/projects/docOnto/omdoc.html,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Semantic Web Collaboration on Semiformal Mathematical Knowledge", "author": ["C. Lange"], "venue": "PhD thesis, Jacobs University Bremen, 2010. submission expected in spring", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2010}, {"title": "LaTeXML: A  LTEX to XML converter", "author": ["B. Miller"], "venue": "Web Manual at http://dlmf.nist.gov/LaTeXML/, seen May", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2010}, {"title": "Isabelle/HOL \u2014 A Proof Assistant for Higher-Order Logic", "author": ["T. Nipkow", "L.C. Paulson", "M. Wenzel"], "venue": "Number 2283 in LNCS. Springer,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2002}, {"title": "Linking enterprise data", "author": ["F.-P. Servant"], "venue": "C. Bizer, T. Heath, K. Idehen, and T. Berners-Lee, editors, Linked Data on the Web (LDOW 2008), number 369 in CEUR Workshop Proceedings, Apr.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2008}, {"title": "rdfQuery \u2013 RDF processing in your browser", "author": ["J. Tennison"], "venue": "http://code.google.com/p/rdfquery/, seen Feb", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2010}, {"title": "TNTBase: a versioned storage for XML", "author": ["V. Zholudev", "M. Kohlhase"], "venue": "Proceedings of Balisage: The Markup Conference 2009, Balisage Series on Markup Technologies. Mulberry Technologies, Inc.,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2009}, {"title": "A [insert xml format] database for [insert cool application", "author": ["V. Zholudev", "M. Kohlhase", "F. Rabe"], "venue": "Proceedings of XML Prague 2010,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 10, "context": "SIL-3 standard compliant (see [13]).", "startOffset": 30, "endOffset": 34}, {"referenceID": 23, "context": "the software development to follow the V-model (figure 1) and to be based on a verification of certain safety properties in the proof checker Isabelle [33].", "startOffset": 151, "endOffset": 155}, {"referenceID": 15, "context": "One such approach is that of \u201cinvasive technology\u201d [21] with the basic idea that from a user\u2019s perspective, semantic authoring and general editing are the same, so why not offer semantic functionalities as an extension of well-known editing systems, thereby \u2018invading\u2019 the existent ones.", "startOffset": 51, "endOffset": 55}, {"referenceID": 17, "context": "Therefore, we used the invasive OMDoc frontend for LTEX documents called STEX [26].", "startOffset": 78, "endOffset": 82}, {"referenceID": 17, "context": "-ORIENTED LTEX MARKUP STEX [26, 37] is an extension of the LTEX language that is geared towards marking up the semantic structure underlying a document.", "startOffset": 27, "endOffset": 35}, {"referenceID": 1, "context": "/background/sets]{sets} \\symdef{Reals}{\\mathbb{R}} \\symdef{greater}[2]{#1>#2} 5 \\symdef{positiveReals}{\\Reals^+} \\begin{definition}[id=posreals.", "startOffset": 67, "endOffset": 70}, {"referenceID": 22, "context": "But the main advantage of markup in STEX is that it can be transformed to XML via the LTEXML system [32]: Listing 2 shows the OMDoc [25] representation generated from the STEX sources in listing 1.", "startOffset": 100, "endOffset": 104}, {"referenceID": 16, "context": "But the main advantage of markup in STEX is that it can be transformed to XML via the LTEXML system [32]: Listing 2 shows the OMDoc [25] representation generated from the STEX sources in listing 1.", "startOffset": 132, "endOffset": 136}, {"referenceID": 6, "context": "that extends the formula markup formats OpenMath [7] and", "startOffset": 49, "endOffset": 52}, {"referenceID": 1, "context": "MathML [2] to a document markup format.", "startOffset": 7, "endOffset": 10}, {"referenceID": 19, "context": ", the semantic structure of the part of a mathematical formula that the user has selected, turns our rendered mathematical documents into powerful mashups [28].", "startOffset": 155, "endOffset": 159}, {"referenceID": 26, "context": "JOBAD architecture has been designed without depending on a particular backend; for most of our services we are using the extensible XML-aware database TNTBase [39, 40, 11], which has special support for OMDoc and integrates the JOMDoc rendering library.", "startOffset": 160, "endOffset": 172}, {"referenceID": 27, "context": "JOBAD architecture has been designed without depending on a particular backend; for most of our services we are using the extensible XML-aware database TNTBase [39, 40, 11], which has special support for OMDoc and integrates the JOMDoc rendering library.", "startOffset": 160, "endOffset": 172}, {"referenceID": 9, "context": "JOBAD architecture has been designed without depending on a particular backend; for most of our services we are using the extensible XML-aware database TNTBase [39, 40, 11], which has special support for OMDoc and integrates the JOMDoc rendering library.", "startOffset": 160, "endOffset": 172}, {"referenceID": 0, "context": "these, we had incorporated RDFa [1] as a flexible metadata", "startOffset": 32, "endOffset": 35}, {"referenceID": 18, "context": "3 [27].", "startOffset": 2, "endOffset": 6}, {"referenceID": 21, "context": "We have explored this correspondence for OMDoc in previous work and implemented a translation between OMDoc and OWL [31, 30].", "startOffset": 116, "endOffset": 124}, {"referenceID": 8, "context": "in line 11 of listing 2 is the transformation result of using the KeyVal [9] pair title=.", "startOffset": 73, "endOffset": 76}, {"referenceID": 0, "context": "\\symdef{state-doc-rd}[1]{rd.", "startOffset": 21, "endOffset": 24}, {"referenceID": 20, "context": "Even though OMDoc uses native non-RDFa markup for these structures, we can also represent these in RDF, exploiting the OMDoc ontology (see [29, 11] for more information).", "startOffset": 139, "endOffset": 147}, {"referenceID": 9, "context": "Even though OMDoc uses native non-RDFa markup for these structures, we can also represent these in RDF, exploiting the OMDoc ontology (see [29, 11] for more information).", "startOffset": 139, "endOffset": 147}, {"referenceID": 25, "context": "We have implemented this using the rdfQuery JavaScript library [38], which parses all RDFa annotations of a document into a local triple store that can be queried using SPARQL-like JavaScript functions.", "startOffset": 63, "endOffset": 67}, {"referenceID": 26, "context": "On the server side, we have extended TNTBase [39], our versioned database backend and web server/application", "startOffset": 45, "endOffset": 49}, {"referenceID": 13, "context": "XHTML+MathML+RDFa, and, optionally, RDF/XML, according to the Linked Data best practices [17].", "startOffset": 89, "endOffset": 93}, {"referenceID": 12, "context": "In our setup, we have experimented with SQUIN [16], a frontend to the Semantic Web Client library [4], which gives access to Linked Data via a simple HTTP frontend at very low integration costs: If the server provides standard-compliant Linked Data, then the client simply has to access the URL of the SQUIN server, providing a SPARQL query as a parameter.", "startOffset": 46, "endOffset": 50}, {"referenceID": 3, "context": "In our setup, we have experimented with SQUIN [16], a frontend to the Semantic Web Client library [4], which gives access to Linked Data via a simple HTTP frontend at very low integration costs: If the server provides standard-compliant Linked Data, then the client simply has to access the URL of the SQUIN server, providing a SPARQL query as a parameter.", "startOffset": 98, "endOffset": 101}, {"referenceID": 2, "context": "An alternative would have been AJAR library, a part of the Tabulator Linked Data browser [3], which implements the same functionality in JavaScript.", "startOffset": 89, "endOffset": 92}, {"referenceID": 9, "context": "Concretely, we make a SPARQL endpoint powered by the Virtuoso triple store [34] available as an extension to TNTBase [11].", "startOffset": 117, "endOffset": 121}, {"referenceID": 24, "context": "In a larger Software Engineering scenario (like a document collection of a company with multiple departments) a combination with a Linked Data crawler, as offered by the Sponger extension to Virtuoso in an integrated server-side fashion, may have advantages: if all these departments publish their document collections as Linked Data in the company intranet (see for instance [36] for the topicality of this example), crawling these may reveal previously unknown connections, e.", "startOffset": 376, "endOffset": 380}, {"referenceID": 11, "context": "SALT [15] also allows for annotating semantic relations in LTEX documents and exporting them as Linked Data.", "startOffset": 5, "endOffset": 9}, {"referenceID": 5, "context": "SOBOLEO [6] is a lightweight graphical user interface for creating and editing vocabularies/ontologies in OWL based on Web 2.", "startOffset": 8, "endOffset": 11}, {"referenceID": 4, "context": "In [5], the authors evaluate its usage along their \u201cOntology Maturing Process Model\u201d, in which they confirm the succeeding phases \u201cemergence of ideas\u201d, \u201cconsolidation in communities\u201d, \u201cformalization\u201d, and \u201caxiomatization\u201d in an ontology engineering process.", "startOffset": 3, "endOffset": 6}, {"referenceID": 14, "context": "loomp is an example of a WYSIWYG editor for annotating HTML documents with terms from vocabularies, yielding RDFa [18].", "startOffset": 114, "endOffset": 118}, {"referenceID": 9, "context": "As a client-side counterpart to the integrated repository and Linked Data publishing solution provided by TNTBase [11], we are currently developing an integrated collection authoring environment STEXIDE for STEX on the basis of the Eclipse framework [20].", "startOffset": 114, "endOffset": 118}], "year": 2013, "abstractText": "We present the STEX+ system, a user-driven advancement of STEX \u2014 a semantic extension of LTEX that allows for producing high-quality PDF documents for (proof)reading and printing, as well as semantic XML/OMDoc documents for the Web or further processing. Originally STEX had been created as an invasive, semantic frontend for authoring XML documents. Here, we used STEX in a Software Engineering case study as a formalization tool. In order to deal with modular pre-semantic vocabularies and relations, we upgraded it to STEX+ in a participatory design process. We present a tool chain that starts with an STEX+ editor and ultimately serves the generated documents as XHTML+RDFa Linked Data via an OMDoc-enabled, versioned XML database. In the final output, all structural annotations are preserved in order to enable semantic information retrieval services.", "creator": "LaTeX with hyperref package"}}}