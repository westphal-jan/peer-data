{"id": "1105.1033", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2011", "title": "Adaptively Learning the Crowd Kernel", "abstract": "We present an algorithm that learns a similarity matrix for n objects over all n ^ 2 pairs solely from crowdsourced data. The algorithm randomly responds to adaptively selected triplet-based relativity similarity queries. Each query is in the form of \"is object\" a \"more similar to\" b \"or\" c \"?\" and is selected based on the previous answers in such a way that it is maximum informative. The result is an embedding of the objects in Euclidean space (such as MDS); we call this a \"crowd kernel.\"", "histories": [["v1", "Thu, 5 May 2011 11:03:03 GMT  (3710kb,D)", "https://arxiv.org/abs/1105.1033v1", "9 pages, 7 figures, Accepted to the 28th, International Conference on Machine Learning, 2011"], ["v2", "Sat, 25 Jun 2011 21:54:08 GMT  (3805kb,D)", "http://arxiv.org/abs/1105.1033v2", "9 pages, 7 figures, Accepted to the 28th International Conference on Machine Learning (ICML), 2011"]], "COMMENTS": "9 pages, 7 figures, Accepted to the 28th, International Conference on Machine Learning, 2011", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["omer tamuz", "ce liu", "serge j belongie", "ohad shamir", "adam kalai"], "accepted": true, "id": "1105.1033"}, "pdf": {"name": "1105.1033.pdf", "metadata": {"source": "META", "title": "Adaptively Learning the Crowd Kernel", "authors": ["Omer Tamuz", "Ce Liu"], "emails": ["omertamuz@weizmann.ac.il", "celiu@microsoft.com", "sjb@cs.ucsd.edu", "ohadsh@microsoft.com", "adum@microsoft.com"], "sections": [{"heading": null, "text": "pairs, from crowdsourced data alone. The algorithm samples responses to adaptively chosen triplet-based relative-similarity queries. Each query has the form \u201cis object a more similar to b or to c?\u201d and is chosen to be maximally informative given the preceding responses. The output is an embedding of the objects into Euclidean space (like MDS); we refer to this as the \u201ccrowd kernel.\u201d SVMs reveal that the crowd kernel captures prominent and subtle features across a number of domains, such as \u201cis striped\u201d among neckties and \u201cvowel vs. consonant\u201d among letters."}, {"heading": "1. Introduction", "text": "Essential to the success of machine learning on a new domain is determining a good \u201csimilarity function\u201d between objects (or alternatively defining good object \u201cfeatures\u201d). With such a \u201ckernel,\u201d one can perform a number of interesting tasks, e.g. binary classification using Support Vector Machines, clustering, interactive database search, or any of a number of other off-the-shelf kernelized applications. Since this step of determining a kernel is most often the step that is still not routinized, effective systems for achieving this step\nAppearing in Proceedings of the 28 th International Conference on Machine Learning, Bellevue, WA, USA, 2011. Copyright 2011 by the author(s)/owner(s).\nare desirable as they hold the potential for completely removing the machine learning researcher from \u201cthe loop.\u201d Such systems could allow practitioners with no machine learning expertise to employ learning on their domain. In many domains, people have a good sense of what similarity is, and in these cases the similarity function may be determined based upon crowdsourced human responses alone.\nThe problem of capturing and extrapolating a human notion of perceptual similarity has received increasing attention in recent years including areas such as vision (Agarwal et al., 2007), audition (McFee & Lanckriet, 2009), information retrieval (Schultz & Joachims, 2003) and a variety of others represented in the UCI Datasets (Xing et al., 2003; Huang et al., 2010). Concretely, the goal of these approaches is to estimate a similarity matrix K over all pairs of n objects given a (potentially exhaustive) subset of human perceptual measurements on tuples of objects. In some cases the set of human measurements represents \u2018side information\u2019 to computed descriptors (MFCC, SIFT, etc.), while in other cases \u2013 the present work included \u2013 one proceeds exclusively with human reported data. When K is a positive semidefinite matrix induced purely from distributed human measurements, we refer to it as the crowd kernel for the set of objects.\nGiven such a Kernel, one can exploit it for a variety of purposes including exploratory data analysis or embedding visualization (as in Multidimensional Scaling) and relevance-feedback based interactive search. As discussed in the above works and (Kendall & Gibbons, 1990), using a triplet based representation of relative similarity, in which a subject is asked \u201cis object\nar X\niv :1\n10 5.\n10 33\nv2 [\ncs .L\nG ]\n2 5\na more similar to b or to c,\u201d has a number of desirable properties over the classical approach employed in Multi-Dimensional Scaling (MDS), i.e., asking for a numerical estimate of \u201chow similar is object a to b.\u201d These advantages include reducing fatigue on human subjects and alleviating the need to reconcile individuals\u2019 scales of similarity. The obvious drawback with the triplet based method, however, is the potential O(n3) complexity. It is therefore expedient to seek methods of obtaining high quality approximations of K from as small a subset of human measurements as possible. Accordingly, the primary contribution of this paper is an efficient method for estimating K via an information theoretic adaptive sampling approach.\nAt the heart of our approach is a new scale-invariant Kernel approximation model. The choice of model is shown to be crucial in terms of the adaptive triples that are produced, and the new model produces effective triples to label. Although this model is nonconvex, we prove that it can be optimized under certain assumptions.\nWe construct an end-to-end system for interactive visual search and browsing using our Kernel acquisition algorithm. The input to this system is a set of images of objects, such as products available in an online store. The system automatically crowdsources1 the\n1Crowdsourcing was done on Amazon\u2019s Mechanical Turk, http://mturk.com.\nkernel acquisition and then uses this kernel to produce a visual interface for searching or browsing the set of products. Figure 1 shows this interface for a dataset of 433 floor tiles available at amazon.com."}, {"heading": "1.1. Human kernels versus machine kernels", "text": "The bulk of work in Machine Learning focuses on \u201cMachine Kernels\u201d that are computed by computer from the raw data (e.g., pixels) themselves. Additional work employs human experiments to try to learn kernels based upon machine features, i.e., to approximate the human similarity assessments based upon features that can be derived by machine. In contrast, when a kernel is learned from human subjects alone (whether it be data from an individual or a crowd) one requires no machine features whatsoever. To the computer, the objects are recognized by ID\u2019s only \u2013 the images themselves are hidden from our system and are only presented to humans.\nThe primary advantage of machine kernels is that they can generalize immediately to new data, whereas each additional object needs to be added to our system, for a cost of approximately $0.15.2 On the other hand, working with a human kernel has two primary advantages. First, it does not require any domain expertise. While for any particular domain, such as music or images of faces, cars, or sofas, decades of research may have provided high-quality features, one does not have to find, implement, and tune these sophisticated feature detectors.\nSecond, human kernels contain features that are simply not available with state-of-the-art feature detectors, because of knowledge and experience that humans possess. For example, from images of celebrities, human similarity may be partly based on whether the two celebrities are both from the same profession, such as politicians, actors, and so forth. Until the longstanding goal of bridging the semantic gap is achieved, humans will be far better than machines at interpreting certain features, such as \u201cdoes a couch look comfortable,\u201d \u201ccan a shoe be worn to an informal occasion,\u201d or \u201cis a joke funny.\u201d\nWe give a simple demonstration of external knowledge through experiments on 26 images of the lower-case Roman alphabet. Here, the learned Kernel is shown to capture features such as \u201cis a letter a vowel versus consonant,\u201d which uses external knowledge beyond the pixels. Note that this experiment is interesting in itself\n2This price was empirically observed to yield \u201cgood performance\u201d across a number of domains. See the experimental results section for evaluation criteria.\nbecause it is not at first clear if people can meaningfully answer the question: \u201cis the letter e more similar to i or p.\u201d Our experiments show statistically significant consistency with 58%3(\u00b12%, with 95% confidence) agreement between users on a random triple of letters. (For random image triples from an online tie store, 68% agreement is observed, and 65% is observed for floor tile images)."}, {"heading": "2. Benefits of adaptation", "text": "We first give high-level intuition for why adaptively choosing triples may yield better kernel approximations than randomly chosen triples. Consider n objects organized in a rooted tree with ` n leaves, inspired by, say, phylogenic trees involving animal species.4 Say the similarity between objects is decreasing in their distance in the tree graph and, furthermore, that objects are drawn uniformly at random from the classes represented by the leaves of the tree. Ignoring the details of how one would identify that two objects are in the same leaf or subtree, it is clear that a nonadaptive method would have to ask \u2126(n`) questions to determine the leaves to which n objects belong (or at least to determine which objects are in the same leaves), because an expected \u2126(`) queries are required per object until just a second object is chosen from the same leaf. On the other hand, in an ideal setting, an adaptive approach might determine such matters using O(n log `) queries in a balanced binary tree, proceeding from the root down, assuming a constant number of comparisons can determine to which subtree of a node an object belongs, hence an exponential savings."}, {"heading": "3. Related work", "text": "As discussed above, much of the work in machine learning on learning kernels employs \u2018side information\u2019 in the form of features about objects. Schultz & Joachims (2003) highlight the fact that triple-based information may also be gathered by web search click data. Agarwal et al. (2007) is probably the most similar work, in which they learn a kernel matrix from triples of similarity comparisons, as we do. However, the triples they consider are randomly (nonadaptively) chosen. Their particular fitting algorithm differs in\n3While this fraction of agreement seems small, it corresponds to about 25% \u201cnoise,\u201d e.g., if 75% of people would say that a is more like b then c, then two random people would agree with probability 0.752 = 0.56.\n4This example is based upon a tree metric rather than a Euclidean one. However, note that any tree with ` leaves can be embedded in `-dimensional Euclidean space, where squared Euclidean distance equals tree distance.\nthat it is based on a max-margin approach, which is more common in the kernel learning literature.\nThere is a wealth of work in active learning for classification, where a learner selects examples from a pool of unlabeled examples to label. A number of approaches have been employed, and our work is in the same spirit as those that employ probabilistic models and information-theoretic measures to maximize information. Other work often labels examples based on those that are closest to the margin or closest to 50% probability of being positive or negative. To see why this latter approach may be problematic in our setting, one could imagine a set of triples where we have accurately learned that the answer is 50/50, e.g., as may be the case if a, b, and c bear no relation to each other or if they are identical. One may not want to focus on such triples."}, {"heading": "4. Preliminaries", "text": "The set of n objects is denoted by [n] = {1, 2, . . . , n}. For a, b, c \u2208 [n], a comparison or triple is of the form, \u201cis a more similar to b or to c.\u201d We refer to a as the head of the triple. We write pabc for the probability that a random crowd member rates a as more similar to b, so pabc + p a cb = 1. The n objects are assumed to have d-dimensional Euclidean representation, and hence the data can be viewed as a matrix M \u2208 Rn\u00d7d, where Ma denotes the row corresponding to a, and the similarity matrix K \u2208 Rn\u00d7n is defined by Kab = Ma \u00b7Mb, or equivalently K = MMT . The goal is to learn M or, equivalently, learn K. (It is easy to go back and forth between positive semidefinite (PSD) K and M , though M is only unique up to change of basis.) Also equivalent is the representation in terms of distances, d2(a, b) = Kaa \u2212 2Kab +Kbb.\nIn our setting, an MDS algorithm takes as input m comparisons (a1b1c1, y1) . . . (ambmcm, ym) on n items, where yi \u2208 {0, 1} indicates whether ai is more like bi than ci. Unless explicitly stated, we will often omit yi and assume that the bi and ci have been permuted, if necessary, so that ai was rated as more similar to bi than ci. The MDS algorithm outputs an embedding M \u2208 Rn\u00d7d for some d \u2265 1. A probabilistic MDS model predicts p\u0302abc based on Ma, Mb, and Mc. The empirical log-loss of a model that predicts p\u0302aibici is 1/m \u2211 i log 1/p\u0302 ai bici\n. Our probabilistic MDS model attempts to minimize empirical log loss subject to some regularization constraint. We choose a probabilistic model due to its suitability for use in combination with our information-gain criteria for selecting adaptive triples, and also due to the fact that the same triple may elicit different answers from different peo-\nple (or the same person on different occasions).\nAn active MDS algorithm chooses each triple, aibici, adaptively based upon previous labels (a1b1c1, y1),. . .,(ai\u22121bi\u22121ci\u22121, yi\u22121). We denote by MT the transpose of matrix M . For compact convex set W , let \u03a0W (K) = arg minT\u2208W \u2211 ij(Kij \u2212 Tij)2 be the closest matrix in W to K. Also define the set of symmetric unit-length PSD matrices,\nB = {K 0 | K11 = K22 = . . . = Knn = 1}.\nProjection to the closest element of B is a quadratic program which can be solved via a number of existing techniques (Srebro & Shraibman, 2005; Lee et al., 2010)."}, {"heading": "5. Our algorithm", "text": "Our algorithm proceeds in phases. In the first phase, it queries a certain number of random triples comparing each object a \u2208 [n] to random pairs of distinct b, c. (Note that we never present a triple where a = b or a = c except for quality control purposes.) Subsequently, it fits the results to a matrix M \u2208 Rn\u00d7d (equivalently, fits K 0) using the probabilistic relative similarity model described below. Then it uses our adaptive selection algorithm to select further random triples. This iterates: in each phase all previous data is refit to the relative model, and then the adaptive selection algorithm generates more triples.\n\u2022 For each item a \u2208 [n], crowdsource labels for R random triples with head a.\n\u2022 For t = 1, 2, . . . , T :\n\u2013 Fit Kt to the labeled data gathered thus far, using the method described in Section 5.1 (with d dimensions). \u2013 For each a \u2208 [n], crowdsource a label for the maximally informative triple with head a, using the method described in Section 6.\nTypical parameter values which worked quickly and well across a number of medium-sized data sets of (hundreds of objects) were R = 10, T = 25, and d = 3. These settings were also used to generate Figure 2. We first describe the probabilistic MDS model and then the adaptive selection procedure. Further details are given in Section 7."}, {"heading": "5.1. Relative similarity model", "text": "The relative similarity model is motivated by the scaleinvariance observed in many perceptual systems (see,\ne.g., Chater & Brown, 1999). Let \u03b4ab = \u2016Ma\u2212Mb\u20162 = Kaa + Kbb \u2212 2Kab. A simple scale-invariant proposal takes p\u0302abc = \u03b4ac \u03b4ab+\u03b4ac . Such a model must also be regularized or else it would have \u0398(n2) degrees of freedom. One may regularize by the rank of K or by setting Kii = 1. Due to the scale-invariance of the model, however, this latter constraint does not have reduced complexity. In particular, note that halving or doubling the matrix M doesn\u2019t change any probabilities. Hence, descent algorithms may lead to very small, large, or numerically unstable solutions. To address this, we modify the model as follows, for distinct a, b, c:\np\u0302abc = \u00b5+ \u03b4ac\n2\u00b5+ \u03b4ab + \u03b4ac and Kii = 1, (1)\nfor some parameter \u00b5 > 0. Alternatively, this change may be viewed as an additional assumption imposed on the previous model \u2013 we suppose each object possesses a minimal amount of \u201cuniqueness,\u201d \u00b5 > 0, such that K = \u00b5I + T , where T 0. We fit the model by local optimization performed directly on M (with random initialization), and high-quality adaptive triples are produced even for low dimensions.5 Here \u00b5 serves a purpose similar to a margin constraint.\nThere are two interesting points to make about our choice of model. First, the loss is not convex in K, so there is a concern that local optimization may be susceptible to local minima. In Section 6.1, we state a theorem which explains why this does not seem to be a significant problem. Second, in Section 6.2, we discuss a simple convex alternative based on logistic regression, and we explain why this model, in combination with our adaptive selection criterion, gives rise to poor adaptively-selected triples."}, {"heading": "6. Adaptive selection algorithm", "text": "The idea is to capture the uncertainty about the location of an object through a probability distribution over points in Rd, and then to ask the question that maximizes information gain. Given a set of previous comparisons of n objects, we generate, for each object a = 1, 2, . . . , n, a new triple to compare a to, as follows. First, we embed the objects into Rd as described above, using the available comparisons. Initially, we use a seed of randomly selected triples for this purpose. Later, we use all available comparisons - the initial random ones and those acquired adaptively.\n5For high-dimensional problems, we perform a gradient projection descent on K. In particular, starting with K0 = I, we compute Kt+1 = \u03a0B(K\nt \u2212 \u03b7\u2207L(K)) for step-size \u03b7 (see Preliminaries for the definition of \u03a0B).\nNow, say the crowd has previously rated a as more similar to bi than ci, for i = 1, 2, . . . , j\u22121, and we want to generate the jth query, (a, bj , cj) (this is a slight abuse of notation because we don\u2019t know which of bj or cj will be rated as closer to a). These observations imply a posterior distribution of \u03c4(x) \u221d \u03c0(x) \u220f i p\u0302 x bici over x \u2208 Rd, where x is the embedding of a, and \u03c0(x) is a prior distribution, to be described shortly.\nGiven any candidate query for objects in the database b and c, the model predicts that the crowd will rate a as more similar to b than c with probability\np \u221d \u222b x \u03b4(x,c) \u03b4(x,b)+\u03b4(x,c)\u03c4(x)dx. If it rates a more similar to b than c then x has a posterior distribution of \u03c4b(x) \u221d \u03c4(x) \u03b4(x,c)\u03b4(x,b)+\u03b4(x,c) , and \u03c4c(x) (of similar form) otherwise. The information gain of this query is defined to be H(\u03c4)\u2212 pH(\u03c4b)\u2212 (1\u2212 p)H(\u03c4a), where H(\u00b7) is the entropy of a distribution. This is equal to the mutual information between the crowd\u2019s selection and x. The algorithm greedily selects a query, among all pairs b, c 6= a, which maximizes information gain. This can be somewhat computationally intensive (seconds per object in our datasets), so for efficiency we take the best pair from a sample of random pairs.\nIt remains to explain how we generate the prior \u03c0. We take \u03c0 to be the uniform distribution over the set of points in M . Hence, the process can be viewed as follows. For the purpose of generating a new triple, we pretend the coordinates of all other objects are perfectly known, and we pretend that the object in question, a, is a uniformly random one of these other objects. The chosen pair is designed to maximize the information we receive about which object it is, given the observations we already have about a. The hope is that, for sufficiently large data sets, such a data-driven prior is a reasonable approximation to the actual distribution over data. Another natural alternative prior would be a multinormal distribution fit to M ."}, {"heading": "6.1. Optimization guarantee", "text": "The relative similarity model is appealing in that it fits the data well, suggests good triples, and also represents interesting features on the data. Unfortunately, the model itself is not convex. We now give some justification for why gradient descent should not get trapped in local minima. As is sometimes the case in learning, it is easier to analyze an online version of the algorithm, i.e., a stochastic gradient descent. Here, we suppose that the sequence of triples is presented in order: the learner predicts Kt+1 based on (a1, b1, c1, y1), . . . , (at, bt, ct, yt). The loss on iteration t is `t(K\nt) = log 1/p where p is the probability that the relative model with Kt assigned to the correct out-\ncome.\nWe state the following theorem about stochastic gradient descent, where K0 \u2208 B is arbitrary and Kt+1 = \u03a0B(K\nt \u2212 \u03b7\u2207`t(Kt)). Theorem 1. Let at, bt, ct \u2208 [n] be arbitrary, for t = 1, 2, . . .. Suppose there is a matrix K\u2217 \u2208 B such that Pr[yt = 1] =\n\u00b5+2\u22122K\u2217ac 2\u00b5+4\u22122K\u2217ab\u22122K\u2217ac . For any > 0, there\nexists an T0 such that for any T > T0 and \u03b7 = 1/ \u221a T ,\nE\n[ 1\nT T\u2211 t=1 `t(K t)\u2212 `t(K\u2217)\n] \u2264 .\nWe prove this theorem in Appendix A."}, {"heading": "6.2. The logistic model: A convex alternative", "text": "As a small digression, we explain why the choice of probabilistic model is especially important for adaptive learning. To this end, consider the following logistic model. This model is a natural hybrid of logistic regression and MDS.\np\u0302abc = eKab\neKab + eKac =\n1\n1 + eKac\u2212Kab . (2)\nNote that log 1 + eKac\u2212Kab is a convex function of K \u2208 Rn\u00d7n. Hence, the problem of minimizing its empirical log loss over a convex set is a convex optimization problem.\nExperiments indicate that the logistic model fits data well and reproduces interesting features, such as vowel/consonant or stripedness. However, empirically it performs poorly in terms of deciding which triples to ask. Note that the logistic model (and any generalized linear model) will select extreme comparisons, where the inner products are as large as possible. To give an intuitive understanding, suppose that hair length was a single feature and one wanted to determine whether a person has hair length x or x+1. The logistic model would compare that person to a bald person (x = 0) and a person with hair length 2x+1, while the relative model would ideally compare him to people with hair lengths x and x+ 1."}, {"heading": "7. System parameters & quality control", "text": "Experiments were performed using Amazon\u2019s Mechanical Turk web service, where we defined \u2018Human Intelligence Tasks\u2019 to be performed by one or more users. Each task consists of 50 comparisons and the interface is optimized to be performed with 50 mouse clicks (and no scrolling). The mean completion time was\napproximately 2 minutes. This payment was determined based upon worker feedback. Initial experiments revealed a high percentage of seemingly random responses, but after closer inspection the vast majority of these poor results came from a small number of individuals. To improve quality control, we imposed a limit on the maximum number of tasks a single user could perform on any one day, we selected users who had completed at least 48 tasks with a 95% approval rate, and each task included 20% triples for which there was tremendous agreement between users. These \u201cgold standard\u201d triples were also automatically generated and proved to be an effective manner to recognize and significantly reduce cheating. The system is implemented using Python, Matlab, and C, and runs completely automatically in Windows or Unix."}, {"heading": "7.1. Question phrasing and crowd alignment", "text": "One interesting issue is how to frame similarity questions. On the one hand, it seems purest in form to give the users carte blanche and ask only, \u201cis a more similar to b than c.\u201d On the other hand, in feedback users complained about these tasks and often asked what we meant by similarity. Moreover, different users will inevitably weigh different features differently when performing comparisons.\nFor example, consider a comparisons of face images, where a is a white male, b is a black male, and c is a white female. Some users will consider gender more important in determining skin color, and others may feel the opposite is true. Others may feel that the question is impossible to answer. Consider phrasing the question as follows, \u201cAt a distance, who would you be more likely to mistake for a: b or c?\u201d For any two people, there is presumably some distance at which one might be mistaken for the other, so the question may seem more possible to answer for some people. Second, users may more often agree that skin color is more important than gender, because both are easily identified close up by skin color may be identifiable even at a great distance. While we haven\u2019t done experiments to determine the importance of question phrasing, anecdotal evidence suggests that users enjoy the tasks more when more specific definitions of similarity are given.\nTwo natural goals of question phrasing might be: (1) to align users in their ranking of the importance of different features and (2) to align user similarity notions with the goals of the task at hand. For example, if the task is to find a certain person, the question, \u201cwhich two people are most likely to be (genealogically) related to one another,\u201d may be poor because\nusers may overlook features such as gender and age. In our experiments on neckties, for example, the task was titled \u201cWhich ties are most similar?\u201d and the complete instructions were: \u201cSomeone went shopping at a tie store and wanted to buy the item on top, but it was not available. Click on item (a) or (b) below that would be the best substitute.\u201d"}, {"heading": "8. Experiments and Applications", "text": "We experiment on four datasets: (1) twenty-six images of the lowercase roman alphabet (Calibri font) (2) 223 country flag images from flagpedia.net, (3) 433 floor tile images from Amazon.com, and (4) 300 product images from an online tie store also hosted at Amazon.com. We also consider a hand-selected \u201cmixed\u201d dataset consisting of 225 images: 75 ties, 75 tiles, and 75 flags. Surprisingly, it seems that for these datasets about 30-40 triples per object suffice to learn the Crowd Kernel well, according to the 20Q metric that we describe below.. Figure 2 shows the results on the mixed dataset, comparing the 20Q metric trained on random vs. adaptive triples. For both adaptive and random questions, for certain performance levels, one requires about 60% more random queries than adaptive queries. Given very little data or a lot of data, one\ndoes not expect the adaptive algorithm to perform significantly better.\nFigure 3 shows the adaptive triples selected on an illustrative dataset composed of a mixture of flags, ties and tiles.\nFor ease of implementation, we assume all users are identical. This is a natural starting point, especially given that our main focus is on active learning."}, {"heading": "8.1. 20 Questions Metric", "text": "Since one application of such systems is search, i.e., searching for an item that a user knows what it looks like (we assume that the user can answer queries as if she even knows what the store image looks like), it is natural to ask how well we have \u201choned in\u201d on\nthe desired object after a certain number of questions. For the 20 Questions (20Q) metric, two independent parts of the system are employed, an evaluator and a guesser. First, the evaluator randomly and secretly selects an object in the database, x. The guesser is aware of the database but not of which item x has been selected. The guesser is allowed to query 20 triples (as in the game \u201c20 Questions\u201d) with head x, after which it produces a ranking of items in the database, from most to least likely. Then the evaluator reveals the identity of x and hence its position in the ordered ranking, as well. The metric is the average log of the position of the random target item in this list. The log reflects the idea that the position of lower-ranked objects is less import \u2013 it weights moving an object from position 2 to 4 as important as moving an object from position 20 to 40. This metric is meant to roughly capture performance, but of course in a real system users may not have the patience to click on twenty pairs of images and may prefer to have fewer clicks but use larger comparison sets. (Our GUI has the user select one of 8 or 9 images, which could potentially convey the same information as 3 binary choices.) Now, the questions that the guesser asks could be random questions, which we refer to as the 20 Random Questions metric, or adaptively chosen, for the 20 Adaptive Questions metric. In the latter case, the guesser uses the same maximum information-gain criterion as in the adaptive triple generation algorithm, relative to whichever model was learned (based on random or adaptively selected training triples)."}, {"heading": "8.2. Using the Kernel for Classification", "text": "The learned Kernels may be used in a linear classifier such as a support vector machine. This helps elucidate which features have been used by humans in labeling\nthe data. In the experiments below, an unambiguous subset of the images were labeled with binary \u00b1 classes. For example, we omitted the letter y in labeling vowels and consonants (y was in fact classified as a consonant, and c was misclassified as a vowel), and we selected only completely striped or unstriped flags for flag stripe classification. The SVM-Light (Joachims, 1998) package was used with default parameters and its leave-one-out (LOO) classification results are reported in Figure 8."}, {"heading": "8.3. Visual Search", "text": "We provide a GUI visual search tool, exemplified in Figure 1. Given n images, their embedding into Rd and the related probabilistic model for triples, we would like to help a user find either a particular object she has in mind, or a similar one. We do this by playing \u201c20 Questions\u201d with 8- or 9-tuple queries, generated by an information-gain adaptive selection algorithm very similar to the one described in Section 6.\nAcknowledgments. We thank Sham Kakade and Varun Kanade for helpful discussions. Serge Belongie\u2019s research is partly funded by ONR MURI Grant N00014-08-1-0638 and NSF Grant AGS-0941760."}, {"heading": "A. Proof of Theorem 1", "text": "A.1. Analysis\nBefore we present the proof of Theorem 1, we introduce a natural generalization which will be a convenient abstraction. We call this relative regression.\nA.2. Relative regression\nConsider the following online relative regression model. There is a sequence of examples (x1, x \u2032 1, y1), (x2, x \u2032 2, y2), . . . , (xT , x \u2032 T , yT ) \u2208 X \u00d7 X \u00d7 {0, 1}, for some set X \u2286 Rd. For w \u2208 Rd, define the relative linear model with w to be,\npt(w) = w \u00b7 xt\nw \u00b7 xt + w \u00b7 x\u2032t .\nThe sequence x1, x \u2032 1, . . . , xT , x \u2032 T is chosen arbitrary (or even adversarially) in advance; afterwards it is assumed that there is some w\u2217 \u2208 Rd such that, Pr[yt = 1] = pt(w\n\u2217) and that the different yt\u2019s are independent. It is further assumed that w\u2217 belongs to some convex compact set W \u2282 Rd and that w \u00b7 x is positive and bounded over w \u2208 W,x \u2208 X. Without loss of generality, by scaling we can require w \u00b7 x \u2208 [1, \u03b2] for some \u03b2 > 0 and every w \u2208W,x \u2208 X.\nOn the tth period, the algorithm outputs wt \u2208W , then\nobserves xt, x \u2032 t, yt, and finally incurs loss `t(wt) where `t(w) = log 1/pt(w) if yt = 1 and `t(w) = log 1/(1 \u2212 pt(w)) if yt = 0. The goal of the algorithm is to incur total loss not much larger than \u2211 t `t(w\n\u2217), the best choice had we known w\u2217 in advance.\nWe note that an analogous (and slightly simpler version of) the following lemma can be proven for squared loss.\nLemma 1. Let X,W \u2286 Rd and suppose that W is compact and convex and \u2203\u03b1 > 0 such that for all x \u2208 X, w \u2208 W : \u2016x\u2016, \u2016w\u2016 \u2264 1, and w \u00b7 x \u2265 \u03b1. The for any \u03b7 > 0 and any w0 \u2208 W and wt+1 = \u03a0W (wt \u2212 \u03b7\u2207`t(wt)),\n1 T E [ T\u2211 t=1 `t(wt)\u2212 `t(w\u2217) ] \u2264 \u03b7 \u03b12 + 2 T\u03b7\u03b1 .\nIn particular, for \u03b7 = \u221a 2\u03b1/T , this gives a bound on\nthe right-hand side of \u221a\n8 T\u03b13 .\nProof. Following the analysis of Zinkevich (Zinkevich, 2003) we consider the potential equal to the squared distance (wt\u2212w\u2217)2 and argue that it decreases whenever we have substantial error. Let \u2207t = \u2207`t(wt) \u2208 Rd, which is,\n\u2207t = xt + x\n\u2032 t\nwt \u00b7 xt + wt \u00b7 x\u2032t \u2212 yt xt wt \u00b7 xt\n\u2212 (1\u2212 yt) x\u2032t\nwt \u00b7 x\u2032t .\nBy the triangle inequality \u2016\u2207t\u2016 \u2264 G for G = 2\u03b1 . Now, as Zinkevich points out, due to convexity of W , (w \u2212 \u03a0W (v))\n2 \u2264 (w \u2212 v)2 for any v \u2208 Rd and w \u2208 W . Hence,\n(w\u2217 \u2212 wt+1)2 \u2264 (w\u2217 \u2212 wt + \u03b7\u2207t)2.\nThus the decrease in potential, call it \u2206t = (w \u2217 \u2212 wt) 2 \u2212 (w\u2217 \u2212 wt+1)2, is at least:\n\u2206t \u2265 (w\u2217 \u2212 wt)2 \u2212 (w\u2217 \u2212 wt + \u03b7\u2207t)2\n= 2\u03b7\u2207t \u00b7 (wt \u2212 w\u2217)\u2212 \u03b72\u22072t .\nNext, we consider the quantity, E[\u2206t \u00b7 w\u2217], where the expectation is taken over the random yt (fixing y1, y2, . . . , yt\u22121). By expansion, the expectations is:\nw\u2217 \u00b7 xt + w\u2217 \u00b7 x\u2032t w \u00b7 xt + w \u00b7 x\u2032t \u2212pt(w\u2217) w\u2217 \u00b7 xt wt \u00b7 xt \u2212(1\u2212pt(w\u2217)) w\u2217 \u00b7 x\u2032t wt \u00b7 x\u2032t .\nAfter simple algebraic manipulation, which is difficult to show in two-column format, we have,\nE[\u2206t \u00b7 w\u2217] = \u2212Zt(pt(w\u2217)\u2212 pt(wt))2 where\nZt = (wt \u00b7 xt + wt \u00b7 x\u2032t)(w\u2217 \u00b7 xt + w\u2217 \u00b7 x\u2032t)\n(wt \u00b7 xt)(wt \u00b7 x\u2032t) .\nAlso note that \u2206t \u00b7 wt = 0 regardless of yt. Hence, E[\u2206t \u00b7wt] = 0. Combining these with the fact that we have shown that \u2206t \u2265 2\u03b7\u2207t \u00b7 (wt \u2212w\u2217)\u2212 \u03b72G2, gives,\nE[\u2206t] \u2265 2\u03b7Zt(pt(w\u2217)\u2212 pt(wt))2 \u2212 \u03b72G2\n\u2265 2\u03b7w \u2217 \u00b7 xt + w\u2217 \u00b7 x\u2032t wt \u00b7 xt + wt \u00b7 x\u2032t (pt(wt)\u2212 pt(w\u2217))2 pt(wt)(1\u2212 pt(wt)) \u2212 \u03b72G \u2265 2\u03b7\u03b1 (pt(wt)\u2212 pt(w \u2217))2\npt(wt)(1\u2212 pt(wt)) \u2212 \u03b72G.\nIn the last line we have used the fact that w \u00b7x \u2208 [\u03b1, 1] for w \u2208 W,x \u2208 X. Now, by Lemma 2 which follows this proof,\n`t(wt)\u2212 `t(w\u2217) \u2264 (pt(wt)\u2212 pt(w\u2217))2\npt(wt)(1\u2212 pt(wt)) .\nCombining the previous two displayed equations gives,\nE[\u2206t] \u2265 2\u03b7\u03b1(`t(wt)\u2212 `t(w\u2217))\u2212 \u03b72G.\nFinally, since the potential (wt \u2212 w\u2217)2 > 0, we have\u2211 \u2206t \u2264 (w0 \u2212 w\u2217)2 \u2264 4. Hence,\u2211\nt\n`t(wt)\u2212 `t(w\u2217) \u2264 T\u03b72G+ 4\n2\u03b7\u03b1 .\nSubstituting G = 2/\u03b1 gives the lemma.\nLemma 2. Let p+ q = 1 and p\u2217 + q\u2217 = 1 for p, p\u2217 \u2208 [0, 1]. Then,\np\u2217 log p\u2217\np + q\u2217 log\nq\u2217 q \u2264 (p\u2212 p \u2217)2 pq .\nProof. By concavity of log, Jensen\u2019s inequality implies,\np\u2217 log p\u2217\np + q\u2217 log\nq\u2217\nq \u2264 log (p\n\u2217)2 p + (q\u2217)2 q .\nSimple algebraic manipulation shows that,\n(p\u2217)2\np +\n(q\u2217)2\nq = 1 +\n(p\u2212 p\u2217)2\npq .\nFinally, the fact that log 1 + x \u2264 x completes the lemma.\nA.3. Proof\nTo prove theorem 1, map matrix S \u2208 Rn\u00d7n to a vector w(S) \u2208 R1+n2 consisting of the constant \u00b5 + 2 in the first coordinate followed by the n2 entries of S. Taken over the set of symmetric S 0 such that Sii = 1,\nthe vectors w(S) for a compact convex set of radius\u221a n2 + (2 + \u00b5)2. Also,\npatbtct = \u00b5+ 2\u2212Kac \u2212Kca\n2\u00b5+ 4\u2212Kab \u2212Kba \u2212Kac \u2212Kca ,\nis our relative regression model for w = w(S), x \u2208 R1+n2 being the vector with a 1 is the first position and -1\u2019s in the positions corresponding to the ac and ca entries of S (and zero elsewhere), and x\u2032 having a 1 in the first position and -1\u2019s in the positions corresponding to ab and ba (and zero elsewhere). The inner product of w(S) and x is \u00b5 + \u03b4ab and hence is bounded. To apply Lemma 1, one must scale w(S) and x, x\u2032 down. However, it is clear that for any and T sufficiently large, setting \u03b7 = 1/ \u221a T in Lemma 1 gives the necessary bound."}], "references": [{"title": "Generalized non-metric multidimensional scaling", "author": ["Agarwal", "Sameer", "Wills", "Josh", "Cayton", "Lawrence", "Lanckriet", "Gert", "Kriegman", "David", "Belongie", "Serge"], "venue": null, "citeRegEx": "Agarwal et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2007}, {"title": "Scale-invariance as a unifying psychological principle", "author": ["N Chater", "Brown", "G D"], "venue": "Cognition, 69(3):B17\u2013", "citeRegEx": "Chater et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Chater et al\\.", "year": 1999}, {"title": "Generalized sparse metric learning with relative comparisons", "author": ["Huang", "Kaizhu", "Ying", "Yiming", "Campbell", "Colin"], "venue": "Knowledge and Information Systems, pp", "citeRegEx": "Huang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2010}, {"title": "Making large-scale svm learning practical. LS8-Report 24, Universit\u00e4t Dortmund", "author": ["Joachims", "Thorsten"], "venue": "LS VIII-Report,", "citeRegEx": "Joachims and Thorsten.,? \\Q1998\\E", "shortCiteRegEx": "Joachims and Thorsten.", "year": 1998}, {"title": "Practical large-scale optimization for max-norm regularization", "author": ["Lee", "Jason", "Recht", "Ben", "Salakhutdinov", "Ruslan", "Srebro", "Nathan", "Tropp", "Joel"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Lee et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2010}, {"title": "Heterogeneous embedding for subjective artist similarity", "author": ["B. McFee", "G.R.G. Lanckriet"], "venue": "In Tenth International Symposium for Music Information Retrieval", "citeRegEx": "McFee and Lanckriet,? \\Q2009\\E", "shortCiteRegEx": "McFee and Lanckriet", "year": 2009}, {"title": "Learning a distance metric from relative comparisons", "author": ["Schultz", "Matthew", "Joachims", "Thorsten"], "venue": "In Advances in Neural Information Processing Systems (NIPS). MIT Press,", "citeRegEx": "Schultz et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Schultz et al\\.", "year": 2003}, {"title": "Rank, tracenorm and max-norm", "author": ["Srebro", "Nathan", "Shraibman", "Adi"], "venue": "In COLT, pp", "citeRegEx": "Srebro et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Srebro et al\\.", "year": 2005}, {"title": "Distance metric learning, with application to clustering with side-information", "author": ["Xing", "Eric P", "Ng", "Andrew Y", "Jordan", "Michael I", "Russell", "Stuart"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Xing et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Xing et al\\.", "year": 2003}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["Zinkevich", "Martin"], "venue": null, "citeRegEx": "Zinkevich and Martin.,? \\Q2003\\E", "shortCiteRegEx": "Zinkevich and Martin.", "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "The problem of capturing and extrapolating a human notion of perceptual similarity has received increasing attention in recent years including areas such as vision (Agarwal et al., 2007), audition (McFee & Lanckriet, 2009), information retrieval (Schultz & Joachims, 2003) and a variety of others represented in the UCI Datasets (Xing et al.", "startOffset": 164, "endOffset": 186}, {"referenceID": 8, "context": ", 2007), audition (McFee & Lanckriet, 2009), information retrieval (Schultz & Joachims, 2003) and a variety of others represented in the UCI Datasets (Xing et al., 2003; Huang et al., 2010).", "startOffset": 150, "endOffset": 189}, {"referenceID": 2, "context": ", 2007), audition (McFee & Lanckriet, 2009), information retrieval (Schultz & Joachims, 2003) and a variety of others represented in the UCI Datasets (Xing et al., 2003; Huang et al., 2010).", "startOffset": 150, "endOffset": 189}, {"referenceID": 0, "context": "Agarwal et al. (2007) is probably the most similar work, in which they learn a kernel matrix from triples of similarity comparisons, as we do.", "startOffset": 0, "endOffset": 22}, {"referenceID": 4, "context": "Projection to the closest element of B is a quadratic program which can be solved via a number of existing techniques (Srebro & Shraibman, 2005; Lee et al., 2010).", "startOffset": 118, "endOffset": 162}], "year": 2011, "abstractText": "We introduce an algorithm that, given n objects, learns a similarity matrix over all n pairs, from crowdsourced data alone. The algorithm samples responses to adaptively chosen triplet-based relative-similarity queries. Each query has the form \u201cis object a more similar to b or to c?\u201d and is chosen to be maximally informative given the preceding responses. The output is an embedding of the objects into Euclidean space (like MDS); we refer to this as the \u201ccrowd kernel.\u201d SVMs reveal that the crowd kernel captures prominent and subtle features across a number of domains, such as \u201cis striped\u201d among neckties and \u201cvowel vs. consonant\u201d among letters.", "creator": "LaTeX with hyperref package"}}}