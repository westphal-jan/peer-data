{"id": "1106.0669", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jun-2011", "title": "GIB: Imperfect Information in a Computationally Challenging Game", "abstract": "This paper examines the problems involved in constructing a program that plays the Contractual Bridge game. These problems include both the difficulty of solving the perfect information variant of the game, as well as the techniques required to take into account the fact that Bridge is in fact not a perfect information game. GIB, as described, includes five different technical advances: partition search, the practical application of Monte Carlo techniques to realistic problems, an emphasis on achievable sentences to solve problems inherent in the Monte Carlo approach, an extension of the Alpha Beta backcut of total jobs to any distribution grid, and the use of squeaky wheel optimizations to find approximately optimal solutions to cardplay problems.", "histories": [["v1", "Fri, 3 Jun 2011 14:53:55 GMT  (208kb)", "http://arxiv.org/abs/1106.0669v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["m l ginsberg"], "accepted": false, "id": "1106.0669"}, "pdf": {"name": "1106.0669.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Matthew L. Ginsberg"], "emails": [], "sections": [{"heading": "Journal of Arti ial Intelligen e Resear h 14 (2001) 303{358 Submitted 10/00; published 6/01", "text": "GIB: Imperfe t Information in a ComputationallyChallenging GameMatthew L. Ginsberg ginsberg irl.uoregon.eduCIRL1269 University of OregonEugene, OR 97405 USA Abstra tThis paper investigates the problems arising in the onstru tion of a program to play thegame of ontra t bridge. These problems in lude both the di\u00c6 ulty of solving the game'sperfe t information variant, and te hniques needed to address the fa t that bridge is not, infa t, a perfe t information game. Gib, the program being des ribed, involves ve separatete hni al advan es: partition sear h, the pra ti al appli ation of Monte Carlo te hniques torealisti problems, a fo us on a hievable sets to solve problems inherent in the Monte Carloapproa h, an extension of alpha-beta pruning from total orders to arbitrary distributivelatti es, and the use of squeaky wheel optimization to nd approximately optimal solutionsto ardplay problems.Gib is urrently believed to be of approximately expert aliber, and is urrently thestrongest omputer bridge program in the world.1. Introdu tionOf all the lassi games of mental skill, only ard games and Go have yet to see the ap-pearan e of serious omputer hallengers. In Go, this appears to be be ause the game isfundamentally one of pattern re ognition as opposed to sear h; the brute-for e te hniquesthat have been so su essful in the development of hess-playing programs have failed al-most utterly to deal with Go's huge bran hing fa tor. Indeed, the arguably strongest Goprogram in the world (Handtalk) was beaten by 1-dan Jani e Kim (winner of the 1984 FujiWomen's Championship) in the 1997 AAAI Hall of Champions after Kim had given theprogram a monumental 25 stone handi ap.Card games appear to be di erent. Perhaps be ause they are games of imperfe t in-formation, or perhaps for other reasons, existing poker and bridge programs are extremelyweak. World poker hampion Howard Lederer (Texas Hold'em, 1996) has said that he wouldexpe t to beat any existing poker program after ve minutes' play.y1 Perennial world bridge hampion Bob Hamman, seven-time winner of the Bermuda Bowl, summarized the state ofbridge programs in 1994 by saying that, \\They would have to improve to be hopeless.\"yIn poker, there is reason for optimism: the gala system (Koller & Pfe er, 1995), ifappli able, promises to produ e a omputer player of unpre edented strength by redu ingthe poker \\problem\" to a large linear optimization problem whi h is then solved to generatea strategy that is nearly optimal in a game-theoreti sense. S hae er, author of the world1. Many of the itations here are the results of personal ommuni ations. Su h ommuni ations are indi- ated simply by the presen e of a y in the a ompanying text. 2001 AI A ess Foundation and Morgan Kaufmann Publishers. All rights reserved.\nGinsberg hampion he kers program Chinook (S hae er, 1997), is also reporting signi ant su essin the poker domain (Billings, Papp, S hae er, & Szafron, 1998).The situation in bridge has been bleaker. In addition, be ause the Ameri an Contra tBridge League (a bl) does not rank the bulk of its players in meaningful ways, it is di\u00c6 ultto ompare the strengths of ompeting programs or players.In general, performan e at bridge is measured by playing the same deal twi e or more,with the ards held by one pair of players being given to another pair during the replay andthe results then being ompared.2 A \\team\" in a bridge mat h thus typi ally onsists oftwo pairs, with one pair playing the North/South (N/S) ards at one table and the otherpair playing the E/W ards at the other table. The results obtained by the two pairs areadded; if the sum is positive, the team wins this parti ular deal and if negative, they loseit. In general, the numeri sum of the results obtained by the two pairs is onverted toInternational Mat h Points, or imps. The purpose of the onversion is to diminish theimpa t of single deals on the total, lest an abnormal result on one parti ular deal have anunduly large impa t on the result of an entire mat h.Je Goldsmithy reports that the standard deviation on a single deal in bridge is about 5.5imps, so that if two roughly equal pairs were to play the deal, it would not be surprising if oneteam beat the other by about this amount. It also appears that the di eren e between anaverage lub player and an expert is about 1.5 imps (per deal played); the strongest playersin the world are approximately 0.5 imps/deal better still. Ex epting gib, the strongestbridge playing programs appear to be slightly weaker than average lub players.Progress in omputer bridge has been slow. An in orporation of planning te hniques intoBridge Baron, for example, appears to have led to a performan e in rement of approximately1/3 imp per deal (Smith, Nau, & Throop, 1996). This modest improvement still leavesBridge Baron far shy of expert-level (or even good amateur-level) performan e.Prior to 1997, bridge programs generally attempted to dupli ate human bridge-playingmethodology in that they pro eeded by attempting to re ognize the lass into whi h anyparti ular deal fell: nesse, end play, squeeze, et . Smith et al.'s work on the Bridge Baronprogram uses planning to extend this approa h, but the plans ontinue to be onstru tedfrom human bridge te hniques. Nygate and Sterling's early work on python (Sterling &Nygate, 1990) produ ed an expert system that ould re ognize squeezes but not prepare forthem. In retrospe t, perhaps we should have expe ted this approa h to have limited su ess; ertainly hess-playing programs that have attempted to mimi human methodology, su has paradise (Wilkins, 1980), have fared poorly.Gib, introdu ed in 1998, works di erently. Instead of modeling its play on te hniquesused by humans, gib uses brute-for e sear h to analyze the situation in whi h it nds itself.A variety of te hniques are then used to suggest plays based on the results of the brute-for esear h. This te hnique has been so su essful that all ompetitive bridge programs haveswit hed from a knowledge-based approa h to a sear h-based approa h.GIB's ardplay based on brute-for e te hniques was at the expert level (see Se tion 3)even without some of the extensions that we dis uss in Se tion 5 and subsequently. Theweakest part of gib's game is bidding, where it relies on a large database of rules des ribing2. The rules of bridge are summarized in Appendix A.304\nGIB: Imperfe t information in a omputationally hallenging gamethe meanings of various au tions. Quantitative omparisons here are di\u00c6 ult, although thegeneral impression of the stronger players using GIB are that its overall play is omparableto that of a human expert.This paper des ribes the various te hniques that have been used in the gib proje t, asfollows:1. Gib's analysis in both bidding and ardplay rests on an ability to analyze bridge'sperfe t-information variant, where all of the ards are visible and ea h side attemptsto take as many tri ks as possible (this perfe t-information variant is generally referredto as double dummy bridge). Double dummy problems are solved using a te hniqueknown as partition sear h, whi h is dis ussed in Se tion 2.2. Early versions of gib used Monte Carlo methods ex lusively to sele t an a tion basedon the double dummy analysis. This te hnique was originally proposed for ardplayby Levy (Levy, 1989), but was not implemented in a performan e program beforegib. Extending Levy's suggestion, gib uses Monte Carlo simulation for both ardplay(dis ussed in Se tion 3) and bidding (dis ussed in Se tion 4).3. Se tion 5 dis usses di\u00c6 ulties with the Monte Carlo approa h. Frank et al. havesuggested dealing with these problems by sear hing the spa e of possible plans forplaying a parti ular bridge deal, but their methods appear to be intra table in boththeory and pra ti e (Frank & Basin, 1998; Frank, Basin, & Bundy, 2000). We instead hoose to deal with the di\u00c6 ulties by modifying our understanding of the game sothat the value of a bridge deal is not an integer (the number of tri ks that an betaken) but is instead taken from a distributive latti e.4. In Se tion 6, we show that the alpha-beta pruning me hanism an be extended to dealwith games of this type. This allows us to nd optimal plans for playing bridge endpositions involving some 32 ards or fewer. (In ontrast, Frank's method is apableonly of nding solutions in 16 ard endings.)5. Finally, applying our ideas to the play of full deals (52 ards) requires solving anapproximate version of the overall problem. In Se tion 7, we des ribe the nature ofthe approximation used and our appli ation of squeaky wheel optimization (Joslin &Clements, 1999) to solve it.Con luding remarks are ontained in Se tion 8.2. Partition sear hComputers are e e tive game players only to the extent that brute-for e sear h an over omeinnate stupidity; most of their time spent sear hing is spent examining moves that a humanplayer would dis ard as obviously without merit.As an example, suppose that White has a for ed win in a parti ular hess position,perhaps beginning with an atta k on Bla k's queen. A human analyzing the position willsee that if Bla k doesn't respond to the atta k, he will lose his queen; the analysis onsiderspla es to whi h the queen ould move and appropriate responses to ea h.305\nGinsbergA ma hine onsiders responses to the queen moves as well, of ourse. But it must alsoanalyze in detail every other Bla k move, arefully demonstrating that ea h of these othermoves an be refuted by apturing the Bla k queen. A six-ply sear h will have to analyzeevery one of these moves ve further ply, even if the refutations are identi al in all ases.Conventional pruning te hniques annot help here; using - pruning, for example, theentire \\main line\" (White's winning hoi es and all of Bla k's losing responses) must beanalyzed even though there is a great deal of apparent redundan y in this analysis.3In other sear h problems, te hniques based on the ideas of dependen y maintenan e (Stall-man & Sussman, 1977) an potentially be used to over ome this sort of di\u00c6 ulty. As anexample, onsider hronologi al ba ktra king applied to a map oloring problem. When adead end is rea hed and the sear h ba ks up, no information is a hed and the e e t is toeliminate only the spe i dead end that was en ountered. Re ording information givingthe reason for the failure an make the sear h substantially more e\u00c6 ient.In attempting to olor a map with only three olors, for example, thirty ountries mayhave been olored while the dete ted ontradi tion involves only ve. By re ording the ontradi tion for those ve ountries, dead ends that fail for the same reason an be avoided.Dependen y-based methods have been of limited use in pra ti e be ause of the overheadinvolved in onstru ting and using the olle tion of a umulated reasons. This problem hasbeen substantially addressed in the work on dynami ba ktra king (Ginsberg, 1993) and itssu essors su h as relsat (Bayardo & Miranker, 1996), where polynomial limits are pla edon the number of nogoods being maintained.In game sear h, however, most algorithms already in lude signi ant a hed informationin the form of a transposition table (Greenblatt, Eastlake, & Cro ker, 1967; Marsland, 1986).A transposition table stores a single game position and the ba ked up value that has beenasso iated with it. The name re e ts the fa t that many games \\transpose\" in that identi alpositions an be rea hed by swapping the order in whi h moves are made. The transpositiontable eliminates the need to re ompute values for positions that have already been analyzed.These olle ted observations lead naturally to the idea that transposition tables shouldstore not single positions and their values, but sets of positions and their values. Continuingthe dependen y-maintenan e analogy, a transposition table storing sets of positions anprune the subsequent sear h far more e\u00c6 iently than a table that stores only singletons.There are two reasons that this approa h works. The rst, whi h we have already men-tioned, is that most game-playing programs already maintain transposition tables, therebyin urring the bulk of the omputational expense involved in storing su h tables in a moregeneral form. The se ond and more fundamental reason is that when a game ends with oneplayer the winner, the reason for the vi tory is generally a lo al one. A hess game an bethought of as ending when one side has its king aptured (a ompletely lo al phenomenon);a he kers game, when one side runs out of moves. Even if an internal sear h node is eval-uated before the game ends, the reason for assigning it any spe i value is likely to beindependent of some global features (e.g., is the Bla k pawn on a5 or a6?). Partition sear hexploits both the existen e of transposition tables and the lo ality of evaluation for realisti games.3. An informal solution to this is Adelson-Velskiy et al.'s method of analogies (Adelson-Velskiy, Arlazarov,& Donskoy, 1975). This approa h appears to have been of little use in pra ti e be ause it is restri tedto a spe i lass of situations arising in hess games.306\nGIB: Imperfe t information in a omputationally hallenging game !!!!!! aaaaaa\nX X XO OO X X X XOO O X X X XO OO X X X OO XO X X XO OO X X XOO O X X XO OO X X X OOO X X XOO X O moves Figure 1: A portion of the game tree for ti -ta -toeThis se tion explains these ideas via an example and then des ribes them formally.Experimental results for bridge are also presented.2.1 An exampleOur illustrative examples for partition sear h will be taken from the game of ti -ta -toe.A portion of the game tree for this game appears in Figure 1, where we are analyzing aposition that is a win for X. We show O's four possible moves, and a winning responsefor X in ea h ase. Although X frequently wins by making a row a ross the top of thediagram, - pruning annot redu e the size of this tree be ause O's losing options mustall be analyzed separately.Consider now the position at the lower left in the diagram, where X has won:X X XO OO X (1)The reason that X has won is lo al. If we are retaining a list of positions with knownout omes, the entry we an make be ause of this position is:X X X? ? ?? ? ? (2)where the ? means that it is irrelevant whether the asso iated square is marked with an X, anO, or unmarked. This table entry orresponds not to a single position, but to approximately36 be ause the unassigned squares an ontain X's, O's, or be blank. We an redu e thegame tree in Figure 1 to: 307\nGinsberg ! !!!!! aaaaaa\nX X X? ? ?? ? ? X X OO XO X X XO OO X X XOO O X X XO OO X X X OOO X X XOO X O moves Continuing the analysis, it is lear that the positionX X? ? ?? ? ? (3)is a win for X if X is on play.4 So is X ? ?? ?? ? Xand the tree an be redu ed to:\nHHHHH X X X? ? ?? ? ? X ? ?? X ?? ? X X X? ? ?? ? ? X ? ?? ?? ? X X XOO X O moves Finally, onsider the position X X?? ? X (4)where it is O's turn as opposed to X's. If O moves in the se ond row, we get an instan e ofX X? ? ?? ? ?while if O moves to the upper right, we get an instan e ofX ? ?? ?? ? X4. We assume that O has not already won the game here, sin e X would not be \\on play\" if the game wereover. 308\nGIB: Imperfe t information in a omputationally hallenging gameThus every one of O's moves leads to a position that is known to be a win for X, and we an on lude that the original position (4) is a win for X as well. The root node in theredu ed tree an therefore be repla ed with the position of (4).These positions apture the essen e of the algorithm we will propose: If player x anmove to a position that is a member of a set known to be a win for x, the given position isa win as well. If every move is to a position that is a loss, the original position is also.2.2 Formalizing partition sear hIn this se tion, we present a summary of existing methods for evaluating positions in gametrees. There is nothing new here; our aim is simply to develop a pre ise framework in whi hour new results an be presented.De nition 2.2.1 An interval-valued game is a quadruple (G; pI ; s; ev), where G is a niteset of legal positions, pI 2 G is the initial position, s : G ! 2G gives the immediatesu essors of a given position, and ev is an evaluation fun tionev : G! fmax; ming [ [0; 1\u2104Informally, p0 2 s(p) means that position p0 an be rea hed from p in a single move, andthe evaluation fun tion ev labels internal nodes based upon whose turn it is to play (max ormin) and values terminal positions in terms of some element of the unit interval [0; 1\u2104.The stru tures G, pI , s and ev are required to satisfy the following onditions:1. There is no sequen e of positions p0; : : : ; pn with n > 0, pi 2 s(pi 1) for ea h i andpn = p0. In other words, there are no \\loops\" that return to an identi al position.2. ev(p) 2 [0; 1\u2104 if and only if s(p) = . In other words, ev assigns a numeri al value top if and only if the game is over. Informally, ev(p) = max means that the maximizeris to play and ev(p) = min means that the minimizer is to play.We use 2G to denote the power set of G, the set of subsets of G. There are two furtherthings to note about this de nition.First, the requirement that the game have no \\loops\" is onsistent with all moderngames. In hess, for example, positions an repeat but there is a on ealed ounter thatdraws the game if either a single position repeats three times or a ertain number of movespass without a apture or a pawn move. In fa t, dealing with the hidden ounter is morenatural in a partition sear h setting than a onventional one, sin e the evaluation fun tionis in general (although not always) independent of the value of the ounter.Se ond, the range of ev in ludes the entire unit interval [0; 1\u2104. The value 0 representsa win for the minimizer, and 1 a win for the maximizer. The intermediate values might orrespond to intermediate results (e.g., a draw) or, more importantly, allow us to deal withinternal sear h nodes that are being treated as terminal and assigned approximate valuesbe ause no time remains for additional sear h.The evaluation fun tion ev an be used to assign numeri al values to the entire set Gof positions: 309\nGinsbergDe nition 2.2.2 Given an interval-valued game (G; pI ; s; ev), we introdu e a fun tionev : G! [0; 1\u2104 de ned re ursively byev (p) = 8<: ev(p); if ev(p) 2 [0; 1\u2104;maxp02s(p) ev (p0); if ev(p) = max;minp02s(p) ev (p0); if ev(p) = min.The value of (G; pI ; s; ev) is de ned to be ev (pI).To evaluate a position in a game, we an use the well-known minimax pro edure:Algorithm 2.2.3 (Minimax) For a game (G; pI ; s; ev) and a position p 2 G, to omputeev (p):if ev(p) 2 [0; 1\u2104 return ev(p)if ev(p) = max return maxp02s(p) minimax(p0)if ev(p) = min return minp02s(p) minimax(p0)There are two ways in whi h the above algorithm is typi ally extended. The rst in-volves the introdu tion of transposition tables; we will assume that a new entry is addedto the transposition table T whenever one is omputed. (A modi ation to a he onlysele ted results is straightforward.) The se ond involves the introdu tion of - pruning.In orporating these ideas gives us the algorithm at the top of the next page.Ea h entry in the transposition table onsists of a position p, the urrent uto s [x; y\u2104,and the omputed value v. Note the need to in lude information about the uto s in thetransposition table itself, sin e the validity of any parti ular entry depends on the uto sin question.As an example, suppose that the value of some node is in fa t 1 (a win for the maxi-mizer) but that when the node is evaluated with uto s of [0; 0:5\u2104 a value of 0.5 is returned(indi ating a draw) be ause the maximizer has an obviously drawing line. It is lear thatthis value is only a urate for the given uto s; wider uto s will lead to a di erent answer.In general, the upper uto y is the urrently smallest value assigned to a minimizingnode; the minimizer an do at least this well in that he an for e a value of y or lower.Similarly, x is the urrently greatest value assigned to a maximizing node. These uto values are updated as the algorithm is invoked re ursively in the lines responsible for settingvnew, the value assigned to a hild of the urrent position p.Proposition 2.2.4 Suppose that v = (p; [x; y\u2104) for ea h entry (p; [x; y\u2104; v) in T . Then ifev (p) 2 [x; y\u2104, the value returned by Algorithm 2.2.5 is ev (p). 310\nGIB: Imperfe t information in a omputationally hallenging game Algorithm 2.2.5 ( - pruning with transposition tables) Given an interval-valuedgame (G; pI ; s; ev), a position p 2 G, uto s [x; y\u2104 [0; 1\u2104 and a transposition table T onsisting of triples (p; [a; b\u2104; v) with p 2 G and a b; v 2 [0; 1\u2104, to ompute (p; [x; y\u2104):if there is an entry (p; [x; y\u2104; z) in T return zif ev(p) 2 [0; 1\u2104 then vans = ev(p)if ev(p) = max thenvans := 0for ea h p0 2 s(p) dovnew = (p0; [max(vans; x); y\u2104)if vnew y thenT := T [ (p; [x; y\u2104; vnew)return vnewif vnew > vans then vans = vnewif ev(p) = min thenvans := 1for ea h p0 2 s(p) dovnew = (p0; [x;min(vans; y)\u2104)if vnew x thenT := T [ (p; [x; y\u2104; vnew)return vnewif vnew < vans then vans = vnewT := T [ (p; [x; y\u2104; vans)return vans 2.3 PartitionsWe are now in a position to present our new ideas. We begin by formalizing the idea of aposition that an rea h a known winning position or one that an rea h only known losingones.De nition 2.3.1 Given an interval-valued game (G; pI ; s; ev) and a set of positions S G,we will say that the set of positions that an rea h S is the set of all p for whi h s(p)\\S 6= .This set will be denoted R0(S). The set of positions onstrained to rea h S is the set ofall p for whi h s(p) S, and is denoted C0(S).These de nitions should mat h our intuition; the set of positions that an rea h a set Sis indeed the set of positions p for whi h some element of S is an immediate su essor of p,so that s(p) \\ S 6= . Similarly, a position p is onstrained to rea h S if every immediatesu essor of p is in S, so that s(p) S.Unfortunately, it may not be feasible to onstru t the R0 and C0 operators expli itly;there may be no on ise representation of the set of all positions that an rea h S. Inpra ti e, this will be re e ted in the fa t that the data stru tures being used to des ribe311\nGinsbergthe set S may not onveniently des ribe the set R0(S) of all situations from whi h S anbe rea hed.Now suppose that we are expanding the sear h tree itself, and we nd ourselves analyz-ing a parti ular position p that is determined to be a win for the maximizer be ause themaximizer an move from p to the winning set S; in other words, p is a win be ause it isin R0(S). We would like to re ord at this point that the set R0(S) is a win for the maxi-mizer, but may not be able to onstru t or represent this set onveniently. We will thereforeassume that we have some omputationally e e tive way to approximate the R0 and C0fun tions, in that we have (for example) a fun tion R that is a onservative implementationof R0 in that if R says we an rea h S, then so we an:R(p; S) R0(S)R(p; S) is intended to represent a set of positions that are \\like p in that they an rea hthe (winning) set S.\" Note the in lusion of p as an argument to R(p; S), sin e we ertainlywant p 2 R(p; S). We are about to a he the fa t that every element of R(p; S) is a winfor the maximizer, and ertainly want that information to in lude the fa t that p itself hasbeen shown to be a win. Thus we require p 2 R(p; S) as well.Finally, we need some way to generalize the information returned by the evaluationfun tion; if the evaluation fun tion itself identi es a position p as a win for the maximizer,we want to have some way to generalize this to a wider set of positions that are also wins.We formalize this by assuming that we have some generalization fun tion P that \\respe ts\"the evaluation fun tion in the sense that the value returned by P is a set of positions thatev evaluates identi ally.De nition 2.3.2 Let (G; pI ; S; ev) be an interval-valued game. Let f be any fun tion withrange 2G, so that f sele ts a set of positions based on its arguments. We will say thatf respe ts the evaluation fun tion ev if whenever p; p0 2 F for any F in the range of f ,ev(p) = ev(p0).A partition system for the game is a triple (P;R;C) of fun tions that respe t ev su hthat:1. P : G ! 2G maps positions into sets of positions su h that for any position p, p 2P (p).2. R : G 2G ! 2G a epts as arguments a position p and a set of positions S. Ifp 2 R0(S), so that p an rea h S, then p 2 R(p; S) R0(S).3. C : G 2G ! 2G a epts as arguments a position p and a set of positions S. Ifp 2 C0(S), so that p is onstrained to rea h S, then p 2 C(p; S) C0(S).As mentioned above, the fun tion P tells us whi h positions are su\u00c6 iently \\like\" p thatthey evaluate to the same value. In ti -ta -toe, for example, the position (1) where X haswon with a row a ross the top might be generalized by P to the set of positionsX X X? ? ?? ? ? (5)312\nGIB: Imperfe t information in a omputationally hallenging gameas in (2).The fun tions R and C approximate R0 and C0. On e again turning to our ti -ta -toeexample, suppose that we take S to be the set of positions appearing in (5) and that p isgiven by X XO OO Xso that S an be rea hed from p. R(p; S) might beX X? ? ?? ? ? (6)as in (3), although we ould also take R(p; S) = fpg or R(p; S) to beX XO OO X [ X X? ? ?? ? ? [ X X? ? ?? ? ?although this last union might be awkward to represent. Note again that R and C arefun tions of p as well as S; the set returned must in lude the given position p but anotherwise be expe ted to vary as p does.We will now modify Algorithm 2.2.5 so that the transposition table, instead of a hingresults for single positions, a hes results for sets of positions. As dis ussed in the introdu -tion to this se tion, this is an analog to the introdu tion of truth maintenan e te hniquesinto adversary sear h. The modi ed algorithm 2.3.3 appears in Figure 2 and returns a pairof values { the value for the given position, and a set of positions that will take the samevalue.Proposition 2.3.4 Suppose that v = (p; [x; y\u2104) for every (S; [x; y\u2104; v) in T and p 2 S.Then if ev (p) 2 [x; y\u2104, the value returned by Algorithm 2.3.3 is ev (p).Proof. We need to show that when the algorithm returns, any position in Sans will havethe value vans. This will ensure that the transposition table remains orre t.To see this, suppose that the node being expanded is a maximizing node; the minimizing ase is dual. Suppose rst that this node is a loss for the maximizer, having value 0.In showing that the node is a loss, we will have examined su essor nodes that are in setsdenoted Snew in Algorithm 2.3.3; if the maximizer subsequently nds himself in a positionfrom whi h he has no moves outside of the various Snew, he will still be in a losing position.Sin e Sall = [Snew, the maximizer will lose in any position from whi h he is onstrained tonext move into an element of Sall. Sin e every position in C(p; Sall) has this property, itis safe to take Sans = C(p; Sall). This is what is done in the rst line with a dagger in thealgorithm.The more interesting ase is where the eventual value of the node is nonzero; now inorder for another node n to demonstrably have the same value, the maximizer must haveno new options at n, and must still have some move that a hieves the value vans at n.The rst ondition is identi al to the earlier ase where vans = 0. For the se ond, notethat any time the maximizer nds a new best move, we set Sans to the set of positions that313"}, {"heading": "Ginsberg", "text": "Algorithm 2.3.3 (Partition sear h) Given a game (G; pI ; s; ev) and (P;R;C) a partitionsystem for it, a position p 2 G, uto s [x; y\u2104 [0; 1\u2104 and a transposition table T onsistingof triples (S; [a; b\u2104; v) with S G and a b; v 2 [0; 1\u2104, to ompute (p; [x; y\u2104):if there is an entry (S; [x; y\u2104; z) with p 2 S return hz; Siif ev(p) 2 [0; 1\u2104 then hvans; Sansi = hev(p); P (p)iif ev(p) = max thenvans := 0Sall := for ea h p0 2 s(p) dohvnew; Snewi = (p0; [max(vans; x); y\u2104)if vnew y thenT := T [ (Snew; [x; y\u2104; vnew)return hvnew; Snewiif vnew > vans then hvans; Sansi = hvnew; SnewiSall := Sall [ Snewif vans = 0 then Sans = C(p; Sall) yelse Sans = R(p; Sans) \\ C(p; Sall) y zif ev(p) = min thenvans := 1Sall := for ea h p0 2 s(p) dohvnew; Snewi = (p0; [x;min(vans; y)\u2104)if vnew x thenT := T [ (Snew; [x; y\u2104; vnew)return hvnew; Snewiif vnew < vans then hvans; Sansi = hvnew; SnewiSall := Sall [ Snewif vans = 1 then Sans = C(p; Sall)else Sans = R(p; Sans) \\ C(p; Sall) zT := T [ (Sans; [x; y\u2104; vans)return hvans; Sansi Figure 2: The partition sear h algorithm\n314\nGIB: Imperfe t information in a omputationally hallenging gamewe know re ursively a hieve the same value. When we omplete the maximizer's loop inthe algorithm, it follows that Sans will be a set of positions from whi h the maximizer anindeed a hieve the value vans. Thus the maximizer an also a hieve that value from anyposition in R(p; Sans). It follows that the overall set of positions known to have the valuevans is given by R(p; Sans) \\ C(p; Sall), interse ting the two onditions of this paragraph.This is what is done in the se ond daggered step in the algorithm.2.4 Zero-window variationsThe e e tiveness of partition sear h depends ru ially on the size of the sets maintained inthe transposition table. If the sets are large, many positions will be evaluated by lookup.If the sets are small, partition sear h ollapses to onventional - pruning.An examination of Algorithm 2.3.3 suggests that the points in the algorithm at whi hthe sets are redu ed the most are those marked with a double dagger in the des ription,where an interse tion is required be ause we need to ensure both that the player an makea move equivalent to his best one and that there are no other options. The e e tiveness ofthe method would be improved if this possibility were removed.To see how to do this, suppose for a moment that the evaluation fun tion always returned0 or 1, as opposed to intermediate values. Now if the maximizer is on play and the valuevnew = 1, a prune will be generated be ause there an be no better value found for themaximizer. If all of the vnew are 0, then vans = 0 and we an avoid the troublesomeinterse tion. The maximizer loses and there is no \\best\" move that we have to worry aboutmaking.In reality, the restri tion to values of 0 or 1 is unrealisti . Some games, su h as bridge,allow more than two out omes, while others annot be analyzed to termination and needto rely on evaluation fun tions that return approximate values for internal nodes. We andeal with these situations using a te hnique known as zero-window sear h (originally alleds out sear h (Pearl, 1980)). To evaluate a spe i position, one rst estimates the valueto be e and then determines whether the a tual value is above or below e by treating anyvalue v > e as a win for the maximizer and any value v e as a win for the minimizer. Theresults of this al ulation an then be used to re ne the guess, and the pro ess is repeated.If no initial estimate is available, a binary sear h an be used to nd the value to withinany desired toleran e.Zero-window sear h is e e tive be ause little time is wasted on iterations where theestimate is wildly ina urate; there will typi ally be many lines showing that a new estimateis needed. Most of the time is spent on the last iteration or two, developing tight boundson the position being onsidered. There is an analog in onventional - pruning, wherethe bounds typi ally get tight qui kly and the bulk of the analysis deals with a situationwhere the value of the original position is known to lie in a fairly narrow range.In zero-window sear h, a node always evaluates to 0 or 1, sin e either v > e or v e.This allows a straightforward modi ation to Algorithm 2.3.3 that avoids the troublesome ases mentioned earlier. 315\nGinsberg2.5 Experimental resultsPartition sear h was tested by analyzing 1000 randomly generated bridge deals and om-paring the number of nodes expanded using partition sear h and onventional methods.In addition to our general interest in bridge, there are two reasons why it an be expe tedthat partition sear h will be useful for this game. First, partition sear h requires that thefun tions R0 and C0 support a partition-like analysis; it must be the ase that an analysis ofone situation will apply equally well to a variety of similar ones. Se ond, it must be possibleto build approximating fun tions R and C that are reasonably a urate representatives ofR0 and C0.Bridge satis es both of these properties. Expert dis ussion of a parti ular deal oftenwill refer to small ards as x's, indi ating that it is indeed the ase that the exa t ranks ofthese ards are irrelevant. Se ond, it is possible to \\ba k up\" x's from one position to itsprede essors. If, for example, one player plays a lub with no han e of having it impa tthe rest of the game, and by doing so rea hes a position in whi h subsequent analysis showshim to have two small lubs, then he learly must have had three small lubs originally.Finally, the fa t that ards are simply being repla ed by x's means that it is possible to onstru t data stru tures for whi h the time per node expanded is virtually un hanged fromthat using onventional methods.Perhaps an example will make this learer. Consider the following partial bridge dealin whi h East is to lead and there are no trumps: |~ |} AK| | 10 AQ~ A ~ |} | } || | | | KJ~ |} || | An analysis of this situation shows that in the main line, the only ards that win tri ksby virtue of their ranks are the spade A e, King and Queen. This san tions the repla ementof the above gure by the following more general one:316\nGIB: Imperfe t information in a omputationally hallenging game |~ |} xx| | x AQ~ x ~ |} | } || | | | Kx~ |} || |Note rst that this repla ement is sound in the sense that every position that is aninstan e of the se ond diagram is guaranteed to have the same value as the original. Wehave not resorted to an informal argument of the form \\Ja ks and lower tend not to matter,\"but instead to a pre ise argument of the form, \\In the expansion of the sear h tree asso iatedwith the given deal, Ja ks and lower were proven never to matter.\"Bridge also appears to be extremely well-suited (no pun intended) to the kind of analysisthat we have been des ribing; a hess analog might involve des ribing a mating ombinationand saying that \\the position of Bla k's queen didn't matter.\" While this does happen, asual hess onversation is mu h less likely to in lude this sort of remark than bridge onversation is likely to refer to a host of small ards as x's, suggesting at least that thepartition te hnique is more easily applied to bridge than to hess (or to other games).That said, however, the results for bridge are striking, leading to performan e improve-ments of an order of magnitude or more on fairly small sear h spa es (perhaps 106 nodes).The deals we tested involved between 12 and 48 ards and were analyzed to termination, sothat the depth of the sear h varied from 12 to 48. (The solver without partition sear h wasunable to solve larger problems.) The bran hing fa tor for minimax without transpositiontables appeared to be approximately 4, and the results appear in Figure 3.Ea h point in the graph orresponds to a single deal. The position of the point on thex-axis indi ates the number of nodes expanded using - pruning and transposition tables,and the position on the y-axis the number expanded using partition sear h as well. Bothaxes are plotted logarithmi ally.In both the partition and onventional ases, a binary zero-window sear h was used todetermine the exa t value to be assigned to the hand, whi h the rules of bridge onstrainto range from 0 to the number of tri ks left (one quarter of the number of ards in play).As mentioned previously, hands generated using a full de k of 52 ards were not onsideredbe ause the onventional method was in general in apable of solving them. The program wasrun on a Spar 5 and PowerMa 6100, where it expanded approximately 15K nodes/se ond.The transposition table shares ommon stru ture among di erent sets and as a result, usesapproximately 6 bytes/node.The dotted line in the gure is y = x and orresponds to the breakeven point relative to - pruning in isolation. The solid line is the least-squares best t to the logarithmi data,and is given by y = 1:57x0:76. This suggests that partition sear h is leading to an e e tiveredu tion in bran hing fa tor of b ! b0:76. This improvement, above and beyond that317\nGinsberg\n10103 105107\n10 103 105 107 Partition Conventionalp pp p ppp ppp ppppp ppp pppp p pp p pppp pp ppp p p p pp p pp p pp ppp pp pp p p pppp pp p pp pp pp pp pppp p p pp p pp pp p pp pp pp p ppp ppp p pp p ppp pppp p pp pp p pp p ppp p ppp pp p pp pp p pp ppp ppp p pppp p ppp p pp pp p ppp pp pp pp p ppp pp pp p pppp p pp p pp pppp pp pp ppp pp p p p pp pp p p pppp pp pp ppp pp ppp pp ppp p pp p pp pp pp ppp pp p ppppp pp pp p ppp ppppp p pp pppp pp p pp ppp pp ppp pp ppp pp pp p pp p pp ppp ppp p pp p p ppp pp pp ppp p pp pppp pp p pp pppp p ppp p pppp pp pp p pp p p p pppppp pp p pp p ppp pp p pp ppp pp p ppp pp p p pp ppp p ppp ppp pp ppp ppp ppp p pp p pp pp pp ppp pp ppp ppp pp pp p pp ppp ppp pp pp ppp p ppp p p ppppp pp p ppp p pp ppppp p pppp p pp pp pp p ppp p pppp p p pp pp pp ppp pp p ppp ppp pp p pp p ppp ppp p pp pp pp p pp pp pp p pp pppp p pp pp ppp pppp pp pp p pp p ppppp ppp p p\npp pp pp pp pp p pp pppp p p ppp pp ppp pp p pp ppp pp pp pp pp pp p pp ppp pp pp p pp pp pp p p pp pp p ppp pp p p ppp ppp pp ppppp p pp p ppp pp pp ppppp pp pp ppppp pp pppppp p pp ppp p ppppp p pp pp p ppp pp ppp p p pp p pp p pp ppp pp pp pp pp p p ppppp p p pp p p ppp p pp pp pp pp ppp ppp p ppppp pp p pp pp pp p ppp pp pp p p ppp pp pp p pp pppp pp p pp ppp p pp pp pp ppp ppp\nppp pppp pp p pp pp p ppp p pppp p p p ppp p ppp p p p p pp p p p pp pp p p pppp pppp pppp pp ppp ppp pp pppp pp ppp pp ppp pp p pp pp p 1:57x0:76\nFigure 3: Nodes expanded as a fun tion of methodprovided by - pruning, an be ontrasted with - pruning itself, whi h gives a redu tionwhen ompared to pure minimax of b ! b0:75 if the moves are ordered randomly (Pearl,1982) and b! b0:5 if the ordering is optimal.The method was also applied to full deals of 52 ards, whi h an be solved while ex-panding an average of 18,000 nodes per deal.5 This works out to about a se ond of putime.3. Monte Carlo ardplay algorithmsOne way in whi h we might use our perfe t-information ardplay engine to pro eed in arealisti situation would be to deal the unseen ards at random, biasing the deal so that itwas onsistent both with the bidding and with the ards played thus far. We ould thenanalyze the resulting deal double dummy and de ide whi h of our possible plays was thestrongest. Averaging over a large number of su h Monte Carlo samples would allow us todeal with the imperfe t nature of bridge information. This idea was initially suggested byLevy (Levy, 1989), although he does not appear to have realized (see below) that there areproblems with it in pra ti e.Algorithm 3.0.1 (Monte Carlo ard sele tion) To sele t a move from a andidate setM of su h moves:5. The version of gib that was released in O tober of 2000 repla ed the transposition table with a datastru ture that uses a xed amount of memory, and also sorts the moves based on narrowness (suggestedby Plaat et al. (Plaat, S hae er, Pijls, & de Bruin, 1996) to be rooted in the idea of onspira y sear h(M Allester, 1988)) and the killer heuristi . While the memory requirements are redu ed, the overallperforman e is little hanged. 318\nGIB: Imperfe t information in a omputationally hallenging game1. Constru t a set D of deals onsistent with both the bidding and play of the deal thusfar.2. For ea h move m 2 M and ea h deal d 2 D, evaluate the double dummy result ofmaking the move m in the deal d. Denote the s ore obtained by making this moves(m; d).3. Return that m for whi h Pd s(m; d) is maximal.The Monte Carlo approa h has drawba ks that have been pointed out by a variety ofauthors, in luding Kollery and others (Frank & Basin, 1998). Most obvious among theseis that the approa h never suggests making an \\information gathering play.\" After all,the perfe t-information variant on whi h the de ision is based invariably assumes that theinformation will be available by the time the next de ision must be made! Instead, thetenden y is for the approa h to simply defer important de isions; in many situations thismay lead to information gathering inadvertently, but the amount of information a quiredwill generally be far less than other approa hes might provide.As an example, suppose that on a parti ular deal, gib has four possible lines of play tomake its ontra t:1. Line A works if West has the Q.2. Line B works if East has the Q.3. Line C defers the guess until later.4. Line D (the lever line) works independent of who has the Q.Assuming that either player is equally likely to hold the Q, a Monte Carlo analyzerwill orre tly on lude that line A works half the time, and line B works half the time. LineC, however, will be presumed to work all of the time, sin e the ontra t an still be made(double dummy) if the guess is deferred. Line D will also be on luded to work all of thetime ( orre tly, in this ase).As a result, gib will hoose randomly between the last two possibilities above, believingas it does that if it an only defer the guess until later (even the next ard), it will makethat guess orre tly. The orre t play, of ourse, is D.We will dis uss a solution to these di\u00c6 ulties in Se tions 5{7; although gib's defensive ardplay ontinues to be based on the above ideas, its de larer play now uses stronger te h-niques. Nevertheless, basing the ard play on the algorithm presented leads to extremelystrong results, approximately at the level of a human expert. Sin e gib's introdu tion, allother ompetitive bridge-playing programs have swit hed their ardplay to similar meth-ods, although gib's double dummy analysis is substantially faster than most of the otherprograms and its play is orrespondingly stronger.We will des ribe three tests of GIB's ardplay algorithms: Performan e on a om-mer ially available set of ben hmarks, performan e in a human hampionship designed tohighlight ardplay in isolation, and statisti al performan e measured over a large set ofdeals. 319\nGinsbergFor the rst test, we evaluated the strength of gib's ardplay using Bridge Master (BM),a ommer ial program developed by Canadian internationalist Fred Gitelman. BM ontains180 deals at 5 levels of di\u00c6 ulty. Ea h of the 36 deals on ea h level is a problem in de larerplay. If you misplay the hand, BM moves the defenders' ards around if ne essary to ensureyour defeat.BM was used for the test instead of randomly dealt deals be ause the signal to noise ra-tio is far higher; good plays are generally rewarded and bad ones punished. Every deal also ontains a lesson of some kind; there are no ompletely uninteresting deals where the lineof play is irrelevant or obvious. There are drawba ks to testing gib's performan e on non-randomly dealt deals, of ourse, sin e the BM deals may in some way not be representativeof the problems a bridge player would a tually en ounter at the table.The test was run under Mi rosoft Windows on a 200 MHz Pentium Pro. As a ben hmark,Bridge Baron (BB) version 6 was also tested on the same deals using the same hardware.6BB was given 10 se onds to sele t ea h play, and gib was given 90 se onds to play the entiredeal with a maximum Monte Carlo sample size of 50.7 New deals were generated ea h timea play de ision needed to be made.These numbers approximately equalized the omputational resour es used by the twoprograms; BB ould in theory take 260 se onds per deal (ten se onds on ea h of 26 plays),but in pra ti e took substantially less. Gib was given the au tions as well; there was nofa ility for doing this in BB. This information was riti al on a small number of deals.Here is how the two systems performed:Level BB GIB1 16 312 8 233 2 124 1 215 4 13Total 33 10018.3% 55.6%Ea h entry is the number of deals that were played su essfully by the program in question.Gib's mistakes are illuminating. While some of them involve failing to gather informa-tion, most are problems in ombining multiple han es (as in ase D above). As BM's dealsget more di\u00c6 ult, they more often involve ombining a variety of possibly winning optionsand that is why GIB's performan e falls o at levels 2 and 3.At still higher levels, however, BM typi ally involves the su essful development of omplex end positions, and gib's performan e rebounds. This appeared to happen to BBas well, although to a mu h lesser extent. It was gratifying to see gib dis over for itself the omplex end positions around whi h the BM deals are designed, and more gratifying stillto witness gib's dis overy of a maneuver that had hitherto not been identi ed in the bridgeliterature, as des ribed in Appendix B.6. The urrent version is Bridge Baron 10 and ould be expe ted to perform guardedly better in a test su has this. Bridge Baron 6 does not in lude the Smith enhan ements (Smith et al., 1996).7. GIB's Monte Carlo sample size is xed at 50 in most ases, whi h provides a good ompromise betweenspeed of play and a ura y of result. 320\nGIB: Imperfe t information in a omputationally hallenging gameExperiments su h as this one are tedious, be ause there is no text interfa e to a om-mer ial program su h as Bridge Master or Bridge Baron. As a result, information regardingthe sensitivity of gib's performan e to various parameters tends to be only ane dotal.Gib solves an additional 16 problems (bringing its total to 64.4%) given additionalresour es in the form of extra time (up to 100 se onds per play, although that time wasvery rarely taken), a larger Monte Carlo sample (100 deals instead of 50) and hand-generatedexplanations of the opponents' bids and opening leads. Ea h of the three fa tors appearedto ontribute equally to the improved performan e.Other authors are reporting omparable levels of performan e for gib. Forrester, workingwith a di erent but similar ben hmark (Bla kwood, 1979), reports8 that gib solves 68% ofthe problems given 20 se onds/play, and 74% of them given 30 se onds/play. Deals wheregib has outplayed human experts are the topi of a series of arti les in the Dut h bridgemagazine IMP (Eskes, 1997, and sequels).9 Based on these results, gib was invited toparti ipate in an invitational event at the 1998 world bridge hampionships in Fran e; theevent involved deals similar to Bridge Master's but substantially more di\u00c6 ult. Gib joineda eld of 34 of the best ard players in the world, ea h player fa ing twelve su h problemsover the ourse of two days. Gib was leading at the halfway mark, but played poorly onthe se ond day (perhaps the pressure was too mu h for it), and nished twelfth.The human parti ipants were given 90 minutes to play ea h deal, although they werepenalized slightly for playing slowly. GIB played ea h deal in about ten minutes, using aMonte Carlo sample size of 500; tests before the event indi ated little or no improvementif gib were allotted more time. Mi hael Rosenberg, the eventual winner of the ontest andthe pre-tournament favorite, in fa t made one more mistake than did Bart Bramley, these ond pla e nisher. Rosenberg played just qui kly enough that Bramley's a umulatedtime penalties gave Rosenberg the vi tory. The s oring method thus favors GIB slightly.Finally, gib's performan e was evaluated dire tly using re ords from a tual play. Thesere ords are available from high levels of human ompetition (world and national hampi-onships, typi ally), so that it is possible to determine exa tly how frequently humans makemistakes at the bridge table. In Figure 4, we show the frequen y with whi h this dataindi ates that a human de larer, leading to the nth tri k of a deal, makes a mistake that auses his ontra t to be ome unmakeable on a double-dummy basis. The y axis gives thefrequen y of the mistakes and is plotted logarithmi ally; as one would expe t, play be omesmore a urate later in the deal.We also give similar data for gib, based on large sample of deals that gib played againstitself. The error pro les of the two are quite similar.Before turning to defensive play, let me point out that this method of analysis favors gibslightly. Failing to make an information gathering play gets re e ted in the above gure,sin e the la k of information will ause gib to make a double-dummy mistake subsequently.But human de larers often work to give the defenders problems that exploit their relativela k of information, and that ta ti is not rewarded in the above analysis. Similar resultsfor defensive play appear in Figure 5.8. Posting to re .games.bridge on 14 July 1997.9. http://www.imp-bridge.nl 321\nGinsberg\n0.00010.001 0.010.1 0 2 4 6 8 10 12 P(err)\ntri k\nhumanGIB\nGIB: Imperfe t information in a omputationally hallenging gameThere are two important te hni al remarks that must be made about the Monte Carloalgorithm before pro eeding. First, note that we were avalier in simply saying, \\Constru ta set D of deals onsistent with both the bidding and play of the deal thus far.\"To onstru t deals onsistent with the bidding, we rst simplify the au tion as observed,building onstraints des ribing ea h of the hands around the table. We then deal hands onsistent with the onstraints using a deal generator that deals unbiased hands givenrestri tions on the number of ards held by ea h player in ea h suit. This set of deals isthen tested to remove elements that do not satisfy the remaining onstraints, and ea h of theremaining deals is passed to the bidding module to identify those for whi h the observed bidswould have been made by the players in question. (This assumes that gib has a reasonableunderstanding of the bidding methods used by the opponents.) The overall dealing pro esstypi ally takes one or two se onds to generate the full set of deals needed by the algorithm.Now the ard play must be analyzed. Ideally, gib would do something similar to what itdoes for the bidding, determining whether ea h player would have played as indi ated on anyparti ular deal. Unfortunately, it is simply impra ti al to test ea h hypotheti al de isionre ursively against the ardplay module itself. Instead, gib tries to evaluate the probabilitythat West (for example) has the K (for example), and to then use these probabilities toweight the sample itself.To understand the sour e of the weighting probabilities, let us onsider a spe i exam-ple. Suppose that in some parti ular situation, gib plays the 5. The analysis indi atesthat 80% of the time that the next player (say West) holds the K, it is a mistake for Westnot to play it. In other words, West's failure to play the K leads to odds of 4:1 that hehasn't got it.These odds are now used via Bayes' rule to adjust the probability that West holds the K at all. The probabilities are then modi ed further to in lude information revealed bydefensive signalling (if any), and the adjusted probabilities are nally used to bias the MonteCarlo sample. The evaluation Pd s(m; d) in Algorithm 3.0.1 is repla ed with Pd wds(m; d)where wd is the weight assigned to deal d. More heavily weighted deals thus have a largerimpa t on gib's eventual de ision.The se ond te hni al point regarding the algorithm itself involves the fa t that it needsto run qui kly and that it may need to be terminated before the analysis is omplete. For theformer, there are a variety of greedy te hniques that an be used to ensure that a move mis not onsidered if we an show Pd s(d;m) Pd s(d;m0) for some m0. The algorithm alsouses iterative broadening (Ginsberg & Harvey, 1992) to ensure that a low-width answeris available if a high-width sear h fails to terminate in time. Results from the low- andhigh-width sear hes are ombined when time expires.Also regarding speed, the algorithm requires that for ea h deal in the Monte Carlosample and ea h possible move, we evaluate the resulting position exa tly. Knowing simplythat move m1 is not as good as move m2 for deal d is not enough; m1 may be better thanm2elsewhere and we need to ompare them quantitatively. This approa h is aided substantiallyby the partition sear h idea, where entries in the transposition table orrespond not to singlepositions and their evaluated values, but to sets of positions and values. In many ases,m1 and m2 may fall into the same entry of the partition table long before they a tuallytranspose into one another exa tly. 323\nGinsberg4. Monte Carlo biddingThe purpose of bidding in bridge is twofold. The primary purpose is to share informationabout your ards with your partner so that you an ooperatively sele t an optimal nal ontra t. A se ondary purpose is to disrupt the opponents' attempt to do the same.In order to a hieve this purpose, a wide variety of bidding \\languages\" have been de-veloped. In some, when you suggest lubs as trumps, it means you have a lot of them. Inothers, the suggestion is only temporary and the information onveyed is quite di erent.In all of these languages, some meaning is assigned to a wide variety of bids in parti ularsituations; there are also default rules that assign meanings to bids that have no spe i allyassigned meanings. Any omputer bridge player will need similar understandings.Bidding is interesting be ause the meanings frequently overlap; there may be one ormore bids that are suitable (or nearly so) on any parti ular set of ards. Existing omputerprograms have simply mat hed possible bids against large databases giving their meanings,sear hing for that bid that best mat hes the ards that the ma hines hold. World hampionChip Martel reportsy that human experts take a di erent approa h.10;11Although expert bidding is based on a database su h as that used by existing programs, lose de isions are made by simulating the results of ea h andidate a tion. This involvesproje ting how the bidding is likely to pro eed and evaluating the play in one of a variety ofpossible nal ontra ts. An expert gets his \\judgment\" from a Monte Carlo-like simulationof the results of possible bids, often referred to in the bridge-playing ommunity as a Borelsimulation (so named after the rst player to des ribe the method). Gib takes a similarta k.Algorithm 4.0.2 (Borel simulation) To sele t a bid from a andidate set B, given adatabase Z that suggests bids in various situations:1. Constru t a set D of deals onsistent with the bidding thus far.2. For ea h bid b 2 B and ea h deal d 2 D, use the database Z to proje t how the au tionwill ontinue if the bid b is made. (If no bid is suggested by the database, the playerin question is assumed to pass.) Compute the double dummy result of the eventual ontra t, denoting it s(b; d).3. Return that b for whi h Pd s(b; d) is maximal.As with the Monte Carlo approa h to ard play, this approa h does not take into a ountthe fa t that bridge is not played double dummy. Human experts often hoose not to makebids that will onvey too mu h information to the opponents in order to make the defenders'task as di\u00c6 ult as possible. This onsideration is missing from the above algorithm.1210. The 1994 Rosenblum Cup World Team Championship was won by a team that in luded Martel andRosenberg.11. Frank suggests (Frank, 1998) that the existing ma hine approa h is apable of rea hing expert levels ofperforman e. While this appears to have been true in the early 1980's (Lindel of, 1983), modern expertbidding pra ti e has begun to highlight the disruptive aspe t of bidding, and ma hine performan e is nolonger likely to be ompetitive.12. In theory at least, this issue ould be addressed using the single-dummy ideas that we will present insubsequent se tions. Computational onsiderations urrently make this impra ti al, however.324\nGIB: Imperfe t information in a omputationally hallenging gameThere are more serious problems also, generally entering around the development ofthe bidding database Z.First, the database itself needs to be built and debugged. A large number of rules needto be written, typi ally in a spe ialized language and dependent upon the bridge expertiseof the author. The rules need to be debugged as a tual play reveals oversights or otherdi\u00c6 ulties.The nature and sizes of these databases vary enormously, although all of them representvery substantial investments on the part of the authors. The database distributed withmeadowlark bridge in ludes some 7300 rules; that with q-plus bridge 2500 rules omprising 40,000 lines of spe ialized ode. Gib's database is built using a derivative of theMeadowlark language, and in ludes about 3000 rules.All of these databases doubtless ontain errors of one sort or another; one of the ni ethings about most bidding methods is that they tend to be fairly robust against su h prob-lems. Unfortunately, the Borel algorithm des ribed above introdu es substantial instabilityin gib's overall bidding.To understand this, suppose that the database Z is somewhat onservative in its a tions.The proje tion in step 2 of Algorithm 4.0.2 now leads ea h player to assume its partner bids onservatively, and therefore to bid somewhat aggressively to ompensate. The partnershipas a whole ends up over ompensating.Worse still, suppose that there is an omission of some kind in Z; perhaps every timesomeone bids 7}, the database suggests a foolish a tion. Sin e 7} is a rare bid, a bid-ding system that mat hes its bids dire tly to the database will en ounter this probleminfrequently.Gib, however, will be mu h more aggressive, bidding 7} often on the grounds thatdoing so will ause the opponents to make a mistake. In pra ti e, of ourse, the bug in thedatabase is unlikely to be repli ated in the opponents' minds, and gib's attempts to exploitthe gap will be unrewarded or worse.This is a serious problem, and appears to apply to any attempt to heuristi ally modelan adversary's behavior: It is di\u00c6 ult to distinguish a good hoi e that is su essful be ausethe opponent has no winning options from a bad hoi e that appears su essful be ause theheuristi fails to identify su h options.There are a variety of ways in whi h this problem might be addressed, none of themperfe t. The most obvious is simply to use gib's aggressive tenden ies to identify the bugsor gaps in the bidding database, and to x them. Be ause of the size of the database, thisis a slow pro ess.Another approa h is to try to identify the bugs in the database automati ally, and to bewary in su h situations. If the bidding simulation indi ates that the opponents are aboutto a hieve a result mu h worse than what they might a hieve if they saw ea h other's ards,that is eviden e that there may be a gap in the database. Unfortunately, it is also eviden ethat gib is simply e e tively disrupting its opponents' e orts to bid a urately.Finally, restri tions ould be pla ed on gib that require it to make bids that are \\ lose\"to the bids suggested by the database, on the grounds that su h bids are more likely tore e t improvements in judgment than to highlight gaps in the database.All of these te hniques are used, and all of them are useful. Gib's bidding is substantiallybetter than that of earlier programs, but not yet of expert aliber.325\nGinsbergThe bidding was tested as part of the 1998 Baron Bar lay/OKBridge World ComputerBridge Championships, and the 2000 Orbis World Computer Bridge Championship. Ea hprogram bid deals that had previously been bid and played by experts; a result of 0 on anyparti ular deal meant that the program bid to a ontra t as good as the average expertresult. A positive result was better, and a negative result was worse.There were 20 deals in ea h ontest; although ard play was not an issue, the deals weresele ted to pose hallenges in bidding and a standard deviation of 5.5 imps/deal is still areasonable estimate. One standard deviation over the 20 deal set ould thus be expe tedto be about 25 imps.Gib's nal s ore in the 1998 bidding ontest was +2 imps; in the 2000 ontest it was +9imps. In both ases, it narrowly edged out the expert eld against whi h it was ompared.13The next best program in 1998, Blue Chip Bridge, nished with a s ore of -35 imps, notdissimilar from the -37 imps that had been su\u00c6 ient to win the bidding ontest in 1997.The se ond pla e program in 2000 (on e again Blue Chip Bridge) had a s ore of -2 imps.5. The value of informationIn previous se tions of this paper, we have des ribed Monte Carlo methods for dealing withthe fa t that bridge is a game of imperfe t information, and have also des ribed possibleproblems with this approa h. We now turn to ways to over omes some of these di\u00c6 ulties.For the moment, let me assume that we repla e bridge with a f0; 1g game, so that weare interested only in the question of whether de larer makes his ontra t. Overtri ks orextra undertri ks are irrelevant. At least as a rst approximation, bridge experts often lookat hands this way, only subsequently re ning the analysis.If you ask su h an expert why he took a parti ular line on a deal, he will often saysomething like, \\I was playing for ea h opponent to have three hearts,\" or \\I was playingfor West to hold the spade queen.\" What he is reporting is that set of distributions of theunseen ards for whi h he was expe ting to make the hand.At some level, the expert is treating the value of the game not as zero or one (whi hit would be if he ould see the unseen ards), but as a fun tion from the set of possibledistributions of unseen ards into f0; 1g. If we denote this set of distributions by S, thevalue of the game is thus a fun tion f : S ! f0; 1gWe will follow standard mathemati al notation and denote the set f0; 1g by 2 and denotethe set of fun tions f : S ! 2 by 2S .It is possible to extend max and min from the set f0; 1g to 2S in a pointwise fashion, sothat, for example min(f; g)(s) = min(f(s); g(s)) (7)for fun tions f; g 2 2S and a spe i situation s 2 S. The maximizing fun tion is de nedsimilarly.13. This is in spite of the earlier remark that GIB's bidding is not of expert aliber. GIB was fortunate inthe bidding ontests in that most of the problems involved situations handled by the database. Whenfa ed with a situation that it does not understand, GIB's bidding deteriorates drasti ally.326\nGIB: Imperfe t information in a omputationally hallenging gameAs an example, suppose that in a parti ular situation, there is one line of play f thatwins if West has the Q. There is another line of play g that wins if East has exa tlythree hearts. Now min(f; g) is the line of play that wins just in ase both West has the Qand East has three hearts, while max(f; g) is the line of play that wins if either onditionobtains.It is important to realize that the set 2S is not totally ordered by these max and minfun tions, like the unit interval is. Instead, 2S is an instan e of a mathemati al stru tureknown as a latti e (Gr atzer, 1978, and Se tion 6). At this point, we note only that we anextend De nition 2.2.1 to any set with maximization and minimization operators:De nition 5.0.3 A game is an o tuple (G;V; pI ; s; ev; f+; f ) su h that:1. G is a nite set of possible positions in the game.2. V is the set of values for the game.3. pI 2 G is the initial position of the game.4. s : G! 2G gives the su essors of a given position.5. ev : G ! fmax; ming [ V gives the value for terminal positions or indi ates whi hplayer is to move for nonterminal positions.6. f+ : P(V )! V and f : P(V )! V are the ombination fun tions for the maximizerand minimizer respe tively.The stru tures G, V , pI , s and ev are required to satisfy the following onditions (un hangedfrom De nition 2.2.1):1. There is no sequen e of positions p0; : : : ; pn with n > 0, pi 2 s(pi 1) for ea h i andpn = p0. In other words, there are no \\loops\" that return to an identi al position.2. ev(p) 2 V if and only if s(p) = .This de nition extends De nition 2.2.1 only in that the value set and ombinationfun tions have been generalized. A su h, De nition 5.0.3 in ludes both \\ onventional\"games in whi h the values are numeri and the ombination fun tions are max/min, andour more general setting where the values are fun tional and the ombination fun tions ombine them as des ribed above.As usual, we an use the maximization and minimization fun tions to assign a value tothe root of the tree:De nition 5.0.4 Given a game (G;V; pI ; s; ev; f+; f ), we introdu e a fun tion ev : G!V de ned re ursively byev (p) = 8<: ev(p); if ev(p) 2 V ;f+fev (p0)jp0 2 s(p)g; if ev(p) = max;f fev (p0)jp0 2 s(p)g; if ev(p) = min.The value of (G;V; pI ; s; ev; f+; f ) is de ned to be ev (pI).327\nGinsbergThe de nition is well founded be ause the game has no loops, and it is straightforwardto extend the minimax algorithm 2.2.3 to this more general formalism. We will dis ussextensions of - pruning in the next se tion.To esh out our previous informal des ription, we need to instantiate De nition 5.0.3.We do this by having the value of any parti ular node orrespond to the set of positionswhere the maximizer an win:1. The set G of positions is a set of pairs (p; Z) where p is a position with only two ofthe four bridge hands visible (i.e., a position in the \\single dummy\" game), and Z isthat subset of S (the set of situations) that is onsistent both with p and with the ards that were played to rea h p from the initial position.2. The value set V is 2S .3. The initial position pI is (p0; S), where p0 is the initial single-dummy position.4. The su essor fun tion is des ribed as follows:(a) If the de larer/maximizer is on play in the given position, the su essors areobtained by enumerating the maximizer's legal plays and leaving the set Z ofsituations un hanged.(b) If the minimizer is on play in the given position, the su essors are obtained byplaying any ard that is legal in any element of Z and then restri ting Z tothat subset for whi h is in fa t a legal play.5. Terminal nodes are nodes where all ards have been played, and therefore orrespondto single situations s, sin e the lo ations of all ards have been revealed. For su h aterminal position, if the de larer has made his ontra t, the value is S (the entire setof positions possible at the root). If the de larer has failed to make his ontra t, thevalue is S fsg.6. The maximization and minimization fun tions are omputed pointwise, so thatf+(U; V ) = U [ Vand f (U; V ) = U \\ VGiven an initial single-dummy situation p orresponding to a set S of situations, we will all the above game the (p; S) game.Proposition 5.0.5 Suppose that the set of situations for whi h the maximizer an makehis ontra t is T S. Then the value of the (p; S) game is T .It is natural to view T as an element of 2S ; it is the fun tion mapping points in T to 1and points outside of T to 0.Proof. The proof pro eeds by indu tion on the depth of the game tree. If the root nodep is also terminal, then S = fsg and the value is learly set orre tly (to s or ) by thede nition of the (p; S) game. 328\nGIB: Imperfe t information in a omputationally hallenging gameIf p is nonterminal, suppose rst that it is a maximizing node. Now let s 2 S be someparti ular situation. If the maximizer an win in s, then there is some su essor (p0; S0)to (p; S) where the maximizer wins, and hen e by the indu tive hypothesis, the value of(p0; S0) is a set U with s 2 U . But sin e the maximizer moves in p, the value assigned to(p; S) is a superset of the value assigned to any subnode, so that s 2 ev (p; S) = T .If, on the other hand, the maximizer annot win in s, then he annot win in any hildof s. If (pi; Si) are the su essors of (p; S) in the game tree, then again by the indu tivehypothesis, we must have s 62 ev (pi; Si) for ea h i. Butev (p; S) = [iev (pi; Si)so that s 62 ev (p; S) = T .For the minimizing ase, suppose that the maximizer wins in s. Then the maximizermust win in every su essor of s, so that s 2 ev (pi; Si) for ea h su h su essor and therefores 2 ev (p; S). Alternatively, if the minimizer wins in s, he must have a legal winning optionso that s 62 ev (pi; Si) for some i and therefore s 62 ev (p; S).Unfortunately, Proposition 5.0.5 is in some sense exa tly what we wanted not to prove:it says that our modi ed game omputes the set of situations in whi h it is possible for themaximizer to make his ontra t if he has perfe t information about the opponents' ards,not the set of situations in whi h it is possible for him to make his ontra t given his a tualstate of in omplete information.Before we go on to deal with this, however, let me look at an example in some detail.The example we will use is similar to that of Se tion 3 and involves a situation where themaximizer an make his ontra t if either West has the Q or East has three hearts. I willdenote by S the set of situations where West has the Q, and by T the set where East hasthree hearts. It's possible to tie in the \\defer the guess\" example from Se tion 3 as well, soI will do that also. Here is the game tree for the game in question: q q q q q q q qq q q qq q q q q PPPPPPPPPPP AAAA AAAA AAAA AAAA CCCC CCCC max maxmin min minmin min1 0 0 1 1 11 0 0 1\nS S SS ST T TT TAt the root node, the maximizer has four hoi es. If he makes the move on the left(playing for S, as it turns out), the minimizer then moves in a situation where the maximizerwins if S holds and loses if T holds. For the se ond move, where the maximizer is essentiallyplaying for T , the reverse is true.In the third ase, the maximizer defers the guess. We suppose that he is on play againimmediately, for ed to ommit between playing for S and playing for T . In the last ase,he wins independent of whether T or S obtains.329\nGinsbergIn the Monte Carlo setting, the above tree will a tually be split based on the element ofthe sample in question. In some ases, S will be true and we will examine only this subtree: q q q qqq q q qq q q PPPPPPPPPPP AAAA max maxmin min minmin min1 0 11 0\nS S SS SThe maximizer an win by making any move other than the se ond. In the ases where Tobtains, we examine: q q q qqq q q qq q q PPPPPPPPPPP AAAA AAAA AAAA AAAACCCC CCCC max maxmin min minmin min0 1 10 1\nT T TT THere, the maximizer an win by making any move other than the rst. In all ases, bothof the last two moves win for the maximizer, sin e this approa h annot re ognize the fa tthat the third move simply defers the guess while the fourth wins outright.Now let us return to the situation where we in lude information about the sets that itis possible to play for. Here is the tree again: q q q q q q q qq q q qq q q q q PPPPPPPPPPP AAAA AAAA AAAA AAAA CCCC CCCC max maxmin min minmin min1 0 0 1 1 11 0 0 1\nS S SS ST T TT TThe rst thing that we need to do is to realize that the terminal nodes should not belabelled with 1's and 0's but instead with sets where the maximizer an win. This produ es:330\nGIB: Imperfe t information in a omputationally hallenging game q q q q q q q qq q q qq q q q\nq PPPPPPPPPPP AAAA AAAA AAAA AAAA CCCC CCCC max maxmin min minmin minS [ T S T S [ T S [ T S [ TS [ T S T S [ TS S SS ST T TT TTo understand the labels, onsider the two leftmost fringe nodes. The leftmost node getslabelled with T \\for free\" be ause T is eliminated by the fa t that the minimizer hose S.Sin e the maximizer wins in S, the maximizer wins in all ases.For the se ond fringe node, S is in luded by virtue of the minimizer's moving to T ; Tis not in luded be ause the minimizer a tually wins on this line. Hen e the label of T forthe node in question. This analysis assumes that S and T are disjoint; if they overlap, thelabels be ome slightly more omplex but the overall analysis is little hanged.Ba king up the values one step gives us:\nq q q q q q q qq q q qq q q q q PPPPPPPPPPP AAAA AAAA AAAA AAAA CCCC CCCC max maxS [ T S T S [ T S [ T S [ TS [ T S T S [ T\nS T S [ TS T The minimizer, playing with perfe t information, always does as best he an. The rstinterior node's label of S, for example, means that the maximizer wins only if S a tually isthe ase.Of ourse, our de nitions thus far imply that the maximizer is playing with perfe tinformation as well, and we an ba k up the rest of the tree to get:\nq q q q q q q qq q q qq q q q q PPPPPPPPPPP AAAA AAAA AAAA AAAA CCCC CCCC S [ T S [ TS [ T S T S [ T S [ T S [ TS [ T S T S [ T\nS T S [ TS T 331\nGinsberg\n1e-050.0001 0.0010.01 0.1 0 2 4 6 8 10 12 P(err)\ntri k\nde laredefend\nFigure 6: Defense vs. de larer play for humansAs before, the maximizer \\wins\" with either of the last two options.Before we address the fa t that the players do not in fa t have perfe t information,let me point out that in most bridge analyses, imperfe t information is assumed to be anissue for the maximizer only. The defenders are assumed to be operating with ompleteinformation for at least the following reasons:1. In general, there is a premium for de laring as opposed to defending, so that bothsides want to de lare. Typi ally, the pair with greater assets in terms of high ardswins the \\bidding battle\" and su eeds in be oming the de laring side, so that theoverall assets available to the defenders in terms of high ards are generally less thanthose available to the de larer. This means that the defenders will generally be ableto predi t ea h other's hands with more a ura y than the de larer an.2. The defenders an signal, onveying to one another information about the ards theyhold. (As an example, play of an unne essarily high ard often indi ates an evennumber of ards in the suit being played.) They are generally assumed to signal onlyinformation that is useful to them but not to de larer, on e again improving their olle tive ability to play as if they had perfe t information.3. After the rst two or three tri ks, defenders' play is typi ally loser to double dummythan is the de larer's. This is shown in Figure 6, whi h ontrasts the quality of humanplay as defender with the quality of human play as de larer; we make more mistakesde laring than defending as of tri k four. (This gure is analogous to Figures 4 and5.) 332\nGIB: Imperfe t information in a omputationally hallenging gameThere are some deals where it is important for de larer to exploit un ertainty on the partof the defenders, but these are de nitely the ex eption as opposed to the rule.This suggests that Proposition 5.0.5 is doing a reasonable job of modeling the defenders' ardplay, but the ombination fun tion for the maximizer needs to be modi ed to re e tthe imperfe t-information nature of his task.To understand this, let us return to our putative expert, who suggested at the beginningof this se tion that he might be playing for West to hold the spade queen. What he mightsay in a bit more detail is, \\I ould play for ea h opponent to hold exa tly three hearts, orI ould play for West to hold the spade queen. The latter was the better han e.\"This suggests that the value assigned to the position by the maximizer is not a singleset of situations (those in whi h he an make the ontra t), but a set S of sets of situations.Ea h set S 2 S orresponds to one set of situations that the maximizer ould play for, givenhis in omplete knowledge of the positions of the opposing ards.Extending the notation used earlier in this se tion, we will denote the set of sets ofsituations by 22S . The maximizer's ombination fun tion on 22S is given bymax(F ;G) = F [ G (8)where ea h of F and G are sets of sets of situations. This says that if the maximizer is onplay in a situation p, and he has one move that will allow him to sele t from a set F ofthings to \\play for\" and another move that will allow him to sele t from a set G, then his hoi e at p is to sele t from any element of F [ G.The minimizer's fun tion is a bit more subtle. Suppose that at a node p, the minimizer an move to a su essor with value F = fFig, or to a su essor with value G = fGig. Whatvalue should we assign to p?Sin e the minimizer has perfe t information, he will always guarantee that the maximizera hieves the minimum value for the a tual situation. Whatever element of Fi 2 F or Gj 2 Gis eventually sele ted by the maximizer, the eventual value of p will be the minimum of Fiand Gj . In other words min(fFig; fGjg) = fmin(Fi; Gj)g (9)where the individual minima are omputed using the perfe t information rule (7).De nition 5.0.6 Let G be the set of positions in an imperfe t information game, a set ofpairs (p; Z) where p is a position from the point of view of the maximizing player and Z isthe set of perfe t information positions onsistent with p. The imperfe t information gamefor G is the game (G;V; pI ; s; ev; f+; f ) where:1. The value set V is 22S .2. The initial position pI is (p0; S), where p0 is the initial imperfe t information positionand S is the set of all perfe t information positions onsistent with it.3. The su essor fun tion is des ribed as follows:(a) If the maximizer is on play in the given position, the su essors are obtained byenumerating the maximizer's legal plays and leaving the elements of the set Z ofsituations un hanged. 333\nGinsberg(b) If the minimizer is on play in the given position, the su essors are obtained bymaking playing any ard that is legal in any element of X and then restri tingZ to those situations for whi h is in fa t a legal play.4. Terminal nodes are nodes where all ards have been played, and therefore orrespond tosingle situations s. For su h a terminal position, if the de larer has made his ontra t,the value is (fsg; fSg). If the de larer has failed to make his ontra t, the value is(fsg; fS fsgg).5. The maximization and minimization fun tions are given by (8) and (9) respe tively.Theorem 5.0.7 Suppose that the value of the imperfe t information game for G is T .Then a set of positions T is a subset of an element of T if and only if the maximizer hasa strategy that wins in every element of T , assuming that the minimizer plays with perfe tinformation.Proof. On e again, the proof pro eeds by indu tion on the depth of the game tree. Andon e again, the ase where p is a terminal position is handled easily by the de nition. Forthe indu tive ase, we onsider the maximizer and minimizer separately.For the maximizer, suppose that there is some set T of situations that satis es the onditions of the theorem, so that the maximizer has a strategy that aters to all of theelements of T . Then the rst move of that strategy will be some single move to a positionpi that is a su essor of p and that aters to the elements of T . Thus if the value of thesu essful hild is F , T is a subset of some F 2 F by the indu tive hypothesis. Thus if thevalue of the original game is G, T is a subset of an element of G by virtue of (8).Alternatively, if T is a set for whi h the maximizer has no su h strategy, then learly themaximizer annot have a strategy after making any of the moves to the su essor positionspi. This means that no superset U T in any ev (pi), and thus no superset of T in ev (p)either.The minimizing ase is not really any harder. Suppose rst that the maximizer has nostrategy for su eeding in every situation in T . Then the minimizer (playing with perfe tinformation) must have some move to a position pi with value Fi su h that T is not a subsetof any element of Fi. Now if Fi = fTig, re all thatmin(fTig; fUig) = fTi \\ Ujg;and T 6 Ti for ea h i. Thus T 6 Ti \\ Uj for ea h i and j, and there is no V T withV 2 min(fTig; fUig)For the last ase, suppose that the maximizer does have a strategy for su eeding inevery situation in T . That means that after any move for the minimizer, the maximizer willstill have a strategy that su eeds in T , so that if pi are the su essors of p and ev (pi) = Ti,then there is a Ti 2 Ti with T Ti. Now T \\iTi 2 min(Ti) = ev (p). Thus ev (p) ontains an element that is a superset of T .Using this result, we an in theory ompute exa tly the set of things we might play forgiven a single-dummy bridge problem. Before we turn to the issues involved in doing so inpra ti e, however, let me repeat the example of this se tion using the imperfe t informationte hnique. Here is the game tree again with values assigned to the terminal nodes:334\nGIB: Imperfe t information in a omputationally hallenging game q q q q q q q qq q q qq q q q\nq PPPPPPPPPPP AAAA AAAA AAAA AAAA CCCC CCCC max maxmin min minmin minfS [ Tg fSg fTg fS [ Tg fS [ Tg fS [ TgfS [ Tg fSg fTg fS [ TgS S SS ST T TT TBa king up past the minimizer's nal move gives us:\nq q q q q q q qq q q qq q q q q PPPPPPPPPPP AAAA AAAA AAAA AAAA CCCC CCCC max maxfSg fTg fS [ TgfSg fTgfS [ Tg fSg fTg fS [ Tg fS [ Tg fS [ TgfS [ Tg fSg fTg fS [ TgAnd we an now omplete the analysis to nally get: q q q q q q q qq q q qq q q q q PPPPPPPPPPP AAAA AAAA AAAA AAAA CCCC CCCC fS; T; S [ TgfS; TgfSg fTg fS [ TgfSg fTgfS [ Tg fSg fTg fS [ Tg fS [ Tg fS [ TgfS [ Tg fSg fTg fS [ TgNote the di eren e in the values assigned to the maximizer's third and fourth hoi es atthe rst ply. The third hoi e has value fS; Tg, indi ating learly that the maximizer willneed to subsequently de ide whether to play for S or for T . But the fourth hoi e has valuefS [ Tg indi ating that both possibilities are atered to.The value assigned to the root ontains some redundan y (whi h we will deal with inSe tion 7), in that one of the maximizer's hoi es (S[T ) dominates the others. Nevertheless,this value learly indi ates that the maximizer has an option available at the root that atersto both situations. 335"}, {"heading": "Ginsberg", "text": "q q q qq AAAAQQQQQQ CCCC minm1 m2 m3 m4 q q qq q q AAAA\nSSSS CCCC minminm2 m1 m3 m4Figure 7: Equivalent games?6. Extending alpha-beta pruning to latti esThe results of the previous se tion allow us to deal with imperfe t information in theory.Unfortunately, omputing the value in theory is hardly the same as omputing it in pra ti e.Some ideas, su h as transposition tables and partition sear h, an fairly obviously be appliedto games with values taken from sets more general than total orders. But what about - pruning, the lin hpin of high-performan e adversary sear h algorithms? The answer here isfar more subtle.6.1 Some ne essary de nitionsLet us begin by onsidering the two small game trees in Figure 7, where the minimizer ison play at the nonfringe nodes and none of the mi is intended to be ne essarily terminal.Are these two games always equivalent?We would argue that they are. In the game on the left, the minimizer needs to sele tamong the four options m1;m2;m3;m4. In the game on the right, he needs to rst sele twhether or not to play m2; if he de ides not to, he must sele t among the remainingoptions. Sin e the minimizer has the same possibilities in both ases, we assume that thevalues assigned to the games are the same.From a more formal point of view, the value of the game on the left is f (m1;m2;m3;m4),while that of the game on the right is f (m2; f (m1;m3;m4)) where we have abused nota-tion somewhat, writing mi for the value of the node mi as well.De nition 6.1.1 A game will be alled simple if for any x 2 v V ,f+fxg = f fxg = xand also f+(v) = f+fx; f+(v x)gand f (v) = f fx; f (v x)g336\nGIB: Imperfe t information in a omputationally hallenging gameWe have augmented the ondition developed in the dis ussion of Figure 7 with theassumption that if a player's move in a position p is for ed (so that p has a unique su essor),then the value before and after the for ed move is the same.Proposition 6.1.2 For any simple game, there are binary fun tions ^ and _ from V toitself that are ommutative, asso iative and idempotent14 and su h thatf+fv0; : : : ; vmg = v0 _ _ vmand f fv0; : : : ; vmg = v0 ^ ^ vmProof. Indu tion on m.When referring to a simple game, we will typi ally repla e the fun tions f+ and f bythe equivalent binary fun tions _ and ^. We assume throughout the rest of this se tionthat all games are simple.15The binary fun tions _ and ^ now indu e a partial order , where we will say that x yif and only if x _ y = y. It is not hard to see that this partial order is re exive (x x),antisymmetri (x y and y x if and only if x = y) and transitive. The operators _and ^ behave like greatest lower bound and least upper bound operators with regard to thepartial order.We also have the following:Proposition 6.1.3 Whenever S T , f+(S) f+(T ) and f (S) f (T ).In other words, assuming that the minimizer is trying to rea h a low value in the partialorder and the maximizer is trying to rea h a high one, having more options is always good.6.2 Shallow pruningWe are now able to investigate - pruning in our general framework. Let us begin withshallow pruning, shown in Figure 8.The idea here is that if the minimizer prefers x to y, he will never allow the maximizereven the possibility of sele ting between y and the value of the subtree rooted at T . Afterall, the value of the maximizing node in the gure is y_ev (T ) y x, and the minimizerwill therefore always prefer x.In order for the usual orre tness proof for (shallow) - pruning to hold, we need thefollowing ondition to be satis ed:De nition 6.2.1 (Shallow - pruning) A game G will be said to allow shallow - prun-ing for the minimizer if x ^ (y _ T ) = x (10)14. A binary fun tion f is alled idempotent if f(a; a) = a for all a.15. We also assume that the games are su\u00c6 iently omplex that we an nd in the game tree a node withany desired fun tional value, e.g., a ^ (b _ ) for spe i a, b and . Were this not the ase, none of ourresults would follow. As an example, a game in whi h the initial position is also terminal surely admitspruning of all kinds (sin e the game tree is empty) but need not satisfy the on lusions of the results inthis se tion. 337\nGinsberg\nq qq q q AAAA SSSS CCCC maxminx y TFigure 8: T an be pruned (shallowly) if x yfor all x; y; T 2 V with x y. The game will be said to allow shallow - pruning for themaximizer if x _ (y ^ T ) = x (11)for all x; y; T 2 V with x y. We will say that G allows shallow pruning if it allows shallow - pruning for both players.The de nition basi ally says that the ba ked up value at the root of the game tree isun hanged by pruning the maximizing subtree in the gure.As we will see shortly, the expressions (10) and (11) des ribing shallow pruning areidenti al to what are more typi ally known as absorption identities.De nition 6.2.2 Suppose V is a set and ^ and _ are two binary operators on V . Thetriple (V;^;_) is alled a latti e if ^ and _ are idempotent, ommutative and asso iative,and satisfy the absorption identities in that for any x; y 2 V ,x _ (x ^ y) = x (12)x ^ (x _ y) = x (13)We also have the following:De nition 6.2.3 A latti e (V;^;_) is alled distributive if ^ and _ distribute with respe tto one another, so that x _ (y ^ z) = (x _ y) ^ (x _ z) (14)x ^ (y _ z) = (x ^ y) _ (x ^ z) (15)Lemma 6.2.4 Ea h of (12) and (13) implies the other. Ea h of (14) and (15) implies theother.Proof. These are well known results from latti e theory (Gr atzer, 1978).Proposition 6.2.5 (Ginsberg & Ja ray, 2001) For a game G, the following onditionsare equivalent: 338\nGIB: Imperfe t information in a omputationally hallenging game\nr rr r r AAAA SSSS CCCC rmaxrmin maxminx y TFigure 9: T an be pruned (deeply) if x y1. G allows shallow - pruning for the minimizer.2. G allows shallow - pruning for the maximizer.3. G allows shallow pruning.4. (V;^;_) is a latti e.Proof.16 We show that the rst and fourth onditions are equivalent; everything else followseasily.If G allows shallow - pruning for the minimizer, we take x = a and y = T = a _ b in(10). Clearly x y so we geta ^ (y _ y) = a ^ y = a ^ (a _ b) = aas in (13).For the onverse, if x y, then x ^ y = x andx ^ (y _ T ) = (x ^ y) ^ (y _ T )= x ^ (y ^ (y _ T ))= x ^ y= x:6.3 Deep pruningDeep pruning is a bit more subtle. An example appears in Figure 9.As before, assume x y. The argument is as des ribed previously: Given that theminimizer has a guaranteed value of x at the upper minimizing node, there is no way thata hoi e allowing the maximizer to rea h y an be on the main line; if it were, then themaximizer ould get a value of at least y.16. The proofs of this and Proposition 6.3.2 are due to Alan Ja ray.339\nGinsbergr r r r r 0 | } ~ | maxmin\nmaxmin Figure 10: The deep pruning ounterexampleDe nition 6.3.1 (Deep - pruning) A game G will be said to allow - pruning for theminimizer if for any x; y; T; z1; : : : ; z2i 2 V with x y,x ^ (z1 _ (z2 ^ _ (z2i ^ (y _ T ))) ) =x ^ (z1 _ (z2 ^ _ z2i) ):The game will be said to allow - pruning for the maximizer ifx _ (z1 ^ (z2 _ ^ (z2i _ (y ^ T ))) ) =x _ (z1 ^ (z2 _ ^ z2i) ):We will say that G allows pruning if it allows - pruning for both players.As before, the prune allows us to remove the dominated node (y in Figure 9) and all of itssiblings.The fa t that a game allows shallow - pruning does not mean that it allows pruningin general, as is shown by the following ounterexample. The example involves a game withone ard that is known to both players; only the suit of the ard matters. The game treeappears in Figure 10.In this tree, a node labelled with a suit symbol is terminal and means that the maximizerwins if and only if the suit of the ard mat hes the given symbol. So at the root of the giventree, the maximizer (whose turn it is to play) an hoose to \\turn over\" the ard, winningif and only if it's a lub, or an defer to the minimizer. The minimizer an hoose to turnthe ard (losing just in ase it's a diamond { the suit symbols refer to the maximizer'sresult), or hand the situation ba k to the maximizer. If the maximizer defers yet again,the minimizer an either turn over the ard, losing if it's a lub, or simply de lare vi tory(presumably his hoi e).There is one other wrinkle in this game. At any point in the game, the maximizer an hange the ard from either a diamond or a spade to a lub.Now let's onsider the game itself. At ply 4, the minimizer will obviously hoose to winthe game. Thus at ply 3, the maximizer will need to hoose ~, winning just in ase the ard is a heart. But this means that at ply 2, the minimizer will win the game, sin e if the ard is not a diamond he will move to the left (and win at on e) while if the ard is not aheart he an win by moving to the right. (Remember that the minimizer knows the suit340\nGIB: Imperfe t information in a omputationally hallenging gameof the ard.) The upshot of this is that the maximizer wins the overall game if and only ifthe ard in question is a lub. A formal analysis pro eeds similarly, labelling the nodes asfollows: r r r r r 0 | } ~ | ~ = ~ _ 00 = | ^ 0\n| = | _ 00 = } ^~ Note, in identally, that the maximizer's ability to hange the ard does not help him winthe game.Now suppose that we apply deep pruning to this game. The ply four node is one wherethe minimizer an for e a value of at most |, suggesting that the siblings of the bottom |node an be pruned. But doing so produ es the following tree:r r r r r\npruned? | } ~ | 1 = ~ _|| | _}} = } ^ 1\nIf the maximizer rea hes ply 3, he an win by hanging the ard to a lub if need be.Of ourse, the minimizer won't let the maximizer rea h ply 3; at ply 2, he'll move leftso that the maximizer wins only if the ard is a diamond. That means that the maximizerwins at the root just in ase the ard is either a lub or a diamond.A partial graph of the values for this game is as follows: r rr r r r QQQQQQ AAAA 0 1| }~ where we have in luded the ru ial fa t that x ^ y = 0 if x 6= y (sin e the minimizer knowsthe ard) and ~ _ | = 1 be ause the maximizer an invoke his spe ial rule. Other leastupper bounds are not shown in the diagram. The maximizing fun tion _ moves up the gure; the minimizing fun tion ^ moves down.The deep prune fails be ause we an't \\push\" the value | ^ 0 past the ~ to get to the| near the root. Somewhat more pre isely, the problem is that~ = ~ _ (| ^ 0) 6= (~ ^|) _ (~ ^ 0) = 0This suggests the following: 341\nGinsbergProposition 6.3.2 (Ginsberg & Ja ray, 2001) For a game G, the following onditionsare equivalent:1. G allows - pruning for the minimizer.2. G allows - pruning for the maximizer.3. G allows pruning.4. (V;^;_) is a distributive latti e.Proof. As before, we show only that the rst and fourth onditions are equivalent. Sin epruning implies shallow pruning (take i = 0 in the de nition), it follows that the rst ondition implies that (V;^;_) is a latti e.From deep pruning for the minimizer with i = 1, we have that if x y, then for anyz1; z2; T , x ^ (z1 _ (z2 ^ (y _ T ))) = x ^ (z1 _ z2)Now take y = T = x to get x ^ (z1 _ (z2 ^ x)) = x ^ (z1 _ z2) (16)It follows that ea h top level term in the left hand side of (16) is greater than or equal tothe right hand side; spe i allyz1 _ (z2 ^ x) x ^ (z1 _ z2): (17)We laim that this implies that the latti e in question is distributive.To see this, let u; v; w 2 V . Now take z1 = u ^ w, z2 = v and x = w in (17) to get(u ^ w) _ (v ^ w) w ^ ((u ^ w) _ v) (18)But v _ (u ^w) w ^ (v _ u) is an instan e of (17), and ombining this with (18) gives us(u ^ w) _ (v ^ w) w ^ ((u ^ w) _ v) w ^ w ^ (v _ u)= w ^ (v _ u)This is the hard dire tion; w ^ (v _ u) (u ^ w) _ (v ^ w) for any latti e be ausew^ (v_u) u^w and w^ (v_u) v^w individually. Thus w^ (v_u) = (u^w)_ (v^w),and deep pruning implies that the latti e is distributive.For the onverse, if the latti e is distributive and x y, thenx ^ (z1 _ (z2 ^ (y _ T ))) = (x ^ z1) _ (x ^ z2 ^ (y _ T ))= (x ^ z1) _ (x ^ z2)= x ^ (z1 _ z2)where the se ond equality is a onsequen e of the fa t that x (y_T ), so that x = x^(y_T ).This validates pruning for i = 1; deeper ases are similar.Finally, note that in games where this result applies, we an ontinue to use Algorithms2.2.5 or 2.3.3 without modi ation, sin e the prunes that they endorse ontinue to be soundas the game tree is expanded. 342\nGIB: Imperfe t information in a omputationally hallenging game6.4 Appli ation to imperfe t informationIn order to apply these ideas to games of imperfe t information treated as in Se tion 5, weneed to show that the value set introdu ed there is a (hopefully distributive) latti e.To do this, re all that there is redundant information in an arbitrary element F of 22S ,sin e if F ontains both T and U with T U (in other words, the maximizer an playfor either T or for U but U is properly better), the set T an be removed from F withouta e ting the maximizer's options in any interesting way. This suggests the following:De nition 6.4.1 Let F 2 22S for an arbitrary set S. We will say that F is redu ed ifthere are no T;U 2 F with T U . We will say that F1 is a redu tion of F2 if F1 is redu edand F1 F2.Lemma 6.4.2 Every F 2 22S has a unique redu tion.Proof. This is immediate; just remove the subsumed elements from F . .We will denote the redu tion of F by r(F).Armed with this de nition, we an now modify De nition 5.0.6 in the obvious way,repla ing the value set V with the set of redu ed elements of V and the maximizing andminimizing fun tions (8) and (9) with the redu ed versions thereof, so thatmax(F ;G) = r(F [ G) (19)and min(fFig; fGjg) = r(fFi \\Gjg) (20)Remember that we typi ally write _ for max and ^ for min.Proposition 6.4.3 Given the above de nitions, (V;_;^) is a distributive latti e.Proof. We need to show that max and min as de ned above are ommutative, asso iative,and idempotent, that they distribute with respe t to one another, and that the absorptionidentity (12) is satis ed. Sin e the redu tion operator learly ommutes with the initialde nitions of max and min, ommutativity, asso iativity and distributivity are obvious, asis the fa t that _ is idempotent. To see that ^ is idempotent, we haveF ^ F = r(fmin(Fi; Fj)g) = r(fFi \\ Fjg)but ea h element of the set on the righthand side is a subset of Fi \\ Fi soF ^ F = r(fFig) = r(F) = F :For the absorption identity, we need to show thatF _ (F ^ G) = FBut F ^ G = rfFi \\Gjg343\nGinsbergso F _ (F ^ G) = r(F _ rfFi \\Gjg)= r(fFig [ fFi \\Gjg)= r(fFig)= r(F)= Fsin e, on e again, ea h element of F ^ G is subsumed by the orresponding Fi.It follows that an implementation designed to ompute the value of an imperfe t in-formation game as des ribed by Theorem 5.0.7 an indeed use - pruning to speed the omputation.6.5 Bridge implementationGiven this body of theory, we implemented a single-dummy version of gib's double-dummysear h engine. Not surprisingly, the most di\u00c6 ult element of the implementation was build-ing e\u00c6 ient data stru tures for the manipulation of elements of 22S .To handle this, we represented ea h element of S as a onjun tion. We rst identi edone of the two hidden hands H, and then for ea h ard , would write if were held byH and : if were not held by H. An element of 2S was then taken to be a disjun tive ombination of these onjun tions, and an element of 22S was taken to be a list of su hdisjun tions. The advantage of this representation was that logi al inferen e ould be usedto onstru t the redu tion of any su h list.In order to make this inferen e as e\u00c6 ient as possible, the disjun tions themselves wererepresented as binary de ision diagrams, or bdd's (Lind-Nielsen, 2000). There are a varietyof publi domain implementations of bdd's available, and we used one provided by Lind-Nielsen (Lind-Nielsen, 2000).17The resulting implementation solves small endings (perhaps 16 ards left in total) qui klybut for larger endings, the running times ome to be dominated by the bdd omputations;this is hardly surprising, sin e the size of individual bdds an be exponential in the sizeof S (the number of possible distributions of the unseen ards). We found that we weregenerally able to solve 32- ard endings in about a minute, but that the running times werein reasing by two orders of magnitude as ea h additional ard was added.This is both good news and bad news. Viewed positively, the performan e of the systemas onstru ted is far superior to the performan e of pre eding attempts to deal with theimperfe t information arising in bridge. Frank et.al, for example, are only apable of solvingsingle suit ombinations (13 ards left, give or take) using an algorithm that appears to takeseveral minutes to run (Frank, Basin, & Matsubara, 1998). They subsequently improve theperforman e to an average time of 0.6 se onds (Frank et al., 2000), but are still restri ted toproblems that are too small to be of mu h use to a program intended to play the ompletegame.17. We tried a variety of non-bdd based implementations as well. The bdd-based implementation was farfaster than any of the others. 344\nGIB: Imperfe t information in a omputationally hallenging gameThat's the good news. The bad news is that a program apable only of solving an 8- ard ending in a minute is inappropriate for produ tion use. Gib is a produ tion program,expe ted to play bridge at human speeds. Another approa h was therefore needed.7. Solving single-dummy problems in pra ti e7.1 A hievable setsThe key to pra ti al appli ation of the ideas in the previous se tion is the realization thatwhen it omes time to make a play, a single element of F must be sele ted: if you an playfor West to have the Q or for ea h player to have three hearts but annot ater to bothpossibilities simultaneously, you eventually have to a tually make the hoi e.De nition 7.1.1 Suppose that the value of the imperfe t information game for G is F .Given a spe i A S, we will say that A is a hievable if there is some F 2 F for whi hA F .In other words, the set A of situations is a hievable if the maximizer has a plan that winsfor all elements of A.De nition 7.1.2 Given a set S of situations, a payo fun tion for S is any fun tionf : 2S ! IR su h that f(U) f(T ) whenever U T .The payo fun tion evaluates potential a hievable sets.De nition 7.1.3 Let G be a game and S the asso iated set of situations. If f is a payo fun tion for S, a solution to G under f is any a hievable set A for whi h f(A) is maximal.In pra ti e, we need not nd the a tual value of the game; nding a solution to G underan appropriate payo fun tion su\u00c6 es. In bridge, the payo fun tion is presumably theprobability that the ards are dealt as in the set A; this fun tion learly in reases within reasing set size as required by De nition 7.1.2 and an be evaluated in pra ti e using theMonte Carlo sample of Se tion 3.Instead of nding the solution to an imperfe t information game, suppose instead thatwe have a Monte Carlo sample for the game onsisting of a set of situations S = fsig thatis ordered as i = 0; : : : ; n. We an now produ e an a hievable set A as follows:Algorithm 7.1.4 To onstru t a maximal a hievable set A from a sequen e hs0; : : : ; sni ofsituations:1. Set A = .2. For i = 0; : : : ; n, if A [ fsig is a hievable, set A = A [ fsig.The algorithm onstru ts the a hievable set in a greedy fashion, gradually adding elementsof S to A until no more an be added.De nition 7.1.5 Given a game G and a sequen e S of situations, the a hievable set in-du ed by S for G is the set onstru ted by Algorithm 7.1.4.345\nGinsbergFrom a omputational point of view, the expensive step in the algorithm is determiningwhether or not the set A [ fsig is a hievable. This is relatively straightforward, however,sin e the fo us on a spe i set e e tively repla es the game G with a new game withvalues in f0; 1g. At any parti ular node n, if expanding n demonstrates that A [ fsig isnot a hievable, the value of the game is zero. If expanding n indi ates that A [ fsig isa hievable on e n is rea hed, then the value of the node n is one. Although the sear h spa eis un hanged from that of the original imperfe t information game as in De nition 5.0.6,there is no longer any need to manipulate omplex values, and the he k for a hievabilityis therefore tra table in pra ti e.Let me illustrate this by returning to our usual example of Se tion 5. Here is the fullyevaluated tree on e again: q q q q q q q qq q q qq q q q\nq PPPPPPPPPPP AAAA AAAA AAAA AAAA CCCC CCCC fS [ Tg fS; TgfSg fTg fS [ TgfSg fTgfS [ Tg fSg fTg fS [ Tg fS [ Tg fS [ TgfS [ Tg fSg fTg fS [ TgNote that we have repla ed the value at the root with its redu tion.Now suppose that we view the set of positions as ontaining only two elements, s 2 Sand t 2 T . Presumably West holds the Q in s, and East holds three hearts in t. If theordering hosen is hs; ti, then we rst try to a hieve fsg. In this ontext, a node n is a winfor the maximizer if either the maximizer an indeed win at n or s is no longer possible (inwhi h ase the maximizer's ability to a hieve fsg is undiminished). The game tree be omes: q q q q q q q qq q q qq q q q q PPPPPPPPPPP AAAA AAAA AAAA AAAA CCCC CCCC max maxmin min minmin min1 1 0 1 1 11 1 0 1S S SS ST T TT TAll of the T bran hes are wins for the maximizer (who is on erned with s only), and theS bran hes are wins just in ase the maximizer does indeed win (as he does if he guessesright at either of the rst two plies). Ba king up the values gives us:346\nGIB: Imperfe t information in a omputationally hallenging game q q q q q q q qq q q qq q q q\nq PPPPPPPPPPP AAAA AAAA AAAA AAAA CCCC CCCC 1 11 0 10 11 1 0 1 1 11 1 0 1S S SS ST T TT TThis indi ates ( orre tly) that the maximizer an a hieve s provided that he doesn't de ideto play for T at the root of the tree. Note that this analysis is a straight minimax, allowingfast algorithms to be applied while avoiding the manipulation of elements of 22S des ribedin the previous se tion.Now we add t to our a hievable set, whi h thus be omes fs; tg. The maximizer winsonly if he really does win (and not just be ause he isn't interested in T any more), and thebasi tree be omes:\nq q q q q q q qq q q qq q q q q PPPPPPPPPPP AAAA AAAA AAAA AAAA CCCC CCCC max maxmin min minmin min1 0 0 1 1 11 0 0 1S S SS ST T TT TBa king up the values gives:\nq q q q q q q qq q q qq q q q q PPPPPPPPPPP AAAA AAAA AAAA AAAA CCCC CCCC 1 00 0 10 01 0 0 1 1 11 0 0 1S S SS ST T TT TThe maximizer an a hieve the extended result only by making the rightmost move, asdesired.What if the rightmost bran h did not exist, so that the maximizer were unable to ombine his han es? Now the value of the root node in the above tree is 0, so that fs; tg isnot a hievable. The maximal a hievable set returned by the algorithm would be S; had the347\nGinsbergordering been ht; si instead, an alternative maximal a hievable set of T would have beenreturned instead.In any event, we have:Proposition 7.1.6 Given a game G and a sequen e S of situations, let A be the a hievableset indu ed by S for G. Then no proper superset of A in S is a hievable.Proof. This is straightforward. For any element s 2 S A, we know that U [ fsg is nota hievable for some U A. Thus A [ fsg is not a hievable as well.Algorithm 7.1.4 allows us to onstru t maximal a hievable sets relative to our MonteCarlo sample; re all that we are taking our sequen e S of situations to be any orderingof the sample itself. In pra ti e, however, it is important not to fo us too sharply on thesample itself, lest the eventual a hievable set onstru ted over t irrelevant probabilisti hara teristi s of that sample. This an be a omplished by repla ing the simple union instep 2 of the algorithm with some more ompli ated operation that aptures the idea of\\situations that are either like si or like those already in A.\" In bridge, for example, A mightbe all situations where West has two or three hearts, and si might be some new situationwhere West has four hearts. The generalized union would be situations where West hastwo, three or four hearts. If this more general set is not a hievable, another attempt ouldbe made with the simple union. If we denote the \\general union\" by , Algorithm 7.1.4be omes:Algorithm 7.1.7 To onstru t an a hievable set A from a sequen e hs0; : : : ; sni of situa-tions:1. Set A = .2. For i = 0; : : : ; n:(a) If A fsig is a hievable, set A = A fsig.(b) Otherwise, if A [ fsig is a hievable, set A = A [ fsig.This algorithm an be used in pra ti e to nd a hievable sets that are either maximalor e e tively so over the set of all possible instan es, not just those appearing in the MonteCarlo sample.7.2 Maximizing the payo It remains to nd not just maximal a hievable sets, but ones that approximate the solutionto the game in question given a parti ular payo fun tion.To understand how we do this, let me draw an analogy between the problem we are tryingto solve and resour e- onstrained proje t s heduling (r ps). In r ps, one has a list of tasksto be performed, together with ordering onstraints saying that ertain tasks need to beperformed before others. In addition, ea h task uses a ertain quantity of various resour es;there are limitations on the availability of any parti ular resour e at any parti ular time.As an example, building an air raft wing may involve fabri ating the top and bottom ightsurfa es, building the aileron, and atta hing the two. It should be lear that the aileron348\nGIB: Imperfe t information in a omputationally hallenging game annot be atta hed until both it and the wing have been onstru ted. Building ea h se tionmay involve the use of three sheetmetal workers, but only ve may be available in general.The goal in an r ps problem is typi ally to minimize the length of the s hedule (often alled the makespan) without ex eeding the resour e limits. In building a wing, it is moree\u00c6 ient (and more ost e e tive) to build it qui kly than slowly.Many produ tion s heduling systems try to minimize makespan by building the s hedulefrom the initial time forward. At ea h point, they sele t a task all of whose prede essorshave been s heduled, and then s hedule that task as early as possible given the previouslys heduled tasks and the resour e onstraints. S heduling the tasks in this way produ es alo ally optimal s hedule that may be improved by modifying the order in whi h the tasksare sele ted for s heduling.One method for nding an appropriate modi ation to the sele tion order is known assqueaky wheel optimization, or swo (Joslin & Clements, 1999). In swo, a lo ally optimals hedule is examined to determine whi h tasks are s heduled most suboptimally relative tosome overall metri ; those tasks are deemed to \\squeak\" and are then advan ed in the tasklist so that they are s heduled earlier when the s hedule is re onstru ted. This pro ess isrepeated, produ ing a variety of andidate solutions to the s heduling problem at hand; oneof these s hedules is typi ally optimal or nearly so.Applying swo to our game-playing problem is relatively straightforward.18 When weuse Algorithm 7.1.7 to onstru t an a hievable set, we also onstru t as a byprodu t a list ofsample elements to whi h that a hievable set annot be extended; moving elements of thislist forward in the sequen e of hs0; : : : ; sni will ause them to be more likely to be in ludedin the a hievable set A if the algorithm is reinvoked. The weights assigned to the failingsequen e elements an be onstru ted by determining how representative ea h parti ularelement is of the remainder of the sample.Returning to our example, suppose that the set S (where West has the Q) has a singlerepresentative s1 in the Monte Carlo sample (presumably this means it is unlikely for Westto hold the ard in question), while T has ve su h representatives t1, t2, t3, t4 and t5.Suppose also that the initial ordering of the six elements is hs1; t4; t2; t1; t5; t3i.Assuming that the maximizer loses his rightmost option (so that he annot ater to Sand T simultaneously), the maximal a hievable set orresponding to this ordering is S. Anexamination now reveals that all of the ti's ould have been a hieved but weren't; in swoterms, these elements of the sample \\squeak.\"At the next iteration, the priorities of the ti's are in reased by moving them forward inthe sequen e, while the priority of s1 falls. Perhaps the new ordering is ht4; t2; s1; t1; t5; t3i.This ordering an be easily seen to lead to the maximal a hievable set T ; S [ T is stilluna hievable. But the payo assigned to T is likely to be mu h better than that assignedto S (a probability of 0.8 instead of 0.2, if the Monte Carlo sample itself is unweighted). Itis in this way that swo allows us to nd a globally optimal (or nearly so) a hievable set.18. Squeaky wheel optimization was developed at the University of Oregon; the patent appli ation for thete hnique has been allowed by the U.S. Patent and Trademark O\u00c6 e. The University's interests in swoare li ensed ex lusively to On Time Systems, In . for use in s heduling and related appli ations, and toJust Write, In . for use in bridge-playing systems.349\nGinsberg7.3 ResultsOur implementation of gib's ardplay when de larer is based on the ideas des ribed above.(As a defender, a dire t Monte Carlo approa h appears preferable be ause enough infor-mation is typi ally available about de larer's hand to make the double-dummy assumptionreasonably valid.) The implementation is fast enough to onform to the time requirementspla ed on a produ tion program (roughly one pu minute to play ea h deal).Evaluating the impa t of these ideas on gib's ardplay is di\u00c6 ult, sin e de larer play isalready the strongest aspe t of its game. In extended mat hes between the two versions ofgib, the approa h based on the ideas des ribed here beats the Monte-Carlo based versionby approximately 0.1 imps/deal, but there is a great deal of noise in the data be ause mostof the swings orrespond to di eren es in bidding or defensive play. It is possible to removesome of these di eren es arti ially (requiring the bidding to be identi al both times thedeal is played, for example), but defensive di eren es remain. Nevertheless, gib is urrentlya strong enough player that the 0.1 imps/deal di eren e is signi ant.The situation on problem deals, su h as those from the par ontests or from the Gitelmansets, is mu h learer. In addition, many of the deals that gib gets \\wrong\" are in fa t dealsthat gib plays orre tly but that the problem omposers play in orre tly (Gitelman or, inthe ase of the par ontests, Swiss bridge expert Pietro Bernas oni). In the following table,we have been generous with all parties, deeming a line to be orre t if it is not learlyinferior to another. Let me point out that the designers of the problems are attempting to onstru t deals where there is a unique solution (the \\answer\" to the test they are posingthe solver), so that a deal with multiple solutions is in fa t one that the omposer hasalready misanalyzed.Sour e size BB GibMC GibSWO omposer ambiguousBM level 1 36 16 31 36 35 0level 2 36 8 23 34 34 1level 3 36 2 12 34 34 2level 4 36 1 21 31 34 4level 5 36 4 13 28 34 51998 par ontest 12 0 5 11 12 21990 par ontest 18 0 8 14 17 3The rows are in order of in reasing di\u00c6 ulty; it was universally felt among the human ompetitors that the deals in the 1990 par ontest were far more di\u00c6 ult than those in1998. The olumns are as follows:Sour e is the sour e from whi h the problems were obtained.Size is the number of problems available from this parti ular sour e.BB gives the number of problems solved orre tly by Bridge Baron 6.GibMC gives the number solved orre tly by gib using a Monte Carlo approa h.GibSWO gives the number solved orre tly by gib using swo and a hievable sets. omposer gives the number solved orre tly by the omposer (in that the intendedsolution was the best one available).ambiguous gives the number misanalyzed by the omposer (in that multiple solutionsexist). 350\nGIB: Imperfe t information in a omputationally hallenging gameNote, in identally, that gib's performan e is still less than perfe t on these problems.The reason is that gib's sample may be skewed in some way, or that swo may fail to nda global optimum among the set of possible a hievable sets.8. Con lusion8.1 GIB omparedOther programs Gib parti ipated in both the 1998 and the 2000 World ComputerBridge Championships. (There was no 1999 event.) Play was organized with ea h ma hineplaying two hands and the ompetitors being trusted not to heat by \\peeking\" at partner's ards or those of the opponents.19Ea h tournament began with a omplete round robin among the programs, with the topfour programs ontinuing to a kno kout phase. The mat hes in the round robin were quiteshort, and it was expe ted that bridge's sto hasti element would keep any program frombeing ompletely dominant.While this may have been true in theory, in pra ti e gib dominated both round robins,winning all of its mat hes in 1998 and all but one in 2000. The round robin results fromthe 2000 event were as follows:20Gib WB Mi ro Buff Q-Plus Chip Baron M'lark TotalGib { 14 11 16 7 19 16 17 100WBridge 6 { 19 13 16 7 18 20 99Mi ro 9 1 { 18 15 15 13 20 91Buff 4 7 2 { 12 20 5 20 70Q-Plus 13 4 5 8 { 11 14 11 66Blue Chip 1 13 5 0 9 { 11 20 59Baron 4 2 7 15 6 9 { 14 57Meadowlark 3 0 0 0 9 0 6 { 18Ea h mat h was onverted rst to imps and then to vi tory points, or VPs, with the two ompeting programs sharing the 20 VPs available in ea h mat h. The rst entry in theabove table indi ates that gib beat wbridge by 14 VPs to 6; the fourth that gib lostto q-plus bridge by 7 VPs to 13. (This is gib's only loss ever to another program intournament play.)In the 1998 kno kout phase, gib beat Bridge Baron in the semi nals by 84 imps over 48deals. Had the programs been evenly mat hed, the imp di eren e ould be expe ted to benormally distributed, and the observed 84 imp di eren e would be a 2.2 standard deviation19. Starting with the 2001 event, ea h omputer will handle only one of the four players, although thereis still no attempt to prevent the (networked) omputers from transmitting illegal information betweenpartners.20. There were eight ompetitors in the event: gib (www.gibware. om), Hans Leber's q-plus(www.q-plus. om), Tomio and Yumiko U hida's mi ro bridge (www.threeweb.ad.jp/~m bridge),Mike Whittaker and Ian Tra kman's blue hip bridge (www.blue hipbridge. o.uk), Rod Lud-wig's meadowlark bridge (rrnet. om/meadowlark), bridge baron (www.bridgebaron. om), andtwo new omers: Doug Bannion's bridge buff (www.bridgebu . om) and Yves Costel's wbridge(ourworld. ompuserve. om/homepages/yves ostel).351\nGinsbergevent. Gib then beat Q-Plus Bridge in the nals by 63 imps over 64 deals (a 1.4 standarddeviation event). In 2000, it beat Bridge Bu by 39 imps over 48 deals in the semi nals(a 1.0 standard deviation event) and then beat wbridge by 101 imps over 58 deals (a 2.6standard deviation event). The nals had been s heduled to run 64 deals, but wbridge on eded after 58 had been played.The most publi ized deal from the nal was this one, an extremely di\u00c6 ult deal that bothprograms played moderately well. Gib rea hed a better ontra t and was aided somewhatby wbridge's misdefen e in a moderately omplex situation. K Q 9~ A Q J} 9 6 4 3 2| 8 6 10 6 8 7 3 2~ 10 9 2 ~ 7 5 3} 10 } A K Q J 8 5| A J 10 9 5 3 2 | | A J 5 4~ K 8 6 4} 7| K Q 7 4When wbridge played the North-South ards and gib was East-West, North opened1} and eventually played in three notrump, ommitting to taking nine tri ks. The gib Eaststarted with four rounds of diamonds as South dis arded two lubs and . . . ?Looking at all four hands, the ontra t is old; South an dis ard another lub and Easthas none to play. There are thus nine tri ks: four in ea h of hearts and spades, and thediamond nine.Give East a lub, however, and the ontra t rates to be down no less than four sin ethe defense will be able to take at least four lub tri ks. WBridge de ided to play safe,keeping the |KQ and dis arding a heart. There are now only eight tri ks and the ontra twas down one.The bidding and play were more interesting when gib was N-S. North opened 1NT,showing 11{14 HCP without four hearts or spades unless exa tly three ards were held inevery other suit. East over alled a natural 2} and South ue bid 3}, showing weakness indiamonds and asking North to bid a 4- ard heart or spade suit if he had one.North has no good bid at this point. Bidding 3NT with ve small diamonds rates to bewrong and 4| is learly out of the question. Gib's simulation suggested that 3 (ostensiblyshowing four of them) was the least of evils. South raised to 4 , and East doubled, endingthe au tion.East led a top diamond, and shifted to the ~3, won by North's ~Q. Gib now ashedthe ~J and led the |6, whi h East hose (wrongly) to ru . WBridge now led the }K asEast, whi h was ru ed with the J. Gib was now able to ash the AK to produ e:352\nGIB: Imperfe t information in a omputationally hallenging game Q~ A} 9 6 2| 8 | 8~ | ~ 7} | } Q J 8 5| A J 10 9 5 3 | | 5~ K 8} || K Q 4Knowing the position exa tly, gib needed ve more tri ks with North to lead. It ru eda diamond, returned to the ~A and drew East's trump with the Q. Now a lub for ed anentry to the South hand, where the ~K provided the tenth tri k.Humans Gib played a 14-deal demonstration mat h against human world hampions ZiaMahmood and Mi hael Rosenberg21 in the AAAI Hall of Champions in 1998, losing by atotal of 6.4 imps (a 0.3 standard deviation event). Early versions of gib also played onOKBridge, an internet bridge lub with some 15,000 members.22 After playing thousandsof deals against human opponents of various levels, gib's ranking was omparable to theOKBridge average.It is probable that neither of these results is an a urate re e tion of gib's urrentstrength. The Mahmood-Rosenberg mat h was extremely short and gib appeared to havethe best of the lu k. The OKBridge interfa e has hanged and the gib `OKbots' no longerfun tion. The performan e gures there are thus somewhat outdated, predating variousre ent improvements in luding all of the ideas in Se tions 5{7. More interesting informationwill be ome available starting in late July of 2001, when gib, paired with Gitelman and hisregular partner Brad Moss, will begin a series of 64-deal mat hes against human opponentsof varying skill levels.8.2 Current and future workRe ent work on gib has fo used on its weakest areas: defensive ardplay and bidding. Thebidding work has been and ontinues to be primarily a matter of extending the existingbidding database, although gib's bidding language is also being hanged from StandardAmeri an (a fairly natural system) to a variant of an arti ial system alled Mos ito de-veloped in Australia.23 Mos ito has very sharply de ned meanings, making it ideal for use21. Mahmood and Rosenberg have won, among other titles, the 1995 Cap Volma World Top InvitationalTournament. As remarked earlier, Rosenberg would also go on after the GIB mat h to win the ParCompetition in whi h GIB nished 12th.22. http://www.okbridge. om23. Gib's version of Mos ito is alled Mos ito Byte. 353\nGinsbergby a omputer program, and is an \\a tion\" system, working hard to make the opponents'bidding as di\u00c6 ult as possible.With regard to defensive ardplay, the key elements of high level defense are to make ithard for partner to make a mistake while making it easy for de larer to do so. Providing gibwith these abilities will involve an extra level of re ursion in the ardplay, as ea h elementof the Monte Carlo sample must now be onsidered from other players' points of view, asthey generate and then analyze their own samples. These ideas have been implemented but urrently lead to small performan e degradations (approximately 0.05 imps/deal) be ausethe omputational ost of the re ursive analyses require redu ing the size of the MonteCarlo sample substantially. As pro essor speeds in rease, it is reasonable to expe t theseideas to bear signi ant fruit.In 1997, Martel, a omputer s ientist himself, suggested that he expe ted gib to be thebest bridge player in the world in approximately 2003.y The work appears to be roughly ons hedule.8.3 Other gamesI have left essentially untou hed the question of to what extent the basi te hniques we havedis ussed ould be applied to games of imperfe t information other than bridge.The ideas that we have presented are likely to be the most appli able in games wherethe perfe t information variant is tra table but omputationally hallenging, and the as-sumption that one's opponents are playing with perfe t information is a reasonable one.This suggests that games like hearts and other tri k-taking games will be amenable to ourte hniques, while games like poker (where it is essential to realize and exploit the fa t thatthe opponents also have imperfe t information) are likely to need other approa hes.A knowledgmentsA great many people have ontributed to the gib proje t over the years. In the te hni al ommunity, I would like to thank Jonathan S hae er, Ri h Korf, David Etherington, BartMassey and the other members of irl. In the bridge ommunity, I have re eived invaluableassistan e from Chip Martel, Rod Ludwig, Zia Mahmood, Andrew Robson, Alan Ja ray,Hans Kuijf, Fred Gitelman, Bob Hamman, Eri Rodwell, Je Goldsmith, Thomas Andrewsand the members of the re .games.bridge ommunity. The work itself has been supportedby Just Write, In ., by DARPA/Rome Labs under ontra ts F30602-95-1-0023 and F30602-97-1-0294, and by the Boeing Company under ontra t AHQ569. To everyone who has ontributed, whether named above or not, I owe my deepest appre iation.Appendix A. A summary of the rules of bridgeWe give here a very brief summary of the rules of bridge. Readers wanting a more ompletedes ription are referred to any of the many ex ellent texts available (Sheinwold, 1996).Bridge is a ard game for four players, who are split into two pairs. Members of a singlepair sit opposite one another, so that North-South form one pair and East-West the other.354\nGIB: Imperfe t information in a omputationally hallenging gameThe de k is distributed evenly among the players, so that ea h deal involves giving ea hplayer a hand of 13 ards. The game then pro eeds through a bidding and a playing phase.The playing phase onsists of 13 tri ks, with ea h player ontributing one ard to ea htri k in a lo kwise fashion. The player who plays rst to any tri k is said to lead to thattri k. The highest ard of the suit led wins the tri k (A e is high and deu e low), unless atrump is played, in whi h ase the highest trump wins the tri k. The person who leads to atri k is free to lead any ard he wishes; subsequent players must play a ard of the suit ledif they have one, and an play any ard they hoose if they don't. The winner of one tri kleads to the next; the person who leads to the rst tri k (the opening leader) is determinedduring the bidding phase of the game.The obje t of the ard play phase is always for your partnership to take as many tri ksas possible; there is no advantage to one partner's taking a tri k over another, and the orderin whi h the tri ks are taken is irrelevant. After the opening leader plays the rst ard tothe rst tri k, the player to his left pla es his ards fa e up on the table so that all of theother players an see them. This player is alled the dummy, and when it is dummy's turnto play, dummy's partner (who an see the partnership's ombined assets) sele ts the ardto be played. Dummy's partner is alled the de larer and the members of the other pairare alled the defenders.The purpose of the bidding phase is to identify trumps and the de larer, and also the ontra t, whi h will be des ribed shortly. The opening leader is identi ed as well, and isthe player to the de larer's left.During the bidding phase, various ontra ts are proposed. The dealer has the rstopportunity to propose a ontra t and subsequent opportunities are given to ea h playerin a lo kwise dire tion. Ea h player has many opportunities to suggest a ontra t duringthis phase of the game, whi h is alled the au tion. Ea h partnership is required to explainthe meanings of their a tions during the au tion to the other side, if requested.Ea h ontra t suggests a parti ular trump suit (or perhaps that there not be a trumpsuit at all). Ea h player suggesting a ontra t is ommitting his side to winning some par-ti ular number of the 13 available tri ks. The minimum ommitment is 7 tri ks, so thereare 35 possible ontra ts (ea h of 4 possible trumps, or no trumps, and seven possible om-mitments, from seven to thirteen tri ks). These 35 ontra ts are ordered, whi h guaranteesthat the bidding phase will eventually terminate.After the bidding phase is omplete, the side that suggested the nal ontra t is thede laring side. Of the two members of the de laring side, the one who rst suggested theeventual trump suit (or no trumps) is the de larer. Play begins with the player to thede larer's left leading to the rst tri k.After the hand is omplete, there are two possible out omes. If the de laring side tookat least as many tri ks as it ommitted to taking, the de laring side re eives a positives ore and the defending side an equal but negative s ore. There are substantial bonusesawarded for ommitting to taking parti ular numbers of tri ks; in general, the larger the ommitment, the larger the bonus. There are small bonuses awarded for winning tri ksabove and beyond the ommitment.If the de laring side failed to honor its ommitment, it re eives a negative s ore andthe defenders re eive an equal but positive s ore. The overall s ore in this ase (where the355\nGinsbergde larer \\goes down\") is generally smaller than the overall s ore in the ase where de larer\\makes it\" (i.e., honors his ommitment).Appendix B. A new ending dis overed by GIBThis deal o urred during a short imp mat h between gib and Bridge Baron. 9 6~ Q J 8 5} A Q 3| K J 10 8 K Q J 8 7 5 4 3~ 9 4 3 ~ A 7 2} 7 } J 10 6 2| 6 4 2 | A Q 7 3 A 10 2~ K 10 6} K 9 8 5 4| 9 5With South (gib) dealing at unfavorable vulnerability, the au tion went P{2 {X{P{3NT{all pass. (P is pass and X is double.) The opening lead was the K, du ked by gib, andBridge Baron now swit hed to a small heart. East won the a e and returned to spades, gibwinning.Gib ashed all the hearts, pit hing a small lub from its hand. It then tested thediamonds, learning of the bad break and winning the third diamond in hand. It then ledthe }9 in the following position: |~ |} || K J 10 8 Q |~ | ~ |} | } J| ? ? ? | A ? ? 10~ |} 9 8| 9When gib pit hed the ten of lubs from dummy (it had been aiming for this ending allalong), the defenders were helpless to take more than two tri ks independent of the lo ationof the lub queen. At the other table, Bridge Baron let gib play in 2 making exa tly, andgib pi ked up 12 imps. 356\nGIB: Imperfe t information in a omputationally hallenging gameReferen esAdelson-Velskiy, G., Arlazarov, V., & Donskoy, M. (1975). Some methods of ontrolling thetree sear h in hess programs. Arti ial Intelligen e, 6, 361{371.Bayardo, R. J., & Miranker, D. P. (1996). A omplexity analysis of spa e-bounded learningalgorithms for the onstraint satisfa tion problem. In Pro eedings of the ThirteenthNational Conferen e on Arti ial Intelligen e, pp. 298{304.Billings, D., Papp, D., S hae er, J., & Szafron, D. (1998). Opponent modeling in poker. InPro eedings of the Fifteenth National Conferen e on Arti ial Intelligen e, pp. 493{499.Bla kwood, E. (1979). Play of the Hand with Bla kwood. Bobbs-Merrill.Eskes, O. (1997). GIB: Sensational breakthrough in bridge software. IMP, 8 (2).Frank, I. (1998). Sear h and Planning under In omplete Information: A Study Using BridgeCard Play. Springer-Verlag, Berlin.Frank, I., & Basin, D. (1998). Sear h in games with in omplete information: A ase studyusing bridge ard play. Arti ial Intelligen e, 100, 87{123.Frank, I., Basin, D., & Bundy, A. (2000). Combining knowledge and sear h to solve single-suit bridge. In Pro eedings of the Sixteenth National Conferen e on Arti ial Intelli-gen e, pp. 195{200.Frank, I., Basin, D., & Matsubara, H. (1998). Finding optimal strategies for imperfe tinformation games. In Pro eedings of the Fifteenth National Conferen e on Arti ialIntelligen e, pp. 500{507.Ginsberg, M. L. (1993). Dynami ba ktra king. Journal of Arti ial Intelligen e Resear h,1, 25{46.Ginsberg, M. L., & Harvey, W. D. (1992). Iterative broadening. Arti ial Intelligen e, 55,367{383.Ginsberg, M. L., & Ja ray, A. (2001). Alpha-beta pruning under partial orders. In Gamesof No Chan e II. To appear.Gr atzer, G. (1978). General Latti e Theory. Birkh auser Verlag, Basel.Greenblatt, R., Eastlake, D., & Cro ker, S. (1967). The greenblatt hess program. In FallJoint Computer Conferen e 31, pp. 801{810.Joslin, D. E., & Clements, D. P. (1999). Squeaky wheel optimization. Journal of Arti ialIntelligen e Resear h, 10, 353{373.Koller, D., & Pfe er, A. (1995). Generating and solving imperfe t information games. InPro eedings of the Fourteenth International Joint Conferen e on Arti ial Intelligen e,pp. 1185{1192.Levy, D. N. (1989). The million pound bridge program. In Levy, D., & Beal, D. (Eds.),Heuristi Programming in Arti ial Intelligen e, Asilomar, CA. Ellis Horwood.Lind-Nielsen, J. (2000). BuDDy: Binary De ision Diagram pa kage. Te h. rep., Depart-ment of Information Te hnology, Te hni al University of Denmark, DK-2800 Lyngby,Denmark. 357\nGinsbergLindel of, T. (1983). COBRA: The Computer-Designed Bidding System. Gollan z, London.Marsland, T. A. (1986). A review of game-tree pruning. J. Intl. Computer Chess Assn.,9 (1), 3{19.M Allester, D. A. (1988). Conspira y numbers for min-max sear hing. Arti ial Intelligen e,35, 287{310.Pearl, J. (1980). Asymptoti properties of minimax trees and game-sear hing pro edures.Arti ial Intelligen e, 14 (2), 113{138.Pearl, J. (1982). A solution for the bran hing fa tor of the alpha-beta pruning algorithmand its optimality. Comm. ACM, 25 (8), 559{564.Plaat, A., S hae er, J., Pijls, W., & de Bruin, A. (1996). Exploiting graph properties of gametrees. In Pro eedings of the Thirteenth National Conferen e on Arti ial Intelligen e,pp. 234{239.S hae er, J. (1997). One Jump Ahead: Challenging Human Suprema y in Che kers.Springer-Verlag, New York.Sheinwold, A. (1996). Five Weeks to Winning Bridge. Po ket Books.Smith, S. J., Nau, D. S., & Throop, T. (1996). Total-order multi-agent task-network plan-ning for ontra t bridge. In Pro eedings of the Thirteenth National Conferen e onArti ial Intelligen e, Stanford, California.Stallman, R. M., & Sussman, G. J. (1977). Forward reasoning and dependen y-dire tedba ktra king in a system for omputer-aided ir uit analysis. Arti ial Intelligen e,9, 135{196.Sterling, L., & Nygate, Y. (1990). PYTHON: An expert squeezer. J. Logi Programming,8, 21{40.Wilkins, D. E. (1980). Using patterns and plans in hess. Arti ial Intelligen e, 14, 165{203.\n358"}], "references": [], "referenceMentions": [], "year": 2011, "abstractText": null, "creator": "dvips(k) 5.86d Copyright 1999 Radical Eye Software"}}}