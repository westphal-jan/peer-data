{"id": "1106.0680", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jun-2011", "title": "Learning Geometrically-Constrained Hidden Markov Models for Robot Navigation: Bridging the Topological-Geometrical Gap", "abstract": "Hidden Markov models (HMMs) and partially observable Markov decision-making processes (POMDPs) are useful tools for modeling dynamic systems, and are particularly useful for mapping the topology of environments such as road networks and office buildings that are typical of robot navigation and planning. The work presented here describes a formal framework for incorporating readily available odometric information and geometric constraints into both the models and the algorithm that learns them. By using this information, HMMs / POMDPs can be learned to generate better solutions and require fewer iterations, while being robust in the face of data reduction. Experimental results obtained from both simulated and real robot data demonstrate the effectiveness of the approach.", "histories": [["v1", "Fri, 3 Jun 2011 14:56:46 GMT  (330kb)", "http://arxiv.org/abs/1106.0680v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.RO", "authors": ["l p kaelbling", "h shatkay"], "accepted": false, "id": "1106.0680"}, "pdf": {"name": "1106.0680.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Hagit Shatkay", "Leslie Pack Kaelbling"], "emails": ["hagit.shatkay@celera.com", "lpk@ai.mit.edu"], "sections": [{"heading": null, "text": "Journal of Arti cial Intelligence Research 16 (2002) 167-207 Submitted 3/01; published 3/02Learning Geometrically-Constrained Hidden Markov Models forRobot Navigation: Bridging the Topological-Geometrical GapHagit Shatkay hagit.shatkay@celera.comInformatics Research Group,Celera Genomics, Rockville, MD 20850Leslie Pack Kaelbling lpk@ai.mit.eduArti cial Intelligence LaboratoryMassachusetts Institute of Technology, Cambridge, MA 02139You will come to a place where the streets are not marked.Some windows are lighted but mostly they're darked.A place you could sprain both your elbow and chin!Do you dare to stay out? Do you dare to go in?...And if you go in, should you turn left or right...or right-and-three-quarters? or, maybe, not quite?...Simple it's not, I'm afraid you will nd,for a mind-maker-upper to make up his mind.Oh, the Places You'll Go, Dr. Seuss.AbstractHidden Markov models (hmms) and partially observable Markov decision processes(pomdps) provide useful tools for modeling dynamical systems. They are particularlyuseful for representing the topology of environments such as road networks and o cebuildings, which are typical for robot navigation and planning. The work presentedhere describes a formal framework for incorporating readily available odometric infor-mation and geometrical constraints into both the models and the algorithm that learnsthem. By taking advantage of such information, learning hmms/pomdps can be madeto generate better solutions and require fewer iterations, while being robust in the faceof data reduction. Experimental results, obtained from both simulated and real robotdata, demonstrate the e ectiveness of the approach.1 IntroductionThis work is concerned with robots that need to perform tasks in structured environments.A robot moving in the environment su ers from two main limitations: its noisy sensors preventit from con dently knowing where it is, while its noisy e ectors prevent it from knowing withcertainty where its actions will take it. We concentrate here on structured environments, whichcan in turn be characterized by two main properties: such environments consist of vast un-eventful and uninteresting areas, and are interspersed with relatively few interesting positions orsituations. Consider for instance a robot delivering a bagel in an o ce building. The interestingsituations are the doors and the intersections in the building hallways, as well as the variousc 2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.\nShatkay & Kaelblingpositions where the bagel might be with respect to the robot's arm (e.g., the robot is holdingthe bagel, puts it down, etc.) Most other aspects of the environment, such as the desk positionsin the o ces, are inconsequential for the bagel delivery task.A natural way to represent the combination of such an environment and the robot's interactionswith it, is as a probabilistic automaton, in which states represent interesting situations, andedges between states represent the actions leading from one situation to another. Probabilitydistributions over the transitions and over the possible observations the robot may perceive ateach situation model the robot's noisy e ectors and sensors, respectively.Such models are formally known as pomdp (partially observable Markov decision process) mod-els, and have been proven useful for robot planning and acting under the inherent world un-certainty (Simmons & Koenig, 1995; Nourbakhsh, Powers, & Birch eld, 1995; Cassandra, Kael-bling, & Kurien, 1996).Despite much work on using such models, the task of learning them directly and automaticallyfrom the data has not been widely addressed. Research concerning this immediate topic to dateconsists mostly of the work done by Simmons and Koenig (1996b). The assumption underlyingtheir work was that a human provides a rather accurate topological model of the states andtheir connections, and the exact probability distributions are then learned on top of this model,using a version of the Baum-Welch algorithm (Rabiner, 1989). Another interesting approach tothe acquisition of topological models is that of Thrun and B ucken (1996a,1996b; Thrun, 1999),who focused on extracting deterministic topological maps from previously acquired geometrical-grid-based maps, where the latter were learned directly from the data. Further discussion ofrelated research on both the geometrical and the topological approaches, in their probabilisticand deterministic versions, is given in the next section.The work reported here is the rst successful attempt we are aware of to learn purely probabilistic-topological models, directly and completely from recorded data, without using previous human-provided or grid-based models. It is based on using weak geometric information, recorded bythe robot, to help learn the topology of the environment, and represent it as a probabilisticmodel. Therefore, it directly bridges the historically perceived gap between topological andgeometrical information, and addresses the claim presented in Thrun's work (1999) that themain shortcoming of the topological approach is its failure to utilize the inherent geometry ofthe learnt environment.Most robots are equipped with wheel encoders that enable an odometer to record the change inthe robot's position as it moves through the environment. This data is typically very noisy andinaccurate. The oors in the environment are rarely smooth, the wheels of the robot are notalways aligned and neither are the motors, the mechanics is imperfect, resulting in slippage anddrift. All these e ects accumulate, and if we were to mark the initial position of the robot, andtry to estimate its current position based on summing a long sequence of odometric recordings,the resulting estimate will be incorrect. That is, the raw recorded odometric information isnot an e ective tool, in and of itself, for determining the absolute location of the robot in theenvironment.While our approach is not aimed at determining absolute locations, the idea underlying it is thatthis weak odometric information, despite its noise and inaccuracy, still provides geometrical cuesthat can help to distinguish between di erent states, as well as to identify revisitation of thesame state. Hence, such information enhances the ability to learn topological models. However,168\nLearning Geometrically-Constrained HMMsthe use of geometrical information requires careful treatment of geometrical constraints anddirectional data. We demonstrate how the existing models and algorithms can be extended totake advantage of the noisy odometric data and the geometrical constraints. The geometricalinformation is directly incorporated into the probabilistic topological framework, producing asigni cant improvement over the standard Baum-Welch algorithm, without the need for human-provided model.The rest of this paper is organized as follows: Section 2 provides a survey of previous work inthe area of learning maps for robot navigation, and brie y refers to earlier work on learningautomata; Section 3 presents the formal framework for this work; Section 4 presents the mainaspects of our iterative learning algorithm, while Section 5 describes the strategies for selectingthe initial point from which the iterative process begins; Section 6 presents experimental resultsobtained from both simulated and real robot data in traditionally hard-to-learn environments.The experiments demonstrate that our algorithm indeed converges to better models with feweriterations than the standard Baum-Welch method, and is robust in the face of data reduction.2 Approaches to Learning Maps and ModelsThe work presented here lies in the intersection between the theoretical area of learning compu-tational models|in particular, learning automata from data sequences|and the applied area ofmap acquisition for robot navigation. We concentrate here on surveying the work in the latterarea, pointing out the distinction between our approach and its predecessors. We brie y reviewsome results from automata and computational learning theory. A more comprehensive reviewof theoretical results is given by Shatkay (1999).2.1 Modeling Environments for Robot NavigationIn the context of maps and models for robot navigation, a distinction is usually made between twoprincipal kinds of maps: geometric and topological. Geometric maps describe the environmentas a collection of objects or occupied positions in space, and the geometric relationships amongthem. The topological framework is less concerned with the geometrical positions, and modelsthe world as a collection of states and their connectivity, that is, which states are reachable fromeach of the other states and what actions lead from one state to the next.We draw an additional distinction, between world-centric1 maps that provide an \\objective\"description of the environment independent of the agent using the map, and robot-centric modelswhich capture the interaction of a particular \\subjective\" agent with the environment. Whenlearning a map, the agent needs to take into account its own noisy sensors and actuators and tryto obtain an objectively correct map that other agents could use as well. Similarly, other agentsusing the map need to compensate for their own limitations in order to assess their positionaccording to the map. When learning a model that captures interaction, the agent acquiring themodel is the one who is also using it. Hence, the noisy sensors and actuators speci c to the agentare re ected in the model. A di erent model is likely to be needed by di erent agents. Mostof the related work described below, especially within the geometrical framework, is centeredaround learning objective maps of the world rather than agent-speci c models. We shall pointout in this survey the work that is concerned with the latter kind of models.Our work focuses on acquiring purely topological models, and is less concerned with learninggeometrical relationships between locations or objects, or objective maps, although geometrical1. We thank Sebastian Thrun for the terminology. 169\nShatkay & Kaelblingrelationships do serve as an aid in our acquisition process. The concept of a state used in thistopological framework is more general than the concept of a geometrical location, since a statecan include information such as the battery level, the arm position etc. Such information, whichis of great importance for planning, is non-geometrical in nature and therefore cannot be readilycaptured in a purely geometrical framework. The following sections provide a survey of workdone both within the geometrical framework and within the topological framework, as well ascombinations of the two approaches.2.2 Geometric MapsGeometric maps provide a description of the environment in terms of the objects placed in itand their positions. For example, grid-based maps are an instance of the geometric approach.In a grid-based map, the environment is modeled as a grid (an array), where each position inthe grid can be either vacant or occupied by some object (binary values placed in the array).This approach can be further re ned to re ect uncertainty about the world, by having grid cellscontain occupancy probabilities rather than just binary values. A lot of work has been done onlearning such grid-based maps for robot navigation through the use of sonar readings and theirinterpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes,1989; Asada, 1991).An underlying assumption when learning such maps is that the robot can tell (or nd out)where it is on the grid when it obtains a sonar reading indicating an object, and therefore canplace the object correctly on the grid. A similar localization assumption, requiring the robotto identify its geometrical location, underlies other geometric mapping techniques by Leonardet al. (1991), Smith et al. (1991), Thrun et al. (1998b) and Dissanayake et al. (2001), evenwhen an explicit grid is not part of the model. Explicit localization can be hard to satisfy.Leonard et al. (1991) and Smith et al. (1991) address this issue through the use of geometricalbeacons to estimate the location of the robot. In what is known as the Kalman lter method, aGaussian probability distribution is used to model the robot's possible current location, basedon observations collected up to the current point, (without allowing the re nement of previousposition estimates based on later observations). Research in this area has recently been extendedin two directions: Leonard and Feder (2000) partition the task of learning one large map intolearning multiple smaller map-sections, thus addressing the issue of computational e ciency.Dissanayake et al. (2001) conduct a theoretical study of the approach and show its convergenceproperties. The latter may lead to computational e ciency by identifying the cases for which asteady-state solution can be readily obtained, accordingly bounding the number of steps requiredby the algorithms to reach a useful solution in these cases.Work by Thrun et al. (1998a) uses a similar probabilistic approach for obtaining grid-based maps.This work is re ned (Thrun et al., 1998b) to rst learn the location of signi cant landmarks inthe environment and then ll in the details of the complete geometrical grid, based on laser rangescans. The latter work extends the approach of Smith et al. , by using observations obtainedboth before and after a location has been visited, in order to derive a probability distributionover possible locations. To achieve this, the authors use a forward-backward procedure similarto the one used in the Baum-Welch algorithm (Rabiner, 1989), in order to determine possiblelocations from observed data. The approach resembles ours both in the use of the forward-backward estimation procedure, and in its probabilistic basis, aiming at obtaining a maximumlikelihood map of the environment. It still signi cantly di ers from ours both in its initialassumptions and in its nal results. The data assumed to be provided to the learner includes170\nLearning Geometrically-Constrained HMMsboth the motion model and the perceptual model of the robot. These consist of transition andobservation probabilities within the grid. Both of these components are learnt by our algorithm,although not in a grid context but in a coarser-grained, topological framework. The end result oftheir algorithm is a probabilistic grid-based map, while ours is a probabilistic topological model,as further explained in the next section.In addition to being concerned only with locations, rather than with the richer notion of state,a fundamental drawback of geometrical maps is their ne granularity and high accuracy. Geo-metrical maps, particularly grid-based ones, tend to give an accurate and detailed picture of theenvironment. In cases where it is necessary for a robot to know its exact location in terms ofmetric coordinates, metric maps are indeed the best choice. However, many planning tasks donot require such ne granularity or accurate measurements, and are better facilitated through amore abstract representation of the world. For example, if a robot needs to deliver a bagel fromo ce a to o ce b, all it needs to have is a map depicting the relative location of a with respect tob, the passageways between the two o ces, and perhaps a few other landmarks to help it orientitself if it gets lost. If it has a reasonably well-operating low-level obstacle avoidance mechanismto help it bypass ower pots and chairs that it might encounter on its way, such objects donot need to be part of the environment map. Just as a driver traveling between cities needs toknow neither his longitude and latitude coordinates on the globe, nor the location of the speci chouses along the way, the robot does not need to know its exact location within the buildingnor the exact location of various items in the environment, in order to get from one point toanother. Hence, the e ort of obtaining such detailed maps is not usually justi ed. In additionthe maps can be very large, which makes planning|even though planning is polynomial in thesize of the map|ine cient.2.3 Topological Maps and ModelsAn alternative to the detailed geometric maps are the more abstract topological maps. Suchmaps specify the topology of important landmarks and situations (states), and routes or tran-sitions (arcs) between them. They are concerned less with the physical location of landmarks,and more with topological relationships between situations. Typically, they are less complex andsupport much more e cient planning than metric maps. Topological maps are built on lower-level abstractions that allow the robot to move along arcs (perhaps by wall- or road-following),to recognize properties of locations, and to distinguish signi cant locations as states; they are exible in allowing a more general notion of state, possibly including information about thenon-geometrical aspects of the robot's situation.There are two typical strategies for deriving topological maps: one is to learn the topologicalmap directly; the other is to rst learn a geometric map, then to derive a topological modelfrom it through some process of analysis.A nice example of the second approach is provided by Thrun and B ucken (1996a, 1996b; Thrun,1999), who use occupancy-grid techniques to build the initial map. This strategy is appropriatewhen the primary cues for decomposition and abstraction of the map are geometric. However,in many cases, the nodes of a topological map are de ned in terms of other sensory data (e.g.,labels on a door or whether or not the robot is holding a bagel). Learning a geometric map rstalso relies on the odometric abilities of a robot; if they are weak and the space is large, it is verydi cult to derive a consistent map. 171\nShatkay & KaelblingIn contrast, our work concentrates on learning a topological model directly, assuming that ab-straction of the robot's perception and action abilities has already been done. Such abstractionswere manually encoded into the lower level of our robot navigational software, as described inSection 6. Work by Pierce and Kuipers (1997) discusses an automatic method for extractingabstract states and features from raw perceptual information.Kuipers and Byun (1991) provide a strategy for learning deterministic topological maps. It workswell in domains in which most of the noise in the robot's perception and action is abstractedaway, learning from single visits to nodes and traversals of arcs. A strong underlying assumptionfor these strategies, when building the map, is that the current state can be reliably identi edbased on local information, or based on distance traversed from the previous well-identi edstate. These methods are unable to handle situations in which long sequences of actions andobservations are necessary to disambiguate the robot's state.Mataric (1990) provides an alternative approach for learning deterministic topological maps,represented as distributed graphs. The learning process again relies on the assumption that thecurrent state can be distinguished from all other states based on local information which includescompass and sonar readings. Uncertainty is not modeled through probability distributions.Instead, matching of current readings to already existing states is not required to be exact, andthresholds of tolerated error are set empirically. Another di erence from the work presentedhere, is that while we learn the complete probabilistic topology of the environment, in Mataric'swork the overall topology of the graph is assumed in advance to be a linear list, and additionaledges are added during the learning process. No probability distribution is associated with theedges, and a mechanism for choosing which edge to take is determined as part of the goal seekingprocess, and is not part of the model itself.Engelson and McDermott (1992) learn \\diktiometric\" maps (topological maps with metric rela-tions between nodes) from experience. The uncertainty model they use is interval-based ratherthan probabilistic, and the learned representation is deterministic. Ad hoc routines handle prob-lems resulting from failures of the uncertainty representation.We prefer to learn a combined model of the world and the robot's interaction with the world;this allows robust planning that takes into account likelihood of error in sensing and action. Thework most closely related to ours is by Koenig and Simmons (1996b, 1996a), who learn pomdpmodels (stochastic topological models) of a robot hallway environment. They also recognizethe di culty of learning a good model without initial information; they solve the problem byusing a human-provided topological map, together with further constraints on the structureof the model. A modi ed version of the Baum-Welch algorithm learns the parameters of themodel. They also developed an incremental version of Baum-Welch that can be used on-line.Their models contain very weak metric information, representing hallways as chains of one-metersegments and allowing the learning algorithm to select the most probable chain length. Thismethod is e ective, but results in large models with size proportional to the hallways' length,and strongly depends on the quality of the human-provided initial model.2.4 Learning Automata from DataInformally speaking, an automaton consists of a set of states and a set of transitions that leadfrom one state to another. In the context of this work, the automaton states correspond to thestates of the modeled environments, and the transitions, to the state changes due to actionsperformed in the environment. Each transition of the automaton is tagged by a symbol from an172\nLearning Geometrically-Constrained HMMsinput alphabet, , corresponding to the action or the input to the system that caused the statetransition. Classical automata theory (e.g., Hopcroft & Ullman, 1979) distinguishes betweendeterministic and non-deterministic automata. If, for each alphabet symbol , there is a singleedge tagged by it, going out of each state, the automaton is deterministic. Otherwise, thetransition between states is not uniquely determined by the input symbol and the automaton isnon-deterministic. If we augment each transition edge of a non-deterministic automaton with aprobability of taking it given a certain input, , the resulting automaton is called probabilistic.The basic problem of learning nite deterministic automata from given data can be roughlydescribed as follows: Given a set of positive and a set of negative example strings, S and Trespectively, over alphabet , and a xed number of states k, construct a minimal deterministic nite automaton with no more than k states that accepts S and does not accept T . This problemhas been shown to be np-complete (Gold, 1978). Despite the hardness, positive results havebeen shown possible under various special settings. Angluin (1987) showed that if an oracle cananswer membership queries and provide counterexamples to conjectures about the automaton,there is a polynomial time learning algorithm from positive and negative examples. Rivestand Schapire (1987, 1989), provide several e ective methods, that under various settings, learndeterministic automata that are correct with high probability. While the above work deals withlearning from noise-free data, Basye, Dean and Kaelbling (1995) presented several algorithmsthat, with high probability, learn input-output deterministic automata, when the data observedby the learner is corrupted by various forms of noise.In all these cases, the learned automaton is deterministic rather than probabilistic. The basiclearning problem in the probabilistic context is to nd an automaton that assigns the samedistribution as the true one to data sequences, using training data S, that was generated bythe true automaton. Another form of a learning problem is that of nding a probabilisticautomaton that assigns the maximum likelihood to the training data S; that is, an automatonthat maximizes Pr(Sj ).Abe and Warmuth (1992) show that nding a probabilistic automaton with 2 states, even whena small error with respect to the true model is allowed with some probability (the probablyapproximately correct, or PAC, learning model), cannot be done in polynomial time with poly-nomial number of examples, unless np = rp. From their work arises the broadly acceptedconjecture, which has not yet been proven, that learning hidden Markov Models is hard evenin the pac sense. There are two ways to address this hardness: one is to restrict the class ofprobabilistic models learned, while the other is to learn unrestricted hidden Markov models withgood practical results but with no pac guarantees on the quality of the result.Work by Ron et al. (1994, 1995, 1998) pursues the rst approach, learning restricted classes ofautomata, namely, acyclic probabilistic nite automata, and probabilistic nite su x automata.Both classes are useful for various applications related to natural language processing, and canbe learned in polynomial time within the pac framework.The second approach, which is the one predominantly taken in this work, is to learn a model thatis a member of the complete unrestricted class of hidden Markov models. Only weak guaranteesexist about the goodness of the model, but the learning procedure may be directed to obtainpractically good results. This approach is based on guessing an automaton (model), and usingan iterative procedure to make the automaton t better to the training data. One algorithmcommonly used for this purpose is the Baum-Welch algorithm (Baum, Petrie, Soules, & Weiss,1970), which is presented in detail by Rabiner (1989). The iterative updates of the model are173\nShatkay & Kaelblingbased on gathering su cient statistics from the data given the current automaton, and theupdate procedure is guaranteed to converge to a model that locally maximizes the likelihoodfunction Pr(datajmodel). Since the maximum is local, the model might not be close enoughto the true automaton by which the data was generated, and a challenging problem is to ndways to force the algorithm into converging to higher-likelihood maxima, or at least to makeit converge faster, facilitating multiple guesses of initial models, thus raising the probabilityof converging to higher-likelihood maxima. Such an approach is the one taken in the workpresented here.We assume, throughout this paper, that the number of states in the model we are learning isknown. This is not a very strong assumption since there are methods for learning the number ofstates. Regularization methods for deciding on the number of states and other model parameters,are discussed, for instance, in Vapnik's book (1995). We do not address this issue here.The rest of the work describes our approach to learning topological models. We use noisyodometric information that is readily available in most robots. This geometrical information istypically not used by topological mapping methods. We demonstrate how a topological modeland the algorithm used to learn it can be extended to directly incorporate this weak odometricinformation. We further show that by doing so, we can avoid the use of human-provided a priorimodels and still learn stochastic environment models e ciently and e ectively.3 Models and AssumptionsThis section describes the formal framework for our work. It starts by introducing the classichiddenMarkov model. The model is then extended to accommodate noisy odometric informationin its most na ve form, ignoring information about the robot's heading and orientation, and lateradapted to accommodate heading information.We concentrate here on describing models and algorithms for learning hmms, rather thanpomdps. This means that the robot has no decisions to make regarding its next action atevery state; only one action can be executed at each state. In our experiments, a human opera-tor gave the action command associated with each state to the robot when gathering the data.Note that the action is not necessarily the same one for every state, e.g., the robot is told toalways turn right in state 1 and move forward at state 2. However, at each state only one ac-tion can be taken. The extension to complete pomdps, which we have implemented, is throughlearning an hmm for each of the possible actions; it is straightforward although notationallymore cumbersome, thus we limit the discussion here to hmms.3.1 HMMs { The BasicsA hidden Markov model consists of states, transitions, observations and probabilistic behavior,and is formally de ned as a tuple = hS;O;A;B; i, satisfying the following conditions: S = fs0; : : : ; sN 1g is a nite set of N states. O = fo0; : : : ; oM 1g is a nite set of M possible observation values.174\nLearning Geometrically-Constrained HMMs A is a stochastic transition matrix, with Ai;j = Pr(qt+1 = sjjqt = si), where 0 i; j N 1.qt is the state at time t. For every state si, N 1Xj=0Ai;j = 1.Ai;j holds the transition probability from state si to state sj. B is a stochastic observation matrix, with Bj;k=Pr(vt=okjqt=sj), where 0 j N 1;0 k M 1. vt is the observation recorded at time t. For every state sj , M 1Xk=0Bj;k = 1.Bj;k holds the probability of observing ok while being at state sj. is a stochastic initial distribution vector, with i = Pr(q0 = si), 0 i N 1. N 1Xi=0 i = 1. i holds the probability of being in state si at time 0, when starting to record observations.This model corresponds to a world whose actual state at any given time t, qt 2 S, is hiddenand not directly observable, but some observable aspects of the state, vt 2 O, are detected andrecorded when the state is visited at time t. An agent moves from one hidden state to thenext according to the probability distribution encoded in matrix A. The observed informationin each state is governed by the probability matrix B. Although our work is concerned withdiscrete observations, the extension to continuous observations is straightforward and has beenwell addressed in work on hidden Markov models (Liporace, 1982; Juang, 1985).Simply stated, the problem of learning an hmm is that of \\reverse engineering\" a hidden Markovmodel for a stochastic system from the sampled data, generated by the system. We formalizethe learning task in Section 4.1. The next section extends hmms to account for geometricinformation.3.2 Adding Odometry to Hidden Markov ModelsThe world is composed of a nite set of states. There is a fundamental distinction in ourframework between the term state and the term location. The state of the robot does notdirectly correspond to its location. A state may include other information, such as the robot'sbattery level or its orientation in that location. A robot standing in the entrance to o ce 101facing right is in a di erent state than a robot standing in the same place facing left; similarly,a robot standing with a bagel in its arm is in a di erent state from the same robot being in thesame position without the bagel.The dynamics of the world are described by state-transition distributions that specify the prob-ability of making transitions from one state to the next as a result of a certain action. Thereis a nite set of observations that can be perceived in each state; the relative frequency of eachobservation is described by a probability distribution and depends only on the current state.In our model, observations are multi-dimensional; an observation is a vector of values, eachchosen from a nite domain. That is, we factorize the observation associated with each stateinto several components. For instance, as demonstrated in Section 6.1, we view the observationrecorded by the robot when standing in an o ce environment as consisting of three components,corresponding to the three cardinal directions: front, left and right. In this example, the obser-vation vector is thus 3-dimensional. It is assumed that the vector's components are conditionallyindependent, given the state. 175\nShatkay & KaelblingIn addition to the above components, each state is assumed to be associated with a position in ametric space. Whenever a state transition is made, the robot records an odometry vector, whichestimates the position of the current state relative to the previous one. For the time being we as-sume that the odometry vector consists of readings along the x and y coordinates of a global coor-dinate system, and that these readings are corrupted with independent normal noise. The latterindependence assumption is not a strict one, and can be relaxed by introducing a complete co-variance matrix, although we have not done this in this work. In Section 3.3 we extend the odom-etry vector to include information about the heading of the robot, and drop the global coordinateframework.Note that the odometric relationship characterizes a transition rather than a state and, asdescribed below, receives a di erent treatment than the observations that are associated withstates.There are two important assumptions underlying our treatment of odometric relations betweenstates: First, that there is an inherent \\true\" odometric relation between the position of everytwo states in the world; second, that when the robot moves from one state to the next, thereis a normal, 0-mean noise around the correct expected odometric reading along each odometricdimension. This noise re ects two kinds of odometric error sources:{ The lack of precision in the discretization of the real world into states (e.g. there is a ratherlarge area in which the robot can stand which can be regarded as \\the doorway of the AIlab\").{ The lack of precision of the odometric measures recorded by the robot, due to slippage,friction, disalignment of the wheels, imprecision of the measuring instruments, etc.To formally introduce odometric information into the hidden Markov model framework, wede ne an augmented hidden Markov model as a tuple = hS;O;A;B;R; i, where: S = fs0; : : : ; sN 1g is a nite set of N states. O = Qli=1Oi is a nite set of observation vectors of length l. The ith element of anobservation vector is chosen from the nite set Oi. A is a stochastic transition matrix, with Ai;j = Pr(qt+1 = sjjqt = si), 0 i; j N 1.qt is the state at time t. For every state si, N 1Xj=0Ai;j = 1.Ai;j holds the transition probability from state si to state sj . B is an array of l stochastic observation matrices, with Bi;j;k = Pr(Vt[i] = okjqt = sj);1 i l; 0 j N 1; ok 2 Oi; Vt is the observation vector at time t; Vt[i] is its ithcomponent.Bi;j;k holds the probability of observing ok along the ith component of the observationvector, while being at state sj . R is a relation matrix, specifying for each pair of states, si and sj , the mean and varianceof the D-dimensional2 odometric relation between them. (Ri;j[m]) is the mean of the mth2. For the time being we consider D to be 2, corresponding to (x; y) readings.176\nLearning Geometrically-Constrained HMMscomponent of the relation between si and sj and 2(Ri;j [m]), the variance. Furthermore,R is geometrically consistent: for each component m, the relation m(a; b) def= (Ra;b[m])must be a directed metric, satisfying the following properties for all states a, b, and c: m(a; a) = 0; m(a; b) = m(b; a) (anti-symmetry); and m(a; c) = m(a; b) + m(b; c) (additivity) :This representation of odometric relations re ects the two assumptions, previously stated,regarding the nature of the odometric information. The \\true\" odometric relation betweenthe position of every two states is represented as the mean. The noise around the correctexpected odometric relation, accounting for both the lack of precision in the real-worlddiscretization and the inaccuracy in measurement, is represented through the variance. is a stochastic initial probability vector describing the distribution of the initial state.For simplicity it is assumed here to be of the form h0; : : : ; 0; 1; 0; : : : ; 0i, implying that thereis one designated initial state, si, in which the robot is always started.This model extends the standard hidden Markov model described in Section 3.1 in two ways: It facilitates observations that are factored into components, and represented as vectors.These components are assumed to be conditionally independent of each other given thestate. Such factorization, together with the conditional independence assumption, allowsfor a simple calculation of the probability of the complete observation vector from theprobabilities of its components. It therefore results in fewer probabilistic parameters inthe learnt model than if we were to view each observation vector, consisting of a possiblecombination of component-values as a single \\atomic\" observation. It introduces the odometric relation matrix R and constraints over its components. UsingR and the constraints over it, as explained in Section 4, has proven useful for learning theother model parameters, as demonstrated in Section 6.3.3 Handling Directional DataWe further extend the model to accommodate directional changes in addition to the positionalchanges. There are two issues stemming from directional changes while moving in an environ-ment: the need for non-traditional distributions to model directional changes, and the needto correct for the cumulative rotational error which severely interferes with location estimationwithin a global coordinate framework. A detailed discussion of these two problems and theirsolution is given in an earlier paper by the authors (Shatkay & Kaelbling, 1998). For the sakeof completeness, we brie y review these two issues here.3.3.1 Circular DistributionsThe robot's change in direction as it moves through the environment is expressed in terms of theangular change with respect to its original heading. Since angular measures are inherently cir-cular, treating them as \\normally distributed\", and using the standard procedures for obtainingsu cient statistics from the data is not adequate. As a trivial example, if we were to average177\nShatkay & Kaelbling 173 0\n\u22121790 \u221230\n11 <x , y >\n33 <x , y >\n22 <x , y >\n\u03b82 \u03b83\n\u03b81\nx\ny 1\n-1\n-1 1\nFigure 1: Simple average of two angles, depictedas vectors to the unit circle. The average angle isformed by the dashed vector. Figure 2: Directional data represented as anglesand as vectors on the unit circle.the two angular readings, 173 and 179 , using simple average we obtain the angle 3 , whichis far from the intuitive 180 , as illustrated in Figure 1.To address the circularity issue, we use the von Mises distribution, which is a circular version ofthe normal distribution, to model the change in heading between two states, as explained below.A collection of changes in heading within a two dimensional space can be represented in termsof either Cartesian or polar coordinates. Using a Cartesian system, n changes in headings canbe recorded as a sequence of 2-dimensional vectors, (hx1; y1i; : : : hxn; yni), on the unit circle,as shown in Figure 2. The same changes can also be represented as the corresponding anglesbetween the radii from the center of the unit circle and the X axis, ( 1; : : : ; n), respectively.The relationship between the two representations is:xi = cos( i); yi = sin( i) ; (1 i n) :The vector mean of the n points, hx; yi, is calculated as:x = Pni=1 cos( i)n ; y = Pni=1 sin( i)n : (1)Using polar coordinates, we can express the mean vector in terms of angle, , and length, a,where (except for the case x = y = 0): = arctan(yx); a = (x2 + y2) 12 :The angle is the mean angle, while the length a is a measure (between 0 and 1) of howconcentrated the sample angles are around . The closer a is to 1, the more concentrated thesample is around the mean, which corresponds to a smaller sample variance.Intuitively, a satisfactory circular version of the normal distribution would have a mean forwhich the maximum likelihood estimate is the average angle as calculated above. In a wayanalogous to Gauss' derivation of the Normal distribution, von Mises developed such a circularversion (Gumbel, Greenwood, & Durand, 1953; Mardia, 1972), which is de ned as follows:De nition: A circular random variable, , 0 2 , is said to have the von Misesdistribution with parameters and , where 0 2 and > 0, if its probability density178\nLearning Geometrically-Constrained HMMsfunction is: f ; ( ) = 12 I0( )e cos( ) ;where I0( ) is the modi ed Bessel function of the rst kind and order 0:I0( ) = 1Xr=0 1r!2 (12 )2r : (2)The parameters and correspond to the distribution's mean and concentration respectively.While other circular-normal distributions do exist, the von Mises has the desirable estimationprocedure alluded to earlier: Given a set of heading samples, angles 1; : : : n, from a von Misesdistribution, the maximum likelihood estimate for is: = arctan(yx) ;where y, x are as de ned in Equation 1.The maximum likelihood estimate for the concentration parameter, , is the that satis es:I1( )I0( ) = max[ 1n nXi=1 cos( i ); 0] ;where I1 is the modi ed Bessel function of the rst kind and order 1:I1( ) = 1Xr=0 1r!(r + 1)! (12 )2r+1 : (3)Further information about the estimation procedure is beyond the scope of this paper and canbe found elsewhere (Gumbel et al., 1953; Mardia, 1972).To conclude, we assume that the change in heading is von Mises-distributed, around a mean with concentration parameter . This assumption is re ected in the model learning proceduresas explained later in Section 4.2.3. The change in heading h (a; b); (a; b)i between each pairof states (a; b) completes the set of parameters included in the relation matrix R which wasintroduced earlier in Section 3.2.3.3.2 Cumulative Rotational ErrorWe tend to think about an environment as consisting of landmarks xed in a global coordinatesystem and corridors or transitions connecting these landmarks. This idea underlies the typicalmaps constructed and used in everyday life. However, this view of the environment may beproblematic when robots are involved.Conceptually, a robot has two levels at which it operates; the abstract level, in which it centersitself through corridors, follows walls and avoids obstacles, and the physical level in which motorsturn the wheels as the robot moves. In the physical level many inaccuracies can manifestthemselves: wheels can be unaligned with each other resulting in a drift to the right or to theleft, one motor can be slightly faster than another resulting in similar drifts, an obstacle underone of the wheels can cause the robot to rotate around itself slightly, or uneven oors may cause179\nShatkay & Kaelbling - recorded position - actual position \u03b5\u2212\u03b5\nFigure 3: A robot moving along the solid arrow, while correcting for drift in the direction of the dashedarrow. The dotted arrow marks its recorded change in position.the robot to slip in a certain direction. In addition, the measuring instrumentation for odometricinformation may not be accurate in and of itself. At the abstract level, corrective actions areconstantly executed to overcome the physical drift and drag. For example, if the left wheel ismisaligned and drags the robot leftwards, a corrective action of moving to the right is constantlytaken in the higher level to keep the robot centered in the corridor.The phenomena described above have a signi cant e ect on the odometry recorded by the robot,if such data interpreted with respect to one global framework. For example, consider the robotdepicted in Figure 3. It drifts to the left when moving from one state to the next, andcorrects for it by moving to the right in order to maintain itself centered in the corridor.Let us assume that states are 5 meters apart along the center of the corridor, and that the centerof the corridor is aligned with the Y axis of the global coordinate system. The robot steps backand forth in the corridor from one state to the next. Whenever the robot reaches a state, itsodometry reading changes by hx; y; i along the hX;Y; headingi dimensions, respectively. As therobot proceeds, the deviation with respect to the X axis becomes more and more severe. Thus,after going through several transitions, the odometric changes recorded between every pair ofstates, if taken with respect to a global coordinate system, become larger and larger. Similarproblems of inconsistent odometric changes recorded between pairs of states can arise along anyof the odometric dimensions. It is especially severe when such inconsistencies arise with respectto the heading, since this can lead to mistakenly switching movement along the X and the Yaxes, as well as confusion between forwards and backwards movement (when the deviation inthe heading is around 90 or 180 respectively).In early work (Shatkay & Kaelbling, 1997) we assumed perpendicularity of the corridors, whichwas taken advantage of while the robot collected the data. Odometric readings were recordedwith respect to a global coordinate system, and the robot could re-align itself with the origin aftereach turn. A trajectory of odometry recorded under this perpendicularity assumption by ourrobot Ramona, along the x and y axes is given in Figure 4. The sequence shown was recordedwhile the robot drove repeatedly around a loop of corridors. Further details about the datagathering process are provided in Section 6. In contrast, Figure 5 shows a trajectory of anothersequence of odometric readings recorded by Ramona, driving through the same corridors, withoutusing the perpendicularity assumption. The data collected under the latter setting is subjectedto cumulative rotational error. 180\nLearning Geometrically-Constrained HMMs\n200 400 600 800 1000\n200\n400\n600\n800\n1000\n1200\n-2500 -2000 -1500 -1000 -500 500 1000\n500\n1000\n1500\n2000\n2500\n3000\nFigure 4: Sequence gathered by Ramona, perpen-dicularity assumed. Figure 5: Sequence gathered by Ramona, no per-pendicularity assumed.Such data can be handled through state-relative coordinate systems (Shatkay & Kaelbling, 1998).The latter implies that each state si has its own coordinate system, as shown in Figure 6: theorigin is anchored in si, the Y axis is aligned with the robot's heading in the state (denoted bybold arrows in the gure), and the X axis is perpendicular to it. This is in contrast to a globalcoordinate system which is anchored in the initial starting state. Within the global coordinatesystem, the relations recorded may vary greatly among multiple instances of the same transitionbetween the same pair of states. By using the state-relative system, the recorded and learnedrelationship between each pair of states, hsi; sji, is reliable, despite the fact that it is based onmultiple transitions recorded from si to sj.Under state-relative coordinate systems, the geometric relation stored in Rij , (which was in-troduced in Section 3.2), is expressed for each pair of states, si and sj, with respect to thecoordinate system associated with state si. Accordingly, the constraints imposed over the x andy components of the relation matrix must be speci ed with respect to the explicit coordinatesystem used, as explained below.Given a pair of states a and b, we denote by hx;yi(a; b) the vector h (Ra;b[x]); (Ra;b[y])i. Letus de ne Tab to be the transformation that maps an hxa; yai point represented with respect tothe coordinate system of state a, to the same point represented with respect to the coordinatesystem of state b, hxb; ybi.More explicitly, let ab be the mean change in heading from state a to state b. Applying Tab toa vector hxaya i results in the vector hxbyb i as follows:*xbyb+ = Tab*xaya+ = *xa cos( ab) ya sin( ab)xa sin( ab) + ya cos( ab)+ :The consistency constraints within this framework must be restated as: hx;yi(a; a) = h0; 0i; hx;yi(a; b) = Tba[ hx;yi(b; a)] (anti-symmetry); hx;yi(a; c) = hx;yi(a; b) + Tba[ hx;yi(b; c)] (additivity).181\nShatkay & Kaelbling x\u2206\ny\u2206\n\u2206\u03b8 Si\nSj\ny\nxFigure 6: A robot in state Si, faces in the Y -axis direction; the relation Si,Sj is wrt Si's coordinatesystem.These consistency constraints are the ones that need to be enforced by our learning algorithmwhich constructs the hmm. It is important to note that the transformation T itself does notconstitute a set of additional parameters that need to be learnt. Rather, it is calculated in termsof the heading-change parameter, , which is already an integral part of the relation matrix wehave de ned in Sections 3.2 and 3.3.1.We have introduced the basic formal model that we use for representing environments andthe robot's interaction with them. In the following section we state the learning problem anddescribe the basic algorithm for learning the model from data.4 Learning HMMs with Odometric InformationThis section formalizes the learning problem for hmms, and discusses how odometric informationis incorporated into the learning algorithm. An overview of the complete algorithm is providedin the Appendix for this paper.4.1 The Learning ProblemThe learning problem for hidden Markov models can be generally stated as follows: Given anexperience sequence E, nd a hidden Markov model that could have generated this sequence andis \\useful\" or \\close to the original\" according to some criterion. An explicit common statisticalapproach is to look for a model that maximizes the likelihood of the data sequence E giventhe model. Formally stated, it maximizes Pr(Ej ). However, given the complicated landscapeof typical likelihood functions in a multi-parameter domain, obtaining a maximum likelihoodmodel is not feasible. All studied practical methods, and in particular the well-known Baum-Welch algorithm (Rabiner (1989) and references therein) can only guarantee a local-maximumlikelihood model.Another way of evaluating the quality of a learned model is by comparing it to the true model.We note that stochastic models (such as hmms) induce a probability distribution over all obser-vation sequences of a given length. The Kullback-Leibler (Kullback & Leibler, 1951) divergenceof a learned distribution from a true one is a commonly used measure for estimating how good a182\nLearning Geometrically-Constrained HMMslearned model is. Obtaining a model that minimizes this measure is a possible learning goal. Theculprit here is that in practice, when we learn a model from data, we do not have any \\groundtruth\" model to compare the learned model with. Still, we can evaluate learning algorithms bymeasuring how well they perform on data obtained from known models. It is reasonable to ex-pect that an algorithm that learns well from data that is generated from a model we do have, willperform well on data generated from an unknown model, assuming that the models indeed forma suitable representation of the true generating process. We discuss the Kullback-Leibler (kl)divergence in more detail in Section 6.2 in the context of evaluating our experimental results.To summarize, the learning problem as we address it in this work is that of obtaining a modelby attempting to (locally) maximize the likelihood, while evaluating the results based on thekl-divergence with respect to the true underlying distribution, when such a distribution isavailable.4.2 The Learning AlgorithmThe learning algorithm starts from an initial model 0 and is given an experience sequence E;it returns a revised model , which (locally) maximizes the likelihood P (Ej ). The experiencesequence E is of length T ; each element, Et, for 0 t (T 1), is a pair hrt; Vti, where rt is theobserved relation vector along the x, y and dimensions, between the states qt 1 and qt, and Vtis the observation vector at time t.Our algorithm extends the standard Baum-Welch algorithm to deal with the relational in-formation and the factored observation sets. The Baum-Welch algorithm is an expectation-maximization (em) algorithm (Dempster, Laird, & Rubin, 1977); it alternates between the E-step of computing the state-occupation and state-transition probabilities, and ,at each time in the sequence given E and the current model , and the M-step of nding a new model, , that maximizes P (Ej ; ; ),providing monotone convergence of the likelihood function P (Ej ) to a local maximum.However, our extension introduces an additional component, namely, the relation matrix R. Itcan be viewed as having two kinds of observations: state observations (as the ordinary hmm |with the distinction that we observe integer vectors rather than integers) and transition observa-tions (the odometry relations between states). The latter must satisfy geometrical constraints.Hence, an extension of the standard update formulae, as described below, is required.4.2.1 State-Occupation ProbabilitiesFollowing Rabiner (1989), we rst compute the forward ( ) and backward ( ) matrices. t(i)denotes the probability density value of observing E0 through Et and qt = si, given ; t(i) isthe probability density of observing Et+1 through ET 1 given qt = si and . Formally: t(i) = Pr(E0; : : : ;Et; qt = sij ) ; t(i) = Pr(Et+1; : : : ;ET 1jqt = si; ) :When some of the measurements are continuous (as is the case with R), these matrices containprobability density values rather than probabilities.The forward procedure for calculating the matrix is initialized with 0(i) = ( bi0 if i = 10 otherwise ;183\nShatkay & Kaelblingand continued for 0 < t T 1 with t(j) = N 1Xi=0 t 1(i)Ai;jf(rtjRi;j)bjt : (4)The expression f(rtjRi;j) denotes the density at point rt according to the distribution representedby the means and variances in entry i; j of the relation matrix R, while bjt is the probability ofobserving vector vt in state sj; that is, bjt =Qli=0Bi;j;vt[i].The backward procedure for calculating the matrix is initialized with T 1(j)=1, and continuedfor 0 t<T 1 with t(i) = N 1Xj=0 t+1(j)Ai;jf(rt+1jRi;j)bjt+1 : (5)Given and , we now compute for each given time point t the state-occupation and state-transition probabilities, and . The state-occupation probabilities, t(i), representing theprobability of being in state si at time t given the experience sequence and the current model,are computed as follows: t(i) = Pr(qt = sijE; ) = t(i) t(i)PN 1j=0 t(j) t(j) : (6)Similarly, t(i; j), the state-transition probabilities from state i to state j at time t given theexperience sequence and the current model, are computed as: t(i; j) = Pr(qt = si; qt+1 = sj jE; )= t(i)Ai;jbjt+1f(rt+1jRi;j) t+1(j)N 1Xi=0 N 1Xj=0 t(i)Ai;jbjt+1f(rt+1jRi;j) t+1(j) : (7)These are essentially the same formulae appearing in Rabiner's tutorial (Rabiner, 1989), butthey also take into account the density of the odometric relations.In the next phase of the algorithm, the goal is to nd a new model, , that maximizes the likeli-hood conditioned on the current transition and observation probabilities, Pr(Ej ; ; ). Usually,this is simply done using maximum-likelihood estimation of the probability distributions in Aand B by computing expected transition and observation frequencies. In our model we must alsocompute a new relation matrix, R, under the constraint that it remain geometrically consistent.Through the rest of this section we use the notation v to denote a reestimated value, where vdenotes the current value.4.2.2 Updating Transition and Observation ParametersThe A and B matrices can be straightforwardly reestimated. Ai;j is the expected number oftransitions from si to sj divided by the expected number of transitions from si, and Bi;j;k is theexpected number of times ok is observed along the ith dimension when in state sj , divided bythe expected number of times of being in sj:Ai;j = PT 2t=0 t(i; j)PT 2t=0 t(i) ; Bi;j;k = PT 1t=0 [Vt[i]=ok] t(j)PT 1t=0 t(i) : (8)The expression c denotes an indicator function with value 1 if condition c is true and 0 otherwise.184\nLearning Geometrically-Constrained HMMs -6 -4 -2 2 4 6 PQ -8 -6 -4 -2 2 4 6 8\n-7.5\n-5\n-2.5\n2.5\n5\n7.5\nP\nQFigure 7: Examples of two sets of normally distributed points with constrained means, in 1 and in 2dimensions.4.2.3 Updating Relation ParametersWhen reestimating the relation matrix, R, the geometrical constraints induce interdependenciesamong the optimal mean estimates as well as between optimal variance estimates and meanestimates. Parameter estimation under this form of constraints is almost untreated in main-stream statistics (Bartels, 1984) and we found no previous existing solutions to the estimationproblem addressed here. As an illustration for the issues involved in estimation under constraintsconsider the following estimation problem of 2 normal means:Example 4.1 The data consists of two sample sets of points P =fp1; p2; : : : ; png and Q =fq1; q2; : : : ; qkg, independently drawn from two distinct normal distributions with means P ; Qand variances 2P ; 2Q, respectively. We are asked to nd maximum likelihood estimates for thetwo distribution parameters. Moreover, we are told that the means of the two distributions arerelated, such that Q= P , as illustrated in Figure 7. If not for the latter constraint, the taskis simple (DeGroot, 1986), and we have: P = Pni=1 pin ; 2P = Pni=1(pi P )2n ;and similarly for Q and 2Q. However, the constraint P = Q requires nding a single mean, ,and setting the other one to its negated value, . Intuitively, when choosing such a maximumlikelihood single mean, the more concentrated sample should have more e ect, while the morevaried sample should be more \\submissive.\" Thus, the overall sample deviation from the meanswould be minimized and the likelihood of the data maximized. Therefore, there is a mutualdependence between the estimation of the mean and the estimation of the variance.Since the samples are independently drawn, their joint likelihood function is:f(P;Qj P ; Q; 2P ; 2Q) = nYi=1 e (pi P )22 2Pp2 P kYj=1 e (qj Q)22 2Qp2 Q :By taking the derivatives of this joint log-likelihood function, with respect to P , P and Q, andequating them to 0, while using the constraint Q = P , we obtain the following set of mutualequations for maximum likelihood estimators: P = ( 2QPni=1 pi) ( 2P Pkj=1 qj)n 2Q + k 2P ; Q = P ; 2P = Pni=1(pi P )2n ; 2Q = Pkj=1(qj + P )2k :185\nShatkay & KaelblingBy substituting the expressions for P and Q into the expression for P , we obtain a cubic equa-tion which is cumbersome, but still solvable (in this simple case). The solution provides a maxi-mum likelihood estimate for the mean and variance under the constraint Q= P : 2We now proceed to the actual update of the relation matrix under constraints. For clarity, weinitially discuss only the rst two geometrical constraints, and discuss the additivity constraint inSection 4.3. Recall that we concentrate here on the enforcement of global constraints, appropriateunder the perpendicularity assumption, although the same idea is applied in the case of state-relative constraints.Zero distances between states and themselves are trivially enforced, by setting all the diagonalentries in the R matrix to 0, with a small variance.Anti-symmetry within a global coordinate system is enforced by using the data recorded alongthe transition from state sj to si as well as from state si to sj when reestimating (Ri;j). Asdemonstrated in Example 4.1, the variance has to be taken into account, leading to the followingset of mutual equations: mi;j = PT 2t=0 rt[m] t(i;j)( mi;j)2 rt[m] t(j;i)( mj;i)2 PT 2t=0 t(i;j)( mi;j)2 + t(j;i)( mj;i)2 ; (9)( mi;j)2 = PT 2t=0 [ t(i; j)(rt[m] mi;j)2]PT 2t=0 t(i; j) : (10)For the x and y dimensions, (m = x; y), this amounts to a complicated but still solvable cubicequation. However, in the more general case, when accounting for the orientation of the robot,and also when complete additivity is enforced, we do not obtain such closed form reestimationformulae.To avoid these hardships, we use a lag-behind update rule; the yet-unupdated estimate of thevariance is used for calculating a new estimate for the mean, and this new mean estimate isused to update the variance, using Equation 10.3 Thus, the mean is updated using a varianceparameter that lags behind it in the update process, and the reestimation Equation (9) needs touse m rather than m as follows: mi;j = PT 2t=0 h rt[m] t(i;j)( mi;j )2 rt[m] t(j;i)( mj;i)2 iPT 2t=0 h t(i;j)( mi;j)2 + t(j;i)( mj;i)2 i : (11)As we have shown (Shatkay, 1999), this lag-behind policy is an instance of generalized em (McLach-lan & Krishnan, 1997). The latter guarantees monotone convergence to a local maximum of thelikelihood function, even when each \\maximization\" step increases rather than strictly maxi-mizes the expected likelihood of the data given the current model.Similarly, the reestimation formula for the von Mises mean ( ) and concentration ( ) parametersof the heading change between states si and sj is the solution to the equations: i;j = arctan0BBBB@ T 2Xt=0 [sin(rt[ ])( t(i; j) i;j t(j; i) j;i)]T 2Xt=0 [cos(rt[ ])( t(i; j) i;j + t(j; i) j;i)] 1CCCCA3. A similar approach, termed one step late update, is taken by others applying em to highly non-linear opti-mization problems (McLachlan & Krishnan, 1997).186\nLearning Geometrically-Constrained HMMsI1[ i;j ]I0[ i;j ] = max\"PT 2t=0 [ t(i; j) cos(rt[ ] i;j)]PT 2t=0 t(i; j) ; 0# ; (12)where I0 and I1 are the modi ed Bessel functions as de ned by Equations 2 and 3 in Section 3.3.1.Again, to avoid the need to solve the mutual equations, we take advantage of the lag-behind strat-egy, updating the mean using the current estimates of the concentration parameters, i;j; j;i,as follows: i;j = arctan PT 2t=0 [sin(rt[ ])( t(i; j) i;j t(j; i) j;i)]PT 2t=0 [cos(rt[ ])( t(i; j) i;j + t(j; i) j;i)]! ; (13)and then calculating the new concentration parameters based on the newly updated mean, asthe solution to Equation 12, through the use of lookup-tables.A possible alternative to our lag-behind approach is to update the mean as though the assump-tion j;i = i;j holds. Under this assumption, the variance terms in Equation 9 cancel out, andthe mean update is independent of the variance once again. Then the variances are updated asstated in Equation 10, without assuming any constraints over them. This approach was takenin earlier stages of this work (Shatkay & Kaelbling, 1997, 1998). The lag-behind strategy issuperior, both according to our experiments, and due to its being an instance of generalized em.4.3 Enforcing AdditivityNote that the additivity constraint directly implies the other two geometrical constraints4. Thus,enforcing it results in complete geometrical consistency. We present here the method for directlyenforcing additivity through the reestimation procedure along the x and y dimensions. For theheading dimension we describe how complete geometrical consistency is achieved through theprojection of anti-symmetric estimates onto a geometrically-consistent space. As before, tosimplify the presentation, we focus on the case of global coordinate systems. The same basicidea applies to state-relative coordinate systems, but the relationship used to recover the mean ij from individual state coordinates is more complex.4.3.1 Additivity in the x, y dimensionsThe main observation underlying our approach is that the additivity constraint is a result of thefact that states can be embedded in a geometrical space. That is, assuming we have N states,s0; : : : ; sN 1, there are points on the X, Y and axes, x0; : : : ; xN 1, y0; : : : ; yN 1, 0; : : : ; N 1,respectively, such that each state, si, is associated with the coordinates hxi; yi; ii. Assumingone global coordinate system, the mean odometric relation from state si to state sj can beexpressed as: hxj xi; yj yi; j ii.During the maximization phase of the em iteration, rather than try to maximize with respectto N2 odometric relation vectors, h Xij , Yij, iji, we reparameterize the problem. Speci cally,we express each odometric relation as a function of two of the N state positions, and maximizewith respect to the unconstrained, N state positions. For instance, for the X dimension, ratherthan search for N2 maximum likelihood estimates for xij, we use the maximization step to ndN 1-dimensional points, x0; : : : ; xN 1. We can then calculate xij = xj xi. Moreover, sinceall we are interested in is nding the best relationships between xi and xj, we can x one of4. f (a; a)= (a; a)+ (a; a)g ) ( (a; a)=0) ; f( (a; a)=0) ; ( (a; a)= (a; b)+ (b; a))g ) ( (a; b) = (b; a)).187\nShatkay & Kaelblingthe xi's at 0 (e.g. x0 = 0), and nd optimal estimates for the remaining N 1 state positions.The variance reestimation remains as before, and the lag-behind policy is used to eliminate theinterdependency between the update of the mean and the variance parameters.4.3.2 Additive Heading EstimationUnfortunately, the reparameterization described above is not feasible for estimation of changesin heading, due to the von Mises distribution assumption over the heading measures. By repa-rameterizing ij as j i and trying to maximize the likelihood function with respect to the parameters, we obtain a set of N 1 trigonometric equations with terms of the form cos( j) sin( i)which do not enable simple solution.As an alternative, it is possible to use the anti-symmetric reestimation procedure describedearlier, followed by a perpendicular projection operator, mapping the resulting headings vectorh 00; : : : ; ij ; : : : ; N 1;N 1i, 0 i; j N 1, which does not satisfy additivity, onto a vector ofheadings within an additive linear vector space. Simple orthogonal projection is not satisfactorywithin our setting, since it simply looks for the additive vector closest to the non-additive one.This procedure ignores the fact that some of the entries in the non-additive vector are based ona lot of observations, and are therefore more reliable, while other, less reliable ones, are based onhardly any data at all. Intuitively, we would like to keep the estimates that are well accountedfor intact, and adapt the less reliable estimates to meet the additivity constraint. More precisely,there are heading-change estimates between states that are better accounted for than others, inthe sense that the transitions between these states have higher expected counts than transitionbetween other states (higher Pt t(i; j)). We would like to project the non-additive headingestimates vector onto a subspace of the additive vector space, in which the vectors have the samevalues as the non-additive vector in the entries that are well-accounted for, that is, those withthe highest values of Pt t(i; j). The di culty is that the latter subspace is not a linear vectorspace (for instance, it does not satisfy closure under scalar multiplication), and the projectionoperator over linear spaces cannot be applied directly. Still, this set of vectors does form ana ne vector space, and we can project onto it using an algebraic technique, as explained below.5De nition A Rn is an n-dimensional a ne space if for all vectors va2A, the set of vectors:A va def= fua vajua 2 Ag is a linear space.Hence, we can pick a vector in an a ne space, va12A, and de ne the translation Ta : A ! V ,where V is a linear space, V = A va1 . This translation is trivially extended for any vectorv0 2 Rn, by de ning Ta(v0) = v0 va1 . In order to project any vector v 2 Rn onto A, we applythe translation Ta to v and project Ta(v) onto V , which results in a vector P(Ta(v)) in V . Byapplying the inverse transform T 1a to it, we obtain the projection of v on A, as demonstratedin Figure 8. The linear space in the gure is the two dimensional vector space fhx; yij y = xg,and the a ne space is fhx; yij y = x+4g. The transform Ta consists of subtracting the vectorh0; 4i. The solid arrow corresponds to the direct projection of the vector v onto the point P(v)of the a ne space. The dotted arrows represent the projection via translation of v to Ta(v), theprojection of the latter onto the linear vector space, and the inverse translation of the result,P(Ta(v)), onto the a ne space.5. Many thanks to John Hughes for introducing us to this technique.188\nLearning Geometrically-Constrained HMMs -2 2 4\n-4\n-2\n2\n4\n6\nv\nTa(v)\nP(v)\nP(Ta(v))\n<x,-x>\n<x,-x+4>\nFigure 8: Projecting v onto the a ne vector space fhx; yij y = x+ 4g.Although the procedure for preserving additivity over headings is not formally proven to pre-serve monotone convergence of the likelihood function towards a local maximum, our extensiveexperiments consisting of hundreds of runs have shown that monotone convergence is preserved.5 Choosing an Initial ModelTypically, in instances of the Baum-Welch algorithm, an initial model is picked uniformly atrandom from the space of all possible models, perhaps trying multiple initial models to nd dif-ferent local likelihood maxima. An alternative approach we have reported (Shatkay & Kaelbling,1997) was based on clustering the accumulated odometric information using the simple k-meansalgorithm (Duda & Hart, 1973), taking the clusters to be the states in which the observationswere recorded, to obtain state and observation counts and estimate the model parameters.If perpendicularity is assumed when collecting the data, as shown in Figure 4, the k-meansalgorithm assigns the same cluster (state) to odometric readings recorded at close locations,leading to reasonable initial models. However, when this assumption is dropped, as illustratedin Figure 5, the cumulative rotational error distorts the odometric location recorded within aglobal coordinate system, so that the location assigned to the same state during multiple visitsvaries greatly and would not be recognized as \\the same\" by a simple location-based clusteringalgorithm. To overcome this, we developed an alternative initialization heuristics, which we calltag-based initialization. It is based directly on the recorded relations between states, rather thanon states' absolute location. For clarity, the description here consists mostly of an illustrativeexample, and concentrates on the case where global consistency constraints are enforced.Given a sequence of observations and odometric readings E, we begin by clustering the odometricreadings into buckets. The number of buckets is at most the number of distinct state transitionsrecorded in the sequence. The goal at this stage is to have each bucket contain all the odometricreadings that are close to each other along all three dimensions.To achieve this, we start by xing a predetermined, small standard deviation value along the x,y, and dimensions. Denote these standard deviation values x; y; respectively, (typically x = y). The rst odometric reading is assigned to bucket 0 and the mean of this bucket isset to be the value of this reading. Through the rest of the process the subsequent odometricreadings are examined. If the next reading is within 1:5 standard deviations along each of thethree dimensions from the mean of some existing non-empty bucket, add it to the bucket and189\nShatkay & Kaelbling <-1, 98, 91.5> \u00b51:\n1\n\u00b52:\n<1996, -2.5, 89>\n2\n\u00b53:\n<0.5, -99.5, 88.5>\n3\n\u00b54:\n<-2001, 3, 90.5>\n4\n< -4, 102, 91 > < 2, 94, 92 > <1994, 0, 88 > < 1998, -5, 90 > < -2, -106, 91 > < 3, -93, 86 > < -1999, -1, 94 > < -2003, 7, 87 >\nFigure 9: The bucket assignment of the example sequence.update the bucket mean accordingly. If not, assign it to an empty bucket and set the mean ofthe bucket to be this reading.Intuitively, by using this heuristic each of the resulting buckets is tightly concentrated aboutits mean. We note that other clustering algorithms (Duda & Hart, 1973) could be used at thebucketing stage.Example 5.1 We would like to learn a 4-state model from a sequence of odometric readings,hx; y; i as follows: h2 94 92i; h1994 0 88i; h3 93 86i; h 1999 1 94i;h 4 102 91i; h1998 5 90i; h 2 106 91i; h 2003 7 87i :As a rst stage we place these readings into buckets. Suppose the standard deviation constant is20. The placement is as shown in Figure 9. The mean value associated with each bucket is shownas well. 2The next stage of the algorithm is the state-tagging phase, in which each odometric reading,rt, is assigned a pair of states, si; sj , denoting the origin state (from which the transition tookplace) and the destination state (to which the transition led), respectively. In conjunction, themean entries, ij, of the relation matrix, R, are populated.Example 5.1 (cont.) Returning to the sequence above, the process is demonstrated in Fig-ure 10. We assume that the data recording starts at state 0, and that the odometric changethrough self transitions is 0, with some small standard deviation (we use 20 here as well). Thisis shown on part A of the gure.Since the rst element in the sequence, h2 94 92i, is more than two standard deviations awayfrom the mean [0][0] and no other entry in the relation row of state 0 is populated, we pick 1as the next state and populate the mean [0][1] to be the same as the mean of bucket 1, to whichh2 94 92i belongs. To maintain geometrical consistency the mean [1][0] is set to [0][1], asshown in part B of the gure. We now have populated 2 o -diagonal entries, and the statesequence is h0; 1i. The entry [0][1] in the matrix becomes associated with bucket 1, and thisinformation is recorded for helping with tagging future odometric readings belonging to the samebucket.The next odometric reading, h1994 0 88i, is a few standard deviations from any populated meanin row 1 (where 1 is the current believed state). Hence, we pick a new state 2, and set the mean [1][2] to be 2|the mean of bucket 2|to which the reading belongs (Figure 10 C). The entry[1][2] is recorded as associated with bucket 2. To preserve anti-symmetry and additivity, [2][1]is set to [1][2]. [0][2] is set to be the sum [0][1] + [1][2], and [2][0] is set to [0][2].190\nLearning Geometrically-Constrained HMMs\n-179.5> 95.5, <1995, 98, 91.5> <-1,\n2.5, -89>\n<-1996,\n89> -2.5, <1996, -91.5> -98, < 1, <-1995, -95.5, 179.5>\n<0,0,0>\n<0,0,0>\n<0,0,0>\n<0,0,0>\n<0,0,0>\n<0,0,0>\n<0,0,0>\n<0,0,0>\n98, 91.5>\n<-1, 95.5, <1995,\n-179.5>\n< 0.5,\n88.5> -99.5,\n99.5, -88.5>\n<-0.5,\n177.5>\n<1996.5, -102,\n102, -177.5>\n<-1996.5,\n<-1995, -95.5, 179.5>\n-98, -91.5>\n< 1,\n89> -2.5, <1996,\n2.5, -89>\n<-1996,\n4, 91>\n<-1995.5,\n<0,0,0>\n<0,0,0>\n<0,0,0>\n-4, -91>\n<1995.5, <0,0,0>\n-91.5>\n< 1, -98,\n<0,0,0>\n<0,0,0>\n<0,0,0>\n<0,0,0>\n98, <-1,\n91.5>\nBucket(R[0][1]) = \u00b51\n0 321 3210\n1 1 2 2 3\n0\n3\n0\nA\nS: 0. 1S: 0\nB\n,..., S:0, 1, 2, 3, 0, 1, 2, 3, 0\nS: 0,1,2,3,0\n\u00b54Bucket(R[3][0]) =\nBucket(R[2][3]) = \u00b53\n32103210\n0 0\n1 2 3 1 2 3\nC D\nBucket(R[1][2]) = \u00b52\nS: 0,1,2,3S: 0, 1, 2\nFigure 10: Populating the odometric relation matrix and creating a state tagging sequence.Similarly, [2][3] is updated to be the mean of bucket 3, causing the setting of [3][2], [1][3], [0][3], [3][1], and [3][0]. Bucket 3 is associated with [2][3].At this stage the odometric table is fully populated, as shown in part D of Figure 10. The statesequence at this point is: h0; 1; 2; 3i. The next reading, h 1999 1 94i, is within one standarddeviation from [3][0] and therefore the next state is 0. Entry [3][0] is associated with bucket 4,(the bucket to which the reading was assigned), and the state sequence becomes: h0; 1; 2; 3; 0i.The next reading, being from bucket 1, is associated with the relation from state 0 that is taggedby bucket 1, namely, state 1. By repeating this for the last two readings, the nal state transitionsequence becomes h0; 1; 2; 3; 0; 1; 2; 3; 0i: 2Note that the process described in the above illustration was simpli ed. In the general case,we need to take into account the rotational error in the data, use state-relative coordinatesystems, and therefore populate the entries under the transformed anti-symmetry and additivityconstraints: hx;yi(a; b) = Tba[ hx;yi(b; a)] ; hx;yi(a; c) = hx;yi(a; b) + Tba[ hx;yi(b; c)],as de ned in Section 3.3.2. 191\nShatkay & KaelblingIt is possible that by the end of the tagging algorithm, some rows or columns of the relationmatrix are still unpopulated. This happens when there is too little data to learn from or whenthe number of states provided to the algorithm is too large with respect to the actual model. Insuch cases we can either \\trim\" the model, using the number of populated rows as the numberof states, or pick random odometric readings to populate the rest of the table, improving theseestimates later. Note that the rst approach suggests a method for learning the number of statesin the model when this is not given, starting from a gross over-estimate of the number, and trun-cating it to the number of populated rows in the odometric table after initialization is performed.Once the state-transition sequence is obtained, the rest of the initialization algorithm is the sameas it is for k-means based initialization, deriving state-transition counts from the state-transitionsequence, assigning the observations to the states under the assumption that the state sequenceis correct, and obtaining state-transition and observation probabilities. The initialization phasedoes not incur much computational overhead, and is equivalent time-wise to performing oneadditional iteration of the em procedure.6 Experiments and ResultsThe goal of the work described so far is to use odometry to improve the learning of topologicalmodels, while using fewer iterations and less data. We tested our algorithm in a simple robot-navigation world. Our experiments consist of running the algorithm both on data obtainedfrom a simulated model and on data gathered by our mobile robot, Ramona. The amount ofdata gathered by Ramona is used here as a proof of concept but is not su cient for statisticalanalysis. For the latter, we use data obtained from the simulated model. We gathered data andused the algorithms both with and without the perpendicularity assumption (see Section 3.3.2),and results are provided from both settings.6.1 Robot DomainThe robot used in our experiments, Ramona, is a modi ed RWI B21 robot. It has a cylindricalsynchro-drive base, 24 ultrasonic sensors and 24 infrared sensors, situated evenly around itscircumference. The infrared sensors are used mostly for short-range obstacle avoidance. Theultrasonic sensors are longer ranged, and are used for obtaining (noisy) observations of theenvironment. In the experiments described here, the robot follows a prescribed path throughthe corridors in the o ce environment of our department. Thus, there is no decision-makinginvolved, and an hmm is a su cient model, rather than a complete pomdp.Low-level software6 provides a level of abstraction that allows the robot to move through hallwaysfrom intersection to intersection and to turn ninety degrees to the left or right. The softwareuses sonar data to distinguish doors, openings, and intersections along the path, and to stopthe robot's current action whenever such a landmark is detected. Each stop|either due to thenatural termination of an action or due to a landmark detection|is considered by the robot tobe a \\state\".At each stop, ultrasonic data interpretation allows the robot to perceive, in each of the threecardinal directions, (front, left and right), whether there is an open space, a door, a wall, orsomething unknown.Encoders on the robot's wheels allow it to estimate its pose (position and orientation) with re-spect to its pose at the previous intersection. After recording both the sonar-based observations6. The low-level software was written and maintained by James Kurien.192\nLearning Geometrically-Constrained HMMs\n0\n1\n2\n3 4 5 6 7 8\n9 10 11 12\n131415 16\n0\n123 4 5\n6\n8\n91012 13\n14 15 17 24\n25 26 27 28 29\n7 42 43\n18\n19\n20 21 22\n23\n11\n30 31 32 33\n34\n35 36 38\n41\n37 39 40\n16\nFigure 11: True model of the corridors Ra-mona traversed. Arrows represent the pre-scribed path direction. Figure 12: True model of a prescribed paththrough the simulated hallway environment.and the odometric information, the robot goes on to execute the next prescribed action. Theaction command is issued manually by a human operator. Of course, both the action perfor-mance and the perception routines are subject to error. The path Ramona followed consists of4 connected corridors in our building, which include 17 states, as shown in Figure 11.In our simulation, we manually generated an hmm representing a prescribed path of the robotthrough the complete o ce environment of our department, consisting of 44 states, and theassociated transition, observation, and odometric distributions. The transition probabilitiesre ect an action failure rate of about 5 10%. That is, the probability of moving from thecurrent state to the correct next state in the environment, under the predetermined action isbetween 0:85 and 0:95. The probability of self transition is typically between 0:05 and 0:15.Some small probability (typically smaller than 0:02) is sometimes assigned to other transitions.Our experience with the real robot proves that this is a reasonable transition model, sincetypically the robot moves to the next state correctly, and the only error that occurs with somesigni cant frequency is when it does not move at all, due to sonar interpretation indicating abarrier when there is actually none. Once the action command is repeated the robot usuallyperforms the action correctly, moving to the expected next state. The observation distributiontypically assigns probabilities of 0:85 0:95 to the true observation that should be perceivedby the robot at each state, and probabilities of 0:05 0:15 to other observations that might beperceived. For example, if a door should actually be perceived, a door is typically assigned aprobability of 0:85 0:9, a wall is assigned a probability of 0:09 0:1 and an open space is assigneda probability of about 0:01 to be perceived. The standard deviation around odometric readingsis about 5% of the mean.Figure 12 shows the hmm corresponding to the simulated hallway environment. Observationsand orientation are omitted from the gure for clarity. Nodes correspond to states in theenvironment, while directed edges correspond to the corridors; the arrows point at the directionin which the corridors were traversed. Further interpretation of the gures is provided in thefollowing section. 193\nShatkay & Kaelbling6.2 Evaluation MethodThere are a number of di erent ways of evaluating the results of a model-learning algorithm.None are completely satisfactory, but they all give some insight into the utility of the results.In this domain, there are transitions and observations that usually take place, and are thereforemore likely than the others. Furthermore, the relational information gives us a rough estimateof the metric locations of the states. To get a qualitative sense of the plausibility of a learntmodel, we can extract an essential map from the learnt model, consisting of the states, themost likely transitions and the metric measures associated with them, and ask whether this mapcorresponds to the essential map underlying the true world.Figures 11 and 12 are such essential versions of the true models, while Figures 15 and 17, shownlater, are essential versions of representative learnt ones (obtained from sequences gatheredunder the perpendicularity assumption). Black dots represent the physical locations of states,and each state is assigned a unique number. Multiple state numbers associated with a singlelocation typically correspond to di erent orientations of the robot at that location. The largerblack circle represents the initial state. Solid arrows represent the most likely non-self transitionsbetween the states. Dashed arrows represent the other transitions when their probability is 0:2or higher. Typically, due to the predetermined path we have taken, the connectivity of themodeled environment is low, and therefore the transitions represented by dashed arrows arealmost as likely as the most likely ones. Note that the length of the arrows, within each plot, issigni cant and represents the length of the corridors, drawn to scale.It is important to note that the gures do not provide a complete representation of the models.First, they lack observation and orientation information. We stress the fact that the guresserve more as a visual aid than as a plot of the true model. We are looking for a good topologicalmodel rather than a geometrical model. The gures provide a geometrical embedding of thetopological model. However, even when the geometry, as described by the relation matrix, isdi erent, the topology, as described by the transition and observation matrices, can still be valid.Traditionally, in simulation experiments, the learnt model is quantitatively compared to theactual model that generated the data. Each of the models induces a probability distributionon strings of observations; the asymmetric Kullback-Leibler divergence (Kullback & Leibler,1951) between the two distributions is a measure of how good the learnt model is with respectto the true model. Given a true probability distribution P = fp1; :::; png and a learnt oneQ = fq1; :::; qng, the kl divergence of Q with respect to P is:D(P jjQ) def= nXi=1 pi log2 piqi :We report our results in terms of a sampled version of the kl divergence, as described by Juangand Rabiner (1985). It is based on generating sequences of su cient length (5 sequences of 1000observations in our case) according to the distribution induced by the true model, and comparingtheir log-likelihood according to the learnt model with the true model log-likelihood. The totaldi erence in log-likelihood is then divided by the total number of observations, accumulatedover all the sequences, giving a number that roughly measures the di erence in log-likelihoodper observation. Formally stated, let M1 be the true model and M2 a learnt one. By generatingK sequences S1; : : : ; SK , each of length T , from the true model,M1, the sampled kl-divergence,Ds is: Ds(M1jjM2) = KXi=1[log(Pr(SijM1)) log(Pr(SijM2))]KT :194\nLearning Geometrically-Constrained HMMs\n200 400 600 800 1000\n200\n400\n600\n800\n1000\n1200\n-1500 -1250 -1000 -750 -500 -250\n-1500\n-1000\n-500\n500\n1000\nFigure 13: Sequence gathered by Ramona,perpendicularity assumed. Figure 14: Sequence generated by our simula-tor, perpendicularity assumed.We ignore the odometric information when applying the kl measure, thus allowing comparisonbetween purely topological models that are learnt with and without odometry.6.3 Results within a Global FrameworkWe let Ramona go around the path depicted in Figure 11 and collect a sequence of about300 observations, while assuming perpendicularity of the environment, that is, at every turningpoint the angle of turn is 90 . Thus at each turn Ramona realigns its odometric readings withits initial X and Y axes. Figure 13 plots the sequence of metric coordinates, gathered in thisway, while accumulating consecutive odometric readings, projected on hx; yi. We applied thelearning algorithm to the data 30 times. 10 of these runs were started from a k-means-basedinitial model, 10 started from a tag-based initial model, and 10 started from a random initialmodel. In addition we also ran the standard Baum-Welch algorithm, ignoring the odometricinformation, 10 times. (Note that there is non-determinism even when using biased initialmodels, since the k-means clustering starts from random seeds, and low7 random noise is addedto the data in all algorithms to avoid numerical instabilities, thus multiple runs give multipleresults). We report here the results obtained using the tag-based method, which is the mostappropriate initialization method in the general case. These results are contrasted with thoseobtained when odometric information is not used at all. For a comparison of all four settingsthe reader is referred to the complete report of this work (Shatkay, 1999).Figure 15 shows the essential representations of typical learnt models starting from a tag-basedinitial model. The geometry of the learnt model strongly corresponds to that of the true en-vironment, and most of the states' positions were learnt correctly. Although the gure doesnot show it, the learnt observation distributions at each state usually match well with the trueobservations.To demonstrate the e ect of odometry on the quality of the learnt topological model, we contrastthe plotted models learnt using odometry with a representative topological model learnt without7. A random number between -1cm and 1cm is added to recorded distances that are typically several meterslong. 195\nShatkay & Kaelbling\n0 15\n16\n1\n2\n3 4 5 6 7 8\n9 10 11 12\n1314\n3 5 6 7 84\n9\n12\n131415 0\n16\n2\n16 10 8 7 5 0 12 1 92314461113\n15 Figure 15: Learnt model of the corridors Ra-mona traversed. Figure 16: The topology of a model learntwithout the use of odometry.the use of odometric information. Figure 16 shows the topology of a typical model learnt withoutthe use of odometric information. In this case, the arcs represent only topological relationships,and their length is not meaningful. The initial state is shown as a bold circle. It is clear thatthe topology learnt does not match the characteristic loop topology of the true environment.For obtaining statistically su cient information, we generated 5 data sequences, each of length1000, using Monte Carlo sampling from the hidden Markov model whose projection is shown inFigure 12. One of these sequences is depicted in Figure 14. The gure demonstrates that thenoise model used in the simulation is indeed compatible with the noise pattern associated withreal robot data. We used four di erent settings of the learning algorithm: starting from a biased, tag-based, initial model and using odometric information; starting from a biased, k-means-based, initial model and using odometric information; starting from an initial model picked uniformly at random, while using odometric infor-mation; starting from a random initial model without using odometric information (standard Baum-Welch).For each sequence and each of the four algorithmic settings we ran the algorithm 10 times. Tokeep the discussion focused, we concentrate here on the rst and the last of these settings andthe reader is referred to a more extensive report (Shatkay, 1999) for a complete discussion.In all the experiments, N was set to be 44, which is the \\correct\" number of states; for gener-alization, it will be necessary to use cross-validation or regularization methods to select modelcomplexity. Section 5 also suggests one possible heuristic for obtaining an estimate of the numberof states.Figure 17 shows an essential version of one learnt model, obtained from the sequence shownin Figure 14, using tag-based initialization. We note that the learnt model is not completely196\nLearning Geometrically-Constrained HMMs 0\n12\n34\n5\n6\n12\n131415\n16 27\n18\n29\n34 35 36\n37 38\n39 40\n41\n424310\n11\n7 8 9\n26\n30\n22\n3132\n23\n33 24\n25\n28\n21\n17 19 20\nFigure 17: Learnt model of the simulated hallway environment.accurate with respect to the true model. However, there is an obvious correspondence betweengroups of states in the learnt and true models, and most of the transitions (as well as theobservations, which are not shown) were learnt correctly. The quality of the geometry of thelearnt model in this simulated large environment varies, and the geometrical results are not asuniformly good as was the case when learning the smaller environment from real robot data.As the environment gets large, the global relations between remote states, which are re ectedin the geometrical consistency constraints, become harder to learn. Still, the topology of thelearnt model as demonstrated by our statistical experiments is good.Table 1 lists the kl divergence between the true and learnt model, as well as the numberof runs until convergence was reached, for each of the 5 sequences for both the setting thatuses odometric information under tag-based initialization and the learning algorithm that doesnot use odometric information, averaged over 10 runs per sequence. We stress that each kldivergence measure is calculated based on new data sequences that are generated from the truemodel, as described in Section 6.2. The 5 sequences from which the models were learnt do notparticipate in the testing process.The kl divergence with respect to the true model for models learnt using odometry, is about 5-6times smaller than for models learnt without odometric data. The standard deviation aroundthe means is about 0.2 for kl distances for models learnt with odometry and 1.5 for the no-odometry setting. To check the signi cance of our results we used the simple two-sample t-test.The models learnt using odometric information have statistically signi cantly (p 0:0005) loweraverage kl divergence than the others.Seq. # 1 2 3 4 5With kl 0.981 1.290 1.115 1.241 1.241Odo Iter # 16.70 20.90 22.30 12.70 27.50No kl 6.351 4.863 5.926 6.261 4.802Odo Iter # 124.1 126.0 113.0 107.4 122.9Table 1: Average results of two learning settings with ve training sequences.197\nShatkay & KaelblingIn addition, the number of iterations required for convergence when learning using odometricinformation is roughly 4-5 times smaller than that required when ignoring such information.Again, the t-test veri es the signi cance of this result.Under all three initialization settings, the models learnt are topologically somewhat inferior (andthis is with high statistical signi cance), in terms of the kl divergence, to those learnt withoutenforcing additivity, reported in earlier papers (Shatkay & Kaelbling, 1997, 1998). This is likelyto be a result of the very strong constraints enforced during the learning process, which preventthe algorithm from searching better areas of the learning-space, and restrict it to reach poor localmaxima. The geometry looks superior in some cases, but it is not signi cantly better. However,there seems to be less variability in the quality of the geometrical models across multiple runswhen additivity is enforced.While the details of an extensive comparison between the di erent initialization methods arebeyond the scope of this paper, we point out that our studies of both small and large modelsshow that when large models and long data sequences are involved, random initialization oftenresults in lower KL-divergence than the tag-based initialization. This again has to do with thestrong bias of tag-based initialization, which can lead to very peaked models compared with theless-peaked distributions associated with the true model. Random initialization leads to attermodels. As the KL-divergence strongly penalizes models that are much more peaked than thetrue ones, randomly initialized models are often closer, in terms of this measure, to the truemodels than the very peaked ones learnt from other initial models. When learning small models,where su cient training data is available, the tag-based initialization results in models that areclearly superior to the random ones. Again, the reader is referred to the complete report of thiswork (Shatkay, 1999) for a comparative study of all initialization methods under the varioussettings.6.4 Results within a Relative FrameworkWe applied the algorithm described in Section 4.3, extended to accommodate the state-relativeconstraints (as listed in Section 3.3.2). The data used was gathered by the robot from thesame environment, and generated from the same simulated model as before (Figures 11, 12).However, here the data is generated without assuming perpendicularity. This means that the xand y coordinates are not realigned after each turn with the global x and y axes, but rather,recorded \\as-is.\" The evaluation methods stay as described above.Figure 18 shows the projection of the odometric readings that Ramona recorded along thex and y dimensions, while traversing this environment. For obtaining statistically su cientinformation, we generated 5 data sequences, each of length 800, using Monte Carlo samplingfrom the hidden Markov model whose projection is shown in Figure 12. One of these sequencesis depicted in Figure 19.Figure 20 shows a typical model obtained by applying the algorithm enforcing the completegeometrical consistency, to the robot data shown in Figure 18, using tag-based initialization.We note that the rectangular geometry of the environment is preserved, although state 0 doesnot participate in the loop. This is explained by observing the corresponding area of the trueenvironment as depicted in Figure 11, consisting of the 4 states clustered at the bottom leftcorner (0, 14, 15 and 16). Due to the relatively large number of states that are close together inthat area of the true environment, it was not recognized that we ever returned particularly tostate 0 during the loop. Therefore, there was only one transition recorded from state 0 to state198\nLearning Geometrically-Constrained HMMs\n0\n1\n2 3\n4 5\n6\n7\n89\n10\n11\n12\n13\n14 15\n16\nFigure 20: Learnt model of the corridors Ramona traversed. Initialization is tag-based.1 according to the expected transition counts calculated by the algorithm. When projecting theangles to maintain additivity, (as described in Section 4.3.2), the angle from state 0 to 1 wastherefore compromised, allowing geometrical consistency to maintain the rectangular geometryamong the more regularly visited states.For the purpose of quantitatively evaluating the learning algorithm we list in Table 2 the kldivergence between the true and learnt model, as well as the number of iterations until conver-gence was reached, for each of the 5 simulation sequences with/without odometric information,averaged over 10 runs per sequence. The table demonstrates that the kl divergence with re-spect to the true model for models learnt using odometric data, is about 8 times smaller thanfor models learnt without it. To check the signi cance of our results we again use the simpletwo-sample t-test. The models learnt using odometric information have highly statistically sig-ni cantly (p 0:0005) lower average kl divergence than the others. In addition, the number of199\nShatkay & KaelblingSeq. # 1 2 3 4 5With kl 1.46 1.18 1.20 1.02 1.22Odo Iter # 11.8 36.8 30.7 24.6 33.3No kl 6.91 9.93 10.03 9.54 12.43Odo Iter # 113.3 113.1 102.0 104.2 112.5Table 2: Average results of 2 learning settings with 5 training sequences.iterations required for convergence when learning using odometric information is smaller thanrequired when ignoring such information. Again, the t-test veri es the signi cance (p < 0:005)of this result.It is important to point out that the number of iterations, although much lower, does not auto-matically imply that our algorithm runs in less time than the non-odometric Baum-Welch. Themajor bottleneck is caused by the need to compute within the forward-backward calculations,as described in Section 4.2.1, the values of the normal and the von-Mises densities. These re-quire the calculation of exponent terms rather than simple multiplications, slowing down eachiteration, under the current na ve implementation. However, we can solve this by augmentingthe program with look-up tables for obtaining the relevant values rather than calculating them.In addition, we can take advantage of the symmetry in the relations table to cut down on theamount of calculation required. It is also possible to use the fact that many odometric rela-tions remain unchanged (particularly in the later iterations of the algorithm) from one iterationto the next, and therefore values can be cached and shared between iterations rather than berecalculated at each iteration.6.5 Reducing the Amount of DataLearning hmms obviously requires visiting states and transitioning between them multiple times,to gather su cient data for robust statistical estimation. Intuitively, exploiting odometric datacan help reduce the number of visits needed for obtaining a reliable model.To examine the in uence of reduction in the length of data sequences on the quality of the learntmodels, we took one of the 5 sequences and used its pre xes of length 100 to 800 (the completesequence), in increments of 100, as training sequences. We ran the two algorithmic settings overeach of the 8 pre x sequences, 10 times repeatedly. We then used the kl-divergence as describedabove to evaluate each of the resulting models with respect to the true model. For each pre xlength we averaged the kl-divergence over the 10 runs.The plot in Figure 21 depicts the average kl-divergence as a function of the sequence length foreach of the two settings. It demonstrates that, in terms of the kl divergence, our algorithm,which uses odometric information, is robust in the face of data reduction, (down to 200 datapoints). In contrast, learning without the use of odometry quickly deteriorates as the amountof data is reduced.We note that the data sequence is twice as \\wide\" when odometry is used than when it isnot; that is, there is more information in each element of the sequence when odometry data isrecorded. However, the e ort of recording this additional odometric information is negligible,and is well rewarded by the fact that fewer observations and less exploration are required forobtaining a data sequence su cient for adequate learning.200\nLearning Geometrically-Constrained HMMs\n0 200 400 600 800 Seq. Length\n10\n20\n30\n40\n50\nKL\nOdometry Used\nNo Odometry\nFigure 21: Average kl divergence as a function of sequence length.7 ConclusionsOdometric information, which is often readily available in the robotics domain, makes it possibleto learn hidden Markov models e ciently and e ectively, while using shorter training sequences.More importantly, in contrast to the traditional perception of viewing the topological and thegeometric models as two distinct types of entities, we have shown that the odometric informationcan be directly incorporated into the traditional topological hmm model, while maintainingconvergence of the reestimation algorithm to a local maximum of the likelihood function.Our method uses the odometric information in two ways. We rst choose an initial model,based on the odometric information. An iterative procedure, which extends the Baum-Welchalgorithm, is then used to learn the topological model of the environment while learning anadditional set of constrained geometric parameters. The additional set of constrained parame-ters constitutes an extension to the basic hmm/pomdp model of transitions and observations.Even though we are primarily interested in the underlying topological model (transition andobservation probabilities), our experiments demonstrate that the use of odometric relations canreduce the number of iterations and the amount of data required by the algorithm, and improvethe resulting model.The initialization procedure and the enforcement of the additivity constraint over relativelysmall models prove helpful both topologically and geometrically. An extensive study (Shatkay,1999) shows that for long data sequences, generated from large models, enforcing only anti-symmetry rather than additivity, leads to better topological models. This is because in thesecases, initialization is not always good, and additivity may over-constrain the learning to anunfavorable area. Learning large models may bene t from enforcing only anti-symmetry duringthe rst few iterations, and complete additivity in later iterations. Alternatively, we may use ouralgorithm, enforcing additivity, to learn separate models for small portions of the environment,combining them later into one complete model. A similar idea of combining small model-fragments into a complete map of an environments was applied, in the context of geometricalmaps, in recent work by Leonard and Feder (2000).201\nShatkay & KaelblingThe work presented here demonstrates how domain-speci c information and constraints can beenforced as part of the statistical estimation process, resulting in better models, while requiringshorter data sequences. We strongly believe that this idea can be applied in domains other thanrobotics. In particular, the acquisition of hmms for use in molecular biology may greatly bene tfrom exploiting geometrical (and other) constraints on molecular structures. Similarly, temporalconstraints may be exploited in domains in which pomdps are appropriate for decision-support,such as air-tra c control and medicine.AcknowledgmentsWe thank Sebastian Thrun for his insightful comments throughout this work, John Hughes and Luis Ortizfor their helpful advice, Anthony Cassandra for his code for generating random distributions, Bill Smartfor sustaining Ramona and Jim Kurien for providing the low level code for driving her. The presentationin this paper has bene ted from the comments made by the anonymous referees to whom we are grateful.This work was done while both authors were at the Computer Science department at Brown University,and was supported by DARPA/Rome Labs Planning Initiative grant F30602-95-1-0020, by NSF grantsIRI-9453383 and IRI-9312395, and by the Brown University Graduate Research Fellowship.\n202\nLearning Geometrically-Constrained HMMsAppendix A. An Overview of the Odometric Learning AlgorithmThe algorithm takes as input an experience sequence E = hr; V i, consisting of the odometricsequence r and the observation sequence V , as de ned in the beginning of Section 4.2. Thenumber of states is also assumed to be given.Learn Odometric HMM(E)1 Initialize matrices A;B;R (See Section 5)2 max change 13 while ( max change > )4 do Calculate Forward probabilities, (Equation 4)5 Calculate Backward probabilities, (Equation 5)6 Calculate state-occupation probabilities, (Equation 6)7 Calculate State-transition probabilities, ; (Equation 7)8 Old A A; Old B B9 A Reestimate (A) (Equation 8, left)10 B Reestimate (B) (Equation 8, right)11 R Reestimate (R ) (Equations 12 and 13)12 hRx; Ryi Reestimate(Rx; Ry) (Equations 10 and 11)13 max change MAX(Get Max Change(A; Old A );Get Max Change(B; Old B ))The equations referenced in Step 12 correspond to updates under the perpendicularity assump-tion, where a global framework is used. See (Shatkay, 1999) for update formulae within astate-relative framework.If additivity is enforced, step 11 is followed by a projection of the reestimated R onto an additivea ne space, as described in Section 4.3.2. In addition, step 12 is substituted by the proceduredescribed in Section 4.3.1. The reader is referred again to (Shatkay, 1999) for further detail.Get Max Change is a function that takes two matrices and returns the maximal element-wiseabsolute di erence between them. is a constant set to denote the margin of error on changesin parameters. When the change in parameters is \\small enough\", the model is regarded as\\unchanged\".\n203\nShatkay & KaelblingReferencesAbe, N., & Warmuth, M. K. (1992). On the computational complexity of approximating distri-butions by probabilistic automata. Machine Learning, 9 (2), 205{260.Angluin, D. (1987). Learning regular sets from queries and counterexamples. Information andComputation, 75, 87{106.Asada, M. (1991). Map building for a mobile robot from sensory data. In Iyengar, S. S., &Elfes, A. (Eds.), Autonomous Mobile Robots, pp. 312{322. IEEE Computer Society Press.Bartels, R. (1984). Estimation in a bidirectional mixture of von Mises distributions. Biometrics,40, 777{784.Basye, K., Dean, T., & Kaelbling, L. P. (1995). Learning dynamics: System identi cation forperceptually challenged agents. Arti cial Intelligence, 72 (1).Baum, L. E., Petrie, T., Soules, G., & Weiss, N. (1970). A maximization technique occurringin the statistical analysis of probabilistic functions of Markov chains. The Annals ofMathematical Statistics, 41 (1), 164{171.Cassandra, A. R., Kaelbling, L. P., & Kurien, J. A. (1996). Acting under uncertainty: DiscreteBayesian models for mobile-robot navigation. In Proceedings of IEEE/RSJ InternationalConference on Intelligent Robots and Systems.DeGroot, M. H. (1986). Probability and Statistics (2nd edition). Addison-Wesley.Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood from incompletedata via the EM algorithm. Journal of the Royal Statistical Society, 39 (1), 1{38.Dissanayake, G., Newman, P., Clark, S., Durrant-Whyte, H. F., & Csorba, M. (2001). A solutionto the simultaneous localization and map building (SLAM) problem. IEEE Transactionson Robotics and Automation, 17 (3).Duda, R. O., & Hart, P. E. (1973). Unsupervised Learning and Clustering, chap. 6. John Wileyand Sons.Elfes, A. (1989). Using occupancy grids for mobile robot perception and navigation. Computer,Special Issue on Autonomous Intelligent Machines, 22 (6), 46{57.Engelson, S. P., & McDermott, D. V. (1992). Error correction in mobile robot map learning.In Proceedings of the IEEE International Conference on Robotics and Automation, pp.2555{2560, Nice, France.Gold, E. M. (1978). Complexity of automaton identi cation from given data. Information andControl, 37, 302{320.Gumbel, E. G., Greenwood, J. A., & Durand, D. (1953). The circular normal distribution:Theory and tables. American Statistical Society Journal, 48, 131{152.Hopcroft, J. E., & Ullman, J. D. (1979). Introduction to Automata Theory, Languages, andComputation. Addison & Wesley. 204\nLearning Geometrically-Constrained HMMsJuang, B. H. (1985). Maximum likelihood estimation for mixture multivariate stochastic obser-vations of Markov chains. AT&T Technical Journal, 64 (6).Juang, B. H., & Rabiner, L. R. (1985). A probabilistic distance measure for hidden Markovmodels. AT&T Technical Journal, 64 (2), 391{408.Koenig, S., & Simmons, R. G. (1996a). Passive distance learning for robot navigation. InProceedings of the Thirteenth International Conference on Machine Learning, pp. 266{274.Koenig, S., & Simmons, R. G. (1996b). Unsupervised learning of probabilistic models for robotnavigation. In Proceedings of the IEEE International Conference on Robotics and Automa-tion.Kuipers, B., & Byun, Y.-T. (1991). A robot exploration and mapping strategy based on a se-mantic hierarchy of spatial representations. Journal of Robotics and Autonomous Systems,8, 47{63.Kullback, S., & Leibler, R. A. (1951). On information and su ciency. Annals of MathematicalStatistics, 22 (1), 79{86.Leonard, J., Durrant-Whyte, H. F., & Cox, I. J. (1991). Dynamic map building for an au-tonomous mobile robot. In Iyengar, S. S., & Elfes, A. (Eds.), Autonomous Mobile Robots,pp. 331{338. IEEE Computer Society Press.Leonard, J. J., & Feder, H. J. S. (2000). A computationally e cient method for large-scale con-current mapping and localization. In Hollerbach, J., & Kodischek, D. (Eds.), Proceedingsof the Ninth International Symposium on Robotics Research.Liporace, L. A. (1982). Maximum likelihood estimation for multivariate observations of Markovsources. IEEE Transactions on Information Theory, 28 (5).Mardia, K. V. (1972). Statistics of Directional Data. Academic Press.Mataric, M. J. (1990). A distributed model for mobile robot environment-learning and naviga-tion. Master's thesis, MIT, Arti cial Intelligence Laboratory.McLachlan, G. J., & Krishnan, T. (1997). The EM Algorithm and Extensions. John Wiley &Sons.Moravec, H. P. (1988). Sensor fusion in certainty grids for mobile robots. AI Magazine, 9 (2),61{74.Moravec, H. P., & Elfes, A. (1985). High resolution maps from wide angle sonar. In Proceedingsof the International Conference on Robotics and Automation, pp. 116{121.Nourbakhsh, I., Powers, R., & Birch eld, S. (1995). Dervish: An o ce-navigating robot. AIMagazine, 16 (1), 53{60.Pierce, D., & Kuipers, B. (1997). Map learning with uninterpreted sensors and e ectors. Arti- cial Intelligence, 92 (1-2), 169{227. 205\nShatkay & KaelblingRabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speechrecognition. Proceedings of the IEEE, 77 (2), 257{285.Rivest, R. L., & Schapire, R. E. (1987). Diversity based inference of nite automata. InProceedings of the IEEE Twenty Eighth Annual Symposium on Foundations of ComputerScience, pp. 78{87, Los Angeles, California.Rivest, R. L., & Schapire, R. E. (1989). Inference of nite automata using homing sequences. InProceedings of the Twenty First Annual Symposium on Theory of Computing, pp. 411{420,Seattle, Washington.Ron, D., Singer, Y., & Tishbi, N. (1994). Learning probabilistic automata with variable mem-ory length. In Proceedings of the Seventh Annual Workshop on Computational LearningTheory, pp. 35{46.Ron, D., Singer, Y., & Tishbi, N. (1995). On the learnability and usage of acyclic probabilistic nite automata. In Proceedings of the Eighth Annual Workshop on Computational LearningTheory, pp. 31{40.Ron, D., Singer, Y., & Tishby, N. (1998). On the learnability and usage of acyclic probabilistic nite automata. Journal of Computer and Systems Science, 56 (2).Shatkay, H. (1999). Learning Models for Robot Navigation. Ph.D. thesis, Department of Com-puter Science, Brown University, Providence, RI.Shatkay, H., & Kaelbling, L. P. (1997). Learning topological maps with weak local odometricinformation. In Proceedings of the Fifteenth International Joint Conference on Arti cialIntelligence, Nagoya, Japan.Shatkay, H., & Kaelbling, L. P. (1998). Heading in the right direction. In Proceedings of theFifteenth International Conference on Machine Learning, Madison, Wisconsin.Simmons, R. G., & Koenig, S. (1995). Probabilistic navigation in partially observable environ-ments. In Proceedings of the International Joint Conference on Arti cial Intelligence.Smith, R., Self, M., & Cheeseman, P. (1991). A stochastic map for uncertain spatial relation-ships. In Iyengar, S. S., & Elfes, A. (Eds.), Autonomous Mobile Robots, pp. 323{330. IEEEComputer Society Press.Thrun, S. (1999). Learning metric-topological maps for indoor mobile robot navigation. AIJournal, 1, 21{71.Thrun, S., & B ucken, A. (1996a). Integrating grid-based and topological maps for mobile robotnavigation. In Proceedings of the Thirteenth National Conference on Arti cial Intelligence,pp. 944{950.Thrun, S., & B ucken, A. (1996b). Learning maps for indoor mobile robot navigation. Tech. rep.CMU-CS-96-121, School of Computer Science, Carnegie Mellon University, Pittsburgh,PA.Thrun, S., Burgard, W., & Fox, D. (1998a). A probabilistic approach to concurrent map acqui-sition and localization for mobile robots. Machine Learning, 31, 29{53.206\nLearning Geometrically-Constrained HMMsThrun, S., Gutmann, J.-S., Fox, D., Burgard, W., & Kuipers, B. J. (1998b). Integrating topolog-ical and metric maps for mobile robot navigation: A statistical approach. In Proceedingsof the Fifteenth National Conference on Arti cial Intelligence, pp. 989{995.Vapnik, V. N. (1995). The Nature of Statistical Learning Theory. Springer.\n207"}], "references": [{"title": "On the computational complexity of approximating distri", "author": ["N. Abe", "M.K. Warmuth"], "venue": null, "citeRegEx": "Abe and Warmuth,? \\Q1992\\E", "shortCiteRegEx": "Abe and Warmuth", "year": 1992}, {"title": "Learning regular sets from queries and counterexamples", "author": ["D. Angluin"], "venue": null, "citeRegEx": "Angluin,? \\Q1987\\E", "shortCiteRegEx": "Angluin", "year": 1987}, {"title": "Map building for a mobile robot from sensory data", "author": ["M. Asada"], "venue": null, "citeRegEx": "Asada,? \\Q1991\\E", "shortCiteRegEx": "Asada", "year": 1991}, {"title": "Estimation in a bidirectional mixture of von Mises distributions", "author": ["R. Bartels"], "venue": null, "citeRegEx": "Bartels,? \\Q1984\\E", "shortCiteRegEx": "Bartels", "year": 1984}, {"title": "Learning dynamics: System", "author": ["K. Basye", "T. Dean", "L.P. Kaelbling"], "venue": null, "citeRegEx": "Basye et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Basye et al\\.", "year": 1995}, {"title": "A maximization technique occurring", "author": ["L.E. Baum", "T. Petrie", "G. Soules", "N. Weiss"], "venue": null, "citeRegEx": "Baum et al\\.,? \\Q1970\\E", "shortCiteRegEx": "Baum et al\\.", "year": 1970}, {"title": "Probability and Statistics (2nd edition)", "author": ["M.H. DeGroot"], "venue": null, "citeRegEx": "DeGroot,? \\Q1986\\E", "shortCiteRegEx": "DeGroot", "year": 1986}, {"title": "Maximum likelihood from incomplete", "author": ["A.P. Dempster", "N.M. Laird", "D.B. Rubin"], "venue": null, "citeRegEx": "Dempster et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Dempster et al\\.", "year": 1977}, {"title": "Unsupervised Learning and Clustering, chap", "author": ["R.O. Duda", "P.E. Hart"], "venue": null, "citeRegEx": "Duda and Hart,? \\Q1973\\E", "shortCiteRegEx": "Duda and Hart", "year": 1973}, {"title": "Using occupancy grids for mobile robot perception and navigation", "author": ["A. Elfes"], "venue": null, "citeRegEx": "Elfes,? \\Q1989\\E", "shortCiteRegEx": "Elfes", "year": 1989}, {"title": "Error correction in mobile robot map learning", "author": ["S.P. Engelson", "D.V. McDermott"], "venue": null, "citeRegEx": "Engelson and McDermott,? \\Q1992\\E", "shortCiteRegEx": "Engelson and McDermott", "year": 1992}, {"title": "Complexity of automaton identi cation from given data", "author": ["E.M. Gold"], "venue": null, "citeRegEx": "Gold,? \\Q1978\\E", "shortCiteRegEx": "Gold", "year": 1978}, {"title": "Introduction to Automata", "author": ["J.E. Hopcroft", "J.D. Ullman"], "venue": null, "citeRegEx": "Hopcroft and Ullman,? \\Q1979\\E", "shortCiteRegEx": "Hopcroft and Ullman", "year": 1979}, {"title": "Maximum likelihood estimation for mixture multivariate stochastic obser", "author": ["B.H. Juang"], "venue": null, "citeRegEx": "Juang,? \\Q1985\\E", "shortCiteRegEx": "Juang", "year": 1985}, {"title": "A probabilistic distance measure for", "author": ["B.H. Juang", "L.R. Rabiner"], "venue": null, "citeRegEx": "Juang and Rabiner,? \\Q1985\\E", "shortCiteRegEx": "Juang and Rabiner", "year": 1985}, {"title": "Passive distance learning for robot navigation", "author": ["S. Koenig", "R.G. Simmons"], "venue": null, "citeRegEx": "Koenig and Simmons,? \\Q1996\\E", "shortCiteRegEx": "Koenig and Simmons", "year": 1996}, {"title": "Unsupervised learning of probabilistic models for robot", "author": ["S. Koenig", "R.G. Simmons"], "venue": null, "citeRegEx": "Koenig and Simmons,? \\Q1996\\E", "shortCiteRegEx": "Koenig and Simmons", "year": 1996}, {"title": "A robot exploration and mapping strategy based on", "author": ["B. Kuipers", "Byun", "Y.-T"], "venue": null, "citeRegEx": "Kuipers et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Kuipers et al\\.", "year": 1991}, {"title": "On information and su ciency", "author": ["S. Kullback", "R.A. Leibler"], "venue": null, "citeRegEx": "Kullback and Leibler,? \\Q1951\\E", "shortCiteRegEx": "Kullback and Leibler", "year": 1951}, {"title": "Dynamic map building for an au", "author": ["J. Leonard", "H.F. Durrant-Whyte", "I.J. Cox"], "venue": null, "citeRegEx": "Leonard et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Leonard et al\\.", "year": 1991}, {"title": "A computationally e cient method for large-scale", "author": ["J.J. Leonard", "H.J.S. Feder"], "venue": null, "citeRegEx": "Leonard and Feder,? \\Q2000\\E", "shortCiteRegEx": "Leonard and Feder", "year": 2000}, {"title": "Maximum likelihood estimation for multivariate observations", "author": ["L.A. Liporace"], "venue": null, "citeRegEx": "Liporace,? \\Q1982\\E", "shortCiteRegEx": "Liporace", "year": 1982}, {"title": "Statistics of Directional Data", "author": ["K.V. Mardia"], "venue": null, "citeRegEx": "Mardia,? \\Q1972\\E", "shortCiteRegEx": "Mardia", "year": 1972}, {"title": "A distributed model for mobile robot environment-learning and naviga", "author": ["M.J. Mataric"], "venue": null, "citeRegEx": "Mataric,? \\Q1990\\E", "shortCiteRegEx": "Mataric", "year": 1990}, {"title": "The EM Algorithm and Extensions", "author": ["G.J. McLachlan", "T. Krishnan"], "venue": null, "citeRegEx": "McLachlan and Krishnan,? \\Q1997\\E", "shortCiteRegEx": "McLachlan and Krishnan", "year": 1997}, {"title": "Sensor fusion in certainty grids for mobile robots", "author": ["H.P. Moravec"], "venue": "AI Magazine,", "citeRegEx": "Moravec,? \\Q1988\\E", "shortCiteRegEx": "Moravec", "year": 1988}, {"title": "High resolution maps from wide angle sonar", "author": ["H.P. Moravec", "A. Elfes"], "venue": null, "citeRegEx": "Moravec and Elfes,? \\Q1985\\E", "shortCiteRegEx": "Moravec and Elfes", "year": 1985}, {"title": "Dervish: An o ce-navigating", "author": ["I. Nourbakhsh", "R. Powers", "S. Birch eld"], "venue": null, "citeRegEx": "Nourbakhsh et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Nourbakhsh et al\\.", "year": 1995}, {"title": "Map learning with uninterpreted sensors and e ectors", "author": ["D. Pierce", "B. Kuipers"], "venue": null, "citeRegEx": "Pierce and Kuipers,? \\Q1997\\E", "shortCiteRegEx": "Pierce and Kuipers", "year": 1997}, {"title": "A tutorial on hidden Markov models and selected applications in speech", "author": ["L.R. Rabiner"], "venue": null, "citeRegEx": "Rabiner,? \\Q1989\\E", "shortCiteRegEx": "Rabiner", "year": 1989}, {"title": "Diversity based inference of nite automata", "author": ["R.L. Rivest", "R.E. Schapire"], "venue": null, "citeRegEx": "Rivest and Schapire,? \\Q1987\\E", "shortCiteRegEx": "Rivest and Schapire", "year": 1987}, {"title": "Inference of nite automata using homing sequences", "author": ["R.L. Rivest", "R.E. Schapire"], "venue": null, "citeRegEx": "Rivest and Schapire,? \\Q1989\\E", "shortCiteRegEx": "Rivest and Schapire", "year": 1989}, {"title": "Learning probabilistic automata with variable", "author": ["D. Ron", "Y. Singer", "N. Tishbi"], "venue": null, "citeRegEx": "Ron et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Ron et al\\.", "year": 1994}, {"title": "On the learnability and usage of acyclic probabilistic", "author": ["D. Ron", "Y. Singer", "N. Tishbi"], "venue": null, "citeRegEx": "Ron et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Ron et al\\.", "year": 1995}, {"title": "On the learnability and usage of acyclic probabilistic", "author": ["D. Ron", "Y. Singer", "N. Tishby"], "venue": null, "citeRegEx": "Ron et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Ron et al\\.", "year": 1998}, {"title": "Learning Models for Robot Navigation", "author": ["H. Shatkay"], "venue": "Ph.D. thesis,", "citeRegEx": "Shatkay,? \\Q1999\\E", "shortCiteRegEx": "Shatkay", "year": 1999}, {"title": "Learning topological maps with weak local odometric", "author": ["H. Shatkay", "L.P. Kaelbling"], "venue": null, "citeRegEx": "Shatkay and Kaelbling,? \\Q1997\\E", "shortCiteRegEx": "Shatkay and Kaelbling", "year": 1997}, {"title": "Heading in the right direction", "author": ["H. Shatkay", "L.P. Kaelbling"], "venue": null, "citeRegEx": "Shatkay and Kaelbling,? \\Q1998\\E", "shortCiteRegEx": "Shatkay and Kaelbling", "year": 1998}, {"title": "Probabilistic navigation in partially observable environ", "author": ["R.G. Simmons", "S. Koenig"], "venue": null, "citeRegEx": "Simmons and Koenig,? \\Q1995\\E", "shortCiteRegEx": "Simmons and Koenig", "year": 1995}, {"title": "A stochastic map for uncertain spatial", "author": ["R. Smith", "M. Self", "P. Cheeseman"], "venue": null, "citeRegEx": "Smith et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Smith et al\\.", "year": 1991}, {"title": "Learning metric-topological maps for indoor mobile robot", "author": ["S. Thrun"], "venue": null, "citeRegEx": "Thrun,? \\Q1999\\E", "shortCiteRegEx": "Thrun", "year": 1999}, {"title": "Integrating grid-based and topological maps for mobile robot", "author": ["A. ucken"], "venue": null, "citeRegEx": "ucken,? \\Q1996\\E", "shortCiteRegEx": "ucken", "year": 1996}, {"title": "Learning maps for indoor mobile robot navigation", "author": ["A. ucken"], "venue": null, "citeRegEx": "ucken,? \\Q1996\\E", "shortCiteRegEx": "ucken", "year": 1996}, {"title": "A probabilistic approach to concurrent map acqui", "author": ["S. Thrun", "W. Burgard", "D. Fox"], "venue": null, "citeRegEx": "Thrun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Thrun et al\\.", "year": 1998}, {"title": "The Nature of Statistical Learning", "author": ["V.N. Vapnik"], "venue": null, "citeRegEx": "Vapnik,? \\Q1995\\E", "shortCiteRegEx": "Vapnik", "year": 1995}], "referenceMentions": [{"referenceID": 29, "context": "The assumption underlying their work was that a human provides a rather accurate topological model of the states and their connections, and the exact probability distributions are then learned on top of this model, using a version of the Baum-Welch algorithm (Rabiner, 1989).", "startOffset": 259, "endOffset": 274}, {"referenceID": 40, "context": "Another interesting approach to the acquisition of topological models is that of Thrun and B\u007f ucken (1996a,1996b; Thrun, 1999), who focused on extracting deterministic topological maps from previously acquired geometricalgrid-based maps, where the latter were learned directly from the data.", "startOffset": 100, "endOffset": 126}, {"referenceID": 29, "context": "The assumption underlying their work was that a human provides a rather accurate topological model of the states and their connections, and the exact probability distributions are then learned on top of this model, using a version of the Baum-Welch algorithm (Rabiner, 1989). Another interesting approach to the acquisition of topological models is that of Thrun and B\u007f ucken (1996a,1996b; Thrun, 1999), who focused on extracting deterministic topological maps from previously acquired geometricalgrid-based maps, where the latter were learned directly from the data. Further discussion of related research on both the geometrical and the topological approaches, in their probabilistic and deterministic versions, is given in the next section. The work reported here is the rst successful attempt we are aware of to learn purely probabilistictopological models, directly and completely from recorded data, without using previous humanprovided or grid-based models. It is based on using weak geometric information, recorded by the robot, to help learn the topology of the environment, and represent it as a probabilistic model. Therefore, it directly bridges the historically perceived gap between topological and geometrical information, and addresses the claim presented in Thrun's work (1999) that the main shortcoming of the topological approach is its failure to utilize the inherent geometry of the learnt environment.", "startOffset": 260, "endOffset": 1295}, {"referenceID": 35, "context": "A more comprehensive review of theoretical results is given by Shatkay (1999). 2.", "startOffset": 63, "endOffset": 78}, {"referenceID": 25, "context": "A lot of work has been done on learning such grid-based maps for robot navigation through the use of sonar readings and their interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes, 1989; Asada, 1991).", "startOffset": 174, "endOffset": 238}, {"referenceID": 9, "context": "A lot of work has been done on learning such grid-based maps for robot navigation through the use of sonar readings and their interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes, 1989; Asada, 1991).", "startOffset": 174, "endOffset": 238}, {"referenceID": 2, "context": "A lot of work has been done on learning such grid-based maps for robot navigation through the use of sonar readings and their interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes, 1989; Asada, 1991).", "startOffset": 174, "endOffset": 238}, {"referenceID": 29, "context": "To achieve this, the authors use a forward-backward procedure similar to the one used in the Baum-Welch algorithm (Rabiner, 1989), in order to determine possible locations from observed data.", "startOffset": 114, "endOffset": 129}, {"referenceID": 2, "context": "A lot of work has been done on learning such grid-based maps for robot navigation through the use of sonar readings and their interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes, 1989; Asada, 1991). An underlying assumption when learning such maps is that the robot can tell (or nd out) where it is on the grid when it obtains a sonar reading indicating an object, and therefore can place the object correctly on the grid. A similar localization assumption, requiring the robot to identify its geometrical location, underlies other geometric mapping techniques by Leonard et al. (1991), Smith et al.", "startOffset": 226, "endOffset": 627}, {"referenceID": 2, "context": "A lot of work has been done on learning such grid-based maps for robot navigation through the use of sonar readings and their interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes, 1989; Asada, 1991). An underlying assumption when learning such maps is that the robot can tell (or nd out) where it is on the grid when it obtains a sonar reading indicating an object, and therefore can place the object correctly on the grid. A similar localization assumption, requiring the robot to identify its geometrical location, underlies other geometric mapping techniques by Leonard et al. (1991), Smith et al. (1991), Thrun et al.", "startOffset": 226, "endOffset": 648}, {"referenceID": 2, "context": "A lot of work has been done on learning such grid-based maps for robot navigation through the use of sonar readings and their interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes, 1989; Asada, 1991). An underlying assumption when learning such maps is that the robot can tell (or nd out) where it is on the grid when it obtains a sonar reading indicating an object, and therefore can place the object correctly on the grid. A similar localization assumption, requiring the robot to identify its geometrical location, underlies other geometric mapping techniques by Leonard et al. (1991), Smith et al. (1991), Thrun et al. (1998b) and Dissanayake et al.", "startOffset": 226, "endOffset": 670}, {"referenceID": 2, "context": "A lot of work has been done on learning such grid-based maps for robot navigation through the use of sonar readings and their interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes, 1989; Asada, 1991). An underlying assumption when learning such maps is that the robot can tell (or nd out) where it is on the grid when it obtains a sonar reading indicating an object, and therefore can place the object correctly on the grid. A similar localization assumption, requiring the robot to identify its geometrical location, underlies other geometric mapping techniques by Leonard et al. (1991), Smith et al. (1991), Thrun et al. (1998b) and Dissanayake et al. (2001), even when an explicit grid is not part of the model.", "startOffset": 226, "endOffset": 700}, {"referenceID": 2, "context": "A lot of work has been done on learning such grid-based maps for robot navigation through the use of sonar readings and their interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes, 1989; Asada, 1991). An underlying assumption when learning such maps is that the robot can tell (or nd out) where it is on the grid when it obtains a sonar reading indicating an object, and therefore can place the object correctly on the grid. A similar localization assumption, requiring the robot to identify its geometrical location, underlies other geometric mapping techniques by Leonard et al. (1991), Smith et al. (1991), Thrun et al. (1998b) and Dissanayake et al. (2001), even when an explicit grid is not part of the model. Explicit localization can be hard to satisfy. Leonard et al. (1991) and Smith et al.", "startOffset": 226, "endOffset": 822}, {"referenceID": 2, "context": "A lot of work has been done on learning such grid-based maps for robot navigation through the use of sonar readings and their interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes, 1989; Asada, 1991). An underlying assumption when learning such maps is that the robot can tell (or nd out) where it is on the grid when it obtains a sonar reading indicating an object, and therefore can place the object correctly on the grid. A similar localization assumption, requiring the robot to identify its geometrical location, underlies other geometric mapping techniques by Leonard et al. (1991), Smith et al. (1991), Thrun et al. (1998b) and Dissanayake et al. (2001), even when an explicit grid is not part of the model. Explicit localization can be hard to satisfy. Leonard et al. (1991) and Smith et al. (1991) address this issue through the use of geometrical beacons to estimate the location of the robot.", "startOffset": 226, "endOffset": 846}, {"referenceID": 2, "context": "A lot of work has been done on learning such grid-based maps for robot navigation through the use of sonar readings and their interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes, 1989; Asada, 1991). An underlying assumption when learning such maps is that the robot can tell (or nd out) where it is on the grid when it obtains a sonar reading indicating an object, and therefore can place the object correctly on the grid. A similar localization assumption, requiring the robot to identify its geometrical location, underlies other geometric mapping techniques by Leonard et al. (1991), Smith et al. (1991), Thrun et al. (1998b) and Dissanayake et al. (2001), even when an explicit grid is not part of the model. Explicit localization can be hard to satisfy. Leonard et al. (1991) and Smith et al. (1991) address this issue through the use of geometrical beacons to estimate the location of the robot. In what is known as the Kalman lter method, a Gaussian probability distribution is used to model the robot's possible current location, based on observations collected up to the current point, (without allowing the re nement of previous position estimates based on later observations). Research in this area has recently been extended in two directions: Leonard and Feder (2000) partition the task of learning one large map into learning multiple smaller map-sections, thus addressing the issue of computational e ciency.", "startOffset": 226, "endOffset": 1322}, {"referenceID": 2, "context": "A lot of work has been done on learning such grid-based maps for robot navigation through the use of sonar readings and their interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes, 1989; Asada, 1991). An underlying assumption when learning such maps is that the robot can tell (or nd out) where it is on the grid when it obtains a sonar reading indicating an object, and therefore can place the object correctly on the grid. A similar localization assumption, requiring the robot to identify its geometrical location, underlies other geometric mapping techniques by Leonard et al. (1991), Smith et al. (1991), Thrun et al. (1998b) and Dissanayake et al. (2001), even when an explicit grid is not part of the model. Explicit localization can be hard to satisfy. Leonard et al. (1991) and Smith et al. (1991) address this issue through the use of geometrical beacons to estimate the location of the robot. In what is known as the Kalman lter method, a Gaussian probability distribution is used to model the robot's possible current location, based on observations collected up to the current point, (without allowing the re nement of previous position estimates based on later observations). Research in this area has recently been extended in two directions: Leonard and Feder (2000) partition the task of learning one large map into learning multiple smaller map-sections, thus addressing the issue of computational e ciency. Dissanayake et al. (2001) conduct a theoretical study of the approach and show its convergence properties.", "startOffset": 226, "endOffset": 1491}, {"referenceID": 2, "context": "A lot of work has been done on learning such grid-based maps for robot navigation through the use of sonar readings and their interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes, 1989; Asada, 1991). An underlying assumption when learning such maps is that the robot can tell (or nd out) where it is on the grid when it obtains a sonar reading indicating an object, and therefore can place the object correctly on the grid. A similar localization assumption, requiring the robot to identify its geometrical location, underlies other geometric mapping techniques by Leonard et al. (1991), Smith et al. (1991), Thrun et al. (1998b) and Dissanayake et al. (2001), even when an explicit grid is not part of the model. Explicit localization can be hard to satisfy. Leonard et al. (1991) and Smith et al. (1991) address this issue through the use of geometrical beacons to estimate the location of the robot. In what is known as the Kalman lter method, a Gaussian probability distribution is used to model the robot's possible current location, based on observations collected up to the current point, (without allowing the re nement of previous position estimates based on later observations). Research in this area has recently been extended in two directions: Leonard and Feder (2000) partition the task of learning one large map into learning multiple smaller map-sections, thus addressing the issue of computational e ciency. Dissanayake et al. (2001) conduct a theoretical study of the approach and show its convergence properties. The latter may lead to computational e ciency by identifying the cases for which a steady-state solution can be readily obtained, accordingly bounding the number of steps required by the algorithms to reach a useful solution in these cases. Work by Thrun et al. (1998a) uses a similar probabilistic approach for obtaining grid-based maps.", "startOffset": 226, "endOffset": 1842}, {"referenceID": 40, "context": "A nice example of the second approach is provided by Thrun and B\u007f ucken (1996a, 1996b; Thrun, 1999), who use occupancy-grid techniques to build the initial map.", "startOffset": 72, "endOffset": 99}, {"referenceID": 24, "context": "Work by Pierce and Kuipers (1997) discusses an automatic method for extracting abstract states and features from raw perceptual information.", "startOffset": 8, "endOffset": 34}, {"referenceID": 24, "context": "Work by Pierce and Kuipers (1997) discusses an automatic method for extracting abstract states and features from raw perceptual information. Kuipers and Byun (1991) provide a strategy for learning deterministic topological maps.", "startOffset": 8, "endOffset": 165}, {"referenceID": 20, "context": "Mataric (1990) provides an alternative approach for learning deterministic topological maps, represented as distributed graphs.", "startOffset": 0, "endOffset": 15}, {"referenceID": 10, "context": "Engelson and McDermott (1992) learn \\diktiometric\" maps (topological maps with metric relations between nodes) from experience.", "startOffset": 0, "endOffset": 30}, {"referenceID": 11, "context": "This problem has been shown to be np-complete (Gold, 1978).", "startOffset": 46, "endOffset": 58}, {"referenceID": 0, "context": "Angluin (1987) showed that if an oracle can answer membership queries and provide counterexamples to conjectures about the automaton, there is a polynomial time learning algorithm from positive and negative examples.", "startOffset": 0, "endOffset": 15}, {"referenceID": 0, "context": "Angluin (1987) showed that if an oracle can answer membership queries and provide counterexamples to conjectures about the automaton, there is a polynomial time learning algorithm from positive and negative examples. Rivest and Schapire (1987, 1989), provide several e ective methods, that under various settings, learn deterministic automata that are correct with high probability. While the above work deals with learning from noise-free data, Basye, Dean and Kaelbling (1995) presented several algorithms that, with high probability, learn input-output deterministic automata, when the data observed by the learner is corrupted by various forms of noise.", "startOffset": 0, "endOffset": 479}, {"referenceID": 0, "context": "Abe and Warmuth (1992) show that nding a probabilistic automaton with 2 states, even when a small error with respect to the true model is allowed with some probability (the probably approximately correct, or PAC, learning model), cannot be done in polynomial time with polynomial number of examples, unless np = rp.", "startOffset": 0, "endOffset": 23}, {"referenceID": 0, "context": "Abe and Warmuth (1992) show that nding a probabilistic automaton with 2 states, even when a small error with respect to the true model is allowed with some probability (the probably approximately correct, or PAC, learning model), cannot be done in polynomial time with polynomial number of examples, unless np = rp. From their work arises the broadly accepted conjecture, which has not yet been proven, that learning hidden Markov Models is hard even in the pac sense. There are two ways to address this hardness: one is to restrict the class of probabilistic models learned, while the other is to learn unrestricted hidden Markov models with good practical results but with no pac guarantees on the quality of the result. Work by Ron et al. (1994, 1995, 1998) pursues the rst approach, learning restricted classes of automata, namely, acyclic probabilistic nite automata, and probabilistic nite su x automata. Both classes are useful for various applications related to natural language processing, and can be learned in polynomial time within the pac framework. The second approach, which is the one predominantly taken in this work, is to learn a model that is a member of the complete unrestricted class of hidden Markov models. Only weak guarantees exist about the goodness of the model, but the learning procedure may be directed to obtain practically good results. This approach is based on guessing an automaton (model), and using an iterative procedure to make the automaton t better to the training data. One algorithm commonly used for this purpose is the Baum-Welch algorithm (Baum, Petrie, Soules, & Weiss, 1970), which is presented in detail by Rabiner (1989). The iterative updates of the model are 173", "startOffset": 0, "endOffset": 1674}, {"referenceID": 21, "context": "Although our work is concerned with discrete observations, the extension to continuous observations is straightforward and has been well addressed in work on hidden Markov models (Liporace, 1982; Juang, 1985).", "startOffset": 179, "endOffset": 208}, {"referenceID": 13, "context": "Although our work is concerned with discrete observations, the extension to continuous observations is straightforward and has been well addressed in work on hidden Markov models (Liporace, 1982; Juang, 1985).", "startOffset": 179, "endOffset": 208}, {"referenceID": 22, "context": "In a way analogous to Gauss' derivation of the Normal distribution, von Mises developed such a circular version (Gumbel, Greenwood, & Durand, 1953; Mardia, 1972), which is de ned as follows: De nition: A circular random variable, , 0 2 , is said to have the von Mises distribution with parameters and , where 0 2 and > 0, if its probability density 178", "startOffset": 112, "endOffset": 161}, {"referenceID": 22, "context": "The maximum likelihood estimate for the concentration parameter, , is the that satis es: I1( ) I0( ) = max[ 1 n n Xi=1 cos( i ); 0] ; where I1 is the modi ed Bessel function of the rst kind and order 1: I1( ) = 1 X r=0 1 r!(r + 1)! (12 )2r+1 : (3) Further information about the estimation procedure is beyond the scope of this paper and can be found elsewhere (Gumbel et al., 1953; Mardia, 1972).", "startOffset": 360, "endOffset": 395}, {"referenceID": 29, "context": "All studied practical methods, and in particular the well-known BaumWelch algorithm (Rabiner (1989) and references therein) can only guarantee a local-maximum likelihood model.", "startOffset": 85, "endOffset": 100}, {"referenceID": 29, "context": "1 State-Occupation Probabilities Following Rabiner (1989), we rst compute the forward ( ) and backward ( ) matrices.", "startOffset": 43, "endOffset": 58}, {"referenceID": 29, "context": "The state-occupation probabilities, t(i), representing the probability of being in state si at time t given the experience sequence and the current model, are computed as follows: t(i) = Pr(qt = sijE; ) = t(i) t(i) PN 1 j=0 t(j) t(j) : (6) Similarly, t(i; j), the state-transition probabilities from state i to state j at time t given the experience sequence and the current model, are computed as: t(i; j) = Pr(qt = si; qt+1 = sj jE; ) = t(i)Ai;jbjt+1f(rt+1jRi;j) t+1(j) N 1 Xi=0 N 1 Xj=0 t(i)Ai;jbjt+1f(rt+1jRi;j) t+1(j) : (7) These are essentially the same formulae appearing in Rabiner's tutorial (Rabiner, 1989), but they also take into account the density of the odometric relations.", "startOffset": 601, "endOffset": 616}, {"referenceID": 3, "context": "Parameter estimation under this form of constraints is almost untreated in mainstream statistics (Bartels, 1984) and we found no previous existing solutions to the estimation problem addressed here.", "startOffset": 97, "endOffset": 112}, {"referenceID": 6, "context": "If not for the latter constraint, the task is simple (DeGroot, 1986), and we have: P = Pni=1 pi n ; 2 P = Pni=1(pi P )2 n ; and similarly for Q and 2 Q.", "startOffset": 53, "endOffset": 68}, {"referenceID": 35, "context": "3 Thus, the mean is updated using a variance parameter that lags behind it in the update process, and the reestimation Equation (9) needs to use m rather than m as follows: mi;j = PT 2 t=0 h rt[m] t(i;j) ( m i;j )2 rt[m] t(j;i) ( m j;i)2 i PT 2 t=0 h t(i;j) ( m i;j)2 + t(j;i) ( m j;i)2 i : (11) As we have shown (Shatkay, 1999), this lag-behind policy is an instance of generalized em (McLachlan & Krishnan, 1997).", "startOffset": 313, "endOffset": 328}, {"referenceID": 13, "context": "Given a true probability distribution P = fp1; :::; png and a learnt one Q = fq1; :::; qng, the kl divergence of Q with respect to P is: D(P jjQ) def = n Xi=1 pi log2 pi qi : We report our results in terms of a sampled version of the kl divergence, as described by Juang and Rabiner (1985). It is based on generating sequences of su cient length (5 sequences of 1000 observations in our case) according to the distribution induced by the true model, and comparing their log-likelihood according to the learnt model with the true model log-likelihood.", "startOffset": 265, "endOffset": 290}, {"referenceID": 35, "context": "For a comparison of all four settings the reader is referred to the complete report of this work (Shatkay, 1999).", "startOffset": 97, "endOffset": 112}, {"referenceID": 35, "context": "To keep the discussion focused, we concentrate here on the rst and the last of these settings and the reader is referred to a more extensive report (Shatkay, 1999) for a complete discussion.", "startOffset": 148, "endOffset": 163}, {"referenceID": 35, "context": "Again, the reader is referred to the complete report of this work (Shatkay, 1999) for a comparative study of all initialization methods under the various settings.", "startOffset": 66, "endOffset": 81}, {"referenceID": 35, "context": "An extensive study (Shatkay, 1999) shows that for long data sequences, generated from large models, enforcing only antisymmetry rather than additivity, leads to better topological models.", "startOffset": 19, "endOffset": 34}, {"referenceID": 20, "context": "A similar idea of combining small modelfragments into a complete map of an environments was applied, in the context of geometrical maps, in recent work by Leonard and Feder (2000). 201", "startOffset": 155, "endOffset": 180}], "year": 2011, "abstractText": null, "creator": "dvipsk 5.58f Copyright 1986, 1994 Radical Eye Software"}}}