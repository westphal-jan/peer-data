{"id": "1106.3498", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2011", "title": "On the expressive power of unit resolution", "abstract": "This preliminary report deals with the validity of unit resolution in relation to input data encoded with partial allocations of statement variables. It provides a characterization of the functions thus calculated, which we call dispersible functions. By finding that dispersible functions can also be calculated with monotonous circuits, we show that there are polynomial time complexity dispersion functions that require an exponential number of clauses to be calculated using unit resolution. These results shed new light on the investigation of CNF coding of NP complete problems to solve them using statement satisfaction algorithms.", "histories": [["v1", "Fri, 17 Jun 2011 14:35:28 GMT  (19kb)", "http://arxiv.org/abs/1106.3498v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CC", "authors": ["olivier bailleux"], "accepted": false, "id": "1106.3498"}, "pdf": {"name": "1106.3498.pdf", "metadata": {"source": "CRF", "title": "On the expressive power of unit resolution", "authors": ["Olivier Bailleux"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n10 6.\n34 98\nv1 [\ncs .A\nI] 1\n7 Ju\nn 20\n11"}, {"heading": "1 Introduction and motivations", "text": "Unit resolution is a key feature of state of the art sat solvers [13] [7] [5], where it speeds up the search for solutions and inconsistencies.\nIt is well known that different cnf representations of a given problem do not always allow unit resolution to deduce the same information. For example, the cnf encoding for pseudo Boolean constraints proposed in [3] allows unit resolution to restore generalized arc consistency. This is not the case with the encoding proposed in [16], which does not allow unit resolution to deduce as much information as the former encoding does. As a manner of speaking, the expressive power of unit resolution is best exploited using the encoding proposed in [3], with notable consequences on the resolution time.\nTwo important related questions are \"What information can be deduced by unit resolution?\" and \"Which clauses are required in order to allow this information to be deduced?\"\nThese questions are strongly connected to the characterization of the application field of sat solvers: \"Which problems can be solved as efficiently using a sat solver as using a specialized solver?\" and \"How to encode these problems into cnf formulae for optimal resolution time?\"\nIn this paper, we are interested in the functions that can be calculated by means of unit resolution. Studying the expressive power of unit resolution requires characterizing these functions, which will be called propagatable functions, and specifying the size of the formulae required to compute them.\nSection 2 presents the three main research directions related to the expressive power of unit resolution. Section 3 introduces the concept of propagators and propagatable functions as a formal framework where unit resolution is a computing model. This section also presents theoretical results that will be used in section 4, where the expressive power of unit resolution is compared to the one of monotone Boolean circuits. Section 5 ends the paper with a synthesis of the results, which highlight their implications regarding the efficiency of unit resolution as a filtering technique in SAT solvers."}, {"heading": "2 Related works", "text": "There are at least three research directions related to the study of the expressive power of unit resolution.\nThe first one aims to identify the classes of formulae for which unit resolution is a complete refutation procedure in the sense that it produces the empty clause if and only if the input formula is not satisfiable. For example, this property holds for the formulae containing only Horn clauses [9]. This approach differs from that proposed in this paper since it considers the formulae as input data instead of computing systems.\nThe second direction aims to characterize the complexity of determining whether a given formula can be refuted by unit resolution or not. This decision problem denoted unit is known to be p-complete, meaning that for any problem \u03c0 with polynomial time complexity, there exists a log space reduction from \u03c0 to unit [10]. Circuit value and monotone circuit value, which consist to determine the output value of a Boolean circuit (monotone Boolean circuit, respectively), given its input values, are both p-complete too [8]. Regarding the complexity theory, unit, circuit value and monotone circuit value have then the same expressive power. In the present paper, a different point of view is adopted. The cnf formula is not the input data of a program, but the program itself. The input data is a partial truth assignment encoded in a natural way, i.e., each input variable can be either assigned to true, assigned to false, or not assigned. Similarly, the Boolean circuits are not considered as inputs of a program, but as a programs by themselves. In this context, circuit value and monotone circuit value have not the same expressive power for at least two reasons : (1) monotone circuits can only compute monotone Boolean functions, while any Boolean function can be computed using a general Boolean circuit, and (2) there exist monotone Boolean functions which can be computed by polynomially sized Boolean circuits, but requiring an exponential number of gates to be computed using monotone circuits [15]. One of our results is that used as a computation model, unit resolution with natural input encoding has the same expressive power as monotone Boolean circuits, then less expressive power than general Boolean circuits. Obviously, the input encoding plays a central role is this result since by the use of another encoding where all input variables are assigned, unit resolution can easily simulate any Boolean circuit. Nevertheless, the natural encoding is the one used internally in the sat solvers.\nThe third line is related to the search for efficient cnf encodings of various problems in order to solve them thanks to a sat solver. Because unit resolution is implemented efficiently in sat solvers, many works aim to find encoding schemes which allow unit resolution to make as many deductions as possible. In [6], a cnf encoding for enumerative constraints is proposed, which allows unit propagation to make the same deductions on the resulting formula as restoring arc consistency on the initial constraints does. This work was innovative because with the previously known encodings, unit propagation had less inference power than restoring arc consistency, which is the basic filtering method used in constraint solvers. It has been followed by various similar works on other kinds of constraints such as Boolean cardinality constraints [2] and pseudo-Boolean constraints [4], while in [1], a general way to construct such an encoding for any constraint is proposed. Today, it has become customary, when a new encoding is proposed, to address the question of the behavior of unit resolution on the obtained sat instances. The problem is that some of these encodings produce a prohibitive number of clauses. This is why some authors seek a trade-off between the size of the formulae and the inference power of unit resolution and other deduction rules implemented in sat solvers, such as the failed literal rule [11]. For example, this approach is developed in [14] and [12] in the context of Boolean cardinality constraints."}, {"heading": "3 Propagatable functions", "text": ""}, {"heading": "3.1 Unit resolution", "text": "This section recalls the terminology and the principles involved in unit resolution, and introduces the notations that will be used in the rest of the paper.\nA literal is either a propositional variable or a negated propositional variable. A cnf formula is\ndefined as a conjunction c1 \u2227 . . . \u2227 ck of clauses, where each clause ci = li,1 \u2228 . . . \u2228 li,|ci| is a disjunction of literals. The size of a cnf formula is its number of literal occurrences.\nA truth assignment on a set of propositional variables is a function mapping some of the variables in this set to truth values, i.e., true or false. These variables are said to be fixed to true or false. If a truth assignment does not fix all the variables, it is said to be partial ; else it is said to be complete. In this paper, a truth assignment will be represented as a set of literals. Given a propositional formula \u03c6 and a truth assignment I, \u03c6|I denotes \u03c6 \u2227\nl\u2208I(l). Any cnf formula \u03c6 is said to be satisfied (falsified, respectively) by a truth assignment I if and only if I causes \u03c6 to evaluate to true (false, respectively) in the standard way. A cnf formula \u03c6 is said to be satisfiable if and only if there exists a truth assignment that satisfy \u03c6. Any complete truth assignment satisfying a cnf formula \u03c6 is called a model of \u03c6.\nFor convenience, a clause can be represented as a set of literals and a cnf formula can be represented as a set of clauses.\nExample 1. The cnf formula (a \u2228 b\u0304) \u2227 (a\u0304 \u2228 b) can be represented as {{a, b\u0304}, {a\u0304, b}}.\nUnit resolution is an inference technique which aims either to detect an inconsistency or to assign some variables, so as to simplify a cnf formula. As described in a standard way by Algorithm 1, until there is no empty clause and there is at least one unit clause (w) in the input formula, all the occurrences of the literal w and all the clauses containing the literal w are removed.\ninput : \u03c6 [cnf formula]; output: (\u03c6,E) [(cnf formula, set of literals)] or \u22a5;\nE \u2190 {}; while {} /\u2208 \u03c6 and \u2203{l} \u2208 \u03c6 do\n\u03c6\u2190 \u03c6 \\ {c : c \u2208 \u03c6, l \u2208 c} \\ {c : c \u2208 \u03c6, l\u0304 \u2208 c} \u222a {c \\ {l\u0304} : c \u2208 \u03c6, l\u0304 \u2208 c}; E \u2190 E \u222a {l};\nend if {} \u2208 \u03c6 then return \u22a5 else return (\u03c6,E) end\nAlgorithm 1: The standard algorithm for unit resolution\nIn the following, we will consider another algorithm (Algorithm 3) that will be called the alternative algorithm for unit resolution. This alternative algorithm return \u22a5 if and only if the standard algorithm return \u22a5, else it returns the same truth assignment as the standard algorithm does. But contrary to the standard algorithm, it does not modify the input formula.\nThe alternative algorithm repeat n+1 propagation stages, where n is the number of variables in the input formula. Each of these propagation stage is performed by the procedure propagation (Algorithm 2).\nThe standard and the alternative algorithms are strictly equivalent. The first one produces a literal w if there is a unit clause (w) in the simplified formula, that is if there is a clause (l1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 lq \u2228 w) in the input formula such that the literals l\u03041, . . . , l\u0304q are previously produced. The second one produces the same literal in the same conditions, with the only difference that it does not modify the input formula. The standard algorithm return \u22a5 when an empty clause is produced. This occurs when there is some unit clause (w) and the opposite clause (w\u0304) in the simplified formula. In the same situation, the alternative algorithm does not stop, but adds both the literals w and w\u0304 in the set E. As the standard algorithm, it will return \u22a5 at the end of its execution.\ninput : \u03c6,E [(cnf formula, set of literals)]; output: F [set of literals];\nF \u2190 {}; foreach literal w in \u03c6 such that w /\u2208 E do\nforeach clause (l1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 lk \u2228 w) of \u03c6 such that l\u03041, . . . , l\u0304k \u2208 E do F \u2190 F \u222a {w} end\nend return F ;\nAlgorithm 2: The procedure propagation, which performs a propagation stage of the alternative algorithm for unit resolution.\ninput : \u03c6 [cnf formula]; output: E [set of literals] or \u22a5;\nE \u2190 {}; n\u2190 the number of variables in \u03c6; repeat n+ 1 times\nE \u2190 E \u222a propagation(\u03c6,E); end if there exists v such that v, v\u0304 \u2208 E then return \u22a5 else return E end\nAlgorithm 3: The alternative algorithm for unit resolution\nOf course, the alternative algorithm could be optimized in such a way that it stops if the last propagation stage did not modify the set E, or if there are a literal w and its opposite w\u0304 in E. One of these two events necessarily occurs during the first n+ 1 propagation stages, because if E contains n+1 literals, it necessarily contains two opposite literals. This optimization has not been done because this algorithm is not intended to be implemented. It is only a way to prove some theoretical results which will be presented later.\nIn the following of the paper, given any cnf formula \u03c6 with n variables and any integer 1 \u2264 k \u2264 n+1,\n\u2022 Uk(\u03c6) will denote the set of literals produced at the k th propagation stage of algorithm 3;\n\u2022 U1..k(\u03c6) will denote \u222a k i=1Ui(\u03c6);\n\u2022 U(\u03c6) will denote the result of unit propagation applied to \u03c6, i.e., either \u22a5 or U1..n+1(\u03c6).\nExample 2. With \u03c6 = (a\u2228 b\u0304)\u2227 (b)\u2227 (a\u0304\u2228 c\u2228 d\u0304) as input, both algorithms 1 and 3 return U(\u03c6) = {b, a}. Regarding algorithm 3, U1(\u03c6) = {b} and U2(\u03c6) = {a}."}, {"heading": "3.2 Reified formulae", "text": "This section introduces the notion of reified cnf formula, which will be subsequently used as a tool to prove several results.\nInformally speaking, the reified counterpart of any cnf formula \u03c6, is a satisfiable cnf formula \u03c3 = reif(\u03c6) such that applying unit resolution on \u03c3 simulates all the inferences produced by applying unit resolution on \u03c6.\nLet var(\u03c6) denote the set of the variables occurring in \u03c6.\nDefinition 1 (reified formula). Let \u03c6 be a cnf formula with n variables. The reified counterpart of \u03c6 is the formula \u03c3 = reif(\u03c6) obtained as follows:\n\u2022 There are 2n(n+ 2) variables in \u03c3, namely\nvar(\u03c3) = \u222av\u2208var(\u03c6){v + 0 , v \u2212 0 , . . . , v + n+1, v \u2212 n+1}\nGiven any propositional variable v \u2208 var(\u03c3), let \u03b4(v) denotes v+ and \u03b4(v) denotes v\u2212.\n\u2022 \u03c3 consists of the following clauses:\n(1) for any unary clause (w) of \u03c6, (\u03b4(w)0)\u2227 (\u03b4(w)0 \u2228 \u03b4(w)1) 1, which will be called initialization\nclauses of rank 0 and 1,\n(2) for any stage 2 \u2264 i \u2264 n+ 1, and any variable v of \u03c6, (v+i\u22121 \u2228 v + i ) \u2227 (v \u2212 i\u22121 \u2228 v \u2212 i ), which will be\ncalled propagation clauses of rank i,\n(3) for any stage 2 \u2264 i \u2264 n+ 1, and for any non-unary clause q of \u03c6, \u2227\nw\u2208q \u03c7(q, i, w), where\n\u03c7(q, i, w) = \u03b4(w)i \u2228 \u2228\nt\u2208q,t6=w\n\u03b4(t)i\u22121,\nwhich will be called deduction clauses of rank i.\nFor convenience, in the following of the paper, each time that a formula \u03c6 and it reified counterpart \u03c3 = reif(\u03c6) will be considered, the propagation stages on \u03c6 will be numbered from 1, while the propagation stages on \u03c3 will be numbered from 0.\nExample 3. Let \u03c6 = (a)\u2227(a\u2228b). The reified counterpart of \u03c6 can be decomposed as \u03c3 = \u03c3(1)\u2227\u03c3(2)\u2227\u03c3(3), where:\n\u03c3(1) = (a + 0 ) \u2227 (a + 0 \u2228 a + 1 )\n\u03c3(2) = (a + 1 \u2228 a + 2 ) \u2227 (a \u2212 1 \u2228 a \u2212 2 ) \u2227 (b + 1 \u2228 b + 2 ) \u2227 (b \u2212 1 \u2228 b \u2212 2 ) \u2227 (a + 2 \u2228 a + 3 ) \u2227 (a \u2212 2 \u2228 a \u2212 3 ) \u2227 (b + 2 \u2228 b + 3 ) \u2227 (b \u2212 2 \u2228 b \u2212 3 )\n\u03c3(3) = (a + 1 \u2228 b + 2 ) \u2227 (b \u2212 1 \u2228 a \u2212 2 ) \u2227 (a + 2 \u2228 b + 3 ) \u2227 (b \u2212 2 \u2228 a \u2212 3 )\nThe stage 1 of unit resolution fixes a to true in \u03c6. Accordingly, thanks to the initialization clauses, the stages 0 and 1 of unit resolution fix a+0 and a + 1 to true in \u03c3.\nAt the stage 2, unit resolution fixes b to true in \u03c6. Accordingly, at the stage 2 of unit resolution of\n\u03c3, the variable b+2 is fixed to true thanks to the deduction clause (a + 1 \u2228 b + 2 ), and the variable a + 2 is fixed to true thanks to the propagation clause (a+1 \u2228 a + 2 ).\nAt the stage 3, unit resolution fixes no new variable in \u03c6. Thanks to the propagation clauses (a+2 \u2228a + 3 )\nand (b+2 \u2228 b + 3 ), the stage 3 of unit resolution on \u03c3 fixes a + 3 and b + 3 to true.\nThis example shows the roles of the three kind of clauses. The initialization clauses simulate the first stage of unit resolution, which consists to fix the variables occurring in unit clauses. The propagation clauses allow unit resolution to propagate the values that where previously assigned. For example, if the variable a is fixed to true in \u03c6 at stage 1, i.e., a+1 is fixed to true in \u03c3, then the clause (a + 1 \u2228 a + 2 ) ensures that a+2 is fixed to true in \u03c3 at stage 2. The deduction clauses allow unit resolution to simulates in \u03c3 the deductions that are made in \u03c6. For example, if at stage 1, the variable a is fixed to true in \u03c6,\n1(\u03b4(w)1) would have the same effect in only one propagation stage, but the reified formula is intentionally tailored in such a way that the variables v+\ni and v\u2212 i are fixed at the (i+ 1)th propagation stage.\nand if there is a clause (a\u0304 \u2228 b) in \u03c6, then the clause (a+1 \u2228 b + 2 ) of \u03c3 allows unit resolution to fix b + 2 to true, which indicates that unit resolution fixes b to true in \u03c6. Note that the proposed model of reified formula is not optimal in the sense that it usually involves redundant clauses and useless clauses. Our purpose is to provide a tool for proving theoretical results which will be presented in the following of the paper. In this context, the relevant property of the reified counterpart of a formula \u03c6 is that its size is polynomially related to the size of \u03c6. Namely, if there are n variables and k clauses of size at most p in \u03c6, then there are O(n2k) clauses of size at most p in the reified counterpart \u03c3 of \u03c6, because for any of the O(n) propagation stages, \u03c3 contains O(n) propagation clauses and O(kn) deduction clauses2, and because the number of literals in any clause of \u03c3 cannot exceed the size of the longest clause of \u03c6.\nDefinition 2 (reified formula with injected variables). Let \u03c6 be any cnf formula with n variables and V \u2286 var(\u03c6) be a set of propositional variables. The formula\nreif(\u03c6, V ) = reif(\u03c6) \u2227 ( \u2227\nv\u2208V\n((v \u2228 v+1 ) \u2227 (v \u2228 v \u2212 1 )))\nis said to be the reified counterpart of \u03c6 with injected variables V . The clauses added to reif(\u03c6) will be called injection clauses.\nLemma 1. Let \u03c6 be any cnf formula with n variables. Let \u03c3 = reif(\u03c6) and i be any integer such that 0 \u2264 i \u2264 n+1. For any variable v \u2208 var(\u03c6), applying unit resolution on \u03c3 can fix v+i and/or v \u2212 i only at the propagation stage i, and only to true.\nProof. This property can be proved by induction on i. The only variables which can be fixed at the first propagation stage, i.e. i=0, are in {v+0 , v \u2212 0 , v \u2208 var(\u03c6)}, because no other variables are in unary clauses, and these variables can only be fixed to true, because they occur positively. Now, given any 1 \u2264 i \u2264 n + 1, let us suppose the the property hold until the (i \u2212 1)th propagation stage (which implies that no variable in {v+i , v \u2212 i , 0 \u2264 i \u2264 i \u2212 1, v \u2208 var(\u03c6)} has been fixed negatively). The only way for unit resolution to fix variables in {v+i , v \u2212 i , v \u2208 var(\u03c6)} is through clauses involving variables in {v+i\u22121, v \u2212 i\u22121, v \u2208 var(\u03c6)}, which, by induction hypothesis, can only be fixed at the propagation stage i \u2212 1. Because the variables in {v+i\u22121, v \u2212 i\u22121, v \u2208 var(\u03c6)} occur positively in these clauses, they can be only fixed to true.\nTheorem 1. Let \u03c6 be any cnf formula with n variables and \u03c3 = reif(\u03c6) be the reified counterpart of \u03c6. The following properties hold:\n1. \u03c3 is satisfiable.\n2. For any variable v \u2208 var(\u03c6), and any integer 1 \u2264 k \u2264 n+ 1, the two following properties hold:\n(a) v+k \u2208 Uk(\u03c3) if and only if v \u2208 U1..k(\u03c6); (b) v\u2212k \u2208 Uk(\u03c3) if and only if v\u0304 \u2208 U1..k(\u03c6).\nProof. The first property arises because each clause of \u03c3 contains at least one positive literal. The second property can be proved by induction on k. For sake of brevity, let us reformulate it as follows: for any variable v \u2208 var(\u03c6), any integer 1 \u2264 k \u2264 n+1, and any literal w \u2208 {v, v}, \u03b4k(w) \u2208 Uk(\u03c3) if and only if w \u2208 U1..k(\u03c6).\nClearly, the property holds for k = 1 because there is a clause (w) in \u03c6 if and only if there is a clause (\u03b40(w)) and a clause (\u03b40(w) \u2228 \u03b41(w)) in \u03c3. Now let us suppose that the property holds until the propagation stage k \u2212 1, k > 1.\n2Because each of the n variables occurs at most in k clauses.\n\u21d2 Let us suppose that \u03b4k(w) \u2208 Uk(\u03c3). Then, according to the lemma 1, one of the two following conditions hold:\n1. There is a propagation clause (\u03b4k\u22121(w) \u2228 \u03b4k(w)) in \u03c3 and \u03b4k\u22121(w) \u2208 Uk(\u03c3). By induction hypothesis, w \u2208 U1..k\u22121(\u03c6), then w \u2208 U1..k(\u03c6).\n2. There is a deduction clause (\u03b4k\u22121(l\u03041)\u2228\u00b7 \u00b7 \u00b7\u2228\u03b4k\u22121(l\u0304q)\u2228\u03b4k(w)) in \u03c3 and \u03b4k\u22121(l\u03041), . . . , \u03b4k\u22121(l\u0304q) \u2208 Uk\u22121(\u03c3). This means that there is a clause (l1\u2228\u00b7 \u00b7 \u00b7\u2228lq\u2228w) in \u03c6, and, by induction hypothesis, l\u03041, . . . , l\u0304q \u2208 U1..k\u22121(\u03c6). Then w \u2208 U1..k(\u03c6).\n\u21d0\nLet us suppose that w \u2208 U1..k(\u03c6). Then, according to the principle of unit resolution, one of the two conditions hold:\n1. There is a clause (w) in \u03c6. Then, as shown in the first part of this proof, \u03b41(w) \u2208 U1(\u03c3). Thanks to the propagation clauses (\u03b41(w) \u2228 \u03b42(w)), . . . , (\u03b4k\u22121(w) \u2228 \u03b4k(w)), \u03b4k(w) \u2208 Uk(\u03c3).\n2. There is a clause (l1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 lq \u2228 w) in \u03c6 and an integer 1 \u2264 i \u2264 k \u2212 1 such that l\u03041, . . . , l\u0304q \u2208\nU1..i(\u03c6). By construction of \u03c3, there is a deduction clause (\u03b4i(l\u03041) \u2228 \u00b7 \u00b7 \u00b7 \u2228 \u03b4i(l\u0304q) \u2228 \u03b4i+1(w)) in \u03c3, and by induction hypothesis, \u03b4i(l\u03041), . . . , \u03b4i(l\u0304q) \u2208 Ui(\u03c3). Then \u03b4i+1(w) \u2208 Ui+1(\u03c3). Either because i+1 = k or thanks to the propagation clauses (\u03b4i(w)\u2228\u03b4i+1(w)), . . . , (\u03b4k\u22121(w)\u2228\u03b4k(w)), \u03b4k(w) \u2208 Uk(\u03c3).\nAs an interesting corollary of Theorem 1, the failed literal rule [11], which is a speed up technique implemented in some modern sat solver, can be simulated by unit propagation. Given a formula \u03c3 and a literal l, the failed literal rule aims to test if l must be fixed. Unit resolution is applied to \u03c3 \u2227 (l\u0304) (\u03c3 \u2227 (l), respectively). If an inconsistency is detected then l (l\u0304, respectively) is fixed to true. The same result can be obtained by applying unit resolution on reif(\u03c6 \u2227 (l)) \u2227 \u2227\nv\u2208var(\u03c6)(v + n+1 \u2228 v \u2212 n+1 \u2228 l)\n(reif(\u03c6 \u2227 (l)) \u2227 \u2227\nv\u2208var(\u03c6)(v + n+1 \u2228 v \u2212 n+1 \u2228 l), respectively).\nTheorem 2. Let \u03c6 be any cnf formula, V \u2286 var(\u03c6) be a set of propositional variables, and I \u2208 IV a truth assignment. U((reif(\u03c6, V ))|I) = U(reif(\u03c6|I)), i.e., unit resolution have the same effect on U((reif(\u03c6, V ))|I) as it does on U(reif(\u03c6|I)).\nProof. For any literal v \u2208 I (v\u0304 \u2208 I, respectively), the two first stages of unit resolution applied to (reif(\u03c6, V ))|I produces the literals v + 1 (v \u2212 1 , respectively), which are the literals produced from the clauses (v+0 \u2228 v + 1 ), (v + 0 ) ((v \u2212 0 \u2228 v \u2212 1 ), (v \u2212 0 ), respectively) of reif(\u03c6|I). The other stages of unit resolution behave similarly in the two formulae, because the same clauses are involved."}, {"heading": "3.3 Computing with unit resolution", "text": "This section explains how unit resolution can be used to compute functions."}, {"heading": "3.3.1 Definitions and terminology", "text": "Definition 3 (Propagator). Let \u03c6 be a cnf formula, var(\u03c6) be the set of propositional variables occurring in \u03c6, V \u2286 var(\u03c6) a set of propositional variables, and s \u2208 V a propositional variable. The triplet P = \u3008\u03c6, V, s\u3009 is called a propagator. The size of P is the size of the formula \u03c6.\nA propagator \u3008\u03c6, V, s\u3009 can act as a computer in the following way:\n\u2022 the input data is a partial truth assignment I of the variables in V , i.e., some variables are assigned to true, some are assigned to false, and the other are not assigned,\n\u2022 the output can take four possible values according to the result of applying unit resolution:\n\u2013 fail if U(\u03c6|I) = \u22a5,\n\u2013 true if U(\u03c6|I) 6= \u22a5 and s \u2208 U(\u03c6|I),\n\u2013 false if U(\u03c6|I) 6= \u22a5 and s\u0304 \u2208 U(\u03c6|I),\n\u2013 na if U(\u03c6|I) 6= \u22a5 and s\u0304 /\u2208 U(\u03c6|I) and s /\u2208 U(\u03c6|I).\nFormally, \u3008\u03c6, V, s\u3009 computes a function f with domain IV and codomain {fail, true, false, na}, where IV denotes the set of all the consistent partial assignments on V , i.e., {I \u2282 V \u222a {v, v \u2208 V },\u2200l \u2208 I, l\u0304 /\u2208 I}.\nConversely, given a set V of propositional variables and any function f with domain D \u2286 IV and codomain {fail, true, false, na}, the following issues can be addressed:\n1. Can f be computed by a propagator ?\n2. If yes, how many clauses are required to compute f using unit resolution ?\nThese questions are important because in a sat solver, unit resolution is used both for detecting inconsistencies (the fail answer) and for inferring new information (the true or false answers), with the effect of accelerating the resolution. It is then useful to use concise cnf encodings which allow unit resolution to achieve as many deductions as possible.\nDefinition 4 (reified propagator). Let P = \u3008\u03c6, V, s\u3009 be a propagator. The reified counterpart of P is reif(P ) = \u3008\u03c8, V, strue, sfalse, sfail\u3009, such that strue is the variable s+n+1, s false is the variable s\u2212n+1, s fail is new fresh variable, and\n\u03c8 = reif(\u03c6, V ) \u2227 ( \u2227\nu\u2208var(\u03c6)\n(u+n+1 \u2227 u \u2212 n+1 \u2227 s fail))\nBy construction of the formula \u03c8, given any I \u2208 IV , applying unit resolution to \u03c8|I never returns \u22a5 and simulates unit resolution on \u03c6|I in the following sense:\n\u2022 unit resolution on \u03c6|I returns \u22a5 if and only if unit resolution on \u03c8|I produces s fail (i.e. fixes to\nsfail to true);\n\u2022 unit resolution on \u03c6|I produces s if and only if unit resolution on \u03c8|I produces s true;\n\u2022 unit resolution on \u03c6|I produces s\u0304 if and only if unit resolution on \u03c8|I produces s false.\nDefinition 5 (filtering function). Let V be a set of propositional variables. Any function f with domain D \u2286 IV and codomain {fail, true, false, na} is called a filtering function.\nDefinition 6 (matching function). Let V be a set of propositional variables. Any function f with domain D \u2286 IV and codomain {yes, no} is called a matching function.\nAny filtering function can be specified with three matching functions in the following way:\nDefinition 7 (matching functions related to a filtering function). Let f be a filtering function with domain D \u2286 IV , V \u2208 {v1, . . . , vn}. The three matching functions related to f are defined as follows:\n\u2022 f fail with domain D and codomain {yes, no}, such that for any I \u2208 D, f fail(I) = yes if and only if f(I) = fail,\n\u2022 f true with domain D\u2032 = {I \u2208 D, f(I) 6= fail}, such that for any I \u2208 D\u2032, f true(I) = yes if and only if f(I) = true,\n\u2022 f false with domain D\u2032 = {I \u2208 D, f(I) 6= fail}, such that for any I \u2208 D\u2032, f false(I) = yes if and only if f(I) = false.\nDefinition 8 (monotone matching function). Given the order relation no \u2264M yes, any matching function f with domain D is said to be monotone if for any I, J \u2208 D such that I \u2286 J , f(I) \u2264M f(J).\nNow we will formally define the filtering and the matching functions that are computable using unit resolution.\nDefinition 9 (propagatable filtering function). Any filtering function f is said to be propagatable if and only if there exists a propagator which computes f .\nNow, two ways will be considered to compute matching functions with unit resolution. The first one consists in using a variable as output under the assumption that \u22a5 is never returned. The second one consists in considering that the output value yes when \u22a5 is returned.\nDefinition 10 (propagatable matching function). Any matching function f with domain D \u2286 IV is said to be propagatable if there exists a propagator \u3008\u03c6, V, s\u3009 such that for any I \u2208 D, the two following conditions hold:\n1. U(\u03c6|I) 6= \u22a5,\n2. f(I) = yes if and only if s \u2208 U(\u03c6|I).\nDefinition 11 (\u03bd-propagatable matching function, \u03bd-propagator). Any matching function f with domain D \u2286 IV is said to be \u03bd-propagatable if there exists a cnf formula \u03c6 such that for any I \u2208 D, f(I) = true if and only if U(\u03c6|I) = \u22a5. The couple \u3008V, \u03c6\u3009 is said to be a \u03bd-propagator computing f .\nTo end this necessary sequence of definitions, let us address the notion of space complexity of propagatable functions.\nDefinition 12 (polynomially propagatable functions). Let F be a family of filtering functions or a family of matching functions. F is said to be polynomially propagatable (or polynomially \u03bd-propagatable, if applicable) if and only if any function f \u2208 F with domain D \u2286 I{v1,...,vn} can be computed using a cnf formula of size polynomially related to n."}, {"heading": "3.3.2 Propagability versus \u03bd-propagability", "text": "In this section, we will show that propagatable and \u03bd-propagatable matching functions have the same expressive power and similar space complexities.\nTheorem 3. Let f be a matching function. f is propagatable if and only if f is \u03bd-propagatable.\nTheorem 4. Let f be a propagatable matching function. f is polynomially propagatable if and only if f is polynomially \u03bd-propagatable.\nProof.\n1. propagatable \u21d2 \u03bd-propagatable.\nLet f be a propagatable matching function with domain D, and P = \u3008\u03c6, V, s\u3009 be a propagator which computes f . Clearly, for any partial truth assignment I \u2208 D, applying unit resolution to the formula (\u03c6 \u2227 (s))|I returns \u22a5 if and only if f(I) = yes.\n2. \u03bd-propagatable \u21d2 propagatable.\nLet f be a \u03bd-propagatable function with domain D \u2282 IV and \u03c6 a cnf formula including n variables, such that for any I \u2208 D, applying unit resolution to \u03c6|I returns \u22a5 if and only if f(I) = yes.\nOur aim is to build a new formula \u03c8 such that for any I \u2208 D, applying unit resolution to \u03c8|I does not return \u22a5 but fixes a variable s to true if and only if applying unit resolution to \u03c6|I returns \u22a5, in such a way that the propagator \u3008\u03c8, V, s\u3009 computes f .\nThe formula \u03c8 can be obtained as follows:\n\u03c8 = reif(\u03c6, V ) \u2227 ( \u2227\nu\u2208var(\u03c6)\n(u+n+1 \u2227 u \u2212 n+1 \u2227 s))\nThe variable s will be fixed to true if and only if unit resolution on \u03c6 fixes both a variable u+i and a variable u\u2212i to true. According to the theorems 1 and 2, this occurs if and only if applying unit resolution to \u03c6|I returns \u22a5. Then, \u3008\u03c8, V, s\u3009 is a propagator which computes f .\nBecause the two transformations have polynomial space complexity, both theorems 4 and 3 hold."}, {"heading": "3.3.3 Filtering functions versus matching functions", "text": "In this section, we will show that without loss of generality, studying the space complexity of propagatable filtering functions reduces to studying the space complexity of propagatable matching functions.\nTheorem 5. Any filtering function f is propagatable if and only if the three related matching functions f true, f false, and f fail are propagatable.\nTheorem 6. Any filtering function f is polynomially propagatable if and only if the three related matching functions f true, f false, and f fail are polynomially propagatable.\nProof.\n1. filtering \u21d2 matching\nLet f be a propagatable filtering function and f true, f false, and f fail the related matching functions. Because f is propagatable, there exists a propagator \u3008\u03c6, V, s\u3009 that computes f . Then f true, f false, and f fail can be computed with the following propagators, respectively:\n(a) \u3008\u03c6, V, s\u3009 (which computes f true);\n(b) \u3008\u03c6 \u2227 (s \u2228 t), V, t\u3009 (which computes f false);\n(c) \u3008\u03c8, V, sfail\u3009, where \u3008\u03c8, V, strue, sfalse, sfail\u3009 is the reified counterpart of \u3008\u03c6, V, s\u3009.\nClearly, f true, f false, and f fail are propagatable. Now, because the size of \u03c8 is polynomially related to the size of \u03c6, if f is polynomially propagatable then f true, f false, and f fail are polynomially propagatable too.\n2. matching \u21d2 filtering\nLet f be a filtering function with domain D \u2282 IV , V \u2208 {v1, . . . , vn} and f true, f false, and f fail the related matching functions. Suppose that f true, f false, and f fail are propagatable (polynomially propagatable, respectively). Now let us consider the three following propagators (with formulae of size polynomially related to n, respectively):\n(a) \u3008\u03c61, V, s1\u3009, which computes f true; (b) \u3008\u03c62, V, s2\u3009, which computes f false; (c) \u3008\u03c63, V, s3\u3009, which computes f fail.\nLet \u3008\u03c81, V, s true 1 , s false 1 , s fail 1 \u3009, \u3008\u03c82, V, s true 2 , s false 2 , s fail 2 \u3009, \u3008\u03c83, V, s true 3 , s false 3 , s fail 3 \u3009 be the reified counterparts of these propagators. Without loss of generality, let us suppose that, except for the input variables in V , the formulae \u03c81, \u03c82, \u03c83 have no common variable.\nThe function f can be computed (in polynomial space, respectively) using the following propagator:\nP = \u3008\u03c81 \u2227 \u03c82 \u2227 \u03c83 \u2227 (strue1 \u2228 s) \u2227 (s false 2 \u2228 s) \u2227 (s fail 3 ), V, s\u3009\nClearly, P computes f , which is then propagatable (polynomially propagatable, respectively)."}, {"heading": "3.3.4 Boolean representations", "text": "Given V = {v1, . . . , vn} a set of propositional variables, D \u2286 IV a set of partial truth assignments of V , f any matching function with domain D, and I any partial assignment in D, let us define:\n\u2022 the Boolean representation of I as IB = (x1, . . . , xn, y1, . . . , yn) \u2208 {0, 1} n such as for any 1 \u2264 i \u2264 n,\nxi = 1 if and only if vi \u2208 I, and yi = 1 if and only if vi \u2208 I,\n\u2022 the Boolean representation of D as DB = {IB, I \u2208 D},\n\u2022 the Boolean representation of f as fB : DB 7\u2192 {0, 1}, such that for any I \u2208 D, fB(IB) = 1 if and only if f(I) = yes.\nExample 4. The following table gives an example of a matching function f and its Boolean counterpart fB.\nI IB f(I) fB(IB) {v1, v2} (0, 0, 1, 1) no 0 {v1, v2} (0, 1, 1, 0) yes 1 {v1} (0, 0, 1, 0) no 0 {v1, v2} (1, 0, 0, 1) yes 1 {v1, v2} (1, 1, 0, 0) yes 1 {v1} (1, 0, 0, 0) yes 1 {v2} (0, 0, 0, 1) no 0 {v2} (0, 1, 0, 0) yes 1 {} (0, 0, 0, 0) no 0\n\u3008(v\u03041 \u2228 s) \u2227 (v\u03042 \u2228 s), {v1, v2}, s\u3009 is a propagator for f .\nExample 5. The following table gives a matching function g which is not propagatable, and its Boolean counterpart gB.\nI IB g(I) gB(IB) {v} (0, 1) yes 1 {v} (1, 0) no 0 {} (0, 0) yes 1\nThere is no propagator for g because for any formulae \u03c61 \u2286 \u03c62, if U(\u03c62) 6= \u22a5 then any variable fixed by unit resolution on \u03c61 will be fixed on \u03c62 as well. It follows that the third line of the table is not consistent with the second one."}, {"heading": "3.4 Synthesis", "text": "In this section, we first introduced the notion of filtering function as a general model of functions that can be computed by unit resolution. We then showed that any filtering function reduces to three matching functions, which are functions with binary codomain ({yes,no} without loss of generality) that can either be computed by unit resolution in two different ways: (1) unit resolution detects an inconsistency when the output value is yes, (2) it fixes a predefined output variable to true when the output value is yes. The main result of this section is that without loss of generality, studying the expressive power of unit resolution can be reduced to studying the tractability and the complexity of computing matching functions with unit resolution. As a corollary, in the sequel of the paper, only propagatable matching functions will be considered."}, {"heading": "4 Expressive power of propagators", "text": "Using a complete truth assignment as input values, unit resolution has the same expressive power as Boolean circuits, because elementary gates can be directly translated into clauses. In this section, we will show that if some input variables are not fixed, the expression power of unit resolution fall down to the expression power of monotone Boolean circuits, i.e., circuits with only or / and gates."}, {"heading": "4.1 Boolean circuits", "text": "A Boolean circuit is a directed acyclic graph representing a Boolean formula. It is said to be monotone when it contains only and and or gates.\nIn the following, a Boolean circuit will be represented by a triplet \u3008L,G,w\u3009, where L is a set of input labels, w is the output label, and G is a set of gates. A or gate (and gate, respectively) is denoted or(E, t) (and(E, t), respectively), where E is the set of input labels and t is the output label of the gate. A not gate is denoted not(q, t), where q is the input label of the gate and t is its output label.\nGiven a Boolean circuit C = \u3008{e1, . . . , en}, G,w\u3009 and any x = (x1, . . . , xn) \u2208 {0, 1} n, let C(x) denote the output value of C under the assumption that its input values are x1, . . . , xn. Formally, C(x) can be defined as val(w) such that for any 1 \u2264 i \u2264 n, val(ei) = xi, for any gate or(E, t) \u2208 G, val(t) = \u2228\ne\u2208E val(e), for any gate and(E, t) \u2208 G, val(t) = \u2227\ne\u2208E val(e), and for any gate not(q, t) \u2208 G, val(t) = \u00acval(q).\nFor convenience, an additional gate tie(q, t) will be used to connect two nodes q and t in such a way that val(t) = val(q).\nGiven any Boolean function f with domain D \u2286 {0, 1}n and codomain {0, 1}, any Boolean circuit C with n inputs is said to compute f if and only if for any x \u2208 D, C(x) = f(x)."}, {"heading": "4.2 Circuits computing propagatable functions", "text": "Because the Boolean counterpart of any matching function is a Boolean function, it can be computed by a Boolean circuit. In this section, we will show that any matching function is propagatable if and only if its Boolean counterpart can be computed using a monotone circuit. Furthermore, we will establish a relationship between space complexity of propagatable matching functions and monotone circuit complexity.\nTheorem 7. For any matching function f , if there exists a monotone circuit with n gates, each of them with at most k inputs, which computes fB, then there exists a propagator with O(nk) clauses, which computes f .\nProof. Let us consider any matching function f with domain D \u2286 IV , V = {v1, . . . , vn}, and any monotone circuit Q = \u3008L,G, uk\u3009 computing fB.\nWithout loss of generality, let us suppose that\n\u2022 the set of input labels of Q is L = {e1, . . . , e2n},\n\u2022 the set of the output labels of the gates of Q is {u1, . . . , uk}.\nLet \u03c4 be a function that maps the labels of Q to propositional literals such that \n\n \u03c4(ei) = vi, 1 \u2264 i \u2264 n \u03c4(ei) = vi\u2212n, n+ 1 \u2264 i \u2264 2n \u03c4(ui) = vn+i, 1 \u2264 i \u2264 k \u2212 1 \u03c4(uk) = s\nFor any gate g = and({\u03b11, . . . , \u03b1m}, t) \u2208 G, let \u03c0(g) = (\u03c4(\u03b11) \u2228 \u00b7 \u00b7 \u00b7 \u2228 \u03c4(\u03b1m) \u2228 \u03c4(t)). For any gate g = or({\u03b11, . . . , \u03b1m}, t) \u2208 G, let \u03c0(g) = \u2227m i=1 (\u03c4(\u03b1i) \u2228 \u03c4(t)). Let \u03c6 = \u2227\ng\u2208G\n\u03c0(g).\nNow let us show by induction on the number k of gates in Q that the propagator P = \u3008\u03c6, V, s\u3009 computes f .\nThe property holds for k = 0 because if the circuit Q has no gate, the output label is one of the input labels ei or ei+n related to the input variable vi \u2208 V . If the input label is ei then the propagator \u3008{}, V, vi\u3009 computes f . If the input label is ei+n then the propagator \u3008(vi \u2228 s), V, s\u3009, where s is a new fresh variable, computes f .\nNow, let us suppose the the property holds for any circuit with less than k clauses, k > 0. Let Q = \u3008L,G, u\u3009 be any k-gates monotone Boolean circuit which computes the Boolean counterpart fB of f with input variables {v1, . . . , vn}. Let g be the output gate of Q. Let \u03b11, . . . , \u03b1m be the input labels of g. For any 1 \u2264 i \u2264 m, let Qi = \u3008L,G\\{g}, \u03b1i\u3009. By induction hypothesis, each Qi computes the Boolean counterpart fBi of the matching function fi computed by the propagator Pi = \u3008\u03c6 \\ \u03c0(g), V, \u03c4(\u03b1i)\u3009.\nLet us consider two cases:\n1. The output gate of Q is g = and({\u03b11, . . . , \u03b1m}, u).\nBecause of the nature of g, for any I \u2208 IV , fB(I) = 1 if and only if for any 1 \u2264 i \u2264 m, fi(IB) = 1. Because of the nature of \u03c0(g), f(I) = yes if and only if for any 1 \u2264 i \u2264 m, \u03c4(\u03b1i) \u2208 U((\u03c6\\\u03c0(g))|I ). Then f(I) = yes if and only if fB(IB) = 1.\n2. The output gate of Q is g = or({\u03b11, . . . , \u03b1m}, u).\nBecause of the nature of g, for any I \u2208 IV , fB(I) = 1 if and only there exists 1 \u2264 i \u2264 m, such as fi(IB) = 1. Because of the nature of \u03c0(g), f(I) = yes if and only if there exists 1 \u2264 i \u2264 m, such that \u03c4(\u03b1i) \u2208 U((\u03c6 \\ \u03c0(g))|I ). Then f(I) = yes if and only if fB(IB) = 1.\nExample 6. The circuit of the figure 1 can be translated into a cnf formula \u03c6 in the following way:\n- the gate and({e1, e2}, u1) produces the clause (v\u03041 \u2228 v\u03042 \u2228 v3);\n- the gate or({u1, e4}, u2) produces the clauses (v\u03043 \u2228 s) and (v2 \u2228 s).\nThis circuit computes the Boolean counterpart fB of the function f computed by the propagator \u3008\u03c6, {v1, v2}, s\u3009.\nTheorem 8. For any matching function f , if there exists a propagator \u3008\u03c6, V, s\u3009 computing f , then there exists a monotone circuit with O(n2k) gates computing fB, where n is the number of variables and k the number of clauses in \u03c6.\nProof. Let \u3008\u03c6, V, s\u3009 be a propagator computing a matching function f . Clearly, the propagator P = \u3008\u03c8 = reif(\u03c6, V ), V, s+n+1\u3009 computes f too. According to Lemma 1 and Theorem 1, \u03c8 can be decomposed as \u03c80 \u2227 \u03c81 \u2227 \u00b7 \u00b7 \u00b7 \u2227 \u03c8n+1 such that\n\u2022 \u03c80 contains the initialization clauses of rank 0 of the reified counterpart of \u03c6,\n\u2022 \u03c81 contains the initialization clauses of rank 1 as well as the injection clauses,\n\u2022 for any 2 \u2264 i \u2264 i, \u03c8i contains both the propagation clauses and the deduction clauses of rank i.\nThe corresponding circuit Q will contain the following nodes:\n\u2022 two input nodes \u22c4t and \u22c4t\u0304 related to each input variable t \u2208 V , with the convention that \u22c4t = 1 if and only if t is assigned to true, and \u22c4t\u0304 = 1 if and only if t is assigned to false;\n\u2022 one major node \u22c4v related to any variable v \u2208 var(\u03c8) that can be assigned to true by unit resolution, with the convention that \u22c4v = 1 if and only if unit resolution fixes v to true;\n\u2022 some additional nodes, if applicable;\nMajor nodes and additional nodes can be constant, i.e. permanently assigned either to 0 or 1. The constant nodes are not explicitly represented in the circuit but are referenced in the sets U0 and U1, respectively.\nThe circuit Q consists of several layers Q1, . . . , Qn+1, where each Qi simulates the stage i of unit resolution on \u03c8|I for any I \u2208 IV .\nAt the first step of the construction, U0 is initialized with the nodes \u22c4v + 0 (\u22c4v \u2212 0 , respectively) for any variable v \u2208 var(\u03c6) such that (v+0 ) ((v \u2212 0 ), respectively) does not occur in \u03c80, and U1 is initialized with the nodes \u22c4v+0 (\u22c4v \u2212 0 , respectively) for any variable v + 0 (v \u2212 0 , respectively) such that the clause (v + 0 ) ((v\u22120 ), respectively) occurs in \u03c80.\nEach of the next steps builds Qi in such a way that it simulates the effect of unit resolution applied to \u03c8i. This is done as follows:\nFor each variable v of \u03c6 and for each variable u \u2208 {v+i , v \u2212 i }, let C be the set of clauses of \u03c8i containing u, simplified by removing the clauses containing a literal w\u0304 such that \u22c4w \u2208 U0 and removing any literal w\u0304 such that \u22c4w \u2208 U1 from the other clauses.\nIf the set C is empty, which means that unit resolution cannot fix u, then \u22c4u is added to U0. If C contains a clause (u), which means that unit resolution will always fix u to true, then \u22c4u is added to U1. If C contains only one clause (w\u0304\u2228u), meaning that u is fixed to true if and only if w is previously fixed to true, the connection tie(\u22c4w, \u22c4u) is produced. If C contains only one clause with more than two literals like (w1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 wk \u2228 u), meaning that u is fixed to true if and only if w1 and ... and wk are previously fixed to true, the gate and({\u22c4w1, \u00b7 \u00b7 \u00b7 , \u22c4wk}, \u22c4u) is produced.\nIn the other cases, i.e., when there are several clauses which can allow unit resolution to fix u, an additional node \u03b1c is created for each clause c \u2208 C. For any binary clause (w\u0304 \u2228 u) \u2208 C, the gate tie(\u22c4w,\u03b1c) is produced. For any other clause (w1 \u2228 \u00b7 \u00b7 \u00b7 \u2228wk \u2228 u), the gate and({\u22c4w1, \u00b7 \u00b7 \u00b7 , \u22c4wk}, \u03b1c) is produced. Then the gate or({\u03b1c, c \u2208 C}, \u22c4u) is produced, in such a way that val(\u22c4u) = 1 if and only if unit resolution fixes u to true.\nBecause each sub-circuit Qi simulates exactly the effect of unit resolution on the corresponding formula \u03c8i, the value of the output node \u22c4s + n+1 will reflect the value of the output variable s + n+1 after all propagation stages on \u03c8 have been made. The number of gates in the circuit is linearly related to the number of clauses in the reified counterpart of \u03c6, which is O(n2k).\nExample 7. Let us consider the propagator \u2329 (a \u2228 b \u2228 c), {a, b}, c \u232a . At the first stage of the construction, U0 = {\u22c4c + 0 , \u22c4c \u2212 0 }, and U1 = {} because \u03c80 is empty. The input nodes of the circuit are \u22c4a, \u22c4a, \u22c4b, and \u22c4b. The first layer of the circuit is based on:\n\u03c81 =\ninjection clauses \ufe37 \ufe38\ufe38 \ufe37 (a \u2228 a+1 ) \u2227 (a \u2228 a \u2212 1 ) \u2227 (b \u2228 b + 1 ) \u2227 (b \u2228 b \u2212 1 )\nIt consists in the connections tie(\u22c4a, \u22c4a+1 ), tie(\u22c4a, \u22c4a \u2212 1 ), tie(\u22c4b, \u22c4b + 1 ), tie(\u22c4b, \u22c4b \u2212 1 ). The variables\n\u22c4c+1 and \u22c4c \u2212 1 are added to U0.\nThe second layer is based on:\n\u03c82 =\npropagation clauses \ufe37 \ufe38\ufe38 \ufe37 (a+1 \u2228 a + 2 ) \u2227 (a \u2212 1 \u2228 a \u2212 2 ) \u2227 (b + 1 \u2228 b + 2 ) \u2227 (b \u2212 1 \u2228 b \u2212 2 ) \u2227 (c + 1 \u2228 c + 2 ) \u2227 (c \u2212 1 \u2228 c \u2212 2 )\u2227\ndeduction clauses \ufe37 \ufe38\ufe38 \ufe37 (a\u22121 \u2228 b + 1 \u2228 c + 2 ) \u2227 (a \u2212 1 \u2228 c \u2212 1 \u2228 b \u2212 2 ) \u2227 (b + 1 \u2228 c \u2212 1 \u2228 a + 2 )\nThe two last propagation clauses and the two last deduction clauses are ignored because \u22c4c+1 and \u22c4c\u22121 are in U0. The four first propagation clauses are translated into tie(\u22c4a + 1 , \u22c4a + 2 ), tie(\u22c4a \u2212 1 , \u22c4a \u2212 2 ), tie(\u22c4b+1 , \u22c4b + 2 ), tie(\u22c4b \u2212 1 , \u22c4b \u2212 2 ). The first deduction clause is translated into the gate and({a \u2212 1 , b + 1 }, c + 2 ). c\u22122 is added to U0. The third layer is based on:\n\u03c83 =\npropagation clauses \ufe37 \ufe38\ufe38 \ufe37 (a+2 \u2228 a + 3 ) \u2227 (a \u2212 2 \u2228 a \u2212 3 ) \u2227 (b + 2 \u2228 b + 3 ) \u2227 (b \u2212 2 \u2228 b \u2212 3 ) \u2227 (c + 2 \u2228 c + 3 ) \u2227 (c \u2212 2 \u2228 c \u2212 3 )\u2227\ndeduction clauses \ufe37 \ufe38\ufe38 \ufe37 (a\u22122 \u2228 b + 2 \u2228 c + 3 ) \u2227 (a \u2212 2 \u2228 c \u2212 2 \u2228 b \u2212 3 ) \u2227 (b + 2 \u2228 c \u2212 2 \u2228 a + 3 )\nThe propagation clause (c+2 \u2228c + 3 ) is translated into the connection tie(\u22c4c + 2 , \u03b11), the deduction clause\n(a\u22122 \u2228 b + 2 \u2228 c + 3 ) is translated into the gate and({a \u2212 2 , b + 2 }, \u03b12), and the clause or({\u03b11, \u03b12}, \u22c4c + 3 ) is added, in such a way that \u22c4c+3 is set to 1 either if \u22c4c + 2 is set to 1 or if both \u22c4a \u2212 2 and \u22c4b + 2 are set to 1, i.e., if at stage 2 of unit resolution, either c is fixed to true or a and b are fixed to false and true, respectively... A part of the corresponding circuit is given Figure 2. (Recall that this circuit is obtained from a reified formula, which, as mentioned above, presents some redundancies.)\nTheorem 9. Let f be any matching function with domain D. f is propagatable if and only if it is monotone.\nProof. Recall that any Boolean function h with domain Dh is said to be monotone if for any z, t \u2208 Dh, if z \u2264B t then h(z) \u2264B h(t), where the ordering relation \u2264B is defined as follows: 0 \u2264B 1, 0 \u2264B 0, 1 \u2264B 1, (z1, . . . zn) \u2264B (t1, . . . tn) if and only if zi \u2264B ti, 1 \u2264 i \u2264 n.\nNow, given any matching function f with domain D, because for any I, J \u2208 D, I \u2286 J if and only if IB \u2264B JB, fB is monotone on DB if and only if f is monotone on D.\nLet f be any monotone matching function with domain D. Because fB is monotone, it can be computed by a monotone circuit. It follows from Theorem 7 that f is propagatable.\nNow let us consider any propagatable matching function f with domain D. It follows from Theorem 8 that fB can be computed by a monotone circuit, which implies that fB is monotone. Then f is monotone.\nTheorem 10. Any family F of propagatable functions is propagatable in polynomial space if and only if the family of the Boolean counterparts of F has polynomial space monotone circuit complexity, i.e., these functions can be calculated by monotone circuits with a polynomial number of gates.\nProof. The proof of theorem 7 shows how to create a propagator from a monotone circuit. Each and gate with n inputs is translated into one n-ary clause, and each or gate with n inputs is translated into n binary clauses.\nThe proof of theorem 8 shows how to create a monotone circuit from a propagator P = \u3008\u03c6, V, s\u3009. This circuit is based on the reified counterpart \u03c8 of the formula \u03c6. Each clause of \u03c8 with n literals is involved in at most n and gates, and each literal is involved in at most one or gate."}, {"heading": "5 Synthesis and perspectives", "text": "Altogether, the results given in this paper provide important information about the expressive power of unit resolution. In particular, we can show that there exist polynomial time complexity propagatable functions that admit only propagators with an exponential number of clauses.\nAs an example, let us consider the Boolean functions pm(n), like perfect matching, such that for any n-bits Boolean encoding g of a graph G, pm(n)(g) = 1 if and only if there exists a perfect matching for G, that is a set of edges that covers each vertex exactly once.\nNext, let us consider the variants vpm(n) such that\n\u2022 the domain Dvpm(n) of vpm (n) is the set {(x1, . . . , xn, 0, . . . , 0), (x1, . . . , xn) \u2208 Dpm(n)}, where\nDpm(n) is the domain of pm (n),\n\u2022 for any b = (x1, . . . , xn, 0, . . . , 0) \u2208 Dvpm(n) , vpm (n)(b) = 1 if and only if pm(n)(x1, . . . , xn) = 1.\nNow, let fpm(n) denote the matching functions related to vpm(n). It is known that pm(n), then vpm(n), have polynomial time computational complexity but exponential monotone circuit complexity [15]. It follows from theorem 8 that fpm(n) are filtering functions requiring an exponential number of clauses to be computed using unit resolution.\nThis means that although unit resolution has the same expression power as Boolean circuits regarding Boolean functions, it has a lower expression power, namely the expression power of monotone circuits, regarding filtering functions.\nThis is both very interesting and annoying, because in sat solvers unit propagation operates on filtering functions rather than Boolean functions. Maybe this potential weakness of unit resolution can be compensated for by other speed-up technologies. As a research perspective, this has to be verified. Meanwhile, in the field of encoding constraints into cnf, it would be very relevant to determine which problems can be solved as efficiently using a simple sat solver, under cnf encoding, as using a dedicated constraint solver maintaining generalized arc consistency. This supposes knowing the complexity of the related filtering functions regarding unit resolution.\nAt least two research directions follow from the ideas presented in this paper. The first one is to characterize the expression power of some other speed-up techniques used in modern sat solvers, like clause learning. The second one consists in the research of deduction techniques that can polynomially compute any cnf encoded polynomial time complexity filtering functions."}], "references": [{"title": "GAC via unit propagation", "author": ["Fahiem Bacchus"], "venue": "Notes in Computer Science,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Efficient cnf encoding of boolean cardinality constraints", "author": ["Olivier Bailleux", "Yacine Boufkhad"], "venue": "In Proceedings of the 9th International Conference on Principles and Practice of Constraint Programming", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "A translation of pseudo boolean constraints to sat", "author": ["Olivier Bailleux", "Yacine Boufkhad", "Olivier Roussel"], "venue": "Journal on Satisfiability, Boolean Modeling and Computation,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "New encodings of pseudo-boolean constraints into cnf", "author": ["Olivier Bailleux", "Yacine Boufkhad", "Olivier Roussel"], "venue": "In Theory and Applications of Satisfiability Testing - SAT 2009 (SAT\u201909),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "An extensible sat-solver", "author": ["Niklas E\u00e9n", "Niklas So\u00f6rensson"], "venue": "In Proceedings of SAT", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Arc consistency in sat", "author": ["Ian P. Gent"], "venue": "In Proceedings of ECAI 2002,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "Berkmin: A fast and robust sat solver", "author": ["E. Goldberg", "Y. Novikov"], "venue": "In Proc. of DATE", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "The monotone and planar circuit value problems are log space complete for p", "author": ["Leslie M. Goldschlager"], "venue": "SIGACT News,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1977}, {"title": "Unit refutations and horn sets", "author": ["L. Henschen", "L. Wos"], "venue": "J. ACM,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1974}, {"title": "Complete problems for deterministic polynomial time", "author": ["Neil D. Jones", "William T. Laaser"], "venue": "Theoretical Computer Science,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1976}, {"title": "Look-ahead versus look-back for satisfiability problems", "author": ["Chu Li", "Anbulagan"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1997}, {"title": "Towards robust cnf encodings of cardinality constraints", "author": ["Joao Marques-Silva", "In\u00eas Lynce"], "venue": "In Proceedings of the 13th International Conference on Principles and Practice of Constraint Programming", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Chaff: Engineering an efficient sat solver", "author": ["M. Moskewicz", "C. Madigan", "Y. Zhao", "L. Zhang", "S. Malik"], "venue": "In 39th Design Automation Conference,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2001}, {"title": "Towards an optimal cnf encoding of boolean cardinality constraints", "author": ["Carsten Sinz"], "venue": "In Proceedings of the 10th International Conference on Principles and Practice of Constraint Programming", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "The gap between the monotone and non monotone circuit complexity is exponential", "author": ["E. Tardos"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1988}, {"title": "A linear-time transformation of linear inequalities into conjunctive normal form", "author": ["J.P. Warners"], "venue": "Information Processing Letters,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1998}], "referenceMentions": [{"referenceID": 12, "context": "Unit resolution is a key feature of state of the art sat solvers [13] [7] [5], where it speeds up the search for solutions and inconsistencies.", "startOffset": 65, "endOffset": 69}, {"referenceID": 6, "context": "Unit resolution is a key feature of state of the art sat solvers [13] [7] [5], where it speeds up the search for solutions and inconsistencies.", "startOffset": 70, "endOffset": 73}, {"referenceID": 4, "context": "Unit resolution is a key feature of state of the art sat solvers [13] [7] [5], where it speeds up the search for solutions and inconsistencies.", "startOffset": 74, "endOffset": 77}, {"referenceID": 2, "context": "For example, the cnf encoding for pseudo Boolean constraints proposed in [3] allows unit resolution to restore generalized arc consistency.", "startOffset": 73, "endOffset": 76}, {"referenceID": 15, "context": "This is not the case with the encoding proposed in [16], which does not allow unit resolution to deduce as much information as the former encoding does.", "startOffset": 51, "endOffset": 55}, {"referenceID": 2, "context": "As a manner of speaking, the expressive power of unit resolution is best exploited using the encoding proposed in [3], with notable consequences on the resolution time.", "startOffset": 114, "endOffset": 117}, {"referenceID": 8, "context": "For example, this property holds for the formulae containing only Horn clauses [9].", "startOffset": 79, "endOffset": 82}, {"referenceID": 9, "context": "This decision problem denoted unit is known to be p-complete, meaning that for any problem \u03c0 with polynomial time complexity, there exists a log space reduction from \u03c0 to unit [10].", "startOffset": 176, "endOffset": 180}, {"referenceID": 7, "context": "Circuit value and monotone circuit value, which consist to determine the output value of a Boolean circuit (monotone Boolean circuit, respectively), given its input values, are both p-complete too [8].", "startOffset": 197, "endOffset": 200}, {"referenceID": 14, "context": "In this context, circuit value and monotone circuit value have not the same expressive power for at least two reasons : (1) monotone circuits can only compute monotone Boolean functions, while any Boolean function can be computed using a general Boolean circuit, and (2) there exist monotone Boolean functions which can be computed by polynomially sized Boolean circuits, but requiring an exponential number of gates to be computed using monotone circuits [15].", "startOffset": 456, "endOffset": 460}, {"referenceID": 5, "context": "In [6], a cnf encoding for enumerative constraints is proposed, which allows unit propagation to make the same deductions on the resulting formula as restoring arc consistency on the initial constraints does.", "startOffset": 3, "endOffset": 6}, {"referenceID": 1, "context": "It has been followed by various similar works on other kinds of constraints such as Boolean cardinality constraints [2] and pseudo-Boolean constraints [4], while in [1], a general way to construct such an encoding for any constraint is proposed.", "startOffset": 116, "endOffset": 119}, {"referenceID": 3, "context": "It has been followed by various similar works on other kinds of constraints such as Boolean cardinality constraints [2] and pseudo-Boolean constraints [4], while in [1], a general way to construct such an encoding for any constraint is proposed.", "startOffset": 151, "endOffset": 154}, {"referenceID": 0, "context": "It has been followed by various similar works on other kinds of constraints such as Boolean cardinality constraints [2] and pseudo-Boolean constraints [4], while in [1], a general way to construct such an encoding for any constraint is proposed.", "startOffset": 165, "endOffset": 168}, {"referenceID": 10, "context": "This is why some authors seek a trade-off between the size of the formulae and the inference power of unit resolution and other deduction rules implemented in sat solvers, such as the failed literal rule [11].", "startOffset": 204, "endOffset": 208}, {"referenceID": 13, "context": "For example, this approach is developed in [14] and [12] in the context of Boolean cardinality constraints.", "startOffset": 43, "endOffset": 47}, {"referenceID": 11, "context": "For example, this approach is developed in [14] and [12] in the context of Boolean cardinality constraints.", "startOffset": 52, "endOffset": 56}, {"referenceID": 10, "context": "As an interesting corollary of Theorem 1, the failed literal rule [11], which is a speed up technique implemented in some modern sat solver, can be simulated by unit propagation.", "startOffset": 66, "endOffset": 70}, {"referenceID": 14, "context": "It is known that pm(n), then vpm(n), have polynomial time computational complexity but exponential monotone circuit complexity [15].", "startOffset": 127, "endOffset": 131}], "year": 2013, "abstractText": "This preliminary report addresses the expressive power of unit resolution regarding input data encoded with partial truth assignments of propositional variables. A characterization of the functions that are computable in this way, which we propose to call propagatable functions, is given. By establishing that propagatable functions can also be computed using monotone circuits, we show that there exist polynomial time complexity propagable functions requiring an exponential amount of clauses to be computed using unit resolution. These results shed new light on studying cnf encodings of np-complete problems in order to solve them using propositional satisfiability algorithms. A paper is being drafted, which aims to present the concepts introduced in the present report and the underlying scientific issues in a more simple way.", "creator": "LaTeX with hyperref package"}}}