{"id": "1202.6157", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Feb-2012", "title": "Distributed Power Allocation with SINR Constraints Using Trial and Error Learning", "abstract": "We model the network as a parallel Gaussian interference channel and introduce a fully decentralized algorithm (based on trial and error) that is able to statistically achieve a congiguration that meets performance requirements. Unlike existing solutions, our algorithm requires only local information and can learn stable and efficient operating points by using only one bit feedback. We model the network under two different game theory frameworks: normal form and satisfaction form. We show that the converged points correspond to equilibrium points, namely Nash and satisfaction equilibrium. Similarly, we provide sufficient conditions for the convergence algorithm in both formulations. In addition, we provide analytical results to estimate the performance of the algorithm as a function of network parameters.", "histories": [["v1", "Tue, 28 Feb 2012 09:51:29 GMT  (85kb,D)", "http://arxiv.org/abs/1202.6157v1", "6 pages, 3 figures, accepted at WCNC 2012"]], "COMMENTS": "6 pages, 3 figures, accepted at WCNC 2012", "reviews": [], "SUBJECTS": "cs.GT cs.AI cs.LG", "authors": ["luca rose", "samir m perlaza", "m\\'erouane debbah", "christophe j le martret"], "accepted": false, "id": "1202.6157"}, "pdf": {"name": "1202.6157.pdf", "metadata": {"source": "CRF", "title": "Distributed Power Allocation with SINR Constraints Using Trial and Error Learning", "authors": ["Luca Rose", "Samir M. Perlaza", "M\u00e9rouane Debbah", "Christophe J. Le Martret"], "emails": ["luca.rose@thalesgroup.com", "merouane.debbah)@supelec.fr", "martret@thalesgroup.com"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nIn this paper, we consider a network where several transmitter-receiver pairs communicate through a common bandwidth divided into several orthogonal sub-bands, thus, subject to mutual interference. All devices must guarantee certain quality of service (QoS), expressed in terms of signal to interference plus noise ratio (SINR). The behaviour of the devices is designed for achieving a stable network operating point (equilibrium) where the maximum number of communicating pairs satisfy their QoS with the minimum global power consumption. Network operating point must be achieved by the radio devices in a fully decentralized way by selecting their power allocation policy, i.e., selecting a sub-band and a power level for each transmission. In this scenario, all communications take place in absence of a centralized controller and neither cooperation nor exchange of information between different pairs are considered. For instance, this scenario may model the case of tactical radios and ad hoc networks, where, in order to set power and channel, current solutions require a certain level of cooperation with exchange of information between the devices or a manual setting. The closest works to ours are [1], [2] and [3]. In [1], variational inequality theory is used to design a centralized power control algorithm for this scenario, in [2] the authors show that, if the assumption of S-modularity holds for the corresponding game,\nthen best response dynamics [4] converges to a generalized Nash equilibrium (GNE); in [3], the authors provide, under the assumption of low interference, a sufficient condition for the convergence of the iterative water-filling algorithm to a GNE. It is worth noting that the works in [1], [2] and [3] assume a compact and convex set of actions, i.e, the possible power allocation (PA) vectors may take any value in the corresponding simplex. Conversely, in our work, we consider a finite action set by quantizing the possible available powers into a certain amount of levels. Basically, this is because in practice power levels must be expressed in a finite amount of bits. Moreover, several authors have pointed out that better global performance (e.g. spectral efficiency) is achieved when the set of PA vectors is substantially reduced [5], [6], [7], [8]. Indeed, this effect has been reported as a Braess kind paradox [9]. In this paper, our contribution is twofold: first, we present a fully decentralized learning algorithm able to keep the SINR level above a certain threshold a high proportion of the time, by means of only one bit feedback and relying only on local information [4]; second, we analytically study the convergence properties and the convergence point, which is shown to be an efficient Nash equilibrium (NE) in terms of global performance. The paper is organized as follows. In Sec. II, we describe the wireless scenario and we formalize the problem; in Sec. III, we model the system as a game in normal form and in satisfaction form; in Sec. IV we present the trial and error algorithm as introduced in [10]; in Sec. V, we present a formal analytical study of the convergence properties (i.e., expected number of iterations to reach the NE and the satisfaction equilibrium (SE)), as well as, the expected fraction of time the system is at the NE and at the SE; in Sec. VI we validate our analysis through numerical simulations; the paper is concluded in Sec. VII."}, {"heading": "II. SYSTEM MODEL", "text": "Let us consider the system described in Fig. 1. Here, a set K 4= {1, ...,K} of transmitter-receiver pairs share a set C 4= { b(1), ..., b(C) } of orthogonal sub-bands. Transmitter k\nis allowed to transmit over one sub-band at a time at a given power level. We denote by pk \u2208 P, with P 4 = {0, ..., PMAX}, |P| = Q, and bk \u2208 C, the power level and the frequency sub-band chosen by transmitter k respectively. We denote by\nar X\niv :1\n20 2.\n61 57\nv1 [\ncs .G\nT ]\n2 8\nFe b\n20 12\nTx Rx\np = (p1, p2, ..., pK) the network power allocation vector, by b = (b1, b2, ..., bK) the spectrum occupation vector and by a = (a1, a2, ..., aK) a network configuration vector, where ak = (pk, bk). To communicate, pairs have to achieve a sufficient SINR level, i.e., SINRk > \u0393 where we denote by \u0393 the minimum SINR threshold allowing transmission. Receivers treat interference as Gaussian noise, thus:\nSINRk (a) = pkg\n(bk) k,k \u03c32 + \u2211 l\u2208K\\k plg (bl) k,l 1{bl=bk} , (1)\nwhere g(b)k,l represents the channel power gain between transmitter l and receiver k over sub-band b, \u03c32 is the power of the thermal noise assumed constant over the whole spectrum and 1{} represents the indicator function. In our scenario, we assume block-fading channels, i.e., channel realizations are time invariant for the whole transmission. Our objective is the satisfaction of the SINR constraints for the largest possible set of pairs by using the lowest global energy consumption. Formally, we want the network configuration vector a\u2217 to be a solution of the following optimization problem{\nminp\u2208PK \u2211K k=1 pk(n) s.t. SINRk (a) > \u0393 \u2200k \u2208 K\u2217 , (2)\nwhere we denote by K\u2217 \u2286 K the largest subset of links able to simultaneously achieve a sufficient SINR level. Generally, to achieve this goal a central controller knowing all the network\u2019s parameters is required. In the following sections, we propose a decentralized algorithm demanding no information on the network which will steer the system to a solution of (2)."}, {"heading": "III. GAME FORMULATION", "text": "In this section, we model the scenario presented in Sec 1 in two different formulations: a normal-form game and a satisfaction-form [11] game.\nA. Normal form formulation\nWe model the network described above by the game in normal form\nG = ( K,A, {uk}k\u2208K ) . (3)\nHere, K represents the set of players, A is the joint set of actions, that is, A = A1 \u00d7 A2 \u00d7 ... \u00d7 AK where Ak = C \u00d7 P and we introduce the utility function uk : A \u2192 R defined by:\nuk(a) = 1\n1 + \u03b2 ( PMAX \u2212 pk PMAX + \u03b21{SINRk(a)>\u0393} ) , (4)\nwhere \u03b2 is a design parameter discussed in Sec V. This function has been designed to be monotonically decreasing with the power consumption, and monotonically increasing with the number of players who achieve the minimum SINR. In the following, we show that, with this utility function, the NE of the game G can solve the problem stated in (2). Moreover, note that to evaluate (4) each transmitter only requires local information, since 1{SINRk(a)>\u0393} can easily be fed back by the receiver with 1 bit.\nDefinition 1: (Interdependent game). G is said to be interdependent if for every non-empty subset K+ \u2282 K and every action profile a = (aK+ ,a\u2212K+)\n1 such that aK+ is the action profile of all players in K+, it holds that:\n\u2203i /\u2208 K+, \u2203a\u2032K+ 6= aK+ : ui(a \u2032 K+ ,a\u2212K+) 6= ui(aK+ ,a\u2212K+)\n(5) In the following, we assume that game G is interdependent. This is a reasonable assumption, since, physically, this means that no link is isolated from the others. The solution concept used under this formulation is the Nash equilibrium, which we define as follows:\nDefinition 2: (Nash equilibrium in pure strategies). An action profile a\u2217 \u2208 A is a NE of game G if \u2200 k \u2208 K and \u2200a\u2032k \u2208 Ak\nuk(a \u2217 k, a \u2217 \u2212k) \u2265 uk(a \u2032 k, a \u2217 \u2212k). (6)\nTo measure the efficiency of each NE, we introduce the social welfare function, defined by the sum of all individual utilities: W (a) = \u2211K k=1 uk(a).\nB. Satisfaction form\nThe satisfaction form is a game theoretical formulation modelling scenarios where players are exclusively interested in the satisfaction of their individual QoS constraints. Let us define the game as\nG\u2032 = ( K,A, {fk}k\u2208K ) , (7)\nwhere K, A follow the previous definitions and the satisfaction correspondence fk : A\u2212k \u2192 R is defined by\nfk(a\u2212k) = (ak \u2208 Ak : SINRk(ak,a\u2212k, ) \u2265 \u0393) . (8)\nThe solution concept used under this formulation is the satisfaction equilibrium (SE) defined as:\nDefinition 3: (Satisfaction equilibrium). A satisfaction equilibrium of game G\u2032 is an action profile a\u2032 \u2208 A such that \u2200k \u2208 K,\na\u2032k \u2208 fk ( a\u2032\u2212k ) . (9)\nMoreover, we measure the effort of player k due to the use of a particular action ak by using the effort function [11] \u03a6k : Ak \u2192 [0, 1]. We can, then, define an efficient satisfaction equilibrium (ESE) as:\nDefinition 4: (Efficient satisfaction equilibrium). A satisfaction equilibrium a\u2032 is said to be efficient, if \u2200k \u2208 K\na\u2032k \u2208 arg min ak\u2208fk(a\u2032\u2212k) \u03a6k(ak) (10)\n1Here, a\u2212K+ refers to the action profile of all the players that are not in K+\nIn brief, an ESE is an action profile where all players are satisfied and no player may decrease its individual effort by unilateral deviation. Since our optimization problem is to minimize the overall transmit power, we identify the effort by the function: \u03a6k(ak) = pk."}, {"heading": "IV. ALGORITHM DESCRIPTION", "text": "In this section, we briefly describe the trial and error (TE) algorithm introduced in [10], [12]. Later, we characterize the degrees of freedom of the system to fit in our scenario. In TE learning, each player k locally implements a state machine, at each iteration n, a state is defined by the triplet:\nZk(n) = {mk(n), a\u0304k(n), u\u0304k(n)} , (11)\nwhere mk(n) \u2208 {C,C+, C\u2212, D} represents a \u201dmood\u201d, i.e., a characteristic that defines the machine reaction to its experience of the environment, a\u0304k \u2208 A and u\u0304k \u2208 [0, 1] represents a benchmark action and benchmark utility, respectively. There are four possible moods: content (C), watchful (C\u2212), hopeful (C+), discontent (D). In the following, we characterize the behaviour of each player in every possible mood. \u2022 Content\nIf at stage n player k is content, it uses the benchmarked action a\u0304k(n) with probability (1 \u2212 ) and experiments a new action a\u2032k(n) with probability . If at stage n the player decided to experiment, at stage (n + 1) it evaluates the utility u\u2032k(n + 1) associated with a\u2032k(n) as follows: if u \u2032 k(n + 1) < u\u0304k(n) then Zk(n + 1) = Zk(n), otherwise if u\u2032k(n + 1) > u\u0304k(n), then, with probability G(u \u2032 k(n+1)\u2212u\u0304k(n)), a new action and utility benchmark are set out, i.e., u\u0304k(n+ 1) = u\u2032k(n+ 1) and a\u0304k(n+ 1) = a\u2032k(n), respectively. Here, G(\u00b7) must be such that:\n0 < G(\u2206u) < 1\n2 , (12)\nwe opt for a linear formulation: G(\u2206u) = \u22120.2\u2206u+ 0.2. \u2022 Hopeful-Watchful\nIf player k achieves an increment or a decrement in its utility without having experimented at the previous stage, then the mood become hopeful or watchful, according to the following rule: (i) if u\u2032k(n + 1) > u\u0304k(n) then, mk(n + 1) = C+, a\u0304k(n + 1) = a\u0304k(n) and u\u0304k(n + 1) = u\u0304k(n); (ii) if mk(n + 1) = C\u2212, then a\u0304k(n + 1) = a\u0304k(n) and u\u0304k(n + 1) = u\u0304k(n). If player k observes an improvement also at the next stage (i.e., u\u2032k(n + 2) > u\u0304k(n + 1)), then the mood switches to content and the benchmark utility is updated with the new one: mk(n+2) = C and u\u0304k(n+2) = u\u2032k(n+1). On the contrary, if a loss is observed also at the next stage (i.e., u\u2032k(n + 2) < u\u0304k(n + 1)), then the mood switches to discontent mk(n+ 2) = D. \u2022 Discontent If player k is discontent, it experiments a new action (a\u2032k(n)) at each step n. We refer to this behaviour as noisy search. When the corresponding utility u\u2032k(n+1) is observed, with probability p = F (u \u2032 k(n+1) the mood turns to content mk(n + 1) = C, a new action and utility benchmark are set up, u\u0304k(n + 1) = u\u2032k(n + 1) and a\u0304k(n + 1) = a \u2032 k(n + 1), while, with probability\n(1\u2212p) it continues the noisy search. Note that function F must be such that\n0 < F (u) < 1\n2K , (13)\nwe opt for a linear formulation: F (u) = \u2212 0.2K u+ 0.2 K .\nA. Algorithm properties\nHereunder, we restate Theorem 1 in [10] and Theorem 1 in [12] using our notation.\nTheorem 1: Let G have at least one pure Nash equilibrium and let be small enough. Then, a pure Nash equilibrium is played at least (1\u2212 \u03b4) of the time. This theorem introduces a different notion of convergence. Generally [4], we say that an algorithm converges when it approaches a certain solution as n\u2192\u221e while, here, it means that this solution is played with a high probability an high proportion of the total time.\nTheorem 2: Let G have at least one pure Nash equilibrium and let each player employ TE, then a Nash equilibrium that maximizes the sum utility among all equilibrium states is played a large proportion of the time.\nNote that, generally, different equilibria are associated with different social welfare values. Learning algorithms available in the literature [4], [13], do not always take into consideration the problem of equilibrium selection, which is a central issue when aiming at global performance."}, {"heading": "V. MAIN RESULTS", "text": "A. Working point properties\nIn this section, we present our results based on the previous analysis. Proofs are omitted due to space constraints. Based on the game theoretical formulation in Sec. III and the algorithm properties in Sec. IV we state the following:\nTheorem 3: Let N 6= \u2205 be the set of NE of G, let \u03b2 > K and let us denote by Kl the number of players satisfied at the l-th NE. Then, TE converges to the NE where Kl is maximized. This theorem states that, if \u03b2 > K, then TE converges to a state where the largest possible number of players are satisfied and are at the NE. Here, \u03b2 represents the interest a network designer has in satisfying the largest set of players over the minimization of the network power consumption. The next two theorems allow us to link this result with the original global design problem expressed in (2).\nTheorem 4: Let (i) A\u2020 6= \u2205 be the set of solutions of (2) with K\u2217 = K, (ii) N 6= \u2205 be the set of NE of G and N \u2229A\u2020 6= \u2205 and let \u03b2 > K. Then, TE learning converges to an action profile a\u2217 such that a\u2217 \u2208 N \u2229A\u2020 and is an ESE. This theorem links together the concept of ESE of game G\u2032, the NE of game G and the solutions of (2). Indeed, when the assumptions are met, the TE algorithm will reach a network state where: (i) all players are satisfied, (ii) the network power consumption is minimized. Note that, generally, it is possible for (2) to have a solution that is not a NE of G.\nTheorem 5: Let (2) have no solution forK\u2217 = K and fix \u03b2 > K. Let K\u2217 be the largest number of players that can be simultaneously satisfied and let K\u2217m be the m-th set, such that |K\u2217m| = K\u2217, where (2) has a solution; let also beA\u2217m the corresponding set of solutions.\nLet us define A\u2217 = \u22c3 mA \u2217 m and N 6= \u2205 the set of NE. Then, TE learning converges to an action profile a\u2217 such that a\u2217 \u2208 N \u2229A\u2217. The previous theorem states that, when some players cannot satisfy their SINR condition, the TE algorithm selects the subset K\u2217m among all possible K\u2217 such that: (i) the highest number of players are satisfied, (ii) the network power consumption is minimized (with the unsatisfied players employing 0 power).\nCorollary 1: Let \u2200k and \u2200b be g(b)k,k \u2265 \u0393\u03c32 PMAX , let C \u2265 K and fix \u03b2 > K. Then, TE converges to a solution of (2). Basically, this corollary means that, if transmitters and receivers are satisfiable on each channel (high SNR regime), then TE converges to an optimal working point.\nB. Convergence analysis\nTE algorithm defines a discrete time Markov chain (DTMC) on the set of the states. Studying the behaviour of the algorithm on the complete chain is an intractable problem due to the number of states, transitions and parameters. In the following, we provide an approximated DTMC that allows us to estimate: (a) the expected converging time at the NE and at the SE, (b) the expected fraction of time the system is at the NE and at the SE. Under the light of the description made in Sec. IV, we state the following: (i) the fraction of time spent in the watchful or hopeful states is negligible compared to the one in discontent or content one; (ii) at any time, the probability of having more than one player discontent is negligible. In the following, we assume C > K and a simplified channel model, defined as {\ng (c) k,k = 1 \u2200k, \u2200c g\n(c) j,k = 1 2 \u2200k, \u2200j 6= k, \u2200c\n. (14)\nIn Sec. VI we will show that these results are good approximations also under less restrictive conditions. The resulting DTMC for studying TE behaviour is represented in Fig. 2. When interested in convergence time and occupancy frequency of the NE, state Eq represents the NE, and CK\u2212k a state where K\u2212k players are using an individually optimal action and D a state where one player is discontent. The transition probabilities we evaluate are listed hereunder, the detailed description is omitted due to space constraints.\nP (NE,D) = K(K\u22121)2 2\nC2\n( Q\u22121 Q )2 (15)\nP (D,NE) = (C\u2212K+1))\nCQ (16)\nP (D,CK\u2212k) = (C\u2212K+k) Ck (K\u22121)! (K\u2212k)! (17)\nP (CK\u2212k, CK\u2212k\u22121) = (K \u2212 k)C\u2212kCQ 1+G(\u2206u). (18)\nThe analysis of this DTMC allows us to state the following theorems:\nTheorem 6: The expected number of iterations needed before reaching the NE for the first time T\u0304NE is bounded as follows:\nT\u0304NE \u2264 CQ\n(1+G(\u2206u)) (C \u2212K)\n( 1 + log ( K (C \u2212K + 1)\nC + 1 )) T\u0304NE \u2265 CQ\n(1+G(\u2206u)) (C \u2212K)\n( \u03b3 + log ( K (C \u2212K)\nC\n)) ;\nwhere, \u03b3 ' 0.577 is the Euler-Mascheroni constant. Note that, the time demanded to converge is directly proportional to the degree of freedom (i.e., |Ak| = CQ) and inversely to the experimentation probability . Nonetheless, as we shall see, choosing a large increases the instability of the NE and, consequentially, the network performance.\nTheorem 7: The expected fraction of time the system is at a NE (1\u2212 \u03b4) is:\n(1\u2212 \u03b4) = 1 1 + P (NE,D)TBNE , (19)\nwhere\nTBNE \u2264 K\u2211 k=1 P (D,CK\u2212k)TCNE(k) + P (D,NE) (1\u2212 P (D,D))2\nTCNE(k) = CQ\n1+G(\u2206u) (C \u2212K)\n( \u03b3 + log ( K (C \u2212 k + 1)\nC + 1 )) P (D,D) = 1\u2212 P (D,NE)\u2212\nK\u2211 k=1 P (D,CK\u2212k).\nHere, (1 \u2212 \u03b4) depends on 1 2 as in (15). This means that, the larger the the shorter the time the system is at a NE. To evaluate convergence time and occupancy frequency of the SE we, again, make use of Fig. 2. In this case, state Eq represents the SE, CK\u2212k is a state where K \u2212 k players are satisfied and D a state where one user is discontent. The corresponding transition probabilities are listed hereunder.\nP (SE,D) = K(K\u22121)2 2\nC2\n( Q\u22121 Q )2 (20)\nP (D,SE) = (C\u2212K+1)\nC (21)\nP (D,CK\u2212k) = 1 Ck (K\u22121)! (K\u2212k)! (C \u2212K + k) (22)\nP (CK\u2212k, CK\u2212k\u22121) = (K \u2212 k)QS (C\u2212k) 1+G(\u2206u) CQ . (23)\nGiven the model in (14) and C > K, the term QS < Q represents the number of power quantization levels that a player can employ to successfully achieve SINRk > \u0393 on any free channel. We can, then, state the following theorems:\nTheorem 8: The expected number of iterations needed before reaching the SE for the first time T\u0304SE is bounded as follows:\nT\u0304SE \u2264 CQ/QS\n(1+G(\u2206u) (C \u2212K)\n( 1 + log ( K (C \u2212K + 1)\nC + 1 )) T\u0304SE \u2265 CQ/QS\n(1+G(\u2206u) (C \u2212K)\n( \u03b3 + log ( K (C \u2212K)\nC\n)) .\nUnder assumption (14), being satisfied is a weaker condition than being at the NE, thus, it results that TNE \u2265 TSE . Predictably, larger PMAX and lower \u0393 increasing QS , are able to improve the converging speed.\nTheorem 9: The expected fraction of time the system is at a SE FSE is:\nFSE = 1\n1 + P (SE,D)TBSE (24)\nwhere\nTBSE \u2264 K\u2211 k=1 P (D,CK\u2212k)TCSE(k) + P (D,SE) (1\u2212 P (D,D))2\nTCSE(k) = CQ\n(C \u2212K)QS\n( \u03b3 + log ( K (C \u2212 k + 1)\nC + 1 )) P (D,D) = 1\u2212 P (D,SE)\u2212\nK\u2211 k=1 P (D,CK\u2212k)."}, {"heading": "VI. SIMULATION RESULTS", "text": "The purpose of this section is threefold. First, we run simulations to numerically validate the DTMCs introduced in Sec. V, second, we validate the results on more general channel models, then, we evaluate the performance of the algorithm in terms of satisfaction and power employed. The first two experiments have been run for two different sets of parameters. The first set is composed by: K = 3, C = 4, = 0.02 and 6 \u2264 Q \u2264 10. The second set is composed by K = 4, C = 5, = 0.02 and 6 \u2264 Q \u2264 10. In our first experiment, we run 107 iterations to estimate (1 \u2212 \u03b4) under two different channel models: the simple channels expressed in (14) and a Rayleigh channel. The results are summarized in Figure 3. As we can see, the analysis, brought on particular channel model, proves to be sufficiently precise also under more general formulations. In our second experiment, we estimated the converging time and compared with the analytical results in Figure 4. As we can see, increasing the action set dimension, i.e., increasing C or Q, brings slower convergence rate since the algorithm requires more time to explore all the possibilities. Note that, here, convergence time means the time needed by the system to work at the NE for the first time. The third experiment\u2019s parameter set is composed as follows: K = 4, C = 5, = 0.02 Q = 8 with the simplified channel model as in (14). Here, we have run 103 tests, each one composed by 6000 iteration of TE. The results are showed in Fig 5, where the upper curve represents the fraction of players satisfied, while the lower curve represents the ratio between the average power employed by the network and the optimal power that should be employed to satisfy all the players. In average, in accordance with Figure 3, the system reaches an optimal equilibrium (all players satisfied\nand minimum amount of power employed) after around 2200 iterations. Note that, even though, for some specific scenarios, this number may be too high, the configurations selected by the algorithm before the convergence are just slightly inefficient. Indeed, a configuration where all the players are able to satisfy their SINR constraints is averagely reached after 600 iterations. Moreover, before this, we observe that only a fraction of satisfiable players is satisfied, in spite of the amount of power used."}, {"heading": "VII. CONCLUSION", "text": "In this paper, we have studied a power control problem in a self configuring decentralized network. We presented a new decentralized algorithm able to steer the network into a working point where the maximum number of transmitterreceiver pairs achieves a sufficient SINR while minimizing the network power consumption. The algorithm does not assume\nany prior knowledge of the network and can learn an efficient equilibrium with only one bit of feedback. By assuming a particular channel realization, we have analytically estimated the expected performance of the algorithm through a Markov chain description of the algorithm behaviour. Finally we have shown through Monte-Carlo simulations that the analysis is approximatively correct also for general channel models."}, {"heading": "VIII. ACKNOWLEDGEMENT", "text": "This research work was carried out in the framework of the\nCORASMA EDA Project B-0781-IAP4-GC."}], "references": [{"title": "Fixed point optimization algorithm and its application to power control in CDMA data networks", "author": ["H. Iiduka"], "venue": "Mathematical Programming, Oct. 2010.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "S-modular games and power control in wireless networkse", "author": ["E. Altman", "Z. Altman"], "venue": "IEEE Trans. Automat. Contr.s, vol. 48, no. 5, pp. 839\u2013842, May 2003.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "Distributed power allocation with rate constraints in Gaussian parallel interference channels", "author": ["J.-S. Pang", "G. Scutari", "F. Facchinei", "C. Wang"], "venue": "IEEE Trans. on Info. Theory, vol. 54, no. 8, pp. 3471\u20133489, Aug. 2008.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning equilibria with partial information in decentralized wireless networks", "author": ["L. Rose", "S. Lasaulce", "S.M. Perlaza", "M. Debbah"], "venue": "IEEE Communications Magazine, vol. 49, no. 8, pp. 136 \u2013142, Aug. 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Water filling may not good neighbors make", "author": ["O. Popescu", "C. Rose"], "venue": "In Proceedings 2003 IEEE Global Telecommunications Conference - GLOBECOM 03, 2003, pp. 1766\u20131770.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "On the Nash equilibria in decentralized parallel interference channels", "author": ["L. Rose", "S.M. Perlaza", "M. Debbah"], "venue": "IEEE Workshop on Game Theory and Resource Allocation for 4G, Kyoto, Japan, Jun. 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "A Braess type paradox in power control over interference channels", "author": ["E. Altman", "V. Kamble", "H. Kameda"], "venue": "1st International ICST Workshop on Physics Inspired Paradigms for Wireless Communications and Network, May 2008.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "On the benefits of bandwidth limiting in decentralized vector multiple access channels", "author": ["S.M. Perlaza", "M. Debbah", "S. Lasaulce", "H. Bogucka"], "venue": "Proc. 4th Intl. Conf. on Cognitive Radio Oriented Wireless Networks and Comm. (CROWNCOM), May 2009.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "On a paradox of traffic planning", "author": ["D. Braess", "A. Nagurney", "T. Wakolbinger"], "venue": "Transportation Science, vol. 39, pp. 446\u2013450, November 2005.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning by trial and error", "author": ["H.P. Young"], "venue": "Tech. Rep., 2008.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Quality-ofservice provisioning in decentralized networks: A satisfaction equilibrium approach", "author": ["S.M. Perlaza", "H. Tembine", "S. Lasaulce", "M. Debbah"], "venue": "IEEE Journal of Selected Topics in Signal Processing, Feb. 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Efficiency and equilibrium in trial and error learning", "author": ["B.S. Pradelski", "H.P. Young"], "venue": "Tech. Rep., 2010.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Optimal linear precoding strategies for wideband non-cooperative systems based on game theory \u2013 part II: Algorithms", "author": ["G. Scutari", "D. Palomar", "S. Barbarossa"], "venue": "IEEE Trans. on Signal Processing, vol. 56, no. 3, pp. 1250\u20131267, mar. 2008.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "The closest works to ours are [1], [2] and [3].", "startOffset": 30, "endOffset": 33}, {"referenceID": 1, "context": "The closest works to ours are [1], [2] and [3].", "startOffset": 35, "endOffset": 38}, {"referenceID": 2, "context": "The closest works to ours are [1], [2] and [3].", "startOffset": 43, "endOffset": 46}, {"referenceID": 0, "context": "In [1], variational inequality theory is used to design a centralized power control algorithm for this scenario, in [2] the authors show that, if the assumption of S-modularity holds for the corresponding game, then best response dynamics [4] converges to a generalized Nash equilibrium (GNE); in [3], the authors provide, under the assumption of low interference, a sufficient condition for the convergence of the iterative water-filling algorithm to a GNE.", "startOffset": 3, "endOffset": 6}, {"referenceID": 1, "context": "In [1], variational inequality theory is used to design a centralized power control algorithm for this scenario, in [2] the authors show that, if the assumption of S-modularity holds for the corresponding game, then best response dynamics [4] converges to a generalized Nash equilibrium (GNE); in [3], the authors provide, under the assumption of low interference, a sufficient condition for the convergence of the iterative water-filling algorithm to a GNE.", "startOffset": 116, "endOffset": 119}, {"referenceID": 3, "context": "In [1], variational inequality theory is used to design a centralized power control algorithm for this scenario, in [2] the authors show that, if the assumption of S-modularity holds for the corresponding game, then best response dynamics [4] converges to a generalized Nash equilibrium (GNE); in [3], the authors provide, under the assumption of low interference, a sufficient condition for the convergence of the iterative water-filling algorithm to a GNE.", "startOffset": 239, "endOffset": 242}, {"referenceID": 2, "context": "In [1], variational inequality theory is used to design a centralized power control algorithm for this scenario, in [2] the authors show that, if the assumption of S-modularity holds for the corresponding game, then best response dynamics [4] converges to a generalized Nash equilibrium (GNE); in [3], the authors provide, under the assumption of low interference, a sufficient condition for the convergence of the iterative water-filling algorithm to a GNE.", "startOffset": 297, "endOffset": 300}, {"referenceID": 0, "context": "It is worth noting that the works in [1], [2] and [3] assume a compact and convex set of actions, i.", "startOffset": 37, "endOffset": 40}, {"referenceID": 1, "context": "It is worth noting that the works in [1], [2] and [3] assume a compact and convex set of actions, i.", "startOffset": 42, "endOffset": 45}, {"referenceID": 2, "context": "It is worth noting that the works in [1], [2] and [3] assume a compact and convex set of actions, i.", "startOffset": 50, "endOffset": 53}, {"referenceID": 4, "context": "spectral efficiency) is achieved when the set of PA vectors is substantially reduced [5], [6], [7], [8].", "startOffset": 85, "endOffset": 88}, {"referenceID": 5, "context": "spectral efficiency) is achieved when the set of PA vectors is substantially reduced [5], [6], [7], [8].", "startOffset": 90, "endOffset": 93}, {"referenceID": 6, "context": "spectral efficiency) is achieved when the set of PA vectors is substantially reduced [5], [6], [7], [8].", "startOffset": 95, "endOffset": 98}, {"referenceID": 7, "context": "spectral efficiency) is achieved when the set of PA vectors is substantially reduced [5], [6], [7], [8].", "startOffset": 100, "endOffset": 103}, {"referenceID": 8, "context": "Indeed, this effect has been reported as a Braess kind paradox [9].", "startOffset": 63, "endOffset": 66}, {"referenceID": 3, "context": "In this paper, our contribution is twofold: first, we present a fully decentralized learning algorithm able to keep the SINR level above a certain threshold a high proportion of the time, by means of only one bit feedback and relying only on local information [4]; second, we analytically study the convergence properties and the convergence point, which is shown to be an efficient Nash equilibrium (NE) in terms of global performance.", "startOffset": 260, "endOffset": 263}, {"referenceID": 9, "context": "IV we present the trial and error algorithm as introduced in [10]; in Sec.", "startOffset": 61, "endOffset": 65}, {"referenceID": 10, "context": "GAME FORMULATION In this section, we model the scenario presented in Sec 1 in two different formulations: a normal-form game and a satisfaction-form [11] game.", "startOffset": 149, "endOffset": 153}, {"referenceID": 10, "context": "Moreover, we measure the effort of player k due to the use of a particular action ak by using the effort function [11] \u03a6k : Ak \u2192 [0, 1].", "startOffset": 114, "endOffset": 118}, {"referenceID": 0, "context": "Moreover, we measure the effort of player k due to the use of a particular action ak by using the effort function [11] \u03a6k : Ak \u2192 [0, 1].", "startOffset": 129, "endOffset": 135}, {"referenceID": 9, "context": "In this section, we briefly describe the trial and error (TE) algorithm introduced in [10], [12].", "startOffset": 86, "endOffset": 90}, {"referenceID": 11, "context": "In this section, we briefly describe the trial and error (TE) algorithm introduced in [10], [12].", "startOffset": 92, "endOffset": 96}, {"referenceID": 0, "context": ", a characteristic that defines the machine reaction to its experience of the environment, \u0101k \u2208 A and \u016bk \u2208 [0, 1] represents a benchmark action and benchmark utility, respectively.", "startOffset": 107, "endOffset": 113}, {"referenceID": 9, "context": "Hereunder, we restate Theorem 1 in [10] and Theorem 1 in [12] using our notation.", "startOffset": 35, "endOffset": 39}, {"referenceID": 11, "context": "Hereunder, we restate Theorem 1 in [10] and Theorem 1 in [12] using our notation.", "startOffset": 57, "endOffset": 61}, {"referenceID": 3, "context": "Generally [4], we say that an algorithm converges when it approaches a certain solution as n\u2192\u221e while, here, it means that this solution is played with a high probability an high proportion of the total time.", "startOffset": 10, "endOffset": 13}, {"referenceID": 3, "context": "Learning algorithms available in the literature [4], [13], do not always take into consideration the problem of equilibrium selection, which is a central issue when aiming at global performance.", "startOffset": 48, "endOffset": 51}, {"referenceID": 12, "context": "Learning algorithms available in the literature [4], [13], do not always take into consideration the problem of equilibrium selection, which is a central issue when aiming at global performance.", "startOffset": 53, "endOffset": 57}], "year": 2012, "abstractText": "In this paper, we address the problem of global transmit power minimization in a self-configuring network where radio devices are subject to operate at a minimum signal to interference plus noise ratio (SINR) level. We model the network as a parallel Gaussian interference channel and we introduce a fully decentralized algorithm (based on trial and error) able to statistically achieve a configuration where the performance demands are met. Contrary to existing solutions, our algorithm requires only local information and can learn stable and efficient working points by using only one bit feedback. We model the network under two different game theoretical frameworks: normal form and satisfaction form. We show that the converging points correspond to equilibrium points, namely Nash and satisfaction equilibrium. Similarly, we provide sufficient conditions for the algorithm to converge in both formulations. Moreover, we provide analytical results to estimate the algorithm\u2019s performance, as a function of the network parameters. Finally, numerical results are provided to validate our theoretical conclusions.", "creator": "LaTeX with hyperref package"}}}