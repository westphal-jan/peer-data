{"id": "1203.3464", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2012", "title": "Gibbs Sampling in Open-Universe Stochastic Languages", "abstract": "Languages for open universal probability models (OUPMs) can present situations with an unknown number of objects and identical uncertainty. While such cases occur in a variety of important real-world applications, existing universal inference methods for OUPMs are far less efficient than those for more restricted languages and model classes. This paper helps to address this shortcoming in some ways by introducing and proving correct a generalization of Gibbs samples in sub-worlds with possibly different model structures. It was implemented for BLOG, a well-known OUPM language. Combined with compilation time optimizations, the resulting algorithm leads to very significant accelerations over existing methods for secondary test cases and greatly improves the practicality of OPM languages.", "histories": [["v1", "Thu, 15 Mar 2012 11:17:56 GMT  (423kb)", "http://arxiv.org/abs/1203.3464v1", "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["nimar s arora", "rodrigo de salvo braz", "erik b sudderth", "stuart russell"], "accepted": false, "id": "1203.3464"}, "pdf": {"name": "1203.3464.pdf", "metadata": {"source": "CRF", "title": "Gibbs Sampling in Open-Universe Stochastic Languages", "authors": ["Nimar S. Arora", "Rodrigo de Salvo Braz"], "emails": [], "sections": [{"heading": null, "text": "Languages for open-universe probabilistic models (OUPMs) can represent situations with an unknown number of objects and identity uncertainty. While such cases arise in a wide range of important real-world applications, existing general purpose inference methods for OUPMs are far less efficient than those available for more restricted languages and model classes. This paper goes some way to remedying this deficit by introducing, and proving correct, a generalization of Gibbs sampling to partial worlds with possibly varying model structure. Our approach draws on and extends previous generic OUPM inference methods, as well as auxiliary variable samplers for nonparametric mixture models. It has been implemented for BLOG, a well-known OUPM language. Combined with compile-time optimizations, the resulting algorithm yields very substantial speedups over existing methods on several test cases, and substantially improves the practicality of OUPM languages generally."}, {"heading": "1 Introduction", "text": "General purpose probabilistic modelling languages aim to facilitate the development of complex models while providing effective, general inference methods so that the model-builder need not write model-specific inference code for each application from scratch. For example, BUGS (Spiegelhalter et al., 1996) can represent directed graphical models over indexed sets of random variables and uses MCMC inference (in particular, Gibbs sampling where this is possible).\nAs the expressive power of modelling languages increases, the range of representable problems also\ngrows. The class of first-order, open-universe probabilistic languages, including BLOG (Milch et al., 2005a) and Church (Goodman et al., 2008), handles cases in which the number of objects (in BUGS, the index set) is unknown and perhaps unbounded, and object identity is uncertain. It is still possible to write a complete inference algorithm for BLOG, based on MCMC over partial worlds; each such world is constructed from the minimal self-supporting set of variables relevant to the evidence and query variables. Generality has a price, however: BLOG\u2019s default Metropolis\u2013Hastings inference engine samples each variable conditioned only on its parents (Milch & Russell, 2006). This approach leads to unacceptably slow mixing rates for many standard models, in which evidence from child variables is highly informative.\nOur goal is to remedy this situation, primarily by extending the range of situations in which Gibbs sampling from the full, conditional posterior can be used within BLOG. Section 2 of this paper introduces the terminology of contingent Bayesian networks (CBNs), which we will use as the propositional \u201cabstract machine\u201d for open-universe stochastic languages. Section 3 surveys previous work related to general purpose sampling of CBNs and describes its limitations. Section 4 then describes our novel Gibbs sampling algorithm for CBNs which addresses these limitations; its implementation for BLOG is described in Section 5. Finally, we present experimental results on various models in Section 6, demonstrating substantial speedups over existing methods."}, {"heading": "2 Contingent Bayesian Networks", "text": "This section repeats, and in some cases generalizes, definitions proposed by Milch et al. (2005b). A contingent Bayesian network (CBN) consists of a set of random variables V, and for each variable X \u2208V, a domain dom(X) and decision tree TX . The decision tree is a directed binary tree, where each node is a predi-\ncate on some subset of V. Each leaf of TX encodes a probability distribution parameterized by a subset of V, and defined on dom(X). Example 1. An aircraft of unknown WingType \u2013 Helicopter or FixedWingPlane \u2013 is detected on a radar. Helicopters have an unknown RotorLength, and depending on this length they might produce a characteristic pattern called a BladeFlash (Tait, 2009) in the returned radar signal. A FixedWingPlane might also produce a BladeFlash. As summarized in Figure 1,\nTWingType = F1 TRotorLength = { F2 if WingType = Helicopter null otherwise\nTBladeFlash = { F3(RL) if WingType = Helicopter F4 otherwise\nwhere RL is an abbreviation for RotorLength.\nAn instantiation \u03c3 is an assignment of values to a subset of V. We write vars(\u03c3) for the set of variables to which \u03c3 assigns values, and \u03c3X for the value that \u03c3 assigns to a variable X. \u03c3X=a is a modified instantiation which agrees with \u03c3 except for setting X to a. An instantiation \u03c3 is said to be finite if vars(\u03c3) is finite. An instantiation \u03c3 supports X if all the variables needed to evaluate TX are present in \u03c3. In Example 1, [WingType=FixedWing] supports BladeFlash, but [WingType=Helicopter] does not.\nWe write \u03c3TX for the minimal subset of \u03c3 needed to evaluate TX , and pX(\u00b7 | \u03c3TX ) for the resulting distribution of X. The parents of X in \u03c3 are vars(\u03c3TX ), while the children of X in \u03c3 are\n\u039b(\u03c3,X) = {Y | Y \u2208 vars(\u03c3), X \u2208 vars(\u03c3TY )}. (1)\nThe subset of vars(\u03c3TX ) which were used to evaluate internal nodes of TX (rather than the leaf) are the\nswitching parents of X in \u03c3. Intuitively, changes in the values of switching parents can switch the distribution of X, as well as its set of parents. A switching variable in \u03c3 is a switching parent for one or more variables in \u03c3. For the CBN of Example 1, the instantiation [ WingType=Helicopter, RotorLength=6, BladeFlash=true ] makes WingType a switching parent of both RotorLength and BladeFlash.\nAn instantiation \u03c3 is self-supporting if it supports all variables in \u03c3. Assuming that the CBN is well-defined (Milch et al., 2005b), we can define the probability of a self-supporting instantiation as follows:\np(\u03c3) = \u220f\nX \u2208 vars(\u03c3)\npX(\u03c3X | \u03c3TX ) (2)\nAn instantiation \u03c3 is feasible if p(\u03c3) > 0."}, {"heading": "3 Related Work", "text": "Milch and Russell (2006) have previously shown that the state space for Markov chain Monte Carlo (MCMC) inference in CBNs may consist of minimal partial instantiations that support the evidence, E, and query variables, Q. This idea has been exploited to build the current, default inference engine for BLOG. Standard sampling algorithms for nonparametric, Dirichlet process mixture models use a related representation: they instantiate parameters for those mixture components which support the evidence, as well as a few auxiliary components (Neal, 2000). Our new algorithm builds on both of these methods."}, {"heading": "3.1 Parent-Conditional Sampling", "text": "In the absence of a model-specific, user supplied proposal distribution, BLOG\u2019s existing inference engine relies on a parent-conditional proposal. This algorithm picks a variable, X, at random from all non-evidence variables in the current instantiation \u03c3, V (\u03c3) = vars(\u03c3)\u2212E, and proposes a new instantiation \u03c3\u2032 with the value of X drawn from pX(\u00b7 | \u03c3TX ). If X was a switching variable in \u03c3, we may then need to instantiate new variables, and uninstantiate unneeded ones, to make \u03c3\u2032 minimal and self-supporting over Q \u222a E. All new variables are instantiated with values drawn from their parent-conditional distribution.\nWe say that any \u03c3\u2032 constructed by this procedure is reachable from \u03c3 via X, or \u03c3 X \u03c3\u2032. The following properties are easily seen to be true of reachability. Proposition 1. A minimal self-supporting feasible instantiation \u03c3\u2032 is reachable from an instantiation \u03c3 via X if and only if X \u2208 vars(\u03c3) \u2229 vars(\u03c3\u2032), and \u03c3 and \u03c3\u2032 agree on all other variables in vars(\u03c3) \u2229 vars(\u03c3\u2032).\nProposition 2. If \u03c3 X \u03c3\u2032, then there does not exist Y \u2208 V (\u03c3), Y 6= X, such that \u03c3 Y \u03c3\u2032.\nThe nature of this proposal distribution q(\u03c3 \u2192 \u03c3\u2032) makes it quite simple to compute the acceptance ratio for the Metropolis\u2013Hastings (MH) method (Andrieu et al., 2003), which takes the following form:\n\u03b1(\u03c3 \u2192 \u03c3\u2032) = min {\n1, p(\u03c3\u2032)q(\u03c3\u2032 \u2192 \u03c3) p(\u03c3)q(\u03c3 \u2192 \u03c3\u2032)\n} (3)\nFor any \u03c3\u2032 reachable from \u03c3 via X, the unique way of proposing this transition is to select X from V (\u03c3), propose the value \u03c3\u2032X for it, and finally propose corresponding values for all new variables in \u03c3\u2032. Thus,\nq(\u03c3 \u2192 \u03c3\u2032) = pX(\u03c3\u2032X | \u03c3TX ) |V (\u03c3)| \u220f Y \u2208vars(\u03c3\u2032)\u2212vars(\u03c3) pY (\u03c3\u2032Y | \u03c3\u2032TY ) (4)\nFrom Equations (2) and (4), the terms corresponding to vars(\u03c3\u2032) \u2212 vars(\u03c3) cancel in p(\u03c3\u2032)/q(\u03c3 \u2192 \u03c3\u2032). Similarly, terms in vars(\u03c3) \u2212 vars(\u03c3\u2032) cancel in q(\u03c3\u2032 \u2192 \u03c3)/p(\u03c3). Further, it is easy to see that for variables Y \u2208 vars(\u03c3) \u2229 vars(\u03c3\u2032)\u2212 \u039b(\u03c3,X) \u2229 \u039b(\u03c3\u2032, X), \u03c3TY = \u03c3 \u2032 TY . Hence, pY (\u00b7 | \u03c3TY ) = pY (\u00b7 | \u03c3 \u2032 TY ) and the terms for all such variables Y , including X, cancel out. Finally, the acceptance ratio \u03b1(\u03c3 \u2192 \u03c3\u2032) reduces to:\nmin 1, |V (\u03c3)||V (\u03c3\u2032)| \u220f Y \u2208\u039b(\u03c3,X)\u2229\u039b(\u03c3\u2032,X) pY (\u03c3\u2032Y |\u03c3\u2032TY ) pY (\u03c3Y |\u03c3TY )  (5) Note the dependence on those variables which are children of X in both \u03c3 and \u03c3\u2032. The overall algorithm is summarized in Figure 2."}, {"heading": "3.2 Gibbs Sampling", "text": "Equation (5) summarizes the main problem with parent-conditional sampling: if the proposed value for the sampled variable X does not assign high probability to the children of X, the move will be rejected. To avoid undue assumptions, hierarchical Bayesian statistical models often use dispersed or \u201cvague\u201d priors, so that such parent-conditional proposals have extremely low acceptance probabilities.\nThe Gibbs sampler addresses this issue by directly sampling X from its full conditional distribution, pX(\u00b7 | \u03c3V\u2212X), rather than its parent-conditional prior pX(\u00b7 | \u03c3TX ). This method was originally proposed by Geman and Geman (1984) for inference in undirected Markov random fields, and later popularized as a general Bayesian inference method by Gelfand and\nSmith (1990). For discrete variablesX, the Gibbs sampler computes a weight w(a) for each a\u2208 dom(X):\nw(a) = pX(a | \u03c3TX ) \u220f\nY \u2208\u039b(\u03c3,X)\npY (\u03c3Y | \u03c3X=aTY ) (6)\nA new value \u03c3\u2032X is then sampled from a normalized distribution with mass proportional to these non-negative weights. Viewed as a Metropolis-Hastings proposal, the acceptance probability for the Gibbs sampler always equals one; Gibbs moves are never rejected.\nThe Gibbs sampler can be consistently applied to variables with finite, countable, or even uncountable domains, so long as the full conditional posterior can be tractably normalized and sampled from. For models specified via languages like BUGS, Gibbs sampling has proven quite successful. However, most existing applications and analysis of the Gibbs sampler implicitly assume a closed universe model, and instantiate the full, finite set of variables at all iterations. If this algorithm were naively applied to a CBN, then for some switching variables X and configurations a \u2208 dom(X), \u03c3X=a might not support some children of X. For such inconsistent model configurations, the normal Gibbs weight w(a) cannot be evaluated.\nOne possible solution, proposed in the context of Dirichlet process (DP) mixture models by Neal (2000), augments \u03c3 with auxiliary variables chosen so that \u03c3X=a is self-supporting for all a\u2208 dom(X). This augmented \u03c3, which is now no longer minimal, is used to construct the Gibbs weights; following the move any remaining non-supported variables are discarded.\ndom(X) = {0, 1, 2} X \u223c Categorical(.1, .6, .3)\ndom(Yi) = {0, 1} for all i\u2208N Yi \u223c {\nBernoulli( 11+X ) if (X + i) mod 2 \u2261 0 Bernoulli( 11+X+Yi+1 ) otherwise\nEvidence: Y1 = true. Query: X.\nFigure 3: A CBN which requires infinitely many auxiliary variables for standard Gibbs sampling approaches.\nSuch auxiliary variables are always sampled conditioned on \u03c3, given the current value of X. For example, if \u03c3X = a and if \u03c3 was augmented with a variable Z needed to support \u03c3X=b for some b\u2208 dom(X) \u2212 a, then we would sample Z from pZ(\u00b7 | \u03c3X=aTZ ). This can lead to poor mixing rates, or an inconsistent sampler if pZ(\u00b7 | \u03c3X=aTZ ) and pZ(\u00b7 | \u03c3 X=b TZ ) have non-overlapping support. Note that this issue doesn\u2019t arise with the DP mixture sampler, since TZ had no dependence on X, and pZ(\u00b7 | \u03c3X=aTZ ) = pZ(\u00b7 | \u03c3 X=b TZ ) for any a, b.\nTo further illustrate this issue, consider the model of Example 1 and a minimal instantiation, \u03c3 = [ WingType = FixedWingPlane, BladeFlash = True ]. If we were to apply a typical auxiliary variable method to do MCMC sampling in this model, we would first instantiate RotorLength given WingType = FixedWingPlane, and then construct Gibbs weights for WingType = FixedWingPlane and Helicopter. However, the only value of RotorLength that can be sampled given WingType = FixedWingPlane is null, and this value has probability 0 with WingType = Helicopter. The resulting chain will not mix to the true posterior.\nIn fact, there are cases when the auxiliary variable method is not well defined, because we may need an unbounded number of auxiliary variables. Consider the rather artificial but instructive CBN in Figure 3, and an instantiation \u03c3 = [X = 0, Y1 = 1, Y2 = 1]. To augment \u03c3 such that it is self-supporting for all values of X, we certainly need to add Y3, since Y2 depends on Y3 when X = 1. But Y3 depends on Y4 when X = 0, and so we need to add Y4, and so on. Ultimately, we would need to instantiate Yi for all i \u2265 1."}, {"heading": "4 Gibbs Sampling in Contingent Bayesian Networks", "text": "We now develop a general-purpose extension of standard Gibbs samplers, which is applicable to arbitrary switching variables with finite domains. The proposal for a switching variable, X, will proceed in three steps. First, the instantiation, \u03c3, is reduced to a subset of variables, core(\u03c3,X), that is guaran-\nteed to exist in a minimal, self-supporting instantiation constructed from \u03c3X=a, for any a\u2208 dom(X). Second, we construct minimal self-supporting instantiations \u03c3i, i = 1, . . . , |dom(X)| \u2212 1, for each value in dom(X)\u2212{\u03c3X}. These instantiations agree with \u03c3 on core(\u03c3,X), but assign different values to X. Any remaining variables in these \u03c3i configurations are sampled from their parent-conditional priors. For notational simplicity, we define \u03c30 = \u03c3. Finally, we assign weights to these \u03c3i, i = 0, . . . , |dom(X)|\u22121, and make a transition proportional to these weights.\nIt may seem counter-intuitive to first reduce the instantiation, and then extend it. After all, the pair of algorithms described in Section 3, parent-conditional sampling and auxiliary variable Gibbs sampling, first extended the current instantiation before reducing it. The motivation for our approach is simple: variables whose existence depends on the value of X should be sampled in a world with the appropriate value of X.\nConsider again, for example, the model in Figure 3, and three partial instantiations illustrated in Figure 4. Now, starting from \u03c30 (in which X = 0), we could have fixed the value of Y2 when constructing \u03c32 (in which X = 2). However, the distribution of Y2 given X = 2 is quite different from that given X = 0, and fixing the value of Y2 could lead to low probability instantiations. The resampling of non-core variables like Y2 also simplifies the detailed balance equations discussed later. In particular, our algorithm is designed so that the distribution of \u03c32 does not depend on whether we start from \u03c30 or \u03c31. Thus, when demonstrating detailed balance between pairs of instantiations, we need\nnot reason about other instantiations which might be involved in the transition. This last observation relies on the fact that core(\u03c30, X) = core(\u03c31, X). We will first prove this in general. Definition 1. For an instantiation \u03c3 and variables X,Y, Z \u2208 vars(\u03c3), if TZ refers to X and Y , and the first reference to X precedes the first reference to Y , the edge linking Y to Z is said to be contingent on X. Definition 2. Let core(\u03c3,X) denote the subset of variables in vars(\u03c3) \u2212 {X} which have a path (possibly of length zero) consisting of parent-child edges, excluding edges contingent on X, to some variable in Q \u222a E.\nNote that we have left X out of core(\u03c3,X) mainly for simplifying the subsequent text. However, it is not hard to see that there is a path from X to Q \u222a E not contingent uponX. For example, consider the shortest path from X to Q\u222aE and let this path start with the X \u2192 Y edge. Now, the edge X \u2192 Y is not contingent upon X (by definition) and if some other edge, W \u2192 Z, along this path is contingent upon X then we can find a shorter path starting with X \u2192 Z. It should be further noted that all the ancestors of X have a path to X not contingent upon X (otherwise, a cyclic instantiation would make the CBN not well-formed). Hence all the ancestors of X are in core(\u03c3,X). Definition 3. For an instantiation \u03c3 and variable X \u2208 vars(\u03c3), let \u03a5(\u03c3,X) 4= \u039b(\u03c3,X) \u2229 core(\u03c3,X) denote the children of X also contained in core(\u03c3,X). Proposition 3. For any pair of minimal selfsupporting instantiations, \u03c3 and \u03c3\u2032, and variable X common to them, if \u03c3 and \u03c3\u2032 agree on core(\u03c3,X) then core(\u03c3,X) = core(\u03c3\u2032, X) and \u03a5(\u03c3,X) = \u03a5(\u03c3\u2032, X).\nProof. Let Y \u2208 core(\u03c3,X), then either Y \u2208Q \u222a E or there exists a path of edges not contingent on X from Y to Q\u222aE. Clearly, if Y \u2208Q\u222aE then Y \u2208 core(\u03c3\u2032, X). Otherwise, let Z be the first child in such a path. Since X is not referenced before Y in TZ , X is also not referenced before any W referenced before Y in TZ . Such a variable W must also be in core(\u03c3,X) since W has the same path to Q\u222aE via Z as Y . But \u03c3 and \u03c3\u2032 agree on core(\u03c3,X) and hence on W . Since \u03c3 and \u03c3\u2032 agree on all the variables referred before Y in TZ it follows that the evaluation of TZ up to Y is identical in \u03c3 and \u03c3\u2032. Hence, the Y to Z edge is not contingent on X in \u03c3\u2032. By induction, the path from Y to Q \u222a E in \u03c3\u2032 is not contingent on X, which implies that Y \u2208 core(\u03c3\u2032, X).\nNow, suppose core(\u03c3,X) \u2282 core(\u03c3\u2032, X). For any element in core(\u03c3\u2032, X)\u2212 core(\u03c3,X) there must be a path of edges not contingent upon X in \u03c3\u2032 to Q \u222a E via some variables in core(\u03c3,X) \u222a {X} (trivially, since Q\u222aE \u2286 core(\u03c3,X)\u222a {X}). Let Y and Z be one such parent-child pair in \u03c3\u2032 s.t. Y \u2208 core(\u03c3\u2032, X)\u2212core(\u03c3,X)\nand Z \u2208 core(\u03c3,X) \u222a {X}. Now, all the variables referred in TZ up to the first reference of X (if any) would also be in core(\u03c3,X) since they have an edge to Z which is not contingent on X. Since \u03c3 and \u03c3\u2032 agree on core(\u03c3,X), the evaluation of TZ would follow an identical path in \u03c3 and \u03c3\u2032 up to the first reference of X. Therefore, since Y is not referred to after X while evaluating TZ in \u03c3\u2032, it follows that Y \u2208 core(\u03c3,X).\nLet Y \u2208\u03a5(\u03c3,X), i.e. Y is a child of X in \u03c3 and Y \u2208 core(\u03c3,X). From the above result Y \u2208 core(\u03c3\u2032, X) and we will next show that Y is a child ofX in \u03c3\u2032. Consider the evaluation path of TY in \u03c3. All the variables that are referred before X are also in core(\u03c3,X) by definition. Since these variables will have the same value in \u03c3\u2032, it follows that the evaluation of TY in \u03c3\u2032 will lead to X being referred. In other words, X is a parent of Y in \u03c3\u2032 which implies that \u03a5(\u03c3,X) \u2286 \u03a5(\u03c3\u2032, X). By symmetry, \u03a5(\u03c3\u2032, X) \u2286 \u03a5(\u03c3,X)\nProposition 4. For any two minimal self-supporting instantiations, \u03c3 and \u03c3\u2032, there is at most one variable X common to them such that \u03c3 and \u03c3\u2032 agree on core(\u03c3,X), but differ on X.\nProof. Assume to the contrary that there exist two such variables X and Y . Now, since \u03c3 and \u03c3\u2032 agree on core(\u03c3,X) but differ on Y , it follows that Y 6\u2208 core(\u03c3,X). Hence Y cannot be in Q \u222a E. But since \u03c3 is a minimal instantiation, Y must have a path to Q\u222aE. Now consider the shortest path of Y to Q\u222aE. Some edge, W \u2192 Z, in this path must be contingent on X. Hence we can construct a path from X to Q\u222aE via Z which can\u2019t be contingent on Y (otherwise, Y would have a shorter path to Q \u222a E). This implies that X \u2208 core(\u03c3, Y ), but then \u03c3 and \u03c3\u2032 agree on X, a contradiction.\nFor each value in dom(X), the corresponding partial instantiation \u03c3i is assigned the following weight:\nw(\u03c3i) = pX(\u03c3iX | \u03c3iTX ) |V (\u03c3i)| \u220f Y \u2208\u03a5(\u03c3,X) pY (\u03c3iY | \u03c3iTY )\n(7) Up to a multiplicative constant, this expression reduces to Equation 6 if X is not a switching variable. The complete pseudo-code is given in Figure 5. Note that if X is not a switching variable then core(\u03c3,X) = vars(\u03c3) \u2212X and the algorithm reduces to regular Gibbs sampling.\nIt only remains to show that detailed balance holds between any two minimal instantiations \u03c30 and \u03c31. It follows from Propositions 3 and 4 that there is at most one shared variable X such that a transition is possible between \u03c30 and \u03c31 by sampling X. Thus, the only way for this transition to occur from\n\u03c30 is to first select X for sampling with probability 1 |V (\u03c30)| . Next, the new variables in \u03c31, \u03c8(\u03c30, X, \u03c31) = vars(\u03c31) \u2212 core(\u03c30, X) \u2212 {X}, must be sampled with probability \u220f Y \u2208\u03c8(\u03c30,X,\u03c31) pY (\u03c31Y |\u03c31TY ). Finally, we must select \u03c31 out of all the other random instantiations, with probability w(\u03c31)w(\u03c30)+...+w(\u03c3n\u22121) . Now, the instantiations \u03c32, . . . , \u03c3n\u22121 are random variables and hence the overall transition probability, q(\u03c30 \u2192 \u03c31), depends on the expected value of this last probability under the distribution of these random variables:\n1 |V (\u03c30)| \u220f Y \u2208\u03c8(\u03c30,X,\u03c31) pY (\u03c31Y | \u03c31TY )E [ w(\u03c31)\u2211n\u22121 i=0 w(\u03c3i) ]\nWe can construct a similar expression for the reverse move probability, and note that the numerator in the expectation is a constant, and the rest of the expectation doesn\u2019t depend on which of \u03c30 or \u03c31 we start out with. Thus, q(\u03c30\u2192\u03c31)q(\u03c31\u2192\u03c30) is:\n|V (\u03c31)| |V (\u03c30)| w(\u03c31) w(\u03c30) \u220f Y \u2208\u03c8(\u03c30,X,\u03c31) pY (\u03c31Y | \u03c31TY )\u220f Y \u2208\u03c8(\u03c31,X,\u03c30) pY (\u03c30Y | \u03c30TY )\nSubstituting for w(\u03c31) and w(\u03c30):\nq(\u03c30 \u2192 \u03c31) q(\u03c31 \u2192 \u03c30)\n= \u220f\nY \u2208\u03a5(\u03c3,X)\npY (\u03c31Y | \u03c31TY ) pY (\u03c30Y | \u03c30TY )\npX(\u03c31X | \u03c31TX ) pX(\u03c30X | \u03c30TX ) \u00b7 \u220f Y \u2208\u03c8(\u03c30,X,\u03c31) pY (\u03c31Y | \u03c31TY )\u220f Y \u2208\u03c8(\u03c31,X,\u03c30) pY (\u03c30Y | \u03c30TY )\nObserve that the only terms missing from p(\u03c31)p(\u03c30) above are those for variables in core(\u03c3,X) \u2212 \u03a5(\u03c3,X). However, if Y \u2208 core(\u03c3,X) then \u03c3Y = \u03c3\u2032Y and further if Y 6\u2208 \u039b(\u03c3,X) all the parents of Y are also in core(\u03c3,X) and hence have the same values in \u03c3 and \u03c3\u2032. Thus these variables have identical values and distributions in \u03c30 and \u03c31 and their terms cancel out. Finally,\nq(\u03c30 \u2192 \u03c31) q(\u03c31 \u2192 \u03c30) = p(\u03c31) p(\u03c30)"}, {"heading": "5 BLOG Compiler", "text": "We have implemented our algorithm in a new implementation of the BLOG language, which we will refer to as blogc1. The broad outline of our implementation is similar to Milch\u2019s public-domain MetropolisHastings version, except in two significant aspects.\nFirst, for variables with (possibly unknown) finite domain, we always use Gibbs sampling. By statically analyzing the structure of the model we can determine which variables are switching variables, which ones need to be resampled for each transition, etc. Based on the analysis, appropriate code is generated that does the actual sampling and reporting.\nConsider, as an example, the BLOG model in Figure 6. This model describes the prior distribution of two types of aircraft \u2013 fixed-wing planes and helicopters. These planes may produce an arbitrary number of blips on the radar (the fact that plane a produces a blip b is represented by setting Source(b) = a). Further, helicopters due to the interaction of their rotor with the radar beam can produce blade-flashes in the radar blip. In this model, the variable RotorLength(a) for all aircraft a can easily be Gibbs sampled. If WingType(a) =Helicopter then RotorLength(a) can be either Short or Long, otherwise it can only be null (as per BLOG semantics for a missing else clause). While compiling the model we can detect that the children variables of WingType(a) in any instantiation are all the BladeFlash(b) variables such that Source(b) = a. In order to speed up the computation of the Gibbs weights at runtime, we maintain a list, for each object a of type Aircraft, of all objects b of type Blip such that Source(b) = a.\n1blogc is available for download from: http://code.google.com/p/blogc/\nThe variable WingType(a) is more interesting. It can only take two possible values, but since it is a switching variable, care has to be taken when sampling it. In particular, the variable RotorLength(a) has to be uninstantiated. This is because all the children edges from RotorLength(a) are contingent on the value of WingType(a). Note that Source(b) for all objects b of type Blip is also a switching variable. However, in this case the decision to uninstantiate a variable WingType(a) such that Source(b) = a depends on whether there exists another object b\u2032 such that Source(b\u2032) = a.\nThe second major difference in our implementation is the handling of number variables. Instead of directly sampling the number variables, our implementation proposes birth and death moves. In the radar example, for each object w of type WingType, we generate an Aircraft object that has no blips assigned to it. The death move kills off such objects with no blips. In order to get faster mixing, we allow some extra flexibility in the birth and death move during an \u201cinitialization\u201d phase. During this phase, birth and death moves ignore the probability of child variables. To understand the motivation, assume for a moment that the expected number of blips for a given aircraft was one million. Now, a birth move which proposes an aircraft with 0 blips would be almost certainly rejected. By allowing such birth moves during initialization, we give the inference engine an opportunity to later attach blips to the aircraft."}, {"heading": "6 Experimental Results", "text": "We have compared the convergence speed and accuracy of blogc against the existing generic MetropolisHastings inference engine provided with BLOG, which we will refer to as BLOG-MH. Since a Gibbs and a MH sampler perform different amount of work in each sample we felt that it was more appropriate to compare the two inference engines with respect to time. In order to control for the compiler optimizations in blogc we have implemented a version of BLOG-MH in blogc which we will refer to as blogc-MH. For some of the other experiments we have also implemented a version of Gibbs sampling that doesn\u2019t uninstantiate and resample variables not in the core, which we shall refer to as blogc-noblock.\nIn the following three models each inference engine is run for a varying number of samples, where a sample is as defined by that inference engine. For each number of samples, inference is repeated 20 times with a different random seed and the mean and variance of a query variable is plotted against the average elapsed time (in seconds).\nFirst, we evaluate on the Alarm network of (Beinlich et al., 1989) available from the Bayes Network Repository2 (Friedman et al., 1997). This is a Bayes Net with 37 discrete random variables of which we observe 9. The results are summarized in Figure 7. The important thing to note is that the variance achieved by blogc in less than 2 seconds is much better than that achieved by blogc-MH in 15 seconds and by BLOGMH in 40 seconds. The compiler optimizations are clearly giving a big boost but the Gibbs sampling is helping considerably as well.\nNext, we consider the model in Figure 8 which is the urns-and-balls example of (Milch et al., 2005a) with a slight twist. Balls have a weight instead of a discrete color. Figure 9 shows that blogc converges significantly faster than BLOG-MH. However, all the improvement here is being driven by the compiler optimizations as evidenced by the fact that blogc-MH is keeping pace with blogc. This similarity is likely due to the fact that our current blogc implementation does not resample the TrueWeight variables from their full posterior. This shortcoming arises because blogc does not yet support Gibbs updates for continuous variables, and is not a limitation of the proposed Gibbs sampler for switching variables. Nevertheless, the example demonstrates the soundness of the blogc-MH implementation in addition to the compiler optimizations.\nOur final result is on the radar example of Figure 6. For this model we experimented running blogc without the logic which detects that RotorLen(a) must be uninstantiated when sampling WingType(a). This mode is labeled as blogc-noblock in Figure 10. In this experiment we are querying the probability that\n2http://www.cs.huji.ac.il/site/labs/compbio/Repository/\nWingType(Source(b1)) = Helicoper. Given that BladeF lash(b1) = true we expect this probability to be quite high. blogc converges to the true probability in less than a second. However, neither BLOG-MH nor blogc-noblock are able to come close to the true probability even after 30 seconds. This is explained by the fact that these two samplers are unable to directly sample the WingType(a) variables. The fact that they are able to make any progress at all is due to the birth move which creates new aircraft for each WingType and samples their RotorLen variable. Later, the move which resamples Source(b) for each blip has the opportunity to select this new aircraft. These two moves thus compensate for the fact that the move which attempts to sample WingType(a) is always rejected.\nIn follow-on work, we plan to demonstrate inference\nperformance comparable to model-specific inference code for a number of widely used statistical models."}, {"heading": "7 Conclusions", "text": "We have demonstrated a significant improvement in inference performance for models written in the BLOG language. Our Gibbs sampling algorithm for CBNs and our compiler techniques for generating efficient inference code are generally applicable to all openuniverse stochastic languages."}, {"heading": "Acknowledgements", "text": "This work wouldn\u2019t have been possible without the considerable assistance provided by Brian Milch to make the models presented here work in BLOG-MH. Matthew Can provided a translation of the Alarm Bayes Net to BLOG. Finally, the first author wishes to thank his family for their boundless patience and support during this work."}], "references": [{"title": "An introduction to MCMC for machine learning", "author": ["C. Andrieu", "N. de Freitas", "A. Doucet", "M.I. Jordan"], "venue": "Machine Learning,", "citeRegEx": "Andrieu et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Andrieu et al\\.", "year": 2003}, {"title": "The alarm monitoring system: A case study with two probabilistic inference techniques for belief networks", "author": ["I. Beinlich", "G. Suermondt", "R. Chavez", "G. Cooper"], "venue": "Proc. 2\u2019nd European Conf. on AI and Medicine. Springer-Verlag,", "citeRegEx": "Beinlich et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Beinlich et al\\.", "year": 1989}, {"title": "Challenge: Where is the impact of Bayesian networks in learning? IJCAI", "author": ["N. Friedman", "M. Goldszmidt", "D. Heckerman", "S. Russell"], "venue": null, "citeRegEx": "Friedman et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 1997}, {"title": "Samplingbased approaches to calculating marginal densities", "author": ["A.E. Gelfand", "A.F.M. Smith"], "venue": null, "citeRegEx": "Gelfand and Smith,? \\Q1990\\E", "shortCiteRegEx": "Gelfand and Smith", "year": 1990}, {"title": "Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images", "author": ["S. Geman", "D. Geman"], "venue": "IEEE Trans. on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Geman and Geman,? \\Q1984\\E", "shortCiteRegEx": "Geman and Geman", "year": 1984}, {"title": "Church: a language for generative models. UAI", "author": ["N. Goodman", "V. Mansinghka", "D. Roy", "K. Bonawitz", "J. Tenenbaum"], "venue": null, "citeRegEx": "Goodman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Goodman et al\\.", "year": 2008}, {"title": "BLOG: Probabilistic models with unknown objects", "author": ["B. Milch", "B. Marthi", "S.J. Russell", "D. Sontag", "D.L. Ong", "A. Kolobov"], "venue": "IJCAI (pp", "citeRegEx": "Milch et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Milch et al\\.", "year": 2005}, {"title": "Approximate inference for infinite contingent Bayesian networks", "author": ["B. Milch", "B. Marthi", "D. Sontag", "S. Russell", "D.L. Ong", "A. Kolobov"], "venue": "In Proc. 10th AISTATS (pp. 238\u2013245)", "citeRegEx": "Milch et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Milch et al\\.", "year": 2005}, {"title": "General-purpose MCMC inference over relational structures", "author": ["B. Milch", "S. Russell"], "venue": "Proceedings of the Proceedings of the Twenty-Second Conference Annual Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "Milch and Russell,? \\Q2006\\E", "shortCiteRegEx": "Milch and Russell", "year": 2006}, {"title": "Markov chain sampling methods for dirichlet process mixture models", "author": ["R.M. Neal"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "Neal,? \\Q2000\\E", "shortCiteRegEx": "Neal", "year": 2000}, {"title": "BUGS: Bayesian inference using gibbs sampling, version", "author": ["D. Spiegelhalter", "A. Thomas", "N. Best", "W. Gilks"], "venue": null, "citeRegEx": "Spiegelhalter et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Spiegelhalter et al\\.", "year": 1996}, {"title": "Introduction to radar target recognition. The Institution of Engineering and Technology, United Kingdom", "author": ["P. Tait"], "venue": null, "citeRegEx": "Tait,? \\Q2009\\E", "shortCiteRegEx": "Tait", "year": 2009}], "referenceMentions": [{"referenceID": 10, "context": "For example, BUGS (Spiegelhalter et al., 1996) can represent directed graphical models over indexed sets of random variables and uses MCMC inference (in particular, Gibbs sampling where this is possible).", "startOffset": 18, "endOffset": 46}, {"referenceID": 5, "context": ", 2005a) and Church (Goodman et al., 2008), handles cases in which the number of objects (in BUGS, the index set) is unknown and perhaps unbounded, and object identity is uncertain.", "startOffset": 20, "endOffset": 42}, {"referenceID": 6, "context": "This section repeats, and in some cases generalizes, definitions proposed by Milch et al. (2005b). A contingent Bayesian network (CBN) consists of a set of random variables V, and for each variable X \u2208V, a domain dom(X) and decision tree TX .", "startOffset": 77, "endOffset": 98}, {"referenceID": 11, "context": "Helicopters have an unknown RotorLength, and depending on this length they might produce a characteristic pattern called a BladeFlash (Tait, 2009) in the returned radar signal.", "startOffset": 134, "endOffset": 146}, {"referenceID": 9, "context": "Standard sampling algorithms for nonparametric, Dirichlet process mixture models use a related representation: they instantiate parameters for those mixture components which support the evidence, as well as a few auxiliary components (Neal, 2000).", "startOffset": 234, "endOffset": 246}, {"referenceID": 0, "context": "The nature of this proposal distribution q(\u03c3 \u2192 \u03c3\u2032) makes it quite simple to compute the acceptance ratio for the Metropolis\u2013Hastings (MH) method (Andrieu et al., 2003), which takes the following form:", "startOffset": 145, "endOffset": 167}, {"referenceID": 4, "context": "This method was originally proposed by Geman and Geman (1984) for inference in undirected Markov random fields, and later popularized as a general Bayesian inference method by Gelfand and 1.", "startOffset": 39, "endOffset": 62}, {"referenceID": 9, "context": "One possible solution, proposed in the context of Dirichlet process (DP) mixture models by Neal (2000), augments \u03c3 with auxiliary variables chosen so that \u03c3 is self-supporting for all a\u2208 dom(X).", "startOffset": 91, "endOffset": 103}, {"referenceID": 1, "context": "First, we evaluate on the Alarm network of (Beinlich et al., 1989) available from the Bayes Network Repository (Friedman et al.", "startOffset": 43, "endOffset": 66}, {"referenceID": 2, "context": ", 1989) available from the Bayes Network Repository (Friedman et al., 1997).", "startOffset": 52, "endOffset": 75}], "year": 2010, "abstractText": "Languages for open-universe probabilistic models (OUPMs) can represent situations with an unknown number of objects and identity uncertainty. While such cases arise in a wide range of important real-world applications, existing general purpose inference methods for OUPMs are far less efficient than those available for more restricted languages and model classes. This paper goes some way to remedying this deficit by introducing, and proving correct, a generalization of Gibbs sampling to partial worlds with possibly varying model structure. Our approach draws on and extends previous generic OUPM inference methods, as well as auxiliary variable samplers for nonparametric mixture models. It has been implemented for BLOG, a well-known OUPM language. Combined with compile-time optimizations, the resulting algorithm yields very substantial speedups over existing methods on several test cases, and substantially improves the practicality of OUPM languages generally.", "creator": "TeX"}}}