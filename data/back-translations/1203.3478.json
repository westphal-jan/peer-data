{"id": "1203.3478", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2012", "title": "Playing games against nature: optimal policies for renewable resource allocation", "abstract": "In this paper, we present a class of Markov decision-making processes that emerge as a natural model for many of the problems of the allocation of renewable resources. By extending the results of the literature on stock control, we demonstrate that they allow for a coherent solution and show how we can use this structure to speed up its calculation. We consider the application of the proposed framework to several problems that arise in very different areas, and as part of ongoing efforts in the emerging field of computational sustainability, we discuss in detail its application to the marine fisheries of the North Pacific halibut. Our approach is applied to a model that is based on real data and achieves a policy with a guaranteed lower threshold in terms of benefit function, which is structurally very different from that currently applied.", "histories": [["v1", "Thu, 15 Mar 2012 11:17:56 GMT  (154kb)", "http://arxiv.org/abs/1203.3478v1", "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)", "reviews": [], "SUBJECTS": "cs.AI cs.GT", "authors": ["stefano ermon", "jon conrad", "carla p gomes", "bart selman"], "accepted": false, "id": "1203.3478"}, "pdf": {"name": "1203.3478.pdf", "metadata": {"source": "CRF", "title": "Playing games against nature: optimal policies for renewable resource allocation", "authors": ["Stefano Ermon"], "emails": ["ermonste@cs.cornell.edu", "jmc16@cornell.edu", "gomes@cs.cornell.edu", "selman@cs.cornell.edu"], "sections": [{"heading": null, "text": "In this paper we introduce a class of Markov decision processes that arise as a natural model for many renewable resource allocation problems. Upon extending results from the inventory control literature, we prove that they admit a closed form solution and we show how to exploit this structure to speed up its computation. We consider the application of the proposed framework to several problems arising in very different domains, and as part of the ongoing effort in the emerging field of Computational Sustainability we discuss in detail its application to the Northern Pacific Halibut marine fishery. Our approach is applied to a model based on real world data, obtaining a policy with a guaranteed lower bound on the utility function that is structurally very different from the one currently employed."}, {"heading": "1 Introduction", "text": "The problem of devising policies to optimally allocate resources over time is a fundamental decision theoretic problem with applications arising in many different fields. In fact, such decisions may involve a variety of different resources such as time, energy, natural and financial resources, in allocation problems arising in domains as diverse as natural resources management, crowdsourcing, supply chain management, QoS and routing in networks, vaccine distribution and pollution management. A particularly interesting class of such problems involves policies for the allocation of renewable resources. A key and unique aspect of such a resource type is the fact that, by definition, its stock is constantly replenished by an intrinsic growth process. The most common example are perhaps living resources, such as fish populations or forests, that increase constantly by natural growth and reproduction, but less conventional resources such as users in a social com-\nmunity or in a crowdsourcing project share the same intrinsic growth feature due to social interactions. A common feature of the growth processes presented is that they are density dependent, in the sense that the growth rate depends on the amount of resource available. This fact creates a challenging management problem when the aim of the intervention is to optimally use the resource, for instance by harvesting a fish population or by requiring some effort from a crowdsourcing community, especially when economic aspects are factored in. We face a similar challenge in vaccine distribution problems, where the growth rate of infections is again density dependent and the objective is to reduce its spreading.\nThis study, in particular, has been motivated by the alarming consideration that many natural resources are endangered due to over-exploitation and generally poorly managed. For instance, the Food and Agricultural Organization estimates in their most recent report that 7% of marine fish stocks are already depleted, 1% are recovering from depletion, 52% are fully exploited and 17% are overexploited ([1]).\nOne of the most fundamental aspects of the problem seems to be the lack of an effective way to handle the uncertainty affecting the complex dynamics involved. While in most of the works in the literature [6, 7] these growth processes are modeled with deterministic first-order difference or differential equations, this approach often represents an oversimplification. In fact their intrinsic growth is often affected by many variables and unpredictable factors. For example, in the case of animal populations such as fisheries, both weather and climate conditions are known to affect both the growth and the mortality in the population. Other variable ecological factors such as the availability of food or the interaction with other species also influence their natural dynamics to the point that it is very difficult even to obtain reliable mathematical models to describe their dynamics.\nOn the other hand, stochastic differential equations can easily incorporate these variable factors and therefore represent a more robust description. However, obtaining a prob-\nabilistic description of such systems is far from easy. In fact, even if in principle uncertainty could be reduced by collecting and analyzing more data, it is generally believed that complex and stochastic systems, such a marine environments, could never become predictable (to the point that the authors of [13] believe that \u201cpredictability of anything as complex as marine ecosystem will forever remain a chimera\u201d). Moreover, there are situations of \u201cradical uncertainty\u201d ([8]) or ambiguity where a stochastic description is not feasible because the probabilities are not quantifiable. For instance, many fundamental environmental issues that we are facing, such as those surrounding the climate change debate, involve ambiguity in the sense of scientific controversies or irreducible beliefs that cannot be resolved.\nIn the context of stochastic optimization, there are two main ways to deal with uncertainty. The first one involves a risk management approach, where it is assumed that the probabilities of the stochastic events are known a priori or are learned from experience through statistical data analysis. Within this framework, decisions are taken according to stochastic control methods. Using tools such as risksensitive Markov decision processes ([12, 15]), it is also possible to encode into the problem the attitude towards risk of the decision maker by using an appropriate utility function. In particular the degree of risk aversion can be controlled by sufficiently penalizing undesirable outcomes with the utility function. When a fine grained stochastic description is not available, worst-case game theoretic frameworks, that are inherently risk averse, play a fundamental role because it is often crucial to devise policies that avoid catastrophic depletion. This type of approach, where the problem of data uncertainty is addressed by guaranteeing the optimality of the solution for the worst realizations of the parameters, is also known in the literature as robust optimization ([3, 5]), and has been successfully applied to uncertain linear, conic quadratic and semidefinite programming.\nIn this paper, we present a class of Markov decision processes that arise as a natural model for many resource management problems. Instead of formulating the optimization problem in a traditional form as a maximization of an expected utility, we tackle the management problems in a game theoretic framework, where the optimization problem is equivalent to a dynamic game against nature. This formulation is a particular type of Markov game [14] (sometimes called a stochastic game [16]) where there are only two agents (the manager and nature) and they have diametrically opposed goals.\nAs mentioned before, although this formulation is more conservative, it also eliminates the very difficult task of estimating the probabilities of the stochastic events affecting the system. In a context where the emphasis in the literature has traditionally been on the study of expected utilities,\nthis approach represents a new perspective. Moreover, the policies thus obtained provide a lower bound on the utility that can be guaranteed to be achieved, no matter the outcomes of the stochastic events. For this class of problems, we are able to completely characterize the optimal policy with a theoretical analysis that extends results from the inventory control literature, obtaining a closed form solution for the optimal policy.\nAs part of the new exciting research area of Computational Sustainability ([10]), where techniques from computer science and related fields are applied to solve the pressing sustainability challenges of our time, we present an application of the proposed framework to the Northern Pacific Halibut fishery, one of the largest and most lucrative fisheries of the Northwestern coast. In particular, our method suggests the use of a cyclic scheme that involves periodic closures of the fishery, a policy that is structurally different from the one usually employed, that instead tries to maintain the stock at a given size with appropriate yearly harvests. However, this framework is interesting in its own right and, as briefly mentioned before, it applies to a variety of other problems that share a similar mathematical structure and that arise in very different domains. For example, we can apply our framework to pollution problems, where a stock of pollutants is evolving over time due to human action, and the objective is to minimize the total costs deriving from the presence of a certain stock of pollutants and the costs incurred with cleanups, but also to crowdsourcing and other problems."}, {"heading": "2 MDP Formulation", "text": "In this section, we will formulate the optimization problem as discrete time, continuous space Markov decision process. Whenever possible, we will use a notation consistent with the one used in [4]. Even if we will consider only a finite horizon problem, the results can be extended to the infinite horizon case with limiting arguments. To make the description concrete, the model will be mostly described having a natural resource management problem in mind.\nWe consider a dynamical system evolving over time according to\nxn+1 = f(xn \u2212 hn, wn), (1)\nwhere xn \u2208 R denotes the stock of a renewable resource at time n. By using a discrete time model we implicitly assume that replacement or birth processes occur in regular, well defined \u201cbreeding seasons\u201d, where f(\u00b7) is a reproduction function that maps the stock level at the end of one season to the new stock level level at the beginning of the next season. The control or decision variable at year n is the harvest level hn (occurring between two consecutive breeding seasons), that must satisfy 0 \u2264 hn \u2264 xn.\nAs mentioned in the introduction, the function f(\u00b7) cap-\ntures the intrinsic replenishment ability of renewable resources, that in many practical applications (such as fisheries or forestry) is density dependent: growth rate is high when the habitat is underutilized but it decreases when the stock is larger and intraspecific competition intensifies. Specific properties of reproduction functions f(\u00b7) will be discussed in detail later, but we will always assume that there is a finite maximum stock level denoted by m. To compensate for the higher level description of the complex biological process we are modeling, we introduce uncertainty into the model throughwn, a random variable that might capture, for example, the temperature of the water, an uncontrollable factor that influences the growth of the resource. Given the worst case framework we are considering, we will never make assumptions on the probability distribution of wn but only on its support (or, in other words, on the possible outcomes). In fact in an adversarial setting it is sufficient to consider all possible scenarios, each one corresponding to an action that nature can take against the policy maker, without assigning them a weight in a probabilistic sense.\nGiven the presence of stochasticity, it is convenient to consider closed loop optimization approaches, where decisions are made in stages and the manager is allowed to gather information about the system between stages. In particular, we assume that the state of the system xn \u2208 R is completely observable. For example, in the context of fisheries this means that we assume to know exactly the level of the stock xn when the harvest level hn is to be chosen. In this context, a policy is a sequence of rules used to select at each period a harvest level for each possible stock size. In particular, an admissible policy \u03c0 = {\u00b51, . . . , \u00b5N} is a sequence of functions, each one mapping stocks sizes x to harvests h, so that for all x and for all i\n0 \u2264 \u00b5i(x) \u2264 x. (2)"}, {"heading": "2.1 Resource Economics", "text": "We now consider the economic aspects of the model. We suppose that the revenue obtained from a harvest h is proportional to h through a fixed price p, and that harvesting is costly. In particular we assume that there is\n\u2022 a fixed set-up costK each time a harvest is undertaken\n\u2022 a marginal harvest cost g(x) per unit harvested when the stock size is x\nIt follows that the utility derived from a harvest h from an initial stock x is\nph\u2212\n\u222b x\nx\u2212h\ng(y)dy \u2212K , R(x)\u2212R(x\u2212 h)\u2212K, (3)\nwhere\nR(x) = px\u2212\n\u222b x\n0\ng(y)dy.\nWe assume that the marginal harvesting cost g(x) increases as the stock size x decreases. We include time preference into the model by considering a fixed discount factor \u03b1 = 1/(1 + \u03b4) ( 0 \u2264 \u03b1 \u2264 1), where \u03b4 > 0 is a discount rate.\nFor any given horizon length N , we consider the problem of finding an admissible policy \u03c0 = {\u00b5i}i\u2208[1,N ] that maximizes\nC\u03c0N (x) =\nmin w1, . . . , wN wi \u2208W (xi)\nN \u2211\nn=1\n\u03b1n(R(xn)\u2212R(xn \u2212 hn)\u2212K\u03b40(hn))\nwhere xn is subject to (1) and hn = \u00b5n(xn), with initial condition x1 = x and\n\u03b40(x) =\n{\n1 if x > 0, 0 otherwise.\nThis is a Max-Min formulation of the optimization problem, where the goal is to optimize the utility in a worst-case scenario. As opposed to the maximization of an expected utility ([17, 18]), this formulation is inherently risk averse. An advantage of this formulation is that there is no need to characterize the probability distribution of the random variables wk explicitly, but only to determine their support. In fact, one should consider all the possible scenarios, without worrying about the probabilities of their occurrence."}, {"heading": "3 Main Results", "text": ""}, {"heading": "3.1 Minimax Dynamic Programming", "text": "A policy \u03c0 is called an optimal N -period policy if C\u03c0N (x) attains its supremum over all admissible policies at \u03c0 for all x. We call\nCN (x) = sup \u03c0\u2208\u03a0\nC\u03c0N (x),\nthe optimal value function, where \u03a0 represents the set of all admissible policies.\nAs a consequence of the principle of optimality([4]), the dynamic programming equation for this problem reads:\nC0(x) = 0,\nCn(x) = max 0\u2264hn\u2264x min wn\u2208W R(xn)\u2212R(xn \u2212 hn)\n\u2212K\u03b40(hn) + \u03b1Cn\u22121(f(x\u2212 hn, wn))\nfor all n > 0. The latter equation can be rewritten in terms of the remaining stock z = x\u2212hn (the post decision state) as\nCn(x) = \u03b1 max 0\u2264z\u2264x\n(\nR(x)\u2212R(z)\u2212K\u03b40(x\u2212 z) + min wn\u2208W Cn\u22121(f(z, wn))\n)\n.\n(4)\nThis formulation of the problem is effectively analogous to a game against nature in the context of a two-person zero-sum game. The objective is in fact devising the value of z that maximizes the utility, but assuming that nature is actively playing against the manager with the opposite intention.\nIt can be shown (see [4]) that Cn(x), the revenue function associated with an optimal policy, is the (unique) solution to equation (4). From equation (4) we see that an optimal policy, when there are n periods left and the stock level is x, undertakes a harvest if and only if there exists 0 \u2264 z \u2264 x such that\nR(x)\u2212R(z)\u2212K + \u03b1 min wn\u2208W Cn\u22121(f(z, wn)) >\n\u03b1 min wn\u2208W Cn\u22121(f(x,wn)).\nIn fact, an action should be taken if and only if its associated benefits are sufficient to compensate the fixed cost incurred. By defining\nPn(x) = \u2212R(x) + \u03b1 min wn\u2208W Cn\u22121(f(x,wn)), (5)\nwe have that an optimal policy, when there are n periods left and the stock level is x, undertakes a harvest if and only if there exists 0 \u2264 z \u2264 x such that\nPn(z)\u2212K > Pn(x). (6)\nTo examine this kind of relationship it is useful to introduce the notion of K-concavity, a natural extension of the Kconvexity property originally introduced by Scarf in [19] to study inventory control problems."}, {"heading": "3.2 Preliminaries on K-concavity", "text": "A function \u03b2(\u00b7) isK-concave if given three points x < y < z, \u03b2(y) exceeds the secant approximation to \u03b2(y) obtained using the points \u03b2(x)\u2212K and \u03b2(z). Therefore for K = 0 no slack is allowed and one recovers the standard definition of concavity. Formally\nDefinition 1. A real valued function \u03b2(\u00b7) is K-concave if for all x, y, x < y, and for all b > 0\n\u03b2(x)\u2212 \u03b2(y)\u2212 (x\u2212 y) \u03b2(y + b)\u2212 \u03b2(y)\nb \u2264 K. (7)\nWe state some useful results concerning K-concavity:\nLemma 1. The following properties hold:\n\u2022 A concave function is 0-concave and hence Kconcave for all K \u2265 0 .\n\u2022 If \u03b21(q) and \u03b22(q) are respectively K1-concave and K2-concave for constants K1 \u2265 0 and K2 \u2265 0, then a\u03b21(q)+b\u03b22(q) is (aK1+bK2)-concave for any scalars a > 0 and b > 0.\n\u2022 If \u03b2(\u00b7) is nondecreasing and concave on I and \u03c8(\u00b7) is nondecreasing and K-concave on [infx\u2208I \u03b2(x), supx\u2208I \u03b2(x)] then the composition \u03c8 \u25e6 \u03b2 is K-concave on I .\n\u2022 Let \u03b21(x), . . . , \u03b2N (x) be a family of functions such that \u03b2i(x) is Ki-concave. Then \u03b3(x) = mini \u03b2i(x) is (maxiKi)-concave.\n\u2022 If \u03b2(\u00b7) is a continuous, K-concave function on the interval [0,m], then there exists scalars 0 \u2264 S \u2264 s \u2264 m such that\n\u2013 \u03b2(S) \u2265 \u03b2(q) for all q \u2208 [0,m]. \u2013 Either s = m and \u03b2(S)\u2212K \u2264 \u03b2(m) or s < m\nand \u03b2(S)\u2212K = \u03b2(s) \u2265 \u03b2(q) for all q \u2208 [s,m). \u2013 \u03b2(\u00b7) is a decreasing function on [s,m]. \u2013 For all x \u2264 y \u2264 s, \u03b2(x)\u2212K \u2264 \u03b2(y).\nThe proof is not reported here for space reasons, but can be found in [9]. Similar results for K-convex functions are proved in [4].\nIn the following section we will prove by induction the Kconcavity of the functions Pn(x), n = 1, . . . , N . This will allow us to characterize the structure of the optimal policy by using the last assertion of Lemma 1."}, {"heading": "3.3 On the Optimality of (S \u2212 s) policies", "text": "Suppose that we can prove that Pn(x) is continuous and strictly K-concave. Then by Lemma 1 there exists Sn, sn with the properties proved in the last point of the Lemma. It is easy to see that condition (6) is satisfied only if x > s, in which case the optimal value of the remaining stock z would be precisely Sn. In conclusion, if we can prove the continuity and K-concavity of the functions Pn(x), n = 1, . . . , N , then following feedback control law, known as a nonstationary (S \u2212 s) policy, is optimal:\nAt period n, a harvest is undertaken if and only if the current stock level is greater than sn; in that case the stock is harvested down to Sn.\nThis policy is known in the inventory control literature as a nonstationary (S\u2212s) policy 1, because the levels Sn and sn are time dependent. Since it is assumed that the marginal harvest cost g(x) is a non increasing function, we define x0 to be the zero profit level such that g(x0) = p. If g(x) < p for all x, we define x0 = 0. As a consequence for all x > x0 we have that R\u2032(x) \u2265 0 so that R (defined in equation (3)) is non decreasing. Moreover if the marginal harvest cost g(x) is a non increasing function, then R is convex.\n1For the sake of consistency, we call sn the threshold value that governs the decision, even if in our case Sn \u2264 sn.\nWe also need to make an assumption on the concavity of R(\u00b7). In particular the marginal cost function g is allowed to decrease but not by too much. Let m be an upper bound on the possible values of x and G(x) = \u222b x\n0 g(t)dt, then we\nneed\n\u03c4 = G(m)\u2212mg(m) < K\n(\n1\u2212 \u03b1\n\u03b1\n)\n, (8)\na condition that implies the \u03c4 -concavity of R.\nThe main result is the following theorem, where we show that if some assumptions are satisfied, the optimal policy is of (S \u2212 s) type. The key point of this inductive proof is to show that the K-concavity property is preserved by the Dynamic Programming operator.\nTheorem 1. For any setup cost K > 0 and any positive integer N , if f(\u00b7, w) is nondecreasing and concave for any w and if g is non increasing and satisfies condition (8), then the functions Pn(x) defined as in (5) are continuous and K-concave for all n = 1, . . . , N . Hence there exists a non-stationary (S \u2212 s) policy that is optimal. The resulting optimal present value functions Cn(x) are continuous, nondecreasing and K-concave for all n = 1, . . . , N .\nProof. From equation (8) we know that there exists a number k such that\n(K + \u03c4)\u03b1 < k < K. (9)\nThe proof is by induction on N . The base case N = 0 is trivial because C0(x) = 0 for all x, and therefore it is continuous, nondecreasing and k-concave. Now we assume that Cn(x) is continuous, nondecreasing and kconcave, and we show that Pn+1(x) is continuous and Kconcave, and that Cn+1(x) is continuous, nondecreasing and k-concave. Since f(\u00b7, w) is nondecreasing and concave for all w, Cn(f(z, wn)) is K-concave by Lemma (1). By Lemma 1\nmin wn\u2208W Cn\u22121(f(z, wn))\nis also K-concave. Again using Lemma 1, if \u2212R(x) is concave, then by equation (5) Pn+1(x) is K-concave. The continuity of Pn+1(x) is implied by the continuity of Cn(x) and R(x). Given that Pn+1(x) is K-concave and continuous, the optimal action is to harvest down to Sn+1 if and only if the current stock level is greater than sn+1, so we have\nCn+1(x) =\n{\n\u03b1(Pn+1(x) +R(x)) if x \u2264 sn+1, \u03b1(Pn+1(Sn+1) +R(x)\u2212K) if x > sn+1.\n(10) The continuity of Cn+1(x) descends from the continuity of Pn+1(x) and because by definition Pn+1(sn+1) + R(sn+1) = Pn+1(Sn+1) + R(sn+1) \u2212 K. To show it is\nnondecreasing, consider the case 0 \u2264 x1 < x2 \u2264 sn+1:\nCn+1(x2)\u2212 Cn+1(x1) =\n\u03b1\n(\nmin wn\u2208W Cn(f(x2, wn))\u2212 min wn\u2208W Cn(f(x1, wn))\n)\n.\nIf for all x2 > x1 \u2265 0,\nmin wn\u2208W (x2) f(x2, wn) \u2265 min wn\u2208W (x1) f(x1, wn),\nthen Cn+1(x2)\u2212 Cn+1(x1) \u2265 0 because Cn(x) is nondecreasing. For the case sn+1 < x1 < x2 and sn+1 \u2265 x0:\nCn+1(x2)\u2212 Cn+1(x1) = \u03b1(R(x2)\u2212R(x1)) \u2265 0,\nbecause R is nondecreasing on that interval. It must be the case that Sn+1 > x0 because harvesting below x0 is not profitable and reduces the marginal growth of the stock, so given that sn+1 \u2265 Sn+1 \u2265 x0 we conclude that Cn+1(x) is nondecreasing. It remains to show that Cn+1(x) is kconcave, and by equation (9) it is sufficient to show that it is (K + \u03c4)\u03b1-concave. To show that definition (7) holds for Cn+1(x), we consider several cases. When x < y \u2264 sn+1 , according to equation (10) we have that Cn+1(x) = \u03b1(Pn+1(x) + R(x)) and therefore equation (7) holds by Lemma 1 because Pn+1 isK-concave and R(\u00b7) is \u03c4 -concave. Similarly when sn+1 < x < y, equation (7) holds because R(\u00b7) is \u03c4 -concave. When x \u2264 sn+1 < y equation (7) reads\nCn+1(x)\u2212 Cn+1(y)\u2212 (x\u2212 y) Cn+1(y + b)\u2212 Cn+1(y)\nb \u2264\n\u03b1\n(\nK +R(x)\u2212R(y)\u2212 (x\u2212 y) R(y + b)\u2212R(y)\nb\n)\n\u2264\n\u03b1(K + \u03c4).\nbecause Pn+1(x) \u2264 Pn+1(Sn+1) and R(\u00b7) is \u03c4 -concave."}, {"heading": "4 Consistency and Complexity", "text": "Even if Theorem 1 completely describes the structure of the optimal policy, in general there is no closed form solution for the values of Sn and sn, that need to be computed numerically. In order to use the standard dynamic programming approach, the state, control and disturbance spaces must be discretized, for instance using an evenly spaced grid. Since we are assuming that those spaces are bounded, we obtain in this way discretized sets with a finite number of elements. We can then write DP like equations for those points, using an interpolation of the value function for the points that are not on the grid. The equations can be then solved recursively, obtaining the semi-optimal action to be taken for each point of the grid, that can then be extended by interpolation to obtain an approximate solution to the original problem.\nAs with all discretization schemes, we need to discuss the consistency of the method. In particular, we would like (uniform) convergence to the solution of the original problem in the limit as the discretization becomes finer. It is well known that in general this property does not hold. However in this case Theorem 1 guarantees the continuity of Cn, that in turn implies the consistency of the method, even if the policy itself is not continuous as a function of the state([4]). Intuitively, discrepancies are possible only around the threshold sn, so that they tend to disappear as the discretization becomes finer.\nThe standard dynamic programming algorithm involves O(|X||W ||U ||T |) arithmetic operations, where |X| is the number of discretized states, |W | the number of possible outcomes of the (discretized) uncontrollable events, |U | the maximum number of possible discretized actions that can be taken in any given state and T is the length of the time horizon. However, the priori knowledge of the structure of the optimal policy can be used to speed up the computation. In fact it is sufficient to find s (for example by bisection) and compute the optimal control associated with any state larger than s to completely characterize the policy for a given time step. The complexity of this latter algorithm is O(|W ||U ||T | log |X|)."}, {"heading": "5 Case Study: the Pacific Halibut", "text": "As part of the ongoing effort in the emerging field of Computational Sustainability, we consider an application of our framework to the Pacific Halibut fishery. The commercial exploitation of the Pacific halibut on the Northwestern coastline of North America dates back to the late 1800s, and it is today one of the region\u2019s largest and most profitable fisheries.The fishery developed so quickly that by the early 20th century it was starting to exhibit signs of overfishing. After the publication of scientific reports which demonstrated conclusively a sharp decline of the stocks, governments of the U.S. and Canada signed a treaty creating the International Pacific Halibut Commission (IPHC) to rationally manage the resource. The IPHC commission controls the amount of fish caught annually by deciding each year\u2019s total allowable catch (TAC), that is precisely the decision variable hn of our optimization problem."}, {"heading": "5.1 Management Problem Formulation", "text": "To develop a bioeconomic model of the fishery, we have extracted data 2 from the IPHC annual reports on estimated biomass xt, harvest ht and effort Et (measured in thousands of skate soaks) for Area 3A (one of the major regulatory areas in which waters are divided) for a 33 years period from 1975 to 2007. To model the population dynamics, we\n2Data is available from the authors upon request.\nconsider the Beverton-Holt model that uses the following reproduction function\nxn+1 = f(sn) = (1\u2212m)sn + r0sn\n1 + sn/M , (11)\nwhere sn = xn\u2212hn is the stock remaining after fishing (escapement) in year n. This model can be considered as a discretization of the continuous-time logistic equation. Here, parameter m represents a natural mortality coefficient, r0 can be interpreted as a reproduction rate andM(r0\u2212m)/m is the carrying capacity of the environment. The (a priori) mortality coefficient we use ism = 0.15, that is the current working value used by the IPHC. The values of r0 and M are estimated by ordinary least square fitting to the historical data. Estimated values thus obtained are reported in table 1, while the fitted curve is shown in figure 1.\nFollowing [18], we suppose that the system is affected by stochasticity in the form of seasonal shocks wn that influence only the new recruitment part\nxn+1 = f(sn, wn) = (1\u2212m)sn + wn r0sn\n1 + sn/M . (12)\nInstead of assuming an a priori probability distribution for wn or trying to learn one from data (that in our case would not be feasible given current scarce data availability), we will make use of the framework developed in the previous sections. In particular we will (a priori) assume that wn are random variables all having the same finite support that we will learn from data, but we will not make any assumption on the actual weight distribution. With our data, we obtain that wn \u2208 [1\u2212 0.11, 1 + 0.06] = Iw.\nFor the economic part of the model, we start by modeling the relationship between a harvest ht that brings the population level from xt to xt \u2212 ht and the effort Et needed to accomplish this result. We will a priori assume that there is a marginal effort involved, so that\nEt =\n\u222b xt\nxt\u2212ht\n1\nqyb dy (13)\nfor some q and b. This is inspired by the fact that less effort is required when the stock is abundant, and can also be interpreted as an integral of infinitesimal Cobb-Douglas production functions (a standard economic model for productivity) where b and g are the corresponding elasticities. Estimated values obtained by least squares fitting are reported in table 1, while the resulting curve is compared with historical data in figure 1. Costs involved in the Halibut fishery are divided into two categories: fixed costs and variable costs. Fixed costs include costs that are independent of the number and the duration of the trips a vessel makes (therefore generically independent from the effort Et). For example, vessel repairs costs, license and insurance fees, mooring and dockage fees are typically considered fixed costs. We will denote with K the sum of all the fixed costs, that will be incurred if and only if a harvest is undertaken. Variable costs include all the expenses that are dependent on the effort level. Variable costs typically include fuel, maintenance, crew wages, gear repair and replacement. We assume that the total variable costs are proportional to the effort Et (measured in skate soaks) according to a constant c. Parameter c is set to 200, 000$ for 1000 skate soaks (200$/skate) as estimated in [2]. Following the analysis of the historical variable and fixed costs for the halibut fishery carried on in [11], we assume K = 5, 000, 000$ for area 3A. The unit price p for the halibut is set to 4, 300, 000$/ 106 pounds, as in [2]. If we further assume a fixed discount rate \u03b4 = 0.05, we obtain a formulation of management problem for the Halibut fishery in Area 3A that fits into the framework described in the previous section. In particular, the problem for an N years horizon is that of finding an admissible policy \u03c0 = {\u00b5i}i\u2208[1,N ] that maximizes the revenue C\u03c0N (x) where xn is subject to (12), hn = \u00b5n(xn) and R(x) = px\u2212 c \u222b x\n0 1 qyb dy."}, {"heading": "5.2 Optimal Policy", "text": "By using the dynamic programming approach on the problem discretized with a step size of 0.25 \u00d7 106 pounds, we compute the optimal policy for a management horizon of N = 33 years, that is the length of our original time series. As predicted by Theorem 1, the optimal policy \u03c0\u2217 = {\u00b51, . . . , \u00b5N} for the model we constructed for area 3A is a non stationary (S\u2212s) policy. In figure 2(a) we plot the function \u00b51(\u00b7) to be used in the first year (the values of S1 and s1 are 133 and 176.75 respectively). In words, the optimal policy dictates that at period n a harvest is to be undertaken if and only if the current stock level is greater than sn; in that case the stock is harvested down to Sn.\nThe trajectory of the system when it is managed using the optimal policy is shown in figure 2, together with the corresponding optimal harvests. As we can see, the optimal policy is pulsing, in the sense that it involves periodic closures of the fishery, when no harvest should be undertaken so that\nthe fish stock has time to recover. Of course, this kind of policy could be acceptable in practice only in combination with some rotation scheme among the different Areas, so that a constant yearly production can be sustained.\nThis scheme is very different from the Constant Proportional Policy (CPP) that has been traditionally used to manage the Halibut fishery. In fact a CPP works by choosing the yearly TAC as a fixed fraction of the current stock level xt, and is aimed at maintaining the exploited stock size (the escapement) at a given fixed level. This policy can be seen as a simplified version of an (S \u2212 s) policy where the two levels do not depend on the stage n and coincide, thus defining the target stock size.\nTo see the advantage of the optimal (S \u2212 s) policy, we compare it with the historical harvest proportions and with a CPP policy that uses the historical average harvest rate a = 0.1277. Table 2 summarizes the discounted revenues corresponding to an initial stock size x1 = 90.989 million pounds, that is the estimated stock size in 1975.\nCompared to the historical policy or the CPP policy, revenues for the optimal (S \u2212 s) policy are about 35% higher, as reported in table 2. Notice that the comparison is done assuming a worst case realization of the stochasticity, or in other words that the nature is actively playing against the manager.\nNotice that the large harvest prescribed by the optimal (S \u2212 s) policy in the last year is an artifact of the finite horizon effect, caused by the fact that there is no reason not to exhaust the resource at the end of the management horizon (as long as it is profitable to harvest it). However it does not affect the comparison significantly due to the discount rate. In fact the (discounted) revenue for the entire last large harvest only accounts for less than 8% of the total revenue. This is confirmed by looking at the results obtained with a rolling horizon strategy that always picks the optimal action with a 33-years long management horizon in mind. As shown in figure 3, this (suboptimal) strategy is not affected by the finite horizon effect. The rolling horizon strategy still involves periodic closures of the fishery and significantly outperforms the historical policies, as reported in table 2.\nTo further clarify that the pulsing nature of the optimal harvests is not an artifact of the finite horizon, it is also interesting to notice that the theoretical results on the optimality of (S \u2212 s) policies and the corresponding pulsing\nharvests can be carried over to the infinite horizon case via limiting arguments. The high level argument is that the optimal value function Cn(x) converges uniformly to C(x) as n\u2192 \u221e, while Pn(x) converges uniformly to a function P (x) as n\u2192 \u221e. Given that by Theorem 1 Pn(x) is continuous and K-concave for all n, we have that P (x) must be also continuous and K-concave. Using an argument similar to the one developed in section 3.3 and by using Lemma 1, one can show that there exists S and s such that the optimal stationary policy for the infinite horizon problem is an (S \u2212 s) policy."}, {"heading": "6 Conclusions", "text": "In this paper, we have analyzed the optimality of (S\u2212s) polices for a fairly general class of stochastic discrete-time resource allocation problems. When a non stationary (S\u2212 s) policy is used, a harvest is undertaken at period n if and only if the current stock level is greater than sn; in that case the stock is harvested down to Sn. The framework developed is quite general and can be applied to problems arising in very different domains, such as natural resource management, crowdsourcing, pollution management. When assumptions of Theorem 1 are met, we have shown that there exists a non stationary (S \u2212 s) policy that maximizes the utility in a worst case scenario.\nA fundamental advantage of the game theoretic approach is that it completely avoids the problem of evaluating the probability distributions of the random variables describing the uncertainty affecting those systems, a task that is difficult or even impossible to accomplish in many practical circumstances. Given the consensus reached by the scientific community on the importance of understanding the role of uncertainty when dealing with renewable resources, we believe that worst-case scenario frameworks such as the\none described here provide new insights and will become increasingly important.\nTo contribute to the effort of the Computational Sustainability community in tackling the fundamental sustainability challenges of our time, we consider an application of our model to a marine natural resource. This type of natural resources are in fact widely believed to be endangered due to over exploitation and generally poorly managed. Using Gulf of Alaska Pacific halibut data from the International Pacific halibut Commission (IPHC) annual reports, we formulated a real world case study problem that fits into our framework. In particular, our approach defines a policy with a guaranteed lower bound on the utility function that is structurally very different from the one currently employed.\nAs a future direction, we plan to study the effects of partial observability on the optimal policies by moving into a POMDP framework. Moreover, we aim at extending the results presented here to the multidimensional case by extending the theory on the so-called (\u03c3, S) policies from the inventory control literature."}, {"heading": "7 Acknowledgments", "text": "This research is funded by NSF Expeditions in Computing grant 0832782."}], "references": [{"title": "Robust optimization\u2013 methodology and applications", "author": ["A. Ben-Tal", "A. Nemirovski"], "venue": "Mathematical Programming,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Dynamic programming and optimal control", "author": ["D.P. Bertsekas"], "venue": "Athena Scientific Belmont, MA,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1995}, {"title": "Robust discrete optimization and network flows", "author": ["D. Bertsimas", "M. Sim"], "venue": "Mathematical Programming,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Mathematical bioeconomics: the optimal management of renewable resources", "author": ["C.W. Clark"], "venue": "Wiley New York:,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1990}, {"title": "Resource economics", "author": ["J.M. Conrad"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1999}, {"title": "Sustainability of fisheries through marine reserves: a robust modeling analysis", "author": ["L. Doyen", "C. B\u00e9n\u00e9"], "venue": "Journal of Environmental Management,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "Computational Sustainability Computational Methods for a Sustainable Environment,Economy, and Society", "author": ["C. Gomes"], "venue": "The Bridge, National Academy of Engineering,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Wilen. A model of regulated open access resource use", "author": ["J.E.F.R. Homans"], "venue": "Journal of Environmental Economics and Management,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1997}, {"title": "Risk-sensitive Markov decision processes", "author": ["R.A. Howard", "J.E. Matheson"], "venue": "Management Science,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1972}, {"title": "Implementing the precautionary principle in fisheries management through marine reserves", "author": ["T. Lauck", "C.W. Clark", "M. Mangel", "G.R. Munro"], "venue": "Ecological Applications,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Markov games as a framework for multi-agent reinforcement learning", "author": ["M.L. Littman"], "venue": "In Proceedings of the eleventh international conference on machine learning,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1994}, {"title": "Risk sensitive Markov decision processes", "author": ["S.I. Marcus", "E. Fern\u00e1ndez-Gaucherand", "D. Hern\u00e1ndez-Hernandez", "S. Coraluppi", "P. Fard"], "venue": "Systems and Control in the Twenty-First Century,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1997}, {"title": "Game theory. Third Edition", "author": ["G. Owen"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1995}, {"title": "A stochastic model for the economic management of a renewable animal resource", "author": ["W.J. Reed"], "venue": "Mathematical Biosciences,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1974}, {"title": "Optimal escapement levels in stochastic and deterministic harvesting models", "author": ["W.J. Reed"], "venue": "Journal of Environmental Economics and Management,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1979}, {"title": "The Optimality of (S, s) Policies in the Dynamic Inventory Problem. Stanford mathematical studies in the social sciences, page", "author": ["H. Scarf"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1960}], "referenceMentions": [{"referenceID": 3, "context": "While in most of the works in the literature [6, 7] these growth processes are modeled with deterministic first-order difference or differential equations, this approach often represents an oversimplification.", "startOffset": 45, "endOffset": 51}, {"referenceID": 4, "context": "While in most of the works in the literature [6, 7] these growth processes are modeled with deterministic first-order difference or differential equations, this approach often represents an oversimplification.", "startOffset": 45, "endOffset": 51}, {"referenceID": 9, "context": "In fact, even if in principle uncertainty could be reduced by collecting and analyzing more data, it is generally believed that complex and stochastic systems, such a marine environments, could never become predictable (to the point that the authors of [13] believe that \u201cpredictability of anything as complex as marine ecosystem will forever remain a chimera\u201d).", "startOffset": 253, "endOffset": 257}, {"referenceID": 5, "context": "Moreover, there are situations of \u201cradical uncertainty\u201d ([8]) or ambiguity where a stochastic description is not feasible because the probabilities are not quantifiable.", "startOffset": 57, "endOffset": 60}, {"referenceID": 8, "context": "Using tools such as risksensitive Markov decision processes ([12, 15]), it is also possible to encode into the problem the attitude towards risk of the decision maker by using an appropriate utility function.", "startOffset": 61, "endOffset": 69}, {"referenceID": 11, "context": "Using tools such as risksensitive Markov decision processes ([12, 15]), it is also possible to encode into the problem the attitude towards risk of the decision maker by using an appropriate utility function.", "startOffset": 61, "endOffset": 69}, {"referenceID": 0, "context": "This type of approach, where the problem of data uncertainty is addressed by guaranteeing the optimality of the solution for the worst realizations of the parameters, is also known in the literature as robust optimization ([3, 5]), and has been successfully applied to uncertain linear, conic quadratic and semidefinite programming.", "startOffset": 223, "endOffset": 229}, {"referenceID": 2, "context": "This type of approach, where the problem of data uncertainty is addressed by guaranteeing the optimality of the solution for the worst realizations of the parameters, is also known in the literature as robust optimization ([3, 5]), and has been successfully applied to uncertain linear, conic quadratic and semidefinite programming.", "startOffset": 223, "endOffset": 229}, {"referenceID": 10, "context": "This formulation is a particular type of Markov game [14] (sometimes called a stochastic game [16]) where there are only two agents (the manager and nature) and they have diametrically opposed goals.", "startOffset": 53, "endOffset": 57}, {"referenceID": 12, "context": "This formulation is a particular type of Markov game [14] (sometimes called a stochastic game [16]) where there are only two agents (the manager and nature) and they have diametrically opposed goals.", "startOffset": 94, "endOffset": 98}, {"referenceID": 6, "context": "As part of the new exciting research area of Computational Sustainability ([10]), where techniques from computer science and related fields are applied to solve the pressing sustainability challenges of our time, we present an application of the proposed framework to the Northern Pacific Halibut fishery, one of the largest and most lucrative fisheries of the Northwestern coast.", "startOffset": 75, "endOffset": 79}, {"referenceID": 1, "context": "Whenever possible, we will use a notation consistent with the one used in [4].", "startOffset": 74, "endOffset": 77}, {"referenceID": 13, "context": "As opposed to the maximization of an expected utility ([17, 18]), this formulation is inherently risk averse.", "startOffset": 55, "endOffset": 63}, {"referenceID": 14, "context": "As opposed to the maximization of an expected utility ([17, 18]), this formulation is inherently risk averse.", "startOffset": 55, "endOffset": 63}, {"referenceID": 1, "context": "As a consequence of the principle of optimality([4]), the dynamic programming equation for this problem reads:", "startOffset": 48, "endOffset": 51}, {"referenceID": 1, "context": "It can be shown (see [4]) that Cn(x), the revenue function associated with an optimal policy, is the (unique) solution to equation (4).", "startOffset": 21, "endOffset": 24}, {"referenceID": 15, "context": "To examine this kind of relationship it is useful to introduce the notion of K-concavity, a natural extension of the Kconvexity property originally introduced by Scarf in [19] to study inventory control problems.", "startOffset": 171, "endOffset": 175}, {"referenceID": 1, "context": "Similar results for K-convex functions are proved in [4].", "startOffset": 53, "endOffset": 56}, {"referenceID": 1, "context": "However in this case Theorem 1 guarantees the continuity of Cn, that in turn implies the consistency of the method, even if the policy itself is not continuous as a function of the state([4]).", "startOffset": 187, "endOffset": 190}, {"referenceID": 14, "context": "Following [18], we suppose that the system is affected by stochasticity in the form of seasonal shocks wn that influence only the new recruitment part", "startOffset": 10, "endOffset": 14}, {"referenceID": 7, "context": "Following the analysis of the historical variable and fixed costs for the halibut fishery carried on in [11], we assume K = 5, 000, 000$ for area 3A.", "startOffset": 104, "endOffset": 108}], "year": 2010, "abstractText": "In this paper we introduce a class of Markov decision processes that arise as a natural model for many renewable resource allocation problems. Upon extending results from the inventory control literature, we prove that they admit a closed form solution and we show how to exploit this structure to speed up its computation. We consider the application of the proposed framework to several problems arising in very different domains, and as part of the ongoing effort in the emerging field of Computational Sustainability we discuss in detail its application to the Northern Pacific Halibut marine fishery. Our approach is applied to a model based on real world data, obtaining a policy with a guaranteed lower bound on the utility function that is structurally very different from the one currently employed.", "creator": "dvips(k) 5.98 Copyright 2009 Radical Eye Software"}}}