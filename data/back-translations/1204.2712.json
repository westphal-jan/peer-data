{"id": "1204.2712", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Apr-2012", "title": "Learning to Rank Query Recommendations by Semantic Similarities", "abstract": "The logs of interactions with a search engine show that users often reformulate their queries. Examining these reformulations shows that recommendations that specify the focus of a query are helpful, such as those based on extensions of the original queries. However, it also shows that queries that express a current shift in relation to the original query can help the user to access the information they need more quickly. We propose a method to use the query logs of past user queries to determine which ones either focus or shift the initial query topic. This method combines various click-based, theme-based and session-based ranking strategies and uses monitored learning to maximize the semantic similarities between the query and the recommendations while at the same time diversifying our method based on the query / click logs of a Japanese web search engine, and we show that the combination of the three suggested methods is significantly better than each of them.", "histories": [["v1", "Thu, 12 Apr 2012 13:15:43 GMT  (105kb)", "http://arxiv.org/abs/1204.2712v1", "2nd International Workshop on Usage Analysis and the Web of Data (USEWOD2012) in the 21st International World Wide Web Conference (WWW2012), Lyon, France, April 17th, 2012"]], "COMMENTS": "2nd International Workshop on Usage Analysis and the Web of Data (USEWOD2012) in the 21st International World Wide Web Conference (WWW2012), Lyon, France, April 17th, 2012", "reviews": [], "SUBJECTS": "cs.AI cs.HC cs.IR", "authors": ["sumio fujita", "georges dupret", "ricardo baeza-yates"], "accepted": false, "id": "1204.2712"}, "pdf": {"name": "1204.2712.pdf", "metadata": {"source": "CRF", "title": "Learning to Rank Query Recommendations by Semantic Similarity", "authors": ["Sumio Fujita", "Georges Dupret"], "emails": ["sufujita@yahoo-corp.jp", "gdupret@yahoo-inc.com", "rbaeza@acm.org"], "sections": [{"heading": null, "text": "ar X\niv :1\n20 4.\n27 12\nv1 [\ncs .A\nI] 1\n2 A\npr 2\n01 2\nWe propose a method to identify from search engine query logs possible candidate queries that can be recommended to focus or shift a topic. This method combines various clickbased, topic-based and session based ranking strategies and uses supervised learning in order to maximize the semantic similarity between the query and the recommendations, while at the same time we diversify them.\nWe evaluate our method using the query/click logs of a Japanese web search engine and we show that the combination of the three methods proposed is significantly better than any of them taken individually."}, {"heading": "Categories and Subject Descriptors", "text": "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval-Search Process; H.3.5 [Information Storage and Retrieval]: Online Information Services-Web based services"}, {"heading": "General Terms", "text": "Algorithms, Experimentation, Performance"}, {"heading": "Keywords", "text": "Web search, query logs, click logs, query recommendation."}, {"heading": "1. INTRODUCTION", "text": ""}, {"heading": "Problem Statement", "text": "Information retrieval is often an interactive process where a user successively refines his or her original search query, switch focus and approach her/his goal in several steps. Assisting users in this process makes it less cumbersome. Query suggestions are particularly useful on mobile devices and for Asian languages with complex character sets where typing queries is particularly inconvenient and time consuming.\nQuery recommendation engines should not limit themselves to proposing more focused queries, but should also suggest queries that are a reasonable switch in focus. This is confirmed by examining search engine query log data. For example, the most frequent queries after \u201ctoyota\u201d are \u201chonda\u201d, \u201cnissan\u201d and \u201clexus\u201d, none of which are a direct refinement of the original query. As another example, the most frequent query after \u201cdriver\u2019s license renewal\u201d is \u201cslight violence of traffic laws\u201d, which may prevent drivers from renewing their driver\u2019s license.\nSearch engines sometimes suggest queries with some additional modifiers, focusing on a particular aspect of the previous query. According to Jansen et al. [13], queries which initiated a new session are in 31% cases followed by query reformulations of the type \u2018specialization\u2019 or \u2018specialization with reformulation\u2019. Such drill down operations are not necessarily observed more frequently than topic shifting. Topic shifting occurs especially when users engage in complex tasks like researching for a new vehicle and comparing competing candidate models, or when they look for information on how to renew a driver license including ancillary tasks, like discovering office hours, finding the required forms, the office address, etc. Boldi [5] pointed out that the typically useful recommendations are either specializations or topic shifting, which they refer to as \u201cparallel moves\u201d.\nUnlike pre-retrieval query suggestions, which frequently propose automatic query completion right in the query box, query recommendation provides semantically related queries and exclude trivially synonymous queries, since state-of-theart commercial search engines are good enough to cover minor spelling variations or even some miss-spellings. Nevertheless, diversifying query recommendations would help for polysemic queries."}, {"heading": "Methodology", "text": "Query recommendations are often based on clustering methods with the inconvenience that queries falling in the same cluster are some time more ambiguous and less helpful than\nthe original query. Instead, we formulate in this work three distinct methods of extracting query recommendations from a search engine\u2019s click-through logs. These methods induce directed links between queries existing in the logs and hence have the potential to overcome the limitations of the clustering methods. The first method is based on the position of the clicked URLs in the search ranking of the original query and its potential recommendations. The second is based on reformulations of the original query that can be easily detected in the logs using the query surface forms. Users reformulate queries for a variety of reasons: because the original formulation is too ambiguous or carry other meanings they did not intend, or because the results returned by the engine are not adequate. The third method is also based on query reformulations but it is based on co-occurrence relations of the queries in the sessions. We show that each method has its own advantages and drawbacks. The first method sometimes leads to recommendations that are more difficult to understand because it tends to include Web jargon, but it is sometimes more useful than the simple reformulation method because it leverages the topical knowledge of other users. By construction, the second method rarely drifts from the original search topic and tends to be limited to specializations of the original query. This results in safer recommendations with less coverage. Variants of this method are used by many commercial search engines because it is safer and more predictable. The last method is better suited for shifting topics because it provides more diverse recommendations such as parallel move reformulations [5]. On the other hand, trivial variants or completely unrelated queries are not useful. Each method has distinct capabilities and short-comings, and then it would be interesting to develop a method that chooses the best candidates and offer to the user an improved set of recommendations. This is the objective of this work."}, {"heading": "Assumptions", "text": "Since most useful recommendations are either specializations or parallel moves, it is better to use distinct methods to cover both types. It is also necessary to exclude trivial synonyms and unrelated queries. We make the following assumption: in the semantic hierarchy of information needs, locating the original user query at the center, generalization queries reside in the upper part of the hierarchy and specialization queries in the lower. The neighbouring queries in the semantic hierarchy are generally useful. In order to identify such queries, we combine the recommendation candidates from three methods and learn the ranking function according to semantic similarities reflected in the topological relations in the semantic hierarchy. We schematized the relations in Figure 1, where too close queries are not useful as recommendations. On the other hand, either specializations or parallel moves are useful to help the searcher with drill down or shift operations respectively."}, {"heading": "Contribution", "text": "The problem we address in this paper is how to combine such candidate recommendations with different characteristics to diversify them. One possible solution is to infer the intention of the user: does she/he intend to drill down into the topic or will she/he quit the current sub topic and move to the next sub topic? This would undoubtedly be a very hard task. A priori, any query may be followed by the user\ndrilling down for more precise information or shifting the intention. This depends among other things on the quality of the results the user finds on the result page. User decisions and consecutive search actions are not only query dependent but also user and context dependent. Instead of attempting to predict the user\u2019s state of mind, we propose to minimize the risk of dissatisfying the user by proposing carefully various solutions. Expressed in the terms of our prior assumption, we try to maximize the semantic similarity between the original query and recommended queries by combining different types of recommendations, to make them more diverse. We will not use lexical features such as semantic categories of query terms, since such lexical knowledge has a usually fairly limited coverage."}, {"heading": "Organization", "text": "In Section 2, we present some related works that make use of query and click logs. We present the methods used to extract the different types of recommendations in Section 3. We show empirically that the session based method is good at identifying shifting queries whereas the other two methods favor focused faceted queries. We combine these three methods to maximize the semantic similarity measure in Section 4. We describe the supervised learning algorithm we use in Section 5. In Section 6, we report the results of an empirical study based on the click logs of a popular Japanese search engine and Section 7 concludes the paper."}, {"heading": "2. RELATED WORK", "text": ""}, {"heading": "Click Log Analysis", "text": "Click logs typically contain information such as the search query string, time stamp, browser identifier, clicked URLs, and rank positions. Although correctly interpreting clicks is not straightforward [14, 8], click information is often used as an implicit feedback on URL relevance.\nBeeferman and Berger studied Web search query logs and clustered click-through data by iterating two steps: (a) combining the two most similar queries and (b) combining the two most similar URLs [4]. The generated clusters were used to enhance query recommendations. Baeza-Yates et al. proposed a query recommendation technique using query clustering based on the similarity of clicked URLs [3]. Dupret and Mendoza also addressed query recommendation using click-through data but focused on document ranking [9].\nXue et al. [18] used click-through data to create metadata for Web pages. They estimated document-to-document similarities on the basis of co-clicked queries and query strings used as metadata or tags. These estimates were then spread over similar documents. Craswell and Szummer, who used clickthrough data for image retrieval, experimented with backward random walks [7]. Their method is based on query-todocument transition probabilities on a click graph. BaezaYates and Tiberi extracted semantic relations between queries on the basis of set relations of clicked URLs [2]. Antonellis et al. proposed the Simrank++ [1] method in which query similarity is propagated through click bipartite graphs. They used the query similarity measure to rewrite queries in order to extend advertisement matching. Again, such a measure of structural-context similarity might be adequate for the task such as query rewrites for sponsored search where rewriting to a practical synonymous query is effective."}, {"heading": "Term Expansion Based", "text": "Jones et al. extracted query substitutions from the same user sessions by identifying correlated term pairs and substituting phrases [15]. Jones\u2019 work addressed query rewrites in sponsored search contexts where the\u201cprecise rewriting\u201d such as\u201cautomobile insurance 7\u2192 automotive insurance\u201d, is mostly preferred. However, the current state of the art search engines return very similar results to these two queries."}, {"heading": "Query Session Based", "text": "Spink et al. surveyed information related to successive Web searches [16] and found that the information involves changes and shifts in search terms, search strategies, and relevance judgments. Jansen et al. analyzed successive queries in large Web search query logs [13], and He et al. tried to detect session boundaries on the basis of search patterns and time intervals in query logs [12]. Fonseca et al. extracted query relations by using association rules from the same user sessions [10]. Boldi et al. analyzed search user sessions, classified query reformulation types [5], and derived queryflow graphs for the extracted query recommendations. They pointed out that the typically useful recommendations are either specializations or parallel moves while trivial variants or completely unrelated queries are not useful. Cao et al. applied click-based clustering to session-based query suggestions [6] and they claim that the context awareness helps to better understand user\u2019s search intent and to make more meaningful suggestions. However, they do not evaluate well if the context awareness really improves the suggestion utility due to the lack of an adequate baseline."}, {"heading": "3. GENERATING CANDIDATES", "text": "In this work we focus on the generation of query recommendations through the use of inter-query relations in Web search logs. As we have seen in the previous section, log based query recommendation techniques fall into one of three approaches, namely click-based, term expansion based and session based. Each approach intends to capture patterns of different user activities from the query logs. Queries are related by a co-click relation in view of users clicking on the same URL in response to them. Queries are also related to their possible expansion by adding facet modifiers, i.e. co-topic relations. Finally, queries are related by their co-occurrence in a user session.\nThe following three methods extract these three types of inter-query relations representing user behaviors in the logs: either a specialization/refinement of the information need or a parallel move from the original search intent. The methods are simple although they are intended to extract candidates thoroughly, so that they are adequately combined and reranked by a supervised learning algorithm to maximize the semantic similarity measure."}, {"heading": "3.1 Best Rank Directed Co-Click Relations", "text": "This method compares the positions in the search results of the documents clicked during a query session. If a query q\u2032 different from query q better orders \u2014according to a suitable measure\u2014the clicked documents in a significant number of sessions of q, then q\u2032 is a candidate query for recommendation. There is a fundamental basis for considering the clicked document rankings rather than the simple similarity of clicked page sets. Take for example the multi-faceted query \u201ccurry,\u201d The documents that a user selects can help identify a posteriori his information need: if he or she is interested in how to cook curry, he or she will select pages related to cooking rather than those related to the origin of \u201ccurry\u201d in Indian culinary history. The assumption is that savvier users with the same information need will probably express the query less ambiguously and enter \u201ccurry recipe,\u201d for example, as the query. The hypothesis we wish to investigate here is whether documents clicked by a previous user are ranked higher in the \u201ccurry recipe\u201d results than in the \u201ccurry\u201d results. If they are, we can retrieve the \u201ccurry recipe\u201d query from the log and recommend it.\nMore formally, suppose that u is a clicked URL1 in the results for query q. For each such clicked URL u, we assume the existence of a set of queries for which URL u is ranked higher in the results. This set might be empty. We hypothesize that such queries are potential recommendations for q.\nWe first define the URL cover UCq of a query q as the set of URLs clicked in response to query q, and the query cover of URL u, QCu as the set of queries for which URL u is clicked. We define ranku(q) as the rank position of URL u for query q. The set of best rank co-click queries for query q, BRCCQq, is as follows:\nBRCCQq \u2261 \u22c3\nu\u2208UCq\narg min q\u2032\u2208QCu\nranku(q \u2032) .\nWe estimate the strength of the relations between a query and its candidate recommendations in accordance with the following weighting scheme. We define cnt(u, q) as the number of clicks on u in response to query q, cnt(q) as the total number of clicks in response to query q, cnt(u) as the total number of clicks on u regardless of the query and Q as the set of all queries. We define the probability PCC(q2|q1) as follows:\nPCC(q2|q1) = \u2211\nu\u2208UCq1\nP (u|q1) \u00b7 P (q2|u)\n= \u2211\nu\u2208UCq1\nP (u|q1) \u00b7 P (q2) \u00b7 P (u|q2)\nP (u)\n1We use \u201cdocument,\u201d\u201cpage,\u201d and \u201cURL\u201d interchangeably.\nwith\nP (u) = cnt(u) \u2211\nq\u2208Q cnt(q)\n,\nP (q) = cnt(q) \u2211\nq\u2032\u2208Q cnt(q\u2032)\n, and\nP (u|q) = cnt(u, q)\ncnt(q) .\nThis approach can be regarded as a special case of the session-based recommendation proposed by Dupret and Mendoza [9]. In this approach, each single click is considered to be a single session. This is clearly distinct from the approach used in query clustering methods because it explicitly uses the positions of the documents in the results list."}, {"heading": "3.2 Co-topic Relations", "text": "Commercial search engines commonly use expansions of input query string in logs as recommendations. Here, we introduce a variation that takes advantage of a characteristic of the Japanese language. The agglutinant nature of the Japanese language makes it comparatively easy to detect topic-facet structure in queries. In practice, a facet directive in Japanese is easily identified as a word that appears as the last term of a significant number of distinct queries. In our experiments, if a word is the last of at least five distinct query strings, it can be safely regarded as a facet word as long as queries appearing fewer than ten times are eliminated from the logs. Thus, from the topic-part-only query \u201ccurry\u201d, we may induce \u201ccurry recipe\u201d, \u201ccurry restaurant\u201d, and other queries with different directives.\nWe define a co-topic query as a query expanded by the addition of a facet directive. As for co-click relations, we define a weighting scheme that captures the strength of the relation between the original query q1 and a co-topic recommendation q2 based on the following probability: we first define CTQq1 as the set of co-topic queries formed over q1, the similarity is expressed as:\nPCT (q2|q1) = cnt(q2)\ncnt(q1) + \u2211\nq 2\u2032 \u2208CTQq1 cnt(q2\u2032)\n.\nThis relation normally represents a specialization of the original concept by adding a facet directive which restrictively modifies the original concept."}, {"heading": "3.3 Co-Session Relations", "text": "This last method identifies the query reformulations observed a significant number of times during the sessions of users. Co-session queries are queries submitted consecutively from the same user in a time interval typically no longer than 5 minutes. Co-session queries includes not only the reformulation or rewriting of queries, such as in the cotopic relation, but also queries that reflect a shift in information needs. (A more complete nomenclature of the relations extracted this way can be found in [5].)\nWe define the set CSQq1 as the set of queries sharing a co-session relation with q1. The strength of a co-session relation between q1 and q2 is estimated as a probability:\nPCS(q2|q1) = cnt(q2, q1)\ncnt(q1) ,\nwhere cnt(q2, q1) denotes the count of the query q2 preceded by the query q1 in the same user session.\nThis method is relatively robust to mistakes during the segmentation of user activities in session: if q2 and q1 do not belong to the same session, cnt(q2, q1) will be small, leading to a relation with a low strength."}, {"heading": "4. QUERY SIMILARITY", "text": "It is not straightforward to assess the quality of query recommendations. To evaluate the three methods presented in the previous section, we use the semantic similarity of the queries after they are mapped into a category hierarchy. We adopt a similarity measure between query pairs by Baeza-Yates and Tiberi [2] who evaluated semantic relations between queries connected by an edge of their click cover graph. For this purpose, they use the Open Directory Project2, where queries are matched against the directory content to find the categories where they belong. We apply the same methodology but using the Yahoo! JAPAN directory3 because it has a more complete coverage of Japanese queries.\nBaeza-Yates and Tiberi use the following similarity function on the categories matching two queries q and q\u2032:\nSimprefix(D,D \u2032) = |P (D,D\u2032)|/max{|D|, |D\u2032|} ,\nwhere P (D,D\u2032) is the longest common prefix of the category paths D and D\u2032 where the queries q and q\u2032 were found, respectively. This is intuitively reasonable: consider for example the query \u201cSpain\u201d. The query term is found in \u201cRegional / Countries / Spain\u201d while \u201cBarcelona\u201d is found in \u201cRegional / Countries / Spain / Autonomous Communities / Catalonia / Cities / Barcelona,\u201d. Then, the similarity is 3\n7 .\nHowever, we needed to make some adjustment because in the Yahoo! directory, a subcategory like \u201cSpain\u201d might appear below diverse top categories such as \u201cMaps / By region / Countries\u201d, \u201cArts / By region / Countries\u201d, or \u201cRecreation / Travel / By region / Countries\u201d. We therefore use the following similarity function:\nSimsubstring(D,D \u2032) =\nC(D,D\u2032)\nmax{|D|, |D\u2032|} ,\nwhere C(D,D\u2032) is the number of common subparts of two category paths that match the queries. The previous similarity function measures the ratio of the hyper concepts that the two categories share whereas this new function considers the facet similarity of subcategories.\nTo associate Yahoo! categories with each query, we used the directory search application programming interface (API), which returns a list of categorized sites retrieved by \u201cAND\u201dboolean queries. This presumably favors co-topic relations over co-click relations because registered sites retrieved by the expanded query q2 are also retrieved by original query q1 due to the \u201cAND\u201d operation. As a categorized site is retrieved, the procedure votes to its category. The category with maximum number of votes is assigned to the query. Inter query similarity depends on similarities of category pairs, and the maximum similarity through category pairs was selected as the final score.\nFor query recommendation, queries that are virtually the same are useless, so we excluded queries falling in the group of trivial variants. Queries were grouped in accordance with the clicked URL set UCq by an online single-pass clustering\n2http://www.dmoz.org/ 3http://dir.yahoo.co.jp/\nusing a vectorial representation of each URL set, where the component is the click frequency of the URL in response to the query."}, {"heading": "5. COMBINING RECOMMENDATIONS", "text": "Identifying the user intention from contextual information is a very difficult task and is not guaranteed to be effective. Instead, we take a more conservative approach and we combine the three methods described above. We attempt to take advantage of each method strength but also hedge against bad recommendations by providing some conservative specialization queries, some serendipitous queries and by proposing some \u201ctopic shifting\u201d queries. In other words, we diversify the set of recommended queries.\nWe formulate the problem as a \u201clearning to rank\u201d task for which we use the similarity measure defined in Section 4. We use gradient boosting decision trees (GBDT) described in [11] because of the robustness to overfitting, the scalability and the ability to handle highly non-linear problems of this method."}, {"heading": "Training Data", "text": "For training and test pairs, we calculated the similarity measure described in Section 4 as the target attribute. For this we cleaned the data and added random query pairs to augment the number of negative examples and balance the training set. The details are given in Section 6."}, {"heading": "Feature Set", "text": "We defined the quantities PCC(q2|q1), PCT (q2|q1) and PCS(q2|q1) in Section 3. On top of these features, we defined 24 features as described in Table 1. Facet extraction features are extracted from the query logs. We adopted the query textual features used in [5]. Cosine similarities are computed based on the bag of character bigrams and on chunks, i.e. contiguous character strings split by a white space. As result click features, we measure how the queries are multi-faceted with respect to user behavior on the result sets. Click entropy is used to reflect query ambiguity as in Teevan et al. [17]. For query session co-occurrence we derive features from pair of queries directly following one another in a user session. LLR is adopted from Jones et al. [15]. We introduced this to identify significant query pairs from sessions. A high value means a strong dependency between two adjacent queries in a session."}, {"heading": "Learning Models", "text": "As mentioned above, we use gradient boosting decision trees (GBDT [11]). This is an additive regression model over an ensemble of shallow regression trees.\nIt iteratively fits an additive model:\nFm(x) = Fm\u22121(x) + \u03b2mTm(x;\u0398m) ,\nwhere Tm(x;\u0398m) is a regression tree at iteration m, weighted by parameter \u03b2m, with a finite number of parameter \u0398m, consisting of split regions and corresponding weights, which are optimized such that a certain loss function is minimized as follows:\n(\u03b2m,\u0398m) = argmin\u03b2,\u0398\nN \u2211\ni=1\nL(yi, Fm\u22121(x) + \u03b2Tm(x; \u0398)) .\nAt iteration m, tree Tm(x; \u0398m) is induced to fit the negative gradient by least squares:\n\u0398\u0302 = argmin\u0398,\u03b2\nN \u2211\ni=1\n(\u2212gm(xi)\u2212 \u03b2mTm(x;\u0398m)) 2 .\nwhere \u2212gm(xi) is the gradient over current prediction function:\n\u2212gm(xi) = \u2212\n[\n\u2202L(yi, F (xi))\n\u2202F (xi)\n]\nF (x)=Fm\u22121(x)\n.\nEach non-terminal node in the tree represents the condition of a split on a feature space and each terminal node represents a region. The improvement criterion to evaluate splits of a current terminal region R into two subregions (R\u2113, Rr) is as follows:\ni2(R\u2113, Rr) = w\u2113wr\nw\u2113 + wr (y\u2113 \u2212 yr)\n2 ,\nwhere y\u2113 and yr are the mean response of left and right subregions, respectively, and w\u2113 and wr are the corresponding\nsums of weights. We evaluate the relative importance of each feature by the normalized sum of i2(R\u2113, Rr) through all the nodes corresponding to the feature."}, {"heading": "6. EXPERIMENTS", "text": ""}, {"heading": "6.1 Evaluation Data", "text": "To evaluate our proposed combined method, we used a sample of the query log of a Japanese commercial search engine. First, query-clicked URL pairs that appear only once were removed. Second, identical query-URL pairs with the same browser cookie (i.e., queries from the same client) were counted only once to improve robustness against spam. Third, we selected from the log the 4,544 queries that contain one of the seven most frequent facet directives appearing in Japanese web search. Table 2 shows the statistics of our evaluation data. On the basis of these initial queries, we extracted 188,737 query pairs, among which, 70,041 pairs are in a best rank co-click relation, 77,991 pairs in a co-topic relation, and 66,612 pairs in a co-session relation. From them, we excluded pairs where either query failed to be assigned to any category. At the end, we obtained 86,544 query URL pairs, which we split into two sets to carry out a two fold cross validation. We supplemented training pairs by 82,212 randomly combined pairs of queries and recommended queries, which act as negative or counter-examples. Notice that average semantic similarities between pairs are high for co-click pairs."}, {"heading": "6.2 Evaluation Measures", "text": "Given a ranked query list Q, the discounted cumulative gain (DCG) at the rank threshold R is defined as follows:\nDCGR(Q) = g1 + R \u2211\nr=2\ngr log2 r ,\nwhere gr is the score according to the judgement at the rank r in Q.\nWe assigned five grades to the similarity of each query pair, namely \u201cperfect\u201d (above 0.75), \u201cexcellent\u201d (between 0.75 and 0.5), \u201cgood\u201d (between 0.5 and 0.25), \u201cfair\u201d (below 0.25 but above 0.0), and\u201cpoor\u201d (at 0) according to the value range of similarities. We assign scores of 10, 7, 3, 0.5 and 0.0 to these five grade labels.\nThe ideal ranked query list I is obtained by ranking the recommendations in decreasing order of their label values. It is used to define the normalized DCG. In particular, we use the normalized DCG at 5 (NDCG5), defined as follows:\nNDCG5(Q, I) = DCG5(Q)\nDCG5(I) .\nThe average precision (AP) of a ranked list is defined as usual:\nAP =\n\u2211k\nj=1 P (j) \u2217R(j) \u2211k\nj=1 R(j)\nwith P (j) =\n\u2211j\ni=1 R(j)\nj\nwhere R(j) is the binary judgement of the relevance of jth item in the list. We set this to 1 if the grade is \u201cexcellent\u201d or better and 0 otherwise. The mean average precision (MAP) of a set of test queries is the mean AP through this set."}, {"heading": "6.3 Ranking by a Single Method", "text": "Table 3 compares the NDCG5 and MAP values of the single methods and machine learned combined methods. Also included are the results of simply taking a linear combination of the query scores of each method computed separately."}, {"heading": "Co-click Relations", "text": "The BRCCQs typically represent a drill down from the original query. It does not necessarily share any lexical part with the original query but it shares at least a clicked document with the original query. It often represents specializations but sometimes parallel moves (\u201cipod\u201d 7\u2192 \u201citune\u201d) or generalization (\u201cANA\u201d 7\u2192 \u201cairplane\u201d)."}, {"heading": "Co-topic Relations", "text": "The CTQs also represent a drill down from the original query. It necessarily shares some lexical part with the original query but it does not necessarily share any clicked document with it. As expected from higher evaluation measures, they seem to be homogeneous because they share the left substring. But the coverage is limited especially for longer queries that are already specific enough. It provides conservative recommendations but strictly limited to specialization queries."}, {"heading": "Co-session relations", "text": "The CSQs might represent a drill down from the original query but it also include topic shifts. It does not necessarily share any lexical part nor any clicked document with the original query. As have been noted, parallel move queries are characteristic of this method. For example, against the original query \u201cANA\u201d4, all of the top five recommendations are either competing traffic companies such as \u201cJAL\u201d, \u201cSkymark\u201d (the names of other airline companies), JR (railway company), or travel agent companies such as \u201cJTB\u201d and \u201cHIS\u201d. This is useful to a searcher who arranges a travel plan. In the case of the query: \u201cJR\u201d, the names of three out of six JR regional railway companies appear as well as \u201cANA\u201d."}, {"heading": "6.4 Combined Ranking", "text": "We used half of the pairs for training and the rest of the pairs for evaluation. For training, similarity measures are used as the target function to learn. After convergence is achieved, we use the model to rank the queries.\nBecause the combined ranking uses many more features other than Pcc, Pct and Pcs, the ranking is very different from a simple mixture of three basic rankings. 4All Nippon Airways or ANA offers domestic flights in Japan.\nAs shown in Table 3, the combined ranking learned by GBDT achieves the best scores. The improvements from the single methods amount to between +1.8% and +4.1% with NDCG5; all results being statistically significant according to a Wilcoxon test (p \u2264 0.01). With MAP, the conclusions are similar. In general, the combination of two methods is better than any single method and combining the three methods improves the performance further, especially in terms of MAP.\nA visual inspection of Fig. 2 where the precision-recall curves are drawn confirms these results. The combined ranking outperforms any single methods over the whole recall range. As seen in the graphs, the improvement is not trivial whereas the differences between the three single methods are small."}, {"heading": "NDCG5 and MAP.", "text": "Finally, Table 4 shows the relative importance of the features listed in Table 1. Although BCos \u2013 the cosine similarity between the bag of character bigrams representations of two queries \u2013 is the most important feature partially because of the evaluation bias mentioned in Section 4, other nine features account for more than 10% of its importance. We understand from this that the proposed feature set is very effective for this task. The BCos feature, as well as other textual features, tends to promote queries sharing lexical items with original, i.e. typically found in the CTQ sets. On the other hand, the second more important features LLR \u2013 the log likelihood ratio of observing q2 after q1 in the same session \u2013 and Next.Ent \u2013 the next query entropy of q1 \u2013\nare related to CSQs. The Freq.\u2217 features are related to the popularity of the queries while the click entropy features Ent.\u2217 are related to the click variance. This confirms our initial hypothesis that the three different methods of identifying potential query recommendations are complementary and combining them is beneficial."}, {"heading": "7. CONCLUSIONS", "text": "We use three methods of extracting recommendations from search logs to improve the quality of the suggested queries. The first method exploits the clicked document position in the ranking and selects as candidate recommendation queries existing in the logs that have a higher rank for the clicked document. The second method is based on the observation that users often refine their query by adding terms. The third method uses the query sequences in search sessions and recommends some typical topic shifts from the query.\nWe carried out experiments on a sample query log of a commercial search engine in Japan to compare the three methods. We observed that each method has its own advantages and drawbacks: the first one, based on the position of the clicked documents, is sometimes more difficult to understand at first glance, but recommendations may turn out to be more useful than those extracted from query reformulations; the second tends to be limited to specializations of the original query, which usually offer safer recommendations but less coverage; the last one is good in the case of a topic shift or mission change. The preliminary experiments conducted on the Yahoo! directory revealed a good semantic similarity between the extracted query pairs. By construction, the second method of adding a facet to a query (CTQ) rarely drifts from the original search topic. On the other hand, the first method (BRCQQ) that consists in identifying queries that would rank higher the clicked documents tend\nto surface more specific, sometimes jargon like queries. This occasionally leads to incomprehensible recommendations, at least to our understanding (although they might make sense for the users who issued them). CTQ and variations on this method are used by many commercial search engines owing to its more conservative nature but BRCCQ might be a more effective way of recommending totally new, eyeopening queries in a more exploratory fashion, despite the risk of recommending over-specific or over-generic queries. Queries extracted from user sessions (CSQ) provides more diverse recommendations such as parallel move reformulations or even topic changes if those happen frequently in the logs (e.g. searching for an image after having looked for some film star).\nIn conclusion, each recommendation method has its own merits and drawbacks, which is the reason why we combined them. Adopting semantic similarities as the target attribute, we learned to combine recommendations from the three different methods in a new ranking according to the similarity to the original query. We showed that the resulting ranking out-performs any of the individual rankings as well as their linear combinations in terms of NDCG5 and MAP.\nAs the next step of this study, we will try to select recommendations so as to maximize the facet diversity. Consequently, we need to evaluate the diversity in recommendation ranking. Evaluation of query recommendations is also an important issue in this research area and relatively less investigated than that of document search, as evaluating diversified results is problematic even for this case."}, {"heading": "8. REFERENCES", "text": "[1] I. Antonellis, H. Garcia-Molina, and C.-C. Chang.\nSimrank++: query rewriting through link analysis of the click graph. PVLDB, 1(1):408\u2013421, 2008.\n[2] R. Baeza-Yates and A. Tiberi. Extracting semantic relations from query logs. In Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 76\u201385, 2007. San Jose, CA, USA.\n[3] R. A. Baeza-Yates, C. A. Hurtado, and M. Mendoza. Improving search engines by query clustering. JASIST, 58(12):1793\u20131804, 2007.\n[4] D. Beeferman and A. Berger. Agglomerative clustering of a search engine query log. In Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 407\u2013416, 2000.\n[5] P. Boldi, F. Bonchi, C. Castillo, and S. Vigna. From \u201ddango\u201d to \u201djapanese cakes\u201d: Query reformulation models and patterns. In WI-IAT \u201909, pages 183\u2013190, 2009.\n[6] H. Cao, D. Jiang, J. Pei, Q. He, Z. Liao, E. Chen, and H. Li. Context-aware query suggestion by mining click-through and session data. In Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 875\u2013883, 2008.\n[7] N. Craswell and M. Szummer. Random walks on the click graph. In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, pages 239\u2013246, 2007.\n[8] G. Dupret and C. Liao. A model to estimate intrinsic\ndocument relevance from the clickthrough logs of a web search engine. In Proceedings of the Third ACM International Conference on Web Search and Web Data Mining, WSDM 2010, New York City, USA, pages 181\u2013190, 2010.\n[9] G. Dupret and M. Mendoza. Recommending Better Queries from Click-Through Data. In Proceedings of the 12th International Symposium on String Processing and Information Retrieval(SPIRE 2005),LNCS 3246, pages 41\u201344. Springer, 2005.\n[10] B. M. Fonseca, P. B. Golgher, B. Po\u0302ssas, B. A. Ribeiro-Neto, and N. Ziviani. Concept-based interactive query expansion. In Proceedings of the 14th ACM international conference on Information and knowledge management, pages 696\u2013703, 2005.\n[11] J. H. Friedman. Greedy function approximation: A gradient boosting machine. Annals of Statistics, 29:1189\u20131232, 2000.\n[12] D. He, A. Go\u0308ker, and D. J. Harper. Combining evidence for automatic web session identification. Information Processing & Management, 38(5):727\u2013742, 2002.\n[13] B. J. Jansen, D. L. Booth, and A. Spink. Patterns of query reformulation during web searching. JASIST, 60(7):1358\u20131371, 2009.\n[14] T. Joachims, L. Granka, B. Pan, H. Hembrooke, and G. Gay. Accurately interpreting clickthrough data as implicit feedback. In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 154\u2013161, 2005.\n[15] R. Jones, B. Rey, O. Madani, and W. Greiner. Generating query substitutions. In Proceedings of the 15th international conference on World Wide Web, pages 387\u2013396, 2006.\n[16] A. Spink, J. Bateman, and B. J. Jansen. Searching heterogeneous collections on the web: behaviour of excite users. Information Research, 4(2), 1998.\n[17] J. Teevan, S. T. Dumais, and D. J. Liebling. To personalize or not to personalize: modeling queries with variation in user intent. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR \u201908, pages 163\u2013170, New York, NY, USA, 2008. ACM.\n[18] G.-R. Xue, H.-J. Zeng, Z. Chen, Y. Yu, W.-Y. Ma, W. Xi, and W. Fan. Optimizing web search using web click-through data. In Proceedings of the thirteenth"}, {"heading": "ACM international conference on Information and", "text": "knowledge management, pages 118\u2013126, 2004. Washington, D.C., USA."}], "references": [{"title": "Simrank++: query rewriting through link analysis of the click", "author": ["I. Antonellis", "H. Garcia-Molina", "C.-C. Chang"], "venue": "graph. PVLDB,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Extracting semantic relations from query logs", "author": ["R. Baeza-Yates", "A. Tiberi"], "venue": "In Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Improving search engines by query clustering", "author": ["R.A. Baeza-Yates", "C.A. Hurtado", "M. Mendoza"], "venue": "JASIST, 58(12):1793\u20131804,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Agglomerative clustering of a search engine query log", "author": ["D. Beeferman", "A. Berger"], "venue": "In Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "From \u201ddango\u201d to \u201djapanese cakes\u201d: Query reformulation models and patterns", "author": ["P. Boldi", "F. Bonchi", "C. Castillo", "S. Vigna"], "venue": "In WI-IAT", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Context-aware query suggestion by mining click-through and session data", "author": ["H. Cao", "D. Jiang", "J. Pei", "Q. He", "Z. Liao", "E. Chen", "H. Li"], "venue": "In Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Random walks on the click graph", "author": ["N. Craswell", "M. Szummer"], "venue": "In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "A model to estimate intrinsic  document relevance from the clickthrough logs of a web search engine", "author": ["G. Dupret", "C. Liao"], "venue": "In Proceedings of the Third ACM International Conference on Web Search and Web Data Mining,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Recommending Better Queries from Click-Through Data", "author": ["G. Dupret", "M. Mendoza"], "venue": "In Proceedings of the 12th International Symposium on String Processing and Information Retrieval(SPIRE 2005),LNCS", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Concept-based interactive query expansion", "author": ["B.M. Fonseca", "P.B. Golgher", "B. P\u00f4ssas", "B.A. Ribeiro-Neto", "N. Ziviani"], "venue": "In Proceedings of the 14th ACM international conference on Information and knowledge management,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Greedy function approximation: A gradient boosting machine", "author": ["J.H. Friedman"], "venue": "Annals of Statistics,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2000}, {"title": "Combining evidence for automatic web session identification", "author": ["D. He", "A. G\u00f6ker", "D.J. Harper"], "venue": "Information Processing & Management,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2002}, {"title": "Patterns of query reformulation during web searching", "author": ["B.J. Jansen", "D.L. Booth", "A. Spink"], "venue": "JASIST, 60(7):1358\u20131371,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Accurately interpreting clickthrough data as implicit feedback", "author": ["T. Joachims", "L. Granka", "B. Pan", "H. Hembrooke", "G. Gay"], "venue": "In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Generating query substitutions", "author": ["R. Jones", "B. Rey", "O. Madani", "W. Greiner"], "venue": "In Proceedings of the 15th international conference on World Wide Web,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "Searching heterogeneous collections on the web: behaviour of excite users", "author": ["A. Spink", "J. Bateman", "B.J. Jansen"], "venue": "Information Research,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1998}, {"title": "To personalize or not to personalize: modeling queries with variation in user intent", "author": ["J. Teevan", "S.T. Dumais", "D.J. Liebling"], "venue": "In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Optimizing web search using web click-through data", "author": ["G.-R. Xue", "H.-J. Zeng", "Z. Chen", "Y. Yu", "W.-Y. Ma", "W. Xi", "W. Fan"], "venue": "In Proceedings of the thirteenth ACM international conference on Information and knowledge management,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2004}], "referenceMentions": [{"referenceID": 12, "context": "[13], queries which initiated a new session are in 31% cases followed by query reformulations of the type \u2018specialization\u2019 or \u2018specialization with reformulation\u2019.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "Boldi [5] pointed out that the typically useful recommendations are either specializations or topic shifting, which they refer to as \u201cparallel moves\u201d.", "startOffset": 6, "endOffset": 9}, {"referenceID": 4, "context": "The last method is better suited for shifting topics because it provides more diverse recommendations such as parallel move reformulations [5].", "startOffset": 139, "endOffset": 142}, {"referenceID": 13, "context": "Although correctly interpreting clicks is not straightforward [14, 8], click information is often used as an implicit feedback on URL relevance.", "startOffset": 62, "endOffset": 69}, {"referenceID": 7, "context": "Although correctly interpreting clicks is not straightforward [14, 8], click information is often used as an implicit feedback on URL relevance.", "startOffset": 62, "endOffset": 69}, {"referenceID": 3, "context": "Beeferman and Berger studied Web search query logs and clustered click-through data by iterating two steps: (a) combining the two most similar queries and (b) combining the two most similar URLs [4].", "startOffset": 195, "endOffset": 198}, {"referenceID": 2, "context": "proposed a query recommendation technique using query clustering based on the similarity of clicked URLs [3].", "startOffset": 105, "endOffset": 108}, {"referenceID": 8, "context": "Dupret and Mendoza also addressed query recommendation using click-through data but focused on document ranking [9].", "startOffset": 112, "endOffset": 115}, {"referenceID": 17, "context": "[18] used click-through data to create metadata for Web pages.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "Craswell and Szummer, who used clickthrough data for image retrieval, experimented with backward random walks [7].", "startOffset": 110, "endOffset": 113}, {"referenceID": 1, "context": "BaezaYates and Tiberi extracted semantic relations between queries on the basis of set relations of clicked URLs [2].", "startOffset": 113, "endOffset": 116}, {"referenceID": 0, "context": "proposed the Simrank++ [1] method in which query similarity is propagated through click bipartite graphs.", "startOffset": 23, "endOffset": 26}, {"referenceID": 14, "context": "extracted query substitutions from the same user sessions by identifying correlated term pairs and substituting phrases [15].", "startOffset": 120, "endOffset": 124}, {"referenceID": 15, "context": "surveyed information related to successive Web searches [16] and found that the information involves changes and shifts in search terms, search strategies, and relevance", "startOffset": 56, "endOffset": 60}, {"referenceID": 12, "context": "analyzed successive queries in large Web search query logs [13], and He et al.", "startOffset": 59, "endOffset": 63}, {"referenceID": 11, "context": "tried to detect session boundaries on the basis of search patterns and time intervals in query logs [12].", "startOffset": 100, "endOffset": 104}, {"referenceID": 9, "context": "sessions [10].", "startOffset": 9, "endOffset": 13}, {"referenceID": 4, "context": "analyzed search user sessions, classified query reformulation types [5], and derived queryflow graphs for the extracted query recommendations.", "startOffset": 68, "endOffset": 71}, {"referenceID": 5, "context": "applied click-based clustering to session-based query suggestions [6] and they claim that the context awareness helps to better understand user\u2019s search intent and to make more meaningful suggestions.", "startOffset": 66, "endOffset": 69}, {"referenceID": 8, "context": "This approach can be regarded as a special case of the session-based recommendation proposed by Dupret and Mendoza [9].", "startOffset": 115, "endOffset": 118}, {"referenceID": 4, "context": "(A more complete nomenclature of the relations extracted this way can be found in [5].", "startOffset": 82, "endOffset": 85}, {"referenceID": 1, "context": "We adopt a similarity measure between query pairs by Baeza-Yates and Tiberi [2] who evaluated semantic relations between queries connected by an edge of their click cover graph.", "startOffset": 76, "endOffset": 79}, {"referenceID": 10, "context": "We use gradient boosting decision trees (GBDT) described in [11] because of the robustness to overfitting, the scalability and the ability to handle highly non-linear problems of this method.", "startOffset": 60, "endOffset": 64}, {"referenceID": 4, "context": "We adopted the query textual features used in [5].", "startOffset": 46, "endOffset": 49}, {"referenceID": 16, "context": "[17].", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15].", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "As mentioned above, we use gradient boosting decision trees (GBDT [11]).", "startOffset": 66, "endOffset": 70}], "year": 2012, "abstractText": "The web logs of the interactions of people with a search engine show that users often reformulate their queries. Examining these reformulations shows that recommendations that precise the focus of a query are helpful, like those based on expansions of the original queries. But it also shows that queries that express some topical shift with respect to the original query can help user access more rapidly the information they need. We propose a method to identify from search engine query logs possible candidate queries that can be recommended to focus or shift a topic. This method combines various clickbased, topic-based and session based ranking strategies and uses supervised learning in order to maximize the semantic similarity between the query and the recommendations, while at the same time we diversify them. We evaluate our method using the query/click logs of a Japanese web search engine and we show that the combination of the three methods proposed is significantly better than any of them taken individually.", "creator": "LaTeX with hyperref package"}}}