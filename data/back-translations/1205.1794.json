{"id": "1205.1794", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-May-2012", "title": "A Novel Method For Speech Segmentation Based On Speakers' Characteristics", "abstract": "Language segmentation is the detection of process change points for dividing an input audio stream into regions that correspond to only one audio source or speaker at a time. An application of this system is in speaker segmentation systems. There are several methods for speaker segmentation, but most speaker segmentation systems use BIC-based segmentation methods. The main objective of this essay is to propose a new method for speaker segmentation at higher speeds than current methods - such as BIC - and acceptable accuracy. Our proposed method is based on pitch frequency of speech. The accuracy of this method is similar to the accuracy of common speaker segmentation methods. However, its calculation costs are much lower than theirs. We show that our method is about 2.4 times faster than the BIC-based method, while the average accuracy of the pitch-based method is slightly higher than the BIC-based method.", "histories": [["v1", "Tue, 8 May 2012 19:54:13 GMT  (378kb)", "http://arxiv.org/abs/1205.1794v1", "14 pages, 8 figures"]], "COMMENTS": "14 pages, 8 figures", "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["behrouz abdolali", "hossein sameti"], "accepted": false, "id": "1205.1794"}, "pdf": {"name": "1205.1794.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Behrouz Abdolali", "Hossein Sameti"], "emails": ["abdolali@ce.sharif.edu", "sameti@sharif.edu"], "sections": [{"heading": null, "text": "DOI : 10.5121/sipij.2012.3205 65\nSpeech Segmentation is the process change point detection for partitioning an input audio stream into regions each of which corresponds to only one audio source or one speaker. One application of this system is in Speaker Diarization systems. There are several methods for speaker segmentation; however, most of the Speaker Diarization Systems use BIC-based Segmentation methods. The main goal of this paper is to propose a new method for speaker segmentation with higher speed than the current methods - e.g. BIC - and acceptable accuracy. Our proposed method is based on the pitch frequency of the speech. The accuracy of this method is similar to the accuracy of common speaker segmentation methods. However, its computation cost is much less than theirs. We show that our method is about 2.4 times faster than the BICbased method, while the average accuracy of pitch-based method is slightly higher than that of the BICbased method.\nKEYWORDS\nSpeaker Diarization, Speech Segmentation, Pitch-based Speech Segmentation"}, {"heading": "1. INTRODUCTION", "text": "The process of speaker change detection from one speaker to another is an important task in many speech processing applications. This task is done before audio indexing, speaker identification, automatic transcription, information extraction, speech summarization and retrieval [1][2][3]. An audio stream can be segmented into various homogeneous parts by recognizing the specific speech characteristics of individual speakers. This process is commonly known as speaker change detection or speaker segmentation. In recent years, there are three major categories of audio segmentation techniques: metric-based, model-based and hybrid methods. Each one has its advantages and disadvantages which will be discussed in the next section.\nThe most common speaker segmentation methods are those metric-based ones which are used Bayesian Information Criterion (BIC). Since these methods suffer from a great amount of computations, they are very time consuming; however, these methods are highly accurate. Achieving a method which has acceptable accuracy along with high computation speed is very desirable and useful for real time systems. In this paper we will discuss about a proposed method for speech segmentation that doesn\u2019t need previous information about speakers and also hasn\u2019t heavy computation. In other word, we want to solve the problem of low speed of metric-based segmentation methods. For solving this problem we have proposed to use of speaker\u2019s pitch frequency information. In this method the change points are detected according to speakers\u2019 pitch\nfrequency function. Of course using this function has some problems such as increasing error, but by using some techniques we decrease the errors."}, {"heading": "2. A SURVEY ON SPEAKER SEGMENTATION METHODS", "text": "Various speaker segmentation algorithms have been proposed. These algorithms can be categorized into the following categories: metric-based, model-based and hybrid segmentation algorithms.\nAnother approach called decoder-based has also proposed. It is assumed that the sentences uttered by different speakers in a conversation are delimited by pauses [4]. As a consequence the segmentation relies on the accuracy of an inter speaker silence detector which usually works by measuring the energy or zero crossing rate of each segment and comparing it to a predefined or adaptively estimated threshold. The main drawback of this approach is no direct connection exists between a detected silence and an actual speaker change. Because of this assumption, this method isn\u2019t used for actual meeting.\nIn metric-based methods, first an acoustic distance criterion has been defined and then two adjacent windows are shifted along the audio stream. Depending on the application the analysis window may overlap or not. By measuring the distance between these two windows the similarity between these segments is evaluated and a distance curve is formed. This distance curve was often low-pass filtered and the locations of peaks were chosen to be acoustic changing points by heuristic thresholds. Most of the distance measure criterions come from the statistical modeling framework. The feature vectors in each of the two adjacent windows are assumed to follow some probability density(usually Gaussian) and the distance is represented by the dissimilarity of these two densities, e.g., the Kullback-Leibler distance(KL,KL2)[5], generalized likelihood ratio(GLR)[6] and Bayesian Information Criterion(BIC) [7][8][9].\nThe metric-based methods have the advantage of not requiring any prior knowledge on the number of speakers, their identities, or signal characteristics; but they have some disadvantages: (1) it is difficult to decide an appropriate threshold. (2)Each acoustic changing point is detected only by its neighboring acoustic information. (3) To deal with homogenous segments of various lengths, the length of window is usually short (typically 2 seconds), so the feature vectors could be insufficient to obtain robust distance statistics.\nIn the model based approach, a set of models is derived and trained for different speaker classes from a training corpus. It assumes that a speaker change is likely to occur at the time indexes where the model\u2019s identification decision changes from one speaker to another. As a result, prior knowledge is a prerequisite to initialize the speaker models. The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].\nHybrid based methods combine metric and model based techniques [18]. A set of speaker models are created by presegmenting the input audio signal using metric based approaches. Then the model based segmentation is applied to yield a more refined segmentation. In [19], HMMs are combined with BIC. Another hybrid system is introduced in [20] where two systems are combined namely LIA system, which is based on HMMs and the CLIPS system, which performs BIC based speaker segmentation followed by hierarchical clustering."}, {"heading": "2.1. Speaker Segmentation based on BIC measure", "text": "Since BIC-based methods are the most common segmentation methods used today, we focus on these methods in detail. BIC is a criterion for choosing a model for a group of data which is\nproposed by Schwarz[21]. Suppose we have a group of data (X) and a Model for describing these data (M). The BIC criterion for this model is shown in Equation 1.\n(1) = log | \u2212 #\n2 log\nIn this equation, P(X|M) is the likelihood value of data X to model M. #M represents the number of free parameters in Model M. N represents the number of samples in data X. In the other word, BIC measures the likelihood of the model and data and scores the model[22]. In the above equation, \u03bb is the penalty factor. If \u03bb is set to zero, BIC changes to GLR[23]. To achieve the expected performance for a specific corpus, we could adjust \u03bb value[24]. As described in [21], maximizing BIC results in maximizing the expected value of likelihood of model and data. Therefore, BIC could be used to select the best model of a group of data[21,22].\nSuppose X= xi\u2208 R d , i = 1,2,...,N is a sequence of feature vectors of d dimensions which are extracted from a speech frame. In such applications, usually MFCC feature vectors are used. BIC criteria don\u2019t have any pre knowledge about the type of feature vectors. Therefore, this criterion could be used even when other feature vectors are used. We suppose that in a frame there are at most two speakers (one speaker boundary). Therefore, the problem of checking if a single speaker change point exists in the frame, could be transformed to a model selection problem[24]. To do this, we consider two adjacent windows (X and Y) around hypothetical time instance (b). Our objective is to decide if a speaker change occurs in this instance time or not.[18].\n\u2022 Model M1 supposes that all samples in X are independent and evenly distributed by a multivariate Gaussian process.\n(2) \u2236 = , , \u2026 , ~ , \u2211\n\u2022 Model M2 suppose that X is created by two multivariate Gaussian processes. One from the beginning of the frame to time b, and one from time b to the end of the frame.\n(3) : = + $\n(4) = , , \u2026 , % ~ & , \u2211&\n(5) $ = %' , %' , \u2026 , ~ ( , \u2211(\nThese two hypotheses are shown in Figure 1.\nThe difference between BIC scores of the models is expresses as \u2206 as shown in Equation 6.\n\u2206 *+, ,- = 2, ) = ./0 1 | 23, 4256 + ./0 1$| 3\n= n2 log8\u03a3:58 n&2 log8\u03a3&58 n(2 In Equation 6, \u0647\u06a94 5, 4 5, 4; are estimations of covariance matrices of corresponding data with maximum correctness. Operator | . | is determinant operator and feature vector. In this equation, \u03bb GLR[23]. If \u2206 = BIC(M2) \u2013 BIC(M1) distributions (M2) is more than that of describing data by a single Gaussian distribution (M1). Therefore, data is not uniform and there is a speaker change point.\nWe should notice that \u2206BIC is used to detect only a single acoustic change point in the speech stream. As a result, it is necessary to use other algorithms to detect more change points. For this\npurpose, sequential detecting algorithms function of change point (b). If the number of feature vectors in X or n equal to n-b, \u2206 will be as shown in Equation 7. \u2206 %*+, ,- = B2 log8\u03a3 58 C 2 log Based on \u2206 value, segmentation of speech stream into two parts is correct when 0. Positive value means Model M2 best describe the signal and change point of b exists. In the following sections, some common algorithms"}, {"heading": "2.1.1. Increasingsize window method for calculating", "text": "This method is used to detect multiple change points in a stream. As shown in Figure 2, we consider an initial size for the window in which N increases its size by Ng ,until a change point is found based on BIC criterion. A higher band for the window size, Nmax, is also determined. If a change point is detected before reaching the window size to Nmax, the point is marked and the process begins from this point with initial window size. Otherwise, after reaching N repeats[23]. It is notable that, as the is needed. Therefore, this method suffers lower performance and requires more processing power.\n( 1, ) E , 4E56 ./0 1 | 3, 4 56 12 FG + 1 2 G(G + 1)H log8\u03a3(58 12 \u03bb Fd + 1 2 d(d + 1)H log n\nd is the dimension of cepstral\nis called penalty factor, when it is set to zero, BIC changes to\nK 0, it means that the score of describing data by two Gaussian\nwere proposed in [23]. We can rewrite\nx is equal to b and n\n8\u03a3258 B C2 log8\u03a3E58 1 2 FG + 1 2 G(G + 1)H log B\nfor finding change points are explained.\n\u2206LMN inifeature vectors exist. This window continually\nmax, the window is shifted by Ns samples and the process time progresses and window size increases more processing\n[24\n./0 B\n(6)\n\u2206 as a y is\n(7)\n\u2206 (C) K\n]."}, {"heading": "2.1.2. Fixed-Size sliding window method for calculating \u2206LMN", "text": "In this method, one window with fixed-size is considered and by sliding it across the steam, \u2206 is calculated. Window size depends on the length of the stream. Setting the window size and \u03bb parameters to optimum values results in higher performance and accuracy. It is obvious that this method needs less processing power. Nevertheless, its accuracy is lower than previous one. According to experiment, for short streams about some of minutes, the window size of 1 second is well[23].\nIn this paper, we implemented the first method to compare the best accuracy achieved by BICbased methods with our proposed method."}, {"heading": "3. THEORETICAL TOPICS ABOUT PITCH FREQUENCY", "text": "In this section, after a short looking at pitch frequency characteristics, we review some important pitch extraction methods."}, {"heading": "3.1. Pitch Frequency and Its Characteristics", "text": "Pitch frequency is the fundamental harmonic of the speech signal. In the other word, it is the fundamental frequency of the human vocal cords\u2019 vibration. More like the sine wave is the wave form of the signal, more clearer the sense of frequency and less clearer the sense of pitch.[26] Likewise, more harmonic to each other are frequency components, more clearly the sense of pitch and less clearer the sense of frequency[27,28,29]"}, {"heading": "3.2. Pitch frequency extraction methods", "text": "There are several methods used for the estimation of fundamental frequency of f0. Nonetheless, it is difficult to propose a method which estimates f0 well, without considering the content of the signal. Therefore, in the environment in which both music and speech signals exist, pitch estimators should be accurate in both fields. The difficulty of detecting f0 in a waveform depends on the wave form. It means that if the waveform contains less high harmonics in the frequency spectrum, or the power of higher harmonics is low, f0 will be simpler to detect[30].\nPitch frequency determination algorithms called PDA, are of a great importance in many speech processing algorithms. In the following sections, pitch determination methods based on autocorrelation function, cepstrum method, linear prediction coding (LPD) method, and average magnitude difference (AMDF) function will be discussed."}, {"heading": "3.2.1. Pitch Detection using autocorrelation function (ACF)", "text": "Our perception of pitch frequency is strongly related to our perception of waveform periodicity in the time domain. The method which can determine the fundamental frequency of a signal based on its waveform is the autocorrelation method[31].autocorrelation function of a signal s[n], is shown in Equation 8 in which \u03c4 is the delay or time shift. Calculating this function and detecting its maximal points, we can estimate pitch frequency of signal s[n]."}, {"heading": "3.2.2. Pitch Detection using cepstral method", "text": "Cepstral analysis provides a method for the pitch estimation. Suppose that a sequence of speech samples is the result of applying convolution function on the sequence of glottal excitation e[n]\n(8) O(P) = Q R(B). T\nUVW R(B + P)\nand vocal tract\u2019s discrete impulse response \u03b8[n]. In the frequency domain, convolution operator changes to multiplication operator. Using the characteristics of Algorithm function (log(A.B)=log(A)+log(B)), multiplication operator could be changed to addition operator. Finally, the real cepstrum of a signal expresses by the formula s[n]=e[n]*\u03b8[n], is c[n] which is shown in Equation 9.\nIn the above formula S(\u03c9) is:\n(10) X(Y) = Q R[B]\\T]U^ _\nUVT_\nTherefore, cepstrum is the result of applying Fourier transform on the logarithm of amplitude of the signal spectrum. If the logarithm of amplitude of the signal spectrum contains several harmonics which are placed at regular distance from each other, Fourier transform of the spectrum includes a peak which corresponds to the distance between harmonics. This peak, in fact, is the fundamental frequency or pitch of the signal."}, {"heading": "3.2.3. Pitch Detection using average magnitude difference function (AMDF)", "text": "AMDF concept is very close to ACF concept, except that in this function amplitude difference between the frame and its delayed version is estimated instead of estimating likeness between them. AMDF calculation is shown in Equation 11. In this equation, \u03c4 is the time range in terms of speech samples. The value of \u03c4, for which AMDF(\u03c4) in a specific range is minimum, is chosen as the period of the pitch.\nIn the other word, delayed version of the frame is moved n times and the absolute value of the summation of difference in overlapping sections is calculated to produce n AMDF value. Pitch value is the result of division of sampling frequency by speech sample corresponds to the first local minimum in AMDF function."}, {"heading": "4. SPEAKER SEGMENTATION USING PROPOSED METHOD", "text": "Distance-based speaker segmentation methods, such as BIC method, use cepstral features like Mel-Frequency Cepstral Coefficient (MFCC). However, there are other feature vectors which can be used for this purpose. In addition, prosodic features like pitch frequency can be used to facilitate distinguish between voice and silence. Pitch frequency changes diagram is a well-suited means for speaker change detection[32]. There are three reasons to use pitch frequency for speaker change detection:\n1- Every speaker has its own pitch frequency which differs from others.\n2- When the speaker changes, pitch frequency diagram has rapid changes.\n(9) c[n] = 12\u03c0 b log |S(\u03c9)|efghd\u03c9 i\nTi\n(11) j kl(P) = Q|X(m) X(m + P)| UT\nnVW\n3- For speech segments less than one second, other methods such as BIC-based methods which utilize MFCC features, suffer lack of speaker change detection accuracy. Since,\nthere is not enough information in such a short segments to calculate meaningful MFCC vectors.\nTo make it possible to use pitch frequency information for speaker segmentation, the preliminary stage is to extract pitch frequency using one of the above mentioned methods. We choose AMDF method because of its calculation speed.\nAfter calculation of pitch frequency value for each individual speech frame, we should use this information for speaker change detection. Since rapid changes in the pitch frequency diagram can be used to indicate speaker change, we use this indication afterwards. Suppose to have divide speech stream to N windows and extract pitch frequency for each window independently. To analyze pitch frequency changes, we use derivation function which is shown in Equation 12.\n(12) kmoo(+) = | mpq\u210e(B + 1) mpq\u210e(B)|\nThen we should determine a threshold value by which we evaluate pitch frequency changes. If derivative function of pitch frequency at one point is above this defined threshold, we consider that point as speaker change point. We define this threshold as 0.7 of maximum difference between higher and lower pitch frequency in the stream. After extracting speaker change points, we could calculate beginning and end of speech segments. This method has very high speed. Nonetheless, its detection accuracy compared with BIC-based methods is less. In the following section accuracy improvement method will be explained."}, {"heading": "5. ACCURACY IMPROVEMENT OF PROPOSED METHOD", "text": "Detailed looking at pitch frequency changes diagram, we noticed that its variation is very sharp. Even during the speech of one speaker, it is be possible to have rapid pitch frequency changes. In these cases, False Alarm (FA) rate error increases. This is the result of considering every point above the threshold as speaker change point.\nAnother problem with this method is the possibility of speaker change while pitch frequency changes is not very quick to be above the predefined threshold. Therefore, we may miss these points of speaker changes and Miss Detection (MD) rate error may be increased. To solve this problem one way may be to choose the threshold value lower to place below the missed points. Obviously, this is not an efficient way, because using the lower threshold, many other points which are not true speaker change points will be placed above the threshold and incorrectly will be reported as change points. As a result, MD rate error decreases at the expense of increase in FA rate error. Using this method decrease the accuracy of speaker change detection method.\nTo cope with this problem, we should apply a function on pitch frequency change function which increase small changes and preserve large changes. Gamma correction function best suited for this purpose.\n(13) stuut1o(+)6 = . o(+)v We apply this function on pitch frequency change diagram. Considering Figure 3, and above mentioned problem, it is clear that for our application, we should use \u03b3<1 which based on our experiments, its best value is 0.3.\nApplying this function, MD rate error decreases. However, since there were false rapid changes before applying gamma correction function, the problem reduce FA rate error, we could benefit the idea used in BIC segmentation. It means that we consider all points above the threshold as speaker change points and investigate correctness of change detection using a small applying this method, results in egregious improvement in detection accuracy. In Figure 4, flowchart of proposed change detection algorithm is shown."}, {"heading": "6. THE EVALUATION MEASURES FOR", "text": "It is obvious that for each system, standard evaluation method should be introduced. It is also necessary for segmentation systems. In this section we discuss about these measures and standard evaluation methods for segmentation systems. Results of this paper are based on these methods.\n[33]\nof high FA rate error is remained. To\nBIC window of length 0.1s.experimental results show that\nRPSS method\nSEGMENTATION METHODS\nOperation of the system could be analyzed for recorded sessions. However, valid results are those which are based on sessions in a speech corpus. There are several corpuses some of the important ones are NIST, AMI and TMIT.\nFor evaluation of segmentation systems, some measures are used which are the comparison between detected change points and real change points in the corpus under investigation. The most important measures used, are %FD and %FR which are calculated as shown in Equations 14,15.\n(14) %lk = # ot.R\\_G\\p\\qpm/BRp/pt._tu/yBp_/o_G\\p\\qpm/BR\n(15) %lO = # umRR\\G_G\\p\\qpm/BRp/pt._tu/yBp_/o_pzy\\_q\u210etB0\\_ /mBpR false_detections: number of points which are not real change points in the reference corpus; but, are detected by the system as change points. These points are called False Alarm (FA).\ntotal_amount_of_detections: total number of points detected by the system as change points.\nmissed_detections: number of points which are real change points in the reference corpus; But, are not detected by the system as change points. These points are called Missed Detection (MD).\ntotal_amount_of_true_change_points: total number of points correctly detected by the system as change points.\nTo determine the accuracy of segmentation method, F measure is defined as shown in Equation 16.\n(16) l = 2 \u2217 (1 lk) \u2217 (1 lO)2 lk lO"}, {"heading": "7. EXPERIMENTAL RESULTS", "text": "In this section using diagrams resulted from changing important parameters involved in the calculations of improved proposed method, we want to investigate the effect of these parameters on the accuracy and performance of the proposed method. In this paper we apply our method on four of AMI sessions. These sessions are selected randomly. The names of the sessions are included in corresponding tables. Diagrams show the average values achieved in four experiments.\nThreshold coefficient is a parameter which determines the acceptable value of pitch changes compared with global maximum. This means that if this factor is 0.7, changes above the 0.7 of global maximum are considered as speaker change points. It is important to consider the effect of changes in this parameter on the accuracy and performance of the proposed method. Higher value\nof this parameter, results in less FA and more MD and vice versa. Experimental results show that the value of 0.75 is well suited for our purpose.\nBased on the diagrams, we understand that increase in the value of \u03b3 for gamma correction, has a dramatic effect on the accuracy of the method. The best value for \u03b3 is 0.3 based on the results.\nTable 1 shows the value of parameters involved in the accuracy and performance of the proposed method for each AMI session to achieve the best accuracy.\nAfter examining all parameters, we achieve the optimum point for the accuracy and performance. Now we should compare our method with implemented BIC-based method. Table 2 summarizes results of two methods in their optimum point in terms of accuracy. Based on data in Table 2, we could conclude that segmentation using proposed method which is based on changes in the pitch frequency, has the advantage of improving the performance by 2.4 times and increasing the accuracy by 1% ."}, {"heading": "8. CONCLUSION", "text": "In this paper a rapid and accurate method of speaker segmentation for speaker diarization applications is proposed. This method is based on pitch frequency changes and is better than BICbased method in terms of run time. Also its disadvantage of lower accuracy is amended using innovative techniques namely Gamma correction function and BIC-based double checking of candidate points. Taking advantage of the novel techniques, we achieve a performance of 2.4 times faster than the BIC-based methods while benefiting the same accuracy."}], "references": [{"title": "speaker tracking system based on speaker turn detection for NIST evaluation", "author": ["J.F.", "P. Delacourt", "C. Fredouille", "T. Merlin", "Wellekens", "C. Bonastre"], "venue": ", Istanbul, 2000, pp. 1177\u20131180.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2000}, {"title": "Speaker tracking in broadcast audio material in the frame work of the THISL project", "author": ["L.", "Boite", "J.M. Couvreur"], "venue": ", 1999, pp. 84-89.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1999}, {"title": "Speaker change detection and tracking in real time news broadcasting analysis", "author": ["L.", "Zhang", "H.J. Lu"], "venue": ", 2002, pp. 602-610.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "Speaker indexing for news articles debates and drama in broadcasted TV programs", "author": ["Y. Ariki M. Nishida"], "venue": "Proceeding of the Speech Recognition Workshop, 1997, pp. 67\u201372.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1997}, {"title": "Speaker tracking in broadcast audio material in the frame work of the THISL project", "author": ["J.M. Boite L. Couvreur"], "venue": "Proceeding of the Workshop on accessing information in spoken audio(ESCA- ETRW99), 1999, pp. 84-89.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1999}, {"title": "Automatic audio segmentation using the Generalized Likelihood Ratio", "author": ["D. Wang", "R. Vogt", "M. Mason", "S. Sridharan"], "venue": ", Gold Coast, pp. 1-5.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 0}, {"title": "Speaker, environment and channel change detection and clustering via the Bayesian Information Criterion", "author": ["P.Gopalakrishnan. S. Chen"], "venue": ", 1998.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1998}, {"title": "Improved speaker segmentation and segments clustering using the Bayesian Information Criterion", "author": ["R. Gopinath A. Tritschler"], "venue": ", 1999.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1999}, {"title": "Unsupervised audio stream segmentation and clustering via the Bayesian Information Criterion", "author": ["John H.L. Hansen B.W. Zhou"], "venue": ", 2000.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2000}, {"title": "Hybrid speaker based segmentation system using model level clustering", "author": ["D. Elter", "T. Sikora H. Kim"], "venue": "pp. 745\u2013748, 2005.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Automatic segmentation of speech recorded in unknown noisy channel characteristics", "author": ["J.H.L. Hansen B.L. Pellom"], "venue": "vol. 25, no. 1-3, pp. 97\u2013116.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 0}, {"title": "speech/music segmentation using entropy and dynamism features in a HMM classification framework", "author": ["I. McCowan", "H. Bourland. J. Ajmera"], "venue": "vol. 40, no. 3, pp. 351\u2013363, 2003.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Speaker change detection and tracking in real time news broadcasting analysis", "author": ["H.J. Zhang L. Lu"], "venue": ", 2002, pp. 602\u2013610.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2002}, {"title": "the LIMSI broadcast news transcription system", "author": ["L. Lamel", "G. Adda J. Gauvain"], "venue": "vol. 37, pp. 89\u2013108, 2002.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2002}, {"title": "Speech discrimination based on multiscale spectro-temporal modulations", "author": ["S. Shamma", "M. Slaney S. Mesgarani"], "venue": ", 2004, pp. 601\u2013604.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "Evaluation of classification techniques for audio indexing", "author": ["J. Pinquier", "R. Ande-Obrecht J.A. Arias"], "venue": ", 2005.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Unsupervised speaker change detection using SVM misclassification rate", "author": ["J. Wang", "J. Wang", "H. Sung P. Lin"], "venue": "vol. 56.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 0}, {"title": "Speaker segmentation and clustering", "author": ["V. Moschou", "C. Kotropoulas M. Kotti"], "venue": "Signal processing, vol. 88, pp. 091\u20131124, 2007.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Hybrid Speaker based segmentation system using model level clustering", "author": ["D. Elter", "T. Sikora H. Kim"], "venue": ", 2005, pp. 745\u2013748.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2005}, {"title": "Step by step and integrated approaches in broadcast news speaker diarization", "author": ["D. Moraru", "C. Fredouille", "J.F. Bonastre", "L.Besacier S. Meignier"], "venue": "vol. 20, pp. 303-330, 2006.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2006}, {"title": "Estimating the dimension of a model", "author": ["G. Schwarz"], "venue": "The Annals of Statistics, vol. 6, no. 2, pp. 461- 464, Mar. 1978.  Signal & Image Processing : An International Journal (SIPIJ) Vol.3, No.2, April 2012 78", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1978}, {"title": "Speaker Diarization in Meetings Domain", "author": ["Nguyen Trung Hieu"], "venue": "School of Computer Engineering, Nanyang Technological University, Proposal for admission to the Degree of Doctor of Philosophy Sept. 2009.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "BIC-Based Speaker Segmentation Using Divide-and-Conquer Strategies With Application to Speaker Diarization", "author": ["Shih-Sian Cheng", "Hsin-Min Wang", "Hsin-Chia Fu"], "venue": "IEEE Transaction on Audio, Speech, and Language Processing, vol. 18, no. 1, pp. 141 \u2013 157, Jan. 2010.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "BIC-based audio segmentation by divide-andconquer", "author": ["Shih-Sian Cheng", "Hsin-Min Wang", "Hsin-Chia Fu"], "venue": "Acoustics, Speech and Signal Processing, 2008. ICASSP 2008. IEEE International Conference on, Las Vegas, NV, Apr. 2008, pp. 4841 - 4844.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}, {"title": "DISTBIC:a speaker-based segmentation for audio data indexing", "author": ["C.J.Wellekens P.Delacourt"], "venue": "Elsevier Jornal on Speech Communication, vol. 32, no. 1-2, pp. 111-126, Sept. 2000.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2000}, {"title": "Handbook for Acoustic Ecology, 2nd ed", "author": ["Barry Truax"], "venue": "Vancouver: A.R.C. Publication,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1999}, {"title": "Auditory Scene Analysis", "author": ["Albert Bregman"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1990}, {"title": "Hearing: Handbook of Perception and Cognition, 2nd, Ed", "author": ["B.C.M. Moore"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1995}, {"title": "Pitch Extraction and Fundamental Frequency: History and Current Techniques", "author": ["David Gerhard"], "venue": "Department of Computer Science, Technical Report TR-CS 2003-06, Nov. 2003.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2003}, {"title": "A Pitch-Based Rapid Speech Segmentation for Speaker Indexing", "author": ["Y. Yang", "M. Yang"], "venue": "IEEE International Symposium on Multimedia (ISM'05), Irvine, California, 2005.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2005}, {"title": "C.Gonzalez, Digital Image Processing.", "author": ["Richard E.Woods", "Rafael"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "This task is done before audio indexing, speaker identification, automatic transcription, information extraction, speech summarization and retrieval [1][2][3].", "startOffset": 149, "endOffset": 152}, {"referenceID": 1, "context": "This task is done before audio indexing, speaker identification, automatic transcription, information extraction, speech summarization and retrieval [1][2][3].", "startOffset": 152, "endOffset": 155}, {"referenceID": 2, "context": "This task is done before audio indexing, speaker identification, automatic transcription, information extraction, speech summarization and retrieval [1][2][3].", "startOffset": 155, "endOffset": 158}, {"referenceID": 3, "context": "It is assumed that the sentences uttered by different speakers in a conversation are delimited by pauses [4].", "startOffset": 105, "endOffset": 108}, {"referenceID": 4, "context": ", the Kullback-Leibler distance(KL,KL2)[5], generalized likelihood ratio(GLR)[6] and Bayesian Information Criterion(BIC) [7][8][9].", "startOffset": 39, "endOffset": 42}, {"referenceID": 5, "context": ", the Kullback-Leibler distance(KL,KL2)[5], generalized likelihood ratio(GLR)[6] and Bayesian Information Criterion(BIC) [7][8][9].", "startOffset": 77, "endOffset": 80}, {"referenceID": 6, "context": ", the Kullback-Leibler distance(KL,KL2)[5], generalized likelihood ratio(GLR)[6] and Bayesian Information Criterion(BIC) [7][8][9].", "startOffset": 121, "endOffset": 124}, {"referenceID": 7, "context": ", the Kullback-Leibler distance(KL,KL2)[5], generalized likelihood ratio(GLR)[6] and Bayesian Information Criterion(BIC) [7][8][9].", "startOffset": 124, "endOffset": 127}, {"referenceID": 8, "context": ", the Kullback-Leibler distance(KL,KL2)[5], generalized likelihood ratio(GLR)[6] and Bayesian Information Criterion(BIC) [7][8][9].", "startOffset": 127, "endOffset": 130}, {"referenceID": 9, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 66, "endOffset": 70}, {"referenceID": 10, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 71, "endOffset": 75}, {"referenceID": 11, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 77, "endOffset": 81}, {"referenceID": 12, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 113, "endOffset": 117}, {"referenceID": 13, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 119, "endOffset": 123}, {"referenceID": 14, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 157, "endOffset": 161}, {"referenceID": 15, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 163, "endOffset": 167}, {"referenceID": 16, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 169, "endOffset": 173}, {"referenceID": 17, "context": "Hybrid based methods combine metric and model based techniques [18].", "startOffset": 63, "endOffset": 67}, {"referenceID": 18, "context": "In [19], HMMs are combined with BIC.", "startOffset": 3, "endOffset": 7}, {"referenceID": 19, "context": "Another hybrid system is introduced in [20] where two systems are combined namely LIA system, which is based on HMMs and the CLIPS system, which performs BIC based speaker segmentation followed by hierarchical clustering.", "startOffset": 39, "endOffset": 43}, {"referenceID": 20, "context": "67 proposed by Schwarz[21].", "startOffset": 22, "endOffset": 26}, {"referenceID": 21, "context": "In the other word, BIC measures the likelihood of the model and data and scores the model[22].", "startOffset": 89, "endOffset": 93}, {"referenceID": 22, "context": "If \u03bb is set to zero, BIC changes to GLR[23].", "startOffset": 39, "endOffset": 43}, {"referenceID": 23, "context": "To achieve the expected performance for a specific corpus, we could adjust \u03bb value[24].", "startOffset": 82, "endOffset": 86}, {"referenceID": 20, "context": "As described in [21], maximizing BIC results in maximizing the expected value of likelihood of model and data.", "startOffset": 16, "endOffset": 20}, {"referenceID": 20, "context": "Therefore, BIC could be used to select the best model of a group of data[21,22].", "startOffset": 72, "endOffset": 79}, {"referenceID": 21, "context": "Therefore, BIC could be used to select the best model of a group of data[21,22].", "startOffset": 72, "endOffset": 79}, {"referenceID": 23, "context": "Therefore, the problem of checking if a single speaker change point exists in the frame, could be transformed to a model selection problem[24].", "startOffset": 138, "endOffset": 142}, {"referenceID": 17, "context": "[18].", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "Hypothetic models for segmentation of one speech frame[25].", "startOffset": 54, "endOffset": 58}, {"referenceID": 22, "context": "In this equation, \u03bb GLR[23].", "startOffset": 23, "endOffset": 27}, {"referenceID": 22, "context": "Otherwise, after reaching N repeats[23].", "startOffset": 35, "endOffset": 39}, {"referenceID": 22, "context": "were proposed in [23].", "startOffset": 17, "endOffset": 21}, {"referenceID": 22, "context": "According to experiment, for short streams about some of minutes, the window size of 1 second is well[23].", "startOffset": 101, "endOffset": 105}, {"referenceID": 25, "context": "[26] Likewise, more harmonic to each other are frequency components, more clearly the sense of pitch and less clearer the sense of frequency[27,28,29]", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[26] Likewise, more harmonic to each other are frequency components, more clearly the sense of pitch and less clearer the sense of frequency[27,28,29]", "startOffset": 140, "endOffset": 150}, {"referenceID": 27, "context": "[26] Likewise, more harmonic to each other are frequency components, more clearly the sense of pitch and less clearer the sense of frequency[27,28,29]", "startOffset": 140, "endOffset": 150}, {"referenceID": 28, "context": "It means that if the waveform contains less high harmonics in the frequency spectrum, or the power of higher harmonics is low, f0 will be simpler to detect[30].", "startOffset": 155, "endOffset": 159}, {"referenceID": 29, "context": "Pitch frequency changes diagram is a well-suited means for speaker change detection[32].", "startOffset": 83, "endOffset": 87}, {"referenceID": 30, "context": "[33]", "startOffset": 0, "endOffset": 4}], "year": 2012, "abstractText": "Speech Segmentation is the process change point detection for partitioning an input audio stream into regions each of which corresponds to only one audio source or one speaker. One application of this system is in Speaker Diarization systems. There are several methods for speaker segmentation; however, most of the Speaker Diarization Systems use BIC-based Segmentation methods. The main goal of this paper is to propose a new method for speaker segmentation with higher speed than the current methods e.g. BIC and acceptable accuracy. Our proposed method is based on the pitch frequency of the speech. The accuracy of this method is similar to the accuracy of common speaker segmentation methods. However, its computation cost is much less than theirs. We show that our method is about 2.4 times faster than the BICbased method, while the average accuracy of pitch-based method is slightly higher than that of the BICbased method.", "creator": "PScript5.dll Version 5.2.2"}}}