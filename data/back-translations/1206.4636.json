{"id": "1206.4636", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Modeling Latent Variable Uncertainty for Loss-based Learning", "abstract": "We look at the problem of parameter estimation with poorly monitored data sets, where a training sample consists of the input and a partially specified annotation, which we call output; the missing information in the annotation is modeled using latent variables; previous methods overload a single distribution with two different tasks: (i) modeling uncertainty in the latent variables during the training; and (ii) accurate predictions for the output and latent variables during the test. We propose a novel framework that separates the requirements of the two tasks by two distributions: (i) a conditional distribution to model uncertainty in the latent variables for a particular input-output pair; and (ii) a delta distribution to predict the output and latent variables for a given input. During learning, we foster agreement between the two distributions by minimizing a loss-based data coefficient.", "histories": [["v1", "Mon, 18 Jun 2012 15:15:13 GMT  (185kb)", "http://arxiv.org/abs/1206.4636v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CV", "authors": ["m pawan kumar", "benjamin packer", "daphne koller"], "accepted": true, "id": "1206.4636"}, "pdf": {"name": "1206.4636.pdf", "metadata": {"source": "CRF", "title": "Modeling Latent Variable Uncertainty for Loss-based Learning", "authors": ["M. Pawan Kumar", "Ben Packer"], "emails": ["pawan.kumar@ecp.fr", "bpacker@cs.stanford.edu", "koller@cs.stanford.edu"], "sections": [{"heading": "1. Introduction", "text": "Latent variable models (lvms) provide an elegant formulation for learning with weakly supervised datasets.\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nFor example, in computer vision, we may wish to learn a model for detecting an object such as \u2018deer\u2019 from images where the location of the deer is unknown, and is therefore treated as a latent variable. In computational medicine, we may wish to diagnose a patient based on the observed symptoms as well as other unknown factors, such as the family\u2019s medical history, which can be represented using latent variables.\nTypically, an lvm employs a single distribution over three types of variables: (i) the observed variables, or input, whose values are known during both training and testing; (ii) the unobserved variables, or output, whose values are known only during training; and (iii) the unknown latent variables. In this setting, a natural framework would be to model the uncertainty in the value of the latent variables and learn an lvm by marginalizing them out (for example, in the case of the expectation-maximization, or em, algorithm). However, such an approach is unsuited for applications that require an accurate prediction of the latent variables during test time. For example, in the above deer detection application, we would like to infer not only whether an image contains a deer, but also the exact location of the deer. Alternately, we can use a delta distribution that provides a pointwise estimate of the output and the latent variables (for example, in the case of the latent support vector machines, or lsvm, framework). However, discarding the uncertainty in latent variables can make such an approach prone to error due to noise (for example, background clutter that can be confused with a deer in feature space).\nThe above argument illustrates the deficiency of using a single joint distribution over the output and the latent variables to address two separate tasks: (i) modeling the uncertainty over latent variables during training; and (ii) making accurate predictions during testing. We address this deficiency by proposing a novel framework that consists of two distributions: (i) a conditional distribution to model the uncertainty of\nthe latent variables for a given input-output pair; and (ii) a delta distribution to predict the output and the latent variables for a given input. In order to learn the distributions from a training dataset, we build on the intuition that they should agree with each other, that is, (i) the output predicted by the delta distribution should match the ground-truth output; and (ii) the latent variables predicted by the delta distribution should have a high probability according to the conditional distribution. Due to the limited representational power of any model we may not be able to achieve complete agreement (that is, all outputs are predicted correctly, and all predicted latent variables have probability 1). In order to make the two distributions as similar as possible, we minimize a regularized upper bound on a loss-based dissimilarity measure (Rao, 1982) between the distributions.\nUnlike previous loss-based learning frameworks for lvms, such as lsvm, we consider a general loss function that not only depends on the output but also the latent variables. Such a loss function is essential when solving problems that require the accurate prediction of latent variables (for example, the aforementioned object detection problem). By not restricting the form of the loss function, our framework greatly enhances the applicability of loss-based learning with latent variables. In fact, our framework can be viewed as a strict generalization of lsvm in the sense that, when the loss function is independent of the true (unknown) value of the latent variables, it reduces to an lsvm.\nThroughout this paper, we will assume that the latent variables are helpful in predicting the correct output of a sample. For example, if we want to distinguish between images of deers and elephants, we would expect that the background clutter to have similar appearance for both categories, and an accurate object localization to be essential for correct prediction. There may be cases where this assumption does not hold. For example, images of deers and cars could be distinguished by detecting roads, or other objects that are more commonly found in urban environments. However, even in such cases, we may be able to learn to detect the object by providing fully supervised annotations for a small fraction of training images, which would help guide the learner towards the correct object locations in other weakly supervised training images."}, {"heading": "2. Related Work", "text": "The most commonly used method for learning the parameters of an lvm is the em algorithm (Dempster et al., 1977; Sundberg, 1974), or its many variants (Gelman et al., 1995). While the em algorithm\nhas an elegant probabilistic interpretation of maximizing the likelihood of the ground-truth output, it marginalizes out the latent variables, which makes it unsuited to problems that require the accurate prediction of latent variables. Furthermore, it does not employ a user-specified loss function, which captures the user\u2019s assessment of the quality of the solution.\nThe most related works to our approach are lsvm (Felzenszwalb et al., 2008; Yu & Joachims, 2009) and its recently proposed generalization called maxmargin min-entropy models (or m3e for short) (Miller et al., 2012). The parameters of an lsvm or an m3e are learned by minimizing a regularized upper bound of the training loss. However, the loss function is restricted to be independent of the true (unknown) value of the latent variables. While such loss functions are useful, and in fact have been successfully employed in practice (Blaschko et al., 2010; Felzenszwalb et al., 2008; Kumar et al., 2010; Miller et al., 2012; Yu & Joachims, 2009), they cannot model several important problems, including the two employed in our experiments\u2014object detection and action detection. In contrast, our framework allows the use of a general loss function. In section 4 we will show that, for loss functions that are independent of the true value of the latent variable, our framework reduces to an lsvm.\nIn our earlier work (Kumar et al., 2011), we proposed an iterative lsvm strategy (or ilsvm for short) with the aim of using a general loss function. In section 5, we show that ilsvm corresponds to using delta functions to model the conditional distribution of the latent variables given the input and the output. In our experiments, we show that using a non-delta conditional distribution significantly outperforms ilsvm."}, {"heading": "3. Preliminaries", "text": "Notation. We denote the input by x \u2208 X , the output by y \u2208 Y and the latent variables by h \u2208 H. The training dataset D = {si = (xi,yi), i = 1, \u00b7 \u00b7 \u00b7 , n} consists of n input-output pairs (or samples) si.\nWe denote the parameters of the delta distribution, which predicts the output and the latent variables for a given input, as w. The parameters of the conditional distribution of the latent variables given the input and the output are denoted by \u03b8.\nWe assume that the user specifies a loss function \u2206(y1,h1,y2,h2) that measures the difference between (y1,h1) and (y2,h2). Similar to previous approaches, we assume that \u2206(y1,h1,y2,h2) = 0 if y1 = y2 and h1 = h2. Otherwise, \u2206(y1,h1,y2,h2) \u2265 0.\nRao\u2019s Dissimilarity Coefficient. We provide a brief description of the dissimilarity measure used in our framework, which was first introduced by Rao (1982). Given a loss function \u2206(z1, z2), where z1, z2 \u2208 Z, the diversity coefficient of two distributions Pi(z) and Pj(z) is defined as the expected loss between two samples drawn randomly from the two distributions respectively, that is,\nH(Pi,Pj) = \u2211\nz1\u2208Z\n\u2211\nz2\u2208Z\n\u2206(z1, z2) Pi(z1) Pj(z2). (1)\nUsing the diversity coefficient, the dissimilarity coefficient between the two distributions can be defined as the following Jensen difference:\nD(Pi,Pj) = H(Pi,Pj)\u2212\u03b2H(Pi,Pi)\u2212(1\u2212\u03b2)H(Pj ,Pj), (2) where \u03b2 \u2208 (0, 1). Note that Rao (1982) fixed \u03b2 = 0.5 in order to ensure that the dissimilarity coefficient is symmetric for Pi and Pj . However, dissimilarity coefficients do not necessarily have to be symmetric (for example, the well-known Kullback-Liebler divergence is non-symmetric); hence we use the more general version shown in equation (2). Rao (1982) showed that the above formulation generalizes other commonly used dissimilarity coefficients such as the Mahalanobis distance and the Gini-Simpson index. We refer the reader to (Rao, 1982) for details."}, {"heading": "4. Loss-based Learning Framework", "text": "Using the above notation and definitions, we now provide the details of our learning framework. We begin by describing the distributions represented by the lvm."}, {"heading": "4.1. Distributions", "text": "We wish to address two separate tasks: (i) to accurately model the distribution of the latent variables for a given input-output pair; and (ii) to accurately predict the output and latent variables for a given input (where accuracy is measured by a user-defined loss). Instead of addressing these two tasks with a single distribution as in previous works, we define two separate distributions, each focused on a single task.\nGiven an input x, we define a delta distribution parameterized by w that predicts the output and the latent variables according to the following rule:\n(y(w),h(w)) = argmax (y,h)\nw\u22a4\u03a8(x,y,h). (3)\nHere, \u03a8(x,y,h) is a joint feature vector of the input x, the output y and the latent variables h. Note that, although for simplicity we defined a linear rule in w, we\ncan also employ a non-linear kernel within our framework. Formally, the delta distribution is given by\nPw(y,h|x) =\n{\n1 if y = y(w),h = h(w), 0 otherwise.\n(4)\nAs mentioned earlier, since the true value of the latent variables is unknown, we would like to model the uncertainty in their values. To this end, we define a separate conditional distribution parameterized by \u03b8 such that\nP\u03b8(hi|si) = 1\nZ(si; \u03b8) exp\n(\n\u03b8 \u22a4\u03a6(xi,yi,hi)\n)\n, (5)\nwhere Z(si; \u03b8) is the partition function, which ensures that the distribution sums to one and \u03a6(xi,yi,hi) is a joint feature vector of the input xi, the output yi and the latent variables hi. This feature vector can be different than the joint feature vector used to specify the delta distribution Pw(\u00b7). Once again, a log-linear distribution is used only to simplify the description. Our framework is valid for any general form of the distribution P\u03b8(\u00b7). Using the above conditional distribution, we also specify a joint distribution as follows:\nP\u2032 \u03b8 (y,hi|xi) =\n{\nP\u03b8(hi|si) if y = yi, 0 otherwise.\n(6)\nAs will be seen shortly, this joint distribution would allow us to employ Rao\u2019s dissimilarity coefficient in our learning framework."}, {"heading": "4.2. The Learning Objective", "text": "Given a dataset D and a loss function \u2206(\u00b7), we propose to learn the parameters w and \u03b8 such that it minimizes the corresponding dissimilarity coefficient over all training samples. Before delving into the details, we give a broad overview of our objective function.\nFor a fixed w, if the predicted output yi(w) is similar to the ground-truth output yi, our objective encourages the probability of the corresponding latent variables, that is P\u03b8(hi(w)|si), and other similar latent variables, to be high. If the predicted output yi(w) is dissimilar to the ground-truth output yi, our objective encourages the diversity coefficient of the corresponding distribution, that is P\u03b8(\u00b7|si), to be high. In other words, for a correctly predicting sample, the conditional distribution is peaky, while for an incorrectly predicted sample, the conditional distribution is flat.\nFor a fixed \u03b8, our objective minimizes the expected loss of the prediction (yi(w),hi(w))) over all the training samples si. This is a key point of our formulation, as the expected loss incorporates the uncertainty of the\nlatent variable values while learning the parameters w. Formally, the expected loss of a pair of output and latent variables (y,h) for the sample si, measured with respect to P\n\u03b8 (\u00b7|si), is defined as\n\u2206i(y,h; \u03b8) = \u2211\nhi\n\u2206(yi,hi,y,h) P\u03b8(hi|si), (7)\nthat is, it is the expectation of the loss between (y,h) and (yi,hi), where the expectation is taken over the distribution of the unknown latent variables hi.\nWe now provide a mathematical description of our learning framework. However, throughout this section and the next, we will reiterate the above intuition at the appropriate places. Our training objective is the sum of the dissimilarity coefficient between Pw(\u00b7) and P\u2032 \u03b8 (\u00b7) over all training samples. Using the definition of dissimilarity coefficient in equation (2), the objective can be written in terms of expected loss as\nD(w, \u03b8) = 1\nn\n(\nn \u2211\ni=1\nHi(w, \u03b8)\u2212 \u03b2Hi(\u03b8)\n)\n,\nHi(w, \u03b8) = \u2206i(yi(w),hi(w); \u03b8), Hi(\u03b8) = \u2211\nh\u2032 i\nP \u03b8 (h\u2032i|si)\u2206i(yi,h \u2032 i; \u03b8). (8)\nNote that the diversity coefficient of Pw(\u00b7) is 0 since it is a delta distribution. Hence, the termHi(w) vanishes from the above objective.\nMinimizing the objective (8) encourages two desirable properties: (i) the predicted output yi(w) should be similar to the ground-truth output yi; and (ii) the predicted latent variable hi(w) should be similar to the latent variables with high probabilities P\u03b8(hi|xi,yi). Importantly, the similarity (or, to be more precise, the dissimilarity) of the outputs and the latent variables is specified by the loss function \u2206(\u00b7). Hence, during learning, the parameters w and \u03b8 are tuned according to the user\u2019s domain knowledge regarding the quality of a solution. This ability to learn loss-specific parameters is absent in traditional frameworks such as em and its variants."}, {"heading": "4.3. Upper Bound on the Learning Objective", "text": "While the objective (8) is smooth and differentiable in \u03b8, for most commonly used choices of the loss function it is highly non-smooth in w. The non-smoothness of the objective results in a difficult optimization problem, which makes the learner prone to bad local minimum solutions. In order to overcome this deficiency, we minimize an upper bound on the objective, similar to the lsvm formulation (Yu & Joachims, 2009).\nSpecifically, we upper bound the term Hi(w, \u03b8), which depends on w, using \u03bei(w, \u03b8) defined as follows.\n\u03bei(w, \u03b8) \u2264 maxy,h { w\u22a4\u03a8(xi,y,h) + \u2206i(y,h; \u03b8) }\n\u2212maxh w \u22a4\u03a8(xi,yi,h) (9)\nUsing the above inequalities, the objectiveD(w, \u03b8) can be upper bounded as\nU(w, \u03b8) = 1\nn\n(\nn \u2211\ni=1\n\u03bei(w, \u03b8)\u2212 \u03b2Hi(\u03b8)\n)\n. (10)\nHowever, if we learn the parameters w and \u03b8 by minimizing the above upper bound (or indeed the original objective function), we run the risk of overfitting to the training data. In order to prevent this, we introduce regularization terms for the parameters. For this work, we use \u21132 norms, though other norms may also be employed. To summarize, the parameters are learned by solving the following optimization problem:\n(w\u2217, \u03b8\u2217) = argmin (w,\u03b8)\n1 2 ||w||2+ J 2 ||\u03b8||2+CU(w, \u03b8), (11)\nwhere the hyperparameters J and C are the relative weights for the regularization of \u03b8 and the upper bound of the dissimilarity coefficient respectively. Note that the upper bound derivation and the resulting optimization problem are similar to the lsvm framework. In fact, the problem can be shown to be a strict generalization of lsvm.\nObservation 1. When the loss function does not depend on the value of the latent variables, problem (11) is equivalent to the problem of learning an lsvm.\nThis observation follows from the fact that, when the loss function is independent of the latent variables, Hi(\u03b8) = \u2206i(yi; \u03b8) \u2211\nh\u2032 i\nP\u03b8(h \u2032 i|si) = 0. Hence, the\noptimization problem is equivalent to minimizing the sum of the regularization of w and \u03bei(w, \u03b8) (which are equivalent to the slack variables that model the upper bound of the loss function for the sample si in lsvm). In fact, even if the loss function does depend on the predicted latent variable hi(w), the optimization problem (11) still generalizes lsvm. This follows from the fact that, in this case, the lsvm problem is equivalent to using delta distributions to model P\u03b8(\u00b7). Formal proofs are omitted."}, {"heading": "5. Optimization", "text": "While the upper bound derived in the previous section still results in a non-smooth and non-convex optimization problem, we obtain an approximate solution using\nblock coordinate descent. Specifically, starting with some initial estimate of parameters, we alternately fix one of the two sets of parameters (either w or \u03b8) while optimizing problem (11) over the other set of parameters. The process is said to terminate when the decrease in the objective falls below C\u01eb, where C is the hyperparameter in problem (11) and \u01eb is a user specified tolerance. The following subsections provide the details of the optimization over each set of parameters."}, {"heading": "5.1. Optimization over w", "text": "For a fixed \u03b8, problem (11) can be interpreted as minimizing a regularized upper bound on the expected loss induced by w, that is,\n\u2211\ni\n\u2206i(yi(w),hi(w); \u03b8), (12)\nsince the term Hi(\u03b8) is a constant for all samples si. The expected loss is an intuitive objective: it gives more weight to the loss corresponding to the latent variables that have a high probability and less weight to those corresponding to the latent variables with low probability. Formally, for a fixed \u03b8, the optimization problem (11) reduces to the following:\nmin w\n1 2 ||w|| 2 + Cn \u2211 i \u03bei\ns.t. \u03bei = maxy,h { w\u22a4\u03a8(xi,y,h) + \u2206i(y,h; \u03b8) }\n\u2212maxh w \u22a4\u03a8(xi,yi,h). (13)\nThe following observation provides us with an efficient algorithm for the above optimization problem.\nObservation 2. Problem (13) is a difference-ofconvex program.\nThe regularization term ||w||2 is convex. The term \u03bei(w, \u03b8) is a difference of two functions that are the pointwise maximum of a set of linear functions. Since the pointwise maximum of convex functions is convex, the observation follows. Similar to lsvm, a local minimum or saddle point solution of problem (13) can be found using the concave-convex procedure (cccp) (Yu & Joachims, 2009). The main steps of cccp are outlined in Algorithm 1. It iteratively estimates the value of the latent variables using the current estimate of w, and updates the parameters by solving a convex optimization problem (14). There are several efficient algorithms for problem (14), for example (Joachims et al., 2009; Shalev-Shwartz et al., 2009; Tsochantaridis et al., 2004). In this work, we use the 1-slack reformulation method proposed by Joachims et al. (2009). We can also solve problem (13) using the selfpaced learning algorithm (Kumar et al., 2010), which\ncan potentially improve the performance of our framework. However, in this paper, we restrict ourselves to the simpler and more efficient cccp algorithm.\nAlgorithm 1 The cccp algorithm for optimizing w.\ninput Dataset D, initial estimate w0, tolerance \u01eb. 1: t \u2190 0. 2: repeat\n3: Update h\u2217i = argmaxhi w \u22a4 t \u03a8(xi,yi,hi). 4: Estimate the updated parameter wt+1 by solving the following convex optimization problem:\nmin w\n1 2 ||w|| 2 + Cn \u2211 i \u03bei\ns.t. \u03bei \u2265 w \u22a4\u03a8(xi,y,h) + \u2206i(y,h; \u03b8)\n\u2212w\u22a4\u03a8(xi,yi,h \u2217 i ), \u2200y,h. (14)\n5: t \u2190 t+ 1. 6: until Objective cannot be decreased below C\u01eb.\nProblem (13) requires the computation of the expected loss \u2206i(y,h; \u03b8) as defined in equation (7), which can be found in O(|H|) time for each pair of (y,h) (where H is the space of all latent variables). For a sufficiently small H this operation is computationally feasible. For a large latent variable space H, we have two options. First, we can choose the joint feature vector \u03a6(x,y,h) for the conditional distribution P\u03b8(\u00b7) to be decomposable in such a manner as to facilitate efficient computation of sufficient statistics (for example, a low tree-width model). Note that this still allows us to use a more complex joint feature vector \u03a8(x,y,h) to make predictions for a given test sample. Second, if the problem requires a complex \u03a6(x,y,h) to encode the conditional distribution, then we can resort to using one of several inference techniques to compute the approximate sufficient statistics. However, we note that several important problems in machine learning can be formulated using latent variables whose space is sufficiently small to allow for exact computations of the expected loss, including motif finding (Yu & Joachims, 2009), image classification (Kumar et al., 2010; Miller et al., 2012), digit recognition (Kumar et al., 2010), and the two problems used in our experiments, namely object detection and action detection."}, {"heading": "5.2. Optimization over \u03b8", "text": "For a fixed w, problem (11) can be interpreted as a regularized upper bound on the following objective\n1\nn\n(\nn \u2211\ni=1\nHi(w, \u03b8)\u2212 \u03b2Hi(\u03b8)\n)\n, (15)\nwhere the divergence coefficients Hi(w, \u03b8) and Hi(\u03b8) are defined in equation (8). To gain an understanding\nof the above objective, let us consider a simple 0/1 loss (that is, the loss is 0 if both the outputs are equal and both the latent variables are equal, otherwise 1). If yi(w) = yi, that is, w predicts the correct output for the sample si, then the first term of the above objective dominates the second. In this case, the parameter \u03b8 is encouraged to assign a high probability to the predicted latent variables hi(w), and other similar latent variables, in order to minimize the objective. If yi(w) 6= yi, the first term is a constant. Thus, the parameter \u03b8 is encouraged to maximize the diversity of the conditional distribution P\u03b8(\u00b7). In other words, for a correct prediction of output, we learn a peaky distribution and for an incorrect prediction of output, we learn a flat distribution. Formally, for a fixed w, the optimization problem (11) reduces to the following:\nmin \u03b8\nJ 2 ||\u03b8||2 + CU(w, \u03b8), (16)\nwhere U(w, \u03b8) is defined in equation (10). We obtain an approximate solution to the above problem using stochastic subgradient descent (ssd). The main steps of ssd are outlined in Algorithm 2.\nAlgorithm 2 The ssd algorithm for optimizing \u03b8.\ninput Dataset D, initial estimate \u03b80, T > 0. 1: t \u2190 0. \u03bb \u2190 J/C. 2: repeat\n3: Choose a sample si randomly from D. 4: Compute the stochastic subgradient gt as\ngt = \u03b8t +\u2207\u03b8Hi(w, \u03b8) +\u2207\u03b8Hi(\u03b8). (17)\n5: t \u2190 t+ 1. 6: Update \u03b8t+1 \u2190 \u03b8t \u2212 1 \u03bbtgt. 7: until Number of iterations t = T .\nEach iteration of ssd takes O(|H|2) time (since the subgradient gt requires a quadratic sum to compute Hi(\u03b8)). Similar to the expected loss, this can be performed exactly for a sufficiently small space of latent variables, or the appropriate choice of the joint feature vector \u03a6(x,y,h). For a large latent variable space and a complex joint feature vector, we would have to resort to approximate inference.\n5.3. Comparison with ilsvm\nOur overall approach is similar in flavor to the ilsvm algorithm (Kumar et al., 2011), which iterates over the following two steps until convergence: (i) obtain the value of the latent variables for all training samples using the current estimate of the parameters; (ii) update the parameters by solving an lsvm, where the\nloss function is measured using the latent variables estimated in the first step instead of the true latent variables. The following observation shows that ilsvm is a special case of our framework.\nObservation 3. The first step of ilsvm minimizes the objective (15) when P\n\u03b8 (\u00b7) are restricted to be\ndelta distributions. The second step of ilsvm solves an lsvm problem similar to the one described in the previous subsection for optimizing over w.\nThe observation regarding the second step is straightforward. For the first step, it follows from the fact that ilsvm minimizes Hi(w, \u03b8). As the second divergence coefficient Hi(\u03b8) vanishes when using delta conditional distributions, ilsvm effectively minimizes objective (15) for a fixed w. A formal proof is omitted."}, {"heading": "6. Experiments", "text": "We now demonstrate the efficacy of our framework on two challenging machine learning applications: object detection and action detection. Specifically, we show how our approach, which models the uncertainty in the values of the latent variables during training, outperforms the previous loss-based learning frameworks, namely lsvm and ilsvm, which only estimate the most likely assignment of the latent variables. All three methods used in our experiments share a common hyperparameter C (the relative weight for the upper bounds \u03bei), which we vary to take values from the set {10\u22124, 10\u22123, \u00b7 \u00b7 \u00b7 , 102}. In addition, our framework introduces two more hyperparameters: J (the relative weight for the regularization of \u03b8) and \u03b2 (the hyperparameter for Rao\u2019s dissimilarity coefficient). In all our experiments, we set J = 0.1 and \u03b2 = 0.1. However, we may obtain better results by carefully tuning these hyperparameters. The tolerance value for all the methods was set to \u01eb = 10\u22123."}, {"heading": "6.1. Object Detection", "text": "Problem Formulation. The aim of this application is to learn discriminative object models that predict the category (for example, \u2018deer\u2019 or \u2018elephant\u2019) and the location of the object present in an image. In a fully supervised setting, we would be required to specify a tight bounding box around the object present in each of the training samples. As the collection of such annotations is onerous and expensive, we would like to learn the object models using image-level labels (that is, labels indicating the presence or absence of an object category in an image), which are considerably easier to obtain. Formally, for each sample, the input x is an image. The output y \u2208 {0, 1, \u00b7 \u00b7 \u00b7 , c\u2212 1},\nwhere c is the number of object categories. The latent variable h models the tight bounding box around the object in the image. Similar to previous works (Kumar et al., 2010; Miller et al., 2012), the joint feature vectors \u03a8(x,y,h) and \u03a6(x,y,h) are defined using the hog descriptor (Dalal & Triggs, 2005; Felzenszwalb et al., 2008) extracted using the pixels of the bounding box. In our experiments, we consider non-overlapping putative bounding boxes that are 8 pixels apart, which results in a maximum of 350 bounding boxes for each image in our dataset. This allows us to compute the exact expected loss and the exact subgradients during learning. We employ two different loss functions, 0/1 loss and overlap loss, which are defined below.\n\u22060/1(y1,h1,y2,h2) =\n{\n0 if y1 = y2,h1 = h2, 1 otherwise,\n\u2206O(y1,h1,y2,h2) =\n{\n1\u2212O(h1,h2) if y1 = y2, 1 otherwise,\nwhere O(h1,h2) \u2208 [0, 1] is the ratio of the area of the intersection and the area of the union of the two bounding boxes (Everingham et al., 2010). Both the loss functions not only encourage the models to predict the right category but also the right location of the object. We note that a similar experimental setup was also used by Blaschko et al. (2010).\nDataset. We use images of 6 different mammals (approximately 45 images per mammal) that have been previously employed for image classification (Kumar et al., 2010; Miller et al., 2012). We split the images of each category into approximately 60% for training and 40% for testing. We report results using 5 folds.\nResults. Figure 1 shows the test loss for lsvm, ilsvm and our method using the 7 different C values. The test loss is computed using the ground-truth labels and bounding boxes for the test samples. Recall that, during training, only the ground-truth labels were assumed to be known, while the bounding boxes were modeled as latent variables.\nWhile lsvm was initially proposed for loss functions that do not depend on the value of the true latent variable, we adopted a similar approach to the cccp algorithm for lsvm to solve the object detection problem. Briefly, we iterate over two steps: estimating the value of the latent variables and solving a convex structured svm problem until the objective function could not be decreased below a user-specified tolerance. In our experiments, this approach provided similar results to the ilsvm method.\nBy incorporating the uncertainty in latent variables, our approach outperformed both lsvm and ilsvm.\nSpecifically, for the 0/1 loss, the best test loss (over all C values) for lsvm, ilsvm and our method is 64.82 \u00b1 4.96, 68.53 \u00b1 5.52 and 47.76 \u00b1 2.53 respectively (where the loss has been scaled to lie between 0 and 100). For the overlap loss, the best test loss is 44.93 \u00b1 1.84, 47.26 \u00b1 3.87 and 42.27 \u00b1 3.64 respectively. While the improvement in the overlap loss is not statistically significant according to paired t-test, the improvement in the 0/1 loss is statistically significant with p < 10\u22124."}, {"heading": "6.2. Action Detection", "text": "Problem Formulation. The aim of this application is to learn human action models that predict the action class (for example, \u2018running\u2019 or \u2018jumping\u2019) and the location of the person present in an image. Similar to object detection, a fully supervised dataset would require annotating each training image with the person bounding box. Instead, we use image-level labels that indicate which action is being performed by a person in the image. Formally, for each sample, the input x is an image. The output y \u2208 {0, 1, \u00b7 \u00b7 \u00b7 , c \u2212 1}, where c is the number of action classes. The latent variable h models the tight bounding box around the person in the image. The joint feature vectors are the Poselet descriptor (Maji et al., 2011) of the bounding box. We consider approximately 20 putative bounding boxes for each image, which are obtained automatically using a standard person detector (Felzenszwalb et al., 2008). The small search space for the latent variables avoids the need for approximate inference. Once again, we report results using both 0/1 loss and overlap loss.\nDataset. We use the pascal voc 2011 \u2018trainval\u2019 dataset (Everingham et al., 2010), which consists of approximately 2500 images of 10 different action classes. We split the images of each class into approximately 60% for training and 40% for testing, and\nreport results using 5 folds. In addition to the detected persons, we introduce the largest ground-truth bounding box into the latent variable space.\nResults. Figure 2 shows the test loss for the three methods, computed using ground-truth labels and bounding boxes. For 0/1 loss, the best test loss over all C values for lsvm, ilsvm and our method is 93.18 \u00b1 1.95, 92.89 \u00b1 3.70 and 76.10 \u00b1 0.71 respectively. For overlap loss, the best test loss is 70.66\u00b10.76, 71.33\u00b11.14 and 67.16\u00b10.32 respectively. Our method significantly outperforms both lsvm and ilsvm, as confirmed by the paired t-test with p < 10\u22123."}, {"heading": "7. Discussion", "text": "We proposed a novel framework for parameter estimation using weakly supervised datasets. Our framework consists of two distributions: a conditional distribution that captures the uncertainty in the latent variables, and a delta distribution that predicts the output and latent variable values. The parameters of the distributions are learned by minimizing a loss-based dissimilarity coefficient between the two distributions for all samples in the training dataset. We empirically demonstrate the benefit of our approach over previous loss-based learning frameworks using publicly available datasets of two challenging problems\u2014object detection and action detection.\nThe proposed optimization requires the computation of the expected loss \u2206i(y,h|\u03b8) (shown in equation (7)) when learning the delta distribution and the lossdependent subgradient gt (shown in equation (17)) when learning the conditional distribution. In special cases (for example, low tree-width models), these terms can be computed exactly. In general, we would have to resort to one of several existing approximate inference techniques or to design customized algorithms to compute the sufficient statistics. Note that,\nsince the conditional distribution is not used during testing, an approximate estimate of its parameters, which is able to accurately model the uncertainty in the latent variables, would suffice in practice.\nAcknowledgments. This work is partially funded by the European Research Council under the European Community\u2019s Seventh Framework Programme (FP7/2007-\n2013)/ERC Grant agreement number 259112, INRIAStanford associate team SPLENDID, NSF under grant IIS 0917151, MURI contract N000140710747, and the Boeing company. We thank Michael Stark for proof-reading the\npaper, Subhransu Maji for the Poselets data, and Daniel Selsam and Andrej Karpathy for helpful discussions."}, {"heading": "Blaschko, M., Vedaldi, A., and Zisserman, A. Simultaneous", "text": "object detection and ranking with weak supervision. In NIPS, 2010.\nDalal, N. and Triggs, B. Histograms of oriented gradients for human detection. In CVPR, 2005.\nDempster, A., Laird, N., and Rubin, D. Maximum likelihood from incomplete data via the EM algorithm. Journal of Royal Statistical Society, 1977."}, {"heading": "Everingham, M., Van Gool, L., Williams, C., Winn, J.,", "text": "and Zisserman, A. The PASCAL visual object classes (VOC) challenge. IJCV, 2010."}, {"heading": "Felzenszwalb, P., McAllester, D., and Ramanan, D. A", "text": "discriminatively trained, multiscale, deformable part model. In CVPR, 2008.\nGelman, A., Carlin, J., Stern, H., and Rubin, D. Bayesian Data Analysis. Chapman and Hall, 1995."}, {"heading": "Joachims, T., Finley, T., and Yu, C.-N. Cutting-plane", "text": "training for structural SVMs. Machine Learning, 2009.\nKumar, M. P., Packer, B., and Koller, D. Self-paced learning for latent variable models. In NIPS, 2010."}, {"heading": "Kumar, M. P., Turki, H., Preston, D., and Koller, D.", "text": "Learning specific-class segmentation from diverse data. In ICCV, 2011."}, {"heading": "Maji, S., Bourdev, L., and Malik, J. Action recognition", "text": "from a distributed representation of pose and appearance. In CVPR, 2011."}, {"heading": "Miller, K., Kumar, M. P., Packer, B., Goodman, D., and", "text": "Koller, D. Max-margin min-entropy models. In AISTATS, 2012.\nRao, C. Diversity and dissimilarity coefficients: A unified approach. Theoretical Population Biology, 1982."}, {"heading": "Shalev-Shwartz, S., Singer, Y., and Srebro, N. Pegasos:", "text": "Primal estimated sub-gradient solver for SVM. In ICML, 2009.\nSundberg, R. Maximum likelihood theory for incomplete data from an exponential family. Scandinavian Journal of Statistics, 1974.\nTsochantaridis, I., Hofmann, T., Altun, Y., and Joachims, T. Support vector machine learning for interdependent and structured output spaces. In ICML, 2004.\nYu, C.-N. and Joachims, T. Learning structural SVMs with latent variables. In ICML, 2009."}], "references": [{"title": "Simultaneous object detection and ranking with weak supervision", "author": ["M. Blaschko", "A. Vedaldi", "A. Zisserman"], "venue": "In NIPS,", "citeRegEx": "Blaschko et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Blaschko et al\\.", "year": 2010}, {"title": "Histograms of oriented gradients for human detection", "author": ["N. Dalal", "B. Triggs"], "venue": "In CVPR,", "citeRegEx": "Dalal and Triggs,? \\Q2005\\E", "shortCiteRegEx": "Dalal and Triggs", "year": 2005}, {"title": "Maximum likelihood from incomplete data via the EM algorithm", "author": ["A. Dempster", "N. Laird", "D. Rubin"], "venue": "Journal of Royal Statistical Society,", "citeRegEx": "Dempster et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Dempster et al\\.", "year": 1977}, {"title": "The PASCAL visual object classes (VOC) challenge", "author": ["M. Everingham", "L. Van Gool", "C. Williams", "J. Winn", "A. Zisserman"], "venue": null, "citeRegEx": "Everingham et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Everingham et al\\.", "year": 2010}, {"title": "A discriminatively trained, multiscale, deformable part model", "author": ["P. Felzenszwalb", "D. McAllester", "D. Ramanan"], "venue": "In CVPR,", "citeRegEx": "Felzenszwalb et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Felzenszwalb et al\\.", "year": 2008}, {"title": "Bayesian Data Analysis", "author": ["A. Gelman", "J. Carlin", "H. Stern", "D. Rubin"], "venue": null, "citeRegEx": "Gelman et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Gelman et al\\.", "year": 1995}, {"title": "Cutting-plane training for structural SVMs", "author": ["T. Joachims", "T. Finley", "Yu", "C.-N"], "venue": "Machine Learning,", "citeRegEx": "Joachims et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Joachims et al\\.", "year": 2009}, {"title": "Self-paced learning for latent variable models", "author": ["M.P. Kumar", "B. Packer", "D. Koller"], "venue": "In NIPS,", "citeRegEx": "Kumar et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kumar et al\\.", "year": 2010}, {"title": "Learning specific-class segmentation from diverse data", "author": ["M.P. Kumar", "H. Turki", "D. Preston", "D. Koller"], "venue": "In ICCV,", "citeRegEx": "Kumar et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kumar et al\\.", "year": 2011}, {"title": "Action recognition from a distributed representation of pose and appearance", "author": ["S. Maji", "L. Bourdev", "J. Malik"], "venue": "In CVPR,", "citeRegEx": "Maji et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Maji et al\\.", "year": 2011}, {"title": "Max-margin min-entropy models", "author": ["K. Miller", "M.P. Kumar", "B. Packer", "D. Goodman", "D. Koller"], "venue": "In AISTATS,", "citeRegEx": "Miller et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Miller et al\\.", "year": 2012}, {"title": "Diversity and dissimilarity coefficients: A unified approach", "author": ["C. Rao"], "venue": "Theoretical Population Biology,", "citeRegEx": "Rao,? \\Q1982\\E", "shortCiteRegEx": "Rao", "year": 1982}, {"title": "Pegasos: Primal estimated sub-gradient solver for SVM", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro"], "venue": "In ICML,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2009}, {"title": "Maximum likelihood theory for incomplete data from an exponential family", "author": ["R. Sundberg"], "venue": "Scandinavian Journal of Statistics,", "citeRegEx": "Sundberg,? \\Q1974\\E", "shortCiteRegEx": "Sundberg", "year": 1974}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["I. Tsochantaridis", "T. Hofmann", "Y. Altun", "T. Joachims"], "venue": "In ICML,", "citeRegEx": "Tsochantaridis et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Tsochantaridis et al\\.", "year": 2004}, {"title": "Learning structural SVMs with latent variables", "author": ["Yu", "C.-N", "T. Joachims"], "venue": "In ICML,", "citeRegEx": "Yu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 11, "context": "In order to make the two distributions as similar as possible, we minimize a regularized upper bound on a loss-based dissimilarity measure (Rao, 1982) between the distributions.", "startOffset": 139, "endOffset": 150}, {"referenceID": 2, "context": "The most commonly used method for learning the parameters of an lvm is the em algorithm (Dempster et al., 1977; Sundberg, 1974), or its many variants (Gelman et al.", "startOffset": 88, "endOffset": 127}, {"referenceID": 13, "context": "The most commonly used method for learning the parameters of an lvm is the em algorithm (Dempster et al., 1977; Sundberg, 1974), or its many variants (Gelman et al.", "startOffset": 88, "endOffset": 127}, {"referenceID": 5, "context": ", 1977; Sundberg, 1974), or its many variants (Gelman et al., 1995).", "startOffset": 46, "endOffset": 67}, {"referenceID": 4, "context": "The most related works to our approach are lsvm (Felzenszwalb et al., 2008; Yu & Joachims, 2009) and its recently proposed generalization called maxmargin min-entropy models (or m3e for short) (Miller et al.", "startOffset": 48, "endOffset": 96}, {"referenceID": 10, "context": ", 2008; Yu & Joachims, 2009) and its recently proposed generalization called maxmargin min-entropy models (or m3e for short) (Miller et al., 2012).", "startOffset": 125, "endOffset": 146}, {"referenceID": 0, "context": "While such loss functions are useful, and in fact have been successfully employed in practice (Blaschko et al., 2010; Felzenszwalb et al., 2008; Kumar et al., 2010; Miller et al., 2012; Yu & Joachims, 2009), they cannot model several important problems, including the two employed in our experiments\u2014object detection and action detection.", "startOffset": 94, "endOffset": 206}, {"referenceID": 4, "context": "While such loss functions are useful, and in fact have been successfully employed in practice (Blaschko et al., 2010; Felzenszwalb et al., 2008; Kumar et al., 2010; Miller et al., 2012; Yu & Joachims, 2009), they cannot model several important problems, including the two employed in our experiments\u2014object detection and action detection.", "startOffset": 94, "endOffset": 206}, {"referenceID": 7, "context": "While such loss functions are useful, and in fact have been successfully employed in practice (Blaschko et al., 2010; Felzenszwalb et al., 2008; Kumar et al., 2010; Miller et al., 2012; Yu & Joachims, 2009), they cannot model several important problems, including the two employed in our experiments\u2014object detection and action detection.", "startOffset": 94, "endOffset": 206}, {"referenceID": 10, "context": "While such loss functions are useful, and in fact have been successfully employed in practice (Blaschko et al., 2010; Felzenszwalb et al., 2008; Kumar et al., 2010; Miller et al., 2012; Yu & Joachims, 2009), they cannot model several important problems, including the two employed in our experiments\u2014object detection and action detection.", "startOffset": 94, "endOffset": 206}, {"referenceID": 8, "context": "In our earlier work (Kumar et al., 2011), we proposed an iterative lsvm strategy (or ilsvm for short) with the aim of using a general loss function.", "startOffset": 20, "endOffset": 40}, {"referenceID": 11, "context": "We refer the reader to (Rao, 1982) for details.", "startOffset": 23, "endOffset": 34}, {"referenceID": 11, "context": "Note that Rao (1982) fixed \u03b2 = 0.", "startOffset": 10, "endOffset": 21}, {"referenceID": 11, "context": "Note that Rao (1982) fixed \u03b2 = 0.5 in order to ensure that the dissimilarity coefficient is symmetric for Pi and Pj . However, dissimilarity coefficients do not necessarily have to be symmetric (for example, the well-known Kullback-Liebler divergence is non-symmetric); hence we use the more general version shown in equation (2). Rao (1982) showed that the above formulation generalizes other commonly used dissimilarity coefficients such as the Mahalanobis distance and the Gini-Simpson index.", "startOffset": 10, "endOffset": 342}, {"referenceID": 6, "context": "There are several efficient algorithms for problem (14), for example (Joachims et al., 2009; Shalev-Shwartz et al., 2009; Tsochantaridis et al., 2004).", "startOffset": 69, "endOffset": 150}, {"referenceID": 12, "context": "There are several efficient algorithms for problem (14), for example (Joachims et al., 2009; Shalev-Shwartz et al., 2009; Tsochantaridis et al., 2004).", "startOffset": 69, "endOffset": 150}, {"referenceID": 14, "context": "There are several efficient algorithms for problem (14), for example (Joachims et al., 2009; Shalev-Shwartz et al., 2009; Tsochantaridis et al., 2004).", "startOffset": 69, "endOffset": 150}, {"referenceID": 7, "context": "We can also solve problem (13) using the selfpaced learning algorithm (Kumar et al., 2010), which can potentially improve the performance of our framework.", "startOffset": 70, "endOffset": 90}, {"referenceID": 6, "context": "There are several efficient algorithms for problem (14), for example (Joachims et al., 2009; Shalev-Shwartz et al., 2009; Tsochantaridis et al., 2004). In this work, we use the 1-slack reformulation method proposed by Joachims et al. (2009). We can also solve problem (13) using the selfpaced learning algorithm (Kumar et al.", "startOffset": 70, "endOffset": 241}, {"referenceID": 7, "context": "However, we note that several important problems in machine learning can be formulated using latent variables whose space is sufficiently small to allow for exact computations of the expected loss, including motif finding (Yu & Joachims, 2009), image classification (Kumar et al., 2010; Miller et al., 2012), digit recognition (Kumar et al.", "startOffset": 266, "endOffset": 307}, {"referenceID": 10, "context": "However, we note that several important problems in machine learning can be formulated using latent variables whose space is sufficiently small to allow for exact computations of the expected loss, including motif finding (Yu & Joachims, 2009), image classification (Kumar et al., 2010; Miller et al., 2012), digit recognition (Kumar et al.", "startOffset": 266, "endOffset": 307}, {"referenceID": 7, "context": ", 2012), digit recognition (Kumar et al., 2010), and the two problems used in our experiments, namely object detection and action detection.", "startOffset": 27, "endOffset": 47}, {"referenceID": 8, "context": "Our overall approach is similar in flavor to the ilsvm algorithm (Kumar et al., 2011), which iterates over the following two steps until convergence: (i) obtain the value of the latent variables for all training samples using the current estimate of the parameters; (ii) update the parameters by solving an lsvm, where the loss function is measured using the latent variables estimated in the first step instead of the true latent variables.", "startOffset": 65, "endOffset": 85}, {"referenceID": 7, "context": "Similar to previous works (Kumar et al., 2010; Miller et al., 2012), the joint feature vectors \u03a8(x,y,h) and \u03a6(x,y,h) are defined using the hog descriptor (Dalal & Triggs, 2005; Felzenszwalb et al.", "startOffset": 26, "endOffset": 67}, {"referenceID": 10, "context": "Similar to previous works (Kumar et al., 2010; Miller et al., 2012), the joint feature vectors \u03a8(x,y,h) and \u03a6(x,y,h) are defined using the hog descriptor (Dalal & Triggs, 2005; Felzenszwalb et al.", "startOffset": 26, "endOffset": 67}, {"referenceID": 4, "context": ", 2012), the joint feature vectors \u03a8(x,y,h) and \u03a6(x,y,h) are defined using the hog descriptor (Dalal & Triggs, 2005; Felzenszwalb et al., 2008) extracted using the pixels of the bounding box.", "startOffset": 94, "endOffset": 143}, {"referenceID": 3, "context": "where O(h1,h2) \u2208 [0, 1] is the ratio of the area of the intersection and the area of the union of the two bounding boxes (Everingham et al., 2010).", "startOffset": 121, "endOffset": 146}, {"referenceID": 0, "context": "We note that a similar experimental setup was also used by Blaschko et al. (2010).", "startOffset": 59, "endOffset": 82}, {"referenceID": 7, "context": "We use images of 6 different mammals (approximately 45 images per mammal) that have been previously employed for image classification (Kumar et al., 2010; Miller et al., 2012).", "startOffset": 134, "endOffset": 175}, {"referenceID": 10, "context": "We use images of 6 different mammals (approximately 45 images per mammal) that have been previously employed for image classification (Kumar et al., 2010; Miller et al., 2012).", "startOffset": 134, "endOffset": 175}, {"referenceID": 9, "context": "The joint feature vectors are the Poselet descriptor (Maji et al., 2011) of the bounding box.", "startOffset": 53, "endOffset": 72}, {"referenceID": 4, "context": "We consider approximately 20 putative bounding boxes for each image, which are obtained automatically using a standard person detector (Felzenszwalb et al., 2008).", "startOffset": 135, "endOffset": 162}, {"referenceID": 3, "context": "We use the pascal voc 2011 \u2018trainval\u2019 dataset (Everingham et al., 2010), which consists of approximately 2500 images of 10 different action classes.", "startOffset": 46, "endOffset": 71}], "year": 2012, "abstractText": "We consider the problem of parameter estimation using weakly supervised datasets, where a training sample consists of the input and a partially specified annotation, which we refer to as the output. The missing information in the annotation is modeled using latent variables. Previous methods overburden a single distribution with two separate tasks: (i) modeling the uncertainty in the latent variables during training; and (ii) making accurate predictions for the output and the latent variables during testing. We propose a novel framework that separates the demands of the two tasks using two distributions: (i) a conditional distribution to model the uncertainty of the latent variables for a given input-output pair; and (ii) a delta distribution to predict the output and the latent variables for a given input. During learning, we encourage agreement between the two distributions by minimizing a loss-based dissimilarity coefficient. Our approach generalizes latent svm in two important ways: (i) it models the uncertainty over latent variables instead of relying on a pointwise estimate; and (ii) it allows the use of loss functions that depend on latent variables, which greatly increases its applicability. We demonstrate the efficacy of our approach on two challenging problems\u2014object detection and action detection\u2014using publicly available datasets.", "creator": "dvips(k) 5.99 Copyright 2010 Radical Eye Software"}}}