{"id": "1302.1538", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Sequential Update of Bayesian Network Structure", "abstract": "Due to errors in the model construction and changes in the dynamics of the domains, we cannot afford to ignore the information in new data. While a sequential update of parameters for a fixed structure can be carried out using standard techniques, a sequential update of the network structure is still an open problem. In this paper, we examine the sequential update of Bayean networks, where both parameters and structure are likely to change. We introduce a new approach that allows flexible manipulation of the trade-off between the quality of the learned networks and the amount of information maintained through past observations. We formally describe our approach, including the necessary modifications of the scoring functions to learn Bayean networks, evaluate their effectiveness through an empirical study, and extend it in case of missing data.", "histories": [["v1", "Wed, 6 Feb 2013 15:55:21 GMT  (1219kb)", "http://arxiv.org/abs/1302.1538v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["nir friedman", "moises goldszmidt"], "accepted": false, "id": "1302.1538"}, "pdf": {"name": "1302.1538.pdf", "metadata": {"source": "CRF", "title": "Sequential Update of Bayesian Network Structure", "authors": ["Nir Friedman", "Moises Goldszmidt"], "emails": ["nir@cs.berkeley.edu", "moises@erg.sri.com"], "sections": null, "references": [{"title": "A tutorial on learning Bayesian net\u00ad works", "author": ["D. Heckerman"], "venue": "Technical Report MSR-TR-95-06, Microsoft Research,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1995}, {"title": "Learning Bayesian belief networks. An approach based on the MDL principle", "author": ["W. Lam", "F. Bacchus"], "venue": "Comp. lnt. ,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1994}, {"title": "A new view of the EM algorithm that justifies incremental and other variants", "author": ["R.M. Neal", "G.E. Hinton"], "venue": "Unpublished manuscript,", "citeRegEx": "Neal and Hinton.,? \\Q1994\\E", "shortCiteRegEx": "Neal and Hinton.", "year": 1994}, {"title": "Estimating the dimension of a model", "author": ["G. Schwarz"], "venue": "Ann. of Stat. ,", "citeRegEx": "Schwarz.,? \\Q1978\\E", "shortCiteRegEx": "Schwarz.", "year": 1978}, {"title": "Sequential up\u00ad dating of conditional probabilities on directed graph\u00ad", "author": ["D.J. Spiegelhalter", "S.L. Lauritzen"], "venue": "ical structures. Networks,", "citeRegEx": "Spiegelhalter and Lauritzen.,? \\Q1990\\E", "shortCiteRegEx": "Spiegelhalter and Lauritzen.", "year": 1990}], "referenceMentions": [], "year": 2011, "abstractText": "There is an obvious need for improving the per\u00ad formance and accuracy of a Bayesian network as new data is observed. Because of errors in model construction and changes in the dynamics of the domains, we cannot afford to ignore the infor\u00ad mation in new data. While sequential update of parameters for a fixed structure can be accom\u00ad plished using standard techniques, sequential up\u00ad date of network structure is still an open problem. In this paper, we investigate sequential update of Bayesian networks were both parameters and structure are expected to change. We introduce a new approach that allows for the flexible ma\u00ad nipulation of the tradeoff between the quality of the learned networks and the amount of informa\u00ad tion that is maintained about past observations. We formally describe our approach including the necessary modifications to the scoring functions for learning Bayesian networks, evaluate its effec\u00ad tiveness through and empirical study, and extend it to the case of missing data.", "creator": "pdftk 1.41 - www.pdftk.com"}}}