{"id": "1302.1575", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Fast Value Iteration for Goal-Directed Markov Decision Processes", "abstract": "Planning problems where the effects of actions are not deterministic can be modeled as Markov decision processes. Planning problems are usually targeted. This paper suggests several techniques to use goal-orientation to accelerate value repetition, a standard algorithm for solving Markov decision processes. Empirical studies have shown that these techniques can cause significant acceleration.", "histories": [["v1", "Wed, 6 Feb 2013 15:59:41 GMT  (716kb)", "http://arxiv.org/abs/1302.1575v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["nevin lianwen zhang", "weihong zhang"], "accepted": false, "id": "1302.1575"}, "pdf": {"name": "1302.1575.pdf", "metadata": {"source": "CRF", "title": "Fast Value Iteration for Goal-Directed Markov Decision Processes", "authors": ["Nevin L. Zhang", "Weihong Zhang"], "emails": [], "sections": null, "references": [{"title": "Dynamic Programming: Deterministic and Stochastic Models, Prentice\u00ad", "author": ["D.P. Bertsekas"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1987}, {"title": "Exploiting Structures In Policy Construc\u00ad", "author": ["C. Boutillier", "R. Dearden", "M. Goldszmidt"], "venue": "Proceedings of IJCAI'95", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1995}, {"title": "Learn\u00ad ing Evaluation Functions for Large Acyclic Do\u00ad mains.", "author": ["J.A. Boyan", "A.W. Moore"], "venue": "In L. Saitta(ed.), Machine LtUJrning: Pro\u00ad ceedings of the Thirteenth International Confer\u00ad ence,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1996}, {"title": "Introduction to Algorithms", "author": ["T.H. Carmen", "C.E. Leiserson", "R.L. Rivest"], "venue": null, "citeRegEx": "Carmen et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Carmen et al\\.", "year": 1990}, {"title": "A Model for Reasoning about Persistence and Causation", "author": ["T.L. Dean", "K. Kanazawa"], "venue": "Computational Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1989}, {"title": "Planning with Deadlines in Stochastic Domains", "author": ["T.L. Dean", "L.P. Kaelbling", "J. Kirman", "A. Nicholson"], "venue": "In Proceedings of the EletJenth National Conference on Artificial Intel\u00ad ligence,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1993}, {"title": "Decompo\u00ad sition techniques for planning in stochastic do\u00ad mains", "author": ["T.L. Dean", "S.H. Lin"], "venue": "TR CS-95-10,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1995}, {"title": "Planning and Control", "author": ["T.L. Dean", "M.P. Wellman"], "venue": null, "citeRegEx": "Dean and Wellman,? \\Q1991\\E", "shortCiteRegEx": "Dean and Wellman", "year": 1991}, {"title": "Optimization of Dis\u00ad counted Markov Decision Problems", "author": ["N.A.J. Hastings"], "venue": "Oper. Res. Quart.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1969}, {"title": "A Modified Dynamic Pro\u00ad gramm", "author": ["J. MacQueen"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1969}], "referenceMentions": [{"referenceID": 0, "context": "Howard 1960, Puter\u00ad man 1990, BertsekaB 1987, White 1993}. Dean and Kanazawa (1989) and Dean and Wellman (1991) ini\u00ad tiated the use of MDPs in planning problems where effects of actions are not deterministic.", "startOffset": 55, "endOffset": 84}, {"referenceID": 0, "context": "Howard 1960, Puter\u00ad man 1990, BertsekaB 1987, White 1993}. Dean and Kanazawa (1989) and Dean and Wellman (1991) ini\u00ad tiated the use of MDPs in planning problems where effects of actions are not deterministic.", "startOffset": 55, "endOffset": 112}], "year": 2011, "abstractText": "P lanning problems where effects of actions are non-deterministic can be modeled a8 Markov decision processes. Planning prob\u00ad lems are usually goal-directed. This paper proposes several techniques for exploiting the goal-directedness to accelerate value itera\u00ad tion, a standard algorithm for solving Markov decision processes. Empirical studies have shown that the techniques can bring about significant speedups.", "creator": "pdftk 1.41 - www.pdftk.com"}}}