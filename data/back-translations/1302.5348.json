{"id": "1302.5348", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Feb-2013", "title": "Graph-based Generalization Bounds for Learning Binary Relations", "abstract": "We examine the generalisability of learned binary relationships: functions that map instance pairs to a logical indicator. This problem is applied in many areas of machine learning, such as ranking, unit resolution, and link prediction. Our learning framework includes an example labeler that examines $m $pairs of $X\\ times X $for a sequence of $n $instances and a desired training size. The challenge in analyzing this learning scenario is that paired combinations of random variables are inherently interdependent, preventing us from using traditional learning theory arguments. We present a unified, graph-based analysis that allows us to analyze this dependence based on well-known graph identities.We are then able to link the generalization error of learned binary relationships using Rademacher's complexity and algorithmic stability.", "histories": [["v1", "Thu, 21 Feb 2013 17:30:42 GMT  (23kb,D)", "https://arxiv.org/abs/1302.5348v1", null], ["v2", "Wed, 27 Feb 2013 03:33:47 GMT  (23kb,D)", "http://arxiv.org/abs/1302.5348v2", null], ["v3", "Fri, 31 May 2013 21:12:47 GMT  (23kb,D)", "http://arxiv.org/abs/1302.5348v3", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ben london", "bert huang", "lise getoor"], "accepted": false, "id": "1302.5348"}, "pdf": {"name": "1302.5348.pdf", "metadata": {"source": "CRF", "title": "Graph-based Generalization Bounds for Learning Binary Relations", "authors": ["Ben London", "Bert Huang", "Lise Getoor"], "emails": ["blondon@cs.umd.edu", "bert@cs.umd.edu", "getoor@cs.umd.edu"], "sections": [{"heading": null, "text": "We investigate the generalizability of learned binary relations: functions that map pairs of instances to a logical indicator. This problem has application in numerous areas of machine learning, such as ranking, entity resolution and link prediction. Our learning framework incorporates an example labeler that, given a sequenceX of n instances and a desired training size m, subsamples m pairs from X \u00d7X without replacement. The challenge in analyzing this learning scenario is that pairwise combinations of random variables are inherently dependent, which prevents us from using traditional learning-theoretic arguments. We present a unified, graph-based analysis, which allows us to analyze this dependence using well-known graph identities. We are then able to bound the generalization error of learned binary relations using Rademacher complexity and algorithmic stability. The rate of uniform convergence is partially determined by the labeler\u2019s subsampling process. We thus examine how various assumptions about subsampling affect generalization; under a natural random subsampling process, our bounds guarantee O\u0303(1/ \u221a n) uniform convergence."}, {"heading": "1 Introduction", "text": "We investigate the generalizability of a learned binary relation: a characteristic function r : X 2 \u2192 {\u00b11} that indicates whether the input pair satisfies a relation. For example, if r is an equivalence relation, then r(x, x\u2032) = 1 indicates that x \u2261 x\u2032; if r is a total ordering, then r(x, x\u2032) = 1 means that x \u2264 x\u2032. Binary relations are found in many learning problems, such as ranking (total ordering), entity resolution (equivalence) and link prediction. There has been significant\nresearch in each of these fields individually, yet no unified view of the learning problem. We formulate the learning objective (in Section 2) as inductive inference on a product space X 2, where instances are drawn from an arbitrary distribution over X . Given a set of n independently and identically distributed (i.i.d.) instances X \u2208 Xn, as well as a subset from X2 that has been labeled by r, our goal is to produce a hypothesis h : X 2 \u2192 {\u00b11} that, with high probability, has low error w.r.t. r.\nThe primary challenge in analyzing this learning setup is reasoning about the dependency structure of a pairwise training set. Even though the instances are i.i.d., the training examples may not be; since each instance may appear in multiple examples, those that involve a common instance are necessarily dependent. This dependence makes the analysis of generalization nontrivial, since it violates the fundamental assumption of independence used in classical statistics and learning theory, rendering existing results incompatible. When the training set does not simply contain all pairs of instances, its dependency structure is difficult to analyze.\nIn Section 3, we introduce graphical representations of the training set and its dependency structure. The training set is viewed as a graph G, in which each instance is a vertex and each pairwise example is an (undirected) edge. The dependency structure is represented by the corresponding line graph GD, since edges that share a common vertex (instance) are adjacent in GD. Casting the dependency structure as a graph allows us to leverage the vast literature of graph theory, which makes our analysis cleaner. The \u201camount of dependence\u201d can be quantified by the chromatic number of GD, since the chromatic number is the minimal number of independent sets. Using well-known chromatic properties, we are able to upper bound this quantity. We then use graph-based arguments in Section 4 to bound the generalization error of learned binary relations, using Rademacher complexity or algorithmic stability. We show that the empirical error ar X\niv :1\n30 2.\n53 48\nv3 [\ncs .L\nG ]\n3 1\nM ay\n2 01\nconverges to the expected error at a rate of O( \u221a \u03c1/m), where m is the number of labeled training pairs and \u03c1 is the maximum frequency of any instance in this set. This ratio depends on how pairs are subsampled (irrespective of their values). Consequently, in Section 5, we explore several learning scenarios in which the subsampling process is working for, against, or is agnostic to the learner (i.e., random). Using a reduction to a random graph model, we prove interesting results for the agnostic scenario. We thus provide a novel analysis of the relationship between subsampling and the rate of uniform convergence for learned binary relations."}, {"heading": "1.1 Related Work", "text": "Goldman et al. [1993] were the first to address learning a binary relation. Their learning setting is entirely different from ours, in that there is no underlying distribution from which instances are generated, and they are not interested in generalization to unseen data. In their setting, the problem size is polynomial in a finite number of objects. Our learning setting subsumes this one.\nOur main analytic tools come from two areas of learning theory: Rademacher complexity and algorithmic stability. The canonical Rademacher bounds are due to Koltchinskii and Panchenko [2002] and Bartlett and Mendelson [2003], while the canonical stability bounds are due to Bousquet and Elisseeff [2002]. Though all of these techniques fundamentally rely on independence, there have been recent applications to non-i.i.d. problems. Inspired by Janson [2004], Usunier et al. [2006] developed a theory of chromatic Rademacher analysis, using it to derive generic risk bounds for dependent data, with bipartite ranking as a motivating example. (Ralaivola et al. [2010] used a similar chromatic analysis to derive PAC-Bayes bounds.) Our analysis draws on this work, though we delve deeper into the setting of pairwise prediction. More recently, Mohri and Rostamizadeh [2009, 2010] used an \u201cindependent blocking\u201d technique to derive both Rademacher- and stability-based risk bounds for time series data drawn from a strongly-mixing stationary process, though this is an entirely different form of dependence.\nA number of authors [Bar-Hillel and Weinshall, 2003, Cle\u0301menc\u0327on et al., 2008, Jin et al., 2009] have developed risk bounds for problems involving pairwise prediction (or learning with pairwise constraints), though they all assume that the training set contains all pairwise combinations of the instances, ignoring the more interesting problem of learning from a (sparse) subsample. Our results are not only more general, but they offer insight into how the subsampling process affects the rate of convergence. Agarwal and Niyogi [2009] consider a random subsampling process similar to one we\ndiscuss and derive risk bounds for ranking using algorithmic stability. We provide an alternate analysis that is clean, natural and interpretable."}, {"heading": "2 Preliminaries", "text": "This section introduces the necessary background concepts. To clarify certain probabilities, we let Pr\u03c9[\u00b7] denote the probability of an event w.r.t. a random draw of \u03c9 from an implicit sample space \u2126. Similarly, let E\u03c9[\u00b7] denote the expectation of a random variable w.r.t. a random draw of \u03c9 \u2208 \u2126, according to an implicit probability distribution."}, {"heading": "2.1 Problem Setting", "text": "Let X denote an abstract instance space (e.g., X could be a subset of Euclidean space). We are interested in learning a binary relation r : X 2 \u2192 {\u00b11}. We will limit our analysis to relations that are reflexive, and either symmetric or antisymmetric, examples of which include equivalence and total ordering.\nWe define the learning process as follows. We are given a sequence of instances X , (x1, . . . , xn) \u2208 Xn, drawn independently and identically from an arbitrary distribution over X . We are also given access to a labeler S, a black-box process that returns a subset of pairwise labeled examples. More precisely, given an input X and a training size m, Sm(X) returns some subset of X2 (sampled without replacement) that has been labeled according to r. In practice, this could be a crowd-sourcing application or a targeted surveying process. The subset returned by Sm(X) is sampled according to a process that is independent of the instance values X. Restricting our theory to consider only labelers that determine which pairs to label, independent of X, ensures that the observed data is drawn from the original distribution; otherwise, the labeler could introduce bias. Within this restriction, the subsampling process remains unknown. It may be adversarial or benign, aiming to either weaken or improve generalization; it may also be agnostic, selecting pairs according to some random process. We will return to the topic of subsampling in Section 5.\nDue to our assumption of (anti)symmetry, only one example per pair is required, since the converse (or contrapositive) can be inferred from context. This means that m is naturally upper bounded by ( n 2 ) . Upon receiving a labeled dataset Z \u2190 Sm(X), we invoke a learning algorithm A to obtain an inductive hypothesis h from a class H of functions from X 2 to {\u00b11}. We let hZ (or, more explicitly, hZ \u2190 A(Z)) denote the hypothesis trained on the dataset Z."}, {"heading": "2.2 Generalization", "text": "For a given cost function c : R2 \u2192 R+, define the loss ` of a hypothesis h w.r.t. a pair z , (x, x\u2032) as `(h, z) , c(r(z), h(z)). Though there are various cost functions, for learning binary relations, we are most interested in the so-called 0-1 loss, `1(h, z) , 1[r(z) 6= h(z)].\nThe quantity we are primarily concerned with is the generalization error, or risk. This is the expected loss of a learned hypothesis hZ w.r.t. a random pair z\u0303 , (x, x\u2032), where x and x\u2032 are sampled independently and identically from the underlying distribution over X . We denote this quantity by R(hZ) , Ez\u0303[`(hZ , z\u0303)]. In practice, we can estimate the true risk with the training error, computed as the average loss over all examples in the training set. We denote this by R\u0302(hZ) , 1m \u2211 z\u2208Z `(hZ , z).\nGiven an empirical risk estimate, we would like to bound its deviation from the true risk. We will refer to this quantity as the defect, which we denote by D(hZ) , R(hZ) \u2212 R\u0302(hZ). We will use the canonical probably approximately correct (PAC) framework [Valiant, 1984], in which we allow the defect to exceed an arbitrary > 0 with probability \u03b4 \u2208 (0, 1). There are a number of ways of analyzing this probability, of which we will focus on hypothesis complexity and algorithmic stability. Analyses of this nature typically aim to bound\nPr [ sup h\u2208H D(h) \u2265 ] or Pr [ sup hZ\u2190AZ D(hZ) \u2265 ] .\nSolving for , one obtains a probabilistic upper bound on the true risk, parameterized by \u03b4."}, {"heading": "3 Graphical Representation", "text": "In this section, we analyze the learning problem and its inherent dependencies using a graphical representation."}, {"heading": "3.1 Training Data", "text": "Recall that the training set, returned by the labeler S, is an arbitrary subset of X2 that has been labeled according to r. We can represent this as a graph G , (V,E), in which each vertex vi \u2208 V corresponds to an instance xi, and each training example (xi, xj , r(xi, xj)) \u2208 Z defines an (un)directed edge (i, j) \u2208 E. Thus, the subsampling pattern reduces to a graph on the instances X. Note that, if r is antisymmetric, then G will be directed; however, since only one example per pair is needed, the corresponding undirected graph is simple (i.e., not a multigraph). This graph representation simplifies the analysis of\ngeneralization and allows the labeler\u2019s subsampling to be viewed as one of many well-studied graph generation processes.\nFor example, we can consider an agnostic, random labeler that selects pairs uniformly at random. Using the above graphical representation, this subsampling process can be modeled by the Erdo\u0308s-Re\u0301nyi random graph model G(n,m). In this model, a graph with n vertices and m edges is chosen uniformly from the set of all such graphs. (This model differs slightly from the popular G(n, p) model, in which each edge is realized independently with probability p.) We analyze generalization using various labeler scenarios, including the G(n,m) labeler, in Section 5."}, {"heading": "3.2 Dependency Structure", "text": "For each instance xi, define a random variable Xi, and recall that these are i.i.d. For each example pair (xi, xj) found in Z, define a random variable Zi,j , (Xi, Xj). Because each instance may appear in multiple pairs, we have that these random variables are not mutually independent. To make this more concrete, consider the set {Z1,2, Z2,3, Z3,4}. Clearly, Z1,2 and Z2,3 are dependent, since they include a common variable, X2. Now consider variables Z1,2 and Z3,4, and note that {1, 2} \u2229 {3, 4} = \u2205. Observing (X1, X2) reveals nothing about (X3, X4); thus, P(Z3,4 | Z1,2) = P(Z3,4), and vice versa, so they are mutually independent.\nWe will represent the dependency structure using a graphical representation due to Erdo\u0308s and Lova\u0301sz [1975], known as a dependency graph.\nDefinition 1 (Dependency Graph). Let Z , {Zi}ni=1 be a set of random variables with joint distribution P(Z), and let GD , (V,E) be a graph, with V , [n]. Then GD forms a dependency graph w.r.t. Z if every independent set (i.e., set of non-adjacent vertices) I \u2286 V satisfies P({Zi}i\u2208I) = \u220f i\u2208I P(Zi).\nIn the context of learning binary relations, we construct a dependency graph GD in which each vertex vi,j is connected to vertices {vk,` : (k = i)\u2228 (` = j)}\u2014 i.e., the set of vertices that involve instances xi or xj . As a result, any independent set of vertices (in the graph-theoretic sense) is a set of independent random variables. To better understand the structure of this dependency graph, it helps to recall the graph G defined in the previous section; GD is in fact its corresponding line graph, a graph representing the adjacencies between edges.1 Therefore, every independent set in GD is a matching in G.\n1If G is directed, then GD is the line graph of its corresponding undirected graph."}, {"heading": "3.3 Chromatic Properties", "text": "In this section, we discuss the chromatic properties of the above graphical representations, which will introduce a key lemma used in our generalization bounds. For completeness, we first review some background on graph coloring. For the following definitions, let G , (V,E) be an arbitrary undirected graph.\nDefinition 2 (Vertex Coloring). A proper k-vertexcoloring (often simply referred to as simply a kcoloring) is a mapping from V to a set of k color classes, such that no two adjacent vertices have the same color. Equivalently, it is a partitioning {Cj : Cj \u2286 V }kj=1, such that \u22c3k j=1 Cj = V , \u22c2k j=1 Cj = \u2205, and every subset Cj is independent. The chromatic number \u03c7(G) is the minimum number of colors needed to achieve a proper coloring.\nDefinition 3 (Edge Coloring). A proper k-edgecoloring is a mapping from E to a set of k color classes, such that no two coincident edges have the same color. The chromatic index \u03c7\u2032(G) is the minimum number of colors needed to achieve a proper edge coloring.\nTheorem 1 (Vizing, 1964). If G has maximum degree \u2206(G), then \u2206(G) \u2264 \u03c7\u2032(G) \u2264 \u2206(G) + 1.\nFor a dependency graph, the chromatic number can be viewed roughly as the \u201camount of dependence\u201d. The lower the chromatic number, the more independence. If the variables are i.i.d., then the chromatic number is 1. Coloring the vertices of the dependency graph GD described in Section 3.2 can be reduced to coloring the edges of the graph G described in Section 3.1, since one is simply the line graph of the other. The chromatic index of G is equal to the chromatic number of GD, so bounding one quantity bounds the other. Although there are many graphs for which \u03c7\u2032(G) = \u2206(G), determining the chromatic index of an arbitrary graph is NP-hard, so we will rely on the upper bound. We can therefore state the amount of dependence in terms of the chromatic index of G. Note that the maximum degree \u2206(G) is simply the maximum frequency of any instance in the training set, which yields the following lemma.\nLemma 1. Let X \u2208 Xn be a set of n i.i.d. instances, and Z \u2190 Sm(X) an arbitrary training set of size m, with maximum instance frequency \u03c1. Let GD be the corresponding dependency graph of Z. Then, \u03c7(GD) \u2264 \u03c1+ 1."}, {"heading": "4 Generalization Bounds", "text": "In this section, we develop risk bounds for learning binary relations using both the Rademacher complexity and algorithmic stability."}, {"heading": "4.1 Concentration Inequalities", "text": "A key component in any generalization analysis is the concentration of random variables. We now present two tail bounds that will be used in our proofs.\nTheorem 2 (McDiarmid, 1989). Let Z , {Zi}ni=1 be a set of i.i.d. random variables that take values in Z. Let f : Zn \u2192 R be a measurable function for which there exist constants {\u03b1i}ni=1 such that, for any i \u2208 [n], and any inputs Z,Z \u2032 \u2208 Zn that differ only in the ith variable, |f(Z)\u2212 f(Z \u2032)| \u2264 \u03b1i. Then, for any > 0,\nPr [f(Z)\u2212 E[f(Z)] \u2265 ] \u2264 exp ( \u22122 2\u2211n i=1 \u03b1 2 i ) .\nTheorem 3 (Usunier et al., 2006). Let GD be a dependency graph (Definition 1) for a set of random variables Z , {Zi}ni=1 that take values in Z. Let {Zj}\u03c7(GD)j=1 denote the subsets induced by an optimal proper coloring of GD, and let nj , |Zj |. Finally, let f : Zn \u2192 R be a measurable function where: (a) there exist functions {fj : Znj \u2192 R}\u03c7(GD)j=1 , such that f(Z) = \u2211 j fj(Zj); (b) there exists a constant \u03b1 such that every fj is \u03b1-Lipschitz w.r.t. the Hamming metric. Then, for any > 0,\nPr [f(Z)\u2212 E[f(Z)] \u2265 ] \u2264 exp ( \u22122 2\n\u03c7(GD)n\u03b12\n) ."}, {"heading": "4.2 Rademacher Complexity", "text": "Informally, the Rademacher complexity measures a hypothesis class\u2019 expressive power, quantified by its ability to fit a random signal. We slightly adapt the traditional definition to better suit our learning context.\nDefinition 4 (Rademacher Complexity). Let X be an instance space, and Z some alternate space. Let \u03d5 : Xn \u2192 Zm denote a mapping from n instances from X to m instances from Z. Let \u03c3 be a set of Rademacher variables that independently take values in {\u00b11} with equal probability. For a class F of functions from Z to R, define the empirical Rademacher complexity of F \u25e6 \u03d5, w.r.t. instances X \u2208 Xn, as\nRX(F \u25e6 \u03d5) , E\u03c3\n[ 2\nm sup f\u2208F \u2223\u2223\u2223\u2223\u2223 m\u2211 i=1 \u03c3if(zi) \u2223\u2223\u2223\u2223\u2223 ] .\nDefine the Rademacher complexity of F\u25e6\u03d5, w.r.t. i.i.d. samples of size n, as Rn(F \u25e6 \u03d5) , EX [RX(F \u25e6 \u03d5)].\nIn our scenario, the data may exhibit dependencies; yet, as we will see, this does not affect the traditional symmetry argument used in Rademacher analysis.\nTheorem 4. Let X \u2208 Xn be an i.i.d. sample of n instances, and Z \u2190 Sm(X) an arbitrary training set\nof size m, with maximum instance frequency \u03c1. Let F be a class of functions from Z , X 2 to [0, 1]. Then, for any n \u2265 2, any m \u2265 1, any f \u2208 F , and any \u03b4 \u2208 (0, 1), with probability at least 1\u2212 \u03b4 over draws of X,\nEz\u0303[f(z\u0303)] \u2264 1\nm \u2211 z\u2208Z f(z) + Rn(F \u25e6 Sm) + \u221a \u03c1+ 1 2m ln 1 \u03b4 .\n(1)\nProof With GD as the dependency graph of Z, we invoke an optimal proper coloring, which partitions Z into \u03c7(GD) \u2264 \u03c1 + 1 (via Lemma 1) independent sets. We can consequently express the defect D(f) , Ez\u0303[f(z\u0303)] \u2212 1m \u2211 z\u2208Z f(z) as a sum over functions of independent random variables. It is easy to show that each of these functions is (1/m)-Lipschitz w.r.t. the Hamming metric. We therefore apply Theorem 3 and obtain\nPr X [ sup f\u2208F D(f)\u2212 EX [sup f\u2208F D(f)] \u2265 ] \u2264 exp ( \u22122 2m \u03c1+ 1 ) ,\n(2) To bound EX [supf\u2208F D(f)], we start by imagining a \u201cghost sample\u201d X \u2032 of n i.i.d. instances that have been labeled using the same pattern as Z to create Z \u2032. Note that Ez\u0303[f(z\u0303)] = EX\u2032 [ 1 m \u2211 z\u2032\u2208Z\u2032 f(z \u2032) ]\nvia linearity of expectation, since all z\u2032 have the same marginal distribution. Using the ghost sample and Jensen\u2019s inequality, we have that\nEX [sup f\u2208F D(f)] = EX [ sup f\u2208F Ez\u0303[f(z\u0303)]\u2212 1 m \u2211 z\u2208Z f(z) ]\n= EX [ sup f\u2208F EX\u2032 [ 1 m \u2211 z\u2032\u2208Z\u2032 f(z\u2032) ] \u2212 1 m \u2211 z\u2208Z f(z) ]\n\u2264 EX,X\u2032 [\nsup f\u2208F\n1\nm m\u2211 i=1 f(z\u2032i)\u2212 f(zi)\n] . (3)\nNow define a set of Rademacher variables \u03c3, and define random variables {Zi}mi=1 and {Z \u2032i}mi=1 for Z and Z \u2032 sets respectively. Because they are labeled using the same pattern, and have isomorphic dependency graphs, we have that P(Z1, . . . , Zm) = P(Z \u20321, . . . , Z \u2032m). In fact, if we exchange any Zi and Z \u2032 i, we have that P(Z1, . . . , Z \u2032i, . . . , Zm) = P(Z \u20321, . . . , Zi, . . . , Z \u2032m). Thus, since every draw of \u03c3 occurs with equal probability, we have via symmetry that\nEq. (3) \u2264 EX,X\u2032,\u03c3 [ sup f\u2208F 1 m m\u2211 i=1 \u03c3i(f(z \u2032 i)\u2212 f(zi)) ]\n\u2264 EX,\u03c3 [ sup f\u2208F 2 m \u2223\u2223\u2223\u2223\u2223 m\u2211 i=1 \u03c3if(z \u2032 i) \u2223\u2223\u2223\u2223\u2223 ] \u2264 Rn(F \u25e6 Sm).\nand so EX [supf\u2208F D(f)] \u2264 Rn(F \u25e6 Sm). To obtain Equation 1, we simply set Equation 2 equal to \u03b4 and\nsolve for .\nIt is possible to derive a similar risk bound for the empirical Rademacher complexity by applying Theorem 3 to the difference of Rn(F \u25e6 Sm) \u2212 RX(F \u25e6 Sm). We omit this proof to save space, since the remainder of our work does not require the empirical Rademacher complexity.\nTo make these bounds more functional, we will replace Rn with an empirically verifiable quantity. For certain hypothesis classes, it is possible to show that the Rademacher complexity is bounded by a function of the model parameters. One such class of hypotheses is reproducing kernel Hilbert spaces (RKHS), which subsume the popular support vector machine (SVM) [Cristianini and Shawe-Taylor, 2000]. Formally, for some mapping \u03c6 : Z \u2192 Z\u0303, where Z is an instance space and Z\u0303 is a Hilbert space, endowed with an inner product \u3008\u00b7, \u00b7\u3009, a kernel \u03ba : Z2 \u2192 R is a function such that, for all (z, z\u2032) \u2208 Z2, \u03ba(z, z\u2032) = \u3008\u03c6(z), \u03c6(z\u2032)\u3009. The only requirement is that the kernel\u2019s Gram matrix K : Ki,j = \u03ba(zi, zj) be symmetric and positive semidefinite. RKHS hypotheses are generally of the form h\u03ba,Z(z) , \u2211m z\u2032\u2208Z \u03ba(z, z\n\u2032), where Z \u2208 Zm is a set of reference points from the problem domain (e.g., support vectors). We may reasonably assume that the norm of the kernel mapping is uniformly bounded by a constant C; i.e., the mapped data is contained within a ball of radius C. We denote the class of kernel functions by H\u03ba. Borrowing results from Koltchinskii and Panchenko [2002] and Bartlett and Mendelson [2003], we are able to prove the following risk bounds for kernel-based hypotheses with bounded kernels, in the context of learning binary relations.\nFor the following, we use the ramp loss as a surrogate for the 0-1 loss. For a given \u03b3 > 0, a realvalued hypothesis h : X 2 \u2192 R and an example z, define the ramp loss as `\u03b3(h, z) , min{max{0, 1 \u2212 r(z)h(z)/\u03b3}, 1}. To differentiate this from the 0-1 loss when dealing with risk metrics, we henceforth use a superscript 1 or \u03b3. Theorem 5. Let X \u2208 Xn, Z \u2190 Sm(X) and \u03c1 be as defined in Theorem 4. Let h\u03ba,Z be a RKHS hypothesis trained on Z, such that supz ||\u03c6(z)|| \u2264 C. Then, for any n \u2265 2, any m \u2265 1, any \u03b3 > 0, and any \u03b4 \u2208 (0, 1), with probability at least 1\u2212 \u03b4 over draws of X,\nR1(h\u03ba,Z) \u2264 R\u0302\u03b3(h\u03ba,Z) + 4C\n\u03b3 \u221a m +\n\u221a \u03c1+ 1\n2m ln\n1 \u03b4 . (4)\nProof Note that `\u03b3 dominates `1, and thus R1(h\u03ba,Z) \u2264 R\u03b3(h\u03ba,Z). Since the ramp loss is bounded by [0, 1], we apply Theorem 4 and obtain\nR1(hZ) \u2264 R\u0302\u03b3(hZ) + Rn(`\u03b3\u25e6H\u03ba\u25e6Sm) + \u221a \u03c1+ 1\n2m ln\n1 \u03b4 .\nTo bound Rn(`\u03b3 \u25e6 H\u03ba \u25e6 Sm), we use Talagrand\u2019s contraction lemma [Ledoux and Talagrand, 1991] and borrow a result from Bartlett and Mendelson [2003, Lemma 22], from which we obtain\nRn(`\u03b3 \u25e6 H\u03ba \u25e6 Sm) \u2264 2\n\u03b3 Rn(H\u03ba \u25e6 Sm) \u2264\n2 \u03b3 \u00b7\n2 \u221a tr(K)\nm .\nUsing Cauchy-Schwarz, we can bound the trace of the kernel\u2019s Gram matrix as\ntr(K) = \u2211 z\u2208Z \u3008\u03c6(z), \u03c6(z)\u3009 \u2264 \u2211 z\u2208Z ||\u03c6(z)||2 \u2264 mC2.\nWe therefore have that Rn(`\u03b3 \u25e6 H\u03ba \u25e6 Sm) \u2264 4C\u03b3\u221am .\nNote that this analysis slightly improves upon that of Usunier et al. [2006] in that we use the regular Rademacher complexity instead of their so-called fractional Rademacher complexity. Because of this, our Rademacher term is O(1/ \u221a m), compared to\nO( \u221a \u03c1/m) using the fractional Rademacher complexity; note that 1/ \u221a m \u2264 \u221a \u03c1/m for all \u03c1 \u2265 1."}, {"heading": "4.3 Algorithmic Stability", "text": "This section derives a different generalization bound for learning pairwise relations using our previous graph representations and algorithmic stability.\nDefinition 5 (Uniform Stability). For a training set Z, let Z \u2032 be a duplicate of Z with the ith example removed. A learning algorithm A has uniform stability \u03b2 w.r.t. a loss function ` if, for any Z \u2208 Zm, and any i \u2208 [m], A returns hypotheses hZ \u2190 A(Z) and hZ\u2032 \u2190 A(Z \u2032) such that\nsup z\u0303\u2208Z |`(hZ , z\u0303)\u2212 `(hZ\u2032 , z\u0303)| \u2264 \u03b2.\nIn other words, excluding any single example from training will increase the loss, w.r.t. any test example z\u0303, by at most \u03b2. Of course, \u03b2 must be a function of the size of the training set; indeed, we will later show that generalization is only possible when \u03b2 = O(1/m). To highlight this dependence, we henceforth use the notation \u03b2m. Using this notion of stability, we now derive alternate risk bounds for learning binary relations.\nLemma 2 (Bousquet and Elisseeff, 2002). Let A be a learning algorithm with uniform stability \u03b2 w.r.t. a loss function `, where ` is upper bounded by M . Then, for any i \u2208 [m], and any training sets Z,Z \u2032 \u2208 Zm that differ only in the value of the ith example, A returns hypotheses hZ \u2190 A(Z) and hZ\u2032 \u2190 A(Z \u2032, G) such that\n|D(hZ)\u2212D(hZ\u2032)| \u2264 4\u03b2m + M\nm .\nTheorem 6. Let X \u2208 Xn be an i.i.d. sample of n instances, and Z \u2190 Sm(X) an arbitrary training set of size m, with maximum instance frequency \u03c1. Let A be a learning algorithm with uniform stability \u03b2 w.r.t. a loss function ` (upper bounded by M), and let hZ \u2190 A(Z). Then, for any n \u2265 2, any m \u2265 1, and any \u03b4 \u2208 (0, 1), with probability at least 1\u2212 \u03b4 over draws of X,\nR(hZ) \u2264 R\u0302(hZ)+4\u03c1\u03b2m+(4m\u03b2m+M) \u221a \u03c1\nm ln\n1 \u03b4 . (5)\nProof We begin by showing that the defect satisfies the conditions of McDiarmid\u2019s inequality (Theorem 2). By Lemma 2, replacing any single example will change the defect by at most 4\u03b2m +M/m. However, if we replace any single instance xi, this will affect up to \u03c1i examples, where \u03c1i denotes the frequency of xi in the training set. We therefore have that replacing any xi has Lipschitz constant \u03b1i = \u03c1i(4\u03b2m + M/m). Since the instances are i.i.d., we can apply McDiarmid\u2019s inequality and obtain\nPr X\n[D(hZ)\u2212 EX [D(hZ)]] \u2264 exp (\n\u22122 2\u2211n i=1 \u03c1 2 i (4\u03b2m +M/m) 2 ) \u2264 exp ( \u22122 2m2\n(4m\u03b2m +M)2\u03c1 \u2211n i=1 \u03c1i ) = exp ( \u2212 2m\n(4m\u03b2m +M)2\u03c1\n) .\nThe last line is due to the handshaking lemma, which states that the sum of the degrees (i.e., instance frequencies) in a graph is equal to twice the number of edges (i.e., examples). Setting the above equal to \u03b4 and solving for , we have that\nR(hZ) \u2264 R\u0302(hZ)+EX [D(hZ)]+(4m\u03b2m+M) \u221a \u03c1\nm ln\n1 \u03b4 .\nWhat remains is to upper bound the expected defect. Using linearity of expectation, we can state this as\nEX [D(hZ)] = 1\nm m\u2211 i=1 EX,z\u0303[`(hZ , z\u0303)\u2212 `(hZ , zi)].\nNote that example zi = (x, x \u2032) depends on any examples that share either x or x\u2032, i.e., its neighborhood N (zi) in the dependency graph. However, by removing zi and N (zi) from the training set, zi becomes independent of any of the remaining examples. Accordingly, let Z \u2032 , Z\\{zi,N (zi)}, and let hZ\u2032 be the resulting hypothesis. Because we have removed deg(zi) + 1 examples from training, by uniform stability, we pay a penalty of at most \u03b2m(deg(zi)+1) loss per prediction.\nFurther, recall that GD is the line graph of the graph G defined in Section 3.1. It is therefore easy to show that any node in GD (i.e., edge in G) has degree equal to the sum of the degrees of its endpoints in G, minus two; hence, deg(zi)+1 = deg(x)+deg(x\n\u2032)\u22121 \u2264 2\u03c1\u22121. We therefore have that\nEX [D(hZ)] \u2264 1\nm m\u2211 i=1 EX,z\u0303[`(hZ\u2032 , z\u0303)\u2212 `(hZ\u2032 , zi)]\n+ 2\u03b2m(deg(zi) + 1)\n= 2\u03b2m m m\u2211 i=1 0 + deg(zi) + 1 \u2264 2\u03b2m(2\u03c1\u2212 1) \u2264 4\u03c1\u03b2m,\nwhere the second line follows from symmetry, since z and zi are now i.i.d. variables.\nTo obtain a non-vacuous bound, we require that \u03b2m = O(1/m). This precludes stability w.r.t. the 0-1 loss `1, since any algorithm will have either \u03b2 = 0 or \u03b2 = 1, regardless of m. We therefore use the ramp loss `\u03b3 again. To use the ramp loss, we introduce the notion of classification stability. For the following, we consider learning algorithms that output a real-valued hypothesis h : Z \u2192 R, where sgn(h(z)) is the predicted label of z.\nDefinition 6 (Classification Stability). Let Z and Z \u2032 be as defined in Definition 5. A learning algorithm A has classification stability \u03b2 if, for any Z \u2208 Zm, and any i \u2208 [m], A returns real-valued hypotheses hZ \u2190 A(Z) and hZ\u2032 \u2190 A(Z \u2032) such that\nsup z\u0303\u2208Z |hZ(z\u0303)\u2212 hZ\u2032(z\u0303)| \u2264 \u03b2.\nLemma 3 (Bousquet and Elisseeff, 2002). A learning algorithm with classification stability \u03b2 has uniform stability \u03b2/\u03b3 w.r.t. the ramp loss `\u03b3 . Theorem 7. Let X \u2208 Xn, Z \u2190 Sm(X) and \u03c1 be as defined in Theorem 6. Let A be a learning algorithm with classification stability \u03b2, and let hZ \u2190 A(Z). Then, for any n \u2265 2, any m \u2265 1, any \u03b3 > 0, and any \u03b4 \u2208 (0, 1), with probability at least 1\u2212 \u03b4 over draws of X,\nR1(hZ) \u2264 R\u0302\u03b3(hZ) + 4\u03c1\u03b2m \u03b3 + ( 4m\u03b2m \u03b3 + 1 )\u221a \u03c1 m ln 1 \u03b4 .\n(6)\nProof The proof follows directly from Theorem 6 and Lemma 3, with the ramp loss obviously upper bounded by M = 1.\nThe application of this bound still depends on a stability parameter, which is unique to the learning algorithm. As a demonstration, we will focus on the class\nof kernel methods described in Section 4.2; specifically, SVM classification. Recall that, using stability analysis, generalization is made possible by properties of the learning algorithm, not the complexity of the hypothesis class. For the class of kernel methods in particular, this mechanism is regularization. We define a kernelbased regularization algorithm as one of the form\nA\u03ba(Z) , argmin h\u2208H\u03ba\n1\nm \u2211 z\u2208Z `(h, z) + \u03bb ||h||2 ,\nwhere \u03bb > 0 is a regularization parameter. The loss function varies, depending on the application and algorithm. In SVM classification, it is common to minimize the hinge loss, defined as `h(h, z) , max{0, 1 \u2212 r(z)h(z)}. Denote the empirical hinge risk by R\u0302h. Using a stability result from Bousquet and Elisseeff [2002], we obtain a risk bound for SVM classification.\nLemma 4 (Bousquet and Elisseeff, 2002). An SVM learning algorithm, with supz ||\u03c6(z)|| \u2264 C and regularization parameter \u03bb > 0, has classification stability \u03b2m \u2264 C2/(2\u03bbm). Theorem 8. Let X \u2208 Xn, Z \u2190 Sm(X) and \u03c1 be as defined in Theorem 6. Let A\u03ba be an SVM learning algorithm, with supz ||\u03c6(z)|| \u2264 C and \u03bb > 0, and let h\u03ba,Z \u2190 A\u03ba(Z). Then, for any n \u2265 2, any m \u2265 1, and any \u03b4 \u2208 (0, 1), with probability at least 1\u2212\u03b4 over draws of X,\nR1(h\u03ba,Z) \u2264 R\u0302h(h\u03ba,Z)+ 2\u03c1C2\n\u03bbm +\n( 2C2\n\u03bb + 1\n)\u221a \u03c1\nm ln\n1 \u03b4 . (7)\nProof Clearly, for \u03b3 = 1, R\u0302h dominates R\u0302\u03b3 . We therefore apply Theorem 7, with \u03b3 = 1 and \u03b2 = C2/(2\u03bbm)."}, {"heading": "4.4 Discussion of Bounds", "text": "Our bounds are dominated by the term \u03c1/m, where \u03c1 is the maximum instance frequency (equivalently, the maximum degree in G) and m is the number of examples (edges). We refer to the inverse of this ratio as the effective training size. Letting \u03c1i denote the frequency (i.e., degree) of instance xi, we have that\n\u03c1 m = 2\u03c1\u2211n i \u03c1i = 2\u2211n i \u03c1i/\u03c1 ,\nIt is straightforward to show that this quantity is minimized when G is regular\u2014that is, when \u03c1i is uniform. In fact, for any regular G, we have that \u03c1/m = 2/n.\nAssuming one cannot acquire new examples, one can discard examples to make a regular graph, which gives\nthe optimal ratio. This is equivalent to finding a kregular spanning subgraph (i.e., k-factor), for some k \u2265 1. This is not always possible without reducing the number of instances (i.e., vertices), as some graphs do not admit such a k-factor. For example, if the highest degree vertex is adjacent to multiple degree1 vertices (as in a star graph), then certain vertices will be \u201cisolated\u201d when edges are removed. In fact, the effective number of instances n\u2032 is the order of the largest k-regular induced subgraph, for some k \u2265 1; we therefore have that the effective training size is upper bounded by n\u2032/2. That said, identifying n\u2032 for an arbitrary graph is NP-hard.\nIt is tempting to think that, by discarding examples to induce a 1-regular subgraph, one can reduce our learning setup to the i.i.d. scenario and consequently apply classical analysis. However, there may be a regular (sub)graph of higher degree that yields a better effective training size. For instance, consider a graph consisting of t disjoint triangles (i.e., n = 3t); this graph is already 2-regular, so without pruning edges it has an effective training size n/2 = 3t/2; if pruned to a 1-regular subgraph, the effective training size would be just t. Moreover, while the above shows that discarding examples might minimize our bounds, without intimate knowledge of the learning algorithm, hypothesis class or distribution, our bounds may be overly pessimistic in certain scenarios. Stronger assumptions may lead to tighter risk bounds, to support the intuition that more training data\u2014albeit dependent data\u2014will always improve generalization."}, {"heading": "5 On Subsampling and the Rate of Uniform Convergence", "text": "We have shown that the empirical risk converges to the true risk at a rate of O( \u221a \u03c1/m), depending primarily on the size of the training set and the maximum frequency of any instance. While m may be determined by one\u2019s annotation or computation budget, \u03c1 depends on the subsampling used to select the training set. In this section, we examine the relationship between the subsampling process used by the labeler and the rate of uniform convergence.\nRecall that the labeler cannot subsample based on the values of the input data, but it can subsample patterns that help or hurt generalization. If the labeler is working against the learner, it can select pairs such that one instance appears in all training examples, meaning \u03c1 = m. In this scenario, our bounds indicate that a hypothesis learned from this training set might not generalize. In contrast, if the labeler is working with the learner, it can subsample pairs so as to induce a regular label graph, as discussed in the previous sec-\ntion. This would yield an optimal convergence rate of O(1/ \u221a n), comparable to classical results.\nWe may also consider a setting in which the subsampling is a random process. For example, if the labeler selects pairs uniformly at random without replacement, then, as previously noted, this process can be modeled by the Erdo\u0308s-Re\u0301nyi random graph model. We then have that the rate of convergence is a function of the maximum degree of G(n,m), since this is equivalent to the maximum instance frequency.\nLemma 5. Let G , (V,E) be a graph in G(n,m), for a given n and m. Then, with probability at least 1\u2212 \u03b4, its maximum degree \u2206(G) is upper bounded as\n\u2206(G) \u2264 2m n\n( 1 + \u221a 3n\n2m ln n \u03b4\n) . (8)\nWe provide the proof in Appendix A.\nUsing this as an upper bound for \u03c1 (since \u03c1 = \u2206(G)), we obtain the following corollary of Theorem 5. A similar result can be shown for Theorem 8.\nTheorem 9. Let X \u2208 Xn, Z \u2190 Sm(X), h\u03ba,Z , C and \u03bb be as previously defined. If S samples m examples uniformly at random from X2, then, for any n \u2265 2, any m \u2265 n/2, any \u03b3 > 0, and any \u03b4 \u2208 (0, 1), with probability at least 1 \u2212 \u03b4 over draws of X, and \u03b7 , 1 + \u221a 3n 2m ln 2n \u03b4 ,\nR1(h\u03ba,Z) \u2264 R\u0302\u03b3(h\u03ba,Z) + \u221a 32C\n\u03b3 \u221a n +\n\u221a \u03b7 + 1\nn ln\n2 \u03b4 . (9)\nProof Equation 9 follows from Theorem 5 and Lemma 5, by allowing failure probability \u03b4/2 to Equation 4 and \u03b4/2 to Equation 8. We then simplify the bound by leveraging the fact that 1/m \u2264 2/n.\nWe point out that these bounds have a natural interpretation. Whereas Agarwal and Niyogi [2009] invoke parameterized families of edge distributions, we consider a simple, intuitive learning setup in which the only parameter is the size m of the training set. If m \u2265 n lnn, then \u03b7 = O(1), and we obtain a uniform convergence rate of O(1/ \u221a n). For m \u2265 n/2, we have that \u03b7 = O( \u221a lnn), and the rate is still O\u0303(1/ \u221a n)."}, {"heading": "Acknowledgements", "text": "This work was partially supported by NSF CAREER grant 0746930 and NSF grant IIS1218488."}, {"heading": "A Proof of Lemma 5", "text": "For each pair of vertices {vi, vj}, define a random variable Ei,j , 1[{i, j} \u2208 E]. Note that deg(vi) =\u2211 j 6=iEi,j and, via linearity of expectation,\nE[deg(vi)] = \u2211 j 6=i E[Ei,j ] = (n\u2212 1) \u00b7 ((n2)\u22121 m\u22121 ) ((n2) m\n) = 2mn . Since the expected degree is uniform, let \u00b5 , E[deg(vi)]. Using the union bound, for any t > 0, we have that\nPr[\u2206(G) \u2265 t] \u2264 n\u2211 i=1 Pr[deg(vi) \u2265 t]\n= n\u2211 i=1 Pr \u2211 j 6=i Ei,j \u2265 t  . Though the variables {Ei,j}j 6=i are dependent, it is straightforward to show that they are negatively correlated. Therefore, we can apply multiplicative Chernoff bounds, with t = \u00b5(1 + ), to obtain Pr[\u2206(G) \u2265 t] \u2264 n\u2211 i=1 exp(\u2212\u00b5 2/3) = n exp ( \u22122m 2 3n ) .\nSetting this equal to \u03b4, then solving for and t completes the proof."}], "references": [{"title": "Generalization bounds for ranking algorithms via algorithmic stability", "author": ["S. Agarwal", "P. Niyogi"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Agarwal and Niyogi.,? \\Q2009\\E", "shortCiteRegEx": "Agarwal and Niyogi.", "year": 2009}, {"title": "Learning with equivalence constraints, and the relation to multiclass learning", "author": ["A. Bar-Hillel", "D. Weinshall"], "venue": "In Proceedings of the Conference on Computational Learning Theory,", "citeRegEx": "Bar.Hillel and Weinshall.,? \\Q2003\\E", "shortCiteRegEx": "Bar.Hillel and Weinshall.", "year": 2003}, {"title": "Rademacher and gaussian complexities: risk bounds and structural results", "author": ["P. Bartlett", "S. Mendelson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bartlett and Mendelson.,? \\Q2003\\E", "shortCiteRegEx": "Bartlett and Mendelson.", "year": 2003}, {"title": "Stability and generalization", "author": ["O. Bousquet", "A. Elisseeff"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bousquet and Elisseeff.,? \\Q2002\\E", "shortCiteRegEx": "Bousquet and Elisseeff.", "year": 2002}, {"title": "Ranking and empirical minimization of U-statistics", "author": ["S. Cl\u00e9men\u00e7on", "G. Lugosi", "N. Vayatis"], "venue": "The Annals of Statistics,", "citeRegEx": "Cl\u00e9men\u00e7on et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Cl\u00e9men\u00e7on et al\\.", "year": 2008}, {"title": "An introduction to support vector machines and other kernel-based learning methods", "author": ["N. Cristianini", "J. Shawe-Taylor"], "venue": null, "citeRegEx": "Cristianini and Shawe.Taylor.,? \\Q2000\\E", "shortCiteRegEx": "Cristianini and Shawe.Taylor.", "year": 2000}, {"title": "Learning binary relations and total orders", "author": ["S. Goldman", "R. Schapire", "R. Rivest"], "venue": "SIAM J. Computing,", "citeRegEx": "Goldman et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Goldman et al\\.", "year": 1993}, {"title": "Large deviations for sums of partly dependent random variables", "author": ["S. Janson"], "venue": "Random Structures Algorithms,", "citeRegEx": "Janson.,? \\Q2004\\E", "shortCiteRegEx": "Janson.", "year": 2004}, {"title": "Regularized distance metric learning: Theory and algorithm", "author": ["R. Jin", "S. Wang", "Y. Zhou"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Jin et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Jin et al\\.", "year": 2009}, {"title": "Empirical margin distributions and bounding the generalization error of combined classifiers", "author": ["V. Koltchinskii", "D. Panchenko"], "venue": "Annals of Statistics,", "citeRegEx": "Koltchinskii and Panchenko.,? \\Q2002\\E", "shortCiteRegEx": "Koltchinskii and Panchenko.", "year": 2002}, {"title": "Probability in Banach spaces: isoperimetry and processes", "author": ["M. Ledoux", "M. Talagrand"], "venue": "Ergebnisse der Mathematik und ihrer Grenzgebiete. SpringerVerlag,", "citeRegEx": "Ledoux and Talagrand.,? \\Q1991\\E", "shortCiteRegEx": "Ledoux and Talagrand.", "year": 1991}, {"title": "On the method of bounded differences. In Surveys in Combinatorics, volume 141 of London Mathematical Society Lecture Note Series, pages 148\u2013188", "author": ["C. McDiarmid"], "venue": null, "citeRegEx": "McDiarmid.,? \\Q1989\\E", "shortCiteRegEx": "McDiarmid.", "year": 1989}, {"title": "Rademacher complexity bounds for non-i.i.d. processes", "author": ["M. Mohri", "A. Rostamizadeh"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Mohri and Rostamizadeh.,? \\Q2009\\E", "shortCiteRegEx": "Mohri and Rostamizadeh.", "year": 2009}, {"title": "Stability bounds for stationary \u03c6-mixing and \u03b2-mixing processes", "author": ["M. Mohri", "A. Rostamizadeh"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Mohri and Rostamizadeh.,? \\Q2010\\E", "shortCiteRegEx": "Mohri and Rostamizadeh.", "year": 2010}, {"title": "Chromatic PAC-bayes bounds for non-iid data: Applications to ranking and stationary \u03b2-mixing processes", "author": ["L. Ralaivola", "M. Szafranski", "G. Stempfel"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Ralaivola et al\\.,? \\Q1956\\E", "shortCiteRegEx": "Ralaivola et al\\.", "year": 1956}, {"title": "Generalization error bounds for classifiers trained with interdependent data", "author": ["N. Usunier", "M.-R. Amini", "P. Gallinari"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Usunier et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Usunier et al\\.", "year": 2006}, {"title": "A theory of the learnable", "author": ["L. Valiant"], "venue": "In Proceedings of the Sixteenth Annual ACM Symposium on Theory of Computing,", "citeRegEx": "Valiant.,? \\Q1984\\E", "shortCiteRegEx": "Valiant.", "year": 1984}, {"title": "On an estimate of the chromatic class of a p-graph", "author": ["V. Vizing"], "venue": "Diskret. Analiz.,", "citeRegEx": "Vizing.,? \\Q1964\\E", "shortCiteRegEx": "Vizing.", "year": 1964}], "referenceMentions": [{"referenceID": 6, "context": "The canonical Rademacher bounds are due to Koltchinskii and Panchenko [2002] and Bartlett and Mendelson [2003], while the canonical stability bounds are due to Bousquet and Elisseeff [2002].", "startOffset": 43, "endOffset": 77}, {"referenceID": 2, "context": "The canonical Rademacher bounds are due to Koltchinskii and Panchenko [2002] and Bartlett and Mendelson [2003], while the canonical stability bounds are due to Bousquet and Elisseeff [2002].", "startOffset": 81, "endOffset": 111}, {"referenceID": 2, "context": "The canonical Rademacher bounds are due to Koltchinskii and Panchenko [2002] and Bartlett and Mendelson [2003], while the canonical stability bounds are due to Bousquet and Elisseeff [2002]. Though all of these techniques fundamentally rely on independence, there have been recent applications to non-i.", "startOffset": 81, "endOffset": 190}, {"referenceID": 2, "context": "The canonical Rademacher bounds are due to Koltchinskii and Panchenko [2002] and Bartlett and Mendelson [2003], while the canonical stability bounds are due to Bousquet and Elisseeff [2002]. Though all of these techniques fundamentally rely on independence, there have been recent applications to non-i.i.d. problems. Inspired by Janson [2004], Usunier et al.", "startOffset": 81, "endOffset": 344}, {"referenceID": 2, "context": "The canonical Rademacher bounds are due to Koltchinskii and Panchenko [2002] and Bartlett and Mendelson [2003], while the canonical stability bounds are due to Bousquet and Elisseeff [2002]. Though all of these techniques fundamentally rely on independence, there have been recent applications to non-i.i.d. problems. Inspired by Janson [2004], Usunier et al. [2006] developed a theory of chromatic Rademacher analysis, using it to derive generic risk bounds for dependent data, with bipartite ranking as a motivating example.", "startOffset": 81, "endOffset": 367}, {"referenceID": 2, "context": "The canonical Rademacher bounds are due to Koltchinskii and Panchenko [2002] and Bartlett and Mendelson [2003], while the canonical stability bounds are due to Bousquet and Elisseeff [2002]. Though all of these techniques fundamentally rely on independence, there have been recent applications to non-i.i.d. problems. Inspired by Janson [2004], Usunier et al. [2006] developed a theory of chromatic Rademacher analysis, using it to derive generic risk bounds for dependent data, with bipartite ranking as a motivating example. (Ralaivola et al. [2010] used a similar chromatic analysis to derive PAC-Bayes bounds.", "startOffset": 81, "endOffset": 552}, {"referenceID": 0, "context": "Agarwal and Niyogi [2009] consider a random subsampling process similar to one we discuss and derive risk bounds for ranking using algorithmic stability.", "startOffset": 0, "endOffset": 26}, {"referenceID": 16, "context": "We will use the canonical probably approximately correct (PAC) framework [Valiant, 1984], in which we allow the defect to exceed an arbitrary > 0 with probability \u03b4 \u2208 (0, 1).", "startOffset": 73, "endOffset": 88}, {"referenceID": 17, "context": "Theorem 1 (Vizing, 1964).", "startOffset": 10, "endOffset": 24}, {"referenceID": 11, "context": "Theorem 2 (McDiarmid, 1989).", "startOffset": 10, "endOffset": 27}, {"referenceID": 15, "context": "Theorem 3 (Usunier et al., 2006).", "startOffset": 10, "endOffset": 32}, {"referenceID": 5, "context": "One such class of hypotheses is reproducing kernel Hilbert spaces (RKHS), which subsume the popular support vector machine (SVM) [Cristianini and Shawe-Taylor, 2000].", "startOffset": 129, "endOffset": 165}, {"referenceID": 4, "context": "One such class of hypotheses is reproducing kernel Hilbert spaces (RKHS), which subsume the popular support vector machine (SVM) [Cristianini and Shawe-Taylor, 2000]. Formally, for some mapping \u03c6 : Z \u2192 Z\u0303, where Z is an instance space and Z\u0303 is a Hilbert space, endowed with an inner product \u3008\u00b7, \u00b7\u3009, a kernel \u03ba : Z \u2192 R is a function such that, for all (z, z\u2032) \u2208 Z, \u03ba(z, z\u2032) = \u3008\u03c6(z), \u03c6(z\u2032)\u3009. The only requirement is that the kernel\u2019s Gram matrix K : Ki,j = \u03ba(zi, zj) be symmetric and positive semidefinite. RKHS hypotheses are generally of the form h\u03ba,Z(z) , \u2211m z\u2032\u2208Z \u03ba(z, z \u2032), where Z \u2208 Z is a set of reference points from the problem domain (e.g., support vectors). We may reasonably assume that the norm of the kernel mapping is uniformly bounded by a constant C; i.e., the mapped data is contained within a ball of radius C. We denote the class of kernel functions by H\u03ba. Borrowing results from Koltchinskii and Panchenko [2002] and Bartlett and Mendelson [2003], we are able to prove the following risk bounds for kernel-based hypotheses with bounded kernels, in the context of learning binary relations.", "startOffset": 130, "endOffset": 932}, {"referenceID": 2, "context": "Borrowing results from Koltchinskii and Panchenko [2002] and Bartlett and Mendelson [2003], we are able to prove the following risk bounds for kernel-based hypotheses with bounded kernels, in the context of learning binary relations.", "startOffset": 61, "endOffset": 91}, {"referenceID": 10, "context": "To bound Rn(`\u03b3 \u25e6 H\u03ba \u25e6 Sm), we use Talagrand\u2019s contraction lemma [Ledoux and Talagrand, 1991] and borrow a result from Bartlett and Mendelson [2003, Lemma 22], from which we obtain", "startOffset": 64, "endOffset": 92}, {"referenceID": 15, "context": "Note that this analysis slightly improves upon that of Usunier et al. [2006] in that we use the regular Rademacher complexity instead of their so-called fractional Rademacher complexity.", "startOffset": 55, "endOffset": 77}, {"referenceID": 3, "context": "Lemma 2 (Bousquet and Elisseeff, 2002).", "startOffset": 8, "endOffset": 38}, {"referenceID": 3, "context": "Lemma 3 (Bousquet and Elisseeff, 2002).", "startOffset": 8, "endOffset": 38}, {"referenceID": 3, "context": "Using a stability result from Bousquet and Elisseeff [2002], we obtain a risk bound for SVM classification.", "startOffset": 30, "endOffset": 60}, {"referenceID": 3, "context": "Lemma 4 (Bousquet and Elisseeff, 2002).", "startOffset": 8, "endOffset": 38}, {"referenceID": 0, "context": "Whereas Agarwal and Niyogi [2009] invoke parameterized families of edge distributions, we consider a simple, intuitive learning setup in which the only parameter is the size m of the training set.", "startOffset": 8, "endOffset": 34}], "year": 2013, "abstractText": "We investigate the generalizability of learned binary relations: functions that map pairs of instances to a logical indicator. This problem has application in numerous areas of machine learning, such as ranking, entity resolution and link prediction. Our learning framework incorporates an example labeler that, given a sequenceX of n instances and a desired training size m, subsamples m pairs from X \u00d7X without replacement. The challenge in analyzing this learning scenario is that pairwise combinations of random variables are inherently dependent, which prevents us from using traditional learning-theoretic arguments. We present a unified, graph-based analysis, which allows us to analyze this dependence using well-known graph identities. We are then able to bound the generalization error of learned binary relations using Rademacher complexity and algorithmic stability. The rate of uniform convergence is partially determined by the labeler\u2019s subsampling process. We thus examine how various assumptions about subsampling affect generalization; under a natural random subsampling process, our bounds guarantee \u00d5(1/ \u221a n) uniform convergence.", "creator": "TeX"}}}