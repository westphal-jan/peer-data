{"id": "1303.5708", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2013", "title": "Some Properties of Plausible Reasoning", "abstract": "This paper presents a plausible system of reasoning to illustrate some general questions of knowledge representation: dualities between different forms of reasoning, the difficulty of unifying complementary styles of reasoning, and the approximate nature of plausible modes of reasoning. These questions have a common underlying theme: there should be an underlying calculation of belief, which is based on the calculation of subjective Bajesian probabilities, which in turn is based on a few simple assumptions about how faith should be manipulated. Approaches, semantics, consistency, and consequence are presented for the system.", "histories": [["v1", "Wed, 20 Mar 2013 15:29:51 GMT  (393kb)", "http://arxiv.org/abs/1303.5708v1", "Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI1991)"]], "COMMENTS": "Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI1991)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["wray l buntine"], "accepted": false, "id": "1303.5708"}, "pdf": {"name": "1303.5708.pdf", "metadata": {"source": "CRF", "title": "Some Properties of Plausible Reasoning", "authors": ["Wray Buntine"], "emails": ["wray@ptolemy.arc.nasa.gov"], "sections": [{"heading": null, "text": "1 INTRODUCTION\nThere are many styles of knowledge representation and inference involving some form of uncertainty or incon sistency: reasoning about likelihoods, independence and related notions such as causality, confirmation, defaults and statistical frequencies, and tasks such as analogy, abduction and belief revision. In knowledge representation there is now a recognised need for the unification and development of these multiple, comple mentary forms of reasoning (Brachman, 1990). To do this unification an underlying belief calculus is needed as a common base for the different reasoning forms. First, this paper presents a system unifying defaults,\n*Research Institute for Advanced C01nputer Science.\nlikelihood, necessity and possibility. Because the sys tem uses Bayesian probability as the underlying belief calculus, independence, abduction, belief revision and many other facets of plausible reasoning could be inte grated as well, although it is not done so here. Second this paper argues that plausible reasoning can be inter preted as a form of approximate reasoning. This has important implications to the implementation of plau sible reasoning systems. For instance, error can accu mulate in a long chain of plausible reasoning, so po tential error should be tracked. So this paper also dis cusses approximate methods for tracking error. Also, we cannot expect plausible reasoning to be correct ev ery time. Many of the so-called paradoxes in plausible reasoning arise because it is assumed that plausible reasoning will always lead to a correct conclusion.\nThe system presented here, like most Bayesian meth ods, is based on a few basic assumptions together with a few approximations. The assumptions are about how belief can be modelled and updated and have been pre sented in (Horvitz et a!., 1986). The same Bayesian principles have led to the development of algorithms for learning (Buntine, 1991a), uncertain inference, and many more applications outside of artificial intelli gence. Bayesian methods arc claimed to be normative, which means they set a standard for plausible rc<cson ing and implies they will not suffer from the standard paradoxes that arc discussed in the non-monotonic lit erature (Hanks and McDermott, 1987; Poole, 1989; Pearl, 1988; Etherington ct a!., 1990). (Treatment of several paradoxes are given here and in (Buntinc, 1001 b).) The system presented here only implcmcn ts one facet of the Bayesian approach and therefore is in complete and may require extending with one of many complementary modes of normative reasoning, such as the making of default assumptions about indepen dence (Goldszmidt and Pearl, 1900b).\nThe next section informally introduces the notation for a qualitative and a quantitative logic that each demon strate a different level of approximation for reasoning about defaults and likelihoods. The default compo nent of the qualitative logic corresponds to the var-\nious conditional logics developed for default reason ing (Delgrande, 1988; Pearl, 1988; Geffner, 1988) but most closely to Adams' improper conditional (Adams, 1966). The quantitative logic has its roots in remarks made by Adams. The qualitative system is presented here only for contrast with the quantitative system, because the quantitative system has many advantages with little extra overhead. The third section cov ers the theory of the two systems, semantics, con sistency and consequence. Since the qualitative logic is an extension of Adams conditional logic (Adams, 1%6; Adams, 1975), applied to default reasoning by Geffner and Pearl (Pearl, 1988; Geffner, 1988), this greatly extends and simplifies Adams' and Goldszmidt and Pearl's (Goldszmidt and Pearl, 1990a) consistency and consequence tests by incorporating necessity, pos sibility, and likelihood in a quantitative framework. The quantitative framework allows approximate de fault and likelihood reasoning and tracking of accumu lated error at the same time. The fourth section illus trates the use of the logics on some standard problems from the literature. The fifth section uses the logics to illustrate some major properties of plausible reasoning.\nIt is beyond the scope of this paper to cover the basic notions of probability and decision theory underlying subsequent sections. Suitable introductions from an AI perspective can be found in (Langlotz and Short liffc, 1989; Horvitz et a!. , 1988; Pearl, 1988).\n2 NOTATION\nDP is a propositionaJl logic annotated with proba bility bounds, and has a probabilistic rather than a possible world semantics. This allows inequality rea soning as an approxilnation to nonnative reasoning about point probabilities. QDP drops the numeric subscripts from DP and is designed to be a qualita tive counterpart of DP. It is intended to be an ap proximation to DP for reasoning about \"small\" but not infinitesimal probabilities. The semantics of QDP complements DP and is based on order of magnitude reasoning, but also has an infinitesimal semantics sim ilar to Adams' conditional logic.\nDP is built on the language Dp that is constructed from the propositional language together with four modal operators: the unary connectives D (necessity), o (possibility), and the binary connectives =? (de fault with error bound) and \ufffd (likelihood with lower bound). There is no nesting of these operators. The operators can be interpreted as follows. (Delow A and D both represent arbitrary propositions.)\n1 Although propositional sentences are dealt with throughout, pseudo-first-order sentences will sometimes be used. They arc effectively propositional if there are known to be a finite number of constants, no quantifiers arc al lowed, and a sentence with variables is intended to repre sent a. sentence scltcma.\nSome Properties of Plausible Reasoning 45\nDA: A is necessarily true in any situation.\noA: Some situation can possibly arise in which A is true.\nA =?, D: Given that you know just A about the current situation, you can infer D by default (with error in belief at most \u20ac) .\nA \ufffd. D: Given that you know just A about the current situation, D is at least likely (with belief no less than e) .\nThese four operators are joined using the standard boolean connectives ( \ufffd (negation), -+ (conditional), II (conjunction), etc.) to form the language Dp. This language also has a qualitative version, QDp, which has the numeric subscripts dropped. The semantics for the language implements this by making \u20ac and e infinitesimal; not because we believe them to be in finitesimal but as a mathematical abstraction to ob tain approximate behaviour of the operators for \u00a3 and e small. Q D p has successively weaker forms of the likelihood operator. A\ufffd D denotes \"likely,\" whereas A \ufffd2 D would denote \"barely likely,\" etc. This is related to the iterated likelihood operator found in (Halpern and Rabin, 1987) and has a formal justifi cation in Theorem 3 part 2.\nA \ufffd\" D: Given that you know just A about the current situation, D is at least likely to be . . . to be likely (to order n).\nThe default and likelihood operators are \"improper\" according to Adams' terminology (Adams, 1966). This means A =? D and A \ufffd D will both hold true if A is necessarily false . The \"proper\" versions must have A being possible, so correspond to oA II (A =? D), and oA II (A\ufffd D) respectively. The logics, being probabilistically based, arc eas ily able to express sentences such as \"an Aus tralian is likely to drink Foster's\": Aust\u00b7ralian \"\" >- Drinks-Foster's; whereas Aust7\u00b7al ian \ufffd2 Drinks -another-Foster's expresses the fact that, at least occasionly, an Australian will drink even more Foster's. Surprisingly enough, they also able to express sentences more in the spirit of autoepistemic (Moore, 1985) and default logics (Reiter, 1980). We can in terpret the sentence \"a professor has a Ph.D. unless known otherwise\" two ways:\no(Prof(x) II Phd(x)) ----> (Prof(x) =? Phd(x)), o(Prof(x) II Phd(x)) ----> D(Prof(x)-+ Phd(x)).\nRead as \"if it is possible that a particnlar profes sor has a PhD, then the professor most l-ikely has a Ph.D.,\" and \"if it is possible that a particular pro fessor has a PhD, then the professor definitely has a Ph.D.\" respectively. The default logic representation, from P.rof(x) II M Phd(x) infer Phd(x), corresponds to the second reading. So the possibility operator, \"o\", behaves rather like the /'.1 operator of default logic.\n46 Buntine\n3 THEORY\nThis section presents the semantics for the two logics and then discusses their intended use in plausible rea soning. Basic consistency and consequence theorems are given.\n3.1 SEMANTICS\nIn DP, \"I=Pr D\" denotes that DE Dp is true for the probability distribution Pr. Pr plays a role not unlike an interpretation in standard propositional logic.\nDefinition 1 Given a probability distribution Pr on propositions, \"I= Pr \" is defined on sentences from D p as follows.\n1. I=Pr DA if and only if Pr(A) = 1.\n2. I=Pr A=?, B if and only if Pr(BIA) 2: 1- \u20ac.\n3. I=Pr -.D if and only if not FPr D. .{. I=Pr D--> E if and only if not I=Pr D or FPr E.\nPossibility and likelihood are by definition dual opera tors for necessity and default respectively. \"oA\" is de fined as \"-.0-.A\", so FPr oA if and only if Pr(A) > 0. \"A :::::>-e B\" is defined as \"-.(A =?e -.B)\", so A :::::>-e B if and only if Pr (BIA) > e.\nDefinition 2 A sentence D E Dp is a theorem of the probabiz.istic logic DP if I=Pr D for all zwssible proba.bil-ity distrib\u00b7ui'ions Pr.\nConsistency and consequence for sentences are defined in the usual manner based on the notion of a theorem.\nTo obtain qualitative rules about default and likeli hood from the quantitative rules in DP, we can per form order of magnitude reasoning. We can consider a representative default error, \u20ac1 where \u20ac might be less than 0.01, or whatever the decision context requires. Likewise, we can consider a representative default like lihood, e, where e might be greater than 0.05, say. In order to approximate the behaviour of our reasoning with these particular limits in mind, we can parame terise the system by \u20ac and e and consider only approx imate calculations to 0(\u20ac) and O(e). QDp is defined in a manner such that \u20ac and e are arbitrarily small, but \u20ac is also arbitrarily smaller than e.\nDefinition 3 A sentenceD E QDp is a theorem of the qualitative probabilistic logic QP D if there exists a theorem D' E Dp corresponding to D (that is, iden tical except for any super or s\u00b7ubscripts), in which all s\u00b7ubscripts to \"=;.\" and \":::::>- \" aTe parameterised by some variables \u20ac and e and each subscript to \"=;.\" is of order \u20ac as \u20ac approaches 0 and e remains finite, and each sub script in D' corresponding to \":::::>-n\" in D is of order e\" as e and\ufffd approach 0. Th-is is denoted \"I=QDP D\".\nAgain, consistency and consequence are defined in the usual manner.\nThis definition can be reinterpreted to give an infinites imal semantics close to that of Adams. Lemma 1 below (Buntine, 1991b) does this using a standard clausal form for defaults and another for likelihoods that col lects all necessities and possibilities into the left-hand side of the clause.\nLemma 1\nFQDP DU 1\\iEivoV;!\\;EIAA; =? B; --> V;ErcGi =? H;, if and only if there exists a 6 and 1) such that for all \u20ac < 1)\nFDP DU 1\\iEiv oV; 1\\;EfA A; =?, B; --> V;ErcGi =?6, H;\nSimilarly,\nI=QDP DU 1\\iEiv oV; 1\\;EfA A; :::::>-n' B; --> ViEicGi \ufffdmi H i ,\nif and only if there exists a 6 and 17 such that for a.ll \u20ac < 1)\nI=DP DU 1\\;Efv ov; 1\\;EfA A; :::::>-, .. , B; --> ViEicGi ::::>-o\u20acmi H i .\nFor the D p sentences in the lemma, 6 is an error prop agation factor, and 0\u20ac and OE\"'' are the error propaga tion functions respectively. For the default clause, the larger the value of 6, the faster error can propagate when the clause is applied in some chain of reason ing. Since a smaller likelihood represents more room for error, in the likelihood clause the smaller the value of 6, the faster error will propagate when the clause is applied in some chain of reasoning.\nFor instance, the sentence\n(A:::::>-, C) 1\\ (B :::::>-d C) --> A VB :::::>-t C,\nis a theorem of DP with the error propagation function f given by\ned f < :::; min(e, d ).\ne + d- ed Therefore we can drop the subscripts to get a Q D P theorem as well.\n3.2 THEOREMS\nDP and QDP give a system for reasoning qualita tively and quantitatively about probability inequal ities. However, normative reasoning according to Bayesian principles is based on point probabilities. Of ten in normative reasoning, we have a specific deci sion context in mind and we wish to determine if the probability of some proposition is less than or greater than some fixed probability (determined by the loss\nfunction) . DP and QDP are then approximations for dealing with this special case. QDP is merely an ab straction of DP given here to show the connection of\nDP with existing conditional and probabilistically mo tivated logics. Because of the inability of QDP to keep track of error, it would be a potentially unsafe system to use in practice.\nIf the problem contains a good deal of uncertainty so the errors are large, or the loss function for the deci sions to be made requires careful evaluation of com parative probabilities, it may be more appropriate to conduct a careful probabilistic analysis instead of us ing the approximate methods suggested here. If how ever, the errors are small, it is shown in this section we can do consistency and consequence tests in D P us ing qualitative reasoning about defaults and likelihood, and follow this with some simple error propagation cal culations to calculate upper bounds on propagated er rors. These approximate probability calculations may then be a sufficient basis for making decisions. Details of this approach arc described in this section. This makes DP a safe alternative to QDP when approxi mate reasoning seems appropriate.\nNotice though that whether a sentence from Dp is con sistent or is a consequence of some other can be con verted to a set of simplex problems in the variables, as done with Probabilistic Logic (Nilsson, 1986) . We shall not pursue this approach, however, since we are concerned with approximate modelling of default and likelihood reasoning, for which \"propagation errors\" can be calculated rapidly using other more approxi mate means, as shown below.\nAlgorithms for consistency and consequence are given here for the numerically annotated logic DP. To ob tain results for QDP, simply drop the subscripts, and in the case of likelihoods, be careful to check the or ders of magnitude of the error propagation functions. Since each of the theorems below allows arbitrary pos sibilities to be included, the algorithms can be readily converted to the proper versions of the operators.\nThe algorithms rely on first computing the subset of the default (likelihood) operators that must have their antecedents necessarily false. For instance, in (A =?B) A (A=? \ufffdB) A (C =? D), A must be neces sarily false since both B and \ufffdn cannot be \"typical\" at the same time. So both the first two defaults must have their antecedents necessarily false. These com puted subsets for defaults (likelihoods) are referred to as the maximum (minimum) inconsistent set. An al gorithm for computing the maximum inconsistent set of a DP sentence with defaults is given in Figure 1. The algorithm for computing the minimum inconsis tent set for a DP sentence containing no defaults is given in Figure 2. Logical tests for consistency and consequence arc given in Theorem 2 for Dp clauses containing no likelihood operator. The role of the max imum inconsistent set can best be seen by looking at\nSome Properties of Plausible Reasoning 47\nparts 1 and 4 of the theorem.\nTheorem 2 Consider the D p sentence D given by DU A;uv oV; A;uA A; =?, B;, where E; < 1},1, t for i E IA. Let I max denote the (unique) maximum inconsistent set for the sentence.\n1. The sentence D is inconsistent if and only if there exists some j E Iv such that U A Vj A;um .. -.A; is unsatisfiable.\n2. The Dp sentence C =?8 B is a consequence of D for some o < \ufffd if and only if D A (C =?6 \ufffdB) i8 inconsistent.- 8 = I;iEIA E; \u00b7is a correct error propagation function.\n3. The Dp sentence oC is a consequence of D if and only -if D A o\ufffdc is inconsistent.\n4. The Dp sentence DC is a consequence of D if and only if D itself is inconsistent or I= U A; Elm .. \ufffdA;_, C.\nNotice by part 1, if the DP sentence contains proper default operators (so possibilities are included) , then the sentence will necessarily be inconsistent if the max imum inconsistent set is non-empty. The correspond ing property applies to likelihoods.\nTests for consistency and consequence using the like lihood operator arc given in Theorem 3. Methods for computing tighter bounds for the error propagation function, linear in some cases, arc given in (Buntinc, 1991b). Theorem 3 Consider the Dp sentence D gi-ven by\n48 Buntine\nDU 1\\iElv oV; /\\;erA A; \ufffde; B;, where e; < JtT for i E IA. Let Imin denote the (unique) minimum inconsistent set.\n1. The sentence D is inconsistent if and only if there exists some j E Iv such that U A;er .. ;. \ufffdA; A Vj is unsatisfiable.\n2. The Dp sentence C \ufffd\ufffd B is a consequence of D for some f < 1 if and only if D is inconsistent or the likelihood inconsistency algorithm in Fig ure 3 terminates yielding a consequence. If con sequence holds, then a lower bound on f , the error\n( ) II AI propagation function, is given by f \ufffd 1\ufffd. , where e = min;ElA e;, although the error propaga tion function can be less, for instance, linear in the e; in some cases.\n3. The D p sentence oC is a consequence of D -if and only if D A o\ufffdc is inconsistent.\n4. The Dp sentence DC is a consequence of D if and only if D is inconsistent or I= U 1\\;EJ .. ;. \ufffdA; __. c.\nAlso, (A \ufffd B) __. \ufffd(A=> \ufffdn) is a theorem of QDP. This property can be used, for instance, to convert a QDP formula containing a mixture of defaults and likelihoods into a stronger formula containing just de faults, and so prove consistency of the weaker formula.\n4 EXAMPLES\nThe logics are illustrated here on some standard para doxes from the knowledge representation literature.\nOthers handled are the \"Yale shooting problem\" and \"Can Joe read and write?\" (Buntine, 1991b).\n4.1 THE LOTTERY PARADOX\nSuppose a lottery has 1, 000,000 participants. The following two sentences are theorems of DP. The first follows from Theorem 2, and the second is its dual constructed by converting defaults to likelihoods and rearranging:\n1,000,000\n1\\ (t1\u00b7ue =>, (person i wont win lottery)) --+ i:::::l\n(t1\u00b7ue =?1,ooo,ooo., (no-one will win lottery)) ,\nwith its dual,\n(true \ufffd' (someone will win lottery)) --+ 1,000,000\nV (t1\u00b7ue \ufffd--' (person i will win lottery)) . 1,000,000 i:::::l\nMoreover, replacing 1, 000, 000 by 999, 999 yields sen tences that are not theorems of Q D P. Ignoring the error bounds as done in QDP, the first sentence would seem to read \"if, by default, any particular person will not win the lottery, then, by default, no-one will win the lottery at all\". Likewise, the second DP sentence would seem to read: \"if it is likely that someone will win the lottery, then for some lottery entrant, it is likely they will win the lottery\" (clearly not the case before the draw).\nThe two readings arc versions of the lottery paradox that arc the dual of each other. In the first DP sen tence the natural value for \u00a3 is 1 00\ufffd 000; this leaves the sentence impotent because the ' err\ufffdr bound in the conclusion becomes 1. In DP there is no paradoxi cal reading. QDP unfortunately drops the subscripts (both are of order \u00a3 as \u00a3 approaches 0) and loses the error information. QDP suffers from the lottery para dox because it disregards the approximate nature of the default and likelihood operators. In the first sen tence above, taking the conjunction of one million dif ferent approximate statements leads to an incorrect statement because the error in each accumulates.\nBecause of the cheap cost of maintaining approximate error calculations, as demonstrated in Theorem 3 for DP, there would seem little reason for using a purely qualitative system such as QDP.\n4.2 THE \"VANISHING\" EMUS\nThe modelling of default reasoning based on infinites imal probabilities has been criticised on the grounds that it makes \"subclasses vanish\" (Neufeld ct al., 1990, pl23). Etherington, Kraus and Perlis (Etherington et al., 1990) show a related problem applies to defanlt logic and circumscription.\nConsider the following rules:\nEmu(x)--> Bird(x) ,\nEmu(x) => -.Flies(x) , Bird(x) => Flies(x) .\nWe can conclude (using Theorem 2) that \"typically, birds aren't emus\", Bird(x) => -.Emu(x), and \"typi cally, things aren't emus\", true=> -.Emu(x).\nIf we take the infinitesimal semantics of the default op erator literally then we could conclude that \"no birds are emus\", or \"nothing is an emu\". The real intent of the probabilistic semantics presented here, however, is about approximations so a more correct reading of the conclusion is that the emu is an uncommon or non typical bird, which in reality is true of emus.\nCircumscription, when presented with this same prob lem will deduce there are no emus to minimise the exceptions (Etherington et a!., 1990). Etherington, Kraus and Perlis invent the notion of scope to over come the same kind of difficulties in default logics and circumscription (Etherington et a!., 1990):\nWe contend that the intention of default rea soning is generally not to determine the prop erties of every individual in the domain, but rather those of some particular individuals of interest.\nQDP resolves the same paradoxes using a related prin ciple that falls out naturally from the Bayesian frame work and can be stated as follows:\nThe intention of default rea.soning is gener ally to determine rea.sonable properties of an individual in the domain. While these may be reasonable individually, they are not nec essarily correct so one cannot rea.sonably say they apply uniformly.\n5 CONCLUSION\nThe systems presented here do not do full norma tive Bayesian reasoning but instead are approxima tions valid in certain situations (as explained at the beginning of Section 3.2). Approximations have two effects: they can make a system incomplete or incor rect. DP has retained correctness but become incom plete. In QDP correctness is also lost by doing order of magnitude reasoning. One result of incompleteness is that on many general problems these systems will need complementary rea.soning forms in order to pro duce a result. A result of incorrectness is that errors in reasoning can creep in, especially when they are hid den in qualitative reasoning which has a logical form making it appear deceptively accurate. As shown with the examples, both these results are a source of ma terial for paradoxes if the underlying approximations arc not understood.\nSome Properties of Plausible Reasoning 49\nThis section discusses the issues raised by this: unify ing complementary reasoning forms, the nature of ap proximate reasoning, and the dualities between default and likelihood reasoning. These insights, together with Theorems 2 and 3 form the major contributions of this paper. This gives us a much deeper insight into the problems of knowledge representation and inference in volving some form of uncertainty.\n5.1 DUALITIES\nOne of the first things taught to students of logic is the duality between disjunction and conjunction (-.(AI\\ B) <--> (-.Av-.B) and \u00b7(AV B)<--> (-.Af\\-.B)). In modal logic, duality also holds between necessity and possibility (DA <--> -, o -.A and oA <--> -.0-,A). In DP the corresponding duality applies between de fault and likelihood. This means, for instance, that we can obtain dual forms for all DP theorems and to a limited degree some QDP theorems (the QDP definitions are only approximately dual) by converting defaults to likelihoods and vice versa. Versions of some QDP theorems and their (rearranged) duals are given in Table 1.\nThese duality properties come about because of the ba sic properties of negation and by the dual definitions for the operators. A more remarkable but not so exact duality can be seen in the consistency and consequence theorems for default and likelihood. Compare the al gorithms for the maximum and minimum inconsistent sets, and compare each of the results in Theorems 2 and 3. These theorems are not duals according to the definition of default and likelihood. For instance, the dual results to Theorem 2 would show a disjunction of likelihoods can be a consequence of a single like lihood rather than show a single likelihood can be a consequence of a conjunction of likelihoods, the situ ation of Theorem 3. The theorems are proven using quite different methods (for instance the results for likelihood are considerably harder to prove than those for default). Yet the theorems and algorithms have a remarkably similar form. Their major difference is\n50 Buntine\nthat error combines slowly (linearly) for defaults but rapidly (multiplicatively) for likelihoods, though lin early in some special cases (Buntine, 1991b). Because likelihood errors combine rapidly, people often keep track of the degree of likelihood. For instance, like lihoods are used to rank order hypotheses in model based diagnosis and abduction. Another result of this difference is that while considerable research has fo cussed on default reasoning, none to date has consid ered variable strength defaults as for instance allowed using error propagation functions and Theorem 2. In contrast, likelihood reasoning systems suggested in the literature introduced qualitative variable strength like lihoods from the beginning (Halpern and Rabin, 1987).\n5.2 UNIFYING COMPLEMENTARY REASONING FORMS\nThe treatment of the two paradoxes \"Can joe read and write?\" and the Yale shooting problem are an example of how independence becomes an important complementary reasoning form for conditional logics. Both these problems yield no paradox in Q D P, N P (Delgrande, 1988) and related conditional logics be cause no default conclusions can be made at all. This holds because the antecedents of a conditional default or likelihood rule cannot be arbitrarily specialised with some additional knowledge. That is, the QDp sen tence (B => C) -> (A 1\\ B => C) is not a theorem of QDP. For instance, the often useful transitive rela tion (A=> B) 1\\ (B =>C) -> A=> C is not a theorem of QDP. However, the QDp sentence\n((B =>C)-> (A 1\\ B =>C)) -+\n((A=> B) 1\\ (B =>C) ->A=> C)\nis a theorem of QDP. This means knowledge of the form (B => C) -> (A 1\\ B => C) will play a vital role in enabling default and likelihood conclusions like transitivity. If A is independent of C given B then we have this knowledge.\nGiven that we need complementary reasoning forms, how do we unify them? It would be nice if we could somehow keep the different reasoning styles in sepa rate modules, as suggested in hybrid reasoning sys tems (Frisch and Cohn, 1991). However, experience gained in the exercise here indicates this may not usu ally be possible. The unifying of necessity and possi bility reasoning with default reasoning and likelihood reasoning, as presented in Theorems 2 and 3, required careful integration of the several approaches. Another unification that needs to be made is to integrate sym bolic reasoning about independence (Lauritzen et a!., 1990; Pearl, 1988) into the algorithms presented in Theorems 2 and 3.\n5.3 APPROXIMATE REASONING\nQualitative reasoning about default and likelihood is interpreted here as an approximate form of reason ing that is bound to sometimes produce incorrect re sults. By investigating the quantitative counterpart to these reasoning forms, we are able to see more closely how this error propagates and accumulates and how we might track it, and we are able to better under stand the assumptions under which the system oper ates. A qualitative system, for instance, has an im plicit assumption that all errors \u20ac are identical. With the quantitative system, however, we are able to allow the errors to vary-a more realistic situation.\nOf course, all these rough approximations could be circumvented if we would adhere to more complete, fully normative Bayesian reasoning in the first place. This raises the important question: When do approx imate systems such as DP buy us improved perfor mance in an application over more complete proba bilistic approaches? Comparative studies here do not exist. Approximate systems such as DP could be ap propriate for generating a comprehensible explanation of probabilistic results obtained, for instance, by other numeric methods. Also, approximate systems due to their more simplistic framework, may be more appro priate for rapid turn-around in system development and user training. They may therefore serve as a use ful complement to a more complete probabilistic ap proach rather than as a replacement. Only application experience will tell.\nReferences\nAdams, E. (1966). Probability and the logic of con ditionals. In Hintikka, J. and Suppes, P., editors, Aspects of Inductive Logic, pages 265-316. North Holland, Amsterdam.\nAdams, E. (1975). The Logic of Conditionals. Reidel, Boston.\nBrachman, R. (1990). The future of knowledge rep resentation. In Eighth National Conference on Ar tificial Intelligence, pages 1082-1092, Boston, Mas sachusetts.\nBuntine, W. (1991a). Classifiers: A theoretical and empirical study. In International Joint Conference on A rt\u00b7ificial Intelligence, Sydney. Morgan Kauf mann.\nBuntine, W. (1991b). Modelling default and likeli hood reasoning as probabilistic reasoning. Annals of Mathematics and AI. To appear.\nDelgrande, J. (1988). An approach to default reason ing based on a first-order conditional logic: revised report. Artificial Intelligence, 36:63-90.\nEtherington, D., Kraus, S., and Perlis, D. (1990). N onmonotonicity and the scope of reasoning: Pre liminary report. In Eighth National Conference on\nArtificial Intelligence, pages 600-607, Boston, Mas sachusetts.\nFrisch, A. and Cohn, A. (1991). Thoughts and af terthoughts on the 1988 workshop on principles of hybrid reasoning. AI Magazine, 11(5):77-83.\nGeffner, H. (1988). On the logic of defaults. In Seventh National Conference on Artificial Intelligence, pages 449-454, Saint Paul, Minnesota.\nGoldszrnidt, M. and Pearl, J. (1990a). Deciding consis tency of databases containing defeasible and strict information. In Henrion, M., Schachter, R., Kana!, L., and Lemmer, J ., editors, Uncertainty in A rtifi cial Intelligence 5. Elsevier Science Publishers, Ams terdam. An extended version appears as UCLA Cog nitive Systems Laboratory, Technical Report CSD890034 (R-122).\nGoldszrnidt, M. and Pearl, J. (1990b). A maxi mum entropy approach to nonmonotonic reasoning. In Eighth National Conference on Artificial Intelli gence, pages 646-652, Boston, Massachusetts.\nHalpern, J. and Rabin, M. (1987). A logic to reason about likelihood. Artificial Intelligence, 32:379-405.\nHanks, S. and McDermott, D. (1987). Nonmono tonic logic and temporal projection. Artificial In telligence, 33:379-412.\nHorvitz, E., Breeze, J ., and Henrion, M. (1988). De cision theory in expert systems and artificial intel ligence. International Journal of Approximate Rea soning, 2:247-302.\nHorvitz, E., Heckerman, D., and Langlotz, C. (1986). A framework for comparing alternative formalisms for plausible reasoning. In Fifth National Conference on Artificial Intelligence, pages 210-214, Philadel phia.\nLanglotz, C. and Shortliffe, E. (1989). Logical and decision theoretic methods for planning under un certainty. AI Magazine, 10(1):39-48.\nLauritzen, S., Dawid, A., Larsen, B., and Leimer, H.-G. (1990). Independence properties of directed Markov fields. Networks, 20:491-505.\nMoore, R. (1985). Semantical considerations on non monotonic logic. Artificial Intelligence, 25:75-94.\nNeufeld, E., Poole, D., and Aleliunas, R. (1990). Prob abilistic semantics and defaults. In Schachter, R., Levitt, T., Kana!, L., and Lemmer, J., editors, Un certainty in Artificial Intelligence 4. North Holland.\nNilsson, N. ( 1986). Probabilistic logic. Artificial Intel ligence, 28:71-87.\nPearl, J. (1988). Probabilistic Reasoning in Intelligent Systems. Morgan and Kauffman.\nPoole, D. (1989). What the lottery paradox tells us about default reasoning. In First International Con ference on Principles of Knowledge Representation and Reasoning, pages 333-340, Toronto.\nSome Properties of Plausible Reasoning 51\nReiter, R. (1980). A logic for default reasoning. Arti ficial Intelligence, 13:81-132."}], "references": [{"title": "Probability and the logic of con\u00ad ditionals", "author": ["E. Adams"], "venue": "Aspects of Inductive Logic,", "citeRegEx": "Adams,? \\Q1966\\E", "shortCiteRegEx": "Adams", "year": 1966}, {"title": "The Logic of Conditionals", "author": ["E. Adams"], "venue": null, "citeRegEx": "Adams,? \\Q1975\\E", "shortCiteRegEx": "Adams", "year": 1975}, {"title": "The future of knowledge rep\u00ad resentation", "author": ["R. Brachman"], "venue": "In Eighth National Conference on Ar\u00ad tificial Intelligence,", "citeRegEx": "Brachman,? \\Q1990\\E", "shortCiteRegEx": "Brachman", "year": 1990}, {"title": "Classifiers: A theoretical and empirical study", "author": ["W. Buntine"], "venue": "In International Joint Conference on A", "citeRegEx": "Buntine,? \\Q1991\\E", "shortCiteRegEx": "Buntine", "year": 1991}, {"title": "Modelling default and likeli\u00ad hood reasoning as probabilistic reasoning", "author": ["W. Buntine"], "venue": "Annals of Mathematics and AI. To appear. Delgrande, J", "citeRegEx": "Buntine,? \\Q1991\\E", "shortCiteRegEx": "Buntine", "year": 1991}, {"title": "N onmonotonicity and the scope of reasoning: Pre\u00ad liminary report", "author": ["D. Etherington", "S. Kraus", "D. Perlis"], "venue": null, "citeRegEx": "Etherington et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Etherington et al\\.", "year": 1990}, {"title": "Thoughts and af\u00ad terthoughts on the 1988 workshop on principles of hybrid reasoning", "author": ["A. Frisch", "A. Cohn"], "venue": null, "citeRegEx": "Frisch and Cohn,? \\Q1991\\E", "shortCiteRegEx": "Frisch and Cohn", "year": 1991}, {"title": "On the logic of defaults", "author": ["H. Geffner"], "venue": "In Seventh National Conference on Artificial Intelligence,", "citeRegEx": "Geffner,? \\Q1988\\E", "shortCiteRegEx": "Geffner", "year": 1988}, {"title": "Deciding consis\u00ad tency of databases containing defeasible and strict information", "author": ["M. Goldszrnidt", "J. Pearl"], "venue": null, "citeRegEx": "Goldszrnidt and Pearl,? \\Q1990\\E", "shortCiteRegEx": "Goldszrnidt and Pearl", "year": 1990}, {"title": "A maxi\u00ad mum entropy approach to nonmonotonic reasoning", "author": ["M. Goldszrnidt", "J. Pearl"], "venue": "In Eighth National Conference on Artificial Intelli\u00ad gence,", "citeRegEx": "Goldszrnidt and Pearl,? \\Q1990\\E", "shortCiteRegEx": "Goldszrnidt and Pearl", "year": 1990}, {"title": "A logic to reason about likelihood", "author": ["J. Halpern", "M. Rabin"], "venue": "Artificial Intelligence,", "citeRegEx": "Halpern and Rabin,? \\Q1987\\E", "shortCiteRegEx": "Halpern and Rabin", "year": 1987}, {"title": "Nonmono\u00ad tonic logic and temporal projection", "author": ["S. Hanks", "D. McDermott"], "venue": "Artificial In\u00ad telligence,", "citeRegEx": "Hanks and McDermott,? \\Q1987\\E", "shortCiteRegEx": "Hanks and McDermott", "year": 1987}, {"title": "De\u00ad cision theory in expert systems and artificial intel\u00ad ligence", "author": ["M. Henrion"], "venue": "International Journal of Approximate Rea\u00ad soning,", "citeRegEx": "Henrion,? \\Q1988\\E", "shortCiteRegEx": "Henrion", "year": 1988}, {"title": "A framework for comparing alternative formalisms for plausible reasoning", "author": ["E. Horvitz", "D. Heckerman", "C. Langlotz"], "venue": "In Fifth National Conference on Artificial Intelligence,", "citeRegEx": "Horvitz et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Horvitz et al\\.", "year": 1986}, {"title": "Logical and decision theoretic methods for planning under un\u00ad certainty", "author": ["C. Langlotz", "E. Shortliffe"], "venue": null, "citeRegEx": "Langlotz and Shortliffe,? \\Q1989\\E", "shortCiteRegEx": "Langlotz and Shortliffe", "year": 1989}, {"title": "Independence properties of directed Markov fields", "author": ["S. Lauritzen", "A. Dawid", "B. Larsen", "Leimer", "H.-G"], "venue": null, "citeRegEx": "Lauritzen et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Lauritzen et al\\.", "year": 1990}, {"title": "Semantical considerations on non\u00ad monotonic logic", "author": ["R. Moore"], "venue": "Artificial Intelligence,", "citeRegEx": "Moore,? \\Q1985\\E", "shortCiteRegEx": "Moore", "year": 1985}, {"title": "Prob\u00ad abilistic semantics and defaults", "author": ["E. Neufeld", "D. Poole", "R. Aleliunas"], "venue": "Un\u00ad certainty in Artificial Intelligence", "citeRegEx": "Neufeld et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Neufeld et al\\.", "year": 1990}, {"title": "Probabilistic logic. Artificial Intel\u00ad ligence, 28:71-87", "author": ["N. Nilsson"], "venue": "Pearl, J", "citeRegEx": "Nilsson,? \\Q1986\\E", "shortCiteRegEx": "Nilsson", "year": 1986}, {"title": "What the lottery paradox tells us about default reasoning", "author": ["D. Poole"], "venue": "In First International Con\u00ad ference on Principles of Knowledge Representation and Reasoning,", "citeRegEx": "Poole,? \\Q1989\\E", "shortCiteRegEx": "Poole", "year": 1989}], "referenceMentions": [{"referenceID": 2, "context": "In knowledge representation there is now a recognised need for the unification and development of these multiple, comple\u00ad mentary forms of reasoning (Brachman, 1990).", "startOffset": 149, "endOffset": 165}, {"referenceID": 11, "context": "Bayesian methods arc claimed to be normative, which means they set a standard for plausible rc<cson\u00ad ing and implies they will not suffer from the standard paradoxes that arc discussed in the non-monotonic lit\u00ad erature (Hanks and McDermott, 1987; Poole, 1989; Pearl, 1988; Etherington ct a!., 1990).", "startOffset": 219, "endOffset": 298}, {"referenceID": 19, "context": "Bayesian methods arc claimed to be normative, which means they set a standard for plausible rc<cson\u00ad ing and implies they will not suffer from the standard paradoxes that arc discussed in the non-monotonic lit\u00ad erature (Hanks and McDermott, 1987; Poole, 1989; Pearl, 1988; Etherington ct a!., 1990).", "startOffset": 219, "endOffset": 298}, {"referenceID": 7, "context": "ious conditional logics developed for default reason\u00ad ing (Delgrande, 1988; Pearl, 1988; Geffner, 1988) but most closely to Adams' improper conditional (Adams, 1966).", "startOffset": 58, "endOffset": 103}, {"referenceID": 0, "context": "ious conditional logics developed for default reason\u00ad ing (Delgrande, 1988; Pearl, 1988; Geffner, 1988) but most closely to Adams' improper conditional (Adams, 1966).", "startOffset": 152, "endOffset": 165}, {"referenceID": 1, "context": "Since the qualitative logic is an extension of Adams conditional logic (Adams, 1%6; Adams, 1975), applied to default reasoning by Geffner and Pearl (Pearl, 1988; Geffner, 1988), this greatly extends and simplifies Adams' and Goldszmidt and Pearl's (Goldszmidt and Pearl, 1990a) consistency and consequence tests by incorporating necessity, pos\u00ad sibility, and likelihood in a quantitative framework.", "startOffset": 71, "endOffset": 96}, {"referenceID": 7, "context": "Since the qualitative logic is an extension of Adams conditional logic (Adams, 1%6; Adams, 1975), applied to default reasoning by Geffner and Pearl (Pearl, 1988; Geffner, 1988), this greatly extends and simplifies Adams' and Goldszmidt and Pearl's (Goldszmidt and Pearl, 1990a) consistency and consequence tests by incorporating necessity, pos\u00ad sibility, and likelihood in a quantitative framework.", "startOffset": 148, "endOffset": 176}, {"referenceID": 10, "context": "This is related to the iterated likelihood operator found in (Halpern and Rabin, 1987) and has a formal justifi\u00ad cation in Theorem 3 part 2.", "startOffset": 61, "endOffset": 86}, {"referenceID": 0, "context": "The default and likelihood operators are \"improper\" according to Adams' terminology (Adams, 1966).", "startOffset": 84, "endOffset": 97}, {"referenceID": 16, "context": "Surprisingly enough, they also able to express sentences more in the spirit of autoepistemic (Moore, 1985) and default logics (Reiter, 1980).", "startOffset": 93, "endOffset": 106}, {"referenceID": 18, "context": "Notice though that whether a sentence from Dp is con\u00ad sistent or is a consequence of some other can be con\u00ad verted to a set of simplex problems in the variables, as done with Probabilistic Logic (Nilsson, 1986) .", "startOffset": 195, "endOffset": 210}, {"referenceID": 5, "context": "Etherington, Kraus and Perlis (Etherington et al., 1990) show a related problem applies to defanlt logic and circumscription.", "startOffset": 30, "endOffset": 56}, {"referenceID": 10, "context": "In contrast, likelihood reasoning systems suggested in the literature introduced qualitative variable strength like\u00ad lihoods from the beginning (Halpern and Rabin, 1987).", "startOffset": 144, "endOffset": 169}, {"referenceID": 6, "context": "Given that we need complementary reasoning forms, how do we unify them? It would be nice if we could somehow keep the different reasoning styles in sepa\u00ad rate modules, as suggested in hybrid reasoning sys\u00ad tems (Frisch and Cohn, 1991).", "startOffset": 211, "endOffset": 234}], "year": 2011, "abstractText": "This paper presents a plausible reasoning sys\u00ad tem to illustrate some broad issues in knowl\u00ad edge representation: dualities between dif\u00ad ferent reasoning forms, the difficulty of uni\u00ad fying complementary reasoning styles, and the approximate nature of plausible reason\u00ad ing. These issues have a common underly\u00ad ing theme: there should be an underlying belief calculus of which the many different reasoning forms are special cases, sometimes approximate. The system presented allows reasoning about defaults, likelihood, neces\u00ad sity and possibility in a manner similar to the earlier work of Adams. The system is based on the belief calculus of subjective Bayesian probability which itself is based on a few simple assumptions about how belief should be manipulated. Approximations, semantics, consistency and consequence results are pre\u00ad sented for the system. While this puts these often discussed plausible reasoning forms on a probabilistic footing, useful application to practical problems remains an issue.", "creator": "pdftk 1.41 - www.pdftk.com"}}}