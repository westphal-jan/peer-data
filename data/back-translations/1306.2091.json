{"id": "1306.2091", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2013", "title": "A framework for (under)specifying dependency syntax without overloading annotators", "abstract": "Our formalism builds on the typical representation of blank dependencies and allows for a simple writing and annotation workflow. In addition, formalism encourages annotators to sub-specify parts of the syntax if this would streamline the annotation process. We demonstrate the effectiveness of these annotations in three languages and develop algorithms to evaluate and compare underspecified annotations.", "histories": [["v1", "Mon, 10 Jun 2013 02:54:10 GMT  (75kb,D)", "https://arxiv.org/abs/1306.2091v1", "This is an expanded version of a paper appearing in Proceedings of the 7th Linguistic Annotation Workshop &amp; Interoperability with Discourse, Sofia, Bulgaria, August 8-9, 2013"], ["v2", "Sat, 15 Jun 2013 01:44:50 GMT  (75kb,D)", "http://arxiv.org/abs/1306.2091v2", "This is an expanded version of a paper appearing in Proceedings of the 7th Linguistic Annotation Workshop &amp; Interoperability with Discourse, Sofia, Bulgaria, August 8-9, 2013"]], "COMMENTS": "This is an expanded version of a paper appearing in Proceedings of the 7th Linguistic Annotation Workshop &amp; Interoperability with Discourse, Sofia, Bulgaria, August 8-9, 2013", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["nathan schneider", "brendan o'connor", "naomi saphra", "david bamman", "manaal faruqui", "noah a smith", "chris dyer", "jason baldridge"], "accepted": false, "id": "1306.2091"}, "pdf": {"name": "1306.2091.pdf", "metadata": {"source": "CRF", "title": "A Framework for (Under)specifying Dependency Syntax without Overloading Annotators", "authors": ["Nathan Schneider", "Brendan O\u2019Connor", "Naomi Saphra", "David Bamman", "Manaal Faruqui", "Noah A. Smith", "Chris Dyer", "Jason Baldridge"], "emails": ["nschneid@cs.cmu.edu"], "sections": [{"heading": null, "text": "A Framework for (Under)specifying Dependency Syntax without Overloading Annotators\nNathan Schneider\u2217 Brendan O\u2019Connor Naomi Saphra David Bamman Manaal Faruqui Noah A. Smith Chris Dyer School of Computer Science Carnegie Mellon University\nJason Baldridge Department of Linguistics, The University of Texas at Austin Abstract\nWe introduce a framework for lightweight dependency syntax annotation. Our formalism builds upon the typical representation for unlabeled dependencies, permitting a simple notation and annotation workflow. Moreover, the formalism encourages annotators to underspecify parts of the syntax if doing so would streamline the annotation process. We demonstrate the efficacy of this annotation on three languages and develop algorithms to evaluate and compare underspecified annotations. This paper is an expanded version of (Schneider et al., 2013) containing additional technical details."}, {"heading": "1 Introduction", "text": "Computational representations for natural language syntax are borne of competing design considerations. When designing such representations, there may be a tradeoff between parsimony and expressiveness. A range of linguistic theories attract support due to differing purposes and aesthetic principles (Chomsky, 1957; Tesni\u00e8re, 1959; Hudson, 1984; Sgall et al., 1986; Mel\u2019c\u030cuk, 1988, inter alia). Formalisms concerned with tractable computation may care chiefly about learnability or parsing efficiency (Shieber, 1992; Sleator and Temperly, 1993; Kuhlmann and Nivre, 2006). Further considerations may include psychological and evolutionary plausibility (Croft, 2001; Tomasello, 2003; Steels et al., 2011; Fossum and Levy, 2012), integration with other representations such as semantics (Steedman, 2000; Bergen and Chang, 2005), or suitability for particular applications (e.g., translation).\nHere we elevate ease of annotation as a primary design concern for a syntactic annotation formalism. Currently, a lack of annotated data is a huge bottleneck for robust NLP, standing in the way of parsers for social media text (Foster et al., 2011) and many low-resourced languages (to\n\u2217Corresponding author: nschneid@cs.cmu.edu\nname two examples). Traditional syntactic annotation projects like the Penn Treebank (Marcus et al., 1993) or Prague Dependency Treebank (Hajic\u030c, 1998) require highly trained annotators and huge amounts of effort. Lowering the cost of annotation, by making it easier and more accessible, could greatly facilitate robust NLP in new languages and genres, and allow researchers to more easily experiment with new tasks and problems.\nTo that end, we design and test new, lightweight methodologies for syntactic annotation. We propose a formalism, Fragmentary Unlabeled Dependency Grammar (FUDG) for unlabeled dependency syntax that addresses some of the most glaring deficiencies of basic unlabeled dependencies (\u00a72), with little added burden on annotators. FUDG requires minimal theoretical commitments, and can be supplemented with a languageor project-specific style guide (we provide a brief one for English). To facilitate efficient annotation, we contribute a simple ASCII markup language, Graph Fragment Language (GFL; \u00a73), that allows annotations to be authored using any text editor. We release tools that make it possible to validate, normalize, and visualize GFL annotations.1\nAn important characteristic of our framework is annotator flexibility. The formalism supports this by allowing underspecification of structural portions that are unclear or unnecessary for the purposes of a project. Fully leveraging this power requires new algorithms for evaluation, e.g., of interannotator agreement, where annotations are partial; such algorithms are presented in \u00a74.2\nFinally, small-scale case studies (\u00a75) apply our framework (formalism, notation, and evaluations) to syntactically annotate social web text in English, news in Malagasy, and dialogues in Kinyarwanda."}, {"heading": "2 A Dependency Grammar for Annotation", "text": "Although dependency-based approaches to syntax play a major role in computational linguistics, the\n1https://github.com/brendano/gfl_syntax/ 2Parsing algorithms are left for future work.\nar X\niv :1\n30 6.\n20 91\nv2 [\ncs .C\nL ]\n1 5\nJu n\n20 13\nnature of dependency representations is far from uniform. Exemplifying one end of the spectrum is the Prague Dependency Treebank, which articulates an elaborate dependency-based syntactic theory in a rich, multi-tiered formalism (Hajic\u030c, 1998; B\u00f6hmov\u00e1 et al., 2003). On the opposite end of the spectrum are the structures used in dependency parsing research which organize all the tokens of a sentence into a tree, sometimes with category labels on the edges (K\u00fcbler et al., 2009). Insofar as they reflect a theory of syntax, these vanilla dependency grammars provide a highly reductionist view of structure\u2014indeed, parses used to train and evaluate dependency parses are often simplifications of Prague-style parses, or else converted from constituent treebanks.\nIn addition to the binary dependency links of vanilla dependency representations, we offer three devices to capture certain linguistic phenomena more straightforwardly:3\n1. We make explicit the meaningful lexical units over which syntactic structure is represented. Our approach (a) allows punctuation and other extraneous tokens to be excluded so as not to distract from the essential structure; and (b) permits tokens to be grouped into shallow multiword lexical units.4 2. Coordination is problematic to represent with unlabeled dependencies due to its non-binary nature. A coordinating conjunction typically joins multiple expressions (conjuncts) with equal status, and other expressions may relate to the compound structure as a unit. There are several different conventions for forcing coordinate structures into a head-modifier straightjacket (Nivre, 2005; de Marneffe and Manning, 2008; Marec\u030cek et al., 2013). Conjuncts, coordinators, and shared de-\n3Some of this is inspired by the conventions of ReedKellogg sentence diagramming, a graphical dependency annotation system for English pedagogy (Reed and Kellogg, 1877; Kolln and Funk, 1994; Florey, 2006).\n4The Stanford representation supports a limited notion of multiword expressions (de Marneffe and Manning, 2008). For simplicity, our formalism treats multiwords as unanalyzed (syntactically opaque) wholes, though some multiword expressions may have syntactic descriptions (Baldwin and Kim, 2010).\npendents can be distinguished with edge labels; we equivalently use a special notation, permitting the coordinate structure to be automatically transformed with any of the existing conventions.5 3. Following Tesni\u00e8re (1959), our formalism offers a simple facility to express anaphoraantecedent relations (a subset of semantic relationships) that are salient in particular syntactic phenomena such as relative clauses, appositives, and wh-expressions."}, {"heading": "2.1 Underspecification", "text": "Our desire to facilitate lightweight annotation scenarios requires us to abandon the expectation that syntactic informants provide a complete parse for every sentence. On one hand, an annotator may be uncertain about the appropriate parse due to lack of expertise, insufficiently mature annotation conventions, or actual ambiguity in the sentence. On the other hand, annotators may be indifferent to certain phenomena. This can happen for a variety of reasons, including: \u2022 Some projects may only need annotations of\nspecific constructions. For example, building a semantic resource for events may require annotation of syntactic verb-argument relations, but not internal noun phrase structure. \u2022 As a project matures, it may be more useful\nto annotate only infrequent lexical items. \u2022 Semisupervised learning from partial an-\nnotations may be sufficient to learn complete parsers (Hwa, 1999; Clark and Curran, 2006). \u2022 Beginning annotators may wish to focus on\neasily understood syntactic phenomena. \u2022 Different members of a project may wish to\nspecialize in different syntactic phenomena, reducing training cost and cognitive load.\nRather than treating annotations as invalid unless and until they are complete trees, we formally represent and reason about partial parse structures.\n5Tesni\u00e8re (1959) and Hudson (1984) similarly use special structures for coordination (Schneider, 1998; Sangati and Mazza, 2009).\nAnnotators produce annotations, which encode constraints on the (inferred) analysis, the parse structure, of a sentence. We say that a valid annotation supports (is compatible with) one or more analyses. Both annotations and analyses are represented as graphs (the graph representation is described below in \u00a73.2). We require that the directed edges in an analysis graph must form a tree over all the lexical items in the sentence.6 Less stringent well-formedness constraints on the annotation graph leave room for underspecification.\nBriefly, an annotation can be underspecified in two ways: (a) an expression may not be attached to any parent, indicating it might depend on any nondescendant in a full analysis\u2014this is useful for annotating sentences piece by piece; and (b) multiple expressions may be grouped together in a fudge expression (\u00a73.3), a constraint that the elements form a connected subgraph in the full analysis while leaving the precise nature of that subgraph indeterminate\u2014this is useful for marking relationships between chunks (possibly constituents)."}, {"heading": "2.2 A Formalism, not a Theory", "text": "Our framework for dependency grammar annotation is a syntactic formalism, but it is not sufficiently comprehensive to constitute a theory of syntax. Though it standardizes the basic treatment of a few basic phenomena, simplicity of the formalism requires us to be conservative about making such extensions. Therefore, just as with simpler formalisms, language- and project-specific conventions will have to be developed for specific linguistic phenomena. By embracing underspecified annotation, however, our formalism aims to encourage efficient corpus coverage in a nascent annotation project, without forcing annotators to make premature decisions."}, {"heading": "3 Syntactic Formalism and GFL", "text": "In our framework, a syntactic annotation of a sentence follows an extended dependency formalism based on the desiderata enumerated in the previous section. We call our formalism Fragmentary Unlabeled Dependency Grammar (FUDG).\nTo make it simple to create FUDG annotations with a text editor, we provide a plain-text de-\n6While some linguistic phenomena (e.g., relative clauses, control constructions) can be represented using non-tree structures, we find that being able to alert annotators when they inadvertently violate the tree constraint is more useful than the expressive flexibility.\npendency notation called Graph Fragment Language (GFL). Fragments of the FUDG graph\u2014 nodes and dependencies linking them\u2014are encoded in this language; taken together, these fragments describe the annotation in its entirety. The ordering of GFL fragments, and of tokens within each fragment, is of no formal consequence. Since the underlying FUDG representation is transparently related to GFL constructions, GFL notation will be introduced alongside the discussion of each kind of FUDG node.7"}, {"heading": "3.1 Tokens", "text": "We expect a tokenized string, such as a sentence or short message. The provided tokenization is respected in the annotation. For human readability, GFL fragments refer to tokens as strings (rather than offsets), so all tokens that participate in an annotation must be unambiguous in the input.8 A token may be referenced multiple times in the annotation."}, {"heading": "3.2 Graph Encoding", "text": "Directed arcs. As in other dependency formalisms, dependency arcs are directed links indicating the syntactic headedness relationship between pairs of nodes. In GFL, directed arcs are indicated with angle brackets pointing from the dependent to its head, as in black > cat or (equivalently) cat < black. Multiple arcs can be chained together: the > cat < black < jet describes three arcs. Parentheses help group portions of a chain: (the > cat < black < jet) > likes < fish (the structure black < jet > likes, in which jet appears to have two heads, is disallowed). Note that another encoding for this structure would be to place the contents of the parentheses and the chain cat > likes < fish on separate lines. Curly braces can be used to list multiple dependents of the same head: {cat fish} > likes. Anaphoric links. These undirected links join coreferent anaphora to each other and to their antecedent(s). In English this includes personal pronouns, relative pronouns (who, which, that), and\n7In principle, FUDG annotations could be created with an alternative mechanism such as a GUI, as in Hajic\u030c et al. (2001).\n8If a word is repeated within the sentence, it must be indexed in the input string in order to be referred to from a fragment. In our notation, successive instances of the same word are suffixed with ~1, ~2, ~3, etc. Punctuation and other tokens omitted from an annotation do not need to be indexed.\nanaphoric do and so (Leo loves Ulla and so does Max). This introduces a bit of semantics into our annotation, though at present we do not attempt to mark non-anaphoric coreference. It also allows a more satisfying treatment of appositives and relative clauses than would be possible from just the directed tree (the third example in figures 3 and 4). Lexical nodes. Whereas in vanilla dependency grammar syntactic links are between pairs of token nodes, FUDG abstracts away from the individual tokens in the input. The lowest level of a FUDG annotation consists of lexical nodes, i.e., lexical item occurrences. Every token node maps to 0 or 1 lexical nodes (punctuation, for instance, can be ignored).\nA multiword is a lexical node incorporating more than one input token and is atomic (does not contain internal structure). A multiword node may group any subset of input tokens; this allows for multiword expressions which are not necessarily contiguous in the sentence (e.g., the verbparticle construction make up in make the story up). GFL notates multiwords with square brackets, e.g., [break a leg]. Coordination nodes. Coordinate structures require at least two kinds of dependents: coordinators (i.e., lexical nodes for coordinating conjunctions\u2014at least one per coordination node) and conjuncts (heads of the conjoined subgraphs\u2014at least one per coordination node). The GFL annotation has three parts: a variable representing the node, a set of conjuncts, and a set of coordinator nodes. For instance, $a :: {[peanut butter] honey} :: {and} (peanut butter and honey) can be embedded within a phrase via the coordination node variable $a; a [fresh [[peanut butter] and honey] sandwich] snack would be formed with {fresh $a} > sandwich > snack < a. A graphical example of coordination can be seen in figure 3\u2014 note the bolded conjunct edges and the dotted coordinator edges.\nIf the conjoined phrase as a whole takes modifiers, these are attached to the coordination node with regular directed arcs. For example, in Sam really adores kittens and abhors puppies., the shared subject Sam and adverb really attach to the entire conjoined phrase. In GFL:\n$a :: {adores abhors} :: {and}\nSam > $a < really\nadores < kittens\nabhors < puppies\nRoot node. This is a special top-level node used to indicate that a graph fragment constitutes a standalone utterance or a discourse connective. For an input with multiple utterances, the head of each should be designated with ** to indicate that it attaches to the root."}, {"heading": "3.3 Means of Underspecification", "text": "As discussed in \u00a72.1, our framework distinguishes annotations from full syntactic analyses. With respect to dependency structure (directed edges), the former may underspecify the latter, allowing the annotator to commit only to a partial analysis.\nFor an annotation A, we define support(A) to be the set of full analyses compatible with that annotation. A full analysis is required to be a directed rooted tree over all lexical nodes in the annotation. An annotation is valid if its support is non-empty.\nFUDG has two mechanisms for dependency underspecification: unattached nodes and fudge nodes.\nUnattached nodes. For any node in an annotation, the annotator is free to simply leave it not attached to any head. This is interpreted as allowing its head to be any other node (including the root node), subject to the tree constraint. We call a node\u2019s possible heads its supported parents. Formally, for an unattached node v in annotation A, suppParentsA(v) = nodes(A) \\ ({v} \u222a descendants(v)).\nFudge nodes. Sometimes, however, it is desirable to represent a sort of skeletal structure without filling in all the details. A fudge expression (FE) asserts that a group of nodes (the expression\u2019s members) belong together in a connected subgraph, while leaving the internal structure of that subgraph unspecified.9 The notation for this is a list of two or more nodes within parentheses: an annotation for Few if any witches are friends with Maria. might contain the FE (Few if any) so as to be compatible with the structures Few < if < any, Few > if > any, etc.\u2014 but not, for instance, Few > witches < any. In the FUDG graph, this is represented with a fudge node to which members are attached by special member arcs. Fudge nodes may be linked to other nodes: the GFL fragment (Few if any) > witches\n9This underspecification semantics is, to the best of our knowledge, novel, though it has been proposed that connected dependency subgraphs (known as catenae) are of theoretical importance in syntax (Osborne et al., 2012).\nis compatible with (Few < if < any) > witches, (Few < (if > any)) > witches, and so forth.\nProperties. Let f be a fudge expression. From the connected subgraph definition and the tree constraint on analyses, it follows that: \u2022 Exactly 1 member of f must, in any com-\npatible analysis, have a parent that is not a member of f. Call this node the top of the fudge expression, denoted f \u2217. f \u2217 dominates all other members of f; it can be considered f\u2019s \u201cinternal head.\u201d \u2022 f does not necessarily form a full subtree.\nAny of its members may have dependents that are not themselves members of the fudge expression. (Such dependencies can be specified in additional GFL fragments.)\nTop designation. A single member of a fudge expression may optionally be designated as its top (internal head). This is specified with an asterisk: (Few* if any) > witches indicates that Few must attach to witches and also dominate both if and any. In the FUDG graph, this is represented with a special top arc as depicted in bold in figure 2.\nNesting. One fudge expression may nest within another, e.g. (Few (if any)) > witches; the word analyzed as attaching to witches might be Few or whichever of (if any) heads the other. A nested fudge expression can be designated as top: (Vanishingly few (if any)*).\nModifiers. An arc attaching a node to a fudge expression as a whole asserts that the external node should modify the top of the fudge expression (whether or not that top is designated in the annotation). For instance, two of the interpretations of British left waffles on Falklands would be preserved by specifying British > left and (left waffles) < on < Falklands. Analyses British > left < waffles < on < Falklands and (British > left < on < Falklands) > waffles would be excluded because the preposition does not attach to the head of (left waffles).10\n10Not all attachment ambiguities can be precisely encoded in FUDG. For instance, there is no way to forbid an attachment to a word that lies along the path between the possible heads. The best that can be done given a sentence\nMultiple membership. A node may be a member of multiple fudge expressions, or a member of an FE while attached to some other node via an explicit arc. Each connected component of the FUDG graph is therefore a polytree (not necessarily a tree). The annotation graph minus all member edges of fudge nodes and all (undirected) anaphoric links must be a directed tree or forest.\nEnumerating supported parents. Fudge expressions complicate the procedure for listing a node\u2019s supported parents (see above). Consider an FE f having some member v. v might be the top of f (unless some other node is so designated), in which case anything the fudge node can attach to is a potential parent of v. If some node other than v might be the top of f, then v\u2019s head could be any member of f. Below (\u00a74.1) we develop an algorithm for enumerating supported parents for any annotation graph node."}, {"heading": "4 Annotation Evaluation Measures", "text": "Quantifying inter-annotator agreement on a common dataset is an important tool for reasoning about individual annotators and the overall difficulty of the annotation task (influenced by the nature of the data, the annotation process, and the training/guidelines/reference materials available to annotators). If there is a well-defined set of decisions that need to be made for each sentence,\nlike They conspired to defenestrate themselves on Tuesday. is They > conspired < to < defenestrate < themselves and (conspired* to defenestrate (on < Tuesday)).\nthe two annotators\u2019 choices can be compared directly. However, when the task allows for a great deal of latitude\u2014as in our case, where a syntactic annotation may be full or partial\u2014the comparison becomes more difficult. We formalize techniques for comparing two annotations in our formalism, keeping in mind that the structure may be underspecified in different parts or to different degrees. We must further address: \u2022 Annotation efficiency, quantified in terms of\nannotator productivity (tokens per hour). \u2022 The amount of information in an underspec-\nified annotation. Intuitively, an annotation that flirts with many full analyses conveys less syntactic information than one which supports few analyses. We define an annotation\u2019s promiscuity to be the number of full analyses it supports, and develop an algorithm to compute it (\u00a74.1). \u2022 Inter-annotator agreement between two\npartial annotations. Our measures for dependency structure agreement (\u00a74.2) incorporate the notion of promiscuity.\nWe test these evaluations on our pilot annotation data in the case studies (\u00a75)."}, {"heading": "4.1 Promiscuity vs. Commitment", "text": "Given a FUDG annotation of a sentence, we quantify the extent to which it underspecifies the full structure by counting the number of analyses that are compatible with the constraints in the annotation. We call this number the promiscuity of the annotation. Each analysis tree is rooted with the root node and must span all lexical nodes.11\nA na\u00efve algorithm for computing promiscuity would be to enumerate all directed spanning trees over the lexical nodes, and then check each of them for compatibility with the annotation. But this quickly becomes intractable: for n nodes,\n11This measure assumes a fixed lexical analysis (set of lexical nodes) and does not consider anaphoric links. Coordinate structures are simplified into ordinary dependencies, with coordinate phrases headed by the coordinator\u2019s lexical node. If a coordination node has multiple coordinators, one is arbitrarily chosen as the head and the others as its dependents.\nAlgorithm 1: Identify the possible top nodes for each fudge node, traversing the annotation graph fragments bottom-up.\ndef upward(F): for n in sorted(F.nodes, key=lambda v: v.height): if n.isFudge: n.topcandidates = set() for (c,e) in n.childedges: if e=='top': n.topcandidates = tc(c) break # there can be only one top edge\nelif e=='member': n.topcandidates |= tc(c)\ndef tc(n): return set(n.topcandidates) if n.isFudge else {n}\none of which is designated as the root, there are nn\u22122 spanning trees. However, we can filter out edges that are known to be incompatible with the annotation before searching for spanning trees. Our \u201cupward-downward\u201d method for constructing a graph of supported edges first enumerates a set of candidate top nodes for every fudge expression (algorithm 1), then uses that information to infer a set of supported parents for every node (algorithm 2). The supported edge graph then consists of vertices lexnodes(A) \u222a {root} and edges\u22c3\nv\u2208lexnodes(A) {(v\u2192 v\u2032) \u2200 v\u2032 \u2208 suppParentsA(v)}. From this graph we then extract all directed spanning trees using the algorithm of Uno (1996). If some lexical node has no supported parents, this reflects conflicting constraints in the annotation, and no spanning tree will be found.\nOne final step is needed to ensure that nonmember attachments to a fudge node, such as e in figure 2, attach to the top node of the fudge expression. The structure a < b < e is not supported by the annotation, though its individual edges are. Such spanning trees must be filtered out post hoc. Alternatively, Kirchhoff\u2019s matrix tree theorem (Chaiken and Kleitman, 1978; Smith and Smith, 2007; Margoliash, 2010) can be used to count all spanning trees in cubic time without enumerating them, and thus obtain an upper bound on promiscuity.12 In \u00a75 we use \u201cExact\u201d promiscuity\n12This would also allow efficient probabilistic inference over analyses given annotations, at least under common modeling assumptions.\nAlgorithm 2: Identify nodes\u2019 possible parents in an analysis by traversing the annotation graph top-down. \u201cFirm\u201d nodes are all non-fudge nodes. Set operators: | (union), & (intersection), - (difference).\ndef downward(G): for n in sorted(G.nodes, key=lambda v: v.depth): if not n.isRoot: n.suppParents = G.firmNodes-{n}-n.descendants for (p,e) in n.parentedges: if p.isFudge: if n in p.members: cands = set() if p.topcandidates & tc(n): # (top of) n might be the top of p cands |= p.suppParents\nif p.topcandidates!=tc(n): # (top of) n might not be the top of p siblings = p.members - {n} for sib in siblings: cands |= tc(sib)\nn.suppParents &= cands else: # external modifier of a fudge node n.suppParents &= p.topcandidates\nelse: # explicit parent a lexical node or root n.suppParents &= {p}\nfor annotations where enumerating all analyses is tractable, and \u201cKirchhoff\u201d promiscuity for approximately measuring all annotations.\nPromiscuity will tend to be higher for longer sentences. To control for this, we define a second quantity, the annotation\u2019s commitment quotient (commitment being the opposite of promiscuity), which normalizes for the number of possible spanning trees given the sentence length. The commitment quotient for an annotation of a sentence with n \u2212 1 lexical nodes and one root node is given by:\ncom(A) = log nn\u22122 \u2212 log prom(A) log nn\u22122 \u2212 log 1 = 1\u2212 log prom(A) log nn\u22122\n(the logs are to attenuate the dominance of the exponential term). This will be 1 if only a single tree is supported by the annotation, and 0 if the annotation does not constrain the structure at all. (If the constraints in the annotation are internally inconsistent, then promiscuity will be 0 and commitment undefined.) In practice, there is a tradeoff between efficiency and commitment: more detailed annotations require more time. The value of minimizing promiscuity will therefore depend on the resources and goals of the annotation project."}, {"heading": "4.2 Inter-Annotator Agreement", "text": "FUDG can encode flat groupings and coreference at the lexical level, as well as syntactic structure over lexical items. Inter-annotator agreement can be measured separately for each of these facets. Pilot annotator feedback indicated that our initial lexical-level guidelines were inadequate, so we fo-\ncus here on measuring structural agreement pending further clarification of the lexical conventions.\nAttachment accuracy, a standard measure for evaluating dependency parsers, cannot be computed between two FUDG annotations if either of them underspecifies any part of the dependency structure. One solution is to consider the intersection of supported full trees, in the spirit of our promiscuity measure. For annotations A1 and A2 of sentence s, one annotation\u2019s supported analyses can be enumerated and then filtered subject to the constraints of the other annotation. The tradeoff between inter-annotator compatibility and commitment can be accounted for by taking their product, i.e. comPrec(A1 | A2) = com(A1)\n|supp(A1)\u2229supp(A2)| |supp(A1)| .\nA limitation of this support-intersection approach is that if the two annotations are not compatible, the intersection will be empty. A more fine-grained approach is to decompose the comparison by lexical node: we generalize attachment accuracy with softComPrec(A1 | A2) = com(A1) \u2211 `\u2208s \u22c2\ni\u2208{1,2} suppParentsAi (`)\u2211 `\u2208s suppParentsA1 (`)\n, taking advantage of the algorithms in the previous section to compute com(\u00b7) and suppParents(\u00b7). As lexical nodes may differ between the two annotations, a reconciliation step is required to compare the structures: multiwords proposed in only one of the two annotations are converted to fudge expressions. Tokens annotated by neither annotator are ignored; excluding punctuation is standard practice in dependency evaluation (Buchholz and Marsi, 2006). Like with the promiscuity measure, we simplify coordinate structures to ordinary dependencies (see footnote 11)."}, {"heading": "5 Case Studies", "text": ""}, {"heading": "5.1 Annotation Time", "text": "To estimate annotation efficiency, we performed a pilot annotation project consisting of annotating several hundred English tweets, about 1,000 sentences in Malagasy, and a further 1,000 sentences in Kinyarwanda.13 Table 1 summarizes the num-\n13Malagasy is a VOS Austronesian language spoken by 15 million people, mostly in Madagascar. Kinyarwanda is an\nber of tokens annotated and the effort required. For the two Twitter cases, the same annotator was first permitted to do partial annotation (specifically, her instructions were to leave unannotated all punctuation and any \u201cTwitter discourse\u201d markers that did not participate in syntactic relations) of 100 tweets, and then spend the same amount of time doing a complete annotation of all tokens. Although this is a very small study, the results clearly suggest she was able to make much more rapid progress when partial annotation was an option.14\nThis pilot study helped us to identify linguistic phenomena warranting specific conventions: these include wh-expressions, comparatives, vocatives, discourse connectives, null copula constructions, and many others. We documented these cases in a 20-page style guide for English,15 which informed the subsequent pilot studies discussed below."}, {"heading": "5.2 Underspecification and Agreement", "text": "With detailed guidelines in place, we then annotated two small English data samples in order to study annotators\u2019 use of underspecification. The first sample is drawn from Owoputi et al.\u2019s (2012) Twitter part-of-speech corpus.16 The second is from the Reviews portion of the English Web Treebank (Bies et al., 2012), which contains Penn Treebank\u2013style constituent parses. (Our annotators only saw the tokenized text.) Both datasets are informal and conversational in nature, and are dominated by short messages/sentences. In spite of their brevity, many of the items were deemed to contain multiple \u201cutterances,\u201d which we define to include discourse connectives and emoticons (at best marginal parts of the syntax); utterance heads are marked with ** in figure 1.\nTable 2 indicates the sizes of the two data samples, and gives statistics over the output of each annotator: total counts of single-word and multiword lexical nodes, tokens not represented by any lexical node, coordination nodes, anaphoric\nSVO Bantu language spoken by 12 million people mostly in Rwanda. All annotations were done by native speakers of English. The Kinyarwanda and Malagasy annotators had basic proficiency in these languages.\n14As a point of comparison, during the Penn Treebank project, annotators corrected the syntactic bracketings produced by a high-quality hand-written parser (Fidditch) and achieved a rate of only 375 tokens/hour using a specialized GUI interface (Marcus et al., 1993).\n15Included with the data and software release (footnote 1). 16Specifically, the Daily547 portion, downloaded from\nhttp://www.ark.cs.cmu.edu/TweetNLP/\nlinks, utterances,17 and fudge nodes; as well as a histogram of promiscuity counts and the average of commitment quotients (see \u00a74.1). For instance, the two sets of annotations obtained for the Tweets sample used underspecification in 17/60 and 23/60 tweets, respectively, though the promiscuity rarely exceeded 100 compatible trees per annotation. Examples can be seen in figure 1, where annotator \u201cA\u201d marked only the noun phrase head for the scarriest mystery door, opted not to choose a head within the quantity 1 1/2, and left ambiguous the attachment of the hedge like. The strong but not utter commitment to the dependency structure is reflected in the mean commitment quotients for this dataset, both of which exceed 0.95.\nInter-annotator agreement (IAA) is quantified in table 3. The row marked A \u223c B, for instance, considers the agreement between annotator \u201cA\u201d and annotator \u201cB\u201d. A handful of individual annotations are too underspecified for enumeration of all analyses to be tractable; sentences having this property for either of the two annotations are removed from consideration in the \u201cExact\u201d measurements, as indicated by the N column. Measuring IAA on the dependency structure requires a common set of lexical nodes, so a lexical reconciliation step ensures that (a) any token used by either annotation is present in both, and (b) no multiword node is present in only one annotation\u2014this is solved by relaxing incompatible multiwords to fudge expressions (which increases promiscuity). For Tweets, lexical reconciliation thus reduces the commitment averages for each annotation\u2014to a greater extent for annotator \u201cA\u201d (.96 in table 2 vs. .86 in table 3) because \u201cA\u201d marked more multiwords. An analysis fully compatible with both annotations exists for only 22/53 sentences; the finergrained softComPrec measure (\u00a74.2), however, offers insight into the balance between commitment and agreement.\nThe right half of table 3 uses Kirchhoff\u2019s matrix tree theorem (see \u00a74.1) to estimate the number of supported analyses for all sentences, including those that support too many analyses to enumerate. (The Kirchhoff count is an upper bound on promiscuity.) In general, the averages seen with the Kirchhoff estimates are comparable to the averages with the exact promiscuity/commitment measures.\n17Utterance counts are given as ranges, as any annotation fragment not explicitly headed by the root node may or may not form its own utterance.\nQualitatively, we observe three leading causes of incompatibilities (disagreements): obvious annotator mistakes (such as the marked as a head); inconsistent handling of verbal auxiliaries; and uncertainty whether to attach expressions to a verb or the root node, as with here in figure 1.18 Annotators noticed occasional ambiguous cases and attempted to encode the ambiguity with fudge expressions: again in the tweet maybe put it off until you feel like ~ talking again ? is one example. More commonly, fudge expressions proved useful for syntactically difficult constructions, such as those shown in figure 1 as well as: such a good night, asked what tribe I was from, you two, 2 shy of breaking it, a $ 13 / day charge, and the most awkward thing ever."}, {"heading": "5.3 Annotator Specialization", "text": "As an experiment in using underspecification for labor division, two of the annotators of Reviews data were assigned specific linguistic phenomena to focus on. Annotator \u201cD\u201d was tasked with the internal structure of base noun phrases, including resolving the antecedents of personal pronouns. \u201cC\u201d was asked to mark the remaining phenomena\u2014\n18Another example: Some uses of conjunctions like and and so could be interpreted either as phrasal coordinators or as discourse connectives (cf. The PDTB Research Group, 2007).\ni.e., utterance/clause/verb phrase structure\u2014but to mark base noun phrases as fudge expressions, leaving their internal structure unspecified. Both annotators provided a full lexical analysis. For comparison, a third individual, \u201cA,\u201d annotated the same data in full. The three annotators worked completely independently.\nOf the results in tables 2 and 3, the most notable difference between full and specialized annotation is that the combination of independent specialized annotations (C \u2229 D) produces somewhat higher promiscuity/lower commitment. This is unsurprising because annotators sometimes overlook relationships that fall under their specialty.19 Still, annotators reported that specialization made the task less burdensome, and the specialized annotations did prove complementary to each other.20"}, {"heading": "5.4 Treebank Comparison", "text": "Though the annotators in our study were native speakers well acquainted with representations of English syntax, we sought to quantify their agreement with the expert treebankers who cre-\n19A more practical and less error-prone approach might be for specialists to work sequentially or collaboratively (rather than independently) on each sentence.\n20In fact, for only 2 sentences did \u201cC\u201d and \u201cD\u201d have incompatible annotations, and both were due to simple mistakes that were then fixed in the combination.\nated the English Web Treebank (the source of the Reviews sentences). To convert the Treebank\u2019s constituent parses to dependencies, we used the PennConverter tool (Johansson and Nugues, 2007) with options chosen to emulate our annotation conventions,21 and then removed punctuation tokens.\nAgreement with the converted treebank parses appears in the bottom two rows of table 3. Because the Treebank commits to a single analysis, precision scores are quite lopsided. Most of its attachments are consistent with our annotations (softComPrec scores upwards of 0.9), but these allow many additional analyses (hence the scores below 0.6)."}, {"heading": "6 Conclusion", "text": "We have presented a framework for simple dependency annotation that overcomes some of the representational limitations of unlabeled dependency grammar and embraces the practical realities of resource-building efforts. Pilot studies (in multiple languages and domains, supported by a humanreadable notation and a suite of open-source tools) showed this approach lends itself to rapid annotation with minimal training.\nThe next step will be to develop algorithms exploiting these representations for learning parsers. Other future extensions might include additional expressive mechanisms (e.g., multi-headedness, labels), crowdsourcing of FUDG annotations (Snow et al., 2008),22 or even a semantic counterpart to the syntactic representation."}, {"heading": "Acknowledgments", "text": "We > thank < ([Lukas Biewald], [Yoav Goldberg], [Kyle Jerro], [Vijay John], [Lori Levin], [Andr\u00e9 Martins], and (several anonymous reviewers*)) for < (their > insights). This research was supported in part by the U. S. Army Research Laboratory and the U. S. Army Research Office under contract/grant number W911NF-10-1-0533 and by NSF grant IIS-1054319.\n21Downloaded from http://nlp.cs.lth.se/ software/treebank_converter/ and run with -rightBranching=false -coordStructure=prague -prepAsHead=true -posAsHead=true -subAsHead=true -imAsHead=true -whAsHead=false 22We ran a pilot survey on Mechanical Turk and found 80 workers with experience in sentence diagramming (footnote 3), suggesting that simple syntactic annotations may be feasibly produced by non-expert annotators."}], "references": [{"title": "Multiword expressions", "author": ["Timothy Baldwin", "Su Nam Kim."], "venue": "Nitin Indurkhya and Fred J. Damerau, editors, Handbook of Natural Language Processing, Second Edition. CRC Press, Taylor and Francis Group, Boca Raton, FL.", "citeRegEx": "Baldwin and Kim.,? 2010", "shortCiteRegEx": "Baldwin and Kim.", "year": 2010}, {"title": "Embodied Construction Grammar in simulation-based language understanding", "author": ["Benjamin K. Bergen", "Nancy Chang."], "venue": "Jan-Ola \u00d6stman and Mirjam Fried, editors, Construction grammars: cognitive grounding and theoretical extensions, pages", "citeRegEx": "Bergen and Chang.,? 2005", "shortCiteRegEx": "Bergen and Chang.", "year": 2005}, {"title": "English Web Treebank", "author": ["Ann Bies", "Justin Mott", "Colin Warner", "Seth Kulick."], "venue": "Technical Report LDC2012T13, Linguistic Data Consortium, Philadelphia, PA.", "citeRegEx": "Bies et al\\.,? 2012", "shortCiteRegEx": "Bies et al\\.", "year": 2012}, {"title": "The Prague Dependency Treebank: a three-level annotation scenario", "author": ["Alena B\u00f6hmov\u00e1", "Jan Haji\u010d", "Eva Haji\u010dov\u00e1", "Barbora Hladk\u00e1", "Anne Abeill\u00e9."], "venue": "Treebanks: building and using parsed corpora, pages 103\u2013127. Springer.", "citeRegEx": "B\u00f6hmov\u00e1 et al\\.,? 2003", "shortCiteRegEx": "B\u00f6hmov\u00e1 et al\\.", "year": 2003}, {"title": "CoNLLX shared task on multilingual dependency parsing", "author": ["Sabine Buchholz", "Erwin Marsi."], "venue": "Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 149\u2013164, New York City, June. Association", "citeRegEx": "Buchholz and Marsi.,? 2006", "shortCiteRegEx": "Buchholz and Marsi.", "year": 2006}, {"title": "Matrix Tree Theorems", "author": ["Seth Chaiken", "Daniel J. Kleitman."], "venue": "Journal of Combinatorial Theory, Series A, 24(3):377\u2013381, May.", "citeRegEx": "Chaiken and Kleitman.,? 1978", "shortCiteRegEx": "Chaiken and Kleitman.", "year": 1978}, {"title": "Syntactic Structures", "author": ["Noam Chomsky."], "venue": "Mouton, La Haye.", "citeRegEx": "Chomsky.,? 1957", "shortCiteRegEx": "Chomsky.", "year": 1957}, {"title": "Partial training for a lexicalized-grammar parser", "author": ["Stephen Clark", "James Curran."], "venue": "Proceedings of the Human Language Technology Conference of the NAACL (HLT-NAACL 2006), pages 144\u2013 151, New York City, USA, June. Association for", "citeRegEx": "Clark and Curran.,? 2006", "shortCiteRegEx": "Clark and Curran.", "year": 2006}, {"title": "Radical Construction Grammar: Syntactic Theory in Typological Perspective", "author": ["William Croft."], "venue": "Oxford University Press, Oxford.", "citeRegEx": "Croft.,? 2001", "shortCiteRegEx": "Croft.", "year": 2001}, {"title": "Stanford typed dependencies manual", "author": ["Marie-Catherine de Marneffe", "Christopher D. Manning."], "venue": "http://nlp.stanford.edu/downloads/ dependencies_manual.pdf.", "citeRegEx": "Marneffe and Manning.,? 2008", "shortCiteRegEx": "Marneffe and Manning.", "year": 2008}, {"title": "Sister Bernadette\u2019s Barking Dog: The quirky history and lost art of diagramming sentences", "author": ["Kitty Burns Florey."], "venue": "Melville House, New York, October.", "citeRegEx": "Florey.,? 2006", "shortCiteRegEx": "Florey.", "year": 2006}, {"title": "Sequential vs", "author": ["Victoria Fossum", "Roger Levy."], "venue": "hierarchical syntactic models of human incremental sentence processing. In Proceedings of the 3rd Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2012), pages 61\u201369, Mon-", "citeRegEx": "Fossum and Levy.,? 2012", "shortCiteRegEx": "Fossum and Levy.", "year": 2012}, {"title": "hardtoparse: POS Tagging and Parsing the Twitterverse", "author": ["Jennifer Foster", "Ozlem Cetinoglu", "Joachim Wagner", "Joseph Le Roux", "Stephen Hogan", "Joakim Nivre", "Deirdre Hogan", "Josef van Genabith."], "venue": "Proceedings of the 2011 AAAI Workshop", "citeRegEx": "Foster et al\\.,? 2011", "shortCiteRegEx": "Foster et al\\.", "year": 2011}, {"title": "The Prague Dependency Treebank: annotation structure and support", "author": ["Jan Haji\u010d", "Barbora Vidov\u00e1 Hladk\u00e1", "Petr Pajas."], "venue": "Proceedings of the IRCS Workshop on Linguistic Databases, pages 105\u2013114. University of Pennsylvania, Philadelphia,", "citeRegEx": "Haji\u010d et al\\.,? 2001", "shortCiteRegEx": "Haji\u010d et al\\.", "year": 2001}, {"title": "Building a syntactically annotated corpus: the Prague Dependency Treebank", "author": ["Jan Haji\u010d."], "venue": "Eva Haji\u010dov\u00e1, editor, Issues of Valency and Meaning. Studies in Honor of Jarmila Panevov\u00e1, pages 12\u2013", "citeRegEx": "Haji\u010d.,? 1998", "shortCiteRegEx": "Haji\u010d.", "year": 1998}, {"title": "Word Grammar", "author": ["Richard A. Hudson."], "venue": "Blackwell, Oxford.", "citeRegEx": "Hudson.,? 1984", "shortCiteRegEx": "Hudson.", "year": 1984}, {"title": "Supervised grammar induction using training data with limited constituent information", "author": ["Rebecca Hwa."], "venue": "Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL-99), pages 73\u201379, College Park, Maryland,", "citeRegEx": "Hwa.,? 1999", "shortCiteRegEx": "Hwa.", "year": 1999}, {"title": "Extended constituent-to-dependency conversion for English", "author": ["Richard Johansson", "Pierre Nugues."], "venue": "Joakim Nivre, Heiki-Jaan Kaalep, Kadri Muischnek, and Mare Koit, editors, Proceedings of the 16th Nordic Conference of Computational Lin-", "citeRegEx": "Johansson and Nugues.,? 2007", "shortCiteRegEx": "Johansson and Nugues.", "year": 2007}, {"title": "Understanding English Grammar", "author": ["Martha Kolln", "Robert Funk."], "venue": "Macmillan, New York.", "citeRegEx": "Kolln and Funk.,? 1994", "shortCiteRegEx": "Kolln and Funk.", "year": 1994}, {"title": "Dependency Parsing", "author": ["Sandra K\u00fcbler", "Ryan McDonald", "Joakim Nivre."], "venue": "Number 2 in Synthesis Lectures on Human Language Technologies. Morgan & Claypool, San Rafael, CA, January.", "citeRegEx": "K\u00fcbler et al\\.,? 2009", "shortCiteRegEx": "K\u00fcbler et al\\.", "year": 2009}, {"title": "Mildly non-projective dependency structures", "author": ["Marco Kuhlmann", "Joakim Nivre."], "venue": "Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 507\u2013514, Sydney, Australia, July. Association for Computational Linguistics.", "citeRegEx": "Kuhlmann and Nivre.,? 2006", "shortCiteRegEx": "Kuhlmann and Nivre.", "year": 2006}, {"title": "Building a large annotated corpus of English: the Penn Treebank", "author": ["Mitchell P. Marcus", "Beatrice Santorini", "Mary Ann Marcinkiewicz."], "venue": "Computational Linguistics, 19(2):313\u2013330.", "citeRegEx": "Marcus et al\\.,? 1993", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "Cross-language study on influence of coordination style on dependency parsing", "author": ["Jan \u0160t\u011bp\u00e1nek", "Daniel Zeman", "Zden\u011bk \u017dabokrtsk\u00fd", "Jan Haji\u010d"], "venue": null, "citeRegEx": "\u0160t\u011bp\u00e1nek et al\\.,? \\Q2013\\E", "shortCiteRegEx": "\u0160t\u011bp\u00e1nek et al\\.", "year": 2013}, {"title": "Matrix-Tree Theorem for directed graphs", "author": ["Jonathan Margoliash"], "venue": null, "citeRegEx": "Margoliash.,? \\Q2010\\E", "shortCiteRegEx": "Margoliash.", "year": 2010}, {"title": "Dependency grammar and dependency parsing", "author": ["Joakim Nivre."], "venue": "Technical Report MSI report 05133, V\u00e4xj\u00f6 University School of Mathematics and Systems Engineering, V\u00e4xj\u00f6, Sweden.", "citeRegEx": "Nivre.,? 2005", "shortCiteRegEx": "Nivre.", "year": 2005}, {"title": "Catenae: introducing a novel unit of syntactic analysis", "author": ["Timothy Osborne", "Michael Putnam", "Thomas Gro\u00df."], "venue": "Syntax, 15(4):354\u2013396.", "citeRegEx": "Osborne et al\\.,? 2012", "shortCiteRegEx": "Osborne et al\\.", "year": 2012}, {"title": "Partof-speech tagging for Twitter: Word clusters and other advances", "author": ["Olutobi Owoputi", "Brendan O\u2019Connor", "Chris Dyer", "Kevin Gimpel", "Nathan Schneider"], "venue": "Technical Report CMU-ML-12107,", "citeRegEx": "Owoputi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Owoputi et al\\.", "year": 2012}, {"title": "Work on English grammar & composition", "author": ["Alonzo Reed", "Brainerd Kellogg."], "venue": "Clark & Maynard.", "citeRegEx": "Reed and Kellogg.,? 1877", "shortCiteRegEx": "Reed and Kellogg.", "year": 1877}, {"title": "An English dependency treebank \u00e0 la Tesni\u00e8re", "author": ["Federico Sangati", "Chiara Mazza."], "venue": "Marco Passarotti, Adam Przepi\u00f3rkowski, Savina Raynaud, and Frank Van Eynde, editors, Proceedings of the Eigth International Workshop on Treebanks and Linguistic", "citeRegEx": "Sangati and Mazza.,? 2009", "shortCiteRegEx": "Sangati and Mazza.", "year": 2009}, {"title": "A framework for (under)specifying dependency syntax without overloading annotators", "author": ["Nathan Schneider", "Brendan O\u2019Connor", "Naomi Saphra", "David Bamman", "Manaal Faruqui", "Noah A. Smith", "Chris Dyer", "Jason Baldridge"], "venue": null, "citeRegEx": "Schneider et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Schneider et al\\.", "year": 2013}, {"title": "A linguistic comparison of constituency, dependency and link grammar", "author": ["Gerold Schneider."], "venue": "Master\u2019s thesis, University of Zurich, July.", "citeRegEx": "Schneider.,? 1998", "shortCiteRegEx": "Schneider.", "year": 1998}, {"title": "The Meaning of the Sentence in its Semantic and Pragmatic Aspects", "author": ["Petr Sgall", "Eva Haji\u010dov\u00e1", "Jarmila Panevov\u00e1."], "venue": "Reidel, Dordrecht and Academia, Prague, May.", "citeRegEx": "Sgall et al\\.,? 1986", "shortCiteRegEx": "Sgall et al\\.", "year": 1986}, {"title": "Constraint-Based Grammar Formalisms", "author": ["Stuart M. Shieber."], "venue": "MIT Press, Cambridge, MA.", "citeRegEx": "Shieber.,? 1992", "shortCiteRegEx": "Shieber.", "year": 1992}, {"title": "Parsing English with a link grammar", "author": ["Daniel Sleator", "Davy Temperly."], "venue": "Proceedings of the Third International Workshop on Parsing Technology (IWPT\u201993), pages 277\u2013292, Tilburg, Netherlands, August.", "citeRegEx": "Sleator and Temperly.,? 1993", "shortCiteRegEx": "Sleator and Temperly.", "year": 1993}, {"title": "Probabilistic models of nonprojective dependency trees", "author": ["David A. Smith", "Noah A. Smith."], "venue": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learn-", "citeRegEx": "Smith and Smith.,? 2007", "shortCiteRegEx": "Smith and Smith.", "year": 2007}, {"title": "Cheap and fast \u2014 but is it good? Evaluating non-expert annotations for natural language tasks", "author": ["Rion Snow", "Brendan O\u2019Connor", "Daniel Jurafsky", "Andrew Ng"], "venue": "In Proceedings of the 2008 Conference on Empirical Methods in Natural Lan-", "citeRegEx": "Snow et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Snow et al\\.", "year": 2008}, {"title": "The Syntatic Process", "author": ["Mark Steedman."], "venue": "MIT Press, Cambridge, MA.", "citeRegEx": "Steedman.,? 2000", "shortCiteRegEx": "Steedman.", "year": 2000}, {"title": "El\u00e9ments de Syntaxe Structurale", "author": ["Lucien Tesni\u00e8re."], "venue": "Klincksieck, Paris.", "citeRegEx": "Tesni\u00e8re.,? 1959", "shortCiteRegEx": "Tesni\u00e8re.", "year": 1959}, {"title": "Constructing a Language: A Usage-Based Theory of Language Acquisition", "author": ["Michael Tomasello."], "venue": "Harvard University Press, Cambridge, MA.", "citeRegEx": "Tomasello.,? 2003", "shortCiteRegEx": "Tomasello.", "year": 2003}, {"title": "An algorithm for enumerating all directed spanning trees in a directed graph", "author": ["Takeaki Uno."], "venue": "Tetsuo Asano, Yoshihide Igarashi, Hiroshi Nagamochi, Satoru Miyano, and Subhash Suri, editors, Algorithms and Computation, number 1178 in Lec-", "citeRegEx": "Uno.,? 1996", "shortCiteRegEx": "Uno.", "year": 1996}], "referenceMentions": [{"referenceID": 29, "context": "This paper is an expanded version of (Schneider et al., 2013) containing additional technical details.", "startOffset": 37, "endOffset": 61}, {"referenceID": 32, "context": "Formalisms concerned with tractable computation may care chiefly about learnability or parsing efficiency (Shieber, 1992; Sleator and Temperly, 1993; Kuhlmann and Nivre, 2006).", "startOffset": 106, "endOffset": 175}, {"referenceID": 33, "context": "Formalisms concerned with tractable computation may care chiefly about learnability or parsing efficiency (Shieber, 1992; Sleator and Temperly, 1993; Kuhlmann and Nivre, 2006).", "startOffset": 106, "endOffset": 175}, {"referenceID": 20, "context": "Formalisms concerned with tractable computation may care chiefly about learnability or parsing efficiency (Shieber, 1992; Sleator and Temperly, 1993; Kuhlmann and Nivre, 2006).", "startOffset": 106, "endOffset": 175}, {"referenceID": 8, "context": "Further considerations may include psychological and evolutionary plausibility (Croft, 2001; Tomasello, 2003; Steels et al., 2011; Fossum and Levy, 2012), integration with other representations such as semantics (Steedman, 2000; Bergen and Chang, 2005), or suitability for particular applications (e.", "startOffset": 79, "endOffset": 153}, {"referenceID": 38, "context": "Further considerations may include psychological and evolutionary plausibility (Croft, 2001; Tomasello, 2003; Steels et al., 2011; Fossum and Levy, 2012), integration with other representations such as semantics (Steedman, 2000; Bergen and Chang, 2005), or suitability for particular applications (e.", "startOffset": 79, "endOffset": 153}, {"referenceID": 11, "context": "Further considerations may include psychological and evolutionary plausibility (Croft, 2001; Tomasello, 2003; Steels et al., 2011; Fossum and Levy, 2012), integration with other representations such as semantics (Steedman, 2000; Bergen and Chang, 2005), or suitability for particular applications (e.", "startOffset": 79, "endOffset": 153}, {"referenceID": 36, "context": ", 2011; Fossum and Levy, 2012), integration with other representations such as semantics (Steedman, 2000; Bergen and Chang, 2005), or suitability for particular applications (e.", "startOffset": 89, "endOffset": 129}, {"referenceID": 1, "context": ", 2011; Fossum and Levy, 2012), integration with other representations such as semantics (Steedman, 2000; Bergen and Chang, 2005), or suitability for particular applications (e.", "startOffset": 89, "endOffset": 129}, {"referenceID": 12, "context": "Currently, a lack of annotated data is a huge bottleneck for robust NLP, standing in the way of parsers for social media text (Foster et al., 2011) and many low-resourced languages (to", "startOffset": 126, "endOffset": 147}, {"referenceID": 21, "context": "Traditional syntactic annotation projects like the Penn Treebank (Marcus et al., 1993) or Prague Dependency Treebank (Haji\u010d, 1998) require highly trained annotators and huge amounts of effort.", "startOffset": 65, "endOffset": 86}, {"referenceID": 14, "context": ", 1993) or Prague Dependency Treebank (Haji\u010d, 1998) require highly trained annotators and huge amounts of effort.", "startOffset": 38, "endOffset": 51}, {"referenceID": 14, "context": "Exemplifying one end of the spectrum is the Prague Dependency Treebank, which articulates an elaborate dependency-based syntactic theory in a rich, multi-tiered formalism (Haji\u010d, 1998; B\u00f6hmov\u00e1 et al., 2003).", "startOffset": 171, "endOffset": 206}, {"referenceID": 3, "context": "Exemplifying one end of the spectrum is the Prague Dependency Treebank, which articulates an elaborate dependency-based syntactic theory in a rich, multi-tiered formalism (Haji\u010d, 1998; B\u00f6hmov\u00e1 et al., 2003).", "startOffset": 171, "endOffset": 206}, {"referenceID": 19, "context": "On the opposite end of the spectrum are the structures used in dependency parsing research which organize all the tokens of a sentence into a tree, sometimes with category labels on the edges (K\u00fcbler et al., 2009).", "startOffset": 192, "endOffset": 213}, {"referenceID": 24, "context": "There are several different conventions for forcing coordinate structures into a head-modifier straightjacket (Nivre, 2005; de Marneffe and Manning, 2008; Mare\u010dek et al., 2013).", "startOffset": 110, "endOffset": 176}, {"referenceID": 27, "context": "3Some of this is inspired by the conventions of ReedKellogg sentence diagramming, a graphical dependency annotation system for English pedagogy (Reed and Kellogg, 1877; Kolln and Funk, 1994; Florey, 2006).", "startOffset": 144, "endOffset": 204}, {"referenceID": 18, "context": "3Some of this is inspired by the conventions of ReedKellogg sentence diagramming, a graphical dependency annotation system for English pedagogy (Reed and Kellogg, 1877; Kolln and Funk, 1994; Florey, 2006).", "startOffset": 144, "endOffset": 204}, {"referenceID": 10, "context": "3Some of this is inspired by the conventions of ReedKellogg sentence diagramming, a graphical dependency annotation system for English pedagogy (Reed and Kellogg, 1877; Kolln and Funk, 1994; Florey, 2006).", "startOffset": 144, "endOffset": 204}, {"referenceID": 0, "context": "For simplicity, our formalism treats multiwords as unanalyzed (syntactically opaque) wholes, though some multiword expressions may have syntactic descriptions (Baldwin and Kim, 2010).", "startOffset": 159, "endOffset": 182}, {"referenceID": 0, "context": "For simplicity, our formalism treats multiwords as unanalyzed (syntactically opaque) wholes, though some multiword expressions may have syntactic descriptions (Baldwin and Kim, 2010). pendents can be distinguished with edge labels; we equivalently use a special notation, permitting the coordinate structure to be automatically transformed with any of the existing conventions.5 3. Following Tesni\u00e8re (1959), our formalism offers a simple facility to express anaphoraantecedent relations (a subset of semantic relationships) that are salient in particular syntactic phenomena such as relative clauses, appositives, and wh-expressions.", "startOffset": 160, "endOffset": 408}, {"referenceID": 16, "context": "\u2022 Semisupervised learning from partial annotations may be sufficient to learn complete parsers (Hwa, 1999; Clark and Curran, 2006).", "startOffset": 95, "endOffset": 130}, {"referenceID": 7, "context": "\u2022 Semisupervised learning from partial annotations may be sufficient to learn complete parsers (Hwa, 1999; Clark and Curran, 2006).", "startOffset": 95, "endOffset": 130}, {"referenceID": 30, "context": "5Tesni\u00e8re (1959) and Hudson (1984) similarly use special structures for coordination (Schneider, 1998; Sangati and Mazza, 2009).", "startOffset": 85, "endOffset": 127}, {"referenceID": 28, "context": "5Tesni\u00e8re (1959) and Hudson (1984) similarly use special structures for coordination (Schneider, 1998; Sangati and Mazza, 2009).", "startOffset": 85, "endOffset": 127}, {"referenceID": 34, "context": "5Tesni\u00e8re (1959) and Hudson (1984) similarly use special structures for coordination (Schneider, 1998; Sangati and Mazza, 2009).", "startOffset": 1, "endOffset": 17}, {"referenceID": 15, "context": "5Tesni\u00e8re (1959) and Hudson (1984) similarly use special structures for coordination (Schneider, 1998; Sangati and Mazza, 2009).", "startOffset": 21, "endOffset": 35}, {"referenceID": 13, "context": "7In principle, FUDG annotations could be created with an alternative mechanism such as a GUI, as in Haji\u010d et al. (2001). 8If a word is repeated within the sentence, it must be indexed in the input string in order to be referred to from a fragment.", "startOffset": 100, "endOffset": 120}, {"referenceID": 25, "context": "9This underspecification semantics is, to the best of our knowledge, novel, though it has been proposed that connected dependency subgraphs (known as catenae) are of theoretical importance in syntax (Osborne et al., 2012).", "startOffset": 199, "endOffset": 221}, {"referenceID": 39, "context": "From this graph we then extract all directed spanning trees using the algorithm of Uno (1996). If some lexical node has no supported parents, this reflects conflicting constraints in the annotation, and no spanning tree will be found.", "startOffset": 83, "endOffset": 94}, {"referenceID": 5, "context": "Alternatively, Kirchhoff\u2019s matrix tree theorem (Chaiken and Kleitman, 1978; Smith and Smith, 2007; Margoliash, 2010) can be used to count all spanning trees in cubic time without enumerating them, and thus obtain an upper bound on promiscuity.", "startOffset": 47, "endOffset": 116}, {"referenceID": 34, "context": "Alternatively, Kirchhoff\u2019s matrix tree theorem (Chaiken and Kleitman, 1978; Smith and Smith, 2007; Margoliash, 2010) can be used to count all spanning trees in cubic time without enumerating them, and thus obtain an upper bound on promiscuity.", "startOffset": 47, "endOffset": 116}, {"referenceID": 23, "context": "Alternatively, Kirchhoff\u2019s matrix tree theorem (Chaiken and Kleitman, 1978; Smith and Smith, 2007; Margoliash, 2010) can be used to count all spanning trees in cubic time without enumerating them, and thus obtain an upper bound on promiscuity.", "startOffset": 47, "endOffset": 116}, {"referenceID": 4, "context": "Tokens annotated by neither annotator are ignored; excluding punctuation is standard practice in dependency evaluation (Buchholz and Marsi, 2006).", "startOffset": 119, "endOffset": 145}, {"referenceID": 2, "context": "16 The second is from the Reviews portion of the English Web Treebank (Bies et al., 2012), which contains Penn Treebank\u2013style constituent parses.", "startOffset": 70, "endOffset": 89}, {"referenceID": 25, "context": "The first sample is drawn from Owoputi et al.\u2019s (2012) Twitter part-of-speech corpus.", "startOffset": 31, "endOffset": 55}, {"referenceID": 21, "context": "14As a point of comparison, during the Penn Treebank project, annotators corrected the syntactic bracketings produced by a high-quality hand-written parser (Fidditch) and achieved a rate of only 375 tokens/hour using a specialized GUI interface (Marcus et al., 1993).", "startOffset": 245, "endOffset": 266}, {"referenceID": 17, "context": "To convert the Treebank\u2019s constituent parses to dependencies, we used the PennConverter tool (Johansson and Nugues, 2007) with options chosen to emulate our annotation conventions,21 and then removed punctuation tokens.", "startOffset": 93, "endOffset": 121}, {"referenceID": 35, "context": ", multi-headedness, labels), crowdsourcing of FUDG annotations (Snow et al., 2008),22 or even a semantic counterpart to the syntactic representation.", "startOffset": 63, "endOffset": 82}], "year": 2013, "abstractText": "We introduce a framework for lightweight dependency syntax annotation. Our formalism builds upon the typical representation for unlabeled dependencies, permitting a simple notation and annotation workflow. Moreover, the formalism encourages annotators to underspecify parts of the syntax if doing so would streamline the annotation process. We demonstrate the efficacy of this annotation on three languages and develop algorithms to evaluate and compare underspecified annotations. This paper is an expanded version of (Schneider et al., 2013) containing additional technical details.", "creator": "LaTeX with hyperref package"}}}