{"id": "1306.3409", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2013", "title": "Constrained fractional set programs and their application in local clustering and community detection", "abstract": "Because these optimization problems are typically NP-hard, convex or spectral relaxations are used in practice. While these relaxation problems can be optimally solved globally, they are often too loose, resulting in results that are far from optimal. In this paper, we show that any limited minimization problem of a ratio of non-negative quantity functions allows close relaxation into an unlimited continuous optimization problem, resulting in a flexible framework for solving limited problems in network analysis. While a globally optimal solution to the resulting non-convex problem cannot be guaranteed, we significantly exceed loose convex or spectral relaxation in limited local cluster problems.", "histories": [["v1", "Fri, 14 Jun 2013 14:20:29 GMT  (353kb,D)", "http://arxiv.org/abs/1306.3409v1", "Long version of paper accepted at ICML 2013"]], "COMMENTS": "Long version of paper accepted at ICML 2013", "reviews": [], "SUBJECTS": "stat.ML cs.LG math.OC", "authors": ["thomas b\u00fchler", "syama sundar rangapuram", "simon setzer", "matthias hein 0001"], "accepted": true, "id": "1306.3409"}, "pdf": {"name": "1306.3409.pdf", "metadata": {"source": "META", "title": "Constrained fractional set programs and their  application in local clustering and community detection", "authors": ["Thomas B\u00fchler", "Syama Sundar Rangapuram"], "emails": ["tb@cs.uni-saarland.de", "srangapu@mpi-inf.mpg.de", "setzer@mia.uni-saarland.de", "hein@cs.uni-saarland.de"], "sections": [{"heading": "1. Introduction", "text": "Graph-based data appear in manifold ways in learning problems - either the data have already graph structure as in the case of social networks and biological networks or a similarity graph is constructed using a similarity measure based on features of the data. Several graph-based problems in clustering and community detection can be modelled as the optimization of\nProceedings of the 30 th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013. JMLR: W&CP volume 28. Copyright 2013 by the author(s).\na ratio of set functions (referred to here as fractional set program). Prominent examples are the normalized cut problem, from which the popular spectral clustering method is derived (Shi & Malik, 2000), and the maximum density subgraph problem, which has applications in community detection (Fortunato, 2010) and bioinformatics (Saha et al., 2010).\nIt turns out that in practice often additional background or domain knowledge about the learning problem is available. Such prior knowledge can then be incorporated as constraints into the optimization problem. In the case of clustering, Wagstaff et al. (2001) are the first to show how prior information given in the form of must-link and cannot-link constraints between vertices can be integrated into the k-means algorithm. Recently, Rangapuram & Hein (2012) proposed a generalization of the normalized cut problem that can handle must-link and cannot-link constraints. In the recent work of Mahoney et al. (2012), locality constraints in the form of a seed set and volume constraint have been integrated into the normalized cut formulation. Furthermore, Khuller & Saha (2009) and Saha et al. (2010) considered size and distance constraints for the maximum density subgraph problem.\nSince the above-mentioned combinatorial problems are NP-hard, the standard approach is to consider convex or spectral relaxations which can be solved globally optimally in polynomial time. Due to its practical efficiency the spectral relaxation is very popular in machine learning, e.g. spectral clustering (Hagen & Kahng, 1991; Shi & Malik, 2000). However, it is often quite loose and thus leads to a solution far away from the optimal one of the original problem. Moreover, spectral-type relaxations (Mahoney et al., 2012)\nar X\niv :1\n30 6.\n34 09\nv1 [\nst at\n.M L\n] 1\n4 Ju\nfail to guarantee that the constraints which encode the prior knowledge are satisfied.\nIn another line of work (Hein & Bu\u0308hler, 2010; Szlam & Bresson, 2010; Hein & Setzer, 2011; Bresson et al., 2012), it has been shown that tight continuous relaxations exist for all balanced graph cut problems and the normalized cut subject to must-link and cannotlink constraints (Rangapuram & Hein, 2012). A tight relaxation means that the continuous and the combinatorial optimization problem are equivalent in the sense that the optimal values agree and the optimal solution of the combinatorial problem can be obtained from the continuous solution. While the resulting algorithms provide no guarantee to yield the globally optimal solution, the standard loose relaxations are outperformed by a large margin in practice.\nIn this paper we show that any constrained minimization problem of a ratio of non-negative set functions allows a tight relaxation into a continuous optimization problem. This result together with our efficient minimization techniques enables the easy integration of prior information in form of constraints into many problems in graph-based clustering and community detection. While the general framework introduced in this paper is applicable to all problems discussed so far, we will focus on two particular applications: local clustering by constrained balanced graph cuts, and community detection via constrained densest subgraph problems. Compared to previous work, the algorithms developed in this paper are the first to guarantee that all given constraints are fulfilled by the obtained solution. Note that in principle our method could also be applied to a setting with soft or noisy constraints, however we will focus here on the case of hard constraints. In the experimental section we will show the superior performance compared to state of the art methods (Andersen & Lang, 2006; Mahoney et al., 2012)."}, {"heading": "2. Fractional set programs in clustering and community detection", "text": "In the following, G = (V,W ) denotes an undirected, weighted graph with a non-negative, symmetric weight matrix W \u2208 Rn\u00d7n, where n = |V |. Moreover, by assigning a non-negative weight gi to each vertex i, we can define the general volume of a subset A \u2282 V as volg(A) = \u2211 i\u2208A gi. As special cases, we obtain for gi = 1 the cardinality |A| and for gi equal to the degree di = \u2211 j\u2208V wij the classical volume vol(A) = vold(A). Furthermore, A = V \\A denotes the complement of A.\nThe balanced graph cut problem is a well-known problem in computer science with applications rang-\ning from parallel computing to image segmentation (Pothen et al., 1990; Shi & Malik, 2000). A very popular balanced graph cut criterion is the normalized cut1,\nNCut(C,C) = cut(C,C)\nvold(C) vold(C) , for C \u2282 V,\nwhere cut(C,C) := \u2211 i\u2208C,j\u2208C wij . The spectral relaxation of the normalized cut leads to the popular spectral clustering method (von Luxburg, 2007). A related criterion is the normalized Cheeger cut,\nNCC(C,C) = cut(C,C)\nmin{vold(C), vold(C)} , for C \u2282 V.\nMore general balanced graph cuts were studied by Hein & Setzer (2011). In practice, often additional information about the desired solution is available which can be incorporated into the problem via constraints. This motivates us to consider a more general class of problems where one optimizes a ratio of set functions2 subject to constraints. In the following, we discuss two examples of constrained problems in network analysis.\nConstrained balanced graph cuts for local clustering. Recently, there has been a strong interest in balanced graph cut methods for local clustering. Starting with the work of Spielman & Teng (2004), initially, the goal was to develop an algorithm that finds a subset near a given seed vertex with small normalized cut or normalized Cheeger cut value with running time linear in the size of the obtained cluster. The proposed algorithm and subsequent work (Andersen et al., 2006; Chung, 2009) use random walks to explore the graph locally, without considering the whole graph. Algorithms of this type have been applied for community detection in networks (Andersen & Lang, 2006).\nIn contrast, Mahoney et al. (2012) give up the runtime requirement and formulate the task as an explicit optimization problem, where one aims at finding the optimal normalized cut subject to a seed constraint and an upper bound on the volume of the set containing the seed set. Again, the idea is to find a local cluster around a given seed set. Motivated by the standard spectral relaxation of the normalized cut problem, they derive a spectral-type relaxation which is biased towards solutions fulfilling the seed constraint. Their method has been successfully applied in semisupervised image segmentation (Maji et al., 2011) and for community detection around a given query set (Mahoney et al., 2012). However, while they provide an ap-\n1This is up to a constant factor the same as the usual definition, NCut(C,C) = cut(C,C)\n( 1\nvold(C) + 1 vold(C)\n) .\n2A set function S\u0302 on a set V is a function S\u0302 : 2V \u2192 R.\nproximation guarantee for their relaxation, they cannot guarantee that the returned solution satisfies seed and volume constraints.\nIn this paper we consider an extended version of the problem of Mahoney et al. (2012). Let J denote the\nset of seed vertices, S\u0302 a symmetric balancing function (e.g. S\u0302(C) = vold(C) vold(C) for the normalized cut) and let volg(C) be the general volume of set C, where g \u2208 Rn+ are vertex weights. The general local clustering problem can then be formulated as\nmin C\u2282V\ncut(C,C)\nS\u0302(C) (1)\nsubject to : volg(C) \u2264 k, and J \u2282 C.\nThe choice of the balancing function S\u0302 allows the user to influence the trade-off between getting a partition with small cut and a balanced partition. One could also combine this with must- and cannot-link constraints (see Rangapuram & Hein, 2012) or add even more complex constraints such as an upper bound on the diameter of C. However, in order to compare to the method of Mahoney et al. (2012), we restrict ourselves in this paper to the normalized cut with volume constraints, that is S\u0302(C) = vold(C) vold(C) and g = d.\nConstrained local community detection. A second related problem is constrained local community detection. In community detection it makes more sense to find a highly connected set instead of emphasizing the separation to the remaining part of the graph by minimizing the cut. Thus, we are searching for a set C which has high association, defined as assoc(C) = \u2211 i,j\u2208C wij . Dividing the association of C by its size yields the density of C. The subgraph of maximum density can be computed in polynomial time (Goldberg, 1984). However, the obtained communities in the unconstrained problem are typically either too large or too small, which calls for size constraints. Note that the introduction of such constraints makes the problem NP-hard (Khuller & Saha, 2009).\nA general class of (local) community detection problems can thus be formulated as\nmax C\u2282V\nassoc(C)\nvolg(C) (2)\nsubject to : k1 \u2264 volh(C) \u2264 k2, and J \u2282 C,\nwhere g, h \u2208 Rn+ are vertex weights. This formulation generalizes the above-mentioned density-based approaches by replacing the denominator by a general volume function volg. One can use the vertex weights g to bias the obtained community towards one with\ndesired properties by assigning small weights to vertices which one would prefer to occur in the solution and larger weights to ones which are less preferred.\nThe problem (2) with only lower bound constraints has been considered in team selection (Gajewar & Das Sarma, 2012) and bioinformatics (Saha et al., 2010) where constant factor approximation algorithms were developed. However, in the case of equality and upper bound constraints the problem is very hard even when using only cardinality constraints (i.e., hi = 1), and it has been shown that there is no polynomial time approximation scheme in these cases (Khot, 2006; Khuller & Saha, 2009). Our method can handle such hard upper bound and equality constraints. In the experiments we show results for a community detection problem with a specified query set J and an upper bound on the size for a co-author network.\nNote that if volg(C) = vold(C), one can decompose the objective of (2) analogously to the argument for the normalized cut (Shi & Malik, 2000) as\nassoc(C) vold(C) = 1\u2212 cut(C,C) vold(C) .\nThis implies that for volg(C) = vold(C) in (2) and S\u0302(C) = vold(C) in (1), the problem (2) is equivalent to (1) if we choose the same constraints. If one has only the constraint vold(C) \u2264 12 vold(V ) both problems are equivalent to the normalized Cheeger cut.\nContributions of this paper. We show that all constrained non-negative fractional set programs have an equivalent tight continuous relaxation. This general result enables the integration of prior information in form of constraints into clustering and community detection problems. In particular, it allows us to derive efficient algorithms for problems (1) and (2). Our algorithms consistently outperform competing methods (Andersen & Lang, 2006; Mahoney et al., 2012). Moreover, we are not aware of any other methods for the above problems which can guarantee that the solution always satisfies volume and seed constraints.\nAlthough the tight relaxation results in Hein & Setzer (2011) and Rangapuram & Hein (2012) encompass a large class of problems, they are not applicable to the problems considered in this paper because of the following limitations: First, tight relaxations were shown by Hein & Setzer (2011) only for a ratio of symmetric non-negative set functions, where the numerator is restricted to be submodular. We extend the results to arbitrary ratios of non-negative set functions without any restrictions concerning symmetry or submodularity. Second, only equality constraints for non-negative\nset functions restricted to be either submodular or supermodular could be handled by Rangapuram & Hein (2012). We generalize this to inequality constraints3 without any restrictions on the constraint set functions in order to handle the constraints in (1) and (2)."}, {"heading": "3. Tight relaxations of fractional set programs with constraints", "text": "The problems discussed in the last section can be written in the following general form:\nmin C\u2282V\nR\u0302(C) S\u0302(C) =: Q\u0302(C) (3)\nsubject to : M\u0302i(C) \u2264 ki, i = 1, . . . ,K\nwhere R\u0302, S\u0302, M\u0302i : 2 V \u2192 R are set functions on a set V = {1, . . . , n}. We assume here that R\u0302, S\u0302 are nonnegative and that R\u0302(\u2205) = S\u0302(\u2205) = 0. No assumptions are made on the set functions M\u0302i, in particular they are not required to be non-negative. Thus also lower bound constraints can be written in the above form. Moreover, the formulation in (3) also encompasses the subset constraint J \u2282 C in (1) and (2) as it can be written as equality constraint |J | \u2212 |J \u2229 C| = 0. Alternatively, we will discuss a direct integration of the subset constraint into the objective in Section 5.\nThe connection between the set-valued and the continuous space is achieved via thresholding. Let f \u2208 Rn, and we assume wlog that f is ordered in ascending order f1 \u2264 f2 \u2264 \u00b7 \u00b7 \u00b7 \u2264 fn. One defines the sets\nCi := {j \u2208 V |fj \u2265 fi} , i = 1, . . . , n. (4)\nWe frequently make use of this notation in the following. Furthermore, we use 1C \u2208 Rn to denote the indicator vector of the set C, i.e. the vector which is 1 at entry j if j \u2208 C and 0 otherwise. A key tool for the derivation of the results of this paper is the Lovasz extension as a way to extend a set function (seen as function on the hypercube) to a function on Rn.\nDefinition 1 Let R\u0302 : 2V \u2192 R be a set function with R\u0302(\u2205) = 0, and f \u2208 Rn in ascending order f1 \u2264 f2 \u2264 \u00b7 \u00b7 \u00b7 \u2264 fn. The Lovasz extension R : Rn \u2192 R of R\u0302 is defined as R(f) = \u2211n\u22121 i=1 R\u0302(Ci+1) (fi+1 \u2212 fi)+R\u0302(V )f1.\nNote thatR(1C) = R\u0302(C) for all C \u2282 V , i.e. R is indeed an extension of R\u0302 from 2V to Rn. In the following, we always use the hat-symbol (\u0302) to denote set functions and omit it for the corresponding Lovasz extension.\n3Note that M\u0302(C) = k is equivalent to k \u2264 M\u0302(C) \u2264 k.\nA particular important class of set functions are submodular set functions since their Lovasz extension is convex (Bach, 2011).\nDefinition 2 A set function R\u0302 : 2V \u2192 R is submodular if for all A,B \u2282 V , R\u0302(A \u222a B) + R\u0302(A \u2229 B) \u2264 R\u0302(A) + R\u0302(B). It is supermodular, if the converse inequality holds true, and modular if we have equality.\nThe connection between submodular set functions and convex functions is as follows (see Bach, 2011).\nProposition 1 Let R : RV \u2192 R be the Lovasz extension of R\u0302 : 2V \u2192 R. Then, R\u0302 is submodular if and only if R is convex. Furthermore, if R\u0302 is submodular, then minA\u2282V R\u0302(A) = minf\u2208[0,1]n R(f).\nThus submodular minimization problems reduce to convex minimization problems. A similar equivalence of continuous and combinatorial optimization problems is the main topic of this paper. In the following we list some useful properties of the Lovasz extension (see Fujishige, 2005; Bach, 2011; Hein & Setzer, 2011).\nProposition 2 Let R : RV \u2192 R be the Lovasz extension of R\u0302 : 2V \u2192 R. Then,\n\u2022 R is positively one-homogeneous4,\n\u2022 R(f) \u2265 0, \u2200 f \u2208 RV and R(1) = 0 if and only if R\u0302(A) \u2265 0, \u2200A \u2282 V and R\u0302(V ) = 0,\n\u2022 Let S : RV \u2192 R be the Lovasz extension of S\u0302 : 2V \u2192 R. Then, \u03bb1R + \u03bb2 S is the Lovasz extension of \u03bb1 R\u0302+ \u03bb2 S\u0302, for all \u03bb1, \u03bb2 \u2208 R.\nUnconstrained fractional set programs. Using the property of the Lovasz extension that R(1C) = R\u0302(C) for all C \u2282 V , one can directly observe that the following continuous fractional program is a relaxation of the unconstrained version of problem (3)\ninf f\u2208Rn+\nR(f) S(f) .\nThe following theorem shows that the relaxation is in fact tight, in the sense that the optimal values agree and the solution of the set-valued problem can be computed from the solution of the continuous problem.\nNote that given a vector f \u2208 Rn for the continuous problem, one can construct a set C \u2032 by computing\nC \u2032 = arg min Ci,i=1,...,n\nR\u0302(Ci) S\u0302(Ci) ,\n4R : RV \u2192 R is positively one-homogeneous if R(\u03b1f) = \u03b1R(f), \u2200\u03b1 \u2208 R with \u03b1 \u2265 0.\nwhere the sets Ci are defined in (4). We refer to this process as optimal thresholding.\nTheorem 1 Let R\u0302, S\u0302 : 2V \u2192 R be non-negative set functions and R,S : Rn \u2192 R their Lovasz extensions, respectively. Then, it holds that\ninf C\u2282V\nR\u0302(C) S\u0302(C) = inf f\u2208Rn+ R(f) S(f) .\nMoreover, it holds for all f \u2208 Rn+, R(f) S(f) \u2265 mini=1,...,n R\u0302(Ci)\nS\u0302(Ci) . Thus a minimizer of the set ratio\ncan be found by optimal thresholding. Let furthermore R\u0302(V ) = S\u0302(V ) = 0, then all the above statements hold if one replaces Rn+ with Rn.\nIn practice it may sometimes by difficult to derive and/or work with explicit forms of the Lovasz exten-\nsions of R\u0302 and S\u0302. However, the following more general version of Theorem 1 shows that, given a decomposition of R\u0302 and S\u0302 into a difference of submodular set functions, one needs the Lovasz extension only for the first term of R\u0302 and the second term of S\u0302. The remaining terms can be replaced by any convex one-homogeneous functions that also extend the corresponding set functions. Note that by Proposition 3 such a decomposition always exists.\nTheorem 1 (b) Let R\u0302, S\u0302 : 2V \u2192 R be non-negative set functions and R\u0302 := R\u03021 \u2212 R\u03022 and S\u0302 := S\u03021 \u2212 S\u03022 be decompositions into differences of submodular set functions. Let the Lovasz extensions of R\u03021, S\u03022 be given by R1, S2 and let R \u2032 2, S \u2032 1 be positively one-homogeneous convex functions with S\u20321(1A) = S\u03021(A) and R \u2032 2(1A) = R\u03022(A) such that S \u2032 1\u2212S2 is non-negative. Define R := R1 \u2212R\u20322 and S := S\u20321 \u2212 S2. Then,\ninf C\u2282V\nR\u0302(C) S\u0302(C) = inf f\u2208RV+ R(f) S(f) .\nMoreover, it holds for all f \u2208 Rn+, R(f) S(f) \u2265 mini=1,...,n R\u0302(Ci)\nS\u0302(Ci) . Thus a minimizer of the set ratio\ncan be found by optimal thresholding. Let furthermore R\u0302(V ) = S\u0302(V ) = 0, then all the above statements hold if one replaces Rn+ with Rn.\nBefore we prove the above Theorem, we collect some useful results. Lemma 1 shows that the Lovasz extension of a submodular set function R\u0302 is an upper bound on any one-homogeneous convex function R\u2032 which extends the set function R\u0302 to the continuous space.\nLemma 1 Let R\u0302 : 2V \u2192 R be a submodular set function with R\u0302(\u2205) = 0. Let R\u2032 be a positively onehomogeneous convex function with R\u2032(1A) = R\u0302(A) for all A \u2282 V . Then, it holds \u2200f \u2208 RV+ that\nR\u2032(f) \u2264 n\u22121\u2211 i=1 R\u0302(Ci+1) (fi+1 \u2212 fi) + f1R\u0302(V ).\nLet furthermore R\u0302(V ) = 0, then the above inequality holds for all f \u2208 RV .\nProof: Let f be ordered in increasing order f1 \u2264 f2 \u2264 \u00b7 \u00b7 \u00b7 \u2264 fn. Note that every convex, positively onehomogeneous function R\u2032 : RV \u2192 R can be written as R(f) = supu\u2208U \u3008u, f\u3009, where U is a convex set (see Hiriart-Urruty & Lemare\u0301chal, 2001). Then, since for any u \u2208 U , \u3008u, f\u3009 \u2264 R\u2032(f), it holds that\nR\u0302(Ci) = R \u2032(1Ci) \u2265 \u3008u,1Ci\u3009 , i = 1, . . . , n,\nfor any u \u2208 U and hence for all f \u2208 RV+,\nn\u22121\u2211 i=1 R\u0302(Ci+1) (fi+1 \u2212 fi) + f1R\u0302(V )\n\u2265 n\u22121\u2211 i=1 \u2329 u,1Ci+1 \u232a (fi+1 \u2212 fi) + f1 \u3008u,1\u3009\n= n\u2211 i=1 fiui. (5)\nAs this holds for all u \u2208 U we obtain for all f \u2208 RV+, n\u22121\u2211 i=1 R\u0302(Ci+1) (fi+1 \u2212 fi) + R\u0302(V )f1 \u2265 sup u\u2208U \u3008f, u\u3009 = R\u2032(f) .\nFor the second statement we use the fact that with the condition R\u0302(V ) = 0 the lower bound in (5) holds for all f \u2208 RV .\nThe main part of the proof of Theorem 1 (b) is the following Lemma which implies that optimal thresholding of a vector f always leads to non-increasing values of R(f)/S(f).\nLemma 2 Let R\u0302, S\u0302 : 2V \u2192 R and R,S : Rn \u2192 R satisfy the assumptions of Theorem 1 (b). Then for all f \u2208 RV+,\nR(f) S(f) \u2265 min i=1,...,n R\u0302(Ci)\nS\u0302(Ci) .\nLet furthermore R\u0302(V ) = S\u0302(V ) = 0, then the result holds for all f \u2208 RV .\nProof: Let R1, S2 and R \u2032 2, S \u2032 1 satisfy the conditions from Theorem 1 (b). Let furthermore R2 and S1 be the Lovasz extensions of R\u03022 and S\u03021. With Lemma 1 and Def. 1, we get \u2200f \u2208 Rn+,\nR(f) = R1(f)\u2212R\u20322(f) \u2265 R1(f)\u2212R2(f)\n= n\u22121\u2211 i=1 R\u0302(Ci+1) (fi+1 \u2212 fi) + f1R\u0302(V )\n= n\u22121\u2211 i=1 R\u0302(Ci+1) S\u0302(Ci+1) S\u0302(Ci+1) (fi+1\u2212 fi) + R\u0302(V ) S\u0302(V ) S\u0302(V )f1\n\u2265 min j=1,...,n\nR\u0302(Cj)\nS\u0302(Cj) ( n\u22121\u2211 i=1 S\u0302(Ci+1) (fi+1\u2212fi)+f1S\u0302(V ) )\nwhere we used the non-negativity of R\u0302 and S\u0302 as well as the fact that f \u2208 Rn+. Again using Def. 1, the above is equal to\nmin j=1,...,n\nR\u0302(Cj) S\u0302(Ci) (S1(f)\u2212 S2(f))\n\u2265 min j=1,...,n\nR\u0302(Cj) S\u0302(Ci) (S\u20321(f)\u2212 S2(f)) .\nBy assumption, S\u20321\u2212S2 is non-negative and thus division gives the result. The second statement is shown analogously.\nNow we are ready to prove Theorem 1 (b).\nProof of Theorem 1 (b): Lemma 2 implies that\ninf f\u2208RV+\nR(f) S(f) \u2265 inf f\u2208RV+\nmin Ci def. by f i=1,...,n\nR\u0302(Ci) S\u0302(Ci) \u2265 inf A\u2282V R\u0302(A) S\u0302(A) .\nOn the other hand we have\ninf A\u2282V\nR\u0302(A) S\u0302(A) = inf A\u2282V R(1A) S(1A) \u2265 inf f\u2208RV+ R(f) S(f) ,\nwhich implies equality. The statement regarding optimal thresholding has been shown in Lemma 2. The proof for the case where R\u0302(V ) = S\u0302(V ) = 0 works analogously.\nNote that no assumptions except non-negativity are made on R\u0302 and S\u0302 - every non-negative fractional set program has a tight relaxation into a continuous fractional program. The efficient minimization of the continuous objective will be the topic of Section 4.\nConstrained fractional set programs. To solve the constrained fractional set program (3) we make use of the concept of exact penalization (Di Pillo, 1994), where the main idea is to transform a given\nconstrained optimization problem into an equivalent unconstrained one by adding a penalty term. We use the same idea for our constrained fractional set programs and define the penalty set function for a constraint M\u0302i(C) \u2264 ki as\nT\u0302i(C) =\n{ max { 0, M\u0302i(C)\u2212 ki } , C 6= \u2205,\n0, C = \u2205. (6)\nThe function T\u0302i(C) is zero if C is feasible for the ith constraint and otherwise increasing with increasing infeasibility. The special treatment of the empty set in the definition of T\u0302i is a technicality required for the Lovasz extension. Defining T\u0302 (C) := \u2211K i=1 T\u0302i(C), we can now formulate a modified problem\nmin C\u2282V\nR\u0302(C) + \u03b3 \u2211K i T\u0302i(C)\nS\u0302(C) =: Q\u0302\u03b3(C). (7)\nWe will show that using a feasible set of (3) one can compute a \u03b3 such that (7) is equivalent to the original constrained problem. Once we have established the equivalence, we can then apply Theorem 1, noting that T\u0302 is a non-negative set function. This leads to the main result of this paper showing a tight relaxation of all problems of form (3) where R\u0302, S\u0302 are non-negative set functions. In the following, the constant \u03b8 quantifies a \u201cminimum value\u201d of T\u0302i on the infeasible sets:\n\u03b8 = min i=1,...,K\n[ min\nM\u0302i(C)>ki\nM\u0302i(C)\u2212 ki ] .\nFor example, if M\u0302(C) = |C|, then \u03b8 is equal to 1. If M\u0302(C) = volg(C) and all vertex weights gi are rational numbers which are multiples of a fraction 1\u03c1 , \u03c1 \u2208 N, then \u03b8 \u2265 1\u03c1 . Note that in practice, the constant \u03b8 and the parameter \u03b3 introduced in the following are never explicitly computed (see experimental section).\nTheorem 2 Let R\u0302, S\u0302 : 2V \u2192 R be non-negative set functions and R, S their Lovasz extensions. Let C0 \u2282 V be feasible and S\u0302(C0) > 0. Denote by T the Lovasz extension of T\u0302 . Then, for \u03b3 > R\u0302(C0) \u03b8S\u0302(C0) maxC\u2282V S\u0302(C),\nmin M\u0302i(C)\u2264ki, i=1,...,K\nR\u0302(C) S\u0302(C) = min f\u2208Rn+ R(f) + \u03b3 T (f) S(f) := Q\u03b3(f)\nMoreover, for any f \u2208 Rn+ with Q\u03b3(f) < Q\u0302\u03b3(C0) for the given \u03b3, we have Q\u03b3(f) \u2265 mini=1,...,n Q\u0302\u03b3(Ci), and the minimizing set on the right hand side is feasible.\nProof: We will first show the equivalence between the constrained fractional set program (3) and the unconstrained problem (7) for the given choice of \u03b3. Then\nthe equivalence to the continuous problem will follow by Theorem 1.\nDefine T\u0302 (C) := \u2211K i=1 T\u0302i(C). Note that for any feasible subset C, that is M\u0302i(C) \u2264 ki, i = 1, . . . ,K, the objective Q\u03b3 of problem (7) is equal to the objective Q of problem (3). Thus, if we show that all minimizers of the second problem satisfy the constraints then the equivalence follows. Suppose that C\u2217 6= \u2205 is a minimizer of the second problem and that C\u2217 is infeasible. Then by definition we have T\u0302 (C\u2217) \u2265 \u03b8. This yields\nQ\u0302\u03b3(C \u2217) =\nR\u0302(C\u2217) + \u03b3T\u0302 (C\u2217)\nS\u0302(C\u2217) (8)\n\u2265 \u03b3T\u0302 (C \u2217)\nS\u0302(C\u2217) \u2265 \u03b3T\u0302 (C\n\u2217)\nmaxC\u2282V S\u0302(C) \u2265 \u03b3\u03b8 maxC\u2282V S\u0302(C) ,\nwhere we used the non-negativity of R\u0302 and S\u0302. Hence\nQ\u0302\u03b3(C \u2217) \u2265 \u03b3\u03b8 maxC\u2282V S\u0302(C) > R\u0302(C0) S\u0302(C0) = Q\u0302\u03b3(C0),\nwhich contradicts the fact that C\u2217 is optimal.\nNoting that T\u0302 is a non-negative function with T\u0302 (\u2205) = 0 and \u03b3 > 0, we have a ratio of non-negative set functions which attain the value zero on the empty set. Thus application of Theorem 1 yields the equivalence to the continuous problem.\nThe second statement can be seen as follows. Suppose Q\u03b3(f) < Q\u0302\u03b3(C0). By Lemma 2 we obtain\nQ\u03b3(f) \u2265 min i=1,...,n Q\u0302\u03b3(Ci).\nNow suppose that the minimizer C\u2217 of the right hand side is not feasible, then again by the derivation in (8) and the choice of \u03b3,\nQ\u0302\u03b3(C \u2217) \u2265 \u03b3\u03b8\nmaxC\u2282V S\u0302(C) > Q\u0302\u03b3(C0),\nwhich leads to a contradiction. Thus C\u2217 is feasible.\nNote that Theorem 2 implies that the set found by optimal thresholding of the solution of the continuous program is guaranteed to satisfy all constraints. We are not aware of any other method which can give the same guarantee for the problems (1) and (2)."}, {"heading": "4. Minimization of the tight continuous relaxation", "text": "The continuous optimization problems in Theorems 1 and 2 have the form\nmin f\u2208Rn+\nR(f) S(f) := Q(f), (9)\nwhere R and S are non-negative. The fact that they are the Lovasz extensions of set functions R\u0302, S\u0302 also implies that they are one-homogeneous, see Bach (2011). We now apply a slightly modified version of a result from Hein & Setzer (2011).\nProposition 3 Every set function S\u0302 with S\u0302(\u2205) = 0 can be written as S\u0302 = S\u03021 \u2212 S\u03022, where S1 and S2 are submodular and S\u03021(\u2205) = S\u03022(\u2205) = 0. The Lovasz extension S can be written as difference of convex functions.\nThe above result implies that (9) can be written as ratio of differences of convex functions (d.c.), i.e. R = R1 \u2212 R2 with R1, R2 convex, and similarly for S. As the proof of Proposition 3 is constructive, the explicit form of this decomposition can be calculated. We can now use a modification of the RatioDCA which has recently been proposed as an algorithm for minimizing a non-negative ratio of one-homogeneous d.c. functions (Hein & Setzer, 2011). This modification is necessary as the problems in Theorem 1 and 2 require optimization over the positive orthant. We report the modified version in order to make the paper self-contained.\nRatioDCA Minimization of a non-negative ratio of one-homogeneous d.c functions over Rn+ 1: Initialization: f0 \u2208 Rn+, \u03bb0 = Q(f0) 2: repeat 3: f l+1 = arg min\nu\u2208Rn+, \u2016u\u20162\u22641\n{ R1(u)\u2212 \u2329 u, r2(f l) \u232a\n+\u03bbl ( S2(u)\u2212 \u2329 u, s1(f l) \u232a )}\nwhere r2(f l) \u2208 \u2202R2(f l), s1(f l) \u2208 \u2202S1(f l)\n4: \u03bbl+1 = Q(f l+1) 5: until |\u03bbl+1\u2212\u03bbl|\n\u03bbl <\nWe will refer to the convex optimization problem solved at each step (line 3) as the inner problem.\nProposition 4 The sequence f l produced by RatioDCA satisfies Q(f l+1) < Q(f l) for all l \u2265 0 or the sequence terminates.\nProof: Let \u03a6f l(u) := R1(u)\u2212 \u2329 u, r2(f l) \u232a +\u03bbl ( S2(u)\u2212\u2329\nu, s1(f l) \u232a )\ndenote the objective of the inner problem. The optimal value of the inner problem is non-positive since\n\u03a6f l(f l) = R1(f l)\u2212 \u2329 f l, r2(f l) \u232a\n+ \u03bbl ( S2(f l)\u2212 \u2329 f l, s1(f l) \u232a )\n= R1(f l)\u2212R2(f l) + \u03bbl ( S2(f l)\u2212 S1(f l) ) = 0,\nwhere we used the fact that \u2329 f l, r2(f l) \u232a = R2(f l) and\u2329\nf l, s1(f l) \u232a = S1(f l). Since \u03a6f l is one-homogeneous,\nthe minimum of \u03a6f l is always attained at the boundary of the constraint set. If the optimal value is zero, then f l is a possible minimizer and the sequence terminates. Otherwise the optimal value is negative and at the optimal point we get\n0 > \u03a6f l(f l+1)\n= R1(f l+1)\u2212 \u2329 f l+1, r2(f l) \u232a\n+ \u03bbl ( S2(f l+1)\u2212 \u2329 f l+1, s1(f l) \u232a )\n\u2265 R1(f l+1)\u2212R2(f l+1) + \u03bbl ( S2(f l+1)\u2212 S1(f l+1) ) ,\nwhere we used that for a positively one-homogeneous convex function one has for all f, g \u2208 Rn+,\nS(f) \u2265 S(g) + \u3008f \u2212 g, s(g)\u3009 = \u3008f, s(g)\u3009 .\nThus we obtain\nQ(f l+1) = R1(f l+1)\u2212R2(f l+1) S1(f l+1)\u2212 S2(f l+1) < \u03bbl = Q(f l).\nThe norm constraint of the inner problem is necessary as otherwise the problem would be unbounded from below. However, the choice of the norm plays no role in the proof and any norm can be chosen. Moreover, in the special case where the one-homogeneous function R is convex and S is concave, the RatioDCA reduces to Dinkelbach\u2019s method from fractional programming (Dinkelbach, 1967) and therefore computes the global optimum. In the general case, convergence to the global optimum cannot be guaranteed. However, we can provide a quality guarantee: RatioDCA either improves a given feasible set or stops after one iteration.\nTheorem 3 Let A be a feasible set and \u03b3 > R\u0302(A) maxC\u2282V S\u0302(C)/(\u03b8 S\u0302(A)). Let f\n\u2217 denote the result of RatioDCA after initializing with the vector 1A, and let Cf\u2217 denote the set found by optimal thresholding of f\u2217. Either RatioDCA terminates after one iteration, or Cf\u2217 is feasible and R\u0302(Cf\u2217 )\nS\u0302(Cf\u2217 ) < R\u0302(A) S\u0302(A) .\nProof: Proposition 4 implies that the RatioDCA either directly terminates or produces a strictly monotonically decreasing sequence. In the latter case, using the strict monotonicity and the fact that thresholding does not increase the objective (Lemma 2), we obtain\nQ\u0302\u03b3(A) = Q\u03b3(1A) Prop. 4 > Q\u03b3(f \u2217)\nLemma 2 \u2265 Q\u03b3(1Cf\u2217 ) = Q\u0302\u03b3(Cf\u2217) .\nAssume now that Cf\u2217 is infeasible. Then, one can derive analogously to the proof of Theorem 2 that\nQ\u0302\u03b3(Cf\u2217) \u2265 \u03b3\u03b8maxC\u2282V S\u0302(C) > Q\u0302(A) = Q\u0302\u03b3(A), which is a contradiction to Q\u0302\u03b3(A) > Q\u0302\u03b3(Cf\u2217). Hence, Cf\u2217 has to be feasible and it holds that Q\u0302(A) = Q\u0302\u03b3(A) > Q\u0302\u03b3(Cf\u2217) = Q\u0302(Cf\u2217).\nThe above theorem implies that all constraints of the original constrained fractional set program are fulfilled by the set Cf\u2217 returned by RatioDCA."}, {"heading": "5. Tight relaxations of constrained maximum density and constrained balanced graph cut problems", "text": "The framework introduced in this paper allows us to derive tight relaxations of all problems discussed in Section 2. In the following, we will derive a tight relaxation of the local community detection problem\nmax C\u2282V\nassoc(C)\nvolg(C) (10)\nsubject to : volh(C) \u2264 k, and J \u2282 C.\nFor the constrained balanced graph cut problem, the tight relaxation can be found in a very similar way and is thus omitted here.\nFirst, we integrate the volume constraint via a penalty term, see (7), which yields the equivalent problem\nmin C\u2282V\ns.t.J\u2282C\nvolg(C) + \u03b3T\u0302k(C)\nassoc(C) , (11)\nwhere T\u0302k is given as T\u0302k(C) = max {0, volh(C)\u2212 k} and \u03b3 >\nvolg(C0) vol(V ) \u03b8 assoc(C0) for a feasible set C0 \u2282 V . Note that the penalty term is equal to T\u0302k(C) = volh(C) \u2212 min {k, volh(C)} , which is a difference of submodular functions.\nWe could reformulate the seed constraint J \u2282 C as inequality constraint |J\u2229C|\u2212|J | \u2265 0 and add a similar penalty function to the numerator of (11). However, using the structure of the problem, a more direct way to incorporate the seed constraint is possible. It holds that (11) has the equivalent form\nmin A\u2282V \\J\nvolg(A) + volg(J) + \u03b3T\u0302k\u2032(A)\nassoc(A) + assoc(J) + 2cut(J,A) , (12)\nwhere k\u2032 = k \u2212 volh(J). Solutions C\u2217 of (11) and A\u2217 of (12) are related via C\u2217 = A\u2217\u222aJ . In order to derive the tight relaxation via Theorem 1, we need the Lovasz extension of the set functions in (12). For technical reasons, we replace the constant set functions volg(J) and assoc(J) by volg(J)P\u0302 (A) and assoc(J)P\u0302 (A), respectively, where P\u0302 is defined as P\u0302 (A) = 1 for A 6= \u2205\nand P\u0302 (\u2205) = 0. This leads to the problem\nmin A\u2282V \\J\nvolg(A) + volg(J)P\u0302 (A) + \u03b3T\u0302k\u2032(A)\nassoc(A) + assoc(J)P\u0302 (A) + 2cut(J,A) . (13)\nThe only difference to (12) lies in the treatment of the empty set. Note that with 00 := \u221e the empty set can never be optimal for problem (13). Given an optimal solution A\u2217 of (13), one then either considers either A\u2217 \u222a J or J , depending on whichever has lower objective, which then implies equivalence to (12).\nThe resulting tight relaxation will be a minimization problem over Rm with m = |V \\J | and we assume wlog that the first m vertices of V are the ones in V \\J . Moreover, we use the notation fmax = maxi=1,...,m fi\nfor f \u2208 Rm, and d(A)i = \u2211 j\u2208A wij . The following Lovasz extensions are useful:\nSet function Lovasz extension\ncut(A,A) 1 2 \u2211m i,j wij |fi \u2212 fj |\nvolg(A) \u3008f, (gi)mi=1\u3009 assoc(A) \u2329 f, (d\n(V \\J) i ) m i=1\n\u232a \u2212 1\n2 \u2211m i,j wij |fi \u2212 fj |\nP\u0302 (A) fmax\nT\u0302k\u2032(A) \u3008f, (hi)mi=1\u3009 \u2212 T (2) k\u2032 (f)\nFor the sake of brevity, we do not specify the convex function T (2) k\u2032 . Recall from Section 4 that we need only an element of the subdifferential for T (2) k\u2032 which by Prop. 2.2 in Bach (2011) is given by\n( t (2) k\u2032 (f) ) ji =  0 volh(Ai+1) > k \u2032 k\u2032 \u2212 volh(Ai+1) volh(Ai) \u2265 k\u2032, volh(Ai+1) \u2264 k\u2032\nhji volh(Ai) < k \u2032\n,\nwhere ji denotes the index of the i-th smallest component of the vector f . The above Lovasz extensions lead to the following tight relaxation of (13):\nmin f\u2208Rm+ R1(f)\u2212R2(f) S1(f)\u2212 S2(f) , (14)\nwhere R1(f) = \u3008(gi)mi=1 + \u03b3(hi)mi=1, f\u3009 + volg(J)fmax, S1(f) = \u3008(di)mi=1 + (d (J) i ) m i=1, f\u3009 + assoc(J) fmax, R2(f) = \u03b3T (2) k\u2032 (f) and S2(f) = 1 2 \u2211m i,j wij |fi \u2212 fj |.\nLower bound constraints. Constraints of the form volh(C) \u2265 k are rewritten as \u2212 volh(C) \u2264 \u2212k, which leads to the penalty term, see (6),\nT\u0302k(C) =\n{ max {0, k \u2212 volh(C)} , C 6= \u2205,\n0, C = \u2205.\nThe decomposition T\u0302k(C) = k P\u0302 (C)\u2212min {k, volh(C)} then again yields a difference of submodular functions (noting k \u2265 0). The derivation then proceeds analogously to the case of upper bound constraints.\nSolution via RatioDCA. Observe that both numerator and denominator of the tight relaxation (14) are one-homogeneous d.c. functions and thus we can apply the RatioDCA of Section 4. The crucial step in the algorithm is solving the inner problem (line 3). For both (14) and the tight relaxation of the constrained balanced graph cut problem, it has the form\nmin f\u2208Rm+ \u2016f\u20162\u22641\n{c1fmax + \u3008f, c2\u3009+ \u03bbl 1\n2 m\u2211 i,j wij |fi \u2212 fj |}, (15)\nfor c1 \u2208 R and c2 \u2208 Rm. We solve this problem via the following equivalent dual problem.\nLemma 3 The inner problem (15) is equivalent to\n\u2212 min \u2016\u03b1\u2016\u221e\u22641 \u03b1ij=\u2212\u03b1ji min v\u2208Sm\n1\n2 \u2225\u2225\u2225\u2225PRm+ (\u2212c1v \u2212 c2 \u2212 \u03bbl2 A\u03b1 )\u2225\u2225\u2225\u22252\n2\nwhere (A\u03b1)i := \u2211 j wij(\u03b1ij \u2212 \u03b1ji), PRm+ denotes the projection on the positive orthant and Sm is the simplex Sm = {v \u2208 Rm | vi \u2265 0, \u2211m i=1 vi = 1}.\nProof: First we replace the inner problem (15) by the modified problem\nmin f\u2208Rm+\n\u03bbl\n2 m\u2211 i,j=1 wij |fi \u2212 fj |+ c1 max i fi + \u3008f, c2\u3009+ 1 2 \u2016f\u201622 .\n(16)\nGiven a solution f\u2217 of (16), a solution of (15) can be obtained via f\u2217/ \u2016f\u2217\u20162, which can be shown using the 1-homogeneity of the objective (15). We then derive the dual problem as follows:\nmin f\u2208Rm+\n\u03bbl\n2 m\u2211 i,j=1 wij |fi \u2212 fj |+ c1 max fi + \u3008f, c2\u3009+ 1 2 \u2016f\u201622\n= min f\u2208Rm+ { max \u2016\u03b1\u2016\u221e\u22641 \u03b1ij=\u2212\u03b1ji \u03bbl 2 m\u2211 i,j=1 wij (fi \u2212 fj)\u03b1ij\n+ max v\u2208Sm\nc1 \u3008f, v\u3009+ \u3008f, c2\u3009+ 1\n2 \u2016f\u201622 } = max \u2016\u03b1\u2016\u221e\u22641 \u03b1ij=\u2212\u03b1ji v\u2208Sm min f\u2208Rm+ 1 2 \u2016f\u201622 + \u2329 f, c1v + c2 + \u03bbl 2 A\u03b1 \u232a ,\nwhere (A\u03b1)i := \u2211 j wij(\u03b1ij \u2212 \u03b1ji). The optimization over f has the solution\nf = PRm+\n( \u2212c1v \u2212 c2 \u2212 \u03bbl\n2 A\u03b1\n) .\nPlugging f into the objective and using that\u2329 PRm+ (x), x \u232a = \u2225\u2225\u2225PRm+ (x)\u2225\u2225\u222522, we obtain the result.\nThis dual problem can be solved efficiently using FISTA (Beck & Teboulle, 2009), a proximal gradient method with guaranteed convergence rate O( 1k2 ) where k is the number of steps. The resulting explicit steps in FISTA with B\u221e(1) = {x \u2208 R | |x| \u2264 1} to solve the inner problem are given below.\nFISTA for the inner problem\nInput: Lipschitz constant L of \u2207\u03a8, Initialization: t1 = 1, \u03b1\n1 \u2208 R|E|, repeat\nv = arg min u\u2208Sm \u2225\u2225\u2225PRm+ (\u2212c1u\u2212 c2 \u2212 \u03bbl2 A\u03b1)\u2225\u2225\u222522 z = PRm+ ( \u2212c1v \u2212 c2 \u2212 \u03bb l 2 A\u03b1 )\n\u03b2k+1rs = PB\u221e(1) ( \u03b1krs + 1 L\u03bb lwrs ( zr \u2212 zs )) tk+1 = 1+ \u221a 1+4t2k 2 , \u03b1k+1rs = \u03b2 k+1 rs + tk\u22121 tk+1 ( \u03b2k+1rs \u2212 \u03b2krs ) .\nuntil duality gap <\nThe most expensive part of each iteration of the algorithm is a sparse matrix multiplication, which scales linearly in the number of edges. To solve the first subproblem in FISTA, we make use of the following fact:\nLemma 4 Let x \u2208 Rn and y := PRn+(x), then\narg min v\u2208Sn \u2016y \u2212 v\u201622 \u2208 arg min v\u2208Sn \u2225\u2225\u2225PRn+ (x\u2212 v)\u2225\u2225\u222522. Proof: The proof is a straightforward but technical transformation of the KKT optimality conditions of the left problem into the ones of the right problem.\nLemma 4 implies that the minimization problem can be solved via a standard projection onto the simplex, which can be computed in linear time (Kiwiel, 2007).\nUnconstrained version. In the unconstrained case of the maximum density problem, the tight relaxation (14) reduces to a convex-concave ratio. As remarked in Section 4 it can then be solved globally optimally with our method, which in this case is equivalent to Dinkelbach\u2019s method (Dinkelbach, 1967). In every iteration, we have to solve\nmin f\u2208Rn+ \u2016f\u2016\u221e\u22641\n{\u3008g, f\u3009 \u2212 \u03bb \u3008d, f\u3009+ \u03bb 2 n\u2211 i,j=1 wij |fi \u2212 fj |}. (17)\nNote that here we used the fact that one can replace the L2 norm constraint in the inner problem by a L\u221e norm constraint, see the remark after Prop. 4. The following lemma shows that (17) can be rewritten as a\ns-t-min-cut-problem, which shows that the procedure is similar to the method of Goldberg (1984).\nLemma 5 Problem (17) is equivalent to the problem\nmin fV \u2208H, fs=1, ft=0\n1\n2 \u2211 i,j\u2208V \u2032 w\u2032ij |fi \u2212 fj |,\nwith V \u2032 = V \u222a {s, t}, H := { u \u2208 Rn+, \u2016u\u2016\u221e \u2264 1 } and some non-negative weights w\u2032ij, i, j \u2208 V \u2032.\nProof: Note that adding constant terms to the objective does not change the minimizer. We rewrite\nn\u2211 i=1 gi(fi\u22120)+\u03bb n\u2211 i=1 di\u2212\u03bb n\u2211 i=1 difi+ \u03bb 2 n\u2211 i,j=1 wij |fi \u2212 fj |\n= n\u2211 i=1 gi|fi \u2212 0|+ \u03bb n\u2211 i=1 di|1\u2212 fi|+ \u03bb 2 n\u2211 i,j=1 wij |fi \u2212 fj |, where we have used that f \u2208 H, where H :={ u \u2208 Rn+, \u2016u\u2016\u221e \u2264 1 } . We define the graph as V \u2032 = V \u222a {s, t} and the weight matrix W \u2032 with\nw\u2032ij =  \u03bbwij if i, j \u2208 V ,2\u03bbdj if i = s and j \u2208 V , 2gi if i \u2208 V and j = t,\nand can rewrite the problem as\nmin fV \u2208H, fs=1, ft=0\n1\n2 \u2211 i,j\u2208V \u2032 w\u2032ij |fi \u2212 fj |,\nwhich is a s-t-mincut.\nThe above problem can be efficiently solved, e.g., using the pseudo-flow algorithm of Hochbaum (1998)."}, {"heading": "6. Experiments", "text": "We empirically evaluate the performance of our approach on local clustering and community detection problems. Our goal is to address the following questions: (i) In terms of the original objective of the fractional set program, how does the locally optimal solution of our tight relaxation compare to the globally optimal solution of a loose relaxation? (ii) How good is our quality guarantee (Theorem 3), i.e. how often does our method improve a given sub-optimal solution obtained by another method?\nIn all experiments we start the RatioDCA with 10 different random initializations and report the result with smallest objective value. Regarding the parameter \u03b3 from Theorem 2, it turns out that best results are obtained by first solving the unconstrained case (\u03b3 = 0)\nand then increasing \u03b3 sequentially, until all constraints are fulfilled. In principle, this strategy could also be used to deal with soft or noisy constraints, however we focus here on the case of hard constraints.\nLocal clustering. We first consider the local normalized cut problem,\nmin C\u2282V\ns\u2208C, vold(C)\u2264k\ncut(C,C) vol (V )\nvold(C) vold(C) , (18)\nwhere s \u2208 V is a given seed vertex. We evaluate our approach (denoted as CFSP) against the Local Spectral (LS) method by Mahoney et al. (2012) and the Lazy Random Walk (LRW) by Andersen & Lang (2006) on large social networks of the Stanford Large Network Dataset Collection (Leskovec).\nIn Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally.\nThe resulting continuous solution is then transformed into a set via optimal thresholding. However, contrary to our method this is not guaranteed to yield a set that satisfies both the seed and volume constraints. Hence Mahoney et al. (2012) suggest, at the cost of losing their approximation guarantees, to perform constrained optimal thresholding which considers only thresholds that yield feasible sets. In a recent generalization of their work, Hansen & Mahoney (2012) compute a sequence of locally-biased eigenvectors, the first of which corresponds to the solution of the spectral-type relaxation of Mahoney et al. (2012). We use the code of Hansen & Mahoney (2012) to compute the solution of LS in our experiments. The local clustering technique of Andersen & Lang (2006) explores the graph locally by performing a lazy random walk with the transition matrix M = 12 ( I +WD\u22121 ) , where D is the degree matrix of the graph and the initial distribution is concentrated on the seed set. Under\nsome conditions on the seed set, it is shown that after a specified number of steps optimal thresholding of the random walk vector yields a set with \u201cgood\u201d normalized Cheeger cut. However, they cannot guarantee that the resulting set contains the seed. For a fair comparison, we compute the full sequence of random walk vectors until the stationary distribution is reached, and in each step perform constrained optimal thresholding according to the normalized cut objective.\nFor each dataset we generate 10 random seeds. In order to ensure that meaningful intervals for the volume constraint are explored, we first solve the local clustering problem only with the seed constraint. Treating this as the \u201cunconstrained\u201d solution C0, we then repeat the experiment with upper bounds of the form vol(C) \u2264 \u03b1 vol(C0), where \u03b1 \u2208 {0.2, 0.4, 0.6, 0.8}.\nTable 1 shows mean and standard deviation of the normalized cut values averaged over the 10 different random trials (seeds) and average runtime over the different runs and volume constraints. To demonstrate the quality guarantee (Theorem 3) we also initialize CFSP with the solution of LS and LRW. Our method CFSP consistently outperforms the competing methods by large margins and always finds solutions that satisfy all constraints. In some cases CFSP initialized with LS or LRW outperforms CFSP with 10 random initializations. While LRW is very fast, the obtained normalized cuts are far from being competitive. Note that CFSP still performs better if one uses for the optimal thresholding the normalized Cheeger cut for which LRW has been designed. This is shown in Table 2 where we compare the normalized Cheeger cut of our solutions (note that we optimized the normalized cut) to the solution obtained by the Lazy Random Walk method where we threshold in each step according to the normalized Cheeger cut objective.\nCommunity detection. We evaluate our approach for local community detection according to (10). The task is to extract communities around given seed sets in a co-author network constructed from the DBLP\npublication database. Each node in the network represents a researcher and an edge between two nodes indicates a common publication. The weights of the graph are defined as wij = \u2211 l\u2208Pi\u2229Pj 1 |Al| , where Pi, Pj denotes the set of publications of authors i and j and Al denote the sets of authors for publication l, i.e. the weights represent the total contribution to shared papers. This normalization avoids the problem of giving high weight to a researcher who has publications that have a large number of authors, which usually does not reflect close collaboration with all co-authors.\nTo avoid finding a trivial densely connected group of researchers with few connections to the rest of the authors, we further restrict the graph by considering only authors with at least two publications and maximum distance two from the seed set. As volume function in (10), we use the volume of the original graph in order to further enforce densely connected components.\nWe perform local community detection with the size constraint |C| \u2264 20 and three different seed sets J1 = {P. Bartlett , P. Long, G. Lugosi}, J2 = {E. Candes , J. Tropp} and J3 = {O. Bousquet}. J1 consists of well-known researchers in learning theory, and all members of the detected community work in this area. To validate this, we counted the number of publications in the two main theory conferences COLT and ALT. On average each author has 18.2 publications in these two conferences (see Table 3 for more details). The seeds J2 yield a community of key scientists in the field of sparsity such as T. Tao, R. Baraniuk, J. Romberg, M. Wakin, R. Vershynin etc. The third community contains researchers who either are/were members of the group of B. Scho\u0308lkopf or have closely collaborated with his group."}, {"heading": "Acknowledgements", "text": "This work has been supported by DFG Excellence Cluster MMCI and ERC Starting Grant NOLEPRO."}], "references": [{"title": "Communities from seed sets", "author": ["R. Andersen", "K. Lang"], "venue": "In WWW, pp", "citeRegEx": "Andersen and Lang,? \\Q2006\\E", "shortCiteRegEx": "Andersen and Lang", "year": 2006}, {"title": "Local graph partitioning using pagerank vectors", "author": ["R. Andersen", "F. Chung", "K. Lang"], "venue": "In FOCS, pp", "citeRegEx": "Andersen et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Andersen et al\\.", "year": 2006}, {"title": "Learning with submodular functions: A convex optimization perspective", "author": ["F. Bach"], "venue": "CoRR, abs/1111.6453,", "citeRegEx": "Bach,? \\Q2011\\E", "shortCiteRegEx": "Bach", "year": 2011}, {"title": "Fast gradient-based algorithms for constrained total variation image denoising and deblurring problems", "author": ["A. Beck", "M. Teboulle"], "venue": "IEEE Trans. Image Processing,", "citeRegEx": "Beck and Teboulle,? \\Q2009\\E", "shortCiteRegEx": "Beck and Teboulle", "year": 2009}, {"title": "Convergence and energy landscape for Cheeger cut clustering", "author": ["X. Bresson", "T. Laurent", "D. Uminsky", "J.H. von Brecht"], "venue": "In NIPS,", "citeRegEx": "Bresson et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bresson et al\\.", "year": 2012}, {"title": "A local graph partitioning algorithm using heat kernel pagerank", "author": ["F. Chung"], "venue": "In WAW, pp", "citeRegEx": "Chung,? \\Q2009\\E", "shortCiteRegEx": "Chung", "year": 2009}, {"title": "Exact penalty methods", "author": ["G. Di Pillo"], "venue": "Algorithms for Continuous Optimization,", "citeRegEx": "Pillo,? \\Q1994\\E", "shortCiteRegEx": "Pillo", "year": 1994}, {"title": "On nonlinear fractional programming", "author": ["W. Dinkelbach"], "venue": "Management Science,", "citeRegEx": "Dinkelbach,? \\Q1967\\E", "shortCiteRegEx": "Dinkelbach", "year": 1967}, {"title": "Community detection in graphs", "author": ["S. Fortunato"], "venue": "Physics Reports,", "citeRegEx": "Fortunato,? \\Q2010\\E", "shortCiteRegEx": "Fortunato", "year": 2010}, {"title": "Multi-skill collaborative teams based on densest subgraphs", "author": ["A. Gajewar", "A. Das Sarma"], "venue": "In SDM, pp", "citeRegEx": "Gajewar and Sarma,? \\Q2012\\E", "shortCiteRegEx": "Gajewar and Sarma", "year": 2012}, {"title": "Finding a maximum density subgraph", "author": ["A.V. Goldberg"], "venue": "Technical Report UCB/CSD-84-171,", "citeRegEx": "Goldberg,? \\Q1984\\E", "shortCiteRegEx": "Goldberg", "year": 1984}, {"title": "Fast spectral methods for ratio cut partitioning and clustering", "author": ["L. Hagen", "A.B. Kahng"], "venue": "In ICCAD, pp", "citeRegEx": "Hagen and Kahng,? \\Q1991\\E", "shortCiteRegEx": "Hagen and Kahng", "year": 1991}, {"title": "Semi-supervised eigenvectors for locally-biased learning", "author": ["T. Hansen", "M. Mahoney"], "venue": "In NIPS, pp. 2537\u20132545,", "citeRegEx": "Hansen and Mahoney,? \\Q2012\\E", "shortCiteRegEx": "Hansen and Mahoney", "year": 2012}, {"title": "An inverse power method for nonlinear eigenproblems with applications in 1spectral clustering and sparse PCA", "author": ["M. Hein", "T. B\u00fchler"], "venue": "In NIPS,", "citeRegEx": "Hein and B\u00fchler,? \\Q2010\\E", "shortCiteRegEx": "Hein and B\u00fchler", "year": 2010}, {"title": "Beyond spectral clustering tight relaxations of balanced graph cuts", "author": ["M. Hein", "S. Setzer"], "venue": "In NIPS, pp", "citeRegEx": "Hein and Setzer,? \\Q2011\\E", "shortCiteRegEx": "Hein and Setzer", "year": 2011}, {"title": "The pseudoflow algorithm and the pseudoflow-based simplex for the maximum flow problem", "author": ["D.S. Hochbaum"], "venue": "In IPCO, pp", "citeRegEx": "Hochbaum,? \\Q1998\\E", "shortCiteRegEx": "Hochbaum", "year": 1998}, {"title": "Ruling out PTAS for graph min-bisection, dense k-subgraph, and bipartite clique", "author": ["S. Khot"], "venue": "SIAM J. Comput.,", "citeRegEx": "Khot,? \\Q2006\\E", "shortCiteRegEx": "Khot", "year": 2006}, {"title": "On finding dense subgraphs", "author": ["S. Khuller", "B. Saha"], "venue": "In ICALP, pp", "citeRegEx": "Khuller and Saha,? \\Q2009\\E", "shortCiteRegEx": "Khuller and Saha", "year": 2009}, {"title": "On Linear-Time algorithms for the continuous quadratic knapsack problem", "author": ["K. Kiwiel"], "venue": "J. Opt. Theory Appl.,", "citeRegEx": "Kiwiel,? \\Q2007\\E", "shortCiteRegEx": "Kiwiel", "year": 2007}, {"title": "A local spectral method for graphs: With applications to improving graph partitions and exploring data graphs locally", "author": ["M.W. Mahoney", "L. Orecchia", "N.K. Vishnoi"], "venue": null, "citeRegEx": "Mahoney et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mahoney et al\\.", "year": 2012}, {"title": "Biased normalized cuts", "author": ["S. Maji", "N.K. Vishnoi", "J. Malik"], "venue": "In CVPR, pp. 2057\u20132064,", "citeRegEx": "Maji et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Maji et al\\.", "year": 2011}, {"title": "Partitioning sparse matrices with eigenvectors of graphs", "author": ["A. Pothen", "H.D. Simon", "Liou", "K.-P"], "venue": "SIAM J. Matrix Anal. Appl.,", "citeRegEx": "Pothen et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Pothen et al\\.", "year": 1990}, {"title": "Constrained 1spectral clustering", "author": ["S.S. Rangapuram", "M. Hein"], "venue": "In AISTATS, pp. 1143\u20131151,", "citeRegEx": "Rangapuram and Hein,? \\Q2012\\E", "shortCiteRegEx": "Rangapuram and Hein", "year": 2012}, {"title": "Dense subgraphs with restrictions and applications to gene annotation graphs", "author": ["B. Saha", "A. Hoch", "S. Khuller", "L. Raschid", "Zhang", "X.-N"], "venue": "In RECOMB,", "citeRegEx": "Saha et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Saha et al\\.", "year": 2010}, {"title": "Normalized cuts and image segmentation", "author": ["J. Shi", "J. Malik"], "venue": "IEEE Trans. Patt. Anal. Mach. Intell.,", "citeRegEx": "Shi and Malik,? \\Q2000\\E", "shortCiteRegEx": "Shi and Malik", "year": 2000}, {"title": "Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems", "author": ["D.A. Spielman", "Teng", "S.-H"], "venue": "In STOC,", "citeRegEx": "Spielman et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Spielman et al\\.", "year": 2004}, {"title": "Total variation and Cheeger cuts", "author": ["A. Szlam", "X. Bresson"], "venue": "In ICML, pp. 1039\u20131046,", "citeRegEx": "Szlam and Bresson,? \\Q2010\\E", "shortCiteRegEx": "Szlam and Bresson", "year": 2010}, {"title": "A tutorial on spectral clustering", "author": ["U. von Luxburg"], "venue": "Statistics and Computing,", "citeRegEx": "Luxburg,? \\Q2007\\E", "shortCiteRegEx": "Luxburg", "year": 2007}, {"title": "Constrained K-means clustering with background knowledge", "author": ["K. Wagstaff", "C. Cardie", "S. Rogers", "S. Schroedl"], "venue": "In ICML, pp", "citeRegEx": "Wagstaff et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Wagstaff et al\\.", "year": 2001}], "referenceMentions": [{"referenceID": 8, "context": "Prominent examples are the normalized cut problem, from which the popular spectral clustering method is derived (Shi & Malik, 2000), and the maximum density subgraph problem, which has applications in community detection (Fortunato, 2010) and bioinformatics (Saha et al.", "startOffset": 221, "endOffset": 238}, {"referenceID": 23, "context": "Prominent examples are the normalized cut problem, from which the popular spectral clustering method is derived (Shi & Malik, 2000), and the maximum density subgraph problem, which has applications in community detection (Fortunato, 2010) and bioinformatics (Saha et al., 2010).", "startOffset": 258, "endOffset": 277}, {"referenceID": 26, "context": "In the case of clustering, Wagstaff et al. (2001) are the first to show how prior information given in the form of must-link and cannot-link constraints between vertices can be integrated into the k-means algorithm.", "startOffset": 27, "endOffset": 50}, {"referenceID": 26, "context": "In the case of clustering, Wagstaff et al. (2001) are the first to show how prior information given in the form of must-link and cannot-link constraints between vertices can be integrated into the k-means algorithm. Recently, Rangapuram & Hein (2012) proposed a generalization of the normalized cut problem that can handle must-link and cannot-link constraints.", "startOffset": 27, "endOffset": 251}, {"referenceID": 19, "context": "In the recent work of Mahoney et al. (2012), locality constraints in the form of a seed set and volume constraint have been integrated into the normalized cut formulation.", "startOffset": 22, "endOffset": 44}, {"referenceID": 19, "context": "In the recent work of Mahoney et al. (2012), locality constraints in the form of a seed set and volume constraint have been integrated into the normalized cut formulation. Furthermore, Khuller & Saha (2009) and Saha et al.", "startOffset": 22, "endOffset": 207}, {"referenceID": 19, "context": "In the recent work of Mahoney et al. (2012), locality constraints in the form of a seed set and volume constraint have been integrated into the normalized cut formulation. Furthermore, Khuller & Saha (2009) and Saha et al. (2010) considered size and distance constraints for the maximum density subgraph problem.", "startOffset": 22, "endOffset": 230}, {"referenceID": 19, "context": "Moreover, spectral-type relaxations (Mahoney et al., 2012) ar X iv :1 30 6.", "startOffset": 36, "endOffset": 58}, {"referenceID": 4, "context": "In another line of work (Hein & B\u00fchler, 2010; Szlam & Bresson, 2010; Hein & Setzer, 2011; Bresson et al., 2012), it has been shown that tight continuous relaxations exist for all balanced graph cut problems and the normalized cut subject to must-link and cannotlink constraints (Rangapuram & Hein, 2012).", "startOffset": 24, "endOffset": 111}, {"referenceID": 19, "context": "In the experimental section we will show the superior performance compared to state of the art methods (Andersen & Lang, 2006; Mahoney et al., 2012).", "startOffset": 103, "endOffset": 148}, {"referenceID": 21, "context": "The balanced graph cut problem is a well-known problem in computer science with applications ranging from parallel computing to image segmentation (Pothen et al., 1990; Shi & Malik, 2000).", "startOffset": 147, "endOffset": 187}, {"referenceID": 1, "context": "The proposed algorithm and subsequent work (Andersen et al., 2006; Chung, 2009) use random walks to explore the graph locally, without considering the whole graph.", "startOffset": 43, "endOffset": 79}, {"referenceID": 5, "context": "The proposed algorithm and subsequent work (Andersen et al., 2006; Chung, 2009) use random walks to explore the graph locally, without considering the whole graph.", "startOffset": 43, "endOffset": 79}, {"referenceID": 20, "context": "Their method has been successfully applied in semisupervised image segmentation (Maji et al., 2011) and for community detection around a given query set (Mahoney et al.", "startOffset": 80, "endOffset": 99}, {"referenceID": 19, "context": ", 2011) and for community detection around a given query set (Mahoney et al., 2012).", "startOffset": 61, "endOffset": 83}, {"referenceID": 19, "context": "In contrast, Mahoney et al. (2012) give up the runtime requirement and formulate the task as an explicit optimization problem, where one aims at finding the optimal normalized cut subject to a seed constraint and an upper bound on the volume of the set containing the seed set.", "startOffset": 13, "endOffset": 35}, {"referenceID": 19, "context": "In this paper we consider an extended version of the problem of Mahoney et al. (2012). Let J denote the set of seed vertices, \u015c a symmetric balancing function (e.", "startOffset": 64, "endOffset": 86}, {"referenceID": 19, "context": "However, in order to compare to the method of Mahoney et al. (2012), we restrict ourselves in this paper to the normalized cut with volume constraints, that is \u015c(C) = vold(C) vold(C) and g = d.", "startOffset": 46, "endOffset": 68}, {"referenceID": 10, "context": "The subgraph of maximum density can be computed in polynomial time (Goldberg, 1984).", "startOffset": 67, "endOffset": 83}, {"referenceID": 23, "context": "The problem (2) with only lower bound constraints has been considered in team selection (Gajewar & Das Sarma, 2012) and bioinformatics (Saha et al., 2010) where constant factor approximation algorithms were developed.", "startOffset": 135, "endOffset": 154}, {"referenceID": 16, "context": ", hi = 1), and it has been shown that there is no polynomial time approximation scheme in these cases (Khot, 2006; Khuller & Saha, 2009).", "startOffset": 102, "endOffset": 136}, {"referenceID": 19, "context": "Our algorithms consistently outperform competing methods (Andersen & Lang, 2006; Mahoney et al., 2012).", "startOffset": 57, "endOffset": 102}, {"referenceID": 2, "context": "A particular important class of set functions are submodular set functions since their Lovasz extension is convex (Bach, 2011).", "startOffset": 114, "endOffset": 126}, {"referenceID": 2, "context": "In the following we list some useful properties of the Lovasz extension (see Fujishige, 2005; Bach, 2011; Hein & Setzer, 2011).", "startOffset": 72, "endOffset": 126}, {"referenceID": 2, "context": "The fact that they are the Lovasz extensions of set functions R\u0302, \u015c also implies that they are one-homogeneous, see Bach (2011). We now apply a slightly modified version of a result from Hein & Setzer (2011).", "startOffset": 116, "endOffset": 128}, {"referenceID": 2, "context": "The fact that they are the Lovasz extensions of set functions R\u0302, \u015c also implies that they are one-homogeneous, see Bach (2011). We now apply a slightly modified version of a result from Hein & Setzer (2011).", "startOffset": 116, "endOffset": 208}, {"referenceID": 7, "context": "Moreover, in the special case where the one-homogeneous function R is convex and S is concave, the RatioDCA reduces to Dinkelbach\u2019s method from fractional programming (Dinkelbach, 1967) and therefore computes the global optimum.", "startOffset": 167, "endOffset": 185}, {"referenceID": 2, "context": "2 in Bach (2011) is given by ( t (2) k\u2032 (f) ) ji = \uf8f1\uf8f4\uf8f2\uf8f4\uf8f4\uf8f3 0 volh(Ai+1) > k \u2032 k\u2032 \u2212 volh(Ai+1) volh(Ai) \u2265 k\u2032, volh(Ai+1) \u2264 k\u2032 hji volh(Ai) < k \u2032 ,", "startOffset": 5, "endOffset": 17}, {"referenceID": 18, "context": "Lemma 4 implies that the minimization problem can be solved via a standard projection onto the simplex, which can be computed in linear time (Kiwiel, 2007).", "startOffset": 141, "endOffset": 155}, {"referenceID": 7, "context": "As remarked in Section 4 it can then be solved globally optimally with our method, which in this case is equivalent to Dinkelbach\u2019s method (Dinkelbach, 1967).", "startOffset": 139, "endOffset": 157}, {"referenceID": 10, "context": "The following lemma shows that (17) can be rewritten as a s-t-min-cut-problem, which shows that the procedure is similar to the method of Goldberg (1984).", "startOffset": 138, "endOffset": 154}, {"referenceID": 15, "context": ", using the pseudo-flow algorithm of Hochbaum (1998).", "startOffset": 37, "endOffset": 53}, {"referenceID": 19, "context": "We evaluate our approach (denoted as CFSP) against the Local Spectral (LS) method by Mahoney et al. (2012) and the Lazy Random Walk (LRW) by Andersen & Lang (2006) on large social networks of the Stanford Large Network Dataset Collection (Leskovec).", "startOffset": 85, "endOffset": 107}, {"referenceID": 19, "context": "We evaluate our approach (denoted as CFSP) against the Local Spectral (LS) method by Mahoney et al. (2012) and the Lazy Random Walk (LRW) by Andersen & Lang (2006) on large social networks of the Stanford Large Network Dataset Collection (Leskovec).", "startOffset": 85, "endOffset": 164}, {"referenceID": 19, "context": "In Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally.", "startOffset": 3, "endOffset": 25}, {"referenceID": 19, "context": "In Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally. The resulting continuous solution is then transformed into a set via optimal thresholding. However, contrary to our method this is not guaranteed to yield a set that satisfies both the seed and volume constraints. Hence Mahoney et al. (2012) suggest, at the cost of losing their approximation guarantees, to perform constrained optimal thresholding which considers only thresholds that yield feasible sets.", "startOffset": 3, "endOffset": 354}, {"referenceID": 19, "context": "In Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally. The resulting continuous solution is then transformed into a set via optimal thresholding. However, contrary to our method this is not guaranteed to yield a set that satisfies both the seed and volume constraints. Hence Mahoney et al. (2012) suggest, at the cost of losing their approximation guarantees, to perform constrained optimal thresholding which considers only thresholds that yield feasible sets. In a recent generalization of their work, Hansen & Mahoney (2012) compute a sequence of locally-biased eigenvectors, the first of which corresponds to the solution of the spectral-type relaxation of Mahoney et al.", "startOffset": 3, "endOffset": 585}, {"referenceID": 19, "context": "In Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally. The resulting continuous solution is then transformed into a set via optimal thresholding. However, contrary to our method this is not guaranteed to yield a set that satisfies both the seed and volume constraints. Hence Mahoney et al. (2012) suggest, at the cost of losing their approximation guarantees, to perform constrained optimal thresholding which considers only thresholds that yield feasible sets. In a recent generalization of their work, Hansen & Mahoney (2012) compute a sequence of locally-biased eigenvectors, the first of which corresponds to the solution of the spectral-type relaxation of Mahoney et al. (2012). We use the code of Hansen & Mahoney (2012) to compute the solution of LS in our experiments.", "startOffset": 3, "endOffset": 740}, {"referenceID": 19, "context": "In Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally. The resulting continuous solution is then transformed into a set via optimal thresholding. However, contrary to our method this is not guaranteed to yield a set that satisfies both the seed and volume constraints. Hence Mahoney et al. (2012) suggest, at the cost of losing their approximation guarantees, to perform constrained optimal thresholding which considers only thresholds that yield feasible sets. In a recent generalization of their work, Hansen & Mahoney (2012) compute a sequence of locally-biased eigenvectors, the first of which corresponds to the solution of the spectral-type relaxation of Mahoney et al. (2012). We use the code of Hansen & Mahoney (2012) to compute the solution of LS in our experiments.", "startOffset": 3, "endOffset": 784}, {"referenceID": 19, "context": "In Mahoney et al. (2012), a spectral-type relaxation is derived for (18) that can be solved globally optimally. The resulting continuous solution is then transformed into a set via optimal thresholding. However, contrary to our method this is not guaranteed to yield a set that satisfies both the seed and volume constraints. Hence Mahoney et al. (2012) suggest, at the cost of losing their approximation guarantees, to perform constrained optimal thresholding which considers only thresholds that yield feasible sets. In a recent generalization of their work, Hansen & Mahoney (2012) compute a sequence of locally-biased eigenvectors, the first of which corresponds to the solution of the spectral-type relaxation of Mahoney et al. (2012). We use the code of Hansen & Mahoney (2012) to compute the solution of LS in our experiments. The local clustering technique of Andersen & Lang (2006) explores the graph locally by performing a lazy random walk with the transition matrix M = 12 ( I +WD\u22121 ) , where D is the degree matrix of the graph and the initial distribution is concentrated on the seed set.", "startOffset": 3, "endOffset": 891}], "year": 2013, "abstractText": "The (constrained) minimization of a ratio of set functions is a problem frequently occurring in clustering and community detection. As these optimization problems are typically NP-hard, one uses convex or spectral relaxations in practice. While these relaxations can be solved globally optimally, they are often too loose and thus lead to results far away from the optimum. In this paper we show that every constrained minimization problem of a ratio of non-negative set functions allows a tight relaxation into an unconstrained continuous optimization problem. This result leads to a flexible framework for solving constrained problems in network analysis. While a globally optimal solution for the resulting non-convex problem cannot be guaranteed, we outperform the loose convex or spectral relaxations by a large margin on constrained local clustering problems.", "creator": "LaTeX with hyperref package"}}}