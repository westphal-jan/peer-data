{"id": "1311.4527", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Nov-2013", "title": "A message-passing algorithm for multi-agent trajectory planning", "abstract": "We describe a novel approach to calculating collision-free global paths for $p $agents with defined initial and end configurations, based on an improved version of the alternate direction multiplier (ADMM) method. Compared to existing methods, our approach is naturally parallelizable and allows the inclusion of different cost functions with only minor adjustments. We apply our method to classic challenging cases and observe that their calculation requirements scale well with $p $for multiple cost functions. We also show that specializing our algorithm can be used to {\\ em local} motion planning by solving the problem of joint velocity optimization.", "histories": [["v1", "Mon, 18 Nov 2013 20:38:57 GMT  (754kb,D)", "http://arxiv.org/abs/1311.4527v1", "In Advances in Neural Information Processing Systems (NIPS), 2013. Demo video available atthis http URL"]], "COMMENTS": "In Advances in Neural Information Processing Systems (NIPS), 2013. Demo video available atthis http URL", "reviews": [], "SUBJECTS": "cs.AI cs.DC cs.MA cs.RO cs.SY", "authors": ["jos\u00e9 bento", "nate derbinsky", "javier alonso-mora", "jonathan s yedidia"], "accepted": true, "id": "1311.4527"}, "pdf": {"name": "1311.4527.pdf", "metadata": {"source": "CRF", "title": "A message-passing algorithm for multi-agent trajectory planning", "authors": ["Jos\u00e9 Bento", "Nate Derbinsky", "Javier Alonso-Mora", "Jonathan Yedidia"], "emails": ["jbento@disneyresearch.com", "nate.derbinsky@disneyresearch.com", "jalonso@disneyresearch.com", "yedidia@disneyresearch.com"], "sections": [{"heading": "1 Introduction", "text": "Robot navigation relies on at least three sub-tasks: localization, mapping, and motion planning. The latter can be described as an optimization problem: compute the lowest-cost path, or trajectory, between an initial and final configuration. This paper focuses on trajectory planning for multiple agents, an important problem in robotics [1, 2], computer animation, and crowd simulation [3].\nCentralized planning for multiple agents is PSPACE hard [4, 5]. To contend with this complexity, traditional multi-agent planning prioritizes agents and computes their trajectories sequentially [6], leading to suboptimal solutions. By contrast, our method plans for all agents simultaneously. Trajectory planning is also simplified if agents are non-distinct and can be dynamically assigned to a set of goal positions [1]. We consider the harder problem where robots have a unique identity and their goal positions are statically pre-specified. Both mixed-integer quadratic programming (MIQP) [7] and [more efficient, although local] sequential convex programming [8] approaches have been applied to the problem of computing collision-free trajectories for multiple agents with pre-specified goal positions; however, due to the non-convexity of the problem, these approaches, especially the former, do not scale well with the number of agents. Alternatively, trajectories may be found by sampling in their joint configuration space [9]. This approach is probabilistic and, alone, only gives asymptotic guarantees. See Appendix A for further comments on discrete search methods.\nDue to the complexity of planning collision-free trajectories, real-time robot navigation is commonly decoupled into a global planner and a fast local planner that performs collision-avoidance. Many single-agent reactive collision-avoidance algorithms are based either on potential fields [10], which typically ignore the velocity of other agents, or \u201cvelocity obstacles\u201d [11], which provide improved performance in dynamic environments by formulating the optimization in velocity space instead of Cartesian space. Building on an extension of the velocity-obstacles approach, recent work on centralized collision avoidance [12] computes collision-free local motions for all agents whilst maximizing a joint utility using either a computationally expensive MIQP or an efficient, though local, QP. While not the main focus of this paper, we show that a specialization of our approach \u2217This author would like to thank Emily Hupf and Noa Ghersin for their support while writing this paper.\nar X\niv :1\n31 1.\n45 27\nv1 [\ncs .A\nI] 1\n8 N\nov 2\nto global-trajectory optimization also applies for local-trajectory optimization, and our numerical results demonstrate improvements in both efficiency and scaling performance.\nIn this paper we formalize the global trajectory planning task as follows. Given p agents of different radii {ri}pi=1 with given desired initial and final positions, {xi(0)} p i=1 and {xi(T )} p i=1, along with a cost functional over trajectories, compute collision-free trajectories for all agents that minimize the cost functional. That is, find a set of intermediate points {xi(t)}pi=1, t \u2208 (0, T ), that satisfies the \u201chard\u201d collision-free constraints that \u2016xi(t)\u2212 xj(t)\u2016 > ri + rj , for all i, j and t, and that insofar as possible, minimizes the cost functional.\nThe method we propose searches for a solution within the space of piece-wise linear trajectories, wherein the trajectory of an agent is completely specified by a set of positions at a fixed set of time instants {ts}\u03b7s=0. We call these time instants break-points and they are the same for all agents, which greatly simplifies the mathematics of our method. All other intermediate points of the trajectories are computed by assuming that each agent moves with constant velocity in between break-points: if t1 and t2 > t1 are consecutive break-points, then xi(t) = 1t2\u2212t1 ((t2\u2212 t)xi(t1)+ (t\u2212 t1)xi(t2)) for t \u2208 [t1, t2]. Along with the set of initial and final configurations, the number of interior break-points (\u03b7\u2212 1) is an input to our method, with a corresponding tradeoff: increasing \u03b7 yields trajectories that are more flexible and smooth, with possibly higher quality; but increasing \u03b7 enlarges the problem, leading to potentially increased computation.\nThe main contributions of this paper are as follows:\ni) We formulate the global trajectory planning task as a decomposable optimization problem. We show how to solve the resulting sub-problems exactly and efficiently, despite their nonconvexity, and how to coordinate their solutions using message-passing. Our method, based on the \u201cthree-weight\u201d version of ADMM [13], is easily parallelized, does not require parameter tuning, and we present empirical evidence of good scalability with p.\nii) Within our decomposable framework, we describe different sub-problems, called minimizers, each ensuring the trajectories satisfy a separate criterion. Our method is flexible and can consider different combinations of minimizers. A particularly crucial minimizer ensures there are no inter-agent collisions, but we also derive other minimizers that allow for finding trajectories with minimal total energy, avoiding static obstacles, or imposing dynamic constraints, such as maximum/minimum agent velocity.\niii) We show that our method can specialize to perform local planning by solving the problem of joint optimization in velocity space [12].\nOur work is among the few examples where the success of applying ADMM to find approximate solutions to a large non-convex problems can be judged with the naked eye, by the gracefulness of the trajectories found. This paper also reinforces the claim in [13] that small, yet important, modifications to ADMM can bring an order of magnitude increase in speed. We emphasize the importance of these modifications in our numerical experiments, where we compare the performance of our method using the three-weight algorithm (TWA) versus that of standard ADMM.\nThe rest of the paper is organized as follows. Section 2 provides background on ADMM and the TWA. Section 3 formulates the global-trajectory-planning task as an optimization problem and describes the separate blocks necessary to solve it (the mathematical details of solving these subproblems are left to appendices). Section 4 evaluates the performance of our solution: its scalability with p, sensitivity to initial conditions, and the effect of different cost functionals. Section 5 explains how to implement a velocity-obstacle method using our method and compares its performance with prior work. Finally, Section 6 draws conclusions and suggests directions for future work."}, {"heading": "2 Minimizers in the TWA", "text": "In this section we provide a short description of the TWA [13], and, in particular, the role of the minimizer building blocks that it needs to solve a particular optimization problem. Section B of the supplementary material includes a full description of the TWA.\nAs a small illustrative example of how the TWA is used to solve optimization problems, suppose we want to solve minx\u2208R3 f(x) = min{x1,x2,x3} f1(x1, x3) + f2(x1, x2, x3) + f3(x3), where fi(.) \u2208\nR\u222a{+\u221e}. The functions can represent soft costs, for example f3(x3) = (x3\u22121)2, or hard equality or inequality constraints, such as f1(x1, x3) = J(x1 \u2264 x3), where we are using the notation J(.) = 0 if (.) is true or +\u221e if (.) is false. The TWA solves this optimization problem iteratively by passing messages on a bipartite graph, in the form of a Forney factor graph [14]: one minimizer-node per function fb, one equality-node per variable xj and an edge (b, j), connecting b and j, if fb depends on xj (see Figure 1-left).\nApart from the first-iteration message values, and two internal parameters1 that we specify in Section 4, the algorithm is fully specified by the behavior of the minimizers and the topology of the graph.\nWhat does a minimizer do? The minimizer-node g1, for example, solves a small optimization problem over its local variables x1 and x3. Without going into the full detail presented in [13] and the supplementary material, the estimates x1,1 and x1,3 are then combined with running sums of the differences between the minimizer estimates and the equality-node consensus estimates to obtain messages m1,1 and m1,3 on each neighboring edge that are sent to the neighboring equality-nodes along with corresponding certainty weights, \u2212\u2192\u03c1 1,2 and \u2212\u2192\u03c1 1,3. All other minimizers act similarly. The equality-nodes receive these local messages and weights and produce consensus estimates for all variables by computing an average of the incoming messages, weighted by the incoming certainty weights \u2212\u2192\u03c1 . From these consensus estimates, correcting messages are computed and communicated back to the minimizers to help them reach consensus. A certainty weight for the correcting messages,\u2190\u2212\u03c1 , is also communicated back to the minimizers. For example, the minimizer g1 receives correcting messages n1,1 and n1,3 with corresponding certainty weights\u2190\u2212\u03c1 1,1 and\u2190\u2212\u03c1 1,3 (see Figure 1-right). When producing new local estimates, the bth minimizer node computes its local estimates {xj} by choosing a point that minimizes the sum of the local function fb and weighted squared distance from the incoming messages (ties are broken randomly):\n{xb,j}j = gb ( {nb,j}j , {\u2190\u2212\u03c1 kb,j}j ) \u2261 arg min\n{xj}j fb({xj}j) + 1 2 \u2211 j \u2190\u2212\u03c1 b,j(xj \u2212 nb,j)2  , (1)\nwhere {}j and \u2211 j run over all equality-nodes connected to b. In the TWA, the certainty weights {\u2212\u2192\u03c1 b,j} that this minimizer outputs must be 0 (uncertain); \u221e (certain); or \u03c10, set to some fixed value. The logic for setting weights from minimizer-nodes depends on the problem; as we shall see, in trajectory planning problems, we only use 0 or \u03c10 weights. If we choose that all minimizers always output weights equal to \u03c10, the TWA reduces to standard ADMM; however, 0-weights allows equality-nodes to ignore inactive constraints, traversing the search space much faster.\nFinally, notice that all minimizers can operate simultaneously, and the same is true for the consensus calculation performed by each equality-node. The algorithm is thus easy to parallelize."}, {"heading": "3 Global trajectory planning", "text": "We now turn to describing our decomposition of the global trajectory planning optimization problem in detail. We begin by defining the variables to be optimized in our optimization problem. In\n1These are the step-size and \u03c10 constants. See Section B in the supplementary material for more detail.\nour formulation, we are not tracking the points of the trajectories by a continuous-time variable taking values in [0, T ]. Rather, our variables are the positions {xi(s)}i\u2208[p], where the trajectories are indexed by i and break-points are indexed by a discrete variable s taking values between 1 and \u03b7 \u2212 1. Note that {xi(0)}i\u2208[p] and {xi(\u03b7)}i\u2208[p] are the initial and final configuration, sets of fixed values, not variables to optimize."}, {"heading": "3.1 Formulation as unconstrained optimization without static obstacles", "text": "In terms of these variables, the non-collision constraints2 are\n\u2016(\u03b1xi(s+ 1) + (1\u2212 \u03b1)xi(s))\u2212 (\u03b1xj(s+ 1) + (1\u2212 \u03b1)xj(s))\u2016 \u2265 ri + rj , (2) for all i, j \u2208 [p], s \u2208 {0, ..., \u03b7 \u2212 1} and \u03b1 \u2208 [0, 1].\nThe parameter \u03b1 is used to trace out the constant-velocity trajectories of agents i and j between break-points s + 1 and s. The parameter \u03b1 has no units, it is a normalized time rather than an absolute time. If t1 is the absolute time of the break-point with integer index s and t2 is the absolute time of the break-point with integer index s+ 1 and t parametrizes the trajectories in absolute time then \u03b1 = (t\u2212 t1)/(t2 \u2212 t1). Note that in the above formulation, absolute time does not appear, and any solution is simply a set of paths that, when travelled by each agent at constant velocity between break-points, leads to no collisions. When converting this solution into trajectories parameterized by absolute time, the break-points do not need to be chosen uniformly spaced in absolute time.\nThe constraints represented in (2) can be formally incorporated into an unconstrained optimization problem as follows. We search for a solution to the problem:\nmin {xi(s)}i,s f cost({xi(s)}i,s) + \u03b7\u22121\u2211 s=0 \u2211 i>j f collri,rj (xi(s), xi(s+ 1), xj(s), xj(s+ 1)), (3)\nwhere {xi(0)}p and {xi(\u03b7)}p are constants rather than optimization variables, and where the function f cost is a function that represents some cost to be minimized (e.g. the integrated kinetic energy or the maximum velocity over all the agents) and the function f collr,r\u2032 is defined as,\nf collr,r\u2032(x, x, x \u2032, x\u2032) = J(\u2016\u03b1(x\u2212 x\u2032) + (1\u2212 \u03b1)(x\u2212 x\u2032)\u2016 \u2265 r + r\u2032 \u2200\u03b1 \u2208 [0, 1]). (4)\nIn this section, x and x represent the position of an arbitrary agent of radius r at two consecutive break-points and x\u2032 and x\u2032 the position of a second arbitrary agent of radius r\u2032 at the same breakpoints. In the expression above J(.) takes the value 0 whenever its argument, a clause, is true and takes the value +\u221e otherwise. Intuitively, we pay an infinite cost in f collr,r\u2032 whenever there is a collision, and we pay zero otherwise.\nIn (3) we can set f cost(.), to enforce a preference for trajectories satisfying specific properties. For example, we might prefer trajectories for which the total kinetic energy spent by the set of agents is small. In this case, defining f costC (x, x) = C\u2016x\u2212 x\u20162, we have,\nf cost({xi(s)}i,s) = 1\np\u03b7 p\u2211 i=1 \u03b7\u22121\u2211 s=0 f costCi,s(xi(s), xi(s+ 1)). (5)\nwhere the coefficients {Ci,s} can account for agents with different masses, different absolute-time intervals between-break points or different preferences regarding which agents we want to be less active and which agents are allowed to move faster.\nMore simply, we might want to exclude trajectories in which agents move faster than a certain amount, but without distinguishing among all remaining trajectories. For this case we can write,\nf costC (x, x) = J(\u2016x\u2212 x\u2016 \u2264 C). (6) In this case, associating each break-point to a time instant, the coefficients {Ci,s} in expression (5) would represent different limits on the velocity of different agents between different sections of the trajectory. If we want to force all agents to have a minimum velocity we can simply reverse the inequality in (6).\n2We replaced the strict inequality in the condition for non-collision by a simple inequality \u201c\u2265\u201d to avoid technicalities in formulating the optimization problem. Since the agents are round, this allows for a single point of contact between two agents and does not reduce practical relevance."}, {"heading": "3.2 Formulation as unconstrained optimization with static obstacles", "text": "In many scenarios agents should also avoid collisions with static obstacles. Given two points in space, xL and xR, we can forbid all agents from crossing the line segment from xL to xR by adding the following term to the function (3): \u2211p i=1 \u2211\u03b7\u22121 s=0 f wall xL,xR,ri(xi(s), xi(s+ 1)). We recall that ri is the radius of agent i and\nfwallxL,xR,r(x, x) = J(\u2016(\u03b1x+ (1\u2212 \u03b1)x)\u2212 (\u03b2xR + (1\u2212 \u03b2)xL)\u2016 \u2265 r for all \u03b1, \u03b2 \u2208 [0, 1]). (7)\nNotice that f coll can be expressed using fwall. In particular,\nf collr,r\u2032(x, x, x \u2032, x\u2032) = fwall0,0,r+r\u2032(x \u2032 \u2212 x, x\u2032 \u2212 x). (8) We use this fact later to express the minimizer associated with agent-agent collisions using the minimizer associated with agent-obstacle collisions.\nWhen agents move in the plane, i.e. xi(s) \u2208 R2 for all i \u2208 [p] and s+1 \u2208 [\u03b7+1], being able to avoid collisions with a general static line segment allows to automatically avoid collisions with multiple static obstacles of arbitrary polygonal shape. Our numerical experiments only consider agents in the plane and so, in this paper, we only describe the minimizer block for wall collision for a 2D world. In higher dimensions, different obstacle primitives need to be considered."}, {"heading": "3.3 Message-passing formulation", "text": "To solve (3) using the TWA, we need to specify the topology of the bipartite graph associated with the unconstrained formulation (3) and the operation performed by every minimizer, i.e. the \u2212\u2192\u03c1 - weight update logic and x-variable update equations. We postpone describing the choice of initial values and internal parameters until Section 4.\nWe first describe the bipartite graph. To be concrete, let us assume that the cost functional has the form of (5). The unconstrained formulation (3) then tells us that the global objective function is the sum of \u03b7p(p + 1)/2 terms: \u03b7p(p \u2212 1)/2 functions f coll and \u03b7p functions f costC . These functions involve a total of (\u03b7 + 1)p variables out of which only (\u03b7 \u2212 1)p are free (since the initial and final configurations are fixed). Correspondingly, the bipartite graph along which messages are passed has \u03b7p(p+1)/2 minimizer-nodes that connect to the (\u03b7+1)p equality-nodes. In particular, the equalitynode associated with the break-point variable xi(s), \u03b7 > s > 0, is connected to 2(p \u2212 1) different gcoll minimizer-nodes and two different gcostC minimizer-nodes. If s = 0 or s = \u03b7 the equality-node only connects to half as many gcoll nodes and gcostC nodes.\nWe now describe the different minimizers. Every minimizer basically is a special case of (1)."}, {"heading": "3.3.1 Agent-agent collision minimizer", "text": "We start with the minimizer associated with the functions f coll, that we denoted by gcoll. This minimizer receives as parameters the radius, r and r\u2032, of the two agents whose collision it is avoiding. The minimizer takes as input a set of incoming n-messages, {n, n, n\u2032, n\u2032}, and associated \u2190\u2212\u03c1 -weights, {\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 \u2032,\u2190\u2212\u03c1 \u2032}, and outputs a set of updated x-variables according to expression (9). Messages n and n come from the two equality-nodes associated with the positions of one of the agents at two consecutive break-points and n\u2032 and n\u2032 from the corresponding equality-nodes for the other agent.\ngcoll(n, n, n\u2032, n\u2032,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 \u2032,\u2190\u2212\u03c1 \u2032, r, r\u2032) = arg min {x,x,x\u2032,x\u2032} f collr,r\u2032(x, x, x \u2032, x\u2032)\n+ \u2190\u2212\u03c1 2 \u2016x\u2212 n\u20162 + \u2190\u2212 \u03c1 2 \u2016x\u2212 n\u20162 + \u2190\u2212\u03c1 \u2032 2 \u2016x\u2032 \u2212 n\u2032\u20162 + \u2190\u2212 \u03c1 \u2032 2 \u2016x\u2032 \u2212 n\u2032\u20162. (9)\nThe update logic for the weights \u2212\u2192\u03c1 for this minimizer is simple. If the trajectory from n to n for an agent of radius r does not collide with the trajectory from n\u2032 to n\u2032 for an agent of radius r\u2032 then set all the outgoing weights \u2212\u2192\u03c1 to zero. Otherwise set them all to \u03c10. The outgoing zero weights indicate to the receiving equality-nodes in the bipartite graph that the collision constraint for this pair of agents is inactive and that the values it receives from this minimizer-node should be ignored when computing the consensus values of the receiving equality-nodes.\nThe solution to (9) is found using the agent-obstacle collision minimizer that we describe next."}, {"heading": "3.3.2 Agent-obstacle collision minimizer", "text": "The minimizer for fwall is denoted by gwall. It is parameterized by the obstacle position {xL, xR} as well as the radius of the agent that needs to avoid the obstacle. It receives two n-messages, {n, n}, and corresponding weights {\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 }, from the equality-nodes associated with two consecutive positions of an agent that needs to avoid the obstacle. Its output, the x-variables, are defined as\ngwall(n, n, r, xL, xR, \u2190\u2212\u03c1 ,\u2190\u2212\u03c1 ) = arg min\n{x,x} fwallxL,xR,r(x, x) + \u2190\u2212\u03c1 2 \u2016x\u2212 n\u20162 + \u2190\u2212 \u03c1 2 \u2016x\u2212 n\u20162. (10)\nWhen agents move in the plane (2D), this minimizer can be solved by reformulating the optimization in (10) as a mechanical problem involving a system of springs that we can solve exactly and efficiently. This reduction is explained in the supplementary material in Section D and the solution to the mechanical problem is explained in Section I.\nThe update logic for the \u2212\u2192\u03c1 -weights is similar to that of the gcoll minimizer. If an agent of radius r going from n and n does not collide with the line segment from xL to xR then set all outgoing weights to zero because the constraint is inactive; otherwise set all the outgoing weights to \u03c10.\nNotice that, from (8), it follows that the agent-agent minimizer gcoll can be expressed using gwall. More concretely, as proved in the supplementary material, Section C,\ngcoll(n, n, n\u2032, n\u2032,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 \u2032,\u2190\u2212\u03c1 \u2032, r, r\u2032) =M2gwall ( M1.{n, n, n\u2032, n\u2032,\u2190\u2212\u03c1 , \u2190\u2212 \u03c1 ,\u2190\u2212\u03c1 \u2032,\u2190\u2212\u03c1 \u2032, r, r\u2032} ) ,\nfor a constant rectangular matrix M1 and a matrix M2 that depend on {n, n, n\u2032, n\u2032,\u2190\u2212\u03c1 , \u2190\u2212 \u03c1 ,\u2190\u2212\u03c1 \u2032,\u2190\u2212\u03c1 \u2032}."}, {"heading": "3.3.3 Minimum energy and maximum (minimum) velocity minimizer", "text": "When f cost can be decomposed as in (5), the minimizer associated with the functions f cost is denoted by gcost and receives as input two n-messages, {n, n}, and corresponding weights, {\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 }. The messages come from two equality-nodes associated with two consecutive positions of an agent. The minimizer is also parameterized by a cost factor c. It outputs a set of updated x-messages defined as\ngcost(n, n,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 , c) = arg min {x,x} f costc (x, x) + \u2190\u2212\u03c1 2 \u2016x\u2212 n\u20162 + \u2190\u2212 \u03c1 2 \u2016x\u2212 n\u20162. (11)\nThe update logic for the\u2212\u2192\u03c1 -weights of the minimum energy minimizer is very simply: always set all outgoing weights \u2212\u2192\u03c1 to \u03c10. The update logic for the \u2212\u2192\u03c1 -weights of the maximum velocity minimizer is the following. If \u2016n \u2212 n\u2016 \u2264 c set all outgoing weights to zero. Otherwise, set them to \u03c10. The update logic for the minimum velocity minimizer is similar. If \u2016n \u2212 n\u2016 \u2265 c, set all the \u2212\u2192\u03c1 -weights to zero. Otherwise set them to \u03c10.\nThe solution to the minimum energy, maximum velocity and minimum velocity minimizer is written in the supplementary material in Sections E, F, and G respectively."}, {"heading": "4 Numerical results", "text": "We now report on the performance of our algorithm (see Appendix J for an important comment on the anytime properties of our algorithm). Note that the lack of open-source scalable algorithms for global trajectory planning in the literature makes it difficult to benchmark our performance against other methods. Also, in a paper it is difficult to appreciate the gracefulness of the discovered trajectory optimizations, so we include a video in the supplementary material that shows final optimized trajectories as well as intermediate results as the algorithm progresses for a variety of additional scenarios, including those with obstacles. All the tests described here are for agents in a twodimensional plane. All tests but the last were performed using six cores of a 3.4GHz i7 CPU.\nThe different tests did not require any special tuning of parameters. In particular, the step-size in [13] (their \u03b1 variable) is always 0.1. In order to quickly equilibrate the system to a reasonable set of variables and to wash out the importance of initial conditions, the default weight \u03c10 was set equal to a small value (\u03b7p\u00d7 10\u22125) for the first 20 iterations and then set to 1 for all further iterations. The first test considers scenario CONF1: p (even) agents of radius r, equally spaced around on a circle of radius R, are each required to exchange position with the corresponding antipodal agent,\nr = (5/4)R sin(\u03c0/2(p \u2212 4)). This is a classical difficult test scenario because the straight line motion of all agents to their goal would result in them all colliding in the center of the circle. We compare the convergence time of the TWA with a similar version using standard ADMM to perform the optimizations. In this test, the algorithm\u2019s initial value for each variable in the problem was set to the corresponding initial position of each agent. The objective is to minimize the total kinetic energy (C in the energy minimizer is set to 1). Figure 2-left shows that the TWA scales better with p than classic ADMM and typically gives an order of magnitude speed-up. Please see Appendix K for a further comment on the scaling of the convergence time of ADMM and TWA with p.\nThe second test for CONF1 analyzes the sensitivity of the convergence time and objective value when the variables\u2019 value at the first iteration are chosen uniformly at random in the smallest spacetime box that includes the initial and final configuration of the robots. Figure 2-middle shows that, although there is some spread on the convergence time, our algorithm seems to reliably converge to relatively similar-cost local minima (other experiments show that the objective value of these minima is around 5 times smaller than that found when the algorithm is run using only the collision avoidance minimizers without a kinetic energy cost term). As would be expected, the precise trajectories found vary widely between different random runs.\nStill for CONF1, and fixed initial conditions, we parallelize our method using several cores of a 2.66GHz i7 processor and a very primitive scheduling/synchronization scheme. Although this scheme does not fully exploit parallelization, Figure 2-right does show a speed-up as the number of cores increases and the larger p is, the greater the speed-up. We stall when we reach the twelve physical cores available and start using virtual cores.\nFinally, Figure 3-left compares the convergence time to optimize the total energy with the time to simply find a feasible (i.e. collision-free) solution. The agents initial and final configuration is randomly chosen in the plane (CONF2). Error bars indicate \u00b1 one standard deviation. Minimizing the kinetic energy is orders of magnitude computationally more expensive than finding a feasible solution, as is clear from the different magnitude of the left and right scale of Figure 3-left."}, {"heading": "5 Local trajectory planning based on velocity obstacles", "text": "In this section we show how the joint optimization presented in [12], which is based on the concept of velocity obstacles [11] (VO), can be also solved via the message-passing TWA. In VO, given the current position {xi(0)}i\u2208[p] and radius {ri} of all agents, a new velocity command is computed jointly for all agents minimizing the distance to their preferred velocity {vrefi }i\u2208[p]. This new velocity command must guarantee that the trajectories of all agents remain collision-free for at least a time horizon \u03c4 . New collision-free velocities are computed every \u03b1\u03c4 seconds, \u03b1 < 1, until all agents reach their final configuration. Following [12], and assuming an obstacle-free environment and first order dynamics, the collision-free velocities are given by,\nminimize {vi}i\u2208[p] \u2211 i\u2208[p] Ci\u2016vi \u2212 vrefi \u20162 s.t. \u2016(xi(0) + vit)\u2212 (xj(0) + vjt)\u2016 \u2265 ri + rj \u2200 i \u2208 [p], t \u2208 [0, \u03c4 ].\nSince the velocities {vi}i\u2208[p] are related linearly to the final position of each object after \u03c4 seconds, {xi(\u03c4)}i\u2208[p], a simple change of variables allows us to reformulate the above problem as,\nminimize {xi}i\u2208[p] \u2211 i\u2208[p] C \u2032i\u2016xi \u2212 xrefi \u20162\ns.t. \u2016(1\u2212 \u03b1)(xi(0)\u2212 xj(0)) + \u03b1(xi \u2212 xj)\u2016 \u2265 ri + rj \u2200 j > i \u2208 [p], \u03b1 \u2208 [0, 1] (12) where C \u2032i = Ci/\u03c4 2, xrefi = xi(0) + v ref i \u03c4 and we have dropped the \u03c4 in xi(\u03c4). The above problem, extended to account for collisions with the static line segments {xRk, xLk}k, can be formulated in an unconstrained form using the functions f cost, f coll and fwall. Namely,\nmin {xi}i \u2211 i\u2208[p] f costC\u2032i (xi, x ref i ) + \u2211 i>j f collri,rj (xi(0), xi, xj(0), xj) + \u2211 i\u2208[p] \u2211 k fwallxRk,xLk,ri(xi(0), xi). (13)\nNote that {xi(0)}i and {xrefi }i are constants, not variables being optimized. Given this formulation, the TWA can be used to solve the optimization. All corresponding minimizers are special cases of minimizers derived in the previous section for global trajectory planning (see Section H in the supplementary material for details). Figure 3-right shows the distribution of the time to solve (12) for CONF1. We compare the mixed integer quadratic programming (MIQP) approach from [12] with ours. Our method finds a local minima of exactly (13), while [12] finds a global minima of an approximation to (13). Specifically, [12] requires approximating the search domain by hyperplanes and an additional branch-and-bound algorithm while ours does not. Both approaches use a mechanism for breaking the symmetry from CONF1 and avoid deadlocks: theirs uses a preferential rotation direction for agents, while we use agents with slightly different C coefficients in their energy minimizers (Cith agent = 1 + 0.001i). Both simulations were done on a single 2.66GHz core. The results show the order of magnitude is similar, but, because our implementation is done in Java while [12] uses Matlab-mex interface of CPLEX 11, the results are not exactly comparable."}, {"heading": "6 Conclusion and future work", "text": "We have presented a novel algorithm for global and local planning of the trajectory of multiple distinct agents, a problem known to be hard. The solution is based on solving a non-convex optimization problem using TWA, a modified ADMM. Its similarity to ADMM brings scalability and easy parallelization. However, using TWA improves performance considerably. Our implementation of the algorithm in Java on a regular desktop computer, using a basic scheduler/synchronization over its few cores, already scales to hundreds of agents and achieves real-time performance for local planning.\nThe algorithm can flexibly account for obstacles and different cost functionals. For agents in the plane, we derived explicit expressions that account for static obstacles, moving obstacles, and dynamic constraints on the velocity and energy. Future work should consider other restrictions on the smoothness of the trajectory (e.g. acceleration constraints) and provide fast solvers to our minimizers for agents in 3D.\nThe message-passing nature of our algorithm hints that it might be possible to adapt our algorithm to do planning in a decentralized fashion. For example, minimizers like gcoll could be solved by message exchange between pairs of agents within a maximum communication radius. It is an open problem to build a practical communication-synchronization scheme for such an approach."}, {"heading": "A Comment on related literature", "text": "A\u2217-search based methods and sampling-based methods require exploring a continuous domain using discrete graph structures. For problems with many degrees of freedom or complex kinematic and dynamic constraints, as when dealing with multiple agents or manipulators, fixed-grid search methods are impractical. Alternatively, exploration can be done using sampling algorithms with proved asymptotic convergence to the optimal solution [15]. However, as the dimensionality of the configuration space increases, the convergence rate degrades and the local planners required by the exploration loop become harder to implement. In addition, as pointed out in [9], sampling algorithms cannot easily produce solutions where multiple agents move in tight spaces, like in CONF1 with obstacles. Some of the disadvantages of using discrete random search structures are even visible in extremely simple scenarios. For example, for a single holonomic agent that needs to move as quickly as possible between two points in free-space, [15] require around 10000 samples on their RRT* method to find something close to the shortest-path solution. For our algorithm this is a trivial scenario: it outputs the optimal straight-line solution in 200 iterations and 37 msecs. in our Java implementation.\nB Full description of the improved three-weight message-passing algorithm of [13]\nFirst we give a self-contained (complete) description of the three-weight algorithm TWA from [13]. Their method is an improvement of the alternating direction method of multipliers (ADMM) 3. Assume we want to solve\nmin x\u2208Rd l\u2211 b=1 fb(x\u2202b), (14)\nwhere the set x\u2202b = {xj : j \u2208 \u2202b} is a vector obtained by considering the subset of entries of x with index in \u2202b \u2286 [d]. The functions fb do not need to be convex or smooth for the algorithm to be well-defined. However, the algorithm is only guaranteed to find the global minimum under convexity [22].\nStart by forming the following bipartite graph consisting of minimizer-nodes and equality-nodes. Create one minimizer-node, labeled \u201cg\u201d, per function fb and one equality-node, labeled \u201c=\u201d, per variable xj . There are l minimizer-nodes and d equality-nodes in total. If function fb depends on variable xj , create an edge (b, j) connecting b and j (see Figure B for a general representation).\nThe algorithm in [13] works by repetitively updating seven kind of variables. These can be listed as follows. Every equality-node j has a corresponding variable zj . Every edge (b, j) from minimizernode b to equality-node j has a corresponding variable xb,j , variable ub,j , message nb,j , message mb,j , weight \u2212\u2192\u03c1 b,j and weight\u2190\u2212\u03c1 b,j . To start the method, one specifies the initial values {z0j }, {u0b,j} and { \u2190\u2212\u03c1 0b,j}. Then, at every iteration k, repeat the following.\n3ADMM is a decomposition procedure for solving optimization problems. It coordinates the solutions to small local sub-problems to solve a large global problem. Hence, it is useful to derive parallel algorithms. It was introduced in [16] and [17] but is closely related to previous work as the dual decomposition method introduced by [18] and the method of multipliers introduced by [19, 20] and [21]. For a good review on ADMM see [22], where you can also find a self-contained proof of its convergence for convex problems.\n1\n2\nb\nl =\n=\n=\n=\ng\ng\ng\ng\n\u2026\n\u2026\n\u2026\n\u2026 nb, j,  \u03c1b, j mb, j,  \u03c1b, j\nxb, j ub, j zj j\nd\n2\n1\nThe set \u2202j contains all the minimizer-nodes that connect to equality-node j. If all weights {\u2212\u2192\u03c1 kb,j}b\u2208\u2202j are zero in the previous expression, treat them as 1.\n6. Compute the updated weights \u2190\u2212\u03c1 k+1. Weights leaving the same equality-node j, i.e.{\u2190\u2212\u03c1 k+1b,j }b\u2208\u2202j , are computed simultaneously. The update logic is described in Figure 5-right. According to which of the three distinct scenarios \u2212\u2192\u03c1 k falls, \u2190\u2212\u03c1 k+1 is uniquely determined. This logic again assigns three possible values for the weights {0, \u03c10,\u221e}.\n7. Update the u-variables for all edges. If edge (b, j) has \u2212\u2192\u03c1 kb,j = \u03c10 and \u2190\u2212\u03c1 k+1b,j = \u03c10 then\nuk+1b,j = u k b,j + (\u03b1/\u03c10)(x k+1 b,j \u2212 z k+1 j ), where \u03b1 is a pre-specified constant. Otherwise, choose uk+1b,j according to the three scenarios described in Figure 5-left, depending on the weights \u2212\u2192\u03c1 and\u2190\u2212\u03c1 .\nIn short, given \u03c10, \u03b1, the initial values {z0j }, {u0b,j} and { \u2190\u2212\u03c1 0b,j}, all the minimizers {gb}, with corresponding update logic for \u2212\u2192\u03c1 , and the bipartite graph, the method is completely specified. If all weights, \u2212\u2192\u03c1 and\u2190\u2212\u03c1 , are set to \u03c10 across all iterations, the described method reduces to classical ADMM , interpreted as a message-passing algorithm. Finally, notice that at each time step k, all the variables associated with each edge can be updated in parallel. In particular, the update of the x-variables, usually the most expensive operation, can be parallelized."}, {"heading": "C Agent-agent collision minimizer", "text": "Here we give the details of how to write the agent-agent collision minimizer, gcoll using the agentobstacle minimizer gwall of equation (10).\nFirst recall that f collr,r\u2032(x, x, x \u2032, x\u2032) = fwall0,0,r+r\u2032(x \u2032 \u2212 x, x\u2032 \u2212 x). Then, rewrite (9) as,\ngcoll(n, n, n\u2032, n\u2032,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 \u2032,\u2190\u2212\u03c1 \u2032, r, r\u2032) = arg min {x,x,x\u2032,x\u2032}\n[ fwall0,0,r+r\u2032(x \u2032 \u2212 x, x\u2032 \u2212 x)\n+ \u2190\u2212\u03c1 2 \u2016x\u2212 n\u20162 + \u2190\u2212 \u03c1 2 \u2016x\u2212 n\u20162 + \u2190\u2212\u03c1 \u2032 2 \u2016x\u2032 \u2212 n\u2032\u20162 + \u2190\u2212 \u03c1 \u2032 2 \u2016x\u2032 \u2212 n\u2032\u20162\n] . (15)\nNow introduce the following variables v = x\u2032 \u2212 x, u = x\u2032 + x, v = x\u2032 \u2212 x and u = x\u2032 + x. The function being minimized in (15) can be written as\nfwall0,0,r+r\u2032(v, v) + \u2190\u2212\u03c1 2 \u2225\u2225\u2225u\u2212 v 2 \u2212 n \u2225\u2225\u22252 + \u2190\u2212\u03c1 2 \u2225\u2225\u2225u\u2212 v 2 \u2212 n \u2225\u2225\u22252 + \u2190\u2212\u03c1 \u2032\n2 \u2225\u2225\u2225u+ v 2 \u2212 n\u2032 \u2225\u2225\u22252 + \u2190\u2212\u03c1 \u2032 2 \u2225\u2225\u2225u+ v 2 \u2212 n\u2032 \u2225\u2225\u22252. (16) Now notice that we can write, \u2190\u2212\u03c1 2 \u2225\u2225\u2225u\u2212 v 2 \u2212 n \u2225\u2225\u22252 + \u2190\u2212\u03c1 \u2032 2 \u2225\u2225\u2225u+ v 2 \u2212 n\u2032 \u2225\u2225\u22252 = \u2190\u2212\u03c1 8 \u2016u\u2212 v \u2212 2n\u20162 + \u2190\u2212\u03c1 \u2032 8 \u2016u+ v \u2212 2n\u2032\u20162\n= \u2190\u2212\u03c1 8 (\u2016u\u20162 + \u2016v + 2n\u20162 \u2212 2\u3008u, v + 2n\u3009) + \u2190\u2212\u03c1 \u2032 8 (\u2016u\u20162 + \u2016v \u2212 2n\u2032\u20162 + 2\u3008u, v \u2212 2n\u2032\u3009) = \u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032\n8 \u2016u\u20162 + 2\n\u2329 u, \u2190\u2212\u03c1 \u2032 \u2212\u2190\u2212\u03c1\n8 v \u2212 \u2190\u2212\u03c1 n+\u2190\u2212\u03c1 \u2032n\u2032 4 \u232a + \u2190\u2212\u03c1 8 \u2016v + 2n\u20162 + \u2190\u2212\u03c1 \u2032 8 \u2016v \u2212 2n\u2032\u20162\n= \u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032\n8\n\u2225\u2225\u2225u\u2212 (\u2190\u2212\u03c1 \u2212\u2190\u2212\u03c1 \u2032\u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032 v + 2( \u2190\u2212\u03c1 n+\u2190\u2212\u03c1 \u2032n\u2032) \u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032 )\u2225\u2225\u22252 + \u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032 8 \u2225\u2225\u2225v \u2212 2(\u2190\u2212\u03c1 \u2032n\u2032 \u2212\u2190\u2212\u03c1 n)\u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032 \u2225\u2225\u22252 + C(n,\u2190\u2212\u03c1 , n\u2032,\u2190\u2212\u03c1 \u2032),\nwhere C(n,\u2190\u2212\u03c1 , n\u2032,\u2190\u2212\u03c1 \u2032) is a constant that depends on the variables {n,\u2190\u2212\u03c1 , n\u2032,\u2190\u2212\u03c1 \u2032}. A similar manipulation can be done to \u2190\u2212 \u03c1 2 \u2225\u2225\u2225u\u2212v2 \u2212 n\u2225\u2225\u22252 + \u2190\u2212\u03c1 \u20322 \u2225\u2225\u2225u+v2 \u2212 n\u2032\u2225\u2225\u22252. Therefore, the expression (16) can be\nrewritten as\nfwall0,0,r+r\u2032(v, v) + \u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032\n8\n\u2225\u2225\u2225v \u2212 2(\u2190\u2212\u03c1 \u2032n\u2032 \u2212\u2190\u2212\u03c1 n)\u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032 \u2225\u2225\u22252 + \u2190\u2212 \u03c1 + \u2190\u2212 \u03c1 \u2032 8 \u2225\u2225\u2225v \u2212 2(\u2190\u2212\u03c1 \u2032n\u2032 \u2212\u2190\u2212\u03c1 n)\u2190\u2212 \u03c1 + \u2190\u2212 \u03c1 \u2032 \u2225\u2225\u22252 + \u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032\n8\n\u2225\u2225\u2225u\u2212 (\u2190\u2212\u03c1 \u2212\u2190\u2212\u03c1 \u2032\u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032 v + 2( \u2190\u2212\u03c1 n+\u2190\u2212\u03c1 \u2032n\u2032) \u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032 )\u2225\u2225\u22252 + \u2190\u2212 \u03c1 + \u2190\u2212 \u03c1 \u2032\n8\n\u2225\u2225\u2225u\u2212(\u2190\u2212\u03c1 \u2212\u2190\u2212\u03c1 \u2032\u2190\u2212 \u03c1 + \u2190\u2212 \u03c1 \u2032 v + 2( \u2190\u2212 \u03c1 n+ \u2190\u2212 \u03c1 \u2032n\u2032) \u2190\u2212 \u03c1 + \u2190\u2212 \u03c1 \u2032 )\u2225\u2225\u22252 + C(n, n\u2032, n, n\u2032,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 \u2032,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 \u2032), (17) where C(n, n\u2032, n, n\u2032,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 \u2032,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 \u2032) is a constant that depends on the variables n, n\u2032, n, n\u2032,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 \u2032, \u2190\u2212 \u03c1 and \u2190\u2212 \u03c1 \u2032.\nLet {v\u2217, v\u2217, u\u2217, u\u2217} be a set of values that minimizes equation (17). We have, {v\u2217, v\u2217} \u2208 gwall ( 2(\u2190\u2212\u03c1 \u2032n\u2032 \u2212\u2190\u2212\u03c1 n) \u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032 , 2( \u2190\u2212 \u03c1 \u2032n\u2032 \u2212\u2190\u2212\u03c1 n) \u2190\u2212 \u03c1 + \u2190\u2212 \u03c1 \u2032 , r + r\u2032, 0, 0, \u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032 4 , \u2190\u2212 \u03c1 + \u2190\u2212 \u03c1 \u2032 4 ) , (18)\n{u\u2217, u\u2217} = {\u2190\u2212\u03c1 \u2212\u2190\u2212\u03c1 \u2032 \u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032 v\u2217 + 2(\u2190\u2212\u03c1 n+\u2190\u2212\u03c1 \u2032n\u2032) \u2190\u2212\u03c1 +\u2190\u2212\u03c1 \u2032 , \u2190\u2212 \u03c1 \u2212\u2190\u2212\u03c1 \u2032 \u2190\u2212 \u03c1 + \u2190\u2212 \u03c1 \u2032 v\u2217 + 2( \u2190\u2212 \u03c1 n+ \u2190\u2212 \u03c1 \u2032n\u2032) \u2190\u2212 \u03c1 + \u2190\u2212 \u03c1 \u2032 } . (19)\nWe can now produce a set of values that satisfy\n{x\u2217, x\u2217, x\u2032\u2217, x\u2032\u2217} \u2208 gcoll(n, n, n\u2032, n\u2032,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 \u2032,\u2190\u2212\u03c1 \u2032, r, r\u2032) using the following relation,\n{x\u2217, x\u2217, x\u2032\u2217, x\u2032\u2217} = {u\u2217 \u2212 v\u2217\n2 , u\u2217 \u2212 v\u2217 2 , v\u2217 + u\u2217 2 , u\u2217 + v\u2217 2\n} .\nIn fact, all values {x\u2217, x\u2217, x\u2032\u2217, x\u2032\u2217} \u2208 gcoll(n, n, n\u2032, n\u2032,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 \u2032,\u2190\u2212\u03c1 \u2032, r, r\u2032) can be obtained from some {v\u2217, v\u2217, u\u2217, u\u2217} that minimizes equation (17). In other words, the minimizer gcoll can be expressed in terms of the minimizer gwall by means of a linear transformation.\nMinimizers can receive zero-weight messages\u2190\u2212\u03c1 from their neighboring equality nodes. In (18) and (19), this can lead to indeterminacies. We address this as follows. If\u2190\u2212\u03c1 and\u2190\u2212\u03c1 \u2032 are simultaneously zero then we compute (18) and (19) in the limit when \u2190\u2212\u03c1 = \u2190\u2212\u03c1 \u2032 \u2192 0+. When implementing this on software, we simply replace them by small equal values. The fact that \u2190\u2212\u03c1 = \u2190\u2212\u03c1 \u2032 resolves the indeterminacies in the fractions and taking the limit to zero from above guarantees that the wall minimizer gwall, that is solved using a mechanical analogy involving springs, is well behaved (See Section I). If \u2190\u2212 \u03c1 and \u2190\u2212 \u03c1 \u2032 are simultaneously zero, we perform a similar operation."}, {"heading": "D Agent-obstacle collision minimizer", "text": "In Section C we expressed the agent-agent collision minimizer by applying a linear transformation to the agent-obstacle collision minimizer. Now we show how the agent-obstacle minimizer can be posed as a classical mechanical problem involving a system of springs. Although the relationship in Section C holds in general, the transformation presented in this section holds only when the agents move in the plane, i.e. xi(s) \u2208 R2 \u2200s, i. Similar transformations should hold in higher dimensions. When the obstacle is a line-segment [xL, xR], the agent-obstacle minimizer (10) solves the following non-convex optimization problem,\nminimize {x,x} [\u2190\u2212\u03c1 2 \u2016x\u2212 n\u20162 + \u2190\u2212 \u03c1 2 \u2016x\u2212 n\u20162 ] (20)\ns.t. \u2016(\u03b1x+ (1\u2212 \u03b1)x)\u2212 (\u03b2xR + (1\u2212 \u03b2)xL)\u2016 \u2265 r for all \u03b1, \u03b2 \u2208 [0, 1]. (21)\nObserve that the term \u2190\u2212\u03c1 2 \u2016x \u2212 n\u2016\n2 equals the energy of a spring with zero rest-length and elastic coefficient \u2190\u2212\u03c1 whose end points are at positions x and n. The same interpretation applies for the\nsecond term in (20). With this interpretation in mind, the non-convex constraint (21) means that the line from x to x cannot cross the region swept out by a circle of radius r that moves from xL to xR. We call this region R. Figure 6-left shows a feasible solution and an unfeasible solution under this interpretation. When the line from n to n does not cross R, the solution of (20)-(21) is\nx = n and x = n. In general however, x and x adopt the minimum energy configuration of a system with two zero rest-length springs, with end points (n, x) and (n, x) and elastic coefficients\u2190\u2212\u03c1 and \u2190\u2212 \u03c1 , and with a hard extensible slab, connecting x to x, that cannot go over region R. The slab can be extended without spending any energy. Figure 6-right shows two feasible configurations of the system of springs and slab when x = n and x = n cannot be a feasible solution.\nIt is possible that this minimizer receives two zero-weight messages from its neighboring equality nodes, i.e., \u2190\u2212\u03c1 = \u2190\u2212\u03c1 = 0. This would correspond to not having any spring connecting point n to x and n to x. The mechanic system would then be indeterminate. When this is the case, we solve the mechanic system in the limit when\u2190\u2212\u03c1 =\u2190\u2212\u03c1 \u2192 0+. In terms of software implementation, this is achieved by replacing\u2190\u2212\u03c1 and\u2190\u2212\u03c1 by small equal values. In Section I we explain how to compute the minimum energy configuration of this system quickly. In other words, we show that the minimizer gwall can be implemented efficiently."}, {"heading": "E Energy minimizer", "text": "The energy minimizer solves the quadratic optimization problem\nmin {x,x}\n[ C\u2016x\u2212 x\u20162 + (\u2190\u2212\u03c1 /2)\u2016x\u2212 n\u20162 + (\u2190\u2212\u03c1 /2)\u2016x\u2212 n\u20162 ] .\nFrom the first order optimality conditions we get 2C(x \u2212 x) +\u2190\u2212\u03c1 (x \u2212 n) = 0 and 2C(x \u2212 x) + \u2190\u2212 \u03c1 (x\u2212 n) = 0. Solving for x and x we obtain,\nx = \u2190\u2212\u03c1\u2190\u2212\u03c1 n+ 2C(\u2190\u2212\u03c1 n+\u2190\u2212\u03c1 n) 2C(\u2190\u2212\u03c1 +\u2190\u2212\u03c1 ) +\u2190\u2212\u03c1\u2190\u2212\u03c1 , x = \u2190\u2212\u03c1\u2190\u2212\u03c1 n+ 2C(\u2190\u2212\u03c1 n+\u2190\u2212\u03c1 n) 2C(\u2190\u2212\u03c1 +\u2190\u2212\u03c1 ) +\u2190\u2212\u03c1\u2190\u2212\u03c1 . (22)\nIf the energy minimizer receives\u2190\u2212\u03c1 = \u2190\u2212\u03c1 = 0, we resolve the indeterminacy in computing (22) by letting\u2190\u2212\u03c1 =\u2190\u2212\u03c1 \u2192 0+."}, {"heading": "F Maximum velocity minimizer", "text": "This minimizer solves the convex problem minimize{x,x}\n[ (\u2190\u2212\u03c1 /2)\u2016x \u2212 n\u20162 + (\u2190\u2212\u03c1 /2)\u2016x \u2212 n\u20162 ] subject to \u2016x\u2212x\u2016 \u2264 C. If \u2016n\u2212n\u2016 \u2264 C then x = n and x = n. Otherwise, the constraint is active, and, using the KKT conditions, we have \u2190\u2212\u03c1 (x \u2212 n) = \u2212\u03bb(x \u2212 x) and \u2190\u2212\u03c1 (x \u2212 n) = \u2212\u03bb(x \u2212 x) where \u03bb 6= 0 is such that \u2016x\u2212 x\u2016 = C. Solving for x and x we get,\nx = \u2190\u2212\u03c1 (\u2190\u2212\u03c1 + \u03bb)n+ \u03bb\u2190\u2212\u03c1 n \u2190\u2212\u03c1\u2190\u2212\u03c1 + \u03bb(\u2190\u2212\u03c1 +\u2190\u2212\u03c1 ) , x = \u2190\u2212 \u03c1 (\u2190\u2212\u03c1 + \u03bb)n+ \u03bb\u2190\u2212\u03c1 n \u2190\u2212\u03c1\u2190\u2212\u03c1 + \u03bb(\u2190\u2212\u03c1 +\u2190\u2212\u03c1 ) . (23)\nTo find the solution we just need to determine \u03bb. Computing the difference between the above expressions we get,\nx\u2212 x = n\u2212 n 1 + ( 1\u2190\u2212\u03c1 + 1\u2190\u2212 \u03c1 )\u03bb . (24)\nTaking the norm of the right hand side and setting it equal to C we get\n\u03bb = \u00b1 (\u2016n\u2212 n\u2016/C)\u2212 1\u2190\u2212\u03c1 \u22121 +\u2190\u2212\u03c1 \u22121 . (25)\nNow examine equation (24). Starting from an n\u2212 n such that \u2016n\u2212 n\u2016 > C, the fastest way to get to x \u2212 x with \u2016x \u2212 x\u2016 = C is to increase \u03bb > 0. Hence, in (25), we should choose the positive solution, i.e.\n\u03bb = (\u2016n\u2212 n\u2016/C)\u2212 1 \u2190\u2212\u03c1 \u22121 +\u2190\u2212\u03c1 \u22121 . (26)\nIf the maximum velocity minimizer receives\u2190\u2212\u03c1 =\u2190\u2212\u03c1 = 0, we resolve any indeterminacy by letting \u2190\u2212\u03c1 =\u2190\u2212\u03c1 \u2192 0+. In software, this is achieved by setting\u2190\u2212\u03c1 equal to\u2190\u2212\u03c1 equal to some small value."}, {"heading": "G Minimum velocity minimizer", "text": "This minimizer can be computed in a very similar way to the maximum velocity minimizer. If \u2016n \u2212 n\u2016 \u2265 C, then x = n and x = n. Otherwise, from the KKT conditions, we again obtain equation (23). The difference x \u2212 x is again the expression (24). Now, however, starting from n \u2212 n such that \u2016n \u2212 n\u2016 > C, the fastest way to get to x \u2212 x with \u2016x \u2212 x\u2016 = C, is to decrease \u03bb < 0. Hence, in (25), we should choose the negative solution, i.e. (26) holds again. If the minimum velocity minimizer receives\u2190\u2212\u03c1 =\u2190\u2212\u03c1 = 0, we resolve any indeterminacy by letting\u2190\u2212\u03c1 =\u2190\u2212\u03c1 \u2192 0+. In software, this is achieved by setting\u2190\u2212\u03c1 equal to\u2190\u2212\u03c1 equal to some small value.\nH Velocity obstacle minimizers\nIn this section we explain how to write the minimizers associated to each of the terms in equation (13) using the minimizers gcoll, gwall and gcost for global planning.\nFirst however, we briefly describe the bipartite graph that connects all these minimizers together. The bipartite graph for this problem has a gVO coll minimizer-node connecting every pair of equalitynodes. There is one equality-node per variable in {xi}. Recall that each of these variables describes the position of an agent at the end of a planning epoch. Each equality-node is also connected to a separate gVO cost minimizer-node. Finally, for obstacles in 2D, every equality node is also connected to several gVO wall minimizer-nodes, one per obstacle.\nWe start by describing the minimizer associated to the terms {f collri,rj (xi(0), xi, xj(0), xj)} in equation (13). This is given by\ngVO coll(n, n\u2032,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 \u2032, x0, x\u20320, r, r\u2032) = arg min {x,x\u2032}\n[ f collr,r\u2032(x 0, x, x\u20320, x\u2032)+ \u2190\u2212\u03c1 2 \u2016x\u2212n\u20162+ \u2190\u2212\u03c1 \u2032 2 \u2016x\u2032\u2212n\u2032\u20162 ] .\nThe messages n and n\u2032, and corresponding certainty weights \u2190\u2212\u03c1 and \u2190\u2212\u03c1 \u2032, come from the equalitynodes associated to the end position of two agents of radius r and r\u2032 that, during one time epoch, move from their initial positions x0 and x\u20320 to x and x\u2032 without colliding.\nThe outgoing weights\u2212\u2192\u03c1 and \u2212\u2192 \u03c1\u2032 associated to the variables x and x\u2032 are determined in the following way. If an agent of radius r moving from x0 to n does not collide with an agent of radius r\u2032 moving from x\u20320 to n\u2032, the minimizer will not propose a new trajectory for them, i.e., the minimizer will return x = n and x\u2032 = n\u2032. Hence, in this case, we set all outgoing weights equal to 0, signaling to neighboring equality-nodes that the minimizer wants to have no say when try to reach consensus. Otherwise, we set all outgoing weights equal to \u03c10.\nFor this minimizer, by direct substitution one sees that,\ngVO coll(n, n\u2032,\u2190\u2212\u03c1 ,\u2190\u2212\u03c1 \u2032, x0, x\u20320, r, r\u2032) = gcoll(x0, n, x\u20320, n\u2032,+\u221e,\u2190\u2212\u03c1 ,+\u221e,\u2190\u2212\u03c1 \u2032, r, r\u2032). (27)\nAbove we are using a notation where, given a function f , f(+\u221e) \u2261 limx\u2192+\u221e f(x). In software, this is implemented by replacing +\u221e by a very large value. In a very similar way, the minimizer associated to the terms {fwallxRk,xLk,ri(xi(0), xi)} can be written using the agent-obstacle minimizer for the global planning problem. Concretely,\ngVO wall(n, xL, xR, r, \u2190\u2212\u03c1 ) = gwall(x0, n, r, xL, xR,+\u221e,\u2190\u2212\u03c1 ). (28)\nFor this minimizer, the rule to set the outgoing weights is the following. If an agent of radius r can move from x0 to n without colliding with the line segment [xL xR] then set all outgoing weights to 0. Otherwise set them to \u03c10.\nFinally, we turn to the the minimizer associated to the terms {f costC\u2032i (xi, x ref i )}. This minimizer receives as input a message n, with corresponding certainty weight\u2190\u2212\u03c1 , from the equality-minimizer associated to the position of an agent at the end of a time epoch and outputs a local estimate, x, of its position at the end of the epoch. It also receives as parameter a reference position xref and a cost c of x deviating from it. To be concrete, its output is chosen uniformly at random from following argmin set,\ngVO cost(n,\u2190\u2212\u03c1 , xref, c) = argmin x\n[ f costc (x, x ref) + \u2190\u2212\u03c1 2 \u2016x\u2212 n\u20162 ] (29)\n= argmin x\n[ c\u2016x\u2212 xref\u20162 +\n\u2190\u2212\u03c1 2 \u2016x\u2212 n\u20162\n] . (30)\nThe outgoing weights for this minimizer are always set to \u03c10.\nAgain by direct substitution we see that, gVO cost(n,\u2190\u2212\u03c1 , xref, c) = gcost ( xref, n,+\u221e,\u2190\u2212\u03c1 , c ) , (31)\nwhere in gcost we are using the energy minimizer for the global planning problem."}, {"heading": "I Mechanical analog", "text": "In this section we explain how to compute the minimum energy configuration of the springs-slab system described in Section D. Basically, it reduces to computing the minimum of a one-dimensional real function over a closed interval.\nGiven n and n, two main scenarios need to be considered.\n1. If n, n /\u2208 R and [nn] \u2229 R = \u2205, i.e. the segment from n to n does not intersect R, then x = n and x = n.\n2. Otherwise, because there might be multiple local minima, i.e. multiple stable static configurations, we need to compare the energy of the following two configurations and return the one with minimum energy.\n(a) The slab is tangent toR, for example as in the blue configuration of Figure 6-right. (b) One of the springs is fully compressed and exactly one end of the slab is touching the\nboundary ofR, for example as in the red configuration of Figure 6-right.\nLet us compute the energy for Scenario 2a. The slab can be tangent to R in many different ways. However, the arrangement must always satisfy two properties. First, the point of contact, p, between the slab and R touches either the boundary of the semi-circle centered at xL or the boundary of the semi-circle centered at xR. Second, because extending/compressing the slab costs zero energy, the slab must be orthogonal to the line segment [nx] and to the line segment [nx].\nThe first observation allows us to express p using the map P (\u03b8) : [0, 2\u03c0] 7\u2192 R2 between the direction of the slab and the point of contact at boundary of the semi-circles,\nP (\u03b8) = { xR + rn\u0302(\u03b8) \u3008xR \u2212 xL, n\u0302(\u03b8)\u3009 \u2265 \u3008xL \u2212 xR, xR\u3009 xL + rn\u0302(\u03b8) otherwise\n(32)\nwhere n\u0302(\u03b8) = {cos(\u03b8), sin(\u03b8)}. Specifically, there is a \u03b80 \u2208 [0, 2\u03c0] such that p = P (\u03b80). The second observation tells us that x = n + \u03b3n\u0302(\u03b80) and x = n + \u03b3n\u0302(\u03b80) where \u03b3 and \u03b3 can be determined using the orthogonality conditions,\n\u3008x\u2212 P (\u03b80), n\u0302(\u03b80)\u3009 = 0\u21d2 \u03b3 = \u3008P (\u03b80)\u2212 n, n\u0302(\u03b80)\u3009 (33) \u3008x\u2212 P (\u03b80), n\u0302(\u03b80)\u3009 = 0\u21d2 \u03b3 = \u3008P (\u03b80)\u2212 n, n\u0302(\u03b80)\u3009. (34)\nTherefore, the minimum energy configuration over all tangent configurations, which is fully determined by \u03b80, must satisfy\n\u03b80 \u2208 arg min \u03b8\u2208[0,2\u03c0] Etangent(\u03b8) where, (35)\nEtangent(\u03b8) = \u2190\u2212\u03c1 2 (\u3008P (\u03b8)\u2212 n, n\u0302(\u03b8)\u3009)2 + \u2190\u2212 \u03c1 2 (\u3008P (\u03b8)\u2212 n, n\u0302(\u03b8)\u3009)2. (36)\nProblem (35) involves minimizing the one-dimensional function (36). Figure 7-left shows the typical behavior of Etangent(\u03b8). It is non-differentiable in at most 2 points. When the agent-obstacle\nminimizer is used to solve the agent-agent minimizer, the function becomes smooth and has second derivative throughout all its domain, see Figure 7-right. In the numerical results of Section 4, our implementation of the agent-agent minimizer uses Newton\u2019s method to solve (35). To find the global minimum, we apply Newton\u2019s method starting from four equally-space points in [0, 2\u03c0]. To produce the video accompanying this appendix, our implementation of the agent-obstacle minimizer solves (35) by scanning points in [0, 2\u03c0] with a step size of 2\u03c0/1000. In this case, it is obvious there is room for improvement in speed and accuracy by choosing smarter ways in which to solve (35).\nTo compute the energy for Scenario 2b, we need to determine which of the springs is fully contracted, or which side of the slab is touching R. If n \u2208 R and n /\u2208 R then x = n and x is the point in the boundary of R closest to n such that [xx] does not intersect R. Since the boundary of R is formed by parts of the boundary of two circles and of two lines, this closest point can be computed in closed form. If n \u2208 R and n /\u2208 R the situation is the opposite. If n, n \u2208 R, then we know we cannot be in Scenario 2b. Finally, if n, n /\u2208 R, we compute the energy assuming that x = n and then assuming that x = n and take the configuration with smallest energy between them."}, {"heading": "J Comment on our algorithm", "text": "Note that our algorithm does not possess anytime guarantees and, if stopped earlier, the trajectories might have collisions. However, if stopped early, a suboptimal set of non-colliding trajectories can be found at very low computational cost by using our algorithm to solve the feasibility problem in (2) starting from the state of the algorithm at stop time. In addition, although dynamic/static obstacles\ncan be seamlessly integrated into our framework, a solution must be recomputed (as is the case with A\u2217 or RRT\u2217) if their trajectories/positions change unexpectedly. This being said, in our algorithm, if a new piece of information is received, the previous solution can be used as the initial guess, potentially decreasing convergence time. Note that in some scenarios, a low-cost local-planning approach, such as the one presented in Section 5, can be beneficial."}, {"heading": "K Comment on the scaling of convergence time with p", "text": "Based on [13], we think that in non-adversarial configurations, in contrast to CONF1 where deadlocks are likely, the scaling of convergence time with p is not exponential. Our reasoning is based on a connection between trajectory planning and disk packing. For example, minimum-energy trajectory planning using piece-wise linear trajectories is related to, although not the same as, packing disks in multiple 2D layers, where the two matched disks between consecutive layers generate a larger cost when far away from each other. The numerical results in [13] report that, for disk packing, the runtime of ADMM and TWA is no more than polynomial in the number of disks and we believe the runtime for trajectory planning for non-adversarial configurations has a similar complexity. We interpret the seemingly exponential curve of convergence time versus p for n = 8 in Figure2-left as an atypical, adversarial scenario. By comparison, in Figure 3-left, which assumes randomly chosen initial and final points and also minimization of energy, the dashed-blue curve of runtime versus p for n = 8 does not appear to exhibit exponential growth."}], "references": [{"title": "Image and animation display with multiple mobile robots", "author": ["Javier Alonso-Mora", "Andreas Breitenmoser", "Martin Rufli", "Roland Siegwart", "Paul Beardsley"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Coordinating hundreds of cooperative, autonomous vehicles in warehouses", "author": ["Peter R. Wurman", "Raffaello D\u2019Andrea", "Mick Mountz"], "venue": "AI Magazine,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Clearpath: highly parallel collision avoidance for multi-agent simulation", "author": ["Stephen J. Guy", "Jatin Chhugani", "Changkyu Kim", "Nadathur Satish", "Ming Lin", "Dinesh Manocha", "Pradeep Dubey"], "venue": "In Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Complexity of the mover\u2019s problem and generalizations", "author": ["John H. Reif"], "venue": "In IEEE Annual Symposium on Foundations of Computer Science,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1979}, {"title": "On the complexity of motion planning for multiple independent objects; pspace-hardness of the \u201dwarehouseman\u2019s problem", "author": ["John E. Hopcroft", "Jacob T. Schwartz", "Micha Sharir"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1984}, {"title": "Finding and optimizing solvable priority schemes for decoupled path planning techniques for teams of mobile robots", "author": ["Maren Bennewitz", "Wolfram Burgard", "Sebastian Thrun"], "venue": "Robotics and Autonomous Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "Mixed-integer quadratic program trajectory generation for heterogeneous quadrotor teams", "author": ["Daniel Mellinger", "Alex Kushleyev", "Vijay Kumar"], "venue": "In IEEE International Conference on Robotics and Automation,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Generation of collision-free trajectories for a quadrocopter fleet: A sequential convex programming approach", "author": ["Federico Augugliaro", "Angela P. Schoellig", "Raffaello D\u2019Andrea"], "venue": "In IEEE/RSJ International Conference on Intelligent Robots and Systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Randomized kinodynamic planning", "author": ["Steven M. LaValle", "James J. Kuffner"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "Real-time obstacle avoidance for manipulators and mobile robots", "author": ["Oussama Khatib"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1986}, {"title": "Motion planning in dynamic environments using velocity obstacles", "author": ["Paolo Fiorini", "Zvi Shiller"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1998}, {"title": "Collision avoidance for multiple agents with joint utility maximization", "author": ["Javier Alonso-Mora", "Martin Rufli", "Roland Siegwart", "Paul Beardsley"], "venue": "In IEEE International Conference on Robotics and Automation,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "An improved three-weight messagepassing algorithm", "author": ["Nate Derbinsky", "Jos\u00e9 Bento", "Veit Elser", "Jonathan S. Yedidia"], "venue": "[cs.AI],", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Codes on graphs: Normal realizations", "author": ["G. David Forney Jr."], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2001}, {"title": "Incremental sampling-based algorithms for optimal motion planning", "author": ["Sertac Karaman", "Emilio Frazzoli"], "venue": "arXiv preprint arXiv:1005.0416,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Sur l\u2019approximation, par \u00e9l\u00e9ments finis d\u2019ordre un, et la r\u00e9solution, par p\u00e9nalisization-dualit\u00e9, d\u2019une class de probl\u00e8ms de Dirichlet non lin\u00e9are", "author": ["R. Glowinski", "A. Marrocco"], "venue": "Revue Franc\u0327aise d\u2019Automatique, Informatique, et Recherche Ope\u0301rationelle,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1975}, {"title": "A dual algorithm for the solution of nonlinear variational problems via finite element approximation", "author": ["Daniel Gabay", "Bertrand Mercier"], "venue": "Computers & Mathematics with Applications,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1976}, {"title": "Generalized lagrange multiplier method for solving problems of optimum allocation of resources", "author": ["Hugh Everett III"], "venue": "Operations Research,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1963}, {"title": "Hestenes. Multiplier and gradient methods", "author": ["R. Magnus"], "venue": "Journal of Optimization Theory and Applications,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1969}, {"title": "Hestenes. Multiplier and gradient methods", "author": ["R. Magnus"], "venue": "Computing Methods in Optimization Problems", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1969}, {"title": "A method for nonlinear constraints in minimization problems", "author": ["M.J.D. Powell"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1969}], "referenceMentions": [{"referenceID": 0, "context": "This paper focuses on trajectory planning for multiple agents, an important problem in robotics [1, 2], computer animation, and crowd simulation [3].", "startOffset": 96, "endOffset": 102}, {"referenceID": 1, "context": "This paper focuses on trajectory planning for multiple agents, an important problem in robotics [1, 2], computer animation, and crowd simulation [3].", "startOffset": 96, "endOffset": 102}, {"referenceID": 2, "context": "This paper focuses on trajectory planning for multiple agents, an important problem in robotics [1, 2], computer animation, and crowd simulation [3].", "startOffset": 145, "endOffset": 148}, {"referenceID": 3, "context": "Centralized planning for multiple agents is PSPACE hard [4, 5].", "startOffset": 56, "endOffset": 62}, {"referenceID": 4, "context": "Centralized planning for multiple agents is PSPACE hard [4, 5].", "startOffset": 56, "endOffset": 62}, {"referenceID": 5, "context": "To contend with this complexity, traditional multi-agent planning prioritizes agents and computes their trajectories sequentially [6], leading to suboptimal solutions.", "startOffset": 130, "endOffset": 133}, {"referenceID": 0, "context": "Trajectory planning is also simplified if agents are non-distinct and can be dynamically assigned to a set of goal positions [1].", "startOffset": 125, "endOffset": 128}, {"referenceID": 6, "context": "Both mixed-integer quadratic programming (MIQP) [7] and [more efficient, although local] sequential convex programming [8] approaches have been applied to the problem of computing collision-free trajectories for multiple agents with pre-specified goal positions; however, due to the non-convexity of the problem, these approaches, especially the former, do not scale well with the number of agents.", "startOffset": 48, "endOffset": 51}, {"referenceID": 7, "context": "Both mixed-integer quadratic programming (MIQP) [7] and [more efficient, although local] sequential convex programming [8] approaches have been applied to the problem of computing collision-free trajectories for multiple agents with pre-specified goal positions; however, due to the non-convexity of the problem, these approaches, especially the former, do not scale well with the number of agents.", "startOffset": 119, "endOffset": 122}, {"referenceID": 8, "context": "Alternatively, trajectories may be found by sampling in their joint configuration space [9].", "startOffset": 88, "endOffset": 91}, {"referenceID": 9, "context": "Many single-agent reactive collision-avoidance algorithms are based either on potential fields [10], which typically ignore the velocity of other agents, or \u201cvelocity obstacles\u201d [11], which provide improved performance in dynamic environments by formulating the optimization in velocity space instead of Cartesian space.", "startOffset": 95, "endOffset": 99}, {"referenceID": 10, "context": "Many single-agent reactive collision-avoidance algorithms are based either on potential fields [10], which typically ignore the velocity of other agents, or \u201cvelocity obstacles\u201d [11], which provide improved performance in dynamic environments by formulating the optimization in velocity space instead of Cartesian space.", "startOffset": 178, "endOffset": 182}, {"referenceID": 11, "context": "Building on an extension of the velocity-obstacles approach, recent work on centralized collision avoidance [12] computes collision-free local motions for all agents whilst maximizing a joint utility using either a computationally expensive MIQP or an efficient, though local, QP.", "startOffset": 108, "endOffset": 112}, {"referenceID": 12, "context": "Our method, based on the \u201cthree-weight\u201d version of ADMM [13], is easily parallelized, does not require parameter tuning, and we present empirical evidence of good scalability with p.", "startOffset": 56, "endOffset": 60}, {"referenceID": 11, "context": "iii) We show that our method can specialize to perform local planning by solving the problem of joint optimization in velocity space [12].", "startOffset": 133, "endOffset": 137}, {"referenceID": 12, "context": "This paper also reinforces the claim in [13] that small, yet important, modifications to ADMM can bring an order of magnitude increase in speed.", "startOffset": 40, "endOffset": 44}, {"referenceID": 12, "context": "In this section we provide a short description of the TWA [13], and, in particular, the role of the minimizer building blocks that it needs to solve a particular optimization problem.", "startOffset": 58, "endOffset": 62}, {"referenceID": 13, "context": "The TWA solves this optimization problem iteratively by passing messages on a bipartite graph, in the form of a Forney factor graph [14]: one minimizer-node per function fb, one equality-node per variable xj and an edge (b, j), connecting b and j, if fb depends on xj (see Figure 1-left).", "startOffset": 132, "endOffset": 136}, {"referenceID": 12, "context": "Without going into the full detail presented in [13] and the supplementary material, the estimates x1,1 and x1,3 are then combined with running sums of the differences between the minimizer estimates and the equality-node consensus estimates to obtain messages m1,1 and m1,3 on each neighboring edge that are sent to the neighboring equality-nodes along with corresponding certainty weights, \u2212 \u2192\u03c1 1,2 and \u2212 \u2192\u03c1 1,3.", "startOffset": 48, "endOffset": 52}, {"referenceID": 0, "context": ", \u03b7 \u2212 1} and \u03b1 \u2208 [0, 1].", "startOffset": 17, "endOffset": 23}, {"referenceID": 0, "context": "the integrated kinetic energy or the maximum velocity over all the agents) and the function f coll r,r\u2032 is defined as, f coll r,r\u2032(x, x, x \u2032, x\u2032) = J(\u2016\u03b1(x\u2212 x\u2032) + (1\u2212 \u03b1)(x\u2212 x\u2032)\u2016 \u2265 r + r\u2032 \u2200\u03b1 \u2208 [0, 1]).", "startOffset": 191, "endOffset": 197}, {"referenceID": 0, "context": "We recall that ri is the radius of agent i and fwall xL,xR,r(x, x) = J(\u2016(\u03b1x+ (1\u2212 \u03b1)x)\u2212 (\u03b2xR + (1\u2212 \u03b2)xL)\u2016 \u2265 r for all \u03b1, \u03b2 \u2208 [0, 1]).", "startOffset": 124, "endOffset": 130}, {"referenceID": 12, "context": "In particular, the step-size in [13] (their \u03b1 variable) is always 0.", "startOffset": 32, "endOffset": 36}, {"referenceID": 11, "context": "Convergence-time distribution for each epoch using our method (blue bars) and using the MIQP of [12] (red bars and star-values).", "startOffset": 96, "endOffset": 100}, {"referenceID": 11, "context": "In this section we show how the joint optimization presented in [12], which is based on the concept of velocity obstacles [11] (VO), can be also solved via the message-passing TWA.", "startOffset": 64, "endOffset": 68}, {"referenceID": 10, "context": "In this section we show how the joint optimization presented in [12], which is based on the concept of velocity obstacles [11] (VO), can be also solved via the message-passing TWA.", "startOffset": 122, "endOffset": 126}, {"referenceID": 11, "context": "Following [12], and assuming an obstacle-free environment and first order dynamics, the collision-free velocities are given by, minimize {vi}i\u2208[p] \u2211", "startOffset": 10, "endOffset": 14}, {"referenceID": 0, "context": "\u2016(1\u2212 \u03b1)(xi(0)\u2212 xj(0)) + \u03b1(xi \u2212 xj)\u2016 \u2265 ri + rj \u2200 j > i \u2208 [p], \u03b1 \u2208 [0, 1] (12) where C \u2032 i = Ci/\u03c4 , xref i = xi(0) + v ref i \u03c4 and we have dropped the \u03c4 in xi(\u03c4).", "startOffset": 65, "endOffset": 71}, {"referenceID": 11, "context": "We compare the mixed integer quadratic programming (MIQP) approach from [12] with ours.", "startOffset": 72, "endOffset": 76}, {"referenceID": 11, "context": "Our method finds a local minima of exactly (13), while [12] finds a global minima of an approximation to (13).", "startOffset": 55, "endOffset": 59}, {"referenceID": 11, "context": "Specifically, [12] requires approximating the search domain by hyperplanes and an additional branch-and-bound algorithm while ours does not.", "startOffset": 14, "endOffset": 18}, {"referenceID": 11, "context": "The results show the order of magnitude is similar, but, because our implementation is done in Java while [12] uses Matlab-mex interface of CPLEX 11, the results are not exactly comparable.", "startOffset": 106, "endOffset": 110}], "year": 2013, "abstractText": "We describe a novel approach for computing collision-free global trajectories for p agents with specified initial and final configurations, based on an improved version of the alternating direction method of multipliers (ADMM). Compared with existing methods, our approach is naturally parallelizable and allows for incorporating different cost functionals with only minor adjustments. We apply our method to classical challenging instances and observe that its computational requirements scale well with p for several cost functionals. We also show that a specialization of our algorithm can be used for local motion planning by solving the problem of joint optimization in velocity space.", "creator": "LaTeX with hyperref package"}}}