{"id": "1312.0841", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Dec-2013", "title": "Combining Simulated Annealing and Monte Carlo Tree Search for Expression Simplification", "abstract": "In many applications of computer algebra, large expressions need to be simplified in order to make repeated numerical evaluations comprehensible. Previous work has shown heuristically guided improvements, e.g. for Horner schemes, and the remaining expression is then further reduced by eliminating the usual subexpression. A more recent approach successfully applied a relatively new algorithm, Monte Carlo Tree Search (MCTS) with UCT as the selection criterion to find better variable orders. Nevertheless, this approach lends itself to further improvements as it is sensitive to the so-called exploration exploitation constant $C _ p $and the number of tree updates $N $. In this paper, we propose a new selection criterion called Simulated Annealing UCT (SA-UCT), which has a dynamic exploration exploitation parameter that reduces with the iteration number $i $and thus reduces the importance of the exploration over time we provide an intuitive explanation of the exploration algorithm.", "histories": [["v1", "Tue, 3 Dec 2013 14:56:28 GMT  (2131kb,D)", "http://arxiv.org/abs/1312.0841v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ben ruijl", "jos vermaseren", "aske plaat", "jaap van den herik"], "accepted": false, "id": "1312.0841"}, "pdf": {"name": "1312.0841.pdf", "metadata": {"source": "CRF", "title": "Combining Simulated Annealing and Monte Carlo Tree Search for Expression Simplification", "authors": ["Ben Ruijl", "Jos Vermaseren", "Aske Plaat", "Jaap van den Herik"], "emails": [], "sections": [{"heading": "1 INTRODUCTION", "text": "In High Energy Physics (HEP) expressions with millions of terms arise from the calculation of processes described by Feynman diagrams. Typically, these expressions have to be numerically integrated to predict cross sections and particle decays in collision processes. For example, in the Large Hadron Collider in CERN such calculations were essential to confirm the likely existence of the Higgs boson.\nIn order to predict the effects of currently undiscovered particles and to improve the accuracy of current HEP models, higher-order loop corrections are needed, causing the size of the expressions to grow exponentially (Peskin and Schroeder, 1995). The intermediate forms of these expressions may often take terabytes of disk space. Novel approaches are required to simplify these expressions to make evaluation feasible.\nTo simplify expressions Horner schemes and common subexpression elimination (CSEE) may be used. Horner\u2019s rule for simplifying expressions goes back to 1819 (Horner, 1819). CSEE is commonly used in compiler construction (Aho et al., 1988). In (Kuipers et al., 2013a) the first application of MCTS for finding a better variable ordering was presented, using UCT (Kocsis and Szepesva\u0301ri, 2006a) as the selection\ncriterion (see section 3). The MCTS performance is sensitive to the choice of three parameters: Cp, N, and R. Cp is the constant that governs the explorationexploitation choices of the algorithm, N is the number of tree updates, and R is the number of times the MCTS is repeated. At the previous ICAART conference the sensitivity to Cp and N was presented (van den Herik et al., 2013b). At CCIS/BNAIC the sensitivity to R was recognized (van den Herik et al., 2013a; Kuipers et al., 2013b). We believe that the practical applicability of the algorithm will improve as the sensitivity to these parameters is harmonized.\nThis paper focuses on Cp. We modify the UCT formula by introducing an exploration-exploitation parameter T (i), which decreases with the current iteration number i, effectively making the constant Cp a variable T (i). As a result, the first iterations will be explorative and throughout the search, the child selection will gradually become more exploitative, favoring optimizing a local minimum over exploration. The parameter T is similar to the role of the temperature in simulated annealing (hence the name T ). We refer to the new formula as Simulated Annealing UCT (SA-UCT).\nWe have tested our algorithms on three large expressions of different origins and we observed that SA-UCT widens the interval of good initial temper-\nar X\niv :1\n31 2.\n08 41\nv1 [\ncs .A\nI] 3\nD ec\n2 01\n3\natures T (0), where the number of operations is near the global minimum, by more than a tenfold for all three test expressions.\nThe paper is structured as follows. Section 2 provides a background and related work on expression simplification and MCTS. Section 3 presents our new selection criterion called SA-UCT. Section 4 shows our measurement results. Section 5 presents the conclusion and section 6 gives an outlook on future work."}, {"heading": "2 BACKGROUND", "text": "Numerous methods for simplifying expressions have been proposed. Here we mention Horner schemes (Knuth, 1997), common subexpression elimination (Aho et al., 1988), Breuer\u2019s growth algorithm for systems of expressions (Breuer, 1969), and partial syntactic factorization (Leiserson et al., 2010). In this paper we focus on two of these: Horner schemes and common subexpression elimination."}, {"heading": "2.1 Horner schemes", "text": "One elementary method of reducing the number of multiplications in an expression is based on Horner\u2019s rule (Horner, 1819; Knuth, 1997; Ceberio and Kreinovich, 2004). Horner\u2019s rule is straightforwardly lifting a variable outside brackets. For multivariate expressions Horner\u2019s rule can be applied multiple times, once for each variable. The order of the extracted variables is called a Horner scheme. For example:\nx3y2 + x2y+ x3z\u21d2 x2(y+ x(y2 + z)) (1) By twice extracting the variable x (i.e., x2 and x), the number of multiplications is reduced from 9 to 4. The number of additions remains the same, which is a general property of Horner schemes.\nIn multivariate expressions with n variables, there are n! ways of extracting variables. For example, the above expression could also be transformed to\nx3z+ y(x2(1+ xy)) (2)\nby first extracting y and then x. Using this scheme, we have 7 multiplications left. Thus, this Horner scheme is inferior to the first one.\nThe problem of selecting an optimal ordering is NP-hard (Ceberio and Kreinovich, 2004). A heuristic that works reasonably well is to select the variables according to their frequency of occurrence (\u201coccurrence order\u201d), see e.g., (Kuipers et al., 2013a). However, this does not always yield good results, also not when combined with common subexpression elimination (see below)."}, {"heading": "2.2 Common subexpression elimination", "text": "A way to reduce the number of operations even further is to perform a common subexpression elimination (CSEE). This strategy is well known in the field of compiler construction (Aho et al., 1988). CSEE creates new symbols for each subexpression that appears twice or more. Consequently, the subexpression has to be computed only once. Figure 1 shows an example of a subexpression in a tree representation.\nWe note that there is an interplay between Horner and CSEE in the following example:\nsin(x)+ cos(x)+ sin(x)x+ cos(x)x = sin(x)+ cos(x)+ x(sin(x)+ cos(x)) = T + xT\nMost practical methods of detecting common subexpressions will not find sin(x)+cos(x) as a subexpression in the first line, whereas in the second line it is detected. Hence, we observe that Horner schemes can expose common subexpressions."}, {"heading": "2.3 Monte Carlo Tree Search", "text": "Because there is an interplay between Horner schemes and CSEE, a trade-off exists between (1) selecting the optimal Horner scheme that reduces the largest number of multiplications and (2) selecting the Horner scheme that exposes the maximum number of CSEs. The contrast is between (1) a Horner scheme that reduces many multiplications, but has few CSEs, and (2) an average Horner scheme that exposes many CSEs. Category (2) would probably reduce the number of operations more than category (1). To find the best option, an optimization method is needed.\nOur goal is to minimize the total number of operations after both the Horner scheme and the CSEE have been applied to the expression. Motivated by the successes in (Kuipers et al., 2013a), we apply Monte Carlo Tree Search (MCTS) to our set of large expressions. A rich literature exists on MCTS, which is suc-\na.\nb.\nc.\nd.\ncessfully applied in the game of Go (Coulom, 2007). For an overview, see, e.g., (Browne et al., 2012).\nAn outline of the MCTS algorithm is displayed in figure 2. A tree is built in which each node is a variable that will be extracted. The tree will be built iteratively. At each iteration, a leaf (or a not fully expanded node) is chosen according to a selection criterion (see 2(a)) and section 3). This node is (further) expanded by randomly picking one of the unvisited children (see 2(b)). Starting from this new leaf, we continue the path by randomly selecting children (i.e., variables) that have not been selected so far (see 2(c)). The complete path is our Horner scheme1. For this scheme, we compute a score \u2206, which is the number of operations after the Horner scheme and CSEE have been applied (see 2(c) again). Finally, the result is propagated backwards through the tree (see 2(d)). For a more detailed explanation of MCTS, see (Browne et al., 2012).\nThus, MCTS is able to capture the trade-off of the Horner scheme and CSEE by using a score \u2206 which is the number of operations of the final expression after Horner and CSEE have been applied.\nSince we are interested in the best Horner scheme, we keep track of the best path that we come across during the tree updates. This path may not be completed in the tree if the tree did not reach the bottom or if there was another random playout that is better than the (partial) path through the tree.\nThe essence of MCTS is finding a proper tradeoff between exploiting nodes that have been characterized as good and exploring other (new) nodes that may contain a promising path. The challenge\n1Note the difference with games such as Go, where only the first move is needed.\nof a good algorithm is in balancing the explorationexploitation issue.\nIn the next section we modify the exploration part of the UCT selection criterion to scale with the iteration number. In related work a different strategy has been applied to make the importance of exploration versus exploitation iteration-number dependent. For example, Discounted UCB (Kocsis and Szepesva\u0301ri, 2006b) and Accelerated UCT (Hashimoto et al., 2012) both modify the average score of a node (see below) to discount old wins over new ones. In contrast, this work focuses on the explorationexploitation constant Cp."}, {"heading": "3 OUR ALGORITHM: SA-UCT", "text": "In many MCTS implementations UCT (eq. (3)) is chosen as the selection criterion (Browne et al., 2012; Kocsis and Szepesva\u0301ri, 2006a):\nargmax children c of s x\u0304(c)+2Cp\n\u221a 2lnn(s)\nn(c) (3)\nwhere c is a child node of node s, x\u0304(c) the average score of node c, n(c) the number of times the node c has been visited, and Cp the exploration-exploitation constant. This constant determines the probability that a child is selected that does not have a good average score2, but has not been visited often. If this constant is high, more iterations will be spent on exploration and if this constant is low, the iterations will be\n2In our application, the average score is the number of operations without optimizations divided by the average number of operations for visited paths through this node, see (Kuipers et al., 2013a).\nspent on exploitation. Generally, a higher Cp results in broader trees, whereas a smaller Cp yields deeper trees.\nFor our application, it matters that the tree is expanded as deeply as possible, since we want to optimize the entire Horner scheme, instead of just selecting the optimal first node, as is the case in games such as Go (please note, this is an important difference). Therefore, it is of higher value that the last iterations are used to deepen the tree and improve the current local minimum than performing additional explorations. To achieve this, we introduce a dynamic exploration-exploitation parameter T (for Temperature) that linearly decreases with the number of iterations:\nT (i) =Cp N\u2212 i\nN (4)\nwhere i is the current iteration number, N the preset maximum number of iterations, and Cp the initial exploration-exploitation constant at i = 0.\nOur new best child criterion becomes:\nargmax children c of s x\u0304(c)+2T\n\u221a 2lnn(s)\nn(c) (5)\nwhere c is a child of node s, x\u0304(c) is the average score of child c, n(c) the number of visits at node c, and T the dynamic exploration-exploitation parameter of eq. (4).\nThus, the first iterations are used for exploration and gradually the focus shifts to exploitation and optimization of the currently found local minimum. This process can be thought of as a variant of simulated annealing (Kirkpatrick et al., 1983), where a temperature determines the probability of exploring energetically unfavorable states. Starting at high temperatures, there is a great deal of exploration and when the temperature gradually decreases, the system converges to a local minimum. In our case, the decreasing exploration-exploration parameter T takes the role of the temperature. Because of the similarity between these approaches, we call eq. (5) \u201cSimulated Annealing UCT (SA-UCT)\u201d."}, {"heading": "4 RESULTS", "text": "In (Kuipers et al., 2013a), a sensitivity analysis of different parameters of MCTS is presented, which shows that there is a small interval of Cp for which the number of operations is close to the global best. We call this the region of interest. Below we investigate how this region changes if we use SA-UCT as selection criterion. Our experimental setup is as follows: we\ncompare the number of operations after the Horner scheme and CSEE have been applied for fixed N and different Cp for SA-UCT (eq. (5)) with those for the original UCT (eq. (3)). In SA-UCT, Cp is the starting value (initial temperature) T (0). We randomly sample 4000 dots for each graph (not to be confused with the number of operations on the y-axis that also starts with 4000).\nWe shall perform a sensitivity analysis of Cp on the number of operations for three expressions from mathematics and physics, namely HEP(\u03c3), res(7,5), and F13, see (Kuipers et al., 2013a). HEP(\u03c3) and F13 arise from parts of different Feynman diagrams and res(7,5) is a resultant (an object commonly used in number theory).\nIn figure 3 we show the results for HEP(\u03c3) with 15 variables. The figures on the left are generated using SA-UCT (where Cp is the initial temperature). The figures on the right use UCT. Figure 3(a) and 3(b) are measured with N = 300 tree updates, 3(c) and 3(d) with N = 1000, and 3(e) and 3(f) with N = 3000 updates. We see that for both algorithms there are different regions: one region in 3(a) and 3(b), two regions in 3(e) and three regions in 3(c), 3(d), and 3(f). The regions are separated by dashed lines. The regions are called low, intermediate and high. In figure 3(f) these regions are most prominent. At low Cp we observe that there are multiple local minima, indicated by high-density band structures (three are prominently visible). At intermediate values of Cp we have the region of interest where only the near global minimum is present. At high values there is a diffuse region with no distinguishable local minima. This happens when there is too much exploration.\nComparing the graphs on the left and on the right, we see that the linearly decreasing Cp causes a horizontal stretching, which makes the region of interest larger. If we look at the middle graphs, 3(c) and 3(d), where the number of updates N = 1000, the region of interest is approximately [0.8,5.0] for a linearly decreasing Cp, whereas it is roughly [0.5,0.7] for a constant Cp. Thus, SA-UCT makes the region of interest about 20 times larger for HEP(\u03c3), relative to the uninteresting low Cp region with local minima which did not grow significantly. For N = 3000, the difference in size of the region of interest is even larger.\nIn figure 4 we have tested our method on an expression from the field of mathematics, namely a resultant res(7,5), where res(m,n) = resx(\u2211mi=0 aixi,\u2211 n i=0 bix\ni), as described in (Leiserson et al., 2010). While from a different field, we still observe the band structures at low Cp and the widening of the region of interest occurs here as well. For figure 4(c) with N = 1000 tree updates using SA-UCT the\nregion of interest is approximately [0.1,1.0] and for 4(d) using UCT it is approximately [0.07,0.15]. This means that the region of interest has become about 10 times wider. In section 6 we continue our findings on this polynomial in a discussion.\nIn figure 5 we show the results for our third expression, called F13, which again stems from the field of high energy physics and has 22 variables. Since the depth of a complete tree is equal to the number of variables, more tree updates are required to reach the final node for F13, compared to the other two expressions. From the graphs we see that structure emerges around N = 1000. For UCT, there are two clouds: one near the global minimum and one near a higher local minimum. Contrary to the previous two expressions, F13 does not have a band structure at low Cp, but exhibits a diffuse cloud near the global minimum. However, we see that this cloud is wider (roughly 50 times at N = 1000) for SA-UCT than for UCT, as was the case for HEP(\u03c3) and res(7,5). Since the band is still broad, multiple samples are required to approach the global minimum, regardless of Cp. This is governed by the R parameter (van den Herik et al., 2013a; Kuipers et al., 2013b), and is consequently a topic for future research."}, {"heading": "5 CONCLUSION", "text": "In this work we proposed a new UCT formula, called SA-UCT, that has a decreasing explorationexploitation parameter T , similar to the temperature in simulated annealing. We have compared the performance of SA-UCT to the performance of UCT using three large expressions from physics and mathematics. From our experimental results we may provisionally conclude that SA-UCT significantly increases the range of initial temperatures Cp for which good results are obtained. This facilitates the selection of an appropriate Cp.\nDuring our research, we uncovered multiple areas for future research."}, {"heading": "6 DISCUSSION / FUTURE WORK", "text": "We start the discussion by distinguishing normal Horner scheme constructions from reversed constructions, also called forward and backward respectively. In the backward scheme, we create the Horner scheme from the inside out, reversing the extraction order. For example, in eq. (2) the forward scheme is y,x and the backward scheme is x,y. The distinction between the two constructions is important for MCTS, because by\nits nature the tree of MCTS is asymmetric: the children of the root are all explored, but most nodes at the bottom will not. Since we are interested in the entire path, this means that the end of the path will be underexplored compared to the beginning of the path. If large improvements can be made by carefully selecting variables at the end of the scheme, these optimizations will likely not be found. Figure 6 illustrates the effect that a forward and a backward scheme have on the res(7,5) expression, where N = 1000 and SAUCT is used. A forward scheme yields the three regions mentioned in section 4, whereas the backward scheme yields multiple local minima and a diffuse area for every Cp. The difference between forward and backward schemes is present for both SA-UCT and UCT, although it is more prominent in the latter. For UCT with Cp > 0.1, the tree often does not reach the end if the number of variables is larger than 15. The path is then completed using the random default policy, which selects a single path and consequently does no exploration. For SA-UCT, the tree often does reach the end and some exploration occurs, because a low and exploitative Cp effectively explores deeper in the tree. However, this effect is not suffi-\ncient to smooth out the differences between forward and backward schemes, as can be seen in figure 6. We found that choosing a backward scheme for HEP(\u03c3) and F13 leads to significant improvements. Whether we can predict beforehand (by looking at the expression) if forward or backward search has to be used is a topic of current research. Additionally, other ways than forward or backward construction of the Horner schemes could be used. For example, one could put more emphasis on the middle part of the scheme, by making the first variables map to the middle of the Horner scheme and working outwards from the center. Here again additional work is needed to predict which Horner scheme construction works best.\nAlso, more research is needed to find quickly a value of Cp in the region of interest. If the number of tree updates N is sufficiently high, the region of interest becomes so large that even a binary search may be sufficient to find a good Cp. In order to understand what N is required to obtain such a large region of interest, the relation between an adequate N and the number of variables has to be further investigated.\nFurthermore, the performance of SA-UCT has to be measured for different applications. Examples are the travelling salesman problem and Go. Many Go implementations currently set Cp = 0, effectively disabling UCT, but perhaps a small value for Cp is fruitful if SA-UCT is applied (Lee et al., 2009).\nMoreover, additional work is needed to examine different schemes for decreasing Cp. For example, the current depth in the tree may be a good candidate. One other possibility is detecting if the best child selection gets stuck in a local minimum and \u2018over-explores\u2019 a branch. If this is the case, the T could be increased to find further minima in unexplored branches. Different cooling functions could also be tried, such as exponentially decreasing T .\nFinally, we believe that the use of domain specific knowledge can be fruitfully explored if the expression has sufficient structure. To confirm this belief more research is needed."}], "references": [{"title": "Compilers: Principles, Techniques and Tools", "author": ["A.V. Aho", "R. Sethi", "J.D. Ullman"], "venue": null, "citeRegEx": "Aho et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Aho et al\\.", "year": 1988}, {"title": "Generation of Optimal Code for Expressions via Factorization", "author": ["M.A. Breuer"], "venue": "Commun. ACM,", "citeRegEx": "Breuer,? \\Q1969\\E", "shortCiteRegEx": "Breuer", "year": 1969}, {"title": "A Survey of Monte Carlo Tree Search Methods", "author": ["C. Browne", "E. Powley", "D. Whitehouse", "S. Lucas", "P. Cowling", "P. Rohlfshagen", "S. Tavener", "D. Perez", "S. Samothrakis", "S. Colton"], "venue": null, "citeRegEx": "Browne et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Browne et al\\.", "year": 2012}, {"title": "Greedy Algorithms for Optimizing Multivariate Horner Schemes", "author": ["M. Ceberio", "V. Kreinovich"], "venue": null, "citeRegEx": "Ceberio and Kreinovich,? \\Q2004\\E", "shortCiteRegEx": "Ceberio and Kreinovich", "year": 2004}, {"title": "Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search", "author": ["R. Coulom"], "venue": "In Proceedings of the 5th International Conference on Computers and Games,", "citeRegEx": "Coulom,? \\Q2007\\E", "shortCiteRegEx": "Coulom", "year": 2007}, {"title": "Accelerated UCT and Its Application to TwoPlayer Games", "author": ["J. Hashimoto", "A. Kishimoto", "K. Yoshizoe", "K. Ikeda"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "Hashimoto et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hashimoto et al\\.", "year": 2012}, {"title": "A New Method of Solving Numerical Equations of All Orders by Continuous Approximation", "author": ["W. Horner"], "venue": "W. Bulmer & Co. Dover reprint,", "citeRegEx": "Horner,? \\Q1959\\E", "shortCiteRegEx": "Horner", "year": 1959}, {"title": "Optimization by simulated annealing", "author": ["S. Kirkpatrick", "C.D. Gelatt", "M.P. Vecchi"], "venue": null, "citeRegEx": "Kirkpatrick et al\\.,? \\Q1983\\E", "shortCiteRegEx": "Kirkpatrick et al\\.", "year": 1983}, {"title": "The Art of Computer Programming, Volume 2 (3rd Ed.)", "author": ["D.E. Knuth"], "venue": null, "citeRegEx": "Knuth,? \\Q1997\\E", "shortCiteRegEx": "Knuth", "year": 1997}, {"title": "Bandit based MonteCarlo Planning", "author": ["L. Kocsis", "C. Szepesv\u00e1ri"], "venue": "In In: ECML-06", "citeRegEx": "Kocsis and Szepesv\u00e1ri,? \\Q2006\\E", "shortCiteRegEx": "Kocsis and Szepesv\u00e1ri", "year": 2006}, {"title": "Discounted UCB. Video Lecture", "author": ["L. Kocsis", "C. Szepesv\u00e1ri"], "venue": "In the lectures of PASCAL Second Challenges Workshop", "citeRegEx": "Kocsis and Szepesv\u00e1ri,? \\Q2006\\E", "shortCiteRegEx": "Kocsis and Szepesv\u00e1ri", "year": 2006}, {"title": "Improving multivariate Horner schemes with Monte Carlo Tree Search", "author": ["J. Kuipers", "A. Plaat", "J. Vermaseren", "J. van den Herik"], "venue": "Computer Physics Communications", "citeRegEx": "Kuipers et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kuipers et al\\.", "year": 2013}, {"title": "Code Optimization in FORM", "author": ["J. Kuipers", "T. Ueda", "J. Vermaseren"], "venue": null, "citeRegEx": "Kuipers et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kuipers et al\\.", "year": 2013}, {"title": "The Computational Intelligence of MoGo Revealed in Taiwan\u2019s Computer Go Tournaments", "author": ["Lee", "C.-S", "Wang", "M.-H", "G. Chaslot", "Hoock", "J.-B", "A. Rimmel", "O. Teytaud", "Tsai", "S.-R", "Hsu", "S.-C", "Hong", "T.-P"], "venue": "IEEE Trans. Comput. Intellig. and AI", "citeRegEx": "Lee et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2009}, {"title": "Efficient Evaluation of Large Polynomials", "author": ["C.E. Leiserson", "L. Li", "M.M. Maza", "Y. Xie"], "venue": "In In Proc. International Congress of Mathematical Software ICMS", "citeRegEx": "Leiserson et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Leiserson et al\\.", "year": 2010}, {"title": "An Introduction To Quantum Field Theory (Frontiers in Physics)", "author": ["M.E. Peskin", "D.V. Schroeder"], "venue": null, "citeRegEx": "Peskin and Schroeder,? \\Q1995\\E", "shortCiteRegEx": "Peskin and Schroeder", "year": 1995}, {"title": "Investigations with Monte Carlo Tree Search for finding better multivariate Horner schemes", "author": ["J. van den Herik", "J. Kuipers", "J. Vermaseren", "A. Plaat"], "venue": "Communications in Computer and Information Science", "citeRegEx": "Herik et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Herik et al\\.", "year": 2013}, {"title": "Connecting Sciences", "author": ["J. van den Herik", "A. Plaat", "J. Kuipers", "J. Vermaseren"], "venue": "In ICAART 2013 - Proceedings of the 5th International Conference on Agents and Artificial Intelligence,", "citeRegEx": "Herik et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Herik et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 15, "context": "In order to predict the effects of currently undiscovered particles and to improve the accuracy of current HEP models, higher-order loop corrections are needed, causing the size of the expressions to grow exponentially (Peskin and Schroeder, 1995).", "startOffset": 219, "endOffset": 247}, {"referenceID": 0, "context": "CSEE is commonly used in compiler construction (Aho et al., 1988).", "startOffset": 47, "endOffset": 65}, {"referenceID": 8, "context": "Here we mention Horner schemes (Knuth, 1997), common subexpression elimination (Aho et al.", "startOffset": 31, "endOffset": 44}, {"referenceID": 0, "context": "Here we mention Horner schemes (Knuth, 1997), common subexpression elimination (Aho et al., 1988), Breuer\u2019s growth algorithm for systems of expressions (Breuer, 1969), and partial syntactic factorization (Leiserson et al.", "startOffset": 79, "endOffset": 97}, {"referenceID": 1, "context": ", 1988), Breuer\u2019s growth algorithm for systems of expressions (Breuer, 1969), and partial syntactic factorization (Leiserson et al.", "startOffset": 62, "endOffset": 76}, {"referenceID": 14, "context": ", 1988), Breuer\u2019s growth algorithm for systems of expressions (Breuer, 1969), and partial syntactic factorization (Leiserson et al., 2010).", "startOffset": 114, "endOffset": 138}, {"referenceID": 8, "context": "One elementary method of reducing the number of multiplications in an expression is based on Horner\u2019s rule (Horner, 1819; Knuth, 1997; Ceberio and Kreinovich, 2004).", "startOffset": 107, "endOffset": 164}, {"referenceID": 3, "context": "One elementary method of reducing the number of multiplications in an expression is based on Horner\u2019s rule (Horner, 1819; Knuth, 1997; Ceberio and Kreinovich, 2004).", "startOffset": 107, "endOffset": 164}, {"referenceID": 3, "context": "The problem of selecting an optimal ordering is NP-hard (Ceberio and Kreinovich, 2004).", "startOffset": 56, "endOffset": 86}, {"referenceID": 0, "context": "This strategy is well known in the field of compiler construction (Aho et al., 1988).", "startOffset": 66, "endOffset": 84}, {"referenceID": 2, "context": "See also (Browne et al., 2012).", "startOffset": 9, "endOffset": 30}, {"referenceID": 4, "context": "cessfully applied in the game of Go (Coulom, 2007).", "startOffset": 36, "endOffset": 50}, {"referenceID": 2, "context": ", (Browne et al., 2012).", "startOffset": 2, "endOffset": 23}, {"referenceID": 2, "context": "For a more detailed explanation of MCTS, see (Browne et al., 2012).", "startOffset": 45, "endOffset": 66}, {"referenceID": 5, "context": "For example, Discounted UCB (Kocsis and Szepesv\u00e1ri, 2006b) and Accelerated UCT (Hashimoto et al., 2012) both modify the average score of a node (see below) to discount old wins over new ones.", "startOffset": 79, "endOffset": 103}, {"referenceID": 2, "context": "(3)) is chosen as the selection criterion (Browne et al., 2012; Kocsis and Szepesv\u00e1ri, 2006a):", "startOffset": 42, "endOffset": 93}, {"referenceID": 7, "context": "This process can be thought of as a variant of simulated annealing (Kirkpatrick et al., 1983), where a temperature determines the probability of exploring energetically unfavorable states.", "startOffset": 67, "endOffset": 93}, {"referenceID": 14, "context": "In figure 4 we have tested our method on an expression from the field of mathematics, namely a resultant res(7,5), where res(m,n) = resx(\u2211i=0 aix,\u2211 n i=0 bix i), as described in (Leiserson et al., 2010).", "startOffset": 178, "endOffset": 202}, {"referenceID": 13, "context": "Many Go implementations currently set Cp = 0, effectively disabling UCT, but perhaps a small value for Cp is fruitful if SA-UCT is applied (Lee et al., 2009).", "startOffset": 139, "endOffset": 157}], "year": 2013, "abstractText": "In many applications of computer algebra large expressions must be simplified to make repeated numerical evaluations tractable. Previous works presented heuristically guided improvements, e.g., for Horner schemes. The remaining expression is then further reduced by common subexpression elimination. A recent approach successfully applied a relatively new algorithm, Monte Carlo Tree Search (MCTS) with UCT as the selection criterion, to find better variable orderings. Yet, this approach is fit for further improvements since it is sensitive to the so-called \u201cexploration-exploitation\u201d constant Cp and the number of tree updates N. In this paper we propose a new selection criterion called Simulated Annealing UCT (SA-UCT) that has a dynamic explorationexploitation parameter, which decreases with the iteration number i and thus reduces the importance of exploration over time. First, we provide an intuitive explanation in terms of the exploration-exploitation behavior of the algorithm. Then, we test our algorithm on three large expressions of different origins. We observe that SA-UCT widens the interval of good initial values Cp where best results are achieved. The improvement is large (more than a tenfold) and facilitates the selection of an appropriate Cp.", "creator": "TeX"}}}