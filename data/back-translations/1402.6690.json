{"id": "1402.6690", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Feb-2014", "title": "Why Are You More Engaged? Predicting Social Engagement from Word Use", "abstract": "We present a study to analyze how word usage can predict social engagement behaviors such as responses and retweets on Twitter. We calculate psycholinguistic category values from word usage and investigate how people with different results displayed different response and retweet behavior on Twitter. We also found psycholinguistic categories that exhibit significant correlations with such social engagement behaviors. In addition, we have built predictive models of responses and retweets from such psycholinguistic category-based characteristics. Our experiments, using a real-world data set collected on Twitter, confirm that such predictions can be made with reasonable accuracy.", "histories": [["v1", "Wed, 26 Feb 2014 20:58:00 GMT  (182kb)", "http://arxiv.org/abs/1402.6690v1", null]], "reviews": [], "SUBJECTS": "cs.SI cs.CL cs.CY", "authors": ["jalal mahmud", "jilin chen", "jeffrey nichols"], "accepted": false, "id": "1402.6690"}, "pdf": {"name": "1402.6690.pdf", "metadata": {"source": "CRF", "title": "Why Are You More Engaged? Predicting Social Engagement from Word Use", "authors": ["Jalal Mahmud", "Jilin Chen"], "emails": ["jumahmud@us.ibm.com", "jilinc@us.ibm.com", "jwnichols@us.ibm.com"], "sections": [{"heading": null, "text": "We present a study to analyze how word use can predict social engagement behaviors such as replies and retweets in Twitter. We compute psycholinguistic category scores from word usage, and investigate how people with different scores exhibited different reply and retweet behaviors on Twitter. We also found psycholinguistic categories that show significant correlations with such social engagement behaviors. In addition, we have built predictive models of replies and retweets from such psycholinguistic category based features. Our experiments using a real world dataset collected from Twitter validates that such predictions can be done with reasonable accuracy."}, {"heading": "Author Keywords", "text": "Word Use, Social Engagement, Psycholinguistic"}, {"heading": "ACM Classification Keywords", "text": "H.5.2 [Information Interfaces and Presentation]: User Interfaces - Interaction styles."}, {"heading": "General Terms", "text": "Human Factors; Design; Measurement."}, {"heading": "INTRODUCTION", "text": "Recent years have seen a rapid growth in micro-blogging and the rise of popular micro-blogging services, such as Twitter where millions of tweets are posted every day. There have been a number of research works that have explored users\u2019 tweeting activity, such as replies and retweets [12, 15, 2]. Twitter has also been used to engage with strangers [13, 10]. Recently Chen et al. has investigated users\u2019 engagement behavior in Twitter relating to a political movement [6]. Understanding factors of users\u2019 social engagement can benefit social question answering [13, 10, 12, 15], viral marketing [3], and information diffusion [1], etc.\nIn this paper, we focus on understanding how users\u2019 word\nusage may affect different social engagement behaviors on Twitter. Prior research reported correlations of people\u2019s word usage with personality, and predicting personality from word usage [20, 7, 11]. In addition, algorithms that use word-based features to predict other attributes, such as sentiment [14] and political polarization [4] also exist. However, word use has not been studied in the context of different types of social engagement behaviors, such as response and retweets in Twitter.\nIn this work, we attempt to understand the role of word usage in two social engagement behaviors on Twitter: replies and retweets. We measured word use in a number of psycholinguistic categories as defined by the Linguistic Inquiry and Word Count (LIWC) dictionary [16]. Then, we correlated such psycholinguistic category scores with replies and retweets. Based on our analysis with a realworld dataset collected from Twitter, we have found statistically significant correlations of several psycholinguistic categories with replies and retweets. Furthermore, we have built predictive models from psycholinguistic category features for predicting likelihood of such replies and retweets on Twitter.\nOur work contributes to both theory and practice. On the theoretical side, our work is the first study that reports correlations of word usage with social engagement behaviors such as replies and retweets. On the practical side, our prediction models for predicting likelihood of replies and retweets from word usage can be used in wide varieties of scenarios such as recommending potential answerers for social question-answering [10, 12, 15], or potential information propagators for spreading alerts and warning messages in an emergency [17], viral marketing [3] and campaigns ranging from politics and government to social issues. Our experiments demonstrate that replies and retweets can be predicted reasonably accurately (23.6- 29.9% Mean Absolute Error and 76-85% binary classification accuracy). This result shows the promise of developing predictive models for wide varieties of social behaviors (e.g., following, liking, mentions) from word use and using such models in personalized systems."}, {"heading": "DATASETS", "text": "We used Twitter\u2019s Streaming API to randomly sample 17640 users in July 2013. Then we used Twitter\u2019s REST\nAPI to obtain their past 200 tweets. We computed each user\u2019s past_response_rate, which is the ratio of each user\u2019s\nnumber of responses to the total number of questions asked on Twitter. We used a rule-based method of using only question (?) mark to detect questions. Our choice is justified by previous studies which have found that most (81.5% as reported in [12]) questions asked on social network sites contained a question (?) mark. Also a rule-based method of using only question (?) mark to identify question in online content achieves more than 97% precision in detecting questions [4]. We did not consider retweets and tweets containing URLs. The average past_response_rate was 0.754 and standard deviation was 0.097.\nWe also collected each user\u2019s previous retweet history and computed each user\u2019s past_retweet_rate, which is the ratio of the number of retweets the user made to the total number of user\u2019s tweets. The average past_retweet rate was 0.117 and standard deviation was 0.15."}, {"heading": "PSYCHO-LINGUISTIC ANALYSIS FROM TEXT", "text": "We measured word uses with the Linguistic Inquiry and Word Count (LIWC) 2001 dictionary [16]. LIWC is the most commonly used language analysis tool for investigating the relation between word use and psychological variables [16]. LIWC 2001 defines over 70 different categories, each of which contains several dozens to hundreds of words [16]. We excluded the categories that are non-semantic (e.g., proportion of long words) or relevant to speech (e.g. fillers), and considered the remaining 66 LIWC categories.\nFor each person, we computed his/her LIWC-based scores in each category as the ratio of the number of occurrences of words in that category in one\u2019s tweets and the total number of words in his/her tweets. We excluded retweets when computing LIWC-based personality scores, because retweets are content generated by others."}, {"heading": "RESPONSE ANALYSIS", "text": "We begin by running a Pearson correlation analysis between the LIWC categories and users\npast_response_rate. The statistically significant correlations are shown in Table 1. LIWC category anger is\nnegatively correlated with response which indicates that people who use more angry words (such as anger, angry) are less likely to respond. The LIWC category communication is significantly positively correlated with response, which indicates that more communicative people are more likely to respond. An anxious person, exhibited by the LIWC category anxiety and consisting of words such as afraid and alarm, is less likely to respond. The LIWC category cognition, exemplified by words such as accept, acknowledge, admit, and agree, has a significant positive correlation with response. Similarly, a social (exemplified by words such as interact, involve), and individual with positive feelings (exemplified by words such as care, cheer, attachment) are more likely to respond. These are quite intuitive."}, {"heading": "RETWEET ANALYSIS", "text": "We also ran a Pearson correlation analysis between the LIWC categories and past_retweet_rate. The significant correlations are shown in Table 2. The LIWC categories perception, communication, social process, positive feelings, positive emotions, inclusive and other refs show positive significant correlations with retweeting behavior. The LIWC categories communication, social process and positive feelings also exhibited similar characteristics with response behavior.\nSo a person who is more communicative, social and has positive feelings is more responsive and more willing to retweet. The LIWC category perception represents words such as ask, call, and contact. These words are often used by people who are more interactive, and it seems intuitive that a person who scores high in the perception category is also more likely to retweet. The LIWC category positive emotions is exemplified by words such as accept and admit.\nThis is quite intuitive that a person who scores high in such category is more likely to retweet. In addition, we found that a person who scores high in the LIWC category inclusive, containing words such as along and also, is also more likely to retweet. This category is intuitively related with people who are more social and friendly, and it follows that people who scores high also seem to retweet. A person who scores high in the LIWC category \u201cother refs,\u201d exemplified by words such as he, she, and they, is also more likely to retweet others\u2019 tweets.\nThe LIWC category \u201cphysical states\u201d has significant negative correlations with retweet behavior. This category represents words such as diabetes, disease, dizziness, and sleep. These words often indicate someone\u2019s sickness or inactivity. This may indicate apathy on the part of the user, which would make them less likely to retweet. However, we lack a good explanation of the significant negative correlation of LIWC category tentative (represents words such as luck, may, perhaps) and retweet behavior."}, {"heading": "PREDICTION MODELS", "text": "We attempted to build predictive models for response and retweet based on the psycholinguistic category features to understand their predictive power. We performed both regression analysis and a classification study using WEKA [19], a widely used machine learning toolkit.\nFor regression analysis, we formulated linear regressions to predict response and retweet rates using LIWC measures. Thus, LIWC attributes were independent variables of the regression model and users\u2019 past_response_rate/ past_retweet_rate was the dependent variable. We tried a number of regression approaches, including simple linear regression, multiple linear regression, pace regression, logistic regression and SVM regression. We performed 10- fold cross validation. SVM regression slightly outperformed other algorithms.\nTable 3 presents the result of the regression analysis in terms of mean absolute error (MAE). We find that response can be predicted within 25.3%-29.9% MAE and retweet can be predicted within 23.6%-29.7% MAE. The best result is obtained when LIWC categories with significant correlations were used as independent variables in the regression model.\nIn the classification study, we used supervised binary machine learning algorithms to classify users with above-\nmedian levels of past_response_rate/past_retweet_rate. We experimented with a number of classifiers from WEKA [19], including naive Bayes, SVM, J48 (a decision-treebased classifier), Random Forest (an ensemble method that combines multiple decision trees).\nTable 4 shows the classification result of the best WEKA classifier in terms of AUC under 10-fold cross validation. We see that classifying high (above median) or low (below median) responders/retweeters from LIWC category based features can be done quite accurately. The best classification result is obtained when LIWC categories with significant correlations are used as features for the classification model."}, {"heading": "DISCUSSION", "text": "Our findings suggest several implications for social media interactions and personalized systems. Our work is the first study that reports correlations of word usage with different social engagements such as responses and retweets. Our work also discovers a set of psycholinguistic categories which have significant correlations with users\u2019 responses and retweets in Twitter. Such psycholinguistic categories are also shown to be useful to predict the likelihood of responses and retweets. Our findings also suggest that certain word use can predict such likelihoods. For instance, people who use angry words (such as anger, hate, kill) are less likely to respond, people who write about communication are more likely to respond, and people who write about positive feelings are more likely to retweet.\nPredictive models of response behavior from word usage can identify users who are more likely to respond to a question. Question-asking systems such as [12, 13] can use the recommendations/ranks produced from such predictions to send questions to potential answerers. This can increase response rates of such systems [12, 13]. Predictive models of retweet from word uses can identify users who are more willing to retweet a tweet. This can increase the rate of retweeting which is useful for various information propagation applications including viral marketing [3], propagating emergency news [17] and social/government/political campaigns (e.g., a campaign to support \u201cvaccination\u201d). For example, when antigovernment messages are spread in social media, government would want to spread counter messages to balance that effort and hence identify users who are more likely to retweet those counter messages. Our research to\npredict retweet behavior from word uses and identify potential retweeters is orthogonal to existing research on influence modeling and information diffusion [1] for the above applications.\nOur regression analysis confirms that such predictions can be done with reasonably low error (23.6-29.9% MAE). We also observed comparable prediction errors for predicting responses and retweets. Furthermore, our classification study shows that classifying high/low responders/retweeters can be done quite accurately (76-85% binary classification accuracy). In this study we did not explore ranking algorithms. However, learning-to-rank algorithms [9] may be useful to further harness the predictive information from word use.\nBased on this finding, we hope that other social behaviors such as mentions and follow behavior on Twitter or liking on Facebook may be predictable from word uses. Predicting such interactions from word uses can be useful for followee recommendations [8] or recommending users to mention [18]. Moreover, we may explore word based activity prediction (such as usage of specific hashtag) for followers of a specific account within the context of a campaign [6]. In addition, a word-based predictive model for response can be useful to predict the potential responders in a questionasking forum."}, {"heading": "CONCLUSIONS", "text": "In this paper, we have presented a study on understanding how people with different word usage exhibit different social engagement behaviors through an analysis of responses and retweets on Twitter. We conducted psycholinguistic analysis from word usage and found certain psycholinguistic categories have significant correlations with such social engagement behavior. In addition, our findings suggest that a few psycholinguistic categories share common characteristics for both responding and retweeting behavior. We have built predictive models of social engagement behaviors from the psycho-linguistic category features and demonstrated that our models are reasonably accurate to predict such social engagement behaviors.\nIn future, we would like to extend our analytics to other social media platforms, verify the generality of the findings with other forms of social engagement, and continue deeper investigation of predictive models for social engagement based on word uses."}], "references": [{"title": "The role of social network in information diffusion", "author": ["Bakshy.E", "Rosenm", "I. Marlow.C. Adamic. L"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Tweet, Tweet, Retweet: Conversational Aspects of Retweeting on Twitter", "author": ["Boyd", "S.D. Golder", "G. Lotan"], "venue": "In Proc. HICSS", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Social ties and word-of-mouth referral behavior", "author": ["J. Brown", "P. Reinegan"], "venue": "Journal of Consumer Research", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1987}, {"title": "Classifying Political Orientation on Twitter: It\u2019s Not Easy", "author": ["R. Cohen", "D. Ruths"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Finding Question-Answer Pairs from Online Forums", "author": ["Cong", "L.G. Wang", "C. Lin", "Y Song", "Y. Sun"], "venue": "In Proc. SIGIR", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Why You Are More Engaged: Factors Influencing Twitter Engagement", "author": ["Chen", "P.J. Pirolli"], "venue": "In Proc. ICWSM", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Predicting Personality from Twitter", "author": ["Golbeck", "C.J. Robles", "M. Edmondson", "K. Turner"], "venue": "In Proc. IEEE SocialCom", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Recommending twitter users to follow using content and collaborative filtering approaches", "author": ["Hannon", "M.J. Bennet", "B. Smith"], "venue": "In Proc. RecSys", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Learning to rank for information retrieval", "author": ["T.Y. Liu"], "venue": "Foundations and Trends in Information Retrieval,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Recommending Targeted Strangers from Whom to Solicit Information in Twitter", "author": ["Mahmud", "J. Zhou", "N.M. Megiddo", "J. Nichols", "C. Drews"], "venue": "Proc.IUI", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Words Mark the Nerds: Computational Models of Personality Recognition through language", "author": ["F. Mairesse", "M. Walker"], "venue": "In Proc. of CogSci", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "What Do People Ask Their Social Networks, and Why? A Survey Study of Status Message Q&A Behavior", "author": ["M. Morris", "J. Teevan", "K. Panovich"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Asking Questions of Targeted Strangers on Social Networks", "author": ["J. Nichols", "J.H. Kang"], "venue": "In Proc. CSCW", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval", "author": ["B. Pang", "L. Lee"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Is Twitter a Good Place for Asking Questions? A Characterization Study", "author": ["Paul", "S.A", "L. Hong", "E.H. Chi"], "venue": "In Proc.ICWSM Posters", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "Linguistic Inquiry and Word Count", "author": ["J.W. Pennebaker", "M.E. Francis", "R.J. Booth"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2001}, {"title": "Whom to Mention: Expand the Diffusion of Tweets by @Recommendation on Micro-blogging Systems", "author": ["Wang", "B. Wang", "C. Bu", "J. Chen", "W.V.C. Zhang", "D. Cai", "X. He"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Data mining: Practical machine learning tools and techniques, 3rd Edition", "author": ["I.H. Witten", "E. Frank", "M.A. Hall"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Personality in 100,000 words: A largescale analysis of personality and word usage among bloggers", "author": ["Yarkoni", "Tal"], "venue": "Journal of Research in Personality", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}], "referenceMentions": [{"referenceID": 11, "context": "There have been a number of research works that have explored users\u2019 tweeting activity, such as replies and retweets [12, 15, 2].", "startOffset": 117, "endOffset": 128}, {"referenceID": 14, "context": "There have been a number of research works that have explored users\u2019 tweeting activity, such as replies and retweets [12, 15, 2].", "startOffset": 117, "endOffset": 128}, {"referenceID": 1, "context": "There have been a number of research works that have explored users\u2019 tweeting activity, such as replies and retweets [12, 15, 2].", "startOffset": 117, "endOffset": 128}, {"referenceID": 12, "context": "Twitter has also been used to engage with strangers [13, 10].", "startOffset": 52, "endOffset": 60}, {"referenceID": 9, "context": "Twitter has also been used to engage with strangers [13, 10].", "startOffset": 52, "endOffset": 60}, {"referenceID": 5, "context": "has investigated users\u2019 engagement behavior in Twitter relating to a political movement [6].", "startOffset": 88, "endOffset": 91}, {"referenceID": 12, "context": "Understanding factors of users\u2019 social engagement can benefit social question answering [13, 10, 12, 15], viral marketing [3], and information diffusion [1], etc.", "startOffset": 88, "endOffset": 104}, {"referenceID": 9, "context": "Understanding factors of users\u2019 social engagement can benefit social question answering [13, 10, 12, 15], viral marketing [3], and information diffusion [1], etc.", "startOffset": 88, "endOffset": 104}, {"referenceID": 11, "context": "Understanding factors of users\u2019 social engagement can benefit social question answering [13, 10, 12, 15], viral marketing [3], and information diffusion [1], etc.", "startOffset": 88, "endOffset": 104}, {"referenceID": 14, "context": "Understanding factors of users\u2019 social engagement can benefit social question answering [13, 10, 12, 15], viral marketing [3], and information diffusion [1], etc.", "startOffset": 88, "endOffset": 104}, {"referenceID": 2, "context": "Understanding factors of users\u2019 social engagement can benefit social question answering [13, 10, 12, 15], viral marketing [3], and information diffusion [1], etc.", "startOffset": 122, "endOffset": 125}, {"referenceID": 0, "context": "Understanding factors of users\u2019 social engagement can benefit social question answering [13, 10, 12, 15], viral marketing [3], and information diffusion [1], etc.", "startOffset": 153, "endOffset": 156}, {"referenceID": 18, "context": "Prior research reported correlations of people\u2019s word usage with personality, and predicting personality from word usage [20, 7, 11].", "startOffset": 121, "endOffset": 132}, {"referenceID": 6, "context": "Prior research reported correlations of people\u2019s word usage with personality, and predicting personality from word usage [20, 7, 11].", "startOffset": 121, "endOffset": 132}, {"referenceID": 10, "context": "Prior research reported correlations of people\u2019s word usage with personality, and predicting personality from word usage [20, 7, 11].", "startOffset": 121, "endOffset": 132}, {"referenceID": 13, "context": "In addition, algorithms that use word-based features to predict other attributes, such as sentiment [14] and political polarization [4] also exist.", "startOffset": 100, "endOffset": 104}, {"referenceID": 3, "context": "In addition, algorithms that use word-based features to predict other attributes, such as sentiment [14] and political polarization [4] also exist.", "startOffset": 132, "endOffset": 135}, {"referenceID": 15, "context": "We measured word use in a number of psycholinguistic categories as defined by the Linguistic Inquiry and Word Count (LIWC) dictionary [16].", "startOffset": 134, "endOffset": 138}, {"referenceID": 9, "context": "On the practical side, our prediction models for predicting likelihood of replies and retweets from word usage can be used in wide varieties of scenarios such as recommending potential answerers for social question-answering [10, 12, 15], or potential information propagators for spreading alerts and warning messages in an emergency [17], viral marketing [3] and campaigns ranging from politics and government to social issues.", "startOffset": 225, "endOffset": 237}, {"referenceID": 11, "context": "On the practical side, our prediction models for predicting likelihood of replies and retweets from word usage can be used in wide varieties of scenarios such as recommending potential answerers for social question-answering [10, 12, 15], or potential information propagators for spreading alerts and warning messages in an emergency [17], viral marketing [3] and campaigns ranging from politics and government to social issues.", "startOffset": 225, "endOffset": 237}, {"referenceID": 14, "context": "On the practical side, our prediction models for predicting likelihood of replies and retweets from word usage can be used in wide varieties of scenarios such as recommending potential answerers for social question-answering [10, 12, 15], or potential information propagators for spreading alerts and warning messages in an emergency [17], viral marketing [3] and campaigns ranging from politics and government to social issues.", "startOffset": 225, "endOffset": 237}, {"referenceID": 2, "context": "On the practical side, our prediction models for predicting likelihood of replies and retweets from word usage can be used in wide varieties of scenarios such as recommending potential answerers for social question-answering [10, 12, 15], or potential information propagators for spreading alerts and warning messages in an emergency [17], viral marketing [3] and campaigns ranging from politics and government to social issues.", "startOffset": 356, "endOffset": 359}, {"referenceID": 11, "context": "5% as reported in [12]) questions asked on social network sites contained a question (?) mark.", "startOffset": 18, "endOffset": 22}, {"referenceID": 3, "context": "Also a rule-based method of using only question (?) mark to identify question in online content achieves more than 97% precision in detecting questions [4].", "startOffset": 152, "endOffset": 155}, {"referenceID": 15, "context": "PSYCHO-LINGUISTIC ANALYSIS FROM TEXT We measured word uses with the Linguistic Inquiry and Word Count (LIWC) 2001 dictionary [16].", "startOffset": 125, "endOffset": 129}, {"referenceID": 15, "context": "LIWC is the most commonly used language analysis tool for investigating the relation between word use and psychological variables [16].", "startOffset": 130, "endOffset": 134}, {"referenceID": 15, "context": "LIWC 2001 defines over 70 different categories, each of which contains several dozens to hundreds of words [16].", "startOffset": 107, "endOffset": 111}, {"referenceID": 17, "context": "We performed both regression analysis and a classification study using WEKA [19], a widely used machine learning toolkit.", "startOffset": 76, "endOffset": 80}, {"referenceID": 17, "context": "We experimented with a number of classifiers from WEKA [19], including naive Bayes, SVM, J48 (a decision-treebased classifier), Random Forest (an ensemble method that combines multiple decision trees).", "startOffset": 55, "endOffset": 59}, {"referenceID": 11, "context": "Question-asking systems such as [12, 13] can use the recommendations/ranks produced from such predictions to send questions to potential answerers.", "startOffset": 32, "endOffset": 40}, {"referenceID": 12, "context": "Question-asking systems such as [12, 13] can use the recommendations/ranks produced from such predictions to send questions to potential answerers.", "startOffset": 32, "endOffset": 40}, {"referenceID": 11, "context": "This can increase response rates of such systems [12, 13].", "startOffset": 49, "endOffset": 57}, {"referenceID": 12, "context": "This can increase response rates of such systems [12, 13].", "startOffset": 49, "endOffset": 57}, {"referenceID": 2, "context": "This can increase the rate of retweeting which is useful for various information propagation applications including viral marketing [3], propagating emergency news [17] and social/government/political campaigns (e.", "startOffset": 132, "endOffset": 135}, {"referenceID": 0, "context": "predict retweet behavior from word uses and identify potential retweeters is orthogonal to existing research on influence modeling and information diffusion [1] for the above applications.", "startOffset": 157, "endOffset": 160}, {"referenceID": 8, "context": "However, learning-to-rank algorithms [9] may be useful to further harness the predictive information from word use.", "startOffset": 37, "endOffset": 40}, {"referenceID": 7, "context": "Predicting such interactions from word uses can be useful for followee recommendations [8] or recommending users to mention [18].", "startOffset": 87, "endOffset": 90}, {"referenceID": 16, "context": "Predicting such interactions from word uses can be useful for followee recommendations [8] or recommending users to mention [18].", "startOffset": 124, "endOffset": 128}, {"referenceID": 5, "context": "Moreover, we may explore word based activity prediction (such as usage of specific hashtag) for followers of a specific account within the context of a campaign [6].", "startOffset": 161, "endOffset": 164}], "year": 2014, "abstractText": "We present a study to analyze how word use can predict social engagement behaviors such as replies and retweets in Twitter. We compute psycholinguistic category scores from word usage, and investigate how people with different scores exhibited different reply and retweet behaviors on Twitter. We also found psycholinguistic categories that show significant correlations with such social engagement behaviors. In addition, we have built predictive models of replies and retweets from such psycholinguistic category based features. Our experiments using a real world dataset collected from Twitter validates that such predictions can be done with reasonable accuracy. Author", "creator": "Microsoft\u00ae Word 2010"}}}