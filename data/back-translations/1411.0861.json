{"id": "1411.0861", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Nov-2014", "title": "Using Linguistic Features to Estimate Suicide Probability of Chinese Microblog Users", "abstract": "If people at high risk of suicide can be identified via social media such as microblogs, it is possible to implement an active intervention system to save their lives. Based on this motivation, the current study administered the Suicide Probability Scale (SPS) to 1041 weibo users at Sina Weibo, a leading microblog service provider in China. Two NLP (Natural Language Processing) methods, the Chinese edition of Linguistic Inquiry and Word Count (LIWC) and Latent Dirichlet Allocation (LDA), are used to extract linguistic traits from the Sina Weibo data. We trained the prediction of models based on these two traits to estimate the likelihood of suicide based on linguistic traits. The results of the experiment suggest that LDA can find issues related to the likelihood of suicide and improve prediction performance.", "histories": [["v1", "Tue, 4 Nov 2014 11:06:01 GMT  (39kb,D)", "http://arxiv.org/abs/1411.0861v1", null]], "reviews": [], "SUBJECTS": "cs.SI cs.CL", "authors": ["lei zhang", "xiaolei huang", "tianli liu", "zhenxiang chen", "tingshao zhu"], "accepted": false, "id": "1411.0861"}, "pdf": {"name": "1411.0861.pdf", "metadata": {"source": "CRF", "title": "Using Linguistic Features to Estimate Suicide Probability of Chinese Microblog Users", "authors": ["Lei Zhang", "Xiaolei Huang", "Tianli Liu", "Zhenxiang Chen", "Tingshao Zhu"], "emails": [], "sections": [{"heading": null, "text": "Keywords: suicidal ideation, topic model, LIWC, linguistic features, microblog"}, {"heading": "1 Introduction", "text": "Along with the wide spread of Sina Weibo, the leading microblog website in China, more and more people are willing to express their thoughts and emotions on the Internet. The messages they post have the potential to reveal their psychological indexes like suicidal ideation with or without intension. In this paper we proposed a task that predict the suicidal ideation of Sina Weibo users. By doing that, the group with high probability to commit suicide can be identified and lives may be saved by intervention.\nFirst, we collect information both on suicidal ideation and messages of Sina Weibo users. Suicidal ideation is measured by Suicide Probability Scale(SPS), a widely used psychological scale. Messages are downloaded with a crawler. Second, Linguistic Inquiry and Word Count (LIWC) and Latent Dirichlet Allocation\nar X\niv :1\n41 1.\n08 61\nv1 [\ncs .S\nI] 4\nN ov\n2 (LDA) are applied to messages to extract features. Then we build a supervised machine learning model to predict SPS score. The major contributions we made are:\n\u2013 This is the first large scale suicide probability detection study on social media users. \u2013 Consistent with findings of previous studies, our study results suggested that topics extracted from texts can reveal more information than LIWC lexicon. \u2013 We compared the predictive power of trained topics with inferred topics. The inferred topics have the equal, even higher, predictive power than trained topics. On the other hand, inferred topics are more reusable than trained topics."}, {"heading": "2 Related Work", "text": ""}, {"heading": "2.1 Sensing Suicidal Ideation", "text": "Hotline service and face-to-face diagnose are two effective methods for suicide intervention, but both have limitations in lacking of initiative. Mental health professionals are encouraged to contact with the high-risk group of suicide users, but with low efficiency.\nEnlightened by the phenomenon that many people post suicide notes on the Internet, online suicidal ideation sensation shows out an effective way of proactive suicide defense. Even though it is not yet clear to what extent suicide notes on social networks produce bad influence or even actually induce copycat suicides [18], the suicide intervention of network users is a promising way to save lives. To our knowledge, there are only two studies which are focused on detecting suicidal ideation on the Internet. Silenzio proposed a method to identify hard-to-reach population who reported high rates of suicide ideation [20]. Jared et al. made a more straightforward progress to create a message filter on Twitter using words and phrases created from suicide risk factors [12].\nIn addition, there are some similar studies which sense negative emotions related to psychopathy or mental health: Wald predict Twitter users score in the top 1.4 percent on psychopathy [22] using public visible information on Twitter. Although the accuracy several algorithms achieved are not good enough to replace diagnosis, still the research can play the effect of early warning."}, {"heading": "2.2 Predict Psychological Indexes with Social Network", "text": "In recent years, it becomes a research focus using social network data to predict psychological indexes automatically. Psychological indexes that had been well studied included personality, mental health, subjective well-being and so on.\nGolbeck et al. build predictive models on both Twitter and Facebook [8,10] .The information they collected from two websites involves language features, personal info, activities and preferences, internal website statistics, composite features, structural and so on. Then Sibel and Golbeck proposed a comparative\n3 study about predicting personality with social behavior [1]. The latest progress of theirs is that with the follower connections in the Twitter network, they computed the political preferences of an organization\u2019s Twitter followers [9].\nA solid predict model requires large scale data, that\u2019s why Kosinski et al. made such a great effort that they collected more than 6,000,000 test results together with more than 4,000,000 individual Facebook profiles. With the help of large scale data, they create a Users-Likes matrix to predict a wide range of people\u2019s personal attributes, ranging from sexual orientation to Big-Five personality [14]. Quercia map the psycho-score from Facebook to Twitter and create a predictive model on Twitter [16]. Schwartz et al. extracted words, phrases and topics from the same dataset and proposed the open-vocabulary approach to predict age, gender and personality [19].\nSocial networks in non-English speaking country are also proved to have the predictive power to psychological indexes. Bai predict personality on both RenRen and Sina Weibo [2,3]. Hao predict subjective well-being on Sina Weibo [11]."}, {"heading": "2.3 Linguistic Feature Extraction", "text": "Dictionary based methods are generally used by psychologists to analyze people\u2019s linguistic differences. For example, a positive emotion words dictionary might contains words like \u201chappy\u201d, \u201cgood\u201d, \u201clove\u201d, \u201cnice\u201d and \u201csweet\u201d. Counting the frequency of positive emotion words used by introverts and extroverts provides psychologists a quantitative result that distinguish two kinds of people on their linguistic differences. Linguistic Inquiry and Word Count (LIWC) is a handcrafted dictionary employed in social psychology studies which has been widely used [15]. Consider \u201cpositive emotion\u201d is only one category in our example, the 2007 version of LIWC provides 64 categories to cover a wide range of human linguistic features. So for every document we are interested in, LIWC can provide 64 features to analysis for researchers.\nTopic models are a series of algorithms to uncover the salient information lay behind document collections. Among these algorithms, the unsupervised algorithm Latent Dirichlet Allocation (LDA) which proposed by David Blei on 2003 [4] made topic models even more well known. The results of LDA are two matrixes, one is document-topic matrix and the other topic-term matrix. People can get to know the possible meaning of each topic by viewing the top ranked words estimated for the topic in the topic-term matrix. Just like the 64 features, the document-topic matrix provides similar features only without category names (number of topics can be seen as category name but it is not intuitively meaningful). Topic models can help us developing new ways to summarize large archives of texts and predicting specific features of users or the messages themselves.\n4"}, {"heading": "3 Methods", "text": ""}, {"heading": "3.1 Data Collection", "text": "Sina Weibo is the biggest microblog website in China. During May and Jun 2014, 1038 Sina Weibo users are recruited to complete Suicide Probability Scale (SPS) [6]. The SPS consists of four sub-scales with eight items in each sub-scale. The final score of SPS is the sum of all the four parts.\nThe participants who complete the scale can get paid for 30 Chinese yuan. The age of participants range from 14 to 63 and the average value is 24. The gender of participants is not evenly distributed that in totally 647 women and 391 men involved in the test. Figure1 shows age and gender distribution of all the participants.\nTo associate the score to Sina Weibo users, we create a crawler program to download participants\u2019 recent 2000 messages on the Sina Weibo (download all the messages if there are less than 2000 messages). Figure 2 shows the distribution of the number of messages per user.\nTo ensure the reliability of SPS score, we excluded the users who answered one question using less than 2 seconds or more than 10 seconds. Users with less than 20KB texts were also excluded, because a small amount of text are not likely reveal psycho-information of users. Our final analytic sample included 697 Sina Weibo Users."}, {"heading": "3.2 Text Process", "text": "The length of messages on microblog are always restricted. Sina Weibo allow users post less than 140 Chinese characters each time. Even so, Sina Weibo is a very good source of text for web content mining because all the messages\nare publicly visible and the amount is huge. LWIC and topic models are used widely on Facebook status updates and Twitter messages which are all written in English. On Chinese corpus like Sina Weibo messages, the process details and their performance remains questions.\nPreprocess. Firstly, we removed some Sina Weibo specific marks (like retweet marks, hashtags) and the words don\u2019t speak by the author (like retweets, replies). Then a segmentor is used [5], as Chinese words are not separated by default. The segment model of the segmentor is trained by manual segmented Sina Weibo sentences. After segmenting, we removed the stop words and single words (consider the express unit of Chinese).\nLIWC. The dictionary we used is a revised and improved version of the original LIWC which fit for simplified Chinese [7]. This simplified Chinese version extended the existing 64 categories to 88 categories. To make the LIWC features normalized, the counts of every categories are divided by the document length for each document.\nTopic Model. We use an implementation of LDA algorithm provided by the Mallet toolkit. Aggregating all the messages from a user as a single document allows us to compute topics at user level. It can be considered as an application of the author-topic model [21]. Different from LIWC, we remove all the single words from segmented texts before topic modelling because single word is not the basic ideographic unit in Chinese.\nThere are two strategies to get the documents-topics matrix. The first strategy is simply train all the 697 documents and use the post-estimated probability as features. As shown in figure 3, from 10 to 300, a large range of number of topics are empirically used. All other parameters are set as their default. The second strategy is to train a model with another corpus then infer the 697 documents. Consider the trades of suicidal ideation may be rare, the chance to estimate a topics about suicidal ideation may be little. To maximum this chance\n6 on our own minds, we trained 12 models (with the same number of topics of the first strategy) which only include texts from high suicidal ideation participants. The high suicidal ideation group involves 107 participants whose SPS scores are higher than the sum of the mean value and one standard deviation. Additionally appended to the corpus, there are 30 more documents from Sina Weibo users that are confirmed to have committed suicide. At last, the topics of texts from 697 users with SPS score are inferred with the pre-trained model trained by 137 documents."}, {"heading": "3.3 Predict Model", "text": "We use caret package in R to conduct linear regression analysis with stepwise selection [13]. In building predict model, text features (LIWC features and topics features) are independent variable and SPS score is dependent variable. Caret creates a unified interface for modeling and prediction which contains a variety of \u201chelper\u201d functions and classes. The metric we use to evaluation uncertainty of predicted score is RMSE (Root Mean Square Error) [23]."}, {"heading": "4 Results", "text": "With the help of caret package, a 10-fold cross validation is used to take most advantage of data and avoid potential over-fitting."}, {"heading": "4.1 Predictive Power of LIWC", "text": "A correlation analysis is run for each language feature of LIWC. The dimension with highest correlation coefficient of 0.13, is \u201cinhibition\u201d words (e.g., \u201cblock\u201d, \u201cconstrain\u201d, \u201cstop\u201d in English). The second highest correlated dimension is \u201ccognitive processes\u201d (e.g., \u201ccause\u201d, \u201cknow\u201d, \u201cought\u201d in English), with the correlation coefficient of 0.09. Both of the correlations are significant at p < 0.01 level.\nBecause we have only one parameter to predict, its RMSE is 15.43. Using this number as the baseline value, we can compare it with results topics model obtained."}, {"heading": "4.2 Predictive Power of Topic Model", "text": "As is discussed in chapter 3.2, we run topic features in two different way. Result of trained topics As is shown in figure 3 we experimented with LDA using 10, 20, ..., 100, 200 and 300 topics. When the number of topics is no more than 70, RMSE fluctuated only slightly (from 11.68 to 11.97). When a bigger number is set to LDA, RMSE increased obviously (top to 15.06). It indicates that when the granularity of topics are too small, the topics are more likely fail to capture the clue of suicidal ideation. The best performed RMSE is 11.68 when number of topics is set to 70, which is much better than the\nresult of LIWC (15.43). It also confirmed the earlier research that topic features outperform LIWC features on predictive power [17,19]\nResult of inferred topics As presented in Figure4, we plot RMSE with the same number of topics set by trained topics strategy. When the number of topics is less than 70, RMSE fluctuated slightly and performed almost equally with trained topics. On a bigger number of topics, inferred topics performed still steadily which was different from trained topics. The reason may be the small training set with high suicidal ideation is easier to estimate topics related to suicidal ideation.\nWe also inspect the number of significantly correlated topics and the maximum correlation coefficient of single topic. As shown in figure 5, along with the increasing of number of topics, the number of significantly correlated topics also increase but the maximum of correlation coefficient didn\u2019t show in the models with highest number of topics. We are also curious about how to estimate a topic which have correlation as high as possible. From table 1, it seems a suicide correlated topic has nothing to do with number of topics and whether it\u2019s trained or inferred."}, {"heading": "4.3 Predictive Power of LIWC+Topic Model", "text": "As is shown in Table 2, we see that LIWC didn\u2019t add much value on predictive power for SPS score. When we combine LIWC and trained topics as features, predict model was improved with regard to big number of topics compared with using trained topics only. When we combine LIWC and inferred topics as\n9\nfeatures, predict model was not improved. In general, only inferred topics can achieve highest performance no matter with or without help from LIWC."}, {"heading": "5 Conclusion", "text": "In this paper, we established models to detect Sina Weibo users\u2019 suicidal ideation using two different NLP methods. The best RMSE value achieved with stepwise linear regression is around 11 at 1-32 scale. The study results suggested that suicidal ideation is predictable. But the predictive accuracy need to be improved. Furthermore, as trades of suicidal ideation may be rare, innovatively we attempt topics inferred from a model trained by high suicidal ideation group. The inferred\n10\ntopics reached equal or higher quota in the predict task. The same method is worth trying on other predict tasks. Moreover, some conclusions made by previous works are confirmed in our study."}, {"heading": "6 Acknowledgments", "text": "The authors gratefully acknowledge the generous support from National Hightech R&D Program of China (2013AA01A606), National Basic Research Program of China(973 Program 2014CB744600), Key Research Program of CAS (KJZD-EW-L04) and Strategic Priority Research Program (XDA06030800) from Chinese Academy of Sciences."}], "references": [{"title": "Predicting personality with social behavior: a comparative study", "author": ["S. Adal\u0131", "J. Golbeck"], "venue": "Social Network Analysis and Mining 4(1), 1\u201320", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Determining personality traits from renren status usage behavior", "author": ["S. Bai", "R. Gao", "T. Zhu"], "venue": "Computational Visual Media, pp. 226\u2013233. Springer", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Predicting big five personality traits of microblog users", "author": ["S. Bai", "B. Hao", "A. Li", "S. Yuan", "R. Gao", "T. Zhu"], "venue": "Web Intelligence (WI) and Intelligent Agent Technologies (IAT), 2013 IEEE/WIC/ACM International Joint Conferences on. vol. 1, pp. 501\u2013508", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "J. Mach. Learn. Res", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "Ltp: A chinese language technology platform", "author": ["W. Che", "Z. Li", "T. Liu"], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics: Demonstrations. pp. 13\u201316. Association for Computational Linguistics", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Suicide probability scale", "author": ["J. Cull", "W. Gill"], "venue": "Western Psychological Services, Los Angeles, CA. The Suicide Probability Scale is a proprietary instrument published by Western Psychological Services 12031, 1997\u20132005", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1982}, {"title": "Developing simplified chinese psychological linguistic analysis dictionary for microblog", "author": ["R. Gao", "B. Hao", "H. Li", "Y. Gao", "T. Zhu"], "venue": "Brain and Health Informatics, pp. 359\u2013368. Springer", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Predicting personality from twitter", "author": ["J. Golbeck", "C. Robles", "M. Edmondson", "K. Turner"], "venue": "Privacy, Security, Risk and Trust (PASSAT) and 2011 IEEE Third Inernational Conference on Social Computing (SocialCom), 2011 IEEE Third International Conference on. pp. 149\u2013156", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "A method for computing political preference among twitter followers", "author": ["J. Golbeck", "D. Hansen"], "venue": "Social Networks 36(0),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Predicting personality with social media", "author": ["J. Golbeck", "C. Robles", "K. Turner"], "venue": "Extended Abstracts on Human Factors in Computing Systems", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Sensing subjective well-being from social media", "author": ["B. Hao", "L. Li", "R. Gao", "A. Li", "T. Zhu"], "venue": "arXiv preprint arXiv:1403.3807", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Tracking suicide risk factors through twitter in the us", "author": ["J. Jashinsky", "S.H. Burton", "C.L. Hanson", "J. West", "C. Giraud-Carrier", "M.D. Barnes", "T. Argyle"], "venue": "Crisis: The Journal of Crisis Intervention and Suicide Prevention 35(1), 51", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "http://CRAN.R-project.org/package=caret, r package version", "author": ["M.K.C. Jed Wing", "S. Weston", "A. Williams", "C. Keefer", "A. Engelhardt", "T. Cooper", "Z. Mayer"], "venue": "R Core Team: caret: Classification and Regression Training", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Private traits and attributes are predictable from digital records of human behavior", "author": ["M. Kosinski", "D. Stillwell", "T. Graepel"], "venue": "Proceedings of the National Academy of Sciences", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Linguistic inquiry and word count: Liwc 2001", "author": ["J.W. Pennebaker", "M.E. Francis", "R.J. Booth"], "venue": "Mahway: Lawrence Erlbaum Associates 71, 2001", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2001}, {"title": "Our twitter profiles, our selves: Predicting personality with twitter", "author": ["D. Quercia", "M. Kosinski", "D. Stillwell", "J. Crowcroft"], "venue": "Privacy, Security, Risk and Trust (PASSAT) and 2011 IEEE Third Inernational Conference on Social Computing (SocialCom), 2011 IEEE Third International Conference on. pp. 180\u2013185", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Using topic modeling to improve prediction of neuroticism and depression in college students", "author": ["P. Resnik", "A. Garron", "R. Resnik"], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. pp. 1348\u20131353", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Suicide announcement on facebook", "author": ["T.D. Ruder", "G.M. Hatch", "G. Ampanozi", "M.J. Thali", "N. Fischer"], "venue": "Crisis: The Journal of Crisis Intervention and Suicide Prevention 32(5), 280\u2013282", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Personality, gender, and age in the language of social media: The open-vocabulary approach", "author": ["H.A. Schwartz", "J.C. Eichstaedt", "M.L. Kern", "L. Dziurzynski", "S.M. Ramones", "M. Agrawal", "A. Shah", "M. Kosinski", "D. Stillwell", "M.E.P. Seligman", "L.H. Ungar"], "venue": "PLoS ONE 8(9), e73791", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Connecting the invisible dots: Reaching lesbian, gay, and bisexual adolescents and young adults at risk for suicide through online social networks", "author": ["V. Silenzio", "P.R. Duberstein", "W. Tang", "N. Lu", "X. Tu", "C.M. Homan"], "venue": "Social Science & Medicine 69(3), 469\u2013474", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Probabilistic author-topic models for information discovery", "author": ["M. Steyvers", "P. Smyth", "M. Rosen-Zvi", "T. Griffiths"], "venue": "Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. pp. 306\u2013315. ACM", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2004}, {"title": "Using twitter content to predict psychopathy", "author": ["R. Wald", "T.M. Khoshgoftaar", "A. Napolitano", "C. Sumner"], "venue": "Machine Learning and Applications (ICMLA), 2012 11th International Conference on. vol. 2, pp. 394\u2013401. IEEE", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Evaluation metrics for recommender systems", "author": ["Y.X. Zhu", "L.Y. Lu"], "venue": "Journal of University of Electronic Science and Technology of China 41(2), 163\u2013175", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 17, "context": "Even though it is not yet clear to what extent suicide notes on social networks produce bad influence or even actually induce copycat suicides [18], the suicide intervention of network users is a promising way to save lives.", "startOffset": 143, "endOffset": 147}, {"referenceID": 19, "context": "Silenzio proposed a method to identify hard-to-reach population who reported high rates of suicide ideation [20].", "startOffset": 108, "endOffset": 112}, {"referenceID": 11, "context": "made a more straightforward progress to create a message filter on Twitter using words and phrases created from suicide risk factors [12].", "startOffset": 133, "endOffset": 137}, {"referenceID": 21, "context": "4 percent on psychopathy [22] using public visible information on Twitter.", "startOffset": 25, "endOffset": 29}, {"referenceID": 7, "context": "build predictive models on both Twitter and Facebook [8,10] .", "startOffset": 53, "endOffset": 59}, {"referenceID": 9, "context": "build predictive models on both Twitter and Facebook [8,10] .", "startOffset": 53, "endOffset": 59}, {"referenceID": 0, "context": "study about predicting personality with social behavior [1].", "startOffset": 56, "endOffset": 59}, {"referenceID": 8, "context": "The latest progress of theirs is that with the follower connections in the Twitter network, they computed the political preferences of an organization\u2019s Twitter followers [9].", "startOffset": 171, "endOffset": 174}, {"referenceID": 13, "context": "With the help of large scale data, they create a Users-Likes matrix to predict a wide range of people\u2019s personal attributes, ranging from sexual orientation to Big-Five personality [14].", "startOffset": 181, "endOffset": 185}, {"referenceID": 15, "context": "Quercia map the psycho-score from Facebook to Twitter and create a predictive model on Twitter [16].", "startOffset": 95, "endOffset": 99}, {"referenceID": 18, "context": "extracted words, phrases and topics from the same dataset and proposed the open-vocabulary approach to predict age, gender and personality [19].", "startOffset": 139, "endOffset": 143}, {"referenceID": 1, "context": "Bai predict personality on both RenRen and Sina Weibo [2,3].", "startOffset": 54, "endOffset": 59}, {"referenceID": 2, "context": "Bai predict personality on both RenRen and Sina Weibo [2,3].", "startOffset": 54, "endOffset": 59}, {"referenceID": 10, "context": "Hao predict subjective well-being on Sina Weibo [11].", "startOffset": 48, "endOffset": 52}, {"referenceID": 14, "context": "Linguistic Inquiry and Word Count (LIWC) is a handcrafted dictionary employed in social psychology studies which has been widely used [15].", "startOffset": 134, "endOffset": 138}, {"referenceID": 3, "context": "Among these algorithms, the unsupervised algorithm Latent Dirichlet Allocation (LDA) which proposed by David Blei on 2003 [4] made topic models even more well known.", "startOffset": 122, "endOffset": 125}, {"referenceID": 5, "context": "During May and Jun 2014, 1038 Sina Weibo users are recruited to complete Suicide Probability Scale (SPS) [6].", "startOffset": 105, "endOffset": 108}, {"referenceID": 4, "context": "Then a segmentor is used [5], as Chinese words are not separated by default.", "startOffset": 25, "endOffset": 28}, {"referenceID": 6, "context": "The dictionary we used is a revised and improved version of the original LIWC which fit for simplified Chinese [7].", "startOffset": 111, "endOffset": 114}, {"referenceID": 20, "context": "It can be considered as an application of the author-topic model [21].", "startOffset": 65, "endOffset": 69}, {"referenceID": 12, "context": "We use caret package in R to conduct linear regression analysis with stepwise selection [13].", "startOffset": 88, "endOffset": 92}, {"referenceID": 22, "context": "The metric we use to evaluation uncertainty of predicted score is RMSE (Root Mean Square Error) [23].", "startOffset": 96, "endOffset": 100}, {"referenceID": 16, "context": "It also confirmed the earlier research that topic features outperform LIWC features on predictive power [17,19] Result of inferred topics As presented in Figure4, we plot RMSE with the same number of topics set by trained topics strategy.", "startOffset": 104, "endOffset": 111}, {"referenceID": 18, "context": "It also confirmed the earlier research that topic features outperform LIWC features on predictive power [17,19] Result of inferred topics As presented in Figure4, we plot RMSE with the same number of topics set by trained topics strategy.", "startOffset": 104, "endOffset": 111}], "year": 2014, "abstractText": "If people with high risk of suicide can be identified through social media like microblog, it is possible to implement an active intervention system to save their lives. Based on this motivation, the current study administered the Suicide Probability Scale(SPS) to 1041 weibo users at Sina Weibo, which is a leading microblog service provider in China. Two NLP (Natural Language Processing) methods, the Chinese edition of Linguistic Inquiry and Word Count (LIWC) lexicon and Latent Dirichlet Allocation (LDA), are used to extract linguistic features from the Sina Weibo data. We trained predicting models by machine learning algorithm based on these two types of features, to estimate suicide probability based on linguistic features. The experiment results indicate that LDA can find topics that relate to suicide probability, and improve the performance of prediction. Our study adds value in prediction of suicidal probability of social network users with their behaviors.", "creator": "LaTeX with hyperref package"}}}