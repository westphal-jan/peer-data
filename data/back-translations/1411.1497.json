{"id": "1411.1497", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Nov-2014", "title": "The Spaces of Data, Information, and Knowledge", "abstract": "We examine the data space $D $of any dataset $X $and explain how functions and relationships over $D $are defined. From $D $and for a specific domain $\\ Delta $we construct the information space $I $of $X $by interpreting variables, functions and explicit relationships over $D $in $\\ Delta $and incorporating other relationships that $D $implies under the interpretation in $\\ Delta $. Then we construct from $I $the knowledge space $K $of $X $as the product of two spaces $K _ T $and $K _ P $, where $K _ T $is derived from $I $by using the production principle to generalize production relationships to quantified relationships, the deduction principle to generate new relationships, and standard mechanisms for validating relationships and $K _ P $is the space of specifications of methods with operational statements that are in $K _ T defined by the topological information provided by the following construct of the following topological spaces:", "histories": [["v1", "Thu, 6 Nov 2014 04:50:45 GMT  (14kb)", "http://arxiv.org/abs/1411.1497v1", "14 pages"]], "COMMENTS": "14 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["xiaoyu chen", "dongming wang"], "accepted": false, "id": "1411.1497"}, "pdf": {"name": "1411.1497.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Xiaoyu Chen", "Dongming Wang"], "emails": ["franknewchen@gmail.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n41 1.\n14 97\nv1 [\ncs .A\nI] 6\nN ov\n2 01\n4\nWe study the data space D of any given data set X and explain how functions and relations are defined over D. From D and for a specific domain \u2206 we construct the information space I of X by interpreting variables, functions, and explicit relations over D in \u2206 and by including other relations that D implies under the interpretation in \u2206. Then from I we build up the knowledge space K of X as the product of two spaces KT and KP , where KT is obtained from I by using the induction principle to generalize propositional relations to quantified relations, the deduction principle to generate new relations, and standard mechanisms to validate relations and KP is the space of specifications of methods with operational instructions which are valid in KT . Through our construction of the three topological spaces the following key observation is made clear: the retrieval of information from the given data set for \u2206 consists essentially in mining domain objects and relations, and the discovery of knowledge from the retrieved information consists essentially in applying the induction and deduction principles to generate propositions, synthesizing and modeling the information to generate specifications of methods with operational instructions, and validating the propositions and specifications. Based on this observation, efficient approaches may be designed to discover profound knowledge automatically from simple data, as demonstrated by the result of our study in the case of geometry.\nKeywords data space, declarative knowledge, deduction principle, implied knowledge, induction principle, information retrieval, knowledge discovery, procedural knowledge, quantified relation"}, {"heading": "1 Introduction", "text": "With increasingly wide use of digital devices and networks, more and more scientific explorations and social activities are carried out electronically, where the involved objects, phenomena, and behaviors of interest are measured and presented in the form of data. Thus analyzing and modeling data, retrieving information from data, and discovering knowledge that data imply become essential tasks. In fact, data\naSKLSDE - School of Computer Science and Engineering, Beihang University, Beijing 100191, China. E-mail: franknewchen@gmail.com bLMIB - School of Mathematics and Systems Science, Beihang University, Beijing 100191, China cCentre National de la Recherche Scientifique, 3 rue Michel-Ange, 75794 Paris cedex 16, France\nmining, machine learning, information retrieval, and knowledge discovery are some of the directions of research and development which have been given high priority in various national programs [1]. Let us address three issues in more detail.\n(1) Data Management. Data are acquired, collected, and recorded in digital databases with respect to different aspects of concern, such as time, location, state, and relation, of observed objects. Data models and schemas need be well designed in order to provide manipulable structures for efficiently storing, retrieving, exchanging, and acting on data. Visualization techniques should be capable of representing the underling features and properties of data in the form of intuitive diagrams with dynamic animation. Data management techniques should be available as fundamental utilities in dealing with the activities of observation, measurement, and experiment. It becomes more and more difficult to process collections of complex data with large volume, high velocity of change, uncertain veracity, and variety of types, called big data [2], using traditional methodologies and existing database management tools. There is a need of substantially new ideas, techniques, approaches, and systems for the management of big data.\n(2) Information Retrieval. Information is implied in data and may be retrieved manually or mechanically through analyzing, modeling, computing, and learning. Valuable information depicts the essence of observed phenomena and can thus be used to predict the changing of the phenomena and to study the properties of the objects under observation. A large variety of methods, techniques, and tools have been developed in the fields of data mining, knowledge discovery, pattern recognition, and machine learning for retrieving information from data (see, e.g., the top 10 influential data mining algorithms identified by the research community [3] and ensemble methods of effectively combining multiple algorithms and techniques [4]), with applications to information dissemination and the analysis of crowd behaviors and social networks [5, 6, 7]. Current investigations tend to be more expertiseoriented and more problem-centered, as witnessed by the publications of a series of conference proceedings and journals. An integrated study of qualitative and quantitative methods from natural sciences with cognitive science, psychology, and human behaviors is likely to help enhance our understanding of information retrieval [8], hopefully resulting in revolutionary approaches for intelligent retrieval of information from big data.\n(3) Logical Reasoning. The discovery of scientific knowledge is inseparable from logical reasoning. The principle of induction points out how to formulate conjectures as to acquire knowledge based on experience of a few existing cases [9]. On the other hand, the inductive logic provides a less-than-certain inference mechanism of evidential support by using probability [10]. Holding a controversial view on the function of induction, Popper [11] argued that scientific theories are not inductively inferred from experience, nor is scientific experimentation carried out with a view to verifying or finally establishing the truth of theories; rather, all knowledge is\nprovisional, conjectural, hypothetical, disprovable rather than provable. In his view, scientific discovery is a deductive process in which scientists formulate hypotheses and theories that they test by deriving particular observable consequences, modify falsified theories based on empirical facts, and create new theories that corroborate the necessary predictions. Along this line of thought, Li [12] developed an operable revision calculus to deal with refutations and a logical framework for formalizing the process of scientific discovery.\nKnowledge may be discovered from data via information retrieval. To understand the process of knowledge discovery, one needs to study the properties of data, information, and knowledge and to clarify their relationship. Such studies are also necessary for the establishment of theoretical foundations for the sciences of data and knowledge. This paper presents the result of our initial study on what we call implied knowledge discovery by constructing three topological spaces for data, information, and knowledge. A key idea that is responsible for the richness of the constructed space of knowledge is to generate data-implied knowledge by applying meta-knowledge (notably the induction and deduction principles) and domain knowledge. We provide formal definitions for various concepts and theorems to describe features and relations of the three spaces and objects therein. According to the process of construction of the three spaces, efficient approaches may be designed to discover profound knowledge automatically from simple data. The interested reader is encouraged to consult [13] for one such approach, which is capable of generating nontrivial geometric theorems from images of diagrams."}, {"heading": "2 The Space of Data", "text": "We start by recalling a few standard concepts from the area of data analysis.\nDefinition 2.1 (Data point). A data point is a set of one or more measurements on a single member of a set of observed objects.\nDefinition 2.2 (Data set). A data set is a collection of data points.\nLet X be any given finite nonempty data set.\nDefinition 2.3 (Data space). The data space D of X is the set X of points endowed with a family \u03c4 of subsets of X such that (1) both \u2205 and X are elements of \u03c4 , (2) any union of elements of \u03c4 is an element of \u03c4 , and (3) any intersection of finitely many elements of \u03c4 is an element of \u03c4 . Each element in \u03c4 is called an open set and \u03c4 is called the data structure of D.\nTheorem 2.1. The space D defined above is a finite topological space.\nProof. By definition of topology [14], it can be easily proved that \u03c4 is a topology on X . Thus, D is a topological space for which there are only finitely many data points.\nLet n be a positive integer and T \u2282 \u03c4n.\nDefinition 2.4 (Data Function). A data function is a map\nf : T 7\u2192 \u03c4 (t1, . . . , tn) \u2192 f(t1, . . . , tn).\nDefinition 2.5 (Data Relation). A data relation is a map\nR : T 7\u2192 {true, false} (t1, . . . , tn) \u2192 R[t1, . . . , tn].\nFor n = 2, the relation R[t1, t2] is sometimes written as t1R t2.\nExample 2.1. Given t, s \u2208 \u03c4 , the data function intersection maps (t, s) to intersection(t, s), which is written usually as t \u2229 s. There are two kinds of data relations: propositional (without using variables, e.g., {3} \u2282 {3, 7}) and quantified (to represent a set of propositional relations, e.g., \u2200t \u2208 \u03c4 \u2203s \u2208 \u03c4 (t \u222a s = X)).\nFor any fixed data set X , one can define different data spaces with different topologies. One can also define different binary relations (called preorders) on X that are reflexive and transitive. For any preorder on X , there is a data space with topology \u03c4 such that every upper set U of X with respect to (i.e., if x \u2208 U and x y then y \u2208 U) is an open set of \u03c4 . Conversely, for any data space with topology \u03c4 , there is a preorder on X such that x y if x is in the closure of {y} in \u03c4 . Therefore, the binary relations are in one-to-one correspondence with the data spaces.\nIn what follows, we list some properties of data spaces which are useful for data analysis.\n(1) Compactness. Every data space is compact (because each open cover of it has a finite subcover).\n(2) Separability. For any data space D of X , if D is T1 (i.e., for every pair of distinct data points in D, each point has an open neighborhood not containing the other), then D must be discrete (i.e., the data structure of D is the power set of X).\n(3) Connectivity. A data space is connected if and only if the associated graph with respect to its corresponding preorder is path-connected.\n(4) Metrizablity. A data space is metrizable if and only if it is discrete.\nIf a data space ofX is metrizable, then one can introduce a metric on X as follows.\nDefinition 2.6 (Metric). A metric on X is a map d : X2 7\u2192 R (where R denotes the field of real numbers) which satisfies the following conditions: for all x, y, z \u2208 X , (1) d(x, y) > 0; (2) d(x, y) = 0 if and only if x = y; (3) d(x, y) = d(y, x); (4) d(x, z) 6 d(x, y) + d(y, z).\nDefinition 2.7 (Similarity). Two data points x and y in X are said to be \u01eb-similar, denoted as x \u223c\u01eb y, if d(x, y) 6 \u01eb, where d is a metric\n1 on X and \u01eb is a given threshold. If x and y are not \u01eb-similar, then we write x 6\u223c\u01eb y.\nDefinition 2.8 (Cluster). A subset C of X is called a cluster of X if\n(a) for any two data points x0, x \u2208 C, there exist x1, . . . , xn \u2208 C such that xi \u223c\u01eb xi\u22121 for i = 1, . . . , n and x \u223c\u01eb xn;\n(b) for any x \u2208 C and y \u2208 X \\ C, x 6\u223c\u01eb y,\nwhere \u01eb is a given threshold.\nObviously, any two clusters of X are disjoint. It is also easy to prove the following.\nTheorem 2.2. For any given finite data set X and threshold \u01eb, there are finitely many clusters C1, . . . , Cm such that X = C1 \u222a \u00b7 \u00b7 \u00b7 \u222a Cm.\nWhen X is a subset of the Euclidean space and d is the Euclidean distance, X can be converted into a graph by taking the points in X as its vertices and connections of proximate vertices as its edges. The obtained graph can be turned into a simplicial complex of X by gluing together simplices. The constructed simplicial complex is a topological space. Therefore, methods from algebraic topology can be used to study the simplicial complex of X (see [15] for more details).\nThe data structure of a data space, in which useful domain information is implied, plays an important role in depicting the features of the space."}, {"heading": "3 Domain and Interpretation", "text": "Let \u2206 be an arbitrary but fixed domain.\nExample 3.1. The data set X = {3, 7, 11, 23} has no meaning. It may be interpreted as a set of strings of characters, or a set of mathematical numbers, or a set of identifiers for different athletes.\n1When the metric is Euclidean distance, \u01eb-similarity measures the closeness of data points in X .\nDefinition 3.1 (Domain object). A domain object is an object of study that has clear meaning in \u2206.\nDefinition 3.2 (Domain function). A domain function is a function that is defined over a subdomain of \u2206 and has clear meaning in \u2206.\nDefinition 3.3 (Domain relation). A domain relation is a relation among domain objects that has clear meaning in \u2206.\nDefinition 3.4 (Propositional and quantified relation). A domain relation which does not involve any quantifier is called a propositional relation. A quantified relation is a relation which involves at least one of the quantifiers \u2200 and \u2203 to represent a set of propositional relations.2\nDomain functions and relations are introduced usually by definitions in the domain. There are two types of domain objects: primitive objects and derived objects. Primitive objects may be defined informally, while derived objects are defined through domain functions on primitive objects and already defined derived objects. Similarly, there are two types of domain relations: primitive relations and derived relations. The former may be defined informally, while the latter are defined through domain functions on primitive relations and already defined derived relations. To facilitate the study of the domain, let the set of primitive objects and relations be well chosen and then fixed.\nDefinition 3.5 (Operation). Let y = f(x1, . . . , xn) be a function defined over a subdomain \u03b4 of \u2206. For any given values x\u03041, . . . , x\u0304n \u2208 \u03b4, the evaluation f(x\u03041, . . . , x\u0304n) is called an operation in \u2206.\nDefinition 3.6 (Instruction). An instruction is a specification about where, when, and how to perform a sequence of operations in \u2206.\nDefinition 3.7 (Method). A method consists of a specification about what is given and what is the goal to be achieved and a sequence of instructions on how to achieve the goal step-by-step using what is given.\nLet D\u2217 be a set consisting of open sets of data space D as well as data functions and relations on the open sets.\nDefinition 3.8 (Interpretation). An interpretation in \u2206 is a map from D\u2217 to \u2206 that maps each open set of D to a domain object (or a set of domain objects) in \u2206, each data function in D\u2217 to a domain function in \u2206, and each data relation in D\u2217 to a domain relation in \u2206.\n2For the sake of convenience, we call any first-order logical formula over \u2206 a domain relation; so\na proposition is also a domain relation.\nDefinition 3.9 (Implied relation). Any set of domain relations in \u2206 which can be obtained from D\u2217 by means of interpretation in \u2206 is a set of D-implied relations. Furthermore, any set of domain relations in \u2206 which can be deduced from sets of D-implied relations is also a set of D-implied relations.\nTo retrieve information from X , one needs to mine domain objects and D-implied relations."}, {"heading": "4 The Space of Information", "text": "Definition 4.1 (Piece of information). A piece of information in \u2206 is a pair \u3008O,R\u3009, where O is a set of domain objects in \u2206 and R is a set of domain relations in \u2206 which involves the objects in O.\nExample 4.1. Let X in Example 3.1 be interpreted as a set X \u2032 = {3, 7, 11, 23} of mathematical numbers (i.e., \u2206 is mathematics). Then X \u2032 with the relations that (1) the average (which is a derived object in \u2206) of the numbers in X \u2032 is equal to 11 and (2) every number in X \u2032 is prime is a piece of information.\nEach piece of information can be presented in a standard mathematical structure (such as an ordered set, a table, a tree, or a graph).\nDefinition 4.2 (Implied information). Any piece of information in \u2206 which can be obtained from D by means of interpretation in \u2206 is a piece of D-implied information. Any piece of information in \u2206 which can be deduced from pieces of D-implied information is also a piece of D-implied information.\nPieces of D-implied information may be retrieved from D and thus from the given data set X interpreted in \u2206. To retrieve information from X , the domain \u2206 must be specified or detected.\nExample 4.2. Assume that in the domain of administration, two open sets of a data space are interpreted into Cd and Bd. Cd, together with relations involving elements of Cd, is interpreted as a piece of information Ci for China and Bd, together with relations involving elements of Bd, is interpreted as a piece of information Bi for Beijing. Then Ci and Bi, together with D-implied information involving elements of Cd and/or Bd, form a piece of information Ai for China and Beijing.\nAi may contain such relations as \u201cChina is a country,\u201d \u201cBeijing is a city of China,\u201d and \u201cBeijing is the capital of China.\u201d These relations are propositional and involve only the constants \u201cChina\u201d and \u201cBeijing\u201d (without variables).\nDefinition 4.3 (Information space). The information space I of X for \u2206 is the set S of pieces of D-implied information in \u2206 endowed with a topology \u03c4I on S. Here \u03c4I is called the information structure of I.\nThere are different topologies, such as cofinite topology and discrete topology, which can be defined on S. In particular, as deductive relation \u2192 on S (a \u2192 b means that b can be deduced from a where a, b \u2208 S) forms a preorder, a topology \u03c4\u2192 can thus be defined on S with respect to \u2192.\nAn information space I of X for \u2206 is said to be induced from a data space D of X if the information structure \u03c4I for I is constructed as follows:\n(a) if u \u2208 \u03c4I , then u is a piece of D-implied information;\n(b) if u, v \u2208 \u03c4I , then u \u2229 v \u2208 \u03c4I ;\n(c) if u, v \u2208 \u03c4I , then u \u222a v \u2208 \u03c4I .\nEach open set of an information space induced from a data space is a finite family of pieces of D-implied information with respect to the same set of objects in \u2206.\nInformation is not necessarily true. It becomes knowledge when validated. For example, when \u201cBeijing is the capital of China\u201d is validated, it becomes part of a knowledge object."}, {"heading": "5 The Space of Knowledge", "text": "Knowledge is formulated from information spaces by means of induction, deduction, synthesis, modeling, and validation.\nDefinition 5.1 (Induction principle [9]). The principle of induction is a law to extrapolate from given information (called premises) and predict things containing more information than the premises make available. Let each domain object in \u2206 be an instance of a concept or a class. Then the principle of induction may be stated as follows.\n(a) The greater the number of pieces of information in the form of \u3008{o1, o2, . . . , on}, R\u3009 is, where each oi is an instance of a class Ci, the more probable it is (if no piece of information of failure of the relation R is known) that the relation R holds among all the instances of Ci for 1 6 i 6 n.\n(b) Under the same circumstances, a sufficient number of pieces of information on the relation R among some instances of C1, . . . , Cn will make it nearly certain that the relation R among other instances of C1, . . . , Cn is always satisfied, and will make this general law approach certainty without limit.\nThe induction principle may be used as a method to generalize propositional relations to quantified relations and as a scheme for the generation of induction proofs. Induction in a narrow sense refers to inferences with less than 100% probability\nbecause the conclusion is tentatively valid, provided that and so long as no cases are found that belie it; whereas deduction refers specifically to inferences with 100% probability [16].\nDefinition 5.2 (Deduction principle [16]). The principle of deduction is a law asserting that new relations or conclusions can be logically deduced from already established premises.\n(a) The conclusion must be fully justified by the premises.\n(b) The conclusion is sure and immutable, so long as no new information contradicts the premises.\nThe deduction principle may be used as a method to derive new information from known pieces of information and as a scheme for the generation of new relations (propositions in \u2206).\nDefinition 5.3 (Modeling principle). The principle of modeling is a law pointing out that models for phenomena and their behaviors can be established from the information on instances of the phenomena and their behaviors.\n(a) Initial models are formulated with embedded parameters according to the information on the instances in analog to known models for similar phenomena.\n(b) The formulated models may be verified, modified, or improved iteratively through optimization of the parameter values by using additional information on the phenomena and their behaviors.\nThe modeling principle may be used to design schemes for the generation of algorithmic methods.\nDefinition 5.4 (Validation). A piece of information, a proposition, or a method may be validated by belief, by assumption, by proof, or by verification.\nProof may be deterministic or probabilistic and verification may be exhaustive or for samples in the domain. Statistical verification may be used for statements involving vague words such as \u201cmost,\u201d \u201calmost,\u201d and \u201cvery.\u201d Methods are validated usually by proofs or verifications for correctness.\nDefinition 5.5 (Knowledge object). A knowledge object is a description of a piece of information (representing a segment of a fact or a phenomenon), or a definition (of a function or a relation), or a proposition (representing a general law), or a method in the given domain, . . . , which has been validated.\nThere are mainly two types of knowledge objects, declarative and procedural.\nDefinition 5.6 (Declarative knowledge object). A knowledge object is said to be declarative if it declares a propositional or quantified relation.\nDefinition 5.7 (Procedural knowledge object). A knowledge object is said to be procedural if it specifies the functionality of a segment of a method in terms of input and output and provides the sequence of instructions on how to produce the output from the input.\nThe record of a sequence of operations performed according to the instructions provided in a procedural knowledge object for a particular input may also be considered as a knowledge object. Such knowledge objects include sequences of computations and proofs of theorems produced by general or particular methods and are secondary. They are also called procedural knowledge objects.\nBy synthesis we mean the generation of procedural knowledge objects from declarative ones. Validated pieces of information together with their extensions made by using induction, deduction, modeling, synthesis, and validation form the space of knowledge.\nExample 5.1. Refer to the previous example and let HasCapital(x) denote \u201cx has a capital.\u201d From the relations contained in Ai, one can conclude that HasCapital(China) by deduction and conjecture that \u201cevery country has a capital\u201d by induction. The conjecture can be formulated as \u2200x \u2208 G (HasCapital(x)), where G denotes the set of all countries. When the conjecture is validated, it becomes part of a knowledge object in the domain of administration.\nDefinition 5.8 (Declarative knowledge space). The declarative knowledge space KT of X for \u2206 is the set of declarative knowledge objects, which can be obtained from I for \u2206 by applying the induction principle, the deduction principle, and validation mechanisms, endowed with a topology. The topology is called the knowledge structure of KT .\nDefinition 5.9 (Procedural knowledge space). The procedural knowledge space KP of X for \u2206 is the set of procedural knowledge objects, which are valid in KT , endowed with a topology. The topology is called the knowledge structure of KP .\nDefinition 5.10 (Derivation relation). A derivation relation \u0589 is a binary relation on KT and KP . For any two knowledge objects o1 and o2, if o2 is obtained on the basis of o1, then we say that o2 is derived from o1, denoted as o1 \u0589 o2.\nThe derivation relation induces a partial order because it satisfies the following conditions for all o1, o2, and o3 inKT andKP : (1) o1 \u0589 o1; (2) if o1 \u0589 o2 and o2 \u0589 o1, then o1 = o2; (3) if o1 \u0589 o2 and o2 \u0589 o3, then o1 \u0589 o3. Therefore, the derivation relation also induces a preorder. Hence we can introduce knowledge structures \u03c4T\u0589 and \u03c4P\u0589 to define the declarative knowledge space KT\u0589 and the procedural knowledge space KP\u0589, respectively, because every open set of KT\u0589 and KP\u0589 is an upper set with respect to \u0589.\nDefinition 5.11 (Knowledge space). The knowledge space K of X for \u2206 is the product of the declarative knowledge space KT and the procedural knowledge space KP , denoted as KT \u00d7KP .\nDefinition 5.12 (Section of knowledge). A subset k of KT\u0589 or KP\u0589 is called a section of knowledge if\n(a) k is a singleton set containing only one element o from which no other element is derived and there is also no other element from which o is derived; or\n(b) for any two knowledge objects o0, om \u2208 k, there exist o1, . . . , om\u22121 \u2208 k such that oj is derived from oj\u22121 for j = 1, . . . , m; or\n(c) for any two knowledge objects o, o0 \u2208 k, there exist om, . . . , o1 \u2208 k such that o is derived from om and oj is derived from oj\u22121 for j = m, . . . , 1.\nA section k of knowledge is said to be complete if k cannot be enlarged. Each section of knowledge is an open set of KT\u0589 or KP\u0589.\nTheorem 5.1. If the knowledge space KT\u0589 or KP\u0589 is finite, then any set of the space may be uniquely decomposed into finitely many complete sections of knowledge.\nProof. Let k be a set of KT\u0589 or KP\u0589. If there exists an element o \u2208 k such that no other element is derived from o and there is no other element from which o is derived, then k can be decomposed into a section of knowledge {o} and the set k \\ {o}. Otherwise, as the derivation relation \u0589 is a partial order, k with \u0589 can be represented as finitely many disjoint directed acyclic graphs. Each directed acyclic graph can be uniquely decomposed into finitely many longest chains of which each corresponds to a complete section of knowledge.\nConsider the set\nSK =\n{\nkT \u2297 kP\n\u2223 \u2223 \u2223 \u2223 kT \u2282 KT , kP \u2282 KP , \u2200a \u2208 kT\u2203b \u2208 kP (a \u0589 b), \u2200b \u2208 kP\u2203a \u2208 kT (b \u0589 a) }\nof subspaces of K. An element kT \u2297 kP of SK is called a dual section of knowledge if both kT and kP are sections of knowledge. A dual section kT \u2297 kP \u2208 Sk of knowledge is said to be complete if neither kT nor kP can be enlarged. A complete dual section of knowledge is also called a chapter of knowledge. A chapter of knowledge may be decomposed into dual sections of knowledge.\nAssumption. For each knowledge object oT in KT\u0589, there exists at least one knowledge object oP in KP\u0589 such that oT \u0589 oP or oP \u0589 oT ; for each knowledge object oP in KP\u0589, there exists at least one knowledge object oT in KT\u0589 such that oP \u0589 oT or oT \u0589 oP .\nUnder the above assumption, we can prove the following theorem.\nTheorem 5.2. If the knowledge space K\u0589 = KT\u0589 \u00d7KP\u0589 is finite, then K\u0589 may be decomposed into finitely many chapters of knowledge. The decomposition is unique.\nProof. As the knowledge space K\u0589 is finite, KT\u0589 and KP\u0589 must be finite. Then by Theorem 3, KT\u0589 and KP\u0589 can be uniquely decomposed into finitely many complete sections of knowledge, say ST1, ST2, . . . , STn and SP1, SP2, . . . , SPm, respectively. For each ST i and each SPj, there exists only one chapter kT \u2297 kP such that kT \u2282 ST i and kP \u2282 SPj for 1 6 i 6 n and 1 6 j 6 m. Under the assumption above, it is certain that the knowledge space K\u0589 can be decomposed into such chapters. For each chapter kT \u2297 kP of knowledge, there must exist two and only two complete sections ST i and SPj of knowledge such that kT \u2282 ST i and kP \u2282 SPj where 1 6 i 6 n and 1 6 j 6 m. Therefore, the decomposition is unique.\nRemark. One can also define another binary relation on KT and KP . For any two knowledge objects o1 and o2, if o2 is related to o1, then o2 is said to be connected to o1. In this case, the relation has no \u201cdirection\u201d and one can establish similar results for the relation.\nOne of the biggest challenges for implied knowledge discovery is how to effectively synthesize procedural knowledge objects from declarative ones. There are a few studies focused on specific issues, such as derivation of simple programs or algorithms from given specifications in particular declarative forms [17, 18], yet developing a general method or framework to mechanize and automate the process of synthesis is certainly hard."}, {"heading": "6 Concluding Remarks", "text": "We have introduced the three spaces of data, information, and knowledge with structures, from which one may observe how domain information and knowledge can be acquired from data. Some properties and characteristics of the three spaces are presented and their interrelations are clarified. More properties about the spaces of knowledge and their subspaces will be investigated further. Our study results in a general approach for the discovery of knowledge implied in data.\nThe data space D may be simple and small, while the knowledge space K built up from D for the given domain \u2206 can become very rich because application of metaknowledge (mainly the induction and deduction principles) and domain knowledge to the information space I may yield many new and valuable knowledge objects which are related to or may be induced or deduced from D under the interpretation in \u2206. Therefore, profound knowledge can be discovered from D by constructing knowledge objects of K according to specially designed domain-dependent procedures. The feasibility and effectiveness of our general approach has been demonstrated by our\nimplementation in the case of geometry [13], where nontrivial geometric theorems can be discovered automatically and efficiently from images of diagrams.\nTo apply our approach to discover knowledge of a concrete domain, one has to work on several issues, including formalization and representation of domain knowledge (see, e.g., [19]), design and implementation of induction and deduction schemes, and interpretation of data and retrieval of information from data in the domain. We shall report on the results of our studies in selected domains."}], "references": [{"title": "An introduction to scientific research", "author": ["B. Wilson E"], "venue": "New York: McGraw-Hill,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1952}, {"title": "Big data: The next frontier for innovation, competition, and productivity", "author": ["J Manyika", "M Chui", "B Brown", "J Bughin", "R Dobbs", "C Roxburgh", "A. Byers"], "venue": "McKinsey Global Institute,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Top 10 algorithms in data mining", "author": ["D Wu X", "V Kumar", "R Quinlan J", "J Ghosh", "Q Yang", "H Motoda", "J McLachlan G", "A Ng", "B Liu", "S Yu P", "H Zhou Z", "M Steinbach", "J Hand D", "D. Steinberg"], "venue": "Knowledge and Information Systems,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Ensemble methods: Foundations and algorithms", "author": ["H. Zhou Z"], "venue": "Chapman and Hall/CRC,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Navigation in a small world", "author": ["J. Kleinberg"], "venue": "Nature,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Graphs over time: densification laws, shrinking diameters and possible explanations", "author": ["J Leskovec", "J Kleinberg", "C. Faloutsos"], "venue": "Proceedings of the 11th ACM SIGKDD international conference on Knowledge discovery in data mining, Chicago,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2005}, {"title": "Mining frequent patterns without candidate generation", "author": ["W Han J", "J Pei", "W. Yin Y"], "venue": "Newsletter ACM SIGMOD Record,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2000}, {"title": "Data mining techniques and applications \u2013 A decade review", "author": ["H Liao S", "H Chu P", "Y. Hsiao P"], "venue": "Expert Systems with Applications,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2000}, {"title": "The problems of philosophy", "author": ["B. Russell"], "venue": "Wilder Publications,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "The logic of scientific discovery (Routledge Classics)", "author": ["K. Popper"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "Mathematical logic: Foundations for information science", "author": ["W. Li"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Automated generation of geometric theorems from images of diagrams", "author": ["Y Chen X", "D Song", "M. Wang D"], "venue": "Geometric Reasoning \u2014 Special issue of the Annals of Mathematics and Artificial Intelligence. Springer,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Introduction to topology: third edition", "author": ["B. Mendelson"], "venue": "Dover Publications,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1990}, {"title": "Topology and data", "author": ["G. Carlsson"], "venue": "Bulletin of the American Mathematical Society,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "The principle of deduction", "author": ["A. Sion"], "venue": "TheLogician.net,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "A Deductive Approach to Program Synthesis", "author": ["Z Manna", "R. Waldinger"], "venue": "ACM Transactions on Programming Languages and Systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1980}, {"title": "Automated synthesis of some algorithms on finite sets", "author": ["I Dramnesc", "T. Jebelean"], "venue": "Proceedings of the 14th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Management of geometric knowledge in textbooks", "author": ["Y Chen X", "M. Wang D"], "venue": "Data & Knowledge Engineering,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "mining, machine learning, information retrieval, and knowledge discovery are some of the directions of research and development which have been given high priority in various national programs [1].", "startOffset": 193, "endOffset": 196}, {"referenceID": 1, "context": "It becomes more and more difficult to process collections of complex data with large volume, high velocity of change, uncertain veracity, and variety of types, called big data [2], using traditional methodologies and existing database management tools.", "startOffset": 176, "endOffset": 179}, {"referenceID": 2, "context": ", the top 10 influential data mining algorithms identified by the research community [3] and ensemble methods of effectively combining multiple algorithms and techniques [4]), with applications to information dissemination and the analysis of crowd behaviors and social networks [5, 6, 7].", "startOffset": 85, "endOffset": 88}, {"referenceID": 3, "context": ", the top 10 influential data mining algorithms identified by the research community [3] and ensemble methods of effectively combining multiple algorithms and techniques [4]), with applications to information dissemination and the analysis of crowd behaviors and social networks [5, 6, 7].", "startOffset": 170, "endOffset": 173}, {"referenceID": 4, "context": ", the top 10 influential data mining algorithms identified by the research community [3] and ensemble methods of effectively combining multiple algorithms and techniques [4]), with applications to information dissemination and the analysis of crowd behaviors and social networks [5, 6, 7].", "startOffset": 279, "endOffset": 288}, {"referenceID": 5, "context": ", the top 10 influential data mining algorithms identified by the research community [3] and ensemble methods of effectively combining multiple algorithms and techniques [4]), with applications to information dissemination and the analysis of crowd behaviors and social networks [5, 6, 7].", "startOffset": 279, "endOffset": 288}, {"referenceID": 6, "context": ", the top 10 influential data mining algorithms identified by the research community [3] and ensemble methods of effectively combining multiple algorithms and techniques [4]), with applications to information dissemination and the analysis of crowd behaviors and social networks [5, 6, 7].", "startOffset": 279, "endOffset": 288}, {"referenceID": 7, "context": "An integrated study of qualitative and quantitative methods from natural sciences with cognitive science, psychology, and human behaviors is likely to help enhance our understanding of information retrieval [8], hopefully resulting in revolutionary approaches for intelligent retrieval of information from big data.", "startOffset": 207, "endOffset": 210}, {"referenceID": 8, "context": "The principle of induction points out how to formulate conjectures as to acquire knowledge based on experience of a few existing cases [9].", "startOffset": 135, "endOffset": 138}, {"referenceID": 9, "context": "Holding a controversial view on the function of induction, Popper [11] argued that scientific theories are not inductively inferred from experience, nor is scientific experimentation carried out with a view to verifying or finally establishing the truth of theories; rather, all knowledge is", "startOffset": 66, "endOffset": 70}, {"referenceID": 10, "context": "Along this line of thought, Li [12] developed an operable revision calculus to deal with refutations and a logical framework for formalizing the process of scientific discovery.", "startOffset": 31, "endOffset": 35}, {"referenceID": 11, "context": "The interested reader is encouraged to consult [13] for one such approach, which is capable of generating nontrivial geometric theorems from images of diagrams.", "startOffset": 47, "endOffset": 51}, {"referenceID": 12, "context": "By definition of topology [14], it can be easily proved that \u03c4 is a topology on X .", "startOffset": 26, "endOffset": 30}, {"referenceID": 13, "context": "Therefore, methods from algebraic topology can be used to study the simplicial complex of X (see [15] for more details).", "startOffset": 97, "endOffset": 101}, {"referenceID": 8, "context": "1 (Induction principle [9]).", "startOffset": 23, "endOffset": 26}, {"referenceID": 14, "context": "because the conclusion is tentatively valid, provided that and so long as no cases are found that belie it; whereas deduction refers specifically to inferences with 100% probability [16].", "startOffset": 182, "endOffset": 186}, {"referenceID": 14, "context": "2 (Deduction principle [16]).", "startOffset": 23, "endOffset": 27}, {"referenceID": 15, "context": "There are a few studies focused on specific issues, such as derivation of simple programs or algorithms from given specifications in particular declarative forms [17, 18], yet developing a general method or framework to mechanize and automate the process of synthesis is certainly hard.", "startOffset": 162, "endOffset": 170}, {"referenceID": 16, "context": "There are a few studies focused on specific issues, such as derivation of simple programs or algorithms from given specifications in particular declarative forms [17, 18], yet developing a general method or framework to mechanize and automate the process of synthesis is certainly hard.", "startOffset": 162, "endOffset": 170}, {"referenceID": 11, "context": "implementation in the case of geometry [13], where nontrivial geometric theorems can be discovered automatically and efficiently from images of diagrams.", "startOffset": 39, "endOffset": 43}, {"referenceID": 17, "context": ", [19]), design and implementation of induction and deduction schemes, and interpretation of data and retrieval of information from data in the domain.", "startOffset": 2, "endOffset": 6}], "year": 2014, "abstractText": "We study the data space D of any given data set X and explain how functions and relations are defined over D. From D and for a specific domain \u2206 we construct the information space I of X by interpreting variables, functions, and explicit relations over D in \u2206 and by including other relations that D implies under the interpretation in \u2206. Then from I we build up the knowledge space K of X as the product of two spaces KT and KP , where KT is obtained from I by using the induction principle to generalize propositional relations to quantified relations, the deduction principle to generate new relations, and standard mechanisms to validate relations and KP is the space of specifications of methods with operational instructions which are valid in KT . Through our construction of the three topological spaces the following key observation is made clear: the retrieval of information from the given data set for \u2206 consists essentially in mining domain objects and relations, and the discovery of knowledge from the retrieved information consists essentially in applying the induction and deduction principles to generate propositions, synthesizing and modeling the information to generate specifications of methods with operational instructions, and validating the propositions and specifications. Based on this observation, efficient approaches may be designed to discover profound knowledge automatically from simple data, as demonstrated by the result of our study in the case of geometry.", "creator": "LaTeX with hyperref package"}}}