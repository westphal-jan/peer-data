{"id": "1411.3320", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Nov-2014", "title": "On Sparse Discretization for Graphical Games", "abstract": "This short paper deals with discretization schemes for displaying and calculating the Nash equilibrium, focusing on graphical games, but briefly on normal form and poly matrix games. The most important technical contribution is a representation theorem that informally states that a uniform linear discretization size is sufficient to account for any exact Nash equilibrium using a near approximate Nash equilibrium on a grid over mixed strategies. In graphical games, discretization under natural conditions is logarithmic in the game representation size, which is a significant improvement over the previously required linear game.The paper has five additional objectives: (1) the venue to highlight the important but often ignored role that work on constraint networks in AI in simplifying the derivation and analysis of algorithms for calculating concrete weights (2) to highlight the importance of Nash in the equilibrium of concrete weights (2).", "histories": [["v1", "Wed, 12 Nov 2014 20:59:07 GMT  (47kb)", "http://arxiv.org/abs/1411.3320v1", "30 pages. Original research note drafted in Dec. 2002 and posted online Spring'03 (this http URLedu/~mkearns/teaching/cgt/revised_approx_bnd.pdf) as part of a course on computational game theory taught by Prof. Michael Kearns at the University of Pennsylvania; First major revision sent to WINE'10; Current version sent to JAIR on April 25, 2014"]], "COMMENTS": "30 pages. Original research note drafted in Dec. 2002 and posted online Spring'03 (this http URLedu/~mkearns/teaching/cgt/revised_approx_bnd.pdf) as part of a course on computational game theory taught by Prof. Michael Kearns at the University of Pennsylvania; First major revision sent to WINE'10; Current version sent to JAIR on April 25, 2014", "reviews": [], "SUBJECTS": "cs.AI cs.GT", "authors": ["luis e ortiz"], "accepted": false, "id": "1411.3320"}, "pdf": {"name": "1411.3320.pdf", "metadata": {"source": "CRF", "title": "On Sparse Discretization for Graphical Games", "authors": ["Luis E. Ortiz"], "emails": ["leortiz@cs.stonybrook.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n41 1.\n33 20\nv1 [\ncs .A\nI] 1\n2 N\nov 2\n01 4"}, {"heading": "1. Introduction", "text": "There has been quite a bit of work over last 10 years, mostly, but not exclusively, in the theoretical computer science community, on the problem of computing approximate Nash equilibria in games (see, e.g., the work of Kearns, Littman, & Singh, 2001; Vickrey & Koller, 2002; Ortiz & Kearns, 2003; Lipton, Markakis, & Mehta, 2003; Singh, Soni, & Wellman, 2004; Soni, Singh, & Wellman, 2007; Daskalakis, Mehta, & Papadimitriou, 2007; Tsaknakis & Spirakis, 2007; Feder, Nazerzadeh, & Saberi, 2007; Daskalakis & Papadimitriou, 2008; Daskalakis, Mehta, & Papadimitriou, 2009; Kontogiannis, Panagopoulou, & Spirakis, 2009; He\u0301mon, de Rougemont, & Santha, 2008; Awasthi, Balcan, Blum, Sheffet, & Vempala, 2010; Bosse, Byrka, & Markakis, 2010; Ponsen, de Jong, & Lanctot, 2011 and the references therein; see also the book by Nisan, Roughgarden, E\u0301va Tardos, & Vazirani, 2007 for additional references). 1\n1. To keep the focus and length of this short paper, the presentation and motivation of the significance and broader scientific and practical impact the study of Nash equilibria is beyond the scope of this paper. Similarly, the main focus here is on graphical games (GGs) and absolute approximations of Nash equilibria, the most common type of approximation found in the literature. However, the curious reader can go to Appendix A to find a brief discussion of the significance of Nash equilibria (Appendix A.1), other classes of graphical models for game theory (Appendix A.2), and other types of approximations of Nash equilibria (Appendix A.3).\nThis short paper revisits the simple uniform-discretization scheme that Kearns et al. (2001) originally introduced in the context of n-player 2-action graphical games (GGs). (Formal definitions of concepts from game theory, graph theory, AI, and uniform-discretization appear in Section 3. The presentation in the Introduction will remain informal.)\nKearns et al. (2001) showed that if the size of the individual grid that the uniformdiscretization scheme induces over the probability of playing an action was O(2k/\u01eb), where k is the size of the largest set of neighbors of any player and \u01eb is an approximation quality parameter, then for each exact Nash equilibrium of the GG, its closest joint mixed-strategy in the resulting regular joint grid is an approximate \u01eb-Nash equilibrium of the GG. 2 Kearns et al. (2001) used that discretization to design a special type of dynamic-programming algorithm tailored to computing approximate Nash equilibria in GGs with tree-structured graphs they called TreeNash that runs in time linear in the number of players and O(2k 2 ), assuming a fixed \u01eb. The size of the input representation of the n-player 2-action GG is O(n 2k). In collaboration with Prof. Kearns, we later extended TreeNash as a heuristic for GGs with loopy graphs, leading to an algorithm we called NashProp, which stands for \u201cNash Propagation\u201d (Ortiz & Kearns, 2003).\nAn unpublished note drafted back in December 2002 (Ortiz, 2002), later posted online3 as part of a course on computational game theory taught by Prof. Michael Kearns during the Spring 2003 at the University of Pennsylvania, provided a significantly sharper bound of O(k/\u01eb) on the size of the discretization required to achieve the same approximation result. The revised bound was logarithmic in the representation size of the game, as opposed to the previous linear bound that Kearns et al. (2001) derived. 4 The revised, significantly tighter upper-bound led to an improved running time of O(kk) for TreeNash in terms of just k, which meant that, when using the sparser discretization derived in the old note (Ortiz, 2002), TreeNash becomes a quasi-polynomial time approximation scheme (quasi-PTAS) to compute an \u01eb-Nash equilibrium. Daskalakis and Papadimitriou (2008) independently rediscovered this result, about five years later, using a considerably more complex approach to the proof/derivation than the simple, algebraic approach presented in the old note (Ortiz, 2002) and here.\nSimilarly, some of the results regarding algorithmic implications presented here that followed from the old note (Ortiz, 2002), particularly for normal-form games, have also been independently rediscovered in the literature using different approaches throughout the years (see, e.g., some of the results of Lipton et al., 2003, and Daskalakis & Papadimitriou, 2008). Those particular results, discussed in more detail in the technical sections of this paper, followed immediately from the improved discretization bound given in the old note (Ortiz, 2002), combined with previously known results from the CSP and graphical-models literature in AI.\nThe present short paper extends the old note (Ortiz, 2002) and shows how the improved discretization-size bounds for GGs, and some specializations, fall off immediately as corollaries of a theorem that holds for GG generalizations.\n2. In an \u01eb-Nash equilibrium, players tolerate losing expected gains, up to an \u01eb amount, from not unilaterally deviating. 3. http://www.cis.upenn.edu/~mkearns/teaching/cgt/revised_approx_bnd.pdf 4. Note that Kearns et al. (2001) only considered the case of binary actions, i.e., m = 2, hence m does not\nplay a role in the results within the context of that paper.\nIn particular, the current paper presents a result on the sufficient size for uniform discretization to capture, in a formal sense, every possible Nash equilibrium of the game via another close approximate Nash equilibria in the induced grid over the space of mixed strategies of players in the game. As example corollaries of the main result, for graphical games with largest neighborhood size k, the sufficient size is O(km/\u01eb), which implies, O(nm/\u01eb) for standard normal-form games, while for n-player m-action poly-matrix games, the sufficient size is O(m/\u01eb).\nSimilarly, the representation result yields immediate computational results based on connection to algorithms for constraint satisfaction problems (CSPs). Section 6 presents and discusses several results on polynomial and quasi-polynomial time algorithms for several interesting subclasses of graphical and normal-form games that fall off from that connection.\nThe paper ends with a discussion of the algorithmic implications that the main technical result may have on other work in computational game theory. It also lists several open problems."}, {"heading": "2. Motivation", "text": "This section provides additional motivation for the necessity and significance of the study of the problem of computing approximate Nash equilibria, particularly in GGs, and for the development and dissemination of this short paper, with emphasis on its particular relevance to the AI community."}, {"heading": "2.1 The Computational Complexity of Nash Equilibria: State of Affairs", "text": "Chen and Deng (2005b) settled the complexity of computing an exact Nash equilibrium in bimatrix games, a 50-years-old open problem, proving the problem to be PPAD-complete (see also later work by Chen & Deng, 2006 and Chen, Deng, & Teng, 2009). 5 Daskalakis, Goldberg, and Papadimitriou (2006) later proved the same result (see also the presentation of Daskalakis, Goldberg, & Papadimitriou, 2009a, 2009b). This means that a polynomialtime algorithm for this problem is unlikely. This seminal result was the culmination of a series of results that same year for 3-player (Daskalakis & Papadimitriou, 2005; Chen & Deng, 2005a), and 4-player (Daskalakis, Goldberg, & Papadimitriou, 2005) normal-form games.\nWithin the game-theory community, Bubelis (1979) devised a polynomial-time reduction of any n-player normal-form game to some 3-player normal-form game; in the theoretical computer science community, Goldberg and Papadimitriou (2005) rediscovered a similar result, reducing n-player normal-form games to 4-player normal-form games. This last result rendered the computational complexity of computing a Nash equilibrium in arbitrary n-player normal-form games as PPAD-complete (Goldberg & Papadimitriou, 2005).\nSeveral results on the PPAD-completeness of computing Nash equilibria in arbitrary GGs served as lemmas to the proofs for normal-form games (Daskalakis et al., 2005; Daskalakis & Papadimitriou, 2005). In fact, GGs played a very important role in finally settling the computational complexity of bimatrix games.\n5. Papadimitriou (1994) introduced the complexity class PPAD to characterize fixed-point-type problems such as those of Nash equilibria in which a solution always exists. A discussion on the complexity class PPAD is beyond the scope of this short paper.\nThere is other important, seminal work regarding the computation of Nash equilibria prior to the hardness results discussed above, including some regarding other equilibrium notions such as pure-strategy Nash equilibria and correlated equilibria (Aumann, 1974, 1987) in graphical and normal-form games (see, e.g., the work of Gilboa and Zemel (1989), McKelvey and McLennan (1996), Kakade, Kearns, Langford, and Ortiz (2003), Gottlob, Greco, and Scarcello (2005), Conitzer and Sandholm (2008), Papadimitriou and Roughgarden (2008), Roughgarden (2009), Jiang and Leyton-Brown (2011), and the references therein). But the focus of this short paper is on representing and computing approximate Nash equilibria in GGs."}, {"heading": "2.2 A Caveat: Exact vs. Approximate Nash Equilibria in Multiplayer Games", "text": "Technically, the result for more than 3 players is for the problem of computing an approximate Nash equilibrium with an approximation quality exponentially small in the representation size of the game. This is because, as is well-known since Nash\u2019s journal version (Nash, 1951) of his original paper (Nash, 1950), Nash presents a poker-inspired game of 3 players, built in collaboration with Lloyd Shapley, a 2012 Nobel Laureate in Economics, in which all payoff hypermatrix entries/values are rational numbers, but whose unique Nash equilibrium contains mixed strategies with irrational numbers.\nChen, Deng, and Teng (2006) also proved that there does not exist a fully-polynomialtime approximation scheme (FPTAS) for computing an approximate Nash equilibrium, unless PPAD=P (see also the presentation of Chen et al., 2009). 6 For this result, they proved that the approximation quality can not go below an inverse-polynomial function of the representation size of the game. They stated in their paper, without proof, that it is easy to extend the result for 2-player normal-form games to n-player normal-form games and n-player graphical games. Hence, computing a Nash equilibrium (or more formally, an approximate Nash equilibrium with approximation quality inversely-exponential in the representation size of the game), in an arbitrary n-player GG is PPAD-complete. Yet, it is still open whether there exists a polynomial-time approximation scheme (PTAS) for n-player games in normal-form and arbitrary GGs.\nThe result of Daskalakis et al. (2009a) also implied that the problem of computing an approximate Nash equilibrium in n-player normal-form games, for n \u2265 2, with approximation quality inversely exponential on the game\u2019s representation size is PPAD-complete.\nAll of the above helps us motivate the study of approximate Nash equilibria in arbitrary GGs from a technical perspective:\n(a) there are multiplayer games with payoff matrices represented entirely using rational numbers but with unique Nash equilibria formed of mixed strategies with irrational numbers;\n(b) computing \u201cexact\u201d Nash equilibria is likely to be computationally intractable in general; and\n6. Formal definitions of the different approximation schemes, which textbooks such as those of Vazirani (2001) and Williamson and Shmoys (2011) cover, are beyond the scope of this short paper. See Appendix D for a general description of some of the approximation schemes.\n(c) while there is no FPTAS to compute an approximate Nash equilibrium with approximation quality below a value inversely polynomial of the representation size of the game, the existence of a PTAS is open.\nHere, we provide an array of results, from polynomial time, to FPTAS and quasi-PTAS, for a variety of GGs under reasonable conditions on the parameters and network characteristics of the GG."}, {"heading": "2.3 \u201cWhy revisit an old research note now?\u201d", "text": "There are several motivations for reviving the old note (Ortiz, 2002).\n\u2022 The note has gained significance and relevance with time. The sparse discretization and main representation results are proving to be particularly useful in establishing polynomial running times for a specific class of dynamic-programming and propagation algorithms.\n\u2022 Many algorithmic results immediately follow from the connection to the previous work on constraint networks in AI. Thus, this paper highlights the usefulness and significance of those results, coming from the AI community, regarding the use of constraint networks to solve network-structured CSPs.\n\u2022 The derivation of the proof of the result on sparse discretization is deliberately simple, relative to considerably more mathematically complex proofs of the same results (see, e.g., the derivations by Daskalakis & Papadimitriou, 2008): no fancy mathematical sophistication needed when simple algebraic manipulations suffice. Similarly, this short paper highlights the important, but often ignored, role that the work on constraint networks in AI has in simplifying the derivation and analysis of algorithms to compute approximate Nash equilibria in GGs and some of their specializations, including normal-form games.\n\u2022 This paper helps clarify the distinct pros and cons of the two approaches most often used to compute approximate Nash Equilibria: sparse support vs. sparse discretization.\n\u2022 This paper seeks to present the state-of-the-art on computing approximate Nash equilibria in GGs, and lists several important open problems, particular for GG generalizations, with important practical consequences, and for which the AI community is particularly well-suited to eventually solve.\nThe following discussion expands on the first two bullet points, with some emphasis on prior and current work in my research group or with collaborators, but mentioning briefly potential implications for the work of other AI researchers."}, {"heading": "2.3.1 Games as CSPs", "text": "The computation of Nash equilibria in games is inherently a CSP, an area of great relevance to AI research. In the game-induced CSP, we have one variable for each player\u2019s mixed strategy, one domain for each player corresponding to the simplex over the player\u2019s\nactions, and a set of constraints for each player\u2019s Nash equilibrium conditions. For example, for binary-action games, recall that a mixed-strategy is just a probability, real-valued number between 0 and 1; thus, the number of mixed-strategies available to each player is uncountable. Hence, the corresponding CSP would have real-valued variables, each with an uncountably infinite domain size: an infinite or continuous CSP. The same holds for multi-action games.\nAs stated previously, Kearns et al. (2001) introduced the idea in AI of using a uniform discretization of the mixed strategies of each player which leads to a regular grid. This turns the problem of computing approximate Nash equilibria into a discrete CSP (Vickrey & Koller, 2002), i.e., a CSP with finite, discrete domains. This paper considers the same type of discretization.\nOne motivation to revisit the old note (Ortiz, 2002) is the implications it has on extensions of NashProp (Ortiz & Kearns, 2003) based on survey propagation (SP) (Mezard, 2003; Parisi, 2003d; Parisi, 2003a; Braunstein & Zecchina, 2004; Braunstein, Me\u0301zard, & Zecchina, 2005; Maneva, Mossel, & Wainwright, 2007), a message-passing technique with roots in physics and introduced to computer science to solve boolean satisfiability problems, such as random 3-SAT formulas (Me\u0301zard, Parisi, & Zecchina, 2002; Parisi, 2003c; Me\u0301zard, 2004), and more generally, a variety of CSPs, such as graph 3-coloring (Parisi, 2003b). Ortiz (2008) introduced an axiomatic way to view the standard SP algorithm for boolean satisfiability, and an approach called constraint propagation relaxation (CPR) that facilitates the derivation of SP-like techniques tailored to specific CSPs. In the case of GGs, the computation of each message-passing, between players, takes exponential time in the size of the discretization of the space of mixed strategies. (A thorough description of the SP-like version of NashProp is beyond the scope of this paper.) But the improved bound on the discretization size for each player is logarithmic in the representation size of the GG, assuming a constant number of actions, leading to a running time that is polynomial in 1/\u01eb, where \u01eb is the approximation-quality parameter, and either quasi-polynomial in the representation size of the game in the case of arbitrary maximum neighborhood size k, or simply polynomial in the case k is bounded by a constant, independent of the number of players n. The representation size of each message is simply quadratic in k, m and 1/\u01eb, even if k and m are free parameters.\nAnother motivation for considering GG generalizations is that they include the class of graphical poly-matrix games, which in the case of 2-action games relates to linear (or generalized linear) influence games (Irfan & Ortiz, 2011, 2013; Irfan, 2013). In part because of their very compact representations (i.e., of size O(nm2)), poly-matrix games (Janovskaja, 1968) are an important class of games within game theory. We revisit their graphical version when we consider generalizations of GGs in Section 7.\nIn summary, particular interest in the application of CPR to derive better algorithms for computing and counting Nash equilibria in arbitrary, loopy GGs, as well as more specific GG classes such as linear or generalized-linear influence games (Irfan & Ortiz, 2011, 2013; Irfan, 2013), motivates this paper in large part.\nSimilarly, the new bounds may also provide improvements to previous discretizationbased schemes for computing \u01eb-Nash equilibria in other similar models (e.g., those of Singh et al., 2004; Soni et al., 2007)."}, {"heading": "3. Preliminaries", "text": "This section introduces the basic technical notation and concepts necessary to understand the upcoming technical sections of the research note."}, {"heading": "3.1 Basic Notation", "text": "Denote by x \u2261 (x1, x2, . . . , xn) an n-dimensional vector and by x\u2212i \u2261 (x1, . . . , xi\u22121, xi+1, . . . , xn) the same vector without component i. Similarly, for every set S \u2282 [n] \u2261 {1, . . . , n}, denote by xS \u2261 (xi : i \u2208 S) the (sub-)vector formed from x using only components in S, such that, if Sc \u2261 [n]\u2212 S denotes the complement of S, x \u2261 (xS , xSc) \u2261 (xi, x\u2212i) for every i. If A1, . . . , An are sets, denote by A \u2261 \u00d7i\u2208[n]Ai, A\u2212i \u2261 \u00d7j\u2208[n]\u2212{i}Aj and AS \u2261 \u00d7j\u2208SAj .\nIf G = (V,E) is an undirected graph, then for each i \u2208 V denote by Ni \u2261 {j | (j, i) \u2208 E} the neighbors of node/vertex i in G, and Ni \u2261 Ni \u22c3 {i} the neighborhood of node/vertex i in G. Note that we have i /\u2208 Ni but i \u2208 Ni for all i \u2208 V ."}, {"heading": "3.2 Graphical Games in Local Normal-Form Payoff Representations", "text": "This section formally defines graphical games (GGs), which are graphical models for compact representations of classical game representations in game theory (Kearns et al., 2001). GGs extend and generalize normal-form games. In particular, a normal-form game is a GG with a complete/fully-connected graph.\nDefinition 1. A graphical game (GG) consists of an undirected graph G = (V,E), 7 where each node i \u2208 V in the graph corresponds to a player i in the game, and for each player i, we have a set of actions or pure strategies Ai and a local payoff hypermatrix/function M \u2032i : ANi \u2192 R, where Ni is the neighborhood of player i in the graph defined with respect to the edges E of the graph. The (global) payoff hypermatrix/function Mi of player i is such that, for each joint-action x \u2208 A \u2261 AV , we have Mi(x) \u2261 M \u2032 i(xNi). That is, the payoff that each individual player i receives when all players, including i, take joint-action/purestrategy x is a function of the joint-actions xNi of player i\u2019s neighborhood Ni only, thus conditionally independent of xV\u2212Ni given xNi. It is convention to let V = {1, . . . , n} \u2261 [n], so that n \u2261 |V |. The representation size of each local payoff hypermatrix M \u2032i is \u0398(|ANi |) = O(mk), where m \u2261 maxi\u2208V |Ai| and k \u2261 maxi\u2208V |Ni|. The representation size of the GG is \u0398( \u2211 i\u2208V |ANi |) = O(nm\nk). If for all i we have Ni = V , then the GG is a standard normal-form game, also called strategic- or matrix-form game, which has a representation size \u0398(n|A|) = O(nmn).\nA GG achieves considerable representation savings whenever k \u226a n."}, {"heading": "3.3 Solution Concepts", "text": "A joint mixed strategy p \u2261 (p1, . . . , pn) in a game is formed from each individual mixed strategy pi \u2261 (pi(xi) : xi \u2208 Ai) for player i, which is a probability distribution over the players actions Ai (i.e., pi(xi) \u2265 0 for all xi \u2208 Ai and \u2211 xi\u2208Ai\npi(xi) = 1). Denote by Pi \u2261 { pi | pi(xi) \u2265 0, for all xi \u2208 Ai and \u2211 xi\u2208Ai pi(xi) = 1} the set of all possible mixed\n7. It is easy to extend the same result to GGs with directed graphs.\nstrategies of player i (i.e., all possible probability distributions over Ai). Similar to the vector notation introduced above, for all i and any clique/set S \u2282 V , denote by p\u2212i and pS the mixed strategies corresponding to all the players except i and all the players in clique S, respectively, so that p \u2261 (pi, p\u2212i) \u2261 (pS, pV\u2212S). A joint mixed strategy p induces a joint (product) probability distribution over the joint action space A, such that, for all x \u2208 A, p(x) \u2261 \u220f i\u2208V pi(xi) is the probability, with respect to joint mixed strategy p, that joint action x is played.\nThe expected payoff of player i with respect to joint mixed strategy p is denoted by Mi(p) \u2261 \u2211 x\u2208A p(x)Mi(x).\nDefinition 2. For any \u01eb \u2265 0, a joint mixed-strategy p\u2217is called an \u01eb-Nash equilibrium if for every player i, and for all xi \u2208 Ai, Mi(p \u2217 i , p \u2217 \u2212i) \u2265 Mi(xi, p \u2217 i )\u2212 \u01eb. That is, no player can increase its expected payoff more than \u01eb by unilaterally deviating from its mixed strategy part p\u2217i in the equilibrium, assuming the others play according to their respective parts p \u2217 \u2212i. A Nash equilibrium, or more formally, a mixed-strategy Nash Equilibrium, is then a 0-Nash equilibrium.\nNote that, for all p\u2212i \u2208 P\u2212i, maxpi\u2208Pi Mi(pi, p\u2212i) = maxxi\u2208Ai Mi(xi, p\u2212i) \u2265 Mi(x \u2032 i, p\u2212i), for all x\u2032i \u2208 Ai. Also, note that the equilibrium conditions are invariant to affine transformations. In the case of GGs with local payoff matrices represented in tabular/matrix/normalform, it is convention to assume, without loss of generality, that the payoff values are such that, for each player i \u2208 V , we have minxMi(x) = minxNi M \u2032 i(xNi) = 0 and maxxMi(x) = maxxNi M \u2032 i(xNi) = 1. Note that in the case of GGs using such \u201ctabular\u201d representations, we do not lose generality by assuming the maximum and minimum local payoff values of each player are 0 and 1, respectively, because we can compute them both efficiently. This will not be the case for GG generalizations, in the worst case. Section 7 revisits this point."}, {"heading": "4. Discretization Schemes", "text": "The discretization scheme considered here is similar to that of (Kearns et al., 2001), except that we allow for the possibility of different discretization sizes for the mixed strategies of players.\nDefinition 3. In an (individually-uniform) discretization scheme, the uncountable set I = [0, 1] of possible value assignments to the probability pi(xi) of each action xi of each player i is approximated by a finite grid defined by the set I\u0303i = {0, \u03c4i, 2\u03c4i, . . . , (si \u2212 1)\u03c4i, 1} of values separated by the same distance \u03c4i = 1/si for some integer si. Thus the discretization size is |I\u0303i| = si + 1. Then, we would only consider mixed strategies qi such that qi(xi) \u2208 I\u0303i for all xi, and \u2211 xi\u2208Ai qi(xi) = 1. The induced discretized space of joint mixed strategies is I\u0303 \u2261 \u00d7i\u2208V I\u0303 |Ai| i , subject to the individual normalization constraints."}, {"heading": "5. Sparse Discretization", "text": "The obvious question is, how small can we make si and still guarantee that there exists an \u01eb-Nash equilibrium in the induced discretized space of joint mixed strategies? The following corollary provides a stronger answer for GGs: it provides values for the si\u2019s that\nguarantee that for every Nash equilibrium, its closest point in the induced grid is an \u01eb-Nash equilibrium. An interesting aspect of the result is that si depends only on information local to player i\u2019s neighborhood: the number of actions |Ai| available to player i and the largest number of neighbors |Nj | of the neighbors j \u2208 Ni of player i.\nNote that the corresponding discretization bound provided in (Kearns et al., 2001) in the context of GGs is exponential in the largest neighborhood size k. In contrast, the bound here is linear in k, a substantial reduction.\nThe corollary is a GG instantiation of the Nash-equilibria Representation Theorem based on sparse discretization, Theorem 3, which holds for a broader class of GG generalizations. The statement and discussion of the theorem is in Section 7. The statement of the corollary uses notation introduced above.\nCorollary 1. (Sparse Discretization for Graphical Games) For any m-action graphical game and any \u01eb > 0, a (individually-uniform) discretization with\nsi =\n\u2308 2 |Ai| maxj\u2208Ni |Nj |\n\u01eb\n\u2309 = O ( mk\n\u01eb\n)\nfor each player i is sufficient to guarantee that for every true (i.e., not approximate) Nash equilibrium of the game, its closest (in \u2113\u221e distance) joint mixed strategy in the induced discretized space is also an \u01eb-Nash equilibrium of the game."}, {"heading": "6. Algorithmic Implications", "text": "One objective of this research note is to clarify the distinction between sparse discretization and sparse support in the context of approximate Nash equilibria. The next subsection deals with that objective in the context of normal-form games. Then, the second subsection presents the algorithmic implications of the sparse-discretization approach, borrowing heavily from standard results in AI, and highlighting their simplifying usefulness and powers.\nBefore starting the presentation, it is important to note a crucial distinction between the parameters of interest in GGs versus those of normal-form games, a specialization of GGs. In the study of GGs, the main objects of interest, in terms of input-game representation size, is the number of players n and the graph structure (e.g., the maximum number of neighbors k, the graph tree-width, or the hypertree-width of the game-induced constraint network), and their effect in both representation and computations of (approximate) Nash equilibria; the maximum number of actions m of each player plays a lesser role, and is often assumed constant. Yet, the statements of the results here still sometimes include the explicit dependence on m, so that such dependence is clear should m also be an important component/aspect of interest in evaluating the quality of the approximations and the resulting algorithms."}, {"heading": "6.1 Sparse Discretization vs. Sparse/Small Support", "text": "Before starting this subsection, it is important to clarify that the work of Altho\u0308fer (1994) does not imply, and cannot be used to derive, the sparse representation result presented as the main technical contribution here. Instead, the approximation bounds presented\nin Lipton et al. (2003) follow immediately from those of Altho\u0308fer (1994); in fact, both use the same approach based on applying Hoe\u0308ffding bounds (Hoeffding, 1963) and the probabilistic method (Alon & Spencer, 2004). More recently, He\u0301mon et al. (2008) derived a slightly improved small-support upper-bound result in multi-player games by using a more general large deviation bound than Hoe\u0308ffding\u2019s, due to McDiarmid (1989).\nIt is equally important to understand the distinctions between the two types of approximations. Each type has their own pros and cons.\nAs a warmup to the results and discussion regarding GGs and their generalization, let us first consider GG simplifications, starting with the simple case of 2-player games in normal form, and then moving to n-player games in normal-form."}, {"heading": "6.1.1 Bimatrix games", "text": "In the small-support approach to approximation, we perform a brute-force support-enumeration search over all possible ( m r ) subsets of strategies, where r is the minimum support necessary to guarantee the desired absolute approximation quality \u01eb > 0; thus, it is important to keep in mind that r depends on \u01eb. Hence, the running time of approximation algorithms of that type is (m r ) = O(mr), thus polynomial in m but exponential in a function of the approximation parameter. Given \u01eb > 0, the support size that results from the approach\nof Altho\u0308fer (1994) and Lipton et al. (2003) is r = O ( ln (mn)\n\u01eb2\n) . It is a well-known fact that\ngiven the supports for each player in a Nash equilibrium, one can set up a simple linear program (LP) to find the Nash equilibrium. Each call to the LP runs in polynomial time in r. This leads to a naive brute-force algorithm, also called \u201csupport enumeration,\u201d for computing \u01eb-Nash equilibrium in bimatrix games: for each possible support set of size r, run an LP to either find an \u01eb-Nash equilibrium or decide there is none with that particular set. There are (m r ) = O(mr) possible support for each player. Hence, for 2-player games, the algorithm runs in time mO(r) = m O ( lnm \u01eb2 )\n, thus exponential in 1/\u01eb2, and also exponential in (lnm)2, which means quasi-polynomial in m.\nBut, there is actually an alternative to the LP. Because of the probabilistic way in which the result for sparse supports arises (i.e., using a combination of Hoeffding\u2019s or other large deviation bound and invoking the probabilistic method), we only need to search over mixed strategies in the support whose individual probability value has the form zk/r, for each action k = 1, . . . ,m, and \u2211 k zk/r = 1, 0 \u2264 zk \u2264 r. Lipton et al. (2003) call such \u201cdiscretization scheme\u201d r-uniform. Another way of viewing this is as a uniform-discretization scheme of size r + 1, which does not seem to guarantee to find all Nash equilibria, but it does guarantee to find at least one. Thus, in that case, the worst-case running time to find at least one \u01eb-Nash equilibrium is (mr)O(r). Recalling that r = O ( lnm \u01eb2 ) , we have that the worst-case running time is still exponential in 1/\u01eb2 and exponential in (lnm)2, thus quasi-polynomial in m.\nRegardless, because the representation size of the game is N = O(m2), both algorithms run in time NO(lnN), thus both are quasi-PTASs for computing approximate Nash equilibria in bimatrix games (Lipton et al., 2003).\nIn contrast, suppose that s is the size of the uniform-grid sparse discretization presented here. A simple analysis reveals s = O ( m \u01eb ) . Hence, using the sparse discretization, a naive\nbrute-force search runs in time O ((\nm \u01eb\n)m) , thus polynomial in 1/\u01eb, but exponential inm lnm."}, {"heading": "6.1.2 Multiplayer games", "text": "For multiplayer games, one cannot use an LP to compute an \u01eb-Nash equilibrium even if one were to know the support of the \u01eb-Nash equilibrium strategies of all players. This is because now the \u01eb-Nash equilibrium conditions are highly non-linear, involving the product of n variables, where n is the number of players, each variable corresponding to the probability of a particular action in the mixed strategy of a player. (Recall that a Nash equilibrium is a product distribution.) Thus, it might first appear unclear how to efficiently perform this computation efficiently in multiplayer games. It would seem, on the surface, that for sparse support, an algorithm based on support enumeration would run in worst-case time O (mr nrtime(n,m, r)), where rtime(n,m, r) is the worst-case running time of the algorithm that attempts to compute an \u01eb-Nash equilibrium with the given players\u2019 supports, and is a direct function of r,m, and n, and of course, indirectly, of \u01eb too.\nBut, as mentioned in the case of bimatrix games, because of the probabilistic way in which the result for sparse supports arises, we only need to search over the set of r-uniform mixed strategies in the support. Thus, using this approach of support enumeration the worst-case running time becomes rtime(n,m, r) = O ((m r ) rr ) . Thus, the total running\ntime is O ((mr)r n). Lipton et al. (2003) proved that using r = O ( n2 ln (n2m)\n\u01eb2\n) is suffi-\ncient. 8 Substituting that value of r, the expression of the worst-case running time becomes m O ( (n3 ln (n2 m)) ( 1 \u01eb2 ln 1 \u01eb2 ))\n. Now, to obtain a quasi-PTAS, we would have to impose a condition on n, such as n = O(lnm). This is unlike the bimatrix-game case in which no restriction was necessary.\nIn contrast, for sparse discretization in multiplayer games, the value of s = O ( m n \u01eb ) . Hence, a brute-force search algorithm applied to a normal-form game, for example, would run in worst-case time ( mn \u01eb )O(mn) , thus polynomial in 1/\u01eb, but exponential in mn lnmn. (The results for GGs are in a later section.) To obtain a quasi-PTAS, we would have to impose a condition on m = poly(n), not n."}, {"heading": "6.1.3 Tradeoff", "text": "The tradeoff is now clear. If the interest is m, and \u01eb is fixed, then the approach of Altho\u0308fer (1994) and Lipton et al. (2003) is better. On the other hand, if the interest is \u01eb, and m is fixed, which is often the case for GGs as discussed above, then the sparse discretization wins. It is important to note that the sparse discretization guarantees the computation of all \u01eb-Nash equilibria, while the sparse-support approach can only guarantee one \u01eb-Nash equilibrium. It is also important to note that in the case of multiplayer games, the sparsesupport approach yields a quasi-PTAS only after bounding n, which is the quantity of most interest in GGs. The sparse-discretization approach bounds m, which is the number of actions of each player to obtain a quasi-PTAS, but m is not as significant in a GG setting as n is.\n8. The reader should be aware that the notation of Lipton et al. (2003) is the exact opposite of the one here: here n denotes the number of players, while there it denotes the maximum number of actions of any player; also, here m denotes the maximum number of actions of any player, while there it denotes the number of players."}, {"heading": "6.2 Reductions to Consistency in CSPs", "text": "This section involves concepts from AI and graph theory; in the interest of space, the reader is referred to appropriate standard references (see, e.g., the textbooks of Russell & Norvig, 2003, for AI and Dechter, 2003 for graph theory as used in AI; or Bollobas, 1979 for graph theory).\nThe representation result of the last section has several immediate computational consequences for the problem of computing approximate Nash equilibria in GGs with local payoff matrices represented in tabular form, and in turn, also for multi-player games represented in standard normal (tabular) form.\nTo simplify the presentation, let us assume that payoff values are in [0, 1], all the players in the GG have the same number of actions m and the largest neighborhood size in the graph of the game is k, so that the representation size of the GG is \u0398(nmk). For this case, the uniform discretization presented in Theorem 3 has size s = si = O(mk/\u01eb) for all i."}, {"heading": "6.2.1 Sparse-discretization GG-induced CSP", "text": "Once we introduce a discretization over the space of mixed strategies, then it is natural to formulate the problem of computing \u01eb-Nash equilibria on the induced discretized space as a CSP, or more specifically in the case of GGs, as a special type of constraint network (Dechter, 2003). (In the interest of keeping this paper short, please see Russell & Norvig, 2003, or other introductory textbook on AI, for general information on CSPs. The presentation here contains only the CSP concepts necessary exclusively within the context of the paper\u2019s topic.) Several researchers have taken this or related approaches either explicitly or implicitly (Kearns et al., 2001; Vickrey & Koller, 2002; Ortiz & Kearns, 2003; Soni et al., 2007). The CSP for the game has one variable, domain and constraint for each player. Each variable corresponds to mixed strategy pi for each player i. Each variable\u2019s domain corresponds to the discretized set I\u0303mi of mixed strategies for each player i, properly corrected to account for normalization. The approximate best-response equilibrium conditions are the following: for each player i, each constraint function (table) ci : I\u0303 mk i \u2192 {0, 1} is defined such that, for all pN(i) \u2208 I\u0303 mk i , ci(pN(i)) = 1 if and only if Mi(pi, p\u2212i) \u2265 maxx\u2032i\u2208Ai Mi(x \u2032 i, p\u2212i) \u2212 \u01eb. Each constraint has arity at most k and encodes the approximate best-response equilibrium conditions, each represented in tabular form using smk = O((mk/\u01eb)mk) bits. The transformation takes time O(poly(n, (mk/\u01eb)mk)) and the size of the resulting CSP is T = \u0398(n(mk/\u01eb)mk).\nAs previously discussed, for GGs, it is natural to consider the number of players n as being the \u201cfree\u201d parameter of the representation. Hence, if mk log(mk) = O(log(n)) and \u01eb = n\u2126(\u22121/(mk)) = (mk)\u2212\u2126(1) = (log n)\u2212\u2126(1), then both the time to perform the CSP transformation and its resulting representation size are polynomial in the representation size of the game (i.e., polynomial in the number of players). Similarly, if m and k are bounded (by a constant, independent of n), then the representation size of the game is linear in n and the running time of the transformation is polynomial in n and 1/\u01eb. Note that this is a natural restriction on the game parameters because otherwise the representation size would be exponential in the number of players, thus defeating the main purpose of the GG representation in the first place: succinctness.\nAt this point, we can apply any of a large number of existing off-the-shelf techniques for solving the induced game-CSP, or apply techniques such as NashProp (Ortiz & Kearns, 2003) that take advantage of the particular properties of the game best-response constraints.\nInstead, in the next section, we will see how standard results for solving constraint networks (Dechter, 2003) lead immediately to simple derivations of algorithmic results for GGs, some of which had been independently re-discovered by employing more sophisticated mathematical tools (Daskalakis & Papadimitriou, 2008). Facilitated in large part by the knowledge acquired for solving constraint networks and other graphical models in the AI community over the last 50 years, the derivations here are quite straightforward and do not require complex mathematics. By building on existing AI knowledge, fancy mathematical derivations for the same result become unnecessary despite their elegance."}, {"heading": "6.2.2 An approach based on the GG-induced CSP hypergraph", "text": "An approach to solving CSPs in AI, now over 10 years olds, works on the hypergraph induced by the game CSP (Gottlob, Leone, & Scarcello, 2001). If T is the representation size of the game-CSP, w is the hypertree width of the hypergraph, and the corresponding hypertree decomposition for the CSP has been computed, then solving the CSP takes time O(Tw+1 log(T )) (Gottlob, Leone, & Scarcello, 2000, 2002; Gottlob et al., 2001) (see also page 158 of \u201cBibliographical and Historical Notes\u201d Section in Chapter 5 of Russell & Norvig, 2003). In the case of GGs, we can compute the hypertree decomposition that the algorithm would use in time O(n2w+2).\nThe following theorem summarizes the discussion. As a preamble to a discussion on primal graphs and treewidths later in the section, note that it is known that a CSP might have hypergraphs with bounded hypertree width, but whose primal graph has unbounded treewidth. However, the treewidth always bounds the hypertree width. Thus, the restriction that the hypertree width be bounded by a constant may not be as limiting to the application of the results as it first appears.\nTheorem 1. There exists an algorithm that, given as input a number \u01eb > 0 and a GG with n players, maximum neighborhood size k and maximum number of actions m, and whose corresponding CSP has a hypergraph with hypertree width w, computes an \u01eb-Nash equilibrium of the GG in time [n (mk/\u01eb)mk]O(w).\nThe following corollary characterizes the computational complexity of the approximation schemes resulting from instances of the last theorem.\nCorollary 2. There exists an algorithm that, given as input a GG with corresponding hypergraph of hypertree width w bounded by a constant independent of the number of players n, with a logarithmic function of n restricting the maximum number of actions m and the maximum neighborhood size k as mk log(mk) = O(log(n)), and given \u01eb = n\u2126(\u22121/(mk)) = (mk)\u2212\u2126(1) = (log n)\u2212\u2126(1), outputs an \u01eb-Nash equilibria of the game in time polynomial in the representation size of the input. If, in particular, both m and k are bounded by constants independent of n, then the algorithm runs in polynomial time in n and 1/\u01eb, for any \u01eb > 0; hence, the algorithm is a fully polynomial time approximation scheme (FPTAS). If, instead, the expression constraining m and k as a logarithmic function of n holds, and w = polylog(n), then the algorithm is a quasi-polynomial time approximation scheme (quasiPTAS)."}, {"heading": "6.2.3 A side note on normal-form games", "text": "For normal-form games, k = n and w = 1. This leads to the following corollary.\nCorollary 3. There exists a quasi-PTAS for computing an \u01eb-Nash equilibrium of n-player m-action normal-form games with m = O(poly(n)) that runs in time NO(polylog (N) log(1/\u01eb)) =( 1 \u01eb )O(polylog(N)) , where N = n\u0398(n) is the representation size of the game. If, in particular, m is bounded by a constant independent of n, then the running time is NO(log log(N) \u01eb ), where N = 2\u0398(n) is the corresponding representation size of the game.\nAs briefly mentioned in Section 6.1.2, we can also obtain the same result by using the sparse-support approach of Lipton et al. (2003), even if m = 2O(n), but the dependence is exponential in 1/\u01eb2 (i.e., NO(polylog(N)(1/\u01eb) 2); or NO( log(N) \u01eb2 ), if m is bounded by a constant). The result of the last corollary for the case of m fixed or bounded by a constant is stated by Daskalakis and Papadimitriou (2008). The same result for m fixed or bounded by a constant also follows from Theorem 4 of Kearns (2007). While no formal proof appears for Theorem 4 of Kearns (2007), the theorem follows immediately from the proof in the original note of Ortiz (2002).\nBut, it is important to emphasize, as touched upon in Section 6.1.2, that in the case of normal-form games, we could have obtained the result directly by using an exhaustive search over the induced grid over mixed strategies, which is essentially what the algorithm referred to in the corollary reduces to in this case. Hence, we could output not just one \u01eb-Nash equilibrium, but all \u01eb-Nash equilibria in the induced grid in the worst-case running time given in the corollary. The algorithms based on the sparse-support approach can only guarantee to output one \u01eb-Nash equilibrium among all mixed strategies of a given maximum support. Algorithms based on sparse support that would output (a compact representation of) all \u01eb-Nash equilibria do not seem to exist, even for the given maximum support size; let alone (a compact representation of) all \u01eb-Nash equilibria in the game, as the exhaustive search that uses the sparse discretization result presented here does for normal-form games. Section 6.1 here discusses the distinctions between the sparse-support and the sparse-discretization approaches."}, {"heading": "6.2.4 An approach based on the GG-induced CSP primal graph", "text": "Another approach is to build a clique (or join) tree from the primal graph of the game-CSP, which in the case of the GGs is the graph created by forming cliques of every neighborhood. Then, one applies a dynamic programming (or message-passing) algorithm on the clique tree. Once the clique tree is built, the running time is linear in the number of nodes of the join tree and exponential in the size of the largest clique associated to a node in the clique tree. If the primal graph has treewidth w\u2032, the largest clique associated to the optimal clique tree is w\u2032+1. It has been common knowledge in the graphical-models community for quite a while now, almost two decades, at least (see, e.g., the textbooks of Dechter, 2003; Russell & Norvig, 2003, and the references therein, for a recent accounting of previous work in this area) that if the primal graph of a CSP has treewidth w\u2032 that is logarithmic in the number of nodes n, then one can solve the CSP in polynomial time if the CSP is represented in tabular form. The following theorem and corollary follow from careful\napplication of previously known results for solving constraint networks and other related graphical models. Note that the treewidth w\u2032\u2032 of the original graph of the game is always no smaller than the hypertree width w of its hypergraph (Gottlob et al., 2005). In addition, the GG\u2019s primal graph treewidth w\u2032 \u2264 (w\u201d + 1)k (Daskalakis & Papadimitriou, 2006). So the interesting bounds in the hypertree case is as given in the corollary. Also, this means that the results can be easily extended to GGs with (original) graphs that have O(log(n)) treewidth as long as k is bounded. Finally, if a graph with n nodes has treewidth w\u2032, then the graph has at most (w\u2032 + 1)n edges (see, e.g., the work of Becker & Geiger, 2001). Because the number of edges of a GG primal graph is O(k2n), w\u2032 = O(log(n)) implies k = O( \u221a log(n)).\nTheorem 2. There exists an algorithm that, given as input a number \u01eb > 0 and an n-player m-action GG with maximum neighborhood size k and primal-graph treewidth w\u2032, computes an \u01eb-Nash equilibrium of the game in time 2O(w \u2032)n log(n) + n[(mk/\u01eb)mk]O(w \u2032).\nCorollary 4. There exists a PTAS for computing an approximate Nash equilibria in nplayer GGs with bounded maximum number of actions, bounded neighborhood size and primal-graph treewidth w\u2032 = O(log(n)).\nThe new discretization bounds also provide significant improvements on the representation results and running times for NashProp and its variants (Kearns et al., 2001; Ortiz & Kearns, 2003)."}, {"heading": "7. Graphical Multi-hypermatrix Games: Generalizing Graphical Games", "text": "This section introduces graphical multi-hypermatrix games (GMhGs), a class of games that extends and generalizes GGs while capturing many classical game-theoretic model representations, as discussed below. This class of games is not some theoretical concoction: they are not only convenient in their generality, covering a large number of existing models, but also practical. Indeed, Yu and Berthod (1995) used the same type of games to establish an equivalence between local maximum-a-posteriori (MAP) inference in Markov random fields and the Nash equilibria of the induced game. 9\nThis section also states and discuss the core theorem on sparse discretization in this broader class generalizing GGs. The simplicity, broadness and strength of impact makes this extension theorem the major technical contribution of this research note.\nDefinition 4. A graphical multi-hypermatrix game (GMhG) is defined by a set V of n players, and for each player i \u2208 V , a set of actions, or pure strategies, Ai; a set Ci \u2282 2 V of cliques, or hyperedges, such that if C \u2208 Ci then i \u2208 C; and a set {M \u2032 i,C : AC \u2192 R |\n9. Unbeknown at the time, the MRF-induced game is a potential game (Monderer & Shapley, 1996); therefore sequential (or synchronous) best-response dynamics converges. Because, in addition, the goal in MAP inference is to obtain a global optimum configuration, in an attempt to avoid local minima, Yu and Berthod (1995) proposed a Metropolis-Hastings-style algorithm, which is also similar to simulated annealing algorithms used for solving satisfiability problems, and other local methods such as WalkSAT. We can view their proposed method as a kind of learning-in-games scheme (Fudenberg & Levine, 1999) based on best-response with random exploration, or \u201ctrembling hand\u201d best-response, in which, at every round, each player individually play some best-response, with some probability; otherwise the player replays the player\u2019s previous/last response.\nC \u2208 Ci} of local-clique payoff matrices. For each player i \u2208 V , the sets N(i) \u2261 \u222aC\u2208CiC and Ni \u2261 {j \u2208 V | i \u2208 N(j), j 6= i} are the clique of players affecting i\u2019s payoff including i (i.e., i\u2019s neighborhood) and those affected by i not including i, respectively. The local and global payoff matrices M \u2032i : AN(i) \u2192 R and Mi : A \u2192 R of i are (implicitly) defined as M \u2032i(xN(i)) \u2261 \u2211 C\u2208Ci M \u2032i,C(xC) and Mi(x) \u2261 M \u2032 i(xN(i)), respectively.\nConnections to other game classes. If for each player, each clique set is a singleton, we obtain a graphical game, and the single clique in the set defines the neighborhood of the player (i.e., in that case, Ci = {N(i)} for all i). Furthermore, if, in addition, each clique is the complete set of players, then the game is a standard normal-form game, also called strategicor matrix-form game (i.e., in that case, N(i) = V for all i). A GMhG becomes a classical, standard polymatrix game (Janovskaja, 1968) if for each player i, Ci = {{i, j} | j \u2208 V, j 6= i}, which is the set of cliques of pairs of nodes involving the player and every other player. 10 In contrast to hypergraphical games (Papadimitriou, 2005), a GMhG is more expressive, in part because a GMhG does not require that the same \u201csub-game\u201d (i.e., local-clique payoff hypermatrix) be shared among all players in the clique of the \u201csub-game.\u201d For example, a local-clique payoff hypermatrix may appear in the summation defining the local payoff hypermatrix of exactly one player. 11 A GMhG has the polynomial intersection property and thus a polynomial correlated equilibrium scheme (Papadimitriou, 2005). Representation size. The representation size of a GMhG is \u0398( \u2211\ni\u2208V \u2211 C\u2208Ci \u220f j\u2208C |Aj |) =\nO(n lmc), where l \u2261 maxi\u2208V |Ci| and c \u2261 maxi\u2208V maxC\u2208Ci |C|. Hence, the size is dominated by the representation of the local-clique payoff matrices, which are each of size exponential in their respective clique size. However, this representation size could be considerably smaller than for a graphical game, which is exponential in the neighborhood size. For example, if for each i, we have |Ci| \u2264 k, and for each C \u2208 Ci, we have |C| = 2, then the GMhG becomes a graphical poly-matrix game, with representation size O(n km2), linear in the maximum number of neighbors k, compared to O(nmk) for a standard graphical game with \u201ctabular\u201d representations, which is exponential in k.\nPayoff Scale. Normalizing the payoff of a GG in standard local strategic/normal-form takes linear time in the representation size of the game, because we can find the minimum and maximum local payoff values for each local payoff hypermatrix (which, for each player, is exponential in the size of the player\u2019s neighborhood) simply by going over each payoff value in the hypermatrix in sequence. However, such an approach is intractable in GMhGs in general. Denote the maximum and minimum payoff values for each player i \u2208 V, ui \u2261 maxxNi \u2211 C\u2208Ci M \u2032i,C(xC) and li \u2261 minxNi \u2211 C\u2208Ci M \u2032i,C(xC), respectively. Computing both ui and li is NP-hard. To see this, first note that ui and li are the result of a max and min operation over an additive function of the set of the player\u2019s hyper-edges and its possible joint-actions. It is easy to reduce the problem of finding a solution to an arbitrary contraint network to that of computing both ui and li for each player i. Hence, in general, we do not have much of a choice but to assume that the payoffs of all players are in the same scale, so that using a global approximation-quality value \u01eb is meaningful; and to compute\n10. Note that this is the standard definition of polymatrix games. It requires symmetry in the hyperedges: for all pair of players i, j \u2208 V, i 6= j, {i, j} \u2208 Ci \u2229 Cj . 11. Appendix B expands on the relation between GMhGs and hypergraphical games.\nthe individual maximum and minimum values of each hypermatrix payoff of each player as a way to set up the sparse uniform-discretization.\nSome additional notation is necessary before stating the theorem. Denote by ui,C \u2261 maxxC\u2208AC M \u2032 i,C(xC) and li,C \u2261 minxC\u2208AC M \u2032 i,C(xC) the largest and smallest payoff values achieved by the local-grid payoff hypermatrix M \u2032i,C , respectively; and by Ri,C \u2261 ui,C \u2212 li,C its largest range of values.\nTheorem 3. (Sparse Nash-Equilibria Representation) For any graphical multi-hypermatrix game and any \u01eb such that\n0 < \u01eb \u2264 2 min i\u2208V\n\u2211 C\u2208Ci Ri,C (|C| \u2212 1)\nmaxC\u2032\u2208Ci |C \u2032| \u2212 1\n,\na (uniform) discretization with\nsi =\n\u2308 2 |Ai| maxj\u2208Ni \u2211 C\u2208Cj Rj,C (|C| \u2212 1)\n\u01eb\n\u2309\nfor each player i is sufficient to guarantee that for every Nash equilibrium of the game, its closest (in \u2113\u221e distance) joint mixed strategy in the induced discretized space is also an \u01eb-Nash equilibrium of the game.\nThe proof of the theorem appears in Appendix C, deliberately. This is not only because it is simple, based on algebraic manipulations only, but also because the proof is irrelevant to the evaluation of the significance of the actual result stated in the theorem. Stating the proof here would simply be distracting, getting in the way of the really important objective: determining the importance of the theorem on its own.\nThe theorem establishes minimal sizes for each player\u2019s individually uniform-discretization to capture a compact representation of all Nash equilibria with respect to the resulting grid over joint mixed strategies in GMhGs. Hence, as a result of the theorem, we can represent every exact Nash equilibria of any GMhG via a sparse multi-dimensional grid over the joint mixed-strategies induced by a sparse uniform-discretization of the individual probabilities of each action of each mixed strategy of each player individually. This sparse discretization can lead not only to compact representations of the set of exact NE, but also to tractable algorithms or effective methods for the computation of approximate Nash equilibria in some classes of games. We have already seen examples of important representational and computational implications that result from the theorem\u2019s application in the previous section, which focused on GGs and some of their specializations, such as normal-form games.\nAlso, the generalized bound has already proved useful to derive and analyze dynamicprograming algorithms for computing approximate Nash equilibria in non-trivial special cases of interdependent defense (IDD) games with specific, practical graph structures. Chan, Ceyko, and Ortiz (2012) recently introduced IDD games to model, study, and analyze security and defense mechanism for deterrence in network-structured interdependent security systems under the risk of a deliberate attack from an external agent. One objective is the potential to study the effect of minimal interventions in overall system security for deterrence purposes.\nAnother example in which the generalized bounds have proven useful is in the design of specific instantiations of CPR that lead to versions of survey propagation for arbitrary GGs, which generalize NashProp (Ortiz & Kearns, 2003), and for linear influence games (Irfan & Ortiz, 2011, 2013; Irfan, 2013). In the particular case of Survey NashProp, the theorem helped us jump a major hurdle. Each message-passing process in most general CPR instances require time exponential in the size of the largest variable domains in the CSP; this is in contrast to NashProp whose running time is linear in the domain size. In the case of Survey NashProp, that would be exponential in the number of mixed-strategies it considers due to the discretization of the mixed-strategy space; for NashProp, on the other hand, that would be quasi-linear. But using the generalized version of the sparse discretization result given in the last theorem, we can now perform each message-passing in time exponential in k2, which means quasi-linear in the size of the input with respect to k, while keeping the size of the messages quadratic in the representation size of the game, assuming m is bounded by a constant, independent of n. In short, this means that we can now perform each message-passing step in time quasi-linear in the size of the game!\nUnlike for standard GGs, the broader algorithmic and computational implications of the sparse discretization in GMhGs remains wide open for the most part. The next section lists and briefly discusses several of such open problems."}, {"heading": "8. Concluding Remarks and Open Problems to the AI Community", "text": "While sparse-discretization result for graphical games (GGs) and its algorithmic implications are actually old, going back to a simple unpublished note wrote in 2002 (Ortiz, 2002), posted online a few months later as part of a course on computational game theory at the University of Pennsylvania, 12 it has gained considerable relevance over the last few years because of the need to deal with even more compact representations than GGs provide, and algorithms/heuristics that require running times exponential in the size of the discretization, thus linear in the size of the model, under many reasonable conditions. Of particular relevance along this line is prior and current exploration of extensions, based on constraint propagation relaxation (Ortiz, 2008), of survey propagation to the problem of computing approximate Nash equilibria in GGs and recent work on linear influence games, and their generalizations (Irfan & Ortiz, 2011, 2013; Irfan, 2013). As stated at the end of Section 2, the new bounds may also provide improvements to previous discretization-based schemes for computing \u01eb-Nash equilibria in other similar models, such as those in the work of Singh et al. (2004) and Soni et al. (2007).\nSeveral open questions remain, perhaps most important of which are those related to computation in GG generalizations such as GMhGs. The following is a partial list of open problems for which the AI community, and in particular, the community on constraint networks (Dechter, 2003) for CSPs, are very well equipped to solve.\n\u2022 Can we combine the sparse-support and sparse-discretization approach to obtain a better algorithm? For example, can we reduce dependency on the number of actions or the accuracy parameter, without unduly increasing the dependency on either? A naive\n12. http://www.cis.upenn.edu/\\homedirmkearns/teaching/cgt/\napproach does not seem to work, but maybe a more sophisticated approach would. Are the sparse-discretization and sparse-support approaches simply incompatible?\n\u2022 Can we do away with the uniform discretization scheme and still guarantee that every Nash equilibria is near a grid point? Would it help if the objective is to find a single approximate solution only? What if we want our approximate Nash equilibria to also be \u201cstable\u201d (i.e., near an actual Nash equilibrium)?\n\u2022 Computing exact Nash equilibria, or more formally, approximate Nash equilibria with exponentially small approximation parameter, in n-player 2-action poly-matrix games, which is a GG generalization, is PPAD-complete. This result is an implicit corollary of the work of Daskalakis et al. (2009b), although they do not provide any explicit, formal proof. Yet, the design of efficient algorithms or effective heuristics for computing approximate Nash equilibria in such GG generalizations is wide open! A naive application of the sparse-discretization approach does not seem to help. Can sparse discretization or a sparse-support approach help? If so, how?\n\u2022 There is no substantive work on using the sparse-support approach for GGs, at least not directly. Action-graph games (Jiang, Leyton-Brown, & Bhat, 2011) contain GGs. Thompson, Leung, and Leyton-Brown (2011) designed methods based on the sparse-support approach to compute approximate Nash equilibria in the context of action-graph games. How exactly do these methods apply to GGs directly, or indirectly, if at all? Can we adapt those methods to obtain direct versions, still based on sparse support, for computing approximate Nash equilibria in GGs? Is the sparsesupport approach simply incompatible with GGs, when it comes to the design of efficient or effective algorithms for computing approximate Nash equilibria that are also natural within the GG context?\n\u2022 One can view a sparse discretization as generating an equivalent game in which the discretized mixed-strategy space of the original game becomes the pure strategies of the equivalent game. It seems possible to extend the computational results of Gottlob et al. (2005) by considering the computation of pure-strategy Nash equilibria of the equivalent game, which corresponds to approximate mixed-strategy Nash equilibria of the original game. How to do this exactly requires further research and thus remains open."}, {"heading": "Acknowledgement", "text": "This manuscript was supported in part by NSF CAREER Award IIS-1054541."}, {"heading": "Appendix A. What is Beyond the Scope of This Short Paper?", "text": "This section briefly discusses some motivation for the study of Nash equilibria and other technical aspects that, while interesting, addressing them within this short paper will make it lose its focus.\nA.1 Significance of Non-cooperative Game Theory and Nash Equilibria\nAt this point, it would not be an exaggeration to say that game theory and the concept of Nah equilibrium have touched almost all areas of science and engineering. The list of the multitude of areas and applications would be too long to present here. It is beyond the scope of this note to discuss the theoretical and practical relevance that non-cooperative game theory and the concept of a Nash equilibrium have to real-world problem. But, here are a few quotes from the organization that awards what most people call the \u201cNobel Prize in Economics\u201d every year. They give a taste for the broader impact of non-cooperative game theory and the Nash equilibria as a solution concept.\nSummary: \u201cThe Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 1994 was awarded jointly to John C. Harsanyi, John F. Nash Jr. and Reinhard Selten \u201dfor their pioneering analysis of equilibria in the theory of non-cooperative games\u201d.\u201d 13\nPress Release: \u201cGame theory is a mathematical method for analyzing strategic interaction.\u201d 14\nPress Release: \u201cMany interesting economic issues, such as the analysis of oligopoly, originate in non-cooperative games. In general, firms cannot enter into binding contracts regarding restrictive trade practices because such agreements are contrary to trade legislation. Correspondingly, the interaction among a government, special interest groups and the general public concerning, for instance, the design of tax policy is regarded as a non-cooperative game. Nash equilibrium has become a standard tool in almost all areas of economic theory. The most obvious is perhaps the study of competition between firms in the theory of industrial organization. But the concept has also been used in macroeconomic theory for economic policy, environmental and resource economics, foreign trade theory, the economics of information, etc. in order to improve our understanding of complex strategic interactions.\u201d 15\nA.2 Other Game-theoretic Graphical Models\nThis note does not consider other kinds of graphical models for game theory such as multiagent influence diagrams (MAIDs) (Koller & Milch, 2003), which provide graphical models for extensive-form games, action-graph games (Jiang et al., 2011), 16 which exploit \u201ccontext-sensitive\u201d conditional expected-payoff independence, and expected utility networks (EUNs) (La Mura, 2000), which focuses on models for the \u201cstrategic\u201d decision-making aspects of a single, individual player.\n13. http://www.nobelprize.org/nobel_prizes/economic-sciences/laureates/1994/ 14. http://www.nobelprize.org/nobel_prizes/economic-sciences/laureates/1994/press.html 15. http://www.nobelprize.org/nobel_prizes/economic-sciences/laureates/1994/press.html 16. Thompson et al. (2011) considers enumeration methods based on sparse support to compute approximate\nNash equilibria in the context of action-graph games.\nA.3 Relative and Constant Approximations\nThis note only considers absolute approximations, the most commonly studied form of approximation of Nash equilibria. Relative approximations have also been the subject of study, but mostly for non-graphical models (He\u0301mon et al., 2008).\nA very recent interest is to provide polynomial-time algorithms for computing Nash equilibria of specific, constant approximation quality (see, e.g., work by Tsaknakis & Spirakis, 2007; Daskalakis et al., 2009; He\u0301mon et al., 2008; Bosse et al., 2010 and the references therein). Most results of this kind are in 2-player games. Several authors have shown how to turn such polynomial algorithms for a constant approximation quality from 2-player to results for n-player, with a larger, still constant approximation quality. Most of that work uses a sparse-support approach. This type of approximate Nash equilibria problem does not seem to have been studied for arbitrary GGs, just specializations such as normal-form games. This paper does not consider such problems to compute approximate Nash equilibria with constant approximation quality here, except for revisiting it in the list of open problems at the end."}, {"heading": "Appendix B. Expanding on the Relation between GMhGs and", "text": "Hypergraphical Games\nIn the standard definition of hypergraphical games we have a hypergraph (V, E), where each vertex i \u2208 V corresponds to a player i in the game and E \u2282 2V is a set of hyperedges (i.e., sets of subsets of V ). Each player i \u2208 V has a finite set of actions Ai. There is \u201cgame\u201d for each hyperedge C \u2208 E . By \u201cgame\u201d here we mean that each player i \u2208 C has the same set of actions Ai in all (local) \u201cgames\u201d defined by E , and a local payoff hypermatrix M \u2032\u2032i,C(xC) that is a function of the joint-actions xC \u2208 AC of all the players in C. Let C\u2032\u2032i \u2261 {C \u2208 E | i \u2208 C} be the (local) set of hyperedges that the hypergraphical game induces for each player i \u2208 V . The final/global payoff functions of each player i in the hypergraphical game is Mi(x) \u2261 \u2211 C\u2208C\u2032\u2032i M \u2032\u2032i,C(xC).\nNote that by definition, for all pairs of players i, j \u2208 V , we have that, for any hyperedge C \u2208 E such that i, j \u2208 C, the following symmetry property must hold in a hypergraphical game: C \u2208 C\u2032\u2032i if and only if C \u2208 C \u2032\u2032 j . GMhGs do not require this symmetry condition.\nOf course, from a mathematical perspective, one can always take a GMhG with a set of player\u2019s hyperedges Ci and local hypermatrices M \u2032 i,C for each player i \u2208 V and hyperedge C \u2208 Ci, and turn it into a hypermatrix game; just as one can take a GG and turn it into a normal-form game. In the case of the GMhG transformation, we can set the set of hyperedges E of the GMhG-induced hypergraphical game to E \u2261 \u222ai\u2208V \u222aC\u2208Ci C, and, letting the GMhG-induced hyperedges C\u2032i \u2261 {C \u2208 E | i \u2208 C} for all i \u2208 V . Then, for every i \u2208 V , we must either create a local zero-valued hypermatrix M \u2032\u2032i,C(xC) \u2261 0, for all xC \u2208 AC if C 6\u2208 Ci; otherwise, if C \u2208 Ci, set the local hypermatrix of the hypergraphical game to M \u2032\u2032i,C \u2261 M \u2032 i,C .\nIndeed, one can take any game with a finite number of players and actions and always turn it back into a normal-form game. But, from a computational perspective, such transformations could take an exponential amount of time and space, defeating the main purpose for introducing compact, tractable, and flexible representations of significant expressive power in the first place! Although, from a theoretical standpoint, the given transformation from\nGMhGs to hypergraphical games is computationally efficient, from a practical standpoint, the loss in expressive power is clear, and significant."}, {"heading": "Appendix C. Proof of Theorem 3", "text": "To simplify notation, given any joint mixed-strategy (i.e., a product distribution) p, for all B \u2282 V , and xB \u2208 AB, we denote by p(xB) \u2261 \u220f i\u2208B pi(xi) = \u2211 x\u2212B p(xB, x\u2212B) the joint mixed-strategy over players in B only (i.e., marginal product-distributions of p over the joint-actions of players in B). Let p and q be two joint mixed strategies and, for each player i and each action xi, denote by \u2206i(xi) \u2261 pi(xi) \u2212 qi(xi). In a slight abuse of notation, let \u2206(xS) \u2261 \u220f k\u2208S \u2206k(xk).\nThe following very simple lemma is a cornerstone of the proof.\nLemma 1. (Product-Distribution Differences) For any clique B \u2282 V of players, for any clique joint action xB,\np(xB)\u2212 q(xB) = \u2211\nS\u22082B\u2212\u2205\n\u2206(xS) q(xB\u2212S) .\nProof. The lemma follows by applying a binomial expansion:\np(xB) = \u220f\nj\u2208B\n(qj(xj) + \u2206j(xj))\n= \u2211\nS\u22082B\n\u2206(xS) q(xB\u2212S)\n=q(xB) + \u2211\nS\u22082B\u2212\u2205\n\u2206(xS) q(xB\u2212S) .\nTo further simplify the presentation of the proof it is convenient to introduce a slight abuse of notation: for all, i \u2208 C,C \u2208 Ci, B, S \u2282 C,B \u2229 S = \u2205, xS \u2208 AS , pC\u2212B\u2212S \u2208 PC\u2212B\u2212S , let M \u2032i,C(xS ,\u2206B , pC\u2212B\u2212S) \u2261 \u2211 xB\u2208AB \u2206(xB)M \u2032 i,C(xS , xB , pC\u2212B\u2212S).\nThe following useful claim follows immediately from the last lemma of joint product distribution differences (Lemma 1).\nClaim 1. Under the conditions of Lemma 1, for all i \u2208 V , C \u2208 Ci, B \u2282 C, xB \u2208 AB and pC\u2212B, qC\u2212B \u2208 PC\u2212B, we have\nM \u2032i,C(xB , pC\u2212B)\u2212M \u2032 i,C(xB , qC\u2212B) =\n\u2211\nS\u22082C\u2212B\u2212\u2205\nM \u2032i,C(xB ,\u2206S , qC\u2212B\u2212S) .\nProof. Applying the last lemma on the differences between product distributions (Lemma 1), we have\nM \u2032i,C(xB , pC\u2212B)\u2212M \u2032 i,C(xB , qC\u2212B) =\n\u2211\nxC\u2212B\n  \u2211\nS\u22082C\u2212B\u2212\u2205\n\u2206(xS)q(xC\u2212B\u2212S)  M \u2032i,C(xC)\n= \u2211\nS\u22082C\u2212B\u2212\u2205\n\u2211\nxS\n\u2206(xS) \u2211\nxC\u2212B\u2212S\nq(xC\u2212B\u2212S)M \u2032 i,C(xC)\n= \u2211\nS\u22082C\u2212B\u2212\u2205\nM \u2032i,C(xB ,\u2206S , qC\u2212B\u2212S) .\nUsing some algebra we can show another useful claim.\nClaim 2. Under the conditions of Lemma 1, for all i \u2208 V , and C \u2208 Ci, we have\n\u2211\nS\u22082C\u2212\u2205\nM \u2032i,C(\u2206S , qC\u2212S) = \u2211\nB\u22082C\u2212{i}\u2212\u2205\nM \u2032i,C(pi,\u2206B, qC\u2212B\u2212{i}) .\nProof. First note that we can decompose the left-hand side of the equation in the claim as\n\u2211\nS\u22082C\u2212\u2205\nM \u2032i,C(\u2206S , qC\u2212S) = \u2211\nB\u22082C\u2212{i}\u2212\u2205\nM \u2032i,C(qi,\u2206B , qC\u2212B\u2212{i})+\n\u2211\nB\u22082C\u2212{i}\u2212\u2205\nM \u2032i,C(\u2206i,\u2206B, qC\u2212B\u2212{i}) .\nNow note that, using the definition of \u2206i, we have\nM \u2032i,C(\u2206i,\u2206B , qC\u2212B\u2212{i}) =M \u2032 i,C(pi,\u2206B , qC\u2212B\u2212{i})\u2212M \u2032 i,C(qi,\u2206B, qC\u2212B\u2212{i}) .\nThe claim follows after making the appropriate substitution for that expressions and simplifying:\n\u2211\nS\u22082C\u2212\u2205\nM \u2032i,C(\u2206S , qC\u2212S) = \u2211\nB\u22082C\u2212{i}\u2212\u2205\nM \u2032i,C(qi,\u2206B , qC\u2212B\u2212{i})+\n\u2211\nB\u22082C\u2212{i}\u2212\u2205\n(M \u2032i,C(pi,\u2206B, qC\u2212B\u2212{i})\u2212M \u2032 i,C(qi,\u2206B , qC\u2212B\u2212{i}))\n= \u2211\nB\u22082C\u2212{i}\u2212\u2205\nM \u2032i,C(pi,\u2206B , qC\u2212B\u2212{i}) .\nSuppose p is a Nash equilibrium of the game, which must exist by Nash\u2019s Theorem (Nash, 1951). Applying the last two claims above, we obtain\nMi(p) =Mi(q) + \u2211\nC\u2208Ci\n\u2211\nS\u22082C\u2212\u2205\nM \u2032i,C(\u2206S , qC\u2212S)\n=Mi(q) + \u2211\nC\u2208Ci\n\u2211\nB\u22082C\u2212{i}\u2212\u2205\nM \u2032i,C(pi,\u2206B , qC\u2212B\u2212{i})\n\u2265max x\u2032i\nMi(x \u2032 i, p\u2212i)\n=max x\u2032 i\n Mi(x\u2032i, q\u2212i) + \u2211\nC\u2208Ci\n\u2211\nB\u22082C\u2212{i}\u2212\u2205\nM \u2032i,C(x \u2032 i,\u2206B , qC\u2212B\u2212{i})\n  .\nRearranging and simplifying, we obtain the following expression:\nMi(q) \u2265max x\u2032i\nMi(x \u2032 i, q\u2212i)+\n\u2211\nC\u2208Ci\n\u2211\nB\u22082C\u2212{i}\u2212\u2205\n( M \u2032i,C(x \u2032 i,\u2206B , qC\u2212B\u2212{i})\u2212M \u2032 i,C(pi,\u2206B , qC\u2212B\u2212{i}) ) .\nLet q be the closest (in \u2113\u221e distance) joint mixed strategy in I\u0303, defined using sizes si as given in the statement of the theorem, to exact Nash equilibrium p. Hence, we have\n|\u2206i(xi)| \u2264 \u01eb\n2 |Ai| maxj\u2208Ni \u2211 C\u2208Cj Rj,C (|C| \u2212 1) .\nConsider the conditional expected hypermatrix payoff difference in parenthesis within the innermost summation inside the maximization of the equilibrium condition above. Noting that\n|M \u2032i,C(x \u2032 i, xB , qC\u2212i,B )\u2212M \u2032 i,C(pi, xB , qC\u2212i,B )| \u2264 Ri,C ,\nwe obtain the following lower bound on that innermost summation:\n( M \u2032i,C(x \u2032 i,\u2206B , qC\u2212i,B )\u2212M \u2032 i,C(pi,\u2206B , qC\u2212i,B ) ) \u2265 \u2211\nxB\n[ \u220f\nk\u2208B\n|\u2206k(xk)| ] (\u2212Ri,C)\n=\u2212Ri,C \u2211\nxB\n\u220f\nk\u2208B\n|\u2206k(xk)| . (1)\nWe can upper bound the last factor in the right-hand side of the last expression as \u2211\nxB\n\u220f\nk\u2208B\n|\u2206k(xk)| = \u220f\nk\u2208B\n\u2211\nxk\n|\u2206k(xk)|\n\u2264 \u220f\nk\u2208B\n\u2211\nxk\n\u01eb\n2 |Ak| maxj\u2208Nk \u2211 C\u2032\u2208Cj Rj,C\u2032 (|C \u2032| \u2212 1)\n= \u220f\nk\u2208B\n\u01eb\n2 maxj\u2208Nk \u2211 C\u2032\u2208Cj Rj,C\u2032 (|C \u2032| \u2212 1)\n\u2264 \u220f\nk\u2208B\n\u01eb\n2 \u2211\nC\u2032\u2208Ci Ri,C\u2032 (|C \u2032| \u2212 1)\n=\n( \u01eb\n2 \u2211\nC\u2032\u2208Ci Ri,C\u2032 (|C \u2032| \u2212 1)\n)|B| .\nThus, using the resulting lower bound on the expression given in (1), we obtain\nMi(q) \u2265 max x\u2032i\nMi(x \u2032 i, q\u2212i)\u2212\n\u2211\nC\u2208Ci\n\u2211\nB\u22082C\u2212{i}\u2212\u2205\nRi,C\n( \u01eb\n2 \u2211\nC\u2032\u2208Ci Ri,C\u2032 (|C \u2032| \u2212 1)\n)|B| .\nThe second term in the right-hand side of the last expression equals\n\u2211\nC\u2208Ci\nRi,C \u2211\nB\u22082C\u2212{i}\u2212\u2205\n( \u01eb\n2 \u2211\nC\u2032\u2208Ci Ri,C\u2032 (|C \u2032| \u2212 1)\n)|B|\n= \u2211\nC\u2208Ci\nRi,C\n  ( 1 +\n\u01eb\n2 \u2211\nC\u2032\u2208Ci Ri,C\u2032 (|C \u2032| \u2212 1)\n)|C|\u22121 \u2212 1  \n\u2264 \u2211\nC\u2208Ci\nRi,C\n[ \u01eb (|C| \u2212 1)\u2211\nC\u2032\u2208Ci Ri,C\u2032 (|C \u2032| \u2212 1)\n] = \u01eb .\nThe last inequality follows from using the upper bound condition on \u01eb given in the statement of the theorem and applying the well-known inequality, 1 + z \u2264 exp(z) \u2264 1 + z + z2 for |z| < 1 (Cormen, Leiserson, & Rivest, 1990). This completes the proof of the theorem."}, {"heading": "Appendix D. Approximation Schemes", "text": "This appendix presents a brief, general description of the different approximation schemes. To begin, it is important to note that it is most common to define approximations in terms of relative factors. Here, given the standard/traditional mathematical definition of approximate Nash equilibria in a game setting, the description assumes that the approximation quality is in absolute terms. The description assumes that the problem is that of computing absolute approximations of Nash equilibria in games, as defined in the main body of the text.\nDefinition 5. Let N be the representation size of the input game G and \u01eb > 0 the (absolute) approximation quality. An algorithm A is a polynomial-time approximation scheme (PTAS)\nif, for every \u01eb > 0, on input G, A runs in time polynomial in N . If, in addition, A runs in time polynomial in 1\u01eb , then A is a fully-polynomial-time approximation scheme (FPTAS). If, instead, A runs in time NO(polylog (N)), where polylog(N) denotes a polynomial function of logN , then A is a quasi-polynomial-time approximation scheme (quasi-PTAS)."}], "references": [], "referenceMentions": [], "year": 2014, "abstractText": "This short paper concerns discretization schemes for representing and computing approximate Nash equilibria, with emphasis on graphical games, but briefly touching on normal-form and poly-matrix games. The main technical contribution is a representation theorem that informally states that to account for every exact Nash equilibrium using a nearby approximate Nash equilibrium on a grid over mixed strategies, a uniform discretization size linear on the inverse of the approximation quality and natural game-representation parameters suffices. For graphical games, under natural conditions, the discretization is logarithmic in the game-representation size, a substantial improvement over the linear dependency previously required. The paper has five other objectives: (1) given the venue, to highlight the important, but often ignored, role that work on constraint networks in AI has in simplifying the derivation and analysis of algorithms for computing approximate Nash equilibria; (2) to summarize the state-of-the-art on computing approximate Nash equilibria, with emphasis on relevance to graphical games; (3) to help clarify the distinction between sparse-discretization and sparse-support techniques; (4) to illustrate and advocate for the deliberate mathematical simplicity of the formal proof of the representation theorem; and (5) to list and discuss important open problems, emphasizing graphical-game generalizations, which the AI community is most suitable to solve.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}