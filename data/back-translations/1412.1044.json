{"id": "1412.1044", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2014", "title": "Problem Theory", "abstract": "We define a problem theory on the basis of first principles. We examine the objects of this theory: problems, resolutions and solutions. We combine problem theory with set theory and computer theory. We find taxonomies for resolutions and for problems. We build a hierarchy of resolvers: mechanism, adapter, internalizer, learner and subject. We show that the problem theory is complete. Finally, we propose a thesis: We reverse complete subjects because we are the result of an evolution of solvers of the survival problem.", "histories": [["v1", "Mon, 1 Dec 2014 18:13:34 GMT  (426kb,D)", "https://arxiv.org/abs/1412.1044v1", "37 pages"], ["v2", "Mon, 26 Jan 2015 10:03:24 GMT  (49kb)", "http://arxiv.org/abs/1412.1044v2", "40 pages"], ["v3", "Sun, 12 Apr 2015 10:37:07 GMT  (50kb)", "http://arxiv.org/abs/1412.1044v3", "42 pages. Using a better definition for the range of a resolver"], ["v4", "Wed, 3 Jun 2015 08:55:52 GMT  (52kb)", "http://arxiv.org/abs/1412.1044v4", "42 pages. New abstract (informative, less than 250 words)"], ["v5", "Tue, 4 Aug 2015 08:46:12 GMT  (52kb)", "http://arxiv.org/abs/1412.1044v5", "43 pages"], ["v6", "Fri, 2 Sep 2016 09:08:05 GMT  (55kb)", "http://arxiv.org/abs/1412.1044v6", "43 pages"]], "COMMENTS": "37 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ram\\'on casares"], "accepted": false, "id": "1412.1044"}, "pdf": {"name": "1412.1044.pdf", "metadata": {"source": "META", "title": "Problem Theory", "authors": ["Ram\u00f3n Casares"], "emails": ["papa@ramoncasares.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n41 2.\n10 44\nv6 [\ncs .A\nI] 2\nS ep\n2 01\n6\nProblem Theory\nRamo\u0301n Casares\norcid: 0000-0003-4973-3128\nThe Turing machine, as it was presented by Turing himself, models\nthe calculations done by a person. This means that we can com-\npute whatever any Turing machine can compute, and therefore we\nare Turing complete. The question addressed here is why, Why\nare we Turing complete? Being Turing complete also means that\nsomehow our brain implements the function that a universal Turing\nmachine implements. The point is that evolution achieved Turing\ncompleteness, and then the explanation should be evolutionary, but\nour explanation is mathematical. The trick is to introduce a mathe-\nmatical theory of problems, under the basic assumption that solving\nmore problems provides more survival opportunities. So we build\na problem theory by fusing set and computing theories. Then we\nconstruct a series of resolvers, where each resolver is defined by its\ncomputing capacity, that exhibits the following property: all prob-\nlems solved by a resolver are also solved by the next resolver in the\nseries if certain condition is satisfied. The last of the conditions\nis to be Turing complete. This series defines a resolvers hierarchy\nthat could be seen as a framework for the evolution of cognition.\nThen the answer to our question would be: to solve most problems.\nBy the way, the problem theory defines adaptation, perception, and\nlearning, and it shows that there are just three ways to resolve any\nproblem: routine, trial, and analogy. And, most importantly, this\ntheory demonstrates how problems can be used to found mathe-\nmatics and computing on biology.\nKeywords: problem solving; adaptation, perception & learning; Turing\ncompleteness; resolvers hierarchy; evolution of cognition.\nThis is arXiv:1412.1044 version 20160902, and it is licensed as cc-by. Any comments on it to papa@ramoncasares.com are welcome.\nProblem Theory\n\u00a71 Introduction . . . . . . . . . . . . . . . . . . . . . . . 3\n\u00a71.1 Object . . . . . . . . . . . . . . . . . . . . . . . . . 3 \u00a71.2 Contents . . . . . . . . . . . . . . . . . . . . . . . . 4\n\u00a72 Theory . . . . . . . . . . . . . . . . . . . . . . . . . 5\n\u00a72.1 Problem . . . . . . . . . . . . . . . . . . . . . . . . 5 \u00a72.2 Solution . . . . . . . . . . . . . . . . . . . . . . . . 6 \u00a72.3 Resolution . . . . . . . . . . . . . . . . . . . . . . . 6 \u00a72.4 Eight Concepts . . . . . . . . . . . . . . . . . . . . . . 7\n\u00a73 Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n\u00a73.1 Problems . . . . . . . . . . . . . . . . . . . . . . . . 7 \u00a73.2 Solutions . . . . . . . . . . . . . . . . . . . . . . . . 9 \u00a73.3 Routines and Trials . . . . . . . . . . . . . . . . . . . 11 \u00a73.4 Analogies . . . . . . . . . . . . . . . . . . . . . . . 12 \u00a73.5 Metaproblems . . . . . . . . . . . . . . . . . . . . . 14 \u00a73.6 Resolution Typology . . . . . . . . . . . . . . . . . . . 16\n\u00a74 Computers . . . . . . . . . . . . . . . . . . . . . . . . 17\n\u00a74.1 Turing Machine . . . . . . . . . . . . . . . . . . . . . 17 \u00a74.2 Turing Completeness . . . . . . . . . . . . . . . . . . . 19 \u00a74.3 Turing\u2019s Thesis . . . . . . . . . . . . . . . . . . . . . 22 \u00a74.4 Full Resolution Machine . . . . . . . . . . . . . . . . . 24 \u00a74.5 Problem Topology . . . . . . . . . . . . . . . . . . . . 27\n\u00a75 Resolvers . . . . . . . . . . . . . . . . . . . . . . . . 29\n\u00a75.1 Semantics and Syntax . . . . . . . . . . . . . . . . . . 29 \u00a75.2 Mechanism . . . . . . . . . . . . . . . . . . . . . . 31 \u00a75.3 Adapter . . . . . . . . . . . . . . . . . . . . . . . 32 \u00a75.4 Perceiver . . . . . . . . . . . . . . . . . . . . . . . 34 \u00a75.5 Learner . . . . . . . . . . . . . . . . . . . . . . . 36 \u00a75.6 Subject . . . . . . . . . . . . . . . . . . . . . . . 38 \u00a75.7 Resolvers Hierarchy . . . . . . . . . . . . . . . . . . . 39\n\u00a76 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . 41\n\u00a76.1 Purpose . . . . . . . . . . . . . . . . . . . . . . . 41 \u00a76.2 Countability . . . . . . . . . . . . . . . . . . . . . . 42 \u00a76.3 Intuition . . . . . . . . . . . . . . . . . . . . . . . 43\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . 44\n\u00a71 Introduction\nDevoid of problems, thinking is useless.\nWarning This paper does not explain how to solve, nor how to resolve, any problem.\n\u00a71.1 Object \u00b61 \u00b7 The object of this paper is to present a mathematical theory of problems. The resulting problem theory provides meaning to set theory and to computing theory. \u00b62 \u00b7 Problems are nearly everywhere. We can say that mathematics is all about mathematical problems, but also that physics is all about physical problems, and philosophy is all about philosophical problems. I said nearly because there are not problems in a river; a river just flows. So, where are problems? \u00b63 \u00b7 This problem theory gives an answer: There are problems where there is freedom. Determinists will surely object, but they should note that if there were only uncertainty, and not the possibility of doing otherwise, then problem resolving would be purposeless and absurd. Nevertheless, in this theory freedom cannot exist by itself, but freedom is always limited by a condition and both together, freedom and a condition, are a problem. In fact, the resolution of any problem is the process of spending all of its freedom while still satisfying the condition. So resolving is fighting freedom away. And, if people fight for freedom, it is because we want problems; in fact, not having any problem is boring. But I would say more, we are devices exquisitely selected to resolve problems, because surviving is literally the problem of being dead or alive: \u201cTo be, or not to be\u2014that is the question.\u201d \u00b64 \u00b7 I am digressing, sorry! The point is that problems are related to sets at the very bottom: for each problem there is a condition that determines if anything is a solution to it or not, so for each problem there is a set, the set of its solutions, and the condition is its characteristic function. This means that problems and sets are just two names for the same thing. So problem theory, being just a rewording of set theory, would be a better foundation for mathematics than set theory, because problems are more related to thinking than sets are. \u00b65 \u00b7 We have just seen how problems and solutions fit with sets, but we have seen nothing about resolutions, that is, the ways to go from a problem to its solutions. It is a fact that computing is helping us in resolving many problems. Perhaps too many: How our modern society would subsist without computers? I am digressing again, sorry! The right question is: What is the relation between problem resolving and computing? \u00b66 \u00b7 Computing is the mechanical manipulation of strings of symbols. Mechanical in the sense that the manipulations do not take into account the meaning of the symbols, but they just obey blindly a finite set of well-defined rules. Being meaningless, what could be the purpose of computing? Historically, computing resulted from two apparently different pursuits: the foundation of mathematics, and the enhancement of calculating machines. The second, the development of mechanical aids to calculation, is easier to understand. When we learn the algorithm for division we readily appreciate that those fixed rules can be better applied by a machine than by a person. This explains why an arithmetic calculator comes handy when resolving a problem that requires performing a numerical division. And it could also help us to understand why computation was seen as the ideal for mathematical rigor, and then how computing relates to the foundations of mathematics.\n\u00b67 \u00b7 But, again, what is the purpose of mathematical formalization? Is it true that a complete formalization of mathematics would render it meaningless? What would be the use of something meaningless? And again, the arithmetic calculator, dividing for us, answers the three questions: formalization prevents mistakes and assures that nothing has been taken for granted, and, while it is literally meaningless, it is not useless if the formalism helps us in resolving problems. Though pending on an if, formalism is not yet lost. This paper cuts that Gordian knot by showing that problem resolving is computing.\n\u00b68 \u00b7 In fact, that \u2018resolving is computing\u2019 comes from the founding paper of computing. Turing (1936) proved that the Entscheidungsproblem, which is the German word for \u2018decision problem\u2019, is unsolvable, because it cannot be solved by any Turing machine. For this proof to be valid, \u2018solved by a Turing machine\u2019 has to be equal to \u2018solved\u2019, and therefore \u2018resolved by computing\u2019 has to be redundant.\n\u00b69 \u00b7 Summarizing, a problem is a set, and resolving is computing. This is how this problem theory relates to set and computing theories at the highest level of abstraction. For a more detailed view you should continue reading this paper.\n\u00a71.2 Contents\n\u00b61 \u00b7 The object of this paper is to introduce a mathematical theory of problems. Because our approach is minimalist, aiming to keep only what is essential, we will define a problem theory from first principles. Section \u00a72 contains this problem theory, including its eight concepts: problem, with freedom and condition; resolution, with routine, trial and analogy; and solution. Some care is advisable to distinguish \u2018solution\u2019 from \u2018resolution\u2019, because while they are usually considered synonyms, they are very distinct concepts in this theory: a solution is a state, and a resolution is a transition. Then that \u2018a problem is resolved unsolvable\u2019 achieves a very precise meaning.\n\u00b62 \u00b7 Section \u00a73 translates the problem theory to set theory. Subsection \u00a73.1 defines what a problem is, and what is the set of its solutions is defined in Subsection \u00a73.2. Then, in Subsection \u00a73.3, we develop the first two ways to resolve a problem, by routine and by trial, while we devote Subsection \u00a73.4 to the third way, by analogy. The conclusion of these two subsections is that there is a general form that includes the three forms. Then we observe that looking for a resolution to a problem is also a problem, the metaproblem, so Subsection \u00a73.5 deals with metaproblems. The last subsection of this section, Subsection \u00a73.6, shows that there is only one level of problem meta-ness and that there are five types of resolution. \u00b63 \u00b7 The next section, Section \u00a74, is about computing. In Subsection \u00a74.1 we present the Turing machine, concluding that all computing is inside countable sets. In Subsection \u00a74.2 we deal with universal computers and Turing completeness. Then, in Subsection \u00a74.3, we explain that Turing\u2019s thesis implies that everything is an expression, that resolving is computing, and that all problem sets are countable. In Subsection \u00a74.4, we introduce the full resolution machine, and we show some equivalences between problem theory and computing theory. In the last subsection of this section, Subsection \u00a74.5, we show that there are five types of problem.\n\u00b64 \u00b7 Section \u00a75 is about resolvers, that is, devices that resolve problems. In the first subsection, \u00a75.1, we present the practical scenario, where functions are not solutions, so we distinguish the semantics of solutions from the syntax of functions, and we define the range of a resolver as the set of problems that the resolver solves, and the power of a\nresolver as the set of problems that the resolver resolves. Then we construct a series of five resolvers: \u25e6 Mechanism, Subsection \u00a75.2, is any device that implements a semantic unconditional computation. We show that mechanisms can resolve problems by routine.\n\u25e6 Adapter, in \u00a75.3, is any device that implements a semantic conditional computation. We show that adapters can resolve problems by trial. \u25e6 Perceiver, in \u00a75.4, is any device that implements a semantic functional computation or a syntactic unconditional computation. We show that perceivers can resolve problems by analogy and metaproblems by routine. \u25e6 Learner, in \u00a75.5, is any device that implements a syntactic conditional computation. We show that learners can resolve metaproblems by trial. \u25e6 Subject, in \u00a75.6, is any device that implements a syntactic functional computation. We show that subjects can resolve metaproblems by analogy.\nIn addition, we show that the range and power of each resolver in the series includes the range and power of the previous one, provided that a specific condition is satisfied. The last of these conditions requires the subject to be Turing complete. So, in the last subsection of this section, \u00a75.7, we summarize the findings of the section: we show that there is a hierarchy of five types of resolver, and that the problem theory is complete. The theory is complete because Turing completeness is the maximum computing capacity, and this means that there are exactly three ways to resolve any problem: routine, trial, and analogy. Finally, we argue that we are the Turing complete subjects that have resulted from an evolution of resolvers of the survival problem.\n\u00b65 \u00b7 The paper finishes with some conclusions, in Section \u00a76. In the first subsection, \u00a76.1, we explain how problem theory provides purpose and meaning to set theory and to computing theory. In the next subsection, \u00a76.2, we argue that countableness is the golden mean that keeps paradoxes under control. And in the last subsection, \u00a76.3, we explore what would be the implications of non-computable ways of resolving, as intuition.\n\u00a72 Theory\n\u00a72.1 Problem \u00b61 \u00b7 Every problem is made up of freedom and of a condition. There have to be possibilities and freedom to choose among them, because if there is only necessity and fatality, then there is neither a problem nor is there a decision to make. The different possible options could work, or not, as solutions to the problem, so that in every problem a certain condition that will determine if an option is valid or not as a solution to the problem must exist.\nProblem {\nFreedom Condition\n\u00a72.2 Solution \u00b61 \u00b7 A fundamental distinction that we must make is between the solution and the resolution of a problem. Resolving is to searching as solving is to finding, and please note that one can search for something that does not exist.\nResolving \u00b7 Searching Solving \u00b7 Finding\nThus, resolution is the process that attempts to reach the solutions to the problem, while a solution of the problem is any use of freedom that satisfies the condition. In the statetransition jargon: a problem is a state of ignorance, a solution is a state of satisfaction, and a resolution is a transition from uncertainty to certainty.\nProblem Resolution\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192 Solution\n\u00b62 \u00b7 We can explain this with another analogy. The problem is defined by the tension that exists between two opposites: freedom, free from any limits, and the condition, which is pure limit. This tension is the cause of the resolution process. But once the condition is fulfilled and freedom is exhausted, the solution annihilates the problem. The resolution is, then, a process of annihilation that eliminates freedom as well as the condition of the problem, in order to produce the solution.\nFreedom Condition \ufe38 \ufe37\ufe37 \ufe38\nProblem\n} Resolution\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192 Solution\n\u00b63 \u00b7 A mathematical example may also be useful in order to distinguish resolution from solution. In a problem of arithmetical calculation, the solution is a number and the resolution is an algorithm such as the algorithm for division, for example.\n\u00a72.3 Resolution \u00b61 \u00b7 There are three ways to resolve a problem: routine, trial, and analogy.\nResolution\n \n Routine Trial Analogy\n\u00b62 \u00b7 To resolve a problem by routine, that is, by knowing or without reasoning, it is necessary to know the solutions, and it is necessary to know that they solve that problem. \u00b63 \u00b7 If the solutions to a problem are not known, but it is known a set of possible solutions, then we can use a trial and error procedure, that is, we can try the possible solutions. To resolve by trial is to test each possible solution until the set of possible solutions is exhausted or a halting condition is met. There are two tasks when we try: to test if a particular possibility satisfies the problem condition, and to govern the process determining the order of the tests and when to halt. There are several ways to govern the process, that is, there is some freedom in governing the trial, and so, if we also put\na condition on it, for example a temporal milestone, then governing is a problem. And there are three ways to resolve a problem (da capo). \u00b64 \u00b7 By analogy we mean to transform a problem into a different one, called question, which is usually composed of several subproblems. This works well if the subproblems are easier to resolve than the original problem. There are usually several ways to transform any problem (there is freedom), but only those transformations that result in questions that can be resolved are valid (which is a condition), so applying an analogy to a problem is a problem. There are three ways to resolve the analogy, the question, and each of its subproblems: routine, trial, and analogy (da capo). If we could translate a problem into an analogue question, and we could find a solution to that question, called answer, and we could perform the inverse translation on it, then we would have found a solution to the original problem.\nProblem Solution \u2193 \u2191 Question \u2212\u2192 Answer\n\u00a72.4 Eight Concepts \u00b61 \u00b7 Lastly we are ready to list the eight concepts of the problem theory. They are: problem, with freedom and condition; resolution, with routine, trial, and analogy; and solution.\nProblem Theory\n \n \nProblem {\nFreedom Condition\nResolution\n \n Routine Trial Analogy\nSolution\n\u00a73 Sets\n\u00a73.1 Problems\n\u00a73.1.1 Notation We will refer to the set of problems as P. We will refer to the set of resolutions as R. We will refer to the set of solutions as S.\nDefinition A resolution takes a problem and returns the set of the solutions to the problem. Then resolutions are R = P \u2192 2S, where 2S is the powerset, or the set of the subsets, of S.\n\u00a73.1.2 Notation \u22a4 stands for \u2018true\u2019, and \u22a5 for \u2018false\u2019. We will refer to the set of these Boolean values as B. B = {\u22a4,\u22a5}. Comment \u22a4 = \u00ac\u22a5 and \u22a5 = \u00ac\u22a4. Also [P = \u22a4] = P and [P = \u22a5] = \u00acP . \u00a73.1.3 Notation Given s \u2208 S \u2286 S and f \u2208 F \u2286 (S \u2192 S), so f : S \u2192 S and f(s) \u2208 S,\nwe will use the following rewriting rules: f(S) = { f(s) | s \u2208 S }, F (s) = { f(s) | f \u2208 F }, and F (S) = { f(s) | s\u2208S \u00d7 f \u2208F }.\nComment As f(s) \u2208 S, then f(S) \u2208 2S, F (s) \u2208 2S, and F (S) \u2208 2S. Proposition If s \u2208 S and f \u2208 F , then f(S) \u2286 F (S) and F (s) \u2286 F (S).\n\u00a73.1.4 Definition Problem \u03c0 is x?P\u03c0(x), where P\u03c0 is any predicate, or Boolean-valued function, on S; so P\u03c0 : S \u2192 B, where P\u03c0(x) = \u22a4 means that x is a solution of \u03c0, and P\u03c0(x) = \u22a5 means that x is not a solution of \u03c0.\nComment A problem \u03c0 = x?P\u03c0(x) is made up of freedom and of a condition, as defined in Section \u00a72. The condition is P\u03c0, and freedom is represented by the free variable x, which is free to take any value in S, x \u2208 S.\n\u00a73.1.5 Definition A function \u2217f is effectively calculable if there is a purely mechanical process to find \u2217f(s) for any s. Comment This definition of effective calculability was stated by Turing (1938), \u00a72. Comment If the result of the calculation is finite, then an effective calculation has to\ncomplete it. If the result of the calculation is infinite, then an effective calculation has to proceed forever towards the result.\nNotation We will refer to the set of effectively calculable functions as \u2217F.\n\u00a73.1.6 Definition A problem \u03c0 is expressible if its condition P\u03c0 is an effectively calculable function. Comment The result of a condition is in set B = {\u22a4,\u22a5}, so it is always finite. Therefore a problem is not expressible if for some x we cannot calculate whether x is a solution or not in a finite time.\n\u00a73.1.7 Definition The condition isomorphism is the natural isomorphism that relates each problem \u03c0 with its condition P\u03c0: for each predicate P there is a problem, x?P (x), and for each problem, \u03c0 = x?P\u03c0(x) there is a predicate, P\u03c0. That is, P \u21d4 (S \u2192 B) : x?P\u03c0(x) \u2194 P\u03c0.\nComment Using the condition isomorphism, two problems are equal if they have the same condition, that is, \u03c0 = \u03c1 \u21d4 P\u03c0 = P\u03c1.\nComment The condition isomorphism abstracts freedom away.\n\u00a73.1.8 Theorem The set of problems is the set of predicates, that is, P = S \u2192 B. Proof P \u223c= S \u2192 B, by the condition isomorphism, see \u00a73.1.7, and, abstracting freedom,\nP = S \u2192 B. But freedom has to be abstracted away from mathematics because freedom is free of form and it cannot be counted nor measured. \u22c4\nComment Although in mathematics we cannot deal with freedom, it is an essential part of problems, see \u00a72.1. In any case, what defines problem \u03c0 is its condition P\u03c0.\n\u00a73.1.9 Lemma The name of the free variable is not important, it can be replaced: x?P (x) = y?P (y). Proof By the condition isomorphism, and \u00a73.1.8, both problems, x?P (x) and y?P (y), are equal, x?P (x) = y?P (y), because they have the same condition, P . \u22c4\nComment This means that the rule of \u03b1-conversion stands for problem expressions. See Curry & Feys (1958), Section 3D.\n\u00a73.1.10 Definition Let \u03c0 and \u03c1 be two problems. Then \u03c0\u2227\u03c1 = x?P\u03c0(x)\u2227P\u03c1(x), and \u03c0 \u2228 \u03c1 = x?P\u03c0(x) \u2228 P\u03c1(x), and \u03c0\u0304 = x?\u00acP\u03c0(x). Comment In other words, P\u03c0\u2227\u03c1(x) = P\u03c0(x) \u2227 P\u03c1(x), P\u03c0\u2228\u03c1(x) = P\u03c0(x) \u2228 P\u03c1(x), and P\u03c0\u0304(x) = \u00acP\u03c0(x).\nComment This provides a way to compose, or decompose, problems.\n\u00a73.1.11 Definition A problem \u03c4 is tautological if its condition is a tautology; P\u03c4 is a tautology, if \u2200x, P\u03c4 (x) = \u22a4. A problem \u03c4\u0304 is contradictory if its condition is a contradiction; P\u03c4\u0304 is a contradiction, if \u2200x, P\u03c4\u0304 (x) = \u22a5.\nLemma Both \u03c4 and \u03c4\u0304 are expressible. Proof Because P\u03c4 and P\u03c4\u0304 are effectively calculable, see \u00a73.1.6 and \u00a73.1.5. \u22c4\n\u00a73.1.12 Theorem \u3008P,\u2228,\u2227,\u00ac, \u03c4\u0304 , \u03c4\u3009 is a Boolean algebra, where \u03c4\u0304 is the neutral for \u2228, and \u03c4 is the neutral for \u2227. Proof Because P\u03c0(x) \u2208 B. In detail, \u2200\u03c0, \u03c1, \u03c3 \u2208 P: 1o. (\u03c0 \u2228 \u03c1) \u2228 \u03c3 = x?P\u03c0\u2228\u03c1(x) \u2228 P\u03c3(x) = x? (P\u03c0(x) \u2228 P\u03c1(x)) \u2228 P\u03c3(x) =\nx?P\u03c0(x) \u2228 (P\u03c1(x) \u2228 P\u03c3(x)) = x?P\u03c0(x) \u2228 P\u03c1\u2228\u03c3(x) = \u03c0 \u2228 (\u03c1 \u2228 \u03c3). 1a. (\u03c0 \u2227 \u03c1) \u2227 \u03c3 = x?P\u03c0\u2227\u03c1(x) \u2227 P\u03c3(x) = x? (P\u03c0(x) \u2227 P\u03c1(x)) \u2227 P\u03c3(x) = x?P\u03c0(x) \u2227 (P\u03c1(x) \u2227 P\u03c3(x)) = x?P\u03c0(x) \u2227 P\u03c1\u2227\u03c3(x) = \u03c0 \u2227 (\u03c1 \u2227 \u03c3). 2o. \u03c0 \u2228 \u03c1 = x?P\u03c0(x) \u2228 P\u03c1(x) = x?P\u03c1(x) \u2228 P\u03c0(x) = \u03c1 \u2228 \u03c0. 2a. \u03c0 \u2227 \u03c1 = x?P\u03c0(x) \u2227 P\u03c1(x) = x?P\u03c1(x) \u2227 P\u03c0(x) = \u03c1 \u2227 \u03c0. 3o. \u03c0 \u2228 \u03c4\u0304 = x?P\u03c0(x) \u2228 P\u03c4\u0304 (x) = x?P\u03c0(x) \u2228 \u22a5 = x?P\u03c0(x) = \u03c0. 3a. \u03c0 \u2227 \u03c4 = x?P\u03c0(x) \u2227 P\u03c4 (x) = x?P\u03c0(x) \u2227 \u22a4 = x?P\u03c0(x) = \u03c0. 4o. \u03c0 \u2228 \u03c0\u0304 = x?P\u03c0(x) \u2228 P\u03c0\u0304(x) = x?P\u03c0(x) \u2228 \u00acP\u03c0(x) = x?\u22a4 = x?P\u03c4 (x) = \u03c4 . 4a. \u03c0 \u2227 \u03c0\u0304 = x?P\u03c0(x) \u2227 P\u03c0\u0304(x) = x?P\u03c0(x) \u2227 \u00acP\u03c0(x) = x?\u22a5 = x?P\u03c4\u0304 (x) = \u03c4\u0304 . 5o. \u03c0 \u2228 (\u03c1 \u2227 \u03c3) = x?P\u03c0(x) \u2228 P\u03c1\u2227\u03c3(x) = x?P\u03c0(x) \u2228 (P\u03c1(x) \u2227 P\u03c3(x)) =\nx? (P\u03c0(x)\u2228P\u03c1(x))\u2227 (P\u03c0(x)\u2228P\u03c3(x)) = x?P\u03c0\u2228\u03c1(x)\u2227P\u03c0\u2228\u03c3(x) = (\u03c0 \u2228 \u03c1)\u2227 (\u03c0 \u2228 \u03c3). 5a. \u03c0 \u2227 (\u03c1 \u2228 \u03c3) = x?P\u03c0(x) \u2227 P\u03c1\u2228\u03c3(x) = x?P\u03c0(x) \u2227 (P\u03c1(x) \u2228 P\u03c3(x)) =\nx? (P\u03c0(x)\u2227P\u03c1(x))\u2228 (P\u03c0(x)\u2227P\u03c3(x)) = x?P\u03c0\u2227\u03c1(x)\u2228P\u03c0\u2227\u03c3(x) = (\u03c0 \u2227 \u03c1)\u2228 (\u03c0 \u2227 \u03c3). \u22c4\n\u00a73.2 Solutions\n\u00a73.2.1 Theorem Everything is in S. In other words, S is the set of everything. Proof Anything, let us call it s, is a solution to problem x? [x = s], because equality\nis reflexive, and therefore everything satisfies the condition of being equal to itself. \u22c4 Comment Freedom is complete, because x is free to take any value; x \u2208 S is not a\nrestriction. And P\u03c0 : S \u2192 B is a predicate on everything. Comment Some paradoxes derive from this theorem, see \u00a73.2.12. For a constructive\nvision of S, see Section \u00a75. See also Subsection \u00a76.2. Corollary P \u2282 S and R \u2282 S. Even B \u2282 S. Comment If you are a teacher looking for a problem to ask in an exam, then your\nsolution is a problem, so P \u2282 S makes sense. And if you are a mathematician looking for an algorithm to resolve some kind of problems, then your solution is a resolution, so R \u2282 S makes sense. There are many yes-or-no questions, so B \u2282 S makes sense.\n\u00a73.2.2 Notation Let \u03a3\u03c0 be the (possibly infinite) set of all the solutions to problem \u03c0. So \u03a3\u03c0 \u2286 S, or \u03a3\u03c0 \u2208 2S, and \u03a3\u03c0 = { s | P\u03c0(s) }.\nComment A solution of the problem is any use of freedom that satisfies the condition, see Section \u00a72, so s is a solution of problem \u03c0, if P\u03c0(s) stands.\nComment The condition of the problem \u03c0 is the characteristic function of its set of solutions, that is, P\u03c0 is the characteristic function of \u03a3\u03c0.\n\u00a73.2.3 Lemma \u03a3\u03c0\u2228\u03c1 = \u03a3\u03c0 \u222a \u03a3\u03c1, and \u03a3\u03c0\u2227\u03c1 = \u03a3\u03c0 \u2229 \u03a3\u03c1, and \u03a3\u03c0\u0304 = \u03a3\u03c0. Proof Just apply the definitions in \u00a73.1.10:\n\u03a3\u03c0\u2228\u03c1 = { s | P\u03c0\u2228\u03c1(s) } = { s | P\u03c0(s) \u2228 P\u03c1(s) } = { s | s \u2208 \u03a3\u03c0 \u2228 s \u2208 \u03a3\u03c1 } = \u03a3\u03c0 \u222a \u03a3\u03c1. \u03a3\u03c0\u2227\u03c1 = { s | P\u03c0\u2227\u03c1(s) } = { s | P\u03c0(s) \u2227 P\u03c1(s) } = { s | s \u2208 \u03a3\u03c0 \u2227 s \u2208 \u03a3\u03c1 } = \u03a3\u03c0 \u2229 \u03a3\u03c1. \u03a3\u03c0\u0304 = { s | P\u03c0\u0304(s) } = { s | \u00acP\u03c0(s) } = { s | s /\u2208 \u03a3\u03c0 } = \u03a3\u03c0. \u22c4\n\u00a73.2.4 Lemma For a tautological problem, x?P\u03c4 (x), everything is a solution, \u03a3\u03c4 = S. For a contradictory problem, x?P\u03c4\u0304 (x), nothing is a solution, \u03a3\u03c4\u0304 = \u2205. Proof \u03a3\u03c4 = { s | P\u03c4 (s) } = { s | \u22a4 } = S. \u03a3\u03c4\u0304 = { s | P\u03c4\u0304 (s) } = { s | \u22a5 } = {} = \u2205. \u22c4\n\u00a73.2.5 Lemma \u03a3\u03c0 \u222a \u03a3\u03c0\u0304 = S and \u03a3\u03c0 \u2229 \u03a3\u03c0\u0304 = \u2205. Proof \u03a3\u03c0 \u222a\u03a3\u03c0\u0304 = { s | P\u03c0(s) }\u222a { s | \u00acP\u03c0(s) } = { s | P\u03c0(s)\u2228\u00acP\u03c0(s) } = { s | \u22a4 } = S.\n\u03a3\u03c0 \u2229 \u03a3\u03c0\u0304 = { s | P\u03c0(s) } \u2229 { s | \u00acP\u03c0(s) } = { s | P\u03c0(s) \u2227 \u00acP\u03c0(s) } = { s | \u22a5 } = \u2205. \u22c4\n\u00a73.2.6 Lemma The solutions of \u03c0 \u2227 \u03c1 are solutions of \u03c0 and of \u03c1. Proof \u2200s \u2208 S; s \u2208 \u03a3\u03c0\u2227\u03c1 \u21d4 s \u2208 \u03a3\u03c0 \u2229 \u03a3\u03c1 \u21d4 s \u2208 \u03a3\u03c0 \u2227 s \u2208 \u03a3\u03c1. \u22c4 Comment The reader is free to explore this Boolean landscape, but here we will close\nwith the following theorems.\n\u00a73.2.7 Theorem \u30082S,\u222a,\u2229,\u2212, \u2205, S\u3009 is a Boolean algebra, where \u2205 is the neutral for \u222a, and S is the neutral for \u2229. Proof The powerset of a set M , with the operations of union \u222a, intersection \u2229, and complement with respect to setM , noted Q, is a typical example of a Boolean algebra. In detail, \u2200Q,R, S \u2208 2S: 1o. (Q \u222a R) \u222a S = Q \u222a (R \u222a S). 1a. (Q \u2229R) \u2229 S = Q \u2229 (R \u2229 S). 2o. Q \u222a R = R \u222aQ. 2a. Q \u2229R = R \u2229Q. 3o. Q \u222a \u2205 = Q. 3a. Q \u2229 S = Q. 4o. Q \u222aQ = S. 4a. Q \u2229Q = \u2205. 5o. Q \u222a (R \u2229 S) = (Q \u222a R) \u2229 (Q \u222a S). 5a. Q \u2229 (R \u222a S) = (Q \u2229 R) \u222a (Q \u2229 S). \u22c4\n\u00a73.2.8 Theorem \u3008P,\u2228,\u2227,\u00ac, \u03c4\u0304 , \u03c4\u3009 is isomorphic to \u30082S,\u222a,\u2229,\u2212, \u2205, S\u3009, that is, P \u223c= 2S. Proof We define the bijection \u03a3 that relates each problem \u03c0 with the set of its solutions\n\u03a3\u03c0: for every problem \u03c0 \u2208 P there is a set, the set of its solutions, \u03a3\u03c0 \u2208 2S, and for every set S \u2208 2S there is a problem, \u03c0S = x? [x \u2208 S], where \u03c0S \u2208 P. Now, by Lemma \u00a73.2.3, the bijection translates properly all three operations, \u2228 \u2194 \u222a, \u2227 \u2194 \u2229, \u00ac \u2194 \u2212, and, by Lemma \u00a73.2.4, also the two neutrals, \u03c4\u0304 \u2194 \u2205, \u03c4 \u2194 S. \u22c4 Comment We will call P \u223c= 2S the set isomorphism. That is, P \u21d4 2S : \u03c0 \u2194 \u03a3\u03c0. Comment Using the set isomorphism, two problems are equal if they have the same\nsolutions, that is, \u03c0 = \u03c1 \u21d4 \u03a3\u03c0 = \u03a3\u03c1.\n\u00a73.2.9 Theorem The set of problems is equal to the powerset of the solutions, that is, P = 2S. Proof The equality P = 2S derives directly from the set isomorphism P \u223c= 2S, see \u00a73.2.8, because no property was abstracted out. \u22c4\n\u00a73.2.10 Definition The set of singletons is: S1 = {S \u2208 2S | [ |S| = 1 ] }. Proposition S1 \u2282 2S, because \u2200S \u2208 S1, S \u2208 2S, but \u2205 \u2208 2S and \u2205 /\u2208 S1.\n\u00a73.2.11 Definition The singleton isomorphism is the isomorphism between S and S1 that relates each s \u2208 S to the set {s} \u2208 S1, and the converse. That is, S \u223c= S1, and S \u21d4 S1 : s \u2194 {s}.\nComment We can extend any operation on S to S1. For example, for any binary operation \u2217 on S, we define {a} \u2217 {b} = {a \u2217 b}. Comment From the singleton isomorphism: S \u223c= S1 \u2282 2S.\n\u00a73.2.12 Lemma The set of solutions S is a proper subset of the set of problems P, that is, S \u2282 P. Proof By the singleton isomorphism, see \u00a73.2.11, S \u223c= S1, and, by the set isomorphism, see \u00a73.2.8, for each singleton there is a problem, so S1 \u2282 P, and then S \u223c= S1 \u2282 P. \u22c4 Paradox We have both, S \u2282 P and, by \u00a73.2.1, P \u2282 S. Comment If we only accept computable functions and computable sets, then S\u2217 6\u2282 P\u2217,\nsee Subsection \u00a76.2.\n\u00a73.2.13 Definition A problem \u03c0 is solved if a solution of \u03c0 is known. Comment To solve a problem, given the set of its solutions \u03a3\u03c0, a choice function\nfc : 2 S \\ \u2205 \u2192 S is needed.\n\u00a73.2.14 Definition A problem is unsolvable if \u03a3\u03c0 = {} = \u2205, that is, if |\u03a3\u03c0| = 0. A problem is solvable if |\u03a3\u03c0| > 0.\nComment If a problem has not any solution, then it is unsolvable. If a problem has a solution, then it can be solved. A problem is solvable if it can be solved. Comment Solved implies solvable, but not the converse: Solved \u21d2 Solvable.\n\u00a73.3 Routines and Trials\n\u00a73.3.1 Definition We will refer to the routine of problem \u03c0 as R\u03c0. The routine is the set of the solutions to the problem, a set that is known, see \u00a72.3. Then R\u03c0 = \u03a3\u03c0.\nComment The routine of problem \u03c0, R\u03c0, is then, or an extensive definition of \u03a3\u03c0, \u03a3\u03c0 = {s1, . . . , sn}, or a procedure P that generates all problem \u03c0 solutions and then halts. If the number of solutions is infinite, |\u03a3\u03c0| \u2265 \u21350, then R\u03c0 has to be a procedure P that keeps generating solutions forever.\n\u00a73.3.2 Definition A trial on problem \u03c0 over the set of possible solutions S, written T\u03c0(S), returns the set of those elements in S that satisfy the problem condition P\u03c0, see \u00a72.3. Then T\u03c0(S) = { s \u2208 S | P\u03c0(s) }.\nComment Mathematically we will ignore the practical problem of governing the trial. Practically we will need a halt condition to truncate the calculations that are too long (or infinite), and some ordering on the tests to fit the execution of the tests to the available calculating machinery.\n\u00a73.3.3 Definition To test if a possible solution s \u2208 S is a solution to problem \u03c0, is to replace the free variable with s. So, being \u03c0 = x?P\u03c0(x), then to test if s is a solution is to calculate P\u03c0(s). Comment Testing is a calculation S \u2192 B.\n\u00a73.3.4 Remark Replacing variables in expressions requires not confusing free with bound variables, nor bound with free variables.\nComment This means that the rule of \u03b2-conversion and the rules \u03b3 for substitution stand for testing. See Curry & Feys (1958), Section 3D for \u03b2-conversion, and Section 3E for substitution (the rules \u03b3).\n\u00a73.3.5 Theorem A trial on problem \u03c0 over the set S is equal to the intersection of S with the set of the solutions \u03a3\u03c0, that is, T\u03c0(S) = S \u2229 \u03a3\u03c0. Proof T\u03c0(S) = { s \u2208 S | P\u03c0(s) } = { s | s \u2208 S \u2227 P\u03c0(s) } = { s | s \u2208 S \u2227 s \u2208 \u03a3\u03c0 } = { s | s \u2208 S } \u2229 { s | s \u2208 \u03a3\u03c0 } = S \u2229 \u03a3\u03c0. \u22c4 Corollary Any trial is a subset of the set of solutions, T\u03c0(S) \u2286 \u03a3\u03c0. Proof T\u03c0(S) = S \u2229 \u03a3\u03c0 \u2286 \u03a3\u03c0. \u22c4 Corollary Any trial is a subset of the routine, that is, T\u03c0(S) \u2286 \u03a3\u03c0 = R\u03c0.\n\u00a73.3.6 Lemma If S is a superset of \u03a3\u03c0, then a trial on problem \u03c0 over S is equal to \u03a3\u03c0, and the converse, that is, \u03a3\u03c0 \u2286 S \u21d4 T\u03c0(S) = \u03a3\u03c0. Proof \u03a3\u03c0 \u2286 S \u21d4 S \u2229 \u03a3\u03c0 = \u03a3\u03c0 \u21d4 T\u03c0(S) = \u03a3\u03c0, using Theorem \u00a73.3.5. \u22c4 Corollary If S is a superset of \u03a3\u03c0, then a trial on problem \u03c0 over S is equal to the\nroutine of \u03c0, and the converse, that is, \u03a3\u03c0 \u2286 S \u21d4 T\u03c0(S) = R\u03c0. Proof \u03a3\u03c0 \u2286 S \u21d4 S \u2229 \u03a3\u03c0 = \u03a3\u03c0 \u21d4 T\u03c0(S) = R\u03c0. \u22c4 Corollary A trial on problem \u03c0 over the whole S is equal to \u03a3\u03c0, that is, T\u03c0(S) = \u03a3\u03c0. Proof Because \u03a3\u03c0 \u2286 S. \u22c4 Comment T\u03c0(S) is an exhaustive search.\n\u00a73.3.7 Theorem The routine is a trial over all the solutions, that is, R\u03c0 = T\u03c0(\u03a3\u03c0). Proof By Theorem \u00a73.3.5, T\u03c0(\u03a3\u03c0) = \u03a3\u03c0 \u2229 \u03a3\u03c0 = \u03a3\u03c0 = R\u03c0. \u22c4 Comment T\u03c0(R\u03c0) = T\u03c0(\u03a3\u03c0) = \u03a3\u03c0 = R\u03c0.\n\u00a73.4 Analogies\n\u00a73.4.1 Definition If A is an analogy, and \u03c0 = x?P\u03c0(x) is a problem, then A\u03c0 is another problem A\u03c0 = x?PA\u03c0(x). That is, A : P \u2192 P.\nComment So analogies transform a condition into a condition, P\u03c0 into PA\u03c0 in this example. Comment Taking advantage of problem decomposition, see \u00a73.1.10, the result of an analogy, A\u03c0, can be a composition of problems that are easier to resolve than the original problem, \u03c0, see \u00a72.3.\n\u00a73.4.2 Definition If \u03a3\u03c0 = \u03a3A\u03c0, then we say that the analogy is conservative. Comment If an analogy is not conservative, then a function TA to translate \u03a3A\u03c0 to \u03a3\u03c0\nis required, because otherwise the analogy would be useless.\n\u00a73.4.3 Notation We will call function TA the translating function of analogy A. TA : 2S \u2192 2S and TA(\u03a3A\u03c0) = \u03a3\u03c0.\n\u00a73.4.4 Lemma An analogy followed by another one is an analogy. Proof Because any analogy transforms a problem into a problem: P \u2192 P. \u22c4 Corollary Analogies can be chained.\n\u00a73.4.5 Lemma Using only analogies we cannot resolve any problem. Proof Because using analogies we only get problems. \u22c4 Comment While routines R and trials T (S) are functions that return a set, P \u2192 2S,\nanalogies A are functions that return a function, P \u2192 P. \u00a73.4.6 Notation We will write A \u25e6 T to express the composition of functions, where\nA is applied first and then T .\nComment [A \u25e6 T ](x) = T (A(x)). Diagram: x A\u2212\u2212\u2192A(x) T\u2212\u2212\u2192T (A(x)). Comment If A1 and A2 are analogies, then A1\u25e6A2 is also an analogy, by Lemma \u00a73.4.4. \u00a73.4.7 Definition To resolve a problem by analogy A is to compose A\u25e6\u211c\u25e6TA, where\n\u211c is any resolution, and TA is the translating function of A. Diagrams:\n\u03c0 A\u2212\u2212\u2192A\u03c0 \u211c\u2212\u2212\u2192\u03a3A\u03c0 TA\u2212\u2212\u2192\u03a3\u03c0 or P A\u2212\u2212\u2192P \u211c\u2212\u2212\u2192 2S TA\u2212\u2212\u2192 2S .\nComment Analogy A is a translation from some original problem domain to some analogue problem domain. Then, by Lemma \u00a73.4.5, we need a resolution \u211c to resolve the analogue problem. And, finally, we need to translate the solutions back to the original domain.\n\u00a73.4.8 Lemma The translating function of the composition A \u25e6 A\u2032 is TA\u2032 \u25e6 TA. Proof If \u211c = A\u2032 \u25e6\u211c\u2032 \u25e6 TA\u2032 then we get A \u25e6 (A\u2032 \u25e6\u211c\u2032 \u25e6 TA\u2032) \u25e6 TA = A \u25e6A\u2032 \u25e6\u211c\u2032 \u25e6 TA\u2032 \u25e6 TA =\n(A \u25e6 A\u2032) \u25e6 \u211c\u2032 \u25e6 (TA\u2032 \u25e6 TA), because function composition is associative. Diagram:\nP A\u2212\u2212\u2192P A\n\u2032 \u2212\u2212\u2192P \u211c \u2032 \u2212\u2212\u2192 2S TA\u2032\u2212\u2212\u2212\u2192 2S \ufe38 \ufe37\ufe37 \ufe38\n\u211c\nTA\u2212\u2212\u2192 2S. \u22c4\nCorollary The translating function of the composition A1 \u25e6A2 . . . \u25e6An is TAn \u25e6 . . . \u25e6 TA2 \u25e6 TA1. That is: TA1\u25e6A2...\u25e6An = TAn \u25e6 . . . \u25e6 TA2 \u25e6 TA1 . Comment This is how analogies can be chained.\n\u00a73.4.9 Definition The identity function, written I, transforms anything into itself: \u2200x, I(x) = x. Comment The identity function I is an effectively calculable function, see \u00a73.1.5. It is \u03bb-definable; in \u03bb-calculus, I = (\u03bbx.x).\nComment Identity I transforms \u03c0 into \u03c0, I(\u03c0) = \u03c0, and P\u03c0 into P\u03c0, I(P\u03c0) = P\u03c0. Comment Identity I can work as an analogy: I\u03c0 = I(\u03c0) = \u03c0.\n\u00a73.4.10 Lemma The translating function of the identity analogy is the identity function: TI = I. Proof Because I(\u03a3\u03c0) = \u03a3\u03c0. Diagram: \u03c0 I\u2212\u2192\u03c0 \u211c\u2212\u2212\u2192\u03a3\u03c0 I\u2212\u2192\u03a3\u03c0. \u22c4 Comment The identity analogy is conservative, see \u00a73.4.2. \u00a73.4.11 Lemma The identity I followed by any function f , or any function f followed\nby identity I, is equal to the function: \u2200f, I \u25e6 f = f = f \u25e6 I. Proof \u2200f, \u2200x, [I \u25e6 f ](x) = f(I(x)) = f(x) = I(f(x)) = [f \u25e6 I](x). \u22c4 Comment I \u25e6 \u211c(I\u03c0) \u25e6 TI = I \u25e6 \u211c(\u03c0) \u25e6 I = \u211c(\u03c0).\n\u00a73.4.12 Theorem A \u25e6 TA\u03c0(S) \u25e6 TA, where A is an analogy, TA\u03c0(S) is a trial, and TA is the translating function of A, is the general form of a resolution.\nProof If the analogy is the identity I, then the general form is reduced to T\u03c0(S), because TI = I, I\u03c0 = \u03c0, so I\u25e6TI\u03c0(S)\u25e6I = T\u03c0(S), which is a trial. By Theorem \u00a73.3.7, a routine is a specific trial, R\u03c0 = T\u03c0(R\u03c0), so I \u25e6 T\u03c0(R\u03c0) \u25e6 I = T\u03c0(R\u03c0) = R\u03c0 reduces the general form to the routine. Resolving by analogy is, by definition, A \u25e6 \u211c \u25e6 TA, and analogies can be chained, by Lemma \u00a73.4.4, so a chain of analogies is an analogy, A1\u25e6A2\u25e6 . . .\u25e6An = A, and by Lemma \u00a73.4.8, TA = TA1\u25e6A2\u25e6...\u25e6An = TAn \u25e6 . . .\u25e6TA2 \u25e6TA1 . Then A1 \u25e6 A2 \u25e6 . . . \u25e6 An \u25e6 TA\u03c0(S) \u25e6 TAn \u25e6 . . . \u25e6 TA2 \u25e6 TA1 = A \u25e6 TA\u03c0(S) \u25e6 TA. \u22c4 Summary There are three ways to resolve a problem: routine R\u03c0 = I \u25e6T\u03c0(R\u03c0)\u25e6 I, trial T\u03c0(S) = I\u25e6T\u03c0(S)\u25e6I, and analogy A1\u25e6. . .\u25e6An\u25e6TA\u03c0(S)\u25e6TAn\u25e6. . .\u25e6TA1 = A\u25e6TA\u03c0(S)\u25e6TA.\n\u00a73.5 Metaproblems\n\u00a73.5.1 Definition A resolution \u211c : P \u2192 2S is a valid resolution for a problem \u03c0 if it finds all the solutions of problem \u03c0 and then halts. In other words, \u211c is a valid resolution for \u03c0 if it satisfies two conditions: that \u211c(\u03c0) is effectively calculable, and that \u211c fits problem \u03c0, that is, that \u211c(\u03c0) = \u03a3\u03c0. Comment If \u03a3\u03c0 is infinite, |\u03a3\u03c0| \u2265 \u21350, then a valid \u211c(\u03c0) does not halt, but it keeps building \u03a3\u03c0 forever.\n\u00a73.5.2 Definition A problem \u03c0 is resolved if a valid resolution for \u03c0 is known. Comment To solve a problem we have to find one solution, see \u00a73.2.13. To resolve a\nproblem we have to find all the solutions. To resolve a problem is to exhaust the problem.\n\u00a73.5.3 Lemma Once a problem is resolved, we can thereafter resolve it by routine. Proof Once a problem is resolved, we know all of its solutions, \u03a3\u03c0, and knowing \u03a3\u03c0,\nwe know its routine resolution, because R\u03c0 = \u03a3\u03c0, see \u00a73.3.1. \u22c4 Proposition If \u03c0 \u2227 \u03c1 is solvable, then by resolving \u03c0 \u2227 \u03c1 both \u03c0 and \u03c1 are solved. \u00a73.5.4 Definition A problem is resolvable if there is a valid resolution for the problem,\nsee \u00a73.5.1, that is, if there is a resolution \u211c such that \u211c(\u03c0) is effectively calculable, and \u211c(\u03c0) = \u03a3\u03c0. Otherwise, the problem is unresolvable.\nComment A problem is resolvable if it can be resolved. Comment Resolved implies resolvable, but not the converse: Resolved \u21d2 Resolvable. \u00a73.5.5 Definition For any Boolean-valued function P : S \u2192 B, we define the function\nP\u030c : B \u2192 2S, called the inverse of condition P , as follows:\nP\u030c (\u22a4) = { x | [P (x) = \u22a4] }, P\u030c (\u22a5) = { x | [P (x) = \u22a5] }.\n\u00a73.5.6 Lemma If P\u03c0(x) is the condition of a problem \u03c0, then P\u030c\u03c0(\u22a4) = \u03a3\u03c0 and P\u030c\u03c0(\u22a5) = \u03a3\u03c0 = \u03a3\u03c0\u0304. Proof Because P\u030c\u03c0(\u22a4) = { x | [P\u03c0(x) = \u22a4] } = { x | P\u03c0(x) } = \u03a3\u03c0, and P\u030c\u03c0(\u22a5) = { x | [P\u03c0(x) = \u22a5] } = { x | \u00acP\u03c0(x) } = \u03a3\u03c0 = \u03a3\u03c0\u0304, by Lemma \u00a73.2.3. \u22c4\n\u00a73.5.7 Theorem The inverse of the condition of a problem, provided it is an effectively calculable function, resolves the problem and its complementary by routine. Proof By \u00a73.5.6 and \u00a73.3.1, P\u030c\u03c0(\u22a4) = \u03a3\u03c0 = R\u03c0, then P\u030c\u03c0(\u22a4) is the routine resolution of \u03c0, if P\u030c\u03c0(\u22a4) is effectively calculable, see \u00a73.1.5. And if P\u030c\u03c0(\u22a5) is effectively calculable, then it resolves the complementary problem by routine, P\u030c\u03c0(\u22a5) = \u03a3\u03c0\u0304 = R\u03c0\u0304. \u22c4\nComment It is a nice theorem, but how can we find the inverse of a condition?\n\u00a73.5.8 Definition The metaproblem of a problem, written \u03a0\u03c0, is the problem of finding the valid resolutions for problem \u03c0. In other words, if \u03c0 = x?P\u03c0(x), then \u03a0\u03c0 = \u211c? [\u211c(\u03c0) = \u03a3\u03c0].\nComment The solutions of the metaproblems are the resolutions, \u03a0S = R. Comment The condition of the metaproblem, P\u03a0\u03c0, is [\u211c(\u03c0) = \u03a3\u03c0], that is, P\u03a0\u03c0(\u211c) =\n[\u211c(\u03c0) = \u03a3\u03c0], or using an \u03b1-conversion, P\u03a0\u03c0(x) = [x(\u03c0) = \u03a3\u03c0]. \u00a73.5.9 Lemma A metaproblem is a problem, that is, \u03a0P \u2282 P. Proof Because \u03a0\u03c0 = x?P\u03a0\u03c0(x), but some problems are not metaproblems. \u22c4 Comment A metaproblem is a problem because it has its two ingredients: there are\nseveral ways to resolve a problem, so there is freedom, but only the valid resolutions resolve the problem, so there is a condition.\n\u00a73.5.10 Definition The metacondition P\u03a0 is P\u03a0(p, r) = [r(p) = \u03a3p], for any problem p \u2208 P, and for any resolution r \u2208 R.\nComment Using another \u03b1-conversion, P\u03a0(\u03c0, x) = [x(\u03c0) = \u03a3\u03c0] = P\u03a0\u03c0(x). Comment \u03a0\u03c0 = x?P\u03a0(\u03c0, x).\n\u00a73.5.11 Definition Metaresolving is resolving the metaproblem to resolve the problem.\nComment Metaresolving is a kind of analogy. Diagram:\n\u03c0 \u03a0\u2212\u2212\u2192\u03a0\u03c0 \u03a0\u211c\u2212\u2212\u2212\u2192\u03a3\u03a0\u03c0 = {\u211c | [\u211c(\u03c0) = \u03a3\u03c0] } fc\u2212\u2212\u2192\u211cc (\u03c0)\u2212\u2212\u2192\u211cc(\u03c0) = \u03a3\u03c0 .\nFunction fc is a choice function, and the last calculation, noted (\u03c0), means to apply \u03c0 as the argument, not as the function. If you only metasolve, then you don\u2019t need to choose. In any case, the translating function of metaresolving is T\u03a0 = fc \u25e6 (\u03c0). Then we can draw the following diagrams:\n\u03c0 \u03a0\u2212\u2212\u2192\u03a0\u03c0 \u03a0\u211c\u2212\u2212\u2212\u2192\u03a3\u03a0\u03c0 T\u03a0\u2212\u2212\u2192\u03a3\u03c0 or P \u03a0\u2212\u2212\u2192\u03a0P \u03a0\u211c\u2212\u2212\u2212\u2192 2\u03a0S = 2R T\u03a0\u2212\u2212\u2192 2S .\n\u00a73.5.12 Lemma The metaproblem \u03a0\u03c0 of some problem \u03c0 is solvable if, and only if, the problem \u03c0 is resolvable, that is, \u03a0\u03c0 is solvable \u21d4 \u03c0 is resolvable. Proof If \u03a0\u03c0 is solvable, then there is a solution to it, see \u00a73.2.14, and that solution is a valid resolution for \u03c0, see \u00a73.5.8, and then \u03c0 is resolvable, see \u00a73.5.4. If \u03c0 is resolvable, then there is a valid resolution for it, see \u00a73.5.4, and that resolution is a solution of its metaproblem \u03a0\u03c0, see \u00a73.5.8, and then \u03a0\u03c0 is solvable, see \u00a73.2.14. \u22c4\nCorollary To solve the metaproblem \u03a0\u03c0 of problem \u03c0 is to resolve problem \u03c0. Proof Because to resolve problem \u03c0 is to find a valid resolution for \u03c0, see \u00a73.5.2, and\nto solve the metaproblem \u03a0\u03c0 is to find a solution to \u03a0\u03c0, see \u00a73.2.13, which is also to find a valid resolution for \u03c0, see \u00a73.5.8. \u22c4\nComment And again, R = \u03a0S.\n\u00a73.5.13 Lemma The set of the valid resolutions for problem \u03c0 is the routine resolution of its metaproblem \u03a0\u03c0, that is, {\u211c | [\u211c(\u03c0) = \u03a3\u03c0] } = R\u03a0\u03c0. Proof R\u03a0\u03c0 = \u03a3\u03a0\u03c0, by the definition of routine, see \u00a73.3.1. And \u03a3\u03a0\u03c0 = {\u211c | [\u211c(\u03c0) = \u03a3\u03c0] }, by the definition of \u03a0\u03c0, see \u00a73.5.8. \u22c4\n\u00a73.6 Resolution Typology\n\u00a73.6.1 Definition The metan-metaproblem of \u03c0, \u03a0n\u03a0\u03c0, is (the metaproblem of)n the metaproblem of \u03c0, where n \u2208 N. Special case The meta-metaproblem of \u03c0, \u03a0\u03a0\u03c0 = \u03a01\u03a0\u03c0, is the metaproblem of the metaproblem of \u03c0. Examples \u03a00\u03a0\u03c0 = \u03a0\u03c0. \u03a01\u03a0\u03c0 = \u03a0\u03a0\u03c0 = \u03a02\u03c0. \u03a02\u03a0\u03c0 = \u03a0\u03a0\u03a0\u03c0 = \u03a03\u03c0. Comment From \u03a0S = R, we get \u03a0\u03a0S = \u03a0R and \u03a0n\u03a0S = \u03a0nR. Comment The condition of the metan-metaproblem of \u03c0, P\u03a0n\u03a0\u03c0, where n \u2208 N, is:\nP\u03a0n\u03a0\u03c0(x) = [x(\u03a0 n\u03c0) = \u03a3\u03a0n\u03c0].\nExamples P\u03a00\u03a0\u03c0(x) = [x(\u03a0 0\u03c0) = \u03a3\u03a00\u03c0] = [x(\u03c0) = \u03a3\u03c0] = P\u03a0\u03c0(x).\nP\u03a01\u03a0\u03c0(x) = [x(\u03a0 1\u03c0) = \u03a3\u03a01\u03c0] = [x(\u03a0\u03c0) = \u03a3\u03a0\u03c0] = P\u03a0\u03a0\u03c0(x).\n\u00a73.6.2 Lemma A metan-metaproblem is a problem, where n \u2208 N. Proof If n > 0, then \u03a0n\u03a0\u03c0 = x?P\u03a0n\u03a0\u03c0(x). For n = 0, see \u00a73.5.9. \u22c4 Corollary \u22c3\nn\u2208N \u03a0 n\u03a0P \u2282 P.\n\u00a73.6.3 Definition The metan-metacondition P\u03a0n\u03a0, with n \u2208 N, p \u2208 P, and r \u2208 R is: P\u03a0n\u03a0(p, r) = [r(\u03a0\nnp) = \u03a3\u03a0np]. Comment Using an \u03b1-conversion, P\u03a0n\u03a0(\u03c0, x) = [x(\u03a0\nn\u03c0) = \u03a3\u03a0n\u03c0] = P\u03a0n\u03a0\u03c0(x). Example P\u03a01\u03a0(\u03c0, x) = P\u03a0\u03a0(\u03c0, x) = [x(\u03a0\u03c0) = \u03a3\u03a0\u03c0] = [x(\u03a0 1\u03c0) = \u03a3\u03a01\u03c0].\n\u00a73.6.4 Lemma P\u03a0n\u03a0(\u03c0, x) = P\u03a0(\u03a0n\u03c0, x), where n \u2208 N. Proof By \u00a73.5.10, P\u03a0(\u03a0n\u03c0, x) = [x(\u03a0n\u03c0) = \u03a3\u03a0n\u03c0] = P\u03a0n\u03a0(\u03c0, x). \u22c4 Special Case P\u03a0\u03a0(\u03c0, x) = P\u03a0(\u03a0\u03c0, x). Comment The meta-metacondition is the metacondition of the metaproblem.\n\u00a73.6.5 Lemma A metan-metaproblem is a metaproblem, where n \u2208 N. Proof If n > 0, \u03a0n\u03a0\u03c0 = x?P\u03a0(\u03a0\nn\u03c0, x), and \u03a00\u03a0\u03c0 = \u03a0\u03c0 = x?P\u03a0(\u03c0, x). \u22c4 Corollary \u22c3\nn\u2208N \u03a0 n\u03a0P = \u03a0P.\n\u00a73.6.6 Lemma We have the following infinite series of mathematical objects: S, P = 2S, R = \u03a0S = 2S \u2192 2S, \u03a0P = 22S\u21922S , \u03a0R = \u03a0\u03a0S = 22S\u21922S \u2192 22S\u21922S , . . . Proof P = S \u2192 B = 2S, by Theorems \u00a73.1.8 and \u00a73.2.9. \u03a0S = R, by the metaproblem definition, see \u00a73.5.8, and R = P \u2192 2S = 2S \u2192 2S. \u03a0P = \u03a0S \u2192 B = R \u2192 B = 2R = 22S\u21922S . \u03a0R = \u03a0P \u2192 2\u03a0S = 2R \u2192 2R = 22S\u21922S \u2192 22S\u21922S . And so on. \u22c4\n\u00a73.6.7 Theorem There is only one level of problem meta-ness. Proof By Lemma \u00a73.6.5, because every metan-metaproblem is a metaproblem, and\nevery metaproblem is a meta0-metaproblem, so \u22c3 n\u2208N\u03a0 n\u03a0P = \u03a0P \u2282 P. \u22c4\nComment While a problem condition is any predicate, P (x), a metaproblem condition is a specific kind of predicate, namely, P\u03a0(p, r) = [r(p) = \u03a3p]. And any meta\nnmetaproblem condition, P\u03a0n\u03a0, is the same specific predicate P\u03a0, see \u00a73.6.4.\nComment We are assuming that functions are free to take functions as arguments. See that, in predicate P\u03a0(p, r) = [r(p) = \u03a3p], argument r is a function in \u03a0\nnR that takes p \u2208 \u03a0nP as argument. Therefore, the theorem holds unconditionally for \u03bb-definable functions, including predicates, see \u00a74.2.9. And then, under Church\u2019s thesis, see \u00a74.3.1, the theorem is true for effectively calculable functions, and in particular, it is true for expressible and for resolvable problems, see \u00a73.1.6 and \u00a73.5.4.\n\u00a73.6.8 Theorem There are five types of resolution. Proof From Theorem \u00a73.4.12 we get three types for the resolution of problems: R\u03c0,\nT\u03c0(S), and A \u25e6 TA\u03c0(S) \u25e6 TA. This shows that there are several ways of resolving, so choosing a resolution that find solutions to the original problem \u03c0 is another problem, the metaproblem \u03a0\u03c0, see \u00a73.5.8. Then we should get another three for the resolution of the metaproblem, but, by \u00a73.5.13, the set of the resolutions of a problem is the routine resolution of its metaproblem, so we only add two more for the metaproblem: T\u03a0\u03c0(R), and A \u25e6 TA\u03a0\u03c0(R) \u25e6 TA. Finally, by \u00a73.6.7, we do not need to go deeper into metan-metaproblems. \u22c4 Comment We will call them: routine R\u03c0, trial T\u03c0(S), analogy A \u25e6 TA\u03c0(S) \u25e6 TA, metatrial T\u03a0\u03c0(R), and meta-analogy A \u25e6 TA\u03a0\u03c0(R) \u25e6 TA. The first three can also be called meta-routines.\n\u00a73.6.9 Remark The diagram for the meta-trial, or trial of the metaproblem, is:\n\u03c0 \u03a0\u2212\u2212\u2192\u03a0\u03c0 T\u03a0\u03c0(R)\u2212\u2212\u2212\u2212\u2212\u2192\u03a3\u03a0\u03c0 T\u03a0\u2212\u2212\u2192\u03a3\u03c0 .\nAnd the diagram for the meta-analogy, or analogy of the metaproblem, is:\n\u03c0 \u03a0\u2212\u2212\u2192\u03a0\u03c0 A\u2212\u2212\u2192A\u03a0\u03c0 TA\u03a0\u03c0(R)\u2212\u2212\u2212\u2212\u2212\u2212\u2192\u03a3A\u03a0\u03c0 TA\u2212\u2212\u2192\u03a3\u03a0\u03c0 T\u03a0\u2212\u2212\u2192\u03a3\u03c0 .\nSee that A : \u03a0P \u2192 \u03a0P = 22S\u21922S \u2192 22S\u21922S and TA : 2\u03a0S \u2192 2\u03a0S = 22 S\u21922S \u2192 22S\u21922S , using \u00a73.6.6. Both are functions taking sets of functions on sets to sets and returning sets of functions on sets to sets.\n\u00a74 Computers\n\u00a74.1 Turing Machine\n\u00a74.1.1 Definition A computation is any manipulation of a string of symbols, irrespective of the symbols meanings, but according to a finite set of well-defined rules.\nComment Computing is any mechanical transformation of a string of symbols.\n\u00a74.1.2 Definition A computing device, or computer, is any mechanism that can perform computations.\nComment The prototype of computing device is a Turing machine, see Turing (1936).\n\u00a74.1.3 Notation The Turing machine has two parts: the processor P, which is a finite state automaton, and an infinite tape, \u3008 \u3009, which in any moment contains only a finite number of symbols.\nComment In the case of a processor of a Turing machine, the output alphabet O, that is, the finite set of output symbols, has to be: O = I+\u00d7{l, h, r}, where I is the finite not empty input alphabet, I+ = I \u222a {b}, where b /\u2208 I is blank, and l, h, and r mean left, halt, and right. Then its transition function is T : S \u00d7 I+ \u2192 S \u00d7 I+ \u00d7 {l, h, r}, where S is the finite set of internal states. And the strings that the Turing machine transforms are sequences of symbols taken from set I.\n\u00a74.1.4 Notation We will refer to the set of Turing machines as T. We will refer to the set of the strings of symbols as E.\nComment Because all Turing machines tapes are equal, the processor defines the Turing machine, and therefore we will refer to the Turing machine with processor P as the Turing machine P, and then P \u2208 T. We will refer to the string of symbols written on the tape as the expression e \u2208 E.\n\u00a74.1.5 Lemma The set of expressions is countable, that is, |E| = |N| = \u21350. Proof Let I be any finite alphabet, and s its cardinality, that is, s is the number of\nsymbols, s = |I| > 0. We write In the set of strings of length n, so |In| = sn. Then E = \u22c3\nn\u2208N I n, and we can define a bijection between E and N this way: it maps the\nempty string in I0 to 0, it maps the s strings in I1 to the next s numbers, it maps the s2 strings in I2 to the next s2 numbers, and so on. Note that ordering the symbols in I, we can order alphabetically the strings in each In. \u22c4 Comment Most real numbers are not expressible. See Turing (1936) \u00a710 for details; but, for example, transcendental numbers \u03c0 and e are computable, page 256.\n\u00a74.1.6 Notation We will use the notation P\u3008e\u3009 \u2192\u0592 r to indicate that, if we write the expression e \u2208 E on the tape of the Turing machine with processor P and we leave it running, then when it halts we will find the expression r \u2208 E on the tape. If, on the contrary, the Turing machine P does not halt when we write the expression w, then we would say that w is a paradox in P, and we would indicate this as follows: P\u3008w\u3009 \u2192\u0592 \u221e.\n\u00a74.1.7 Definition E+ = E \u222a {\u221e}. Comment Some computations do not halt, so we need \u221e to refer to them. Note that\n\u221e /\u2208 E, but \u221e \u2208 E+. So E \u2282 E+.\n\u00a74.1.8 Definition For each Turing machine P \u2208 T we define a function FP : E \u2192 E+, this way:\nFP(e) = { r if P\u3008e\u3009 \u2192\u0592 r \u221e if P\u3008e\u3009 \u2192\u0592 \u221e .\nComment If \u2200e \u2208 E, FP(e) = FQ(e), then we say that Turing machines P and Q are behaviorally equivalent, P \u2261F Q, or that P and Q implement the same function.\n\u00a74.1.9 Definition We say that a function is computable if there is a Turing machine that implements the function.\n\u00a74.1.10 Lemma For each Turing machine we can define a unique finite string of symbols, that is, \u2203c : T \u2192 E such that P = Q \u21d4 c(P) = c(Q). Proof Proved by Turing (1936), \u00a75. Turing machines are defined by their processors, which are finite state automata. And every finite state automaton is defined by the table that describes its transition function T in full, which is a finite table of expressions referring to internal states, input symbols, and output symbols. A table can be converted to a string just using an additional symbol for the end of line, and another symbol for the end of cell. To assure uniqueness, we have to impose some order on the lines and on the cells. \u22c4 Comment c(P) \u2208 E is the string of symbols that represents the Turing machine P \u2208 T. \u00a74.1.11 Notation We will refer to p = c(P) as a program, and to the set of programs\nas P. The set of programs is a proper subset of the set of expressions, P \u2282 E. \u00a74.1.12 Definition The program isomorphism is the natural isomorphism that relates\neach Turing machine P \u2208 T with the expression describing it, c(P) = p \u2208 P. That is, T \u21d4 P : P \u2194 c(P). Comment Now, T \u223c= P \u2282 E. \u00a74.1.13 Lemma The set of Turing machines is countable, that is, |T| = |N| = \u21350. Proof Proved by Turing (1936), \u00a75. Using the program isomorphism, see \u00a74.1.12, we\norder the Turing machines according to its corresponding program p = c(P). We can order the programs, because they are finite strings of symbols, for example first by length, and then those of a given length by some kind of alphabetical order. Once ordered, we can assign a natural number to each one. \u22c4\n\u00a74.1.14 Theorem All computing sets are countable, that is, |T| = |E| = \u21350. Proof By Lemmas \u00a74.1.5 and \u00a74.1.13. \u22c4 Comment All computing is about countable sets. Computing is counting.\n\u00a74.2 Turing Completeness\n\u00a74.2.1 Theorem There is a Turing machine, called universal Turing machine, U , that can compute anything that any Turing machine can compute. That is:\n\u2203U \u2208 T | \u2200P \u2208 T, \u2200d \u2208 E, U\u3008c(P) d\u3009 = P\u3008d\u3009.\nProof Proved by Turing (1936), \u00a76 and \u00a77. \u22c4 Comment The equality means that if P\u3008d\u3009 \u2192\u0592 r then U\u3008c(P) d\u3009 \u2192\u0592 r, and the converse,\nand also that if P\u3008d\u3009 \u2192\u0592 \u221e then U\u3008c(P) d\u3009 \u2192\u0592 \u221e, and the converse. That is, U\u3008c(P)\u3009 \u2261F P. To complete the definition, if e /\u2208 P, then U\u3008e d\u3009 \u2192\u0592 e d.\n\u00a74.2.2 Notation We will refer to the set of universal Turing machines as U. Comment The set of universal Turing machines is a proper subset of the set of Turing\nmachines, U \u2282 T. \u00a74.2.3 Lemma For each universal Turing machine U there is a universal program u. Proof Universal Turing machines are Turing machines, and u = c(U). Then, by the\nprogram isomorphism, see \u00a74.1.12, u = U . \u22c4 Comment Given u = c(U) and p = c(P), then U\u3008p d\u3009 = P\u3008d\u3009 and U\u3008u p d\u3009 = U\u3008p d\u3009,\nso u is the identity for programs, and U\u3008u u p d\u3009 = U\u3008u p d\u3009 = U\u3008p d\u3009 = P\u3008d\u3009.\n\u00a74.2.4 Definition The terminating condition P\u03c3 : T \u2192 B is:\nP\u03c3(P) = {\u22a5 if \u2203w \u2208 E, P\u3008w\u3009 \u2192\u0592 \u221e \u22a4 otherwise .\nComment A terminating Turing machine always halts. There are not paradoxes in a terminating Turing machine. While Turing machines implement partial functions, E \u2192 E+, see \u00a74.1.8, terminating Turing machines implement total functions, E \u2192 E.\n\u00a74.2.5 Definition The terminating problem is \u03c3 = p?P\u03c3(p). The non-terminating problem is \u03c3\u0304 = p? \u00acP\u03c3(p).\nComment The terminating problem follows from the condition isomorphism of problems, see \u00a73.1.7, applied to the terminating condition P\u03c3. The non-terminating problem is derived from the terminating one by negation, see \u00a73.1.10.\nComment The set of terminating Turing machines is \u03a3\u03c3, and the set of non-terminating Turing machines is \u03a3\u03c3\u0304. Proposition \u03a3\u03c3 and \u03a3\u03c3\u0304 are a partition of T, because \u03a3\u03c3 \u2229\u03a3\u03c3\u0304 = \u2205 and \u03a3\u03c3 \u222a\u03a3\u03c3\u0304 = T. \u00a74.2.6 Definition We will call a = c(P\u03c3) \u2208 E, where P\u03c3 \u2208 \u03a3\u03c3, an algorithm. Comment \u2200d, P\u03c3\u3008d\u3009 \u2192\u0592 r 6= \u221e \u21d4 \u2200d, U\u3008a d\u3009 \u2192\u0592 r 6= \u221e. Comment An algorithm is the expression of a computation that always halts. Notation We will refer to the set of algorithms as A. Comment A \u2282 P \u2282 E. \u00a74.2.7 Lemma Universal Turing machines are non-terminating, that is, U \u2282 \u03a3\u03c3\u0304 \u2282 T. Proof Because there are paradoxes in some Turing machines. For example, for Turing\nmachine W, that has not any h (halt) in its transition table, every expression is a paradox. That is, \u2203P \u2208 T, \u2203w \u2208 E, P\u3008w\u3009 \u2192\u0592 \u221e \u21d2 \u2200U \u2208 U, U\u3008c(P) w\u3009 \u2192\u0592 \u221e. \u22c4 Comment If expression w is a paradox in P, then expression c(P) w is a paradox in U . Then, U \u2208 \u03a3\u03c3\u0304.\n\u00a74.2.8 Definition A computing device is Turing complete if it can compute whatever any Turing machine can compute. We will call every Turing complete device a universal computer. Comment The prototype of universal computer is a universal Turing machine, U . Comment The Turing machine, as it was presented by Turing (1936), models the\ncalculations done by a person. This means that we can compute whatever any Turing machine can compute provided we have enough time and memory, and therefore we are Turing complete provided we have enough time and memory.\n\u00a74.2.9 Theorem All universal computers are equivalent. Proof Go\u0308del and Herbrand recursiveness, Church \u03bb-definability, and Turing com-\nputability are equivalent, because Kleene (1936) showed that every recursive function is \u03bb-definable, and the converse, and then Turing (1937) showed that every \u03bb-definable function is computable, and that every computable function is recursive. \u22c4\nComment A universal Turing machine is equivalent to a \u03bb-calculus interpreter, where a \u03bb-calculus interpreter is a device that can perform any \u03bb-calculus reduction. A universal Turing machine is equivalent to a mathematician calculating formally, and without errors, any recursive function.\nComment The universal Turing machine, the \u03bb-calculus interpreter, and the mathematician, who is a person, are equal in computing power. And all of them are Turing complete.\n\u00a74.2.10 Proviso Whenever we apply a general statement to a finite universal computing device, we should add a cautious \u2018provided it has enough time and memory\u2019.\nComment Although the finite universal computer can perform each and every step of the computation exactly the same as the unrestricted universal computer, the finite universal computer could meet some limitations of time or memory that would prevent it to complete the computation. In that case, the same finite universal computer, provided with some additional time and some more memory, would perform some more computing steps exactly the same as the unrestricted universal computer. This extension procedure can be repeated as desired to close the gap between the finite and the unrestricted universal computer.\nComment We will understand that the proviso \u2018provided it has enough time and memory\u2019 is implicitly stated whenever we refer to a finite universal computing device.\n\u00a74.2.11 Convention Because all universal computers are equivalent, we can use any of them, let us call the one used U , and then drop every U from the formulas, and just examine expressions, that is, elements in E. In case we need to note a non-halting computation, we will use \u221e.\nComment Using the convention is as if we were always looking inside the tape of U . Given a universal computer, U , computing is about expressions manipulating expressions. Example Formula U\u3008c(P) d\u3009 \u2192\u0592 r is reduced to \u3008c(P) d\u3009 \u2192\u0592 r, and even to \u3008p d\u3009 \u2192\u0592 r, using the rewriting rule: \u2200P \u2208 T, c(P) = p. If the universal computer is a \u03bb-calculus interpreter, then this is usually written as the \u03b2-reduction (p d) \u2192 r, where the left hand side is a \u03bb-application, and p is defined by some \u03bb-abstraction.\n\u00a74.2.12 Definition For each program p \u2208 P we define a function Fp : E \u2192 E+, this way:\nFp(e) = { r if \u3008p e\u3009 \u2192\u0592 r \u221e if \u3008p e\u3009 \u2192\u0592 \u221e .\nComment If \u2200e \u2208 E, Fp(e) = Fq(e), then we say that programs p and q are behaviorally equivalent, p \u2261F q, or that p and q implement the same function.\n\u00a74.2.13 Theorem \u2200P \u2208 T, FP = Fp, where p = c(P). Proof \u2200d \u2208 E, \u2200P \u2208 T, Fp(d) = FP(d), see \u00a74.1.8, because U\u3008c(P) d\u3009 = P\u3008d\u3009, by\nTheorem \u00a74.2.1, and therefore FP = Fp when the universal computer is a universal Turing machine, U . Theorem \u00a74.2.9 extends it to every universal computer. \u22c4 Comment P and p implement the same function. Comment This theorem is a consequence of the program isomorphism, see \u00a74.1.12. In\nother words, T \u223c= P implies that \u2261F \u2194 \u2261F, so P \u2261F Q \u21d4 p \u2261F q. Corollary FU = Fu, where u = c(U).\n\u00a74.3 Turing\u2019s Thesis\n\u00a74.3.1 Thesis What is effectively calculable is computable. Comment This is Church\u2019s thesis, or rather Turing\u2019s thesis, as it was expressed by\nGandy (1980). There, \u2018something is effectively calculable\u2019 if its results can be found by some purely mechanical process, see \u00a73.1.5, and \u2018computable\u2019 means that the same results will be found by some Turing machine. Then, \u2217F \u2286 T. Comment \u2018What is computable is effectively calculable\u2019, or T \u2286 \u2217F, is the converse of Turing\u2019s thesis. And it is obvious that if a Turing machine can compute a function, then the function is effectively calculable, see \u00a73.1.5, by a Turing machine. Therefore, \u2217F = T, and |\u2217F| = \u21350, by \u00a74.1.13.\n\u00a74.3.2 Remark An effectively calculable function is not an input to output mapping; it is a process to calculate the output from the input.\nExample To multiply a number expressed in binary by two we can append a \u20180\u2019 to it, which is an effectively calculable function that we will call app0. But the complete memoization of the same function, which we will call memoby2, is not effectively calculable because it would require an infinite quantity of memory. And therefore, app0 6= memoby2.\n\u00a74.3.3 Notation We will call every universe where the Turing\u2019s thesis is true a Turing universe. When we want to note that something is true in a Turing universe, we will use an asterisk, so A \u2217 = B means that A = B if the Turing\u2019s thesis stands. Examples \u2217F \u2217 = T and |\u2217F| \u2217= \u21350.\nComment The Turing\u2019s thesis affirms that this is a Turing universe. In any Turing universe the Turing\u2019s thesis is a law of nature, as it was defended by Post (1936), last paragraph. Then a Turing universe can also be called a Post universe.\nComment While the Turing\u2019s thesis is true, you can ignore the asterisks.\n\u00a74.3.4 Theorem Universal computers are* the most capable computing devices. Proof If Turing\u2019s thesis stands, see \u00a74.3.1, then anything that any mechanism can\neffectively calculate can be computed by some Turing machine, and therefore, by Theorem \u00a74.2.1, it can be computed by any universal Turing machine, and finally, by Theorem \u00a74.2.9, it can be computed by any universal computer. \u22c4\n\u00a74.3.5 Lemma There are definable functions that no Turing machine can compute. Proof You can use a diagonal argument, or work from other theorems that use the\ndiagonal argument. For example, the set of Turing machines is countable, see \u00a74.1.13, |T| = |N| = \u21350, while the possible number of predicates on natural numbers, that is, the number of functions N \u2192 B, is 2|N| = 2\u21350, which is not countable, |T| = |N| = \u21350 < 2\u21350 = 2|N|. This uses Cantor\u2019s theorem, |S| < |2S|, with its diagonal argument. So there are not enough Turing machines to compute every definable function. \u22c4\nCorollary Universal computers cannot compute every definable function. Comment If the Turing\u2019s thesis stands, see \u00a74.3.1, then it follows that there are defin-\nable functions that are not effectively calculable, see \u00a73.1.5. Comment There are* more mappings than processes.\n\u00a74.3.6 Definition The identity Turing machine, I, just halts. Comment It does nearly nothing. But, wait!\n\u00a74.3.7 Lemma \u2200x \u2208 E, I\u3008x\u3009 \u2192\u0592 x, where I is the identity Turing machine. Proof Whatever expression x \u2208 E is written on the tape of I, that very same expression\nx is written when I halts, because halting is all what I does. \u22c4 Comment I does not touch the expression. \u00a74.3.8 Lemma The identity Turing machine is terminating, that is, I \u2208 \u03a3\u03c3. Proof The identity Turing machine, which just halts, is terminating, see \u00a74.2.5, be-\ncause it always halts; it only halts. \u22c4 Comment I behaves, because sometimes \u2018you can look, but you better not touch\u2019. \u00a74.3.9 Lemma The identity Turing machine I : E \u2192 E is* the identity function i :\nS \u2192 S such that \u2200x \u2208 S, i(x) = x, that is, I \u2217= i. Proof The identity function i is an effectively calculable function, see \u00a73.1.5. There-\nfore, if the Turing\u2019s thesis stands, see \u00a74.3.1, then there is a Turing machine J such that \u2200x \u2208 E, J \u3008x\u3009 \u2192\u0592 x. By Lemma \u00a74.3.7, that Turing machine J is the identity Turing machine I. \u22c4 Comment If i = c(I), then U\u3008i p d\u3009 = I\u3008p d\u3009 \u2192\u0592 p d, and U\u3008u p d\u3009 = U\u3008p d\u3009 = P\u3008d\u3009 \u2192\u0592 r, or \u221e, see \u00a74.2.3. Then i is the literal identity for expressions, or quotation, and u is the functional identity for programs, or evaluation. Both are computable, but I \u2208 \u03a3\u03c3 and U \u2208 \u03a3\u03c3\u0304, see \u00a74.2.7.\n\u00a74.3.10 Theorem Everything is* an expression, that is, E \u2217= S. Proof S is the set of everything, see \u00a73.2.1. In computing, there are only computing\ndevices, T, and expressions, E, see \u00a74.1.4. But then, by the program isomorphism, see \u00a74.1.12, computing devices are expressions, T \u2282 E. Therefore, in computing everything is an expression. And now, if the Turing\u2019s thesis stands, see \u00a74.3.1, then Lemma \u00a74.3.9 also stands, so \u2200x \u2208 S, x = i(x) \u2217= I\u3008x\u3009 \u2192\u0592 x \u2208 E. The converse, \u2200x \u2208 E, x \u2190\u0593 I\u3008x\u3009 = i(x) = x \u2208 S, holds irrespective of Turing\u2019s thesis. Therefore, S \u2217 = E. \u22c4 Comment We will write x to indicate a computing point of view of x, but \u2200x, x \u2217= x. For example, i \u2217 = i.\n\u00a74.3.11 Lemma The set of solutions S is* countable, that is, |S| \u2217= \u21350. Proof S \u2217 = E, by \u00a74.3.10, and |E| = |N| = \u21350, by \u00a74.1.5, therefore |S| \u2217= |E| = \u21350. \u22c4 Comment We will refer to the set of solutions in a Turing universe as S\u2217. So we can also write this lemma as |S\u2217| = \u21350.\n\u00a74.3.12 Theorem Resolving is* computing, that is, T \u2217= R. Proof From Theorem \u00a74.3.10, everything is* an expression, and taking transitions\nand not states, it follows that whatever transforms expressions in computing theory, that is, a Turing machine P, or its equivalent program p, or a \u03bb-function of the \u03bbcalculus, is* equivalent to whatever transforms sets in set theory, that is, an effectively calculable function, and it is* also equivalent to whatever transforms problems in problem theory, that is, a resolution \u211c. Therefore, resolving is* computing, R \u2217= T. \u22c4\nComment \u2217f \u2217\u2261 P \u2261 p \u2217\u2261 \u211c, and \u2217F \u2217= T \u2217= R. Comment We can define functions that are not effectively calculable, see \u00a74.3.5. Those functions that cannot effectively calculate, cannot therefore transform, and they are, in this sense, useless; we can define them, but we cannot use them.\nCorollary Metasolutions are* effectively calculable functions, that is, \u03a0S \u2217 = \u2217F. Proof Because R = \u03a0S, see \u00a73.5.8, so \u03a0S = R \u2217= \u2217F. \u22c4 \u00a74.3.13 Lemma The set of resolutions R is* countable, that is, |R| \u2217= \u21350. Proof R \u2217 = T, by \u00a74.3.12, and |T| = |N| = \u21350, by \u00a74.1.13, therefore |R| \u2217= |T| = \u21350. \u22c4 Comment We will refer to the set of resolutions in a Turing universe as R\u2217. So we can also write this lemma as |R\u2217| = \u21350.\n\u00a74.3.14 Lemma Predicate P\u03b4s, where P\u03b4s(x) = [x = s], is* effectively calculable. Proof Both s and x are* expressions, by \u00a74.3.10, so both are finite strings of symbols,\ns = s1s2 . . . sn, and x = x1x2 . . . xm. Then we can define a Turing machine with n+2 states, that starts in state 1, and that when some string x is written on its tape, it scans the string x, symbol by symbol, from the leftest one, this way: 1) in state i, with 1 \u2264 i \u2264 n, if the read symbol is si, then it writes a blank, goes to state i + 1, and moves to the right, but if the read symbol is not si, then it writes a blank, goes to state 0, and moves to the right; 2) in state n+ 1, if the read symbol is blank, then it writes a \u22a4, goes to state 0, and halts, but if the read symbol is not blank, then it writes a blank, goes to state 0, and moves to the right; 3) in state 0, if the read symbol is not blank, then it writes a blank, goes to state 0, and moves to the right, but if the read symbol is blank, then it writes a \u22a5, goes to state 0, and halts. This Turing machine implements P\u03b4s , and therefore P\u03b4s is computable. \u22c4 Corollary Problem \u03b4s = x? [x = s] is* expressible. Proof Because problem \u03b4s condition P\u03b4s is* effectively calculable, see \u00a73.1.6. \u22c4 Comment Problem \u03b4s is used in the proof of Theorem \u00a73.2.1. Corollary The only solution to problem \u03b4s is s, so \u03a3\u03b4s = {s} \u2208 S1. Proof Because \u03a3\u03b4s = { x | P\u03b4s(x) } = { x | [x = s] } = {s}. \u22c4 \u00a74.3.15 Lemma The set of problems P is* countable, that is, |P| \u2217= \u21350. Comment We will refer to the set of problems in a Turing universe as P\u2217. So we can\nalso write this lemma as |P\u2217| = \u21350. If the condition of a problem is computable, then the problem is in P\u2217; \u03b4s \u2208 P\u2217, for example. Proof Problem \u03b4s is* expressible, see \u00a74.3.14. Then, \u03b4S\u2217 = { \u03b4s | s \u2208 S\u2217 } \u2286 P\u2217 because each \u03b4s \u2208 P\u2217, and |\u03b4S\u2217| = |S\u2217| because there is a bijection \u03b4S\u2217 \u21d4 S\u2217 : \u03b4s \u2194 s. Also, by Theorem \u00a74.3.10, P\u2217 \u2286 E. Therefore, \u03b4S\u2217 \u2286 P\u2217 \u2286 E, and |\u03b4S\u2217| = |S\u2217| = \u21350 = |E|, and then, by the Cantor-Bernstein-Schro\u0308der theorem, |P\u2217| = \u21350. \u22c4 Comment The Cantor-Bernstein-Schro\u0308der theorem is Theorem B of \u00a72, page 484, in Cantor (1895). We have really used the equivalent Theorem C, in the same page.\n\u00a74.3.16 Theorem All problem sets are* countable, that is, |S\u2217| = |P\u2217| = |R\u2217| = \u21350. Proof By Lemmas \u00a74.3.11, \u00a74.3.15, and \u00a74.3.13. \u22c4 \u00a74.4 Full Resolution Machine\n\u00a74.4.1 Definition A full resolution machine is a device that can execute any resolution. \u00a74.4.2 Theorem A full resolution machine is* a Turing complete device. Proof By Theorem \u00a74.3.12, resolving is* computing, \u211c \u2217\u2261 P. This means that to\nachieve the maximum resolving power is* to achieve the maximum computing power, which is* the computing power of a universal computer, by Theorem \u00a74.3.4. Therefore, in a Turing universe a full resolution machine has to be Turing complete. \u22c4\nComment To execute any resolution \u211c : P \u2192 2S, the full resolution machine has to calculate functions that can take functions and that can return functions without limitations, as 22\nS\u21922S \u2192 22S\u21922S for meta-analogies, see \u00a73.6.9. Then a full resolution machine has to execute every possible function, and therefore, in a Turing universe, it has to execute every computable function, and then it has to be a \u03bb-calculus interpreter, or an equivalent computing device, for example U .\nComment This means that problem resolving is* equal to computing, and then full problem resolving is* equal to universal computing.\nCorollary A full resolution machine* is a universal computer. Proof Because a full resolution machine is* a universal computer. \u22c4 Comment Now we will state two equivalences between computing theory and problem\ntheory concepts that are true in any Turing universe, and that are needed to show the limitations of full resolution machines.\n\u00a74.4.3 Definition A set is recursively enumerable if there is a Turing machine that generates all of its members, and then halts.\nComment If the set is infinite, the Turing machine will keep generating its members forever.\nDefinition A set is computable if it is recursively enumerable.\n\u00a74.4.4 Theorem Resolvable in problem theory is* equivalent to recursively enumerable in computing theory, that is,\nResolvable \u2217 = Recursively Enumerable .\nProof To see that a problem is resolvable if, and only if, the set of its solutions is recursively enumerable, just compare the definition of resolvable problem, in \u00a73.5.4, with the definition of recursively enumerable set, in \u00a74.4.3. The only remaining gap is to equate the valid resolution \u211c of the resolvable problem to the Turing machine of the recursively enumerable set, a gap that we can bridge with the help of Theorem \u00a74.3.12. Finally see that, by the set isomorphism, see \u00a73.2.9, we can refer interchangeably to the problem \u03c0 or to the set of its solutions \u03a3\u03c0. Then we can say that a problem is recursively enumerable, or that a set is resolvable. \u22c4\n\u00a74.4.5 Definition A set is recursive if its characteristic function can be computed by a Turing machine that always halts.\n\u00a74.4.6 Theorem Expressible in problem theory is* equivalent to recursive in computing theory, that is,\nExpressible \u2217 = Recursive .\nProof The condition of a problem, P\u03c0, is the characteristic function of the set of its solutions, because \u03a3\u03c0 = { s | P\u03c0(s) }, see \u00a73.2.2. Then, if the set of all the solutions to a problem is a recursive set, see \u00a74.4.5, then the condition P\u03c0 can be computed by a Turing machine that always halts. So the condition P\u03c0 is an effectively calculable function, and therefore the problem is expressible, see \u00a73.1.6. If Turing\u2019s thesis, \u00a74.3.1, is true, then the converse is also true; just go backwards from expressible to recursive. Finally, by the set isomorphism, see \u00a73.2.9, we can refer interchangeably to the problem \u03c0 or to the set of its solutions \u03a3\u03c0. Then, we can say that a problem is recursive, or that a set is expressible. \u22c4\n\u00a74.4.7 Lemma The limitations of full resolution machines are* the limitations of universal computers. Proof Because a full resolution machine is* a universal computer, see \u00a74.4.2. \u22c4 Comment Even if universal computers are the most capable computers, they cannot\ncompute everything, see \u00a74.3.5. Now we will present three limits related to problems. \u00a74.4.8 Lemma A full resolution machine can* execute any resolution, but it cannot*\nexpress some problems. Proof There is a recursively enumerable set that is not recursive; this is the last\ntheorem in Post (1944) \u00a71. Translating, by Theorems \u00a74.4.4 and \u00a74.4.6, to problem theory: there is* a resolvable problem that is* not expressible. \u22c4\nComment This is the problem limit of full resolution machines*. Comment That last theorem in Post (1944) \u00a71, page 291, is an abstract form of Go\u0308del\u2019s\nincompleteness theorem, see Post (1944) \u00a72. \u00a74.4.9 Lemma A full resolution machine can* execute any resolution, but it cannot*\nresolve some problems. Proof Let us call \u03ba some problem that is resolvable but not expressible, see \u00a74.4.8.\nThis means that \u2203\u211c | \u211c(\u03ba) = \u03a3\u03ba, but 6 \u2203P\u03ba | P\u03ba(x) = [x \u2208 \u03a3\u03ba]. Note that |\u03a3\u03ba| \u2265 \u21350, because otherwise \u2203P\u03ba. Then its metaproblem \u03a0\u03ba is solvable but not resolvable. \u03a0\u03ba is solvable because \u03ba is resolvable, see \u00a73.5.12, or, easier, because \u211c is a solution to \u03a0\u03ba. For \u03a0\u03ba to be resolvable there should be a resolution that would find \u2018all the solutions of \u03a0\u03ba\u2019, that is, \u2018all the valid resolutions for \u03ba\u2019. But, whenever a possible valid resolution for \u03ba, let us call it \u211c\u2032, generates a value not yet generated by \u211c, let us call it z, we cannot decide whether z \u2208 \u03a3\u03ba and it will be eventually generated by \u211c, or if z /\u2208 \u03a3\u03ba and it will never be generated by \u211c; remember that \u03ba is not expressible, 6 \u2203P\u03ba. And, not being able to decide on z, we cannot decide whether \u211c\u2032 is a valid resolution for \u03ba or not. \u22c4\nComment This is the resolution limit of full resolution machines*. Comment Problem \u03ba is named after the complete set K of Post (1944), \u00a73. \u00a74.4.10 Lemma A full resolution machine can execute any resolution, but it cannot\nsolve some problems. Proof Simply because some problems have not any solution, \u03a3\u03c0 = {} = \u2205. \u22c4 Comment This is the solution limit of full resolution machines, which also applies to\nfull resolution machines*. Comment An unsolvable problem can be resolved by showing that it has not any\nsolution. For example, the decision problem of the halting problem, \u2206\u03b7, see \u00a74.5.4 below, was resolved unsolvable by Turing (1936), \u00a78.\n\u00a74.4.11 Theorem A full resolution machine* can execute any resolution, but it cannot express some problems (problem limit), and it cannot resolve some problems (resolution limit), and it cannot solve some problems (solution limit). Proof By Lemmas \u00a74.4.8, \u00a74.4.9, and \u00a74.4.10. \u22c4 Comment Full resolution machines* have limitations on each of the three main con-\ncepts of the problem theory.\nProblem Resolution\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192{ Solution }\n\u00a74.5 Problem Topology\n\u00a74.5.1 Definition The decision problem of a problem \u03c0 = x?P\u03c0(x), written \u2206\u03c0, is:\n\u2206\u03c0 = P? [P \u2208 \u03a3\u03c3] \u2227 [\u2200(x \u2217= x), P\u3008x\u3009 \u2217= P\u03c0(x)].\nComment A solution to the decision problem \u2206\u03c0 of some original problem \u03c0 is a Turing machine P that always halts and that computes the original problem condition P\u03c0 for any input. Decision problems are only defined in Turing universes, where x \u2217 = x\nby Theorem \u00a74.3.10. Comment This definition follows Post (1944), page 287.\n\u00a74.5.2 Definition The halting condition P\u03b7 : T\u00d7 E \u2192 B is:\nP\u03b7(P, d) = {\u22a5 if P\u3008d\u3009 \u2192\u0592 \u221e \u22a4 otherwise .\n\u00a74.5.3 Definition The halting problem is \u03b7 = (p, d)?P\u03b7(p, d). Comment The halting problem \u03b7 corresponds to the halting condition P\u03b7 by the con-\ndition isomorphism of problems, see \u00a73.1.7. Comment P\u03c3(p) = \u2227 d\u2208E P\u03b7(p, d), see \u00a74.2.5, so \u03c3 = \u2227\nd\u2208E \u03b7, by \u00a73.1.7 and \u00a73.1.10. \u00a74.5.4 Definition The decision problem of the halting problem, \u2206\u03b7, is:\n\u2206\u03b7 = H? [H \u2208 \u03a3\u03c3] \u2227 [\u2200P \u2208 T, \u2200d \u2208 E, H\u3008c(P) d\u3009 = P\u03b7(P, d)].\n\u00a74.5.5 Theorem The decision problem of the halting problem \u2206\u03b7 has not any solution. Proof Turing (1936), \u00a78, resolved that \u2206\u03b7 is unsolvable. \u22c4 Comment There is not any Turing machine that always halts and that compute P\u03b7 for\neach possible input. There is not any algorithm a \u2208 A that would compute P\u03b7(p, d) for every pair (p, d) \u2208 P\u00d7 E.\n\u00a74.5.6 Lemma The decision problem \u2206\u03c0 of some problem \u03c0 is solvable if, and only if, the problem \u03c0 is expressible*, that is, \u2206\u03c0 is solvable \u21d4 \u03c0 is expressible*.\nProof From solvable to expressible. That the decision problem \u2206\u03c0 is solvable, see \u00a74.5.1, means that there is a Turing machine that always halts, and that computes P\u03c0 for each possible input. Therefore, P\u03c0 is effectively calculable, see \u00a73.1.5, by a Turing machine, and then the problem \u03c0 is expressible, see \u00a73.1.6, and then it is also expressible*. Now from expressible to solvable. If a problem \u03c0 es expressible, then its condition P\u03c0 is an effectively calculable function, see \u00a73.1.6. Then, if the Turing\u2019s thesis stands, see \u00a74.3.1, that is, if it is expressible*, then there is a Turing machine P that can compute P\u03c0 exactly as the effectively calculable function. P always halts, because P\u03c0 is a condition, so its result is finite. Therefore, the decision problem \u2206\u03c0 of the problem has a solution, P, and then \u2206\u03c0 is solvable, see \u00a73.2.14. \u22c4\nCorollary The halting problem \u03b7 is not expressible*. Proof The decision problem of the halting problem, \u2206\u03b7, is not solvable, see \u00a74.5.5,\nand then the halting problem \u03b7 is not expressible*. \u22c4 Comment The halting problem \u03b7 is inexpressible*, but solvable. While the decision\nproblem of the halting problem \u2206\u03b7 is unsolvable, the halting problem \u03b7 has many solutions.\n\u00a74.5.7 Theorem The following equivalences stand: \u2206\u03c0 is solvable\n\u2217\u21d4 \u03c0 is expressible, \u03a0\u03c0 is solvable \u21d4 \u03c0 is resolvable, \u03c0 is solvable \u21d4 \u03c0 is solvable.\nProof The last one is trivial, and the other two equivalences were already proved by Lemmas \u00a74.5.6 and \u00a73.5.12. \u22c4\n\u00a74.5.8 Definition A problem \u03c0 can be: expressible* (E) or not expressible* (E), resolvable* (R) or not resolvable* (R), and solvable (S) or not solvable (S). Comment An expressible problem is* equivalent to a recursive set, by Theorem \u00a74.4.6, a resolvable problem is* equivalent to a recursively enumerable set, by Theorem \u00a74.4.4, and an unsolvable problem is equivalent to an empty set. Comment Then R is the set of computable sets, see \u00a74.4.3. Comment Not every combination is possible.\n\u00a74.5.9 Lemma If a problem is expressible*, then it is resolvable*, that is, E \u2282 R. Proof Because every recursive set is recursively enumerable, E \u2286 R. This is a corollary\nto the first theorem in Post (1944) \u00a71. And E 6= R, see the proof of Lemma \u00a74.4.8. To translate between sets and problems we use Theorems \u00a74.4.4 and \u00a74.4.6. \u22c4 Comment The first theorem in Post (1944) \u00a71, page 290, states that a setM is recursive if and only if both the set M and its complement M are recursively enumerable.\n\u00a74.5.10 Lemma If a problem is not solvable, then it is expressible*, that is, S \u2282 E . Proof If a problem \u03bd is not solvable, \u03bd \u2208 S, then \u03a3\u03bd = {}, see \u00a73.2.14. So \u03bd is a\ncontradictory problem, see \u00a73.1.11, and its condition P\u03bd is the contradiction P\u03c4\u0304 , that is, \u2200x, P\u03bd(x) = P\u03c4\u0304 (x) = \u22a5. So P\u03bd = P\u03c4\u0304 is an effectively calculable function, see \u00a73.1.5, and therefore \u03bd is expressible, see \u00a73.1.6, and then expressible*. And S 6= E , because (x? [2x = x2]) \u2208 S \u2229 E . \u22c4 Comment Being expressible*, by Lemma \u00a74.5.9, \u03bd is also resolvable*: S \u2282 E \u2282 R. \u00a74.5.11 Theorem Regarding expressibility* E , resolvability* R, and solvability S, the\ntopology of the problem space is:\nS \u2282 E \u2282 R \u2282 P .\nProof By Lemmas \u00a74.5.9 and \u00a74.5.10. As shown in the table, these lemmas prevent four of the eight combinations, and the examples show that the other four do exist.\nE R S Example & Comment \u22a4 \u22a4 \u22a4 x? [2x = x2] \u22a4 \u22a4 \u22a5 x? [2x = x2] \u2227 [x > 2] \u22a4 \u22a5 \u22a4 None, by Lemma \u00a74.5.9 \u22a4 \u22a5 \u22a5 None, by Lemma \u00a74.5.9 \u22a5 \u22a4 \u22a4 \u03ba, see \u00a74.4.9 \u22a5 \u22a4 \u22a5 None, by Lemma \u00a74.5.10 \u22a5 \u22a5 \u22a4 \u03a0\u03ba, see \u00a74.4.9 \u22a5 \u22a5 \u22a5 None, by Lemma \u00a74.5.10 \u22c4\nCorollary Then, { S, E \u2229 S,R \u2229 E ,R} is a partition of P.\nComment See below, in \u00a76.2, that E \u2217= P, and then P\u2217 \u2282 P. Also R \u2217= 2S. \u00a74.5.12 Definition We say that a problem is finite, if the set of its solutions is finite.\nWe will refer to the set of finite problems as F . That is, F = { \u03c0 | |\u03a3\u03c0| < \u21350 }. \u00a74.5.13 Lemma The set of finite problems F is a proper subset of the set of expressible\nproblems E . The set of not solvable problems S is a proper subset of the set of finite problems F . That is, S \u2282 F \u2282 E . Proof F \u2282 E because all finite sets are recursive, but not the converse. S \u2282 F because \u2200\u03bd \u2208 S, |\u03a3\u03bd | = 0 < \u21350, but (x? [2x = x2]) \u2208 S \u2229 F . \u22c4 Proposition Including F , the topology of P is: S \u2282 F \u2282 E \u2282 R \u2282 P. Corollary The topology S \u2282 F \u2282 E \u2282 R \u2282 P partitions the problem space P into\nfive non-empty places: S, F \u2229 S, E \u2229 F , R\u2229 E , and R. \u00a74.5.14 Remark The upper part of this topology is further refined by the so called\nTuring degrees of unsolvability, that we will call Turing degrees of inexpressibility. Turing degree zero, 0, corresponds to the first three places, because E = 0. Comment Then, |E| = |0| = \u21350, |R| = \u21350, and |P| = 2\u21350 > \u21350. To complete the cardinalities, |S| = 1, so |S| = 2\u21350, and |F| = \u21350.\n\u00a74.5.15 Remark Noting Ep the set of problems defined by a condition that can be computed in polynomial time, and Rp the set of problems that can be resolved in polynomial time, then Ep \u2282 E and Rp \u2282 R. The so called \u2018P = NP?\u2019 question asks if Ep = Rp, because P = Ep and NP = Rp, and then it should be called the \u2018Ep = Rp?\u2019 question. See that the general question \u2018E = R?\u2019 was answered negatively by Lemma \u00a74.5.9, because E \u2282 R, and that Ep \u2286 Rp. Comment A similar question is \u2018Ep \\ {\u2205} = Sp?\u2019, where Sp is the set of problems that can be solved in polynomial time, so Sp \u2282 S. The corresponding general question is also answered negatively, because P = S \u222a {\u2205}, so E \\ {\u2205} \u2282 S.\n\u00a75 Resolvers\n\u00a75.1 Semantics and Syntax\n\u00a75.1.1 Remark In this Section \u00a75, we will always be inside a Turing universe, see \u00a74.3.3, and accordingly we will drop every asterisk. Though some results do not depend on Turing\u2019s thesis, by now the reader should know when it is the case.\n\u00a75.1.2 Definition A resolver is a device that takes problems and returns solutions. Comment A resolver executes resolutions. Comment After Theorem \u00a74.3.12, we can equate a resolution \u211c \u2208 R to the computing\ndevice that executes the resolution P \u2208 T, that is, \u211c = P. \u00a75.1.3 Definition We will call the domain of S semantics. We will call the domain of\nS \u2192 S syntax. Comment As \u03bb-calculus shows, we only need functions to implement any syntax. Comment By Theorem \u00a73.2.1, everything is in S, including S \u2192 S. But this is both\nmathematically impossible, by Cantor\u2019s theorem, and practically not interesting. Example Using a practical example, if the problem is the survival problem, so some\nbehaviors keep the resolver alive, and the rest cause the death of the resolver, then S\nis the set of behaviors, and it does not include anything that is not a behavior, not even predicates on behaviors, nor functions. Note that the condition of the survival problem, which is satisfied if the resolver does not die, is a predicate on behaviors.\n\u00a75.1.4 Remark In this Section \u00a75, we will assume that S is not the set of everything, and, in particular, we will assume that there is not any function in S. We will focus on the survival problem, and then assume that S is the set of behaviors, or finite state automata, but you can think that S = N, or any other countable set, see \u00a74.3.11. Then we will build a series of resolvers, from the simplest one implementing one element of S, to more complex resolvers that have to implement functions in order to look for resolutions to deal with metaproblems.\n\u00a75.1.5 Definition A problem type, for example P\u03a8, is a subset of the set of problems, that is, P\u03a8 \u2286 P. We will note S\u03a8 the set of the solutions to the type of problems P\u03a8. That is, \u2200\u03c0\u03a8 \u2208 P\u03a8, \u03a3\u03c0\u03a8 \u2286 S\u03a8 \u2286 S. Comment The survival problem is not a single problem, but a type of problems, P\u2126; each living being faces a different survival problem. But, in this case as in many others, what it is certain is that the solutions to any of these problems is of a specific kind. For example, while eating can be a solution, imagining how to eat is not a solution, even though it can help us to get something to eat, because it can be a metasolution. Then S\u2126 is the set of behaviors.\n\u00a75.1.6 Remark Metaproblems \u03a0\u03c0 are a type of problem, \u03a0P = P\u03a0, and its solutions are resolutions, \u03a0S = S\u03a0 = R, see \u00a73.5.8.\n\u00a75.1.7 Lemma If the set of the solutions to some type of problem is finite, 0 < |S\u0393| < \u21350, then each and every problem of that type is expressible and resolvable. Proof Because those problems are in F , so Lemma \u00a74.5.13 apply. \u22c4 Comment If 0 < |S\u0393| = N < \u21350, then |P\u0393| = 2N < \u21350 and |R\u0393| = (2N )2 N\n< \u21350. In the finite case, |S\u0393| < |P\u0393| < |R\u0393| < \u21350.\n\u00a75.1.8 Definition A constant function Ks : S \u2192 S is: \u2200s \u2208 S, \u2200x \u2208 S, Ks(x) = s. Comment Every constant function Ks is effectively calculable, see \u00a73.1.5. They are\n\u03bb-definable; in \u03bb-calculus, K = (\u03bbsx.s). This is because our \u03bb-calculus includes the K combinator, and so we refer to the \u03bbK-calculus simply as \u03bb-calculus. Special cases Tautology: K\u22a4 = P\u03c4 . Contradiction: K\u22a5 = P\u03c4\u0304 . See \u00a73.1.11. \u00a75.1.9 Definition The constant isomorphism is the natural isomorphism between S\nand the set of constant functions K that relates each s \u2208 S with Ks \u2208 (S \u2192 S). That is, S \u21d4 K : s \u2194 Ks.\nComment We can extend any operation on S to K. For example, for any binary operation \u2217 on S, we define \u2200x, [Ka \u2217Kb](x) = Ka(x) \u2217Kb(x) = a \u2217 b = Ka\u2217b(x). Comment Semantics is included in syntax, that is, S \u223c= K \u2282 (S \u2192 S). \u00a75.1.10 Remark A semantic function f : S \u2192 S is a syntactic element, f \u2208 (S \u2192 S),\nbut it is not a syntactic function f \u2208 ((S \u2192 S) \u2192 (S \u2192 S)), because the semantic function f takes semantic elements and returns semantic elements, while, using the constant isomorphism, the syntactic function f is not restricted. In particular, a semantic function cannot take a function, and a semantic function cannot return a function.\nComment In semantics, literal identity i is the identity, see \u00a74.3.9, because there are not higher order functions in semantics. But, different syntactic objects can refer to the same semantic object, as in f(x) = y, which means that f(x) and y are two syntactic objects that refer to the same semantic object. Then, there are two identities in syntax: literal identity i, or quotation, which is the semantic function that just returns what it takes, and functional identity u, or evaluation, which is the syntactic function that follows the references and returns the final one, see \u00a74.2.3. Note also that a syntactic object can refer to no semantic object, and then we say that the syntactic object is a paradox.\n\u00a75.1.11 Definition The range of a resolver \u211c, noted \u039e\u211c, is the set of the problems for which \u211c provides a non-empty subset of solutions, and only of solutions, that is, \u039e\u211c = { \u03c0 | \u211c(\u03c0)\u2286\u03a3\u03c0 \u2227 \u211c(\u03c0) 6=\u2205 }.\nComment The range of a resolver is the set of the problems that the resolver solves.\n\u00a75.1.12 Definition The power of a resolver \u211c, noted \u03a6\u211c, is the set of the problems that the resolver \u211c resolves, that is, \u03a6\u211c = { \u03c0 | \u211c(\u03c0) = \u03a3\u03c0 }. Comment In practice, if |\u03a3\u03c0| > 1, it is not sensible to generate all the solutions, \u03a3\u03c0, when just one solution solves the problem. In these cases the range of the resolver is more important than its power.\n\u00a75.1.13 Theorem \u2200\u211c, S \u2229 \u03a6\u211c \u2286 \u039e\u211c. Proof Because \u2200\u03c0 \u2208 \u03a6\u211c \u2229 S, we have that \u03c0 \u2208 \u03a6\u211c so \u211c(\u03c0) = \u03a3\u03c0, see \u00a75.1.12, and\nthen \u211c(\u03c0) \u2286 \u03a3\u03c0, and also that \u03c0 \u2208 S, so |\u03a3\u03c0| > 0 \u21d4 \u03a3\u03c0 6= \u2205, see \u00a74.5.8 and \u00a73.2.14, and then \u211c(\u03c0) = \u03a3\u03c0 6= \u2205, and therefore \u03c0 \u2208 \u039e\u211c, see \u00a75.1.11. \u22c4 Comment For solvable problems, \u03a6\u211c \u2286 \u039e\u211c, so they are easier to solve than to resolve. But unsolvable problems, some of them resolved, are impossible to solve!\n\u00a75.1.14 Definition We will say that the resources of a resolver are in a set if the capability implemented in the resolver belongs to that set. Comment Now we will construct a series of resolvers \u211cn, from the minimal one that only implements one solution, and then growing naturally step by step. Each resolver will implement just one element out of its resources Notation We will use {\u00b7 \u211cn \u00b7} to refer to the set of all the resolvers of step n.\n\u00a75.2 Mechanism\n\u00a75.2.1 Definition A mechanism \u211c0 is any resolver that implements one member of S. We will note \u211c0[s], where s \u2208 S, the mechanism that implements s, that is, \u211c0[s] = s \u2208 S. Then the mechanisms resources are in S, and {\u00b7 \u211c0 \u00b7} = S. Comment Mechanism \u211c0[s] returns s unconditionally. Comment A mechanism \u211c0 implements a semantic unconditional computation.\n\u00a75.2.2 Notation As resolutions return sets of elements in S, to normalize the situation of mechanisms \u211c0 we will use the singleton isomorphism, see \u00a73.2.11, and we will write \u211c0[{s}] to mean the singleton {s}, that is, \u211c0[{s}] = {\u211c0[s]} = {s} \u2208 2S.\n\u00a75.2.3 Lemma \u2200s \u2208 S, \u039e\u211c0[{s}] = { \u03c0 | P\u03c0(s) }. Proof Just applying the definition of range, see \u00a75.1.11, to the definition of mechanism,\nwe get: \u039e\u211c0[{s}] = { \u03c0 | \u211c0[{s}]\u2286\u03a3\u03c0 \u2227 \u211c0[{s}] 6= \u2205 } = { \u03c0 | {s}\u2286\u03a3\u03c0 \u2227 {s} 6= \u2205 } = { \u03c0 | s\u2208\u03a3\u03c0 \u2227 \u22a4} = { \u03c0 | s \u2208 \u03a3\u03c0 } = { \u03c0 | P\u03c0(s) }. \u22c4 Comment The range of the mechanism \u211c0[s] is the set of problems for which s is a solution.\n\u00a75.2.4 Lemma \u2200s \u2208 S, \u03a6\u211c0[{s}] = {\u03b4s}. Proof Just applying the definition of power, see \u00a75.1.12, to the definition of mechanism,\nwe get: \u03a6\u211c0[{s}] = { \u03c0 | \u211c0[{s}] = \u03a3\u03c0 } = { \u03c0 | {s} = \u03a3\u03c0 } = {\u03b4s}, the last equation because \u03a3\u03b4s = {s}, see \u00a74.3.14. \u22c4 Comment Mechanism \u211c0[s] only resolves problem \u03b4s. \u00a75.2.5 Lemma Any singleton routine resolution R\u03c0 = {s} can be implemented by the\nmechanism \u211c0[R\u03c0]. Proof If R\u03c0 = {s}, then R\u03c0 = {s} = {\u211c0[s]} = \u211c0[{s}] = \u211c0[R\u03c0]. \u22c4 Comment In theory, we can equal any finite routine resolution to a union of a finite\nnumber of mechanisms, R\u03c0 = \u03a3\u03c0 = \u22c3 s\u2208\u03a3\u03c0{s} = \u22c3 s\u2208\u03a3\u03c0{\u211c0[s]}. \u00a75.2.6 Summary In practice, it only makes sense to implement one solution, as \u211c0[s]\ndoes. Without conditional calculations, the mechanism could not control when to apply one result or any of the others, so it would gain nothing implementing more than one.\nComment The mechanism is a body capable of one behavior. Example A mechanism can only survive in a specific and very stable environment, as\nit is the case of some extremophile archaea.\n\u00a75.3 Adapter\n\u00a75.3.1 Definition An adapter \u211c1 is any resolver that implements one condition on the members of S. We will note \u211c1[PS ] the adapter that implements PS , where PS \u2208 (S \u2192 B), that is, \u211c1[PS ] = PS \u2208 (S \u2192 B). Then the adapters resources are in S \u2192 B, and {\u00b7 \u211c1 \u00b7} = (S \u2192 B). Comment An adapter \u211c1 implements a semantic conditional computation. \u00a75.3.2 Lemma Each adapter \u211c1[PS ] implements one set of elements of S. Proof Because every predicate PS defines a set S = { s \u2208 S | PS(s) } \u2208 2S. The\ncondition PS is the characteristic function of S, \u2200s \u2208 S, PS(s) = [s \u2208 S]. \u22c4 Comment We will write \u211c1[PS ] = \u211c1[S] = S \u2208 2S. Only effectively calculable con-\nditions are implementable, and then adapters can only implement expressible, or recursive, sets, E . Then, \u211c1[PS ] = \u211c1[S] = S \u2208 E .\n\u00a75.3.3 Lemma Every mechanism \u211c0 is an adapter \u211c1, that is, {\u00b7 \u211c0 \u00b7} \u2282 {\u00b7 \u211c1 \u00b7}. Proof For each mechanism \u211c0[s], which implements s \u2208 S, there is an adapter \u211c1[P\u03b4s],\nsee \u00a74.3.14, that implements the singleton {s} \u2208 (S \u2192 B). But not every set is a singleton. Summarizing, {\u00b7 \u211c0 \u00b7} = S \u2282 (S \u2192 B) = {\u00b7 \u211c1 \u00b7}. \u22c4 Comment In Cantor\u2019s paradise, but out of Turing universes, by the singleton (\u00a73.2.11) and the set (\u00a73.2.8) isomorphisms: {\u00b7 \u211c0 \u00b7} = S \u223c= S1 \u2282 2S \u223c= (S \u2192 B) = {\u00b7 \u211c1 \u00b7}.\n\u00a75.3.4 Lemma \u211c1[S] = \u22c3 s\u2208S{\u211c0[s]}. Proof Because \u211c0[s] = s, so \u22c3 s\u2208S{\u211c0[s]} = \u22c3\ns\u2208S{s} = S = \u211c1[S]. \u22c4 Comment The results are the same, but not the implementation, because while the\nadapter \u211c1[S] implements a condition, the union of mechanisms \u22c3 s\u2208S{\u211c0[s]} works unconditionally. Thus, the output of the union of mechanisms is independent of any problem, and then the union cannot implement \u211c1[PS \u2227 P\u03c0] = \u211c1[S \u2229 \u03a3\u03c0], for example, so it cannot implement any trial, see Theorem \u00a73.3.5.\n\u00a75.3.5 Lemma \u2200S \u2208 2S, \u2200\u03c0 \u2208 P, \u039e\u211c1[S \u2229 \u03a3\u03c0] = { \u03c0 | S \u2229 \u03a3\u03c0 6= \u2205 }. Proof Because \u039e\u211c1[S \u2229 \u03a3\u03c0] = { \u03c0 | (\u211c1[S \u2229 \u03a3\u03c0] \u2286 \u03a3\u03c0) \u2227 (\u211c1[S \u2229 \u03a3\u03c0] 6= \u2205) } =\n{ \u03c0 | (S \u2229 \u03a3\u03c0 \u2286 \u03a3\u03c0) \u2227 (S \u2229 \u03a3\u03c0 6= \u2205) } = { \u03c0 | \u22a4 \u2227 (S \u2229 \u03a3\u03c0 6= \u2205) } = { \u03c0 | S \u2229 \u03a3\u03c0 6= \u2205 }. \u22c4\nComment The range of the adapter \u211c1[S \u2229 \u03a3\u03c0] is the set of problems that have any solution in S. The adapter \u211c1[S\u2229\u03a3\u03c0] solves any problem such that any of its solutions are in S. Corollary If S \u2282 S\u2032, then \u039e\u211c1[S \u2229 \u03a3\u03c0] \u2282 \u039e\u211c1[S\u2032 \u2229 \u03a3\u03c0]. Proof In that case, if a solution to a problem is in S, then it is also in S\u2032. But there\nare also solutions in S\u2032 that are not in S. \u22c4 \u00a75.3.6 Lemma If s \u2208 S, then \u2200\u03c0 \u2208 P, \u039e\u211c0[{s}] \u2286 \u039e\u211c1[S \u2229 \u03a3\u03c0]. Proof By Lemma \u00a75.2.3, \u2200\u03c0 \u2208 \u039e\u211c0[{s}], P\u03c0(s), that is, s \u2208 \u03a3\u03c0, so, if s \u2208 S, then\nS \u2229 \u03a3\u03c0 6= \u2205, and therefore \u03c0 \u2208 \u039e\u211c1[S \u2229 \u03a3\u03c0], by Lemma \u00a75.3.5. \u22c4 Definition We will call s \u2208 S the adapter condition. If the adapter condition holds,\nthen the adapter \u211c1[S \u2229 \u03a3\u03c0] solves any problem that the mechanism \u211c0[s] solves. Corollary If {s} \u2282 S, then \u039e\u211c0[{s}] \u2282 \u039e\u211c1[S \u2229 \u03a3\u03c0]. Proof Because, if t \u2208 S and t 6= s, then \u03b4t \u2208 \u039e\u211c1[S \u2229 \u03a3\u03c0] but \u03b4t 6\u2208 \u039e\u211c0[{s}]. \u22c4 Proposition If {s} \u2282 S, then \u039e\u211c0[{s}] 6\u2282 \u039e\u211c1[S].\nBecause \u03b4s \u2208 \u039e\u211c0[{s}], but \u03b4s 6\u2208 \u039e\u211c1[S]. \u00a75.3.7 Lemma \u2200S \u2208 2S, \u2200\u03c0 \u2208 P, \u03a6\u211c1[S \u2229 \u03a3\u03c0] = 2S . Proof Because \u03a6\u211c1[S \u2229 \u03a3\u03c0] = { \u03c0 | \u211c1[S \u2229 \u03a3\u03c0] = \u03a3\u03c0 } = { \u03c0 | S \u2229 \u03a3\u03c0 = \u03a3\u03c0 } =\n{ \u03c0 | \u03a3\u03c0 \u2286 S } = 2S , where the last equality uses the set isomorphism, see \u00a73.2.8. \u22c4 Comment The power of the adapter \u211c1[S \u2229 \u03a3\u03c0] is the powerset of S. The adapter\n\u211c1[S \u2229 \u03a3\u03c0] resolves any problem such that all of its solutions are in S. Corollary If S \u2282 S\u2032, then \u03a6\u211c1[S \u2229 \u03a3\u03c0] \u2282 \u03a6\u211c1[S\u2032 \u2229 \u03a3\u03c0]. Proof Just because, if S \u2282 S\u2032, then 2S \u2282 2S\u2032 . \u22c4 \u00a75.3.8 Lemma If s \u2208 S, then \u2200\u03c0 \u2208 P, \u03a6\u211c0[{s}] \u2282 \u03a6\u211c1[S \u2229 \u03a3\u03c0]. Proof Using the set isomorphism, see \u00a73.2.8, \u03b4s = \u03a3\u03b4s = {s}, and then, if s \u2208 S,\n\u03a6\u211c0[{s}] = {\u03b4s} = {{s}} \u2282 2S = \u03a6\u211c1[S \u2229 \u03a3\u03c0], by Lemmas \u00a75.2.4 and \u00a75.3.7. \u22c4 Comment If the adapter condition holds, s \u2208 S, then the adapter \u211c1[S \u2229 \u03a3\u03c0] resolves\nany problem that the mechanism \u211c0[s] resolves, and more. Proposition If {s} \u2282 S, then \u03a6\u211c0[{s}] 6\u2282 \u03a6\u211c1[S], because \u03b4s 6\u2208 \u03a6\u211c1[S] = {S}. \u00a75.3.9 Lemma Any effectively calculable trial resolution T\u03c0(S) can be implemented by\nthe adapter \u211c1[S \u2229 \u03a3\u03c0]. Proof T\u03c0(S) = { s \u2208 S | s \u2208 \u03a3\u03c0 } = { s | s\u2208S \u2227 s\u2208\u03a3\u03c0 } = { s | PS(s) \u2227 P\u03c0(s) }. Then\nT\u03c0(S) . = \u211c1[PS \u2227P\u03c0] = \u211c1[S \u2229\u03a3\u03c0]. The equality is dotted because, if the trial is not an effectively calculable function, then it cannot be implemented. \u22c4\n\u00a75.3.10 Summary In practice, an adapter \u211c1[PS\u2227P\u03c0] = \u211c1[S\u2229\u03a3\u03c0] has a body capable of several behaviors that provides the set S of behaviors. If the current behavior were not satisfying the adapter condition P\u03c0, which is interpreted as an error, then the adapter would change its behavior trying another one in S.\nComment The adapter is a body capable of several behaviors, and a governor that selects the current behavior.\nExample A deciduous tree, which switches its behavior with seasons, is an adapter.\n\u00a75.4 Perceiver\n\u00a75.4.1 Definition A perceiver \u211c2 is any resolver that implements one transformation of the elements in S into the elements in S. We will note \u211c2[f ] the perceiver that implements f , where f \u2208 (S \u2192 S), that is, \u211c2[f ] = f \u2208 (S \u2192 S). Then the perceiver resources are in S \u2192 S, and {\u00b7 \u211c2 \u00b7} = (S \u2192 S). Comment From a semantic point of view, a perceiver \u211c2 implements a semantic functional computation. From a syntactic point of view, a perceiver \u211c2 implements a syntactic unconditional computation.\n\u00a75.4.2 Remark Perceivers are to syntax as mechanisms are to semantics. Comment When solutions are functions S \u2192 S, then a perceiver does what a mech-\nanism does, which is to return a solution unconditionally. That is, perceivers on metaproblems are as mechanisms on problems. But, perceivers can go further. Comment The perceiver \u211c2[f ] implements function f from S to S, that is, f : S \u2192 S. Then, \u2200s \u2208 S, \u211c2[f ](s) = f(s) \u2208 S.\n\u00a75.4.3 Notation By the rewriting rules in \u00a73.1.3, \u211c2[f ](S) = {\u211c2[f ](s) | s \u2208 S } \u2208 2S. Then \u211c2[f ](S) returns a set of solutions, as any well-behaved resolution should do. Comment The perceiver \u211c2[f ](S) implements f , meaning that f is hardwired in the perceiver, while S is just data. We will call what is implemented hardware, and what is data software. We write the hardware between brackets, and the software between parentheses. We will assume that coding software costs less than implementing hardware, or, in fewer words, that software is cheaper than hardware\n\u00a75.4.4 Lemma Every adapter \u211c1 is a perceiver \u211c2, that is, {\u00b7 \u211c1 \u00b7} \u2282 {\u00b7 \u211c2 \u00b7}. Proof Because B \u2282 S, and then (S \u2192 B) \u2282 (S \u2192 S). So\n{\u00b7 \u211c1 \u00b7} = (S \u2192 B) \u2282 (S \u2192 S) = {\u00b7 \u211c2 \u00b7}. \u22c4 Comment Each adapter implements one condition PS \u2208 (S \u2192 B). And any condition\nPS \u2208 (S \u2192 B) is also a function PS \u2208 (S \u2192 S), because B \u2282 S. Therefore, for each adapter \u211c1[PS ], which implements condition PS , there is a perceiver \u211c2[PS ] that implements the function PS , and then we write \u211c1[PS ] = PS = \u211c2[PS ]. Comment Again, \u211c1[PS ] = \u211c2[PS ] explains that the results are the same, but not the implementation.\n\u00a75.4.5 Lemma \u2200S \u2208 2S, \u211c1[S] = \u211c2[i](S). Proof Function i : S \u2192 S is the semantic identity, i = i see \u00a75.1.10, so \u2200s \u2208 S, i(s) = s,\nand \u211c2[i](S) = {\u211c2[i](s) | s \u2208 S } = { i(s) | s \u2208 S } = { s | s \u2208 S } = S = \u211c1[S]. \u22c4 Comment The same perceiver hardware \u211c2[i], just by changing its software, can em-\nulate different adapters: \u211c2[i](S) = \u211c1[S], and \u211c2[i](S\u2032) = \u211c1[S\u2032]. Then the perceiver \u211c2[i](S) is more flexible than the adapter \u211c1[S], because S is hardwired in the adapter, while it is easily replaceable data for the perceiver.\n\u00a75.4.6 Lemma \u2200S \u2208 2S, \u039e\u211c1[S] = \u039e\u211c2[i](S) and \u03a6\u211c1[S] = \u03a6\u211c2[i](S). Proof Because, by Lemma \u00a75.4.5, \u211c1[S] = \u211c2[i](S). \u22c4 Definition The perceiver condition is satisfied if it implements the semantic identity i. Comment If the perceiver condition holds, then the perceiver \u211c2[i](S) solves any prob-\nlem solved by the adapter \u211c1[S], and the perceiver \u211c2[i](S) resolves any problem resolved by the adapter \u211c1[S].\nRemark Semantic identity i is the ideal for perception.\n\u00a75.4.7 Corollary \u039e\u211c2[i](S \u2229\u03a3\u03c0) = \u039e\u211c1[S \u2229\u03a3\u03c0] and \u03a6\u211c2[i](S \u2229\u03a3\u03c0) = \u03a6\u211c1[S \u2229\u03a3\u03c0]. Proof By Lemma \u00a75.4.6. \u22c4 Comment The same perceiver hardware \u211c2[i] can be tuned to a different trial just by\nchanging its software, from \u211c2[i](S \u2229 \u03a3\u03c0) to \u211c2[i](S\u2032 \u2229 \u03a3\u03c1), for example. Proposition If S \u2282 S\u2032, then \u039e\u211c2[i](S \u2229\u03a3\u03c0) \u2282 \u039e\u211c2[i](S\u2032 \u2229\u03a3\u03c0), and \u03a6\u211c2[i](S \u2229\u03a3\u03c0) \u2282\n\u03a6\u211c2[i](S\u2032 \u2229 \u03a3\u03c0), by Lemma \u00a75.4.5 and corollaries to Lemmas \u00a75.3.5 and \u00a75.3.7. \u00a75.4.8 Definition A function on sets F : 2S \u2192 2S is elementable if it exists an\neffectively calculable function f : S \u2192 S such that \u2200S, F (S) = { f(s) | s \u2208 S }. Comment We write F (S) = f(S), by the rules in \u00a73.1.3. Note the three requirements:\nthat f is a semantic function, f : S \u2192 S, that f is effectively calculable, and that F (S) = f(S). Proposition Set identity I : 2S \u2192 2S | \u2200S \u2208 2S, I(S) = S, is elementable by semantic identity i, because \u2200S \u2208 2S, i(S) = { i(s) | s \u2208 S } = { s | s \u2208 S } = S = I(S).\n\u00a75.4.9 Lemma Any analogy resolution A \u25e6 TA\u03c0(S) \u25e6 TA can be implemented by the tri-perceiver \u211c2[Ta](\u211c2[i](S \u2229 \u211c2[a](\u03a3\u03c0))), if A is elementable by a, and TA by Ta. Proof An analogy resolution is A \u25e6 TA\u03c0(S) \u25e6 TA. Both A and TA are functions from sets to sets, TA : 2S \u2192 2S and A : (P \u2192 P) = (2S \u2192 2S), so if both A and TA are elementable, then a perceiver can implement them. We have a and Ta, which are both semantic functions such that A(S) = a(S), and TA(S) = Ta(S). Then Pa\u03c0 = a(P\u03c0) = \u211c2[a](P\u03c0) = \u211c2[a](\u03a3\u03c0) implements the first third, Ta\u03c0(S) = \u211c1[PS \u2227 Pa\u03c0] = \u211c1[PS \u2227 \u211c2[a](P\u03c0)] = \u211c1[S \u2229 \u211c2[a](\u03a3\u03c0)] implements the second third, see \u00a75.3.9, and using \u00a75.4.5, \u211c2[Ta](\u211c2[i](S \u2229 \u211c2[a](\u03a3\u03c0))) implements the whole analogy resolution a \u25e6 Ta\u03c0(S) \u25e6 Ta. \u22c4 Corollary Identity analogy I \u25e6 TI\u03c0(S) \u25e6 TI can be implemented by the bi-perceiver \u211c2[i](S \u2229 \u211c2[i](\u03a3\u03c0)), which uses the identity perceiver \u211c2[i] twice. Proof \u211c2[Ti](\u211c2[i](S\u2229\u211c2[i](\u03a3\u03c0))) = \u211c2[i](\u211c2[i](S\u2229\u211c2[i](\u03a3\u03c0))) = \u211c2[i](S\u2229\u211c2[i](\u03a3\u03c0)), because set identity I is elementable by semantic identity i, and TI = I, so it is also elementable by Ti = i, and i \u25e6 i = i. \u22c4\n\u00a75.4.10 Summary While an adapter uses a trial and error resolution, and this means that error is part of the usual procedure, a perceiver executes the trial and error inside itself. If the analogy provides a good model, then the internal trial is as good as the external one, with the advantage that the errors are only simulated errors. More to the point, if the problem the resolver faces is the survival problem, then the adapter errors are literally death errors, or at least pain, while the perceiver errors are just mental previsions of what not to do. See that, if the perceiver implements the identity analogy, as \u211c2[i] does, then the model is good, because the internal problem is equal to the external one. And the perceiver \u211c2[i] is more flexible than the adapter.\nComment The perceiver is a body capable of several behaviors, a governor that selects the current behavior, and a simulator that internalizes behaviors.\nExample The perceiver governor determines what to do based upon an internal interpretation. According to Lettvin et al. (1959), a frog is a perceiver that uses an internal routine. Frog\u2019s i is such that any dark point that moves rapidly in its field of vision is a fly which it will try to eat.\n\u00a75.5 Learner\n\u00a75.5.1 Definition A learner \u211c3 is any resolver that implements one condition on the members of S \u2192 S. We will note \u211c3[PF ] the learner that implements PF , where PF \u2208 ((S \u2192 S) \u2192 B), that is, \u211c1[PF ] = PF \u2208 ((S \u2192 S) \u2192 B). Then the learners resources are in (S \u2192 S) \u2192 B, and {\u00b7 \u211c3 \u00b7} = ((S \u2192 S) \u2192 B). Comment A learner \u211c3 implements a syntactic conditional computation.\n\u00a75.5.2 Remark Learners are to syntax as adapters are to semantics. Comment When solutions are functions S \u2192 S, then a learner does what an adapter\ndoes, which is to return a predicate on solutions. That is, learners on metaproblems are as adapters on problems. But, learners can go further.\n\u00a75.5.3 Lemma Each learner \u211c3[PF ] implements one set of members of (S \u2192 S). Proof Because every predicate PF : (S \u2192 S) \u2192 B defines a set\nF = { f \u2208 (S \u2192 S) | PF (f) } \u2208 2S\u2192S. The condition PF is the characteristic function of F , \u2200f \u2208 (S \u2192 S), PF (f) = [f \u2208 F ]. \u22c4 Comment We will write \u211c3[PF ] = \u211c3[F ] = F \u2208 2S\u2192S. Comment The learner \u211c3[F ] implements F \u2208 2S\u2192S. So \u2200s \u2208 S, \u211c3[F ](s) = F (s) \u2208 2S,\nbecause F (s) = { f(s) | f \u2208 F }, by the rewriting rules in \u00a73.1.3, and then \u211c3[F ](s) returns a set of solutions, as any well-behaved resolution should do. Also, by the same rules, \u211c3[F ](S) = F (S) = { f(s) | s\u2208S \u00d7 f \u2208F } \u2208 2S.\n\u00a75.5.4 Lemma Every perceiver \u211c2 is a learner \u211c3, that is, {\u00b7 \u211c2 \u00b7} \u2282 {\u00b7 \u211c3 \u00b7}. Proof For each perceiver \u211c2[f ], which implements f \u2208 (S \u2192 S), there is a learner\n\u211c3[P\u03b4f ], see \u00a74.3.14, that implements the singleton {f} \u2208 ((S \u2192 S) \u2192 B). But not every set is a singleton. Then, {\u00b7 \u211c2 \u00b7} = (S \u2192 S) \u2282 ((S \u2192 S) \u2192 B) = {\u00b7 \u211c3 \u00b7}. \u22c4\n\u00a75.5.5 Lemma \u211c3[F ] = \u22c3 f\u2208F {\u211c2[f ]}. Proof Because \u211c2[f ] = f , so \u22c3 f\u2208F {\u211c2[f ]} = \u22c3\nf\u2208F {f} = F = \u211c3[F ]. \u22c4 Comment Again, the results are the same, but not the implementation. The union of\nperceivers \u22c3 f\u2208F {\u211c2[f ]} cannot select a function to use, so it cannot implement any meta-trial, as \u211c3[R \u2229 \u03a3\u03a0\u03c0] does, see \u00a75.5.11.\nComment These are not sets of solutions, but sets of semantic functions.\n\u00a75.5.6 Lemma \u2200f \u2208 F , \u2200S \u2208 2S, \u211c2[f ](S) \u2286 \u211c3[F ](S). Proof If f \u2208 F , then f(S) = { f(s) | s \u2208 S } \u2286 { f \u2032(s) | s\u2208S \u00d7 f \u2032\u2208F } = F (S). \u22c4\n\u00a75.5.7 Notation We will rewrite \u211c1[\u211c3[F ](S) \u2229 \u03a3\u03c0] as \u211c3[F ](S \u2229 \u03a3\u03c0). Comment We can write \u211c1[\u211c3[F ](S) \u2229\u03a3\u03c0] = \u211c3[F ](S \u2229 \u03a3\u03c0), because any learner can\nimplement semantic conditions, that is, because {\u00b7 \u211c1 \u00b7} \u2282 {\u00b7 \u211c3 \u00b7}.\n\u00a75.5.8 Lemma If f \u2208 F , then \u2200S \u2208 2S, \u2200\u03c0 \u2208 P, \u039e\u211c2[f ](S) \u2286 \u039e\u211c3[F ](S \u2229 \u03a3\u03c0). Proof Firstly see that, if f \u2208 F , then f(S) \u2286 F (S), by \u00a73.1.3, so, f(S) \u2229 \u03a3\u03c0 \u2286\nF (S) \u2229 \u03a3\u03c0. Secondly see that \u2200\u03c0 \u2208 \u039e\u211c2[f ](S), f(S) \u2229 \u03a3\u03c0 = f(S) 6= \u2205. This is because \u039e\u211c2[f ](S) = { \u03c0 | f(S) \u2286 \u03a3\u03c0 \u2227 f(S) 6= \u2205 }. Now, taking both together, \u2200\u03c0 \u2208 \u039e\u211c2[f ](S), \u2205 6= f(S) = f(S)\u2229\u03a3\u03c0 \u2286 F (S) \u2229\u03a3\u03c0, so for these \u03c0, F (S) \u2229\u03a3\u03c0 6= \u2205. Then these \u03c0 \u2208 { \u03c0 | F (S) \u2229 \u03a3\u03c0 \u2286 \u03a3\u03c0 \u2227 F (S) \u2229 \u03a3\u03c0 6= \u2205 } = \u039e\u211c1[\u211c3[F ](S) \u2229 \u03a3\u03c0], because F (S) \u2229 \u03a3\u03c0 \u2286 \u03a3\u03c0 is always true. \u22c4 Definition We will call f \u2208 F the learner condition. If the learner condition holds, then the learner \u211c3[F ](S \u2229\u03a3\u03c0) solves any problem that the perceiver \u211c2[f ](S) solves.\n\u00a75.5.9 Lemma If f \u2208 F , then \u2200S \u2208 2S, \u2200\u03c0 \u2208 P, \u03a6\u211c2[f ](S) \u2286 \u03a6\u211c3[F ](S \u2229 \u03a3\u03c0). Proof If f \u2208 F , then f(S) \u2286 F (S), see \u00a73.1.3, so, f(S) \u2229 \u03a3\u03c0 \u2286 F (S) \u2229 \u03a3\u03c0. Now\n\u2200\u03c0 \u2208 \u03a6\u211c2[f ](S), f(S) = \u03a3\u03c0, and then for these \u03c0, \u03a3\u03c0 = f(S)\u2229\u03a3\u03c0 \u2286 F (S)\u2229\u03a3\u03c0 \u2286 \u03a3\u03c0. Therefore, for these \u03c0, F (S) \u2229 \u03a3\u03c0 = \u03a3\u03c0, and \u03a6\u211c2[f ](S) \u2286 { \u03c0 | F (S) \u2229 \u03a3\u03c0 = \u03a3\u03c0 } = \u03a6\u211c1[\u211c3[F ](S) \u2229 \u03a3\u03c0]. \u22c4 Comment If the learner condition holds, f \u2208 F , then the learner \u211c3[F ](S \u2229\u03a3\u03c0) resolves any problem that the perceiver \u211c2[f ](S) resolves.\n\u00a75.5.10 Corollary In particular, if i \u2208 R, then \u039e\u211c2[i](S \u2229 \u03a3\u03c0) \u2286 \u039e\u211c3[R](S \u2229 \u03a3\u03c0) and \u03a6\u211c2[i](S \u2229 \u03a3\u03c0) \u2286 \u03a6\u211c3[R](S \u2229 \u03a3\u03c0). Proof By Lemmas \u00a75.5.8 and \u00a75.5.9. See that \u039e\u211c3[R](S\u2229\u03a3\u03c0 \u2229\u03a3\u03c0) \u2286 \u039e\u211c3[R](S \u2229\u03a3\u03c0), and \u03a6\u211c3[R](S \u2229\u03a3\u03c0 \u2229 \u03a3\u03c0) \u2286 \u03a6\u211c3[R](S \u2229 \u03a3\u03c0), because \u211c3[R](S \u2229\u03a3\u03c0) \u2286 \u211c3[R](S), so corollaries to Lemmas \u00a75.3.5 and \u00a75.3.7 apply (the equal case is trivial). \u22c4\n\u00a75.5.11 Lemma Any meta-trial resolution T\u03a0\u03c0(R) can be implemented by the learner \u211c3[R \u2229 \u03a3\u03a0\u03c0], if PR and P\u03a0\u03c0 are elementable. Comment The diagram for the meta-trial, or trial of the metaproblem, see \u00a73.6.9, is:\n\u03c0 \u03a0\u2212\u2212\u2192\u03a0\u03c0 T\u03a0\u03c0(R)\u2212\u2212\u2212\u2212\u2212\u2192\u03a3\u03a0\u03c0 T\u03a0\u2212\u2212\u2192\u03a3\u03c0 .\nComment A learner solves metaproblems by trial, as an adapter solves problems by trial. The following correlations stand: \u211c3 \u2194 \u211c1, \u03a0\u03c0 \u2194 \u03c0, R \u2194 S, and then \u211c3[R \u2229\u03a3\u03a0\u03c0] \u2194 \u211c1[S \u2229\u03a3\u03c0]. Therefore, \u211c3[R \u2229\u03a3\u03a0\u03c0] compares to \u211c2[i], where i \u2208 R, as \u211c1[S \u2229 \u03a3\u03c0] compares to \u211c0[s], where s \u2208 S. Proof T\u03a0\u03c0(R) = { r \u2208 R | r \u2208 \u03a3\u03a0\u03c0 } = { r | r\u2208R \u2227 r\u2208\u03a3\u03a0\u03c0 } = { r | PR(r)\u2227P\u03a0\u03c0(r) }. In the meta-trial T\u03a0\u03c0(R), R is a set of resolutions, where R = (P \u2192 2S) = (2S \u2192 2S), that is, PR : (2\nS \u2192 2S) \u2192 B, and the condition of the metaproblem \u03a0\u03c0 is also P\u03a0\u03c0 : R \u2192 B = (P \u2192 2S) \u2192 B = (2S \u2192 2S) \u2192 B. So if both PR and P\u03a0\u03c0 are elementable by \u2118R and \u2118\u03a0\u03c0, then both of them, and its conjunction, are implementable. Then T\u03a0\u03c0(R) = { r | PR(r) \u2227 P\u03a0\u03c0(r) } .= \u211c3[\u2118R \u2227 \u2118\u03a0\u03c0] = \u211c3[R \u2229 \u03a3\u03a0\u03c0]. \u22c4\n\u00a75.5.12 Summary Perceiver success depends crucially on the analogy, that is, on how much the analogy resembles the identity i. And a learner can adapt the analogy to the problem it is facing, because the learner \u211c3[R] implements a set of functions R from which it can select another analogy when the current one fails. Adapting the analogy is also known as modeling. So a learner can apply different analogies, but a learner can also apply a routine if it knows a solution, because the routine is more efficient, or a trial, when the model is not good enough or too pessimistic.\nComment The learner is a body capable of several behaviors, a governor that selects the current behavior, a simulator that internalizes behaviors, and a modeler that adjusts the model used by the simulator.\nExample Where there is modeling and simulation there is learning, because enhancing the model prevents repeating errors. A dog is a learner.\n\u00a75.6 Subject\n\u00a75.6.1 Definition A subject \u211c4 is any resolver that implements one transformation of the elements in S \u2192 S into the elements in S \u2192 S. We will note \u211c4[f] the subject that implements f, where f \u2208 ((S \u2192 S) \u2192 (S \u2192 S)), that is, \u211c4[f] = f \u2208 ((S \u2192 S) \u2192 (S \u2192 S)). Then the subject resources are in (S \u2192 S) \u2192 (S \u2192 S), and {\u00b7 \u211c4 \u00b7} = ((S \u2192 S) \u2192 (S \u2192 S)). Comment A subject \u211c4 implements a syntactic functional computation. \u00a75.6.2 Remark Subjects are to syntax as perceivers are to semantics. Comment When solutions are functions S \u2192 S, then a subject does what a perceiver\ndoes, which is to return a function on solutions to solutions. That is, subjects on metaproblems are as perceivers on problems. But, subjects can go further. Comment The subject \u211c4[f] implements function f from S \u2192 S to S \u2192 S, that is, f : (S \u2192 S) \u2192 (S \u2192 S). Then, \u2200f \u2208 (S \u2192 S), \u211c4[f](f) = f(f) \u2208 (S \u2192 S).\n\u00a75.6.3 Notation As resolutions return sets of elements in S, to normalize the situation of subjects, for which \u211c4[f](f)(s) \u2208 S, we will use the rewriting rules in \u00a73.1.3 to get \u211c4[f](F )(S) = {\u211c4[f](f)(s) | s\u2208S \u00d7 f \u2208F } \u2208 2S. Comment Subject \u211c4[f](F )(S) has two software levels: semantics (S) and syntax (F ). \u00a75.6.4 Lemma Every learner \u211c3 is a subject \u211c4, that is, {\u00b7 \u211c3 \u00b7} \u2282 {\u00b7 \u211c4 \u00b7}. Proof First we define set B = {K\u22a4, K\u22a5}, both functions S \u2192 S, see \u00a75.1.8. Next we\ndefine the the natural isomorphism between B and B, mapping \u22a4 to the function that always returns \u22a4, which is K\u22a4 = P\u03c4 , and \u22a5 to the function that always returns \u22a5, which is K\u22a5 = P\u03c4\u0304 , see \u00a73.1.11. And so B \u21d4 B : \u22a4 \u2194 K\u22a4,\u22a5 \u2194 K\u22a5, and B \u223c= B \u2282 (S \u2192 S). Then, ((S \u2192 S) \u2192 B) \u2282 ((S \u2192 S) \u2192 (S \u2192 S)), and therefore {\u00b7 \u211c3 \u00b7} = ((S \u2192 S) \u2192 B) \u2282 ((S \u2192 S) \u2192 (S \u2192 S)) = {\u00b7 \u211c4 \u00b7}. \u22c4 Comment Each learner implements one condition PF \u2208 ((S \u2192 S) \u2192 B). And any condition on functions PF \u2208 ((S \u2192 S) \u2192 B) is also a function on functions to functions PF \u2208 ((S \u2192 S) \u2192 (S \u2192 S)), because B \u2282 (S \u2192 S). Therefore, for each learner \u211c3[PF ], which implements condition PF , there is a subject \u211c4[PF ] that implements the function PF , and then we write \u211c3[PF ] = PF = \u211c4[PF ]. Comment Again, \u211c3[PF ] = \u211c4[PF ] explains that the results are the same, but not the implementation.\n\u00a75.6.5 Lemma \u2200F \u2208 2S\u2192S, \u2200S \u2208 2S, \u211c3[F ](S) = \u211c4[u](F )(S). Comment Function u is the identity for programs, see \u00a74.2.3, or functional identity, or\nevaluation, see \u00a74.3.9. Function u is syntactic because it is not restricted to semantic objects, see \u00a75.1.10. Syntactic function u is equivalent to \u03bb-calculus I = (\u03bbx.x), see \u00a73.4.9: \u2200f \u2208 S \u2192 S, u(f) = f and \u2200s \u2208 S, u(f)(s) = f(s). Proof By the rewriting rules in \u00a73.1.3, \u211c4[u](F )(S) = {\u211c4[u](f)(s) | s\u2208S\u00d7 f \u2208F } = { u(f)(s) | s\u2208S \u00d7 f \u2208F } = { f(s) | s\u2208S \u00d7 f \u2208F } = F (S) = \u211c3[F ](S). \u22c4 Corollary \u2200F \u2208 2S\u2192S, \u211c3[F ] = \u211c4[u](F ).\n\u00a75.6.6 Lemma \u2200F \u2208 2S\u2192S, \u2200S \u2208 2S, \u039e\u211c3[F ](S) = \u039e\u211c4[u](F )(S) and \u03a6\u211c3[F ](S) = \u03a6\u211c4[u](F )(S). Proof Because, by Lemma \u00a75.6.5, \u211c3[F ](S) = \u211c4[u](F )(S). \u22c4 Definition The subject condition is satisfied if it implements the functional identity u. Comment If the subject condition holds, then the subject \u211c4[u](F )(S) solves any prob-\nlem solved by the learner \u211c3[F ](S), and also the subject \u211c4[u](F )(S) resolves any problem resolved by the learner \u211c3[F ](S).\nRemark Functional identity u is the ideal for reason.\n\u00a75.6.7 Corollary In particular, \u039e\u211c4[u](R)(S \u2229 \u03a3\u03c0) = \u039e\u211c3[R](S \u2229 \u03a3\u03c0) and \u03a6\u211c4[u](R)(S \u2229 \u03a3\u03c0) = \u03a6\u211c3[R](S \u2229 \u03a3\u03c0). Proof By Lemma \u00a75.6.6. \u22c4 Comment Subject \u211c4[u](R)(S\u2229\u03a3\u03c0) is more flexible than learner \u211c3[R](S\u2229\u03a3\u03c0), because\nR is software for the subject while it is hardware in the learner, and software is cheaper than hardware, see \u00a75.4.3.\n\u00a75.6.8 Theorem Subject \u211c4[u] is a full resolution machine. Proof By Theorem \u00a74.2.1 and Lemma \u00a74.2.3, \u211c4[u] = u = c(U), so using the program\nisomorphism, see \u00a74.1.12, \u211c4[u] = U , which is a Turing complete device, and therefore is a full resolution machine, by Theorem \u00a74.4.2. \u22c4\n\u00a75.6.9 Lemma Any effectively calculable resolution \u211c can be implemented by the subject \u211c4[u]. Proof By Theorem \u00a75.6.8. \u22c4 Corollary Any effectively calculable meta-analogy resolution A \u25e6 TA\u03a0\u03c0(R) \u25e6 TA can\nbe implemented by the subject \u211c4[u], including metaresolving, see \u00a73.5.11. \u00a75.6.10 Summary The subject, by internalizing metaproblems, prevents meta-errors,\nthat is, the subject can test internally a resolution before executing it. The subject is also more flexible than the learner, because subject modeling is done in software, instead of in hardware. And subject \u211c4[u] can reason about any model. This means that subject \u211c4[u] is a resolver that can calculate solutions, but also problems and resolutions without limits; it can represent the problem it is facing to itself, and it can represent itself to itself. In this sense, the subject \u211c4[u] is conscious.\nComment The subject is a body capable of several behaviors, a governor that selects the current behavior, a simulator that internalizes behaviors, a modeler that adjusts the model used by the simulator, and a reason that internalizes resolutions.\nExample It seems that only our species, Homo sapiens, is Turing complete. We deal with the evolution to Turing completeness and its relation to language in Casares (2016b).\n\u00a75.7 Resolvers Hierarchy\n\u00a75.7.1 Theorem There is a hierarchy of resolvers: {\u00b7 \u211c0 \u00b7} \u2282 {\u00b7 \u211c1 \u00b7} \u2282 {\u00b7 \u211c2 \u00b7} \u2282 {\u00b7 \u211c3 \u00b7} \u2282 {\u00b7 \u211c4 \u00b7}. Proof Because S \u2282 (S \u2192 B) \u2282 (S \u2192 S) \u2282 ((S \u2192 S) \u2192 B) \u2282 ((S \u2192 S) \u2192 (S \u2192 S)), by Lemmas \u00a75.3.3, \u00a75.4.4, \u00a75.5.4, and \u00a75.6.4. There are not more types of resolvers, because there is not a resolver more capable than \u211c4[u] = U , by Theorems \u00a75.6.8 and \u00a74.3.4. \u22c4\n\u00a75.7.2 Summary This table groups concepts closely related from problem theory, as trial, computing theory, as adapter \u211c1, and set theory, as S \u2208 S \u2192 B.\nSemantics Syntax\nRoutine Meta-routine one Mechanism \u211c0 Perceiver \u211c2 element\ns \u2208 S f \u2208 (S \u2192 S) Trial Meta-trial\nsome Adapter \u211c1 Learner \u211c3 set S \u2208 S \u2192 B F \u2208 (S \u2192 S) \u2192 B Analogy Meta-analogy\nany Perceiver \u211c2 Subject \u211c4 function f \u2208 S \u2192 S f \u2208 (S \u2192 S) \u2192 (S \u2192 S)\nS S \u2192 S Elements Functions\nComment A perceiver is a syntactic mechanism. A learner is a syntactic adapter. A subject is a syntactic perceiver. A subject is a syntactic2 mechanism.\n\u00a75.7.3 Theorem The problem theory is complete. Proof Aside from definitions, the problem theory posits that there are three ways to\nresolve a problem: routine, trial, and analogy; see \u00a72.3. Adding the metaproblem of the problem, we get five ways to resolve a problem and its metaproblem, which are the basic three plus meta-trial and meta-analogy, see \u00a73.6.8. For each way there is a resolver, see Lemmas \u00a75.2.5, \u00a75.3.9, \u00a75.4.9, \u00a75.5.11, and \u00a75.6.9, and the resources of each resolver are in a series of mathematical objects of increasing generality that covers everything until syntactic functions, see \u00a75.7.1 and \u00a75.7.2. Now, to execute metaanalogies, 22\nS\u21922S \u2192 22S\u21922S, see \u00a73.6.9, or at least the elementable ones, see \u00a75.4.8, we need subjects, which implement syntactic functions (S \u2192 S) \u2192 (S \u2192 S). And there is a subject that is a Turing complete device, \u211c4[u], see \u00a75.6.8, so it has the maximum computing power, see \u00a74.3.4, and then the maximum resolving power, see \u00a74.4.2. This means that there are not more resolvers beyond the subject, and therefore that the series is complete, and then that the problem theory covers everything and is complete. \u22c4\nComment It also means that no more resolutions are needed, although we could do without routine, for example, by using Theorem \u00a73.3.7, and then reducing routines to trials. Nevertheless, a routine is not a trial, because a semantic element is not a semantic set, or because a mechanism implementing a routine is not an adapter implementing a trial, see comment to Lemma \u00a75.3.4. Comment This theorem is true if the Turing\u2019s thesis is true, see \u00a74.3.1. Conversely, if this theorem is true, then \u2018what is effectively calculable to resolve problems is computable\u2019.\n\u00a75.7.4 Remark Provided that a bigger range means more survival opportunities, that software is cheaper than hardware, that the adapter, the perceiver, the learner, and the subject conditions are satisfied in some environments, and that in each step the increasing of complexity was overcome by its fitness, then an evolution of resolvers \u2014mechanism to adapter to perceiver to learner to subject\u2014 should follow.\nComment Although depending on conditions, see Lemmas \u00a75.3.6, \u00a75.4.6, \u00a75.5.8, and \u00a75.6.6, the evolution of resolvers is directed, and its final singularity is the Turing complete subject \u211c4[u]. Comment In detail, the strictest evolution of resolvers is: \u039e\u211c0[s] {s}\u2282S\u2282 \u039e\u211c1[S \u2229\u03a3\u03c0]\nS\u2282S\u2032\u2282 \u039e\u211c2[i](S\u2032\u2229 \u03a3\u03c0) {i}\u2282R \u2286 \u039e\u211c3[R](S\u2032 \u2229 \u03a3\u03c0) R\u2282R\u2032\n\u2286 \u039e\u211c4[u](R\u2032)(S\u2032 \u2229 \u03a3\u03c0). \u00a75.7.5 Thesis We are the result of an evolution of resolvers of the survival problem. Argument The resolvers hierarchy suggests an evolution of resolvers of the survival\nproblem, see \u00a75.7.4. And lacking of better explanations, that we are Turing complete resolvers, that is, subjects \u211c4[u] = U , see \u00a74.2.8, suggests that we are indeed the result of an evolution of resolvers of the survival problem.\nComment Our species is Turing complete. Therefore we must explain the evolution of Turing completeness.\n\u00a76 Conclusion\n\u00a76.1 Purpose \u00b61 \u00b7 The problem theory is the union of set theory and computing theory. The integration of the two theories is achieved by using a new vocabulary to refer to old concepts, but mainly by giving the old theories a purpose that they did not have: to resolve problems. For example, a set defined by intension is named a problem, and the same set defined by extension is named its set of solutions. While both still refer to the same set, as it is the case in set theory, the status of each of them is now very different: one is a question and the other is an answer. And when the problem theory states that computing is resolving, it is calling a set resolvable if it is recursively enumerable, but mainly it is saying that the transition from intension to extension has to be calculated, because it is not written magically in \u201cThe Book\u201d; someone has to write it. \u00b62 \u00b7 The purpose of resolving problems is not final, but the main conclusion of the paper, the Thesis \u00a75.7.5, is nearly ultimate: We are Turing complete subjects because we are the result of an evolution of resolvers of the survival problem. In other words, we resolve problems to survive. So, if survival is indeed the ultimate purpose, then the problem theory provides purpose and meaning to set theory and to computing theory. \u00b63 \u00b7 The final Thesis \u00a75.7.5 also closes a loop, because a Turing complete resolver \u211c4[u] can model everything, and then everything can be a solution, as it is stated in Theorem \u00a73.2.1. But those everythings are not absolute, but limited to what is computable, see \u00a74.4.11. That is, if Turing\u2019s thesis stands, see \u00a74.3.1, then everything is everything that is computable. This way a restriction of computing theory, countability, is inherited by problem theory and transferred to set theory; see the details below in Subsection \u00a76.2. The other question that requires some more elaboration is the status of the Turing\u2019s thesis itself, which we will postpone until Subsection \u00a76.3. \u00b64 \u00b7 Nevertheless, besides that main Thesis \u00a75.7.5, the problem theory concepts presented in this paper can be used to model, understand, and classify both natural and artificial resolvers, because the paper provides definitions, theorems, and taxonomies for resolvers, and also for problems. And, by the way, the paper defines adaptation, perception, and learning, and it shows that there are just three ways to resolve any problem: routine, trial, and analogy.\n\u00a76.2 Countability \u00b61 \u00b7 In computing everything is countable, see \u00a74.1.14, and the problem theory in Turing universes inherited countability from computing theory, see \u00a74.3.16. In a Turing universe, see \u00a74.3.3, the limits of calculation are the limits of computing, and then there are only computable functions, including predicates, see \u00a74.1.9, and computable sets, see \u00a74.4.3. Then the problem theory in Turing universes is consistent if and only if computing is consistent. And computing is consistent, as a corollary to Church-Rosser theorem in \u03bb-calculus, see Curry & Feys (1958) Chapter 4. \u00b62 \u00b7 Therefore, our way to control paradoxes in set theory, and then in this paper, is to confine ourselves to Turing universes. But don\u2019t worry; if this is a Turing universe, as it seems to be, then we are only excluding imaginary universes. \u00b63 \u00b7 For example, the mathematical theorem that states that everything is a solution is proved, and it makes sense, see \u00a73.2.1. But it also causes paradoxes, because from it we derive P \u2282 S, but P 1= (S \u2192 B) 2= 2S, and then |P| 3= |2S| 4= 2|S| > |S|, by Cantor\u2019s theorem. It is not a paradox in a Turing universe because the forth equality is false in it. The second equality is false in a Turing universe because, as we saw in Lemma \u00a74.4.8, there are resolvable problems that are not expressible, so (S \u2192 B) \u2217\u2282 2S. The third equality is true, though it follows the second one! And the forth equality is false in a Turing universe because the number of computable sets is countable, so, if |S\u2217| = \u21350, then |2S|\u2217 = \u21350 < 2\u21350 = 2|S\n\u2217|, that is, |2S| \u2217< 2|S|. Therefore, P\u2217\u2282 S\u2217 is true, but P\u2217 is the set of computable predicates, that is, P\u2217 = E of \u00a74.5.8, and [2S]\u2217 \u2282 S\u2217 is also true, but [2S]\u2217 is the set of computable sets, that is, [2S]\u2217 = R of \u00a74.5.8. The conclusion is that S\u2217, the set of solutions, is the set of everything that is computable. \u00b64 \u00b7 We have just rejected the uncountable case, where |P| > \u21350, but there are two other possibilities: the (infinite) countable case, where |S\u2217| = |P\u2217| = |R\u2217| = \u21350, see \u00a74.3.16; and the finite case, where |S\u0393| < |P\u0393| < |R\u0393| < \u21350, see \u00a75.1.7. \u00b65 \u00b7 We are finite, so it would be natural to restrict our investigations to the finite case, calling for finiteness instead of calling for countableness. But the finite case is trivial, and more importantly, the difference between an unrestricted universal computer and a finite universal computer is not qualitative but quantitative. There is not any step of any calculation that an unrestricted universal computer can compute and a finite universal computer cannot compute, see \u00a74.2.10. So in the limit, that is, without time nor memory restrictions, we are universal computers. And note that those restrictions are variable, and that they can be relaxed nearly as desired just spending some more time, or building a faster computer machine, or using some more external memory. In the case of a Turing machine, the external memory is the tape, and the internal memory is where its processor keeps the internal state, see \u00a74.1.3. Note also that we can code a program to generate every natural number, although we cannot follow the computation till its end. Summarizing: we are better defined saying that we are qualitatively universal Turing machines, but with some unspecified quantitative limitations, than saying that we are qualitatively finite state automata, because finite state automata are not expandable. \u00b66 \u00b7 Finally, the rejections of finiteness and uncountableness imply that countableness is the golden mean. This is Pythagorean heaven revisited, everything is countable, but this time we have rescued the terrifying \u221a 2, and other irrational numbers. As Kronecker said:\n\u201cGod made counting numbers; all else is the work of man\u201d.\n\u00a76.3 Intuition \u00b61 \u00b7 Is it possible to resolve a non-computable problem? A problem is computable if, by definition, see \u00a74.4.3 and \u00a74.4.4, a Turing machine can execute a valid resolution of the problem, so the non-computable problem would not be resolved by computing, but by other means. My answer to the question is \u2018no\u2019, because I think that a problem is resolvable if, and only if, the problem is computable, see \u00a74.3.12. \u00b62 \u00b7 Nevertheless you may think otherwise, and say that there is another way of resolving, let us call it \u2018intuition\u2019, that is not computable. If that were the case, then the problem theory with its mathematical formulation, as presented in this paper, would capture the concept of \u2018computable problem\u2019, but not the whole concept of \u2018problem\u2019. In order to see this, please consider the following two statements: \u25e6 Some problems are computable. \u25e6 A universal computer can execute any computable resolution.\nEven if you believe that there are resolvable problems that are not computable, you can still decide easily that both are true; the first is a fact, and the second is a theorem. And then everything in this paper would still be true of computable problems, computable resolutions, and computable solutions. \u00b63 \u00b7 The key point in this discussion is that \u2018intuition\u2019 would refute Turing\u2019s thesis, see \u00a74.3.1, because if there were \u2018intuitive\u2019 resolutions, then we could effectively calculate what is not computable. Turing\u2019s thesis is not a theorem, and we follow Post (1936) in considering Turing\u2019s thesis to be a law of nature that states a limitation of our own species calculating capacity, see Casares (2016a), by which we are bound to see ourselves as a final singularity. Summarizing: If Turing\u2019s thesis were eventually false, then this problem theory would be about computable problems. But, while Turing\u2019s thesis remains valid, the problem theory is about problems, the set of effectively calculable functions is countable (\u00a74.3.1), universal computers are the most capable computing devices (\u00a74.3.4), everything is an expression (\u00a74.3.10), resolving is computing (\u00a74.3.12), and the problem theory is complete (\u00a75.7.3)."}], "references": [{"title": "Turing, \u201cOn Computable Numbers, with an Application to the Entscheidungsproblem\u201d; in Proceedings of the London Mathematical Society", "author": ["M. Alan"], "venue": "vol. s242,", "citeRegEx": "Alan,? \\Q1937\\E", "shortCiteRegEx": "Alan", "year": 1937}, {"title": "Turing, \u201cSystems of Logic Based on Ordinals\u201d; Princeton University PhD dissertation", "author": ["M. Alan"], "venue": "Submitted 17 May,", "citeRegEx": "Alan,? \\Q1938\\E", "shortCiteRegEx": "Alan", "year": 1938}], "referenceMentions": [], "year": 2016, "abstractText": "The Turing machine, as it was presented by Turing himself, models the calculations done by a person. This means that we can compute whatever any Turing machine can compute, and therefore we are Turing complete. The question addressed here is why, Why are we Turing complete? Being Turing complete also means that somehow our brain implements the function that a universal Turing machine implements. The point is that evolution achieved Turing completeness, and then the explanation should be evolutionary, but our explanation is mathematical. The trick is to introduce a mathematical theory of problems, under the basic assumption that solving more problems provides more survival opportunities. So we build a problem theory by fusing set and computing theories. Then we construct a series of resolvers, where each resolver is defined by its computing capacity, that exhibits the following property: all problems solved by a resolver are also solved by the next resolver in the series if certain condition is satisfied. The last of the conditions is to be Turing complete. This series defines a resolvers hierarchy that could be seen as a framework for the evolution of cognition. Then the answer to our question would be: to solve most problems. By the way, the problem theory defines adaptation, perception, and learning, and it shows that there are just three ways to resolve any problem: routine, trial, and analogy. And, most importantly, this theory demonstrates how problems can be used to found mathematics and computing on biology.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}