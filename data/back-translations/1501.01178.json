{"id": "1501.01178", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jan-2015", "title": "Constraint-based sequence mining using constraint programming", "abstract": "The aim of sequence mining is to find sequences of symbols that are contained in a large number of input sequences (i.e. partial sequences thereof). In the literature, many limitations have been suggested for this type of problem, but there is no general framework for dealing with these limitations. We examine the use of constraint programming as a general framework for this task. First, we identify four categories of limitations that are applicable to sequence mining. Subsequently, we propose two constraint programming formulations: the first introduces a new global limitation, the existing embedding, which hides the complexity of the inclusion relationship. However, this approach does not support one category of limitations. To support such limitations, we develop a second, more general formulation, which, however, causes more effort. Both formulations can be associated with the projected database technology used in specialized algorithms, and we can use the constraint based on existing search frequencies to show the flexibility that exists.", "histories": [["v1", "Tue, 6 Jan 2015 13:47:24 GMT  (59kb,D)", "https://arxiv.org/abs/1501.01178v1", null], ["v2", "Thu, 8 Jan 2015 13:50:53 GMT  (63kb,D)", "http://arxiv.org/abs/1501.01178v2", null], ["v3", "Wed, 25 Feb 2015 16:31:27 GMT  (66kb,D)", "http://arxiv.org/abs/1501.01178v3", "In Integration of AI and OR Techniques in Constraint Programming (CPAIOR), 2015"]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["benjamin negrevergne", "tias guns"], "accepted": false, "id": "1501.01178"}, "pdf": {"name": "1501.01178.pdf", "metadata": {"source": "CRF", "title": "Constraint-based sequence mining using constraint programming", "authors": ["Benjamin Negrevergne", "Tias Guns"], "emails": ["firstname.lastname@cs.kuleuven.be"], "sections": [{"heading": null, "text": "Keywords: sequential pattern mining, sequence mining, episode mining, constrained pattern mining, constraint programming, declarative programming"}, {"heading": "1 Introduction", "text": "In AI in general and in data mining in particular, there is an increasing interest in developing general methods for data analysis. In order to be useful, such methods should be easy to extend with domain-specific knowledge.\nIn pattern mining, the frequent sequence mining problem has already been studied in depth, but usually with a focus on efficiency and less on generality and extensibility. An important step in the development of more general approaches was the cSpade algorithm [19] which supports a variety constraints. It supports many constraints such as constraints on the length of the pattern, on the maximum gap in embeddings or on the discriminative power of the patterns between datasets. Many other constraints have been integrated into specific mining algorithms (e.g. [6,17,16,13]). However, none of these are truly generic in that adding extra constraints usually amounts to changing the data-structures used in the core of the algorithm.\n? This paper is published at CPAIOR 2015, this arxiv version additionally has an appendix.\nar X\niv :1\n50 1.\n01 17\n8v 3\n[ cs\n.A I]\n2 5\nFe b\nFor itemset mining, the simplest form of pattern mining, it has been shown that constraint programming (CP) can be used as a generic framework for constraint-based mining [5] and beyond [14,11]. Recent works have also investigated the usage of CP-based approaches for mining sequences with explicit wildcards [3,7,8]. A wildcard represents the presence of exactly one arbitrary symbol in that position in the sequence.\nThe main difference between mining itemsets, sequences with wildcards and standard sequences lies in the complexity of testing whether a pattern is included in another itemset/sequence, e.g. from the database. For itemsets, this is simply testing the subset inclusion relation which is easy to encode in CP. For sequences with wildcards and general sequences, one has to check whether an embedding exists (matching of the individual symbols). But in case only few embeddings are possible, as in sequences with explicit wildcards, this can be done with a disjunctive constraint over all possible embeddings [8]. In general sequence (the setting we address in this paper), a pattern of size m can be embedded into a sequence of size n in O(nm) different ways, hence prohibiting a direct encoding or enumeration.\nThe contributions of this paper are as follows:\n\u2013 We present four categories of user-constraints, this categorization will be useful to compare the generality of the two proposed models. \u2013 We introduce an exists-embedding global constraint for sequences, and show the relation to projected databases and projected frequency used in the sequence mining literature to speedup the mining process [6,20]. \u2013 We propose a more general formulation using a decomposition of the exists-embedding constraint. Searching whether an embedding exists for each transaction is not easily expressed in CP and requires a modified search procedure. \u2013 We investigating the effect of adding constraints, and compare our method with state-of-the-art sequence mining algorithms.\nThe rest of the paper is organized as follows: Section 2 formally introduces the sequence mining problem and the constraint categories. Section 3 explains the basics of encoding sequence mining in CP. Section 4 and 5 present the model with the global constraint and the decomposition respectively. Section 6 presents the experiments. After an overview of related work (Section 7), we discuss the proposed approach and results in Section 8."}, {"heading": "2 Sequence mining", "text": "Sequence mining [1] can be seen as a variation of the well-known itemset mining problem proposed in [2]. In itemset mining, one is given a set of transactions, where each transaction is a set of items, and the goal is to find patterns (i.e. sets of items) that are included in a large number of transactions. In sequence mining, the problem is similar except that both transactions and patterns are ordered, (i.e. they are sequences instead of sets) and symbols can be repeated. For example, \u3008b, a, c,b\u3009 and \u3008a, c, c,b,b\u3009 are two sequences, and the sequence \u3008a,b\u3009 is one possible pattern included in both.\nThis problem is known in the literature under multiple names, such as embedded subsequence mining, sequential pattern mining, flexible motif mining, or serial episode mining depending on the application."}, {"heading": "2.1 Frequent sequence mining: problem statement", "text": "A key concept of any pattern mining setting is the pattern inclusion relation. In sequence mining, a pattern is included in a transaction if there exists an embedding of that sequence in the transaction; where an embedding is a mapping of every symbol in the pattern to the same symbol in the transaction such that the order is respected.\nDefinition 1 (Embedding in a sequence). Let S = \u3008s1, . . . , sm\u3009 and S\u2032 = \u3008s\u20321, . . . , s\u2032n\u3009 be two sequences of size m and n respectively with m \u2264 n. The tuple of integers e = (e1, . . . , em) is an embedding of S in S\u2032 (denoted S ve S\u2032) if and only if:\nS ve S\u2032 \u2194 e1 < . . . < em and \u2200i \u2208 1, . . . ,m : si = s\u2032ei (1)\nFor example, let S = \u3008a,b\u3009 be a pattern, then (2, 4) is an embedding of S in \u3008b, a, c,b\u3009 and (1, 4), (1, 5) are both embeddings of S in \u3008a, c, c,b,b\u3009. An alternative setting considers sequences of itemsets instead of sequences of individual symbols. In this case, the definition is S ve S\u2032 \u2194 e1 < . . . < en and \u2200i \u2208 1, . . . , n : si \u2286 s\u2032ei . We do not consider this setting further in this paper, though it is an obvious extension.\nWe can now define the sequence inclusion relation as follows:\nDefinition 2 (Inclusion relation for sequences). Given two sequences S and S\u2032, S is included in S\u2032 (denoted S v S\u2032) if there exists an embedding e of S in S\u2032:\nS v S\u2032 \u2194 \u2203e s.t. S ve S\u2032. (2)\nTo continue on the example above, S = \u3008a,b\u3009 is included in both \u3008b, a, c,b\u3009 and \u3008a, c, c,b,b\u3009 but not in \u3008c,b, a, a\u3009.\nDefinition 3 (Sequential dataset). Given an alphabet of symbols\u03a3, a sequential dataset D is a multiset of sequences defined over symbols in \u03a3.\nEach sequence in D is called a transaction using the terminology from itemset mining. The number of transactions in D is denoted |D| and the sum of the lengths of every transaction in D is denoted ||D|| (||D|| = \u2211|D| i=1 |Ti|). Furthermore, we use dataset as a shorthand for sequential dataset when it is clear from context. Given a dataset D = {Ti, . . . , Tn}, one can compute the cover of a sequence S as the set of all transactions Ti that contain S:\ncover(S,D) = {Ti \u2208 D : S v Ti} (3)\nWe can now define frequent sequence mining, where the goal is to find all patterns that are frequent in the database; namely, the size of their cover is sufficiently large.\nDefinition 4 (Frequent sequence mining). Given:\n1. an alphabet \u03a3 2. a sequential dataset D = {T1, . . . , Tn} defined over \u03a3 3. a minimum frequency threshold \u03b8,\nenumerate all sequences S such that |cover(S,D)| \u2265 \u03b8.\nIn large datasets, the number of frequent sequences is often too large to be analyzed by a human. Extra constraints can be added to extract fewer, but more relevant or interesting patterns. Many such constraints have been studied in the past."}, {"heading": "2.2 Constraints", "text": "Constraints typically capture background knowledge and are provided by the user. We identify four categories of constraints for sequence mining: 1) constraints over the pattern, 2) constraints over the cover set, 3) constraints over the inclusion relation and 4) preferences over the solution set.\nConstraints on the pattern These put restrictions on the structure of the pattern. Typical examples include size constraints or regular expression constraints. Size constraints: A size constraint is simply |S| \u2277 \u03b1 where \u2277\u2208 {=, 6=, >,\u2265, <,\u2264} and \u03b1 is a user-supplied threshold. It is used to discard small patterns. Item constraints: One can constrain a symbol t to surely be in the pattern: \u2203s \u2208 S : s = t; or that it can not appear in the pattern: \u2200s \u2208 S : s 6= t, or more complex logical expressions over the symbols in the pattern. Regular expression constraints: Let R be a regular expression over the vocabulary V and LR be the language of sequences recognised by R, then for any sequence pattern S over V , the match-regular constraint requires that S \u2208 LR [6].\nConstraints on the cover set. The minimum frequency constraint |cover(S,D)| \u2265 \u03b8 is the most common example of a constraint over the cover set. Alternatively, one can impose the maximum frequency constraint: |cover(S,D)| \u2264 \u03b2 Discriminating constraints: In case of multiple datasets, discriminating constraints require that patterns effectively distinguish the datasets from each other. Given two datasets D1 and D2, one can require that the ratio between the size of the cover of both is above a threshold: |cover(S,D1)||cover(S,D2)| \u2265 \u03b1. Other examples include more statistical measures such as information gain and entropy [12].\nConstraints over the inclusion relation. The inclusion relation in definition 2 states that S v S\u2032 \u2194 \u2203e s.t. S ve S\u2032. Hence, an embedding of a pattern can match symbols that are far apart in the transaction. For example, the sequence \u3008a, c\u3009 is embedded in the transaction \u3008a,b,b,b, . . . ,b, c\u3009 independently of the distance between a and c in the transaction. This is undesirable when mining datasets with long transactions. The max-gap and max-span constraints [19] impose a restriction on the embedding, and hence on the inclusion relation. The max-gap constraint is satisfied on a transaction Ti if an embedding e maps every two consecutive symbols in S to symbols in Ti that are close to each-other: max-gapi(e) \u21d4 \u2200j \u2208 2..|Ti|, (ej \u2212 ej\u22121 \u2212 1) \u2264 \u03b3. For example, the sequence \u3008abc\u3009 is embedded in the transaction \u3008adddbc\u3009 with a maximum gap of 3 whereas \u3008ac\u3009 is not. The max-span constraint requires that the distance between the first and last position of the embedding of all transactions Ti is below a threshold \u03b3: max-spani(e)\u21d4 e|Ti| \u2212 e1 + 1 \u2264 \u03b3.\nPreferences over the solution set. A pairwise preference over the solution set expresses that a pattern A is preferred over a pattern B. In [11] it was shown that condensed representations like closed, maximal and free patterns can be expressed as pairwise preference relations. Skypatterns [14] and multi-objective optimisation can also be seen as preference over patterns. As an example, let\u2206 be the set of all patterns; then, the set of all closed patterns is {S \u2208 \u2206|@S\u2032 s.t. S @ S\u2032 and cover(S,D) = cover(S\u2032, D)}."}, {"heading": "3 Sequence Mining in Constraint Programming", "text": "In constraint programming, problems are expressed as a constraint satisfaction problem (CSP), or a constraint optimisation problem (COP). A CSP X = (V,D,C) consists of a set of variables V , a finite domain D that defines for each variable v \u2208 V the possible values that it can take, and a set of constraints C over the variables in V . A solution to a CSP is an assignment of each variable to a value from its domain such that all constraints are satisfied. A COP additionally consists of an optimisation criterion f(V ) that expresses the quality of the solution.\nThere is no restriction on what a constraint C can represent. Examples include logical constraints like X\u2227Y or X\u2192 Y and mathematical constraints such as Z = X+Y etc. Each constraint has a corresponding propagator that ensures the constraint is satisfied during the search. Many global constraints have been proposed, such as alldifferent, which have a custom propagator that is often more efficient then if one would decompose that constraint in terms of simple logical or mathematical constraints. A final important concept used in this paper is that of reified constraints. A reified constraint is of the form B\u2194 C \u2032 where B is a Boolean variable which will be assigned to the truth value of constraint C \u2032. Reified constraints have their own propagator too.\nVariables and domains for modeling sequence mining. Modeling a problem as a CSP requires the definition of a set of variables with a finite domain, and a set of constraints. One solution to the CSP will correspond to one pattern, that is, one frequent sequence.\nWe model the problem using an array S of integer variables representing the characters of the sequence and an array C of Boolean variables representing which transactions include the pattern. This is illustrated in Fig. 1:\n1. T1 and T2 represent two transactions given as input. We denote the number of transactions by n; 2. The array of variables S represents the sequence pattern. Each variable Sj represents the character in the jth position of the sequence. The size of S is determined by the length of the longest transactions (in the example this is 4). We want to allow patterns that have fewer than maxi(|Ti) characters, hence we use to represent an unused position in S. The domain of each variable Sj is thus \u03a3 \u222a { }; 3. Boolean variables Ci represent whether the pattern is included in transaction Ti, that is, whether S v Ti. In the example, this is the case for T1 but not for T2.\nWhat remains to be defined is the constraints. The key part here is how to model the inclusion relation; that is, the constraint that verifies whether a pattern is included in the\ntransaction. Conceptually, this is the following reified constraint: Ci \u2194 \u2203e s.t. S ve Ti. As mentioned in the introduction, the number of possible embeddings is exponential in the size of the pattern. Hence, one can not model this as a disjunctive constraint over all possible embeddings (as is done for sequences with explicit wildcards [8]).\nWe propose two approaches to cope with this problem: one with a global constraint that verifies the inclusion relation directly on the data, and one in which the inclusion relation is decomposed and the embedding is exposed through variables.\n4 Sequence mining with a global exists-embedding constraint\nThe model consists of three parts: encoding of the pattern, of the minimum frequency constraint and finally of the inclusion relation using a global constraint.\nVariable-length pattern: The array S has length k; patterns with l < k symbols are represented with l symbols from \u03a3 and (k \u2212 l) times an value. To avoid enumerating the same pattern with values in different positions, values can only appear at the end:\n\u2200j \u2208 1..(k \u2212 1) : Sj = \u2192 Sj+1 = (4)\nMinimum frequency: At least \u03b8 transactions should include the pattern. This inclusion is indicated by the array of Boolean variables C:\nn\u2211 i=1 Ci \u2265 \u03b8 (5)\nGlobal exists-embedding constraint: The goal is to encode the relation: Ci \u2194 \u2203e s.t. S ve Ti. The propagator algorithm for this constraint is given in Algorithm 1. It is an incremental propagator that should be run when one of the S variables is assigned. Line 1 will loop over the variables in S until reaching an unassigned one at position posS . In the sequence mining literature, the sequence \u3008S1..SposS\u3009 is called the prefix. For each assigned Sj variable, a matching element in the transaction is sought, starting from the position pose after the element that matched the previous Sj\u22121 assigned variable. If no such match is found then an embedding can not be found and Ci is set to false.\nLine 11 is called when an Sj variable is assigned to . This line can only be reached if all previous values of S are assigned and were matched in Ti, hence the propagator can set Ci to true and quit. Similarly for line 14 when the end of the sequence is reached, and lines 15-20 in case the transaction is smaller than the sequence. Lines 21- 22 propagate the remaining possible symbols from Ti to the first unassigned S variable in case Ci = True.\nThe propagator algorithm has complexity O(|Ti|): the loop on line 1 is run up to |Ti| times and on line 3 at most |Ti| times in total, as pose is monotonically increasing.\n4.1 Improved pruning with projected frequency\nCompared to specialised sequence mining algorithms, posS in Algorithm 1 points to the first position in S after the current prefix. Dually, pose points to the position after\nAlgorithm 1 Incremental propagator for Ci \u2194 \u2203e s.t. S ve Ti: internal state, posS: current position in S to check, initially 1 internal state, pose: current position in Ti to match to, initially 1 1: while posS \u2264 |Ti| and S[posS] is assigned do . note that |Ti| \u2264 |S| 2: if S[posS] 6= then 3: while not (Ti[pose] = S[posS ]) and pose \u2264 |Ti| do . find match 4: pose \u2190 pose + 1 5: end while 6: if pose \u2264 |Ti| then . match found, on to next one 7: posS \u2190 posS + 1; pose \u2190 pose + 1 8: else 9: propagate Ci = False and return 10: else . previous ones matched and rest is 11: propagate Ci = True and return 12: end while 13: if posS > |S| then . previous ones matched and reached end of sequence 14: propagate Ci = True and return 15: if posS > |Ti| and |Ti| < |S| then 16: let R\u2190 S[|Ti|+ 1] 17: if R is assigned and R = then . S should not be longer than this transaction 18: propagate Ci = True and return 19: if is not in the domain of R then 20: propagate Ci = False and return 21: if Ci is assigned and Ci = True then 22: propagate by removing from S[posS ] all symbols not in \u3008Ti[pose]..Ti[|Ti|]\u3009 except\nthe first match of the prefix in the transaction. If one would project the prefix away, only the symbols in the transaction from pose on would remain; this is known as prefix projection [6]. Given prefix \u3008a, c\u3009 and transaction \u3008b, a, a, e, c,b, c,b,b\u3009 the projected transaction is \u3008b, c,b,b\u3009.\nThe concept of a prefix-projected database can be used to recompute the frequency of all symbols in the projected database. If a symbol is present but not frequent in the projected database, one can avoid searching over it. This is known to speed up specialised mining algorithms considerably [6,16].\nTo achieve this in the above model, we need to adapt the global propagator so that it exports the symbols that still appear after pose. We introduce an auxiliary integer variable Xi for every transaction Ti, whose domain represents these symbols (the set of symbols is monotonically decreasing). To avoid searching over infrequent symbols, we define a custom search routine (brancher) over the S variables. It first computes the local frequencies of all symbols based on the domains of the Xi variables; symbols that are locally infrequent will not not be branched over. See Appendix A for more details."}, {"heading": "4.2 Constraints", "text": "This formulation supports a variety of constraints, namely on the pattern (type 1), on the cover set (type 2) and over the solution set (type 4). For example, the type 1 constraint\nmin-size, constrains the size of the pattern to be larger than a user-defined threshold \u03b1. This constraint can be formalised as follows.\nk\u2211 j=1 [Sj 6= ] \u2265 \u03b1 (6)\nMinimum frequency in Equation (5) is an example of a constraint of type 2, over the cover set. Another example is the discriminative constraint mentioned in Section 2.2: given two datasets D1 and D2, one can require that the ratio between the cover in the two datasets is larger than a user defined threshold \u03b1: |cover(S,D1)||cover(S,D2)| \u2265 \u03b1. Let D = D1 \u222a D2 and let t1 = {i|Ti \u2208 D1} and t2 = {i|Ti \u2208 D2} then we can extract the discriminant patterns from D by applying the following constraint.\u2211\ni\u2208t1 Ci\u2211 i\u2208t2 Ci \u2265 \u03b1 (7)\nSuch a constraint can also be used as an optimisation criterion in a CP framework. Type 4 constraints a.k.a. preference relations have been proposed in [11] to formalise well-known pattern mining settings such as maximal or closed patterns. Such preference relations can be enforced dynamically during search for any CP formulation [11]. The preference relation for closed is S\u2032 S \u21d0\u21d2 S @ S\u2032 \u2227 cover(S,D) = cover(S\u2032, D) and one can reuse the global reified exists-embedding constraint for this.\nFinally, type 3 constraints over the inclusion relation are not possible in this model. Indeed, a new global constraint would have to be created for every possible (combination of) type 3 constraints. For example for max-gap, one would have to modify Algorithm 1 to check whether the gap is smaller than the threshold, and if not, to search for an alternative embedding instead (thereby changing the complexity of the algorithm)."}, {"heading": "5 Decomposition with explicit embedding variables", "text": "In the previous model, we used a global constraint to assign the Ci variables to their appropriate value, that is: Ci \u2194 \u2203e s.t. S ve Ti. The global constraint efficiently tests the existence of one embedding, but does not expose the value of this embedding, thus it is impossible to express constraints over embeddings such as themax-gap constraint.\nTo address this limitation, we extend the previous model with a set of embedding variables Ei1, . . . ,Ei|Ti| that will represent an embedding e = (e1, . . . , e|Ti|) of sequence S in transaction Ti. In case there is no possible match for a character Si in Ti, the corresponding Eij variable will be assigned a no-match value."}, {"heading": "5.1 Variables and constraints", "text": "Embedding variables. For each transaction Ti of length |Ti|, we introduce integer variables Ei1, . . . ,Ei|Ti|. Each variable Eij is an index in Ti, and an assignment to Eij maps the variable Sj to a position in Ti; see Figure 2, the value of the index is materialized by the red arrows. The domain of Eij is initialized to all possible positions of Ti, namely 1, . . . , |Ti| plus a no-match entry which we represent by the value |Ti|+1.\nThe position-match constraint. This constraint ensures that the variables Ei either represent an embedding e such that S ve Ti or otherwise at least one Eij has the nomatch value. Hence, each variable Eij is assigned the value x only if the character in Si is equal to the character at position x in Ti. In addition, the constraint also ensures that the values between two consecutive variables Eij,Ei(j+1) are increasing so that the order of the characters in the sequence is preserved in the transaction. If there exist no possible match satisfying these constraints, the no-match value is assigned.\n\u2200i \u2208 1, . . . , n, \u2200j \u2208 1, . . . , |Ti| : (Sj = Ti[Eij]) \u2228 (Eij = |Ti|+ 1) (8) \u2200i \u2208 1, . . . , n, \u2200j \u2208 2, . . . , |Ti| : (Ei(j\u22121) < Eij) \u2228 (Eij = |Ti|+ 1) (9)\nHere Sj = Ti[Eij] means that the symbol of Sj equals the symbol at index Eij in transaction Ti. See Appendix B for an effective reformulation of these constraints.\nIs-embedding constraint. Finally, this constraint ensures that a variable Ci is true if the embedding variables Ei1, . . . ,Ei|Ti| together form a valid embedding of sequence S in transaction Ti. More precisely: if each character Sj 6= is mapped to a position in the transaction that is different from the no-match value.\n\u2200i \u2208 1, . . . , n : Ci \u2194 \u2200j \u2208 1, . . . , |Ti| : (Sj 6= )\u2192 (Eij 6= |Ti|+ 1) (10)\nNote that depending on how the Eij variables will be searched over, the above constraints are or are not equivalent to enforcing Ci \u2194 \u2203e s.t. S ve Ti. This is explained in the following section."}, {"heading": "5.2 Search strategies for checking the existence of embeddings", "text": "CP\u2019s standard enumerative search would search for all satisfying assignments to the Sj,Ci and Eij variables. As for each sequence of size m, the number of embeddings in a transaction of size n can be O(nm), such a search would not perform well. Instead, we only need to search whether one embedding exists for each transaction.\nWith additional constraints on Eij but not Ci. When there are additional constraints on the Eij variables such as max-gap, one has to perform backtracking search to find a valid embedding. We do this after the S variables have been assigned.\nWe call the search over the S variables the normal search, and the search over the Eij variables the sub search. Observe that one can do the sub search for each transaction i independently of the other transactions as the different Ei have no influence on each other, only on Ci. Hence, one does not need to backtrack across different sub searchers.\nThe goal of a sub search for transaction i is to find a valid embedding for that transaction. Hence, that sub search should search for an assignment to the Eij variables with Ci set to true first. If a valid assignment is found, an embedding for Ti exists and the sub search can stop. If no assignment is found, Ci is set to false and the sub search can stop too. See Appendix C for more details on the sub search implementation.\nWith arbitrary constraints. The constraint formulation in Equation (10) is not equivalent to Ci \u2194 \u2203e s.t. S ve Ti. For example, lets say some arbitrary constraint propagates Ci to false. For the latter constraint, this would mean that it will enforce that S is such that there does not exists an embedding of it in Ti. In contrast, the constraint in Equation (10) will propagate some Eij to the no-match value, even if there exists a valid match for the respective Sj in Ti!\nTo avoid an Eij being set to the no-match value because of an assignment to Ci, we can replace Equation (10) by the half-reified \u2200i : Ci \u2192 (\u2200j (Sj 6= ) \u2192 (Eij 6= |Ti|+ 1) ) during normal search.\nThe sub search then has to search for a valid embedding, even if Ci is set to false by some other constraint. One can do this in the sub search of a specific transaction i by replacing the respective half-reified constraint by the constraint C\u2032i \u2194 (\u2200j (Sj 6= )\u2192 (Eij 6= |Ti|+1) ) over a new variable C\u2032i that is local to this sub search. The sub search can then proceed as described above, by setting C\u2032i to true and searching for a valid assignment to Ei. Consistency between C\u2032i and the original Ci must only be checked after the sub search for transaction i is finished. This guarantees that for any solution found, if Ci is false and so is C\u2032i then indeed, there exists no embedding of S in Ti."}, {"heading": "5.3 Projected frequency", "text": "Each Eij variable represents the positions in Ti that Sj can still take. This is more general than the projected transaction, as it also applies when the previous symbol in the sequence Sj\u22121 is not assigned yet. Thus, we can also use the Eij variables to require that every symbol of Sj must be frequent in the (generalised) projected database. This is achieved as follows.\n\u2200j \u2208 1 . . . n,\u2200x \u2208 \u03a3,Sj = x\u2192 |{i : Ci \u2227 Ti[Eij] = x}| \u2265 \u03b8 (11)\nSee Appendix D for a more effective reformulation."}, {"heading": "5.4 Constraints", "text": "All constraints from Section 4.2 are supported in this model too. Additionally, constraints over the inclusion relations are also supported; for example, max-gap and max-span. Recall from Section 2.2 that for an embedding e = (e1, . . . , ek), we have\nmax-gapi(e) \u21d4 \u2200j \u2208 2 . . . |Ti|, (ej \u2212 ej\u22121 \u2212 1) \u2264 \u03b3. One can constrain all the embeddings to satisfy the max-gap constraint as follows (note how x is smaller than the no-match value |Ti|+ 1):\n\u2200i \u2208 1 . . . n,\u2200j \u2208 2 . . . |Ti|, x \u2208 1 . . . |Ti| : Eij = x\u2192 x\u2212Ei(j\u22121) \u2264 \u03b3 + 1 (12)\nMax-span was formalized as max-spani(e)\u21d4 e|Ti|\u2212 e1 +1 \u2264 \u03b3 and can be formulated as a constraint as follows:\n\u2200i \u2208 1 . . . n,\u2200j \u2208 2 . . . |Ti|, x \u2208 1 . . . |Ti| : Eij = x\u2192 x\u2212Ei1 \u2264 \u03b3 \u2212 1 (13)\nIn practice, we implemented a simple difference-except-no-match constraint that achieves the same without having to post a constraint for each x separately."}, {"heading": "6 Experiments", "text": "The goal of these experiments is to answer the four following questions: Q1: What is the overhead of exposing the embedding variables in the decomposed model? Q2: What is the impact of using projected frequency in our models? Q3: What is the impact of adding constraints on runtime and on number of results? Q4: How does our approach compares to existing methods?\nAlgorithm and execution environment: All the models described in this paper have been implemented in the Gecode solver1. We compare our global and decomposed models (Section 4 and Section 5) to the state-of-the-art algorithms cSpade[19] and PrefixSpan [6]. We use the author\u2019s cSpade implementation2 and a publicly available PrefixSpan implementation by Y. Tabei3. We also compare our models to the CP-based approach proposed by [10]. No implementation of this is available so we reimplemented it in Gecode. Gecode does not support non-deterministic automata so we use a more compact DFA encoding that requires only O(n \u2217 |\u03a3|) transitions, by constructing it back-to-front. We call this approach regular-dfa. Unlike the non-deterministic version, this does not allow the addition of constraints of type 3 such as max-gap.\nAll algorithms were run on a Linux PC with 16 GB of memory. Algorithm runs taking more than 1 hour or more than 75% of the RAM were terminated. The implementation and the datasets used for the experiments are available online 4.\nDatasets: The datasets used are from real data and have been chosen to represent a variety of application domains. In Unix user5, each transaction is a series of shell commands executed by a user during one session. We report results on User 3; results are similar for the other users. JMLR is a natural language processing dataset; each transaction is an abstract of a paper from the Journal of Machine Learning Research. iPRG\n1 http://www.gecode.org 2 http://www.cs.rpi.edu/ zaki/www-new/pmwiki.php/Software/ 3 https://code.google.com/p/prefixspan/ 4 https://dtai.cs.kuleuven.be/CP4IM/cpsm 5 https://archive.ics.uci.edu/ml/datasets/\nis a proteomics dataset from the application described in [4]; each transaction is a sequence of peptides that is known to cleave in presence of a Trypsin enzyme. FIFA is click stream dataset6 from logs of the website of the FIFA world cup in 98; each transaction is a sequence of webpages visited by a user during a single session. Detailed characteristics of the datasets are given in Table 1. Remark that the characteristic of these datasets are very diverse due to their different origins.\nIn our experiments, we vary the minimum frequency threshold (minsup). Lower values for minsup result in larger solution sets, thus in larger execution times.\nExperiments: First we compare the global and the decomposed models. The execution times for these models are shown on Fig. 3, both without and with projected frequency (indicated by -p.f.). We first look at the impact of exposing the embedding variables in the decomposed model (Q1). Perhaps unsurprisingly, the global model is up to one order of magnitude faster than the decomposed model, which hasO(n\u2217k) extra variables. This is the overhead required to allow one to add constraints over the inclusion relation. We also study the impact of the projected frequency on both models (Q2). In the global model this is done as part of the search, while in the decomposed model this is achieved with an elaborate constraint formulation. For global-p.f. we always observe a speedup in Fig. 3. Not so for decomposed-p.f. for the two largest (in terms of ||D||) datasets.\nWe now evaluate the impact of user constraints on the number of results and on the execution time (Q3). Fig. 4 shows the number of patterns and the execution times for\n6 http://www.philippe-fournier-viger.com/spmf/\nvarious combinations of constraints. We can see that adding constraints enables users to control the explosion of the number of patterns, and that the execution times decrease accordingly. The constraint propagation allows early pruning of invalid solutions which effectively compensates the computation time of checking the constraints. For example, on the Unix user dataset, it is not feasible to mine for patterns at 5% minimum frequency without constraints, let alone do something with the millions of patterns found. On the other hand, by adding constraints one can look for interesting patterns at low frequency without being overwhelmed by the number of results (see also later).\nThe last experiment compares our models to existing algorithms. Fig. 5 shows the execution times for our global model compared with regular-dfa, PrefixSpan and cSpade (Q4). First, we can observe that regular-dfa is always slowest. On iPRG it performs reasonably well, but the number of transitions in the DFAs does not permit it to perform well on datasets with a large alphabet or large transactions, such as Unix user, JMLR or FIFA. Furthermore, it can not make use of projected frequencies.\nglobal shows similar, but much faster, behaviour than regular-dfa. On datasets with many symbols such as JMLR and FIFA, we can see that not using projected frequency is a serious drawback; indeed, global-p.f. performs much better than global there.\nOf the specialised algorithms, cSpade performs better than PrefixSpan; it is the most advanced algorithm and is the fastest in all experiments (not counting the highest frequency thresholds). global-p.f. has taken inspiration from PrefixSpan and we can see that they indeed behave similarly. Although, for the dense iPRG dataset PrefixSpan performs better than global-p.f. and inversely for the large and sparse FIFA dataset. This might be due to implementation choices in the CP solver and PrefixSpan software.\nAnalysis of the pattern quality Finally, we use our constraint-based framework to perform exploratory analysis of the Unix user datasets. Table 2 shows different settings we\ntried and patterns we found interesting. Few constraints lead to too many patterns while more constrained settings lead to fewer and more interesting patterns."}, {"heading": "7 Related work", "text": "The idea of mining patterns in sequences dates from earlier work by Agrawal et al. [1] shortly after their well-known work on frequent itemset mining [2]. The problem introduced in [1] consisted of finding frequent sequences of itemsets; that is: sequences of sets included in a database of sequences of sets. Mining sequences of individual symbols was introduced later by [9]; the two problems are closely related and one can adapt one to the other [16]. Sequence mining was driven by the application of market basket analysis for customer data spread over multiple days. Other applications include bio-medical ones where a large number of DNA and protein sequence datasets are available (e.g. [18]), or natural language processing where sentences can be represented as sequences of words (e.g. [15]).\nSeveral specialised algorithm have addressed the problem of constrained sequence mining. The cSpade algorithm [19] for example is an extension of the Spade sequence mining algorithm [20] that supports constraints of type 1, 2 and 3. PrefixSpan [6] mentions regular expression constraints too. The LCMseq algorithm [13] also supports a range of constraints, but does not consider all embeddings during search. Other sequence mining algorithms have often focussed on constraints of type 4, and on closed sequence mining in particular. CloSpan [17] and Bide [16] are both extentions of Pre-\nfixSpan to mine closed frequent sequences. We could do the same in our CP approach by adding constraints after each solution found, following [11,8].\nDifferent flavors of sequence mining have been studied in the context of a generic framework, and constraint programming in particular. They all study constraints of type 1, 2 and 4. In [3] the setting of sequence patterns with explicit wildcards in a single sequence is studied: such a pattern has a linear number of embeddings. As only a single sequence is considered, frequency is defined as the number of embeddings in that sequence, leading to a similar encoding to itemsets. This is extended in [7] to sequences of itemsets (with explicit wildcards over a single sequence). [8] also studies patterns with explicit wildcards, but in a database of sequences. Finally, [10] considers standard sequences in a database, just like this paper; they also support constraints of type 3. The main difference is in the use of a costly encoding of the inclusion relation using non-deterministic automata and the inherent inability to use projected frequency."}, {"heading": "8 Conclusion and discussion", "text": "We have investigated a generic framework for sequence mining, based on constraint programming. The difficulty, compared to itemsets and sequences with explicit wildcards, is that the number of embeddings can be huge, while knowing that one embedding exists is sufficient.\nWe proposed two models for the sequence mining problem: one in which the existsembedding relation is captured in a global constraint. The benefit is that the complexity of dealing with the existential check is hidden in the constraint. The downside is that modifying the inclusion relation requires modifying the global constraint; it is hence not generic towards such constraints. We were able to use the same projected frequency technique as well-studied algorithms such as PrefixSpan [6], by altering the global exists-embedding constraint and using a specialised search strategy. Doing this does amount to implementing specific propagators and search strategies into a CP solver, making the problem formulation not applicable to other solvers out-of-the-box. On the other hand, it allows for significant efficiency gains.\nThe second model exposes the actual embedding through variables, allowing for more constraints and making it as generic as can be. However, it has extra overhead and requires a custom two-phased search strategy.\nOur observations are not just limited to sequence mining. Other pattern mining tasks such as tree or graph mining also have multiple (and many) embeddings, hence they will also face the same issues with a reified exists relation. Whether a general framework exists for all such pattern mining problems is an open question."}, {"heading": "Acknowledgments", "text": "The authors would like to thank Siegfried Nijssen, Anton Dries and Re\u0301mi Coletta for discussions on the topic, and the reviewers for their valuable comments. This work was supported by the European Commission under project FP7-284715 \u201cInductive Constraint Programming\u201d and a Postdoc grant by the Research Foundation \u2013 Flanders.\nAppendix"}, {"heading": "A Branching with projected frequency", "text": "We want to branch only over the symbols that are still frequent in the prefix-projected sequences. Taking the current partially assigned sequence into account, after projecting this prefix away from each transaction, some transactions will be empty and others will have only some subset of its original symbols left.\nFor each propagator Ci \u2194 \u2203e s.t. S ve Ti we maintain the (monotonically decreasing) set of symbols for that transaction in a variable Xi. The propagator in Algorithm 1 needs just a one line addition, that is, after line 12 we add the following:\npropagate by removing from Xi all symbols not in \u3008Ti[pose]..Ti[|Ti|]\u3009 except which removes all symbols from Xi that do not appear after the current prefix.\nThe brancher than first computes the local frequency of each symbol across all Xi, and only branches on the frequent ones. Let \u03b8 be the minimum frequency threshold, then the branching algorithm is the following:\nAlgorithm 2 local-frequency-brancher(S,X) 1: posS \u2190 position of first unassigned variable in S 2: for s in S[posS ] do 3: count\u2190 0 4: for all Xi do 5: if s \u2208 D(Xi) then . symbol in domain of Xi 6: count\u2190 count+ 1 7: end for 8: if count >= \u03b8 then 9: add branch-choice \u2019S = s\u2019 10: end for 11: branch over all branch-choices (if any)"}, {"heading": "B Decomposition with explicit embedding variables, modeling details", "text": "The decomposition consists of two constraints: the position-match constraint and the is-embedding constraint.\nposition-match formulation, part 1 The first constraint needed to enforce position-match is formally defined as follows:\n\u2200i \u2208 1, . . . , n, \u2200j \u2208 1, . . . , |Ti| : (Sj = Ti[Eij]) \u2228 (Eij = |Ti|+ 1) (14)\nInstead of modeling this with a reified element constraint, we can decompose the element constraint over all values in Eij except the no-match value |Ti|+ 1:\n\u2200i \u2208 1, . . . , n, \u2200j \u2208 1, . . . , |Ti|,\u2200x \u2208 1 . . . |Ti| : Eij = x\u2192 Sj = Ti[x] (15)\nObserve that in the above formulation Ti[x] is a constant, so the reified Sj = v expressions can be shared for all unique values of v \u2208 \u03a3.\nFurthermore, using half-reified constraints we need only one auxiliary variable for both Eij = x \u2192 B and B \u2192 Sj = s, where the latter can be shared for all unique values of s \u2208 \u03a3. This leads to O(n \u00b7 k \u00b7 k) half-reified constraints of the former type and O(k \u00b7 k) auxiliary variables and half-reified constraints of the latter type, with k = maxi(|Ti|).\nposition-match formulation, part 2 The second constraint needed to enforce position-match is:\n\u2200i \u2208 1, . . . , n, \u2200j \u2208 2, . . . , |Ti| : (Ei(j\u22121) < Eij) \u2228 (Eij = |Ti|+ 1) (16)\nFormulating this in CP would not perform any propagation until |Ti|+1 is removed from the domain of Eij. However, one can see that the lower-bound on Ei(j\u22121), when not equal to |Ti|+ 1, can be propagated to the lower-bound of Eij.\nConsider the following example: let S = [{B,C, }, {A,B,C, }, {A,B,C, }] and T1 = [A,B,C] then k = 3 and D(E1) = {2, 3, 4}, D(E2) = {2, 3, 4}, D(E3) = {2, 3, 4}. However, because min(D(E1)) = 2 we know that E2 6= 2 and similar for E3. This leads to E3 = {4}, from which the is-embedding propagator can derive that there is no embedding of the pattern in T1. This is a quite common situation.\nThis propagation can be obtained with the following decomposition over all elements of the domain (except |Ti|+ 1):\n\u2200i \u2208 1 . . . n,\u2200j \u2208 1 . . . |Ti| \u2212 1,\u2200x \u2208 1 . . . |Ti| : (Eij+1 = x)\u2192 (Eij < x) (17)\nHowever, this would require in the order O(n \u00b7 k2) reified constraints and auxiliary variables.\nInstead, we use a simple modification of the binary inequality propagator X < Y that achieves the same required result. This propagator always propagates the lowerbound of X to Y , and as soon as |Ti| + 1 /\u2208 Y it propagates like a standard X < Y propagator.\nThere are O(n \u00b7 k) such constraints needed and no auxiliary variables.\nis-embedding formulation The constraint is the following:\n\u2200i \u2208 1, . . . , n : Ci \u2194 \u2200j \u2208 1, . . . , |Ti| : (Sj 6= )\u2192 (Eij 6= |Ti|+ 1) (18)\nAcross all transactions, the reified Sj 6= expressions can be shared. O(n \u00b7 k) such constraints and auxiliary variables are needed in total. For each transaction, the forall requires |Ti| times 2 auxiliary variables, one for reifying Eij 6= |Ti| + 1 and one for reifying the implication. This leads to an additional O(n \u00b7 k) auxiliary variables and constraints, plus n reified conjunction constraints."}, {"heading": "C Sub-search for the existence of a valid Ei", "text": "For each transaction i independently, we can search for a valid assignment of the Ei variables. As soon as a valid one is found, the sub search can stop and propagate the corresponding assignment to the Ci and Ei variables of the master problem.\nThe following pseudo-code describes how we implemented this scheme as a brancher in a copying solver (implementation for a trailing solver is similar):\nAlgorithm 3 sub-search-brancher(C,E) 1: substate\u2190 copy of the current search state 2: for all Ci do 3: remove all other branchers (e.g. variable/value orderings) 4: add to substate the variable/value ordering that tries Ci =true before Ci =false 5: add to substate as next variable/value ordering to search over all Eij variables in lexico-\ngraphic order, trying their smallest value first 6: solve substate 7: if substate has a solution then 8: save substate\u2019s assignment of Ci and Ei 9: else\n10: fail the master problem . When no valid Ci,Ei can be found 11: end for 12: merge all saved assignments and have this as the only resulting branch-choice for the master\nproblem\nIn the above algorithm, for each transaction i we enter the loop and remove all branchers, meaning that there are currently no search choices for the subproblem. We then force the sub-search to only search over Ci and Ei, such that an assignment for Ci =true is found first, if it exists. By removing all branchers at the start of loop, the next transaction\u2019s sub-search will not reconsider branching choices made in the previous sub-search.\nAs the master problem should not branch over any of the sub-search choices either, we merge all the assignments found by the sub-searches and present this as the only branch-choice for the master problem.\nUsing this sub-search-brancher, for each Ti for which an embedding of S in Ti exists, Ci will be true. Only if no such embedding exists will Ci be false. This is the required behaviour for our constraint formulation."}, {"heading": "D Projected frequency for explicit embedding variables", "text": "We introduced the following constraint specification:\n\u2200j \u2208 1 . . . n, x \u2208 \u03a3, Sj = x\u2192 |{i : Ci \u2227 Ti[Eij] = x}| \u2265 \u03b8 (19)\nA naive formulation of this expression would require reifying an element constraint B\u2194 Ti[Eij] = x. Instead, we will create element constraints Ti[Eij] = Aij, where Aij\nis an auxiliary integer variable. This leads to the following more efficient reformulation:\n\u2200i \u2208 1 . . . n, j \u2208 1 . . . |Ti|, Ti[Eij] = Aij (20) \u2200i \u2208 1 . . . n, j \u2208 1 . . . |Ti|, x \u2208 \u03a3, Sj = x\u2192 |{i : Ci \u2227Aij = x}| \u2265 \u03b8 (21)"}], "references": [{"title": "Mining sequential patterns", "author": ["R. Agrawal", "R. Srikant"], "venue": "Data Engineering, 1995. Proceedings of the Eleventh International Conference on. pp. 3\u201314. IEEE", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1995}, {"title": "Fast algorithms for mining association rules in large database", "author": ["R. Agrawal", "R Srikant"], "venue": "Proc. 20th Int. Conf. Very Large Data Bases, VLDB. vol. 1215, pp. 487\u2013499", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1994}, {"title": "A sat-based approach for discovering frequent, closed and maximal patterns in a sequence", "author": ["E. Coquery", "S. Jabbour", "L. Sais", "Y. Salhi"], "venue": "European Conference on Artificial Intelligence (ECAI). p. 258\u2013263", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Predicting tryptic cleavage from proteomics data using decision tree ensembles", "author": ["T. Fannes", "E. Vandermarliere", "L. Schietgat", "S. Degroeve", "L. Martens", "J. Ramon"], "venue": "Journal of Proteome Research 12(5),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Itemset mining: A constraint programming perspective", "author": ["T. Guns", "S. Nijssen", "L. De Raedt"], "venue": "Artificial Intelligence 175(12-13), 1951\u20131983", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Prefixspan: mining sequential patterns efficiently by prefix-projected pattern growth", "author": ["J. Han", "J. Pei", "B. Mortazavi-Asl", "H. Pinto", "Q. Chen", "U. Dayal", "M. Hsu"], "venue": "ICDE\u20192001, April pp. 215\u201324", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "Boolean satisfiability for sequence mining", "author": ["S. Jabbour", "L. Sais", "Y. Salhi"], "venue": "22nd International Conference on Information and Knowledge Management(CIKM\u201913). pp. 649\u2013658. ACM Press, San Francisco, CA, USA", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Mining relevant sequence patterns with cp-based framework", "author": ["A. Kemmar", "W. Ugarte", "S. Loudni", "T. Charnois", "Y. Lebbah", "P. Boizumault", "B. Cremilleux"], "venue": "Tools with Artificial Intelligence (ICTAI), 2013 IEEE 25th International Conference on. IEEE", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Discovery of frequent episodes in event sequences", "author": ["H. Mannila", "H. Toivonen", "A. Inkeri Verkamo"], "venue": "Data Mining and Knowledge Discovery 1(3), 259\u2013289", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1997}, {"title": "A constraint programming approach for mining sequential patterns in a sequence database", "author": ["J.P. M\u00e9tivier", "S. Loudni", "T. Charnois"], "venue": "ECML/PKDD 2013 Workshop on Languages for Data Mining and Machine Learning", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Dominance programming for itemset mining", "author": ["B. Negrevergne", "A. Dries", "T. Guns", "S. Nijssen"], "venue": "International Conference on Data Mining (ICDM)", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Correlated itemset mining in ROC space: A constraint programming approach", "author": ["S. Nijssen", "T. Guns", "L. De Raedt"], "venue": "Flach, P., Zaki, M. (eds.) Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Paris, France, 28 June - 1 July 2009. pp. 647\u2013656. ACM Press", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "Efficient serial episode mining with minimal occurrences", "author": ["H. Ohtani", "T. Kida", "T. Uno", "H. Arimura", "H. Arimura"], "venue": "ICUIMC. pp. 457\u2013464", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Mining (soft-) skypatterns using dynamic CSP", "author": ["W.U. Rojas", "P. Boizumault", "S. Loudni", "B. Cr\u00e9milleux", "A. Lepailleur"], "venue": "Integration of AI and OR Techniques in Constraint Programming - 11th International Conference, CPAIOR 2014, Cork, Ireland, May 19-23, 2014. Proceedings. pp. 71\u201387", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "The long and the short of it: summarising event sequences with serial episodes", "author": ["N. Tatti", "J. Vreeken"], "venue": "KDD. pp. 462\u2013470", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Bide: Efficient mining of frequent closed sequences", "author": ["J. Wang", "J. Han"], "venue": "Data Engineering, 2004. Proceedings. 20th International Conference on. pp. 79\u201390. IEEE", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}, {"title": "Clospan: Mining closed sequential patterns in large datasets", "author": ["X. Yan", "J. Han", "R. Afshar"], "venue": "Proceedings of SIAM International Conference on Data Mining. pp. 166\u2013177", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "An efficient, versatile and scalable pattern growth approach to mine frequent patterns in unaligned protein sequences", "author": ["K. Ye", "W.A. Kosters", "A.P. IJzerman"], "venue": "Bioinformatics 23(6), 687\u2013693", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Sequence mining in categorical domains: incorporating constraints", "author": ["M.J. Zaki"], "venue": "Proceedings of the ninth international conference on Information and knowledge management. pp. 422\u2013429. ACM", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2000}, {"title": "Spade: An efficient algorithm for mining frequent sequences", "author": ["M.J. Zaki"], "venue": "Machine Learning 42(1), 31\u201360", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2001}], "referenceMentions": [{"referenceID": 18, "context": "An important step in the development of more general approaches was the cSpade algorithm [19] which supports a variety constraints.", "startOffset": 89, "endOffset": 93}, {"referenceID": 5, "context": "[6,17,16,13]).", "startOffset": 0, "endOffset": 12}, {"referenceID": 16, "context": "[6,17,16,13]).", "startOffset": 0, "endOffset": 12}, {"referenceID": 15, "context": "[6,17,16,13]).", "startOffset": 0, "endOffset": 12}, {"referenceID": 12, "context": "[6,17,16,13]).", "startOffset": 0, "endOffset": 12}, {"referenceID": 4, "context": "For itemset mining, the simplest form of pattern mining, it has been shown that constraint programming (CP) can be used as a generic framework for constraint-based mining [5] and beyond [14,11].", "startOffset": 171, "endOffset": 174}, {"referenceID": 13, "context": "For itemset mining, the simplest form of pattern mining, it has been shown that constraint programming (CP) can be used as a generic framework for constraint-based mining [5] and beyond [14,11].", "startOffset": 186, "endOffset": 193}, {"referenceID": 10, "context": "For itemset mining, the simplest form of pattern mining, it has been shown that constraint programming (CP) can be used as a generic framework for constraint-based mining [5] and beyond [14,11].", "startOffset": 186, "endOffset": 193}, {"referenceID": 2, "context": "Recent works have also investigated the usage of CP-based approaches for mining sequences with explicit wildcards [3,7,8].", "startOffset": 114, "endOffset": 121}, {"referenceID": 6, "context": "Recent works have also investigated the usage of CP-based approaches for mining sequences with explicit wildcards [3,7,8].", "startOffset": 114, "endOffset": 121}, {"referenceID": 7, "context": "Recent works have also investigated the usage of CP-based approaches for mining sequences with explicit wildcards [3,7,8].", "startOffset": 114, "endOffset": 121}, {"referenceID": 7, "context": "But in case only few embeddings are possible, as in sequences with explicit wildcards, this can be done with a disjunctive constraint over all possible embeddings [8].", "startOffset": 163, "endOffset": 166}, {"referenceID": 5, "context": "\u2013 We introduce an exists-embedding global constraint for sequences, and show the relation to projected databases and projected frequency used in the sequence mining literature to speedup the mining process [6,20].", "startOffset": 206, "endOffset": 212}, {"referenceID": 19, "context": "\u2013 We introduce an exists-embedding global constraint for sequences, and show the relation to projected databases and projected frequency used in the sequence mining literature to speedup the mining process [6,20].", "startOffset": 206, "endOffset": 212}, {"referenceID": 0, "context": "Sequence mining [1] can be seen as a variation of the well-known itemset mining problem proposed in [2].", "startOffset": 16, "endOffset": 19}, {"referenceID": 1, "context": "Sequence mining [1] can be seen as a variation of the well-known itemset mining problem proposed in [2].", "startOffset": 100, "endOffset": 103}, {"referenceID": 5, "context": "Regular expression constraints: Let R be a regular expression over the vocabulary V and LR be the language of sequences recognised by R, then for any sequence pattern S over V , the match-regular constraint requires that S \u2208 LR [6].", "startOffset": 228, "endOffset": 231}, {"referenceID": 11, "context": "Other examples include more statistical measures such as information gain and entropy [12].", "startOffset": 86, "endOffset": 90}, {"referenceID": 18, "context": "The max-gap and max-span constraints [19] impose a restriction on the embedding, and hence on the inclusion relation.", "startOffset": 37, "endOffset": 41}, {"referenceID": 10, "context": "In [11] it was shown that condensed representations like closed, maximal and free patterns can be expressed as pairwise preference relations.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "Skypatterns [14] and multi-objective optimisation can also be seen as preference over patterns.", "startOffset": 12, "endOffset": 16}, {"referenceID": 7, "context": "Hence, one can not model this as a disjunctive constraint over all possible embeddings (as is done for sequences with explicit wildcards [8]).", "startOffset": 137, "endOffset": 140}, {"referenceID": 5, "context": "If one would project the prefix away, only the symbols in the transaction from pose on would remain; this is known as prefix projection [6].", "startOffset": 136, "endOffset": 139}, {"referenceID": 5, "context": "This is known to speed up specialised mining algorithms considerably [6,16].", "startOffset": 69, "endOffset": 75}, {"referenceID": 15, "context": "This is known to speed up specialised mining algorithms considerably [6,16].", "startOffset": 69, "endOffset": 75}, {"referenceID": 10, "context": "preference relations have been proposed in [11] to formalise well-known pattern mining settings such as maximal or closed patterns.", "startOffset": 43, "endOffset": 47}, {"referenceID": 10, "context": "Such preference relations can be enforced dynamically during search for any CP formulation [11].", "startOffset": 91, "endOffset": 95}, {"referenceID": 18, "context": "We compare our global and decomposed models (Section 4 and Section 5) to the state-of-the-art algorithms cSpade[19] and PrefixSpan [6].", "startOffset": 111, "endOffset": 115}, {"referenceID": 5, "context": "We compare our global and decomposed models (Section 4 and Section 5) to the state-of-the-art algorithms cSpade[19] and PrefixSpan [6].", "startOffset": 131, "endOffset": 134}, {"referenceID": 9, "context": "We also compare our models to the CP-based approach proposed by [10].", "startOffset": 64, "endOffset": 68}, {"referenceID": 3, "context": "is a proteomics dataset from the application described in [4]; each transaction is a sequence of peptides that is known to cleave in presence of a Trypsin enzyme.", "startOffset": 58, "endOffset": 61}, {"referenceID": 0, "context": "[1] shortly after their well-known work on frequent itemset mining [2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[1] shortly after their well-known work on frequent itemset mining [2].", "startOffset": 67, "endOffset": 70}, {"referenceID": 0, "context": "The problem introduced in [1] consisted of finding frequent sequences of itemsets; that is: sequences of sets included in a database of sequences of sets.", "startOffset": 26, "endOffset": 29}, {"referenceID": 8, "context": "Mining sequences of individual symbols was introduced later by [9]; the two problems are closely related and one can adapt one to the other [16].", "startOffset": 63, "endOffset": 66}, {"referenceID": 15, "context": "Mining sequences of individual symbols was introduced later by [9]; the two problems are closely related and one can adapt one to the other [16].", "startOffset": 140, "endOffset": 144}, {"referenceID": 17, "context": "[18]), or natural language processing where sentences can be represented as sequences of words (e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "The cSpade algorithm [19] for example is an extension of the Spade sequence mining algorithm [20] that supports constraints of type 1, 2 and 3.", "startOffset": 21, "endOffset": 25}, {"referenceID": 19, "context": "The cSpade algorithm [19] for example is an extension of the Spade sequence mining algorithm [20] that supports constraints of type 1, 2 and 3.", "startOffset": 93, "endOffset": 97}, {"referenceID": 5, "context": "PrefixSpan [6] mentions regular expression constraints too.", "startOffset": 11, "endOffset": 14}, {"referenceID": 12, "context": "The LCMseq algorithm [13] also supports a range of constraints, but does not consider all embeddings during search.", "startOffset": 21, "endOffset": 25}, {"referenceID": 16, "context": "CloSpan [17] and Bide [16] are both extentions of Pre-", "startOffset": 8, "endOffset": 12}, {"referenceID": 15, "context": "CloSpan [17] and Bide [16] are both extentions of Pre-", "startOffset": 22, "endOffset": 26}, {"referenceID": 10, "context": "We could do the same in our CP approach by adding constraints after each solution found, following [11,8].", "startOffset": 99, "endOffset": 105}, {"referenceID": 7, "context": "We could do the same in our CP approach by adding constraints after each solution found, following [11,8].", "startOffset": 99, "endOffset": 105}, {"referenceID": 2, "context": "In [3] the setting of sequence patterns with explicit wildcards in a single sequence is studied: such a pattern has a linear number of embeddings.", "startOffset": 3, "endOffset": 6}, {"referenceID": 6, "context": "This is extended in [7] to sequences of itemsets (with explicit wildcards over a single sequence).", "startOffset": 20, "endOffset": 23}, {"referenceID": 7, "context": "[8] also studies patterns with explicit wildcards, but in a database of sequences.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "Finally, [10] considers standard sequences in a database, just like this paper; they also support constraints of type 3.", "startOffset": 9, "endOffset": 13}, {"referenceID": 5, "context": "We were able to use the same projected frequency technique as well-studied algorithms such as PrefixSpan [6], by altering the global exists-embedding constraint and using a specialised search strategy.", "startOffset": 105, "endOffset": 108}], "year": 2015, "abstractText": "The goal of constraint-based sequence mining is to find sequences of symbols that are included in a large number of input sequences and that satisfy some constraints specified by the user. Many constraints have been proposed in the literature, but a general framework is still missing. We investigate the use of constraint programming as general framework for this task. We first identify four categories of constraints that are applicable to sequence mining. We then propose two constraint programming formulations. The first formulation introduces a new global constraint called exists-embedding. This formulation is the most efficient but does not support one type of constraint. To support such constraints, we develop a second formulation that is more general but incurs more overhead. Both formulations can use the projected database technique used in specialised algorithms. Experiments demonstrate the flexibility towards constraint-based settings and compare the approach to existing methods.", "creator": "LaTeX with hyperref package"}}}