{"id": "1501.07399", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jan-2015", "title": "Particle swarm optimization for time series motif discovery", "abstract": "Efficiently finding similar segments or motifs in time series data is a fundamental task that exists in a variety of areas and situations due to the ubiquity of this data. Therefore, countless solutions have been designed, but to date none of them seem to be completely satisfactory and flexible. In this article, we propose an innovative standpoint and present a solution that results from it: a multimodal optimization algorithm for finding motifs in time series based on particle swarms at all times. By considering data from a variety of areas, we show that this solution is highly competitive compared to the state of the art and obtains comparable motifs in a much shorter time and with minimal memory requirements. Furthermore, we show that it is robust against various implementation options and see that it offers an unprecedented degree of flexibility in the task. All these qualities make the presented solution one of the most prominent candidates for finding motifs in long time series streams. Furthermore, we believe that potential research tasks can be used to expand the scope and scope of the proposed solution.", "histories": [["v1", "Thu, 29 Jan 2015 10:18:46 GMT  (287kb,D)", "http://arxiv.org/abs/1501.07399v1", "12 pages, 9 figures, 2 tables"]], "COMMENTS": "12 pages, 9 figures, 2 tables", "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["joan serr\\`a", "josep lluis arcos"], "accepted": false, "id": "1501.07399"}, "pdf": {"name": "1501.07399.pdf", "metadata": {"source": "CRF", "title": "Particle Swarm Optimization for Time Series Motif Discovery", "authors": ["Joan Serr\u00e0", "Josep Lluis Arcos"], "emails": ["jserra@iiia.csic.es.", "arcos@iiia.csic.es."], "sections": [{"heading": null, "text": "1 Particle Swarm Optimization for Time Series Motif Discovery Joan Serra\u0300 and Josep Lluis Arcos\nAbstract\u2014Efficiently finding similar segments or motifs in time series data is a fundamental task that, due to the ubiquity of these data, is present in a wide range of domains and situations. Because of this, countless solutions have been devised but, to date, none of them seems to be fully satisfactory and flexible. In this article, we propose an innovative standpoint and present a solution coming from it: an anytime multimodal optimization algorithm for time series motif discovery based on particle swarms. By considering data from a variety of domains, we show that this solution is extremely competitive when compared to the state-of-the-art, obtaining comparable motifs in considerably less time using minimal memory. In addition, we show that it is robust to different implementation choices and see that it offers an unprecedented degree of flexibility with regard to the task. All these qualities make the presented solution stand out as one of the most prominent candidates for motif discovery in long time series streams. Besides, we believe the proposed standpoint can be exploited in further time series analysis and mining tasks, widening the scope of research and potentially yielding novel effective solutions.\nIndex Terms\u2014Particle swarm, multimodal optimization, time series streams, motifs, anytime.\nI. INTRODUCTION\nT IME SERIES are sequences of real numbers measuredat successive, usually regular time intervals. Data in the form of time series pervade science, business, and society. Examples range from economics to medicine, from biology to physics, and from social to computer sciences. Repetitions or recurrences of similar phenomena are a fundamental characteristic of non-random natural and artificial systems and, as a measurement of the activity of such systems, time series often include pairs of segments of strikingly high similarity. These segment pairs are commonly called motifs [1], and their existence is unlikely to be due to chance alone. In fact, they usually carry important information about the underlying system. Thus, motif discovery is fundamental for understanding, characterizing, modeling, and predicting the system behind the time series [2]. Besides, motif discovery is a core part of several higher-level algorithms dealing with time series, in particular classification, clustering, summarization, compression, and rule-discovery algorithms (see, e.g., references in [2], [3]).\nIdentifying similar segment pairs or motifs implies examining all pairwise comparisons between all possible segments in a time series. This, specially when dealing with long time series streams, results in prohibitive time and space complexities. It is for this reason that the majority of motif\nJ. Serra\u0300 and J. Ll. Arcos are with IIIA-CSIC, the Artificial Intelligence Research Institute of the Spanish National Research Council, Campus de la UAB s/n, 08193 Bellaterra, Barcelona, Spain, email: {jserra,arcos}@iiia.csic.es.\ndiscovery algorithms resort to some kind of data discretization or approximation that allows them to hash and retrieve segments efficiently. Following the works by Lin et al. [1] and Chiu et al. [4], many of such approaches employ the SAX representation [5] and/or a sparse collision matrix [6]. These allow them to achieve a theoretically low computational complexity, but sometimes at the expense of very high constant factors. In addition, approximate algorithms usually suffer from a number of data-dependent parameters that, in most situations, are not intuitive to set (e.g., time/amplitude resolutions, dissimilarity radius, segment length, minimum segment frequency, etc.).\nA few recent approaches overcome some of these limitations. For instance, Castro & Azevedo [7] propose an amplitude multi-resolution approach to detect frequent segments, Li & Lin [8] use a grammar inference algorithm for exploring motifs with lengths above a certain threshold, Wilson et al. [9] use concepts from immune memory to deal with different lengths, and Floratou et al. [10] combine suffix trees with segment models to find motifs of any length. Nevertheless, in general, these approaches still suffer from other data-dependent parameters whose correct tuning can require considerable time. In addition, approximate algorithms are restricted to a specific dissimilarity measure between segments (the one implicit in their discretization step) and do not allow easy access to preliminary results, which is commonly known as anytime algorithms [11]. Finally, to the best of our knowledge, only [12]\u2013[14] consider the identification of motif pairs containing segments of different lengths. This can be considered a relevant feature, as it produces better results in a number of different domains [13].\nIn contrast to approximate approaches, algorithms that do not discretize the data have been comparatively much less popular, with low efficiency generally. Exceptions to this statement achieved efficiency by sampling the data stream [15] or by identifying extreme points that constrained the search [16]. In fact, until the work of Mueen et al. [17], the exact identification of time series motifs was thought to be intractable for even time series of moderate length. In said work, a clever segment ordering was combined with a lower bound based on the triangular inequality to yield the true, exact, most similar motif. According to the authors, the proposed algorithm was more efficient than existing approaches, including all exact and many approximate ones [17]. After Mueen et al.\u2019s work, a number of improvements have been proposed, the majority focusing on eliminating the need to set a fixed segment length [18]\u2013[20].\nMueen himself has recently published a variable-length motif discovery algorithm which clearly outperforms the it-\nar X\niv :1\n50 1.\n07 39\n9v 1\n[ cs\n.L G\n] 2\n9 Ja\nn 20\n15\n2 erative search for the optimal length using [17] and, from the reported numbers, also outperforms further approaches such as [18]\u2013[20]. This algorithm, called MOEN [3], is essentially parameter-free, and is believed to be one of the most efficient motif discovery algorithms available nowadays. However, its complexity is still quadratic in the length of the time series [3], and hence its applicability to large-scale time series streams remains problematic. Furthermore, in order to derive the lower bounds used, the algorithm is restricted with regard to the\ndissimilarity measure used to compare time series segments (Euclidean distance after z-normalization). In general, exact motif discovery algorithms have important restrictions with regard to the dissimilarity measure, and many of them still suffer from being non-intuitive and tedious to tune parameters. Moreover, few of them allow for anytime versions and, to the best of our knowledge, not one of them is able to identify motif pairs containing segments of different lengths.\nIn this article, we propose a new standpoint to time series motif discovery by treating the problem as an anytime multimodal optimization task. To the best of our knowledge, this standpoint is completely unseen in the literature. Here, we firstly reason and discuss its multiple advantages (Sec. II). Next, we present SWARMMOTIF (Sec. III), an anytime algorithm for time series motif discovery based on particle swarm optimization (PSO). We subsequently evaluate the performance of the proposed approach using 9 different real-world time series from distinct domains (Sec. IV). Our results show that SWARMMOTIF is extremely competitive when compared to the state-of-the-art, obtaining motif pairs of comparable similarity in considerably less time and with minimum storage requirements (Sec. V). Moreover, we show that SWARMMOTIF is significantly robust against different implementation choices. To conclude, we briefly comment on the application of multimodal optimization techniques to time series analysis and mining, which we believe has great potential (Sec. VI). The data and code used in our experiments will available online."}, {"heading": "II. TIME SERIES MOTIF DISCOVERY AS AN ANYTIME MULTIMODAL OPTIMIZATION TASK", "text": ""}, {"heading": "A. Definitions and Task Complexity", "text": "From the work by Mueen et al. [3], [17], we can derive a formal, generic similarity-based definition [2] of time series motifs. Given a time series z of length n, z = [z1, . . . zn], a normalized segment dissimilarity measure D, and a temporal window of interest between wmin and wmax samples, the topk time series motifs M = {m1, . . .mk} correspond to the k most similar segment pairs zwaa = [za, . . . za+wa\u22121] and z wb b = [zb, . . . zb+wb\u22121], for wa, wb \u2208 [wmin, wmax], a \u2208 [1, n\u2212wa+1], and b \u2208 [1, n \u2212 wb + 1] where, in order to avoid repeated and trivial matches [1], a + wa < b. Thus, the i-th motif can be fully described by the tuple mi = {a,wa, b, wb}. The motifs in M are non-overlapping1 and ordered from lowest to highest dissimilarity such that D(m1) \u2264 D(m2) \u2264 \u00b7 \u00b7 \u00b7 \u2264 D(mk) where D(mi) = D({a,wa, b, wb}) = D(zwaa , z wb b ).\n1Notice that, following [3], this definition can be trivially extended to different degrees of overlap.\n0 100 200 300 400 500 600 700 800 900\n\u221221\n\u221219\n\u221217\n\u221215\ni [samples]\nM FC\nC 1\nFig. 1. Example of a time series motif pair found in the WILDLIFE time series of [21] using SWARMMOTIF and normalized dynamic time warping as the dissimilarity measure: a = 248, wa = 244, b = 720, and wb = 235. Note that wa 6= wb and, hence, a warping of the two segments needs to take place. This specific solution cannot be found by any of the approaches mentioned in Sec. I.\nAn example of a time series motif pair from a real data set is shown in Fig. 1.\nIt is important to stress that D needs to normalize with respect to the lengths of the considered segments. Otherwise, we would not be able to compare motifs of different lengths. There are many ways to normalize with respect to the length of the considered segments. Ratanamahatana & Keogh [22] list a number of intuitive normalization mechanisms for dynamic time warping that can easily be applied to other measures. For instance, in the case of a dissimilarity measure based on the Lp norm [23], we can directly divide by the segment length2, using brute-force upsampling to the largest length [22] when wa 6= wb.\nFrom the definitions above, we can see that a brute-force search in the motif space for the most similar motifs is of O(n2w\u2206\n2), where w\u2206 = wmax \u2212 wmin + 1 (for the final time complexity one needs to further multiply by the cost of calculating D). Hence, for instance, in a perfectly feasible case where n = 107 and w\u2206 = 103, we have 1020 possibilities. Magnitudes like this challenge the memory and speed of any optimization algorithm, specially if we have no clue to guide the search [24]. However, it is one of our main objectives to show here that time series generally provide some continuity to this search space, and that this continuity can be exploited by optimization algorithms."}, {"heading": "B. Continuity", "text": "A fundamental property of time series is autocorrelation, implying that consecutive samples in a time series have some degree of resemblance and that, most of the time, we do not observe extremal differences between them3. This property, together with the established ways of computing similarity between time series [23], is what gives continuity to our search space. Consider a typical dissimilarity measure like dynamic time warping between z-normalized segments and the time series of Fig. 1. If we fix the motif starting points a and b to some random values, we can compute D(zia, z j b) for i, j = wmin, . . . , wmax (Fig. 2A). We see that these two dimensions\n2The only exception is with L\u221e, which could be considered as already being normalized.\n3If a time series had no autocorrelation, we might better treat it as an independent random process.\n3 i [samples] j [ sa m pl es ] 200 210 220 230 240 250 200 210 220 230 240 250 A i [samples] j [ sa m pl es ] 100 200 300 400 500 100 200 300 400 500 B\nFig. 2. Visualizations of the search space obtained with the WILDLIFE time series [21] and dynamic time warping as the dissimilarity measure: (A) fixing a = 110 and b = 602 but i, j = 200, . . . 250 and (B) fixing wa = 222 and wb = 240 but i, j = 1, . . . 500. Darker colors corresponds to more similarity.\nhave a clear continuity, i.e., that D(zia, z j b) \u223c D(zi+1a , z j b) \u223c D(zia, z j+1 b ) \u223c D(zi+1a , z j+1 b ), and so forth. Similarly, if we fix the motif lengths wa and wb to some random values, we can compute D(zwai , z wb j ) for i = 1, . . . n\u2212wa and j = 1, . . . n\u2212 wb (Fig. 2B). We see that the remaining two dimensions of the problem also have some continuity, i.e., D(zwai , z wb+j j ) \u223c D(zwai+1, z wb j ) \u223c D(z wa i , z wb j+1) \u223c D(z wa i+1, z wb j+1), and so forth. The result is a four-dimensional, multimodal, continuous but noisy4 motif space, where the dissimilarity D acts as the fitness measure and the top-k valley peaks (considering dissimilarity) correspond to the top-k motifs in M."}, {"heading": "C. Anytime Solutions", "text": "Finding an optimization algorithm that can locate the global minima of the previous search spaces faster than existing motif discovery algorithms can be a difficult task. However, we have robust and established algorithms for efficiently locating prominent local minima in complex search spaces [25]\u2013[27]. Hence, we can intuitively devise a simple strategy: if we keep the best found minima and randomly reinitialize the optimization algorithm every time it stagnates, we should, sooner or later, start locating the global minima. In the meantime, we could have obtained relatively good candidates. This corresponds to the basic paradigm of anytime algorithms [11].\nAnytime algorithms have recently been highlighted as \u201cvery beneficial for motif discovery in massive [time series] datasets\u201d [19]. In an anytime algorithm for motif discovery, D(mi) improves over time, until it reaches the top-k dissimilarity values D(mi)\u2217 obtained by a brute-force search approach. Thus, we gradually improve M until we reach the true exact solution M\u2217. A good anytime algorithm will quickly find low D(mi), ideally reaching D(mi)\u2217 earlier than its non-anytime competitors (Fig. 3).\nNote that a sufficiently good M may suffice in most situations, without the need thatM =M\u2217. This is particularly true for more exploratory tasks, where one is typically interested in data understanding and visual inspection (see [2]), and can also hold for other tasks, as top-k motifs can be very similar among themselves. In the latter situation, given a seed within\n4We use the term noisy here to stress that the continuity of the space may be altered at some points due to potential noise in the time series. It is not the case that we have a noisy, unreliable dissimilarity measurement D that could change in successive evaluations.\n10 \u22121\n10 0\n10 1\n10 2\n10 3\n10 4\n0.0082\n0.0142\n0.0247\n0.0430\n0.0749\n0.1304\nt [s]\nD (m\ni)\nRandom sampling Baseline reference Anytime algorithm\nFig. 3. Schema of a plot to assess the performance of an anytime motif discovery algorithm (blue curve). Error bars indicate 5 and 95 percentiles of D(mi), their central marker indicates the median, and the isolated dots indicate maximum and minimum values. The gray area at the bottom denotes the area where D(mi)\u2217 lie. The top-left black error bar acts as a reference and shows the range of D(mi) obtained by random sampling the motif space. The bottom-right red error bar is placed at the time that the baseline algorithm spent in the calculations. Better performing anytime algorithms have a curve closer to the bottom left corner, quickly entering the gray area as their execution time increases. Notice that both axes are logarithmic.\nM\u2217, we can easily and efficiently retrieve further repetitions via common established approaches [28], [29]. Thus, only non-frequent or singular motifs may be missed. These can be valuable too, as the fact that they are non-frequent does not imply that they cannot carry important information (think for example of extreme events of interest that perhaps only happen twice in a measurement). For those singular motifs, we can wait longer if using an anytime algorithm, or we can resort to the state-of-the-art if that is able to provide its output within an affordable time limit."}, {"heading": "D. Particle Swarm Optimization", "text": "The continuity and anytime observations above (Secs. II-B and II-C) relax the requirements for the optimization algorithm to be employed in the considered motif spaces. In fact, if we do not have to assess the global optimality of a solution, we have a number of approaches that can deal with large, multimodal, continuous but noisy search spaces [25]\u2013[27]. Among them, we choose PSO [30]\u2013[34]. PSO is a populationbased stochastic approach for solving continuous and discrete optimization problems [33] which has been applied to multimodal problems [35]. It is a metaheuristic [27], meaning that it cannot guarantee whether the found solution corresponds to a global optimum. The original PSO algorithm cannot even guarantee the convergence to a local optimum, but adapted versions of it have been proven to solve this issue [36]. Other versions guarantee the convergence to the global optimum, but only with the number of iterations approaching infinity [36].\nPSO has gained increasing popularity among researchers and practitioners as a robust and efficient technique for solving\n4 difficult optimization problems. It makes few or no assumptions about the problem being optimized, does not require it to be differentiable, can search very large spaces of candidate solutions, and can be applied to problems that are irregular, incomplete, noisy, dynamic, etc. (see [30]\u2013[35] and references therein). PSO iteratively tries to improve a candidate solution with regard to a given measure of quality or fitness function. Hence, furthermore, it can be considered an anytime algorithm."}, {"heading": "E. Advantages of an Optimization-Based Solution Using Particle Swarms", "text": "Notice that treating time series motif discovery as an optimization problem naturally yields several advantages: 1) We do not require much memory, as we can basically store\nonly the stream time series and preprocess the required segments at every fitness evaluation. 2) We are able to achieve a certain efficiency, as optimization algorithms do not usually explore the full solution space and perform few fitness evaluations [24]. 3) We can employ any dissimilarity measure D as our fitness function. Its only requirements are segment length independence and a minimal search space continuity. Intuitively, this holds for the high majority of time series dissimilarity measures that are currently used (Secs. II-A and II-B). Additionally, we can straightforwardly incorporate notions of \u2018interestingness\u2019, hubness, or complexity (see references in [23]). This flexibility is very uncommon in current time series motif discovery algorithms (Sec. I). 4) We do not need to force the two segments of the motif to be of the same length. The dissimilarity function D can expressly handle segments of different lengths or we can simply upsample to the largest length (see [22]). Although considering different segment lengths has been highlighted as an objectively better approach, practically none of the current time series motif discovery algorithms contemplates this option (Sec. I). 5) Since we search for the optimal wa and wb, together with a and b, we do not need to set the exact segment lengths as a parameter. Instead, we can use a more intuitive and easier to set range of lengths wa, wb \u2208 [wmin, wmax]. 6) We can easily modify our fitness criterion to work with different task settings. Thus, just by replacing D, we are able to work with multi-dimensional time series [37], detect sub-dimensional motifs [38], perform a constrained motif discovery task [16], etc. 7) We can incorporate notions of motif frequency to our fitness function and hence expand our similarity-based definition of motif to incorporate both notions [2]. For instance, instead of optimizing for individual motifs mi, we can optimize sets of motifs M\u2032i of size ri such that 1 ri \u2211 mj\u2208M\u2032i\nD(mj) is minimal. We can choose ri to be a minimum frequency of motif appearance or we can even decide to optimize it following any suitable criterion.\nIn addition, using PSO has a number of interesting properties, some of which may be shared with other metaheurisics: 1) We have a straightforward mapping to the problem at hand\n(Sec. III-A).\n2) By construction, we have an anytime algorithm (Sec. II-D). 3) We can obtain accurate and much faster solutions, as com-\npared to the state-of-the-art in time series motif discovery (Sec. V-C). 4) We have an essentially parameter-free algorithm [33]. As will be shown, all our parameter choices turn out to be non-critical to achieve the most competitive performances (Secs. V-A and V-B). 5) We have an easily parallelizable algorithm. The agentbased nature of PSO naturally yields to parallel implementations [32]. 6) We still have the possibility to apply lower bounding techniques to D in order to reduce its computational cost [2], [29]. Among others, we may exploit the particles\u2019 best-sofar values or spatially close dissimilarities. 7) All of these use a simple, easy to implement algorithm requiring low storage capabilities (Sec. III-B)."}, {"heading": "III. SWARMMOTIF", "text": ""}, {"heading": "A. Main Algorithm", "text": "Our PSO approach to time series motif discovery is based on the combination of two well-known extensions to the canonical PSO [31]. On one hand, we employ multiple reinitializations of the swarm on stagnation [39]. On the other hand, we exploit the particles\u2019 \u201clocal memories\u201d with the intention of forming stable niches across different local minima [40]. The former emulates a parallel multi-swarm approach [35] without the need of having to define the number of swarms and their communication. The latter, when combined with the former, results in a low-complexity niching strategy [35] that does not require niching parameters (see the related discussion in [41], [42]). SWARMMOTIF, the implementation of the two extensions, is detailed in Algorithm 1.\nSWARMMOTIF takes a time series z of length n as input, together with a segment dissimilarity measure D, and the range of segment lengths of interest, limited by wmin and wmax. The user also needs to specify k, the desired number of motifs, and tmax, the maximum time spent by the algorithm (in iterations5). SWARMMOTIF outputs a set of k nonoverlapping motifsM. We implementM as a priority queue, which typically stores more than k elements to ensure that it contains k non-overlapping motifs. This way, by sorting the motif candidates as soon as they are found, we allow potential queries toM at any time during the algorithm\u2019s execution. In that case, we only need to dynamically check the candidates\u2019 overlap (Sec. III-B). Notice that n, D, wmin, wmax, k, and tmax are not parameters of the algorithm, but requirements of the task (they depend on the data, the problem, and the available time). The only parameters to be set, as specified in Algorithm 1\u2019s requirements, are the number of particles \u03ba, the topology \u03b8, the constriction constant \u03c6, and the maximum amount of iterations at stagnation \u03c4 . Nevertheless, we will show that practically none of the possible parameter choices\n5The number of iterations is easy to infer from the available time as, for the same input, the elapsed time will be roughly directly proportional to the number of iterations.\n5 Algorithm 1 SWARMMOTIF(z,D,wmin,wmax,k,tmax) Input: Time series z of length n, dissimilarity measure D,\nminimum and maximum segment length wmin and wmax, number of motifs k, and maximum amount of time (number of iterations) tmax. Require: Number of particles \u03ba, topology \u03b8, constriction constant \u03c6, and maximum amount of time at stagnation (number of iterations) \u03c4 . Output: A set of motifs M. 1: c0, c1, c2 \u2190 GETCONSTANTS(\u03c6) 2: X ,V,S,P \u2190 INITIALIZESWARM(n,wmin,wmax,\u03ba) 3: \u0398\u2190 INITIALIZETOPOLOGY(\u03b8,\u03ba) 4: s\u2217 \u2190\u221e 5: M\u2190 EMPTYPRIORITYQUEUE() 6: for t = 1, . . . tmax 7: for i = 1, . . . \u03ba 8: if VALIDPOSITION(xi) 9: d\u2190 D(xi) 10: if d < si 11: si \u2190 d 12: pi \u2190 xi 13: M.PUSH(d,xi) 14: if d < s\u2217 15: s\u2217 \u2190 d 16: tupdate \u2190 t 17: for i = 1, . . . \u03ba 18: g \u2190 i 19: for j in \u0398i 20: if sj \u2264 sg 21: g \u2190 j 22: vi \u2190 c0vi + c1u1 \u2297 (pi \u2212 xi) + c2u2 \u2297 (pg \u2212 xi) 23: xi \u2190 xi + vi 24: if t\u2212 tupdate = \u03c4 25: X ,V,S,P \u2190 INITIALIZESWARM(n,wmin,wmax,\u03ba) 26: s\u2217 \u2190\u221e 27: return NONOVERLAPPING(M,k)\nintroduces a significant variation in the reported performance (Sec. V-A).\nHaving clarified SWARMMOTIF\u2019s input, output, and requirements, we now elaborate on its procedures. Algorithm 1 starts by computing the velocity update constants (line 1) following Clerc\u2019s constriction method [43], i.e.,\nc0 = 2\u2223\u2223\u22232\u2212 \u03c6\u2212\u221a\u03c62 \u2212 4\u03c6\u2223\u2223\u2223\nand c1 = c2 = c0\u03c6/2. (1)\nNext, a swarm with \u03ba particles is initialized (line 2). The swarm is formed by four data structures: a set of particle positions X = {x1, . . . x\u03ba}, a set of particle velocities V = {v1, . . . v\u03ba}, a set of particle best scores S = {s1, . . . s\u03ba}, and a set of particle best positions P = {p1, . . .p\u03ba} (the initialization of these four data structures is detailed in Algorithm 2). Particles\u2019 positions xi and pi completely determine\nAlgorithm 2 INITIALIZESWARM(n,wmin,wmax,\u03ba) Input: Time series length n, minimum and maximum seg-\nment length wmin and wmax, and number of particles \u03ba. Output: Particle positions X , velocities V , best scores S, and\nbest positions P . 1: for i = 1, . . . \u03ba 2: xi,2 \u2190 wmin + (wmax + 1\u2212 wmin)u 3: xi,4 \u2190 wmin + (wmax + 1\u2212 wmin)u 4: xi,1 \u2190 1 + (n\u2212 xi,2)(1\u2212 \u221a u) 5: xi,3 \u2190 1 + (n\u2212 xi,4 \u2212 (xi,1 + xi,2))u 6: x\u2032 \u2190 As in lines 2\u20135 7: vi \u2190 x\u2032 \u2212 xi 8: si \u2190\u221e 9: pi \u2190 xi\n10: return X ,V,S,P\na motif candidate, and have a direct correspondence with mi (see Sec. III-B). A further data structure \u0398 indicates the indices of the neighbors of each particle according to a given social topology \u03b8 (line 3). Apart from the swarm, we also initialize a global best score s\u2217 (line 4) and the priority queueM (line 5). We then enter the main loop (lines 6\u201326). In it, we perform three main actions. Firstly, we compute the particles\u2019 fitness and perform the necessary updates (lines 7\u201316). Secondly, we modify the particles\u2019 position and velocity using their personal and neighborhood best positions (lines 17\u201323). Thirdly, we control for stagnation and reinitialize the swarm if needed (lines 24\u201326). Finally, when we exit the loop, we return the first k non-overlapping motif candidates from M (line 27).\nThe particles\u2019 fitness loop (lines 7\u201316) can be described as follows. For the particles that have a valid position within the ranges used for particle initializations (line 8; see also Algorithm 2 for initializations), we calculate their fitness D (line 9) and, if needed, update their personal bests si and pi (lines 10\u201312). As mentioned, D needs to be independent of the segments\u2019 lengths, which is typically an easy condition for time series dissimilarity measures (Sec. II-A). In the case that the particles find a new personal best, we save the motif dissimilarity d and its position xi into M (line 13). Next, we update tupdate, the last iteration when an improvement of the global best score s\u2217 has occurred (lines 14\u201316).\nThe particles\u2019 update loop (lines 17\u201323) is straightforward. We first select each particle\u2019s best neighbor g using the neighborhood personal best scores sj (lines 18\u201321). Then, we use the positions of the best neighbor\u2019s personal best pg and the particle\u2019s personal best pi to compute its new velocity and position (lines 22\u201323). We employ componentwise multiplication, denoted by \u2297, and two random vectors u1 and u2 whose individual components ui,j = U(0, 1), being U(l, h) a uniform real random number generator such that l \u2264 U(l, h) < h. Note that by considering the particles\u2019 neighborhood personal bests pg we follow the aforementioned local neighborhood niching strategy [40]. At the end of the loop we control for stagnation by counting the number of iterations since the last global best update and applying a threshold \u03c4 (line 24). Note that this is the mechanism responsible for the\n6 aforementioned multiple reinitialization strategy [39]. The initialization of the swarm used in Algorithm 1 (lines 2 and 25) is further detailed in Algorithm 2. In it, for each particle, two random positions xi and x\u2032 are drawn (lines 2\u20136) and the initial velocity is computed as the subtraction of the two (line 7). To obtain xi and x\u2032, uniform real random numbers u = U(0, 1) are subsequently generated. The personal best score si is set to infinite (line 8) and xi is taken as the current best position pi (line 9). Note that \u221a u (line 4) is used to ensure a uniform distribution of the particles across the triangular subspace formed by xi,1 and xi,3 (line 5; see also Sec. II-A).\nB. Implementation Details\nSome implementation details are missing in Algorithms 1 and 2. Firstly, positions xi are floored component-wise inside VALIDPOSITION, D, and M (thus obtaining motif mi). Secondly, the motif priority queue M is implemented as an associative container (logarithmic insertion time) that sorts its elements according to d and stores mi. Thirdly, the last visited positions are cached into a hash table (constant lookup time) in order to avoid some of the possible repeated dissimilarity computations. Fourthly, we incorporate the option to constrain the motif search by specifying a maximum segment stretch in Algorithm 2 and VALIDPOSITION. Finally, the function that returns the non-overlapping top-k motifs employs a boolean array of size n in order to avoid O(k2) comparisons between members of the queue (cf. [3]). Notice that we have a memoryefficient implementation, as we basically only need to store z and the boolean array (both of O(n) space), M (of O(k) space, k n), and X , V , S, P , and \u0398 (all of them of O(\u03ba) space, \u03ba n). The aforementioned hash table (optional) can be allocated in any predefined, available memory segment. For the sake of brevity, the interested reader is referred to the provided code for a full account of the outlined implementation details.\nC. Variants\nGiven the main Algorithm 1, we consider a number of variations that may potentially improve SWARMMOTIF\u2019s performance without introducing too much algorithmic complexity: \u2022 Sociability: We study whether a \u201ccognitive-only\u201d model, a\n\u201csocial-only\u201d one, or different weightings of the two yield to some improvements [44]. To do so, we just need to introduce a parameter \u03b1 \u2208 [0, 1] controlling the degree of \u2018sociability\u2019 of the particles, and implement lines 1\u20132 of Algorithm 3 instead of Eq. 1. \u2022 Stochastic: We investigate the use of a random inertia weight [39]. This may alleviate the need of using the same c0 in different environments, providing a potentially more adaptive trade-off between exploration and exploitation (also controlled by \u03b1 in the previous point). To consider this variant, we just need to replace line 22 in Algorithm 1 by line 3 in Algorithm 3. \u2022 Velocity clamping: In addition to constriction, we study limiting the maximum velocity of the particles [45]. Empirical studies have shown that the simultaneous consideration of a\nAlgorithm 3 Variations to Algorithm 1: sociability (lines 1\u20132), stochastic (line 3), velocity clamping (lines 4\u20136), and craziness (lines 7\u201310).\n1: c1 \u2190 c0\u03c6(1\u2212 \u03b1) 2: c2 \u2190 c0\u03c6\u03b1\n3: vi \u2190 (1\u22122(1\u2212c0))uvi+c1u1\u2297(pi\u2212xi)+c2u2\u2297(pg\u2212xi)\n4: vrange \u2190 [n,w\u2206, n, w\u2206]/2 5: for vrangej in vrange 6: vi,j \u2190 min(vrangej ,max(\u2212v range j , vi,j))\n7: v\u2032i \u2190 As in Algorithm 2 8: for vi,j in vi 9: if u < \u03c1\n10: vi,j \u2190 v\u2032i,j .\nconstriction factor and velocity clamping results in improved performance on certain problems [46]. To apply velocity clamping we add lines 4\u20136 of Algorithm 3 between lines 22 and 23 of Algorithm 1. \u2022 Craziness: We introduce so-called \u201ccraziness\u201d or \u201cperturbation\u201d in the particles\u2019 velocities, as initially suggested by Kennedy & Eberhart [45]. In such variant, inspired by the sudden direction changes observed in flocking birds, the particles\u2019 velocity is altered with a certain probability \u03c1, with the aim of favoring exploration by increasing directional diversity and discouraging premature convergence [47]. We coincide with [47] in that, in some sense, this can be seen as a mutation operation. To implement craziness we add lines 7\u201310 of Algorithm 3 between lines 22 and 23 of Algorithm 1."}, {"heading": "IV. EVALUATION METHODOLOGY", "text": "To evaluate SWARMMOTIF\u2019s speed and accuracy we consider plots like the one presented in Fig. 3. As a reference, we draw uniform random samples from the motif search space and compute their dissimilarities (we take as many samples as the length n of the time series). As a baseline, we use the top25 motifs found by MOEN [3], which we will denote byM\u2217. Existing empirical evidence [3], [17] suggests that MOEN is the most efficient algorithm to retrieve the top exact similaritybased motifs in a range of lengths6 (Sec. I). Notice furthermore that here we are not that interested in obtaining all top-25 true exact motifs, but more concerned on obtaining good seed motifs within these using an anytime approach (Sec. II-C).\nAs its competitors, MOEN has however some limitations (Sec. I). Thus, to fairly compare results, we have to apply some constrains to our algorithm. Since MOEN can only use the Euclidean distance between z-normalized segments, here we also adopt this formulation for D. In addition, as MOEN only considers pairs of segments of the same length (without resampling), we have to constrain SWARMMOTIF so\n6Besides, we could not find any other promising exact or anytime approach with some available code, nor with sufficient detail to allow a reliable implementation.\n7\nthat xi,2 = xi,4. Therefore, the reported motif dissimilarities D(mi) correspond to the Euclidean distance between two znormalized segments of the same length (we divide by the length of the segments to compare different segment lengths, Sec. II-A). In the reported experiments, SWARMMOTIF is run 10 times with k = 10. We stop its execution when we find 95% of D(mi) within M\u2217. This way, we assess the time taken to retrieve any 10 motifs from those with at least 95% confidence. All experiments are performed using a single core of an Intel R\u00a9 Xeon R\u00a9 CPU E5-2620 at 2.00 GHz.\nTo demonstrate that SWARMMOTIF is not biased towards a particular data source, time series length, or motif length, we consider 9 different time series of varying length, coming from distinct domains, and a number of arbitrary but sourceconsistent motif lengths (Table I). As mentioned, we make these time series and our code available online (Sec. I). Four of the time series have been used for motif discovery in previous studies [17], [48], while the other five are employed here for the first time for this task: 1) DOWJONES: The daily closing values of the Dow Jones\naverage in the USA from May 2, 1885 to April 22, 2014 [49]. 2) CARCOUNT: The number of cars measured for the Glendale on ramp for the 101 North freeway in Los Angeles, CA, USA [50]. The measurement was carried out by the Freeway Performance Measurement System7 and the data was retrieved from the UCI Machine Learning Repository [51]. Segments of missing values were manually interpolated or removed. 3) INSECT: The electrical penetration graph of a beet leafhopper (circulifer tenellus) [17]. The time series was retrieved from Mueen\u2019s website8. 4) EEG: A one hour electroencephalogram (in \u00b5V) from a single channel in a sleeping patient [17]. The time series was retrieved from Mueen\u2019s website9 and, according to the authors, was smoothed and filtered using domain-standard procedures. 5) FIELDRECORDING: The spectral centroid (in Hz) of a field recording retrieved from Freesound10 [52]. We used the mean of the stereo channels and the spectral centroid\n7http://pems.dot.ca.gov 8http://www.cs.ucr.edu/\u223cmueen/MK 9http://www.cs.ucr.edu/\u223cmueen/OnlineMotif 10http://www.freesound.org/people/JeffWojo/sounds/121250\n(linear frequency) Vamp SDK example plugin from Sonic Visualizer [53]. We used a Hann window of 8192 samples at 44.1 KHz with 75% overlap. 6) WIND: The wind speed (in m/s) registered in the buoy of Rincon del San Jose, TX, USA, between January 1, 2010 and April 11, 2014. The time series was retrieved from the Texas Coastal Ocean Observation Network website11. Segments of missing values were manually interpolated or removed. 7) POWER: The electric power consumption (in KW) of an individual household12. The data was retrieved from the UCI Machine Learning Repository [51]. We took the global active power, removed missing values, and downsampled the original time series by a factor of 5 using averaging and 50% overlap. 8) EOG: An electrooculogram tracking the eye movements of a sleeping patient [54]. We took the downsampled time series [48] from Mueen\u2019s web page13. 9) RANDOMWALK: A random walk time series. This was artificially synthesized using zi+1 = zi + N(0, 1) for i = 2, . . . n and z1 = 0, where N(0, 1) is a real Gaussian random number generator with zero mean and unit variance.\nTo assess the statistical significance of the differences between alternative parameter settings, we employ a two stage approach. First, we consider all settings at the same time and perform the Friedman\u2019s test [55], which is a non-parametric statistical test used to detect differences in treatments across multiple test attempts. We use as inputs the median values for all settings for 25 equally-spaced time steps. In the case some difference between settings is detected (i.e., we reject the null hypothesis that the settings\u2019 performances come from the same distribution), we proceed to the second stage. In it, we perform all possible pairwise comparisons between settings using the Wilcoxon signed-rank test [55], another non-parametric statistical hypothesis test used for comparing matched samples. To counteract the problem of multiple comparisons and control the so-called family-wise error rate, we employ the HolmBonferroni correction [56]. In all statistical tests, we consider a significance level of 0.01."}, {"heading": "V. RESULTS", "text": ""}, {"heading": "A. Configuration", "text": "In pre-analysis, and according to common practice, we set \u03ba = 100, \u03c6 = 4.1, and \u03c4 = 2000. We then experimented with 6 different static topologies \u03b8 [57]: global best, local best (two neighbors), Von Neumann, random (three neighbors), wheel, and binary tree. The results showed the qualitative equivalence of all topologies except, perhaps, global best and wheel (Fig. 4). In some data sets, these two turned out to yield slightly worse performances for short-time runs of the algorithm (small t), although for longer runs they gradually became equivalent to the rest. However, in general,\n11http://lighthouse.tamucc.edu/pq 12http://archive.ics.uci.edu/ml/datasets/Individual+household+electric+\npower+consumption 13http://www.cs.ucr.edu/\u223cmueen/DAME\n8 10 1 10 2 10 3 10 4 0.0082 0.0142 0.0247 0.0430 0.0749 0.1304\nt [s]\nD (m\ni)\nGlobal best Local best Von Neumann Random Wheel Binary tree\nFig. 4. Effect of \u03b8 on the EEG time series. Equivalent results were observed with the other time series.\nno systematic statistically significant difference was detected between topologies. With this in mind, we chose the local best topology to further favor exploration and parallelism, and to be more consistent with our local neighborhood design principle of Sec. III-A.\nNext, we studied the effect of the number of particles \u03ba and the stagnation threshold \u03c4 . To do so, we kept the previous configuration with the local best topology and subsequently evaluated \u03ba = {20, 40, 80, 160, 320} and \u03c4 = {500, 1000, 2000, 4000, 8000}. Essentially, we observed almost no performance changes under these alternative settings (Figs. 5 and 6). We only found a statistically significant difference in the case of the CARCOUNT data set. Specifically, the performance with \u03c4 = 500 was found to be statistically significantly worse than \u03c4 \u2265 2000. Regarding \u03ba, and after considering different n, w\u2206 and k, a partial tendency seemed to emerge: an increasing number of particles \u03ba was slightly beneficial for increasing lengths n, increasing w\u2206, and increasing k. Unfortunately, we could not obtain strong empirical evidence nor formal proof for this statement. Nonetheless, in subsequent experiments, we decided to use a value for \u03ba and \u03c4 that dynamically adapts SWARMMOTIF\u2019s configuration to such predefined task parameters. We arbitrarily set \u03c4 proportional to \u03ba, and \u03ba proportional to n and in direct relation to w\u2206 and k (we refer to the provided code for the exact formulation).\nTo conclude our pre-analysis, we studied the influence of the constriction constant \u03c6. Following common practice, we considered \u03c6 = {4.02, 4.05, 4.1, 4.2, 4.4, 4.8}. In this case, we saw that high values had a negative impact on performance (Fig. 7). In particular, values of \u03c6 \u2265 4.2 or \u03c6 \u2265 4.4, depending on the data set, statistically significantly increased the motif dissimilarities at a given t. Contrastingly, values 4 < \u03c6 < 4.2 yielded stable dissimilarities with no statistically significant variation (in some data sets, this range could be extended to 4 < \u03c6 \u2264 4.4). It is well-known that higher \u03c6 values favor exploitation rather than exploration [43]. Hence, it is not\n10 0\n10 1\n10 2\n10 3\n10 4\n0.0102\n0.0168\n0.0276\n0.0452\n0.0742\n0.1219\nt [s]\nD (m\ni)\n20 40 80 160 320\nFig. 5. Effect of \u03ba on the WIND time series. Equivalent results were observed with the other time series.\n10 0\n10 1\n10 2\n10 3\n10 4\n0.0240\n0.0368\n0.0562\n0.0860\n0.1316\n0.2012\nt [s]\nD (m\ni)\n500 1000 2000 4000 8000\nFig. 6. Effect of \u03c4 on the FIELDRECORDING time series. Equivalent results were observed with the other time series.\nstrange to observe that low \u03c6 values are more appropriate for searching the large motif spaces we consider here. We finally chose \u03c6 = 4.05.\nOverall, the result of our pre-analysis suggests a high degree of robustness with respect to the possible configurations. The topology \u03b8, the number of particles \u03ba, the stagnation threshold \u03c4 , and the constriction constant \u03c6 have, in general, no significant influence on the obtained results. The only consistent exception is observed for values of \u03c6 \u2265 4.4, which are not the most common practice [34]. The global best and wheel topologies could also constitute a further exception. However, as we have shown, these become qualitatively equivalent to the rest as execution time t increases, yielding no statistically significant difference. We believe that the reported stability of SWARMMOTIF against the tested configurations and data sets justifies the use of our setting for finding motifs in diverse time series coming from further application domains.\n9 10 0 10 1 10 2 10 3 10 4 0.0102 0.0157 0.0243 0.0375 0.0579 0.0895\nt [s]\nD (m\ni)\n4.02 4.05 4.1 4.2 4.4 4.8\nFig. 7. Effect of \u03c6 on the INSECT time series. Equivalent results were observed with the other time series.\nB. Variants\nUsing the configuration resulting from the previous section, we subsequently assessed the performance of the variations considered in Sec. III-C. We started with the sociability variant, experimenting with social-only models, \u03b1 = 1, cognitive-only models, \u03b1 = 0, and intermediate configurations, \u03b1 = {0.2, 0.33, 0.66, 0.8}. Apart from the fact that no clear tendency could be observed, none of the previous settings was able to consistently reach the performance achieved by the original variant (\u03b1 = 1/2, Eq. 1) in all time series. That is, none of the previous settings could statistically significantly outperform \u03b1 = 1/2 in the majority of the data sets.\nNext, we experimented with the stochastic and the velocity clamping variants. While the former did not improve our results, the latter led to a statistically significant improvement for some time series. Because of that, we decided to discard the use of a stochastic variant but to incorporate velocity clamping to our main algorithm. The former could be difficult to justify while the latter has empirical evidence behind it (Sec. III-C).\nFinally, we experimented with craziness and its probability \u03c1. The results showed a similar performance for 0 \u2264 \u03c1 < 0.001, a slightly better performance for 0.001 \u2264 \u03c1 \u2264 0.01, and an increasingly worse performance for \u03c1 > 0.01 (Fig. 8). A statistically significant difference was found between \u03c1 \u2264 0.01 and \u03c1 > 0.1, being \u03c1 > 0.1 a consistently worse setting. These results were expected, as the swarm performs a more random search with increasing \u03c1, being completely random in the limiting case of \u03c1 = 1. The slightly better performance for 0.001 \u2264 \u03c1 \u2264 0.01 was not found to be statistically significant under our criteria. However, it was visually noticeable for some data sets. For instance, with the EEG data set, we see that curves 33 and 34 hit the dissimilarities of the true exact motif setM\u2217 (gray area) two or three times earlier than curves 30, 31, and 32 (Fig. 8). With these results, and seeing that \u03c1 values between 0.001 and 0.01 never harmed the performance of the algorithm, we chose \u03c1 = 0.002.\n10 1\n10 2\n10 3\n10 4\n0.0082\n0.0142\n0.0247\n0.0430\n0.0749\n0.1304\nt [s]\nD (m\ni)\n0 0.00001 0.0001 0.001 0.01 0.1\nFig. 8. Effect of \u03c1 on the EEG time series. Equivalent results were observed with the other time series."}, {"heading": "C. Final Performance", "text": "After extending SWARMMOTIF with velocity clamping and craziness, we assess its performance on all considered time series using the default parameter combination resulting from the previous two sections. As can be seen, the obtained motif dissimilarities are far from the random sampling in all cases (Fig. 9; notice the logarithmic axes). In addition, we see that SWARMMOTIF is able to already obtain dissimilarities withinM\u2217 as soon as its execution begins. Specifically, motif dissimilarities inM start to overlap the ones inM\u2217 at t < 10 s for practically all time series. The only exceptions are EOG and RANDOMWALK, where M starts to overlap with M\u2217 at t < 100 s. We hypothesize that taking a smaller number of particles \u03ba could make M overlap with M\u2217 earlier, but leave the formal assessment of this hypothesis for future work.\nFinally, as execution time t progresses, we see that SWARMMOTIF consistently retrieves lower dissimilarities, up to the point that M ' M\u2217 (Fig. 9 and Table II). Following the condition we specify in Sec. IV, this means that the distances in the motif set obtained by SWARMMOTIF are not statistically worse than the ones of the true exact motif set. With respect to MOEN\u2019s execution time, this happens 1487 (DOWJONES), 184 (CARCOUNT), 50 (INSECT), 179 (EEG), 100 (FIELDRECORDING), 241 (WIND), 286 (POWER), 74 (EOG), and 287 (RANDOMWALK) times faster. This implies between one and three orders of magnitude speedups (more than that for DOWJONES). Overall, we believe this is an extremely competitive performance for an anytime motif discovery algorithm."}, {"heading": "VI. CONCLUSION", "text": "In this article, we propose an innovative standpoint to the task of time series motif discovery by formulating it as an anytime multimodal optimization problem. After a concise but comprehensive literature review, we reason out the new formulation and the development of an approach based on\n10\nevolutionary computation. We then highlight the several advantages of this new formulation, many of which relate to a high degree of flexibility of the solutions that come from it. To the best of our knowledge, such a degree of flexibility is unseen in previous works on time series motif discovery.\nWe next present SWARMMOTIF, an anytime multimodal optimization algorithm for time series motif discovery based on particle swarms. We show that SWARMMOTIF is extremely competitive when compared to the best approach we could find in the literature. It obtains motifs of comparable similarities, in considerably less time, and with minimum memory requirements. This is confirmed with 9 independent real-world time series of increasing length coming from a variety of domains. Besides, we find that the high majority of the possible implementation choices lead to non-significant performance changes in all considered time series. Thus, given this robustness, we can think about the proposed solution as being parameter-free from the user\u2019s perspective. Overall, if we add the aforementioned, unprecedented degree of\nflexibility, SWARMMOTIF stands out as one of the most prominent choices for motif discovery in long time series streams. Since the used data and code are available online (Sec. I), the research presented here is fully reproducible, and SWARMMOTIF is freely available to researchers and practitioners.\nWe believe that the consideration of multimodal optimization algorithms is a relevant direction for future research in the field of time series analysis and mining. Not only with regard to motif discovery, but also in other tasks such as querying for segments of unknown length [28] or determining optimal alignments and similarities [23]. With regard to the latter, we envision powerful approaches to variable-length local similarity calculations, in the vein of existing dynamic programming approaches [58], [59]. Finally, we believe that considering the search spaces and the time constraints derived from time series problems can be a challenge for the evolutionary computation community. We look forward to exploring all these topics in forthcoming works, together with\n11\nother multimodal optimization techniques that could be easily mapped to the problem of time series motif discovery."}, {"heading": "ACKNOWLEDGMENT", "text": "We would like to thank all the people who contributed the data sets used in this study and Abdullah Mueen for additionally sharing his code. We would also like to thank Xavier Anguera for useful discussions that motivated the present work. This research has been funded by 2009-SGR-1434 from Generalitat de Catalunya, JAEDOC069/2010 from Consejo Superior de Investigaciones Cient\u0131\u0301ficas (JS), TIN2012-38450C03-03 from the Spanish Government, and E.U. Social and FEDER funds (JS)."}], "references": [{"title": "Finding motifs in time series", "author": ["J. Lin", "E. Keogh", "S. Lonardi", "P. Patel"], "venue": "Proc. of the Workshop on Temporal Data Mining, 2002, pp. 53\u201356.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "Time series motif discovery: dimensions and applications", "author": ["A. Mueen"], "venue": "WIREs Data Mining and Knowledge Discovery, vol. 4, no. 2, pp. 152\u2013 159, 2014.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Enumeration of time series motifs of all lengths", "author": ["\u2014\u2014"], "venue": "Proc. of the IEEE Int. Conf. on Data Mining (ICDM), 2013, pp. 547\u2013556.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Probabilistic discovery of time series motifs", "author": ["B. Chiu", "E. Keogh", "S. Lonardi"], "venue": "Proc. of the ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD), 2003, pp. 493\u2013498.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "Experiencing SAX: a novel symbolic representation of time series", "author": ["J. Lin", "E. Keogh", "L. Wei", "S. Lonardi"], "venue": "Data Mining and Knowledge Discovery, vol. 15, no. 2, pp. 107\u2013144, 2007.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Finding motifs using random projections", "author": ["J. Buhler", "M. Tompa"], "venue": "Journal of Computational Biology, vol. 9, no. 2, pp. 225\u2013242, 2002.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2002}, {"title": "Multiresolution motif discovery in time series", "author": ["N. Castro", "P. Azevedo"], "venue": "Proc. of the SIAM Int. Conf. on Data Mining (SDM), 2010, pp. 665\u2013676.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Approximate variable-length time series motif discovery using grammar inference", "author": ["Y. Li", "J. Lin"], "venue": "Proc. of the Int. Workshop on Multimedia Data Mining (MDM), 2010, p. 10.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "The motif tracking algorithm", "author": ["W. Wilson", "P. Birkin", "U. Aickelin"], "venue": "International Journal of Automation and Computing, vol. 5, no. 1, pp. 32\u201344, 2008.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "Efficient and accurate discovery of patterns in sequence data sets", "author": ["A. Floratou", "S. Tata", "J.M. Patel"], "venue": "IEEE Trans. on Knowledge and Data Engineering, vol. 23, no. 8, pp. 1154\u20131168, 2011.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Using anytime algorithms in intelligent systems", "author": ["S. Zilberstein"], "venue": "AI Magazine, vol. 17, no. 3, pp. 73\u201383, 1996.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1996}, {"title": "Discovery of time-series motif from multi-dimensional data based on MDL principle", "author": ["Y. Tanaka", "K. Iwamoto", "K. Uehara"], "venue": "Machine Learning, vol. 58, pp. 269\u2013300, 2005.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Detecting time series motifs under uniform scaling", "author": ["D. Yankov", "E. Keogh", "J. Medina", "B. Chiu", "V. Zordan"], "venue": "Proc. of the ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD), 2007, pp. 844\u2013853.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Discovering original motifs with different lengths from time series", "author": ["H. Tang", "S.S. Liao"], "venue": "Knowledge-Based Systems, vol. 21, pp. 666\u2013 671, 2008.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Discovering patterns in realvalued time series", "author": ["J. Catalano", "T. Armstrong", "T. Oates"], "venue": "Knowledge Discovery in Databases: PKDD 2006, ser. Lecture Notes on Artificial Intelligence, J. F\u00fcrnkranz, T. Scheffer, and M. Spiliopoulou, Eds. Berlin, Germany: Springer, 2006, vol. 4213, pp. 462\u2013469.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Constrained motif discovery in time series", "author": ["Y. Mohammad", "T. Nishida"], "venue": "New Generation Computing, vol. 27, no. 4, pp. 319\u2013346, 2009.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Exact discovery of time series motifs", "author": ["A. Mueen", "E. Keogh", "Q. Zhu", "S. Cash", "B. Westover"], "venue": "Proc. of the SIAM Int. Conf. on Data Mining (SDM), 2009, pp. 473\u2013484.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Discovery of variable length time series motif", "author": ["P. Nunthanid", "V. Niennattrakul", "C.A. Ratanamahatana"], "venue": "Proc. of the Int. Conf. on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), 2011, pp. 472\u2013475.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Efficient proper length time series motif discovery", "author": ["S. Yingchareonthawornchai", "H. Sivaraks", "T. Rakthanmanon", "C.A. Ratanamahatana"], "venue": "Proc. of the IEEE Int. Conf. on Data Mining (ICDM), 2013, pp. 1265\u20131270.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Exact discovery of length-range motifs", "author": ["Y. Mohammad", "T. Nishida"], "venue": "Intelligent Information and Database Systems, ser. Lecture Notes in Artificial Intelligence, N. T. Nguyen, B. Attachoo, B. Trawiski, and K. Somboonviwat, Eds. Cham, Switzerland: Springer Int. Publishing, 2014, vol. 8398, pp. 23\u201332.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Online discovery and maintenance of time series motifs", "author": ["A. Mueen", "E. Keogh"], "venue": "Proc. of the ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD), 2010, pp. 1089\u20131098.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Everything you know about dynamic time warping is wrong", "author": ["C.A. Ratanamahatana", "E. Keogh"], "venue": "ACM SIGKDD Workshop on Mining Temporal and Sequential Data, 2004, pp. 22\u201325.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2004}, {"title": "An empirical evaluation of similarity measures for time series classification", "author": ["J. Serr\u00e0", "J.L. Arcos"], "venue": "Knowledge-Based Systems, vol. 67, pp. 305\u2013314, 2014.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Introduction to operations research, 9th ed", "author": ["F.S. Hillier", "G.J. Lieberman"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "Metaheuristics in combinatorial optimization: overview and conceptual comparison", "author": ["C. Blum", "A. Roli"], "venue": "ACM Computing Surveys, vol. 35, no. 3, pp. 268\u2013308, 2003.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2003}, {"title": "Evolutionary optimization in uncertain environments: a survey", "author": ["Y. Jin", "J. Branke"], "venue": "IEEE Trans. on Evolutionary Computation, vol. 9, no. 3, pp. 303\u2013317, 2005.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2005}, {"title": "A survey on metaheuristics for stochastic combinatorial optimization", "author": ["L. Bianchi", "M. Dorigo", "L.M. Gambardella", "W.J. Gutjahr"], "venue": "Natural Computing, vol. 8, no. 2, pp. 239\u2013287, 2009.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2009}, {"title": "Optimizing similarity search for arbitrary length time series queries", "author": ["T. Kahveci", "A.K. Singh"], "venue": "IEEE Trans. on Knowledge and Data Engineering, vol. 16, no. 4, pp. 418\u2013433, 2004.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2004}, {"title": "Searching and mining trillions of time series subsequences under dynamic time warping", "author": ["T. Rakthanmanon", "B. Campana", "A. Mueen", "G.E.A.P.A. Batista", "B. Westover", "Q. Zhu", "J. Zakaria", "E. Keogh"], "venue": "Proc. of the ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD), 2012, pp. 262\u2013270.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "Particle swarm optimization", "author": ["M. Clerc"], "venue": "London, UK: ISTE,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2006}, {"title": "Particle swarm optimization", "author": ["R. Poli", "J. Kennedy", "T.M. Blackwell"], "venue": "Swarm Intelligence, vol. 1, no. 1, pp. 33\u201357, 2007.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}, {"title": "A review of particle swarm optimization. Part I: background and development", "author": ["A. Banks", "J. Vincent", "C. Anyakoha"], "venue": "Natural Computing, vol. 6, no. 4, pp. 467\u2013484, 2007.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2007}, {"title": "Particle swarm optimization and  12 intelligence: advances and applications", "author": ["K.E. Parsopoulos", "M.N. Vrahatis"], "venue": "Hershey, USA: IGI Global,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2010}, {"title": "A review of particle swarm optimization methods used for multimodal optimization", "author": ["J. Barrera", "C. Coello Coello"], "venue": "Innovations in Swarm Intelligence, ser. Studies in Computational Intelligence, C. P. Lim, L. C. Jain, and S. Dehuri, Eds. Berlin, Germany: Springer, 2009, vol. 248, pp. 9\u201337.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2009}, {"title": "A convergence proof for the particle swarm optimizer", "author": ["F. van der Bergh", "A.P. Engelbrecht"], "venue": "Fundamenta Informaticae, vol. 105, no. 4, pp. 341\u2013374, 2010.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2010}, {"title": "Visual exploration of frequent patterns in multivariate time series", "author": ["M.C. Hao", "M. Marwah", "H. Janetzko", "U. Dayal", "D.A. Keim", "D. Patnaik", "N. Ramakrishnan", "R.K. Sharma"], "venue": "Information Visualization, vol. 11, no. 1, pp. 71\u201383, 2014.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2014}, {"title": "Detecting subdimensional motifs: an efficient algorithm for generalized multivariate pattern discovery", "author": ["D. Minnen", "C. Isbell", "I. Essa", "T. Starner"], "venue": "Proc. of the IEEE Int. Conf. on Data Mining (ICDM), 2007, pp. 601\u2013606.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2007}, {"title": "Tracking and optimizing dynamic systems with particle swarms", "author": ["R.C. Eberhart", "Y. Shi"], "venue": "Proc. of the IEEE Congress on Evolutionary Computation (CEC), 2001, pp. 94\u2013100.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2001}, {"title": "Niching without niching parameters: particle swarm optimization using a ring topology", "author": ["X. Li"], "venue": "IEEE Trans. on Evolutionary Computation, vol. 14, no. 1, pp. 150\u2013169, 2010.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}, {"title": "A hybrid particle swarm with a time-adaptive topology for constrained optimization", "author": ["M.R. Bonyadi", "X. Li", "Z. Michalewicz"], "venue": "Swarm and Evolutionary Computation, vol. 18, pp. 22\u201337, 2014.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2014}, {"title": "Locating potentially disjoint feasible regions of a search space with a particle swarm optimizer", "author": ["M.R. Bonyadi", "Z. Michalewicz"], "venue": "Evolutionary Constrained Optimization. In press. Springer.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 0}, {"title": "The particle swarm - explosion, stability, and convergence in a multidimensional complex space", "author": ["M. Clerc", "J. Kennedy"], "venue": "IEEE Trans. on Evolutionary Computation, vol. 6, no. 1, pp. 58\u201373, 2002.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2002}, {"title": "The particle swarm: social adaptation of knowledge", "author": ["J. Kennedy"], "venue": "Proc. of the IEEE Int. Conf. on Evolutionary Computation (CEC), 1997, pp. 303\u2013308.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1997}, {"title": "Particle swarm optimization", "author": ["J. Kennedy", "R.C. Eberhart"], "venue": "Proc. of the IEEE Int. Conf. on Neural Networks (ICNN), 1995, pp. 1942\u2013 1948.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 1995}, {"title": "Comparing inertia weights and constriction factors in particle swarm optimization", "author": ["R.C. Eberhart", "Y. Shi"], "venue": "Proc. of the IEEE Congress on Evolutionary Computation (CEC), 2000, pp. 84\u201388.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2000}, {"title": "Particle swarms in size and shape optimization", "author": ["P.C. Fourie", "A.A. Groenwold"], "venue": "Proc. of the Int. Workshop on Multidisciplinary Design Optimization, 2000, pp. 97\u2013106.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2000}, {"title": "Finding time series motifs in disk-resident data", "author": ["A. Mueen", "E. Keogh", "N. Bigdely-Shamlo"], "venue": "Proc. of the IEEE Int. Conf. on Data Mining (ICDM), 2009, pp. 367\u2013376.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2009}, {"title": "Daily closing value of the Dow Jones average, 1885 to present", "author": ["S.H. Williamson"], "venue": "2012. [Online]. Available: http://www.measuringworth.com/ datasets/DJA/index.php", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2012}, {"title": "Adaptive event detection with timevarying Poisson processes", "author": ["A. Ihler", "J. Hutchins", "P. Smyth"], "venue": "Proc. of the ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD), 2006, pp. 207\u2013216.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2006}, {"title": "The UCI machine learning repository", "author": ["K. Bache", "M. Lichman"], "venue": "2013. [Online]. Available: http://archive.ics.uci.edu/ml", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2013}, {"title": "Freesound technical demo", "author": ["F. Font", "G. Roma", "X. Serra"], "venue": "Proc. of the ACM Multimedia Int. Conf. (ACM-MM), 2013, pp. 411\u2013412.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2013}, {"title": "Sonic Visualiser: an open source application for viewing, analysing, and annotating music audio files", "author": ["C. Cannam", "C. Landone", "M.B. Sandler"], "venue": "Proc. of the ACM Multimedia Int. Conf. (ACM-MM), 2010, pp. 1467\u20131468.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2010}, {"title": "Physiobank, physiotoolkit, and physionet: components of a new research resource for complex physiologic signals", "author": ["A.L. Goldberger", "L.A.N. Amaral", "L. Glass", "J.M. Hausdorff", "P.C. Ivanov", "R.G. Mark", "J.E. Mietus", "G.B. Moody", "C.-K. Peng", "H.E. Stanley"], "venue": "Circulation, vol. 101, no. 23, pp. e215\u2013e220, 2000.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2000}, {"title": "Nonparametric statistical methods, 2nd ed", "author": ["M. Hollander", "D.A. Wolfe"], "venue": null, "citeRegEx": "55", "shortCiteRegEx": "55", "year": 1999}, {"title": "A simple sequentially rejective multiple test procedure", "author": ["S. Holm"], "venue": "Scandinavian Journal of Statistics, vol. 6, no. 2, pp. 65\u201370, 1979.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 1979}, {"title": "Population topologies and their influence in particle swarm performance", "author": ["R. Mendes"], "venue": "Ph.D. dissertation, Escola de Engenharia, Universidade do Minho, Braga, Portugal, 2004.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2004}, {"title": "Identification of common molecular subsequences", "author": ["T.F. Smith", "M.S. Waterman"], "venue": "Journal of Molecular Biology, vol. 147, pp. 195\u2013197, 1981.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 1981}], "referenceMentions": [{"referenceID": 0, "context": "These segment pairs are commonly called motifs [1], and their existence is unlikely to be due to chance alone.", "startOffset": 47, "endOffset": 50}, {"referenceID": 1, "context": "the time series [2].", "startOffset": 16, "endOffset": 19}, {"referenceID": 1, "context": ", references in [2], [3]).", "startOffset": 16, "endOffset": 19}, {"referenceID": 2, "context": ", references in [2], [3]).", "startOffset": 21, "endOffset": 24}, {"referenceID": 0, "context": "[1] and Chiu et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4], many of such approaches employ the SAX representation [5] and/or a sparse collision matrix [6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[4], many of such approaches employ the SAX representation [5] and/or a sparse collision matrix [6].", "startOffset": 59, "endOffset": 62}, {"referenceID": 5, "context": "[4], many of such approaches employ the SAX representation [5] and/or a sparse collision matrix [6].", "startOffset": 96, "endOffset": 99}, {"referenceID": 6, "context": "For instance, Castro & Azevedo [7] propose an amplitude multi-resolution approach to detect frequent segments, Li & Lin [8] use a grammar inference algorithm for exploring motifs with lengths above a certain threshold, Wilson et al.", "startOffset": 31, "endOffset": 34}, {"referenceID": 7, "context": "For instance, Castro & Azevedo [7] propose an amplitude multi-resolution approach to detect frequent segments, Li & Lin [8] use a grammar inference algorithm for exploring motifs with lengths above a certain threshold, Wilson et al.", "startOffset": 120, "endOffset": 123}, {"referenceID": 8, "context": "[9] use concepts from immune memory to deal with different lengths, and Floratou et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] combine suffix trees with segment models to find motifs of any length.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "In addition, approximate algorithms are restricted to a specific dissimilarity measure between segments (the one implicit in their discretization step) and do not allow easy access to preliminary results, which is commonly known as anytime algorithms [11].", "startOffset": 251, "endOffset": 255}, {"referenceID": 11, "context": "Finally, to the best of our knowledge, only [12]\u2013[14] consider the identification of motif pairs containing segments of different lengths.", "startOffset": 44, "endOffset": 48}, {"referenceID": 13, "context": "Finally, to the best of our knowledge, only [12]\u2013[14] consider the identification of motif pairs containing segments of different lengths.", "startOffset": 49, "endOffset": 53}, {"referenceID": 12, "context": "This can be considered a relevant feature, as it produces better results in a number of different domains [13].", "startOffset": 106, "endOffset": 110}, {"referenceID": 14, "context": "Exceptions to this statement achieved efficiency by sampling the data stream [15] or by identifying extreme points that constrained the search [16].", "startOffset": 77, "endOffset": 81}, {"referenceID": 15, "context": "Exceptions to this statement achieved efficiency by sampling the data stream [15] or by identifying extreme points that constrained the search [16].", "startOffset": 143, "endOffset": 147}, {"referenceID": 16, "context": "[17], the exact identification of time series motifs was thought to be intractable for even time series of moderate length.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "and many approximate ones [17].", "startOffset": 26, "endOffset": 30}, {"referenceID": 17, "context": "\u2019s work, a number of improvements have been proposed, the majority focusing on eliminating the need to set a fixed segment length [18]\u2013[20].", "startOffset": 130, "endOffset": 134}, {"referenceID": 19, "context": "\u2019s work, a number of improvements have been proposed, the majority focusing on eliminating the need to set a fixed segment length [18]\u2013[20].", "startOffset": 135, "endOffset": 139}, {"referenceID": 16, "context": "erative search for the optimal length using [17] and, from the", "startOffset": 44, "endOffset": 48}, {"referenceID": 17, "context": "reported numbers, also outperforms further approaches such as [18]\u2013[20].", "startOffset": 62, "endOffset": 66}, {"referenceID": 19, "context": "reported numbers, also outperforms further approaches such as [18]\u2013[20].", "startOffset": 67, "endOffset": 71}, {"referenceID": 2, "context": "This algorithm, called MOEN [3], is essentially parameter-free, and is believed to be one of the most efficient motif discovery algorithms available nowadays.", "startOffset": 28, "endOffset": 31}, {"referenceID": 2, "context": "However, its complexity is still quadratic in the length of the time series [3], and hence its applicability to large-scale time series streams remains problematic.", "startOffset": 76, "endOffset": 79}, {"referenceID": 2, "context": "[3], [17], we can derive a formal, generic similarity-based definition [2] of time series motifs.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "[3], [17], we can derive a formal, generic similarity-based definition [2] of time series motifs.", "startOffset": 5, "endOffset": 9}, {"referenceID": 1, "context": "[3], [17], we can derive a formal, generic similarity-based definition [2] of time series motifs.", "startOffset": 71, "endOffset": 74}, {"referenceID": 0, "context": "zb+wb\u22121], for wa, wb \u2208 [wmin, wmax], a \u2208 [1, n\u2212wa+1], and b \u2208 [1, n \u2212 wb + 1] where, in order to avoid repeated and trivial matches [1], a + wa < b.", "startOffset": 132, "endOffset": 135}, {"referenceID": 2, "context": "1Notice that, following [3], this definition can be trivially extended to different degrees of overlap.", "startOffset": 24, "endOffset": 27}, {"referenceID": 20, "context": "Example of a time series motif pair found in the WILDLIFE time series of [21] using SWARMMOTIF and normalized dynamic time warping as the dissimilarity measure: a = 248, wa = 244, b = 720, and wb = 235.", "startOffset": 73, "endOffset": 77}, {"referenceID": 21, "context": "Ratanamahatana & Keogh [22] list a number of intuitive normalization mechanisms for dynamic time warping that can easily be applied to other measures.", "startOffset": 23, "endOffset": 27}, {"referenceID": 22, "context": "For instance, in the case of a dissimilarity measure based on the Lp norm [23], we can directly divide by the segment length2, using brute-force upsampling to the largest length [22] when wa 6= wb.", "startOffset": 74, "endOffset": 78}, {"referenceID": 21, "context": "For instance, in the case of a dissimilarity measure based on the Lp norm [23], we can directly divide by the segment length2, using brute-force upsampling to the largest length [22] when wa 6= wb.", "startOffset": 178, "endOffset": 182}, {"referenceID": 23, "context": "Magnitudes like this challenge the memory and speed of any optimization algorithm, specially if we have no clue to guide the search [24].", "startOffset": 132, "endOffset": 136}, {"referenceID": 22, "context": "between time series [23], is what gives continuity to our search space.", "startOffset": 20, "endOffset": 24}, {"referenceID": 20, "context": "Visualizations of the search space obtained with the WILDLIFE time series [21] and dynamic time warping as the dissimilarity measure: (A) fixing a = 110 and b = 602 but i, j = 200, .", "startOffset": 74, "endOffset": 78}, {"referenceID": 24, "context": "However, we have robust and established algorithms for efficiently locating prominent local minima in complex search spaces [25]\u2013[27].", "startOffset": 124, "endOffset": 128}, {"referenceID": 26, "context": "However, we have robust and established algorithms for efficiently locating prominent local minima in complex search spaces [25]\u2013[27].", "startOffset": 129, "endOffset": 133}, {"referenceID": 10, "context": "corresponds to the basic paradigm of anytime algorithms [11].", "startOffset": 56, "endOffset": 60}, {"referenceID": 18, "context": "Anytime algorithms have recently been highlighted as \u201cvery beneficial for motif discovery in massive [time series] datasets\u201d [19].", "startOffset": 125, "endOffset": 129}, {"referenceID": 1, "context": "This is particularly true for more exploratory tasks, where one is typically interested in data understanding and visual inspection (see [2]), and can also hold for other tasks, as top-k motifs can be very similar among themselves.", "startOffset": 137, "endOffset": 140}, {"referenceID": 27, "context": "M\u2217, we can easily and efficiently retrieve further repetitions via common established approaches [28], [29].", "startOffset": 97, "endOffset": 101}, {"referenceID": 28, "context": "M\u2217, we can easily and efficiently retrieve further repetitions via common established approaches [28], [29].", "startOffset": 103, "endOffset": 107}, {"referenceID": 24, "context": "In fact, if we do not have to assess the global optimality of a solution, we have a number of approaches that can deal with large, multimodal, continuous but noisy search spaces [25]\u2013[27].", "startOffset": 178, "endOffset": 182}, {"referenceID": 26, "context": "In fact, if we do not have to assess the global optimality of a solution, we have a number of approaches that can deal with large, multimodal, continuous but noisy search spaces [25]\u2013[27].", "startOffset": 183, "endOffset": 187}, {"referenceID": 29, "context": "Among them, we choose PSO [30]\u2013[34].", "startOffset": 26, "endOffset": 30}, {"referenceID": 32, "context": "Among them, we choose PSO [30]\u2013[34].", "startOffset": 31, "endOffset": 35}, {"referenceID": 33, "context": "optimization problems [33] which has been applied to multimodal problems [35].", "startOffset": 73, "endOffset": 77}, {"referenceID": 26, "context": "It is a metaheuristic [27], meaning that it cannot guarantee whether the found solution corresponds to a global optimum.", "startOffset": 22, "endOffset": 26}, {"referenceID": 34, "context": "versions of it have been proven to solve this issue [36].", "startOffset": 52, "endOffset": 56}, {"referenceID": 34, "context": "Other versions guarantee the convergence to the global optimum, but only with the number of iterations approaching infinity [36].", "startOffset": 124, "endOffset": 128}, {"referenceID": 29, "context": "(see [30]\u2013[35] and references therein).", "startOffset": 5, "endOffset": 9}, {"referenceID": 33, "context": "(see [30]\u2013[35] and references therein).", "startOffset": 10, "endOffset": 14}, {"referenceID": 23, "context": "2) We are able to achieve a certain efficiency, as optimization algorithms do not usually explore the full solution space and perform few fitness evaluations [24].", "startOffset": 158, "endOffset": 162}, {"referenceID": 22, "context": "Additionally, we can straightforwardly incorporate notions of \u2018interestingness\u2019, hubness, or complexity (see references in [23]).", "startOffset": 123, "endOffset": 127}, {"referenceID": 21, "context": "The dissimilarity function D can expressly handle segments of different lengths or we can simply upsample to the largest length (see [22]).", "startOffset": 133, "endOffset": 137}, {"referenceID": 35, "context": "Thus, just by replacing D, we are able to work with multi-dimensional time series [37], detect sub-dimensional motifs [38], perform a constrained motif discovery task [16], etc.", "startOffset": 82, "endOffset": 86}, {"referenceID": 36, "context": "Thus, just by replacing D, we are able to work with multi-dimensional time series [37], detect sub-dimensional motifs [38], perform a constrained motif discovery task [16], etc.", "startOffset": 118, "endOffset": 122}, {"referenceID": 15, "context": "Thus, just by replacing D, we are able to work with multi-dimensional time series [37], detect sub-dimensional motifs [38], perform a constrained motif discovery task [16], etc.", "startOffset": 167, "endOffset": 171}, {"referenceID": 1, "context": "definition of motif to incorporate both notions [2].", "startOffset": 48, "endOffset": 51}, {"referenceID": 31, "context": "The agentbased nature of PSO naturally yields to parallel implementations [32].", "startOffset": 74, "endOffset": 78}, {"referenceID": 1, "context": "6) We still have the possibility to apply lower bounding techniques to D in order to reduce its computational cost [2], [29].", "startOffset": 115, "endOffset": 118}, {"referenceID": 28, "context": "6) We still have the possibility to apply lower bounding techniques to D in order to reduce its computational cost [2], [29].", "startOffset": 120, "endOffset": 124}, {"referenceID": 30, "context": "Our PSO approach to time series motif discovery is based on the combination of two well-known extensions to the canonical PSO [31].", "startOffset": 126, "endOffset": 130}, {"referenceID": 37, "context": "On one hand, we employ multiple reinitializations of the swarm on stagnation [39].", "startOffset": 77, "endOffset": 81}, {"referenceID": 38, "context": "On the other hand, we exploit the particles\u2019 \u201clocal memories\u201d with the intention of forming stable niches across different local minima [40].", "startOffset": 136, "endOffset": 140}, {"referenceID": 33, "context": "The former emulates a parallel multi-swarm approach [35] without the need of having to define the number of swarms and their communication.", "startOffset": 52, "endOffset": 56}, {"referenceID": 33, "context": "The latter, when combined with the former, results in a low-complexity niching strategy [35] that does not require niching parameters (see the related discussion in [41], [42]).", "startOffset": 88, "endOffset": 92}, {"referenceID": 39, "context": "The latter, when combined with the former, results in a low-complexity niching strategy [35] that does not require niching parameters (see the related discussion in [41], [42]).", "startOffset": 165, "endOffset": 169}, {"referenceID": 40, "context": "The latter, when combined with the former, results in a low-complexity niching strategy [35] that does not require niching parameters (see the related discussion in [41], [42]).", "startOffset": 171, "endOffset": 175}, {"referenceID": 41, "context": "Algorithm 1 starts by computing the velocity update constants (line 1) following Clerc\u2019s constriction method [43], i.", "startOffset": 109, "endOffset": 113}, {"referenceID": 38, "context": "Note that by considering the particles\u2019 neighborhood personal bests pg we follow the aforementioned local neighborhood niching strategy [40].", "startOffset": 136, "endOffset": 140}, {"referenceID": 37, "context": "aforementioned multiple reinitialization strategy [39].", "startOffset": 50, "endOffset": 54}, {"referenceID": 2, "context": "[3]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 42, "context": "\u2022 Sociability: We study whether a \u201ccognitive-only\u201d model, a \u201csocial-only\u201d one, or different weightings of the two yield to some improvements [44].", "startOffset": 141, "endOffset": 145}, {"referenceID": 0, "context": "To do so, we just need to introduce a parameter \u03b1 \u2208 [0, 1] controlling the degree of \u2018sociability\u2019 of the particles, and implement lines 1\u20132 of Algorithm 3 instead of Eq.", "startOffset": 52, "endOffset": 58}, {"referenceID": 37, "context": "\u2022 Stochastic: We investigate the use of a random inertia weight [39].", "startOffset": 64, "endOffset": 68}, {"referenceID": 43, "context": "\u2022 Velocity clamping: In addition to constriction, we study limiting the maximum velocity of the particles [45].", "startOffset": 106, "endOffset": 110}, {"referenceID": 44, "context": "constriction factor and velocity clamping results in improved performance on certain problems [46].", "startOffset": 94, "endOffset": 98}, {"referenceID": 43, "context": "\u2022 Craziness: We introduce so-called \u201ccraziness\u201d or \u201cperturbation\u201d in the particles\u2019 velocities, as initially suggested by Kennedy & Eberhart [45].", "startOffset": 141, "endOffset": 145}, {"referenceID": 45, "context": "In such variant, inspired by the sudden direction changes observed in flocking birds, the particles\u2019 velocity is altered with a certain probability \u03c1, with the aim of favoring exploration by increasing directional diversity and discouraging premature convergence [47].", "startOffset": 263, "endOffset": 267}, {"referenceID": 45, "context": "We coincide with [47] in that, in some sense, this can be seen as a mutation operation.", "startOffset": 17, "endOffset": 21}, {"referenceID": 2, "context": "As a baseline, we use the top25 motifs found by MOEN [3], which we will denote byM\u2217.", "startOffset": 53, "endOffset": 56}, {"referenceID": 2, "context": "Existing empirical evidence [3], [17] suggests that MOEN is", "startOffset": 28, "endOffset": 31}, {"referenceID": 16, "context": "Existing empirical evidence [3], [17] suggests that MOEN is", "startOffset": 33, "endOffset": 37}, {"referenceID": 16, "context": "Four of the time series have been used for motif discovery in previous studies [17], [48], while the other five are employed here for the first time for this task:", "startOffset": 79, "endOffset": 83}, {"referenceID": 46, "context": "Four of the time series have been used for motif discovery in previous studies [17], [48], while the other five are employed here for the first time for this task:", "startOffset": 85, "endOffset": 89}, {"referenceID": 47, "context": "1) DOWJONES: The daily closing values of the Dow Jones average in the USA from May 2, 1885 to April 22, 2014 [49].", "startOffset": 109, "endOffset": 113}, {"referenceID": 48, "context": "2) CARCOUNT: The number of cars measured for the Glendale on ramp for the 101 North freeway in Los Angeles, CA, USA [50].", "startOffset": 116, "endOffset": 120}, {"referenceID": 49, "context": "The measurement was carried out by the Freeway Performance Measurement System7 and the data was retrieved from the UCI Machine Learning Repository [51].", "startOffset": 147, "endOffset": 151}, {"referenceID": 16, "context": "3) INSECT: The electrical penetration graph of a beet leafhopper (circulifer tenellus) [17].", "startOffset": 87, "endOffset": 91}, {"referenceID": 16, "context": "single channel in a sleeping patient [17].", "startOffset": 37, "endOffset": 41}, {"referenceID": 50, "context": "5) FIELDRECORDING: The spectral centroid (in Hz) of a field recording retrieved from Freesound10 [52].", "startOffset": 97, "endOffset": 101}, {"referenceID": 51, "context": "Visualizer [53].", "startOffset": 11, "endOffset": 15}, {"referenceID": 49, "context": "The data was retrieved from the UCI Machine Learning Repository [51].", "startOffset": 64, "endOffset": 68}, {"referenceID": 52, "context": "8) EOG: An electrooculogram tracking the eye movements of a sleeping patient [54].", "startOffset": 77, "endOffset": 81}, {"referenceID": 46, "context": "We took the downsampled time series [48] from Mueen\u2019s web page13.", "startOffset": 36, "endOffset": 40}, {"referenceID": 53, "context": "First, we consider all settings at the same time and perform the Friedman\u2019s test [55], which is a non-parametric statistical test used to detect differences in treatments across multiple test attempts.", "startOffset": 81, "endOffset": 85}, {"referenceID": 53, "context": "In it, we perform all possible pairwise comparisons between settings using the Wilcoxon signed-rank test [55], another non-parametric statistical hypothesis test used for comparing matched samples.", "startOffset": 105, "endOffset": 109}, {"referenceID": 54, "context": "To counteract the problem of multiple comparisons and control the so-called family-wise error rate, we employ the HolmBonferroni correction [56].", "startOffset": 140, "endOffset": 144}, {"referenceID": 55, "context": "We then experimented with 6 different static topologies \u03b8 [57]: global best, local best (two neighbors), Von Neumann, random (three neighbors), wheel, and binary tree.", "startOffset": 58, "endOffset": 62}, {"referenceID": 41, "context": "It is well-known that higher \u03c6 values favor exploitation rather than exploration [43].", "startOffset": 81, "endOffset": 85}, {"referenceID": 32, "context": "4, which are not the most common practice [34].", "startOffset": 42, "endOffset": 46}, {"referenceID": 27, "context": "regard to motif discovery, but also in other tasks such as querying for segments of unknown length [28] or determining optimal alignments and similarities [23].", "startOffset": 99, "endOffset": 103}, {"referenceID": 22, "context": "regard to motif discovery, but also in other tasks such as querying for segments of unknown length [28] or determining optimal alignments and similarities [23].", "startOffset": 155, "endOffset": 159}, {"referenceID": 56, "context": "With regard to the latter, we envision powerful approaches to variable-length local similarity calculations, in the vein of existing dynamic programming approaches [58], [59].", "startOffset": 164, "endOffset": 168}], "year": 2015, "abstractText": "Efficiently finding similar segments or motifs in time series data is a fundamental task that, due to the ubiquity of these data, is present in a wide range of domains and situations. Because of this, countless solutions have been devised but, to date, none of them seems to be fully satisfactory and flexible. In this article, we propose an innovative standpoint and present a solution coming from it: an anytime multimodal optimization algorithm for time series motif discovery based on particle swarms. By considering data from a variety of domains, we show that this solution is extremely competitive when compared to the state-of-the-art, obtaining comparable motifs in considerably less time using minimal memory. In addition, we show that it is robust to different implementation choices and see that it offers an unprecedented degree of flexibility with regard to the task. All these qualities make the presented solution stand out as one of the most prominent candidates for motif discovery in long time series streams. Besides, we believe the proposed standpoint can be exploited in further time series analysis and mining tasks, widening the scope of research and potentially yielding novel effective solutions.", "creator": "LaTeX with hyperref package"}}}