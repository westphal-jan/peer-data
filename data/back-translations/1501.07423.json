{"id": "1501.07423", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jan-2015", "title": "A Flexible Coupling Approach to Multi-Agent Planning under Incomplete Information", "abstract": "Multi-Agent Planning (MAP) approaches typically focus on solving loosely coupled problems and are ineffective in dealing with more complex, highly interconnected problems. In most cases, agents work with complete information and build complete knowledge databases. This article presents a universal MAP framework designed to address problems at all levels of coupling with incomplete information. Agents in our MAP model are partially unaware of the information administered by the other agents and share only the critical information that affects other agents, thus maintaining a distributed vision of the task.", "histories": [["v1", "Thu, 29 Jan 2015 11:56:41 GMT  (700kb,D)", "http://arxiv.org/abs/1501.07423v1", "40 pages, 10 figures"]], "COMMENTS": "40 pages, 10 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["alejandro torre\\~no", "eva onaindia", "\\'oscar sapena"], "accepted": false, "id": "1501.07423"}, "pdf": {"name": "1501.07423.pdf", "metadata": {"source": "CRF", "title": "A Flexible Coupling Approach to Multi-Agent Planning under Incomplete Information", "authors": ["Alejandro Torre\u00f1o", "Eva Onaindia", "\u00d3scar Sapena"], "emails": [], "sections": [{"heading": null, "text": "Agents solve MAP tasks through the adoption of an iterative refinement planning procedure that uses single-agent planning technology. In particular, agents will devise refinements through the Partial-Order Planning paradigm, a flexible framework to build refinement plans leaving unsolved details that will be gradually completed by means of new refinements. Our proposal is supported with the implementation of a fullyoperative MAP system and we show various experiments when running our system over different types of MAP problems, from the most strongly-related to the most loosely-coupled.\nKeywords: Planning & scheduling; Multi-agent systems"}, {"heading": "1. Introduction", "text": "Planning is the art of building control algorithms that synthesize a course of action to achieve a desired set of goals from an initial situation. Traditionally,\nReceived Jan 25, 2012 Revised Jun 15, 2012 Accepted Sep 01, 2012\nar X\niv :1\n50 1.\n07 42\n3v 1\n[ cs\nplanning has been regarded as a centralized process in which a single entity is in charge of devising a plan that satisfies the problem goals.\nMulti-Agent Planning (MAP) generalizes the problem of planning in domains where several agents plan and act together. MAP introduces a social approach to planning (Nguyen and Katarzyniak, 2009), focusing on the collective effort of multiple planning entities to accomplish tasks by combining their knowledge, information and capabilities. This is required when agents are unable to solve their tasks by themselves, or at least can accomplish them better (more quickly, completely, precisely, or certainly) when working with others (Durfee, 2001).\nMAP is concerned with planning by multiple agents, i.e., distributed planning, and planning for multiple agents, i.e., planning for multi-agent execution, thus giving rise to a great variety of tools and techniques. The approach traditionally adopted by the Multi-Agent Systems (MAS) research community assumes that, in general, agents are self-interested and that there is not a common goal to solve, thus focusing on coordinating the activities of multiple agents in a shared environment (desJardins, Durfee, Ortiz and Wolverton, 1999). In agent-oriented approaches, the ultimate objective is to ensure that the agents\u2019 local objectives (private goals) will be achieved by their plans and so the emphasis is put on distributed execution, plan synchronization and collaborative activity at runtime planning (Durfee and Lesser, 1991; Tambe, 1997; Kaminka, Pynadath and Tambe, 2002). All in all, these techniques use planning as a means to controlling and coordinating agents rather than building a competent and joint plan, and so they are very appropriate for the design of real-time systems (Micacchi and Cohen, 2008).\nIn planning-oriented approaches dealing with contexts in which agents are assumed to be cooperative, the objective is to study how planning can be extended into a distributed environment or, more particularly, on the construction of a competent plan by several planning entities. There exist different approaches to address this objective, varying according to the typology of the planning problem to solve. In particular, the adoption of one or another strategy depends on the coordination needs of the problem, i.e., to which extent agents are able to make their own plans without affecting what the other agents are planning to do. Thus, when agents are assumed to be relatively independent, they carry out their planning activities individually and exchange information about their local plans, which they iteratively refine and revise until they fit together in order to ensure that the resulting plan will jointly execute in a coherent and efficient manner (desJardins et al., 1999). This has been the predominant approach in cooperative MAP, existing a large body of research on post-planning coordination, i.e., solving inconsistencies among local plans that have been constructed separately. The well-known Partial Global Planning (PGP) framework (Durfee and Lesser, 1991) is one of the first techniques that allows agents to communicate and merge their local plans. Ever since, many works on plan merging methods for building a joint plan given the local plans of each participating agent have arisen (see section 2 for a detailed description).\nThe application of MAP to loosely-coupled multi-agent tasks, in which agents have little interaction to each other, is still an active area of research. Some recent works in this line, where agents are engaged in some cooperative behaviour, have emerged lately. These works follow a common approach that consists of coordinating the local solutions developed by the agents. For instance, the work in (Kvarnstr\u00f6m, 2011) considers that agents have sequential threads of execution and interactions only occur when distributing sub-plans to individual agents\nfor plan execution. This approximation follows a single-agent planning and distributed coordination. The work in (Brafman and Domshlak, 2008) applies individual planning and coordinates the local solutions through the resolution of a Constraint Satisfaction Problem (CSP). In an extension of this latter work, authors use a distributed CSP to solve inconsistencies among agents\u2019 plans (Nissim, Brafman and Domshlak, 2010).\nMost of the aforementioned approaches turn out to be inefficient at the time of solving strongly-related problems in which the number of coordination points among agents is large (Nissim et al., 2010). To deal with these problems, other MAP models use a unified approach in which planning and coordination of activities are integrated rather than being treated as independent processes (Jonsson and Rovatsos, 2011; Belesiotis, Rovatsos and Rahwan, 2010). However, these approaches do not achieve high performance in loosely-coupled problems because the reasoning procedures rely very strongly on a high degree of interdependency between the agents\u2019 actions.\nThe problem of building a competent joint plan among several planning entities has been generally dismissed by the MAS community, more concerned with the development of coordination mechanisms for agents, and ignored by the planning community, which has traditionally resorted to efficient single-agent algorithms to solve planning problems. MAP is not only about a divide-andconquer strategy to tackle large planning problems, it is also about the development of techniques for planning entities that are geographically or spatially distributed. While one might expect the number of coordination points in inherently distributed problems not to be very large, another issue that comes up is the distribution of information among agents. In frameworks like those presented in (Brenner and Nebel, 2009; Belesiotis et al., 2010) agents communicate all the available information and build complete knowledge bases, i.e., agents have complete information on the MAP task. However, in large-size problems with heterogeneous agents, building complete knowledge bases is not viable. Besides efficiency issues, agents may be unable to manage the information handled by other agents as they may have different knowledge and abilities.\nIn this paper, we present a novel approach to cooperative MAP that allows to efficiently solve problems with any level of interaction among agents. Unlike other techniques, our MAP system is capable of solving from the most loosely-coupled problems to the most strongly-related problems. The key point to address this aspect is to use a refinement planning approach (Kambhampati, 1997) that allows agents to interleave planning and coordination, or more specifically, to coordinate their plans during planning. We also allow heterogeneous agents to work under incomplete information, sharing only the critical information that affects other agents and maintaining a distributed vision of the MAP task. This issue, which has been ignored in almost all of the MAP approaches, is of key importance to efficiently handle inherently distributed problems. Last but not least, our MAP approach is entirely based on the use of single-agent planning technology adapted to a multi-agent context. More precisely, agents follow the Partial-Order Planning paradigm (Nguyen and Kambhampati, 2001; Younes and Simmons, 2003).\nAs well as introducing the MAP architecture and a theoretical model for multi-agent planning, our proposal is supported with the implementation of a fully-operative MAP system. The empirical evaluation of the system demonstrates this novel approach to be effective when dealing with both strongly-\nrelated problems and loosely-coupled problems in which agents manage incomplete information.\nThis paper is organized as follows: section 2 summarizes some background on the main topics related to this work and reviews the most recent literature on MAP; section 3 introduces the example MAP scenario we will use to illustrate the different aspects of our framework; section 4 outlines our MAP architecture; section 5 presents the theoretical planning model upon which our system is based; section 6 outlines the planning language used to model MAP tasks; section 7 provides an overview of the MAP algorithm followed by the agents; section 8 describes the first stage of our MAP algorithm, the initial information exchange; section 9 outlines second stage of the MAP algorithm, the refinement planning and coordination protocol; section 10 presents the experimental results, and finally, section 11 concludes and summarizes our future lines of research."}, {"heading": "2. Background", "text": "Our MAP model builds upon several single-agent planning techniques. This section provides a review on the principal single-agent planning concepts used in our MAP approach as well as the most relevant and recent approaches to cooperative MAP. We also outline the most relevant works on MAP architectures and frameworks and we conclude by summarizing the main contributions and novelties of our approach."}, {"heading": "2.1. Single-agent planning", "text": "Single-agent planning is regarded as a search process by which a single entity synthesizes a set of actions (plan) to reach a set of objectives from an initial situation (Weld, 1999). Over the last years, single-agent planning has experienced great advances, specifically in the construction of domain-independent heuristics. Nowadays, it is possible to find a great variety of planning systems. The most recent planners combine different techniques in order to increase the algorithms efficiency: landmarks (Richter and Westphal, 2010), domain transition graphs (Helmert, 2006), forward-chaining partial-order planning (Coles, Coles, Fox and Long, 2010), probes (Lipovetzky and Geffner, 2011) or divide-and-conquer strategies (Dr\u00e9o, Sav\u00e9ant, Schoenauer and Vidal, 2011), among others.\nThe work in (Blum and Furst, 1997) introduced the concept of Relaxed Planning Graph, which has proven to be one of the most effective constructs to devise heuristics in state-space planning (Hoffmann and Nebel, 2001). This technique has been integrated in many single-agent planning frameworks and has also been extended to a distributed context (Zhang, Nguyen and Kowalczyk, 2007).\nWhile state-space planners such as Fast Forward (Hoffmann and Nebel, 2001) are still a relevant research topic, plan-space planning has been replaced by other more efficient techniques. However, plan-space planning has recently seen a revival since its flexibility makes it specially suitable for distributed environments.\nAmong plan-space search algorithms, the Partial-Order Planning (POP) approach (Penberthy and Weld, 1992; Younes and Simmons, 2003) is particularly relevant. POP performs a plan-based, backward search process, refining partial plans through the addition of actions, causal links and ordering constraints. POP is based on the least commitment strategy (Weld, 1994), which defers planning\ndecisions during the search process and introduces partial-order relations among actions rather than enforcing a concrete order among them. The particular nature of the POP paradigm (absence of states, backward search) makes it difficult to devise competitive heuristics to guide the search process. Although some recent works reformulate the basic algorithm to improve its performance (Coles et al., 2010), POP has been discontinued by the planning community in favor of other approaches. Nevertheless, it is still used in temporal planning and MAP environments as it is a flexible paradigm to handle concurrency (Boutilier and Brafman, 2001)."}, {"heading": "2.2. Cooperative Multi-Agent Planning", "text": "MAP extends the single-agent planning problem by distributing the planning task among several entities which work together to devise a competent joint plan that meets the problem goals. This generalization entails some differences to the more restrictive single-agent planning approach. MAP can be viewed as the problem of coordinating agents in a shared environment where information is distributed (desJardins et al., 1999). This definition emphasizes two aspects of MAP that are not present in single-agent planning: the coordination of the planning activities and the distribution of the information among agents.\nIn general, solving a cooperative MAP task involves the following stages (Durfee, 2001): 1) global goal refinement, 2) task allocation, 3) coordination before planning, 4) individual planning, 5) coordination after planning, and 6) plan execution. Some of the previous stages can be avoided or combined. For instance, some works do not distribute the goals explicitly (avoiding stage 2) (Belesiotis et al., 2010; Brenner and Nebel, 2009), while others apply only coordination after planning (avoiding stage 3) (Van Der Krogt and De Weerdt, 2005; Cox, Durfee and Bartold, 2005).\nMAP problems can be classified according to their coupling level, a measure of the number of interactions or coordination points among agents that will arise during the task resolution (Brafman and Domshlak, 2008). In loosely-coupled problems, each problem goal problem is likely to be solved by a single agent, while goals in strongly-related problems tend to require the cooperation of several agents. The number of coordination points in a MAP problem determines which approaches are more suitable to solve it efficiently.\nA wide range of MAP approaches put the emphasis on coordination after individual planning (coordination is performed at stage 5 of the MAP scheme described above). This way, these frameworks perform the planning and coordination stages independently and separately, combining or merging solutions into a global joint plan (Durfee, 2001; de Weerdt and Clement, 2009; Tonino, Bos, de Weerdt and Witteveen, 2002; Kaminka et al., 2002).\nDifferent coordination techniques have been proposed for merging and gathering several individual plans into a single joint plan. The Partial Global Planning framework (Durfee and Lesser, 1991) and its extension, the Generalized Partial Global Planning approach (Decker and Lesser, 1992), allow agents to communicate their local plans to the rest of agents and then they merge this information into their own partial global plan in order to improve it. This iterative process goes on until the agents\u2019 local plans fit together. The work in (Tonino et al., 2002) proposes a post-planning coordination approach based on the iterative revision of the agents\u2019 local plans. Agents in this model cooperate\nby mutually adapting their individual plans, with a focus on maximizing their common or individual profit. (Nissim et al., 2010) introduces a cooperative MAP approach for loosely-coupled systems in which agents carry out planning individually through a state-based planner (Hoffmann and Nebel, 2001; Coles, Fox, Long and Smith, 2008). The resulting local plans are then coordinated by solving a distributed Constraint Satisfaction Problem. The approach in (Van Der Krogt and De Weerdt, 2005) solves inconsistencies among the local plans devised by self-interested agents through plan repair. Other proposals deal with insincere agents by combining planning, coordination, and execution (Ephrati and Rosenschein, 1996) or consider the communication needs that arise when plans are being executed (Tang, Norman and Parsons, 2010).\nThe aforementioned plan merging methods follow a common approach: agents build plans individually while a subsequent independent process is used to coordinate these plans. This approach is suitable for solving loosely-coupled problems efficiently as the agents\u2019 local solutions in these problems present few interdependencies with each other. Thus, plan merging through post-planning coordination is an appropriate method to tackle problems in which agents can solve the different problem goals independently and the majority of the environment resources are not shared.\nHowever, plan merging methods present several limitations. On the one hand, goals must be a priori allocated to each agent or at least implicitly distributed among the planning entities, as agents perform their planning activity in an isolated manner. Because of this, methods based on plan merging lose flexibility against other MAP proposals. On the other hand, the previous merging approaches have proven to be inefficient when solving strongly-related problems in which most of the resources are shared and most of the goals require cooperation among agents (Nissim et al., 2010). The individual planning combined with a post-planning coordination strategy is not adequate to solve these strongly-related problems, since merging may introduce exponentially many ordering constraints in problems which require a coordination effort.\nAnother research trend on cooperative MAP stresses the importance of combining and integrating planning and coordination activities, i.e., apply coordination during planning. Hence, this trend can be seen as an extension of single-agent planning to MAP, providing a unified vision of MAP. Proposals in this line focus on the cooperative incremental construction of a joint plan, allowing agents to perform their planning activity over a centralized plan representation. This is a more suitable approach than the plan merging techniques for tackling stronglyrelated MAP problems with a large number of coordination points, as agents work over a centralized plan representation and planning and coordination of activities are carried out in an integrated way.\nThe proposal in (desJardins et al., 1999) applies the continual planning approach, which interleaves planning and execution and coordinates agents by synchronizing them at execution time (Brenner and Nebel, 2009). The approach in (Jonsson and Rovatsos, 2011) introduces the best-response planning algorithm, which iteratively improves the quality of the agents\u2019 plans through single-agent planning technology. Finally, the works in (Belesiotis et al., 2010; Pajares and Onaindia, 2012) solve inconsistencies among agents\u2019 plans through a coordination protocol based on iterated dialogues. Agents discuss and argument about the different plan proposals until the agents\u2019 viewpoints are aligned and an agreement is reached.\nThe integrated planning and coordination approach followed by the afore-\nmentioned MAP models copes with a wider range of MAP problems than the plan merging method, which can only deal with simpler, loosely-coupled problems. In addition, the continual revision and coordination of the agents\u2019 plans provides better results in terms of plan quality. However, integrating planning and coordination entails higher communication costs for loosely-coupled problems than using plan merging, as coordination has to be performed throughout the planning process, thus introducing an overhead. Hence, the simpler plan merging approach is far more effective for small-size and non-complex planning tasks.\nResearch on cooperative MAP, traditionally carried out by the planning community, has generally overlooked the management of incomplete information, an active research topic, though, within the MAS community. Planning with incomplete information has several different meanings: that certain facts of the initial state are not known, that operators can have random or nondeterministic effects, or that the plans built contain sensing operations and are branching (Haslum and Jonsson, 1999). In our case, we interpret incomplete information as agents not knowing the initial state completely and being total or partially unaware of the information managed by other agents.\nThe issue of incomplete information has been treated from two different perspectives: the probabilistic way, with the development of formal models such as Dec-POMDPs (Decentralized Partial Observable Markov Decision Processes) for coordination among multiple agents in contexts with partial observability (Wu, Zilberstein and Chen, 2011; Kumar, Zilberstein and Toussaint, 2011); and the epistemological way, which assumes that agents have beliefs about the state of the world and beliefs over the other agents\u2019 knowledge (Kraus, 1997; Doshi, 2007). This latter approach has been widely used in games of incomplete information (Gmytrasiewicz and Doshi, 2005). Both perspectives define agents as having an imprecise or uncertain view of the world and of the other agents\u2019 information but, to the best of our knowledge, there are not proposals to deal with ignorance, i.e., local views of agents that reflect agent\u2019s unawareness over the information of the rest of agents. This introduces a complexity factor in the planning process as agents can only plan on the basis of their information, being ignorant on the planning decisions of other agents. It is important to note, though, that the information unknown to one agent does not have a direct impact on the agents\u2019 choices because its actions are not involved with the unknown piece of information. However, this absence of information may have an indirect impact in the overall planning process and quality of the plan."}, {"heading": "2.3. Architectures and frameworks for MAP", "text": "The design of architectures and frameworks constitutes another active research field in MAP. Over the last years, some relevant works in MAP frameworks have been published. The work in (Wilkins and Myers, 1998) presents a complete MAP architecture for large-scale problem solving, which organizes agents into planning cells committed to a particular planning process. The TAEMS domainindependent coordination framework (Lesser, Decker, Wagner, Carver, Garvey, Horling, Neiman, Podorozhny, Prasad, Raja et al., 2004) provides agents with planning capabilities, and applies the GPGP approach to coordinate them.\nOther MAP architectures are based on general-purpose MAS platforms, rather than being designed from the ground up. MAS platforms, such as Magentix2\n(Fogu\u00e9s, Alberola, Such, Espinosa and Garcia-Fornes, 2010; Argente, Botti, Carrascosa, Giret, Julian and Rebollo, 2011) or JADE (Bellifemine, Poggi and Rimassa, 2001), provide the sets of services, conventions and knowledge required by agents to interact with each other. For instance, the domain-independent multiagent system infrastructure RETSINA (Sycara and Pannu, 1998) introduced a planning component (Paolucci, Shehory, Sycara, Kalp and Pannu, 2000). Once integrated into the agents\u2019 internal architecture, this component provides them with planning capabilities.\nSimilarly, our MAP approach builds upon the Magentix2 MAS platform, which provides the communication services required by the agents. From this base, we introduce the additional components to provide the agents with planning capabilities and allow them to tackle MAP tasks."}, {"heading": "2.4. Contributions of our model", "text": "Our novel approach to cooperative MAP can be classified into the research trend that integrates planning and coordination. The MAP system achieves two main objectives: 1) it solves complex strongly-related problems as well as looselycoupled problems without losing generality; and 2) it allows heterogeneous agents to work under incomplete information, sharing only the critical information that affects other agents and being partially unaware of the other agents\u2019 information on the MAP task.\nOur MAP approach focuses on a novel method that combines single-agent planning technologies and a refinement-based methodology. More precisely, we combine a distributed refinement planning procedure (Kambhampati, 1997) and an individual Partial-Order Planning (POP) (Nguyen and Kambhampati, 2001; Younes and Simmons, 2003). Agents incrementally build local refinements to a certain base plan through their local POPs, and coordinate these partial solutions through the refinement planning process. Empirical evaluation proves this method to perform effectively for both strongly-related and loosely-coupled problems.\nAnother key feature of our method is the ability to work under incomplete information. Unlike many MAP proposals, agents in our approach do not require to build complete knowledge bases, but they can be partially unaware of the information on the initial state and the knowledge and abilities of the rest of agents. Our PDDL3.1 -based MAP specification language (Kovacs, 2011) defines this partial visibility of the agents, allowing to specify which information can be shared with other agents for cooperation purposes. Agents exchange the shareable information with other agents through the construction of a distributed Relaxed Planning Graph (Zhang et al., 2007) and perform planning while being partially unaware of the other agents\u2019 knowledge. This way, our proposal stresses the importance of privacy in a MAP context, as agents share only the essential information that affects other agents and are partially unaware of the information held by the rest of planning entities."}, {"heading": "3. Motivating example", "text": "This section introduces the example MAP scenario we use in the following to illustrate the concepts presented throughout this paper. The example of appli-\ncation, depicted in Figure 1, describes a transportation and storage scenario in which two agents (Ag1 and Ag2) take the role of transport agencies and a third agent (Ag3) manages a storage facility. Transport agents deliver packages through a network of cities. In turn, the warehouse agent is in charge of storing and delivering packages to the trucks. Packages can be either raw materials or final products. Agents in the MAP task are entrusted with two different goals: deliver the final product p1 to city cA and the raw material p3 to city cE.\nThis scenario includes bidirectional links among cities that allow transport agents to move trucks from one city to another. Transport agents Ag1 and Ag2 can perform three different actions: they can load and unload packages in the trucks and they can move the trucks between cities in their working areas. Ag1 and Ag2 can only move trucks within the cities included in their working areas, depicted in Figure 1 as two different circles. This way, transport agents have to interact and cooperate in order to deliver packages to a different working area.\nA possible plan to solve the scenario depicted in Figure 1 involves Ag1 loading the raw material p3 in the truck t1. Then Ag1 would handle t1 to Ag2 in cB or cD, both included in the working areas of Ag1 and Ag2, and Ag2 would take care of transporting the product to cE. This leads to a key aspect of our model: in order to promote cooperation, Ag1 should share with Ag2 the information on the position of t1 once it reaches cB or cD. As we will discuss in the following section, agents will share the information that is relevant for other agents in order to successfully cooperate.\nThe warehouse agent Ag3 is in charge of interacting with the trucks to store raw materials and deliver final products. The warehouse has a table in which packages can be stacked and unstacked. Packages are swapped in the city in which the warehouse is placed, the exchange city. As seen in Figure 1, cF is the exchange city used by Ag2 and Ag3 to swap packages.\nAg2 and Ag3 will also share information on the packages they leave in the exchange city, which will be necessary for them to interact. For example, to accomplish the first goal of the task (transporting the final product p1 to cA), Ag3 will deliver p1 to the exchange city cF, informing Ag2 about the position of the package. Then, Ag2 will load p1 in the truck t1 and will drive t1 to cB or cD. Finally, Ag1 will perform the final transportation, delivering p1 to city cA."}, {"heading": "4. Multi-Agent Planning architecture", "text": "The architecture of our MAP system is depicted in Figure 2. The MAP architecture basically consists of a set of agents endowed with planning capabilities and an underlying communication infrastructure that allows them to interact with each other.\nAll the agents share the same internal structure, and the internal planning algorithm followed by each agent is a POP procedure, so they all develop the same rationale. However, since agents handle different information and knowledge, that is, incomplete information on the MAP task and different planning abilities, our MAP system features heterogeneous agents. In the example of application presented in section 3, two agents play the role of transport agencies and a third agent manages a storage facility. The first two agents will likely perform similar actions like driving vehicles from one location to another, which will be different from the planning abilities of the third agent devoted to stack and arrange packages in a warehouse. Additionally, agents will have a different view of the planning task accordingly to their abilities and initial knowledge; thus, the first two agents will have information about the trucks and roads connecting the different locations, and the third agent will manage the information about the packages and the hoists in the warehouse.\nTogether with the planning agents, the MAP architecture provides a set of components that allow the user to interact with the platform. The main components of the MAP architecture are:\n\u2013 Graphical User Interface (GUI): This component allows the user to interact with the MAP system. The user requests the resolution of a MAP task by providing, for each agent involved in the task, two input files encoded through our MAP specification language, the domain and problem file (see section 6). The first file defines the typology and the planning capabilities of the agent,\nwhile the second file defines the concrete aspects of the task it has to solve. Once a solution is found, it is displayed to the user through the GUI.\n\u2013 MAP manager: This component interacts with the GUI by collecting the user\u2019s request for a plan and assigning the MAP task to a subset of agents that are available, i.e., they are not solving any particular planning task at the moment. Agents are fully reconfigurable and can be reused when they become available again by assigning a new MAP task to them.\n\u2013 Pool of planning agents: The architecture includes a pool of planning agents which all share the same internal structure shown in Figure 3. Agents are configurable through the domain and problem files provided by the user, which define the agents\u2019 knowledge and abilities. Once a subset of the agents in the pool receive a planning task, they start working together to find a solution plan.\n\u2013 Communication infrastructure: Agents interact with each other through a communication infrastructure, which allows them to exchange messages by following the FIPA communication protocols (Kone, Shimazu and Nakajima, 2000). The developed MAP system uses the Magentix2 MAS platform (Fogu\u00e9s et al., 2010) as its communication infrastructure.\nThe internal structure of the planning agents includes several modules to accomplish the requirements of our refinement planning approach. Through these modules, agents make plan refinements over a base plan, select the best alternative from a set of refinement plans and communicate with each other (see Figure 3). Although agents have the same internal structure, they have different planning abilities and visibility over the MAP task as defined in the domain and problem file provided by the user. The internal modules of a planning agent are:\n\u2013 Communication module: Through this module, each planning agent interacts with the rest of agents via the communication infrastructure. The communication module receives messages from the rest of agents and transmits the received information to the rest of internal modules of the planning agent.\nWhen the agent wants to communicate with other agents, this module is in charge of sending the messages through the communication infrastructure (the Magentix2 MAS platform). Hence, this module acts as an interface between the planning agent and the rest of agents in the MAP task.\n\u2013 Planning module: This module is in charge of performing the actual planning search. It includes an embedded Partial-Order Planner which has been modified to be able to start the planning process from an incomplete plan and return valid refinements instead of complete solution plans. The planning module receives the current base plan from the communication module and returns a set of valid refinements over the base plan.\n\u2013 Reasoning module: Agents coordination consists in evaluating the refinement plans and choosing the most promising one as the next base plan (see section 7). The reasoning module of each agent receives the refinement proposals of the agents and evaluates them according to the view of the MAP task of the respective agent. Hence, this module provides agents with facilities to perform the coordination process, allowing agents to reason about the different proposals and vote for the next base plan. In conclusion, the internal design of planning agents provides them with the basic capabilities required to solve MAP tasks. Agents use their internal components to interact with each other through the communication infrastructure, reason about plans and proceed with the next plan refinement."}, {"heading": "5. Planning model", "text": "This section presents the MAP model upon which our planning architecture is based. It also describes the procedure followed by the agents for building and exchanging plans among them.\nThe following subsections describe and formalize the main components of a MAP task and outline the Partial-Order Planning concepts used in the MAP algorithm (see section 7). In order to illustrate the formal definitions introduced in this section, we provide simple examples based on the transportation MAP task presented in section 3. Also, for the sake of clarification of some definitions, we point out the reader to the figures of plans showed in section 9."}, {"heading": "5.1. Formalization of a MAP task", "text": "Definition 1. (MAP task) A MAP task is a tuple T = \u3008AG,O,V,A, I,G,\u3009. AG = {1, . . . , n} is a finite non-empty set of planning agents. O is a finite set of objects that model the elements of the planning domain over which the planning actions can act. V is a finite set of state variables that model the states of the world. Each state variable v \u2208 V is mapped to a finite domain of mutually exclusive values Dv. Each value in a state variables\u2019s domain corresponds to an object of the planning domain, i.e. \u2200v \u2208 V, Dv \u2286 O. When a value is assigned to a state variable, the pair variable-value acts as a ground atom in propositional planning. A is the set of deterministic actions of the agents. I is the set of values assigned to the state variables in V and represents the initial state of the MAP task T . G is the set of goals of the MAP task that agents have to achieve; G represents the values that the state variables are expected to take in the final state.\nInformation that agents have on the states of the world (problem states) is modeled through a set of ground atoms or fluents. This includes the initial state, I, and the goal state, G. As opposite to STRIPS-like models (Fikes and Nilsson, 1971), which apply negation by failure (only positive fluents are represented, the absence of a fluent implies its negation), we allow to explicitly represent both true and false information. Thus, our model adopts the open world assumption, considering that the information which is not explicitly stored in the internal model of agents is unknown to them. Again, this also refers to the information in the initial state, I, and the goals, G. Definition 2. (Fluent) A ground atom or fluent of the problem is a tuple of the form \u3008v, d\u3009, where v \u2208 V and d \u2208 Dv. A negative fluent is of the form \u3008v,\u00acd\u3009. A positive fluent \u3008v, d\u3009 indicates that the variable v takes the value d, while a negative fluent \u3008v,\u00acd\u3009 indicates that the variable v does not take the value d.\nAs stated in Definition 2, a fluent relates a variable with one of the values in its domain. For instance, let (at t1) be a variable that refers to the position of a truck object t1 in the example introduced in section 3. Possible values for this variable are the cities cA, cB, cC, cD, cE and cF. Then, a positive fluent \u3008at t1, cA\u3009 indicates that t1 is in cA while a negative fluent \u3008at t1, \u00accA\u3009 indicates that t1 is not in cA.\nIn our model, agents are heterogeneous as they may have different knowledge and planning capabilities. In addition, they may have incomplete information on the MAP task as this can be distributed across agents. In this case, agents must cooperate with each other to solve the MAP task. Even though information is distributed across agents, there must be a subset of state variables shareable between agents in order to exchange the values of such variables and successfully communicate between each other. To denote the actions, goals, etc. of an agent i \u2208 AG we will use the superscript notation xi for any such aspect x.\nFrom the set of variables, V, of the MAP task, we distinguish Vi as the set of variables managed by agent i, which includes the private variables, only known to agent i, and the public variables, shared with other agents. Thus, V = {Vi}ni=1. Div \u2286 Dv is the set of values of a variable v \u2208 Vi that are visible to agent i. The information of the initial state of the MAP task, I, is modeled through a set of positive and negative fluents. This information is distributed among agents under the assumption that agents\u2019 partial knowledge about I is consistent, i.e. there is not contradictory information among agents. Hence, I can be defined as I = \u22c3 \u2200i\u2208AG Ii. It is possible to define MAP tasks in which all the agents have a complete view of the initial state I, i.e. \u2200i \u2208 AG, Ii = I. For example, Ag1 and Ag2 are two transport agents in the MAP scenario of section 3. Initially, Ag1 knows that the truck t1 is in city cA so the fluent \u3008at t1, cA\u3009 is part of IAg1. On the contrary, Ag2 does not know where t1 is initially located, but it knows that the truck is not in city cB. Hence, the fluent \u3008at t1, \u00accB\u3009 belongs to IAg2, the initial state of Ag2.\nEach agent i \u2208 AG is associated with a set, Ai, of possible actions such that the set of actions of a planning task is defined as A = \u22c3 \u2200i\u2208AG Ai. An action \u03b1 is said to be public if it is shared by two or more agents, i.e. \u03b1 \u2208 Ai \u2227 \u03b1 \u2208 Aj , i 6= j. \u03b1 \u2208 Ai is private to agent i iff \u03b1 6\u2208 Aj ,\u2200j 6= i. An action \u03b1 \u2208 Ai denotes that agent i has the capability expressed in \u03b1. If \u03b1 forms part of the final plan then agent i is also responsible of executing \u03b1.\nDefinition 3. (Planning rule or action) A planning rule or action \u03b1 \u2208 A is a tuple \u3008PRE(\u03b1), EFF (\u03b1)\u3009. PRE(\u03b1) = {p1, . . . , pn} is a set of fluents that represents the preconditions of \u03b1, while EFF (\u03b1) = {e1, . . . , em} is a set of operations of the form (v = d) or (v 6= d), v \u2208 V, d \u2208 Dv, that represent the consequences of executing \u03b1.\nAn action \u03b1 may belong to different agents, i.e. \u03b1 \u2208 Ai and \u03b1 \u2208 Aj , i 6= j. Executing an action \u03b1 in a world state S gives rise to a new world state S\u2032 generated as the result of applying EFF (\u03b1) over S. Particularly: \u2013 An operation (v = d) \u2208 EFF (\u03b1) implies the addition of a fluent \u3008v, d\u3009 and a set of fluents \u3008v,\u00acd\u2032\u3009, \u2200d\u2032 \u2208 Dv | d\u2032 6= d, to the world state S\u2032. If \u3008v, d\u2032\u3009 \u2208 S or \u3008v,\u00acd\u3009 \u2208 S, d\u2032 6= d, the operation (v = d) also implies that the fluents \u3008v, d\u2032\u3009 or \u3008v,\u00acd\u3009 will not be present in S\u2032. For example, suppose that agent Ag1 knows that the truck t1 can be placed at the cities cA, cB, cC and cD, i.e., DAg1at t1 = {cA, cB, cC, cD}. If Ag1 knows a positive fluent \u3008at t1, cA\u3009, it also knows the negative fluents \u3008at t1, \u00accB\u3009, \u3008at t1, \u00accC\u3009 and \u3008at t1, \u00accD\u3009.\n\u2013 An operation (v 6= d) \u2208 EFF (\u03b1) implies the addition of a fluent \u3008v,\u00acd\u3009 to the world state S\u2032. If \u3008v, d\u3009 \u2208 S, the operation (v 6= d) also entails that the fluent \u3008v, d\u3009 will not be present in S\u2032. Note that the only existence of a fluent \u3008v,\u00acd\u3009 in a state indicates that the value of the variable v is not known in such a state and, consequently, the rest of values in Dv, except for d, are unknown values. For example, if the fluent \u3008at t1, \u00accB\u3009 is in the world state of agent Ag2, then the agent only knows that the truck t1 is not in city cB but the agent is not aware of the actual position of the truck. Thus, whether t1 is in cA, cC or cD is unknown to Ag2. The set of preconditions of an action \u03b1, PRE(\u03b1), defines the fluents that must hold in a world state S for that \u03b1 is applicable in this state. A positive precondition of the form \u3008v, d\u3009 indicates that the fluent \u3008v, d\u3009 must hold in S, while a negative precondition \u3008v,\u00acd\u3009 indicates that the fluent \u3008v,\u00acd\u3009 must hold in S. Note that the existence of a positive fluent \u3008v, d\u3009 also implies the existence of a negative fluent \u3008v,\u00acd\u2032\u3009 for the rest of values in the variable\u2019s domain, i.e. (\u2203\u3008v, d\u3009 \u2208 S)\u21d2 (\u2200d\u2032 \u2208 Dv, d\u2032 6= d, \u2203\u3008v,\u00acd\u2032\u3009 \u2208 S).\nAdditionally, agents use a utility function F to evaluate the quality of the plan proposals. For each agent i, F assigns a cost, cost(viewi(\u03a0)) \u2208 R+0 , to each plan proposal \u03a0 according to the view that agent i has of that plan, viewi(\u03a0). Finally, the private goals of an agent i, PGi, are fluents that agent i is interested in attaining. Private goals are encoded as soft constraints (Gerevini and Long, 2006), as it is not mandatory that agents achieve them."}, {"heading": "5.2. Concepts on Partial-Order Planning", "text": "Our MAP model can be regarded as a multi-agent refinement planning framework, a general method based on the refinement of the set of all possible plans (Kambhampati, 1997). An agent proposes a plan \u03a0 that typically enforces some of the goals that have not yet been supported (see definition 5); then, the rest of agents collaborate on the refinement of \u03a0 by solving some of these pending goals in \u03a0. This way, agents cooperatively solve the MAP task by consecutively refining an initially empty plan.\nIn this context, Partial-Order Planning (POP) (Barrett and Weld, 1994)\narises as a suitable approach to address refinement planning, since it is focused on solving the pending goals progressively. Consequently, agents in our MAP approach plan concurrent actions through the adoption of the POP paradigm. In the following, we provide some basic definitions concerning single-agent POP and its adaptation to a MAP context."}, {"heading": "5.2.1. Single-agent Partial-Order Planning", "text": "Definition 4. (Partial plan) A partial plan is a tuple \u03a0 = \u3008\u2206,OR, CL\u3009. \u2206 \u2286 A is the set of actions in \u03a0. OR is a set of ordering constraints (\u227a) on \u2206. CL is a set of causal links over \u2206. A causal link is of the form \u03b1 \u3008v,d\u3009\u2192 \u03b2 or \u03b1\n\u3008v,\u00acd\u3009\u2192 \u03b2, where \u03b1 \u2208 A and \u03b2 \u2208 A are actions in \u2206. \u03b1 \u3008v,d\u3009\u2192 \u03b2 indicates that there is an operation (v = d) such that v \u2208 V, d \u2208 Dv, (v = d) \u2208 EFF (\u03b1) and a fluent \u3008v, d\u3009 \u2208 PRE(\u03b2). \u03b1 \u3008v,\u00acd\u3009\u2192 \u03b2 indicates that there is a fluent \u3008v,\u00acd\u3009 such that v \u2208 V, d \u2208 Dv, \u3008v,\u00acd\u3009 \u2208 PRE(\u03b2) supported by an operation (v 6= d) \u2208 EFF (\u03b1) or an operation (v = d\u2032) \u2208 EFF (\u03b1), d\u2032 \u2208 Dv, d\u2032 6= d.\nThis definition of partial plan represents the mapping of a plan into a directed acyclic graph, where \u2206 represents the nodes of the graph (actions) and OR and CL are sets of directed edges representing the precedences and causal links among these actions, respectively.\nAn empty partial plan is defined as \u03a00 = \u3008\u22060, OR0, CL0\u3009, where \u22060 contains \u03b10 and \u03b1f , the initial and final action of the plan, respectively. \u03b10 and \u03b1f are fictitious actions that do not belong to the action set of any particular agent. OR0 contains the constraint \u03b10 \u227a \u03b1f and CL0 is an empty set. This way, a plan \u03a0 for any given MAP task T will always contain the two fictitious actions such that PRE(\u03b10) = \u2205 and EFF (\u03b10) = I, PRE(\u03b1f ) = G, and EFF (\u03b1f ) = \u2205; i.e. \u03b10 represents the initial situation of the MAP task T , and \u03b1f represents the global goals of T .\nAssuming that G 6= \u2205, an empty plan is said to be incomplete if the preconditions of \u03b1f are not yet supported through a causal link. The POP process is aimed at introducing causal links to support these preconditions, also called open goals.\nDefinition 5. (Open goal) An open goal in a partial plan \u03a0 = \u3008\u2206, OR, CL\u3009 is a fluent og of the form \u3008v, d\u3009 or \u3008v,\u00acd\u3009, such that v \u2208 V, d \u2208 Dv, og \u2208 PRE(\u03b2), \u03b2 \u2208 \u2206, and @\u03b1 \u2208 \u2206/\u03b1 og\u2192 \u03b2 \u2208 CL, i.e., an open goal og is a precondition of ab action \u03b2 in the plan \u03a0 that is not yet supported by a causal link \u03b1 og\u2192 \u03b2 \u2208 CL. openGoals(\u03a0) denotes the set of open goals in \u03a0. A plan is incomplete if it has open goals. Otherwise, we say it is a complete plan.\nAs the POP search progresses, the causal links in a partial plan may become unsafe as a result of the introduction of a new action which is not ordered with respect to the causal link. These conflicts are called threats.\nDefinition 6. (Threat) A threat in a partial plan \u03a0 = \u3008\u2206,OR, CL\u3009 represents a conflict between an action of the plan and a causal link. An action \u03b3 causes a threat over a causal link \u03b1 \u3008v,d\u3009\u2192 \u03b2 if ((v = d\u2032) \u2208 EFF (\u03b3) \u2228 (v 6= d) \u2208 EFF (\u03b3)), where v \u2208 V, d \u2208 Dv, d\u2032 \u2208 Dv and d 6= d\u2032, and there is neither an ordering constraint \u03b3 \u227a \u03b1 nor \u03b2 \u227a \u03b3. The action \u03b3 will cause a threat over a causal link\nof the form \u03b1 \u3008v,\u00acd\u3009\u2192 \u03b2 if (v = d) \u2208 EFF (\u03b3), where v \u2208 V, d \u2208 Dv, and there is neither an ordering \u03b3 \u227a \u03b1 nor \u03b2 \u227a \u03b3. Threats(\u03a0) denotes the set of threats in \u03a0.\nA threat t \u2208 Threats(\u03a0) can be solved by promoting or demoting the threatening action \u03b3 with respect to the causal link \u03b1 \u3008v,d\u3009\u2192 \u03b2 or \u03b1 \u3008v,\u00acd\u3009\u2192 \u03b2, i.e. introducing an ordering constraint \u03b3 \u227a \u03b1 or \u03b2 \u227a \u03b3. Threats and open goals are referred to as the flaws of a partial-order plan. The POP process is guided by solving the pending flaws of an initially empty partial plan.\nFigure 4 in section 9 depicts a refinement plan for the example introduced in section 3. This refinement plan includes a causal link Init \u3008at t1, cA\u3009\u2192 load t1 p3 cA. Suppose that a new action drive t1 cA cB, that causes the truck t1 to move from cA to cB, is added to the refinement plan and that this new action is not ordered with respect to load t1 p3 cA. In this case, (at t1 = cB) \u2208 EFF (drive t1 cA cB). This effect causes a threat over the previous causal link, as it introduces a fluent \u3008at t1, cB\u3009 that affects the value of the variable (at t1). This threat can be solved by introducing an ordering constraint load t1 p3 cA \u227a drive t1 cA cB, i.e., demoting the threatening action drive t1 cA cB with respect to the causal link."}, {"heading": "5.2.2. Multi-agent Partial-Order Planning", "text": "Agents in our MAP model cooperate on the refinement of a base plan \u03a0 by proposing refinement steps that solve some open goals in \u03a0. This way, agents cooperatively solve the MAP task by consecutively refining \u03a0, the initially empty base plan.\nDefinition 7. (Refinement step) A refinement step \u03a0i devised by an agent i over a base plan \u03a0g, where g \u2208 openGoals(\u03a0g), is a triple \u03a0i = \u3008\u2206i, ORi, CLi\u3009, where \u2206i \u2286 A is a set of actions and ORi and CLi are sets of orderings and causal links over \u2206i, respectively. \u03a0i is a threat-free partial plan that solves g as well as all the new open goals of the form \u3008v, d\u3009 or \u3008v,\u00acd\u3009 that arise from this resolution and can only be achieved by agent i, where (v \u2208 Vi)\u2227(v 6\u2208 Vj ,\u2200j 6= i). That is, when solving a goal of a base plan, agents only accomplish the new open goals concerning their private fluents, leaving public goals unresolved. In other words, the refinement method only iterates over the public fluents. Let g \u2208 openGoals(\u03a0g) be a fluent of the form \u3008v, d\u3009 or \u3008v,\u00acd\u3009; an agent i proposes a refinement step over \u03a0g iff v \u2208 Vi.\nIn our MAP approach partial plans are multi-agent concurrent plans as two or more actions can be concurrently executed by different agents. Some MAP models adopt a simple form of concurrency: two concurrent actions are mutually consistent if none of them changes the value of a state variable that the other relies on or affects, too (Brenner and Nebel, 2009). We impose the additional concurrency constraint that the preconditions of two actions have to be consistent (Boutilier and Brafman, 2001) for these two actions to be mutually consistent. This definition of concurrency is straightforwardly extended to a joint action \u03b1 = \u3008\u03b11, . . . , \u03b1n\u3009.\nDefinition 8. (Mutually consistent actions) Two concurrent actions \u03b1 \u2208 Ai and \u03b2 \u2208 Aj are mutually consistent if none of the following conditions holds:\n\u2013 \u2203(v = d) \u2208 EFF (\u03b1) and \u2203(\u3008v, d\u2032\u3009 \u2208 PRE(\u03b2) \u2228 \u3008v,\u00acd\u3009 \u2208 PRE(\u03b2)), where v \u2208 Vi \u2229 Vj , d \u2208 Div \u2229 Djv, d\u2032 \u2208 Djv and d 6= d\u2032, or vice versa. \u2013 \u2203(v = d) \u2208 EFF (\u03b1) and \u2203((v = d\u2032) \u2208 EFF (\u03b2) \u2228 (v 6= d) \u2208 EFF (\u03b2)), where v \u2208 Vi \u2229 Vj , d \u2208 Div \u2229 Djv, d\u2032 \u2208 Djv and d 6= d\u2032, or vice versa. \u2013 \u2203\u3008v, d\u3009 \u2208 PRE(\u03b1) and \u2203(\u3008v, d\u2032\u3009 \u2208 PRE(\u03b2) \u2228 \u3008v,\u00acd\u3009 \u2208 PRE(\u03b2)), where v \u2208 Vi \u2229 Vj , d \u2208 Div \u2229 Djv, d\u2032 \u2208 Djv and d 6= d\u2032, or vice versa.\nGoing back to our example in section 3, two concurrent actions drive t1 cA cB, planned by agent Ag1, and drive t1 cA cC, planned by agent Ag2, are mutually inconsistent as (at t1 = cB) \u2208 EFF (drive t1 cA cB) and \u3008at t1, cC\u3009 \u2208 PRE(drive t1 cC cB) (the first condition in Definition 8 holds). Concurrent actions drive t1 cA cB and drive t1 cA cC are also mutually inconsistent as (at t1 = cB) \u2208 EFF (drive t1 cA cB) and (at t1 = cC) \u2208 EFF (drive t1 cA cC) (second condition holds). Finally, concurrent actions drive t1 cA cB and drive t1 cC cB are mutually inconsistent as \u3008at t1, cA\u3009 \u2208 PRE(drive t1 cA cB) and \u3008at t1, cC\u3009 \u2208 PRE(drive t1 cC cB) (third condition holds).\nAs agents address concurrency inconsistencies through the detection of threats over the causal links of their plans, concurrency is ensured among private actions since a refinement step put forward by an agent is always a threat-free plan. However, concurrency issues between two public actions introduced by different agents do not arise until their preconditions are fully supported through causal links. This way, it is not possible to ensure that two concurrent actions are mutually consistent until their preconditions are fully supported. Thus, our notion of multi-agent concurrent plan distinguishes between public and private actions when dealing with concurrency.\nDefinition 9. (Multi-agent concurrent plan) A partial plan \u03a0 = \u3008\u2206,OR, CL\u3009 is a multi-agent concurrent plan if for every pair of unequal, concurrent, public actions \u03b1 and \u03b2, \u03b1 6= \u03b2, \u2200p\u03b1 \u2208 PRE(\u03b1), p\u03b1 6\u2208 openGoals(\u03a0), \u2200p\u03b2 \u2208 PRE(\u03b2), p\u03b2 6\u2208 openGoals(\u03a0), \u03b1 and \u03b2 are mutually consistent.\nDefinition 10. (Refinement plan) A refinement plan \u03a0 devised by an agent i over a base plan \u03a0g is a concurrent multi-agent plan that results from the composition of \u03a0g and a refinement step \u03a0i proposed by agent i. \u03a0 is defined as \u03a0 = \u03a0g \u25e6\u03a0i, where \u25e6 represents the composition operation.\nThus, an agent i can build a refinement plan \u03a0 upon a base plan \u03a0g by composing \u03a0g and a refinement step \u03a0i that solves at least g \u2208 openGoals(\u03a0g), i.e. \u03a0 = \u03a0g\u25e6\u03a0i. As previously mentioned, refinement steps are always threat-free and their actions are mutually consistent. Hence, if a refinement step brings about a concurrency inconsistency or a threat on the composite plan, the proposer agent is responsible for addressing such a flaw. If an agent is not able to come up with a consistent refinement plan, then it refrains from suggesting it. In case no refinements for a base plan can be found, the base plan is said to be a dead-end plan.\nDefinition 11. (Dead-end plan) A plan \u03a0 is called a dead-end plan if \u2203g \u2208 openGoals(\u03a0) and there is no refinement step \u03a0i such that g 6\u2208 openGoals(\u03a0 \u25e6 \u03a0i); that is, no refinement step solves the open goal g.\nDefinition 12. (Solution plan) A multi-agent concurrent plan \u03a0 is a solution plan for a planning task T if openGoals(\u03a0) = \u2205 (\u03a0 is a complete plan), Threats(\u03a0) = \u2205, and every pair of actions \u03b1, \u03b2 \u2208 \u03a0 are mutually consistent.\nThat is, a solution plan is a complete multi-agent concurrent plan. Note that we require \u03a0 to be a complete plan so it cannot have pending open goals. Consequently, the preconditions of the fictitious final action \u03b1f will also hold thus guaranteeing that \u03a0 solves the MAP task T . For instance, Figure 6 in section 9 shows a solution plan for the MAP task presented in section 3. The different shapes of the actions indicate which agent has proposed them. The solution plan in Figure 6 is a complete, concurrent plan to which all the agents in the MAP task have contributed."}, {"heading": "6. Planning language for MAP tasks", "text": "In our MAP system, we define the agents\u2019 planning tasks through several specification files. These files encode the information of the agent on the MAP task, namely the variables, Vi; the objects associated to the variables, Oi; the planning actions, Ai; and the initial state of the agent, Ii. All this information is written in a planning definition language.\nTraditionally, planning has been regarded as a single-agent problem, where only one centralized planning entity is required. MAP presents new requirements and challenges that are not present in classical, centralized planning. Planning agents in our MAP model can withhold their private information, and decide which information to share with the rest of agents. In addition, planning agents can have private individual objectives besides the goals of the planning task. Therefore, the planning language must provide support to allow us to define shareable information and private goals.\nPlanning definition languages have experienced a remarkable evolution over the last years, continuously increasing their expressivity through the addition of new features. Our MAP language is based on PDDL3.1 (Kovacs, 2011), the most recent version of PDDL (Ghallab, Howe, Knoblock, McDermott, Ram, Veloso, Weld and Wilkins, 1998), which was introduced in the context of the 2008 International Planning Competition. Unlike its predecessors, that model a planning domain through logical predicates, PDDL3.1 also incorporates state variables by adding fluents that map a tuple of objects to an object of the planning task. We have extended the PDDL3.1 language with some new structures to model the multi-agent features of a planning task.\nIn single-agent PDDL language, the user writes two files, one containing the domain of the task and another one containing the data of the problem to be solved. The domain file describes the planning actions, the types of objects and the state variables of the task, while the problem file details the current objects of the task, the initial state (the initial values of the state variables) and the task goals. These files have a similar structure to their PDDL counterparts, and reflects the additional information required by MAP tasks.\nIn our MAP system, each agent has a domain and a problem file that model, respectively, the typology of the planning agent and its particular vision of the MAP task. The domain and problem files also include the information that is shared among agents. The shared-data structure allows the problem designer to define which fluents will be shared by each agent and with whom. Through\nthis structure, the designer can define the incomplete information of the agent. This way, the domain knowledge of the agents can be modeled (or specified) from a complete unawareness to a full visibility of the domain. Additionally, since agents in MAP may have both global and local goals, this information is modeled through the structures global-goal and private-goal. Finally, we have included an additional multi-functions structure in order to simplify the specification of fluents in the initial state of an agent.\nThe following subsections analyze the structures that cover the requirements of MAP domains, i.e. modeling the data shared among agents, and the definition of local and global goals. The last subsection provides an example that describes the encoding of the MAP task introduced in section 3 with our language."}, {"heading": "6.1. Shared data", "text": "The shared-data structure, located on the agent\u2019s problem file, determines which fluents are shareable and with which agent or agents they will be shared. As shown in section 8, this structure directly affects the initial information exchange that agents perform before planning, and it also defines the partial view of the planning task of each agent.\nAs agents only exchange fluents, in the :shared-data structure the problem designer specifies the fluents that the agent can share and with which agents. The shared-data structure has the following BNF syntax: <shared-data-def> ::= (:shared-data <share-def>+) <share-def> ::= (<atom-formula-def>+ [- <agent-def>?]) <agent-def> ::= <agent> | (either <agent> <agent>+) <agent> ::= <name> <atom-formula-def> ::= (<predicate> <typed-list(element)>) <atom-formula-def> ::= (= <object-fluent> <object>) <predicate> ::= <name> <object-fluent> ::= (<name> <object>*) <object> ::= <name> <element> ::= <variable> | <constant> <variable> ::= ?<name> <constant> ::= <name> <typed-list(x)> ::= x*\nAs the BNF syntax shows, it is possible to define fluents or predicates within the :shared-data section and associate them to one, some or all the agents in the system (if agent is not specified, the predicates or fluents are shared with all the agents)."}, {"heading": "6.2. Private and global goals", "text": "A particularity of the MAP approach when compared to traditional planning is the fact that agents have private and global goals. To reflect this information in the model, the private-goal and global-goal structures have been included into the problem files. Similarly to the goal section in PDDL3.1, goals can be modeled through predicates or fluents. The private-goal and global-goal structures use the following BNF syntax:\n<private-goal-def> ::= (:private-goal <predicate-def>) <global-goal-def> ::= (:global-goal <predicate-def>) <predicate-def> ::= <atom-formula-def> <predicate-def> ::= (and <atom-form-def> <atom-form-def>+) <predicate-def> ::= (or <atom-form-def> <atom-form-def>+) <atom-form-def> ::= (<predicate> <typed-list(element)>) <atom-form-def> ::= (= <object-fluent-def> <object>) <predicate> ::= <name> <object-fluent-def> ::= (<name> <object>*) <object> ::= <name> <element> ::= <variable> | <constant> <variable> ::= ?<name> <constant> ::= <name> <typed-list(x)> ::= x*\nAs shown in the BNF syntax description, both global and local goals are described as conjunctions or disjunctions of fluents and predicates, or rather as a single fluent or predicate."}, {"heading": "6.3. Encoding example", "text": "This subsection describes the encoding of the MAP task presented in section 3 with our MAP language. This MAP task describes a transportation and storage scenario in which two agents (Ag1 and Ag2) take the role of transport agencies and an agent (Ag3) manages a storage facility. Transport agents deliver packages through a network of cities, while the warehouse agent stores and loads the packages in trucks. In the following, we provide a description of the domain and problem files of the agents for this task, stressing the specification of shareable information.\nPlanning agents receive two different description files, namely the domain and problem file. The domain file contains a general description of the capabilities of the agent, including the actions that the agent can perform and the predicates and functions it can manage. All agents of the same type share the same domain file, e.g. transport agents Ag1 and Ag2 in this example receive the same domain file. The problem file models the concrete problem assigned to each agent, including a description of the objects of the task, the initial situation and the global goals of the task as well as private goals of the agent. Each agent receives its particular problem file."}, {"heading": "6.3.1. Domain files", "text": "The domain file for transport agents specifies bidirectional links among cities, which allow trucks to move from one city to another. Trucks can only travel within the cities included in their working areas, depicted in Figure 1 with two circles. This way, transport agents have to interact and cooperate in order to deliver packages to a different area. The domain file for transport agents is modeled as follows:\n(define (domain Transport) (:requirements :typing :equality :fluents) (:types truck package agent city - object\nraw-material final-product - package) (:predicates (empty ?c - city)) (:functions (at ?t - truck) - city\n(pos ?p - package) - (either city truck) ) (:multi-functions (link ?c - city) - city\n(area) - city ) (:action load :parameters (?t - truck ?p - package ?c - city) :precondition (and (member (area) ?c)(= (at ?t) ?c)(= (pos ?p) ?c)) :effect (and (assign (pos ?p) ?t)(empty ?c))\n) (:action unload :parameters (?t - truck ?p - package ?c - city) :precondition (and (empty ?c)(member (area) ?c)\n(= (at ?t) ?c)(= (pos ?p) ?t)) :effect (and (assign (pos ?p) ?c)(not (empty ?c)))\n) (:action drive :parameters (?t - truck ?c1 ?c2 - city) :precondition (and (member (area) ?c1)(member (area) ?c2)\n(member (link ?c1) ?c2)(= (at ?t) ?c1)) :effect (assign (at ?t) ?c2)\n) )\nThe domain file shown above is structured similarly as a regular PDDL3.1 file. The main sections of the file are highlighted in bold. The :requirements section indicates the PDDL features that have been used to encode the domain information. :types describes the object-type hierarchy of this particular domain. As it can be seen, the planning domain of transport agents includes four different types of objects, namely truck, agent, city and package. A package can be either a raw-material or a final-product.\nStructures :predicates, :functions and :multi-functions define the state variables used in the transport domain. During the planning process, these variables will be instantiated to objects defined in the transport agents\u2019 problems, thus giving rise to the fluents that will be used throughput the planning process. For instance, let us consider the function (at ?t - truck) - city, where (at ?t) is a state variable and city is the type of its domain values. Given a truck object t1 and a city object c1, the previous function will result in a fluent of the form (= (at t1) c1), which indicates that t1 is located at c1.\nThe domain file of transport agents include the following predicates, functions and multi-functions: empty is a predicate to indicate whether a city is empty or already contains a package (a city can only have one package simultaneously); function at returns the city in which a certain truck is placed; function pos describes the position of a package, either a truck or a city; multi-function link returns the outcoming connections (roads) from a certain city; and area describes the working area of an agent in terms of the cities it can drive a truck to.\nThe last portion of a PDDL3.1 domain file defines the abilities of the agent, i.e., the actions it can perform. Actions are described through its parameters\n(objects that take part in the action), preconditions (predicates and functions that must hold for the action to be applicable) and effects (predicates and functions that describe the consequences of applying the action). As in the case of predicates, functions and multi-functions, actions are described through state variables. In particular, preconditions encode queries on fluents that check whether a variable takes on a particular value, and effects encode assignment operations on fluents to make a state variable take on a value.\nAs described in the domain file, transport agents can perform three different actions: load and unload a package into/from a truck, and drive a truck from a city to another one of the agent\u2019s area.\nThe domain file for warehouse agents is similar to the classical blocksworld domain, in which packages can be stacked and unstacked on/from the table or other packages. In this case, only one pile of packages can be stacked on the table, and there are two types of packages, raw materials and final products. The transportation and storage scenario depicted in Figure 1 includes two final products (packages p1 and p2) and a raw material (package p3). The warehouse agent delivers final products to the city in which the warehouse is placed (the exchange city, cF in Figure 1), and acquires raw materials that are unloaded from the trucks in the exchange city. Following, we show a sketch of the warehouse domain file encoding: (define (domain Warehouse) (:requirements :typing :equality :fluents) (:types package agent city table hoist - object\nraw-material final-product - package) (:predicates (empty ?c - city)\n(clear ?p - (either package table hoist)) (exchange-city ?c - city)\n) (:functions (pos ?p - package) - (either city package table hoist)) (:action acquire :parameters (?p - raw-material ?c - city ?h - hoist) :precondition (and (= (pos ?p) ?c)(clear ?h)(exchange-city ?c)) :effect (and (assign (pos ?p) ?h)(not (clear ?h))(empty ?c))\n)\n...\n)\nAs the transport agents, warehouse agents manage city, hoist and package objects. Additionally, warehouse agents consider table and hoist objects. The hoist is used to deliver and acquire packages, while the table is used to stack and unstack packages within the warehouse.\nWarehouse agents perform the four actions indicated above: they can stack and unstack a package on top/from a clear table or package; and can also acquire and deliver a package from/to the exchange-city by using a hoist. The sketch of the domain file illustrates the encoding of the acquire action."}, {"heading": "6.3.2. Problem files", "text": "Each agent receives its own problem file that models the particular objects managed by the agent, the initial situation known to the agent and the global and private goals that the agent must achieve. Moreover, the problem files include the definition of the shareable fluents and with which agents they can be shared.\nWe now explain the problem file of transport agent Ag1 (this problem will be later used to illustrate the construction of the dis-RPG). Problem files describe the initial state of the task by including both the positive and negative information known by the agent. This way, the information not represented in the problem file is unknown to the agent. Ag1\u2019s problem file is encoded as follows:\n(define (problem Ag1) (:domain Transport) (:objects\nAg1 Ag2 Ag3 - agent t1 - truck cA cB cC cD cE cF - city p3 - raw-material p1 p2 - final-product)\n(:shared-data (empty ?c - city) - (either Ag2 Ag3) ((at ?t - truck) - city) ((pos ?p - package) - (either city truck)) - Ag2 ((pos ?p - package) - city) - Ag3\n) (:init\n(empty cB) (empty cC) (empty cD) (not (empty cA)) (= (at t1) cA) (not (= (at t1) cB)) (not (= (at t1) cC)) (not (= (at t1) cD)) (= (pos p3) cA) (not (= (pos p3) cB)) (not (= (pos p3) cC)) (not (= (pos p3) cD)) (= (link cA) {cB cC}) (not (= (link cA) {cA cD})) (= (link cB) {cA cC}) (not (= (link cB) {cB cD})) (= (link cC) {cA cB cD}) (not (= (link cC) {cC})) (= (link cD) {cC}) (not (= (link cD) {cA cB cD})) (= (area) {cA cB cC cD}) (not (= (area) {cE cF}))\n) (:global-goal (and (= (pos p1) cA)(= (pos p3) cE))) )\nSections of the problem file are also highlighted in bold. A domain file starts with a description of the :objects that the agent manages. As shown in the code, agents are represented as objects. Ag1 knows that there is a truck t1 in the task, and it has knowledge of six different cities, although it only manages the four cities included in its working area (see Figure 1). The agent also knows that there are three packages in the MAP task, the final-products p1 and p2 and the raw-material p3.\nThe :shared-data section is a key aspect of our MAP language, as it defines the information shareable by the agents and directly affects their knowledge of the task. The predicates and functions defined in this structure are the patterns of the fluents that the agent regards as shareable with other agents. For instance, Ag1\u2019s :shared-data section includes the following pattern: (empty ?c - city) - (either Ag2 Ag3). This pattern indicates that Ag1 will share the fluents that match the pattern (empty ?c - city) with both Ag2 and Ag3. Given that Ag1 knows the cities cA, cB, cC, cD, cE and cF, fluents as (= (empty cA) true) or (= (empty cD) false) match the pattern, and Ag1 shares this information with Ag2 and Ag3.\nThe :init section describes the initial state of Ag1, i.e., the initial situation of the world known to Ag1. It is defined with predicates like (empty cB), functions like (= (at t1) cA)) and multi-functions like (= (link cA) {cB cC}), that hold in the initial situation. The initial state includes both positive and negative information. For instance, the function (not (= (at t1) cC)) indicates that\nAg1 knows that truck t1 is not initially placed at city cC. The information not included in the initial state is considered unknown to Ag1.\nWhile the initial state contains predicates, functions and multi-functions, internally the system treats all of them as fluents. For instance, a predicate (empty cB) is internally converted into a fluent (= (empty cB) true), while functions like (= (at t1) cA) are already in the form of fluents. Multi-functions are used to easily define multiple functions through a simplified notation. The conversion into fluents is straightforward: given a multi-function (= (link cA) cB cC), we generate the fluents (= (link cA cB) true) and (= (link cA cC) true).\nFinally, the :global-goal structure shows the global objective of the MAP task. In this case, the goal is to transport the raw-material p3 to city cF, and to deliver a final-product to city cA. Notice that, in this example, there is not a :private-goal section."}, {"heading": "7. MAP algorithm overview", "text": "This section summarizes the main stages of the MAP algorithm followed by the agents to devise, exchange and select refinement plans to come up with a solution for the MAP task. Agents follow a procedure that integrates planning and coordination, allowing agents to solve both strongly-related and loosely-coupled problems without losing generality. Agents perform an individual Partial-Order Planning (POP) search to build refinements over the current base plan, while one of the agents leads the process of gathering the new refinement plans and selecting the next base plan.\nAlgorithm 1 Overview of the MAP algorithm Initial information exchange repeat Individual refinement process Coordination process\nuntil a solution plan is found or the search space is completely explored\nAlgorithm 1 shows the main steps of the MAP algorithm. The stages of the algorithm are outlined as follows:\n\u2013 Initial information exchange: The algorithm starts with an initial communication stage by which agents exchange the shareable information on the planning domain in order to generate the data structures that will be used in the subsequent planning process. Agents take advantage of the exchanged information to build a distributed Relaxed Planning Graph, which provides them with their partial view on the MAP task.\n\u2013 Resolution process: Once agents have exchanged the shareable information and the distributed Relaxed Planning Graph is computed, they start the iterative resolution process by which they explore the search space until they find a solution for the MAP task. As shown in Algorithm 1, this process comprises two different interleaved stages, an individual planning process by which agents devise refinements over a centralized base plan and a coordination process to exchange the new refinement plans and to select the next base plan:\n\u00b7 Individual refinement process: Agents individually refine the current base plan of the MAP system. Each planning agent is provided with an internal POP system. The classical POP algorithm has been adapted to a MAP context in order to obtain valid refinement plans over an incomplete base plan (see section 9.1).\n\u00b7 Coordination process: Agents communicate and exchange the new refinement plans over the current base plan. Later, they jointly evaluate these refinement plans and select the most promising one as the next base plan.\nThe following sections detail the two main stages of the MAP algorithm. Section 8 describes the initial information exchanging stage performed by the agents, while section 9 details the resolution process, including both the coordination process and the individual construction of the refinement plans."}, {"heading": "8. Initial information exchange", "text": "Prior to the resolution process itself, agents perform a preliminary stage to share public planning information effectively. This initial stage builds a distributed Relaxed Planning Graph (dis-RPG), whose construction is inspired by the approach in (Zhang et al., 2007). Unlike the proposal in (Zhang et al., 2007), which stops the graph construction once all the problem goals appear in the graph, our procedure builds a complete dis-RPG by maintaining the incomplete information of the agents, so they only exchange the information defined as shareable in the input files (see section 6). This section describes in detail the dis-RPG building process and subsection 8.1 provides a trace based on the MAP task presented in section 3 that illustrates this process.\nThe dis-RPG provides the agents with valuable planning information that will be used throughout the refinement planning process: \u2013 Agents exchange the fluents defined as shareable in the :shared-data section of the MAP domain definition files (see subsection 6.1). Fluents are labeled with the list of agents that can achieve them, giving each agent a view of the possible interactions that can arise at planning time with other agents.\n\u2013 An estimate of the best cost to achieve each fluent is computed. This information is used to design heuristics to guide the refinement planning process. Following Algorithm 2, the first step of the dis-RPG construction consists in computing the initial RPG for each agent i, RPGi, taking only into account the fluents and actions initially known to the agent. Agents compute this initial planning graph by following the procedure presented in (Hoffmann and Nebel, 2001). The RPG consists of a set of alternating fluent and action levels. The first fluent level contains the fluents that are part of the initial state, and the first action level includes all the actions whose preconditions appear in the first fluent level. Fluents that are part of the effects of these actions (and have not been included in the first fluent level) are placed in the second fluent level, and actions whose preconditions are included in the two prior fluent levels of the graph (and are not in the first action level) are stored in the second action level. By following this procedure, the RPG is expanded until no new fluents are found. This way, the level of the graph in which an action or fluent appears gives an estimate of the cost of achieving such an action or fluent.\nOnce all agents have computed their initial RPGs, the iterative composition\nAlgorithm 2 Dis-RPG construction for an agent i Build initial RPGi repeat \u2200j 6= i, i sends j shareable fluents SF i\u2192j \u2208 RPGi of the form \u3008v, d\u3009 or \u3008v,\u00acd\u3009, where v \u2208 Vi \u2229 Vj and d \u2208 Div \u2229 Djv \u2200j 6= i, i receives from j shareable fluents SF j\u2192i \u2208 RPGj of the form \u3008v, d\u3009 or \u3008v,\u00acd\u3009, where v \u2208 Vi \u2229 Vj and d \u2208 Div \u2229 Djv RF i \u2190 \u2205 \u2200j 6= i, RF i \u2190 RF i \u222a SF j\u2192i for all received fluents f \u2208 RF i do if f 6\u2208 RPGi then Insert f in RPGi levelRPGi(f)\u2190 level(f)\nend if if (f \u2208 RPGi) \u2227 (levelRPGi(f) > level(f)) then levelRPGi(f)\u2190 level(f)\nend if end for Expand RPGi\nuntil RF i = \u2205\nof the dis-RPG begins. As depicted in Algorithm 2, after computing the initial RPGi, agent i executes the first iteration of the algorithm and exchanges the fluents and actions of its RPGi with the rest of agents. Agents only exchange the fluents defined as shareable in the :shared-data structure of the input files (see subsection 6.1). Agent i sends agent j the set of fluents SF i\u2192j that are visible to agent j, i.e., the fluents in RPGi of the form \u3008v, d\u3009 or \u3008v,\u00acd\u3009, where v \u2208 Vi \u2229Vj and d \u2208 Div \u2229Djv. Likewise, agent i will receive from the rest of agents j 6= i the shareable fluents of their RPGj that are visible to agent i.\nAgent i updates its RPGi accordingly with the new fluents received from the rest of agents. We will refer to these fluents as RF i (see Algorithm 2). If a fluent f \u2208 RF i is not in RPGi then it is stored according to level(f). If f is already in RPGi, its level in the graph is updated if levelRPGi(f) > level(f). Hence, agents only store the best estimated level to reach each fluent, placing each fluent at the lowest possible level of the graph. After updating RPGi, agent i expands it by checking wether the new inserted fluents trigger new actions in RPGi or not. The fluents produced as effects of these new actions will be shared in the next information exchange iteration. The RPG expansion procedure also updates the existing actions by placing them at a lower action level if their preconditions have been updated.\nSince agents only exchange those fluents defined as shareable, the dis-RPG process gives each agent a different view of the planning task, so no agent handles a complete representation of the dis-RPG. In contrast, each agent i maintains its own internal RPGi, whose information depends on the fluents other agents have shared with it, which makes each agent have its own, partial view of the planning task. Thus, agents design plans under incomplete information, as they are partly aware of the information on the planning task.\nThe dis-RPG process finishes when agents do not receive more fluents from\nthe others. Following, agents start the resolution process to jointly devise a solution plan."}, {"heading": "8.1. dis-RPG example", "text": "In order to illustrate the dis-RPG stage of the MAP algorithm, this section provides an example trace based on the transportation and storage MAP task introduced in section 3. The planning agents receive the input files presented in subsection 6.3 and start the MAP algorithm by building the dis-RPG.\nIn the first stage of Algorithm 2, each agent individually generates an initial RPG, according to its problem file. To illustrate this stage of the process, we focus on the initial RPGs built by the transport agents Ag1 and Ag2.\nTable 1 shows the initial RPG calculated by agent Ag2. The numbers in brackets indicate the agents that can generate the fluent, while the values T and F stand for true and false, respectively. Ag2 does not know the position of the packages and the truck because they are initially located out of its working area (see Figure 1 in section 3). Therefore, its initial RPG only includes F0, the first level of fluents, which stores the fluents on the initial state of Ag2. The initial RPG of Ag2 does not contain any action level because there are no applicable actions, that is, their preconditions do not hold in F0.\nAgent Ag1 does know the position of the package p3 and the truck t1, and consequently, it can compute a much larger initial RPG (see Table 2). Notice that the level A0 includes the actions whose preconditions are satisfied in F0, while F1 stores the fluents that are part of the effects of the actions in A0 and are not in F0. For instance, the action drive t1 cA cB, at level A0, has the following preconditions: (= (area) cA), (= (area) cB), (= (link cA cB) true) and\n(= (at t1) cA). As Table 2 shows, these fluents are at F0, which triggers the action drive t1 cA cB at A0.\nOnce agents have built their initial RPGs, they start the iterative dis-RPG building process by exchanging the shareable fluents in their RPGs.\nIn subsection 6.3.2, we show the :shared-data section of Ag1, which shares with Ag2 fluents that match the following patterns: (empty ?c - city), ((at ?t - truck) - city) and ((at ?t - truck) - city). The fluents shared by Ag1 and Ag2 are marked in red in Table 2. Ag2 also sends its shareable fluents to the rest of agents and stores the fluents received from other agents.\nAgents expand their RPGs by checking if the fluents they have received trigger new actions in the graph. The process carries on until no new fluents appear in the dis-RPG. As each agent has a different :shared-data section, the information will vary from one RPG to another, giving each agent a different and incomplete view of the dis-RPG and the MAP task itself.\nTable 3 shows the final dis-RPG of the transportation scenario as seen by agent Ag2. As it can be observed, the dis-RPG provides both an estimate of the cost of achieving each fluent (this cost corresponds to the level at which the fluent appears), and the set of agents that achieve that fluent in the RPG."}, {"heading": "9. Resolution process", "text": "After the information exchange, agents initiate the resolution process (see Algorithm 3), which comprises two interleaved stages: the individual refinement stage and the coordination stage. The first stage involves agents building individual\nrefinements over a centralized base plan by using a POP. In the second stage, agents follow a coordination process to gradually build a joint solution plan for the MAP task, exchanging and evaluating the refinements generated individually and selecting the most promising one in order to reach a solution.\nAlgorithm 3 Resolution process for an agent i \u03a0\u2190 \u03a00 R = \u2205 repeat Select open goal g \u2208 openGoals(\u03a0) Refinementsi(\u03a0g)\u2190 Refine base plan \u03a0g individually \u2200j 6= i, send Refinementsi(\u03a0g) to agent j \u2200j 6= i, receive Refinementsj(\u03a0g) Refinements(\u03a0g)\u2190 Refinementsi(\u03a0g) \u2200j 6= i, Refinements(\u03a0g)\u2190 Refinements(\u03a0g) \u222aRefinementsj(\u03a0g) Evaluate Refinements(\u03a0g) R\u2190 R \u222aRefinements(\u03a0g) Vote for the best plan \u03a0i \u2208 R \u03a0\u2190 \u03a0i if openGoals(\u03a0) = \u2205 then return \u03a0\nend if until R = \u2205"}, {"heading": "9.1. Individual refinement stage", "text": "A planning agent i executes its individual POP process in order to refine the current base plan \u03a0. As shown in Algorithm 3, agent i refines \u03a0 by solving a particular open goal g \u2208 openGoals(\u03a0), thus obtaining a set of valid refinement plans over \u03a0g, Refinementsi(\u03a0g).\nOur definition of refinement plan (see subsection 5.2.2) states that a refinement plan \u03a0i of an agent i over a base plan \u03a0 solves one of its open goals g \u2208 openGoals(\u03a0), as well as all the private open goals gi of the form \u3008v, d\u3009 or \u3008v,\u00acd\u3009 that arise from this resolution, where v \u2208 Vi \u2227 d \u2208 Div \u2227 ((\u2200j 6= i, v 6\u2208 Vj) \u2228 (\u2200j 6= i, d 6\u2208 Djv)) \u2227 (gi 6\u2208 openGoals(\u03a0)).\nWe have designed a customized version of the classical POP algorithm compliant with the requirements introduced by the MAP approach. Our POP system is able to start the search process from any given base plan, rather than starting with an empty plan as in a traditional POP process. In addition, the POP is aimed at building refinement plans, rather than complete solution plans."}, {"heading": "9.2. Coordination process", "text": "The coordination process is based on a democratic leadership in which a leadership baton is scheduled among the agents (initially, the baton is randomly assigned to one of the participating agents). The resolution process interleaves the coordination process with the individual refinement stage. A coordination\niteration is led by the agent which has the baton (baton agent). Once the coordination iteration is completed, the baton is handed over to the following agent.\nAlgorithm 3 depicts the main steps of the coordination process. After the individual refinement stage, agents exchange the refinement plans they have elicited over the current base plan \u03a0. Following, agents receive the refinement plans of the other agents and evaluate them according to their view of the planning task. Agents apply a voting process to adopt the most promising plan as the next base plan \u03a0, and check if the selected plan is a solution. Otherwise, agents choose a new open goal of the plan g \u2208 openGoals(\u03a0) and each agent i starts a new individual refinement stage to compute the refinements over \u03a0, Refinementsi(\u03a0g).\nIn the first step of the coordination process, the individual refinement plans are exchanged between agents for their evaluation. An agent i sends the refinement plans it has devised over the current base plan \u03a0 by solving g \u2208 openGoals(\u03a0), Refinementsi(\u03a0g), to the rest of agents in the task. In turn, agent i receives the refinements devised by each agent j in the task,Refinementsj (\u03a0g), where j 6= i. Note that agents have a local, partial view of the plans, so given a refinement plan \u03a0, an agent i will only view the open goals og \u2208 openGoals(\u03a0) of the form \u3008v, d\u3009 or \u3008v,\u00acd\u3009 such that v \u2208 Vi and d \u2208 Div. The view agent i has on each refinement plan \u03a0, viewi(\u03a0), ensures agents\u2019 privacy and directly affects the evaluation of the refinements.\nThe evaluation of the refinement plans is carried out through a utility function F , by which agents estimate the quality of the plans. Since an agent i evaluates a plan accordingly to its view, F(viewi(\u03a0)), the results of the evaluation may be different from the other agents\u2019. Therefore, agents will have different perspectives on the quality of the refinement plans.\nOnce the refinement plans are evaluated, agents vote for the most promising candidate in R, which stores all the refinement plans that have not yet been selected as a base plan (see Algorithm 3). Each agent i votes for the best refinement plan in R according to the utility function F . In case of a draw, the baton agent will choose the next base plan among the most voted alternatives. If R = \u2205, the refinement planning process ends with no solution found.\nOnce a refinement plan is selected, agents adopt it as the new base plan \u03a0. If openGoals(\u03a0) = \u2205, a solution plan is returned. As some open goals might not be visible to some agents, all agents must confirm that \u03a0 is a solution plan according to their view of \u03a0. Finally, the baton agent selects the next open goal g \u2208 openGoals(\u03a0) to be solved, and a new iteration of the refinement and coordination process starts.\nThe resolution process carried out by the agents can be regarded as a joint exploration of the refinement space. Nodes in the search tree represent refinement plans and each iteration of the process expands a different node."}, {"heading": "9.3. Resolution example", "text": "This subsection illustrates the resolution process by showing a partial trace that follows the trace example described in subsection 8.1. After completing the initial information exchange and building the dis-RPG, agents proceed with the resolution process in order to solve the MAP task.\nThe plan construction starts with an initial empty plan, \u03a00, which contains only the two fictitious steps that represent the initial state and the goals of the\nMAP task. The first open goal selected by Ag1 (which takes the role of baton agent in this first iteration) for its resolution is (= (pos p1) cA), as it is the most costly one according to the dis-RPG. The goals of the task are highlighted in bold in Table 3. This dis-RPG shows that (= (pos p1) cA) has a cost of 5, (= (pos p3) cF) has a cost of 4, and the only agent that can achieve (= (pos p1) cA) is Ag1. Hence, Ag1 proposes a set of refinements over \u03a00, \u03a000, . . . ,\u03a009, while Ag2 and Ag3 refrain from making proposals. The proposed refinements are evaluated through the utility function F , and the best-valued one, \u03a000, is selected as the new base plan.\nFigure 4 depicts the refinement plan \u03a000. Since all the causal links in \u03a000 involve shareable fluents, all the agents have a complete view of this refinement plan. However, agents Ag1 and Ag3 have different views of the refinement \u03a006 (see Figure 5). In order to guarantee privacy, several causal links (black arrows) of \u03a006 have been occluded to Ag3, which only sees ordering constraints instead (grey arrows). According to the problem definition files, the fluents involved in these causal links are private to the transport agent Ag1 because they are not shareable data, and therefore, Ag1 does not communicate them to Ag3.\nOnce the refinement plan \u03a000 is chosen as the new base plan, Ag1 passes on the baton to Ag2 and a new iteration of the resolution process starts. The MAP process will carry on until a solution plan is found. Since some open goals are not visible to some agents, all participating agents must confirm that the plan has no pending open goals. Figure 6 depicts the solution plan for the MAP task\nat hand, showing in different shapes the actions to be executed by each agent. As it can be observed, the solution of the MAP task is a joint plan to which all the participant agents have contributed."}, {"heading": "10. Experimental results", "text": "Several tests have been performed to evaluate the performance of our MAP system. The tests compare the MAP model with a single-agent approach to analyze its advantages and shortcomings against a centralized planning model. We have used two different planning domains for our experiments. Next subsections present the MAP domains and analyze the results of the different tests."}, {"heading": "10.1. Multi-agent planning domains", "text": "The two planning domains used to test the MAP system have been taken from real-life problems or adapted from well-known case studies. The two domains were designed such that we could test the performance and the quality of the solutions obtained with a wide range of problems. We tested our MAP system with different levels of complexity: from loosely-coupled problems, in which interactions among agents are rather low, to strongly-related problems, that require a strong coordination effort to be solved. Additionally, we created both a multiagent and a single-agent version for each problem.\nIn section 3, we described a transportation and storage domain, in which agents take the roles of transport agencies and storage facilities, which work together to transport raw materials and final products to different cities. This domain gives rise to strongly-related problems as interactions between agents are required in order to accomplish the different objectives. Agents in the transportation domain have different abilities, so they should cooperate with each other in order to achieve the different goals.\nWe defined an additional planning domain, the picture domain. This domain gives rise to simpler, loosely-coupled problems as agents can work independently in order to solve the objectives, and hence cooperation and interactions among agents are not mandatory to find a solution. Planning agents in the picture domain (workers) are not specialized, they all share the same abilities and so they all can perform the same actions. In addition, agents in this domain do not keep private information for themselves but all the problem information is shared among the agents. Next subsection describes the picture domain."}, {"heading": "10.1.1. Picture domain", "text": "This domain, adapted from the case study in (Parsons, Sierra and Jennings, 1998), presents a situation in which several workers have to cooperate to hang a set of pictures on walls. To do so, they have to acquire different tools that are scattered over several locations. Agents move through the locations to get the tools and hang the pictures. The domain defines a set of bidirectional links that connect the locations.\nFigure 7 depicts an example of this planning domain. In contrast to the transportation domain, agents in the picture domain share the same capabilities: agents can pickUp and putDown a tool in the location where the agent\nand the tool are placed; an agent can also pass the tool it is carrying on to another agent at the same location; agents can walk from one location to another through the link that connects both locations; finally, an agent can hang a picture on a certain location with the tool it is carrying.\nThis domain gives rise to loosely-coupled problems because an individual agent is likely to solve the problem goals by itself in most cases. Moreover, agents share the same abilities and have access to all the locations, so they are able to work independently and cooperation is not a requirement to complete the task. Cooperation is however useful to improve the quality of the solutions and to solve conflicts on the use of the tools, as they are limited resources shared by all the participating agents."}, {"heading": "10.2. Tests and results", "text": "The following subsections show the experimental results. We carried out two different tests1. The first one compares the quality of the solution plans obtained by a single agent and by a set of planning agents working together on the problem. To do so, we defined a set of MAP problems and the single-agent equivalent version. Finally, we measured the robustness and scalability of the MAP system by executing a planning problem several times, increasing each time the number of planning agents in the system."}, {"heading": "10.2.1. Multi-Agent vs. Single-Agent Planning", "text": "This first set of tests compares the quality of the solution plans of our MAP approach versus the centralized single-agent framework. The testbed includes twenty planning problems (ten problems per domain) of increasing difficulty.\nAs stated in subsection 10.1, the transportation problems present a high coupling level because agents are required to interact between each other to solve most of the problem goals. In contrast, agents in the picture problems can solve\n1 All the tests were performed on a single machine with a 2.83 GHz Intel Core 2 Quad CPU and 8 GB RAM.\nthe goals independently in most cases so the coupling level in these problems is rather low. Another key difference between both domains is that planning agents in the picture domain (workers) are also the entities that execute the plans, whereas agents in the transportation domain are merely planning entities. This way, given two parallel actions in a plan of the picture domain, each one is associated to a different agent (worker) whereas two parallel actions in a plan of the transportation domain can be associated to two different trucks of the same transport agent, which is the planning entity. In other words, concurrency is associated to the agents in the picture domain and to the resources managed by the agents (trucks, hoists, etc.) in the transportation domain.\nTable 4 shows the obtained results. #Ag indicates the number of agents that perform the planning problem in the MAP tests. #Actions and #TS refer to the number of actions and time steps of the solution plan, respectively (notice that we do not count the plans\u2019 fictitious actions). Finally, Parallelism indicates the maximum number of parallel branches in the MAP solution plans.\nTime steps are the number of time units necessary to execute the plan, i.e., the duration of the plan. For instance, Figure 8 depicts the solution plan for the Picture2 MAP problem. Although the plan is composed of twelve planning actions (without taking into account the two fictitious actions), it can be executed in only eight time steps, since most of its actions can be executed in two parallel branches. Then, the duration of the plan in Figure 8 is 8 time units.\nDiscussion on the results. In the transportation domain, the MAP approach obtains the same results than the single-agent approach w.r.t. the number of actions and time steps. The single-agent approach performs rather well in this particular domain, obtaining good-quality solutions, if not optimal, for almost all the tested problems. Notice that the single-agent approach features a single planning entity that has a full visibility on the planning problem. Despite the fact that the participating agents on the MAP tests have an incomplete view of the problem, the results show that MAP agents cooperate effectively, obtaining plans of the same quality as the single-agent approach, both in terms of number of actions and plan duration (time steps).\nIn the transportation domain, planning agents have a set of resources at their disposal (truck and hoists) to execute the actions of the plan. Since partial-order planners allow for parallelism, both the MAP and single-agent plans contain parallel actions. Actions in this domain are executed by the trucks and hoists instead of the planning agents themselves. Hence, the number of parallel branches and the duration of the solution plans of this domain is only conditioned by the number of available resources (trucks and hoists). For this reason, both ap-\nproaches give rise to plans with the same number of actions and time steps. On the basis of these results, we can affirm that the quality of the MAP plans is not diminished by the limited view and incomplete information of the agents and the existence of private information among agents.\nThe results of the picture domain present more differences between both approaches. The single-agent approach obtains sequential plans because the single planning agent is also the only execution entity. MAP, however, takes advantage of having several planning/execution agents cooperating. MAP enforces cooperation as agents can work together to reach an objective. For instance, Figure 8 shows that an agent can pick up a tool and pass it on to another agent. This cooperation improves the solution because it prevents the agent from going for the tool and retrace its steps, thus reducing the number of actions of the plan. Agents also cooperate by proposing different parts of the plan that can be executed concurrently, which reduces the duration of the plans with respect to the centralized approach. Table 4 shows that all the MAP solution plans for the picture domain include at least two parallel branches of actions, meaning that at least two agents work concurrently, which improves the quality of the solutions as shown in Table 4.\nIn conclusion, while being a more costly approach (see next subsection for scalability tests), MAP obtains equal or better solution plans in terms of both number of actions and duration of the plans than the single-agent model. We have shown that MAP promotes cooperation among agents thus improving the quality of the solution. In addition, MAP agents manage their incomplete information on the MAP task efficiently as the quality of the solution plans is not affected, being at least on par with the single-agent approach. Moreover, results show that our approach obtains good-quality solution plans for problems with different coupling and complexity levels, from loosely-coupled to strongly-related problems."}, {"heading": "10.2.2. Scalability analysis", "text": "In this subsection we evaluate the scalability of our MAP framework, i.e., how the number of agents in the MAP system affects its efficiency. To do so, eight different test problems were generated for both the transportation and the picture domains. Each test increases the number of agents by one, keeping the rest of the planning problem\u2019s parameters unchanged.\nAll the transportation tests include ten different cities, one truck, one empty table in the warehouse and one package of raw material. All the problems include a single warehouse agent, and each of them adds an extra transport agent, up to eight transport agents. The problem goal for all the test problems is to deliver the raw material to the warehouse, which must place it on the empty table. The optimal solution plan for all the problems includes ten actions and involves the participation of at least one transport agent and the warehouse agent.\nAs for the picture domain, all the test problems include two different tools and twelve different locations. The goal for all the problems is to hang two different pictures. The optimal solution plan for these problems has eight actions and involves the participation of two different agents. Each agent picks up one tool and hangs one picture.\nFigures 9 and 10 depict the results for each domain. As it can be observed, the number of messages experiences a notable increase with each new agent included\nin the MAP process. So does the execution time, which is conditioned by the number of messages exchanged among agents. Discussion on the results. These results are caused by the growing number of refinement plans proposed by the agents. Refinement plans are communicated to all the agents in the MAP system, reason why the addition of a planning agent represents such an overhead as each new agent proposes and communicates a number of extra refinement plans. In addition, the refinement plans proposed by each new planning agent increase the complexity of the search tree as they may also be adopted as base plans at some point.\nNotice that the number of messages is much larger in the case of the picture problems, even though we have defined similar size and complexity problems for the two planning domains. This is due to the loosely-coupled nature of the picture problems because agents in this domain share the same abilities and every agent can make a plan proposal over any base plan.\nAs opposite to the picture domain, agents in the transportation domain are specialized, which makes them unable to make plan refinements over every base plan. Transport agents are limited by their working areas, while warehouse agents cannot take part in the transportation of the packages. This fact limits the number of exchanged messages, which also benefits the execution time. This way, our system proves to be more stable when solving strongly-related problems like the transportation tests since the addition of a new agent causes a lower increase in the number of messages, which directly affects the execution time.\nIn conclusion, the number of agents in the MAP system is a parameter that has a significant influence on its efficiency because the number of messages among agents constitutes one of the bottlenecks of the system. This issue is more noticeable when dealing with loosely-coupled problems, as agents can devise plan proposals over almost any base plan, whereas our MAP system shows a more robust behavior when solving strongly-related problems. Therefore, our immediate challenge is to reduce the number of messages between agents. This way, we will improve the scalability of the system and we will be able to test more complex planning problems."}, {"heading": "11. Conclusions", "text": "This article presents a MAP model that allows agents to plan under incomplete information. Our approach is suitable to solve a wide range of MAP problems, from strongly-related problems with a high degree of interaction among agents to simpler loosely-coupled problems, which present limited interactions among agents. Our model allows for heterogeneous agents with different information, capabilities and private goals to cooperatively build a joint plan while handling an incomplete view of the MAP task. Agents keep their private data and share only the relevant information for their interactions with other agents, thus being unaware of part of the information managed by the rest of agents.\nShareable information is defined through our MAP language, extended from PDDL3.1. The information exchange is carried out through the construction of a distributed Relaxed Planning Graph, by which agents share the public fluents and estimate the best cost to achieve them.\nThe MAP resolution process is based on a refinement planning procedure whereby agents propose successive refinements to an initially empty base plan until a consistent joint plan is obtained. This procedure, that iteratively combines\nplanning and coordination, uses single-agent planning technology to build the refinement plans. More precisely, we adapt the POP paradigm to a MAP context, which allows agents to build refinement plans leaving details unresolved that will be gradually completed by other agents until a solution plan is found.\nConclusions drawn from the experiments show that MAP agents obtain solution plans of equal or better quality than a single-agent approach for both loosely-coupled and strongly-related problems. Despite agents do not have a complete view of the MAP task and keep private information, the quality of the MAP solution plans is not affected, neither in terms of number of actions nor plan duration. Hence, we can affirm that our model tackles large MAP tasks in which information is distributed among a number of planning entities at least as effectively as a single-agent planning approach working under complete information.\nMoreover, our MAP approach enforces cooperation among agents since they work together to solve goals more efficiently. MAP improves plan concurrency as agents can solve different goals in parallel, which reduces the duration and the number of actions of the solution plans. Acknowledgements. This work has been partly supported by the Spanish MICINN under projects Consolider Ingenio 2010 CSD2007-00022 and TIN2011-27652-C03-01, and the Valencian Prometeo project 2008/051."}], "references": [{"title": "An abstract architecture for virtual organizations: the THOMAS approach", "author": ["E. Argente", "V. Botti", "C. Carrascosa", "A. Giret", "V. Julian", "M. Rebollo"], "venue": "Knowledge and Information Systems", "citeRegEx": "Argente et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Argente et al\\.", "year": 2011}, {"title": "Partial-order planning: Evaluating possible efficiency gains", "author": ["A. Barrett", "D.S. Weld"], "venue": "Artificial Intelligence", "citeRegEx": "Barrett and Weld,? \\Q1994\\E", "shortCiteRegEx": "Barrett and Weld", "year": 1994}, {"title": "Agreeing on plans through iterated disputes", "author": ["A. Belesiotis", "M. Rovatsos", "I. Rahwan"], "venue": "in \u2018Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems\u2019,", "citeRegEx": "Belesiotis et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Belesiotis et al\\.", "year": 2010}, {"title": "JADE: a FIPA2000 compliant agent development environment, in \u2018Proceedings of the 5th international conference on Autonomous Agents (AAMAS)", "author": ["F. Bellifemine", "A. Poggi", "G. Rimassa"], "venue": null, "citeRegEx": "Bellifemine et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Bellifemine et al\\.", "year": 2001}, {"title": "Fast planning through planning graph analysis", "author": ["A. Blum", "M.L. Furst"], "venue": "Artificial Intelligence", "citeRegEx": "Blum and Furst,? \\Q1997\\E", "shortCiteRegEx": "Blum and Furst", "year": 1997}, {"title": "Partial-order planning with concurrent interacting actions", "author": ["C. Boutilier", "R. Brafman"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "Boutilier and Brafman,? \\Q2001\\E", "shortCiteRegEx": "Boutilier and Brafman", "year": 2001}, {"title": "From one to many: Planning for loosely coupled multiagent systems, in \u2018Proceedings of the 18th International Conference on Automated Planning and Scheduling (ICAPS)", "author": ["R. Brafman", "C. Domshlak"], "venue": null, "citeRegEx": "Brafman and Domshlak,? \\Q2008\\E", "shortCiteRegEx": "Brafman and Domshlak", "year": 2008}, {"title": "Continual planning and acting in dynamic multiagent environments", "author": ["M. Brenner", "B. Nebel"], "venue": "Journal of Autonomous Agents and Multiagent Systems", "citeRegEx": "Brenner and Nebel,? \\Q2009\\E", "shortCiteRegEx": "Brenner and Nebel", "year": 2009}, {"title": "Forward-chaining partial-order planning, in \u2018Proceedings of the 20th International Conference on Automated Planning and Scheduling (ICAPS)", "author": ["A. Coles", "M. Fox", "D. Long"], "venue": null, "citeRegEx": "Coles et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Coles et al\\.", "year": 2010}, {"title": "Teaching forward-chaining planning with JavaFF, in \u2018Colloquium on AI Education, 23rd AAAI Conference on Artificial Intelligence", "author": ["A. Coles", "M. Fox", "D. Long", "A. Smith"], "venue": null, "citeRegEx": "Coles et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Coles et al\\.", "year": 2008}, {"title": "A distributed framework for solving the multiagent plan coordination", "author": ["J. Cox", "E. Durfee", "T. Bartold"], "venue": "problem, in \u2018Proceedings of the 4th International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS)\u2019,", "citeRegEx": "Cox et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Cox et al\\.", "year": 2005}, {"title": "Introduction to planning in multiagent systems", "author": ["M. de Weerdt", "B. Clement"], "venue": "Multiagent and Grid Systems", "citeRegEx": "Weerdt and Clement,? \\Q2009\\E", "shortCiteRegEx": "Weerdt and Clement", "year": 2009}, {"title": "Generalizing the Partial Global Planning algorithm", "author": ["K. Decker", "V.R. Lesser"], "venue": "International Journal of Cooperative Information Systems (IJCIS)", "citeRegEx": "Decker and Lesser,? \\Q1992\\E", "shortCiteRegEx": "Decker and Lesser", "year": 1992}, {"title": "A survey of research in distributed continual planning", "author": ["M. desJardins", "E. Durfee", "C. Ortiz", "M. Wolverton"], "venue": "AI Magazine", "citeRegEx": "desJardins et al\\.,? \\Q1999\\E", "shortCiteRegEx": "desJardins et al\\.", "year": 1999}, {"title": "On the role of interactive epistemology in multiagent planning, in \u2018Artificial Intelligence and Pattern Recognition", "author": ["P. Doshi"], "venue": null, "citeRegEx": "Doshi,? \\Q2007\\E", "shortCiteRegEx": "Doshi", "year": 2007}, {"title": "Divide-and-evolve: the marriage of Descartes and Darwin, in \u2018Proceedings of the 7th International Planning Competition (IPC)", "author": ["J. Dr\u00e9o", "P. Sav\u00e9ant", "M. Schoenauer", "V. Vidal"], "venue": null, "citeRegEx": "Dr\u00e9o et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dr\u00e9o et al\\.", "year": 2011}, {"title": "Distributed problem solving and planning, in \u2018Multi-agents Systems and Applications: Selected tutorial papers from the 9th ECCAI Advanced Course (ACAI) and AgentLink\u2019s", "author": ["E.H. Durfee"], "venue": "Third European Agent Systems Summer School (EASSS)\u2019,", "citeRegEx": "Durfee,? \\Q2001\\E", "shortCiteRegEx": "Durfee", "year": 2001}, {"title": "Partial Global Planning: A coordination framework for distributed hypothesis formation", "author": ["E.H. Durfee", "V. Lesser"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Special Issue on Distributed Sensor Networks", "citeRegEx": "Durfee and Lesser,? \\Q1991\\E", "shortCiteRegEx": "Durfee and Lesser", "year": 1991}, {"title": "Deriving consensus in multiagent systems", "author": ["E. Ephrati", "J.S. Rosenschein"], "venue": "Artificial Intelligence", "citeRegEx": "Ephrati and Rosenschein,? \\Q1996\\E", "shortCiteRegEx": "Ephrati and Rosenschein", "year": 1996}, {"title": "STRIPS: A new approach to the application of theorem proving to problem solving", "author": ["R. Fikes", "N. Nilsson"], "venue": "Artificial Intelligence", "citeRegEx": "Fikes and Nilsson,? \\Q1971\\E", "shortCiteRegEx": "Fikes and Nilsson", "year": 1971}, {"title": "Towards dynamic agent interaction support in open multiagent systems, in \u2018Proceedings of the 2010 conference on Artificial Intelligence Research and Development: Proceedings of the 13th International Conference of the Catalan Association for Artificial Intelligence", "author": ["R. Fogu\u00e9s", "J. Alberola", "J. Such", "A. Espinosa", "A. Garcia-Fornes"], "venue": null, "citeRegEx": "Fogu\u00e9s et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Fogu\u00e9s et al\\.", "year": 2010}, {"title": "Preferences and soft constraints in PDDL3, in \u2018ICAPS", "author": ["A. Gerevini", "D. Long"], "venue": "Workshop on Planning with Preferences and Soft Constraints\u2019,", "citeRegEx": "Gerevini and Long,? \\Q2006\\E", "shortCiteRegEx": "Gerevini and Long", "year": 2006}, {"title": "PDDL - the Planning Domain Definition Language", "author": ["M. Ghallab", "A. Howe", "C. Knoblock", "D. McDermott", "A. Ram", "M. Veloso", "D. Weld", "D. Wilkins"], "venue": null, "citeRegEx": "Ghallab et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Ghallab et al\\.", "year": 1998}, {"title": "A framework for sequential planning in multi-agent settings", "author": ["P. Gmytrasiewicz", "P. Doshi"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "Gmytrasiewicz and Doshi,? \\Q2005\\E", "shortCiteRegEx": "Gmytrasiewicz and Doshi", "year": 2005}, {"title": "Some results on the complexity of planning with incomplete information, in \u2018Proceedings of the 5th European Conference on Planning (ECP)", "author": ["P. Haslum", "P. Jonsson"], "venue": null, "citeRegEx": "Haslum and Jonsson,? \\Q1999\\E", "shortCiteRegEx": "Haslum and Jonsson", "year": 1999}, {"title": "The Fast Downward planning system", "author": ["M. Helmert"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "Helmert,? \\Q2006\\E", "shortCiteRegEx": "Helmert", "year": 2006}, {"title": "The FF planning system: Fast planning generation through heuristic search", "author": ["J. Hoffmann", "B. Nebel"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "Hoffmann and Nebel,? \\Q2001\\E", "shortCiteRegEx": "Hoffmann and Nebel", "year": 2001}, {"title": "Scaling up multiagent planning: A best-response approach, in \u2018Proceedings of the 21st International Conference on Automated Planning and Scheduling (ICAPS)", "author": ["A. Jonsson", "M. Rovatsos"], "venue": null, "citeRegEx": "Jonsson and Rovatsos,? \\Q2011\\E", "shortCiteRegEx": "Jonsson and Rovatsos", "year": 2011}, {"title": "Refinement planning as a unifying framework for plan synthesis", "author": ["S. Kambhampati"], "venue": "AI Magazine", "citeRegEx": "Kambhampati,? \\Q1997\\E", "shortCiteRegEx": "Kambhampati", "year": 1997}, {"title": "Monitoring teams by overhearing: A multi-agent plan-recognition approach", "author": ["G.A. Kaminka", "D.V. Pynadath", "M. Tambe"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "Kaminka et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Kaminka et al\\.", "year": 2002}, {"title": "The state of the art in agent communication languages", "author": ["M. Kone", "A. Shimazu", "T. Nakajima"], "venue": "Knowledge and Information Systems", "citeRegEx": "Kone et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Kone et al\\.", "year": 2000}, {"title": "Complete BNF description of PDDL3.1, Technical report", "author": ["D.L. Kovacs"], "venue": null, "citeRegEx": "Kovacs,? \\Q2011\\E", "shortCiteRegEx": "Kovacs", "year": 2011}, {"title": "Beliefs, time and incomplete information in multiple encounter negotiations among autonomous agents", "author": ["S. Kraus"], "venue": "Annals of Mathematics and Artificial Intelligence", "citeRegEx": "Kraus,? \\Q1997\\E", "shortCiteRegEx": "Kraus", "year": 1997}, {"title": "Scalable multiagent planning using probabilistic inference, in \u2018Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI)", "author": ["A. Kumar", "S. Zilberstein", "M. Toussaint"], "venue": null, "citeRegEx": "Kumar et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kumar et al\\.", "year": 2011}, {"title": "Planning for loosely coupled agents using partial order forward-chaining", "author": ["J. Kvarnstr\u00f6m"], "venue": "in \u2018Proceedings of the 21st International Conference on Automated Planning and Scheduling (ICAPS)\u2019,", "citeRegEx": "Kvarnstr\u00f6m,? \\Q2011\\E", "shortCiteRegEx": "Kvarnstr\u00f6m", "year": 2011}, {"title": "Evolution of the GPGP/TAEMS domain-independent coordination framework", "author": ["V. Lesser", "K. Decker", "T. Wagner", "N. Carver", "A. Garvey", "B. Horling", "D. Neiman", "R. Podorozhny", "M. Prasad", "A Raja"], "venue": "Autonomous Agents and Multi-Agent Systems", "citeRegEx": "Lesser et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lesser et al\\.", "year": 2004}, {"title": "Searching for plans with carefully designed probes", "author": ["N. Lipovetzky", "H. Geffner"], "venue": null, "citeRegEx": "Lipovetzky and Geffner,? \\Q2011\\E", "shortCiteRegEx": "Lipovetzky and Geffner", "year": 2011}, {"title": "A framework for simulating real-time multi-agent systems\u2019, Knowledge and information systems", "author": ["C. Micacchi", "R. Cohen"], "venue": null, "citeRegEx": "Micacchi and Cohen,? \\Q2008\\E", "shortCiteRegEx": "Micacchi and Cohen", "year": 2008}, {"title": "Actions and social interactions in multi-agent systems", "author": ["N. Nguyen", "R. Katarzyniak"], "venue": "Knowledge and Information Systems", "citeRegEx": "Nguyen and Katarzyniak,? \\Q2009\\E", "shortCiteRegEx": "Nguyen and Katarzyniak", "year": 2009}, {"title": "Reviving partial order planning, in \u2018Proceedings of the 17th International Joint Conference on Artificial Intelligence (IJCAI)", "author": ["X. Nguyen", "S. Kambhampati"], "venue": null, "citeRegEx": "Nguyen and Kambhampati,? \\Q2001\\E", "shortCiteRegEx": "Nguyen and Kambhampati", "year": 2001}, {"title": "A general, fully distributed multi-agent planning algorithm, in \u2018Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems (AAMAS)", "author": ["R. Nissim", "R. Brafman", "C. Domshlak"], "venue": null, "citeRegEx": "Nissim et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Nissim et al\\.", "year": 2010}, {"title": "Defeasible argumentation for multi-agent planning in ambient intelligence applications, in \u2018Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems (AAMAS)", "author": ["S. Pajares", "E. Onaindia"], "venue": null, "citeRegEx": "Pajares and Onaindia,? \\Q2012\\E", "shortCiteRegEx": "Pajares and Onaindia", "year": 2012}, {"title": "A planning component for RETSINA agents", "author": ["M. Paolucci", "O. Shehory", "K. Sycara", "D. Kalp", "A. Pannu"], "venue": "Intelligent Agents VI. Agent Theories Architectures, and Languages", "citeRegEx": "Paolucci et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Paolucci et al\\.", "year": 2000}, {"title": "Agents that reason and negotiate by arguing", "author": ["S. Parsons", "C. Sierra", "N. Jennings"], "venue": "Journal of Logic and computation", "citeRegEx": "Parsons et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Parsons et al\\.", "year": 1998}, {"title": "UCPOP: A sound, complete, partial order planner for ADL, in \u2018Proceedings of the 3rd International Conference on Principles of Knowledge Representation and Reasoning (KR)", "author": ["J. Penberthy", "D. Weld"], "venue": null, "citeRegEx": "Penberthy and Weld,? \\Q1992\\E", "shortCiteRegEx": "Penberthy and Weld", "year": 1992}, {"title": "The LAMA planner: Guiding cost-based anytime planning with landmarks", "author": ["S. Richter", "M. Westphal"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "Richter and Westphal,? \\Q2010\\E", "shortCiteRegEx": "Richter and Westphal", "year": 2010}, {"title": "The RETSINA multiagent system (video session): towards integrating planning, execution and information", "author": ["K. Sycara", "A. Pannu"], "venue": "gathering, in \u2018Proceedings of the 2nd International Conference on Autonomous Agents (Agents)\u2019,", "citeRegEx": "Sycara and Pannu,? \\Q1998\\E", "shortCiteRegEx": "Sycara and Pannu", "year": 1998}, {"title": "Towards flexible teamwork", "author": ["M. Tambe"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "Tambe,? \\Q1997\\E", "shortCiteRegEx": "Tambe", "year": 1997}, {"title": "A model for integrating dialogue and the execution of joint plans\u2019, Argumentation in Multi-Agent Systems", "author": ["Y. Tang", "T. Norman", "S. Parsons"], "venue": null, "citeRegEx": "Tang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2010}, {"title": "Plan coordination by revision in collective agent based systems", "author": ["H. Tonino", "A. Bos", "M. de Weerdt", "C. Witteveen"], "venue": "Artificial Intelligence", "citeRegEx": "Tonino et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Tonino et al\\.", "year": 2002}, {"title": "Plan repair as an extension of planning, in \u2018Proceedings of the 15th International Conference on Automated Planning and Scheduling (ICAPS)", "author": ["R. Van Der Krogt", "M. De Weerdt"], "venue": null, "citeRegEx": "Krogt and Weerdt,? \\Q2005\\E", "shortCiteRegEx": "Krogt and Weerdt", "year": 2005}, {"title": "An introduction to least commitment planning", "author": ["D. Weld"], "venue": "AI magazine 15(4),", "citeRegEx": "Weld,? \\Q1994\\E", "shortCiteRegEx": "Weld", "year": 1994}, {"title": "Recent advances in AI planning", "author": ["D. Weld"], "venue": "AI Magazine", "citeRegEx": "Weld,? \\Q1999\\E", "shortCiteRegEx": "Weld", "year": 1999}, {"title": "A multiagent planning architecture, in \u2018Proceedings of the 4th International Conference on Artificial Intelligence Planning Systems (AIPS)", "author": ["D. Wilkins", "K. Myers"], "venue": null, "citeRegEx": "Wilkins and Myers,? \\Q1998\\E", "shortCiteRegEx": "Wilkins and Myers", "year": 1998}, {"title": "Online planning for multi-agent systems with bounded communication", "author": ["F. Wu", "S. Zilberstein", "X. Chen"], "venue": "Artificial Intelligence", "citeRegEx": "Wu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2011}, {"title": "VHPOP: Versatile heuristic partial order planner", "author": ["H. Younes", "R. Simmons"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "Younes and Simmons,? \\Q2003\\E", "shortCiteRegEx": "Younes and Simmons", "year": 2003}, {"title": "Graph-based multi-agent replanning algorithm, in \u2018Proceedings of the 6th Conference on Autonomous Agents and Multiagent Systems (AAMAS)", "author": ["J. Zhang", "X. Nguyen", "R. Kowalczyk"], "venue": null, "citeRegEx": "Zhang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 38, "context": "MAP introduces a social approach to planning (Nguyen and Katarzyniak, 2009), focusing on the collective effort of multiple planning entities to accomplish tasks by combining their knowledge, information and capabilities.", "startOffset": 45, "endOffset": 75}, {"referenceID": 16, "context": "This is required when agents are unable to solve their tasks by themselves, or at least can accomplish them better (more quickly, completely, precisely, or certainly) when working with others (Durfee, 2001).", "startOffset": 192, "endOffset": 206}, {"referenceID": 17, "context": "In agent-oriented approaches, the ultimate objective is to ensure that the agents\u2019 local objectives (private goals) will be achieved by their plans and so the emphasis is put on distributed execution, plan synchronization and collaborative activity at runtime planning (Durfee and Lesser, 1991; Tambe, 1997; Kaminka, Pynadath and Tambe, 2002).", "startOffset": 269, "endOffset": 342}, {"referenceID": 47, "context": "In agent-oriented approaches, the ultimate objective is to ensure that the agents\u2019 local objectives (private goals) will be achieved by their plans and so the emphasis is put on distributed execution, plan synchronization and collaborative activity at runtime planning (Durfee and Lesser, 1991; Tambe, 1997; Kaminka, Pynadath and Tambe, 2002).", "startOffset": 269, "endOffset": 342}, {"referenceID": 37, "context": "All in all, these techniques use planning as a means to controlling and coordinating agents rather than building a competent and joint plan, and so they are very appropriate for the design of real-time systems (Micacchi and Cohen, 2008).", "startOffset": 210, "endOffset": 236}, {"referenceID": 13, "context": "Thus, when agents are assumed to be relatively independent, they carry out their planning activities individually and exchange information about their local plans, which they iteratively refine and revise until they fit together in order to ensure that the resulting plan will jointly execute in a coherent and efficient manner (desJardins et al., 1999).", "startOffset": 328, "endOffset": 353}, {"referenceID": 17, "context": "The well-known Partial Global Planning (PGP) framework (Durfee and Lesser, 1991) is one of the first techniques that allows agents to communicate and merge their local plans.", "startOffset": 55, "endOffset": 80}, {"referenceID": 34, "context": "For instance, the work in (Kvarnstr\u00f6m, 2011) considers that agents have sequential threads of execution and interactions only occur when distributing sub-plans to individual agents", "startOffset": 26, "endOffset": 44}, {"referenceID": 6, "context": "The work in (Brafman and Domshlak, 2008) applies individual planning and coordinates the local solutions through the resolution of a Constraint Satisfaction Problem (CSP).", "startOffset": 12, "endOffset": 40}, {"referenceID": 40, "context": "Most of the aforementioned approaches turn out to be inefficient at the time of solving strongly-related problems in which the number of coordination points among agents is large (Nissim et al., 2010).", "startOffset": 179, "endOffset": 200}, {"referenceID": 27, "context": "To deal with these problems, other MAP models use a unified approach in which planning and coordination of activities are integrated rather than being treated as independent processes (Jonsson and Rovatsos, 2011; Belesiotis, Rovatsos and Rahwan, 2010).", "startOffset": 184, "endOffset": 251}, {"referenceID": 7, "context": "In frameworks like those presented in (Brenner and Nebel, 2009; Belesiotis et al., 2010) agents communicate all the available information and build complete knowledge bases, i.", "startOffset": 38, "endOffset": 88}, {"referenceID": 2, "context": "In frameworks like those presented in (Brenner and Nebel, 2009; Belesiotis et al., 2010) agents communicate all the available information and build complete knowledge bases, i.", "startOffset": 38, "endOffset": 88}, {"referenceID": 28, "context": "The key point to address this aspect is to use a refinement planning approach (Kambhampati, 1997) that allows agents to interleave planning and coordination, or more specifically, to coordinate their plans during planning.", "startOffset": 78, "endOffset": 97}, {"referenceID": 39, "context": "More precisely, agents follow the Partial-Order Planning paradigm (Nguyen and Kambhampati, 2001; Younes and Simmons, 2003).", "startOffset": 66, "endOffset": 122}, {"referenceID": 55, "context": "More precisely, agents follow the Partial-Order Planning paradigm (Nguyen and Kambhampati, 2001; Younes and Simmons, 2003).", "startOffset": 66, "endOffset": 122}, {"referenceID": 52, "context": "Single-agent planning is regarded as a search process by which a single entity synthesizes a set of actions (plan) to reach a set of objectives from an initial situation (Weld, 1999).", "startOffset": 170, "endOffset": 182}, {"referenceID": 45, "context": "The most recent planners combine different techniques in order to increase the algorithms efficiency: landmarks (Richter and Westphal, 2010), domain transition graphs (Helmert, 2006), forward-chaining partial-order planning (Coles, Coles, Fox and Long, 2010), probes (Lipovetzky and Geffner, 2011) or divide-and-conquer strategies (Dr\u00e9o, Sav\u00e9ant, Schoenauer and Vidal, 2011), among others.", "startOffset": 112, "endOffset": 140}, {"referenceID": 25, "context": "The most recent planners combine different techniques in order to increase the algorithms efficiency: landmarks (Richter and Westphal, 2010), domain transition graphs (Helmert, 2006), forward-chaining partial-order planning (Coles, Coles, Fox and Long, 2010), probes (Lipovetzky and Geffner, 2011) or divide-and-conquer strategies (Dr\u00e9o, Sav\u00e9ant, Schoenauer and Vidal, 2011), among others.", "startOffset": 167, "endOffset": 182}, {"referenceID": 36, "context": "The most recent planners combine different techniques in order to increase the algorithms efficiency: landmarks (Richter and Westphal, 2010), domain transition graphs (Helmert, 2006), forward-chaining partial-order planning (Coles, Coles, Fox and Long, 2010), probes (Lipovetzky and Geffner, 2011) or divide-and-conquer strategies (Dr\u00e9o, Sav\u00e9ant, Schoenauer and Vidal, 2011), among others.", "startOffset": 267, "endOffset": 297}, {"referenceID": 4, "context": "The work in (Blum and Furst, 1997) introduced the concept of Relaxed Planning Graph, which has proven to be one of the most effective constructs to devise heuristics in state-space planning (Hoffmann and Nebel, 2001).", "startOffset": 12, "endOffset": 34}, {"referenceID": 26, "context": "The work in (Blum and Furst, 1997) introduced the concept of Relaxed Planning Graph, which has proven to be one of the most effective constructs to devise heuristics in state-space planning (Hoffmann and Nebel, 2001).", "startOffset": 190, "endOffset": 216}, {"referenceID": 26, "context": "While state-space planners such as Fast Forward (Hoffmann and Nebel, 2001) are still a relevant research topic, plan-space planning has been replaced by other more efficient techniques.", "startOffset": 48, "endOffset": 74}, {"referenceID": 44, "context": "Among plan-space search algorithms, the Partial-Order Planning (POP) approach (Penberthy and Weld, 1992; Younes and Simmons, 2003) is particularly relevant.", "startOffset": 78, "endOffset": 130}, {"referenceID": 55, "context": "Among plan-space search algorithms, the Partial-Order Planning (POP) approach (Penberthy and Weld, 1992; Younes and Simmons, 2003) is particularly relevant.", "startOffset": 78, "endOffset": 130}, {"referenceID": 51, "context": "POP is based on the least commitment strategy (Weld, 1994), which defers planning", "startOffset": 46, "endOffset": 58}, {"referenceID": 8, "context": "Although some recent works reformulate the basic algorithm to improve its performance (Coles et al., 2010), POP has been discontinued by the planning community in favor of other approaches.", "startOffset": 86, "endOffset": 106}, {"referenceID": 5, "context": "Nevertheless, it is still used in temporal planning and MAP environments as it is a flexible paradigm to handle concurrency (Boutilier and Brafman, 2001).", "startOffset": 124, "endOffset": 153}, {"referenceID": 13, "context": "MAP can be viewed as the problem of coordinating agents in a shared environment where information is distributed (desJardins et al., 1999).", "startOffset": 113, "endOffset": 138}, {"referenceID": 16, "context": "In general, solving a cooperative MAP task involves the following stages (Durfee, 2001): 1) global goal refinement, 2) task allocation, 3) coordination before planning, 4) individual planning, 5) coordination after planning, and 6) plan execution.", "startOffset": 73, "endOffset": 87}, {"referenceID": 2, "context": "For instance, some works do not distribute the goals explicitly (avoiding stage 2) (Belesiotis et al., 2010; Brenner and Nebel, 2009), while others apply only coordination after planning (avoiding stage 3) (Van Der Krogt and De Weerdt, 2005; Cox, Durfee and Bartold, 2005).", "startOffset": 83, "endOffset": 133}, {"referenceID": 7, "context": "For instance, some works do not distribute the goals explicitly (avoiding stage 2) (Belesiotis et al., 2010; Brenner and Nebel, 2009), while others apply only coordination after planning (avoiding stage 3) (Van Der Krogt and De Weerdt, 2005; Cox, Durfee and Bartold, 2005).", "startOffset": 83, "endOffset": 133}, {"referenceID": 6, "context": "MAP problems can be classified according to their coupling level, a measure of the number of interactions or coordination points among agents that will arise during the task resolution (Brafman and Domshlak, 2008).", "startOffset": 185, "endOffset": 213}, {"referenceID": 16, "context": "This way, these frameworks perform the planning and coordination stages independently and separately, combining or merging solutions into a global joint plan (Durfee, 2001; de Weerdt and Clement, 2009; Tonino, Bos, de Weerdt and Witteveen, 2002; Kaminka et al., 2002).", "startOffset": 158, "endOffset": 267}, {"referenceID": 29, "context": "This way, these frameworks perform the planning and coordination stages independently and separately, combining or merging solutions into a global joint plan (Durfee, 2001; de Weerdt and Clement, 2009; Tonino, Bos, de Weerdt and Witteveen, 2002; Kaminka et al., 2002).", "startOffset": 158, "endOffset": 267}, {"referenceID": 17, "context": "The Partial Global Planning framework (Durfee and Lesser, 1991) and its extension, the Generalized Partial Global Planning approach (Decker and Lesser, 1992), allow agents to communicate their local plans to the rest of agents and then they merge this information into their own partial global plan in order to improve it.", "startOffset": 38, "endOffset": 63}, {"referenceID": 12, "context": "The Partial Global Planning framework (Durfee and Lesser, 1991) and its extension, the Generalized Partial Global Planning approach (Decker and Lesser, 1992), allow agents to communicate their local plans to the rest of agents and then they merge this information into their own partial global plan in order to improve it.", "startOffset": 132, "endOffset": 157}, {"referenceID": 49, "context": "The work in (Tonino et al., 2002) proposes a post-planning coordination approach based on the iterative revision of the agents\u2019 local plans.", "startOffset": 12, "endOffset": 33}, {"referenceID": 40, "context": "(Nissim et al., 2010) introduces a cooperative MAP approach for loosely-coupled systems in which agents carry out planning individually through a state-based planner (Hoffmann and Nebel, 2001; Coles, Fox, Long and Smith, 2008).", "startOffset": 0, "endOffset": 21}, {"referenceID": 26, "context": ", 2010) introduces a cooperative MAP approach for loosely-coupled systems in which agents carry out planning individually through a state-based planner (Hoffmann and Nebel, 2001; Coles, Fox, Long and Smith, 2008).", "startOffset": 152, "endOffset": 212}, {"referenceID": 18, "context": "Other proposals deal with insincere agents by combining planning, coordination, and execution (Ephrati and Rosenschein, 1996) or consider the communication needs that arise when plans are being executed (Tang, Norman and Parsons, 2010).", "startOffset": 94, "endOffset": 125}, {"referenceID": 40, "context": "On the other hand, the previous merging approaches have proven to be inefficient when solving strongly-related problems in which most of the resources are shared and most of the goals require cooperation among agents (Nissim et al., 2010).", "startOffset": 217, "endOffset": 238}, {"referenceID": 13, "context": "The proposal in (desJardins et al., 1999) applies the continual planning approach, which interleaves planning and execution and coordinates agents by synchronizing them at execution time (Brenner and Nebel, 2009).", "startOffset": 16, "endOffset": 41}, {"referenceID": 7, "context": ", 1999) applies the continual planning approach, which interleaves planning and execution and coordinates agents by synchronizing them at execution time (Brenner and Nebel, 2009).", "startOffset": 153, "endOffset": 178}, {"referenceID": 27, "context": "The approach in (Jonsson and Rovatsos, 2011) introduces the best-response planning algorithm, which iteratively improves the quality of the agents\u2019 plans through single-agent planning technology.", "startOffset": 16, "endOffset": 44}, {"referenceID": 2, "context": "Finally, the works in (Belesiotis et al., 2010; Pajares and Onaindia, 2012) solve inconsistencies among agents\u2019 plans through a coordination protocol based on iterated dialogues.", "startOffset": 22, "endOffset": 75}, {"referenceID": 41, "context": "Finally, the works in (Belesiotis et al., 2010; Pajares and Onaindia, 2012) solve inconsistencies among agents\u2019 plans through a coordination protocol based on iterated dialogues.", "startOffset": 22, "endOffset": 75}, {"referenceID": 24, "context": "Planning with incomplete information has several different meanings: that certain facts of the initial state are not known, that operators can have random or nondeterministic effects, or that the plans built contain sensing operations and are branching (Haslum and Jonsson, 1999).", "startOffset": 253, "endOffset": 279}, {"referenceID": 32, "context": "The issue of incomplete information has been treated from two different perspectives: the probabilistic way, with the development of formal models such as Dec-POMDPs (Decentralized Partial Observable Markov Decision Processes) for coordination among multiple agents in contexts with partial observability (Wu, Zilberstein and Chen, 2011; Kumar, Zilberstein and Toussaint, 2011); and the epistemological way, which assumes that agents have beliefs about the state of the world and beliefs over the other agents\u2019 knowledge (Kraus, 1997; Doshi, 2007).", "startOffset": 521, "endOffset": 547}, {"referenceID": 14, "context": "The issue of incomplete information has been treated from two different perspectives: the probabilistic way, with the development of formal models such as Dec-POMDPs (Decentralized Partial Observable Markov Decision Processes) for coordination among multiple agents in contexts with partial observability (Wu, Zilberstein and Chen, 2011; Kumar, Zilberstein and Toussaint, 2011); and the epistemological way, which assumes that agents have beliefs about the state of the world and beliefs over the other agents\u2019 knowledge (Kraus, 1997; Doshi, 2007).", "startOffset": 521, "endOffset": 547}, {"referenceID": 23, "context": "This latter approach has been widely used in games of incomplete information (Gmytrasiewicz and Doshi, 2005).", "startOffset": 77, "endOffset": 108}, {"referenceID": 53, "context": "The work in (Wilkins and Myers, 1998) presents a complete MAP architecture for large-scale problem solving, which organizes agents into planning cells committed to a particular planning process.", "startOffset": 12, "endOffset": 37}, {"referenceID": 46, "context": "For instance, the domain-independent multiagent system infrastructure RETSINA (Sycara and Pannu, 1998) introduced a planning component (Paolucci, Shehory, Sycara, Kalp and Pannu, 2000).", "startOffset": 78, "endOffset": 102}, {"referenceID": 28, "context": "More precisely, we combine a distributed refinement planning procedure (Kambhampati, 1997) and an individual Partial-Order Planning (POP) (Nguyen and Kambhampati, 2001; Younes and Simmons, 2003).", "startOffset": 71, "endOffset": 90}, {"referenceID": 39, "context": "More precisely, we combine a distributed refinement planning procedure (Kambhampati, 1997) and an individual Partial-Order Planning (POP) (Nguyen and Kambhampati, 2001; Younes and Simmons, 2003).", "startOffset": 138, "endOffset": 194}, {"referenceID": 55, "context": "More precisely, we combine a distributed refinement planning procedure (Kambhampati, 1997) and an individual Partial-Order Planning (POP) (Nguyen and Kambhampati, 2001; Younes and Simmons, 2003).", "startOffset": 138, "endOffset": 194}, {"referenceID": 31, "context": "1 -based MAP specification language (Kovacs, 2011) defines this partial visibility of the agents, allowing to specify which information can be shared with other agents for cooperation purposes.", "startOffset": 36, "endOffset": 50}, {"referenceID": 56, "context": "Agents exchange the shareable information with other agents through the construction of a distributed Relaxed Planning Graph (Zhang et al., 2007) and perform planning while being partially unaware of the other agents\u2019 knowledge.", "startOffset": 125, "endOffset": 145}, {"referenceID": 20, "context": "The developed MAP system uses the Magentix2 MAS platform (Fogu\u00e9s et al., 2010) as its communication infrastructure.", "startOffset": 57, "endOffset": 78}, {"referenceID": 19, "context": "As opposite to STRIPS-like models (Fikes and Nilsson, 1971), which apply negation by failure (only positive fluents are represented, the absence of a fluent implies its negation), we allow to explicitly represent both true and false information.", "startOffset": 34, "endOffset": 59}, {"referenceID": 21, "context": "Private goals are encoded as soft constraints (Gerevini and Long, 2006), as it is not mandatory that agents achieve them.", "startOffset": 46, "endOffset": 71}, {"referenceID": 28, "context": "Our MAP model can be regarded as a multi-agent refinement planning framework, a general method based on the refinement of the set of all possible plans (Kambhampati, 1997).", "startOffset": 152, "endOffset": 171}, {"referenceID": 1, "context": "In this context, Partial-Order Planning (POP) (Barrett and Weld, 1994)", "startOffset": 46, "endOffset": 70}, {"referenceID": 7, "context": "Some MAP models adopt a simple form of concurrency: two concurrent actions are mutually consistent if none of them changes the value of a state variable that the other relies on or affects, too (Brenner and Nebel, 2009).", "startOffset": 194, "endOffset": 219}, {"referenceID": 5, "context": "We impose the additional concurrency constraint that the preconditions of two actions have to be consistent (Boutilier and Brafman, 2001) for these two actions to be mutually consistent.", "startOffset": 108, "endOffset": 137}, {"referenceID": 31, "context": "1 (Kovacs, 2011), the most recent version of PDDL (Ghallab, Howe, Knoblock, McDermott, Ram, Veloso, Weld and Wilkins, 1998), which was introduced in the context of the 2008 International Planning Competition.", "startOffset": 2, "endOffset": 16}, {"referenceID": 56, "context": "This initial stage builds a distributed Relaxed Planning Graph (dis-RPG), whose construction is inspired by the approach in (Zhang et al., 2007).", "startOffset": 124, "endOffset": 144}, {"referenceID": 56, "context": "Unlike the proposal in (Zhang et al., 2007), which stops the graph construction once all the problem goals appear in the graph, our procedure builds a complete dis-RPG by maintaining the incomplete information of the agents, so they only exchange the information defined as shareable in the input files (see section 6).", "startOffset": 23, "endOffset": 43}, {"referenceID": 26, "context": "Agents compute this initial planning graph by following the procedure presented in (Hoffmann and Nebel, 2001).", "startOffset": 83, "endOffset": 109}], "year": 2015, "abstractText": "Multi-agent planning (MAP) approaches are typically oriented at solving loosely-coupled problems, being ineffective to deal with more complex, strongly-related problems. In most cases, agents work under complete information, building complete knowledge bases. The present article introduces a general-purpose MAP framework designed to tackle problems of any coupling levels under incomplete information. Agents in our MAP model are partially unaware of the information managed by the rest of agents and share only the critical information that affects other agents, thus maintaining a distributed vision of the task. Agents solve MAP tasks through the adoption of an iterative refinement planning procedure that uses single-agent planning technology. In particular, agents will devise refinements through the Partial-Order Planning paradigm, a flexible framework to build refinement plans leaving unsolved details that will be gradually completed by means of new refinements. Our proposal is supported with the implementation of a fullyoperative MAP system and we show various experiments when running our system over different types of MAP problems, from the most strongly-related to the most loosely-coupled.", "creator": "LaTeX with hyperref package"}}}