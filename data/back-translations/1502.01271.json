{"id": "1502.01271", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Feb-2015", "title": "INRIASAC: Simple Hypernym Extraction Methods", "abstract": "This is the task 17 of SemEval 2015. Here we present our simple taxonomic structuring techniques that, despite their simplicity, came first in this benchmark 2015. We use large amounts of text (Wikipedia) and simple heuristics such as term overlaps and the incidence of documents and sentences to create hypernymlists. We describe these techniques and send a preliminary evaluation of the results in advance.", "histories": [["v1", "Wed, 4 Feb 2015 17:53:01 GMT  (318kb)", "http://arxiv.org/abs/1502.01271v1", "submitted to SemEval 2015"], ["v2", "Wed, 6 Jan 2016 09:05:18 GMT  (309kb)", "http://arxiv.org/abs/1502.01271v2", "SemEval 2015, Jun 2015, Denver, United States"]], "COMMENTS": "submitted to SemEval 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["gregory grefenstette"], "accepted": false, "id": "1502.01271"}, "pdf": {"name": "1502.01271.pdf", "metadata": {"source": "CRF", "title": "INRIASAC: Simple Hypernym Extraction Methods", "authors": ["Gregory Grefenstette"], "emails": ["Gregory.grefenstette@inria.fr"], "sections": [{"heading": null, "text": "how can we structure them into a taxonomy without manual intervention? This is the task 17 of SemEval 2015. Here we present our simple taxonomy structuring techniques which, despite their simplicity, ranked first in this 2015 benchmark. We use large quantities of text (English Wikipedia) and simple heuristics such as term overlap and document and sentence co-occurrence to produce hypernym lists. We describe these techniques and present an initial evaluation of results."}, {"heading": "1 Introduction", "text": "This paper describes the simple hypernym extraction methods implemented in this first participation of Inria in the Semeval campaigns. We participated in task 17 of the 2015 Semeval campaign (Bordea et al., 2015). This task consists in structuring a list of pre-identified domain terms into a list of hypernym pairs. List of terms automatically identified for four domains (equipment; food, chemical, science) were provided by the task organisers. For each domain, two lists were provided, one extracted from WordNet and one from on other source, making eight lists in all. Using any resources, the participants were invited to return eight lists of pairs of terms, in which the first term was a hyponym of the second term. For example, if the words airship and blimp were included in the list of terms for a domain, the system was expected to return lines such as: 25 blimp airship\ner). Given the domain terms lists by the task organizers, we used Wikipedia (downloaded from http://dumps.wikimedia.org on August 13, 2014) as our only resource for discovering these relations. From the download source, we only extracted the text of articles, leaving out any categories, infoboxes, or other typed information.\nThe campaign organizers provided training data from the domains of Artificial Intelligence, vehicules and plants, different from the test domains. The training data consisted in term lists (for plants), and term lists and lists of hypernyms (for AI and for vehicles). We examined these files to get an understanding of the task but did not process them in any way."}, {"heading": "2 Domain Lists", "text": "We were provided with the following lists of domain terms, with no explanation of how they were created (though WN stands for WordNet): chemical.terms: agarose, nickel sulfate heptahydrate, aminoglycan, pinoquercetin, lupanine, \u2026 equipment.terms: storage equipment, strapping, traveling microscope, minneapolis-moline, \u2026 food.terms: sauce gribiche, botifarra, phitti, food colouring, bean, limequat, kalach, \u2026 science.terms: electro-mechanical systems, biological and physical, history of religions of eastern origins, linguistic anthropology, metaphysics, religion, semantics, \u2026 WN_chemical.terms: abo antibodies, acaricide, acaroid resin, acceptor, acetal, acetaldehyde, acetaldol, acetamide, acetate, acetic acid, \u2026 WN_equipment.terms: acoustic modem, aerator, air search radar, amplifier, anti submarine rocket, apishamore, apparatus, astronomy satellite, atomic pile, audio amplifier, \u2026\nWN_food.terms: absinth, acidophilus milk, adobo, agar, aioli, alcohol, ale, alfalfa, allemande, allergy diet, \u2026 WN_science.terms: abnormal psychology, acoustics, aerology, aeromechanics, aeronautics, \u2026\nThe lists contained between 370 and 1555 terms. Terms consisted of one to nine words. Shortest terms: ga, os, tu, ada, aji, \u2026. Longest\nterms: in characters: udp-n-acetyl-alpha-dmuramoyl-l-alanyl-gamma-d-glutamyl-l-\nlysyl-d-alanyl-d-alanine, and in words: korea advanced institute of science\nand technology satellite 4. It is specified that the taxonomies produced during the task\nshould be rooted on chemical for the two chemi-\ncal domain lists, on equipment for the equipment\nlists, on food for the food lists, and on science\nfor the science lists, even though the term chemi-\ncal was absent from the domain list WN_chemical.terms. Participants were allowed to \u201cadd additional nodes, i.e. terms, in the hierarchy as they consider appropriate.\u201d We did not add any new terms, except for chemical in the WN_chemical list."}, {"heading": "2.1 Preprocessing the resource", "text": "Our only resource for discovering hypernym relations was the English Wikipedia. Starting from the wiki-latest-pages-articles.xml, we extracted all the text between <text> markers, and marked off document boundaries using <title> markers. The text was then tokenized (Grefenstette, 1999) and output as one sentence per line, using our own programs. The first English Wikipedia sentence extracted looked like this: ' Anarchism ' is a political philosophy that advocates stateless societies often \u2026 based on non-\nhierarchical free associations . As mentioned, no other information (infoboxes, categories, etc.) was kept. We further applied Porter stemming (Willet, 2006) and stopword removal (Buckley et al., 1995) (replaced by underscores). The lowercased first sentence, then, looked like:\nanarch _ _ _ polit philosophi _ advoc stateless societi _ defin _ self-govern voluntari institut _ _ _ sever author _ defin _ _ specif institut base _ non-hierarch free associ _\nWe also applied the same Porter stemming and stopword removal to the task-supplied domain terms. So that science.terms, for example, becomes 0 electro-mechan system 1 biolog _ physic 2 histori _ religion _ eastern origin 3 linguist anthropolog 4 metaphys\nWe retained both the Porter stemmed versions of the Wikipedia sentences and domain terms as well as the original unstemmed versions for the treatment described below."}, {"heading": "3 Extracting Hypernyms", "text": "In order to extract hypernyms, we used the following features: (i) presence of terms in the same sentence, (ii) presence in the same document (iii) term frequency (iv) document frequency, and (v) subsequences."}, {"heading": "3.1 Subterms", "text": "In addition to domain lists supplied for the Semeval task, we were supplied with training data. One file in this training data, ontolearn_AX.taxo, gives ground truth for the training file ontolearn_AX.terms, and contains: 42 source code code 2251 theory of inheritance theory\nFrom these validated examples, we concluded that an \u201eeasy\u201f way to find hypernyms is to check whether one term is a suffix of the other (e.g.,\ncommunications satellite as a type of satellite), or whether one term B is the prefix of another term B A C where A is any two-letter word (e.g. helmet of co\u0163ofene\u015fti as a type of\nhelmet; caterpillar d9 as a type of ca-\nterpillar). This heuristic was unexpectedly productive in the chemical domain where many hypernym pairs were similar to: ginsenoside\nmc as a type of ginsenoside.\nWe did not attempt to generalize the prefix matching to second words of length different from two, and so we missed hypernyms such as fortimicin\nb as a type of fortimicin or ginsenoside\nc-y as a type of ginsenoside.\nOther examples of errors, false positives, caused by these heuristics are licorice as a type of\nrice or surface to air missile system\nas a type of surface, but they are often correct, so any terms in these relations were kept as hypernym pairs without any filtering."}, {"heading": "3.2 Sentence and Document Co-occurrence Statistics", "text": "Any domain terms produced as possible hyponyms by the prefix or the suffix heuristic were no longer considered. For the remaining terms (which could, of course, include the hypernyms found by the suffix and prefix heuristics), we decided, after trying a number of alternatives described in the next section below, to use the statistics of document presence, and of co-occurrence of terms in sentences to predict hypernym relations.\nLet Dporter(term) be the document frequency of a Poter-stemmed term in the stemmed version of Wikipedia. Since Wikipedia article boundaries were stored, we considered each Wikipedia article as a new document.\nLet SentCoocporter(termi, termj) be the number of times that the Porter-stemmed versions of termi and termj appear in the same sentence in the stemmed English Wikipedia.\nGiven two terms, termi and termj, we decided that if termi is appears in more documents than termj, then termi is a candidate hypernym for termj.\nCandHypenym(termi) = { termj :\nSentCoocporter(termi, termj) > 0 && Dporter(termj) > Dporter(termi) }\nThis heuristically derived set is meant to capture the intuition that general terms are more widely\ndistributed than more specific terms (e.g., dog ap-\npears in more Wikipedia than poodle).\nNext define the best candidate for termi as being the term termk that appears in the most documents (the most articles in Wikipedia, here):\nBestHypernym(termi) = termk\nsuch that \u2200 termj \u2208 CandHypernym(termi) : Dporter(termk) \u2265 Dporter(termj)\nNext, we removed this term termk from CandHypernym(termi) and repeated the choice twice, retaining, then, the three candidate hypernyms\nappearing in the most documents for each term not found by using the prefix or suffix heuristics."}, {"heading": "3.2.1 Co-occurrence Example", "text": "Consider the following example. In the domain file\nscience.terms there is the term biblical stu-\ndies. The Porter-stemmed version of this term\nbiblic studi appears in 887 sentences. Considering all the other terms in science.terms, we find that biblic studi appears 215 times in the same sentence as the stemmed version of theology (theologi), 111 times in the same sentences as\nstemmed history (histori), 50 times with religion, 43 times with music, and 42 times with\nscience (scienc).\n215 887 21977 biblic studi theologi 111 887 383927 biblic studi histori 50 887 64044 biblic studi religion 43 887 412791 biblic studi music 42 887 224983 biblic studi scienc\nWe decided to keep the top three for simplicity, so this term contributed three lines to our submitted science.taxo file: 121 biblical studies history 122 biblical studies religion 123 biblical studies theology"}, {"heading": "3.3 Other Attempts at Finding Relations", "text": "We tried a number of other methods to find hypernyms, none of which gave satisfaction by looking at the results. We implemented a method to recog-\nnize sentences containing Hearst patterns (list from (Cimiano et al., 2005)) involving the domain\nterms. For example, tape is in equipment.terms, and were able to find stemmed sentences of the form A, B and other C \u2026 such as todai , sticki note , 3m #tape# @, and other@ #tape# ar exampl of psa ( pressure-\nsensit adhes ) from which we should have\nbeen able to extract relations such as 3m tape is a\ntype of tape, and sticky note is a type of\ntape. But we would have had to the parse the sentence, and been willing to add new terms (which was permitted by the organizers, to the derived hypernym lists) but in our first participation in Semeval, we did not want to make that processing investment yet.\nWe tried to discover the basic vocabulary (Kit, 2002) of each domain by counting the number of times that each term appeared in Wikipedia in the set phrase A, such as. For example, using all the terms from equipment.terms, we found\n225 instances of equipment, such as\n24 instances of internet, such as\n4 instances of telescop, such as\n2 instances of manual, such as\n2 instances of manipul, such as\nBut this did not seem very useful or productive."}, {"heading": "4 Evaluation", "text": "Each participant in Task 17 of SemEval 2015 was allowed to submit one run for each of the 8 domains (see Table 1 for the names of the domains, and the number of hypernym pairs we submitted). The task organizers evaluated the submissions of the six participating teams, using automated and manual methods, and published their evaluation three weeks after the submission deadline. Our team placed first in the official ranking of the six teams.\nThe evaluation criteria, which were not published before the submission, combined the presences of cycles in the hypernyms submitted, the Fowlkes & Mallows measure of the overlap between the submitted, the F-score ranking, the number of domains submitted (not all teams returned results for all domains), and a manual precision ranking (for hypernyms not present in the gold standard). The gold standards used by the task organizers came\nfrom published taxonomies, or from subtrees of WordNet (prefixed as WN_ above). Here is a quick evaluation of how well our simple hypernym extraction techniques fared on each gold standard in Table 2.\nstandard relations found by each technique. \u201cunion\u201d is the union of columns 2, 3 and 4. Since the cooccurrence technique can find relations that have been found by the suffix and prefix techniques."}, {"heading": "5 Conclusion", "text": "Even though training data was provided for this taxonomy creation task, we did not exploit it in this our first participation in Semeval. We implemented some simple frequency-based co-occurrence statistics, and substring inclusion heuristics to propose a set of hypernyms. We did not implement any graph algorithms (cycle detection, branch deletion) that would be useful to build a true hierarchy. We hope to learn from interaction from the other participants what paths to explore in the future to improve recall."}, {"heading": "Acknowledgments", "text": "This research is partially funded by a research grant from INRIA, and from the Paris-Saclay Institut de la Soci\u00e9t\u00e9 Num\u00e9rique funded by the IDEX Paris-Saclay, ANR-11-IDEX-0003-02."}], "references": [{"title": "Semeval-2015 task 17: Taxonomy Extraction Evaluation", "author": ["Georgeta Bordea", "Paul Buitelaar", "Stefano Faralli", "Roberto Navigli."], "venue": "Proceedings of the 9th International Workshop on Semantic Evaluation. Association for Computational Linguistics", "citeRegEx": "Bordea et al\\.,? 2015", "shortCiteRegEx": "Bordea et al\\.", "year": 2015}, {"title": "Automatic query expansion using SMART: TREC3", "author": ["Chris Buckley", "Gerard Salton", "James Allan", "Amit Singhal."], "venue": "Proceedings of the 3rd Text REtrieval Conference (TREC-3). NIST Special Publication 500\u2013226. National Institute of Standards and", "citeRegEx": "Buckley et al\\.,? 1995", "shortCiteRegEx": "Buckley et al\\.", "year": 1995}, {"title": "Learning taxonomic relations from heterogeneous sources of evidence", "author": ["Philipp Cimiano", "Aleksander Pivk", "Lars SchmidtThieme", "Steffen Staab."], "venue": "Ontology Learning from Text: Methods, evaluation and applications. IoS Press.", "citeRegEx": "Cimiano et al\\.,? 2005", "shortCiteRegEx": "Cimiano et al\\.", "year": 2005}, {"title": "Tokenization", "author": ["Gregory Grefenstette."], "venue": "Syntactic Wordclass Tagging. Springer Netherlands, pp. 117133.", "citeRegEx": "Grefenstette.,? 1999", "shortCiteRegEx": "Grefenstette.", "year": 1999}, {"title": "Corpus tools for retrieving and deriving termhood evidence", "author": ["Chunyu Kit."], "venue": "Proceedings of the 5th East Asia Forum of Terminology, pp. 69-80.", "citeRegEx": "Kit.,? 2002", "shortCiteRegEx": "Kit.", "year": 2002}, {"title": "The Porter stemming algorithm: then and now", "author": ["Peter Willett."], "venue": "Program 40(3): 219-223.", "citeRegEx": "Willett.,? 2006", "shortCiteRegEx": "Willett.", "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "We participated in task 17 of the 2015 Semeval campaign (Bordea et al., 2015).", "startOffset": 56, "endOffset": 77}, {"referenceID": 3, "context": "The text was then tokenized (Grefenstette, 1999) and output as one sentence per line, using our own programs.", "startOffset": 28, "endOffset": 48}, {"referenceID": 1, "context": "We further applied Porter stemming (Willet, 2006) and stopword removal (Buckley et al., 1995) (replaced by underscores).", "startOffset": 71, "endOffset": 93}, {"referenceID": 2, "context": "nize sentences containing Hearst patterns (list from (Cimiano et al., 2005)) involving the domain terms.", "startOffset": 53, "endOffset": 75}, {"referenceID": 4, "context": "We tried to discover the basic vocabulary (Kit, 2002) of each domain by counting the number of times that each term appeared in Wikipedia in the set phrase A, such as.", "startOffset": 42, "endOffset": 53}], "year": 2015, "abstractText": "Given a set of terms from a given domain, how can we structure them into a taxonomy without manual intervention? This is the task 17 of SemEval 2015. Here we present our simple taxonomy structuring techniques which, despite their simplicity, ranked first in this 2015 benchmark. We use large quantities of text (English Wikipedia) and simple heuristics such as term overlap and document and sentence co-occurrence to produce hypernym lists. We describe these techniques and present an initial evaluation of results.", "creator": "Microsoft\u00ae Office Word 2007"}}}