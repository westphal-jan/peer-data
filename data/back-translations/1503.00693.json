{"id": "1503.00693", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2015", "title": "Bayesian Optimization of Text Representations", "abstract": "When applying machine learning to NLP problems, there are many ways in which input texts can be represented. These decisions can have a big impact on performance, but are often of little interest to researchers or practitioners who simply need a powerful module. We propose an approach to optimization in this area and formulate the problem as global optimization. We apply a sequential model-based optimization technique and show that our method makes standard linear models competitive against more complex, expensive state-of-the-art methods based on latent variable models or neural networks on various topic classification and sentiment analysis issues. Our approach is a first step toward black box NLP systems that work with raw text and do not require manual coordination.", "histories": [["v1", "Mon, 2 Mar 2015 20:23:18 GMT  (215kb,D)", "http://arxiv.org/abs/1503.00693v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG stat.ML", "authors": ["dani yogatama", "lingpeng kong", "noah a smith"], "accepted": true, "id": "1503.00693"}, "pdf": {"name": "1503.00693.pdf", "metadata": {"source": "CRF", "title": "Bayesian Optimization of Text Representations", "authors": ["Dani Yogatama", "Noah A. Smith"], "emails": ["dyogatama@cs.cmu.edu", "nasmith@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "NLP researchers and practitioners spend a considerable amount of time comparing machine-learned models of text that differ in relatively uninteresting ways. For example, in categorizing texts, should the \u201cbag of words\u201d include bigrams, and is tf-idf weighting a good idea? These choices matter experimentally, often leading to big differences in performance, with little consistency across tasks and datasets in which combination of choices works best. Unfortunately, these differences tell us little about language or the problems that machine learners are supposed to solve.\nWe propose that these decisions can be automated in a similar way to hyperparameter selection (e.g., choosing the strength of a ridge or lasso regularizer). Given a particular text dataset and classification task, we introduce a technique for optimizing over the space of representational choices,\nalong with other \u201cnuisances\u201d that interact with these decisions, like hyperparameter selection.1 For example, using higher-order n-grams means more features and a need for stronger regularization and more training iterations. Generally, these decisions about instance representation are made by humans, heuristically; our work is the first to automate them.\nOur technique instantiates sequential modelbased optimization (SMBO; Hutter et al., 2011). SMBO and other Bayesian optimization approaches have been shown to work well for hyperparameter tuning (Bergstra et al., 2011; Hoffman et al., 2011; Snoek et al., 2012). Though popular in computer vision (Bergstra et al., 2013), these techniques have received little attention in NLP.\nWe apply the technique to logistic regression on a range of topic and sentiment classification tasks. Consistently, our method finds representational choices that perform better than linear baselines previously reported in the literature, and that, in some cases, are competitive with more sophisticated non-linear models trained using neural networks."}, {"heading": "2 Problem Formulation and Notation", "text": "Let the training data consist of a collection of pairs dtrain = \u3008\u3008d.i1, d.o1\u3009, . . . , \u3008d.in, d.on\u3009\u3009, where each input d.i \u2208 I is a text document and each output d.o \u2208 O, the output space. The overall training goal is to maximize a performance function f (e.g., classification accuracy, log-likelihood, F1 score, etc.) of a machine-learned model, on a held-out dataset, ddev \u2208 (I\u00d7 O)n \u2032 .\nClassfication proceeds in three steps: first, x : I\u2192 RN maps each input to a vector representation. Second, a classifier is learned from the inputs (now transformed into vectors) and outputs: L : (RN \u00d7 O)n \u2192 (RN \u2192 O). Finally, the resulting classifier\n1In \u00a75 we argue that the technique is also applicable in unsupervised settings.\nar X\niv :1\n50 3.\n00 69\n3v 1\n[ cs\n.C L\n] 2\nM ar\n2 01\n5\nc : I\u2192 O is fixed as\nL(dtrain) \u25e6 x O\u2190 RN RN \u2190 I\n(i.e., the composition of the representation function with the learned classifier).\nHere we consider linear classifiers of the form\nc(d.i) = argmax o\u2208O\nw>o x(d.i) (1)\nwhere the coefficients wo \u2208 RN , for each output o, are learned using logistic regression on the training data. We let w denote the concatenation of all wo. Hence the parameters can be understood as a function of the training data and the representation function x. The performance function f , in turn, is a function of the held-out data ddev and x\u2014also w and dtrain , through x. For simplicity, we will write \u201cf(x)\u201d when the rest are clear from context.\nTypically, x is fixed by the model designer, perhaps after some experimentation, and learning focuses on selecting the parameters w. For logistic regression and many other linear models, this training step reduces to convex optimization in N |O| dimensions\u2014a solvable problem that is still costly for large datasets and/or large output spaces. In seeking to maximize f with respect to x, we do not wish to carry out training any more times than necessary.\nChoosing x can be understood as a problem of selecting hyperparameter values. We therefore turn to Bayesian optimization, a family of techniques recently introduced for selecting hyperparameter values intelligently when solving for parameters (w) is costly."}, {"heading": "3 Bayesian Optimization", "text": "Our approach is based on sequential model-based optimization (SMBO; Hutter et al., 2011). It iteratively chooses representation functions x. On each round, it makes this choice through a nonparametrically-estimated probabilistic model of f , then evaluates f\u2014we call this a \u201ctrial.\u201d As in any iterative search algorithm, the goal is to balance exploration of options for x with exploitation of previously-explored options, so that a good choice is found in a small number of trials. See Algorithm 1.\nMore concretely, in the tth trial, xt is selected using an acquisition function A and a \u201csurrogate\u201d probabilistic model pt. Second, f is evaluated\ngiven xt\u2014an expensive operation which involves training to select parameters w and assessing performance on the held-out data. Third, the probabilistic model is updated using a nonparametric estimator.\nAlgorithm 1 SMBO algorithm Input: number of trials T , target function f p1 = initial surrogate model Initialize y\u2217\nfor t = 1 to T do xt \u2190 argmaxx A(x; pt, y\u2217) yt \u2190 evaluate f(xt) Update y\u2217\nEstimate pt given x1:t and y1:t end for\nWe next describe the acquisition function A and the surrogate model pt used in our experiments."}, {"heading": "3.1 Acquisition Function", "text": "A good acquisition function returns high values for x such that either the value f(x) is predicted to be high, or because uncertainty about f(x)\u2019s value is high; balancing between these is the classic tradeoff between exploitation and exploration. We use a criterion called Expected Improvement (EI; Jones, 2001), which is the expectation (under the current surrogate model pt) that the choice y will exceed y\u2217:\nA(x; pt, y \u2217) = \u222b \u221e \u2212\u221e max(y \u2212 y\u2217, 0)pt(y | x)dy\nwhere y\u2217 is chosen depending on the surrogate model, discussed below. (For now, think of it as a strongly-performing \u201cbenchmark\u201d value of f , discovered in earlier iterations.) Other options for the acquisition function include maximum probability of improvement (Jones, 2001), minimum conditional entropy (Villemonteix et al., 2006), Gaussian process upper confidence bound (Srinivas et al., 2010), or a combination of them (Hoffman et al., 2011). We selected EI because it is the most widely used acquisition function that has been shown to work well on a range of tasks."}, {"heading": "3.2 Surrogate Model", "text": "As a surrogate model, we use a tree-structured Parzen estimator (TPE; Bergstra et al., 2011). This is a nonparametric approach to density estimation. We seek to estimate pt(y | x) where y = f(x), the\nperformance function that is expensive to compute exactly. The TPE approach is as follows:\npt(y | x) \u221d pt(y) \u00b7 pt(x | y)\npt(x | y) =\n{ p<t (x), if y < y \u2217\np\u2265t (x), if y \u2265 y\u2217\nwhere p<t and p \u2265 t are densities estimated using observations from previous trials that are less than and greater than y\u2217, respectively. In TPE, y\u2217 is defined as some quantile of the observed y; we use 15-quantiles.\nAs shown by Bergstra et al. (2011), the Expected Improvement in TPE can be written as:\nA(x; pt, y \u2217) \u221d ( \u03b3 + p<t (x)\np\u2265t (x) (1\u2212 \u03b3)\n)\u22121 , (2)\nwhere \u03b3 = pt(y < y\u2217), fixed at 0.15 by definition of y\u2217 (above). Here, we prefer x with high probability under p\u2265t (x) and low probability under p<t (x). To maximize this quantity, we draw many candidates according to p\u2265t (x) and evaluate them according to p<t (x)/p \u2265 t (x). Note that p(y) does not need to be given an explicit form. In order to evaluate Eq. 2, we need to compute p<t (x) and p \u2265 t (x). These joint distributions depend on the graphical model of the hyperparameter space\u2014which is allowed to form a tree structure.\nWe discuss how to compute p<t (x) in the following. p\u2265t (x) is computed similarly, using trials where y \u2265 y\u2217. We associate each hyperparameter with a node in the graphical model; consider the kth dimension of x, denoted by random variable Xk.\n\u2022 If Xk ranges over a discrete set X, TPE uses a reweighted categorical distribution, where the probability that Xk = x is proportional to a smoothing parameter plus the counts of occurrences of Xk = x in xk1:t with yt < y\n\u2217. \u2022 When Xk is continuous-valued, TPE constructs\na probability distribution by placing a truncated Gaussian distribution centered at each of xkk,1:t where yt < y\u2217, with standard deviation set to the greater of the distances to the left and right neighbors.\nIn the simplest version, each node is independent, so we can compute p<t (x) by multiplying individual probabilities at every node. In the treestructured version, we only multiply probabilities along the relevant path, excluding some nodes.\nAnother common approach to the surrogate is the Gaussian Process (Rasmussen and Williams, 2006; Hoffman et al., 2011; Snoek et al., 2012). Like Bergstra et al. (2011), our preliminary experiments found the TPE to perform favorably. Further TPE\u2019s tree-structured configuration space is advantageous, because it allows nested definitions of hyperparameters, which we exploit in our experiments (e.g., only allows bigrams to be chosen if unigrams are also chosen)."}, {"heading": "3.3 Implementation Details", "text": "Because research on SMBO is active, many implementations are publicly available; we use the HPOlib library (Eggensperger et al., 2013).2 The libray takes as input a function L, which is treated as a black box\u2014in our case, a logistic regression trainer that wraps the LIBLINEAR library (Fan et al., 2008), based on the trust region Newton method (Lin et al., 2008)\u2014and a specification of hyperparameters."}, {"heading": "4 Experiments", "text": "Our experiments consider representational choices and hyperparameters for several text categorization problems."}, {"heading": "4.1 Setup", "text": "We fix our learner L to logistic regression. We optimize text representation based on the types of n-grams used, the type of weighting scheme, and the removal of stopwords. For n-grams, we have two parameters, minimum and maximum lengths (nmin and nmax ). (All n-gram lengths between the minimum and maximum, inclusive, are used.) For weighting scheme, we consider term frequency, tf-idf, and binary schemes. Last, we also choose whether we should remove stopwords before constructing feature vectors for each document.\nFurthermore, the choice of representation interacts with the regularizer and the training convergence criterion (e.g., more n-grams means slower training time). We consider two regularizers, `1 penalty (Tibshirani, 1996) or squared `2 penalty (Hoerl and Kennard, 1970). We also have hyperparameters for regularization strength and training convergence tolerance. See Table 1 for a complete list of hyperparameters in our experiments.\nNote that even with this limited number of options, the number of possible combinations is\n2http://www.automl.org/hpolib.html\nhuge (it is actually infinite since the regularization strength and convergence tolerance are continuous values, although we can also use sets of possible values), so exhaustive search is computationally expensive. In all our experiments for all datasets, we limit ourselves to 30 trials per dataset. The only preprocessing we applied was downcasing (see \u00a75 for discussion about this).\nWe always use a development set to evaluate f(x) during learning and report the final result on an unseen test set."}, {"heading": "4.2 Datasets", "text": "We evaluate our method on five text categorization tasks.\n\u2022 Stanford sentiment treebank (Socher et al., 2013): a sentence-level sentiment analysis dataset for movie reviews from the rottentomatoes.com website. We use the binary classification task where the goal is to predict whether a review is positive or negative (no neutral reviews). We obtained this dataset from http://nlp.stanford. edu/sentiment. \u2022 Electronics product reviews from Amazon\n(McAuley and Leskovec, 2013): this dataset consists of electronic product reviews, which is a subset of a large Amazon review dataset. Following the setup of Johnson and Zhang (2014), we only use the text section and ignore the summary section. We also only consider positive and negative reviews. We obtained this dataset from http://riejohnson.com/ cnn_data.html. \u2022 IMDB movie reviews (Maas et al., 2011): a\nbinary sentiment analysis dataset of highly\npolar IMDB movie reviews, obtained from http://ai.stanford.edu/\u02dcamaas/ /data/sentiment. \u2022 Congressional vote (Thomas et al., 2006): tran-\nscripts from the U.S. Congressional floor debates. The dataset only includes debates for controversial bills (the losing side has at least 20% of the speeches). Similar to previous work (Thomas et al., 2006; Yessenalina et al., 2010), we consider the task to predict the vote (\u201cyea\u201d or \u201cnay\u201d) for the speaker of each speech segment (speaker-based speech-segment classification). We obtained it from http://www.cs.cornell.edu/ \u02dcainur/sle-data.html. \u2022 20 Newsgroups (Lang, 1995): the 20\nNewsgroups dataset is a benchmark topic classification dataset, we use the publicly available copy at http://qwone.com/ \u02dcjason/20Newsgroups. There are 20 topics in this dataset. We derived four topic classification tasks from this dataset. The first task is to classify documents across all 20 topics. The second task is to classify related science documents into four science topics (sci.crypt, sci.electronics, sci.med, sci.med). 3 The third and fourth tasks are talk.religion.misc vs. alt.atheism and comp.graphics vs. comp.windows.x. To consider a more realistic setting, we removed header information from each article since they often contain label information.\nThese are standard datasets for evaluating text categorization models, where benchmark results are available. In total, we have eight tasks, of which four are sentiment analysis tasks and four are topic classification tasks. See Table 2 for descriptive\n3We were not able to find previous results that are comparable to ours on the second task; we include them to enable further comparisons in the future.\nstatistics of our datasets."}, {"heading": "4.3 Baselines", "text": "For each dataset, we select supervised, nonensemble classification methods from previous literature as baselines. In each case, we emphasize comparisons with the best-published linear method (often an SVM with a linear kernel with representation selected by experts) and the best-published method overall. In the followings, \u201cSVM\u201d always means \u201clinear SVM\u201d. All methods were trained and evaluated on the same training/testing data splits; in cases where standard development sets were not available, we used a random 20% of the training data as a development set."}, {"heading": "4.4 Results", "text": "We summarize the hyperparameters selected by our method, and the accuracies achieved (on test data) in Table 3. We discuss comparisons to baselines for each dataset in turn.\nStanford sentiment treebank (Table 4). Our logistic regression model outperforms the baseline SVM reported by Socher et al. (2013), who used only unigrams but did not specify the weighting scheme for their SVM baseline. While our result is still below the state-of-the-art based on the the recursive neural tensor networks (Socher et al., 2013) and the paragraph vector (Le and Mikolov, 2014), we show that logistic regression is comparable with recursive and matrix-vector neural networks (Socher et al., 2011; Socher et al., 2012).\nAmazon electronics (Table 5). The bestperforming methods on this dataset are based on convolutional neural networks (Johnson and Zhang, 2014).4 Our method is on par with the\n4These are fully connected neural networks with a rectifier activation function, trained under `2 regularization with stochastic gradient descent.\nsecond-best of these, outperforming all of the reported feed-forward neural networks and SVM variants Johnson and Zhang used as baselines. They varied the representations, and used log term frequency and normalization to unit vectors as the weighting scheme, after finding that this outperformed term frequency. Our method achieved the best performance with binary weighting, which they did not consider.\nIMDB reviews (Table 6). The results parallel those for Amazon electronics; our method comes\nclose to convolutional neural networks (Johnson and Zhang, 2014), which are state-of-the-art.5 It outperforms SVMs and feed-forward neural networks, the restricted Boltzmann machine approach presented by Dahl et al. (2012), and compressive feature learning (Paskov et al., 2013).6\nCongressional vote (Table 7). Our method outperforms the best reported results of Yessenalina et al. (2010), which use a multi-level structured model based on a latent-variable SVM. We show comparisons to two well-known but weaker baselines, as well.\n20 Newsgroups: all topics (Table 8). Our method outperforms state-of-the-art methods in-\n5As noted, semi-supervised and ensemble methods are excluded for a fair comparison.\n6This approach is based on minimum description length, using unlabeled data to select a set of higher-order n-grams to use as features. It is technically a semi-supervised method. The results we compare to use logistic regression with elastic net regularization and heuristic normalizations.\ncluding the distributed structured output model (Srikumar and Manning, 2014).7 The strong logistic regression baseline from Paskov et al. (2013) uses all 5-grams, heuristic normalization, and elastic net regularization; our method found that unigrams and bigrams, with binary weighting and `2 penalty, achieved far better results.\n20 Newsgroups: talk.religion.misc vs. alt.atheism and comp.graphics vs. comp.windows.x Wang and Manning (2012) report a bigram na\u0131\u0308ve Bayes model achieving 85.1% and 91.2% on these tasks, respectively.8 Our method achieves 86.3% and 92.1% using slightly different setups (see Table 3)."}, {"heading": "5 Discussion", "text": "Raw text as input and other hyperparameters. Our results suggest that seemingly mundane representation choices can raise the performance of simple linear models to be comparable with much more sophisticated models. Achieving these results is not a matter of deep expertise about the domain or engineering skill; the choices can be automated. Our experiments only considered logistic regression with downcased text; more choices\u2014 stemming, count thresholding, normalization of numbers, etc.\u2014can be offered to the optimizer, as can additional feature options like gappy n-grams.\nAs NLP becomes more widely used in applications, we believe that automating these choices will be very attractive for those who need to train a high-performance model quickly.\n7This method was designed for structured prediction, but Srikumar and Manning (2014) also applied it to classification. It attempts to learn a distributed representation for features and for labels. The authors used unigrams and did not elaborate the weighting scheme.\n8They also report a na\u0131\u0308ve Bayes/SVM ensemble achieving 87.9% and 91.2%.\nOptimized representations. For each task, the chosen representation is different. Out of all possible hyperparameter choices in our experiments (Table 1), each of them is used by at least one of the datsets (Table 3). For example, on the Congressional Vote dataset, we only need to use bigrams, whereas on the Amazon electronics dataset we need to use unigrams, bigrams, and trigrams. The binary weighting scheme works well for most of the datasets, except the sentence-level sentence analysis task, where the tf-idf weighting scheme was selected. `2 regularization was best in all cases but one.\nWe do not believe that an NLP expert would be likely to make these particular choices, except through the same kind of trial-and-error process our method automates efficiently. Often, we believe, researchers in NLP make initial choices and stick with them through all experiments (as we have admittedly done with logistic regression). Optimizing over more of these choices will give stronger baselines.\nTraining time. We ran 30 trials for each dataset in our experiments. Figure 1 shows each trial accuracy and the best accuracy on development data as we increase the number of trials for three datasets. We can see that 30 trials are generally enough for the model to obtain good results, although the search space is large.\nIn the presence of unlimited computational resources, Bayesian optimization is slower than grid search on all hyperparameters, since the latter is easy to parallelize. This is not realistic in most research and development environments, and it is certainly impractical in increasingly widespread\ninstances of personalized machine learning. The Bayesian optimization approach that we use in our experiments is performed sequentially. It attempts to predict what set of hyperparameters we should try next based on information from previous trials. There has been work to parallelize Bayesian optimization, making it possible to leverage the power of multicore architectures (Snoek et al., 2012; Desautels et al., 2012; Hutter et al., 2012).\nTransfer learning and multitask setting. We treat each dataset independently and create a separate model for each of them. It is also possible to learn from previous datasets (i.e., transfer learning) or to learn from all datasets simultaneously (i.e., multitask learning) to improve performance. This has the potential to reduce the number of trials required even further. See Bardenet et al. (2013), Swersky et al. (2013), and Yogatama and Mann (2014) for how to perform Bayesian optimization in these settings.\nBeyond linear models. We use logistic regression as our classification model, and our experiments show how simple linear models can be competitive with more sophisticated models given the right representation. Other models, can be considered, of course, as can ensembles (Yogatama and Mann, 2014). Increasing the number of options may lead to a need for more trials, and evaluating f(x) (e.g., training the neural network) will take longer for more sophisticated models. We have demonstrated, using one of the simplest classification models (logistic regression), that even simple choices about text representation can matter quite a lot.\nStructured prediction problems Our framework could also be applied to structured prediction problems. For example, in part-of-speech tagging, the set of features can include character n-grams, word shape features, and word type features. The optimal choice for different languages is not always the same, our approach can automate this process.\nBeyond supervised learning. Our framework could also be extended to unsupervised and semisupervised models. For example, in document clustering (e.g., k-means), we also need to construct representations for documents. Log-likelihood might serve as a performance function. A range of random initializations might be considered. Investigation of this approach for nonconvex problems like clustering is an exciting area for future work."}, {"heading": "6 Conclusion", "text": "We used a Bayesian optimization approach to optimize choices about text representations for various categorization problems. Our sequential modelbased optimization technique identifies settings for a standard linear model (logistic regression) that are competitive with far more sophisticated stateof-the-art methods on topic classification and sentiment analysis. Every task and dataset has its own optimal choices; though relatively uninteresting to researchers and not directly linked to domain or linguistic expertise, these choices have a big effect on performance. We see our approach as a first step towards black-box NLP systems that work with raw text and do not require manual tuning."}, {"heading": "Acknowledgements", "text": "This work was supported by the Defense Advanced Research Projects Agency through grant FA87501420244 and computing resources provided by Amazon."}], "references": [{"title": "The power of negative thinking: Exploiting label disagreement in the min-cut classification framework", "author": ["Mohit Bansal", "Clair Cardie", "Lillian Lee."], "venue": "Proc. of COLING.", "citeRegEx": "Bansal et al\\.,? 2008", "shortCiteRegEx": "Bansal et al\\.", "year": 2008}, {"title": "Collaborative hyperparameter tuning", "author": ["Remi Bardenet", "Matyas Brendel", "Balazs Kegl", "Michele Sebag."], "venue": "Proc. of ICML.", "citeRegEx": "Bardenet et al\\.,? 2013", "shortCiteRegEx": "Bardenet et al\\.", "year": 2013}, {"title": "Algorithms for hyper-parameter optimization", "author": ["James Bergstra", "Remi Bardenet", "Yoshua Bengio", "Balazs Kegl."], "venue": "Proc. of NIPS.", "citeRegEx": "Bergstra et al\\.,? 2011", "shortCiteRegEx": "Bergstra et al\\.", "year": 2011}, {"title": "Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures", "author": ["James Bergstra", "Daniel Yamins", "David Cox."], "venue": "Proc. of ICML.", "citeRegEx": "Bergstra et al\\.,? 2013", "shortCiteRegEx": "Bergstra et al\\.", "year": 2013}, {"title": "Training restricted boltzmann machines on word observations", "author": ["George E. Dahl", "Ryan P. Adams", "Hugo Larochelle."], "venue": "Proc. of ICML.", "citeRegEx": "Dahl et al\\.,? 2012", "shortCiteRegEx": "Dahl et al\\.", "year": 2012}, {"title": "Parallelizing explorationexploitation tradeoffs with gaussian process bandit optimization", "author": ["Thomas Desautels", "Andreas Krause", "Joel Burdick."], "venue": "Proc. of ICML.", "citeRegEx": "Desautels et al\\.,? 2012", "shortCiteRegEx": "Desautels et al\\.", "year": 2012}, {"title": "Towards an empirical foundation for assessing bayesian optimization of hyperparameters", "author": ["Katharina Eggensperger", "Matthias Feurer", "Frank Hutter", "James Bergstra", "Jasper Snoek", "Holger H. Hoos", "Kevin Leyton-Brown."], "venue": "Proc. of NIPS Workshop on", "citeRegEx": "Eggensperger et al\\.,? 2013", "shortCiteRegEx": "Eggensperger et al\\.", "year": 2013}, {"title": "LIBLINEAR: A library for large linear classification", "author": ["Rong-En Fan", "Kai-Wei Chang", "Cho-Jui Hsieh", "XiangRui Wang", "Chih-Jen Lin."], "venue": "Journal of Machine Learning Research, (9):1871\u20131874.", "citeRegEx": "Fan et al\\.,? 2008", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "Ridge regression: Biased estimation for nonorthogonal problems", "author": ["Arthur E. Hoerl", "Robert W. Kennard."], "venue": "Technometrics, 12(1):55\u201367.", "citeRegEx": "Hoerl and Kennard.,? 1970", "shortCiteRegEx": "Hoerl and Kennard.", "year": 1970}, {"title": "Portfolio allocation for bayesian optimization", "author": ["Matthew Hoffman", "Eric Brochu", "Nando de Freitas."], "venue": "Proc. of UAI.", "citeRegEx": "Hoffman et al\\.,? 2011", "shortCiteRegEx": "Hoffman et al\\.", "year": 2011}, {"title": "Sequential model-based optimization for general algorithm configuration", "author": ["Frank Hutter", "Holger H. Hoos", "Kevin Leyton-Brown."], "venue": "Proc. of LION-5.", "citeRegEx": "Hutter et al\\.,? 2011", "shortCiteRegEx": "Hutter et al\\.", "year": 2011}, {"title": "Parallel algorithm configuration", "author": ["Frank Hutter", "Holger H. Hoos", "Kevin Leyton-Brown."], "venue": "Proc. of LION.", "citeRegEx": "Hutter et al\\.,? 2012", "shortCiteRegEx": "Hutter et al\\.", "year": 2012}, {"title": "Effective use of word order for text categorization with convolutional neural networks", "author": ["Rie Johnson", "Tong Zhang."], "venue": "arXiv:1412.1058.", "citeRegEx": "Johnson and Zhang.,? 2014", "shortCiteRegEx": "Johnson and Zhang.", "year": 2014}, {"title": "A taxonomy of global optimization methods based on response surfaces", "author": ["Donald R. Jones."], "venue": "Journal of Global Optimization, 21:345\u2013385.", "citeRegEx": "Jones.,? 2001", "shortCiteRegEx": "Jones.", "year": 2001}, {"title": "Newsweeder: Learning to filter netnews", "author": ["Ken Lang."], "venue": "Proc. of ICML.", "citeRegEx": "Lang.,? 1995", "shortCiteRegEx": "Lang.", "year": 1995}, {"title": "Classification using discriminative restricted boltzmann machines", "author": ["Hugo Larochelle", "Yoshua Bengio."], "venue": "Proc. of ICML.", "citeRegEx": "Larochelle and Bengio.,? 2008", "shortCiteRegEx": "Larochelle and Bengio.", "year": 2008}, {"title": "Distributed representations of sentences and documents", "author": ["Quoc V. Le", "Tomas Mikolov."], "venue": "Proc. of ICML.", "citeRegEx": "Le and Mikolov.,? 2014", "shortCiteRegEx": "Le and Mikolov.", "year": 2014}, {"title": "Trust region newton method for large-scale logistic regression", "author": ["Chih-Jen Lin", "Ruby C. Weng", "S. Sathiya Keerthi."], "venue": "Journal of Machine Learning Research, (9):627\u2013650.", "citeRegEx": "Lin et al\\.,? 2008", "shortCiteRegEx": "Lin et al\\.", "year": 2008}, {"title": "Learning word vectors for sentiment analysis", "author": ["Andrew L. Maas", "Raymond E. Daly", "Peter T. Pham", "Dan Huang", "Andrew Y. Ng", "Christopher Potts."], "venue": "Proc. of ACL.", "citeRegEx": "Maas et al\\.,? 2011", "shortCiteRegEx": "Maas et al\\.", "year": 2011}, {"title": "Hidden factors and hidden topics: understanding rating dimensions with review text", "author": ["Julian McAuley", "Jure Leskovec."], "venue": "Proc. of RecSys.", "citeRegEx": "McAuley and Leskovec.,? 2013", "shortCiteRegEx": "McAuley and Leskovec.", "year": 2013}, {"title": "Compressive feature learning", "author": ["Hristo S. Paskov", "Robert West", "John C. Mitchell", "Trevor J. Hastie."], "venue": "Proc of NIPS.", "citeRegEx": "Paskov et al\\.,? 2013", "shortCiteRegEx": "Paskov et al\\.", "year": 2013}, {"title": "Gaussian Processes for Machine Learning", "author": ["Carl Edward Rasmussen", "Christopher K.I. Williams."], "venue": "The MIT Press.", "citeRegEx": "Rasmussen and Williams.,? 2006", "shortCiteRegEx": "Rasmussen and Williams.", "year": 2006}, {"title": "Practical bayesian optimization of machine learning algorithms", "author": ["Jasper Snoek", "Hugo Larrochelle", "Ryan P. Adams."], "venue": "Proc. of NIPS.", "citeRegEx": "Snoek et al\\.,? 2012", "shortCiteRegEx": "Snoek et al\\.", "year": 2012}, {"title": "Semi-supervised recursive autoencoders for predicting sentiment distributions", "author": ["Richard Socher", "Jeffrey Pennington", "Eric H. Huang", "Andrew Y. Ng", "Christopher D. Manning."], "venue": "Proc. of EMNLP.", "citeRegEx": "Socher et al\\.,? 2011", "shortCiteRegEx": "Socher et al\\.", "year": 2011}, {"title": "Semantic compositionality through recursive matrix-vector spaces", "author": ["Richard Socher", "Brody Huval", "Christopher D. Manning", "Andrew Y. Ng."], "venue": "Proc. of EMNLP.", "citeRegEx": "Socher et al\\.,? 2012", "shortCiteRegEx": "Socher et al\\.", "year": 2012}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "Chris Manning", "Andrew Ng", "Chris Potts."], "venue": "Proc. of EMNLP.", "citeRegEx": "Socher et al\\.,? 2013", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Learning distributed representations for structured output prediction", "author": ["Vivek Srikumar", "Christopher D. Manning."], "venue": "Proc. of NIPS.", "citeRegEx": "Srikumar and Manning.,? 2014", "shortCiteRegEx": "Srikumar and Manning.", "year": 2014}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["Niranjan Srinivas", "Andreas Krause", "Sham Kakade", "Matthias Seeger."], "venue": "Proc. of ICML.", "citeRegEx": "Srinivas et al\\.,? 2010", "shortCiteRegEx": "Srinivas et al\\.", "year": 2010}, {"title": "Multi-task bayesian optimization", "author": ["Kevin Swersky", "Jasper Snoek", "Ryan P. Adams."], "venue": "Proc. of NIPS.", "citeRegEx": "Swersky et al\\.,? 2013", "shortCiteRegEx": "Swersky et al\\.", "year": 2013}, {"title": "Get out the vote: Determining support or opposition from congressional floor-debate transcripts", "author": ["Matt Thomas", "Bo Pang", "Lilian Lee."], "venue": "Proc. of EMNLP.", "citeRegEx": "Thomas et al\\.,? 2006", "shortCiteRegEx": "Thomas et al\\.", "year": 2006}, {"title": "Regression shrinkage and selection via the lasso", "author": ["Robert Tibshirani."], "venue": "Journal of Royal Statistical Society B, 58(1):267\u2013288.", "citeRegEx": "Tibshirani.,? 1996", "shortCiteRegEx": "Tibshirani.", "year": 1996}, {"title": "An informational approach to the global optimization of expensive-to-evaluate functions", "author": ["Julien Villemonteix", "Emmanuel Vazquez", "Eric Walter."], "venue": "Journal of Global Optimization.", "citeRegEx": "Villemonteix et al\\.,? 2006", "shortCiteRegEx": "Villemonteix et al\\.", "year": 2006}, {"title": "Baselines and bigrams: Simple, good sentiment and topic classification", "author": ["Sida Wang", "Christopher D. Manning."], "venue": "Proc. of ACL.", "citeRegEx": "Wang and Manning.,? 2012", "shortCiteRegEx": "Wang and Manning.", "year": 2012}, {"title": "Multi-level structured models for document sentiment classification", "author": ["Ainur Yessenalina", "Yisong Yue", "Claire Cardie."], "venue": "Proc. of EMNLP.", "citeRegEx": "Yessenalina et al\\.,? 2010", "shortCiteRegEx": "Yessenalina et al\\.", "year": 2010}, {"title": "Efficient transfer learning method for automatic hyperparameter tuning", "author": ["Dani Yogatama", "Gideon Mann."], "venue": "Proc. of AISTATS.", "citeRegEx": "Yogatama and Mann.,? 2014", "shortCiteRegEx": "Yogatama and Mann.", "year": 2014}], "referenceMentions": [{"referenceID": 10, "context": "Our technique instantiates sequential modelbased optimization (SMBO; Hutter et al., 2011).", "startOffset": 62, "endOffset": 89}, {"referenceID": 2, "context": "SMBO and other Bayesian optimization approaches have been shown to work well for hyperparameter tuning (Bergstra et al., 2011; Hoffman et al., 2011; Snoek et al., 2012).", "startOffset": 103, "endOffset": 168}, {"referenceID": 9, "context": "SMBO and other Bayesian optimization approaches have been shown to work well for hyperparameter tuning (Bergstra et al., 2011; Hoffman et al., 2011; Snoek et al., 2012).", "startOffset": 103, "endOffset": 168}, {"referenceID": 22, "context": "SMBO and other Bayesian optimization approaches have been shown to work well for hyperparameter tuning (Bergstra et al., 2011; Hoffman et al., 2011; Snoek et al., 2012).", "startOffset": 103, "endOffset": 168}, {"referenceID": 3, "context": "Though popular in computer vision (Bergstra et al., 2013), these techniques have received little attention in NLP.", "startOffset": 34, "endOffset": 57}, {"referenceID": 10, "context": "Our approach is based on sequential model-based optimization (SMBO; Hutter et al., 2011).", "startOffset": 61, "endOffset": 88}, {"referenceID": 13, "context": "We use a criterion called Expected Improvement (EI; Jones, 2001), which is the expectation (under the current surrogate model pt) that the choice y will exceed y\u2217:", "startOffset": 47, "endOffset": 64}, {"referenceID": 13, "context": ") Other options for the acquisition function include maximum probability of improvement (Jones, 2001), minimum conditional entropy (Villemonteix et al.", "startOffset": 88, "endOffset": 101}, {"referenceID": 31, "context": ") Other options for the acquisition function include maximum probability of improvement (Jones, 2001), minimum conditional entropy (Villemonteix et al., 2006), Gaussian process upper confidence bound (Srinivas et al.", "startOffset": 131, "endOffset": 158}, {"referenceID": 27, "context": ", 2006), Gaussian process upper confidence bound (Srinivas et al., 2010), or a combination of them (Hoffman et al.", "startOffset": 49, "endOffset": 72}, {"referenceID": 9, "context": ", 2010), or a combination of them (Hoffman et al., 2011).", "startOffset": 34, "endOffset": 56}, {"referenceID": 2, "context": "As a surrogate model, we use a tree-structured Parzen estimator (TPE; Bergstra et al., 2011).", "startOffset": 64, "endOffset": 92}, {"referenceID": 2, "context": "As shown by Bergstra et al. (2011), the Expected Improvement in TPE can be written as:", "startOffset": 12, "endOffset": 35}, {"referenceID": 21, "context": "Another common approach to the surrogate is the Gaussian Process (Rasmussen and Williams, 2006; Hoffman et al., 2011; Snoek et al., 2012).", "startOffset": 65, "endOffset": 137}, {"referenceID": 9, "context": "Another common approach to the surrogate is the Gaussian Process (Rasmussen and Williams, 2006; Hoffman et al., 2011; Snoek et al., 2012).", "startOffset": 65, "endOffset": 137}, {"referenceID": 22, "context": "Another common approach to the surrogate is the Gaussian Process (Rasmussen and Williams, 2006; Hoffman et al., 2011; Snoek et al., 2012).", "startOffset": 65, "endOffset": 137}, {"referenceID": 2, "context": "Like Bergstra et al. (2011), our preliminary experiments found the TPE to perform favorably.", "startOffset": 5, "endOffset": 28}, {"referenceID": 6, "context": "Because research on SMBO is active, many implementations are publicly available; we use the HPOlib library (Eggensperger et al., 2013).", "startOffset": 107, "endOffset": 134}, {"referenceID": 17, "context": ", 2008), based on the trust region Newton method (Lin et al., 2008)\u2014and a specification of hyperparameters.", "startOffset": 49, "endOffset": 67}, {"referenceID": 30, "context": "We consider two regularizers, `1 penalty (Tibshirani, 1996) or squared `2 penalty (Hoerl and Kennard, 1970).", "startOffset": 41, "endOffset": 59}, {"referenceID": 8, "context": "We consider two regularizers, `1 penalty (Tibshirani, 1996) or squared `2 penalty (Hoerl and Kennard, 1970).", "startOffset": 82, "endOffset": 107}, {"referenceID": 25, "context": "\u2022 Stanford sentiment treebank (Socher et al., 2013): a sentence-level sentiment analysis dataset for movie reviews from the rottentomatoes.", "startOffset": 30, "endOffset": 51}, {"referenceID": 19, "context": "\u2022 Electronics product reviews from Amazon (McAuley and Leskovec, 2013): this dataset consists of electronic product reviews, which is a subset of a large Amazon review dataset.", "startOffset": 42, "endOffset": 70}, {"referenceID": 18, "context": "\u2022 IMDB movie reviews (Maas et al., 2011): a binary sentiment analysis dataset of highly Dataset Training Dev.", "startOffset": 21, "endOffset": 40}, {"referenceID": 12, "context": "Following the setup of Johnson and Zhang (2014), we only use the text section and ignore the summary section.", "startOffset": 23, "endOffset": 48}, {"referenceID": 29, "context": "\u2022 Congressional vote (Thomas et al., 2006): transcripts from the U.", "startOffset": 21, "endOffset": 42}, {"referenceID": 29, "context": "Similar to previous work (Thomas et al., 2006; Yessenalina et al., 2010), we consider the task to predict the vote (\u201cyea\u201d or \u201cnay\u201d) for the speaker of each speech segment (speaker-based speech-segment classification).", "startOffset": 25, "endOffset": 72}, {"referenceID": 33, "context": "Similar to previous work (Thomas et al., 2006; Yessenalina et al., 2010), we consider the task to predict the vote (\u201cyea\u201d or \u201cnay\u201d) for the speaker of each speech segment (speaker-based speech-segment classification).", "startOffset": 25, "endOffset": 72}, {"referenceID": 14, "context": "\u2022 20 Newsgroups (Lang, 1995): the 20 Newsgroups dataset is a benchmark topic classification dataset, we use the publicly available copy at http://qwone.", "startOffset": 16, "endOffset": 28}, {"referenceID": 25, "context": "While our result is still below the state-of-the-art based on the the recursive neural tensor networks (Socher et al., 2013) and the paragraph vector (Le and Mikolov, 2014), we show that logistic regression is comparable with recursive and matrix-vector neural networks (Socher et al.", "startOffset": 103, "endOffset": 124}, {"referenceID": 16, "context": ", 2013) and the paragraph vector (Le and Mikolov, 2014), we show that logistic regression is comparable with recursive and matrix-vector neural networks (Socher et al.", "startOffset": 33, "endOffset": 55}, {"referenceID": 23, "context": ", 2013) and the paragraph vector (Le and Mikolov, 2014), we show that logistic regression is comparable with recursive and matrix-vector neural networks (Socher et al., 2011; Socher et al., 2012).", "startOffset": 153, "endOffset": 195}, {"referenceID": 24, "context": ", 2013) and the paragraph vector (Le and Mikolov, 2014), we show that logistic regression is comparable with recursive and matrix-vector neural networks (Socher et al., 2011; Socher et al., 2012).", "startOffset": 153, "endOffset": 195}, {"referenceID": 22, "context": "Our logistic regression model outperforms the baseline SVM reported by Socher et al. (2013), who used only unigrams but did not specify the weighting scheme for their SVM baseline.", "startOffset": 71, "endOffset": 92}, {"referenceID": 12, "context": "The bestperforming methods on this dataset are based on convolutional neural networks (Johnson and Zhang, 2014).", "startOffset": 86, "endOffset": 111}, {"referenceID": 22, "context": "Scores are as reported by Socher et al. (2013) and Le and Mikolov (2014).", "startOffset": 26, "endOffset": 47}, {"referenceID": 16, "context": "(2013) and Le and Mikolov (2014).", "startOffset": 11, "endOffset": 33}, {"referenceID": 12, "context": "Scores are as reported by Johnson and Zhang (2014).", "startOffset": 26, "endOffset": 51}, {"referenceID": 12, "context": "close to convolutional neural networks (Johnson and Zhang, 2014), which are state-of-the-art.", "startOffset": 39, "endOffset": 64}, {"referenceID": 20, "context": "(2012), and compressive feature learning (Paskov et al., 2013).", "startOffset": 41, "endOffset": 62}, {"referenceID": 4, "context": "5 It outperforms SVMs and feed-forward neural networks, the restricted Boltzmann machine approach presented by Dahl et al. (2012), and compressive feature learning (Paskov et al.", "startOffset": 111, "endOffset": 130}, {"referenceID": 29, "context": "SVM results are from Wang and Manning (2012), the RBM (restricted Bolzmann machine) result is from Dahl et al.", "startOffset": 21, "endOffset": 45}, {"referenceID": 4, "context": "SVM results are from Wang and Manning (2012), the RBM (restricted Bolzmann machine) result is from Dahl et al. (2012), NN and CNN results are from Johnson and Zhang (2014), and LR{1, 2, 3, 4, 5}-grams and compressive feature learning results are from Paskov et al.", "startOffset": 99, "endOffset": 118}, {"referenceID": 4, "context": "SVM results are from Wang and Manning (2012), the RBM (restricted Bolzmann machine) result is from Dahl et al. (2012), NN and CNN results are from Johnson and Zhang (2014), and LR{1, 2, 3, 4, 5}-grams and compressive feature learning results are from Paskov et al.", "startOffset": 99, "endOffset": 172}, {"referenceID": 4, "context": "SVM results are from Wang and Manning (2012), the RBM (restricted Bolzmann machine) result is from Dahl et al. (2012), NN and CNN results are from Johnson and Zhang (2014), and LR{1, 2, 3, 4, 5}-grams and compressive feature learning results are from Paskov et al. (2013).", "startOffset": 99, "endOffset": 272}, {"referenceID": 33, "context": "Our method outperforms the best reported results of Yessenalina et al. (2010), which use a multi-level structured model based on a latent-variable SVM.", "startOffset": 52, "endOffset": 78}, {"referenceID": 29, "context": "SVM-link exploits link structures (Thomas et al., 2006); the min-cut result is from Bansal et al.", "startOffset": 34, "endOffset": 55}, {"referenceID": 0, "context": ", 2006); the min-cut result is from Bansal et al. (2008); and SVM-SLE result is reported by Yessenalina et al.", "startOffset": 36, "endOffset": 57}, {"referenceID": 0, "context": ", 2006); the min-cut result is from Bansal et al. (2008); and SVM-SLE result is reported by Yessenalina et al. (2010).", "startOffset": 36, "endOffset": 118}, {"referenceID": 26, "context": "cluding the distributed structured output model (Srikumar and Manning, 2014).", "startOffset": 48, "endOffset": 76}, {"referenceID": 20, "context": "7 The strong logistic regression baseline from Paskov et al. (2013) uses all 5-grams, heuristic normalization, and elastic net regularization; our method found that unigrams and bigrams, with binary weighting and `2 penalty, achieved far better results.", "startOffset": 47, "endOffset": 68}, {"referenceID": 15, "context": "The disriminative RBM result is from Larochelle and Bengio (2008); compressive feature learning and LR-5-grams results are from Paskov et al.", "startOffset": 37, "endOffset": 66}, {"referenceID": 15, "context": "The disriminative RBM result is from Larochelle and Bengio (2008); compressive feature learning and LR-5-grams results are from Paskov et al. (2013), and the distributed structured output result is from Srikumar and Manning (2014).", "startOffset": 37, "endOffset": 149}, {"referenceID": 15, "context": "The disriminative RBM result is from Larochelle and Bengio (2008); compressive feature learning and LR-5-grams results are from Paskov et al. (2013), and the distributed structured output result is from Srikumar and Manning (2014).", "startOffset": 37, "endOffset": 231}, {"referenceID": 32, "context": "x Wang and Manning (2012) report a bigram na\u0131\u0308ve Bayes model achieving 85.", "startOffset": 2, "endOffset": 26}, {"referenceID": 26, "context": "This method was designed for structured prediction, but Srikumar and Manning (2014) also applied it to classification.", "startOffset": 56, "endOffset": 84}, {"referenceID": 22, "context": "There has been work to parallelize Bayesian optimization, making it possible to leverage the power of multicore architectures (Snoek et al., 2012; Desautels et al., 2012; Hutter et al., 2012).", "startOffset": 126, "endOffset": 191}, {"referenceID": 5, "context": "There has been work to parallelize Bayesian optimization, making it possible to leverage the power of multicore architectures (Snoek et al., 2012; Desautels et al., 2012; Hutter et al., 2012).", "startOffset": 126, "endOffset": 191}, {"referenceID": 11, "context": "There has been work to parallelize Bayesian optimization, making it possible to leverage the power of multicore architectures (Snoek et al., 2012; Desautels et al., 2012; Hutter et al., 2012).", "startOffset": 126, "endOffset": 191}, {"referenceID": 1, "context": "See Bardenet et al. (2013), Swersky et al.", "startOffset": 4, "endOffset": 27}, {"referenceID": 1, "context": "See Bardenet et al. (2013), Swersky et al. (2013), and Yogatama and Mann (2014) for how to perform Bayesian optimization in these settings.", "startOffset": 4, "endOffset": 50}, {"referenceID": 1, "context": "See Bardenet et al. (2013), Swersky et al. (2013), and Yogatama and Mann (2014) for how to perform Bayesian optimization in these settings.", "startOffset": 4, "endOffset": 80}, {"referenceID": 34, "context": "Other models, can be considered, of course, as can ensembles (Yogatama and Mann, 2014).", "startOffset": 61, "endOffset": 86}], "year": 2015, "abstractText": "When applying machine learning to problems in NLP, there are many choices to make about how to represent input texts. These choices can have a big effect on performance, but they are often uninteresting to researchers or practitioners who simply need a module that performs well. We propose an approach to optimizing over this space of choices, formulating the problem as global optimization. We apply a sequential model-based optimization technique and show that our method makes standard linear models competitive with more sophisticated, expensive state-of-theart methods based on latent variable models or neural networks on various topic classification and sentiment analysis problems. Our approach is a first step towards blackbox NLP systems that work with raw text and do not require manual tuning.", "creator": "LaTeX with hyperref package"}}}