{"id": "1503.08873", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Mar-2015", "title": "Fast Label Embeddings for Extremely Large Output Spaces", "abstract": "Many modern multi-class and multi-label problems are characterized by ever-increasing output space. To address these problems, label embedding has proven to be a useful primitive that can improve computing and statistical efficiency. In this work, we use a correspondence between rank-limited estimation and low-dimensional label embedding that reveals a fast label embedding algorithm that works in both the multi-class and multi-label environments, resulting in a randomized sub-squares algorithm whose runtime is exponentially faster than naive algorithms. We demonstrate our techniques on two large public datasets, the Large Scale Hierarchical Text Challenge and the Open Directory Project, where we achieve state-of-the-art results.", "histories": [["v1", "Mon, 30 Mar 2015 23:29:46 GMT  (13kb)", "http://arxiv.org/abs/1503.08873v1", "Accepted as a workshop contribution at ICLR 2015"]], "COMMENTS": "Accepted as a workshop contribution at ICLR 2015", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["paul mineiro", "nikos karampatziakis"], "accepted": true, "id": "1503.08873"}, "pdf": {"name": "1503.08873.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["pmineiro@microsoft.com", "nikosk@microsoft.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 3.\n08 87\n3v 1\n[ cs\n.L G\n] 3\n0 M\nar 2\n01 5"}, {"heading": "1 CONTRIBUTIONS", "text": "We provide a statistical motivation for label embedding by demonstrating that the optimal rankconstrained least squares estimator can be constructed from an optimal unconstrained estimator of an embedding of the labels. In other words, embedding can provide beneficial sample complexity reduction even if computational constraints are not binding.\nWe identify a natural object to define label similarity: the expected outer product of the conditional label probabilities. In particular, in conjunction with a low-rank constraint, this indicates two label embeddings are similar when their conditional probabilities are linearly dependent across the dataset. This unifies prior work utilizing the confusion matrix for multiclass (Bengio et al., 2010) and the empirical label covariance for multilabel (Tai & Lin, 2012).\nWe apply techniques from randomized linear algebra (Halko et al., 2011) to develop an efficient and scalable algorithm for constructing the embeddings, essentially via a novel randomized algorithm for partial least squares (Geladi & Kowalski, 1986). Intuitively, this technique implicitly decomposes the prediction matrix of a model which would be prohibitively expensive to form explicitly."}, {"heading": "2 DESCRIPTION", "text": ""}, {"heading": "2.1 NOTATION", "text": "We denote vectors by lowercase letters x, y etc. and matrices by uppercase letters W , Z etc. The input dimension is denoted by d, the output dimension by c and the embedding dimension by k. For an m\u00d7n matrix X \u2208 Rm\u00d7n we use ||X ||F for its Frobenius norm, X\u2020 for the pseudoinverse,\u03a0X,L for the projection onto the left singular subspace of X ."}, {"heading": "2.2 PROPOSED ALGORITHM", "text": "Our proposal is Rembrandt, described in Algorithm 1. We use the top right singular space of \u03a0X,LY as a label embedding, or equivalently, the top principal components of Y \u22a4\u03a0X,LY (leveraging the fact that the projection is idempotent). Using randomized techniques, we can decompose this matrix without explicitly forming it, because we can compute the product of \u03a0X,LY with another matrix Q via Y \u22a4\u03a0X,LY Q = Y \u22a4XZ\u2217 where Z\u2217 = argminZ\u2208Rd\u00d7(k+p) \u2016Y Q \u2212 XZ\u2016 2 F . Algorithm 1\nAlgorithm 1 Rembrandt: Response EMBedding via RANDomized Techniques\n1: function REMBRANDT(k,X \u2208 Rn\u00d7d, Y \u2208 Rn\u00d7c) 2: (p, q) \u2190 (20, 1) \u22b2 These hyperparameters rarely need adjustment. 3: Q \u2190 randn(c, k + p) 4: for i \u2208 {1, . . . , q} do \u22b2 Randomized range finder for Y \u22a4\u03a0X,LY 5: Z \u2190 argmin \u2016Y Q\u2212XZ\u20162F 6: Q \u2190 orthogonalize(Y \u22a4XZ) 7: end for \u22b2 NB: total of (q + 1) data passes, including next line 8: F \u2190 (Y \u22a4XQ)\u22a4(Y \u22a4XQ) \u22b2 F \u2208 R(k+p)\u00d7(k+p) is \u201csmall\u201d 9: (V,\u03a32) \u2190 eig(F, k) 10: V \u2190 QV \u22b2 V \u2208 Rc\u00d7k is the embedding 11: return (V,\u03a3) 12: end function\nis a specialization of randomized PCA to this particular form of the matrix multiplication operator. Fortunately, because X\u2020(\u03a0X,LY )k is the optimal rank-constrained least squares weight matrix, Rembrandt is a randomized algorithm for partial least squares (Geladi & Kowalski, 1986).\nAlgorithm 1 is inexpensive to compute. The matrix vector product Y Q is a sparse matrix-vector product so complexity O(nsk) depends only on the average (label) sparsity per example s and the embedding dimension k, and is independent of the number of classes c. The fit is done in the embedding space and therefore is independent of the number of classes c, and the outer product with the predicted embedding is again a sparse product with complexity O(nsk). The orthogonalization step is O(ck2), but this is amortized over the data set and essentially irrelevant as long as n > c. Furthermore random projection theory suggests k should grow only logarithmically with c."}, {"heading": "2.3 EXPERIMENTS", "text": ""}], "references": [{"title": "Logarithmic time online multiclass prediction", "author": ["Choromanska", "Anna", "Langford", "John"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Choromanska et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Choromanska et al\\.", "year": 2010}, {"title": "Partial least-squares regression: a tutorial", "author": ["Geladi", "Paul", "Kowalski", "Bruce R"], "venue": "Analytica chimica acta,", "citeRegEx": "Geladi et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Geladi et al\\.", "year": 1986}, {"title": "Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions", "author": ["Halko", "Nathan", "Martinsson", "Per-Gunnar", "Tropp", "Joel A"], "venue": "SIAM review,", "citeRegEx": "Halko et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Halko et al\\.", "year": 2011}, {"title": "Fastxml: a fast, accurate and stable tree-classifier for extreme multi-label learning", "author": ["Prabhu", "Yashoteja", "Varma", "Manik"], "venue": "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Prabhu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Prabhu et al\\.", "year": 2014}, {"title": "Multilabel classification with principal label space transformation", "author": ["Tai", "Farbound", "Lin", "Hsuan-Tien"], "venue": "Neural Computation,", "citeRegEx": "Tai et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Tai et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 2, "context": "We apply techniques from randomized linear algebra (Halko et al., 2011) to develop an efficient and scalable algorithm for constructing the embeddings, essentially via a novel randomized algorithm for partial least squares (Geladi & Kowalski, 1986).", "startOffset": 51, "endOffset": 71}], "year": 2015, "abstractText": "Many modern multiclass and multilabel problems are characterized by increasingly large output spaces. For these problems, label embeddings have been shown to be a useful primitive that can improve computational and statistical efficiency. In this work we utilize a correspondence between rank constrained estimation and low dimensional label embeddings that uncovers a fast label embedding algorithm which works in both the multiclass and multilabel settings. The result is a randomized algorithm for partial least squares, whose running time is exponentially faster than naive algorithms. We demonstrate our techniques on two large-scale public datasets, from the Large Scale Hierarchical Text Challenge and the Open Directory Project, where we obtain state of the art results.", "creator": "LaTeX with hyperref package"}}}