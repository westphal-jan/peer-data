{"id": "1505.02552", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-May-2015", "title": "Relations between MDDs and Tuples and Dynamic Modifications of MDDs based constraints", "abstract": "We study the relationships between Multi-Value Decision Diagrams (MDD) and tuples (i.e. elements of the Cartesian variable product). First, we improve existing methods for converting a set of tuples, global cut seeds, sequences of tuples to MDDs. Then, we present some established algorithms for adding and deleting tuples from an MDD. Next, we consider an MDD constraint that is modified during the search by removing some tuples. We specify an algorithm that adapts MDD-4R to these dynamic and persistent modifications. Some experiments show that MDD constraints compete with table constraints.", "histories": [["v1", "Mon, 11 May 2015 10:32:59 GMT  (405kb,D)", "http://arxiv.org/abs/1505.02552v1", "15 pages, 16 figures"]], "COMMENTS": "15 pages, 16 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["guillaume perez", "jean-charles r\\'egin"], "accepted": false, "id": "1505.02552"}, "pdf": {"name": "1505.02552.pdf", "metadata": {"source": "CRF", "title": "Relations between MDDs and Tuples and Dynamic Modifications of MDDs based constraints", "authors": ["Guillaume Perez", "Jean-Charles R\u00e9gin"], "emails": ["guillaume.perez06@gmail.com,", "jcregin@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "Table constraints are fundamental and implemented in any CP solver. They are explicitly defined by the set of elements of the Cartesian Product of the variables, also called tuples, that are allowed.\nCheng and Yap have proposed to compress the tuple set of the constraint by using Multi-valued Decision Diagrams (MDD) and designed mddc one of the first filtering algorithm establishing arc consistency for them [8,7]. Recently, Perez and R\u00e9gin have presented MDD-4R a new algorithm which improves mddc [17]. MDD-4R proceeds like GAC-4R and, unlike mddc, maintains the MDD during the search for a solution. They have also introduced an efficient algorithm for reducing a MDD and some powerful algorithms for combining MDDs [18]. Thanks to these new algorithms , some experiments based on real life applications shown that the MDD approach becomes competitive with ad-hoc approaches like the filtering algorithms associated with the regular or the knapsack constraints. Thus, the replacement of Table constraints by MDD based constraints appears to be a possible future. In this paper, we wish to take a further step forward in that direction.\nWe propose to improve the MDD capabilities in three ways. First, we define new methods for transforming a set of tuples, Global Cut Seeds (GCS), sequences of tuples into MDDs. Then, we present some algorithms for adding and removing tuples from an MDD. Next, we consider an MDD constraint which is modified during the search by deleting some tuples.\nTable constraints are useful for modeling and solving many real-world problems. They can be specified either directly, by input from the user, or indirectly by synthesizing other constraints or subproblems [15,14]. They have been reinforced in order to deal either from tuples or from sequences of tuples [10,12,19]. Thus, their expressiveness is strong. So, if we want to be competitive with Table constraints we need to be\nar X\niv :1\n50 5.\n02 55\n2v 1\n[ cs\n.A I]\n1 1\nM ay\n2 01\nable to represent efficiently different kind of compressed tuple sets. Hence, in the first part of this paper we will show how GCSs and tuple sequences can be represented by an MDD. Notably, we will show that an MDD can be built directly from a sorted list of tuples and that it is not necessary to use an intermediate data structure having a greater space complexity as proposed by Cheng and Yap. In addition, we will show that the MDD representing several disjoint tuple sequences has a space complexity which is never greater than the one used for expressing the tuple sequences.\nThen, we consider the addition and the deletion of one tuple from an MDD. We will see that these operations can be efficiently done by using the method which consists of isolating the path of the MDD corresponding to the tuple in case of deletion and to the common prefix of the tuple in case of addition. These operations make easier the addition/deletion of a set of tuples, that is the modifications that we can make on an MDD. On one hand, this reinforces the expressiveness of MDDs. On the other hand it also opens the door to dynamic algorithms for maintaining arc consistency of MDDs based constraints. Therefore, we propose an arc consistency algorithm for these constraints when some tuples are definitely deleted during the search for solutions. This algorithm is based on previous operations but must be carefully implemented because the deletion of a tuple may create new nodes in the MDD and it causes some problems with the restoration arising after backtracking. In other words, a persistent deletion is a monotonic modification according to the consistency of the constraints, but the maintenance of the MDD is no longer monotonic.\nBeing able to maintain the arc consistency of an MDD whereas some tuples are permanently has two main advantages. First, it is useful for dealing with some problems like nogoods recording. Currently, either ad-hoc algorithms or dynamic table constraint are used. So, it supports our idea to see the MDD constraint as a possible replacement of Table constraints. Second, MDD contraints are now competitive with ad-hoc algorithms of regular constraint. Thus, having a partially dynamic arc consistency algorithms for them gives us immediately a partially dynamic arc consistency algorithm for regular constraints.\nThe paper is organized as follows. First we recall background information. Then, we describe how an MDD can be build from tuple sets. Next, we study the addition and the deletion of tuples from an MDD and we present an algorithm for maintaining arc consistency for MDD based constraint when some tuples are permanently deleted during the search for solutions. We discuss experiments that empirically establish that using MDD constraints is a competitive approach with using Table constraints. Finally, we conclude this paper."}, {"heading": "2 Background", "text": "Multi-valued decision diagram (MDD) is a method for representing discrete functions. It is a multiple-valued extension of BDDs [6]. An MDD, as used in CP [1,13,14,3,11], is a rooted directed acyclic graph (DAG) used to represent some multi-valued function f : {0...d\u22121}r \u2192 {true, false}, based on a given integer d (See Figure 1.). Given the r input variables, the DAG representation is designed to contain r layers of nodes, such that each variable is represented at a specific layer of the graph. Each node on a given\nlayer has at most d outgoing arcs to nodes in the next layer of the graph. Each arc is labeled by its corresponding integer. The final layer is represented by the true terminal node (the false terminal node is typically omitted). There is an equivalence between f(v1, ..., vr) = true and the existence of a path from the root node to the true terminal node whose arcs are labeled v1, ..., vr. Nodes without any outgoing arc or without any incoming arc are removed.\nIn an MDD constraint, the MDD models the set of tuples satisfying the constraint, such that every path from the root to the true terminal node corresponds to an allowed tuple. Each variable of the MDD corresponds to a variable of the constraint. An arc associated with an MDD variable corresponds to a value of the corresponding variable of the constraint.\nFor convenience, we will denote by d the maximum number of values in the domain of a variable; and an arc from x to y labeled by v will be denoted by (x, v, y).\nAn example of MDD is given in Figure 1. This MDD represents the tuples {a,a}, {a,b}, {c,a}, {c,b} and {c,c}. For each tuple, there is a path from the root node (node 0) to the terminal node (node tt) whose are labeled by the tuple values.\nThe reduction of an MDD is one of the most important operations. It consists of merging equivalent nodes, i.e. nodes having the same set of outgoing neighbors associated with the same labels. Usually, a reduction algorithm merge nodes until there is no more any equivalent nodes.\nMost of the time, only reduced MDDs are considered mainly because they are smaller. Figure 6 exhibits an MDD having two equivalent nodes: b and e. These nodes will be merged by the reduction operation. Note that the reduction operation cannot increase the number of nodes or arcs."}, {"heading": "3 Transformations", "text": "Cheng and Yap have proposed an algorithm for building an MDD from a Table. It uses an internal data structure similar as a trie which requires to have d entries per nodes in order to be able to add a new tuples to the MDD. Then they merge the leaves of the trie\nand apply the reduction operator. The space complexity is not really an issue with their algorithm because their reduction algorithm also requires to have a direct access to the children of a node, so d entries per node. However, a new reduction algorithm has been recently proposed by Perez and R\u00e9gin [18]. Its space and time complexity are linear, so we can improve the transformation of tuple sets into MDD if we are able to add tuples into an MDD in linear time. In this section, we propose such algorithms."}, {"heading": "3.1 From Trie to MDD", "text": "A Trie is a data structure used by Gent et al. for compressing tuple sets [12]. Each path from the root to a leaf represents an allowed tuple. A trie representing a set of T tuples will have |T | leaves. Each variable corresponds to a layer of the trie. A node has a maximum of d children, where d is the size of the domain of the corresponding variable of the node. A example of trie is given in Figure 2. It corresponds to the same tuple set as the MDD of Figure 1.\nA trie can be transformed into an MDD by merging all the leaves into the terminal node tt and by applying the reduction operation [7]."}, {"heading": "3.2 From Table to MDD", "text": "A Table is a data structure where each row represent a tuple and where each column corresponds to a value of a tuple.\nCheng and Yap build and MDD from a Table by defining a trie. Tuples are successively added to the trie. These additions are made by creating first a common node: the root of the trie and by creating paths starting from the root . The rooted subpaths common to several tuples are merged together in order to be represented only once. Afterwards, all the leaves are merged and the MDD is reduced. The drawback of this approach is the addition of a tuple. In order to determine in linear time where it should be added into the existing MDD, the algorithm requires to have d entries per node1.\n1 Note that if we accept to increase the time complexity then we can avoid that space complexity.\nWe propose a simple linear method: we sort the Table and we build the trie from the sorted Table. This can be done efficiently because all tuples are consecutives and so there is no need to search for any position for a tuple: the last one is always the correct one. So we do not need the random access to children and this step can be achieved in linear time. Since the merge of the leaves and the reduction can be performed in linear time too we obtain a linear time algorithm."}, {"heading": "3.3 From GCS and Tuple Sequence to MDD.", "text": "A GCS (Global Cut Seed), is a compact representation of a tuple set [10]. A GCS is defined by a set of set of values. The Cartesian Product of these sets define the represented tuples. It is usually defined as c = {{v1,1, v1,2, ..., v1,k1}, ..., {vn,1, vn,2, ..., vn,kn}}, where each set of values corresponds to a variable. For instance, given d ={1,2,3,4}, the GCS c = {d, d, d, d} represents the tuple set { {1,1,1,1}, {1,1,1,2},..., {4,4,4,3}, {4,4,4,4}}. One GCS may represent an exponential number of tuples. However all the tuples cannot be compressed by only one GCS. Two tuples can be represented by the same GCS if they have an Hamming distance equals to 1. For instance, the tuples {1,1,1} and {1,1,2} may be compressed into {1,1,{1,2}}. By contrast the tuples {1,1,1} and {1,2,2} have an Hamming distance equals to 2 and so cannot be represented by only one GCS. So, the compression of a Table by a set of GCS may required a huge number of GCSs. In order to remedy to this problem, tuple sequences have been introduced [19].\nTuple sequences generalize GCSs. A tuple sequence encapsulates a GCS and two tuples: a minimum tuple denoted by tmin and a maximum tuple denoted by tmax. It bounds the enumeration of the tuples of the GCS by these two tuples.For instance, let d be the value set {1,2,3,4} then the tuple sequence defined by the triplet s = {{d, d, d, d}, {1, 2, 2, 2}, {3, 1, 4, 2}} represents the tuple set {{1,2,2,2}, {1,2,2,3}, ..., {3,1,4,1}, {3,1,4,2}}.\nSince a tuple sequence is a generalization of a GCS, a method transforming a tuple sequence into an MDD could also be used for transforming a GCS into an MDD.\nFirst, we propose an algorithm for representing one tuple sequence by an MDD. Then, we will show how we can deal with several tuple sequences. Let s = (g, tmin, tmax) be a tuple sequence. For transforming s into an MDD we introduce special nodes: wild card nodes. There is a maximum of one wild card node per layer which is denoted by w[i] for the layer i. The wild card nodes are linked together. All the arcs outgoing from w[i] are incoming arcs of node w[i + 1] and all arcs outgoing wn\u22121 are incoming arcs of tt.\nThe creation of the MDD representing s is performed in three steps:\n1. The paths corresponding to tuples tmin and tmax are created. 2. Arcs from the nodes of the paths previously created to wild card nodes are created\nas follows. Consider the path created for tmin. For each layer i, let x[i] be the variable corresponding at this layer. Let val[i] be the value set of g for the layer i. For each value a \u2208 val[i] such that a > tmin[i] we create an arc from the node ni of the path representing tmin to the wild card node w[i + 1]. We repeat this process for the path created for tmax. In addition, we add a particular treatment\nwhen a node is shared by the two initial paths, for instance for the root node. In this case, instead of considering all values of val[i], we consider only the values in the interval val[i]\u2229]tmin[i], tmax[i][. 3. From nodes w[i] to node w[i + 1] we add as many arcs as there are values in val[i+ 1].\nFigure 3 shows the construction of an MDD for the tuple s = {{d,d,d,d}, {1,2,2,2}, {3,1,4,2}} with d ={1,2,3,4}. The left graph contains the two paths representing the minimum and maximum tuples. The right graph shows how arcs are added to wild card nodes. These arcs are represented by dashed lines. For instance, for node a each value in {1,2,3,4} greater than 2 labels an arc to node w1. Arcs joining wild card nodes together and with tt are represented by dotted lines.\nLet r be the the number of involved variables. The number of nodes of the obtained MDD is bounded by 3(r \u2212 1) + 2. There are 2r arcs for the paths corresponding to tmin and tmax. There are at most |val[i]| arcs from nodes of the tmin path to wild card nodes. We have the same number for the tmax path. There are |val[i + 1]| arcs from node w[i] to node w[i+1]. Thus, there are at most \u2211r i=1 |val[i]|+2r arcs in the MDD. This is equivalent to the number of values of the tuple sequence. Now, suppose that we have a set of tuple sequences. We can consider successively each tuple sequence and build for each sequence MDD with the previous algorithm. Then, there are two possibilities. Either the tuple sequences are disjoint or not. The former case arises frequently. We just have to merge the graph representation of the MDDs. This can be easily done because they are disjoint. The resulting MDD has a space complexity equivalent to set of tuple sequences and we have:\nProperty 1 A set of disjoint tuple sequences can be represented by an MDD having an equivalent space complexity.\nThe latter case is more complex. A set of disjoint tuple sequences may be computed from a set of non disjoint tuple sequences. Nevertheless, it may create an exponential number of tuple sequences [19]. One possible solution is to partition of the set of tuple sequences into parts of disjoints tuple sequences. Then, each part can be represented by an MDD. If we need to define a constraint then we define a disjunction of MDD constraints. However, the representation of a set of disjoint tuple sequences by a unique MDD without changing the space complexity remains an open question."}, {"heading": "4 Addition and Deletions of tuples from an MDD", "text": "Some work have been carried out for performing operations on BDDs. For instance, Bryant define some algorithms for applying different operators [6,5]. However, the described algorithms are not in-place (i.e. there is the creation of a resulting BDD) and it is not easy to generalize some algorithms designed for BDDs to MDDs mainly because some Booleans rules are no longer true when we have d values in the domain and because the complexity of some algorithms is multiplied by O(d) when dealing with d values. Some algorithms have also been proposed for applying operators on MDDs [2,18]. However, there are not in-place.\nIn this section we define in-place algorithms for the addition/deletion of tuples from an MDD. Such algorithms are necessary to be able to define a dynamic algorithm for MDD constraint in order to be competitive with dynamic Table constraints."}, {"heading": "4.1 Deletion of tuples from an MDD", "text": "First we give an algorithm for deleting a tuple from an MDD. Then, we generalize it. The deletion of one tuple from an MDD is performed by an operation named path isolation. The idea of this operation is to build a specific path whose arcs are labeled by the values of the tuple that must be deleted. In addition the arcs equivalent of the ones of the isolated path are deleted from the MDD. It is performed in four steps:\n1. The isolation for the first layer 2. The isolation for any intermediate layer (neither the first nor the last). 3. The isolation for the last layer 4. We call an incremental the reduction operator on the MDD\nWe detail these steps. Let \u03c4 be the tuple that must be deleted. Let \u03c4 [i] be the value for the variable x[i].\nStep 1. First we identify a1 = (r, n1, \u03c4 [1]) the arc of the first layer labeled by \u03c4 [1] the first value of the tuple. We create the node ne1, the arc (r, ne1, \u03c4 [1]) and we delete the arc a1. We set mddNode to n1 and isolatedNode to ne1.\nStep 2. For each layer i from 2 to r \u2212 1 we repeat the following operation. We identify ai = (mddNode, ni+1, \u03c4 [i]) the outgoing arc from the mddNode labeled with \u03c4 [i]. We create the node nei+1 and the arc (isolatedNode, nei+1, \u03c4 [i]). For each arc (mddNode, y, w) such that w 6= \u03c4 [i] we create the arc (isolatedNode, y, w). We set mddNode to ni+1 and isolatedNode to nei+1.\nStep 3. For each arc (mddNode, tt, w) such that w 6= \u03c4 [i] we create the arc (isolatedNode, tt, w).\nStep 4. We apply the reduction on the MDD by considering only the path and the neighbors of nodes of the path.\nIf at any moment we cannot identify an arc then it means that \u03c4 does not belong to the MDD. Figure 4 shows the application of this algorithm.\nThe complexity of the deletion of a tuple is bounded by O(rd) because for each isolated node we need to recreate its arcs. However, in practice it is often close to O(d). Thus, we can easily implement the deletion of a tuple set by repeating this algorithm. We propose to improve this method\nDeletion of a set of tuples. We give an in-place algorithm for deleting a set of tuples from an MDD. In this case, we transform the set of tuples into an MDD and we subtract this new MDD from the initial one. This algorithm generalizes the previous one. It follows the same four steps. It isolates nodes having a common path in both MDD, then\nit removes the common arcs to the isolated nodes of the second last layer. Algorithm 1 is a possible implementation.\nFigure 5 shows the substraction of the GCS {1,{0,1,2,3},1} from the MDD representing all the tuples possibles for the values {0,1,2,3}. The GCS is isolated from the MDD. Then, the deletion of the arc labeled 1 of node d correspond to the deletion of only the tuples contained in the GCS.\nIt is difficult to bound the complexity of the deletion of T tuples, because the MDD created from them may compress the information."}, {"heading": "4.2 Addition of tuples to an MDD", "text": "The addition of tuples into MDD follows the same principles as for the deletion. That is, we also use the idea of path isolation. We also need to use this idea in order to avoid adding to many things. In other words, we need to precisely control what we add to the MDD.\nIn this case, the isolated path contains arcs labeled by the values of the tuple that must be added. It is performed in four steps:\n1. The isolation for the first layer 2. The isolation for any intermediate layer (neither the first nor the last). 3. The isolation for the last layer 4. We call an incremental the reduction operator on the MDD\nWe consider first the addition of one tuple \u03c4 . The two first steps are very similar as for the deletion. Excepted that at a point, there will be no more path in the MDD having the same subpath as \u03c4 . Otherwise, it would mean that \u03c4 is already in the MDD. Thus, at a certain moment we will not be able to identify any arc (mddNode, ni+1, \u03c4 [i]) as in step 2 in the deletion algorithm. When this case arises we can stop step 2 and directly create the path from the current isolated node to the terminal node. This path will be\nAlgorithm 1: In-place Deletion Algorithm DELETION(L,mdd1,mdd2)\n// Step 1: first layer for each (root(mdd1), v, y1) \u2208 \u03c9+(root(mdd1)) do\nif \u2203(root(mdd2), v, y2) \u2208 \u03c9+(root(mdd2)) then ADDARCANDNODE(L, 1, root(mdd1), v, y1, y2) DELETEARC(root(mdd1), v, y1)\n// Step 2: intermediate layers // L[i] is the set of nodes in layer i. for each i \u2208 1..r \u2212 2 do\nL[i]\u2190 \u2205 for each node x \u2208 L[i\u2212 1] do\nget x1 and x2 from x = (x1, x2) for each (x1, v, y1) \u2208 \u03c9+(x1) do\nif \u2203(x2, v, y2) \u2208 \u03c9+(x2) then ADDARCANDNODE(L, i, x, v, y1, y2) else CREATEARC(L, i, x, v, y1)\n// Step 3: last layer for each node x \u2208 L[r \u2212 1] do\nget x1 and x2 from x = (x1, x2) for each (x1, v, tt) \u2208 \u03c9+(x1) do\nif 6 \u2203(x2, v, y2) \u2208 \u03c9+(x2) then CREATEARC(L, r, x, v, tt)\nPREDUCE(L) return root\nADDARCANDNODE(L, i, x, y1, v, y2) if 6 \u2203y \u2208 L[i] s.t. y = (y1, y2) then\ny\u2190 CREATENODE(y1, y2) add y to L[i]\nCREATEARC(x, v, y)\nlabeled by the values of \u03c4 for the remaining layers. Step 3 can be skip. Step 4. remains the same and must be performed.\nThe complexity of the addition of a tuple is inO(rd) because for each isolated node we need to recreate its arcs.\nAddition of a set of tuples. We give an in-place algorithm for adding a set of tuples to an MDD. In this case, we transform the set of tuples into an MDD and we add this new MDD, named mdd2 to the initial one, named mdd1. This algorithm generalizes the previous one. It follows the same steps. Roughly, it isolates nodes having a common path in both MDDs. When a an arc belongs to mdd2 we create a new isolated node and we create an arc from the current isolated node to it. When an arc belongs only tomdd1, we create a arc from the current isolated node to the node in the mdd1. Algorithm 2 is a possible implementation.\nFigure 6 shows the effect of the addition of the tuple {1,2,1} in the MDD given in Figure 5. We can see the usefulness of isolated a path for avoiding the addition of the tuples {1,{0,1,3},1}. The right MDD shows the impact of the reduction on the MDD: nodes e and b are merged because they have the same outgoing arcs.\nIt is also difficult to bound the complexity of the addition of T tuples, because the MDD created from them may compress the information.\nDuality : The proximity of these algorithms is due to the duality of the problems: adding a tuple set T to an MDD M is equivalent to delete T from the complementary MDD of M ."}, {"heading": "4.3 Incremental Reduction", "text": "A reduction step is needed after the deletion and addition of tuples. Using a generic algorithm is costly because it will traverse all the nodes of the MDD and merge the equivalent ones. Since we consider that we add/delete tuples from an MDD which is reduced we can save some computations for the reduction applied after the operation. In fact, it is easy to show that only isolated nodes and nodes having an isolated node as neighbor need to be reconsidered for checking their equivalence. In addition, it is easy to identify isolated nodes because they belongs to the list L of the algorithms. The advantage of this approach is that the reduction step does not increase the complexity of the addition or deletion operations."}, {"heading": "5 Persistent modifications during the search", "text": "Consider C an MDD constraint, we propose to study the problem of the persistent deletions of tuples during the search for solutions and its consequences on the maintenance\nAlgorithm 2: In-place Addition Algorithm ADDITION(L,mdd1,mdd2)\n// Step 1: first layer for each v \u2208 \u03c9+(root(mdd1)) \u222a \u03c9+(root(mdd2)) do\nif \u2203 (root(mdd1), v, y1) \u2208 \u03c9+(root(mdd1)) then if \u2203 (root(mdd2), v, y2) \u2208 \u03c9+(root(mdd2)) then\nADDARCANDNODE(L, 1, root(mdd1), v, y1, y2) DELETEARC(L, i, root(mdd1), v, y1)\nelse ADDARCANDNODE(L, 1, root(mdd1), v, nil, y2) // Step 2: intermediate layers // L[i] is the set of nodes in layer i. for each i \u2208 1..r \u2212 2 do\nL[i]\u2190 \u2205 for each node x \u2208 L[i\u2212 1] do\nget x1 and x2 from x = (x1, x2) // If x1 is nil then \u03c9+(x1) is empty for each v \u2208 \u03c9+(x1) \u222a \u03c9+(x2) do\nif \u2203 (x1, v, y1) \u03c9+(x1) then if \u2203 (x2, v, y2) \u2208 \u03c9+(x2) then\nADDARCANDNODE(L, i, x, v, y1, y2)\nelse CREATEARC(L, i, x, v, y1) else ADDARCANDNODE(L, i, x, v, nil, y2)\n// Step 3: last layer for each node x \u2208 L[r \u2212 1] do\n// If x1 is nil then \u03c9+(x1) is empty for each v \u2208 \u03c9+(x1) \u222a \u03c9+(x2) do\nCREATEARC(L, i, x, v, tt)\nPREDUCE(L) return root\nof the arc consistency of C. In other words we would like to define a kind of dynamic arc consistency algorithm for C. It is not a fully dynamic arc consistency algorithm like DnAC-4 [4] or DnAC-6 [9] because we will not consider the addition of tuples in the MDD.\nMDD-4R is one of the most efficient algorithm for maintaining the arc consistency of C during the search for solutions. This is a adaptation of GAC-4 [16] to MDD which improves the incrementality of GAC-4 [17]. For each value v of each variable x[i], MDD-4R maintains List[i, v] the list of the arcs of the layer i labeled by v, and belonging to a path from the root to the terminal node. When a value is deleted all the arcs of List[i, v] are deleted from the MDD and these deletions are propagated. That is, each node which has no longer any incoming or outgoing arc is deleted. When a node n is deleted, for instance when it has no more incoming arc, this may lead to the deletion of some arcs, for instance the arcs outgoing from n, and MDD-4R checks for each label v whether there is another arc of the same layer having this label. If it is not the case, then\nthe value v is deleted from the domain of its variable. The strong advantage of MDD-4R is that it does not systematically update the data structures by deleting elements. When it can identify that more than half of the elements of a set will be deleted, it recomputes the set from scratch by adding to it the valid elements. In this case, we say that we \u201creset\u201d the set. This idea can be implemented efficiently with sparse sets and it strongly improves the behavior of the algorithm in practice.\nWe propose a simple way for dealing with persistent deletions. When a persistent modification arises for a node nd of the tree search, we will need to also apply this deletion for the ascendant nodes of nd. In addition, we need to be able to backtrack the current MDD from nd to its parent node and so on... But the deletion of a tuple from an MDD may deeply modified the MDD by adding nodes and removing arcs, so we may have some issues with the backtracking because we will need to reintroduce some arcs. A simple solution for this problem consists of saving the current MDD when a persistent deletion arises for the node nd. Then, when nd is backtracked, first we restore the MDD to the saved MDD and we apply the operations required by the backtrack to it. These modifications surely works on the saved MDD. Then, we save the restored MDD and redo all the persistent deletions that have been made from node nd during the search for a solution. This methods also works well for Table constraint because deleting a tuple is quite simple.\nNote that it is required to restart the arc consistency algorithm associated with each constraint impacted by the persistent deletion after a backtrack because some values may be no longer valid.\nThis algorithm can be improved but the algorithm becomes quite complex and is out of the scope of this paper."}, {"heading": "6 Experiments", "text": "The goal of these experiments is not to show that MDD-4R is a competitive algorithms compared with GAC-4R or some other efficient algorithms for Table constraints, even if we recall some results. This study has already been done in [17]. We aim at showing that even when performing deletions, an MDD approach is competitive with a Table approach, even if it uses compressed tuples.\nMachines MacBook Pro, Intel Core I7, 2,3GHz, 8GB memory.\nSolveur or-tools 3158.\nSelected Instances We build random instances for having a global pictures of the behaviors of the two approaches.\nGAC-4R vs MDD-4R We recall the advantage of MDD-4R over GAC-4R when there are a large number of tuples (See Figure 7).\nImpacts of Deletions We study the number of modifications triggered by the deletions of tuples. The tuple set involves 6 variables and 5 values. Figure 8 shows the results for three types of tuple sets one having a low tightness (8%), medium tightness (15%) and high tightness (25%). We observe a linear evolution for the Table constraint which is normal. The MDD approach requires less modifications. Surprisingly, the best results are obtained for the low or high densities. The worst case for MDDs seems to be a medium density. This can be explained by the fact that the modifications have a lot of work to do and there are a lot of nodes. High density are strongly compressed, whereas there are less work to do for low density.\nDeletions of tuples during the search We consider a problem involving constraints of arity 6. Each constraint is defined from a Table having 230 000 tuples. We search for all solutions and perform 100 000 persistent modifications during this search. This lead to 600 000 modifications for the Table constraints, because we need to check whether a deleted tuple was a support or not for each of its value. Interestingly, the number of modifications ( creation/deletion of arcs and nodes) triggered for the MDD is 135 000 . This is smaller. This comes from the fact that an MDD compresses the tuples. Thus, more operations may be required when one tuple is deleted but the data structure remains compressed and so remains more powerful. The following table gives us some information about the time needed for performing these operations. Once again, the MDD approach performs well."}, {"heading": "7 Conclusion", "text": "We have given an algorithm for transforming tuple sets, GCS and tuple sequences into an MDD. Then, we have described efficient in-place algorithms for adding or deleting tuples from an MDD. At last, we have considered the dynamic modification of an MDD constraint and proposed a dynamic algorithm for maintaining the arc consistency during the search for solution. We have also shown some experiments. This works contributes to the proof that an MDD approach is competitive with a Table approach for representing constraints in extension in constraint programming."}], "references": [{"title": "A constraint store based on multivalued decision diagrams", "author": ["Henrik Reif Andersen", "Tarik Hadzic", "John N. Hooker", "Peter Tiedemann"], "venue": "In CP,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Mdd propagation for sequence constraints", "author": ["D. Bergman", "A. Cire", "W-J. van Hoeve"], "venue": "Jour- nal of Artificial Intelligence Research,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Manipulating mdd relaxations for combinatorial optimization", "author": ["David Bergman", "Willem Jan van Hoeve", "John N. Hooker"], "venue": "In CPAIOR,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Arc-consistency in dynamic constraint satisfaction problems", "author": ["C. Bessi\u00e8re"], "venue": "Proceedings AAAI,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1991}, {"title": "Symbolic boolean manipulation with ordered binary decision diagrams", "author": ["R.E. Bryant"], "venue": "ACM Computing Surveys,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1992}, {"title": "Graph-based algorithms for boolean function manipulation", "author": ["Randal E. Bryant"], "venue": "IEEE Trans- actions on Computers,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1986}, {"title": "An mdd-based generalized arc consistency algorithm for positive and negative table constraints and some global", "author": ["K. Cheng", "R. Yap"], "venue": "constraints. Constraints,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Maintaining generalized arc consistency on ad hoc r-ary constraints", "author": ["Kenil C.K. Cheng", "Roland H.C. Yap"], "venue": "In CP,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Global cut framework for removing symmetries", "author": ["F. Focacci", "M. Milano"], "venue": "In Proc. CP\u201901,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2001}, {"title": "Mdd propagators with explanation", "author": ["G. Gange", "P. Stuckey", "Radoslaw Szymanek"], "venue": "Con- straints,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Data structures for generalised arc con- sistency for extensional constraints", "author": ["I. Gent", "C. Jefferson", "I. Miguel", "P. Nightingale"], "venue": "In Proc", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Approximate com- pilation of constraints into multivalued decision diagrams", "author": ["Tarik Hadzic", "John N. Hooker", "Barry O\u2019Sullivan", "Peter Tiedemann"], "venue": "In CP,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "A systematic approach to mdd- based constraint programming", "author": ["Samid Hoda", "Willem Jan van Hoeve", "John N. Hooker"], "venue": "In CP,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Practical reformulations with table constraints", "author": ["Olivier Lhomme"], "venue": "In ECAI, pages 911\u2013912,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Good old discrete relaxation", "author": ["R. Mohr", "G. Masini"], "venue": "In Proceedings of ECAI-88,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1988}, {"title": "Improving GAC-4 for table and MDD constraints", "author": ["G. Perez", "J-C. R\u00e9gin"], "venue": "In Principles and Practice of Constraint Programming - 20th International Conference,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Efficient operations on mdds for building constraint programming models", "author": ["G. Perez", "J-C. R\u00e9gin"], "venue": "In International Joint Conference on Artificial Intelligence,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Improving the expressiveness of table constraints", "author": ["J-C. R\u00e9gin"], "venue": "In CP\u201911, proceedings work- shop ModRef\u201911,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}], "referenceMentions": [{"referenceID": 7, "context": "Cheng and Yap have proposed to compress the tuple set of the constraint by using Multi-valued Decision Diagrams (MDD) and designed mddc one of the first filtering algorithm establishing arc consistency for them [8,7].", "startOffset": 211, "endOffset": 216}, {"referenceID": 6, "context": "Cheng and Yap have proposed to compress the tuple set of the constraint by using Multi-valued Decision Diagrams (MDD) and designed mddc one of the first filtering algorithm establishing arc consistency for them [8,7].", "startOffset": 211, "endOffset": 216}, {"referenceID": 15, "context": "Recently, Perez and R\u00e9gin have presented MDD-4R a new algorithm which improves mddc [17].", "startOffset": 84, "endOffset": 88}, {"referenceID": 16, "context": "They have also introduced an efficient algorithm for reducing a MDD and some powerful algorithms for combining MDDs [18].", "startOffset": 116, "endOffset": 120}, {"referenceID": 13, "context": "They can be specified either directly, by input from the user, or indirectly by synthesizing other constraints or subproblems [15,14].", "startOffset": 126, "endOffset": 133}, {"referenceID": 12, "context": "They can be specified either directly, by input from the user, or indirectly by synthesizing other constraints or subproblems [15,14].", "startOffset": 126, "endOffset": 133}, {"referenceID": 8, "context": "They have been reinforced in order to deal either from tuples or from sequences of tuples [10,12,19].", "startOffset": 90, "endOffset": 100}, {"referenceID": 10, "context": "They have been reinforced in order to deal either from tuples or from sequences of tuples [10,12,19].", "startOffset": 90, "endOffset": 100}, {"referenceID": 17, "context": "They have been reinforced in order to deal either from tuples or from sequences of tuples [10,12,19].", "startOffset": 90, "endOffset": 100}, {"referenceID": 5, "context": "It is a multiple-valued extension of BDDs [6].", "startOffset": 42, "endOffset": 45}, {"referenceID": 0, "context": "An MDD, as used in CP [1,13,14,3,11], is a rooted directed acyclic graph (DAG) used to represent some multi-valued function f : {0.", "startOffset": 22, "endOffset": 36}, {"referenceID": 11, "context": "An MDD, as used in CP [1,13,14,3,11], is a rooted directed acyclic graph (DAG) used to represent some multi-valued function f : {0.", "startOffset": 22, "endOffset": 36}, {"referenceID": 12, "context": "An MDD, as used in CP [1,13,14,3,11], is a rooted directed acyclic graph (DAG) used to represent some multi-valued function f : {0.", "startOffset": 22, "endOffset": 36}, {"referenceID": 2, "context": "An MDD, as used in CP [1,13,14,3,11], is a rooted directed acyclic graph (DAG) used to represent some multi-valued function f : {0.", "startOffset": 22, "endOffset": 36}, {"referenceID": 9, "context": "An MDD, as used in CP [1,13,14,3,11], is a rooted directed acyclic graph (DAG) used to represent some multi-valued function f : {0.", "startOffset": 22, "endOffset": 36}, {"referenceID": 16, "context": "However, a new reduction algorithm has been recently proposed by Perez and R\u00e9gin [18].", "startOffset": 81, "endOffset": 85}, {"referenceID": 10, "context": "for compressing tuple sets [12].", "startOffset": 27, "endOffset": 31}, {"referenceID": 6, "context": "A trie can be transformed into an MDD by merging all the leaves into the terminal node tt and by applying the reduction operation [7].", "startOffset": 130, "endOffset": 133}, {"referenceID": 8, "context": "A GCS (Global Cut Seed), is a compact representation of a tuple set [10].", "startOffset": 68, "endOffset": 72}, {"referenceID": 17, "context": "In order to remedy to this problem, tuple sequences have been introduced [19].", "startOffset": 73, "endOffset": 77}, {"referenceID": 17, "context": "Nevertheless, it may create an exponential number of tuple sequences [19].", "startOffset": 69, "endOffset": 73}, {"referenceID": 5, "context": "For instance, Bryant define some algorithms for applying different operators [6,5].", "startOffset": 77, "endOffset": 82}, {"referenceID": 4, "context": "For instance, Bryant define some algorithms for applying different operators [6,5].", "startOffset": 77, "endOffset": 82}, {"referenceID": 1, "context": "Some algorithms have also been proposed for applying operators on MDDs [2,18].", "startOffset": 71, "endOffset": 77}, {"referenceID": 16, "context": "Some algorithms have also been proposed for applying operators on MDDs [2,18].", "startOffset": 71, "endOffset": 77}, {"referenceID": 0, "context": "First we identify a1 = (r, n1, \u03c4 [1]) the arc of the first layer labeled by \u03c4 [1] the first value of the tuple.", "startOffset": 33, "endOffset": 36}, {"referenceID": 0, "context": "First we identify a1 = (r, n1, \u03c4 [1]) the arc of the first layer labeled by \u03c4 [1] the first value of the tuple.", "startOffset": 78, "endOffset": 81}, {"referenceID": 0, "context": "We create the node ne1, the arc (r, ne1, \u03c4 [1]) and we delete the arc a1.", "startOffset": 43, "endOffset": 46}, {"referenceID": 3, "context": "It is not a fully dynamic arc consistency algorithm like DnAC-4 [4] or DnAC-6 [9] because we will not consider the addition of tuples in the MDD.", "startOffset": 64, "endOffset": 67}, {"referenceID": 14, "context": "This is a adaptation of GAC-4 [16] to MDD which improves the incrementality of GAC-4 [17].", "startOffset": 30, "endOffset": 34}, {"referenceID": 15, "context": "This is a adaptation of GAC-4 [16] to MDD which improves the incrementality of GAC-4 [17].", "startOffset": 85, "endOffset": 89}, {"referenceID": 15, "context": "This study has already been done in [17].", "startOffset": 36, "endOffset": 40}], "year": 2015, "abstractText": "We study the relations between Multi-valued Decision Diagrams (MDD) and tuples (i.e. elements of the Cartesian Product of variables). First, we improve the existing methods for transforming a set of tuples, Global Cut Seeds, sequences of tuples into MDDs. Then, we present some in-place algorithms for adding and deleting tuples from an MDD. Next, we consider an MDD constraint which is modified during the search by deleting some tuples. We give an algorithm which adapts MDD-4R to these dynamic and persistent modifications. Some experiments show that MDD constraints are competitive with Table constraints.", "creator": "LaTeX with hyperref package"}}}