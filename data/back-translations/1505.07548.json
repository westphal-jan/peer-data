{"id": "1505.07548", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-May-2015", "title": "Multidefender Security Games", "abstract": "Stackelberg's safety game models and related calculation tools have been used in a number of security systems with high consequences, such as LAX dog patrols and the Federal Air Marshal Service. These models focus on isolated systems with only one defender, although they are part of a more complex system with multiple actors. In addition, many real-life systems such as transportation networks and the power grid exhibit interdependencies between targets, and thus also between decision makers who are jointly tasked with protecting these targets. To understand such strategic interactions between multiple defenders, we examine game theory models of safety games with multiple defenders. Unlike most previous analyses, we focus on situations where each defender must protect multiple targets, so that even the best response decision of a single defender is generally highly non-trivial. We begin with an analytical study of safety games with independent goals, which have an equilibrium and price anarchy analysis of three models with increasing generality to protect the defenders, noting that all models have different incentives to protect the targets.", "histories": [["v1", "Thu, 28 May 2015 04:54:53 GMT  (1727kb,D)", "http://arxiv.org/abs/1505.07548v1", null]], "reviews": [], "SUBJECTS": "cs.GT cs.AI", "authors": ["jian lou", "andrew m smith", "yevgeniy vorobeychik"], "accepted": false, "id": "1505.07548"}, "pdf": {"name": "1505.07548.pdf", "metadata": {"source": "CRF", "title": "Multidefender Security Games", "authors": ["Jian Lou", "Andrew M. Smith"], "emails": ["jian.lou@vanderbilt.edu", "amsmi@ucdavis.edu", "yevgeniy.vorobeychik@vanderbilt.edu"], "sections": [{"heading": "1. Introduction", "text": "Security, physical and cyber, has come to the forefront of national attention, particularly after 9/11. Among the variety of approaches that are used to tackle security problems, from risk analysis to red teaming, game theory has had a significant impact, with tools based on game theoretic analysis having been deployed in LAX airport to schedule canine patrols (Paruchuri et al., 2008; Jain et al., 2008; Pita et al., 2009), by Federal Air Marshall Service (FAMS) to schedule the air marshals (Kiekintveld et al., 2009; Jain et al., 2010, 2010), and by the US Coast Guard to schedule boat patrols (Shieh et al., 2012). All of these deployments, and numerous other related efforts, have cast security as a Stackelberg game between a single defender and an attacker, in which the defender leads (i.e., acts first),\nar X\niv :1\n50 5.\n07 54\n8v 1\n[ cs\n.G T\n] 2\n8 M\nay 2\nchoosing a probability distribution over defense actions, and the attacker, upon learning this probability distribution, chooses a response (Conitzer & Sandholm, 2006). In many cases, the attacker is modeled as a rational agent who selects an optimal response and, in the many applications that compute a Strong Stackelberg equilibrium, an attacker is often assumed to break ties in the defender\u2019s favor (Paruchuri et al., 2008; Korzhyk et al., 2011).\nA crucial assumption that all these efforts have in common is that a single defender is responsible for all the targets that need protection, and that she has control over all of the security resources. However, there are many domains in which there are multiple defender agencies who are in charge of different subsets of all targets. In practice, numerous parties are responsible for security; indeed, the fact that the basic framework has been deployed by different entities and agencies makes this manifest already. If security decisions made by different parties were entirely independent, both from the defender\u2019s and the attacker\u2019s perspective, a single-defender model would be entirely satisfactory. However, the assets protected by different entities are typically interdependent, or, more generally, have value to others who are not involved in security decisions. Additionally, attackers, insofar as they may target different sectors under the charge of different defenders, are resource constrained, implicitly coupling otherwise independent targets.\nAn important motivating application for our multidefender security game is security and reliability in the power grid. Independent System Operators (ISOs) and profit-driven independent utility operators are largely responsible for operating and controlling subsystems of the entire grid (Lazar, 2011). These operators are held responsible for the reliability of their system, and thus have independent, and possibly even competing, goals with neighboring ISOs. As such, their security decisions are made independently, despite the interdependencies present between subsystems. As a result of this organization, cascading failures in the power grid can present a great threat to the entire system, even when an explicit attacker is not present. This problem is exacerbated by the fact that components in the grid are controlled by multiple entities and are also dependent on other independently operated utility networks (water, communications, natural gas, etc.).\nWe extend the previous Stackelberg game models in two ways:\n1. an analytic equilibrium and price of anarchy (PoA) characterization of 3 multidefender security scenarios, in which we assume homogeneous and independent valuations of the targets for each defender; and\n2. a computational analysis leveraging a novel mixed-integer linear program (MIP) approach for computing a defender\u2019s best response, combined with a novel heuristic method for approximating equilibria in interdependent multi-defender security games with heterogeneous targets.\nIn case 1 where there are multiple defenders, and the values of the targets are independent and homogeneous among the defenders, our analysis is focused on three models of such multi-defender games (each varying in their level of generality). We show that a Nash equilibrium among defenders in this two-stage game model need not always exist, even when the defenders utilize randomized strategies (i.e., probability distributions over target protection levels); this is distinct from a model in which the attacker moves simultaneously with the defenders, where a mixed strategy equilibrium is guaranteed to exist. When\nan equilibrium does exist, we show that the defenders protect all of their targets with probability 1 in all three models, whereas the socially optimal protection levels are generally significantly lower. When no equilibrium exists, we characterize the best approximate Nash equilibrium (that is, one in which defenders have the least gain from deviation), showing that over-investment is substantial in this case as well. Our price of anarchy (PoA) analysis, which relies on the unique equilibrium when it exists, and the approximate equilibrium otherwise, demonstrates a surprising finding: whereas PoA is unbounded in the simpler models, increasing linearly with the number of defenders, the more general model shows this to be an atypical special case achieved when several parameters are exactly zero. More generally, PoA is bounded by a constant.\nFor case 2, we introduce interdependencies between targets. Because closed-form analysis in this setting is intractable, we propose a novel mixed-integer linear programming approach combined with a novel heuristic method to approximate equilibrium behavior. Unlike other multi-defender models (e.g., (Kunreuther & Heal, 2003; Chan et al., 2012; Bachrach et al., 2013; Acemoglu et al., 2013)), our approach maintains the typical complexity of individual defender decision process in the multi-defender framework, with each defender responsible for securing many, possibly interdependent, targets. Our setup gives rise to two competing externalities of security decisions: a positive externality, where greater security implies reduced contagion risk to other defenders, and a negative externality, which arises because high security by one player pushes the attacker to attack someone else\u2019s assets. We study the impact of competing externality effects of defense on the resulting Nash equilibrium outcomes as a function of network topology (using both synthetic and real networks), interdependent risk, and the level of system decentralization. One of our key findings is that the impact of system decentralization on security and welfare can be non-monotonic when systems are highly interdependent: high levels of decentralization can yield near-optimal outcomes, even as moderate decentralization results in significant underinvestment. With weak interdependencies, on the other hand, an increasingly decentralized system tends more strongly to over-invest in security.\nThe remainder of our paper is outlined as follows. In Section 2, we give an overview of related work. In Section 3, we briefly outline the definitions and solution concepts of our independent and interdependent multi-defender security games, respectively. Section 4 provides an equilibrium and PoA analysis of the homogeneous, independent security game models. Section 5 further explains the interdependent multi-defender model, and presents results on well-studied synthetic networks, as well as on real-world power grid networks."}, {"heading": "2. Related Work", "text": "Our work, like much work in the recent security game literature, builds on the notion of Stackelberg games (Osborne & Rubenstein, 1994), which model commitment in strategic settings. The first thorough computational treatment of randomized (mixed strategy) commitment was due to Conitzer and Sandholm (2006). In this line of work, of greatest relevance to our effort are multiple-leader Stackelberg games (Sherali, 1984; DeMiguel & Xu, 2009; Leyffer & Munson, 2007; Rodoplu & Raj, 2010; Kulkarni & Shanbhag, 2014; Sinha et al., 2014). In many cases, these approaches leverage specialized problem structure, and are not immediately applicable to our setting. In particular, Sherali (1984) and DeMiguel\nand Xu (2009) focus on relatively simple models with firms setting production quantity (a single variable), aiming to maximize profit. Both show existence and uniqueness of equilibria in their setting, and leverage these characterization results to obtain solutions to the games. Similarly, Rodoplu and Raj (2010) consider a relatively simple model of network competition in which leaders are nodes setting prices for packets transmitted through them; again, each leader only sets a single variable, the utility functions are problem-specific, and algorithms are specialized to the particular problem structure (and are inapplicable to our setting).\nSinha et al. (2014) propose an evolutionary algorithm for solving bi-level Stackelberg problems, but their problem structure is also highly specific to the domain of interest (firms choosing production, investment, and marketing, and maximizing profit), and the evolutionary algorithm leverages significant simplifications, such as the assumption that the market eventually clears. Leyffer and Munson (2007) present a very generic multi-leader multi-follower setting and solution framework in the context of shared complementarity constraints (which is the case for our problem, where a single follower attacks a single target), but rely on separability of objective functions in leader and follower variables, the assumption that does not obtain in our setting (in addition, their approach only scales to 2-4 leaders, whereas we are able to approximately solve games with 64 leaders). Kulkarni and Shanbhag (2014) offer a deep theoretical treatment of a relatively broad class of multileader multi-follower games, but much of their analysis and positive results are restricted to potential games, and they do not offer specific algorithmic suggestions. Like us, they leverage shared constraints to resolve the issue of incompatible leader assumptions about the follower tie-breaking behavior.\nOur point of departure is a class of Stackelberg games specifically pertinent to security: commonly, these are simply known as security games (Korzhyk et al., 2011; Paruchuri et al., 2008; Jain et al., 2010; Vorobeychik et al., 2011). In these games, a single defender allocates a set of resources among potential targets of attack in a randomized fashion (that is, the defender commits to a probability distribution over resource-to-target mappings), with an attacker choosing a single target to attack after observing the defender\u2019s strategy. Almost universally in this domain, a Strong Stackelberg equilibrium (SSE) is a solution concept of choice. In SSE, the follower (attacker) is assumed to break ties in the defender\u2019s favor. As we will see below, this solution concept presents conceptual and technical problems in a multi-defender setting.\nA similar, though mostly orthogonal, line of work are network interdiction problems (Cormican et al., 1998; Woodruff, 2003), in which a leader attempts to interdict a network over which the follower subsequently solves a variation of a network flow problem. Unlike the literature on security games, as well as our setting, network interdiction problems are almost universally zero-sum (minimax).\nAnother somewhat related line of work considers the problem of coordination and teamwork among multiple defenders in a purely cooperative setting (Jiang, Procaccia, Qian, Shah, & Tambe, 2013; Shieh, Jiang, Yadav, Varakantham, & Tambe, 2014a). This work, however, is entirely unlike ours: in particular, our primary focus is on the impact of incentive misalignment among the defenders with different (though certainly related) motivations, rather than coordination issues and teamwork. While often effective coordination among multiple defenders can be achieved, just as often (if not predominantly) decentral-\nization of decision making processes and resources inherently give rise to distinct, and often conflicting, incentives among defenders.\nAmong the earliest multi-defender models is the literature on interdependent security games (Kunreuther & Heal, 2003), in which interactions among multiple defenders are modeled as an n-player, 2-action game, where a player decides whether to invest in security; however, no attacker is considered. More recently, time-dependent scenarios where coordination of defender resources amongst multiple defenders is assumed have been studied using Markov decision processes (Shieh et al., 2014b). Since total cooperation is assumed, this model effectively reduces to a single defender game in which the defender controls all resources. A recent extension, interdependent defense games (Chan et al., 2012), does consider an attacker who acts simultaneously with the defenders, rather than after observing the joint defense configuration, as in our model. Interdependent defense games have also been studied in the context of traffic infrastructure defense (Alderson et al., 2011). Two recent efforts studying multi-defender games explicitly model interdependence among targets through a probabilistic contagion process (Bachrach et al., 2013; Acemoglu et al., 2013). Like our paper, they consider attackers who observe the joint defense prior to making a decision, but each defender is restricted to secure a single node, and strategy space is assumed to be continuous. Vorobeychik et al. (2011) is, to our knowledge, the only other attempt to study strategic settings related to security in which each player\u2019s decision space is combinatorial. However, this work does not consider a strategic attacker."}, {"heading": "3. Multidefender Models", "text": "Our modeling effort proceeds in four steps, each generalizing the previous. As we see below, each generalization step reveals new and surprising insights about the multi-defender security setting, allowing us to appreciate the fundamental incentive forces. The first three models deal with homogeneous, independent targets and will be analyzed exactly using Nash equilibrium and price of anarchy (PoA) analysis. Our final model introduces interdependencies, and will be analyzed using computational methods."}, {"heading": "3.1 The Baseline Model", "text": "We start with a model which most reflects the related literature: in particular, this model involves n defenders and a single attacker, with each defender engaged in protecting a single target. Each target has the same value to the defender v > 0. We suppose that the defender has two discrete choices: to protect the target, or not. In addition, the defender can randomly choose among these; our focus is on these coverage probabilities (i.e., the probability of protecting, or covering, the target), which we denote by qi for a given defender i. The attacker is strategic, can observe the defenders\u2019 coverage probabilities, and chooses a target that maximizes the damage. We assume that attacker is indifferent among the targets, and attacks the target with the lowest coverage probability, breaking ties uniformly at random. In a given scenario, for all defenders, the attacker\u2019s strategy is a vector of probabilities P =< p1, p2, ..., pn >, where pi is the probability of attacking the target protected by defender i, with \u2211n i=1 pi = 1.\nWe assume that if the attacker chooses to attack a target corresponding to defender i and defender i chooses to protect the target, then the utility of both is 0, and if the\nattacker attacks the target but it is not protected, then the utility of the defender is \u2212v while the attacker\u2019s utility is v. If a defender chooses to cover a target, it will incur a cost c > 0. Additionally, we assume that targets are independent, i.e., if defender i is successfully attacked, all other defenders j 6= i receive 0 utility. We can thus define the expected utility of a defender i as\nui = piu a i + (1\u2212 pi)uui ,\nwhere uai is the utility of i if it is attacked, and u u i is the utility of i if it is not attacked. By the assumptions above,\nuai = \u2212(1\u2212 qi)v \u2212 qic = \u2212v + qi(v \u2212 c)\nuui = \u2212qic."}, {"heading": "3.2 The Multi-Target Model", "text": "Our key conceptual departure from related work is in allowing each defender to protect multiple targets, aligning it better with practical security domains. Specifically, suppose that there are n defenders, each protecting k \u2265 1 targets. Then the strategy of defender i will be a vector < qi1, qi2, ...qik >. The strategy profile of the attacker can then be described as a matrix of probabilities,  p11 p12 . . . p1k p21 p22 . . . p2k ... ... . . .\n... pn1 pn2 . . . pnk  in which \u2211n i=1 \u2211k j=1 pij = 1 and pij \u2265 0 for each i and j. The expected utility of a defender i in this model is\nui = k\u2211 j=1 piju a ij + (1\u2212 pij)uuij ,\nwhere uaij is the utility of target j to defender i if it is attacked, and u u ij is the utility of target j to i if it is not attacked. Using the notation introduced earlier, we have\nuaij = \u2212(1\u2212 qij)v \u2212 qijc = \u2212v + qij(v \u2212 c)\nuuij = \u2212qijc."}, {"heading": "3.3 The General Model", "text": "Generalizing further, we assume that if the attacker chooses to attack a target protected by defender i and the defender chooses to protect the target, then the utility of the target to defender i is U c, and if the attacker attacks the target but it is not protected, then the utility of the target to the defender is Uu. It is reasonable to assume that U c \u2265 Uu. If the target of defender i is not attacked, then we assume that the utility of the target for defender i is \u2126 \u2265 U c. Other assumptions are the same as those in the multi-target model. In the general model, therefore,\nuaij = qijU c + (1\u2212 qij)Uu \u2212 qijc = (U c \u2212 Uu \u2212 c)qij + Uu\nuuij = \u2126\u2212 qijc."}, {"heading": "3.4 The Interdependent Model", "text": "The previous three models featured three important restrictions: first, that target values are homogeneous, second, that targets are independent, and third, that defenders protect the same number of targets. We now relax these restrictions. Suppose that a defender i can choose from a finite set O of security configurations for each target j \u2208 Ti, where Ti is the set of targets under i\u2019s direct influence. Let T be the set of all targets, that is, T = \u222aiTi, with |T | = m. A configuration o \u2208 O for target j \u2208 Ti incurs a cost coj to the defender i. If the attacker attacks a target j \u2208 T while configuration o is in place, the expected value to a defender i is denoted by Uoi,j , while the attacker\u2019s value is V o j . We assume in this model that each player\u2019s utility depends only on the target attacked and its security configuration (Kiekintveld et al., 2009; Letchford & Vorobeychik, 2012). We denote by qoi,j the probability that the defender i chooses o at target j \u2208 Ti.\nWhile the problem we study assumes that that the utility of any player for a given target depends only on its security configuration o, there is a rather natural way to model interdependencies while retaining this structure, proposed by Letchford and Vorobeychik (2012). Specifically, suppose that dependencies between targets are represented by a graph (T,E), with T the set of targets (nodes) as above, and E the set of edges (j, j\u2032), where an edge from j to j\u2032 means that a successful attack on j may have impact on j\u2032. Each target j has associated with it a value, vij , for the defender i, which is the loss to i if j is affected (e.g., compromised, broken). The security configuration determines the probability zoj (j) that target j is affected if the attacker attacks it directly and the defense configuration is o. We model the interdependencies between the nodes as independent cascade contagion (Kempe et al., 2003; Letchford & Vorobeychik, 2012). The contagion proceeds starting at an attacked node j, affecting its network neighbors j\u2032 each with probability rj,j\u2032 , the contagion then spreads from the newly affected nodes j\u2032 to their neighbors, and so on. The contagion can only occur one time along any network edge, and once a node is affected it stays affected through the diffusion process. Each player\u2019s valuation for each target is then updated based on the probability of a failure cascading to one of the player\u2019s owned targets."}, {"heading": "3.5 The Weakness of Strong Stackelberg Equilibrium", "text": "By far the most important solution concept in Stackelberg security games is a Strong Stackelberg equilibrium (SSE). A SSE is characterized by an assumption that the attacker breaks ties in defender\u2019s favor. When there is a single defender, this is well defined, and quite reasonable when the defender can commit to a mixed strategy: a slight adjustment in the defense policy will force the attacker to strictly prefer the desired option, with little loss to the defender. As we now illustrate, however, SSE is fundamentally problematic in a multidefender context, because the notion of \u201cbreaking ties in defender\u2019s favor\u201d is no longer well defined in general, as we must specify which defender will receive the favor.\nTo see concretely what goes wrong, consider the example in Figure 1. In this example there are two defenders, one who defends the target on the left, while the other defends the target on the right. Both defenders value their respective targets at 1, and have no value for the counterpart\u2019s target. The cost of defending each target is 0 < \u03b4 1. Now, consider a strategy profile in which qj = 0 for both targets t, and let us focus on the best\nresponse of the first (left) defender. If this defender attempts to compute an SSE by fixing the strategy of the second player, he perceives his utility under the current strategy profile to be 1, since he would assume that the attacker breaks ties in his favor and, thus, attacks the defender on the right. By the same logic, the defender on the right will assume that the attacker will attack his counterpart, and perceive qj = 0 to be the best response. Since the attacker actually attacks one of them, the best response of the defender being attacked is to defend with a small probability, pushing the attacker towards the other target. What goes wrong here is that both players assume that the attacker attacks the other (breaks ties in their favor), which is inconsistent with the assumption that the attacker will certainly attack some target.1"}, {"heading": "3.6 Solution Concepts", "text": "Since the classic (two-player) SSE solution concept used in Stackelberg security games does not conceptually extend to be an individual defender best-response problem in the multidefender setting, we need to consider an alternative. One option is to compute an arbitrary subgame perfect equilibrium. However, we wish to impose a natural constraint on the solution concept that the attacker\u2019s best response be computed consistently for any joint defense policy, just as it is in a SSE (in other words, we wish to fix a tie-breaking rule). One natural tie-breaking rule is that the attacker chooses a target uniformly at random from the set of all best responses. We call the corresponding solution concept (which is a refinement of the subgame perfect equilibrium of our game) the Average-case Stackelberg Equilibrium (ASE). The crucial property of this solution concept that we desire is that the attacker\u2019s behavior presumed by a defender\u2019s best response problem is independent of that defender\u2019s identity, a property that SSE violates. As we demonstrate below, ASE is not guaranteed to exist, in which case we focus on -equilibria, in which no defender gains more than by deviating; in particular, we will consider -equilibria with the smallest attainable .\nTo measure how the efficiency of the game degrades due to selfish behavior of the defenders, we consider Utilitarian Social Welfare and ( )-Price of Anarchy in our paper. Utilitarian Social Welfare is the sum of all defenders\u2019 payoffs. For the smallest attainable\n1. The problem we observe is similar to the issue of inconsistent conjectures the leaders in a multi-leader Stackelberg game could have about follower behavior noted by Kulkarni and Shanbhag (Kulkarni & Shanbhag, 2014). The solution we propose below\u2014ASE\u2014has the effect of imposing a shared constraint, the idea introduced by Kulkarni and Shanbhag generically. We note, however, that our concern here is not merely the fact that inconsistent conjectures lead to disequilibrium; rather, they could lead to nonsensical equilibria!\n, we define -Price of Anarchy ( -PoA) as follows:\n-PoA = SWO SWE\nwhere SWO is the optimal (utilitarian) social welfare that can be obtained (i.e., if there was a single defender), and SWE is the worst-case (utilitarian) social welfare in -equilibrium. An underlying assumption of this definition is that the value of SWO and SWE are both positive. If they are both negative, then -PoA will be the reciprocal of above equation. Note that the ordinary Price of Anarchy is a special case of -Price of Anarchy with = 0."}, {"heading": "4. Equilibrium Analysis of Independent Multi-Defender Security Games", "text": "In this section, we consider scenarios in which the values of the targets are independent and homogeneous among the defenders. Our equilibrium and Price of Anarchy analysis will show that a Nash equilibrium among defenders in the two-stage game model (equivalently, ASE) need not always exist, even when the defenders utilize randomized strategies (i.e., probability distributions over target protection levels). For cases when there is no Nash equilibrium, we make use of approximate Nash (ASE) equilibrium and the associated ( )- Price of Anarchy."}, {"heading": "4.1 The Baseline Model", "text": "Our first result presents necessary and sufficient conditions for the existence of a Nash equilibrium among defenders in the baseline model, and characterizes it when it does exist.\nTheorem 1. In the Baseline model, Nash equilibrium exists if and only if v \u2265 c. In this equilibrium all targets are protected with probability 1.\nProof. Firstly, we claim that Nash equilibrium among defenders can appear only if all targets have the same coverage probability q. Otherwise, some defender j who has probability 0 of being attacked has the incentive to decrease her qj . To find the Nash equilibria, we need only consider strategy profiles in which all targets have the same coverage probability.\nWhen all defenders use the same coverage probability q, each defender\u2019s expected utility is\nu = (v \u2212 cn)q \u2212 v\nn .\nIf q < 1, some defender i could increase q to q + \u03b4, where \u03b4 is a small positive real number, to avoid being attacked, and receive utility u\u2032 = \u2212(q + \u03b4)c, so that\nu\u2032 \u2212 u = v(1\u2212 q)\u2212 nc\u03b4 n .\nAs \u03b4 can be arbitrarily small, u\u2032\u2212u > 0 when q < 1. Consequently, when q < 1, a defender always has an incentive to deviate, which implies that the only possible Nash equilibrium can be for all players to play q = 1.\nWhen all defenders use coverage probability q = 1, each earns an expected utility of\nu = \u2212c.\nIf a defender i decreases her coverage probability to q\u2032 < 1, then she will be attacked with probability 1, and receive expected utility u\u2032 = \u2212v + q\u2032(v \u2212 c), so that\nu\u2032 \u2212 u = (v \u2212 c)(q\u2032 \u2212 1).\nIf v \u2265 c, then u\u2032 \u2212 u \u2264 0, and q = 1 is indeed a Nash equilibrium. If v < c, however, u\u2032 \u2212 u > 0, which implies that a Nash equilibrium does not exist.\nThus, if a Nash equilibrium does exist, it is unique, with all defenders always protecting their targets. But what if the equilibrium does not exist? Next, we characterize the (unique) -equilibrium with the minimal that arises in such a case. We will use this approximate equilibrium strategy profile as a prediction of the defenders\u2019 strategies.\nTheorem 2. In the Baseline model, if v < c, the optimal -equilibrium is for all defenders to cover their target with probability vc . The corresponding is v(c\u2212v) cn .\nProof. We firstly consider strategy profiles in which all targets have the same probability q of being protected. Then each defender\u2019s expected utility is\nu = (v \u2212 cn)q \u2212 v\nn .\nSuppose 0 \u2264 q < 1. If a defender i slightly increases q to q + \u03b41, she could receive a utility u\u2032 = \u2212(q + \u03b41)c, with\nu\u2032 \u2212 u = v(1\u2212 q)\u2212 nc\u03b41 n < v(1\u2212 q) n .\nSuppose 0 < q \u2264 1. If a defender i slightly decreases q to q\u2212 \u03b42, she could receive utility u\u2032\u2032 = \u2212v + (q \u2212 \u03b42)(v \u2212 c), with\nu\u2032\u2032 \u2212 u = v(1\u2212 q)(1\u2212 n) + \u03b42n(c\u2212 v) n .\nSince \u03b42 \u2264 q,\nu\u2032\u2032 \u2212 u \u2264 v(1\u2212 q)(1\u2212 n) + qn(c\u2212 v) n = v(1\u2212 q) n + (qc\u2212 v).\nLet d1 = v(1\u2212q) n , d2 = v(1\u2212q) n + (qc\u2212 v). If q = 0, a defender could deviate to increase utility by at most vn . If q = 1, a defender could deviate to increase utility by at most (c \u2212 v). When 0 < q \u2264 vc , we have that d2 \u2264 d1, and it is d1-equilibrium. When v c < q < 1, we have that d2 > d1, and it is d2-equilibrium. Putting everything together, there is an -equilibrium with\n=\n{ v(1\u2212q) n , if 0 \u2264 q \u2264 v c ;\nv(1\u2212q) n + (qc\u2212 v), if v c < q \u2264 1.\nMoreover, q = vc gives us the unique minimal = v(c\u2212v) cn when all defenders use the same coverage probabilities.\nWe now claim that the v(c\u2212v)cn -equilibrium could only exist when all defenders play an identical coverage probability. Suppose defenders use different coverage probabilities. Then there are \u03b1 defenders for 1 \u2264 \u03b1 < n who have the same minimal probability q\u2032 of protecting their targets. The expected utility for each defender among these \u03b1 defenders is:\nue = (v \u2212 c\u03b1)q\u2032 \u2212 v\n\u03b1 .\nWhen vc < q \u2032 \u2264 1, some defender i among these \u03b1 defenders could decrease her probability to 0 to get a utility of u1 = \u2212v, with\nu1 \u2212 ue = v(1\u2212 q\u2032) \u03b1 + (q\u2032c\u2212 v) > v(1\u2212 q \u2032) n + (q\u2032c\u2212 v) > v(c\u2212 v) cn .\nWhen 0 \u2264 q\u2032 \u2264 vc , some defender i among these \u03b1 defenders could increase her probability to q\u2032 + \u03b43 to get utility u2 = \u2212(q\u2032 + \u03b43)c with\nu2 \u2212 ue = v(1\u2212 q\u2032)\u2212 \u03b1c\u03b43 \u03b1 > v(1\u2212 q\u2032) n \u2265 v(c\u2212 v) cn ,\nwhere the first inequality follows because \u03b43 can be made arbitrarily small.\nArmed with a complete characterization of predictions of strategic behavior among the defenders, we can now consider how this behavior related to socially optimal protection decisions. Since the solutions are unique, there is no distinction between the notions of price of anarchy and price of stability ; we term the ratio of socially optimal welfare to welfare in equilibrium as the price of anarchy for convenience.\nFirst, we characterize the socially optimal outcome.\nTheorem 3. In the Baseline model, the optimal social welfare SWO is\nSWO = { \u2212cn, if v \u2265 cn; \u2212v, if v < cn.\nProof sketch. We firstly claim that we could get optimal social welfare only if all defenders use the same coverage probability q. If their coverage probabilities are different, and some defender j has probability 0 of being attacked, we could decrease qj to improve social welfare. Therefore we need only to consider identical coverage probabilities q in determining optimal social welfare. Welfare, as a function of symmetric coverage q is\nSW (q) = \u2212v + q(v \u2212 c) + (n\u2212 1)(\u2212c) = (v \u2212 cn)q \u2212 v.\nWhen v \u2265 cn, q = 1 is optimal, whereas q = 0 is optimal otherwise, giving the desired result.\nFrom this result, it is already clear that defenders systematically over-invest in security, except when values of the targets are quite high. This stems from the fact that the attacker creates a negative externality of protection: if a defender protects his target with higher probability than others, the attacker will have an incentive to attack another defender.\nIn such a case, we can expect a \u201cdynamic\u201d adjustment process with defenders increasing their security investment well beyond what is socially optimal. To see just how much the defenders lose in the process, we now characterize the price of anarchy of our game.\nIf v \u2265 c, social welfare in the unique equilibrium with q = 1 is\nSWE = \u2212cn.\nThe associated PoA is then\nPoA = { 1, if v \u2265 cn; nc v , if c < v < cn.\nFigure 2 shows the relationship among PoA, the number of defenders, and the ratio cv . From the figure we can see that when number of defenders and cv are small (e.g. n \u2264 5 and c v = 0.2), the price of anarchy is close to 1. Otherwise, PoA is unbounded, growing linearly with n.\nWhen v < c, there is no Nash equilibrium. However, the optimal -equilibrium features all defenders with the same coverage probability vc for their targets. The corresponding Social Welfare is\nSWE = (v \u2212 cn) v\nc \u2212 v,\nand the associated v(c\u2212v)cn -PoA is cn+c\u2212v c , which is, again, linear in n."}, {"heading": "4.2 The Multi-Target Model", "text": "Armed with observations from the model with a single target for each defender, we now extend the model to a case not as yet considered in the literature in a theoretical light: each defender protects a set of k targets. This gives rise to a combinatorial set of possible\ndecisions for each defender, so that even computing a best response is not necessarily easy. Remarkably, we are able to characterize equilibria and approximate equilibria in this setting as well. The proofs for this subsection are in the appendix.\nOur first result is almost a mirror-image of the corresponding result in the baseline model: when a Nash equilibrium exists, all defenders protect all of their targets with probability 1.\nTheorem 4. In the Multi-Target model, Nash equilibrium exists if and only if v \u2265 kc. In this equilibrium all targets are protected with probability 1.\nNext, we consider scenarios when v < kc, in which there is no Nash equilibrium. Our next result characterizes optimal (lowest- ) approximate Nash equilibria.\nTheorem 5. In the Multi-Target model, if v < kc, then in the optimal -equilibrium all targets are protected with probability vkc . The corresponding is v(kc\u2212v) cnk .\nThus, as n increases, the optimal approximate equilibrium approaches a Nash equilibrium. Figure 3 illustrates the relationship between and the number of targets each defender protects when v = 10 and c = 1. In this figure, = 0 when k \u2264 10, which means that an exact Nash equilibrium exists; increases with k when k > 10, but at a decreasing rate, converging to vn as k \u2192\u221e.\nFinally, we characterize socially optimal welfare, and, subsequently, put everything together in describing the price of anarchy.\nTheorem 6. In the Multi-Target model, the optimal social welfare SWO is\nSWO = { \u2212cnk, if v \u2265 cnk; \u2212v, if v < cnk.\nThus, just as in the baseline case, the defenders will generally over-invest in security.\nIf v \u2265 kc, there is a unique Nash equilibrium with all targets protected with probability 1. The corresponding social welfare is\nSWE = \u2212cnk\nBecause it is the only Nash equilibrium, the Price of Anarchy is\nPoA = { 1, if v \u2265 cnk; nkc v , if ck \u2264 v < cnk.\nIf v < kc, there is no Nash equilibrium. The optimal approximate equilibrium features identical coverage probability of vkc for all targets. The corresponding Social Welfare is\nSWE = (v \u2212 cnk) v\nkc \u2212 v,\nand the associated v(kc\u2212v)cnk -Price of Anarchy is n+ 1\u2212 v kc . Clearly, in either case, and just as in the baseline model, the price of anarchy is unbounded, growing linearly with n.\nWe now consider how PoA changes as a function of k, i.e. the number of targets each defender has. When k \u2264 vcn , a Nash equilibrium exists and the PoA is 1; when v cn < k \u2264 v c , PoA increases linearly in k with slope ncv . However, when k > v c , a Nash equilibrium does not exist and the approximate PoA is n+ 1\u2212 vkc , which increases very slowly with k, and is bounded by n+1 when k \u2192\u221e. Figure 4 illustrates the relationship between (approximate) Price of Anarchy and k for n = 2. When k is very small, PoA = 1. For intermediate k, PoA increases linearly, and when k is sufficiently large, Nash equilibrium no longer exists, and -PoA increases quite slowly, converging to 3 when k \u2192\u221e."}, {"heading": "4.3 The General Model", "text": "Both the baseline and the multi-target models made rather strong assumptions about the structure of the utility functions of the players. In the general model, we relax these assumptions, allowing for arbitrary utilities for the players when the target is attacked or not, and when it is protected or not (when attacked). Quite surprisingly, our findings here are qualitatively different : the special case of the baseline and multi-target models turns out to be an exception, rather than the rule when more general models are considered.\nJust as before, we start by characterizing Nash and approximate Nash equilibria.\nTheorem 7. In the General model, Nash equilibrium exists if and only if U c \u2212 Uu \u2265 kc\u2212 (n\u22121)(\u2126\u2212U\nc) n . In this equilibrium all targets are protected with probability 1.\nProof. We firstly claim that Nash equilibrium can appear only if coverage probabilities of all of targets tij are identical. Otherwise, there will be a target tik which has the probability 0 of being attacked, and the defender i has an incentive to decrease qik. To determine a Nash equilibrium, we therefore need only consider scenarios in which all targets have the same coverage probability.\nWhen all targets have the same coverage probability q to be protected, the utility of each defender is\nu = (U c \u2212 Uu \u2212 nkc)q + Uu + (nk \u2212 1)\u2126\nn .\nIf q < 1, then some defender i could increase q to q+ \u03b4 for all of her targets to ensure none of them are attacked, and obtain utility of u\u2032 = k\u2126\u2212 k(q + \u03b4)c, so that\nu\u2032 \u2212 u = (U c \u2212 Uu)(1\u2212 q) + (\u2126\u2212 U c)\u2212 nkc\u03b4\nn .\nAs U c \u2265 Uu, \u2126 \u2265 U c, and \u03b4 can be arbitrarily small, u\u2032 \u2212 u > 0 when q < 1, which means that this cannot be a Nash equilibrium. Thus, the only possible equilibrium can be qij = 1 for all targets tij .\nWhen all targets have the same coverage probability q = 1, each defender\u2019s utility is\nu = U c \u2212 nkc+ (nk \u2212 1)\u2126\nn .\nWe claim that if a defender i has an incentive to deviate, it is optimal for this defender to use the same coverage probability for all her targets. Otherwise, for some target tik which has probability 0 of being attacked, she could decrease q\u2032ik to obtain higher utility. If probabilities of targets protected by defender i are all q\u2032 (0 \u2264 q\u2032 < 1), then her expected utility is u\u2032 = (U c \u2212 Uu \u2212 c)q\u2032 + Uu + (k \u2212 1)(\u2126\u2212 q\u2032c), and\nu\u2032 \u2212 u = (U c \u2212 Uu \u2212 kc)(q\u2032 \u2212 1) + (n\u2212 1)(U c \u2212 \u2126)\nn .\nWe therefore have two cases:\n1) If U c \u2212 Uu \u2265 kc, then u\u2032 \u2212 u \u2264 0, and q = 1 for all targets is a Nash equilibrium.\n2) If U c \u2212 Uu < kc, the maximal value of u\u2032 \u2212 u corresponds to q\u2032 = 0:\nmax 0\u2264q\u2032<1\nu\u2032 \u2212 u = \u2212(U c \u2212 Uu \u2212 kc)\u2212 (n\u2212 1)(\u2126\u2212 U c)\nn .\nIf kc\u2212 (n\u22121)(\u2126\u2212U c) n \u2264 U c\u2212Uu < kc, u\u2032\u2212 u \u2264 0, it is a Nash equilibrium; otherwise, it is not.\nTo sum up, a Nash equilibrium exists if and only if U c \u2212 Uu \u2265 kc \u2212 (n\u22121)(\u2126\u2212U c)\nn , and the equilibrium corresponds to all targets having probability 1 of being protected.\nNext, we characterize the optimal approximate equilibrium when no Nash equilibrium exists.\nTheorem 8. In the General model, in the optimal -equilibrium all targets are protected with probability \u2126\u2212U u\nkc . The corresponding is (\u2126\u2212Uu)(kc\u2212Uc+Uu) cnk .\nProof. When all targets have the same coverage probability q, the expected utility of each defender is\nu = (U c \u2212 Uu \u2212 nkc)q + Uu + (nk \u2212 1)\u2126\nn .\nSuppose 0 \u2264 q < 1. If some defender i increases q to q + \u03b4ij for target tij , then she would obtain utility u\u2032 = \u2211k j=1 \u2126\u2212 (q + \u03b4ij)c, and\nu\u2032 \u2212 u = \u2126\u2212 (U c \u2212 Uu)q \u2212 Uu\nn \u2212 k\u2211 j=1 \u03b4ijc\n\u2264 \u2126\u2212 (U c \u2212 Uu)q \u2212 Uu\nn .\n(1)\nNow we consider scenarios in which a defender i could obtain higher utility by decreasing protection probability. We claim that if a defender i has an incentive to deviate, it is optimal for this defender to use the same coverage probability for all her targets. Otherwise, for some target tik which has probability 0 of being attacked, she could decrease q \u2032 ik to obtain higher utility. Thus, we need only consider cases in which a defender deviates by decreasing coverage probabilities for all her targets to q \u2212 \u03b4. Her utility will become u\u2032\u2032 = (U c\u2212Uu\u2212 kc)(q\u2212 \u03b4) +Uu + (k\u2212 1)\u2126. Since U c\u2212Uu < kc, \u03b4 = q (the maximal value of \u03b4) maximizes u\u2032\u2032 \u2212 u:\nmax 0<\u03b4\u2264q\nu\u2032\u2032 \u2212 u = \u2126\u2212 (U c \u2212 Uu)q \u2212 Uu\nnk + kcq + Uu \u2212 \u2126. (2)\nBy comparing the value of equation (1) and equation (2), we get different values of for -equilibrium:\n=\n{ \u2126\u2212(Uc\u2212Uu)q\u2212Uu\nn , if 0 \u2264 q \u2264 \u2126\u2212Uu kc ;\n\u2126\u2212(Uc\u2212Uu)q\u2212Uu n + kcq + U u \u2212 \u2126, if \u2126\u2212Uukc < q \u2264 1.\nWhen q = \u2126\u2212U u kc , we get the minimal = (\u2126\u2212Uu)(kc\u2212Uc+Uu) cnk .\nWe claim that the (\u2126\u2212U u)(kc\u2212Uc+Uu)\ncnk -equilibrium can appear only if all targets have the same coverage probability q. We prove this by contradiction. Suppose that targets have different coverage probabilities. This gives rise to two cases: 1) Each defender uses an identical coverage probability for each target she owns (these may differ between defenders); and 2) Some defender has different coverage probabilities for her targets. In case 1), there exist \u03b2 defenders (1 \u2264 \u03b2 < n) who have the same minimal coverage probability q\u2032. The expected utility for each defender among these \u03b2 is\nu = (U c \u2212 Uu \u2212 k\u03b2c)q\u2032 + Uu + (k\u03b2 \u2212 1)\u2126\n\u03b2 .\nWhen \u2126\u2212U u kc < q \u2032 \u2264 1, some defender i among these \u03b2 could decrease the coverage probability of all her targets to 0 and obtain the utility of u1 = U u + (k \u2212 1)\u2126, so that\nu1 \u2212 u = \u2126\u2212 (U c \u2212 Uu)q\u2032 \u2212 Uu\n\u03b2 + kcq\u2032 + Uu \u2212 \u2126\n> \u2126\u2212 (U c \u2212 Uu)q\u2032 \u2212 Uu\nn + kcq\u2032 + Uu \u2212 \u2126.\nWhen 0 \u2264 q\u2032 \u2264 \u2126\u2212Uukc , some defender i among these \u03b2 can increase coverage probabilities of all her targets to q\u2032 + \u03b43 to obtain utility of u2 = k\u2126\u2212 k(q\u2032 + \u03b43)c, with\nu2 \u2212 u = \u2126\u2212 (U c \u2212 Uu)q\u2032 \u2212 Uu \u2212 k\u03b2c\u03b43\n\u03b2\n> \u2126\u2212 (U c \u2212 Uu)q\u2032 \u2212 Uu\nn ,\nwhere the inequality holds because \u03b43 can be arbitrarily small. Thus, no profile in case 1) can be a (\u2126\u2212U u)(kc\u2212Uc+Uu)\ncnk -equilibrium. In case 2), any defender who has different coverage probabilities among her targets can always increase her payoff by decreasing the coverage probabilities of the targets with higher coverage to yield identical coverage for all targets. Consequently, no profile in case 2) can be a (\u2126\u2212U\nu)(kc\u2212Uc+Uu) cnk -equilibrium.\nAs the final step towards characterizing the Price of Anarchy, we derive optimal social welfare in this model.\nTheorem 9. In the General model, the optimal social welfare SWO is\nSWO = { U c \u2212 nkc+ (nk \u2212 1)\u2126, if U c \u2212 Uu \u2265 nkc; Uu + (n\u2212 1)\u2126, if U c \u2212 Uu < nkc.\nProof sketch. We firstly claim that we could get optimal social welfare only if all targets have the same coverage probability q. Otherwise, some target tij has probability 0 of being attacked, and we can decrease qij to improve social welfare. Consequently, we need only to consider an optimal symmetric coverage probability q to maximize social welfare, which can be done in a manner similar to that for the baseline case.\nIf U c\u2212Uu \u2265 kc\u2212 (n\u22121)(\u2126\u2212U c)\nn , the Nash equilibrium is unique, with all targets protected with probability 1. The corresponding social welfare is\nSWE = U c \u2212 nkc+ (nk \u2212 1)\u2126.\nSo far we have not yet added any constrains to value of \u2126, U c, and Uu (except that \u2126 \u2265 U c \u2265 Uu). In order to make Price of Anarchy well-defined, we need to add constraints that values of \u2126, U c, and Uu are all non-positive (just as in the previous two models) or all non-negative. To be consistent with previous models, we add constraints that U c, Uu and \u2126 are all non-positive (little changes if all are non-negative).\nIn the case of a unique Nash equilibrium, the price of anarchy is\nPoA =  1, if U c \u2212 Uu \u2265 nkc; Uc\u2212Uu\u2212nkc Uu+(nk\u22121)\u2126 + 1, if kc\u2212 (n\u22121)(\u2126\u2212Uc) n \u2264\nU c \u2212 Uu < nkc.\nIf U c \u2212 Uu < kc\u2212 (n\u22121)(\u2126\u2212U c)\nn , there is no Nash equilibrium. The Social Welfare in the optimal approximate equilibrium is\nSWE = (U c \u2212 Uu \u2212 nkc)\u2126\u2212 U u\nkc + Uu + (nk \u2212 1)\u2126,\nand the (\u2126\u2212U u)(kc\u2212Uc+Uu) cnk -Price of Anarchy is (Uc\u2212Uu\u2212nkc)(\u2126\u2212Uu) kcUu+(nk\u22121)kc\u2126 + 1.\nWe now analyze the relationship between ( -)PoA and the values of n and k. Here are the key differences from the Multi-Target Model. First we consider ( -)PoA as the function of n. If \u2126 = 0, the result is same as that in the Multi-Target Model: ( -)PoA linearly increases in n, and is therefore unbounded. However, if \u2126 6= 0, while PoA and -PoA are\nincreasing in n, as n\u2192\u221e, they approach 1\u2212 c\u2126 and 1+ Uu\u2212\u2126 k\u2126 , respectively. In other words, PoA (exact and approximate) is bounded by a constant, for a constant k!\nConsider now approximate price of anarchy as a function of k. If \u2126 = 0, it is bounded by n+1. However, if \u2126 6= 0, when kc\u2212 (n\u22121)(\u2126\u2212U\nc) n \u2264 U\nc\u2212Uu, it is an increasing function of k. When kc\u2212 (n\u22121)(\u2126\u2212U\nc) n > U\nc\u2212Uu, it may at first increase or decrease in k, depending on the the values of the model parameters. However, when k is large enough, price of anarchy will invariably be decreasing in k, and as k \u2192\u221e, -PoA \u2192 1. Figure 5 provides an example of the relationship between -PoA and k. Observe that all the curves begin to decrease when k > 10, and they all approach 1 as k \u2192\u221e. Thus, price of anarchy in the general model is only unbounded in the special case when \u2126 = 0, whereas when \u2126 6= 0, price of anarchy is always bounded by a constant. This observation is particularly surprising and significant considering the fact that the baseline and simplified multi-target models are quite natural, and seemingly innocuous, restrictions of the general case."}, {"heading": "5. Analysis of Interdependent Multi-defender Security Games", "text": "We now develop and analyze a computational framework for approximating Nash equilibria in interdependent multi-defender security games. A crucial step in computing (or approximating) a Nash equilibrium of a game is to consider the problem of computing a best response for an arbitrary player (in our case, defender, since the attacker\u2019s best response is straightforward). Next, we develop a novel mixed-integer linear programming formulation for computing ASE best response, and then propose a hightly effective heuristic method for approximating ASE in multi-defender games."}, {"heading": "5.1 Computing Defender Best Response: A Mixed-Integer Linear Programming Formulation", "text": "While ASE seems a very natural alternative to SSE even in two-player security games, we are not aware of any proposals for computing it. Below, in equations 3-13, we present the first (to our knowledge) mixed-integer linear programming formulation for computing ASE which, in our case, would compute a best response for an arbitrary defender i when the strategies of all other players, q\u2212i, are fixed.\nmax a,qi,s,u,v u\u2212 \u2211 j\u2208Ti \u2211 o\u2208O cojq o i,j (3)\ns.t.\n0 \u2264 qoi,j \u2264 1 \u2200 j \u2208 Ti, \u2200o (4)\u2211 o\u2208O qoi,j = 1 \u2200j \u2208 Ti (5) aj \u2208 {0, 1} \u2200 j \u2208 T (6)\u2211 j\u2208T aj \u2265 1 (7)\n0 \u2264 v \u2212 \u2211 o qoi,jV o j \u2264 (1\u2212 aj)M \u2200 j \u2208 Ti (8)\n0 \u2264 v \u2212 \u2211 o qo\u2212i,jV o j \u2264 (1\u2212 aj)M \u2200 j \u2208 T\u2212i (9)\nsj = v \u2212 \u2211 o qoi,jV o j \u2200 j \u2208 Ti (10)\nsj = v \u2212 \u2211 o qo\u2212i,jV o j \u2200 j \u2208 T\u2212i (11) aj +Msj \u2265 1 \u2200 j \u2208 T (12) u = f(q, a), (13)\nwhere M is a very large number and\nf(q, a) =\n\u2211 j\u2208Ti aj \u2211 o\u2208O q o i,jU o j + \u2211 j\u2208T\u2212i aj \u2211 o\u2208O q o \u2212i,jU\no j\u2211\nj\u2208T aj .\nWhile constraint 13 is non-linear, we can linearize it using McCormick inequalities. Constraints 4 and 5 ensure that the defender\u2019s strategy is a valid probability distribution. Constraint 7 ensures that at least one target is chosen by the attacker. Constraints 8 and 9 compute the optimal attacker utility v; alone, they ensure that this utility corresponds to some attack target. Constraints 10 and 11 compute an auxiliary variable sj , which is 0 if and only if attacking a target j yields an optimal utility to the attacker. These variables, together with constraints 12 and 8-9 ensure that the binary variable aj = 1 if and only if the attacker (weakly) prefers to attack target j; that is, these jointly compute the set of optimal attack targets. Finally, constraint 13 computes the expected utility to the defender if the attacker chooses one of his most preferred targets uniformly at random.\nIf M is infinite and numbers can be computed to arbitrary precision, the above formulation is correct. In practice, of course, numerical precision and stability are an issue, and they arise with this formulation. Consider constraints 10 and 11, which compute sj for all targets j. These require that the expected value of the target exactly equal the optimal attacker utility computed in constraints 8-9; even a slight error will technically violate our requirement that sj = 0 at an optimal target. Moreover, even if the difference is, indeed, non-zero, from an attacker\u2019s perspective it seems intuitive that sufficiently small differences from optimal utility are ignored. We address these problems by adding a fixed small quantity \u03b4 to the right-hand-side of constraints 8, 9, while subtracting it from the right-hand-side of constraint 12. Because the constraints are interrelated, we cannot simply choose an arbitrary 0 < \u03b4 < 1, but must ensure that \u03b4 and M satisfy the constraint that M\u03b4 < 1\u2212 \u03b4."}, {"heading": "5.2 Approximating ASE", "text": "Previously, Vorobeychik and Wellman (2008) presented a convergent equilibrium approximation algorithm based on simulated annealing (SA) that would be applicable in our setting. They additionally showed in simulation that SA is actually outperformed by a simple heuristic based on iterated best response (IBR) dynamics. Here, we interpret IBR as a local search heuristic, with the property that if the starting point is a Nash equilibrium, IBR will never deviate from it (i.e., Nash equilibrium is a fixed point). Clearly, then, the choice of a starting point can be significant for the performance of IBR, making it natural to consider coupling\nit with random restarts. Our main contribution in this section is to present evidence that IBR with random restarts is a highly effective equilibrium approximation approach in our setting (and outperforms several alternatives). This is both of broad significance, and of particular importance in our setting, as we use this algorithm for our analyses below.\nWe compare the following Nash equilibrium approximation algorithms executed for 1000 iterations: random search (RS), which simply generates 1000 strategy profiles randomly, computes the game theoretic regret of each, and chooses a profile with the smallest regret; simulated annealing (SA), with the temperature exponentially increasing with iterations; and iterated best response (IBR) with no restarts. We also include in the comparison two additional variations of IBR: the first uses SA for the first 100 iterations, and then switches to IBR for the remainder (starting with the best approximation produced by SA); the second is IBR with random restarts, which we term RIBR. RIBR includes initial corner cases that may be hard to converge to in a limited amount of time (i.e., all defenders not defending, all defenders defending completely). We execute our comparison on games with 2 players and 10 targets and games with 5 players and 20 targets. In all cases, targets are divided evenly among the players, and values over the targets are generated uniformly at random. The cost of defense is fixed at c = 0.2, and the targets are assumed to be independent (but players may have values for targets under the control of other defenders). Figure 6 demonstrate that in both settings, RIBR outperforms other alternatives."}, {"heading": "5.3 Analysis of Multi-Defender Games on Synthetic Networks", "text": "For our first set of experiments, we use RIBR on 3 artificially generated networks, with 40 samples for each parameter variation. First, we will illustrate and compare the results of our interdependent multi-defender game on artificial networks. We use 3 commonly analyzed network structures: a grid, Erdo\u030bs-Re\u0301nyi networks, and preferential attachment networks. In all of the generated networks, there are 64 nodes or targets. For the latter two, we use the Metis graph partitioning software to partition the nodes (targets) among defenders. This\nsoftware partitions nodes to minimize connectivity among the targets belonging to different defenders, a property that we expect to common hold in real networks due to efficiency considerations.\nWe begin by considering average strategies, as well as social welfare, for the three different synthetic networks (grid, Erdo\u030bs-Re\u0301nyi, and preferential attachment), as a function of the number of players (degree of decentralization) and the cascade probability (interdependent risk). The results are shown in Figure 7. We do not show these as a function of defense cost as increasing defense cost roughly mirrors decreasing cascade probability p. The first rather stark observation is that network structure makes little difference when each node is controlled by a single player, but it makes a significant qualitative difference both for social welfare and actual strategies utilized by the players in all other cases.\nLooking at the results in greater detail, let\u2019s consider first social welfare (Figure 7, top). First, when interdependent risk is low (0.1 \u2264 p \u2264 0.3), social welfare follows a relatively simple pattern: increasing decentralization makes initially almost no difference, until sufficiently\nmany players are involved, at which point social welfare falls rather dramatically; this pattern is roughly monotonic with increasing decentralization, with worst outcomes emerging when each player controls a single node, and mirrors previous findings (Vorobeychik et al., 2011). Both Erdo\u030bs-Re\u0301nyi and preferential attachment networks are less susceptible to the negative effects of decentralization in this case than the grid network, where the dropoff occurs with fewer players (less decentralization). This may be largely a consequence of the fact that network partitioning tools we use attempt to minimize interdependence among players\u2014something that is likely to mirror reality\u2014and far more opportunities for doing so exist in Erdo\u030bs-Re\u0301nyi and preferential attachment models.\nWhen p is higher (greater interdependencies), the results exhibit an entirely new phenomenology. Across all three network models, for a sufficiently large p, the impact of decentralization is non-monotonic: an intermediate level of decentralization has the most detrimental impact on security, while a highly decentralized system becomes near-optimal!\nInvestigating actual (average) strategic decisions by the players yields deeper insights into the findings above. When interdependencies are weak, optimal decision is to invest relatively little in security, in any generative model. Increasing decentralization, therefore, gives rise primarily to over-investment, mirroring our analytical results for the limiting case when targets were independent, although the tendency to over-invest is quite weak until the network is extremely decentralized, except in the grid network. When p is high, on the other hand, the predominant phenomenon is underinvestment. This in itself is not surprising: after all, a high level of interdependencies should imply that positive externalities of security should be dominant. What is surprising is, again, non-monotonicity in the level of decentralization: when decentralization is moderate, underinvestment can be quite dramatic. On the other hand, a high level of decentralization often appears to dull this effect, and the level of investment in security becomes much closer to optimal."}, {"heading": "5.4 Results on power grid networks", "text": "The grid network studied above is arguably the most \u201cartificial\u201d, in the sense that both Erdo\u030bs-Re\u0301nyi and preferential attachment models were developed in part to resemble real networks (this is particularly true of the latter, which aims to replicate the scale-free properties of observed networks). Surprisingly, however, the approximate equilibrium results applied to three snippets of actual power networks most resemble the phenomena observed for the grid, as can be seen in Figure 8. In particular, just as in the grid above, overinvestment in security appears to dominate, even at relatively high levels of interdependence, but only when decentralization is significant, while most levels of decentralization are relatively robustly near-optimal (these are, in fact, more robust to decentralization than the grid network above).\nTo dig somewhat deeper into the rather complex phenomenology we have observed, Figure 9 shows several examples of actual strategy realizations. First, consider the top series of plots for the grid with cascade probability p = 0.1. As previously described, we can clearly see that the optimal security configuration involves no security investment (leftmost grid), whereas an increasing level of decentralization gives rise to increased security investment, culminating, ultimately, with full protection in the extreme level of decentralization. The contrast between the two extremes offers some guidance: even though optimal global configuration involves no security, when each player controls (and cares about) only a single node, the best response of an attacked node is to defend it just enough to force the attacker to attack another; for example, slightly more than the next weakest node. Iterating on this idea, strategies \u201ccascade\u201d to full defense. When the player controls more than one node, however, there is suddenly strategic tension: higher security on one node may well push the attacker to attack another node under this player\u2019s control. Positive externalities become more significant as well: pushing the attacker to attack another node \u201cnearby\u201d is likely to gain little when cascade probabilities are high and multiple nodes owned by the defender could be affected. For sufficiently high cascade probabilities, and sufficiently low\nnumber of players, such positive network effects can actually sway players to under-invest in security, as we can see both in the middle and last rows of Figure 9 (the 4-player case). Here, strategic complementarities make security investment not worthwhile in equilibrium: the nodes that need to be defended are relatively central, and cut across different players (i.e., the critical central nodes create a kind of \u201cbuffer\u201d between defenders). This behavior diminishes as decentralization increases."}, {"heading": "5.5 Security and Network Centrality", "text": "Finally, we consider the relationship between network centrality and strategic choice of a node. The results, shown in Figure 10, plot each node\u2019s closeness centrality and corresponding security across 10 instances for each network. When the interdependence of networks is low, security investment appears to correlate rather strongly with closeness in synthetic networks: in other words, nodes more central in the network invest more in security. A similar relationship is seen with node degrees. This correlation, however, largely disappears with greater interdependence, likely because the difference between being one-hop vs. twohops away from an attacked node (i.e., being a low-connected neighbor of a high-connected node) becomes considerably less in such a case.\nFor the power networks, the correlation between centrality and strategy remains even with higher cascade probabilities. This relationship can be seen by comparing the strategy profile in the second column of Figure 9 and the closeness plot for p = 0.7 for the power network. The structure of the power network has several small \u201dchains\u201d that have low centrality. The node that connects the chain to the rest of the network (higher centrality) incurs most of the defense cost, since a failure cascade would have to pass through this node to reach the rest of the chain. As the amount of interdependence increases (column 3 in Figure 9), these chains become partitioned between defenders, weakening the relationship between centrality and strategy."}, {"heading": "6. Conclusion", "text": "In this work, we have extended the current state of Stackelberg security games to include multiple defenders in non-cooperative scenarios with independent and interdependent targets.\nFor the independent case, we provided complete characterizations of Nash and approximate equilibria, socially optimal solutions, and price of anarchy (PoA) for three models of varying generality. Our analysis showed that defenders generally over protect the targets, but different modelling assumptions give rise to qualitatively different outcomes: a simpler model gives rise to an unbounded PoA, whereas a more general model sees PoA converge to a constant when the number of defenders increases.\nFor the interdependent case, we developed a novel computation framework to overcome the difficulties of providing a concise formal analysis of such a complex model. Our simulations characterize a broad space of strategic predicaments, varying cascade probability, network structure, and system decentralization. In contrast to the independent models, our results show differing behavior in terms of security investment dependent on the strength and structure of interdependencies. One of our most stark findings is the non-monotonicity of welfare and strategic choices as a function of the number of players: in a number of\ncases, higher levels of decentralization become near-optimal, even while intermediate decentralization leads to very poor outcomes. As security decisions are almost universally decentralized, and often highly interdependent, our findings enable a deeper understanding of practical security considerations, highlighting the importance of both, over- and underinvestment in security, and the dependence of each on network structure, the magnitude of network externalities, and the level of decentralization. Finally, we have shown how security behavior in our model on real-world power networks relates to those in synthetic networks, highlighting similar behaviors with grid networks, and unveiling structural differences with Erdo\u030bs-Re\u0301nyi and preferential attachment networks using the relationship between strategy and centrality."}], "references": [{"title": "Network security and contagion", "author": ["D. Acemoglu", "A. Malekian", "A. Ozdaglar"], "venue": "Working paper", "citeRegEx": "Acemoglu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Acemoglu et al\\.", "year": 2013}, {"title": "Solving defenderattacker-defender models for infrastructure defense", "author": ["D.L. Alderson", "G.G. Brown", "W.M. Carlyle", "R.K. Wood"], "venue": "INFORMS Computing Society Conference", "citeRegEx": "Alderson et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Alderson et al\\.", "year": 2011}, {"title": "Contagion and observability in security domains", "author": ["Y. Bachrach", "M. Draief", "S. Goyal"], "venue": "In Allerton Conference", "citeRegEx": "Bachrach et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bachrach et al\\.", "year": 2013}, {"title": "Interdependent defense games: Modeling interdependent security under deliberate attack", "author": ["H. Chan", "M. Ceyko", "L.E. Ortiz"], "venue": "In Twenty-Eighth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Chan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chan et al\\.", "year": 2012}, {"title": "Computing the optimal strategy to commit to", "author": ["V. Conitzer", "T. Sandholm"], "venue": "In Proceedings of the 7th ACM conference on Electronic commerce, EC", "citeRegEx": "Conitzer and Sandholm,? \\Q2006\\E", "shortCiteRegEx": "Conitzer and Sandholm", "year": 2006}, {"title": "Stochastic network interdiction", "author": ["K.J. Cormican", "D.P. Morton", "R.K. Wood"], "venue": "Operations Research,", "citeRegEx": "Cormican et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Cormican et al\\.", "year": 1998}, {"title": "A stochastic multiple-leader stackelberg model: analysis, computation, and applications", "author": ["V. DeMiguel", "H. Xu"], "venue": "Operations Research,", "citeRegEx": "DeMiguel and Xu,? \\Q2009\\E", "shortCiteRegEx": "DeMiguel and Xu", "year": 2009}, {"title": "Security games with arbitrary schedules: A branch and price approach", "author": ["M. Jain", "E. Kardes", "C. Kiekintveld", "M. Tambe", "F. Ordonez"], "venue": "In Twenty-Fourth National Conference on Artificial Intelligence", "citeRegEx": "Jain et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jain et al\\.", "year": 2010}, {"title": "Bayesian stackelberg games and their application for security at los angeles international airport", "author": ["M. Jain", "J. Pita", "M. Tambe", "F. Ordonez", "P. Paruchuri", "S. Kraus"], "venue": "SIGecom Exch.,", "citeRegEx": "Jain et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Jain et al\\.", "year": 2008}, {"title": "Software assistants for randomized patrol planning for the lax airport police and the federal air", "author": ["M. Jain", "J. Tsai", "J. Pita", "C. Kiekintveld", "S. Rathi", "M. Tambe", "F. Ordonez"], "venue": "marshal service. Interfaces,", "citeRegEx": "Jain et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jain et al\\.", "year": 2010}, {"title": "Defender (mis)coordination in security games", "author": ["A.X. Jiang", "A.D. Procaccia", "Y. Qian", "N. Shah", "M. Tambe"], "venue": "In Twenty-Third International Joint Conference on Artificial Intelligence,", "citeRegEx": "Jiang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Jiang et al\\.", "year": 2013}, {"title": "Maximizing the spread of influence in a social network", "author": ["D. Kempe", "J.M. Kleinberg", "\u00c9va Tardos"], "venue": "In Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Kempe et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kempe et al\\.", "year": 2003}, {"title": "Computing optimal randomized resource allocations for massive security games", "author": ["C. Kiekintveld", "M. Jain", "J. Tsai", "J. Pita", "F. Ordonez", "M. Tambe"], "venue": "In Proceedings of the Eighth International Conference on Autonomous Agents and Multiagent Systems", "citeRegEx": "Kiekintveld et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kiekintveld et al\\.", "year": 2009}, {"title": "Stackelberg vs. nash in security games: An extended investigation of interchangeability, equivalence, and uniqueness", "author": ["D. Korzhyk", "Z. Yin", "C. Kiekintveld", "V. Conitzer", "M. Tambe"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Korzhyk et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Korzhyk et al\\.", "year": 2011}, {"title": "A shared-constraint approach to multi-leader multi-follower games. Set-Valued and Variational Analysis", "author": ["A.A. Kulkarni", "U.V. Shanbhag"], "venue": null, "citeRegEx": "Kulkarni and Shanbhag,? \\Q2014\\E", "shortCiteRegEx": "Kulkarni and Shanbhag", "year": 2014}, {"title": "Electricity regulation in the US: A guide", "author": ["J. Lazar"], "venue": "Tech. rep., Regulatory Assistance Project", "citeRegEx": "Lazar,? \\Q2011\\E", "shortCiteRegEx": "Lazar", "year": 2011}, {"title": "Computing optimal security strategies for interdependent assets", "author": ["J. Letchford", "Y. Vorobeychik"], "venue": "In Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Letchford and Vorobeychik,? \\Q2012\\E", "shortCiteRegEx": "Letchford and Vorobeychik", "year": 2012}, {"title": "A Course in Game Theory", "author": ["M. Osborne", "A. Rubenstein"], "venue": null, "citeRegEx": "Osborne and Rubenstein,? \\Q1994\\E", "shortCiteRegEx": "Osborne and Rubenstein", "year": 1994}, {"title": "Playing games with security: an efficient exact algorithm for bayesian stackelberg games", "author": ["P. Paruchuri", "J.P. Pearce", "J. Marecki", "M. Tambe", "F. Ordonez", "S. Kraus"], "venue": "In Proceedings of the Seventh International Conference on Autonomous Agents and Multiagent Systems,", "citeRegEx": "Paruchuri et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Paruchuri et al\\.", "year": 2008}, {"title": "Using game theory for los angeles airport security", "author": ["J. Pita", "M. Jain", "F. Ordonez", "C. Portway", "M. Tambe", "C. Western", "P. Paruchuri", "S. Kraus"], "venue": "AI Magazine,", "citeRegEx": "Pita et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Pita et al\\.", "year": 2009}, {"title": "Computation of a nash equilibrium of multiple-leader stackelberg network games", "author": ["V. Rodoplu", "G.S. Raj"], "venue": "In International Conference on Systems and Networks Communications,", "citeRegEx": "Rodoplu and Raj,? \\Q2010\\E", "shortCiteRegEx": "Rodoplu and Raj", "year": 2010}, {"title": "A multiple leader stackelberg model and analysis", "author": ["H.D. Sherali"], "venue": "Operations Research,", "citeRegEx": "Sherali,? \\Q1984\\E", "shortCiteRegEx": "Sherali", "year": 1984}, {"title": "Unleashing dec-mdps in security games: Enabling effective defender teamwork", "author": ["E. Shieh", "A.X. Jiang", "A. Yadav", "P. Varakantham", "M. Tambe"], "venue": "In European Conference on Artificial Intelligence", "citeRegEx": "Shieh et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Shieh et al\\.", "year": 2014}, {"title": "Unleasing decmdps in security games: Enabling effective defender teamwork", "author": ["E. Shieh", "A.X. Jiang", "A. Yadav", "P. Varakantham", "M. Tambe"], "venue": "European Conference on Artificial Intelligence", "citeRegEx": "Shieh et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Shieh et al\\.", "year": 2014}, {"title": "Protect: A deployed game theoretic system to protect the ports of the United States", "author": ["E. Shieh", "R. Yang", "M. Tambe", "C. Baldwin", "J. DiRenzo", "B. Maule", "G. Meyer"], "venue": null, "citeRegEx": "Shieh et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Shieh et al\\.", "year": 2012}, {"title": "Finding optimal strategies in a multiperdio multi-leader-follower stackelberg game using an evolutionary algorithm", "author": ["A. Sinha", "P. Malo", "A. Frantsev", "K. Deb"], "venue": "Journal of Computers and Operations Research,", "citeRegEx": "Sinha et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sinha et al\\.", "year": 2014}, {"title": "Noncooperatively optimized tolerance: Decentralized strategic optimization in complex systems", "author": ["Y. Vorobeychik", "J. Mayo", "R. Armstrong", "J. Ruthruff"], "venue": "Physical Review Letters,", "citeRegEx": "Vorobeychik et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Vorobeychik et al\\.", "year": 2011}, {"title": "Stochastic search methods for nash equilibrium approximation in simulation-based games", "author": ["Y. Vorobeychik", "M.P. Wellman"], "venue": "In Seventh International Conference on Autonomous Agents and Multiagent Systems,", "citeRegEx": "Vorobeychik and Wellman,? \\Q2008\\E", "shortCiteRegEx": "Vorobeychik and Wellman", "year": 2008}, {"title": "Network Interdiction and Stochastic Integer Programming", "author": ["Woodruff", "D.L. (Ed"], "venue": null, "citeRegEx": "Woodruff and .Ed...,? \\Q2003\\E", "shortCiteRegEx": "Woodruff and .Ed...", "year": 2003}], "referenceMentions": [{"referenceID": 18, "context": "Among the variety of approaches that are used to tackle security problems, from risk analysis to red teaming, game theory has had a significant impact, with tools based on game theoretic analysis having been deployed in LAX airport to schedule canine patrols (Paruchuri et al., 2008; Jain et al., 2008; Pita et al., 2009), by Federal Air Marshall Service (FAMS) to schedule the air marshals (Kiekintveld et al.", "startOffset": 259, "endOffset": 321}, {"referenceID": 8, "context": "Among the variety of approaches that are used to tackle security problems, from risk analysis to red teaming, game theory has had a significant impact, with tools based on game theoretic analysis having been deployed in LAX airport to schedule canine patrols (Paruchuri et al., 2008; Jain et al., 2008; Pita et al., 2009), by Federal Air Marshall Service (FAMS) to schedule the air marshals (Kiekintveld et al.", "startOffset": 259, "endOffset": 321}, {"referenceID": 19, "context": "Among the variety of approaches that are used to tackle security problems, from risk analysis to red teaming, game theory has had a significant impact, with tools based on game theoretic analysis having been deployed in LAX airport to schedule canine patrols (Paruchuri et al., 2008; Jain et al., 2008; Pita et al., 2009), by Federal Air Marshall Service (FAMS) to schedule the air marshals (Kiekintveld et al.", "startOffset": 259, "endOffset": 321}, {"referenceID": 12, "context": ", 2009), by Federal Air Marshall Service (FAMS) to schedule the air marshals (Kiekintveld et al., 2009; Jain et al., 2010, 2010), and by the US Coast Guard to schedule boat patrols (Shieh et al.", "startOffset": 77, "endOffset": 128}, {"referenceID": 24, "context": ", 2010, 2010), and by the US Coast Guard to schedule boat patrols (Shieh et al., 2012).", "startOffset": 66, "endOffset": 86}, {"referenceID": 18, "context": "In many cases, the attacker is modeled as a rational agent who selects an optimal response and, in the many applications that compute a Strong Stackelberg equilibrium, an attacker is often assumed to break ties in the defender\u2019s favor (Paruchuri et al., 2008; Korzhyk et al., 2011).", "startOffset": 235, "endOffset": 281}, {"referenceID": 13, "context": "In many cases, the attacker is modeled as a rational agent who selects an optimal response and, in the many applications that compute a Strong Stackelberg equilibrium, an attacker is often assumed to break ties in the defender\u2019s favor (Paruchuri et al., 2008; Korzhyk et al., 2011).", "startOffset": 235, "endOffset": 281}, {"referenceID": 15, "context": "Independent System Operators (ISOs) and profit-driven independent utility operators are largely responsible for operating and controlling subsystems of the entire grid (Lazar, 2011).", "startOffset": 168, "endOffset": 181}, {"referenceID": 3, "context": ", (Kunreuther & Heal, 2003; Chan et al., 2012; Bachrach et al., 2013; Acemoglu et al., 2013)), our approach maintains the typical complexity of individual defender decision process in the multi-defender framework, with each defender responsible for securing many, possibly interdependent, targets.", "startOffset": 2, "endOffset": 92}, {"referenceID": 2, "context": ", (Kunreuther & Heal, 2003; Chan et al., 2012; Bachrach et al., 2013; Acemoglu et al., 2013)), our approach maintains the typical complexity of individual defender decision process in the multi-defender framework, with each defender responsible for securing many, possibly interdependent, targets.", "startOffset": 2, "endOffset": 92}, {"referenceID": 0, "context": ", (Kunreuther & Heal, 2003; Chan et al., 2012; Bachrach et al., 2013; Acemoglu et al., 2013)), our approach maintains the typical complexity of individual defender decision process in the multi-defender framework, with each defender responsible for securing many, possibly interdependent, targets.", "startOffset": 2, "endOffset": 92}, {"referenceID": 21, "context": "In this line of work, of greatest relevance to our effort are multiple-leader Stackelberg games (Sherali, 1984; DeMiguel & Xu, 2009; Leyffer & Munson, 2007; Rodoplu & Raj, 2010; Kulkarni & Shanbhag, 2014; Sinha et al., 2014).", "startOffset": 96, "endOffset": 224}, {"referenceID": 25, "context": "In this line of work, of greatest relevance to our effort are multiple-leader Stackelberg games (Sherali, 1984; DeMiguel & Xu, 2009; Leyffer & Munson, 2007; Rodoplu & Raj, 2010; Kulkarni & Shanbhag, 2014; Sinha et al., 2014).", "startOffset": 96, "endOffset": 224}, {"referenceID": 4, "context": "The first thorough computational treatment of randomized (mixed strategy) commitment was due to Conitzer and Sandholm (2006). In this line of work, of greatest relevance to our effort are multiple-leader Stackelberg games (Sherali, 1984; DeMiguel & Xu, 2009; Leyffer & Munson, 2007; Rodoplu & Raj, 2010; Kulkarni & Shanbhag, 2014; Sinha et al.", "startOffset": 96, "endOffset": 125}, {"referenceID": 4, "context": "The first thorough computational treatment of randomized (mixed strategy) commitment was due to Conitzer and Sandholm (2006). In this line of work, of greatest relevance to our effort are multiple-leader Stackelberg games (Sherali, 1984; DeMiguel & Xu, 2009; Leyffer & Munson, 2007; Rodoplu & Raj, 2010; Kulkarni & Shanbhag, 2014; Sinha et al., 2014). In many cases, these approaches leverage specialized problem structure, and are not immediately applicable to our setting. In particular, Sherali (1984) and DeMiguel", "startOffset": 96, "endOffset": 505}, {"referenceID": 13, "context": "Our point of departure is a class of Stackelberg games specifically pertinent to security: commonly, these are simply known as security games (Korzhyk et al., 2011; Paruchuri et al., 2008; Jain et al., 2010; Vorobeychik et al., 2011).", "startOffset": 142, "endOffset": 233}, {"referenceID": 18, "context": "Our point of departure is a class of Stackelberg games specifically pertinent to security: commonly, these are simply known as security games (Korzhyk et al., 2011; Paruchuri et al., 2008; Jain et al., 2010; Vorobeychik et al., 2011).", "startOffset": 142, "endOffset": 233}, {"referenceID": 7, "context": "Our point of departure is a class of Stackelberg games specifically pertinent to security: commonly, these are simply known as security games (Korzhyk et al., 2011; Paruchuri et al., 2008; Jain et al., 2010; Vorobeychik et al., 2011).", "startOffset": 142, "endOffset": 233}, {"referenceID": 26, "context": "Our point of departure is a class of Stackelberg games specifically pertinent to security: commonly, these are simply known as security games (Korzhyk et al., 2011; Paruchuri et al., 2008; Jain et al., 2010; Vorobeychik et al., 2011).", "startOffset": 142, "endOffset": 233}, {"referenceID": 5, "context": "A similar, though mostly orthogonal, line of work are network interdiction problems (Cormican et al., 1998; Woodruff, 2003), in which a leader attempts to interdict a network over which the follower subsequently solves a variation of a network flow problem.", "startOffset": 84, "endOffset": 123}, {"referenceID": 13, "context": "Similarly, Rodoplu and Raj (2010) consider a relatively simple model of network competition in which leaders are nodes setting prices for packets transmitted through them; again, each leader only sets a single variable, the utility functions are problem-specific, and algorithms are specialized to the particular problem structure (and are inapplicable to our setting).", "startOffset": 11, "endOffset": 34}, {"referenceID": 13, "context": "Similarly, Rodoplu and Raj (2010) consider a relatively simple model of network competition in which leaders are nodes setting prices for packets transmitted through them; again, each leader only sets a single variable, the utility functions are problem-specific, and algorithms are specialized to the particular problem structure (and are inapplicable to our setting). Sinha et al. (2014) propose an evolutionary algorithm for solving bi-level Stackelberg problems, but their problem structure is also highly specific to the domain of interest (firms choosing production, investment, and marketing, and maximizing profit), and the evolutionary algorithm leverages significant simplifications, such as the assumption that the market eventually clears.", "startOffset": 11, "endOffset": 390}, {"referenceID": 13, "context": "Similarly, Rodoplu and Raj (2010) consider a relatively simple model of network competition in which leaders are nodes setting prices for packets transmitted through them; again, each leader only sets a single variable, the utility functions are problem-specific, and algorithms are specialized to the particular problem structure (and are inapplicable to our setting). Sinha et al. (2014) propose an evolutionary algorithm for solving bi-level Stackelberg problems, but their problem structure is also highly specific to the domain of interest (firms choosing production, investment, and marketing, and maximizing profit), and the evolutionary algorithm leverages significant simplifications, such as the assumption that the market eventually clears. Leyffer and Munson (2007) present a very generic multi-leader multi-follower setting and solution framework in the context of shared complementarity constraints (which is the case for our problem, where a single follower attacks a single target), but rely on separability of objective functions in leader and follower variables, the assumption that does not obtain in our setting (in addition, their approach only scales to 2-4 leaders, whereas we are able to approximately solve games with 64 leaders).", "startOffset": 11, "endOffset": 778}, {"referenceID": 9, "context": "Kulkarni and Shanbhag (2014) offer a deep theoretical treatment of a relatively broad class of multileader multi-follower games, but much of their analysis and positive results are restricted to potential games, and they do not offer specific algorithmic suggestions.", "startOffset": 0, "endOffset": 29}, {"referenceID": 3, "context": "A recent extension, interdependent defense games (Chan et al., 2012), does consider an attacker who acts simultaneously with the defenders, rather than after observing the joint defense configuration, as in our model.", "startOffset": 49, "endOffset": 68}, {"referenceID": 1, "context": "Interdependent defense games have also been studied in the context of traffic infrastructure defense (Alderson et al., 2011).", "startOffset": 101, "endOffset": 124}, {"referenceID": 2, "context": "Two recent efforts studying multi-defender games explicitly model interdependence among targets through a probabilistic contagion process (Bachrach et al., 2013; Acemoglu et al., 2013).", "startOffset": 138, "endOffset": 184}, {"referenceID": 0, "context": "Two recent efforts studying multi-defender games explicitly model interdependence among targets through a probabilistic contagion process (Bachrach et al., 2013; Acemoglu et al., 2013).", "startOffset": 138, "endOffset": 184}, {"referenceID": 0, "context": ", 2013; Acemoglu et al., 2013). Like our paper, they consider attackers who observe the joint defense prior to making a decision, but each defender is restricted to secure a single node, and strategy space is assumed to be continuous. Vorobeychik et al. (2011) is, to our knowledge, the only other attempt to study strategic settings related to security in which each player\u2019s decision space is combinatorial.", "startOffset": 8, "endOffset": 261}, {"referenceID": 12, "context": "We assume in this model that each player\u2019s utility depends only on the target attacked and its security configuration (Kiekintveld et al., 2009; Letchford & Vorobeychik, 2012).", "startOffset": 118, "endOffset": 175}, {"referenceID": 11, "context": "We model the interdependencies between the nodes as independent cascade contagion (Kempe et al., 2003; Letchford & Vorobeychik, 2012).", "startOffset": 82, "endOffset": 133}, {"referenceID": 11, "context": "We assume in this model that each player\u2019s utility depends only on the target attacked and its security configuration (Kiekintveld et al., 2009; Letchford & Vorobeychik, 2012). We denote by qo i,j the probability that the defender i chooses o at target j \u2208 Ti. While the problem we study assumes that that the utility of any player for a given target depends only on its security configuration o, there is a rather natural way to model interdependencies while retaining this structure, proposed by Letchford and Vorobeychik (2012). Specifically, suppose that dependencies between targets are represented by a graph (T,E), with T the set of targets (nodes) as above, and E the set of edges (j, j\u2032), where an edge from j to j\u2032 means that a successful attack on j may have impact on j\u2032.", "startOffset": 119, "endOffset": 531}, {"referenceID": 27, "context": "Previously, Vorobeychik and Wellman (2008) presented a convergent equilibrium approximation algorithm based on simulated annealing (SA) that would be applicable in our setting.", "startOffset": 12, "endOffset": 43}, {"referenceID": 26, "context": "many players are involved, at which point social welfare falls rather dramatically; this pattern is roughly monotonic with increasing decentralization, with worst outcomes emerging when each player controls a single node, and mirrors previous findings (Vorobeychik et al., 2011).", "startOffset": 252, "endOffset": 278}], "year": 2015, "abstractText": "Stackelberg security game models and associated computational tools have seen deployment in a number of high-consequence security settings, such as LAX canine patrols and Federal Air Marshal Service. These models primarily focus on isolated systems where only one defender is present, despite being part of a more complex system with multiple players. Furthermore, many real systems such as transportation networks and the power grid exhibit interdependencies between targets and, consequently, between decision makers jointly charged with protecting them. In order to understand such multi-defender strategic interactions present in security, we investigate game theoretic models of security games with multiple defenders. Unlike most prior analysis, we specifically focus on the situations in which each defender must protect multiple targets, so that even a single defender\u2019s best response decision is, in general, highly non-trivial. We start with an analytical investigation of multi-defender security games with independent targets, offering an equilibrium and price-of-anarchy analysis of three models with increasing generality. In all models, we find that the defenders have the incentive to over-protect the targets, at times significantly. Additionally, in the simpler models, we find that the price of anarchy is unbounded, linearly increasing both in the number of defenders and the number of targets per defender. Considering interdependencies among targets, we develop a novel mixedinteger linear programming formulation to compute a defender\u2019s best response, and make use of this formulation in approximating Nash equilibria of the game. We apply this approach towards computational strategic analysis of several models of networks representing interdependencies, including real-world power networks. Our analysis shows how network structure and the probability of failure spread determine the propensity of defenders to overor under-invest in security.", "creator": "TeX"}}}