{"id": "1506.02850", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2015", "title": "Adversarial patrolling with spatially uncertain alarm signals", "abstract": "When securing complex infrastructures or large environments, constant monitoring of each area is not affordable. To address this problem, a common countermeasure is the use of cheap but far-reaching sensors that are able to detect suspicious events occurring in large areas and help patrols improve the effectiveness of their strategies. However, such sensors are often affected by uncertainty. In this work, we focus on spatially unsafe alarm signals. That is, the alarm system is able to detect an attack, but it is uncertain where the attack will take place. This is common when the area to be protected is broad, as in border patrols and fair site surveillance. We propose the first patrolling security game model, to the best of knowledge, in which a defender is supported by a spatially unsafe alarm system that generates non-deterministic signals as soon as a target is attacked. We show that the optimal strategy in arbitrary graphics allows even zero-sum analysis of a strategy (we expose two algorithms) and two in zero-sum analysis.", "histories": [["v1", "Tue, 9 Jun 2015 10:22:43 GMT  (5154kb,D)", "http://arxiv.org/abs/1506.02850v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.GT", "authors": ["nicola basilico", "giuseppe de nittis", "nicola gatti"], "accepted": false, "id": "1506.02850"}, "pdf": {"name": "1506.02850.pdf", "metadata": {"source": "CRF", "title": "Adversarial patrolling with spatially uncertain alarm signals", "authors": ["Nicola Basilicoa", "Giuseppe De Nittisb", "Nicola Gattib"], "emails": [], "sections": [{"heading": null, "text": "When securing complex infrastructures or large environments, constant surveillance of every area is not affordable. To cope with this issue, a common countermeasure is the usage of cheap but wide\u2013ranged sensors, able to detect suspicious events that occur in large areas, supporting patrollers to improve the effectiveness of their strategies. However, such sensors are commonly affected by uncertainty. In the present paper, we focus on spatially uncertain alarm signals. That is, the alarm system is able to detect an attack but it is uncertain on the exact position where the attack is taking place. This is common when the area to be secured is wide such as in border patrolling and fair site surveillance. We propose, to the best of our knowledge, the first Patrolling Security Game model where a Defender is supported by a spatially uncertain alarm system which non\u2013deterministically generates signals once a target is under attack. We show that finding the optimal strategy in arbitrary graphs isAPX\u2013hard even in zero\u2013sum games and we provide two (exponential time) exact algorithms and two (polynomial time) approximation algorithms. Furthermore, we analyse what happens in environments with special topologies, showing that in linear and cycle graphs the optimal patrolling strategy can be found in polynomial time, de facto allowing our algorithms to be used in real\u2013life scenarios, while in trees the problem is NP\u2013hard. Finally, we show that without false positives and missed detections, the best patrolling strategy reduces to stay in a place, wait for a signal, and respond to it at best. This strategy is optimal even with non\u2013negligible missed detection rates, which, unfortunately, affect every commercial alarm system. We evaluate our methods in simulation, assessing both quantitative and qualitative aspects.\nKeywords: Security Games, Adversarial Patrolling, Algorithmic Game Theory\nPreprint submitted to Artificial Intelligence June 10, 2015\nar X\niv :1\n50 6.\n02 85\n0v 1\n[ cs\n.A I]\n9 J\nun 2"}, {"heading": "1. Introduction", "text": "Security Games model the task of protecting physical environments as a non\u2013 cooperative game between a Defender and an Attacker [1]. These games usually take place under a Stackelberg (a.k.a. leader\u2013follower) paradigm [2], where the Defender (leader) commits to a strategy and the Attacker (follower) first observes such commitment, then best responds to it. As discussed in the seminal work [3], finding a leader\u2013follower equilibrium is computationally tractable in games with one follower and complete information, while it becomes hard in Bayesian games with different types of Attacker. The availability of such computationally tractable aspects of Security Games led to the development of algorithms capable of scaling up to large problems, making them deployable in the security enforcing systems of several real\u2013world applications. The first notable examples are the deployment of police checkpoints at the Los Angels International Airport [4] and the scheduling of federal air marshals over the U.S. domestic airline flights [5]. More recent case studies include the positioning of U.S. Coast Guard patrols to secure crowded places, bridges, and ferries [6] and the arrangement of city guards to stop fare evasion in Los Angeles Metro [7]. Finally, a similar approach is being tested and evaluated in Uganda, Africa, for the protection of wildlife [8]. Thus, Security Games emerged as an interesting game theoretical tool and then showed their on\u2013 the-field effectiveness in a number of real security scenarios.\nWe focus on a specific class of security games, called Patrolling Security Games. These games are modelled as infinite\u2013horizon extensive\u2013form games in which the Defender controls one or more patrollers moving within an environment represented as a discrete graph. The Attacker, besides having knowledge of the strategy to which the Defender committed to, can observe the movements of the patrollers at any time and use such information in deciding the most convenient time and target location to attack [9]. When multiple patrollers are available, coordinating them at best is in general a hard task which, besides computational aspects, must also keep into account communication issues [10]. However, the patrolling problem is tractable, even with multiple patrollers, in border security (e.g., linear and cycle graphs), when patrollers have homogeneous moving and sensing capabilities and all the vertices composing the border share the same features [11]. Scaling this model involved the study of how to compute patrolling strategies in scenarios where the Attacker is allowed to perform multiple attacks [12]. Similarly, coordination strategies among multiple Defenders are investigated in [13]. In [14], the authors study the case in which there is a temporal discount on the targets. Extensions are discussed in [15], where coordination strategies between\ndefenders are explored, in [16], where a resource can cover multiple targets, and in [17] where attacks can detected at different stages with different associated utilities. Finally, some theoretical results about properties of specific patrolling settings are provided in [18]. In the present paper, we provide a new model of patrolling security games in which the Defender is supported by an alarm system deployed in the environment."}, {"heading": "1.1. Motivation scenarios", "text": "Often, in large environments, a constant surveillance of every area is not affordable while focused inspections triggered by alarms are more convenient. Real\u2013 world applications include UAVs surveillance of large infrastructures [19], wildfires detection with CCD cameras [20], agricultural fields monitoring [21], and surveillance based on wireless sensor networks [22], and border patrolling [23]. Alarm systems are in practice affected by detection uncertainty, e.g., missed detections and false positives, and localization (a.k.a. spatial) uncertainty, e.g., the alarm system is uncertain about the exact target under attack. We summarily describe two practical security problems that can be ascribed to this category. We report them as examples, presenting features and requirements that our model can properly deal with. In the rest of the paper we will necessarily take a general stance, but we encourage the reader to keep in mind these two cases as reference applications for a real deployment of our model."}, {"heading": "1.1.1. Fight to illegal poaching", "text": "Poaching is a widespread environmental crime that causes the endangerment of wildlife in several regions of the world. Its devastating impact makes the development of surveillance techniques to contrast this kind of activities one of the most important matters in national and international debates. Poaching typically takes place over vast and savage areas, making it costly and ineffective to solely rely on persistent patrol by ranger squads. To overcome this issue, recent developments have focused on providing rangers with environmental monitoring systems to better plan their inspections, concentrating them in areas with large likelihood of spotting a crime. Such systems include the use of UAVs flying over the area, alarmed fences, and on\u2013the\u2013field sensors trying to recognize anomalous activities.1 In all these cases, technologies are meant to work as an alarm system: once the illegal activity is recognized, a signal is sent to the rangers base station from\n1See, for example, http://wildlandsecurity.org/.\nwhere a response is undertaken. In the great majority of cases, a signal corresponds to a spatially uncertain localization of the illegal activity. For example, a camera\u2013equipped UAV can spot the presence of a pickup in a forbidden area but cannot derive the actual location to which poachers are moving. In the same way, alarmed fences and sensors can only transmit the location of violated entrances or forbidden passages. In all these cases a signal implies a restricted, yet not precise, localization of the poaching activity. The use of security games in this particular domain is not new (see, for example, [8]). However, our model allows the computation of alarm response strategies for a given alarm system deployed on the field. This can be done by adopting a discretization of the environment, where each target corresponds to a sector, values are related to the expected population of animals in that sector, and deadlines represent the expected completion time of illegal hunts (these parameters can be derived from data, as discussed in [8])."}, {"heading": "1.1.2. Safety of fair sites", "text": "Fairs are large public events attended by thousands of visitors, where the problem of guaranteeing safety for the hosting facilities can be very hard. For example, Expo 2015, the recent Universal Exposition hosted in Milan, Italy, estimates an average of about 100,000 visits per day. This poses the need for carefully addressing safety risks, which can also derive from planned act of vandalism or terrorist attacks. Besides security guards patrols, fair sites are often endowed with locally installed monitoring systems. Expo 2015 employs around 200 baffle gates and 400 metal detectors at the entrance of the site. The internal area is constantly monitored by 4,000 surveillance cameras and by 700 guards. Likely, when one or more of these devices/personnel identify a security breach, a signal is sent to the control room together with a circumscribed request of intervention. This approach is required because, especially in this kind of environments, detecting a security breach and neutralizing it are very different tasks. The latter one, in particular, usually requires a greater effort involving special equipment and personnel whose employment on a demand basis is much more convenient. Moreover, the detecting location of a threat is in many cases different from the location where it could be neutralized, making the request of intervention spatially uncertain. For instance, consider a security guard or a surveillance camera detecting the visitors\u2019 reactions to a shooting rampage performed by some attacker. In examples like these, we can restrict the area where the security breach happened but no precise information about the location can be gathered since the attacker will probably have moved. Our model could be applied to provide a policy with which schedule interventions upon a security breach is detected in some particular section of the site.\nIn such case, targets could correspond to buildings or other installations where visitors can go. Values and deadlines can be chosen according to the importance of targets, their expected crowding, and the required response priority."}, {"heading": "1.2. Alarms and security games", "text": "While the problem of managing a sensor network to optimally guard security\u2013 critical infrastructure has been investigated in restricted domains, e.g. [24], the problem of integrating alarm signals together with adversarial patrolling is almost completely unexplored. The only work that can be classified under this scope is [25]. The paper proposes a skeleton model of an alarm system where sensors have no spatial uncertainty in detecting attacks on single targets. The authors analyse how sensory information can improve the effectiveness of patrolling strategies in adversarial settings. They show that, when sensors are not affected by false negatives and false positives, the best strategy prescribes that the patroller just responds to an alarm signal rushing to the target under attack without patrolling the environment. As a consequence, in such cases the model treatment becomes trivial. On the other hand, when sensors are affected only by false negatives, the treatment can be carried out by means of an easy variation of the algorithm for the case without sensors [9]. In the last case, where false positives are admitted, the problem becomes computationally intractable. To the best of our knowledge, no previous result dealing with spatial uncertain alarm signals in adversarial patrolling is present in the literature.\nEffectively exploiting an alarm system and determining a good deployment for it (e.g., selecting the location where install sensor) are complementary but radically different problems. The results we provide in this work lie in the scope of the first one while the treatment of the second one is left for future works. In other words, we assume that a deployed alarm system is given and we deal with the problem of strategically exploiting it at best. Any approach to search for the optimal deployment should, in principle, know how to evaluate possible deployments. In such sense, our problem needs to be addressed before one might deal with the deployment one."}, {"heading": "1.3. Contributions", "text": "In this paper, we propose the first Security Game model that integrates a spatially uncertain alarm system in game\u2013theoretic settings for patrolling.2 Each\n2A very preliminary short version of the present paper is [26].\nalarm signal carries the information about the set of targets that can be under attack and it is described by the probability of being generated when each target is attacked. Moreover, the Defender can control only one patroller. The game can be decomposed in a finite number of finite\u2013horizon subgames, each called Signal Response Game from v (SRG\u2013v) and capturing the situation in which the Defender is in a vertex v and the Attacker attacked a target, and an infinite\u2013horizon game, called Patrolling Game (PG), in which the Defender moves in absence of any alarm signal. We show that, when the graph has arbitrary topology, finding the equilibrium in each SRG\u2013v isAPX\u2013hard even in the zero\u2013sum case. We provide two exact algorithms. The first one, based on dynamic programming, performs a breadth\u2013first search, while the second one, based on branch\u2013and\u2013bound approach, performs a depth\u2013first search. We use the same two approaches to design two approximation algorithms. Furthermore, we provide a number of additional results for the SRG\u2013v. We study special topologies, showing that there is a polynomial time algorithm solving a SRG\u2013v on linear and cycle graphs, while it is NP\u2013hard with trees. Then, we study the PG, showing that when no false positives and no missed detections are present, the optimal Defender strategy is to stay in a fixed location, wait for a signal, and respond to it at best. This strategy keeps being optimal even when non\u2013negligible missed detection rates are allowed. We experimentally evaluate the scalability of our exact algorithms and we compare them w.r.t. the approximation ones in terms of solution quality and compute times, investigating in hard instances the gap between our hardness results and the theoretical guarantees of our approximation algorithms. We show that our approximation algorithms provide very high quality solutions even in hard instances. Finally, we provide an example of resolution for a realistic instance, based on Expo 2015, and we show that our exact algorithms can be applied for such kind of settings. Moreover, in our realistic instance we assess how the optimal patrolling strategy coincides with a static placement even when allowing a false positive rate of less or equal to 30%."}, {"heading": "1.4. Paper structure", "text": "In Section 2, we introduce our game model. In Section 3, we study the problem of finding the strategy of the Defender for responding to an alarm signal in an arbitrary graph while in Section 4, we provide results for specific topologies. In Section 5, we study the patrolling problem. In Section 6, we experimentally evaluate our algorithms. In Section 7, we briefly discuss the main Security Games research directions that have been explored in the last decades. Finally, Section 8\nconcludes the paper. Appendix A includes a notation table, while Appendix B reports some additional experimental results."}, {"heading": "2. Problem statement", "text": "In this section we formalize the problem we study. More precisely, in Section 2.1 we describe the patrolling setting and the game model, while in Section 2.2 we state the computational questions we shall address in this work."}, {"heading": "2.1. Game model", "text": "Initially, in Section 2.1.1, we introduce a basic patrolling security game model integrating the main features from models currently studied in literature. Next, in Section 2.1.2, we extend our game model by introducing alarm signals. In Section 2.1.3, we depict the game tree of our patrolling security game with alarm signals and we decompose it in notable subgames to facilitate its study."}, {"heading": "2.1.1. Basic patrolling security game", "text": "As is customary in the artificial intelligence literature [9, 14], we deal with discrete, both in terms of space and time, patrolling settings, representing an approximation of a continuous environment. Specifically, we model the environment to be patrolled as an undirected connected graph G = (V,E), where vertices represent different areas connected by various corridors/roads, formalized through the edges. Time is discretized in turns. We define T \u2286 V the subset of sensible vertices, called targets, that must be protected from possible attacks. Each target t \u2208 T is characterized by a value \u03c0(t) \u2208 (0, 1] and a penetration time d(t) \u2208 N+ which measures the number of turns needed to complete an attack to t.\nExample 1 We report in Figure 1 an example of patrolling setting. Here, V = {v0, v1, v2, v3, v4}, T = {t1, t2, t3, t4} where ti = vi for i \u2208 {1, 2, 3, 4}. All the targets t present the same value \u03c0(t) and the same penetration time d(t).\nAt each turn, an Attacker A and a Defender D play simultaneously having the following available actions:\n\u2022 ifA has not attacked in the previous turns, it can observe the position ofD in the graph G3 and decide whether to attack a target or to wait for a turn. The\n3Partial observability of A over the position of D can be introduced as discussed in [27].\nattack is instantaneous, meaning that there is no delay between the decision to attack and the actual presence of a threat in the selected target4;\n\u2022 D has no information about the actions undertaken by A in previous turns and selects the next vertex to patrol among those adjacent to the current one; each movement is a non\u2013preemptive traversal of a single edge (v, v\u2032) \u2208 E and takes one turn to be completed (along the paper, we shall use \u03c9\u2217v,v\u2032 to denote the temporal cost expressed in turns of the shortest path between any v and v\u2032 \u2208 V ).\nThe game may conclude in correspondence of any of the two following events. The first one is when D patrols a target t that is under attack by A from less than d(t) turns. In such case the attack is prevented and A is captured. The second one is when target t is attacked and D does not patrol t during the d(t) turns that follow the beginning of the attack. In such case the attack is successful and A escapes without being captured. WhenA is captured, D receives a utility of 1 and A receives a utility of 0. When an attack to t has success, D receives 1\u2212 \u03c0(t) and A receives \u03c0(t). The game may not conclude ifA decides to never attack (namely to wait for every turn). In such case,D receives 1 andA receives 0. Notice that the game is constant sum and therefore it is equivalent to a zero\u2013sum game through an affine transformation.\nThe above game model is in extensive form (being played sequentially), with imperfect information (D not observing the actions undertaken by A), and with infinite horizon (A being in the position to wait forever). The fact that A can\n4This is a worst\u2013case assumption according to which A is as strong as possible. It can be relaxed by associating execution costs to the Attacker\u2019s actions as shown in [28].\nobserve the actions undertaken by D before acting makes the leader\u2013follower equilibrium the natural solution concept for our problem, where D is the leader and A is the follower. Since we focus on zero\u2013sum games, the leader\u2019s strategy at the leader\u2013follower equilibrium is its maxmim strategy and it can be found by employing linear mathematical programming, which requires polynomial time in the number of actions available to the players [29]."}, {"heading": "2.1.2. Introducing alarm signals", "text": "We extend the game model described in the previous section by introducing a spatial uncertain alarm system that can be exploited by D. The basic idea is that an alarm system uses a number of sensors spread over the environment to gather information about possible attacks and raises an alarm signal at any time an attack occurs. The alarm signal provides some information about the location (target) where the attack is ongoing, but it is affected by uncertainty. In other words, the alarm system detects an attack but it is uncertain about the target under attack. Formally, the alarm system is defined as a pair (S, p), where S = {s1, \u00b7 \u00b7 \u00b7 , sm} is a set of m \u2265 1 signals and p : S \u00d7 T \u2192 [0, 1] is a function that specifies the probability of having the system generating a signal s given that target t has been attacked. With a slight abuse of notation, for a signal s we define T (s) = {t \u2208 T | p(s | t) > 0} and, similarly, for a target t we have S(t) = {s \u2208 S | p(s | t) > 0}. In this work, we assume that:\n\u2022 the alarm system is not affected by false positives (signals generated when no attack has occurred). Formally, p(s | 4) = 0, where4 indicates that no targets are under attack;\n\u2022 the alarm system is not affected by false negatives (signals not generated even though an attack has occurred). Formally, p(\u22a5 | t) = 0, where \u22a5 indicates that no signals have been generated; in Section 5 we will show that the optimal strategies we compute under this assumption can preserve optimality even in presence of non\u2013negligible false negatives rates.\nExample 2 We report two examples of alarm systems for the patrolling setting depicted in Figure 1. The first example is reported in Figure 2(a). It is a low\u2013 accuracy alarm system that generates the same signal anytime each target is under attack and therefore the alarm system does not provide any information about the target under attack. The second example is reported in Figure 2(b). It provides more accurate information about the localization of the attack than the previous example. Here, each target ti, once attacked, generates an alarm signal si with\nhigh probability and a different signal with low probability. That is, if alarm signal si has been observed, it is more likely that the attack is in target ti (given a uniform strategy of A over the targets).\nGiven the presence of an alarm system defined as above, the game mechanism changes in the following way. At each turn, before deciding its next move, D observes whether or not a signal has been generated by the alarm system and then makes its decision considering such information. This introduces in our game a node of chance implementing the non\u2013deterministic selection of signals, which characterizes the alarm system."}, {"heading": "2.1.3. The game tree and its decomposition", "text": "Here we depict the game tree of our game model, decomposing it in some recurrent subgames. A portion of the game is depicted in Figure 3. Such tree can be read along the following steps.\n\u2022 Root of the tree. A decides whether to wait for a turn (this action is denoted by the symbol4 since no target is under attack) or to attack a target ti \u2208 T (this action is denoted by the label ti of the target to attack).\n\u2022 Second level of the tree. N denotes the alarm system, represented by a nature\u2013type player. Its behavior is a priori specified by the conditional probability mass function p which determines the generated signal given the attack performed by A. In particular, it is useful to distinguish between two cases:\n(a) if no attack is present, then no signal will be generated under the assumption that p(\u22a5 | 4) = 1;\n(b) if an attack on target ti is taking place, a signal s will be drawn from S(ti) with probability p(s | ti) (recall that we assumed p(\u22a5 | ti) = 0).\n\u2022 Third level of the tree.D observes the signal raised by the alarm system and decides the next vertex to patrol among those adjacent to the current one (the current vertex is initially chosen by D).\n\u2022 Fourth level of the tree and on. It is useful to distinguish between two cases:\n(a) if no attack is present, then the tree of the subgame starting from here is the same of the tree of the whole game, except for the position of D that may be different from the initial one;\n(b) if an attack is taking place on target ti, then only D can act.\nSuch game tree can be decomposed in a number of finite recurrent subgames such that the best strategies of the agents in each subgame are independent from those in other subgames. This decomposition allows us to apply a divide et impera approach, simplifying the resolution of the problem of finding an equilibrium. More precisely, we denote with \u0393 one of these subgames. We define \u0393 as a game subtree that can be extracted from the tree of Figure 3 as follows. Given D\u2019s current vertex v \u2208 V , select a decision node for A and call it i. Then, extract the subtree rooted in i discarding the branch corresponding to action \u2206 (no attack)5.\n5Rigorously speaking, our definition of subgame is not compliant with the definition provided in game theory [30], which requires that all the actions of a node belong to the same subgame (and therefore we could not separate action \u2206 from actions ti). However, we can slightly change the structure of our game making our definition of subgame compliant with the one from game theory. More precisely, it is sufficient to split each node of A into two nodes: in the first A decides to attack a target or to wait for one turn, and in the second, conditioned to the fact that A decided to attack,A decides which target to attack. This way, the subtree whose root is the second node ofA is a subgame compliant with game theory. It can be easily observed that this change to the game tree structure does not affect the behaviour of the agents.\nIntuitively, such subgame models the players interaction when the Defender is in some given vertex v and the Attacker will perform an attack. As a consequence, each \u0393 obtained in such way is finite (once an attack on t started, the maximum length of the game is d(t)). Moreover, the set of different \u0393s we can extract is finite since we have one subgame for each possible current vertex for D, as a consequence we can extract at most |V | different subgames. Notice that, due to the infinite horizon, each subgame can recur an infinite number of times along the game tree. However, being such repetitions independent and the game zero\u2013sum, we only need to solve one subgame to obtain the optimal strategy to be applied in each of its repetitions. In other words, when assuming that an attack will be performed, the agents\u2019 strategies can be split in a number of independent strategies solely depending on the current position of the Defender. The reason why we discarded the branch corresponding to action \u2206 in each subgame is that we seek to deal with such complementary case exploiting a simple backward induction approach as explained in the following.\nFirst, we call Signal Response Game from v the subgame \u0393 defined as above and characterized by a vertex v representing the current vertex of D (for brevity, we shall use SRG\u2013v). In an SRG\u2013v, the goal of D is to find the best strategy starting from vertex v to respond to any alarm signal. All the SRG\u2013vs are independent one each other and thus the best strategy in each subgame does not depend on the strategies of the other subgames. The intuition is that the best strategies in an SRG\u2013v does not depend on the vertices visited by D before the attack. Given an SRG\u2013v, we denote by \u03c3Dv,s the strategy of D once observed signal s, by \u03c3Dv the strategy profile \u03c3Dv = (\u03c3 D v,s1 . . . , \u03c3Dv,sm) of D, and by \u03c3 A v the strategy of A. Let us notice that in an SRG\u2013v, given a signal s,D is the only agent that plays and therefore each sequence of moves between vertices of D in the tree can be collapsed in a single action. Thus, SRG\u2013v is essentially a two\u2013level game in which A decides the target to attack and D decides the sequence of moves to visit the targets.\nThen, according to classical backward induction arguments [30], once we have found the best strategies of each SRG\u2013v, we can substitute the subgames with the agents\u2019 equilibrium utilities and then we can find the best strategy of D for patrolling the vertices whenever no alarm signal has been raised and the best strategy of attack for A. We call this last problem Patrolling Game (for conciseness, we shall use PG). We denote by \u03c3D and \u03c3A the strategies of D and A respectively in the PG.\n2.2. The computational questions we pose In the present paper, we focus on some questions whose answers play a fundamental role in the design of the best algorithms to find an equilibrium of our game. More precisely, we investigate the computational complexity of the following four problems. The first problem concerns the PG.\nQuestion 1 Which is the best patrolling strategy for D maximizing its expected utility?\nThe other three questions concern SRG\u2013v. For the sake of simplicity, we focus on the case in which there is only one signal s, we shall show that it is possible to scale linearly in the number of signals.\nQuestion 2 Given a starting vertex v and a signal s, is there any strategy of D that allows D to visit all the targets in T (s), each within its deadline?\nQuestion 3 Given a starting vertex v and a signal s, is there any pure strategy of D giving D an expected utility of at least k?\nQuestion 4 Given a starting vertex v and a signal s, is there any mixed strategy of D giving D an expected utility of at least k?\nIn the following, we shall take a bottom\u2013up approach answering the above questions starting from the last three and then dealing with the first one at the whole\u2013game level."}, {"heading": "3. Signal response game on arbitrary graphs", "text": "In this section we show how to deal with an SRG\u2013v on arbitrary graphs. Specifically, in Section 3.1 we prove the hardness of the problem, analyzing its computational complexity. Then, in Section 3.2 and in Section 3.3 we propose two algorithms, the first based on dynamic programming (breadth\u2013first search) while the second adopts a branch and bound (depth\u2013first search) paradigm. Furthermore, we provide a variation for each algorithm, approximating the optimal solution."}, {"heading": "3.1. Complexity results", "text": "In this section we analyse SRG\u2013v from a computational point of view. We initially observe that each SRG\u2013v is characterized by |T | actions available to A, each corresponding to a target t, and by O(|V |maxt{d(t)}) decision nodes of D. The portion of game tree played by D can be safely reduced by observing that D will move between any two targets along the minimum path. This allows us to discard from the tree all the decision nodes where D occupies a non\u2013target vertex. However, this reduction keeps the size of the game tree exponential in the parameters of the game, specifically O(|T ||T |).6 The exponential size of the game tree does not constitute a proof that finding the equilibrium strategies of an SRG\u2013v requires exponential time in the parameters of the game because it does not exclude the existence of some compact representation of D\u2019s strategies, e.g., Markovian strategies. Indeed such representation should be polynomially upper bounded in the parameters of the game and therefore they would allow the design of a polynomial\u2013time algorithm to find an equilibrium. We show below that it is unlikely that such a representation exists in arbitrary graphs, while it exists for special topologies as we shall discuss later.\nWe denote by gv the expected utility of A from SRG\u2013v and therefore the expected utility of D is 1\u2212 gv. Then, we define the following problem.\nDefinition 1 (k\u2013SRG\u2013v) The decision problem k\u2013SRG\u2013v is defined as: INSTANCE: an instance of SRG\u2013v; QUESTION: is there any \u03c3D such that gv \u2264 k (when A plays its best response)?\nTheorem 1 k\u2013SRG\u2013v is strongly NP\u2013hard even when |S| = 1.\nProof. Let us consider the following reduction from HAMILTONIAN\u2013PATH [31]. Given an instance of HAMILTONIAN\u2013PATH GH = (VH , EH), we build an instance for k\u2013SRG\u2013v as:\n\u2022 V = VH \u222a {v};\n\u2022 E = EH \u222a {(v, h),\u2200h \u2208 VH};\n\u2022 T = VH ;\n\u2022 d(t) = |VH |;\n6A more accurate bound is O(|T |min{|T |,maxt{d(t)}}).\n\u2022 \u03c0(t) \u2208 (0, 1], for all t \u2208 T (any value);\n\u2022 S = {s1};\n\u2022 T (s1) = T ;\n\u2022 p(s1 | t) = 1, for all t \u2208 T ;\n\u2022 k = 0.\nIf gs \u2264 0, then there must exist a path starting from v and visiting all the targets in T by d = |VH |. Given the penetration times assigned in the above construction and recalling that edge costs are unitary, the path must visit each target exactly once. Therefore, since T = VH , the game\u2019s value is less than or equal to zero if and only if GH admits a Hamiltonian path. This concludes the proof.\nNotice that the problem of assessing the membership of k\u2013SRG\u2013v to NP is left open and it strictly depends on the size of the support of the strategy of \u03c3Dv . That is, if any strategy \u03c3 D v has a polynomially upper bounded support, then k\u2013SRG\u2013v is in NP . We conjecture it is not and therefore there can be optimal strategies in which an exponential number of actions are played with strictly positive probability. Furthermore, the above result shows that with arbitrary graphs:\n\u2022 answering to Question 1 is FNP\u2013hard,\n\u2022 answering to Questions 2, 3, 4 is NP\u2013hard.\nAs a consequence a polynomial\u2013time algorithm solving those problems is unlikely to exist. In particular, the above proof shows that we cannot produce a compact representation (a.k.a. information lossless abstractions) of the space of strategies of D that is smaller than O(2|T (s)|), unless there is an algorithm better than the best\u2013known algorithm for HAMILTONIAN\u2013PATH. This is due to the fact that the best pure maxmin strategy can be found in linear time in the number of the pure strategies and the above proof shows that it cannot be done in a time less than O(2|T (s)|). More generally, no polynomially bounded representation of the space of the strategies can exist, unless P = NP .\nAlthough we can deal only with exponentially large representations of D\u2019s strategies, we focus on the problem of finding the most efficient representation. Initially, we provide the following definitions.\nDefinition 2 (Route) Given a starting vertex v and a signal s, a route (over the targets) r is a generic sequence of targets of T (s) such that:\n\u2022 r starts from v,\n\u2022 each target t \u2208 T (s) occurs at most once in r (but some targets may not occur),\n\u2022 r(i) is the i\u2013th visited target in r (in addition, r(0) = v).\nAmong all the possible routes we restrict our attention on a special class of routes that we call covering and are defined as follows.\nDefinition 3 (Covering Route) Given a starting vertex v and a signal s, a route r is covering when, denoted by Ar(r(i)) = \u2211i\u22121 h=0 \u03c9 \u2217 r(h),r(h+1) the time needed by D to visit target t = r(i) \u2208 T (s) starting from r(0) = v and moving along the shortest path between each pair of consecutive targets in r, for every target t occurring in r it holds Ar(r(i)) \u2264 d(r(i)) (i.e., all the targets are visited within their penetration times).\nWith a slight abuse of notation, we denote by T (r) the set of targets covered by r and we denote by c(r) the total temporal cost of r, i.e., c(r) = Ar(r(|T (r)|)). Notice that in the worst case the number of covering routes is O(|T (s)||T (s)|), but computing all of them may be unnecessary since some covering routes will never be played by D due to strategy domination and therefore they can be safely discarded [32]. More precisely, we introduce the following two forms of dominance.\nDefinition 4 (Intra\u2013Set Dominance) Given a starting vertex v, a signal s and two different covering routes r, r\u2032 such that T (r) = T (r\u2032), if c(r) \u2264 c(r\u2032) then r dominates r\u2032.\nDefinition 5 (Inter\u2013Set Dominance) Given a starting vertex v, a signal s and two different covering routes r, r\u2032, if T (r) \u2283 T (r\u2032) then r dominates r\u2032.\nFurthermore, it is convenient to introduce the concept of covering set, which is strictly related to the concept of covering route. It is defined as follows.\nDefinition 6 (Covering Set) Given a starting vertex v and a signal s, a covering set Q is a subset of targets T (s) such that there exists a covering route r with T (r) = Q.\nLet us focus on Definition 4. It suggests that we can safely use only one route per covering set. Covering sets suffice for describing all the outcomes of the game, since the agents\u2019 payoffs depend only on the fact that A attacks a target t that is\ncovered byD or not, and in the worst case areO(2|T (s)|), with a remarkable reduction of the search space w.r.t. O(|T (s)||T (s)|). However, any algorithm restricting on covering sets should be able to determine whether or not a set of targets is a covering one. Unfortunately, this problem is hard too.\nDefinition 7 (COV\u2013SET) The decision problem COV\u2013SET is defined as: INSTANCE: an instance of SRG\u2013v with a target set T ; QUESTION: is T a covering set for some covering route r?\nBy trivially adapting the same reduction for Theorem 1 we can state the following theorem.\nTheorem 2 COV\u2013SET is NP\u2013complete.\nTherefore, computing a covering route for a given set of targets (or deciding that no covering route exists) is not doable in polynomial time unless P = NP . This shows that, while covering sets suffice for defining the payoffs of the game and therefore the size of payoffs matrix can be bounded by the number of covering sets, in practice we also need covering routes to certificate that a given subset of targets is covering. Thus, we need to work with covering routes, but we just need the routes corresponding to the covering sets, limiting the number of covering routes that are useful for the game to the number of covering sets. In addition, Theorem 2 suggests that no algorithm for COV\u2013SET can have complexity better than O(2|T (s)|) unless there exists a better algorithm for HAMILTONIAN\u2013PATH than the best algorithm known in the literature. This seems to suggest that enumerating all the possible subsets of targets (corresponding to all the potential covering sets) and, for each of them, checking whether or not it is covering requires a complexity worse than O(2|T (s)|). Surprisingly, we show in the next section that there is an algorithm with complexity O(2|T (s)|) (neglecting polynomial terms) to enumerate all and only the covering sets and, for each of them, one covering route. Therefore, the complexity of our algorithm matches (neglecting polynomial terms) the complexity of the best\u2013known algorithm for HAMILTONIAN\u2013PATH.\nLet us focus on Definition 5. Inter\u2013Set dominance can be leveraged to introduce the concept of maximal covering sets which could enable a further reduction in the set of actions available to D.\nDefinition 8 (MAXIMAL COV\u2013SET) Given a covering setQ (whereQ = T (r) for some r), we say that Q is maximal if there is no route r\u2032 such that Q \u2282 T (r\u2032).\nFurthermore, we say that r such that T (r) = Q is a maximal covering route. In the best case, when there is a route covering all the targets, the number of maximal covering sets is 1, while the number of covering sets (including the non\u2013maximal ones) is 2|T (s)|. Thus, considering only maximal covering sets allows an exponential reduction of the payoffs matrix. In the worst case, when all the possible subsets composed of |T (s)|/2 targets are maximal covering sets, the number of maximal covering sets is O(2|T (s)|\u22122), while the number of covering sets is O(2|T (s)|\u22121), allowing a reduction of the payoffs matrix by a factor of 2. Furthermore, if we knew a priori that Q is a maximal covering set, we could avoid searching for covering routes for any set of targets that strictly contains Q. When designing an algorithm to solve this problem, Definition 5 could then be exploited to introduce some kind of pruning technique to save average compute time. However, the following result shows that deciding if a covering set is maximal is hard.\nDefinition 9 (MAX\u2013COV\u2013SET) The decision problem MAX\u2013COV\u2013SET is defined as: INSTANCE: an instance of SRG\u2013v with a target set T and a covering set T \u2032 \u2282 T ; QUESTION: is T \u2032 maximal?\nTheorem 3 There is no polynomial\u2013time algorithm for MAX\u2013COV\u2013SET unless P = NP .\nProof. Assume for simplicity that S = {s1} and that T (s1) = T . Initially, we observe that MAX\u2013COV\u2013SET is in co\u2013NP . Indeed, any covering route r such that T (r) \u2283 T \u2032 is a NO certificate for MAX\u2013COV\u2013SET, placing it in co\u2013NP . (Notice that, trivially, any covering route has length bounded by O(|T |2); also, notice that due to Theorem 2, having a covering set would not suffice given that we cannot verify in polynomial time whether it is actually covering unless P = NP .)\nLet us suppose we have a polynomial\u2013time algorithm for MAX\u2013COV\u2013SET, called A. Then (since P \u2286 NP \u2229 co\u2013NP) we have a polynomial algorithm for the complement problem, i.e., deciding whether all the covering routes for T \u2032 are dominated. Let us consider the following algorithm: given an instance for COV\u2013 SET specified by graph G = (V,E), a set of target T with penetration times d, and a starting vertex v:\n1. assign to targets in T a lexicographic order t1, t2, . . . , t|T |;\n2. for every t \u2208 T , verify if {t} is a covering set in O(|T |) time by comparing \u03c9\u2217v,t and d(t); if at least one is not a covering set, then output NO and terminate; otherwise set T\u0302 = {t1} and k = 2;\n3. apply algorithm A on the following instance: graph G = (V,E), target set {T\u0302\u222a{tk}, d\u0302} (where d\u0302 is d restricted to T\u0302\u222a{tk}), start vertex v, and covering set T\u0302 ;\n4. if A\u2019s output is YES (that is, T\u0302 is not maximal) then set T\u0302 = T\u0302 \u222a {tk}, k = k + 1 and restart from step 3; if A\u2019s output is NO and k = |T | then output YES; if A\u2019s output is NO and k < |T | then output NO;\nThus, the existence of A would imply the existence of a polynomial algorithm for COV\u2013SET which (under P 6= NP) would contradict Theorem 2. This concludes the proof.\nNevertheless, we show hereafter that there exists an algorithm enumerating all and only the maximal covering sets and one route for each of them (which potentially leads to an exponential reduction of the time needed for solving the linear program) with only an additional polynomial cost w.r.t. the enumeration of all the covering sets. Therefore, neglecting polynomial terms, our algorithm has a complexity of O(2|T (s)|).\nFinally, we focus on the complexity of approximating the best solution in an SRG\u2013v. When D restricts its strategies to be pure, the problem is clearly not approximable in polynomial time even when the approximation ratio depends on |T (s)|. The basic intuition is that, if a game instance admits the maximal covering route that covers all the targets and the value of all the targets is 1, then either the maximal covering route is played returning a utility of 1 to D or any other route is played returning a utility of 0, but no polynomial\u2013time algorithm can find the maximal covering route covering all the targets, unless P = NP . On the other hand, it is interesting to investigate the case in which no restriction to pure strategies is present. We show that the problem keeps being hard.\nTheorem 4 The optimization version of k\u2013SRG\u2013v, say OPT\u2013SRG\u2013v, is APX\u2013 hard even in the restricted case in which the graph is metric, there is only one signal s, all targets t \u2208 T (s) have the same penetration time d(t), and there is the maximal covering route covering all the targets.\nProof. We produce an approximation\u2013preserving reduction from TSP(1,2) that is known to beAPX\u2013hard [33]. For the sake of clarity, we divide the proof in steps.\nTSP(1,2) instance. An instance of undirected TSP(1,2) is defined as follows:\n\u2022 a set of vertices VTSP ,\n\u2022 a set of edges composed of an edge per pair of vertices,\n\u2022 a symmetric matrix CTSP of weights, whose values can be 1 or 2, each associated with an edge and representing the cost of the shortest path between the corresponding pair of vertices.\nThe goal is to find the minimum cost tour. Let us denote by OPTSOLTSP and OPTTSP the optimal solution of TSP(1,2) and its cost, respectively. Furthermore, let us denote by APXSOLTSP and APXTSP an approximate solution of TSP(1,2) and its cost, respectively. It is known that there is no polynomial\u2013time approximation algorithm with APXTSP/OPTAPX < \u03b1 for some \u03b1 > 1, unless P = NP [33].\nReduction. We map an instance of TSP(1,2) to a specific instance of SRG\u2013v as follows:\n\u2022 there is only one signal s,\n\u2022 T (s) = VTSP ,\n\u2022 w\u2217t,t\u2032 = CTSP (t, t\u2032), for every t, t\u2032 \u2208 T (s),\n\u2022 \u03c0(t) = 1, for every t \u2208 T (s),\n\u2022 w\u2217v,t = 1, for every t \u2208 T (s),\n\u2022 d(t) = { OPTTSP if OPTTSP = |VTSP | OPTTSP \u2212 1 if OPTTSP > |VTSP | , for every t \u2208 T (s).\nIn this reduction, we use the value ofOPTTSP even if there is no polynomial\u2013time algorithm solving exactly TSP(1,2), unless P = NP . We show below that with an additional polynomial\u2013time effort we can deal with the lack of knowledge of OPTTSP .\nOPT\u2013SRG\u2013v optimal solution. By construction of the SRG\u2013v instance, there is a covering route starting from v and visiting all the targets t \u2208 T (s), each within its penetration time. This route has a cost of exactly d(t) and it is \u3008v, t1, . . . , t|T (s)|\u3009, where \u3008t1, . . . , t|T (s)|, t1\u3009 corresponds to OPTSOLTSP with the constraint that w\u2217t|T (s)|,t1 = 2 if OPTTSP > |VTSP | (essentially, we transform the tour in a path by discarding one of the edges with the largest cost). Therefore, the optimal solution of SRG\u2013v, say OPTSOLSRG, prescribes to play the maximal route with probability one and the optimal value, say OPTSRG, is 1.\nOPT\u2013SRG\u2013v approximation. Let us denote by APXSOLSRG and APXSRG an approximate solution of OPT\u2013SRG\u2013v and its value, respectively. We assume\nthere is a polynomial\u2013time approximation algorithm with APXSRG/OPTSRG \u2265 \u03b2 where \u03b2 \u2208 (0, 1). Let us notice that APXSOLSRG prescribes to play a polynomially upper bounded number of covering routes with strictly positive probability. We introduce a lemma that characterizes such covering routes.\nLemma 5 The longest covering route played with strictly positive probability in APXSOLSRG visits at least \u03b2|T (s)| targets.\nProof. Assume by contradiction that the longest route visits \u03b2|T (s)|\u22121 targets. The best case in terms of maximization of the value of OPT\u2013SRG\u2013v is, due to reasons of symmetry (all the targets have the same value), when there is a set of |T (s)| covering routes of length \u03b2|T (s)| \u2212 1 such that each target is visited exactly by \u03b2|T (s)| \u2212 1 routes. When these routes are available, the best strategy is to randomize uniformly over the routes. The probability that a target is covered is \u03b2 \u2212 1|T (s)| and therefore the value of APXSRG is \u03b2 \u2212 1 |T (s)| . This leads to a contradiction, since the algorithm would provide an approximation strictly smaller than \u03b2.\nTSP(1,2) approximation from OPT\u2013SRG\u2013v approximation. We use the above lemma to show that we can build a (3\u22122\u03b2)\u2013approximation for TSP(1,2) from a \u03b2\u2013 approximation of OPT\u2013SRG\u2013v. Given an APXSOLSRG, we extract the longest covering route played with strictly positive probability, say \u3008v, t1, . . . , t\u03b2|T (s)|\u3009. The route has a cost of at most d(t), it would not cover \u03b2|T (s)| targets otherwise. Any tour \u3008t1, . . . , t\u03b2|T (s)|, t\u03b2|T (s)|+1, . . . , t|T (s)|, t1\u3009 has a cost not larger than d(t) \u2212 1 + 2(1 \u2212 \u03b2)|T (s)| = OPTTSP \u2212 1 + 2(1 \u2212 \u03b2)|VTSP | (under the worst case in which all the edges in \u3008t\u03b2|T (s)|, t\u03b2|T (s)|+1, . . . , t|T (s)|, t1\u3009 have a cost of 2). Given that OPTTSP \u2265 |VTSP |, we have that such a tour has a cost not larger than OPTTSP \u2212 1 + 2(1 \u2212 \u03b2)|VTSP | \u2264 OPTTSP (3 \u2212 2\u03b2). Therefore, the tour is a (3 \u2212 2\u03b2)\u2013approximation for TSP(1,2). Since TSP(1,2) is not approximable in polynomial time for any approximation ratio smaller than \u03b1, we have the constraint that 3 \u2212 2\u03b2 \u2265 \u03b1, and therefore that \u03b2 \u2264 3\u2212\u03b1\n2 . Since \u03b1 > 1, we have that\n3\u2212\u03b1 2 < 1 and therefore that there is no polynomial\u2013time approximation algorithm for OPT\u2013SRG\u2013v when \u03b2 \u2208 (3\u2212\u03b1 2 , 1), unless P = NP .\nOPTTSP oracle. In order to deal with the fact that we do not know OPTTSP , we can execute the approximation algorithm for OPT\u2013SRG\u2013v using a guess over OPTTSP . More precisely, we execute the approximation algorithm for every value in {|VTSP |, . . . , 2|VTSP |} and we return the best approximation found for TSP(1,2). Given thatOPTTSP \u2208 {|VTSP |, . . . , 2|VTSP |}, there is an execution of the approximation algorithm that uses the correct guess.\nWe report some remarks to the above theorem.\nRemark 1 The above result does not exclude the existence of constant\u2013ratio approximation algorithms for OPT\u2013SRG\u2013v. We conjecture that it is unlikely. OPT\u2013 SRG\u2013v presents similarities with the (metric) DEADLINE\u2013TSP, where the goal is to find the longest path of vertices each traversed before its deadline. The DEADLINE\u2013TSP does not admit any constant\u2013ratio approximation algorithm [34] and the best\u2013known approximation algorithm has logarithmic approximation ratio [35]. The following observations can be produced about the relationships between OPT\u2013SRG\u2013v and DEADLINE\u2013TSP:\n\u2022 when the maximal route covering all the targets in the OPT\u2013SRG\u2013v exists, the optimal solution of the OPT\u2013SRG\u2013v is also optimal for the DEADLINE\u2013 TSP applied to the same graph;\n\u2022 when the maximal route covering all the targets in the OPT\u2013SRG\u2013v does not exist, the optimal solutions of the two problems are different, even when we restrict us to pure\u2013strategy solutions for the OPT\u2013SRG\u2013v;\n\u2022 approximating the optimal solution of the DEADLINE\u2013TSP does not give a direct technique to approximate OPT\u2013SRG\u2013v, since we should enumerate all the subsets of targets and for each subset of targets we would need to execute the approximation of the DEADLINE\u2013TSP, but this would require exponential time. We notice in addition that even the total number of sets of targets with logarithmic size is not polynomial, being \u2126(2log\n2(|T |)), and therefore any algorithm enumerating them would require exponential time;\n\u2022 when the optimal solution of the OPT\u2013SRG\u2013v is randomized, examples of optimal solutions in which maximal covering routes are not played can be produced, showing that at the optimum it is not strictly necessary to play maximal covering routes, but even approximations suffice.\nRemark 2 If it is possible to map DEADLINE\u2013TSP instances to OPT\u2013SRG\u2013v instances where the maximal covering route covering all the targets exists, then it trivially follows that OPT\u2013SRG\u2013v does not admit any constant\u2013approximation ratio. We were not able to find such a mapping and we conjecture that, if there is an approximation\u2013preserving reduction from DEADLINE\u2013TSP to OPT\u2013SRG\u2013v, then we cannot restrict to such instances. The study of instances of OPT\u2013SRG\u2013v where mixed strategies may be optimal make the treatment very challenging."}, {"heading": "3.2. Dynamic\u2013programming algorithm", "text": "We start by presenting two algorithms. The first one is exact, while the second one is an approximation algorithm. Both algorithms are based on a dynamic programming approach."}, {"heading": "3.2.1. Exact algorithm", "text": "Here we provide an algorithm based on the dynamic programming paradigm returning the set of strategies available to D when it is in v and receives a signal s. The algorithm we present in this section enumerates all the covering sets and, for each of them, it returns also the corresponding covering route. Initially, we observe that we can safely restrict our attention to a specific class of covering sets, that we call proper, defined as follows.\nDefinition 10 (Proper Covering Set) Given a starting vertex v and a signal s, a covering set Q is proper if there is a route r such that, once walked (along the shortest paths) over graph G, it does not traverse any target t \u2208 T (s) \\ T (r).\nWhile in the worst case the number of proper covering sets is equal to the number of covering sets (consider, for example, fully connected graphs with unitary edge costs) in realistic scenarios we expect that the number of proper covering sets is much smaller than the number of covering sets. As we show in Section 5, restricting to proper covering sets makes the complexity of our algorithm polynomial with respect to some special topologies: differently from the number of covering sets, the number of proper covering sets is polynomially upper bounded. Hereafter we provide the description of the algorithm.\nLet us denote Ckv,t a collection of proper covering sets, where each set in this collection is denoted as Qkv,t. The proper covering set Q k v,t has cardinality k and admits a covering route r whose starting vertex is v and whose last covered target is t. Each Qkv,t is associated with a cost c(Q k v,t) representing the temporal cost of the shortest covering route for Qkv,t that specifies t as the k\u2013th target to visit. Upon this basic structure, our algorithm iteratively computes proper covering sets collections and costs for increasing cardinalities, that is from k = 1 possibly up to k = |T (s)| including one target at each iteration. Using a dynamic programming approach, we assume to have solved up to cardinality k \u2212 1 and we specify how to complete the task for cardinality k. Detailed steps are reported in Algorithm 1, while in the following we provide an intuitive description. Given Qk\u22121v,t , we can compute a set of targets Q+ (Line 6) that is a subset of T (s) such that for each target t\u2032 \u2208 Q+ the following properties hold:\n\u2022 t\u2032 6\u2208 Qk\u22121v,t ,\n\u2022 if t\u2032 is appended to the shortest covering route for Qk\u22121v,t , it will be visited before d(t\u2032),\n\u2022 the shortest path between t and t\u2032 does not traverse any target t\u2032\u2032 \u2208 T (s) \\ Qk\u22121v,t .\nFunction ShortestPath(G, t, t\u2032) returns the shortest path on G between t and t\u2032. For efficiency, we calculate (in polynomial time) all the shortest paths offline by means of the Floyd\u2013Warshall algorithm [36]. IfQ+ is not empty, for each t\u2032 \u2208 Q+, we extend Qk\u22121v,t (Step 8) by including it and naming the resulting covering set as Qkv,t\u2032 since it has cardinality k and we know it admits a covering route with last vertex t\u2032. Such route can be obtained by appending t\u2032 to the covering route for Qk\u22121v,t and has cost c(Q k\u22121 v,t ) + \u03c9 \u2217 t,t\u2032 . This value is assumed to be the cost of the extended proper covering set.\u2014In Step 9, we make use of a procedure called Search(Q,C) where Q is a covering set and C is a collection of covering sets. The procedure outputs Q if Q \u2208 C and \u2205 otherwise. We adopted an efficient implementation of such procedure which can run in O(|T (s)|). More precisely, we represent a covering set Q as a binary vector of length |T (s)| where the i\u2013th component is set to 1 if target ti \u2208 Q and 0 otherwise. A collection of covering sets C can then be represented as a binary tree with depth |T (s)|. The membership of a covering set Q to collection C is represented with a branch of the tree in such a way that if ti \u2208 Q then we have a left edge at depth i \u2212 1 on such branch. We can easily determine if Q \u2208 C by checking if traversing a left (right) edge in the tree each time we read a 1 (0) in Q\u2019s binary vector we reach a leaf node at depth |T (s)|. The insertion of a new covering set in the collection can be done in the same way by traversing existing edges and expanding the tree where necessary.\u2014 If such extended proper covering set is not present in collection Ckv,t\u2032 or is already present with a higher cost (Step 10), then collection and cost are updated (Steps 11 and 12). After the iteration for cardinality k is completed, for each proper covering set Q in collection Ckv,t, c(Q) represents the temporal cost of the shortest covering route with t as last target.\nAfter Algorithm 1 completed its execution, for any arbitrary T \u2032 \u2286 T we can easily obtain the temporal cost of its shortest covering route as\nc\u2217(T \u2032) = min Q\u2208Y|T \u2032| c(Q)\nAlgorithm 1 DP\u2013ComputeCovSets(v, s) 1: \u2200t \u2208 T (s), k \u2208 {2, . . . , |T (s)|}: C1v,t = { {t} if (v, t) \u2208 ER \u2205 otherwise , Ckv,t = \u2205\n2: \u2200t \u2208 T (s): c({t}) = { \u03c9\u2217v,t if C 1 v,t 6= \u2205\n\u221e otherwise , c(\u2205) =\u221e\n3: for all k \u2208 {2 . . . |T (s)|} do 4: for all t \u2208 T (s) do 5: for all Qk\u22121v,t \u2208 Ck\u22121v,t do 6: Q+ = { t\u2032 \u2208 T (s) \\Qk\u22121v,t : ( c(Qk\u22121v,t ) + \u03c9 \u2217 t,t\u2032 \u2264 d(t \u2032) ) \u2227 ( 6 \u2203t\u2032\u2032 \u2208 T (s) \\Q : t\u2032\u2032 \u2208 ShortestPath(G, t, t\u2032)\n)} 7: for all t\u2032 \u2208 Q+ do 8: Qk\nv,t\u2032 = Q k\u22121 v,t \u222a {t\u2032}\n9: U = Search(Qk v,t\u2032 , C k v,t\u2032 ) 10: if c(U) > c(Qk\u22121v,t ) + \u03c9\u2217t,t\u2032 then 11: Ck\nv,t\u2032 = C k v,t\u2032 \u222a {Q k v,t\u2032}\n12: c(Qk v,t\u2032 ) = c(Q k\u22121 v,t ) + \u03c9 \u2217 t,t\u2032 13: end if 14: end for 15: end for 16: end for 17: end for 18: return {Ckv,t : t \u2208 T (s), k \u2264 |T (s)|}\nwhere Y|T \u2032| = \u222at\u2208T{Search(T \u2032, C |T \u2032|\nv,t )} (notice that if T \u2032 is not a covering set then c\u2217(T \u2032) = \u221e). For the sake of simplicity, Algorithm 1 does not specify how to carry out two sub\u2013tasks we describe in the following.\nThe first one is the annotation of dominated (proper) covering sets. Each time Steps 11 and 12 are executed, a covering set is added to some collection. Let us call it Q and assume it has cardinality k. Each time a new Q has to be included at cardinality k, we mark all the covering sets at cardinality k\u22121 that are dominated by Q (as per Definition 5). The number of sets that can be dominated is in the worst case |Q| since each of them has to be searched in collection Ck\u22121v,t for each feasible terminal t and, if found, marked as dominated. The number of terminal targets and the cardinality of Q are at most n and, as described above, the Search procedure takes O(|T (s)|). Therefore, dominated (proper) covering sets can be annotated with a O(|T (s)|3) extra cost at each iteration of Algorithm 1. We can only mark and not delete dominated (proper) covering sets since they can generate non\u2013dominated ones in the next iteration.\nThe second task is the generation of routes. Algorithm 1 focuses on proper covering sets and does not maintain a list of corresponding routes. In fact, to build the payoffs matrix for SRG\u2013v we do not strictly need covering routes since covering sets would suffice to determine payoffs. However, we do need them opera-\ntively sinceD should know in which order targets have to be covered to physically play an action. This task can be accomplished by maintaining an additional list of routes where each route is obtained by appending terminal vertex t\u2032 to the route stored for Qk\u22121v,t when set Q k\u22121 v,t \u222a {t\u2032} is included in its corresponding collection. At the end of the algorithm only routes that correspond to non\u2013dominated (proper) covering sets are returned. Maintaining such a list introduces a O(1) cost.\nTheorem 6 The worst\u2013case complexity of Algorithm 1 is O(|T (s)|22|T (s)|) since it has to compute proper covering sets up to cardinality |T (s)|. With annotations of dominances and routes generation the whole algorithm yields a worst\u2013case complexity of O(|T (s)|52|T (s)|)."}, {"heading": "3.2.2. Approximation algorithm", "text": "The dynamic programming algorithm presented in the previous section cannot be directly adopted to approximate the maximal covering routes. We notice that even in the case we introduce a logarithmic upper bound over the size of the covering sets generated by Algorithm 1, we could obtain a number of routes that is O(2log\n2(|T (s)|)), and therefore exponential. Thus, our goal is to design a polynomial\u2013time algorithm that generates a polynomial number of good covering routes. We observe that if we have a total order over the vertices and we work over the complete graph of the targets where each edge corresponds to the shortest path, we can find in polynomial time the maximal covering routes subject to the constraint that, given any pair of targets t, t\u2032 in a route, t can precede t\u2032 in the route only if t precedes t\u2032 in the order. We call monotonic a route satisfying a given total order. Algorithm 2 returns the maximal monotonic covering routes when the total order is lexicographic (trivially, in order to change the order, it is sufficient to re\u2013label the targets).\nAlgorithm 2 is based on dynamic programming and works as follows. R(k, l) is a matrix storing in each cell one route, while L(k, l) is a matrix storing in each cell the maximum lateness of the corresponding route, where the lateness associated with a target t is the difference between the (first) arrival time at t along r and d(t) and the maximum lateness of the route is the maximum lateness of the targets covered by the route. The route stored in R(k, l) is the one with the minimum lateness among all the monotonic ones covering l targets where tk is the first visited target. Thus, basically, when l = 1, R(k, l) contains the route \u3008v, tk\u3009, while, when l > 1, R(k, l) is defined appending to R(k, 1) the best (in terms of minimizing the maximum lateness) route R(k\u2032, l\u2212 1) for every k\u2032 > k, in order to\nsatisfy the total order. The whole set of routes in R are returned.7 The complexity of Algorithm 2 is O(|T (s)|3), except the time needed to find all the shortest paths.\nAlgorithm 2 MonotonicLongestRoute(v, s) 1: \u2200k, k\u2032 \u2208 {1, 2, . . . , |T (s)|}, R(k, k\u2032) = \u2205, L(k, k\u2032) = +\u221e, CR(k) = \u2205, CL(k) = +\u221e 2: for all \u2200k \u2208 {|T (s)|, |T (s)| \u2212 1, . . . , 1} do 3: for all \u2200l \u2208 {1, 2, . . . , |T (s)|} do 4: if l = 1 then 5: R(k, l) = \u3008v, tk\u3009 6: L(k, l) = w\u2217v,tk \u2212 d(tk) 7: else 8: for all k\u2032 s.t. |T (s)| \u2265 k\u2032 > |T (s)| \u2212 k do 9: CR(k\u2032) = \u3008R(k, 1), R(k\u2032, l \u2212 1)\u3009 10: CL(k\u2032) = max{L(k, 1), w\u2217v,tk + w \u2217 tk,k \u2032 \u2212 w\u2217v,k\u2032 + L(k \u2032, l \u2212 1)} 11: end for 12: j = argminj{CL(j)} 13: if CL(j) \u2264 0 then 14: R(k, l)\u2190 CR(j) 15: L(k, l)\u2190 CL(j) 16: end if 17: end if 18: end for 19: end for 20: return R\nWe use different total orders over the set of targets, collecting all the routes generated using each total order. The total orders we use are (where ties are broken randomly):\n\u2022 increasing order w\u2217v,t: the rationale is that targets close to v will be visited before targets far from v;\n\u2022 increasing order dv,t: the rationale is that targets with short deadlines will be visited before targets with long deadlines;\n\u2022 increasing order dv,t \u2212 w\u2217v,t: the rationale is that targets with short excess time will be visited before targets with long excess time.\nIn addition, we use a sort of random restart, generating random permutations over the targets.\nTheorem 7 Algorithm 2 provides an approximation with ratio \u2126( 1|T (s)|).\n7We notice that dominance can be applied to discard dominated routes. However, in this case, the improvement would be negligible since the total number of routes, including the non\u2013 dominated ones, is polynomial.\nProof sketch. The worst case for the approximation ratio of our algorithm occurs when the covering route including all the targets exists and each covering route returned by our heuristic algorithm visits only one target. In that case, the optimal expected utility of D is 1. Our algorithm, in the worst case in which \u03c0(t) = 1 for every target t, returns an approximation ratio \u2126( 1|T (s)|). It is straightforward to see that, in other cases, the approximation ratio is larger."}, {"heading": "3.3. Branch\u2013and\u2013bound algorithms", "text": "The dynamic programming algorithm presented in the previous section essentially implements a breadth\u2013first search. In some specific situations, depth\u2013first search could outperform breadth\u2013first search, e.g., when penetration times are relaxed and good heuristics lead a depth\u2013first search to find in a brief time the maximal covering route, avoiding to scan an exponential number of routes as the breadth\u2013first search would do. In this section, we adopt the branch\u2013and\u2013bound approach to design both an exact algorithm and an approximation algorithm. In particular, in Section 3.3.1 we describe our exact algorithm, while in Section 3.3.2 we present the approximation one."}, {"heading": "3.3.1. Exact algorithm", "text": "Our branch\u2013and\u2013bound algorithm (see Algorithm 3) is a tree\u2013search based algorithm working on the space of the covering routes and returning a set of covering routes R. It works as follows.\nInitial step. We exploit two global set variables, CLmin and CLmax initially set to empty (Steps 1\u20132 of Algorithm 3). These variables contain closed covering routes, namely covering routes which cannot be further expanded without violating the penetration time of at least one target during the visit. CLmax contains the covering routes returned by the algorithm (Step 8 of Algorithm 3), while CLmin is used for pruning as discussed below. The update of CLmin and CLmax is driven by Algorithm 5, as discussed below. Given a starting vertex v and a signal s, for each target t \u2208 T (s) such that w\u2217v,t \u2264 d(t) we generate a covering route r with r(0) = v and r(1) = t (Steps 1\u20133 of Algorithm 3). Thus, D has at least one covering route per target that can be covered in time from v. Notice that if, for some t, such minimal route does not exist, then target t cannot be covered because we assume triangle inequality. This does not guarantee that A will attack t with full probability since, depending on the values \u03c0, A could find more profitable to randomize over a different set of targets. The meaning of parameter \u03c1 is described below.\nAlgorithm 3 Branch\u2013and\u2013Bound(v, s, \u03c1) 1: CLmax \u2190 \u2205 2: CLmin \u2190 \u2205 3: for all t \u2208 T (s) do 4: if w\u2217v,t \u2264 d(t) then 5: Tree\u2013Search(d\u03c1 \u00b7 |T (s)|e, \u3008v, t\u3009) 6: end if 7: end for 8: return CLmax\nRoute expansions. The subsequent steps essentially evolve on each branch according to a depth\u2013first search with backtracking limited by \u03c1 (Step 4 of Algorithm 3). The choice of \u03c1 directly influences the behavior of the algorithm and consequently its complexity. Each node in the search tree represents a route r built so far starting from an initial route \u3008v, t\u3009. At each iteration, route r is expanded by inserting a new target at a particular position. We denote with r+(q, p) the route obtained by inserting target q after the p\u2013th target in r. Notice that every expansion of r will preserve the relative order with which targets already present in r will be visited. The collection of all the feasible expansions r+s (i.e., the ones that are covering routes) is denoted by R+ and it is ordered according to a heuristic that we describe below. Algorithm 6, described below, is used to generate R+ (Step 1 of Algorithm 4). In each open branch (i.e.,R+ 6= \u2205), if the depth of the node in the tree is smaller or equal to d\u03c1 \u00b7 |T (s)|e then backtracking is disabled (Steps 7\u201311 of Algorithm 4), while, if the depth is larger than such value, is enabled (Steps 5\u20136 of Algorithm 4). This is equivalent to fix the relative order of the first (at most) d\u03c1 \u00b7 |T (s)|e inserted targets in the current route. In this case, with \u03c1 = 0 we do not rely on the heuristics at all, full backtracking is enabled, the tree is fully expanded and the returned R is complete, i.e., it contains all the non\u2013dominated covering routes. Route r is repeatedly expanded in a greedy fashion until no insertion is possible. As a result, Algorithm 4 generates at most |T (s)| covering routes.\nPruning. Algorithm 5 is in charge of updating CLmin and CLmax each time a route r cannot be expanded and, consequently, the associated branch must be closed. We call CLmin the minimal set of closed routes. This means that a closed route r belongs to CLmin only if CLmin does not already contain another r\u2032 \u2286 r. Steps 1\u20136 of Algorithm 5 implement such condition: first, in Steps 2\u20133 any route r\u2032 such that r\u2032 \u2287 r is removed from CLmin, then route r is inserted in CLmin. Routes in CLmin are used by Algorithm 6 in Steps 2 and 6 for pruning during the search. More precisely, a route r is not expanded with a target q at position p if there exists a route r\u2032 \u2208 CLmin such that r\u2032 \u2286 r+(q, p). This pruning rule\nAlgorithm 4 Tree\u2013Search(k, r) 1: R+ = {r(1), r(2), . . .} \u2190 Expand(r) 2: if R+ = \u2205 then 3: Close(r) 4: else 5: if k > 0 then 6: Tree\u2013Search(k \u2212 1, r(1)) 7: else 8: for all r+ \u2208 R+ do 9: Tree\u2013Search(0, r+) 10: Close(r+) 11: end for 12: end if 13: end if\nis safe since by definition if r\u2032 \u2208 CLmin, then all the possible expansions of r\u2032 are unfeasible and if r\u2032 \u2286 r then r can be obtained by expanding from r\u2032. This pruning mechanism explains why once a route r is closed is always inserted in CLmin without checking the insertion against the presence in CLmin of a route r\u2032\u2032 such that r\u2032\u2032 \u2286 r. Indeed, if such route r\u2032\u2032 would be included in CLmin we would not be in the position of closing r, having r being pruned before by Algorithm 6 in Step 2 or Step 8.\nWe use CLmax to maintain a set of the generated maximal closed routes. This means that a closed route r is inserted here only ifCLmax does not already contain another r\u2032 such that r\u2032 \u2287 r. This set keeps track of closed routes with maximum number of targets. Algorithm 5 maintains this set by inserting a closed route r in Step 12 only if no route r\u2032 \u2287 r is already present in CLmax. Once the whole algorithm terminates, CLmax contains the final solution.\nAlgorithm 5 Close(r) 1: for all r\u2032 \u2208 CLmin do 2: if r \u2286 r\u2032 then 3: CLmin = CLmin \\ {r\u2032} 4: end if 5: end for 6: CLmin = CLmin \u222a {r} 7: for all r\u2032 \u2208 CLmax do 8: if r \u2286 r\u2032 then 9: return 10: end if 11: end for 12: CLmax = CLmax \u222a {r}\nHeuristic function. A key component of this algorithm is the heuristic function that drives the search. The heuristic function is defined as hr : {T (s)\\T (r)}\u00d7\n{1 . . . |T (r)|} \u2192 Z, where hr(t\u2032, p) evaluates the cost of expanding r by inserting target t\u2032 after the p\u2013th target of r. The basic idea, inspired by [37], is to adopt a conservative approach, trying to preserve feasibility. Given a route r, let us define the possible forward shift of r as the minimum temporal margin in r between the arrival at a target t and d(t):\nPFS(r) = mint\u2208T (r)(d(t)\u2212 Ar(t)) The extra mileage er(t\u2032, p) for inserting target t\u2032 after position p is the addi-\ntional traveling cost to be paid:\ner(t \u2032, p) = (Ar(r(t \u2032)) + \u03c9\u2217r(p),t\u2032 + \u03c9 \u2217 t\u2032,r(p+1))\u2212 Ar(r(p+ 1))\nThe advance time that such insertion gets with respect to d(t\u2032) is defined as:\nar(t \u2032, p) = d(t\u2032)\u2212 (Ar(r(p)) + \u03c9\u2217r(p),t\u2032)\nFinally, hr(t\u2032, p) is defined as:\nhr(t \u2032, p) = min{ar(t\u2032, p); (PFS(r)\u2212 er(t\u2032, p))}\nWe partition the set T (s) in two sets Ttight and Tlarge where t \u2208 Ttight if d(t) < \u03b4 \u00b7 \u03c9\u2217v,t and t \u2208 Tlarge otherwise (\u03b4 \u2208 R is a parameter). The previous inequality is a non\u2013binding choice we made to discriminate targets with a tight penetration time from those with a large one. Initially, we insert all the tight targets and only subsequently we insert the non\u2013tight targets. We use the two sets according to the following rules (see Algorithm 6):\n\u2022 the insertion of a target belonging to Ttight is always preferred to the insertion of a target belonging to Tlarge, independently of the insertion position;\n\u2022 insertions of t \u2208 Ttight are ranked according to h considering first the insertion position and then the target;\n\u2022 insertions of t \u2208 Tlarge are ranked according to h considering first the target and then the insertion position.\nThe rationale behind this rule is that targets with a tight penetration time should be inserted first and at their best positions. On the other hand, targets with a large penetration time can be covered later. Therefore, in this last case, it is less important which target to cover than when to cover it.\nTheorem 8 Algorithm 3 with \u03c1 = 0 is an exact algorithm and has an exponential computational complexity since it builds a full tree of covering routes with worst\u2013 case size O(|T (s)||T (s)|).\nAlgorithm 6 Expand(r) 1: if Ttight * T (r) then 2: for all q \u2208 Ttight \\ T (r) do\nPq = { p(1)q , p (2) q , . . . p (b) q } s.t. \u2200i \u2208 {1, . . . , b},  hr(q, p (i) q ) \u2265 hr(q, p (i+1) q ) r+(q, p (i) q ) is a covering route\n6 \u2203v\u2032 \u2208 CLmin : r\u2032 \u2286 r+(q, p (i) q )\n3: end for 4: Q = {q(1), q(2), . . . , q(c)} s.t. \u2200i \u2208 {1, . . . , c}, hr(q(i), p(1)\nq(i) ) \u2265 hr(q(i+1), p(1) q(i+1) )\n5: R+ = {r(1), r(2), . . . r(k)} where  r(1) = r+(q(1), p (1) q(1) ) \u00b7 \u00b7 \u00b7 = \u00b7 \u00b7 \u00b7 r(k) = r+(q(c), p (b)\nq(c) )\n6: end if 7: if Tlarge * T (r) then 8: for all u \u2208 Tlarge \\ T (r) do\nQp = { q(1)p , q (2) p , . . . q (b) p } s.t. \u2200i \u2208 {1, . . . , b},  hr(q (i) p , p) \u2265 hr(q (i+1) p , p) r+(q (i) p , p) is a covering route\n6 \u2203 r\u2032 \u2208 CLmin : r\u2032 \u2286 r+(q (i) p , p)\n9: end for 10: P = {p(1), p(2), . . . , p(c)} s.t. \u2200i \u2208 {1, . . . , c}, hr(q(1), p(i)\nq(1) ) \u2265 hr(q(1), p(i+1) q(1) )\n11: R+ = R+ \u222a {r(k+1), r(k+2), . . . r(K)} where  r(k+1) = r+(q (1) p , p (1)) \u00b7 \u00b7 \u00b7 = \u00b7 \u00b7 \u00b7 r(K) = r+(q (b) p , p (c)) 12: end if 13: return R+"}, {"heading": "3.3.2. Approximation algorithm", "text": "Since \u03c1 determines the completness degree of the generated tree, we can exploit Algorithm 3 tuning \u03c1 to obtain an approximation algorithm that is faster w.r.t. the exact one.\nIn fact, when \u03c1 < 1 completeness is not guaranteed in favour of a less computational effort. In this case, the only guarantees that can be provided for each covering route r \u2208 CLmax, once the algorithm terminates are:\n\u2022 no other r\u2032 \u2208 CLmax dominates r;\n\u2022 no other r\u2032 /\u2208 CLmax such that r \u2286 r\u2032 dominates r. Notice this does not prevent the existence of a route r\u2032\u2032 not returned by the algorithm that visits targets T (r) in a different order and that dominates r.\nWhen \u03c1 is chosen as k|T (s)| (where k \u2208 N is a parameter), the complexity of generating covering routes becomes polynomial in the size of the input. We can state the following theorem, whose proof is analogous to that one of Theorem 7.\nTheorem 9 Algorithm 4 with \u03c1 = k|T (s)| provides an approximation with ratio \u2126( 1|T (s)|) and runs in O(|T (s)| 3) given that heuristic hr can be computed in O(|T (s)|2)."}, {"heading": "3.4. Solving SRG\u2013v", "text": "Now we can formulate the problem of computing the optimal signal\u2013response strategy forD. Let us denote with \u03c3Dv,s(r) the probability with whichD plays route r under signal s and with Rv,s the set of all the routes available to D generated by some algorithm. We introduce function UA(r, t), representing the utility function of A and defined as follows:\nUA(r, t) = { \u03c0(t) if t 6\u2208 r 0 otherwise .\nThe best D strategy (i.e., the maxmin strategy) can be found by solving the following linear mathematical programming problem:\nmin gv s.t.\u2211 s\u2208S(t) p(s | t) \u2211 r\u2208Rv,s \u03c3Dv,s(r)UA(r, t) \u2264 gv \u2200t \u2208 T\u2211\nr\u2208Rv,s \u03c3Dv,s(r) = 1 \u2200s \u2208 S\n\u03c3Dv,s(r) \u2265 0 \u2200r \u2208 Rv,s, s \u2208 S The size of the mathematical program is composed of |T | + |S| constraints (excluded \u2265 0 constraints) and O(|V ||S|maxv,s{|Rv,s|}) variables. This shows that the hardness is due only to maxv,s{|Rv,s|}, which, in its turn, depends only on |T (s)|. We provide the following remark.\nRemark 3 We observe that the discretization of the environment as a graph is as accurate as the number of vertices is large, corresponding to reduce the size of the areas associated with each vertex, as well as to reduce the temporal interval associated with each turn of the game. Our algorithms show that increasing the accuracy of the model in terms of number of vertices requires polynomial time."}, {"heading": "4. SRG\u2013v on special topologies", "text": "In this section, we focus on special topologies, showing in Section 4.1 the topologies with which solving a SRG\u2013v is computationally easy, those that are hard in Section 4.2, and the topologies for which the problem remains open in Section 4.3."}, {"heading": "4.1. Easy topologies", "text": "In this section, we show that, with some special topologies, there exists an efficient algorithm to solve exactly the SRG\u2013v. Let us consider a linear graph. An example is depicted in Figure 4. We state the following theorem.\nTheorem 10 There is a polynomial\u2013time algorithm solving OPT\u2013SRG\u2013v with linear graphs.\nProof. We show that Algorithm 1 requires polynomial time in generating all the pure strategies of D. The complexity of Algorithm 1, once applied to a given instance, depends on the number of proper covering sets (recall Definition 10). It can be shown that linear graphs have a polynomial number of proper covering sets. Given a starting vertex v, any proper covering set Q can be characterized by two extreme targets of Q, the first being the farthest from v on the left of v (if any, and v otherwise) and the second being the farthest from v on the right of v (if any, and v otherwise). For example, see Figure 4, given proper covering set Q = {t1, t2, t3}, the left extreme is t1 and the right extreme is t3. Therefore, the number of proper covering sets for each pair v, s is O(|T (s)|2). Since the actions available to D are polynomially upper bounded, the time needed to compute the maxmin strategy is polynomial.\nLet us consider a cycle graph. An example is depicted in Figure 5. We can state the following theorem.\nTheorem 11 There is a polynomial\u2013time algorithm solving OPT\u2013SRG\u2013v with cycle graphs (perimeters).\nProof. The proof is analogous to that one of linear graphs. That is, each proper covering set can be characterized by two extremes: the left one and the right one. For example, see Figure 5, given proper covering set Q = {t1, t2, t4, t5, t6, t7}, the left extreme is t4 and the right extreme is t2. As in linear graphs, the number of proper covering sets in a cycle graph is O(|T (s)|2).\nThe above results can be generalized to the case of tree graphs where the number of leaves is fixed. We can state the following theorem.\nTheorem 12 There is a polynomial\u2013time algorithm solving OPT\u2013SRG\u2013v with tree graphs where the number of leaves is fixed.\nProof. The proof is analogous to those of linear and cycle graphs. Here, each proper covering set can be characterized by a tuple of extremes, one for each path connecting v to a leaf. The number of proper covering sets is O(|T (s)|n) where n is the number of leaves of the tree.\nThe above results show that Questions 2\u20134 are solvable in polynomial time with the above special topologies. We show in the next section that when the number of leaves in a tree is not fixed, the problem becomes hard. Finally, we provide a remark to the above theorem.\nRemark 4 We already showed that, given an arbitrary topology, scaling the graph by introducing new vertices is possible with a polynomial\u2013time cost. Theorem 12 shows that with tree\u2013based graphs this holds even when we introduce new targets."}, {"heading": "4.2. Hard topologies", "text": "Let us consider a special topology, as shown in Figure 6 and defined in the following.\nDefinition 11 (S2L\u2013STAR) Special 2\u2013level star graph instances (S2L\u2013STAR) are:\n\u2022 V = {v0, v1, v2, . . . , v2n}, where v0 is the starting position;\n\u2022 T = V \\{v0}, where vertices vi with i \u2208 {1, . . . , n} are called inner targets, while vertices vi with i \u2208 {n+ 1, . . . , 2n} are called outer targets;\n\u2022 E = {(v0, vi), (vi, vn+i) : \u2200i \u2208 {1, . . . , n}} and we call i\u2013th branch the pair of edges ((v0, vi), (vi, vn+i));\n\u2022 travel costs are c(v0, vi) = c(vi, vn+i) = \u03b3i for every i \u2208 {1, . . . , n}, where \u03b3i \u2208 N+;\n\u2022 penetration times are, for i \u2208 {1, . . . , n}, d(t) = { 6H \u2212 3\u03b3i t = vi 10H \u2212 2\u03b3i, t = vn+i ,\nwhere H = \u2211n\ni=1 \u03b3i 2 ;\n\u2022 \u03c0(t) = 1 for every t \u2208 T .\nInitially, we show a property of S2L\u2013STAR instances that we shall use below.\nLemma 13 If an instance of S2L\u2013STAR admits a maximal covering route r that covers all the targets, then the branches can be partitioned in two sets C1 and C2 such that:\n\u2022 all the branches in C1 are visited only once while all the branches in C2 are visited twice, and\n\u2022 \u2211 i\u2208C1 \u03b3i = \u2211 i\u2208C2 \u03b3i = H .\nProof. Initially, we observe that, in a feasible solution, the visit of a branch can be of two forms. If branch i is visited once, thenD will visit the inner target before time 6H \u2212 3\u03b3i and immediately after the outer target. C1 denotes the set of all the branches visited according to this form. If branch i is visited twice, then D will visit at first the inner target before time 6H \u2212 3\u03b3i, coming back immediately after to v0, and subsequently in some time after 6H\u22123\u03b3i, but before 10H\u22122\u03b3i,D will visit again the inner target and immediately after the outer target. C2 denotes the set of all the branches that are visited according to this form. All the other forms of visits (e.g., three or more visits, different order visits, and visits at different times) are useless and any route in which some branch is not neither in C1 nor in C2 can be modified such that all the branches are either in C1 or in C2 strictly decreasing the cost of the solution as follows:\n\u2022 if branch i is visited only once and the visit of the inner target is after time 6H \u2212 3\u03b3i, then the solution is not feasible;\n\u2022 if branch i is visited twice and the first visit of the inner target is after time 6H \u2212 3\u03b3i, then the solution is not feasible;\n\u2022 if branch i is visited twice and the second visit of the inner target is before time 6H \u2212 3\u03b3i, then the first visit of the branch can be omitted saving 2\u03b3i;\n\u2022 if branch i is visited twice and the outer target is visited during the first visit, then the second visit of the branch can be omitted saving \u2265 2\u03b3i;\n\u2022 if branch i is visited three or more times, all the visits except the first one in\nwhich the inner target is visited and the first one in which the outer target is visited can be omitted saving \u2265 2\u03b3i.\nWe assume that, if there is a maximal covering route r that covers all the targets, then the visits are such that C1 \u222a C2 = {1, . . . , n} and therefore that each branch is visited either once or twice as discussed above. We show below that in S2L\u2013STAR instances such an assumption is always true. Since r covers all the targets, we have that the following conditions are satisfied:\n2 \u2211 i\u2208C2 \u03b3i + 4 \u2211 i\u2208C1 \u03b3i \u2264 6H (1)\n6 \u2211 i\u2208C2 \u03b3i + 4 \u2211 i\u2208C1 \u03b3i \u2264 10H (2)\nConstraint (1) requires that the cost of visiting entirely all the branches in C1 and partially (only the inner target) all the branches in C2 is not larger than the penetration times of the inner targets. Notice that this holds only when the last inner target is first\u2013visited on a branch inC1. We show below that such assumption is always verified. Constraint (2) requires that the cost of visiting entirely all the branches in C1 and at first partially and subsequently entirely all the branches in C2 is not larger than the penetration times of the outer targets. We can simplify the above pair of constraints as follows:\n2 \u2211 i\u2208C2 \u03b3i + 2 \u2211 i\u2208C1\n\u03b3i\ufe38 \ufe37\ufe37 \ufe38 4H\n+2 \u2211 i\u2208C1 \u03b3i \u2264 6H\n2 \u2211 i\u2208C2 \u03b3i + 4 \u2211 i\u2208C2 \u03b3i + 4 \u2211 i\u2208C1\n\u03b3i\ufe38 \ufe37\ufe37 \ufe38 8H\n\u2264 10H\nobtaining: \u2211 i\u2208C1\n\u03b3i \u2264 H\u2211 i\u2208C2 \u03b3i \u2264 H\nsince, by definition, \u2211 i\u2208C1 \u03b3i + \u2211\ni\u2208C2 \u03b3i = 2H , it follows that:\u2211 i\u2208C1 \u03b3i = \u2211 i\u2208C2 \u03b3i = H.\nTherefore, if r covers all the targets and it is such that all the branches belong either to C1 or to C2, we have that r visits the last outer target exactly at its penetration time. This is because Constraints (1) and (2) hold as equalities. Thus, as shown above, in any route in which a branch is not neither in C1 nor in C2 we can change the visits such that all the branches are in either C1 or C2, strictly reducing the total cost. It follows that no route with at least one branch that is not neither in C1 nor in C2 can have a total cost equal to or smaller than the penetration time of the outer targets. Similarly, from the above equality it follows that any solution where the last inner target is first\u2013visited on a C2 branch can be strictly improved by moving such branch to C1 and therefore no route in which the last inner target is first\u2013visited on a C2 branch can have a total cost equal to or smaller than the penetration time of the outer targets.\nDefinition 12 (PARTITION) The decision problem PARTITION is defined as: INSTANCE: A finite set I = {1, 2, . . . , l}, a size ai \u2208 N+ for each i \u2208 I , and a bound B \u2208 N+ such that \u2211 i\u2208I ai = 2B.\nQUESTION: Is there any subset I \u2032 \u2286 I such that \u2211 i\u2208I\u2032 ai = \u2211 i\u2208I\\I\u2032 ai = B?\nWe can now state the following theorem:\nTheorem 14 k\u2013SRG\u2013v isNP\u2013hard even when restricted to S2L\u2013STAR instances.\nProof. We provide a reduction from PARTITION that is known to be weaklyNP\u2013 hard. For the sake of clarity, we divide the proof in steps.\nReduction. We map an instance of PARTITION to an instance of k\u2013SRG\u2013v on S2L\u2013STAR graphs as follows\n\u2022 S = {s},\n\u2022 n = l (i.e., the number of branches in S2L\u2013STAR equals the number of elements in PARTITION);\n\u2022 \u03b3i = ai for every i \u2208 I;\n\u2022 H = B,\n\u2022 k = 0.\nThe rationale is that there is a feasible solution for PARTITION if and only if there is the maximal covering route that covers all the targets in a k\u2013SRG\u2013v on a S2L\u2013STAR graph.\nIf. From Lemma 13 we know that, if there is the maximal covering route that covers all the targets in a k\u2013SRG\u2013v on a S2L\u2013STAR graph, then the branches can be partitioned in two sets C1, C2 such that \u2211 i\u2208C1 \u03b3i = \u2211 i\u2208C2 \u03b3i = H . By construction \u03b3i = ai and H = B. So, if there is the maximal covering route that covers all the targets in a k\u2013SRG\u2013v on a S2L\u2013STAR graph, then there is partition of set I in two subsets I \u2032 = C1 and I \u2032\u2032 = C2 such that \u2211 i\u2208C1 \u03b3i = \u2211 i\u2208I\u2032 ai =\nH = B = \u2211 i\u2208C2 \u03b3i = \u2211\ni\u2208I\u2032\u2032 ai. Only if. If PARTITION admits a feasible solution, then, once assigned I \u2032 = C1 and I \u2032\u2032 = C2, it is straightforward to see that the route visits all the targets by their penetration times and therefore that the route is a maximal covering route.\nLet us notice that the above reduction, differently from that of Theorem 1, does not exclude the existence of an FPTAS, i.e., Fully Polynomial Time Approximation Scheme. This may hold since PARTITION admits an FPTAS. Furthermore, we observe that S2L\u2013STAR graphs are special kinds of trees and therefore k\u2013 SRG\u2013v on trees isNP\u2013hard. Finally, we observe that the above result shows that it is unlikely that there is a polynomial\u2013time algorithm solving Questions 1\u20134."}, {"heading": "4.3. Borderline topologies", "text": "Let us consider a star graph, as shown in Figure 7, defined as follows.\nDefinition 13 (SIMPLE\u2013STAR) Simple star graph instances (SIMPLE\u2013STAR) are:\n\u2022 V = {v0, v1, v2, . . . , vn}, where v0 is the starting vertex of D;\n\u2022 T = V \\ {v0};\n\u2022 E = {(v0, vi),\u2200i \u2208 {1, . . . , n}};\n\u2022 travel costs are c(v0, vi) = \u03b3i, where \u03b3i \u2208 N+;\n\u2022 penetration times di and values \u03c0(vi) can be any.\nWe can state the following theorem.\nTheorem 15 If the maximal covering route r covering all the targets exists, the Earliest Due Date algorithm returns r in polynomial time once applied to SIMPLE\u2013 STAR graph instances.\nProof. The Earliest Due Date [38] (EDD) algorithm is an optimal algorithm for synchronous (i.e., without release times) aperiodic scheduling with deadlines. It executes (without preemption) the tasks in ascending order according to the deadlines, thus requiring polynomial complexity in the number of tasks. Any SIMPLE\u2013STAR graph instance can be easily mapped to a synchronous aperiodic scheduling problem: each target ti is an aperiodic task Ji, the computation time of Ji is equal to 2\u03b3i, the deadline of task Ji is d(ti) + \u03b3i. It is straightforward to see that, if EDD returns a feasible schedule, then there is the maximal covering route, and, if EDD returns a non\u2013feasible schedule, then there is not any maximal covering route.\nThe above result shows that Question 2 can be answered in polynomial time. We show that also Question 3 can be answered in polynomial time be means of a simple variation of EDD algorithm.\nTheorem 16 Given a signal s, the best pure strategy of D in an SRG\u2013v game on SIMPLE\u2013STAR graph instances can be found in polynomial time.\nProof. Given a signal s, the algorithm that finds the best pure strategy is a variation of the EDD algorithm. For the sake of clarity, we describe the algorithm in the\nsimplified case in which there is only one signal s. The extension to the general case is straightforward. The algorithm works as follows:\n1. apply EDD,\n2. if the maximal covering route exists, then return it,\n3. else remove the target t with the smallest \u03c0(t) from T (s),\n4. go to Point 1.\nEssentially, the algorithm returns the subset of targets admitting a covering route minimizing the maximum value among all the non\u2013covered targets.\nAlthough the treatment of SIMPLE\u2013STAR graph instances in pure strategies is computationally easy, it is not clear if the treatment keeps being easy when D is not restricted to play pure strategies. We just observe that Algorithm 1 requires exponential complexity, the number of proper covering sets being exponential. Thus, the complexity of solving Questions 1 and 4 remains unaddressed."}, {"heading": "5. Patrolling game", "text": "In this section, we focus on the PG. Specifically, in Section 5.1 we state our main result showing that patrolling is not necessary when an alarm system is present, in Section 5.2 we propose the algorithm to deal with the PG, in Section 5.3 we summarize the complexity results about Questions 1\u20134."}, {"heading": "5.1. Stand still", "text": "We focus on the problem of finding the best patrolling strategy given that we know the best signal\u2013response strategy for each vertex v in which D can place. Given the current vertex of D and the sequence of the last, say n, vertices visited by D (where n is a tradeoff between effectiveness of the solution and computational effort), a patrolling strategy is usually defined as a randomization over the next adjacent vertices [9]. We define v\u2217 = arg minv\u2208V {gv}, where gv is the value returned by the optimization problem described in Section 3.3, as the vertex that guarantees the maximum expected utility toD over all the SRG\u2013vs. We show that the maxmin equilibrium strategy in PG prescribes that D places at v\u2217, waits for a signal, and responds to it.\nTheorem 17 Without false positives and missed detections, if \u2200t \u2208 T we have that |S(t)| \u2265 1, then any patrolling strategy is dominated by the placement in v\u2217.\nProof. Any patrolling strategy different from the placement in v\u2217 should necessarily visit a vertex v\u2032 6= v\u2217. Since the alarm system is not affected by missed detections, every attack will raise a signal which, in turn, will raise a response yielding an utility of gx where x is the current position of D at the moment of the attack. Since A can observe the current position of D before attacking, x = arg maxv\u2208P{gv} where P is the set of the vertices patrolled byD. Obviously, for any P \u2287 {v\u2217} we would have that gx \u2265 gv\u2217 and therefore placing at v\u2217 and waiting for a signal is the best strategy for D.\nThe rationale is that, if the patrolling strategy of D prescribes to patrol a set of vertices, say V \u2032, then, since A can observe the position of D, the best strategy of A is to wait for D being in v\u2032 = arg maxv\u2208V \u2032{gv} and then to attack. Thus, by definition of gv\u2217 , if D leaves v\u2217 to patrol additional vertices the expected utility it receives is no larger than that it receives from staying in v\u2217.\nA deeper analysis of Theorem 17 can show that its scope does include cases where missed detections are present up to a non\u2013negligible extent. For such cases, placement\u2013based strategies keep being optimal even in the case when the alarm systems fails in detecting an attack. We encode the occurrence of this robustness property in the following proposition, which we shall prove by a series of examples.\nProposition 1 There exist Patrolling Games where staying in a vertex, waiting for a signal, and responding to it is the optimal patrolling strategy for D even with a missed detection rate \u03b1 = 0.5.\nProof. The expected utility forD given by the placement in v\u2217 is (1\u2212\u03b1)(1\u2212 gv\u2217), where (1\u2212 \u03b1) is the probability with which the alarm system correctly generates a signal upon an attack and (1 \u2212 gv\u2217) denotes D\u2019s payoff when placed in v\u2217. A non\u2013placement\u2013based patrolling strategy will prescribe, by definition, to move between at least two vertices. From this simple consideration, we observe that an upper bound to the expected utility of any non\u2013placement strategy is entailed by the case where D alternately patrols vertices v\u2217 and v\u22172 , where v\u22172 is the second best vertex in whichD can statically place. Such scenario gives us an upper bound over the expected utility of non\u2013placement strategies, namely 1 \u2212 gv\u22172 . It follows that a sufficient condition for the placement in v\u2217 being optimal is given by the following inequality:\n(1\u2212 \u03b1)(1\u2212 gv\u2217) > (1\u2212 gv\u22172 ). (3)\nTo prove Proposition 1, it then suffices to provide a Patrolling Game instance where Equation 3 holds under some non\u2013null missed detection rate \u03b1. In Fig. 8(a) and Fig. 8(b), we report two of such examples. The depicted settings have unitary edges except where explicitly indicated. For both, without missed detections, the best patrolling strategy is a placement v\u2217 = 4. When allowing missed detections, in Fig. 8(a) it holds that gv\u2217 = 0 and gv\u22172 = 0.75, where v\n\u2217 = 4 and v\u22172 = 1. Thus, by Equation 3, placement v\u2217 = 4 is the optimal strategy for \u03b1 \u2264 0.25. Under the same reasoning scheme, in Fig. 8(b) we have that gv\u2217 = 0 and gv\u22172 = 0.5, making the placement v\u2217 = 4 optimal for any \u03b1 \u2264 0.5.\nIt is reasonable to expect that a similar result holds also for the case with false positives. However, dealing with false positives is much more intricate than handling false negative and requires new models, e.g., D could respond to an alarm signal only with a given probability and with the remaining probability could stay in the current vertex. For this reason, we leave the treatment of false positives and a more accurate treatment of false negatives to future works."}, {"heading": "5.2. Computing the best placement", "text": "Under the absence of false positives and missed detections, Theorem 17 simplifies the computation of the patrolling strategy by reducing it to the problem of finding v\u2217. To such aim, we must solve a SRG\u2013v for each possible starting vertex v and select the one with the maximum expected utility forD. Algorithm 7 depicts the solving algorithm. Function SolveSRG(v) returns the optimal value 1\u2212 gv\u2217 . The complexity is linear in |V |, once gv has been calculated for every v.\nAlgorithm 7 BestPlacement(G, s) 1: U(v)\u2190 0 for every v \u2208 V 2: for all v \u2208 V do 3: U(v)\u2190 SolveSRG(v) 4: end for 5: return max(U)\nSince all the vertices are possible starting points, we should face this hard problem (see Theorem 1) |V | times, computing, for each signal, the covering routes from all the vertices. To avoid this issue, we ask whether there exists an algorithm that in the worst case allows us to consider a number of iterations such that solving the problem for a given starting vertex v could help us finding the solution for another starting vertex v\u2032. In other words, considering a specific set of targets, we wonder whether a solution for COV\u2013SET with starting vertex v can be used to derive, in polynomial time, a solution to COV\u2013SET for another starting vertex v\u2032. This would allow us to solve an exponential\u2013time problem only once instead of solving it for each vertex of the graph. To answer this question, we resort to hardness results for reoptimization, also called locally modified problems [39]. We show that, even if we know all the covering routes from a starting vertex, once we changed the starting vertex selecting an adjacent one, finding the covering routes from the new starting vertex is hard.\nDefinition 14 (LM\u2013COV\u2013ROUTE) A locally modified covering route (LM\u2013COV\u2013 ROUTE) problem is defined as follows: INSTANCE: graph G = (V,E), a set of targets T with penetration times d, two starting vertices v1 and v2 that are adjacent, and a covering route r1 with r1(0) = v1 such that T (r1) = T . QUESTION: is there r2 with r2(0) = v2 and T (r2) = T?\nTheorem 18 LM\u2013COV\u2013ROUTE is NP\u2013complete.\nProof. We divide the proof in two steps, membership and hardness. Membership. Given a YES certificate constitutes by a route, the verification is easy, requiring one to apply the route and check whether each target is visited by its deadline. It requires linear time in the number of targets.\nHardness. Let us consider the Restricted Hamiltonian Circuit problem (RHC) which is known to be NP\u2013complete. RHC is defined as follows: given a graph GH = (VH , EH) and an Hamiltonian path P = \u3008h1, . . . , hn\u3009 forGH such that hi \u2208 VH and (h1, hn) /\u2208 EH , find an Hamiltonian cycle for GH . From such instance of RHC, following the approach of [39], we build the following instance for LM\u2013 COV\u2013ROUTE:\n\u2022 V = VH \u222a {v1, v2, vt};\n\u2022 T = VH \u222a {vt};\n\u2022 E = EH \u222a {(hn, vt), (hi, vs) : i \u2208 {1, . . . , n}};\n\u2022 d(vt) = n+ 1 and d(t) = n for any t \u2208 T with t 6= vt;\n\u2022 wv,v\u2032 =  1 if v = hn, v\u2032 = vt 1 if v = hi, v\u2032 = hj, \u2200i, j \u2208 {1, . . . n} 1 if v = v1, v\u2032 = h1 2 if v = v1, v\u2032 = hn\u22121 \u2265 2 if v = v1, v\u2032 = hi,\u2200i \u2208 {1, . . . n\u2212 2, n} \u2265 2 if v = v1, v\u2032 = vt 2 if v = v2, v\u2032 = h1 1 if v = v2, v\u2032 = hn\u22121 \u2265 2 if v = v2, v\u2032 = hi,\u2200i \u2208 {1, . . . n\u2212 2, n} \u2265 2 if v = v2, v\u2032 = vt ;\n\u2022 r1 = \u3008v1, h1, \u00b7 \u00b7 \u00b7 , hn, vt\u3009.\nBasically, givenGH we introduce three vertices v1, v2, vt, where v1, v2 are adjacent starting vertices and vt is a target. We know the covering routes from v1, and we aim at finding the covering routes from v2. The new starting vertex (v2) is closer to hn\u22121 than the previous one (v1) by 1 and farther from h1 than previous one (v1) by 1. There is no constraint over the distances between the starting vertices and the other targets except that they are larger than or equal to 2. We report in\nFigure 9 an example of the above construction. Notice that by construction, if the maximal covering route r2 with r2(0) = v2 and T (r2) = T exists, then vt must be the last visited target. Route r1 is covering since \u3008h1, . . . , hn\u3009 is a Hamiltonian path for GH . We need to show that route r2 with r2(0) = v2 and T (r2) = T exists if and only if GH admits a Hamiltonian cycle. It can observed that, if r2 exists, then it must be such that r2 = \u3008v2, hn\u22121, . . . , hn, vt\u3009 and therefore \u3008hn\u22121, . . . , hn\u3009 must be a Hamiltonian path for GH . Since we know, by r1, that (hn\u22121, hn) \u2208 EH , it follows that \u3008hn\u22121, . . . , hn, hn\u22121\u3009 is a Hamiltonian cycle. This concludes the proof.\nThis shows that iteratively applying Algorithm 1 to SRG\u2013v for each starting vertex v and then choosing the vertex with the highest utility is the best we can do in the worst case."}, {"heading": "5.3. Summary of results", "text": "We summarize our computational results about Questions 1\u20134 in Table 1, including also results about the resolution of the PG. We use \u2018?\u2019 for the problems remained open in this paper."}, {"heading": "6. Experimental evaluation", "text": "In this section, we experimentally evaluate our algorithms. We implemented our algorithms in MATLAB and we used a 2.33GHz LINUX machine to run our\nexperiments. For a better analysis, we provide two different experimental evaluations. In Section 6.1, we apply our algorithms to worst\u2013case instances suggested by our NP\u2013hardness reduction, in order to evaluate the worst\u2013case performance of the algorithms and to investigate experimentally the gap between our APX\u2013 hardness result and the theoretical guarantees of our approximation algorithms. In Section 6.2, we apply our algorithms to a specific realistic instance we mentioned in Section 1, Expo 2015."}, {"heading": "6.1. Worst\u2013case instances analysis", "text": "We evaluate the scalability of Algorithm 1 and the quality of the solution returned by our approximation algorithms for a set of instances of SRG\u2013v. We do not include results on the evaluation of the algorithm to solve completely a PG, given that it trivially requires asymptotically |V | times the effort required by the resolution of a single instance of SRG\u2013v. In the next section we describe our experimental setting, in Section 6.1.2 we provide a quantitative analysis of the exact algorithms while in Section 6.1.3 we evaluate the quality of our approximations."}, {"heading": "6.1.1. Setting", "text": "As suggested by the proof of Theorem 2, we can build hard instances for our problem from instances of HAMILTONIAN\u2013PATH. More precisely, our worst\u2013 case instances are characterized by:\n\u2022 all the vertices are targets,\n\u2022 edge costs are set to 1,\n\u2022 there is only one signal,\n\u2022 penetration times are set to |T | \u2212 1,\n\u2022 values are drawn from (0, 1] with uniform probability for all the targets,\n\u2022 the number of edges is drawn from a normal distribution with mean , said edge density and defined as = |E|/ |T |(|T |\u22121)\n2 , and\n\u2022 starting vertex v is drawn among the targets of T with uniform probability.\nWe explore two parameter dimensions: the number of targets |T | and the value of edge density . In particular, we use the following values:\n|T | \u2208 {6, 8, 10, 12, 14, 16, 20, 25, 30, 35, 40, 45, 50}, \u2208 {0.05, 0.10, 0.25, 0.50, 0.75, 1.00}.\nFor each combination of values of |T | and , we randomly generate 100 instances with the constraint that, if |T | 2\n2 < |T |, we introduce additional edges in order to\nassure the graph connectivity. The suitability of our worst\u2013case analysis is corroborated by the results obtained with a realistic setting (see Section 6.2) which present hard subproblems characterized by the features listed above."}, {"heading": "6.1.2. Exact algorithms scalability", "text": "We report in Figure 10 the compute time (averaged over 100 SRG\u2013v instances) required by our exact dynamic programming algorithm (Algorithm 1), with the annotation of dominated (proper) covering sets and the generation of the routes, as |T | and vary. We report in Appendix B, the boxplots showing the statistical significance of the results. It can be observed that the compute times are exponential in |T |, the curves being lines in a semilogarithmic plot, and the value of determines the slope of the line. Notice that with \u2208 {0.05, 0.10, 0.25} the number of edges is almost the same when |T | \u2264 16 due to the constraint of connectivity of the graph, leading thus to the same compute times. Beyond 16 targets, the compute times of our exact dynamic programming algorithm are excessively long (with only = 0.25, the compute time when |T | = 20 is lower than104 seconds). Interestingly, the compute time monotonically decreases as decreases. This is thanks to the fact that the number of proper covering sets dramatically reduces as reduces and that Algorithm 1 enumerates only the proper covering sets.\nWe do not report any plot of the compute times of our exact branch\u2013and\u2013bound algorithm, since it requires more than 104 seconds when |T | > 8 even with =\n0.25, resulting thus non\u2013applicable in practice. This is because the branch\u2013and\u2013 bound algorithm has a complexity O(|T ||T |), while the dynamic programming algorithm has a complexity O(2|T |).\nFigure 11 shows the impact of discarding dominated actions from the game when = 0.25. It depicts the trend of some performance ratios for different metrics. We shall call G the complete game including all D\u2019s dominated actions and GR the reduced game; CCS will denote the full version of Algorithm 1 and LP will denote the linear program to solve SRG\u2013v. Each instance is solved for a random starting vertex v; we report average ratios for 100 instances. \u201cn. covsets\u201d is the ratio between the number of covering sets in GR and in G. Dominated actions constitute a large percentage, increasing with the number of targets. This result indicates that the structure of the problem exhibits a non-negligible degree of redundancy. LP times (iterations) report the ratio between GR and G for the time (iterations) required to solve the maxmin linear program. A relative gain directly proportional to the percentage of dominated covering sets is observable (LP has less variables and constraints). A similar trend is not visible when considering the same ratio for the total time, which includes CCS. Indeed, the time needed by CCS largely exceed LP\u2019s and removal of dominated actions determines a polynomial additional cost, which can be seen in the slightly increasing trend of the curve. The relative gap between LP and CCS compute times can be assessed by look-\ning at the LP/CCS curve: when more targets are considered the time taken by LP is negligible w.r.t. CCS\u2019s. This shows that removing dominated actions is useful, allowing a small improvement in the average case, and assuring an exponential improvement in the worst case.\nFigure 12 shows the game value for D, 1 \u2212 gv, as |T | and vary (averaged over 100 instances). It can be observed that the game value is almost constant as |T | varies for \u2208 {0.05, 0.10, 0.25} and it is about 0.87. This is because all these instances have a similar number of edges, very close to the minimum number necessary for having connected graphs. With a larger number of edges, the game value increases. Interestingly, fixed a value of , there is a threshold of |T | such that beyond the threshold the game value increases as |T | increases. This suggests that the minimum game value is obtained for connected graphs with the minimum number of edges.\nIn Tab. 2, we report compute times with multiple signals, where the targets covered by a signal and the probability that a target triggers a signal are randomly chosen according to a uniform distribution. Values are averages over 100 random instances and give insights on the computation effort along the considered dimensions. The results show that the problem is computationally challenging even for\na small number of targets and signals."}, {"heading": "6.1.3. Approximation algorithms", "text": "We evaluate the actual approximation ratios obtained with our approximation algorithms as (1\u2212 g\u0302v)/(1\u2212 gv), where gv is the expected utility of A at the equilibrium considering all the covering sets and g\u0302v is the expected utility of A at the equilibrium when covering sets are generated by our heuristic algorithm. We execute our approximation dynamic programming algorithm with a different number, say RandRes, of randomly generated orders from {10, 20, 30, 40, 50}, in addition to the 3 heuristics discussed in Section 3.2.2. We executed our approximation branch and bound algorithm with constant values of \u03c1 from {0.25, 0.50, 0.75, 1.00} (we recall that with \u03c1 = 1.00 backtracking is completely disabled).\nFigure 13 and Figure 14 report the actual approximation ratios (averaged over 100 instances) obtained with our approximation algorithms for different values of |T | \u2208 {6, 8, 10, 12, 14, 16}, i.e., the instances for which we know the optimal game value, and \u2208 {0.05, 0.10, 0.25, 0.50, 0.75, 1.00}. We remark that the ratios obtained with the approximation branch\u2013and\u2013bound algorithm for some values of \u03c1 are omitted. This is because the compute time needed by the algorithm is over 104 seconds. The algorithm always terminates by the deadline for only \u03c1 \u2208 {0.75, 1.00}. We focus on the ratios obtained with the dynamic programming algorithm. Given a value of , as |T | increases, the ratio decreases up to a given threshold of |T | and then it is a constant. The threshold increases as decreases, while the constant decreases as decreases. The value of the constant is high for every , being larger than 0.8. Although the ratios increase as RandRes increases, it is worth noting that the increase is not very significant, being of the order of 0.05 between 10 RandRes and 50 RandRes. We focus on the ratios obtained with the branch\u2013and\u2013bound algorithm. Given a value of , as |T | increases, the ratio decreases up to a given threshold of |T | and then it increases approaching a ratio of 1. The threshold increases as decreases, while the minimum ratio decreases as decreases. Interestingly, ratios with \u03c1 = 1.00 are very close to ratios with \u03c1 \u2208 0.75, showing that performing even significant backtracking around the solution found with \u03c1 = 1.00 does not lead to a significant improvement of the solution. The solution can be effectively improved only with \u03c1 = 0.25, but it is not affordable due to the excessive required compute time. This shows that the heuristic performs very well. Comparing the ratios of the two algorithms, it can be observed that the approximation dynamic programming algorithm performs better than the approximation branch\u2013and\u2013bound algorithm. While the dynamic programming one always provides a ratio larger than 0.8, the branch\u2013and\u2013bound one provides for combinations of |T | and ratios lower than 0.4.\nFigure 15 reports the game values obtained with the approximation dynamic programming algorithm for every value of RandRes and with the approximation branch\u2013and\u2013bound algorithm when |T | \u2208 {20, 25, 30, 35, 40, 45, 50} only for \u03c1 = 1.00. Indeed, with \u03c1 = 0.75 the compute time is excessive and, as shown above, the purely heuristic solution cannot be significantly improved for \u2265 0.75. We report experimental results only for \u2208 {0.05, 0.25}. We notice that for these instances we do not have the optimal game value. However, since the optimal game value cannot be larger than 1 by construction of the instances, the game value obtained with our approximation algorithms represents a lower bound to the actual approximation ratio. It can be observed that, given a value of , the ratios obtained with the dynamic programming algorithm are essentially constant as |T |\n= 0.05 = 0.25\nincreases and this constant reduced as reduces. Surprisingly, after a certain value of |T |, the game values obtained with the branch and bound algorithm are higher than those obtained with the dynamic programming algorithm. This is because, fixed a value of , as |T | increases, the problem becomes easier and the heuristic used by the branch and bound algorithm performs well finding the best covering routes. This shows that there is not an algorithm outperforming the other for every combination of parameters |T | and . Furthermore, the above result shows that the worst cases for the approximation algorithms are those in which = O( 1|T |), corresponding to instances in which the number of edges per vertex is a constant in |T |. It is not clear from our experimental analysis whether increasing |T | with = \u03bd|T | for some \u03bd > 1 the game value approaches to 0 or to a strictly positive value. However, our approximation algorithms provide a very good approximation even with a large number of targets and a small value of .\nFigure 16 reports the compute times required by the approximation dynamic programming algorithms. As it can be seen, the required time slightly increases when adopting a larger number of randomly generated orders with respect to the baseline with \u03c1 = 1.00."}, {"heading": "6.2. Real case study", "text": "In this section we present the results obtained by applying our approach to a real case study, in order to show an example of real application of our model. We imagine to face the task of protecting a fair site as we already discussed in Section 1.1.2 and we focus on the particular setting of Expo 2015. Figure 17 shows the map of the Expo 2015 site together with its graph representation. We manually\nbuild a discretized version of the site map by exploiting publicly available knowledge of the event8. We identify \u2248 170 sensible locations which correspond to an equal number of targets in our graph. More specifically, we identify \u2248 130 targets located at the entrances of each pavilion and in the surroundings of those areas which could be of interest for a high number of visitors. Some targets (\u2248 35) are located over the main roads, being these critical mainly due to their high crowd. Such roads also define our set of edges which resulted in a density of \u2248 0.02. Figure 17 reports a graphical representation of chosen deadlines d(\u00b7) and values \u03c0(\u00b7), respectively. To determine such values in a reasonable way we apply a number of simple rules of thumb. First, to ease our task, we discretize the spaces of possible deadlines and values in four different levels. To assign a value to a target, we estimate the interest (in terms of popularity and expected crowd) of the corresponding area in the fair site. The higher the interest, the higher the value (actual values are reported in the figure). To assign deadlines we estimate the time an attacker should spend to escape from the attacked target after some malicious activity is started (for example, blending into the crowd without leaving any trace). In particular, we estimate a smaller escape time for those locations lying near the external border of the fair site while for locations that are more central we estimated a larger time. The smaller the escape time, the tighter the deadline for that target. Actual values are extracted from a normal distribution where \u03c32 = 1 and \u00b5 is set according to the chosen level. The maximum distance between any two target locations is about 1.5Km which we assume can be be covered in about 7.5\n8Detailed information can be found at http://www.expo2015.org/.\nminutes (we imagined a crowded scenario). Given such reference scenario, our means span from 5 minutes (very tight) to 7.5 minutes (very large). To derive our alarm system model we assume to have a number of panoramic cameras deployed in the environment at locations we manually choose in order to cover the whole environment and to guarantee a wide area of view for each camera (i.e., trying to keep, in general, more than one target under each camera\u2019s view). To map our set of cameras over the alarm system model, we adopt this convention: each group of cameras sharing an independent partial view of a target t is associated to a signal s \u2208 S(t); if target t is covered by k signals then each signal is generated with probability 1/k once t is attacked. Obviously, a deeper knowledge of the security systems deployed on the site can enable specific methods to set the parameters of our model. This is why we encourage involving agencies in charge of security when dealing with such task.\nWe first show a qualitative evaluation of our method. Figure 18 depicts the best placement for the Defender (the circle in the figure) and the attacked targets (the squares in the figure, these are the actions played by the Attacker with non\u2013null probability at the equilibrium). As intuition would suggest, the best location from where any signal response should start is a central one w.r.t. the whole fair site. Our simulations show that the optimal patrolling strategy coincides with such fixed placement even under false negatives rates of at least \u2248 0.3. Notice that such false negatives value can be considered unrealistically pessimistic for alarm systems deployed in structured environment like the one we are dealing\nwith. Attacked targets correspond to areas, which exhibit rather high interest and small escape time. Figure 19 reports an example of signal response strategy for a given starting vertex (the small circle in the figure) and a given signal (whose covered targets are depicted with the large circle in the figure). The table lists the computed covering sets and the probabilities with which the Defender plays the corresponding covering routes.\nBoxplots of Figure 20(a) provide some quantitative insights on the computational effort we measured in solving such realistic instance. Given a signal, we report the statistical distribution of the time required by Algorithm 1 to compute covering routes from each possible start vertex. In general, we observe a high variance in each boxplot. Indeed, once fixed a signal s in our realistic instance, it is easy to identify starting vertices from which computing covering routes is likely to be very easy or, instead, much harder. For the easy case, consider a starting vertex lying very much far away from the group of targets covered by s. In such case, Algorithm 1 will soon stop iterating through covering set cardinalities being not able to further generate feasible sets. Such feature is induced by the large distance of the starting vertex from the targets covered by s together with the low edge density and the spatial locality shared among targets covered by the same signal (these last two are, indeed, features that frequently recur in realistic scenarios). For the harder case, just consider a situation in which the distance of the starting vertex from the targets covered by s is such that a large number of covering routes is available. An example of this kind can be inspected in Figure 19. Interestingly, a similar high variance trend cannot be observed when depicting the statistical distribution of the compute time per starting vertex. The boxplot of Figure 20(b) suggests that, by fixing the starting vertex and solving for different signals, hard\ninstances counterbalance, on average, the easy ones."}, {"heading": "7. Related works", "text": "In the last few years, Security Games received an increasing interest from the Artificial Intelligence scientific community, leading to the exploration of a large number of research directions around this topic. In this section, we briefly discuss what we deem to be the most significant ones, starting from the game theoretical foundations on which these models are built.\nComputing solution concepts is the central problem upon which the real applicability of these game theoretical models is based. A lot of works concentrated on algorithmic studies of this topic, analysing the relationships holding among different kinds of solution concepts and their computational complexity. In [40] the relationship between Stackelberg, Nash and min\u2013max equilibria is studied, while in [41] some refinements of the Stackelberg equilibrium are proposed. Many efforts have been made to develop tractable algorithms for finding Stackelberg equilibria in Bayesian games [42]. Furthermore, in [43] the authors analysed scenarios in which the Defender has multiple objectives, searching for the Pareto curve of the Stackelberg equilibria.\nBesides fundamental works like the ones cited above, a more recent research line devoted efforts towards the definition of game model refinements in the attempt to overcome some of their ideal assumptions. One remarkable issue belonging to this scope is how to model the behaviour of the Attacker. In the attempt to have a more realistic behaviour, some works considered bounded rationality and defined algorithms to deal with it. In [44] different models of the Attacker are analysed while in [45, 46] the Attacker is allowed to have different observation and planning capabilities. Moreover, in [47] Quantal\u2013Best Response is used to model the behaviour of the Attacker and in [48] algorithms that scale up with bounded rational adversaries are proposed. In our paper, we assume that the attacker is rational.\nOther model refinements focused on those cases in which games exhibit specific structures that can be leveraged in the design of algorithms to compute the Stackelberg equilibrium. For instance, the study of the spread of contagion over a network is investigated in [49]. When no scheduling constraints are present and payoffs exhibit a special form, the computation of a Stackelberg equilibrium can be done very efficiently enabling the resolution of remarkably big scenarios [50]. In [51] realistic aspects of infrastructures to be protected are taken into account."}, {"heading": "8. Conclusions and future research", "text": "In this paper we provide the first Security Game for large environments surveillance, e.g. for fair sites protection, that can exploit an alarm system with spatially uncertain signals. To monitor and protect large infrastructure such as stations, airports, and cities, a two\u2013level paradigm is commonly adopted: a broad area surveillance phase, where an attack is detected but only approximately localized due to the spatially uncertainty of the alarm system, triggers a local investigation phase, where guards have to find and clear the attack. Abstracting away from technological details, we propose a simple model of alarm systems that can be widely adopted with every specific technology and we include it in the state\u2013of\u2013art patrolling models, obtaining a new security game model. We show that the problem of finding the best patrolling strategy to respond to a given alarm signal isAPX\u2013 hard with arbitrary graphs even when the game is zero\u2013sum. Then, we provide two exponential\u2013time exact algorithms to find the best patrolling strategy to respond to a given alarm signal. The first algorithm performs a breath\u2013first search by exploiting a dynamic programming approach, while the second algorithm performs a depth\u2013first approach by exploiting a branch\u2013and\u2013bound approach. We provide also a variation of these two algorithms to find an approximate solution. We experimentally evaluate our exact and approximation algorithms both in worst\u2013case instances, to evaluate empirically the gap between our hardness results and the theoretical guarantees of our approximation algorithms, and in one realistic instance, Expo 2015. The limit of our exact algorithms is about 16 targets with worst\u2013 case instances while we were able to compute an optimal solution for a realistic instance with\u2248 170 targets. On the other side, our approximation algorithms provide a very effective approximation even with worst\u2013case instances. We provide also results for special topologies, showing that our dynamic programming algorithm requires polynomial time with linear and cycle graphs, while the problem is NP\u2013hard with tree graphs. Finally, we focus on the problem of patrolling the environment, showing that if every target is alarmed and no false positives and missed detections are present, then the best patrolling strategy prescribes that the patroller stays in a given place waiting for an alarm signal. Furthermore, we show that such a strategy may be optimal even for missed detection rates up to 50%.\nOf course, our research does not end here since some problems related to our model remain open. The main theoretical issue is the closure of the approximation gap of SRG\u2013v. We believe that investigating the relationship between our model and the DEADLINE\u2013TSP could help in closing the gap. Another interesting problem is the study of approximation algorithms for tree graphs. Our NP\u2013hardness\nresult does not exclude the existence of a PTAS (i.e., polynomial time approximation scheme), even if we conjecture that the existence is unlikely. In addition, a number of extensions of our model are worth being explored. The most important extension is to include false positives and missed detections, allowing the patroller to patrol even in absence of alarm signals. Other interesting extensions regard cases in which the number of patrollers is larger than one or there are multiple attackers, which coordinate to perform their malicious attack. Finally, a different research direction stemming from the problem concerns the alarm system dimension. Indeed, trying to deploy sensors and devices in the environment in such a way to maximize the utility in responding to alarms is a non\u2013trivial and interesting problem, mainly due to the inherent budget constraint and trade\u2013offs that would exhibit."}, {"heading": "Appendix A. Notation", "text": "We report in Tab. A.3 the symbols used along the paper."}, {"heading": "Appendix B. Additional experimental results", "text": "We report in Fig. B.21 the boxplots of the results depicted in Fig. 10. They show that the variance of the compute times drastically reduces as increases. This is because the number of edges increases as increases and so the number of proper covering sets increases approaching 2|T |. On the other hand, with small values of , the number of proper covering sets of different instances can be extremely different."}], "references": [{"title": "An overview of recent application trends at the AAMAS conference: Security", "author": ["M. Jain", "B. An", "M. Tambe"], "venue": "sustainability, and safety, AI Magazine 33 (3) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Leadership with commitment to mixed strategies", "author": ["B. Von Stengel", "S. Zamir"], "venue": "Tech. rep. ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Computing the optimal strategy to commit to", "author": ["V. Conitzer", "T. Sandholm"], "venue": "in: Proceedings of the 7th ACM Conference on Electronic Commerce", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Deployed armor protection: The application of a gametheoretic model for security at the los angeles international airport", "author": ["J. Pita", "M. Jain", "C. Western", "C. Portway", "M. Tambe", "F. Ord\u00f3\u00f1ez", "S. Kraus", "P. Paruchuri"], "venue": "in: Proceedings of the International Joint Conference on Autonomous Agents and Multi\u2013Agent Systems (AAMAS)", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Iris \u2013 a tool for strategic security allocation in transportation networks", "author": ["J. Tsai", "S. Rathi", "C. Kiekintveld", "F. Ord\u00f3\u00f1ez", "M. Tambe"], "venue": "in: Proceedings of the International Joint Conference on Autonomous Agents and Multi\u2013Agent Systems (AAMAS)", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Protect \u2013 a deployed game theoretic system for strategic security 65  allocation for the united states coast guard", "author": ["B. An", "E. Shieh", "R. Yang", "M. Tambe", "C. Baldwin", "J. DiRenzo", "B. Maule", "G. Meyer"], "venue": "AI Magazine 33 (4) ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Game\u2013theoretic security patrolling with dynamic execution uncertainty and a case study on a real transit system", "author": ["F.M. Delle Fave", "A.X. Jiang", "Z. Yin", "C. Zhang", "M. Tambe", "S. Kraus", "J. Sullivan"], "venue": "Journal of Artificial Intelligence Research 50 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Paws: Adaptive game-theoretic patrolling for wildlife protection", "author": ["B. Ford", "D. Kar", "F.M. Delle Fave", "R. Yang", "M. Tambe"], "venue": "in: International Conference on Autonomous Agents and Multi\u2013Agent Systems (AAMAS)", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Patrolling security games: Definition and algorithms for solving large instances with single patroller and single intruder", "author": ["N. Basilico", "N. Gatti", "F. Amigoni"], "venue": "ARTIF INTELL 184\u2013185 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Asynchronous multi-robot patrolling against intrusion in arbitrary topologies", "author": ["N. Basilico", "N. Gatti", "F. Villa"], "venue": "in: Proceedings of the Twenty-Fourth Conference on Artificial Intelligence (AAAI)", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Multi\u2013robot adversarial patrolling: Facing a full\u2013knowledge opponent", "author": ["N. Agmon", "G.A. Kaminka", "S. Kraus"], "venue": "Journal of Artificial Intelligence Research (JAIR) 42 ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Multi\u2013robot adversarial patrolling: facing coordinated attacks", "author": ["E. Sless", "N. Agmon", "S. Kraus"], "venue": "in: International conference on Autonomous Agents and Multi-Agent Systems (AAMAS)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "On coordination in practical multi-robot patrol", "author": ["N. Agmon", "C. Fok", "Y. Emaliah", "P. Stone", "C. Julien", "S. Vishwanath"], "venue": "in: IEEE International Conference on Robotics and Automation (ICRA)", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Computing solutions in infinite\u2013horizon discounted adversarial patrolling games", "author": ["Y. Vorobeychik", "B. An", "M. Tambe", "S.P. Singh"], "venue": "in: Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling (ICAPS)", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficiently solving joint activity based security games", "author": ["E.A. Shieh", "M. Jain", "A.X. Jiang", "M. Tambe"], "venue": "in: Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI)", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Security games with protection externalities", "author": ["J. Gan", "B. An", "Y. Vorobeychik"], "venue": "in: Proceedings of the Twenty-Ninth Conference on Artificial Intelligence (AAAI)", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "On events in multi-robot patrol in adversarial environments", "author": ["N. Agmon"], "venue": "in: International conference on Autonomous Agents and Multi\u2013Agent Systems (AAMAS)", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Patrolling games", "author": ["S. Alpern", "A. Morton", "K. Papadaki"], "venue": "Operations Research 59 (5) ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Distributed online patrolling with multiagent teams of sentinels and searchers", "author": ["N. Basilico", "S. Carpin", "T. Chung"], "venue": "in: DARS", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Spatiotemporal bag-of-features for early wildfire smoke detection", "author": ["B.C. Ko", "J.O. Park", "J.-Y. Nam"], "venue": "Image and Vision Computing 31 (10) ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Wireless sensor network deployment for integrating video-surveillance and data-monitoring in precision agriculture over distributed crops", "author": ["A.-J. Garcia-Sanchez", "F. Garcia-Sanchez", "J. Garcia-Haro"], "venue": "Computers and Electronics in Agriculture 75 (2) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Wireless sensor network survey", "author": ["J. Yick", "B. Mukherjee", "D. Ghosal"], "venue": "Comput. Netw. 52 (12) ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "Bordersense: Border patrol through advanced wireless sensor networks", "author": ["Z. Sun", "P. Wang", "M.C. Vuran", "M.A. Al-rodhaan", "A.M. Al-dhelaan", "I.F. Akyildiz"], "venue": "Ad Hoc Networks 9 (3) ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Randomized sensing in adversarial environments", "author": ["A. Krause", "A. Roper", "D. Golovin"], "venue": "in: Proceedings of the International Joint Conference on Artificial Intelligence, Barcelona", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Introducing alarms in adversarial patrolling games", "author": ["E. Munoz de Cote", "R. Stranders", "N. Basilico", "N. Gatti", "N. Jennings"], "venue": "in: International conference on Autonomous Agents and Multi\u2013Agent Systems (AAMAS),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Strategic guard placement for optimal response to alarms in security games", "author": ["N. Basilico", "N. Gatti"], "venue": "in: International conference on Autonomous Agents and Multi\u2013Agent Systems (AAMAS)", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Extending algorithms for mobile robot patrolling in the presence of adversaries to more realistic settings", "author": ["N. Basilico", "N. Gatti", "T. Rossi", "S. Ceppi", "F. Amigoni"], "venue": "in: Proceedings of the 2009 IEEE/WIC/ACM International Conference on Intelligent Agent Technology (IAT)", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2009}, {"title": "Capturing augmented sensing capabilities and intrusion delay in patrolling-intrusion games", "author": ["N. Basilico", "N. Gatti", "T. Rossi"], "venue": "in: IEEE Symposium on Computational Intelligence and Games (CIG)", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Multiagent Systems: Algorithmic", "author": ["Y. Shoham", "K. Leyton-Brown"], "venue": "Game- Theoretic, and Logical Foundations, Cambridge University Press, New York, NY, USA", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}, {"title": "Game Theory", "author": ["M. Maschler", "S. Zamir", "E. Solan"], "venue": "Cambridge University Press", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}, {"title": "Computers and Intractability; A Guide to the Theory of NP-Completeness", "author": ["M.R. Garey", "D.S. Johnson"], "venue": "W. H. Freeman & Co., New York, NY, USA", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1990}, {"title": "An introduction to game theory", "author": ["M.J. Osborne"], "venue": "Vol. 3, Oxford University Press New York", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2004}, {"title": "The traveling salesman problem with distances one and two", "author": ["C.H. Papadimitriou", "M. Yannakakis"], "venue": "Mathematics of Operations Research 18 (1) ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1993}, {"title": "The parameterized approximability of tsp with deadlines", "author": ["H.-J. Bckenhauer", "J. Hromkovic", "J. Kneis", "J. Kupke"], "venue": "Theory Computing Systems 41 (3) ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2007}, {"title": "Approximation algorithms for deadline-tsp and vehicle routing with time-windows", "author": ["N. Bansal", "A. Blum", "S. Chawla", "A. Meyerson"], "venue": "in: Proceedings of the Thirty-sixth Annual ACM Symposium on Theory of Computing (STOC)", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2004}, {"title": "Combinatorial Optimization: Networks and Matroids", "author": ["E. Lawler"], "venue": "Dover Books on Mathematics", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2011}, {"title": "Local search in routing problems with time windows", "author": ["M.W. Savelsbergh"], "venue": "ANN OPER RES 4 (1) ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1985}, {"title": "Theory of scheduling", "author": ["R.W. Conway", "W.L. Maxwell", "L.W. Millerr"], "venue": "Dover Books on Mathematics", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2003}, {"title": "Reusing optimal tsp solutions for locally modified input instances", "author": ["H.-J. B\u00f6ckenhauer", "L. Forlizzi", "J. Hromkovi\u010d", "J. Kneis", "J. Kupke", "G. Proietti", "P. Widmayer"], "venue": "in: IFIP TCS", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2006}, {"title": "Stackelberg vs", "author": ["D. Korzhyk", "Z. Yin", "C. Kiekintveld", "V. Conitzer", "M. Tambe"], "venue": "nash in security games: An extended investigation of interchangeability, equivalence, and uniqueness, Juornal of Artificial Intelligence Research (JAIR) 41 ", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2011}, {"title": "Refinement of strong stackelberg equilibria in security games", "author": ["B. An", "M. Tambe", "F. Ord\u00f3\u00f1ez", "E.A. Shieh", "C. Kiekintveld"], "venue": "in: Proceedings of the Twenty-Fifth Conference on Artificial Intelligence (AAAI)", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2011}, {"title": "Quality\u2013bounded solutions for finite bayesian stackelberg games: scaling up", "author": ["M. Jain", "C. Kiekintveld", "M. Tambe"], "venue": "in: International Conference on Autonomous Agents and Multi\u2013Agent Systems (AAMAS)", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2011}, {"title": "An extended study on multi\u2013objective security games", "author": ["M. Brown", "B. An", "C. Kiekintveld", "F. Ord\u00f3\u00f1ez", "M. Tambe"], "venue": "Autonomous Agents and Multi\u2013Agent Systems (AAMAS) 28 (1) ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2014}, {"title": "Analyzing the effectiveness of adversary modeling in security games", "author": ["T.H. Nguyen", "R. Yang", "A. Azaria", "S. Kraus", "M. Tambe"], "venue": "in: Proceedings of the Twenty-Seventh Conference on Artificial Intelligence (AAAI)", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2013}, {"title": "Security games with surveillance cost and optimal timing of attack execution", "author": ["B. An", "M. Brown", "Y. Vorobeychik", "M. Tambe"], "venue": "in: International conference on Autonomous Agents and Multi\u2013Agent Systems (AAMAS)", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2013}, {"title": "Adaptive resource allocation for wildlife protection against illegal poachers", "author": ["R. Yang", "B. Ford", "M. Tambe", "A. Lemieux"], "venue": "in: International Conference on Autonomous Agents and Multiagent Systems (AAMAS)", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "G", "author": ["B. An", "F. Ord\u00f3\u00f1ez", "M. Tambe", "E. Shieh", "R. Yang", "C. Baldwin", "J. DiRenzo", "K. Moretti", "B. Maule"], "venue": "Meyer, A deployed quantal response\u2013based patrol planning system for the U.S. coast guard, Interfaces 43 (5) ", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2013}, {"title": "Scaling\u2013up security games with boundedly rational adversaries: A cutting\u2013plane approach", "author": ["R. Yang", "A.X. Jiang", "M. Tambe", "F. Ord\u00f3\u00f1ez"], "venue": "in: Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2013}, {"title": "Game\u2013theoretic target selection in contagion\u2013based domains", "author": ["J. Tsai", "T.H. Nguyen", "N. Weller", "M. Tambe"], "venue": "The Computer Journal 57 (6) ", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2014}, {"title": "Computing optimal randomized resource allocations for massive security games", "author": ["C. Kiekintveld", "M. Jain", "J. Tsai", "J. Pita", "F. Ord\u00f3\u00f1ez", "M. Tambe"], "venue": "in: International Joint Conference on Autonomous Agents and Multi\u2013Agent Systems (AAMAS)", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2009}, {"title": "Lazy defenders are almost optimal against diligent attackers", "author": ["A. Blum", "N. Haghtalab", "A.D. Procaccia"], "venue": "in: Proceedings of the Twenty-Eighth Conference on Artificial Intelligence ", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Security Games model the task of protecting physical environments as a non\u2013 cooperative game between a Defender and an Attacker [1].", "startOffset": 128, "endOffset": 131}, {"referenceID": 1, "context": "leader\u2013follower) paradigm [2], where the Defender (leader) commits to a strategy and the Attacker (follower) first observes such commitment, then best responds to it.", "startOffset": 26, "endOffset": 29}, {"referenceID": 2, "context": "As discussed in the seminal work [3], finding a leader\u2013follower equilibrium is computationally tractable in games with one follower and complete information, while it becomes hard in Bayesian games with different types of Attacker.", "startOffset": 33, "endOffset": 36}, {"referenceID": 3, "context": "The first notable examples are the deployment of police checkpoints at the Los Angels International Airport [4] and the scheduling of federal air marshals over the U.", "startOffset": 108, "endOffset": 111}, {"referenceID": 4, "context": "domestic airline flights [5].", "startOffset": 25, "endOffset": 28}, {"referenceID": 5, "context": "Coast Guard patrols to secure crowded places, bridges, and ferries [6] and the arrangement of city guards to stop fare evasion in Los Angeles Metro [7].", "startOffset": 67, "endOffset": 70}, {"referenceID": 6, "context": "Coast Guard patrols to secure crowded places, bridges, and ferries [6] and the arrangement of city guards to stop fare evasion in Los Angeles Metro [7].", "startOffset": 148, "endOffset": 151}, {"referenceID": 7, "context": "Finally, a similar approach is being tested and evaluated in Uganda, Africa, for the protection of wildlife [8].", "startOffset": 108, "endOffset": 111}, {"referenceID": 8, "context": "The Attacker, besides having knowledge of the strategy to which the Defender committed to, can observe the movements of the patrollers at any time and use such information in deciding the most convenient time and target location to attack [9].", "startOffset": 239, "endOffset": 242}, {"referenceID": 9, "context": "When multiple patrollers are available, coordinating them at best is in general a hard task which, besides computational aspects, must also keep into account communication issues [10].", "startOffset": 179, "endOffset": 183}, {"referenceID": 10, "context": ", linear and cycle graphs), when patrollers have homogeneous moving and sensing capabilities and all the vertices composing the border share the same features [11].", "startOffset": 159, "endOffset": 163}, {"referenceID": 11, "context": "Scaling this model involved the study of how to compute patrolling strategies in scenarios where the Attacker is allowed to perform multiple attacks [12].", "startOffset": 149, "endOffset": 153}, {"referenceID": 12, "context": "Similarly, coordination strategies among multiple Defenders are investigated in [13].", "startOffset": 80, "endOffset": 84}, {"referenceID": 13, "context": "In [14], the authors study the case in which there is a temporal discount on the targets.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "Extensions are discussed in [15], where coordination strategies between", "startOffset": 28, "endOffset": 32}, {"referenceID": 15, "context": "defenders are explored, in [16], where a resource can cover multiple targets, and in [17] where attacks can detected at different stages with different associated utilities.", "startOffset": 27, "endOffset": 31}, {"referenceID": 16, "context": "defenders are explored, in [16], where a resource can cover multiple targets, and in [17] where attacks can detected at different stages with different associated utilities.", "startOffset": 85, "endOffset": 89}, {"referenceID": 17, "context": "Finally, some theoretical results about properties of specific patrolling settings are provided in [18].", "startOffset": 99, "endOffset": 103}, {"referenceID": 18, "context": "Real\u2013 world applications include UAVs surveillance of large infrastructures [19], wildfires detection with CCD cameras [20], agricultural fields monitoring [21], and surveillance based on wireless sensor networks [22], and border patrolling [23].", "startOffset": 76, "endOffset": 80}, {"referenceID": 19, "context": "Real\u2013 world applications include UAVs surveillance of large infrastructures [19], wildfires detection with CCD cameras [20], agricultural fields monitoring [21], and surveillance based on wireless sensor networks [22], and border patrolling [23].", "startOffset": 119, "endOffset": 123}, {"referenceID": 20, "context": "Real\u2013 world applications include UAVs surveillance of large infrastructures [19], wildfires detection with CCD cameras [20], agricultural fields monitoring [21], and surveillance based on wireless sensor networks [22], and border patrolling [23].", "startOffset": 156, "endOffset": 160}, {"referenceID": 21, "context": "Real\u2013 world applications include UAVs surveillance of large infrastructures [19], wildfires detection with CCD cameras [20], agricultural fields monitoring [21], and surveillance based on wireless sensor networks [22], and border patrolling [23].", "startOffset": 213, "endOffset": 217}, {"referenceID": 22, "context": "Real\u2013 world applications include UAVs surveillance of large infrastructures [19], wildfires detection with CCD cameras [20], agricultural fields monitoring [21], and surveillance based on wireless sensor networks [22], and border patrolling [23].", "startOffset": 241, "endOffset": 245}, {"referenceID": 7, "context": "The use of security games in this particular domain is not new (see, for example, [8]).", "startOffset": 82, "endOffset": 85}, {"referenceID": 7, "context": "This can be done by adopting a discretization of the environment, where each target corresponds to a sector, values are related to the expected population of animals in that sector, and deadlines represent the expected completion time of illegal hunts (these parameters can be derived from data, as discussed in [8]).", "startOffset": 312, "endOffset": 315}, {"referenceID": 23, "context": "[24], the problem of integrating alarm signals together with adversarial patrolling is almost completely unexplored.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "The only work that can be classified under this scope is [25].", "startOffset": 57, "endOffset": 61}, {"referenceID": 8, "context": "On the other hand, when sensors are affected only by false negatives, the treatment can be carried out by means of an easy variation of the algorithm for the case without sensors [9].", "startOffset": 179, "endOffset": 182}, {"referenceID": 25, "context": "2A very preliminary short version of the present paper is [26].", "startOffset": 58, "endOffset": 62}, {"referenceID": 8, "context": "Basic patrolling security game As is customary in the artificial intelligence literature [9, 14], we deal with discrete, both in terms of space and time, patrolling settings, representing an approximation of a continuous environment.", "startOffset": 89, "endOffset": 96}, {"referenceID": 13, "context": "Basic patrolling security game As is customary in the artificial intelligence literature [9, 14], we deal with discrete, both in terms of space and time, patrolling settings, representing an approximation of a continuous environment.", "startOffset": 89, "endOffset": 96}, {"referenceID": 26, "context": "3Partial observability of A over the position of D can be introduced as discussed in [27].", "startOffset": 85, "endOffset": 89}, {"referenceID": 27, "context": "It can be relaxed by associating execution costs to the Attacker\u2019s actions as shown in [28].", "startOffset": 87, "endOffset": 91}, {"referenceID": 28, "context": "Since we focus on zero\u2013sum games, the leader\u2019s strategy at the leader\u2013follower equilibrium is its maxmim strategy and it can be found by employing linear mathematical programming, which requires polynomial time in the number of actions available to the players [29].", "startOffset": 261, "endOffset": 265}, {"referenceID": 0, "context": "Formally, the alarm system is defined as a pair (S, p), where S = {s1, \u00b7 \u00b7 \u00b7 , sm} is a set of m \u2265 1 signals and p : S \u00d7 T \u2192 [0, 1] is a function that specifies the probability of having the system generating a signal s given that target t has been attacked.", "startOffset": 125, "endOffset": 131}, {"referenceID": 29, "context": "5Rigorously speaking, our definition of subgame is not compliant with the definition provided in game theory [30], which requires that all the actions of a node belong to the same subgame (and therefore we could not separate action \u2206 from actions ti).", "startOffset": 109, "endOffset": 113}, {"referenceID": 29, "context": "Then, according to classical backward induction arguments [30], once we have found the best strategies of each SRG\u2013v, we can substitute the subgames with the agents\u2019 equilibrium utilities and then we can find the best strategy of D for patrolling the vertices whenever no alarm signal has been raised and the best strategy of attack for A.", "startOffset": 58, "endOffset": 62}, {"referenceID": 30, "context": "Let us consider the following reduction from HAMILTONIAN\u2013PATH [31].", "startOffset": 62, "endOffset": 66}, {"referenceID": 31, "context": "Notice that in the worst case the number of covering routes is O(|T (s)||T (s)|), but computing all of them may be unnecessary since some covering routes will never be played by D due to strategy domination and therefore they can be safely discarded [32].", "startOffset": 250, "endOffset": 254}, {"referenceID": 32, "context": "We produce an approximation\u2013preserving reduction from TSP(1,2) that is known to beAPX\u2013hard [33].", "startOffset": 91, "endOffset": 95}, {"referenceID": 32, "context": "It is known that there is no polynomial\u2013time approximation algorithm with APXTSP/OPTAPX < \u03b1 for some \u03b1 > 1, unless P = NP [33].", "startOffset": 122, "endOffset": 126}, {"referenceID": 33, "context": "The DEADLINE\u2013TSP does not admit any constant\u2013ratio approximation algorithm [34] and the best\u2013known approximation algorithm has logarithmic approximation ratio [35].", "startOffset": 75, "endOffset": 79}, {"referenceID": 34, "context": "The DEADLINE\u2013TSP does not admit any constant\u2013ratio approximation algorithm [34] and the best\u2013known approximation algorithm has logarithmic approximation ratio [35].", "startOffset": 159, "endOffset": 163}, {"referenceID": 35, "context": "For efficiency, we calculate (in polynomial time) all the shortest paths offline by means of the Floyd\u2013Warshall algorithm [36].", "startOffset": 122, "endOffset": 126}, {"referenceID": 36, "context": "The basic idea, inspired by [37], is to adopt a conservative approach, trying to preserve feasibility.", "startOffset": 28, "endOffset": 32}, {"referenceID": 37, "context": "The Earliest Due Date [38] (EDD) algorithm is an optimal algorithm for synchronous (i.", "startOffset": 22, "endOffset": 26}, {"referenceID": 8, "context": "Given the current vertex of D and the sequence of the last, say n, vertices visited by D (where n is a tradeoff between effectiveness of the solution and computational effort), a patrolling strategy is usually defined as a randomization over the next adjacent vertices [9].", "startOffset": 269, "endOffset": 272}, {"referenceID": 38, "context": "To answer this question, we resort to hardness results for reoptimization, also called locally modified problems [39].", "startOffset": 113, "endOffset": 117}, {"referenceID": 38, "context": "From such instance of RHC, following the approach of [39], we build the following instance for LM\u2013 COV\u2013ROUTE:", "startOffset": 53, "endOffset": 57}, {"referenceID": 39, "context": "In [40] the relationship between Stackelberg, Nash and min\u2013max equilibria is studied, while in [41] some refinements of the Stackelberg equilibrium are proposed.", "startOffset": 3, "endOffset": 7}, {"referenceID": 40, "context": "In [40] the relationship between Stackelberg, Nash and min\u2013max equilibria is studied, while in [41] some refinements of the Stackelberg equilibrium are proposed.", "startOffset": 95, "endOffset": 99}, {"referenceID": 41, "context": "Many efforts have been made to develop tractable algorithms for finding Stackelberg equilibria in Bayesian games [42].", "startOffset": 113, "endOffset": 117}, {"referenceID": 42, "context": "Furthermore, in [43] the authors analysed scenarios in which the Defender has multiple objectives, searching for the Pareto curve of the Stackelberg equilibria.", "startOffset": 16, "endOffset": 20}, {"referenceID": 43, "context": "In [44] different models of the Attacker are analysed while in [45, 46] the Attacker is allowed to have different observation and planning capabilities.", "startOffset": 3, "endOffset": 7}, {"referenceID": 44, "context": "In [44] different models of the Attacker are analysed while in [45, 46] the Attacker is allowed to have different observation and planning capabilities.", "startOffset": 63, "endOffset": 71}, {"referenceID": 45, "context": "In [44] different models of the Attacker are analysed while in [45, 46] the Attacker is allowed to have different observation and planning capabilities.", "startOffset": 63, "endOffset": 71}, {"referenceID": 46, "context": "Moreover, in [47] Quantal\u2013Best Response is used to model the behaviour of the Attacker and in [48] algorithms that scale up with bounded rational adversaries are proposed.", "startOffset": 13, "endOffset": 17}, {"referenceID": 47, "context": "Moreover, in [47] Quantal\u2013Best Response is used to model the behaviour of the Attacker and in [48] algorithms that scale up with bounded rational adversaries are proposed.", "startOffset": 94, "endOffset": 98}, {"referenceID": 48, "context": "For instance, the study of the spread of contagion over a network is investigated in [49].", "startOffset": 85, "endOffset": 89}, {"referenceID": 49, "context": "When no scheduling constraints are present and payoffs exhibit a special form, the computation of a Stackelberg equilibrium can be done very efficiently enabling the resolution of remarkably big scenarios [50].", "startOffset": 205, "endOffset": 209}, {"referenceID": 50, "context": "In [51] realistic aspects of infrastructures to be protected are taken into account.", "startOffset": 3, "endOffset": 7}], "year": 2015, "abstractText": "When securing complex infrastructures or large environments, constant surveillance of every area is not affordable. To cope with this issue, a common countermeasure is the usage of cheap but wide\u2013ranged sensors, able to detect suspicious events that occur in large areas, supporting patrollers to improve the effectiveness of their strategies. However, such sensors are commonly affected by uncertainty. In the present paper, we focus on spatially uncertain alarm signals. That is, the alarm system is able to detect an attack but it is uncertain on the exact position where the attack is taking place. This is common when the area to be secured is wide such as in border patrolling and fair site surveillance. We propose, to the best of our knowledge, the first Patrolling Security Game model where a Defender is supported by a spatially uncertain alarm system which non\u2013deterministically generates signals once a target is under attack. We show that finding the optimal strategy in arbitrary graphs isAPX\u2013hard even in zero\u2013sum games and we provide two (exponential time) exact algorithms and two (polynomial time) approximation algorithms. Furthermore, we analyse what happens in environments with special topologies, showing that in linear and cycle graphs the optimal patrolling strategy can be found in polynomial time, de facto allowing our algorithms to be used in real\u2013life scenarios, while in trees the problem is NP\u2013hard. Finally, we show that without false positives and missed detections, the best patrolling strategy reduces to stay in a place, wait for a signal, and respond to it at best. This strategy is optimal even with non\u2013negligible missed detection rates, which, unfortunately, affect every commercial alarm system. We evaluate our methods in simulation, assessing both quantitative and qualitative aspects.", "creator": "LaTeX with hyperref package"}}}