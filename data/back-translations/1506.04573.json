{"id": "1506.04573", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2015", "title": "A New PAC-Bayesian Perspective on Domain Adaptation", "abstract": "Our main contribution is a novel theoretical analysis of target risk, formulated as the upper limit, which expresses a trade-off between only two terms: (i) the common errors of voters in distributing the source and (ii) voter disagreement in distributing the target, both of which are easily assessed from random sampling. Therefore, this new study is more precise than other analyses, which are usually based on three terms (including a term that is difficult to control), and we derive a PAC-Bayesian generalization and specialize the result in linear classifiers to propose a learning algorithm.", "histories": [["v1", "Mon, 15 Jun 2015 12:46:45 GMT  (800kb,D)", "https://arxiv.org/abs/1506.04573v1", null], ["v2", "Mon, 21 Sep 2015 10:49:00 GMT  (800kb,D)", "http://arxiv.org/abs/1506.04573v2", null], ["v3", "Mon, 14 Mar 2016 19:44:22 GMT  (381kb,D)", "http://arxiv.org/abs/1506.04573v3", null], ["v4", "Tue, 26 Jul 2016 10:29:33 GMT  (422kb,D)", "http://arxiv.org/abs/1506.04573v4", "Published at ICML 2016"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["pascal germain", "amaury habrard", "fran\u00e7ois laviolette", "emilie morvant"], "accepted": true, "id": "1506.04573"}, "pdf": {"name": "1506.04573.pdf", "metadata": {"source": "META", "title": "A New PAC-Bayesian Perspective on Domain Adaptation", "authors": ["Pascal Germain", "Amaury Habrard", "Fran\u00e7ois Laviolette", "Emilie Morvant"], "emails": ["PASCAL.GERMAIN@INRIA.FR", "AMAURY.HABRARD@UNIV-ST-ETIENNE.FR", "FRANCOIS.LAVIOLETTE@IFT.ULAVAL.CA", "EMILIE.MORVANT@UNIV-ST-ETIENNE.FR"], "sections": [{"heading": "1. Introduction", "text": "Machine learning practitioners are commonly exposed to the issue of domain adaptation1 (Jiang, 2008; Margolis, 2011): One usually learns a model from a corpus, i.e., a fixed yet unknown source distribution, then wants to apply it on a new corpus, i.e., a related but slightly different target distribution. Therefore, domain adaptation is widely studied in a lot of application fields like computer vision (Patel et al., 2015; Ganin & Lempitsky, 2015), bioinformatics (Liu et al., 2008), natural language processing (Blitzer, 2007; Daume\u0301 III, 2007), etc. A common example is the\n1Domain adaptation is associated with transfer learning (Pan & Yang, 2010; Quionero-Candela et al., 2009).\nProceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s).\nspam filtering problem where a model needs to be adapted from one user mailbox to another receiving significantly different emails. Many approaches exist to address domain adaptation, often with the same idea: If we can apply a transformation to \u201cmove closer\u201d the distributions, then we can learn a model with the available labels. This is generally performed by reweighting the importance of labeled data (Huang et al., 2006; Sugiyama et al., 2007; Cortes et al., 2010; 2015), and/or by learning a common representation for the source and target distributions (Chen et al., 2012; Ganin et al., 2016), and/or by minimizing a measure of divergence between the distributions (Morvant et al., 2012; Germain et al., 2013; Cortes & Mohri, 2014). The divergence-based approach has especially been explored to derive generalization bounds for domain adaptation (e.g., Ben-David et al., 2006; 2010; Mansour et al., 2009; Li & Bilmes, 2007; Zhang et al., 2012). Recently, this issue has been studied through the PAC-Bayesian framework (Germain et al., 2013), which focuses on learning weighted majority votes2 without target label. Even the latter result opened the door to tackle domain adaptation in a PAC-Bayesian fashion, it shares the same philosophy as the seminal works of Ben-David et al. (2006; 2010); Mansour et al. (2009): The risk of the target model is upper-bounded jointly by the model\u2019s risk on the source distribution, the divergence between the marginal distributions, and a nonestimable term3 related to the ability to adapt in the current space. Note that Li & Bilmes (2007) proposed a PACBayesian generalization bound for domain adaptation but they considered target labels.\n2This setting is not too restrictive since many algorithms can be seen as a majority vote learning. E.g., ensemble learning and kernel methods output models interpretable as majority votes.\n3More precisely, this term can only be estimated in the presence of labeled data from both the source and the target domains.\nar X\niv :1\n50 6.\n04 57\n3v 4\n[ st\nat .M\nL ]\n2 6\nIn this paper, we derive a novel domain adaptation bound for the weighted majority vote framework. Concretely, the risk of the target model is still upper-bounded by three terms, but they differ in the information they capture. The first term is estimable from unlabeled data and relies on a notion of expected voters\u2019 disagreement on the target domain. The second term depends on the expected accuracy of the voters on the source domain. Interestingly, this latter is weighted by a divergence between the source and the target domains that enables controlling the relationship between domains. The third term estimates the \u201cvolume\u201d of the target domain living apart from the source one4, which has to be small for ensuring adaptation. From our bound, we deduce that a good adaptation strategy consists in finding a weighted majority vote leading to a suitable tradeoff\u2014controlled by the domains\u2019 divergence\u2014between the first two terms: Minimizing the first one corresponds to look for voters that disagree on the target domain, and minimizing the second one to seek accurate voters on the source. Thereafter, we provide PAC-Bayesian generalization guarantees to justify the empirical minimization of our new domain adaptation bound, and specialize it to linear classifiers (following a methodology known to give rise to tight bound values). This allows to design DALC, a learning algorithm that improves the performances of the previous PAC-Bayesian domain adaptation algorithm.\nThe rest of the paper is organized as follows. Section 2 presents the PAC-Bayesian domain adaptation setting. Section 3 reviews previous theoretical results on domain adaptation. Section 4 states our new analysis of domain adaptation for majority votes, that we relate to other works in Section 5. Then, Section 6 provides generalization bounds, specialized to linear classifiers in Section 7 to motivate the DALC learning algorithm, evaluated in Section 8."}, {"heading": "2. Unsupervised Domain Adaptation Setting", "text": "We tackle domain adaptation for binary classification, from a d-dimensional input space X\u2286Rd to an output space Y ={\u22121, 1}. Our goal is to perform domain adaptation from a distribution S\u2014the source domain\u2014to another (related) distribution T\u2014the target domain\u2014on X\u00d7Y ; SX and TX being the associated marginal distributions on X. Given a distribution D, we denote (D)m the distribution of am-sample constituted bym elements drawn i.i.d. fromD. We consider the unsupervised domain adaptation setting in which the algorithm is provided with a labeled source mssample S={(xi, yi)}msi=1\u223c(S)ms , and with an unlabeled target mt-sample T ={xi}mti=1\u223c(TX)mt . PAC-Bayesian domain adaptation. Our work is inspired by the PAC-Bayesian theory (first introduced by\n4Here we do not focus on learning a new representation to help the adaptation: We directly aim at adapting in the current space.\nMcAllester, 1999). More precisely, we adopt the PACBayesian domain adaptation setting previously studied in Germain et al. (2013). GivenH, a set of voters h : X\u2192 Y , the elements of this approach are a prior distribution \u03c0 on H, a pair of source-target learning samples (S, T ) and a posterior distribution \u03c1 on H. The prior distribution \u03c0 models an a priori belief\u2014before observing (S, T )\u2014of the voters\u2019 accuracy. Then, given the information provided by (S, T ), we aim at learning a posterior distribution \u03c1 leading to a \u03c1-weighted majority vote overH,\nB\u03c1(\u00b7) = sign [ E h\u223c\u03c1 h(\u00b7) ] ,\nwith nice generalization guarantees on the target domain T . In other words, we want to find the posterior distribution \u03c1 minimizing the true target risk of B\u03c1 :\nRT (B\u03c1) = E (x,y)\u223cT\nI [ B\u03c1(x) 6= y ] ,\nwhere I [ a ]\n= 1 if a is true, and 0 otherwise. However, in most PAC-Bayesian analyses one does not directly focus on this majority vote risk, but studies the expectation of the risks overH according to \u03c1, designed as the Gibbs risk :\nRD(G\u03c1) = E (x,y)\u223cD E h\u223c\u03c1\nI [ h(x) 6= y ] . (1)\nIt is well-known in the PAC-Bayesian literature that RD(B\u03c1) \u2264 2 RD(G\u03c1) (e.g., Herbrich & Graepel, 2000). Unfortunately, this worst case bound often leads to poor generalization guarantees on the majority vote risk. To address this issue, Lacasse et al. (2006) (refined in Germain et al., 2015) have exhibited that one can obtain a tighter bound on RD(B\u03c1) by studying the expected disagreement dD(\u03c1) of pairs of voters, defined as\ndD(\u03c1) = E x\u223cDX E h\u223c\u03c1 E h\u2032\u223c\u03c1\nI [ h(x) 6= h\u2032(x) ] , (2)\nas RD(B\u03c1) \u2264 1\u2212 (1\u22122 RD(G\u03c1)) 2\n1\u22122 dD(\u03c1) . Note that, although relying on dD(\u03c1), our present work does not reuse the latter result.5 Instead, we adopt another well-known strategy to obtain tight majority vote bounds, by specializing our PAC-Bayesian bound to linear classifiers. We describe this approach, and refer to related works, in Section 7."}, {"heading": "3. Some Previous Domain Adaptation Bounds", "text": "Many approaches tackling domain adaptation share the same underlying \u201cphilosophy\u201d, pulling its origins in the work of Ben-David et al. (2006; 2010) which proposed a domain adaptation bound (Theorem 1, below). To summarize, the domain adaptation bounds reviewed in this section (see Zhang et al., 2012; Cortes et al., 2010; 2015, for other\n5The quantity dD(\u03c1) is also used in the domain adaptation bound of Germain et al. (2013) to measure divergence between distributions. See forthcoming Theorem 2.\nbounds) express a similar trade-off between three terms: (i) the source risk, (ii) the distance between source and target marginal distributions over X, (iii) a non-estimable term (without target label) quantifying the difficulty of the task. Ben-David et al. (2006) assumed that the domains are related in the sense that there exists a (unknown) model performing well on both domains. Formally, their domain adaptation bound depends on the error \u00b5h\u2217=RS(h \u2217)+RT (h \u2217) of the best hypothesis overall\nh\u2217=argminh\u2208H ( RS(h) + RT (h) ) . In practice, when no target label is available, \u00b5h\u2217 is non-estimable and is assumed to be low when domain adaptation is achievable (or at least that there exists a representation space in which this assumption can be verified). In such a scenario, the domain adaptation strategy is then to look for a set H of possible models that behave \u201csimilarly\u201d on both the source and target data, and to learn a model inH with a good accuracy on the source data. This similarity, called the H\u2206H-distance, dH\u2206H(SX, TX) = 2 sup (h,h\u2032)\u2208H2 \u2223\u2223\u2223 E x\u223cSX I [ h(x) 6= h\u2032(x) ] \u2212 E x\u223cTX I [ h(x) 6= h\u2032(x)\n]\u2223\u2223\u2223, gives rise to the following domain adaptation bound. Theorem 1 (Ben-David et al., 2006; 2010). Let H be a (symmetric6) hypothesis class. We have,\n\u2200h\u2208H, RT (h) \u2264 RS(h)+ 12dH\u2206H(SX, TX)+\u00b5h\u2217 . (3)\nPursuing in the same line of research, Mansour et al. (2009) generalizes the H\u2206H-distance to real-valued loss functions L : [\u22121, 1]2 \u2192 R+, to express a similar theorem for regression. Their discrepancy discL(SX, TX) is defined as\nsup (h,h\u2032)\u2208H2 \u2223\u2223\u2223\u2223 Ex\u223cSX L(h(x), h\u2032(x))\u2212 Ex\u223cTX L(h(x), h\u2032(x)) \u2223\u2223\u2223\u2223 . The accuracy of the Mansour et al. (2009)\u2019s bound also relies on a non-estimable term assumed to be low when adaptation is achievable. Roughly, this term depends on the risk of the best target hypothesis and its agreement with the best source hypothesis on the source domain.\nBuilding on previous domain adaptation analyses, Germain et al. (2013) derived a PAC-Bayesian domain adaptation bound. This bound is based on a divergence suitable for PAC-Bayes, i.e., for the risk of a \u03c1-weighted majority vote of the voters of H (instead of a single classifier h \u2208 H). This domain disagreement dis\u03c1(SX, TX) is defined as\ndis\u03c1(SX, TX) = \u2223\u2223dS(\u03c1)\u2212 dT (\u03c1) \u2223\u2223 . (4)\nTheorem 2 (below) needs the strong assumption that, in favorable adaptation situations, the learned posterior agrees with the best target one \u03c1T\u2217 = argmin\u03c1RT (G\u03c1). Indeed, it relies on the following non-estimable term: \u03bb(\u03c1) = RT (G\u03c1T \u2217)+Eh\u223c\u03c1Eh\u2032\u223c\u03c1T \u2217 Ex\u223cSX I [ h(x)6=h\u2032(x) ] +\nEh\u223c\u03c1Eh\u2032\u223c\u03c1T \u2217 Ex\u223cTX I [ h(x) 6=h\u2032(x) ] .\n6In a symmetricH, for all h \u2208 H, its inverse \u2212h is also inH.\nTheorem 2 (Germain et al., 2013). Let H be a set of voters. For any domains S and T over X\u00d7 Y , we have, \u2200\u03c1 onH, RT (G\u03c1) \u2264 RS(G\u03c1) + dis\u03c1(SX, TX) + \u03bb(\u03c1).\nA compelling aspect of this PAC-Bayesian analysis is the suggested trade-off, which is function of \u03c1. Indeed, given a fixed instance space X and a fixed class H, apart from using importance weighting methods, the only way to minimize the bound of Theorem 1 is to find h \u2208H that minimizes RS(h). In Germain et al. (2013), the bound of Theorem 2 inspired an algorithm\u2014named PBDA\u2014selecting \u03c1 over H that achieves a trade-off between RS(G\u03c1) and dis\u03c1(SX, TX). However, the term \u03bb(\u03c1) does not appear in the optimization process of PBDA, even if it relies on the learned weight distribution \u03c1. It is assumed that the value of \u03bb(\u03c1) should be negligible (uniformly for all \u03c1) when adaptation is achievable. Nevertheless, this strong assumption cannot be verified because the best target posterior distribution \u03c1T \u2217 is unknown. This is a major weakness of the previous PAC-Bayesian work that our new approach overcomes."}, {"heading": "4. A New Domain Adaptation Perspective", "text": "In this section, we introduce an original approach to upperbound the non-estimable risk of a \u03c1-weighted majority vote on a target distribution T thanks to a term depending on its marginal distribution TX, another one on a related source domain S, and a term capturing the \u201cvolume\u201d of the source distribution uninformative for the target task. We base our bound on the expected disagreement dD(\u03c1) of Equation (2) and the expected joint error eD(\u03c1), defined as\neD(\u03c1) = E (x,y)\u223cD E h\u223c\u03c1 E h\u2032\u223c\u03c1\nI [ h(x) 6= y ] I [ h\u2032(x) 6= y ] . (5)\nIndeed, Lacasse et al. (2006); Germain et al. (2015) observed that, given a domain D on X\u00d7Y and a distribution \u03c1 onH, we can decompose the Gibbs risk as\nRD(G\u03c1)= 1 2 E(x,y)\u223cD E h\u223c\u03c1 E h\u2032\u223c\u03c1\nI [ h(x)6=y ] +I [ h\u2032(x) 6=y ] = E (x,y)\u223cD E h\u223c\u03c1 E h\u2032\u223c\u03c1 I [ h(x)6=h\u2032(x) ] +2 I [ h(x)6=y\u2227h\u2032(x)6=y ] 2\n= 12 dD(\u03c1) + eD(\u03c1) . (6)\nA key observation is that the voters\u2019 disagreement does not rely on labels; we can compute dD(\u03c1) using the marginal distribution DX. Thus, in the present domain adaptation context, we have access to dT (\u03c1) even if the target labels are unknown. However, the expected joint error can only be computed on the labeled source domain.\nDomains\u2019 divergence. In order to link the target joint error eT (\u03c1) with the source one eS(\u03c1), we weight the latter thanks to a divergence measure between the domains\n\u03b2q(T \u2016S) parametrized by a real value q > 0 :\n\u03b2q(T \u2016S) = [\nE (x,y)\u223cS ( T (x, y) S(x, y) )q ] 1q . (7)\nIt is worth noting that considering some q values allow us to recover well-known divergences. For instance, choosing q=2 relates our result to the \u03c72-distance, as \u03b22(T \u2016S)= \u221a \u03c72(T \u2016S) + 1 . Moreover, we can link \u03b2q(T \u2016S) to the Re\u0301nyi divergence7, which has led to generalization bounds in the context of importance weighting (Cortes et al., 2010). We denote the limit case q\u2192\u221e by\n\u03b2\u221e(T \u2016S) = sup (x,y)\u2208SUPP(S) ( T (x, y) S(x, y) ) ,\nwith SUPP(S) the support of S . The divergence \u03b2q(T \u2016S) handles the input space areas where the source domain support SUPP(S) is included in the target one SUPP(T ). It seems reasonable to assume that, when adaptation is achievable, such areas are fairly large. However, it is likely that SUPP(T ) is not entirely included in SUPP(S). We denote T \\S the distribution of (x, y)\u223cT conditional to (x, y)\u2208SUPP(T )\\SUPP(S). Since it is hardly conceivable to estimate the joint error eT \\S(\u03c1) without making extra assumptions, we define the worst risk for this unknown area\n\u03b7T \\S = Pr (x,y)\u223cT\n( (x, y) /\u2208 SUPP(S) ) sup h\u2208H RT \\S(h) . (8)\nEven if we cannot evaluate supHRT \\S(h), the value of \u03b7T \\S is necessarily lower than PrT ((x, y)/\u2208SUPP(S)).\nThe domain adaptation bound. Let us state the result underlying the domain adaptation perspective of this paper. Theorem 3. Let H be a hypothesis space, let S and T respectively be the source and the target domains on X\u00d7Y . Let q > 0 be a constant. We have, for all \u03c1 onH,\nRT (G\u03c1) \u2264 1\n2 dT (\u03c1) + \u03b2q(T \u2016S)\u00d7\n[ eS(\u03c1) ]1\u2212 1q + \u03b7T \\S ,\nwhere dT (\u03c1), eS(\u03c1), \u03b2q(T \u2016S) and \u03b7T \\S are respectively defined by Equations (2), (5), (7) and (8). Proof. Let us define t=E(x,y)\u223cT I [ (x, y)/\u2208SUPP(S) ] , then\n\u03b7\u03c1 = E (x,y)\u223cT\nI [ (x, y)/\u2208SUPP(S) ] E h\u223c\u03c1 E h\u2032\u223c\u03c1 I [ h(x)6=y ] I [ h\u2032(x)6=y ] = t E\n(x,y)\u223cT \\S E h\u223c\u03c1 E h\u2032\u223c\u03c1\nI [ h(x)6=y ] I [ h\u2032(x)6=y ] = t eT \\S(\u03c1)\n= t ( RT \\S(G\u03c1)\u2212 12dT \\S(\u03c1) ) \u2264 t sup\nh\u2208H RT \\S(h) = \u03b7T \\S .\nThen, with \u03b2q=\u03b2q(T \u2016S) and p such that 1p=1\u2212 1 q ,\neT (\u03c1) = E (x,y)\u223cT E h\u223c\u03c1 E h\u2032\u223c\u03c1\nI [ h(x) 6=y ] I [ h\u2032(x)6=y ] 7For q \u2265 0, we can show \u03b2q(T \u2016S)=2 q\u22121 q Dq(T \u2016S), where\nDq(T \u2016S) is the Re\u0301nyi divergence between T and S.\n= E (x,y)\u223cS T (x,y) S(x,y) Eh\u223c\u03c1 E h\u2032\u223c\u03c1\nI [ h(x)6=y ] I [ h\u2032(x)6=y ] +\u03b7\u03c1 (9)\n\u2264 \u03b2q [ E h\u223c\u03c1 E h\u2032\u223c\u03c1 E (x,y)\u223cS ( I [ h(x)6=y ] I [ h\u2032(x)6=y ])p]1p +\u03b7\u03c1 .\nLast line is due to Ho\u0308lder inequality. Finally, we remove the exponent from expression (I [ h(x) 6= y ] I [ h\u2032(x) 6= y ] )p without affecting its value, which is either 1 or 0, and the final result follows from Equation (6).\nNote that the bound of Theorem 3 is reached whenever the domains are equal (S = T ). Thus, when adaptation is not necessary, our analysis is still sound and non-degenerated:\nRS(G\u03c1) = RT (G\u03c1) \u2264 12 dT (\u03c1) + 1\u00d7 [eS(\u03c1)] 1 + 0\n= 12 dS(\u03c1) + eS(\u03c1) = RS(G\u03c1) .\nMeaningful quantities. Similarly to the previous results recalled in Section 3, our domain adaptation theorem bounds the target risk by a sum of three terms. However, our approach breaks the problem into atypical quantities: (i) The expected disagreement dT (\u03c1) captures second degree information about the target domain. (ii) The domains\u2019 divergence \u03b2q(T \u2016S) weights the influence of the expected joint error eS(\u03c1) of the source domain; the parameter q allows us to consider different relationships between \u03b2q(T \u2016S) and eS(\u03c1). (iii) The term \u03b7T \\S quantifies the worst feasible target error on the regions where the source domain is uninformative for the target one. In the current work, we assume that this area is small."}, {"heading": "5. Comparison With Related Works", "text": "In this section, we discuss how our domain adaptation bound can be related to some previous works."}, {"heading": "5.1. On the previous PAC-Bayesian bound", "text": "It is instructive to compare the new bound of Theorem 3 with the previous PAC-Bayesian domain adaptation bound of Theorem 2. In Theorem 3, the non-estimable terms are the domain divergence \u03b2q(T \u2016S) and the term \u03b7T \\S . Contrary to the non-controllable term \u03bb(\u03c1) of Theorem 2, these terms do not depend on the learned posterior distribution \u03c1: For every \u03c1 on H, \u03b2q(T \u2016S) and \u03b7T \\S are constant values measuring the relation between the domains. Moreover, the fact that the domain divergence \u03b2q(T \u2016S) is not an additive term but a multiplicative one (as opposed to dis\u03c1(SX, TX)+\u03bb(\u03c1) in Theorem 2) is a contribution of our new analysis. Consequently, \u03b2q(T \u2016S) can be viewed as a hyperparameter allowing us to tune the trade-off between the target voters\u2019 disagreement and the source joint error. Experiments of Section 8 confirm that this hyperparameter can be successfully selected."}, {"heading": "5.2. On some domain adaptation assumptions", "text": "In order to characterize which domain adaptation task may be learnable, Ben-David et al. (2012) presented three assumptions that can help domain adaptation. Our Theorem 3 does not rely on these assumptions, but they can be interpreted in our framework as discussed below. On the covariate shift. A domain adaptation task fulfills the covariate shift assumption (Shimodaira, 2000) if the source and target domains only differ in their marginals according to the input space, i.e., TY |x(y) = SY |x(y). In this scenario, one may estimate \u03b2q(TX\u2016SX), and even \u03b7T \\S , by using unsupervised density estimation methods. Interestingly, by also assuming that the domains share the same support, we have \u03b7T \\S=0. Then from Line (9) we obtain\nRT (G\u03c1)= 1 2 dT (\u03c1)+ E\nx\u223cSX\nTX(x) SX(x) E h\u223c\u03c1 E h\u2032\u223c\u03c1\nI [ h(x) 6=y ] I [ h\u2032(x)6=y ] ,\nwhich suggests a way to correct the shift between the domains by reweighting the labeled source distribution, while considering the information from the target disagreement. On the weight ratio. The weight ratio (Ben-David et al., 2012) of source and target domains, with respect to a collection of input space subsets B \u2286 2X, is given by\nCB(S, T ) = inf b\u2208B, TX(b) 6=0 SX(b) TX(b) .\nWhen CB(S, T ) is bounded away from 0, adaptation should be achievable under covariate shift. In this context, and when SUPP(S)= SUPP(T ), the limit case of \u03b2\u221e(T \u2016S) is equal to the inverse of the point-wise weight ratio obtained by letting B = {{x} : x \u2208 X} in CB(S, T ). Indeed, both \u03b2q and CB compare the densities of source and target domains, but provide distinct strategies to relax the point-wise weight ratio; the former by lowering the value of q and the latter by considering larger subspaces B. On the cluster assumption. A target domain fulfills the cluster assumption when examples of the same label belong to a common \u201carea\u201d of the input space, and the differently labeled \u201careas\u201d are well separated by low-density regions (formalized by the probabilistic Lipschitzness of Urner et al., 2011). Once specialized to linear classifiers, dT (\u03c1) behaves nicely in this context (see Section 7)."}, {"heading": "5.3. On representation learning", "text": "The main assumption underlying our domain adaptation algorithm exhibited in Section 7 is that the support of the target domain is mostly included in the support of the source domain, i.e., the value of the term \u03b7T \\S is small. When T \\S is sufficiently large to prevent proper adaptation, one could try to reduce its volume while taking care to preserve a good compromise between dT (\u03c1) and eS(\u03c1), using a representation learning approach, i.e., by projecting source and target examples into a new common space, as done for example by Chen et al. (2012); Ganin et al. (2016)."}, {"heading": "6. PAC-Bayesian Generalization Guarantees", "text": "To compute our domain adaptation bound, one needs to know the distributions S and TX, which is never the case in real life tasks. The PAC-Bayesian theory provides tools to convert the bound of Theorem 3 into a generalization bound on the target risk computable from a pair of sourcetarget samples (S, T )\u223c(S)ms\u00d7(TX)mt . To achieve this, we first provide generalization guarantees for dT (\u03c1) and eS(\u03c1). These results are presented as corollaries of Theorem 4 below, that generalizes a PAC-Bayesian theorem of Catoni (2007) to arbitrary loss functions.8 Indeed, Theorem 4, with `(h,x, y)=I [ h(x) 6=y ] and Equation (1), gives the usual bound on the Gibbs risk.\nTheorem 4. For any domain D over X\u00d7Y , any set of voters H, any prior \u03c0 over H, any loss ` : H\u00d7X\u00d7Y\u2192[0, 1], any real number c>0, with a probability at least 1\u2212\u03b4 over the choice of {(xi, yi)}mi=1\u223c(D)m, we have for all \u03c1 onH:\nE (x,y)\u223cD E h\u223c\u03c1 `(h,x, y)\n\u2264 c 1\u2212e\u2212c\n[ 1\nm m\u2211 i=1 E h\u223c\u03c1 `(h,xi, yi) + KL(\u03c1\u2016\u03c0) + ln 1\u03b4 m\u00d7 c\n] .\nNote that, similarly to McAllester & Keshet (2011), we could choose to restrict c \u2208 (0, 2) to obtain a slightly looser but simpler bound. Using e\u2212c \u2264 1 \u2212 c \u2212 12c\n2, an upper bound on the right hand side of above equation is given by\n1 1\u2212 12 c\n[ 1 m \u2211m i=1 Eh\u223c\u03c1 `(h,xi, yi) + KL(\u03c1\u2016\u03c0)+ln 1\u03b4 m\u00d7c ] .\nWe now exploit Theorem 4 to obtain generalization guarantees on the expected disagreement and the expected joint error. PAC-Bayesian bounds on these quantities appeared in Germain et al. (2015), but under different forms. In Corollary 5 below, we are especially interested in the possibility of controlling the trade-off\u2014between the empirical estimate computed on the samples and the complexity term KL(\u03c1\u2016\u03c0)\u2014with the help of parameters b and c. Corollary 5. For any domains S and T over X\u00d7Y , any set of voters H, any prior \u03c0 over H, any \u03b4\u2208(0, 1], any real numbers b > 0 and c > 0, we have: \u2014 with a probability at least 1\u2212\u03b4 over T \u223c (TX)mt ,\n\u2200\u03c1 onH, dT (\u03c1) \u2264 c\n1\u2212e\u2212c\n[ d\u0302T (\u03c1)+\n2KL(\u03c1\u2016\u03c0)+ln 1\u03b4 mt \u00d7 c\n] ,\n\u2014 with a probability at least 1\u2212\u03b4 over S \u223c (S)ms ,\n\u2200\u03c1 onH, eS(\u03c1) \u2264 b\n1\u2212e\u2212b\n[ e\u0302S(\u03c1)+\n2KL(\u03c1\u2016\u03c0)+ln 1\u03b4 ms \u00d7 b\n] ,\nwhere d\u0302T (\u03c1) and e\u0302S(\u03c1) are the empirical estimations of the target voters\u2019 disagreement and the source joint error.\n8To do so, we exploit a result of Maurer (2004) that allows to generalize PAC-Bayes theorems to arbitrary bounded loss function (see the proof of Theorem 4 in supplemental).\nProof. Given \u03c0 and \u03c1 over H, we consider a new prior \u03c02 and a new posterior \u03c12, both over H2, such that: \u2200hij = (hi, hj) \u2208 H2, \u03c02(hij) = \u03c0(hi)\u03c0(hj), and \u03c12(hij) = \u03c1(hi)\u03c1(hj). Thus, KL(\u03c12\u2016\u03c02) = 2KL(\u03c12\u2016\u03c02) (see Germain et al., 2015). Let us define two new loss functions for a \u201cpaired voter\u201d hij \u2208 H2:\n`d(hij ,x, y) = I [ hi(x) 6= hj(x) ] ,\nand `e(hij ,x, y) = I [ hi(x) 6= y ] \u00d7I [ hj(x) 6= y ] .\nThen, the bound on dT (\u03c1) is obtained from Theorem 4 with ` := `d, and Equation (2). The bound on eS(\u03c1) is similarly obtained with ` := `e and using Equation (5).\nFor algorithmic simplicity, we deal with Theorem 3 when q\u2192\u221e. Thanks to Corollary 5, we obtain the following generalization bound defined with respect to the empirical estimates of the target disagreement and the source joint error. Theorem 6. For any domains S and T over X\u00d7Y , any set of votersH, any prior \u03c0 overH, any \u03b4\u2208(0, 1], any b>0 and c>0, with a probability at least 1\u2212\u03b4 over the choices of S\u223c(S)ms and T\u223c(TX)mt , we have\n\u2200\u03c1 onH, RT (G\u03c1) \u2264 c\u2032 12 d\u0302T (\u03c1) + b \u2032 e\u0302S(\u03c1) + \u03b7T \\S + ( c\u2032\nmt\u00d7c+ b\u2032 ms\u00d7b )( 2 KL(\u03c1\u2016\u03c0) + ln 2\u03b4 ) ,\nwhere d\u0302T (\u03c1) and e\u0302S(\u03c1) are the empirical estimations of the target voters\u2019 disagreement and the source joint error, and b\u2032 = b\n1\u2212e\u2212b \u03b2\u221e(T \u2016S), and c \u2032 = c1\u2212e\u2212c .\nProof. We bound separately dT (\u03c1) and eS(\u03c1) using Corollary 5 (with probability 1\u2212 \u03b42 each), and then combine the two upper bounds according to Theorem 3.\nFrom an optimization perspective, the problem suggested by the bound of Theorem 6 is much more convenient to minimize than the PAC-Bayesian bound derived from Theorem 2 in Germain et al. (2013). The former is smoother than the latter: the absolute value related to the domain disagreement dis\u03c1(SX, TX) of Equation (4) disappears in benefit of the domain divergence \u03b2\u221e(T \u2016S), which is constant and can be considered as an hyperparameter of the algorithm. Additionally, Theorem 2 requires equal source and target sample sizes while Theorem 6 allows ms 6=mt. Moreover, recall that in Germain et al. (2013) the \u03c1-dependent non-constant term \u03bb(\u03c1) is ignored. In our new analysis, such compromise is not mandatory in order to apply the theoretical result to real problems, since the non-estimable term \u03b7T \\S is constant and does not depend on the learned \u03c1. Hence, we can neglect \u03b7T \\S without any impact on the optimization problem described in the next section. Beside, it is realistic to consider \u03b7T \\S as a small quantity in situations where the source and target supports are similar."}, {"heading": "7. Specialization to Linear Classifiers", "text": "In order to derive an algorithm, we now specialize the bounds of Theorems 3 and 6 to the risk of a linear classifier hw, defined by a weight vector w \u2208 Rd :\n\u2200x \u2208 X, hw(x) = sign (w \u00b7 x) .\nThe taken approach is the one privileged in numerous PACBayesian works (e.g., Langford & Shawe-Taylor, 2002; Ambroladze et al., 2006; McAllester & Keshet, 2011; Parrado-Herna\u0301ndez et al., 2012; Germain et al., 2009; 2013), as it makes the risk of the linear classifier hw and the risk of a (properly parametrized) majority vote coincide, while in the same time promoting large margin classifiers. To this end, let H be the set of all linear classifiers over the input space, H = { hw\u2032 | w\u2032 \u2208 Rd } , and let \u03c1w over H be a posterior distribution, resp. a prior distribution \u03c00, that is constrained to be a spherical Gaussian with identity covariance matrix centered on vector w, resp. 0,\n\u2200hw\u2032 \u2208 H, \u03c1w(hw\u2032) = (\n1\u221a 2\u03c0\n)d e\u2212 1 2\u2016w \u2032\u2212w\u20162 ,\nand \u03c00(hw\u2032) = (\n1\u221a 2\u03c0\n)d e\u2212 1 2\u2016w \u2032\u20162 .\nThe KL-divergence between \u03c1w and \u03c00 simply is\nKL(\u03c1w\u2016\u03c00) = 12\u2016w\u2016 2 . (10)\nThanks to this parameterization, the majority vote classifier B\u03c1w corresponds to the one of the linear classifier hw (see above cited PAC-Bayesian works). That is,\n\u2200x\u2208X,w\u2208H, hw(x) = sign [\nE hw\u2032\u223c\u03c1w hw\u2032(x)\n] =B\u03c1w(x) .\nThen, RD(hw) = RD(B\u03c1w) for any data distribution D. Moreover, Langford & Shawe-Taylor (2002) showed that the closely related Gibbs risk (Equation 1) is related to the linear classifier margin y w\u00b7x\u2016x\u2016 , as follows:\nRD(G\u03c1w) = E (x,y)\u223cD \u03a6 ( y w \u00b7 x \u2016x\u2016 ) , (11)\nwhere \u03a6(x)= 12\u2212 1 2 Erf ( x\u221a 2 ) , and Erf(x) = 2\u221a \u03c0 \u222b x 0 e\u2212t 2\ndt is the Gauss error function. Here, \u03a6(x) can be seen as a smooth surrogate\u2014sometimes called the probit loss (e.g., McAllester & Keshet, 2011)\u2014of the zero-one loss function I [ x \u2264 0 ] relying on y w\u00b7x\u2016x\u2016 . Note that \u2016w\u2016 plays an important role on the value of RD(G\u03c1w), but not on RD(hw). Indeed, RD(G\u03c1w) tends to RD(hw) as \u2016w\u2016 grows, which can provide very tight bounds (see the empirical analyses of Ambroladze et al., 2006; Germain et al., 2009). In the PAC-Bayesian context, \u2016w\u2016 turns out to be a measure of complexity of the learned classifier, as Equation (10) shows. We now seek to express the expected disagreement dD(\u03c1w) and the expected joint error eD(\u03c1w) of Equations (2)\nand (5) related to the parameterized distribution \u03c1w. As shown in Germain et al. (2013) the former is given by\ndD(\u03c1w) = E x\u223cDX \u03a6dis ( w \u00b7 x \u2016x\u2016 ) ,\nwhere \u03a6dis(x) = 2\u00d7\u03a6(x)\u00d7\u03a6(\u2212x). Following a similar approach, we obtain, for all w \u2208 R,\neD(\u03c1w) = E (x,y)\u223cD E h\u223c\u03c1w E h\u2032\u223c\u03c1w\nI [ h(x) 6=y ] I [ h\u2032(x) 6=y ] = E\n(x,y)\u223cD E h\u223c\u03c1w I [ h(x) 6=y ] E h\u2032\u223c\u03c1w I [ h\u2032(x)6=y ] = E\n(x,y)\u223cD \u03a6err ( y w \u00b7 x \u2016x\u2016 ) ,\nwith \u03a6err(x) = [ \u03a6(x) ]2 . As function \u03a6 in Equation (11), functions \u03a6err and \u03a6dis defined above can be interpreted as loss functions for linear classifiers (illustrated by Figure 1). Domain adaptation bound. Theorem 3 specialized to linear classifiers gives the following corollary. Note that, as mentioned above, RT (hw) = RT (B\u03c1w) \u2264 2 RT (G\u03c1w). Corollary 7. Let S and T respectively be the source and the target domains on X\u00d7Y . For all w \u2208 R, we have : RT (hw) \u2264 dT (\u03c1w) + 2\u03b2\u221e(T \u2016S)\u00d7 eS(\u03c1w) + 2 \u03b7T \\S ,\nFigure 1 leads to an insightful geometric interpretation of the domain adaptation trade-off promoted by Corollary 7. For fixed values of \u03b2\u221e(T \u2016S) and \u03b7T \\S , the target risk RT (hw) is upper-bounded by a (\u03b2\u221e-weighted) sum of two losses. The expected \u03a6err-loss (i.e., the joint error) is computed on the (labeled) source domain; it aims to label the source examples correctly, but is more permissive on the required margin than the \u03a6-loss (i.e., the Gibbs risk). The expected \u03a6dis-loss (i.e., the disagreement) is computed on the target (unlabeled) domain; it promotes large unsigned target margins. Thus, if a target domain fulfills the cluster assumption (described in Section 5.2), dT (\u03c1w) will be low when the decision boundary crosses a low-density region between the homogeneous labeled clusters. Hence, Corollary 7 reflects that some source errors may be allowed if, doing so, the separation of the target domain is improved. Generalization bound and learning algorithm. Theorem 6 specialized to linear classifiers gives the following.\nCorollary 8. For any domains S and T over X\u00d7Y , any \u03b4\u2208(0, 1], any a>0 and b>0, with a probability at least 1\u2212\u03b4 over the choices of S\u223c(S)ms and T\u223c(TX)mt , we have\n\u2200w \u2208 R : RT (hw) \u2264 c\u2032 d\u0302T (\u03c1w) + 2 b\u2032 e\u0302S(\u03c1w) + 2 \u03b7T \\S + 2 ( c\u2032\nmt\u00d7c + b\u2032 ms\u00d7b )( \u2016w\u20162 + ln 2\u03b4 ) .\nFor a source S={(xi, yi)}msi=1 and a target T={(x\u2032i)} mt i=1 samples of potentially different size, and some hyperparameters C>0, B>0, minimizing the next objective function w.r.t w\u2208R is equivalent to minimize the above bound.\nC d\u0302T (\u03c1w) +B e\u0302S(\u03c1w) + \u2016w\u20162 (12)\n= C mt\u2211 i=1 \u03a6dis ( w\u00b7x\u2032i \u2016x\u2032i\u2016 ) +B ms\u2211 i=1 \u03a6err ( yi w\u00b7xi \u2016xi\u2016 ) + \u2016w\u20162 .\nWe call the optimization of Equation (12) by gradient descent the DALC algorithm, for Domain Adaptation of Linear Classifiers. The kernel trick applies to DALC. That is, given a kernel k :Rd\u00d7Rd\u2192R, one can express a linear classifier in a RKHS9 by a dual weight vector \u03b1 \u2208 Rms+mt :\nhw(\u00b7) = sign [ ms\u2211 i=1 \u03b1ik(xi, \u00b7) + mt\u2211 i=1 \u03b1i+msk(x \u2032 i, \u00b7) ] .\nEven though the objective function is highly non-convex, we achieved good empirical results by minimizing the \u201ckernelized\u201d version of Equation (12) by gradient descent, with a uniform weight vector as a starting point. More details are given in the supplementary material."}, {"heading": "8. Experimental Results", "text": "Firstly, Figure 2 illustrates the behavior of the decision boundary of our algorithm DALC on an intertwining moons toy problem10, where each moon corresponds to a label.\n9It is non-trivial to show that the kernel trick holds when \u03c00 and \u03c1w are Gaussian over infinite-dimensional feature space. As mentioned by McAllester & Keshet (2011), it is, however, the case provided we consider Gaussian processes as measure of distributions \u03c00 and \u03c1w over (infinite)H.\n10We generate each pair of moons with the make moons function provided in scikit-learn (Pedregosa et al., 2011).\nThe target domain, for which we have no label, is a rotation of the source one. The figure shows clearly that DALC succeeds to adapt to the target domain, even for a rotation angle of 50\u25e6. We see that DALC does not rely on the restrictive covariate shift assumption, as some source examples are misclassified. This behavior illustrates the DALC trade-off in action, that concedes some errors on the source sample to lower the disagreement on the target sample.\nSecondly, we evaluate DALC on the classical Amazon.com Reviews benchmark (Blitzer et al., 2006) according to the setting used by Chen et al. (2011); Germain et al. (2013). This dataset contains reviews of four types of products (books, DVDs, electronics, and kitchen appliances) described with about 100, 000 attributes. Originally, the reviews were labeled with a rating from 1 to 5. Chen et al. (2011) proposed a simplified binary setting by regrouping ratings into two classes (products rated lower than 3 and products rated higher than 4). Moreover, they reduced the dimensionality to about 40,000 by only keeping the features appearing at least ten times for a given domain adaptation task. Finally, the data are pre-processed with a tf-idf re-weighting. A domain corresponds to a kind of product. Therefore, we perform twelve domain adaptation tasks. For instance, \u201cbooks\u2192DVD\u2019s\u201d is the task for which the source domain is \u201cbooks\u201d and the target one is \u201cDVDs\u201d. We compare DALC with the classical non-adaptive algorithm SVM (trained only on the source sample), the adaptive algorithm DASVM (Bruzzone & Marconcini, 2010), the adaptive cotraining CODA (Chen et al., 2011), and the PAC-Bayesian domain adaptation algorithm PBDA (Germain et al., 2013) based on Theorem 2. Note that, in Germain et al. (2013), DASVM has shown better accuracy than SVM, CODA and PBDA. Each parameter is selected with a grid search thanks to a usual cross-validation (CV) on the source sample for SVM, and thanks to a reverse validation procedure11 (RCV)\n11For details on the reverse validation procedure, see Bruzzone & Marconcini (2010); Zhong et al. (2010). Other details on our\nfor CODA, DASVM, PBDA, and DALC. The algorithms use a linear kernel and consider 2,000 labeled source examples and 2,000 unlabeled target examples. Table 1 reports the error rates of all the methods evaluated on the same separate target test sets proposed by Chen et al. (2011).\nAbove all, the adaptive approaches show the best result, implying that tackling this problem with a domain adaptation method is reasonable. Then, our new method DALC is the best algorithm overall on this task. Except for the two adaptive tasks between \u201celectronics\u201d and \u201cDVDs\u201d, DALC is either the best one (six times), or the second one (four times). Moreover, according to a Wilcoxon signed rank test with a 5% significance level, we obtain a probability of 89.5% that DALC is better than PBDA. This test tends to confirm that our new bound improves the analysis done previously in Germain et al. (2013), in addition to being more interpretable."}, {"heading": "9. Conclusion", "text": "We propose a new domain adaptation analysis for majority vote learning. It relies on an upper bound on the target risk, expressed as a trade-off between the voters\u2019 disagreement on the target domain, the voters\u2019 joint errors on the source one, and a term reflecting the worst case error in regions where the source domain is non-informative. To the best of our knowledge, a crucial novelty of our contribution is that the trade-off is controlled by the divergence \u03b2q(T \u2016S) (Equation 7) between the domains: The divergence is not an additive term (as in many domain adaptation bounds) but is a factor weighting the importance of the source information. Our analysis, combined with a PAC-Bayesian generalization bound, leads to a new domain adaptation algorithm for linear classifiers. The empirical experiments show that our new algorithm outperforms the previous PAC-Bayesian approach (Germain et al., 2013).\nAs future work, we first aim at investigating the case where the domains\u2019 divergence \u03b2q(T \u2016S) can be estimated, i.e., when the covariate shift assumption holds or when some target labels are available. In these scenarios, \u03b2q(T \u2016S) might not be considered as a hyperparameter to tune. Last but not least, the term \u03b7T \\S of our bound\u2014suggesting that the two domains should live in the same regions\u2014 can be dealt with a representation learning approach. As mentioned in Section 5.3, this could be an incentive to combine our learning algorithm with existing representation learning techniques. In another vein, considering an active learning setup (as in Berlind & Urner, 2015), one could query the labels of target examples to estimate the value bounded by \u03b7T \\S . We see this as a great source of inspiration for new algorithms for this learning paradigm.\nexperimental protocol are given in supplementary material."}, {"heading": "Acknowledgements", "text": "This work was supported in part by the French project LIVES ANR-15-CE23-0026-03, and in part by NSERC discovery grant 262067."}, {"heading": "A. Proof of Theorem 4", "text": "Proof. We use the following shorthand notation:\nLD(h) = E (x,y)\u223cD `(h,x, y)\nand\nLS(h) = 1\nm \u2211 (x,y)\u2208S `(h,x, y) .\nConsider any convex function \u2206 : [0, 1]\u00d7[0, 1] \u2192 R. Applying consecutively Jensen\u2019s Inequality and the change of measure inequality (see Seldin & Tishby (2010, Lemma 4) and McAllester (2013, Equation (20))), we obtain\n\u2200\u03c1 onH : m\u00d7\u2206 (\nE h\u223c\u03c1 LS(h), E h\u223c\u03c1 LD(h) ) \u2264 E\nh\u223c\u03c1 m\u00d7\u2206 (LS(h),LD(h)) \u2264 KL(\u03c1\u2016\u03c0) + ln [ X\u03c0(S) ] ,\nwith X\u03c0(S) = E\nh\u223c\u03c0 em\u00d7\u2206(LS(h),LD(h)).\nThen, Markov\u2019s Inequality gives\nPr S\u223cDm ( X\u03c0(S) \u2264 1\u03b4 ES\u2032\u223cDmX\u03c0(S \u2032) ) \u2265 1\u2212\u03b4 ,\nand\nE S\u2032\u223cDm\nX\u03c0(S \u2032) = E\nS\u2032\u223cDm E h\u223c\u03c0\nem\u00d7\u2206(LS\u2032 (h),LD(h))\n= E h\u223c\u03c0 E S\u2032\u223cDm\nem\u00d7\u2206(LS\u2032 (h),LD(h))\n\u2264 E h\u223c\u03c0 m\u2211 k=0 ( k m ) (LD(h))k(1\u2212LD(h))m\u2212kem\u00d7\u2206( k m ,LD(h)),\n(13)\nwhere the last inequality is due to Maurer (2004, Lemma 3) (we have an equality when the output of ` is in {0, 1}). As shown in Germain et al. (2009, Corollary 2.2), by fixing\n\u2206(q, p) = \u2212c\u00d7q \u2212 ln[1\u2212p (1\u2212e\u2212c)] ,\nLine 13 becomes equal to 1, and then E S\u2032\u223cDm\nX\u03c0(S \u2032) \u2264 1.\nHence,\nPr S\u223cDm\n( \u2200\u03c1 onH : \u2212c E\nh\u223c\u03c1 LS(h)\u2212 ln[1\u2212 E h\u223c\u03c1 LD(h) (1\u2212e\u2212c)]\n\u2264 KL(\u03c1\u2016\u03c0) + ln 1\u03b4\nm\n) \u2265 1\u2212\u03b4 .\nBy reorganizing the terms, we have, with probability 1\u2212\u03b4 over the choice of S \u2208 Dm,\n\u2200\u03c1 onH : E h\u223c\u03c1 LD(h)\n\u2264 1 1\u2212e\u2212c\n[ 1\u2212 exp ( \u2212c E\nh\u223c\u03c1 LS(h)\u2212 KL(\u03c1\u2016\u03c0) + ln 1\u03b4 m\n)] .\nThe final result is obtained by using the inequality 1\u2212 exp(\u2212z) \u2264 z.\nB. Using DALC with a kernel function Let S = {(xi, yi)}msi=1, T = {x\u2032i} mt i=1 and M = ms + mt. We will denote\nx# = { xi if # \u2264 ms (source examples) x\u2032#\u2212ms otherwise. (target examples)\nThe kernel trick allows us to work with dual weight vector \u03b1 \u2208 RM that is a linear classifier in an augmented space. Given a kernel k : Rd \u00d7 Rd \u2192 R, we have\nhw(\u00b7) = sign [ M\u2211 i=1 \u03b1ik(xi, \u00b7) ] .\nLet us denote K the kernel matrix of size M \u00d7 M such as Ki,j = k(xi,xj) . In that case, the objective function\u2014 Equation (13) of the main paper\u2014can be rewritten in term of the vector\n\u03b1 = (\u03b11, \u03b12, . . . \u03b1M)\nas\nC \u00d7 M\u2211\ni=ms\n\u03a6 (\u2211M j=1 \u03b1jKi,j\u221a\nKi,i\n) \u03a6 ( \u2212 \u2211M j=1 \u03b1jKi,j\u221a\nKi,i\n)\n+B \u00d7 ms\u2211 i=1\n[ \u03a6 ( yi \u2211M j=1 \u03b1jKi,j\u221a\nKi,i\n)]2 +\nM\u2211 i=1 M\u2211 j=1 \u03b1i\u03b1jKi,j .\nFor our experiments, we minimize this objective function using a Broyden-Fletcher-Goldfarb-Shanno method (BFGS) implemented in the scipy python library (Jones et al., 2001\u2013).\nWe initialize the optimization procedure at \u03b1i = 1M for all i \u2208 {1, . . . ,M}."}, {"heading": "C. Experimental Protocol", "text": "For obtaining the DALCRCV results of Table 1, the reverse validation procedure searches on a 20\u00d7 20 parameter grid for a C between 0.01 and 106 and a parameter B between 1.0 and 108, both on a logarithm scale. The results of the other algorithms are reported from Germain et al. (2013)."}], "references": [{"title": "Tighter PAC-Bayes bounds", "author": ["A. Ambroladze", "E. Parrado-Hern\u00e1ndez", "J. ShaweTaylor"], "venue": "In NIPS, pp", "citeRegEx": "Ambroladze et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Ambroladze et al\\.", "year": 2006}, {"title": "Analysis of representations for domain adaptation", "author": ["S. Ben-David", "J. Blitzer", "K. Crammer", "F. Pereira"], "venue": "In NIPS, pp", "citeRegEx": "Ben.David et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Ben.David et al\\.", "year": 2006}, {"title": "A theory of learning from different domains", "author": ["S. Ben-David", "J. Blitzer", "K. Crammer", "A. Kulesza", "F. Pereira", "Vaughan", "J. Wortman"], "venue": null, "citeRegEx": "Ben.David et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ben.David et al\\.", "year": 2010}, {"title": "Domain adaptation\u2013can quantity compensate for quality", "author": ["S. Ben-David", "S. Shalev-Shwartz", "R. Urner"], "venue": "In ISAIM,", "citeRegEx": "Ben.David et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ben.David et al\\.", "year": 2012}, {"title": "Active nearest neighbors in changing environments", "author": ["C. Berlind", "R. Urner"], "venue": "In ICML, pp", "citeRegEx": "Berlind and Urner,? \\Q2015\\E", "shortCiteRegEx": "Berlind and Urner", "year": 2015}, {"title": "Domain adaptation of natural language processing systems", "author": ["J. Blitzer"], "venue": "PhD thesis, UPenn,", "citeRegEx": "Blitzer,? \\Q2007\\E", "shortCiteRegEx": "Blitzer", "year": 2007}, {"title": "Domain adaptation with structural correspondence learning", "author": ["J. Blitzer", "R. McDonald", "F. Pereira"], "venue": "In EMNLP, pp", "citeRegEx": "Blitzer et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Blitzer et al\\.", "year": 2006}, {"title": "Domain adaptation problems: A DASVM classification technique and a circular validation strategy", "author": ["L. Bruzzone", "M. Marconcini"], "venue": "IEEE Trans. Pattern Anal. Mach. Intel.,", "citeRegEx": "Bruzzone and Marconcini,? \\Q2010\\E", "shortCiteRegEx": "Bruzzone and Marconcini", "year": 2010}, {"title": "PAC-Bayesian supervised classification: the thermodynamics of statistical learning, volume 56", "author": ["O. Catoni"], "venue": "Inst. of Mathematical Statistic,", "citeRegEx": "Catoni,? \\Q2007\\E", "shortCiteRegEx": "Catoni", "year": 2007}, {"title": "Co-training for domain adaptation", "author": ["M. Chen", "K.Q. Weinberger", "J. Blitzer"], "venue": "In NIPS, pp", "citeRegEx": "Chen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2011}, {"title": "Marginalized denoising autoencoders for domain adaptation", "author": ["M. Chen", "Z.E. Xu", "K.Q. Weinberger", "F. Sha"], "venue": "In ICML, pp", "citeRegEx": "Chen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2012}, {"title": "Domain adaptation and sample bias correction theory and algorithm for regression", "author": ["C. Cortes", "M. Mohri"], "venue": "Theor. Comput. Sci.,", "citeRegEx": "Cortes and Mohri,? \\Q2014\\E", "shortCiteRegEx": "Cortes and Mohri", "year": 2014}, {"title": "Learning bounds for importance weighting", "author": ["C. Cortes", "Y. Mansour", "M. Mohri"], "venue": "In NIPS, pp", "citeRegEx": "Cortes et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cortes et al\\.", "year": 2010}, {"title": "Adaptation algorithm and theory based on generalized discrepancy", "author": ["C. Cortes", "M. Mohri", "Medina", "A. Mu\u00f1oz"], "venue": "In ACM SIGKDD,", "citeRegEx": "Cortes et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cortes et al\\.", "year": 2015}, {"title": "Frustratingly easy domain adaptation", "author": ["III H. Daum\u00e9"], "venue": "In ACL,", "citeRegEx": "Daum\u00e9,? \\Q2007\\E", "shortCiteRegEx": "Daum\u00e9", "year": 2007}, {"title": "Unsupervised domain adaptation by backpropagation", "author": ["Y. Ganin", "V.S. Lempitsky"], "venue": "In ICML, pp", "citeRegEx": "Ganin and Lempitsky,? \\Q2015\\E", "shortCiteRegEx": "Ganin and Lempitsky", "year": 2015}, {"title": "PAC-Bayesian learning of linear classifiers", "author": ["P. Germain", "A. Lacasse", "F. Laviolette", "M. Marchand"], "venue": "In ICML, pp", "citeRegEx": "Germain et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Germain et al\\.", "year": 2009}, {"title": "A PAC-Bayesian approach for domain adaptation with specialization to linear classifiers", "author": ["P. Germain", "A. Habrard", "F. Laviolette", "E. Morvant"], "venue": "In ICML,", "citeRegEx": "Germain et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Germain et al\\.", "year": 2013}, {"title": "Risk bounds for the majority vote: From a PAC-Bayesian analysis to a learning", "author": ["P. Germain", "A. Lacasse", "F. Laviolette", "Marchand", "Roy", "J.-F"], "venue": null, "citeRegEx": "Germain et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Germain et al\\.", "year": 2015}, {"title": "A PAC-Bayesian margin bound for linear classifiers: Why svms work", "author": ["R. Herbrich", "T. Graepel"], "venue": "In NIPS, pp", "citeRegEx": "Herbrich and Graepel,? \\Q2000\\E", "shortCiteRegEx": "Herbrich and Graepel", "year": 2000}, {"title": "Correcting sample selection bias by unlabeled data", "author": ["J. Huang", "A. Smola", "A. Gretton", "K. Borgwardt", "B. Sch\u00f6lkopf"], "venue": "In NIPS, pp", "citeRegEx": "Huang et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2006}, {"title": "A literature survey on domain adaptation of statistical classifiers", "author": ["J. Jiang"], "venue": null, "citeRegEx": "Jiang,? \\Q2008\\E", "shortCiteRegEx": "Jiang", "year": 2008}, {"title": "SciPy: Open source scientific tools for Python, 2001", "author": ["E. Jones", "T. Oliphant", "P Peterson"], "venue": "URL http: //www.scipy.org/", "citeRegEx": "Jones et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Jones et al\\.", "year": 2001}, {"title": "PAC-Bayes bounds for the risk of the majority vote and the variance of the Gibbs classifier", "author": ["A. Lacasse", "F. Laviolette", "M. Marchand", "P. Germain", "N. Usunier"], "venue": "In NIPS, pp", "citeRegEx": "Lacasse et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Lacasse et al\\.", "year": 2006}, {"title": "PAC-Bayes & margins", "author": ["J. Langford", "J. Shawe-Taylor"], "venue": "In NIPS, pp", "citeRegEx": "Langford and Shawe.Taylor,? \\Q2002\\E", "shortCiteRegEx": "Langford and Shawe.Taylor", "year": 2002}, {"title": "A Bayesian divergence prior for classiffier adaptation", "author": ["X. Li", "J. Bilmes"], "venue": "In AISTATS, pp", "citeRegEx": "Li and Bilmes,? \\Q2007\\E", "shortCiteRegEx": "Li and Bilmes", "year": 2007}, {"title": "Evigan: a hidden variable model for integrating gene evidence for eukaryotic gene", "author": ["Q. Liu", "A.J. Mackey", "D.S. Roos", "F. Pereira"], "venue": "prediction. Bioinformatics,", "citeRegEx": "Liu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2008}, {"title": "Domain adaptation: Learning bounds and algorithms", "author": ["Y. Mansour", "M. Mohri", "A. Rostamizadeh"], "venue": "In COLT,", "citeRegEx": "Mansour et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mansour et al\\.", "year": 2009}, {"title": "A literature review of domain adaptation with unlabeled data", "author": ["A. Margolis"], "venue": null, "citeRegEx": "Margolis,? \\Q2011\\E", "shortCiteRegEx": "Margolis", "year": 2011}, {"title": "A note on the PAC-Bayesian theorem", "author": ["A. Maurer"], "venue": "CoRR, cs.LG/0411099,", "citeRegEx": "Maurer,? \\Q2004\\E", "shortCiteRegEx": "Maurer", "year": 2004}, {"title": "A PAC-Bayesian tutorial with a dropout", "author": ["D. McAllester"], "venue": "bound. CoRR,", "citeRegEx": "McAllester,? \\Q2013\\E", "shortCiteRegEx": "McAllester", "year": 2013}, {"title": "Generalization bounds and consistency for latent structural probit and ramp loss", "author": ["D.A. McAllester", "J. Keshet"], "venue": "In NIPS,", "citeRegEx": "McAllester and Keshet,? \\Q2011\\E", "shortCiteRegEx": "McAllester and Keshet", "year": 2011}, {"title": "Parsimonious Unsupervised and Semi-Supervised Domain Adaptation with Good Similarity Functions", "author": ["E. Morvant", "A. Habrard", "S. Ayache"], "venue": "KAIS, 33(2):309\u2013349,", "citeRegEx": "Morvant et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Morvant et al\\.", "year": 2012}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "T. Knowl. Data En.,", "citeRegEx": "Pan and Yang,? \\Q2010\\E", "shortCiteRegEx": "Pan and Yang", "year": 2010}, {"title": "PAC-Bayes bounds with data dependent", "author": ["E. Parrado-Hern\u00e1ndez", "A. Ambroladze", "J. Shawe-Taylor", "S. Sun"], "venue": "priors. JMLR,", "citeRegEx": "Parrado.Hern\u00e1ndez et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Parrado.Hern\u00e1ndez et al\\.", "year": 2012}, {"title": "Visual domain adaptation: A survey of recent advances", "author": ["V.M. Patel", "R. Gopalan", "R. Li", "R. Chellappa"], "venue": "IEEE Signal Proc. Mag.,", "citeRegEx": "Patel et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Patel et al\\.", "year": 2015}, {"title": "Dataset shift in machine learning", "author": ["J. Quionero-Candela", "M. Sugiyama", "A. Schwaighofer", "N.D. Lawrence"], "venue": null, "citeRegEx": "Quionero.Candela et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Quionero.Candela et al\\.", "year": 2009}, {"title": "PAC-Bayesian analysis of coclustering and beyond", "author": ["Y. Seldin", "N. Tishby"], "venue": "JMLR, 11:3595\u20133646,", "citeRegEx": "Seldin and Tishby,? \\Q2010\\E", "shortCiteRegEx": "Seldin and Tishby", "year": 2010}, {"title": "Improving predictive inference under covariate shift by weighting the log-likelihood function", "author": ["H. Shimodaira"], "venue": "J. Statist. Plann. Inference,", "citeRegEx": "Shimodaira,? \\Q2000\\E", "shortCiteRegEx": "Shimodaira", "year": 2000}, {"title": "Direct importance estimation with model selection and its application to covariate shift adaptation", "author": ["M. Sugiyama", "S. Nakajima", "H. Kashima", "P. von B\u00fcnau", "M. Kawanabe"], "venue": "In NIPS,", "citeRegEx": "Sugiyama et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Sugiyama et al\\.", "year": 2007}, {"title": "Access to unlabeled data can speed up prediction time", "author": ["R. Urner", "S. Shalev-Shwartz", "S. Ben-David"], "venue": "In ICML, pp", "citeRegEx": "Urner et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Urner et al\\.", "year": 2011}, {"title": "Generalization bounds for domain adaptation", "author": ["C. Zhang", "L. Zhang", "J. Ye"], "venue": "In NIPS, pp", "citeRegEx": "Zhang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2012}, {"title": "Cross validation framework to choose amongst models and datasets for transfer learning", "author": ["E. Zhong", "W. Fan", "Q. Yang", "O. Verscheure", "J. Ren"], "venue": "In ECML-PKDD,", "citeRegEx": "Zhong et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zhong et al\\.", "year": 2010}, {"title": "Applying consecutively Jensen\u2019s Inequality and the change of measure inequality", "author": [], "venue": "(see Seldin & Tishby (2010,", "citeRegEx": "h et al\\.,? \\Q2013\\E", "shortCiteRegEx": "h et al\\.", "year": 2013}, {"title": "For our experiments, we minimize this objective function using a Broyden-Fletcher-Goldfarb-Shanno method (BFGS) implemented in the scipy python library", "author": ["\u03b1i\u03b1jKi"], "venue": null, "citeRegEx": "\u03b1i\u03b1jKi and .,? \\Q2001\\E", "shortCiteRegEx": "\u03b1i\u03b1jKi and .", "year": 2001}], "referenceMentions": [{"referenceID": 21, "context": "Machine learning practitioners are commonly exposed to the issue of domain adaptation1 (Jiang, 2008; Margolis, 2011): One usually learns a model from a corpus, i.", "startOffset": 87, "endOffset": 116}, {"referenceID": 28, "context": "Machine learning practitioners are commonly exposed to the issue of domain adaptation1 (Jiang, 2008; Margolis, 2011): One usually learns a model from a corpus, i.", "startOffset": 87, "endOffset": 116}, {"referenceID": 35, "context": "Therefore, domain adaptation is widely studied in a lot of application fields like computer vision (Patel et al., 2015; Ganin & Lempitsky, 2015), bioinformatics (Liu et al.", "startOffset": 99, "endOffset": 144}, {"referenceID": 26, "context": ", 2015; Ganin & Lempitsky, 2015), bioinformatics (Liu et al., 2008), natural language processing (Blitzer, 2007; Daum\u00e9 III, 2007), etc.", "startOffset": 49, "endOffset": 67}, {"referenceID": 5, "context": ", 2008), natural language processing (Blitzer, 2007; Daum\u00e9 III, 2007), etc.", "startOffset": 37, "endOffset": 69}, {"referenceID": 36, "context": "Domain adaptation is associated with transfer learning (Pan & Yang, 2010; Quionero-Candela et al., 2009).", "startOffset": 55, "endOffset": 104}, {"referenceID": 20, "context": "This is generally performed by reweighting the importance of labeled data (Huang et al., 2006; Sugiyama et al., 2007; Cortes et al., 2010; 2015), and/or by learning a common representation for the source and target distributions (Chen et al.", "startOffset": 74, "endOffset": 144}, {"referenceID": 39, "context": "This is generally performed by reweighting the importance of labeled data (Huang et al., 2006; Sugiyama et al., 2007; Cortes et al., 2010; 2015), and/or by learning a common representation for the source and target distributions (Chen et al.", "startOffset": 74, "endOffset": 144}, {"referenceID": 12, "context": "This is generally performed by reweighting the importance of labeled data (Huang et al., 2006; Sugiyama et al., 2007; Cortes et al., 2010; 2015), and/or by learning a common representation for the source and target distributions (Chen et al.", "startOffset": 74, "endOffset": 144}, {"referenceID": 10, "context": ", 2010; 2015), and/or by learning a common representation for the source and target distributions (Chen et al., 2012; Ganin et al., 2016), and/or by minimizing a measure of divergence between the distributions (Morvant et al.", "startOffset": 98, "endOffset": 137}, {"referenceID": 32, "context": ", 2016), and/or by minimizing a measure of divergence between the distributions (Morvant et al., 2012; Germain et al., 2013; Cortes & Mohri, 2014).", "startOffset": 80, "endOffset": 146}, {"referenceID": 17, "context": ", 2016), and/or by minimizing a measure of divergence between the distributions (Morvant et al., 2012; Germain et al., 2013; Cortes & Mohri, 2014).", "startOffset": 80, "endOffset": 146}, {"referenceID": 27, "context": "The divergence-based approach has especially been explored to derive generalization bounds for domain adaptation (e.g., Ben-David et al., 2006; 2010; Mansour et al., 2009; Li & Bilmes, 2007; Zhang et al., 2012).", "startOffset": 113, "endOffset": 210}, {"referenceID": 41, "context": "The divergence-based approach has especially been explored to derive generalization bounds for domain adaptation (e.g., Ben-David et al., 2006; 2010; Mansour et al., 2009; Li & Bilmes, 2007; Zhang et al., 2012).", "startOffset": 113, "endOffset": 210}, {"referenceID": 17, "context": "Recently, this issue has been studied through the PAC-Bayesian framework (Germain et al., 2013), which focuses on learning weighted majority votes2 without target label.", "startOffset": 73, "endOffset": 95}, {"referenceID": 1, "context": ", Ben-David et al., 2006; 2010; Mansour et al., 2009; Li & Bilmes, 2007; Zhang et al., 2012). Recently, this issue has been studied through the PAC-Bayesian framework (Germain et al., 2013), which focuses on learning weighted majority votes2 without target label. Even the latter result opened the door to tackle domain adaptation in a PAC-Bayesian fashion, it shares the same philosophy as the seminal works of Ben-David et al. (2006; 2010); Mansour et al. (2009): The risk of the target model is upper-bounded jointly by the model\u2019s risk on the source distribution, the divergence between the marginal distributions, and a nonestimable term3 related to the ability to adapt in the current space.", "startOffset": 2, "endOffset": 465}, {"referenceID": 1, "context": ", Ben-David et al., 2006; 2010; Mansour et al., 2009; Li & Bilmes, 2007; Zhang et al., 2012). Recently, this issue has been studied through the PAC-Bayesian framework (Germain et al., 2013), which focuses on learning weighted majority votes2 without target label. Even the latter result opened the door to tackle domain adaptation in a PAC-Bayesian fashion, it shares the same philosophy as the seminal works of Ben-David et al. (2006; 2010); Mansour et al. (2009): The risk of the target model is upper-bounded jointly by the model\u2019s risk on the source distribution, the divergence between the marginal distributions, and a nonestimable term3 related to the ability to adapt in the current space. Note that Li & Bilmes (2007) proposed a PACBayesian generalization bound for domain adaptation but they considered target labels.", "startOffset": 2, "endOffset": 727}, {"referenceID": 16, "context": "More precisely, we adopt the PACBayesian domain adaptation setting previously studied in Germain et al. (2013). GivenH, a set of voters h : X\u2192 Y , the elements of this approach are a prior distribution \u03c0 on H, a pair of source-target learning samples (S, T ) and a posterior distribution \u03c1 on H.", "startOffset": 89, "endOffset": 111}, {"referenceID": 20, "context": "To address this issue, Lacasse et al. (2006) (refined in Germain et al.", "startOffset": 23, "endOffset": 45}, {"referenceID": 16, "context": "The quantity dD(\u03c1) is also used in the domain adaptation bound of Germain et al. (2013) to measure divergence between distributions.", "startOffset": 66, "endOffset": 88}, {"referenceID": 1, "context": "Ben-David et al. (2006) assumed that the domains are related in the sense that there exists a (unknown) model performing well on both domains.", "startOffset": 0, "endOffset": 24}, {"referenceID": 1, "context": "Theorem 1 (Ben-David et al., 2006; 2010).", "startOffset": 10, "endOffset": 40}, {"referenceID": 27, "context": "Pursuing in the same line of research, Mansour et al. (2009) generalizes the H\u2206H-distance to real-valued loss functions L : [\u22121, 1] \u2192 R, to express a similar theorem for regression.", "startOffset": 39, "endOffset": 61}, {"referenceID": 27, "context": "The accuracy of the Mansour et al. (2009)\u2019s bound also relies on a non-estimable term assumed to be low when adaptation is achievable.", "startOffset": 20, "endOffset": 42}, {"referenceID": 16, "context": "Building on previous domain adaptation analyses, Germain et al. (2013) derived a PAC-Bayesian domain adaptation bound.", "startOffset": 49, "endOffset": 71}, {"referenceID": 17, "context": "Theorem 2 (Germain et al., 2013).", "startOffset": 10, "endOffset": 32}, {"referenceID": 16, "context": "In Germain et al. (2013), the bound of Theorem 2 inspired an algorithm\u2014named PBDA\u2014selecting \u03c1 over H that achieves a trade-off between RS(G\u03c1) and dis\u03c1(SX, TX).", "startOffset": 3, "endOffset": 25}, {"referenceID": 20, "context": "Indeed, Lacasse et al. (2006); Germain et al.", "startOffset": 8, "endOffset": 30}, {"referenceID": 16, "context": "(2006); Germain et al. (2015) observed that, given a domain D on X\u00d7Y and a distribution \u03c1 onH, we can decompose the Gibbs risk as", "startOffset": 8, "endOffset": 30}, {"referenceID": 12, "context": "Moreover, we can link \u03b2q(T \u2016S) to the R\u00e9nyi divergence7, which has led to generalization bounds in the context of importance weighting (Cortes et al., 2010).", "startOffset": 135, "endOffset": 156}, {"referenceID": 38, "context": "A domain adaptation task fulfills the covariate shift assumption (Shimodaira, 2000) if the source and target domains only differ in their marginals according to the input space, i.", "startOffset": 65, "endOffset": 83}, {"referenceID": 1, "context": "In order to characterize which domain adaptation task may be learnable, Ben-David et al. (2012) presented three assumptions that can help domain adaptation.", "startOffset": 72, "endOffset": 96}, {"referenceID": 3, "context": "The weight ratio (Ben-David et al., 2012) of source and target domains, with respect to a collection of input space subsets B \u2286 2, is given by", "startOffset": 17, "endOffset": 41}, {"referenceID": 9, "context": ", by projecting source and target examples into a new common space, as done for example by Chen et al. (2012); Ganin et al.", "startOffset": 91, "endOffset": 110}, {"referenceID": 9, "context": ", by projecting source and target examples into a new common space, as done for example by Chen et al. (2012); Ganin et al. (2016). 6.", "startOffset": 91, "endOffset": 131}, {"referenceID": 8, "context": "These results are presented as corollaries of Theorem 4 below, that generalizes a PAC-Bayesian theorem of Catoni (2007) to arbitrary loss functions.", "startOffset": 106, "endOffset": 120}, {"referenceID": 30, "context": "Note that, similarly to McAllester & Keshet (2011), we could choose to restrict c \u2208 (0, 2) to obtain a slightly looser but simpler bound.", "startOffset": 24, "endOffset": 51}, {"referenceID": 16, "context": "PAC-Bayesian bounds on these quantities appeared in Germain et al. (2015), but under different forms.", "startOffset": 52, "endOffset": 74}, {"referenceID": 29, "context": "To do so, we exploit a result of Maurer (2004) that allows to generalize PAC-Bayes theorems to arbitrary bounded loss function (see the proof of Theorem 4 in supplemental).", "startOffset": 33, "endOffset": 47}, {"referenceID": 16, "context": "From an optimization perspective, the problem suggested by the bound of Theorem 6 is much more convenient to minimize than the PAC-Bayesian bound derived from Theorem 2 in Germain et al. (2013). The former is smoother than the latter: the absolute value related to the domain disagreement dis\u03c1(SX, TX) of Equation (4) disappears in benefit of the domain divergence \u03b2\u221e(T \u2016S), which is constant and can be considered as an hyperparameter of the algorithm.", "startOffset": 172, "endOffset": 194}, {"referenceID": 16, "context": "From an optimization perspective, the problem suggested by the bound of Theorem 6 is much more convenient to minimize than the PAC-Bayesian bound derived from Theorem 2 in Germain et al. (2013). The former is smoother than the latter: the absolute value related to the domain disagreement dis\u03c1(SX, TX) of Equation (4) disappears in benefit of the domain divergence \u03b2\u221e(T \u2016S), which is constant and can be considered as an hyperparameter of the algorithm. Additionally, Theorem 2 requires equal source and target sample sizes while Theorem 6 allows ms 6=mt. Moreover, recall that in Germain et al. (2013) the \u03c1-dependent non-constant term \u03bb(\u03c1) is ignored.", "startOffset": 172, "endOffset": 603}, {"referenceID": 0, "context": "The taken approach is the one privileged in numerous PACBayesian works (e.g., Langford & Shawe-Taylor, 2002; Ambroladze et al., 2006; McAllester & Keshet, 2011; Parrado-Hern\u00e1ndez et al., 2012; Germain et al., 2009; 2013), as it makes the risk of the linear classifier hw and the risk of a (properly parametrized) majority vote coincide, while in the same time promoting large margin classifiers.", "startOffset": 71, "endOffset": 220}, {"referenceID": 34, "context": "The taken approach is the one privileged in numerous PACBayesian works (e.g., Langford & Shawe-Taylor, 2002; Ambroladze et al., 2006; McAllester & Keshet, 2011; Parrado-Hern\u00e1ndez et al., 2012; Germain et al., 2009; 2013), as it makes the risk of the linear classifier hw and the risk of a (properly parametrized) majority vote coincide, while in the same time promoting large margin classifiers.", "startOffset": 71, "endOffset": 220}, {"referenceID": 16, "context": "The taken approach is the one privileged in numerous PACBayesian works (e.g., Langford & Shawe-Taylor, 2002; Ambroladze et al., 2006; McAllester & Keshet, 2011; Parrado-Hern\u00e1ndez et al., 2012; Germain et al., 2009; 2013), as it makes the risk of the linear classifier hw and the risk of a (properly parametrized) majority vote coincide, while in the same time promoting large margin classifiers.", "startOffset": 71, "endOffset": 220}, {"referenceID": 16, "context": "Indeed, RD(G\u03c1w) tends to RD(hw) as \u2016w\u2016 grows, which can provide very tight bounds (see the empirical analyses of Ambroladze et al., 2006; Germain et al., 2009).", "startOffset": 82, "endOffset": 159}, {"referenceID": 17, "context": "The blue dashed line shows the decision boundaries of algorithm PBDA (Germain et al., 2013).", "startOffset": 69, "endOffset": 91}, {"referenceID": 16, "context": "As shown in Germain et al. (2013) the former is given by", "startOffset": 12, "endOffset": 34}, {"referenceID": 30, "context": "As mentioned by McAllester & Keshet (2011), it is, however, the case provided we consider Gaussian processes as measure of distributions \u03c00 and \u03c1w over (infinite)H.", "startOffset": 16, "endOffset": 43}, {"referenceID": 6, "context": "com Reviews benchmark (Blitzer et al., 2006) according to the setting used by Chen et al.", "startOffset": 22, "endOffset": 44}, {"referenceID": 9, "context": "We compare DALC with the classical non-adaptive algorithm SVM (trained only on the source sample), the adaptive algorithm DASVM (Bruzzone & Marconcini, 2010), the adaptive cotraining CODA (Chen et al., 2011), and the PAC-Bayesian domain adaptation algorithm PBDA (Germain et al.", "startOffset": 188, "endOffset": 207}, {"referenceID": 17, "context": ", 2011), and the PAC-Bayesian domain adaptation algorithm PBDA (Germain et al., 2013) based on Theorem 2.", "startOffset": 63, "endOffset": 85}, {"referenceID": 5, "context": "com Reviews benchmark (Blitzer et al., 2006) according to the setting used by Chen et al. (2011); Germain et al.", "startOffset": 23, "endOffset": 97}, {"referenceID": 5, "context": "com Reviews benchmark (Blitzer et al., 2006) according to the setting used by Chen et al. (2011); Germain et al. (2013). This dataset contains reviews of four types of products (books, DVDs, electronics, and kitchen appliances) described with about 100, 000 attributes.", "startOffset": 23, "endOffset": 120}, {"referenceID": 5, "context": "com Reviews benchmark (Blitzer et al., 2006) according to the setting used by Chen et al. (2011); Germain et al. (2013). This dataset contains reviews of four types of products (books, DVDs, electronics, and kitchen appliances) described with about 100, 000 attributes. Originally, the reviews were labeled with a rating from 1 to 5. Chen et al. (2011) proposed a simplified binary setting by regrouping ratings into two classes (products rated lower than 3 and products rated higher than 4).", "startOffset": 23, "endOffset": 353}, {"referenceID": 5, "context": "com Reviews benchmark (Blitzer et al., 2006) according to the setting used by Chen et al. (2011); Germain et al. (2013). This dataset contains reviews of four types of products (books, DVDs, electronics, and kitchen appliances) described with about 100, 000 attributes. Originally, the reviews were labeled with a rating from 1 to 5. Chen et al. (2011) proposed a simplified binary setting by regrouping ratings into two classes (products rated lower than 3 and products rated higher than 4). Moreover, they reduced the dimensionality to about 40,000 by only keeping the features appearing at least ten times for a given domain adaptation task. Finally, the data are pre-processed with a tf-idf re-weighting. A domain corresponds to a kind of product. Therefore, we perform twelve domain adaptation tasks. For instance, \u201cbooks\u2192DVD\u2019s\u201d is the task for which the source domain is \u201cbooks\u201d and the target one is \u201cDVDs\u201d. We compare DALC with the classical non-adaptive algorithm SVM (trained only on the source sample), the adaptive algorithm DASVM (Bruzzone & Marconcini, 2010), the adaptive cotraining CODA (Chen et al., 2011), and the PAC-Bayesian domain adaptation algorithm PBDA (Germain et al., 2013) based on Theorem 2. Note that, in Germain et al. (2013), DASVM has shown better accuracy than SVM, CODA and PBDA.", "startOffset": 23, "endOffset": 1257}, {"referenceID": 5, "context": "com Reviews benchmark (Blitzer et al., 2006) according to the setting used by Chen et al. (2011); Germain et al. (2013). This dataset contains reviews of four types of products (books, DVDs, electronics, and kitchen appliances) described with about 100, 000 attributes. Originally, the reviews were labeled with a rating from 1 to 5. Chen et al. (2011) proposed a simplified binary setting by regrouping ratings into two classes (products rated lower than 3 and products rated higher than 4). Moreover, they reduced the dimensionality to about 40,000 by only keeping the features appearing at least ten times for a given domain adaptation task. Finally, the data are pre-processed with a tf-idf re-weighting. A domain corresponds to a kind of product. Therefore, we perform twelve domain adaptation tasks. For instance, \u201cbooks\u2192DVD\u2019s\u201d is the task for which the source domain is \u201cbooks\u201d and the target one is \u201cDVDs\u201d. We compare DALC with the classical non-adaptive algorithm SVM (trained only on the source sample), the adaptive algorithm DASVM (Bruzzone & Marconcini, 2010), the adaptive cotraining CODA (Chen et al., 2011), and the PAC-Bayesian domain adaptation algorithm PBDA (Germain et al., 2013) based on Theorem 2. Note that, in Germain et al. (2013), DASVM has shown better accuracy than SVM, CODA and PBDA. Each parameter is selected with a grid search thanks to a usual cross-validation (CV) on the source sample for SVM, and thanks to a reverse validation procedure11 (RCV) For details on the reverse validation procedure, see Bruzzone & Marconcini (2010); Zhong et al.", "startOffset": 23, "endOffset": 1566}, {"referenceID": 5, "context": "com Reviews benchmark (Blitzer et al., 2006) according to the setting used by Chen et al. (2011); Germain et al. (2013). This dataset contains reviews of four types of products (books, DVDs, electronics, and kitchen appliances) described with about 100, 000 attributes. Originally, the reviews were labeled with a rating from 1 to 5. Chen et al. (2011) proposed a simplified binary setting by regrouping ratings into two classes (products rated lower than 3 and products rated higher than 4). Moreover, they reduced the dimensionality to about 40,000 by only keeping the features appearing at least ten times for a given domain adaptation task. Finally, the data are pre-processed with a tf-idf re-weighting. A domain corresponds to a kind of product. Therefore, we perform twelve domain adaptation tasks. For instance, \u201cbooks\u2192DVD\u2019s\u201d is the task for which the source domain is \u201cbooks\u201d and the target one is \u201cDVDs\u201d. We compare DALC with the classical non-adaptive algorithm SVM (trained only on the source sample), the adaptive algorithm DASVM (Bruzzone & Marconcini, 2010), the adaptive cotraining CODA (Chen et al., 2011), and the PAC-Bayesian domain adaptation algorithm PBDA (Germain et al., 2013) based on Theorem 2. Note that, in Germain et al. (2013), DASVM has shown better accuracy than SVM, CODA and PBDA. Each parameter is selected with a grid search thanks to a usual cross-validation (CV) on the source sample for SVM, and thanks to a reverse validation procedure11 (RCV) For details on the reverse validation procedure, see Bruzzone & Marconcini (2010); Zhong et al. (2010). Other details on our for CODA, DASVM, PBDA, and DALC.", "startOffset": 23, "endOffset": 1587}, {"referenceID": 5, "context": "com Reviews benchmark (Blitzer et al., 2006) according to the setting used by Chen et al. (2011); Germain et al. (2013). This dataset contains reviews of four types of products (books, DVDs, electronics, and kitchen appliances) described with about 100, 000 attributes. Originally, the reviews were labeled with a rating from 1 to 5. Chen et al. (2011) proposed a simplified binary setting by regrouping ratings into two classes (products rated lower than 3 and products rated higher than 4). Moreover, they reduced the dimensionality to about 40,000 by only keeping the features appearing at least ten times for a given domain adaptation task. Finally, the data are pre-processed with a tf-idf re-weighting. A domain corresponds to a kind of product. Therefore, we perform twelve domain adaptation tasks. For instance, \u201cbooks\u2192DVD\u2019s\u201d is the task for which the source domain is \u201cbooks\u201d and the target one is \u201cDVDs\u201d. We compare DALC with the classical non-adaptive algorithm SVM (trained only on the source sample), the adaptive algorithm DASVM (Bruzzone & Marconcini, 2010), the adaptive cotraining CODA (Chen et al., 2011), and the PAC-Bayesian domain adaptation algorithm PBDA (Germain et al., 2013) based on Theorem 2. Note that, in Germain et al. (2013), DASVM has shown better accuracy than SVM, CODA and PBDA. Each parameter is selected with a grid search thanks to a usual cross-validation (CV) on the source sample for SVM, and thanks to a reverse validation procedure11 (RCV) For details on the reverse validation procedure, see Bruzzone & Marconcini (2010); Zhong et al. (2010). Other details on our for CODA, DASVM, PBDA, and DALC. The algorithms use a linear kernel and consider 2,000 labeled source examples and 2,000 unlabeled target examples. Table 1 reports the error rates of all the methods evaluated on the same separate target test sets proposed by Chen et al. (2011).", "startOffset": 23, "endOffset": 1887}, {"referenceID": 16, "context": "This test tends to confirm that our new bound improves the analysis done previously in Germain et al. (2013), in addition to being more interpretable.", "startOffset": 87, "endOffset": 109}, {"referenceID": 17, "context": "The empirical experiments show that our new algorithm outperforms the previous PAC-Bayesian approach (Germain et al., 2013).", "startOffset": 101, "endOffset": 123}], "year": 2016, "abstractText": "We study the issue of PAC-Bayesian domain adaptation: We want to learn, from a source domain, a majority vote model dedicated to a target one. Our theoretical contribution brings a new perspective by deriving an upper-bound on the target risk where the distributions\u2019 divergence\u2014 expressed as a ratio\u2014controls the trade-off between a source error measure and the target voters\u2019 disagreement. Our bound suggests that one has to focus on regions where the source data is informative. From this result, we derive a PACBayesian generalization bound, and specialize it to linear classifiers. Then, we infer a learning algorithm and perform experiments on real data.", "creator": "LaTeX with hyperref package"}}}