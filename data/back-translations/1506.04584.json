{"id": "1506.04584", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2015", "title": "Re-scale AdaBoost for Attack Detection in Collaborative Filtering Recommender Systems", "abstract": "Common Filter Recommendation Systems (CFRS) are the key components of successful e-commerce systems. In fact, CFRS have been highly vulnerable to attack since their openness. However, since the size of an attack is much smaller than that of a real user, conventionally monitored learning-based detection methods may be too \"boring\" to handle such an unbalanced classification. In this paper, we improve detection performance from two aspects: First, we extract well-designed features from user profiles based on the statistical properties of the different attack models, making the detection method of difficult classification tasks easier to perform. Second, we apply a variant of AdaBoost called re-scale AdaBoost (RAdaBoost), because our detection method is based on extracted features. RAdaBoost is comparable to the optimal boosting algorithm and can effectively improve performance in some harsh scenarios.", "histories": [["v1", "Mon, 15 Jun 2015 13:07:52 GMT  (6785kb,D)", "http://arxiv.org/abs/1506.04584v1", "30 pages, 8 figures"]], "COMMENTS": "30 pages, 8 figures", "reviews": [], "SUBJECTS": "cs.IR cs.CR cs.LG", "authors": ["zhihai yang", "lin xu", "zhongmin cai"], "accepted": false, "id": "1506.04584"}, "pdf": {"name": "1506.04584.pdf", "metadata": {"source": "CRF", "title": "Re-scale AdaBoost for Attack Detection in Collaborative Filtering Recommender Systems", "authors": ["I Zhihai Yang", "Lin Xu", "Zhongmin Cai"], "emails": ["xulinshadow@gmail.com"], "sections": [{"heading": null, "text": "Collaborative filtering recommender systems (CFRSs) are the key components of successful e-commerce systems. Actually, CFRSs are highly vulnerable to attacks since its openness. However, since attack size is far smaller than that of genuine users, conventional supervised learning based detection methods could be too \u201cdull\u201d to handle such imbalanced classification. In this paper, we improve detection performance from following two aspects. First, we extract well-designed features from user profiles based on the statistical properties of the diverse attack models, making hard classification task becomes easier to perform. Then, refer to the general idea of re-scale Boosting (RBoosting) and AdaBoost, we apply a variant of AdaBoost, called the rescale AdaBoost (RAdaBoost) as our detection method based on extracted features. RAdaBoost is comparable to the optimal Boosting-type algorithm and can effectively improve the performance in some hard scenarios. Finally, a series of experiments on the MovieLens-100K data set are conducted to demonstrate the outperformance of RAdaBoost comparing with some classical techniques such as SVM, kNN and AdaBoost.\nKeywords: Recommender system, attack detection, imbalanced classification, re-scale Boosting, detection rate.\nIThe research was supported by the National 973 Programming (2013CB329404) and the National Natural Science Foundation (Grant No. 11131006, 11401462 and 61221063).\n\u2217Corresponding author: xulinshadow@gmail.com\nPreprint submitted to Elsevier June 16, 2015\nar X\niv :1\n50 6.\n04 58\n4v 1\n[ cs\n.I R\n] 1\n5 Ju"}, {"heading": "1. Introduction", "text": "Personalization recommender systems (RSs) utilize a variety of recommendation methods to suggest products that users may like, such as movies, music, news, books and other products. Collaborative filtering recommender systems (CFRSs) have been proved to be one of the most successful RSs used by many e-commerce companies such as Amazon, Ringo, eBay, GroupLens etc. [2], [3], [5], [19]. In practice, CFRSs are prone to manipulation from attackers since its openness. Typically, attackers carefully inject chosen attack profiles into CFRSs in order to bias the recommendation results to their benefits, which is termed \u201cshilling\u201d or \u201cprofile injection\u201d attacks. It decreases the trustworthiness of recommendation and leads to a negative impact on the CFRSs. Thus, constructing an effective method to defend the attackers and remove them from the CFRSs is crucial.\nSupervised learning based detection method for \u201cshilling\u201d or \u201cprofile injection\u201d in CFRSs is an important research direction, which regards the detection attributions as the classification features and distinguishes attack profiles from genuine profiles by constructed features. Actually, the attack detection problem can be formulated as an imbalanced classification. The number of attackers is far smaller than genuine users in CFRSs, especially when attack size 1 is small. However, the traditional supervised learning (i.e., SVM and kNN) based attack detection methods often inevitably have individual weaknesses for handling this kind of issues and fail to effectively capture the concerned attackers.\nIn the current paper, we aim to improve detection performance from two aspects. Firstly, we consider the overall statistical signature of attack profiles would differ significantly from that of genuine profiles. The difference comes from two sources: the distribution of ratings (or items among the filler items or selected items) and the ratings of the target items. Based on the statistical properties of the diverse attack models, as many extracted features as possible are designed and used to transform their \u201cinputs\u201d, distorting the space so that the task (i.e., classification or clustering) becomes easier to perform. Specifically, we extract as many as 18 features from user profiles (consists of attack profiles and genuine profiles) to construct a sophisticated features representation for each user to make it much more easily classified. Secondly, refer to the general idea of re-scale Boosting (RBoosting) [17],\n1The ratio between the number of attackers and genuine users.\n2\n[29] and AdaBoost [9, 10], we apply a variant of Boosting algorithm, called the re-scale AdaBoost (RAdaBoost) as our detection method based on extracted features. RBoosting is theoretically and experimentally proved to be better than the classical Boosting algorithm [17]. Furthermore, the theoretical near optimality of the numerical convergence of RBoosting among all the variants of the Boosting-type algorithms was also specified. This means that if the parameter is appropriately selected, RBoosting is comparable to the optimal Boosting-type algorithm. And AdaBoost [9, 10] is one of the most popular ensemble techniques paradigm and has been shown to be very effective in practice in some hard scenarios [13]. Typically, AdaBoost employs re-weighted loss function for gradually increasing emphasis (or weights) on misclassifications (i.e., concerned attackers) and can distinctly improve the predictive performance on a difficult data set. Thus, with the help of the re-scale operator, RAdaBoost can be used in conjunction with many other types of learning algorithms (or weak learners) to improve the performance in \u201cshilling\u201d attacks detection. Finally, a series of experiments on the MovieLens-100K dataset are conducted to demonstrate the outperformance (i.e., classification error, detection rate and false alarm rate) of RAdaBoost comparing with conventional classification techniques such as SVM, kNN and the original non-rescale AdaBoost version. The experimental results show that RAdaBoost can effectively improve the performance.\nThe rest of paper is organized as follows. In Section 2, we give a brief introduction to the related work. In Section 3, we give a brief introduction of attack profiles and attack models. In Section 4, our approach are described in details. In Section 5, experimental results are reported and analyzed. In the last section, we conclude the paper with a brief summary and prospect the directions of future works."}, {"heading": "2. Related work", "text": "Existing work in this area have focused on detecting and preventing the \u201cshilling\u201d attacks (or \u201cprofile injection\u201d attacks). Burke et al. [3] proposed and studied several attributions derived from user profiles for their utility in attack detection. They employed the kNN classifier as their detection approach. But it is unsuccessful when detecting attacks with small filler size\n3\n2. Then, Williams et al. [25], [26] tried to extract features from user profiles and utilized them to detect shilling attacks. They also suffered from low detection accuracy and many genuine profiles are misclassified as attack profiles. After that, He et al. [15] introduced the rough set theory into shilling attacks detection by means of taking features of user profiles as the condition attributes of the decision table. However, their method faced with the low overall classification rate in some cases, especially for bandwagon attack. Afterwards, Wu et al. [28] proposed a hybrid detection method to detect shilling attacks, which combined the naive Bayesian classifiers and augmented expectation maximization based on several selected metrics. Regretfully, their technique also suffered from low F-measure [6] when the filler size is small. Zhang et al. [30] introduced the idea of ensemble learning for improving predictive capability in the attack detection problem. They constructed the base-classifiers (or weaker learner) with the Support Vector Machine (SVM) approach and then integrated them to generate a high predictive ability learner for detection. Their proposed method exhibited better performance than some benchmarked methods. Nevertheless, it still suffered from low precision especially when the attack size is small. In addition, the same authors Zhang et al. [31] also proposed an online method, HHT-SVM, to detect profile injection attacks by combining Hilbert-Huang transform (HHT) and support vector machine (SVM). They created rating series for each user profile based on the novelty and popularity of items in order to provide basic data for feature extraction. The precision of their method shown better than the benchmarked methods, but the precision significantly decreased with the filler size increased.\nGenerally speaking, previous studies showed that the detection results of \u201cshilling\u201d attacks is dissatisfactory and leave much to be desired, especially when the filler size or attack size is small. In the current work, we intend to improve the detection performance from two aspects. First, we introduce more well-designed features to depict the distinction between attack profiles and genuine profiles to make hard classification task (i.e., with small filler size and attack size) becomes easier to perform. Secondly, in view of conventional classification techniques could be inadequate to handle such imbalanced classification, particularly when the attack size is small, we\n2The ratio between the number of items rated by user u and the number of entire items in the recommender system.\n4\napplied a variant of AdaBoost algorithm, called the re-scale AdaBoost (RAdaBoost) as our detection method. RAdaBoost gradually increases emphasis on the concerned attacks and can distinctly improve the performance for the imbalanced classification task."}, {"heading": "3. Attack profiles and attack models", "text": "The attackers have different attack intents to bias the recommendation results for their benefits. In the literature, \u201cshilling\u201d attacks are classified into two ways: nuke attack and push attack [3], [12], [25]. In nuke attacks, attackers demote the target items by rating the lowest score, whereas in push attacks, attackers promote the target items by rating the highest score. In order to effectively \u201cnuke\u201d or \u201cpush\u201d a target item, the attacker should clearly know the form of the attack profiles. The general form of attack profiles is shown in Table 1. The details of the four sets of items are described as follows:\nIT : A set of target items with singleton or multiple items, called singletarget attack or multi-target attack. The rating is \u03b3(iTj ), generally rated the maximum or minimum value in the entire profiles.\nIS: The set of selected items with specified rating by the function \u03c3(i S k ) [33]; IF : A set of filler items, received randomly items with random assigned ratings \u03c1(iFl ); IN : A set of items with no ratings; In the present work, we utilize 14 attack models to generate attack profiles. The involved attack profiles and corresponding explanations are listed in Table 2. The details of these attack models are described as follows:\n1) Random attack: IS = \u03c6 and \u03c1(i) \u223c N(r, \u03c32) [33]. 2) Average attack: IS = \u03c6 and \u03c1(i) \u223c N(ri, \u03c3i2) [33].\n3) Bandwagon (average) attack: IS contains a set of popular items. And then, we use these items as IS, \u03c3(i) = rmax/rmin (push/nuke) and \u03c1(i) \u223c N(ri, \u03c3i\n2) [27]. 4) Bandwagon (random) attack: IS contains a set of popular items, \u03c3(i) = rmax/rmin (push/nuke) and \u03c1(i) \u223c N(r, \u03c32) [27]. 5) Segment attack: IS contains a set of segmented items. And then, we use these items as IS, \u03c3(i) = rmax/rmin (push/nuke) and \u03c1(i) = rmin/rmax (push/nuke) [12].\n6) Reverse Bandwagon attack: IS contains a set of unpopular items, \u03c3(i) = rmin/rmax (push/nuke) and \u03c1(i) \u223c N(r, \u03c32) [12].\n7) Love/Hate attack: IS = \u03c6 and \u03c1(i) = rmin/rmax (push/nuke) [12]. 8) AOP attack: A simple and effective strategy to obfuscate the Average attack is to choose filler items with equal probability from the top x% of most popular items rather than from the entire collection of items [22].\n6\n9) PIA-AS attack: The top-N items with the highest aggregate similarity (AS) scores become the selected set of power items. This method requires at least 5 users who have rated the same item i and item j [22].\n10) PIA-ID attack: Based on In-Degree centrality, power items participate in the highest number of similarity neighborhoods. For each item i compute similarity with every item j applying significance weighting\nncij 50\n, where ncij is the number of users that have rated the same items i and j, then discard all but the top-N neighbors for each item i. Count the number of similarity scores for each item j, and select the top-N item j\u2019s [22].\n11) PIA-NR attack: Power items are the items with the highest number of user ratings. We select the top-N items based on the total number of user ratings they have in their profile [22].\n12) PUA-AS attack: The top 50 users with the highest Aggregate Similarity scores become the selected set of power users. This method requires at least 5 co-rated items between user u and user v and does not use significance weighting [21].\n13) PUA-ID attack: Based on the In-Degree centrality concept from social network analysis, power users are those who participate in the highest number of neighborhoods. For each user u compute its similarity with every other user v applying significance weighting, then discard all but the top 50 neighbors for each user u. Count the number of similarity scores for each user v and select the top 50 user v\u2019s [21].\n14) PUA-NR attack: Power users are the users with the highest number of ratings. We selected the top 50 users based on the total number of ratings they have in their user profile [21]."}, {"heading": "4. Our approach", "text": "In this section, we first present an overall introduction of our approach. Then, the two main aspects of our work including features extraction from user profiles and RAdaBoost for attack detection are described in detail."}, {"heading": "4.1. The framework of our approach", "text": "As shown in Figure 1, our approach consists of four phases: the phase of constructing training dataset and test datasets, the phase of feature extraction, the phase of training classifier via RAdaBoost, and the phase of test for generating detection results. At the phase of constructing training set and\n7\ntest sets, the data sets are constructed by attack profiles (diverse attack models are injected) and genuine profiles. Concretely, for training data set, we use several representative attack models such as Random, Average attacks etc. to generate mixed attack profiles. Specially, we modest increase the number of attacks (160 attackers for each attack models) when constructing the training data set aim to relieve the extent of imbalance in training phase (more details in section 5). Then, we combine them with genuine profiles as the our training data set. For test data sets, attack profiles with different filler sizes and attack sizes are inserted into the genuine profiles to form the test data sets (see section 5). At the phase of feature extraction, we employ 18 features (more details in the next subsection) extracted from user profiles to characterize a feature representation (or feature vector) for each user in both training data set and test data sets. At the phase of training, we use RAdaBoost to train a strong composite estimator (or classifier) based on training features. Finally, we use features retrieved from test data sets as the input into the obtained trained estimator and generate detection results at the phase of testing."}, {"heading": "4.2. Feature extraction from user profiles", "text": "Previous works [3, 25, 26, 20] summarized different metrics to characterize the features extracted from user profiles. These features generally fall into two types: generic and type-specific features. The generic features are basic descriptive statistics that attempt to discriminate between attack profiles and genuine profiles and the type-specific features are implemented to detect characteristics of profiles generated by specific attack models or specific signatures of attacks. In the present work, we employ 10 features from these two types. Besides, we also employ 5 features based on the filler size [31] and propose additional 3 new features which measure the distribution of specific rating such as mean rating, maximum rating and minimum rating in filler items for each user."}, {"heading": "4.2.1. Generic features", "text": "Attack profiles usually have high deviation from the mean value for the target items and low deviation from the mean value for remaining items. Thus, generic features such as RDMA, WDMA etc. are often used to measure the deviation of rating for user profiles [3, 25, 26, 34].\n8\nRating Deviation from Mean Agreement (RDMA):\nRDMAu =\n\u2211Nu i=0 |ru,i\u2212ri| NRi\nNu (4.1)\nwhere Nu is the number of ratings that user u has rated and NRi is the number of ratings provided for item i. ru,i denotes the rating given by user u to item i, ri denotes the mean rating of item i across all users.\nWeighted Deviation from Mean Agreement (WDMA):\nWDMAu =\n\u2211Nu i=0 |ru,i\u2212ri| NR2i\nNu (4.2)\nWeighted Degree of Agreement (WDA):\nWDAu = Nu\u2211 i=0 |ru,i \u2212 ri| NRi\n(4.3)\nLength Variance (LengthVar):\nLengthV aru = |nu \u2212 n|\u2211\nk\u2208U (nk \u2212 n) 2 (4.4)\nwhere nu is the total number of ratings in the system for user u. U is the total number of users in the system. n is the average length of a profile in the system.\n9"}, {"heading": "4.2.2. Type-specific features", "text": "Model-based methods assume that we have some prior knowledge about the attack models. Based on an assumed model, ratings can be automatically divided into filler items and selected items [3, 25, 26, 34]. Therefore, the measurements such as MeanVar, FMTD etc. can be calculated from each subset to measure the authenticity of profiles.\nMean Variance (MeanVar):\nMeanV aru =\n\u2211 j\u2208Pu,F (ru,j \u2212 ru) 2\n|Pu,F | (4.5)\nwhere Pu,F is the rest of the profile: Pu\u2212Pu,T , Pu,T = {i \u2208 Pu, such that ru,i = rmax} (or rmin for nuke attack), Pu is the profile of user u.\nFiller Mean Target Difference (FMTD):\nFMTDu = \u2223\u2223\u2223\u2223\u2223 \u2211 i\u2208Pu,T ru,i |Pu,T | \u2212 \u2211 k\u2208Pu,F ru,k |Pu,F | \u2223\u2223\u2223\u2223\u2223 (4.6) Target Model Focus (TMF):\nTMFu = max j\u2208PT Fj (4.7)\nwhere Fi = ( \u2211 u\u2208U \u03c6u,i)/( \u2211\nu\u2208U |Pu,T |), and \u03c6u,i is 1 if i \u2208 Pu,T , 0 otherwise. PT denotes the item set of potential targets [26].\nFiller Mean Variance (FMV):\nFMVu = 1 |UFmu | \u2211 i\u2208UFmu (ru,i \u2212 ri)2 (4.8)\nwhere UFmu is the partition of the profile of user u hypothesized to be the set of filler items F by model m. \u2223\u2223UFmu \u2223\u2223 is the number of items in the hypothesized filler partition of profile Pu by model m.\nFiller Mean Difference (FMD):\nFMDu = 1\n|Uu| |Uu|\u2211 i=1 |ru,i \u2212 ri| (4.9)\nwhere Uu is the partition of the profiles of user u. |Uu| is the number of the profiles of user u.\n10\nFiller Average Correlation (FAC):\nFACu = \u2211 i\u2208Iu (ru,i \u2212 ri)\u221a\u2211 i\u2208Iu (ru,i \u2212 ri) 2 (4.10)\nwhere Iu is the set of items rated by user u."}, {"heading": "4.2.3. Features based on the filler size", "text": "User profiles with different number of ratings will generate different features. Similarly, the number of rating on different types of items will also generate different features. Such as FSTI, FSPI etc. [31].\nFiller Size with Total Items (FSTI): The ratio between the number of items rated by user u and the number of entire items in the recommender system [31].\nFSTIu =\n\u2211|I| i=1O(ru,i)\n|I| (4.11)\nwhere I is the set of items in the system. |I| denotes the total number of items in the system. O(ru,i) is 1 if user u rated item i, 0 otherwise.\nFiller Size with Popular Items (FSPI): The ratio between the number of popular items rated by user u and the number of entire popular items in the recommender system [31].\nFSPIu =\n\u2211K i=1O(ru,i)\nK (4.12)\nwhere K denotes the boundary point of popular items and unpopular items. Filler Size with Popular Items in Itself (FSPII): The ratio between the number of popular items rated by user u and the number of entire items rated by user u [31].\nFSPIIu = \u2211K i=1O(ru,i)\u2211|I| j=1O(ru,j)\n(4.13)\nFiller Size with Unpopular Items (FSUI): The ratio between the number of unpopular items rated by user u and the number of entire unpopular items in the recommender system [31].\nFSUIu =\n\u2211|I| i=1O(ru,i)\n|I| \u2212K (4.14)\n11\nFiller Size with Unpopular Items in Itself (FSUII): The ratio between the number of unpopular items rated by user u and the number of entire items rated by user u [31].\nFSUIIu = \u2211|I| i=K+1O(ru,i)\u2211|I| k=1O(ru,k)\n(4.15)"}, {"heading": "4.2.4. Our proposed features", "text": "We propose 3 new features which focus on the number of specific ratings (such as the maximum score, minimum score and average score) on filler or selected items. Since attackers show different attack intents in CFRSs, the filler or selected set of attack profiles may be filled by specific items (i.e., select popular items for Bandwagon (average and random) attacks, select randomly items in the system for Random attack) with the highest score or the lowest score or average score. Take nuke attacks for example, the selected items or filler items are rated with maximum score in Reverse Bandwagon, Segment and Love/Hate attacks (as shown in Table 2). Similarly, the selected items or filler items are rated with minimum score in Bandwagon (average), Bandwagon (random) and Segment attacks. In Random attack, the filler items are rated with some average score (normal distribution around system mean). Therefore, the number of specific ratings can be used to evaluate partly the difference between genuine profiles and attack profiles.\nFiller Size with Maximum Rating in Itself (FSMAXRI): The ratio between the number of items rated by user u with maximum score and the number of entire items rated by user u.\nFSMAXRIu = \u2211Iu i=1O(ru,i = rmax)\u2211Iu\nk=1O(ru,k) (4.16)\nwhere ru,i is the rating given by user u to item i, rmax is the maximum score in the system. Iu denotes the set of items rated by user u. O(ru,i = rmax) is 1 if user u rated item i with rating rmax, 0 otherwise. O(ru,k) is 1 if user u rated item k, 0 otherwise.\nFiller Size with Minimum Rating in Itself (FSMINRI): The ratio between the number of items rated by user u with minimum score and the number of entire items rated by user u.\nFSMINRIu = \u2211|I| i=1O(ru,i = rmin)\u2211|I|\nk=1O(ru,k) (4.17)\n12\nwhere rmin is the minimum score in the system. O(ru,i = rmin) is 1 if user u rated item i with rating rmin, 0 otherwise.\nFiller Size with Average Rating in Itself (FSARI): The ratio between the number of items rated by user u with average score and the number of entire items rated by user u.\nFSARIu = \u2211|I| i=1O(ru,i = ravg)\u2211|I|\nk=1O(ru,k) (4.18)\nwhere ravg is the average score in the system. O(ru,i = ravg) is 1 if user u rated item i with rating ravg, 0 otherwise."}, {"heading": "4.3. Re-scale AdaBoost for attack detection", "text": "After the raw user profiles are transformed to a set of sophisticated features, an effective detection method based on these features for \u201cshilling\u201d attacks is crucial. As is known, the number of attackers is usually far smaller than genuine users in CFRSs, thus the supervised learning based attack detection can be formulated as an imbalanced classification, actually. Conventional supervised learning based detection method (i.e., SVM or kNN) often inevitably have individual weaknesses for handling this kind of issues. Under this circumstance, Boosting comes into our sights as it has been proved to be efficient when faced with some difficult scenarios as imbalanced classification [13]. In Boosting, weak learners are fitted iteratively to the training data, using appropriate methods to gradually increase emphasis on observations modelled poorly by the existing collection of weak learners. More specifically, AdaBoost apply weights to the observations (or samples), emphasising poorly modelled ones and gradually (or iteratively, more precisely) strengthening the correction of misclassifications. The following Algorithm 1 interpret the main idea of AdaBoost [9].\n13\nAlgorithm 1 AdaBoost\nStep 1: (Initialization): Given data {(xi, yi) : i = 1, . . . ,m}, where x \u2208 Rd and y \u2208 {\u22121,+1}, weights {(w(1)i ) = 1m : i = 1, . . . ,m} , dictionary Dn = {g1, . . . , gn}, iteration number T and f0 \u2208 span(Dn). Step 2: Find gt \u2208 Dn such that minimizes the weighted sum error\nt = Pri\u223cw(t) [gt(xi) 6= yi] = m\u2211 i=1 wi (t)1(gt(xi)6=yi)\nfor misclassified samples. Step 3: Choose\n\u03b1t = 1\n2 ln ( 1\u2212 t t ) and update weights\nw (t) i =\nw (t\u22121) i exp \u2212yi\u03b1tgt(xi)\nZt\nfor all samples, where Zt = 2[ t(1\u2212 t)]1/2 is a normalization factor. Step 4: Add to ensemble ft = ft\u22121 + \u03b1tgt. Step 5: Increase t by one and repeat Step 2 and Step 3 if t < T .\nFrom a statistical view, AdaBoost also can be viewed as a form of \u201dGradient Boosting Machine\u201d [11]. Consider a loss function in this case, a measure that represents the loss in predictive performance due to a sub-optimal model. Boosting is a numerical optimisation technique for minimising the loss function by adding at each step a new weak learner that best reduces (steps down the gradient of) the loss function. Original gradient Boosting algorithm was proved to be consistent, which can be easily deduced by applying the method in [1] to [18, Theorem1], however, a number of studies [7, 18, 24] also showed that its approximation rate is far slower. The numerical convergence rate of Boosting lies in (C0t \u22120.1898, C \u20320t \u22120.182), which is much slower than the minimax nonlinear approximation rate O(t\u22121/2). Here and hereafter, t denotes the number of iterations, and C0, C \u2032 0 are absolute constants.\nRecently, Lin et al. [17] and Xu et al. [29] proposed a re-scale Boosting (RBoosting) to improve the performance of original gradient Boosting. Different from the aforementioned strategies that focus on controlling the stepsize of g\u2217t such as some existing variants like Regularized shrinkage Boosting\n14\n[8], Regularized truncated Boosting [32], \u03b5-Boosting [14], they cheered a novel direction to improve the numerical convergence rate and consequently, the generalization capability of Boosting. The core idea is that if the approximation (or learning) effect of the tth iteration is not good, then we regard ft to be too aggressive and therefore shrink it within a certain extent. By such an interesting modification, the optimal numerical convergence of RBoosting can be guaranteed. This means that, RBoosting is among the almost optimal nonlinear approximant and therefore, RBoosting may possess better learning performance than other Boosting-type algorithms. Based on the general idea of RBoosting, the re-scale AdaBoost (RAdaBoost) can be interpreted as the following Algorithm 2.\nAlgorithm 2 Re-scale AdaBoost\nStep 1: (Initialization): Given data {(xi, yi) : i = 1, . . . ,m}, where x \u2208 Rd and y \u2208 {\u22121,+1}, weights {(w(1)i ) = 1m : i = 1, . . . ,m} , dictionary Dn = {g1, . . . , gn}, a set of shrinkage degree {st}t \u2217 t=1 where st = 2/(t + u), u \u2208 N, iteration number T and f0 \u2208 span(Dn). Step 2: Find gt \u2208 Dn such that minimizes the weighted sum error\nt = Pri\u223cw(t) [gt(xi) 6= yi] = m\u2211 i=1 wi (t)1(gt(xi)6=yi)\nfor misclassified samples. Step 3: Choose\n\u03b1t = 1\n2 ln ( 1\u2212 t t ) and update weights\nw (t) i =\nw (t\u22121) i exp \u2212yi\u03b1tgt(xi)\nZt\nfor all samples, where Zt = 2[ t(1\u2212 t)]1/2 is a normalization factor. Step 4: Add to ensemble ft = (1\u2212 st)ft\u22121 + \u03b1tgt. Step 5: Increase t by one and repeat Step 2 and Step 3 if t < T ."}, {"heading": "5. Experiments and analysis", "text": "In this part, we firstly introduce the experimental settings, including the data sets, evaluation metrics and computational environment. Secondly, the\n15\nimpact of the extracted features are analyzed. Then, we compare the performance of RAdaBoost with three other benchmarked methods such as SVM, kNN and AdaBoost on diverse 4 attack detection methods to demonstrate the outperformance of RAdaBoost. Finally, the remaining 10 types of attacks are conducted by means of RAdaBoost to further evaluate its performance."}, {"heading": "5.1. Experimental settings", "text": "In our experiments, we use the MovieLens-100K 3 dataset as the data set describing the behaviors of genuine users in recommender system. MovieLens100K was collected by the GroupLens Research Project at the University of Minnesota. It is the one of the most popular data sets used by researchers and developers in the field of collaborative filtering and attack detection in recommender systems. It consists of 100,000 ratings on 1682 movies by 943 raters and each rater had to rate at least 20 movies. All ratings are in the form of integral values between minimum value 1 and maximum value 5. The minimum score means the rater distastes the movie, while the maximum score means the rater enjoyed the movie. According to the information derived from MovieLens website, the sparse ratio 4 of the rating data approximates to 93.7% and the average rating of all users is around 3.53. Besides, the Average Number of Items Rated (ANIR) by each user is approximately 7%. Attack profiles are generated according to different attack models (as shown in Table 2). The attack profiles indicate the attackers intention that he wishes a particular item can be rated the highest or lowest rating. In this paper, we just detect the nuke attacks and the push attacks can be detected in the analogous manner. For each attack model, we generate nuke attack profiles according to the corresponding attack models with different attack sizes {1.1%, 6.4%, 11.7%, 17.0%, 22.3%, 27.6%} and filler sizes {1.2%, 4.2%, 7.3%, 10.3%, 13.3%, 16.4%}. To ensure the rationality of the results, the target item is randomly selected for each attack profile. In addition, for bandwagon attacks, we select movies {50, 56, 100, 127, 174, 181, 258, 286, 288, 294} as the popular movies which are rated by more than 300 users in the system. In segment attack, we use movies {50, 183, 185, 200, 234, 443} as the segmented movies [16]. And for Reverse Bandwagon attack, we randomly choose 10 movies as the selected movies which are rated by one user\n3http://grouplens.org/datasets/movielens/ 4The ratio between the number of ratings and entire ratings in the rating matrix.\n16\nin the system. For training set, we use the whole MovieLens-100K dataset to generate a attack profiles by exploiting 7 representative known attack models (random, average, bandwagon (average), segment, reverseBandwagon, PIAID and PUA-NR) with 17.0% attack size (160 attackers) and diverse filler sizes {1.2%, 4.2%, 7.3%, 10.3%, 13.3%, 16.4%}. And then, we combine these 7 attack datasets into MovieLens-100K dataset to construct a mixed user profiles as our training data. Thus, the training dataset consists of 943 genuine users and 1120 (160\u00d77) attackers. For test data sets, based on the whole MovieLens-100K dataset, we generate respectively attack profiles by exploiting 14 attack models with different attack sizes {1.1%, 6.4%, 11.7%, 17.0%, 22.3%, 27.6%} and filler sizes {1.2%, 4.2%, 7.3%, 10.3%, 13.3%, 16.4%}. And then, the generated attack profiles are respectively inserted into genuine profiles to construct our test datasets. Therefore, we have 504 (14\u00d7 6\u00d7 6) test datasets including 14 attack models, 6 different attack sizes and 6 different filler sizes.\nTo measure the effectiveness of the proposed detection methods, we use three metrics such as classification error, detection rate and false alarm rate in the test sets, which are used in similar experiments [5]. Classification error is defined as the number of misclassifications divided by the number of all test user profiles.\nclassification error = #Misclassifications\n#User Profiles (5.1)\nDetection rate is defined as the number of detected attack profiles divided by the number of attack profiles.\ndetection rate = #Detection\n#Attack Profiles (5.2)\nFalse alarm rate is the number of genuine profiles that are predicted as attack profiles divided by the number of genuine profiles.\nfalsealarm rate = #False alarm\n#Genuine Profiles (5.3)\nAll numerical studies are implemented using MATLAB R2014a on a Windows personal computer with Core(TM) i7-3770 3.40GHz CPUs and RAM 16.00GB.\n17"}, {"heading": "5.2. Impact of extracted features", "text": "Bandwagon(average)\n18\nTo evaluate the impact of the extracted features, we conduct a list of experiments in several attack models with diverse filler sizes as Figure 2 illustrated. We utilize EM (Expectation-maximization) clustering method (Clustering results and EM clustering method were created using Weka 5) to separate attackers from genuine users as far as possible based on 10 features (generic and type-specific features), 15 features (additional 5 features based on filler size) and 18 features (all aforementioned features including 3 our proposed features), respectively, in order to analyze the relationship between the number of extracted features and the performance with respect to the filler size. Just as shown in Figure 2, Bandwagon (average), Segment, Reverse Bandwagon and PIA-AS attacks are taken for examples. It is distinctly observed from the results that the false alarm rate significantly decrease with using more extracted features. Furthermore, we take two diagrams to intuitively show the clustering results as shown in Figure 3 (Bandwagon (average) and Segment attacks are taken for examples). By fixing attack size (17.0%, 160 attackers) and filler size (13.3%, 170 items), the strikingly clustering results illustrate that hard classification task becomes easier to perform with more well-designed features employed."}, {"heading": "5.3. Experimental results and analysis", "text": "First, we compare the detection performance of RAdaBoost with three benchmarked methods such as SVM, kNN and AdaBoost on 4 test attack profiles described above to validate the outperformance of RAdaBoost. The details of setting of each method is described as follows: \u2022 SVM: LibSVM and the default parameters are employed as [4] for training binary profile classifier with Prediction = +1 if classified as authentic and Prediction = \u22121 if classified as attack. To classify unseen test data sets, the trained SVM model (or classifier) in the training set are used to determine the class label. \u2022 kNN: Standard kNN algorithm is used as [23]. The k nearest neighbors (k is chosen by 5-folds cross validation on the training data set) in the training set are collected for prediction using one over Pearson correlation distance weighting. \u2022 AdaBoost: We utilize decision stumps (with the number of splits J = 1) to build up the week learners for classification. The number of iterations (or\n5http://www.cs.waikato.ac.nz/ml/weka/\n19\nthe number of stumps to be fitted) is also selected via 5-folds cross validation on the training data set. \u2022 RAdaBoost: For additional shrinkage degree parameter, sk = 2/(k + u), u \u2208 N, in RBoosting, we create 20 equally spaced values of u in logarithmic space between 1 to 106 and select the appropriate u\u2217 as [29]. The other settings are the same as Boosting.\nFig.4-Fig.7 illustrate the performance surfaces of the RAdaBoost classifier for the aforementioned test sets, which contain 4 attack models (take AOP, Bandwagon (random), PIA-NR and PUA-NR attacks for examples) with different attack sizes {1.1%, 6.4%, 11.7%, 17.0%, 22.3%, 27.6%} and filler sizes {1.2%, 4.2%, 7.3%, 10.3%, 13.3%, 16.4%}. For comparison, the performance surfaces of SVM, kNN and AdaBoost are also presented. It can be easily observed from these figures that, the classification error of SVM rise with the increase of the attack size, which implies the SVM classifier could not effectively classify and detect attacks generated by these 4 types of attack models when the total number of attacks are far smaller than genuine users. Although SVM can achieve fairly high classification performance within some small attack size areas, the detection rates of SVM are also small. It shows that the high prediction accuracy is almost produced by abundant genuine users but fail to capture the little concerned attackers. In our 4 sets of experiments, only a few bandwagon (random) attack profiles could be detected by SVM and naturally SVM barely false alarmed. kNN essentially outperforms SVM in our 4 types of attack detection methods with lower classification error, much more higher detection rate and pimping false alarm rate. However, we also notice that the classification performance of kNN is still poor and it may fail for detection within some certain attack and filler size areas. Just as figures showed, kNN fail to detect AOP, PIA-NR attacks when the filler size is too small and bandwagon (random) attacks when the attack size is small. And for PUA-NR attack, kNN is just slightly better than SVM and barely detected. For AOP attack detected by kNN, the results may indicate that some genuine profiles are misclassified as attack profiles since a large number of genuine profiles have the same or similar number of popular items as the AOP attack profiles when filler size is too big and small. Compare with SVM and kNN, Boosting significantly improve the classification performance owing to it iteratively strengthen the correction of the misclassifications. And hence, AdaBoost further enhance detection rate with very low false alarm rate. However, just as figures shown, although AdaBoost can effectively detect attack over a wide range of attack and filler size, we also observe that its\n20\nfailure within some certain areas (i.e., AOP and PIA-NR attacks with small attack size and high filler size, bandwagon (random) attacks with small attack and filler size). Especially, AdaBoost can not effectively detect PUA-NR attacks within a large high attack size area. As figures shown, RAdaBoost additionally improve the classification performance of AdaBoost by imposing a re-scale operator and consequence enhance detection rate with negligible false alarm rate in the 4 types of attacks. So far, all the comparative experimental results illustrate that the RAdaBoost outperforms Boosting and conventional supervised learning based detection methods including SVM and kNN. Finally, to further evaluate the effectiveness of RAdaBoost, we also conduct other 10 types of attacks to show the performance surfaces of RAdaBoost just as Fig.8 illustrated. From results, we can distinctly observe that, except for PUA-AS and PUA-ID attacks, RAdaBoost can effectively detect all of the attacks with almost no false alarm. Although it also shows low detection rates for some attacks with small attack and filler size. Comparing with previous research results [3, 26, 30], the detection performance of RAdaBoost is more optimistic. For PUA-AS and PUA-ID attacks, which are recently published attack models and few researchers pay close attention to them. Just as figures shown, the RAdaBoost can not effectively detect such attacks mainly because the present extractive features (as described in section 4) are not enough to depict their material characteristics. Therefore, the results indicate the adaptive new classification features are needed for detecting such new attacks as PUA-AS, PUA-NR and PUA-ID."}, {"heading": "6. Conclusion and further discussions", "text": "\u201cShilling\u201d attacks or \u201cprofile injection\u201d attacks are serious threats to the collaborative filtering recommender systems (CFRSs). Since the number of detected attackers is far smaller than genuine users. Conventional supervised learning based detection methods have the challenges faced with this imbalanced classification. In the present paper, we improved the detection performance in two directions. First, we extracted features from user profiles based on the statistical properties of the diverse attack models to make them much more easily classified. Then, we applied a variant of Boosting algorithm, called the re-scale AdaBoost (RAdaBoost) as our detection method, which gradually increasing emphasis on concerned attacks and could distinctly improve the predictive performance on a difficult classification task. And all our experimental results also demonstrated the outperformance of\n21\nRAdaBoost in \u201cshilling\u201d attacks detection. In our future work, we will explore more simpler and effective features to characterize attack profiles from different perspectives. The existing features based on basic description statistics and model-specific are difficult to fully discriminate between attack profiles and genuine profiles in diverse attack models. In addition, some features based on global calculating similarity such as DegSim (similarity with top neighbors) are unrealistic in mass user profiles, although they are effective to capture the concerned attack profiles. Therefore, how to extract local and effective features from user profiles is still an open issue.\n22\nAOP Model\nBandwagon (random) Model\nPIA-NR\nPUA-NR"}], "references": [{"title": "Approximation and learning by greedy algorithms", "author": ["A. Barron", "A. Cohen", "W. Dahmen", "R. DeVore"], "venue": "Ann. Stat., 36(1):64\u201394", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Unsupervised retrieval of attack profiles in collaborative recommender systems", "author": ["K. Bryan", "M. OMahony", "P. Cunningham"], "venue": "ACM conference on Recommender Systems, page 155C162", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Classification features for attack detection in collaborative recommender systems", "author": ["R. Burke", "B. Mobasher", "C. Williams"], "venue": "International Conference on Knowledge Discovery and Data Mining, pages 17\u201320", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "LIBSVM: A library for support vector machines", "author": ["C.C. Chang", "C.J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology, 2:27:1\u201327:27", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "A novel approach to filter out malicious rating profiles from recommender systems", "author": ["C. Chung", "P. Hsu", "S. Huang"], "venue": "Journal of Decision Support Systems, page 314C325", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Evaluation: From precision", "author": ["M.W. David"], "venue": "recall and f-measure to roc, informedness, markedness correlation. Journal of Machine Learning Technologies", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Some remarks on greedy algorithms", "author": ["R. DeVore", "V. Temlyakov"], "venue": "Adv. Comput. Math., 5(1):173\u2013187", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1996}, {"title": "Characterizing l2 boosting", "author": ["J. Ehrlinger", "H. Ishwaran"], "venue": "Ann. Stat., 40(2):1074\u20131101", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "pages 23\u201337", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1995}, {"title": "Experiments with a new boosting algorithm", "author": ["Y. Freund", "R.E. Schapire"], "venue": "ICML, 96:148\u2013156", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1996}, {"title": "Greedy function approximation: a gradient boosting machine", "author": ["J. Friedman"], "venue": "Ann. Stat., 29(5):1189\u20131232", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}, {"title": "Shilling attacks against recommender systems: A comprehensive survey", "author": ["I. Gunes", "C. Kaleli", "A. Bilge", "H. Polat"], "venue": "Artificial Intelligence Review, pages 1\u201333", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Machine Learning in Action", "author": ["P. Harrington"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Forward stagewise regression and the monotone lasso", "author": ["T. Hastie", "J. Taylor", "R. Tibshirani", "G. Walther"], "venue": "Electron. J. Stat., 1:1\u201329", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Attack detection by rough set theory in recommendation system", "author": ["F. He", "X.Wang", "B. Liu"], "venue": "IEEE International Conference on Granular Computing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Detection of shilling attacks in collaborative filtering recommender systems", "author": ["C. Li", "Z. Luo"], "venue": "International Conference of Soft Computing and Pattern Recognition, page 190C193", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Re-scale boosting for regression and classification", "author": ["S.B. Lin", "Y. Wang", "L. Xu"], "venue": "ArXiv:1505.01371", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Lower bounds for the rate of convergence of greedy algorithms", "author": ["E.D. Livshits"], "venue": "Izvestiya: Mathematics, 73(6):1197\u20131215", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Lies and propaganda: detecting spam users in collaborative filtering", "author": ["B. Mehta", "T. Hofmann", "P. Fankhauser"], "venue": "In: IUI07: Proceedings of the 12th International Conference on Intelligent User Interfaces, page 14C21", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Defending recommender systems by influence analysis", "author": ["M. Morid", "M. Shajari"], "venue": "Information Retrieval, pages 137\u2013152", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Assessing impacts of a power user attack on a matrix factorization collaborative recommender system", "author": ["C.E. Seminario", "D.C. Wilson"], "venue": "Florida Artificial Intelligence Research Society Conference", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Attacking item-based recommender systems with power items", "author": ["C.E. Seminario", "D. C Wilson"], "venue": "ACM Conference on Recommender Systems, pages 57\u201364", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "The elements of statistical learning", "author": ["R. Tibshirani T. Hastie", "Jerome J. Friedman"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2001}, {"title": "Greedy approximation", "author": ["V. Temlyakov"], "venue": "Acta Numer., 17:235\u2013409", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}, {"title": "Defending recommender systems: detection of profile injection attacks", "author": ["C.A. Williams", "B. Mobasher", "R. Burke"], "venue": "SOCA, page 157C170", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "Detecting profile injection attacks in collaborative filtering: a classification-based approach", "author": ["C.A. Williams", "B. Mobasher", "R. Burke", "R. Bhaumik"], "venue": "Advances in Web Mining and Web Usage Analysis, page 167C186", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "A survey on shilling attack models and detection techniques for recommender systems", "author": ["Z.A. Wu", "Y.Q. Wang", "J. Cao"], "venue": "Science China, 59(7):551\u2013560", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Hysad: a semi-supervised hybrid shilling attack detector for trustworthy product recommendation", "author": ["Z.A. Wu", "J.J. Wu", "J. Cao", "D.C. Tao"], "venue": "ACM SIGKDD Conference on Knowledge Discovery and Data Mining, page 985C993", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "Shrinkage degree in l2-rescale boosting for regression", "author": ["L. Xu", "S.B. Lin", "Y. Wang", "Z.B. Xu"], "venue": "Submitted to IEEE Trans. Neural Netw. & Learn. Syst.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1505}, {"title": "A meta-learning-based approach for detecting profile injection attacks in collaborative recommender systems", "author": ["F. Zhang", "Q. Zhou"], "venue": "J. Comput., 7(1):226\u2013234", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "HHT-SVM: An online method for detecting profile injection attacks in collaborative recommender systems", "author": ["F. Zhang", "Q. Zhou"], "venue": "Knowledge- Based Systems", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "Boosting with early stopping: convergence and consistency", "author": ["T. Zhang", "B. Yu"], "venue": "Ann. Stat., 33(4):1538\u20131579", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2005}, {"title": "Graph-based detection of shilling attacks in recommender systems", "author": ["Z. Zhang", "S. Kulkarni"], "venue": "IEEE International Workshop on Machine Learning for Signal Processing, pages 1\u20136", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}, {"title": "Detection of shilling attacks in recommender systems via spectral clustering", "author": ["Z. Zhang", "S.R. Kulkarni"], "venue": "International Conference on Information Fusion, pages 1\u20138", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 1, "context": "[2], [3], [5], [19].", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[2], [3], [5], [19].", "startOffset": 5, "endOffset": 8}, {"referenceID": 4, "context": "[2], [3], [5], [19].", "startOffset": 10, "endOffset": 13}, {"referenceID": 18, "context": "[2], [3], [5], [19].", "startOffset": 15, "endOffset": 19}, {"referenceID": 16, "context": "Secondly, refer to the general idea of re-scale Boosting (RBoosting) [17],", "startOffset": 69, "endOffset": 73}, {"referenceID": 28, "context": "[29] and AdaBoost [9, 10], we apply a variant of Boosting algorithm, called the re-scale AdaBoost (RAdaBoost) as our detection method based on extracted features.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[29] and AdaBoost [9, 10], we apply a variant of Boosting algorithm, called the re-scale AdaBoost (RAdaBoost) as our detection method based on extracted features.", "startOffset": 18, "endOffset": 25}, {"referenceID": 9, "context": "[29] and AdaBoost [9, 10], we apply a variant of Boosting algorithm, called the re-scale AdaBoost (RAdaBoost) as our detection method based on extracted features.", "startOffset": 18, "endOffset": 25}, {"referenceID": 16, "context": "RBoosting is theoretically and experimentally proved to be better than the classical Boosting algorithm [17].", "startOffset": 104, "endOffset": 108}, {"referenceID": 8, "context": "And AdaBoost [9, 10] is one of the most popular ensemble techniques paradigm and has been shown to be very effective in practice in some hard scenarios [13].", "startOffset": 13, "endOffset": 20}, {"referenceID": 9, "context": "And AdaBoost [9, 10] is one of the most popular ensemble techniques paradigm and has been shown to be very effective in practice in some hard scenarios [13].", "startOffset": 13, "endOffset": 20}, {"referenceID": 12, "context": "And AdaBoost [9, 10] is one of the most popular ensemble techniques paradigm and has been shown to be very effective in practice in some hard scenarios [13].", "startOffset": 152, "endOffset": 156}, {"referenceID": 2, "context": "[3] proposed and studied several attributions derived from user profiles for their utility in attack detection.", "startOffset": 0, "endOffset": 3}, {"referenceID": 24, "context": "[25], [26] tried to extract features from user profiles and utilized them to detect shilling attacks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[25], [26] tried to extract features from user profiles and utilized them to detect shilling attacks.", "startOffset": 6, "endOffset": 10}, {"referenceID": 14, "context": "[15] introduced the rough set theory into shilling attacks detection by means of taking features of user profiles as the condition attributes of the decision table.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] proposed a hybrid detection method to detect shilling attacks, which combined the naive Bayesian classifiers and augmented expectation maximization based on several selected metrics.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "Regretfully, their technique also suffered from low F-measure [6] when the filler size is small.", "startOffset": 62, "endOffset": 65}, {"referenceID": 29, "context": "[30] introduced the idea of ensemble learning for improving predictive capability in the attack detection problem.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[31] also proposed an online method, HHT-SVM, to detect profile injection attacks by combining Hilbert-Huang transform (HHT) and support vector machine (SVM).", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "In the literature, \u201cshilling\u201d attacks are classified into two ways: nuke attack and push attack [3], [12], [25].", "startOffset": 96, "endOffset": 99}, {"referenceID": 11, "context": "In the literature, \u201cshilling\u201d attacks are classified into two ways: nuke attack and push attack [3], [12], [25].", "startOffset": 101, "endOffset": 105}, {"referenceID": 24, "context": "In the literature, \u201cshilling\u201d attacks are classified into two ways: nuke attack and push attack [3], [12], [25].", "startOffset": 107, "endOffset": 111}, {"referenceID": 32, "context": "IS: The set of selected items with specified rating by the function \u03c3(i S k ) [33]; IF : A set of filler items, received randomly items with random assigned ratings \u03c1(il ); IN : A set of items with no ratings; In the present work, we utilize 14 attack models to generate attack profiles.", "startOffset": 78, "endOffset": 82}, {"referenceID": 32, "context": "The details of these attack models are described as follows: 1) Random attack: IS = \u03c6 and \u03c1(i) \u223c N(r, \u03c3) [33].", "startOffset": 105, "endOffset": 109}, {"referenceID": 32, "context": "2) Average attack: IS = \u03c6 and \u03c1(i) \u223c N(ri, \u03c3i) [33].", "startOffset": 47, "endOffset": 51}, {"referenceID": 26, "context": "And then, we use these items as IS, \u03c3(i) = rmax/rmin (push/nuke) and \u03c1(i) \u223c N(ri, \u03c3i ) [27].", "startOffset": 87, "endOffset": 91}, {"referenceID": 26, "context": "4) Bandwagon (random) attack: IS contains a set of popular items, \u03c3(i) = rmax/rmin (push/nuke) and \u03c1(i) \u223c N(r, \u03c3) [27].", "startOffset": 114, "endOffset": 118}, {"referenceID": 11, "context": "And then, we use these items as IS, \u03c3(i) = rmax/rmin (push/nuke) and \u03c1(i) = rmin/rmax (push/nuke) [12].", "startOffset": 98, "endOffset": 102}, {"referenceID": 11, "context": "6) Reverse Bandwagon attack: IS contains a set of unpopular items, \u03c3(i) = rmin/rmax (push/nuke) and \u03c1(i) \u223c N(r, \u03c3) [12].", "startOffset": 115, "endOffset": 119}, {"referenceID": 11, "context": "7) Love/Hate attack: IS = \u03c6 and \u03c1(i) = rmin/rmax (push/nuke) [12].", "startOffset": 61, "endOffset": 65}, {"referenceID": 21, "context": "8) AOP attack: A simple and effective strategy to obfuscate the Average attack is to choose filler items with equal probability from the top x% of most popular items rather than from the entire collection of items [22].", "startOffset": 214, "endOffset": 218}, {"referenceID": 21, "context": "This method requires at least 5 users who have rated the same item i and item j [22].", "startOffset": 80, "endOffset": 84}, {"referenceID": 21, "context": "Count the number of similarity scores for each item j, and select the top-N item j\u2019s [22].", "startOffset": 85, "endOffset": 89}, {"referenceID": 21, "context": "We select the top-N items based on the total number of user ratings they have in their profile [22].", "startOffset": 95, "endOffset": 99}, {"referenceID": 20, "context": "This method requires at least 5 co-rated items between user u and user v and does not use significance weighting [21].", "startOffset": 113, "endOffset": 117}, {"referenceID": 20, "context": "Count the number of similarity scores for each user v and select the top 50 user v\u2019s [21].", "startOffset": 85, "endOffset": 89}, {"referenceID": 20, "context": "We selected the top 50 users based on the total number of ratings they have in their user profile [21].", "startOffset": 98, "endOffset": 102}, {"referenceID": 2, "context": "Feature extraction from user profiles Previous works [3, 25, 26, 20] summarized different metrics to characterize the features extracted from user profiles.", "startOffset": 53, "endOffset": 68}, {"referenceID": 24, "context": "Feature extraction from user profiles Previous works [3, 25, 26, 20] summarized different metrics to characterize the features extracted from user profiles.", "startOffset": 53, "endOffset": 68}, {"referenceID": 25, "context": "Feature extraction from user profiles Previous works [3, 25, 26, 20] summarized different metrics to characterize the features extracted from user profiles.", "startOffset": 53, "endOffset": 68}, {"referenceID": 19, "context": "Feature extraction from user profiles Previous works [3, 25, 26, 20] summarized different metrics to characterize the features extracted from user profiles.", "startOffset": 53, "endOffset": 68}, {"referenceID": 30, "context": "Besides, we also employ 5 features based on the filler size [31] and propose additional 3 new features which measure the distribution of specific rating such as mean rating, maximum rating and minimum rating in filler items for each user.", "startOffset": 60, "endOffset": 64}, {"referenceID": 2, "context": "are often used to measure the deviation of rating for user profiles [3, 25, 26, 34].", "startOffset": 68, "endOffset": 83}, {"referenceID": 24, "context": "are often used to measure the deviation of rating for user profiles [3, 25, 26, 34].", "startOffset": 68, "endOffset": 83}, {"referenceID": 25, "context": "are often used to measure the deviation of rating for user profiles [3, 25, 26, 34].", "startOffset": 68, "endOffset": 83}, {"referenceID": 33, "context": "are often used to measure the deviation of rating for user profiles [3, 25, 26, 34].", "startOffset": 68, "endOffset": 83}, {"referenceID": 2, "context": "Based on an assumed model, ratings can be automatically divided into filler items and selected items [3, 25, 26, 34].", "startOffset": 101, "endOffset": 116}, {"referenceID": 24, "context": "Based on an assumed model, ratings can be automatically divided into filler items and selected items [3, 25, 26, 34].", "startOffset": 101, "endOffset": 116}, {"referenceID": 25, "context": "Based on an assumed model, ratings can be automatically divided into filler items and selected items [3, 25, 26, 34].", "startOffset": 101, "endOffset": 116}, {"referenceID": 33, "context": "Based on an assumed model, ratings can be automatically divided into filler items and selected items [3, 25, 26, 34].", "startOffset": 101, "endOffset": 116}, {"referenceID": 25, "context": "PT denotes the item set of potential targets [26].", "startOffset": 45, "endOffset": 49}, {"referenceID": 30, "context": "[31].", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "Filler Size with Total Items (FSTI): The ratio between the number of items rated by user u and the number of entire items in the recommender system [31].", "startOffset": 148, "endOffset": 152}, {"referenceID": 30, "context": "Filler Size with Popular Items (FSPI): The ratio between the number of popular items rated by user u and the number of entire popular items in the recommender system [31].", "startOffset": 166, "endOffset": 170}, {"referenceID": 30, "context": "Filler Size with Popular Items in Itself (FSPII): The ratio between the number of popular items rated by user u and the number of entire items rated by user u [31].", "startOffset": 159, "endOffset": 163}, {"referenceID": 30, "context": "Filler Size with Unpopular Items (FSUI): The ratio between the number of unpopular items rated by user u and the number of entire unpopular items in the recommender system [31].", "startOffset": 172, "endOffset": 176}, {"referenceID": 30, "context": "Filler Size with Unpopular Items in Itself (FSUII): The ratio between the number of unpopular items rated by user u and the number of entire items rated by user u [31].", "startOffset": 163, "endOffset": 167}, {"referenceID": 12, "context": "Under this circumstance, Boosting comes into our sights as it has been proved to be efficient when faced with some difficult scenarios as imbalanced classification [13].", "startOffset": 164, "endOffset": 168}, {"referenceID": 8, "context": "The following Algorithm 1 interpret the main idea of AdaBoost [9].", "startOffset": 62, "endOffset": 65}, {"referenceID": 10, "context": "From a statistical view, AdaBoost also can be viewed as a form of \u201dGradient Boosting Machine\u201d [11].", "startOffset": 94, "endOffset": 98}, {"referenceID": 0, "context": "Original gradient Boosting algorithm was proved to be consistent, which can be easily deduced by applying the method in [1] to [18, Theorem1], however, a number of studies [7, 18, 24] also showed that its approximation rate is far slower.", "startOffset": 120, "endOffset": 123}, {"referenceID": 6, "context": "Original gradient Boosting algorithm was proved to be consistent, which can be easily deduced by applying the method in [1] to [18, Theorem1], however, a number of studies [7, 18, 24] also showed that its approximation rate is far slower.", "startOffset": 172, "endOffset": 183}, {"referenceID": 17, "context": "Original gradient Boosting algorithm was proved to be consistent, which can be easily deduced by applying the method in [1] to [18, Theorem1], however, a number of studies [7, 18, 24] also showed that its approximation rate is far slower.", "startOffset": 172, "endOffset": 183}, {"referenceID": 23, "context": "Original gradient Boosting algorithm was proved to be consistent, which can be easily deduced by applying the method in [1] to [18, Theorem1], however, a number of studies [7, 18, 24] also showed that its approximation rate is far slower.", "startOffset": 172, "endOffset": 183}, {"referenceID": 16, "context": "[17] and Xu et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] proposed a re-scale Boosting (RBoosting) to improve the performance of original gradient Boosting.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[8], Regularized truncated Boosting [32], \u03b5-Boosting [14], they cheered a novel direction to improve the numerical convergence rate and consequently, the generalization capability of Boosting.", "startOffset": 0, "endOffset": 3}, {"referenceID": 31, "context": "[8], Regularized truncated Boosting [32], \u03b5-Boosting [14], they cheered a novel direction to improve the numerical convergence rate and consequently, the generalization capability of Boosting.", "startOffset": 36, "endOffset": 40}, {"referenceID": 13, "context": "[8], Regularized truncated Boosting [32], \u03b5-Boosting [14], they cheered a novel direction to improve the numerical convergence rate and consequently, the generalization capability of Boosting.", "startOffset": 53, "endOffset": 57}, {"referenceID": 15, "context": "In segment attack, we use movies {50, 183, 185, 200, 234, 443} as the segmented movies [16].", "startOffset": 87, "endOffset": 91}, {"referenceID": 4, "context": "To measure the effectiveness of the proposed detection methods, we use three metrics such as classification error, detection rate and false alarm rate in the test sets, which are used in similar experiments [5].", "startOffset": 207, "endOffset": 210}, {"referenceID": 3, "context": "The details of setting of each method is described as follows: \u2022 SVM: LibSVM and the default parameters are employed as [4] for training binary profile classifier with Prediction = +1 if classified as authentic and Prediction = \u22121 if classified as attack.", "startOffset": 120, "endOffset": 123}, {"referenceID": 22, "context": "\u2022 kNN: Standard kNN algorithm is used as [23].", "startOffset": 41, "endOffset": 45}, {"referenceID": 28, "context": "\u2022 RAdaBoost: For additional shrinkage degree parameter, sk = 2/(k + u), u \u2208 N, in RBoosting, we create 20 equally spaced values of u in logarithmic space between 1 to 10 and select the appropriate u\u2217 as [29].", "startOffset": 203, "endOffset": 207}, {"referenceID": 2, "context": "Comparing with previous research results [3, 26, 30], the detection performance of RAdaBoost is more optimistic.", "startOffset": 41, "endOffset": 52}, {"referenceID": 25, "context": "Comparing with previous research results [3, 26, 30], the detection performance of RAdaBoost is more optimistic.", "startOffset": 41, "endOffset": 52}, {"referenceID": 29, "context": "Comparing with previous research results [3, 26, 30], the detection performance of RAdaBoost is more optimistic.", "startOffset": 41, "endOffset": 52}], "year": 2015, "abstractText": "Collaborative filtering recommender systems (CFRSs) are the key components of successful e-commerce systems. Actually, CFRSs are highly vulnerable to attacks since its openness. However, since attack size is far smaller than that of genuine users, conventional supervised learning based detection methods could be too \u201cdull\u201d to handle such imbalanced classification. In this paper, we improve detection performance from following two aspects. First, we extract well-designed features from user profiles based on the statistical properties of the diverse attack models, making hard classification task becomes easier to perform. Then, refer to the general idea of re-scale Boosting (RBoosting) and AdaBoost, we apply a variant of AdaBoost, called the rescale AdaBoost (RAdaBoost) as our detection method based on extracted features. RAdaBoost is comparable to the optimal Boosting-type algorithm and can effectively improve the performance in some hard scenarios. Finally, a series of experiments on the MovieLens-100K data set are conducted to demonstrate the outperformance of RAdaBoost comparing with some classical techniques such as SVM, kNN and AdaBoost.", "creator": "LaTeX with hyperref package"}}}