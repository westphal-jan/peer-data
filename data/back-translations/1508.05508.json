{"id": "1508.05508", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Aug-2015", "title": "Towards Neural Network-based Reasoning", "abstract": "We propose Neural Reasoner, a framework for neural network-based thinking about sentences in natural language. When a question is asked, Neural Reasoner can infer several supporting facts and find an answer to the question in specific form. Neural Reasoner has 1) a specific interaction pooling mechanism that allows it to examine several facts, and 2) a deep architecture that allows it to model the complicated logical relationships in argumentation tasks. If no specific structure exists in the questions and facts, Neural Reasoner is able to accommodate different types of thinking and different forms of speech expressions. Despite the complexity of the model, Neural Reasoner can still be trained effectively in an end-to-end manner. Our empirical studies show that Neural Reasoner can surpass existing neural thinking systems with remarkable margins on two difficult artificial tasks (Positional Reasoning and Path Finding).", "histories": [["v1", "Sat, 22 Aug 2015 13:15:09 GMT  (130kb,D)", "http://arxiv.org/abs/1508.05508v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.LG cs.NE", "authors": ["baolin peng", "zhengdong lu", "hang li", "kam-fai wong"], "accepted": false, "id": "1508.05508"}, "pdf": {"name": "1508.05508.pdf", "metadata": {"source": "CRF", "title": "Towards Neural Network-based Reasoning", "authors": ["Baolin Peng", "Zhengdong Lu", "Hang Li", "Kam-Fai Wong"], "emails": ["kfwong}@se.cuhk.edu.hk", "HangLi.HL}@huawei.com"], "sections": [{"heading": "1 Introduction", "text": "Reasoning is essential to natural language processing tasks, most obviously in examples like document summarization, question-answering, and dialogue. Previous efforts in this direction are built on rule-based models, requiring first mapping natural languages to logic forms and then inference over them. The mapping (roughly corresponding to semantic parsing), and the inference, are by no means easy, given the variability and flexibility of natural language, the variety of the reasoning tasks, and the brittleness of a rule-based system.\nJust recently, there is some new effort, mainly represented by Memory Network and its dynamic variants [9, 5], trying to build a purely neural network-based reasoning system with fully distributed semantics that can infer over multiple facts to answer simple questions, all in natural language, e.g.,\nFact1: John travelled to the hallway.\nFact2: Mary journeyed to the bathroom.\nQuestion: Where is Mary?\nThe Memory Nets perform fairly well on simple tasks like the examples above, but poorly\n\u2217The work is done when the first author worked as intern at Noah\u2019s Ark Lab, Huawei Technologies.\nar X\niv :1\n50 8.\n05 50\n8v 1\n[ cs\n.A I]\n2 2\nA ug\non more complicated ones due to their simple and rigid way of modeling the dynamics of question-fact interaction and the complex process of reasoning.\nIn this paper we give a more systematic treatment of the problem and propose a flexible neural reasoning system, named Neural Reasoner. It is purely neural network based and can be trained in an end-to-end way [6], using only supervision from the final answer. Our contributions are mainly two-folds\n\u2022 we propose a novel neural reasoning system Neural Reasoner that can infer over multiple facts in a way insensitive to 1) the number of supporting facts, 2)the form of language, and 3) the type of reasoning;\n\u2022 we give a particular instantiation of Neural Reasoner and a multi-task training method for effectively fitting the model with relatively small amount of data, yielding significantly better results than existing neural models on two artificial reasoning task;"}, {"heading": "2 Overview of Neural Reasoner", "text": "Neural Reasoner has a layered architecture to deal with the complicated logical relations in reasoning, as illustrated in Figure 1. It consists of one encoding layer and multiple reasoning layers. The encoder layer first converts the question and facts from natural language sentences to vectorial representations. More specifically,\nQ encode \u2212\u2212\u2212\u2212\u2192 q(0), Fk encode \u2212\u2212\u2212\u2212\u2192 f (0)k , k = 1, 2, \u00b7 \u00b7 \u00b7 ,K.\nwhere q(0) \u2208 RdQ and f (0)k \u2208 R dF . With the representations obtained from the encoding layer, the reasoning layer recursively updates the representations of questions and facts,\n{q(`) f (`)1 \u00b7 \u00b7 \u00b7 f (`) K } reason \u2212\u2212\u2212\u2212\u2192 {q(`+1) f (`+1)1 \u00b7 \u00b7 \u00b7 f (`+1) K }\nthrough the interaction between question representation and fact representations. Intuitively, this interaction models the reasoning, including examination of the facts and comparison of the facts and the questions. Finally at layer-L, the resulted question representation q(L) is fed to an answerer, which layer can be a classifier for choosing between a number of pre-determined classes (e.g., {Yes, No}) or a text generator for create a sentence.\nWe argue that Neural Reasoner has the following desired properties:\n\u2022 it can handle varying number of facts, including irrelevant ones, and reach the final conclusion through repeated processing of filtering and combining;\n\u2022 it makes no assumption about the form of language, as long as enough training examples are given."}, {"heading": "3 Model", "text": "In this section we give an instantiation of Neural Reasoner described in Section 2, as illustrated in Figure 2. In a nutshell, question and facts, as symbol sequences, are first converted to vectorial representations in the encoding layer via recurrent neural networks (RNNs). The vectorial representations are then fed to the reasoning layers, where the question and the facts get updated through an nonlinear transformation jointly controlled by deep neural networks (DNNs)and pooling. Finally at the answering layer, the resulted question representation is used to generate the final answer to the question. More specifically\n\u2022 in the encoding layer (Layer-0) we use recurrent neural networks (RNNs) to convert question and facts to their vectorial representations, which are then forwarded to the first reasoning layer;\n\u2022 in each reasoning layer (i.e., Layer-` with 1 \u2264 ` \u2264 L\u2212 1), we use a deep neural network (denoted as DNN`) to model the pairwise interaction between question representation\nq(`\u22121) and each fact representation f (`\u22121) k from the previous layer, which yields updated fact representation f (`) k and updated (fact-dependent) question representation q (`) k ;\n\u2022 we then fuse the individual updated fact representations {q(`)1 ,q (`) 2 , \u00b7 \u00b7 \u00b7 ,q (`) K } for the\nglobal updated representation q(`) through a pooling operation (see Section 3.2 for more details)\n\u2022 finally in Layer-L, the interaction net (DNNL) returns only question update, which, after summarization by the pooling operation, will serve as input to the Answering Layer.\nIn the rest of this section, we will give details of different components of the model."}, {"heading": "3.1 Encoding Layer", "text": "The encoding layer is designed to find semantic representations of question and facts. Suppose that we are given a fact or a question as word sequence {x1, \u00b7 \u00b7 \u00b7 , xT }, the encoding module summarizes the word sequence with a vector with fixed length. We have different modeling choices for this purpose, e.g., CNN [4] and RNN [7], while in this paper we use GRU [2], a variant of RNN, as the encoding module. GRU is shown to be able to alleviate the gradient vanishing issue of RNN and have similar performance to the more complicated LSTM [3].\nAs shown in Figure 3, GRU takes as input a sequence of word vectors (for either question or facts)\nX = {x1, \u00b7 \u00b7 \u00b7 ,xT }, xi \u2208 R|V| (1)\nwhere |V| stands for the size of vocabulary for input sentences. Detailed forward computations are as follows:\nzt = \u03c3(WxzExt + Whzht\u22121) (2)\nrt = \u03c3(WxrExt + Whrht\u22121) (3)\nh\u0302t = tanh(WxhExt + Uhh(rt ht\u22121)) (4) ht = (1\u2212 zt) ht\u22121 + zt h\u0302t (5)\nwhere E \u2208 Rm\u00d7k is the word embedding and Wxz,Wxr,Wxh,Whz,Whr,Uhh are weight matrices. We take the last hidden state ht as the representation of the word sequence."}, {"heading": "3.2 Reasoning Layers", "text": "The modules in the reasoning layers include those for question-fact interaction, pooling."}, {"heading": "3.2.1 Question-Fact Interaction", "text": "On reasoning layer `, the kth interaction is between q(`\u22121) and f (`\u22121) k , resulting in updated representations q (`) k and f (`) k\n[q (`) k , f (`) k ] def = gDNN`([(q (`\u22121))>, f (`\u22121) k > ]>; \u0398`), (6)\nwith \u0398` being the parameters. In general, q (`) k and f (`) k can be of different dimensionality as those of the previous layers. In the simplest case with a single layer in DNN`, we have\nq (`) k def = \u03c3(W>` [(q (`\u22121))>, f (`\u22121) k > ] + b`), (7)\nwhere \u03c3(\u00b7) stands for the nonlinear activation function. Roughly speaking, q\n(`) k contains the update of the system\u2019s understanding on answering\nthe question after its interaction with fact K, while f (`) k records the change of the K th fact. Therefore, {(q(`)k ,f (`) k )} constitute the \u201cstate\u201d of the reasoning process."}, {"heading": "3.2.2 Pooling", "text": "Pooling aims to fuse the understanding of the question right after its interaction with all the facts to form the current status of the question, through which we can enable the comparison between different facts. There are several strategies for this pooling\n\u2022 Average/Max Pooling: To obtain the nth element in q(`), we can take the average or the maximum of the elements at the same location from {q(`)1 , \u00b7 \u00b7 \u00b7q (`) K }. For example,\nwith max-pooling, we have\nq(`)(d) = max({q(`)1 (d),q (`) 2 (d), \u00b7 \u00b7 \u00b7 ,q (`) K (d)}), d = 1, 2, \u00b7 \u00b7 \u00b7 , D`\nwhere q(`)(d) stands for the dth element of vector q(`). Clearly this kind of pooling is the simplest, without any associated parameters;\n\u2022 Gating: We can have an extra gating network g(`)(\u00b7) to determine the certainty of the features in q\n(`) k based on {q (`\u22121), f (`\u22121) k } (the input for getting q (`) k ). The output\ng(`)(q(`\u22121), f (`\u22121) k ) has the same dimension as q (`) k , whose n th element, after normalization, can be used as weight for the corresponding element in q (`) k in obtaining q (`).\n\u2022 Model-based: In the case of temporal-reasoning, there is crucial information in the sequential order of the facts. To account for this temporal structure, we can use a CNN\nor RNN to combine the information in {q(`)1 , \u00b7 \u00b7 \u00b7q (`) K }.\nAt layer-L, the query representation q(L) after the pooling will serve as the features for the final decision."}, {"heading": "3.3 Answering Layer", "text": "For simplicity, we focus on the reasoning tasks which can be formulated as classification with predetermined classes. More specifically, we apply Neural Reasoner to deal with the following two types of questions\n\u2022 Type I: General questions, i.e., questions with Yes-No answer;\n\u2022 Type II: Special questions with a small set of candidate answers.\nAt reasoning Layer-L, it performs pooling over the intermediate results to select important information for further uses.\nq = pool({q(L)1 ,q (L) 2 , \u00b7 \u00b7 \u00b7 ,q (L) K }) (8) y = softmax(W>softmaxq (L)) (9)\nAfter reaching the last reasoning step, in this paper we take two steps, Q2 is sent to a standard softmax layer to generate an answer which is formulated as a classification problem.\nThere is another type of prediction as classification where the effective classes dynamically change with instances, e.g., the Single-Supporting-Fact task in [9]. Those tasks cannot be directly solved with Neural Reasoner. One simple way to circumvent this is to define the following score function\nscorez = gmatch(q (L),wz; \u03b8)\nwhere gmatch is a function (e.g., a DNN) parameterized with \u03b8, and wz is the embedding for class z, with z being dynamically determined for the task."}, {"heading": "3.4 Training", "text": "The training of model tunes the parameters in {RNN0,DNN1, \u00b7 \u00b7 \u00b7 ,DNNL} and those in the softmax classifier. Similar to [6], we perform end-to-end training, taking the final answer as the only supervision. More specifically, We use the cross entropy for the cost of classification\nEreasoning = \u2211 n\u2208T DCE(p(y|rn)||yn)\nwhere n indexes the instances in the training set T , and rn = {Qn, Fn,1, \u00b7 \u00b7 \u00b7 , Fn,Kn} stands for question and facts for the nth instance.\nOur end-to-end training is the same as [6], while the training in [9]and [5] use the stepby-step labels on the supporting facts for each instance (see Table 1 for examples) in addition to the answer. As described in [6], those extra labels brings much stronger supervision just the answer in the end-to-end learning setting, and typically yield significantly better result on relatively complicated tasks."}, {"heading": "4 Auxiliary Training for Question/Fact Representation", "text": "We use auxiliary training to facilitate the learning of representations of question and facts. Basically, in addition to using the learned representations of question and facts in the reasoning process, we also use those representations to reconstruct the original questions or their more abstract forms with variables (elaborated later in Section 4.2).\nIn the auxiliary training, we intend to achieve the following two goals\n\u2022 to compensate the lack of supervision in the learning task. In our experiments, the supervision can be fairly weak since for each instance it is merely a classification with no more than 12 classes, while the number of instances are 1K to 10K.\n\u2022 to introduce beneficial bias for the representation learning task. Since the network is a complicated nonlinear function, the back-propagation from the answering layer to the encoding layer can easily fail to learn well."}, {"heading": "4.1 Multi-task Learning Setting", "text": "As illustrated in Figure 4, we take the simplest way to fuse the auxiliary tasks (recovering) with the main task (reasoning) through linearly combining their costs with trade-off parameter \u03b1\nE = \u03b1Erecovering + (1\u2212 \u03b1)Ereasoning (10)\nwhereEreasoning is the cross entropy loss describing the discrepancy of model prediction from correct answer (see Section 3.4), and Erecovering is the negative log-likelihood of the sequences (question or facts) to be recovered. More specifically,\nErecovering = \u2211 n\u2208T { Kn\u2211 k=1 log p(Fn,k|f (0) n,k) + log p(Qn|q (0) n )}\nwhere the likelihood is estimated as in the encoder-decoder framework proposed in [2]. On top of the encoding layer (RNN), we add another decoding layer (RNN) which is trained to sequentially predict words in the original sentence."}, {"heading": "4.2 Abstract Forms with Variables", "text": "Instead of recovering the original sentence in question and facts, we also study the effect of producing a more abstract form in the auxiliary training task. More specifically, we let the decoding RNN to recover a sentence with entities replaced with variables (treated as particular symbols), e.g.,\nThe triangle is above the pink rectangle. recover \u2212\u2212\u2212\u2212\u2192x is above y.\nThe blue square is to the left of the triangle. recover \u2212\u2212\u2212\u2212\u2192z is to the left of x.\nIs the pink rectangle to the right of the square? recover \u2212\u2212\u2212\u2212\u2192Is y to the right of the z ?\nThrough this, we intend to teach the system a more abstract way of representing sentences (both question and facts) and their interactions. More specifically,\n\u2022 all the entities are only meaningful only when they are compared with each other. In other words, the model (in the encoding and reasoning layers) should not consider specific entities, but their general notions.\n\u2022 it helps the model to focus on the relations between the entities, the commonality of different facts, and the patterns shared between different instances."}, {"heading": "5 Experiments", "text": "We report our empirical study on applying Neural Reasoner to the Question Answer task defined in [8], and compare it against state-of-the-art neural models [9, 5]."}, {"heading": "5.1 Setup", "text": "bAbI is a synthetic question and answering dataset. It contains 20 tasks, and each of them is composed of a set of facts, a question and followed by an answer which is mostly a single word. For most of the time, only a subset of facts are relevant to the given question. Two versions of the data are available, one has 1K training instances per task and the other has 10K instances per task, while the testing set are the same for the two versions.\nWe select the two most challenging tasks (among the 20 tasks in [8] ) Positional Reasoning and Path Finding, to test the reasoning ability of Neural Reasoner. Positional Reasoning task tests model\u2019s spatial reasoning ability, while Path Finding task, first proposed in [1] tests the ability to reason the correct path between objects based on natural language instructions. In Table 1, we give an instance of each task."}, {"heading": "5.2 Implementation Details", "text": "In our experiments, we actually used a simplified version of Neural Reasoner . In the version\n\u2022 we choose to keep the representation un-updated on each layer, e.g.,\nFk encode \u2212\u2212\u2212\u2212\u2192 f (0)k = f (1) k = \u00b7 \u00b7 \u00b7 = f (L\u22121) k , k = 1, 2, \u00b7 \u00b7 \u00b7 ,K.\nThis choice pushes the update q (`) k (and its summarization q (`)) to record all the information in the interaction between facts and question.\n\u2022 we use only two layers, i.e., L = 2, for the relatively simple task in the experiments.\nOur model was trained with the standard back-propagation (BP) aiming to maximize the likelihood of correct answers. All the parameters including the word-embeddings were initialized by randomly sampling from a uniform distribution [-0.1, 0.1]. No momentum and weight decay was used. We trained all the tasks for 200 epochs with stochastic gradient descent and the gradients which had `2 norm larger than 40 were clipped, learning rate being controlled by AdaDelta [10]. For multi-task learning, different mixture ratios were tried, from 0.1 to 0.9."}, {"heading": "5.3 Neural Reasoner vs. Competitor Models", "text": "We compare Neural Reasoner with the following three neural reasoning models: 1)Memory Network, including the one with step-by-step supervision [9](denoted as Memory Net-Step) and the end-to-end version [6] (denoted as Memory Net-N2N), and 2) Dynamic Memory Network, proposed in [5], also with step-by-step supervision. In Table 2, we report the performance of a particular case of Neural Reasoner with 1) two reasoning layers, 2) 2-layer DNNs as the interaction modules in each reasoning layer, and 3) auxiliary task of recovering the original question and facts. The results are compared against three neural competitors. We have the following observations.\n\u2022 The proposed Neural Reasoner performs significantly better than Memory Net-N2N, especially with more training data.\n\u2022 Although not a fair comparison to our model, Neural Reasoner is actually better than Memory Net-N2N and Dynamic Memory Net on Positional Reasoning (1K)\n& (10K) as well as Path Finding (10K), with about 20% margin on both tasks with 10K training instances.\nPlease note that the results of Neural Reasoner reported in Table 2 are not based on architectures specifically tuned for the tasks. As a matter of fact, with more complicated models (more reasoning layers and deeper interaction modules), we can achieve even better results on large datasets (e.g., over 98% accuracy on Path Finding with 10K instances). We will however leave the discussion on different architectural variants to the next section."}, {"heading": "5.4 Architectural Variations", "text": "This section is devoted to the study of architectural variants of Neural Reasoner. More specifically, we consider the variations in 1)the number of reasoning layers, 2) the depth of the interaction DNN, and 3) the auxiliary tasks, with results summarized by Table 3. We have the following observations:\n\u2022 Auxiliary tasks are essential to the efficacy of Neural Reasoner, without which the performances of Neural Reasoner drop dramatically. The reason, as we conjecture in Section 4, is that the reasoning task alone cannot give enough supervision for learning accurate word vectors and parameters of the RNN encoder. We note that Neural Reasoner can still outperform Memory Net (N2N) with 10K data on both tasks.\n\u2022 Neural Reasoner with shallow architectures, more specifically two reasoning layers and 1-layer DNN, apparently can benefit from the auxiliary learning of recovering abstract forms on small datasets (1K on both tasks). However, with deeper architectures or more training data, the improvement over that of recovering original sentences become smaller, despite the extra information it utilizes.\n\u2022 When larger training datasets are available, Neural Reasoner appears to prefer relatively deeper architectures. More importantly, although both tasks require two reasoning steps, the performance does not deteriorate with three reasoning layers. On both\ntasks, with 10K training instances, Neural Reasoner with three reasoning layers and 3-layer DNN can achieve over 98% accuracy."}, {"heading": "6 Conclusion and Future Work", "text": "We have proposed Neural Reasoner, a framework for neural network-based reasoning over natural language sentences. Neural Reasoner is flexible, powerful, and language indepedent. Our empirical studies show that Neural Reasoner can dramatically improve upon existing neural reasoning systems on two difficult artificial tasks proposed in [9]. For future work, we will explore 1) tasks with higher difficulty and reasoning depth, e.g., tasks which require a large number of supporting facts and facts with complex intrinsic structures, 2) the common structure in different but similar reasoning tasks (e.g., multiple tasks all with general questions), and 3) automatic selection of the reasoning architecture, for example, determining when to stop the reasoning based on the data."}], "references": [{"title": "Learning to interpret natural language navigation instructions from observations", "author": ["D.L. Chen", "R.J. Mooney"], "venue": "Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, 11  AAAI 2011, San Francisco, California, USA, August 7-11, 2011", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "B", "author": ["K. Cho"], "venue": "van Merrienboer, C. Gulcehre, F. Bougares, H. Schwenk, and Y. Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. In Proceedings of EMNLP, pages 1724\u20131734", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "cC", "author": ["J. Chung"], "venue": "G\u00fclccehre, K. Cho, and Y. Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Convolutional neural network architectures for matching natural language sentences", "author": ["B. Hu", "Z. Lu", "H. Li", "Q. Chen"], "venue": "Advances in Neural Information Processing Systems 27, pages 2042\u20132050", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Ask me anything: Dynamic memory networks for natural language processing", "author": ["A. Kumar", "O. Irsoy", "J. Su", "J. Bradbury", "R. English", "B. Pierce", "P. Ondruska", "I. Gulrajani", "R. Socher"], "venue": "CoRR, abs/1506.07285", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Weakly supervised memory networks", "author": ["S. Sukhbaatar", "A. Szlam", "J. Weston", "R. Fergus"], "venue": "CoRR, abs/1503.08895", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Advances in Neural Information Processing Systems, pages 3104\u20133112", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Towards ai-complete question answering: A set of prerequisite toy tasks", "author": ["J. Weston", "A. Bordes", "S. Chopra", "T. Mikolov"], "venue": "CoRR, abs/1502.05698", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Memory networks", "author": ["J. Weston", "S. Chopra", "A. Bordes"], "venue": "CoRR, abs/1410.3916", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Adadelta: an adaptive learning rate method", "author": ["M.D. Zeiler"], "venue": "arXiv preprint arXiv:1212.5701", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 7, "context": "Our empirical studies show that Neural Reasoner can outperform existing neural reasoning systems with remarkable margins on two difficult artificial tasks (Positional Reasoning and Path Finding) proposed in [8].", "startOffset": 207, "endOffset": 210}, {"referenceID": 5, "context": "4% [6] to over 98%.", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": "Just recently, there is some new effort, mainly represented by Memory Network and its dynamic variants [9, 5], trying to build a purely neural network-based reasoning system with fully distributed semantics that can infer over multiple facts to answer simple questions, all in natural language, e.", "startOffset": 103, "endOffset": 109}, {"referenceID": 4, "context": "Just recently, there is some new effort, mainly represented by Memory Network and its dynamic variants [9, 5], trying to build a purely neural network-based reasoning system with fully distributed semantics that can infer over multiple facts to answer simple questions, all in natural language, e.", "startOffset": 103, "endOffset": 109}, {"referenceID": 5, "context": "It is purely neural network based and can be trained in an end-to-end way [6], using only supervision from the final answer.", "startOffset": 74, "endOffset": 77}, {"referenceID": 3, "context": ", CNN [4] and RNN [7], while in this paper we use GRU [2], a variant of RNN, as the encoding module.", "startOffset": 6, "endOffset": 9}, {"referenceID": 6, "context": ", CNN [4] and RNN [7], while in this paper we use GRU [2], a variant of RNN, as the encoding module.", "startOffset": 18, "endOffset": 21}, {"referenceID": 1, "context": ", CNN [4] and RNN [7], while in this paper we use GRU [2], a variant of RNN, as the encoding module.", "startOffset": 54, "endOffset": 57}, {"referenceID": 2, "context": "GRU is shown to be able to alleviate the gradient vanishing issue of RNN and have similar performance to the more complicated LSTM [3].", "startOffset": 131, "endOffset": 134}, {"referenceID": 8, "context": ", the Single-Supporting-Fact task in [9].", "startOffset": 37, "endOffset": 40}, {"referenceID": 5, "context": "Similar to [6], we perform end-to-end training, taking the final answer as the only supervision.", "startOffset": 11, "endOffset": 14}, {"referenceID": 5, "context": "Our end-to-end training is the same as [6], while the training in [9]and [5] use the stepby-step labels on the supporting facts for each instance (see Table 1 for examples) in addition to the answer.", "startOffset": 39, "endOffset": 42}, {"referenceID": 8, "context": "Our end-to-end training is the same as [6], while the training in [9]and [5] use the stepby-step labels on the supporting facts for each instance (see Table 1 for examples) in addition to the answer.", "startOffset": 66, "endOffset": 69}, {"referenceID": 4, "context": "Our end-to-end training is the same as [6], while the training in [9]and [5] use the stepby-step labels on the supporting facts for each instance (see Table 1 for examples) in addition to the answer.", "startOffset": 73, "endOffset": 76}, {"referenceID": 5, "context": "As described in [6], those extra labels brings much stronger supervision just the answer in the end-to-end learning setting, and typically yield significantly better result on relatively complicated tasks.", "startOffset": 16, "endOffset": 19}, {"referenceID": 1, "context": "where the likelihood is estimated as in the encoder-decoder framework proposed in [2].", "startOffset": 82, "endOffset": 85}, {"referenceID": 7, "context": "We report our empirical study on applying Neural Reasoner to the Question Answer task defined in [8], and compare it against state-of-the-art neural models [9, 5].", "startOffset": 97, "endOffset": 100}, {"referenceID": 8, "context": "We report our empirical study on applying Neural Reasoner to the Question Answer task defined in [8], and compare it against state-of-the-art neural models [9, 5].", "startOffset": 156, "endOffset": 162}, {"referenceID": 4, "context": "We report our empirical study on applying Neural Reasoner to the Question Answer task defined in [8], and compare it against state-of-the-art neural models [9, 5].", "startOffset": 156, "endOffset": 162}, {"referenceID": 7, "context": "We select the two most challenging tasks (among the 20 tasks in [8] ) Positional Reasoning and Path Finding, to test the reasoning ability of Neural Reasoner.", "startOffset": 64, "endOffset": 67}, {"referenceID": 0, "context": "Positional Reasoning task tests model\u2019s spatial reasoning ability, while Path Finding task, first proposed in [1] tests the ability to reason the correct path between objects based on natural language instructions.", "startOffset": 110, "endOffset": 113}, {"referenceID": 9, "context": "We trained all the tasks for 200 epochs with stochastic gradient descent and the gradients which had `2 norm larger than 40 were clipped, learning rate being controlled by AdaDelta [10].", "startOffset": 181, "endOffset": 185}, {"referenceID": 8, "context": "We compare Neural Reasoner with the following three neural reasoning models: 1)Memory Network, including the one with step-by-step supervision [9](denoted as Memory Net-Step) and the end-to-end version [6] (denoted as Memory Net-N2N), and 2) Dynamic Memory Network, proposed in [5], also with step-by-step supervision.", "startOffset": 143, "endOffset": 146}, {"referenceID": 5, "context": "We compare Neural Reasoner with the following three neural reasoning models: 1)Memory Network, including the one with step-by-step supervision [9](denoted as Memory Net-Step) and the end-to-end version [6] (denoted as Memory Net-N2N), and 2) Dynamic Memory Network, proposed in [5], also with step-by-step supervision.", "startOffset": 202, "endOffset": 205}, {"referenceID": 4, "context": "We compare Neural Reasoner with the following three neural reasoning models: 1)Memory Network, including the one with step-by-step supervision [9](denoted as Memory Net-Step) and the end-to-end version [6] (denoted as Memory Net-N2N), and 2) Dynamic Memory Network, proposed in [5], also with step-by-step supervision.", "startOffset": 278, "endOffset": 281}, {"referenceID": 8, "context": "The results of Memory Net-step, Memory Net-N2N, and Dynamic Memory Net are taken respectively from [9],[6] and [5].", "startOffset": 99, "endOffset": 102}, {"referenceID": 5, "context": "The results of Memory Net-step, Memory Net-N2N, and Dynamic Memory Net are taken respectively from [9],[6] and [5].", "startOffset": 103, "endOffset": 106}, {"referenceID": 4, "context": "The results of Memory Net-step, Memory Net-N2N, and Dynamic Memory Net are taken respectively from [9],[6] and [5].", "startOffset": 111, "endOffset": 114}, {"referenceID": 8, "context": "Our empirical studies show that Neural Reasoner can dramatically improve upon existing neural reasoning systems on two difficult artificial tasks proposed in [9].", "startOffset": 158, "endOffset": 161}], "year": 2015, "abstractText": "We propose Neural Reasoner , a framework for neural network-based reasoning over natural language sentences. Given a question, Neural Reasoner can infer over multiple supporting facts and find an answer to the question in specific forms. Neural Reasoner has 1) a specific interaction-pooling mechanism, allowing it to examine multiple facts, and 2) a deep architecture, allowing it to model the complicated logical relations in reasoning tasks. Assuming no particular structure exists in the question and facts, Neural Reasoner is able to accommodate different types of reasoning and different forms of language expressions. Despite the model complexity, Neural Reasoner can still be trained effectively in an end-to-end manner. Our empirical studies show that Neural Reasoner can outperform existing neural reasoning systems with remarkable margins on two difficult artificial tasks (Positional Reasoning and Path Finding) proposed in [8]. For example, it improves the accuracy on Path Finding(10K) from 33.4% [6] to over 98%.", "creator": "LaTeX with hyperref package"}}}