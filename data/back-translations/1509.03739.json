{"id": "1509.03739", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2015", "title": "Improving distant supervision using inference learning", "abstract": "Remote monitoring is a widely used approach to automatically train relationship extraction systems and has the advantage that it can generate large amounts of tagged data with minimal effort. However, this data can contain errors and, as a result, systems trained by remote monitoring tend not to perform as well as those based on manually tagged data. This work proposes a new method of detecting possible false negative training examples using a method of knowledge deduction. Results show that our approach improves the performance of relationship extraction systems trained using remotely monitored data.", "histories": [["v1", "Sat, 12 Sep 2015 12:59:05 GMT  (43kb,D)", "http://arxiv.org/abs/1509.03739v1", "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)"]], "COMMENTS": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["roland roller", "eneko agirre", "aitor soroa", "mark stevenson"], "accepted": true, "id": "1509.03739"}, "pdf": {"name": "1509.03739.pdf", "metadata": {"source": "CRF", "title": "Improving distant supervision using inference learning", "authors": ["Roland Roller", "Eneko Agirre", "Aitor Soroa", "Mark Stevenson"], "emails": ["roland.roller@sheffield.ac.uk", "mark.stevenson@sheffield.ac.uk", "e.agirre@ehu.eus", "a.soroa@ehu.eus"], "sections": [{"heading": "1 Introduction", "text": "Distantly supervised relation extraction relies on automatically labelled data generated using information from a knowledge base. A sentence is annotated as a positive example if it contains a pair of entities that are related in the knowledge base. Negative training data is often generated using a closed world assumption: pairs of entities not listed in the knowledge base are assumed to be unrelated and sentences containing them considered to be negative training examples. However this assumption is violated when the knowledge base is incomplete which can lead to sentences containing instances of relations being wrongly annotated as negative examples.\nWe propose a method to improve the quality of distantly supervised data by identifying possible wrongly annotated negative instances. Our proposed method includes a version of the Path Ranking Algorithm (PRA) (Lao and Cohen, 2010; Lao et al., 2011) which infers relation paths by combining random walks though a knowledge base.\nWe use this knowledge inference to detect possible false negatives (or at least entity pairs closely connected to a target relation) in automatically labelled training data and show that their removal can improve relation extraction performance."}, {"heading": "2 Related Work", "text": "Distant supervision is widely used to train relation extraction systems with Freebase and Wikipedia commonly being used as knowledge bases, e.g. (Mintz et al., 2009; Riedel et al., 2010; Krause et al., 2012; Zhang et al., 2013; Min et al., 2013; Ritter et al., 2013). The main advantage is its ability to automatically generate large amounts of training data automatically. On the other hand, this automatically labelled data is noisy and usually generates lower performance than approaches trained using manually labelled data. A range of filtering approaches have been applied to address this problem including multi-class SVM (Nguyen and Moschitti, 2011) and Multi-Instance learning methods (Riedel et al., 2010; Surdeanu et al., 2012). These approaches take into account the fact that entities might occur in different relations at the same time and may not necessarily express the target relation. Other approaches focus directly on the noise in the data. For instance Takamatsu et al. (2012) use a generative model to predict incorrect data while Intxaurrondo et al. (2013) use a range of heuristics including PMI to remove noise. Augenstein et al. (2014) apply techniques to detect highly ambiguous entity pairs and discard them from their labelled training set.\nThis work proposes a novel approach to the problem by applying an inference learning method to identify potential false negatives in distantly labelled data. Our method makes use of a modified version of PRA to learn relation paths from a knowledge base and uses this information to identify false negatives.\nar X\niv :1\n50 9.\n03 73\n9v 1\n[ cs\n.C L\n] 1\n2 Se\np 20\n15"}, {"heading": "3 Data and Methods", "text": "We chose to apply our approach to relation extraction tasks from the biomedical domain since this has proved to be an important problem within these documents (Jensen et al., 2006; Hahn et al., 2012; Cohen and Hunter, 2013; Roller and Stevenson, 2014). In addition, the first application of distant supervision was to biomedical journal articles (Craven and Kumlien, 1999). In addition, the most widely used knowledge source in this domain, the UMLS Metathesaurus (Bodenreider, 2004), is an ideal resource to apply inference learning given its rich structure.\nWe develop classifiers to identify relations found in two subsets of UMLS: the National Drug File-Reference Terminology (ND-FRT) and the National Cancer Institute Thesaurus (NCI). A corpus of approximately 1,000,000 publications is used to create the distantly supervised training data. The corpus contains abstracts published between 1990 and 2001 annotated with UMLS concepts using MetaMap (Aronson and Lang, 2010)."}, {"heading": "3.1 Distantly labelled data", "text": "Distant supervision is carried out for a target UMLS relation by identifying instance pairs and using them to create a set of positive instance pairs. Any pairs which also occur as an instance pair of another UMLS relation are removed from this set. A set of negative instance pairs is then created by forming new combinations that do not occur within the positive instance pairs. Sentences containing a positive or negative instance pair are then extracted to generate positive and negative training examples for the relation. These candidate sentences are then stemmed (Porter, 1997) and PoS tagged (Charniak and Johnson, 2005).\nThe sets of positive and negative training examples are then filtered to remove sentences that meet any of the following criteria: contain the same positive pair more than once; contain both a positive and negative pair; more than 5 words between the two elements of the instance pair; contain very common instance pairs."}, {"heading": "3.2 PRA-Reduction", "text": "PRA (Lao and Cohen, 2010; Lao et al., 2011) is an algorithm that infers new relation instances from knowledge bases. By considering a knowledge base as a graph, where nodes are connected through typed relations, it performs random walks\nover it and finds bounded-length relation paths that connect graph nodes. These paths are used as features in a logistic regression model, which is meant to predict new relations in the graph. Although initially conceived as an algorithm to discover new links in the knowledge base, PRA can also be used to learn relevant relation paths for any given relation. For instance, if x and y are related via sibling relation, the model trained by PRA would learn that the relation path parent(x,a) \u2227 parent(a,y)1 is highly relevant, as siblings share the same parents.\nKnowledge graphs were extracted from the NDFRT and NCI vocabularies generating approximately 200, 000 related instance pairs for NDFRT and 400, 000 for NCI. PRA is then run on both graphs in order to learn paths for each target relation. Table 1 shows examples of the paths PRA generated for the relation biological-processinvolves-gene-product together with their weights. We only make use of relation paths with positive weights generated by PRA.\nThe paths induced by PRA are used to identify potential false negatives in the negative training examples (Section 3.1). Each negative training example is examined to check whether the entity pair is related in UMLS by following any of the relation paths extracted by PRA for the relevant target relation. Examples containing related entity pairs are assumed to be false negatives, since the relation can be inferred from the knowledge base, and removed from the set of negatives training examples. For instance, using the path in the top row of Table 1, sentences containing the entities x and y would be removed if the path geneencodes-gene-product(x,a) \u2227 gene-plays-role-inprocess(a,y) could be identified within UMLS.\n1An underline (\u2018 \u2019) prefix represents the inverse of a relation while \u2227 represents path composition."}, {"heading": "3.3 Evaluation", "text": "Relation Extraction system: The MultiR system (Hoffmann et al., 2010) with features described by Surdeanu et al. (2011) was used for the experiments. Datasets: Three datasets were created to train MultiR and evaluate performance. The first (Unfiltered) uses the data obtained using distant supervision (Section 3.1) without removing any examples identified by PRA. The overall ratio of positive to negative sentences in this dataset was 1:5.1. However, this changes to 1:2.3 after removing examples identified by PRA. Consequently the bias in the distantly supervised data was adjusted to 1:2 to increase comparability across configurations. Reducing bias was also found to increase relation extraction performance, producing a strong baseline. The PRA-reduced dataset is created by applying PRA reduction (Section 3.2) to the Unfiltered dataset to remove a portion of the negative training examples. Removing these examples produces a dataset that is smaller than Unfiltered and with a different bias. Changing the bias of the training data can influence the classification results. Consequently the Random-reduced dataset was created by removing randomly selected negative examples from Unfiltered to produce a dataset with the same size and bias as PRA-reduced. The Random-reduced dataset is used to show that randomly removing negative instances leads to lower results than removing those suggested by PRA.\nEvaluation: Two approaches were used to evaluate performance.\nThe Held-out datasets consist of the Unfiltered, PRA-reduced and Random-reduced data sets. The set of entity pairs obtained from the knowledge base is split into four parts and a process similar to 4-fold cross validation applied. In each fold the automatically labelled sentences obtained from the pairs in 3 of the quarters are used as training data and sentences obtained from the remaining quarter used for testing.\nThe Manually labelled dataset contains 400 examples of the relation may-prevent and 400 of may-treat which were manually labelled by two annotators who were medical experts. Both relations are taken from the ND-FRT subset of UMLS. Each annotator was asked to label every sentence and then re-examine cases where there was disagreement. This process lead to inter-annotator agreement of 95.5% for may-treat and 97.3% for\nmay-prevent. The annotated data set is publicly available2. Any sentences in the training data containing an entity pair that occurs within the manually labelled dataset are removed. Although this dataset is smaller than the held-out dataset, its annotations are more reliable and it is therefore likely to be a more accurate indicator of performance accuracy. This dataset is more balanced than the held-out data with a ratio of 1:1.3 for may-treat and 1:1.8 for may-prevent.\nEvaluation metric: Our experiments use entity level evaluation since this is the most appropriate approach to determine suitability for database population. Precision and recall are computed based on the proportion of entity pairs identified. For the held-out data the set of correct entity pairs are those which occur in sentences labeled as positive examples of the relation and which are also listed as being related in UMLS. For the manually labelled data it is simply the set of entity pairs that occur in positive examples of the relation."}, {"heading": "4 Results", "text": ""}, {"heading": "4.1 Held-out data", "text": "Table 2 shows the results obtained using the heldout data. Overall results, averaged across all relations with maximum recall, are shown in the top portion of the table and indicate that applying PRA improves performance. Although the highest precision is obtained using the Unfiltered classifier, the PRA-reduced classifier leads to the best recall and F1. Performance of the Random-reduced classifier indicates that the improvement is not simply due to a change in the bias in the data but that the examples it contains lead to an improved model.\nThe lower part of Table 2 shows results for each relation. The PRA-reduced classifier produces the best results for the majority of relations and always increases recall compared to Unfiltered.\nIt is perhaps surprising that removing false negatives from the training data leads to an increase in recall, rather than precision. False negatives cause the classifier to generate an overly restrictive model of the relation and to predict positive examples of a relation as negative. Removing them leads to a less constrained model and higher recall.\nThere are two relations where there is also an increase in precision (contraindicating-class-of and mechanism-of-action-of ) and these are also the ones for which the fewest training examples are\n2https://sites.google.com/site/umlscorpus/home\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0 0.2 0.4 0.6 0.8 1\nP re\nc is\nio n\nRecall\nunfiltered PRA-reduced Random-reduced\nFigure 1: Precision/Recall Curve for Held-out data\navailable. The classifier has access to such a limited amount of data for these relations that removing the false negatives identified by PRA allows it to learn a more accurate model.\nFigure 1 presents a precision/recall curve computed using MultiR\u2019s output probabilities. Results for the PRA-reduced and the Random-reduced classifiers show that reducing the amount of negative training data increases recall. However, using PRA-reduced generally leads to higher precision, indicating that PRA is able to identify suitable instances for removal from the training set. The Unfiltered classifier produces good results but precision and recall are lower than PRA-reduced."}, {"heading": "4.2 Manually labelled", "text": "Table 3 shows results of evaluation on the more reliable manually labelled data set. The best over-\nall performance is once again obtained using the PRA-reduced classifier. There is an increase in recall for both relations and a slight increase in precision for may treat. Performance of the Randomreduced classifier also improves due to an increasing recall but remains below PRA-reduced. Performance of the Random-reduced classifier is also better than Unfiltered, with the overall improvement largely resulting from increased recall, but below PRA-reduced. These results confirm that removing examples identified by PRA improves the quality of training data.\nFurther analysis indicated that the PRA-reduced classifier produces the fewest false negatives in its predictions on the manually annotated dataset. It incorrectly labels 82 entity pairs (45 may-treat, 37 may-prevent) as negative while Unfiltered predicts 120 (73, 47) and Random-reduced 114 (69, 45). This supports our initial hypothesis that removing potential false negatives from training data improves classifier predictions."}, {"heading": "5 Conclusions and Future Work", "text": "This paper proposes a novel approach to identifying incorrectly labelled instances generated using distant supervision. Our method applies an inference learning method to detect and discard possible false negatives from the training data. We show that our method improves performance for a range of relations in the biomedical domain by making use of information from UMLS.\nIn future we would like to explore alternative\nmethods for selecting PRA relation paths to identify false negatives. Furthermore we would like to examine the PRA-reduced data in more detail. We would like to find which kind of entity pairs are detected by our proposed method and whether the reduced data can also be used to extend the positive training data. We would also like to apply the approach to other domains and alternative knowledge bases. Finally it would be interesting to compare our approach to other state of the art relation extraction systems for distant supervision or biased-SVM approaches such as Liu et al. (2003)."}, {"heading": "Acknowledgements", "text": "The authors are grateful to the Engineering and Physical Sciences Research Council for supporting the work described in this paper (EP/J008427/1)."}], "references": [{"title": "An overview of MetaMap: historical perspective and recent advances", "author": ["Aronson", "Lang2010] A. Aronson", "F. Lang"], "venue": "Journal of the American Medical Association,", "citeRegEx": "Aronson et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Aronson et al\\.", "year": 2010}, {"title": "Relation extraction from the web using distant supervision", "author": ["Diana Maynard", "Fabio Ciravegna"], "venue": "In Proceedings of the 19th International Conference on Knowledge Engineering and Knowledge", "citeRegEx": "Augenstein et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Augenstein et al\\.", "year": 2014}, {"title": "The unified medical language system (umls): integrating biomedical terminology", "author": ["Olivier Bodenreider"], "venue": "Nucleic acids research,", "citeRegEx": "Bodenreider.,? \\Q2004\\E", "shortCiteRegEx": "Bodenreider.", "year": 2004}, {"title": "Coarse-to-fine n-best parsing and maxent discriminative reranking", "author": ["Charniak", "Johnson2005] Eugene Charniak", "Mark Johnson"], "venue": "In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Charniak et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Charniak et al\\.", "year": 2005}, {"title": "Text mining for translational bioinformatics", "author": ["Cohen", "Hunter2013] K Bretonnel Cohen", "Lawrence E Hunter"], "venue": "PLoS computational biology,", "citeRegEx": "Cohen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 2013}, {"title": "Constructing biological knowledge bases by extracting information from text sources", "author": ["Craven", "Kumlien1999] Mark Craven", "Johan Kumlien"], "venue": "Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology", "citeRegEx": "Craven et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Craven et al\\.", "year": 1999}, {"title": "Mining the pharmacogenomics literaturea survey of the state of the art", "author": ["Hahn et al.2012] Udo Hahn", "K Bretonnel Cohen", "Yael Garten", "Nigam H Shah"], "venue": "Briefings in bioinformatics,", "citeRegEx": "Hahn et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hahn et al\\.", "year": 2012}, {"title": "Learning 5000 relational extractors", "author": ["Congle Zhang", "Daniel S. Weld"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Hoffmann et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2010}, {"title": "Removing noisy mentions for distant supervision", "author": ["Mihai Surdeanu", "Oier Lopez de Lacalle", "Eneko Agirre"], "venue": "Procesamiento del Lenguaje Natural,", "citeRegEx": "Intxaurrondo et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Intxaurrondo et al\\.", "year": 2013}, {"title": "Literature mining for the biologist: from information retrieval to biological discovery", "author": ["Jasmin Saric", "Peer Bork"], "venue": "Nature reviews genetics,", "citeRegEx": "Jensen et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Jensen et al\\.", "year": 2006}, {"title": "Large-scale learning of relation-extraction rules with distant supervision from the web", "author": ["Hong Li", "Hans Uszkoreit", "Feiyu Xu"], "venue": "In Proceedings of the 11th International Conference on The Semantic Web", "citeRegEx": "Krause et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krause et al\\.", "year": 2012}, {"title": "Relational retrieval using a combination of path-constrained random walks", "author": ["Lao", "Cohen2010] Ni Lao", "William W. Cohen"], "venue": null, "citeRegEx": "Lao et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lao et al\\.", "year": 2010}, {"title": "Random walk inference and learning in a large scale knowledge base", "author": ["Lao et al.2011] Ni Lao", "Tom Mitchell", "William W. Cohen"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Lao et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lao et al\\.", "year": 2011}, {"title": "Building text classifiers using positive and unlabeled examples", "author": ["Liu et al.2003] Bing Liu", "Yang Dai", "Xiaoli Li", "Wee Sun Lee", "Philip S. Yu"], "venue": "In Intl. Conf. on Data Mining,", "citeRegEx": "Liu et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2003}, {"title": "Distant supervision for relation extraction with an incomplete knowledge base", "author": ["Min et al.2013] Bonan Min", "Ralph Grishman", "Li Wan", "Chang Wang", "David Gondek"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Asso-", "citeRegEx": "Min et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Min et al\\.", "year": 2013}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mintz et al.2009] Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International", "citeRegEx": "Mintz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "End-to-end relation extraction using distant supervision from external semantic repositories", "author": ["Nguyen", "Alessandro Moschitti"], "venue": "In Proceedings of the 49th Annual Meeting of the Association", "citeRegEx": "Nguyen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2011}, {"title": "Readings in information retrieval. chapter An Algorithm for Suffix Stripping, pages 313\u2013316", "author": ["M.F. Porter"], "venue": null, "citeRegEx": "Porter.,? \\Q1997\\E", "shortCiteRegEx": "Porter.", "year": 1997}, {"title": "Modeling relations and their mentions without labeled text", "author": ["Limin Yao", "Andrew McCallum"], "venue": "In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML", "citeRegEx": "Riedel et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2010}, {"title": "Modeling missing data in distant supervision for information extraction. Transactions of the Association for Computational Linguistics, 1:367\u2013378", "author": ["Ritter et al.2013] Alan Ritter", "Luke Zettlemoyer", "Oren Etzioni"], "venue": null, "citeRegEx": "Ritter et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ritter et al\\.", "year": 2013}, {"title": "Self-supervised relation extraction using umls", "author": ["Roller", "Stevenson2014] Roland Roller", "Mark Stevenson"], "venue": "In Proceedings of the Conference and Labs of the Evaluation Forum", "citeRegEx": "Roller et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Roller et al\\.", "year": 2014}, {"title": "Customizing an information extraction system to a new domain", "author": ["David McClosky", "Mason Smith", "Andrey Gusev", "Christopher Manning"], "venue": "In Proceedings of the ACL 2011 Workshop on Relational Models", "citeRegEx": "Surdeanu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2011}, {"title": "Multi-instance multi-label learning for relation extraction", "author": ["Julie Tibshirani", "Ramesh Nallapati", "Christopher D. Manning"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Lan-", "citeRegEx": "Surdeanu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2012}, {"title": "Reducing wrong labels in distant supervision for relation extraction", "author": ["Issei Sato", "Hiroshi Nakagawa"], "venue": "In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers", "citeRegEx": "Takamatsu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Takamatsu et al\\.", "year": 2012}, {"title": "Towards accurate distant supervision for relational facts extraction", "author": ["Zhang et al.2013] Xingxing Zhang", "Jianwen Zhang", "Junyu Zeng", "Jun Yan", "Zheng Chen", "Zhifang Sui"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computa-", "citeRegEx": "Zhang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 12, "context": "Our proposed method includes a version of the Path Ranking Algorithm (PRA) (Lao and Cohen, 2010; Lao et al., 2011) which infers relation paths by combining random walks though a knowledge base.", "startOffset": 75, "endOffset": 114}, {"referenceID": 15, "context": "(Mintz et al., 2009; Riedel et al., 2010; Krause et al., 2012; Zhang et al., 2013; Min et al., 2013; Ritter et al., 2013).", "startOffset": 0, "endOffset": 121}, {"referenceID": 18, "context": "(Mintz et al., 2009; Riedel et al., 2010; Krause et al., 2012; Zhang et al., 2013; Min et al., 2013; Ritter et al., 2013).", "startOffset": 0, "endOffset": 121}, {"referenceID": 10, "context": "(Mintz et al., 2009; Riedel et al., 2010; Krause et al., 2012; Zhang et al., 2013; Min et al., 2013; Ritter et al., 2013).", "startOffset": 0, "endOffset": 121}, {"referenceID": 24, "context": "(Mintz et al., 2009; Riedel et al., 2010; Krause et al., 2012; Zhang et al., 2013; Min et al., 2013; Ritter et al., 2013).", "startOffset": 0, "endOffset": 121}, {"referenceID": 14, "context": "(Mintz et al., 2009; Riedel et al., 2010; Krause et al., 2012; Zhang et al., 2013; Min et al., 2013; Ritter et al., 2013).", "startOffset": 0, "endOffset": 121}, {"referenceID": 19, "context": "(Mintz et al., 2009; Riedel et al., 2010; Krause et al., 2012; Zhang et al., 2013; Min et al., 2013; Ritter et al., 2013).", "startOffset": 0, "endOffset": 121}, {"referenceID": 18, "context": "this problem including multi-class SVM (Nguyen and Moschitti, 2011) and Multi-Instance learning methods (Riedel et al., 2010; Surdeanu et al., 2012).", "startOffset": 104, "endOffset": 148}, {"referenceID": 22, "context": "this problem including multi-class SVM (Nguyen and Moschitti, 2011) and Multi-Instance learning methods (Riedel et al., 2010; Surdeanu et al., 2012).", "startOffset": 104, "endOffset": 148}, {"referenceID": 16, "context": "this problem including multi-class SVM (Nguyen and Moschitti, 2011) and Multi-Instance learning methods (Riedel et al., 2010; Surdeanu et al., 2012). These approaches take into account the fact that entities might occur in different relations at the same time and may not necessarily express the target relation. Other approaches focus directly on the noise in the data. For instance Takamatsu et al. (2012) use a generative model to predict incorrect data while Intxaurrondo et al.", "startOffset": 105, "endOffset": 408}, {"referenceID": 7, "context": "(2012) use a generative model to predict incorrect data while Intxaurrondo et al. (2013) use a range of heuristics including PMI to remove noise.", "startOffset": 62, "endOffset": 89}, {"referenceID": 1, "context": "Augenstein et al. (2014) apply techniques to detect highly ambiguous entity pairs and discard them from their labelled training set.", "startOffset": 0, "endOffset": 25}, {"referenceID": 9, "context": "traction tasks from the biomedical domain since this has proved to be an important problem within these documents (Jensen et al., 2006; Hahn et al., 2012; Cohen and Hunter, 2013; Roller and Stevenson, 2014).", "startOffset": 114, "endOffset": 206}, {"referenceID": 6, "context": "traction tasks from the biomedical domain since this has proved to be an important problem within these documents (Jensen et al., 2006; Hahn et al., 2012; Cohen and Hunter, 2013; Roller and Stevenson, 2014).", "startOffset": 114, "endOffset": 206}, {"referenceID": 2, "context": "In addition, the most widely used knowledge source in this domain, the UMLS Metathesaurus (Bodenreider, 2004), is an ideal resource to apply inference learning given its rich structure.", "startOffset": 90, "endOffset": 109}, {"referenceID": 17, "context": "These candidate sentences are then stemmed (Porter, 1997) and PoS tagged (Charniak and Johnson, 2005).", "startOffset": 43, "endOffset": 57}, {"referenceID": 12, "context": "PRA (Lao and Cohen, 2010; Lao et al., 2011) is an algorithm that infers new relation instances from knowledge bases.", "startOffset": 4, "endOffset": 43}, {"referenceID": 7, "context": "Relation Extraction system: The MultiR system (Hoffmann et al., 2010) with features described by Surdeanu et al.", "startOffset": 46, "endOffset": 69}, {"referenceID": 7, "context": "Relation Extraction system: The MultiR system (Hoffmann et al., 2010) with features described by Surdeanu et al. (2011) was used for the experiments.", "startOffset": 47, "endOffset": 120}, {"referenceID": 13, "context": "Finally it would be interesting to compare our approach to other state of the art relation extraction systems for distant supervision or biased-SVM approaches such as Liu et al. (2003).", "startOffset": 167, "endOffset": 185}], "year": 2015, "abstractText": "Distant supervision is a widely applied approach to automatic training of relation extraction systems and has the advantage that it can generate large amounts of labelled data with minimal effort. However, this data may contain errors and consequently systems trained using distant supervision tend not to perform as well as those based on manually labelled data. This work proposes a novel method for detecting potential false negative training examples using a knowledge inference method. Results show that our approach improves the performance of relation extraction systems trained using distantly supervised data.", "creator": "LaTeX with hyperref package"}}}