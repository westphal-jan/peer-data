{"id": "1509.05181", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Sep-2015", "title": "Efficient Task Collaboration with Execution Uncertainty", "abstract": "We examine a general problem of task allocation involving multiple agents who perform tasks together and where the tasks assigned to them cannot be successfully accomplished (the so-called execution uncertainty), with the goal of choosing an assignment that maximizes social well-being while taking into account execution uncertainty. We show that this can be achieved through the post-execution review mechanism if and only if the agents \"evaluations meet a multilinearity condition. We then look at a more complex environment in which the execution uncertainty of an agent is not entirely predictable by the agent alone, but is aggregated from the private opinions of all agents (known as trusts). We show that a PEV-based mechanism with trust is still truthfully implementable when and only when the trust uncertainty is multilinear.", "histories": [["v1", "Thu, 17 Sep 2015 09:34:24 GMT  (36kb)", "http://arxiv.org/abs/1509.05181v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.GT", "authors": ["dengji zhao", "sarvapali d ramchurn", "nicholas r jennings"], "accepted": false, "id": "1509.05181"}, "pdf": {"name": "1509.05181.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Nicholas R. Jennings"], "emails": ["nrj}@ecs.soton.ac.uk"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 9.\n05 18\n1v 1\n[ cs\n.A I]\n1 7\nSe p\n20 15"}, {"heading": "Introduction", "text": "We study a general task allocation problem, where multiple agents collaboratively accomplish a set of tasks. However, agents may fail to successfully complete the task(s) allocated to them (known as execution uncertainty). Such task allocation problems arise in many real-world applications such as transportation networks (Sandholm 1993), data routing (Roughgarden 2007), cloud computing (Armbrust et al. 2010) and sharing economy (Belk 2014). Execution uncertainty is typically unavoidable in these applications due to unforeseen events and limited resources, especially sharing economy applications such as Uber and Freelancer, where services are mostly provided by individuals with no qualifications or certifications.\nIn addition to the execution uncertainty underlying the task allocation problem, the completion of a task may also depend on the completion of other tasks, e.g., in Uber a rider cannot ride without a driver offering the ride. The completion of the tasks of an allocation gives a (private) value to each agent, and our goal is to choose an allocation of tasks that maximises the total value of all agents, while taking their execution uncertainty into account.\nIt has been shown that traditional mechanism design (based on Groves mechanisms (Groves 1973)) is not applicable to settings that involve execution uncertainty (Porter et al. 2008; Conitzer and Vidali 2014). This is\nbecause execution uncertainty implies interdependencies between the agents\u2019 valuations (e.g., a rider\u2019s value for a ride will largely depend on whether the driver will successfully finish the drive). To combat the problem, Porter et al. (2008) have proposed a solution based on post-execution verification (PEV), which is broadly aligned with type verification (Nisan and Ronen 2001). The essential idea of the PEVbased mechanism is that agents are paid according to their task executions, rather than what they have reported.\nWhile Porter et al. (2008) considered a single task requester setting where one requester has multiple tasks that can be completed by multiple workers, Stein et al. (2011) and Conizter and Vidali (2014) studied similar settings but considering workers\u2019 uncertain task execution time. Moreover, Ramchurn et al. (2009) looked at a more complex setting where each agent is a task requester and is also capable to complete some tasks for the others. Except for different settings, all the solutions in these studies are PEVbased. However, these results may not applicable in other different problem settings where, for example, agents\u2019 valuations may have externalities, e.g., agent A prefers working with B to others (Jehiel, Moldovanu, and Stacchetti 1999), and an agent may even incur some costs without doing any task, e.g., a government is building a costly public good (Maniquet and Sprumont 2010).\nTherefore, in this paper, we study a more general task allocation setting where agents\u2019 valuations are not constrained. Under this general setting, we characterise the applicability of the PEV-based mechanism. We show that the PEV-based mechanism is applicable (truthfully implementable) if and only if agents are risk-neutral with respect to their execution uncertainty. Moreover, we consider a more complex setting where an agent\u2019s ability to successfully complete a task is judged by all agents\u2019 private opinion (known as trust) as proposed by (Ramchurn et al. 2009). Trust-based information exists in many real-world applications and plays an important role in decision making (Aberer and Despotovic 2001). We show that the PEVbased mechanism is still applicable with trust if and only if the trust aggregation is multilinear. This characterisation can help in designing efficient mechanisms for task allocation problems that have not been addressed yet."}, {"heading": "The Model", "text": "We study a task allocation problem where there are n agents denoted by N = {1, ..., n} and a finite set of task allocations T 1. Each allocation \u03c4 \u2208 T is defined by \u03c4 = (\u03c4i)i\u2208N , where \u03c4i is a set of tasks assigned to agent i. Let \u03c4i = \u2205 if there is no task assigned to i in \u03c4 . For each allocation \u03c4 , agent i may fail to successfully complete her tasks \u03c4i, which is modelled by p\u03c4i \u2208 [0, 1], the probability that i will successfully complete her tasks \u03c4i. Let pi = (p\u03c4i )\u03c4\u2208T be i\u2019s probability of success (PoS) profile for all allocations T , and p\u03c4 = (p\u03c4i )i\u2208N be the PoS profile of all agents for allocation \u03c4 .\nNote that the completion of one task in an allocation may depend on the completion of the other tasks. Take the delivery example in Figure 1 with two agents 1, 2 delivering one package from S to D. There are two possible task allocations to finish the delivery: \u03c4 is collaboratively executed by agents 1 and 2, while \u03c4 \u2032 is done by agent 2 alone. It is clear that task \u03c42 depends on \u03c41. However, p\u03c42 only indicates 2\u2019s PoS for \u03c42, assuming that 1 will successfully complete \u03c41. That is, p\u03c4i does not include task dependencies and it only specifies i\u2019s probability to successfully complete \u03c4i, if \u03c4i is ready for i to execute.\nFor each allocation \u03c4 \u2208 T , the completion of \u03c4 brings each agent i a value (either positive or negative), which combines costs and benefits. For example, building a train station near one\u2019s house may costs one\u2019s money as well as a peaceful living environment, but it may reduce the inconvenience of commuting. Considering the execution uncertainty, agent i\u2019s valuation is modelled by a function vi : T\u00d7[0, 1]N \u2192 R, which assigns a value for each allocation \u03c4 , for each PoS profile p\u03c4 = (p\u03c4i )i\u2208N .\nFor each agent i, we assume that vi and pi are privately observed by i, known as i\u2019s type and denoted by \u03b8i = (vi, pi). Let \u03b8 = (\u03b8i)i\u2208N be the type profile of all agents, \u03b8\u2212i be the type profile of all agents except i, and\n1 T is the task allocation outcome space, which may contain all feasible task allocations that agents can execute. The precise definition depends on the applications.\n\u03b8 = (\u03b8i, \u03b8\u2212i). Let \u0398i be i\u2019s type space, \u0398 = (\u0398i)i\u2208N and \u0398\u2212i = (\u0398j)j 6=i\u2208N .\nGiven the above setting, our goal is to choose one task allocation from T that maximises all agents\u2019 valuations, i.e., a socially optimal allocation. This can be achieved (according to the revelation principle (Myerson 2008)) by designing a mechanism that directly asks all agents to report their types and then chooses an allocation maximising their valuations. However, agents may not report their types truthfully. Therefore, we need to incentivize them to reveal their true types, which is normally achieved by choosing a specific allocation of tasks and an associated monetary transfer to each agent. The direct revelation allocation mechanism is defined by a task allocation choice function \u03c0 : \u0398 \u2192 T and a payment function x = (x1, ..., xn) where xi : \u0398 \u2192 R is the payment function for agent i."}, {"heading": "Solution Concepts", "text": "The goal of the allocation mechanism is to choose a task allocation that maximises the valuation of all agents, i.e., the social welfare. Since the agents\u2019 types are privately observed by the agents, the mechanism is only able to maximise social welfare if it can receive their true types. Therefore, the mechanism needs to incentivize all agents to report their types truthfully. Moreover, agents should not lose when they participate in the task allocation mechanism, i.e., they are not forced to join the allocation. In the following, we formally define these concepts.\nWe say an allocation choice \u03c0 is efficient if it always chooses an allocation that maximises the expected social welfare for all type report profiles.\nDefinition 1. Allocation choice \u03c0 is efficient if and only if for all \u03b8 \u2208 \u0398, for all \u03c4 \u2032 \u2208 T , let \u03c4 = \u03c0(\u03b8), we have:\n\u2211\ni\u2208N\nvi(\u03c4, p \u03c4 ) \u2265\n\u2211\ni\u2208N\nvi(\u03c4 \u2032, p\u03c4\n\u2032\n)\nwhere p\u03c4 = (p\u03c4i )i\u2208N , and p \u03c4 \u2032 = (p\u03c4 \u2032 i )i\u2208N .\nNote that the expected social welfare calculated by \u03c0 is based on the agents\u2019 reported types, which are not necessarily their true types. However, agents\u2019 actual/realized valuation for an allocation only depends on their true types.\nGiven the agents\u2019 true type profile \u03b8, their reported type profile \u03b8\u0302 and the allocation mechanism (\u03c0, x), agent i\u2019s expected utility is quasilinear and defined as:\nui(\u03b8i, \u03c0(\u03b8\u0302), xi(\u03b8\u0302), p \u03c0(\u03b8\u0302)) = vi(\u03c0(\u03b8\u0302), p \u03c0(\u03b8\u0302))\u2212 xi(\u03b8\u0302),\nwhere p\u03c0(\u03b8\u0302) = (p\u03c0(\u03b8\u0302)i )i\u2208N is agents\u2019 true PoS profile for task \u03c0(\u03b8\u0302) and p\u0302\u03c0(\u03b8\u0302) = (p\u0302\u03c0(\u03b8\u0302)i )i\u2208N is what they have reported.\nDefinition 2. Mechanism (\u03c0, x) is individually rational if for all i \u2208 N , for all \u03b8 \u2208 \u0398, for all \u03b8\u0302\u2212i \u2208 \u0398\u2212i, ui(\u03b8i, \u03c0(\u03b8i, \u03b8\u0302\u2212i), xi(\u03b8i, \u03b8\u0302\u2212i), p \u03c0(\u03b8i,\u03b8\u0302\u2212i)) \u2265 0.\nThat is, an agent never receives a negative expected utility in an individually rational mechanism if she reports truthfully, no matter what others report.\nFurthermore, we say the mechanism is truthful (aka dominant-strategy incentive-compatible) if it always maximises an agent\u2019s expected utility if she reports her type truthfully no matter what the others report, i.e., reporting type truthfully is a dominant strategy. It has been shown that truthful and efficient mechanism is impossible to achieve in a special settings of the model (Porter et al. 2008). Instead we focus on a weaker solution concept (but still very valid) called ex-post truthful, which requires that reporting truthfully maximises an agent\u2019s expected utility, if everyone else also reports truthfully (i.e., reporting truthfully is an ex-post equilibrium).\nDefinition 3. Mechanism (\u03c0, x) is ex-post truthful if and only if for all i \u2208 N , for all \u03b8 \u2208 \u0398, for all \u03b8\u0302i \u2208 \u0398i, we have ui(\u03b8i, \u03c0(\u03b8i, \u03b8\u2212i), xi(\u03b8i, \u03b8\u2212i), p\u03c0(\u03b8i,\u03b8\u2212i))) \u2265 ui(\u03b8i, \u03c0(\u03b8\u0302i, \u03b8\u2212i), xi(\u03b8\u0302i, \u03b8\u2212i), p \u03c0(\u03b8\u0302i,\u03b8\u2212i))."}, {"heading": "Failure of the Groves Mechanism", "text": "The Groves mechanism is a well-known class of mechanisms that are efficient and truthful in many domains (Groves 1973). However, they are not directly applicable in our domain due to the interdependent valuations created by the execution uncertainty. As we will see later, a simply variation of the Groves mechanism can solve the problem. In the following, we briefly introduce the Groves mechanism and show why it cannot be directly applied.\nGiven agents\u2019 type report profile \u03b8, Groves mechanisms compute an efficient allocation \u03c0\u2217(\u03b8) (\u03c0\u2217 denotes the efficient allocation choice function) and charge each agent i\nxGrovesi (\u03b8) = hi(\u03b8\u2212i)\u2212 V\u2212i(\u03b8, \u03c0 \u2217) (1)\nwhere\n\u2022 hi is a function that only depends on \u03b8\u2212i,\n\u2022 V\u2212i(\u03b8, \u03c0 \u2217) =\n\u2211\nj 6=i vj(\u03c0 \u2217(\u03b8), p\u03c0 \u2217(\u03b8)) is the social welfare for all agents, excluding i, under the efficient allocation \u03c0\u2217(\u03b8).\nSince hi is independent of i\u2019s report, we can set hi(\u03b8\u2212i) = 0, and then each agent\u2019s utility is vi(\u03c0\u2217(\u03b8)) + V\u2212i(\u03b8, \u03c0\u2217), which is the social welfare of the efficient allocation. The following example shows that the Groves mechanism is not directly applicable in our task allocation setting.\nTake the example from Figure 1 with the setting from Table 1. If both 1 and 2 report truthfully, the efficient allocation is \u03c4 \u2032 with social welfare 0.5 (which is also their utility if hi(\u03b8\u2212i) = 0). Now if 1 misreported p\u0302\u03c41 > 0.5, then the efficient allocation will be \u03c4 with social welfare p\u0302\u03c41 > 0.5, i.e., 1 can misreport to receive a higher utility."}, {"heading": "Applicability of PEV-Based Mechanisms", "text": "As shown in the last section, the Groves mechanisms are not directly applicable due to the interdependency of agents\u2019 valuations created by their probability of success (PoS). The other reason is that the Groves payment is calculated from agents\u2019 reported PoS rather than their realized/true PoS.\nThe fact is that we can partially verify their reported PoS by delaying their payments until they have executed their\ntasks (post-execution verification). To utilize this fact, Porter et al. (2008) have proposed a variation of the Groves mechanism which pays an agent according to their actual task completion, rather than what they have reported. More specifically, we define two payments for each agent: a reward for successful completion and a penalty for non-completion. Let us call this mechanism PEV-based mechanism.\nPorter et al. (2008) have considered a simple setting where there is one requester who has one or multiple tasks to be allocated to multiple workers each of whom have a fixed cost to attempt each task. Later, Ramchurn et al. (2009) extended Porter et al.\u2019s model to a multiple-requester setting (a combinatorial task exchange) and especially considered trust information which will be further studied later in this paper. Our setting generalises both models and allows any types of valuations and allocations. In the following, we formally define the PEV-based mechanism and analyse its applicability in our general domain.\nGiven the agents\u2019 true type profile \u03b8 and their reports \u03b8\u0302, let p\u03c4\u2212i be the true PoS profile of all agents except i for task \u03c4 , p\u03c4 = (p\u03c4i , p \u03c4 \u2212i), and p\u0302 \u03c4 \u2212i, p\u0302\n\u03c4 be the corresponding reported, PEV-based payment xPEV for each agent i is defined as:\nxPEVi (\u03b8\u0302) =\n{\nhi(\u03b8\u0302\u2212i)\u2212 V 1\u2212i(\u03b8\u0302, \u03c0 \u2217) if i succeeded, hi(\u03b8\u0302\u2212i)\u2212 V 0\u2212i(\u03b8\u0302, \u03c0 \u2217) if i failed. (2)\nwhere\n\u2022 hi(\u03b8\u0302\u2212i) = \u2211 j\u2208N\\{i} v\u0302j(\u03c0 \u2217(\u03b8\u0302\u2212i), (0, p\u0302 \u03c0\u2217(\u03b8\u0302\u2212i) \u2212i )) is the\nmaximum expected social welfare that the other agents can achieve without i\u2019s participation,\n\u2022 V 1\u2212i(\u03b8\u0302, \u03c0 \u2217) =\n\u2211\nj\u2208N\\{i} v\u0302j(\u03c0 \u2217(\u03b8\u0302), (1, p \u03c0\u2217(\u03b8\u0302) \u2212i )) is the re-\nalized expected social welfare of all agents except i under the efficient allocation \u03c0\u2217(\u03b8\u0302) when p\u03c0 \u2217(\u03b8\u0302)\ni = 1, i.e., i suc-\nceeded. V 0\u2212i(\u03b8\u0302, \u03c0 \u2217) =\n\u2211\nj\u2208N\\{i} v\u0302j(\u03c0 \u2217(\u03b8\u0302), (0, p \u03c0\u2217(\u03b8\u0302) \u2212i )) is\nthe corresponding social welfare when p\u03c0 \u2217(\u03b8\u0302)\ni = 0.\nNote that hi(\u03b8\u0302\u2212i) is calculated according to what agents have reported, while V 1\u2212i(\u03b8\u0302, \u03c0 \u2217), V 0\u2212i(\u03b8\u0302, \u03c0 \u2217) are based on the realization of their task completion, which is actually their true PoS as we used in the calculation. xPEVi pays/rewards agent i the social welfare increased by i if she completed her tasks, otherwise penalizes her the social welfare loss due to her failure.\nPorter et al. (2008) have shown that the mechanism (\u03c0\u2217, xPEV ) is ex-post truthful and individually rational if the dependencies between tasks are non-cyclical. In Theorem 1, we show that (\u03c0\u2217, xPEV ) is ex-post truthful in general if agents\u2019 valuations satisfy a multilinearity condition (Definition 4), which generalizes the non-cyclical task dependencies condition applied in (Porter et al. 2008).\nDefinition 4. Valuation vi of i is multilinear in PoS if for all type profiles \u03b8 \u2208 \u0398, for all allocations \u03c4 \u2208 T , for all j \u2208 N , vi(\u03c4, p \u03c4 ) = p\u03c4j \u00d7vi(\u03c4, (1, p \u03c4 \u2212j))+(1\u2212p \u03c4 j )\u00d7vi(\u03c4, (0, p \u03c4 \u2212j)).\nIntuitively, vi is multilinear in PoS if all its variables but p\u03c4j are held constant, vi is a linear function of p \u03c4 j , which\nalso means that agent i is risk-neutral (with respect to j\u2019s execution uncertainty). However, multilinearity in PoS does not indicate that vi has to be a linear form of vi(\u03c4, p\u03c4 ) = b+ a1p \u03c4 1 + ...+ anp \u03c4 n, where b, ai are constant (see Table 1 for example)."}, {"heading": "Multilinearity in PoS is Sufficient for Truthfulness", "text": "Theorem 1. Mechanism (\u03c0\u2217, xPEV ) is ex-post truthful if for all i \u2208 N , vi is multilinear in PoS.\nProof. According to the characterization of truthful mechanisms given by Proposition 9.27 from (Nisan et al. 2007), we need to prove that for all i \u2208 N , for all \u03b8 \u2208 \u0398:\n1. xPEVi (\u03b8) does not depend on i\u2019s report, but only on the task allocation alternatives;\n2. i\u2019s utility is maximized by reporting \u03b8i truthfully if the others report \u03b8\u2212i truthfully.\nFrom the definition of xPEVi in (2), we can see that given the allocation \u03c0\u2217(\u03b8), agent i cannot change V 1\u2212i(\u03b8, \u03c0\n\u2217) and V 0\u2212i(\u03b8, \u03c0\n\u2217) without changing the allocation \u03c0\u2217(\u03b8). Therefore, xPEVi does not depend on i\u2019s report, but only on the task allocation outcome \u03c0\u2217(\u03b8).\nIn what follows, we show that for each agent i, if the others report types truthfully, then i\u2019s utility is maximized by reporting her type truthfully.\nGiven an agent i\u2019 of type \u03b8i and the others\u2019 true type profile \u03b8\u2212i, assume that i reported \u03b8\u0302i 6= \u03b8i. For the allocation \u03c4 = \u03c0\u2217(\u03b8\u0302i, \u03b8\u2212i), according to xPEVi , when i finally completes her tasks, i\u2019s utility is u1i = vi(\u03c4, (1, p \u03c4 \u2212i)) \u2212 hi(\u03b8\u2212i) + V 1 \u2212i((\u03b8\u0302i, \u03b8\u2212i), \u03c0 \u2217) and her utility if she fails is u0i = vi(\u03c4, (0, p \u03c4 \u2212i)) \u2212 hi(\u03b8\u2212i) + V 0 \u2212i((\u03b8\u0302i, \u03b8\u2212i), \u03c0\n\u2217). Note that i\u2019s expected valuation depends on her true valuation vi and all agents\u2019 true PoS. Therefore, i\u2019s expected utility is:\np\u03c4i\u00d7u 1 i + (1\u2212 p \u03c4 i )\u00d7 u 0 i =\np\u03c4i \u00d7 vi(\u03c4, (1, p \u03c4 \u2212i)) (3)\n+ (1\u2212 p\u03c4i )\u00d7 vi(\u03c4, (0, p \u03c4 \u2212i)) (4) + p\u03c4i \u2211\nj\u2208N\\{i}\nvj(\u03c4, (1, p \u03c4 \u2212i)) (5)\n+ (1\u2212 p\u03c4i ) \u2211\nj\u2208N\\{i}\nvj(\u03c4, (0, p \u03c4 \u2212i)) (6)\n\u2212 hi(\u03b8\u2212i).\nSince all valuations are multilinear in PoS, the sum of (3) and (4) is equal to vi(\u03c4, p\u03c4 ), and the sum of (5) and (6) is \u2211\nj\u2208N\\{i} vj(\u03c4, p \u03c4 ). Thus, the sum of (3), (4), (5) and (6) is the social welfare under allocation \u03c0\u2217(\u03b8\u0302i, \u03b8\u2212i). The social welfare is maximized when i reports truthfully because \u03c0\u2217 maximizes social welfare (note that this is not the case when \u03b8\u2212i is not truthfully reported). Moreover, hi(\u03b8\u2212i) is independent of i\u2019s report and is the maximum social welfare that the others can achieve without i. Therefore, by reporting \u03b8i truthfully, i\u2019s utility is maximized.\nTheorem 1 shows that multilinearity in PoS is sufficient to truthfully implement (\u03c0\u2217, xPEV ) in an expost equilibrium (ex-post truthful), but not in a dominant strategy (truthful). It has been shown in similar settings that ex-post truthfulness is the best we can achieve here (Porter et al. 2008; Ramchurn et al. 2009; Stein et al. 2011; Conitzer and Vidali 2014)."}, {"heading": "Multilinearity in PoS is also Necessary", "text": "In the above we showed that multilinearity in PoS is sufficient for (\u03c0\u2217, xPEV ) to be ex-post truthful. Here we show that the multilinearity is also necessary.\nTheorem 2. If (\u03c0\u2217, xPEV ) is ex-post truthful for all type profiles \u03b8 \u2208 \u0398, then for all i \u2208 N , vi is multilinear in PoS.\nProof. By contradiction, assume that vi of agent of type \u03b8i is not multilinear in PoS, i.e., there exist a \u03b8\u2212i, an allocation \u03c4 \u2208 T , and a j \u2208 N (without loss of generality, assume that j 6= i) such that:\nvi(\u03c4, p \u03c4 ) 6= p\u03c4j \u00d7 vi(\u03c4, (1, p \u03c4 \u2212j)) + (1\u2212 p \u03c4 j )\u00d7 vi(\u03c4, (0, p \u03c4 \u2212j)) (7)\nUnder efficient allocation choice function \u03c0\u2217, it is not hard to find a type profile \u03b8\u0302\u2212i such that \u03c0\u2217(\u03b8i, \u03b8\u0302\u2212i) = \u03c4 and the PoS profile is the same between \u03b8\u2212i and \u03b8\u0302\u2212i. We can choose \u03b8\u0302\u2212i by setting v\u0302j(\u03c4, p\u03c4 ) to a sufficiently large value for each j 6= i.\nApplying (\u03c0\u2217, xPEV ) on profile (\u03b8i, \u03b8\u0302\u2212i), when j finally successfully completes her tasks \u03c4j , her utility is u1j = v\u0302j(\u03c4, (1, p \u03c4 \u2212j))\u2212hj((\u03b8i, \u03b8\u0302\u2212i)\u2212j)+V 1 \u2212j((\u03b8i, \u03b8\u0302\u2212i), \u03c0 \u2217) and her utility if she fails is u0j = v\u0302j(\u03c4, (0, p \u03c4 \u2212j)) \u2212 hj((\u03b8i, \u03b8\u0302\u2212i)\u2212j) + V 0 \u2212j((\u03b8i, \u03b8\u0302\u2212i), \u03c0\n\u2217). Thus, j\u2019s expected utility is (note that p\u0302\u03c4j = p \u03c4 j ):\np\u03c4j\u00d7u 1 j + (1\u2212 p \u03c4 j )\u00d7 u 0 j =\np\u03c4j \u00d7 vi(\u03c4, (1, p \u03c4 \u2212j)) (8)\n+ (1\u2212 p\u03c4j )\u00d7 vi(\u03c4, (0, p \u03c4 \u2212j)) (9)\n+ p\u03c4j \u2211\nk\u2208N\\{i}\nv\u0302k(\u03c4, (1, p \u03c4 \u2212j)) (10)\n+ (1\u2212 p\u03c4j ) \u2211\nk\u2208N\\{i}\nv\u0302k(\u03c4, (0, p \u03c4 \u2212j)) (11)\n\u2212 hj(\u03b8\u2212j).\nGiven the assumption (7), terms (8) and (9) together can be written as vi(\u03c4, p\u03c4 ) + \u03b4i where \u03b4i = (8) + (9) \u2212 vi(\u03c4, p\u03c4 ). Similar substitutions can be carried out for all other agents k \u2208 N \\ {i} in terms (10) and (11) regardless of whether vk is mutlilinear in PoS. After this substitution, j\u2019s utility can be written as:\npj\u00d7u 1 j + (1 \u2212 pj)\u00d7 u 0 j =\nvi(\u03c4, p \u03c4 ) +\n\u2211\nk\u2208N\\{i}\nv\u0302k(\u03c4, p \u03c4 ) (12)\n+ \u2211\nk\u2208N\n\u03b4k (13)\n\u2212 hj(\u03b8\u2212j).\nNow consider a suboptimal allocation \u03c4\u0302 6= \u03c4 , if \u03c4\u0302 is chosen by the mechanism, then j\u2019s utility can be written as:\nu\u0302j =\nvi(\u03c4\u0302 , p \u03c4\u0302 ) +\n\u2211\nk\u2208N\\{i}\nv\u0302k(\u03c4\u0302 , p \u03c4\u0302 ) (14)\n+ \u2211\nk\u2208N\n\u03b4\u0302k (15)\n\u2212 hj(\u03b8\u2212j).\nIn the above two utility representations, we know that terms (12) > (14) because \u03c0\u2217 is efficient, but terms (13) and (15) can be any real numbers.\nIn what follows, we tune the valuation of j such that the optimal allocation is either \u03c4 or \u03c4\u0302 , and in either case j is incentivized to misreport.\nIn the extreme case where all agents except i\u2019s valuations are multilinear in PoS, we have \u03b4k = 0, \u03b4\u0302k = 0 for all k 6= i in (13) and (15). Therefore, \u2211\nk\u2208N \u03b4k = \u03b4i 6= 0\nand \u2211\nk\u2208N \u03b4\u0302k = \u03b4\u0302i (possibly = 0). It might be the case that\n\u03b4i = \u03b4\u0302i, but there must exist a setting where \u03b4i 6= \u03b4\u0302i, otherwise vi is multilinear in PoS, because constant \u03b4i for any PoS does not violate the multilinearity definition.\n1. If \u03b4i > \u03b4\u0302i, we have (12) + \u03b4i > (14) + \u03b4\u0302i. In this case, we can increase v\u0302j(\u03c4\u0302 , p\u03c4\u0302 ) such that \u03c4\u0302 becomes optimal, i.e., (12) < (14), but (12) + \u03b4i > (14) + \u03b4\u0302i still holds. Therefore, if j\u2019s true valuation is the one that chooses \u03c4\u0302 as the optimal allocation, then j would misreport to get allocation \u03c4 which gives her a higher utility.\n2. If \u03b4i < \u03b4\u0302i, we can easily modify v\u0302j(\u03c4\u0302 , p\u03c4\u0302 ) such that (12)+ \u03b4i < (14) + \u03b4\u0302i but (12) > (14) still holds. In this case, if j\u2019s true valuation again is the one just modified, j would misreport to get allocation \u03c4\u0302 with a better utility.\nIn both of the above situations, agent j is incentivized to misreport, which contradicts that (\u03c0\u2217, xPEV ) is ex-post truthful. Thus, vi has to be multilinear in PoS.\nIt is worth mentioning that Theorem 2 does not say that given a specific type profile \u03b8, all vi have to be multilinear in PoS for (\u03c0\u2217, xPEV ) to be ex-post truthful. Take the delivery example from Table 1 and change agent 2\u2019s valuation for \u03c4 to be v2(\u03c4, p\u03c4 ) = (p\u03c41)\n2 \u00d7 p\u03c42 which is not multilinear in PoS. It is easy to check that under this change, no agent can gain anything by misreporting if the other agent reports truthfully. However, given each agent i of valuation vi, to truthfully implement (\u03c0\u2217, xPEV ) in an ex-post equilibrium for all possible type profiles of the others, Theorem 2 says that vi has to be multilinear in PoS, otherwise, there exist settings where some agent is incentivized to misreport."}, {"heading": "Conditions for Achieving Individual Rationality", "text": "PEV-based mechanism is individually rational in Porter et al. (2008)\u2019s specific setting. However, in the general model we consider here, it may not guarantee this property. For example, there is an allocation where an agent has no task to complete in an allocation, but has a negative valuation\nfor the completion of the tasks assigned to the others (i.e. she is penalised if the others complete their tasks). If that allocation is the optimal allocation and the allocation does not change with or without that agent, then she will get a zero payment therefore a negative utility.\nProposition 1 shows by restricting agents\u2019 valuations to some typical constraint, PEV-based mechanism can be made individually rational. The constraint says if an agent is not involved in a task allocation (i.e., when the tasks assigned to her is empty), she will not be penalised by the completion of the others\u2019 tasks.\nProposition 1. Mechanism (\u03c0\u2217, xPEV ) is individually rational if and only if for all i \u2208 N , for all \u03c4 \u2208 T , if \u03c4i = \u2205, then vi(\u03c4, p\u03c4 ) \u2265 0 for any p\u03c4 \u2208 [0, 1]N .\nProof. (If part) For all type profile \u03b8 \u2208 \u0398, for all i \u2208 N , let \u03c4 = \u03c0\u2217(\u03b8) and \u03c4\u0302 = \u03c0\u2217(\u03b8\u2212i), i\u2019s utility is given by \u2211\nk\u2208N vk(\u03c4, p \u03c4 ) \u2212\n\u2211\nk\u2208N\\{i} vk(\u03c4\u0302 , p \u03c4\u0302 \u2212i), where the first\nterm is the optimal social welfare with i\u2019s participation and the second term is the optimal social welfare without i\u2019s participation. It is clear that \u03c4\u0302i = \u2205 as \u03c4\u0302 is the optimal allocation without i\u2019s participation. \u2211\nk\u2208N\\{i} vk(\u03c4\u0302 , p \u03c4\u0302 \u2212i) + vi(\u03c4\u0302 , p \u03c4\u0302 )\nis the social welfare for allocation \u03c4\u0302 . Since \u03c4 is optimal, we get that \u2211\nk\u2208N vk(\u03c4, p \u03c4 ) \u2265\n\u2211\nk\u2208N\\{i} vk(\u03c4\u0302 , p \u03c4\u0302 \u2212i) +\nvi(\u03c4\u0302 , p \u03c4\u0302 ). Thus,\n\u2211\nk\u2208N vk(\u03c4, p \u03c4 )\u2212\n\u2211\nk\u2208N\\{i} vk(\u03c4\u0302 , p \u03c4\u0302 \u2212i) \u2265\nvi(\u03c4\u0302 , p \u03c4\u0302 ) \u2265 0, i.e. i\u2019s utility is non-negative.\n(Only if part) If there exist an i of type \u03b8i, a \u03c4 , a p\u03c4 \u2208 [0, 1]N such that \u03c4i = \u2205 and vi(\u03c4, p\u03c4 ) < 0. We can always find a profile \u03b8\u0302\u2212i s.t. p\u0302\u03c4 = p\u03c4 and \u03c0\u2217(\u03b8i, \u03b8\u0302\u2212i) = \u03c0\u2217(\u03b8\u0302\u2212i) = \u03c4 . It is clear that the payment for i is 0 and her utility is vi(\u03c4, p \u03c4 ) < 0 (violates individual rationality).\nExtension to Trust-Based Environments So far, we have assumed that each agent can correctly predict her probability of success (PoS) for each task, but in some environments, an agent\u2019s PoS is not perfectly perceived by the agent alone. Instead, multiple other agents may have had prior experiences with a given agent and their experiences can be aggregated to create a more informed measure of the PoS for the given agent. This measure is termed the trust in the agent (Ramchurn et al. 2009). Ramchurn et al. have extended Porter et al.\u2019s mechanism to consider agents\u2019 trust information and showed that the extension is still truthfully implementable in their settings.\nSimilarly, our general model can also be extended to handle the trust information by changing singleton p\u03c4i to be a vector p\u03c4i = (p \u03c4 i,1, ..., p \u03c4 i,j , ..., p \u03c4 i,n) where p \u03c4 i,j is the probability that i believes j will complete j\u2019s tasks in \u03c4 . Agent i\u2019s aggregated/true PoS for task \u03c4 is given by a function f \u03c4i : [0, 1] N \u2192 [0, 1] with input (p\u03c41,i, ..., p \u03c4 n,i). Given this extension, for any type profile \u03b8, let \u03c1\u03c4i = f \u03c4 i (p \u03c4 1,i, ..., p \u03c4 n,i), the social welfare of a task allocation \u03c4 is defined as: \u2211\ni\u2208N\nvi(\u03c4, \u03c1 \u03c4 ) (16)\nwhere \u03c1\u03c4 = (\u03c1\u03c41 , ..., \u03c1 \u03c4 n).\nAs shown in (Ramchurn et al. 2009), PEV-based mechanism can be extended to handle this trust information by simply updating the efficient allocation choice function \u03c0\u2217 with the social welfare calculation given by Equation (16). Let us call the extended mechanism Mtrust. Ramchurn et al. have demonstrated that Mtrust is ex-post truthful in their settings when the PoS aggregation function is the following linear form:\nf \u03c4i (p \u03c4 1,i, ..., p \u03c4 n,i) =\n\u2211\nj\u2208N\n\u03c9j \u00d7 p \u03c4 j,i (17)\nwhere constant \u03c9j \u2208 [0, 1] and \u2211\nj\u2208N \u03c9j = 1. Following the results in Theorems 1 and 2, we generalize Ramchurn et al.\u2019s results to characterize all aggregation forms under which Mtrust is ex-post truthful.\nDefinition 5. A PoS aggregation fi = (f \u03c4i )\u03c4\u2208T is multilinear if for all j \u2208 N , for all \u03c4 \u2208 T , for all \u03b8 \u2208 \u0398, f \u03c4i (p \u03c4 1,i, ..., p \u03c4 j,i, ..., p \u03c4 n,i) = p\u03c4j,i \u00d7 f \u03c4 i (p \u03c4 1,i, ..., p \u03c4 j\u22121,i, 1, p \u03c4 j+1,i, ..., p \u03c4 n,i) + (1 \u2212 p \u03c4 j,i) \u00d7 f \u03c4i (p \u03c4 1,i, ..., p \u03c4 j\u22121,i, 0, p \u03c4 j+1,i, ..., p \u03c4 n,i).\nDefinition 5 is similar to the multilinear in PoS definition given by Definition 4. Multilinear aggregations cover the linear form given by Equation (17), but also consist of many non-linear forms such as \u220f\nj\u2208N p \u03c4 j,i. The following corol-\nlary directly follows Theorems 1 and 2. We omit the proof here. The basic idea of the proof is that given a multilinear function, if we substitute another multilinear function (with no shared variables) for one variable of the function, then the new function must be multilinear.\nCorollary 1. Trust-based mechanism Mtrust is ex-post truthful if and only if for all i \u2208 N , vi is multilinear in PoS, and the PoS aggregation fi is multilinear.\nFor Mtrust to be individually rational, the constraint specified in Proposition 1 is still sufficient and necessary, if we change h\u2212i in the payment definition (Equation (2)) to be the optimal social welfare that the others can achieve without i, but assume that i offered the worst trust in the others (see (Ramchurn et al. 2009) for more details)."}, {"heading": "Discussions", "text": ""}, {"heading": "Link to General Interdependent Valuations", "text": "So far, we have characterised the applicability of PEV-based mechanism and its extension with trust in a general task allocation setting. We should also note that there exists a body of research for general interdependent valuations such as (Milgrom and Weber 1982; Jehiel and Moldovanu 2001). Hence, in what follows we draw the parallels between the two areas and compare and contrast their key results and assumptions.\nThe work of (Jehiel and Moldovanu 2001) is especially interesting to this study, because they have identified a necessary condition for implementing an efficient and Bayes-Nash truthful2 mechanism (see Theorem 4.3 in\n2Bayes-Nash truthful is weaker than ex-post truthful and it assumes that all agents know the correct probabilistic distribution of each agent\u2019s type.\n(Jehiel and Moldovanu 2001)). However, their setting and the necessary condition do not apply to our setting, because:\n1. The model in (Jehiel and Moldovanu 2001) can only model one special setting of our problem, namely the setting where the tasks between agents are independent. Also it is impossible to model trust at the same time.\n2. The mechanism considered in (Jehiel and Moldovanu 2001) has no ability to verify agents\u2019 reports.\nTherefore, we can see that our problem is a very special interdependent valuation setting, which allows the mechanism to partially verify agents\u2019 reports and to design mechanisms with better performance."}, {"heading": "When Agents are Not Risk-Neutral", "text": "We have shown that as soon as agents are risk-neutral with respect to their execution uncertainty, PEV-based mechanism is sufficient to provide incentives for agents to reveal their true types. However, in many real-world applications, participants are often not risk-neutral. For instance, when we reserve a ride from a taxi/carsharing company to catch a flight, we certainly do not want to take risk to get an unreliable booking. On the other hand, we often face challenging tasks that are very unlikely to be successfully completed (for example open research questions and financial investments), but we are very willing to take risks to try. Our results indicate that, to handle these non-risk-neutral settings, we need better solutions.\nFurthermore, when agents are not risk-neutral, individual rationality (Definition 2) needs to be redefined, as the current definition assumes that agents are risk-neutral with respect to their execution uncertainty."}, {"heading": "Challenge of the Efficient Allocation Design", "text": "In our model, we assumed that the set of possible task allocation outcomes are given and the efficient task allocation is chosen from that set. It is worth mentioning that given a specific task allocation setting, finding an efficient allocation may not come so easy, e.g., (Ramchurn et al. 2009; Stein et al. 2011; Feige and Tennenholtz 2011; Conitzer and Vidali 2014). If it is computationally hard to get an efficient outcome, there exist techniques to tackle it without violating the truthfulness properties, e.g., (Nisan and Ronen 2007).\nConclusions We studied a general task allocation problem where multiple agents collaboratively accomplish a set of tasks, but they may fail to successfully complete tasks assigned to them. To design an efficient task allocation mechanism for this problem, we showed that post-execution verification based mechanism is truthfully implementable, if and only if all agents are risk-neutral with respect to their execution uncertainty. We also showed that trust information between agents can be integrated into the mechanism without violating its properties, if and only if the trust information is aggregated by a multilinear function. This characterisation will help us\nfurther study specific task allocation settings. As mentioned in the above discussions, one very interesting future work is to design efficient mechanisms for task allocation settings with non-risk-neutral participants."}], "references": [{"title": "and Despotovic", "author": ["K. Aberer"], "venue": "Z.", "citeRegEx": "Aberer and Despotovic 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "A", "author": ["M. Armbrust", "A. Fox", "R. Griffith", "Joseph"], "venue": "D.; Katz, R.; Konwinski, A.; Lee, G.; Patterson, D.; Rabkin, A.; Stoica, I.; and Zaharia, M.", "citeRegEx": "Armbrust et al. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "R", "author": ["Belk"], "venue": "2014. You are what you can access: Sharing and collaborative consumption online. Journal of Business Research 67(8):1595 \u2013", "citeRegEx": "Belk 2014", "shortCiteRegEx": null, "year": 1600}, {"title": "and Vidali", "author": ["V. Conitzer"], "venue": "A.", "citeRegEx": "Conitzer and Vidali 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "and Tennenholtz", "author": ["U. Feige"], "venue": "M.", "citeRegEx": "Feige and Tennenholtz 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "and Moldovanu", "author": ["P. Jehiel"], "venue": "B.", "citeRegEx": "Jehiel and Moldovanu 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "Multidimensional Mechanism Design for Auctions with Externalities", "author": ["B. Moldovanu", "E. Stacchetti"], "venue": "Journal of Economic Theory 85(2):258\u2013293", "citeRegEx": "P. et al\\.,? \\Q1999\\E", "shortCiteRegEx": "P. et al\\.", "year": 1999}, {"title": "and Sprumont", "author": ["F. Maniquet"], "venue": "Y.", "citeRegEx": "Maniquet and Sprumont 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "R", "author": ["P.R. Milgrom", "Weber"], "venue": "J.", "citeRegEx": "Milgrom and Weber 1982", "shortCiteRegEx": null, "year": 1982}, {"title": "R", "author": ["Myerson"], "venue": "B.", "citeRegEx": "Myerson 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "and Ronen", "author": ["N. Nisan"], "venue": "A.", "citeRegEx": "Nisan and Ronen 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "and Ronen", "author": ["N. Nisan"], "venue": "A.", "citeRegEx": "Nisan and Ronen 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "V", "author": ["Nisan, N.", "Roughgarden, T.", "\u00c9va Tardos", "Vazirani"], "venue": "V.", "citeRegEx": "Nisan et al. 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "Fault tolerant mechanism design", "author": ["Porter"], "venue": null, "citeRegEx": "Porter,? \\Q2008\\E", "shortCiteRegEx": "Porter", "year": 2008}, {"title": "N", "author": ["S.D. Ramchurn", "C. Mezzetti", "A. Giovannucci", "J.A. Rodriguez-Aguilar", "R.K. Dash", "Jennings"], "venue": "R.", "citeRegEx": "Ramchurn et al. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Algorithms and mechanisms for procuring services with uncertain durations using redundancy", "author": ["Stein"], "venue": "Artificial Intelligence", "citeRegEx": "Stein,? \\Q2011\\E", "shortCiteRegEx": "Stein", "year": 2011}], "referenceMentions": [], "year": 2015, "abstractText": "We study a general task allocation problem, involving multiple agents that collaboratively accomplish tasks and where agents may fail to successfully complete the tasks assigned to them (known as execution uncertainty). The goal is to choose an allocation that maximises social welfare while taking their execution uncertainty into account. We show that this can be achieved by using the post-execution verification (PEV)-based mechanism if and only if agents\u2019 valuations satisfy a multilinearity condition. We then consider a more complex setting where an agent\u2019s execution uncertainty is not completely predictable by the agent alone but aggregated from all agents\u2019 private opinions (known as trust). We show that PEV-based mechanism with trust is still truthfully implementable if and only if the trust aggregation is multilinear.", "creator": "LaTeX with hyperref package"}}}