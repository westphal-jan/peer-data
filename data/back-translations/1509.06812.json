{"id": "1509.06812", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Sep-2015", "title": "Learning Wake-Sleep Recurrent Attention Models", "abstract": "Despite their success, Convolutionary Neural Networks are computationally expensive because they need to examine all image locations. Stochastic attention-based models have been shown to improve computational efficiency at test time, but they remain difficult to train due to insoluble posterior inference and high variance in stochastic gradient estimates. Drawing on literature on deep generative model training, we present the Wake-Sleep Recurrent Attention Model, a method for creating stochastic attention networks that improves posterior inferences and reduces stochastic gradient variability. We show that our method can significantly accelerate the training time of stochastic attention networks in image classification and signature generation.", "histories": [["v1", "Tue, 22 Sep 2015 23:52:30 GMT  (490kb,D)", "http://arxiv.org/abs/1509.06812v1", "To appear in NIPS 2015"]], "COMMENTS": "To appear in NIPS 2015", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jimmy ba", "ruslan salakhutdinov", "roger b grosse", "brendan j frey"], "accepted": true, "id": "1509.06812"}, "pdf": {"name": "1509.06812.pdf", "metadata": {"source": "CRF", "title": "Learning Wake-Sleep Recurrent Attention Models", "authors": ["Jimmy Ba", "Roger Grosse"], "emails": ["jimmy@psi.toronto.edu", "rgrosse@cs.toronto.edu", "rsalskhu@cs.toronto.edu", "frey@psi.toronto.edu"], "sections": [{"heading": "1 Introduction", "text": "Convolutional neural networks, trained end-to-end, have been shown to substantially outperform previous approaches to various supervised learning tasks in computer vision (e.g. [1])). Despite their wide success, convolutional nets are computationally expensive when processing high-resolution input images, because they must examine all image locations at a fine scale. This has motivated recent work on visual attention-based models [2, 3, 4], which reduce the number of parameters and computational operations by selecting informative regions of an image to focus on. In addition to computational speedups, attention-based models can also add a degree of interpretability, as one can understand what signals the algorithm is using by seeing where it is looking. One such approach was recently used by [5] to automatically generate image captions and highlight which image region was relevant to each word in the caption.\nThere are two general approaches to attention-based image understanding: hard and soft attention. Soft attention based models (e.g. [5]) obtain features from a weighted average of all image locations, where locations are weighted based on a model\u2019s saliency map. By contrast, a hard attention model (e.g. [2, 3]) chooses, typically stochastically, a series of discrete glimpse locations. Soft attention models are computationally expensive, as they have to examine every image location; we believe that the computational gains of attention require a hard attention model. Unfortunately, this comes at a cost: while soft attention models can be trained with standard backpropagation [6, 5], this does not work for hard attention models, whose glimpse selections are typically discrete.\nTraining stochastic hard attention models is difficult because the loss gradient involves intractable posterior expectations, and because the stochastic gradient estimates can have high variance. (The latter problem was also observed by [7] in the context of memory networks.) In this work, we propose the Wake-Sleep Recurrent Attention Model (WS-RAM), a method for training stochastic recurrent attention models which deals with the problems of intractable inference and high-variance gradients by taking advantage of several advances from the literature on training deep generative models:\nar X\niv :1\n50 9.\n06 81\n2v 1\n[ cs\n.L G\n] 2\n2 Se\ninference networks [8], the reweighted wake-sleep algorithm [9], and control variates [10, 11]. During training, the WS-RAM approximates posterior expectations using importance sampling, with a proposal distribution computed by an inference network. Unlike the prediction network, the inference network has access to the object category label, which helps it choose better glimpse locations. As the name suggests, we train both networks using the reweighted wake-sleep algorithm. In addition, we reduce the variance of the stochastic gradient estimates using carefully chosen control variates. In combination, these techniques constitute an improved training procedure for stochastic attention models.\nThe main contributions of our work are the following. First, we present a new learning algorithm for stochastic attention models and compare it with a training method based on variational inference [2]. Second, we develop a novel control variate technique for gradient estimation which further speeds up training. Finally, we demonstrate that our stochastic attention model can learn to (1) classify translated and scaled MNIST digits, and (2) generate image captions by attending to the relevant objects in images and their corresponding scale. Our model achieves similar performance to the variational method [2], but with much faster training times."}, {"heading": "2 Related work", "text": "In recent years, there has been a flurry of work on attention-based neural networks. Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15]. Attention has been shown both to improve computational efficiency [2] and to yield insight into the network\u2019s behavior [5].\nOur work is most closely related to stochastic hard attention models (e.g. [2]). A major difficulty of training such models is that computing the gradient requires taking expectations with respect to the posterior distribution over saccades, which is typically intractable. This difficulty is closely related to the problem of posterior inference in training deep generative models such as sigmoid belief networks [16]. Since our proposed method draws heavily from the literature on training deep generative models, we overview various approaches here.\nOne of the challenges of training a deep (or recurrent) generative model is that posterior inference is typically intractable due to the explaining away effect. One way to deal with intractable inference is to train a separate inference network whose job it is to predict the posterior distribution. A classic example was the Helmholtz machine [8], where the inference network predicts a mean field approximation to the posterior.1 The generative and inference networks are trained with the wake-sleep algorithm: in the wake phase, the generative model is updated to increase a variational lower bound on the data likelihood. In the sleep phase, data are generated from the model, and the inference network is trained to predict the latent variables used to generate the observations.\nThe wake-sleep approach was limited by the fact that the wake and sleep phases were minimizing two unrelated objective functions. More recently, various methods have been proposed which unify the training of the generative and inference networks into a single objective function. Neural variational inference and learning (NVIL) [11] trains both networks to maximize a variational lower bound on the log-likelihood. Since the stochastic gradient estimates in NVIL are very noisy, the method of control variates is used to reduce the variance. In particular, one uses an algortihm from reinforcement learning called REINFORCE [17], which attempts to infer a reward baseline for each instance. The choice of baseline is crucial to good performance; NVIL uses a separate neural network to compute the baseline, an approach also used by [3] in the context of attention networks. Control variates are discussed in more detail in Section 4.4.\nThe reweighted wake-sleep approach [9] is similar to traditional wake-sleep, but uses importance sampling in place of mean field inference to approximate the posterior. Reweighted wake-sleep is described more formally in Section 4.3. Another method based on inference networks is variational autoencoders [18, 19], which exploit a clever reparameterization of the probabilistic model in order to improve the signal in the stochastic gradients. NVIL, reweighted wake-sleep, and variational autoencoders have all been shown to achieve considerably higher test log-likelihoods compared to\n1In the literature, the inference network is often called a recognition network; we avoid this terminology to prevent confusion with the task of image classification.\ntraditional wake-sleep. The term \u201cHelmholtz machine\u201d is often used loosely to refer to the entire collection of techniques which simultaneously learn a generative network and an inference network."}, {"heading": "3 Wake-Sleep Recurrent Attention Model", "text": "We now describe our wake-sleep recurrent attention model (WS-RAM). Given an image I, the network first chooses a sequence of glimpses a = (a1, . . . , aN ), and after each glimpse, receives an observation xn computed by a mapping g(an, I). This mapping might, for instance, extract an image patch at a given scale. The first glimpse is based on a low-resolution version of the input, while subsequent glimpses are chosen based on information acquired from previous glimpses. The glimpses are chosen stochastically according to a distribution p(an | a1:n\u22121, I,\u03b8), where \u03b8 denotes the parameters of the network. This is in contrast with soft attention models, which deterministically allocate attention across all image locations. After the last glimpse, the network predicts a distribution p(y |a, I,\u03b8) over the target y (for instance, the caption or image category). As shown in Figure 1, the core of the attention network is a two-layer recurrent network, which we term the \u201cprediction network\u201d, where the output at each time step is an action (saccade) which is used to compute the input at the next time step. A low-resolution version of the input image is fed to the network at the first time step, and the network predicts the class label at the final time step. Importantly, the low-resolution input is fed to the second layer, while the class label prediction is made by the first layer, preventing information from propagating directly from the low-resolution image to the output. This prevents local optima where the network learns to predict y directly from the low-resolution input, disregarding attention completely.\nOn top of the prediction network is an inference network, which receives both the class label and the attention network\u2019s top layer representation as inputs. It tries to predict the posterior distribution q(an+1 | y, a1:n, I,\u03b7), parameterized by \u03b7, over the next saccade, conditioned on the image category being correctly predicted. Its job is to guide the posterior sampler during training time, thereby acting as a \u201cteacher\u201d for the attention network. The inference network is described further in Section 4.3.\nOne of the benefits of stochastic attention models is that the mapping g can be localized to a small image region or coarse granularity, which means it can potentially be made very efficient. Furthermore, g need not be differentiable, which allows for operations (such as choosing a scale) which would be difficult to implement in a soft attention network. The cost of this flexibility is that standard backpropagation cannot be applied, so instead we use novel algorithms described in the next section."}, {"heading": "4 Learning", "text": "In this work, we assume that we have a dataset with labels y for the supervised prediction task (e.g. object category). In contrast to the supervised saliency prediction task (e.g. [20, 21]), there are no labels for where to attend. Instead, we learn an attention policy based on the idea that the best locations to attend to are the ones which most robustly lead the model to predict the correct category. In particular, we aim to maximize the probability of the class label (or equivalently, minimize the cross-entropy) by marginalizing over the actions at each glimpse:\n` = log p(y | I,\u03b8) = log \u2211 a p(a | I,\u03b8)p(y |a, I,\u03b8). (1)\nWe train the attention model by maximizing a lower bound on `. In Section 4.1, we first describe a previous approach which minimized a variational lower bound. We then introduce our proposed method which directly estimates the gradients of `. As shown in Section 4.2, our method can be seen as maximizing a tighter lower bound on `."}, {"heading": "4.1 Variational lower bound", "text": "We first outline the approach of [2], who trained the model to maximize a variational lower bound on `. Let q(a | y, I) be an approximating distribution. The lower bound on ` is then given by:\n` = log \u2211 a p(a | I,\u03b8)p(y |a, I,\u03b8) \u2265 \u2211 a q(a | y, I) log p(y,a | I,\u03b8) +H[q] = F . (2)\nIn the case where q(a | y, I) = p(a | I,\u03b8) is the prior, as considered by [2], this reduces to\nF = \u2211 a p(a | I,\u03b8) log p(y |a, I,\u03b8). (3)\nThe learning rules can be derived by taking derivatives of Eqn. 3 with respect to the model parameters:\n\u2202F \u2202\u03b8 = \u2211 a p(a | I,\u03b8) [ \u2202 log p(y |a, I,\u03b8) \u2202\u03b8 + log p(y |a, I,\u03b8)\u2202 log p(a | I,\u03b8) \u2202\u03b8 ] . (4)\nThe summation can be approximated using M Monte Carlo samples a\u0303m from p(a | I,\u03b8):\n\u2202F \u2202\u03b8 \u2248 1 M M\u2211 m=1 [ \u2202 log p(y | a\u0303m, I,\u03b8) \u2202\u03b8 + log p(y | a\u0303m, I,\u03b8)\u2202 log p(a\u0303 m | I,\u03b8) \u2202\u03b8 ] . (5)\nThe partial derivative terms can each be computed using standard backpropagation. This suggests a simple gradient-based training algorithm: For each image, one first computes the samples a\u0303m from the prior p(a | I,\u03b8), and then updates the parameters according to Eqn. 5. As observed by [2], one must carefully use control variates in order to make this technique practical; we defer discussion of control variates to Section 4.4."}, {"heading": "4.2 An improved lower bound on the log-likelihood", "text": "The variational method described above has some counterintuitive properties early in training. First, because it averages the log-likelihood over actions, it greatly amplifies the differences in probabilities assigned to the true category by different bad glances. For instance, a glimpse sequence which leads to 0.01 probability assigned to the correct class is considered much worse than one which leads to 0.02 probability under the variational objective, even though in practice they may be equally bad since they have both missed the relevant information. A second odd behavior is that all glimpse sequences are weighted equally in the log-likelihood gradient. It would be better if the training procedure focused its effort on using those glances which contain the relevant information. Both of these effects contribute noise in the training procedure, especially in the early stages of training.\nInstead, we adopt an approach based on the wake-p step of reweighted wake-sleep [9], where we attempt to maximize the marginal log-probability ` directly. We differentiate the marginal loglikelihood objective in Eqn. 1 with respect to the model parameters:\n\u2202` \u2202\u03b8 =\n1 p(y | I,\u03b8) \u2211 a p(a | I,\u03b8)p(y |a, I,\u03b8) [ \u2202 log p(y |a, I,\u03b8) \u2202\u03b8 + \u2202 log p(a | I,\u03b8) \u2202\u03b8 ] . (6)\nThe summation and normalizing constant are both intractable to evaluate, so we estimate them using importance sampling. We must define a proposal distribution q(a | y, I), which ideally should be close to the posterior p(a | y, I,\u03b8). One reasonable choice is the prior p(a | I,\u03b8), but another choice is described in Section 4.3. Normalized importance sampling gives a biased but consistent estimator of the gradient of `. Given samples a\u03031, . . . , a\u0303M from q(a | y, I), the (unnormalized) importance weights are computed as:\nw\u0303m = p(a\u0303m | I,\u03b8)p(y | a\u0303m, I,\u03b8)\nq(a\u0303m | y, I) . (7)\nThe Monte Carlo estimate of the gradient is given by:\n\u2202` \u2202\u03b8 \u2248 M\u2211 m=1 wm [ \u2202 log p(y | a\u0303m, I,\u03b8) \u2202\u03b8 + \u2202 log p(a\u0303m | I,\u03b8) \u2202\u03b8 ] , (8)\nwhere wm = w\u0303m/ \u2211M\ni=1 w\u0303 i are the normalized importance weights. When q is chosen to be the\nprior, this approach is equivalent to the method of [22] for learning generative feed-forward networks.\nOur importance sampling based estimator can also be viewed as the gradient ascent update on the objective function E [ log 1M \u2211M m=1 w\u0303 m ] . Combining Jensen\u2019s inequality with the unbiasedness of the w\u0303m shows that this is a lower bound on the log-likelihood:\nE [ log 1\nM M\u2211 m=1 w\u0303m\n] \u2264 logE [ 1\nM M\u2211 m=1 w\u0303m\n] = logE [w\u0303m] = `. (9)\nWe relate this to the previous section by noting thatF = E[log w\u0303m]. Another application of Jensen\u2019s inequality shows that our proposed bound is at least as accurate as F :\nF = E [log w\u0303m] = E [ 1\nM M\u2211 m=1 log w\u0303m\n] \u2264 E [ log 1\nM M\u2211 m=1 w\u0303m\n] . (10)\nBurda et al. [23] further analyzed a closely related importance sampling based estimator in the context of generative models, bounding the mean absolute deviation and showing that the bias decreases monotonically with the number of samples."}, {"heading": "4.3 Training an inference network", "text": "Late in training, once the attention model has learned an effective policy, the prior distribution p(a | I,\u03b8) is a reasonable choice for the proposal distribution q(a | y, I), as it puts significant probability mass on good actions. But early in training, the model may have only a small probability of choosing a good set of glimpses, and the prior may have little overlap with the posterior. To deal with this, we train an inference network to predict, given the observations as well as the class label, where the network should look to correctly predict that class (see Figure 1). With this additional information, the inference network can act as a \u201cteacher\u201d for the attention policy.\nThe inference network predicts a sequence of glimpses stochastically:\nq(a | y, I,\u03b7) = N\u220f\nn=1\nq(an | y, I,\u03b7, a1:n\u22121). (11)\nThis distribution is analogous to the prior, except that each decision also takes into account the class label y. We denote the parameters for the inference network as \u03b7. During training, the prediction network is learnt by following the gradient of the estimator in Eqn. 8 with samples a\u0303m \u223c q(a | y, I,\u03b7) drawn from the inference network output.\nOur training procedure for the inference network parallels the wake-q step of reweighted wakesleep [9]. Intuitively, the inference network is most useful if it puts large probability density over locations in an image that are most informative for predicting class labels. We therefore train the inference weights \u03b7 to minimize the Kullback-Leibler divergence between the recognition model prediction q(a | y, I,\u03b7) and posterior distribution from the attention model p(a | y, I,\u03b8):\nmin \u03b7 DKL(p \u2016 q) = min \u03b7 \u2212 \u2211 a p(a | y, I,\u03b8) log q(a | y, I,\u03b7). (12)\nThe gradient update for the recognition weights can be obtained by taking the derivatives of Eq. (12) with respect to the recognition weights \u03b7:\n\u2202DKL(p \u2016 q) \u2202\u03b7\n= Ep(a | y,I,\u03b8) [ \u2202 log q(a | y, I,\u03b7)\n\u2202\u03b7\n] . (13)\nSince the posterior expectation is intractable, we estimate it with importance sampling. In fact, we reuse the importance weights computed for the prediction network update (see Eqn. 7) to obtain the following gradient estimate for the recognition network:\n\u2202DKL(p \u2016 q) \u2202\u03b7\n\u2248 M\u2211\nm=1\nwm \u2202 log q(a\u0303m | y, I,\u03b7)\n\u2202\u03b7 . (14)"}, {"heading": "4.4 Control variates", "text": "The speed of convergence of gradient ascent with the gradients defined in Eqns. 8 and 14 suffers from high variance of the stochastic gradient estimates. Past work using similar gradient updates has found significant benefit from the use of control variates, or reward baselines, to reduce the variance [17, 10, 3, 11, 2]. Choosing effective control variates for the stochastic gradient estimators amounts to finding a function that is highly correlated with the gradient vectors, and whose expectation is known or tractable to compute [10, 24]. Unfortunately, a good choice of control variate is highly model-dependent.\nWe first note that: Eq(a | y,I,\u03b7) [\np(a | I,\u03b8) q(a | y, I,\u03b7) \u2202 log p(a | I,\u03b8) \u2202\u03b8\n] = 0, Eq(a | y,I,\u03b7) [ \u2202 log q(a | y, I,\u03b7)\n\u2202\u03b7\n] = 0. (15)\nThe terms inside the expectation are very similar to the gradients in Eqns. 8 and 14, suggesting that stochastic estimates of these expectations would make good control variates. To increase the correlation between the gradients and the control variates, we reuse the same set of samples and importance weights for the gradients and control variates. Using these control variates results in the gradient estimates for the prediction and recognition networks, we obtain:\n\u2202 log p(a | I,\u03b8) \u2202\u03b8\n\u2248 M\u2211\nm=1 wm \u2212 p(a\u0303m | I,\u03b8)q(a\u0303m | y,I,\u03b7)\u2211M i=1 p(a\u0303i | I,\u03b8) q(a\u0303i | y,I,\u03b7)  \u2202 log p(a\u0303m | I,\u03b8) \u2202\u03b8 , (16)\n\u2202DKL(p \u2016 q) \u2202\u03b7\n\u2248 M\u2211\nm=1\n( wm \u2212 1\nM\n) \u2202 log q(a\u0303m | y, I,\u03b7)\n\u2202\u03b7 . (17)\nOur use of control variates does not bias the gradient estimates (beyond the bias which is present due to importance sampling). However, as we show in the experiments, the resulting estimates have much lower variance than those of Eqns. 8 and 14.\nFollowing the analogy with reinforcement learning highlighted by [11], these control variates can also be viewed as reward baselines:\nbp =\np(a | I,\u03b8) q(a | y,I,\u03b7)Eq(a | y,I,\u03b7) [p(y |a, I,\u03b8)] M \u00b7 Eq(a | y,I,\u03b7) [ p(a | I,\u03b8) q(a | y,I,\u03b7)Eq(a | y,I,\u03b8) [p(y |a, I,\u03b8)] ] \u2248 p(a\u0303m | I,\u03b8)q(a\u0303m | y,I,\u03b7)\u2211M i=1 p(a\u0303i | I,\u03b8) q(a\u0303i | y,I,\u03b7) , (18)\nbq = Ep(a | I,\u03b8) [p(y |a, I,\u03b8)]\nM \u00b7 Ep(a | I,\u03b8) [p(y |a, I,\u03b8)] =\n1\nM , (19)\nwhere M is the number of samples drawn for proposal q."}, {"heading": "4.5 Encouraging exploration", "text": "Similarly to other methods based on reinforcement learning, stochastic attention networks face the problem of encouraging the method to explore different actions. Since the gradient in Eqn. 8 only rewards or punishes glimpse sequences which are actually performed, any part of the space which is never visited will receive no reward signal. [2] introduced several heuristics to encourage exploration, including: (1) raising the temperature of the proposal distribution, (2) regularizing the attention policy to encourage viewing all image locations, and (3) adding a regularization term to encourage high entropy in the action distribution. We have implemented all three heuristics for the WS-RAM and for the baselines. While these heuristics are important for good performance of the baselines, we found that they made little difference to the WS-RAM because the basic method already explores adequately."}, {"heading": "5 Experimental results", "text": "To measure the effectiveness of the proposed WS-RAM method, we first investigated a toy classification task involving a variant of the MNIST handwritten digits dataset [25] where transformations were applied to the images. We then evaluated the proposed method on a substantially more difficult image caption generation task using the Flickr8k [26] dataset."}, {"heading": "5.1 Translated scaled MNIST", "text": "We generated a dataset of randomly translated and scaled handwritten digits from the MNIST dataset [25]. Each digit was placed in a 100x100 black background image at a random location and scale. The task was to identify the digit class. The attention models were allowed four glimpses before making a classification prediction. The goal of this experiment was to evaluate the effectiveness of our proposed WS-RAM model compared with the variational approach of [2].\nFor both the WS-RAM and the baseline, the architecture was a stochastic attention model which used ReLU units in all recurrent layers. The actions included both continuous and discrete latent variables, corresponding to glimpse scale and location, respectively. The distribution over actions was represented as a Gaussian random variable for the location and an independent multinomial random variable for the scale. All networks were trained using Adam [27], with the learning rate set to the highest value that allowed the model to successfully converge to a sensible attention policy.\nThe classification performance results are shown in Table 1. In Figure 2, the WS-RAM is compared with the variational baseline, each using the same number of samples (in order to make computation time roughly equivalent). We also show comparisons against ablated versions of the WS-RAM where the control variates and inference network were removed. When the inference network was removed, the prior p(a | I,\u03b8) was used for the proposal distribution. In addition to the classification results, we measured the effective sample size (ESS) of our method with and without control variates and the inference network. ESS is a standard metric for evaluating importance samplers, and is defined as 1/ \u2211 m(w\nm)2, where wm denotes the normalized importance weights. Results are shown in Figure 2. Using the inference network reduced the variances in\ngradient estimation, although this improvement did not reflect itself in the ESS. Control variates improved both metrics.\nIn Section 4.5, we described heuristics which encourage the models to explore the action space. Figure 3 compares the training with and without these heuristics. Without the heuristics, the variational method quickly fell into a local minimum where the model predicted only one glimpse scale over all images; the exploration heuristics fixed this problem. By contrast, the WS-RAM did not appear to have this problem, so the heuristics were not necessary."}, {"heading": "5.2 Generating captions using multi-scale attention", "text": "We also applied the WS-RAM method to learn a stochastic attention model similar to [5] for generating image captions. We report results on the widely-used Flickr8k dataset. The training/valid/test split followed the same protocol as used in previous work [28].\nThe goal of this experiment was to examine the improvement of the WS-RAM over the variational method for learning with realistic imgaes. Similarly to [5], we first ran a convolutional network, and the attention network then determined which part of the convolutional net representation to attend to. The attention network predicted both which layer to attend to and a location within the layer, in contrast with [5], where the scale was held fixed. Because a convolutional net shrinks the representation with max-pooling, choosing a layer is analogous to choosing a scale. At each glimpse, the inference network was given the immediate preceding word in the target sentences. We compare the BLEU scores of our WS-RAM and the variational method in in Table 2. Figure 4 shows training curves for both models. We observe that WS-RAM obtained similar performance to the variatinoal method, but trained more efficiently."}, {"heading": "6 Conclusions", "text": "In this paper, we introduced the Wake-Sleep Recurrent Attention Model (WS-RAM), an efficient method for training stochastic attention models. This method improves upon prior work by using the reweighted wake-sleep algorithm [9] to approximate expectations from the posterior over glimpses. We also introduced control variates to reduce the variability of the stochastic gradients. Our method reduces the variance in the gradient estimates and accelerates training of attention networks for both invariant handwritten digit recognition and image caption generation."}, {"heading": "Acknowledgments", "text": "This work was supported by the Fields Institute, Samsung, ONR Grant N00014-14-1-0232 and the hardware donation of NVIDIA Corporation."}], "references": [{"title": "ImageNet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Multiple object recognition with visual attention", "author": ["J. Ba", "V. Mnih", "K. Kavukcuoglu"], "venue": "International Conference on Learning Representations,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Recurrent models of visual attention", "author": ["V. Mnih", "N. Heess", "A. Graves", "K. Kavukcuoglu"], "venue": "Neural Information Processing Systems,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning generative models with visual attention", "author": ["Y. Tang", "N. Srivastava", "R. Salakhutdinov"], "venue": "Neural Information Processing Systems,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Show, attend, and tell: neural image caption generation with visual attention", "author": ["K. Xu", "J. Ba", "R. Kiros", "K. Cho", "A. Courville", "R. Salakhutdinov", "R.S. Zemel", "Y. Bengio"], "venue": "International Conference on Machine Learning,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "International Conference on Learning Representations,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Reinforcement learning neural Turing machines", "author": ["W. Zaremba", "I. Sutskever"], "venue": "arXiv:1505.00521,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "The Helmholtz machine", "author": ["P. Dayan", "G.E. Hinton", "R.M. Neal", "R.S. Zemel"], "venue": "Neural Computation, 7:889\u2013904,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1995}, {"title": "Reweighted wake-sleep", "author": ["J. Bornschein", "Y. Bengio"], "venue": "arXiv:1406.2751,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Variational Bayesian inference with stochastic search", "author": ["J. Paisley", "D.M. Blei", "M.I. Jordan"], "venue": "International Conference on Machine Learning,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Neural variational inference and learning in belief networks", "author": ["A. Mnih", "K. Gregor"], "venue": "International Conference on Machine Learning,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning to combine foveal glimpses with a third-order Boltzmann machine", "author": ["H. Larochelle", "G.E. Hinton"], "venue": "Neural Information Processing Systems,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning where to attend with deep architectures for image tracking", "author": ["M. Denil", "L. Bazzani", "H. Larochelle", "N. de Freitas"], "venue": "Neural Computation,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Generating sequences with recurrent neural networks", "author": ["A. Graves"], "venue": "arXiv:1308.0850,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "DRAW: a recurrent neural network for image generation", "author": ["K. Gregor", "I. Danihelka", "A. Graves", "D. Wierstra"], "venue": "arXiv:1502.04623,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Connectionist learning of belief networks", "author": ["Radford M. Neal"], "venue": "Artificial Intelligence,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1992}, {"title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "author": ["R.J. Williams"], "venue": "Machine Learning, 8:229\u2013256,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1992}, {"title": "Auto-encoding variational Bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "International Conference on Learning Representations,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["D.J. Rezende", "S. Mohamed", "D. Wierstra"], "venue": "International Conference on Machine Learning,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "A model of saliency-based visual attention for rapid scene analysis", "author": ["L. Itti", "C. Koch", "E. Niebur"], "venue": "IEEE Transactions of Pattern Analysis and Machine Intelligence, 20(11):1254\u201359, November", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1998}, {"title": "Learning to predict where humans look", "author": ["T. Judd", "K. Ehinger", "F. Durand", "A. Torralba"], "venue": "International Conference on Computer Vision,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning stochastic feedforward neural networks", "author": ["Y. Tang", "R. Salakhutdinov"], "venue": "Neural Information Processing Systems,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Importance weighted autoencoders", "author": ["Y. Burda", "R. Grosse", "R. Salakhutdinov"], "venue": "arXiv:1509.00519,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "The optimal reward baseline for gradient-based reinforcement learning", "author": ["Lex Weaver", "Nigel Tao"], "venue": "In Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2001}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, 86(11):2278\u20132324,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1998}, {"title": "Framing image description as a ranking task: Data, models and evaluation metrics", "author": ["Micah Hodosh", "Peter Young", "Julia Hockenmaier"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Adam: a method for stochastic optimization", "author": ["D. Kingma", "J.L. Ba"], "venue": "arXiv:1412.6980,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["Andrej Karpathy", "Li Fei-Fei"], "venue": "arXiv preprint arXiv:1412.2306,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "[1])).", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "This has motivated recent work on visual attention-based models [2, 3, 4], which reduce the number of parameters and computational operations by selecting informative regions of an image to focus on.", "startOffset": 64, "endOffset": 73}, {"referenceID": 2, "context": "This has motivated recent work on visual attention-based models [2, 3, 4], which reduce the number of parameters and computational operations by selecting informative regions of an image to focus on.", "startOffset": 64, "endOffset": 73}, {"referenceID": 3, "context": "This has motivated recent work on visual attention-based models [2, 3, 4], which reduce the number of parameters and computational operations by selecting informative regions of an image to focus on.", "startOffset": 64, "endOffset": 73}, {"referenceID": 4, "context": "One such approach was recently used by [5] to automatically generate image captions and highlight which image region was relevant to each word in the caption.", "startOffset": 39, "endOffset": 42}, {"referenceID": 4, "context": "[5]) obtain features from a weighted average of all image locations, where locations are weighted based on a model\u2019s saliency map.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2, 3]) chooses, typically stochastically, a series of discrete glimpse locations.", "startOffset": 0, "endOffset": 6}, {"referenceID": 2, "context": "[2, 3]) chooses, typically stochastically, a series of discrete glimpse locations.", "startOffset": 0, "endOffset": 6}, {"referenceID": 5, "context": "Unfortunately, this comes at a cost: while soft attention models can be trained with standard backpropagation [6, 5], this does not work for hard attention models, whose glimpse selections are typically discrete.", "startOffset": 110, "endOffset": 116}, {"referenceID": 4, "context": "Unfortunately, this comes at a cost: while soft attention models can be trained with standard backpropagation [6, 5], this does not work for hard attention models, whose glimpse selections are typically discrete.", "startOffset": 110, "endOffset": 116}, {"referenceID": 6, "context": "(The latter problem was also observed by [7] in the context of memory networks.", "startOffset": 41, "endOffset": 44}, {"referenceID": 7, "context": "inference networks [8], the reweighted wake-sleep algorithm [9], and control variates [10, 11].", "startOffset": 19, "endOffset": 22}, {"referenceID": 8, "context": "inference networks [8], the reweighted wake-sleep algorithm [9], and control variates [10, 11].", "startOffset": 60, "endOffset": 63}, {"referenceID": 9, "context": "inference networks [8], the reweighted wake-sleep algorithm [9], and control variates [10, 11].", "startOffset": 86, "endOffset": 94}, {"referenceID": 10, "context": "inference networks [8], the reweighted wake-sleep algorithm [9], and control variates [10, 11].", "startOffset": 86, "endOffset": 94}, {"referenceID": 1, "context": "First, we present a new learning algorithm for stochastic attention models and compare it with a training method based on variational inference [2].", "startOffset": 144, "endOffset": 147}, {"referenceID": 1, "context": "Our model achieves similar performance to the variational method [2], but with much faster training times.", "startOffset": 65, "endOffset": 68}, {"referenceID": 11, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 67, "endOffset": 80}, {"referenceID": 3, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 67, "endOffset": 80}, {"referenceID": 2, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 67, "endOffset": 80}, {"referenceID": 1, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 67, "endOffset": 80}, {"referenceID": 12, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 98, "endOffset": 105}, {"referenceID": 2, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 98, "endOffset": 105}, {"referenceID": 5, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 127, "endOffset": 130}, {"referenceID": 4, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 151, "endOffset": 154}, {"referenceID": 13, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 177, "endOffset": 185}, {"referenceID": 14, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 177, "endOffset": 185}, {"referenceID": 1, "context": "Attention has been shown both to improve computational efficiency [2] and to yield insight into the network\u2019s behavior [5].", "startOffset": 66, "endOffset": 69}, {"referenceID": 4, "context": "Attention has been shown both to improve computational efficiency [2] and to yield insight into the network\u2019s behavior [5].", "startOffset": 119, "endOffset": 122}, {"referenceID": 1, "context": "[2]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "This difficulty is closely related to the problem of posterior inference in training deep generative models such as sigmoid belief networks [16].", "startOffset": 140, "endOffset": 144}, {"referenceID": 7, "context": "A classic example was the Helmholtz machine [8], where the inference network predicts a mean field approximation to the posterior.", "startOffset": 44, "endOffset": 47}, {"referenceID": 10, "context": "Neural variational inference and learning (NVIL) [11] trains both networks to maximize a variational lower bound on the log-likelihood.", "startOffset": 49, "endOffset": 53}, {"referenceID": 16, "context": "In particular, one uses an algortihm from reinforcement learning called REINFORCE [17], which attempts to infer a reward baseline for each instance.", "startOffset": 82, "endOffset": 86}, {"referenceID": 2, "context": "The choice of baseline is crucial to good performance; NVIL uses a separate neural network to compute the baseline, an approach also used by [3] in the context of attention networks.", "startOffset": 141, "endOffset": 144}, {"referenceID": 8, "context": "The reweighted wake-sleep approach [9] is similar to traditional wake-sleep, but uses importance sampling in place of mean field inference to approximate the posterior.", "startOffset": 35, "endOffset": 38}, {"referenceID": 17, "context": "Another method based on inference networks is variational autoencoders [18, 19], which exploit a clever reparameterization of the probabilistic model in order to improve the signal in the stochastic gradients.", "startOffset": 71, "endOffset": 79}, {"referenceID": 18, "context": "Another method based on inference networks is variational autoencoders [18, 19], which exploit a clever reparameterization of the probabilistic model in order to improve the signal in the stochastic gradients.", "startOffset": 71, "endOffset": 79}, {"referenceID": 19, "context": "[20, 21]), there are no labels for where to attend.", "startOffset": 0, "endOffset": 8}, {"referenceID": 20, "context": "[20, 21]), there are no labels for where to attend.", "startOffset": 0, "endOffset": 8}, {"referenceID": 1, "context": "We first outline the approach of [2], who trained the model to maximize a variational lower bound on `.", "startOffset": 33, "endOffset": 36}, {"referenceID": 1, "context": "In the case where q(a | y, I) = p(a | I,\u03b8) is the prior, as considered by [2], this reduces to F = \u2211", "startOffset": 74, "endOffset": 77}, {"referenceID": 1, "context": "As observed by [2], one must carefully use control variates in order to make this technique practical; we defer discussion of control variates to Section 4.", "startOffset": 15, "endOffset": 18}, {"referenceID": 8, "context": "Instead, we adopt an approach based on the wake-p step of reweighted wake-sleep [9], where we attempt to maximize the marginal log-probability ` directly.", "startOffset": 80, "endOffset": 83}, {"referenceID": 21, "context": "When q is chosen to be the prior, this approach is equivalent to the method of [22] for learning generative feed-forward networks.", "startOffset": 79, "endOffset": 83}, {"referenceID": 22, "context": "[23] further analyzed a closely related importance sampling based estimator in the context of generative models, bounding the mean absolute deviation and showing that the bias decreases monotonically with the number of samples.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "Our training procedure for the inference network parallels the wake-q step of reweighted wakesleep [9].", "startOffset": 99, "endOffset": 102}, {"referenceID": 16, "context": "Past work using similar gradient updates has found significant benefit from the use of control variates, or reward baselines, to reduce the variance [17, 10, 3, 11, 2].", "startOffset": 149, "endOffset": 167}, {"referenceID": 9, "context": "Past work using similar gradient updates has found significant benefit from the use of control variates, or reward baselines, to reduce the variance [17, 10, 3, 11, 2].", "startOffset": 149, "endOffset": 167}, {"referenceID": 2, "context": "Past work using similar gradient updates has found significant benefit from the use of control variates, or reward baselines, to reduce the variance [17, 10, 3, 11, 2].", "startOffset": 149, "endOffset": 167}, {"referenceID": 10, "context": "Past work using similar gradient updates has found significant benefit from the use of control variates, or reward baselines, to reduce the variance [17, 10, 3, 11, 2].", "startOffset": 149, "endOffset": 167}, {"referenceID": 1, "context": "Past work using similar gradient updates has found significant benefit from the use of control variates, or reward baselines, to reduce the variance [17, 10, 3, 11, 2].", "startOffset": 149, "endOffset": 167}, {"referenceID": 9, "context": "Choosing effective control variates for the stochastic gradient estimators amounts to finding a function that is highly correlated with the gradient vectors, and whose expectation is known or tractable to compute [10, 24].", "startOffset": 213, "endOffset": 221}, {"referenceID": 23, "context": "Choosing effective control variates for the stochastic gradient estimators amounts to finding a function that is highly correlated with the gradient vectors, and whose expectation is known or tractable to compute [10, 24].", "startOffset": 213, "endOffset": 221}, {"referenceID": 10, "context": "Following the analogy with reinforcement learning highlighted by [11], these control variates can also be viewed as reward baselines:", "startOffset": 65, "endOffset": 69}, {"referenceID": 1, "context": "[2] introduced several heuristics to encourage exploration, including: (1) raising the temperature of the proposal distribution, (2) regularizing the attention policy to encourage viewing all image locations, and (3) adding a regularization term to encourage high entropy in the action distribution.", "startOffset": 0, "endOffset": 3}, {"referenceID": 24, "context": "To measure the effectiveness of the proposed WS-RAM method, we first investigated a toy classification task involving a variant of the MNIST handwritten digits dataset [25] where transformations were applied to the images.", "startOffset": 168, "endOffset": 172}, {"referenceID": 25, "context": "We then evaluated the proposed method on a substantially more difficult image caption generation task using the Flickr8k [26] dataset.", "startOffset": 121, "endOffset": 125}, {"referenceID": 24, "context": "We generated a dataset of randomly translated and scaled handwritten digits from the MNIST dataset [25].", "startOffset": 99, "endOffset": 103}, {"referenceID": 1, "context": "The goal of this experiment was to evaluate the effectiveness of our proposed WS-RAM model compared with the variational approach of [2].", "startOffset": 133, "endOffset": 136}, {"referenceID": 26, "context": "All networks were trained using Adam [27], with the learning rate set to the highest value that allowed the model to successfully converge to a sensible attention policy.", "startOffset": 37, "endOffset": 41}, {"referenceID": 4, "context": "We also applied the WS-RAM method to learn a stochastic attention model similar to [5] for generating image captions.", "startOffset": 83, "endOffset": 86}, {"referenceID": 27, "context": "The training/valid/test split followed the same protocol as used in previous work [28].", "startOffset": 82, "endOffset": 86}, {"referenceID": 4, "context": "Similarly to [5], we first ran a convolutional network, and the attention network then determined which part of the convolutional net representation to attend to.", "startOffset": 13, "endOffset": 16}, {"referenceID": 4, "context": "The attention network predicted both which layer to attend to and a location within the layer, in contrast with [5], where the scale was held fixed.", "startOffset": 112, "endOffset": 115}, {"referenceID": 8, "context": "This method improves upon prior work by using the reweighted wake-sleep algorithm [9] to approximate expectations from the posterior over glimpses.", "startOffset": 82, "endOffset": 85}], "year": 2015, "abstractText": "Despite their success, convolutional neural networks are computationally expensive because they must examine all image locations. Stochastic attention-based models have been shown to improve computational efficiency at test time, but they remain difficult to train because of intractable posterior inference and high variance in the stochastic gradient estimates. Borrowing techniques from the literature on training deep generative models, we present the Wake-Sleep Recurrent Attention Model, a method for training stochastic attention networks which improves posterior inference and which reduces the variability in the stochastic gradients. We show that our method can greatly speed up the training time for stochastic attention networks in the domains of image classification and caption generation.", "creator": "LaTeX with hyperref package"}}}