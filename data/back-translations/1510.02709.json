{"id": "1510.02709", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Oct-2015", "title": "Large-scale Artificial Neural Network: MapReduce-based Deep Learning", "abstract": "In the face of ever-increasing amounts of data, the original neural network-based machine learning algorithm of back propagation presents two non-trivial challenges: enormous amounts of data make it difficult to maintain both efficiency and accuracy; redundant data exacerbates the system's workload. This project focuses mainly on solving the above problems, combining a deep learning algorithm with a cloud computing platform for dealing with large-scale data. In this project, a MapReduce-based character recognition mechanism will be developed to test the efficiency improvement that this mechanism will achieve on the training and in practice on a large scale. Careful discussions and experiments will be developed to demonstrate how a deep learning algorithm works to train handwritten digit data, such as MapReduce will be implemented in the deep learning neural network, and why this combination will accelerate calculation. In addition to performance, this report also mentions robustness and robustness.", "histories": [["v1", "Fri, 9 Oct 2015 15:45:44 GMT  (893kb,D)", "http://arxiv.org/abs/1510.02709v1", null]], "reviews": [], "SUBJECTS": "cs.DC cs.LG cs.NE", "authors": ["kairan sun", "xu wei", "gengtao jia", "risheng wang", "ruizhi li"], "accepted": false, "id": "1510.02709"}, "pdf": {"name": "1510.02709.pdf", "metadata": {"source": "CRF", "title": "Large-scale Artificial Neural Network: MapReduce-based Deep Learning", "authors": ["Kairan Sun", "Xu Wei", "Gengtao Jia", "Risheng Wang", "Ruizhi Li"], "emails": ["ksun@ufl.edu)."], "sections": [{"heading": null, "text": "Index Terms\u2014Neural Network, MapReduce, Machine Learning, Deep learning.\nI. INTRODUCTION\nClassification of data patterns generated by handwriting characters, photograph pixels, audio signals has long been a popular topic in machine learning field. We used to take advantages of the non-volatile feature of computer memory so as to create huge database to afford data searching and pattern matching mechanism. However, we are expecting machines behave more closely to human beings and instead of merely remembering, they could be capable of observing, learning, analysing and recognizing just as human beings\u2019 behavior when they come with an unfamiliar object.\nInspired by animal central nervous system, artificial neural network (ANN) comes into the domain of machine learning and pattern recognition [1]. An artificial neural network is made of artificial nodes called \u201cneurons\u201d, connected together, in order to mimic a biological neural network. One could compare it with human being\u2019s brain or neural system. The difference is that each neural node in an artificial neural network not only plays a role of signal carrier, but also contributes to the process of pattern recognition. In other\n1K. Sun, X. Wei, G. Jia, R. Wang, and R. Li are with the team of NerveCloud in the course of EEL-6935: Cloud Computing and Storage, Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, 32611 USA (e-mail: ksun@ufl.edu).\nwords, the artificial neural network as a whole acts as a human brain.\nInside an artificial neural network, complex global behavior is exhibited by connection between simple processing elements. Neural statistical models consist of sets of weighting factors, which make up two types of connections, a positive weighting factor that has the tendency to increase the activation level of neuron, and a negative one that tends to reduce the output signal of neuron.\nFigure 1 shows the basic structure of artificial neural network model. Neurons are located in separated layers, which may contain different numbers of processing elements. Input signals first come to first layer, as known as the input layer, and directly transfer to the middle/hidden layer through weighted connections. The incoming signals are operated by each specific neuron in the hidden layers; in such way output values transfer to each neuron in the output layer through a second layer of weights. At last, via the calculation and operation of the output layer, the output signal is produced. Apparently, the hidden layer may include several layers.\nThe learning procedures aim at adjusting the weights in the artificial neural network model, so that the performance of models is advanced over time. The learning procedures can roughly be categorized to two types, namely the unsupervised learning and the supervise learning. For unsupervised learning, an input vector from the set of possible network inputs is presented to the network model, then the latter adjusts the weights in order to group the input samples into classes based on their statistical properties. For supervised learning, a set of training samples is presented to the network in sequence. According to the inputs, the network calculates outputs. Via compare between the resulting outputs with an expected output for the particular input sample, some error, which can be used to modify weights, will be found. So the distinguish between unsupervised and supervise learning is that there is no error or feedback to evaluate a potential solution, because the learner is provided with unlabeled samples.\nHowever, the process described above cannot be implemented on any individual computation node because with tremendously increasing number of data on Internet, the incredible complexity of computation would lead to unbounded execution time, thus in turn making the whole mechanism infeasible. Despite the performance, few disks can afford that enormous amount of data, which is usually hundreds of\nar X\niv :1\n51 0.\n02 70\n9v 1\n[ cs\n.D C\n] 9\nO ct\n2 01\n5\ngigabytes or even terabytes. On the other hand, conventional data mining algorithms for classification are not suitable for cloud computing platform either since the weight processing of each layer in back-propagation neural network are dependent on other layers, and in this way, MapReduce is helpless when dividing the entire back-propagation algorithm into mappers and reducers. This problem is carefully reviewed in [2]. Even though supplied with cluster computing resources, the iteration cycle keeps the same and it can hardly improve the performance of ANN.\nIn our project, we implement the latest achievement of neural network algorithm, deep learning [4], to accelerate the performance of back-propagation neural network. Inspiration comes from the progress we learn to recognize objects. Before studying an unfamiliar object, we are already informed its shape: whether it is a line, a circle, a triangle, or a rectangle and so on. Instead of learning a totally strange object, we learn the representation of the combination of several recognized objects. The fundamental concept of deep learning is that an observation can be represented in multiple ways, but certain representations make it easier to learn tasks of interest from examples. A many-layered neural network could be effectively pre-trained one layer at a time, treating each layer in turn as un unsupervised Restricted Boltzmann Machine, then followed by supervised back-propagation fine-tuning.\nIntegrating back-propagation in non-linear deep learning network, our cluster-computing framework is built on top of Amazon Web Service. The aim is quite simple: distribute the complex, large-scale computation to clusters of computers, enforcing parallelized cluster computing."}, {"heading": "II. RELATED WORK", "text": "Of course, we are not the first ones who tried to combine parallel methods of neural network with the cluster computing. Most of existing work achieves parallelization by mapping the nodes in network to the nodes in computing cluster, like [5]\u2013[7]. However, these algorithms are not suitable for\nMapReduce. In MapReduce structure, users cannot specifically control a certain node in a cluster. Instead, MapReduce can only assign the mapper\u2019s and reducers\u2019 jobs as a whole, so the algorithms above are not implementable in this cloud computing environment. Moreover, the scale of these work is relatively small, and lack of elasticity. Mapping the network nodes to different computing nodes will inevitably increase the I/O cost. In most cases, neural network problem are dealing with big data, which requires large amount of I/O operations. As the result, I/O cost is the major cost in the distributed computing environment of existing methods.\nChu et al. [8] and Liu et al. [9] both proposed their own algorithm that used back-propagation algorithm to train a three-layer neural network based on MapReduce. They did the supervised learning (which is the only kind of learning back-propagation can do) to classify the input data into two categories and did some experiments on multi-core environment. However, They did not adopt the latest neural network achievement, deep learning, and therefore still suffered from the problem of low learning efficiency."}, {"heading": "III. SYSTEM ARCHITECTURE", "text": ""}, {"heading": "A. Main Strategy", "text": "In detail, we implement deep learning algorithm [4] to train the input data, where a MapReduce programming model is made use of to parallelize the computation. The MapReduce job consists of the mapper and reducer functions, of which the mapper function will extract key/value pairs from input data and transfer them into a list of intermediate key/value pairs, and reducer function merges these intermediate values corresponding to the same key generated from mapper function to produce output values. In the case of Machine Learning, the input value will be the data from a certain object that a machine is going to \u201clearn\u201d, and in our project, the objects are data sets extracted from handwriting characters. The intermediate key/value pair will be the weights, in order for a machine to determine whether it has acknowledged the object correctly. Reducer function uses these weights to compute the so-called \u201cacknowledgment\u201d of the machine of an intended object [10]. If there exits an intolerable difference between the precision of training set and expected precision, the MapReduce job will loop until an acceptable result has worked out.\n1) Difficulties: As mentioned before, the main problem is the huge amount of data waiting to be trained. Although deep learning learns from representation, it is not capable of eliminating similarity and noisiness contained in data sets, and this will terribly affect machine learning [11]. Thus the most straightforward consequence is that the MapReduce job would loop many times so that it is hard to provide a satisfying precision, or even it cannot produce an output. It is necessary, however, to implement a mechanism to somehow improve the efficiency of the procedure of neural network. One idea is to remove the similar items by using diversity-based data sampling method. It can be applied to MapReduce programming model, too, where the frequency of input data will be counted, and those duplicated data is eliminated. Another way\nis to somehow train the data so that the machine would find a certain pattern corresponded with the data set. Both are applicable to develop the efficiency of back-propagation."}, {"heading": "B. Modules and Subsystems", "text": "Our system is made up of three different parts, the Deep learning implemented by Java, the Cloud Computing by Hadoop, and Demonstration software implanted by Matlab. Such design can be well illustrated in figure 2.\nBriefly, we divide our progress of machine learning into three steps: the step of pre-training which makes use of deep learning technology to initialize weights, the step to finetune the weights, and the last step aiming at improving the precision."}, {"heading": "IV. DEEP LEARNING", "text": ""}, {"heading": "A. Pre-training", "text": "The motivation to insert pre-training step before fine-tuning is the unacceptable inefficiency of back propagation when converting a high-dimensional data into low-dimensional codes. When we have multiple layers, large initial weights always witnesses poor local minima, while small initial weights will lead to tiny gradients in early layers, making it infeasible to train the whole back propagation system with many hidden layers [12].\nTherefore, we have to make the initial weights close to the solution. The idea is simple. Think about two pictures of number zero and number one. Instead of jumping to the final step of recognizing the number, we let machine accomplish the task step by step, where it first looks for the internal pattern of two pictures, namely, recognizing a circle and a stick, then encodes the circle and the stick to zero and one respectively. Practically, however, it is not easy because this process requires a very different type of algorithm that learns one layer of features at a time.\nWe make advantage of restricted Boltzmann machine (RBM) to realize pre-training, where an ensemble of binary vectors can be modelled using a two-layer network, in which\nstochastic, binary pixels are connected to stochastic, binary feature detectors using symmetrically weighted connections. Pre-training involves learning a stack of RBMs, each of which has one layer of feature detectors, and it is sort of recursive process where the learned feature activations of one RBM are used as \u201cdata\u201d for training the next RBM in the stack. For each RBM, we are not going to evaluate the weights between two layers for infinite times in order for the efficiency. Instead we get the modified weights result from two rounds of RBM calculation, and the result of this recursive execution is unrolled to create a deep auto encoder. Note that this does not hurt the precision quite much because of the mathematics proof by Geoffrey E. Hinton. Thanks to the largely increased number of machines involved in, the time cost for training will decrease in inverse proportion, too. Figure 3 give us a directly illustration of what RBM is.\nOne more point to be noticed is that we are adjusting the weights of paths based on the average variations of a single weight resulting from the modification made by a batch of training items. The reason is updating the value of weights once a single training item is extremely slow and inapplicable for MapReduce method."}, {"heading": "B. Fine-tuning", "text": "This is the step where we get zero and one from a circle and a stick. Pre-training initializes the weights so that they are close to the solution we want, but they are not the answer. We train the weights using back propagation [13] algorithm based on MapReduce method in multiple layer neural network [14]. Back propagation and its improved methods are applied in mobile data processing. Such applications can be found in [15]\u2013[17]. Note that here the trained data is not randomized weights but well-initialized weights, making it easier to get the solution. Every mapper receives one training item and then computes all update value of the weights. Then each reducer gathers update-values for one weight and calculating the average. The input value of mapper is the input item while the input key is empty. On the other hand, the value of the reducer is the difference between original weight and updated weight, and the corresponding key is the weight. Similar to pre-training, variations of each weight should be updated batch by batch for the sake of efficiency."}, {"heading": "C. Precision Refinement", "text": "This step is still in discussion. We are going to use Adaboosting [18] method to refine the result of data training. Basically, a neural network model after training is regarded as a classifier. Unfortunately, the precision of a classifier is vulnerable to the noisy and the large-scale of the mobile data. Such learning is called weak learning, and we need to improve the performance of the classifier.\nThe general concepts of the Adaboosting method can be summarized as: get one weak classifier from part of the training set; get more using different parts of the training set sampled out by the features of the former one; assemble them. This is just the basis and we are not going to talk much about the Adaboosting method here because we do not have a good idea about it now. Our main focus at present is implementing the pre-training step, using deep learning, and realizing the MapReduce based back-propagation algorithm."}, {"heading": "V. CLOUD COMPUTING BASED ON MAPREDUCE", "text": ""}, {"heading": "A. Choice of Cloud Computing Platform", "text": "One of the most severe disadvantages of deep learning is the long training time. Such time-consuming problem prohibit trained machine from quickly equipped with accurate nueral network data and accomplish required task. To solve such problem, applying cloud computing algorithm to machine learning is a good idea.\nAmong all the MapReduce platform, Hadoop [19] is a good choice for our project. It is an open source software for data storage as well as large scale processing of data-sets on clusters of commodity hardware [20]. The main modules that compose Hadoop framework are Hadoop Common, Hadoop Distributed File System (HDFS), Hadoop Yarn,and Hadoop MapReduce [21]. Hadoop Common contains all the utilities and libraries that required by all the other Hadoop modules. HDFS is a distributed file-system that containing data on the clustering machines. It can provide highly aggregated bandwidth for both masters and slaves across the commodity. Hadoop Yarn is a resource-management platform. It is responsible for arranging computing resources in commodity through which the users\u2019 applications are scheduled. Hadoop MapReduce is the most important part here. It provides a programming model for large scale data.\nIn this project, we use Amazon Web Service EC2 platform to achieve our MapReduce algorithm. It is a collection of remote computing services that provides a cloud computing platform. Based on a physical srver farm, it can provides customer faster and cheaper large computing capacity."}, {"heading": "B. MapRedeuce Structure Design", "text": "In order to implement MapReduce to RBM, we apply an algorithm that can be well illustrated in figure 4. For the sake of easy calculation, all the weights coming from paths between nodes are allocated in a matrix. For each mapper task, one training item is sent to a mapper. Their outputs are matrices of variables of weight resulted through the RBM algorithm. A unique ID can identify every element in the output matrix of\nmapping tasks, which is considered as the key of the reducing task. For each reducer task, a reducer accepts the ID and the value of a certain element of the matrix as key value pair. Since each reducer will only receive variable value of one particular ID, it can sum up all the results provided by each training item and find the final update of that element."}, {"heading": "C. Pseudo-code for Algorithm", "text": "Our MapReduce-based deep learning algorithm contains 6 Java classes. A MapReduce driver class (DeepLearningDriver.java), two mappers and two reducers for RBM training and forward propagation tasks (RBMMapper.java, RBMReducer.java, PropMapper.java, and PropReducer.java), and a class that implements all the matrix operations (Matrix.java).\nWe present our algorithms using Pseudo-codes listed below. First, Algorithm 1 describes the driver of deep learning MapReduce program. It contains two MapReduce structures: RBM and forward propagation. It is the scheduler for the MapReduce tasks.\nAlgorithm 2 describes the mapper of restricted Boltzmann machine (RBM) training part in deep learning MapReduce program. Each mapper only trains the weights for one iteration using one test case. So, in order to train the weights of the whole neural network, the MapReduce program needs to execute (maxEpoch\u00d7numLayers) times. It contains six parts: configure() reads all the configurations and distributed cache from outside; initialize() parse the input strings into parameters, and initialize parameters for algorithm; getposphase() does the positive phase of RBM training; getnegphase() does the negative phase of RBM training; update() computes the update of weights using previous results and parameters; map() implements the mapper. It outputs the original key and updated value pair as the intermediate data. In the pseudo-\nAlgorithm 1 The Driver for MapReduce-based Deep Learning algorithm Initialization:\nThe user provides the input file location, output file location, max iteration number (maxEpoch), number of layers (numLayer), number of nodes in each layer (numNodes(layer)) via input arguments.\nIteration: 1: for layer \u2190 1 to numLayers\u2212 1 do 2: numV is\u2190 numNodes(layer \u2212 1); 3: numHid\u2190 numNodes(layer); 4: Weights(layer)\u2190 RandomizeWeights(); 5: iter \u2190 1; 6: for iter \u2264 Max Iteration Times do 7: JobRBM \u2190 Initialized MapReduce Job for RBM; 8: Store Weights(layer) into \u2192 file system: FS; 9: Give config data: numV is\u2192 JobRBM ; 10: Give config data: numHid\u2192 JobRBM ; 11: Assign Distributed Cache: FS \u2192 JobRBM ; // Each Mapper has a full copy of weights 12: Start JobRBM : 13: input: the network input for current layer; // (# of Mappers: num of cases) 14: output: Weightsupdate \u2190 update for every weight; // (# of Reducers: numV is\u00d7 numHid) 15: Update Weights(layer): 16: for all weight \u2208Weights(layer) do 17: weight\u2190 weight+ weightupdate; 18: end for 19: iter++; 20: end for 21: Jobprop \u2190 Initialized MapReduce Job for propagate; 22: Store Weights(current) into \u2192 file system: FS; 23: Give config data: numV is\u2192 Jobprop; 24: Give config data: numHid\u2192 Jobprop; 25: Assign Distributed Cache: FS \u2192 Jobprop; 26: Start Jobprop : 27: input: the network input for current layer; 28: output: the network output for current layer; 29: end for 30: return\nThe final Weights(last layer) is the trained result we want.\ncode, we skip the details of RBM training algorithm, because that is not the focus of this paper. If the reader is interested in it, please refer to Dr. Hinton\u2019s paper in [4].\nAlgorithm 3 describes the reducer of restricted Boltzmann machine (RBM) training part in deep learning MapReduce program. Each reducer collects all the weight updates from one single weight ID. It adds up the updates from the same weight and write to the final output.\nAlgorithm 4 describes the mapper of forward propagation part in deep learning MapReduce program. It is executed between every two layers. So the total execution time for\nAlgorithm 2 The mapper of restricted Boltzmann machine (RBM) training part in deep learning MapReduce program. Initialization:\nInput of the mapper is one training case from network input. Also, there are arguments like numV is, numHid and Weight(current) past in via configurations or distributed cache.\nIteration: 1: initialize(); 2: getposphase(); 3: getnegphase(); 4: update(); 5: for i\u2190 0 to numV is\u2212 1 do 6: for j \u2190 0 to numHid\u2212 1 do 7: output \u3008key, value\u3009 pair:\n\u3008WeightID,WeightUpdate\u3009 8: end for 9: end for\n10: return Each mapper output its update of Weights() according to its train case.\nAlgorithm 3 The reducer of restricted Boltzmann machine (RBM) training part in deep learning MapReduce program. Initialization:\nInput of the reducer is the intermediate data output by the mappers from the same weight ID.\nIteration: 1: sum\u2190 0; 2: for all Weightupdate \u2208 same WeightID do 3: sum\u2190 sum+Weightupdate; 4: end for 5: output \u3008key, value\u3009 pair: \u3008WeightID, sum\u3009\n6: return Each reducer output the overall update of Weights().\nthis MapReduce program is numLayer \u2212 1. It contains four parts: configure() reads all the configurations and distributed cache from outside; initialize() parses the input strings into parameters, and initializes parameters for algorithm; prop2nextLayer() computes the forward propagation algorithm; map() implements the mapper. It outputs the original key and updated value pair. We also skip the algorithm details here, and just focus on the structure.\nThe reducer of forward propagation part is just output the intermediate data as final output, so it is omitted."}, {"heading": "VI. PERFORMANCE AND RESULTS", "text": "In the performance evaluation section, extensive experiments have been conducted. The experimental results prove the efficiency, and scalability of our proposed MapReduce on neural network method. This method can be applied over large-scale realistic data on the cloud-computing platform of AWS.\nAlgorithm 4 The mapper of forward propagation part in deep learning MapReduce program. Initialization:\nInput of the mapper is one training case from network input. Also, there are arguments like numV is, numHid and Weight(current) past in via configurations or distributed cache.\nIteration: 1: initialize(); 2: prop2nextLayer(); 3: Initialize string update\u2190 \u201c\u201d 4: for i\u2190 0 to numHid\u2212 1 do 5: update\u2190 update+ Caseupdate + \u201c \u201d; 6: end for 7: output \u3008key, value\u3009 pair: \u3008CaseID, update\u3009\n8: return Each mapper output the forward-propagated training case Caseupdate.\nBecause the goals of our project consist of two parts: deep learning on neural network and MapReduce-based parallelized computing, three sets of experiments have been conducted: objective performance evaluation of deep learning algorithm, experiments on speed-up gained from MapReduce, and subjective performance evaluation of demo applications."}, {"heading": "A. Performance Experiment Set-up", "text": "We use the hand-written digit training and testing cases from the on-line database available in [22]. It has a training set of 60,000 examples, and a test set of 10,000 examples. And all of them are labeled.\nThe AWS cloud-computing platform is built up by multiple EC2 instances. Up to 32 EC2 nodes have been used in these experiments for comparing the performance of experiments in different running instances. Massive input data and intermediate results are stored in the distributed cache offered by the platform. The raw input data is in the size of 300 megabytes and stored distributed across the platform. Each EC2 instances has Intel 64 bit CPU, 16 GB memories and high network performance. Moreover each node can be boosted up to 4 virtual CPU with the performance triple increased. Open source framework Hadoop is adopted by AWS for the distributed architecture of those nodes.\nAmazon EC2 instances provide a number of additional features to deploy, manage, and scale our applications. Multiple storage options based on our requirements can be choose. Details about how EC2 instances work can be found in figure 5."}, {"heading": "B. Result Evaluations", "text": "In the first part, we conduct the objective performance evaluation of deep learning algorithm. Error rate of our system is the primary concern, therefore we conducting several experiments to measure the error rate after several iterations. Figure 6\nshows the number of training error and testing error as the iteration number increases, for unsupervised learning of handwritten digits. As we can see from figure 6, the error rate for reconstruction of hand-written digits decreases significantly after several iterations, for both training cases and testing cases. This is achieved by the application of RBM algorithm and back-propagation algorithm.\n(a) Training Error v.s. iteration time curve (b) Testing Error v.s. iteration time curve\nFig. 6. Train and test error v.s. iteration time curve for unsupervised learning.\nFigure 7 shows the number of misclassification in training and testing as the number of iterations increases, for supervised learning of hand-written digits recognition. As we can see in figure 7 (a), the training error soon reaches 0 after several iterations. However, in figure 7 (b), it shows that the misclassification rate of testing cases increases as number of iterations increases. This is a sign of over-fitting problem, which is clearly discussed in [23]. Over-fitting is inevitable in supervised learning and classification problems.\nIn the second part, we conduct the experiments on speedup gained from MapReduce. The efficiency and scalability of our MapReduce method is tested on cloud clusters with 2,4,8,16,and 32 nodes. The test input size is 300 MB. From our result, we can clearly conclude that the running time of tasks is linearly dependent on the aspects of nodes numbers in the cluster. The slightly mismatch between result and our anticipation is because of the overhead of system architecture. Our result proves MapReduce have an excellent speed-up performance. Figure 8 shows the running time has an inverse\n(a) Training Error v.s. iteration time curve (b) Testing Error v.s. iteration time curve\nFig. 7. Train and test error v.s. iteration time for supervised learning. Note that the misclassification decreases in training (a), but increases in testing (b), which is a sign of over-fitting problem.\nFig. 8. Performance result \u2013 time performance v.s. number of slaves curve for unsupervised learning.\nratio relationship with the nodes number approximately. Our result proves our method has an excellent scalability."}, {"heading": "C. GUI Demo by MATLAB", "text": "To further refine our project, we implement two GUI demo software inherited from MATLAB GUI package. GUIs also known as graphical user interfaces will provide a type of pointand-click control of the software application we designed. By implementing a GUI interface, users are easier to understand the performance of our system. The reason why we choose to use MATLAB GUIs is MATLAB apps are self-contained programs with GUI front ends that automate a test. MATLAB GUIs usually includes controls such as menus, toolbars, buttons, and sliders.\nThere are two demos: figure 9 shows the screen shots of demo software for supervised learning (hand-written digit recognition) results, and figure 10 shows the screen shots of the demo software for unsupervised learning (hand-written digit auto-encoding and auto-decoding) results.\nAs figure 9 shown, to use the software, there are three steps:(a) step is to import the corresponding supervised learning weights file by selecting \u201cFile \u2192 Open\u201d; (b) step is to draw a digit with mouse on left box; (c) step is to click the \u201crecognize\u201d button and the recognition result shows on the right.\nAs figure 10 shown, to use the software, there are four steps:(a) step is to import the corresponding unsupervised learning weights file by selecting \u201cFile \u2192 Open\u201d; (b) step\nis to draw a digit with mouse on left box; (c) step is to click encode button and the code shows in the middle; (d) step is to click decode button and the reconstruction shows on the right. Note that the picture is 28 \u00d7 28 dimensions, and the code in the middle only has 30 dimensions, so the compress rate is 30\u00f7 784 = 0.357.\nIn the last part, we present a subjective evaluation of our system using some screen shots of our demo software.\nThe supervised learning (hand-written digit recognition) results are shown in figure 11. As we can see, the recognition results are very accurate, despite of some informal handwriting, like 7 with a bar.\nThe unsupervised learning (hand-written digit autoencoding and auto-decoding) results are shown in figure 12. In figure 12 (a - c), the numbers are nicely reconstructed after encoding and decoding. Bear in mind that the recovery is purely based on the code in the middle, but not the original picture. Although there is very subtle difference between them, you can definitely understand the reconstructed number.\nHowever, if we write a different category of symbols (like a Chinese character) in the box on the left, instead on digits, the reconstruction ability is very poor. Moreover, we can see from figure 12 (d), the program \u201ctries\u201d to recover the symbol into a digit. That is because we trained the neural network with hand-written digits, and the network does not recognize other symbols."}, {"heading": "VII. CONCLUSIONS", "text": "In general, we successfully designed and implemented a MapReduce neural network algorithm on large scale of data which running on top of Amazon Web Service platform. Great improvements on efficiency and accuracy have been achieved by our system, due to the facts that our system is running on distributed file platform. We also observe that the running time of processing data is decreasing as the number of nodes increasing, almost in an inverse linear mode. The slightly mismatch between experiments and theory is because of the\nsystem overhead when larger number of nodes is introduced into the system. We are convinced that with the application of MapReduce, neural network is capable of successfully recognizing handwriting digits with great efficiency and accuracy. In the future we are planning to apply our algorithm on more complex input model including face recognition, speech recognition and human language processing.\nAPPENDIX\nThe code repository can be found on Github at: https:// github.com/sunkairan/MapReduce-Based-Deep-Learning"}, {"heading": "ACKNOWLEDGEMENT", "text": "The authors thank Dr. Andy Li and his teaching assistances for their suggestions that significantly improved the quality of the paper. The authors also thank Dr. Dapeng Oliver Wu and his team for providing deep discussions about our research details. The computing cluster resources used by this project is supported by the course of EEL-6935: Cloud Computing and Storage."}], "references": [{"title": "Process control via artificial neural networks and reinforcement learning", "author": ["J. Hoskins", "D. Himmelblau"], "venue": "Computers & chemical engineering, vol. 16, no. 4, pp. 241\u2013251, 1992.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1992}, {"title": "Parallel distributed processing: explorations in the microstructure of cognition. volume 1. foundations", "author": ["D.E. Rumelhart", "J.L. McClelland"], "venue": "1986.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1986}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Y.-W. Teh"], "venue": "Neural computation, vol. 18, no. 7, pp. 1527\u20131554, 2006.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Parallelization of a backpropagation neural network on a cluster computer", "author": ["M. Pethick", "M. Liddle", "P. Werstein", "Z. Huang"], "venue": "International conference on parallel and distributed computing and systems (PDCS 2003), 2003.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "On the performance of parallel neural network implementations on distributed memory architectures", "author": ["K. Ganeshamoorthy", "D. Ranasinghe"], "venue": "Cluster Computing and the Grid, 2008. CCGRID\u201908. 8th IEEE International Symposium on. IEEE, 2008, pp. 90\u201397.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Parallel implementation of backpropagation algorithm in networks of workstations", "author": ["S. Suresh", "S. Omkar", "V. Mani"], "venue": "Parallel and Distributed Systems, IEEE Transactions on, vol. 16, no. 1, pp. 24\u201334, 2005. 8 Project Report for Cloud Computing and Storage. Dept. of Electrical and Computer Engineering, University of Florida, October 12, 2015", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Map-reduce for machine learning on multicore", "author": ["C. Chu", "S.K. Kim", "Y.-A. Lin", "Y. Yu", "G. Bradski", "A.Y. Ng", "K. Olukotun"], "venue": "Advances in neural information processing systems, vol. 19, p. 281, 2007.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Mapreduce-based backpropagation neural network over large scale mobile data", "author": ["Z. Liu", "H. Li", "G. Miao"], "venue": "Natural Computation (ICNC), 2010 Sixth International Conference on, vol. 4. IEEE, 2010, pp. 1726\u2013 1730.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Mapreduce: Distributed computing for machine learning", "author": ["D. Gillick", "A. Faria", "J. DeNero"], "venue": "Berkley (December 18, 2006), 2006.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "Systemml: Declarative machine learning on mapreduce", "author": ["A. Ghoting", "R. Krishnamurthy", "E. Pednault", "B. Reinwald", "V. Sindhwani", "S. Tatikonda", "Y. Tian", "S. Vaithyanathan"], "venue": "Data Engineering (ICDE), 2011 IEEE 27th International Conference on. IEEE, 2011, pp. 231\u2013242.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "A theory of the learnable", "author": ["L.G. Valiant"], "venue": "Communications of the ACM, vol. 27, no. 11, pp. 1134\u20131142, 1984.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1984}, {"title": "Neural networks: a comprehensive foundation", "author": ["S. Haykin"], "venue": "Prentice Hall PTR,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1994}, {"title": "Theory of the backpropagation neural network", "author": ["R. Hecht-Nielsen"], "venue": "Neural Networks, 1989. IJCNN., International Joint Conference on. IEEE, 1989, pp. 593\u2013605.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1989}, {"title": "Predicting subscriber dissatisfaction and improving retention in the wireless telecommunications industry", "author": ["M.C. Mozer", "R. Wolniewicz", "D.B. Grimes", "E. Johnson", "H. Kaushansky"], "venue": "Neural Networks, IEEE Transactions on, vol. 11, no. 3, pp. 690\u2013696, 2000.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2000}, {"title": "Data mining techniques on the evaluation of wireless churn.", "author": ["J. Ferreira", "M.B. Vellasco", "M.A.C. Pacheco", "R. Carlos", "H. Barbosa"], "venue": "ESANN,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2004}, {"title": "An ltv model and customer segmentation based on customer value: a case study on the wireless telecommunication industry", "author": ["H. Hwang", "T. Jung", "E. Suh"], "venue": "Expert systems with applications, vol. 26, no. 2, pp. 181\u2013188, 2004.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2004}, {"title": "Boosting the margin: A new explanation for the effectiveness of voting methods", "author": ["R.E. Schapire", "Y. Freund", "P. Bartlett", "W.S. Lee"], "venue": "The annals of statistics, vol. 26, no. 5, pp. 1651\u20131686, 1998.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1998}, {"title": "Cloud computing: state-of-the-art and research challenges", "author": ["Q. Zhang", "L. Cheng", "R. Boutaba"], "venue": "Journal of Internet Services and Applications, vol. 1, no. 1, pp. 7\u201318, 2010.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Mapreduce: simplified data processing on large clusters", "author": ["J. Dean", "S. Ghemawat"], "venue": "Communications of the ACM, vol. 51, no. 1, pp. 107\u2013113, 2008.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "The MNIST database of handwritten digits", "author": ["C.C. Yann LeCun", "C.J. Burges"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Inspired by animal central nervous system, artificial neural network (ANN) comes into the domain of machine learning and pattern recognition [1].", "startOffset": 141, "endOffset": 144}, {"referenceID": 1, "context": "Architecture of ANN [3].", "startOffset": 20, "endOffset": 23}, {"referenceID": 2, "context": "In our project, we implement the latest achievement of neural network algorithm, deep learning [4], to accelerate the performance of back-propagation neural network.", "startOffset": 95, "endOffset": 98}, {"referenceID": 3, "context": "Most of existing work achieves parallelization by mapping the nodes in network to the nodes in computing cluster, like [5]\u2013[7].", "startOffset": 119, "endOffset": 122}, {"referenceID": 5, "context": "Most of existing work achieves parallelization by mapping the nodes in network to the nodes in computing cluster, like [5]\u2013[7].", "startOffset": 123, "endOffset": 126}, {"referenceID": 6, "context": "[8] and Liu et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[9] both proposed their own algorithm that used back-propagation algorithm to train a three-layer neural network based on MapReduce.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "In detail, we implement deep learning algorithm [4] to train the input data, where a MapReduce programming model is made use of to parallelize the computation.", "startOffset": 48, "endOffset": 51}, {"referenceID": 8, "context": "Reducer function uses these weights to compute the so-called \u201cacknowledgment\u201d of the machine of an intended object [10].", "startOffset": 115, "endOffset": 119}, {"referenceID": 9, "context": "Although deep learning learns from representation, it is not capable of eliminating similarity and noisiness contained in data sets, and this will terribly affect machine learning [11].", "startOffset": 180, "endOffset": 184}, {"referenceID": 10, "context": "When we have multiple layers, large initial weights always witnesses poor local minima, while small initial weights will lead to tiny gradients in early layers, making it infeasible to train the whole back propagation system with many hidden layers [12].", "startOffset": 249, "endOffset": 253}, {"referenceID": 11, "context": "We train the weights using back propagation [13] algorithm", "startOffset": 44, "endOffset": 48}, {"referenceID": 12, "context": "based on MapReduce method in multiple layer neural network [14].", "startOffset": 59, "endOffset": 63}, {"referenceID": 13, "context": "Such applications can be found in [15]\u2013[17].", "startOffset": 34, "endOffset": 38}, {"referenceID": 15, "context": "Such applications can be found in [15]\u2013[17].", "startOffset": 39, "endOffset": 43}, {"referenceID": 16, "context": "We are going to use Adaboosting [18] method to refine the result of data training.", "startOffset": 32, "endOffset": 36}, {"referenceID": 17, "context": "It is an open source software for data storage as well as large scale processing of data-sets on clusters of commodity hardware [20].", "startOffset": 128, "endOffset": 132}, {"referenceID": 18, "context": "The main modules that compose Hadoop framework are Hadoop Common, Hadoop Distributed File System (HDFS), Hadoop Yarn,and Hadoop MapReduce [21].", "startOffset": 138, "endOffset": 142}, {"referenceID": 2, "context": "Hinton\u2019s paper in [4].", "startOffset": 18, "endOffset": 21}, {"referenceID": 19, "context": "We use the hand-written digit training and testing cases from the on-line database available in [22].", "startOffset": 96, "endOffset": 100}], "year": 2015, "abstractText": "Faced with continuously increasing scale of data, original back-propagation neural network based machine learning algorithm presents two non-trivial challenges: huge amount of data makes it difficult to maintain both efficiency and accuracy; redundant data aggravates the system workload. This project is mainly focused on the solution to the issues above, combining deep learning algorithm with cloud computing platform to deal with large-scale data. A MapReduce-based handwriting character recognizer will be designed in this project to verify the efficiency improvement this mechanism will achieve on training and practical large-scale data. Careful discussion and experiment will be developed to illustrate how deep learning algorithm works to train handwritten digits data, how MapReduce is implemented on deep learning neural network, and why this combination accelerates computation. Besides performance, the scalability and robustness will be mentioned in this report as well. Our system comes with two demonstration software that visually illustrates our handwritten digit recognition/encoding application. 1", "creator": "LaTeX with hyperref package"}}}