{"id": "1511.00787", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Nov-2015", "title": "A Pareto Optimal D* Search Algorithm for Multiobjective Path Planning", "abstract": "Route planning is one of the most important elements of mobile robotics and provides the agent with a collision-free route through the workspace. The global route map can be calculated using a variety of well-founded search algorithms, especially the A * search method, which guarantees a complete and optimal solution that minimizes route costs.D * is widely used for its dynamic re-planning capabilities.Route planning optimization typically aims to minimize the distance traveled from start to finish, but many mobile robotic applications require additional route planning objectives and pose a multi-objective optimization problem.Common search algorithms, such as A * and D *, are not well suited to MOO problems and provide suboptimal results. The search algorithm presented in this paper is designed for optimal MOO route planning.The algorithm integrates Pareto optimization in D * and therefore bears the name -PO calculation step is not guaranteed in each search front.", "histories": [["v1", "Tue, 3 Nov 2015 05:48:26 GMT  (4182kb)", "http://arxiv.org/abs/1511.00787v1", "arXiv admin note: substantial text overlap witharXiv:1505.05947"]], "COMMENTS": "arXiv admin note: substantial text overlap witharXiv:1505.05947", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["alexander lavin"], "accepted": false, "id": "1511.00787"}, "pdf": {"name": "1511.00787.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Alexander Lavin"], "emails": ["alavin@alumni.cmu.edu)."], "sections": [{"heading": null, "text": "Keywords\u2014multiobjective optimization; path plan; search algorithm; A*; D*; Pareto; mobile robot; Mars rover\nI. INTRODUCTION A crucial task for mobile robots is to navigate intelligently through their environment. It can be argued that path planning is one of the most important issues in the navigation process [1], and subsequently much research in field robotics is concerned with path planning [2], [3]. To complete the navigation task, methods will read the map of the environment and search algorithms will attempt to find free paths for the robot to traverse. Path planning methods find a path connecting the defined start and goal positions, while environmental parameters play the role as algorithm inputs, and the output is an optimized path from the start to goal [4]. The important issue in mobile robot navigation is optimizing path efficiency according to some parameters such as cost, distance, energy, and time. A* search is the leading search algorithm for mobile robot path planning, yielding solutions guaranteed to be optimal [5]. Recently the mobile robot community has put an increased emphasis on suboptimal path planning methods which meet time-critical constraints over slow, optimal algorithms. D* is the dynamic version of A*, sacrificing optimality for computational efficiency in changing environments. Notable implementations of D* in the field robotics include the DARPA Urban Challenge vehicle from Carnegie Mellon University, and Mars rovers Opportunity and Spirit [6].\nAlexander Lavin was a mechanical engineering graduate student with Carnegie Mellon University. This work was done independently after graduation in 2014 (email: alavin@alumni.cmu.edu).\nPath planning methods typically optimize the path efficiency for one criterion, yet many mobile robot operations call for a path plan that optimizes for several parameters [7]. Path optimization over several parameters \u2013 e.g. distance and energy \u2013 is a multiobjective optimization (MOO) problem. The best path is not necessarily the shortest path, nor the path calling for the least amount of energy expenditure.\nCombining the optimization criteria into a single objective function is a common approach, often with tools such as thresholds and penalty functions, and weights for linear combinations of objective values. But these methods are problematic as the final solution is typically very sensitive to small adjustments in the penalty function coefficients and weighting factors [8], posing an issue for MOO path planning with A*, D*, or similar search algorithms. Another issue is these methods yield suboptimal solution paths. Evolutionary algorithms, particularly genetic algorithms, have been used widely for MOO problems, including success in path planning [7], [9]. Drawing on evolutionary computation techniques in a previous study, Lavin [10] defined an A* alternative specifically designed for MOO path planning. This algorithm, named A*-PO, yields Pareto optimal solutions: solutions in which there exist no other solutions superior in all objectives. The key feature in A*-PO is the use of a Pareto front cost function when searching for the solution path. Lavin shows A*-PO outperforms the standard A* search algorithm across all optimization criteria of a given MOO problem, with minimal loss to computational efficiency.\nThis paper continues Lavin\u2019s previous work of implementing Pareto optimality into multiobjective optimization for mobile robot path planning. Presented in this study is D*-PO: a Pareto optimal version of the D* search algorithm specifically designed for MOO path planning. The path planning algorithms D*-PO and A*-PO are novel because each step is Pareto optimal, solving the aforementioned issue of suboptimal results.\nThe next section further discusses Pareto optimality and the application to mobile robot path planning. Section III discusses the technical approach used in this study, and Section IV presents the results. The results are over a set of simulations running the A*, D*, and D*-PO algorithms in Mars environments. Section V concludes the paper with discussion and future work.\nII. BACKGROUND AND METHODS"}, {"heading": "A. Mobile Robot Path Planning", "text": "The aim of mobile robot path planning is to provide an efficient path from start to goal that avoids objects and obstacles. An efficient path is one that minimizes path costs, where the cost is typically the travel distance or time. Search\nalgorithms find a negotiable path from start to goal states in the configuration space: data structures that show the position and orientations of objects and robots in the workspace area, including both the free and obstructed regions. Typically the robot\u2019s world is represented by either an occupancy grid, a vertex graph, or a Voronoi diagram [1]. The methods discussed in this study use an occupancy grid representation composed of binary states, where 0s and 1s represent free and occupied cells, respectively. As shown in the first flowchart block of Fig. 1, the robot (agent) has at most eight possible successors for the next step in the path; the robot in the green position is capable of moving into a neighboring yellow position, but not the occupied grey cells.\nPotential solution paths connect the start cell to the goal cell via free cells. Searching for the optimum path is an optimization problem, where the optimum path is defined as that which minimizes the path cost, or the objective function.\nA candidate path can be denoted by\n\ud835\udc43 = {\ud835\udc5d!, \ud835\udc5d!,\u2026 , \ud835\udc5d!} (1)\nwhere \ud835\udc5d! is the \ud835\udc56th waypoint of the path \ud835\udc43. The MOO problem is then framed as determining a path\n\ud835\udc43\u2217 \u2208 \ud835\udc43 (2)\nthat satisfies\n\ud835\udc39 \ud835\udc43\u2217 = \ud835\udc5a\ud835\udc56\ud835\udc5b \ud835\udc39! \ud835\udc43 ,\ud835\udc39! \ud835\udc43 ,\u2026 ,\ud835\udc39!(\ud835\udc43) (3)\nwhere \ud835\udc39! denotes the \ud835\udc56 th cost function of the path planning problem. That is, equations (1-3) state the aim of the problem is to minimize path cost across all \ud835\udc61 objective functions. The study here considers four cost functions, or \ud835\udc61 = 4. Equation (4) gives the total length of the path:\n\ud835\udc39! \ud835\udc43 = \ud835\udc5d! , \ud835\udc5d!!!\n!!!\n!!!\n(4)\nwhere \ud835\udc5d! , \ud835\udc5d!!! is the Euclidean distance between subsequent cells in the path. Minimizing \ud835\udc39! finds the path of shortest length from start to goal.\nEquation (5) gives the average elevation of the path:\n\ud835\udc39! \ud835\udc43 = \ud835\udc52!/\ud835\udc5b !\n!!!\n(5)\nwhere \ud835\udc52! is the elevation at waypoint \ud835\udc56\u2026 \ud835\udc5b . Running algorithms on workspaces with the same terrains and start/goal states, the minimization of \ud835\udc39! gives the path which climbs up the least amount of incline (or alternatively moves the robot down the most decline).\nThe simulations in this study model a planetary exploration rover, thus a relevant path cost is solar vector deviation. That is, the MOO problem includes an additional optimization objective to minimize the total angular deviation of sunlight from the rover\u2019s rear solar panel. This was computed by minimizing the dot product of the rover vector \ud835\udc5f and the solar ray vector \ud835\udc60:\n\ud835\udc39! \ud835\udc43 = \ud835\udc5f! \u2219 \ud835\udc60!\n!\n!!!\n= \ud835\udc5f! \ud835\udc60! \ud835\udc50\ud835\udc5c\ud835\udc60\ud835\udf03 (6)\nThis cost layer is dependent on both time and the robot\u2019s orientation in the configuration space, and is thus it is dynamic. That is, the costmap changes at each step in the path, depending on the two-dimensional rover vector and the solar vector field. For this case study, the solar incidence was modeled as a two-dimensional vector whose angle rotated 0.01 radians per search step.\nIn the simulations an area of high risk in each workspace is to be avoided. Equation (7) models a cost for path risk:\n\ud835\udc39! \ud835\udc43 = 1 \ud835\udc5b\n1 (x \u2212 \ud835\udc65!)!+(y \u2212 \ud835\udc66!)!\n!\n!!!\n(7)\nThe path risk decreases quadratically with the distance from the location of risk in the workspace. The costs of (4)- (7) are illustrated in Fig. 4. The aim is to minimize these four cost sums.\nIn path optimization the search method aims to plan an efficient path according to (3). With a priori knowledge of the exploration area, we can use an informed search method. Specifically best-first search, which traverses a graph or grid using a priority queue to find the shortest, collision-free path [4]. A priority queue, or open list, is used to focus the search and order cost updates efficiently [11]. The decision of the next node expanded, the successor, is based on the evaluation function, \ud835\udc53(\ud835\udc5b): estimated cost of the cheapest solution through node \ud835\udc5b (Note: lowercase \ud835\udc53 is used here to specify the cost function at an individual search step, whereas capital \ud835\udc39 was used previously to denote the cost function for an entire path). Informed search methods benefit from a heuristic function \u210e(\ud835\udc5b): the estimated cost of the cheapest path from a node \ud835\udc5b to the goal state. Greedy bestfirst search is built solely on this heuristic, where \ud835\udc53 \ud835\udc5b = \u210e(\ud835\udc5b), expanding the node closest to the goal at each search step. The incorporation of the heuristic into the path cost makes the search algorithm more efficient because the search is focused in the direction of the robot, reducing the total number of state expansions [12].\nThe A* algorithm is perhaps the most popular best-first search method, adding to the heuristic the cost to reach the node, \ud835\udc54(\ud835\udc5b) . That is, \ud835\udc53 \ud835\udc5b = \u210e \ud835\udc5b + \ud835\udc54(\ud835\udc5b) . The search algorithm, looking for the cheapest path, tries (expands) the node with the lowest \ud835\udc53 \ud835\udc5b [13], [14]. To determine the optimal sequence of waypoints, the A* algorithm is a favorite for route search problems [15], [16], guaranteeing optimal solution paths [13]. Norvig and Russel [13] explain how A* is optimally efficient: no other optimal algorithm is guaranteed to expand fewer nodes than A*. As long as a better-informed heuristic is not used, A* will find the leastcost path solution at least as fast as any other method. The A*-PO algorithm defined by Lavin [10] builds off this optimality guarantee to offer an algorithm yielding Pareto optimal solution paths, specifically for problems of multiple path costs.\nA* is a favorite method for path planning in static environments, where the positions of all obstacles and objects are fixed and known. The dynamic environment, on the other hand, may have obstacles and objects which vary positions with time. Similarly, an unknown or partially known environment calls for dynamic path planning because more is learned as the mobile robot progresses through the environment; the robot may receive info through e.g. an on board or offboard sensor. Thus it is important the optimal path(s) can be replanned when new information arrives.\nThe control architecture in mobile robotics is typically a combination of local and global planners, organized as shown in Fig 2. The reactive level handles local information, with real-time constraints. The deliberative, or global, level considers the entire world, likely requiring computation time\nproportional to the problem size [13]. The A* and D* algorithms, and their variations discussed in this paper, are global path planners.\nFor reactive, or real-time planning, computational speed is a priority. Previous studies [17], [18] have modified A* for fast planning. The D* algorithm is a dynamic version of A*, built to be capable of fast rerouting when the robot encounters new obstacles in the environment [4]. D* has been shown to be up to two orders of magnitude more efficient than planning from scratch with A* [11]. The speed of these searching algorithms is increased dramatically, but at the cost of sub-optimal solution paths [6]. The algorithm defined here, D*-PO, yields Pareto optimal solutions with D* functionality."}, {"heading": "B. Pareto Optimality", "text": "The MOO problem presents multiple cost criteria, where a solution stronger for one criterion may be weaker for another. There are two general approaches to optimizing for multiple objectives: (i) combine the individual objective functions into one composite function, and (ii) determine a Pareto optimal solution set. The first can be accomplished with weighted sums or utility functions, but selection of parameters is difficult because small perturbations in the weights can lead to very different solutions. These approaches also negate the optimality guarantees in select search algorithms, i.e. in A*. Despite these difficulties it is common the path cost function sums over the cost criteria at each step; the A* algorithm sums \u210e \ud835\udc5b and \ud835\udc54(\ud835\udc5b).\nThe second MOO approach finds the Pareto optimal set of the population, which is a set of solutions that are nondominated with respect to each other. Non-dominated solutions are those in which there exist no other solutions superior in all attributes (i.e. objectives). Moving between Pareto solutions, there is always sacrifice in one objective to achieve gain in another objective [19]. In objective space, the set of non-dominated solutions lie on a surface known as the Pareto front. Fig. 3 illustrates the two-dimensional case, where there is a tradeoff between minimizing both functions \ud835\udc54! and \ud835\udc54!. The second flowchart block of Fig. 1 shows the projection of path nodes into objective space.\nThe MOO problem is defined as\nmin ! \ud835\udc54! \ud835\udc65 ,\ud835\udc54! \ud835\udc65 ,\u2026 ,\ud835\udc54!(\ud835\udc65) (8)\nsubject to\n\u210e!(\ud835\udc65) \u2264 0 (9)\n\u210e! \ud835\udc65 = 0 (10)\n\ud835\udc65 \u2208 \ud835\udefa! (11)\nwhere \ud835\udc54! is the \ud835\udc56 th objective function of \ud835\udc41 total objectives; in path planning, \ud835\udc41 is the number of cost criteria. The inequality and equality constraints are \u210e! and \u210e! , respectively, and \ud835\udc65 is the vector of optimization or decision variables in the set of \ud835\udefa!.\nThen a solution \ud835\udc65\u2217 is Pareto optimal such that there exists no \ud835\udc65 that makes\n\ud835\udc54! \ud835\udc65 \u2264 \ud835\udc54! \ud835\udc65\u2217 for all \ud835\udc56 = 1,\u2026 ,\ud835\udc41 (12)\n\ud835\udc54! \ud835\udc65 < \ud835\udc54! \ud835\udc65\u2217 for at least one \ud835\udc57 \u2208 [1,\u2026 ,\ud835\udc41] (13)\nand the projection of \ud835\udc65\u2217 in the objective space, i.e. the point [\ud835\udc54! \ud835\udc65\u2217 ,\ud835\udc54! \ud835\udc65\u2217 ,\u2026 ,\ud835\udc54! \ud835\udc65\u2217 ] is a Pareto point.\nMultiobjective optimization is, therefore, concerned with the generation and selection of non-inferior solution points \u2013 those on the Pareto front. Pareto optimality is a crucial concept for finding solutions to MOO problems because identifying a single solution that simultaneously optimizes across several objectives is a nontrivial task [20].\nMOO problems are typically handled with evolutionary algorithms, where it is common to use Pareto fronts in the fitness functions. The non-dominated paths are favored in the population, and this increases generation over generation [21]. The main drawback, however, of using evolutionary algorithms for path planning is computational complexity; the methods must generate populations (search space) composed of full or segmented paths. And the solution paths are suboptimal.\nOne may also consider that summing over the costs to calculate a composite \ud835\udc53 presents another possible issue in search algorithms: depending on the current development of the path, some cost criteria may be favored over others, and this changes as the path development continues. For instance, the heuristic values \u2013 the estimated cost of the cheapest path from the current cell to the goal cell \u2013 will contribute more to the composite cost function close to the start than they will\nclose to the goal. That is, near the start state \u210e(\ud835\udc5b) will have a greater influence on \ud835\udc53 than will \ud835\udc54(\ud835\udc5b), and vise-versa for the goal state. Thus, as the path develops from start to goal, the heuristic value will contribute less and less. Using a Pareto front solves this issue because each cost criterion is valued as its own dimension in the Pareto space, not summed together.\nIII. TECHNICAL APPROACH"}, {"heading": "A. Costmap", "text": "To calculate cost functions at each step the search algorithms use a costmap. This representation of the configuration space is built off of the aforementioned occupancy grid, but now a cost value is assigned to each cell. Traversing a free space adds a unit cost to the path total, and the obstacles are represented by infinite cost; thus, they are not traversable. This is illustrated in the front image of Fig. 4. If traversing straight across a cell carries a unit distance cost, the cost for traversing a cell at a diagonal (a 45\u00b0 angle) carries a cost of 2.\nYet this costmap only reflects the distance of taking a given path through the configuration space. For a MOO problem, the path cost needs to consider the other cost criteria, for which we use additional layers. Each additional cost layer adds a dimension to the Pareto space, from which the Pareto front is calculated.\nThe first costmap layer is the distance cost, \ud835\udc54(\ud835\udc5b), and the second layer is the heuristic, \u210e(\ud835\udc5b). These two suffice for traditional A* and D* search, but we\u2019re interested in optimizing the robot\u2019s path for additional criteria. A third layer, \ud835\udc52(\ud835\udc5b) , is added to the costmap to incorporate the\nelevation costs. The fourth layer, solar deviation \ud835\udc60(\ud835\udc5b), is dynamic, changing at each step. That is, to simulate solar rays changing direction over time, the solar vector is rotated as the robot progresses. The fifth layer, \ud835\udc5f(\ud835\udc5b), has a risk value associated with each location in the workspace. Fig. 4 illustrates the layering of these path costs. An \ud835\udc5b-dimensional Pareto space has at most \ud835\udc5b layers to the costmap. The points on the Pareto front are non-dominated across the \ud835\udc5b dimensions, one dimension for each cost.\nThe cost values associated with the layers makeup a given node\u2019s projection to objective space, as in the second flowchart block of Fig. 1. All nodes in the open list are projected to objective space. At each search step the costs for each objective are normalized [0:1] over the nodes in the open list. This is an unnecessary step, however, for D*-PO (and A*-PO) because each cost value is relative to the cost metric\u2019s dimension in Pareto space. But normalization is necessary for the A* and D* algorithms because the composite cost function merges costs of varied measuring units and scales; without normalization, the objective values would not carry equal weight in the combined objective function. For instance, the elevation values are small relative to the distance values, and without normalization the elevation metric would be insignificant"}, {"heading": "B. D*-PO Search Algorithm", "text": "The algorithm presented in this study, D*-PO, is effectively the standard D* search algorithm but for a key modification: rather than computing the cost function \ud835\udc53 by summing cost criteria, D*-PO calculates the Pareto front of the cost criteria. The original D* paper by Stentz [12] explains D* extensively, including the algorithm\u2019s pseudocode, and is not repeated here. The inherent dynamic qualities of D* are maintained in D*-PO. The only departure from D* is using the Pareto front of the priority queue to determine the next successor node, as shown in the second through fourth flowchart blocks of Fig. 1. The D* search algorithm is guaranteed complete, but not optimal. The D*PO algorithm, however, is guaranteed to yield complete and Pareto optimal solution paths.\nCalculating the Pareto front of the open list will at times yield multiple Pareto points. To break the tie amongst the Pareto optimal successor nodes, a priority cost is defined. This cost is customizable, and can be e.g. a preferred criterion or a new criterion. As shown in the final flowchart block of Fig. 1, the cheaper node according to this priority cost is chosen for expansion. Because the priority cost decides between Pareto optimal nodes, the D*-PO search algorithm still maintains the quality that every step in the solution path is Pareto optimal.\nIV. RESULTS The MOO path planning algorithms were tested in simulated mobile robot environments. The computer\nsimulation environment included a Lenovo notebook computer with Intel Core i5 vPro CPU and 4 GB memory, running on Windows 8.1. The code is written in MATLAB R2013a."}, {"heading": "A. Algorithm Comparison", "text": "The algorithms yield the same solutions for single path cost problems, as expected. Where the advantages of D*-PO are significant is for MOO path problems. D*-PO was evaluated by comparing it with A* and D* for a set of 100 simulated environments.\nThe workspaces were setup as a 100x100 cell grids of randomly assigned obstacles, sized large, medium, and small. On average, the obstacles accounted for 23% of the configuration space. The start and goal locations were fixed at the lower-left (0,0) and upper-right (100,100), respectively. For each workspace a random 100x100meter terrain was sampled from HiRISE Mars terrain data [22], where the elevations were normalized [0:1] for each sample. Fig. 5 shows ten sampled workspaces from one Mars image. The solar vector is defined to rotate counterclockwise one radian for every path step, initially set at [1,0]. For each workspace a random cell was chosen as the location of max risk, with the risk decreasing radially with the inverse of the distance squared, as described in equation (7).\nThe optimization objectives, as presented above in (4)- (7), were to minimize the total path distance, elevation, solar vector deviation, and proximity to risk. Fig. 6 shows two examples of simulation runs with the resulting paths for the A*, D*, and D*-PO search methods, where the red and green marked squares represent the start and goal states, respectively. The left side diagrams of Fig. 6 are the final solution paths plotted over the layer of obstacles (red) and free spaces, where the background layer represents the heuristic cost. The right side diagrams show the same paths over a contour map, representing the elevation layer of the costmap. These plots also include the solar vector at the beginning and end of the paths.\n \u00a0\nFor the sample workspaces in this example, it is clear to see the benefits of calculating the Pareto front at each search step. The data over the set of 100 simulations echo these results, as shown in Table 1. Lower values are preferred for all metrics. The D*-PO algorithm outperforms both A* and D* across all of the MOO criteria, even though the resulting solution paths are not completely non-dominated solutions \u2013 i.e. at some steps the solution is the preference of the nondominated frontier. Thus, D*-PO solutions are always at least as good as those produced by A* and D*. The search time results show paths with Pareto optimal steps can be obtained efficiently with the D*-PO algorithm; A* is markedly faster than the others because the dynamic features of D* rely on priority queues that reopen (raise) states. All algorithms gave complete solution paths for all 100 simulations.\nThe average elevation of each solution path is used as a metric to compare the robot\u2019s net incline from start to goal. A path of a given average elevation implies the robot traversed up less slope (or down more slope) as compared to a path of higher average elevation. All paths share common start and goal states, so the elevation values are relative to one another.\nThe four functions cover the five cost criteria because both the distance travelled and the heuristic contribute to \ud835\udc39!. The simulations show the D*-PO algorithm provides the least-cost global path according to several independent preferences for a mobile robot in practice \u2013 e.g. planetary exploration rover.\nExpanding on these Mars rover simulations, one may account for more elaborate thermal constraints, such as heating of sensitive components by direct sunlight. Minimizing the number of turns could be another optimization objective.\nV. CONCLUSION In this study, global path planning for mobile robots is investigated. The optimal path is generated according to several cost criteria, solving the multiobjective optimization problem with the presented D*-PO algorithm. As demonstrated in the previous section, D*-PO is capable of providing paths where each step is Pareto optimal, and computes these solutions efficiently. In comparison to the traditional D* algorithm, it can be concluded the incorporation of Pareto fronts in D*-PO offers a better MOO search algorithm \u2013 a method that is both dynamic and optimal. D*-PO also is shown to outperform the widely-used A* search for MOO problems.\nThis study used a cell grid representation, which reduces computational complexity at the expense of reducing\ncompleteness. That is, solution paths are restricted to a constrained mobility. Future implementations of D*-PO (and A*-PO) may opt for state lattice representation: a discretized set of all reachable configurations of a system [23]. This representation would better model mobility constraints, leading to superior motion planning results because no time is wasted either generating, evaluating, or fixing infeasible plans.\nContinuation of this study may aim to further validate the D*-PO and A*-PO algorithms by evaluating paths based on a complete mobile robot energy expenditure metric. For a given path, this metric will provide a single energy value which would include the robot\u2019s energy output (factors of distance traversed, elevation change, and degrees of turns) and input (from solar array). Additionally the next implementation may use Pareto fronts in D* Lite which has been found to be slightly more efficient for some navigation tasks and easier to analyze [24].\nThe D*-PO and A*-PO algorithms would be beneficial to many applications for mobile robots with global path planning, including agricultural harvesting and information gathering (i.e. drones), disaster relief, DARPA challenges, factory and residential robot workers, and exploration rovers. D* is a very general algorithm and can be applied to problems in artificial intelligence other than robot motion planning, essentially any path cost optimization problem where the cost parameters change during the traverse of the solution [12]. D*-PO should be up to the task as well."}], "references": [{"title": "An Overview of Autonomous Mobile Robot Path Planning Algorithms", "author": ["N. Sariff", "N. Buniyamin"], "venue": "Research and Development, 2006. SCOReD 2006. 4th Student Conference on , vol., no., pp.183,188, 27- 28 June 2006", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Literature review on path planning in dynamic environment", "author": ["P.M. Bhushan Mahajan"], "venue": "International Journal of Computer Science and Network, vol. 2, no. 1, pp. 115\u2013118, 2013.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Map-based navigation in mobile robots:: Ii. a review of map-learning and path-planning strategies", "author": ["J.-A. Meyer", "D. Filliat"], "venue": "Cognitive Systems Research, vol. 4, no. 4, pp. 283 \u2013 317, 2003", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2003}, {"title": "Optimal and efficient path planning for partiallyknown environments.", "author": ["Stentz", "Anthony"], "venue": "Robotics and Automation,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1994}, {"title": "Pathfinding Using A* (A-Star).\" Searching Using A* (A- Star)", "author": ["R. Eranki"], "venue": "MIT, 2002. Web", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Graph-based Path Planning for Mobile Robots.\" Thesis", "author": ["Wooden", "David T"], "venue": "Georgia Institute of Technology,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Multi-objective Mobile Robot Path Planning Based on Improved Genetic Algorithm", "author": ["Hu Jun", "Zhu Qingbao"], "venue": "Intelligent Computation Technology and Automation (ICICTA), 2010 International Conference on , vol.2, no., pp.752,756, 11-12 May 2010", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Some guidelines for genetic algorithms with penalty functions.", "author": ["J. Richardson", "M. Palmer", "G. Liepins", "M. Hilliard"], "venue": "Proceedings of the third international conference on Genetic algorithms,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1989}, {"title": "Global Path Planning for Autonomous Mobile Robot Using Genetic Algorithm", "author": ["M. Samadi", "M.F. Othman"], "venue": "Signal-Image Technology & Internet-Based Systems (SITIS), 2013 International Conference on , vol., no., pp.726,730, 2-5 Dec. 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "A Pareto Front-Based Multiobjective Path Planning Algorithm.", "author": ["Lavin", "Alexander"], "venue": "International Conference on Intelligent Robots and Systems. IEEE/RSJ,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Anytime Dynamic A*: An Anytime, Replanning Algorithm", "author": ["M. Likhachev", "S. Thrun"], "venue": "American Association for Artificial Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "The D* Algorithm for Real-Time Planning of Optimal Traverses.", "author": ["A. Stentz"], "venue": "Pittsburgh: Carnegie Mellon U,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1994}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["Norvig", "Peter", "Stuart Russell"], "venue": "NJ: Pearson Education Limited,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Mission-Integrated Path Planning for Planetary Rover Exploration.", "author": ["Wu", "Peng", "Hehua Ju"], "venue": "Journal of Software", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Fuzzy terrain-based path planning for planetary rovers", "author": ["A. Howard", "H. Seraji", "B. Werger"], "venue": "Proceedings of the 2002 IEEE International Conference on Fuzzy Systems, vol.1, pp.316-320, 2002.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "An Integrated Traverse Planner and Analysis Tool for Planetary Exploration.", "author": ["Johnson", "Aaron", "Jeffrey Hoffman", "Dava Newman", "Erwan Mazarico", "Maria Zuber"], "venue": "AIAA SPACE 2010 Conference & Exposition, Anaheim, California,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Solving the find-path problem in mapped environments using modified A* search algorithm", "author": ["Kuo-Chin Fan", "Po-Chang Lui"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, vol.24, no.9, September 1994, pp 1390-1396.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1994}, {"title": "Fast path planning method using modified A* method", "author": ["Charles W. Warren"], "venue": "IEEE International Conference on Robotics and Automation, pp 662-667.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 0}, {"title": "Calculating Complete and Exact Pareto Front for Multiobjective Optimization: A New Deterministic Approach for Discrete Problems", "author": ["Xiao-Bing Hu", "Ming Wang", "Di Paolo, E."], "venue": "Cybernetics, IEEE Transactions on , vol.43, no.3, pp.1088,1101, June 2013.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "A niched Pareto genetic algorithm for multiobjective optimization", "author": ["J. Horn", "N. Nafpliotis", "D.E. Goldberg"], "venue": "Evolutionary Computation, 1994. IEEE World Congress on Computational Intelligence., Proceedings of the First IEEE Conference on , vol., no., pp.82,87 vol.1, 27-29 Jun 1994.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1994}, {"title": "Constrained Motion Planning in Discrete State Spaces.", "author": ["A. Kelly", "M. Pivtoraiko"], "venue": "Pittsburgh: Carnegie Mellon U,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}, {"title": "Improved fast replanning for robot navigation in unknown terrain.", "author": ["S. Koenig", "M. Likhachev"], "venue": "In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": "It can be argued that path planning is one of the most important issues in the navigation process [1], and subsequently much research in field robotics is concerned with path planning [2], [3].", "startOffset": 98, "endOffset": 101}, {"referenceID": 1, "context": "It can be argued that path planning is one of the most important issues in the navigation process [1], and subsequently much research in field robotics is concerned with path planning [2], [3].", "startOffset": 184, "endOffset": 187}, {"referenceID": 2, "context": "It can be argued that path planning is one of the most important issues in the navigation process [1], and subsequently much research in field robotics is concerned with path planning [2], [3].", "startOffset": 189, "endOffset": 192}, {"referenceID": 3, "context": "Path planning methods find a path connecting the defined start and goal positions, while environmental parameters play the role as algorithm inputs, and the output is an optimized path from the start to goal [4].", "startOffset": 208, "endOffset": 211}, {"referenceID": 4, "context": "A* search is the leading search algorithm for mobile robot path planning, yielding solutions guaranteed to be optimal [5].", "startOffset": 118, "endOffset": 121}, {"referenceID": 5, "context": "Notable implementations of D* in the field robotics include the DARPA Urban Challenge vehicle from Carnegie Mellon University, and Mars rovers Opportunity and Spirit [6].", "startOffset": 166, "endOffset": 169}, {"referenceID": 6, "context": "Path planning methods typically optimize the path efficiency for one criterion, yet many mobile robot operations call for a path plan that optimizes for several parameters [7].", "startOffset": 172, "endOffset": 175}, {"referenceID": 7, "context": "But these methods are problematic as the final solution is typically very sensitive to small adjustments in the penalty function coefficients and weighting factors [8], posing an issue for MOO path planning with A*, D*, or similar search algorithms.", "startOffset": 164, "endOffset": 167}, {"referenceID": 6, "context": "Evolutionary algorithms, particularly genetic algorithms, have been used widely for MOO problems, including success in path planning [7], [9].", "startOffset": 133, "endOffset": 136}, {"referenceID": 8, "context": "Evolutionary algorithms, particularly genetic algorithms, have been used widely for MOO problems, including success in path planning [7], [9].", "startOffset": 138, "endOffset": 141}, {"referenceID": 9, "context": "Drawing on evolutionary computation techniques in a previous study, Lavin [10] defined an A* alternative specifically designed for MOO path planning.", "startOffset": 74, "endOffset": 78}, {"referenceID": 0, "context": "Typically the robot\u2019s world is represented by either an occupancy grid, a vertex graph, or a Voronoi diagram [1].", "startOffset": 109, "endOffset": 112}, {"referenceID": 3, "context": "Specifically best-first search, which traverses a graph or grid using a priority queue to find the shortest, collision-free path [4].", "startOffset": 129, "endOffset": 132}, {"referenceID": 10, "context": "A priority queue, or open list, is used to focus the search and order cost updates efficiently [11].", "startOffset": 95, "endOffset": 99}, {"referenceID": 11, "context": "The incorporation of the heuristic into the path cost makes the search algorithm more efficient because the search is focused in the direction of the robot, reducing the total number of state expansions [12].", "startOffset": 203, "endOffset": 207}, {"referenceID": 12, "context": "The search algorithm, looking for the cheapest path, tries (expands) the node with the lowest f n [13], [14].", "startOffset": 98, "endOffset": 102}, {"referenceID": 13, "context": "The search algorithm, looking for the cheapest path, tries (expands) the node with the lowest f n [13], [14].", "startOffset": 104, "endOffset": 108}, {"referenceID": 14, "context": "To determine the optimal sequence of waypoints, the A* algorithm is a favorite for route search problems [15], [16], guaranteeing optimal solution paths [13].", "startOffset": 105, "endOffset": 109}, {"referenceID": 15, "context": "To determine the optimal sequence of waypoints, the A* algorithm is a favorite for route search problems [15], [16], guaranteeing optimal solution paths [13].", "startOffset": 111, "endOffset": 115}, {"referenceID": 12, "context": "To determine the optimal sequence of waypoints, the A* algorithm is a favorite for route search problems [15], [16], guaranteeing optimal solution paths [13].", "startOffset": 153, "endOffset": 157}, {"referenceID": 12, "context": "Norvig and Russel [13] explain how A* is optimally efficient: no other optimal algorithm is guaranteed to expand fewer nodes than A*.", "startOffset": 18, "endOffset": 22}, {"referenceID": 9, "context": "The A*-PO algorithm defined by Lavin [10] builds off this optimality guarantee to offer an algorithm yielding Pareto optimal solution paths, specifically for problems of multiple path costs.", "startOffset": 37, "endOffset": 41}, {"referenceID": 12, "context": "The deliberative, or global, level considers the entire world, likely requiring computation time proportional to the problem size [13].", "startOffset": 130, "endOffset": 134}, {"referenceID": 5, "context": "High-level block diagram of the standard hybrid control system architecture for mobile robots [6].", "startOffset": 94, "endOffset": 97}, {"referenceID": 16, "context": "Previous studies [17], [18] have modified A* for fast planning.", "startOffset": 17, "endOffset": 21}, {"referenceID": 17, "context": "Previous studies [17], [18] have modified A* for fast planning.", "startOffset": 23, "endOffset": 27}, {"referenceID": 3, "context": "The D* algorithm is a dynamic version of A*, built to be capable of fast rerouting when the robot encounters new obstacles in the environment [4].", "startOffset": 142, "endOffset": 145}, {"referenceID": 10, "context": "D* has been shown to be up to two orders of magnitude more efficient than planning from scratch with A* [11].", "startOffset": 104, "endOffset": 108}, {"referenceID": 5, "context": "The speed of these searching algorithms is increased dramatically, but at the cost of sub-optimal solution paths [6].", "startOffset": 113, "endOffset": 116}, {"referenceID": 18, "context": "Illustration of the Pareto front in two-dimensional objective space for (a) continuous and infinite, and (b) discrete and finite problems [20].", "startOffset": 138, "endOffset": 142}, {"referenceID": 18, "context": "Pareto optimality is a crucial concept for finding solutions to MOO problems because identifying a single solution that simultaneously optimizes across several objectives is a nontrivial task [20].", "startOffset": 192, "endOffset": 196}, {"referenceID": 19, "context": "The non-dominated paths are favored in the population, and this increases generation over generation [21].", "startOffset": 101, "endOffset": 105}, {"referenceID": 11, "context": "The original D* paper by Stentz [12] explains D* extensively, including the algorithm\u2019s pseudocode, and is not repeated here.", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": "The solar vector is defined to rotate counterclockwise one radian for every path step, initially set at [1,0].", "startOffset": 104, "endOffset": 109}, {"referenceID": 20, "context": "Layered bedrock northwest of the Hellas Region of Mars [23].", "startOffset": 55, "endOffset": 59}, {"referenceID": 20, "context": "Future implementations of D*-PO (and A*-PO) may opt for state lattice representation: a discretized set of all reachable configurations of a system [23].", "startOffset": 148, "endOffset": 152}, {"referenceID": 21, "context": "Additionally the next implementation may use Pareto fronts in D* Lite which has been found to be slightly more efficient for some navigation tasks and easier to analyze [24].", "startOffset": 169, "endOffset": 173}, {"referenceID": 11, "context": "D* is a very general algorithm and can be applied to problems in artificial intelligence other than robot motion planning, essentially any path cost optimization problem where the cost parameters change during the traverse of the solution [12].", "startOffset": 239, "endOffset": 243}], "year": 2015, "abstractText": "Path planning is one of the most vital elements of mobile robotics, providing the agent with a collision-free route through the workspace. The global path plan can be calculated with a variety of informed search algorithms, most notably the A* search method, guaranteed to deliver a complete and optimal solution that minimizes the path cost. D* is widely used for its dynamic replanning capabilities. Path planning optimization typically looks to minimize the distance traversed from start to goal, but many mobile robot applications call for additional path planning objectives, presenting a multiobjective optimization (MOO) problem. Common search algorithms, e.g. A* and D*, are not well suited for MOO problems, yielding suboptimal results. The search algorithm presented in this paper is designed for optimal MOO path planning. The algorithm incorporates Pareto optimality into D*, and is thus named D*-PO. Non-dominated solution paths are guaranteed by calculating the Pareto front at each search step. Simulations were run to model a planetary exploration rover in a Mars environment, with five path costs. The results show the new, Pareto optimal D*-PO outperforms the traditional A* and D* algorithms for MOO path planning. Keywords\u2014multiobjective optimization; path plan; search algorithm; A*; D*; Pareto; mobile robot; Mars rover", "creator": "Word"}}}