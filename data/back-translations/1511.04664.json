{"id": "1511.04664", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Nov-2015", "title": "Deep Activity Recognition Models with Triaxial Accelerometers", "abstract": "Despite the widespread installation of accelerometers in almost all mobile phones and portable devices, activity detection with accelerometers is still immature due to the poor accuracy of existing detection methods and the scarcity of marked training data. We look at the problem of detecting human activity using triaxial accelerometers and deep learning paradigms. This paper shows that low activity detection models (a) provide better detection accuracy of human activity, (b) avoid the expensive design of handcrafted features in existing systems, and (c) utilize massive unlabeled acceleration patterns for unattended feature extraction. In addition, a hybrid approach of deep learning and hidden Markov models (DL-HMM) for sequential activity detection is presented. This hybrid approach integrates the hierarchical representations of deep activity detection models with stochastic modeling of time sequences in Markov modelling sequences.", "histories": [["v1", "Sun, 15 Nov 2015 06:23:40 GMT  (1222kb,D)", "http://arxiv.org/abs/1511.04664v1", null], ["v2", "Tue, 25 Oct 2016 07:39:29 GMT  (1232kb,D)", "http://arxiv.org/abs/1511.04664v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.HC cs.NE", "authors": ["mohammad abu alsheikh", "ahmed selim", "dusit niyato", "linda doyle", "shaowei lin", "hwee-pink tan"], "accepted": false, "id": "1511.04664"}, "pdf": {"name": "1511.04664.pdf", "metadata": {"source": "CRF", "title": "Deep Activity Recognition Models with Triaxial Accelerometers", "authors": ["Mohammad Abu Alsheikh", "Ahmed Selim", "Dusit Niyato", "Linda Doyle", "Shaowei Lin", "Hwee-Pink Tan"], "emails": [], "sections": [{"heading": null, "text": "Index Terms\u2014Activity recognition, deep learning, feature learning, accelerometers.\nI. INTRODUCTION\nHuman activity recognition has become an integral part in many modern applications such as robot learning, health monitoring and smart hospitals, pervasive gaming, and home automation. Activity recognition methods are classified into three main types of vision-based [1], radio-based [2], and sensor-based [3] methods. Vision-based methods utilize image and video processing techniques to detect human activities from visionary materials captured by various types of cameras. Wireless radio-based methods use signal attenuation, propagation, and fading characteristics to detect human activities within system\u2019s coverage area. In sensor-based methods, physical senors, e.g., accelerometers, sample time series of a performed activity. Among these three types, selecting the most suitable method depends on the intended application domain, coverage area, number of tracked users, and recognition performance. Sensor-based methods have a few advantages over the other approaches: (i) Sensor-based methods do not work under a limited coverage area, (ii) sensor-based methods use wearable sensors or smart phones which are widely available at affordable prices, and (iii) unlike radio-based methods, sensor-based methods do not expose a human body to radiating signals that may raise health concerns. These\nadvantages sparked widespread research for developing robust sensor-based recognition algorithms.\nYet, existing sensor-based activity recognition systems use shallow and conventional supervised machine learning algorithms such as multilayer perceptrons (MLPs), support vector machines, and decision trees. This reveals a gap between the recent developments of deep learning algorithms and existing sensor-based activity recognition systems. When deep learning is applied for sensor-based activity recognition, it results in many advantages in terms of system performance and flexibility. Firstly, deep learning provides an effective tool for extracting high-level feature hierarchies from highdimensional data which is useful in classification and regression tasks [4]. These automatically generated features eliminate the need for handcrafted features of existing activity recognition systems. Secondly, deep generative models, such as deep belief networks [5], can utilize unlabeled activity samples for model fitting in an unsupervised pre-training phase which is exceptionally important due to the scarcity of labeled activity datasets. In the contrary, unlabeled activity datasets are abundant and cheap to collect. Thirdly, deep generative models are more robust against the overfitting problem as compared to discriminative models (e.g., MLP). Specifically, Mohamed et al. [6] argued that the number of constraints imposed on a deep generative model is equal to the number of bits required to represent the input samples. On the other hand, the number of constraints of a discriminative model is smaller and only equals the number of bits required to represent the labels. Finally, training deep generative models using very large datasets is relatively fast, and the time complexity of both pre-training and fine-tuning algorithms is linear to the size of training samples [7].\nIn this paper, we present a systematic approach towards detecting human activities using deep learning and triaxial accelerometers. This paper is also motivated by the success of deep learning in acoustic modeling [6], [8], as we believe that speech and acceleration data have similar patterns of temporal fluctuations. Our approach is grounded over the automated ability of deep activity recognition models in extracting intrinsic features from acceleration data. Our extensive experiments are based on three public and community-based datasets. In summary, our main results on deep activity recognition models can be summarized as follows: \u2022 Deep versus shallow models. Our experimentation\nar X\niv :1\n51 1.\n04 66\n4v 1\n[ cs\n.L G\n] 1\n5 N\nov 2\n01 5\n2 shows that using deep activity recognition models significantly enhances the recognition accuracy compared with conventional shallow models. Equally important, deep activity recognition models automatically learn meaningful features and eliminate the need for the hand-engineering of features, e.g., statistical features [9]\u2013[13], in state-ofthe-art methods.\n\u2022 Semi-supervised learning. The scarce availability of labeled activity data motivates the exploration of semisupervised learning techniques for a better fitting of activity classifiers. Our experiments show the importance of the generative (unsupervised) training of deep activity recognition models in weight tuning and optimization. \u2022 Spectrogram analysis. Accelerometers generate multifrequency, aperiodic, and fluctuating signals which complicate the activity recognition using time series data. We show that using spectrogram signals instead of the raw acceleration data exceptionally helps the deep activity recognition models to capture variations in the input data. \u2022 Temporal Modeling. This paper presents a hybrid approach of deep learning and hidden Markov model (DL-HMM) for better recognition accuracy of temporal sequence of activities, e.g., fitness movement and car maintenance checklist. This hybrid technique integrates the hierarchical representations of deep learning with stochastic modeling of temporal sequences in HMMs. Experiments show that a DL-HMM outperforms HMMbased methods for temporal activity recognition. Specifically, the learned representation of deep activity recognition models is shown to be effective in estimating the posterior probabilities of HMMs. Unlike Gaussian mixture models which provide an alternative method, deep neural networks do not impose restrict assumptions on the input data distribution [6].\nThe rest of this paper is organized as follows. Section II reviews related work on activity recognition algorithms. Section III discusses the problem formulation and data framing of accelerometer time series. In Section IV, the deep learning model for human activity recognition is described in details. Real world datasets and a summarized comparison with baseline methods are described in Section V. Then, experimental validation using real world datasets is presented in Section VI. Finally, the paper is concluded in Section VII, and future research directions are also highlighted."}, {"heading": "II. RELATED WORK", "text": "In this section, we will focus on classification and feature engineering methods for activity recognition using accelerometers. For a more comprehensive review of the field, we refer interested readers to recent survey papers by Lara et al. [14] and Chen et al. [3]. To clarify the limitations of existing sensor-based activity recognition methods, Section II-A firstly discusses the limitations of conventional shallow classification methods. Then, the limitations of using traditional handcrafted features in activity recognition systems are presented in Section II-B."}, {"heading": "A. Limitations of Shallow Classifiers", "text": "Machine learning algorithms have been used for a wide range of activity recognition applications [9], [11], [15], [16], allowing the mapping between feature sets and various human activities. The classification of accelerometer samples into static and dynamic activities using MLPs is presented in [16]. Conventional neural networks, including MLPs, often stuck in local optima [17] which often leads to poor performance of activity recognition systems. Moreover, training MLPs using backpropagation [17] only hinders the addition of many hidden layers due to the vanishing gradient problem. The authors in [15] used decision trees and MLPs to classify daily human activities. In [10], a fuzzy inference system is designed to detect human activities. Altun et al. [9] analyzed the activity recognition using Bayesian decision theory, least-squares, knearest neighbors (k-NNs), dynamic time warping, support vector machines, and MLPs. Similarly, Kwapisz et al. [11] compared the recognition accuracy of decision tree (C4.5), logistic regression, and MLPs, where MLPs are found to outperform the other methods.\nIn this paper, we show significant recognition accuracy improvement on real world datasets over state-of-the-art methods for human activity recognition using triaxial accelerometers. Additionally, even though some previous works have purportedly reported promising results of activity recognition accuracy, they still require a degree of handcrafted features as discussed below."}, {"heading": "B. Limitations of Handcrafted Features", "text": "Handcrafted features are widely utilized in existing activity recognition systems for generating distinctive features that are fed to classifiers. The authors in [9]\u2013[13] utilized statistical features, e.g., mean, variance, kurtosis and entropy, as distinctive representation features. On the negative side, statistical features are problem-specific, and they poorly generalize to other problem domains. In [18], the signs of raw signal (positive, negative, or null) are used as distinctive features. Despite its simple design, these sign features are plain and cannot represent complex underlying activities which increase the number of required accelerometer nodes. The authors in [19] used the energy and frequency bands in detecting the freezing events of Parkinson\u2019s disease patients. Generally speaking, any handcrafted-based approach involves laborious human intervention for selecting the most effective features and decision thresholds from sensory data.\nQuite the contrary, data-driven approaches, e.g., using deep learning, can learn discriminative features from historical data which is both systematic and automatic. Therefore, deep learning can play a key role in developing self-configurable framework for human activity recognition. The author in [20] discussed the utilization of a few feature learning methods, including deep learning, in activity recognition systems. Nonetheless, this prior work is elementary in its use of deep learning methods, and it does not provide any analysis of the deep network construction (e.g., setup of layers and neurons). Moreover, our probabilistic framework supports temporal sequence modeling of activities by producing the activity\n3 membership probabilities as the emission matrix of an HMM. This is a considerable advantage for temporally modeling human actions that consist of a sequence of ordered activities, e.g., fitness movement and car maintenance checklist.\nTo overcome the limitations of state-of-the-art methods, this paper proposes a framework for human activity recognition which learns high level features from unlabeled acceleration data. Unlike the training of conventional neural networks using backpropagation [17], a pre-training step enables the deep activity recognition model to utilize the massive unlabeled acceleration samples in data structure exploration, and hence generating more accurate classifiers is achieved. The pretraining step is considered as a regularization that helps in minimizing the model overfitting to training data [21]. Then, the fine-tuning step discriminatively regulates the learned intrinsic features using the available set of labeled data. This semi-supervised learning minimizes the human intervention for designing handcrafted features with the expensive trial and error process."}, {"heading": "III. PROBLEM STATEMENT", "text": "This section gives a formal description of the activity recognition problem using accelerometer sensors."}, {"heading": "A. Activity Recognition using Triaxial Accelerometers", "text": "Accelerometers are key sensors in many modern inertial systems, e.g., navigation, early warning, aerospace, and activity recognition systems. Accelerometers are sensors that measure proper acceleration of an object due to motion and gravitational force. Modern accelerometers are tiny devices that consist of electromechanically sensitive elements and generate electrical signal in response to any mechanical motion. The proper acceleration is distinctive from coordinate acceleration in classical mechanics. The latter measures the rate of change of velocity while the former measures acceleration relative to a free fall, i.e., the proper acceleration of an object in a free fall is zero. In this section, we introduce the problem of human activity recognition using triaxial accelerometers. Triaxial accelerometers measure proper acceleration in three perpendicular directions. In what follows, we address the mapping between proper acceleration readings and the corresponding human activities.\nData acquisition. Consider an accelerometer sensor that is attached to a human body and takes samples (at time index t ) of the form\nrt = r \u2217 t + wt, t = 1, 2, . . . (1) where rt = [ rxt r y t r z t ]T is a 3D accelerometer data point generated at time t and composed of rxt , r y t , and r z t which are the x-acceleration, y-acceleration, and z-acceleration components, respectively. The proper acceleration in each axis channel is a floating-point value that is bounded to some known constant B > 0 such that |rxt | \u2264 B, |r y t | \u2264 B, and |rzt | \u2264 B. For example, an accelerometer with B = 2g units indicates that it can record proper acceleration up to twice the gravitational acceleration (recall that 1g ' 9.8 metersecond2 ). Clearly, an accelerometer that is placed on a flat surface\nrecord a vertical acceleration value of \u00b11g upward. r\u2217t \u2208 R3 is a vector that contains 3-axial noiseless acceleration readings. wt \u2208 R3 is a noise vector of independent, zeromean Gaussian random variables with variance \u03c32w such that wt v N (0, \u03c32wI3). Examples of added noise during signal acquisition include the effect of temperature drifts and electromagnetic fields on electrical accelerometers [22].\nTime-series segmentation. The aim of any activity recognition algorithm is the mapping of raw input data to the most probable human activity. However, time series of accelerometer readings are highly fluctuating over time which prevents detecting human activities using single data point in time [14], i.e., a human activity cannot be detected using a single reading rt. Instead, finite length sequences of proper acceleration readings should be collected at regular intervals over time. Firstly, three channel frames sxt , s y t , and s z t \u2208 RN are formed to contain the x-acceleration, y-acceleration, and z-acceleration components, respectively. Particularly, these channel frames are created using a sliding window as follows:\nsxt = [ r x t \u00b7 \u00b7 \u00b7 rxt+N\u22121 ]T , (2) sxt = [ r y t \u00b7 \u00b7 \u00b7 r y t+N\u22121 ] T , (3) szt = [ r z t \u00b7 \u00b7 \u00b7 rzt+N\u22121 ]T . (4)\nThe sequence size N should be carefully selected such as to ensure an adequate and efficient activity recognition. We assume that the system supports M different activities. Specifically, let A = {a1, a2, . . . , aM} be a finite activity space. Based the windowed excerpts sxt , s x t , and s z t , the activity recognition method infers the occurrence of an activity yt \u2208 A. To this end, it is important to note that performance-sensitive systems, e.g., healthcare systems [19] and quality control checkpoints [18], may utilize more than one accelerometer sensors to detect complex and correlated activities with high recognition accuracy. In this case, each accelerometer data is formed as in (2), (3), and (4), then the classification is performed over concatenated data from all accelerometers in parallel."}, {"heading": "B. Data Preprocessing", "text": "The problem of activity recognition using sxt , s x t , and s z t can be framed within the discipline of time-series classification and forecasting which generally requires finding a parametric representation of the time domain data. In particular, an accelerometer generates non-stationary signal where the frequency content of the each axis acceleration signal changes over time. These multi-frequency, aperiodic, and fluctuating signals complicate the activity recognition using time series data. Therefore, a data preparation step is applied to effectively capture a parametric representation of the accelerometer signal with lower information rate. A spectrogram of an accelerometer signal is a three dimensional representation of changes in the energy acceleration content of a signal as a function of frequency and time. Historically, spectrograms of speech waveforms are widely used as distinguishable features in acoustic modeling (e.g., the mel-frequency cepstral [23]). In this paper, we use the spectrogram representation as the\n4 input of deep activity recognition models as it introduces the following advantages:\n1) Classification accuracy. The spectrogram representation provides interpretable features in capturing the intensity differences among nearest acceleration data points. This enables the classification of activities based on the variations of spectral density which reduce the classification complexity. 2) Computational complexity. After applying the spectrogram on sxt , s x t , and s z t , the length of the spectral signal\nis L = 3(N2 + 1) while the time domain signal length is 3N . This significantly reduces the computational burdens of any classification method due to the lower data dimensionality.\nHenceforth, the spectrogram signal of the triaxial accelerometer is denoted as xt \u2208 RL, where L = 3(N2 + 1) is the concatenated spectrogram signals from the triaxial input data."}, {"heading": "IV. DEEP LEARNING FOR ACTIVITY RECOGNITION: SYSTEM AND MODEL", "text": "This section presents our approach for human activity recognition form triaxial accelerometer data. Our deep model learns not only the classifier\u2019s weights used to recognize different activities, but also the informative features for recognizing these activities from raw data. This provides a competitive advantage over traditional systems that are hand-engineered. The model fitting and training consist of two main stages: (i) An unsupervised, generative, and pre-training step, and (ii) a supervised, discriminative, and fine-tuning step. The pretraining step generates intrinsic features based on a layer-bylayer training approach using unlabeled acceleration samples only. Firstly, we use deep belief networks [5] to find the activity membership probabilities as described in Section IV-A. In Section IV-B, we show how to utilize the activity membership probabilities generated by deep models to model the temporal correlation of sequential activities.\nFigure 1 shows the working flow of the proposed activity recognition system. We implement deep activity recognition models based on deep belief networks (BBNs). DBNs are generative models composed of multiple layers of hidden units. In [5], the hidden units are formed from restricted Boltzmann machines (RBMs) which are trained in a layerby-layer fashion. Notably, an alternative approach is based on using stacked auto-encoders [24]. An RBM is a bipartite graph that is restricted in that no weight connections exist between hidden units. This restriction facilitates the model fitting as the hidden units become conditional independent for a given input vector. After the unsupervised pre-training, the learned weights are fine-tuned in an up-down manner using available data labels. A practical tutorial on the training of RBMs is presented in [25]."}, {"heading": "A. Deep Activity Recognition Models", "text": "DBNs [5] can be trained on greedy layer-wise training of RBMs as shown in Figure 2. In our model, the acceleration spectrogram signals x are continuous and are fed to a deep activity recognition model. As a result, the first layer of the\nData acquisition\n.\n.\n.\nW al\nki n\ng\nW at\nch in\ng TV\nEa ti\nn g ... Supported activities\nOne-sided spectrum\nTriaxial accelerometer\nLearning deep generative model\nSpectrogram\nTime-series segmentation\nEmission matrix\nGaussianbinary RBM\nBinarybinary RBM\nClass membership probability\n.\n.\n.\n.\n.\n.\nSoftmax regression\nTemporal modeling\nOptional stepTime\nHMM...\n... 1x 2x Tx\n...\ntx\n)|( 12 yyP\n)|(x 11 yP )|(x TT yP\n )x|(max 1 ti Mi t aPy  \n1y 2y Tyty\nFigure 1. Activity recognition using deep activity recognition model. Our system automatically (1) takes triaxial acceleration time series, (2) extracts the spectrogram of windowed excerpts, (3) computes intrinsic features using a deep generate model, and then (4) recognizes the underlying human activities by finding the posterior probability distribution {P (ai|xt)}Mi=1. This deep architecture outperforms existing methods for human activity recognition using accelerometers as shown by the experimental analysis on real world datasets in Section VI. Furthermore, an optional step involves using the emission probabilities out of the deep model to train a hidden Markov model (HMM) for modeling temporal patterns in activities.\nBRBM\nBRBM\nBRBM\nGRBMGRBMGRBM\n1h\nx\n1h 1h\n2h 2h\n3h\nConcatenated triaxial acceleration data x x\nHidden code\n1 W 1W 1W\n2 W 2 W\n3 W\nHigh-level code\nFigure 2. The greedy layer-wise training of DBNs. The first level is trained on triaxial acceleration data. Then, more RBMs are repeatedly stacked to form a deep activity recognition model until forming a high-level representation.\ndeep model is selected as a Gaussian-binary RBM (GRBM) which can model the energy content in the continuous accelerometer data. Afterward, the subsequent layers are binarybinary RBMs (BRBMs). RBMs are energy-based probabilistic models which are trained using stochastic gradient descent on the negative log-likelihood of the training data. For the GRBM layer, the energy of an observed vector v = x and a hidden code h is denoted as follows:\nE (v = x,h) = 1 2 (v \u2212 b)> (v \u2212 b)\u2212 c>h\u2212 v>Wh (5)\nwhere W is the weight matrix connecting the input and hidden layers, b and c are the visible and hidden unit biases, respectively. For a BRBM, the energy function is defined as follows:\nE (v,h) = \u2212b>v \u2212 c>h\u2212 v>Wh. (6)\n5 The probability of any joint configuration (v,h) is given as\nP (v,h) = e\u2212E(v,h)\u2211 v,h e \u2212E(v,h) (7)\nwhere the denominator is known as the partitioning function. An RBM can be trained using the contrastive divergence approximation [26] as follows:\n4Wij = \u03b1 ( \u3008vihj\u3009data \u2212 \u3008vihj\u30091 ) (8)\nwhere \u03b1 is a learning rate. \u3008vihj\u3009data is the expectation of reconstruction over the data, and \u3008vihj\u30091is the expectation of reconstruction over the model using one step of the Gibbs sampler. Please refer to [5], [25] for further details on the training of DBNs. For simplicity, we denote the weights and biases of a DBN model as \u03b8 which can be used to find the posterior probabilities P (ai|xt, \u03b8) for each joint configuration (ai,xt).\nTo this end, the underlying activity yt can be predicted at time t using the softmax regression as follows:\nyt = arg max 1\u2264i\u2264M\n{P (ai|xt, \u03b8)} . (9)\nAlternatively, the temporal patterns in a sequence of activities can be further analyzed using HMMs. The following section establishes the probabilistic connection between the input data xt and activity prediction yt over a sequence of observations 1 \u2264 t \u2264 T ."}, {"heading": "B. Temporal Activity Recognition Models (DL-HMM)", "text": "In some activity recognition applications, there is a temporal pattern in executed human activities (e.g., car checkpoint [18]). Hidden Markov models (HMMs) [27] are a type of graphical models that can simulate the temporal generation of a first-order Markov process. The temporal activity recognition problem includes finding the most probable sequence of (hidden) activities y1, . . . , yT that produce an (observed) sequence of input x1, . . . ,xT . An HMM model \u03a6 is represented as a 3-tuple \u03a6 = (\u03c0, \u03c8,\u03a5) where \u03c0 = (P (y1 = ai) : i = 1, . . . ,M) is the prior probabilities of all activities in the first hidden state, \u03c8 = (P (yt = ai|yt\u22121 = aj) : i, j = 1, . . . ,M) is the transition probabilities, and \u03a5 = (P (xt|yt = ai) : i = 1, . . . ,M and t = 1, . . . , T ) is the emission matrix for observables xt from hidden symbols ai. Given a sequence of observations, the emission probabilities is found using a deep model. In particular, the joint probabilities P (yt,xt) of each joint configuration (yt,xt) in an HMM is found as follows:\nP (yt,xt) = P (y1)P (x1|y1) T\u220f\ni=2\nP (yi|yi\u22121)P (xi|yi) ,(10)\n= P (yt\u22121,xt\u22121)P (yt|yt\u22121)P (xt|yt) , (11)\nHerein, (11) shows that an HMM infers the posterior distribution P (yt|xt) as a recursive process. This decoding problem is solved for the most probable path of sequential activities."}, {"heading": "C. Computational complexity", "text": "Our algorithm consists of three working phases: (a) data gathering, (b) offline learning, and (c) online activity recognition and inference. The computational burden of the offline learning is relatively heavy to be run on a mobile device as it based on stochastic gradient descent optimization. Therefore, it is recommended to run the offline training of a deep activity recognition model on a capable server. Nonetheless, after the offline training is completed, the model parameter \u03b8 is only disseminated to the wearable device where the online activity recognition is lightweight with a linear time complexity (O (T )), where T is the temporal sequence length. Here, the time complexity of the online activity recognition system represents the time needed to recognize the activity as a function of the accelerometer input length. The time complexity of finding the short-time Fourier transform (STFT) is O (L log (L)). Finally, the time complexity of the HMM decoding problem is O ( M2 \u00d7 T ) ."}, {"heading": "V. BASELINES AND RESULT SUMMARY", "text": "We test our activity recognition approach on three datasets. The experimental analysis shows the improvement on recognition accuracy over state-of-the-art methods."}, {"heading": "A. Datasets", "text": "For empirical comparison with existing approaches, we use three public datasets that represent different application domains to verify the efficiency of our proposed solution. These three testbeds are described as follows:\n\u2022 WISDM Actitracker dataset [11]: This dataset contains 1, 098, 213 samples of one triaxial accelerometer that is programmed to sample at a rate of 20 Hz. The data samples belong to 29 users and 6 distinctive human activities of walking, jogging, sitting, standing, and climbing stairs. The acceleration samples are collected using mobile phones with Android operating system. \u2022 Daphnet freezing of gait dataset [19]: We used this dataset to demonstrate the healthcare applications of deep activity recognition models. The data samples are collected from patients with the Parkinson\u2019s disease. Three triaxial accelerometers are fixed at patient\u2019s ankle, upper leg, and trunk with a sampling frequency of 64 Hz. The objective is to detect freezing events of patients. The dataset contains 1, 140, 835 experimentation samples from 10 users. The samples are labeled with either \u201cfreezing\u201d or \u201cno freezing\u201d classes. \u2022 Skoda checkpoint dataset [18]: The 10 distinctive activities of this dataset belong to a car maintenance scenario in typical quality control checkpoints. The sampling rate is 98 Hz. Even though the dataset contains 20 nodes of triaxial accelerometers, it would be inconvenient and costly to fix 20 nodes to employee hands which can hinder the maintenance work. Therefore, we use one accelerometer node (ID # 16) for the experimental validation of deep models."}, {"heading": "B. Performance Measures", "text": "For binary classification (experimentation on the Daphnet dataset), we use three performance metrics: Sensitivity (TPR) = TPTP+FN , specificity (TNR) = TN TN+FP , and accuracy (ACC) = TP+TNTP+TN+FP+FN where TP, TN, FP, and FN mean true positive, true negative, false positive, and false negative, respectively. For multiclass classification of non-overlapping activities, which are based on the experimentation of the WISDM Actitracker and Skoda checkpoint datasets, the average recognition accuracy (ACC) is found as ACC = 1M \u2211M i=1 TPi+TNi TPi+TNi+FPi+FNi\n, where M is the number of supported activities."}, {"heading": "C. Baselines", "text": "Table I summarizes the main performance results of our proposed method and some previous solutions on using the three datasets. Deep activity recondition models introduce significant accuracy improvement over conventional methods. For example, it improves accuracy by 6.53% over MLPs and 3.93% over ensemble learning on the WISDM Actitracker dataset. Similarly, significant improvements are also reported for the Daphnet freezing of gait and Skoda checkpoint datasets. This summarized result shows that the deep models are both (a) effective in improving recognition accuracy over stateof-the-art methods, and (b) practical for avoiding the handengineering of features."}, {"heading": "VI. EXPERIMENTS ON REAL DATASETS", "text": "We present our experimental validation in three stages. Firstly, Section VI-A gives spectrogram analysis of real world datasets. Then, the performance analysis of deep activity recognition models is given in Section VI-B. Finally, a test case of temporal modeling using a DL-HMM is introduced in Section VI-C."}, {"heading": "A. Spectrogram Analysis", "text": "Figure 3 shows triaxial time series and spectrogram signals of 6 activities of the WISDM Actitracker dataset. Clearly, the high frequency signals (a.k.a. AC components) belong to activities with active body motion, e.g., jogging and walking. On the other hand, the low frequency signals (a.k.a. DC components) are collected during semi-static body motions, e.g., sitting and standing. Thereby, these low frequency activities are only distinguishable by the accelerometer measurement of the gravitational acceleration.\nFigure 4 shows the two-sided power spectral density (PSD) of acceleration data. The power content is concentrated at low spectral bands, e.g., below 30 Hz, and symmetrical around DC. Therefore, the negative spectral information is redundant and is not fed to the deep activity recognition model."}, {"heading": "B. Performance Analysis", "text": "In this section, we numerically examine the performance of the deep activity recognition models on real world datasets. The recognition accuracy is mainly examined on different setups of hidden layers and segmentation lengths. The main\nresults show that (a) deep activity recognition models are more competent than shallow models, and (b) overcomplete representations are required to optimize deep activity recognition models.\nIn our experiments, the data is firstly centered to the mean and scaled to a unit variance. The deep activity recognition models are trained using stochastic gradient decent with minibatch size of 75. For the first GBRM layer, the pre-training learning rate is set to 0.001 with pre-training epochs of 150. For next BRBM layers, the number of pre-training epochs is fixed to 75 with pre-training learning rate of 0.01. The fine-tuning learning rate is 0.1 and the number of fine-tuning epochs is 1000. For interested technical readers, Hinton [25] provides a tutorial on training RBMs with many practical advices on parameter setting and tuning.\n7 Table I COMPARISON OF OUR PROPOSED SOLUTION AGAINST EXISTING METHODS IN TERMS OF RECOGNITION ACCURACY. C4.5 IS A DECISION TREE\nGENERATION METHOD.\n1) Deep Model Structure: Figure 5 shows the recognition accuracy on different DBN structures (joint configurations of number of layers and number of neurons per layer). Two important results are summarized as follows:\n1) Deep models outperforms shallow ones. Clearly, the general trend in the recognition accuracy is that using more layers will enhance the recognition accuracy. For example, using 4 layers of 500 neurons at each layer is better than 2 layers of 1000 neurons at each layer, which is better than 1 layer of 2000 neurons. 2) Overcomplete representations are advantageous. An overcompete representation is achieved when the number of neurons at each layer is larger than the input length. An overcompete representation is essential for learning deep models with many hidden layers (e.g., deep model of 2000 neurons per layer). On the other hand, it is noted that a deep model will be hard to optimized when using undercomplete representations (e.g., 5 layers of 200 neurons at each layer). This harder optimization issue is distinguishable from the overfitting problem as the training data accuracy is also degrading by adding more layers (i.e., an overfitted model is diagnosed when the recognition accuracy on training data is enhancing by adding more layer while getting poorer accuracy on testing data). Therefore, we recommend 4x overcomplete deep activity recognition models (i.e., the number of neurons at each layer is four times the input size).\nEXPRIEMENT # OF LAYERS ACCURACY (%)\nGenerative & discriminative training\n1 96.87 3 97.75 5 97.85\nDiscriminative training only\n1 96.87 3 96.46 5 96.51\n2) Data Segmentation: An obvious question to ask is whether the window length during data segmentation affects the activity recognition. Figure 6 shows the recognition accuracy of deep activity recognition models on different window lengths. The general trend is that using longer windows results in better recognition accuracy. However, there is a tradeoff between the recognition accuracy and recognition delay. Generally speaking, a 10-second window seems to be a valid configuration in many applications as it provides a good recognition accuracy with tolerable delay. Moreover, the window length should be small enough to be fully contained within one activity duration.\nA second important result that should be incorporated from Figure 6 is the overfitting problem when using 4 layers of 1000 neurons with the 2-second windowing. At this point, the recognition accuracy on training data decreases while it increases on the testing data.\n3) Pre-training Effects: Table II shows the recognition accuracy with and without the pre-training phase. These results confirm the importance of the generative pre-training phase of deep activity recognition models. Specifically, a generative pre-training of a deep model guides the discriminative training to better generalization solutions [21]. Clearly, the generative pre-training is almost ineffective for 1-layer networks. However, using the generative pre-training becomes more essential for the recognition accuracy of deeper activity recognition models, e.g., 5 layers.\n8 2 4 6 8 10 Activity index 2 4 6 8 10 A ct iv it y i n d e x (a) Transition matrix\n0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n2 4 6 8 10 Activity index\n(b) Prior probabilities\n0.05 0.06 0.07 0.08 0.09 0.10 0.11 0.12 0.13\nFigure 7. Transition and prior probabilities of sequential activities. (a) The transition matrix \u03c8 \u2208 RN\u00d7N that represents the probabilities of moving among activities. (b) The prior belief \u03c0 \u2208 RN that stores the initial probabilities of different activities. These parameters are extracted from the Skoda checkpoint dataset (node ID 16)."}, {"heading": "C. Temporal Modeling", "text": "We used a deep activity recognition model with 3 layers of 1000 neurons each. The recognition accuracy is 89.38% for the 10 activities on the Skoda checkpoint dataset (node ID 16), improving 3.38% over the HMM method presented by Zappi et al. [18]. Furthermore, the results can be significantly enhanced by exploring the temporal correlation in the dataset. Our hybrid DL-HMM achieves near perfect recognition accuracy of 99.13%. In particular, Figure 7 shows the parameters of a HMM model that is used to model the temporal sequences of the Skoda checkpoint dataset. Here, the checkpoint task follows a specific activity sequence."}, {"heading": "VII. CONCLUSIONS AND FUTURE WORK", "text": "We investigated the problem of activity recognition using triaxial accelerometers. The proposed approach is superior to traditional methods of using shallow networks with handcrafted features by using deep activity recognition models. The deep activity recognition models produce significant improvement to the recognition accuracy by extracting hierarchical features from triaxial acceleration data. Moreover, the recognition probabilities of deep activity recognition models are utilized as an emission matrix of a hidden Markov model to temporally model a sequence of human activities.\nEven though this paper focus on the activity recognition using triaxial accelerometers, it would be applicable for other types of sensors, e.g., using gyroscopes and accelerometers simultaneously. Specifically, using many types of sensors generates multimodal data which might be useful in accuracysensitive applications with complex activity set."}], "references": [{"title": "A survey on vision-based human action recognition", "author": ["R. Poppe"], "venue": "Image and vision computing, vol. 28, no. 6, pp. 976\u2013990, 2010.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "A review on radio based activity recognition", "author": ["S. Wang", "G. Zhou"], "venue": "Digital Communications and Networks, vol. 1, no. 1, pp. 20\u201329, 2015.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Sensorbased activity recognition", "author": ["L. Chen", "J. Hoey", "C.D. Nugent", "D.J. Cook", "Z. Yu"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews, vol. 42, no. 6, pp. 790\u2013 808, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning deep generative models", "author": ["R. Salakhutdinov"], "venue": "Annual Review of Statistics and Its Application, vol. 2, no. 1, pp. 361\u2013385, 2015.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Y.-W. Teh"], "venue": "Neural computation, vol. 18, no. 7, pp. 1527\u20131554, 2006.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Acoustic modeling using deep belief networks", "author": ["A.-R. Mohamed", "G.E. Dahl", "G. Hinton"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 1, pp. 14\u201322, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["G.E. Hinton", "R.R. Salakhutdinov"], "venue": "Science, vol. 313, no. 5786, pp. 504\u2013507, 2006.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Context-dependent pretrained deep neural networks for large-vocabulary speech recognition", "author": ["G.E. Dahl", "D. Yu", "L. Deng", "A. Acero"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 1, pp. 30\u201342, 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Human activity recognition using inertial/magnetic sensor units", "author": ["K. Altun", "B. Barshan"], "venue": "Human Behavior Understanding. Springer, 2010, pp. 38\u201351.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "ActiServ: Activity recognition service for mobile phones", "author": ["M. Berchtold", "M. Budde", "D. Gordon", "H.R. Schmidtke", "M. Beigl"], "venue": "Proceedings of the International Symposium on Wearable Computers. IEEE, 2010, pp. 1\u20138.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Activity recognition using cell phone accelerometers", "author": ["J.R. Kwapisz", "G.M. Weiss", "S.A. Moore"], "venue": "ACM SigKDD Explorations Newsletter, vol. 12, no. 2, pp. 74\u201382, 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Robust human activity and sensor location corecognition via sparse signal representation", "author": ["W. Xu", "M. Zhang", "A.A. Sawchuk", "M. Sarrafzadeh"], "venue": "IEEE Transactions on Biomedical Engineering, vol. 59, no. 11, pp. 3169\u20133176, 2012.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "On the use of ensemble of classifiers for accelerometer-based activity recognition", "author": ["C. Catal", "S. Tufekci", "E. Pirmit", "G. Kocabag"], "venue": "Applied Soft Computing, 2015.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "A survey on human activity recognition using wearable sensors", "author": ["O.D. Lara", "M.A. Labrador"], "venue": "IEEE Communications Surveys & Tutorials, vol. 15, no. 3, pp. 1192\u20131209, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Activity classification using realistic data from wearable sensors", "author": ["J. Parkka", "M. Ermes", "P. Korpipaa", "J. Mantyjarvi", "J. Peltola", "I. Korhonen"], "venue": "IEEE Transactions on Information Technology in Biomedicine, vol. 10, no. 1, pp. 119\u2013128, 2006.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "A triaxial accelerometer-based physical-activity recognition via augmented-signal features and a hierarchical recognizer", "author": ["A.M. Khan", "Y.-K. Lee", "S.Y. Lee", "T.-S. Kim"], "venue": "IEEE Transactions on Information Technology in Biomedicine, vol. 14, no. 5, pp. 1166\u20131172, 2010.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning representations by back-propagating errors", "author": ["D.E. Rumelhart", "G.E. Hinton", "R.J. Williams"], "venue": "Nature, vol. 323, no. 6088, pp. 533\u2013536, 1986.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1986}, {"title": "Activity recognition from on-body sensors: Accuracypower trade-off by dynamic sensor selection", "author": ["P. Zappi", "C. Lombriser", "T. Stiefmeier", "E. Farella", "D. Roggen", "L. Benini", "G. Tr\u00f6ster"], "venue": "Wireless sensor networks. Springer, 2008, pp. 17\u201333.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Wearable assistant for Parkinson\u2019s disease patients with the freezing of gait symptom", "author": ["M. B\u00e4chlin", "M. Plotnik", "D. Roggen", "I. Maidan", "J.M. Hausdorff", "N. Giladi", "G. Tr\u00f6ster"], "venue": "IEEE Transactions on Information Technology in Biomedicine, vol. 14, no. 2, pp. 436\u2013446, 2010.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Feature learning for activity recognition in ubiquitous computing", "author": ["T. Pl\u00f6tz", "N.Y. Hammerla", "P. Olivier"], "venue": "IJCAI Proceedings- International Joint Conference on Artificial Intelligence, vol. 22, no. 1, 2011, p. 1729.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Why does unsupervised pre-training help deep learning?", "author": ["D. Erhan", "Y. Bengio", "A. Courville", "P.-A. Manzagol", "P. Vincent", "S. Bengio"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Two-axis temperature-insensitive accelerometer based on multicore fiber Bragg gratings", "author": ["A. Fender", "W.N. MacPherson", "R. Maier", "J.S. Barton", "D.S. George", "R.I. Howden", "G.W. Smith", "B. Jones", "S. McCulloch", "X. Chen"], "venue": "IEEE sensors journal, vol. 7, no. 8, pp. 1292\u2013 1298, 2008.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "Comparison of different implementations of MFCC", "author": ["F. Zheng", "G. Zhang", "Z. Song"], "venue": "Journal of Computer Science and Technology, vol. 16, no. 6, pp. 582\u2013589, 2001.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2001}, {"title": "Greedy layer-wise training of deep networks", "author": ["Y. Bengio", "P. Lamblin", "D. Popovici", "H. Larochelle"], "venue": "Advances in neural information processing systems, vol. 19, p. 153, 2007.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2007}, {"title": "A practical guide to training restricted Boltzmann machines", "author": ["G.E. Hinton"], "venue": "Neural Networks: Tricks of the Trade. Springer, 2012, pp. 599\u2013619.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Training products of experts by minimizing contrastive divergence", "author": ["\u2014\u2014"], "venue": "Neural computation, vol. 14, no. 8, pp. 1771\u20131800, 2002.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2002}, {"title": "An introduction to hidden markov models", "author": ["L.R. Rabiner", "B.-H. Juang"], "venue": "IEEE ASSP Magazine, vol. 3, no. 1, pp. 4\u201316, 1986.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1986}, {"title": "On preserving statistical characteristics of accelerometry data using their empirical cumulative distribution", "author": ["N.Y. Hammerla", "R. Kirkham", "P. Andras", "T. Ploetz"], "venue": "Proceedings of the International Symposium on Wearable Computers. ACM, 2013, pp. 65\u201368.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Activity recognition methods are classified into three main types of vision-based [1], radio-based [2], and sensor-based [3] methods.", "startOffset": 82, "endOffset": 85}, {"referenceID": 1, "context": "Activity recognition methods are classified into three main types of vision-based [1], radio-based [2], and sensor-based [3] methods.", "startOffset": 99, "endOffset": 102}, {"referenceID": 2, "context": "Activity recognition methods are classified into three main types of vision-based [1], radio-based [2], and sensor-based [3] methods.", "startOffset": 121, "endOffset": 124}, {"referenceID": 3, "context": "Firstly, deep learning provides an effective tool for extracting high-level feature hierarchies from highdimensional data which is useful in classification and regression tasks [4].", "startOffset": 177, "endOffset": 180}, {"referenceID": 4, "context": "Secondly, deep generative models, such as deep belief networks [5], can utilize unlabeled activity samples for model fitting in an unsupervised pre-training phase which is exceptionally important due to the scarcity of labeled activity datasets.", "startOffset": 63, "endOffset": 66}, {"referenceID": 5, "context": "[6] argued that the number of constraints imposed on a deep generative model is equal to the number of bits required to represent the input samples.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "Finally, training deep generative models using very large datasets is relatively fast, and the time complexity of both pre-training and fine-tuning algorithms is linear to the size of training samples [7].", "startOffset": 201, "endOffset": 204}, {"referenceID": 5, "context": "This paper is also motivated by the success of deep learning in acoustic modeling [6], [8], as we believe that speech and acceleration data have similar patterns of temporal fluctuations.", "startOffset": 82, "endOffset": 85}, {"referenceID": 7, "context": "This paper is also motivated by the success of deep learning in acoustic modeling [6], [8], as we believe that speech and acceleration data have similar patterns of temporal fluctuations.", "startOffset": 87, "endOffset": 90}, {"referenceID": 8, "context": ", statistical features [9]\u2013[13], in state-ofthe-art methods.", "startOffset": 23, "endOffset": 26}, {"referenceID": 12, "context": ", statistical features [9]\u2013[13], in state-ofthe-art methods.", "startOffset": 27, "endOffset": 31}, {"referenceID": 5, "context": "Unlike Gaussian mixture models which provide an alternative method, deep neural networks do not impose restrict assumptions on the input data distribution [6].", "startOffset": 155, "endOffset": 158}, {"referenceID": 13, "context": "[14] and Chen et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "Machine learning algorithms have been used for a wide range of activity recognition applications [9], [11], [15], [16], allowing the mapping between feature sets and various human activities.", "startOffset": 97, "endOffset": 100}, {"referenceID": 10, "context": "Machine learning algorithms have been used for a wide range of activity recognition applications [9], [11], [15], [16], allowing the mapping between feature sets and various human activities.", "startOffset": 102, "endOffset": 106}, {"referenceID": 14, "context": "Machine learning algorithms have been used for a wide range of activity recognition applications [9], [11], [15], [16], allowing the mapping between feature sets and various human activities.", "startOffset": 108, "endOffset": 112}, {"referenceID": 15, "context": "Machine learning algorithms have been used for a wide range of activity recognition applications [9], [11], [15], [16], allowing the mapping between feature sets and various human activities.", "startOffset": 114, "endOffset": 118}, {"referenceID": 15, "context": "The classification of accelerometer samples into static and dynamic activities using MLPs is presented in [16].", "startOffset": 106, "endOffset": 110}, {"referenceID": 16, "context": "Conventional neural networks, including MLPs, often stuck in local optima [17] which often leads to poor performance of activity recognition systems.", "startOffset": 74, "endOffset": 78}, {"referenceID": 16, "context": "Moreover, training MLPs using backpropagation [17] only hinders the addition of many hidden layers due to the vanishing gradient problem.", "startOffset": 46, "endOffset": 50}, {"referenceID": 14, "context": "The authors in [15] used decision trees and MLPs to classify daily human activities.", "startOffset": 15, "endOffset": 19}, {"referenceID": 9, "context": "In [10], a fuzzy inference system is designed to detect human activities.", "startOffset": 3, "endOffset": 7}, {"referenceID": 8, "context": "[9] analyzed the activity recognition using Bayesian decision theory, least-squares, knearest neighbors (k-NNs), dynamic time warping, support vector machines, and MLPs.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "[11] compared the recognition accuracy of decision tree (C4.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "The authors in [9]\u2013[13] utilized statistical features, e.", "startOffset": 15, "endOffset": 18}, {"referenceID": 12, "context": "The authors in [9]\u2013[13] utilized statistical features, e.", "startOffset": 19, "endOffset": 23}, {"referenceID": 17, "context": "In [18], the signs of raw signal (positive, negative, or null) are used as distinctive features.", "startOffset": 3, "endOffset": 7}, {"referenceID": 18, "context": "The authors in [19] used the energy and frequency bands in detecting the freezing events of Parkinson\u2019s disease patients.", "startOffset": 15, "endOffset": 19}, {"referenceID": 19, "context": "The author in [20] discussed the utilization of a few feature learning methods, including deep learning, in activity recognition systems.", "startOffset": 14, "endOffset": 18}, {"referenceID": 16, "context": "Unlike the training of conventional neural networks using backpropagation [17], a pre-training step enables the deep activity recognition model to utilize the massive unlabeled acceleration samples in data structure exploration, and hence generating more accurate classifiers is achieved.", "startOffset": 74, "endOffset": 78}, {"referenceID": 20, "context": "The pretraining step is considered as a regularization that helps in minimizing the model overfitting to training data [21].", "startOffset": 119, "endOffset": 123}, {"referenceID": 21, "context": "Examples of added noise during signal acquisition include the effect of temperature drifts and electromagnetic fields on electrical accelerometers [22].", "startOffset": 147, "endOffset": 151}, {"referenceID": 13, "context": "However, time series of accelerometer readings are highly fluctuating over time which prevents detecting human activities using single data point in time [14], i.", "startOffset": 154, "endOffset": 158}, {"referenceID": 18, "context": ", healthcare systems [19] and quality control checkpoints [18], may utilize more than one accelerometer sensors to detect complex and correlated activities with high recognition accuracy.", "startOffset": 21, "endOffset": 25}, {"referenceID": 17, "context": ", healthcare systems [19] and quality control checkpoints [18], may utilize more than one accelerometer sensors to detect complex and correlated activities with high recognition accuracy.", "startOffset": 58, "endOffset": 62}, {"referenceID": 22, "context": ", the mel-frequency cepstral [23]).", "startOffset": 29, "endOffset": 33}, {"referenceID": 4, "context": "Firstly, we use deep belief networks [5] to find the activity membership probabilities as described in Section IV-A.", "startOffset": 37, "endOffset": 40}, {"referenceID": 4, "context": "In [5], the hidden units are formed from restricted Boltzmann machines (RBMs) which are trained in a layerby-layer fashion.", "startOffset": 3, "endOffset": 6}, {"referenceID": 23, "context": "Notably, an alternative approach is based on using stacked auto-encoders [24].", "startOffset": 73, "endOffset": 77}, {"referenceID": 24, "context": "A practical tutorial on the training of RBMs is presented in [25].", "startOffset": 61, "endOffset": 65}, {"referenceID": 4, "context": "DBNs [5] can be trained on greedy layer-wise training of RBMs as shown in Figure 2.", "startOffset": 5, "endOffset": 8}, {"referenceID": 25, "context": "An RBM can be trained using the contrastive divergence approximation [26] as follows:", "startOffset": 69, "endOffset": 73}, {"referenceID": 4, "context": "Please refer to [5], [25] for further details on the training of DBNs.", "startOffset": 16, "endOffset": 19}, {"referenceID": 24, "context": "Please refer to [5], [25] for further details on the training of DBNs.", "startOffset": 21, "endOffset": 25}, {"referenceID": 17, "context": ", car checkpoint [18]).", "startOffset": 17, "endOffset": 21}, {"referenceID": 26, "context": "Hidden Markov models (HMMs) [27] are a type of graphical models that can simulate the temporal generation of a first-order Markov process.", "startOffset": 28, "endOffset": 32}, {"referenceID": 10, "context": "\u2022 WISDM Actitracker dataset [11]: This dataset contains 1, 098, 213 samples of one triaxial accelerometer that is programmed to sample at a rate of 20 Hz.", "startOffset": 28, "endOffset": 32}, {"referenceID": 18, "context": "\u2022 Daphnet freezing of gait dataset [19]: We used this dataset to demonstrate the healthcare applications of deep activity recognition models.", "startOffset": 35, "endOffset": 39}, {"referenceID": 17, "context": "\u2022 Skoda checkpoint dataset [18]: The 10 distinctive activities of this dataset belong to a car maintenance scenario in typical quality control checkpoints.", "startOffset": 27, "endOffset": 31}, {"referenceID": 24, "context": "For interested technical readers, Hinton [25] provides a tutorial on training RBMs with many practical advices on parameter setting and tuning.", "startOffset": 41, "endOffset": 45}, {"referenceID": 10, "context": "WISDM [11] Kwapisz et al.", "startOffset": 6, "endOffset": 10}, {"referenceID": 10, "context": "[11] C4.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] Logistic regression 78.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] MLPs 91.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] Ensemble learning 94.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "Daphnet [19] B\u00e4chlin et al.", "startOffset": 8, "endOffset": 12}, {"referenceID": 18, "context": "[19] Energy threshold on power spectral density (0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] C4.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "5 Skoda [18] Zappi et al.", "startOffset": 8, "endOffset": 12}, {"referenceID": 17, "context": "[18] HMMs Node 16 (86), nodes 20, 22 and 25 (84) Our solution Deep learning models 4 sec Node 16 (89.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "Specifically, a generative pre-training of a deep model guides the discriminative training to better generalization solutions [21].", "startOffset": 126, "endOffset": 130}, {"referenceID": 17, "context": "[18].", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "Despite the widespread installation of accelerometers in almost all mobile phones and wearable devices, activity recognition using accelerometers is still immature due to the poor recognition accuracy of existing recognition methods and the scarcity of labeled training data. We consider the problem of human activity recognition using triaxial accelerometers and deep learning paradigms. This paper shows that deep activity recognition models (a) provide better recognition accuracy of human activities, (b) avoid the expensive design of handcrafted features in existing systems, and (c) utilize the massive unlabeled acceleration samples for unsupervised feature extraction. Moreover, a hybrid approach of deep learning and hidden Markov models (DL-HMM) is presented for sequential activity recognition. This hybrid approach integrates the hierarchical representations of deep activity recognition models with the stochastic modeling of temporal sequences in the hidden Markov models. We show substantial recognition improvement on real world datasets over state-of-the-art methods of human activity recognition using triaxial accelerometers.", "creator": "LaTeX with hyperref package"}}}