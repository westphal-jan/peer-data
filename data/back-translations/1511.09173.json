{"id": "1511.09173", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Nov-2015", "title": "Recognizing Temporal Linguistic Expression Pattern of Individual with Suicide Risk on Social Media", "abstract": "Early detection of individual suicide risk plays a key role in suicide prevention. In this paper, we propose to investigate individual suicide risk based on time series analysis of personal language expression on social media (Weibo), and then use such temporal patterns as predictor variables to create classification models to assess individual suicide risk. Characteristics of time course curves on linguistic traits such as parentheses, auxiliary verbs, personal pronouns and body words are reported to have the greatest impact on the performance of suicide prevention programs, and the prediction model has an accuracy above 0.60 based on the results. This paper confirms the efficiency of social media data in detecting individual suicide risk. The results of this study could be instructive in improving the performance of suicide prevention programs.", "histories": [["v1", "Mon, 30 Nov 2015 06:15:31 GMT  (298kb)", "http://arxiv.org/abs/1511.09173v1", "16 pages, 6 figures"]], "COMMENTS": "16 pages, 6 figures", "reviews": [], "SUBJECTS": "cs.SI cs.CL", "authors": ["aiqi zhang", "ang li", "tingshao zhu"], "accepted": false, "id": "1511.09173"}, "pdf": {"name": "1511.09173.pdf", "metadata": {"source": "META", "title": "ABSTRACT", "authors": ["Aiqi Zhang", "Ang Li", "Tingshao Zhu"], "emails": ["tszhu@psych.ac.cn"], "sections": [{"heading": null, "text": "Suicide is a global public health problem. Early detection of individual suicide risk plays a key role in suicide prevention. In this paper, we propose to look into individual suicide risk through time series analysis of personal linguistic expression on social media (Weibo). We examined temporal patterns of the linguistic expression of individuals on Chinese social media (Weibo). Then, we used such temporal patterns as predictor variables to build classification models for estimating levels of individual suicide risk. Characteristics of time sequence curves to linguistic features including parentheses, auxiliary verbs, personal pronouns and body words are reported to affect performance of suicide most, and the predicting model has a accuracy higher than 0.60, shown by the results. This paper confirms the efficiency of the social media data in detecting individual suicide risk. Results of this study may be insightful for improving the performance of suicide prevention programs.\nKEYWORDS: suicidal process, blogs, Chinese, classification model, fast Fourier transformation\nINTRODUCTION Suicide is one of the leading causes of deaths worldwide. The World Health Organization (WHO) reported that, on average, a suicide occurs in every 40 seconds (World Health Organization, 2014). Furthermore, the effect of completed suicide on families and communities are often devastating (Clark & D Goldney, 2000; Jordan & McIntosh, 2011). Many suicide deaths are preventable (Bailey et al., 2011), which requires to detect individual suicide risk among populations in real-time. However, traditional methods (e.g. self-report ratings, structured interview, and clinical judgment) fail to meet the requirement of early detection (McCarthy, 2010), which suggests the need to improve existing methods.\nThe development and prevalence of social media sheds new light on this direction. Social media users are motivated to disclose themselves online, and some of them even have broadcasted their suicide thoughts and behaviors on social media sites, such as Facebook and Sina Weibo (Murano, 2014). More importantly, social media data is publicly available and can be processed in real-time. It implies that social media might be an efficient platform for detecting individual suicide risk. Because the characteristics of the language use can be indicative of personal inner process (e.g. thoughts, intentions, and motivations), conducting content analysis on personal linguistic materials (e.g. suicide notes) is recognized as an important method for understanding suicidal thoughts and behaviors (Pestian, et al, 2012; Cheung, et al, 2015). Many studies have confirmed correlations between the frequency of any words in social media posts and individual scores on suicide risk, suggesting the linguistic features of the language use can be used as valid indicators for detecting individual suicide risk on social media (McCarthy, 2010; Sueki, 2015). However, few studies focused on the temporal relationships between the changes in patterns of the language use and levels of suicide risk, which may provide insight into the track of the suicidal process on social media. Li et al (2014) used the Chinese Linguistic Inquiry and Word Count (CLIWC) program to analyze a 13-year-old boy\u2019s 193 blogs, which were posted during the year prior to his suicide death. They found that the temporal analysis method can be helpful to understand the suicidal process of completed suicides on social media. Although the temporal analysis on social media data provides an opportunity to identify those at risk of suicide, computational methods of online detection have not yet been fully established (Christensen, et al, 2014). Besides, due to the limited sample size, the performance of the temporal analysis also needs to be tested on a larger population.\nThis paper aims to examine the temporal patterns of suicidal users\u2019 language use and then use of such patterns to build classification models for differentiating people with higher and lower levels of suicide risk.\nMETHOD\nBecause Weibo (weibo.com) is the most popular Chinese micrologging service provider in China, this study was conducted on such platform. This study consists of two steps: Examining temporal patterns of the suicidal language use and Building classification models for identifying people at risk of suicide.\nExamining temporal patterns of the suicidal language use: We examined temporal patterns of the suicidal language use using a three-step procedure: (1) Collecting Weibo posts; (2) Extracting linguistic features; (3) Exporting time series data; and (4) Conducting cluster analysis on time series data.\nTo identify the unique use of language among suicidal users, we need to collect Weibo posts from individuals with different levels of suicide risk (i.e. individuals who complete suicide, individuals at high risk of suicide, and individuals at low risk of suicide), separately.\nTo find out users who complete suicide, we contacted with a user (\u901d\u8005\u5982\u65af\u592b dead), who is famous for collecting news reports about suicidal users. He advised us a list of suicidal users. We confirmed the list by both double-checking relevant news reports and looking through comments\nleft on Weibo accounts of those suggested users. Then, we did a further scrutiny of those confirmed suicidal users to exclude the following: (a) users who are not Chinese citizens; (b) users who might update Weibo posts for business purposes (e.g. movie and sports stars); (c) users who updated less than 20 posts. Finally, we got a total of 30 suicidal Weibo users (15 males and 15 females) and downloaded their Weibo posts since registration.\nTo find out users at high or low risk of suicide, we randomly selected 1,500 users from a customized Weibo database composed of 1.06 million active Weibo users (Li, et al., 2014). All 1,500 users were administrated by Suicidal Possibility Scale (SPS), which is an effective screening tool designed to assess suicide risk in adolescents and adults (Gen\u00e7\u00f6z, 2006; Naud, 2010). SPS consists of 36 self-rating items. Participants rated themselves on each item by a 4-point Likert Scale (1=None or little of the time to 4=All of the time). High scores indicate high suicide risk. The Chinese version of SPS was used in this study (Huang et al., 2012). The Cronbach\u2019s Alphas for the whole-questionnaire was ? in our data. All participants were divided into high risk and low risk group based on scores of the test (Li, et al., 2014). In this study, we randomly selected 30 users from each one group and got a total of 60 users. Then, we downloaded Weibo posts of these 60 users since registration.\nPre-processing We extracted linguistic features from collected Weibo posts using SCMBWC (Simplified Chinese Micro-blog Word Count Dictionary) and TextMind, based on the Chinese version of LIWC (CLIWC). This provides 80 psychologically meaningful language variables (e.g. emotion words) and other 22 linguistic features indicating the frequency of using different punctuation marks and words, such as the number of word-per-sentence and frequency of latin words. Finally, we got a total of 102 linguistic features (80+22). For each user, we computed feature values per day and produced a time vector (102 \u00d7 number of observation days) composed of 102 time series data. Sequences of 80 linguistic features and 11 kinds of punctuation were obtained by computing frequency of certain features using day as unit, while sequences of the other 11 features described counting of words and word-per-sentence, rates of Latin word, numbers of URLs and so on.\nAfter producing individual time vectors, we found there existed differences in the length of time vectors among different users. For example, among a total of 90 users, the maximum length of the time vector was 1844 (days) and the minimum length was 42 (days). Because some users updated\n11540*102 curves of 11540 users\n90*102 curves of 90 users\nfast Fourier transform\n11540 periods\n90 periods\nre-extract using the last period\nnew 11540*102 curves\nnew 90*102 curves\nclustering of users within each feature groups of users by feature, named 1, 2, 3\u2026\n90 curves classified into nearest groups\nmatrix of size 90*102, whose entries in the i-th column are names of groups in the i-th feature\nclassification\nDECISION TREES\nand\nPREDICTING MODELS\ntheir Weibo posts with few Chinese characters in the last 42 days of the observation period, we cannot make the length of observation uniformly by selecting the minimum length of observation. Besides, because of the different patterns of use, different users have personalized plans for updating Weibo posts. In our dataset, we found that, among different users, the time period for updating the last 100 Weibo posts ranges from 2 days to 2 years. Therefore, we also cannot conduct analysis on a certain number of latest Weibo posts for all users. To solve the problem, for each time series data, we used the algorithm of Fast Fourier Transform (FFT) to compute the Discrete Fourier Transform (DFT), which was recognized as the amplitudes of all possible frequencies. we viewed changes of values to the features by day as personally fluctuations of mental or physical state and used Fourier transformation to compute the period. A fast Fourier transform (FFT) is implemented to decompose the original time sequence as several sin curves with different frequencies. With this we take periods to the maximal amplitudes for the re-extracting of the time sequences. From each user we intercept the last period of his sequence and use 1/12 of the period as time unit. 1/12 is defined because the shortest period is 12 days. By this method we got sequences with fairly good consistency.\nBesides, to cluster and classify the 90 users into clusters, 11,540 users were chosen randomly from a specific group of Weibo users, of whom the total duration since the accounts opened was between 50 - 1800, consistent with that of the 90\u2019s. By conducting the same process to all the users, we now obtained the final (11540 + 90)*102 time sequences of length 12 for learning and predicting.\nSmoothing and Fourier transforming Missing values, referred particularly items equaling 0 in the sequences in our case, meant the user didn't post any words in a certain period of time. The missing data effects statistical inference much, since one didn\u2019t post anything online never means that there was no linguistic behavior.\nTo deal with zero values in the sequences, we applied lpint (Martingale estimating equation local polynomial estimator of counting process intensity function) in package lpint to the sequences. Take social-life words (SLW), one of the typical patterns mentioned above, as an example, we model the numbers of SLW by a doubly stochastic Poisson process N(t) with intensity process Y(t)a(t), where Y(t) counts the words of Weibo posts at time t, and a(t) denotes the SLW rate at time t. We estimated the intensity function with the local polynomial intensity estimator proposed in (Chen, Yip, and Lam 2011), and the estimator for a(t) is given by\n,\nwhere\n,\nwith the convention J(s)/Y(s) = 0 when Y(s) = 0 to protect against division by zero, and with the\nnotations introduced as follows. ei = (0, ..., 0, 1, 0, ..., 0)T is a (p+1)-dimensional unit vector with 1 as its i-th component, g(x) = (1, x, ..., xp/p!)T and Kb(\u00b7) = (1/b)K(\u00b7/b) is the scaled version of the Epanechnikov kernel where bandwidth b is decided by a data-driven selector.\nWe got an output of a smoothed vector with length longer than length of the input vector by 2. The smoothed sequence was obtained by excising the sub-sequence of the second to the last but one items. By normalizing it we got the final sequence for later processing, while the same method was implemented (11540 + 90) times, covering every user studied. (11540 + 90) smoothed and normalized sequences were obtained.\nThen we applied Fast Fourier Transformation again to the smoothed sequence to get the period properties of them. For each of the 102 features, we combined descriptive statistics (mean values and standard deviations) with fft coefficients and phase corresponding to the maximum amplitude, which are extracted from the returned values of the fft function, and got a matrix telling characteristics about the given feature.Then we had a number of rows, each represented one of the users with information of time sequence. So in all there were 204 matrices computed, 102 of them based on the 11540 random users and other 102 based on 90 observations with labels 0,1 and 2.\nK-means clustering The 102 matrices of row number 11540 were for k-means clustering in our case. For each feature, a proper value for the number of clusters k was found out by respectively calculating Silhouette coefficient while k was possibly taken value between 1 and 7. We then applied function kmeans to matrices and got 102 vectors with levels 1 to the selected number of k, each of length 11540, describing nominally which cluster the subjects were in. Correspondingly we got 102 matrices of cluster centers also.\nMatrices telling properties of sequences of observations with labels were subtracted from the centers obtained from kmeans clustering. Absolute values are calculated to show distances. We classified each user into a certain cluster, which was noted by a number. From this we got a 90*102 matrix with every column nominal scales indicating several classes of time sequences. By binding factor vector with levels 0,1 and 2 and length 90 with the 90*102 matrix we obtained a matrix with 103 columns, the last column dependent variable. On this basis, classification could be implemented and decision trees were to be drawn.\nDrawing decision trees and predicting We aimed at getting the relevant features to the labels and predicting by classifying and computing decision trees. Two method were applied to do this work: rpart (Recursive Partitioning and Regression Trees) in package rpart and train (Fit Predictive Models over Different Tuning Parameters) gbm (Generalized Boosted Regression Modeling) in package caret.\nIn the rpart method, we draw regression tree based on random 3/4 of all the 90 observations with the not chosen 1/4 used as test set, while by functions in package caret we remove variables whose variance too small and apply function rfe to the training set for feature selection before modeling, sampling as well. 3/4 random users for training and the rest 1/4 for testing.\nDifferent from the first method, we set resampling method, the number of folds and the number of complete sets of folds for cross validation and set the range of parameters needed in random forest algorithm when building boosted models. The output of the modeling were selected variables, confusion matrix out from the predicting process compared with the test set, resampling results and computed relative influence of each variable in the gbm object, generated by function summary.gbm.\nFrom the two classification model we predicted the level of any unstudied time sequence of Weibo users, corresponding to the factor vector label with levels 0, 1 and 2. Variables with the most significant influence were also obtained, by running several times and finding the most frequently appearing features in the summary part.\nRESULTS\nSince training set was random extracted, we got different models with different accuracy every time. Here is a confusion matrix of the learning process using 10-folds.\nReference\nPrediction 0 1 2\n0 2 0 1 1 0 3 1 2 1 0 1\nAccuracy : 0.6667 95% CI : (0.2993, 0.9251) No Information Rate : 0.3333 P-Value [Acc > NIR] : 0.04242 Kappa : 0.5\nFigure 1-5 are decision trees generated by rpart method, followed by confusion matrices interpreting the effect of predicting.\n----------------------------------\nConfusion Matrix and Statistics\nReference\nPrediction 0 1 2\n0 2 1 0 1 0 3 0 2 1 0 2\nAccuracy : 0.7778 95% CI : (0.3999, 0.9719) No Information Rate : 0.4444 P-Value [Acc > NIR] : 0.04635 Kappa : 0.6667\nTo study which of the features influences most to the result, the following shows 3 independent experiment of gbm fitting and summary.gbm.\n--------------------------------------------\nFirst 5 variables in the summary graph: body words, auxiliary verbs, motion words, parenthesis, and time words\nBy counting frequency of variables during the computed relative influence, we get 10 most significant ones:\npunctuation_parenth, textmind_achieve, textmind_anx, textmind_auxverb, textmind_body, textmind_feel, textmind_home, textmind_insight, textmind_motion, textmind_ppron\nDiscussion & Comparison with previous case studies Previous studies worked on the correlation between suicide and LIWC features, selecting features with small p values as significant ones (M. Fern\u00e1ndez Cabana, 2012). Other reports show comparison of factors like time career age and word type and conclude the most related treatment (Stirman, 2001). Logistic regression is applied to some data as the independent variables were viewed continuous (Masuda1, 2013). There are no studies on suicide dealing with a bunch of users making use of LIWC before. In our case we classify the observations into several groups by features and draw decision trees using group names made in classifying. Since all the features expressed as nominal scales, there was no correlation test to be computed, and instead of p-value showing the relationship between suicide and variables we obtained relatively most significant ones in among all the features and statistics. Future studies, therefore, can start up in logistic regression with Fourier coefficients of the sequences as independent variables. Chinese materials were studied in our case, whereas most previous studies have only analyzed\nmaterials written in or translated into English, while the writer\u2019s original psychological meaning and linguistic style may not be completely preserved after translation (Tim M.H. Li, 2014). Our study differs from previous ones using Chinese version of the LIWC in that we studied a number of social network site users and computed decision trees. Chinese-specific categories may further reveal psychological cues of suicide that cannot be used in other languages (Tim M.H. Li, 2014).\nNotice that we use cluster centers to notify properties of clusters, thus these centers should be showed to demonstrate distinctive features for suicide groups. According to decision trees gained from different training sets, among the 10 most significant features, we got 4 relative to group 0, that is, users who committed suicide.\npunctuation_parenth\nAVG SD 0 1 2 Arg1"}, {"heading": "1 15.13012161 14.51798345 0.395844657 0.287937124 0.205698385 0.031531324", "text": ""}, {"heading": "2 2.741153902 2.866167462 0.382331809 0.310391627 0.192305825 0.019072178", "text": ""}, {"heading": "3 8.239399639 6.85765465 0.42652605 0.295963262 0.197711739 0.033835113", "text": "textmind_auxverb\nAVG SD 0 1 2 Arg1"}, {"heading": "1 0.859780602 1.13359216 0.42544777 0.351378434 0.192942227 -0.030703143", "text": ""}, {"heading": "2 0.45646321 0.643238929 0.381737123 0.360421457 0.198317093 -0.028562451", "text": ""}, {"heading": "3 1.23507966 2.083186149 0.364611951 0.330547531 0.219752759 -0.016703396", "text": ""}, {"heading": "4 1.569081052 0.761592293 0.495306702 0.273604439 0.168876502 0.101621611", "text": ""}, {"heading": "5 2.746256923 5.222238298 0.300807037 0.307408881 0.230586356 0.007398932", "text": ""}, {"heading": "6 2.288426194 2.067912902 0.457584683 0.305631784 0.191989699 0.044695307", "text": ""}, {"heading": "7 0.035452023 0.099684427 0.09538323 0.127791217 0.076010697 0.011927493", "text": "textmind_ppron\nAVG SD 0 1 2 Arg1"}, {"heading": "1 4.886485982 5.88412429 0.390026292 0.309999442 0.20601711 -0.006538162", "text": ""}, {"heading": "2 2.605513666 3.248422761 0.4117724 0.320524585 0.206776553 -0.002718911", "text": ""}, {"heading": "3 1.357334981 1.392897273 0.410696572 0.324519575 0.187144587 0.005262552", "text": ""}, {"heading": "4 3.547252654 1.608387298 0.497152643 0.275347883 0.168847521 0.063698304", "text": "textmind_body\nAVG SD 0 1 Arg1"}, {"heading": "1 2.395603793 4.59783583 0.301782598 0.318970376 0.037743009", "text": ""}, {"heading": "2 0.129525066 0.263360931 0.228623388 0.266353604 -0.012259764", "text": ""}, {"heading": "3 1.492920946 0.917740263 0.488347043 0.288160849 0.105404415", "text": ""}, {"heading": "4 0.649327344 0.671164326 0.450879339 0.338566756 0.009294324", "text": ""}, {"heading": "5 3.877760453 9.115389734 0.219022062 0.296123209 0.038607001", "text": ""}, {"heading": "6 0.894588789 1.546070027 0.362208628 0.344195046 -0.012441021", "text": ""}, {"heading": "7 1.666291015 2.568380012 0.360546753 0.324560843 0.027588917", "text": "From the decision trees we see that in the use of parentheses, the suicide group are matched with time sequences in cluster 2. Relatively low average value, small standard deviation and phases corresponding to max amplitudes near 0 are mainly observed to describe the characteristic of this cluster of curves, among which phases near 0 mean that the sine waves with the largest amplitudes start at somewhere near time 0. For use of auxiliary verbs, group of suicides were found high at both FFT coefficient of 1 Hertz and average value (see at parameters of cluster 2, 4, 5, 6 and 7). The large coefficients corresponding to 1 Hertz may imply that the time sequence curves are of relatively significant property of forming one whole sine period.\nBesides parentheses and auxiliary verbs we got personal pronouns also relative to classifying groups. All the 4 clusters except the third one are divided to node with suicide group. Comparing parameters we found that cluster 3 has got the lowest level of average value and the smallest standard deviation, which means the suicide group is of relatively much use of personal pronouns, which is in line with previous reports. Another result different from former studies is the use of body words. Cluster 3, 4, 5 and 7 are claimed to be related to suicide group and most curves in these clusters share a similarly high level of phase to the max amplitude. Also coefficients of 0 Hertz are distinctively larger than the other two matched groups, showing that tiny fluctuations are recorded in the curves of suicide group.\nCONCLUSION\nRelationship between suicide and linguistic performance has been studied for long. Previous cases used several methods, including method to treat posting frequency, and the studies focused on materials in several languages, on and off-line. We didn\u2019t get the consistent results with former cases except use of pronouns. However there are limitations in our study. 90 is a rather small sample size for classifying users with known labels 0, 1 or 2, and high-score group and low-score group might not be exactly classified. Besides, the CLIWC categories shows only the originally used meanings of the words with no other meanings like irony or sarcasm, not to mention the meaning of the contents.\nStill, it is an interesting field for future studies to deal with linguistic and behavioral characteristics of suicides. Our work provides a new method to see into the problem and gives different results from previous studies, which may help to the prediction and cure of psychological health.\nREFERENCE\nBailey, R.K., Patel, T.C., Avenido, J., Patel, M., Jaleel, M., Barker, N.C., Khan, J.A., Ali, S., Jabeen, S., (2011). Suicide: current trends. J. Natl. Med. Assoc. 103, 614\u2013617.\nCheung, G., Merry, S., & Sundram, F. (2015). Late-life suicide: Insight on motives and contributors derived from suicide notes. Journal of affective disorders, 185, 17-23\nChristensen, H., Batterham, P., O'Dea, B., 2014. E-health interventions for suicide prevention. Int. J. Environ. Res. Public Health 11, 8193\u20138212.\nClark, S. E., & Goldney, R. D. (2000). The impact of suicide on relatives and friends. The international handbook of suicide and attempted suicide, 467-484.\nFern\u00e1ndez-Cabana, M., et al. (2013). \"Suicidal Traits in Marilyn Monroe\u2019s Fragments.\" Crisis 34(2).\nGao, Rui, et al. \"Developing simplified Chinese psychological linguistic analysis dictionary for microblog.\" Brain and Health Informatics. Springer International Publishing, 2013. 359-368.\nGen\u00e7\u00f6z TOP. (2006). Associated factors of suicide among university students: importance of family environment. Contemporary Family Therapy 28: 261-268. DOI: 10.1007/s10591-006-9003-1.\nGuan, L., et al. (2014). Identifying Chinese Microblog Users with High Suicide Probability using Internet-based Profile and Linguistic Features: Classification Model.\nHuang C, Chung C, Hui N, Lin Y, Seih Y, Lam B, Pennebaker J. (2012). The development of the Chinese Linguistic Inquiry and Word Count Dictionary. Chinese Journal of Psychology 55: 185-201.\nJordan, J. R., & McIntosh, J. L. (2011). Suicide bereavement: Why study survivors of suicide loss. Grief after suicide: Understanding the consequences and caring for the survivors, 3-17.\nLi L, Li A, Hao B, Guan Z, Zhu T. (2014). Predicting active users' personality based on micro-blogging behaviors. PLoS ONE9: e84997 DOI 10.1371/journal.pone.0084997.\nLi, T. M., et al. (2014). \"Temporal and computerized psycholinguistic analysis of the blog of a\nChinese adolescent suicide.\" Crisis 35(3).\nMasuda, N., et al. (2013). \"Suicide ideation of individuals in online social networks.\" 9(1).\nMcCarthy, M. J. (2010). Internet monitoring of suicide risk in the population. Journal of affective disorders, 122(3), 277-279.\nMurano G. (2014). 8 shocking suicide attempts posted on the Internet. Available at http://www.oddee.com/item 98907.aspx (accessed 8 July 2015).\nNaud H, Daigle M S. (2010). Predictive validity of the Suicide Probability Scale in a male inmate population. Journal of Psychopathology and Behavioral Assessment 32: 333-342. DOI: 10.1007/s10862-009-9159-8.\nPestian, J. P., Matykiewicz, P., Linn-Gust, M., South, B., Uzuner, O., Wiebe, J., ... & Brew, C. (2012). Sentiment analysis of suicide notes: A shared task.Biomedical informatics insights, 5(Suppl 1), 3.\nStirman, et al. (2001). \"Word use in the poetry of suicidal and nonsuicidal poets.\" Psychosomatic Medicine 63(4).\nSueki, H. (2015). The association of suicide-related Twitter use with suicidal behaviour: A cross-sectional study of young internet users in Japan. Journal of affective disorders, 170, 155-160.doi: 10.1016/j.jad.2014.08.04\nTausczik, et al. (2010). \"The Psychological Meaning of Words: LIWC and Computerized Text Analysis Methods.\" Journal of language and social psychology 29(1).\nWorld Health Organization, (2014). Preventing Suicide: A Global Imperative. World Health Organisation, Geneva, Switzerland."}], "references": [{"title": "Suicide: current trends", "author": ["S. Jabeen"], "venue": "J. Natl. Med", "citeRegEx": "Jabeen,? \\Q2011\\E", "shortCiteRegEx": "Jabeen", "year": 2011}, {"title": "The impact of suicide on relatives and friends. The international handbook of suicide and attempted suicide, 467-484", "author": ["S.E. Clark", "R.D. Goldney"], "venue": "Ferna\u0301ndez-Cabana, M., et al", "citeRegEx": "Clark and Goldney,? \\Q2000\\E", "shortCiteRegEx": "Clark and Goldney", "year": 2000}, {"title": "Identifying Chinese Microblog Users with High Suicide Probability using Internet-based Profile and Linguistic Features: Classification", "author": ["L 1007/s10591-006-9003-1. Guan"], "venue": "Chinese Journal of Psychology", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Suicide bereavement: Why study survivors of suicide loss. Grief after suicide: Understanding the consequences and caring for the survivors", "author": ["J.R. 185-201. Jordan", "J.L. McIntosh"], "venue": null, "citeRegEx": "Jordan and McIntosh,? \\Q2011\\E", "shortCiteRegEx": "Jordan and McIntosh", "year": 2011}, {"title": "Temporal and computerized psycholinguistic analysis of the blog", "author": ["Li", "T. M"], "venue": null, "citeRegEx": "Li and M,? \\Q2014\\E", "shortCiteRegEx": "Li and M", "year": 2014}, {"title": "Chinese adolescent suicide.\" Crisis", "author": ["N Masuda"], "venue": "Journal of affective disorders,", "citeRegEx": "Masuda,? \\Q2013\\E", "shortCiteRegEx": "Masuda", "year": 2013}, {"title": "Predictive validity of the Suicide Probability Scale in a male inmate population", "author": ["H Naud", "S. Daigle M"], "venue": "Journal of Psychopathology and Behavioral Assessment", "citeRegEx": "Naud and M,? \\Q2015\\E", "shortCiteRegEx": "Naud and M", "year": 2015}, {"title": "Sentiment analysis of suicide notes: A shared task.Biomedical informatics insights", "author": ["P. Matykiewicz", "M. Linn-Gust", "B. South", "O. Uzuner", "J. Wiebe", "C. Brew"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "The association of suicide-related Twitter use with suicidal behaviour: A cross-sectional study of young internet users in Japan", "author": ["H. Sueki"], "venue": "Journal of affective disorders,", "citeRegEx": "Sueki,? \\Q2015\\E", "shortCiteRegEx": "Sueki", "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "Many studies have confirmed correlations between the frequency of any words in social media posts and individual scores on suicide risk, suggesting the linguistic features of the language use can be used as valid indicators for detecting individual suicide risk on social media (McCarthy, 2010; Sueki, 2015).", "startOffset": 278, "endOffset": 307}, {"referenceID": 2, "context": "Many studies have confirmed correlations between the frequency of any words in social media posts and individual scores on suicide risk, suggesting the linguistic features of the language use can be used as valid indicators for detecting individual suicide risk on social media (McCarthy, 2010; Sueki, 2015). However, few studies focused on the temporal relationships between the changes in patterns of the language use and levels of suicide risk, which may provide insight into the track of the suicidal process on social media. Li et al (2014) used the Chinese Linguistic Inquiry and Word Count (CLIWC) program to analyze a 13-year-old boy\u2019s 193 blogs, which were posted during the year prior to his suicide death.", "startOffset": 291, "endOffset": 546}, {"referenceID": 0, "context": ", Jabeen, S., (2011). Suicide: current trends.", "startOffset": 2, "endOffset": 21}], "year": 2015, "abstractText": "Suicide is a global public health problem. Early detection of individual suicide risk plays a key role in suicide prevention. In this paper, we propose to look into individual suicide risk through time series analysis of personal linguistic expression on social media (Weibo). We examined temporal patterns of the linguistic expression of individuals on Chinese social media (Weibo). Then, we used such temporal patterns as predictor variables to build classification models for estimating levels of individual suicide risk. Characteristics of time sequence curves to linguistic features including parentheses, auxiliary verbs, personal pronouns and body words are reported to affect performance of suicide most, and the predicting model has a accuracy higher than 0.60, shown by the results. This paper confirms the efficiency of the social media data in detecting individual suicide risk. Results of this study may be insightful for improving the performance of suicide prevention programs.", "creator": "Microsoft Office Word 2007"}}}