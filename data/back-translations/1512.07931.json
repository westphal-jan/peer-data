{"id": "1512.07931", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Dec-2015", "title": "Probabilistic Model-Based Approach for Heart Beat Detection", "abstract": "Nowadays, hospitals are ubiquitous and an integral part of modern society, with patients flocking in and out of a veritable whirlwind of paperwork, consultations and potential hospital admissions through an abstract system that is not without flaws. Perhaps one of the biggest flaws in the medical system is an unexpected one: the patient alert system. A longitudinal study reported a false alert rate of 88.8%, while other studies report numbers of similar magnitude. These false alarms lead to a number of harmful effects that manifest themselves in a significantly lower standard of care in all clinics.", "histories": [["v1", "Thu, 24 Dec 2015 23:24:24 GMT  (7458kb,D)", "http://arxiv.org/abs/1512.07931v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["hugh chen", "yusuf erol", "eric shen", "stuart russell"], "accepted": false, "id": "1512.07931"}, "pdf": {"name": "1512.07931.pdf", "metadata": {"source": "CRF", "title": "Probabilistic Model-Based Approach for Heart Beat Detection", "authors": ["Hugh Chen", "Yusuf Erol", "Eric Shen", "Stuart Russell"], "emails": [], "sections": [{"heading": null, "text": "Submitted to: PMEA"}, {"heading": "Probabilistic Model-Based Approach for Heart Beat", "text": "Detection\nHugh Chen University of California Berkeley California, USA hugh.chen{at}berkeley.edu\nYusuf Erol University of California Berkeley\nCalifornia, USA yusufbugraerol{at}berkeley.edu\nEric Shen University of California Berkeley\nCalifornia, USA ericshen{at}berkeley.edu\nStuart Russell University of California Berkeley California, USA russell{at}cs.berkeley.edu\nNowadays, hospitals are ubiquitous and integral to modern society. Patients flow in and out of a veritable whirlwind of paperwork, consultations, and potential inpatient admissions, through an abstracted system that is not without flaws. One of the biggest flaws in the medical system is perhaps an unexpected one: the patient alarm system. One longitudinal study reported an 88.8% rate of false alarms, with other studies reporting numbers of similar magnitudes. These false alarm rates lead to a number of deleterious effects that manifest in a significantly lower standard of care across clinics.\nThis paper discusses a model-based probabilistic inference approach to identifying variables at a detection level. We design a generative model that complies with an overview of human physiology and perform approximate Bayesian inference. One primary goal of this paper is to justify a Bayesian modeling approach to increasing robustness in a physiological domain.\nWe use three data sets provided by Physionet, a research resource for complex physiological signals, in the form of the Physionet 2014 Challenge set-p1 and set-p2, as well as the MGH/MF Waveform Database. On the extended data set our algorithm is on par with the other top six submissions to the Physionet 2014 challenge.\nKeywords: Beat Detection, PhysioNet Challenge, Particle Filter, Dynamic Bayesian Network, ECG, Blood Pressure, Model Based Probabilistic Inference.\nar X\niv :1\n51 2.\n07 93\n1v 1\n[ cs\n.A I]\n2 4\nD ec\n2 01\n5"}, {"heading": "1 Introduction", "text": "Patient monitoring is a significant part of health care, not only to ensure that physicians can accurately diagnose and treat patients, but also to trigger biometric-based alarms. The intent of these alarms is to guarantee that a patient receives attention from clinicians whenever his or her condition takes a turn for the worse.\nOne of the important facets of such biometric data are heart beats. By monitoring heart beats, a number of cardiac issues, including a variety of life-threatening arrhythmia (asystole, bradycardia, tachycardia, etc.), can be detected (Goldberger, Amaral, Glass, Hausdorff, Ivanov, Mark, Mietus, Moody, Peng & Stanley 2000 (June 13)). In the case where there is a high noise level and poor signal quality the heart beats themselves are unreliable. These unreliable beats can lead to false-negatives, where alarms fail to be triggered, as well as false-positives, where alarms are triggered for no substantive reason. These two cases respectively result in alarm failure and alarm fatigue (Chopra & McMahon 2014).\nFalse-negatives are direct alarm failures. Instances of alarm failure are dangerous because they mean that patients in life-threatening situations may be completely overlooked. Alarm fatigue, on the other hand, is an indirect consequence of an excess of false-positives (AKA false alarms). An excess of false alarms has a number of pernicious effects, including the desensitization of nurses and doctors to true alarms, disturbance of ailing patients, and the cost of time wasted for both physicians and patients. One article cites alarm fatigue as one of the top patient safety concerns in hospitals (MacDonald 2007). In a 31-day study across 461 adults in intensive care units, 88.8% of the 12,671 arrhythmia alarms were falsely detected (Drew, Harris, Ze\u0300greHemsey, Mammone, Schindler, SalasBoni, Bai, Tinoco, Ding & Hu 2014). Other studies report similar numbers, indicating that alarm fatigue is a real phenomenon.\nTypically, the methods used to identify the heart beats are straightforward signal processing algorithms that take advantage of the regular waveforms of either electrocardiogram (ECG) or arterial blood pressure (ABP) signals. In ECG signals, there exists a regular QRS complex. In signals with well-defined QRS complexes, executing signal processing algorithms that annotate heart beats at the R peaks achieves high accuracy. Likewise for the ABP signals, there exists a spike, albeit not as sharply defined as the QRS peak, that indicates the location of the heartbeat. In ABP, heart beat detection is further complicated by a delay between heartbeats and the pressure peaks. Standard methods for heart beat detection\ntypically include signal processing algorithms that rely on a particular lead for a particular signal. This\nnaive approach is already problematic because of the potential for dropped signals. Figure 1 provides an example of dropped signals within a single piece of data. This shows that for a given patient, across a relatively short period of time, it is possible for either the ECG or the ABP signal to simply flat-line and yield no useful information. These dropped signals occur for a variety of reasons, including but not limited to technical malfunctions or the detachment of sensors due to patient movement. In these cases, any signal processing algorithm that naively depends on a single signal\u2019s lead will fail to provide useful data for extended periods of time.\nThe problem of dropped signals almost naturally suggests a solution in the form of a signal switching algorithm. One that evaluates whether the lead has flatlined, and if so, switches to a lead with a notable stream of data. This approach certainly works to a degree, but a naive application will fail due to events that disturb the signal and generate noise, otherwise known as artifacts. In Figure 2, the middle of the\nECG signal has a clear example of an artifact. The regular QRS complexes are disturbed, leaving a signal that bears no recognizable patterns. Artifacts can be the manifestation of a patient brushing their teeth, bumping into something, or simply rolling around in their sleep. They complicate the detection of heart beats, because the artifacts can corrupt the signals in a variety of ways, thereby rendering any naive switching algorithm insufficient. Ultimately, the goal is to robustly detect heart beats despite the occurrence of artifacts, noise, and dropped signals. In doing so, patient monitoring systems in hospitals can become much more efficient, reducing ICU false alarm rates.\nGiven all of this clinical data, we recognize the problem as one that can be solved through either a data-driven or a model-based approach. We could potentially treat the problem as a regression problem and allow the program to train on the Physionet data and develop its own interpretation and understanding of the problem. Alternatively, we can assume that the problem is an inherently biological problem, and take an approach that borrows from modern understanding of human physiology.\nBecause there exists a large corpus of research in the direction of human physiology, we choose the latter. Yet earlier, we have recognized that the data we are dealing with is inherently uncertain. In order to capture both the model and inherent uncertainty we approach the problem through a model-based probabilistic inference approach.\nWe develop a Dynamic Bayesian Network (DBN) to describe the interactions of the patient\u2019s physiological characteristics over time. In order to incorporate our beliefs about how artifiacts and noise\nmanifest themselves in data we also incorporate an observation model. Finally, we use particle filtering, which is a Sequential Monte Carlo (SMC) method, to perform combined state and parameter estimation on our non-linear, non-Gaussian model."}, {"heading": "2 Physionet", "text": "Before moving directly into the algorithm it is worth mentioning Physionet. Physionet is a research resource that offers access to a sizable supply of recorded physiological signals and their open source software. In addition, they hold challenges on a yearly basis, with last year\u2019s challenge pertaining to heart beat detection. We use several of the datasets provided by Physionet to evaluate our algorithm\u2019s performance."}, {"heading": "2.1 Material", "text": "The first is the Physionet Challenge 2014 training set (set-p1), which is was a dataset released during the first phase of the challenge (Goldberger et al. 2000 (June 13)). There are 100 examples that are all relatively clean and artifact-free. The data is typically 10 minutes long or shorter and each record contains at least one ECG signal and at least one ABP signal. The sampling frequency is also consistent among these examples at 250 samples per second.\nThe next dataset set is the Physionet Challenge 2014 extended training set (set-p2), consisting of 100 records (Goldberger et al. 2000 (June 13)). These records contain signals that have more noise and artifacts than those of set-p1. The signals in set-p2 are mostly 10 minutes long, although there are occasionally shorter signals. The sampling frequency varies between 250 samples per second to 360 samples per second.\nThe final dataset we use is the Massachusetts General Hospital/Marquette Foundation (MGH/MF) Waveform Database provided by Physionet (Welch, Ford, Teplick & Rubsamen 1991). The database consists of 250 recordings and represents a broad spectrum of physiologic and pathophysiologic states. Individual recordings vary in length from 12 to 86 minutes, and in most cases are about an hour long. The effective sampling frequency is 360 samples per second.\nFor these three datasets, reference beat annotations are available. These reference beat annotations represent the consensus of several expert beat annotators, and are used for determining the accuracy of the algorithms.\nBeyond the datasets, we also make use of the GQRS and WABP functions, which are the basic beat detectors for ECG and ABP respectively provided by Physionet\u2019s WFDB Toolbox (Silva & Moody 2014). In addition, we use other WFDB Toolbox functions for processing signals and annotations."}, {"heading": "2.2 Related Work", "text": "Since Physionet held a challenge and collected many submissions, there are also quite a few bodies of work that make meaningful progress towards improving heart beat detection. The top six algorithms that were submitted to the Physionet 2014 Challenge, ordered by their performance in Physionet are Pangerc (Pangerc & Jager 2014), Johnson (Johnson, Bechar, Andreotti, Clifford & Oster 2014), Antink (Hoog Antink, Bruser & Leonhardt 2014), De Cooman (De Cooman, Goovaerts, Varon, Widjaja & Huffel 2014), Johannesen (Johannesen, Vicente, Scully, Galeotti & Strauss 2014), and Vollmer (Vollmer 2014).\nIn general, most of the submissions involved a subset of a few typical techniques: pre-processing, a combination algorithm, and then post-processing. In addition most algorithms used some form of delay incorporation, either in their pre-processing or combination algorithm to account for the ABP delay. Finally, a few algorithms make use of signals outside of the ECG and ABP signals. It is worth noting that Pangerc, whose performance is significantly higher than the other applications involved reimplementing ECG and pulsatile-signal detection algorithms. For a recent review of the submissions, refer to the Physionet 2014 Challenge summary paper (Silva, Moody, Behar, Johnson, Oster, Clifford & Moody 2015)."}, {"heading": "3 Methods - Algorithm", "text": ""}, {"heading": "3.1 Introduction", "text": "Dynamic Bayesian networks (DBNs) are widely used to model the processes underlying sequential data such as speech signals, financial time series, genetic sequences, and in our case, physiological signals. DBNs model a process using static parameters, hidden variables that evolve over time, and observations at each time step, as shown in Figure 3.\nMore specifically, for a partially observable Markov process with unobserved state variables {Xt}t\u22650, and observations {Yt}t\u22650 that is parametrized by a static parameter space \u0398, the probabilistic model is defined as follows.\nX0 \u223c p(x0 | \u03b8) (1) Xt | xt\u22121 \u223c p(xt | xt\u22121,\u03b8) (2)\nYt | xt \u223c p(yt | xt ,\u03b8) (3)\nThe first equation represents the initialization of state variables, which corresponds to the prior probability. The second equation represents the propagation model, which is based on transition probabilities from one state to another. For our propagation model, we implemented a drastically simplified model of human biometrics and then evolved variables in a physiological manner. The final equation represents the observation model, which corresponds to the probability of a particular observation given a certain state. In our case, our observations consisted of annotations and signal quality indices from signal detection algorithms.\n000 001 002 003 004 005 006 007 008 009 010 011 012 013 014 015 016 017 018 019 020 021 022 023 024 025 026 027 028 029 030 031 032 033 034 035 036 037 038 039 040 041 042 043 044 045 046 047 048 049 050 051 052 053 054\n055 056 057 058 059 060 061 062 063 064 065 066 067 068 069 070 071 072 073\n074\n075 076 077 078 079 080 081 082 083 084 085 086 087 088 089 090 091 092 093 094 095 096 097 098 099 100 101 102 103 104 105 106 107 108 109\nThe Extended Parameter Filter Abstract The parameters of temporal models such as dynamic Bayesian networks may be viewed in the Bayesian context as static or atemporal variables that influence the transition probabilities at every time step. Particle filters fail for models that include such variables, while methods that use Gibbs sampling of parameter variables may incur a per-sample cost that grows linearly with the length of the ob-\nservation sequence. Storvik (2002) devised a\nmethod for incremental computation of ex-\nact sufficient statistics that, for some cases, reduces the per-sample cost to a constant. In this paper, we demonstrate a connection between Storvik\u2019s filter and a Kalman filter in parameter space and establish more general conditions under which it works. Drawing on an analogy to the extended Kalman filter, we develop and analyze, both theoretically and experimentally, a Taylor approximation to the parameter posterior that allows Storvik\u2019s method to be applied to a broader class of models. Our experiments on both synthetic examples and real applications show improvement over existing methods. 1. Introduction Dynamic Bayesian networks are widely used to model the processes underlying sequential data such as speech signals, financial time series, genetic sequences, and medical or physiological signals. State estimation or filtering\u2014computing the posterior distribution over the state of a partially observable Markov process from a sequence of observations\u2014is one of the most widely studied problems in control theory, statistics and AI. Exact filtering is intractable except for certain special cases (linear\u2013Gaussian models and discrete HMMs), but approximate filtering using the particle filter (a sePreliminary work. Under review by the International Conference on Machine Learning (ICML). Do not distribute.\n\u03b8 X1 Y1 X2 Y2 X3 Y3 \u00b7 \u00b7 \u00b7 XT YT Figure 1. A state-space model with static parameters \u03b8.\nX1:T are latent states, and Y1:T observations.\nquential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2008). In the machine learning context, model parameters may be represented by static parameter variables that define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) converges to a delta function at the true value in the limit of infinitely many observations. Unfortunately, particle filters fail for such models: the algorithm samples parameter values for each particle at time t= 0, but these remain fixed; over time, the particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009); Carvalho et al. (2010) describe several algorithms that have been proposed to solve this degeneracy problem, but the issue remains open because known algorithms either suffer from bias or computational inefficiency. For example, the \u201cartificial dynamics\u201d approach (Liu and West, 2001) introduces a stochastic transition model for the parameter variables, allowing exploration of parameter space, but this may result in biased estimates. Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution. The particle MCMC algorithm (An-\nFigure 3: A state-space model with static parameters \u03b8 . X1:T are latent states and Y1:T are observations."}, {"heading": "3.2 Sequential Monte Carlo", "text": "Given a probabilistic odel and a sequence of observations, one can attempt to estimate the latent states. That is the problem of state estima ion, also k own as filtering: t process of computing the posterior\ndistribution of the hidden state variables given a sequence of observations. Exact filtering is often intractable except for specific cases, but approximate filtering using the particle filter (a sequential Monte Carlo method) is feasible in many applications (Arulampalam, Maskell, Gordon & Clapp 2002) (Doucet & Johansen 2011).\nThe specific method we use is Sequential Importance Sampling-Resampling (SIR), otherwise known as bootstrap filtering and particle filtering. This representation relies on approximating the posterior density, p(xt |y0:t ,\u03b8) function at any given time using a set of random particles that we recursively evolve. As the cardinality of the set grows, the approximation improves in accuracy.\nWe initialize the states of our particles based on the prior probabilities. We then propagate the state of the particles using the transition probabilities, weight based on the observation probabilities, and resample at each time step. Through this propagate-weight-resample scheme, particle filtering generates simulations that explore the likely portions of the latent probability space.\nAlgorithm 1: Sequential importance sampling-resampling (SIR) Input: N: number of particles; y0, . . . ,yT : observation sequence Output: x\u03041:N1:T initialize { xi0 }\n; for t = 1, . . . ,T do\nfor i = 1, . . . ,N do sample xit \u223c p(xt | xit\u22121); wit \u2190 p(yt | xit);\nresample { 1 N , x\u0304 i t } \u2190 { wit ,x i t }\n;{ xit } \u2190 { x\u0304it } ;"}, {"heading": "4 Methods - Model", "text": "Our approach relies on the assumption that human physiology follows a pattern that can be modeled in a Bayesian manner. Specifically, we construct a DBN that corresponds to human physiology, with static variables \u03b8 (e.g. resting heart rate), dynamic state variables Xi (e.g. true heart rate) which define a propagation model, and observations Yi (e.g. ECG annotations and signal quality) which define an observation model. The propagation and observation models are described in the following sections and illustrated in Figure 5. We proceed to use the filtering techniques covered in the previous section to perform state estimation on the DBN we have constructed.\n4.1 Propagation Model; p(xt |xt\u22121,\u03b8) Our propagation model (transition model) encodes a DBN, and indicates our beliefs about the interdependent evolution of our relevant variables over time. The model makes use of nine variables to represent a simplified model of human physiology. Refer to Figure 4, to see the physical representation of a few of the propagation variables.\nThe first two variables are static parameters: RestHR and Latency, which represent the resting heart rate of the patient and the delay between ECG and ABP signals, respectively (Zong, Moody & Mark 1998). These static parameters converge quickly during particle filtering.\nThe next variables we cover are latent variables. The third variable is the TrueHR, which represents the belief of the patient\u2019s heart rate at a particular point in the signal. The fourth variable is the ECGPeak, which is a binary variable that represents whether there is a peak in the current window of the ECG signal. The ECGPeak variable evolves based on the TrueHR and the next variable, ECGLastPeak, which represents the last time we believed there was a peak in the ECG signal. The sixth and seventh variables are ABPPeak and ABPLastPeak which are analogous to the corresponding ECG variables, but incorporate the Latency variable. Note that in this model, the ECGPeak at time t coincides with the ABPPeak at time t + Latency. This means that the ABPPeak variable represents our final belief about heart beat annotations, because it incorporates both ECG and ABP information. The final two variables are ECGArti f act and ABPArti f act, which are binary variables that are used to label a signal as artifactual. For a more in-depth explanation, refer to the Propagation Model in Appendix A.\n4.2 Observation Model; p(yt |xt ,\u03b8) The observation model (sensor model) encodes our beliefs about the functions we use to derive observations and the probability that the observations correspond to the current states. In the observation model there are six variables that we relate to the variables in our propagation model.\nThe first two variables are annotation observations, ECGAnn and ABPAnn. These binary variables represent whether the algorithms provided by Physionet, GQRS and WABP, found an annotation at the current time. The observation model describes a relationship between these variables and the corresponding Peak, LastPeak, and Arti f act variables in the propagation model. The next two are heart rate observations, ECGHR and ABPHR, which once again are derived using WABP and GQRS to give an estimate of the heart rate. These parameters are mainly associated with the TrueHR variable. Finally we\nhave two SQI observations, ECGSQI and ABPSQI, which represent how trustworthy a particular signal is. The ECGSQI is calculated by comparing the results from two of Physionet\u2019s ECG signal detectors, and the ABPSQI is calculated by checking that the detections are within certain physiological boundaries (Johnson et al. 2014) (Sun, Reisner, Saeed & Mark 2005) (Sun 2006). For a more in-depth explanation, refer to the Observation Model in the Appendix B."}, {"heading": "4.3 Performing State Estimation", "text": "Given our probabilistic heart beat model, we now use particle filtering to perform state estimation and to determine when heart beats occurred. Our particle filter follows SIR whereby we perform three steps recursively: propagation, weighting, and resampling.\nFirst, we split our signals into 25 millisecond windows, and calculate the values of the observation model variables for each of these windows. Then, the particle filter assigns a prior belief to our set of particles (in our algorithm we use a set of 2000). For the propagation step we propagate the particles individually according to our transition model to acquire the state of the model one step into the future. Next, for each particle, we calculate a weight which is representative of the likelihood of that particle\u2019s realized state given the observations we have made at the corresponding time. The final recursive step is to resample the particles according to the weights we calculated in order to avoid the degeneracy problem, where the particles all have negligible weight (Doucet & Johansen 2011).\nWe repeat the recursive steps above for the duration of the signal in a sequential fashion. At each step in the recursion we also save the average state of the variables across the particles, which is used to compose our actual heart beat annotations. Based on ABPPeaks, we backshift a distance of Latency and then annotate a beat only if enough particles are in the state that corresponds to a peak. This threshold is one of several hyperparameters within our algorithm that were tuned over the development of the filter.\nThe final annotations we use correspond to timesteps where enough particles were in a state of ABPPeaks backshifted by the Latency between ECGPeaks and ABPPeaks."}, {"heading": "5 Results", "text": "Now that we have established the algorithm, we discuss the performance of the algorithm on several datasets. In this section we compare results in terms of the sensitivity (recall) and positive predictivity (precision). The sensitivity represents the percentage of actual beats our algorithm annotated, and the positive predictivity represents the percentage of detections that corresponded to actual beats."}, {"heading": "5.1 Results - Individual", "text": "The first example we discuss is record 1376 from set-p2. This record is an example where we make a large improvement over GQRS and WABP.\nIn Figure 6 we note that the particle filter can recover from spurious GQRS annotations on the left and spurious WABP annotations on the right, all within the same signal. Our algorithm performs well overall on record 1376, and this example illustrates its capacity for artifact recovery. Most of the improvement our algorithm achieves is in knowing when to trust a particular signal to the point that it will incorporate it within our observation model.\nThe next example we discuss is record 2664 from set-p2. This record demonstrates our improvement over GQRS and provides an illustrative example of signal quality and artifacts.\nIn Figure 7, we see that our estimate of the ECGArti f act correlates strongly with the ECGSQI. Wherever the ECGSQI is low, our particle filter correspondingly believes there to be an artifact. The fact that the ECGArti f act variable is quite accurate serves as a proof of concept that our particle filter can track other biometric or sensor state in addition to heart beats. In addition, we see that the TrueHR matches the actual heart rate quite closely. This means we can potentially incorporate other variables, such as those that could determine the presence of arrhythmia or other information relevant to the general status of a patient, to create a more refined model.\nThen, in Figure 8, we see a strong improvement over GQRS. Our algorithm has a sensitivity of 0.941 and a predictivity of 0.988, whereas GQRS has a sensitivity of 0.343 and a predictivity of 0.975. These numbers indicate that for example 2664, GQRS missed a lot of actual beats, but didn\u2019t make many false predictions, which is reflected in the figure as well. Overall, this example highlights the powerful recovery our algorithm elicited simply by combining GQRS and WABP annotations under a physiological model.\nIn our last record of interest, 1033 from set-p2, we observe a phenomenon we denoted as \u201ddouble annotations\u201d pictured in Figure 9. These double annotations are mainly due to artificial pacemakers and low dicrotic notches. This is where the signals are shaped in such a way that either the GQRS or WABP or both algorithms annotate an extra set of beats. Here we observe the case where both GQRS and WABP believe there to be a double annotation, resulting in our particle filter believing there to be a double annotations as well. These double annotation phenomena are the primary reason for our lower positive predictivity in the next results section. Recovering from double annotations is actually quite difficult within the generative capabilities of our probabilistic model, however through the introduction of new features the double annotations can potentially be ameliorated. Without other data about the signal, determining the presence of double annotations is infeasible."}, {"heading": "5.2 Results - Overall", "text": "In order to generate these results, we took the top submissions on Physionet, downloaded their entries, and re-ran them against the exact same datasets we used. We then used Physionet\u2019s provided bxb function to compare the generated heart beat annotations with the reference ones and to determine the sensitivity and predictivity for a given record. Finally, we averaged the sensitivity and predictivity across all records from a given dataset. This was for the sake of consistency in our comparisons. While all the submissions ran without errors on set-p1 and set-p2, our algorithm, Pangerc\u2019s, and Johnson\u2019s did not run properly on some of the records in the MGH/MF Waveform Database. We omitted those records when calculating scores. The results for set-p1 (top left), set-p2 (top right), and the MGH/MF Waveform Database (bottom):\nset-p1 Method Sensitivity Pos. Pred.\nDBN-PF 0.99893 0.99380 GQRS 0.99942 0.99320 WABP 0.39006 0.38997 Pangerc 0.99995 0.99950 Johnson 0.99829 0.99805 Antink 0.99965 0.99972 De Cooman 0.99962 0.99985 Johannesen 0.99956 0.99809\nVollmer 0.99963 0.99992\nset-p2 Method Sensitivity Pos. Pred.\nDBN-PF 0.92808 0.89527 GQRS 0.88134 0.85048 WABP 0.48544 0.45173 Pangerc 0.95737 0.94473 Johnson 0.92734 0.89265 Antink 0.91394 0.91829 De Cooman 0.88364 0.88341 Johannesen 0.91535 0.86260\nVollmer 0.91092 0.91334 MGH/MF Waveform Database Method Sensitivity Pos. Pred.\nDBN-PF 0.92853 0.93716 GQRS 0.80400 0.85934 Pangerc 0.88567 0.91749 Johnson 0.93832 0.91808\nOverall, the performance from GQRS is nigh impossible to beat on set-p1, precisely because the data is so clean and regular. It seems highly unlikely that there is any statistical significance to be derived from set-p1. All algorithms perform extremely well, except for WABP which suffers primarily from delay.\nIn regards to set-p2, we start to observe some differentiation. Comparing against the other entries, we see that our particle filter ends up outperforming all algorithms in regards to sensitivity except for Pangerc on set-p2. Our predictivity does suffer due to double annotations, but we still perform well overall. This is fairly strong evidence that our algorithm is capable of accurately combining the information from multiple channels of signals. In set-p2 we see that the performance of the Pangerc submission is substantially better than the others. This is likely due to their use of custom ECG and BP pulse detectors. Their QRS detector (repdet) provided a much improved performance over GQRS on set-p2 in particular, likely due to their inclusion of a step in the detector to identify double annotations (paced beats) (Silva et al. 2015) (Pangerc & Jager 2014). This step may account for Pangerc\u2019s improved performance over the algorithms that used GQRS.\nFinally, for the MGH/MF Waveform Database, we note that the particle filter outperforms all other algorithms in predictivity, and does very well in the sensitivity aspect as well with approximately .929\nsensitivity and .937 predictivity. In comparison to Pangerc and GQRS this is a great improvement, and in comparison to Johnson, we improve predictivity and only slightly lose out on sensitivity. Our algorithm was able to perform well on multiple datasets, which suggests that the improvement was fairly significant."}, {"heading": "6 Discussion", "text": "In this section, we discuss some of the interesting features of our algorithm. First, it is important to state that our algorithm is slower than other standard signal detection algorithms mainly because it is a simulation based filtering algorithm. In general, on the set-p1 (10 minutes signals), our algorithm takes 94.33 seconds on average to run on MATLAB r2015a (on a MacBook Pro with a 2.9 GHz Intel Core i5 processor and 8 GB 1867 MHz DDR3 memory), but it is worth noting that it is quite feasible for it to be implemented as an online algorithm. This is simply because particle filters process data sequentially.\nWe showed an example of double annotation in the previous section. In order to mitigate double annotations we would have to augment our model. One way to do this would be to incorporate information about the amplitude of the beat as an observation to determine if our algorithm should expect a double annotation, and determine peaks based off the new information. The model augmentations would likely be a few variables to probabilistically indicate the presence of double annotations and represent the amplitude of the signal.\nBecause there were so many other meaningful algorithms, it is worth comparing our own algorithm against the other top submissions. First of all, our algorithm inherently differed from the other approaches, and was the only one that focused on performing probabilistic inference on a Dynamic Bayesian Model. In terms of similarities, our algorithm slightly resembles the Johnson algorithm, because both algorithms use signal quality indices. However, not only do they focus on a deterministic switching, in the latter part of their algorithm they focus on the regularity of signals besides ECG and ABP as well. As a whole, our algorithm outperforms the others that relied on implementing a form of intelligent switching. Only Pangerc, who relied on their reimplemented beat detection algorithm (repdet) outperformed our own (Silva et al. 2015).\nAnother point of discussion is actually a point of differentiation between our algorithm and the others, which is our flexibility. With the flexibility of inputs, it becomes feasible to consider using alternate detectors to further strengthen our algorithm. One alternative would be to use the detectors used in the Pangerc submission, which should in theory greatly boost our performance.\nApart from performance concerns, we can consider the ease of implementation. Model based probabilistic inference approaches are becoming more and more appealing due to the emergence of probabilistic programming languages (PPL). A probabilistic programming language is a high-level language that makes it easy to represent probabilistic models and perform inference over them. PPLs enable domain experts who don\u2019t have enough experience in probability theory or machine learning to use state-ofthe-art machine learning methodologies to perform meaningful inferences (Gordon, Henzinger, Nori & Rajamani 2014). Because the problem we are analyzing is within the domain of physicians and clinicians, it would be best if we could empower them to create the physiological models they wished to represent on their own. As a proof of concept, we have also implemented our probabilistic model in a probabilistic modeling language called BLOG (Milch, Marthi, Russell, Sontag, Ong & Kolobov 2007). We used BLOG\u2019s particle filtering engine to perform the state estimation, and our results agree with our MATLAB implementation. For physicians, they simply need to implement their model, and use the particle filter (or any other estimation technique) implemented in BLOG. For a glimpse at the BLOG\nimplementation, refer to Appendix D.1."}, {"heading": "7 Conclusion", "text": "Based on our results, we find that using particle filtering on our DBN model performs quite well. It matches or outperforms a majority of the top submissions for the Physionet 2014 Challenge. In regards to the default Physionet beat detector GQRS, we improve in set-p2 by about 4% in both sensitivity and positive predictivity. As a whole, our particle filter serves as a strong proof of concept that a probabilistic model based inference approach can robustly detect heart beats.\nOur probabilistic model is not completely perfect, but some of our algorithm\u2019s advantages include: 1. Utilizes multi-channel information by incorporating the ECG-ABP peak delay (latency). 2. Flexible model - easy to incorporate new variables and relationships. 3. Flexible observations - easy to switch out GQRS and WABP for any other signal processing algorithms. 4. Consistent with a physiological perspective. 5. Can be implemented using a PPL. 6. Unlike many machine learning techniques, our model does not require a training set. Some of our disadvantages include: 1. Slower run time. One ten-minute signal takes approximately a minute and a half for the algorithm to run. 2. Depends on the signal processing methods heavily.\nIn terms of future work on the particle filter, we can incorporate the preprocessing mentioned in the other submissions for the sake of reducing noise. In addition, our algorithm only looks at one ECG and one ABP signal, when there are a multitude of other signals that could be utilized. Incorporating these would likely improve performance, as would initializing the delay based on one of the methods described in the other submissions. In the far future, this algorithm could be tweaked to directly detect arrhythmia. By placing emphasis on the artifacts and introducing arrhythmia variables, it would be possible to develop beliefs regarding these cardiac abnormalities. Since we have improved the detection rate for heart beats, it stands to reason we can improve the detection rate for the arrhythmia as well as for other problems that can be modelled physiologically."}, {"heading": "8 Acknowledgements", "text": "We are thankful to Xiao Hu, Quan Ding, Yong Bai, Rebeca Salas-Boni and Daniel Schindler for helpful discussions."}, {"heading": "A Propagation Model", "text": "The propagation model (transition model) encodes interdependent evolution of our relevant physiological variables over time. The structure of the dependencies is observable in the figure in section 5."}, {"heading": "A.1 RestHR", "text": "RestHR is a real-valued static variable that represents the resting heart of a particular patient, which is simply the patient\u2019s expected heart rate while at rest. The prior value is a Gaussian around the average heart rate as determined by patient demographics. It obeys the following static (i.e., identity) propagation function:\nRestHRt+1\u2190 RestHRt (4)"}, {"heading": "A.1.1 Latency", "text": "In Figure 10, it is possible to see that the heartbeats fall on, or very near to, the R peaks in the ECG\u2019s QRS signals. Conversely, in the ABP signals the heart beat does not fall on the peaks pictured, but instead it falls a reliable distance before the peaks. In our model, Latency is an integer-valued static variable that represents this relationship between heart beats and the blood pressure. The prior value is a Gaussian\naround 200 milliseconds. It obeys the following propagation function:\nLatencyt+1\u2190 Latencyt (5)"}, {"heading": "A.2 TrueHR", "text": "TrueHR is a real-valued variable that represents the heart rate of a patient at the current time. The prior value of the TrueHR starts off as a gaussian around the RestHR. Here norm means sampling from a gaussian distribution with a given \u00b5 and \u03c3 .\nTrueHR0\u2190 RestingHR0 +5\u2217norm(\u00b5 = 0,\u03c3 = 1) (6)\nSince the true heart rate of a patient might vary over a few minutes where the resting heart rate might vary over a few months, the true heart rate is not a static variable. It obeys the following propagation function:\nTrueHRt+1\u2190 .8\u2217TrueHRt + .2\u2217RestHRt +15\u2217norm(\u00b5 = 0,\u03c3 = 1) (7)"}, {"heading": "A.3 ECGPeak", "text": "ECGPeak is a boolean-valued variable that is 1 if there should be a beat annotated at the current timestep and 0 otherwise. ECGPeak\u2019s prior starts as 1 with a small probability (currently .01). It obeys the following propagation function:\nECGPeakt+1\u2190 Bernoulli(P) (8)\nWe calculate P dynamically. As time progresses, the P parameter will change depending on the current values of the TrueHR and ECGLastPeak. First we define the difference between the current timestep and the lastpeak as di f f = t\u2212ECGLastPeakt . Then we define BeatWindowt = 60/(window\u2217TrueHRt), which is the number of windows per beat based on the current heart rate.\nP = binopd f (x = max(mod(di f f ,BeatWindowt),mod(di f f ,BeatWindowt)+BeatWindowt),\nn = 3/2\u2217BeatWindowt , p = 2/3) (9)\nThus, we represent the probability according to repeated binomial distributions, as in figure 11. The reason for this calculation is to create a few important properties. The first is to create a memory that allows us to believe beats should occur based on the TrueHR and to not preclude beats even if we don\u2019t believe there to be a beat earlier on. It also has the convenient property of generally not allowing us to double annotate beats, because it\u2019s unlikely the heart will beat twice in a short span of time. The other reason is that the binomial distributed random variable X with parameters n and p has an E[X ] = np and Var[X ] = np(1\u2212 p). This means that we can control the expected value in our case to be BeatWindow and the variance to be 1/3\u2217BeatWindow, using our values of n and p."}, {"heading": "A.4 ECGLastPeak", "text": "ECGLastPeak is an integer-valued variable that represents the last time we believed there was a peak based on ECG. The prior for ECGLastPeak is a uniform distribution in the range of integers between [\u2212BeatWindow,\u22121]. The ECGLastPeak helps to shift the expected location of all of the heartbeats,\nbecause of the multimodal value of P in the ECGPeak. The uniform sampling means that the prior believes the expected heartbeats may be shifted to cover all possible initializations. It obeys the following propagation function:\nECGLastPeakt+1 = {\nt +1 i f ECGPeakt+1 == 1 ECGLastPeakt i f ECGPeakt+1 == 0\nIn words, this equation states that the ECGLastPeak will change purely to record the last time ECGPeak was 1."}, {"heading": "A.5 ABPPeak", "text": "ABPPeak is a boolean-valued variable that represents whether there is a peak based on the ABP and the ECG. Since theoretically the ABPPeak should align with the ECGPeak while accounting for the Latency, it obeys the following propagation function (even for the prior):\nABPPeakt+1\u2190 (t == ECGLastPeakt +ParticleMean(Latencyt)) (10)\nHere, ParticleMean means that we take the mean across all the particles. This is admittedly unorthodox, but it means that we ameliorate the issue of double and triple annotations in adjacent locations for the ABPPeak. If the particle filter had a while to learn the latency and let it converge, then this fix would be unnecessary, but, as is, this fix means that the particle filter\u2019s particles will not overly diverge at the ABPPeak."}, {"heading": "A.6 ABPLastPeak", "text": "ABPLastPeak is an integer-valued variable that represents the last time we believed there was a peak based on both ECG and ABP. The prior starts off as ECGLastPeak0 +Latency0. It obeys the following propagation function:\nABPLastPeakt+1 = {\nt +1 i f ABPPeakt+1 == 1 ABPLastPeakt i f ABPPeakt+1 == 0"}, {"heading": "A.7 ECGArtifact and ABPArtifact", "text": "ECGArti f act and ABPArti f act are boolean-valued variables that represents whether we believe there is currently an artifact associated with either ECGPeak or ABPPeak, respectively. Their prior and propagations behavior is exactly the same. 1 represents an artifact and 0 represents no artifact. The prior belief for the artifacts starts off as 1 with a small probability (currently .01) It obeys the following propagation function:\nArti f actt+1\u2190 Bernoulli(PA) (11)\nHere, PA represents the Pr(Arti f actt+1|Arti f actt), which is determined by the following conditional probability table:\nArti f actt Arti f actt+1 Pr(Arti f actt+1|Arti f actt) 1 1 0.99 1 0 0.01 0 1 0.01 0 0 0.99\nThis table represents a form of inertia. Given that there is currently an artifact, the probability that there continues to be an artifact is high. Likewise, it there is currently an absence of an artifact, the probability that there continues to be an absence is similarly high."}, {"heading": "B Observation Model", "text": "The observation model (sensor model) encodes our beliefs about the functions we use to derive observations and the probability that the observations correspond to the current states. The structure of the dependencies is observable in the figure in section 5."}, {"heading": "B.1 Annotation Observations", "text": "These are the ABPAnn and the ECGAnn variables in the model. The observations are derived by using the WABP and GQRS algorithms that are provided by Physionet. The algorithms simply use a specified window size and see if the signal processing algorithms place any annotations within a given window. If so, then the Ann observation is set to be true (1), and otherwise it\u2019s set to be false (0). Then, we define the probability of the annotations given the states according to the following probability table:\nPeak Arti f act Ann Pr(Ann|States) 0 1 1 NormBeatProb 0 1 0 1\u2212NormBeatProb 0 0 1 BeatProb 0 0 0 1\u2212BeatProb 1 1 1 0.7 1 1 0 0.3 1 0 1 0.99 1 0 0 0.01\nIn the case that there is a peak and there is no artifact, then the belief that there should be an annotation is quite high (.99), because there is high likelihood of signal accuracy. Correspondingly the belief that there should not be an annotation is quite low (.01).\nIn the case that there is a peak and there is an artifact, then the belief that there should be an annotation is lower than without an artifact (.7), because the artifact means that we are not entirely able to trust the signal. Correspondingly the belief that there should not be an annotation is higher than without an artifact (.3). In general when we fix the other states, the presence of an artifact makes our annotation beliefs less certain.\nNext in the case that there is no peak and no artifact, BeatProb should represent the likelihood that the observation can be trusted. Since the probability of the annotation occuring in this case truly depends on the LastPeak and the TrueHR, we end up calculating it in the same way as the P for the ECGPeak. First we define the difference between the current timestep and the lastpeak as di f f = t \u2212 LastPeak. Then we define BeatWindow = 60/(window\u2217TrueHR), which is the number of windows per beat based on the current heart rate.\nBeatProb = binopd f (x = max(mod(di f f ,BeatWindow),mod(di f f ,BeatWindow)+BeatWindow),\nn = 3/2\u2217BeatWindow, p = 2/3) (12)\nThen, we know that the probability of the annotation not occuring will simply be 1\u2212BeatProb. Finally in the case that there is no peak and an artifact, we can apply what we used earlier and say that the presence of an artifact makes our belief about the annotation less certain. So if we strongly believe there would be an annotation, in the case of an artifact, we only moderately believe there would be an annotation. Likewise if we don\u2019t believe there would be an annotation, then an artifact would make us moderately not believe in an annotation. This means that we can simply represent the NormBeatProb according to the following definition:\nNormBeatProb = mean(.5,BeatProb) (13)"}, {"heading": "C Heart Rate Observations", "text": "These are the WABPHR and the GQRSHR variables in the model (collectively called HRobs variables). The observations are derived by using the WABP and GQRS algorithms that are provided by Physionet. The algorithms simply use a specified window size and have a sliding window that computes the local heart rate. The HRobs observations are set accordingly. Then, we define the probability of the observations given the states according to the following:\nPr(HRobs|States) = normpd f (TrueHR,HRobs,1/4\u2217HRobs) (14)\nHere, normpd f corresponds to the probability density function of a Gaussian random variable with the given parameters."}, {"heading": "D SQI Observations", "text": "These correspond to the ECQSQI and ABPSQI variables. ECGSQI is calculated by taking two signal processing algorithms and comparing them beat by beat. It was derived using the ecgsqi function that was\ndeveloped in another Physionet submission (Johnson et al. 2014). In particular, we use gqrs (unpublished algorithm optimized for sensitivity) and wqrs (open source algorithm optimized for adult human ECGs). The number of beats that match between the two algorithms is reported as a real number between 0 and 1. ABPSQI is calculated by checking to see if the pressure, the mean arterial pressure, the heart rate, the pulse pressure, and a variety of other physiologic details are within normal ranges or not. If everything is in a normal range, ABPSQI is 1, otherwise it is 0. This was also derived from the abpsqi function in the same Physionet submission, which was in turn borrowing from other publications (Sun et al. 2005) (Sun 2006).\nThe SQI observations are used to choose which observations to depend on. If the ECGSQI < .8 and ABPSQI == 1, then we weight based on the ABP annotations and heart rates, otherwise we weight based on the ECG annotations and heart rates."}, {"heading": "D.1 BLOG Code - Propagation Functions", "text": "The following code is the propagation model represented in the BLOG language:\n// Functions\nrandom Real Rest_HR(Timestep t) ~\nif t == @0 then\nGaussian(avg_hr, 10)\nelse\nRest_HR(prev(t));\nrandom Real True_HR(Timestep t) ~\nif t == @0 then\nGaussian(Rest_HR(t), 5)\nelse\nGaussian(.2*Rest_HR(prev(t)) + .8*True_HR(prev(t)), 1);\nrandom Integer ECG_Art(Timestep t) ~\nif t == @0 then\nBernoulli(.01)\nelse case ECG_Art(prev(t)) in {\n0 -> Bernoulli(.01),\n1 -> Bernoulli(.99)\n};\nrandom Integer ECG_Peak(Timestep t) ~\nif t == @0 then\nBernoulli(.01)\nelse\nBernoulli(binompdf(round(60/(w_off*True_HR(prev(t)))), 2.0/3.0,\n(toInt(t)-ECG_Last_Peak(prev(t)))%round(60/(w_off*True_HR(prev(t))))));\nrandom Integer ECG_Last_Peak(Timestep t) ~\nif t == @0 then\nUniformInt(-round(60/(w_off*True_HR(t))), -1)\nelse\nif ECG_Peak(t) == 1 then\ntoInt(t)\nelse\nECG_Last_Peak(prev(t));\nrandom Integer ABP_Art(Timestep t) ~\nif t == @0 then\nBernoulli(.01)\nelse case ABP_Art(prev(t)) in {\n0 -> Bernoulli(.01),\n1 -> Bernoulli(.99)\n};\nrandom Integer ABP_Peak(Timestep t) ~\nif (ECG_Last_Peak(t) + Latency) == toInt(t) then\n1\nelse\n0;\nrandom Integer ABP_Last_Peak(Timestep t) ~\nif t == @0 then\nECG_Last_Peak(t) + Latency\nelse\nif ABP_Peak(t) == 1 then\ntoInt(t)\nelse\nABP_Last_Peak(prev(t));"}, {"heading": "D.2 BLOG Code - Observation Functions", "text": "The following code is the observation model represented in the BLOG language:\n// Functions\nrandom Integer ECG_Ann(Timestep t) ~\nif ECG_Peak(t) == 1 then\nif ECG_Art(t) == 1 then\nBernoulli(.7)\nelse\nBernoulli(.9)\nelse\nif ECG_Art(t) == 1 then\nBernoulli((binompdf(round(60/(w_off*True_HR(t))), 2.0/3.0,\n(toInt(t)-ECG_Last_Peak(t))%round(60/(w_off*True_HR(t)))) + .5)/2)\nelse\nBernoulli(binompdf(round(60/(w_off*True_HR(t))), 2.0/3.0,\n(toInt(t)-ECG_Last_Peak(t))%round(60/(w_off*True_HR(t)))));\nrandom Real ECG_HR(Timestep t) ~\nGaussian(True_HR(t), abs(True_HR(t))/4);\nrandom Integer ABP_Ann(Timestep t) ~\nif ABP_Peak(t) == 1 then\nif ABP_Art(t) == 1 then\nBernoulli(.7)\nelse\nBernoulli(.9)\nelse\nif ABP_Art(t) == 1 then\nBernoulli((binompdf(round(60/(w_off*True_HR(t))), 2.0/3.0,\n(toInt(t)-ABP_Last_Peak(t))%round(60/(w_off*True_HR(t)))) + .5)/2)\nelse\nBernoulli(binompdf(round(60/(w_off*True_HR(t))), 2.0/3.0,\n(toInt(t)-ABP_Last_Peak(t))%round(60/(w_off*True_HR(t)))));\nrandom Real ABP_HR(Timestep t) ~\nGaussian(True_HR(t), abs(True_HR(t))/4);"}, {"heading": "D.3 Running BLOG", "text": "The following is the shell script we ran to execute the blog particle filter.\n#!/bin/sh\ntime ./../../blog/dblog \\\nprop_fn.dblog \\\nquery.dblog \\\nobs_fn.dblog \\\nobs.dblog \\\n-n 1000 -o out.json\nThe query.dblog and obs.dblog files contained the data we wanted to load. This command ran the particle filter with 1000 particles and put the output into the out.json file. Note: we will be making the Matlab and BLOG code we wrote available at a later date."}], "references": [{"title": "A tutorial on particle filters for online nonlinear/non-gaussian bayesian tracking", "author": ["M.S. Arulampalam", "S. Maskell", "N. Gordon", "T. Clapp"], "venue": "Signal Processing, IEEE Transactions", "citeRegEx": "Arulampalam et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Arulampalam et al\\.", "year": 2002}, {"title": "Redesigning hospital alarms for patient", "author": ["V. Chopra", "L.F. McMahon"], "venue": null, "citeRegEx": "Chopra and McMahon,? \\Q2014\\E", "shortCiteRegEx": "Chopra and McMahon", "year": 2014}, {"title": "A tutorial on particle filtering and smoothing: fifteen years later, The Oxford Handbook of Nonlinear Filtering", "author": ["A. Doucet", "A.M. Johansen"], "venue": null, "citeRegEx": "Doucet and Johansen,? \\Q2011\\E", "shortCiteRegEx": "Doucet and Johansen", "year": 2011}, {"title": "Insights into the problem of alarm fatigue with physiologic monitor devices: A comprehensive observational study of consecutive intensive care unit patients, PLoS ONE", "author": ["B.J. Drew", "P. Harris", "J.K. Z\u00e8greHemsey", "T. Mammone", "D. Schindler", "R. SalasBoni", "Y. Bai", "A. Tinoco", "Q. Ding", "X. Hu"], "venue": null, "citeRegEx": "Drew et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Drew et al\\.", "year": 2014}, {"title": "Multimodal sensor fusion of cardiac signals via blind deconvolution: A source-filter approach, Computing in Cardiology", "author": ["C. Hoog Antink", "C. Bruser", "S. Leonhardt"], "venue": null, "citeRegEx": "Antink et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Antink et al\\.", "year": 2014}, {"title": "Robust algorithm to locate heart beats from multiple physiological waveforms, Computing in Cardiology", "author": ["L. Johannesen", "J. Vicente", "C.G. Scully", "L. Galeotti", "D.G. Strauss"], "venue": null, "citeRegEx": "Johannesen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Johannesen et al\\.", "year": 2014}, {"title": "R- peak estimation using multimodal lead switching", "author": ["A.E. Johnson", "J. Bechar", "F. Andreotti", "G.D. Clifford", "J. Oster"], "venue": "Computing in Cardiology", "citeRegEx": "Johnson et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2014}, {"title": "Hospitals rank alarm fatigue as top patient safety concern, Fierce Healthcare", "author": ["I. MacDonald"], "venue": null, "citeRegEx": "MacDonald,? \\Q2007\\E", "shortCiteRegEx": "MacDonald", "year": 2007}, {"title": "Blog: Probabilistic models with unknown objects, Introduction to Statistical Relational Learning", "author": ["B. Milch", "B. Marthi", "S. Russell", "D. Sontag", "D.L. Ong", "A. Kolobov"], "venue": null, "citeRegEx": "Milch et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Milch et al\\.", "year": 2007}, {"title": "Robust detection of heart beats in multimodal data: The physionet/computing in cardiology challenge", "author": ["G. Moody", "B. Moody", "I. Silva"], "venue": null, "citeRegEx": "Moody et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Moody et al\\.", "year": 2014}, {"title": "Robust detection of heart beats in multimodal data using integer multiplier digital filters and morphological algorithms, Computing in Cardiology", "author": ["U. Pangerc", "F. Jager"], "venue": null, "citeRegEx": "Pangerc and Jager,? \\Q2014\\E", "shortCiteRegEx": "Pangerc and Jager", "year": 2014}, {"title": "Robust detection of heart beats in multimodal data, Physiological Measurement", "author": ["I. Silva", "B. Moody", "J. Behar", "A. Johnson", "J. Oster", "G.D. Clifford", "G. Moody"], "venue": null, "citeRegEx": "Silva et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Silva et al\\.", "year": 2015}, {"title": "An open-source toolbox for analysing and processing physionet databases in matlab and octave", "author": ["I. Silva", "G. Moody"], "venue": "Journal of Open Research Software", "citeRegEx": "Silva and Moody,? \\Q2014\\E", "shortCiteRegEx": "Silva and Moody", "year": 2014}, {"title": "Cardiac output estimation using arterial blood pressure waveforms", "author": ["J.X. Sun"], "venue": null, "citeRegEx": "Sun,? \\Q2006\\E", "shortCiteRegEx": "Sun", "year": 2006}, {"title": "Estimating cardiac output from arterial blood pressure waveforms: a critical evaluation using the mimic ii database, Computing in Cardiology", "author": ["J.X. Sun", "A.T. Reisner", "M. Saeed", "R.G. Mark"], "venue": null, "citeRegEx": "Sun et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2005}, {"title": "Robust detection of heart beats using dynamic thresholds and moving windows, Computing in Cardiology", "author": ["M. Vollmer"], "venue": null, "citeRegEx": "Vollmer,? \\Q2014\\E", "shortCiteRegEx": "Vollmer", "year": 2014}, {"title": "The massachusetts general hospital-marquette foundation hemodynamic and electrocardiographic database \u2013 comprehensive collection of critical care waveforms", "author": ["J.P. Welch", "P.J. Ford", "R.S. Teplick", "R.M. Rubsamen"], "venue": "J Clinical Monitoring", "citeRegEx": "Welch et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Welch et al\\.", "year": 1991}, {"title": "Effects of vasoactive drugs on the relationship between ecg-pulse wave delay time and arterial blood pressure in icu patients, Computing in Cardiology", "author": ["W. Zong", "G. Moody", "R. Mark"], "venue": null, "citeRegEx": "Zong et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Zong et al\\.", "year": 1998}], "referenceMentions": [{"referenceID": 7, "context": "One article cites alarm fatigue as one of the top patient safety concerns in hospitals (MacDonald 2007).", "startOffset": 87, "endOffset": 103}, {"referenceID": 15, "context": "The top six algorithms that were submitted to the Physionet 2014 Challenge, ordered by their performance in Physionet are Pangerc (Pangerc & Jager 2014), Johnson (Johnson, Bechar, Andreotti, Clifford & Oster 2014), Antink (Hoog Antink, Bruser & Leonhardt 2014), De Cooman (De Cooman, Goovaerts, Varon, Widjaja & Huffel 2014), Johannesen (Johannesen, Vicente, Scully, Galeotti & Strauss 2014), and Vollmer (Vollmer 2014).", "startOffset": 405, "endOffset": 419}, {"referenceID": 0, "context": "quential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2008).", "startOffset": 72, "endOffset": 125}, {"referenceID": 6, "context": "The ECGSQI is calculated by comparing the results from two of Physionet\u2019s ECG signal detectors, and the ABPSQI is calculated by checking that the detections are within certain physiological boundaries (Johnson et al. 2014) (Sun, Reisner, Saeed & Mark 2005) (Sun 2006).", "startOffset": 201, "endOffset": 222}, {"referenceID": 13, "context": "2014) (Sun, Reisner, Saeed & Mark 2005) (Sun 2006).", "startOffset": 40, "endOffset": 50}, {"referenceID": 11, "context": "Their QRS detector (repdet) provided a much improved performance over GQRS on set-p2 in particular, likely due to their inclusion of a step in the detector to identify double annotations (paced beats) (Silva et al. 2015) (Pangerc & Jager 2014).", "startOffset": 201, "endOffset": 220}, {"referenceID": 11, "context": "Only Pangerc, who relied on their reimplemented beat detection algorithm (repdet) outperformed our own (Silva et al. 2015).", "startOffset": 103, "endOffset": 122}], "year": 2015, "abstractText": "The parameters of temporal models such as dynamic Bayesian networks may be viewed in the Bayesian context as static or atemporal variables that influence the transition probabilities at every time step. Particle filters fail for models that include such variables, while methods that use Gibbs sampling of parameter variables may incur a per-sample cost that grows linearly with the length of the observation sequence. Storvik (2002) devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant. In this paper, we demonstrate a connection between Storvik\u2019s filter and a Kalman filter in parameter space and establish more general conditions under which it works. Drawing on an analogy to the extended Kalman filter, we develop and analyze, both theoretically and experimentally, a Taylor approximation to the parameter posterior that allows Storvik\u2019s method to be applied to a broader class of models. Our experiments on both synthetic examples and real applications show improvement over existing methods.", "creator": "LaTeX with hyperref package"}}}