{"id": "1601.06971", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Jan-2016", "title": "Sentiment Analysis of Twitter Data: A Survey of Techniques", "abstract": "As Web technology advances and grows, there is an enormous amount of data available on the Web for Internet users, and a lot of data is also being generated; the Internet has become a platform for online learning, sharing ideas and exchanging opinions; social networks like Twitter, Facebook, Google + are rapidly gaining popularity because they allow people to share and express their views on topics, have discussions with different communities, or post messages around the world. There has been a lot of work in the field of mood analysis of Twitter data. This survey focuses mainly on the mood analysis of Twitter data, which is helpful for analyzing the information in tweets where opinions are highly unstructured, heterogeneous, and in some cases either positive or negative or neutral. In this essay, we offer a survey and a comparative analysis of existing opinion-forming techniques such as machine learning and lexicon-based approaches, along with valuation metrics.", "histories": [["v1", "Tue, 26 Jan 2016 10:44:30 GMT  (363kb)", "http://arxiv.org/abs/1601.06971v1", "7 figures, 10 tables"], ["v2", "Tue, 16 Feb 2016 04:53:56 GMT  (0kb,I)", "http://arxiv.org/abs/1601.06971v2", "This paper has been withdrawn by the author due to a crucial changes in results section. It had some inconsistency in results. It requires major changes and revisions in methods discussed. There are some major errors in effects of methods discussed"], ["v3", "Fri, 22 Apr 2016 09:43:11 GMT  (701kb)", "http://arxiv.org/abs/1601.06971v3", "7 figures, 10 tables"]], "COMMENTS": "7 figures, 10 tables", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["vishal a kharde", "prof sheetal sonawane"], "accepted": false, "id": "1601.06971"}, "pdf": {"name": "1601.06971.pdf", "metadata": {"source": "CRF", "title": "Sentiment Analysis of Twitter Data :A Survey of Techniques", "authors": [], "emails": ["vishal.kharde@india.com;", "sssonawane@pict.edu"], "sections": [{"heading": null, "text": "Sentiment Analysis of Twitter Data :A Survey of Techniques\nVishal.A.Kharde1, Prof.S.S.Sonawane2 Department of Computer Engg,\nPune Institute of Computer Technology,Pune University of Pune (India)\n1vishal.kharde@india.com; 2sssonawane@pict.edu Abstract: With the advancement of web technology and its growth, there is a huge volume of data present in the web for internet users and a lot of data is generated too. Internet has become a platform for online learning, exchanging ideas and sharing opinions. Social networking sites like Twitter, Facebook, Google+ are rapidly gaining popularity as they allow people to share and express their views about topics,have discussion with different communities, or post messages across the world. There has been lot of work in the field of sentiment analysis of twitter data. This survey focuses mainly on sentiment analysis of twitter data which is helpful to analyze the information in the tweets where opinions are highly unstructured, heterogeneous and are either positive or negative, or neutral in some cases. In this paper, we provide a survey and a comparative analyses of existing techniques for opinion mining like machine learning and lexicon-based approaches, together with evaluation metrics. Using various machine learning algorithms like Naive Bayes, Max Entropy, and Support Vector Machine, we provide a research on twitter data streams. We have also discussed general challenges and applications of Sentiment Analysis on Twitter. Index Terms: Twitter, Sentiment analysis (SA), Opinion mining, Machine learning, Naive Bayes (NB), Maximum Entropy, Support Vector Machine (SVM).\nI. INTRODUCTION\nNowadays, the age of Internet has changed the way people express their views, opinions. It is now mainly done through blog posts, online forums, product review websites, social media ,etc. Nowadays, millions of people are using social network sites like Facebook, Twitter, Google Plus, etc. to express their emotions, opinion and share views about their daily lives. Through the online communities, we get an interactive media where consumers inform and influence others through forums. Social media is generating a large volume of sentiment rich data in the form of tweets, status updates, blog posts, comments, reviews, etc. Moreover, social media provides an opportunity for businesses by giving a platform to connect with their customers for advertising. People mostly depend upon user generated content over online to a great extent for decision making. For e.g. if someone wants to buy a product or wants to use any service, then they firstly look up its reviews online, discuss about it on social media before taking a decision. The amount of content generated by users is too vast for a normal user to analyze. So\nthere is a need to automate this, various sentiment analysis techniques are widely used. Sentiment analysis (SA) tells user whether the information about the product is satisfactory or not before they buy it. Marketers and firms use this analysis data to understand about their products or services in such a way that it can be offered as per the user\u2019s requirements. Textual Information retrieval techniques mainly focus on processing, searching or analyzing the factual data present. Facts have an objective component but, there are some other textual contents which express subjective characteristics. These contents are mainly opinions, sentiments, appraisals, attitudes, and emotions, which form the core of Sentiment Analysis (SA). It offers many challenging opportunities to develop new applications, mailnly due to the huge growth of available information on online sources like blogs and social networks. For example, recommendations of items proposed by a recommendation system can be predicted by taking into account considerations such as positive or negative opinions about those items by making use of SA."}, {"heading": "II. SENTIMENT ANALYSIS", "text": "Sentiment analysis can be defined as a process that automates mining of attitudes, opinions, views and emotions from text, speech, tweets and database sources through Natural Language Processing (NLP). Sentiment analysis involves classifying opinions in text into categories like \"positive\" or \"negative\" or \"neutral\". It's also referred as subjectivity analysis, opinion mining, and appraisal extraction. The words opinion, sentiment, view and belief are used interchangeably but there are differences between them. \u2022 Opinion: A conclusion open to dispute (because different\nexperts have different opinions ) \u2022 View: subjective opinion \u2022 Belief: deliberate acceptance and intellectual assent \u2022 Sentiment: opinion representing one\u2018s feelings An example for terminologies for Sentiment Analysis is as given below,\nSentiment Analysis is a term that include many tasks such as sentiment extraction, sentiment classification, subjectivity classification, summarization of opinions or opinion spam detection, among others. It aims to analyze people's sentiments, , attitudes, opinions emotions, etc. towards elements such as, products, individuals, topics ,organizations, and services. Mathematically we can represent an opinion as a quintuple (o, f, so, h, t), where o = object; f = feature of the object o; so = orientation or polarity of the opinion on feature f of object o; h = opinion holder; t = time when the opinion is expressed. Object: An entity which can be a, person, event, product ,organization, or topic Feature: An attribute (or a part) of the object with respect to which evaluation is made. Opinion orientation or polarity: The orientation of an opinion on a feature f represent whether the opinion is positive, negative or neutral . Opinion holder: The holder of an opinion is the person or organization or an entity that expresses the opinion . In recent years a lot of work has been done in the field of \u201cSentiment Analysis on Twitter\u201c by number of researchers. In its early stage it was intended for binary classification which assigns opinions or reviews to bipolar classes such as positive or negative only. Pak and Paroubek(2010) [1] proposed a model to classify the tweets as objective, positive and negative. They created a twitter corpus by collecting tweets using Twitter API and automatically annotating those tweets using emoticons. Using that corpus, theydeveloped a sentiment classifier based on the multinomial Naive Bayes method that uses features like Ngram and POS-tags. The training set they used was less efficient since it contains only tweets having emoticons. Parikh and Movassate(2009) [2] implemented two models, a Naive Bayes bigram model and a Maximum Entropy model to classify tweets. They found that the Naive Bayes classifiers worked much better than the Maximum Entropy model. Go and L.Huang (2009) [3] proposed a solution for sentiment analysis for twitter data by using distant supervision, in which their training data consisted of tweets with emoticons which served as noisy labels. They build\nmodels using Naive Bayes, MaxEnt and Support Vector Machines (SVM). Their feature space consisted of unigrams, bigrams and POS. They concluded that SVM outperformed other models and that unigram were more effective as features. Barbosa et al.(2010) [4] designed a two phase automatic sentiment analysis method for classifying tweets. They classified tweets as objective or subjective and then in second phase, the subjective tweets were classified as positive or negative. The feature space used included retweets, hashtags, link, punctuation and exclamation marks in conjunction with features like prior polarity of words and POS. Bifet and Frank(2010) [5] used Twitter streaming data provided by Firehouse API , which gave all messages from every user which are publicly available in real-time. They experimented multinomial naive Bayes, stochastic gradient descent, and the Hoeffding tree. They arrived at a conclusion that SGD-based model, when used with an appropriate learning rate was the better than the rest used. Agarwal et al. (2011)[6] developed a 3-way model for classifying sentiment into positive, negative and neutral classes. They experimented with models such as: unigram model, a feature based model and a tree kernel based model. For tree kernel based model they represented tweets as a tree.The feature based model uses 100 features and the unigram model uses over 10,000 features. They arrived on a conclusion that features which combine prior polarity of words with their parts-of-speech(pos) tags are most important and plays a major role in the classification task. The tree kernel based model outperformed the other two models. Davidov et al.,(2010) [7] proposed a approach to utilize Twitter user-defined hastags in tweets as a classification of sentiment type using punctuation, single words, n-grams and patterns as different feature types, which are then combined into a single feature vector for sentiment classification. They made use of K-Nearest Neighbor strategy to assign sentiment labels by constructing a feature vector for each example in the training and test set. Po-Wei Liang et.al.(2014) [8] used Twitter API to collect twitter data. Their training data falls in three different categories (camera, movie , mobile). The data is labeled as positive, negative and non-opinions. Tweets containing opinions were filtered. Unigram Naive Bayes model was implemented and the Naive Bayes simplifying independence assumption was employed. They also eliminated useless features by using the Mutual Information and Chi square feature extraction method. Finally , the orientation of an tweet is predicted. i.e. positive or negative. Pablo et. al. [9] presented variations of Naive Bayes classifiers for detecting polarity of English tweets. Two different variants of Naive Bayes classifiers were built namely Baseline (trained to classify tweets as positive, negative and neutral), and Binary (makes use of a polarity lexicon and classifies as positive and negative. Neutral tweets neglected). The features considered by classifiers were Lemmas (nouns, verbs, adjectives and adverbs), Polarity\nLexicons, and Multiword from different sources and Valence Shifters. Turney et al [11] used bag-of-words method for sentiment analysis in which the relationships between words was not at all considered and a document is represented as just a collection of words. To determine the sentiment for the whole document, sentiments of every word was determined and those values are united with some aggregation functions. Kamps et al. [12] used the lexical database WordNet to determine the emotional content of a word along different dimensions. They developed a distance metric on WordNet and determined semantic polarity of adjectives. Xia et al. [13] used an ensemble framework for Sentiment Classification which is obtained by combining various feature sets and classification techniques. In thier work, they used two types of feature sets (Part-of-speech information and Wordrelations) and three base classifiers (Naive Bayes, Maximum Entropy and Support Vector Machines) . They applied ensemble approaches like fixed combination, weighted combination and Meta-classifier combination for sentiment classification and obtained better accuracy. Luo et. al. [13] highlighted the challenges and an efficient techniques to mine opinions from Twitter tweets. Spam and wildly varying language makes opinion retrieval within Twitter challenging task. A General model for sentiment analysis is as follows,\nFig.1. Sentiment Analysis Architecture Following are the phases required for sentiment analysis of twitter data, A. Pre-processing of the datasets:\nA tweet contains a lot of opinions about the data which are expressed in different ways by different users .The twitter dataset used in this survey work is already labeled into two classes viz. negative and positive polarity and thus the sentiment analysis of the data becomes easy to observe the effect of various features. The raw data having polarity is highly susceptible to inconsistency and redundancy. Preprocessing of tweet include following points, \u2022 Remove all URLs (e.g. www.xyz.com), hash tags (e.g. #topic), targets (@username) \u2022 Correct the spellings; sequence of repeated characters is to be handled \u2022 Replace all the emoticons with their sentiment. \u2022 Remove all punctuations ,symbols,numbers \u2022 Using a POS tagger, the NL Processor linguistic Parser , we\ntag the adjectives, verbs and adverbs \u2022 Remove Stop Words \u2022 Expand Acronyms(we can use a acronym dictionary) \u2022 Remove Non-English Tweets"}, {"heading": "B. Feature Extraction", "text": "The preprocessed dataset has many distinctive properties.In the feature extraction method,we extract the aspects from the processed dataset. Later this aspect are used to compute the positive and negative polarity in a sentence which is useful for determining the opinion of the individuals using models like unigram,bigram [18].\nMachine learning techniques require representing the key features of text or documents for processing. These key features are c o n s i d e r e d as feature vectors which are used for the classification task.. Some examples features that have been reported in literature are:\n1. Words And Their Frequencies: Unigrams, bigrams and n-gram models with their frequency counts are considered as features. There has been more reseach on using word presence rather than frequencies to\nbetter describe this feature. Pang et al. [23] showed better results by using presence instead of frequencies. 2. Parts Of Speech Tags Parts of speech like adjectives, adverbs and some groups of verbs and nouns are good indicators of subjectivity and sentiment. We can generate syntactic dependency patterns by parsing or dependency trees. 3. Opinion Words And Phrases Apart from specific words, some phrases and idioms which convey sentiments can be used as features. e.g. cost someone an arm and leg. 4. Position Of Terms The position of a term within a text can affect on how much the term makes difference in overall sentiment of the text. 5. Negation Negation is an important but difficult feature to interpret. The presence of a negation usually changes the polarity of the opinion.. e.g., no doubt android is best in the market currently. 6. Syntax Syntactic patterns like collocations are used as features to learn subjectivity patterns by many of the researchers."}, {"heading": "C. Training:", "text": "Supervised learning is an important technique for solving classification problems. Training the classifier makes it easier for future predictions for unknown data."}, {"heading": "D. Classification:", "text": ""}, {"heading": "1. Naive Bayes:", "text": "It is a probabilistic classifier and can learn the pattern of examining a set of documents that has been categorized [9]. It compares the contents with the list of words to classify the documents to their right category or class. Let d be the tweet and c* be a class that is assigned to d, where\nFrom the above equation, \u2018f\u2019 is a \u2018feature\u2019, count of feature (fi) is denoted with ni(d) and is present in d which represents a tweet. Here, m denotes no. of features.\nParameters P(c) and P(f|c) are computed through maximum likelihood estimates, and smoothing is utilized for unseen features. To train and classify using Na\u00efve Bayes Machine Learning technique ,we can use the Python NLTK library . 2. Maximum Entropy:\nIn Maximum Entropy Classifier, no assumptions are taken regarding the relationship inbetween the features extracted from dataset. This classifier always tries to maximize the entropy of the system by estimating the conditional distribution of the class label. Maximum entropy even handles overlap feature and is same as logistic regression method which finds the distribution over classes. The conditional distribution is defined as MaxEnt makes no independence assumptions for its features, unlike Naive Bayes. The model is represented by the following:\nWhere c is the class,d is the tweet and \u03bbi is the weight vector.The weight vectors decide the importance of a feature in classification. 3. Support Vector Machine:\nSupport vector machine analyzes the data, define the decision boundaries and uses the kernels for computation which are performed in input space[15]. The input data are two sets of vectors of size m each. Then every data which represented as a vector is classified into a class. Nextly we find a margin between the two classes that is far from any document. The distance defines the margin of the classifier, maximizing the margin reduces indecisive decisions. SVM also supports classification and regression which are useful for statistical learning theory and it also helps recognizing the factors precisely, that needs to be taken into account, to understand it successfully."}, {"heading": "III. APPROACHES FOR SENTIMENT ANALYSIS", "text": "There are mainly two techniques for sentiment analysis for the twitter data:"}, {"heading": "A. Machine Learning Approaches", "text": "Machine learning based approach uses classification technique to classify text into classes. There are mainly two types of machine learning techniques"}, {"heading": "1. Unsupervised learning:", "text": "It does not consist of a category and they do not provide with the correct targets at all and therefore rely on clustering."}, {"heading": "2. Supervised learning:", "text": "It is based on labeled dataset and thus the labels are provided to the model during the process. These labeled dataset are trained to get meaningful outputs when encountered during decision- making. The success of both this learning methods is mainly depends on the selection and extraction of the specific set of features used to detect sentiment. The machine learning approach applicable to sentiment analysis mainly belongs to supervised classification. In a machine learning techniques, two sets of data are needed:\n1. Training Set 2. Test Set.\nA number of machine learning techniques have been formulated to classify the tweets into classes. Machine learning techniques like Naive Bayes (NB), maximum entropy (ME), and support vector machines (SVM) have achieved great success in sentiment analysis. Machine learning starts with collecting training dataset. Nextly we train a classifier on the training data. Once a supervised classification technique is selected, an important decision to make is to select feature. They can tell us how documents are represented. The most commonly used features in sentiment classification are :\n\u2022 Term presence and their frequency \u2022 Part of speech information \u2022 Negations \u2022 Opinion words and phrases\nFig.2 Sentiment Classification Based On Emoticons\nWith respect to supervised techniques, support vector machines (SVM), Naive Bayes, Maximum Entropy are some of the most common techniques used. Whereas semi-supervised and unsupervised techniques are proposed when it is not possible to have an initial set of labeled documents/opinions to classify the rest of items"}, {"heading": "B. Lexicon-Based Approaches", "text": "Lexicon based method [20] uses sentiment dictionary with opinion words and match them with the data to determine polarity. They assigns sentiment scores to the opinion words describing how Positive, Negative and Objective the words contained in the dictionary are. Lexicon-based approaches mainly rely on a sentiment lexicon, i.e., a collection of known and precompiled sentiment terms, phrases and even idioms, developed for traditional genres of communication, such as the Opinion Finder lexicon;\nThere are Two sub classifications for this approach: 1.Dictionary-based: It is based on the usage of terms (seeds) that are usually collected and annotated manually. This set grows by searching the synonyms and antonyms of a dictionary. An example of that dictionary is WordNet ,which is used to develop a thesaurus called SentiWordNet. Drawback : Can\u2019t deal with domain and context specific orientations."}, {"heading": "2. Corpus-Based:", "text": "The corpus-based approach have objective of providing dictionaries related to a specific domain. These dictionaries are generated from a set of seed opinion terms that grows through the search of related words by means of the use of either statistical or semantic techniques.\n\u2022 Methods based on statistics: Latent Semantic Analysis (LSA).\n\u2022 Methods based on semantic such as the use of synonyms and antonyms or relationships from thesaurus like WordNet may also represent an interesting solution.\nAccording to the performance measures like precision and recall, we provide a comparative study of existing techniques for opinion mining, including machine learning, lexicon-based\napproaches, crossdomain and cross-lingual approaches, etc., as shown in Table 2."}, {"heading": "IV. SENTIMENT ANALYSIS TASKS", "text": "Sentiment analysis is a challenging interdisciplinary task which includes natural language processing, web mining and machine learning. It is a complex task and can be decomposed into following tasks, viz:\n\u2022 Subjectivity Classification \u2022 Sentiment Classification \u2022 Complimentary Tasks\no Object Holder Extraction o Object/ Feature Extraction\nFig.4 Sentiment Analysis Tasks"}, {"heading": "A . Subjectivity classification", "text": "Subjectivity classification is the task of classifying sentences as opinionated or not opinionated.\nLet S = {s1, . . . , sn} be a set of sentences in document D. The problem of subjectivity classification is to identify sentences used to represent opinions and other forms of subjectivity (subjective sentences set Ss) from sentences used to objectively present factual information (objective sentences set So), where Ss U So = S."}, {"heading": "B. Sentiment Classification", "text": "Once the task of finding whether a sentence is opinionated is done, we have to find the polarity of the sentence i.e., whether it expresses a positive or negative opinion.Sentiment classification can be a binary classification (positive or negative), multi-class classification (extremely negative, negative, neutral, positive or extremely positive), regression or ranking .\nDepending upon the application of sentiment analysis, subtasks of opinion holder extraction and object feature extraction cane be treated as optional."}, {"heading": "C. Complimentary Tasks", "text": "\u2022 Opinion Holder Extraction It is the discovery of opinion holders or sources. Detection of opinion holder is to recognize direct or indirect sources of opinion. \u2022 Object /Feature Extraction It the discovery of the target entity."}, {"heading": "V. LEVELS OF SENTIMENT ANALYSIS", "text": "Tasks described in the previous section can be done at several levels of granularity.\nFig.5 Levels Of Sentiment Analysis\nA. Document level:\nIt deals with tagging individual documents with their sentiment. In Document level the whole document is classify either into positive or negative class. General Approach: Find the sentiment polarities of individual sentences or words and combine them together to find the polarity of the document. Other approaches: Complex linguistic phenomena like co-reference resolution, pragmatics, etc. Various Tasks involved in this are: \u2022 Task: Sentiment Classification of whole document \u2022 Classes: Positive, negative and neutral \u2022 Assumption : Each Document focuses on a single object\n(not true in discussion posts, blogs ,etc. ) and contain opinion from a single opinion holder\nB. Sentence or phrase level:\nSentence-level Sentiment Analysis deals with tagging individual sentences with their respective sentiment polarities. Sentence level sentiment classification classifies sentence into positive, negative or neutral class. General approach: find the sentiment orientation of individual words in the sentence/phrase and then to combine combine them to determine the sentiment of the whole sentence or phrase. Other approaches: consider discourse structure of the text Various Tasks involved in this are: \u2022 Task 1: Identifying Subjective/ Objective\nSentences Classes: Objective and Subjective\n\u2022 Task 2: Sentiment Classification of Sentences\nClasses: positive and negative o Assumption: A sentence contains only one opinion which may not always be true\nC. Aspect level or Feature level:\nIt deals with labeling each word with their sentiment and also identifying the entity towards which the sentiment is directed. Aspect or Feature level sentiment classification concerns with identifying and extracting product features from the source data. Techniques like dependency parser and discourse structures are used in this. Various Tasks involved in this are:\n\u2022 \u2022 Task 1: Identify and extract object features that have been\ncommented on by an opinion holder (eg. A reviewer) \u2022 Task 2: Determining whether the opinions on features are\nnegative, positive or neutral \u2022 Task 3: Find feature synonyms"}, {"heading": "D. Word Level:", "text": "Most recent works have used the prior polarity of words and phrases for sentiment classification at sentence and document levels Word sentiment classification use mostly adjectives as features but adverbs, The two methods of automatically annotating sentiment at the word level are: (1) Dictionary-Based Approaches (2) Corpus-Based Approaches."}, {"heading": "VI. EVALUATION OF SENTIMENT CLASSIFICATION", "text": "The performance of sentiment classification can be evaluated by using four indexes calculated as the following equations: Accuracy = (TP+TN)/(TP+TN+FP+FN) Precision = TP/(TP+FP) Recall = TP/(TP+FN) F1 = (2\u00d7Precision\u00d7Recall)/(Precision+Recall) In which TP, FN, FP and TN refer respectively to the number of true positive instances, the number of false negative instances, the number of false positive instances and the number of true negative instances, as defined in the table 1."}, {"heading": "VII. RESULTS AND DISCUSSION", "text": "We used the twitter dataset publicly made available by Stanford university. Analyses was done on this labeled datasets using various feature extraction technique. We used the framework where the preprocessor is applied to the raw sentences which make it more appropriate to understand. Further, the different machine learning techniques trains the dataset with feature vectors and then the semantic analysis offers a large set of synonyms and similarity which provides the polarity of the content.\nDataset Description: Train Data 45000 Negative 23514 Positive 21486 Test Data 44832 Negative 22606 Positive 22226"}, {"heading": "A. Baseline Algorithm:", "text": "The baseline algorithm used is Na\u00efve Bayes without preprocessed data and unigram model. Following table shows the accuracy obtained at different sizes for the baseline algorithm."}, {"heading": "10 0.46475731620", "text": ""}, {"heading": "50 0.533324411135", "text": ""}, {"heading": "100 0.54744379015", "text": ""}, {"heading": "500 0.612375089222", "text": ""}, {"heading": "1000 0.652301927195", "text": ""}, {"heading": "5000 0.697403640257", "text": ""}, {"heading": "10000 0.712928265525", "text": ""}, {"heading": "15000 0.717389364739", "text": ""}, {"heading": "20000 0.722764989293", "text": ""}, {"heading": "25000 0.729478943612", "text": ""}, {"heading": "30000 0.729122055675", "text": ""}, {"heading": "35000 0.73244557459", "text": ""}, {"heading": "40000 0.733226266952", "text": ""}, {"heading": "45000 0.736549785867", "text": "Following are the details on most informative features after the classifier is executed on train data. sad = True neg : pos = 37.6 : 1.0 worst. = True neg : pos = 32.4 : 1.0 crying = True neg : pos = 24.7 : 1.0 fml = True neg : pos = 24.1 : 1.0 hurts = True neg : pos = 21.2 : 1.0 awful = True neg : pos = 21.1 : 1.0\nugh. = True neg : pos = 20.4 : 1.0 terrible = True neg : pos = 20.4 : 1.0 boo. = True neg : pos = 19.2 : 1.0 cancelled = True neg : pos = 19.2 : 1.0"}, {"heading": "B. Na\u00efve Bayes Algorithm:", "text": "Effect of Stopwords:. When Naive Bayes(Baseline) was run, it gave an accuracy of 73.65 percent, which is considered as the baseline result. The next thing used was removal of stopword. When stopwords were removed and Naive Bayes was run, it gave an accuracy of 74.56 percent. Following table shows the accuracy obtained at different sizes for the Na\u00efve Bayes with stopwords removed and using preprocessed data and based on unigram model."}, {"heading": "10 0.522305496074", "text": "The results are slightly different, this was the case even with Linear SVC. This shows that stopwords really affect the predictions . An intuition to this can be obtained from the fact that given the short length of tweets, people generally use stopwords such as and, while, before, after and so on. Thus removal of stopwords makes a lot of difference to the accuracy.\nEffect of Bigram: Bigram uses a combination of two words as a feature. Bigram effectively captures some features in the data that unigram fails to capture. For example, words like \u2019not sad\u2019, \u2019not good\u2019 clearly say that the sentiment is negative. This effect can be clearly seen from the increase in accuracy from 74.56(Unigram) to 76.44 percent which is almost a 2% increase. Following table shows the accuracy obtained at different sizes for the Na\u00efve Bayes algorithm with bigram model."}, {"heading": "10 0.544990185582", "text": "The most informative features for Naive Bayes with Bigrams as features. ('so', 'sad') = True neg : pos = 55.2 : 1.0 sad. = True neg : pos = 44.2 : 1.0 bummed = True neg : pos = 33.8 : 1.0 horrible = True neg : pos = 32.0 : 1.0 ('USERNAME', 'welcome') = True pos : neg = 29.5 : 1.0 ('welcome', 'to') = True pos : neg = 28.1 : 1.0 sad = True neg : pos = 27.5 : 1.0 ('i', 'lost') = True neg : pos = 24.7 : 1.0 died = True neg : pos = 24.3 : 1.0 ('miss', 'him') = True neg : pos = 24.1 : 1.0 Effect of using Trigram:. Running Naive Bayes using Trigrams, bigrams and unigrams together gave an accuracy of 75.41 percent which is less than the accuracy obtained when Bigrams were used as a feature. Also this feature combination bloats up the feature space exponentially and the execution becomes extremely slow. Hence for further analysis, the trigrams are not considered as they do not have a noticeable impact on the accuracy. Following table shows the accuracy obtained at different sizes for the Na\u00efve Bayes algorithm with Trigram model."}, {"heading": "10 0.486995895789", "text": "Fig.6 Graph Representing Different results obtained for\nNa\u00efve Bayes Algorithm.\nTable 8. Accuracy of Na\u00efve Bayes Algorithm\nAlgorithm Accuracy Na\u00efve Bayes (unigram) 74.56 Na\u00efve Bayes (bigram) 76.44 Na\u00efve Bayes (trigram) 75.41"}, {"heading": "C. Support Vector Machine (SVM):", "text": "Effect using unigram: Following table shows the accuracy obtained at different sizes for the SVM algorithm with unigram model."}, {"heading": "10 0.525450571021", "text": ""}, {"heading": "10 0.500223054961", "text": ""}, {"heading": "D. Maximum Entropy:", "text": "In Maximum Entropy Classifier, no assumptions are taken regarding the relationship between features.we obtained an accuracy of 74.93 percent with unigram model With all the features considered, the results show that SVM outperforms Naive Bayes and maximum entropy as well in all cases. In particular, the feature combination of Slang stopwords removal and Bigram gives the maximum accuracy of 77.73 with SVM.\nMaximum Entropy model gives an accuracy consistently inbetween Naive Bayes and SVM. Also it runs iteratively and takes a large amount of time to run. Hence MaxEnt was not used for all the feature combinations.\nFig.7 Graph Representing Different results obtained for\nNa\u00efve Bayes Algorithm And Linear SVC (SVM)."}, {"heading": "VIII. CHALLENGES IN SENTIMENT ANALYSIS", "text": "Sentiment Analysis is a very challenging task. Following are some of the challenges[13] faced in Sentiment Analysis of Twitter."}, {"heading": "1. Identifying subjective portions of text:", "text": "Subjective portion here refers to sentiment-bearing content. The same word can be treated as subjective in one context, while it might be objective in some other. This makes it difficult to identify the subjective portions of text.\nFor example: 1. The language of the author was very crude. 2. Crude oil is extracted from the sea beds. The same word \u2018crude\u2019 is used as an opinion in first sentence, while it is completely objective in the second sentence. 2. Associating sentiment with keywords:\nIt is difficult to pinpoint the source of these sentiments in sentences having strong opinion. Hence an association to a keyword or phrase is difficult. For example: Every time I read `Pride and Prejudice' I want to dig her up and beat her over the skull with her own shin-bone. In this example, \u2018her\u2019 refers to the character in the book \u2018Pride and Prejudice\u2019, which is not explicitly mentioned. In such cases the negative sentiment must be associated with the character in the book. 3. Domain dependence[24]:\nThe same sentence or phrase can have different meanings in different domains. For Example, the word \u2018unpredictable\u2019 is positive in the domain of movies, but if the same word is used in the context of a vehicle's steering, then it has a negative opinion.\n4. Sarcasm Detection:\nSarcastic sentences express negative opinion about a target using positive words in unique way.. Example: Nice perfume. You must marinate in it. The sentence contains only positive words but actually it expresses a negative sentiment. 5. Thwarted expressions:\nThere are some sentences in which only some part of text determines the overall polarity of the document. Example: This Movie should be amazing. It sounds like a great plot, the popular actors , and the supporting cast is talented as well.\nHowever, it can't hold up. Simple bag-of-words approaches will term it as positive sentiment, but the ultimate sentiment is negative. 6. Indirect negation of sentiment:\nSentiment can be negated in many ways as opposed to using simple no, not, never, etc. It is difficult to identify such negations easily. Example: It avoids all clich\u00e9s and predictability found in Hollywood movies. While the words cliche and predictable bear a negative sentiment, the usage of \u2018avoids\u2019 negates their respective sentiments. 7. Order dependence:\nDiscourse Structure analysis is essential for Sentiment Analysis/Opinion Mining. For example: A is better than B, conveys the exact opposite opinion from, B is better than A. 8. Entity Recognition:\nThere is a need to separate out the text about a specific entity and then analyze sentiment towards it. For Example: \u201cI hate Microsoft, but I like Linux\u201d. A simple bag-of-words approach will label it as neutral, however, it carries a specific sentiment for both the entities present in the statement."}, {"heading": "9. Building a classifier for subjective vs. objective tweets.", "text": "We've focused mostly on classifying positive vs. negative correctly. We haven't looked at classifying tweets with sentiment vs. no sentiment very closely."}, {"heading": "10. Handling comparisons.", "text": "Bag of words model doesn't handle comparisons very well. Example: \"IIT\u2019s are better than most of the private colleges\", the tweet would be considered positive for both IIT\u2019s and private colleges using bag of words model because it doesn't take into account the relation towards \"better\". 11. Applying sentiment analysis to Facebook messages.\nThere has been less work on sentiment analysis on Facebook data mainly due to various restrictions by Facebook graph api and security policies in accessing data.\n12. Internationalization [16,17].\nCurrent Research work focus mainly on English content, but Twitter has many varied users from across."}, {"heading": "IX. APPLICATIONS OF SENTIMENT ANALYSIS", "text": "Sentiment Analysis has many applications in various Fields. 1.Applications to Review Websites: Today Internet has an wide variety of reviews and feedbacks on almost everything. This includes product reviews, feedbacks on political issues, comments about services, etc. Thus there is a need for a sentiment analysis system that can extract sentiments about a particular product or services. It will help in providing feedback or rating for the given product,item,etc.This would serve the needs of both the users and the vendors."}, {"heading": "2. Applications as a Sub-component Technology", "text": "A sentiment predictor system can be helpful in recommender systems as well. The recommender system will not recommend items that receive a lot of negative feedback or less ratings. In online communication, we come across abusive language and other negative elements. These can be detected simply by identifying a highly negative sentiment and correspondingly taking action against it."}, {"heading": "3. Applications in Business Intelligence", "text": "It has been observed that people nowadays tend to look upon reviews of products online before buying them. And for many businesses the online opinion can make or break their product. Thus, Sentiment Analysis plays an important role in businesses. Businesses also wish to extract sentiment from the online reviews in order to improve their products and in turn their reputation."}, {"heading": "4. Applications across different Domains:", "text": "Studies in sociology and other fields have been benefitted by Sentiment Analysis that show trends in human emotions especially on social media."}, {"heading": "5. Applications In Smart Homes", "text": "Smart homes are supposed to be the technology of the future. In future entire homes would be networked and people would be able to control any part of the home using a tablet device. Recently there has been lot of research going on Internet of Things(IoT). Sentiment Analysis would also find its way in IoT. Like for example, based on the current sentiment or emotion of the user, the home could alter its ambiance to create a soothing and peaceful environment. Sentiment Analysis can also be used in trend prediction. By tracking public views, important data regarding sales trends and customer satisfaction can be extracted."}, {"heading": "X. CONCLUSION", "text": "In this paper, we provide a survey and comparative study of existing techniques for opinion mining including machine learning and lexicon-based approaches, together with crossdomain and cross-lingual methods and some evaluation metrics. Research results show that machine learning methods, such as SVM and naive Bayes have the highest accuracy and can be regarded as the baseline learning methods, while lexicon-based methods are very effective in some cases, which require few effort in human-labeled document.We also studied the effects of various features on classifier.We can conclude that more the cleaner data,more accurate results can be obtained.Use of bigram model provides better sentiment accuracy as compared to other models. In future, we can focus on the study on combining machine learning method into opinion lexicon method in order to improve the accuracy of sentiment classification and adaptive capacity to variety of domains and different languages."}], "references": [{"title": "Twitter as a Corpus for Sentiment Analysis and Opinion Mining", "author": ["A.Pak", "P. Paroubek"], "venue": "In Proceedings of the Seventh Conference on International Language Resources and Evaluation,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Movassate, \u201cSentiment Analysis of User- Generated Twitter Updates using Various Classi_cation Techniques\",CS224N", "author": ["M.R. Parikh"], "venue": "Final Report,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Twitter Sentiment Classification Using Distant Supervision", "author": ["Go", "R. Bhayani", "L.Huang"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Robust Sentiment Detection on Twitter from Biased and Noisy Data", "author": ["L. Barbosa", "J. Feng"], "venue": "COLING 2010: Poster Volume,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Sentiment Knowledge Discovery in Twitter Streaming Data", "author": ["Bifet", "E. Frank"], "venue": "In Proceedings of the 13th International Conference on Discovery Science, Berlin,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "Sentiment Analysis of Twitter Data", "author": ["Agarwal", "B. Xie", "I. Vovsha", "O. Rambow", "R. Passonneau"], "venue": "In Proceedings of the ACL 2011 Workshop on Languages", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Enhanced Sentiment Learning Using Twitter Hashtags and Smileys", "author": ["Dmitry Davidov", "Ari Rappoport"], "venue": "Coling 2010: Poster Volume pages 241{249,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Opinion Mining on Social Media Data\", IEEE 14th International Conference on Mobile Data Management, Milan, Italy, June 3 ", "author": ["Po-Wei Liang", "Bi-Ru Dai"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Citius: A Naive-Bayes Strategy for Sentiment Analysis on English Tweets", "author": ["Pablo Gamallo", "Marcos Garcia"], "venue": "8th International Workshop on Semantic Evaluation (SemEval", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Sentiment Analysis in Twitter using Machine Learning Techniques", "author": ["M S Neethu", "R Rajashree"], "venue": "4th ICCCNT 2013,at Tiruchengode, India", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews,", "author": ["P.D. Turney"], "venue": "Proceedings of the 40th annual meeting on association for computational linguistics,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "Ensemble of feature sets and classification algorithms for sentiment classification,", "author": ["R. Xia", "C. Zong", "S. Li"], "venue": "Information Sciences: an International Journal,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "TingWang, An effective approach to tweets opinion retrieval", "author": ["Zhunchen Luo", "Miles Osborne"], "venue": "Springer Journal onWorld WideWeb,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Adaptive cotraining SVM for sentiment classification on tweets", "author": ["S. Liu", "F. Li", "X. Cheng", "Shen"], "venue": "In Proceedings of the 22nd ACM international conference on Conference on information & knowledge management (pp. 2079-2088)", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Cross-domain sentiment classification via spectral feature alignment", "author": ["J Pan S", "X Ni", "T Sun J"], "venue": "Proceedings of the 19th international conference on World wide web. ACM,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Recursive deep models for semantic compositionality over a sentiment Treebank.", "author": ["Socher", "Richard"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Cross-lingual mixture model for sentiment classification.\" Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1.Association", "author": ["Meng", "Xinfan"], "venue": "Computational Linguistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Lexicon based methods for sentiment analysis", "author": ["M. Taboada", "J. Brooke", "M. Tofiloski", "K. Voll", "Stede"], "venue": "Computational linguistics,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Active learning for cross-domain sentiment classification", "author": ["S. Li", "Y. Xue", "Z. Wang", "Zhou"], "venue": "In Proceedings of the Twenty-Third international joint conference on Artificial Intelligence (pp", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Cross-Domain Sentiment Classification using a Sentiment Sensitive Thesaurus", "author": ["D. Bollegala", "D. Weir", "Carroll"], "venue": "Knowledge and Data Engineering, IEEE Transactions on,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["B. Pang", "L. Lee"], "venue": "42nd Meeting of the Association for Computational Linguistics[C]", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "Pak and Paroubek(2010) [1] proposed a model to classify the tweets as objective, positive and negative.", "startOffset": 23, "endOffset": 26}, {"referenceID": 1, "context": "Parikh and Movassate(2009) [2] implemented two models, a Naive Bayes bigram model and a Maximum Entropy model to classify tweets.", "startOffset": 27, "endOffset": 30}, {"referenceID": 2, "context": "Huang (2009) [3] proposed a solution for sentiment analysis for twitter data by using distant supervision, in which their training data consisted of tweets with emoticons which served as noisy labels.", "startOffset": 13, "endOffset": 16}, {"referenceID": 3, "context": "(2010) [4] designed a two phase automatic sentiment analysis method for classifying tweets.", "startOffset": 7, "endOffset": 10}, {"referenceID": 4, "context": "Bifet and Frank(2010) [5] used Twitter streaming data provided by Firehouse API , which gave all messages from every user which are publicly available in real-time.", "startOffset": 22, "endOffset": 25}, {"referenceID": 5, "context": "(2011)[6] developed a 3-way model for classifying sentiment into positive, negative and neutral classes.", "startOffset": 6, "endOffset": 9}, {"referenceID": 6, "context": ",(2010) [7] proposed a approach to utilize Twitter user-defined hastags in tweets as a classification of sentiment type using punctuation, single words, n-grams and patterns as different feature types, which are then combined into a single feature vector for sentiment classification.", "startOffset": 8, "endOffset": 11}, {"referenceID": 7, "context": "(2014) [8] used Twitter API to collect twitter data.", "startOffset": 7, "endOffset": 10}, {"referenceID": 8, "context": "[9] presented variations of Naive Bayes classifiers for detecting polarity of English tweets.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "Turney et al [11] used bag-of-words method for sentiment analysis in which the relationships between words was not at all considered and a document is represented as just a collection of words.", "startOffset": 13, "endOffset": 17}, {"referenceID": 11, "context": "[13] used an ensemble framework for Sentiment Classification which is obtained by combining various feature sets and classification techniques.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[13] highlighted the challenges and an efficient techniques to mine opinions from Twitter tweets.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Later this aspect are used to compute the positive and negative polarity in a sentence which is useful for determining the opinion of the individuals using models like unigram,bigram [18].", "startOffset": 183, "endOffset": 187}, {"referenceID": 20, "context": "[23] showed better results by using presence instead of frequencies.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "It is a probabilistic classifier and can learn the pattern of examining a set of documents that has been categorized [9].", "startOffset": 117, "endOffset": 120}, {"referenceID": 13, "context": "Support vector machine analyzes the data, define the decision boundaries and uses the kernels for computation which are performed in input space[15].", "startOffset": 144, "endOffset": 148}, {"referenceID": 17, "context": "Lexicon based method [20] uses sentiment dictionary with opinion words and match them with the data to determine polarity.", "startOffset": 21, "endOffset": 25}, {"referenceID": 20, "context": "40% Pang, Lee[23]", "startOffset": 13, "endOffset": 17}, {"referenceID": 12, "context": "52% Liu[14]", "startOffset": 7, "endOffset": 11}, {"referenceID": 15, "context": "70% Richard[18]", "startOffset": 11, "endOffset": 15}, {"referenceID": 17, "context": "Dictionary Amazon\u2019 s Mechani cal Turk --- Taboada[20]", "startOffset": 49, "endOffset": 53}, {"referenceID": 14, "context": "00% Wan,X[16]", "startOffset": 9, "endOffset": 13}, {"referenceID": 14, "context": "[16]", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "Thesaurus Bollegala[22 ] SFA Pan S J[15]", "startOffset": 19, "endOffset": 24}, {"referenceID": 13, "context": "Thesaurus Bollegala[22 ] SFA Pan S J[15]", "startOffset": 36, "endOffset": 40}, {"referenceID": 11, "context": "Following are some of the challenges[13] faced in Sentiment Analysis of Twitter.", "startOffset": 36, "endOffset": 40}, {"referenceID": 14, "context": "Internationalization [16,17].", "startOffset": 21, "endOffset": 28}], "year": 2016, "abstractText": "With the advancement of web technology and its growth, there is a huge volume of data present in the web for internet users and a lot of data is generated too. Internet has become a platform for online learning, exchanging ideas and sharing opinions. Social networking sites like Twitter, Facebook, Google+ are rapidly gaining popularity as they allow people to share and express their views about topics,have discussion with different communities, or post messages across the world. There has been lot of work in the field of sentiment analysis of twitter data. This survey focuses mainly on sentiment analysis of twitter data which is helpful to analyze the information in the tweets where opinions are highly unstructured, heterogeneous and are either positive or negative, or neutral in some cases. In this paper, we provide a survey and a comparative analyses of existing techniques for opinion mining like machine learning and lexicon-based approaches, together with evaluation metrics. Using various machine learning algorithms like Naive Bayes, Max Entropy, and Support Vector Machine, we provide a research on twitter data streams. We have also discussed general challenges and applications of Sentiment Analysis on Twitter.", "creator": "Acrobat PDFMaker 11 for Word"}}}