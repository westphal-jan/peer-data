{"id": "1602.05439", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Feb-2016", "title": "Cell segmentation with random ferns and graph-cuts", "abstract": "Advances in imaging techniques have enabled us to study various aspects of cellular mechanisms. To isolate individual cells in live image data, we introduce an elegant image segmentation framework that effectively extracts cell boundaries, even when edges are poor. Our approach works in two stages: First, we estimate the probabilities of pixels within / boundary / outer boundary using random ferns; then we use an energy minimization framework to calculate boundaries whose localization matches the probabilities of the pixel class. We validate our approach using a manually annotated dataset.", "histories": [["v1", "Wed, 17 Feb 2016 14:47:32 GMT  (2873kb,D)", "http://arxiv.org/abs/1602.05439v1", "submitted to ICIP"]], "COMMENTS": "submitted to ICIP", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["arnaud browet", "christophe de vleeschouwer", "laurent jacques", "navrita mathiah", "bechara saykali", "isabelle migeotte"], "accepted": false, "id": "1602.05439"}, "pdf": {"name": "1602.05439.pdf", "metadata": {"source": "CRF", "title": "CELL SEGMENTATION WITH RANDOM FERNS AND GRAPH-CUTS", "authors": ["A. Browet", "C. De Vleeschouwer", "Jacques", "N. Mathiah", "B. Saykali", "I. Migeotte"], "emails": [], "sections": [{"heading": null, "text": "Index Terms\u2014 cell segmentation, fluorescent microscopy, random ferns, graph-cuts"}, {"heading": "1. INTRODUCTION / OVERVIEW", "text": "Embryo morphogenesis relies on coordinated cell movements and tissue reorganization to allow correct shaping. Progress in embryo culture and live imaging techniques has allowed direct observation of cellular rearrangements in embryos from various species, including those with internal development [1]. Important insight has been obtained through qualitative analysis of live imaging data, but quantitative automated analysis remains a bottleneck. The specific question addressed here is the cellular mechanisms of mesoderm migration during mouse embryo gastrulation [2]. To look at cell shape changes of the nascent mesoderm after ingression, we examine Brachyury-Cre; mTomato/mGFP embryos between e6.75 and e7.5 by confocal microscopy. Cells expressing Brachyury that have gone through the streak and are populating the embryos as migrating mesoderm have green membranes, while the rest of the embryo has red membranes. To ensure optimal embryo survival, it is best to avoid multiple colors imaging [3], and we have thus favored a membrane marker. The goal is to track cell movements to build a map of cell trajectories depending on time and place of ingression.\nAs a preliminary step to cell movement analysis, our work focuses on cell detection and segmentation. The images collected using fluorescence microscopy exhibit many characteristics that make segmentation challenging. These include\n\u2020 Part of this work was supported by a fellowship from Phoenix, the FRS/FRIA, the FNRS, WELBIO and by the Mecatech project SAVE.\nlimited spatial resolution and contrast, resulting in poor membrane details. Specifically, as can be observed in Fig. 1.a, the fluorophores do not strictly concentrate along the cell membranes in our dataset [25]. In contrast to images studied in [6, 7, 8], this makes the border between two adjacent cells difficult to isolate, even visually. Moreover, the inner textures of distinct cells present quite similar statistics, making region merging strategies inappropriate as long as they do not use edge information. This is in contrast with natural images, in which the objects to segment are characterized by distinct inner textures and color, and can therefore be effectively segmented using superpixel merging techniques [9].\nFig. 1 illustrates two approaches that are widely employed for image segmentation. The graph-based method of Felzenszwalb and Huttenlocher merges the regions in a greedy manner, using a minimum spanning-tree to measure the pixels uniformity in a region and compare it to border transitions [5, 10]. The Mean Shift (MS) algorithm offers an alternative popular clustering framework. MS represents pixels in the joint spatial-range domain by concatenating their spatial coordinates and intensity values into a single vector. This method then assigns each pixel to a local maxima of the statistical distribution of the pixels in this domain, using a gradient-\nar X\niv :1\n60 2.\n05 43\n9v 1\n[ cs\n.C V\n] 1\n7 Fe\nb 20\n16\ndescent process [4]. We observe in Fig. 1 that none of these approaches succeeds in segmenting adjacent cells. Hence, they are not able to capture the semantic knowledge required to distinguish individual cells within cells aggregate.\nAmong the approaches proposed in the literature to address semantic segmentation problems, [11] and [12] have respectively considered an interactive framework or a prior discriminative description of the object to segment. In the context of microscopy, [13] have defined such prior models based on templates, learned in a supervised manner. In super-resolution localization microscopy and in MRI, [14] and [15] respectively rely on density estimation or SVM texture features classification to differentiate structures of interest. Those approaches are however only relevant when strong appearance priors exist about how the object to segment differs from its environment. This is not the case in our dataset, where the shape of the cells is subject to significant variability, and where the environment of each cell is composed of quite similar other cell patterns.\nIn cases where the object appearance is not discriminant, training appropriate edge detectors appears to be a natural approach [16, 17]. The work in [17] is of particular interest. It has been proposed in the context of neurons reconstruction, using electron microscopy. It combines a pixel-level membrane probability estimator with a conventional watershed algorithm to segment regions that are likely to be closed by a membrane. In practice however, the membrane probability map presents too many local minima, which leads to an oversegmented partition. To address this problem, a so-called boundary classifier is trained to control the merging of adjacent regions, based on the statistics of boundary and region pixels. The main drawback of this approach is that the boundary classifier is trained directly on the output of the watershed stage, thereby requiring training adjustment when the watershed thresholds are tuned. Moreover, the contours defined in the first step, strictly based on the membrane detector, can only be removed in the second step, without being corrected based on the observed region pixel statistics.\nTo circumvent those limitations, we propose to adopt an approach that does not consider edge- and inside- pixels sequentially, but instead considers them jointly. In an initial stage, our approach learns how interior pixels differ from background or border pixels. It then adopts a global energy minimization framework to assign cell-representative labels to pixels, based on their posterior interior/border/exterior class probabilities. Considering explicitly a class of pixels lying on borders between adjacent cells is critical since the main problem encountered by previous works on our dataset consists in splitting cellular aggregates into individual cells (see Fig. 1). Formally, we use a semi-Naive Bayesian approach to estimate, in each pixel, the probabilities that this pixel lies inside a cell, on a boundary between adjacent cells, and in the background. We have chosen semi-Naive Bayesian estimation because it has been shown to be accurate and of-\nfer good robustness and generalization properties in many vision classification tasks [18, 19]. This last point is important since the manual definition of cell contour ground-truth is generally considered as a tedious task, which practically limits the number of available training samples. Regarding the subsequent energy-minimization framework, we rely on the fast approximate minimization with label costs introduced by Delong et al. [20], based on the seminal work of Boykov et al. [21]. In final, our work appears to be an elegant and effective solution to exploit posterior interior/border/exterior probability maps in a segmentation context.\nThe rest of the paper is organized as follows. Section 2 introduces our semi-Naive Bayesian probability vector estimator. Section 3 describes the energy minimization labelling framework. Section 4 validates our approach, and Section 5 provides some concluding comments."}, {"heading": "2. PIXEL CLASS PROBABILITY ESTIMATION", "text": "This section explains how to assign interior/border/exterior class probabilities to a pixel, based on the observation of its neighborhood. Following many successful recent works [18, 22, 23], we use randomized sets of binary tests to characterize the different classes of point neighborhoods.\nIn practice, the point neighborhood is defined by a small square window of radius l and of size (2l + 1)2 centered around the pixel of interest. Each binary test compares the intensity of two pixels, and is set to 1 when the first is larger than the second, and to 0 otherwise. The pixel positions of each test are drawn uniformly at random within the square window. The approach considers N \u2208 N sets of S \u2208 N binary tests that are randomly selected, to define N flat structures, named ferns.\nAs in [18], let C \u2208 C denote the random variable that represents the class of an image sample, and C = {ci : 0 < i \u2264 H} be the set of H = 3 interior/border/exterior classes. Given the ensemble of N ferns F = {Fk \u2208 {0, 1}S : 1 \u2264 k \u2264 N}, where Fk denotes the kth fern, we are interested in estimating the posterior probabilities P (C = ci|F1, \u00b7 \u00b7 \u00b7 , FN ). If we admit a uniform prior with P (C = ci) = 1/H for 1 \u2264 i \u2264 H , Bayes\u2019 formula yields:\nP (C = ci|F1, \u00b7 \u00b7 \u00b7 , FN ) \u221d P (F1, \u00b7 \u00b7 \u00b7 , FN |C = ci). (1)\nLearning and handling the class conditional joint probability in (1) is not feasible for large N \u00d7 S products since it would require to compute and store 2NS entries for each class. To keep the conditional probabilities tractable while accounting for some binary tests dependencies, the semi-naive Bayesian approach proposed in [18] assumes independence between the ferns, but accounts for dependencies between the binary tests belonging to the same fern. The joint conditional probability is approximated by:\nP (F1, \u00b7 \u00b7 \u00b7 , FN |C = ci) ' N\u220f k=1 P (Fk|C = ci), (2)\nwhere the class conditional distribution of each fern is simply learned based on the accumulation of the training samples observations, as detailed in [18].\nWhen the number of ferns is large, the product in (2) may cause computational underflow. Hence, in general, one defines the score\nsc = log (\u03c3c) = N\u2211 k=1 log (P (Fk |C = c )) , (3)\nThe scores extracted with the random ferns provide an interesting insight about the class distribution of pixels within the image. In a conventional classification framework, a pixel class MAP estimate c\u0302 is defined by:\nc\u0302 = argmax c\u2208C P (C = c|F1, \u00b7 \u00b7 \u00b7 , FN ) ' argmax c\u2208C sc. (4)\nIn our segmentation problem, however, the MAP does not define accurately the cell boundaries, see Fig. 2.b. Therefore, we turn to a global energy-minimization, build upon the ferns scores, to derive an appropriate segmentation. In what follows, when we refer to the ferns scores, we consider them normalized, i.e. s\u0303c = sc/ ( \u2211 c sc), although we will abuse the notation sc for clarity."}, {"heading": "3. CLASS COMPLIANT ENERGY MINIMIZATION", "text": "The global energy minimization framework introduced in [21, 20] is used to assign cell-representative labels to pixels, based on their posterior interior/border/exterior class probabilities. Given a set of n labels L = {1, \u00b7 \u00b7 \u00b7 , n}, we are looking for a pixel-to-label assignment f that minimizes the energy E (f) = \u2211 p\u2208P Dp (fp) + \u2211 (p,q)\u2208N W (p, q) (1\u2212 \u03b4(fp, fq)) + \u2211 l\u2208L hl (f) ,\n(5)\nwhere \u03b4 is the Kronecker delta, P stands for the set of pixels and N for a set of pairs of interacting pixels. As detailed below, the first term, Dp (fp), is called data fidelity and measures the cost to associated each pixel p to its label fp. The second term,W (p, q), regularizes the label assignment by penalizing the assignment of distinct labels to interacting pixels p and q in a graph structure (P,W ). Finally, as detailed in [20], the last term, hl (f), introduces a cost when f assigns the label l to at least one pixel. The graph structure penalizes local inconsistencies of the labels while the label cost penalizes having to many different labels globally.\nWe initialize the label set so that each cell is represented by at least one label. To do so, we extract a number of cellrepresentative seeds. In practice, each seed corresponds to the center of a connected set of pixels whose interior score lies above a threshold. To circumvent the threshold selection issue, and to adapt the seed definition to the local image contrast, we consider a decreasing sequence of thresholds. Large thresholds result in small segments, that progressively\ngrow and merge as the threshold decreases. Among those segments, we only keep the largest ones whose size remains (significantly) smaller than the expected cell size. This might result in multiple seeds per cell, as depicted by red dots in Fig. 2.b and e. A unique label is then attached to each seed, adding one virtual label for the background. The fact that a single cell induces multiple seeds, and thus multiple labels, is not dramatic since the subsequent energy-minimization tends to filter redundant labels.\nTo obtain a label assignment that is compliant with the class probabilities obtained in Section 2, we define the cost functions in (5) upon the ferns scores: \u2022 the data fidelity of assigning a pixel p to a seed label fp builds on two complementary signals because we want the cost to increase largely when the path from a pixel to a seed crosses a cell border, whether this border is between the cell and the background or between two cells. Hence,\nDp(fp) = \u222b \u03c1 max (0, se(\u03c1)\u2212 si(\u03c1), sb(\u03c1)\u2212 si(\u03c1)) , (6)\nwhere si, sb and se correspond to the fern scores for the interior, the boundary and the exterior classes respectively, and \u03c1 is the set of pixels along the line connecting pixel p to the seed associated to fp [24]. The max operator is used to penalize the allocation of p to fp only when \u03c1 crosses a border, i.e. se > si or sb > si. As depicted in Fig. 2.c and d, the signal se\u2212 si indeed peaks for borders between the cells and the background while the signal sb\u2212si peaks for borders between two cells. \u2022 the data fidelity of assigning a pixel p to the background is the minimal exterior score integral computed over the set of lines \u0393dp, each line originating in p, and having a length d. Hence,\nDp(fp = e) = min \u03c1\u2208\u0393dp \u222b \u03c1 se(\u03c1). (7)\n\u2022 the graph edge weight W (p, q) between interacting pixels, that are adjacent pixels on an 8-neighborhood connectivity, is computed using a sigmoid function as\nW (p, q) = 1\u2212 1 1 + \u03b1we\u2212\u03b2wM(p,q) ,\nwhere M(p, q) is defined by\nM(p, q) = max k\u2208{p,q}\n( min ( sb(k)\u2212 si(k), sb(k)\u2212 se(k) )) .\nDoing so, the edge weight is low (high), allowing (discouraging) neighboring pixels to have different labels, when the probability of having a boundary at pixels p or q is high (low). Values for \u03b1w and \u03b2w are not critical and chosen empirically.\nMinimizing (5) is NP-hard. We compute an approximate solution efficiently using graph-cuts, with \u03b1-expansions, as described in [20]. This energy minimization framework is particularly well suited to our problem because it may account for multiple seeds spanning the same cell, as opposed to classical watershed approaches [17]."}, {"heading": "4. EXPERIMENTAL RESULTS", "text": "We validate our segmentation framework on a sequence of images with manually annotated ground truth, publicly released [25]1.\nTo define our training set based on the manually annotated cell contours (white dashed contours in Fig. 2.a), we rely on morphological operations. Specifically, the interior class is set with binary erosion while the exterior class is set with binary dilation. The boundary class is composed of pixels lying on the exterior region of at least 2 different cells.\nSince the number of annotated cells is limited and because we enforce balanced classes for training, our training set is restricted to 1500 pixels for each class. To increase the training set diversity and become invariant to rotation, we train the ferns on square windows that sample the image according to 10 different orientations. Each fern involves 10 tests, and we use 200 ferns. To measure the overall performance, we have run a 10-fold cross-validation, and have measured a classification accuracy of 94%, with 1% standard deviation.\nWe have then tested our energy minimization framework on all the images available in the dataset2,3. The parameters have been empirically selected as follows, d = 5, \u03b1w = 40 and \u03b2w = 15. Fig. 2 presents some representative examples of segmentation, together with some insightful intermediate metrics.\n1To favor reproducible research, our code will also be made publicly available at camera ready submission\n2see http://perso.uclouvain.be/arnaud.browet/bioseg/results.html for additional results.\n3To avoid overfitting, each image has been segmented based on ferns trained exclusively from other images annotations.\nFig. 2.b depicts the segmentation resulting from the ferns only, using an argmax decision defined in (4).\nFig. 2.c and d present the line integrals considered in equation (6). Note that the integral values are only provided in pixels that lies within a 50 pixels distance from a seed. This explains the particular landscape of Fig. 2.c and d. We observe that both metrics provide complementary information, delineating the cells either from the background or from an adjacent cells.\nThe last column in Fig. 2 presents the segmentation resulting from our proposed ferns-based energy minimization. We observe that the regions extracted are in very good agreement with the ground truth. As depicted in the 1st row of Fig. 2, our segmentation is able to accurately localize boundaries between touching cells. Moreover, our method is also able to merge multiple seeds within a unique region or to reject seeds situated in the background, as displayed in the 2nd row of Fig. 2."}, {"heading": "5. CONCLUSION", "text": "Our work has adopted an energy-minimization framework to segment cell images according to the cues provided by random ferns about the probability that each pixel is located within a cell or not.\nOur framework is highly versatile, since the classes definition and the energy terms can account for any prior knowledge related to the problem at hand. Additionally, it is also interactive-friendly, in the sense that the seeds definition can easily be manually adjusted, if needed."}, {"heading": "6. REFERENCES", "text": "[1] S. Nowotschin and A.-K. Hadjantonakis, \u201cLive imaging mouse embryonic development: Seeing is believing and revealing,\u201d Mouse Molecular Embryology, vol. 1092, October 2013.\n[2] S. J. Arnold and E. J. Robertson, \u201cMaking a commitment: cell lineage allocation and axis patterning in the early mouse embryo,\u201d Nature Reviews Molecular Cell Biology, vol. 10, no. 2, February 2009.\n[3] X. Lou, M. Kang, and P. Xenopoulos, et al., \u201cA rapid and efficient 2d/3d nuclear segmentation method for analysis of early mouse embryo and stem cell image data,\u201d Stem Cell Reports, vol. 2, no. 3, January 2014.\n[4] D. Comaniciu and P. Meer, \u201cMean shift: A robust approach toward feature space analysis,\u201d IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 24, no. 5, May 2002.\n[5] P.F. Felzenszwalb and D.P. Huttenlocher, \u201cEfficient graph-based image segmentation,\u201d Int. Journal of Computer Vision, vol. 59, no. 2, May 2004.\n[6] Romain Fernandez, Pradeep Das, Vincent Mirabet, and Eric Moscardi, et al., \u201cImaging plant growth in 4d: robust tissue reconstruction and lineaging at cell resolution,\u201d Nature Methods, vol. 7, no. 7, July 2010.\n[7] Zia Khan, Yu-Chiun Wang, Eric F. Wieschaus, and Matthias Kaschube, \u201cQuantitative 4d analyses of epithelial folding during drosophila gastrulation,\u201d Development, vol. 141, no. 14, 2014.\n[8] K. R. Mosaliganti, R. R. Noche, F. Xiong, I. A. Swinburne, and S. G. Megason, \u201cAcme: Automated cell morphology extractor for comprehensive reconstruction of cell membranes,\u201d PLoS Computational Biology, vol. 8, no. 12, December 2012.\n[9] P. Arbelaez, M. Maire, C. Fowlkes, and Malik J., \u201cContour detection and hierarchical image segmentation,\u201d IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 33, no. 5, May 2011.\n[10] C. Couprie, C. Farabet, Y. LeCun, and L. Najman, \u201cCausal graph-based video segmentation,\u201d in IEEE Int. Conf. on Image Processing, Sept 2013.\n[11] Dingding Liu, Yingen Xiong, L. Shapiro, and K. Pulli, \u201cRobust interactive image segmentation with automatic boundary refinement,\u201d in IEEE Int. Conf. on Image Processing, Oct. 2010.\n[12] H. Zhang and S.A. Goldman, \u201cImage segmentation using salient points-based object templates,\u201d in IEEE Int. Conf. on Image Processing, Oct. 2006.\n[13] C. Chen, W. Wang, J.A. Ozolek, and G.K Rohde, \u201cA flexible and robust approach for segmenting cell nuclei from 2d microscopy images using supervised learning and template matching,\u201d Cytometry A, vol. 85, no. 5, 2013.\n[14] K.-C.J. Chen, Ge Yang, and J. Kovacevic, \u201cSpatial density estimation based segmentation of super-resolution localization microscopy images,\u201d in IEEE Int. Conf. on Image Processing, Oct. 2014.\n[15] P.K. Roy, A. Bhuiyan, and K. Ramamohanarao, \u201cAutomated segmentation of multiple sclerosis lesion in intensity enhanced flair mri using texture features and support vector machine,\u201d in IEEE Int. Conf. on Image Processing, Oct. 2013.\n[16] J. Mairal, M. Leordeanu, F. Bach, M. Hebert, and J. Ponce, \u201cDiscriminative sparse image models for class-specific edge detection and image interpretation,\u201d in Eur. Conf. on Computer Vision, Oct. 2008.\n[17] Ting Liu, M. Seyedhosseini, M. Ellisman, and T. Tasdizen, \u201cWatershed merge forest classification for electron microscopy image stack segmentation,\u201d in IEEE Int. Conf. on Image Processing, Oct. 2013.\n[18] M. Ozuysal, M. Calonder, V. Lepetit, and P. Fua, \u201cFast keypoint recognition using random ferns,\u201d IEEE Trans. on Pattern Analysis and Machine Intelligence,, vol. 32, no. 3, March 2010.\n[19] P. Parisot, B. Sevilmis, and C. De Vleeschouwer, \u201cTraining with corrupted labels to reinforce a probably correct teamsport player detector,\u201d in Int. Conf. on Advanced Concepts for Intelligent Vision Systems, 2013.\n[20] A. Delong, A. Osokin, H. N. Isack, and Y. Boykov, \u201cFast approximate energy minimization with label costs,\u201d Int. Journal of Computer Vision, vol. 96, no. 1, 2011.\n[21] Y. Boykov, O. Veksler, and R. Zabih, \u201cFast approximate energy minimization via graph cuts,\u201d IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 23, no. 11, Nov 2001.\n[22] A. Bosch, A. Zisserman, and X. Munoz, \u201cImage classification using random forests and ferns,\u201d in IEEE Int. Conf. on Computer Vision, Oct 2007.\n[23] P. Geurts, D. Ernst, and L. Wehenkel, \u201cExtremely Randomized Trees,\u201d Machine Learning, vol. 63, no. 1, 2006.\n[24] J.E. Bresenham, \u201cAlgorithm for computer control of a digital plotter,\u201d IBM Systems Journal, vol. 4, no. 1, 1965.\n[25] Dataset available under the \u201cData/Software\u201d tab at, \u201chttp://sites.uclouvain.be/ispgroup,\u201d ."}], "references": [{"title": "Live imaging mouse embryonic development: Seeing is believing and revealing", "author": ["S. Nowotschin", "A.-K. Hadjantonakis"], "venue": "Mouse Molecular Embryology, vol. 1092, October 2013.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Making a commitment: cell lineage allocation and axis patterning in the early mouse embryo", "author": ["S.J. Arnold", "E.J. Robertson"], "venue": "Nature Reviews Molecular Cell Biology, vol. 10, no. 2, February 2009.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "A rapid and efficient 2d/3d nuclear segmentation method for analysis of early mouse embryo and stem cell image data", "author": ["X. Lou", "M. Kang", "P. Xenopoulos"], "venue": "Stem Cell Reports, vol. 2, no. 3, January 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Mean shift: A robust approach toward feature space analysis", "author": ["D. Comaniciu", "P. Meer"], "venue": "IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 24, no. 5, May 2002.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2002}, {"title": "Efficient graph-based image segmentation", "author": ["P.F. Felzenszwalb", "D.P. Huttenlocher"], "venue": "Int. Journal of Computer Vision, vol. 59, no. 2, May 2004.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2004}, {"title": "Imaging plant growth in 4d: robust tissue reconstruction and lineaging at cell resolution", "author": ["Romain Fernandez", "Pradeep Das", "Vincent Mirabet", "Eric Moscardi"], "venue": "Nature Methods, vol. 7, no. 7, July 2010.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Quantitative 4d analyses of epithelial folding during drosophila gastrulation", "author": ["Zia Khan", "Yu-Chiun Wang", "Eric F. Wieschaus", "Matthias Kaschube"], "venue": "Development, vol. 141, no. 14, 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Acme: Automated cell morphology extractor for comprehensive reconstruction of cell membranes", "author": ["K.R. Mosaliganti", "R.R. Noche", "F. Xiong", "I.A. Swinburne", "S.G. Megason"], "venue": "PLoS Computational Biology, vol. 8, no. 12, December 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Contour detection and hierarchical image segmentation", "author": ["P. Arbelaez", "M. Maire", "C. Fowlkes", "Malik J."], "venue": "IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 33, no. 5, May 2011.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Causal graph-based video segmentation", "author": ["C. Couprie", "C. Farabet", "Y. LeCun", "L. Najman"], "venue": "IEEE Int. Conf. on Image Processing, Sept 2013.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Robust interactive image segmentation with automatic boundary refinement", "author": ["Dingding Liu", "Yingen Xiong", "L. Shapiro", "K. Pulli"], "venue": "IEEE Int. Conf. on Image Processing, Oct. 2010.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Image segmentation using salient points-based object templates", "author": ["H. Zhang", "S.A. Goldman"], "venue": "IEEE Int. Conf. on Image Processing, Oct. 2006.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "A flexible and robust approach for segmenting cell nuclei from 2d microscopy images using supervised learning and template matching", "author": ["C. Chen", "W. Wang", "J.A. Ozolek", "G.K Rohde"], "venue": "Cytometry A, vol. 85, no. 5, 2013.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Spatial density estimation based segmentation of super-resolution localization microscopy images", "author": ["K.-C.J. Chen", "Ge Yang", "J. Kovacevic"], "venue": "IEEE Int. Conf. on Image Processing, Oct. 2014.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Automated segmentation of multiple sclerosis lesion in intensity enhanced flair mri using texture features and support vector machine", "author": ["P.K. Roy", "A. Bhuiyan", "K. Ramamohanarao"], "venue": "IEEE Int. Conf. on Image Processing, Oct. 2013.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Discriminative sparse image models for class-specific edge detection and image interpretation", "author": ["J. Mairal", "M. Leordeanu", "F. Bach", "M. Hebert", "J. Ponce"], "venue": "Eur. Conf. on Computer Vision, Oct. 2008.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2008}, {"title": "Watershed merge forest classification for electron microscopy image stack segmentation", "author": ["Ting Liu", "M. Seyedhosseini", "M. Ellisman", "T. Tasdizen"], "venue": "IEEE Int. Conf. on Image Processing, Oct. 2013.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Fast keypoint recognition using random ferns", "author": ["M. Ozuysal", "M. Calonder", "V. Lepetit", "P. Fua"], "venue": "IEEE Trans. on Pattern Analysis and Machine Intelligence,, vol. 32, no. 3, March 2010.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Training with corrupted labels to reinforce a probably correct teamsport player detector", "author": ["P. Parisot", "B. Sevilmis", "C. De Vleeschouwer"], "venue": "Int. Conf. on Advanced Concepts for Intelligent Vision Systems, 2013.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Fast approximate energy minimization with label costs", "author": ["A. Delong", "A. Osokin", "H.N. Isack", "Y. Boykov"], "venue": "Int. Journal of Computer Vision, vol. 96, no. 1, 2011.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Fast approximate energy minimization via graph cuts", "author": ["Y. Boykov", "O. Veksler", "R. Zabih"], "venue": "IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 23, no. 11, Nov 2001.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2001}, {"title": "Image classification using random forests and ferns", "author": ["A. Bosch", "A. Zisserman", "X. Munoz"], "venue": "IEEE Int. Conf. on Computer Vision, Oct 2007.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "Extremely Randomized Trees", "author": ["P. Geurts", "D. Ernst", "L. Wehenkel"], "venue": "Machine Learning, vol. 63, no. 1, 2006.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2006}, {"title": "Algorithm for computer control of a digital plotter", "author": ["J.E. Bresenham"], "venue": "IBM Systems Journal, vol. 4, no. 1, 1965.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1965}, {"title": "http://sites.uclouvain.be/ispgroup", "author": ["Dataset available under the \u201cData/Software\u201d tab at"], "venue": ".", "citeRegEx": "25", "shortCiteRegEx": null, "year": 0}], "referenceMentions": [{"referenceID": 0, "context": "Progress in embryo culture and live imaging techniques has allowed direct observation of cellular rearrangements in embryos from various species, including those with internal development [1].", "startOffset": 188, "endOffset": 191}, {"referenceID": 1, "context": "gration during mouse embryo gastrulation [2].", "startOffset": 41, "endOffset": 44}, {"referenceID": 2, "context": "To ensure optimal embryo survival, it is best to avoid multiple colors imaging [3], and we have thus favored a membrane marker.", "startOffset": 79, "endOffset": 82}, {"referenceID": 3, "context": "(a) Input and ground truth (b) Mean-Shift [4]", "startOffset": 42, "endOffset": 45}, {"referenceID": 4, "context": "[5] (d) Our result", "startOffset": 0, "endOffset": 3}, {"referenceID": 24, "context": "a, the fluorophores do not strictly concentrate along the cell membranes in our dataset [25].", "startOffset": 88, "endOffset": 92}, {"referenceID": 5, "context": "In contrast to images studied in [6, 7, 8], this makes the border between two adjacent cells difficult to isolate, even visually.", "startOffset": 33, "endOffset": 42}, {"referenceID": 6, "context": "In contrast to images studied in [6, 7, 8], this makes the border between two adjacent cells difficult to isolate, even visually.", "startOffset": 33, "endOffset": 42}, {"referenceID": 7, "context": "In contrast to images studied in [6, 7, 8], this makes the border between two adjacent cells difficult to isolate, even visually.", "startOffset": 33, "endOffset": 42}, {"referenceID": 8, "context": "This is in contrast with natural images, in which the objects to segment are characterized by distinct inner textures and color, and can therefore be effectively segmented using superpixel merging techniques [9].", "startOffset": 208, "endOffset": 211}, {"referenceID": 4, "context": "The graph-based method of Felzenszwalb and Huttenlocher merges the regions in a greedy manner, using a minimum spanning-tree to measure the pixels uniformity in a region and compare it to border transitions [5, 10].", "startOffset": 207, "endOffset": 214}, {"referenceID": 9, "context": "The graph-based method of Felzenszwalb and Huttenlocher merges the regions in a greedy manner, using a minimum spanning-tree to measure the pixels uniformity in a region and compare it to border transitions [5, 10].", "startOffset": 207, "endOffset": 214}, {"referenceID": 3, "context": "descent process [4].", "startOffset": 16, "endOffset": 19}, {"referenceID": 10, "context": "Among the approaches proposed in the literature to address semantic segmentation problems, [11] and [12] have respectively considered an interactive framework or a prior discriminative description of the object to segment.", "startOffset": 91, "endOffset": 95}, {"referenceID": 11, "context": "Among the approaches proposed in the literature to address semantic segmentation problems, [11] and [12] have respectively considered an interactive framework or a prior discriminative description of the object to segment.", "startOffset": 100, "endOffset": 104}, {"referenceID": 12, "context": "In the context of microscopy, [13] have defined such prior models based on templates, learned in a supervised manner.", "startOffset": 30, "endOffset": 34}, {"referenceID": 13, "context": "In super-resolution localization microscopy and in MRI, [14] and [15] respectively rely on density estimation or SVM texture features classification to differentiate structures of interest.", "startOffset": 56, "endOffset": 60}, {"referenceID": 14, "context": "In super-resolution localization microscopy and in MRI, [14] and [15] respectively rely on density estimation or SVM texture features classification to differentiate structures of interest.", "startOffset": 65, "endOffset": 69}, {"referenceID": 15, "context": "In cases where the object appearance is not discriminant, training appropriate edge detectors appears to be a natural approach [16, 17].", "startOffset": 127, "endOffset": 135}, {"referenceID": 16, "context": "In cases where the object appearance is not discriminant, training appropriate edge detectors appears to be a natural approach [16, 17].", "startOffset": 127, "endOffset": 135}, {"referenceID": 16, "context": "The work in [17] is of particular interest.", "startOffset": 12, "endOffset": 16}, {"referenceID": 17, "context": "We have chosen semi-Naive Bayesian estimation because it has been shown to be accurate and offer good robustness and generalization properties in many vision classification tasks [18, 19].", "startOffset": 179, "endOffset": 187}, {"referenceID": 18, "context": "We have chosen semi-Naive Bayesian estimation because it has been shown to be accurate and offer good robustness and generalization properties in many vision classification tasks [18, 19].", "startOffset": 179, "endOffset": 187}, {"referenceID": 19, "context": "[20], based on the seminal work of Boykov et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21].", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "Following many successful recent works [18, 22, 23], we use randomized sets of binary tests to characterize the different classes of point neighborhoods.", "startOffset": 39, "endOffset": 51}, {"referenceID": 21, "context": "Following many successful recent works [18, 22, 23], we use randomized sets of binary tests to characterize the different classes of point neighborhoods.", "startOffset": 39, "endOffset": 51}, {"referenceID": 22, "context": "Following many successful recent works [18, 22, 23], we use randomized sets of binary tests to characterize the different classes of point neighborhoods.", "startOffset": 39, "endOffset": 51}, {"referenceID": 17, "context": "As in [18], let C \u2208 C denote the random variable that represents the class of an image sample, and C = {ci : 0 < i \u2264 H} be the set of H = 3 interior/border/exterior classes.", "startOffset": 6, "endOffset": 10}, {"referenceID": 17, "context": "To keep the conditional probabilities tractable while accounting for some binary tests dependencies, the semi-naive Bayesian approach proposed in [18] assumes independence between the ferns, but accounts for dependencies between the binary tests belonging to the same fern.", "startOffset": 146, "endOffset": 150}, {"referenceID": 17, "context": "where the class conditional distribution of each fern is simply learned based on the accumulation of the training samples observations, as detailed in [18].", "startOffset": 151, "endOffset": 155}, {"referenceID": 20, "context": "The global energy minimization framework introduced in [21, 20] is used to assign cell-representative labels to pixels, based on their posterior interior/border/exterior class probabilities.", "startOffset": 55, "endOffset": 63}, {"referenceID": 19, "context": "The global energy minimization framework introduced in [21, 20] is used to assign cell-representative labels to pixels, based on their posterior interior/border/exterior class probabilities.", "startOffset": 55, "endOffset": 63}, {"referenceID": 19, "context": "Finally, as detailed in [20], the last term, hl (f), introduces a cost when f assigns the label l to at least one pixel.", "startOffset": 24, "endOffset": 28}, {"referenceID": 23, "context": "where si, sb and se correspond to the fern scores for the interior, the boundary and the exterior classes respectively, and \u03c1 is the set of pixels along the line connecting pixel p to the seed associated to fp [24].", "startOffset": 210, "endOffset": 214}, {"referenceID": 19, "context": "We compute an approximate solution efficiently using graph-cuts, with \u03b1-expansions, as described in [20].", "startOffset": 100, "endOffset": 104}, {"referenceID": 16, "context": "This energy minimization framework is particularly well suited to our problem because it may account for multiple seeds spanning the same cell, as opposed to classical watershed approaches [17].", "startOffset": 189, "endOffset": 193}, {"referenceID": 24, "context": "We validate our segmentation framework on a sequence of images with manually annotated ground truth, publicly released [25]1.", "startOffset": 119, "endOffset": 123}], "year": 2016, "abstractText": "The progress in imaging techniques have allowed the study of various aspect of cellular mechanisms. To isolate individual cells in live imaging data, we introduce an elegant image segmentation framework that effectively extracts cell boundaries, even in the presence of poor edge details. Our approach works in two stages. First, we estimate pixel interior/border/exterior class probabilities using random ferns. Then, we use an energy minimization framework to compute boundaries whose localization is compliant with the pixel class probabilities. We validate our approach on a manually annotated dataset.", "creator": "LaTeX with hyperref package"}}}