{"id": "1602.06484", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Feb-2016", "title": "Computational Narrative Intelligence: A Human-Centered Goal for Artificial Intelligence", "abstract": "Narrative intelligence is the ability to construct, tell, understand and react affectively to stories. We argue that imparting artificial intelligence with computer-assisted narrative intelligence enables a range of beneficial applications for humans. We outline some of the challenges that machine learning needs to solve to achieve computer-assisted narrative intelligence. Finally, we argue that computer-assisted narration is a practical step toward machine de-culturation, the imparting of socio-cultural values to machines.", "histories": [["v1", "Sun, 21 Feb 2016 01:59:09 GMT  (30kb,D)", "http://arxiv.org/abs/1602.06484v1", "5 pages, published in the CHI 2016 Workshop on Human-Centered Machine Learning"]], "COMMENTS": "5 pages, published in the CHI 2016 Workshop on Human-Centered Machine Learning", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["mark o riedl"], "accepted": false, "id": "1602.06484"}, "pdf": {"name": "1602.06484.pdf", "metadata": {"source": "META", "title": "Computational Narrative Intelligence: A Human-Centered Goal for Artificial Intelligence", "authors": ["Mark O. Riedl"], "emails": ["riedl@cc.gatech.edu"], "sections": [{"heading": "Author Keywords", "text": "Artificial Intelligence, Machine Learning, Narrative Intelligence, Machine Enculturation"}, {"heading": "ACM Classification Keywords", "text": "I.2.0 Artificial Intelligence: General"}, {"heading": "INTRODUCTION", "text": "Storytelling is an important part of how we, as humans, communicate, entertain, and teach each other. We tell stories dozens of times a day: around the dinner table to share experiences; through fables to teach values; through journalism to communicate important events, and in entertainment movies, novels, and computer games for fun. Stories also motivate people to learn, which is why they form the backbone of training scenarios and case studies at school or work.\nDespite the importance of storytelling as part of the human experience, computers still cannot reliably create and tell novel stories, nor understand stories told by humans. When computers do tell stories, via an eBook or computer game, they simply regurgitate something written by a human. They do not partake in the culture we are immersed in, as manifested through journalistic news articles, the movies we watch, or the books we read.\nWhy does it matter that computers cannot create, tell, or understand stories? Artificial intelligence has become more\nprevalent in our everyday lives. Soon, it will not be unusual for us to interact with more advanced forms of Siri or Cortana on a daily basis. However, when we use those systems today, we find it to be an alien sort of intelligence. The AI makes decisions that sometimes can be hard for us to make sense of. Their failures are often due to the fact that they cannot make sense of what we are trying to accomplish or why.\nNarrative intelligence is the ability to craft, tell, understand, and respond affectively to stories. Research in computational narrative intelligence seeks to instill narrative intelligence into computers. In doing so, the goal of developing computational narrative intelligence is to make computers better communicators, educators, entertainers, and more capable of relating to us by genuinely understanding our needs. Computational narrative intelligence is as much about human-computer interaction as it is about solving hard artificial intelligence problems.\nIn this position paper, we enumerate a number of humancentered applications of computational narrative intelligence that may be of benefit to humans interacting with artificial intelligences in the future. We also discuss some of the machine learning challenges that will need to be overcome through research to achieve computational narrative intelligence. Finally, we describe how computational intelligence can provide a way forward to creating artificial intelligences that are more human-like, better at understanding their human users, and more easily comprehended by human users."}, {"heading": "COMPUTATIONAL NARRATIVE INTELLIGENCE", "text": "Winston [37] argues that narrative intelligence is one of the abilities that sets humans apart from other animals and nonhuman-like artificial intelligences. Research in computational narrative intelligence has sought to create computational intelligences that can answer questions about stories, generate fictional stories and news articles, respond affectively to stories, and represent the knowledge contained in natural language narratives.\nGiven that humans communicate regularly and naturally though narratives, one of the long-standing challenges of computational narrative intelligence has been to answer questions about stories [32, 25, 36]. Question-answering is a way of verifying that a computer is able to understand what a human is saying. However, question-answering about narrative content is considered to be more challenging than fact-based question-answering due to the causal and temporal relationships between events, which can be complex and are often left\nar X\niv :1\n60 2.\n06 48\n4v 1\n[ cs\n.A I]\n2 1\nFe b\n20 16\nimplicit. One prerequisite for narrative question-answering is a better understanding of how to represent the knowledge contained in natural language narratives [4, 10, 5].\nThe flip-side of understanding stories is the creation of novel, fictional story content such as fairy tales and computer game plots [12, 31, 28, 38]. The obvious application of fictional story generation is entertainment. On-demand narrative generation can maintain a continuous flow of novel content for users to engage with while customizing the content to individual preferences and demands. One may imagine serial novels, serial scripts for TV shows and movies, or serial quests and plotlines in computer games. However, note that even entertainment can convey morals and other pedagogical aspects.\nComputational narrative intelligences can also create plausible sounding\u2014but fictional\u2014stories that might happen in the real world [33, 20]. While not meant to be entertaining, the generation of plausible real world stories provides a strong, objective measure of general computational intelligence. Plausible real-world story generation can be used to generate virtually unlimited scenarios for skill mastery in training simulations [39]. Computational narrative intelligences could engage in forensic investigations by hypothesizing about sequences of events that have not been directly observed. Virtual agents, such as virtual health coaches, can appear more life-like and create rapport with humans by sharing fictional vignettes and gossip [2].\nComputational narrative intelligence also brings computers one step closer to understanding the human experience and predicting how humans will respond to narrative content. Automated journalists generate narrative texts about real world events and data such as sports and financial reports (e.g., [1]). Automated journalists may benefit from narrative intelligence when determining how best to convey a narrative to different audiences. Going beyond journalism, it is important to note that humans can have very visceral emotional responses to stories. Understanding how the human will interpret and respond to narrative situations has important implications if we wish for computers to avoid accidentally making people upset or anxious. Computers may one day intentionally attempt to induce pleasure, or create a sense of suspense [26] in both entertainment and journalistic contexts.\nFinally, narrative can be used to explain the behavior of artificial intelligences. Any process or procedure can be told as a narrative, so it follows that an AI can describe the means by which it came to a conclusion or the reasons why it performed an action by couching its explanation in narrative terms. As part of a explanatory process, narratives can convey counterfactuals\u2014what would have happened if circumstances had been different. We hypothesize that narrative explanation will be more easily understood by non-expert human operators of artificial intelligence since the human mind is tuned for narrative understanding."}, {"heading": "MACHINE LEARNING CHALLENGES", "text": "Automated story understanding and automated story generation have a long history of pursuit in the field of artificial intelligence. Until recently, most approaches used hand-authored\nformal models of the story world domain the generator or understander would operate in [32, 23, 18, 25, 13, 31]. This made open-domain narrative intelligence\u2014the sort employed by humans\u2014intractable due to knowledge engineering bottlenecks. More recent approaches use machine learning to attempt to automatically acquire and reuse domain models from narrative corpora on the Internet [22, 4, 33] and from crowdsourcing [20].\nThere are at least four primary challenges related to learning domain models from narrative corpora and using them to create stories or explanations. First, human-written narratives are written to be consumed by other humans. We use theory of mind to infer what others are likely to already know and adjust our storytelling accordingly. Thus, human-written narratives collected into a corpus often leave out elements that are assumed to be commonly shared knowledge among other humans but possibly not known by computers. For example, a news corpus may have a story about bank robbery, but that story only has the points that make it unique from other bank robberies and \u201cnewsworthy.\u201d In some sense, all stories interesting enough to tell, or to have been told, are outliers from each other, making patterns hard to detect. A machine learning system would never learn about the aspects of the domain model that are most common to all bank robberies.\nStories are often told to highlight an unexpected obstacle or event in an otherwise typical situation. By virtue of telling a story of this sort, one may infer the counterfactual as the norm [14]. Crowdsourcing allows for greater control of the narrative content and can be used to acquire a corpus of typical stories about situations at the desired level of granularity [20]. Many children\u2019s books and television shows teach expectations for common situations such as going to a doctor\u2019s office or what to expect on the first day of school.\nSecond, narrative intelligence is closely associated with commonsense reasoning. It is necessary for both narrative understanding and for narrative generation. Humans learn commonsense knowledge and reasoning through a lifetime of experiences in the real world. Learning commonsense knowledge as been an ongoing challenge in AI and machine learning.\nCommonsense knowledge in the form of declarative facts and procedures will be essential in comprehending narratives. Research into automated commonsense knowledge acquisition includes [19, 21, 7, 24]. Images and video also implicitly capture commonsense knowledge (e.g., things fall downward, people kick balls but not bricks, etc.) [35] and techniques that jointly learn from stories with accompanying video or illustrations may provide key insights.\nThird, natural language stories written by humans for humans make abundant use of metaphors and metonymy [17]. Decoding the meaning of metaphors and metonymy requires high-level semantic comprehension of the narratives collected into a machine learning corpus.\nA few research projects have attempted to use metaphor in the automated generation of stories [15, 34]. Hobbs [16] lays out three general approaches to understanding metaphors: transferring properties from one entity to another, mapping aspects of\none thing to another by inference, or mapping aspects of one thing to another by analogy. Analogical mapping has received the most attention in computational narrative intelligence [8, 30, 38].\nFourth, creating stories requires a model of creativity as process that transcend straightforward pattern learning. The space of all possible, tellable, and interesting stories is vast. This is one explanation for why the generation of stories via sampling from recurrent neural networks trained on narrative corpora has not fared well to date because of the complexity of humanwritten narratives and the need for very large training sets. Further, stories make use of long-term causal connections between events that have not been easy to model; long term dependencies mean that stories, and the process of creating stories, are non-Markovian. However, some recent progress has been made in using long short-term memory neural nets that can extract script-like representations from text [27].\nDescriptions of human creativity emphasize the blending of two or more mental models to create new concepts. The appeal of conceptual blending [9] is the invention of concepts that might never have existed in a data set or even the real world. Conceptual blending shares similarities to unsupervised transfer learning, a critical area of research in machine learning. One example in the domain of creativity is the blending of two neural nets trained on different aspects of art [11]. However, an equivalent approach has not yet been found for story generation.\nSolving these challenges will be necessary in order to achieve a complete, open-domain, computational narrative intelligence that is trained from narrative corpora. In some cases, the challenges are those associated with semantic-level natural language processes. However note that television, movies, dramatic plays, comic books, and illustrated children\u2019s books can also be sources of valuable data and require integrated natural language processing and machine vision."}, {"heading": "MACHINE ENCULTURATION", "text": "In addition to the applications described ealier\u2014and assuming the above challenges can be met\u2014computational narrative intelligence may present a way forward toward machine enculturation [29]. Machine enculturation is the act of instilling social norms, customs, values, and etiquette into computers so that they can (a) more readily relate to us and (b) avoid harming us (physically or psychologically) or creating social disruptions. In a perfect world, humanity would come with a user manual that we could simply scan into a computer. However, for any sufficiently complex domain, such as the real world, manually encoding a comprehensive set of values or rewards in order to recreate sociocultural behavior is intractable.\nIf sociocultural values are not easily instilled in artificial intelligences, perhaps they can be learned. Instead of a user manual we have the collected works of fiction by different cultures and societies. This collected works give us examples with which to teach an artificial intelligence the \u201crules\u201d of our societies and cultures. These stories includes the fables or allegorical tales passed down from generation to generation,\nsuch as the tale of George Washington confessing to chopping down a cherry tree. Fictional stories meant to entertain can be viewed as examples of protagonists existing within and enacting the values of the culture to which they belong, from the mundane\u2014eating at a restaurant\u2014to the extreme\u2014saving the world.\nStories are an effective means of conveying complex tacit and experiential knowledge that implicitly encodes social and cultural values [3]. Humans do not need to be trained to communicate via storytelling, nor be trained to decode the knowledge contained within narratives. Computers will likely require require human-level narrative comprehension to mine social and cultural values from fictional and non-fictional narrative texts because those values are rarely made explicit.\nThe actions of characters in stories can be viewed as demonstrations of socioculturally appropriate behavior under hypothetical situations. Unlike demonstrations, which occur in the environment that the artificial intelligence will operate in, narratives may be more general. This presents some new challenges. Stories written in natural language can contain events and actions that are not executable by an artificial intelligence. Stories are written by humans for humans and thus make use of commonly shared knowledge, leaving many things unstated. Stories frequently skip over events that do not directly impact the telling of the story, and sometimes also employ flashbacks, flashforwards, and achrony which may confuse an artificial learner. However, learning from narratives can make certain things easier. Stories can make explicit the normally unobservable mental operations and thought processes of characters. Written stories make dialogue more explicit in terms of whom is speaking, although some ambiguity remains [6] and comprehension of language is still be an open challenge.\nMachine enculturation may give us a way forward toward achieving artificial intelligences that understand humans better, and make themselves more comprehensible\u2014less alien\u2014to humans. Further, agents and robotics that act in accordance with social values will naturally avoid situations where humans will be harmed or inconvenienced whenever possible. Harrison and Riedl [29] describe a technique, learning from stories (LfS), for emulating human behavior expressed in simple, crowdsourced narratives. It is proof of concept that machine enculturation may be feasible via machine learning over a corpus of stories."}, {"heading": "CONCLUSIONS", "text": "Narrative intelligence is central to many of the things we as humans do, from communication to entertainment to learning. Narrative is also an effective means of storing and disseminating culture. In this position paper we argue that future artificial intelligences should be instilled with computational narrative intelligence so that they can act like humans, or understand human wants, needs, and desires. Artificial intelligences instilled with computational narrative intelligence may be more effective at communicating with humans and explaining their behavior. Finally, computational narrative intelligence may be a practical step towards machine enculturation."}], "references": [{"title": "StatsMonkey: A Data-Driven Sports Narrative Writer", "author": ["Nicholas Allen", "John Templon", "Patrick Summerhays McNally", "Larry Birnbaum", "Kristian Hammond"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Engagement vs. Deceit: Virtual Humans with Human Autobiographies", "author": ["Timothy Bickmore", "Daniel Schulman", "Langxuan Yin"], "venue": "In Proceedings of the 2009 International Conference on Intelligent Virtual Agents", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "The Narrative Construction of Reality", "author": ["J. Bruner"], "venue": "Critical Inquiry 18,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1991}, {"title": "Unsupervised learning of narrative event chains", "author": ["Nathanael Chambers", "Dan Jurafsky"], "venue": "In Proceedings of 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Modeling Narrative Discourse", "author": ["David K. Elson"], "venue": "Ph.D. Dissertation. Columbia University", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Automatic Attribution of Quoted Speech in Literary Narrative", "author": ["David K. Elson", "Kathleen McKeown"], "venue": "In Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Open Information Extraction: the Second Generation", "author": ["Oren Etzioni", "Anthony Fader", "Janara Christensen", "Stephen Soderland", "Mausam"], "venue": "In Proceedings of the 2011 International Joint Conference on Artificial Intelligence", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "The Structure-Mapping Engine: Algorithms and Examples", "author": ["Brian Falkenhainer", "Ken Forbus", "Dedre Gentner"], "venue": "Artificial Intelligence", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1989}, {"title": "Conceptual Integration Networks", "author": ["Gilles Fauconnier", "Mark Turner"], "venue": "Cognitive Science", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "Learning Narrative Structure from Annotated Folktales", "author": ["Mark Finlayson"], "venue": "Ph.D. Dissertation. Department of Electrical Engineering and Computer Science,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Computational Approaches to Storytelling and Creativity", "author": ["Pablo Gerv\u00e1s"], "venue": "AI Magazine 30,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Story Plot Generation based on CBR", "author": ["Pablo Gerv\u00e1s", "Belen D\u00edaz-Agudo", "Federico Peinado", "Raquel Herv\u00e1s"], "venue": "Journal of Knowledge-Based Systems", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "Discovering Commonsense Entailment Rules Implicit in Sentences", "author": ["Jonathan Gordon", "Lenhart Schubert"], "venue": "In Proceedings of the TextInfer 2011 Workshop on Textual Entailment", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Cross-Domain Analogy in Automated Text Generation", "author": ["Raquel Herv\u00e1s", "Francisco Pereira", "Pablo Gerv\u00e1s", "Amilcar Cardoso"], "venue": "In Proceedings of the 3rd Workshop on Computational Creativity", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Metaphor and Abduction", "author": ["Jerry Hobbs"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1992}, {"title": "Women, Fire, and Dangerous Things: What Categories Reveal About the Mind", "author": ["George Lakoff"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1987}, {"title": "Planning stories", "author": ["Michael Lebowitz"], "venue": "In Proceedings of the 9th Annual Conference of the Cognitive Science Society", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1987}, {"title": "Cyc: A Large-Scale Investment in Knowledge Infrastructure", "author": ["Doug Lenat"], "venue": "Commun. ACM", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1995}, {"title": "Story Generation with Crowdsourced Plot Graphs", "author": ["Boyang Li", "Stephen Lee-Urban", "George Johnston", "Mark O. Riedl"], "venue": "In Proceedings of the 27th AAAI Conference on Artificial Intelligence", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "ConceptNet\u2013a practical commonsense reasoning tool-kit", "author": ["Hugo Liu", "Push Singh"], "venue": "BT Technology Journal 22,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2004}, {"title": "Plot Induction and Evolutionary Search for Story Generation", "author": ["Neil McIntyre", "Mirella Lapata"], "venue": "In The 48th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "TALE-SPIN: An Interactive Program that Writes Stories", "author": ["James R. Meehan"], "venue": "In Proceedings of the 5th International Joint Conference on Artificial Intelligence", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1977}, {"title": "Never-Ending Learning", "author": ["T. Mitchell", "W. Cohen", "E. Hruschka", "P. Talukdar", "J. Betteridge", "A. Carlson", "B. Dalvi", "M. Gardner", "B. Kisiel", "J. Krishnamurthy", "N. Lao", "K. Mazaitis", "T. Mohamed", "N. Nakashole", "E. Platanios", "A. Ritter", "M. Samadi", "B. Settles", "R. Wang", "D. Wijaya", "A. Gupta", "X. Chen", "A. Saparov", "M. Greaves", "J. Welling"], "venue": "In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI-15)", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Understanding script-based stories using commonsense reasoning", "author": ["Erik Mueller"], "venue": "Cognitive Systems Research 5,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2004}, {"title": "Dramatis: A Computational Model of Suspense", "author": ["Brian C. O\u2019Neill", "Mark O. Riedl"], "venue": "In Proceedings of the 28th AAAI Conference on Artificial Intelligence", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Learning Statistical Scripts with LSTM Recurrent Neural Networks", "author": ["Karl Pichotta", "Raymond Mooney"], "venue": "In Proceedings of the 30th AAAI Conference on Artificial Intelligence", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "Applying Planning to Interactive Storytelling: Narrative Control using State Constraints", "author": ["Julie Porteous", "Marc Cavazza", "Fred Charles"], "venue": "ACM Transactions on Intelligent Systems and Technology", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "Using Stories to Teach Human Values to Artificial Agents", "author": ["Mark Riedl", "Brent Harrison"], "venue": "In Proceedings of the 2nd International Workshop on AI, Ethics and Society", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "Case-Based Story Planning: Creativity Through Exploration, Retrieval, and Analogical Transformation", "author": ["Mark O. Riedl"], "venue": "Minds and Machines 20,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2010}, {"title": "Narrative Planning: Balancing Plot and Character", "author": ["Mark O. Riedl", "R. Michael Young"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2010}, {"title": "Scripts, Plans, Goals, and Understanding: An Inquiry into Human Knowledge Structures", "author": ["R. Schank", "R. Abelson"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1977}, {"title": "Say Anything: Using Textual Case-Based Reasoning to Enable Open-Domain Interactive Storytelling", "author": ["Reid Swanson", "Andrew Gordon"], "venue": "ACM Transactions on Interactive Intelligent Systems 2,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2012}, {"title": "Coming Good and Breaking Bad: Generating Transformative Character Arcs For Use in Compelling Stories", "author": ["Tony Veale"], "venue": "In Proceedings of the 2014 International Conference on Computational Creativity", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2014}, {"title": "Learning Common Sense Through Visual Abstraction", "author": ["Ramakrishna Vedantam", "Xiao Lin", "Tanmay Batra", "C. Lawrence Zitnick", "Devi Parikh"], "venue": "In Proceedings of the 2015 International Conference on Computer Vision", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2015}, {"title": "The Strong Story Hypothesis and the Directed Perception Hypothesis", "author": ["Patrick H. Winston"], "venue": "In Advances in Cognitive Systems: Papers from the 2011 AAAI Fall Symposium (Technical Report FSS-11-01),", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2011}, {"title": "Shall I Compare Thee to Another Story: An Empirical Study of Analogy-Based Story Generation", "author": ["Jichen Zhu", "Santiago Onta\u00f1\u00f3n"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2014}, {"title": "Automated Scenario Generation: Toward Tailored and Optimized Military Training in Virtual Environments", "author": ["Alexander Zook", "Mark O. Riedl", "Heather K. Holden", "Robert A. Sottilare", "Keith W. Brawner"], "venue": "In Proceedings of the 7th International Conference on the Foundations of Digital Games. Raleigh, North Carolina,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2012}], "referenceMentions": [{"referenceID": 34, "context": "Winston [37] argues that narrative intelligence is one of the abilities that sets humans apart from other animals and nonhuman-like artificial intelligences.", "startOffset": 8, "endOffset": 12}, {"referenceID": 30, "context": "Given that humans communicate regularly and naturally though narratives, one of the long-standing challenges of computational narrative intelligence has been to answer questions about stories [32, 25, 36].", "startOffset": 192, "endOffset": 204}, {"referenceID": 23, "context": "Given that humans communicate regularly and naturally though narratives, one of the long-standing challenges of computational narrative intelligence has been to answer questions about stories [32, 25, 36].", "startOffset": 192, "endOffset": 204}, {"referenceID": 3, "context": "One prerequisite for narrative question-answering is a better understanding of how to represent the knowledge contained in natural language narratives [4, 10, 5].", "startOffset": 151, "endOffset": 161}, {"referenceID": 9, "context": "One prerequisite for narrative question-answering is a better understanding of how to represent the knowledge contained in natural language narratives [4, 10, 5].", "startOffset": 151, "endOffset": 161}, {"referenceID": 4, "context": "One prerequisite for narrative question-answering is a better understanding of how to represent the knowledge contained in natural language narratives [4, 10, 5].", "startOffset": 151, "endOffset": 161}, {"referenceID": 10, "context": "The flip-side of understanding stories is the creation of novel, fictional story content such as fairy tales and computer game plots [12, 31, 28, 38].", "startOffset": 133, "endOffset": 149}, {"referenceID": 29, "context": "The flip-side of understanding stories is the creation of novel, fictional story content such as fairy tales and computer game plots [12, 31, 28, 38].", "startOffset": 133, "endOffset": 149}, {"referenceID": 26, "context": "The flip-side of understanding stories is the creation of novel, fictional story content such as fairy tales and computer game plots [12, 31, 28, 38].", "startOffset": 133, "endOffset": 149}, {"referenceID": 35, "context": "The flip-side of understanding stories is the creation of novel, fictional story content such as fairy tales and computer game plots [12, 31, 28, 38].", "startOffset": 133, "endOffset": 149}, {"referenceID": 31, "context": "Computational narrative intelligences can also create plausible sounding\u2014but fictional\u2014stories that might happen in the real world [33, 20].", "startOffset": 131, "endOffset": 139}, {"referenceID": 18, "context": "Computational narrative intelligences can also create plausible sounding\u2014but fictional\u2014stories that might happen in the real world [33, 20].", "startOffset": 131, "endOffset": 139}, {"referenceID": 36, "context": "Plausible real-world story generation can be used to generate virtually unlimited scenarios for skill mastery in training simulations [39].", "startOffset": 134, "endOffset": 138}, {"referenceID": 1, "context": "Virtual agents, such as virtual health coaches, can appear more life-like and create rapport with humans by sharing fictional vignettes and gossip [2].", "startOffset": 147, "endOffset": 150}, {"referenceID": 0, "context": ", [1]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 24, "context": "Computers may one day intentionally attempt to induce pleasure, or create a sense of suspense [26] in both entertainment and journalistic contexts.", "startOffset": 94, "endOffset": 98}, {"referenceID": 30, "context": "Until recently, most approaches used hand-authored formal models of the story world domain the generator or understander would operate in [32, 23, 18, 25, 13, 31].", "startOffset": 138, "endOffset": 162}, {"referenceID": 21, "context": "Until recently, most approaches used hand-authored formal models of the story world domain the generator or understander would operate in [32, 23, 18, 25, 13, 31].", "startOffset": 138, "endOffset": 162}, {"referenceID": 16, "context": "Until recently, most approaches used hand-authored formal models of the story world domain the generator or understander would operate in [32, 23, 18, 25, 13, 31].", "startOffset": 138, "endOffset": 162}, {"referenceID": 23, "context": "Until recently, most approaches used hand-authored formal models of the story world domain the generator or understander would operate in [32, 23, 18, 25, 13, 31].", "startOffset": 138, "endOffset": 162}, {"referenceID": 11, "context": "Until recently, most approaches used hand-authored formal models of the story world domain the generator or understander would operate in [32, 23, 18, 25, 13, 31].", "startOffset": 138, "endOffset": 162}, {"referenceID": 29, "context": "Until recently, most approaches used hand-authored formal models of the story world domain the generator or understander would operate in [32, 23, 18, 25, 13, 31].", "startOffset": 138, "endOffset": 162}, {"referenceID": 20, "context": "More recent approaches use machine learning to attempt to automatically acquire and reuse domain models from narrative corpora on the Internet [22, 4, 33] and from crowdsourcing [20].", "startOffset": 143, "endOffset": 154}, {"referenceID": 3, "context": "More recent approaches use machine learning to attempt to automatically acquire and reuse domain models from narrative corpora on the Internet [22, 4, 33] and from crowdsourcing [20].", "startOffset": 143, "endOffset": 154}, {"referenceID": 31, "context": "More recent approaches use machine learning to attempt to automatically acquire and reuse domain models from narrative corpora on the Internet [22, 4, 33] and from crowdsourcing [20].", "startOffset": 143, "endOffset": 154}, {"referenceID": 18, "context": "More recent approaches use machine learning to attempt to automatically acquire and reuse domain models from narrative corpora on the Internet [22, 4, 33] and from crowdsourcing [20].", "startOffset": 178, "endOffset": 182}, {"referenceID": 12, "context": "By virtue of telling a story of this sort, one may infer the counterfactual as the norm [14].", "startOffset": 88, "endOffset": 92}, {"referenceID": 18, "context": "Crowdsourcing allows for greater control of the narrative content and can be used to acquire a corpus of typical stories about situations at the desired level of granularity [20].", "startOffset": 174, "endOffset": 178}, {"referenceID": 17, "context": "Research into automated commonsense knowledge acquisition includes [19, 21, 7, 24].", "startOffset": 67, "endOffset": 82}, {"referenceID": 19, "context": "Research into automated commonsense knowledge acquisition includes [19, 21, 7, 24].", "startOffset": 67, "endOffset": 82}, {"referenceID": 6, "context": "Research into automated commonsense knowledge acquisition includes [19, 21, 7, 24].", "startOffset": 67, "endOffset": 82}, {"referenceID": 22, "context": "Research into automated commonsense knowledge acquisition includes [19, 21, 7, 24].", "startOffset": 67, "endOffset": 82}, {"referenceID": 33, "context": ") [35] and techniques that jointly learn from stories with accompanying video or illustrations may provide key insights.", "startOffset": 2, "endOffset": 6}, {"referenceID": 15, "context": "Third, natural language stories written by humans for humans make abundant use of metaphors and metonymy [17].", "startOffset": 105, "endOffset": 109}, {"referenceID": 13, "context": "A few research projects have attempted to use metaphor in the automated generation of stories [15, 34].", "startOffset": 94, "endOffset": 102}, {"referenceID": 32, "context": "A few research projects have attempted to use metaphor in the automated generation of stories [15, 34].", "startOffset": 94, "endOffset": 102}, {"referenceID": 14, "context": "Hobbs [16] lays out three general approaches to understanding metaphors: transferring properties from one entity to another, mapping aspects of", "startOffset": 6, "endOffset": 10}, {"referenceID": 7, "context": "Analogical mapping has received the most attention in computational narrative intelligence [8, 30, 38].", "startOffset": 91, "endOffset": 102}, {"referenceID": 28, "context": "Analogical mapping has received the most attention in computational narrative intelligence [8, 30, 38].", "startOffset": 91, "endOffset": 102}, {"referenceID": 35, "context": "Analogical mapping has received the most attention in computational narrative intelligence [8, 30, 38].", "startOffset": 91, "endOffset": 102}, {"referenceID": 25, "context": "However, some recent progress has been made in using long short-term memory neural nets that can extract script-like representations from text [27].", "startOffset": 143, "endOffset": 147}, {"referenceID": 8, "context": "The appeal of conceptual blending [9] is the invention of concepts that might never have existed in a data set or even the real world.", "startOffset": 34, "endOffset": 37}, {"referenceID": 27, "context": "In addition to the applications described ealier\u2014and assuming the above challenges can be met\u2014computational narrative intelligence may present a way forward toward machine enculturation [29].", "startOffset": 186, "endOffset": 190}, {"referenceID": 2, "context": "Stories are an effective means of conveying complex tacit and experiential knowledge that implicitly encodes social and cultural values [3].", "startOffset": 136, "endOffset": 139}, {"referenceID": 5, "context": "Written stories make dialogue more explicit in terms of whom is speaking, although some ambiguity remains [6] and comprehension of language is still be an open challenge.", "startOffset": 106, "endOffset": 109}, {"referenceID": 27, "context": "Harrison and Riedl [29] describe a technique, learning from stories (LfS), for emulating human behavior expressed in simple, crowdsourced narratives.", "startOffset": 19, "endOffset": 23}], "year": 2016, "abstractText": "Narrative intelligence is the ability to craft, tell, understand, and respond affectively to stories. We argue that instilling artificial intelligences with computational narrative intelligence affords a number of applications beneficial to humans. We lay out some of the machine learning challenges necessary to solve to achieve computational narrative intelligence. Finally, we argue that computational narrative is a practical step towards machine enculturation, the teaching of sociocultural values to machines.", "creator": "LaTeX with hyperref package"}}}