{"id": "1602.06897", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Feb-2016", "title": "Enablers and Inhibitors in Causal Justifications of Logic Programs", "abstract": "In this paper, we propose an extension of logic programming (LP), in which each standard dictionary derived from the well-founded model is associated with a justification that is presented as an algebraic expression, which contains both causal explanations (in the form of evidence curves created with rule names) and terms within the framework of negation that represent conditions that enable or prevent the application of causal rules. We will use a few examples to discuss how these new conditions, which we call \"enablers\" and \"inhibitors,\" are closely related to the standard negation and have a substantially different character from regular cause-effect relationships. The main result is a formal comparison with the recent algebraic justification approaches in LP: \"Why-not Provenance\" (WnP) and \"Causal Graphs\" (CG). We show that the current approach establishes both WnP and CG justifications under the Well-Founded Sementics extends a formal relationship between these two approaches.", "histories": [["v1", "Mon, 22 Feb 2016 19:18:54 GMT  (65kb)", "http://arxiv.org/abs/1602.06897v1", null]], "reviews": [], "SUBJECTS": "cs.LO cs.AI", "authors": ["pedro cabalar", "jorge fandinno"], "accepted": false, "id": "1602.06897"}, "pdf": {"name": "1602.06897.pdf", "metadata": {"source": "CRF", "title": "Enablers and Inhibitors in Causal Justifications of Logic Programs\u2217", "authors": ["Pedro Cabalar", "Miroslaw Truszczynski"], "emails": ["jorge.fandino}@udc.es)"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 2.\n06 89\n7v 1\n[ cs\n.L O\nKEYWORDS: causal justifications, well-founded semantics, stable models, answer set programming."}, {"heading": "1 Introduction", "text": "The strong connection between Non-Monotonic Reasoning (NMR) and Logic Programming (LP) semantics for default negation has made possible that LP tools became nowadays an important paradigm for Knowledge Representation (KR) and problem-solving in Artificial Intelligence (AI). In particular, Answer Set Programming (ASP) (Niemela\u0308 1999; Marek and Truszczyn\u0301ki 1999) has established as a preeminent LP paradigm for practical NMR with applications in diverse areas of AI including planning, reasoning about actions, diagnosis, abduction and beyond. The ASP paradigm is based on the stable models semantics (Gelfond and Lifschitz 1988) and is also closely related to the other mainly accepted interpretation for default negation, well-founded semantics (WFS) (Van Gelder et al. 1991). One interesting difference between these two LP semantics and classical models (or even other NMR approaches) is that true atoms in LP must be founded or justified by a given derivation. These justifications are not provided in the semantics\n\u2217 This is an extended version of a paper presented at the Logic Programming and Nonmonotonic Reasoning Conference (LPNMR 2015), invited as a rapid communication in TPLP. The authors acknowledge the assistance of the conference program chairs Giovambattista Ianni and Miroslaw Truszczynski.\nitself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).\nRather than manipulating justifications as mere syntactic objects, two recent approaches have considered extended multi-valued semantics for LP where justifications are treated as algebraic constructions: Why-not Provenance (WnP) (Dama\u0301sio et al. 2013) and Causal Graphs (CG) (Cabalar et al. 2014a). Although these two approaches present formal similarities, they start from different understandings of the idea of justification. On the one hand, WnP answers the query \u201cwhy literal L might hold\u201d by providing conjunctions of hypothetical modifications on the program that would allow deriving L. These modifications include rule labels, expressions like not(A) with A an atom, or negations \u2018\u00ac\u2019 of the two previous cases. As an example, a justification for L like r1 \u2227not(p)\u2227\u00acr2 \u2227\u00acnot(q) means that the presence of rule r1 and the absence of atom p would allow deriving L (hypothetically) if both rule r2 were removed and atom q were added to the program. If we want to explain why L actually holds, we have to restrict to justifications without \u2018\u00ac\u2019, that is, those without program modifications (which will be the focus of this paper).\nOn the other hand, CG-justifications start from identifying program rules as causal laws so that, for instance, (p \u2190 q) can be read as \u201cevent q causes effect p.\u201d Under this viewpoint, (positive) rules offer a natural way for capturing the concept of causal production, i.e. a continuous chain of events that has helped to cause or produce an effect (Hall 2004; Hall 2007). The explanation of a true atom is made in terms of graphs formed by rule labels that reflect the ordered rule applications required for deriving that atom. These graphs are obtained by algebraic operations exclusively applied on the positive part of the program. Default negation in CG is understood as absence of cause and, consequently, a false atom has no justification.\nThe explanation of an atom A in CG is more detailed than in WnP, since the former contains graphs that correspond to all relevant proofs of A whereas in WnP we just get conjunctions that do not reflect any particular ordering among rule applications. However, as explained before, CG does not capture the effect of default negation in a given derivation and, sometimes, this information is very valuable, especially if we want to answer questions of the form \u201cwhy not.\u201d\nAs in the previous paper on CG (Cabalar et al. 2014a), our final goal is to achieve an elaboration tolerant representation of causality that allows reasoning about cause-effect relations. Under this perspective, although WnP is more oriented to program debugging, its possibility of dealing with hypothetical reasoning of the form \u201cwhy not\u201d would be an interesting feature to deal with counterfactuals, since several approaches to causality (see Section 5) are based on this concept. To understand the kind of problems we are interested in, consider the following example. A drug d in James Bond\u2019s drink causes his paralysis p provided that he was not given an antidote a that day. We know that Bond\u2019s enemy, Dr. No, poured the drug:\np \u2190 d, nota (1)\nd (2)\nIn this case it is obvious that d causes p, whereas the absence of a just enables the application of the rule. Now, suppose we are said that Bond is daily administered an antidote by the MI6, unless it is a holiday h:\na \u2190 noth (3)\nAdding this rule makes a become an inhibitor of p, as it prevents d to cause p by rule (1). But suppose now that we are in a holiday, that is, fact h is added to the program (1)-(3). Then, the\ninhibitor a is disabled and d causes p again. However, we do not consider that the holiday h is a (productive) cause for Bond\u2019s paralysis p although, indeed, the latter counterfactually depends on the former: \u201chad not been a holiday h, Bond would have not been paralysed.\u201d We will say that the fact h, which disables inhibitor a, is an enabler of p, as it allows applying rule (1).\nIn this work we propose dealing with these concepts of enablers and inhibitors by augmenting CG justifications with a new negation operator \u2018\u223c\u2019 in the CG causal algebra. We show that this new approach, which we call Extended Causal Justifications (ECJ), captures WnP justifications under the Well-founded Semantics, establishing a formal relation between WnP and CG as a byproduct.\nThe rest of the paper is structured as follows. The next section defines the new approach. Sections 3 and 4 explain the formal relations to CG and WnP through a running example. Section 5 studies several examples of causal scenarios from the literature and finally, Section 6 concludes the paper. Appendix A contains an auxiliary figure depicting some common algebraic properties and Appendix B contains the formal proofs of theorems from the previous sections."}, {"heading": "2 Extended Causal Justifications (ECJ)", "text": "A signature is a pair \u3008At,Lb\u3009 of sets that respectively represent atoms (or propositions) and labels. Intuitively, each atom in At will be assigned justifications built with rule labels from Lb. In principle, the intersection At \u2229Lb does not need to be empty: we may sometimes find it convenient to label a rule using an atom name (normally, the head atom). Justifications will be expressions that combine four different algebraic operators: a product \u2018\u2217\u2019 representing conjunction or joint causation; a sum \u2018+\u2019 representing alternative causes; a non-commutative product \u2018\u00b7\u2019 that captures the sequential order that follows from rule applications; and a non-classical negation \u2018\u223c\u2019 which will precede inhibitors (negated labels) and enablers (doubly negated labels).\nDefinition 1 (Terms) Given a set of labels Lb, a term, t is recursively defined as one of the following expressions t ::= l | \u220fS | \u2211S | t1 \u00b7 t2 | \u223ct1 where l \u2208 Lb, t1, t2 are in their turn terms and S is a (possibly empty and possibly infinite) set of terms. A term is elementary if it has the form l, \u223cl or \u223c\u223cl with l \u2208 Lb being a label.\nWhen S = {t1, . . . , tn} is finite we simply write \u220fS as t1\u2217\u00b7 \u00b7 \u00b7\u2217 tn and \u2211S as t1+ \u00b7 \u00b7 \u00b7+ tn. Moreover, when S = /0, we denote \u220fS by 1 and \u2211S by 0, as usual, and these will be the identities of the product \u2018\u2217\u2019 and the addition \u2018+\u2019, respectively. We assume that \u2018\u00b7\u2019 has higher priority than \u2018\u2217\u2019 and, in turn, \u2018\u2217\u2019 has higher priority than \u2018+\u2019.\nDefinition 2 (Values) A (causal) value is each equivalence class of terms under axioms for a completely distributive (complete) lattice with meet \u2018\u2217\u2019 and join \u2018+\u2019 plus the axioms of Figures 1 and 2. The set of (causal) values is denoted by VLb.\nNote that \u3008VLb,+,\u2217,\u223c ,0,1\u3009 is a completely distributive Stone algebra (a pseudo-complemented, completely distributive, complete lattice which satisfies the weak excluded middle axiom) whose meet and join are, as usual, the product \u2018\u2217\u2019 and the addition \u2018+\u2019. Informally speaking, this means that these two operators satisfy the properties of a Boolean algebra but without negation.\nNote also that all three operations, \u2018\u2217\u2019, \u2018+\u2019 and \u2018\u00b7\u2019 are associative. Product \u2018\u2217\u2019 and addition \u2018+\u2019 are also commutative, and they hold the usual absorption and distributive laws with respect to infinite sums and products of a completely distributive lattice.\nThe axioms for \u2018\u00b7\u2019 in Figure 1 are directly extracted from the CG algebraic structure. For a more detailed explanation on their induced behaviour see (Cabalar et al. 2014a). The new contribution in this paper with respect to the CG algebra is the introduction of the \u2018\u223c\u2019 operator whose meaning is captured by the axioms in Figure 2. As we can see, this operator satisfies De Morgan laws and acts as a complement for the product t \u2217\u223ct = 0. However, it diverges from a classical Boolean negation in some aspects. In the general case, the axioms \u223c\u223ct = t (double negation) and t +\u223ct = 1 (excluded middle) are not valid. Instead1, we can replace a triple negation \u223c\u223c\u223ct by \u223ct, and we have a weak version of the excluded middle axiom \u223ct +\u223c\u223ct = 1. The negation of an application is defined as the negation of the product \u223c(t \u00b7 u) def= \u223c(t \u2217 u) which, in turn, is equivalent to \u223c(u\u2217t), since \u2217 is commutative. In other words, under negation, the rule application ordering is disregarded. It is not difficult to see that we can apply the axioms of negation to reach an equivalent expression that avoids its application to other operators. We say that a term is in negation normal form (NNF) if no other operator is in the scope of negation \u2018\u223c\u2019. Moreover, an NNF term is in disjuntive normal form (DNF) if: (1) no sum is in the scope of another operator; (2) only elementary terms are in the scope of application; and (3) every product is transitively closed, that is, of the form of a\u00b7b \u2217 b\u00b7c \u2217 a\u00b7c. Without loss of generality, we assume from now that all functions defined over causal terms are applied over their DNF form, although, we will usually write them in NNF for short.\nThe lattice order relation is defined as usual in the following way:\nt \u2264 u iff (t \u2217 u = t) iff (t + u = u)\nConsequently 1 and 0 are respectively the top and bottom elements with respect to relation \u2264.\nDefinition 3 (Labelled logic program)\n1 This behaviour coincides indeed with the properties for default negation obtained in Equilibrium Logic (Pearce 1996) or the equivalent General Theory of Stable Models (Ferraris et al. 2007).\nGiven a signature \u3008At,Lb\u3009, a (labelled logic) program P is a set of rules of the form:\nri : H \u2190 B1, . . . , Bm, notC1, . . . , notCn (4)\nwhere ri \u2208 Lb is a label or ri = 1, H (the head of the rule) is an atom, and Bi\u2019s and Ci\u2019s (the body of the rule) are either atoms or terms.\nWhen n = 0 we say that the rule is positive, furthermore, if in addition m = 0 we say that the rule is a fact and omit the symbol \u2018\u2190.\u2019 When ri \u2208 Lb we say that the rule is labelled; otherwise ri = 1 and we omit both ri and \u2018:\u2019. By these conventions, for instance, an unlabelled fact A is actually an abbreviation of (1 : A \u2190). A program P is positive when all its rules are positive, i.e. it contains no default negation. It is uniquely labelled when each rule has a different label or no label at all. In this paper, we will assume that programs are uniquely labelled. Furthermore, for the sake of clarity, we also assume that, for every atom A \u2208 At, there is an homonymous label A \u2208 Lb, and that each fact A in the program actually stands for the labelled rule (A : A \u2190). For instance, following these conventions, a possible labelled version for the James Bond\u2019s program could be program P1 below:\nr1 : p \u2190 d,nota\nr2 : a \u2190 noth\nd\nh\nwhere facts d and h stand for rules (d : d \u2190) and (h : h \u2190), respectively. An ECJ-interpretation is a mapping I : At \u2212\u2192 VLb assigning a value to each atom. For interpretations I and J we say that I \u2264 J when I(A)\u2264 J(A) for each atom A \u2208 At. Hence, there is a \u2264-bottom interpretation 0 (resp. a \u2264-top interpretation 1) that stands for the interpretation mapping each atom A to 0 (resp. 1). The value assigned to a negative literal notA by an interpretation I, denoted as I(notA), is defined as I(notA) def=\u223cI(A), as expected. Similarly, for a term t, I(t) def= [t] is the equivalence class of t.\nDefinition 4 (Model) An interpretation I satisfies a rule like (4) iff\n( I(B1)\u2217 . . .\u2217 I(Bm)\u2217 I(notC1)\u2217 . . .\u2217 I(notCn) ) \u00b7 ri \u2264 I(H) (5)\nand I is a (causal) model of P, written I |= P, iff I satisfies all rules in P.\nAs usual in LP, for positive programs, we may define a direct consequence operator TP s.t.\nTP(I)(H) def= \u2211\n{ ( I(B1)\u2217 . . .\u2217 I(Bn) ) \u00b7 ri | (ri : H \u2190 B1, . . . ,Bn) \u2208 P }\nfor any interpretation I and atom H \u2208 At. We also define TP \u2191\u03b1 (0) def= TP(TP \u2191\u03b1\u22121 (0)) for any successor ordinal \u03b1 and\nTP \u2191 \u03b1 (0) def= \u2211\n\u03b2<\u03b1 TP \u2191\n\u03b2 (0)\nfor any limit ordinal alpha. As usual, \u03c9 denotes the smallest infinite limit ordinal. Note that 0 is considered a limit ordinal and, thus, TP \u21910 (0) = \u2211\u03b2<0 TP \u2191\u03b2 (0) = 0.\nTheorem 1 Let P be a (possibly infinite) positive logic program. Then, (i) the least fixpoint of the TP operator, denoted by lfp(TP), satisfies lfp(TP) = TP \u2191\u03c9 (0) and it is the least model of P, (ii) furthermore, if P is positive and has n rules, then lfp(TP) = TP \u2191\u03c9 (0) = TP \u2191n (0).\nTheorem 1 asserts that, as usual, positive programs have a \u2264-least causal model. As we will see later, this least model coincides with the traditional least model (of the program without labels) when one just focuses on the set of true atoms, disregarding the justifications explaining why they are true. For programs with negation we define the following reduct.\nDefinition 5 (Reduct) Given a program P and an interpretation I we denote by PI the positive program containing a rule of the form\nri : H \u2190 B1, . . . ,Bm, I(notC1), . . . , I(notCn) (6)\nfor each rule of the form (4) in P.\nProgram PI is positive and, from Theorem 1, it has a least causal model. By \u0393P(I) we denote the least model of program PI . The operator \u0393P is anti-monotonic and, consequently, \u03932P is monotonic (Proposition 4 in the appendix) so that, by Knaster-Tarski\u2019s theorem, it has a least fixpointLP and a greatest fixpoint UP\ndef= \u0393P(LP). These two fixpoints respectively correspond to the justifications for true and for non-false atoms in the (standard) well-founded model (WFM), we denote as WP.\nFor instance, in our running example, LP1 (d) = \u03932P1 \u2191\u03b1 (0)(d) = d for 1 \u2264 \u03b1 points out that atom d is true because of fact d. Similarly, LP1 (h) = h and LP1 (a) =\u223ch\u00b7r2 reveals that atom h is true because of fact h, and that atom a is not true because fact h has inhibited rule r2. Furthermore,\nLP1 (p) = \u03932P1 \u2191\u03b1 (0)(p) = (\u223c(\u223ch\u00b7r2)\u2217 d)\u00b7r1 = (\u223c\u223ch \u2217 d)\u00b7r1 +(\u223cr2 \u2217 d)\u00b7r1\nfor 2 \u2264 \u03b1 . That is, Bond has been paralysed because fact h has enabled drug d to cause the paralysis by means of rule r1. This corresponds to the justification (\u223c\u223ch \u2217 d)\u00b7r1. Notice how the real cause d is a positive label (not in the scope of negation) whereas the enabler h is in the scope of a a double negation \u223c\u223ch. Justification (\u223cr2 \u2217 d)\u00b7r1 means that d\u00b7r1 would have been sufficient to cause p, had not been present r2. This example is also useful for illustrating the importance of axiom appl. negation. By directly evaluating the body of rule r1, we have seen that \u03932P1 \u21912 (0)(p)=(\u223c(\u223ch \u00b7 r2)\u2217 d) \u00b7 r1. Then, axiom appl. negation allows us to break the dependence between \u223ch and r2 into enablers and inhibitors: \u223c(\u223ch \u00b7 r2) =\u223c(\u223ch \u2217 r2) =\u223c\u223ch+\u223cr2 and, applying distributivity, we obtain one enabled justification, (\u223c\u223ch \u2217 d)\u00b7r1, and one disabled one, (\u223cr2 \u2217 d)\u00b7r1.\nIn our previous example, the least and greatest fixpoint coincided LP1 =UP1 = \u03932P1 \u21912 (0). To illustrate the case where this does not hold consider, for instance, the program P2 formed by the following negative cycle:\nr1 : a \u2190 notb r2 : b \u2190 nota\nIn this case, the least fixpoint of \u03932P assigns LP2(a) =\u223cr2\u00b7r1 and LP2(b) = \u223cr1\u00b7r2, while, in its turn, the greatest fixpoint of \u03932P corresponds to UP2(a) = r1 and UP2(b) = r2. If we focus on atom a, we can observe that it is not concluded to be true, since the least fixpoint LP has only provided one disabled justification \u223cr2\u00b7r1 meaning that r2 is acting as a disabler for a. But, on the other hand, a cannot be false either since the greatest fixpoint provides an enabled justification r1 for being non-false (remember that UP provides justifications for non-false atoms). As a result, we get that a is left undefined because r2 prevents it to become true while r1 can still be used to conclude that it is not false.\nTo capture these intuitions, we provide some definitions. A query literal (q-literal) L is either an atom A, its default negation \u2018notA\u2019 or the expression \u2018undef A\u2019 meaning that A is undefined.\nDefinition 6 (Causal well-founded model) Given a program P, its causal well-founded model WP is a mapping from q-literals to values s.t.\nWP(A) def= LP(A) WP(notA) def= \u223cUP(A) WP(undef A) def=\u223cWP(A)\u2217\u223cWP(notA)\nLet l be a label occurrence in a term t in the scope of n \u2265 0 negations. We say that l is an odd or an even occurrence if n is odd or even, respectively. We further say that l is a strictly even occurrence if it is even and n > 0.\nDefinition 7 (Justification) Given a program P and a q-literal L we say that a term E with no sums is a (sufficient causal) justification for L iff E \u2264 WP(L). Odd (resp. strictly even) labels2 in E are called inhibitors (resp. enablers) of E . A justification is said to be inhibited if it contains some inhibitor and it is said to be enabled otherwise.\nTrue atoms will have at least one enabled justification, whereas false atoms only contain disabled justifications. As an example of a query for a plain atom A, take the already seen explanation for p in Bond\u2019s example program P1: WP1 (p)=LP1 (p)=(\u223c\u223ch \u2217 d)\u00b7r1 +(\u223cr2 \u2217 d)\u00b7r1. We have here two justifications for atom p, let us call them E1=(\u223c\u223ch\u2217d)\u00b7r1 and E2 = (\u223cr2 \u2217d)\u00b7r1. Justification E1 is enabled because it contains no inhibitors (in fact, E1 is the unique real support for p). Moreover, h is an enabler in E1 because it is strictly even (it is in the scope of double negation) whereas d is a productive cause, since it is not in the scope of any negation. On the contrary, E2 is disabled because it contains the inhibitor r2 (it occurs in the scope of one negation). Intuitively, r2 has prevented d\u00b7r1 to become a justification of p. On the other hand, for atom a we had WP1\n(a)=\u223ch \u00b7 r2 that only contains an inhibited justification (being h the inhibitor), and so, atom a is not true. Now, if we query about the negative q-literal nota, we obtain WP1 (nota)=\u223cUP1 (a) which in this case happens to be \u223cLP1\n(a)=\u223c(\u223ch \u00b7 r2) = \u223c\u223ch+\u223cr2. That is, q-literal nota holds, being enabled by h. Moreover, \u223cr2 points out that removing r2 would suffice to cause nota too. It is easy to see that the explanations we can get for q-literals notA or undef A will have all their labels in the scope of negation (either as inhibitors or as enablers).\nTo illustrate a query for undef A, let us return to program P2 whose standard well-founded model left both a and b undefined. Given the values we obtained in the least and greatest fixpoints, the causal WFM will assign WP2 (a) = \u223cr2\u00b7r1 and WP2 (b) = \u223cr1\u00b7r2, that is, r2 prevents r1 to cause a and r1 prevents r2 to cause b. Furthermore, the values assigned to their respective negations, WP2 (nota) = \u223cr1 and WP2 (notb) = \u223cr2, point out that atoms a and b are not false because rules r1 and r2 have respectively prevented them to be so. Finally, we obtain that undef a is true because\nWP(undef a) =\u223cWP2 (a)\u2217\u223cWP2 (nota) = (\u223c\u223cr2 +\u223cr1)\u2217\u223c\u223cr1 =\u223c\u223cr2 \u2217\u223c\u223cr1\nthat is, rules r1 and r2 together have made a undefined. Similarly, b is also undefined because of rules r1 and r2, WP(undef b) =\u223c\u223cr1 \u2217\u223c\u223cr2.\n2 We just mention labels, and not their occurrences because terms are in NNF and E contains no sums. Thus, having odd and even occurrences of a same label at a same time would mean that E = 0.\nThe next theorem shows that the literals satisfied by the standard WFM are precisely those ones containing at least one enabled justification in the causal WFM.\nTheorem 2 Let P be a labelled logic program over a signature \u3008At,Lb\u3009 where Lb is a finite set of labels and let WP its (standard) well-founded model. A q-literal L holds with respect to WP if and only if there is some enabled justification E of L, that is, E \u2264WP(L) and E does not contain odd negative labels.\nBack to our example program P1, as we had seen, atom p had a unique enabled justification E1 = (\u223c\u223ch \u2217 d)\u00b7r1. The same happens for atoms d and h whose respective justifications are just their own atom labels. Therefore, these three atoms hold in the standard WFM, WP1. On the contrary, as we discussed before, the only justification for a, WP1 (a) = \u223ch\u00b7r2, is inhibited by h, and thus, a does not hold in WP1 . The interest of an inhibited justification for a literal is to point out \u201cpotential\u201d causes that have been prevented by some abnormal situation. In our case, the presence of \u223ch in WP1\n(a) = \u223ch\u00b7r2 points out that an exception h has prevented r2 to cause a. When the exception is removed, the inhibited justification (after removing the inhibitors) becomes an enabled justification.\nIn our running example, if we consider a program P3 obtained by removing the fact h from P1, then WP3(a) = r2 points out that a has been caused by rule r2 in this new scenario. This intuition about inhibited justifications is formalized as follows.\nDefinition 8 Given a term t in DNF, by \u03c1x : VCGLb \u2212\u2192 V CG Lb , we denote the function that removes the elementary term x from t as follows:\n\u03c1x(t) def=\n\n  \n  \n\u03c1x(u)\u2297\u03c1x(w) if t = u\u2297 v with \u2297 \u2208 {+,\u2217, \u00b7} 1 if \u223c\u223ct is equivalent to \u223c\u223cx\n0 if t is equivalent to \u223cx\nNote that we have assumed that t is in DNF. Otherwise, \u03c1x(t) def= \u03c1x(u) where u is an equivalent term in DNF.\nTheorem 3 Let P be a program over a signature \u3008At,Lb\u3009 where Lb is a finite set of labels. Let Q be the result of removing from P all rules labelled by some ri \u2208 Lb. Then, the result of removing ri from the justifications of some atom A with respect to program P are justifications of A with respect to Q, that is, \u03c1\u223cri(WP(A))\u2264WQ(A)."}, {"heading": "3 Relation to Causal Graph Justifications", "text": "We discuss now the relation between ECJ and CG approaches. Intuitively, ECJ extends CG causal terms by the introduction of the new negation operator \u2018\u223c\u2019. Semantically, however, there are more differences than a simple syntactic extension. A first minor difference is that ECJ is defined in terms of a WFM, whereas CG defines (possibly) several causal stable models. In the case of stratified programs, this difference is irrelevant, since the WFM is complete and coincides with the unique stable model. A second, more important difference is that CG exclusively considers productive causes in the justifications, disregarding additional information like the inhibitors or\nenablers from ECJ. As a result, a false atom in CG has no justification \u2013 its causal value is 0 because there was no way to derive the atom. For instance, in program P1, the only CG stable model I just makes I(a) = 0 and we lose the inhibited justification \u223ch \u00b7 r2 (default r2 could not be applied). True atoms like p also lose any information about enablers: I(p) = d\u00b7r1 and nothing is said about \u223c\u223ch. Another consequence of the CG orientation is that negative literals notA are never assigned a cause (different from 0 or 1), since they cannot be \u201cderived\u201d or produced by rules. In the example, we simply get I(nota) = 1 and I(not p) = 0.\nTo further illustrate the similarities and differences between ECJ and CG, consider the following program P4 capturing a variation of the Yale Shooting Scenario.\ndt+1 : deadt+1 \u2190 shoott , loadedt , notabt\nlt+1 : loadedt+1 \u2190 loadt\nat+1 : abt+1 \u2190 watert\nloaded0\ndead0\nab0\nload1\nwater3\nshoot8\nplus the following rules corresponding inertia axioms\nFt+1 \u2190 Ft , notF t+1 Ft+1 \u2190 F t , notFt+1\nfor F \u2208 {loaded, ab, dead}. Atoms of the form A represent the strong negation of A and we disregard models satisfying both A and A. Atom dead9 does not hold in the standard WFM of P4, and so there is no CG-justification for it. Note here the importance of default reasoning. On the one hand, the default flow of events is that the turkey, Fred, continues to be alive when nothing threats him. Hence, we do not need a cause to explain why Fred is alive. On the other hand, shooting a loaded gun would normally kill Fred, being this a cause of its death. But, in this example, another exceptional situation \u2013 water spilled out \u2013 has inhibited this existing threat and allowed the world to flow as if nothing had happened (that is, following its default behaviour).\nIn the CG-approach, dead9 is simply false by default and no justification is provided. However, a gun shooter could be \u201cdisappointed\u201d since another conflicting default (shooting a loaded gun normally kills) has not worked. Thus, an expected answer for the shooter\u2019s question \u201cwhy notdead9?\u201d is that water3 broke the default, disabling d9. In fact, ECJ yields the following inhibited justification for dead9:\nWP4 (dead9) = (\u223cwater3 \u2217 shoot8 \u2217 load1\u00b7l2) \u00b7d9 (7)\nmeaning that dead9 could not be derived because inhibitor water3 prevented the application of rule d9 to cause the death of Fred. Note that inertia rules are not labelled, which, as mentioned before, is syntactic sugar for rules with label 1. Since 1 is the identity of product and application, this has the effect of not being traced in the justifications. Note also that, according to Theorem 3, if we remove fact water3 (the inhibitor) from P4 leading to a new program P5, then we get:\nWP5 (dead9) = (shoot8 \u2217 load1\u00b7l2) \u00b7d9 (8)\nwhich is nothing else but the result of removing \u223cwater3 from (7). In fact, the only CG stable model of P5 makes this same assignment (8) which also corresponds to the causal graph depicted in Figure 3. In the general case, CG-justifications intuitively correspond to enabled justifications after forgetting all the enablers. Formally, however, there is one more difference in the definition of causal values: CG causal values are defined as ideals for the poset of a type of graphs formed by rule labels.\nDefinition 9 (Causal graph)\nGiven some set Lb of (rule) labels, a causal graph (c-graph) G \u2286 Lb\u00d7 Lb is a reflexively and transitively closed set of edges. By GLb, we denote the set of causal graphs. Given two c-graphs G and G\u2032, we write G \u2264 G\u2032 when G \u2287 G\u2032.\nIntuitively, causal graphs, like G2 in Figure 3, are directed graphs representing the causal structure that has produced some event. Furthermore, G \u2264 G\u2032 means that G contains enough information to yield the same effect as G\u2032, but perhaps more than needed (this explains G \u2287 G\u2032). For this reason, we sometimes read G \u2264 G\u2032 as \u201cG\u2032 is stronger than G.\u201d Causes will be \u2264- maximal (or \u2286-minimal) causal graphs. Formally, including reflexive and transitive edges allows to capture this intuitive relation simply by the subgraph relation. Note that, since causal graphs are reflexively closed, every vertex has at least one edge (the reflexive one) and, thus, we can omit the set of vertices. Besides, for the sake of clarity, we only depict the minimum set of edges necessary for defining a causal graph (transitive and reflexive reduction). For instance, graph G2 in Figure 3 is the transitive and reflexive reduction of the causal graph G\u22172.\nDefinition 10 (CG Values in Cabalar et al. 2014a) Given a set of labels Lb, a CG causal value is any ideal (or lower-set) for the poset \u3008GLb,\u2264\u3009. By ICGLb , we denote the set of CG causal values. Product \u2018\u2217\u2019, sums \u2018+\u2019 and the \u2264-order relation are defined as the set intersection, union and the subset relation, respectively. Application is given by U \u00b7U \u2032 def= { G\u2032\u2032 \u2264 G \u00b7G\u2032 \u2223 \u2223 G \u2208U and G\u2032 \u2208U \u2032 }.\nIt has been shown in (Fandinno 2015a) that CG values can be alternatively characterised as a free algebra generated by rule labels under the axioms of a complete distributive lattice plus the axioms of Figure 1.\nDefinition 11 (CG Values in Fandinno 2015a) Given a set of labels Lb, a CG term is a term without negation \u2018\u223c\u2019. CG causal values are the equivalence classes of CG terms for a completely distributive (complete) lattice with meet \u2018\u2217\u2019 and join \u2018+\u2019 plus the axioms of Figure 1. By VCGLb , we denote the set of CG causal values.\nTheorem 4 (Causal values isomorphism from Fandinno 2015a) The function term : ICGLb \u2212\u2192 V CG Lb given by\nterm(U) 7\u2192 \u2211 G\u2208U \u220f (v1,v2)\u2208G v1\u00b7v2\nis an isomorphism between algebras \u3008ICGLb ,+,\u2217, \u00b7,GLb, /0\u3009 and \u3008V CG Lb ,+,\u2217, \u00b7,1,0\u3009.\nTheorem 4 states that CG causal values can be equivalently described either as ideals of causal graphs or as elements of an algebra of terms. Furthermore, by abuse of notation, by G we also denote the ideal whose maximum element is G, corresponding to term(G) as well. For instance, for the causal graph G2 in Figure 3, it follows G2 = term(G2) = term(\u2193G2) with \u2193G2 the ideal whose maximum element is G2. Moreover, from the equivalences in Figure 1, it also follows that\nG2 = shoot8\u00b7d9 \u2217 load1\u00b7l2 \u2217 l2\u00b7d9 \u2217 \u03b1 = shoot8\u00b7d9 \u2217 load1\u00b7l2 \u2217 l2\u00b7d9\n= shoot8\u00b7d9 \u2217 load1\u00b7l2\u00b7d9\n= (shoot8 \u2217 load1\u00b7l2)\u00b7d9\nwhere \u03b1 = load1\u00b7d9 \u2217 shoot8\u00b7shoot8 \u2217 d9\u00b7d9 \u2217 load1\u00b7load1 \u2217 l2\u00b7l2 \u2217 d9\u00b7d9 is a term that, as we can see, can be ruled out and corresponds to the transitive and reflexive doted edges in G\u22172. That is, justification (8) associated to atom dead9 by the causal well-founded model of program P5 actually corresponds to causal graph G2.\nTheorem 4 also formalises the intuition that opens this section: ECJ extends CG causal terms by the introduction of the new negation operator \u2018\u223c\u2019. We formalise next the correspondence between CG and ECJ justifications.\nDefinition 12 (CG mapping) We define a mapping \u03bb c : VLb \u2212\u2192 VCGLb from ECJ values into CG values in the following recursive way:\n\u03bb c(t) def=\n\n    \n    \n\u03bb c(u)\u2297\u03bb c(w) if t = u\u2297 v with \u2297 \u2208 {+,\u2217, \u00b7} 1 if t =\u223c\u223cl with l \u2208 Lb\n0 if t = \u223cl with l \u2208 Lb\nl if t = l with l \u2208 Lb\nNote that we have assumed that t is in DNF. Otherwise, \u03bb c(t) def= \u03bb c(u) where u is an equivalent term in DNF.\nFunction \u03bb c maps every negated label \u223cl to 0 (which is the annihilator of both product \u2018\u2217\u2019 and application \u2018\u00b7\u2019 and the identity of addition \u2018+\u2019). Hence \u03bb c removes all the inhibited justifications. Furthermore \u03bb c maps every doubly negated label \u223c\u223cl to 1 (which is the identity of both product \u2018\u2217\u2019 and application \u2018\u00b7\u2019). Therefore \u03bb c removes all the enablers (i.e. doubly negated labels \u223c\u223cl) for the remaining (i.e. enabled) justifications.\nA CG interpretation is a mapping I\u0303 : At \u2212\u2192 VCGLb . The value assigned to a negative literal notA by a CG interpretation I\u0303, denoted as I\u0303(not A), is defined as: I\u0303(notA) def= 1 if I\u0303(A) = 0; I\u0303(notA) def= 0 otherwise. A CG interpretation I\u0303 is a CG model of rule like (4) iff\n( I\u0303(B1)\u2217 . . .\u2217 I\u0303(Bm)\u2217 I\u0303(notC1)\u2217 . . .\u2217 I\u0303(notCn) ) \u00b7 ri \u2264 I\u0303(H) (9)\nNotice that the value assigned to a negative literal by CG and ECJ interpretations is different. According to (Cabalar et al. 2014a), a CG interpretation I\u0303 is a CG stable model of a program P iff I\u0303 is the least model of the program PI\u0303 . In the following, we provide an ECJ based characterisation of the CG stable models that will allow us to relate both approaches. By \u03bb c(I) we will denote a CG interpretation I\u0303 s.t. I\u0303(A) = \u03bb c(I(A)) for every atom A.\nDefinition 13 (CG stable models) Given a program P, a CG interpretation I\u0303 is a CG stable model of P iff there exists a fixpoint I of the operator \u03932P, i.e. \u0393P(\u0393P(I)) = I, such that I\u0303 = \u03bb c(I) = \u03bb c(\u0393P(I)).\nTheorem 5 Let P be a program over a signature \u3008At,Lb\u3009 where Lb is a finite set of labels. Then, the CG stable models (Definition 13) are exactly the causal values and causal stable models defined in (Cabalar et al. 2014a).\nTheorem 5 shows that Definition 13 is an alternative definition of CG causal stable models. Furthermore, it settles that every causal model corresponds to some fixpoint of the operator \u03932P. Therefore, for every enabled justification there is a corresponding CG-justification common to all stable models. In order to formalise this idea we just take the definition of causal explanation from (Cabalar et al. 2014b).\nDefinition 14 (CG-justification) Given an interpretation I we say that a c-graph G is a (sufficient) CG-justification for an atom A iff term(G)\u2264 I\u0303(A).\nSince term(\u00b7) is a one-to-one correspondence, we can define its inverse graph(v) def= term\u22121(v) for all v \u2208 VCGLb .\nTheorem 6 Let P be a program over a signature \u3008At,Lb\u3009 where Lb is a finite set of labels. For any enabled justification E of some atom A w.r.t. WP, i.e. E \u2264WP(A), there is a CG-justification G def= graph(\u03bb c(E)) of A with respect to any stable model I\u0303 of P.\nAs happens between the (standard) well-founded and stable model semantics, the converse of Theorem 6 does not hold in general. That is, we may get a justification that is common to all CG-stable models but does not occur in the ECJ well-founded model. For instance, let P6 be the program consisting on the following rules:\nr1 : a \u2190 notb r2 : b \u2190 nota, notc c r3 : c \u2190 a r4 : d \u2190 b, notd\nThe (standard) WFM of program P6 is two-valued and corresponds to the unique (standard) stable model {a,c}. Furthermore, there are two causal explanations of c with respect to this unique stable model: the fact c and the pair of rules r1\u00b7r3. Note that when c is removed {a,c} is still the unique stable model, but all atoms are undefined in the WFM. Hence, r1\u00b7r3 is a justification with respect to the unique stable model of the program, but not with respect to its WFM."}, {"heading": "4 Relation to Why-not Provenance", "text": "An evident similarity between ECJ and WnP approaches is the use of an alternating fixpoint operator (Van Gelder 1989) which has been actually borrowed from WnP. However, there are some slight differences. A first one is that we have incorporated from CG the non-commutative operator \u2018\u00b7\u2019 which allows capturing not only which rules justify a given atom, but also the dependencies among these rules. The second is the use of a non-classical negation \u2018\u223c\u2019 that is crucial to distinguish between productive causes and enablers. This distinction cannot be represented with the classical negation \u2018\u00ac\u2019 in WnP since double negation can always be removed. Apart from the\ninterpretation of negation in both formalisms, there are other differences too. As an example, let us compare the justifications we obtain for dead9 in program P5. While for ECJ we obtained (8) (or graph G2 in Figure 3), the corresponding WnP justification has the form:\nl2 \u2227d9 \u2227 load1 \u2227 shoot8\n\u2227not(ab1)\u2227not(ab2)\u2227 . . .\u2227not(ab7)\u2227not(water0)\u2227 . . .\u2227not(water6) (10)\nA first observation is that the subexpression l2\u2227d9\u2227 load1\u2227shoot8 constitutes, informally speaking, a \u201cflattening\u201d of (8) (or graph G2) where the ordering among rules has been lost. We get, however, new labels of the form not(A) meaning that atom A is required not to be a program fact, something that is not present in CG-justifications. For instance, (10) points out that water can not be spilt on the gun along situations 0, . . . ,7. Although this information can be useful for debugging (the original purpose of WnP) its inclusion in a causal explanation is obviously inconvenient from a Knowledge Representation perspective, since it explicitly enumerates all the defaults that were applied (no water was spilt at any situation) something that may easily blow up the (causally) irrelevant information in a justification.\nAn analogous effect happens with the enumeration of exceptions to defaults, like inertia. Take program P7 obtained from P4 by removing all the performed actions, i.e., facts load1, water3, and shoot7. As expected, Fred will be alive, deadt , at any situation t by inertia. ECJ will assign no cause for deadt , not even any inhibited one, i.e. WP(deadt) = 1 and WP(deadt) = 0 for any t. The absence of labels in WP(deadt) = 1 is, of course, due to the fact that inertia axioms are not labelled, as they naturally represent a default and not a causal law. Still, even if inertia were labelled, say, with ink per each situation k, we would obtain a unique cause for WP(deadt) = in1 \u00b7 . . . \u00b7 int for any t > 0 while maintaining no cause for WP(deadt) = 0. However, the number of minimal WnP justifications of deadt grows quadratically, as it collects all the plans for killing Fred in t steps loading and shooting once. For instance, among others, all the following:\nd9 \u2227\u00acnot(load0)\u2227 r2 \u2227\u00acnot(shoot1)\u2227not(water0)\u2227 not(ab1)\nd9 \u2227\u00acnot(load0)\u2227 r2 \u2227\u00acnot(shoot2)\u2227not(water0)\u2227not(water1)\u2227not(ab1)\u2227not(ab2)\nd9 \u2227\u00acnot(load1)\u2227 r2 \u2227\u00acnot(shoot3)\u2227not(water0)\u2227\n\u2227 not(water1) \u2227not(water2)\u2227 not(ab1) \u2227not(ab2)\u2227not(ab3)\n. . .\nare WnP-justifications for dead9. The intuitive meaning of expressions of the form \u00acnot(A) is that dead9 can be justified by adding A as a fact to the program. For instance, the first conjunction means that it is possible to justify dead9 by adding the facts load0 and shoot1 and not adding the fact water0. We will call these justifications, which contain a subterm of the form \u00acnot(A), hypothetical in the sense that they involve some hypothetical program modification.\nDefinition 15 (Provenance values) Given a set of labels Lb, a provenance term t is recursively defined as one of the following expressions t ::= l | \u220fS | \u2211S | \u00act1 where l \u2208 Lb, t1 is in its turn a provenance term and S is a (possibly empty and possible infinite) set of provenance terms. Provenance values are the equivalence classes of provenance terms under the equivalences of the Boolean algebra. We denote by BLb the set of provenance values over Lb.\nInformally speaking, with respect to ECJ, we have removed the application \u2018\u00b7\u2019 operator, whereas product \u2018\u2217\u2019 and addition \u2018+\u2019 hold the same equivalences as in Definition 2 and negation \u2018\u223c\u2019\nhas been replaced by \u2018\u00ac\u2019 from Boolean algebra. Thus, \u2018\u00ac\u2019 is classical and satisfies all the axioms of \u2018\u223c\u2019 plus \u00ac\u00act = t. Note also that, in the examples, we have followed the convention from (Dama\u0301sio et al. 2013) of using the symbols \u2018\u2227\u2019 and \u2228 to respectively represent meet and join. However, in formal definitions, we will keep respectively using \u2018\u2217\u2019 and \u2018+\u2019 for that purpose. We define a mapping \u03bb p : VLb \u2212\u2192 BLb in the following recursive way:\n\u03bb p(t) def=\n\n    \n     \u03bb p(u)\u2297\u03bb p(w) if t = u\u2297 v with \u2297 \u2208 {+,\u2217} \u03bb p(u) \u2217 \u03bb p(w) if t = u \u00b7 v \u00ac\u03bb p(u) if t =\u223cu l if t = l with l \u2208 Lb\nDefinition 16 (Provenance) Given a program P, the why-not provenance program P(P) def= P\u222aP\u2032 where P\u2032 contains a labelled fact of the form (\u223cnot(A) : A) for each atom A \u2208 At not occurring in P as a fact. We will write P instead of P(P) when the program P is clear by the context. We denote by WhyP(L) def= \u03bb p(WP(L)) the why-not provenance of a q-literal L. We also say that a justification is hypothetical when not(A) occurs oddly negated in it, non-hypothetical otherwise.\nTheorem 7 Let P be program over a finite signature \u3008At,Lb\u3009. Then, the provenance of a literal according to Definition 16 is equivalent to the provenance defined by (Dama\u0301sio et al. 2013).\nTheorem 8 Let P be program over a finite signature \u3008At,Lb\u3009.WP is the result of removing all non-hypothetical justification from WP and each occurrence of the form \u223c\u223cnot(A) for the remaining ones, that is, WP = \u03c1(WP) where \u03c1 is the result of removing every label of the form not(A), that is \u03c1 is the composition of \u03c1not(A1) \u25e6\u03c1not(A2) \u25e6 . . .\u25e6\u03c1not(An) with At = {A1,A2, . . . ,An}.\nOn the one hand, Theorem 7 shows that the provenance of a literal can be obtained by replacing the negation \u2018\u223c\u2019 by \u2018\u00ac\u2019 and \u2018\u00b7\u2019 by \u2018\u2217\u2019 in the causal WFM of the augmented program P. On the other hand, Theorem 8 asserts that non-hypothetical justifications of a program and its augmented one coincide when subterms of the form \u223c\u223cnot(A) are removed from justifications of the latter. Consequently, we can establish the following correspondence between the ECJ justifications and the non-hypothetical WnP justifications.\nTheorem 9 Let P be program over a finite signature \u3008At,Lb\u3009. Then, the ECJ justifications of some atom A (after replacing \u201c\u00b7\u201d by \u201c\u2217\u201d and \u201c\u223c\u201d by \u201c\u00ac\u201d) correspond to the WnP justifications of A (after removing every label of the form not(B) with B \u2208 At), that is, \u03bb p(WP)(A) = \u03c1(WhyP)(A) where \u03c1 is the result of removing every label of the form not(A) as in Theorem 8.\nTheorem 9 establishes a correspondence between non-hypothetical WnP-justifications and (flattened) ECJ justifications. In our running example, (7) is the unique causal justification of dead9, while (11) (below) is its unique non-hypothetical WnP justification.\n\u00acwater3 \u2227 shoot8 \u2227 load1 \u2227 l2 \u2227d9 \u2227\n\u2227not(dead1)\u2227 . . .\u2227not(dead9)\u2227not(ab1)\u2227 . . .\u2227not(ab8) (11)\nIt is easy to see that, by applying \u03bb p to (7) we obtain\n\u03bb p ( (\u223cwater3 \u2217 shoot8 \u2217 load1\u00b7l2) \u00b7d9 ) = \u00acwater3 \u2227 shoot8 \u2227 load1 \u2227 l2 \u2227d9 (12)\nwhich is just the result of removing all labels of the form \u2018not(A)\u2019 from (11). The correspondence between the ECJ justification (8) and the WnP justification (10) for program P5 can be easily checked in a similar way.\nHypothetical justifications are not directly captured by ECJ, but can be obtained using the augmented program P as stated by Theorem 7. As a byproduct we establish a formal relation between WnP and CG.\nTheorem 10 Let P be a program over a finite signature \u3008At,Lb\u3009. Then, every non-hypothetical and enabled WnP-justification D of some atom A (after removing every label of the form not(B) with B \u2208 At) is a justification with respect to every CG stable model I\u0303 (after replacing \u201c\u00b7\u201d by \u201c\u2217\u201d and \u201c\u223c\u201d by \u201c\u00ac\u201d), that is D \u2264 W hyP(A) implies \u03c1(D) \u2264 \u03bb p(I\u0303)(A) where \u03c1 is the result of removing every label of the form not(B) as in Theorem 8.\nNote that, as happened between the ECJ and CG justifications, the converse of Theorem 10 does not hold in general due to the well-founded vs stable model difference in their definitions. As an example, the explanation for atom c at program P6 has a unique WnP justification c as opposed to the two CG justifications, c and r1\u00b7r3."}, {"heading": "5 Contributory causes", "text": "Intuitively, a contributory cause is an event that has helped to produce some effect. For instance, in program P5, it is easy to identify both actions, load1 and shoot8, as events that have helped to produce dead9 and, thus, they are both contributory causes of Fred\u2019s death. We may define the above informal concept of contributory cause as: any non-negated label l that occurs in a maximal enabled justification of some atom A. Similarly, a contributory enabler can be defined as a doubly negated label \u223c\u223cl that occurs in a maximal enabled justification of some atom A. These definitions correctly identify load1 and shoot8 as contributory causes of dead9 in program P5 and d as a contributory cause of p in program P1. Fact h is considered a contributory enabler of p. These definitions will also suffice for dealing with what Hall (2007) calls trouble cases: nonexistent threats, short-circuits, late-preemption and switching examples.\nIt is worth to mention that, in the philosophic and AI literature, the concept of contributory cause is usually discussed in the broader sense of actual causation which tries to provide an unique everyday-concept of causation. Pearl (2000) studied actual and contributory causes relying on causal networks. In this approach, it is possible to conclude cause-effect relations like \u201cA has been an actual (resp. contributory) cause of B\u201d from the behaviour of structural equations by applying, under some contingency (an alternative model in which some values are fixed) the counterfactual dependence interpretation from (Hume 1748): \u201chad A not happened, B would not have happened.\u201d Consider the following example which illustrates the difference between contributory and actual causes under this approach.\nExample 1 (Firing Squad) Suzy and Billy form a two-man firing squad that responds to the order of the captain. The shot of any of the two riflemen would kill the prisoner. Indeed, the captain gives the order, both riflemen shoot together and the prisoner dies.\nOn the one hand, the captain is an actual cause of the prisoner\u2019s death: \u201chad the captain not given the order, the riflemen would not have shot and the prisoner would not have died.\u201d On the other hand, each rifleman alone is not an actual cause: \u201chad one rifleman not shot, the prisoner would have died anyway because of the other rifleman.\u201d However, each rifleman\u2019s shot is a contributory cause because, under the contingency where the other rifleman does not shoot, the prisoner\u2019s death manifests counterfactual dependence on the first rifleman\u2019s shot. Later approaches like (Halpern and Pearl 2001; Halpern and Pearl 2005; Hall 2004; Hall 2007) have not made this distinction and consider the captain and the two riflemen as actual causes of the prisoner\u2019s death, while (Halpern 2015) considers the captain and the conjunction of both riflemen\u2019s shoots, but not each of them alone, as actual causes. We will focus here on representing the above concept of contributory cause and leave to the reader whether this agrees with the concept of cause in the every-day discourse or not.\nAs has been slightly discussed in the introduction, Hall (2004; 2007), has emphasized the difference between two types of causal relations: dependence and production. The former relies on the idea that \u201ccounterfactual dependence between wholly distinct events is sufficient for causation.\u201d The latter is characterised by being transitive, intrinsic (two processes following the same laws must be both or neither causal) and local (causes must be connected to their effects via sequences of causal intermediates).\nThese two concepts can be illustrated in Bond\u2019s example by observing the difference between pouring the drug (atom d), which is a cause under both understandings, and being a holiday (atom h), which is not considered a cause under the production viewpoint, although it is considered a cause under the dependence one.\nIn this sense, all the above approaches to actual causation, but (Hall 2004), can be classified in the dependence category. ECJ and CG do not consider h a productive cause of d because the default (or normal) behaviour of rule (1) is that \u201cd causes p.\u201d This default criterion is also shared by (Hall 2007; Halpern 2008; Hitchcock and Knobe 2009; Halpern and Hitchcock 2011). Note that, ECJ (but not CG) captures the fact that d counterfactually depends on h, as it considers it an enabler. In (Hall 2004), the author relies on intrinsicness for rejecting h as a productive cause of d: any causal structure (justification) including h and p would have to include the absence of the antidote (atom a), and it would be enough that Bond had taken the antidote by another reason to break the counterfactual dependence between h and p. By applying the above contributory cause definition to the WnP justification h\u2227d \u2227 r1 of Bond\u2019s paralysis (atom p) in program P1, we can easily identify that h is being considered a cause in WnP, thus, a causal interpretation of WnP clearly follows the dependence-based viewpoint. On the other hand, the unique CG justification d\u00b7r1 only considers d as a cause, which illustrates the fact that CG is mostly related to the concept of production. ECJ combines both understandings, and what is a cause under the dependence viewpoint is either an enabler or a cause under the production viewpoint.\nIn order to illustrate how ECJ can be used for representing the so-called non-existent threat scenarios, consider a variation of Bond\u2019s example where today is not a holiday and, thus, Bond takes the antidote. The poured drug d is a threat to Bond\u2019s safety, represented as s, but that threat is prevented by the antidote. We may represent this scenario by program P8 below:\nr1 : p \u2190 d,nota\nr2 : a \u2190 noth\nr3 : s \u2190 not p\na\nd\nThe causal WFM of program P8 assigns\nWP8 (s) = \u223c\u223cr2\u00b7r3 + \u223cd\u00b7r3 + \u223cr1\u00b7r3\nwhich recognises rule r2 (taking the antidote) as a contributory enabler of Bond\u2019s safety. The difficulty in this kind of scenarios consists in avoiding the wrong recognition of r2 as an enabler when the threat d does not exist. If we remove fact d from P8 to get the new program P9 then we obtain that WP9 (d) = 0 and, consequently,WP9 (s) = r3. Intuitively, in the absence of any threat, Bond is just safe because that is his default behaviour as stated by rule r3. Short-circuit examples consist in avoiding the wrong recognition of an event as a contributory enabler that provokes a threat that eventually prevents itself. Consider the program P10 below:\nr1 : p \u2190 a, not f\nr2 : f \u2190 c, notb\nr3 : b \u2190 c\na\nc\nHere, c is a threat to p, since it may cause f through rule r2. However, c eventually prevents r2, since it also causes b through rule r3. The causal WFM of program P10 assigns\nWP10(p) = (a \u2217\u223c\u223cr3)\u00b7r1 + (a \u2217\u223cr2)\u00b7r1 + (a \u2217\u223cc)\u00b7r1\nwhich correctly avoids considering c as a contributory enabler of p and recognises r3 as the enabler of p. Note that c is actually considered an inhibitor due to justification (a\u2217\u223cc)\u00b7r1 pointing out that, had c not happened, then a\u00b7r1 would have been an enabled justification. But then, (a \u2217\u223c\u223cr3)\u00b7r1 would stop being a justification since (a \u2217\u223c\u223cr3)\u00b7r1 + a\u00b7r1 = a\u00b7r1.\nTo illustrate late-preemention consider the following example from (Lewis 2000).\nExample 2 (Rock Throwers)\nBilly and Suzy throw rocks at a bottle. Suzy throws first and her rock arrives first. The bottle shattered. When Billy\u2019s rock gets to where the bottle used to be, there is nothing there but flying shards of glass. Who has caused the bottle to shatter?\nThe key of this example is to recognise that Suzy, and not Billy, has caused the shattering. The usual way of representing this scenario in the actual causation literature is by introducing two new fluents hit suzy and hit billy in the following way (Hall 2007; Halpern and Hitchcock 2011; Halpern 2014; Halpern 2015):\nhit suzy \u2190 throw suzy (13)\nhit billy \u2190 throw billy, \u00achit suzy (14)\nshattered \u2190 hit suzy (15)\nshattered \u2190 hit billy (16)\nIt is easy to see that such a representation mixes, in law (14), both the description of the world and the narrative fact asserting that Suzy threw first. This may easily lead to a problem of elaboration tolerance. For instance, if we have N shooters and they shoot sequentially we would have to modify the equations for all of them in an adequate way, so that the last shooter\u2019s equation would have the negation of the preceding N-1 and so on. Moreover, all these equations would have to be reformulated if we simply change the shooting order. On the other hand, we may represent\nthis scenario by a program P11 consisting of the following rules\nst+1 : shatteredt+1 \u2190 throw(A)t , not shatteredt\nshattered0\nthrow(suzy)0\nthrow(billy)1\nwith A \u2208 {suzy, billy}, plus the following rules corresponding to the inertia axioms\nshatteredt+1 \u2190 shatteredt, not shatteredt+1\nshatteredt+1 \u2190 shatteredt , not shatteredt+1\nAtom shattered2 holds in the standard WFM of P11 and its justification corresponds to\nthrow(suzy)0\u00b7s1 + (\u223cthrow(suzy)\u2217 throw(billy)1)\u00b7s2 + (\u223cs1 \u2217 throw(billy)1)\u00b7s2\nOn the one hand, the first addend points out that fact throw(suzy)0 has caused shattered2 by means of rule s1. On the other hand, the second addend indicates that throw(billy)1 has not caused it because Suzy\u2019s throw has prevented it. Finally, the third addend means that throw(billy)1 would have caused the shattering if it were not for rule s1. This example shows how our semantics is able to recognise that it was Suzy, and not Billy, who caused the bottle shattering. Furthermore, it also explains that Billy did not cause it because Suzy did it first.\nFinally, consider the following example from (Hall 2000).\nExample 3 (The Engineer) An engineer is standing by a switch in the railroad tracks. A train approaches in the distance. She flips the switch, so that the train travels down the right-hand track, instead of the left. Since the tracks reconverge up ahead, the train arrives at its destination all the same; let us further suppose that the time and manner of its arrival are exactly as they would have been, had she not flipped the switch.\nThis has been a controversial example. In (Hall 2000), the author has argued that the switch should be considered a cause of the arrival because switch has contributed to the fact that the train has travelled down the right-hand track. In a similar manner, it seems clear that the train travelling down the right-hand track has contributed to the train arrival. If causality is considered to be a transitive relation, as (Hall 2000) does, the immediate consequence of the above reasoning is that flipping the switch has contributed to the train arrival. In (Hall 2007) he argues otherwise and points out that commonsense tells that the switch is not a cause of the arrival. (Halpern and Pearl 2005) had considered switch a cause of arrival depending on whether the train travelling down the tracks is represented by one or two variables in the model. Although our understanding of causality is closer to the one expressed in (Hall 2007), it is not the aim of this work to go more in depth in this discussion, but to show instead how both understandings can be represented in ECJ. Consider the following program P12\nr1 : arrival \u2190 right\nr2 : arrival \u2190 le f t\nr3 : right \u2190 train, not switch\nr4 : le f t \u2190 train, not switch\nswitch \u2190 not switch\nswitch \u2190 not switch\ntrain\nswitch\nwhere switch represents the strong negation of switch. The two unlabelled rules capture the idea that the switch behaves classically, that is, it must be activated or not. The literal not switch in the body of rule r3 points out that the switch position is an enabler and not a cause of the track\ntaken by the train. This representation can be arguable, but the way in which the rule has been written would be expressing that if a train is coming, then a train will cross the right track by default unless switch prevents it. In that sense, the only productive cause for right (a train in the right track) is train (a train is coming) whereas the switch position just enables the causal rule to be applied. A similar default r4 is built for the left track, flipping the roles of switch and switch.\nThe causal WFM of program P12 corresponds to\nWP12 (arrival) = (train \u2217\u223c\u223cswitch)\u00b7r3\u00b7r1 + (train \u2217\u223cswitch)\u00b7r4\u00b7r2\nIt is easy to see that switch is a doubly-negated label occurring in the maximal enabled justification E1 = (train \u2217\u223c\u223cswitch)\u00b7r3\u00b7r1 and, thus, we may identify it as a contributory enabler of arrival, but not its productive cause. On the other hand, by looking at the inhibited justification E2 = (train\u2217\u223cswitch)\u00b7r4\u00b7r2, we observe that switch is also preventing rules r4 and r2 to produce the same effect, arrival, that is helping to produce in E1.\nIf we want to ignore the way in which the train arrives, one natural possibility is using the same label for all the rules for atom arrival, reflecting in this way that we do not want to trace whether r1 or r2 has been actually used. Suppose we label r2 with r1 instead, leading to the new program P13\nr1 : arrival \u2190 right\nr1 : arrival \u2190 le f t\nr3 : right \u2190 train, not switch\nr3 : le f t \u2190 train, not switch\nswitch \u2190 not switch\nswitch \u2190 not switch\ntrain\nswitch\nwhose causal WFM corresponds to\nWP12 (arrival) = (train \u2217\u223c\u223cswitch)\u00b7r3\u00b7r1 + (train \u2217\u223cswitch)\u00b7r3\u00b7r1 = train\u00b7r3\u00b7r1\nAs we can see, this justification does not consider switch at all as a cause of the arrival (nor even a contributory enabler, as before). In other words, switch is irrelevant for the train arrival, which probably coincides with the most common intuition.\nHowever, we do not find this solution fully convincing yet, because the explanation we obtain for right,WP13\n(right)= (train\u2217\u223c\u223cswitch)\u00b7r3 is showing that switch is just acting as an enabler, as we commented before. If we wanted to represent switch as a contributory cause of right, we would have more difficulties to simultaneously keep switch irrelevant in the explanation of arrival. One possibility we plan to explore in the future is allowing the declaration of a given atom or fluent, like our switch, as classical so that we include both, the the rule:\nswitch \u2190 notnotswitch\nin the logic program3 and the axiom \u223c\u223cswitch = switch in the algebra. The latter immediately implies switch+\u223cswitch = 1 (due to the weak excluded middle axiom).\n3 This implication actually corresponds to a choice rule 0{switch}1, commonly used in Answer Set Programming.\nThen, P13 could be simply expressed as\nr1 : arrival \u2190 right\nr1 : arrival \u2190 le f t\nr3 : right \u2190 train, switch\nr3 : le f t \u2190 train, not switch\ntrain\nswitch\nand the justification of right and le f t would become\nWP(right) = (train \u2217 switch)\u00b7r3 WP(le f t) = (train \u2217\u223cswitch)\u00b7r3\npointing out that switch is a cause (resp. an inhibitor) of the train travelling down the right (resp. left) track. Then, the justification of arrival would be\nWP(arrival) = (train \u2217 switch)\u00b7r3\u00b7r1 + (train \u2217\u223cswitch)\u00b7r3\u00b7r1 = train\u00b7r3\u00b7r1\nWe leave the study of this possibility for a future deeper analysis."}, {"heading": "6 Conclusions and other related work", "text": "In this paper we have introduced a unifying approach that combines causal production with enablers and inhibitors. We formally capture inhibited justifications by introducing a \u201cnon-classical\u201d negation \u2018\u223c\u2019 in the algebra of causal graphs (CG). An inhibited justification is nothing else but an expression containing some negated label. We have also distinguished productive causes from enabling conditions (counterfactual dependences that are not productive causes) by using a double negation \u2018\u223c\u223c\u2019 for the latter. The existence of enabled justifications is a sufficient and necessary condition for the truth of a literal. Furthermore, our justifications capture, under the WellFounded Semantics, both Causal Graph and Why-not Provenance justifications. As a byproduct we established a formal relation between these two approaches.\nWe have also shown how several standard examples from the literature on actual causation can be represented in our formalism and illustrated how this representation is suitable for domains which include dynamic defaults \u2013 those whose behaviour are not predetermined, but rely on some program condition \u2013 as for instance the inertia axioms. As pointed out by (Maudlin 2004), causal knowledge can be structured by a combination of inertial laws \u2013 how the world would evolve if nothing intervened \u2013 and deviations from these inertial laws.\nIn addition to the literature on actual causes cited in Section 5, our work also relates to papers on reasoning about actions and change (Lin 1995; McCain and Turner 1997; Thielscher 1997). These works have been traditionally focused on using causal inference to solve representational problems (such as, the frame, ramification and qualification problems) without paying much attention to the derivation of cause-effect relations. Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013). The most important difference of these works with respect to ECJ, and also WnP and CG, is that the last three provide fully algebraic semantics in which justifications are embedded into program models. A formal relation between (Pontelli et al. 2009) and WnP was established in (Dama\u0301sio et al. 2013) and so, using Theorems 7 and 9, it can be directly extended to ECJ, but at the cost of flattening the graph information (i.e. losing the order among rules).\nInteresting issues for future study are incorporating enabled and inhibited justifications to the\nstable model semantics and replacing the syntactic definition in favour of a logical treatment of default negation, as done for instance with the Equilibrium Logic (Pearce 1996) characterisation of stable models. Other natural steps would be the consideration of syntactic operators, for capturing more specific knowledge about causal information as done in (Fandinno 2015b) capturing sufficient causes in the CG approach, and also the representation of non-deterministic causal laws, by means of disjunctive programs or the incorporation of probabilistic knowledge.\nAcknowledgements We are thankful to Carlos Dama\u0301sio for his suggestions and comments on earlier versions of this work. We also thank the anonymous reviewers for their help to improve the paper. This research was partially supported by Spanish Project TIN2013-42149-P."}, {"heading": "Appendix A. Auxiliary figures", "text": "Associativity\nt + (u+w) = (t+u) + w t \u2217 (u\u2217w) = (t \u2217u) \u2217 w\nCommutativity\nt + u = u + t t \u2217 u = u \u2217 t\nAbsorption\nt = t + (t \u2217u) t = t \u2217 (t+u)\nDistributive\nt + (u\u2217w) = (t+u) \u2217 (t+w) t \u2217 (u+w) = (t \u2217u) + (t \u2217w)\nIdentity\nt = t + 0 t = t \u2217 1\nIdempotency\nt = t + t t = t \u2217 t\nAnnihilator\n1 = 1 + t 0 = 0 \u2217 t\nFig. A 1. Sum and product satisfy the properties of a completely distributive lattice."}, {"heading": "Appendix B. Proofs of Theorems and Implicit Results", "text": "In the following, by abuse of notation, for every function f : VLb \u2212\u2192 VLb, we will also denote by f a function over the set of interpretations such that f (I)(A) = f (I(A)) for every atom A \u2208 At. We have organized the proofs into different subsections."}, {"heading": "Appendix B.1. Proofs of Propositions 1 to 3", "text": "Proposition 1 Negation \u2018\u223c\u2019 is anti-monotonic. That is t \u2264 u holds if and only if \u223ct \u2265 \u223cu for any given two causal terms t and u.\nProof . By definition t \u2264 u iff t \u2217u= t. Furthermore, by De Morgan laws, \u223c(t \u2217u) =\u223ct+\u223cu and, thus, \u223c(t \u2217 u) = \u223ct iff \u223ct +\u223cu = \u223ct. Finally, just note that \u223ct +\u223cu = \u223ct iff \u223ct \u2265 \u223cu. Hence, t \u2264 u holds iff \u223ct \u2265\u223cu.\nProposition 2 The map t 7\u2192 \u223c\u223ct is a closure. That is, it is monotonic, idempotent and it holds that t \u2264\u223c\u223ct for any given causal term t.\nProof . To show that t 7\u2192 \u223c\u223ct is monotonic just note that t 7\u2192 \u223ct is antimonotonic (Proposition 1) and then t \u2264 u iff \u223ct \u2265 \u223cu iff \u223c\u223ct \u2264 \u223c\u223cu. Furthermore, \u223c\u223c(\u223c\u223ct) = \u223c(\u223c\u223c\u223ct) = \u223c\u223ct, that\nis, t 7\u2192 \u223c\u223ct is idempotent. Finally, note that, by definition, t \u2264\u223c\u223ct iff t \u2217\u223c\u223ct = t and\nt \u2217\u223c\u223ct = t \u2217\u223c\u223ct + 0 (identity)\n= t \u2217\u223c\u223ct + t \u2217\u223ct (pseudo-complement)\n= (t \u2217\u223c\u223ct + t)\u2217 (t \u2217\u223c\u223ct +\u223ct) (distributivity)\n= (t + t) \u2217 (\u223c\u223ct + t) \u2217 (t +\u223ct) \u2217 (\u223c\u223ct +\u223ct) (distributivity)\n= t \u2217 (\u223c\u223ct + t) \u2217 (t +\u223ct) \u2217 (\u223c\u223ct +\u223ct) (idempotency)\n= t \u2217 (t +\u223ct) \u2217 (\u223c\u223ct + t) \u2217 1 (w. excluded middle)\n= t \u2217 (t +\u223ct) \u2217 (\u223c\u223ct + t) (identity)\n= t \u2217 (\u223c\u223ct + t) (absorption)\n= t (absorption)\nHence, t 7\u2192 \u223c\u223ct is a closure.\nProposition 3 Given any term t, it can be rewritten as an equivalent term u in negation and disjuntive normal forms.\nProof . This is a trivial proof by structural induction using the DeMorgan laws and negation of application axiom. Furthermore, using the axiom \u223c\u223c\u223ct = t no more than two nested negations are required. Furthermore, it is easy to see that by applying distributivity of \u201c\u00b7\u201d and \u201c\u2217\u201d over \u201c+,\u201d every term can be equivalently represented as a term \u201c+\u201d is not in the scope of any other operation. Moreover, applying distributivity of \u201c\u00b7\u201d over \u201c\u2217\u201d every such term can be represented as one in every application subterm is elementary.\nLemma B.1 Let t be a join irreducible causal value. Then, either t \u2217\u223c\u223cu = 0 or t \u2217\u223c\u223cu is join irreducible for every causal value u \u2208 VLb.\nProof . Suppose that t \u2217 u is not join irreducible and let W \u2286 VLb a set of causal values such that w 6= t \u2217\u223c\u223cu for every w \u2208 W and t \u2217\u223c\u223cu = \u2211w\u2208W w. Since t \u2217\u223c\u223cu = \u2211w\u2208W w, it follows that w \u2264 t \u2217\u223c\u223cu for every w \u2208 W and, since w 6= t \u2217\u223c\u223cu, it follows that w < t \u2217\u223c\u223cu for every w \u2208W . Furthermore, t \u2217\u223c\u223cu+ t \u2217\u223cu = t \u2217 (\u223c\u223cu+\u223cu) = t.\nSince t is join irreducible, it follows that either t = t \u2217\u223c\u223cu or t = t \u2217\u223cu. If t = t \u2217\u223cu, then t \u2217\u223c\u223cu = (t \u2217\u223cu)\u2217\u223c\u223cu = 0. Otherwise, t = t \u2217\u223c\u223cu and t is join irreducible by hypothesis.\nLemma B.2 Let t be a term. Then \u03bb p(\u223ct) = \u00ac\u03bb p(t).\nProof . We proceed by structural induction assuming that t is in negated normal form. In case that t = a is elementary, it follows that \u03bb p(\u223ca) = \u00aca = \u00ac\u03bb p(a). In case that t = \u223ca with a elementary, \u03bb p(\u223ct) = \u03bb p(\u223c\u223ca) and \u03bb p(\u223c\u223ca) = a = \u00ac\u00aca = \u00ac\u03bb p(\u223ca) = \u03bb p(t). In case that t =\u223c\u223ca, with a elementary, \u03bb p(\u223ct) = \u03bb p(\u223c\u223c\u223ca) and\n\u03bb p(\u223c\u223c\u223ca) = \u03bb p(\u223ca) = \u00aca = \u00ac\u03bb p(\u223c\u223ca) = \u00ac\u03bb p(t)\nIn case that t = u+ v. Then\n\u03bb p(\u223ct) = \u03bb p(\u223cu \u2217\u223cv) = \u03bb p(\u223cu)\u2227\u03bb p(\u223cv)\nBy induction hypothesis \u03bb p(\u223cu) = \u00ac\u03bb p(u) and \u03bb p(\u223cv) = \u00ac\u03bb p(v) and, therefore, it holds that \u03bb p(\u223ct) = \u00ac\u03bb p(u)\u2227\u00ac\u03bb p(v). Thus, \u00ac\u03bb p(t) = \u00ac(\u03bb p(u)\u2228\u03bb p(v)) = \u00ac\u03bb p(u)\u2227\u00ac\u03bb p(v) = \u03bb p(\u223ct).\nIn case that t = u\u2297 v with \u2297 \u2208 {\u2217, \u00b7}. Then \u03bb p(\u223ct) = \u03bb p(\u223cu+\u223cv) = \u03bb p(\u223cu)\u2228 \u03bb p(\u223cv) and by induction hypothesis \u03bb p(\u223cu) = \u00ac\u03bb p(u) and \u03bb p(\u223cv) = \u00ac\u03bb p(v). Consequently it holds that \u03bb p(\u223ct) = \u00ac\u03bb p(t).\nLemma B.3 Let t be a term and \u03c6 a provenance term. If \u03c6 \u2264 \u03bb p(t), then \u03bb p(\u223ct)\u2264\u00ac\u03c6 and if \u03bb p(t)\u2264 \u03c6 , then \u00ac\u03c6 \u2264 \u03bb p(\u223ct).\nProof . If \u03c6 \u2264 \u03bb p(t), then \u03c6 = \u03bb p(t) \u2217 \u03c6 and then \u00ac\u03c6 = \u00ac\u03bb p(t) +\u00ac\u03c6 and, by Lemma B.2, it follows that \u00ac\u03c6 = \u03bb p(\u223ct) +\u00ac\u03c6 . Hence \u03bb p(\u223ct) \u2264 \u00ac\u03c6 . Furthermore if \u03bb p(t) \u2264 \u03c6 , then \u03c6 = \u03bb p(t)+ \u03c6 and then \u00ac\u03c6 = \u00ac\u03bb p(t) \u2217\u00ac\u03c6 and, by Lemma B.2, it follows that \u00ac\u03c6 = \u03bb p(\u223ct) \u2217\u00ac\u03c6 . Hence \u00ac\u03c6 \u2264 \u03bb p(\u223ct)."}, {"heading": "Appendix B.2. Proof of Theorem 1", "text": "The proof of Theorem 1 will relay on the definition of the following direct consequence operator\nT\u0303P(I\u0303)(H) def= \u2211\n{ ( I\u0303(B1)\u2217 . . .\u2217 I\u0303(Bn) ) \u00b7 ri | (ri : H \u2190 B1, . . . ,Bn) \u2208 P }\nfor any CG interpretation I\u0303 and atom H \u2208 At. Note that the definition of this direct consequence operator T\u0303P is analogous to the TP operator, but the domain and image of T\u0303P are the set of CG interpretations while the domain and image of TP are the set of ECJ interpretations.\nTheorem 11 (Theorem 2 from Cabalar et al. 2014a) Let P be a (possibly infinite) positive logic program with n causal rules. Then, (i) lfp(T\u0303P) is the least model of P, and (ii) lfp(T\u0303P) = T\u0303P \u2191\u03c9 (0) = T\u0303P \u2191n (0).\nProof of Theorem 1. Assume that every term occurring in P is NNF and let Q be the program obtained by renaming in P each occurrence of \u223cl as l\u2032 and each occurrence of \u223c\u223cl as l\u2032\u2032 with l\u2032 and l\u2032\u2032 new symbols. Note that this renaming implies that \u223cl and \u223c\u223cl are treated as completely independent symbols from l and, thus, all equalities among terms derived from program Q are also satisfied by P, although the converse does not hold. Note also that, since \u223c does not occur in Q, this is also a CG program. From Theorem 11, lfp(T\u0303Q) = T\u0303Q \u2191\u03c9 (0) is the least model of Q. By renaming back l\u2032 and l\u2032\u2032 as \u223cl and \u223c\u223cl in T\u0303Q \u2191k (0) we obtain TP \u2191k (0) for any k. Hence, lfp(TP) = TP \u2191\u03c9 (0) is the least model of P. Statement (ii) is proved in the same manner.\nAppendix B.3. Proof of Proposition 4\nLemma B.4 Let P1 and P2 be two programs and let U1 and U2 be two interpretations such that P1 \u2287 P2 and U1 \u2264U2. Let also I1 and I2 be the least models of P U1 1 and P U2 2 , respectively. Then I1 \u2265 I2.\nProof . First, for any rule ri and pair of interpretations J1 and J2 such that J1 \u2265 J2,\nJ1(body +(rU1i )) \u2265 J2(body +(rU2i ))\nFurthermore, since U1 \u2264U2, by Proposition 1, it follows\nU1(body \u2212(rU1i )) \u2265 U2(body \u2212(rU2i ))\nand, since by Definition 5 J j(body\u2212(r U1 i )) def= U j(body\u2212(r U1 i )), it follows that\nJ1(body \u2212(rU1i )) \u2265 J2(body \u2212(rU2i ))\nHence, we obtain that J1(body(r U1 i ))\u2265 J2(body(r U2 i )).\nSince P1 \u2287 P2, it follows that every rule ri \u2208 P2 is in P1 as well. Thus, TPU11 (J1)(H)\u2265 TPU22 (J2)(H) for every atom H. Furthermore, since\nT P\nU1 1\n\u21910 (0)(H) = T P\nU2 2\n\u21910 (0)(H) = 0\nit follows T P\nU1 1\n\u2191i (0)(H) \u2265 T P\nU2 2\n\u2191i (0)(H) for all 0 \u2264 i. Finally,\nT P\nUj j \u2191\u03c9 (0)(H) def= \u2211 i\u2264\u03c9 T P Uj j \u2191i (0)(H) = 0\nand hence T P\nU1 1\n\u2191\u03c9 (0)(H) \u2265 T P\nU2 2\n\u2191\u03c9 (0)(H). By Theorem 1, these are respectively the least\nmodels of PU11 and P U2 2 . That is I1 \u2265 I2.\nProposition 4 \u0393P operator is anti-monotonic and operator \u03932P is monotonic. That is, \u0393P(U1) \u2265 \u0393P(U2) and \u03932P(U1)\u2264 \u03932P(U2) for any pair of interpretations U1 and U2 such that U1 \u2264U2.\nProof . Since U1 \u2264 U2, by Lemma B.4, it follows I1 \u2265 I2 with I1 and I2 being respectively the least models of PU1 and PU2 . Then, \u0393P(U1) = I1 and \u0393P(U2) = I2 and, thus, \u0393P(U1) \u2265 \u0393P(U2). Since \u0393P is anti-monotonic it follows that \u03932P is monotonic."}, {"heading": "Appendix B.4. Proof of Theorem 2", "text": "The proof of Theorem 2 will rely on the relation between ECJ justifications and non-hypothetical WnP justifications established by Theorem 9 and it can be found below the proof of that theorem in page 36.\nAppendix B.5. Proof of Theorem 3\nDefinition 17 A term t \u2208 VLb is join irreducible iff t = \u2211u\u2208U u implies that u = t for some u \u2208U and it is join prime iff t \u2264 \u2211u\u2208U u implies that u \u2264 t for some u \u2208U .\nProposition 5 The following results hold:\n1. A term is join irreducible iff is join prime. 2. If Lb is finite, then every term t can be represented as a unique finite sum of pairwise\nincomparable join irreducible terms.\nProof . The first result directly follows from Theorem 1 in (Balbes and Dwinger 1975, page 65). Furthermore, from Theorem 2 in (Balbes and Dwinger 1975, page 66), in every distributive lattice satisfying the descending chain condition, any element can be represented as a unique finite sum of pairwise incomparable join irreducible elements and it is clear that every finite lattice satisfies the descending chain condition.\nLemma B.5 Let P be a positive program over a signature \u3008At,Lb\u3009 where Lb is a finite set of labels and Q be the result of removing all rules labelled by some label l \u2208 Lb. Let I and J be two interpretations such that J such that \u03c1\u223cl(I)\u2265 J. Then, \u03c1\u223cl(\u0393P(I))\u2264 \u0393Q(J).\nProof . By definition \u0393P(I) and \u0393Q(J) are the least models of programs PI and QJ , respectively. Furthermore, from Theorem 1, the least model of any program P is the least fixpoint of the TP operator, that is, \u0393X (Y ) = TXY \u2191\u03c9 (0) with X \u2208 {P,Q} and XY \u2208 {PI,PJ}. Then, the proof follows by induction assuming that u \u2264 TQJ \u2191\n\u03b2 (0)(H) implies \u03c1\u223cl(u) \u2264 TQI \u2191\u03b2 (0)(H) for any join irreducible u, atom H and every ordinal \u03b2 < \u03b1 .\nNote that TQJ \u2191 0 (0)(H) = 0 = \u03c1\u223cl(0) = TPI \u21910 (0)(A) for any atom H and, thus, the statement holds vacuous.\nIf \u03b1 is a successor ordinal, since u \u2264 TPI \u2191\u03b1 (0)(H), there is a rule in P of the form (4) such that\nu \u2264 (uB1 \u2217 . . .\u2217 uBm \u2217 uC1 \u2217 . . .\u2217 uCn) \u00b7 ri\nwhere uB j \u2264 TPI \u2191 \u03b1\u22121 (0)(B j) and uC j \u2264\u223cI(C j) for each positive literal B j and each negative literal not C j in the body of rule ri. Then,\n1. By induction hypothesis, it follows that \u03c1\u223cl(uB j)\u2264 TQJ \u2191\u03b1\u22121 (0)(B j), and 2. from \u03c1\u223cl(I(H))\u2265 J(H), it follows that uC j \u2264\u223cI(C j) implies \u03c1\u223cl(uC j )\u2264\u223cJ(C j).\nFurthermore, if ri 6= l, then ri \u2208 Q and, thus,\n\u03c1\u223cl(u) \u2264 (\u03c1\u223cl(uB1)\u2217 . . .\u2217\u03c1\u223cl(uBm)\u2217\u03c1\u223cl(uC1)\u2217 . . .\u2217\u03c1\u223cl(uCn)) \u00b7 ri \u2264 TQJ \u2191 \u03b1 (0)(H)\nIf otherwise ri = l, then \u03c1\u223cl(u) = 0 \u2264 TQJ \u2191\u03b1 (0)(H).\nIn case that \u03b1 is a limit ordinal, u \u2264 TPI \u2191\u03b1 (0) iff u \u2264 TPI \u2191\u03b2 (0) for some \u03b2 < \u03b1 and any join irreducible u. Hence, by induction hypothesis, it follows that \u03c1\u223cl(u) \u2264 TQJ \u2191\u03b2 (0) \u2264 TQJ \u2191\u03b1 (0) and, thus, \u03c1\u223cl(TPI \u2191\u03b1 (0))\u2264 TQJ \u2191\u03b1 (0).\nProof of Theorem 3. In the sake of simplicity, we just write \u03c1 instead of \u03c1\u223cri . Note that, by definition, for any atom H, it follows that WX(H) = LX(H) with X \u2208 {P,Q}. The proof follows by induction in the number of steps of the \u03932 operator assuming as induction hypothesis that \u03932Q \u2191\u03b2 (0)\u2264 \u03c1(\u03932P \u2191\u03b2 (0)) for every \u03b2 < \u03b1 . Note that \u03932Q \u21910 (0)(H) = 0 \u2264 \u03c1(\u03932P \u21910 (0))(H) and, thus, the statement trivially holds for \u03b1 = 0 .\nIn case that \u03b1 is a successor ordinal, by induction hypothesis, it follows that\n\u03932Q \u2191 \u03b1\u22121 (0) \u2264 \u03c1(\u03932P \u2191 \u03b1\u22121 (0))\nand, from Lemma B.5, it follows that\n\u0393Q(\u03932Q \u2191 \u03b1\u22121 (0)) \u2265 \u03c1(\u0393P(\u03932P \u2191 \u03b1\u22121 (0))) \u03932Q(\u0393 2 Q \u2191 \u03b1\u22121 (0)(H))) \u2264 \u03c1(\u03932P(\u0393 2 P \u2191 \u03b1\u22121 (0)))\nThat is, \u03932Q \u2191\u03b1 (0) \u2264 \u03c1(\u03932P \u2191\u03b1 (0). Finally, in case that \u03b1 is a limit ordinal, every join irreducible u satisfies u \u2264 \u03932Q \u2191 \u03b1 (0) = \u2211\u03b2<\u03b1 \u03932Q \u2191\u03b2 (0) iff u \u2264 \u03932Q \u2191\u03b2 (0) for some \u03b2 < \u03b1 and, thus, by induction hypothesis \u03c1(u) \u2264 \u03932P \u2191\u03b2 (0)\u2264 \u03932P \u2191\u03b1 (0). Consequently, \u03932Q \u2191\u221e (0)\u2264 \u03c1(\u03932P \u2191\u221e (0) and WQ(A)\u2264 \u03c1(WP(A) for any atom A."}, {"heading": "Appendix B.6. Proof of Theorem 5", "text": "By \u0393\u0303P(I\u0303) we denote the least model of a program PI\u0303 . Note that the relation between \u0393\u0303P and \u0393P is similar to the relation between T\u0303P and TP: the \u0393\u0303P operator is a function in the set of CG interpretations while \u0393P is a function in the set of ECJ interpretations. Note also that the evaluation of negated literals with respect to CG and ECJ interpretations and, thus, the reducts PI\u0303 and PI may be different even if I\u0303(A) = I(A) for every atom A.\nLemma B.6 Let P be a labelled logic program, I\u0303 and J be respectively an CG and a ECJ interpretation such that I\u0303 \u2265 \u03bb c(J). Then \u0393\u0303P(I\u0303)\u2264 \u03bb c(\u0393P(J)).\nProof . By definition \u0393\u0303P(I\u0303) and \u0393P(J) are respectively the least model of the programs PI\u0303 and PJ . Furthermore, from Theorem 1 the least model of any program P is the least fixpoint of the TP operator, that is, \u0393\u0303P(I\u0303) = T\u0303PI\u0303 \u2191\n\u03c9 (0) and \u0393P(J) = TPJ \u2191\u03c9 (0). In case that \u03b1 = 0, it follows that T\u0303PI\u0303 \u2191\n0 (0)(H) = 0 \u2264 \u03bb c(TPJ \u21910 (0))(H) for every atom H. We assume as induction hypothesis that T\u0303PI\u0303 \u2191 \u03b2 (0)\u2264 \u03bb c(TPJ \u2191\u03b2 (0)) for all \u03b2 < \u03b1 . In case that \u03b1 is a successor ordinal, E \u2264 T\u0303PI\u0303 \u2191 \u03b1 (0)(H) = T\u0303PI\u0303 (T\u0303PI\u0303 \u2191 \u03b1\u22121 (0))(H) if and only if there is a rule RI in PI\u0303 of the form\nri : H \u2190 B1, . . . ,Bm,\nwhich is the reduct of a rule R of the form (4) in P and that satisfies E \u2264 (EB1 \u2217 . . .\u2217EBm) \u00b7 ri with each EB j \u2264 T\u0303PI\u0303 \u2191\n\u03b1\u22121 (0)(B j) and I\u0303(C j) = 0 for all B j and C j in body(R). Hence there is a rule in PJ of the form\nri : H \u2190 B1, . . . ,Bm, J(notC1), . . . , J(notCn)\nand, by induction hypothesis, EB j \u2264 \u03bb c ( TPJ \u2191 \u03b1\u22121 (0)(B j) )\nfor all B j. Furthermore, by definition (\nTPJ \u2191 \u03b1\u22121 (0)(B1)\u2217 . . .\u2217TPJ \u2191 \u03b1\u22121 (0)(Bm)\u2217 J(notC1)\u2217 . . .\u2217 J(notCm) ) \u00b7 ri \u2264 TPJ \u2191 \u03b1 (0)(H)\nFrom the fact that I\u0303(C j) = 0 and the lemma\u2019s hypothesis I\u0303 \u2265 \u03bb c(J), it follows that 0 \u2265 \u03bb c(J(C j)) and, thus, 1 \u2264 \u03bb c(\u223cJ(C j)) = \u03bb c(J(notC j)). Hence,\n\u03bb c ( (TPJ \u2191 \u03b1\u22121 (0)(B1)\u2217 . . .\u2217TPJ \u2191 \u03b1\u22121 (0)(Bm)\u2217 J(notC1)\u2217 . . .\u2217 J(notCm)) \u00b7 ri ) =\n= \u03bb c ( (TPJ \u2191 \u03b1\u22121 (0)(B1)\u2217 . . .\u2217TPJ \u2191 \u03b1\u22121 (0)(Bm) ) \u2217\u03bb c ( J(notC1) ) \u2217 . . .\u2217\u03bb c ( J(notCm) )) \u00b7 ri = \u03bb c (\n(TPJ \u2191 \u03b1\u22121 (0)(B1)\u2217 . . .\u2217TPJ \u2191 \u03b1\u22121 (0)(Bm) ) \u2217 1 \u2217 . . .\u2217 1 ) \u00b7 ri\n= \u03bb c ( (TPJ \u2191 \u03b1\u22121 (0)(B1)\u2217 . . .\u2217TPJ \u2191 \u03b1\u22121 (0)(Bm) )) \u00b7 ri\nand, thus,\n\u03bb c ( (TPJ \u2191 \u03b1\u22121 (0)(B1)\u2217 . . .\u2217TPJ \u2191 \u03b1\u22121 (0)(Bm) )) \u00b7 ri \u2264 \u03bb c ( TPJ \u2191 \u03b1 (0)(H) )\nSince EB j \u2264 \u03bb c ( TPJ \u2191 \u03b1\u22121 (0)(B j) ) for all B j, it follows that\nE \u2264 (EB1 \u2217 . . .\u2217EBm) \u00b7 ri \u2264 \u03bb c(TPJ \u2191 \u03b1 (0))(H)\nFinally, in case that \u03b1 is a limit ordinal, it follows from Theorem 1 that \u03b1 = \u03c9 . Furthermore, since I\u0303 is a CG interpretation, it follows that PI\u0303 is a CG program and, thus, E \u2264 TPI\u0303 \u2191\n\u03c9 (0) iff E \u2264 TPI\u0303 \u2191\nn (0) for some n < \u03c9 (see Cabalar et al. 2014a). Hence, by induction hypothesis, it follows that E \u2264 TPJ \u2191 n (0)\u2264 TPJ \u2191 \u03c9 (0).\nLemma B.7 Let P be a labelled logic program over a signature \u3008At,Lb\u3009 where Lb is a finite set of labels, I\u0303 and J respectively be a CG and a ECJ interpretation such that I\u0303 \u2264 \u03bb c(J). Then \u0393\u0303P(I\u0303)\u2265 \u03bb c(\u0393P(J)).\nProof . Since Lb is finite, it follows that VLb is also finite. Furthermore, since VLb is a finite distributive lattice, every element t \u2208 VLb can be represented as a unique sum of join irreducible elements (Proposition 5).\nAssume as induction hypothesis that u \u2264 TPJ \u2191 \u03b2 (0)(H) implies \u03bb c(u)\u2264 T\u0303PI\u0303 \u2191 \u03b2 (0)(H) for every join irreducible u, atom H \u2208 At and ordinal \u03b2 < \u03b1 .\nIn case that \u03b1 is a successor ordinal. For any join irreducible justification u\u2264 TPJ \u2191\u03b1 (0)(H) there is a rule RJ in PJ of the form (6) and there are join irreducible terms uB j \u2264 TPJ \u2191\n\u03b1\u22121 (0)(B j) and uC j \u2264\u223cJ(C j) for all B j and C j such that\nu \u2264 (uB1 \u2217 . . .\u2217 uBm \u2217 uC1 \u2217 . . .\u2217 uCn) \u00b7 ri\nIf uC j contains an oddly negated label for some C j, then \u03bb c(uC j ) = 0 and it consequently follows that \u03bb c(u) = 0 \u2264 T\u0303PI\u0303 \u2191\n\u03b1 (0)(H). Thus, we assume that uC j only contains evenly negated labels for any C j. Note that, since uC j \u2264 \u223cJ(C j), then uC j cannot contain any non-negated label, that is, all occurrences of labels in uC j are strictly evenly negated and, thus, every term u \u2032 C j \u2264 J(C j) must contain some oddly negated label. Hence, I\u0303(C j)\u2264 \u03bb c(J(C j)) = 0 for any C j and there is a rule RI\u0303 in QI\u0303 of the form\nri : H \u2190 B1, . . . ,Bm\nBy induction hypothesis, uB j \u2264 TPJ \u2191 \u03b1\u22121 (0)(B j) implies \u03bb c(uB j) \u2264 T\u0303PI\u0303 \u2191 \u03b1\u22121 (0)(B j) and, consequently, \u03bb c(u)\u2264 T\u0303PI\u0303 \u2191 \u03b1 (0)(H). Since TPJ \u2191 \u03b1 (0)(H) = \u2211u\u2208UH u where every u \u2208UH is join irreducible and every u \u2208UH satisfies u\u2264 TPJ \u2191 \u03b1 (0)(H), it follows that \u03bb c(u)\u2264 T\u0303PI\u0303 \u2191 \u03b1 (0)(H) and, thus, \u2211u\u2208UH \u03bb c(u)\u2264 T\u0303PI\u0303 \u2191\n\u03b1 (0)(H). Note that, by definition, \u03bb c(\u2211u\u2208UH u) = \u2211u\u2208UH \u03bb c(u) and, thus,\n\u03bb c(TPJ \u2191 \u03b1 (0)(H)) = \u03bb c( \u2211\nu\u2208UH\nu) \u2264 T\u0303PI\u0303 \u2191 \u03b1 (0)(H)\nIn case that \u03b1 is a limit ordinal, it follows u \u2264 TPJ \u2191\u03b1 (0)(H) iff u \u2264 TPJ \u2191\u03b2 (0)(H) for some \u03b2 < \u03c9 and, by induction hypothesis, it follows that \u03bb c(u)\u2264 T\u0303PI\u0303 \u2191 \u03b2 (0)(H)\u2264 T\u0303PI\u0303 \u2191 \u03b1 (0)(H) and, thus, T\u0303PI\u0303 \u2191 \u03b1 (0)\u2265 \u03bb c(TPJ \u2191\u03b1 (0)).\nFinally, by definition \u0393\u0303P(I\u0303) and \u0393P(J) are respectively the least models of PI\u0303 and PJ and, from Theorem 11, these are precisely T\u0303PI\u0303 \u2191 \u03c9 (0) and TPJ \u2191 \u03c9 (0). Hence, T\u0303PI\u0303 \u2191\n\u03c9 (0) \u2265 \u03bb c(TPJ \u2191\u03c9 (0)) implies \u0393\u0303P(I\u0303)\u2265 \u03bb c(\u0393P(J)).\nProposition 6\nGiven a program P over a signature \u3008At,Lb\u3009 where Lb is a finite set of labels, any ECJ interpretation I satisfies \u0393\u0303P(\u03bb c(I)) = \u03bb c(\u0393P(I))).\nProof of Proposition 6. Let I\u0303 be a CG interpretation such that I(H) = I\u0303(H) for every atom H. Then, it follows that I\u0303 = \u03bb c(I). Hence, from Lemmas B.6 and B.7, it respectively follows that \u0393\u0303P(I\u0303)\u2264 \u03bb c(\u0393P(I)) and \u0393\u0303P(I\u0303)\u2265 \u03bb c(\u0393P(I)). Then, \u0393\u0303P(I\u0303) = \u0393\u0303P(\u03bb c(I)) = \u03bb c(\u0393P(I)).\nProof of Theorem 5. According to (Cabalar et al. 2014a), a CG interpretation I\u0303 is a CG stable model of P iff I\u0303 is the least model of the program PI\u0303 . Then, the CG stable models are just the fixpoints of the \u0393\u0303P operator.\nLet I\u0303 be a CG stable model according to (Cabalar et al. 2014a), let I be a ECJ interpretation such that I(H) = I\u0303(H) for every atom H \u2208 At and let J def= \u03932P \u2191\u221e (I) be the least fixpoint of \u03932P iterating from I. Since I(H) = I\u0303(H) for every atom H \u2208 At, it follows that I\u0303 = \u03bb c(I) and, by definition of CG stable model, it follows that I\u0303 = \u0393\u0303P(I\u0303). Thus, from Proposition 6, it follows that I\u0303 = \u03bb c(\u0393P(I)). Applying \u0393\u0303P to both sides of this equality, we obtain that \u0393\u0303P(I\u0303) = \u0393\u0303P(\u03bb c(\u0393P(I))). From Proposition 6 again, it follows that \u0393\u0303P(\u03bb c(\u0393P(I))) = \u03bb c(\u0393P(\u0393P(I))) = \u03bb c(\u03932P(I)) and, thus, \u0393\u0303P(I\u0303) = \u03bb c(\u03932P(I)). Furthermore, since I\u0303 = \u0393\u0303P(I\u0303), it follows that I\u0303 = \u03bb c(\u03932P(I)). Inductively applying this argument, it follows that I\u0303 = \u03bb c(\u03932P \u2191\u03b1 (I)) for any successor ordinal \u03b1 . Moreover, for a limit ordinal \u03b1 ,\n\u03bb c ( \u03932P \u2191 \u03b1 (I) )\n= \u03bb c (\n\u2211 \u03b2<\u03b1 \u03932P \u2191 \u03b2 (I)\n)\n= \u2211 \u03b2<\u03b1 \u03bb c ( \u03932P \u2191 \u03b2 (I) ) = I\u0303\nThen, since we have defined J = \u03932P \u2191\u221e (I), it follows that I\u0303 = \u03bb c(J) = \u03bb c(I) and, since we also have that I\u0303 = \u03bb c(\u0393P(I)), we obtain that \u03bb c(I) = \u03bb c(\u0393P(I)).\nThe other way around. Let I be a fixpoint of \u03932P such that \u03bb c(I) = \u03bb c(\u0393P(I)) and let I\u0303 def= \u03bb c(I). In the same way as above, it follows that \u0393\u0303P(I\u0303) = \u03bb c(\u0393P(I)) = \u03bb c(I) = I\u0303. That is, \u0393\u0303P(I\u0303) = I\u0303 and so that I\u0303 is a causal stable model of P according to (Cabalar et al. 2014a)."}, {"heading": "Appendix B.7. Proof of Theorem 6", "text": "Proof of Theorem 6 . Let I\u0303 be a causal stable model of P and I be the correspondent fixpoint of \u03932P with I\u0303 = \u03bb c(I). Since E is a enabled justification of A, i.e. E \u2264WP(A), then E \u2264 LP(A) with LP the least fixpoint of \u03932P. Since, I is a fixpoint of \u03932P, if follows that E \u2264 LP(A) \u2264 I(A) and, thus, \u03bb c(E) \u2264 \u03bb c(I(A)) = I\u0303(A). Then G def= graph(\u03bb c(E)) is, by definition, a causal explanation of the atom A."}, {"heading": "Appendix B.8. Proof of Theorem 7", "text": "The proof of Theorem 7 will need the following definition.\nDefinition 18 Given a program P, a WnP interpretation is a mapping I : At \u2212\u2192 BLb assigning a Boolean formula to each atom. The evaluation of a negated literal notA with respect to a WnP interpretation is given by I(notA) = \u00acI(A). An interpretation I is a WnP model of rule like (4) iff\nI(B1)\u2217 . . .\u2217I(Bm)\u2217I(notC1)\u2217 . . .\u2217I(notCn)\u2217 ri \u2264 I(H)\nThe operator GP(I) maps a WnP interpretation I to the least model of the program PI.\nNote that the only differences in the model evaluation between ECJ and WnP comes from the valuation of negative literals and the use of \u2018\u2217\u2019 instead of \u2018\u00b7\u2019 for keeping track of rule application. Besides, we will also use the following facts whose proof is addressed in an appendix.\nDefinition 19 Given a positive program P, we define a direct consequence operator TP such that\nTP(I)(H) def= \u2211\n{ I(B1)\u2217 . . .\u2217I(Bn)\u2217 ri | (ri : H \u2190 B1, . . . ,Bn) \u2208 P }\nfor any WnP interpretation I and atom H \u2208 At.\nDefinition 20 (From Dama\u0301sio et al. 2013) Given a program P, its why-not program is given by P def= P\u222aP\u2032 here P\u2032 contains a labelled fact of the form\n\u00acnot(A) : A\nfor each atom A \u2208 At not occurring in P as a fact. The why-not provenance information under the well-founded semantics is defined as follows: WhyP(H) = [TP(H)]; WhyP(H) = [\u00acTUP(H)]; and WhyP(undef A) = [\u00acTP(H)\u2227TUQ(H)] where TP and TUP =GP (TP) be the least and greates fixpoints of G2\nP , respectively.\nLemma B.8 Let P be a labelled logic program over a signature \u3008At,Lb\u3009 where Lb is a finite set of labels and let I and I be respectively a ECJ and a WnP interpretation such that \u03bb p(I) \u2265 I. Then, \u03bb p(\u0393P(I))\u2264GP(I).\nProof . By definition \u0393P(I) and GP(I) are the least model of the programs PI and PI, respectively. Furthermore, the least model of programs PI and PI are the least fixpoint of the TPI and T\nPJ operators, that is, \u0393P(I) = TPI \u2191\u03c9 (0) and GP(J) = TPI \u2191\u03c9 (\u22a5).\nIn case that \u03b1 = 0, it follows that \u03bb p(TPI \u21910 (0)(H)) = TPI \u21910 (\u22a5)(H) = 0 for every atom H. We assume as induction hypothesis that \u03bb p(TPI \u2191\u03b2 (0))\u2264 TPI \u2191\u03b2 (\u22a5) for all \u03b2 < \u03b1 . In case that \u03b1 is a successor ordinal. Assume that u\u2264 TPI \u2191\u03b1\u22121 (0)(H) for some join irreducible u and atom H. Then there is a rule ri \u2208 P of the form (4) and\nu \u2264 (uB1 \u2217 . . .\u2217 uB1 \u2217 uC1 \u2217 . . .\u2217 uC1) \u00b7 ri\nwhere uB j \u2264 TPI \u2191 \u03b1\u22121 (0)(B j) and uC j \u2264\u223cI(C j). Hence, by induction hypothesis, it follows that \u03bb p(uB j) \u2264 TPI \u2191\u03b1\u22121 (\u22a5)(B j) and, since uC j \u2264\u223cI(C j), it also follows that \u03bb p(uC j )\u2264 \u00acI(C j) for all C j. Consequently, we have that \u03bb p(u)\u2264 TPI \u2191\u03b1 (\u22a5)(H). In case that \u03b1 is a limit ordinal, u \u2264 TPI \u2191\u03b1 (0) iff u \u2264 TPI \u2191\u03b2 (0) for some \u03b2 < \u03b1 and all join irreducible u. Hence, by induction hypothesis, it follows that \u03bb p(u)\u2264 T\nPJ \u2191\u03b2 (0)\u2264 T PJ \u2191\u03b1 (0)\nand, thus, \u03bb p(TPI \u2191\u03b1 (0))\u2264 TPJ \u2191\u03b1 (\u22a5).\nLemma B.9 Let P be a labelled logic program over a signature \u3008At,Lb\u3009 where Lb is a finite set of labels and let I and I be respectively a ECJ and a WnP interpretation such that \u03bb p(I) \u2264 I. Therefore, \u03bb p(\u0393P(I))\u2265GP(I).\nProof . The proof is similar to the proof of Lemma B.8 and we just show the case in which \u03b1 is a successor ordinal.\nAssume that u \u2264 T PI \u2191\u03b1 (\u22a5)(H) for some join irreducible u and atom H. Hence, there is some rule ri \u2208 P of the form (4) and\nu \u2264 uB1 \u2217 . . .\u2217 uBm \u2217 uC1 \u2217 . . .\u2217 uCn \u2217 ri\nwhere uB j \u2264 TPI \u2191 \u03b1\u22121 (\u22a5)(B j) for each B j and uC j \u2264 \u00acI(C j) for each C j. By induction hypothesis, uB j \u2264 \u03bb p(TPI \u2191\u03b1\u22121 (0))(B j) for all B j. Furthermore, since \u03bb p(I) \u2264 I it follows, from Lemma B.3, that \u03bb p(\u223cI)\u2265 \u00acI and, since uC j \u2264 \u00acI(C j), it also follows that uC j \u2264 \u03bb p(\u223cI(C j)). Hence,\n\u03bb (u) \u2264 (\u03bb p(uB1)\u2217 . . .\u2217\u03bb p(uB1)\u2217\u03bb p(uC1)\u2217 . . .\u2217\u03bb p(uC1))\u2217 ri \u2264 \u03bb p(TPI \u2191 \u03b1 (0)(H))\nThus, T PI \u2191\u03b1 (\u22a5)(B j)\u2264 \u03bb p(TPI \u2191\u03b1 (0)(B j)).\nNote that the image of \u03bb p is a boolean algebra and the set of causal values corresponding to negated terms { \u223ct \u2223\n\u2223 t \u2208 VLb } are also a boolean algebra. Consequently, we define a function \u03bb q(t) =\u223c\u223ct which is analogous to \u03bb p but whose image is in VLb.\nLemma B.10 Let P be a labelled logic program and let I be an ECJ interpretation. Then, \u0393P(I) = \u0393P(\u03bb q(I)) and \u03bb p(t) = \u03bb p(\u03bb q(t)).\nProof . For \u0393P(I) = \u0393P(\u03bb q(I)). Since \u03bb q(t) = \u223c\u223ct and \u223c\u223c\u223ct = \u223ct, it follows that \u03bb q(\u223cI) = \u223c\u223c\u223cI = \u223cI and, thus, PI =P\u03bb\nq(I). Since by definition \u0393P(I) and \u0393P(\u03bb q(I)) are respectively the least models of programs PI and P\u03bb q(I) it is clear that \u0393P(I) = \u0393P(\u03bb q(I)).\nFor \u03bb p(t) = \u03bb p(\u03bb q(t)), just note \u03bb p(\u03bb q(t)) = \u03bb p(\u223c\u223ct) = \u00ac\u00ac\u03bb p(t) = \u03bb p(t).\nProposition 7 Let P be a program over a signature \u3008At,Lb\u3009 where Lb is a finite set of labels. Then, any causal interpretation I satisfies:\n(i). GP(\u03bb p(I)) = \u03bb p(\u0393P(I)), (ii). \u0393P(\u03bb q(I)) = \u0393P(I) and\n(iii). \u03bb p(t) = \u03bb p(\u03bb q(t)).\nProof . (i) From Lemmas B.8 and B.9, it respectively follows that \u03bb p(\u0393P(I)) \u2264 GP (\u03bb p(I)) and that \u03bb p(\u0393P(I)) \u2265 GP(\u03bb p(I)). Then, GP(\u03bb p(I)) = \u03bb p(\u0393P(I)). (ii) and (iii) follow from Lemma B.10.\nProof of Theorem 7. Note that WhyP(A) = TP(A) and that, by \u03bb p definition, it follows that \u03bb p(0) = 0 and thus, from Proposition 7 (i), it follows that GP(\u22a5) =GP (\u03bb p(0)) = \u03bb p(\u0393P(0)) and\nGP(\u22a5) = GP(\u03bb p(0)) = \u03bb p(\u0393P (0)) = \u03bb p(\u03bb q(\u0393P(0)))\nHence, from Proposition 7, it follows that\nG2P(\u22a5) = GP (GP(\u22a5)) = GP (\u03bb p(\u03bb q(\u0393P(0))))\n= \u03bb p(\u0393P(\u03bb q(\u0393P(0)))) = \u03bb p(\u0393P(\u0393P(0))) = \u03bb p(\u03932P(0))\nInductively applying this reasoning it follows thatG2 P \u2191\u221e (0)= \u03bb p(\u03932P \u2191 \u221e (0)) which, by KnasterTarski theorem are the least fixpoints of the operators, that is, TP = \u03bb p(LP) and, consequently, WhyP(A) = TP(A) = \u03bb p(LP(A)) = \u03bb p(WP(A)) =WhyP(A). Similarly, by definition, it follows that W hyP(notA) = \u00acTUP(A) where TUP is the greatest fixpoint of the operator G2P . Thus,\nW hyP(notA) = \u00acGP (TP) = \u03bb p(\u223c\u0393P(LP)) = \u03bb p(\u223cUP(A)) = \u03bb p(WP(notA))\nFinally, WhyP(undef A) = \u00acTP(A)\u2217TUP(A) and, thus\nWhyP(undef A) = \u03bb p(\u223cLP(A))\u2217\u03bb p(\u223c\u223cUP(A)) = \u03bb p(\u223cLP(A)\u2217\u223c\u223cUP(A)) = \u03bb p(\u223cWP(A)\u2217\u223cWP(notA)) = \u03bb p(WP(undef A))\nand, thus, WhyP(undef A) = \u03bb p(WP(undef A)) =WhyP(notA).\nAppendix B.9. Proof of Theorem 8\nLemma B.11 Let P be a labelled logic program over a signature \u3008At,Lb\u3009 where Lb is a finite set of labels and no rule is a labelled by not(A) nor \u223c\u223cnot(A). Let Q be the result of removing all rules labelled by \u223cnot(A) for some atom A. Let I and J be two interpretations such that J = \u03c1not(A)(I). Then, \u0393Q(J) = \u03c1not(A)(\u0393P(I)).\nProof . In the sake of simplicity, we just write \u03c1 instead of \u03c1not(A). By definition \u0393P(I) and \u0393Q(J) are respectively the least model of PI and QJ . The proof follows then by induction on the steps of the TP operator assuming that \u03c1(TPI \u2191\u03b2 (0)) = TQJ \u2191\u03b2 (0) for all \u03b2 < \u03b1 .\nNote that, TX \u21910 (0)(H) = 0 for any program X and atom H and, thus, the statement trivially holds.\nIn case that \u03b1 is a successor ordinal. Let u \u2208 VLb be a join irreducible causal value such that u \u2264 TPI \u2191 \u03b1 (0)(H). Then, there is a rule in P of the form (4) such that\nu \u2264 (uB1 \u2217 . . .\u2217 uBm \u2217 uC1 \u2217 . . .\u2217 uCn) \u00b7 ri\nwhere uB j \u2264 TPI \u2191 \u03b1\u22121 (0)(B j) and uC j \u2264\u223cI(C j) for each positive literal B j and each negative literal notC j in the body of rule ri.\nIf ri =\u223cnot(A), then \u03c1(u) = 0 \u2264 TQ \u2191\u03b1\u22121 (0)(H). Otherwise,\n1. By induction hypothesis, it follows that \u03c1(uB j)\u2264 TQ \u2191\u03b1\u22121 (0)(B j), and 2. from J(H) = \u03c1(I(H)) and uC j \u2264\u223cI(C j), it follows that \u03c1(uC j)\u2264\u223cJ(C j).\nFurthermore, no rule in the program P is labelled with not(A) nor \u223c\u223cnot(A) and, thus, ri 6= not(A) and ri 6=\u223c\u223cnot(A). Hence, \u03c1(u)\u2264 TQ \u2191\u03b1\u22121 (0)(H).\nThe other way around is similar. Since u \u2264 TQJ \u2191 \u03b1 (0)(H) there is a rule in Q of the form (4) such that\nu \u2264 (uB1 \u2217 . . .\u2217 uBm \u2217 uC1 \u2217 . . .\u2217 uCn) \u00b7 ri\nand uB j \u2264 TQJ \u2191 \u03b1\u22121 (0)(B j) and uC j \u2264\u223cJ(C j) for each positive literal B j and each negative literal notC j in the body of rule ri. By induction hypothesis, uB j \u2264 \u03c1(TPI \u2191\u03b1\u22121 (0)(B j)) for each B j with 1 \u2264 j \u2264 m and, since J(H) = \u03c1(I(H)) and uC j \u2264\u223cJ(C j), it follows that uC j \u2264 \u03c1(\u223cI(C j)). Then, u \u2264 \u03c1(TPI \u2191\u03b1 (0)(H)). In case that \u03b1 is a limit ordinal TX \u2191\u03b1 (0) = \u2211\u03b2<\u03b1 TX \u2191\u03b2 (0)(H) and, thus, u \u2264 TX \u2191\u03b1 (0) if and only if u\u2264 TX \u2191\u03b2 (0)(H) with \u03b2 <\u03b1 . By induction hypothesis, \u03c1(TPI \u2191\u03b2 (0)(H))= TQJ \u2191\u03b2 (0)(H) and, thus, u\u2264 \u03c1(TPI \u2191\u03b1 (0)) if and only if u\u2264 TQJ \u2191\u03b1 (0). Hence, \u03c1(TPI \u2191\u03b1 (0)) = TQJ \u2191\u03b1 (0) and, consequently, \u0393Q(J) = \u03c1(\u0393P(I)).\nProposition 8 Let P be a labelled logic program over a signature \u3008At,Lb\u3009 where Lb is a finite set of labels where no rule is a labelled by not(A) nor \u223c\u223cnot(A). Let Q be the result of removing all rules labelled by \u223cnot(A) for some atom A. Then, LQ = \u03c1not(A)(LP) and UQ = \u03c1not(A)(UP).\nProof . Note that LX = \u03932X \u2191\u221e (0) with X \u2208 {P,Q}. Furthermore, by definition, it follows that \u03932P \u21910 (0) = \u03932Q \u21910 (0) = 0. Then, assume as induction hypothesis that \u03932Q \u2191\u03b2 (0) = \u03c1(\u03932P \u2191\u03b2 (0)) for all \u03b2 < \u03b1 . When \u03b1 is a successor ordinal, by definition \u03932X \u2191\u03b1 (0) = \u03932X(\u03932X \u2191\u03b1\u22121 (0)) = \u0393X(\u0393X (\u03932X \u2191\u03b1\u22121 (0))) with X \u2208 {P, Q} and, thus, the statement follows from Lemma B.11. In case that \u03b1 is a limit ordinal \u03932X \u2191\u03b1 (0) = \u2211\u03b2<\u03b1 \u03932X \u2191\u03b2 (0). Then, for every join irreducible u it follows that u \u2264 \u03932P \u2191\u03b1 (0) if and only if u \u2264 \u03932P \u2191\u03b2 (0) for some \u03b2 < \u03b1 (by induction hypothesis) iff \u03c1(u) \u2264 \u03932P \u2191\u03b2 (0) iff \u03c1(u) \u2264 \u03932P \u2191\u03b1 (0). Hence, \u03932Q \u2191\u03b1 (0) = \u03c1(\u03932P \u2191\u03b1 (0)) and, conseuqntly, LQ = \u03c1(LP)\nFinally, note that UX = \u0393X (LX ) with X \u2208 {P, Q} and, thus, the statement follows directly from Lemma B.11.\nProof of Theorem 8. By definition, program P is the result of removing all rules labelled with \u223cnot(A) in P. In case that L is some atom H, by definition, it follows that WP(H) = LP(H) and WP(H) =LP(H) and, from Proposition 8, it follows that LP = \u03c1(LP) and, thus WP = \u03c1(WP).\nSimilarly, in case that L is a negative literal (L = notH), then WP(H) =\u223cUP(H) and WP(H) = \u223cUP(H) and, from Proposition 8, it follows that UP = \u03c1(UP). Just note tha \u03c1x(\u223cu) = \u223c\u03c1x(u) for any elementary term x and any value u. Hence, UP = \u03c1(UP) implies that \u223cUP = \u03c1(\u223cUP) and, consequently, WP = \u03c1(WP).\nIn case that L is an undefined literal (L = undef H), by definition, it follows that WP(H) = \u223cWP(H)\u2217\u223cWP(notH) =\u223cLP(H)\u2217\u223c\u223cUP(H) and WP(H) =\u223cLP(H)\u2217\u223c\u223cUP(H) and the result follows as before from Proposition 8."}, {"heading": "Appendix B.10. Proof of Theorem 9", "text": "Proof of Theorem 9. Note that \u03c1(\u03bb p(u)) = \u03bb p(\u03c1(u)) for any causal value u\u2208 VLb. By definition WhyP(L) = \u03bb p(WP)(L) and, thus\n\u03c1(WhyP(L)) = \u03c1(\u03bb p(WP)(L)) = \u03bb p(\u03c1(WP))(L)\nFrom Theorem 8, it follows that WP = \u03c1(WP) and, thus, \u03c1(WhyP(L)) = \u03bb p(WP)(L)."}, {"heading": "Appendix B.11. Proof of Theorem 2", "text": "The proof of Theorem 2 will rely on the relation between ECJ justifications and non-hypothetical WnP justifications established by Theorem 9 plus the following result from (Dama\u0301sio et al. 2013). First, we need some notation. Given a conjuntion of labels D, by Remove(D) we denote the set of negated labels in D, by Keep(D) the set of positive labels, by AddFacts(D) the set of facts A such that \u00acnot(A) occurs in D and by NoFacts(D) the set of facts A such that not(A) occurs in D.\nTheorem 12 (Theorem 3 from Dama\u0301sio et al. 2013) Given a labelled logic program P, let N be a set of facts not in program P and R be a subset of rules of P. A literal L belongs to the WFM of (P\\R)\u222a N iff there is a conjunction of literals D |=WhyP(L), such that Remove(D)\u2286 R, Keep(D)\u2229R = /0, AddFacts(D)\u2286 N, and NoFacts(D)\u2229N = /0.\nDefinition 21 Given a positive program P, we define a direct consequence operator T\u0302P such that\nT\u0302P(I\u0302)(H) def= \u2211\n{ I\u0302(B1)\u2217 . . .\u2217 I\u0302(Bn) | (ri : H \u2190 B1, . . . ,Bn) \u2208 P }\nfor any standard interpretation interpretation I\u0302 and atom H \u2208 At.\nLemma B.12 Let P be a labelled logic program over a signature \u3008At,Lb\u3009 where Lb is a finite set of labels and let I and I\u0302 be respectively a ECJ and a standard interpretation satisfying that there is some enable justification E \u2264 \u223cI(H) for every atom H such that I\u0302(H) = 0. Then, every atom H satisfies \u0393\u0302P(I\u0302)(H) = 1 iff there is some enabled justification E \u2264 \u0393P(I)(H).\nProof . By definition \u0393P(I) and \u0393\u0302P(I\u0302) are the least model of the programs PI and PI\u0302 , respectively. Furthermore, the least model of programs PI and PI\u0302 are the least fixpoint of the TP and T\u0302P operators, that is, \u0393P(I) = TPI \u2191\u03c9 (0) and \u0393\u0302P(J) = T\u0302PI\u0302 \u2191\n\u03c9 (0). In case that \u03b1 = 0, it follows that T\u0302PI\u0302 \u2191\n0 (0)(H) for every atom H and, thus, the statement holds vacuous. We assume as induction hypothesis that for every atom H and ordinal \u03b2 < \u03b1 such that T\u0302PI\u0302 \u2191\n\u03b2 (0)(H) = 1, there is some enabled justification E \u2264 TPI \u2191 \u03b2 (0)(H). In case that \u03b1 is a successor ordinal. If T\u0302PI \u2191\u03b1\u22121 (0)(H) = 1, then there is a rule ri \u2208 P of the form (4) such that T\u0302PI \u2191\n\u03b1\u22121 (0)(B j) = 1 and I(C j) = 0. On the one hand, by induction hypothesis, it follows that there is some enabled justification EB j \u2264 TPI \u2191\n\u03b1\u22121 (0)(B j) and, by hypothesis, there is some enabled justification EC j \u2264\u223cI(C j). Hence,\nE def= (EB1 \u2217 . . .EBm \u2217EC1 \u2217 . . .\u2217ECn)\u00b7ri\nis an enabled justification E \u2264 TPI \u2191 \u03b1 (0)(H). The other way around, let E be some join irreducible justification. If E \u2264 TPI \u2191 \u03b1 (0)(H), then there is a rule ri \u2208 P of the form (4) such that\nE \u2264 (EB1 \u2217 . . .EBm \u2217EC1 \u2217 . . .\u2217ECn)\u00b7ri\nwhere EB j \u2264 TPI \u2191 \u03b1 (0)(B j) and EC j \u2264 \u223cI(C j) are enabled justifications. Hence, it follows that T\u0302PI\u0302 \u2191 \u03b1 (0)(B j) = 1 and I\u0302(C j) = 0. In case that \u03b1 is a limit ordinal, T\u0302PI\u0303 \u2191 \u03b1 (0) = 1 iff T\u0302PI\u0303 \u2191\n\u03b2 (0) = 1 for some \u03b2 < \u03b1 iff there is a join irreducible enabled justification E \u2264 TPI \u2191 \u03b2 (0))\u2264 \u03bb p(TPI \u2191\u03b1 (0).\nProof of Theorem 2. Let E \u2264WP(L) be an enabled justification of L\u2208 {A, notA, undef A}. From Theorem 9, it follows that \u03bb p(E) \u2264 \u03bb p(WP(L)) = \u03c1(WhyP(L)), that is, \u03bb p(E) \u2264 \u03c1(WhyP(L)). Note that the minimum causal value t such that \u03c1(t) = \u03c1(WhyP(L)) is WhyP(L)\u2227 \u2227\nA\u2208At not(A) and, thus, D \u2264 WhyP(L) where D is defined by D = \u03bb p(E)\u2227 \u2227\nA\u2208At not(A). Furthermore, since E is an enabled justification, \u03bb p(E) is a positive conjunction and, thus, so it is D. Hence, there is a positive conjunction D such that D \u2264WhyP(L) and, from Theorem 12, it follows that L holds with respect to the standard WFM of P.\nThe other way around. If L = A is an atom, then L holds with respect to the standard WFM iff lfp(\u0393\u03022P)(L) = 1. Furthermore, \u0393\u03022P \u21910 (0)(H) = \u03932P \u21910 (0) = 0 for any atom H and, thus, there is an enabled justification E \u2264\u223c\u03932P \u21910 (0) =\u223c0 = 1 for any atom H. Then, from Lemma B.12, for any atom H , there is an enabled justification E \u2264 \u0393P(\u03932P \u21910 (0))(H) iff \u0393\u0302P(\u0393\u03022P \u21910 (0))(H) = 1. Applying this result again, it follows that E \u2264 \u03932P \u21911 (0)(H) = \u03932P(\u03932P \u21910 (0))(H) if and only if \u0393\u03022P \u21911 (0))(H) = \u0393\u03022P(\u0393\u03022P \u21910 (0))(H) = 1. Inductively applying this reasoning it follows that \u0393\u03022P \u2191\u221e (0)(H) = 1 iff there is an enabled justification E \u2264 \u03932P \u2191\u221e (0)(H) which, by Knaster-Tarski theorem are the least fixpoints respectively of the \u0393\u0302P and \u0393P operators.\nSimilarly, if L= notA, then L holds with respect to the standard WFM if and only if gfp(\u0393\u03022P)(L) = \u0393\u0302P(lfp(\u0393\u03022P))(L) = 0 iff there is not any an enabled justification E \u2264\u0393P(lfp(\u03932P))(L) = gfp(\u03932P)(L) iff there is an enabled justification E \u2264WP(L) =\u223cgfp(\u03932P)(L).\nFinally, if L = undef A, then L holds with respect to the standard WFM iff lfp(\u0393\u03022P)(L) = 0 and gfp(\u0393\u03022P)(L) = 1 if and only if there is not any enabled justification E \u2264WP(L) and there is not\nany enabled justification E \u2264 WP(notL) iff there is some enabled justification E \u2264 \u223cWP(L) and there is some enabled justification E \u2264 \u223cWP(notL) iff there is some enabled justification WP(undef A) =\u223cWP(A)\u2217\u223cWP(notA).\nAppendix B.12. Proof of Theorem 10\nLemma B.13 Let t and u be two causal terms such that no-sums occur in t ant t \u2264 u. Then, \u03c1x(t)\u2264 \u03c1x(u).\nProof . By definition t \u2264 u if and only if t = t \u2217u. Then, \u03c1x(t) = \u03c1x(t \u2217u) = \u03c1x(t)\u2217\u03c1x(u) and, thus if follows that \u03c1x(t)\u2264 \u03c1x(u).\nLemma B.14 Let t be a causal term. Then, \u03bb c(\u03bb p(t))\u2264 \u03bb p(\u03bb c(t)).\nProof . If t \u2208 Lb is a label, then \u03bb c(t) = t and \u03bb p(t) = t and, thus, \u03bb c(\u03bb p(t)) = t \u2264 t = \u03bb p(\u03bb c(t)). If t = \u223cl with l \u2208 Lb a label, then \u03bb c(t) = 0 and \u03bb p(t) = \u00acl and, thus, \u03bb c(\u03bb p(t)) = 0 \u2264 0 = \u03bb p(\u03bb c(t)). If t = \u223c\u223cl with l \u2208 Lb a label, then \u03bb c(t) = 1 and \u03bb p(t) = l and, thus, \u03bb c(\u03bb p(t)) = l \u2264 1 = \u03bb p(\u03bb c(t)).\nAssume as induction hypothesis that \u03bb c(\u03bb p(u)) \u2264 \u03bb p(\u03bb c(u)) for every subterm u of t. If t = u1\u00b7u2, then\n\u03bb c(\u03bb p(u1\u00b7u2)) = \u03bb c(\u03bb p(u1)\u2217\u03bb c(\u03bb p(u2) \u2264 \u03bb p(\u03bb c(u1)\u2217\u03bb p(\u03bb c(u2) = \u03bb p(\u03bb c(u1\u00b7u2))\nSimilarly, if t = \u2211u\u2208U u, then\n\u03bb c(\u03bb p(\u2211 u\u2208U u) = \u2211 u\u2208U \u03bb c(\u03bb p(u) \u2264 \u2211 u\u2208U \u03bb p(\u03bb c((u)) = \u03bb p(\u03bb c(\u2211 u\u2208U u))\nand if t = \u220fu\u2208U u, then\n\u03bb c(\u03bb p(\u220f u\u2208U u) = \u220f u\u2208U \u03bb c(\u03bb p(u) \u2264 \u220f u\u2208U \u03bb p(\u03bb c((u)) = \u03bb p(\u03bb c(\u220f u\u2208U u))\nProof of Theorem 10. From Theorem 9, it follows that \u03c1(WhyP(A)) = \u03bb p(WP)(A). Furthermore, since D \u2264W hyP(A), from Lemma B.13, it follows that\n\u03c1(D) \u2264 \u03c1(WhyP(A)) = \u03bb p(WP)(A) = \u03bb p(LP)(A)\nand, thus, \u03bb c(\u03c1(D))\u2264 \u03bb c(\u03bb p(LP))(A). Let I\u0303 be any CG stable model. Then, since I\u0303 = \u03bb c(I) for some fixpoint I of \u03932P, it follows that \u03bb c(LP) \u2264 I\u0303 and, thus, \u03bb p(\u03bb c(LP)) \u2264 \u03bb p(I\u0303). Furthermore, from Lemma B.14, it follows that \u03bb c(\u03bb p(LP))\u2264 \u03bb p(\u03bb c(LP)) and, thus\n\u03bb c(\u03c1(D)) \u2264 \u03bb c(\u03bb p(LP))(A) \u2264 \u03bb p(\u03bb c(LP))(A) \u2264 \u03bb p(I\u0303)(A)\nNote that, since D is non-hypothetical and enabled, it does not contain negated labels and, thus, \u03bb c(\u03c1(D)) = \u03c1(D). Consequently, \u03c1(D)\u2264 \u03bb p(I\u0303)(A)."}], "references": [{"title": "Distributive lattices", "author": ["R. BALBES", "P. DWINGER"], "venue": "Melinda Inn.", "citeRegEx": "BALBES and DWINGER,? 1975", "shortCiteRegEx": "BALBES and DWINGER", "year": 1975}, {"title": "Causal graph justifications of logic programs", "author": ["P. CABALAR", "J. FANDINNO", "M. FINK"], "venue": "Theory and Practice of Logic Programming TPLP 14, 4-5, 603\u2013618.", "citeRegEx": "CABALAR et al\\.,? 2014a", "shortCiteRegEx": "CABALAR et al\\.", "year": 2014}, {"title": "A complexity assessment for queries involving sufficient and necessary causes", "author": ["P. CABALAR", "J. FANDINNO", "M. FINK"], "venue": "Logics in Artificial Intelligence - 14th European Conference, JELIA 2014, Funchal, Madeira, Portugal, September 24-26, 2014. Proceedings, E. Ferm\u00e9 and J. Leite, Eds. Lecture Notes in Computer Science, vol. 8761. Springer, 297\u2013310.", "citeRegEx": "CABALAR et al\\.,? 2014b", "shortCiteRegEx": "CABALAR et al\\.", "year": 2014}, {"title": "Justifications for logic programming", "author": ["C.V. DAM\u00c1SIO", "A. ANALYTI", "G. ANTONIOU"], "venue": "Logic Programming and Nonmonotonic Reasoning, Twelfth International Conference, LPNMR 2013, Corunna, Spain, September 15-19, 2013. Proceedings, P. Cabalar and T. C. Son, Eds. Lecture Notes in Computer Science, vol. 8148. Springer, 530\u2013542.", "citeRegEx": "DAM\u00c1SIO et al\\.,? 2013", "shortCiteRegEx": "DAM\u00c1SIO et al\\.", "year": 2013}, {"title": "Justification semantics: A unifiying framework for the semantics of logic programs", "author": ["M. DENECKER", "D.D. SCHREYE"], "venue": "Logic Programming and Non-monotonic Reasoning, 2nd International Workshop, LPNMR 1993, Lisbon, Portugal, June 1993. The MIT Press, 365\u2013379.", "citeRegEx": "DENECKER and SCHREYE,? 1993", "shortCiteRegEx": "DENECKER and SCHREYE", "year": 1993}, {"title": "A causal semantics for logic programming", "author": ["J. FANDINNO"], "venue": "Ph.D. thesis, University of Corunna.", "citeRegEx": "FANDINNO,? 2015a", "shortCiteRegEx": "FANDINNO", "year": 2015}, {"title": "Towards deriving conclusions from cause-effect relations", "author": ["J. FANDINNO"], "venue": "ASPOCP.", "citeRegEx": "FANDINNO,? 2015b", "shortCiteRegEx": "FANDINNO", "year": 2015}, {"title": "A new perspective on stable models", "author": ["P. FERRARIS", "J. LEE", "V. LIFSCHITZ"], "venue": "IJCAI 2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence, Hyderabad, India, January 6-12, 2007, M. M. Veloso, Ed. 372\u2013379.", "citeRegEx": "FERRARIS et al\\.,? 2007", "shortCiteRegEx": "FERRARIS et al\\.", "year": 2007}, {"title": "A meta-programming technique for debugging answer-set programs", "author": ["M. GEBSER", "J. P\u00dcHRER", "T. SCHAUB", "H. TOMPITS"], "venue": "Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence, AAAI 2008, Chicago, Illinois, USA, July 13-17, 2008, D. Fox and C. P. Gomes, Eds. AAAI Press, 448\u2013453.", "citeRegEx": "GEBSER et al\\.,? 2008", "shortCiteRegEx": "GEBSER et al\\.", "year": 2008}, {"title": "The stable model semantics for logic programming", "author": ["M. GELFOND", "V. LIFSCHITZ"], "venue": "Logic Programming, Proceedings of the Fifth International Conference and Symposium, Seattle, Washington, August 15-19, R. A. Kowalski and K. A. Bowen, Eds. MIT Press, 1070\u20131080.", "citeRegEx": "GELFOND and LIFSCHITZ,? 1988", "shortCiteRegEx": "GELFOND and LIFSCHITZ", "year": 1988}, {"title": "Causation and the price of transitivity", "author": ["N. HALL"], "venue": "The Journal of Philosophy 97, 4, 198\u2013222.", "citeRegEx": "HALL,? 2000", "shortCiteRegEx": "HALL", "year": 2000}, {"title": "Two concepts of causation", "author": ["N. HALL"], "venue": "Causation and counterfactuals, J. Collins, N. Hall, and L. A. Paul, Eds. Cambridge, MA: MIT Press, 225\u2013276.", "citeRegEx": "HALL,? 2004", "shortCiteRegEx": "HALL", "year": 2004}, {"title": "Structural equations and causation", "author": ["N. HALL"], "venue": "Philosophical Studies 132, 1, 109\u2013136.", "citeRegEx": "HALL,? 2007", "shortCiteRegEx": "HALL", "year": 2007}, {"title": "Defaults and normality in causal structures", "author": ["J.Y. HALPERN"], "venue": "Principles of Knowledge Representation and Reasoning: Proceedings of the Eleventh International Conference, KR 2008, Sydney, Australia, September 16-19, 2008, G. Brewka and J. Lang, Eds. AAAI Press, 198\u2013208.", "citeRegEx": "HALPERN,? 2008", "shortCiteRegEx": "HALPERN", "year": 2008}, {"title": "Appropriate causal models and stability of causation", "author": ["J.Y. HALPERN"], "venue": "Principles of Knowledge Representation and Reasoning: Proceedings of the Fourteenth International Conference, KR 2014, Vienna, Austria, July 20-24, 2014, C. Baral, G. D. Giacomo, and T. Eiter, Eds. AAAI Press.", "citeRegEx": "HALPERN,? 2014", "shortCiteRegEx": "HALPERN", "year": 2014}, {"title": "A modification of the halpern-pearl definition of causality", "author": ["J.Y. HALPERN"], "venue": "Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence, IJCAI 2015, Buenos Aires, Argentina, July 25-31, 2015, Q. Yang and M. Wooldridge, Eds. AAAI Press, 3022\u20133033.", "citeRegEx": "HALPERN,? 2015", "shortCiteRegEx": "HALPERN", "year": 2015}, {"title": "Actual causation and the art of modeling", "author": ["J.Y. HALPERN", "C. HITCHCOCK"], "venue": "CoRR abs/1106.2652.", "citeRegEx": "HALPERN and HITCHCOCK,? 2011", "shortCiteRegEx": "HALPERN and HITCHCOCK", "year": 2011}, {"title": "Causes and explanations: A structural-model approach", "author": ["J.Y. HALPERN", "J. PEARL"], "venue": "part I: Causes. Proceedings of the Seventeenth Conference in Uncertainty in Artificial Intelligence, UAI 2001, University of Washington, Seattle, Washington, USA, August 2-5, 194\u2013202.", "citeRegEx": "HALPERN and PEARL,? 2001", "shortCiteRegEx": "HALPERN and PEARL", "year": 2001}, {"title": "Causes and explanations: A structural-model approach", "author": ["J.Y. HALPERN", "J. PEARL"], "venue": "part I: Causes. British Journal for Philosophy of Science 56, 4, 843\u2013887.", "citeRegEx": "HALPERN and PEARL,? 2005", "shortCiteRegEx": "HALPERN and PEARL", "year": 2005}, {"title": "Cause and norm", "author": ["C. HITCHCOCK", "J. KNOBE"], "venue": "Journal of Philosophy 11, 587\u2013612.", "citeRegEx": "HITCHCOCK and KNOBE,? 2009", "shortCiteRegEx": "HITCHCOCK and KNOBE", "year": 2009}, {"title": "An enquiry concerning human understanding", "author": ["D. HUME"], "venue": "Reprinted by Open Court Press, LaSalle, IL, 1958.", "citeRegEx": "HUME,? 1748", "shortCiteRegEx": "HUME", "year": 1748}, {"title": "Causation as influence", "author": ["D.K. LEWIS"], "venue": "The Journal of Philosophy 97, 4, 182\u2013197.", "citeRegEx": "LEWIS,? 2000", "shortCiteRegEx": "LEWIS", "year": 2000}, {"title": "Embracing causality in specifying the indirect effects of actions", "author": ["LIN F."], "venue": "Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, IJCAI 95, Montr\u00e9al Qu\u00e9bec, Canada, August 20-25 1995, 2 Volumes. Morgan Kaufmann, 1985\u20131993.", "citeRegEx": "F.,? 1995", "shortCiteRegEx": "F.", "year": 1995}, {"title": "Stable models and an alternative logic programming paradigm", "author": ["V.W. MAREK", "M. TRUSZCZY\u0143KI"], "venue": "The Logic Programming Paradigm, K. R. Apt, V. W. Marek, M. Truszczy\u0144ski, and D. Warren, Eds. Artificial Intelligence. Springer Berlin Heidelberg, 375\u2013398.", "citeRegEx": "MAREK and TRUSZCZY\u0143KI,? 1999", "shortCiteRegEx": "MAREK and TRUSZCZY\u0143KI", "year": 1999}, {"title": "Causation, counterfactuals, and the third factor", "author": ["T. MAUDLIN"], "venue": "Causation and Counterfactuals, J. Collins, E. J. Hall, and L. A. Paul, Eds. MIT Press.", "citeRegEx": "MAUDLIN,? 2004", "shortCiteRegEx": "MAUDLIN", "year": 2004}, {"title": "Causal theories of action and change", "author": ["N. MCCAIN", "H. TURNER"], "venue": "Proceedings of the Fourteenth National Conference on Artificial Intelligence and Ninth Innovative Applications of Artificial Intelligence Conference, AAAI 97, IAAI 97, July 27-31, 1997, Providence, Rhode Island., B. Kuipers and B. L. Webber, Eds. AAAI Press / The MIT Press, 460\u2013465.", "citeRegEx": "MCCAIN and TURNER,? 1997", "shortCiteRegEx": "MCCAIN and TURNER", "year": 1997}, {"title": "Logic programs with stable model semantics as a constraint programming paradigm", "author": ["I. NIEMEL\u00c4"], "venue": "Annals of Mathematics and Artificial Intelligence 25, 3-4, 241\u2013273.", "citeRegEx": "NIEMEL\u00c4,? 1999", "shortCiteRegEx": "NIEMEL\u00c4", "year": 1999}, {"title": "Catching the ouroboros: On debugging non-ground answer-set programs", "author": ["J. OETSCH", "J. P\u00dcHRER", "H. TOMPITS"], "venue": "CoRR abs/1007.4986.", "citeRegEx": "OETSCH et al\\.,? 2010", "shortCiteRegEx": "OETSCH et al\\.", "year": 2010}, {"title": "A new logical characterisation of stable models and answer sets", "author": ["D. PEARCE"], "venue": "Non-Monotonic Extensions of Logic Programming, NMELP 1996, Bad Honnef, Germany, September 5-6, 1996, Selected Papers, J. Dix, L. M. Pereira, and T. C. Przymusinski, Eds. Lecture Notes in Computer Science, vol. 1216. Springer, 57\u201370.", "citeRegEx": "PEARCE,? 1996", "shortCiteRegEx": "PEARCE", "year": 1996}, {"title": "Causality: models, reasoning, and inference", "author": ["J. PEARL"], "venue": "Cambridge University Press, New York, NY, USA.", "citeRegEx": "PEARL,? 2000", "shortCiteRegEx": "PEARL", "year": 2000}, {"title": "Online justification for tabled logic programs", "author": ["G. PEMMASANI", "H. GUO", "Y. DONG", "C.R. RAMAKRISHNAN", "I.V. RAMAKRISHNAN"], "venue": "Functional and Logic Programming, Seventh International Symposium, FLOPS 2004, Nara, Japan, April 7-9, 2004, Proceedings, Y. Kameyama and P. J. Stuckey, Eds. Lecture Notes in Computer Science, vol. 2998. Springer, 24\u201338.", "citeRegEx": "PEMMASANI et al\\.,? 2004", "shortCiteRegEx": "PEMMASANI et al\\.", "year": 2004}, {"title": "Justifications for logic programs under answer set semantics", "author": ["E. PONTELLI", "T.C. SON", "O. EL-KHATIB"], "venue": "Theory and Practice of Logic Programming TPLP 9, 1, 1\u201356.", "citeRegEx": "PONTELLI et al\\.,? 2009", "shortCiteRegEx": "PONTELLI et al\\.", "year": 2009}, {"title": "Aba-based answer set justification", "author": ["C. SCHULZ", "F. TONI"], "venue": "Theory and Practice of Logic Programming TPLP 13, 4-5 Online-Supplement.", "citeRegEx": "SCHULZ and TONI,? 2013", "shortCiteRegEx": "SCHULZ and TONI", "year": 2013}, {"title": "Generating explanation trees even for negations in deductive database systems", "author": ["G. SPECHT"], "venue": "Proceedings of the Fifth Workshop on Logic Programming Environments (LPE 1993), October 29-30, 1993, In conjunction with ILPS 1993, Vancouver, British Columbia, Canada, M. Ducass\u00e9, B. L. Charlier, Y. Lin, and L. \u00dc. Yal\u00e7inalp, Eds. IRISA, Campus de Beaulieu, France, 8\u201313.", "citeRegEx": "SPECHT,? 1993", "shortCiteRegEx": "SPECHT", "year": 1993}, {"title": "Ramification and causality", "author": ["M. THIELSCHER"], "venue": "Artificial Intelligence 89, 1-2, 317\u2013364.", "citeRegEx": "THIELSCHER,? 1997", "shortCiteRegEx": "THIELSCHER", "year": 1997}, {"title": "The alternating fixpoint of logic programs with negation", "author": ["A. VAN GELDER"], "venue": "Proceedings of the Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, March 29-31, 1989, Philadelphia, Pennsylvania, USA, A. Silberschatz, Ed. ACM Press, 1\u201310.", "citeRegEx": "GELDER,? 1989", "shortCiteRegEx": "GELDER", "year": 1989}, {"title": "The well-founded semantics for general logic", "author": ["A. VAN GELDER", "K.A. ROSS", "J.S. SCHLIPF"], "venue": null, "citeRegEx": "GELDER et al\\.,? \\Q1991\\E", "shortCiteRegEx": "GELDER et al\\.", "year": 1991}, {"title": "Given a labelled logic program P, let N be a set of facts not in program P and R be a subset of rules of P. A literal L belongs to the WFM of (P\\R)\u222a N iff there is a conjunction of literals D", "author": ["Dam\u00e1sio"], "venue": null, "citeRegEx": "Dam\u00e1sio,? \\Q2013\\E", "shortCiteRegEx": "Dam\u00e1sio", "year": 2013}], "referenceMentions": [{"referenceID": 9, "context": "The ASP paradigm is based on the stable models semantics (Gelfond and Lifschitz 1988) and is also closely related to the other mainly accepted interpretation for default negation, well-founded semantics (WFS) (Van Gelder et al.", "startOffset": 57, "endOffset": 85}, {"referenceID": 33, "context": "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 115, "endOffset": 262}, {"referenceID": 4, "context": "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 115, "endOffset": 262}, {"referenceID": 30, "context": "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 115, "endOffset": 262}, {"referenceID": 8, "context": "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 115, "endOffset": 262}, {"referenceID": 31, "context": "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 115, "endOffset": 262}, {"referenceID": 27, "context": "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 115, "endOffset": 262}, {"referenceID": 32, "context": "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 115, "endOffset": 262}, {"referenceID": 1, "context": "2013) and Causal Graphs (CG) (Cabalar et al. 2014a).", "startOffset": 29, "endOffset": 51}, {"referenceID": 11, "context": "a continuous chain of events that has helped to cause or produce an effect (Hall 2004; Hall 2007).", "startOffset": 75, "endOffset": 97}, {"referenceID": 12, "context": "a continuous chain of events that has helped to cause or produce an effect (Hall 2004; Hall 2007).", "startOffset": 75, "endOffset": 97}, {"referenceID": 1, "context": "\u201d As in the previous paper on CG (Cabalar et al. 2014a), our final goal is to achieve an elaboration tolerant representation of causality that allows reasoning about cause-effect relations.", "startOffset": 33, "endOffset": 55}, {"referenceID": 1, "context": "For a more detailed explanation on their induced behaviour see (Cabalar et al. 2014a).", "startOffset": 63, "endOffset": 85}, {"referenceID": 28, "context": "1 This behaviour coincides indeed with the properties for default negation obtained in Equilibrium Logic (Pearce 1996) or the equivalent General Theory of Stable Models (Ferraris et al.", "startOffset": 105, "endOffset": 118}, {"referenceID": 7, "context": "1 This behaviour coincides indeed with the properties for default negation obtained in Equilibrium Logic (Pearce 1996) or the equivalent General Theory of Stable Models (Ferraris et al. 2007).", "startOffset": 169, "endOffset": 191}, {"referenceID": 5, "context": "It has been shown in (Fandinno 2015a) that CG values can be alternatively characterised as a free algebra generated by rule labels under the axioms of a complete distributive lattice plus the axioms of Figure 1.", "startOffset": 21, "endOffset": 37}, {"referenceID": 1, "context": "According to (Cabalar et al. 2014a), a CG interpretation \u0128 is a CG stable model of a program P iff \u0128 is the least model of the program P\u0128 .", "startOffset": 13, "endOffset": 35}, {"referenceID": 1, "context": "Then, the CG stable models (Definition 13) are exactly the causal values and causal stable models defined in (Cabalar et al. 2014a).", "startOffset": 109, "endOffset": 131}, {"referenceID": 2, "context": "In order to formalise this idea we just take the definition of causal explanation from (Cabalar et al. 2014b).", "startOffset": 87, "endOffset": 109}, {"referenceID": 20, "context": "contributory) cause of B\u201d from the behaviour of structural equations by applying, under some contingency (an alternative model in which some values are fixed) the counterfactual dependence interpretation from (Hume 1748): \u201chad A not happened, B would not have happened.", "startOffset": 209, "endOffset": 220}, {"referenceID": 10, "context": "These definitions will also suffice for dealing with what Hall (2007) calls trouble cases: nonexistent threats, short-circuits, late-preemption and switching examples.", "startOffset": 58, "endOffset": 70}, {"referenceID": 10, "context": "These definitions will also suffice for dealing with what Hall (2007) calls trouble cases: nonexistent threats, short-circuits, late-preemption and switching examples. It is worth to mention that, in the philosophic and AI literature, the concept of contributory cause is usually discussed in the broader sense of actual causation which tries to provide an unique everyday-concept of causation. Pearl (2000) studied actual and contributory causes relying on causal networks.", "startOffset": 58, "endOffset": 408}, {"referenceID": 17, "context": "Later approaches like (Halpern and Pearl 2001; Halpern and Pearl 2005; Hall 2004; Hall 2007) have not made this distinction and consider the captain and the two riflemen as actual causes of the prisoner\u2019s death, while (Halpern 2015) considers the captain and the conjunction of both riflemen\u2019s shoots, but not each of them alone, as actual causes.", "startOffset": 22, "endOffset": 92}, {"referenceID": 18, "context": "Later approaches like (Halpern and Pearl 2001; Halpern and Pearl 2005; Hall 2004; Hall 2007) have not made this distinction and consider the captain and the two riflemen as actual causes of the prisoner\u2019s death, while (Halpern 2015) considers the captain and the conjunction of both riflemen\u2019s shoots, but not each of them alone, as actual causes.", "startOffset": 22, "endOffset": 92}, {"referenceID": 11, "context": "Later approaches like (Halpern and Pearl 2001; Halpern and Pearl 2005; Hall 2004; Hall 2007) have not made this distinction and consider the captain and the two riflemen as actual causes of the prisoner\u2019s death, while (Halpern 2015) considers the captain and the conjunction of both riflemen\u2019s shoots, but not each of them alone, as actual causes.", "startOffset": 22, "endOffset": 92}, {"referenceID": 12, "context": "Later approaches like (Halpern and Pearl 2001; Halpern and Pearl 2005; Hall 2004; Hall 2007) have not made this distinction and consider the captain and the two riflemen as actual causes of the prisoner\u2019s death, while (Halpern 2015) considers the captain and the conjunction of both riflemen\u2019s shoots, but not each of them alone, as actual causes.", "startOffset": 22, "endOffset": 92}, {"referenceID": 15, "context": "Later approaches like (Halpern and Pearl 2001; Halpern and Pearl 2005; Hall 2004; Hall 2007) have not made this distinction and consider the captain and the two riflemen as actual causes of the prisoner\u2019s death, while (Halpern 2015) considers the captain and the conjunction of both riflemen\u2019s shoots, but not each of them alone, as actual causes.", "startOffset": 218, "endOffset": 232}, {"referenceID": 11, "context": "In this sense, all the above approaches to actual causation, but (Hall 2004), can be classified in the dependence category.", "startOffset": 65, "endOffset": 76}, {"referenceID": 12, "context": "\u201d This default criterion is also shared by (Hall 2007; Halpern 2008; Hitchcock and Knobe 2009; Halpern and Hitchcock 2011).", "startOffset": 43, "endOffset": 122}, {"referenceID": 13, "context": "\u201d This default criterion is also shared by (Hall 2007; Halpern 2008; Hitchcock and Knobe 2009; Halpern and Hitchcock 2011).", "startOffset": 43, "endOffset": 122}, {"referenceID": 19, "context": "\u201d This default criterion is also shared by (Hall 2007; Halpern 2008; Hitchcock and Knobe 2009; Halpern and Hitchcock 2011).", "startOffset": 43, "endOffset": 122}, {"referenceID": 16, "context": "\u201d This default criterion is also shared by (Hall 2007; Halpern 2008; Hitchcock and Knobe 2009; Halpern and Hitchcock 2011).", "startOffset": 43, "endOffset": 122}, {"referenceID": 11, "context": "In (Hall 2004), the author relies on intrinsicness for rejecting h as a productive cause of d: any causal structure (justification) including h and p would have to include the absence of the antidote (atom a), and it would be enough that Bond had taken the antidote by another reason to break the counterfactual dependence between h and p.", "startOffset": 3, "endOffset": 14}, {"referenceID": 21, "context": "To illustrate late-preemention consider the following example from (Lewis 2000).", "startOffset": 67, "endOffset": 79}, {"referenceID": 12, "context": "The usual way of representing this scenario in the actual causation literature is by introducing two new fluents hit suzy and hit billy in the following way (Hall 2007; Halpern and Hitchcock 2011; Halpern 2014; Halpern 2015):", "startOffset": 157, "endOffset": 224}, {"referenceID": 16, "context": "The usual way of representing this scenario in the actual causation literature is by introducing two new fluents hit suzy and hit billy in the following way (Hall 2007; Halpern and Hitchcock 2011; Halpern 2014; Halpern 2015):", "startOffset": 157, "endOffset": 224}, {"referenceID": 14, "context": "The usual way of representing this scenario in the actual causation literature is by introducing two new fluents hit suzy and hit billy in the following way (Hall 2007; Halpern and Hitchcock 2011; Halpern 2014; Halpern 2015):", "startOffset": 157, "endOffset": 224}, {"referenceID": 15, "context": "The usual way of representing this scenario in the actual causation literature is by introducing two new fluents hit suzy and hit billy in the following way (Hall 2007; Halpern and Hitchcock 2011; Halpern 2014; Halpern 2015):", "startOffset": 157, "endOffset": 224}, {"referenceID": 10, "context": "Finally, consider the following example from (Hall 2000).", "startOffset": 45, "endOffset": 56}, {"referenceID": 10, "context": "In (Hall 2000), the author has argued that the switch should be considered a cause of the arrival because switch has contributed to the fact that the train has travelled down the right-hand track.", "startOffset": 3, "endOffset": 14}, {"referenceID": 10, "context": "If causality is considered to be a transitive relation, as (Hall 2000) does, the immediate consequence of the above reasoning is that flipping the switch has contributed to the train arrival.", "startOffset": 59, "endOffset": 70}, {"referenceID": 12, "context": "In (Hall 2007) he argues otherwise and points out that commonsense tells that the switch is not a cause of the arrival.", "startOffset": 3, "endOffset": 14}, {"referenceID": 18, "context": "(Halpern and Pearl 2005) had considered switch a cause of arrival depending on whether the train travelling down the tracks is represented by one or two variables in the model.", "startOffset": 0, "endOffset": 24}, {"referenceID": 12, "context": "Although our understanding of causality is closer to the one expressed in (Hall 2007), it is not the aim of this work to go more in depth in this discussion, but to show instead how both understandings can be represented in ECJ.", "startOffset": 74, "endOffset": 85}, {"referenceID": 24, "context": "As pointed out by (Maudlin 2004), causal knowledge can be structured by a combination of inertial laws \u2013 how the world would evolve if nothing intervened \u2013 and deviations from these inertial laws.", "startOffset": 18, "endOffset": 32}, {"referenceID": 25, "context": "In addition to the literature on actual causes cited in Section 5, our work also relates to papers on reasoning about actions and change (Lin 1995; McCain and Turner 1997; Thielscher 1997).", "startOffset": 137, "endOffset": 188}, {"referenceID": 34, "context": "In addition to the literature on actual causes cited in Section 5, our work also relates to papers on reasoning about actions and change (Lin 1995; McCain and Turner 1997; Thielscher 1997).", "startOffset": 137, "endOffset": 188}, {"referenceID": 33, "context": "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 98, "endOffset": 245}, {"referenceID": 4, "context": "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 98, "endOffset": 245}, {"referenceID": 30, "context": "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 98, "endOffset": 245}, {"referenceID": 8, "context": "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 98, "endOffset": 245}, {"referenceID": 31, "context": "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 98, "endOffset": 245}, {"referenceID": 27, "context": "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 98, "endOffset": 245}, {"referenceID": 32, "context": "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).", "startOffset": 98, "endOffset": 245}, {"referenceID": 31, "context": "A formal relation between (Pontelli et al. 2009) and WnP was established in (Dam\u00e1sio et al.", "startOffset": 26, "endOffset": 48}, {"referenceID": 28, "context": "stable model semantics and replacing the syntactic definition in favour of a logical treatment of default negation, as done for instance with the Equilibrium Logic (Pearce 1996) characterisation of stable models.", "startOffset": 164, "endOffset": 177}, {"referenceID": 6, "context": "Other natural steps would be the consideration of syntactic operators, for capturing more specific knowledge about causal information as done in (Fandinno 2015b) capturing sufficient causes in the CG approach, and also the representation of non-deterministic causal laws, by means of disjunctive programs or the incorporation of probabilistic knowledge.", "startOffset": 145, "endOffset": 161}], "year": 2016, "abstractText": "To appear in Theory and Practice of Logic Programming (TPLP). In this paper we propose an extension of logic programming (LP) where each default literal derived from the well-founded model is associated to a justification represented as an algebraic expression. This expression contains both causal explanations (in the form of proof graphs built with rule labels) and terms under the scope of negation that stand for conditions that enable or disable the application of causal rules. Using some examples, we discuss how these new conditions, we respectively call enablers and inhibitors, are intimately related to default negation and have an essentially different nature from regular cause-effect relations. The most important result is a formal comparison to the recent algebraic approaches for justifications in LP: Why-not Provenance (WnP) and Causal Graphs (CG). We show that the current approach extends both WnP and CG justifications under the Well-Founded Semantics and, as a byproduct, we also establish a formal relation between these two approaches.", "creator": "LaTeX with hyperref package"}}}