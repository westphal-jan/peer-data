{"id": "1602.07236", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Feb-2016", "title": "Petrarch 2 : Petrarcher", "abstract": "PETRARCH 2 is the fourth generation in a series of event data encoders that emerged from Phillip Schrodt's research. Each iteration has brought new functionality and ease of use, and this is no exception. Petrarch 2 takes much of the power of the original dictionaries of the Petrarch and redirects it to a faster and smarter core logic. Previous iterations treated sentences largely as a list of words, with some syntactical information contained here and there. Petrarch 2 now looks at the sentence entirely at the syntactic level. It receives the syntactic extract of a sentence from the Stanford CoreNLP software and stores this data as a tree of linked nodes, with each node being a phrase object. Prepositional, noun, and verb phrases each have their own version of this phrase class that deals with the logic of this type of phrases in particular. As it is an event coder, the question of who is based on the logic behind this theory and what is happening is.", "histories": [["v1", "Tue, 23 Feb 2016 17:05:06 GMT  (10kb,D)", "http://arxiv.org/abs/1602.07236v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["clayton norris"], "accepted": false, "id": "1602.07236"}, "pdf": {"name": "1602.07236.pdf", "metadata": {"source": "CRF", "title": "PETRARCH 2 : PETRARCHer", "authors": ["Clayton Norris", "Phillip Schrodt"], "emails": [], "sections": [{"heading": null, "text": "PETRARCH 2 : PETRARCHer\nClayton Norris\nPETRARCH 2 is the fourth generation of a series of Event-Data coders stemming from research by Phillip Schrodt1. Each iteration has brought new functionality and usability 2, and this is no exception. Petrarch 2 takes much of the power of the original Petrarch\u2019s dictionaries and redirects it into a faster and smarter core logic. Earlier iterations handled sentences largely as a list of words, incorporating some syntactic information here and there. Petrarch 2 (henceforth referred to as Petrarch) now views the sentence entirely on the syntactic level. It receives the syntactic parse of a sentence from the Stanford CoreNLP software, and stores this data as a tree structure of linked nodes, where each node is a Phrase object. Prepositional, noun, and verb phrases each have their own version of this Phrase class, which deals with the logic particular to those kinds of phrases. Since this is an event coder, the core of the logic focuses around the verbs: who is acting, who is being acted on, and what is happening. The theory behind this new structure and its logic is founded in Generative Grammar, Information Theory, and Lambda-Calculus Semantics."}, {"heading": "1 Tree structure", "text": "In an attempt to take advantage of all the syntactic information provided to us by the Stanford Parse, Petrarch implements the sentence coding in such a way that the syntax tree is apparent in the data structure and the logic. It\u2019s a simple tree structure, with every phrase or word being its own node, with pointers to the parent node and the set of children nodes3. The syntactic phrases are stored as nested objects of the \u201cPhrase\u201d class, which has three subclasses \u201cNounPhrase,\u201d \u201cVerbPhrase,\u201d and \u201cPrepPhrase.\u201d If a phrase doesn\u2019t fall under one of these categories, it is just kept as a \u201cPhrase,\u201d though if eventually enough reason can be shown to add another type (adjective phrases, for example), it an be done so easily. Each of these phrase types has several methods unique to it and its own version of a get meaning() method, which is what determines the coding of a node from the meaning of its children.\n1Schrodt, 2001 2Schrodt, 2012 3The relationship between nodes is frequently described using terms of familial relation (most frequently, \u201cparent\u201d and \u201cchild\u201d), or direction (\u201cabove\u201d meaning \u201ccloser to the root,\u201d and \u201cbelow\u201d meaning \u201ccloser to word-level.\u201d)\nar X\niv :1\n60 2.\n07 23\n6v 1\n[ cs\n.C L\n] 2\n3 Fe\nb 20\n16\nThe simplicity of this recursive approach in comparison with the expensive listbased pattern matching from previous versions of Petrarch yields a significant speed improvement, and the theoretically-grounded tree-based semantic searching takes advantage of the relationships between nouns and verbs encoded in the syntax tree."}, {"heading": "1.1 Syntax trees", "text": "Let\u2019s start with a short linguistics lesson. Every sentence in English (and most languages) is made up of several \u201cconstituents\u201d. A constituent can be a single word or a whole phrase (which is a constituent of constituents), but the defining characteristic is that each constituent serves a specific syntactic (i.e. grammatical) role. Constituents of a sentence are associated hierarchically (hence the phrasal constituent-of-constituents), and so the most convenient way of visualizing or storing syntactic structure is in a syntax tree. There is an example of a syntax tree and how it is used in the parse at the end of this document.\nThe CoreNLP software on which Petrarch relies for syntactic parsing uses the Penn Treebank II 4 syntax notation, which can differ slightly from canonical generative grammar labeling, but for our purposes they are equally useful. Constituents have specific type, depending on their \u201chead\u201d and distribution. The cases we care most about in this program are Noun, Verb, and Prepositional phrases. Heads, in this case, are effectively the single word that a phrase can be reduced to, both semantically and syntactically. They can be predictably located by navigating the syntax tree, so Petrarch relies on the idea of phrasal headedness for much of its speed. A head of a phrase can be formalized as the lowest word-level constituent to which there is an unbroken path of phrase-level similarly-typed constituents from the phrase\u2019s root node. Basically, to find the head of an NP (Noun Phrase), you follow the path of NP\u2019s down the tree until you find a Noun. If there\u2019s ever a choice of which path to take, in English you will take the rightmost5."}, {"heading": "2 Flow", "text": "The core logic of the semantic parsing is based on the notion that each node in the tree has a meaning, and the meaning of a node is a combination of the meanings of its children. That means that in moving up the tree and going from word-level to sentence-level, words and meanings get combined until you have one noun phrase meaning and one verb phrase meaning. The meaning of the verb phrase is what captures most of the meaning of the sentence, and accounts for all the relevant nouns and verbs below it.\n4https://www.cis.upenn.edu/~treebank/ 5Many theories of syntax dictate that any node can have at most two children, which would never yield a situation where you have several choices, but CoreNLP does not follow this binary branching restriction\nBecause of the recursive nature of the meaning determination, one call to get meaning() from the upper most verb phrase will cause a domino effect that finds the meaning of the rest of the tree. The flow of each specific phrase type is determined by its get meaning() method. While the logical flow can\u2019t be strictly linearized due to the domino effect of recursion, it can be abstracted to follow these steps:\n1. Read Stanford CoreNLP parse into memory using Phrase classes.\n2. Identify coded actors in noun phrases.\n3. Identify the usage of the verbs in the verb phrases based on the dictionary entries.\n4. Identify how verbs interact with their constituent verb, prepositional, and noun phrases.\n5. Identify how verbs interact with the noun phrases in their subject position.\n6. Resolve verb+verb interactions.\n7. Return the coding of the uppermost VerbPhrase using CAMEO67 verb and actor codes, if it satisfies the conditions specified by the user"}, {"heading": "3 Classes and class-specific flow", "text": ""}, {"heading": "3.1 Noun Phrases", "text": "The NounPhrase class only has one unique method, check date(), which is what decides which actor code to choose when the code for a specific person or country changes over time. This is taken almost directly from the older version of Petrarch.\nThe get meaning() method in the noun phrase both matches the patterns for the actors and agents of word-level children, and combines the meanings of constituent PP, NP, and VP children. The priority is given as WordPatterns > NP > PP > V P , and only when actors and agents are not coded will the node finding the meaning look at a lower-priority phrase. This means that the noun phrase \u201cAmerican troops in Iraq\u201d would only code as USAMIL but \u201cTroops in Iraq\u201d would code as IRQMIL."}, {"heading": "3.1.1 Pronouns", "text": "When Petrarch encounters a pronoun, it looks up the tree for an antecedent within the same sentence. If the pronoun is relfexive (ends with -self or -selves), Petrarch looks until it finds a noun, or until it finds a verb phrase with a defined subject,\n6http://eventdata.parusanalytics.com/cameo.dir/CAMEO.09b6.pdf 7Schrodt et al. 2008\nand assigns that as the meaning. However, if the pronoun is not reflexive, Petrarch moves up until it finds an S-level phrase, then begins its search. This is based on the binding rules that pronouns follow in Generative Grammar. Because of the distinction between the two types of pronouns, Petrarch can correctly identify that \u201citself\u201d in A said B hurt itself refers to B, while \u201cit\u201d in A said B hurt it refers to A.\nSince Petrarch currently has no concept of number or gender, it sometimes makes mistakes in instances where the pronoun reference depends on the characteristics of the nouns in the sentence. Such is the case differentiating Obama told Hillary that he should run for President again from Obama told Hillary that she should run for President again. Both of these would be interpreted by Petrarch as Obama told Hillary that Hillary should run for President again"}, {"heading": "3.2 Prepositional Phrases", "text": "The get meaning() method of PrepPhrase objects returns the meaning of their nonpreposition constituent. This makes it easier for the actor searching to pass through prepositional phrases. The preposition is stored as an attribute of the object and is used in some cases to determine whether or not a certain PrepPhrase should be considered."}, {"heading": "3.3 Verb Phrases", "text": "Verb phrases drive most of the complex logic of the program. They play the largest role in all three parts of finding \u201cwho did what to whom\u201d, assigning verb codes and finding the appropriate noun phrases to fit. The get meaning() method of verb phrases relies on three other verb-specific methods:\n3.3.1 get upper()\nThis method is fairly simple. If the VP has an NP specifier 8 with a coded actor, it returns this. Otherwise, this returns nothing.\n3.3.2 get lower()\nThis is slightly more complicated. In most cases, the verb get lower() method behaves very similarly to the NounPhrase get meaning() method. It looks for some coded actor in noun or prepositional phrases, and returns this.\nHowever, if a VP has a VP as a child, it returns the meaning of only that phrase, as well as looking for some sort of negation word. The only VP\u2019s with VP children\n8In Syntax, two phrase-level siblings are called specifiers. These occur most frequently between VP\u2019s,NP\u2019s,and PP\u2019s. The NP specifier of a VP is the phrase that contains the grammatical subject of the verb.\nare modals (could, might, will, etc.) or helping verbs (has, is, do, etc.)9. These won\u2019t have other NP, or PP children that are relevant to this verb, but can have \u201cnot\u201d as a child, so this is where negation is flagged.\n3.3.3 get code()\nThis is where the program looks to see if the verb follows a pattern specified in the dictionary. The patterns consist of four parts:\n1. Pre-verb noun phrases\n2. Pre-verb prepositional phrases 10\n3. Post-verb noun phrases\n4. Post-verb prepositional phrases\nThe process from this point differs for active and passive verbs, but only in where each search takes place. Active verbs look for (1) at the closest S-level (Sentence node) above the verb, i.e. the nearest point where there will be an NP specifier. It first finds this level via the get S() method, and looks to see if the head of the NP specifier is part of a pattern. If a head is found and there is more to the pattern\u2019s noun phrase, then the program begins to look for the rest of the pattern phrase in the noun phrase from which the head came. The verbs find (2) in the same place, but in PP\u2019s instead of NP\u2019s. Since we almost never see patterns with this format in English, this hasn\u2019t been fine tuned. Then the search begins for (3). This involves checking if any of the heads of child NP\u2019s are part of a pattern. Then Petrarch follows the same process of looking for longer noun patterns within the phrases of the respective heads. Part (4) looks at child PP\u2019s for matches, then matches nouns within the phrases if necessary by the same methods it matched child NP\u2019s.\nFor passive verbs, the process for prepositions is exactly the same. However, it looks for (1) inside the NP\u2019s of child PP\u2019s with the preposition \u201cby,\u201d \u201cfrom,\u201d or \u201cin,\u201d. If no such phrase is found, the verb is left without a subject. This is simply a specific case to deal with how English deals with the party that is performing the action in a passive sentence. (3) is found in the same place that (1) is found in the active sentences.\nAs an illustration, consider the active and passive forms of a simple sentence that would match the pattern\nprotesters \u2217monument [145] #DESTROY 9If it intuitively seems like a verb would have another verb phrase as a child, but it does not fall into one of these categories, it most likely takes a sentence as a child, rather than a verb phrase. 10I can\u2019t think of a scenario where this would actually be necessary, but the option is there for consistency\u2019s sake.\n1. The protesters destroyed the monument.\nS\n.\n.\nVP\nNP\nNN\nMONUMENT\nDT\nTHE\nVBD\nDESTROYED\nNP\nNN\nPROTESTERS\n2. The monument was destroyed by protesters.\nS\n.\n.\nVP\nVP\nPP\nNP\nNN\nPROTESTERS\nIN\nBY\nVBN\nDESTROYED\nVBD\nWAS\nNP\nNN\nMONUMENT\nDT\nTHE\nKey: (1) Location (1) Match (3) Location (3) Match Note that this is only for matching patterns entered in the dictionary, not Source and Target matching. That happens within the get meaning() method, based on the outcomes of get upper() and get lower().\n3.3.4 get meaning()\nThe get meaning() method of the Verb class first combines the values of the previous three methods in one of a number of ways, depending on what those methods find. In most cases, this method returns a list of events that are described by the subtree of which the verb phrase is the root. Sometimes, however, if there isn\u2019t enough verb information available, it will simply return the list of actors described by the subtree. In deciding what to do, the verb has several things to consider:\n\u2022 Do I have a source actor? (from get upper())\n\u2022 Do I have a code? (from get code())\n\u2022 Do I have a S-level or VP child? (from get lower())\n\u2022 If so, does that child code an event?\n\u2022 If so, how does the event that I code relate the event that it codes?\n3.3.5 match transform()\nThis method accounts for the fact that ontologies don\u2019t always line up exactly with how words work. For example, there are times when you get a sentence like \u201cA says it will attack B,\u201d but what you\u2019re looking to code is \u201cA threatens B.\u201d Match transform() reads transformations from the Verb dictionary and checks to see if any of the events match the transformation format. If that\u2019s the case, then the event is converted into a simple (S,T,V) format. The entry in the dictionary for that example would be\na (a b WILL ATTACK) SAY = a b 138\nwhich is basically post-fix notation. This is described in more detail in the dictionary specifications.\n3.3.6 is valid()\nThis method is used to catch a consistent mistake that happens in CoreNLP when a past participle is used as an adjective in front of a noun, but is instead coded as a verb."}, {"heading": "3.4 Event extraction", "text": "One call to the get meaning() method of the uppermost VP will cause the rest of the tree to be parsed, and return the event coding of that VP, which is the event coding of the whole tree. Since not all events of the sentence at this point might not be complete, the Sentence object which contains the Phrase tree will call get meaning() in its get events() method, and check to see if the event is satisfactory. If the event that is returned by get meaning() is a complete coding (has all three parts), it is assigned to the sentence and the process is complete."}, {"heading": "4 Dictionaries", "text": "Petrarch uses the same Actor, Agent, Discard, and Issue dictionaries as it always has, but the newest version has brought changes to the format and structure of the Verb Dictionary. The sets of synonymous nouns (synsets) remain the same, as well as how the base verbs are organized and stored. The two biggest differences are the\ntransformations, which match transform() looks at, and the patterns for matching phrases."}, {"heading": "4.1 Patterns", "text": "The patterns in the dictionaries should now follow a few simple rules:\n1. The intended pattern should contain exactly one verb: the verb being matched\n2. The pattern entries should be minimal, i.e. the smallest amount of information necessary to capture the intended phrases. This is just to keep the dictionary small but effective.\n3. The pattern has up to four parts: Pre-verb nouns, Pre-verb Prepositions, Post-verb nouns, Post-verb prepositions.\nThe patterns themselves also contain additional annotative symbols to provide the parser with more syntactic information:\n\u2022 Unmarked words are nouns or particles. These nouns are phrase heads.\n\u2022 {Bracketed phrases} are for specifying things that can\u2019t be covered by a single noun, e.g. (necessary) adjectives, complex nouns, etc.. The last word in the brackets should be the head.\n\u2022 Prepositional phrases are (in parentheses). The first word is the preposition, the rest is considered as nouns are.\n\u2022 Note that these prepositional markers can be combined (with {Noun Phrases})"}, {"heading": "4.2 Verb+Verb interaction", "text": ""}, {"heading": "4.2.1 Combinations", "text": "Verbs can interact with each other in one of two ways. The first is what we call a combination. This is what happens when the meaning of the two verbs together is literally the meanings of the two verbs individually. These occur mostly frequently to specify the subcode of somewhat vague or high-level CAMEO categories, like appeal, intend, refuse or demand. This is handled using an internal translation of CAMEO codes into a system that expands the hierarchy of CAMEO beyond the basic top-level/subcode classification system. This allows for more controllable processing of verb combinations that are inherent in CAMEO. So rather than a system where\u201cIntend [030] + Help [070] =Intend to help[033],\u201d we get \u201cIntend [3000] + Help [0040] =Intend to help[3040].\u201d The full conversion schema can be found in the utilities.py file under convert code().\nCodes are converted and stored as four-digit hex (base 16) codes. The general principle behind it is in the table below. The first three columns encompass the\ntop-level codes, the fourth position is a specifier. For the most part they follow the descriptions here, but some top-level codes have unique subclasses, which don\u2019t follow these specifically. Notice that not all combinations refer to CAMEO codes. This is intentional, and means that if we wanted to code things beyond CAMEO we could. The strength of this is predictability and the possibility of semantic addition. When returning the event code, Petrarch converts back to CAMEO for the sake of reverse compatibility.\n0 0 0 0 1 Say 1 Reduce 1 Meet 1 Leadership 2 Appeal 2 Yield 2 Settle 2 Policy 3 Intend 3 Mediate 3 Rights 4 Demand 4 Aid 4 Regime 5 Protest 5 Expel 5 Econ 6 Threaten 6 Pol. Change 6 Military 7 Disapprove 7 Mat. Coop 7 Humanitarian 8 Posture 8 Dip. Coop 8 Judicial 9 Coerce 9 Assault 9 Peacekeeping A Investigate A Fight A Intelligence B Consult B Mass violence B Admin. Sanctions\nC Dissent D Release E Int\u2019l Involvement F De-escalation\nThe one class not present here is 120, which classifies rejections and refusal to cooperate. Because the action of \u201crefusing to do X\u201d is so often the same as \u201cnot doing X,\u201d these are simply categorized as the value of their cooperative version minus 0xFFFF. So, since \u201cprovide aid\u201d is 0040, \u201crefuse to provide aid\u201d is 0040- FFFF = -FFBF. This is functionally equivalent to the negative, since there is no positive FFFF code, the subtraction always yields a negative value. This allows us to convert negations such as \u201cWILL NOT HELP\u201d = 0\u2212FFFF + 0040 = \u2212FFBF = \u201cREFUSE TO HELP.\u201d"}, {"heading": "4.2.2 Transformations", "text": "Sometimes this is insufficient, like when the meaning of the verb interaction depends also on the relationships between the nouns that are acting and being acted upon. The difference between \u201cA says B attacked C\u201d and \u201cA says A attacked B\u201d is such a case. The first is equivalent to \u201cA blames B for an attack,\u201d and the second \u201cA\ntakes credit for an attack on B.\u201d Since this depends on the nouns involved, we must consider them in the transformation category and not the combination category. The specification on how these are formatted is in the documentation."}, {"heading": "5 Example", "text": "Consider the sentence\n\u2022 \u201cIsrael said a mortar bomb was launched at it from the Gaza strip on Tuesday\u201d\nPetrarch would code this sentence as ISR PSEGZA 112 with the following tree: 11 S\n.\n.\nVP\nISR PSEGZA 112\nSBAR\nS\nVP\nPSEGZA ISR 190\nVP\nPSEGZA ISR 190\nPP\nNP\n+PSEGZA\nPP\nNP\nNNP\nTUESDAY\nIN\nON\nNP\n+PSEGZA\nNNP\nSTRIP\nNNP\nGAZA\nDT\nTHE\nIN\nFROM\nPP\nNP\n+ISR\nPRP\nIT\nIN\nAT\nVBN\nLAUNCHED\nVBD\nWAS\nNP\nNN\nBOMB\nJJ\nMORTAR\nDT\nA\nVBD\nSAID\nNP\n+ISR\nNNP\nISRAEL\nThe color coding shows where the actor codes come from. The significant steps taken in this parse involve the verbs \u201csaid\u201d and \u201cflaunched,\u201d and the pronoun \u201cit.\u201d The pronoun coreference follows the non-reflexive matching process described above. When Petrarch is analyzing \u201claunched,\u201d it\n1. Identifies the verb as passive\n2. Finds the patterns for this verb\n3. Finds the target under the prepositional phrase with \u201cit\u201d\n4. Identifies the antecedent of \u201cit\u201d to be \u201cISR\u201d\n5. Finds the source under the prepositional phrase with \u201cfrom\u201d\n11For those unfamiliar with CAMEO verb codes, 190 is an organized attack, while 112 is an accusation of aggression\nThen, the analysis of \u201csaid\u201d follows the process:\n1. Finds the lower event (PSEGZA ISR 190)\n2. Identifies the subject of \u201csaid\u201d as ISR\n3. Matches this with the dictionary-specified verb transformation a (b . ATTACK) SAY = a b 112\n4. Transforms this into ISR PSEGZA 112."}, {"heading": "6 Works Cited", "text": ""}], "references": [{"title": "Automated Coding of International Event Data Using Sparse Pars- ing Techniques.", "author": ["Schrodt", "Philip A"], "venue": "Paper presented at the International Studies Association,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "Precedents, Progress and Prospects in Political Event Data.\u201d Inter- national Interactions 38(5):546569", "author": ["Schrodt", "Philip A"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Coding Sub-State Actors using the CAMEO (Conflict and Mediation Event Observations) Actor Coding Framework.", "author": ["Schrodt", "Philip A", "Omur Yilmaz", "Deborah J. Gerner", "Dennis Hermrick"], "venue": "International Studies Association,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}], "referenceMentions": [], "year": 2016, "abstractText": "PETRARCH 2 is the fourth generation of a series of Event-Data coders stemming from research by Phillip Schrodt1. Each iteration has brought new functionality and usability 2, and this is no exception. Petrarch 2 takes much of the power of the original Petrarch\u2019s dictionaries and redirects it into a faster and smarter core logic. Earlier iterations handled sentences largely as a list of words, incorporating some syntactic information here and there. Petrarch 2 (henceforth referred to as Petrarch) now views the sentence entirely on the syntactic level. It receives the syntactic parse of a sentence from the Stanford CoreNLP software, and stores this data as a tree structure of linked nodes, where each node is a Phrase object. Prepositional, noun, and verb phrases each have their own version of this Phrase class, which deals with the logic particular to those kinds of phrases. Since this is an event coder, the core of the logic focuses around the verbs: who is acting, who is being acted on, and what is happening. The theory behind this new structure and its logic is founded in Generative Grammar, Information Theory, and Lambda-Calculus Semantics.", "creator": "LaTeX with hyperref package"}}}