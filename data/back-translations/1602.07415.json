{"id": "1602.07415", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2016", "title": "Ensuring Rapid Mixing and Low Bias for Asynchronous Gibbs Sampling", "abstract": "Gibbs sampling is a Markov chain Monte Carlo technique commonly used to estimate boundary distributions. In order to speed up Gibbs sampling, there has recently been interest in asynchronous parallelization. While empirical results suggest that many models can be efficiently sampled asynchronously, traditional Markov chain analysis does not apply to the asynchronous case, and asynchronous Gibbs sampling is therefore poorly understood. In this paper, we derive a better understanding of the two main challenges of asynchronous Gibbs: sampling bias and mixing time. We experimentally demonstrate that our theoretical results correspond with practical results.", "histories": [["v1", "Wed, 24 Feb 2016 06:54:43 GMT  (57kb)", "http://arxiv.org/abs/1602.07415v1", null], ["v2", "Mon, 30 May 2016 21:19:52 GMT  (58kb)", "http://arxiv.org/abs/1602.07415v2", null], ["v3", "Thu, 16 Jun 2016 20:55:19 GMT  (58kb)", "http://arxiv.org/abs/1602.07415v3", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["christopher de sa", "christopher r\u00e9", "kunle olukotun"], "accepted": true, "id": "1602.07415"}, "pdf": {"name": "1602.07415.pdf", "metadata": {"source": "CRF", "title": "Ensuring Rapid Mixing and Low Bias for Asynchronous Gibbs Sampling", "authors": ["Christopher De Sa", "Kunle Olukotun"], "emails": ["cdesa@stanford.edu", "kunle@stanford.edu", "chrismre@stanford.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 2.\n07 41\n5v 1\n[ cs\n.L G\n] 2\n4 Fe"}, {"heading": "1 Introduction", "text": "Gibbs sampling is one of the most common Markov Chain Monte Carlo methods used with graphical models Koller & Friedman (2009). In this setting, Gibbs sampling (Algorithm 1) operates iteratively by choosing at random a variable from the model at each timestep, and updating it by sampling from its conditional distribution given the other variables in the model. Often, it is applied to inference problems, in which we are trying to estimate the marginal probabilities of some query events in a given distribution.\nAlgorithm 1 Gibbs sampling Require: Variables xi for 1 \u2264 i \u2264 n, and distribution \u03c0.\nfor t = 1 to T do Sample s uniformly from {1, . . . , n}. Re-sample xs uniformly from P\u03c0(Xs|X{1,...,n}\\{s}). end for\nFor sparse graphical models, to which Gibbs sampling is often applied, each of these updates needs to read the values of only a small subset of the variables; therefore each update can be computed very quickly on modern hardware. Because of this and other useful properties of Gibbs sampling, many systems use Gibbs sampling to perform inference on big data Newman et al. (2007); Lunn et al. (2009); McCallum et al. (2009); Smola & Narayanamurthy (2010); Theis et al. (2012); Zhang & Re\u0301 (2014).\nSince Gibbs sampling is such a ubiquitous algorithm, it is important to try to optimize its execution speed on modern hardware. Unfortunately, while modern computer hardware has been trending towards more parallel architectures Sutter (2005), traditional Gibbs sampling is an inherently sequential algorithm; that is, the outer loop in Algorithm 1 is not embarrassingly parallel. Furthermore, for sparse models, very little work happens within each iteration, meaning it is difficult to extract much parallelism from the body of this outer loop. Since traditional Gibbs sampling parallelizes so poorly, it is interesting to study variants of Gibbs sampling that can be parallelized. Several such variants have been proposed, including applications to latent Dirichlet allocation Newman et al. (2007); Smola & Narayanamurthy (2010) and distributed constraint optimization problems Nguyen et al. (2013).\nIn one popular variant, multiple threads run the Gibbs sampling update rule in parallel without locks, a strategy called asynchronous or HOGWILD! execution\u2014in this paper, we use these two terms interchangeably. This idea was\nproposed, but not analyzed theoretically, in Smola & Narayanamurthy (2010), and has been shown to give empirically better results on many models Zhang & Re\u0301 (2014). But when can we be sure that HOGWILD! Gibbs sampling will produce accurate results? Except for the case of Gaussian random variables Johnson et al. (2013), there is no existing analysis by which we can ensure that asynchronous Gibbs sampling will be appropriate for a particular application. Even the problems posed by HOGWILD!-Gibbs are poorly understood, and their solutions more so.\nAs we will see in the following sections, there are two main issues when analyzing asynchronous Gibbs sampling. Firstly, we will show by example that, surprisingly, HOGWILD!-Gibbs can be biased\u2014unlike sequential Gibbs, it does not always produce samples that are arbitrarily close to the target distribution. Secondly, we will show that the mixing time (the time for the chain to become close to its stationary distribution) of asynchronous Gibbs sampling can be at worst exponentially greater than that of the corresponding sequential chain.\nTo address the issue of bias, we need some way to describe the distance between the target distribution \u03c0 and the distribution of the samples produced by HOGWILD!-Gibbs. The standard notion to use here is the total variation distance, but for the task of computing marginal probabilities, it gives an overestimate on the error caused by bias. To better describe the bias, we introduce a new notion of statistical distance, the sparse variation distance. While this relaxed notion of statistical distance is interesting in its own right, its main benefit here is that it more tightly measures the effect of bias on marginal estimation.\nOur main goal is to identify conditions under which the bias and mixing time of asynchronous Gibbs can be bounded. One parameter that has been used to great effect in the analysis of Gibbs sampling is the total influence \u03b1 of a model. The total influence measures the degree to which the marginal distribution of a variable can depend on the values of the other variables in the model\u2014this parameter has appeared as part of a celebrated line of work on Dobrushin\u2019s condition (\u03b1 < 1), which ensures the rapid mixing of spin statistics systems Dobrushin (1956); Dyer et al. (2006); Hayes (2006). It turns out that we can use this parameter to bound both the bias and mixing time of HOGWILD!-Gibbs, and so we make the following contributions:\n\u2022 We describe a way to statistically model the asynchronicity in HOGWILD!-Gibbs sampling.\n\u2022 To bound the bias, we prove that for classes of models with bounded total influence \u03b1 = O(1), if sequential Gibbs sampling achieves small sparse variation distance to \u03c0 in O(n) steps, where n is the number of variables, then HOGWILD!-Gibbs samples achieve the same distance in at most O(1) more steps.\n\u2022 For models that satisfy Dobrushin\u2019s condition (\u03b1 < 1), we show that the mixing time bounds of sequential and HOGWILD!-Gibbs sampling differ only by a factor of 1 +O(n\u22121).\n\u2022 We validate our results experimentally and show that, by using asynchronous execution, we can achieve wallclock speedups of up to 2.8\u00d7 on real problems."}, {"heading": "2 Related Work", "text": "Much work has been done on the analysis of parallel Gibbs samplers. One simple way to parallelize Gibbs sampling is to run multiple chains independently in parallel: this heuristic uses parallelism to produce more samples overall, but does not produce accurate samples more quickly. Additionally, this strategy is sometimes worse than other strategies on a systems level Smola & Narayanamurthy (2010); Zhang & Re\u0301 (2014), typically because it requires additional memory to maintain multiple models of the chain. Another strategy for parallelizing Gibbs sampling involves taking advantage of the structure of the underlying factor graph to run in parallel while still maintaining an execution pattern to which the standard sequential Gibbs sampling analysis can be applied Gonzalez et al. (2011). Much further work has focused on parallelizing sampling for specific problems, such as LDA Newman et al. (2007); Smola & Narayanamurthy (2010) and others Nguyen et al. (2013).\nOur approach follows on the paper of Johnson et al. (2013), which proposes the HOGWILD!-Gibbs sampling algorithm and analyzes it for the case of Gaussian models. Their main contribution is an analysis framework that includes a sufficient condition under which HOGWILD! Gaussian Gibbs samples are guaranteed to have the correct asymptotic mean. Recent work Terenin et al. (2015) has analyzed a similar algorithm under even stronger regularity conditions. Here, we seek to give more general results for the analysis of HOGWILD!-Gibbs sampling on discrete-valued factor graphs.\nThe HOGWILD!-Gibbs sampling algorithm was inspired by a line of work on parallelizing stochastic gradient descent (SGD) by running it asynchronously. HOGWILD! SGD was first proposed by Niu et al. (2011), who proved that\nwhile running without locks causes race conditions, they do not impede the convergence of the algorithm. The asynchronous execution strategy has been applied to many problems\u2014such as PageRank approximations Mitliagkas et al. (2015), deep learning Noel & Osindero (2014) and recommender systems Yu et al. (2012)\u2014so it is not surprising that it has been proposed for use with Gibbs sampling. Our goal in this paper is to combine analysis ideas that have been applied to Gibbs sampling and HOGWILD!, in order to characterize the behavior of asynchronous Gibbs. In particular, we are motivated by some recent work on the analysis of HOGWILD! for SGD Liu et al. (2015); De Sa et al. (2015a); Mania et al. (2015); Liu & Wright (2015). Several of these results suggest modeling the race conditions inherent in HOGWILD! SGD as noise in a stochastic process; this lets them bring a trove of statistical techniques to bear on the analysis of HOGWILD! SGD. Therefore, in this paper, we will apply a similar stochastic process model to Gibbs sampling.\nSeveral recent papers have focused on the mixing time of Gibbs sampling for factor graphs. Gotovos et al. (2015) and De Sa et al. (2015b) each show that Gibbs sampling mixes in polynomial time for a class of distributions bounded by some parameter. Unfortunately, these results both depend on spectral methods (that try to bound the spectral gap of the Markov transition matrix), which are difficult to apply to HOGWILD! Gibbs sampling for two reasons. First, spectral methods don\u2019t let us represent the sampler as a stochastic process, which limits the range of techniques we can use to model the noise. Secondly, while most spectral methods only apply to reversible Markov chains\u2014and sequential Gibbs sampling is always a reversible chain\u2014for HOGWILD!-Gibbs sampling the asynchronicity and parallelism make the chain non-reversible. Because of this, we were unable to use these spectral results in our asynchronous setting. We are forced to rely on the other method Guruswami (2000) for analyzing Markov processes, coupling\u2014the type of analysis used with the Dobrushin condition\u2014which we will describe in the following sections."}, {"heading": "3 Modeling Asynchronicity", "text": "In this section, we describe a statistical model for asynchronous Gibbs sampling by adapting the hardware model outlined in De Sa et al. (2015a). Because we are motivated by the factor graph inference problem, we will focus on the case where the distribution \u03c0 that we want to sample comes from a sparse, discrete graphical model.\nAny HOGWILD!-Gibbs implementation involves some number of threads each repeatedly executing the Gibbs update rule on a single copy of the model (typically stored in RAM). We assume that this model serializes all writes, such that we can speak of the state of the system after t writes have occurred. We call this time t, and we will model the HOGWILD! system as a stochastic process adapted to the natural filtration Ft \u2014 Ft contains all events that have occurred up to time t, and we say an event is Ft measurable if it is known deterministically by time t.\nWe begin our construction by letting xi,t denote the (Ft measurable) value of variable i at time t, and letting I\u0303t be the (Ft+1 measurable) index of the variable that we choose to sample at time t. For Gibbs sampling, we have\n\u2200i \u2208 {1, . . . , n}, P ( I\u0303t = i \u2223 \u2223 \u2223 Ft ) = 1\nn ;\nthis represents the fact that we have an equal probability of sampling each variable. Now that we have defined which variables are to be sampled, we proceed to describe how they are sampled. For HOGWILD!-Gibbs sampling, we must model the fact that the sampler does not get to use exactly the values of xi,t; rather it has access to a cache containing potentially stale values. To do this, we define (Ft+1 measurable) v\u0303i,t where\nv\u0303i,t = xi,t\u2212\u03c4\u0303i,t ,\nwhere \u03c4\u0303i,t \u2265 0 is a delay parameter (Ft+1 measurable and independent of I\u0303t) that represents how old the currentlycached value for variable i could be. A variable resampled using this stale data would have distribution\nP (z\u0303i,t = z|Ft) \u221d \u03c0(v\u03031,t, . . . , v\u0303i\u22121,t, z, v\u0303i+1,t, . . . , v\u0303n,t).\nUsing this, we can relate the values of the variables across time with\nxi,t+1 =\n{\nz\u0303i,t if i = I\u0303t xi,t otherwise.\nSo far, our model is incompletely specified, because we have not described the distribution of the delays \u03c4\u0303i,t. Unfortunately, since these delays are a property of the underlying hardware, their distribution is difficult to measure.\nInstead of specifying a particular distribution, we require only a bound on the expected delay\nE [\u03c4\u0303i,t|Ft] \u2264 \u03c4.\nIn this model, the \u03c4 parameter represents everything that is relevant about the hardware; representing the hardware in this way has been successful for the analysis of asynchronous SGD Niu et al. (2011), so it is reasonable to use it for Gibbs sampling. In addition to this, we will need a similar parameter that bounds the tails of \u03c4\u0303i,t slightly more aggressively. We require that for some parameter \u03c4\u2217, and for all i and t,\nE [ exp ( n\u22121\u03c4\u0303i,t ) \u2223 \u2223Ft ] \u2264 1 + n\u22121\u03c4\u2217.\nThis parameter is typically very close to the expected value bound \u03c4 ; in particular, as n approaches infinity, \u03c4\u2217 approaches \u03c4 ."}, {"heading": "4 The First Challenge: Bias", "text": "Perhaps the most basic result about sequential Gibbs sampling is the fact that, in the limit of large numbers of samples, it is unbiased. In order to measure convergence of Markov chains to their stationary distribution, it is standard to use the total variation distance.\nDefinition 1 (Total Variation Distance). The total variation distance (Levin et al., 2009, p. 48) between two probability measures \u00b5 and \u03bd on probability space \u2126 is defined as\n\u2016\u00b5\u2212 \u03bd\u2016TV = max A\u2282\u2126 |\u00b5(A) \u2212 \u03bd(A)| ,\nthat is, the maximum difference between the probabilities that \u00b5 and \u03bd assign to a single event A.\nIt is a well-known result that, for Gibbs sampling on a strictly-positive target distribution \u03c0, it will hold that\nlim t\u2192\u221e \u2016\u00b5t \u2212 \u03c0\u2016TV = 0, (1)\nwhere \u00b5t denotes the distribution of the t-th sample. One of the difficulties that arises when applying HOGWILD! to Gibbs sampling is that the race conditions from the asynchronous execution add bias to the samples \u2014 Equation 1 no longer holds. To understand why, we can consider a simple example."}, {"heading": "4.1 Bias Example", "text": "Consider a simple model with two variables X1 and X2 each taking on values in {0, 1}, and having distribution\np(0, 1) = p(1, 0) = p(1, 1) = 1\n3 p(0, 0) = 0.\nSequential Gibbs sampling on this model will produce unbiased samples from the target distribution. Unfortunately, this is not the case if we run HOGWILD!-Gibbs sampling on this model. Assume that the state is currently (1, 1) and two threads, T1 and T2, simultaneously update X1 and X2 respectively. Since T1 reads state (1, 1) it will update X1 to 0 or 1 each with probability 0.5; the same will be true for T2 and X2. Therefore, after this happens, every state will have probability 0.25; this includes the state (0, 0) which should never occur! Over time, this race condition will produce samples with value (0, 0) with some non-zero frequency; this is an example of bias introduced by the HOGWILD! sampling. Worse, this bias is not just theoretical: Figure 2 illustrates how the measured distribution for this model is affected by two-thread asynchronous execution. In particular, we observe that almost 5% of the mass is erroneously measured to be in the state (0, 0), which has no mass at all in the true distribution. The total variation distance to the target distribution is quite large at 9.8%, and, unlike in the sequential case, this bias doesn\u2019t disappear as the number of samples goes to infinity."}, {"heading": "4.2 Bounding the Bias", "text": "The previous example has shown that asynchronous Gibbs sampling will not necessarily produce a sequence of samples arbitrarily close to the target distribution. Instead, the samples will approach some other distribution, which we hope is sufficiently similar for some practical purpose. Often, the purpose of Gibbs sampling is to estimate the marginal distributions of individual variables or of events that each depend on only a small number of variables in the model. To characterize the accuracy of these estimates, the total variation distance is too conservative: it depends on the difference over all the events in the space, when most of these are events that we do not care about. To address this, we introduce the following definition.\nDefinition 2 (Sparse Variation Distance). For any event A in a probability space \u2126 over a set of variables V , let |A| denote the number of variables upon which A depends. Then, for any two distributions \u00b5 and \u03bd over \u2126, we define the \u03c9-sparse variation distance to be\n\u2016\u00b5\u2212 \u03bd\u2016SV(\u03c9) = max |A|\u2264\u03c9 |\u00b5(A) \u2212 \u03bd(A)| .\nFor the wide variety of applications that use sampling for marginal estimation, the sparse variation distance measures the quantity we actually care about: the maximum possible bias in the marginal distribution of the samples. As we will show, asynchronous execution seems to have less effect on the sparse variation distance than the total variation distance. For example, in Figure 2, the total variation distance between the sequential and HOGWILD! distributions is 9.8%, while the 1-sparse variation distance is only 0.4%. That is, while HOGWILD! execution does introduce great bias into the distribution, it still estimates marginals of the individual variables accurately.\nThis definition suggests the question: how long do we have to run before our samples have low sparse variation distance from the target distribution? To answer this question, we introduce the following definition.\nDefinition 3 (Sparse Estimation Time). The \u03c9-sparse estimation time of a stochastic sampler with distribution \u00b5t at time t and target distribution \u03c0 is the first time t at which, for any initial distribution \u00b50, the estimated distribution is\nwithin sparse variation distance \u01eb of \u03c0. That is,\ntSE(\u03c9)(\u01eb) = min { t \u2208 N \u2223 \u2223 \u2223 \u2200\u00b50, \u2016\u00b5t \u2212 \u03c0\u2016SV(\u03c9) \u2264 \u01eb } .\nIn many practical systems Neubig (2014); Shin et al. (2015), Gibbs sampling is used without a proof that it works; instead, it is naively run for some fixed number of passes through the dataset. This naive strategy works for models for which accurate marginal estimates can be achieved after O(n) samples. This O(n) runtime is necessary for Gibbs sampling to be feasible at all on big data, meaning roughly that models in this class are those which it is interesting to try to speed up using asynchronous execution. Therefore, for the rest of this section, we will focus on bias of the HOGWILD! chain for this class of models. When analyzing Gibbs sampling, we can bound the bias within the context of a coupling argument using a parameter called the total influence. While we arrived at this condition independently, it has been studied before, especially in the context of Dobrushin\u2019s condition, which ensures rapid mixing of Gibbs sampling.\nDefinition 4 (Total Influence). Let \u03c0 be a probability distribution over some set of variables I . Let Bj be the set of state pairs (X,Y ) which differ only at variable j. Let \u03c0i(\u00b7|XI\\{i}) denote the conditional distribution in \u03c0 of variable i given all the other variables in state X . Then, define \u03b1, the total influence of \u03c0, as\n\u03b1 = max i\u2208I\n\u2211\nj\u2208I\nmax (X,Y )\u2208Bj\n\u2225 \u2225\u03c0i(\u00b7|XI\\{i})\u2212 \u03c0i(\u00b7|YI\\{i}) \u2225 \u2225\nTV .\nWe say the model satisfies Dobrushin\u2019s condition if \u03b1 < 1.\nOne way to think of total influence for factor graphs is as a generalization of maximum degree; indeed, if a factor graph has maximum degree \u2206, it can easily be shown that \u03b1 \u2264 \u2206. It turns out that if we can bound both this parameter and the sparse estimation time of sequential Gibbs sampling, we can give a simple bound on the sparse estimation time for asynchronous Gibbs sampling.\nClaim 1. Assume that we have a class of distributions with bounded total influence \u03b1 = O(1). For each distribution \u03c0 in the class, let t\u0304SE\u2212seq(\u03c9)(\u03c0, \u01eb) be an upper bound on the \u03c9-sparse estimation time of its sequential Gibbs sampler, and assume that it is a convex, decreasing function of \u01eb. Further assume that, for any \u01eb, across all models,\nt\u0304SE\u2212seq(\u03c9)(\u03c0, \u01eb) = O(n),\nwhere n is the number of variables in the model. Then, for any \u01eb, the sparse estimation time of HOGWILD!-Gibbs across all models is bounded by\ntSE\u2212hog(\u03c9)(\u03c0, \u01eb) \u2264 t\u0304SE\u2212seq(\u03c9)(\u03c0, \u01eb) + O(1).\nRoughly, this means that HOGWILD!-Gibbs sampling \u201cworks\u201d on all problems for which we know marginal estimation is \u201cfast\u201d and the total influence is bounded. Since the sparse estimation times here are measured in iterations, and the asynchronous sampler is able, due to parallelism, to run many more iterations in the same amount of wall clock time, this result implies that HOGWILD!-Gibbs can be much faster than sequential Gibbs for producing estimates of similar quality. While this corollary tells us that any error \u01eb can be achieved for sufficiently large problem sizes, it does not actually tell us what error can be achieved for any particular n. To prove Claim 1, and specify a more explicit bound on the bias of HOGWILD!-Gibbs, we present the following theorem.\nTheorem 1. Assume that we run HOGWILD!-Gibbs sampling on a distribution \u03c0 with total influence\u03b1. Let t\u0304SE\u2212seq(\u03c9)(\u01eb) be some upper bound on the \u03c9-sparse estimation time of the corresponding sequential chain, and assume that it is a convex and decreasing function of \u01eb. For any \u01eb > 0, define\nc = 1\nn t\u0304SE\u2212seq(\u03c9)\n( \u01eb\n2\n)\n.\nThen, as long as \u01eb is large enough that\n\u01eb \u2265 2\u03c9\u03b1\u03c4c\nn ec\u00b7(\u03b1\u22121)+ ,\nwhere we use the notation (x)+ = max(0, x), the \u03c9-sparse estimation time of the HOGWILD! chain can be bounded with\ntSE\u2212hog(\u03c9)(\u01eb) \u2264\n\u2308\nt\u0304SE\u2212seq(\u03c9)(\u01eb) + 2\u03c9\u03b1\u03c4c2\n\u01eb ec\u00b7(\u03b1\u22121)+\n\u2309\n.\nThe required bound on \u01eb in Theorem 1 is to be expected: because of bias, it is impossible to produce arbitrarily good samples with HOGWILD!-Gibbs. Looked at another way, this bound on \u01eb characterizes the inherent bias of HOGWILD! sampling, in the limit as t becomes large. When c = O\u0303(1), this bias is O\u0303(n\u22121), which has an intuitive explanation: for HOGWILD! execution, race conditions occur about once every \u0398(n) iterations, so the bias is roughly proportional to the frequency of race conditions. This gives us a relationship between the statistical error of the algorithm and a more traditional notion of computational error.\nUp until now, we have been assuming that we have a class for which the sparse estimation time is O(n). Using the total influence \u03b1, we can identify a class of models known to meet this criterion.\nTheorem 2. For any distribution that satisfies Dobrushin\u2019s condition, \u03b1 < 1, the \u03c9-sparse estimation time of the sequential Gibbs sampling process will be bounded by\ntSE\u2212seq(\u03c9)(\u01eb) \u2264\n\u2308\nn 1\u2212 \u03b1 log (\u03c9 \u01eb )\n\u2309\n.\nThis surprising result says that, in order to produce good marginal estimates for any model that satisfies Dobrushin\u2019s condition, we need onlyO(n) samples! While we could now apply Theorem 1 to bound the sparse estimation time for HOGWILD!-Gibbs, a more direct analysis produces a slightly better result, which we present here.\nTheorem 3. For any distribution that satisfies Dobrushin\u2019s condition, \u03b1 < 1, and for any \u01eb that satisfies\n\u01eb \u2265 2\u03c9\u03b1\u03c4\n(1 \u2212 \u03b1)n ,\nthe \u03c9-sparse estimation time of the HOGWILD! Gibbs sampling process will be bounded by\ntSE\u2212hog(\u03c9)(\u01eb) \u2264\n\u2308\nn 1\u2212 \u03b1 log (\u03c9 \u01eb ) + 2\u03c9\u03b1\u03c4 (1\u2212 \u03b1)2\u01eb\n\u2309\n.\nThis result gives us a definite class of models for which HOGWILD!-Gibbs sampling is guaranteed to produce accurate marginal estimates quickly."}, {"heading": "5 The Second Challenge: Mixing Times", "text": "Even though the HOGWILD!-Gibbs sampler produces biased estimates, it is still interesting to analyze how long we need to run it before the samples it produces are independent of its initial conditions. To measure the efficiency of a Markov chain, it is standard to use the mixing time, the time necessary to produce samples that are close, in terms of total variation distance, to the stationary distribution.\nDefinition 5 (Mixing Time). The mixing time (Levin et al., 2009, p. 55) of a stochastic process with distribution \u00b5t at time t and stationary distribution \u03c0\u0304 is the first time t at which, for any initial distribution \u00b50, the estimated distribution is within TV-distance \u01eb of \u03c0\u0304. That is,\ntmix(\u01eb) = min {t|\u2200\u00b50, \u2016\u00b5t \u2212 \u03c0\u0304\u2016TV \u2264 \u01eb} ."}, {"heading": "5.1 Mixing Time Example", "text": "As we did with bias, here we construct an example model for which asynchronous execution disastrously increases the mixing time. The model we will construct is rather extreme; we choose this model because simpler, practical models do not seem to exhibit this type of catastrophic increase in the mixing time. We start, for some odd constant N , with N variables X1, . . . , XN all in {\u22121, 1}, and one factor with energy\n\u03c6X(X) = \u2212M1 \u2223 \u22231 TX \u2223 \u2223 .\nfor some very large energy parameter M1. The resulting distribution will be almost uniform over all states with 1 TX \u2208 {\u22121, 1}. To this model, we add another bank of variables Y1, . . . , YN all in {\u22121, 1}. These variables also have a single associated factor with energy\n\u03c6Y (X,Y ) =\n{\n\u03b2 N\n( 1 TY )2\nif \u2223 \u22231 TX \u2223 \u2223 = 1\nM2 ( 1 TY )2 if \u2223 \u22231 TX \u2223 \u2223 > 1\nCombining these two factors gives us the overall distribution for our model,\n\u03c0(X,Y ) = 1\nZ exp (\u03c6X(X) + \u03c6Y (X,Y )) ,\nwhere Z is the constant necessary for this to be a distribution. Roughly, the X dynamics are constructed to regularly \u201cgenerate\u201d race conditions, while the Y dynamics are chosen to \u201cdetect\u201d these race conditions and mix very slowly as a result. This model is illustrated in Figure 3.\nWe simulated two-thread HOGWILD!-Gibbs on this model, measuring the marginal probability that 1TY > 0; by symmetry, this event has probability 0.5 in the stationary distribution for both the sequential and asynchronous samplers. Our results, for a model with N = 2001, \u03b2 = 0.3, M1 = 1010, and M2 = 100, and initial state X = Y = 1, are plotted in Figure 4. Notice that, while the sequential sampler achieves the correct marginal probability relatively quickly, the asynchronous samplers take a much longer time to achieve the correct result, even for a relatively small expected delay (\u03c4 = 0.5). These results suggest that something catastrophic is happening to the mixing time when we switch from sequential to asynchronous execution \u2014 and in fact we can prove this is the case.\nStatement 1. For the example model described above, there exist parameters M1, M2, and \u03b2 (as a function of N ) such that the mixing time of sequential Gibbs sampling is O(N logN) but the mixing time of HOGWILD!-Gibbs sampling, even with \u03c4 = O(1), can be exp(\u2126(N)).\nThe intuition behind this statement is that for sequential Gibbs, the dynamics of the X part of the chain quickly causes it to have \u2223 \u22231 TX \u2223\n\u2223 = 1, and then remain there for the remainder of the simulation with high probability. This in turn causes the energy of the \u03c6Y factor to be essentially \u03b2 N (1TY )2, a model which is known to be fast-mixing. On the other hand, for HOGWILD! Gibbs, due to race conditions we will see \u2223 \u22231 TX \u2223\n\u2223 6= 1 with constant probability; this will cause the effective energy of the \u03c6Y factor to be dominated by the M2(1TY )2 term, a model that is known to take exponential time to mix."}, {"heading": "5.2 Bounding the Mixing Time", "text": "This example illustrates that fast mixing of the sequential sampler alone is not sufficient to guarantee fast mixing of the HOGWILD! chain. Consequently, we try to look for classes of models for which we can say something about the mixing time of both sequential and HOGWILD!-Gibbs. Dobrushin\u2019s condition is well known to imply rapid mixing of sequential Gibbs, and it turns out that we can leverage it again here to bound the mixing time of the asynchronous sampler.\nTheorem 4. Assume that we run Gibbs sampling on a distribution that satisfies Dobrushin\u2019s condition, \u03b1 < 1. Then the mixing time of sequential Gibbs will be bounded by\ntmix\u2212seq(\u01eb) \u2264 n 1\u2212 \u03b1 log (n \u01eb ) .\nUnder the same conditions, the mixing time of HOGWILD!-Gibbs will be bounded by\ntmix\u2212hog(\u01eb) \u2264 n+ \u03b1\u03c4\u2217 1\u2212 \u03b1 log (n \u01eb ) .\nWe can compare these two mixing time results as\ntmix\u2212hog(\u01eb) \u2248 ( 1 + \u03b1\u03c4\u2217n\u22121 ) tmix\u2212seq(\u01eb); (2)\nthe bounds on the mixing times differ by a negligible factor of 1 + O(n\u22121). This result shows that, for problems that satisfy Dobrusin\u2019s condition, HOGWILD!-Gibbs sampling mixes in about the same time as sequential Gibbs sampling, and is therefore a practical choice for generating samples."}, {"heading": "5.3 A Positive Example: Ising Model", "text": "To gain intuition here, we consider a simple example. The Ising model Ising (1925) on a graph G = (V,E) is a model over probability space {\u22121, 1}V , and has distribution\np(\u03c3) = 1\nZ exp\n(\n\u03b2 \u2211\n(x,y)\u2208E\n\u03c3(x)\u03c3(y) + \u2211\nx\u2208V\nBx\u03c3(x)\n)\n,\nwhere \u03b2 is a parameter that is called the inverse temperature, the Bx are parameters that encode a prior on the variables, and Z is the normalization constant necessary for this to be a distribution. For graphs of maximum degree \u2206 and sufficiently small \u03b2, a bound on the mixing time of Gibbs sampling is known when \u2206tanh\u03b2 \u2264 1. It turns out that the total influence of the Ising model can be bounded by \u03b1 \u2264 \u2206tanh\u03b2, and so this condition is simply another way of writing Dobrushin\u2019s condition. We can therefore apply Theorem 4 to bound the mixing time of HOGWILD!Gibbs with\ntmix(\u01eb) \u2264 n+ \u03c4\u2217\u2206tanh\u03b2 1\u2212\u2206tanh\u03b2 log (n \u01eb ) .\nThis illustrates that the class of graphs we are considering includes some common, well-studied models."}, {"heading": "5.4 Proof Outline", "text": "Here, we briefly describe the technique used to prove Theorem 4; for ease of presentation, we focus on the case where every variable takes on values in {\u22121, 1}. We start by introducing the idea of a coupling-based argument (Levin et al., 2009, p. 64). The argument starts with constructing two copies of the same Markov chain, X and X\u0304 , starting from different states but running together in the same probability space (i.e. using the same sources of randomness). For analyzing HOGWILD!-Gibbs sampling, we share randomness by having both chains sample the same variable at each iteration and sample it such that the resulting values are maximally correlated\u2014additionally both chains are subject to the same HOGWILD! delays \u03c4\u0303i,t.\nAt some random time, called the coupling time Tc, the chains will become equal\u2014independent of their initial conditions. Using this, we can bound the mixing time with\ntmix(\u01eb) \u2264 min { t \u2223 \u2223 \u2223 P (Tc > t) \u2264 \u01eb } .\nIn order to bound the probability that the chains are not equal at a particular time t, we focus on the quantity\n\u03c6t = max i\nP ( Xi,t 6= X\u0304i,t ) . (3)\nUnder the conditions of Theorem 4, we are able to bound this using the total influence parameter. From here, we notice that by the union bound, P (Tc > t) \u2264 n\u03c6t. Combining this with Equation 3 and reducing the subsequent expression\nlets us bound the mixing time, producing the result of Theorem 4."}, {"heading": "6 Experiments", "text": "Now that we have derived a theoretical characterization of the behavior of HOGWILD!-Gibbs sampling, we examine whether this characterization holds up under experimental evaluation. First, we examine the mixing time claims we made in Section 5. Specifically, we want to check whether increasing the expected delay parameter \u03c4\u2217 actually increases the mixing time as predicted by Equation 2.\nTo do this, we simulated HOGWILD!-Gibbs sampling running on a random synthetic Ising model graph of order n = 1000, degree \u2206 = 3, inverse temperature \u03b2 = 0.2, and prior weights Ex = 0. This model has total influence \u03b1 \u2264 0.6, and Theorem 4 guarantees that it will mix rapidly. Unfortunately, the mixing time of a chain is difficult to calculate experimentally. While techniques such as coupling from the past Propp & Wilson (1996) exist for estimating the mixing time, using these techniques in order to expose the (relatively small) dependence of the mixing time on \u03c4 proved to be computationally intractable.\nInstead, we use a technique called coupling to the future. We initialize two chains, X and Y , by setting all the variables in X0 to 1 and all the variables in Y0 to \u22121. We proceed by simulating a coupling between the two chains, and return the coupling time Tc. Our estimate of the mixing time will then be t\u0302(\u01eb), where P(Tc \u2265 t\u0302(\u01eb)) = \u01eb.\nStatement 2. This experimental estimate is an upper bound for the mixing time. That is, t\u0302(\u01eb) \u2265 tmix(\u01eb).\nTo estimate t\u0302(\u01eb), we ran 10000 instances of the coupling experiment, and returned the sample estimate of t\u0302(1/4). To compare across a range of \u03c4\u2217, we selected the \u03c4\u0303i,t to be independent and identically distributed according to the maximum-entropy distribution supported on {0, 1, . . . , 200} consistent with a particular assignment of \u03c4\u2217. The resulting estimates are plotted as the blue series in Figure 5. The red line represents the mixing time that would be predicted by naively applying Equation 2 using the estimate of the sequential mixing time as a starting point \u2014 we can see that it is a very good match for the experimental results. This experiment shows that, at least for one archetypal model, our theory accurately characterizes the behavior of HOGWILD! Gibbs sampling as the delay parameter \u03c4\u2217 is changed, and that using HOGWILD!-Gibbs doesn\u2019t cause the model to catastrophically fail to mix.\nOf course, in order for HOGWILD!-Gibbs to be useful, it must also speed up the execution of Gibbs sampling on some practical models. It is already known that this is the case, as these types of algorithms been widely implemented\nin practice Smyth et al. (2009); Smola & Narayanamurthy (2010). To further test this, we ran HOGWILD!-Gibbs sampling on a real-world 11 GB Knowledge Base Population dataset (derived from the TAC-KBP challenge) using a machine with a single-socket, 18-core Xeon E7-8890 CPU and 1 TB RAM. As a comparison, we also ran a \u201cmultimodel\u201d Gibbs sampler: one which runs an independent copy of the sequential chain on each worker. This sampler will produce the same number of samples as HOGWILD!-Gibbs, but the samples could be of lower quality since they are split up among several independent chains.\nFigure 6 reports the speedup, in terms of wall-clock time, achieved by HOGWILD!-Gibbs on this dataset. On this machine, we get speedups of up to 2.8\u00d7, although the program becomes memory-bandwidth bound at around 8 threads, and we see no significant speedup beyond this. With any number of workers, the run time of HOGWILD!-Gibbs is close to that of multi-model Gibbs, which illustrates that the additional cache contention caused by the HOGWILD! updates has little effect on the algorithm\u2019s performance."}, {"heading": "7 Conclusion", "text": "We analyzed HOGWILD!-Gibbs sampling, a heuristic for parallelized MCMC sampling, on discrete-valued graphical models. First, we constructed a statistical model for HOGWILD!-Gibbs by adapting a model already used for the analysis of asynchronous SGD. Next, we illustrated a major issue with HOGWILD!-Gibbs sampling: that it produces biased samples. To address this, we proved that if for some class of models with bounded total influence, only O(n) sequential Gibbs samples are necessary to produce good marginal estimates (in terms of sparse variation distance), then HOGWILD!-Gibbs sampling produces equally good estimates after only O(1) additional steps. Additionally, for models that satisfy Dobrushin\u2019s condition (\u03b1 < 1), we proved mixing time bounds for sequential and asynchronous Gibbs sampling that differ by only a factor of 1 + O(n\u22121). Finally, we showed that our theory matches experimental results, and that HOGWILD!-Gibbs sampling produces speedups up to 2.8\u00d7 on a real dataset."}, {"heading": "Acknowledgments", "text": "The authors acknowledge the support of: DARPA FA8750-12-2-0335; NSF IIS-1247701; NSF CCF-1111943; DOE 108845; NSF CCF-1337375; DARPA FA8750-13-2-0039; NSF IIS-1353606; ONR N000141210041 and N000141310129; NIH U54EB020405; Oracle; NVIDIA; Huawei; SAP Labs; Sloan Research Fellowship; Moore Foundation; American Family Insurance; Google; and Toshiba.\n\u201cThe views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of DARPA, AFRL, NSF, ONR, NIH, or the U.S. Government.\u201d"}, {"heading": "A Proofs", "text": "Here, we provide proofs for the results in the paper. In the first subsection, we will state lemmas and known results that we will use in the subsequent proofs. Next, we will prove the Claims and Theorems stated in the body of the paper. Finally, we will prove the lemmas previously stated.\nA.1 Statements of Lemmas\nFirst, we state a proposition from Levin et al. (2009). This proposition relates the concept of a coupling with the total variation distance between the distributions of two random variables.\nProposition 1 (Proposition 4.7 from Levin et al. (2009)). Let X and Y be two random variables that take on values in the same set, and let their distributions be \u00b5 and \u03bd, respectively. Then for any coupling, (X\u0304, Y\u0304 ) it will hold that\n\u2016\u00b5\u2212 \u03bd\u2016TV \u2264 P ( X\u0304 6= Y\u0304 ) .\nFurthermore, there exists a coupling for which equality is achieved; this is called an optimal coupling.\nWe can prove a related result for sparse variation distance.\nLemma 1. Let X and Y be two random variables that each assign values to a set of variables {1, . . . , n}, and let their distributions be \u00b5 and \u03bd, respectively. Then for any coupling, (X\u0304, Y\u0304 ) it will hold that\n\u2016\u00b5\u2212 \u03bd\u2016SV(\u03c9) \u2264 max I\u2282{1,...,n}, |I|\u2264\u03c9\nP ( \u2203i \u2208 I, X\u0304i 6= Y\u0304i ) .\nWe state a lemma that bounds the expected total variation distance between the marginal distributions of two states using the total influence \u03b1. This lemma will be useful later when proving the subsequent lemmas stated in this subsection.\nLemma 2. If \u03c0 is a distribution with total influence \u03b1, and X and Y are two random variables that take on values in the state space of \u03c0, then for any variable i\nE [\u2016\u03c0i(\u00b7|X)\u2212 \u03c0i(\u00b7|Y )\u2016TV] \u2264 \u03b1max j P (Xj 6= Yj) .\nNext, we state three lemmas, each of which give bounds on the quantity\nP (Xi,t 6= Yi,t)\nfor some coupling of two (potentially asynchronous) Gibbs sampling chains. First, we state the result for comparing two synchronous chains.\nLemma 3. Consider sequential Gibbs sampling on a distribution \u03c0 with total influence \u03b1. Then, for any initial states (X0, Y0) there exists a coupling of the chains (Xt, Yt) such that for any variable i and any time t,\nP (Xi,t 6= Yi,t) \u2264 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n.\nSecond, we state the result comparing two HOGWILD! chains.\nLemma 4. Consider any model of HOGWILD!-Gibbs sampling on a distribution \u03c0 with total influence \u03b1. Then, for any initial states (X0, Y0) there exists a coupling (Xt, Yt) of the HOGWILD!-Gibbs sampling chains starting at X0 and Y0 respectively such that for any variable i and any time t,\nP (Xi,t 6= Yi,t) \u2264 exp\n(\n\u2212 1\u2212 \u03b1\nn+ \u03b1\u03c4\u2217 t\n)\n.\nThird, we state the result comparing a sequential and an asynchronous chain.\nLemma 5. Consider any model of HOGWILD!-Gibbs sampling on a distribution \u03c0 with total influence \u03b1. Then if for any initial states (X0, Y0) we can construct a coupling (Xt, Yt) such that the process Xt is distributed according to the dynamics of HOGWILD!-Gibbs, the process Yt is distributed according to the dynamics of sequential Gibbs, and for any time t,\nmax i P (Xi,t+1 6= Yi,t+1) \u2264\n(\n1\u2212 1\u2212 \u03b1\nn\n)\nmax i\nP (Xi,t 6= Yi,t) + \u03b1\u03c4\nn2 .\nAs a secondary result, if the chain satisfies Dobrushin\u2019s condition (\u03b1 < 1), then for any variable i and any time t,\nP (Xi,t 6= Yi,t) \u2264 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n+ \u03b1\u03c4\n(1\u2212 \u03b1)n .\nTo prove that our catastrophic mixing time example mixes in O(n logn) time in the sequential case, we will need to use the following result, which is inspired by work on mixing using strong stationary times in Diaconis & Shahshahani (1981) and Diaconis (1988).\nLemma 6 (Monotonic Sequence Domination Lemma). Let x0, x1, . . . be a sequence such that, for all t,\nxt+1 \u2264 ft(xt, xt\u22121, . . . , x0),\nwhere ft is a function that is monotonically increasing in all of its arguments. Then, for any sequence y0, y1, . . ., if x0 = y0 and for all t,\nyt+1 \u2265 ft(yt, yt\u22121, . . . , y0),\nthen for all t, xt \u2264 yt.\nLemma 7. Consider the model on N variables Xi, for N odd, where each Xi takes on values in {\u22121, 1} and has probability\n\u03c0(X) = 1\nZX\n{ 1 if \u2223 \u22231 TX \u2223\n\u2223 = 1 0 if \u2223 \u22231 TX \u2223 \u2223 > 1\nThen Gibbs sampling on this model has mixing time\ntmix = O(n logn).\nA.2 Proofs of Bias Results\nFirst, we prove Claim 1. This proof will use the result of Theorem 1, which we will prove subsequently. We note here that the use of a convex upper bound for the sparse estimation time of the sequential chain (as opposed to using the sequential chain\u2019s sparse estimation time directly) is an unfortunate consequence of the proof\u2014we hope that a more careful analysis could remove it or replace it with a more natural condition.\nProof of Claim 1. First, note that, since \u03b1 = O(1), we know by the definition of big-O notation that for some \u03b1\u2217, for all models in the class, the total influence of that model will be \u03b1 \u2264 \u03b1\u2217. Similarly, since we assumed that, for any \u01eb and across all models \u03c0,\nt\u0304SM\u2212seq(\u03c9)(\u03c0, \u01eb) = O(n),\nthen for each \u01eb, there must exist a c(\u01eb) such that for any distribution \u03c0 with n variables in the class,\ntSM\u2212seq(\u03c9)(\u03c0, \u01eb) \u2264 n \u00b7 c(\u01eb).\nFor some error \u01eb and model \u03c0, we would like to apply Theorem 1 to bound its mixing time. In order to apply the theorem, we must satisfy the conditions on \u01eb: it suffices for\nn \u2265 2\u03c9\u03b1\u2217\u03c4c(\u01eb/2)\n\u01eb exp ((\u03b1\u2217 \u2212 1)+c(\u01eb/2)) .\nUnder this condition, applying the theorem allows us to bound the \u03c9-sparse estimation time of the HOGWILD! chain with\ntSE\u2212hog(\u03c9)(\u01eb) \u2264\n\u2308\nt\u0304SE\u2212seq(\u03c9)(\u01eb) + 2\u03c9\u03b1\u2217\u03c4c(\u01eb/2)2\n\u01eb exp ((\u03b1\u2217 \u2212 1)+c(\u01eb/2))\n\u2309\n\u2264 t\u0304SE\u2212seq(\u03c9)(\u01eb) + 2\u03c9\u03b1\u2217\u03c4c(\u01eb/2)2\n\u01eb exp ((\u03b1\u2217 \u2212 1)+c(\u01eb/2)) + 1\nTherefore, if we define\nN(\u01eb) = 2\u03c9\u03b1\u2217\u03c4c(\u01eb/2)\n\u01eb exp ((\u03b1\u2217 \u2212 1)+c(\u01eb/2)) ,\nand\nT (\u01eb) = 2\u03c9\u03b1\u2217\u03c4c(\u01eb/2)2\n\u01eb exp ((\u03b1\u2217 \u2212 1)+c(\u01eb/2)) + 1,\nthen it follows that, for any \u01eb and for all models with n \u2265 N(\u01eb),\ntSM\u2212hog(\u03c9)(\u01eb) \u2264 tSM\u2212seq(\u03c9)(\u01eb) + T (\u01eb).\nThis is equivalent to saying that, for any \u01eb and across all models,\ntSM\u2212hog(\u03c9)(\u01eb) \u2264 tSM\u2212seq(\u03c9)(\u01eb) +O(1).\nThis proves the claim.\nNext, we prove the main bias result, Theorem 1.\nProof of Theorem 1. We start by using the primary result from Lemma 5. This result states that we can construct a coupling (Xt, Yt) of the HOGWILD! and sequential chains starting at any initial distributions X0 and Y0 such that at any time t,\nmax i P (Xi,t+1 6= Yi,t+1) \u2264\n(\n1\u2212 1\u2212 \u03b1\nn\n)\nmax i\nP (Xi,t 6= Yi,t) + \u03b1\u03c4\nn2 .\nNow, for any initial distribution \u00b50, assume that we let both X0 and Y0 be distributed according to \u00b50. Then, trivially,\nP (Xi,0 6= Yi,0) = 0.\nIt follows from recursive application of the sub-result of Lemma 5 that, for this coupling,\nmax i P (Xi,t 6= Yi,t) \u2264\nt\u22121 \u2211\nk=0\n(\n1 + \u03b1\u2212 1\nn\n)k \u03b1\u03c4\nn2\n\u2264 t\n(\n1 + (\u03b1\u2212 1)+\nn\n)t \u03b1\u03c4\nn2\n\u2264 exp\n(\n(\u03b1\u2212 1)+ n t\n)\n\u03b1\u03c4t\nn2 ,\nwhere (x)+ denotes max(0, x). It follows by the union bound that, for any set of variables I with |I| \u2264 \u03c9, the probability that the coupling is unequal in at least one of those variables is\nP (\u2203i \u2208 I, Xi,t 6= Yi,t) \u2264 \u03c9max i P (Xi,t 6= Yi,t)\n\u2264 exp\n(\n(\u03b1\u2212 1)+ n t\n)\n\u03c9\u03b1\u03c4t\nn2 .\nSince this inequality holds for any set of variable I with |I| \u2264 \u03c9, it follows that\nmax I \u2286{1,...,n}, |I|\u2264\u03c9 P (\u2203i \u2208 I, Xi,t 6= Yi,t) \u2264 \u03c9max i P (Xi,t 6= Yi,t)\n\u2264 exp\n(\n(\u03b1\u2212 1)+ n t\n)\n\u03c9\u03b1\u03c4t\nn2 .\nWe can proceed to apply Lemma 1, which lets us conclude that\n\u2016\u00b5t \u2212 \u03bdt\u2016 SV(\u03c9) \u2264 \u03c9max i P (Xi,t 6= Yi,t)\n\u2264 exp\n(\n(\u03b1\u2212 1)+ n t\n)\n\u03c9\u03b1\u03c4t\nn2\nwhere \u00b5t and \u03bdt are the distributions of the HOGWILD! and sequential Gibbs sampling chains, respectively, starting in state \u00b50. Next, since \u03bdt has the dynamics of the sequential Gibbs sampling chain, since t\u0304SM\u2212seq(\u03c9)(\u01eb) is an upper bound for the sparse estimation time, it follows that for any \u01eb, if\nt \u2265 t\u0304SM\u2212seq(\u03c9)(\u01eb),\nthen \u2016\u03bdt \u2212 \u03c0\u2016SV(\u03c9) \u2264 \u01eb.\nSince t\u0304SM\u2212seq(\u03c9)(\u01eb) is a decreasing function of \u01eb, it must have an inverse function. Furthermore, since it is convex, its inverse function must also be convex. Therefore, we can also write the above expression in terms of the inverse function; for any t,\n\u2016\u03bdt \u2212 \u03c0\u2016SV(\u03c9) \u2264 t\u0304 \u22121 SM\u2212seq(\u03c9)(t).\nTherefore, by the triangle inequality, for any t,\n\u2016\u00b5t \u2212 \u03c0\u2016 SV(\u03c9) \u2264 \u2016\u00b5t \u2212 \u03bdt\u2016 SV(\u03c9) + \u2016\u03bdt \u2212 \u03c0\u2016 SV(\u03c9)\n\u2264 \u03c9\u03b1\u03c4t\nn2 exp\n(\n(\u03b1\u2212 1)+ n t\n)\n+ t\u0304\u22121SM\u2212seq(\u03c9)(t).\nNow, for any particular \u01eb, let t0 = t\u0304SM\u2212seq(\u03c9)(\u01eb),\nand let t1 = t\u0304SM\u2212seq(\u03c9) ( \u01eb\n2\n)\n.\nFurther define\nR = \u03c9\u03b1\u03c4t1 n2 exp\n(\n(\u03b1\u2212 1)+ n t1\n)\n.\nTherefore, for any t0 \u2264 t \u2264 t1, \u2016\u00b5t \u2212 \u03c0\u2016 SV(\u03c9) \u2264 R+ t\u0304 \u22121 SM\u2212seq(\u03c9)(t).\nBy convexity of t\u0304\u22121SM\u2212seq(\u03c9), we can bound this expression over the interval t0 \u2264 t \u2264 t1 with\n\u2016\u00b5t \u2212 \u03c0\u2016 SV(\u03c9) \u2264 R+ t1 \u2212 t\nt1 \u2212 t0 \u00b7 \u01eb+ t\u2212 t0 t1 \u2212 t0 \u00b7 \u01eb 2 ,\nand so, if we want this to be less than \u01eb, it suffices to choose t such that\n\u01eb = R+ t1 \u2212 t\nt1 \u2212 t0 \u00b7 \u01eb + t\u2212 t0 t1 \u2212 t0 \u00b7 \u01eb 2\nwhich will occur when\nt = t0 + 2R(t1 \u2212 t0)\n\u01eb .\nNow, applying the definition\nc = 1\nn t\u0304SM\u2212seq(\u03c9)\n( \u01eb\n2\n) = t1 n\nlets us equivalently write R as\nR = \u03c9\u03b1\u03c4c\nn exp\n(\n(\u03b1\u2212 1)+ n t1\n)\n.\nRecall that as a condition for the theorem, we assumed that\n\u01eb \u2265 2\u03c9\u03b1\u03c4c\nn exp\n(\n(\u03b1\u2212 1)+ n t1\n)\n.\nIt follows from this and our expression for R that\nR \u2264 \u01eb\n2 .\nTherefore this assignment of t will satisfy the previous constraint that t0 \u2264 t \u2264 t1, and so for this assignment of t, and for any initial distribution \u00b50, it holds that\n\u2016\u00b5t \u2212 \u03c0\u2016 SV(\u03c9) \u2264 \u01eb.\nTherefore, by the definition of sparse estimation time, the sparse estimation time of the HOGWILD! chain will be\ntSE\u2212hog(\u03c9)(\u01eb) \u2264 t,\nfor this assignment of t. Now, recall that above we assigned\nt = t0 + 2R(t1 \u2212 t0)\n\u01eb .\nUnder this condition, we can bound this whole error term as\n2R(t1 \u2212 t0)\n\u01eb \u2264 2\u03c9\u03b1\u03c4t21 n2\u01eb exp\n(\n(\u03b1\u2212 1)+ n t1\n)\n.\nCombining this with the definitions of t0 and c lets us state that\nt \u2264 t\u0304SM\u2212seq(\u03c9)(\u01eb) + 2\u03c9\u03b1\u03c4c2\n\u01eb exp ((\u03b1\u2212 1)+c) .\nTaking the ceiling implies that, when\nt =\n\u2308\nt\u0304SM\u2212seq(\u03c9)(\u01eb) + 2\u03c9\u03b1\u03c4c2\n\u01eb exp ((\u03b1\u2212 1)+c)\n\u2309\n,\nfor any initial distribution \u00b50, \u2016\u00b5t \u2212 \u03c0\u2016SV(\u03c9) \u2264 \u01eb.\nTherefore, by the definition of sparse estimation time,\ntSE\u2212hog(\u01eb) \u2264\n\u2308\nt\u0304SM\u2212seq(\u03c9)(\u01eb) + 2\u03c9\u03b1\u03c4c2\n\u01eb exp ((\u03b1\u2212 1)+c)\n\u2309\n.\nThis proves the theorem.\nNext, we prove the theorem that bounds the sparse estimation time of sequential Gibbs for distributions that satisfy Dobrushin\u2019s condition.\nProof of Theorem 2. We start by using the result of Lemma 3. This result states that, for any initial distributions (X0, Y0), there exists a coupling (Xt, Yt) of the sequential Gibbs sampling chains starting at distributions X0 and Y0, respectively, such that for any variable i and any time t,\nP (Xi,t 6= Yi,t) \u2264 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n.\nIt follows by the union bound that, for any set of variables I with |I| \u2264 \u03c9, the probability that the coupling is unequal in at least one of those variables is\nP (\u2203i \u2208 I, Xi,t 6= Yi,t) \u2264 \u03c9 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n.\nSince this inequality holds for any set of variable I with |I| \u2264 \u03c9, it follows that\nmax I \u2286{1,...,n}, |I|\u2264\u03c9 P (\u2203i \u2208 I, Xi,t 6= Yi,t) \u2264 \u03c9 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n.\nWe can proceed to apply Lemma 1, which lets us conclude that\n\u2016\u00b5t \u2212 \u03bdt\u2016 SV(\u03c9) \u2264 \u03c9 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n.\nSince this was true for any initial distributions for X0 and Y0, it will hold in particular for Y0 distributed according to \u03c0, the stationary distribution of the chain. In this case, \u03bdt = \u03c0, and so for any initial distribution \u00b50 for X0,\n\u2016\u00b5t \u2212 \u03c0\u2016 SV(\u03c9) \u2264 \u03c9 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n.\nNow, in order for this to be bounded by \u01eb, it suffices to choose t such that\n\u03c9 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n\u2264 \u01eb.\nThis will occur whenever t \u2265 n\n1\u2212 \u03b1 log (\u03c9 \u01eb )\n(here we used the fact that \u03b1 < 1 to do the division). Taking the ceiling, we can conclude that when\nt =\n\u2308\nn 1\u2212 \u03b1 log (\u03c9 \u01eb )\n\u2309\n.\nfor any initial distribution \u00b50, \u2016\u00b5t \u2212 \u03c0\u2016SV(\u03c9) \u2264 \u01eb.\nTherefore, by the definition of sparse estimation time,\ntSE\u2212hog(\u01eb) \u2264\n\u2308\nn 1\u2212 \u03b1 log (\u03c9 \u01eb )\n\u2309\n.\nThis proves the theorem.\nNext, we prove the theorem that bounds the sparse estimation time of HOGWILD! Gibbs for distributions that satisfy Dobrushin\u2019s condition.\nProof of Theorem 3. We start by using the secondary result from Lemma 5\u2014we can safely use this result because we assumed the chain satisfied Dobrushin\u2019s condition (\u03b1 < 1). This result states that we can construct a coupling (Xt, Yt) of the HOGWILD! and sequential chains starting at any initial distributions X0 and Y0 such that at any time t,\nP (Xi,t 6= Yi,t) \u2264 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n+ \u03b1\u03c4\n(1\u2212 \u03b1)n .\nIt follows by the union bound that, for any set of variables I with |I| \u2264 \u03c9, the probability that the coupling is unequal in at least one of those variables is\nP (\u2203i \u2208 I, Xi,t 6= Yi,t) \u2264 \u03c9 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n+ \u03c9\u03b1\u03c4\n(1\u2212 \u03b1)n\nSince this inequality holds for any set of variable I with |I| \u2264 \u03c9, it follows that\nmax I \u2286{1,...,n}, |I|\u2264\u03c9 P (\u2203i \u2208 I, Xi,t 6= Yi,t) \u2264 \u03c9 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n+ \u03c9\u03b1\u03c4\n(1\u2212 \u03b1)n .\nWe can proceed to apply Lemma 1, which lets us conclude that\n\u2016\u00b5t \u2212 \u03bdt\u2016 SV(\u03c9) \u2264 \u03c9 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n+ \u03c9\u03b1\u03c4\n(1 \u2212 \u03b1)n .\nTo bound the sparse estimation time, notice that for any fixed \u01eb (independent of n), in order to achieve\n\u2016\u00b5t \u2212 \u03c0\u2016SV(\u03c9) \u2264 \u01eb,\nit suffices to choose any t such that\n\u03c9 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n\u2264 \u01eb\u2212 \u03c9\u03b1\u03c4\n(1\u2212 \u03b1)n .\nThis will occur when 1\u2212 \u03b1\nn t \u2265 log\n(\u03c9\n\u01eb\n)\n\u2212 log\n(\n1\u2212 \u03c9\u03b1\u03c4\n(1\u2212 \u03b1)n\u01eb\n)\n.\nNext, recall that we assumed that\n\u01eb \u2265 2\u03c9\u03b1\u03c4\n(1 \u2212 \u03b1)n ;\ntherefore \u01eb is large enough that \u03c9\u03b1\u03c4\n(1\u2212 \u03b1)n\u01eb \u2264\n1 2 .\nIt is easy to prove that, for all x \u2264 12 , log(1\u2212 x) \u2265 2x.\nTherefore, under this condition in \u01eb, it suffices to choose t such that\n1\u2212 \u03b1\nn t \u2265 log\n(\u03c9\n\u01eb\n) + 2\u03c9\u03b1\u03c4\n(1\u2212 \u03b1)n\u01eb ;\nthis will occur whenever\nt \u2265 n 1\u2212 \u03b1 log (\u03c9 \u01eb ) + 2\u03c9\u03b1\u03c4 (1\u2212 \u03b1)2\u01eb .\nTaking the ceiling implies that, when\nt =\n\u2308\nn 1\u2212 \u03b1 log (\u03c9 \u01eb ) + 2\u03c9\u03b1\u03c4 (1\u2212 \u03b1)2\u01eb\n\u2309\n,\nfor any initial distribution \u00b50, \u2016\u00b5t \u2212 \u03c0\u2016SV(\u03c9) \u2264 \u01eb.\nTherefore, by the definition of sparse estimation time,\ntSE\u2212hog(\u01eb) \u2264\n\u2308\nn 1\u2212 \u03b1 log (\u03c9 \u01eb ) + 2\u03c9\u03b1\u03c4 (1\u2212 \u03b1)2\u01eb\n\u2309\n.\nThis proves the theorem.\nA.3 Proofs of Mixing Time Results\nProof of Statement 1. We start out by proving that the model mixes rapidly in the sequential case. First, we assume that we select M1 large enough that, even for potentially exponential run times, the dynamics of the chain are indistinguishable from the chain with M1 = \u221e. In particular, this alternate chain will have the following properties:\n\u2022 The dynamics of the X part of the chain do not depend in any way on the value of Y .\n\u2022 If at any point, \u2223 \u22231 TX \u2223\n\u2223 > 1, whenever we sample an X variable, we will re-sample it if possible to decrease the value of \u2223 \u22231 TX \u2223 \u2223 with probability 1.\n\u2022 As long as \u2223 \u22231 TX \u2223\n\u2223 = 1 at some point in time, this will remain true, and the dynamics of the X part of the chain will be those of the chain described in Lemma 7.\nWe assume that we choose M1 large enough that these properties hold over all time windows discussed in this proof with high probability.\nNow, by the coupon collector\u2019s problem, after O(N logN) timesteps, we have sampled all the variables with high probability. If we have sampled all the variables with high probability, then we will certainly have \u2223 \u22231 TX \u2223\n\u2223 = 1 with high probability.\nOnce we have \u2223 \u22231 TX \u2223\n\u2223 = 1, Lemma 7 ensures that, after O(N logN) additional timesteps, the X part of the chain will be close to its stationary distribution.\nMeanwhile, while \u2223 \u22231 TX \u2223\n\u2223 = 1, the dynamics of the Y part of the chain are exactly Gibbs sampling over the model with energy\n\u03c6Y (Y ) = \u03b2\nN\n( 1 TY )2 .\nFor any \u03b2 < 1, this is known to mix in O(N logN) time, since it satisfies Dobrushin\u2019s condition. Therefore, after O(N logN) steps after we have \u2223 \u22231 TX \u2223\n\u2223 = 1, the Y part of the chain will also be close to its stationary distribution. Summing up the times for the above events gives us a total mixing time for this chain of\ntmix\u2212seq = O(N logN).\nNext we prove that the model takes a potentially exponential time to mix in the asynchronous case. Assume here that our model of execution has two threads, which always either sample two X variables independently and asynchronously, or sample a single Y variable synchronously (i.e. there is never any delay when reading the value of a Y variable). For this execution pattern, we have uniformly that \u03c4i,t \u2264 1. In particular, this has \u03c4 = O(1).\nNow, consider the case where the two threads each choose to sample a variable in X that can be switched. Since at least 14 of the variables are variables in X that can be switched, this will occur with probability at least 1 16 . Given this, they will each independently switch their variable with probability 12 . This means that both variables are switched with probability 14 \u2014 but this would place the system in a state where\n\u2223 \u22231 TX \u2223 \u2223 > 1.\nAt any time when \u2223 \u22231 TX \u2223 \u2223 = 1, this will occur with probability 164 , which implies that whenever we sample Y , the probability that \u2223 \u22231 TX \u2223\n\u2223 > 1 is at least 164 . Now, assume without loss of generality that we initialize Y such that 1TY = N . Let \u03c1t denote the value of 1TY at\ntime t. Assuming that we sample a variable Yi with value 1, while \u2223 \u22231 TX \u2223\n\u2223 = 1, the probability that it will be switched will be\nP (value switched) = exp\n( \u03b2n\u22121(\u03c1t \u2212 1) 2 )\nexp (\u03b2n\u22121(\u03c1t \u2212 1)2) + exp (\u03b2n\u22121(\u03c1t)2)\n= ( 1 + exp ( \u03b2n\u22121 ( (\u03c1t) 2 \u2212 (\u03c1t \u2212 1)\n2 )))\u22121\n= ( 1 + exp ( \u03b2n\u22121(2\u03c1t \u2212 1) ))\u22121 .\nNote that since \u03c1t \u2264 N at all times, if \u03b2 < 1,\n\u03b2N\u22121(2\u03c1t \u2212 1) \u2264 2.\nWe also can verify that, for any 0 \u2264 x \u2264 2, as a basic property of the exponential function,\n(1 + exp(x)) \u22121 \u2264 1\n2 \u2212\nx 6 .\nTherefore, as long as \u03c1t > 0,\nP (value switched) \u2264 1\n2 \u2212 \u03b2\u03c1t 3n .\nTherefore, as long as \u03c1t > 0, and \u2223 \u22231 TX \u2223 \u2223 = 1,\nE [\u03c1t+1|Ft] \u2265 \u03c1t + 2\n(\nN \u2212 \u03c1t 2N \u2212 1 2 + \u03b2\u03c1t 3N\n)\n= \u03c1t + 2\n(\n\u2212\u03c1t 2N + \u03b2\u03c1t 3N\n)\n= \u03c1t\n(\n1\u2212 3\u2212 2\u03b2\n3N\n)\n.\nOn the other hand, if \u2223 \u22231 TX \u2223\n\u2223 > 1, then we can pick M2 large enough such that with high probability, as long as \u03c1t > 0, all variables Yi are always sampled to be 1. In this case,\nE [\u03c1t+1|Ft] \u2265 \u03c1t + 2\n(\nN \u2212 \u03c1t 2N\n)\n= \u03c1t\n(\n1\u2212 1\nN\n)\n+ 1.\nIn general, since \u2223 \u22231 TX \u2223 \u2223 > 1 with probability at least 164 ,\nE [\u03c1t+1|Ft] \u2265\n(\n1\u2212 1\n64\n)\n\u03c1t\n(\n1\u2212 3\u2212 2\u03b2\n3N\n)\n+ 1\n64\n(\n\u03c1t\n(\n1\u2212 1\nN\n)\n+ 1\n)\n= \u03c1t\n(\n1\u2212\n(\n1\u2212 1\n64\n)\n3\u2212 2\u03b2\n3N \u2212\n1\n64N\n)\n+ 1\n64\n= \u03c1t\n(\n1\u2212 1\nN +\n(\n1\u2212 1\n64\n)\n2\u03b2\n3N\n)\n+ 1\n64\n\u2265 \u03c1t\n(\n1\u2212 1\nN\n)\n+ 1\n64\nThis expression has fixed point\n\u03c1\u2217 = N\n64 .\nSince \u03c1 is written as a sum of independent samples, as long as \u03c1 > 0, the distribution of \u03c1 is going to be exponentially concentrated around its expected value, which we have just shown is at least N64 . It follows that it is exponentially unlikely to ever achieve a value of \u03c1 that is not positive. By the union bound, there is some t = exp(\u2126(N)) such that, after t timesteps, \u03c1t > 0 with high probability.\nBut, the actual probability that \u03c1 > 0 in the stationary distribution is exactly 12 , by symmetry. It follows that the mixing time for the HOGWILD! chain must be greater than t; that is,\ntmix\u2212hog \u2265 exp(\u2126(N)).\nThis finishes our proof of the statement.\nProof of First Part of Theorem 4. If we use the coupling from Lemma 3, then by the result of that lemma,\nP (Xi,t 6= Yi,t) \u2264 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n,\nIt follows by the union bound that\nP (Xt 6= Yt) \u2264 n exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n.\nNow, assume that we initialize X0 with distribution \u00b50, and Y0 with the stationary distribution \u03c0. By Proposition 1, since Xt has distribution \u00b5t and Yt has distribution \u03c0, this is equivalent to saying\n\u2016\u00b5t \u2212 \u03c0\u2016TV \u2264 n exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n.\nTherefore, in order for \u2016\u00b5t \u2212 \u03c0\u2016TV \u2264 \u01eb,\nit suffices to choose t such that\n\u01eb = n exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n.\nThis occurs when t = n\n1\u2212 \u03b1 log (n \u01eb ) ,\nwhich is the desired expression.\nProof of Second Part of Theorem 4. If we use the coupling from Lemma 4, then by the result of that lemma,\nP (Xi,t 6= Yi,t) \u2264 exp\n(\n\u2212 1\u2212 \u03b1\nn+ \u03b1\u03c4\u2217 t\n)\n,\nIt follows by the union bound that\nP (Xt 6= Yt) \u2264 n exp\n(\n\u2212 1\u2212 \u03b1\nn+ \u03b1\u03c4\u2217 t\n)\n.\nNext, recall that we assumed that our HOGWILD!-Gibbs sampler had a stationary distribution; call this distribution \u03c0\u0304. Now, assume that we initialize X0 with distribution \u00b50, and Y0 with the stationary distribution \u03c0\u0304. Since \u03c0\u0304 is stationary under the HOGWILD!-Gibbs sampler, it follows that at all times t, the distribution of Yt is exactly \u03c0\u0304. Therefore, by Proposition 1, since Xt has distribution \u00b5t and Yt has distribution \u03c0\u0304, this is equivalent to saying\n\u2016\u00b5t \u2212 \u03c0\u0304\u2016TV \u2264 n exp\n(\n\u2212 1\u2212 \u03b1\nn+ \u03b1\u03c4\u2217 t\n)\n.\nTherefore, in order for \u2016\u00b5t \u2212 \u03c0\u0304\u2016TV \u2264 \u01eb,\nit suffices to choose t such that\n\u01eb = n exp\n(\n\u2212 1\u2212 \u03b1\nn+ \u03b1\u03c4\u2217 t\n)\n.\nThis occurs when\nt = n+ \u03b1\u03c4\u2217 1\u2212 \u03b1 log (n \u01eb ) ,\nwhich is the desired expression.\nNext, we prove that our experimental strategy provides a valid upper bound on the mixing time.\nProof of Statement 2. Consider the partial ordering of states in this Ising model defined by\nY X \u21c6 \u2200i, Yi \u2264 Xi.\nNext, consider the coupling procedure that, at each time t, chooses a random variable I\u0303t to sample and a random R\u0303t uniformly on [0, 1]. It then computes pt, the marginal probability of sampling the chosen variable as 1, and assigns the variable as\nnew value of XI\u0303t =\n{\n1 if R\u0303t < pt, 0 otherwise .\nThis sampling procedure is equivalent to the one that we use in the experiment, and it will produce a chain that is consistent with the Ising model\u2019s dynamics.\nIf we consider the evolution of two coupled chains X(t) and Y (t) using the same values of I\u0303t and R\u0303t, then from the way that we constructed the coupling, it follows that if\nY (0) X(0),\nthen for any future time t, Y (t) X(t).\nThis is because if Y (t) X(t),\nthen the marginal probability of assigning 1 to any particular variable in X is always no less than the marginal probability of assigning 1 to the same variable in Y .\nTherefore, if we initialize all X(0)i = 1 and all Y (0) i = \u22121, and run the coupling until time Tcoupling, the time at\nwhich Y (Tcoupling) = X(Tcoupling),\nthen by the previous analysis, since for any chain U initialized at any state U (0),\nY (0) U (0) X(0),\nit follows that Y (Tcoupling) U (Tcoupling) X(Tcoupling),\nand so, Y (Tcoupling) = U (Tcoupling) = X(Tcoupling).\nSince this was true for any initial value of U , it follows that Tcoupling is a coupling time for any two initial values of the chain. Therefore, by Corollary 5.3 from Levin et al. (2009),\nmax \u00b50 \u2016\u00b5t \u2212 \u03c0\u2016TV \u2264 P (Tcoupling > t) .\nIf we use our definition of t\u0302(\u01eb) where P ( Tcoupling > t\u0302(\u01eb) ) = \u01eb,\nthen this implies that max \u00b50 \u2016\u00b5t\u0302 \u2212 \u03c0\u2016TV \u2264 \u01eb.\nThis in turn implies that t\u0302 is a upper bound on the mixing time, which is the desired result.\nA.4 Proofs of Lemmas\nProof of Lemma 1. For any set of variables I \u2282 {1, . . . , n}, let MI(\u00b5) denote the marginal distribution of the variables in I in the distribution \u00b5. In particular, MI includes all events A that depend only on variables in set I . Next, let X\u0304I and Y\u0304I denote the values of X\u0304 and Y\u0304 on those variables in I; this will be a coupling of the distributions MI(\u00b5) and MI(\u03bd). Therefore, by Proposition 1,\n\u2016MI(\u00b5)\u2212MI(\u03bd)\u2016TV \u03c9 \u2264 P ( X\u0304I 6= Y\u0304I ) = P ( \u2203i \u2208 I, X\u0304i 6= Y\u0304i ) .\nLet \u2126I denote all events in the original probability space \u2126 that depend only on the variables in I . By the definition of total variation distance,\n\u2016MI(\u00b5)\u2212MI(\u03bd)\u2016TV \u03c9 = max A\u2208\u2126I |\u00b5(A) \u2212 \u03bd(A)| .\nTherefore, max A\u2208\u2126I |\u00b5(A)\u2212 \u03bd(A)| \u2264 P ( \u2203i \u2208 I, X\u0304i 6= Y\u0304i ) .\nNow, since this was true for any I , it is certainly true if we maximize both sides over all I with |I| \u2264 \u03c9. Therefore,\nmax I\u2282{1,...,n}, |I|\u2264\u03c9 max A\u2208\u2126I |\u00b5(A)\u2212 \u03bd(A)| \u2264 max I\u2282{1,...,n}, |I|\u2264\u03c9\nP ( \u2203i \u2208 I, X\u0304i 6= Y\u0304i ) .\nThe left side can be reduced to\nmax |A|\u2264\u03c9 |\u00b5(A)\u2212 \u03bd(A)| \u2264 max I\u2282{1,...,n}, |I|\u2264\u03c9\nP ( \u2203i \u2208 I, X\u0304i 6= Y\u0304i )\nand applying the definition of sparse variation distance proves the lemma.\nProof of Lemma 2. Let n be the number of variables in the model. For all k \u2208 {0, 1, . . . , n}, let Zk be a random variable that takes on values in the state space of \u03c0 such that, for all j \u2208 {1, n},\nZk,j =\n{\nXj if j \u2265 k Yj if j < k .\nIn particular, Z0 = X and Zn = Y . Now, by the triangle inequality on the total variation distance,\n\u2016\u03c0i(\u00b7|X)\u2212 \u03c0i(\u00b7|Y )\u2016TV = \u2016\u03c0i(\u00b7|Z0)\u2212 \u03c0i(\u00b7|Zn)\u2016TV\n\u2264\nn \u2211\nk=1\n\u2016\u03c0i(\u00b7|Zk\u22121)\u2212 \u03c0i(\u00b7|Zk)\u2016TV\nNext, we note that Zk\u22121 = Zk if Xk = Yk. Therefore,\n\u2016\u03c0i(\u00b7|X)\u2212 \u03c0i(\u00b7|Y )\u2016TV \u2264\nn \u2211\nk=1\n1Xk 6=Yk \u2016\u03c0i(\u00b7|Zk\u22121)\u2212 \u03c0i(\u00b7|Zk)\u2016TV .\nSince Zk\u22121 and Zk differ only at most at index k, it follows that (Zk\u22121, Zk) \u2208 Bk, and so,\n\u2016\u03c0i(\u00b7|X)\u2212 \u03c0i(\u00b7|Y )\u2016TV \u2264 max i\nn \u2211\nk=1\n1Xk 6=Yk max (U,V )\u2208Bk \u2016\u03c0i(\u00b7|U)\u2212 \u03c0i(\u00b7|V )\u2016TV .\nTaking the expected value of both sides produces\nE [\u2016\u03c0i(\u00b7|X)\u2212 \u03c0i(\u00b7|Y )\u2016TV] \u2264 max i\nn \u2211\nk=1\nE [1Xk 6=Yk ] max (U,V )\u2208Bk \u2016\u03c0i(\u00b7|U)\u2212 \u03c0i(\u00b7|V )\u2016TV\n= max i\nn \u2211\nk=1\nP (Xk 6= Yk) max (U,V )\u2208Bk \u2016\u03c0i(\u00b7|U)\u2212 \u03c0i(\u00b7|V )\u2016TV\n\u2264\n(\nmax k P (Xk 6= Yk)\n)\n(\nmax i\nn \u2211\nk=1\nmax (U,V )\u2208Bk \u2016\u03c0i(\u00b7|U)\u2212 \u03c0i(\u00b7|V )\u2016TV\n)\n.\nFinally, applying the definition of total influence gives us\nE [\u2016\u03c0i(\u00b7|X)\u2212 \u03c0i(\u00b7|Y )\u2016TV] \u2264 \u03b1max k P (Xk 6= Yk) .\nThis proves the lemma.\nProof of Lemma 3. Define the coupling as follows. Start in state (X0, Y0), and at each timestep, choose a single variable i uniformly at random for both chains to sample. Then, sample the selected variable in both chains using the optimal coupling guaranteed by Proposition 1. Iterated over time, this defines a full coupling of the two chains.\nNext, consider the event that Xi,t+1 6= Yi,t+1. This event will occur if one of two things happens: either we didn\u2019t sample variable i at time t and Xi,t 6= Yi,t; or we did sample variable i at time t, and the sampled variables were not equal. Since the probability of sampling variable i is 1\nn , and we know the probability that the sampled variables were\nnot equal from Proposition 1, it follows that, by the law of total probability,\nP (Xi,t+1 6= Yi,t+1) =\n(\n1\u2212 1\nn\n)\nP (Xi,t 6= Yi,t) + 1\nn E [\u2016\u03c0i(\u00b7|Xt)\u2212 \u03c0i(\u00b7|Yt)\u2016 TV] ,\nwhere \u03c0i(\u00b7|Xt) denotes the conditional distribution of variable i in \u03c0 given the values of the other variables in Xt. Next, we apply the Lemma 2, which gives us\nP (Xi,t+1 6= Yi,t+1) \u2264\n(\n1\u2212 1\nn\n)\nP (Xi,t 6= Yi,t) + \u03b1\nn max j P (Xj,t 6= Yj,t) .\nMaximizing both sides over i produces\nmax i P (Xi,t+1 6= Yi,t+1) \u2264\n(\n1\u2212 1\nn\n)\nmax i\nP (Xi,t 6= Yi,t) + \u03b1\nn max j P (Xj,t 6= Yj,t)\n=\n(\n1\u2212 1\nn +\n\u03b1\nn\n)\nmax i P (Xi,t 6= Yi,t) .\nApplying this inequality recursively, and noting that maxi P (Xi,0 6= Yi,0) \u2264 1, we get\nmax i P (Xi,t 6= Yi,t) \u2264\n(\n1\u2212 1\u2212 \u03b1\nn\n)t\n\u2264 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n.\nThis gives us the desired result.\nProof of Lemma 4. Define the coupling as follows. Start in state (X0, Y0), and at each timestep, choose a single variable i uniformly at random for both chains to sample. Similarly, choose the HOGWILD! delays \u03c4\u0303i,t to also be the same between the two chains. At time t, let U\u0303t denote the state that would be read by chain X\u2019s sampler based on the delays, and similarly let V\u0303t denote the state that would be read by chain Y \u2019s sampler. That is,\nU\u0303i,t = Xi,t\u2212\u03c4\u0303i,t ,\nand similarly, V\u0303i,t = Yi,t\u2212\u03c4\u0303i,t .\nAs in the sequential case, we sample the selected variable in both chains using the optimal coupling guaranteed by Proposition 1. Iterated over time, this defines a full coupling of the two chains.\nWe follow the same argument as in the sequential case. First, consider the event that Xi,t+1 6= Yi,t+1. This event will occur if one of two things happens: either we didn\u2019t sample variable i at time t and Xi,t 6= Yi,t; or we did sample variable i at time t, and the sampled variables were not equal. Since the probability of sampling variable i is 1\nn , and\nwe know the probability that the sampled variables were not equal from Proposition 1, it follows that, by the law of total probability,\nP (Xi,t+1 6= Yi,t+1) =\n(\n1\u2212 1\nn\n)\nP (Xi,t 6= Yi,t) + 1\nn E\n[\u2225\n\u2225 \u2225 \u03c0i(\u00b7|U\u0303t)\u2212 \u03c0i(\u00b7|V\u0303t)\n\u2225 \u2225 \u2225 TV ] ,\nwhere \u03c0i(\u00b7|Xt) denotes the conditional distribution of variable i in \u03c0 given the values of the other variables in Xt. Next, we apply the Lemma 2, which gives us\nP (Xi,t+1 6= Yi,t+1) \u2264\n(\n1\u2212 1\nn\n)\nP (Xi,t 6= Yi,t) + \u03b1\nn max j P (Uj,t 6= Vj,t)\n=\n(\n1\u2212 1\nn\n)\nP (Xi,t 6= Yi,t) + \u03b1\nn max j\n\u221e \u2211\nk=0\nP (\u03c4\u0303j,t = k)P (Xj,t\u2212k 6= Yj,t\u2212k) .\nNow, if we let \u03c6t = max\ni P (Xi,t 6= Yi,t) ,\nthen maximizing the previous expression over i implies that\n\u03c6t+1 \u2264\n(\n1\u2212 1\nn\n)\n\u03c6t + \u03b1\nn max j\n\u221e \u2211\nk=0\nP (\u03c4\u0303j,t = k)\u03c6t\u2212k.\nNow, for some constant r \u2264 n\u22121, let yt be defined to be the sequence\nyt = exp(\u2212rt).\nThen, notice that (\n1\u2212 1\nn\n)\nyt + \u03b1\nn max j\n\u221e \u2211\nk =0\nP (\u03c4\u0303j,t = k) yt\u2212k =\n(\n1\u2212 1\nn\n)\nexp(\u2212rt) + \u03b1\nn max j\n\u221e \u2211\nk=0\nP (\u03c4\u0303j,t = k) exp(\u2212rt+ rk)\n= exp(\u2212rt)\n(\n(\n1\u2212 1\nn\n)\n+ \u03b1\nn max j\n\u221e \u2211\nk=0\nP (\u03c4\u0303j,t = k) exp(rk)\n)\n= exp(\u2212rt)\n((\n1\u2212 1\nn\n)\n+ \u03b1\nn max j E [exp(r\u03c4\u0303j,t)]\n)\n.\nNow, by the convexity of the exponential function, (\n1\u2212 1\nn\n)\nyt + \u03b1\nn max j\n\u221e \u2211\nk =0\nP (\u03c4\u0303j,t = k) yt\u2212k \u2264 exp(\u2212rt)\n((\n1\u2212 1\nn\n)\n+ \u03b1\nn max j\n(\n1 + rnE\n[\nexp\n(\n\u03c4\u0303j,t n\n)\n\u2212 1\n]))\n.\nApplying the constraint that\nE\n[\nexp\n(\n\u03c4\u0303j,t n\n)]\n\u2264 1 + \u03c4\u2217\nn ,\nwe can reduce this to (\n1\u2212 1\nn\n)\nyt + \u03b1\nn max j\n\u221e \u2211\nk =0\nP (\u03c4\u0303j,t = k) yt\u2212k \u2264 exp(\u2212rt)\n((\n1\u2212 1\nn\n)\n+ \u03b1\nn (1 + r\u03c4\u2217)\n)\n= yt+1 exp(r)\n(\n1\u2212 1\nn +\n\u03b1 n +\nr\u03b1\u03c4\u2217\nn\n)\n\u2264 yt+1 exp(r) exp\n(\n\u2212 1\nn +\n\u03b1 n +\nr\u03b1\u03c4\u2217\nn\n)\n= yt+1 exp\n(\nn+ \u03b1\u03c4\u2217\nn r \u2212\n1\u2212 \u03b1\nn\n)\n.\nNow, we choose r such that the argument to this exponential is zero; that is, we choose\nr = 1\u2212 \u03b1\nn+ \u03b1\u03c4\u2217 .\nNotice that this choice satisfies the earlier assumption that 0 < r \u2264 n\u22121. Using this choice, we can conclude that\nyt+1 \u2265\n(\n1\u2212 1\nn\n)\nyt + \u03b1\nn max j\n\u221e \u2211\nk=0\nP (\u03c4\u0303j,t = k) yt\u2212k.\nTherefore, by Lemma 6,\n\u03c6t \u2264 yt = exp\n(\n\u2212 1\u2212 \u03b1\nn+ \u03b1\u03c4\u2217 t\n)\n.\nThis proves the lemma.\nProof of Lemma 5. Define the coupling as follows. Start in state (X0, Y0), and at each timestep, choose a single variable I\u0303t uniformly at random for both chains to sample. Then, choose the delays \u03c4\u0303i,t for the HOGWILD! chain Xt. At time t, let U\u0303t denote the state that would be read by chain X\u2019s sampler based on the delays. That is,\nU\u0303i,t = Xi,t\u2212\u03c4\u0303i,t .\nAs done previously, we sample the selected variable I\u0303t in both chains using the optimal coupling guaranteed by Proposition 1. Iterated over time, this defines a full coupling of the two chains.\nWe follow a similar argument as in the above lemmas used to bound the mixing time. First, consider the event that Xi,t+1 6= Yi,t+1. This event will occur if one of two things happens: either we didn\u2019t sample variable i at time t and Xi,t 6= Yi,t; or we did sample variable i at time t, and the sampled variables were not equal. Since the probability of\nsampling variable i is 1 n , and we know the probability that the sampled variables were not equal from Proposition 1, it follows that, by the law of total probability,\nP (Xi,t+1 6= Yi,t+1) =\n(\n1\u2212 1\nn\n)\nP (Xi,t 6= Yi,t) + 1\nn E\n[ \u2225\n\u2225 \u2225 \u03c0i(\u00b7|U\u0303t)\u2212 \u03c0i(\u00b7|Y\u0303t)\n\u2225 \u2225 \u2225TV ] ,\nwhere \u03c0i(\u00b7|Xt) denotes the conditional distribution of variable i in \u03c0 given the values of the other variables in Xt. Next, we apply the Lemma 2, which gives us\nP (Xi,t+1 6= Yi,t+1) \u2264\n(\n1\u2212 1\nn\n)\nP (Xi,t 6= Yi,t) + \u03b1\nn max j P (Uj,t 6= Yj,t)\n=\n(\n1\u2212 1\nn\n)\nP (Xi,t 6= Yi,t) + \u03b1\nn max j\n\u221e \u2211\nk=0\nP (\u03c4\u0303j,t = k)P (Xj,t\u2212k 6= Yj,t) .\nIn order to evaluate this, we notice that the event Xj,t\u2212k 6= Yj,t can happen only if either Xj,t 6= Yj,t or at some time s, where t\u2212 k \u2264 s < t, we sampled variable j (that is, I\u0303s = j). Therefore, by the union bound,\nP (Xj,t\u2212k 6= Yj,t) \u2264 P (Xj,t 6= Yj,t) +\nt\u22121 \u2211\ns=t\u2212k\nP ( I\u0303s = j ) .\nSince the probability of sampling variable j at any time is always just 1 n , we can reduce this to\nP (Xj,t\u2212k 6= Yj,t) \u2264 P (Xj,t 6= Yj,t) + k\nn .\nSubstituting this into our previous expression produces\nP (Xi,t+1 6= Yi,t+1) \u2264\n(\n1\u2212 1\nn\n)\nP (Xi,t 6= Yi,t) + \u03b1\nn max j\n\u221e \u2211\nk=0\nP (\u03c4\u0303j,t = k)\n(\nP (Xj,t 6= Yj,t) + k\nn\n)\n=\n(\n1\u2212 1\u2212 \u03b1\nn\n)\nP (Xi,t 6= Yi,t) + \u03b1\nn2 max j E [\u03c4\u0303j,t]\n\u2264\n(\n1\u2212 1\u2212 \u03b1\nn\n)\nP (Xi,t 6= Yi,t) + \u03b1\u03c4\nn2 .\nNow, if we let \u03c6t = max\ni P (Xi,t 6= Yi,t) ,\nthen maximizing the previous expression over i implies that\n\u03c6t+1 \u2264\n(\n1\u2212 1\u2212 \u03b1\nn\n)\n\u03c6t + \u03b1\u03c4\nn2 .\nSubtracting from both sides to identify the fixed point gives us\n\u03c6t+1 \u2212 \u03b1\u03c4\n(1\u2212 \u03b1)n \u2264\n(\n1\u2212 1\u2212 \u03b1\nn\n)\n\u03c6t + \u03b1\u03c4\nn2 \u2212\n\u03b1\u03c4\n(1 \u2212 \u03b1)n\n=\n(\n1\u2212 1\u2212 \u03b1\nn\n)(\n\u03c6t \u2212 \u03b1\u03c4\n(1\u2212 \u03b1)n\n)\n.\nApplying this inequality recursively lets us conclude that\n\u03c6t \u2212 \u03b1\u03c4\n(1 \u2212 \u03b1)n \u2264\n(\n1\u2212 1\u2212 \u03b1\nn\n)t (\n\u03c60 \u2212 \u03b1\u03c4\n(1\u2212 \u03b1)n\n)\n\u2264 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n,\nand so,\n\u03c6t \u2264 exp\n(\n\u2212 1\u2212 \u03b1\nn t\n)\n+ \u03b1\u03c4\n(1 \u2212 \u03b1)n .\nThis is the desired expression.\nProof of Lemma 6. We will approach this by induction. The base case holds by assumption, since x0 = y0. For the inductive case, if xt \u2264 yt for all t \u2264 T , then\nxT+1 \u2264 fT (xT , xT\u22121, . . . , x0).\nBy monotonicity and the inductive hypothesis,\nxT+1 \u2264 fT (yT , yT\u22121, . . . , y0),\nand therefore, xT+1 \u2264 yT+1.\nApplying induction to this proves the lemma.\nProof of Lemma 7. Assume that, as we run the chain described in this lemma, we also assign a \u201ccolor\u201d to each of the variables. All variables with an initial value of 1 start out as black, and all other variables start out as white. Let Bt denote the set of variables that are colored black at any time t, and let St denote the sum of all variables that are colored black at that time. We re-color variables according to the following procedure:\n1. Whenever we change a variable\u2019s value from \u22121 to 1, if it is colored white, color it black.\n2. Whenever we change a variable\u2019s value from \u22121 to 1, if it is already colored black, choose a random variable that had value \u22121 at time t, and if it is white, color it black.\nNote that as a consequence of this result, a variable that is colored white always has value \u22121. We will prove the following sub-result by induction on t: given a time t, set Bt, and sum St, the values of the variables in Bt are uniformly distributed over the set of possible assignments that are consistent with St. (Base Case.) The base case is straightforward. Since B0 is just the set of variables that have value 1, there is only one possible assignment that is consistent with S0: the assignment in which all variables take on the value 1. Since this assignment actually occurs with probability 1, the statement holds.\n(Inductive Case.) Assume that the sub-result is true at time t. The sampler chooses a new variable i to sample. One of the following things will happen:\n\u2022 We don\u2019t re-color any variables, or change the values of any variables in Bt. In this case, Bt+1 = Bt and St+1 = St. Since there is no change to B or S, all consistent assignments of the black variables are still equiprobable.\n\u2022 We don\u2019t re-color any variables, but we do change the value of some variable in Bt (by changing its value from 1 to \u22121). Since we sampled the variable i at random, all consistent assignments of the black variables will remain equiprobable.\n\u2022 We re-color some variable j black. There are two events that can cause this:\n\u2013 We could have sampled variable j (that is i = j), and changed its value from \u22121 to 1. This will happen with probability\n1 N \u00b7 1 2 = 1 2N\n\u2013 We could have sampled a variable i 6= j that is already colored black, changed its value from \u22121 to 1, and then chosen variable j at random to color black. Since, at time t, the number of variables with value \u22121 must be\nN + 1\n2 ,\n(since we are about to change a value from \u22121 to 1), this will happen with probability\nu N \u00b7 1 2 \u00b7 2 N + 1 =\nu\nN(N + 1)\nwhere u is the number of black-colored variables that have value \u22121 at time t.\nFrom this analysis, it follows that, given that we re-colored some variable j black, it will have value \u22121 with probability\nP (variable j has value \u22121) = u N(N+1)\n1 2N + u N(N+1)\n= u\nu+ N+12 .\nIn particular, at time t, the number of variables that are in Bt is\nN \u2212 1\n2 + u,\nsince all variables with value 1 are in Bt, and Bt is stipulated to contain u additional variables with value \u22121. It follows that at time t+ 1, the number of variables that are in Bt is\nN + 1\n2 + u,\nand there will still be u variables in Bt+1 with value \u22121. Therefore, the fraction of variables in Bt+1 that have value \u22121 will be\nu\nu+ N+12 .\nNote that this is exactly equal to the probability that variable j will have value \u22121. Combining this with the inductive hypothesis shows that the consistent states will all remain equiprobable in this case.\nSince the consistent states remain equiprobable in all of the possible cases, it follows from the law of total probability that the consistent states are equiprobable in all cases. This shows that the sub-result holds in the inductive case.\nWe have now showed that given a time t, set Bt, and sum St, the values of the variables in Bt are uniformly distributed over the set of possible assignments that are consistent with St. This implies that if T1 is the first time at which the set Bt contains all variables, the value of XT is are uniformly distributed over all possible states with 1 TX = 1.\nNow, we performed this construction for a particular polarity of swaps (i.e. focusing on switches from \u22121 to 1), but by symmetry we could just as easily have used the same construction with the signs of all the variables reversed. If we let T\u22121 be the first time at which the set Bt contains all variables using this reverse-polarity construction, then the value of XT is uniformly distributed over all possible states with 1TX = \u22121.\nLet T \u2217 be a random variable that is T1 with probability 12 and T\u22121 with probability 1 2 . It follows that at time T \u2217, the distribution of XT\u2217 will be \u03c0. Therefore, T \u2217 is a strong stationary time for this chain. By the properties of strong stationary times,\ntmix \u2264 4E [T \u2217] .\nTo bound the mixing time, we start by noticing that\nE [T \u2217] = 1\n2 E [T1] +\n1 2 E [T\u22121] = E [T1] .\nIf we let T\u0304 be the first time at which each variable has been set to 1 at least once, then\nT1 \u2264 T\u0304 .\nNow, if we sample a variable, the probability that we will set it to 1 is (roughly) 14 . It follows from the coupon collector\u2019s problem bound that the expected amount of time required to set all variables to 1 at least once is\nE [ T\u0304 ] = O(n log n).\nCombining this with the previous inequalities lets us conclude that\ntmix = O(n logn),\nwhich proves the lemma.\nSecondary Literature\nDiaconis, Persi. Group representations in probability and statistics. Lecture Notes-Monograph Series, 11:i\u2013192, 1988.\nDiaconis, Persi and Shahshahani, Mehrdad. Generating a random permutation with random transpositions. Probability Theory and Related Fields, 57(2):159\u2013179, 1981.\nLevin, David Asher, Peres, Yuval, and Wilmer, Elizabeth Lee. Markov chains and mixing times. American Mathematical Soc., 2009."}], "references": [{"title": "Taming the wild: A unified analysis of HOGWILD!-style algorithms", "author": ["De Sa", "Christopher", "Zhang", "Ce", "Olukotun", "Kunle", "R\u00e9"], "venue": "In NIPS. NIPS Foundation,", "citeRegEx": "Sa et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sa et al\\.", "year": 2015}, {"title": "Rapidly mixing gibbs sampling for a class of factor graphs using hierarchy width", "author": ["De Sa", "Christopher M", "Zhang", "Ce", "Olukotun", "Kunle", "R\u00e9", "Christopher"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Sa et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sa et al\\.", "year": 2015}, {"title": "Central limit theorem for nonstationary markov chains", "author": ["Dobrushin", "RL"], "venue": "i. Theory of Probability & Its Applications,", "citeRegEx": "Dobrushin and RL.,? \\Q1956\\E", "shortCiteRegEx": "Dobrushin and RL.", "year": 1956}, {"title": "Dobrushin conditions and systematic scan", "author": ["Dyer", "Martin", "Goldberg", "Leslie Ann", "Jerrum", "Mark"], "venue": "In in Proc. 10th International Workshop on Randomization and Computation, Lecture Notes in Computer Science", "citeRegEx": "Dyer et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dyer et al\\.", "year": 2006}, {"title": "Parallel gibbs sampling: From colored fields to thin junction trees", "author": ["Gonzalez", "Joseph", "Low", "Yucheng", "Gretton", "Arthur", "Guestrin", "Carlos"], "venue": "In AISTATS, pp", "citeRegEx": "Gonzalez et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gonzalez et al\\.", "year": 2011}, {"title": "Sampling from probabilistic submodular models", "author": ["Gotovos", "Alkis", "Hassani", "Hamed", "Krause", "Andreas"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Gotovos et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gotovos et al\\.", "year": 2015}, {"title": "Rapidly mixing markov chains: A comparison of techniques", "author": ["Guruswami", "Venkatesan"], "venue": null, "citeRegEx": "Guruswami and Venkatesan.,? \\Q2000\\E", "shortCiteRegEx": "Guruswami and Venkatesan.", "year": 2000}, {"title": "A simple condition implying rapid mixing of single-site dynamics on spin systems", "author": ["Hayes", "Thomas P"], "venue": "In Foundations of Computer Science,", "citeRegEx": "Hayes and P.,? \\Q2006\\E", "shortCiteRegEx": "Hayes and P.", "year": 2006}, {"title": "Beitrag zur theorie des ferromagnetismus", "author": ["Ising", "Ernst"], "venue": "Zeitschrift fu\u0308r Physik A Hadrons and Nuclei,", "citeRegEx": "Ising and Ernst.,? \\Q1925\\E", "shortCiteRegEx": "Ising and Ernst.", "year": 1925}, {"title": "Analyzing hogwild parallel gaussian gibbs sampling", "author": ["Johnson", "Matthew", "Saunderson", "James", "Willsky", "Alan"], "venue": "In NIPS, pp", "citeRegEx": "Johnson et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2013}, {"title": "Probabilistic graphical models: principles and techniques", "author": ["Koller", "Daphne", "Friedman", "Nir"], "venue": "MIT press,", "citeRegEx": "Koller et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Koller et al\\.", "year": 2009}, {"title": "Markov chains and mixing times", "author": ["Levin", "David Asher", "Peres", "Yuval", "Wilmer", "Elizabeth Lee"], "venue": "American Mathematical Soc.,", "citeRegEx": "Levin et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Levin et al\\.", "year": 2009}, {"title": "Asynchronous stochastic coordinate descent: Parallelism and convergence properties. SIOPT", "author": ["Liu", "Ji", "Wright", "Stephen J"], "venue": null, "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "An asynchronous parallel stochastic coordinate descent algorithm", "author": ["Liu", "Ji", "Wright", "Stephen J", "R\u00e9", "Christopher", "Bittorf", "Victor", "Sridhar", "Srikrishna"], "venue": null, "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "The BUGS project: evolution, critique and future directions", "author": ["Lunn", "David", "Spiegelhalter", "Thomas", "Andrew", "Best", "Nicky"], "venue": "Statistics in medicine,", "citeRegEx": "Lunn et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lunn et al\\.", "year": 2009}, {"title": "Perturbed iterate analysis for asynchronous stochastic optimization", "author": ["Mania", "Horia", "Pan", "Xinghao", "Papailiopoulos", "Dimitris", "Recht", "Benjamin", "Ramchandran", "Kannan", "Jordan", "Michael I"], "venue": "arXiv preprint arXiv:1507.06970,", "citeRegEx": "Mania et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mania et al\\.", "year": 2015}, {"title": "Factorie: Probabilistic programming via imperatively defined factor graphs", "author": ["McCallum", "Andrew", "Schultz", "Karl", "Singh", "Sameer"], "venue": "In NIPS, pp", "citeRegEx": "McCallum et al\\.,? \\Q2009\\E", "shortCiteRegEx": "McCallum et al\\.", "year": 2009}, {"title": "Frogwild!: Fast pagerank approximations on graph engines", "author": ["Mitliagkas", "Ioannis", "Borokhovich", "Michael", "Dimakis", "Alexandros G", "Caramanis", "Constantine"], "venue": null, "citeRegEx": "Mitliagkas et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mitliagkas et al\\.", "year": 2015}, {"title": "Simple, correct parallelization for blocked gibbs sampling", "author": ["Neubig", "Graham"], "venue": "Technical report, Nara Institute of Science and Technology,", "citeRegEx": "Neubig and Graham.,? \\Q2014\\E", "shortCiteRegEx": "Neubig and Graham.", "year": 2014}, {"title": "Distributed inference for latent dirichlet allocation", "author": ["Newman", "David", "Smyth", "Padhraic", "Welling", "Max", "Asuncion", "Arthur U"], "venue": "In NIPS, pp", "citeRegEx": "Newman et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Newman et al\\.", "year": 2007}, {"title": "Distributed gibbs: A memory-bounded sampling-based dcop algorithm", "author": ["Nguyen", "Duc Thien", "Yeoh", "William", "Lau", "Hoong Chuin"], "venue": "In Proceedings of the 2013 international conference on Autonomous agents and multi-agent systems,", "citeRegEx": "Nguyen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2013}, {"title": "Hogwild: A lock-free approach to parallelizing stochastic gradient descent", "author": ["Niu", "Feng", "Recht", "Benjamin", "Re", "Christopher", "Wright", "Stephen"], "venue": "In NIPS, pp", "citeRegEx": "Niu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Niu et al\\.", "year": 2011}, {"title": "Dogwild!\u2013Distributed Hogwild for CPU & GPU", "author": ["Noel", "Cyprien", "Osindero", "Simon"], "venue": null, "citeRegEx": "Noel et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Noel et al\\.", "year": 2014}, {"title": "Exact sampling with coupled markov chains and applications to statistical mechanics", "author": ["Propp", "James Gary", "Wilson", "David Bruce"], "venue": "Random Structures & Algorithms,", "citeRegEx": "Propp et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Propp et al\\.", "year": 1996}, {"title": "Incremental knowledge base construction using deepdive", "author": ["Shin", "Jaeho", "Wu", "Sen", "Wang", "Feiran", "De Sa", "Christopher", "Zhang", "Ce", "R\u00e9"], "venue": null, "citeRegEx": "Shin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shin et al\\.", "year": 2015}, {"title": "An architecture for parallel topic models", "author": ["Smola", "Alexander", "Narayanamurthy", "Shravan"], "venue": null, "citeRegEx": "Smola et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Smola et al\\.", "year": 2010}, {"title": "Asynchronous distributed learning of topic models", "author": ["Smyth", "Padhraic", "Welling", "Max", "Asuncion", "Arthur U"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Smyth et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Smyth et al\\.", "year": 2009}, {"title": "The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software", "author": ["Sutter", "Herb"], "venue": "Dr. Dobb\u2019s Journal,", "citeRegEx": "Sutter and Herb.,? \\Q2005\\E", "shortCiteRegEx": "Sutter and Herb.", "year": 2005}, {"title": "Asynchronous distributed gibbs sampling", "author": ["Terenin", "Alexander", "Simpson", "Daniel", "Draper", "David"], "venue": "arXiv preprint arXiv:1509.08999,", "citeRegEx": "Terenin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Terenin et al\\.", "year": 2015}, {"title": "Training sparse natural image models with a fast gibbs sampler of an extended state space", "author": ["Theis", "Lucas", "Sohl-dickstein", "Jascha", "Bethge", "Matthias"], "venue": "In NIPS,", "citeRegEx": "Theis et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Theis et al\\.", "year": 2012}, {"title": "Scalable coordinate descent approaches to parallel matrix factorization for recommender systems", "author": ["Yu", "Hsiang-Fu", "Hsieh", "Cho-Jui", "Si", "Dhillon", "Inderjit S"], "venue": "In ICDM,", "citeRegEx": "Yu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2012}, {"title": "DimmWitted: A study of main-memory statistical analytics", "author": ["Zhang", "Ce", "R\u00e9", "Christopher"], "venue": null, "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "This proposition relates the concept of a coupling with the total variation distance between the distributions of two random variables", "author": ["Levin"], "venue": null, "citeRegEx": "Levin,? \\Q2009\\E", "shortCiteRegEx": "Levin", "year": 2009}, {"title": "Group representations in probability and statistics", "author": ["Diaconis", "Persi"], "venue": "Lecture Notes-Monograph Series,", "citeRegEx": "Diaconis and Persi.,? \\Q1988\\E", "shortCiteRegEx": "Diaconis and Persi.", "year": 1988}, {"title": "Generating a random permutation with random transpositions", "author": ["Diaconis", "Persi", "Shahshahani", "Mehrdad"], "venue": "Probability Theory and Related Fields,", "citeRegEx": "Diaconis et al\\.,? \\Q1981\\E", "shortCiteRegEx": "Diaconis et al\\.", "year": 1981}, {"title": "Markov chains and mixing times", "author": ["Levin", "David Asher", "Peres", "Yuval", "Wilmer", "Elizabeth Lee"], "venue": "American Mathematical Soc.,", "citeRegEx": "Levin et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Levin et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 17, "context": "Because of this and other useful properties of Gibbs sampling, many systems use Gibbs sampling to perform inference on big data Newman et al. (2007); Lunn et al.", "startOffset": 128, "endOffset": 149}, {"referenceID": 14, "context": "(2007); Lunn et al. (2009); McCallum et al.", "startOffset": 8, "endOffset": 27}, {"referenceID": 14, "context": "(2007); Lunn et al. (2009); McCallum et al. (2009); Smola & Narayanamurthy (2010); Theis et al.", "startOffset": 8, "endOffset": 51}, {"referenceID": 14, "context": "(2007); Lunn et al. (2009); McCallum et al. (2009); Smola & Narayanamurthy (2010); Theis et al.", "startOffset": 8, "endOffset": 82}, {"referenceID": 14, "context": "(2007); Lunn et al. (2009); McCallum et al. (2009); Smola & Narayanamurthy (2010); Theis et al. (2012); Zhang & R\u00e9 (2014).", "startOffset": 8, "endOffset": 103}, {"referenceID": 14, "context": "(2007); Lunn et al. (2009); McCallum et al. (2009); Smola & Narayanamurthy (2010); Theis et al. (2012); Zhang & R\u00e9 (2014). Since Gibbs sampling is such a ubiquitous algorithm, it is important to try to optimize its execution speed on modern hardware.", "startOffset": 8, "endOffset": 122}, {"referenceID": 14, "context": "(2007); Lunn et al. (2009); McCallum et al. (2009); Smola & Narayanamurthy (2010); Theis et al. (2012); Zhang & R\u00e9 (2014). Since Gibbs sampling is such a ubiquitous algorithm, it is important to try to optimize its execution speed on modern hardware. Unfortunately, while modern computer hardware has been trending towards more parallel architectures Sutter (2005), traditional Gibbs sampling is an inherently sequential algorithm; that is, the outer loop in Algorithm 1 is not embarrassingly parallel.", "startOffset": 8, "endOffset": 365}, {"referenceID": 14, "context": "(2007); Lunn et al. (2009); McCallum et al. (2009); Smola & Narayanamurthy (2010); Theis et al. (2012); Zhang & R\u00e9 (2014). Since Gibbs sampling is such a ubiquitous algorithm, it is important to try to optimize its execution speed on modern hardware. Unfortunately, while modern computer hardware has been trending towards more parallel architectures Sutter (2005), traditional Gibbs sampling is an inherently sequential algorithm; that is, the outer loop in Algorithm 1 is not embarrassingly parallel. Furthermore, for sparse models, very little work happens within each iteration, meaning it is difficult to extract much parallelism from the body of this outer loop. Since traditional Gibbs sampling parallelizes so poorly, it is interesting to study variants of Gibbs sampling that can be parallelized. Several such variants have been proposed, including applications to latent Dirichlet allocation Newman et al. (2007); Smola & Narayanamurthy (2010) and distributed constraint optimization problems Nguyen et al.", "startOffset": 8, "endOffset": 923}, {"referenceID": 14, "context": "(2007); Lunn et al. (2009); McCallum et al. (2009); Smola & Narayanamurthy (2010); Theis et al. (2012); Zhang & R\u00e9 (2014). Since Gibbs sampling is such a ubiquitous algorithm, it is important to try to optimize its execution speed on modern hardware. Unfortunately, while modern computer hardware has been trending towards more parallel architectures Sutter (2005), traditional Gibbs sampling is an inherently sequential algorithm; that is, the outer loop in Algorithm 1 is not embarrassingly parallel. Furthermore, for sparse models, very little work happens within each iteration, meaning it is difficult to extract much parallelism from the body of this outer loop. Since traditional Gibbs sampling parallelizes so poorly, it is interesting to study variants of Gibbs sampling that can be parallelized. Several such variants have been proposed, including applications to latent Dirichlet allocation Newman et al. (2007); Smola & Narayanamurthy (2010) and distributed constraint optimization problems Nguyen et al.", "startOffset": 8, "endOffset": 954}, {"referenceID": 14, "context": "(2007); Lunn et al. (2009); McCallum et al. (2009); Smola & Narayanamurthy (2010); Theis et al. (2012); Zhang & R\u00e9 (2014). Since Gibbs sampling is such a ubiquitous algorithm, it is important to try to optimize its execution speed on modern hardware. Unfortunately, while modern computer hardware has been trending towards more parallel architectures Sutter (2005), traditional Gibbs sampling is an inherently sequential algorithm; that is, the outer loop in Algorithm 1 is not embarrassingly parallel. Furthermore, for sparse models, very little work happens within each iteration, meaning it is difficult to extract much parallelism from the body of this outer loop. Since traditional Gibbs sampling parallelizes so poorly, it is interesting to study variants of Gibbs sampling that can be parallelized. Several such variants have been proposed, including applications to latent Dirichlet allocation Newman et al. (2007); Smola & Narayanamurthy (2010) and distributed constraint optimization problems Nguyen et al. (2013). In one popular variant, multiple threads run the Gibbs sampling update rule in parallel without locks, a strategy called asynchronous or HOGWILD! execution\u2014in this paper, we use these two terms interchangeably.", "startOffset": 8, "endOffset": 1024}, {"referenceID": 7, "context": "But when can we be sure that HOGWILD! Gibbs sampling will produce accurate results? Except for the case of Gaussian random variables Johnson et al. (2013), there is no existing analysis by which we can ensure that asynchronous Gibbs sampling will be appropriate for a particular application.", "startOffset": 133, "endOffset": 155}, {"referenceID": 7, "context": "But when can we be sure that HOGWILD! Gibbs sampling will produce accurate results? Except for the case of Gaussian random variables Johnson et al. (2013), there is no existing analysis by which we can ensure that asynchronous Gibbs sampling will be appropriate for a particular application. Even the problems posed by HOGWILD!-Gibbs are poorly understood, and their solutions more so. As we will see in the following sections, there are two main issues when analyzing asynchronous Gibbs sampling. Firstly, we will show by example that, surprisingly, HOGWILD!-Gibbs can be biased\u2014unlike sequential Gibbs, it does not always produce samples that are arbitrarily close to the target distribution. Secondly, we will show that the mixing time (the time for the chain to become close to its stationary distribution) of asynchronous Gibbs sampling can be at worst exponentially greater than that of the corresponding sequential chain. To address the issue of bias, we need some way to describe the distance between the target distribution \u03c0 and the distribution of the samples produced by HOGWILD!-Gibbs. The standard notion to use here is the total variation distance, but for the task of computing marginal probabilities, it gives an overestimate on the error caused by bias. To better describe the bias, we introduce a new notion of statistical distance, the sparse variation distance. While this relaxed notion of statistical distance is interesting in its own right, its main benefit here is that it more tightly measures the effect of bias on marginal estimation. Our main goal is to identify conditions under which the bias and mixing time of asynchronous Gibbs can be bounded. One parameter that has been used to great effect in the analysis of Gibbs sampling is the total influence \u03b1 of a model. The total influence measures the degree to which the marginal distribution of a variable can depend on the values of the other variables in the model\u2014this parameter has appeared as part of a celebrated line of work on Dobrushin\u2019s condition (\u03b1 < 1), which ensures the rapid mixing of spin statistics systems Dobrushin (1956); Dyer et al.", "startOffset": 133, "endOffset": 2123}, {"referenceID": 3, "context": "The total influence measures the degree to which the marginal distribution of a variable can depend on the values of the other variables in the model\u2014this parameter has appeared as part of a celebrated line of work on Dobrushin\u2019s condition (\u03b1 < 1), which ensures the rapid mixing of spin statistics systems Dobrushin (1956); Dyer et al. (2006); Hayes (2006).", "startOffset": 325, "endOffset": 344}, {"referenceID": 3, "context": "The total influence measures the degree to which the marginal distribution of a variable can depend on the values of the other variables in the model\u2014this parameter has appeared as part of a celebrated line of work on Dobrushin\u2019s condition (\u03b1 < 1), which ensures the rapid mixing of spin statistics systems Dobrushin (1956); Dyer et al. (2006); Hayes (2006). It turns out that we can use this parameter to bound both the bias and mixing time of HOGWILD!-Gibbs, and so we make the following contributions: \u2022 We describe a way to statistically model the asynchronicity in HOGWILD!-Gibbs sampling.", "startOffset": 325, "endOffset": 358}, {"referenceID": 3, "context": "The total influence measures the degree to which the marginal distribution of a variable can depend on the values of the other variables in the model\u2014this parameter has appeared as part of a celebrated line of work on Dobrushin\u2019s condition (\u03b1 < 1), which ensures the rapid mixing of spin statistics systems Dobrushin (1956); Dyer et al. (2006); Hayes (2006). It turns out that we can use this parameter to bound both the bias and mixing time of HOGWILD!-Gibbs, and so we make the following contributions: \u2022 We describe a way to statistically model the asynchronicity in HOGWILD!-Gibbs sampling. \u2022 To bound the bias, we prove that for classes of models with bounded total influence \u03b1 = O(1), if sequential Gibbs sampling achieves small sparse variation distance to \u03c0 in O(n) steps, where n is the number of variables, then HOGWILD!-Gibbs samples achieve the same distance in at most O(1) more steps. \u2022 For models that satisfy Dobrushin\u2019s condition (\u03b1 < 1), we show that the mixing time bounds of sequential and HOGWILD!-Gibbs sampling differ only by a factor of 1 +O(n). \u2022 We validate our results experimentally and show that, by using asynchronous execution, we can achieve wallclock speedups of up to 2.8\u00d7 on real problems. 2 Related Work Much work has been done on the analysis of parallel Gibbs samplers. One simple way to parallelize Gibbs sampling is to run multiple chains independently in parallel: this heuristic uses parallelism to produce more samples overall, but does not produce accurate samples more quickly. Additionally, this strategy is sometimes worse than other strategies on a systems level Smola & Narayanamurthy (2010); Zhang & R\u00e9 (2014), typically because it requires additional memory to maintain multiple models of the chain.", "startOffset": 325, "endOffset": 1641}, {"referenceID": 3, "context": "The total influence measures the degree to which the marginal distribution of a variable can depend on the values of the other variables in the model\u2014this parameter has appeared as part of a celebrated line of work on Dobrushin\u2019s condition (\u03b1 < 1), which ensures the rapid mixing of spin statistics systems Dobrushin (1956); Dyer et al. (2006); Hayes (2006). It turns out that we can use this parameter to bound both the bias and mixing time of HOGWILD!-Gibbs, and so we make the following contributions: \u2022 We describe a way to statistically model the asynchronicity in HOGWILD!-Gibbs sampling. \u2022 To bound the bias, we prove that for classes of models with bounded total influence \u03b1 = O(1), if sequential Gibbs sampling achieves small sparse variation distance to \u03c0 in O(n) steps, where n is the number of variables, then HOGWILD!-Gibbs samples achieve the same distance in at most O(1) more steps. \u2022 For models that satisfy Dobrushin\u2019s condition (\u03b1 < 1), we show that the mixing time bounds of sequential and HOGWILD!-Gibbs sampling differ only by a factor of 1 +O(n). \u2022 We validate our results experimentally and show that, by using asynchronous execution, we can achieve wallclock speedups of up to 2.8\u00d7 on real problems. 2 Related Work Much work has been done on the analysis of parallel Gibbs samplers. One simple way to parallelize Gibbs sampling is to run multiple chains independently in parallel: this heuristic uses parallelism to produce more samples overall, but does not produce accurate samples more quickly. Additionally, this strategy is sometimes worse than other strategies on a systems level Smola & Narayanamurthy (2010); Zhang & R\u00e9 (2014), typically because it requires additional memory to maintain multiple models of the chain.", "startOffset": 325, "endOffset": 1660}, {"referenceID": 3, "context": "The total influence measures the degree to which the marginal distribution of a variable can depend on the values of the other variables in the model\u2014this parameter has appeared as part of a celebrated line of work on Dobrushin\u2019s condition (\u03b1 < 1), which ensures the rapid mixing of spin statistics systems Dobrushin (1956); Dyer et al. (2006); Hayes (2006). It turns out that we can use this parameter to bound both the bias and mixing time of HOGWILD!-Gibbs, and so we make the following contributions: \u2022 We describe a way to statistically model the asynchronicity in HOGWILD!-Gibbs sampling. \u2022 To bound the bias, we prove that for classes of models with bounded total influence \u03b1 = O(1), if sequential Gibbs sampling achieves small sparse variation distance to \u03c0 in O(n) steps, where n is the number of variables, then HOGWILD!-Gibbs samples achieve the same distance in at most O(1) more steps. \u2022 For models that satisfy Dobrushin\u2019s condition (\u03b1 < 1), we show that the mixing time bounds of sequential and HOGWILD!-Gibbs sampling differ only by a factor of 1 +O(n). \u2022 We validate our results experimentally and show that, by using asynchronous execution, we can achieve wallclock speedups of up to 2.8\u00d7 on real problems. 2 Related Work Much work has been done on the analysis of parallel Gibbs samplers. One simple way to parallelize Gibbs sampling is to run multiple chains independently in parallel: this heuristic uses parallelism to produce more samples overall, but does not produce accurate samples more quickly. Additionally, this strategy is sometimes worse than other strategies on a systems level Smola & Narayanamurthy (2010); Zhang & R\u00e9 (2014), typically because it requires additional memory to maintain multiple models of the chain. Another strategy for parallelizing Gibbs sampling involves taking advantage of the structure of the underlying factor graph to run in parallel while still maintaining an execution pattern to which the standard sequential Gibbs sampling analysis can be applied Gonzalez et al. (2011). Much further work has focused on parallelizing sampling for specific problems, such as LDA Newman et al.", "startOffset": 325, "endOffset": 2034}, {"referenceID": 3, "context": "The total influence measures the degree to which the marginal distribution of a variable can depend on the values of the other variables in the model\u2014this parameter has appeared as part of a celebrated line of work on Dobrushin\u2019s condition (\u03b1 < 1), which ensures the rapid mixing of spin statistics systems Dobrushin (1956); Dyer et al. (2006); Hayes (2006). It turns out that we can use this parameter to bound both the bias and mixing time of HOGWILD!-Gibbs, and so we make the following contributions: \u2022 We describe a way to statistically model the asynchronicity in HOGWILD!-Gibbs sampling. \u2022 To bound the bias, we prove that for classes of models with bounded total influence \u03b1 = O(1), if sequential Gibbs sampling achieves small sparse variation distance to \u03c0 in O(n) steps, where n is the number of variables, then HOGWILD!-Gibbs samples achieve the same distance in at most O(1) more steps. \u2022 For models that satisfy Dobrushin\u2019s condition (\u03b1 < 1), we show that the mixing time bounds of sequential and HOGWILD!-Gibbs sampling differ only by a factor of 1 +O(n). \u2022 We validate our results experimentally and show that, by using asynchronous execution, we can achieve wallclock speedups of up to 2.8\u00d7 on real problems. 2 Related Work Much work has been done on the analysis of parallel Gibbs samplers. One simple way to parallelize Gibbs sampling is to run multiple chains independently in parallel: this heuristic uses parallelism to produce more samples overall, but does not produce accurate samples more quickly. Additionally, this strategy is sometimes worse than other strategies on a systems level Smola & Narayanamurthy (2010); Zhang & R\u00e9 (2014), typically because it requires additional memory to maintain multiple models of the chain. Another strategy for parallelizing Gibbs sampling involves taking advantage of the structure of the underlying factor graph to run in parallel while still maintaining an execution pattern to which the standard sequential Gibbs sampling analysis can be applied Gonzalez et al. (2011). Much further work has focused on parallelizing sampling for specific problems, such as LDA Newman et al. (2007); Smola & Narayanamurthy (2010) and others Nguyen et al.", "startOffset": 325, "endOffset": 2147}, {"referenceID": 3, "context": "The total influence measures the degree to which the marginal distribution of a variable can depend on the values of the other variables in the model\u2014this parameter has appeared as part of a celebrated line of work on Dobrushin\u2019s condition (\u03b1 < 1), which ensures the rapid mixing of spin statistics systems Dobrushin (1956); Dyer et al. (2006); Hayes (2006). It turns out that we can use this parameter to bound both the bias and mixing time of HOGWILD!-Gibbs, and so we make the following contributions: \u2022 We describe a way to statistically model the asynchronicity in HOGWILD!-Gibbs sampling. \u2022 To bound the bias, we prove that for classes of models with bounded total influence \u03b1 = O(1), if sequential Gibbs sampling achieves small sparse variation distance to \u03c0 in O(n) steps, where n is the number of variables, then HOGWILD!-Gibbs samples achieve the same distance in at most O(1) more steps. \u2022 For models that satisfy Dobrushin\u2019s condition (\u03b1 < 1), we show that the mixing time bounds of sequential and HOGWILD!-Gibbs sampling differ only by a factor of 1 +O(n). \u2022 We validate our results experimentally and show that, by using asynchronous execution, we can achieve wallclock speedups of up to 2.8\u00d7 on real problems. 2 Related Work Much work has been done on the analysis of parallel Gibbs samplers. One simple way to parallelize Gibbs sampling is to run multiple chains independently in parallel: this heuristic uses parallelism to produce more samples overall, but does not produce accurate samples more quickly. Additionally, this strategy is sometimes worse than other strategies on a systems level Smola & Narayanamurthy (2010); Zhang & R\u00e9 (2014), typically because it requires additional memory to maintain multiple models of the chain. Another strategy for parallelizing Gibbs sampling involves taking advantage of the structure of the underlying factor graph to run in parallel while still maintaining an execution pattern to which the standard sequential Gibbs sampling analysis can be applied Gonzalez et al. (2011). Much further work has focused on parallelizing sampling for specific problems, such as LDA Newman et al. (2007); Smola & Narayanamurthy (2010) and others Nguyen et al.", "startOffset": 325, "endOffset": 2178}, {"referenceID": 3, "context": "The total influence measures the degree to which the marginal distribution of a variable can depend on the values of the other variables in the model\u2014this parameter has appeared as part of a celebrated line of work on Dobrushin\u2019s condition (\u03b1 < 1), which ensures the rapid mixing of spin statistics systems Dobrushin (1956); Dyer et al. (2006); Hayes (2006). It turns out that we can use this parameter to bound both the bias and mixing time of HOGWILD!-Gibbs, and so we make the following contributions: \u2022 We describe a way to statistically model the asynchronicity in HOGWILD!-Gibbs sampling. \u2022 To bound the bias, we prove that for classes of models with bounded total influence \u03b1 = O(1), if sequential Gibbs sampling achieves small sparse variation distance to \u03c0 in O(n) steps, where n is the number of variables, then HOGWILD!-Gibbs samples achieve the same distance in at most O(1) more steps. \u2022 For models that satisfy Dobrushin\u2019s condition (\u03b1 < 1), we show that the mixing time bounds of sequential and HOGWILD!-Gibbs sampling differ only by a factor of 1 +O(n). \u2022 We validate our results experimentally and show that, by using asynchronous execution, we can achieve wallclock speedups of up to 2.8\u00d7 on real problems. 2 Related Work Much work has been done on the analysis of parallel Gibbs samplers. One simple way to parallelize Gibbs sampling is to run multiple chains independently in parallel: this heuristic uses parallelism to produce more samples overall, but does not produce accurate samples more quickly. Additionally, this strategy is sometimes worse than other strategies on a systems level Smola & Narayanamurthy (2010); Zhang & R\u00e9 (2014), typically because it requires additional memory to maintain multiple models of the chain. Another strategy for parallelizing Gibbs sampling involves taking advantage of the structure of the underlying factor graph to run in parallel while still maintaining an execution pattern to which the standard sequential Gibbs sampling analysis can be applied Gonzalez et al. (2011). Much further work has focused on parallelizing sampling for specific problems, such as LDA Newman et al. (2007); Smola & Narayanamurthy (2010) and others Nguyen et al. (2013). Our approach follows on the paper of Johnson et al.", "startOffset": 325, "endOffset": 2210}, {"referenceID": 3, "context": "The total influence measures the degree to which the marginal distribution of a variable can depend on the values of the other variables in the model\u2014this parameter has appeared as part of a celebrated line of work on Dobrushin\u2019s condition (\u03b1 < 1), which ensures the rapid mixing of spin statistics systems Dobrushin (1956); Dyer et al. (2006); Hayes (2006). It turns out that we can use this parameter to bound both the bias and mixing time of HOGWILD!-Gibbs, and so we make the following contributions: \u2022 We describe a way to statistically model the asynchronicity in HOGWILD!-Gibbs sampling. \u2022 To bound the bias, we prove that for classes of models with bounded total influence \u03b1 = O(1), if sequential Gibbs sampling achieves small sparse variation distance to \u03c0 in O(n) steps, where n is the number of variables, then HOGWILD!-Gibbs samples achieve the same distance in at most O(1) more steps. \u2022 For models that satisfy Dobrushin\u2019s condition (\u03b1 < 1), we show that the mixing time bounds of sequential and HOGWILD!-Gibbs sampling differ only by a factor of 1 +O(n). \u2022 We validate our results experimentally and show that, by using asynchronous execution, we can achieve wallclock speedups of up to 2.8\u00d7 on real problems. 2 Related Work Much work has been done on the analysis of parallel Gibbs samplers. One simple way to parallelize Gibbs sampling is to run multiple chains independently in parallel: this heuristic uses parallelism to produce more samples overall, but does not produce accurate samples more quickly. Additionally, this strategy is sometimes worse than other strategies on a systems level Smola & Narayanamurthy (2010); Zhang & R\u00e9 (2014), typically because it requires additional memory to maintain multiple models of the chain. Another strategy for parallelizing Gibbs sampling involves taking advantage of the structure of the underlying factor graph to run in parallel while still maintaining an execution pattern to which the standard sequential Gibbs sampling analysis can be applied Gonzalez et al. (2011). Much further work has focused on parallelizing sampling for specific problems, such as LDA Newman et al. (2007); Smola & Narayanamurthy (2010) and others Nguyen et al. (2013). Our approach follows on the paper of Johnson et al. (2013), which proposes the HOGWILD!-Gibbs sampling algorithm and analyzes it for the case of Gaussian models.", "startOffset": 325, "endOffset": 2270}, {"referenceID": 3, "context": "The total influence measures the degree to which the marginal distribution of a variable can depend on the values of the other variables in the model\u2014this parameter has appeared as part of a celebrated line of work on Dobrushin\u2019s condition (\u03b1 < 1), which ensures the rapid mixing of spin statistics systems Dobrushin (1956); Dyer et al. (2006); Hayes (2006). It turns out that we can use this parameter to bound both the bias and mixing time of HOGWILD!-Gibbs, and so we make the following contributions: \u2022 We describe a way to statistically model the asynchronicity in HOGWILD!-Gibbs sampling. \u2022 To bound the bias, we prove that for classes of models with bounded total influence \u03b1 = O(1), if sequential Gibbs sampling achieves small sparse variation distance to \u03c0 in O(n) steps, where n is the number of variables, then HOGWILD!-Gibbs samples achieve the same distance in at most O(1) more steps. \u2022 For models that satisfy Dobrushin\u2019s condition (\u03b1 < 1), we show that the mixing time bounds of sequential and HOGWILD!-Gibbs sampling differ only by a factor of 1 +O(n). \u2022 We validate our results experimentally and show that, by using asynchronous execution, we can achieve wallclock speedups of up to 2.8\u00d7 on real problems. 2 Related Work Much work has been done on the analysis of parallel Gibbs samplers. One simple way to parallelize Gibbs sampling is to run multiple chains independently in parallel: this heuristic uses parallelism to produce more samples overall, but does not produce accurate samples more quickly. Additionally, this strategy is sometimes worse than other strategies on a systems level Smola & Narayanamurthy (2010); Zhang & R\u00e9 (2014), typically because it requires additional memory to maintain multiple models of the chain. Another strategy for parallelizing Gibbs sampling involves taking advantage of the structure of the underlying factor graph to run in parallel while still maintaining an execution pattern to which the standard sequential Gibbs sampling analysis can be applied Gonzalez et al. (2011). Much further work has focused on parallelizing sampling for specific problems, such as LDA Newman et al. (2007); Smola & Narayanamurthy (2010) and others Nguyen et al. (2013). Our approach follows on the paper of Johnson et al. (2013), which proposes the HOGWILD!-Gibbs sampling algorithm and analyzes it for the case of Gaussian models. Their main contribution is an analysis framework that includes a sufficient condition under which HOGWILD! Gaussian Gibbs samples are guaranteed to have the correct asymptotic mean. Recent work Terenin et al. (2015) has analyzed a similar algorithm under even stronger regularity conditions.", "startOffset": 325, "endOffset": 2589}, {"referenceID": 3, "context": "The total influence measures the degree to which the marginal distribution of a variable can depend on the values of the other variables in the model\u2014this parameter has appeared as part of a celebrated line of work on Dobrushin\u2019s condition (\u03b1 < 1), which ensures the rapid mixing of spin statistics systems Dobrushin (1956); Dyer et al. (2006); Hayes (2006). It turns out that we can use this parameter to bound both the bias and mixing time of HOGWILD!-Gibbs, and so we make the following contributions: \u2022 We describe a way to statistically model the asynchronicity in HOGWILD!-Gibbs sampling. \u2022 To bound the bias, we prove that for classes of models with bounded total influence \u03b1 = O(1), if sequential Gibbs sampling achieves small sparse variation distance to \u03c0 in O(n) steps, where n is the number of variables, then HOGWILD!-Gibbs samples achieve the same distance in at most O(1) more steps. \u2022 For models that satisfy Dobrushin\u2019s condition (\u03b1 < 1), we show that the mixing time bounds of sequential and HOGWILD!-Gibbs sampling differ only by a factor of 1 +O(n). \u2022 We validate our results experimentally and show that, by using asynchronous execution, we can achieve wallclock speedups of up to 2.8\u00d7 on real problems. 2 Related Work Much work has been done on the analysis of parallel Gibbs samplers. One simple way to parallelize Gibbs sampling is to run multiple chains independently in parallel: this heuristic uses parallelism to produce more samples overall, but does not produce accurate samples more quickly. Additionally, this strategy is sometimes worse than other strategies on a systems level Smola & Narayanamurthy (2010); Zhang & R\u00e9 (2014), typically because it requires additional memory to maintain multiple models of the chain. Another strategy for parallelizing Gibbs sampling involves taking advantage of the structure of the underlying factor graph to run in parallel while still maintaining an execution pattern to which the standard sequential Gibbs sampling analysis can be applied Gonzalez et al. (2011). Much further work has focused on parallelizing sampling for specific problems, such as LDA Newman et al. (2007); Smola & Narayanamurthy (2010) and others Nguyen et al. (2013). Our approach follows on the paper of Johnson et al. (2013), which proposes the HOGWILD!-Gibbs sampling algorithm and analyzes it for the case of Gaussian models. Their main contribution is an analysis framework that includes a sufficient condition under which HOGWILD! Gaussian Gibbs samples are guaranteed to have the correct asymptotic mean. Recent work Terenin et al. (2015) has analyzed a similar algorithm under even stronger regularity conditions. Here, we seek to give more general results for the analysis of HOGWILD!-Gibbs sampling on discrete-valued factor graphs. The HOGWILD!-Gibbs sampling algorithm was inspired by a line of work on parallelizing stochastic gradient descent (SGD) by running it asynchronously. HOGWILD! SGD was first proposed by Niu et al. (2011), who proved that", "startOffset": 325, "endOffset": 2989}, {"referenceID": 11, "context": "The asynchronous execution strategy has been applied to many problems\u2014such as PageRank approximations Mitliagkas et al. (2015), deep learning Noel & Osindero (2014) and recommender systems Yu et al.", "startOffset": 102, "endOffset": 127}, {"referenceID": 11, "context": "The asynchronous execution strategy has been applied to many problems\u2014such as PageRank approximations Mitliagkas et al. (2015), deep learning Noel & Osindero (2014) and recommender systems Yu et al.", "startOffset": 102, "endOffset": 165}, {"referenceID": 11, "context": "The asynchronous execution strategy has been applied to many problems\u2014such as PageRank approximations Mitliagkas et al. (2015), deep learning Noel & Osindero (2014) and recommender systems Yu et al. (2012)\u2014so it is not surprising that it has been proposed for use with Gibbs sampling.", "startOffset": 102, "endOffset": 206}, {"referenceID": 9, "context": "In particular, we are motivated by some recent work on the analysis of HOGWILD! for SGD Liu et al. (2015); De Sa et al.", "startOffset": 88, "endOffset": 106}, {"referenceID": 0, "context": "(2015); De Sa et al. (2015a); Mania et al.", "startOffset": 11, "endOffset": 29}, {"referenceID": 0, "context": "(2015); De Sa et al. (2015a); Mania et al. (2015); Liu & Wright (2015).", "startOffset": 11, "endOffset": 50}, {"referenceID": 0, "context": "(2015); De Sa et al. (2015a); Mania et al. (2015); Liu & Wright (2015). Several of these results suggest modeling the race conditions inherent in HOGWILD! SGD as noise in a stochastic process; this lets them bring a trove of statistical techniques to bear on the analysis of HOGWILD! SGD.", "startOffset": 11, "endOffset": 71}, {"referenceID": 0, "context": "(2015); De Sa et al. (2015a); Mania et al. (2015); Liu & Wright (2015). Several of these results suggest modeling the race conditions inherent in HOGWILD! SGD as noise in a stochastic process; this lets them bring a trove of statistical techniques to bear on the analysis of HOGWILD! SGD. Therefore, in this paper, we will apply a similar stochastic process model to Gibbs sampling. Several recent papers have focused on the mixing time of Gibbs sampling for factor graphs. Gotovos et al. (2015) and De Sa et al.", "startOffset": 11, "endOffset": 496}, {"referenceID": 0, "context": "(2015); De Sa et al. (2015a); Mania et al. (2015); Liu & Wright (2015). Several of these results suggest modeling the race conditions inherent in HOGWILD! SGD as noise in a stochastic process; this lets them bring a trove of statistical techniques to bear on the analysis of HOGWILD! SGD. Therefore, in this paper, we will apply a similar stochastic process model to Gibbs sampling. Several recent papers have focused on the mixing time of Gibbs sampling for factor graphs. Gotovos et al. (2015) and De Sa et al. (2015b) each show that Gibbs sampling mixes in polynomial time for a class of distributions bounded by some parameter.", "startOffset": 11, "endOffset": 521}, {"referenceID": 0, "context": "(2015); De Sa et al. (2015a); Mania et al. (2015); Liu & Wright (2015). Several of these results suggest modeling the race conditions inherent in HOGWILD! SGD as noise in a stochastic process; this lets them bring a trove of statistical techniques to bear on the analysis of HOGWILD! SGD. Therefore, in this paper, we will apply a similar stochastic process model to Gibbs sampling. Several recent papers have focused on the mixing time of Gibbs sampling for factor graphs. Gotovos et al. (2015) and De Sa et al. (2015b) each show that Gibbs sampling mixes in polynomial time for a class of distributions bounded by some parameter. Unfortunately, these results both depend on spectral methods (that try to bound the spectral gap of the Markov transition matrix), which are difficult to apply to HOGWILD! Gibbs sampling for two reasons. First, spectral methods don\u2019t let us represent the sampler as a stochastic process, which limits the range of techniques we can use to model the noise. Secondly, while most spectral methods only apply to reversible Markov chains\u2014and sequential Gibbs sampling is always a reversible chain\u2014for HOGWILD!-Gibbs sampling the asynchronicity and parallelism make the chain non-reversible. Because of this, we were unable to use these spectral results in our asynchronous setting. We are forced to rely on the other method Guruswami (2000) for analyzing Markov processes, coupling\u2014the type of analysis used with the Dobrushin condition\u2014which we will describe in the following sections.", "startOffset": 11, "endOffset": 1368}, {"referenceID": 0, "context": "(2015); De Sa et al. (2015a); Mania et al. (2015); Liu & Wright (2015). Several of these results suggest modeling the race conditions inherent in HOGWILD! SGD as noise in a stochastic process; this lets them bring a trove of statistical techniques to bear on the analysis of HOGWILD! SGD. Therefore, in this paper, we will apply a similar stochastic process model to Gibbs sampling. Several recent papers have focused on the mixing time of Gibbs sampling for factor graphs. Gotovos et al. (2015) and De Sa et al. (2015b) each show that Gibbs sampling mixes in polynomial time for a class of distributions bounded by some parameter. Unfortunately, these results both depend on spectral methods (that try to bound the spectral gap of the Markov transition matrix), which are difficult to apply to HOGWILD! Gibbs sampling for two reasons. First, spectral methods don\u2019t let us represent the sampler as a stochastic process, which limits the range of techniques we can use to model the noise. Secondly, while most spectral methods only apply to reversible Markov chains\u2014and sequential Gibbs sampling is always a reversible chain\u2014for HOGWILD!-Gibbs sampling the asynchronicity and parallelism make the chain non-reversible. Because of this, we were unable to use these spectral results in our asynchronous setting. We are forced to rely on the other method Guruswami (2000) for analyzing Markov processes, coupling\u2014the type of analysis used with the Dobrushin condition\u2014which we will describe in the following sections. 3 Modeling Asynchronicity In this section, we describe a statistical model for asynchronous Gibbs sampling by adapting the hardware model outlined in De Sa et al. (2015a). Because we are motivated by the factor graph inference problem, we will focus on the case where the distribution \u03c0 that we want to sample comes from a sparse, discrete graphical model.", "startOffset": 11, "endOffset": 1685}, {"referenceID": 21, "context": "In this model, the \u03c4 parameter represents everything that is relevant about the hardware; representing the hardware in this way has been successful for the analysis of asynchronous SGD Niu et al. (2011), so it is reasonable to use it for Gibbs sampling.", "startOffset": 185, "endOffset": 203}, {"referenceID": 24, "context": "In many practical systems Neubig (2014); Shin et al. (2015), Gibbs sampling is used without a proof that it works; instead, it is naively run for some fixed number of passes through the dataset.", "startOffset": 41, "endOffset": 60}, {"referenceID": 26, "context": "in practice Smyth et al. (2009); Smola & Narayanamurthy (2010).", "startOffset": 12, "endOffset": 32}, {"referenceID": 26, "context": "in practice Smyth et al. (2009); Smola & Narayanamurthy (2010). To further test this, we ran HOGWILD!-Gibbs sampling on a real-world 11 GB Knowledge Base Population dataset (derived from the TAC-KBP challenge) using a machine with a single-socket, 18-core Xeon E7-8890 CPU and 1 TB RAM.", "startOffset": 12, "endOffset": 63}, {"referenceID": 11, "context": "1 Statements of Lemmas First, we state a proposition from Levin et al. (2009). This proposition relates the concept of a coupling with the total variation distance between the distributions of two random variables.", "startOffset": 58, "endOffset": 78}, {"referenceID": 11, "context": "1 Statements of Lemmas First, we state a proposition from Levin et al. (2009). This proposition relates the concept of a coupling with the total variation distance between the distributions of two random variables. Proposition 1 (Proposition 4.7 from Levin et al. (2009)).", "startOffset": 58, "endOffset": 271}, {"referenceID": 11, "context": "3 from Levin et al. (2009), max \u03bc0 \u2016\u03bct \u2212 \u03c0\u2016TV \u2264 P (Tcoupling > t) .", "startOffset": 7, "endOffset": 27}], "year": 2015, "abstractText": "Gibbs sampling is a Markov Chain Monte Carlo technique commonly used for estimating marginal distributions. To speed up Gibbs sampling, there has recently been interest in parallelizing it by executing asynchronously. While empirical results suggest that many models can be efficiently sampled asynchronously, traditional Markov chain analysis does not apply to the asynchronous case, and thus asynchronous Gibbs sampling is poorly understood. In this paper, we derive a better understanding of the two main challenges of asynchronous Gibbs: sampling bias and mixing time. We show experimentally that our theoretical results match practical outcomes.", "creator": "gnuplot 5.0 patchlevel 0"}}}