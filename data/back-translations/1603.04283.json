{"id": "1603.04283", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Mar-2016", "title": "Universal probability-free prediction", "abstract": "We are constructing a universal prediction system in the spirit of Popper's falsifiability and Kolmogorov's complexity. This prediction system is not dependent on any statistical assumptions, but under the IID assumption it dominates compliant predictions, albeit in a rather weak sense.", "histories": [["v1", "Mon, 14 Mar 2016 14:43:48 GMT  (8kb)", "http://arxiv.org/abs/1603.04283v1", "8 pages"], ["v2", "Tue, 4 Apr 2017 12:02:43 GMT  (24kb)", "http://arxiv.org/abs/1603.04283v2", "27 pages"]], "COMMENTS": "8 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["vladimir vovk", "dusko pavlovic"], "accepted": false, "id": "1603.04283"}, "pdf": {"name": "1603.04283.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Dusko Pavlovic", "Karl Popper"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n60 3.\n04 28\n3v 1\n[ cs\n.L G\n] 1\n4 M\nWe construct a universal prediction system in the spirit of Popper\u2019s falsifiability and Kolmogorov complexity. This prediction system does not depend on any statistical assumptions, but under the IID assumption it dominates, although in a rather weak sense, conformal prediction.\nNot for nothing do we call the laws of nature \u201claws\u201d: the more they prohibit, the more they say.\nThe Logic of Scientific Discovery\nKarl Popper"}, {"heading": "1 Introduction", "text": "In this paper we consider the problem of predicting labels, assumed to be binary, of a sequence of objects. This is an online version of the standard problem of binary classification. Namely, we will be interested in infinite sequences of observations\n\u03c9 = (z1, z2, . . .) = ((x1, y1), (x2, y2), . . .) \u2208 (X\u00d7 2) \u221e\n(also called infinite data sequences), where X is an object space and 2 := {0, 1}. For simplicity, we will assume that X is a given finite set of, say, binary strings (the intuition being that finite objects can always be encoded as binary strings).\nFinite sequences \u03c3 \u2208 (X \u00d7 2)\u2217 of observations will be called finite data sequences. If \u03c31, \u03c32 are two finite data sequences, their concatenation will be denoted (\u03c31, \u03c32); \u03c32 is also allowed to be an element of X \u00d7 2. A standard partial order on (X\u00d72)\u2217 is defined as follows: \u03c31 \u2291 \u03c32 means that \u03c31 is a prefix of \u03c32; \u03c31 \u2741 \u03c32 means that \u03c31 \u2291 \u03c32 and \u03c31 6= \u03c32.\nWe use the notation N := {1, 2, . . .} for the set of positive integers and N0 := {0, 1, 2, . . .} for the set of nonnegative integers. If \u03c9 \u2208 (X \u00d7 2)\u221e and n \u2208 N0, \u03c9n \u2208 (X\u00d7 2)n is the prefix of \u03c9 of length n.\nA situation is a concatenation (\u03c3, x) \u2208 (X\u00d72)\u2217\u00d7X of a finite data sequence \u03c3 and an object x; our task in the situation (\u03c3, x) is to be able to predict the\nlabel of the new object x given the sequence \u03c3 of labelled objects. Given a situation s = (\u03c3, x) and a label y \u2208 2, we let (s, y) stand for the finite data sequence (\u03c3, (x, y)), which is the concatenation of s and y."}, {"heading": "2 Laws of nature as prediction systems", "text": "According to Popper\u2019s [1] view of the philosophy of science, scientific laws of nature should be falsifiable: if a finite sequence of observations contradicts such a law, we should be able to detect it. (Popper often preferred to talk about scientific theories or statements instead of laws of nature.) The empirical content of a law of nature is the set of its potential falsifiers ([1], Sections 31 and 35). We start from formalizing this notion in our toy setting, interpreting the requirement that we should be able to detect falsification as that we should be able to detect it eventually.\nFormally, we define a law of nature L to be a recursively enumerable prefixfree subset of (X \u00d7 2)\u2217 (where prefix-free means that \u03c32 /\u2208 L whenever \u03c31 \u2208 L and \u03c31 \u2741 \u03c32). Intuitively, these are the potential falsifiers, i.e., sequences of observations prohibited by the law of nature. The requirement of being recursively enumerable is implicit in the notion of a falsifier, and the requirement of being prefix-free reflects the fact that extensions of prohibited sequences of observations are automatically prohibited and there is no need to mention them in the definition.\nA law of nature L gives rise to a prediction system: in a situation s = (\u03c3, x) it predicts that the label y \u2208 2 of the new object x will be an element of\n\u03a0L(s) := {y \u2208 2 | (s, y) /\u2208 L} . (1)\nThere are three possibilities in each situation s:\n\u2022 The law of nature makes a prediction, either 0 or 1, in situation s when the prediction set (1) is of size 1, |\u03a0L(s)| = 1.\n\u2022 The prediction set is empty, |\u03a0L(s)| = 0, which means that the law of nature has been falsified.\n\u2022 The law of nature refrains from making a prediction when |\u03a0L(s)| = 2. This can happen in two cases:\n\u2013 the law of nature was falsified in past: \u03c3\u2032 \u2208 L for some \u03c3\u2032 \u2291 \u03c3;\n\u2013 the law of nature has not been falsified as yet."}, {"heading": "3 Strong prediction systems", "text": "The notion of a law of nature is static; experience tells us that laws of nature eventually fail and are replaced by other laws. Popper represented his picture of this process by formulas (\u201cevolutionary schemas\u201d) similar to\nPS1 \u2192 TT1 \u2192 EE1 \u2192 PS2 \u2192 \u00b7 \u00b7 \u00b7 (2)\n(introduced in his 1965 talk on which [2], Chapter 6, is based and also discussed in several other places in [2] and [3]; in our notation we follow Wikipedia). In response to a problem situation PS, a tentative theory TT is subjected to attempts at error elimination EE, whose success leads to a new problem situation PS and scientists come up with a new tentative theory TT, etc. In our toy version of this process, tentative theories are laws of nature, problem situations are situations in which our current law of nature becomes falsified, and there are no active attempts at error elimination (so that error elimination simply consists in waiting until the current law of nature becomes falsified).\nIf L and L\u2032 are laws of nature, we define L \u2741 L\u2032 to mean that for any \u03c3\u2032 \u2208 L\u2032 there exists \u03c3 \u2208 L such that \u03c3 \u2741 \u03c3\u2032. To formalize the philosophical picture (2), we define a strong prediction system L to be a nested sequence L1 \u2741 L2 \u2741 \u00b7 \u00b7 \u00b7 of laws of nature L1, L2, . . . that are jointly recursively enumerable, in the sense of the set {(\u03c3, n) \u2208 (X\u00d7 2)\u2217 \u00d7 N | \u03c3 \u2208 Ln} being recursively enumerable.\nThe interpretation of a strong prediction system L = (L1, L2, . . .) is that L1 is the initial law of nature used for predicting the labels of new objects until it is falsified; as soon as it is falsified we start looking for and then using for prediction the following law of nature L2 until it is falsified in its turn, etc. Therefore, the prediction set in a situation s = (\u03c3, x) is natural to define as the set\n\u03a0L(s) := {y \u2208 2 | (s, y) /\u2208 \u222a \u221e n=1Ln} . (3)\nAs before, it is possible that \u03a0L(s) = \u2205. Fix a situation s = (\u03c3, x) \u2208 (X \u00d7 2)\u2217 \u00d7 X. Let n = n(s) be the largest integer such that s has a prefix in Ln. It is possible that n = 0 (when s does not have such prefixes), but if n \u2265 1, s will also have prefixes in Ln\u22121, . . . , L1, by the definition of a strong prediction system. Then Ln+1 will be the current law of nature; all earlier laws, Ln, Ln\u22121, . . . , L1, have been falsified. The prediction (3) in situation s is then interpreted as the set of all observations y that are not prohibited by the current law Ln+1.\nIn the spirit of the theory of Kolmogorov complexity, we would like to have a universal prediction system. However, we are not aware of any useful notion of a universal strong prediction system. Therefore, in the next section we will introduce a wider notion of a prediction system that does not have this disadvantage."}, {"heading": "4 Weak prediction systems and universal pre-", "text": "diction\nA weak prediction system L is defined to be a sequence (not required to be nested in any sense) L1, L2, . . . of laws of nature Ln \u2286 (X\u00d7 2)\u2217 that are jointly recursively enumerable.\nRemark. Popper\u2019s evolutionary schema (2) was the simplest one that he con-\nsidered; his more complicated ones, such as\nPS1\n\u0580 TTa \u2192 EEa \u2192 PS2a \u2192 \u00b7 \u00b7 \u00b7\n\u2192TTb \u2192 EEb \u2192 PS2b \u2192 \u00b7 \u00b7 \u00b7\n\u0581 TTc \u2192 EEc \u2192 PS2c \u2192 \u00b7 \u00b7 \u00b7\n(cf. [2], pp. 243 and 287), give rise to weak rather than strong prediction systems.\nIn the rest of this paper we will omit \u201cweak\u201d in \u201cweak prediction system\u201d. The most basic way of using a prediction system L for making a prediction in situation s = (\u03c3, x) is as follows. Decide on the maximum number N of errors you are willing to make. Ignore all Ln apart from L1, . . . , LN in L, so that the prediction set in situation s is\n\u03a0NL (s) := {y \u2208 2 | \u2200n \u2208 {1, . . . , N} : (s, y) /\u2208 Ln} .\nNotice that this way we are guaranteed to make at most N mistakes: making a mistake eliminates at least one law in the list {L1, . . . , LN}.\nSimilarly to the usual theory of conformal prediction, another way of packaging L\u2019s prediction in situation s is, instead of choosing the threshold (or level) N in advance, to allow the user to apply her own threshold: in a situation s, for each y \u2208 2 report the attained level\n\u03c0sL(y) := min {n \u2208 N | (s, y) \u2208 Ln} (4)\n(with min \u2205 := \u221e). The user whose threshold is N will then consider y \u2208 2 with \u03c0sL(y) \u2264 N as prohibited in s. Notice that the function (4) is upper semicomputable (for a fixed L).\nThe strength of a prediction system L = (L1, L2, . . .) at levelN is determined by its N -part\nL\u2264N := N \u22c3\nn=1\nLn.\nAt levelN , the prediction system L prohibits y \u2208 2 as continuation of a situation s if and only if (s, y) \u2208 L\u2264N .\nThe following lemma says that there exists a universal prediction system, in the sense that it is stronger than any other prediction system if we ignore a multiplicative increase in the number of errors made.\nLemma 1. There is a universal prediction system U , in the sense that for any prediction system L there exists a constant C > 0 such that, for any N ,\nL\u2264N \u2286 U\u2264CN . (5)\nProof. Let L1,L2, . . . be a recursive enumeration of all prediction systems; their component laws of nature will be denoted (Lk1 , L k 2 , . . .) := L k. For each n \u2208 N,\ndefine the nth component Un of U = (U1, U2, . . .) as follows. Let the binary representation of n be\n(a, 0, 1, . . . , 1), (6)\nwhere a is a binary string (starting from 1) and the number of 1s in the 1, . . . , 1 is k \u2212 1 \u2208 N0 (this sentence is the definition of a = a(n) and k = k(n) in terms of n). If the binary representation of n does not contain any 0s, a and k are undefined, and we set Un := \u2205. Otherwise, set\nUn := L k A,\nwhere A \u2208 N is the number whose binary representation is a. In other words, U consists of the components of Lk, k \u2208 N; namely, Lk1 is placed in U as U3\u00d72k\u22121\u22121 and then Lk2 , L k 3 , . . . are placed at intervals of 2 k:\nU3\u00d72k\u22121\u22121+2k(i\u22121) = L k i , i = 1, 2, . . . .\nIt is easy to see that Lk\u2264N \u2286 U\u22643\u00d72k\u22121\u22121+2k(N\u22121), (7)\nwhich is stronger than (5).\nLet us fix a universal prediction system U . By K(L) we will denote the smallest prefix complexity of the programs for computing a prediction system L. The following lemma makes (5) uniform in L showing how C depends on L.\nLemma 2. There is a constant C > 0 such that, for any prediction system L and any N , the universal prediction system U satisfies\nL\u2264N \u2286 U\u2264C2K(L)N . (8)\nProof. Follow the proof of Lemma 1 replacing the \u201ccode\u201d (0, 1, . . . , 1) for Lk in (6) by any prefix-free description of Lk (with its bits written in the reverse order). Then the modification\nLk\u2264N \u2286 U\u22642k\u2032+1\u22121+2k\u2032 (N\u22121)\nof (7) with k\u2032 := K(Lk) implies that (8) holds for some universal prediction system, which, when combined with the statement of Lemma 1, implies that (8) holds for our chosen universal prediction system U .\nThis is a corollary for laws of nature:\nCorollary 1. There is a constant C such that, for any law of nature L, the universal prediction system U satisfies\nL \u2286 U\u2264C2K(L) . (9)\nProof. We can regard laws of nature L to be a special case of prediction systems identifying L with L := (L,L, . . .). It remains to apply Lemma 2 to L setting N := 1.\nWe can equivalently rewrite (5), (8), and (9) as\n\u03a0CNU (s) \u2286 \u03a0 N L (s), (10)\n\u03a0C2 K(L)N\nU (s) \u2286 \u03a0 N L (s), (11)\nand\n\u03a0C2 K(L)\nU (s) \u2286 \u03a0L(s), (12)\nrespectively, for all situations s. Intuitively, (10) says that the prediction sets output by the universal prediction system are at least as precise as the prediction sets output by any other prediction system L if we ignore a constant factor in specifying the levelN ; and (11) and (12) indicate the dependence of the constant factor on L."}, {"heading": "5 Universal conformal prediction under the IID", "text": "assumption\nComparison of prediction systems and conformal predictors is hampered by the fact that the latter are designed for the case where we have a constant amount of noise for each observation, and so we expect the number of errors to grow linearly rather than staying bounded. In this situation a reasonable prediction set is \u03a0\u01ebNL (s), where N is the number of observations in the situation s. For a small \u01eb using \u03a0\u01ebNL (s) means that we trust the prediction system whose percentage of errors so far is at most \u01eb.\nUp to this point our exposition has been completely probability-free, but in the rest of this section we will consider the special case where the data are generated in the IID manner. For simplicity, we will only consider computable conformity measures that take values in the set Q of rational numbers.\nCorollary 2. Let \u0393 be a conformal predictor based on a computable conformity measure taking values in Q. Then there exists C > 0 such that, for almost all infinite sequences of observations \u03c9 = ((x1, y1), (x2, y2), . . .) \u2208 (X\u00d72) \u221e and all significance levels \u01eb \u2208 (0, 1), from some N on we will have\n\u03a0 CN\u01eb ln2(1+1/\u01eb) U ((\u03c9 N , xN+1)) \u2286 \u0393 \u01eb((\u03c9N , xN+1)). (13)\nThis corollary asserts that the prediction set output by the universal prediction system is at least as precise as the prediction set output by \u0393 if we increase slightly the significance level: from \u01eb to C\u01eb ln2(1+ 1/\u01eb). It involves not just multiplying by a constant (as is the case for (5) and (8)\u2013(12)) but also the logarithmic term ln2(1 + 1/\u01eb).\nIt is easy to see that we can replace the C in (13) by C2K(\u0393), where C now does not depend on \u0393 (and K(\u0393) is the smallest prefix complexity of the programs for computing the conformity measure on which \u0393 is based).\nProof of Corollary 2. Let \u01eb\u2032 := 2\u2308log \u01eb\u2309+1,\nwhere log stands for the base 2 logarithm. (Intuitively, we simplify \u01eb, in the sense of Kolmogorov complexity, by replacing it by a number of the form 2\u2212m for an integer m, and make it at least twice as large as the original \u01eb.) Define a prediction system (both weak and strong) L as, essentially, \u0393\u01eb \u2032\n; formally, L := (L1, L2, . . .) and Ln is defined to be the set of all \u03c9N , where \u03c9 ranges over the infinite data sequences and N over N, such that the set\n{\ni \u2208 {1, . . . , N} | yi /\u2208 \u0393 \u01eb\u2032((\u03c9i\u22121, xi))\n}\nis of size n and contains N . The prediction system L is determined by \u01eb\u2032, so that K(L) does not exceed (apart from the usual additive constant) K(\u01eb\u2032). By the standard validity property of conformal predictors ([6], Corollary 1.1), Hoeffding\u2019s inequality, and the Borel\u2013Cantelli lemma,\n\u03a0\u01eb \u2032N L ((\u03c9 N , xN+1)) \u2286 \u0393 \u01eb((\u03c9N , xN+1)) (14)\nfrom some N on almost surely. By Lemma 2 (in the form of (11)),\n\u03a0C12 K(\u01eb\u2032)\u01eb\u2032N\nU ((\u03c9 N , xN+1)) \u2286 \u03a0 \u01eb\u2032N L ((\u03c9 N , xN+1)) (15)\nfor all N . The statement (13) of the corollary is obtained by combining (14), (15), and\n2K(\u01eb \u2032) \u2264 C2 ln 2(1 + 1/\u01eb).\nTo check the last inequality, remember that \u01eb\u2032 = 2\u2212m for an integer m, which we assume to be positive, without loss of generality; therefore, our task reduces to checking that\n2K(m) \u2264 C3 ln 2(1 + 2m),\ni.e., 2K(m) \u2264 C4m 2. Since 2\u2212K(m) is the universal semimeasure on the positive integers (see, e.g., [5], Theorem 7.29), we even have\n2K(m) \u2264 C5m(logm)(log logm) \u00b7 \u00b7 \u00b7 (log \u00b7 \u00b7 \u00b7 logm),\nwhere the product contains all factors that are greater than 1 (see [4], Appendix A)."}, {"heading": "6 Conclusion", "text": "In this note we have ignored the computational resources, first of all, the required computation time and space (memory). Developing versions of our definitions and results taking into account the time of computations is a natural next step. In analogy with the theory of Kolmogorov complexity, we expect that the simplest and most elegant results will be obtained for computational models that are more flexible than Turing machines, such as Kolmogorov\u2013Uspensky algorithms and Scho\u0308nhage machines.\nAcknowledgments.\nWe thank the anonymous referees for helpful comments. This work has been supported by the Air Force Office of Scientific Research (grant \u201cSemantic Completions\u201d), EPSRC (grant EP/K033344/1), and the EU Horizon 2020 Research and Innovation programme (grant 671555)."}], "references": [{"title": "English translation: The Logic of Scientific Discovery", "author": ["Karl R. Popper"], "venue": "Logik der Forschung. Springer, Vienna,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1934}, {"title": "Objective Knowledge: An Evolutionary Approach", "author": ["Karl R. Popper"], "venue": "First edition:", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1979}, {"title": "All Life is Problem Solving", "author": ["Karl R. Popper"], "venue": "Abingdon, Routledge,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "A universal prior for integers and estimation by minimum description length", "author": ["Jorma Rissanen"], "venue": "Annals of Statistics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1983}, {"title": "Around Kolmogorov complexity: Basic notions and results", "author": ["Alexander Shen"], "venue": "Measures of Complexity: Festschrift for Alexey Chervonenkis,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "The basic conformal prediction framework", "author": ["Vladimir Vovk"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "According to Popper\u2019s [1] view of the philosophy of science, scientific laws of nature should be falsifiable: if a finite sequence of observations contradicts such a law, we should be able to detect it.", "startOffset": 22, "endOffset": 25}, {"referenceID": 0, "context": ") The empirical content of a law of nature is the set of its potential falsifiers ([1], Sections 31 and 35).", "startOffset": 83, "endOffset": 86}, {"referenceID": 1, "context": "(introduced in his 1965 talk on which [2], Chapter 6, is based and also discussed in several other places in [2] and [3]; in our notation we follow Wikipedia).", "startOffset": 38, "endOffset": 41}, {"referenceID": 1, "context": "(introduced in his 1965 talk on which [2], Chapter 6, is based and also discussed in several other places in [2] and [3]; in our notation we follow Wikipedia).", "startOffset": 109, "endOffset": 112}, {"referenceID": 2, "context": "(introduced in his 1965 talk on which [2], Chapter 6, is based and also discussed in several other places in [2] and [3]; in our notation we follow Wikipedia).", "startOffset": 117, "endOffset": 120}, {"referenceID": 1, "context": "[2], pp.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "By the standard validity property of conformal predictors ([6], Corollary 1.", "startOffset": 59, "endOffset": 62}, {"referenceID": 4, "context": ", [5], Theorem 7.", "startOffset": 2, "endOffset": 5}, {"referenceID": 3, "context": "29), we even have 2 \u2264 C5m(logm)(log logm) \u00b7 \u00b7 \u00b7 (log \u00b7 \u00b7 \u00b7 logm), where the product contains all factors that are greater than 1 (see [4], Appendix A).", "startOffset": 134, "endOffset": 137}], "year": 2017, "abstractText": "We construct a universal prediction system in the spirit of Popper\u2019s falsifiability and Kolmogorov complexity. This prediction system does not depend on any statistical assumptions, but under the IID assumption it dominates, although in a rather weak sense, conformal prediction. Not for nothing do we call the laws of nature \u201claws\u201d: the more they prohibit, the more they say. The Logic of Scientific Discovery Karl Popper", "creator": "LaTeX with hyperref package"}}}