{"id": "1603.08091", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Mar-2016", "title": "Measuring Book Impact Based on the Multi-granularity Online Review Mining", "abstract": "As with articles and journals, the usual methods of measuring the academic impact of books mainly include quotations that are simple but limited to surveying traditional citation databases and scholarly book reviews. Meanwhile, researchers have tried to use other metrics such as Google Books, libcitation and publisher prestige. However, these approaches lack content-level information and we cannot determine users \"citation intentions. Meanwhile, the abundant online review resources for academic books can be used to mine deeper information and content using old-metric perspectives. In this study, we measure the impact of academic books using multigranularity online reviews and identify factors that affect the impact of a book. First, online reviews of a sample of academic books on Amazon.cn are crawled and processed. Then, multigranularity review mining is performed to measure the scientific impact of floating scientific books on ratings and aspects of negative reviews of books, and finally, the impact of reviews on the impact of reviews, with regard to the numbers and the impact of reviews.", "histories": [["v1", "Sat, 26 Mar 2016 09:25:16 GMT  (763kb)", "http://arxiv.org/abs/1603.08091v1", "21pages,3 figures, 12 tables"]], "COMMENTS": "21pages,3 figures, 12 tables", "reviews": [], "SUBJECTS": "cs.DL cs.CL", "authors": ["qingqing zhou", "chengzhi zhang", "star x zhao", "bikun chen"], "accepted": false, "id": "1603.08091"}, "pdf": {"name": "1603.08091.pdf", "metadata": {"source": "CRF", "title": "Measuring Book Impact Based on the Multi-granularity Online Review Mining", "authors": ["Qingqing Zhou", "X. Zhao", "Bikun Chen"], "emails": [], "sections": [{"heading": null, "text": "academic impact mainly involve citations, which is easy but limited to interrogating traditional citation databases and scholarly book reviews. Researchers have attempted to use other metrics, such as Google Books, libcitation, and publisher prestige. However, these approaches lack content-level information and cannot determine the citation intentions of users. Meanwhile, the abundant online review resources concerning academic books can be used to mine deeper information and content utilizing altmetric perspectives. In this study, we measure the impacts of academic books by multi-granularity mining online reviews, and we identify factors that affect a book\u2019s impact. First, online reviews of a sample of academic books on Amazon.cn are crawled and processed. Then, multi-granularity review mining is conducted to identify review sentiment polarities and aspects\u2019 sentiment values. Lastly, the numbers of positive reviews and negative reviews, aspect sentiment values, star values, and information regarding helpfulness are integrated via the entropy method, and lead to the calculation of the final book impact scores. The results of a correlation analysis of book impact scores obtained via our method versus traditional book citations show that, although there are substantial differences between subject areas, online book reviews tend to reflect the academic impact. Thus, we infer that online reviews represent a promising source for mining book impact within the altmetric perspective and at the multi-granularity content level. Moreover, our proposed method might also be a means by which to measure other books besides academic publications.\nKeywords: Online book reviews; Sentiment analysis; Book citation; Information content; Altmetrics"}, {"heading": "Introduction", "text": "Impact measures pertaining to academic publications usually focus on research articles. However, monographs are also an important form of academic output. Book impact measures, traditionally, are similar to those used for articles, journals, or other research, and mainly take citations into consideration. For example, Su (2009) analyzed the impact of social sciences and humanities books using the Chinese Social Sciences Citation Index. However, with the development of Web 2.0, researchers have increasingly applied alternative metrics to assess the qualities of academic publications. Kousha et al. (2011) examined whether online citations from Google Books and Google Scholar could provide alternative sources of citation evidence. However, prior research based on citation metrics has often ignored the content of the information, which encompasses the intention and motivation of its users. Thus, deeper intention cannot be mined through such methods. For example, sometimes a negative citing is counted as a positive citation. In the present case, book impact assessments based on citations may not be accurate enough.\nIn a bid to try to assess the academic impact of books more comprehensively, some researchers have endeavored to combine citations metrics with scholarly reviews about the books under consideration. For example, Nicolaisen (2002) proposed a bibliometric technique for determining the scholarliness of scholarly book reviews. Zuccala et al. (2014) employed a machine-learning approach to qualitatively code scholarly book reviews as quality indicators to assess a book\u2019s impact. Although such analysis indicates that it is useful to combine scholarly book reviews with citations, the large-scale peer review\n* Corresponding author: Chengzhi Zhang, E-mail: zhangcz@njust.edu.cn, Tel: +86-025-84315963.\nexercises required are expensive and time consuming. Also, existing research has neglected to incorporate sentiment information from the scholarly book reviews. Instead, online book reviews are abundant and widely available from e-commerce and social network websites, such as Amazon, LibraryThing, and Douban 1 . Compared with scholarly reviews, online reviews are plentiful and feature preferences expressed by users, which comprehensively and instantly reflect a book\u2019s impact. Hence, it may be worthwhile utilizing online reviews as an alternative impact measure.\nIn our study of measuring book impact in the online context, we propose a method based on multi-granularity mining of books\u2019 online reviews. This method aims to assess the impacts of academic books by mining online books reviews, and determining the most influential factors. We use online reviews of academic books as our dataset, and conduct multi-granularity mining on books reviews, in which macro-level review mining is used to identify the sentiment polarities of reviews and micro-level review mining is applied to calculate the sentiment values of aspects. Then, we apply the entropy method to integrate the values measured by review mining and compute the final book impact scores. In order to prove the validity of our method, correlation analysis between book impact scores obtained using our method and using traditional book citations is undertaken with the resultant significant correlations suggesting that online reviews can be used to measure book impact from an altmetric perspective."}, {"heading": "Related works", "text": "In this section, we describe three categories of related works: (1) traditional impact assessments, (2) alternative impact assessments, and (3) online review mining."}, {"heading": "Traditional impact assessments", "text": "Traditional impact assessments are mainly based on citations. Garfield (1972) used citation analysis as a tool in journal assessment, and found that journals can be ranked by frequency and impact of citations. Stremersch et al. (2007) demonstrated that citations were drivers of article impact by contrasting, synthesizing, and simultaneously testing three scientometric perspectives on the impact of article and author characteristics on article citations. Few prior studies, though, have paid much attention to book impact assessments.\nTorres-Salinas et al. (2012) analyzed different impact indicators referred to by scientific publishers and included in the Book Citation Index for the social sciences and humanities fields during 2006\u20132011. Also, with the development of Thomson Reuters\u2019 Web of Science, Elsevier\u2019s Scopus, and the aforementioned Book Citation Index (again maintained by Thomson Reuters), many researchers have begun to use these and similar citation indexing services to assess book impact. Bar-Ilan (2010) examined three citation databases (Google Scholar, Scopus, and Web of Science) through citations of the book Introduction to Informetrics published by Leo Egghe and Ronald Rousseau (1990), so as to identify similarities and differences between the results obtained through them. Studies such as these show that citations can be a valuable measurement for evaluating books, as well as monographs. However, it represents just the viewpoint of traditional and offline impact."}, {"heading": "Alternative impact assessments", "text": "Traditional, citation-based bibliometric methods are proving increasingly inadequate in the age of Web 2.0, and many researchers are seeking alternative metrics with which to assess various qualities of academic publications. Using the Web for research assessment, Kousha et al. (2010) introduced a new, combined, Integrated Online Impact indicator, and concluded that it can be used to help monitor research performance. Torres-Salinas et al. (2012) analyzed the different impact indicators referred to by book publishers in the Book Citation Index, while Gorraiz et al. (2013) introduced the Book Citation Index in detail, and Gorraiz et al. (2014) found that book reviews can be considered a suitable selection criterion for such a citation index.\nBornmann (2014) set out to ascertain whether altmetric data could validly be used for the measurement of societal impact with a comprehensive dataset from disparate sources. Shema et al. (2014) examined blog posts aggregated at ResearchBlogging.org, and, based on their results, suggested that blog citations could be used as an altmetric source. Torres-Salinas et al. (2014) used the Book Citation Index to analyze factors that determine the citation characteristics of books. Zuccala et al. (2015) assessed the value of reader ratings in Goodreads for measuring the wider impact of scholarly books published in the field of history. Their findings showed that, Goodreads, as a unique altmetric data source, could allow scholarly authors from the social sciences and humanities disciplines to measure the wider impact of their books. Haustein et al. (2015) discussed social media metrics in scholarly communication. Kousha and Thelwall (2015) assessed whether academic reviews in Choice (published\n1 http://www.douban.com (in Chinese).\nby the U.S. Association of College and Research Libraries) could be systematically used for indicators of scholarly impact, uptake, or educational value for scholarly books. Their findings showed that metrics derived from Choice academic book reviews could be used as indicators of different aspects for books, but more evidences were needed before they could be used as proxies for peer judgments of individual books.\nThese previous studies of alternative impact assessments reveal that, beyond the traditional methods like citations, more interesting perspectives of book impact measurement might be abstracted by using online or altmetric information."}, {"heading": "Online review mining", "text": "In order to assess book impact via online reviews from e-commerce or social network websites, a data mining method is applied to process these reviews. As a burgeoning research topic, review mining has already attracted a comprehensive set of theories and technologies. For example, Shi and Chang (2006) extracted product feature-orientation (sentiment) pairs from online product reviews, and Ding et al. (2008) determined the semantic orientations (positive, negative, or neutral) of opinions expressed on product features in reviews using a holistic lexicon-based approach. Chaovalit and Zhou (2005) compared supervised and unsupervised classification approaches to mine movie reviews, while Zhuang et al. (2006) integrated WordNet, statistical analysis, and movie knowledge to determine whether opinions were positive or negative. Specifically regarding books, Chevalier and Mayzlin (2006) examined the effect of consumer reviews on the relative sales of books on Amazon.com and BarnesandNoble.com, mentioning nothing about book impact. Conversely, Kousha and Thelwall (2016) assessed whether a number of simple metrics derived from Amazon.com reviews of academic books could give evidence about their respective impact.\nPrevious research on the academic impact of books has generally considered traditional citation databases, scholarly book reviews, and so on. Recently, Thelwall and Kousha (2015) did describe web indicators for the impact of books, such as Google Books, Libcitations, book reviews, online book reviews, and book review sentiments, but, as suggested above, most of the current research continues to rely on the data of the scientific literatures, which commonly either lacks content information or neglects reviews from e-commerce or social network websites. Some prior studies, such as Shaw (1991) and Kousha and Thelwall (2016), have paid attention to book review sentiments, but they generally neglect the fine-grained sentiments about aspects of books.\nIn the present study, we aim to measure the impact of academic books using multi-granularity mining on online book reviews of Amazon.cn (Amazon China). In contrast to Kousha and Thelwall\u2019s (2016) study, we conduct micro-level sentiment analysis to identify the most influential factors, and focus on the context and content of online book reviews. We expect that the method presented herein could lead to new insights into content-level evaluation of book impact."}, {"heading": "Research questions", "text": "This study aims to introduce a method for measuring academic book impact based on online content and sentiment analysis. In the empirical part of the study, we also try to evaluate whether online reviews are useful for the impact assessment of academic books. Additional research questions are addressed as follows:  Are online book reviews a sufficient academic book impact measure?  Which category of aspects most affects book impact: content-related aspects, publisher-related aspects, or operator-related aspects? For example, content, price, and packaging belong to these\nthree categories, respectively. If a book is published well or sold on a good e-commerce platform, it may be accessed and read by more people. Hence, publisher-related aspects and operator-related aspects need to be considered as well as content-related aspects.\n Do disciplinary differences affect the answers to the questions above?"}, {"heading": "Methodology Data collection", "text": "Academic books were used as the study\u2019s research samples, and, along with their citations, were selected using Su\u2019s (2011) \u201cA report on the academic impact of Chinese books in the humanities and social sciences,\u201d which covers 20 academic disciplines of Chinese books from the humanities and social sciences fields. References to each book in the report include its academic discipline, title, author, publication year, and citation, with the latter collected from the Chinese Social Sciences Citation Index 2 .\n2 http://cssci.nju.edu.cn/\nFor the present study, 544 economics books, 216 management books, 190 library and information science (LIS) books, 137 psychology books, and 428 literature books were chosen.\nAs noted above, most traditional reviews in this context are scholarly book reviews. Such appraisals are prefaced by the book\u2019s title, author, publisher, page extent, and price, after which the main content of the review is presented, including a content evaluation of the book and an academic impact evaluation; lastly, references and information about the review\u2019s author are presented. By contrast, in this study, the sample book reviews were taken from Amazon China (Amazon.cn), where they often differ in length and focus on diverse aspects of the same book. Fig. 1 shows a sample review of an edition of Karl Marx\u2019s Das Kapital (Capital in English), including the book\u2019s star rating (average customer rating using Amazon\u2019s 1\u20135 star scale), the review\u2019s contents, and a measure of its helpfulness. Star ratings reflects the overall assessment of a book by Amazon users (hereafter, \u201creview holders\u201d); a review\u2019s content is the main body of a book\u2019s review, reflecting users\u2019 intentions, sentiments, and assessments of the book; a review\u2019s helpfulness is judged by other users (hereafter, \u201creview evaluators\u201d) in terms of whether or not it proved useful for prospective readers/purchasers (Yin et al. 2014). Other Amazon users\u2014review evaluators\u2014can assess a book review\u2019s helpfulness by clicking on the \u201cYes\u201d or \u201cNo\u201d voting buttons, as applicable. Thereby, review helpfulness can be used to evaluate star ratings and review contents, potentially reducing the effects of fake and low-quality reviews.\nIn order to use online reviews to evaluate the academic impact of the study\u2019s sample books, we crawled the reviews of each candidate book listed on Amazon.cn in October 2014. Each review had to contain three parts\u2014\u201cstar rating,\u201d \u201creview contents,\u201d and \u201creview helpfulness\u201d\u2014and books with more than 10 reviews were extracted. Ultimately, 242 books, comprising 40 economics titles, 44 management titles, 30 psychology titles, 30 LIS titles, and 98 literature titles, were selected, the basic descriptive statistics for which are shown in Table 1.\ninformation for me.\nLiterature Old Tang Records Printing and paper is of\ntoo bad a quality. 5 9/10 346\na Macroeconomics by Rudiger Dornbusch (China Renmin University Press, 1997), A Theory of Justice by John Rawls (Harvard University Press, 1971), Understanding Media: The Extensions of Man by Marshall McLuhan (McGraw-Hill, 1964), Introduction to Cognitive Psychology by Danny Moates (Wadsworth Publishing Company, 1980), Old Tang Records by Liu Xun (Zhonghua Book Company, 1975).\nThe star ratings, review contents, and review helpfulness of each book were then extracted, by parsing the html file crawled from Amazon.cn. Table 2 presents the study\u2019s sample following the integration of the citation data with that for review content, star rating, and review helpfulness."}, {"heading": "Method", "text": "The primary purpose of this study is to specify how and whether it is feasible to measure the impact of academic books through the multi-granularity mining of online book reviews. For each book review, review content and a star rating are generated by the review holder. Meanwhile, review helpfulness is generated by review evaluators. Therefore, this study examines, first, the book impact measure and correlation analysis of information from review holders only, and, second, the book impact measure and correlation analysis of information from both the review holder and review evaluators. Fig. 2 summarizes the overall framework of the book impact measure and correlation analysis.\n(2) Factor calculation. Ratings range from one to five stars on Amazon.cn. Multi-granularity sentiment analysis of review content can be classified into \u201cmacro\u201d and \u201cmicro\u201d levels. Specifically, macro-level sentiment analysis is conducted to calculate the number of positive and negative reviews, while micro-level sentiment analysis is conducted to extract high-frequency aspects and calculate aspects\u2019 sentiment values. Aspects are usually the nouns in the review content, and reflect particular attributes of a book. For example, in the sentence \u201cThe content of this book is amazing,\u201d the aspect is \u201ccontent.\u201d Review helpfulness is calculated by the number of review evaluations. For example, in \u201c359 of 365 people think it is helpful,\u201d the value of helpfulness in the review is 359/365. Finally, the entropy method (Hongzhan et al. 2009) is used to integrate the values to obtain final book impact scores.\n(3) Multi-level correlation analysis. In order to corroborate the validity of multi-granularity online review mining, correlation analysis between book impact scores and book citations is investigated. In addition, in order to discover which aspects in a review affect citations most, correlation analysis are conducted. Moreover, in order to avoid the effect of the single aspect, the aspects are divided into three categories\u2014content related, publisher related, and operator related\u2014and then the correlation analysis is conducted.\nImpact measure and correlation analysis Factor combination Factors considered in this study were the \u201cnumber of positive reviews,\u201d the \u201cnumber of negative reviews,\u201d the \u201caspect sentiment value,\u201d the \u201cstar value,\u201d and the \u201chelpfulness value.\u201d Also, investigations of three levels of combinations were separately conducted for the \u201cReview holder\u201d and the \u201cReview holder & Reviewer evaluator\u201d parts, incorporating a macro-level combination, a micro-level combination, and a macro- and micro-level combination, as shown in Table 3."}, {"heading": "Factor calculation", "text": "As listed in Table 3, five factors were calculated for the \u201cReview holder\u201d and \u201cReview holder & Reviewer evaluator\u201d parts, respectively (the difference between the two parts being whether or not review helpfulness was taken into consideration), and the computation methods used for each factor is specified in this section.\nCalculating the number of positive reviews and negative reviews. Macro-level sentiment analysis was used to calculate the numbers of positive and negative reviews. First, word segmentation 3 was applied to the reviews. Then, the \u201cterm frequency\u2013inverse document frequency\u201d (TF\u2013IDF) method (Salton and McGill 1983) was applied to the segmented words in order to select feature words, with the aim of improving classification performance. This was calculated using equation (1):\n(1)\nwhere TF is \u201cterm frequency,\u201d and refers to the number of times a given word appears in the document;\nis the number of times a word term appears; is the number of words in the\ndocument; IDF is \u201cinverse document frequency,\u201d a measure of the general importance of words; denotes the number of documents; and stands for the number of documents containing the word term.\nFinally, a \u201csupport vector network\u201d (Cortes and Vapnik 1995) was used to conduct sentiment classification. The sentiment polarity (positive or negative) of each review was identified based on the classification results, and the numbers of positive reviews and negative reviews were then calculated.\nCalculating aspect sentiment values. A three-step calculation was used to determine the aspect sentiment values, incorporating: (1) aspect extraction, (2) aspect sentiment classification, and (3) aspect sentiment values calculation. In the first step, aspect extraction was conducted in three stages: (a) Chinese word segmentation of the reviews, (b) part-of-speech tagging and the selection of nouns as candidate aspects (as shown in Fig. 3, and (c) TF value calculations of each candidate aspect, and then selecting the top 10 high-frequency aspects.\nIn the second step, an aspect sentiment classification of each review was computed using equation (2)\n(Ding et al. 2008) with a sentiment lexicon: 4\n(2)\n3 Using Jieba (https://github.com/fxsjy/jieba) for the Chinese text segmentation. 4 Using SentiWordNet (http://sentiwordnet.isti.cnr.it/).\nwhere, for the sentiment polarity of aspect in review , n is the number of sentiment words in review ; denotes the sentiment value of sentiment word , and is equal to +1 if is a positive word, otherwise it is equal to \u22121; denotes the distance between aspect and sentiment word denotes the number of aspects; and is the number of reviews. So, for example, in \u201cThe content of this book is interesting, but the price is expensive,\u201d interesting is a positive sentiment word, and is equal to +1; expensive is a negative sentiment word, and is equal to\n\u22121; for the aspect content, , ; and, for the aspect price,\n, . Thus, the content in this review was found to be\npositive, while reference to the price was deemed to be negative.\nIn the third step, aspect sentiment value was calculated for \u201cReview holder\u201d and \u201cReview holder & Reviewer evaluator,\u201d according to whether or not the review\u2019s helpfulness was taken into consideration. Equation (3) calculates aspect sentiment value in the \u201cReview holder\u201d part without considering the review\u2019s helpfulness:\n(3)\nwhere, for aspect sentiment values of aspect about book , N is the number of reviews with aspect about book ; denotes the number of aspects; and is the number of books in each discipline.\nIn turn, aspect sentiment value in \u201cReview holder & Reviewer evaluator\u201d including review\nhelpfulness was computed by equation (4):\n(4)\nwhere, for aspect sentiment values of aspect about book , N is the number of reviews with aspect about book ; denotes the number of aspects; is the number of books in each discipline; and is the review helpfulness score of review .\nCalculating star value. Equation (5), without considering review helpfulness, gives the star value\ncalculation for the \u201cReview holder\u201d part as:\n(5)\nwhere, for star values of review about book , is the star score of review , ranging from 1 to 5; denotes the number of reviews about book ; and is the number of books of each discipline.\nIn turn, star value calculation in \u201cReview holder & Reviewer evaluator,\u201d including review helpfulness,\nwas computed by equation (6):\n(6)\nwhere, for star values of review about book , is the star score of review , ranging from 1 to 5; denotes the number of reviews about book ; means the number of books of each discipline; and is the helpfulness score of review .\nCalculating total score of a book via its reviews. After the five factors were calculated for the \u201cReview holder\u201d and the \u201cReview holder & Reviewer evaluator\u201d parts, the entropy method was used to calculate the factor weight and total book impact scores (Hongzhan et al. 2009), as shown in Table 4 (equations 7\u201310)."}, {"heading": "Multi-level correlation analysis", "text": "Two levels of correlations were analyzed in this study. We first conducted a correlation analysis of the book impact scores obtained using our method versus those determined through book citations, trying to find the most correlated combination, and, in turn, prove the reliability of our method. Then, correlation analysis was conducted between the aspect sentiment values of each category and citations of the books, with the aim of discovering which aspect categories most affect book impact."}, {"heading": "Results", "text": "Book rankings as computed by our proposed method are presented in the next section, followed by the results of the correlation analysis of the \u201cReview holder only\u201d and \u201cReview holder & Review evaluator\u201d parts. Finally, the results of the correlation analysis between book citations and sentiment values of high-frequency aspects are presented.\nBook rankings computed by multi-granularity online review mining Book rankings obtained using our method have two main parts\u2014\u201creview holders only\u201d and \u201creview holder & review evaluator\u201d\u2014each containing three levels of rankings: macro, micro, and macro and micro. Table 5 lists, as an example, the top 10 economics books, and it can be seen that while, overall, the top 10 books in each level are almost the same, their orders are different. The micro-level combination in \u201cReview holder only\u201d has the highest average (0.7824) and lowest variance (0.0123), suggesting that book impact scores calculated in this combination are generally higher. Scores for Economics (2004 edition) and Economics (1999 edition) are similar in all six combinations, which seems to indicate that different versions of the same book may get similar public evaluations.\nIn order to test the results obtained using our method, a correlation analysis of book impact scores\ncalculated using it versus those found using traditional book citations was undertaken.\nCorrelation analysis\u2014\u201cReview holder only\u201d A correlation analysis of rankings between the citations approach and the book impact scores obtained via our method was conducted for the \u201cReview holder only\u201d part across three levels of combination\u2014macro, micro, and macro and micro\u2014as shown in Table 6.\n* Correlation is significant at the 0.05 level (two-tailed) ** Correlation is significant at the 0.01 level (two-tailed)\nOverall, the book impact scores obtained using our method in the economics and management subject areas have significant positive Pearson correlations with the citations approach in all three combinations. Book scores for LIS publications have significant positive Pearson correlations with citations in both micro-level and macro- and micro-level combinations. Psychology book scores have a significant positive Pearson correlation with citations only in macro- and micro-level combinations, though, while the scores for literature titles show no significant correlation. Reasons for these findings may have to do with the professional degrees corresponding to the books and the educational background of their readers (Zhou and Zhang 2013). That is, books concerning economics, management, and LIS topics are relatively professional and their readers will often follow a definite, protracted educational advancement, whereas books in the psychology or literature categories are typically more popular in style and accessible to a far broader range of readers, each with a wide variety of attitudes and opinions. For the economics and management books in our study, correlations are higher in the micro-level combinations (0.538 and 0.423) and the macro- and micro-level combinations (0.383 and 0.401) than in the macro-level combinations (0.370 and 0.340). For the LIS and psychology titles, correlations are higher in the macro- and micro-level combinations (0.416 and 0.377) and the micro-level combinations (0.380 and none) than in the macro-level combinations. This finding suggests that aspects are important elements in the assessment of a book\u2019s impact.\nNext, in order to determine the most influential factor for each discipline in the \u201cReview holder only\u201d part, ranking correlation analysis between book citations and values of four single factors was conducted\u2014incorporating star values, number of positive reviews, number of negative reviews, and aspect sentiment values\u2014as shown in Table 7.\nCorrelations between citations and the values of the four factors are higher for economics (0.475, 0.352, and 0.528) and management (0.466, 0.340, and 0.425) than for LIS, psychology, and literature publications. The highest correlation between citations and factor values in economics is aspect sentiment values (0.528), followed by the number of positive reviews (0.475), while, in management, the highest correlation is the number of positive reviews (0.466), followed by aspect sentiment values (0.425). Hence, it seems that, in the \u201cReview holder only\u201d part, books with more reviews or higher aspect evaluations tend to be cited more often in some disciplines. In addition, factor combination is shown to be useful in measuring a book\u2019s impact.\nCorrelation analysis\u2014\u201cReview holder & Review evaluator\u201d In addition, a correlation analysis of rankings between the citations approach and the book impact scores obtained via our method was also conducted for the \u201cReview holder & Review evaluator\u201d part across three levels of combination\u2014macro, micro, and macro and micro\u2014as shown in Table 8.\nOverall, book impact scores via our method in macro- and micro-level combinations have significant positive Pearson correlations with citations in all disciplines, although the scores for literature show a less significant correlation. Compared with the results in Table 6, the correlation values shown in Table 8 are an improvement. This signifies that review helpfulness is useful in the correlation results, as well as affirming that online reviews can be used to assess a book\u2019s impact.\nIn terms of differences between the academic disciplines, the correlations between citations and book scores are distinct. In economics, the highest correlations between citations and the three combination levels are seen for the macro-level and micro-level combinations, while, in management, the highest correlation is for macro- and micro-level combinations, followed by micro-level combinations. In LIS, the highest correlations between citations and the three combination levels are seen for micro-level combinations, followed by macro- and micro-level combinations. As for the psychology and literature disciplines, only the macro- and micro-level combinations show a significant correlation. Only the macro- and micro-level combination has a significant correlation with citations in all the disciplines, from which finding it might be inferred that this combination will assess the academic impact of books more accurately.\nNext, in order to ascertain the most influential factor for each discipline in the \u201cReview holder & Review evaluator\u201d part, ranking correlation analysis between book citations and the values of four single factors was conducted, as shown in Table 9.\nAspect sentiment values \u22120.352* \u22120.340* \u22120.099 0.116 0.187\n* Correlation is significant at the 0.05 level (two-tailed)\n** Correlation is significant at the 0.01 level (two-tailed)\nCorrelations between citations and the values of the four factors are higher in the economics, management, and LIS subject areas than in psychology and literature. The highest correlation between citations and factor values in economics and management books are the number of negative reviews, followed by star values. For LIS publications, only star values have a significant correlation with citations. Hence, it seems that, in the \u201cReview holder & Review evaluator\u201d part, books with less negative reviews or a lower aspect evaluation tend to be highly cited, while books with higher star evaluations may have different impacts in different disciplines. The results for the psychology and literature titles also indicate that it is necessary to combine the factors, incorporating star values, the number of positive reviews, the number of negative reviews, and aspect sentiment values.\nCorrelation analysis\u2014citations versus sentiment values of high-frequency aspects The results of our correlation analysis of citations versus the sentiment values of high-frequency aspects are shown in Table 10. The aspect sentiment values were calculated using equation (4), as detailed above.\nIn all academic disciplines, there is no significant correlation between citations and the sentiment values of most aspects, which suggests that grouping and integrating the aspects is necessary. According to the degree of semantic correlation among aspects, we divided the top 10 aspects into three categories\u2014content related, publisher related, and operator related\u2014as shown in Table 11. Note that the aspect \u201cquality\u201d is an abstract noun and always co-concurrent with other frequent aspects, and cannot be distinguished clearly. Thus, it is not summarized into the three categories."}, {"heading": "Categories Aspects", "text": "The results of the correlation analysis of citations and the sentiment values of grouped aspects are presented in Table 12. Overall, aspect sentiment values in economics, management, and LIS show\nsignificant Pearson correlations with citations, while aspect sentiment values in psychology and literature show no significant correlation. These results are almost the same as those presented in Tables 8 and 10, supporting the inference that the differences between the disciplines lead to the phenomenon of correlation differences.\nThe highest correlations between citations and grouped aspect sentiment values in the economics, management, and LIS subject areas are content-related aspects (0.389, 0.437, and 0.474), followed by operator-related aspects (0.350, 0.366, and none). This finding may suggest that the content and translations of books are quite important in improving their academic impact, and that choosing a better operator (with good logistics and service) is also imperative."}, {"heading": "Discussion", "text": "This study used online book reviews to assess the impact of academic books. Compared with citation-based evaluation methods, our approach makes use of content information through the application of multi-granularity online review mining. It is thus not simply an analysis of the number of citations, but also an attempt to discover the meaning of each citation by mining content-level information. Thus, we posit that online reviews could prove a useful resource when assessing the academic impact of books.\nCompared with evaluation methods based on scholarly reviews, the review corpus for our method is much larger, as online reviews are multiple and updated quickly. With the development of technology concerned with web crawling, the cost of collecting online reviews is reducing. Moreover, online reviews are provided by the public, which reflecting the attitudes and opinions of book users directly. This viewpoint, in contrast to that of traditional impact measurement, leads to a much wider observation of book impacts. Thus, we advance our approach as an additional methodology for use within the toolbox of altmetrics.\nFor example, for the book Das Kapital, our method can not only discover its rank among the books to be assessed, but can also obtain its score (i.e., 0.7019 for the micro- and macro-level combinations in the \u201cReview holder & Review evaluator\u201d part). In addition, we can also calculate the sentiment score of each aspect, such as 0.2694 for content and 0.1071 for price. All of these sentiment scores are useful for improving books, too. For instance, when a book needs to be reprinted, related personnel can become very well informed about which aspects should have more attention paid to them.\nFinally, our method is not limited to the assessment of monographs, and can be applied to other forms of books, as well as to other academic entities, such as journals, articles, research papers, reports, and so on."}, {"heading": "Limitations", "text": "Our study is subject to a few limitations. First, its coverage was limited to five academic disciplines (economics, management, LIS, psychology, and literature), which were chosen as academic books in\nthese disciplines usually attract more online reviews than books from other disciplines in the social sciences and humanities fields\u2014hence their selection as a dataset for this, our preliminary study on the topic. Another limitation is that the method presented in this paper can only be used to assess books that have had online reviews prepared in relation to them. Some influential books, such as free EBooks, with no or few reviews cannot be assessed, and may be widely accessed, distributed, and cited without assessable online reviews. Also, the method might be not suitable for measuring new books.\nIn addition, the credibility of the reviews and our study\u2019s single data source may affect the generalizability of the results. Although data pertaining to \u201chelpfulness\u201d is used to reduce the impact of fake reviews, information relating to it is sparse for some books. Moreover, the sample data came from Amazon and thus may lack the diversity of reviews available from other websites. Amazon is an e-commerce website, and reviews featured on it, written by users, are usually quite short and may focus on, for example, the packaging of books, while other websites may feature different characteristic. For example, users of Douban.com might pay more attention to books\u2019 contents and prefer to give longer reviews. How best to integrate reviews from different websites is a challenging question for future research.\nFinally, the technologies of review mining need to be improved, including the systems for the identification of review sentiment polarities, aspect extraction, and the calculation of aspect sentiment values. In this study, we used a supervised method to classify review sentiments, based on the quality of a tagged corpus; if the scale of the data were to surge, the performance of sentiment analysis might diminish."}, {"heading": "Future studies", "text": "For future studies, following the present work, we propose a few interesting directions. First, scholarly book reviews could be combined with social media book reviews to get more comprehensive assessment results. Expert book reviews are usually provided by professional scholars, who primarily evaluate the contents of the books and assess their academic values; for example, Dugan (2008) commented on the contents of each part of the book Management Basics for Information Professionals first, and then evaluated its advantages and disadvantages. By contrast, online review information comes from the wider public, who reflect the different features of the books. When users give online reviews, they may not only consider the contents of a book, but also focus on other aspects, such as printing, packaging, etc. Online reviews of Management Basics for Information Professionals from Amazon, 5 in comparison with Dugan (2008), not only reviewed the content, but also evaluated the logistics, appearance, etc. In a further study, scholar book reviews could be collected from websites, such as that for Choice magazine (Kousha and Thelwall 2015), and reviews integrated from e-commerce websites and social media, in order to assess books and their impact more comprehensively.\nAdditional metrics might be considered to validate and strengthen the performance of our method, such as Google Book Search, Web of Science, etc. Also, location information could be taken into consideration to identify user differences across different regions. Sales information for the books, too, could be collected to prove the correlations between citations and the three combination levels discussed above.\nFinally, our method is not limited to the assessment of Chinese books, and should be applied to books published in other languages. As diverse language users may possess regional distinctions (Zhou et al.\n5 http://www.amazon.com/Management-Basics-Information-Professionals-Edition/product-reiews/1555709095/ref =cm_cr_dp_see_all_btm?ie=UTF8&showViewpoints=1&sortBy=recent (accessed Feb 02, 2016).\n2016), difference analysis among different language reviews is also a topic that might usefully be explored further. Moreover, due to the development of the natural language process, our method will become more accurate and operable."}, {"heading": "Conclusions", "text": "This study introduced a framework for measuring book impact according to online reviews and their content. We assessed how online reviews can be used for book evaluations, and found some positive results. In answer to our first research question, online reviews do seem to be valuable for use in the impact assessment of academic books. The multi-granularity mining of such reviews can be applied to identify their sentiment polarities and aspect sentiment values.\nRegarding the second research question, content-related aspects have the highest correlation values, followed by operator-related aspects. This suggests that the contents and translations of books are, perhaps unsurprisingly, particularly important in improving the impact of academic books, while choosing a superior operator (with good logistics and service offerings) is also important.\nFinally, addressing the third research question, there are clear differences between books published in different academic categories. In economics, management, and LIS disciplines, there were found to be significant positive Pearson correlations between book scores obtained via our method and from citations, while, in the psychology and literature disciplines, there were less or no significant correlations. As theorized above, the reason for this likely lies in the dissimilar readerships (attitudes, opinions, user intentions) and markets for books published in the economics, management, and LIS fields and the more popular titles published in the psychology and literature categories.\nAs a new and comprehensive perspective for the measurement of book impacts, our method is set to serve as an effective alternative metric with which to assess the qualities of academic publications in the era of Web 2.0 and the development of altmetrics. The theoretical implication of our study lies in the idea that future measurements of altmetrics should incorporate content and sentiment within the web information. The value of motivation analysis is not only revealed in altmetrics, but can also be an important perspective within traditional citation analysis and citation motivation studies. In practice, our method makes enhanced use of current functions and information in social networks and e-commerce sites. Its use could provide interesting solutions at the level of application and inspire more effective communication rules or marketing strategies. As online reviews about authors, journals, and even universities or other institutions can be collected from social media websites, our method has the potential to assess the impacts of these too, although its use has been restricted to measuring book impact in the present study."}], "references": [{"title": "Citations to the \u201cIntroduction to informetrics\u201d indexed by WOS, Scopus and Google Scholar", "author": ["J. Bar-Ilan"], "venue": null, "citeRegEx": "Bar.Ilan,? \\Q2010\\E", "shortCiteRegEx": "Bar.Ilan", "year": 2010}, {"title": "Validity of altmetrics data for measuring societal impact: A study using data from Altmetric", "author": ["L. Bornmann"], "venue": null, "citeRegEx": "Bornmann,? \\Q2014\\E", "shortCiteRegEx": "Bornmann", "year": 2014}, {"title": "Movie review mining: A comparison between supervised and unsupervised", "author": ["P. Chaovalit", "L. Zhou"], "venue": null, "citeRegEx": "Chaovalit and Zhou,? \\Q2005\\E", "shortCiteRegEx": "Chaovalit and Zhou", "year": 2005}, {"title": "The effect of word of mouth on sales: Online book reviews", "author": ["J.A. Chevalier", "D. Mayzlin"], "venue": null, "citeRegEx": "Chevalier and Mayzlin,? \\Q2006\\E", "shortCiteRegEx": "Chevalier and Mayzlin", "year": 2006}, {"title": "A holistic lexicon-based approach to opinion mining", "author": ["C. Cortes", "V. Vapnik"], "venue": "Support\u2013vector networks. Machine learning,", "citeRegEx": "Cortes and Vapnik,? \\Q1995\\E", "shortCiteRegEx": "Cortes and Vapnik", "year": 1995}, {"title": "Association for Computing Machinery", "author": ["NY York"], "venue": "Dugan, R. E", "citeRegEx": "York,? \\Q2008\\E", "shortCiteRegEx": "York", "year": 2008}, {"title": "Introduction to informetrics: Quantitative methods in library, documentation", "author": ["L. Egghe", "R. Rousseau"], "venue": null, "citeRegEx": "Egghe and Rousseau,? \\Q1990\\E", "shortCiteRegEx": "Egghe and Rousseau", "year": 1990}, {"title": "Citation analysis as a tool in journal evaluation", "author": ["J. Gorraiz", "C. Gumpenberger", "P.J. Purnell"], "venue": null, "citeRegEx": "Gorraiz et al\\.,? \\Q1972\\E", "shortCiteRegEx": "Gorraiz et al\\.", "year": 1972}, {"title": "enhancement approach for book citation indexes", "author": ["J. Gorraiz", "P.J. Purnell", "W. Gl\u00e4nzel"], "venue": null, "citeRegEx": "Gorraiz et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gorraiz et al\\.", "year": 2013}, {"title": "Comprehensive fuzzy evaluation for transmission network planning scheme based on entropy weight method", "author": ["Q.Y. Pan", "X. Yao"], "venue": "Power System Technology,", "citeRegEx": "Pan and Yao,? \\Q2009\\E", "shortCiteRegEx": "Pan and Yao", "year": 2009}, {"title": "Alternative metrics for book impact assessment: Can Choice reviews be a useful source", "author": ["K. Kousha", "M. Thelwall"], "venue": "Proceedings of the 15th international conference on scientometrics and informetrics (pp. 59\u201370)", "citeRegEx": "Kousha and Thelwall,? \\Q2015\\E", "shortCiteRegEx": "Kousha and Thelwall", "year": 2015}, {"title": "Can Amazon.com reviews help to assess the wider impacts of books? Journal of the Association for Information", "author": ["K. Kousha", "M. Thelwall"], "venue": "Science and Technology,", "citeRegEx": "Kousha and Thelwall,? \\Q2016\\E", "shortCiteRegEx": "Kousha and Thelwall", "year": 2016}, {"title": "Using the web for research evaluation: The integrated online impact indicator", "author": ["K. Kousha", "M. Thelwall", "S. Rezaie"], "venue": "Journal of Informetrics,", "citeRegEx": "Kousha et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kousha et al\\.", "year": 2010}, {"title": "Assessing the citation impact of books: The role of Google Books, Google Scholar, and Scopus", "author": ["K. Kousha", "M. Thelwall", "S. Rezaie"], "venue": "Journal of the American Society for Information Science and Technology,", "citeRegEx": "Kousha et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kousha et al\\.", "year": 2011}, {"title": "The scholarliness of published peer reviews: A bibliometric study of book reviews in selected social science fields", "author": ["J. Nicolaisen"], "venue": "Research Evaluation,", "citeRegEx": "Nicolaisen,? \\Q2002\\E", "shortCiteRegEx": "Nicolaisen", "year": 2002}, {"title": "Introduction to modern information retrieval", "author": ["G. Salton", "M.J. McGill"], "venue": null, "citeRegEx": "Salton and McGill,? \\Q1983\\E", "shortCiteRegEx": "Salton and McGill", "year": 1983}, {"title": "An analysis of the relationship between book reviews and fiction Hholdings in OCLC", "author": ["D. Shaw"], "venue": "Library & Information Science Research,", "citeRegEx": "Shaw,? \\Q1991\\E", "shortCiteRegEx": "Shaw", "year": 1991}, {"title": "Do blog citations correlate with a higher number of future citations? Research blogs as a potential source for alternative metrics", "author": ["H. Shema", "J. Bar-Ilan", "M. Thelwall"], "venue": "Journal of the Association for Information Science and Technology,", "citeRegEx": "Shema et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Shema et al\\.", "year": 2014}, {"title": "Mining Chinese reviews", "author": ["B. Shi", "K. Chang"], "venue": "In Proceedings of the sixth IEEE international conference on data mining workshops (pp. 585\u2013589)", "citeRegEx": "Shi and Chang,? \\Q2006\\E", "shortCiteRegEx": "Shi and Chang", "year": 2006}, {"title": "The quest for citations: Drivers of article impact", "author": ["S. Stremersch", "I. Verniers", "P.C. Verhoef"], "venue": "Journal of Marketing,", "citeRegEx": "Stremersch et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Stremersch et al\\.", "year": 2007}, {"title": "Citation analysis on Chinese books of humanities and social sciences\u2014based on the CSSCI database", "author": ["X. Su"], "venue": "Donyue Tribune,", "citeRegEx": "Su,? \\Q2009\\E", "shortCiteRegEx": "Su", "year": 2009}, {"title": "A report on the academic influence of Chinese humanity and social science", "author": ["X. Su"], "venue": null, "citeRegEx": "Su,? \\Q2011\\E", "shortCiteRegEx": "Su", "year": 2011}, {"title": "Web indicators for research evaluation. Part 3: books and non-standard outputs", "author": ["M. Thelwall", "K. Kousha"], "venue": "El Profesional De La Informacio\u0301n,", "citeRegEx": "Thelwall and Kousha,? \\Q2015\\E", "shortCiteRegEx": "Thelwall and Kousha", "year": 2015}, {"title": "Analyzing the citation characteristics of books: Edited books, book series and publisher types in the book citation", "author": ["D. Torres-Salinas", "N. Robinson-Garc\u00eda", "\u00c1. Cabezas-Clavijo", "E. Jim\u00e9nez-Contreras"], "venue": "index. Scientometrics,", "citeRegEx": "Torres.Salinas et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Torres.Salinas et al\\.", "year": 2014}, {"title": "Towards a Book Publishers Citation Reports. First approach using the Book Citation Index", "author": ["D. Torres-Salinas", "N. Robinson-Garc\u00eda", "E. Jim\u00e9nez-Contreras", "E.D. L\u00f3pez-C\u00f3zar"], "venue": "Revista Espaola De Documentacio\u0301n Cienti\u0301fica,", "citeRegEx": "Torres.Salinas et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Torres.Salinas et al\\.", "year": 2012}, {"title": "Anxious or angry? Effects of discrete emotions on the perceived helpfulness of online reviews", "author": ["D. Yin", "S.D. Bond", "H. Zhang"], "venue": "MIS Quarterly,", "citeRegEx": "Yin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yin et al\\.", "year": 2014}, {"title": "Online shopping behavior study based on multi-granularity opinion mining: China versus America", "author": ["Q. Zhou", "R. Xia", "C. Zhang"], "venue": "Cognitive Computation. Published online ahead of print. doi:10.1007/s12559-016-9384-x", "citeRegEx": "Zhou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2016}, {"title": "Relationship between scores and tags for Chinese books\u2014in the case of Douban", "author": ["Q. Zhou", "C. Zhang"], "venue": "Book. Chinese Journal of Library and Information", "citeRegEx": "Zhou and Zhang,? \\Q2013\\E", "shortCiteRegEx": "Zhou and Zhang", "year": 2013}, {"title": "Movie review mining and summarization", "author": ["L. Zhuang", "F. Jing", "Zhu", "X.-Y"], "venue": "Proceedings of the 15th ACM international conference on information and knowledge management (pp. 43\u201350)", "citeRegEx": "Zhuang et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Zhuang et al\\.", "year": 2006}, {"title": "A machine-learning approach to coding book reviews as quality indicators: Toward a theory of megacitation", "author": ["A. Zuccala", "M. Someren", "M. Bellen"], "venue": "Journal of the Association for Information Science and Technology,", "citeRegEx": "Zuccala et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zuccala et al\\.", "year": 2014}, {"title": "Altmetrics for the humanities: Comparing Goodreads reader ratings with citations to history books", "author": ["A. Zuccala", "F.T. Verleysen", "R. Cornacchia", "T.C. Engels", "D. Lewandowski", "S. Haustein"], "venue": "Aslib Journal of Information Management,", "citeRegEx": "Zuccala et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zuccala et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 17, "context": "For example, Su (2009) analyzed the impact of social sciences and humanities books using the Chinese Social Sciences Citation Index.", "startOffset": 13, "endOffset": 23}, {"referenceID": 12, "context": "Kousha et al. (2011) examined whether online citations from Google Books and Google Scholar could provide alternative sources of citation evidence.", "startOffset": 0, "endOffset": 21}, {"referenceID": 12, "context": "Kousha et al. (2011) examined whether online citations from Google Books and Google Scholar could provide alternative sources of citation evidence. However, prior research based on citation metrics has often ignored the content of the information, which encompasses the intention and motivation of its users. Thus, deeper intention cannot be mined through such methods. For example, sometimes a negative citing is counted as a positive citation. In the present case, book impact assessments based on citations may not be accurate enough. In a bid to try to assess the academic impact of books more comprehensively, some researchers have endeavored to combine citations metrics with scholarly reviews about the books under consideration. For example, Nicolaisen (2002) proposed a bibliometric technique for determining the scholarliness of scholarly book reviews.", "startOffset": 0, "endOffset": 768}, {"referenceID": 12, "context": "Kousha et al. (2011) examined whether online citations from Google Books and Google Scholar could provide alternative sources of citation evidence. However, prior research based on citation metrics has often ignored the content of the information, which encompasses the intention and motivation of its users. Thus, deeper intention cannot be mined through such methods. For example, sometimes a negative citing is counted as a positive citation. In the present case, book impact assessments based on citations may not be accurate enough. In a bid to try to assess the academic impact of books more comprehensively, some researchers have endeavored to combine citations metrics with scholarly reviews about the books under consideration. For example, Nicolaisen (2002) proposed a bibliometric technique for determining the scholarliness of scholarly book reviews. Zuccala et al. (2014) employed a machine-learning approach to qualitatively code scholarly book reviews as quality indicators to assess a book\u2019s impact.", "startOffset": 0, "endOffset": 885}, {"referenceID": 18, "context": "Stremersch et al. (2007) demonstrated that citations were drivers of article impact by contrasting, synthesizing, and simultaneously testing three scientometric perspectives on the impact of article and author characteristics on article citations.", "startOffset": 0, "endOffset": 25}, {"referenceID": 18, "context": "Stremersch et al. (2007) demonstrated that citations were drivers of article impact by contrasting, synthesizing, and simultaneously testing three scientometric perspectives on the impact of article and author characteristics on article citations. Few prior studies, though, have paid much attention to book impact assessments. Torres-Salinas et al. (2012) analyzed different impact indicators referred to by scientific publishers and included in the Book Citation Index for the social sciences and humanities fields during 2006\u20132011.", "startOffset": 0, "endOffset": 357}, {"referenceID": 0, "context": "Bar-Ilan (2010) examined three citation databases (Google Scholar, Scopus, and Web of Science) through citations of the book Introduction to Informetrics published by Leo Egghe and Ronald Rousseau (1990), so as to identify similarities and differences between the results obtained through them.", "startOffset": 0, "endOffset": 16}, {"referenceID": 0, "context": "Bar-Ilan (2010) examined three citation databases (Google Scholar, Scopus, and Web of Science) through citations of the book Introduction to Informetrics published by Leo Egghe and Ronald Rousseau (1990), so as to identify similarities and differences between the results obtained through them.", "startOffset": 0, "endOffset": 204}, {"referenceID": 7, "context": "Using the Web for research assessment, Kousha et al. (2010) introduced a new, combined, Integrated Online Impact indicator, and concluded that it can be used to help monitor research performance.", "startOffset": 39, "endOffset": 60}, {"referenceID": 7, "context": "Using the Web for research assessment, Kousha et al. (2010) introduced a new, combined, Integrated Online Impact indicator, and concluded that it can be used to help monitor research performance. Torres-Salinas et al. (2012) analyzed the different impact indicators referred to by book publishers in the Book Citation Index, while Gorraiz et al.", "startOffset": 39, "endOffset": 225}, {"referenceID": 6, "context": "(2012) analyzed the different impact indicators referred to by book publishers in the Book Citation Index, while Gorraiz et al. (2013) introduced the Book Citation Index in detail, and Gorraiz et al.", "startOffset": 113, "endOffset": 135}, {"referenceID": 6, "context": "(2012) analyzed the different impact indicators referred to by book publishers in the Book Citation Index, while Gorraiz et al. (2013) introduced the Book Citation Index in detail, and Gorraiz et al. (2014) found that book reviews can be considered a suitable selection criterion for such a citation index.", "startOffset": 113, "endOffset": 207}, {"referenceID": 1, "context": "Bornmann (2014) set out to ascertain whether altmetric data could validly be used for the measurement of societal impact with a comprehensive dataset from disparate sources.", "startOffset": 0, "endOffset": 16}, {"referenceID": 1, "context": "Bornmann (2014) set out to ascertain whether altmetric data could validly be used for the measurement of societal impact with a comprehensive dataset from disparate sources. Shema et al. (2014) examined blog posts aggregated at ResearchBlogging.", "startOffset": 0, "endOffset": 194}, {"referenceID": 1, "context": "Bornmann (2014) set out to ascertain whether altmetric data could validly be used for the measurement of societal impact with a comprehensive dataset from disparate sources. Shema et al. (2014) examined blog posts aggregated at ResearchBlogging.org, and, based on their results, suggested that blog citations could be used as an altmetric source. Torres-Salinas et al. (2014) used the Book Citation Index to analyze factors that determine the citation characteristics of books.", "startOffset": 0, "endOffset": 376}, {"referenceID": 1, "context": "Bornmann (2014) set out to ascertain whether altmetric data could validly be used for the measurement of societal impact with a comprehensive dataset from disparate sources. Shema et al. (2014) examined blog posts aggregated at ResearchBlogging.org, and, based on their results, suggested that blog citations could be used as an altmetric source. Torres-Salinas et al. (2014) used the Book Citation Index to analyze factors that determine the citation characteristics of books. Zuccala et al. (2015) assessed the value of reader ratings in Goodreads for measuring the wider impact of scholarly books published in the field of history.", "startOffset": 0, "endOffset": 500}, {"referenceID": 1, "context": "Bornmann (2014) set out to ascertain whether altmetric data could validly be used for the measurement of societal impact with a comprehensive dataset from disparate sources. Shema et al. (2014) examined blog posts aggregated at ResearchBlogging.org, and, based on their results, suggested that blog citations could be used as an altmetric source. Torres-Salinas et al. (2014) used the Book Citation Index to analyze factors that determine the citation characteristics of books. Zuccala et al. (2015) assessed the value of reader ratings in Goodreads for measuring the wider impact of scholarly books published in the field of history. Their findings showed that, Goodreads, as a unique altmetric data source, could allow scholarly authors from the social sciences and humanities disciplines to measure the wider impact of their books. Haustein et al. (2015) discussed social media metrics in scholarly communication.", "startOffset": 0, "endOffset": 858}, {"referenceID": 1, "context": "Bornmann (2014) set out to ascertain whether altmetric data could validly be used for the measurement of societal impact with a comprehensive dataset from disparate sources. Shema et al. (2014) examined blog posts aggregated at ResearchBlogging.org, and, based on their results, suggested that blog citations could be used as an altmetric source. Torres-Salinas et al. (2014) used the Book Citation Index to analyze factors that determine the citation characteristics of books. Zuccala et al. (2015) assessed the value of reader ratings in Goodreads for measuring the wider impact of scholarly books published in the field of history. Their findings showed that, Goodreads, as a unique altmetric data source, could allow scholarly authors from the social sciences and humanities disciplines to measure the wider impact of their books. Haustein et al. (2015) discussed social media metrics in scholarly communication. Kousha and Thelwall (2015) assessed whether academic reviews in Choice (published", "startOffset": 0, "endOffset": 944}, {"referenceID": 13, "context": "For example, Shi and Chang (2006) extracted product feature-orientation (sentiment) pairs from online product reviews, and Ding et al.", "startOffset": 13, "endOffset": 34}, {"referenceID": 13, "context": "For example, Shi and Chang (2006) extracted product feature-orientation (sentiment) pairs from online product reviews, and Ding et al. (2008) determined the semantic orientations (positive, negative, or neutral) of opinions expressed on product features in reviews using a holistic lexicon-based approach.", "startOffset": 13, "endOffset": 142}, {"referenceID": 2, "context": "Chaovalit and Zhou (2005) compared supervised and unsupervised classification approaches to mine movie reviews, while Zhuang et al.", "startOffset": 0, "endOffset": 26}, {"referenceID": 2, "context": "Chaovalit and Zhou (2005) compared supervised and unsupervised classification approaches to mine movie reviews, while Zhuang et al. (2006) integrated WordNet, statistical analysis, and movie knowledge to determine whether opinions were positive or negative.", "startOffset": 0, "endOffset": 139}, {"referenceID": 2, "context": "Chaovalit and Zhou (2005) compared supervised and unsupervised classification approaches to mine movie reviews, while Zhuang et al. (2006) integrated WordNet, statistical analysis, and movie knowledge to determine whether opinions were positive or negative. Specifically regarding books, Chevalier and Mayzlin (2006) examined the effect of consumer reviews on the relative sales of books on Amazon.", "startOffset": 0, "endOffset": 317}, {"referenceID": 2, "context": "Chaovalit and Zhou (2005) compared supervised and unsupervised classification approaches to mine movie reviews, while Zhuang et al. (2006) integrated WordNet, statistical analysis, and movie knowledge to determine whether opinions were positive or negative. Specifically regarding books, Chevalier and Mayzlin (2006) examined the effect of consumer reviews on the relative sales of books on Amazon.com and BarnesandNoble.com, mentioning nothing about book impact. Conversely, Kousha and Thelwall (2016) assessed whether a number of simple metrics derived from Amazon.", "startOffset": 0, "endOffset": 503}, {"referenceID": 2, "context": "Chaovalit and Zhou (2005) compared supervised and unsupervised classification approaches to mine movie reviews, while Zhuang et al. (2006) integrated WordNet, statistical analysis, and movie knowledge to determine whether opinions were positive or negative. Specifically regarding books, Chevalier and Mayzlin (2006) examined the effect of consumer reviews on the relative sales of books on Amazon.com and BarnesandNoble.com, mentioning nothing about book impact. Conversely, Kousha and Thelwall (2016) assessed whether a number of simple metrics derived from Amazon.com reviews of academic books could give evidence about their respective impact. Previous research on the academic impact of books has generally considered traditional citation databases, scholarly book reviews, and so on. Recently, Thelwall and Kousha (2015) did describe web indicators for the impact of books, such as Google Books, Libcitations, book reviews, online book reviews, and book review sentiments, but, as suggested above, most of the current research continues to rely on the data of the scientific literatures, which commonly either lacks content information or neglects reviews from e-commerce or social network websites.", "startOffset": 0, "endOffset": 827}, {"referenceID": 2, "context": "Chaovalit and Zhou (2005) compared supervised and unsupervised classification approaches to mine movie reviews, while Zhuang et al. (2006) integrated WordNet, statistical analysis, and movie knowledge to determine whether opinions were positive or negative. Specifically regarding books, Chevalier and Mayzlin (2006) examined the effect of consumer reviews on the relative sales of books on Amazon.com and BarnesandNoble.com, mentioning nothing about book impact. Conversely, Kousha and Thelwall (2016) assessed whether a number of simple metrics derived from Amazon.com reviews of academic books could give evidence about their respective impact. Previous research on the academic impact of books has generally considered traditional citation databases, scholarly book reviews, and so on. Recently, Thelwall and Kousha (2015) did describe web indicators for the impact of books, such as Google Books, Libcitations, book reviews, online book reviews, and book review sentiments, but, as suggested above, most of the current research continues to rely on the data of the scientific literatures, which commonly either lacks content information or neglects reviews from e-commerce or social network websites. Some prior studies, such as Shaw (1991) and Kousha and Thelwall (2016), have paid attention to book review sentiments, but they generally neglect the fine-grained sentiments about aspects of books.", "startOffset": 0, "endOffset": 1246}, {"referenceID": 2, "context": "Chaovalit and Zhou (2005) compared supervised and unsupervised classification approaches to mine movie reviews, while Zhuang et al. (2006) integrated WordNet, statistical analysis, and movie knowledge to determine whether opinions were positive or negative. Specifically regarding books, Chevalier and Mayzlin (2006) examined the effect of consumer reviews on the relative sales of books on Amazon.com and BarnesandNoble.com, mentioning nothing about book impact. Conversely, Kousha and Thelwall (2016) assessed whether a number of simple metrics derived from Amazon.com reviews of academic books could give evidence about their respective impact. Previous research on the academic impact of books has generally considered traditional citation databases, scholarly book reviews, and so on. Recently, Thelwall and Kousha (2015) did describe web indicators for the impact of books, such as Google Books, Libcitations, book reviews, online book reviews, and book review sentiments, but, as suggested above, most of the current research continues to rely on the data of the scientific literatures, which commonly either lacks content information or neglects reviews from e-commerce or social network websites. Some prior studies, such as Shaw (1991) and Kousha and Thelwall (2016), have paid attention to book review sentiments, but they generally neglect the fine-grained sentiments about aspects of books.", "startOffset": 0, "endOffset": 1277}, {"referenceID": 2, "context": "Chaovalit and Zhou (2005) compared supervised and unsupervised classification approaches to mine movie reviews, while Zhuang et al. (2006) integrated WordNet, statistical analysis, and movie knowledge to determine whether opinions were positive or negative. Specifically regarding books, Chevalier and Mayzlin (2006) examined the effect of consumer reviews on the relative sales of books on Amazon.com and BarnesandNoble.com, mentioning nothing about book impact. Conversely, Kousha and Thelwall (2016) assessed whether a number of simple metrics derived from Amazon.com reviews of academic books could give evidence about their respective impact. Previous research on the academic impact of books has generally considered traditional citation databases, scholarly book reviews, and so on. Recently, Thelwall and Kousha (2015) did describe web indicators for the impact of books, such as Google Books, Libcitations, book reviews, online book reviews, and book review sentiments, but, as suggested above, most of the current research continues to rely on the data of the scientific literatures, which commonly either lacks content information or neglects reviews from e-commerce or social network websites. Some prior studies, such as Shaw (1991) and Kousha and Thelwall (2016), have paid attention to book review sentiments, but they generally neglect the fine-grained sentiments about aspects of books. In the present study, we aim to measure the impact of academic books using multi-granularity mining on online book reviews of Amazon.cn (Amazon China). In contrast to Kousha and Thelwall\u2019s (2016) study, we conduct micro-level sentiment analysis to identify the most influential factors, and focus on the context and content of online book reviews.", "startOffset": 0, "endOffset": 1600}, {"referenceID": 20, "context": "Methodology Data collection Academic books were used as the study\u2019s research samples, and, along with their citations, were selected using Su\u2019s (2011) \u201cA report on the academic impact of Chinese books in the humanities and social sciences,\u201d which covers 20 academic disciplines of Chinese books from the humanities and social sciences fields.", "startOffset": 139, "endOffset": 151}, {"referenceID": 25, "context": "Star ratings reflects the overall assessment of a book by Amazon users (hereafter, \u201creview holders\u201d); a review\u2019s content is the main body of a book\u2019s review, reflecting users\u2019 intentions, sentiments, and assessments of the book; a review\u2019s helpfulness is judged by other users (hereafter, \u201creview evaluators\u201d) in terms of whether or not it proved useful for prospective readers/purchasers (Yin et al. 2014).", "startOffset": 389, "endOffset": 406}, {"referenceID": 15, "context": "Then, the \u201cterm frequency\u2013inverse document frequency\u201d (TF\u2013IDF) method (Salton and McGill 1983) was applied to the segmented words in order to select feature words, with the aim of improving classification performance.", "startOffset": 70, "endOffset": 94}, {"referenceID": 4, "context": "Finally, a \u201csupport vector network\u201d (Cortes and Vapnik 1995) was used to conduct sentiment classification.", "startOffset": 36, "endOffset": 60}, {"referenceID": 27, "context": "Reasons for these findings may have to do with the professional degrees corresponding to the books and the educational background of their readers (Zhou and Zhang 2013).", "startOffset": 147, "endOffset": 168}, {"referenceID": 10, "context": "In a further study, scholar book reviews could be collected from websites, such as that for Choice magazine (Kousha and Thelwall 2015), and reviews integrated from e-commerce websites and social media, in order to assess books and their impact more comprehensively.", "startOffset": 108, "endOffset": 134}], "year": 2016, "abstractText": "As with articles and journals, the customary methods for measuring books\u2019 academic impact mainly involve citations, which is easy but limited to interrogating traditional citation databases and scholarly book reviews. Researchers have attempted to use other metrics, such as Google Books, libcitation, and publisher prestige. However, these approaches lack content-level information and cannot determine the citation intentions of users. Meanwhile, the abundant online review resources concerning academic books can be used to mine deeper information and content utilizing altmetric perspectives. In this study, we measure the impacts of academic books by multi-granularity mining online reviews, and we identify factors that affect a book\u2019s impact. First, online reviews of a sample of academic books on Amazon.cn are crawled and processed. Then, multi-granularity review mining is conducted to identify review sentiment polarities and aspects\u2019 sentiment values. Lastly, the numbers of positive reviews and negative reviews, aspect sentiment values, star values, and information regarding helpfulness are integrated via the entropy method, and lead to the calculation of the final book impact scores. The results of a correlation analysis of book impact scores obtained via our method versus traditional book citations show that, although there are substantial differences between subject areas, online book reviews tend to reflect the academic impact. Thus, we infer that online reviews represent a promising source for mining book impact within the altmetric perspective and at the multi-granularity content level. Moreover, our proposed method might also be a means by which to measure other books besides academic publications.", "creator": "Microsoft\u00ae Word 2010"}}}