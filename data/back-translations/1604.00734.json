{"id": "1604.00734", "review": {"conference": "HLT-NAACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Apr-2016", "title": "Capturing Semantic Similarity for Entity Linking with Convolutional Neural Networks", "abstract": "A key challenge in linking entities is the effective use of context information to identify distinct mentions that can relate to different entities in different contexts. We present a model that uses Convolutionary Neural Networks to capture semantic similarities between the context of a mention and a proposed target unit. These Convolutionary Networks work with multiple granularities to utilize different types of topic information, and their rich parameterization gives them the ability to learn which n-grams characterize different topics. We combine these networks with a sparse linear model to achieve state-of-the-art performance in linking multiple entities, surpassing the earlier systems of Durrett and Klein (2014) and Nguyen et al. (2014).", "histories": [["v1", "Mon, 4 Apr 2016 03:58:31 GMT  (121kb,D)", "http://arxiv.org/abs/1604.00734v1", "Accepted at NAACL 2016"]], "COMMENTS": "Accepted at NAACL 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["matthew francis-landau", "greg durrett", "dan klein"], "accepted": true, "id": "1604.00734"}, "pdf": {"name": "1604.00734.pdf", "metadata": {"source": "CRF", "title": "Capturing Semantic Similarity for Entity Linking with Convolutional Neural Networks", "authors": ["Matthew Francis-Landau", "Greg Durrett", "Dan Klein"], "emails": ["mfl@cs.berkeley.edu", "gdurrett@cs.berkeley.edu", "klein@cs.berkeley.edu"], "sections": [{"heading": "1 Introduction", "text": "One of the major challenges of entity linking is resolving contextually polysemous mentions. For example, Germany may refer to a nation, to that nation\u2019s government, or even to a soccer team. Past approaches to such cases have often focused on collective entity linking: nearby mentions in a document might be expected to link to topically-similar entities, which can give us clues about the identity of the mention currently being resolved (Ratinov et al., 2011; Hoffart et al., 2011; He et al., 2013; Cheng and Roth, 2013; Durrett and Klein, 2014). But an even simpler approach is to use context information from just the words in the source document itself to make sure the entity is being resolved sensibly in context. In past work, these approaches have typically relied on heuristics such as tf-idf (Ratinov et\n1Source available at github.com/matthewfl/nlp-entity-convnet\nal., 2011), but such heuristics are hard to calibrate and they capture structure in a coarser way than learning-based methods.\nIn this work, we model semantic similarity between a mention\u2019s source document context and its potential entity targets using convolutional neural networks (CNNs). CNNs have been shown to be effective for sentence classification tasks (Kalchbrenner et al., 2014; Kim, 2014; Iyyer et al., 2015) and for capturing similarity in models for entity linking (Sun et al., 2015) and other related tasks (Dong et al., 2015; Shen et al., 2014), so we expect them to be effective at isolating the relevant topic semantics for entity linking. We show that convolutions over multiple granularities of the input document are useful for providing different notions of semantic context. Finally, we show how to integrate these networks with a preexisting entity linking system (Durrett and Klein, 2014). Through a combination of these two distinct methods into a single system that leverages their complementary strengths, we achieve state-ofthe-art performance across several datasets."}, {"heading": "2 Model", "text": "Our model focuses on two core ideas: first, that topic semantics at different granularities in a document are helpful in determining the genres of entities for entity linking, and second, that CNNs can distill a block of text into a meaningful topic vector.\nOur entity linking model is a log-linear model that places distributions over target entities t given a mention x and its containing source document. For now, we take P (t|x) \u221d expw>fC(x, t; \u03b8), where fC produces a vector of features based on CNNs with parameters \u03b8 as discussed in Section 2.1. Section 2.2 describes how we combine this simple model with a full-fledged entity linking system. As shown in the middle of Figure 1, each feature in fC\nar X\niv :1\n60 4.\n00 73\n4v 1\n[ cs\n.C L\n] 4\nA pr\n2 01\n6\nis a cosine similarity between a topic vector associated with the source document and a topic vector associated with the target entity. These vectors are computed by distinct CNNs operating over different subsets of relevant text.\nFigure 1 shows an example of why different kinds of context are important for entity linking. In this case, we are considering whether Pink Floyd might link to the article Gavin Floyd on Wikipedia (imagine that Pink Floyd might be a person\u2019s nickname). If we look at the source document, we see that the immediate source document context around the mention Pink Floyd is referring to rock groups (Led Zeppelin, Van Halen) and the target entity\u2019s Wikipedia page is primarily about sports (baseball starting pitcher). Distilling these texts into succinct topic descriptors and then comparing those helps tell us that this is an improbable entity link pair. In this case, the broader source document context actually does not help very much, since it contains other generic last names like Campbell and Savage that might not necessarily indicate the document to be in the music genre. However, in general, the whole document might provide a more robust topic estimate than a small context window does."}, {"heading": "2.1 Convolutional Semantic Similarity", "text": "Figure 1 shows our method for computing topic vectors and using those to extract features for a potential Wikipedia link. For each of three text granularities\nin the source document (the mention, that mention\u2019s immediate context, and the entire document) and two text granularities on the target entity side (title and Wikipedia article text), we produce vector representations with CNNs as follows. We first embed each word into a d-dimensional vector space using standard embedding techniques (discussed in Section 3.2), yielding a sequence of vectorsw1, . . . , wn. We then map those words into a fixed-size vector using a convolutional network parameterized with a filter bank M \u2208 Rk\u00d7d`. We put the result through a rectified linear unit (ReLU) and combine the results with sum pooling, giving the following formulation:\nconvg(w1:n) = n\u2212\u2211\u0300\nj=1\nmax{0,Mgwj:j+`} (1)\nwhere wj:j+` is a concatenation of the given word vectors and the max is element-wise.2 Each convolution granularity (mention, context, etc.) has a distinct set of filter parameters Mg.\nThis process produces multiple representative topic vectors sment, scontext, and sdoc for the source document and ttitle and tdoc for the target entity, as shown in Figure 1. All pairs of these vectors between the source and the target are then compared using cosine similarity, as shown in the middle of Figure 1. This yields the vector of features fC(s, te)\n2For all experiments, we set ` = 5 and k = 150.\nwhich indicate the different types of similarity; this vector can then be combined with other sparse features and fed into a final logistic regression layer (maintaining end-to-end inference and learning of the filters). When trained with backpropagation, the convolutional networks should learn to map text into vector spaces that are informative about whether the document and entity are related or not."}, {"heading": "2.2 Integrating with a Sparse Model", "text": "The dense model presented in Section 2.1 is effective at capturing semantic topic similarity, but it is most effective when combined with other signals for entity linking. An important cue for resolving a mention is the use of link counts from hyperlinks in Wikipedia (Cucerzan, 2007; Milne and Witten, 2008; Ji and Grishman, 2011), which tell us how often a given mention was linked to each article on Wikipedia. This information can serve as a useful prior, but only if we can leverage it effectively by targeting the most salient part of a mention. For example, we may have never observed President Barack Obama as a linked string on Wikipedia, even though we have seen the substring Barack Obama and it unambiguously indicates the correct answer.\nFollowing Durrett and Klein (2014), we introduce a latent variable q to capture which subset of a mention (known as a query) we resolve. Query generation includes potentially removing stop words, plural suffixes, punctuation, and leading or tailing words. This processes generates on average 9 queries for each mention. Conveniently, this set of queries also defines the set of candidate entities that we consider linking a mention to: each query generates a set of potential entities based on link counts, whose unions are then taken to give on the possible entity targets for each mention (including the null link). In the example shown in Figure 1, the query phrases are Pink Floyd and Floyd, which generate Pink Floyd and Gavin Floyd as potential link targets (among other options that might be derived from the Floyd query). Our final model has the form P (t|x) =\u2211 q P (t, q|x). We parameterize P (t, q|x) in a loglinear way with three separate components: P (t, q|x) \u221d exp ( w>(fQ(x, q) + fE(x, q, t) + fC(x, t; \u03b8)) )\nfQ and fE are both sparse features vectors and are\ntaken from previous work (Durrett and Klein, 2014). fC is as discussed in Section 2.1. Note that fC has its own internal parameters \u03b8 because it relies on CNNs with learned filters; however, we can compute gradients for these parameters with standard backpropagation. The whole model is trained to maximize the log likelihood of a labeled training corpus using Adadelta (Zeiler, 2012).\nThe indicator features fQ and fE are described in more detail in Durrett and Klein (2014). fQ only impacts which query is selected and not the disambiguation to a title. It is designed to roughly capture the basic shape of a query to measure its desirability, indicating whether suffixes were removed and whether the query captures the capitalized subsequence of a mention, as well as standard lexical, POS, and named entity type features. fE mostly captures how likely the selected query is to correspond to a given entity based on factors like anchor text counts from Wikipedia, string match with proposed Wikipedia titles, and discretized cosine similarities of tf-idf vectors (Ratinov et al., 2011). Adding tf-idf indicators is the only modification we made to the features of Durrett and Klein (2014)."}, {"heading": "3 Experimental Results", "text": "We performed experiments on 4 different entity linking datasets.\n\u2022 ACE (NIST, 2005; Bentivogli et al., 2010): This corpus was used in Fahrni and Strube (2014) and Durrett and Klein (2014).\n\u2022 CoNLL-YAGO (Hoffart et al., 2011): This corpus is based on the CoNLL 2003 dataset; the test set consists of 231 news articles and contains a number of rarer entities.\n\u2022 WP (Heath and Bizer, 2011): This dataset consists of short snippets from Wikipedia.\n\u2022 Wikipedia (Ratinov et al., 2011): This dataset consists of 10,000 randomly sampled Wikipedia articles, with the task being to resolve the links in each article.3\n3We do not compare to Ratinov et al. (2011) on this dataset because we do not have access to the original Wikipedia dump they used for their work and as a result could not duplicate their results or conduct comparable experiments, a problem which was also noted by Nguyen et al. (2014).\nWe use standard train-test splits for all datasets except for WP, where no standard split is available. In this case, we randomly sample a test set. For all experiments, we use word vectors computed by running word2vec (Mikolov et al., 2013) on all Wikipedia, as described in Section 3.2.\nTable 2 shows results for two baselines and three variants of our system. Our main contribution is the combination of indicator features and CNN features (Full). We see that this system outperforms the results of Durrett and Klein (2014) and the AIDALIGHT system of Nguyen et al. (2014). We can also compare to two ablations: using just the sparse features (a system which is a direct extension of Durrett and Klein (2014)) or using just the CNNderived features.5 Our CNN features generally outperform the sparse features and improve even further when stacked with them. This reflects that they capture orthogonal sources of information: for example, the sparse features can capture how frequently the target document was linked to, whereas the CNNs can capture document context in a more nuanced way. These CNN features also clearly supersede the sparse features based on tf-idf (taken from (Ratinov et al., 2011)), showing that indeed that CNNs are better at learning semantic topic similarity than heuristics like tf-idf.\n4The test set for this dataset is only 40 out of 10,000 documents and subject to wide variation in performance.\n5In this model, the set of possible link targets for each mention is still populated using anchor text information from Wikipedia (Section 2.2), but note that link counts are not used as a feature here.\nIn the sparse feature system, the highest weighted features are typically those indicating the frequency that a page was linked to and those indicating specific lexical items in the choice of the latent query variable q. This suggests that the system of Durrett and Klein (2014) has the power to pick the right span of a mention to resolve, but then is left to generally pick the most common link target in Wikipedia, which is not always correct. By contrast, the full system has a greater ability to pick less common link targets if the topic indicators distilled from the CNNs indicate that it should do so."}, {"heading": "3.1 Multiple Granularities of Convolution", "text": "One question we might ask is how much we gain by having multiple convolutions on the source and target side. Table 3 compares our full suite of CNN features, i.e. the six features specified in Figure 1, with two specific convolutional features in isolation. Using convolutions over just the source document (sdoc) and target article text (tdoc) gives a system6 that performs, in aggregate, comparably to using convolutions over just the mention (sment) and the entity title (ttitle). These represent two extremes of the system: consuming the maximum amount of context, which might give the most robust representation of topic semantics, and consuming the minimum amount of context, which gives the most focused representation of topics semantics (and which more generally might allow the system to directly memorize train-test pairs observed in training). However, neither performs as well as the combination of all CNN features, showing that the different granularities capture complementary\n6This model is roughly comparable to Model 2 as presented in Sun et al. (2015).\naspects of the entity linking task."}, {"heading": "3.2 Embedding Vectors", "text": "We also explored two different sources of embedding vectors for the convolutions. Table 4 shows that word vectors trained on Wikipedia outperformed Google News word vectors trained on a larger corpus. Further investigation revealed that the Google News vectors had much higher out-of-vocabulary rates. For learning the vectors, we use the standard word2vec toolkit (Mikolov et al., 2013) with vector length set to 300, window set to 21 (larger windows produce more semantically-focused vectors (Levy and Goldberg, 2014)), 10 negative samples and 10 iterations through Wikipedia. We do not fine-tune word vectors during training of our model, as that was not found to improve performance."}, {"heading": "3.3 Analysis of Learned Convolutions", "text": "One downside of our system compared to its purely indicator-based variant is that its operation is less interpretable. However, one way we can inspect the learned system is by examining what causes high activations of the various convolutional filters (rows of the matrices Mg from Equation 1). Table 1 shows the n-grams in the ACE dataset leading to maximal\nactivations of three of the filters from Mdoc. Some filters tend to learn to pick up on n-grams characteristic of a particular topic. In other cases, a single filter might be somewhat inscrutable, as with the third column of Table 1. There are a few possible explanations for this. First, the filter may generally have low activations and therefore have little impact in the final feature computation. Second, the extreme points of the filter may not be characteristic of its overall behavior, since the bulk of n-grams will lead to more moderate activations. Finally, such a filter may represent the superposition of a few topics that we are unlikely to ever need to disambiguate between; in a particular context, this filter will then play a clear role, but one which is hard to determine from the overall shape of the parameters."}, {"heading": "4 Conclusion", "text": "In this work, we investigated using convolutional networks to capture semantic similarity between source documents and potential entity link targets. Using multiple granularities of convolutions to evaluate the compatibility of a mention in context and several potential link targets gives strong performance on its own; moreover, such features also improve a pre-existing entity linking system based on sparse indicator features, showing that these sources of information are complementary."}, {"heading": "Acknowledgments", "text": "This work was partially supported by NSF Grant CNS-1237265 and a Google Faculty Research\nAward. Thanks to the anonymous reviewers for their helpful comments."}], "references": [{"title": "Extending English ACE 2005 Corpus Annotation with Groundtruth Links to Wikipedia", "author": ["Pamela Forner", "Claudio Giuliano", "Alessandro Marchetti", "Emanuele Pianta", "Kateryna Tymoshenko"], "venue": null, "citeRegEx": "Bentivogli et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bentivogli et al\\.", "year": 2010}, {"title": "Relational Inference for Wikification", "author": ["Cheng", "Roth2013] Xiao Cheng", "Dan Roth"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "Cheng et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cheng et al\\.", "year": 2013}, {"title": "Large-Scale Named Entity Disambiguation Based on Wikipedia Data", "author": ["Silviu Cucerzan"], "venue": "In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-", "citeRegEx": "Cucerzan.,? \\Q2007\\E", "shortCiteRegEx": "Cucerzan.", "year": 2007}, {"title": "Question Answering over Freebase with Multi-Column Convolutional Neural Networks", "author": ["Dong et al.2015] Li Dong", "Furu Wei", "Ming Zhou", "Ke Xu"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association", "citeRegEx": "Dong et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dong et al\\.", "year": 2015}, {"title": "A Joint Model for Entity Analysis: Coreference, Typing, and Linking. In Transactions of the Association for Computational Linguistics (TACL)", "author": ["Durrett", "Klein2014] Greg Durrett", "Dan Klein"], "venue": null, "citeRegEx": "Durrett et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Durrett et al\\.", "year": 2014}, {"title": "A latent variable model for discourseaware concept and entity disambiguation", "author": ["Fahrni", "Strube2014] Angela Fahrni", "Michael Strube"], "venue": "In Gosse Bouma and Yannick Parmentier 0001,", "citeRegEx": "Fahrni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Fahrni et al\\.", "year": 2014}, {"title": "Efficient collective entity linking with stacking", "author": ["He et al.2013] Zhengyan He", "Shujie Liu", "Yang Song", "Mu Li", "Ming Zhou", "Houfeng Wang"], "venue": "In EMNLP,", "citeRegEx": "He et al\\.,? \\Q2013\\E", "shortCiteRegEx": "He et al\\.", "year": 2013}, {"title": "Linked Data: Evolving the Web into a Global Data Space", "author": ["Heath", "Bizer2011] Tom Heath", "Christian Bizer"], "venue": null, "citeRegEx": "Heath et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Heath et al\\.", "year": 2011}, {"title": "Robust Disambiguation", "author": ["Mohamed Amir Yosef", "Ilaria Bordino", "Hagen F\u00fcrstenau", "Manfred Pinkal", "Marc Spaniol", "Bilyana Taneva", "Stefan Thater", "Gerhard Weikum"], "venue": null, "citeRegEx": "Hoffart et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hoffart et al\\.", "year": 2011}, {"title": "Deep Unordered Composition Rivals Syntactic Methods for Text Classification", "author": ["Iyyer et al.2015] Mohit Iyyer", "Varun Manjunatha", "Jordan Boyd-Graber", "Hal Daum\u00e9 III"], "venue": "In Proceedings of the Association for Computational Linguistics (ACL)", "citeRegEx": "Iyyer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Iyyer et al\\.", "year": 2015}, {"title": "Knowledge Base Population: Successful Approaches and Challenges", "author": ["Ji", "Grishman2011] Heng Ji", "Ralph Grishman"], "venue": "In Proceedings of the Association for Computational Linguistics (ACL)", "citeRegEx": "Ji et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2011}, {"title": "A convolutional neural network for modelling sentences", "author": ["Edward Grefenstette", "Phil Blunsom"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Kalchbrenner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Convolutional Neural Networks for Sentence Classification", "author": ["Yoon Kim"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "Kim.,? \\Q2014\\E", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Dependency-Based Word Embeddings", "author": ["Levy", "Goldberg2014] Omer Levy", "Yoav Goldberg"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)", "citeRegEx": "Levy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2014}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Learning to Link with Wikipedia", "author": ["Milne", "Witten2008] David Milne", "Ian H. Witten"], "venue": "In Proceedings of the Conference on Information and Knowledge Management (CIKM)", "citeRegEx": "Milne et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Milne et al\\.", "year": 2008}, {"title": "AIDAlight: High-Throughput Named-Entity Disambiguation", "author": ["Nguyen et al.2014] Dat Ba Nguyen", "Johannes Hoffart", "Martin Theobald", "Gerhard Weikum"], "venue": "In Proceedings of the Workshop on Linked Data on the Web co-located with the 23rd International", "citeRegEx": "Nguyen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2014}, {"title": "Local and Global Algorithms for Disambiguation to Wikipedia", "author": ["Ratinov et al.2011] Lev Ratinov", "Dan Roth", "Doug Downey", "Mike Anderson"], "venue": "In Proceedings of the 49th Annual Meeting of the Association", "citeRegEx": "Ratinov et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ratinov et al\\.", "year": 2011}, {"title": "Modeling Mention, Context and Entity with Neural Networks for Entity Disambiguation", "author": ["Sun et al.2015] Yaming Sun", "Lei Lin", "Duyu Tang", "Nan Yang", "Zhenzhou Ji", "Xiaolong Wang"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelli-", "citeRegEx": "Sun et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2015}, {"title": "AdaDelta: An Adaptive Learning Rate Method. CoRR, abs/1212.5701", "author": ["Matthew D. Zeiler"], "venue": null, "citeRegEx": "Zeiler.,? \\Q2012\\E", "shortCiteRegEx": "Zeiler.", "year": 2012}], "referenceMentions": [{"referenceID": 16, "context": "We combine these networks with a sparse linear model to achieve state-of-the-art performance on multiple entity linking datasets, outperforming the prior systems of Durrett and Klein (2014) and Nguyen et al. (2014).1", "startOffset": 194, "endOffset": 215}, {"referenceID": 17, "context": "Past approaches to such cases have often focused on collective entity linking: nearby mentions in a document might be expected to link to topically-similar entities, which can give us clues about the identity of the mention currently being resolved (Ratinov et al., 2011; Hoffart et al., 2011; He et al., 2013; Cheng and Roth, 2013; Durrett and Klein, 2014).", "startOffset": 249, "endOffset": 357}, {"referenceID": 8, "context": "Past approaches to such cases have often focused on collective entity linking: nearby mentions in a document might be expected to link to topically-similar entities, which can give us clues about the identity of the mention currently being resolved (Ratinov et al., 2011; Hoffart et al., 2011; He et al., 2013; Cheng and Roth, 2013; Durrett and Klein, 2014).", "startOffset": 249, "endOffset": 357}, {"referenceID": 6, "context": "Past approaches to such cases have often focused on collective entity linking: nearby mentions in a document might be expected to link to topically-similar entities, which can give us clues about the identity of the mention currently being resolved (Ratinov et al., 2011; Hoffart et al., 2011; He et al., 2013; Cheng and Roth, 2013; Durrett and Klein, 2014).", "startOffset": 249, "endOffset": 357}, {"referenceID": 18, "context": ", 2015) and for capturing similarity in models for entity linking (Sun et al., 2015) and other related tasks (Dong et al.", "startOffset": 66, "endOffset": 84}, {"referenceID": 3, "context": ", 2015) and other related tasks (Dong et al., 2015; Shen et al., 2014), so we expect them to be effective at isolating the relevant topic semantics for", "startOffset": 32, "endOffset": 70}, {"referenceID": 2, "context": "An important cue for resolving a mention is the use of link counts from hyperlinks in Wikipedia (Cucerzan, 2007; Milne and Witten, 2008; Ji and Grishman, 2011), which tell us how often a given mention was linked to each article on", "startOffset": 96, "endOffset": 159}, {"referenceID": 19, "context": "The whole model is trained to maximize the log likelihood of a labeled training corpus using Adadelta (Zeiler, 2012).", "startOffset": 102, "endOffset": 116}, {"referenceID": 19, "context": "The whole model is trained to maximize the log likelihood of a labeled training corpus using Adadelta (Zeiler, 2012). The indicator features fQ and fE are described in more detail in Durrett and Klein (2014). fQ only impacts which query is selected and not the disambiguation to a title.", "startOffset": 103, "endOffset": 208}, {"referenceID": 17, "context": "chor text counts from Wikipedia, string match with proposed Wikipedia titles, and discretized cosine similarities of tf-idf vectors (Ratinov et al., 2011).", "startOffset": 132, "endOffset": 154}, {"referenceID": 17, "context": "chor text counts from Wikipedia, string match with proposed Wikipedia titles, and discretized cosine similarities of tf-idf vectors (Ratinov et al., 2011). Adding tf-idf indicators is the only modification we made to the features of Durrett and Klein (2014).", "startOffset": 133, "endOffset": 258}, {"referenceID": 0, "context": "\u2022 ACE (NIST, 2005; Bentivogli et al., 2010): This corpus was used in Fahrni and Strube (2014) and Durrett and Klein (2014).", "startOffset": 6, "endOffset": 43}, {"referenceID": 0, "context": "\u2022 ACE (NIST, 2005; Bentivogli et al., 2010): This corpus was used in Fahrni and Strube (2014) and Durrett and Klein (2014).", "startOffset": 19, "endOffset": 94}, {"referenceID": 0, "context": "\u2022 ACE (NIST, 2005; Bentivogli et al., 2010): This corpus was used in Fahrni and Strube (2014) and Durrett and Klein (2014).", "startOffset": 19, "endOffset": 123}, {"referenceID": 8, "context": "\u2022 CoNLL-YAGO (Hoffart et al., 2011): This corpus is based on the CoNLL 2003 dataset; the test set consists of 231 news articles and con-", "startOffset": 13, "endOffset": 35}, {"referenceID": 17, "context": "\u2022 Wikipedia (Ratinov et al., 2011): This dataset consists of 10,000 randomly sampled Wikipedia articles, with the task being to resolve the links in each article.", "startOffset": 12, "endOffset": 34}, {"referenceID": 16, "context": "We do not compare to Ratinov et al. (2011) on this dataset because we do not have access to the original Wikipedia dump they used for their work and as a result could not duplicate their results or conduct comparable experiments, a problem which was also noted by Nguyen et al.", "startOffset": 21, "endOffset": 43}, {"referenceID": 16, "context": "(2011) on this dataset because we do not have access to the original Wikipedia dump they used for their work and as a result could not duplicate their results or conduct comparable experiments, a problem which was also noted by Nguyen et al. (2014).", "startOffset": 228, "endOffset": 249}, {"referenceID": 16, "context": "Our results outperform those of Durrett and Klein (2014) and Nguyen et al. (2014). In general, we also see that the convolutional networks by themselves can outperform the system using only sparse features, and in all cases these stack to give substantial benefit.", "startOffset": 61, "endOffset": 82}, {"referenceID": 14, "context": "For all experiments, we use word vectors computed by running word2vec (Mikolov et al., 2013) on all", "startOffset": 70, "endOffset": 92}, {"referenceID": 16, "context": "We see that this system outperforms the results of Durrett and Klein (2014) and the AIDALIGHT system of Nguyen et al. (2014). We can", "startOffset": 104, "endOffset": 125}, {"referenceID": 17, "context": "These CNN features also clearly supersede the sparse features based on tf-idf (taken from (Ratinov et al., 2011)), showing that indeed that CNNs are better at learning semantic topic similarity than heuristics like tf-idf.", "startOffset": 90, "endOffset": 112}, {"referenceID": 18, "context": "This model is roughly comparable to Model 2 as presented in Sun et al. (2015).", "startOffset": 60, "endOffset": 78}, {"referenceID": 14, "context": "For learning the vectors, we use the standard word2vec toolkit (Mikolov et al., 2013) with vector length set to 300, window set to 21 (larger windows produce more semantically-focused vectors (Levy and Goldberg, 2014)), 10 negative samples and 10 iterations through Wikipedia.", "startOffset": 63, "endOffset": 85}], "year": 2016, "abstractText": "A key challenge in entity linking is making effective use of contextual information to disambiguate mentions that might refer to different entities in different contexts. We present a model that uses convolutional neural networks to capture semantic correspondence between a mention\u2019s context and a proposed target entity. These convolutional networks operate at multiple granularities to exploit various kinds of topic information, and their rich parameterization gives them the capacity to learn which n-grams characterize different topics. We combine these networks with a sparse linear model to achieve state-of-the-art performance on multiple entity linking datasets, outperforming the prior systems of Durrett and Klein (2014) and Nguyen et al. (2014).1", "creator": "LaTeX with hyperref package"}}}