{"id": "1604.01348", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Apr-2016", "title": "Bayesian Optimization with Exponential Convergence", "abstract": "This paper presents a Bayesian optimization method with exponential convergence without the need for additional optimization and without delta cover sampling. Most Bayesian optimization methods require additional optimization: an additional non-convex global optimization problem that can be time-consuming and difficult to implement in practice. In addition, the existing Bayesian optimization method with exponential convergence requires access to delta cover sampling, which was considered impractical. Our approach eliminates both requirements and exponential convergence rates.", "histories": [["v1", "Tue, 5 Apr 2016 17:53:59 GMT  (1008kb,D)", "http://arxiv.org/abs/1604.01348v1", "In NIPS 2015 (Advances in Neural Information Processing Systems 2015)"]], "COMMENTS": "In NIPS 2015 (Advances in Neural Information Processing Systems 2015)", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["kenji kawaguchi", "leslie pack kaelbling", "tom\u00e1s lozano-p\u00e9rez"], "accepted": true, "id": "1604.01348"}, "pdf": {"name": "1604.01348.pdf", "metadata": {"source": "CRF", "title": "Bayesian Optimization with Exponential Convergence", "authors": ["Kenji Kawaguchi", "Leslie Pack Kaelbling"], "emails": ["kawaguch@mit.edu", "lpk@csail.mit.edu", "tlp@csail.mit.edu"], "sections": [{"heading": null, "text": "This paper presents a Bayesian optimization method with exponential convergence without the need of auxiliary optimization and without the \u03b4-cover sampling. Most Bayesian optimization methods require auxiliary optimization: an additional non-convex global optimization problem, which can be time-consuming and hard to implement in practice. Also, the existing Bayesian optimization method with exponential convergence [1] requires access to the \u03b4-cover sampling, which was considered to be impractical [1, 2]. Our approach eliminates both requirements and achieves an exponential convergence rate."}, {"heading": "1 Introduction", "text": "We consider a general global optimization problem: maximize f(x) subject to x \u2208 \u2126 \u2282 RD where f : \u2126 \u2192 R is a non-convex black-box deterministic function. Such a problem arises in many realworld applications, such as parameter tuning in machine learning [3], engineering design problems [4], and model parameter fitting in biology [5]. For this problem, one performance measure of an algorithm is the simple regret, rn, which is given by rn = supx\u2208\u2126 f(x) \u2212 f(x+) where x+ is the best input vector found by the algorithm. For brevity, we use the term \u201cregret\u201d to mean simple regret.\nThe general global optimization problem is known to be intractable if we make no further assumptions [6]. The simplest additional assumption to restore tractability is to assume the existence of a bound on the slope of f . A well-known variant of this assumption is Lipschitz continuity with a known Lipschitz constant, and many algorithms have been proposed in this setting [7, 8, 9]. These algorithms successfully guaranteed certain bounds on the regret. However appealing from a theoretical point of view, a practical concern was soon raised regarding the assumption that a tight Lipschitz constant is known. Some researchers relaxed this somewhat strong assumption by proposing procedures to estimate a Lipschitz constant during the optimization process [10, 11, 12].\nBayesian optimization is an efficient way to relax this assumption of complete knowledge of the Lipschitz constant, and has become a well-recognized method for solving global optimization problems with non-convex black-box functions. In the machine learning community, Bayesian optimization\u2014 especially by means of a Gaussian process (GP)\u2014is an active research area [13, 14, 15]. With the requirement of the access to the \u03b4-cover sampling procedure (it samples the function uniformly such that the density of samples doubles in the feasible regions at each iteration), de Freitas et al. [1] recently proposed a theoretical procedure that maintains an exponential convergence rate (exponential regret). However, as pointed out by Wang et al. [2], one remaining problem is to derive a GP-based optimization method with an exponential convergence rate without the \u03b4-cover sampling procedure, which is computationally too demanding in many cases.\nIn this paper, we propose a novel GP-based global optimization algorithm, which maintains an exponential convergence rate and converges rapidly without the \u03b4-cover sampling procedure.\nar X\niv :1\n60 4.\n01 34\n8v 1\n[ st\nat .M\nL ]\n5 A\npr 2"}, {"heading": "2 Gaussian Process Optimization", "text": "In Gaussian process optimization, we estimate the distribution over function f and use this information to decide which point of f should be evaluated next. In a parametric approach, we consider a parameterized function f(x; \u03b8), with \u03b8 being distributed according to some prior. In contrast, the nonparametric GP approach directly puts the GP prior over f as f(\u00b7) \u223c GP (m(\u00b7), \u03ba(\u00b7, \u00b7)) wherem(\u00b7) is the mean function and \u03ba(\u00b7, \u00b7) is the covariance function or the kernel. That is, m(x) = E[f(x)] and \u03ba(x, x\u2032) = E[(f(x)\u2212m(x))(f(x\u2032)\u2212m(x\u2032))T ]. For a finite set of points, the GP model is simply a joint Gaussian: f(x1:N ) \u223c N (m(x1:N ),K), where Ki,j = \u03ba(xi, xj) and N is the number of data points. To predict the value of f at a new data point, we first consider the joint distribution over f of the old data points and the new data point:\n( f(x1:N ) f(xN+1) ) \u223c N ( m(x1:N ) m(xN+1) , [ K k kT \u03ba(xN+1, xN+1) ]) where k = \u03ba(x1:N ,xN+1) \u2208 RN\u00d71. Then, after factorizing the joint distribution using the Schur complement for the joint Gaussian, we obtain the conditional distribution, conditioned on observed entities DN := {x1:N , f(x1:N )} and xN+1, as:\nf(xN+1)|DN , xN+1 \u223c N (\u00b5(xN+1|DN ), \u03c32(xN+1|DN )) where \u00b5(xN+1|DN ) = m(xN+1) + kTK\u22121(f(x1:N ) \u2212 m(x1:N )) and \u03c32(xN+1|DN ) = \u03ba(xN+1,xN+1)\u2212 kTK\u22121k. One advantage of GP is that this closed-form solution simplifies both its analysis and implementation.\nTo use a GP, we must specify the mean function and the covariance function. The mean function is usually set to be zero. With this zero mean function, the conditional mean \u00b5(xN+1|DN ) can still be flexibly specified by the covariance function, as shown in the above equation for \u00b5. For the covariance function, there are several common choices, including the Matern kernel and the Gaussian kernel. For example, the Gaussian kernel is defined as \u03ba(x, x\u2032) = exp ( \u2212 12 (x\u2212 x \u2032) T \u03a3\u22121(x\u2212 x\u2032) ) where \u03a3\u22121 is the kernel parameter matrix. The kernel parameters or hyperparameters can be estimated by empirical Bayesian methods [16]; see [17] for more information about GP.\nThe flexibility and simplicity of the GP prior make it a common choice for continuous objective functions in the Bayesian optimization literature. Bayesian optimization with GP selects the next query point that optimizes the acquisition function generated by GP. Commonly used acquisition functions include the upper confidence bound (UCB) and expected improvement (EI). For brevity, we consider Bayesian optimization with UCB, which works as follows. At each iteration, the UCB function U is maintained as U(x|DN ) = \u00b5(x|DN ) + \u03c2\u03c3(x|DN ) where \u03c2 \u2208 R is a parameter of the algorithm. To find the next query xn+1 for the objective function f , GP-UCB solves an additional non-convex optimization problem with U as xN+1 = arg maxx U(x|DN ). This is often carried out by other global optimization methods such as DIRECT and CMA-ES. The justification for introducing a new optimization problem lies in the assumption that the cost of evaluating the objective function f dominates that of solving additional optimization problem.\nFor deterministic function, de Freitas et al. [1] recently presented a theoretical procedure that maintains exponential convergence rate. However, their own paper and the follow-up research [1, 2] point out that this result relies on an impractical sampling procedure, the \u03b4-cover sampling. To overcome this issue, Wang et al. [2] combined GP-UCB with a hierarchical partitioning optimization method, the SOO algorithm [18], providing a regret bound with polynomial dependence on the number of function evaluations. They concluded that creating a GP-based algorithm with an exponential convergence rate without the impractical sampling procedure remained an open problem."}, {"heading": "3 Infinite-Metric GP Optimization", "text": ""}, {"heading": "3.1 Overview", "text": "The GP-UCB algorithm can be seen as a member of the class of bound-based search methods, which includes Lipschitz optimization, A* search, and PAC-MDP algorithms with optimism in the\nface of uncertainty. Bound-based search methods have a common property: the tightness of the bound determines its effectiveness. The tighter the bound is, the better the performance becomes. However, it is often difficult to obtain a tight bound while maintaining correctness. For example, in A* search, admissible heuristics maintain the correctness of the bound, but the estimated bound with admissibility is often too loose in practice, resulting in a long period of global search.\nThe GP-UCB algorithm has the same problem. The bound in GP-UCB is represented by UCB, which has the following property: f(x) \u2264 U(x|D) with some probability. We formalize this property in the analysis of our algorithm. The problem is essentially due to the difficulty of obtaining a tight bound U(x|D) such that f(x) \u2264 U(x|D) and f(x) \u2248 U(x|D) (with some probability). Our solution strategy is to first admit that the bound encoded in GP prior may not be tight enough to be useful by itself. Instead of relying on a single bound given by the GP, we leverage the existence of an unknown bound encoded in the continuity at a global optimizer.\nAssumption 1. (Unknown Bound) There exists a global optimizer x\u2217 and an unknown semi-metric ` such that for all x \u2208 \u2126, f(x\u2217) \u2264 f(x) + ` (x, x\u2217) and ` (x, x\u2217) <\u221e.\nIn other words, we do not expect the known upper bound due to GP to be tight, but instead expect that there exists some unknown bound that might be tighter. Notice that in the case where the bound by GP is as tight as the unknown bound by semi-metric ` in Assumption 1, our method still maintains an exponential convergence rate and an advantage over GP-UCB (no need for auxiliary optimization). Our method is expected to become relatively much better when the known bound due to GP is less tight compared to the unknown bound by `.\nAs the semi-metric ` is unknown, there are infinitely many possible candidates that we can think of for `. Accordingly, we simultaneously conduct global and local searches based on all the candidates of the bounds. The bound estimated by GP is used to reduce the number of candidates. Since the bound estimated by GP is known, we can ignore the candidates of the bounds that are looser than the bound estimated by GP. The source code of the proposed algorithm is publicly available at http://lis.csail.mit.edu/code/imgpo.html."}, {"heading": "3.2 Description of Algorithm", "text": "Figure 1 illustrates how the algorithm works with a simple 1-dimensional objective function. We employ hierarchical partitioning to maintain hyperintervals, as illustrated by the line segments in the figure. We consider a hyperrectangle as our hyperinterval, with its center being the evaluation point of f (blue points in each line segment in Figure 1). For each iteration t, the algorithm performs the following procedure for each interval size:\n(i) Select the interval with the maximum center value among the intervals of the same size.\n(ii) Keep the interval selected by (i) if it has a center value greater than that of any larger interval.\n(iii) Keep the interval accepted by (ii) if it contains a UCB greater than the center value of any smaller interval.\n(iv) If an interval is accepted by (iii), divide it along with the longest coordinate into three new intervals.\n(v) For each new interval, if the UCB of the evaluation point is less than the best function value found so far, skip the evaluation and use the UCB value as the center value until the interval is accepted in step (ii) on some future iteration; otherwise, evaluate the center value.\n(vi) Repeat steps (i)\u2013(v) until every size of intervals are considered\nThen, at the end of each iteration, the algorithm updates the GP hyperparameters. Here, the purpose of steps (i)\u2013(iii) is to select an interval that might contain the global optimizer. Steps (i) and (ii) select the possible intervals based on the unknown bound by `, while Step (iii) does so based on the bound by GP.\nWe now explain the procedure using the example in Figure 1. Let n be the number of divisions of intervals and let N be the number of function evaluations. t is the number of iterations. Initially, there is only one interval (the center of the input region \u2126 \u2282 R) and thus this interval is divided,\nresulting in the first diagram of Figure 1. At the beginning of iteration t = 2 , step (i) selects the third interval from the left side in the first diagram (t = 1, n = 2), as its center value is the maximum. Because there are no intervals of different size at this point, steps (ii) and (iii) are skipped. Step (iv) divides the third interval, and then the GP hyperparameters are updated, resulting in the second diagram (t = 2, n = 3). At the beginning of iteration t = 3, it starts conducting steps (i)\u2013(v) for the largest intervals. Step (i) selects the second interval from the left side and step (ii) is skipped. Step (iii) accepts the second interval, because the UCB within this interval is no less than the center value of the smaller intervals, resulting in the third diagram (t = 3, n = 4). Iteration t = 3 continues by conducting steps (i)\u2013(v) for the smaller intervals. Step (i) selects the second interval from the left side, step (ii) accepts it, and step (iii) is skipped, resulting in the forth diagram (t = 3, n = 4). The effect of the step (v) can be seen in the diagrams for iteration t = 9. At n = 16, the far right interval is divided, but no function evaluation occurs. Instead, UCB values given by GP are placed in the new intervals indicated by the red asterisks. One of the temporary dummy values is resolved at n = 17 when the interval is queried for division, as shown by the green asterisk. The effect of step (iii) for the rejection case is illustrated in the last diagram for iteration t = 10. At n = 18, t is increased to 10 from 9, meaning that the largest intervals are first considered for division. However, the three largest intervals are all rejected in step (iii), resulting in the division of a very small interval near the global optimum at n = 18."}, {"heading": "3.3 Technical Detail of Algorithm", "text": "We define h to be the depth of the hierarchical partitioning tree, and ch,i to be the center point of the ith hyperrectangle at depth h. Ngp is the number of the GP evaluations. Define depth(T ) to be the largest integer h such that the set Th is not empty. To compute UCB U , we use \u03c2M =\u221a\n2 log(\u03c02M2/12\u03b7) whereM is the number of the calls made so far for U (i.e., each time we use U , we increment M by one). This particular form of \u03c2M is to maintain the property of f(x) \u2264 U(x|D) during an execution of our algorithm with probability at least 1 \u2212 \u03b7. Here, \u03b7 is the parameter of IMGPO. \u039emax is another parameter, but it is only used to limit the possibly long computation of step (iii) (in the worst case, step (iii) computes UCBs 3\u039emax times although it would rarely happen).\nThe pseudocode is shown in Algorithm 1. Lines 8 to 23 correspond to steps (i)-(iii). These lines compute the index i\u2217h of the candidate of the rectangle that may contain a global optimizer for each depth h. For each depth h, non-null index i\u2217h at Line 24 indicates the remaining candidate of a rectangle that we want to divide. Lines 24 to 33 correspond to steps (iv)-(v) where the remaining candidates of the rectangles for all h are divided. To provide a simple executable division scheme (line 29), we assume \u2126 to be a hyperrectangle (see the last paragraph of section 4 for a general case).\nLines 8 to 17 correspond to steps (i)-(ii). Specifically, line 10 implements step (i) where a single candidate is selected for each depth, and lines 11 to 12 conduct step (ii) where some candidates are screened out. Lines 13 to 17 resolve the the temporary dummy values computed by GP. Lines 18\nAlgorithm 1 Infinite-Metric GP Optimization (IMGPO)\nInput: an objective function f , the search domain \u2126, the GP kernel \u03ba, \u039emax \u2208 N+ and \u03b7 \u2208 (0, 1) 1: Initialize the set Th = {\u2205} \u2200h \u2265 0 2: Set c0,0 to be the center point of \u2126 and T0 \u2190 {c0,0} 3: Evaluate f at c0,0: g(c0,0)\u2190 f(c0,0) 4: f+ \u2190 g(c0,0),D \u2190 {(c0,0, g(c0,0))} 5: n,N \u2190 1, Ngp \u2190 0,\u039e\u2190 1 6: for t = 1, 2, 3, ... do 7: \u03c5max \u2190 \u2212\u221e 8: for h = 0 to depth(T ) do # for-loop for steps (i)-(ii) 9: while true do 10: i\u2217h \u2190 arg maxi:ch,i\u2208Th g(ch,i) 11: if g(ch,i\u2217h) < \u03c5max then 12: i\u2217h \u2190 \u2205, break 13: else if g(ch,i\u2217h) is not labeled as GP-based then 14: \u03c5max \u2190 g(ch,i\u2217h), break 15: else 16: g(ch,i\u2217h)\u2190 f(ch,i\u2217h) and remove the GP-based label from g(ch,i\u2217h) 17: N \u2190 N + 1, Ngp \u2190 Ngp \u2212 1 18: D \u2190 {D, (ch,i\u2217h , g(ch,i\u2217h))} 19: for h = 0 to depth(T ) do # for-loop for step (iii) 20: if i\u2217h 6= \u2205 then 21: \u03be \u2190 the smallest positive integer s.t. i\u2217h+\u03be 6= \u2205 and \u03be \u2264 min(\u039e,\u039emax) if exists, and 0 otherwise 22: z(h, i\u2217h) = maxk:ch+\u03be,k\u2208T \u2032h+\u03be(ch,i\u2217h )\nU(ch+\u03be,k|D) 23: if \u03be 6= 0 and z(h, i\u2217h) < g(ch+\u03be,i\u2217h+\u03be ) then 24: i\u2217h \u2190 \u2205, break 25: \u03c5max \u2190 \u2212\u221e 26: for h = 0 to depth(T ) do # for-loop for steps (iv)-(v) 27: if i\u2217h 6= \u2205 and g(ch,i\u2217h) \u2265 \u03c5max then 28: n\u2190 n+ 1. 29: Divide the hyperrectangle centered at ch,i\u2217\nh along with the longest coordinate into three new hy-\nperrectangles with the following centers: S = {ch+1,i(left), ch+1,i(center), ch+1,i(right)}\n30: Th+1 \u2190 {Th+1,S} 31: Th \u2190 Th \\ ch,i\u2217h , g(ch+1,i(center))\u2190 g(ch,i\u2217h) 32: for inew = {i(left), i(right)} do 33: if U(ch+1,inew |D) \u2265 f\n+ then 34: g(ch+1,inew )\u2190 f(ch+1,inew ) 35: D \u2190 {D, (ch+1,inew , g(ch+1,inew ))} N \u2190 N + 1, f+ \u2190 max(f+, g(ch+1,inew )), \u03c5max = max(\u03c5max, g(ch+1,inew )) 36: else 37: g(ch+1,inew )\u2190 U(ch+1,inew |D) and label g(ch+1,inew ) as GP-based. Ngp \u2190 Ngp + 1 38: Update \u039e: if f+ was updated, \u039e\u2190 \u039e + 22 , and otherwise, \u039e\u2190 max(\u039e\u2212 2\u22121, 1) 39: Update GP hyperparameters by an empirical Bayesian method\nto 23 correspond to step (iii) where the candidates are further screened out. At line 21, T \u2032h+\u03be(ch,i\u2217h) indicates the set of all center points of a fully expanded tree until depth h + \u03be within the region covered by the hyperrectangle centered at ch,i\u2217h . In other words, T \u2032 h+\u03be(ch,i\u2217h) contains the nodes of the fully expanded tree rooted at ch,i\u2217h with depth \u03be and can be computed by dividing the current rectangle at ch,i\u2217h and recursively divide all the resulting new rectangles until depth \u03be (i.e., depth \u03be from ch,i\u2217h , which is depth h+ \u03be in the whole tree)."}, {"heading": "3.4 Relationship to Previous Algorithms", "text": "The most closely related algorithm is the BaMSOO algorithm [2], which combines SOO with GPUCB. However, it only achieves a polynomial regret bound while IMGPO achieves a exponential\nregret bound. IMGPO can achieve exponential regret because it utilizes the information encoded in the GP prior/posterior to reduce the degree of the unknownness of the semi-metric `.\nThe idea of considering a set of infinitely many bounds was first proposed by Jones et al. [19]. Their DIRECT algorithm has been successfully applied to real-world problems [4, 5], but it only maintains the consistency property (i.e., convergence in the limit) from a theoretical viewpoint. DIRECT takes an input parameter to balance the global and local search efforts. This idea was generalized to the case of an unknown semi-metric and strengthened with a theoretical support (finite regret bound) by Munos [18] in the SOO algorithm. By limiting the depth of the search tree with a parameter hmax, the SOO algorithm achieves a finite regret bound that depends on the near-optimality dimension."}, {"heading": "4 Analysis", "text": "In this section, we prove an exponential convergence rate of IMGPO and theoretically discuss the reason why the novel idea underling IMGPO is beneficial. The proofs are provided in the supplementary material. To examine the effect of considering infinitely many possible candidates of the bounds, we introduce the following term. Definition 1. (Infinite-metric exploration loss). The infinite-metric exploration loss \u03c1t is the number of intervals to be divided during iteration t. The infinite-metric exploration loss \u03c1\u03c4 can be computed as \u03c1t = \u2211depth(T ) h=1 1(i \u2217 h 6= \u2205) at line 25. It is the cost (in terms of the number of function evaluations) incurred by not committing to any particular upper bound. If we were to rely on a specific bound, \u03c1\u03c4 would be minimized to 1. For example, the DOO algorithm [18] has \u03c1t = 1 \u2200t \u2265 1. Even if we know a particular upper bound, relying on this knowledge and thus minimizing \u03c1\u03c4 is not a good option unless the known bound is tight enough compared to the unknown bound leveraged in our algorithm. This will be clarified in our analysis. Let \u03c1\u0304t be the maximum of the averages of \u03c11:t\u2032 for t\u2032 = 1, 2, ..., t (i.e., \u03c1\u0304t \u2261 max({ 1t\u2032 \u2211t\u2032 \u03c4=1 \u03c1\u03c4 ; t\n\u2032 = 1, 2, . . . , t}). Assumption 2. For some pair of a global optimizer x\u2217 and an unknown semi-metric ` that satisfies Assumption 1, both of the following, (i) shape on ` and (ii) lower bound constant, conditions hold:\n(i) there exist L > 0, \u03b1 > 0 and p \u2265 1 in R such that for all x, x\u2032 \u2208 \u2126, `(x\u2032, x) \u2264 L||x\u2032\u2212x||\u03b1p .\n(ii) there exists \u03b8 \u2208 (0, 1) such that for all x \u2208 \u2126, f(x\u2217) \u2265 f(x) + \u03b8` (x, x\u2217).\nIn Theorem 1, we show that the exponential convergence rate O ( \u03bbN+Ngp ) with \u03bb < 1 is achieved. We define \u039en \u2264 \u039emax to be the largest \u03be used so far with n total node expansions. For simplicity, we assume that \u2126 is a square, which we satisfied in our experiments by scaling original \u2126.\nTheorem 1. Assume Assumptions 1 and 2. Let \u03b2 = supx,x\u2032\u2208\u2126 12\u2016x\u2212x \u2032\u2016\u221e. Let \u03bb = 3\u2212 \u03b1 2CD\u03c1\u0304t < 1. Then, with probability at least 1\u2212 \u03b7, the regret of IMGPO is bounded as\nrN \u2264 L(3\u03b2D1/p)\u03b1 exp ( \u2212\u03b1 [ N +Ngp 2CD\u03c1\u0304t \u2212 \u039en \u2212 2 ] ln 3 ) = O ( \u03bbN+Ngp ) .\nImportantly, our bound holds for the best values of the unknown L,\u03b1 and p even though these values are not given. The closest result in previous work is that of BaMSOO [2], which obtained O\u0303(n\u2212 2\u03b1 D(4\u2212\u03b1) ) with probability 1 \u2212 \u03b7 for \u03b1 = {1, 2}. As can be seen, we have improved the regret bound. Additionally, in our analysis, we can see how L, p, and \u03b1 affect the bound, allowing us to view the inherent difficulty of an objective function in a theoretical perspective. Here, C is a constant in N and is used in previous work [18, 2]. For example, if we conduct 2D or 3D \u2212 1 function evaluations per node-expansion and if p =\u221e, we have that C = 1. We note that \u03bb can get close to one as input dimension D increases, which suggests that there is a remaining challenge in scalability for higher dimensionality. One strategy for addressing this problem would be to leverage additional assumptions such as those in [14, 20]. Remark 1. (The effect of the tightness of UCB by GP) If UCB computed by GP is \u201cuseful\u201d such thatN/\u03c1\u0304t = \u2126(N), then our regret bound becomesO ( exp ( \u2212N+Ngp2CD \u03b1 ln 3 )) . If the bound due to\nUCB by GP is too loose (and thus useless), \u03c1\u0304t can increase up to O(N/t) (due to \u03c1\u0304t \u2264 \u2211t i=1 i/t \u2264\nO(N/t)), resulting in the regret bound of O ( exp ( \u2212 t(1+Ngp/N)2CD \u03b1 ln 3 )) , which can be bounded\nby O ( exp ( \u2212N+Ngp2CD max( 1\u221a N , tN )\u03b1 ln 3 )) 1. This is still better than the known results.\nRemark 2. (The effect of GP) Without the use of GP, our regret bound would be as follows: rN \u2264 L(3\u03b2D1/p)\u03b1 exp(\u2212\u03b1[ N2CD 1 \u03c1\u0303t \u22122] ln 3), where \u03c1\u0304t \u2264 \u03c1\u0303t is the infinite-metric exploration loss without GP. Therefore, the use of GP reduces the regret bound by increasingNgp and decreasing \u03c1\u0304t, but may potentially increase the bound by increasing \u039en \u2264 \u039e. Remark 3. (The effect of infinite-metric optimization) To understand the effect of considering all the possible upper bounds, we consider the case without GP. If we consider all the possible bounds, we have the regret bound L(3\u03b2D1/p)\u03b1 exp(\u2212\u03b1[ N\n2CD 1 \u03c1\u0303t \u2212 2] ln 3) for the best unknown L, \u03b1 and p.\nFor standard optimization with a estimated bound, we have L\u2032(3\u03b2D1/p \u2032 )\u03b1 \u2032 exp(\u2212\u03b1\u2032[ N\n2C\u2032D \u2212 2] ln 3) for an estimated L\u2032, \u03b1\u2032, and p\u2032. By algebraic manipulation, considering all the possible bounds has\na better regret when \u03c1\u0303\u22121t \u2265 2CDN ln 3\u03b1 (( N 2C\u2032D \u2212 2) ln 3 \u03b1\u2032 + 2 ln 3\u03b1\u2212 ln L\n\u2032(3\u03b2D1/p \u2032 )\u03b1 \u2032 L(3\u03b2D1/p)\u03b1 ). For an intuitive\ninsight, we can simplify the above by assuming \u03b1\u2032 = \u03b1 and C \u2032 = C as \u03c1\u0303\u22121t \u2265 1\u2212 Cc2DN ln L\u2032D\u03b1/p\n\u2032\nLD\u03b1/p .\nBecause L and p are the ones that achieve the lowest bound, the logarithm on the right-hand side is always non-negative. Hence, \u03c1\u0303t = 1 always satisfies the condition. When L\u2032 and p\u2032 are not tight enough, the logarithmic term increases in magnitude, allowing \u03c1\u0303t to increase. For example, if the second term on the right-hand side has a magnitude of greater than 0.5, then \u03c1\u0303t = 2 satisfies the inequality. Therefore, even if we know the upper bound of the function, we can see that it may be better not to rely on this, but rather take the infinite many possibilities into account.\nOne may improve the algorithm with different division procedures than one presented in Algorithm 1 as discussed in the supplementary material.\n1This can be done by limiting the depth of search tree as depth(T ) = O( \u221a N). Our proof works with this additional mechanism, but results in the regret bound with N being replaced by \u221a N . Thus, if we assume to have at least \u201cnot useless\u201d UCBs such that N/\u03c1\u0304t = \u2126( \u221a N), this additional mechanism can be disadvantageous. Accordingly, we do not adopt it in our experiments."}, {"heading": "5 Experiments", "text": "In this section, we compare the IMGPO algorithm with the SOO, BaMSOO, GP-PI and GP-EI algorithms [18, 2, 3]. In previous work, BaMSOO and GP-UCB were tested with a pair of a handpicked good kernel and hyperparameters for each function [2]. In our experiments, we assume that the knowledge of good kernel and hyperparameters is unavailable, which is usually the case in practice. Thus, for IMGPO, BaMSOO, GP-PI and GP-EI, we simply used one of the most popular kernels, the isotropic Matern kernel with \u03bd = 5/2. This is given by \u03ba(x, x\u2032) = g( \u221a 5||x\u2212 x\u2032||2/l), where g(z) = \u03c32(1 + z + z2/3) exp(\u2212z). Then, we blindly initialized the hyperparameters to \u03c3 = 1 and l = 0.25 for all the experiments; these values were updated with an empirical Bayesian method after each iteration. To compute the UCB by GP, we used \u03b7 = 0.05 for IMGPO and BaMSOO. For IMGPO, \u039emax was fixed to be 22 (the effect of selecting different values is discussed later). For BaMSOO and SOO, the parameter hmax was set to \u221a n, according to Corollary 4.3 in [18]. For GP-PI and GP-EI, we used the SOO algorithm and a local optimization method using gradients to solve the auxiliary optimization. For SOO, BaMSOO and IMGPO, we used the corresponding deterministic division procedure (given \u2126, the initial point is fixed and no randomness exists). For GP-PI and GP-EI, we randomly initialized the first evaluation point and report the mean and one standard deviation for 50 runs.\nThe experimental results for eight different objective functions are shown in Figure 2. The vertical axis is log10(f(x\u2217) \u2212 f(x+)), where f(x\u2217) is the global optima and f(x+) is the best value found by the algorithm. Hence, the lower the plotted value on the vertical axis, the better the algorithm\u2019s performance. The last five functions are standard benchmarks for global optimization [21]. The first two were used in [18] to test SOO, and can be written as fsin1(x) = (sin(13x) sin +1)/2 for Sin1 and fsin2(x) = fsin1(x1)fsin1(x2) for Sin2. The form of the third function is given in Equation (16) and Figure 2 in [22]. The last function is Sin2 embedded in 1000 dimension in the same manner described in Section 4.1 in [14], which is used here to illustrate a possibility of using IMGPO as a main subroutine to scale up to higher dimensions with additional assumptions. For this function, we used REMBO [14] with IMGPO and BaMSOO as its Bayesian optimization subroutine. All of these functions are multimodal, except for Rosenbrock2, with dimensionality from 1 to 1000.\nAs we can see from Figure 2, IMGPO outperformed the other algorithms in general. SOO produced the competitive results for Rosenbrock2 because our GP prior was misleading (i.e., it did not model the objective function well and thus the property f(x) \u2264 U(x|D) did not hold many times). As can be seen in Table 1, IMGPO is much faster than traditional GP optimization methods although it is slower than SOO. For Sin 1, Sin2, Branin and Hartmann3, increasing \u039emax does not affect IMGPO because \u039en did not reach \u039emax = 22 (Figure 2). For the rest of the test functions, we would be able to improve the performance of IMGPO by increasing \u039emax at the cost of extra CPU time."}, {"heading": "6 Conclusion", "text": "We have presented the first GP-based optimization method with an exponential convergence rate O ( \u03bbN+Ngp ) (\u03bb < 1) without the need of auxiliary optimization and the \u03b4-cover sampling. Perhaps more importantly in the viewpoint of a broader global optimization community, we have provided a practically oriented analysis framework, enabling us to see why not relying on a particular bound is advantageous, and how a non-tight bound can still be useful (in Remarks 1, 2 and 3). Following the advent of the DIRECT algorithm, the literature diverged along two paths, one with a particular bound and one without. GP-UCB can be categorized into the former. Our approach illustrates the benefits of combining these two paths.\nAs stated in Section 3.1, our solution idea was to use a bound-based method but rely less on the estimated bound by considering all the possible bounds. It would be interesting to see if a similar principle can be applicable to other types of bound-based methods such as planning algorithms (e.g., A* search and the UCT or FSSS algorithm [23]) and learning algorithms (e.g., PAC-MDP algorithms [24])."}, {"heading": "Acknowledgments", "text": "The authors would like to thank Dr. Remi Munos for his thoughtful comments and suggestions. We gratefully acknowledge support from NSF grant 1420927, from ONR grant N00014-14-1-0486, and from ARO grant W911NF1410433. Kenji Kawaguchi was supported in part by the Funai Overseas Scholarship. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of our sponsors.\nBayesian Optimization with Exponential Convergence: Supplementary Material\nIn this supplementary material, we provide the proofs of the theoretical results. Along the way, we also prove regret bounds for a general class of algorithms, the result of which may be used to design a new algorithm.\nWe first provide a known property of the upper confidence bound of GP.\nLemma 1. (Bound Estimated by GP) According to the belief encoded in the GP prior/posterior2, for any x, f(x) \u2264 U(x|D) holds during the execution of Algorithm 1 with probability at least 1\u2212 \u03b7.\nProof. It follows the proof of lemma 5.1 of [15]. From the property of the standard gaussian distribution, Pr(f(x) > U(x|D)) < 12e\n\u2212\u03c22M/2. Taking union bound on the entire execution of Algorithm 1, Pr(f(x) > U(x|D) \u2200M \u2265 1) < 12 \u2211\u221e M=1 e \u2212\u03c22M/2. Substituting \u03c2M = \u221a\n2 log(\u03c02M2/12\u03b7), we obtain the statement.\nOur algorithm has a concrete division procedure in line 27 of Algorithm 1. However, one may improve the algorithm with different division procedures. Accordingly, we first derive abstract version of regret bound for the IMGPO (Algorithm 1) under a family of division procedures that satisfy Assumptions 3 and 4. After that, we provide a proof for the main results in the paper."}, {"heading": "A With Family of Division Procedure", "text": "In this section, we modify the result obtained by [18]. Let xh,i to be any point in the region covered by the ith hyperinterval at depth h, and x\u2217h,i be the global optimizer that may exist in the i\nth hyperinterval at depth h. The previous work provided the regret bound of the SOO algorithm with a family of division procedure that satisfies the following two assumptions.\nAssumption 3. (Decreasing diameter) There exists a diameter function \u03b4(h) > 0 such that, for any hyperinterval \u03c9h,i \u2282 \u2126 and its center ch,i \u2208 \u03c9h,i and any xh,i \u2208 \u03c9h,i, we have \u03b4(h) \u2265 supxh,i`(xh,i, ch,i) and \u03b4(h\u2212 1) \u2265 \u03b4(h) for all h \u22651. Assumption 4. (Well-shaped cell) There exists \u03bd > 0 such that any hyperinterval \u03c9h,i contains at least an `-ball of radius \u03bd\u03b4(h) centered in \u03c9h,i.\nThus, in this section, hyperinterval is not restricted to hyperrectangle. We now revisit the definitions of several terms and variables used in [18]. Let the -optimal space X be defined as X := {x \u2208 \u2126 : f(x) + \u2265 f(x\u2217)}. That is, the -optimal space is the set of input vectors whose function value is at least -close to the global optima. To bound the number of hyperintervals relevant to this -optimal space, we define a near-optimality dimension as follows.\nDefinition 3. (Near-optimality dimension) The near-optimality dimension is the smallest d > 0 such that, there exists C > 0, for all > 0, the maximum number of disjoint `-balls of radius \u03bd with center in the -optimal space X is less than C \u2212d.\nFinally, we define the set of \u03b4-optimal hyperintervals I\u03b4(h) as I\u03b4(h) := {c \u2208 \u2126 : f(c) + \u03b4(h) \u2265 f(x\u2217), c is the center point of the interval, \u03c9h,i, for some (h, i)}. The \u03b4-optimal hyperinterval I\u03b4(h) is used to relate the hyperintervals to the -optimal space. Indeed, the \u03b4-optimal hyperinterval I\u03b4(h) is almost identical to the \u03b4(h)-optimal space X\u03b4(h), except that I\u03b4(h) is focused on the center points\n2Thus, the probability in this analysis should be seen as that of the subjective view. If we assume that f is indeed a sample from the GP, we have the same result with the objective view of probability.\nwhereas X\u03b4(h) considers the whole input vector space. In the following, we use |I\u03b4(h)| to denote the number of I\u03b4(h) and derive its upper bound.\nLemma 2. (Lemma 3.1 in [18]) Let d be the near-optimality dimension and C denote the corresponding constant in Definition 1. Then, the number of \u03b4-optimal hyperintervals is bounded by |I\u03b4(h)|\u2264 C\u03b4(h)\u2212d.\nWe are now ready to present the main result in this section. In the following, we use the term optimal hyperinterval to indicate a hyperinterval that contains a global optimizer x\u2217. We say a hyperinterval is dominated by other intervals when it is rejected or not selected in step (i)-(iii). In Lemma 3, we bound the maximum size of the optimal hyperinterval. From Assumption 1, this can be translated to the regret bound, as we shall see in Theorem 2.\nLemma 3. Let \u039en \u2264 min(\u039e,\u039emax) be the largest \u03be used so far with n total node expansions. Let h\u2217n be the depth of the deepest expanded node that contains a global optimizer x\n\u2217 after n total node expansions (i.e., h\u2217n \u2264 n determines the size of the optimal hyperinterval). Then, with probability at least 1\u2212 \u03b7, h\u2217n is bounded below by some h\u2032 that satisfies\nn \u2265 \u2211h\u2032+\u039e l=0 |Il|\u2211 \u03c4 =1 \u03c1\u03c4 .\nProof. Let Th denote the time at which the optimal hyperinterval is further divided. We prove the statement by showing that the time difference Th+1 \u2212 Th is bounded by the number of \u03b4-optimal hyperintervals. To do so, we first note that there are three types of hyperinterval that can dominate an optimal hyperinterval ch+1,\u2217 during the time [Th, Th+1 \u2212 1], all of which belong to \u03b4-optimal hyperintervals I\u03b4 . The first type has the same size (i.e., same depth h), ch+1,i. In this case,\nf(ch+1,i) \u2265 f(ch+1,\u2217) \u2265 f(x\u2217h+1,\u2217)\u2212 \u03b4(h+ 1),\nwhere the first inequality is due to line 10 (step (i)) and the second follows Assumptions 1 and 2. Thus, it must be ch+1,i \u2208 Ih+1. The second case is where the optimal hyperinterval may be dominated by a hyperinterval of larger size (depth l < h+ 1), cl,i. In this case, similarly,\nf(cl,i) \u2265 f(ch+1,\u2217) \u2265 f(x\u2217h+1,\u2217)\u2212 \u03b4(l),\nwhere the first inequality is due to lines 11 to 12 (step (ii)) and thus cl,i \u2208 Il. In the final scenario, the optimal hyperinterval is dominated by a hyperinterval of smaller size (depth h+1+\u03be), ch+1+\u03be,i. In this case,\nf(ch+1+\u03be,i) \u2265 z(h+ 1, \u2217) \u2265 f(x\u2217h+1,\u2217)\u2212 \u03b4(h+ 1 + \u03be)\nwith probability at least 1\u2212 \u03b7 where z(\u00b7, \u00b7) is defined in line 21 of Algorithm 1. The first inequality is due to lines 19 to 23 (step (iii)) and the second inequality follows Lemma 1 and Assumptions 1 and 3. Hence, we can see that ch+1+\u03be,i \u2208 Ih+1+\u03be. For all of the above arguments, the temporarily assigned U under GP has no effect. This is because the algorithm still covers the above three types of \u03b4-optimal hyperintervals I\u03b4 , as U \u2265 f with probability at least 1\u2212 \u03b7 (Lemma 1). However, these are only expanded based on f because of the temporary nature of U . Putting these results together,\nTh+1 \u2212 Th \u2264\n\u2211h+1+\u039en l=1 |I\u03b4(l)|\u2211\n\u03c4=1\n\u03c1\u03c4 .\nSince if one of the I\u03b4 is divided during [Th, Th+1 \u2212 1], it cannot be divided again during another time period,\nh\u2217n\u2211 h=0 Th+1 \u2212 Th \u2264 \u2211h\u2217n+1+\u039en l=1 |Il|\u2211 \u03c4=1 \u03c1\u03c4 ,\nwhere on the right-hand side, we could combine the summation \u2211h\u2217n h=0 and \u2211\u2211h+1+\u039en l=1 |I\u03b4(l)|\n\u03c4=1 into the one, because each h in the summation refers to the same \u03b4-optimal interval I\u03b4(l) with l \u2264 h\u2217n+1+\u039en,\nand should not be double-counted. As \u2211h\u2217n h=0 Th+1 \u2212 Th = Th\u2217n+1 \u2212 T0, T0 = 1 and |I\u03b4(0)|= 1,\nTh\u2217n+1 \u2264 1 + \u2211h\u2217n+1+\u039en l=1 |Il|\u2211 \u03c4=1 \u03c1\u03c4 \u2264 \u2211h\u2217n+1+\u039en l=0 |Il|\u2211 \u03c4=1 \u03c1\u03c4 .\nAs Th\u2217n+1 > n by definition, for any h \u2032 such that\n\u2211\u2211h\u2032+\u039en l=0 |Il| \u03c4=1 \u03c1\u03c4 \u2264 n < \u2211\u2211h\u2217n+1+\u039en l=0 |Il| \u03c4=1 \u03c1\u03c4 , we\nhave h\u2217n > h \u2032.\nWith Lemmas 2 and 3, we are ready to present a finite regret bound with the family of division procedures.\nTheorem 2. Assume Assumptions 1, 3, and 4. Let h(n) be the smallest integer h such that\nn \u2264 C\n\u2211h+\u039en l=0 \u03b4(l)\n\u2212d\u2211 \u03c4=1 \u03c1\u03c4 .\nThen, with probability at least 1 \u2212 \u03b7, the regret of the IMGPO with any general division procedure is bounded as\nrn \u2264 \u03b4(h(n)\u2212 1).\nProof. Let c(n) and ch\u2217n,\u2217 be the center point expanded at the nth expansion and the optimal hyperinterval containing a global optimizer x\u2217, respectively. Then, from Assumptions 1, 3, and 4, f(c(n)) \u2265 f(ch\u2217n,\u2217) \u2265 f\n\u2217 \u2212 \u03b4(h\u2217n), where f\u2217 is the global optima. Hence, the regret bound is rh \u2264 \u03b4(h\u2217n). To find a lower bound for the quantity h\u2217n, we first relate h(n) to Lemma 3 by\nn >\nC \u2211h(n)+\u039en\u22121 l=0 \u03b4(l)\n\u2212d\u2211 \u03c4=1 \u03c1\u03c4 \u2265 \u2211h(n)+\u039en\u22121 l=0 |Il|\u2211 \u03c4=1 \u03c1\u03c4 ,\nwhere the first inequality comes from the definition of h(n), and the second follows from Lemma 2. Then, from Lemma 3, we have h\u2217n \u2265 h(n)\u2212 1. Therefore, rn \u2264 \u03b4(h\u2217n) \u2264 \u03b4(h(n)\u2212 1).\nAssumption 5. (Decreasing diameter revisit) The decreasing diameter defined in Assumption 3 can be written as \u03b4(h) = c1\u03b3h/D for some c1 > 0 and \u03b3 < 1 with a division procedure that requires c2 function evaluations per node expansion.\nCorollary 1. Assume Assumptions 1, 3, 4, and 5. Then, if d = 0, with probability at least 1\u2212 \u03b7, rN \u2264 O ( exp ( \u2212N +Ngp c2CD\u03c1\u0304t )) .\nIf d > 0, with probability at least 1\u2212 \u03b7,\nrN \u2264 O\n(( 1\nN +Ngp\n)1/d( \u2212 c2C\u03c1\u0304t\n1\u2212 \u03b3d/D\n)1/d \u03b3\u2212 1 D ) .\nProof. For the case d = 0, we have n \u2264 \u2211C\u2211h(n)+\u039enl=0 \u03b4(l)\u2212d \u03c4=1 \u03c1\u03c4 \u2264 \u2211C(h(n)+\u039en+1) \u03c4=1 \u03c1\u0304t, where the first inequality follows from the definition of h(n), and the second comes from the definition of \u03c1\u0304t and the assumption d = 0. The second inequality holds for \u03c1\u0304t that only considers \u03c1\u03c4 with \u03c4 \u2264 t. This is computable, because \u03c4 \u2264 t by construction. Indeed, the condition of Lemma 3 implies t \u2265 \u2211h\u2032+\u039en l=0 |Il|. Therefore, the two inequalities hold, and we can deduce that h(n) \u2265 n C\u03c1\u0304t \u2212\u039en\u22121 by algebraic manipulation. By Assumption 5, n = (N +Ngp)/c2. With this, substituting the lower bound of h(n) into the statement of Theorem 2 with Assumption 5,\nrN \u2264 c1 exp ( \u2212 [ N +Ngp c2D 1 C\u03c1\u0304t \u2212 \u039en \u2212 2 ] ln 1 \u03b3 ) .\nSimilarly, for the case d > 0,\nn \u2264 C\n\u2211h(n)+\u039en l=0 \u03b4(l)\n\u2212d\u2211 \u03c4=1 \u03c1\u03c4 \u2264 c\u2212dC \u03b3 \u2212(h(n)+\u039en+1)d/D\u22121 \u03b3\u2212d/D\u22121\u2211 \u03c4=1 \u03c1\u0304t,\nand hence c\u03b3 h(n)+\u039en D \u2264 ( n(1\u2212\u03b3d/D)\nC\u03c1\u0304t\n)\u22121/d by algebraic manipulation. Substituting this into the\nresult of Theorem 2, we arrive at the desired result."}, {"heading": "B With a Concrete Division Procedure", "text": "In this section, we prove the main result in the paper. In Theorem 1, we show that the exponential convergence rate bound O ( \u03bbN+Ngp ) with \u03bb < 1 is achieved without Assumptions 3, 4 and 5 and without the assumption that d = 0.\nTheorem 1. Assume Assumptions 1 and 2. Let \u03b2 = supx,x\u2032\u2208\u2126 12\u2016x\u2212x \u2032\u2016\u221e. Let \u03bb = 3\u2212 \u03b1 2C\u03c1\u0304tD < 1. Then, without Assumptions 3, 4 and 5 and without the assumption on d, with probability at least 1\u2212 \u03b7, the regret of IMGPO with the division procedure in Algorithm 1 is bounded as\nrN \u2264 L(3\u03b2D1/p)\u03b1 exp ( \u2212\u03b1 [ N +Ngp 2C\u03c1\u0304tD \u2212 \u039en \u2212 2 ] ln 3 ) = O ( \u03bbN+Ngp ) .\nProof. To prove the statement, we show that Assumptions 3, 4, and 5 can all be satisfied while maintaining d = 0. From Assumption 2 (i), and based on the division procedure that the algorithm uses,\nsup x\u2208\u03c9h,i `(x, ch,i) \u2264 sup x\u2208\u03c9h,i\nL||x\u2212 ch,i||\u03b1p\u2264 L ( 3\u2212bh/Dc\u03b2D1/p )\u03b1 .\nThis upper bound corresponds to the diagonal length of each hyperrectangle with respect to pnorm, where 3\u2212bh/Dc\u03b2 corresponds to the length of the longest side. We fix the form of \u03b4 as \u03b4(h) = L3\u03b1D\u03b1/p3\u2212h\u03b1/D\u03b2\u03b1 \u2265 L(3\u2212bh/Dc\u03b2D1/p)\u03b1, which satisfies Assumption 3.\nThis form of \u03b4(h) also satisfies Assumption 5 with \u03b3 = 3\u2212\u03b1 and c1 = L3\u03b1D\u03b1/p\u03b2\u03b1.\nEvery hyperrectangle contains at least one `-ball with a radius corresponding to the length of the shortest side of the hyperrectangle. Thus, we have at least one `-ball of radius \u03bd\u03b4(h) = L3\u2212\u03b1dh/De \u2265 L3\u2212\u03b13\u2212\u03b1h/D for every hyperrectangle with \u03bd \u2265 3\u22122\u03b1D\u2212\u03b1/p. This satisfies Assumption 4.\nFinally, we show that d = 0. The set of \u03b4-optimal hyperintervals I\u03b4(h) is contained by the \u03b4(h)optimal space X\u03b4(h) as\nI\u03b4(h) = {c \u2208 \u2126 : f(x\u2217)\u2212 f(c) \u2264 \u03b4(h), c is the center point of the interval, \u03c9h,i, for some (h, i)} \u2286 {x \u2208 \u2126 : f(x\u2217)\u2212 f(x) \u2264 \u03b4(h)} = X\u03b4(h)\nLet \u03b8 be a value that satisfies Assumption 2 (ii) (which is nonzero). Consider an `-ball of radius \u03b4(h) \u03b8 at x\n\u2217, which is a set {x \u2208 \u2126 | \u03b8`(x, x\u2217) \u2264 \u03b4(h)}. Since \u03b8`(x, x\u2217) \u2264 f(x\u2217) \u2212 f(x) by Assumption 2 (ii), the \u03b4(h)-optimal space X\u03b4(h) is covered by an `-ball of radius \u03b4(h) \u03b8 . Therefore, I\u03b4(h) \u2286 X\u03b4(h) \u2286 (an `-ball of radius \u03b4(h)\n\u03b8 at x\u2217). By Assumption 2 (i), the volume V of an `-ball of\nradius \u03bd\u03b4(h) is proportional to (\u03bd\u03b4(h))D as V pD(\u03bd\u03b4(h)) = (2\u03bd\u03b4(h)\u0393(1+1/p)) D/\u0393(1+D/p). Thus, the number of disjoint `-balls of radius \u03bd\u03b4(h) that fit in X\u03b4(h) is at most d( \u03b4(h)\u03b8\u03bd\u03b4(h) ) De = d(\u03b8\u03bd)\u2212De. Therefore, the number of `-balls does not depend on \u03b4(h) in this case, which means d = 0.\nNow that we have satisfied Assumptions 3, 4, and 5 with d = 0, \u03b3 = 3\u2212\u03b1, and c1 = L3\u03b1D\u03b1/p\u03b2\u03b1, we follow the proof of Corollary 1 and deduce the desired statement."}], "references": [{"title": "Exponential regret bounds for Gaussian process bandits with deterministic observations", "author": ["N. De Freitas", "A.J. Smola", "M. Zoghi"], "venue": "In Proceedings of the 29th International Conference on Machine Learning (ICML),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Bayesian Multi-Scale Optimistic Optimization", "author": ["Z. Wang", "B. Shakibi", "L. Jin", "N. de Freitas"], "venue": "In Proceedings of the 17th International Conference on Artificial Intelligence and Statistics (AISTAT),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Practical Bayesian optimization of machine learning algorithms", "author": ["J. Snoek", "H. Larochelle", "R.P. Adams"], "venue": "In Proceedings of Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Algorithms for noisy problems in gas transmission pipeline optimization", "author": ["R.G. Carter", "J.M. Gablonsky", "A. Patrick", "C.T. Kelley", "O.J. Eslinger"], "venue": "Optimization and engineering,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2001}, {"title": "Globally optimised parameters for a model of mitotic control in frog egg extracts", "author": ["J.W. Zwolak", "J.J. Tyson", "L.T. Watson"], "venue": "IEEE Proceedings-Systems Biology,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Global optima without convexity", "author": ["L.C.W. Dixon"], "venue": "Numerical Optimisation Centre, Hatfield Polytechnic,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1977}, {"title": "A sequential method seeking the global maximum of a function", "author": ["B.O. Shubert"], "venue": "SIAM Journal on Numerical Analysis,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1972}, {"title": "Outer approximation algorithm for nondifferentiable optimization problems", "author": ["D.Q. Mayne", "E. Polak"], "venue": "Journal of Optimization Theory and Applications,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1984}, {"title": "An algorithm for finding the global maximum of a multimodal, multivariate function", "author": ["R.H. Mladineo"], "venue": "Mathematical Programming,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1986}, {"title": "Convergence of an algorithm for finding a global extremum", "author": ["R.G. Strongin"], "venue": "Engineering Cybernetics,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1973}, {"title": "Local tuning and partition strategies for diagonal GO methods", "author": ["D.E. Kvasov", "C. Pizzuti", "Y.D. Sergeyev"], "venue": "Numerische Mathematik,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "Lipschitz bandits without the Lipschitz constant", "author": ["S. Bubeck", "G. Stoltz", "J.Y. Yu"], "venue": "In Algorithmic Learning Theory,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Bayesian Optimization with Inequality Constraints", "author": ["J. Gardner", "M. Kusner", "K. Weinberger", "J. Cunningham"], "venue": "In Proceedings of The 31st International Conference on Machine Learning (ICML),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Bayesian optimization in high dimensions via random embeddings", "author": ["Z. Wang", "M. Zoghi", "F. Hutter", "D. Matheson", "N. De Freitas"], "venue": "In Proceedings of the Twenty-Third international joint conference on Artificial Intelligence,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design", "author": ["N. Srinivas", "A. Krause", "M. Seeger", "S.M. Kakade"], "venue": "In Proceedings of the 27th International Conference on Machine Learning (ICML),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Machine learning: a probabilistic perspective", "author": ["K.P. Murphy"], "venue": "MIT press,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Gaussian Processes for Machine Learning", "author": ["C.E. Rasmussen", "C. Williams"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "Optimistic optimization of deterministic functions without the knowledge of its smoothness", "author": ["R. Munos"], "venue": "In Proceedings of Advances in neural information processing systems (NIPS),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Lipschitzian optimization without the Lipschitz constant", "author": ["D.R. Jones", "C.D. Perttunen", "B.E. Stuckman"], "venue": "Journal of Optimization Theory and Applications,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1993}, {"title": "High dimensional Bayesian optimisation and bandits via additive models", "author": ["K. Kandasamy", "J. Schneider", "B. Poczos"], "venue": "arXiv preprint arXiv:1503.01673,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Virtual library of simulation experiments: Test functions and datasets", "author": ["S. Surjanovic", "D. Bingham"], "venue": "Retrieved November", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Global and local optimization using radial basis function response surface models", "author": ["D.B. McDonald", "W.J. Grantham", "W.L. Tabor", "M.J. Murphy"], "venue": "Applied Mathematical Modelling,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "Integrating Sample-Based Planning and Model- Based Reinforcement Learning", "author": ["T.J. Walsh", "S. Goschin", "M.L. Littman"], "venue": "In Proceedings of the 24th AAAI conference on Artificial Intelligence (AAAI),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Reinforcement learning in finite MDPs: PAC analysis", "author": ["A.L. Strehl", "L. Li", "M.L. Littman"], "venue": "The Journal of Machine Learning Research (JMLR),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "Also, the existing Bayesian optimization method with exponential convergence [1] requires access to the \u03b4-cover sampling, which was considered to be impractical [1, 2].", "startOffset": 77, "endOffset": 80}, {"referenceID": 0, "context": "Also, the existing Bayesian optimization method with exponential convergence [1] requires access to the \u03b4-cover sampling, which was considered to be impractical [1, 2].", "startOffset": 161, "endOffset": 167}, {"referenceID": 1, "context": "Also, the existing Bayesian optimization method with exponential convergence [1] requires access to the \u03b4-cover sampling, which was considered to be impractical [1, 2].", "startOffset": 161, "endOffset": 167}, {"referenceID": 2, "context": "Such a problem arises in many realworld applications, such as parameter tuning in machine learning [3], engineering design problems [4], and model parameter fitting in biology [5].", "startOffset": 99, "endOffset": 102}, {"referenceID": 3, "context": "Such a problem arises in many realworld applications, such as parameter tuning in machine learning [3], engineering design problems [4], and model parameter fitting in biology [5].", "startOffset": 132, "endOffset": 135}, {"referenceID": 4, "context": "Such a problem arises in many realworld applications, such as parameter tuning in machine learning [3], engineering design problems [4], and model parameter fitting in biology [5].", "startOffset": 176, "endOffset": 179}, {"referenceID": 5, "context": "The general global optimization problem is known to be intractable if we make no further assumptions [6].", "startOffset": 101, "endOffset": 104}, {"referenceID": 6, "context": "A well-known variant of this assumption is Lipschitz continuity with a known Lipschitz constant, and many algorithms have been proposed in this setting [7, 8, 9].", "startOffset": 152, "endOffset": 161}, {"referenceID": 7, "context": "A well-known variant of this assumption is Lipschitz continuity with a known Lipschitz constant, and many algorithms have been proposed in this setting [7, 8, 9].", "startOffset": 152, "endOffset": 161}, {"referenceID": 8, "context": "A well-known variant of this assumption is Lipschitz continuity with a known Lipschitz constant, and many algorithms have been proposed in this setting [7, 8, 9].", "startOffset": 152, "endOffset": 161}, {"referenceID": 9, "context": "Some researchers relaxed this somewhat strong assumption by proposing procedures to estimate a Lipschitz constant during the optimization process [10, 11, 12].", "startOffset": 146, "endOffset": 158}, {"referenceID": 10, "context": "Some researchers relaxed this somewhat strong assumption by proposing procedures to estimate a Lipschitz constant during the optimization process [10, 11, 12].", "startOffset": 146, "endOffset": 158}, {"referenceID": 11, "context": "Some researchers relaxed this somewhat strong assumption by proposing procedures to estimate a Lipschitz constant during the optimization process [10, 11, 12].", "startOffset": 146, "endOffset": 158}, {"referenceID": 12, "context": "In the machine learning community, Bayesian optimization\u2014 especially by means of a Gaussian process (GP)\u2014is an active research area [13, 14, 15].", "startOffset": 132, "endOffset": 144}, {"referenceID": 13, "context": "In the machine learning community, Bayesian optimization\u2014 especially by means of a Gaussian process (GP)\u2014is an active research area [13, 14, 15].", "startOffset": 132, "endOffset": 144}, {"referenceID": 14, "context": "In the machine learning community, Bayesian optimization\u2014 especially by means of a Gaussian process (GP)\u2014is an active research area [13, 14, 15].", "startOffset": 132, "endOffset": 144}, {"referenceID": 0, "context": "[1] recently proposed a theoretical procedure that maintains an exponential convergence rate (exponential regret).", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2], one remaining problem is to derive a GP-based optimization method with an exponential convergence rate without the \u03b4-cover sampling procedure, which is computationally too demanding in many cases.", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "The kernel parameters or hyperparameters can be estimated by empirical Bayesian methods [16]; see [17] for more information about GP.", "startOffset": 88, "endOffset": 92}, {"referenceID": 16, "context": "The kernel parameters or hyperparameters can be estimated by empirical Bayesian methods [16]; see [17] for more information about GP.", "startOffset": 98, "endOffset": 102}, {"referenceID": 0, "context": "[1] recently presented a theoretical procedure that maintains exponential convergence rate.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "However, their own paper and the follow-up research [1, 2] point out that this result relies on an impractical sampling procedure, the \u03b4-cover sampling.", "startOffset": 52, "endOffset": 58}, {"referenceID": 1, "context": "However, their own paper and the follow-up research [1, 2] point out that this result relies on an impractical sampling procedure, the \u03b4-cover sampling.", "startOffset": 52, "endOffset": 58}, {"referenceID": 1, "context": "[2] combined GP-UCB with a hierarchical partitioning optimization method, the SOO algorithm [18], providing a regret bound with polynomial dependence on the number of function evaluations.", "startOffset": 0, "endOffset": 3}, {"referenceID": 17, "context": "[2] combined GP-UCB with a hierarchical partitioning optimization method, the SOO algorithm [18], providing a regret bound with polynomial dependence on the number of function evaluations.", "startOffset": 92, "endOffset": 96}, {"referenceID": 1, "context": "The most closely related algorithm is the BaMSOO algorithm [2], which combines SOO with GPUCB.", "startOffset": 59, "endOffset": 62}, {"referenceID": 18, "context": "[19].", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "Their DIRECT algorithm has been successfully applied to real-world problems [4, 5], but it only maintains the consistency property (i.", "startOffset": 76, "endOffset": 82}, {"referenceID": 4, "context": "Their DIRECT algorithm has been successfully applied to real-world problems [4, 5], but it only maintains the consistency property (i.", "startOffset": 76, "endOffset": 82}, {"referenceID": 17, "context": "This idea was generalized to the case of an unknown semi-metric and strengthened with a theoretical support (finite regret bound) by Munos [18] in the SOO algorithm.", "startOffset": 139, "endOffset": 143}, {"referenceID": 17, "context": "For example, the DOO algorithm [18] has \u03c1t = 1 \u2200t \u2265 1.", "startOffset": 31, "endOffset": 35}, {"referenceID": 1, "context": "The closest result in previous work is that of BaMSOO [2], which obtained \u00d5(n 2\u03b1 D(4\u2212\u03b1) ) with probability 1 \u2212 \u03b7 for \u03b1 = {1, 2}.", "startOffset": 54, "endOffset": 57}, {"referenceID": 17, "context": "Here, C is a constant in N and is used in previous work [18, 2].", "startOffset": 56, "endOffset": 63}, {"referenceID": 1, "context": "Here, C is a constant in N and is used in previous work [18, 2].", "startOffset": 56, "endOffset": 63}, {"referenceID": 13, "context": "One strategy for addressing this problem would be to leverage additional assumptions such as those in [14, 20].", "startOffset": 102, "endOffset": 110}, {"referenceID": 19, "context": "One strategy for addressing this problem would be to leverage additional assumptions such as those in [14, 20].", "startOffset": 102, "endOffset": 110}, {"referenceID": 17, "context": "In this section, we compare the IMGPO algorithm with the SOO, BaMSOO, GP-PI and GP-EI algorithms [18, 2, 3].", "startOffset": 97, "endOffset": 107}, {"referenceID": 1, "context": "In this section, we compare the IMGPO algorithm with the SOO, BaMSOO, GP-PI and GP-EI algorithms [18, 2, 3].", "startOffset": 97, "endOffset": 107}, {"referenceID": 2, "context": "In this section, we compare the IMGPO algorithm with the SOO, BaMSOO, GP-PI and GP-EI algorithms [18, 2, 3].", "startOffset": 97, "endOffset": 107}, {"referenceID": 1, "context": "In previous work, BaMSOO and GP-UCB were tested with a pair of a handpicked good kernel and hyperparameters for each function [2].", "startOffset": 126, "endOffset": 129}, {"referenceID": 17, "context": "3 in [18].", "startOffset": 5, "endOffset": 9}, {"referenceID": 20, "context": "The last five functions are standard benchmarks for global optimization [21].", "startOffset": 72, "endOffset": 76}, {"referenceID": 17, "context": "The first two were used in [18] to test SOO, and can be written as fsin1(x) = (sin(13x) sin +1)/2 for Sin1 and fsin2(x) = fsin1(x1)fsin1(x2) for Sin2.", "startOffset": 27, "endOffset": 31}, {"referenceID": 21, "context": "The form of the third function is given in Equation (16) and Figure 2 in [22].", "startOffset": 73, "endOffset": 77}, {"referenceID": 13, "context": "1 in [14], which is used here to illustrate a possibility of using IMGPO as a main subroutine to scale up to higher dimensions with additional assumptions.", "startOffset": 5, "endOffset": 9}, {"referenceID": 13, "context": "For this function, we used REMBO [14] with IMGPO and BaMSOO as its Bayesian optimization subroutine.", "startOffset": 33, "endOffset": 37}, {"referenceID": 22, "context": ", A* search and the UCT or FSSS algorithm [23]) and learning algorithms (e.", "startOffset": 42, "endOffset": 46}, {"referenceID": 23, "context": ", PAC-MDP algorithms [24]).", "startOffset": 21, "endOffset": 25}, {"referenceID": 14, "context": "1 of [15].", "startOffset": 5, "endOffset": 9}, {"referenceID": 17, "context": "In this section, we modify the result obtained by [18].", "startOffset": 50, "endOffset": 54}, {"referenceID": 17, "context": "We now revisit the definitions of several terms and variables used in [18].", "startOffset": 70, "endOffset": 74}, {"referenceID": 17, "context": "1 in [18]) Let d be the near-optimality dimension and C denote the corresponding constant in Definition 1.", "startOffset": 5, "endOffset": 9}], "year": 2016, "abstractText": "This paper presents a Bayesian optimization method with exponential convergence without the need of auxiliary optimization and without the \u03b4-cover sampling. Most Bayesian optimization methods require auxiliary optimization: an additional non-convex global optimization problem, which can be time-consuming and hard to implement in practice. Also, the existing Bayesian optimization method with exponential convergence [1] requires access to the \u03b4-cover sampling, which was considered to be impractical [1, 2]. Our approach eliminates both requirements and achieves an exponential convergence rate.", "creator": "LaTeX with hyperref package"}}}