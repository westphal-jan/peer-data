{"id": "1605.02257", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-May-2016", "title": "A corpus of preposition supersenses in English web reviews", "abstract": "We present the first corpus annotated with preposition supersenses, delexicalized categories for semantic functions that can be characterized by English prepositions (Schneider et al., 2015), a scheme that improves on its predecessors to better enable comprehensive manual annotation, and a hierarchical organization of preposition supersenses, unlike the previous schemes. Our data will be published on the Internet after publication.", "histories": [["v1", "Sun, 8 May 2016 01:38:34 GMT  (428kb,D)", "http://arxiv.org/abs/1605.02257v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["nathan schneider", "jena d hwang", "vivek srikumar", "meredith green", "kathryn conger", "tim o'gorman", "martha palmer"], "accepted": false, "id": "1605.02257"}, "pdf": {"name": "1605.02257.pdf", "metadata": {"source": "CRF", "title": "A Corpus of Preposition Supersenses in English Web Reviews", "authors": ["Nathan Schneider", "Jena D. Hwang", "Vivek Srikumar", "Meredith Green", "Kathryn Conger", "Tim O\u2019Gorman", "Martha Palmer"], "emails": ["nschneid@inf.ed.ac.uk", "jhwang@ihmc.us", "svivek@cs.utah.edu", "laura.green@colorado.edu", "kathryn.conger@colorado.edu", "timothy.ogorman@colorado.edu", "martha.palmer@colorado.edu"], "sections": [{"heading": "1 Introduction", "text": "English prepositions exhibit stunning frequency and wicked polysemy. In the 450M-word COCA corpus (Davies, 2010), 11 prepositions are more frequent than the most frequent noun.1 In the corpus presented in this paper, prepositions account for 8.5% of tokens (the top 11 prepositions comprise >6% of all tokens). Far from being vacuous grammatical formalities, prepositions serve as essential linkers of meaning, and the few extremely frequent ones are exploited for many different functions (figure 1). For all their importance, however, prepositions have received relatively little attention in computational semantics, and the community has not yet arrived at a comprehensive and reliable scheme for annotating the semantics prepositions in context (\u00a72). We believe that such annotation of preposition functions is needed if preposition sense disambiguation systems are to be useful for downstream tasks\u2014e.g., translation2 or semantic parsing (cf. Dahlmeier et al., 2009; Srikumar and Roth, 2011).\n1http://www.wordfrequency.info/free.asp?s=y 2This work focuses on English, but adposition and case systems vary considerably between languages, challenging second language learners and machine translation systems (Chodorow et al., 2007; Shilon et al., 2012; Hashemi and Hwa, 2014).\nThis paper describes a new corpus fully annotated with preposition supersenses (hierarchically organized unlexicalized classes). We note that none of the existing English corpora annotated with preposition semantics, on which existing disambiguation models have been trained and evaluated, are both comprehensive (describing all preposition types and tokens) and double-annotated (to attenuate subjectivity in the annotation scheme and measure inter-annotator agreement). As an alternative to fine-grained sense annotation for individual prepositions\u2014which is difficult and limited by the coverage and quality of a lexicon\u2014we instead train human annotators to label preposition supersenses, reporting the first inter-annotator agreement figures for this task. We comprehensively annotate English preposition tokens in a corpus of web reviews and examine the distribution of their supersenses, and improve upon the supersense hierarchy as necessitated by the data encountered during the annotation process. Our annotated corpus will be publicly released at the time of publication."}, {"heading": "2 Background and Motivation", "text": "Theoretical linguists have puzzled over questions such as how individual prepositions can acquire such a broad range of meanings\u2014and to what extent those meanings are systematically related (e.g., Brugman, 1981; Lakoff, 1987; Tyler and Evans,\nar X\niv :1\n60 5.\n02 25\n7v 1\n[ cs\n.C L\n] 8\nM ay\n2 01\n6\n2003; O\u2019Dowd, 1998; Saint-Dizier and Ide, 2006; Lindstromberg, 2010).\nPrepositional polysemy has also been recognized as a challenge for AI (Herskovits, 1986) and natural language processing, motivating semantic disambiguation systems (O\u2019Hara and Wiebe, 2003; Ye and Baldwin, 2007; Hovy et al., 2010; Srikumar and Roth, 2013b). Training and evaluating these requires semantically annotated corpus data. Below, we comment briefly on existing resources and why (in our view) a new resource is needed to \u201croad-test\u201d an alternative, hopefully more scalable, semantic representation for prepositions."}, {"heading": "2.1 Existing Preposition Corpora", "text": "Beginning with the seminal resources from The Preposition Project (TPP; Litkowski and Hargraves, 2005), the computational study of preposition semantics has been fundamentally grounded in corpus-based lexicography centered around individual preposition types. Most previous datasets of preposition semantics at the token level (Litkowski and Hargraves, 2005, 2007; Dahlmeier et al., 2009; Tratz and Hovy, 2009; Srikumar and Roth, 2013a) only cover high-frequency prepositions (the 34 represented in the SemEval-2007 shared task based on TPP, or a subset thereof).3\nWe sought a scheme that would facilitate comprehensive semantic annotation of all preposition tokens in a corpus: thus, it would have to cover the full range of usages possible for the full range of English preposition types. The recent TPP PDEP corpus (Litkowski, 2014, 2015) comes closer to this goal, as it consists of randomly sampled tokens for over 300 types. However, sentences were sampled separately for each preposition, so there is only one annotated preposition token per sentence. By contrast, we will fully annotate documents for all preposition tokens. No inter-annotator agreement figures have been reported for the PDEP data to indicate its quality, or the overall difficulty of token annotation with TPP senses across a broad range of prepositions."}, {"heading": "2.2 Supersenses", "text": "From the literature on other kinds of supersenses, there is reason to believe that token annotation with\n3A further limitation of the SemEval-2007 dataset is the way in which it was sampled: illustrative tokens from a corpus were manually selected by a lexicographer. As (Litkowski, 2014) showed, a disambiguation system trained on this dataset will therefore be biased and perform poorly on an ecologically valid sample of tokens.\npreposition supersenses (Schneider et al., 2015) will be more scalable and useful than senses. The term supersense has been applied to lexical semantic classes that label a large number of word types (i.e., they are unlexicalized). The best-known supersense scheme draws on two inventories\u2014one for nouns and one for verbs\u2014which originated as a high-level partitioning of senses in WordNet (Miller et al., 1990). A scheme for adjectives has been proposed as well (Tsvetkov et al., 2014).\nOne argument advanced in favor of supersenses is that they provide a coarse level of generalization for essential contextual distinctions\u2014such as artifact vs. person for chair, or temporal vs. locative in\u2014without being so fine-grained that systems cannot learn them (Ciaramita and Altun, 2006). A similar argument applies for human learning as pertains to rapid, cost-effective, and open-vocabulary annotation of corpora: an inventory of dozens of categories (with mnemonic names) can be learned and applied to unlimited vocabulary without having to refer to dictionary definitions (Schneider et al., 2012). Like with WordNet for nouns and verbs, the same argument holds for prepositions: TPPstyle sense annotation requires familiarity with a different set of (often highly nuanced) distinctions for each preposition type. For example, in has 15 different TPP senses, among them in 10(7a) \u2018indicating the key in which a piece of music is written: Mozart\u2019s Piano Concerto in E flat\u2019.\nSupersenses have been exploited for a variety of tasks (e.g., Agirre et al., 2008; Tsvetkov et al., 2013, 2015), and full-sentence noun and verb taggers have been built for several languages (Segond et al., 1997; Johannsen et al., 2014; Picca et al., 2008; Mart\u00ednez Alonso et al., 2015; Schneider et al., 2013, 2016). They are typically implemented as sequence taggers. In the present work, we extend a corpus that has already been hand-annotated with noun and verb supersenses, thus raising the possibility of systems that can learn all three kinds of supersenses jointly (cf. Srikumar and Roth, 2013b)."}, {"heading": "2.3 PrepWiki", "text": "Schneider et al.\u2019s (2015) preposition supersense scheme is described in detail in a lexical resource, PrepWiki,4 which records associations between supersenses and preposition types. Hereafter, we adopt the term usage for a pairing of a preposition type and a supersense label\u2014e.g., at/TIME. Usages\n4http://tiny.cc/prepwiki\nare organized in PrepWiki via (lexicalized) senses from the TPP lexicon. The mapping is many-tomany, as senses and supersenses capture different generalizations. (TPP senses, being lexicalized, are more numerous and generally finer-grained, but in some cases lump together functions that receive different supersenses, as in the sense for 2(2) \u2018affecting, with regard to, or in respect of\u2019.) Thus, for a given preposition, a sense may be mapped to multiple usages, and vice versa."}, {"heading": "2.4 The Supersense Hierarchy", "text": "Of the four supersense schemes mentioned above, Schneider et al.\u2019s (2015) inventory for prepositions (which improved upon the inventory of Srikumar and Roth (2013a)) is unique in being hierarchical. It is an inheritance hierarchy (see figure 2): characteristics of higher-level categories are asserted to apply to their descendants. Multiple inheritance is used for cases of overlap: e.g., DESTINATION inherits from both LOCATION (because a destination is a point in physical space) and GOAL (it is the endpoint of a concrete or abstract path).\nThe structure of the hierarchy was modeled after VerbNet\u2019s hierarchy of thematic roles (Bonial et al., 2011; Hwang, 2014). But there are many additional categories: some are refinements of the VerbNet roles (e.g., subclasses of TIME), while others have no VerbNet counterpart because they do not pertain to core roles of verbs. The CONFIGURATION subhierarchy, which is used for of and other prepositions when they relate two nominals, is a good example."}, {"heading": "3 Corpus Annotation", "text": ""}, {"heading": "3.1 Annotating Preposition Supersenses", "text": "Source data. We fully annotated the REVIEWS section of the English Web Treebank (Bies et al., 2012), selected because it had previously been annotated for multiword expressions and noun and verb supersenses (Schneider et al., 2014; Schneider and Smith, 2015). The corpus consists of 55,579 tokens organized into 3812 sentences and 723 documents, with gold tokenization and PTB-style POS tags.\nIdentifying preposition tokens. TPP, and therefore PrepWiki, contains senses for canonical prepositions, i.e., those used transitively in the [PP P NP] construction. Taking inspiration from Pullum and Huddleston (2002), PrepWiki further assigns supersenses to spatiotemporal particle uses of out, up, away, together, etc., and subordinating uses of as, after, in, with, etc. (including infinitival to and infinitival-subject for, as in It took over 1.5 hours for our food to come out).5\nNon-supersense labels. These are used where the heuristics fail (sometimes due to a POS tagging error) or where the preposition serves a special syntactic function not captured by the supersense inventory. The most frequent is `i, which applies only to infinitival to tokens that are not PURPOSE or FUNCTION adjuncts.6 The label `d applies to\n5PrepWiki does not include subordinators/ complementizers that cannot take NP complements: that, because, while, if, etc.\n6See figure 1 for examples from the corpus. I want/love/try to eat cookies and To love is to suffer would qualify as `i; a\ndiscourse expressions; the unqualified backtick (`) applies to miscellaneous cases such as infinitivalsubject for and both prepositions in the as-as comparative construction (as wet as water; as much cake as you want).\nMultiword expressions. Figure 3 shows how prepositions can interact with multiword expressions (MWEs). An MWE may function holistically as a preposition: PrepWiki treats these as multiword prepositions. An idiomatic phrase may be headed by a preposition, in which case we assign it a preposition supersense or tag it as a discourse expression (`d). Finally, a preposition may be embedded within an MWE (but not its head): we do not use a preposition supersense in this case, though the MWE as a whole may already be tagged with a verb supersense.\nHeuristics. The annotation tool uses heuristics to detect candidate preposition tokens in each sentence given its POS tagging and MWE annotation. A single-word expression is included if:\n\u2022 it is tagged as a verb particle (RP) or infinitival to (TO), or \u2022 it is tagged as a transitive preposition or subordinator (IN) or adverb (RB), and the word is listed in PrepWiki (or the spelling variants list). A strong MWE instance is included if: \u2022 the MWE begins with a word that matches the\nsingle-word criteria (idiomatic PP), or \u2022 the MWE is listed in PrepWiki (multiword\npreposition). Annotation task. Annotators proceeded sentence by sentence, working in a custom web interface\nshoulder to cry on would qualify as FUNCTION.\n(figure 4). For each token matched by the above heuristics, annotators filled in a text box with the contextually appropriate label. A dropdown menu showed the list of preposition supersenses and nonsupersense labels, starting with labels known to be associated with the preposition being annotated. Hovering over a menu item would show example sentences to illustrate the usage in question, as well as a brief definition of the supersense. This preposition-specific rendering of the dropdown menu\u2014supported by data from PrepWiki\u2014was crucial to reducing the overhead of annotation (and annotator training) by focusing the annotator\u2019s attention on the relevant categories/usages. New examples were added to PrepWiki as annotators spotted coverage gaps. The tool also showed the multiword expression annotation of the sentence, which could be modified if necessary to fit PrepWiki\u2019s conventions for multiword prepositions."}, {"heading": "3.2 Quality Control", "text": "Annotators. Annotators were selected from undergraduate and graduate linguistics students at the University of Colorado at Boulder. All annotators had prior experience with semantic role labeling. Every sentence was independently annotated by two annotators, and disagreements were subsequently adjudicated by a third, \u201cexpert\u201d annotator. There were two expert annotators, both authors of this paper.\nTraining. 200 sentences were set aside for training annotators. Annotators were first shown how to use the preposition annotation tool and instructed on the supersense distinctions for this task. Annotators then completed a training set of 100 sentences. An adjudicator evaluated the annotator\u2019s annotations, providing feedback and assigning another 50\u2013100 training instances if necessary.\nInter-annotator agreement (IAA) measures are useful in quantifying annotation \u201creliability\u201d, i.e., indicating how trustworthy and reproducible the process is (given guidelines, training, tools, etc.). Specifically, IAA scores can be used as a diagnostic for the reliability of (i) individual annotators (to identify those who need additional training/guidance); (ii) the annotation scheme and guidelines (to identify problematic phenomena requiring further documentation or substantive changes to the scheme); (iii) the final dataset (as an indicator of what could reasonably be expected of an automatic system).\nIndividual annotators. The main annotation was divided into 34 batches of 100 sentences. Each batch took on the order of an hour for an annotator to complete. We monitored original annotators\u2019 IAA throughout the annotation process as a diagnostic for when to intervene in giving further guidance. Original IAA for most of these batches fell between 60% and 78%, depending on factors such as the identities of the annotators and when the annotation took place (annotator experience and PrepWiki documentation improved over time).7 These rates show that it was not an easy annotation task, though many of the disagreements were over slight distinctions in the hierarchy (such as PURPOSE vs. FUNCTION). Guidelines. Though Schneider et al. (2015) conducted pilot annotation in constructing the supersense inventory, our annotators found a few details of the scheme to be confusing. Informed by their difficulties and disagreements, we therefore made several minor improvements to the preposition supersense categories and hierarchy structure. For example, the supersense categories for partitive constructions proved persistently problematic, so we adjusted their boundaries and names. We also improved the high-level organization of the original hierarchy, clarified some supersense descriptions,\n7Specifically, the agreement rate among tokens where both annotators assigned a preposition supersense was between 82% and 87% for 4 batches; 72% and 78% for 11; 60% and 70% for 17; and below 60% for 2. This measure did not award credit for agreement on non-supersense labels and ignored some cases of disagreement on the MWE analysis.\nand removed the miscellaneous OTHER supersense.\nRevisions. The changes to categories/guidelines noted in the previous paragraph required a smallscale post hoc revision to the annotations, which was performed by the expert annotators. Some additional post hoc revisions were performed to improve consistency; e.g., some anomalous multiword expression annotations involving prepositions were fixed.8\nAdjudication reliability. Because sentences were adjudicated by one of two expert annotators, we can estimate the dataset\u2019s adjudication reliability\u2014roughly, the expected proportion of tokens that would have been labeled the same way if adjudicated by the other expert\u2014by measuring IAA on a sample independently annotated by both experts.9 Applying this procedure to 203 sentences annotated late in the process (using the measure described in footnote 7) gives an agreement rate of 276/313 = 88%.10 It is difficult to put an exact\n8In particular, many of the borderline prepositional verbs were revised according to the guidlines outlined at https://github.com/nschneid/nanni/wiki/ Prepositional-Verb-Annotation-Guidelines.\n9These sentences were then jointly adjudicated by the experts to arrive at a final version.\n10For completeness, Cohen\u2019s \u03ba = .878. It is almost as high as raw agreement because the expected agreement rate is very low\u2014but keep in mind that \u03ba\u2019s model of chance agreement does not take into account preposition types or the fact that a relatively small subset of labels were suggested for most prepositions. On the 4 most frequent prepositions in the sample, per-preposition \u03ba is .84 for for, 1.0 for to, .59 for of, and .73 for in.\nquality figure on a dataset that was developed over a period of time and with the involvement of many individuals; however, the fact that the expert-to-expert adjudication estimate approaches 90% despite the large number of labels suggests that the data can serve as a reliable resource for training and benchmarking disambiguation systems."}, {"heading": "3.3 Resulting Corpus", "text": "4250 tokens have preposition supersenses. Their distribution appears in figure 5. Over 75% of tokens belong to the top 10 preposition types, while the supersense distribution is closer to uniform. 1170 tokens are labeled as LOCATION, PATH, or a subtype thereof: these can roughly be described as spatial. 528 come from the TEMPORAL subtree of the hierarchy, and 452 from the CONFIGURATION subtree. Thus, fully half the tokens (2100) mark non-spatiotemporal participants and circumstances.\nOf the 4250 tokens, 582 are MWEs (multiword prepositions and/or PP idioms).11 A further 588 have non-supersense labels: 484 `i, 83 `d, and 21 `."}, {"heading": "3.4 Splits", "text": "To facilitate future experimentation on a standard benchmark, we partitioned our data into training and test sets. We randomly sampled 447 sentences (4,073 total tokens and N = 950 = 19.6% of preposition instances) for a held-out test set, leaving 3,888 preposition instances for training.12 The sampling was stratified by preposition supersense so as to encourage a reasonable balance for the rare labels; e.g., supersenses that occur twice are split so that one instance is assigned to the training set\n11For the purpose of counting prepositions by type, we split up supersense-tagged PP idioms such as those shown in (5) and (6) by taking the longest prefix of words that has a PrepWiki entry to be the preposition.\n12Excluding `i and `other instances, the supersense-labeled prepositions amount to 3,397 training and 853 test instances.\nand one to the test set.13 Figure 6 shows, at a type level, the extent of overlap between the training set, test set, and PrepWiki. 61 preposition supersenses are attested in the training data, while 14 are unattested."}, {"heading": "4 Conclusion", "text": "We have introduced a new lexical semantics corpus that disambiguates prepositions with hierarchical supersenses. Because it is comprehensively annotated over full documents, it offers insights into the semantic distribution of prepositions. The corpus will further facilitate the development of automatic preposition disambiguation systems."}, {"heading": "Acknowledgments", "text": "We thank our annotators\u2014Evan Coles-Harris, Audrey Farber, Nicole Gordiyenko, Megan Hutto, Celeste Smitz, and Tim Watervoort\u2014as well as Ken Litkowski, Michael Ellsworth, Orin Hargraves, and Susan Brown for helpful discussions. This research was supported in part by a Google research grant for Q/A PropBank Annotation."}], "references": [{"title": "Improving parsing and PP attachment performance with sense information", "author": ["Eneko Agirre", "Timothy Baldwin", "David Martinez."], "venue": "Proc. of ACL-HLT, pages 317\u2013325. Columbus, Ohio, USA.", "citeRegEx": "Agirre et al\\.,? 2008", "shortCiteRegEx": "Agirre et al\\.", "year": 2008}, {"title": "English Web Treebank", "author": ["Ann Bies", "Justin Mott", "Colin Warner", "Seth Kulick."], "venue": "Technical Report LDC2012T13, Linguistic Data Consortium, Philadelphia, PA. URL http://www.ldc.upenn.edu/Catalog/ catalogEntry.jsp?catalogId=LDC2012T13.", "citeRegEx": "Bies et al\\.,? 2012", "shortCiteRegEx": "Bies et al\\.", "year": 2012}, {"title": "A hierarchical unification of LIRICS and VerbNet semantic roles", "author": ["Claire Bonial", "William Corvey", "Martha Palmer", "Volha V. Petukhova", "Harry Bunt."], "venue": "Fifth IEEE International Conference on Semantic Computing, pages 483\u2013489. Palo Alto, CA, USA.", "citeRegEx": "Bonial et al\\.,? 2011", "shortCiteRegEx": "Bonial et al\\.", "year": 2011}, {"title": "The story of \u2018over\u2019: polysemy, semantics and the structure of the lexicon", "author": ["Claudia Brugman."], "venue": "MA thesis, University of California, Berkeley, Berkeley, CA. Published New York: Garland, 1981.", "citeRegEx": "Brugman.,? 1981", "shortCiteRegEx": "Brugman.", "year": 1981}, {"title": "Detection of grammatical errors involving prepositions", "author": ["Martin Chodorow", "Joel R. Tetreault", "Na-Rae Han."], "venue": "Proc. of the Fourth ACL-SIGSEM Workshop on Prepositions, pages 25\u201330. Prague, Czech Republic.", "citeRegEx": "Chodorow et al\\.,? 2007", "shortCiteRegEx": "Chodorow et al\\.", "year": 2007}, {"title": "Broadcoverage sense disambiguation and information extraction with a supersense sequence tagger", "author": ["Massimiliano Ciaramita", "Yasemin Altun."], "venue": "Proc. of EMNLP, pages 594\u2013602. Sydney, Australia.", "citeRegEx": "Ciaramita and Altun.,? 2006", "shortCiteRegEx": "Ciaramita and Altun.", "year": 2006}, {"title": "Joint learning of preposition senses and semantic roles of prepositional phrases", "author": ["Daniel Dahlmeier", "Hwee Tou Ng", "Tanja Schultz."], "venue": "Proc. of EMNLP, pages 450\u2013458. Suntec, Singapore.", "citeRegEx": "Dahlmeier et al\\.,? 2009", "shortCiteRegEx": "Dahlmeier et al\\.", "year": 2009}, {"title": "The Corpus of Contemporary American English as the first reliable monitor corpus of English", "author": ["Mark Davies."], "venue": "Literary and Linguistic Computing, 25(4):447\u2013464.", "citeRegEx": "Davies.,? 2010", "shortCiteRegEx": "Davies.", "year": 2010}, {"title": "A comparison of MT errors and ESL errors", "author": ["Homa B. Hashemi", "Rebecca Hwa."], "venue": "Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proc. of LREC, pages 2696\u20132700.", "citeRegEx": "Hashemi and Hwa.,? 2014", "shortCiteRegEx": "Hashemi and Hwa.", "year": 2014}, {"title": "Language and spatial cognition: an interdisciplinary study of the prepositions in English", "author": ["Annette Herskovits."], "venue": "Studies in Natural Language Processing. Cambridge University Press, Cambridge, UK.", "citeRegEx": "Herskovits.,? 1986", "shortCiteRegEx": "Herskovits.", "year": 1986}, {"title": "What\u2019s in a preposition? Dimensions of sense disambiguation for an interesting word class", "author": ["Dirk Hovy", "Stephen Tratz", "Eduard Hovy."], "venue": "Coling 2010: Posters, pages 454\u2013462. Beijing, China.", "citeRegEx": "Hovy et al\\.,? 2010", "shortCiteRegEx": "Hovy et al\\.", "year": 2010}, {"title": "Identification and representation of caused motion constructions", "author": ["Jena D. Hwang."], "venue": "Ph.D. dissertation, University of Colorado, Boulder, Colorado.", "citeRegEx": "Hwang.,? 2014", "shortCiteRegEx": "Hwang.", "year": 2014}, {"title": "More or less supervised supersense tagging of Twitter", "author": ["Anders Johannsen", "Dirk Hovy", "H\u00e9ctor Mart\u00ednez Alonso", "Barbara Plank", "Anders S\u00f8gaard."], "venue": "Proc. of *SEM, pages 1\u201311. Dublin, Ireland.", "citeRegEx": "Johannsen et al\\.,? 2014", "shortCiteRegEx": "Johannsen et al\\.", "year": 2014}, {"title": "Women, fire, and dangerous things: what categories reveal about the mind", "author": ["George Lakoff."], "venue": "University of", "citeRegEx": "Lakoff.,? 1987", "shortCiteRegEx": "Lakoff.", "year": 1987}, {"title": "English Prepositions Explained", "author": ["Seth Lindstromberg."], "venue": "John Benjamins, Amsterdam, revised edition.", "citeRegEx": "Lindstromberg.,? 2010", "shortCiteRegEx": "Lindstromberg.", "year": 2010}, {"title": "Pattern Dictionary of English Prepositions", "author": ["Ken Litkowski."], "venue": "Proc. of ACL, pages 1274\u20131283. Baltimore, Maryland, USA.", "citeRegEx": "Litkowski.,? 2014", "shortCiteRegEx": "Litkowski.", "year": 2014}, {"title": "Notes on barbecued opakapaka: ontology in preposition patterns", "author": ["Ken Litkowski."], "venue": "Technical Report 15-01, CL Research, Damascus, MD. URL http://www.clres.com/ online-papers/PDEPOntology.pdf.", "citeRegEx": "Litkowski.,? 2015", "shortCiteRegEx": "Litkowski.", "year": 2015}, {"title": "The Preposition Project", "author": ["Ken Litkowski", "Orin Hargraves."], "venue": "Proc. of the Second ACL-SIGSEM Workshop on the Linguistic Dimensions of Prepositions and their Use in Computational Linguistics Formalisms and Applications, pages 171\u2013179. Colchester, Essex, UK.", "citeRegEx": "Litkowski and Hargraves.,? 2005", "shortCiteRegEx": "Litkowski and Hargraves.", "year": 2005}, {"title": "SemEval-2007 Task 06: Word-Sense Disambiguation of Prepositions", "author": ["Ken Litkowski", "Orin Hargraves."], "venue": "Proc. of SemEval, pages 24\u201329. Prague, Czech Republic.", "citeRegEx": "Litkowski and Hargraves.,? 2007", "shortCiteRegEx": "Litkowski and Hargraves.", "year": 2007}, {"title": "Supersense tagging for Danish", "author": ["H\u00e9ctor Mart\u00ednez Alonso", "Anders Johannsen", "Sussi Olsen", "Sanni Nimb", "Nicolai Hartvig S\u00f8rensen", "Anna Braasch", "Anders S\u00f8gaard", "Bolette Sandford Pedersen."], "venue": "Be\u00e1ta Megyesi, editor, Proc. of NODALIDA, pages 21\u201329. Vilnius, Lithuania.", "citeRegEx": "Alonso et al\\.,? 2015", "shortCiteRegEx": "Alonso et al\\.", "year": 2015}, {"title": "Five Papers on WordNet", "author": ["George A. Miller", "Richard Beckwith", "Christiane Fellbaum", "Derek Gross", "Katherine Miller."], "venue": "Technical Report 43, Princeton University, Princeton, NJ.", "citeRegEx": "Miller et al\\.,? 1990", "shortCiteRegEx": "Miller et al\\.", "year": 1990}, {"title": "Prepositions and particles in English: a discourse-functional account", "author": ["Elizabeth M. O\u2019Dowd"], "venue": null, "citeRegEx": "O.Dowd.,? \\Q1998\\E", "shortCiteRegEx": "O.Dowd.", "year": 1998}, {"title": "Preposition semantic classification via Treebank and FrameNet", "author": ["Tom O\u2019Hara", "Janyce Wiebe"], "venue": "Proc. of CoNLL,", "citeRegEx": "O.Hara and Wiebe.,? \\Q2003\\E", "shortCiteRegEx": "O.Hara and Wiebe.", "year": 2003}, {"title": "Supersense Tagger for Italian", "author": ["Davide Picca", "Alfio Massimiliano Gliozzo", "Massimiliano Ciaramita."], "venue": "Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odjik, Stelios Piperidis, and Daniel Tapias, editors, Proc. of LREC, pages 2386\u20132390. Marrakech, Mo-", "citeRegEx": "Picca et al\\.,? 2008", "shortCiteRegEx": "Picca et al\\.", "year": 2008}, {"title": "Prepositions and preposition phrases", "author": ["Geoffrey K. Pullum", "Rodney Huddleston."], "venue": "Rodney Huddleston and Geoffrey K. Pullum, editors, The Cambridge Grammar of the English Language, pages 579\u2013611. Cambridge University Press, Cambridge, UK.", "citeRegEx": "Pullum and Huddleston.,? 2002", "shortCiteRegEx": "Pullum and Huddleston.", "year": 2002}, {"title": "SemEval-2016 Task 10: Detecting Minimal Semantic Units and their Meanings (DiMSUM)", "author": ["Nathan Schneider", "Dirk Hovy", "Anders Johannsen", "Marine Carpuat."], "venue": "Proc. of SemEval. San Diego, California, USA.", "citeRegEx": "Schneider et al\\.,? 2016", "shortCiteRegEx": "Schneider et al\\.", "year": 2016}, {"title": "Supersense tagging for Arabic: the MT-in-the-middle attack", "author": ["Nathan Schneider", "Behrang Mohit", "Chris Dyer", "Kemal Oflazer", "Noah A. Smith."], "venue": "Proc. of NAACL-HLT, pages 661\u2013667. Atlanta, Georgia, USA.", "citeRegEx": "Schneider et al\\.,? 2013", "shortCiteRegEx": "Schneider et al\\.", "year": 2013}, {"title": "Coarse lexical semantic annotation with supersenses: an Arabic case study", "author": ["Nathan Schneider", "Behrang Mohit", "Kemal Oflazer", "Noah A. Smith."], "venue": "Proc. of ACL, pages 253\u2013258. Jeju Island, Korea.", "citeRegEx": "Schneider et al\\.,? 2012", "shortCiteRegEx": "Schneider et al\\.", "year": 2012}, {"title": "Comprehensive annotation of multiword expressions in a social web corpus", "author": ["Nathan Schneider", "Spencer Onuffer", "Nora Kazour", "Emily Danchik", "Michael T. Mordowanec", "Henrietta Conrad", "Noah A. Smith."], "venue": "Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Hrafn Lofts-", "citeRegEx": "Schneider et al\\.,? 2014", "shortCiteRegEx": "Schneider et al\\.", "year": 2014}, {"title": "A corpus and model integrating multiword expressions and supersenses", "author": ["Nathan Schneider", "Noah A. Smith."], "venue": "Proc. of NAACL-HLT, pages 1537\u20131547. Denver, Colorado.", "citeRegEx": "Schneider and Smith.,? 2015", "shortCiteRegEx": "Schneider and Smith.", "year": 2015}, {"title": "A hierarchy with, of, and for preposition supersenses", "author": ["Nathan Schneider", "Vivek Srikumar", "Jena D. Hwang", "Martha Palmer."], "venue": "Proc. of The 9th Linguistic Annotation Workshop, pages 112\u2013123. Denver, Colorado, USA.", "citeRegEx": "Schneider et al\\.,? 2015", "shortCiteRegEx": "Schneider et al\\.", "year": 2015}, {"title": "An experiment in semantic tagging using hidden Markov model tagging", "author": ["Fr\u00e9d\u00e9rique Segond", "Anne Schiller", "Gregory Grefenstette", "Jean-Pierre Chanod."], "venue": "Piek Vossen, Geert Adriaens, Nicoletta Calzolari, Antonio Sanfilippo, and Yorick Wilks, editors, Automatic Information Extrac-", "citeRegEx": "Segond et al\\.,? 1997", "shortCiteRegEx": "Segond et al\\.", "year": 1997}, {"title": "Incorporating linguistic knowledge in statistical machine translation: translating prepositions", "author": ["Reshef Shilon", "Hanna Fadida", "Shuly Wintner."], "venue": "Proc. of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data, pages 106\u2013114. Avignon, France.", "citeRegEx": "Shilon et al\\.,? 2012", "shortCiteRegEx": "Shilon et al\\.", "year": 2012}, {"title": "A joint model for extended semantic role labeling", "author": ["Vivek Srikumar", "Dan Roth."], "venue": "Proc. of EMNLP, pages 129\u2013139. Edinburgh, Scotland, UK.", "citeRegEx": "Srikumar and Roth.,? 2011", "shortCiteRegEx": "Srikumar and Roth.", "year": 2011}, {"title": "An inventory of preposition relations", "author": ["Vivek Srikumar", "Dan Roth."], "venue": "Technical Report arXiv:1305.5785. URL http://arxiv.org/abs/1305.5785.", "citeRegEx": "Srikumar and Roth.,? 2013a", "shortCiteRegEx": "Srikumar and Roth.", "year": 2013}, {"title": "Modeling semantic relations expressed by prepositions", "author": ["Vivek Srikumar", "Dan Roth."], "venue": "Transactions of the Association for Computational Linguistics, 1:231\u2013242.", "citeRegEx": "Srikumar and Roth.,? 2013b", "shortCiteRegEx": "Srikumar and Roth.", "year": 2013}, {"title": "Disambiguation of preposition sense using linguistically motivated features", "author": ["Stephen Tratz", "Dirk Hovy."], "venue": "Proc. of NAACL-HLT Student Research Workshop and Doctoral Consortium, pages 96\u2013100. Boulder, Colorado.", "citeRegEx": "Tratz and Hovy.,? 2009", "shortCiteRegEx": "Tratz and Hovy.", "year": 2009}, {"title": "Evaluation of word vector representations by subspace alignment", "author": ["Yulia Tsvetkov", "Manaal Faruqui", "Wang Ling", "Guillaume Lample", "Chris Dyer."], "venue": "Proc. of EMNLP. Lisbon, Portugal.", "citeRegEx": "Tsvetkov et al\\.,? 2015", "shortCiteRegEx": "Tsvetkov et al\\.", "year": 2015}, {"title": "Cross-lingual metaphor detection using common semantic features", "author": ["Yulia Tsvetkov", "Elena Mukomel", "Anatole Gershman."], "venue": "Proc. of the First Workshop on Metaphor in NLP, pages 45\u201351. Atlanta, Georgia, USA.", "citeRegEx": "Tsvetkov et al\\.,? 2013", "shortCiteRegEx": "Tsvetkov et al\\.", "year": 2013}, {"title": "Augmenting English adjective senses with supersenses", "author": ["Yulia Tsvetkov", "Nathan Schneider", "Dirk Hovy", "Archna Bhatia", "Manaal Faruqui", "Chris Dyer."], "venue": "Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan", "citeRegEx": "Tsvetkov et al\\.,? 2014", "shortCiteRegEx": "Tsvetkov et al\\.", "year": 2014}, {"title": "The Semantics of English Prepositions: Spatial Scenes, Embodied Meaning and Cognition", "author": ["Andrea Tyler", "Vyvyan Evans."], "venue": "Cambridge University Press, Cambridge, UK.", "citeRegEx": "Tyler and Evans.,? 2003", "shortCiteRegEx": "Tyler and Evans.", "year": 2003}, {"title": "MELB-YB: Preposition sense disambiguation using rich semantic features", "author": ["Patrick Ye", "Timothy Baldwin."], "venue": "Proc. of SemEval, pages 241\u2013244. Prague, Czech Republic.", "citeRegEx": "Ye and Baldwin.,? 2007", "shortCiteRegEx": "Ye and Baldwin.", "year": 2007}], "referenceMentions": [{"referenceID": 30, "context": "can be marked by English prepositions (Schneider et al., 2015).", "startOffset": 38, "endOffset": 62}, {"referenceID": 7, "context": "corpus (Davies, 2010), 11 prepositions are more frequent than the most frequent noun.", "startOffset": 7, "endOffset": 21}, {"referenceID": 33, "context": ", translation2 or semantic parsing (cf. Dahlmeier et al., 2009; Srikumar and Roth, 2011).", "startOffset": 35, "endOffset": 88}, {"referenceID": 4, "context": "asp?s=y 2This work focuses on English, but adposition and case systems vary considerably between languages, challenging second language learners and machine translation systems (Chodorow et al., 2007; Shilon et al., 2012; Hashemi and Hwa, 2014).", "startOffset": 177, "endOffset": 244}, {"referenceID": 32, "context": "asp?s=y 2This work focuses on English, but adposition and case systems vary considerably between languages, challenging second language learners and machine translation systems (Chodorow et al., 2007; Shilon et al., 2012; Hashemi and Hwa, 2014).", "startOffset": 177, "endOffset": 244}, {"referenceID": 8, "context": "asp?s=y 2This work focuses on English, but adposition and case systems vary considerably between languages, challenging second language learners and machine translation systems (Chodorow et al., 2007; Shilon et al., 2012; Hashemi and Hwa, 2014).", "startOffset": 177, "endOffset": 244}, {"referenceID": 9, "context": "Prepositional polysemy has also been recognized as a challenge for AI (Herskovits, 1986) and natural language processing, motivating semantic disam-", "startOffset": 70, "endOffset": 88}, {"referenceID": 22, "context": "biguation systems (O\u2019Hara and Wiebe, 2003; Ye and Baldwin, 2007; Hovy et al., 2010; Srikumar and Roth, 2013b).", "startOffset": 18, "endOffset": 109}, {"referenceID": 41, "context": "biguation systems (O\u2019Hara and Wiebe, 2003; Ye and Baldwin, 2007; Hovy et al., 2010; Srikumar and Roth, 2013b).", "startOffset": 18, "endOffset": 109}, {"referenceID": 10, "context": "biguation systems (O\u2019Hara and Wiebe, 2003; Ye and Baldwin, 2007; Hovy et al., 2010; Srikumar and Roth, 2013b).", "startOffset": 18, "endOffset": 109}, {"referenceID": 35, "context": "biguation systems (O\u2019Hara and Wiebe, 2003; Ye and Baldwin, 2007; Hovy et al., 2010; Srikumar and Roth, 2013b).", "startOffset": 18, "endOffset": 109}, {"referenceID": 17, "context": "Beginning with the seminal resources from The Preposition Project (TPP; Litkowski and Hargraves, 2005), the computational study of preposition", "startOffset": 66, "endOffset": 102}, {"referenceID": 15, "context": "As (Litkowski, 2014) showed, a disambiguation system trained on this dataset will therefore be biased and perform poorly on an ecologically valid sample of tokens.", "startOffset": 3, "endOffset": 20}, {"referenceID": 30, "context": "preposition supersenses (Schneider et al., 2015)", "startOffset": 24, "endOffset": 48}, {"referenceID": 20, "context": "for nouns and one for verbs\u2014which originated as a high-level partitioning of senses in WordNet (Miller et al., 1990).", "startOffset": 95, "endOffset": 116}, {"referenceID": 39, "context": "A scheme for adjectives has been proposed as well (Tsvetkov et al., 2014).", "startOffset": 50, "endOffset": 73}, {"referenceID": 5, "context": "cannot learn them (Ciaramita and Altun, 2006).", "startOffset": 18, "endOffset": 45}, {"referenceID": 27, "context": "and applied to unlimited vocabulary without having to refer to dictionary definitions (Schneider et al., 2012).", "startOffset": 86, "endOffset": 110}, {"referenceID": 31, "context": "have been built for several languages (Segond et al., 1997; Johannsen et al., 2014; Picca et al., 2008; Mart\u00ednez Alonso et al., 2015; Schneider et al., 2013, 2016).", "startOffset": 38, "endOffset": 163}, {"referenceID": 12, "context": "have been built for several languages (Segond et al., 1997; Johannsen et al., 2014; Picca et al., 2008; Mart\u00ednez Alonso et al., 2015; Schneider et al., 2013, 2016).", "startOffset": 38, "endOffset": 163}, {"referenceID": 23, "context": "have been built for several languages (Segond et al., 1997; Johannsen et al., 2014; Picca et al., 2008; Mart\u00ednez Alonso et al., 2015; Schneider et al., 2013, 2016).", "startOffset": 38, "endOffset": 163}, {"referenceID": 25, "context": "Of the four supersense schemes mentioned above, Schneider et al.\u2019s (2015) inventory for prepositions (which improved upon the inventory of Srikumar and Roth (2013a)) is unique in being hierarchical.", "startOffset": 48, "endOffset": 74}, {"referenceID": 25, "context": "Of the four supersense schemes mentioned above, Schneider et al.\u2019s (2015) inventory for prepositions (which improved upon the inventory of Srikumar and Roth (2013a)) is unique in being hierarchical.", "startOffset": 48, "endOffset": 165}, {"referenceID": 2, "context": "The structure of the hierarchy was modeled after VerbNet\u2019s hierarchy of thematic roles (Bonial et al., 2011; Hwang, 2014).", "startOffset": 87, "endOffset": 121}, {"referenceID": 11, "context": "The structure of the hierarchy was modeled after VerbNet\u2019s hierarchy of thematic roles (Bonial et al., 2011; Hwang, 2014).", "startOffset": 87, "endOffset": 121}, {"referenceID": 1, "context": "section of the English Web Treebank (Bies et al., 2012), selected because it had previously been annotated for multiword expressions and noun and verb supersenses (Schneider et al.", "startOffset": 36, "endOffset": 55}, {"referenceID": 28, "context": ", 2012), selected because it had previously been annotated for multiword expressions and noun and verb supersenses (Schneider et al., 2014; Schneider and Smith, 2015).", "startOffset": 115, "endOffset": 166}, {"referenceID": 29, "context": ", 2012), selected because it had previously been annotated for multiword expressions and noun and verb supersenses (Schneider et al., 2014; Schneider and Smith, 2015).", "startOffset": 115, "endOffset": 166}, {"referenceID": 24, "context": "Taking inspiration from Pullum and Huddleston (2002), PrepWiki further assigns supersenses to spatiotemporal particle uses of out,", "startOffset": 24, "endOffset": 53}, {"referenceID": 25, "context": "Though Schneider et al. (2015) conducted pilot annotation in constructing the supersense inventory, our annotators found a few details of the scheme to be confusing.", "startOffset": 7, "endOffset": 31}], "year": 2016, "abstractText": "We present the first corpus annotated with preposition supersenses, unlexicalized categories for semantic functions that can be marked by English prepositions (Schneider et al., 2015). That scheme improves upon its predecessors to better facilitate comprehensive manual annotation. Moreover, unlike the previous schemes, the preposition supersenses are organized hierarchically. Our data will be publicly released on the web upon publication.", "creator": "LaTeX with hyperref package"}}}