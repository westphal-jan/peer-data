{"id": "1605.03269", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-May-2016", "title": "A Hierarchical Emotion Regulated Sensorimotor Model: Case Studies", "abstract": "Inspired by the hierarchical cognitive architecture and the Perception Action Model (PAM), we suggest that internal status acts as a kind of common coding representation that influences, mediates, and even regulates sensorimotor behaviors, which can be represented within the Bayean framework, which is why cognitive actors are able to generate behaviors with subtle differences depending on emotion, or recognize emotion by perception. A novel relapsing neural network called the Recurrent Neural Network with Parametric Bias Units (RNNPB) runs in three modes and constructs a two-level emotion-regulated learning model to support this theory in two different cases.", "histories": [["v1", "Wed, 11 May 2016 03:22:13 GMT  (1553kb)", "http://arxiv.org/abs/1605.03269v1", "Accepted at The 5th International Conference on Data-Driven Control and Learning Systems. 2016"]], "COMMENTS": "Accepted at The 5th International Conference on Data-Driven Control and Learning Systems. 2016", "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["junpei zhong", "rony novianto", "mingjun dai", "xinzheng zhang", "angelo cangelosi"], "accepted": false, "id": "1605.03269"}, "pdf": {"name": "1605.03269.pdf", "metadata": {"source": "CRF", "title": "A Hierarchical Emotion Regulated Sensorimotor Model: Case Studies", "authors": ["Junpei Zhong", "Rony Novianto", "Mingjun Dai", "Xinzheng Zhang", "Angelo Cangelosi"], "emails": ["a.cangelosi}@plymouth.ac.uk", "rony@ronynovianto.com", "mjdai@szu.edu.cn", "ee.xz.zhang@gmail.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 5.\n03 26\n9v 1\n[ cs\n.R O\n] 1\nKey Words: Embodied Emotion Modelling, Cognitive Architecture, Recurrent Neural Networks, Non-verbal Emotion Expression, Social Robotics"}, {"heading": "1 Introduction", "text": "It is widely agreed that the internal state interacts with, modulates and mediates various cognitive processes including sensorimotor process, in the sense that the sensorimotor expression, for instance, the physical expression as motor primitives, are partially caused by, or co-occur with, emotions. For instance, [1, 3, 5, 7] found that body languages have been found to constitute a signal of affective information. certain subtle general motor behaviours of the human body can be thought of as expressing emotional states. For instance, the tilt angle of head can be linked inferiority- and superiorityrelated emotions [12]. Since such behaviour can be accounted for part of the cortical neural responses from neurotransmitter dopamine modulation (such as arousal), these bodily states tend to be relatively slow to arise and slow to dissipate. This facilitates people to differentiate emotions from observing these subtle behaviours.\nJZ and AC were supported by the EU project POETICON++ under grant agreement 288382 and UK EPSRC project BABEL. MD was supported by NSF of China (61301182), NSF of Guangdong (S2013040016857), Specialized Research Fund for the Doctoral Program of Higher Education from the Ministry of Education (20134408120004), Yumiao Engineering from Education Department of Guangdong (2013LYM 0077), Foundation of Shenzhen City (KQCX20140509172609163), and from NSF of Shenzhen University (00002501, 00036107). JZ would like to acknowledge the data-set and inspirations from L. Can\u0303amero and M. Lewis from University of Hertfordshire.\nConversely, similar as we do in our daily social communication, people are able to recognize others\u2019 emotions by their either static postures [23] or dynamic motions [22]. Studies suggested that there exist a hierarchical coding system [2, 7, 6] or \u2018critical features\u2019 [17] for emotion recognition. From a technical perspective, to obtain a learning model about the relation between sensorimotor behaviours and emotions are also useful to endow an artificial agent (e.g. social robotic platform) 1) to obtain a natural non-verbal emotion expression, and 2) to recognize its counterpart\u2019s emotion. Thus, extended by the hierarchical sensorimotor architecture [25], we propose an emotion regulation model based on the perception-action model(PAM) theory [15]. A twolevel neural learning model will be used to realize such an architecture. This neural model will show its feasibility in two different cases about motor action generation and personalized emotion recognition."}, {"heading": "2 A Bayeisan Emotion Regulated PerceptionAction Model", "text": "The framework of PAM is based on the common coding theory which advocates that action and perception are intertwined by sharing the same representational basis [16]. We asserted that this common representation between the perception and action is simply formed by either the mapping\nfrom perception or the perceptual events that actions produce. Specifically, the representation does not explicitly represent actions; instead, there is an encoding of the possible future percept which is learnt from prior sensorimotor knowledge. Therefore, this perception-action framework is derived from the ideomotor principle [9], which advocates that actions are represented with prediction of their perceptual consequences, i.e. it encodes the forthcoming perception that is going to happen when an action is executed (i.e. motor imagery) [4]. Due to the modulation role of emotion state, we propose that there is an intermediate level of internal state between the cognitive processes and the perception-action cycle. As we stated, this level of internal state, such as emotion, regulates the expressions of sensorimotor behaviours. To some extents, we can also regard this level of internal state as a level of common coding. As such, the representation of the internal state reflects the perception input and the motor imagination, forming an imagination of affective understanding such as empathy. Instead of the linkage between action and perception (e.g. sensorimotor contingency), the common coding theory proposes that perception and action may modulate each other directly via the shared coding by a similarity-based matching of common codes, even regulated by the internal state in our model. Therefore, the pairing of perception and action, i.e. the acquisition of \u2018common coding\u2019, emerges from prior experience of the agent. For instance, assume we have the hierarchical PAM model as a two-level architecture, it is degenerated as the model stated in [14]. If the agent (called \u2018observer\u2019) observes that one person (called \u2018presenter\u2019) is hurt by a knife, the model may trigger involuntary and subtle movement when the agent is doing a certain kind of hand movement (e.g. moving a bit of the arm). Even the observer feels sympathy about the incident. In this example, both of the current afferent information (referring to the perceived event) and predictive efferent information (referring to intended events from actions) have the same format and structure of the internal state representation. From the aforementioned sensorimotor functions, we propose a hierarchical cognitive architecture as shown in Fig. 1 focusing on the emotion regulated functions to the sensorimotor behaviours. From the common coding framework of perception and action, the information of the feedback pathways are formed through various levels, regulated by internal states of the cognitive agent in the hierarchical architecture. Between the cognitive processes and the hierarchical motor controls, internal state (such as emotion) regulates perception-action cycle functions such as perception, motor imagery, and action planning. To establish the links between movements (a), the sensory effects (e) and the internal state (s), one may need one or more processes of latent learning [21], reinforcement learning [24] or evolutionarily hard-wired acquisition [10]. This link, once establish, can be described in the following operations:\n\u2022 First, these associations allow to estimate the internal\nstate, given the perceived behaviours performed by the others by means of the forward models (e.g. Bayesian Model) (e \u2192 s). In the formulation of Bayesian inference, it can be written as Eq. 1:\nP (S|A,E) \u221d P (S)P (A|S) (1)\nwhere S estimates the internal state evidence given an executed action A (e.g. motor imagination by the observer itself), the perception E. The term P (A|S) suggests a pre-learnt internal model representing the possibility of a motor action A will be executed given a certain internal state (S). Since this model is solely by the observer itself, it may differ from various cultures, ages, personalities. Therefore, learning of such an internal model is crucial. Here another assumption is held that one\u2019s own action (or imagined action) A is the same as its perceived action (E).\n\u2022 Second, these associations allow the agent to move with a certain voluntary or involuntary behaviour given an internal state. From the backward computations introduced in Eq. 2 (s \u2192 a), a predictive/generative sensorimotor integration occurs:\nP (A|S) \u221d P (A)P (S|E) + P (A)P (S|\u00b7) (2)\nwhere A indicates a motor action given the internal state S. In the equation we omit the factor of goal, but it is also the main target of any voluntary actions. Here we assume that one\u2019s internal state is determined by the current sensory input and a lot more factors (P (S|\u00b7)).\n\u2022 In terms of its hierarchical organization, it also allows this operation: with bidirectional information pathways, a low level perception representation can be expressed on a higher level, with a more complex receptive field, and vice versa (elow \u2194 ehigh). These operations can be achieved by extracting statistical regularity, which may be expressed as deep learning architectures.\nThus, this Bayesian framework proposes that an internal state as one of the prior for feedback pathways represents a linkage between perception and motor actions. We will propose a simple learning model addressing the first two operations at the next section. After that we will demonstrate two case studies about its feasibility."}, {"heading": "3 A Learning Model", "text": ""}, {"heading": "3.1 Parametric Bias", "text": "Recurrent Neural Network with Parametric Bias Units [19, 20, 28, 27, 26] (Fig. 2) is a family of recurrent neural networks that consist of an additional bias unit acting as bifurcation parameters for the nonlinear dynamics. In other words, the adjustable values in such a small number of units can determine different dynamics in the network with large dimension. Being different from ordinary biases, these units are\ntrained from the training sequences with back-propagation through time (BPTT) in a self-organizing way, so the units exhibit the differences of the features of the training sequences. Furthermore, as bifurcation parameters for nonlinear functions, the parametric bias units (PB units) endow the network to acquire the ability of learning different nonlinear dynamic attractors, which makes it advantageous over generic recurrent networks.\nDue to the above features, an RNNPB network can be regarded as a two-layer hierarchical structure for cognitive systems. Based on this feature, this network has also been further adopted to mimic the cognitive processes such as language acquisition [27], language generalisation [18] and other cognitive processes."}, {"heading": "3.2 Three Modes", "text": "The RNNPB three running modes in an RNNPB network, namely learning, recognition and generation modes. They functionally simulate different stages between sensorimotor sequences and high-level internal states of these sequences. The neural dynamics and algorithms of these modes are as following:\n\u2022 Learning mode (Fig. 3a): The learning algorithm performs in an off-line and supervised way as generic recurrent neural networks do. When providing the training stimulus with a new pattern, the weights connecting neurons are updated with BPTT (back-propagation through time). Besides, the residual error from the BPTT updates the internal values in PB units; the internal values of the PB units are updated in a self-organising way by this error derived from the back-propagation. To achieve the slowness update of the internal value, in each epoch e, the kth PB unit u updates its internal value based on the summation of the back-propagated error from one complete sequence.\n\u2022 Recognition mode (Fig. 3b): In this mode, the network recognises which type of sequences by updating the internal values of PB units. The information flow in this mode is mostly the same as in the learning mode, i.e. the error is back-propagated from output neurons to the hidden neurons, but the synaptic weights are not updated; rather, the back-propagated error only contributes to the updating of the PB units. By this mean, if a trained sequence is presented to the network, the values of the PB units will converge to the ones that were previously shown in the learning mode in order to restore the PB values trained before.\n\u2022 Prediction mode (Fig. 3c): After learning and after the synaptic weights are determined, the RNNPB can act in a closed-loop way: the output prediction can be used as an input for the next time step. In principle, the network can generate a trained sequence by providing initial value of the input and externally setting the PB values."}, {"heading": "3.2.1 Learning Mode", "text": "During learning mode, if the training progress is basically determined by this cost function C; following gradient descent, each weight update in the network is proportional to the negative gradient of the cost with respect to the specific weight w that will be updated:\n\u2206wij = \u2212\u03b7ij \u2202C\n\u2202wij (3)\nwhere \u03b7ij is the adaptive learning rate of the weights between neuron i and j, which is adjusted in every epoch. To determine whether the learning rate has to be increased or de-\ncreased, we compute the changes of the weight wi,j in consecutive epochs:\n\u03c3i,j = \u2202C\n\u2202wi,j (e\u2212 1)\n\u2202C\n\u2202wi,j (e) (4)\nThe update of the learning rate is\n\u03b7i,j(e) =\n\n\n\nmin(\u03b7i,j(e \u2212 1) \u00b7 \u03be +, \u03b7max) if \u03c3i,j > 0, max(\u03b7i,j(e \u2212 1) \u00b7 \u03be \u2212, \u03b7min) if \u03c3i,j < 0,\n\u03b7i,j(e\u2212 1) else. (5)\nwhere \u03be+ > 1 and \u03be\u2212 < 1 represent the increasing/decreasing rate of the adaptive learning rates, with \u03b7min and \u03b7max as lower and upper bounds, respectively. Thus, the learning rate of a particular weight increases by \u03be+ to speed up the learning when the changes of that weight from two consecutive epochs have the same sign, and vice versa. As mentioned before, besides the usual weight update according to back-propagation through time, the accumulated error over the whole time-series also contributes to the update of the PB units. The update for the i-th unit in the PB vector for a time-series of length T is defined as:\n\u03c1i(e+ 1) = \u03c1i(e) + \u03b3i\nT \u2211\nt=1\n\u03b4PBi,j (6)\nwhere \u03b4PB is the error back-propagated to the PB units, e is e-th time-step in the whole time-series (e.g. epoch), \u03b3i is PB units\u2019 adaptive updating rate which is proportional to the absolute mean value of the back-propagation error at the i-th PB node over the complete time-series of length T :\n\u03b3i \u221d 1\nT\nT \u2211\nt=1\n\u03b4PBi,j (7)\nThe reason for applying the adaptive technique is that it is hard for the PB units to converge in a stable way. Usually a smaller learning rate is used in the generic version of RNNPB to ensure the convergence of the network. This results in a trade-off in convergence speed. However, the adaptive learning rate we used is an efficient technique to overcome this trade-off."}, {"heading": "3.2.2 Recognition Mode", "text": "The recognition mode is executed with a similar information flow as the learning mode: given a set of spatio-temporal sequences, the error between the target and the real output is back-propagated through the network to the PB units. However, the synaptic weights remain constant and only the PB units will be updated, so that the PB units are self-organized as the pre-trained values after certain epochs. Assuming the length of the observed sequence is a, the update rule is defined as:\n\u03c1i(e + 1) = \u03c1i(e) + \u03b3\nT \u2211\nt=T\u2212a\n\u03b4PBi,j (8)\nwhere \u03b4PB is the error back-propagated from a certain sensory information sequence to the PB units and \u03b3 is the updating rate of PB units in recognition mode, which should be larger than the adaptive rate \u03b3i at the learning mode."}, {"heading": "3.2.3 Generation Mode", "text": "The values of the PB units can also be manually set or obtained from recognition, so that the network can generate the upcoming sequence with one-step prediction. Furthermore, according to [8], a trained RNNPB not only can retrieve and recognise different types of pre-learnt, non-linear oscillation dynamics, as an expansion of the storage capability of working-memory within the sensory system, but also adds the generalisation ability to recognise and generate untrained non-linear dynamics and compositions."}, {"heading": "4 Case Studies", "text": ""}, {"heading": "4.1 Case 1: Generation of Non-verbal Emotion Expression by Avatar Simulation", "text": "In this demonstration, we used a simulation based on RNNPB with the parameters shown in Tab. 1 to generate specialised non-verbal robot behaviours. We separated two kinds of training data based on two different behaviours in order to eliminate the subtle differences in different behaviours generation, corresponding we omit the goal G in Eq. 2.\nThe training data was taken from an inertial motion capture system by Xsens, while the actor was performing two sets of basic behaviours (standing and walking) expressing five kinds of emotions (joy, sadness, fear, anger, pride). This three-dimensional skeleton motion capture was used instead camera-based systems such as Microsoft Kinect, because it would be easier to map the generated motion into humanoid robots for further project developments. Also motions from various body parts could be well-isolated in a quantitative way for network training. Such quantitative data can be reviewed and utilised in external editors and programs (Fig. 4). The sampling frequency of this system was 120Hz.\nAfter training, as depicted in Eq. 2, given that the PB values we obtained from training, we can generate the pre-trained or un-trained temporal sequences in the network\u2019s generation mode. These behaviours were represented in a 78- dimensional data-set by reconstructing the network output. These simulations were done by adjusting the PB units into the pre-trained values and the novel values as the midpoints between either two pre-trained values in the PB space. In the avatar demonstrations, only the body skeleton were shown by means of the lines connecting to skeleton points. Part of the demonstrations can be viewed online. Apart from the trained emotions, some \u2018interval\u2019 emotions from the behaviours can be also perceived when the novel points in the PB spaces were selected."}, {"heading": "4.2 Case 2: Personalised Emotion Recognition", "text": "In the second demonstration, the recognition mode of the network was investigated (Eq. 1) using the parameters shown in Tab. 1. Here we will also testify the real-time recognition ability of this method. Training was done by capturing the Kinect tracking data by OpenNI from one person. We only selected the upper body of the data (9-dimension: head, neck, torso, left shoulder, left elbow, left hand, right shoulder, right elbow, right hand), since the emotion is more significant in the upper body. After training, the Kinect captured the data again to test whether the networks can distinguish the emotion correctly. The real-time demonstration video showed\nwww.xsens.com/en/general/mvn http://youtu.be/9yahOKcEi-A http://youtu.be/JusCuKvHg44\nthat the PB value has a bit delay depending on the choice the updating rate. However, such a delay can be used as a confidence level to simulate the decision processes for the robot. To quantitatively evaluate the performance of the learning, we also compare the differences between the original PB value and the recognised PB value. During recognition, a stopping criterion is set if the updating of PB values was smaller than a threshold 0.1 in consecutive 100 times. Tab. 2 listed the distance of PB values under the training and recognition modes. Although during the experiments we could not guarantee the training and recognition data-sets were identical, we can still observe that behaviours from the same emotion drove the PB values closer to each other. Furthermore, we can also notice the behaviours from \u2018joy\u2019 and \u2018pride\u2019, \u2018fear\u2019 and \u2018anger\u2019 were also quite close which may indicate some connections between these two pairs of emotions."}, {"heading": "5 Summary", "text": "In this paper, we proposed a cognitive framework focusing on the regulation role of emotions to sensorimotor behaviours. This hierarchical architecture is based on the perceptionaction model, in which the internal state (emotion) acts as a prior in the feedback pathways to further modulate perception and actions. Following the proposed two Bayesian inferences between internal state and the sensorimotor behaviours, we propose to use a recurrent neural network with parametric bias units (RNNPB) to contruct a two-layer architecture in which the parametric bias represents an internal state. The non-verbal expression generation and emotion recognition demonstrations witness the feasibility of this hierarchical architecture. In the next steps, a few possibilities can be made to further extend this architecture: 1) more factors, such as goal, perception from previous states and prior knowledge, can be considered in the Bayesian inferences; 2) a more sophisticated hierarchical learning method can be used to extract and generate more statistical regularities; 3) we will further extend this hierarchical PAM model with ASMO architecture[13] to allow a flexible attention between various conditions as well as modulated by internal status such as emotion."}], "references": [{"title": "Bodily communication", "author": ["M. Argyle"], "venue": "Routledge,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "The body action and posture coding system (BAP): Development and reliability", "author": ["N. Dael", "M. Mortillaro", "K.R. Scherer"], "venue": "Journal of Nonverbal Behavior, 36(2):97\u2013121,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "The expression of the emotions in man and animals", "author": ["C. Darwin"], "venue": "Oxford Uni. Press,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1998}, {"title": "Sensory feedback mechanisms in performance control: with special reference to the ideomotor mechanism", "author": ["A.G. Greenwald"], "venue": "Psychol. Rev., 77(2):73,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1970}, {"title": "Seeing fearful body expressions activates the fusiform cortex and amygdala", "author": ["N. Hadjikhani", "B. de Gelder"], "venue": "Curr. Biol.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "The body action coding system ii: muscle activations during the perception and expression of emotion", "author": ["E.M. Huis"], "venue": "Frontiers in behavioral neuroscience,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "The body action coding system i: Muscle activations during the perception and expression of emotion", "author": ["E.M. Huis in t Veld", "G.J. Van Boxtel", "B. de Gelder"], "venue": "Social neuroscience,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Generalization in learning multiple temporal patterns using rnnpb", "author": ["M. Ito", "J. Tani"], "venue": "Neural Information Processing, pages 592\u2013598. Springer,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "The consciousness of self", "author": ["W. James"], "venue": "The Principles of Psychology, 8,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1890}, {"title": "The amygdala", "author": ["J. LeDoux"], "venue": "Current Biology, 17(20):R868\u2013R874,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Are discrete emotions useful in human-robot interaction? feedback from motion capture analysis", "author": ["M. Lewis", "L. Ca\u00f1amero"], "venue": "2013 Humaine Association Conference on Affective Computing and Intelligent Interaction (ACII), pages 97\u2013102. IEEE,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "The many faces of a neutral face: Head tilt and perception of dominance and emotion", "author": ["A. Mignault", "A. Chaudhuri"], "venue": "J. of Nonverbal Behavior, 27(2):111\u2013132,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Flexible attention-based cognitive architecture for robots", "author": ["R. Novianto"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "A perception-action model for empathy", "author": ["S.D. Preston"], "venue": "Empathy in mental illness, pages 428\u2013447,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Empathy: Its ultimate and proximate bases", "author": ["S.D. Preston", "F. De Waal"], "venue": "Behavioral and brain sciences, 25(01):1\u201320,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "Perception and action planning", "author": ["W. Prinz"], "venue": "European Journal of Cognitive Psychology, 9(2):129\u2013154,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1997}, {"title": "Critical features for the perception of emotion from gait", "author": ["C.L. Roether", "L. Omlor", "A. Christensen", "M.A. Giese"], "venue": "J. of Vision, 9(6):15,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning semantic combinatoriality from the interaction between linguistic and behavioral processes", "author": ["Y. Sugita", "J. Tani"], "venue": "Adaptive Behavior, 13(1):33,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Self-organization of behavioral primitives as multiple attractor dynamics: A robot experiment", "author": ["J. Tani", "M. Ito"], "venue": "IEEE Transactions on Systems, Man and Cybernetics, Part A: Systems and Humans, 33(4):481\u2013488,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2003}, {"title": "Self-organization of distributedly represented multiple behavior schemata in a mirror system: reviews of robot experiments using RN- NPB", "author": ["J. Tani", "M. Ito", "Y. Sugita"], "venue": "Neural Networks, 17(8-9):1273\u20131289,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}, {"title": "A critical review of latent learning and related experiments", "author": ["D. Thistlethwaite"], "venue": "Psychological Bulletin, 48(2):97,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1951}, {"title": "Emotion and dance in dynamic light displays", "author": ["R.D. Walk", "C.P. Homan"], "venue": "Bulletin of the Psychonomic Society, 22(5):437\u2013440,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1984}, {"title": "Perception of emotion from body posture", "author": ["K.L. Walters", "R.D. Walk"], "venue": "24(5):329\u2013329,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1986}, {"title": "Reinforcement learning and animat emotions", "author": ["I. Wright"], "venue": "From Animals to Animats IV, Proceedings of the Fourth International Conference on the Simulation of Adaptive Behavior, pages 272\u2013281,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1996}, {"title": "Artificial neural models for feedback pathways for sensorimotor integration", "author": ["J. Zhong"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}, {"title": "From continuous affective space to continuous expression space: Non-verbal behaviour recognition and generation", "author": ["J. Zhong", "L. Canamero"], "venue": "Development and Learning and Epigenetic Robotics (ICDL-Epirob), 2014 Joint IEEE International Conferences on, pages 75\u201380. IEEE,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Towards a self-organizing pre-symbolic neural model representing sensorimotor primitives", "author": ["J. Zhong", "A. Cangelosi", "S. Wermter"], "venue": "Frontiers in Behavioral Neuroscience, 8:22,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Robot trajectory prediction and recognition based on a computational mirror neurons model", "author": ["J. Zhong", "C. Weber", "S. Wermter"], "venue": "Artificial Neural Networks and Machine Learning\u2013ICANN 2011, pages 333\u2013340. Springer,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 14, "context": "Abstract: Inspired by the hierarchical cognitive architecture and the perception-action model (PAM) [15], we propose that the internal status acts as a kind of common-coding representation which affects, mediates and even regulates the sensorimotor behaviours.", "startOffset": 100, "endOffset": 104}, {"referenceID": 0, "context": "For instance, [1, 3, 5, 7] found that body languages have been found to constitute a signal of affective information.", "startOffset": 14, "endOffset": 26}, {"referenceID": 2, "context": "For instance, [1, 3, 5, 7] found that body languages have been found to constitute a signal of affective information.", "startOffset": 14, "endOffset": 26}, {"referenceID": 4, "context": "For instance, [1, 3, 5, 7] found that body languages have been found to constitute a signal of affective information.", "startOffset": 14, "endOffset": 26}, {"referenceID": 6, "context": "For instance, [1, 3, 5, 7] found that body languages have been found to constitute a signal of affective information.", "startOffset": 14, "endOffset": 26}, {"referenceID": 11, "context": "For instance, the tilt angle of head can be linked inferiority- and superiorityrelated emotions [12].", "startOffset": 96, "endOffset": 100}, {"referenceID": 22, "context": "Conversely, similar as we do in our daily social communication, people are able to recognize others\u2019 emotions by their either static postures [23] or dynamic motions [22].", "startOffset": 142, "endOffset": 146}, {"referenceID": 21, "context": "Conversely, similar as we do in our daily social communication, people are able to recognize others\u2019 emotions by their either static postures [23] or dynamic motions [22].", "startOffset": 166, "endOffset": 170}, {"referenceID": 1, "context": "Studies suggested that there exist a hierarchical coding system [2, 7, 6] or \u2018critical features\u2019 [17] for emotion recognition.", "startOffset": 64, "endOffset": 73}, {"referenceID": 6, "context": "Studies suggested that there exist a hierarchical coding system [2, 7, 6] or \u2018critical features\u2019 [17] for emotion recognition.", "startOffset": 64, "endOffset": 73}, {"referenceID": 5, "context": "Studies suggested that there exist a hierarchical coding system [2, 7, 6] or \u2018critical features\u2019 [17] for emotion recognition.", "startOffset": 64, "endOffset": 73}, {"referenceID": 16, "context": "Studies suggested that there exist a hierarchical coding system [2, 7, 6] or \u2018critical features\u2019 [17] for emotion recognition.", "startOffset": 97, "endOffset": 101}, {"referenceID": 24, "context": "Thus, extended by the hierarchical sensorimotor architecture [25], we propose an emotion regulation model based on the perception-action model(PAM) theory [15].", "startOffset": 61, "endOffset": 65}, {"referenceID": 14, "context": "Thus, extended by the hierarchical sensorimotor architecture [25], we propose an emotion regulation model based on the perception-action model(PAM) theory [15].", "startOffset": 155, "endOffset": 159}, {"referenceID": 15, "context": "The framework of PAM is based on the common coding theory which advocates that action and perception are intertwined by sharing the same representational basis [16].", "startOffset": 160, "endOffset": 164}, {"referenceID": 8, "context": "Therefore, this perception-action framework is derived from the ideomotor principle [9], which advocates that actions are represented with prediction of their perceptual consequences, i.", "startOffset": 84, "endOffset": 87}, {"referenceID": 3, "context": "motor imagery) [4].", "startOffset": 15, "endOffset": 18}, {"referenceID": 13, "context": "For instance, assume we have the hierarchical PAM model as a two-level architecture, it is degenerated as the model stated in [14].", "startOffset": 126, "endOffset": 130}, {"referenceID": 20, "context": "To establish the links between movements (a), the sensory effects (e) and the internal state (s), one may need one or more processes of latent learning [21], reinforcement learning [24] or evolutionarily hard-wired acquisition [10].", "startOffset": 152, "endOffset": 156}, {"referenceID": 23, "context": "To establish the links between movements (a), the sensory effects (e) and the internal state (s), one may need one or more processes of latent learning [21], reinforcement learning [24] or evolutionarily hard-wired acquisition [10].", "startOffset": 181, "endOffset": 185}, {"referenceID": 9, "context": "To establish the links between movements (a), the sensory effects (e) and the internal state (s), one may need one or more processes of latent learning [21], reinforcement learning [24] or evolutionarily hard-wired acquisition [10].", "startOffset": 227, "endOffset": 231}, {"referenceID": 18, "context": "Recurrent Neural Network with Parametric Bias Units [19, 20, 28, 27, 26] (Fig.", "startOffset": 52, "endOffset": 72}, {"referenceID": 19, "context": "Recurrent Neural Network with Parametric Bias Units [19, 20, 28, 27, 26] (Fig.", "startOffset": 52, "endOffset": 72}, {"referenceID": 27, "context": "Recurrent Neural Network with Parametric Bias Units [19, 20, 28, 27, 26] (Fig.", "startOffset": 52, "endOffset": 72}, {"referenceID": 26, "context": "Recurrent Neural Network with Parametric Bias Units [19, 20, 28, 27, 26] (Fig.", "startOffset": 52, "endOffset": 72}, {"referenceID": 25, "context": "Recurrent Neural Network with Parametric Bias Units [19, 20, 28, 27, 26] (Fig.", "startOffset": 52, "endOffset": 72}, {"referenceID": 26, "context": "Based on this feature, this network has also been further adopted to mimic the cognitive processes such as language acquisition [27], language generalisation [18] and other cognitive processes.", "startOffset": 128, "endOffset": 132}, {"referenceID": 17, "context": "Based on this feature, this network has also been further adopted to mimic the cognitive processes such as language acquisition [27], language generalisation [18] and other cognitive processes.", "startOffset": 158, "endOffset": 162}, {"referenceID": 7, "context": "Furthermore, according to [8], a trained RNNPB not only can retrieve and recognise different types of pre-learnt, non-linear oscillation dynamics, as an expansion of the storage capability of working-memory within the sensory system, but also adds the generalisation ability to recognise and generate untrained non-linear dynamics and compositions.", "startOffset": 26, "endOffset": 29}, {"referenceID": 12, "context": "In the next steps, a few possibilities can be made to further extend this architecture: 1) more factors, such as goal, perception from previous states and prior knowledge, can be considered in the Bayesian inferences; 2) a more sophisticated hierarchical learning method can be used to extract and generate more statistical regularities; 3) we will further extend this hierarchical PAM model with ASMO architecture[13] to allow a flexible attention between various conditions as well as modulated by internal status such as emotion.", "startOffset": 414, "endOffset": 418}], "year": 2016, "abstractText": "Inspired by the hierarchical cognitive architecture and the perception-action model (PAM) [15], we propose that the internal status acts as a kind of common-coding representation which affects, mediates and even regulates the sensorimotor behaviours. These regulation can be depicted in the Bayesian framework, that is why cognitive agents are able to generate behaviours with subtle differences according to their emotion or recognize the emotion by perception. A novel recurrent neural network called recurrent neural network with parametric bias units (RNNPB) runs in three modes, constructing a two-level emotion regulated learning model, was further applied to testify this theory in two different cases.", "creator": "LaTeX with hyperref package"}}}