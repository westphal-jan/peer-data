{"id": "1605.07747", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-May-2016", "title": "NESTT: A Nonconvex Primal-Dual Splitting Method for Distributed and Stochastic Optimization", "abstract": "We are investigating a stochastic and distributed algorithm for non-convex problems, the goal of which is a sum of $N $non-convex $L _ i / N $smooth functions plus a non-smooth regularizer. The proposed NonconvenEx primary-dual spliTTing (NESTT) algorithm splits the problem into $N $subproblems and uses an advanced lagrangian primary-dual scheme to solve it in a distributed and stochastic manner. By means of a special uneven sampling, a version of NESTT $\\ epsilon $stationary solution achieves $\\ mathcal {O} ((((\\ sum _ sum _ {i = 1} ^ N\\ sqrt {L _ i / N}) ^ 2 /\\ epsilon) $gradient ratings that can be up to $epsilon $fixed solutions that are up to $\\ mathcal {O} (N) times better than the descending (N) -diximal ones.", "histories": [["v1", "Wed, 25 May 2016 06:42:51 GMT  (66kb,D)", "https://arxiv.org/abs/1605.07747v1", "35 pages, 2 figures"], ["v2", "Mon, 7 Nov 2016 23:06:57 GMT  (70kb,D)", "http://arxiv.org/abs/1605.07747v2", "35 pages, 2 figures"]], "COMMENTS": "35 pages, 2 figures", "reviews": [], "SUBJECTS": "math.OC cs.LG stat.ML", "authors": ["davood hajinezhad", "mingyi hong", "tuo zhao", "zhaoran wang"], "accepted": true, "id": "1605.07747"}, "pdf": {"name": "1605.07747.pdf", "metadata": {"source": "CRF", "title": "NESTT: A Nonconvex Primal-Dual Splitting Method for Distributed and Stochastic Optimization", "authors": ["Davood Hajinezhad", "Mingyi Hong", "Tuo Zhao", "Zhaoran Wang"], "emails": ["dhaji@iastate.edu", "mingyi@iastate.edu", "tzhao5@jhu.edu", "zhaoran@princeton.edu"], "sections": [{"heading": null, "text": "\u2211N i=1 \u221a Li/N)\n2/ ) gradient evaluations, which can be up to O(N) times better than the (proximal) gradient descent methods. It also achieves Q-linear convergence rate for nonconvex `1 penalized quadratic problems with polyhedral constraints. Further, we reveal a fundamental connection between primal-dual based methods and a few primal only methods such as IAG/SAG/SAGA.\n1 Introduction\nConsider the following nonconvex and nonsmooth constrained optimization problem\nmin z\u2208Z\nf(z) := 1\nN N\u2211 i=1 gi(z) + g0(z) + p(z), (1)\nwhere Z \u2286 Rd; for each i \u2208 {0, \u00b7 \u00b7 \u00b7 , N}, gi : Rd \u2192 R is a smooth possibly nonconvex function which has Li-Lipschitz continuous gradient; p(z) : Rd \u2192 R is a lower semi-continuous convex but possibly nonsmooth function. Define g(z) := 1N \u2211N i=1 gi(z) for notational simplicity.\nProblem (1) is quite general. It arises frequently in applications such as machine learning and signal processing; see a recent survey [8]. In particular, each smooth functions {gi}Ni=1 can represent: 1) a minibatch of loss functions modeling data fidelity, such as the `2 loss, the logistic loss, etc; 2) nonconvex activation functions for neural networks, such as the logit or the tanh functions; 3) nonconvex utility functions used in signal processing, machine learning, and resource allocation, see [5], and [12]. The smooth function g0 can represent smooth nonconvex regularizers such as the non-quadratic penalties [2], or the smooth part of the SCAD or MCP regularizers (which is a concave function) [30]. The convex function p can take the following form: 1) nonsmooth convex regularizers such as `1 and `2 functions; 2) an indicator function for convex and closed feasible set Z, denoted as \u03b9Z(\u00b7); 3) convex functions without global Lipschitz continuous gradient, such as p(z) = z4 or p(z) = 1/z + \u03b9z\u22650(z).\n\u2217Department of Industrial & Manufacturing Systems Engineering and Department of Electrical & Computer Engineering, Iowa State University, Emails: {dhaji,mingyi}@iastate.edu \u2020Department of Computer Science, Johns Hopkins University, Email: tzhao5@jhu.edu \u2021Department of Operations Research and Financial Engineering, Princeton University, Email: zhaoran@princeton.edu\nar X\niv :1\n60 5.\n07 74\n7v 2\n[ m\nat h.\nO C\n] 7\nN ov\nIn this work we solve (1) in a stochastic and distributed manner. We consider the setting in which N distributed agents each having the knowledge of one smooth function {gi}Ni=1, and they are connected to a cluster center which handles g0 and p. At any given time, a randomly selected agent is activated and performs computation to optimize its local objective. Such distributed computation model has been popular in large-scale machine learning and signal processing [7]. Such model is also closely related to the (centralized) stochastic finite-sum optimization problem [17, 10, 15, 25, 1, 26], in which each time the iterate is updated based on the gradient information of a random component function. One of the key differences between these two problem types is that in the distributed setting there can be disagreement between local copies of the optimization variable z, while in the centralized setting only one copy of z is maintained.\nOur Contributions. We propose a class of NonconvEx primal-dual SpliTTing (NESTT) algorithms for problem (1). We split z \u2208 Rd into local copies of xi \u2208 Rd, while enforcing the equality constraints xi = z for all i. That is, we consider the following reformulation of (1)\nmin x,z\u2208Rd\n`(x, z) := 1\nN N\u2211 i=1 gi(xi) + g0(z) + h(z), s.t. xi = z, i = 1, \u00b7 \u00b7 \u00b7 , N, (2)\nwhere h(z) := \u03b9Z(z) + p(z), x := [x1; \u00b7 \u00b7 \u00b7 ;xN ]. Our algorithm uses the Lagrangian relaxation of the equality constraints, and at each iteration a (possibly non-uniformly) randomly selected primal variable is optimized, followed by an approximate dual ascent step. Note that such splitting scheme has been popular in the convex setting [7], but not so when the problem becomes nonconvex.\nThe NESTT is one of the first stochastic algorithms for distributed nonconvex nonsmooth optimization, with provable and nontrivial convergence rates. Our main contribution is given below. First, in terms of some primal and dual optimality gaps, NESTT converges sublinearly to a point belongs to stationary solution set of (2). Second, NESTT converges Q-linearly for certain nonconvex `1 penalized quadratic problems. To the best of our knowledge, this is the first time that linear convergence is established for stochastic and distributed optimization of such type of problems. Third, we show that a gradient-based NESTT with non-uniform sampling achieves an -stationary solution of (1) using O(( \u2211N i=1 \u221a Li/N)\n2/ ) gradient evaluations. Compared with the classical gradient descent, which in the worst case requires O( \u2211N\ni=1 Li/ ) gradient evaluation to achieve -stationarity [23], our obtained rate can be up to O(N) times better in the case where the Li\u2019s are not equal.\nOur work also reveals a fundamental connection between primal-dual based algorithms and the primal only average-gradient based algorithm such as SAGA/SAG/IAG [10, 25, 26, 6]. With the key observation that the dual variables in NESTT serve as the \u201cmemory\u201d of the past gradients, one can specialize NESTT to SAGA/SAG/IAG. Therefore, NESTT naturally generalizes these algorithms to the nonconvex nonsmooth setting. It is our hope that by bridging the primal-dual splitting algorithms and primal-only algorithms (in both the convex and nonconvex setting), there can be significant further research developments benefiting both algorithm classes. Related Work. Many stochastic algorithms have been designed for (2) when it is convex. In these algorithms the component functions gi\u2019s are randomly sampled and optimized. Popular algorithms include the SAG/SAGA [10, 26], the SDCA [27], the SVRG [15], the RPDG [17] and so on. When the problem becomes nonconvex, the well-known incremental based algorithm can be used [28, 3], but these methods generally lack convergence rate guarantees. The SGD based method has been studied in [11], with O(1/ 2) convergence rate. Recent works [1] and [25] develop algorithms based on SVRG and SAGA for a special case of (1) where the entire problem is smooth and unconstrained. To the best of our knowledge there\nhas been no stochastic algorithms with provable, and non-trivial, convergence rate guarantees for solving problem (1). On the other hand, distributed stochastic algorithms for solving problem (1) in the nonconvex setting has been proposed in [14], [13], in which each time a randomly picked subset of agents update their local variables. However there has been no convergence rate analysis for such distributed stochastic scheme. There has been some recent distributed algorithms designed for (1) [19], but again without global convergence rate guarantee. Preliminaries. The augmented Lagrangian function for problem (1) is given by:\nL (x, z;\u03bb) = N\u2211 i=1 ( 1 N gi(xi) + \u3008\u03bbi, xi \u2212 z\u3009+ \u03b7i 2 \u2016xi \u2212 z\u20162 ) + g0(z) + h(z), (3)\nwhere \u03bb := {\u03bbi}Ni=1 is the set of dual variables, and \u03b7 := {\u03b7i > 0}Ni=1 are penalty parameters. We make the following assumptions about problem (1) and the function (3).\nA-(a) The function f(z) is bounded from below over Z \u2229 int(dom f): f := minz\u2208Z f(z) > \u2212\u221e. p(z) is a convex lower semi-continuous function; Z is a closed convex set.\nA-(b) The gi\u2019s and g have Lipschitz continuous gradients, i.e.,\n\u2016\u2207g(y)\u2212\u2207g(z)\u2016 \u2264 L\u2016y \u2212 z\u2016, and \u2016\u2207gi(y)\u2212\u2207gi(z)\u2016 \u2264 Li\u2016y \u2212 z\u2016, \u2200 y, z\nClearly L \u2264 1/N \u2211N\ni=1 Li, and the equality can be achieved in the worst case. For simplicity of analysis we will further assume that L0 \u2264 1N \u2211N i=1 Li.\nA-(c) Each \u03b7i in (3) satisfies \u03b7i > Li/N ; if g0 is nonconvex, then \u2211N i=1 \u03b7i > 3L0.\nAssumption A-(c) implies that L (x, z;\u03bb) is strongly convex w.r.t. each xi and z, with modulus \u03b3i := \u03b7i \u2212 Li/N and \u03b3z = \u2211N i=1 \u03b7i \u2212 L0, respectively [31, Theorem 2.1].\nWe then define the prox-gradient (pGRAD) for (1), which will serve as a measure of stationarity. It can be checked that the pGRAD vanishes at the set of stationary solutions of (1) [24].\nDefinition 1.1. The proximal gradient of problem (1) is given by (for any \u03b3 > 0)\n\u2207\u0303f\u03b3(z) := \u03b3 ( z \u2212 prox\u03b3p+\u03b9Z [z \u2212 1/\u03b3\u2207(g(z) + g0(z))] ) , with prox\u03b3p+\u03b9Z [u] := argmin\nu\u2208Z p(u) +\n\u03b3 2 \u2016z \u2212 u\u20162.\n2 The NESTT-G Algorithm\nAlgorithm Description. We present a primal-dual splitting scheme for the reformulated problem (2). The algorithm is referred to as the NESTT with Gradient step (NESTT-G) since each agent only requires to know the gradient of each component function. To proceed, let us define the following function (for some constants {\u03b1i > 0}Ni=1):\nVi(xi, z;\u03bbi) = 1\nN gi(z) +\n1\nN \u3008\u2207gi(z), xi \u2212 z\u3009+ \u3008\u03bbi, xi \u2212 z\u3009+ \u03b1i\u03b7i 2 \u2016xi \u2212 z\u20162.\nNote that Vi(\u00b7) is related to L(\u00b7) in the following way: it is a quadratic approximation (approximated at the point z) of L(x, y;\u03bb) w.r.t. xi. The parameters \u03b1 := {\u03b1i}Ni=1 give some freedom to the algorithm\nAlgorithm 1 NESTT-G Algorithm\n1: for r = 1 to R do 2: Pick ir \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , N} with probability pir and update (x, \u03bb)\nxr+1ir = arg minxir Vir ( xir , z r, \u03bbrir ) ; (4) \u03bbr+1ir = \u03bb r ir + \u03b1ir\u03b7ir ( xr+1ir \u2212 z r ) ; (5) \u03bbr+1j = \u03bb r j , x r+1 j = z\nr, \u2200 j 6= ir; (6) Update z: zr+1 = arg min\nz\u2208Z L({xr+1i }, z;\u03bb r). (7)\n3: end for 4: Output: (zm, xm, \u03bbm) where m randomly picked from {1, 2, \u00b7 \u00b7 \u00b7 , R}.\ndesign, and they are critical in improving convergence rates as well as in establishing connection between NESTT-G with a few primal only stochastic optimization schemes.\nThe algorithm proceeds as follows. Before each iteration begins the cluster center broadcasts z to everyone. At iteration r + 1 a randomly selected agent ir \u2208 {1, 2, \u00b7 \u00b7 \u00b7N} is picked, who minimizes Vir(\u00b7) w.r.t. its local variable xir , followed by a dual ascent step for \u03bbir . The rest of the agents update their local variables by simply setting them to z. The cluster center then minimizes L(x, z;\u03bb) with respect to z. See Algorithm 1 for details. We remark that NESTT-G is related to the popular ADMM method for convex optimization [7]. However our particular update schedule (randomly picking (xi, \u03bbi) plus deterministic updating z), combined with the special x-step (minimizing an approximation of L(\u00b7) evaluated at a different block variable z) is not known before. These features are critical in our following rate analysis.\n2.1 Convergence Analysis.\nTo proceed, let us define r(j) as the last iteration in which the jth block is picked before iteration r + 1. i.e.r(j) := max{t | t < r+ 1, j = i(t)}. Define yrj := zr(j) if j 6= ir, and yrir = z\nr. Define the filtration Fr as the \u03c3-field generated by {i(t)}r\u22121t=1 .\nA few important observations are in order. Combining the (x, z) updates (4) \u2013 (7), we have\nxr+1q = z r \u2212 1\n\u03b1q\u03b7q (\u03bbrq +\n1\nN \u2207gq(zr)),\n1\nN \u2207gq(zr) + \u03bbrq + \u03b1q\u03b7q(xr+1q \u2212 zr) = 0, with q = ir (8a)\n\u03bbr+1ir = \u2212 1\nN \u2207gir (zr), \u03bbr+1j = \u2212\n1\nN \u2207gj(zr(j)), \u2200 j 6= ir, \u21d2 \u03bbr+1i = \u2212\n1\nN \u2207gi(yri ), \u2200 i (8b)\nxr+1j (6) = zr (8b) = zr \u2212 1\n\u03b1j\u03b7j (\u03bbrj +\n1\nN \u2207gj(zr(j))), \u2200 j 6= ir. (8c)\nThe key here is that the dual variables serve as the \u201cmemory\u201d for the past gradients of gi\u2019s. To proceed,\nwe first construct a potential function using an upper bound of L(x, y;\u03bb). Note that\n1\nN gj(x\nr+1 j ) + \u3008\u03bb r j , x r+1 j \u2212 z r\u3009+ \u03b7j 2 \u2016xr+1j \u2212 z r\u20162 = 1 N gj(z r), \u2200 j 6= ir (9)\n1\nN gir (x\nr+1 ir ) + \u3008\u03bbrir , x r+1 ir \u2212 zr\u3009+ \u03b7i\n2 \u2016xr+1ir \u2212 z r\u20162\n(i) \u2264 1 N gir (z r) + \u03b7ir + Lir/N 2 \u2016xr+1ir \u2212 z r\u20162 (ii) = 1\nN gir (z\nr) + \u03b7ir + Lir/N\n2(\u03b1ir\u03b7ir ) 2 \u20161/N(\u2207gir (yr\u22121ir )\u2212\u2207gir (z r))\u20162 (10)\nwhere (i) uses (8b) and applies the descent lemma on the function 1/Ngi(\u00b7); in (ii) we have used (5) and (8b). Since each i is picked with probability pi, we have\nEir [L(xr+1, zr;\u03bbr) | Fr]\n\u2264 N\u2211 i=1 1 N gi(z r) + N\u2211 i=1 pi(\u03b7i + Li/N) 2(\u03b1i\u03b7i)2 \u20161/N(\u2207gi(yr\u22121i )\u2212\u2207gi(z r))\u20162 + g0(zr) + h(zr)\n\u2264 N\u2211 i=1 1 N gi(z r) + N\u2211 i=1 3pi\u03b7i (\u03b1i\u03b7i)2 \u20161/N(\u2207gi(yr\u22121i )\u2212\u2207gi(z r))\u20162 + g0(zr) + h(zr) := Qr,\nwhere in the last inequality we have used Assumption [A-(c)]. In the following, we will use EFr [Qr] as the potential function, and show that it decreases at each iteration.\nLemma 2.1. Suppose Assumption A holds, and pick\n\u03b1i = pi = \u03b2\u03b7i, where \u03b2 := 1\u2211N i=1 \u03b7i , and \u03b7i \u2265 9Li Npi , i = 1, \u00b7 \u00b7 \u00b7N. (11)\nThen the following descent estimate holds true for NESTT-G E[Qr \u2212Qr\u22121|Fr\u22121] \u2264 \u2212 \u2211N\ni=1 \u03b7i 8 Ezr\u2016zr \u2212 zr\u22121\u20162 \u2212 N\u2211 i=1 1 2\u03b7i \u2016 1 N (\u2207gi(zr\u22121)\u2212\u2207gi(yr\u22122i ))\u2016 2. (12)\nSublinear Convergence. Define the optimality gap as the following: E[Gr] := E [ \u2016\u2207\u03031/\u03b2f(zr)\u20162 ] = 1 \u03b22 E [ \u2016zr \u2212 prox1/\u03b2h [z r \u2212 \u03b2\u2207(g(zr) + g0(zr))]\u20162 ] . (13)\nNote that when h, g0 \u2261 0, E[Gr] reduces to E[\u2016\u2207g(zr)\u20162]. We have the following result.\nTheorem 2.1. Suppose Assumption A holds, and pick (for i = 1, \u00b7 \u00b7 \u00b7 , N)\n\u03b1i = pi = \u221a Li/N\u2211N\ni=1\n\u221a Li/N , \u03b7i = 3 ( N\u2211 i=1 \u221a Li/N )\u221a Li/N, \u03b2 =\n1 3( \u2211N\ni=1\n\u221a Li/N)2 . (14)\nThen every limit point generated by NESTT-G is a stationary solution of problem (2). Further,\n1) E[Gm] \u2264 80 3 ( N\u2211 i=1 \u221a Li/N )2E[Q1 \u2212QR+1] R ;\n2) E[Gm] + E [ N\u2211 i=1 3\u03b72i \u2225\u2225xmi \u2212 zm\u22121\u2225\u22252 ] \u2264 80 3 ( N\u2211 i=1 \u221a Li/N )2 E[Q1 \u2212QR+1] R .\nNote that Part (1) is useful in the centralized finite-sum minimization setting, as it shows the sublinear convergence of NESTT-G, measured only by the primal optimality gap evaluated at zr. Meanwhile, part (2) is useful in the distributed setting, as it also shows that the expected constraint violation, which measures the consensus among agents, shrinks in the same order. We also comment that the above result suggests\nthat to achieve an -stationary solution, the NESTT-G requires about O ((\u2211N i=1 \u221a Li/N )2 / ) number\nof gradient evaluations (for simplicity we have ignored an additive N factor for evaluating the gradient of the entire function at the initial step of the algorithm).\nIt is interesting to observe that our choice of pi is proportional to the square root of the Lipschitz constant of each component function, rather than to Li. Because of such choice of the sampling probability, the derived convergence rate has a mild dependency on N and Li\u2019s. Compared with the conventional gradientbased methods, our scaling can be up to N times better. Detailed discussion and comparison will be given in Section 4.\nNote that similar sublinear convergence rates can be obtained for the case \u03b1i = 1 for all i (with different scaling constants). However due to space limitation, we will not present those results here.\n2.2 Linear Convergence.\nIn this section we show that the NESTT-G is capable of linear convergence for a family of nonconvex quadratic problems, which has important applications, for example in high-dimensional statistical learning [18]. To proceed, we will assume the following.\nB-(a) Each function gi(z) is a quadratic function of the form gi(z) = 1/2z TAiz + \u3008b, z\u3009, where Ai is a\nsymmetric matrix but not necessarily positive semidefinite;\nB-(b) The feasible set Z is a closed compact polyhedral set;\nB-(c) The nonsmooth function p(z) = \u00b5\u2016z\u20161, for some \u00b5 \u2265 0.\nOur linear convergence result is based upon certain error bound condition around the stationary solutions set, which has been shown in [21] for smooth quadratic problems and has been extended to including `1 penalty in [29, Theorem 4].\nLemma 2.2. Suppose Assumptions A and B hold. Let Z\u2217 denotes the set of stationary solutions of problem (1), and dist (z, Z\u2217) := minu\u2208Z\u2217 \u2016z \u2212 u\u2016. Then we have the following\n1. (Error Bound Condition) For any \u03be \u2265 minz f(z), exists a positive scalar \u03c4 such that the following error bound holds\ndist (z, Z\u2217) \u2264 \u03c4\u2016\u2207\u03031/\u03b2f(z)\u2016 (15)\nfor all z \u2208 (Z \u2229 dom h) and z \u2208 {z : f(z) \u2264 \u03be}.\n2. (Separation of Isocost Surfaces) There exists a scalar \u03b4 > 0 such that\n\u2016z \u2212 v\u2016 \u2265 \u03b4 whenever z \u2208 Z\u2217, v \u2208 Z\u2217, f(z) 6= f(v). (16)\nWe note that the first statement holds true largely due to [29, Theorem 4], and the second statement holds true due to [20, Lemma 2.1]; see detailed discussion after [29, Assumption 2]. Here the only difference\nAlgorithm 2 NESTT-E Algorithm\n1: for r = 1 to R do 2: Update z by minimizing the augmented Lagrangian:\nzr+1 = arg min z L(xr, z;\u03bbr). (17)\n3: Randomly pick ir \u2208 {1, 2, \u00b7 \u00b7 \u00b7N} with probability pir :\nxr+1ir = argminxir Uir(xir , z r+1;\u03bbrir); (18) \u03bbr+1ir = \u03bb r ir + \u03b1ir\u03b7ir ( xr+1ir \u2212 z r+1 ) ; (19) xr+1j = x r j , \u03bb r+1 j = \u03bb r j \u2200 j 6= ir. (20)\n4: end for 5: Output: (zm, xm, \u03bbm) where m randomly picked from {1, 2, \u00b7 \u00b7 \u00b7 , R}.\nwith the statement [29, Theorem 4] is that the error bound condition (15) holds true globally. This is by the assumption that Z is a compact set. The proof will be provided in the Appendix.\nUtilizing the above result, we have the following linear convergence claim.\nTheorem 2.2. Suppose that Assumptions A, B are satisfied. Then the sequence {E[Qr+1]}\u221er=1 converges Q-linearly 1 to some Q\u2217 = f(z\u2217), where z\u2217 is a stationary solution for problem (1). That is, there exists a finite r\u0304 > 0, \u03c1 \u2208 (0, 1) such that for all r \u2265 r\u0304, E[Qr+1 \u2212Q\u2217]\u2264 \u03c1E[Qr \u2212Q\u2217].\nLinear convergence of this type for problems satisfying Assumption B has been shown for (deterministic) proximal gradient based methods [29, Theorem 2, 3]. To the best of our knowledge, this is the first result that shows the same linear convergence for a stochastic and distributed algorithm. There has been some recent works showing linear convergence for nonconvex problems satisfying certain quadratic growth condition [16, 25, 1]. However the problems considered in [16, 25, 1] are smooth unconstrained problems, and every stationary point is a global minimum, therefore they do no cover our nonconvex quadratic problems, whose stationary solutions are not global minimizers.\n3 The NESTT-E Algorithm\n3.1 Algorithm Description\nIn this section, we present a variant of NESTT-G, which is named NESTT with Exact minimization (NESTT-E). Our motivation is the following. First, in NESTT-G every agent should update its local variable at every iteration [cf. (4) or (6)]. In practice this may not be possible, for example at any given time a few agents can be in the sleeping mode so they cannot perform (6). Second, in the distributed setting it has been generally observed (e.g., see [9, Section V]) that performing exact minimization (whenever possible) instead of taking the gradient steps for local problems can significantly speed up the algorithm. The NESTT-E algorithm to be presented in this section is designed to address these issues. To proceed,\n1A sequence {xr} is said to converge Q-linearly to some x\u0304 if lim supr \u2016xr+1 \u2212 x\u0304\u2016/\u2016xr \u2212 x\u0304\u2016 \u2264 \u03c1, where \u03c1 \u2208 (0, 1) is some constant; cf [29] and references therein.\nlet us define a new function as follows:\nU(x, z;\u03bb) := N\u2211 i=1 Ui(xi, z;\u03bbi) := N\u2211 i=1 ( 1 N gi(xi) + \u3008\u03bbi, xi \u2212 z\u3009+ \u03b1i\u03b7i 2 \u2016xi \u2212 z\u20162 ) .\nNote that if \u03b1i = 1 for all i, then the L(x, z;\u03bb) = U(x, z;\u03bb) + p(z) + h(z). The algorithm details are presented in Algorithm 2. The algorithm proceeds as follows. At each iteration the cluster center minimizes L(x, z;\u03bb) with respect to z. Then the updated z is sent to a randomly selected agent ir \u2208 {1, 2, \u00b7 \u00b7 \u00b7N}, who minimizes U(x, z;\u03bb) w.r.t. its local variable xir , followed by a dual ascent step for \u03bbir .\n3.2 Convergence Analysis\nWe begin analyzing NESTT-E. The proof technique is quite different from that for NESTT-G, and it is based upon using the expected value of the Augmented Lagrangian function as the potential function. For the ease of description we define the following quantities:\nw := (x, z, \u03bb), \u03b2 := 1\u2211N i=1 \u03b7i , ci := L2i \u03b1i\u03b7iN2 \u2212 \u03b3i 2 + 1\u2212 \u03b1i \u03b1i Li N , \u03b1 := {\u03b1i}Ni=1.\nTo measure the optimality of NESTT-E, define the prox-gradient of L(x, z;\u03bb) as: \u2207\u0303L(w) = [ (z \u2212 proxh[z \u2212\u2207z(L(w)\u2212 h(z))]);\u2207x1L(w); \u00b7 \u00b7 \u00b7 ;\u2207xNL(w) ] \u2208 R(N+1)d. (21)\nWe define the optimality gap by adding to \u2016\u2207\u0303L(w)\u20162 the size of the constraint violation [14]:\nH(wr) := \u2016\u2207\u0303L(wr)\u20162 + N\u2211 i=1 L2i N2 \u2016xri \u2212 zr\u20162.\nIt can be verified that H(wr) \u2192 0 implies that wr reaches a stationary solution for problem (2). We have the following theorem regarding the convergence properties of NESTT-E.\nTheorem 3.1. Suppose Assumption A holds, and that (\u03b7i, \u03b1i) are chosen such that ci < 0 . Then for some constant f , we have\nE[L(wr)] \u2265 E[L(wr+1)] \u2265 f > \u2212\u221e, \u2200 r \u2265 0.\nFurther, almost surely every limit point of {wr} is a stationary solution of problem (2). Finally, for some function of \u03b1 denoted as C(\u03b1) = \u03c31(\u03b1)/\u03c32(\u03b1), we have the following:\nE[H(wm)] \u2264 C(\u03b1)E[L(w 1)\u2212 L(wR+1)] R , (22)\nwhere \u03c31 := max(\u03c3\u03021(\u03b1), \u03c3\u03031) and \u03c32 := max(\u03c3\u03022(\u03b1), \u03c3\u03032), and these constants are given by\n\u03c3\u03021(\u03b1) = max i\n{ 4 ( L2i N2 + \u03b72i + ( 1 \u03b1i \u2212 1 )2 L2i N2 ) + 3 ( L4i \u03b1i\u03b72iN 4 + L2i N2 )} ,\n\u03c3\u03031 = N\u2211 i=1 4\u03b72i + (2 + N\u2211 i=1 \u03b7i + L0) 2 + 3 N\u2211 i=1 L2i N2 ,\n\u03c3\u03022(\u03b1) = max i\n{ pi ( \u03b3i 2 \u2212 L 2 i N2\u03b1i\u03b7i \u2212 1\u2212 \u03b1i \u03b1i Li N )} , \u03c3\u03032 = \u2211N i=1 \u03b7i \u2212 L0 2 .\nWe remark that the above result shows the sublinear convergence of NESTT-E to the set of stationary solutions. Note that \u03b3i = \u03b7i \u2212 Li/N , to satisfy ci < 0, a simple derivation yields\n\u03b7i > Li\n( (2\u2212 \u03b1i) + \u221a (\u03b1i \u2212 2)2 + 8\u03b1i ) 2N\u03b1i .\nFurther, the above result characterizes the dependency of the rates on various parameters of the algorithm. For example, to see the effect of \u03b1 on the convergence rate, let us set pi = Li\u2211N i=1 Li , and \u03b7i = 3Li/N , and assume L0 = 0, then consider two different choices of \u03b1: \u03b1\u0302i = 1, \u2200 i and \u03b1\u0303i = 4, \u2200 i. One can easily check that applying these different choices leads to following results:\nC(\u03b1\u0302) = 49 N\u2211 i=1 Li/N, C(\u03b1\u0303) = 28 N\u2211 i=1 Li/N.\nThe key observation is that increasing \u03b1i\u2019s reduces the constant in front of the rate. Hence, we expect that in practice larger \u03b1i\u2019s will yield faster convergence. This phenomenon will be later confirmed by the numerical results.\nNext let us briefly present the linear convergence of NESTT-E algorithm under Assumption B. The proof again utilizes the error bound condition in Lemma 2.2.\nTheorem 3.2. Suppose that Assumptions A, B are satisfied. Then the sequence {E[Lr+1]}\u221er=1 converges Q-linearly to some L\u2217 = f(z\u2217), where z\u2217 is a stationary solution for problem (1). That is, there exists a finite r\u0304 > 0, \u03c1 \u2208 (0, 1) such that for all r \u2265 r\u0304, E[Lr+1 \u2212 L\u2217] \u2264 \u03c1E[Lr \u2212 L\u2217].\n4 Connections and Comparisons with Existing Works\nIn this section we compare NESTT-G/E with a few existing algorithms in the literature. First, we present a somewhat surprising observation, that NESTT-G takes the same form as some well-known algorithms for convex finite-sum problems. To formally state such relation, we show in the following result that NESTT-G in fact admits a compact primal-only characterization.\nProposition 4.1. The NESTT-G can be written into the following compact form:\nzr+1 = arg min z\nh(z) + g0(z) + 1\n2\u03b2 \u2016z \u2212 ur+1\u20162 (23a)\nwith ur+1 := zr \u2212 \u03b2 ( 1 N\u03b1ir (\u2207gir(zr)\u2212\u2207gir(yr\u22121ir )) + 1 N N\u2211 i=1 \u2207gi(yr\u22121i ) ) . (23b)\nBased on this observation, the following comments are in order.\n(1) Suppose h \u2261 0, g0 \u2261 0 and \u03b1i = 1, pi = 1/N for all i. Then (23) takes the same form as the SAG presented in [26]. Further, when the component functions gi\u2019s are picked cyclically in a Gauss-Seidel manner, the iteration (23) takes the same form as the IAG algorithm [6].\n(2) Suppose h 6= 0 and g0 6= 0, and \u03b1i = pi = 1/N for all i. Then (23) is the same as the SAGA algorithm [10], which is design for optimizing convex nonsmooth finite sum problems.\nCase I: Li = 1, \u2200i O(N/ ) O(N/ ) Case II : O(N2/3) terms with Li = N2/3 the rest with Li = 1 O(N/ ) O(N4/3/ ) Case II : O( \u221a N) terms with Li = N the rest with Li = 1 O(N/ ) O(N3/2/ ) Case IV : O(1) terms with Li = N2 the rest with Li = 1 O(N/ ) O(N2/ )\nNote that SAG/SAGA/IAG are all designed for convex problems. Through the lens of primal-dual splitting, our work shows that they can be generalized to nonconvex nonsmooth problems as well.\nSecondly, NESTT-E is related to the proximal version of the nonconvex ADMM [14, Algorithm 2]. However, the introduction of \u03b1i\u2019s is new, which can significantly improve the practical performance but complicates the analysis. Further, there has been no counterpart of the sublinear and linear convergence rate analysis for the stochastic version of [14, Algorithm 2].\nThirdly, we note that a recent paper [25] has shown that SAGA works for smooth and unconstrained nonconvex problem. Suppose that h \u2261 0, g0 6= 0, Li = Lj , \u2200 i, j and \u03b1i = pi = 1/N , the authors show that SAGA achieves -stationarity using O(N2/3( \u2211N i=1 Li/N)/ ) gradient evaluations. Compared with GD,\nwhich achieves -stationarity using O( \u2211N\ni=1 Li/ ) gradient evaluations in the worse case (in the sense that\u2211N i=1 Li/N = L), the rate in [25] is O(N1/3) times better. However, the algorithm in [25] is different from NESTT-G in two aspects: 1) it does not generalize to the nonsmooth constrained problem (1); 2) it samples two component functions at each iteration, while NESTT-G only samples once. Further, the analysis and the scaling are derived for the case of uniform Li\u2019s, therefore it is not clear how the algorithm and the rates can be adapted for the non-uniform case. On the other hand, our NESTT works for the general nonsmooth constrained setting. The non-uniform sampling used in NESTT-G is well-suited for problems with non-uniform Li\u2019s, and our scaling can be up to N times better than GD (or its proximal version) in the worst case. Note that problems with non-uniform Li\u2019s for the component functions are common in applications such as sparse optimization and signal processing. For example in LASSO problem the data matrix is often normalized by feature (or \u201ccolumn-normalized\u201d [22]), therefore the `2 norm of each row of the data matrix (which corresponds to the Lipschitz constant for each component function) can be dramatically different.\nIn Table 1 we list the comparison of the number of gradient evaluations for NESTT-G and GD, in the worst case (in the sense that \u2211N i=1 Li/N = L). For simplicity, we omitted an additive constant of O(N) for computing the initial gradients.\n5 Numerical Results\nIn this section we evaluate the performance of NESTT. Consider the high dimensional regression problem with noisy observation [18], where M observations are generated by y = X\u03bd + . Here y \u2208 RM is the observed data sample; X \u2208 RM\u00d7P is the covariate matrix; \u03bd \u2208 RP is the ground truth, and \u2208 RM is\nthe noise. Suppose that the covariate matrix is not perfectly known, i.e., we observe A = X + W where W \u2208 RM\u00d7P is the noise matrix with known covariance matrix \u03a3W . Let us define \u0393\u0302 := 1/M(A>A)\u2212\u03a3W , and \u03b3\u0302 := 1/M(A>y). To estimate the ground truth \u03bd, let us consider the following (nonconvex) optimization problem posed in [18, problem (2.4)] (where R > 0 controls sparsity):\nmin z\nz>\u0393\u0302z \u2212 \u03b3\u0302z s.t. \u2016z\u20161 \u2264 R. (24)\nDue to the existence of noise, \u0393\u0302 is not positive semidefinite hence the problem is not convex. Note that this problem satisfies Assumption A\u2013 B, then by Theorem 2.2 NESTT-G converges Q-linearly.\nTo test the performance of the proposed algorithm, we generate the problem following similar setups as [18]. Let X = (X1; \u00b7 \u00b7 \u00b7 , XN ) \u2208 RM\u00d7P with \u2211 iNi = M and each Xi \u2208 RNi\u00d7P corresponds to Ni data points, and it is generated from i.i.d Gaussian. Here Ni represents the size of each mini-batch of samples. Generate the observations yi = Xi \u00d7 \u03bd\u2217 + i \u2208 RNi , where \u03bd\u2217 is a K-sparse vector to be estimated, and i \u2208 RNi is the random noise. Let W = [W1; \u00b7 \u00b7 \u00b7 ;WN ], with Wi \u2208 RNi\u00d7P generated with i.i.d Gaussian. Therefore we have z>\u0393\u0302z = 1N \u2211N i=1 N M z > (X>i Xi \u2212W>i Wi) z. We set M = 100.000, P = 5000, N = 50,\nK = 22 \u2248 \u221a P ,and R = \u2016\u03bd\u2217\u20161. In simulation, we perform a mini-batch version of the algorithms, meaning that we split the data matrix A and labels y into M submatrices and store them into different nodes. Therefore, in each node we have \u0393\u0302i \u2208 Rni\u00d7p, and \u03b3\u0302i \u2208 Rp such that \u2211M i=1 ni = n. Here we set M = 30. We implement NESTT-G/E, the SGD, and the nonconvex SAGA proposed in [25] with stepsize \u03b2 = 1 3LmaxN2/3 (with Lmax := maxi Li). Note that the SAGA proposed in [25] only works for the unconstrained problems with uniform Li, therefore when applied to (24) it is not guaranteed to converge. Here we only include it for comparison purposes.\nIn Fig. 1 we compare different algorithms in terms of the gap \u2016\u2207\u03031/\u03b2f(zr)\u20162. In the left figure we consider the problem with Ni = Nj for all i, j, and we show performance of the proposed algorithms with uniform sampling (i.e., the probability of picking ith block is pi = 1/N). On the right one we consider problems in which approximately half of the component functions have twice the size of Li\u2019s as the rest, and consider the non-uniform sampling (pi = \u221a Li/N/ \u2211N i=1 \u221a Li/N). Clearly in both cases the proposed algorithms perform quite well. Furthermore, it is clear that the NESTT-E performs well with large \u03b1 := {\u03b1i}Ni=1, which confirms our theoretical rate analysis. Also it is worth mentioning that when the Ni\u2019s are non-uniform, the proposed algorithms [NESTT-G and NESTT-E (with \u03b1 = 10)] significantly outperform SAGA and SGD. In Table 2 we further compare different algorithms when changing the number of component functions (i.e., the number of mini-batches N) while the rest of the setup is as above. We run each algorithm with 100 passes over the dataset. Similarly as before, our algorithms perform well, while SAGA seems to be sensitive to the uniformity of the size of the mini-batch [note that there is no convergence guarantee for SAGA applied to the nonconvex constrained problem (24)].\ndataset. Left: Uniform Sampling pi = 1/N ; Right: Non-uniform Sampling (pi =\n\u221a\nLi/N\u2211N\ni=1\n\u221a Li/N ).\nAppendix\n5.1 Some Key Properties of NESTT-G\nTo facilitate the following derivation, in this section we collect some key properties of NESTT-G. First, from the optimality condition of the x update we have\nxr+1ir = z r \u2212 1\n\u03b1ir\u03b7ir\n( \u03bbrir + 1\nN \u2207gir(zr)\n) , (25a)\nxr+1j (6) = zr (8b) = zr \u2212 1\n\u03b1j\u03b7j (\u03bbrj +\n1\nN \u2207gj(zr(j))), \u2200 j 6= ir. (25b)\nThen using the update scheme of the \u03bb we can further obtain\n\u03bbr+1ir = \u2212 1\nN \u2207gir(zr), (26a)\n\u03bbr+1j = \u2212 1\nN \u2207gj(zr(j)), \u2200 j 6= ir. (26b)\nTherefore, using the definition of yri we have the following compact forms\n\u03bbr+1i = \u2212 1\nN \u2207gi(yri ), i = 1, \u00b7 \u00b7 \u00b7 , N. (27)\nxr+1i = z r \u2212 1\n\u03b1i\u03b7i\n( \u03bbri + 1\nN \u2207gi(yri )\n) , i = 1, \u00b7 \u00b7 \u00b7 , N. (28)\nSecond, let us look at the optimality condition for the z update. The z-update (7) is given by\nzr+1 = arg min z L({xr+1i }, z;\u03bb r)\n= arg min z N\u2211 i=1 ( \u3008\u03bbri , xr+1i \u2212 z\u3009+ \u03b7i 2 \u2016xr+1i \u2212 z\u2016 2 ) + g0(z) + h(z). (29)\nNote that this problem is strongly convex because we have assumed that \u2211\ni=1 \u03b7i > 3L0; cf. Assumption [A-(c)].\nLet us define\nur+1 :=\n\u2211N i=1 \u03b7ix r+1 i + \u2211N i=1 \u03bb\nr i\u2211N\ni=1 \u03b7i\n=\n\u2211N i=1 \u03b7iz\nr \u2212 \u03b7ir(zr \u2212 xr+1ir )\u2211N i=1 \u03b7i +\n\u2211N i=1 \u03bb\nr i\u2211N\ni=1 \u03b7i\n(25a) =\n\u2211N i=1 \u03b7iz r \u2212 \u03b7ir\u03b1ir\u03b7ir (\u03bb r ir\n+ 1/N\u2207gir(zr))\u2211N i=1 \u03b7i +\n\u2211N i=1 \u03bb\nr i\u2211N\ni=1 \u03b7i\n(27) = zr \u2212\n1 \u03b1ir (\u2212\u2207gir(yr\u22121ir ) +\u2207gir(z r)) N \u2211N i=1 \u03b7i \u2212 \u2211N i=1\u2207gi(y r\u22121 i ) N \u2211N i=1 \u03b7i\n(i) = zr \u2212 \u03b2\nN\u03b1ir (\u2212\u2207gir(yr\u22121ir ) +\u2207gir(z\nr))\u2212 \u03b2 \u2211N i=1\u2207gi(y r\u22121 i )\nN (30)\n(ii) : = zr \u2212 \u03b2vr+1ir (31)\nwhere in (i) we have defined \u03b2 := 1/ \u2211N\ni=1 \u03b7i; in (ii) we have defined\nvr+1ir := 1\nN N\u2211 i=1 \u2207gi(yr\u22121i ) + 1 \u03b1ir ( \u2212 1 N \u2207gir(yr\u22121ir ) + 1 N \u2207gir(zr) ) . (32)\nClearly if we pick \u03b1i = pi for all i, then we have\nEir [ur+1 | Fr] = zr \u2212 \u03b2\nN N\u2211 i=1 \u2207gi(zr). (33)\nUsing the definition of ur+1, it is easy to check that\nzr+1 = arg min z\n1\n2\u03b2 \u2016z \u2212 ur+1\u20162 + h(z) + g0(z)\n= prox 1/\u03b2 h [u r+1 \u2212 \u03b2\u2207g0(zr+1)]. (34)\nThe optimality condition for the z subproblem is given by:\nzr+1 \u2212 ur+1 + \u03b2\u2207g0(zr+1) + \u03b2\u03ber+1 = 0 (35)\nwhere, \u03ber+1 \u2208 \u2202h(zr+1) is a subgradient of h(zr+1). Using the definition of vir in (32), we obtain\nzr+1 = zr \u2212 \u03b2(vr+1ir +\u2207g0(z r+1) + \u03ber+1). (36)\nThird, if \u03b1i = pi, then we have:\nEir \u2225\u2225\u2225\u2225\u2225\u2212\u03bbrir + 1/N\u2207gir(zr)\u03b1ir + 1N N\u2211 i=1 \u2207gi(zr)\u2212 N\u2211 i=1 1 N \u2207gi(yr\u22121i ) \u2225\u2225\u2225\u2225\u2225 2 \n(a) = Var [ \u2212 \u03bbrir + 1/N\u2207gir(z r)\n\u03b1ir ] (b)\n\u2264 N\u2211 i=1 1 \u03b1i \u2225\u2225\u2225\u2225 1N\u2207gi(zr)\u2212 1N\u2207gi(yr\u22121i ) \u2225\u2225\u2225\u22252 , (37)\nwhere (a) is true because whenever \u03b1i = pi for all i, then\nEir [ \u2212 \u03bbrir + 1/N\u2207gir(z r)\n\u03b1ir\n] = 1\nN N\u2211 i=1 \u2207gi(zr)\u2212 N\u2211 i=1 1 N \u2207gi(yr\u22121i );\nThe inequality in (b) is true because for a random variable x we have Var(x) \u2264 E[x2].\n5.2 Proof of Lemma 2.1\nStep 1). Using the definition of potential function Qr, we have:\nE[Qr \u2212Qr\u22121 | Fr\u22121]\n= E [ N\u2211 i=1 1 N ( gi(z r)\u2212 gi(zr\u22121) ) + g0(z r)\u2212 g0(zr\u22121) + h(zr)\u2212 h(zr\u22121) | Fr\u22121 ]\n+ E [ N\u2211 i=1 3pi \u03b12i \u03b7i \u2225\u2225\u2225\u2225 1N\u2207gi(zr)\u2212 1N\u2207gi(yr\u22121i ) \u2225\u2225\u2225\u22252 \u2212 3pi\u03b12i \u03b7i \u2225\u2225\u2225\u2225 1N\u2207gi(zr\u22121)\u2212 1N\u2207gi(yr\u22122i ) \u2225\u2225\u2225\u22252 | Fr\u22121 ] . (38)\nStep 2). The first term in (38) can be bounded as follows (omitting the subscript Fr).\nE [ N\u2211 i=1 1 N ( gi(z r)\u2212 gi(zr\u22121) ) + g0(z r)\u2212 g0(zr\u22121) + h(zr)\u2212 h(zr\u22121) | Fr\u22121 ] (i)\n\u2264 E [ 1\nN N\u2211 i=1 \u3008\u2207gi(zr\u22121), zr \u2212 zr\u22121\u3009+ \u3008\u2207g0(zr\u22121), zr \u2212 zr\u22121\u3009\n+ \u3008\u03ber, zr \u2212 zr\u22121\u3009+ \u2211N\ni=1 Li/N + L0 2\n\u2016zr \u2212 zr\u22121\u20162 | Fr\u22121 ]\n(ii) = E\n[\u2329 1\nN N\u2211 i=1 \u2207gi(zr\u22121) + \u03ber +\u2207g0(zr) + 1 \u03b2 (zr \u2212 zr\u22121), zr \u2212 zr\u22121\n\u232a | Fr\u22121 ]\n\u2212\n( 1 \u03b2 \u2212 \u2211N i=1 Li/N + 3L0 2 ) Ezr\u2016zr \u2212 zr\u22121\u20162\n(36) = E\n[\u2329 1\nN N\u2211 i=1 \u2207gi(zr\u22121)\u2212 vri(r\u22121), z r \u2212 zr\u22121\n\u232a | Fr\u22121 ]\n\u2212\n( 1 \u03b2 \u2212 \u2211N i=1 Li/N + 3L0 2 ) Ezr\u2016zr \u2212 zr\u22121\u20162\n(iii)\n\u2264 1 2`1 E \u2225\u2225\u2225\u2225\u22251/N N\u2211 i=1 \u2207gi(zr\u22121)\u2212 vri(r\u22121) \u2225\u2225\u2225\u2225\u2225 2 | Fr\u22121 + `1 2 Ezr\u2016zr \u2212 zr\u22121\u20162\n\u2212\n( 1 \u03b2 \u2212 \u2211N i=1 Li/N + 3L0 2 ) Ezr\u2016zr \u2212 zr\u22121\u20162 (39)\nwhere in (i) we have used the Lipschitz continuity of the gradients of gi\u2019s as well as the convexity of h; in (ii) we have used the fact that\n\u3008\u2207g0(zr\u22121), zr \u2212 zr\u22121\u3009 \u2264 \u3008\u2207g0(zr), zr \u2212 zr\u22121\u3009+ L0\u2016zr \u2212 zr\u22121\u20162; (40)\nin (iii) we have applied the Young\u2019s inequality for some `1 > 0. Choosing `1 = 1 2\u03b2 , we have:\n1\n2`1 E \u2225\u2225\u2225\u2225\u2225 1N N\u2211 i=1 \u2207gi(zr\u22121)\u2212 vri(r\u22121) \u2225\u2225\u2225\u2225\u2225 2\n(32) = \u03b2E \u2225\u2225\u2225\u2225\u2225 1N N\u2211 i=1 \u2207gi(zr\u22121)\u2212 \u03bbr\u22121i(r\u22121) + 1/N\u2207gi(r\u22121)(z r\u22121) \u03b1i(r\u22121) \u2212 N\u2211 i=1 1 N \u2207gi(yr\u22122i ) \u2225\u2225\u2225\u2225\u2225 2 \n(37) \u2264 \u03b2 N\u2211 i=1 1 \u03b1i \u2225\u2225\u2225\u2225 1N\u2207gi(zr\u22121)\u2212 1N\u2207gi(yr\u22122i ) \u2225\u2225\u2225\u22252 .\nOverall we have the following bound for the first term in (38):\nE [ N\u2211 i=1 1 N ( gi(z r)\u2212 gi(zr\u22121) ) + g0(z r)\u2212 g0(zr\u22121) + h(zr)\u2212 h(zr\u22121) | Fr\u22121 ] (41)\n\u2264 N\u2211 i=1 \u03b2 \u03b1i \u2225\u2225\u2225\u2225 1N\u2207gi(zr\u22121)\u2212 1N\u2207gi(yr\u22122i ) \u2225\u2225\u2225\u22252 \u2212 ( 3 4\u03b2 \u2212 \u2211N i=1 Li/N + 3L0 2 ) Ezr\u2016zr \u2212 zr\u22121\u20162.\nStep 3). We bound the second term in (38) in the following way: E [ \u2016\u2207gi(zr)\u2212\u2207gi(yr\u22121i )\u2016 2 | Fr\u22121 ]\n= E [ \u2016\u2207gi(zr)\u2212\u2207gi(yr\u22121i ) +\u2207gi(z r\u22121)\u2212\u2207gi(zr\u22121)\u20162 | Fr\u22121 ] (i)\n\u2264 (1 + \u03bei)Ezr\u2016\u2207gi(zr)\u2212\u2207gi(zr\u22121)\u20162 + ( 1 + 1\n\u03bei\n) Eyr\u22121i \u2016\u2207gi(y r\u22121 i )\u2212\u2207gi(z r\u22121)\u20162\n(ii) = (1 + \u03bei)Ezr\u2016\u2207gi(zr)\u2212\u2207gi(zr\u22121)\u20162 + (1\u2212 pi) ( 1 + 1\n\u03bei\n) \u2016\u2207gi(yr\u22122i )\u2212\u2207gi(z r\u22121)\u20162 (42)\nwhere in (i) we have used the fact that the randomness of zr\u22121 comes from ir\u22122, so fixing Fr\u22121, zr\u22121 is deterministic; we have also applied the following inequality:\n(a+ b)2 \u2264 (1 + \u03be)a2 + (1 + 1 \u03be )b2 \u2200 \u03be > 0.\nThe equality (ii) is true because the randomness of yr\u22121i comes from ir\u22121, and for each i there is a probability pi such that x r i is updated, so that \u2207gi(y r\u22121 i ) = \u2207gi(zr\u22121), otherwise xi is not updated so that \u2207gi(yr\u22121i ) = \u2207gi(y r\u22122 i ).\nStep 4). Applying (42) and set \u03b1i = pi, the second part of (38) can be bounded as\nE [ N\u2211 i=1 3pi \u03b12i \u03b7i \u2225\u2225\u2225\u2225 1N\u2207gi(zr)\u2212 1N\u2207gi(yr\u22121i ) \u2225\u2225\u2225\u22252 \u2212 3pi\u03b12i \u03b7i \u2225\u2225\u2225\u2225 1N\u2207gi(zr\u22121)\u2212 1N\u2207gi(yr\u22122i ) \u2225\u2225\u2225\u22252 | Fr\u22121 ]\n\u2264 N\u2211 i=1 3L2i \u03b1i\u03b7iN2 (1 + \u03bei)Ezr\u2016zr \u2212 zr\u22121\u20162\n+ 3\n\u03b1i\u03b7i\n( (1\u2212 pi)(1 + 1\n\u03bei )\u2212 1 )\u2225\u2225\u2225\u2225 1N\u2207gi(yr\u22122i )\u2212 1N\u2207gi(zr\u22121) \u2225\u2225\u2225\u22252 . (43)\nCombining (41) and (43) eventually we have\nE[Qr \u2212Qr\u22121 | Fr]\n\u2264 N\u2211 i=1 { \u03b2 \u03b1i + 3 \u03b1i\u03b7i ( (1\u2212 pi)(1 + 1 \u03bei )\u2212 1 )}\u2225\u2225\u2225\u2225 1N\u2207gi(zr\u22121)\u2212 1N\u2207gi(yr\u22122i ) \u2225\u2225\u2225\u22252\n+ { \u2212 3\n4\u03b2 +\n\u2211N i=1 Li/N + 3L0\n2 + N\u2211 i=1 3L2i \u03b1i\u03b7iN2 (1 + \u03bei)\n} Ezr\u2016zr \u2212 zr\u22121\u20162. (44)\nLet us define {c\u0303i} and c\u0302 as following:\nc\u0303i = \u03b2\n\u03b1i +\n3\n\u03b1i\u03b7i\n( (1\u2212 pi)(1 + 1\n\u03bei )\u2212 1 ) c\u0302 = \u2212 3\n4\u03b2 +\n\u2211N i=1 Li/N + 3L0\n2 + N\u2211 i=1 3L2i \u03b1i\u03b7iN2 (1 + \u03bei) .\nIn order to prove the lemma it is enough to show that c\u0303i < \u2212 12\u03b7i \u2200 i, and c\u0302 < \u2212 \u2211N i=1 \u03b7i 8 . Let us pick\n\u03b1i = pi, \u03bei = 2\npi , pi = \u03b7i\u2211N i=1 \u03b7i . (45)\nRecall that \u03b2 = 1\u2211N i=1 \u03b7i .These values yield the following\nc\u0303i = 1 \u03b7i \u2212 3 \u03b7i\n( pi + 1\n2 ) \u2264 1 \u03b7i \u2212 3 2\u03b7i = \u2212 1 2\u03b7i < 0.\nTo show that c\u0302 \u2264 \u2212 \u2211N\ni=1 \u03b7i 8 let us assume that \u03b7i = diLi for some di > 0. Note that by assumption we\nhave N\u2211 i=1 \u03b7i \u2265 3L0.\nTherefore we have the following expression for c\u0302:\nc\u0302 \u2264 \u2212 N\u2211 i=1 1 4 diLi + Li 2N + 3Li pidiN2 ( 1 + 2 pi )\n< N\u2211 i=1 Li di ( \u22121 4 d2i + di 2N + 9 p2iN 2 ) .\nAs a result, to have c\u0302 < \u2212 \u2211N\ni=1 \u03b7i 8 , we need\nLi di\n( 1\n4 d2i \u2212 di 2N \u2212 9 p2iN 2\n) \u2265 diLi\n8 , \u2200 i. (46)\nOr equivalently\n1 8 d2i \u2212 di 2N \u2212 9 p2iN 2 \u2265 0, \u2200 i. (47)\nBy finding the root of the above quadratic inequality, we need di \u2265 9Npi , which is equivalent to choosing the following parameters\n\u03b7i \u2265 9Li Npi . (48)\nThe lemma is proved. Q.E.D.\n5.3 Proof of Theorem 2.1\nFirst, using the fact that f(z) is lower bounded [cf. Assumption A-(a)], it is easy to verify that {Qr} is a bounded sequence. Denote its lower bound to be Q. From Lemma 2.1, it is clear that {Qr \u2212 Q} is a nonnegative supermartingale. Apply the Supermartigale Convergence Theorem [4, Proposition 4.2] we conclude that {Qr} converges almost surely (a.s.), and that\u2225\u2225\u2207gi(zr\u22121)\u2212\u2207gi(yr\u22122i )\u2225\u22252 \u2192 0, Ezr\u2016zr \u2212 zr\u22121\u2016 \u2192 0, a.s., \u2200 i. (49) The first inequality implies that \u2016\u03bbrir\u2212\u03bb r\u22121 ir \u2016 \u2192 0. Combining this with equation (5) yields \u2016xrir\u2212z\nr\u22121\u2016 \u2192 0, which further implies that \u2016zr \u2212 zr\u22121\u2016 \u2192 0. By utilizing (8b) \u2013 (8c), we can conclude that\n\u2016xri \u2212 xr\u22121i \u2016 \u2192 0, \u2016\u03bb r i \u2212 \u03bbr\u22121i \u2016 \u2192 0, a.s., \u2200 i. (50)\nThat is, almost surely the successive differences of all the primal and dual variables go to zero. Then it is easy to show that every limit point of the sequence (xr, zr, \u03bbr) converge to a stationary solution of problem (2) (for example, see the argument in [14, Theorem 2]. Here we omit the full proof.\nPart 1). We bound the gap in the following way (where the expectation is taking over the nature history of the algorithm):\nE [ \u2016zr \u2212 prox1/\u03b2h [z r \u2212 \u03b2\u2207(g(zr) + g0(zr))]\u20162 ]\n(a) = E [ \u2016zr \u2212 zr+1 + prox1/\u03b2h [u r+1 \u2212 \u03b2\u2207g0(zr+1)]\u2212 prox1/\u03b2h [z r \u2212 \u03b2\u2207(g(zr) + g0(zr))]\u20162 ] (b) \u2264 3E\u2016zr \u2212 zr+1\u20162 + 3E\u2016ur+1 \u2212 zr + \u03b2\u2207g(zr)\u20162 + 3L20\u03b22\u2016zr+1 \u2212 zr\u20162\n(c) \u2264 10 3 E\u2016zr \u2212 zr+1\u20162 + 3\u03b22E\n[ \u2016\u2207g(zr)\u2212 \u03bbrir + 1/N\u2207gir(z r)\n\u03b1ir \u2212 N\u2211 i=1 1/N\u2207gi(yr\u22121i )\u2016 2 ] (37)\n\u2264 10 3 E\u2016zr \u2212 zr+1\u20162 + 3\u03b22 N\u2211 i=1 1 \u03b1i E \u2225\u2225\u2225\u2225 1N\u2207gi(zr)\u2212 1N\u2207gi(yr\u22121i ) \u2225\u2225\u2225\u22252\n\u2264 10 3 E\u2016zr \u2212 zr+1\u20162 + 3 N\u2211 i=1 \u03b2 \u03b7i E \u2225\u2225\u2225\u2225 1N\u2207gi(zr)\u2212 1N\u2207gi(yr\u22121i ) \u2225\u2225\u2225\u22252 (51) where (a) is due to (34); (b) is true due to the nonexpansivness of the prox operator, and the Cauchy-\nSwartz inequality; in (c) we have used the definition of u in (31) and the fact that 3L0 \u2264 \u2211N i=1 \u03b7i = 1 \u03b2 [cf. Assumption A-(c)]. In the last inequality we have applied (45), which implies that\n\u03b2 \u03b1i =\n1 pi \u2211N j=1 \u03b7j = 1 \u03b7i . (52)\nNote that \u03b7i\u2019s has to satisfy (48). Let us follow (11) and choose\n\u03b7i = 9Li piN\n= 9 \u2211N j=1 \u03b7j\nN\u03b7i Li.\nWe have\n\u03b7i = \u221a\u221a\u221a\u221a9Li/N N\u2211 j=1 \u03b7j = \u221a 9Li/N \u221a\u221a\u221a\u221a N\u2211 j=1 \u03b7j (53)\nSumming i from 1 to N we have \u221a\u221a\u221a\u221a N\u2211 i=1 \u03b7i = N\u2211 i=1 \u221a 9Li/N (54)\nThen we conclude that\n1 \u03b2 = N\u2211 i=1 \u03b7i = ( N\u2211 i=1 \u221a 9Li/N )2 . (55)\nSo plugging the expression of \u03b2 into (52) and (53), we conclude\n\u03b1i = pi = \u221a Li/N\u2211N\ni=1\n\u221a Li/N\n, \u03b7i = \u221a 9Li/N N\u2211 j=1 \u221a 9Lj/N. (56)\nAfter plugging in the above inequity into (13), we obtain:\nE[Gr] (51) \u2264 10 3\u03b22 E\u2016zr \u2212 zr+1\u20162 + N\u2211 i=1 3 \u03b2\u03b7i E \u2225\u2225\u2225\u2225 1N\u2207gi(zr)\u2212 1N\u2207gi(yr\u22121i ) \u2225\u2225\u2225\u22252 (57) (12)\n\u2264 80 3\u03b2 E[Qr \u2212Qr+1] = 80 3 ( N\u2211 i=1 \u221a Li/N )2 E[Qr \u2212Qr+1]\nIf we sum both sides over r = 1, \u00b7 \u00b7 \u00b7 , R, we obtain:\nR\u2211 r=1 E[Gr] \u2264 80 3 ( N\u2211 i=1 \u221a Li/N )2 E[Q1 \u2212QR+1].\nUsing the definition of zm, we have\nE[Gm] = EFr [Em[Gm | Fr]] = 1/R R\u2211 r=1 EFr [Gr].\nTherefore, we can finally conclude that:\nE[Gm] \u2264 80 3 ( N\u2211 i=1 \u221a Li/N )2 E[Q1 \u2212QR+1] R (58)\nwhich proves the first part.\nPart 2). In order to prove the second part let us recycle inequality in (57) and write\nE [ Gr +\nN\u2211 i=1 3 \u03b2\u03b7i \u2225\u2225\u2225\u2225 1N\u2207gi(zr)\u2212 1N\u2207gi(yr\u22121i ) \u2225\u2225\u2225\u22252 ]\n\u2264 10 3\u03b22 E\u2016zr+1 \u2212 zr\u20162 + N\u2211 i=1 6 \u03b2\u03b7i E \u2225\u2225\u2225\u2225 1N\u2207gi(zr)\u2212 1N\u2207gi(yr\u22121i ) \u2225\u2225\u2225\u22252\n\u2264 80 3\u03b2 E[Qr \u2212Qr+1] = 48 ( N\u2211 i=1 \u221a Li/N )2 E[Qr \u2212Qr+1].\nAlso note that\nExr [\u2225\u2225xr+1i \u2212 zr\u2225\u22252 | Fr] = N\u2211\ni=1\n1\n\u03b1i\u03b72i\n\u2225\u2225\u2225\u2225 1N\u2207gi(zr)\u2212 1N\u2207gi(yr\u22121i ) \u2225\u2225\u2225\u22252 (59)\nCombining the above two inequalities, we conclude EFr [Gr] + EFr [ N\u2211 i=1 3\u03b72i \u2225\u2225xr+1i \u2212 zr\u2225\u22252 ]\n= EFr [Gr] + EFr [ N\u2211 i=1 3\u03b7i\u03b1i \u03b2 \u2225\u2225xr+1i \u2212 zr\u2225\u22252 ]\n= E [ Gr +\nN\u2211 i=1 3 \u03b2\u03b7i \u2225\u2225\u2225\u2225 1N\u2207gi(zr)\u2212 1N\u2207gi(yr\u22121i ) \u2225\u2225\u2225\u22252 ]\n\u2264 80 3 ( N\u2211 i=1 \u221a Li/N )2 EFr [Qr \u2212Qr+1] (60)\nwhere in the first equality we have used the relation \u03b1i\u03b2 = \u03b7i [cf. (52)]. Using a similar argument as in first part, we conclude that\nE[Gm] + E [ N\u2211 i=1 3\u03b72i \u2225\u2225xmi \u2212 zm\u22121\u2225\u22252 ] \u2264 80 3 ( N\u2211 i=1 \u221a Li/N )2 E[Q1 \u2212QR+1] R . (61)\nThis completes the proof. Q.E.D.\n5.4 Proof of Theorem 2.2\nProof of Lemma 2.2 The first statement holds true largely due to [29, Theorem 4], and the second statement holds true due to [20, Lemma 2.1]; see detailed discussion after [29, Assumption 2]. Here the only difference with the statement [29, Theorem 4] is that the error bound condition (15) holds true globally. This is by the assumption that Z is a compact set. Below we provide a brief argument.\nFrom [29, Theorem 4], we know that when Assumption B is satisfied, we have that for any \u03be \u2265 minz f(z), there exists scalars \u03c4 and such that the following error bound holds\ndist (z, Z\u2217) \u2264 \u03c4\u2016\u2207\u03031/\u03b2f(z)\u2016, whenever \u2016\u2207\u03031/\u03b2f(z)\u2016 \u2264 , f(z) \u2264 \u03be. (62)\nTo argue that when Z is compact, the above error bound is independent of , we use the following two steps: (1) for all z \u2208 Z \u2229dom(h) such that \u2016\u2207\u03031/\u03b2f(z)\u2016 \u2264 \u03b4, it is clear that the error bound (15) holds true; (2) for all z \u2208 Z \u2229 dom(h) such that \u2016\u2207\u03031/\u03b2f(z)\u2016 \u2265 \u03b4, the ratio\ndist (z,Z\u2217) \u2016\u2207\u03031/\u03b2f(z)\u2016 is a continuous function and well defined over the compact set Z \u2229 dom(h)\u2229 { z | \u2016\u2207\u03031/\u03b2f(z)\u2016 \u2265 \u03b4 } . Thus, the above ratio must be bounded from above by a constant \u03c4 \u2032 (independent of b, and no greater than maxz,z\u2032\u2208Z \u2016z \u2212 z\u2032\u2016/\u03b4). Combining (1) and (2) yields the desired error bound over the set Z \u2229 dom(h). Q.E.D.\nProof of Theorem 2.2 From Theorem 2.1 we know that (xr, zr, \u03bbr) converges to the set of stationary solutions of problem (2). Let (x\u2217, z\u2217, \u03bb\u2217) be one of such stationary solution. Then by the definition of the Q function and the fact that the successive differences of the gradients goes to zero (cf. (49)), we have\nQ\u2217 = f(z\u2217) = N\u2211 i=1 1/Ngi(z \u2217) + g0(z \u2217) + p(z\u2217). (63)\nThen by Lemma 2.2 - (2) we know that f(zr) = \u2211N\ni=1 1/Ngi(z r) + g0(z r) + p(zr) will finally settle at some isocost surface of f , i.e., there exists some finite r\u0304 > 0 such that for all r > r\u0304 and v\u0304 \u2208 R such that\nf(z\u0304r) = v\u0304, \u2200 r \u2265 r\u0304 (64)\nwhere z\u0304r = arg minz\u2208Z\u2217 \u2016zr \u2212 z\u2016. Therefore, combining the fact that \u2016xr+1 \u2212 xr\u2016 \u2192 0, \u2016zr+1 \u2212 zr\u2016 \u2192 0, \u2016xr+1i \u2212 zr+1\u2016 \u2192 0 and \u2016\u03bbr+1 \u2212 \u03bbr\u2016 \u2192 0 (cf. (87), (88)), it is easy to see that\nL(z\u0304r, x\u0304r, \u03bb\u0304r) = f(z\u0304r) = v\u0304, \u2200 r \u2265 r\u0304, (65)\nwhere x\u0304r, \u03bb\u0304r are defined similarly as z\u0304r. Now we prove that the expectation of \u2206r+1 := Qr+1 \u2212 v\u0304 diminishes Q-linearly. All the expectation below is w.r.t. the natural history of the algorithm. The proof consists of the following steps: Step 1: There exists \u03c31 > 0 such that\nE[Qr \u2212Qr+1] \u2265 \u03c31 ( E\u2016zr+1 \u2212 zr\u20162 +\nN\u2211 i=1 E\u20161/N\u2207gi(zr)\u2212 1/N\u2207gi(yr\u22121i )\u2016 2\n) ;\nStep 2: There exists \u03c4 > 0 such that\nE\u2016zr \u2212 z\u0304r\u20162 \u2264 \u03c4\u2016E[\u22071/\u03b2 f\u0303(zr)]\u20162;\nStep 3: There exists \u03c32 > 0 such that\n\u2016E[\u22071/\u03b2 f\u0303(zr)]\u20162 \u2264 \u03c32\n( E\u2016zr+1 \u2212 zr\u20162 +\nN\u2211 i=1 E\u20161/N\u2207gi(zr)\u2212 1/N\u2207gi(yr\u22121i )\u2016 2\n) ;\nStep 4: There exists \u03c33 > 0 such that the following relation holds true for all r \u2265 r\u0304\nE[Qr+1 \u2212 v\u0304] \u2264 \u03c33 ( E\u2016zr \u2212 z\u0304r\u20162 + E\u2016zr+1 \u2212 zr\u20162 +\nN\u2211 i=1 E\u20161/N\u2207gi(zr)\u2212 1/N\u2207gi(yr\u22121i )\u2016 2\n) .\nThese steps will be verified one by one shortly. But let us suppose that they all hold true. Below we show that linear convergence can be obtained.\nCombining step 4 and step 2 we conclude that there exists \u03c33 > 0 such that for all r \u2265 r\u0304\nE[Qr+1 \u2212 v\u0304] \u2264 \u03c33 ( \u03c4\u2016E[\u22071/\u03b2 f\u0303(zr\u22121)]\u20162 + E\u2016zr+1 \u2212 zr\u20162 +\nN\u2211 i=1 E\u20161/N\u2207gi(zr)\u2212 1/N\u2207gi(yr\u22121i )\u2016 2\n) .\nThen if we bound \u2016E(Gr)\u20162 using step 3, we can simply make a \u03c34 > 0 such that\nE[Qr+1 \u2212 v\u0304] \u2264 \u03c34 ( E\u2016zr+1 \u2212 zr\u20162 +\nN\u2211 i=1 E\u20161/N\u2207gi(zr)\u2212 1/N\u2207gi(yr\u22121i )\u2016 2\n) .\nFinally, applying step 1 we reach the following bound for E[Qr+1 \u2212 v\u0304]:\nE[Qr+1 \u2212 v\u0304] \u2264 \u03c34 \u03c31 E[Qr \u2212Qr+1], \u2200 r \u2265 r\u0304,\nwhich further implies that for \u03c35 = \u03c34 \u03c31 > 0, we have\nE[\u2206r+1] \u2264 \u03c35 1 + \u03c35 E[\u2206r], \u2200 r \u2265 r\u0304.\nNow let us verify the correctness of each step. Step 1 can be directly obtained from equation (12). Step 2 is exactly Lemma (2.2). Step 3 can be verified using a similar derivation as in (51)2.\nBelow let us prove the step 4, which is a bit involved. From (7) we know that\nzr+1 = arg min z h(z) + g0(z) + N\u2211 i=1 \u3008\u03bbri , xr+1i \u2212 z\u3009+ \u03b7i 2 \u2016xr+1i \u2212 z\u2016 2.\nThis implies that\nh(zr+1) + g0(z r+1) + N\u2211 i=1 \u3008\u03bbri , xr+1i \u2212 z r+1\u3009+ \u03b7i 2 \u2016xr+1i \u2212 z r+1\u20162\n\u2264 h(z\u0304r) + g0(z\u0304r) + N\u2211 i=1 \u3008\u03bbri , xr+1i \u2212 z\u0304 r\u3009+ \u03b7i 2 \u2016xr+1i \u2212 z\u0304 r\u20162. (66)\nRearranging the terms, we obtain\nh(zr+1) + g0(z r+1)\u2212 h(z\u0304r)\u2212 g0(z\u0304r) \u2264 N\u2211 i=1 \u3008\u03bbri , zr+1 \u2212 z\u0304r\u3009+ \u03b7i 2 \u2016xr+1i \u2212 z\u0304 r\u20162.\n2We simply need to replace \u2212zr\u22121 + prox1/\u03b2h [u r\u22121 \u2212 \u03b2\u2207g0(zr\u22121)] in step (a) of (51) by \u2212zr + prox1/\u03b2h [u r \u2212 \u03b2\u2207g0(zr)] and using the same derivation.\nUsing this inequality we have:\nQr+1 \u2212 v\u0304 \u2264 N\u2211 i=1 1/N ( gi(z r+1)\u2212 gi(z\u0304r) ) + \u3008\u03bbri , zr+1 \u2212 z\u0304r\u3009\n+ N\u2211 i=1 \u03b7i 2 \u2016xr+1i \u2212 z\u0304 r\u20162 + \u20161/N(\u2207gi(zr)\u2212\u2207gi(yr\u22121i )\u2016 2. (67)\nThe first term in RHS can be bounded as follows: N\u2211 i=1 1/N ( gi(z r+1)\u2212 gi(z\u0304r) )\n(a) \u2264 N\u2211 i=1 1/N\u3008\u2207gi(z\u0304r), zr+1 \u2212 z\u0304r\u3009+ Li/2N\u2016zr+1 \u2212 z\u0304r\u20162\n\u2264 N\u2211 i=1 1/N\u3008\u2207gi(z\u0304r) +\u2207gi(zr+1)\u2212\u2207gi(zr+1), zr+1 \u2212 z\u0304r\u3009+ Li/2N\u2016zr+1 \u2212 z\u0304r\u20162\n(b) \u2264 N\u2211 i=1 1/N\u3008\u2207gi(zr+1), zr+1 \u2212 z\u0304r\u3009+ 3Li/2N\u2016zr+1 \u2212 z\u0304r\u20162,\nwhere (a) is true due to the descent lemma; and (b) comes from the Lipschitz continuity of the \u2207gi. Plugging the above bound into (67), we further have:\nQr+1 \u2212 v\u0304 \u2264 N\u2211 i=1 1/N\u3008\u2207gi(zr+1)\u2212\u2207gi(yr\u22121i ), z r+1 \u2212 z\u0304r\u3009+ 3Li/2N\u2016zr+1 \u2212 z\u0304r\u20162\n+ \u03b7i 2 \u2016xr+1i \u2212 z\u0304 r\u20162 + \u20161/N(\u2207gi(zr)\u2212\u2207gi(yr\u22121i )\u2016 2\n= N\u2211 i=1 1/N\u3008\u2207gi(zr+1) +\u2207gi(zr)\u2212\u2207gi(zr)\u2212\u2207gi(yr\u22121i ), z r+1 \u2212 z\u0304r\u3009 + \u03b7i 2 \u2016xr+1i \u2212 z\u0304 r\u20162 + \u20161/N(\u2207gi(zr)\u2212\u2207gi(yr\u22121i )\u2016 2 + 3Li/2N\u2016zr+1 \u2212 z\u0304r\u20162,\nwhere in the first inequality we have used the fact that \u03bbri = \u2212 1N\u2207gi(y r\u22121 i ); cf . (27). Applying the Cauchy-Schwartz inequality we further have:\nQr+1 \u2212 v\u0304 \u2264 N\u2211 i=1 1/2\u20161/N ( \u2207gi(zr+1) +\u2207gi(zr) ) \u20162 + 1/2\u2016zr+1 \u2212 z\u0304r\u20162\n+ N\u2211 i=1 1/2\u20161/N ( \u2207gi(zr)\u2212\u2207gi(yr\u22121i ) ) \u20162 + 1/2\u2016zr+1 \u2212 z\u0304r\u20162 + \u03b7i 2 \u2016xr+1i \u2212 z\u0304 r\u20162 + \u20161/N(\u2207gi(zr)\u2212\u2207gi(yr\u22121i )\u2016 2 + 3Li/2N\u2016zr+1 \u2212 z\u0304r\u20162\n\u2264 N\u2211 i=1 [ L2i 2N2 \u2016zr+1 \u2212 zr\u20162 + 3 2N2 \u2016gi(zr)\u2212\u2207gi(yr\u22121i )\u2016 2 + \u03b7i 2 \u2016xr+1i \u2212 z\u0304 r\u20162 ] + (1 + 3Li/2N) \u2016zr+1 \u2212 z\u0304r\u20162. (68)\nNow let us bound \u2211N\ni=1 \u03b7i 2 \u2016x r+1 i \u2212 z\u0304r\u20162 in the above inequality:\nN\u2211 i=1 \u03b7i 2 \u2016xr+1i \u2212 z\u0304 r\u20162 = N\u2211 i=1 \u03b7i 2 \u2016xr+1i \u2212 z r+1 + zr+1 \u2212 z\u0304r\u20162\n\u2264 N\u2211 i=1 \u03b7i\u2016xr+1i \u2212 z r+1\u20162 + \u03b7i\u2016zr+1 \u2212 z\u0304r\u20162\n= N\u2211 i=1 \u03b7i\u2016xr+1i \u2212 z r + zr \u2212 zr+1\u20162 + \u03b7i\u2016zr+1 \u2212 z\u0304r\u20162\n\u2264 N\u2211 i=1 2\u03b7i\u2016xr+1i \u2212 z r\u20162 + 2\u03b7i\u2016zr \u2212 zr+1\u20162 + \u03b7i\u2016zr+1 \u2212 z\u0304r\u20162.\nUsing the fact that xr+1i = z r when i 6= ir we further have:\nN\u2211 i=1 \u03b7i 2 \u2016xr+1i \u2212 z\u0304 r\u20162 \u2264 2\u03b7ir\u2016xr+1ir \u2212 z r\u20162 + N\u2211 i=1 2\u03b7i\u2016zr \u2212 zr+1\u20162 + \u03b7i\u2016zr+1 \u2212 z\u0304r\u20162\n= 2\n\u03b12ir\u03b7ir \u2016\u03bbir + 1/N\u2207gir(zr)\u20162 + N\u2211 i=1 2\u03b7i\u2016zr \u2212 zr+1\u20162 + \u03b7i\u2016zr+1 \u2212 z\u0304r\u20162\n= 2\n\u03b12ir\u03b7irN 2 \u2016\u2207gir(zr)\u2212\u2207gir(yr\u22121ir )\u2016 2\n+ N\u2211 i=1 2\u03b7i\u2016zr \u2212 zr+1\u20162 + \u03b7i\u2016zr+1 \u2212 zr + zr \u2212 z\u0304r\u20162 \u2264 2 \u03b12ir\u03b7irN 2 \u2016\u2207gir(zr)\u2212\u2207gir(yr\u22121ir )\u2016 2\n+ N\u2211 i=1 4\u03b7i\u2016zr \u2212 zr+1\u20162 + 2\u03b7i\u2016zr \u2212 z\u0304r\u20162. (69)\nTake expectation on both sides of the above equation and set pi = \u03b1i, we obtain:\nN\u2211 i=1 \u03b7i 2 E\u2016xr+1i \u2212 z\u0304 r\u20162 \u2264 N\u2211 i=1 2 \u03b1i\u03b7i E\u2016\u2207gi(zr)\u2212\u2207gi(yr\u22121i )\u2016 2\n+ N\u2211 i=1 4\u03b7iE\u2016zr \u2212 zr+1\u20162 + 2\u03b7iE\u2016zr \u2212 z\u0304r\u20162.\nCombining equations (68) and (69), eventually one can find \u03c33 > 0 such that\nE[Qr+1 \u2212 v\u0304] \u2264 \u03c33 ( E\u2016zr \u2212 z\u0304\u20162 + E\u2016zr+1 \u2212 zr\u20162 +\nN\u2211 i=1 E\u20161/N\u2207gi(zr)\u2212 1/N\u2207gi(yr\u22121i )\u2016 2\n) ,\nwhich completes the proof of Step 4. In summary, we have shown that Step 1 - 4 all hold true. Therefore we have shown that the NESTT-G converges Q-linearly. Q.E.D.\n5.5 Some Key Properties of NESTT-E\nTo facilitate the following derivation, in this section we collect some key properties of NESTT-E. First, for i = ir, using the optimality condition for xi update step (18) we have the following identity:\n1\nN \u2207gir(xr+1ir ) + \u03bb r ir + \u03b1ir\u03b7ir(x r+1 ir \u2212 zr+1) = 0. (70)\nCombined with the dual variable update step (19) we obtain\n1\nN \u2207gir(xr+1ir ) = \u2212\u03bb r+1 ir . (71)\nSecond, the optimality condition for the z-update is given by: zr+1 = proxh [ zr+1 \u2212\u2207z(L(xr, z, \u03bbr)\u2212 h(z)) ] (72)\n= proxh\n[ zr+1 \u2212\nN\u2211 i=1 \u03b7i ( zr+1 \u2212 xri \u2212 \u03bbri \u03b7i ) \u2212\u2207g0(zr+1) ] . (73)\n5.6 Proof of Theorem 3.1\nTo prove this result, we need a few lemmas. For notational simplicity, define new variables {x\u0302r+1i }, {\u03bb\u0302 r+1 i } by\nx\u0302r+1i := arg minxi Ui(xi, z r+1, \u03bbri ), \u03bb\u0302 r+1 i := \u03bb r i + \u03b1i\u03b7i\n( x\u0302r+1i \u2212 z r+1 ) , \u2200i. (74)\nThese variables are the virtual variables generated by updating all variables at iteration r+ 1. Also define:\nLr := L(xr, zr;\u03bbr), w := (x, z, \u03bb), \u03b2 := 1\u2211N i=1 \u03b7i , ci := L2i \u03b1i\u03b7iN2 \u2212 \u03b3i 2 + 1\u2212 \u03b1i \u03b1i Li N\nFirst, we need the following lemma to show that the size of the successive difference of the dual variables can be upper bounded by that of the primal variables. This is a simple consequence of (71); also see [R2, Lemma 2.1]. We include the proof for completeness.\nLemma 5.1. Suppose assumption A holds. Then for NESTT-E algorithm, the following are true:\n\u2016\u03bbr+1i \u2212 \u03bb r i \u20162 \u2264 L2i N2 \u2016xr+1i \u2212 x r i \u20162, \u2016\u03bb\u0302r+1i \u2212 \u03bb r i \u20162 \u2264 L2i N2 \u2016x\u0302r+1i \u2212 x r i \u20162, \u2200 i. (75a)\nProof. We only show the first inequality. The second one follows an analogous argument. To prove (75a), first note that the case for i 6= ir is trivial, as both sides of (75a) are zero. For the index\nir, we have a closed-form expression for \u03bb r ir\nfollowing (71). Notice that for any given i, the primal-dual pair (xi, \u03bbi) is always updated at the same iteration. Therefore, if for each i we choose the initial solutions in a way such that \u03bb0i = \u2212\u2207gi(x0i ), then we have\n1\nN \u2207gi(xr+1i ) = \u2212\u03bb r+1 i \u2200 i = 1, 2, \u00b7 \u00b7 \u00b7N. (76)\nCombining (76) with Assumption A-(a) yields the following:\n\u2016\u03bbr+1i \u2212 \u03bb r i \u2016 =\n1\nN \u2016\u2207gi(xr+1i )\u2212\u2207gi(x r i )\u2016 \u2264 Li N \u2016xr+1i \u2212 x r i \u2016.\nThe proof is complete. Q.E.D.\nSecond, we bound the successive difference of the potential function.\nLemma 5.2. Suppose Assumption A holds true. Then the following holds for NESTT-E\nE[Lr+1 \u2212 Lr|xr, zr] \u2264 \u2212\u03b3z 2 \u2016zr+1 \u2212 zr\u20162 + N\u2211 i=1 pici\u2016xri \u2212 x\u0302r+1i \u2016 2. (77)\nProof. First let us split Lr+1 \u2212 Lr in the following way:\nLr+1 \u2212 Lr = Lr+1 \u2212 L(xr+1, zr+1;\u03bbr) + L(xr+1, zr+1;\u03bbr)\u2212 Lr. (78)\nThe first two terms in (78) can be bounded by\nLr+1 \u2212 L(xr+1, zr+1;\u03bbr) = N\u2211 i=1 \u3008\u03bbr+1i \u2212 \u03bb r i , x r+1 i \u2212 z r+1\u3009\n(a) =\n1\n\u03b1ir\u03b7ir \u2016\u03bbr+1ir \u2212 \u03bb r ir\u2016\n2 (b) \u2264 L2ir\nN2\u03b1ir\u03b7ir \u2016xr+1ir \u2212 x r ir\u2016 2 (79)\nwhere in (a) we have used (19), and the fact that \u03bbr+1i \u2212 \u03bbri = 0 for all variable blocks except irth block; (b) is true because of Lemma 5.1.\nThe last two terms in (78) can be written in the following way:\nL({xr+1i }, z r+1;\u03bbr)\u2212 Lr\n= L(xr+1, zr+1;\u03bbr)\u2212 L(xr, zr+1;\u03bbr) + L(xr, zr+1;\u03bbr)\u2212 Lr. (80)\nThe first two terms in (80) characterizes the change of the Augmented Lagrangian before and after the update of x. Note that x updates do not directly optimize the augmented Lagrangian. Therefore the characterization of this step is a bit involved. We have the following:\nL(xr+1, zr+1;\u03bbr)\u2212 L(xr, zr+1;\u03bbr) (a)\n\u2264 N\u2211 i=1 (\u2329 \u2207iL(xr+1, zr+1;\u03bbr), xr+1i \u2212 x r i \u232a \u2212 \u03b3i 2 \u2016xr+1i \u2212 x r i \u20162 )\n(b) = \u2329 \u2207irL(xr+1, zr+1;\u03bbr), xr+1ir \u2212 x r ir \u232a \u2212 \u03b3ir\n2 \u2016xr+1ir \u2212 x r ir\u2016 2\n(c) = \u2329 \u03b7ir(1\u2212 \u03b1ir)(xr+1ir \u2212 z r+1), xr+1ir \u2212 x r ir \u232a \u2212 \u03b3ir\n2 \u2016xr+1ir \u2212 x r ir\u2016 2\n(d) = \u2329 1\u2212 \u03b1ir \u03b1ir (\u03bbr+1ir \u2212 \u03bb r ir), x r+1 ir \u2212 xrir \u232a \u2212 \u03b3ir 2 \u2016xr+1ir \u2212 x r ir\u2016 2 \u2264 1\u2212 \u03b1ir \u03b1ir ( 1 2Lir/N \u2016\u03bbr+1ir \u2212 \u03bb r ir\u2016 2 + Lir 2N \u2016xr+1ir \u2212 x r ir\u2016 2 ) \u2212 \u03b3ir 2 \u2016xr+1ir \u2212 x r ir\u2016 2 (e)\n\u2264 1\u2212 \u03b1ir \u03b1ir Lir N \u2016xr+1ir \u2212 x r ir\u2016 2 \u2212 \u03b3ir 2 \u2016xr+1ir \u2212 x r ir\u2016 2 (81)\nwhere\n\u2022 (a) is true because L(x, z, \u03bb) is strongly convex with respect to xi.\n\u2022 (b) is true because when i 6= ir, we have xr+1i = xri .\n\u2022 (c) is true because xr+1ir is optimal solution for the problem minUir(xir , z r+1, \u03bbrir) (satisfying (70)),\nand we have used the optimality of such xr+1ir .\n\u2022 (d) and (e) are due to Lemma 5.1.\nSimilarly, the last two terms in (80) can be bounded using equation (70) and the strong convexity of function L with respect to the variable z. Therefor We have:\nL(xr, zr+1, \u03bbr)\u2212 Lr \u2264 \u2212\u03b3z 2 \u2016zr+1 \u2212 zr\u20162. (82)\nCombining equations (79), (81) and (82), eventually we have:\nLr+1 \u2212 L(xr, zr+1, \u03bbr) \u2264 cir\u2016xrir \u2212 x r+1 ir \u20162 (83) Lr+1 \u2212 Lr \u2264 \u2212\u03b3z 2 \u2016zr+1 \u2212 zr\u20162 + cir\u2016xrir \u2212 x r+1 ir \u20162 (84)\nTaking expectation on both side of this inequality with respect to ir, we can conclude that:\nE[Lr+1 \u2212 Lr | zr, xr] \u2264 \u2212\u03b3z 2 \u2016zr+1 \u2212 zr\u20162 + N\u2211 i=1 pici\u2016xri \u2212 x\u0302r+1i \u2016 2 (85)\nwhere pi is the probability of picking ith block. The lemma is proved. Q.E.D.\nLemma 5.3. Suppose that Assumption A is satisfied, then Lr \u2265 f .\nProof. Using the definition of the augmented Lagrangian function we have:\nLr+1 = N\u2211 i=1 ( 1 N gi(x r+1 i ) + \u3008\u03bb r+1 i , x r+1 i \u2212 z r+1\u3009+ \u03b7i 2 \u2016xr+1i \u2212 z r+1\u20162 ) + g0(z r+1) + p(zr+1)\n(a) = N\u2211 i=1 ( 1 N gi(x r+1 i ) + 1 N \u3008\u2207gi(xr+1i ), z r+1 \u2212 xr+1i \u3009+ \u03b7i 2 \u2016xr+1i \u2212 z r+1\u20162 ) + g0(z r+1) + p(zr+1)\n(b) \u2265 N\u2211 i=1 1 N gi(z r+1) + ( \u03b7i 2 \u2212 Li 2N ) \u2016zr+1 \u2212 xr+1i \u2016 2 + g0(z r+1) + p(zr+1)\n(c) \u2265 N\u2211 i=1 1 N gi(z r+1) + g0(z r+1) + p(zr+1) \u2265 f (86)\nwhere (a) is true because of equation (71); (b) follows Assumption A-(b); (c) follows Assumption A-(d). The desired result is proven. Q.E.D.\nProof of Theorem 3.1. We first show that the algorithm converges to the set of stationary solutions, and then establish the convergence rate.\nStep 1. Convergence to Stationary Solutions. Combining the descent estimate in Lemma 5.2 as well as the lower bounded condition in Lemma 5.3, we can again apply the Supermartigale Convergence Theorem [4, Proposition 4.2] and conclude that\n\u2016xr+1i \u2212 x r i \u2016 \u2192 0, \u2016zr+1 \u2212 zr\u2016 \u2192 0,with probability 1. (87)\nFrom Lemma 5.1 we have that the constraint violation is satisfied\n\u2016\u03bbr+1 \u2212 \u03bbr\u2016 \u2192 0, \u2016xr+1i \u2212 z r\u2016 \u2192 0. (88)\nThe rest of the proof follows similar lines as in [14, Theorem 2.4]. Due to space limitations we omit the proof.\nStep 2. Convergence Rate. We first show that there exists a \u03c31(\u03b1) > 0 such that\n\u2016\u2207\u0303L(wr)\u20162 + N\u2211 i=1 L2i N2 \u2016xri \u2212 zr\u20162 \u2264 \u03c31(\u03b1)\n( \u2016zr \u2212 zr+1\u20162 +\nN\u2211 i=1 \u2016xri \u2212 x\u0302r+1i \u2016 2\n) . (89)\nUsing the definition of \u2016\u2207\u0303Lr(wr)\u2016 we have:\n\u2016\u2207\u0303Lr(wr)\u20162 = \u2016zr \u2212 proxh [zr \u2212\u2207z(Lr \u2212 h(zr))] \u20162\n+ N\u2211 i=1 \u2225\u2225\u2225\u2225 1N\u2207gi(xri ) + \u03bbri + \u03b7i(xri \u2212 zr) \u2225\u2225\u2225\u22252 . (90)\nFrom the optimality condition of the z update (73) we have:\nzr+1 = proxh\n[ zr+1 \u2212\nN\u2211 i=1 \u03b7i ( zr+1 \u2212 xri \u2212 \u03bbri \u03b7i ) \u2212\u2207g0(zr+1) ] .\nUsing this, the first term in equation (90) can be bounded as:\n\u2016zr \u2212 proxh [zr \u2212\u2207z(Lr \u2212 h(zr))]\u2016\n= \u2225\u2225\u2225\u2225\u2225zr \u2212 zr+1 + zr+1 \u2212 proxh [ zr \u2212 N\u2211 i=1 \u03b7i(z r \u2212 xri \u2212 \u03bbri \u03b7i )\u2212\u2207g0(zr) ]\u2225\u2225\u2225\u2225\u2225 \u2264 \u2016zr \u2212 zr+1\u2016+ \u2225\u2225\u2225\u2225\u2225proxh [ zr+1 \u2212 N\u2211 i=1 \u03b7i ( zr+1 \u2212 xri \u2212 \u03bbri \u03b7i ) \u2212\u2207g0(zr+1) ]\n\u2212 proxh\n[ zr \u2212\nN\u2211 i=1 \u03b7i(z r \u2212 xri \u2212 \u03bbri \u03b7i )\u2212\u2207g0(zr) ]\u2225\u2225\u2225\u2225\u2225 \u2264 2\u2016zr+1 \u2212 zr\u2016+\n( N\u2211 i=1 \u03b7i + L0 ) \u2016zr \u2212 zr+1\u2016, (91)\nwhere in the last inequality we have used the nonexpansiveness of the proximity operator. Similarly, the optimality condition of the xi subproblem is given by\n1\nN \u2207gi(x\u0302r+1i ) + \u03bb r i + \u03b1i\u03b7i(x\u0302 r+1 i \u2212 z r+1) = 0. (92)\nApplying this identity, the second term in equation (90) can be written as follows:\nN\u2211 i=1 \u2225\u2225\u2225\u2225 1N\u2207gi(xri ) + \u03bbri + \u03b7i(xri \u2212 zr) \u2225\u2225\u2225\u22252\n(a) = N\u2211 i=1 \u2225\u2225\u2225\u2225 1N\u2207gi(xri )\u2212 1N\u2207gi(x\u0302r+1i ) + \u03b7i(xri \u2212 zr)\u2212 \u03b1i\u03b7i(x\u0302r+1i \u2212 zr+1) \u2225\u2225\u2225\u22252\n= N\u2211 i=1 \u2225\u2225\u2225\u2225 1N\u2207gi(xri )\u2212 1N\u2207gi(x\u0302r+1i ) + \u03b7i(xri \u2212 x\u0302r+1i + x\u0302r+1i \u2212 zr+1 + zr+1 \u2212 zr)\u2212 \u03b1i\u03b7i(x\u0302r+1i \u2212 zr+1) \u2225\u2225\u2225\u22252\n(b) \u2264 4 N\u2211 i=1 [( L2i N2 + \u03b72i + (1\u2212 \u03b1i)2L2i N2\u03b12i ) \u2016x\u0302r+1i \u2212 x r i \u20162 + \u03b72i \u2016zr+1 \u2212 zr\u20162 ] , (93)\nwhere (a) holds because of equation (92); (b) holds because of Lemma 5.1. Finally, combining (91) and (93) leads to the following bound for proximal gradient\n\u2016\u2207\u0303Lr\u20162 \u2264 4 N\u2211 i=1 \u03b72i + ( 2 + L0 + N\u2211 i=1 \u03b7i )2 \u2016zr \u2212 zr+1\u20162 +\nN\u2211 i=1 4 ( L2i N2 + \u03b72i + (1\u2212 \u03b1i)2Li N2\u03b12i ) \u2016xri \u2212 x\u0302r+1i \u2016 2. (94)\nAlso note that:\nN\u2211 i=1 L2i N2 \u2016xri \u2212 zr\u20162 \u2264 N\u2211 i=1 3 L2i N2 [ \u2016xri \u2212 x\u0302r+1i \u2016 2 + \u2016x\u0302r+1i \u2212 z r+1\u20162 + \u2016zr+1 \u2212 zr\u20162 ] =\nN\u2211 i=1 3 L2i N2 [ \u2016xri \u2212 x\u0302r+1i \u2016 2 + 1 \u03b12i \u03b7 2 i \u2016\u03bb\u0302r+1i \u2212 \u03bb r i \u20162 + \u2016zr+1 \u2212 zr\u20162 ]\n\u2264 N\u2211 i=1 3 L2i N2 [ \u2016xri \u2212 x\u0302r+1i \u2016 2 + L2i \u03b12i \u03b7 2 iN 2 \u2016x\u0302r+1i \u2212 x r i \u20162 + \u2016zr+1 \u2212 zr\u20162 ] . (95)\nThe two inequalities (94) \u2013 (95) imply that:\n\u2016\u2207\u0303Lr\u20162 + N\u2211 i=1 L2i N2 \u2016xri \u2212 zr\u20162\n\u2264 ( N\u2211 i=1 4\u03b72i + (2 + N\u2211 i=1 \u03b7i + L0) 2 + 3 N\u2211 i=1 L2i N2 ) \u2016zr \u2212 zr+1\u20162\n+ N\u2211 i=1 ( 4 ( L2i N2 + \u03b72i + ( 1 \u03b1i \u2212 1)2 L 2 i N2 ) + 3 ( L4i \u03b1iN4\u03b72i + L2i N2 )) \u2016xri \u2212 x\u0302r+1i \u2016 2. (96)\nDefine the following quantities:\n\u03c3\u03021(\u03b1) = max i\n{ 4 ( L2i N2 + \u03b72i + ( 1 \u03b1i \u2212 1 )2 L2i N2 ) + 3 ( L4i \u03b1i\u03b72iN 4 + L2i N2 )}\n\u03c3\u03031 = N\u2211 i=1 4\u03b72i + (2 + N\u2211 i=1 \u03b7i + L0) 2 + 3 N\u2211 i=1 L2i N2 .\nSetting \u03c31(\u03b1) = max(\u03c3\u03021(\u03b1), \u03c3\u03031) > 0, we have\n\u2016\u2207\u0303Lr\u20162 + N\u2211 i=1 L2i N2 \u2016xri \u2212 zr\u20162 \u2264 \u03c31(\u03b1)\n( \u2016zr \u2212 zr+1\u20162 +\nN\u2211 i=1 \u2016xri \u2212 x\u0302r+1i \u2016 2\n) . (97)\nFrom Lemma 5.2 we know that\nE[Lr+1 \u2212 Lr|zr, xr] \u2264 \u2212\u03b3z 2 \u2016zr+1 \u2212 zr\u20162 + N\u2211 i=1 pici\u2016xri \u2212 x\u0302r+1i \u2016 2 (98)\nNote that \u03b3z = \u2211N i=1 \u03b7i \u2212 L0, then define \u03c3\u03022 and \u03c3\u03032 as\n\u03c3\u03022(\u03b1) = max i\n{ pi ( \u03b3i 2 \u2212 L 2 i \u03b1i\u03b7iN2 \u2212 1\u2212 \u03b1i \u03b1i Li N )} \u03c3\u03032 = \u2211N i=1 \u03b7i \u2212 L0\n2 .\nWe can set \u03c32(\u03b1) = max(\u03c3\u03022(\u03b1), \u03c3\u03032) to obtain\nE[Lr \u2212 Lr+1|xr, zr] \u2265 \u03c32(\u03b1) ( N\u2211 i=1 \u2016x\u0302r+1i \u2212 x r i \u20162 + \u2016zr+1 \u2212 zr\u20162 ) . (99)\nCombining (89) and (99) we have\nH(wr) = \u2016\u2207\u0303Lr\u20162 + N\u2211 i=1 L2i /N\u2016xri \u2212 zr\u20162 \u2264 \u03c31(\u03b1) \u03c32(\u03b1) E[Lr \u2212 Lr+1|F r].\nLet us set C(\u03b1) = \u03c31(\u03b1)\u03c32(\u03b1) and take expectation on both side of the above equation to obtain:\nE[H(wr)] \u2264 C(\u03b1)E[Lr \u2212 Lr+1]. (100)\nSumming both sides of the above inequality over r = 1, \u00b7 \u00b7 \u00b7 , R, we obtain: R\u2211 r=1 E[H(wr)] \u2264 C(\u03b1)E[L1 \u2212 LR+1]. (101)\nUsing the definition of wm = (xm, zm, \u03bbm), and following the same line of argument as Theorem (2.1) we eventually conclude that\nE[H(wm)] \u2264 C(\u03b1)E[L 1 \u2212 LR+1] R . (102)\nThe proof is complete. Q.E.D.\n5.7 Proof of Theorem 3.2\nFollowing similar line of proof as Theorem 2.2, we conclude that there exists some finite r\u0304 > 0 such that for all r > r\u0304 and v\u0304 \u2208 R such that\nf(z\u0304r) = v\u0304, \u2200 r \u2265 r\u0304 (103)\nwhere z\u0304r = arg minz\u2208Z\u2217 \u2016zr \u2212 z\u2016. Therefore, combining the fact that \u2016xr+1 \u2212 xr\u2016 \u2192 0, \u2016zr+1 \u2212 zr\u2016 \u2192 0, \u2016xr+1i \u2212 zr+1\u2016 \u2192 0 and \u2016\u03bbr+1 \u2212 \u03bbr\u2016 \u2192 0 [cf. (87), (88)], it is easy to see that\nL(z\u0304r, x\u0304r, \u03bb\u0304r) = f(z\u0304r) = v\u0304, \u2200 r \u2265 r\u0304 (104)\nwhere x\u0304r, \u03bb\u0304r are defined similarly as z\u0304r. In what follows we will show that \u2206 := Lr+1 \u2212 v\u0304 decreases Q-linearly. From the optimality condition for z subproblem (73), we know that:\nzr+1 = proxh\n[ zr+1 \u2212 ( N\u2211 i=1 \u2212\u03bbri \u2212 \u03b7i(zr+1 \u2212 xri ) ) \u2212\u2207g0(zr+1) ] . (105)\nTherefore, \u2016\u2207\u0303f(zr+1)\u2016 can be bounded in the following way:\n\u2016\u2207\u0303f(zr+1)\u2016 = \u2225\u2225\u2225\u2225proxh [ zr+1 \u2212 ( N\u2211 i=1 \u2212\u03bbri \u2212 \u03b7i(zr+1 \u2212 xri ) ) \u2212\u2207g0(zr+1) ]\n\u2212 proxh\n( zr+1 \u2212\nN\u2211 i=1 \u2207gi(zr+1)\u2212\u2207g0(zr+1) )\u2225\u2225\u2225\u2225 (a) \u2264\n\u2225\u2225\u2225\u2225\u2225\u2212 N\u2211 i=1 \u2207gi(zr+1) + ( N\u2211 i=1 \u2212\u03bbri \u2212 \u03b7i(zr+1 \u2212 xri ) )\u2225\u2225\u2225\u2225\u2225 (b) =\n\u2225\u2225\u2225\u2225\u2225 N\u2211 i=1 [ \u2212\u2207gi(zr+1) +\u2207gi(xri )\u2212 \u03b7i(zr+1 \u2212 xri ) ]\u2225\u2225\u2225\u2225\u2225 \u2264\nN\u2211 i=1 (Li/N + \u03b7i)\u2016zr+1 \u2212 xri \u2016\n\u2264 N\u2211 i=1 (Li/N + \u03b7i) ( \u2016zr+1 \u2212 x\u0302r+1i \u2016+ \u2016x\u0302 r+1 i \u2212 x r i \u2016 )\n= N\u2211 i=1 (Li/N + \u03b7i) ( 1 \u03b1i\u03b7i \u2016\u03bb\u0302r+1i \u2212 \u03bb r i \u2016+ \u2016x\u0302r+1i \u2212 x r i \u2016 )\n(c) \u2264 N\u2211 i=1 (Li/N + \u03b7i) ( Li N\u03b1i\u03b7i + 1 ) \u2016x\u0302r+1i \u2212 x r i \u2016 (106)\nwhere in (a) we have used the fact that poximity operator is nonexpansive, and in (b) we plugged in equation (76); in (c) we have used Lemma 5.1. Therefore, there exists C > 0 such that we can bound the\n\u2016\u2207\u0303f(zr+1)\u20162 as the following:\n\u2016\u2207\u0303f(zr+1)\u20162 \u2264 C ( \u2016zr+1 \u2212 zr\u20162 +\nN\u2211 i=1 \u2016x\u0302r+1i \u2212 x r i \u20162 ) . (107)\nIn what follows we bound L(zr+1, xr, \u03bbr)\u2212 v\u0304. Assume that r > r\u0304, therefore z\u0304r+1 = arg minz\u2208Z\u2217 \u2016zr+1\u2212 z\u2016 satisfies f(z\u0304) = v\u0304. We have the following\nL(zr+1, xr, \u03bbr)\u2212 v\u0304 = N\u2211 i=1 gi(x r i ) + g0(z r+1) + p(zr+1) + N\u2211 i=1 \u3008\u03bbri , xri \u2212 zr+1\u3009+ N\u2211 i=1 \u03b7i 2 \u2016xri \u2212 zr+1\u20162\n\u2212 N\u2211 i=1 gi(z\u0304 r+1)\u2212 p(z\u0304r+1)\u2212 g0(z\u0304r+1). (108)\nFrom the optimality condition of the z subproblem we know that:\np(zr+1) + g0(z r+1) + N\u2211 i=1 \u3008\u03bbri , xri \u2212 zr+1\u3009+ N\u2211 i=1 \u03b7i 2 \u2016xri \u2212 zr+1\u20162\n\u2264 p(z\u0304r+1) + g0(z\u0304r+1) + N\u2211 i=1 \u3008\u03bbri , xri \u2212 z\u0304r+1\u3009+ N\u2211 i=1 \u03b7i 2 \u2016xri \u2212 z\u0304r+1\u20162. (109)\nRearranging the terms in the previous equation we have:\np(zr+1) + g0(z r+1)\u2212 p(z\u0304r+1)\u2212 g0(z\u0304r+1)\n\u2264 N\u2211 i=1 [ \u3008\u03bbri , zr+1 \u2212 z\u0304r+1\u3009+ \u03b7i 2 \u2016xri \u2212 z\u0304r+1\u20162 \u2212 \u03b7i 2 \u2016xri \u2212 zr+1\u20162 ] . (110)\nPlugging in (110) in (108) yields the following:\nL(zr+1, xr, \u03bbr)\u2212 v\u0304 \u2264 N\u2211 i=1 [ 1 N (gi(x r i )\u2212 gi(z\u0304r+1)) + \u03b7i 2 \u2016xri \u2212 z\u0304r+1\u20162 + \u3008\u03bbri , xri \u2212 z\u0304r+1\u3009 ] (a) =\nN\u2211 i=1 [ 1 N \u3008\u2207gi(x\u0303i), xri \u2212 z\u0304r+1\u3009+ \u03b7i 2 \u2016xri \u2212 z\u0304r+1\u20162 + \u3008\u03bbri , xri \u2212 z\u0304r+1\u3009 ] (b) =\nN\u2211 i=1 [ 1 N \u3008\u2207gi(x\u0303i)\u2212\u2207gi(xri ), xri \u2212 z\u0304r+1\u3009+ \u03b7i 2 \u2016xri \u2212 z\u0304r+1\u20162 ] (c)\n\u2264 N\u2211 i=1 ( Li/N 2 + \u03b7i 2 ) \u2016xri \u2212 z\u0304r+1\u20162\n\u2264 N\u2211 i=1 3(Li/N + \u03b7i) [ \u2016xri \u2212 x\u0302r+1i \u2016 2 + \u2016x\u0302r+1i \u2212 z r+1\u20162 + \u2016zr+1 \u2212 z\u0304r+1\u20162 ] \u2264\nN\u2211 i=1 3(Li/N 2 + \u03b7i) [( 1 + L2i \u03b12i \u03b7 2 iN 2 ) \u2016xri \u2212 x\u0302r+1i \u2016 2 + \u2016zr+1 \u2212 z\u0304r+1\u20162 ] . (111)\nIn the above series of inequalities, (a) is the result of applying mean value theorem on function gi, where x\u0303i is a point lies in between the line segment (x r i , z\u0304\nr+1); In (b) we have used (76); (c) is true because of assumption A-(c) and the fact that \u2016x\u0303i \u2212 z\u0304\u2016 \u2264 \u2016xri \u2212 z\u0304r+1\u2016; the last inequality comes from Lemma 5.1.\nOverall, there exists \u03c32 > 0 such that\nL(zr+1, xr, \u03bbr)\u2212 v\u0304 \u2264 \u03c32 ( N\u2211 i=1 \u2016x\u0302r+1i \u2212 x r i \u20162 + \u2016zr+1 \u2212 z\u0304r+1\u20162 ) \u2200 r \u2265 r\u0304. (112)\nFrom Lemma 2.2, we know that\ndist (zr+1, Z\u2217) = \u2016zr+1 \u2212 z\u0304r+1\u2016 \u2264 \u03c4\u2016\u2207\u0303f(zr+1)\u2016. (113)\nAs a result we have: \u2206r+1 = Lr+1 \u2212 v\u0304 \u2264 L(zr+1, xr, \u03bbr)\u2212 v\u0304,\nwhere the inequality comes from the fact that Lr+1 \u2212 L(zr+1, xr, \u03bbr) \u2264 0 [by (83) and the fact that ci < 0 for all i]. Considering the above equations we obtain:\n\u2206r+1 \u2264 \u03c32 ( N\u2211 i=1 \u2016x\u0302r+1i \u2212 x r i \u20162 + \u2016zr+1 \u2212 z\u0304r+1\u20162 ) (113)\n\u2264 \u03c32 N\u2211 i=1 \u2016x\u0302r+1i \u2212 x r i \u20162 + \u03c32\u03c4\u2016\u2207\u0303f(zr+1)\u20162\n(107) \u2264 (\u03c32 + \u03c32\u03c4C) N\u2211 i=1 \u2016x\u0302r+1i \u2212 x r i \u20162 + \u03c32\u03c4C\u2016zr+1 \u2212 zr\u20162, \u2200 r \u2265 r\u0304 (114)\nFrom (99) and (114) we can further construct a \u03c33 > 0 such that E[\u2206r+1] \u2264 \u03c33E[Lr\u2212Lr+1], which further implies the following relationship:\nE[\u2206r+1] \u2264 \u03c33 1 + \u03c33 E[\u2206r], \u2200 r \u2265 r\u0304. (115)\nLet us set \u03c1 = \u03c331+\u03c33 < 1. Thus concluding the proof. Q.E.D.\n5.8 Proof of Proposition 4.1\nApplying the optimality condition on z subproblem in (34) we have:\nzr+1 = argmin z\nh(z) + g0(z) + \u03b2\n2 \u2016z \u2212 ur+1\u20162 (116)\nwhere the variable ur+1 is given by (cf. (31))\nur+1 = \u03b2 N\u2211 i=1 (\u03bbri + \u03b7ix r+1 i ). (117)\nNow from one of the key properties of NESTT-G [cf. Section 5.1, equation (30)], we have that\nur+1 = zr \u2212 \u03b2\n( 1\nN\u03b1ir\n( \u2207gir(zr)\u2212\u2207gir(yr\u22121ir ) ) + 1\nN N\u2211 i=1 \u2207gi(yr\u22121i )N\n) . (118)\nThis verifies the claim. Q.E.D.\nReferences\n[1] Z. A.-Zhu and E. Hazan. Variance reduction for faster non-convex optimization. 2016. Preprint, available on arXiv, arXiv:1603.05643.\n[2] A. Antoniadis, I. Gijbels, and M. Nikolova. Penalized likelihood regression for generalized linear models with non-quadratic penalties. Annals of the Institute of Statistical Mathematics, 63(3):585\u2013615, 2009.\n[3] D. Bertsekas. Incremental gradient, subgradient, and proximal methods f or convex optimization: A survey. 2000. LIDS Report 2848.\n[4] D. P. Bertsekas and J. N. Tsitsiklis. Parallel and Distributed Computation: Numerical Methods, 2nd ed. Athena Scientific, Belmont, MA, 1997.\n[5] E. Bjornson and E. Jorswieck. Optimal resource allocation in coordinated multi-cell systems. Foundations and Trends in Communications and Information Theory, 9, 2013.\n[6] D. Blatt, A. O. Hero, and H. Gauchman. A convergent incremental gradient method with a constant step size. SIAM Journal on Optimization, 18(1):29\u201351, 2007.\n[7] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in Machine Learning, 3(1):1\u2013122, 2011.\n[8] V. Cevher, S. Becker, and M. Schmidt. Convex optimization for big data: Scalable, randomized, and parallel algorithms for big data analytics. IEEE Signal Processing Magazine, 31(5):32\u201343, Sept 2014.\n[9] T.-H. Chang, M. Hong, and X. Wang. Multi-agent distributed optimization via inexact consensus admm. IEEE Transactions on Signal Processing, 63(2):482\u2013497, Jan 2015.\n[10] A. Defazio, F. Bach, and S. Lacoste-Julien. Saga: A fast incremental gradient method with support for non-strongly convex composite objectives. In The Proceeding of NIPS, 2014.\n[11] S. Ghadimi and G. Lan. Stochastic first- and zeroth-order methods for nonconvx stochastic programming. SIAM Journal on Optimizatnoi, 23(4):2341\u20132368, 2013.\n[12] D. Hajinezhad, T.-H. Chang, X. Wang, Q. Shi, and M. Hong. Nonnegative matrix factorization using admm: Algorithm analysis and convergence guarantees. In the Proceedings of ICASSP 2016, 2016.\n[13] D. Hajinezhad and M. Hong. Nonconvex alternating direction method of multipliers for distributed sparse principal component analysis. In the Proceedings of GlobalSIPT, 2015.\n[14] M. Hong, Z.-Q. Luo, and M. Razaviyayn. Convergence analysis of alternating direction method of multipliers for a family of nonconvex problems. SIAM Journal On Optimization, 26(1):337\u2013364, 2016.\n[15] R. Johnson and T. Zhang. Accelerating stochastic gradient descent using predictive variance reduction. In the Proceedings of the Neural Information Processing (NIPS). 2013.\n[16] H. Karimi and M. Schmidt. Linear convergence of proximal-gradient methods under the polyaklojasiewicz condition. In NIPS workshop on optimization, 2016.\n[17] G. Lan. An optimal randomized incremental gradient method. 2015. Preprint.\n[18] P.-L. Loh and M. Wainwright. High-dimensional regression with noisy and missing data: Provable guarantees with nonconvexity. The Annals of Statistics, 40(3):1637\u20131664, 2012.\n[19] P. D. Lorenzo and G. Scutari. Next: In-network nonconvex optimization. 2016. Preprint.\n[20] Z.-Q. Luo and P. Tseng. Error bounds and the convergence analysis of matrix splitting algorithms for the affine variational inequality problem. SIAM Journal on Optimization, pages 43\u201354, 1992.\n[21] Z.-Q. Luo and P. Tseng. On the linear convergence of descent methods for convex essentially smooth minimization. SIAM Journal on Control and Optimization, 30(2):408\u2013425, 1992.\n[22] S. N. Negahban, P. Ravikumar, M. J. Wainwright, and B. Yu. A unified framework for highdimensional analysis of m-estimators with decomposable regularizers. Statist. Sci., 27(4):538\u2013557, 11 2012.\n[23] Y. Nesterov. Introductory lectures on convex optimization: A basic course. Springer, 2004.\n[24] M. Razaviyayn, M. Hong, Z.-Q. Luo, and J. S. Pang. Parallel successive convex approximation for nonsmooth nonconvex optimization. In the Proceedings of NIPS, 2014.\n[25] S. J. Reddi, S. Sra, B. Poczos, and A. Smola. Fast incremental method for nonconvex optimization. 2016. Preprint, available on arXiv: arXiv:1603.06159.\n[26] M. Schmidt, N. L. Roux, and F. Bach. Minimizing finite sums with the stochastic average gradient. 2013. Technical report, INRIA.\n[27] S. Shalev-Shwartz and T. Zhang. Proximal stochastic dual coordinate ascent methods for regularzied loss minimization. Journal of Machine Learning Rsearch, 14:567\u2013599, 2013.\n[28] S. Sra. Scalable nonconvex inexact proximal splitting. In Advances in Neural Information Processing Systems (NIPS), 2012.\n[29] P. Tseng and S. Yun. A coordinate gradient descent method for nonsmooth separable minimization. Mathematical Programming, 117:387\u2013423, 2009.\n[30] Z. Wang, H. Liu, and T. Zhang. Optimal computational and statistical rates of convergence for sparse nonconvex learning problems. Annals of Statistics, 42(6):2164\u20132201, 2014.\n[31] S. Zlobec. On the Liu - Floudas convexification of smooth programs. Journal of Global Optimization, 32:401 \u2013 407, 2005."}], "references": [{"title": "Variance reduction for faster non-convex optimization. 2016", "author": ["Z.A.-Zhu", "E. Hazan"], "venue": "Preprint, available on arXiv,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Penalized likelihood regression for generalized linear models with non-quadratic penalties", "author": ["A. Antoniadis", "I. Gijbels", "M. Nikolova"], "venue": "Annals of the Institute of Statistical Mathematics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Incremental gradient, subgradient, and proximal methods f or convex optimization: A survey", "author": ["D. Bertsekas"], "venue": "LIDS Report", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2000}, {"title": "Parallel and Distributed Computation: Numerical Methods, 2nd ed", "author": ["D.P. Bertsekas", "J.N. Tsitsiklis"], "venue": "Athena Scientific,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1997}, {"title": "Optimal resource allocation in coordinated multi-cell systems", "author": ["E. Bjornson", "E. Jorswieck"], "venue": "Foundations and Trends in Communications and Information Theory,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "A convergent incremental gradient method with a constant step size", "author": ["D. Blatt", "A.O. Hero", "H. Gauchman"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Convex optimization for big data: Scalable, randomized, and parallel algorithms for big data analytics", "author": ["V. Cevher", "S. Becker", "M. Schmidt"], "venue": "IEEE Signal Processing Magazine,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Multi-agent distributed optimization via inexact consensus admm", "author": ["T.-H. Chang", "M. Hong", "X. Wang"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Saga: A fast incremental gradient method with support for non-strongly convex composite objectives", "author": ["A. Defazio", "F. Bach", "S. Lacoste-Julien"], "venue": "In The Proceeding of NIPS,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Stochastic first- and zeroth-order methods for nonconvx stochastic programming", "author": ["S. Ghadimi", "G. Lan"], "venue": "SIAM Journal on Optimizatnoi,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Nonnegative matrix factorization using admm: Algorithm analysis and convergence guarantees", "author": ["D. Hajinezhad", "T.-H. Chang", "X. Wang", "Q. Shi", "M. Hong"], "venue": "In the Proceedings of ICASSP", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Nonconvex alternating direction method of multipliers for distributed sparse principal component analysis", "author": ["D. Hajinezhad", "M. Hong"], "venue": "In the Proceedings of GlobalSIPT,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Convergence analysis of alternating direction method of multipliers for a family of nonconvex problems", "author": ["M. Hong", "Z.-Q. Luo", "M. Razaviyayn"], "venue": "SIAM Journal On Optimization,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["R. Johnson", "T. Zhang"], "venue": "In the Proceedings of the Neural Information Processing (NIPS)", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Linear convergence of proximal-gradient methods under the polyaklojasiewicz condition", "author": ["H. Karimi", "M. Schmidt"], "venue": "In NIPS workshop on optimization,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "An optimal randomized incremental gradient method", "author": ["G. Lan"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "High-dimensional regression with noisy and missing data: Provable guarantees with nonconvexity", "author": ["P.-L. Loh", "M. Wainwright"], "venue": "The Annals of Statistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Next: In-network nonconvex optimization. 2016", "author": ["P.D. Lorenzo", "G. Scutari"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Error bounds and the convergence analysis of matrix splitting algorithms for the affine variational inequality problem", "author": ["Z.-Q. Luo", "P. Tseng"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1992}, {"title": "On the linear convergence of descent methods for convex essentially smooth minimization", "author": ["Z.-Q. Luo", "P. Tseng"], "venue": "SIAM Journal on Control and Optimization,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1992}, {"title": "A unified framework for highdimensional analysis of m-estimators with decomposable regularizers", "author": ["S.N. Negahban", "P. Ravikumar", "M.J. Wainwright", "B. Yu"], "venue": "Statist. Sci., 27(4):538\u2013557,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "Introductory lectures on convex optimization: A basic course", "author": ["Y. Nesterov"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}, {"title": "Parallel successive convex approximation for nonsmooth nonconvex optimization", "author": ["M. Razaviyayn", "M. Hong", "Z.-Q. Luo", "J.S. Pang"], "venue": "In the Proceedings of NIPS,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Fast incremental method for nonconvex optimization. 2016", "author": ["S.J. Reddi", "S. Sra", "B. Poczos", "A. Smola"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "Minimizing finite sums with the stochastic average gradient", "author": ["M. Schmidt", "N.L. Roux", "F. Bach"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Proximal stochastic dual coordinate ascent methods for regularzied loss minimization", "author": ["S. Shalev-Shwartz", "T. Zhang"], "venue": "Journal of Machine Learning Rsearch,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "Scalable nonconvex inexact proximal splitting", "author": ["S. Sra"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "A coordinate gradient descent method for nonsmooth separable minimization", "author": ["P. Tseng", "S. Yun"], "venue": "Mathematical Programming,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2009}, {"title": "Optimal computational and statistical rates of convergence for sparse nonconvex learning problems", "author": ["Z. Wang", "H. Liu", "T. Zhang"], "venue": "Annals of Statistics,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2014}, {"title": "On the Liu - Floudas convexification of smooth programs", "author": ["S. Zlobec"], "venue": "Journal of Global Optimization,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2005}], "referenceMentions": [{"referenceID": 7, "context": "It arises frequently in applications such as machine learning and signal processing; see a recent survey [8].", "startOffset": 105, "endOffset": 108}, {"referenceID": 4, "context": "In particular, each smooth functions {gi}i=1 can represent: 1) a minibatch of loss functions modeling data fidelity, such as the `2 loss, the logistic loss, etc; 2) nonconvex activation functions for neural networks, such as the logit or the tanh functions; 3) nonconvex utility functions used in signal processing, machine learning, and resource allocation, see [5], and [12].", "startOffset": 363, "endOffset": 366}, {"referenceID": 11, "context": "In particular, each smooth functions {gi}i=1 can represent: 1) a minibatch of loss functions modeling data fidelity, such as the `2 loss, the logistic loss, etc; 2) nonconvex activation functions for neural networks, such as the logit or the tanh functions; 3) nonconvex utility functions used in signal processing, machine learning, and resource allocation, see [5], and [12].", "startOffset": 372, "endOffset": 376}, {"referenceID": 1, "context": "The smooth function g0 can represent smooth nonconvex regularizers such as the non-quadratic penalties [2], or the smooth part of the SCAD or MCP regularizers (which is a concave function) [30].", "startOffset": 103, "endOffset": 106}, {"referenceID": 29, "context": "The smooth function g0 can represent smooth nonconvex regularizers such as the non-quadratic penalties [2], or the smooth part of the SCAD or MCP regularizers (which is a concave function) [30].", "startOffset": 189, "endOffset": 193}, {"referenceID": 6, "context": "Such distributed computation model has been popular in large-scale machine learning and signal processing [7].", "startOffset": 106, "endOffset": 109}, {"referenceID": 16, "context": "Such model is also closely related to the (centralized) stochastic finite-sum optimization problem [17, 10, 15, 25, 1, 26], in which each time the iterate is updated based on the gradient information of a random component function.", "startOffset": 99, "endOffset": 122}, {"referenceID": 9, "context": "Such model is also closely related to the (centralized) stochastic finite-sum optimization problem [17, 10, 15, 25, 1, 26], in which each time the iterate is updated based on the gradient information of a random component function.", "startOffset": 99, "endOffset": 122}, {"referenceID": 14, "context": "Such model is also closely related to the (centralized) stochastic finite-sum optimization problem [17, 10, 15, 25, 1, 26], in which each time the iterate is updated based on the gradient information of a random component function.", "startOffset": 99, "endOffset": 122}, {"referenceID": 24, "context": "Such model is also closely related to the (centralized) stochastic finite-sum optimization problem [17, 10, 15, 25, 1, 26], in which each time the iterate is updated based on the gradient information of a random component function.", "startOffset": 99, "endOffset": 122}, {"referenceID": 0, "context": "Such model is also closely related to the (centralized) stochastic finite-sum optimization problem [17, 10, 15, 25, 1, 26], in which each time the iterate is updated based on the gradient information of a random component function.", "startOffset": 99, "endOffset": 122}, {"referenceID": 25, "context": "Such model is also closely related to the (centralized) stochastic finite-sum optimization problem [17, 10, 15, 25, 1, 26], in which each time the iterate is updated based on the gradient information of a random component function.", "startOffset": 99, "endOffset": 122}, {"referenceID": 6, "context": "Note that such splitting scheme has been popular in the convex setting [7], but not so when the problem becomes nonconvex.", "startOffset": 71, "endOffset": 74}, {"referenceID": 22, "context": "Compared with the classical gradient descent, which in the worst case requires O( \u2211N i=1 Li/ ) gradient evaluation to achieve -stationarity [23], our obtained rate can be up to O(N) times better in the case where the Li\u2019s are not equal.", "startOffset": 140, "endOffset": 144}, {"referenceID": 9, "context": "Our work also reveals a fundamental connection between primal-dual based algorithms and the primal only average-gradient based algorithm such as SAGA/SAG/IAG [10, 25, 26, 6].", "startOffset": 158, "endOffset": 173}, {"referenceID": 24, "context": "Our work also reveals a fundamental connection between primal-dual based algorithms and the primal only average-gradient based algorithm such as SAGA/SAG/IAG [10, 25, 26, 6].", "startOffset": 158, "endOffset": 173}, {"referenceID": 25, "context": "Our work also reveals a fundamental connection between primal-dual based algorithms and the primal only average-gradient based algorithm such as SAGA/SAG/IAG [10, 25, 26, 6].", "startOffset": 158, "endOffset": 173}, {"referenceID": 5, "context": "Our work also reveals a fundamental connection between primal-dual based algorithms and the primal only average-gradient based algorithm such as SAGA/SAG/IAG [10, 25, 26, 6].", "startOffset": 158, "endOffset": 173}, {"referenceID": 9, "context": "Popular algorithms include the SAG/SAGA [10, 26], the SDCA [27], the SVRG [15], the RPDG [17] and so on.", "startOffset": 40, "endOffset": 48}, {"referenceID": 25, "context": "Popular algorithms include the SAG/SAGA [10, 26], the SDCA [27], the SVRG [15], the RPDG [17] and so on.", "startOffset": 40, "endOffset": 48}, {"referenceID": 26, "context": "Popular algorithms include the SAG/SAGA [10, 26], the SDCA [27], the SVRG [15], the RPDG [17] and so on.", "startOffset": 59, "endOffset": 63}, {"referenceID": 14, "context": "Popular algorithms include the SAG/SAGA [10, 26], the SDCA [27], the SVRG [15], the RPDG [17] and so on.", "startOffset": 74, "endOffset": 78}, {"referenceID": 16, "context": "Popular algorithms include the SAG/SAGA [10, 26], the SDCA [27], the SVRG [15], the RPDG [17] and so on.", "startOffset": 89, "endOffset": 93}, {"referenceID": 27, "context": "When the problem becomes nonconvex, the well-known incremental based algorithm can be used [28, 3], but these methods generally lack convergence rate guarantees.", "startOffset": 91, "endOffset": 98}, {"referenceID": 2, "context": "When the problem becomes nonconvex, the well-known incremental based algorithm can be used [28, 3], but these methods generally lack convergence rate guarantees.", "startOffset": 91, "endOffset": 98}, {"referenceID": 10, "context": "The SGD based method has been studied in [11], with O(1/ 2) convergence rate.", "startOffset": 41, "endOffset": 45}, {"referenceID": 0, "context": "Recent works [1] and [25] develop algorithms based on SVRG and SAGA for a special case of (1) where the entire problem is smooth and unconstrained.", "startOffset": 13, "endOffset": 16}, {"referenceID": 24, "context": "Recent works [1] and [25] develop algorithms based on SVRG and SAGA for a special case of (1) where the entire problem is smooth and unconstrained.", "startOffset": 21, "endOffset": 25}, {"referenceID": 13, "context": "On the other hand, distributed stochastic algorithms for solving problem (1) in the nonconvex setting has been proposed in [14], [13], in which each time a randomly picked subset of agents update their local variables.", "startOffset": 123, "endOffset": 127}, {"referenceID": 12, "context": "On the other hand, distributed stochastic algorithms for solving problem (1) in the nonconvex setting has been proposed in [14], [13], in which each time a randomly picked subset of agents update their local variables.", "startOffset": 129, "endOffset": 133}, {"referenceID": 18, "context": "There has been some recent distributed algorithms designed for (1) [19], but again without global convergence rate guarantee.", "startOffset": 67, "endOffset": 71}, {"referenceID": 23, "context": "It can be checked that the pGRAD vanishes at the set of stationary solutions of (1) [24].", "startOffset": 84, "endOffset": 88}, {"referenceID": 6, "context": "We remark that NESTT-G is related to the popular ADMM method for convex optimization [7].", "startOffset": 85, "endOffset": 88}, {"referenceID": 17, "context": "In this section we show that the NESTT-G is capable of linear convergence for a family of nonconvex quadratic problems, which has important applications, for example in high-dimensional statistical learning [18].", "startOffset": 207, "endOffset": 211}, {"referenceID": 20, "context": "Our linear convergence result is based upon certain error bound condition around the stationary solutions set, which has been shown in [21] for smooth quadratic problems and has been extended to including `1 penalty in [29, Theorem 4].", "startOffset": 135, "endOffset": 139}, {"referenceID": 15, "context": "There has been some recent works showing linear convergence for nonconvex problems satisfying certain quadratic growth condition [16, 25, 1].", "startOffset": 129, "endOffset": 140}, {"referenceID": 24, "context": "There has been some recent works showing linear convergence for nonconvex problems satisfying certain quadratic growth condition [16, 25, 1].", "startOffset": 129, "endOffset": 140}, {"referenceID": 0, "context": "There has been some recent works showing linear convergence for nonconvex problems satisfying certain quadratic growth condition [16, 25, 1].", "startOffset": 129, "endOffset": 140}, {"referenceID": 15, "context": "However the problems considered in [16, 25, 1] are smooth unconstrained problems, and every stationary point is a global minimum, therefore they do no cover our nonconvex quadratic problems, whose stationary solutions are not global minimizers.", "startOffset": 35, "endOffset": 46}, {"referenceID": 24, "context": "However the problems considered in [16, 25, 1] are smooth unconstrained problems, and every stationary point is a global minimum, therefore they do no cover our nonconvex quadratic problems, whose stationary solutions are not global minimizers.", "startOffset": 35, "endOffset": 46}, {"referenceID": 0, "context": "However the problems considered in [16, 25, 1] are smooth unconstrained problems, and every stationary point is a global minimum, therefore they do no cover our nonconvex quadratic problems, whose stationary solutions are not global minimizers.", "startOffset": 35, "endOffset": 46}, {"referenceID": 28, "context": "To proceed, A sequence {x} is said to converge Q-linearly to some x\u0304 if lim supr \u2016x \u2212 x\u0304\u2016/\u2016x \u2212 x\u0304\u2016 \u2264 \u03c1, where \u03c1 \u2208 (0, 1) is some constant; cf [29] and references therein.", "startOffset": 142, "endOffset": 146}, {"referenceID": 13, "context": "(21) We define the optimality gap by adding to \u2016\u2207\u0303L(w)\u20162 the size of the constraint violation [14]: H(w) := \u2016\u2207\u0303L(w)\u2016 + N \u2211", "startOffset": 94, "endOffset": 98}, {"referenceID": 25, "context": "Then (23) takes the same form as the SAG presented in [26].", "startOffset": 54, "endOffset": 58}, {"referenceID": 5, "context": "Further, when the component functions gi\u2019s are picked cyclically in a Gauss-Seidel manner, the iteration (23) takes the same form as the IAG algorithm [6].", "startOffset": 151, "endOffset": 154}, {"referenceID": 9, "context": "Then (23) is the same as the SAGA algorithm [10], which is design for optimizing convex nonsmooth finite sum problems.", "startOffset": 44, "endOffset": 48}, {"referenceID": 24, "context": "Thirdly, we note that a recent paper [25] has shown that SAGA works for smooth and unconstrained nonconvex problem.", "startOffset": 37, "endOffset": 41}, {"referenceID": 24, "context": "Compared with GD, which achieves -stationarity using O( \u2211N i=1 Li/ ) gradient evaluations in the worse case (in the sense that \u2211N i=1 Li/N = L), the rate in [25] is O(N1/3) times better.", "startOffset": 157, "endOffset": 161}, {"referenceID": 24, "context": "However, the algorithm in [25] is different from NESTT-G in two aspects: 1) it does not generalize to the nonsmooth constrained problem (1); 2) it samples two component functions at each iteration, while NESTT-G only samples once.", "startOffset": 26, "endOffset": 30}, {"referenceID": 21, "context": "For example in LASSO problem the data matrix is often normalized by feature (or \u201ccolumn-normalized\u201d [22]), therefore the `2 norm of each row of the data matrix (which corresponds to the Lipschitz constant for each component function) can be dramatically different.", "startOffset": 100, "endOffset": 104}, {"referenceID": 17, "context": "Consider the high dimensional regression problem with noisy observation [18], where M observations are generated by y = X\u03bd + .", "startOffset": 72, "endOffset": 76}, {"referenceID": 17, "context": "To test the performance of the proposed algorithm, we generate the problem following similar setups as [18].", "startOffset": 103, "endOffset": 107}, {"referenceID": 24, "context": "We implement NESTT-G/E, the SGD, and the nonconvex SAGA proposed in [25] with stepsize \u03b2 = 1 3LmaxN (with Lmax := maxi Li).", "startOffset": 68, "endOffset": 72}, {"referenceID": 24, "context": "Note that the SAGA proposed in [25] only works for the unconstrained problems with uniform Li, therefore when applied to (24) it is not guaranteed to converge.", "startOffset": 31, "endOffset": 35}], "year": 2016, "abstractText": "We study a stochastic and distributed algorithm for nonconvex problems whose objective consists of a sum of N nonconvex Li/N -smooth functions, plus a nonsmooth regularizer. The proposed NonconvEx primal-dual SpliTTing (NESTT) algorithm splits the problem into N subproblems, and utilizes an augmented Lagrangian based primal-dual scheme to solve it in a distributed and stochastic manner. With a special non-uniform sampling, a version of NESTT achieves -stationary solution using O(( \u2211N i=1 \u221a Li/N) / ) gradient evaluations, which can be up to O(N) times better than the (proximal) gradient descent methods. It also achieves Q-linear convergence rate for nonconvex `1 penalized quadratic problems with polyhedral constraints. Further, we reveal a fundamental connection between primal-dual based methods and a few primal only methods such as IAG/SAG/SAGA.", "creator": "LaTeX with hyperref package"}}}