{"id": "1606.02421", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2016", "title": "Gossip Dual Averaging for Decentralized Optimization of Pairwise Functions", "abstract": "In decentralized networks (of sensors, networked objects, etc.), there is an important need for efficient algorithms to optimize a global cost function, for example, to learn a global model from the local data collected by each computing unit. In this paper, we address the problem of decentralized minimization of pairwise functions of data points, where these points are distributed over the nodes of a diagram that defines the communication topology of the network. This general problem is applied, among others, in the areas of ranking, distanced metric learning, and graphical inference. We propose new gossip algorithms based on dual averaging, aimed at solving such problems in both synchronous and asynchronous environments. The proposed framework is flexible enough to deal with limited and regulated variants of the optimization problem. Our theoretical analysis shows that the proposed algorithms maintain the convergence rate of centralized value formation into an additive term.", "histories": [["v1", "Wed, 8 Jun 2016 07:01:47 GMT  (607kb,D)", "http://arxiv.org/abs/1606.02421v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.DC cs.LG cs.SY", "authors": ["igor colin", "aur\u00e9lien bellet", "joseph salmon", "st\u00e9phan cl\u00e9men\u00e7on"], "accepted": true, "id": "1606.02421"}, "pdf": {"name": "1606.02421.pdf", "metadata": {"source": "META", "title": "Gossip Dual Averaging for Decentralized Optimization of  Pairwise Functions", "authors": ["Igor Colin", "Aur\u00e9lien Bellet"], "emails": ["IGOR.COLIN@TELECOM-PARISTECH.FR", "AURELIEN.BELLET@INRIA.FR", "JOSEPH.SALMON@TELECOM-PARISTECH.FR", "STEPHAN.CLEMENCON@TELECOM-PARISTECH.FR"], "sections": [{"heading": "1. Introduction", "text": "The increasing popularity of large-scale and fully decentralized computational architectures, fueled for instance by\nProceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s).\nthe advent of the \u201cInternet of Things\u201d, motivates the development of efficient optimization algorithms adapted to this setting. An important application is machine learning in wired and wireless networks of agents (sensors, connected objects, mobile phones, etc.), where the agents seek to minimize a global learning objective which depends of the data collected locally by each agent. In such networks, it is typically impossible to efficiently centralize data or to globally aggregate intermediate results: agents can only communicate with their immediate neighbors (e.g., agents within a small distance), often in a completely asynchronous fashion. Standard distributed optimization and machine learning algorithms (implemented for instance using MapReduce/Spark) require a coordinator node and/or to maintain synchrony, and are thus unsuitable for use in decentralized networks.\nIn contrast, gossip algorithms (Tsitsiklis, 1984; Boyd et al., 2006; Kempe et al., 2003; Shah, 2009) are tailored to this setting because they only rely on simple peer-to-peer communication: each agent only exchanges information with one neighbor at a time. Various gossip algorithms have been proposed to solve the flagship problem of decentralized optimization, namely to find a parameter vector \u03b8 which minimizes an average of convex functions (1/n) \u2211n i=1 f(\u03b8;xi), where the data xi is only known to agent i. The most popular algorithms are based on (sub)gradient descent (Johansson et al., 2010; Nedic\u0301 & Ozdaglar, 2009; Ram et al., 2010; Bianchi & Jakubowicz, 2013), ADMM (Wei & Ozdaglar, 2012; 2013; Iutzeler et al., 2013) or dual averaging (Duchi et al., 2012; Yuan et al., 2012; Lee et al., 2015; Tsianos et al., 2015), some of which can also accommodate constraints or regularization on \u03b8. The main idea underlying these methods is that each agent seeks to minimize its local function by applying local updates (e.g., gradient steps) while exchanging inforar X iv :1\n60 6.\n02 42\n1v 1\n[ st\nat .M\nL ]\n8 J\nmation with neighbors to ensure a global convergence to the consensus value.\nIn this paper, we tackle the problem of minimizing an average of pairwise functions of the agents\u2019 data:\nmin \u03b8\n1\nn2 \u2211 1\u2264i,j\u2264n f(\u03b8;xi, xj). (1)\nThis problem finds numerous applications in statistics and machine learning, e.g., Area Under the ROC Curve (AUC) maximization (Zhao et al., 2011), distance/similarity learning (Bellet et al., 2015), ranking (Cle\u0301menc\u0327on et al., 2008), supervised graph inference (Biau & Bleakley, 2006) and multiple kernel learning (Kumar et al., 2012), to name a few. As a motivating example, consider a mobile phone application which locally collects information about its users. The provider could be interested in learning pairwise similarity functions between users in order to group them into clusters or to recommend them content without having to centralize data on a server (which would be costly for the users\u2019 bandwidth) or to synchronize phones.\nThe main difficulty in Problem (1) comes from the fact that each term of the sum depends on two agents i and j, making the local update schemes of previous approaches impossible to apply unless data is exchanged between nodes. Although gossip algorithms have recently been introduced to evaluate such pairwise functions for a fixed \u03b8 (Pelckmans & Suykens, 2009; Colin et al., 2015), to the best of our knowledge, efficiently finding the optimal solution \u03b8 in a decentralized way remains an open challenge. Our contributions towards this objective are as follows. We propose new gossip algorithms based on dual averaging (Nesterov, 2009; Xiao, 2010) to efficiently solve Problem (1) and its constrained or regularized variants. Central to our methods is a light data propagation scheme which allows the nodes to compute biased estimates of the gradients of functions in (1). We then propose a theoretical analysis of our algorithms both in synchronous and asynchronous settings establishing their convergence under an additional hypothesis that the bias term decreases fast enough over the iterations (and we have observed such a fast decrease in all our experiments). Finally, we present some numerical simulations on Area Under the ROC Curve (AUC) maximization and metric learning problems. These experiments illustrate the practical performance of the proposed algorithms and the influence of network topology, and show that in practice the influence of the bias term is negligible as it decreases very fast with the number of iterations.\nThe paper is organized as follows. Section 2 formally introduces the problem of interest and briefly reviews the dual averaging method, which is at the root of our approach. Section 3 presents the proposed gossip algorithms and their convergence analysis. Section 4 displays our numerical\nsimulations. Finally, concluding remarks are collected in Section 5."}, {"heading": "2. Preliminaries", "text": ""}, {"heading": "2.1. Definitions and Notation", "text": "For any integer p > 0, we denote by [p] the set {1, . . . , p} and by |F | the cardinality of any finite set F . We denote an undirected graph by G = (V,E), where V = [n] is the set of vertices and E \u2286 V \u00d7 V is the set of edges. A node i \u2208 V has degree di = |{j : (i, j) \u2208 E}|. G is connected if for all (i, j) \u2208 V 2 there exists a path connecting i and j; it is bipartite if there exist S, T \u2282 V such that S \u222a T = V , S\u2229T = \u2205 andE \u2286 (S\u00d7T )\u222a(T\u00d7S). The graph Laplacian of G is denoted by L(G) = D(G)\u2212A(G), whereD(G) and A(G) are respectively the degree and the adjacency matrices of G.\nThe transpose of a matrix M \u2208 Rn\u00d7n is denoted by M>. A matrix P \u2208 Rn\u00d7n is termed stochastic whenever P \u2265 0 and P1n = 1n, where 1n = (1, . . . , 1)> \u2208 Rn, and bistochastic whenever both P and P> are stochastic. We denote by In the identity matrix in Rn\u00d7n, by (e1, . . . , en) the canonical basis of Rn, by I{E} the indicator function of any event E and by \u2016 \u00b7 \u2016 the usual `2-norm. For \u03b8 \u2208 Rd and g : Rd \u2192 R, we denote by \u2207g(\u03b8) the gradient of g at \u03b8. Finally, given a collection of vectors u1, . . . , un, we denote by u\u0304n = (1/n) \u2211n i=1 ui its empirical mean."}, {"heading": "2.2. Problem Statement", "text": "We represent a network of n agents as an undirected graph G = ([n], E), where each node i \u2208 [n] corresponds to an agent and (i, j) \u2208 E if nodes i and j can exchange information directly (i.e., they are neighbors). For ease of exposition, we assume that each node i \u2208 [n] holds a single data point xi \u2208 X . Though restrictive in practice, this assumption can easily be relaxed, but it would lead to more technical details to handle the storage size, without changing the overall analysis (see supplementary material for details).\nGiven d > 0, let f : Rd \u00d7 X \u00d7 X \u2192 R a differentiable and convex function with respect to the first variable. We assume that for any (x, x\u2032) \u2208 X 2, there exists Lf > 0 such that f(\u00b7;x, x\u2032) is Lf -Lipschitz (with respect to the `2-norm). Let \u03c8 : Rd \u2192 R+ be a non-negative, convex, possibly non-smooth, function such that, for simplicity, \u03c8(0) = 0. We aim at solving the following optimization problem:\nmin \u03b8\u2208Rd\n1\nn2 \u2211 1\u2264i,j\u2264n f(\u03b8;xi, xj) + \u03c8(\u03b8). (2)\nIn a typical machine learning scenario, Problem (2) is a (regularized) empirical risk minimization problem and \u03b8\nAlgorithm 1 Stochastic dual averaging in the centralized setting Require: Step size (\u03b3(t))t\u22650 > 0. 1: Initialization: \u03b8 = 0, \u03b8\u0304 = 0, z = 0. 2: for t = 1, . . . , T do 3: Update z \u2190 z + g(t), where E[g(t)|\u03b8] = \u2207f\u0304n(\u03b8) 4: Update \u03b8 \u2190 \u03c0t(z) 5: Update \u03b8\u0304 \u2190 ( 1\u2212 1\nt\n) \u03b8\u0304 + 1\nt \u03b8\n6: end for 7: return \u03b8\u0304\ncorresponds to the model parameters to be learned. The quantity f(\u03b8;xi, xj) is a pairwise loss measuring the performance of the model \u03b8 on the data pair (xi, xj), while \u03c8(\u03b8) represents a regularization term penalizing the complexity of \u03b8. Common examples of regularization terms include indicator functions of a closed convex set to model explicit convex constraints, or norms enforcing specific properties such as sparsity (a canonical example being the `1-norm).\nMany machine learning problems can be cast as Problem (2). For instance, in AUC maximization (Zhao et al., 2011), binary labels (`1, . . . , `n) \u2208 {\u22121, 1}n are assigned to the data points and we want to learn a (linear) scoring rule x 7\u2192 x>\u03b8 which hopefully gives larger scores to positive data points than to negative ones. One may use the logistic loss\nf(\u03b8;xi, xj) = I{`i>`j} log ( 1 + exp((xj \u2212 xi)>\u03b8) ) ,\nand the regularization term \u03c8(\u03b8) can be the square `2-norm of \u03b8 (or the `1-norm when a sparse model is desired). Other popular instances of Problem (2) include metric learning (Bellet et al., 2015), ranking (Cle\u0301menc\u0327on et al., 2008), supervised graph inference (Biau & Bleakley, 2006) and multiple kernel learning (Kumar et al., 2012).\nFor notational convenience, we denote by fi the partial function (1/n) \u2211n j=1 f(\u00b7;xi, xj) for i \u2208 [n] and by f\u0304n =\n(1/n) \u2211n i=1 fi. Problem (2) can then be recast as:\nmin \u03b8\u2208Rd\nRn(\u03b8) = f\u0304 n(\u03b8) + \u03c8(\u03b8). (3)\nNote that the function f\u0304n is Lf -Lipschitz, since all the fi are Lf -Lipschitz.\nRemark 1. Throughout the paper we assume that the function f is differentiable, but we expect all our results to hold even when f is non-smooth, for instance in L1-regression problems or when using the hinge loss. In this case, one simply needs to replace gradients by subgradients in our algorithms, and a similar analysis could be performed."}, {"heading": "2.3. Centralized Dual Averaging", "text": "In this section, we review the stochastic dual averaging optimization algorithm (Nesterov, 2009; Xiao, 2010) to solve\nProblem (2) in the centralized setting (where all data lie on the same machine). This method is at the root of our gossip algorithms, for reasons that will be made clear in Section 3. To explain the main idea behind dual averaging, let us first consider the iterations of Stochastic Gradient Descent (SGD), assuming \u03c8 \u2261 0 for simplicity:\n\u03b8(t+ 1) = \u03b8(t)\u2212 \u03b3(t)g(t),\nwhere E[g(t)|\u03b8(t)] = \u2207f\u0304n(\u03b8(t)), and (\u03b3(t))t\u22650 is a nonnegative non-increasing step size sequence. For SGD to converge to an optimal solution, the step size sequence must satisfy \u03b3(t) \u2212\u2192\nt\u2192+\u221e 0 and\n\u2211\u221e t=0 \u03b3(t) = \u221e. As no-\nticed by Nesterov (2009), an undesirable consequence is that new gradient estimates are given smaller weights than old ones. Dual averaging aims at integrating all gradient estimates with the same weight.\nLet (\u03b3(t))t\u22650 be a positive and non-increasing step size sequence. The dual averaging algorithm maintains a sequence of iterates (\u03b8(t))t>0, and a sequence (z(t))t\u22650 of \u201cdual\u201d variables which collects the sum of the unbiased gradient estimates seen up to time t. We initialize to \u03b8(1) = z(0) = 0. At each step t > 0, we compute an unbiased estimate g(t) of \u2207f\u0304n(\u03b8(t)). The most common choice is to take g(t) = \u2207f(\u03b8;xit , xjt) where it and jt are drawn uniformly at random from [n]. We then set z(t + 1) = z(t) + g(t) and generate the next iterate with the following rule: \u03b8(t+ 1) = \u03c0\u03c8t (z(t+ 1)),\n\u03c0\u03c8t (z) := arg min \u03b8\u2208Rd\n{ \u2212z>\u03b8 + \u2016\u03b8\u2016 2\n2\u03b3(t) + t\u03c8(\u03b8)\n} .\nWhen it is clear from the context, we will drop the dependence in \u03c8 and simply write \u03c0t(z) = \u03c0 \u03c8 t (z). Remark 2. Note that \u03c0t(\u00b7) is related to the proximal operator of a function \u03c6 : Rd \u2192 R defined by prox\u03c6(x) = arg minz\u2208Rd ( \u2016z \u2212 x\u20162/2 + \u03c6(x) ) . Indeed, one can write:\n\u03c0t(z) = proxt\u03b3(t)\u03c8 (\u03b3(t)z) .\nFor many functions \u03c8 of practical interest, \u03c0t(\u00b7) has a closed form solution. For instance, when \u03c8 = \u2016 \u00b7 \u20162, \u03c0t(\u00b7) corresponds to a simple scaling, and when \u03c8 = \u2016 \u00b7 \u20161 it is a soft-thresholding operator. If \u03c8 is the indicator function of a closed convex set C, then \u03c0t(\u00b7) is the projection operator onto C.\nThe dual averaging method is summarized in Algorithm 1. If \u03b3(t) \u221d 1/ \u221a t then for any T > 0:\nET [ Rn(\u03b8\u0304(T ))\u2212Rn(\u03b8\u2217) ] = O(1/ \u221a T ),\nwhere \u03b8\u2217 \u2208 arg min\u03b8\u2208Rd Rn(\u03b8), \u03b8\u0304(T ) = 1T \u2211T i=1 \u03b8(t) is the averaged iterate and ET is the expectation over all possible sequences (g(t))1\u2264t\u2264T . A precise statement of this\nresult along with a proof can be found in the supplementary material for completeness.\nNotice that dual averaging cannot be easily adapted to our decentralized setting. Indeed, a node cannot compute an unbiased estimate of its gradient: this would imply an access to the entire set of data points, which violates the communication and storage constraints. Therefore, data points have to be appropriately propagated during the optimization procedure, as detailed in the following section."}, {"heading": "3. Pairwise Gossip Dual Averaging", "text": "We now turn to our main goal, namely to develop efficient gossip algorithms for solving Problem (2) in the decentralized setting. The methods we propose rely on dual averaging (see Section 2.3). This choice is guided by the fact that the structure of the updates makes dual averaging much easier to analyze in the distributed setting than sub-gradient descent when the problem is constrained or regularized. This is because dual averaging maintains a simple sum of sub-gradients, while the (non-linear) smoothing operator \u03c0t is applied separately.\nOur work builds upon the analysis of Duchi et al. (2012), who proposed a distributed dual averaging algorithm to optimize an average of univariate functions f(\u00b7;xi). In their algorithm, each node i computes unbiased estimates of its local function \u2207f(\u00b7;xi) that are iteratively averaged over the network. Unfortunately, in our setting, the node i cannot compute unbiased estimates of \u2207fi(\u00b7) = \u2207(1/n) \u2211n j=1 f(\u00b7;xi, xj): the latter depends on all data points while each node i \u2208 [n] only holds xi. To go around this problem, we rely on a gossip data propagation step (Pelckmans & Suykens, 2009; Colin et al., 2015) so that the nodes are able to compute biased estimates of \u2207fi(\u00b7) while keeping the communication and memory overhead to a small level for each node.\nWe present and analyze our algorithm in the synchronous setting in Section 3.1. We then turn to the more intricate analysis of the asynchronous setting in Section 3.2."}, {"heading": "3.1. Synchronous Setting", "text": "In the synchronous setting, we assume that each node has access to a global clock such that every node can update simultaneously at each tick of the clock. Although not very realistic, this setting allows for simpler analysis. We assume that the scaling sequence (\u03b3(t))t\u22650 is the same for every node. At any time, each node i has the following quantities in its local memory register: a variable zi (the gradient accumulator), its original observation xi, and an auxiliary observation yi, which is initialized at xi but will change throughout the algorithm as a result of data propagation.\nAlgorithm 2 Gossip dual averaging for pairwise function in synchronous setting Require: Step size (\u03b3(t))t\u22651 > 0. 1: Each node i initializes yi = xi, zi = \u03b8i = \u03b8\u0304i = 0. 2: for t = 1, . . . , T do 3: Draw (i, j) uniformly at random from E 4: Set zi, zj \u2190 zi+zj2 5: Swap auxiliary observations: yi \u2194 yj 6: for k = 1, . . . , n do 7: Update zk \u2190 zk +\u2207\u03b8f(\u03b8k;xk, yk) 8: Compute \u03b8k \u2190 \u03c0t(zk) 9: Average \u03b8\u0304k \u2190 ( 1\u2212 1\nt\n) \u03b8\u0304k +\n1 t \u03b8k\n10: end for 11: end for 12: return Each node k has \u03b8\u0304k\nThe algorithm goes as follows. At each iteration, an edge (i, j) \u2208 E of the graph is drawn uniformly at random. Then, nodes i and j average their gradient accumulators zi and zj , and swap their auxiliary observations yi and yj . Finally, every node of the network performs a dual averaging step, using their original observation and their current auxiliary one to estimate the partial gradient. The procedure is detailed in Algorithm 2, and the following proposition adapts the convergence rate of centralized dual averaging under the hypothesis that the contribution of the bias term decreases fast enough over the iterations.\nTheorem 1. Let G be a connected and non-bipartite graph with n nodes, and let \u03b8\u2217 \u2208 arg min\u03b8\u2208Rd Rn(\u03b8). Let (\u03b3(t))t\u22651 be a non-increasing and non-negative sequence. For any i \u2208 [n] and any t \u2265 0, let zi(t) \u2208 Rd and \u03b8\u0304i(t) \u2208 Rd be generated according to Algorithm 2. Then for any i \u2208 [n] and T > 1, we have:\nET [Rn(\u03b8\u0304i)\u2212Rn(\u03b8\u2217)] \u2264 C1(T ) + C2(T ) + C3(T ),\nwhere  C1(T ) = 1 2T\u03b3(T ) \u2016\u03b8\u2217\u20162 + L2f 2T T\u22121\u2211 t=1 \u03b3(t), C2(T ) = 3L2f T ( 1\u2212 \u221a \u03bbG2 ) T\u22121\u2211 t=1 \u03b3(t), C3(T ) = 1\nT T\u22121\u2211 t=1 Et[(\u03c9(t)\u2212 \u03b8\u2217)>\u0304n(t)],\nand \u03bbG2 < 1 is the second largest eigenvalue of the matrix W (G) = In \u2212 1|E|L(G).\nSketch of proof. First notice that at a given (outer) iteration t+ 1, z\u0304n is updated as follows:\nz\u0304n(t+ 1) = z\u0304n(t) + 1\nn n\u2211 k=1 dk(t), (4)\nwhere dk(t) = \u2207\u03b8f(\u03b8k(t);xk, yk(t + 1)) is a biased estimate of\u2207fk(\u03b8k(t)). Let k(t) = dk(t)\u2212 gk(t) be the bias, so that we have E[gk(t)|\u03b8k(t)] = \u2207fk(\u03b8k(t)).\nLet us define \u03c9(t) = \u03c0t(z\u0304n(t)). Using convexity of Rn, the gradient\u2019s definition and the fact that the functions f\u0304n and \u03c0t are both Lf -Lipschitz, we obtain: for T \u2265 2 and i \u2208 [n],\nET [Rn(\u03b8\u0304i(T ))\u2212Rn(\u03b8\u2217)]\n\u2264 Lf nT T\u2211 t=2 \u03b3(t\u2212 1) n\u2211 j=1 Et [ \u2016zi(t)\u2212 zj(t)\u2016 ] (5)\n+ Lf nT T\u2211 t=2 \u03b3(t\u2212 1) n\u2211 j=1 Et [ \u2016z\u0304n(t)\u2212 zj(t)\u2016 ] (6)\n+ 1\nT T\u2211 t=2 Et[(\u03c9(t)\u2212 \u03b8\u2217)>g\u0304n(t)]. (7)\nUsing Lemma 4 (see supplementary material), the terms (5)-(6) can be bounded by C2(T ). The term (7) requires a specific analysis because the updates are performed using biased estimates. We decompose it as follows:\n1\nT T\u2211 t=2 Et [ \u03c9(t)\u2212 \u03b8\u2217)>g\u0304n(t) ] = 1\nT T\u2211 t=2 Et [ (\u03c9(t)\u2212 \u03b8\u2217)>(d\u0304n(t)\u2212 \u0304n(t)) ] \u2264 1\nT T\u2211 t=2 Et [ (\u03c9(t)\u2212 \u03b8\u2217)>d\u0304n(t) ] (8)\n+ 1\nT T\u2211 t=2 Et [ (\u03c9(t)\u2212 \u03b8\u2217)>\u0304n(t) ] .\nThe term (8) can be bounded by C1(T ) (see Xiao, 2010, Lemma 9). We refer the reader to the supplementary material for the detailed proof.\nThe rate of convergence in Proposition 1 is divided into three parts: C1(T ) is a data dependent term which corresponds to the rate of convergence of the centralized dual averaging, while C2(T ) and C3(T ) are network dependent terms since 1 \u2212 \u03bbG2 = \u03b2Gn\u22121/|E|, where \u03b2Gn\u22121 is the second smallest eigenvalue of the graph Laplacian L(G), also known as the spectral gap of G. The convergence rate of our algorithm thus improves when the spectral gap is large, which is typically the case for well-connected graphs (Chung, 1997). Note that C2(T ) corresponds to the network dependence for the distributed dual averaging algorithm of Duchi et al. (2012) while the term C3(T ) comes from the bias of our partial gradient estimates. In practice, C3(T ) vanishes quickly and has a small impact on the rate of convergence, as shown in Section 4.\nAlgorithm 3 Gossip dual averaging for pairwise function in asynchronous setting Require: Step size (\u03b3(t))t\u22650 > 0, probabilities (pk)k\u2208[n]. 1: Each node i initializes yi = xi, zi = \u03b8i = \u03b8\u0304i = 0, mi = 0. 2: for t = 1, . . . , T do 3: Draw (i, j) uniformly at random from E 4: Swap auxiliary observations: yi \u2194 yj 5: for k \u2208 {i, j} do 6: Set zk \u2190 zi+zj2 7: Update zk \u2190 1pk\u2207\u03b8f(\u03b8k;xk, yk) 8: Increment mk \u2190 mk + 1pk 9: Compute \u03b8k \u2190 \u03c0mk (zk)\n10: Average \u03b8\u0304k \u2190 (\n1\u2212 1 mkpk\n) \u03b8\u0304k\n11: end for 12: end for 13: return Each node k has \u03b8\u0304k"}, {"heading": "3.2. Asynchronous Setting", "text": "For any variant of gradient descent over a network with a decreasing step size, there is a need for a common time scale to perform the suitable decrease. In the synchronous setting, this time scale information can be shared easily among nodes by assuming the availability of a global clock. This is convenient for theoretical considerations, but is unrealistic in practical (asynchronous) scenarios. In this section, we place ourselves in a fully asynchronous setting where each node has a local clock, ticking at a Poisson rate of 1, independently from the others. This is equivalent to a global clock ticking at a rate n Poisson process which wakes up an edge of the network uniformly at random (see Boyd et al., 2006, for details on clock modeling).\nWith this in mind, Algorithm 2 needs to be adapted to this setting. First, one cannot perform a full dual averaging update over the network since only two nodes wake up at each iteration. Also, as mentioned earlier, each node needs to maintain an estimate of the current iteration number in order for the scaling factor \u03b3 to be consistent across the network. For k \u2208 [n], let pk denote the probability for the node k to be picked at any iteration. If the edges are picked uniformly at random, then one has pk = 2dk/|E|. For simplicity, we focus only on this case, although our analysis holds in a more general setting.\nLet us define an activation variable (\u03b4k(t))t\u22651 such that for any t \u2265 1,\n\u03b4k(t) = { 1 if node k is picked at iteration t, 0 otherwise.\nOne can immediately see that (\u03b4k(t))t\u22651 are i.i.d. random variables, Bernoulli distributed with parameter pk. Let us define (mk(t)) \u2265 0 such that mk(0) = 0 and for t \u2265 0, mk(t + 1) = mk(t) +\n\u03b4k(t+1) pk . Since (\u03b4k(t))t\u22651 are\nBernoulli random variables, mk(t) is an unbiased estimate of the time t.\nUsing this estimator, we can now adapt Algorithm 2 to the fully asynchronous case, as shown in Algorithm 3. The update step slightly differs from the synchronous case: the partial gradient has a weight 1/pk instead of 1 so that all partial functions asymptotically count in equal way in every gradient accumulator. In contrast, uniform weights would penalize partial gradients from low degree nodes since the probability of being drawn is proportional to the degree. This weighting scheme is essential to ensure the convergence to the global solution. The model averaging step also needs to be altered: in absence of any global clock, the weight 1/t cannot be used and is replaced by 1/(mkpk), where mkpk corresponds to the average number of times that node k has been selected so far.\nThe following result is the analogous of Theorem 1 for the asynchronous setting.\nTheorem 2. Let G be a connected and non bipartite graph. Let (\u03b3(t))t\u22651 be defined as \u03b3(t) = c/t1/2+\u03b1 for some constant c > 0 and \u03b1 \u2208 (0, 1/2). For i \u2208 [n], let (di(t))t\u22651, (gi(t))t\u22651, ( i(t))t\u22651, (zi(t))t\u22651 and (\u03b8i(t))t\u22651 be generated as described in Algorithm 3. Then, there exists some constant C < +\u221e such that, for \u03b8\u2217 \u2208 arg min\u03b8\u2032\u2208Rd Rn(\u03b8 \u2032), i \u2208 [n] and T > 0,\nRn(\u03b8\u0304i(T ))\u2212Rn(\u03b8\u2217) \u2264C max(T\u2212\u03b1/2, T\u03b1\u22121/2)\n+ 1\nT T\u2211 t=2 Et[(\u03c9(t)\u2212 \u03b8\u2217)> n(t)].\nThe proof is given in the supplementary material.\nRemark 3. In the asynchronous setting, no convergence rate was known even for the distributed dual averaging algorithm of Duchi et al. (2012), which deals with the simpler problem of minimizing univariate functions. The arguments used to derive Theorem 2 can be adapted to derive a convergence rate (without the bias term) for an asynchronous version of their algorithm.\nRemark 4. We have focused on the setting where all pairs of observations are involved in the objective. In practice, the objective may depend only on a subset of all pairs. To efficiently apply our algorithm to this case, one should take advantage of the potential structure of the subset of interest: for instance, one could attach some additional concise information to each observation so that a node can easily identify whether a pair contributes to the objective, and if not set the loss to be zero. This is essentially the case in the AUC optimization problem studied in Section 4, where pairs of similarly labeled observations do not contribute to the objective. If the subset of pairs cannot be expressed in such a compact form, then one would need to provide\neach node with an index list of active pairs, which could be memory-intensive when n is large."}, {"heading": "4. Numerical Simulations", "text": "In this section, we present numerical experiments on two popular machine learning problems involving pairwise functions: Area Under the ROC Curve (AUC) maximization and metric learning. Our results show that our algorithms converge and that the bias term vanishes very quickly with the number of iterations.\nTo study the influence of the network topology, we perform our simulations on three types of network (see Table 1 for the corresponding spectral gap values):\n\u2022 Complete graph: All nodes are connected to each other. It is the ideal situation in our framework, since any pair of nodes can communicate directly. In this setting, the bias of gradient estimates should be very small, as one has for any k \u2208 [n] and any t \u2265 1, Et[dk(t)|\u03b8k(t)] = 1/(n \u2212 1) \u2211 y\u2032 6=yk(t)\u2207\u03b8f(\u03b8k(t);xk, y\n\u2032). For a network size n, the complete graph achieves the highest spectral gap: 1 \u2212 \u03bbG2 = 1/n, see Bolloba\u0301s (1998, Ch.9) or Chung (1997, Ch.1) for details.\n\u2022 Cycle graph: This is the worst case in terms of connectivity: each node only has two neighbors. This network has a spectral gap of order 1/n3, and gives a lower bound in terms of convergence rate.\n\u2022 Watts-Strogatz: This random network generation technique (Watts & Strogatz, 1998) relies on two parameters: the average degree of the network k and a rewiring probability p. In expectation, the higher the rewiring probability, the better the connectivity of the network. Here, we use k = 5 and p = 0.3 to achieve a compromise between the connectivities of the complete graph and the cycle graph.\nAUC Maximization We first present an application of our algorithms to AUC maximization on a real dataset. Given a set of data points x1, . . . , xn \u2208 Rd with associated binary labels `1, . . . , `n \u2208 {\u22121, 1}, the goal is to learn a linear scoring rule x 7\u2192 x>\u03b8 parameterized by \u03b8 \u2208 Rd which maximizes:\nAUC(\u03b8) = \u2211 1\u2264i,j\u2264n I{`i>`j}I{x>i \u03b8>x>j \u03b8}\u2211\n1\u2264i,j\u2264n I{`i>`j} .\nIt corresponds to the probability that the scoring rule associated with \u03b8 outputs a higher score on a positively labeled sample than on a negatively labeled one. This formulation leads to a non-smooth optimization problem; therefore, one\ntypically minimizes a convex surrogate such as the logistic loss:\nRn(\u03b8) = 1\nn2 \u2211 1\u2264i,j\u2264n I{`i>`j} log ( 1 + exp((xj \u2212 xi)>\u03b8) ) .\nWe do not apply any regularization (i.e., \u03c8 \u2261 0), and use the Breast Cancer Wisconsin dataset,1 which consists of n = 699 points in d = 11 dimensions.\nWe initialize each \u03b8i to 0 and for each network, we run 50 times Algorithms 2 and 3 with \u03b3(t) = 1/ \u221a t.2 Figure 1(a) shows the evolution of the objective function and the associated standard deviation (across nodes) with the number of iterations in the synchronous setting. As expected, the average convergence rate on the complete and the WattsStrogatz networks is much better than on the poorly connected cycle network. The standard deviation of the node estimates also decreases with the connectivity of the network.\nThe results for the asynchronous setting are shown in Figure 1(b). As expected, the convergence rate is slower in terms of number of iterations (roughly 5 times) than in the synchronous setting. Note however that much fewer dual averaging steps are performed: for instance, on the WattsStrogatz network, reaching a 0.1 loss requires 210, 000\n1https://archive.ics.uci.edu/ml/datasets/ Breast+Cancer+Wisconsin+(Original)\n2Even if this scaling sequence does not fulfill the hypothesis of Theorem 2 for the asynchronous setting, the convergence rate is acceptable in practice.\n(partial) gradient computations in the synchronous setting and only 25, 000 in the asynchronous setting. Moreover, the standard deviation of the estimates is much lower than in the synchronous setting. This is because communication and local optimization are better balanced in the asynchronous setting (one optimization step for each gradient accumulator averaged) than in the synchronous setting (n optimization steps for 2 gradient accumulators averaged).\nThe good practical convergence of our algorithm comes from the fact that the bias term n(t)>\u03c9(t) vanishes quite fast. Figure 1(c) shows that its average value quickly converges to 0 on all networks. Moreover, its order of magnitude is negligible compared to the objective function. In order to fully estimate the impact of this bias term on the performance, we also compare our algorithm to the ideal but unrealistic situation where each node is given an unbiased estimate of its partial gradient: instead of adding \u2207f(\u03b8i(t);xi, yi(t)) to zi(t), a node i will add \u2207f(\u03b8i(t);xi, xj) where j \u2208 [n] is picked uniformly at random. As shown in Figure 2, the performance of both methods are very similar on well-connected networks.\nMetric Learning We now turn to a metric learning application. We consider the family of Mahalanobis distances D\u03b8(xi, xj) = (xi \u2212 xj)>\u03b8(xi \u2212 xj) parameterized by \u03b8 \u2208 Sd+, where Sd+ is the cone of d \u00d7 d positive semi-definite real-valued matrices. Given a set of data points x1, . . . , xn \u2208 Rd with associated labels `1, . . . , `n \u2208 {\u22121, 1}, the goal is to find \u03b8 \u2208 Sd+ which minimizes the\nfollowing criterion (Jin et al., 2009):\nRn(\u03b8) = 1\nn2 \u2211 1\u2264i,j\u2264n [ `i`j(b\u2212D\u03b8(xi, xj)) ] + + \u03c8(\u03b8),\nwhere [u]+ = max(0, 1 \u2212 u), b > 0, and \u03c8(\u03b8) = \u221e if \u03b8 /\u2208 Sd+ and 0 otherwise. We use a synthetic dataset of n = 1, 000 points generated as follows: each point is drawn from a mixture of 10 Gaussians in R40 (each corresponding to a class) with all Gaussian means contained in a 5d subspace and their shared covariance matrix proportional to the identity with a variance factor such that some overlap is observed.\nFigure 3(a) shows the evolution of the objective function and its standard deviation for the asynchronous setting. As in the case of AUC maximization, the algorithm converges much faster on the well-connected networks than on the cycle network. Again, we can see in Figure 3(b) that the bias vanishes very quickly with the number of iterations.\nAdditional Experiment We refer to the supplementary material for a metric learning experiment on a real dataset."}, {"heading": "5. Conclusion", "text": "In this work, we have introduced new synchronous and asynchronous gossip algorithms to optimize functions depending on pairs of data points distributed over a network. The proposed methods are based on dual averaging and can readily accommodate various popular regularization terms. We provided an analysis showing that they behave similarly to the centralized dual averaging algorithm, with additional terms reflecting the network connectivity and the gradient bias. Finally, we proposed some numerical experiments on AUC maximization and metric learning which illustrate the performance of the proposed algorithms, as well as the influence of network topology. A challenging line of future research consists in designing and analyzing novel adaptive gossip schemes, where the communication scheme is dynamic and depends on the network connectivity properties and on the local information carried by each node."}, {"heading": "A. Outline of the Supplementary Material", "text": "The supplementary material is organized as follows. In Section B, we recall the standard proof of convergence rate for the (centralized) dual averaging. Then, in Section C, we improve the analysis of the decentralized version of the dual averaging algorithm for simple sums of functions, and provide insights to analyze the case of sum of pairwise functions. Our asynchronous variant is investigated in Section D. Technical details on how to extend our framework to the case with multiple points per node are given in Section E. Finally, additional numerical results are discussed in Section F."}, {"heading": "B. Centralized Dual Averaging", "text": "B.1. Deterministic Setting\nWe introduce the dual averaging algorithm for minimizing the sum f + \u03c8, in a context where f is convex and smooth, \u03c8(0) = 0, \u03c8 is convex, non-negative and possibly non-smooth, with a proximity operator simple to compute. In the centralized framework, this algorithm reads as follows:\n\u03b8(t+ 1) = arg min \u03b8\u2032\u2208Rd\n{ \u03b8\u2032>\nt\u2211 s=1 g(s) + \u2016\u03b8\u2032\u20162 2\u03b3(t) + t\u03c8(\u03b8\u2032)\n} , (9)\nfor any t \u2265 1, where \u03b3(t) represents a scale factor similar to a gradient step size use in standard gradient descent algorithms, and g(t) is a sequence of gradient of f taken at \u03b8(t). Moreover we initialize \u03b8(1) = 0. The function f we consider is here of the form f\u0304n(\u03b8) = 1/n \u2211n i=1 fi(\u03b8), where each fi is assumed Lf -Lipschitz for simplicity (so is f then). We denote Rn = f\u0304 n + \u03c8. As a reminder, note that the Centralized dual averaging method is explicitly stated in Algorithm 4.\nThis particular formulation was introduced in (Xiao, 2009; 2010), extending the method introduced by (Nesterov, 2009) in the specific case of indicator functions. In this work, we borrow the notation from (Xiao, 2010).\nIn order to perform a theoretical analysis of this algorithm, we introduce the following functions. Let us define, for t \u2265 0\nVt(z) := max \u03b8\u2208Rd\n{ z>\u03b8 \u2212 \u2016\u03b8\u2016 2\n2\u03b3(t) \u2212 t\u03c8(\u03b8)\n} .\nRemark that with the assumption that \u03c8(0) = 0, then Vt(0) = 0. We also define the smoothing function \u03c0t that plays a crucial role in the dual algorithm formulation:\n\u03c0t(z) := arg max \u03b8\u2208Rd\n{ z>\u03b8 \u2212 \u2016\u03b8\u2016 2\n2\u03b3(t) \u2212 t\u03c8(\u03b8)\n} = arg min\n\u03b8\u2208Rd\n{ \u2212z>\u03b8 + \u2016\u03b8\u2016 2\n2\u03b3(t) + t\u03c8(\u03b8)\n}\nStrong convexity in \u03b8 of the objective function, ensures that the solution of the optimization problem is unique. The following lemma links the function Vt and the algorithm update and is a simple application of the results from (Xiao, 2009, Lemma 10):\nLemma 1. For any z \u2208 Rd, one has:\n\u03c0t(z) = \u2207Vt(z) , (10)\nand the following statements hold true: for any z1, z2 \u2208 Rd\n\u2016\u03c0t(z1)\u2212 \u03c0t(z2)\u2016 \u2264 \u03b3(t)\u2016z1 \u2212 z2\u2016 , (11)\nand for any g, z \u2208 Rd,\nVt(z + g) \u2264 Vt(z) + g>\u2207Vt(z) + \u03b3(t)\n2 \u2016g\u20162. (12)\nWith this notation one can write the dual averaging rule as \u03b8(t+ 1) = \u03c0t (\u2212z(t+ 1)), where z(t) := \u2211t\u22121 s=1 g(s), with the convention z(1) = 0. Moreover, adapting (Xiao, 2009, Lemma 11) we can state:\nAlgorithm 4 Centralized dual averaging Require: Step size (\u03b3(t))t\u22651 > 0. 1: Initialization \u03b8 = 0, \u03b8\u0304 = 0, z = 0. 2: for t = 1, . . . , T do 3: Update z \u2190 z + g(t), where g(t) = \u2207f\u0304n(\u03b8) 4: Update \u03b8 \u2190 \u03c0t(z) 5: Update \u03b8\u0304 \u2190 ( 1\u2212 1\nt\n) \u03b8\u0304 + 1\nt \u03b8\n6: end for 7: return\u03b8\u0304\nLemma 2. For any t \u2265 1 and any non-increasing sequence (\u03b3(t))t\u22651, we have\nVt (\u2212z(t+ 1)) + \u03c8(\u03b8(t+ 1)) \u2264 Vt\u22121 (\u2212z(t+ 1)) . (13)\nWe also need a last technical result that we will use several times in the following: Lemma 3. Let \u03b8(t) = \u03c0t( \u2211t\u22121 s=1 g(s)), and let (\u03b3(t))t\u22651 be a non-increasing and non-negative sequence sequence (with the convention \u03b3(0) = 0), then for any \u03b8 \u2208 Rd:\n1\nT T\u2211 t=1 g(t)>(\u03b8(t)\u2212 \u03b8) + 1 T T\u2211 t=1 (\u03c8(\u03b8(t))\u2212 \u03c8(\u03b8)) \u2264 1 T T\u2211 t=1 \u03b3(t\u2212 1) 2 \u2016g(t)\u20162 + \u2016\u03b8\u2016 2 2T\u03b3(T ) . (14)\nProof. Use the definition of VT to get the following upper bound\n1\nT T\u2211 t=1 g(t)>(\u03b8(t)\u2212 \u03b8) + 1 T T\u2211 t=1 (\u03c8(\u03b8(t))\u2212 \u03c8(\u03b8)) = 1 T T\u2211 t=1 g(t)>\u03b8(t) + \u03c8(\u03b8(t)) + \u2016\u03b8\u20162 2T\u03b3(T ) \u2212 \u03c8(\u03b8)\n\u2212 ( z(T + 1)\nT\n)> \u03b8 \u2212 \u2016\u03b8\u2016 2\n2T\u03b3(T )\n\u2264 1 T T\u2211 t=1 ( g(t)>\u03b8(t) + \u03c8(\u03b8(t)) ) + \u2016\u03b8\u2217\u20162\n2T\u03b3(T ) + VT (\u2212z(T + 1)) . (15)\nThen one can check that with (12) and Lemma 2 that:\nVt(\u2212z(t+ 1)) + \u03c8(\u03b8(t+ 1)) \u2264Vt\u22121(\u2212z(t+ 1)) =Vt\u22121(\u2212z(t)\u2212 g(t))\n\u2264Vt\u22121(\u2212z(t))\u2212 g(t)>\u2207Vt\u22121(\u2212z(t)) + \u03b3(t\u2212 1)\n2 \u2016g(t)\u20162\n=Vt\u22121(\u2212z(t))\u2212 g(t)>\u03b8(t) + \u03b3(t\u2212 1)\n2 \u2016g(t)\u20162.\nFrom the last display, the following holds:\ng(t)>\u03b8(t) + \u03c8(\u03b8(t+ 1)) \u2264 Vt\u22121(\u2212z(t))\u2212 Vt(\u2212z(t+ 1)) + \u03b3(t\u2212 1)\n2 \u2016g(t)\u20162.\nSumming the former for t = 1, . . . , T yields\nT\u2211 t=1 g(t)>\u03b8(t) + \u03c8(\u03b8(t+ 1)) \u2264 V0(\u2212s0)\u2212 VT (\u2212sT ) + T\u2211 t=1 \u03b3(t\u2212 1) 2 \u2016gt\u20162.\nRemark that V0(0) = 0 and \u03c8(\u03b8(1))\u2212 \u03c8(\u03b8(T + 1)) = \u2212\u03c8(\u03b8(T + 1)) \u2264 0, so the previous display can be reduced to:\nT\u2211 t=1 g(t)>\u03b8(t) + \u03c8(\u03b8(t)) + VT (\u2212z(T + 1)) \u2264 T\u2211 t=1 \u03b3(t\u2212 1) 2 \u2016g(t)\u20162. (16)\nCombining with (15), the lemma holds true.\nBounding the error of the dual averaging is provided in the next theorem, where we remind that Rn = f\u0304n + \u03c8:\nTheorem 3. Let (\u03b3(t))t\u22651 be a non increasing sequence. Let (z(t))t\u22651, (\u03b8(t))t\u22651, (\u03b8\u0304(t))t\u22651 and (g(t))t\u22651 be generated according to Algorithm 4. Assume that the function f\u0304n is Lf -Lipschitz and that \u03b8\u2217 \u2208 arg min\u03b8\u2032\u2208Rd Rn(\u03b8\u2032), then for any T \u2265 2, one has:\nRn(\u03b8\u0304(T ))\u2212Rn(\u03b8\u2217) \u2264 \u2016\u03b8\u2217\u20162 2T\u03b3(T ) + L2f 2T T\u22121\u2211 t=1 \u03b3(t). (17)\nMoreover, if one knows D > 0 such that \u2016\u03b8\u2217\u2016 \u2264 D, then for the choice \u03b3(t) = D Lf \u221a 2t , one has:\nRn(\u03b8\u0304(T ))\u2212Rn(\u03b8\u2217) \u2264 \u221a\n2DLf\u221a T .\nProof. Let T \u2265 2. Using the convexity of f\u0304n and \u03c8, we can get:\nRn(\u03b8\u0304(T ))\u2212Rn(\u03b8\u2217) \u2264 1\nT T\u2211 t=1 f\u0304n(\u03b8(t))\u2212 f\u0304n(\u03b8\u2217) + \u03c8(\u03b8\u0304)\u2212 \u03c8(\u03b8\u2217)\n\u2264 1 T T\u2211 t=1 g(t)>(\u03b8(t)\u2212 \u03b8\u2217) + 1 T T\u2211 t=1 (\u03c8(\u03b8(t))\u2212 \u03c8(\u03b8\u2217))\n\u2264 1 T T\u2211 t=1 \u03b3(t\u2212 1) 2 \u2016g(t)\u20162 + \u2016\u03b8\u2016 2 2T\u03b3(T ) .\nwhere the second inequality holds since g(t) = \u2207f\u0304n(\u03b8(t)), and the third one is from an application of Lemma 3 with the choice \u03b8 = \u03b8\u2217. Provided that \u2016g(t)\u2016 \u2264 Lf , which is true whenever f\u0304n is Lf -Lipschitz.\nB.2. Stochastic Dual Averaging\nSimilarly to sub-gradient descent algorithms, one can adapt dual averaging algorithm to a stochastic setting; this was studied extensively by Xiao (2009). Instead of updating the dual variable z(t) with the (full) gradient of f\u0304n at \u03b8(t), one now only requires the expected value of the update to be the gradient, as detailed in Algorithm 1.\nAs in the gradient descent case, convergence results still hold in expectation, as stated in Theorem 4.\nTheorem 4. Let (\u03b3(t))t\u22651 be a non increasing sequence. Let (z(t))t\u22651, (\u03b8(t))t\u22651 and (g(t))t\u22651 be generated according to Algorithm 1. Assume that the function f\u0304n is Lf -Lipschitz and that \u03b8\u2217 \u2208 arg min\u03b8\u2032\u2208Rd Rn(\u03b8\u2032), then for any T \u2265 2, one has:\nET [ Rn(\u03b8\u0304(T ))\u2212Rn(\u03b8\u2217) ] \u2264 \u2016\u03b8 \u2217\u20162\n2T\u03b3(T ) + L2f 2T T\u22121\u2211 t=1 \u03b3(t), (18)\nwhere ET is the expectation over all possible sequence (g(t))1\u2264t\u2264T .\nMoreover, if one knows that D > 0 such that \u2016\u03b8\u2217\u2016 \u2264 D, then for \u03b3(t) = D Lf \u221a 2t , one has:\nET [ Rn(\u03b8\u0304(T ))\u2212Rn(\u03b8\u2217) ] \u2264 \u221a\n2DLf\u221a T .\nProof. One only has to prove that the convexity inequality in Lemma 3 holds in expectation. The rest of the proof can be directly adapted from Theorem 3.\nLet T \u2265 2; using the convexity of f\u0304n, one obtains:\nET [f\u0304n(\u03b8\u0304(T ))\u2212 f\u0304n(\u03b8\u2217)] \u2264 1\nT T\u2211 t=1 ET [f\u0304n(\u03b8(t))\u2212 f\u0304n(\u03b8\u2217)].\nFor any 0 < t \u2264 T , E[\u03b8(t)|g(0), . . . , g(t\u2212 1)] = \u03b8(t). Therefore, we have:\nET [f\u0304n(\u03b8(t))\u2212 f\u0304n(\u03b8\u2217)] = Et\u22121[f\u0304n(\u03b8(t))\u2212 f\u0304n(\u03b8\u2217)].\nThe vector Et[g(t)|\u03b8(t)] is the gradient of f\u0304n at \u03b8(t), we can then use f\u0304n convexity to write: Et\u22121[f\u0304n(\u03b8(t))\u2212 f\u0304n(\u03b8\u2217)] \u2264 Et\u22121 [ (\u03b8(t)\u2212 \u03b8\u2217)>Et[g(t)|\u03b8(t)] ] .\nUsing properties of conditional expectation, we obtain: Et\u22121 [ (\u03b8(t)\u2212 \u03b8\u2217)>Et[g(t)|\u03b8(t)] ] = Et\u22121 [ Et[(\u03b8(t)\u2212 \u03b8\u2217)>g(t)|\u03b8(t)] ] = Et[(\u03b8(t)\u2212 \u03b8\u2217)>g(t)].\nFinally, we can write:\nET [f\u0304n(\u03b8\u0304(T )\u2212 f(\u03b8\u2217)] \u2264 1\nT T\u2211 t=1 Et[(\u03b8(t)\u2212 \u03b8\u2217)>g(t)] = ET\n[ 1\nT T\u2211 t=1 (\u03b8(t)\u2212 \u03b8\u2217)>g(t)\n] . (19)"}, {"heading": "C. Convergence Proof for Synchronous Pairwise Gossip Dual Averaging", "text": "In (Duchi et al., 2012), the following convergence rate for distributed dual averaging is established:\nRn(\u03b8\u0304i(T ))\u2212Rn(\u03b8\u2217) \u2264 1\n2T\u03b3(T ) \u2016\u03b8\u2217\u20162 + L2f 2T T\u2211 t=2 \u03b3(t\u2212 1)\n+ Lf nT T\u2211 t=2 \u03b3(t\u2212 1) n\u2211 j=1 ( \u2016zi(t)\u2212 zj(t)\u2016+ \u2016z\u0304n(t)\u2212 zj(t)\u2016 ) .\nThe first part is an optimization term, which is exactly the same as in the centralized setting. Then, the second part is a network-dependent term which depends on the global variation of the dual variables; the following lemma provides an explicit dependence between this term and the topology of the network.\nLemma 4. Let W (G) = In \u2212 L(G)|E| and let (G(t))t\u22651 and (Z(t))t\u22651 respectively be the gradients and the gradients cummulative sum of the distributed dual averaging algorithm. If G is connected and non bipartite, then one has for t \u2265 1:\n1\nn n\u2211 i=1 E\u2016zi(t)\u2212 zn(t)\u2016 \u2264 Lf 1\u2212 \u221a \u03bbG2 ,\nwhere \u03bbG2 is the second largest eigenvalue of W (G).\nProof. For t \u2265 1, let W (t) be the random matrix such that if (i, j) \u2208 E is picked at t, then\nW (t) = In \u2212 1\n2 (ei \u2212 ej)(ei \u2212 ej)>.\nAs denoted in (Duchi et al., 2012), the update rule for Z can be expressed as follows:\nZ(t+ 1) = G(t) +W (t)Z(t),\nfor any t \u2265 1, reminding that G(0) = 0, Z(1) = 0. Therefore, one can obtain recursively\nZ(t) = t\u2211 s=0 W (t : s)G(s),\nwhere W (t : s) = W (t) . . .W (s + 1), with the convention W (t : t) = In. For any t \u2265 1, let W \u2032(t) := W (t) \u2212 1n1 > n\nn .\nOne can notice that for any 0 \u2264 s \u2264 t, W \u2032(t : s) = W (t : s)\u2212 1n1 > n\nn and write:\nZ(t)\u2212 1nzn(t)> = t\u2211\ns=0\nW \u2032(t : s)G(s).\nWe now take the expected value of the Frobenius norm:\nE [\u2225\u2225Z(t)\u2212 1nzn(t)>\u2225\u2225F ] \u2264 t\u2211\ns=0\nE [\u2016W (t : s)G(s)\u2016F ]\n\u2264 t\u2211\ns=0\n\u221a E [ \u2016W (t : s)G(s)\u20162F ] =\nn\u2211 i=1 t\u2211 s=0 \u221a E [ g(i)(s)>W \u2032(t : s)>W \u2032(t : s)g(i)(s) ] ,\nwhere g(i)(s) is the column i of matrixG(s). Since for any s \u2265 0,W (s) is a symmetric projection matrix,W \u2032(s)>W \u2032(s) = W \u2032(s); moreover, conditioning over Fs leads to:\nE [ g(i)(s)>W \u2032(t : s)>W \u2032(t : s)g(i)(s) ] = E [ g(i)(s)>E[W \u2032(t : s)|Fs]g(i)(s) ] \u2264 \u03bbG2 \u2016g(i)(s)\u20162. (20)\nUsing the fact that for any s \u2265 0, \u2016G(s)\u20162F \u2264 nL2f , one has:\nE [\u2225\u2225Z(t)\u2212 1nzn(t)>\u2225\u2225F ] \u2264 \u221anLf t\u2211\ns=0\n( \u03bbG2 ) t\u2212s 2 \u2264 \u221a nLf\n1\u2212 \u221a \u03bbG2 .\nFinally, using the bounds between `1 and `2-norms yields:\n1\nn n\u2211 i=1 E\u2016zi(t)\u2212 zn(t)\u2016 \u2264 1\u221a n E \u2225\u2225Z(t)\u2212 1nzn(t)>\u2225\u2225F \u2264 Lf 1\u2212 \u221a \u03bbG2 .\nWith this bound on the dual variables, one can reformulate the convergence rate as stated below.\nCorollary 1. Let G be a connected and non bipartite graph. Let (\u03b3(t))t\u22651 be a non-increasing and non-negative sequence. For i \u2208 [n], let (gi(t))t\u22651, (zi(t))t\u22651 and (\u03b8i(t))t\u22651 be generated according to the distributed dual averaging algorithm. For \u03b8\u2217 \u2208 arg min\u03b8\u2032\u2208Rd Rn(\u03b8\u2032), i \u2208 [n] and T \u2265 2, one has:\nRn(\u03b8\u0304i(T ))\u2212Rn(\u03b8\u2217) \u2264 1\n2T\u03b3(T ) \u2016\u03b8\u2217\u20162 + L2f 2T T\u22121\u2211 t=1 \u03b3(t)\n+ 3L2f\nT ( 1\u2212 \u221a \u03bbG2 ) T\u22121\u2211 t=1 \u03b3(t),\nwhere \u03bbG2 < 1 is the second largest eigenvalue of W (G).\nWe now focus on gossip dual averaging for pairwise functions, as shown in Algorithm 2. The key observation is that, at each iteration, the descent direction is stochastic but also a biased estimate of the gradient. That is, instead of updating a dual variable zi(t) with gi(t) such that E[gi(t)|\u03b8i(t)] = \u2207fi(\u03b8i(t)), we perform some update di(t), and we denote by i(t) the quantity such that E[di(t)\u2212 i(t)|\u03b8i(t)] = E[gi(t)|\u03b8i(t)] = \u2207fi(\u03b8i(t)). The following theorem allows to upper-bound the error induced by the bias.\nTheorem 5. Let G be a connected and non bipartite graph. Let (\u03b3(t))t\u22651 be a non increasing and non-negative sequence. For i \u2208 [n], let (di(t))t\u22651, (gi(t))t\u22651, ( i(t))t\u22651, (zi(t))t\u22651 and (\u03b8i(t))t\u22651 be generated by Algorithm 2. Assume that the function f\u0304n is L-Lipschitz and that \u03b8\u2217 \u2208 arg min\u03b8\u2032\u2208Rd Rn(\u03b8\u2032), then for any i \u2208 [n] and T \u2265 2, one has:\nET [Rn(\u03b8\u0304i(T ))]\u2212Rn(\u03b8\u2217) \u2264 1\n2T\u03b3(T ) \u2016\u03b8\u2217\u20162 + L2f 2T T\u22121\u2211 t=1 \u03b3(t)\n+ 3L2f\nT ( 1\u2212 \u221a \u03bbG2 ) T\u22121\u2211 t=1 \u03b3(t)\n+ 1\nT T\u22121\u2211 t=1 Et[(\u03c9(t)\u2212 \u03b8\u2217)>\u0304n(t)].\nProof. We can apply the same arguments as in the proofs of centralized and distributed dual averaging, so for T > 0 and i \u2208 [n]:\nET [Rn(\u03b8\u0304i(T ))]\u2212Rn(\u03b8\u2217) \u2264 L\nnT T\u2211 t=2 \u03b3(t\u2212 1) n\u2211 j=1 E [ \u2016zi(t)\u2212 zj(t)\u2016+ \u2016z\u0304n(t)\u2212 zj(t)\u2016 ]\n+ 1\nT T\u2211 t=2 Et[(\u03c9(t)\u2212 \u03b8\u2217)>g\u0304n(t)].\nHowever, Lemma 3 can no longer be applied here since the updates are performed with dj(t) and not gj(t) = dj(t)\u2212 j(t). With the definition of dj(t), the former yields:\n1\nT T\u2211 t=2 Et[\u03c9(t)\u2212 \u03b8\u2217)>g\u0304n(t)] = 1 T T\u2211 t=2 Et[(\u03c9(t)\u2212 \u03b8\u2217)>(d\u0304n(t)\u2212 \u0304n(t))].\nNow Lemma 3 can be applied to the first term in the right hand side and the result holds."}, {"heading": "D. Asynchronous Distributed Setting", "text": "In this section, we focus on a fully asynchronous setting where each node has a local clock. We assume for simplicity that each node has a clock ticking at a Poisson rate equals to 1, so it is equivalent to a global clock ticking at a Poisson rate of n, and then drawing an edge uniformly at random (see (Boyd et al., 2006) for more details). Under this assumption, we can state a method detailed in Algorithm 3.\nThe main difficulty in the asynchronous setting is that each node i has to use a time estimate mi instead of the global clock reference (that is no longer available in such a context). Even if the time estimate is unbiased, its variance puts an additional error term in the convergence rate. However, for an iteration T large enough, one can bound these estimates as stated bellow.\nLemma 5. There exists T1 > 0 such that for any t \u2265 T1, any k \u2208 [n] and any q > 0,\nt\u2212 := t\u2212 t 12+q \u2264 mk(t) \u2264 t+ t 1 2+q =: t+ a.s.\nProof. Let k \u2208 [n]. For t \u2265 1, let us define \u03b4k(t) such that \u03b4k(t) = 1 if k is picked at iteration t and \u03b4k(t) = 0 otherwise. Then one has mk(t) = (1/pk) \u2211t s=1 \u03b4k(t). Since (\u03b4k(t))t\u22651 is a Bernoulli process of parameter 1/pk, by the law of\niterative logarithms (Dudley, 2010), (Nedic\u0301, 2011, Lemma 3) one has with probability 1 and for any q > 0\nlim t\u2192+\u221e |mk(t)\u2212 t| t 1 2+q = 0,\nand the result holds.\nTheorem 6. Let G be a connected and non bipartite graph. Let (\u03b3(t))t\u22651 be defined as \u03b3(t) = c/t1/2+\u03b1 for some constant c > 0 and \u03b1 \u2208 (0, 1/2). For i \u2208 [n], let (di(t))t\u22651, (gi(t))t\u22651, ( i(t))t\u22651, (zi(t))t\u22651 and (\u03b8i(t))t\u22651 be generated as stated previously. For \u03b8\u2217 \u2208 arg min\u03b8\u2032\u2208Rd Rn(\u03b8\u2032), i \u2208 [n] and T > 0, one has for some C:\nRn(\u03b8\u0304i(T ))\u2212Rn(\u03b8\u2217) \u2264 C max(T\u2212\u03b1/2, T\u03b1\u22121/2) + 1\nT T\u2211 t=1 Et[ n(t)>\u03c9(t)] . (21)\nProof. In the asynchronous case, for i \u2208 [n] and t \u2265 1, one has\n\u03b8\u0304i(T ) = 1\nmi(T ) T\u2211 t=1 \u03b4i(t) pi \u03b8i(t).\nThen, using the convexity of Rn, one has:\nET [Rn(\u03b8\u0304i(T )]\u2212Rn(\u03b8\u2217) \u2264 ET\n[ 1\nmi(T ) T\u2211 t=1 \u03b4i(t) pi Rn(\u03b8i(t))\n] \u2212Rn(\u03b8\u2217). (22)\nBy Lemma 5, one has for q > 0\nET [Rn(\u03b8\u0304i(T )]\u2212Rn(\u03b8\u2217) \u2264 1\nT\u2212 T\u2211 t=1 ET [ \u03b4i(t) pi Rn(\u03b8i(t)) ] \u2212Rn(\u03b8\u2217).\nSimilarly to the synchronous case, one can write ET [ \u03b4i(t)\npi f\u0304n(\u03b8i(t))\n] = n\u2211 j=1 1 n ET [ \u03b4i(t) pi fj(\u03b8i(t)) ]\n= 1\nn n\u2211 j=1 ET [ \u03b4i(t) pi (fj(\u03b8i(t))\u2212 fj(\u03b8j(t)) ] + 1 n n\u2211 j=1 ET [ \u03b4i(t) pi fj(\u03b8j(t)) ] .\nIn order to use the gradient inequality, we need to introduce \u03b4j(t)fj(\u03b8j(t)) instead of \u03b4i(t)fj(\u03b8j(t)). For j \u2208 [n], one has:\n1\nT\u2212 T\u2211 t=1 ET [ \u03b4i(t) pi fj(\u03b8j(t)) ] = 1 T\u2212 T\u2211 t=1 ET [( \u03b4i(t) pi \u2212 \u03b4j(t) pj ) fj(\u03b8j(t)) ] + 1 T\u2212 T\u2211 t=1 ET [ \u03b4j(t) pj fj(\u03b8j(t)) ] .\nLet Nj = \u2211T t=1 \u03b4j(t) and let 1 \u2264 t1 < . . . < tNj \u2264 T be such that \u03b4j(tk) = 1 for k \u2208 [Nj ]. One can write\n1\nT\u2212 T\u2211 t=1 ET [( \u03b4i(t) pi \u2212 \u03b4j(t) pj ) fj(\u03b8j(t)) ] = 1 T\u2212 ET Nj\u22121\u2211 k=1 (( tk+1\u22121\u2211 t=tk \u03b4i(t) pi ) \u2212 1 pj ) fj(\u03b8j(tk))  + 1\nT\u2212 ET [( t1\u2211 t=0 \u03b4i(t) pi ) fj(\u03b8j(0)) ]\n+ 1\nT\u2212 ET  T\u2211 t=tNj \u03b4i(t) pi \u2212 1 pj  fj(\u03b8j(tNj )) \n\u2264+ 1 T\u2212 ET Nj\u22121\u2211 k=1 (( tk+1\u22121\u2211 t=tk \u03b4i(t) pi ) \u2212 1 pj ) fj(\u03b8j(tk))  + fj(0)\npipjT\u2212 + L2fET [\u03b3(tNj \u2212 1)] pipj . (23)\nWe need to study the behavior of \u03b4i and \u03b4j in the first term of the right hand side. One can check that\nET Nj\u22121\u2211 k=1 (( tk+1\u22121\u2211 t=tk \u03b4i(t) pi ) \u2212 1 pj ) fj(\u03b8j(tk))  = ET Nj\u22121\u2211 k=1 ( E [ tk+1\u22121\u2211 t=tk \u03b4i(t) pi \u2223\u2223\u2223\u2223\u2223tk, tk+1 ] \u2212 1 pj ) fj(\u03b8j(tk))  . \u03b4i(t) will not have the same dependency in tk whether i and j are connected or not. Let us first assume that (i, j) \u2208 E. Then,\nE[\u03b4i(tk)|tk] = E[\u03b4i(t)|\u03b4j(t) = 1] = 1\ndj .\nAlso, for tk < t < tk+1, we get:\nE[\u03b4i(t)|tk] = E[\u03b4i(t)|\u03b4j(t) = 0] = pi \u2212 2/|E|\n1\u2212 pj .\nFinally, if (i, j) \u2208 E, we obtain\nE [ tk+1\u22121\u2211 t=tk \u03b4i(t) pi \u2223\u2223\u2223\u2223\u2223tk, tk+1 ] = ( 1 dj + (tk+1 \u2212 tk \u2212 1) pi \u2212 2/|E| 1\u2212 pj ) 1 pi .\nBefore using this relation in the full expectation, let us denote that since tk+1 \u2212 tk is independent from tk, one can write\nE\n[( 1\ndj + (tk+1 \u2212 tk \u2212 1) pi \u2212 2/|E| 1\u2212 pj\n) 1\npi\n\u2223\u2223\u2223\u2223\u2223tk ] = ( 1 dj + ( 1\u2212 pj pj ) pi \u2212 2/|E| 1\u2212 pj ) 1 pi = 1 pj .\nWe can now use this relation in the full expectation\nET [( \u03b4i(t)\npi \u2212 \u03b4j(t) pj\n) fj(\u03b8j(t)) ] = ET Nj\u22121\u2211 k=1 ( E [ E [ tk+1\u22121\u2211 t=tk \u03b4i(t) pi \u2223\u2223\u2223\u2223\u2223tk+1 \u2212 tk ] \u2223\u2223\u2223\u2223\u2223tk ] \u2212 1 pj ) fj(\u03b8j(tk))  = 0. (24) Similarly if (i, j) 6\u2208 E, one has\nE[\u03b4i(tk)|tk] = E[\u03b4i(t)|\u03b4j(t) = 1] = 0,\nand for tk < t < tk+1,\nE[\u03b4i(t)|tk] = E[\u03b4i(t)|\u03b4j(t) = 0] = pi\n1\u2212 pj ,\nso the result of Equation (24) holds in this case. We have just shown that for every j \u2208 [n], we can use \u03b4j(t)fj(\u03b8j(t))/pj instead of \u03b4i(t)fj(\u03b8j(t))/pi . Combining (22) and (23) yields:\nET [Rn(\u03b8\u0304i(T ))]\u2212Rn(\u03b8\u2217) \u2264 1\nnT\u2212 T\u2211 t=2 n\u2211 j=1 ET [ \u03b4i(t) pi (fj(\u03b8i(t))\u2212 fj(\u03b8j(t)) ] (25)\n+ 1\nnT\u2212 T\u2211 t=2 n\u2211 j=1 ET [ \u03b4j(t) pj (fj(\u03b8j(t))\u2212 fj(\u03b8\u2217)) ] (26)\n+ 1\nT\u2212 T\u2211 t=2 ET [ \u03b4i(t) pi (\u03c8(\u03b8i(t))\u2212 \u03c8(\u03b8\u2217)) ] (27)\n+ fj(0) pipjT\u2212 + L2fET [\u03b3(tNj \u2212 1)] pipj . (28)\nLet us focus on the second term of the right hand side. For t \u2265 2, one can write\n1\nn n\u2211 j=1 ET [ \u03b4j(t) pj (fj(\u03b8j(t))\u2212 fj(\u03b8\u2217)) ] \u2264 1 n n\u2211 j=1 ET [ \u03b4j(t) pj gj(t) >(\u03b8j(t)\u2212 \u03b8\u2217) ]\n= 1\nn n\u2211 j=1 ET [ \u03b4j(t) pj gj(t) >(\u03b8j(t)\u2212 \u03c9(t)) ]\n(29)\n+ 1\nn n\u2211 j=1 ET [ \u03b4j(t) pj gj(t) >(\u03c9(t)\u2212 \u03b8\u2217) ]\n(30)\n\u2022 Here we control the term from (30) using \u03c9(t) := \u03c0mi(t)(z\u0304n(t))\n1\nn n\u2211 j=1 ET [ \u03b4j(t) pj gj(t) >(\u03c9(t)\u2212 \u03b8\u2217) ] = ET   1 n n\u2211 j=1 \u03b4j(t) pj gj(t) > (\u03c9(t)\u2212 \u03b8\u2217) \n= ET [ g\u0304n(t)>(\u03c9(t)\u2212 \u03b8\u2217) ] ,\nand the reasoning of the synchronous case can be applied to obtain\n1\nnT\u2212 T\u2211 t=2 n\u2211 j=1 ET [ \u03b4j(t) pj gj(t) >(\u03c9(t)\u2212 \u03b8\u2217) ] \u2264 L2f 2T\u2212 T\u2211 t=2 \u03b3(t\u2212 1) + \u2016\u03b8 \u2217\u20162 2\u03b3(T )\n+ 1\nT T\u2211 t=2 Et[ n(t)>\u03c9(t)]\n+ 1\nT\u2212 T\u2211 t=2 (\u03c8(\u03b8\u2217)\u2212 ET [\u03c8(\u03c9(t))]). (31)\nLet us regroup the term from (31) and (27) together:\n1\nT\u2212 T\u2211 t=2 ET [ \u03b4i(t) pi (\u03c8(\u03b8i(t))\u2212 \u03c8(\u03b8\u2217)) ] + 1 T\u2212 T\u2211 t=2 (\u03c8(\u03b8\u2217)\u2212 ET [\u03c8(\u03c9(t))]) = 1 T\u2212 T\u2211 t=2 ET [ \u03b4i(t) pi \u03c8(\u03b8i(t))\u2212 \u03c8(\u03c9(t)) ]\n= 1\nT\u2212 T\u2211 t=2 ET [ \u03b4i(t) pi (\u03c8(\u03b8i(t))\u2212 \u03c8(\u03c9(t))) ]\n+ 1\nT\u2212 T\u2211 t=2 ET [ ( \u03b4i(t) pi \u2212 1)\u03c8(\u03c9(t)) ]\n= 1\nT\u2212 T\u2211 t=2 ET [ \u03b4i(t) pi (\u03c8(\u03b8i(t))\u2212 \u03c8(\u03c9(t))) ] ,\n(32)\nwhere we have used for the last term the same arguments as in (24) to state 1T\u2212 \u2211T t=2 ET [ ( \u03b4i(t)pi \u2212 1)\u03c8(\u03c9(t)) ] = 0. Then, one can use the fact that \u03c0t is \u03b3(t)-Lipschitz to write:\n1\npiT\u2212 T\u2211 t=2 ET [ 2Lf\u03b3(mi(t\u2212 1))\u2016z\u0304n(t)\u2212 zi(t)\u2016+ \u03b3(mi(t\u2212 1))\u2016z\u0304n(t)\u2212 zi(t)\u20162 2(mi(t\u2212 1)) ] .\nProvided that \u03b3(t) \u2264 C\u221a t for some constant C, then using Lemma 5 we can bound this term by C \u2032 \u221a T .\n\u2022 Now we control the term in (29) as follows:\n1\nn n\u2211 j=1 ET [ \u03b4j(t) pj gj(t) >(\u03b8j(t)\u2212 \u03c9(t)) ] \u2264 Lf npj n\u2211 j=1 ET [\u2016\u03b8j(t)\u2212 \u03c9(t)\u2016] (33)\n\u2264 Lf npj n\u2211 j=1 ET [ \u2016\u03b8j(t)\u2212 \u03b8\u0303j(t)\u2016+ \u2016\u03b8\u0303j(t)\u2212 \u03c9(t)\u2016 ] (34)\n\u2264 Lf npj n\u2211 j=1 ET [ \u03b3(mj(t\u2212 1))\u2016zj(t)\u2212 z\u0304n(t)\u2016+ \u2016\u03b8\u0303j(t)\u2212 \u03c9(t)\u2016 ] . (35)\nwhere \u03b8\u0303j(t) = \u03c0mj(t\u22121)(\u2212z\u0304n(t)). We can apply Lemma 6 with the choice \u03b81 = \u03b8\u0303j(t), \u03b82 = \u03c9(t), t1 = mj(t), t2 = mi(t) and z = z\u0304n(t).\n\u2016\u03c9(t)\u2212 \u03b8\u0303j(t)\u2016 \u2264\u2016z\u0304n(t)\u2016 ( |\u03b3(mi(t))\u2212 \u03b3(mj(t))|+(\n3 2 + max( \u03b3(mj(t)) \u03b3(mi(t)) , \u03b3(mi(t)) \u03b3(mj(t)) )\n)( 1\nmj(t) +\n1\nmi(t)\n) |mj(t)\u03b3(mj(t))\u2212mi(t)\u03b3(mi(t))| ) . (36)\nWe use Lemma 5 with the choice q = \u03b1/2, so we can bound for t large enough the former expression by a term of order \u2016z\u0304n(t)\u2016|\u03b3(mi(t))\u2212 \u03b3(mj(t))|. Note also that \u2016z\u0304n(t)\u2016 \u2264 Lf maxk=1,...,nmk(t), so for t large enough we obtain:\n\u2016\u03c9(t)\u2212 \u03b8\u0303j(t)\u2016 \u2264 LF t+|\u03b3(t\u2212)\u2212 \u03b3(t+)| . (37)\nWith the additional constraint that \u03b3(t) = Ct\u22121/2\u2212\u03b1, \u2016\u03c9(t)\u2212 \u03b8\u0303j(t)\u2016 is bounded by C \u2032t\u2212\u03b1/2 for t large enough, and so is 1 n \u2211n j=1 ET [ \u03b4j(t) pj gj(t) >(\u03b8j(t)\u2212 \u03c9(t)) ] .\n\u2022 To control the term in (25) we use that fj is Lf -Lipschitz\n|fj(\u03b8i(t))\u2212 fj(\u03b8j(t)| \u2264Lf\u2016\u03b8i(t)\u2212 \u03b8j(t)\u2016 (38) \u2264Lf (\u2016\u03b8i(t)\u2212 \u03c9(t)\u2016+ \u2016\u03c9(t)\u2212 \u03b8j(t)\u2016). (39)\nand we use now the same control as for (33), hence the result.\nLemma 6. Let \u03b3 : R+ \u2192 R+ be a non-increasing positive function and let z \u2208 Rd. For any t1, t2 > 0, one has \u2016\u03b82 \u2212 \u03b81\u2016 \u2264\u2016z\u2016 ( |\u03b3(t2)\u2212 \u03b3(t1)|+ ( 3\n2 + max(\n\u03b3(t1) \u03b3(t2) , \u03b3(t2) \u03b3(t1) )\n)( 1\nt1 +\n1\nt2\n) |t1\u03b3(t1)\u2212 t2\u03b3(t2)| ) , (40)\nwhere\n\u03b81 = \u03c0t1(z) := arg max \u03b8\u2208Rd\n{ z>\u03b8 \u2212 \u2016\u03b8\u2016 2\n2\u03b3(t1) \u2212 t1\u03c8(\u03b8) } \u03b82 = \u03c0t2(z) := arg max\n\u03b8\u2208Rd\n{ z>\u03b8 \u2212 \u2016\u03b8\u2016 2\n2\u03b3(t2) \u2212 t2\u03c8(\u03b8)\n} .\nProof. Using the optimality property of the minimizers, for any s1 \u2208 \u2202\u03c8(\u03b81) (resp. s2 \u2208 \u2202\u03c8(\u03b82)):\n(\u03b3(t1)z \u2212 t1\u03b3(t1)s1 \u2212 \u03b81)>(\u03b82 \u2212 \u03b81) \u2264 0 (\u03b3(t2)z \u2212 t2\u03b3(t2)s2 \u2212 \u03b82)>(\u03b81 \u2212 \u03b82) \u2264 0\nRe-arranging the terms, and using properties of sub-gradients yields:\n\u2016\u03b82 \u2212 \u03b81\u20162 \u2264(\u03b3(t2)\u2212 \u03b3(t1))z>(\u03b82 \u2212 \u03b81) + (t1\u03b3(t1)s1 \u2212 t2\u03b3(t2)s2)>(\u03b82 \u2212 \u03b81) (41) \u2264(\u03b3(t2)\u2212 \u03b3(t1))z>(\u03b82 \u2212 \u03b81) + (t1\u03b3(t1)\u2212 t2\u03b3(t2))(\u03c8(\u03b82)\u2212 \u03c8(\u03b81)) (42)\nAlso, using the definition of \u03b81 and \u03b82, one has: |\u03c8(\u03b81)\u2212 \u03c8(\u03b81)| \u2264 \u2016z\u2016\u2016\u03b81 \u2212 \u03b82\u2016 ( 3\n2 + max(\n\u03b3(t1) \u03b3(t2) , \u03b3(t2) \u03b3(t1) )\n)( 1\nt1 +\n1\nt2\n) . (43)\nWith relation (41) and (43) we bound the distance between \u03b81 and \u03b82 as follows:\n\u2016\u03b82 \u2212 \u03b81\u2016 \u2264\u2016z\u2016 ( |\u03b3(t2)\u2212 \u03b3(t1)|+ ( 3\n2 + max(\n\u03b3(t1) \u03b3(t2) , \u03b3(t2) \u03b3(t1) )\n)( 1\nt1 +\n1\nt2\n) |t1\u03b3(t1)\u2212 t2\u03b3(t2)| ) (44)"}, {"heading": "E. Extension to Multiple Points per Node", "text": "For ease of presentation, we have assumed throughout the paper that each node i holds a single data point xi. In this section, we discuss simple extensions of our results to the case where each node holds the same number of points k \u2265 2. First, it is easy to see that our results still hold if nodes swap their entire set of k points (essentially viewing the set of k points as a single one). However, depending on the network bandwidth, this solution may be undesirable.\nWe thus propose another strategy where only two data points are exchanged at each iteration, as in the algorithms proposed in the main text. The idea is to view each \u201cphysical\u201d node i \u2208 V as a set of k \u201cvirtual\u201d nodes, each holding a single observation. These k nodes are all connected to each other as well as to the neighbors of i in the initial graph G and their virtual nodes. Formally, this new graph G\u2297 = (V \u2297, E\u2297) is given by G \u00d7 Kk, the tensor product between G and the k-node complete graph Kk. It is easy to see that |V \u2297| = kn and |E\u2297| = k2|E|. We can then run our algorithms on G\u2297 (each physical node i \u2208 V simulating the behavior of its corresponding k virtual nodes) and the convergence results hold, replacing 1\u2212 \u03bbG2 by 1\u2212 \u03bbG \u2297 2 in the bounds. The following result gives the relationship between these two quantities. Proposition 1. Let G be a connected, non-bipartite and non-complete graph with n nodes. Let k \u2265 2 and let G\u2297 be the tensor product graph of G and Kk. Let 1\u2212 \u03bbG2 = \u03b2Gn\u22121/|E| and 1\u2212 \u03bbG \u2297 2 = \u03b2 G\u2297 kn\u22121/|E\u2297|, where \u03b2 G n\u22121 and \u03b2 G\u2297 kn\u22121 are the second smallest eigenvalues of L(G) and L(G\u2297) respectively. We have that\n1\u2212 \u03bbG \u2297 2 = 1\nk\n( 1\u2212 \u03bbG2 ) .\nProof. Let A \u2208 {0, 1}n\u00d7n and A\u2297 \u2208 {0, 1}nk\u00d7nk be the adjacency matrices of G and G\u2297 respectively. Similarly, let D \u2208 Nn\u00d7n and D\u2297 \u2208 Nnk\u00d7nk be the diagonal degree matrices of G and G\u2297 respectively, i.e., Dii = \u2211n j=1Aij and\nD\u2297ii = \u2211nk j=1A \u2297 ij . Denoting the Kronecker product by \u2297, we can write:\nA\u2297 = 1k1 T k \u2297A, D\u2297 = kIk \u2297D.\nRecall that L(G) = D \u2212A and L(G\u2297) = D\u2297 \u2212A\u2297.\nLet (v, \u03b2G \u2297 ) \u2208 Rnk\u00d7R be an eigenpair of L(G\u2297), i.e., (D\u2297\u2212A\u2297)v = \u03b2G\u2297v and v 6= 0nk. Let us write v = [v1 . . . vk]> where v1, . . . , vk \u2208 Rn. Exploiting the structure of A\u2297 and D\u2297, we have:\nkDvi \u2212 k\u2211 j=1 Avj = \u03b2 G\u2297vi, \u2200i \u2208 {1, . . . , k}. (45)\nSumming up (45) over all i \u2208 {1, . . . , k} gives\nD k\u2211 i=1 vi \u2212A k\u2211 i=1 vi = \u03b2G \u2297 k k\u2211 i=1 vi,\nwhich shows that if (v, \u03b2G \u2297 ) is an eigenpair of L(G\u2297) with \u2211k i=1 vi 6= 0n, then ( \u2211k i=1 vi, \u03b2\nG\u2297/k) is an eigenpair of L(G). In the case where \u2211k i=1 vi = 0n, then there exists an index j \u2208 {1, . . . , k} such that vj = \u2212 \u2211 i 6=j vj 6= 0n. Hence (45) gives\nDvj = \u03b2G \u2297\nk vj ,\nwhich shows that (vj , \u03b2G \u2297 /k) is an eigenpair of L(G). Observe that \u03b2G\u2297 = kdi for some i \u2208 {1, . . . , n}.\nWe have thus shown that any eigenvalue \u03b2G \u2297 of L(G\u2297) is either of the form \u03b2G\u2297 = k\u03b2G , where \u03b2G is an eigenvalue of L(G), or of the form \u03b2G\u2297 = kdi for some i \u2208 {1, . . . , n}.\nSince L(G\u2297) is a Laplacian matrix, its smallest eigenvalue is 0. Let \u03b2G \u2297\nnk\u22121 be the second smallest eigenvalue of L(G\u2297). Note that G\u2297 is not a complete graph since G is not complete. Therefore, \u03b2G \u2297\nnk\u22121 is bounded above by the vertex connectivity of G\u2297 (Fiedler, 1973), which is itself trivially bounded above by the minimum degree d\u2297min = min kn i=1D \u2297 ii of G\n\u2297. This implies that \u03b2G \u2297\nnk\u22121 = k\u03b2 G n\u22121, and hence\n1\u2212 \u03bbG \u2297 2 = \u03b2G \u2297\nkn\u22121 |E\u2297| = k\u03b2Gn\u22121 k2|E| = 1 k (1\u2212 \u03bbG2 ).\nProposition 1 shows that the network-dependent term in our convergence bounds is only affected by a factor k. Furthermore, note that iterations involving two virtual nodes corresponding to the same physical node will not require actual network communication, which somewhat attenuates this effect in practice."}, {"heading": "F. Additional experiments", "text": "In this section, we present additional results of decentralized metric learning. First, we discuss the comparison to the unbiased basline for metric learning on the synthetic dataset introduced in Section 4. Then, we analyze numerical experiments of decentralized metric learning on the Breast Cancer Wisconsin dataset3.\n3https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)\nSynthetic Dataset In Section 4, we discussed the results of decentralized metric learning over a synthetic dataset of n = 1, 000 points generated from a mixture of 10 Gaussians in R40 such that all gaussian means are contained in a 5d subspace.\nWe compare the logistic loss associated to our algorithm\u2019s iterates to the loss associated to the following baseline: instead of adding \u2207f(\u03b8i(t);xi, yi(t)) to its dual variable zi(t), a node i \u2208 [n] receives a vector drawn uniformly at random from the set {\u2207f(\u03b8i(t);xi, x1), . . . ,\u2207f(\u03b8i(t);xi, xn)}. The bias introduced by the random walk procedure is already shown to be very small in comparison to the objective function on Figure 3(b). Here, Figure 4 evidences the fact that this small bias has close to no influence on the optimization process for well-connected networks.\nBreast Cancer Wisconsin Dataset We now focus on decentralized metric learning on the Breast Cancer Wisconsin Dataset already used in Section 4 for AUC maximization. This dataset contains n = 699 observations of dimension 11. Figure 5(a) shows the evolution of the metric learning criterion with the number of iterations, averaged over 50 runs. As in previous experiments, there is almost no difference between the convergence rate of the Watts-Strogatz network and the complete network. Moreover, the bias term is again largely negligible when compared to the metric learning criterion, as shown on Figure 5(b)."}, {"heading": "Acknowledgments", "text": "This work was partially supported by the chair \u201cMachine Learning for Big Data\u201d of Te\u0301le\u0301com ParisTech and by a grant from CPER Nord-Pas de Calais/FEDER DATA Advanced data science and technologies 2015-2020."}], "references": [{"title": "Metric Learning", "author": ["Bellet", "Aur\u00e9lien", "Habrard", "Amaury", "Sebban", "Marc"], "venue": null, "citeRegEx": "Bellet et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bellet et al\\.", "year": 2015}, {"title": "Convergence of a Multi-Agent Projected Stochastic Gradient Algorithm for Non-Convex Optimization", "author": ["Bianchi", "Pascal", "Jakubowicz", "J\u00e9r\u00e9mie"], "venue": "IEEE Trans. Autom. Control,", "citeRegEx": "Bianchi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bianchi et al\\.", "year": 2013}, {"title": "Statistical Inference on Graphs", "author": ["Biau", "G\u00e9rard", "Bleakley", "Kevin"], "venue": "Statistics & Decisions,", "citeRegEx": "Biau et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Biau et al\\.", "year": 2006}, {"title": "Modern Graph Theory, volume 184", "author": ["Bollob\u00e1s", "B\u00e9la"], "venue": null, "citeRegEx": "Bollob\u00e1s and B\u00e9la.,? \\Q1998\\E", "shortCiteRegEx": "Bollob\u00e1s and B\u00e9la.", "year": 1998}, {"title": "Randomized gossip algorithms", "author": ["Boyd", "Stephen", "Ghosh", "Arpita", "Prabhakar", "Balaji", "Shah", "Devavrat"], "venue": "IEEE Trans. Inf. Theory,", "citeRegEx": "Boyd et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2006}, {"title": "Spectral Graph Theory, volume 92", "author": ["Chung", "Fan"], "venue": "Amer. Math. Soc.,", "citeRegEx": "Chung and Fan.,? \\Q1997\\E", "shortCiteRegEx": "Chung and Fan.", "year": 1997}, {"title": "Ranking and Empirical Minimization of U-statistics", "author": ["Cl\u00e9men\u00e7on", "St\u00e9phan", "Lugosi", "G\u00e0bor", "Vayatis", "Nicolas"], "venue": "Ann. Stat.,", "citeRegEx": "Cl\u00e9men\u00e7on et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Cl\u00e9men\u00e7on et al\\.", "year": 2008}, {"title": "Extending Gossip Algorithms to Distributed Estimation of U-Statistics", "author": ["I. Colin", "A. Bellet", "J. Salmon", "S. Cl\u00e9men\u00e7on"], "venue": "In NIPS,", "citeRegEx": "Colin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Colin et al\\.", "year": 2015}, {"title": "Dual Averaging for Distributed Optimization: Convergence Analysis and Network Scaling", "author": ["Duchi", "John", "Agarwal", "Alekh", "Wainwright", "Martin"], "venue": "IEEE Trans. Autom. Control,", "citeRegEx": "Duchi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2012}, {"title": "Distances of probability measures and random variables", "author": ["Dudley", "Richard M"], "venue": "Selected Works of RM Dudley, pp", "citeRegEx": "Dudley and M.,? \\Q2010\\E", "shortCiteRegEx": "Dudley and M.", "year": 2010}, {"title": "Algebra connectivity of graphs", "author": ["Fiedler", "Miroslav"], "venue": "Czechoslovake Mathematical Journal,", "citeRegEx": "Fiedler and Miroslav.,? \\Q1973\\E", "shortCiteRegEx": "Fiedler and Miroslav.", "year": 1973}, {"title": "Asynchronous Distributed Optimization using a Randomized Alternating Direction Method of Multipliers", "author": ["Iutzeler", "Franck", "Bianchi", "Pascal", "Ciblat", "Philippe", "Hachem", "Walid"], "venue": "In IEEE CDC,", "citeRegEx": "Iutzeler et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Iutzeler et al\\.", "year": 2013}, {"title": "Regularized Distance Metric Learning: Theory and Algorithm", "author": ["R. Jin", "S. Wang", "Y. Zhou"], "venue": "In NIPS, pp", "citeRegEx": "Jin et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Jin et al\\.", "year": 2009}, {"title": "A Randomized Incremental Subgradient Method for Distributed Optimization in Networked Systems", "author": ["Johansson", "Bj\u00f6rn", "Rabi", "Maben", "Mikael"], "venue": "SIAM J. Optimiz.,", "citeRegEx": "Johansson et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Johansson et al\\.", "year": 2010}, {"title": "Gossip-Based Computation of Aggregate Information", "author": ["Kempe", "David", "Dobra", "Alin", "Gehrke", "Johannes"], "venue": "In FOCS, pp", "citeRegEx": "Kempe et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kempe et al\\.", "year": 2003}, {"title": "A Binary Classification Framework for Two-Stage Multiple Kernel Learning", "author": ["Kumar", "Abhishek", "Niculescu-Mizil", "Alexandru", "K. Kavukcuoglu", "Daum\u00e9", "Hal"], "venue": "In ICML,", "citeRegEx": "Kumar et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kumar et al\\.", "year": 2012}, {"title": "Decentralized online optimization with global objectives and local communication", "author": ["Lee", "Soomin", "Nedi\u0107", "Angelia", "Raginsky", "Maxim"], "venue": "arXiv preprint arXiv:1508.07933,", "citeRegEx": "Lee et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2015}, {"title": "Asynchronous broadcast-based convex optimization over a network", "author": ["Nedi\u0107", "Angelia"], "venue": "Automatic Control, IEEE Transactions on,", "citeRegEx": "Nedi\u0107 and Angelia.,? \\Q2011\\E", "shortCiteRegEx": "Nedi\u0107 and Angelia.", "year": 2011}, {"title": "Distributed Subgradient Methods for Multi-Agent Optimization", "author": ["Nedi\u0107", "Angelia", "Ozdaglar", "Asuman E"], "venue": "IEEE Trans. Autom. Control,", "citeRegEx": "Nedi\u0107 et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Nedi\u0107 et al\\.", "year": 2009}, {"title": "Primal-dual subgradient methods for convex problems", "author": ["Nesterov", "Yurii"], "venue": "Math. Program.,", "citeRegEx": "Nesterov and Yurii.,? \\Q2009\\E", "shortCiteRegEx": "Nesterov and Yurii.", "year": 2009}, {"title": "Gossip Algorithms for Computing U-Statistics", "author": ["Pelckmans", "Kristiaan", "Suykens", "Johan"], "venue": "In NecSys, pp", "citeRegEx": "Pelckmans et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Pelckmans et al\\.", "year": 2009}, {"title": "Distributed Stochastic Subgradient Projection Algorithms for Convex Optimization", "author": ["S. Ram", "Nedi\u0107", "Angelia", "V. Veeravalli"], "venue": "J. Optimiz. Theory. App.,", "citeRegEx": "Ram et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ram et al\\.", "year": 2010}, {"title": "Push-Sum Distributed Dual Averaging for convex optimization", "author": ["Tsianos", "Konstantinos", "Lawlor", "Sean", "Rabbat", "Michael"], "venue": "In IEEE CDC,", "citeRegEx": "Tsianos et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tsianos et al\\.", "year": 2015}, {"title": "Problems in decentralized decision making and computation", "author": ["Tsitsiklis", "John"], "venue": "PhD thesis, Massachusetts Institute of Technology,", "citeRegEx": "Tsitsiklis and John.,? \\Q1984\\E", "shortCiteRegEx": "Tsitsiklis and John.", "year": 1984}, {"title": "Collective dynamics of \u2018small-world\u2019networks", "author": ["Watts", "Duncan J", "Strogatz", "Steven H"], "venue": "Nature, 393(6684):440\u2013442,", "citeRegEx": "Watts et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Watts et al\\.", "year": 1998}, {"title": "Distributed Alternating Direction Method of Multipliers", "author": ["Wei", "Ermin", "Ozdaglar", "Asuman"], "venue": "In IEEE CDC,", "citeRegEx": "Wei et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Wei et al\\.", "year": 2012}, {"title": "On the O(1/k) Convergence of Asynchronous Distributed Alternating Direction Method of Multipliers", "author": ["Wei", "Ermin", "Ozdaglar", "Asuman"], "venue": "In IEEE GlobalSIP,", "citeRegEx": "Wei et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wei et al\\.", "year": 2013}, {"title": "Dual averaging method for regularized stochastic learning and online optimization", "author": ["Xiao", "Lin"], "venue": "In NIPS, pp", "citeRegEx": "Xiao and Lin.,? \\Q2009\\E", "shortCiteRegEx": "Xiao and Lin.", "year": 2009}, {"title": "Dual averaging methods for regularized stochastic learning and online optimization", "author": ["Xiao", "Lin"], "venue": "JMLR, 11:2543\u20132596,", "citeRegEx": "Xiao and Lin.,? \\Q2010\\E", "shortCiteRegEx": "Xiao and Lin.", "year": 2010}, {"title": "Distributed dual averaging method for multi-agent optimization with quantized communication", "author": ["Yuan", "Deming", "Xu", "Shengyuan", "Zhao", "Huanyu", "Rong", "Lina"], "venue": "Systems & Control Letters,", "citeRegEx": "Yuan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yuan et al\\.", "year": 2012}, {"title": "Online AUC Maximization", "author": ["Zhao", "Peilin", "Hoi", "Steven", "Jin", "Rong", "Yang", "Tianbao"], "venue": "In ICML,", "citeRegEx": "Zhao et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 4, "context": "In contrast, gossip algorithms (Tsitsiklis, 1984; Boyd et al., 2006; Kempe et al., 2003; Shah, 2009) are tailored to this setting because they only rely on simple peer-to-peer communication: each agent only exchanges information with one neighbor at a time.", "startOffset": 31, "endOffset": 100}, {"referenceID": 14, "context": "In contrast, gossip algorithms (Tsitsiklis, 1984; Boyd et al., 2006; Kempe et al., 2003; Shah, 2009) are tailored to this setting because they only rely on simple peer-to-peer communication: each agent only exchanges information with one neighbor at a time.", "startOffset": 31, "endOffset": 100}, {"referenceID": 13, "context": "The most popular algorithms are based on (sub)gradient descent (Johansson et al., 2010; Nedi\u0107 & Ozdaglar, 2009; Ram et al., 2010; Bianchi & Jakubowicz, 2013), ADMM (Wei & Ozdaglar, 2012; 2013; Iutzeler et al.", "startOffset": 63, "endOffset": 157}, {"referenceID": 21, "context": "The most popular algorithms are based on (sub)gradient descent (Johansson et al., 2010; Nedi\u0107 & Ozdaglar, 2009; Ram et al., 2010; Bianchi & Jakubowicz, 2013), ADMM (Wei & Ozdaglar, 2012; 2013; Iutzeler et al.", "startOffset": 63, "endOffset": 157}, {"referenceID": 11, "context": ", 2010; Bianchi & Jakubowicz, 2013), ADMM (Wei & Ozdaglar, 2012; 2013; Iutzeler et al., 2013) or dual averaging (Duchi et al.", "startOffset": 42, "endOffset": 93}, {"referenceID": 8, "context": ", 2013) or dual averaging (Duchi et al., 2012; Yuan et al., 2012; Lee et al., 2015; Tsianos et al., 2015), some of which can also accommodate constraints or regularization on \u03b8.", "startOffset": 26, "endOffset": 105}, {"referenceID": 29, "context": ", 2013) or dual averaging (Duchi et al., 2012; Yuan et al., 2012; Lee et al., 2015; Tsianos et al., 2015), some of which can also accommodate constraints or regularization on \u03b8.", "startOffset": 26, "endOffset": 105}, {"referenceID": 16, "context": ", 2013) or dual averaging (Duchi et al., 2012; Yuan et al., 2012; Lee et al., 2015; Tsianos et al., 2015), some of which can also accommodate constraints or regularization on \u03b8.", "startOffset": 26, "endOffset": 105}, {"referenceID": 22, "context": ", 2013) or dual averaging (Duchi et al., 2012; Yuan et al., 2012; Lee et al., 2015; Tsianos et al., 2015), some of which can also accommodate constraints or regularization on \u03b8.", "startOffset": 26, "endOffset": 105}, {"referenceID": 30, "context": ", Area Under the ROC Curve (AUC) maximization (Zhao et al., 2011), distance/similarity learning (Bellet et al.", "startOffset": 46, "endOffset": 65}, {"referenceID": 0, "context": ", 2011), distance/similarity learning (Bellet et al., 2015), ranking (Cl\u00e9men\u00e7on et al.", "startOffset": 38, "endOffset": 59}, {"referenceID": 6, "context": ", 2015), ranking (Cl\u00e9men\u00e7on et al., 2008), supervised graph inference (Biau & Bleakley, 2006) and multiple kernel learning (Kumar et al.", "startOffset": 17, "endOffset": 41}, {"referenceID": 15, "context": ", 2008), supervised graph inference (Biau & Bleakley, 2006) and multiple kernel learning (Kumar et al., 2012), to name a few.", "startOffset": 89, "endOffset": 109}, {"referenceID": 7, "context": "Although gossip algorithms have recently been introduced to evaluate such pairwise functions for a fixed \u03b8 (Pelckmans & Suykens, 2009; Colin et al., 2015), to the best of our knowledge, efficiently finding the optimal solution \u03b8 in a decentralized way remains an open challenge.", "startOffset": 107, "endOffset": 154}, {"referenceID": 30, "context": "For instance, in AUC maximization (Zhao et al., 2011), binary labels (`1, .", "startOffset": 34, "endOffset": 53}, {"referenceID": 0, "context": "Other popular instances of Problem (2) include metric learning (Bellet et al., 2015), ranking (Cl\u00e9men\u00e7on et al.", "startOffset": 63, "endOffset": 84}, {"referenceID": 6, "context": ", 2015), ranking (Cl\u00e9men\u00e7on et al., 2008), supervised graph inference (Biau & Bleakley, 2006) and multiple kernel learning (Kumar et al.", "startOffset": 17, "endOffset": 41}, {"referenceID": 15, "context": ", 2008), supervised graph inference (Biau & Bleakley, 2006) and multiple kernel learning (Kumar et al., 2012).", "startOffset": 89, "endOffset": 109}, {"referenceID": 7, "context": "To go around this problem, we rely on a gossip data propagation step (Pelckmans & Suykens, 2009; Colin et al., 2015) so that the nodes are able to compute biased estimates of \u2207fi(\u00b7) while keeping the communication and memory overhead to a small level for each node.", "startOffset": 69, "endOffset": 116}, {"referenceID": 7, "context": "Our work builds upon the analysis of Duchi et al. (2012), who proposed a distributed dual averaging algorithm to optimize an average of univariate functions f(\u00b7;xi).", "startOffset": 37, "endOffset": 57}, {"referenceID": 8, "context": "Note that C2(T ) corresponds to the network dependence for the distributed dual averaging algorithm of Duchi et al. (2012) while the term C3(T ) comes from the bias of our partial gradient estimates.", "startOffset": 103, "endOffset": 123}, {"referenceID": 8, "context": "In the asynchronous setting, no convergence rate was known even for the distributed dual averaging algorithm of Duchi et al. (2012), which deals with the simpler problem of minimizing univariate functions.", "startOffset": 112, "endOffset": 132}, {"referenceID": 12, "context": "following criterion (Jin et al., 2009):", "startOffset": 20, "endOffset": 38}, {"referenceID": 8, "context": "Convergence Proof for Synchronous Pairwise Gossip Dual Averaging In (Duchi et al., 2012), the following convergence rate for distributed dual averaging is established:", "startOffset": 68, "endOffset": 88}, {"referenceID": 8, "context": "As denoted in (Duchi et al., 2012), the update rule for Z can be expressed as follows:", "startOffset": 14, "endOffset": 34}, {"referenceID": 4, "context": "We assume for simplicity that each node has a clock ticking at a Poisson rate equals to 1, so it is equivalent to a global clock ticking at a Poisson rate of n, and then drawing an edge uniformly at random (see (Boyd et al., 2006) for more details).", "startOffset": 211, "endOffset": 230}], "year": 2016, "abstractText": "In decentralized networks (of sensors, connected objects, etc.), there is an important need for efficient algorithms to optimize a global cost function, for instance to learn a global model from the local data collected by each computing unit. In this paper, we address the problem of decentralized minimization of pairwise functions of the data points, where these points are distributed over the nodes of a graph defining the communication topology of the network. This general problem finds applications in ranking, distance metric learning and graph inference, among others. We propose new gossip algorithms based on dual averaging which aims at solving such problems both in synchronous and asynchronous settings. The proposed framework is flexible enough to deal with constrained and regularized variants of the optimization problem. Our theoretical analysis reveals that the proposed algorithms preserve the convergence rate of centralized dual averaging up to an additive bias term. We present numerical simulations on Area Under the ROC Curve (AUC) maximization and metric learning problems which illustrate the practical interest of our approach.", "creator": "LaTeX with hyperref package"}}}