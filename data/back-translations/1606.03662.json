{"id": "1606.03662", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jun-2016", "title": "Store Location Selection via Mining Search Query Logs of Baidu Maps", "abstract": "Choosing a good location when opening a new store is critical to a company's future success. Traditional methods include manual offline survey, which is very time-consuming, and analytical models based on census data that cannot be adapted to the dynamic market. The rapid availability of big data from various types of mobile devices, such as online survey data and offline position data, gives us the ability to develop automatic and accurate data-driven predictive models for the placement of stores. In this paper, we propose a Demand Distribution Driven Store Placement (D3SP) framework for the placement of stores by reducing search query data from Baidu Maps. D3SP first identifies the spatial-temporal distributions of customer requests to different business services based on query data from Baidu Maps, the largest online map search engine in China, and determines the gaps between demand and performance. We then determine the candidate locations by predicting the number of potential locations already used by optimizing the cluster of such location models.", "histories": [["v1", "Sun, 12 Jun 2016 03:42:10 GMT  (3641kb,D)", "http://arxiv.org/abs/1606.03662v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.IR", "authors": ["mengwen xu", "tianyi wang", "zhengwei wu", "jingbo zhou", "jian li", "haishan wu"], "accepted": false, "id": "1606.03662"}, "pdf": {"name": "1606.03662.pdf", "metadata": {"source": "CRF", "title": "Store Location Selection via Mining Search Query Logs of Baidu Maps", "authors": ["Mengwen Xu", "Tianyi Wang", "Zhengwei Wu", "Jingbo Zhou", "Jian Li", "Haishan Wu"], "emails": ["xumengwen@baidu.com", "wangtianyi02@baidu.com", "wuzhengwei@baidu.com", "zhoujingbo@baidu.com", "wuhaishan@baidu.com", "lijian83@mail.tsinghua.edu.cn"], "sections": [{"heading": null, "text": "Keywords Business; Store placement; Multi-source data; Machine learning"}, {"heading": "1. INTRODUCTION", "text": "Selecting a location when opening a new store is crucial for future business development: a good location may lead to very good business, while an incorrect one may result in serious business risk and even the failure of business.\nMany efforts have been made to address this task both qualitatively and quantitatively. For example, one can conduct offline manual survey on one potential location. And many business consulting companies provide consulting services by collecting and mining data from third parties such as census and demographic data from the government. Some\n\u2217Haishan Wu is the corresponding author.\nprevious work [2, 25, 5] study optimal location problem as a covering problem which maximizes the number of people a location can attract.\nNowadays, personal mobile devices are ubiquitous with large scale mobile data, making it possible for us to offer big data driven solutions for business solutions, especially for business location selection in our topic here. In a recent work [14], the authors have developed a data-driven approach to solve the problem of retail store placement by predicting the check-in numbers at given locations using linear supervised learning model. However, these models do not capture the targeted user demands (i.e., demands for a category of stores).\nIn this paper, we propose a Demand Distribution Driven Store Placement(D3SP) framework, and utilize multiple spatialtemporal data sources to accomplish this task. Given the category of a new store to be opened, the aim of our ap-\nar X\niv :1\n60 6.\n03 66\n2v 1\n[ cs\n.A I]\n1 2\nJu n\n20 16\nproach is to identify several most promising locations that meet user demands and attract a large number of potential customers. In this paper, we take advantage of search query data from Baidu Maps and integrate other types of spatial-temporal data sources such as POI data etc to solve the problem.\nLocation based applications like map search and navigation systems have been developed in recent years. The will of users going to some places can be inferred from this kind of data (i.e., map query data), demonstrating the potential consumptive demands of users [24]. Generally, the strategy of finding optimal placement is to find the most suitable locations from a list of candidate locations [23]. Here, we define those candidate locations as the places where demands exceed supplies. An example of finding optimal placement for opening a new \u201cHaidilao\u201d using D3SP is shown in Figure 1. For example, when users query \u201cHaidilao\u201d (a popular hot pot restaurant in China), their locations are recorded. In Figure 1(b), after excluding the locations within 5km around the existing stores, there are still many places that do not meet user demands. It is possible to cluster the gaps between demand and supply (Figure 1(c)), and then optimize the placement to obtain most customers (Figure 1(d)).\nLocation placement is naturally a ranking problem. There are at least two methods to achieve. We can first predict the customer numbers and then rank manually, or utilize learn to rank methods directly. In this paper, we will try both and evaluate the results with real-world cases. A lot of factors can impact the number of customers a location can attract. We consider economic development, popularity and transportation convenience [22] in our model. The models are trained and validated with existing stores\u2019 locations and customers\u2019 behavior.\nOur work makes the following contributions:\n\u2022 First, we identify the spatial distribution of user demands from map query data, and obtain the places that demands exceed supplies. Here, we extracted two types of demands of real users: specific demands (for specific brand of chain store) and general demands (for a general category) from the data.\n\u2022 Second, we propose practical features and models to rank the candidate locations. We utilize both supervised regression models to predict the number of customers, and learn-to-rank models to rank the candidate locations directly. Novel features such as distance to the center of the city, popularity of specific area category and real estate price nearby are also proposed.\n\u2022 Finally, we evaluate our methods with real-world cases, and developed a completed system to find optimal placement for opening a new store. D3SP is a crucial part of the location-based business support system developed in Baidu. We evaluate D3SP on both experiments and the real cases. The experiments show that our framework predicts accurately for various categories, and the real cases show that our framework works well in the real world."}, {"heading": "2. DATA AND FRAMEWORK", "text": "2.1 Data and Preprocessing\nIn this section, we provide details of the heterogeneous data sets we use in this paper, as well as the preprocessing of these data sets. The data sets include map query data, POI data and WiFi Connection data.\nLocation query data from Baidu Maps. Map query data contains over one billion queries from 500 million users using Baidu Maps on mobile phones. Each map query record has the following information: an anonymized user ID, timestamp, latitude and longitude of the location where the query was issued, query keywords with the associated POI attributes.\nWhen a user searches for a place or navigates a route to a place using Baidu Maps, the query action reflects a demand of a specific place or a category. The actual location where the user issues a query also implies a spatial demand. For example, a query [ui, 2015-08-08 08:42:28, (116.34, 40.02), \u201cStarbucks\u201d] means that the user ui wants to have coffee at location (116.34, 40.02). Further analysis can be found in Section 3.\nPOI data. Point-of-Interest(POI) in a city is tightly related to people\u2019s consumptive behavior. We can learn a lot from existing POIs that are similar to a new store to be opened. The POI data set is a collection of POIs. For each POI p, its attributes include POI ID p.id, location p.l, or p.x and p.y, category p.c and other detailed information. Attribute \u201ccategory\u201d has two hierarchical levels. For example, category \u201chotel\u201d is the upper level, and \u201cexpress inn\u201d is the subcategory of \u201chotel\u201d.\nWiFi Connection data. We obtained WiFi Connection data from a third-party data source, which contains records of 3-month historical WiFi connections from June 1, 2015 to August 30, 2015. Each record contains an anonymized user id, timestamp, and the corresponding POI.\nWiFi Connection data can be a good indicator of customer numbers, and serves as part of ground truth in prediction of customer numbers. It has several advantages over the checkin data used in previous work [14]. First, only the customers can connect the WiFi in the POI, which eliminates the situation of cheated check-ins. Meanwhile, WiFi Connection data has usually many more records than the check-in data for a single user. A user often connects to wifi in restaurants or hotels, but does not necessarily check in her locations.\nIntegrating the data sets. By integrating WiFi Connection and POI, we obtain the total number of customers for each POI. Note that each user can generate several records in one day at a specific POI, and some POI may have several accessing points. However, for a POI, the number of customers in one day should be the appearance of all the users in that day. Therefore, we clean the data by maintaining one record for a user in one day at a specific POI. Each record contains a POI id, POI category, POI name, POI location and POI customer number. In further analysis, we use the POI customer number to measure how good a store location is.\nData privacy. In this paper we were very careful to protect the user privacy. We have set several key steps and protocols to protect the privacy:\n\u2022 First, all ids in our data are hashed and anonymous. None can be linked to any real-world identifier of a person. So we do not know the offline behavior of any real person.\n\u2022 Second, we have a very strict agreement with the third party that the WiFi Connection data is kept secure, safe and anonymous. Each id is encrypted, and is not even linkable to the ids in map query data.\n\u2022 Finally, we are focused on analysis in aggregation level. For example, we aim to predict the number of customers of a location as a whole, instead of predicting whether a specific user will visit. None individual level analysis is deployed in our paper."}, {"heading": "2.2 Framework and methodology", "text": "A promising location for a new store has two requirements. First, it should meet users\u2019 demands while there are not too many competitions. Second, it needs to attract a significant number of customers. In this paper, we aim to first figure out a few candidate locations by detecting demand centers, and then rank them by predicting the custom number that each location may have. Figure 2 shows the overall framework of our paper, and more details are as follows.\nIn a city, there can be many locations to choose for opening a store. Our first step is to find several demand centers Ld = {l1, l2, ..., lm} as candidate locations for a store category C or a specific brand of chain stores B. Map query data is used to find the demand points where the users query a POI or a POI belonging to the same category. Thus, we obtain the demand centers Ld = l1, \u00b7 \u00b7 \u00b7 , lm from those locations.\nThen, we transform the problem into a global ranking problem. Our goal is to rank the locations in Ld for opening a new store belonging to category. we achieve this by predicting the customer number for each location in Ld. Here we train a supervised machine learning model with the customer numbers of existing stores. The features are mined\nfrom an area Al. Here Al is a disc centered at l with radius r. Considering users\u2019 walking distance and GPS position shifting, we set r to be 1 km. With this model, we are able to predict the custom numbers of the candidate demand centers Ld will have. Locations with higher values are more desirable to open new stores."}, {"heading": "3. OBTAINING DEMAND CENTERS", "text": "Our work is inspired by the fact that map queries reflect users\u2019 targeted demands. Each query contains a source place and a destination. The source place has demands while the destinations can supply the demands. An ideal place for a new store to be opened is where there are many demands but few supplies. In this section, we aim to identify such places with the knowledge of map query data. We start from the analysis of user demands, and then propose methods to identify the demand centers."}, {"heading": "3.1 User Demand Analysis", "text": "An important part of our method is the modeling of user demands. We will first demonstrate that map query reflects user demands, and it is highly correlated with users\u2019 real visitation. We analyze the percentage of the query sessions\nwhich users actually go to that place over all the query sessions. We utilize the method in [24] which assumes that a queried location is actually visited by the user if there is at least one location record in user\u2019s next 1.5-day mobility trace, and the distance of the location record and the queried location is less than 1 km. As shown in Figure 3, the normalized number of map query and real visitations have similar dynamic patterns in a three months period. In Figure 3(b) we also plot the coefficient of determination R2. The numbers of map queries and real visitations have a correlation up to 0.85. These results confirm that map queries are highly correlated with real visitations, and the number of map queries can be indicators of customer numbers and real user demands. More specifically, the visitation ratio can reach the ratio nearly 50%, which is also a strong evidence that there is a relationship between map queries and user demands.\nNext, we will further analyze user demands via map query data. Remind that a map query record has the following attributes: timestamp T , latitude lat and longitude lng of the location where the query was issued, query keyword, attributes of POI. Formally, we denote a demand point as D = (lat, lng, t). That is, a demand point contains the locations and a timestamp where and when the demand happens. We extracted two types of demands of real users. The first type is specific demands. This type of demands can be extracted from the route data in Baidu Maps. For example, a user has a specific need that he wants to get to Starbucks. He or she searches for the routes from his or her current location (lat, lng) to a store of Starbucks at time t. This implies that the user has a specific demand (lat, lng, t) on Starbucks. Another type of demands are general demands. An example is that a user has a general demand that he wants to drink some coffee, but he does not have preference on brands. This type of demands can be extracted from the \u201cnearby\u201d queries which return POIs nearby according to the keyword.\nAfter we define both specific and general demands, we conduct analysis on the demand points we extract from queries. Our analysis basically identifies the temporal and spatial differences among different queries. Here we take Starbucks and Haidilao (a popular hotpot restaurant in China) as examples.\nActive time. In Figure 4 and 5 we plot the active time of the demand points. We find different demands are active at different time. For example, people usually get to Star-\nbucks during the day, while they go to Haidilao at noon and evening for meals. In a week, people prefer to go to Haidilao on Friday, Saturday and Sunday, while people do not show obvious preference on Starbucks.\nEffective distance. We also realize that people may tolerate different distances for different stores. In Figure 6, we plot the distribution of distance between source and destination. While 80% queries of Starbucks are within 2 km, up to 40% queries of Haidilao are more than 5 km. This is understandable, since few people will travel 5 km just for a coffee. Therefore, the nearby area of the location where the user makes a query can be seen as a place where the user demand for the queried place.\nThe above analysis reveals that user demands may have various features and patterns. When we further detect the demand centers, we need to take the type of demands into consideration."}, {"heading": "3.2 Finding Demand centers", "text": "To find demand centers, we have three steps: identifying demand points, excluding supplies, and clustering demands.\nIdentify demand points. In the first step, we will identify and characterize the demands, e.g., Starbucks. As we explain before, we extract timestamp and location from each query, including specific demands with targeted keywords Starbucks or general demands with categories or tags of coffee from \u201cnearby\u201d queries. We then characterize the temporal and spatial features of demands.\nExclude supplies. After we identify the geographic distribution of demand points, we need to identify the gap between demands and supplies. For specific demands, we directly exclude areas where there are already supplies. Here the exclusion is based on distance features. From the distribution of source and destination distance, we identify a threshold of 80%, i.e. 80% of users will not get to a store farther from corresponding distance. Then for each existing store, we consider demand points within the threshold are supplied. Thus these demand points are excluded. The remaining demand points are the demand-supply gap points where demands exceed supplies. For example in Figure 6, 80% of the users search\u201cStarbucks\u201dare within distance 2km. The demand points within 2km from the existing stores are excluded.\nFor general demands, we exclude supplies with some probabilities, because the user has the potential to a new store. We calculate the distance d(lu, ln) between the nearest ex-\nisting store and the demand location lu = (lat, lng) of user u. Also the number of existing stores nearby is defined as N . For a user u, if d(lu, ln) is large, the probability of the demand to be satisfied is low. On the other hand, if N is large, the probability is high. Therefore, we define two scores according to the two intuitions. One is the distance score Sd = 1 \u2212 e\u2212d(lu,ln) 2/\u03c32 , another is the supply score Ss = e \u2212 N . The score of a demand to be remained Sr = \u03b1Sd + (1 \u2212 \u03b1)Ss. Here we set \u03c3 = 300, = 0.5 and \u03b1 = 0.7. Figure 7(a) shows the demand points of coffee shops and existing stores in an area. Figure 7(b) shows the remaining demand points after we remove the possible satisfied ones. We can see that the demand points near the existng stores are more likely to be excluded.\nClustering demands. After we identify the demandsupply gap points, obtaining a place for a new store is still not trivial. This is because the demand points are placed in space without any regularized shapes. Here, we leverage machine learning clustering algorithms, and select the cluster centers. Since we do not know the exact number of clusters we will have, and would require a center point of each cluster, we use MeanShift [6] as our algorithm. We set the bandwidth parameter as the distance threshold we identify in the previous step. This algorithm automatically clusters the demand-supply gap points and returns a center for each cluster. we denote the center points as demand centers which are candidate locations for store placement. The star in Figure 7(b) is the demand center we find."}, {"heading": "4. RANKING PROMISING LOCATIONS", "text": "With the demand centers, we next rank these promising locations. In this paper we utilize supervised machine learning models to rank the locations. There are two directions. First, we can directly apply learn-to-rank methods. Second, we can predict the number of customers with regression models, and then rank based on the predicted customer numbers. We consider both in our paper, as illustrated in Sec 4.1. Then we will introduce the features we use in our models."}, {"heading": "4.1 Ranking Algorithms", "text": "Given a list of demand centers Lm, we utilize the supervised learning methods to rank or predict the number of consumers of a new store located at l \u2208 Lm. The locations with higher scores are the optimal placements.\nBaseline. The baseline method is to rank Lm randomly,\nand the locations rank at top are the results.\nLearn to rank. We first directly apply learn to rank methods. The method we use in this paper is LambdaMART [4], which is a widely used learn to rank method in many works and the winner of 2010 Yahoo! Learning To Rank Challenge. It is a combination of boosted tree MART and a learn to rank method LambdaRank.\nRegression. For regression method, we consider the linear regression with regularization (Lasso) and the kernel methods including Support Vector Regression (SVR) [10] and Kernel ridge regression (KRR) [18]. We also consider two ensemble methods Random Forests (RF) and Gradient Boosting Decision Tree (GBDT).\nMathematically, Lasso consists of a linear model trained with L1 prior as regularizer. The objective function to minimize is:\nmin w\n1\n2nsamples ||Xw \u2212 y||22 + \u03b1||w||1 (1)\nwhere X is feature vectors and y is the target score. \u03b1 is a constant and ||w||1 is the `1-norm of the parameter vector.\nIn SVR, training vectors are implicitly mapped into a higher (maybe infinite) dimensional space by the kernel function. KRR combines Ridge Regression (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.\nRandom Forests[3] and Gradient Boosting Decision Trees[7] are two popular algorithms of the ensemble method. Random Forests is a notion of the general technique of random decision forests. It constructs a multitude of decision trees at training time, and outputs the class that is the mean prediction of the individual tree. Each tree in the ensemble is built from a sample drawn with replacement from the training set.\nGradient Boosting is typically used with decision trees of a fixed size as base learners. For this special case Friedman proposes a modification to Gradient Boosting method which improves the quality of fit of each base learner."}, {"heading": "4.2 Features", "text": "In this part, we will introduce the features mined from the multi-source data. Those features can reflect the quality of the area for the new store including functionality, transportation convenience, competition, economic development\nand so on. When given a location l and the category C of the new store to be opened, the features Fl can be mined from the integrative dataset which is indexed in the geographic POI index. Remind that the Area around l is Al which is a disc centered at l with radius r (1 km). Distance to the center of the city. The popularity of a store is not only related with the local information about the location, but also related with its geographic position in a city. To see how the customers distribute for a kind of stores in a city, we draw the heat maps of the consumption behaviors for express inns and coffee shops in Beijing, respectively in Figure 8. The hotter(red color) the color of a point is, the more customers there are. We find locations near the center of a city usually attract more customers.\nFrom the geographic aspect, we consider the distance between the location l and the center of the city c (here we consider the city of Beijing and the center is (116.404, 39.912)).\nFl = dist(l, c) (2)\nWe can see from the data analysis that the distance of a location to the center of city influences the popularity. Traffic convenience. Here, we use the number of transportation stations(including bus stations and subway stations) in AI to denote the traffic convenience.\nFl = |{t \u2208 T : dist(t, l) < r}| (3)\nT is the set of transportation stations in Beijing. POI density. Since the area of each Al for l \u2208 L is the same, the number of POIs in Al is used to present the density of Al which is defined as\nFl = |{p \u2208 P : dist(p, l) < r}| = N(l). (4)\nwhere P is the set of all POIs in a city. Popularity of specific area category. We use the category of most POIs in Al to define the area category AC(l) = argmaxNc(l). The set of all the POIs of category C is defined as PC . Then, the popularity of specific area category is the average number of WiFi consumers for a category C\u2032 over all POIs in PC and its area category is ACl. Formally,\nFl =\n\u2211 p\u2208P \u2032 W (p)\n|P \u2032| , P \u2032 = {p|p.c = C\u2229AC(p.l) = C\u2032, p \u2208 P},\n(5) where p.c and p.l are the category and location of p, and W (p) is the number of WiFi consumers of POI p. Competition. We also consider the competition between the stores belonging to the same category. We define the number of POIs belonging to category C in Al is Nc(l), and the total number of POIs in Al is N(l). Then the competition is defined as the ratio of Nc(l) and N(l), which is\nFl = Nc(l)\nN(l) . (6)\nArea popularity. Also, the popularity of Al can influence the popularity of l. The people consumed at places in Al are the potential consumers for a new store opened at l. The popularity of an area Al is defined as\nFl = \u2211 p\u2208Al W (p). (7)\nTo avoid self-correlation of the data, we eliminate the connections of the test POI when we evaluate the performance.\nReal estate price nearby. The real estate price of an area reflects the economic development of a location in the area. Thus, given a location l, we compute the average price of the nearest 5 real estate in 2km to estimate the price."}, {"heading": "5. EVALUATION", "text": "Given a POI category or a specific brand, we first evaluate the performance of our prediction method using existing POIs belonging to the same category or brand. Then, we show some real cases of store placement using our framework."}, {"heading": "5.1 Metrics", "text": "After we predict the scores for each POI, we obtain a ranked list of locations LP = (l1, l2, \u00b7 \u00b7 \u00b7 , l|L|). The ranked list LR of locations based on the actual popularity (number of customers) of those POIs is also obtained from the POI-Customer dataset. The position of location li in LR is denoted with rank(li).\nIn order to evaluate the ranking performance of our result, we utilize the nDCG@k (Normalized Discounted Cumulative Gain) metric [12] and the nSD@k (normalized symmetric difference) metric proposed in [16]. nDCG@k. Discounted cumulative gain (DCG) is a measure of ranking quality. DCG measures the usefulness, or gain, of an item based on its position in the result list. The gain is accumulated from the top of the result list to the bottom with the gain of each item discounted at lower ranks. The DCG at a particular rank position p is defined as\nDCGp = p\u2211 i=1 2reli \u2212 1 log2(i+ 1)\n(8)\nSorting documents of the result list by relevance, also called Ideal DCG (IDCG) till p. The normalized discounted cumulative gain(nDCG), is computed as:\nnDCGp = DCGp IDCGp\n(9)\nA relevance score for an instance li is its relative position in the actual ranking LR, i.e., relli = |L|\u2212rank(li)+1 |L| . nSD@k The normalized symmetric difference metric provides an analysis of comparing two top-k lists. Given two top-k lists, \u03c41 and \u03c42, the normalized symmetric difference metric is defined as:\nd\u2206(\u03c41, \u03c42) = 1\n2k |(\u03c41 \\ \u03c42) \u222a (\u03c42 \\ \u03c41)| (10)\nd\u2206 value is denoted by nSD@k which is always between 0 and 1."}, {"heading": "5.2 Evaluation data and algorithms", "text": "We use two categories of stores which are express inns and coffee shops to evaluate the performance of our framework.\nFor each category, the test data are two brands of stores, which is to eliminate the bias of ranking and to avoid overfitting. Specifically, for coffee shops, Starbucks and Costa are chosen as the test data, and for express inns, two famous brands in Beijing \u201cHome-Inn\u201d and \u201cJin Jiang Zhi Xing\u201d are chosen. Also, the training data sets are all POI belonging to category \u201ccoffee shop\u201d and \u201cexpress inn\u201d in Beijing except the POIs in test data. In detail, express inns exclude\u201cHomeInn\u201d are in dataset \u201cInn 1\u201d and those exclude \u201cJin Jiang Zhi Xing\u201d are in dataset \u201cInn 2\u201d. In the same way, \u201cCoffee shops 1\u201d and \u201cCoffee shops 2\u201d are the two training set that exclude \u201cStarbucks\u201d and \u201cCosta\u201d, respectively. The number of items of each evaluation set are shown in Table 1.\nWe have used the corresponding implementations that are public available through the Scikit-learn machine learning package [19]. The abbreviation of the evaluated algorithms and the best parameter setting after several experiments are listed below:\n\u2022 We use Linear to denote the linear regression algorithm Lasso, the regularization parameter here equals to 10\u22122. \u2022 KernelR is the abbreviation of Kernel Regression. The\nkernel function of the Kernel Regression we use here is radial basis function kernel (RBF), and the regularization parameter is set to be 0.1. \u2022 For SVR, the kernel function we use is also RBF. The\npenalty parameter of the error term is set to be 1.0, and the kernel coefficient is set to be 0.1. \u2022 RF is short for Random Forests. The number of trees\nis 10, the minimum number of samples required to split an internal node is set to be 2. The function to measure\nthe quality of a split is mean square error. \u2022 For the Gradient Boosting for regression (GBR), the\nloss function to be optimized is least squares regression, and the number of boosting stages is 100. \u2022 The baseline algorithm is to randomly rank the list of\ntest set. The accuracy result is the mean of 100 times experiments. \u2022 LambdaMART is a famous learn-to-rank algorithm.\nThe number of boosting stages is 100, and the learning rate is 0.1, the minimum loss required to make a further partition is 1.0.\nAlso the implementation of system is shown in Figure 9. The whole system has four functions including detecting spatial distribution of different kinds of users, obtaining demand centers, location analysis and location comparison. Our framework D3SP covers two parts: obtaining demand centers and location analysis."}, {"heading": "5.3 Feature importance", "text": "Before we show the results of prediction algorithms, we use Random Forests with the gini impurity to generate the feature importance for the two categories of POIs which is shown in 10. The features from top to down are the real estate price nearby, the popularity of the area, the number of POIs, the competition, the transportation, the distance to the center of the city and the category of an area. The feature importance of coffee shops and express inns are quite different. For coffee shops, the key features are the popularity of the area, the competition and the distance to the center. However, real estate price, competition and transportation are the key features for express inns. This is not\nsurprising. The real estate price can influence the price of the express inns. When tourists choose a hotel, they tend to choose the one that is cheap and traffic convenient. Coffee shops usually attract people nearby. Competition exists everywhere and is important for all kinds of POIs. From the experimental results, we can see that the importance of features varies with the category of the store, and it\u2019s necessary to learn from the stores belonging to the same category."}, {"heading": "5.4 General demands accuracy", "text": "In this subsection, we evaluate the accuracy in the situation of general demands, and the categories are the coffee shops and express inns.\nWe first evaluate on the test sets in Beijing using the above two metrics with different learning methods. Evaluation results in Table 3 show that our results using learn-to-rank algorithm and ensembled methods are far more improved with respect to the random baseline method. Accuracy with nDCG@10. We measure the performance of the algorithms trained on the features we extracted. As illustrated above, we know that the larger nDCG@10 is the more accuracy the result is. Table 3 show the accuracy results evaluated with nDCG@10 for both coffee shops and express inns.\nWith regard to the coffee shops, the best performance are using Random Forests and LambdaMART with nDCG@10 = 0.774 and nDCG@10=0.755 for \u201cStarbucks\u201d and \u201cCosta\u201d, respectively. The baseline results are nDCG@10 = 0.513 and nDCG@10 = 0.523. Not only Random Forests and LambdaMART, but also the other algorithms outperform the baseline algorithm. Learn-to-rank algorithm has larger nDCG@10 for the two test sets of express inns, whereas linear regression and baseline (randomly ranking) have lower nDCG@10. For example, in the \u201cHome Inn\u201d test, nDCG@10 for kernel regression, SVR, Random Forests, GBR and LambdaMART are 0.640, 0.680, 0.720, 0.685 and 0.736, respectively, while NDCG@10 of Linear Regression and Baseline are 0.510 and 0.540 which are less than the former ones. The JinJiang test shows the similar results, and the best accuracy is 0.767. Accuracy with nSD@10. Unlike nDCG@10 evaluates the ranking of the lists, we use nSD@10 to evaluate the distance of two top-k lists which are the top-k real list and the top-\nk experimental list. Note that the smaller the nSD@10 is, the more similar the two top-k lists are. Table 3 also shows nSD@10 for both test sets of the two categories. As the result of coffee shops shown, the performances of Ensemble method algorithms are still better than the linear algorithm and the baseline algorithm. For \u201cStarbucks\u201d test, the baseline is 0.93, however, nSD@10 of Linear Regression, Kernel Regression, SVR, Random Forests, GBR and LamdaMART are 0.9, 0.9, 0.9, 0.6, 0.8 and 0.8. For \u201cCosta\u201d test, the baseline is 0.87, and the best result are Random Forests and LambdaMART with nSD@10= 0.6 which means that there are at least 4 predicted locations are in the top-10 of the real lists. Results show that the above conclusion is also similar for the express inns. The best nSD@10 for \u201cHome Inn\u201d and \u201cJinJiang\u201d are 0.8 and 0.7."}, {"heading": "5.5 Specific demands accuracy", "text": "Unlike general demands, for specific demands, we evaluate on two brands of chain coffee shops and chain express inns which are \u201cStarbucks\u201d and \u201cHome Inn\u201d using nDCG@5 and nSD@5. We randomly choose 20% of the data as test and remaining as training data. Table 2 shows the average results of the 10 times repeated experiments.\nComparing with the baseline 0.510, Random Forests is the optimal learning algorithm for\u201cStarbucks\u201dwith nDCG@5=0.740 which offer about 45% improvement. For \u201cHomeInn\u201d, the optimal learning algorithm is LambdaMART with nDCG@5= 0.748. Also, the lowest nSD@5 are 0.56 and 0.65 for \u201cStarbucks\u201d and \u201cHome Inn\u201d respectively. Above results show that our framework also works well on the chain stores."}, {"heading": "5.6 Real cases", "text": "Now we study two real cases which can somehow reflect the effectiveness of our framework(both the obtaining demands part and the learning part). The two cases are \u201cStarbucks\u201d opened at January, 2016 and chain hotpot restaurant \u201cHaiDiLao\u201d opened at September, 2015. We obtain the location with demands using the map query data from April, 2015 to June, 2015 which is far early from the existence of two new stores. The locations with demands of \u201cStarbucks\u201d and \u201cHaiDiLao\u201d are shown in Figure 11(a) and Figure 11(b), respectively. Note that we exclude the existing store opened\nat that time. We train the Random Forests model using the two brands of existing chain stores. The ranking of the locations with demands of \u201cHaiDiLao\u201d is [\u20184\u2019, \u20181\u2019, \u20189\u2019, \u20182\u2019, \u20186\u2019, \u201812\u2019, \u20185\u2019, \u201811\u2019, \u20188\u2019, \u201810\u2019, \u20187\u2019, \u20183\u2019], and the distance between location \u20181\u2019 which is in the top-3 of the ranking list and the new opened store is about 1km. For \u201cStarbucks\u201d, the predicted ranking list is [\u20182\u2019, \u20186\u2019, \u20185\u2019, \u20184\u2019, \u20181\u2019, \u20183\u2019] . Location \u20186\u2019 is only 200m away from the real location."}, {"heading": "6. RELATED WORK", "text": "The store placement problem has be studied by researchers from various fields. Researchers have concentrated on various techniques including spatial interaction models, Multiple regression Discriminant analysis and so on [11] . Spatial interaction models are based on the assumptions that the intensity of interaction between two locations decreases with their distance and that the usability of a location increases with the intensity of utilization and the proximity of comple-\nmentarily arranged locations [1, 2, 25, 15]. Specifically, work in [15] employs spatial interaction theory, customer density estimates and minimax decision criterion to address site selection issues. Authors of [2, 25] utilize theoretic models of optimal location by maximizing the number of residents it can attracts in Euclidean space or road network. By saying a location attracts a resident, we mean that the location is closest to the place the resident live among all the existing stores. However, in reality, people are moving and the location can attracts not only residents near it. Multiple regression Discriminant analysis [21] is a location analyst that has been employed to produce a series of sales forecasts for both new and existing stores, which is tested and calibrated across a number of different scenarios and is often used as a benchmarking tool for future development. Jensen [13] proposed a spatial network based formulation of the problem, where nodes are differrient types of retail stores and weighted signed links are defined to model the attraction\nand repulsion of entities in the network. Location based services have been widely used in the analysis of trade and location placement [14, 20]. Karamshuk et al. [14] find optimal retail store location from a list of locations by using supervised learning with features mined from Foursquare check-in data. Researchers in [17] focus on locating the ambulance stations by using the real traffic information so as to minimize the average travel-time to reach the emergency requests. The authors of [20] illustrate how User Generated Mobile Location Data like Foursquare check-ins can be used in trade area analysis. [8] exploits regression modeling, pairwise ranking objective and sparsity regularization to solve the real estate ranking problem with online user reviews and offline moving behaviors. Also authors in [9] propose a method for estate appraisal by leveraging the mutual enforcement of ranking and clustering power.\nPrevious work of finding optimal location do not consider the activity demand of users. [24] predicts users\u2019 activity via integrating data of map query and mobility trace, which concludes the fact that map query data can be seen as demands and signals of users doing the activity. Rogers [22] proposed some key elements of a retail location study including competition, transportation, trade area definition and so on. Inspired by the above work, we combine users\u2019 geodemand with supervised learning [14] using geographic and consumptive information (some key elements) mined from multiple real data sources."}, {"heading": "7. CONCLUSION", "text": "In this paper, we propose a novel framework D3SP for the optimal store placement problem. Our framework combines the spatial distribution of user demands with the popularity and economic attributes of each location. Also the integration of multiple data sources enables us to extract rich features from existing stores. The evaluation results demonstrate the effectiveness of our proposed method for optimal store placement in both experiments and real life business scenarios."}, {"heading": "8. REFERENCES", "text": "[1] A. Athiyaman. Location decision making: the case of retail\nservice development in a closed population. In Academy of Marketing Studies, volume 15, page 13, 2010.\n[2] O. Berman and D. Krass. The generalized maximal covering location problem. Computers & Operations Research, 29(6):563\u2013581, 2002. [3] L. Breiman. Random forests. Machine learning, 45(1):5\u201332, 2001. [4] C. J. Burges. From ranknet to lambdarank to lambdamart: An overview. Learning, 11:23\u2013581, 2010. [5] Z. Chen, Y. Liu, R. C.-W. Wong, J. Xiong, G. Mai, and C. Long. Efficient algorithms for optimal location queries in road networks. In Proceedings of the 2014 ACM SIGMOD international conference on Management of data, pages 123\u2013134. ACM, 2014. [6] D. Comaniciu and P. Meer. Mean shift: A robust approach toward feature space analysis. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 24(5):603\u2013619, 2002. [7] J. H. Friedman. Greedy function approximation: a gradient boosting machine. Annals of statistics, pages 1189\u20131232, 2001. [8] Y. Fu, Y. Ge, Y. Zheng, Z. Yao, Y. Liu, H. Xiong, and N. J. Yuan. Sparse real estate ranking with online user\nreviews and offline moving behaviors. In Data Mining (ICDM), 2014 IEEE International Conference on, pages 120\u2013129. IEEE, 2014.\n[9] Y. Fu, H. Xiong, Y. Ge, Z. Yao, Y. Zheng, and Z.-H. Zhou. Exploiting geographic dependencies for real estate appraisal: A mutual perspective of ranking and clustering. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201914, pages 1047\u20131056, New York, NY, USA, 2014. ACM. [10] M. A. Hearst, S. T. Dumais, E. Osman, J. Platt, and B. Scholkopf. Support vector machines. Intelligent Systems and their Applications, IEEE, 13(4):18\u201328, 1998. [11] T. Hernandez and D. Bennison. The art and science of retail location decisions. International Journal of Retail & Distribution Management, 28(8):357\u2013367, 2000. [12] K. Ja\u0308rvelin and J. Keka\u0308la\u0308inen. Cumulated gain-based evaluation of ir techniques. ACM Transactions on Information Systems (TOIS), 20(4):422\u2013446, 2002. [13] P. Jensen. Network-based predictions of retail store commercial categories and optimal locations. Physical Review E, 74(3):035101, 2006. [14] D. Karamshuk, A. Noulas, S. Scellato, V. Nicosia, and C. Mascolo. Geo-spotting: Mining online location-based services for optimal retail store placement. In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 793\u2013801. ACM, 2013. [15] A. Kubis and M. Hartmann. Analysis of location of large-area shopping centres. a probabilistic gravity model for the halle\u2013leipzig area. Jahrbuch fu\u0308r Regionalwissenschaft, 27(1):43\u201357, 2007. [16] J. Li and A. Deshpande. Consensus answers for queries over probabilistic databases. In Proceedings of the twenty-eighth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems, pages 259\u2013268. ACM, 2009. [17] Y. Li, Y. Zheng, S. Ji, W. Wang, Z. Gong, et al. Location selection for ambulance stations: a data-driven approach. In Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems, page 85. ACM, 2015. [18] K. P. Murphy. Machine learning: a probabilistic perspective. MIT press, 2012. [19] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825\u20132830, 2011. [20] Y. Qu and J. Zhang. Trade area analysis using user generated mobile location data. In Proceedings of the 22nd international conference on World Wide Web, pages 1053\u20131064. International World Wide Web Conferences Steering Committee, 2013. [21] D. Rogers. Site for store buys. New Perspectives, 5:14\u201317, 1997. [22] D. S. Rogers. Retail location analysis in practice. Research Review, 14(2):73\u201378, 2007. [23] S. Wood and J. Reynolds. Leveraging locational insights within retail store development? assessing the use of location planners? knowledge in retail marketing. Geoforum, 43(6):1076\u20131087, 2012. [24] Z. Wu, H. Wu, and T. Zhang. Predict user in-world activity via integration of map query and mobility trace. In UrbComp\u201915, 1991. [25] X. Xiao, B. Yao, and F. Li. Optimal location queries in road network databases. In Data Engineering (ICDE), 2011 IEEE 27th International Conference on, pages 804\u2013815. IEEE, 2011."}], "references": [{"title": "Location decision making: the case of retail service development in a closed population", "author": ["A. Athiyaman"], "venue": "Academy of Marketing Studies, volume 15, page 13", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "The generalized maximal covering location problem", "author": ["O. Berman", "D. Krass"], "venue": "Computers & Operations Research, 29(6):563\u2013581", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2002}, {"title": "Random forests", "author": ["L. Breiman"], "venue": "Machine learning, 45(1):5\u201332", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2001}, {"title": "From ranknet to lambdarank to lambdamart: An overview", "author": ["C.J. Burges"], "venue": "Learning, 11:23\u2013581", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Efficient algorithms for optimal location queries in road networks", "author": ["Z. Chen", "Y. Liu", "R.C.-W. Wong", "J. Xiong", "G. Mai", "C. Long"], "venue": "Proceedings of the 2014 ACM SIGMOD international conference on Management of data, pages 123\u2013134. ACM", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Mean shift: A robust approach toward feature space analysis", "author": ["D. Comaniciu", "P. Meer"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, 24(5):603\u2013619", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2002}, {"title": "Greedy function approximation: a gradient boosting machine", "author": ["J.H. Friedman"], "venue": "Annals of statistics, pages 1189\u20131232", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2001}, {"title": "Sparse real estate ranking with online user  reviews and offline moving behaviors", "author": ["Y. Fu", "Y. Ge", "Y. Zheng", "Z. Yao", "Y. Liu", "H. Xiong", "N.J. Yuan"], "venue": "Data Mining (ICDM), 2014 IEEE International Conference on, pages 120\u2013129. IEEE", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Exploiting geographic dependencies for real estate appraisal: A mutual perspective of ranking and clustering", "author": ["Y. Fu", "H. Xiong", "Y. Ge", "Z. Yao", "Y. Zheng", "Z.-H. Zhou"], "venue": "Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201914, pages 1047\u20131056, New York, NY, USA", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Support vector machines", "author": ["M.A. Hearst", "S.T. Dumais", "E. Osman", "J. Platt", "B. Scholkopf"], "venue": "Intelligent Systems and their Applications, IEEE, 13(4):18\u201328", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1998}, {"title": "The art and science of retail location decisions", "author": ["T. Hernandez", "D. Bennison"], "venue": "International Journal of Retail & Distribution Management, 28(8):357\u2013367", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2000}, {"title": "Cumulated gain-based evaluation of ir techniques", "author": ["K. J\u00e4rvelin", "J. Kek\u00e4l\u00e4inen"], "venue": "ACM Transactions on Information Systems (TOIS), 20(4):422\u2013446", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "Network-based predictions of retail store commercial categories and optimal locations", "author": ["P. Jensen"], "venue": "Physical Review E, 74(3):035101", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "Geo-spotting: Mining online location-based services for optimal retail store placement", "author": ["D. Karamshuk", "A. Noulas", "S. Scellato", "V. Nicosia", "C. Mascolo"], "venue": "Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 793\u2013801. ACM", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Analysis of location of large-area shopping centres", "author": ["A. Kubis", "M. Hartmann"], "venue": "a probabilistic gravity model for the halle\u2013leipzig area. Jahrbuch f\u00fcr Regionalwissenschaft, 27(1):43\u201357", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2007}, {"title": "Consensus answers for queries over probabilistic databases", "author": ["J. Li", "A. Deshpande"], "venue": "Proceedings of the twenty-eighth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems, pages 259\u2013268. ACM", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "et al", "author": ["Y. Li", "Y. Zheng", "S. Ji", "W. Wang", "Z. Gong"], "venue": "Location selection for ambulance stations: a data-driven approach. In Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems, page 85. ACM", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Machine learning: a probabilistic perspective", "author": ["K.P. Murphy"], "venue": "MIT press", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Scikit-learn: Machine learning in Python", "author": ["F. Pedregosa", "G. Varoquaux", "A. Gramfort", "V. Michel", "B. Thirion", "O. Grisel", "M. Blondel", "P. Prettenhofer", "R. Weiss", "V. Dubourg", "J. Vanderplas", "A. Passos", "D. Cournapeau", "M. Brucher", "M. Perrot", "E. Duchesnay"], "venue": "Journal of Machine Learning Research, 12:2825\u20132830", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Trade area analysis using user generated mobile location data", "author": ["Y. Qu", "J. Zhang"], "venue": "Proceedings of the 22nd international conference on World Wide Web, pages 1053\u20131064. International World Wide Web Conferences Steering Committee", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Site for store buys", "author": ["D. Rogers"], "venue": "New Perspectives, 5:14\u201317", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1997}, {"title": "Retail location analysis in practice", "author": ["D.S. Rogers"], "venue": "Research Review, 14(2):73\u201378", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "Leveraging locational insights within retail store development? assessing the use of location planners? knowledge in retail marketing", "author": ["S. Wood", "J. Reynolds"], "venue": "Geoforum, 43(6):1076\u20131087", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Predict user in-world activity via integration of map query and mobility trace", "author": ["Z. Wu", "H. Wu", "T. Zhang"], "venue": "UrbComp\u201915", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1991}, {"title": "Optimal location queries in road network databases", "author": ["X. Xiao", "B. Yao", "F. Li"], "venue": "Data Engineering (ICDE), 2011 IEEE 27th International Conference on, pages 804\u2013815. IEEE", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 1, "context": "previous work [2, 25, 5] study optimal location problem as a covering problem which maximizes the number of people a location can attract.", "startOffset": 14, "endOffset": 24}, {"referenceID": 24, "context": "previous work [2, 25, 5] study optimal location problem as a covering problem which maximizes the number of people a location can attract.", "startOffset": 14, "endOffset": 24}, {"referenceID": 4, "context": "previous work [2, 25, 5] study optimal location problem as a covering problem which maximizes the number of people a location can attract.", "startOffset": 14, "endOffset": 24}, {"referenceID": 13, "context": "In a recent work [14], the authors have developed a data-driven approach to solve the problem of retail store placement by predicting the check-in numbers at given locations using linear supervised learning model.", "startOffset": 17, "endOffset": 21}, {"referenceID": 23, "context": ", map query data), demonstrating the potential consumptive demands of users [24].", "startOffset": 76, "endOffset": 80}, {"referenceID": 22, "context": "Generally, the strategy of finding optimal placement is to find the most suitable locations from a list of candidate locations [23].", "startOffset": 127, "endOffset": 131}, {"referenceID": 21, "context": "We consider economic development, popularity and transportation convenience [22] in our model.", "startOffset": 76, "endOffset": 80}, {"referenceID": 13, "context": "It has several advantages over the checkin data used in previous work [14].", "startOffset": 70, "endOffset": 74}, {"referenceID": 23, "context": "We utilize the method in [24] which assumes that a queried location is actually visited by the user if there is at least one location record in user\u2019s next 1.", "startOffset": 25, "endOffset": 29}, {"referenceID": 5, "context": "Since we do not know the exact number of clusters we will have, and would require a center point of each cluster, we use MeanShift [6] as our algorithm.", "startOffset": 131, "endOffset": 134}, {"referenceID": 3, "context": "The method we use in this paper is LambdaMART [4], which is a widely used learn to rank method in many works and the winner of 2010 Yahoo! Learning To Rank Challenge.", "startOffset": 46, "endOffset": 49}, {"referenceID": 9, "context": "For regression method, we consider the linear regression with regularization (Lasso) and the kernel methods including Support Vector Regression (SVR) [10] and Kernel ridge regression (KRR) [18].", "startOffset": 150, "endOffset": 154}, {"referenceID": 17, "context": "For regression method, we consider the linear regression with regularization (Lasso) and the kernel methods including Support Vector Regression (SVR) [10] and Kernel ridge regression (KRR) [18].", "startOffset": 189, "endOffset": 193}, {"referenceID": 2, "context": "Random Forests[3] and Gradient Boosting Decision Trees[7] are two popular algorithms of the ensemble method.", "startOffset": 14, "endOffset": 17}, {"referenceID": 6, "context": "Random Forests[3] and Gradient Boosting Decision Trees[7] are two popular algorithms of the ensemble method.", "startOffset": 54, "endOffset": 57}, {"referenceID": 11, "context": "In order to evaluate the ranking performance of our result, we utilize the nDCG@k (Normalized Discounted Cumulative Gain) metric [12] and the nSD@k (normalized symmetric difference) metric proposed in [16].", "startOffset": 129, "endOffset": 133}, {"referenceID": 15, "context": "In order to evaluate the ranking performance of our result, we utilize the nDCG@k (Normalized Discounted Cumulative Gain) metric [12] and the nSD@k (normalized symmetric difference) metric proposed in [16].", "startOffset": 201, "endOffset": 205}, {"referenceID": 18, "context": "We have used the corresponding implementations that are public available through the Scikit-learn machine learning package [19].", "startOffset": 123, "endOffset": 127}, {"referenceID": 10, "context": "Researchers have concentrated on various techniques including spatial interaction models, Multiple regression Discriminant analysis and so on [11] .", "startOffset": 142, "endOffset": 146}, {"referenceID": 0, "context": "Spatial interaction models are based on the assumptions that the intensity of interaction between two locations decreases with their distance and that the usability of a location increases with the intensity of utilization and the proximity of complementarily arranged locations [1, 2, 25, 15].", "startOffset": 279, "endOffset": 293}, {"referenceID": 1, "context": "Spatial interaction models are based on the assumptions that the intensity of interaction between two locations decreases with their distance and that the usability of a location increases with the intensity of utilization and the proximity of complementarily arranged locations [1, 2, 25, 15].", "startOffset": 279, "endOffset": 293}, {"referenceID": 24, "context": "Spatial interaction models are based on the assumptions that the intensity of interaction between two locations decreases with their distance and that the usability of a location increases with the intensity of utilization and the proximity of complementarily arranged locations [1, 2, 25, 15].", "startOffset": 279, "endOffset": 293}, {"referenceID": 14, "context": "Spatial interaction models are based on the assumptions that the intensity of interaction between two locations decreases with their distance and that the usability of a location increases with the intensity of utilization and the proximity of complementarily arranged locations [1, 2, 25, 15].", "startOffset": 279, "endOffset": 293}, {"referenceID": 14, "context": "Specifically, work in [15] employs spatial interaction theory, customer density estimates and minimax decision criterion to address site selection issues.", "startOffset": 22, "endOffset": 26}, {"referenceID": 1, "context": "Authors of [2, 25] utilize theoretic models of optimal location by maximizing the number of residents it can attracts in Euclidean space or road network.", "startOffset": 11, "endOffset": 18}, {"referenceID": 24, "context": "Authors of [2, 25] utilize theoretic models of optimal location by maximizing the number of residents it can attracts in Euclidean space or road network.", "startOffset": 11, "endOffset": 18}, {"referenceID": 20, "context": "Multiple regression Discriminant analysis [21] is a location analyst that has been employed to produce a series of sales forecasts for both new and existing stores, which is tested and calibrated across a number of different scenarios and is often used as a benchmarking tool for future development.", "startOffset": 42, "endOffset": 46}, {"referenceID": 12, "context": "Jensen [13] proposed a spatial network based formulation of the problem, where nodes are differrient types of retail stores and weighted signed links are defined to model the attraction", "startOffset": 7, "endOffset": 11}, {"referenceID": 13, "context": "Location based services have been widely used in the analysis of trade and location placement [14, 20].", "startOffset": 94, "endOffset": 102}, {"referenceID": 19, "context": "Location based services have been widely used in the analysis of trade and location placement [14, 20].", "startOffset": 94, "endOffset": 102}, {"referenceID": 13, "context": "[14] find optimal retail store location from a list of locations by using supervised learning with features mined from Foursquare check-in data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Researchers in [17] focus on locating the ambulance stations by using the real traffic information so as to minimize the average travel-time to reach the emergency requests.", "startOffset": 15, "endOffset": 19}, {"referenceID": 19, "context": "The authors of [20] illustrate how User Generated Mobile Location Data like Foursquare check-ins can be used in trade area analysis.", "startOffset": 15, "endOffset": 19}, {"referenceID": 7, "context": "[8] exploits regression modeling, pairwise ranking objective and sparsity regularization to solve the real estate ranking problem with online user reviews and offline moving behaviors.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "Also authors in [9] propose a method for estate appraisal by leveraging the mutual enforcement of ranking and clustering power.", "startOffset": 16, "endOffset": 19}, {"referenceID": 23, "context": "[24] predicts users\u2019 activity via integrating data of map query and mobility trace, which concludes the fact that map query data can be seen as demands and signals of users doing the activity.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Rogers [22] proposed some key elements of a retail location study including competition, transportation, trade area definition and so on.", "startOffset": 7, "endOffset": 11}, {"referenceID": 13, "context": "Inspired by the above work, we combine users\u2019 geodemand with supervised learning [14] using geographic and consumptive information (some key elements) mined from multiple real data sources.", "startOffset": 81, "endOffset": 85}], "year": 2016, "abstractText": "Choosing a good location when opening a new store is crucial for the future success of a business. Traditional methods include offline manual survey, which is very time consuming, and analytic models based on census data, which are unable to adapt to the dynamic market. The rapid increase of the availability of big data from various types of mobile devices, such as online query data and offline positioning data, provides us with the possibility to develop automatic and accurate data-driven prediction models for business store placement. In this paper, we propose a Demand Distribution Driven Store Placement (D3SP) framework for business store placement by mining search query data from Baidu Maps. D3SP first detects the spatial-temporal distributions of customer demands on different business services via query data from Baidu Maps, the largest online map search engine in China, and detects the gaps between demand and supply. Then we determine candidate locations via clustering such gaps. In the final stage, we solve the location optimization problem by predicting and ranking the number of customers. We not only deploy supervised regression models to predict the number of customers, but also learn to rank models to directly rank the locations. We evaluate our framework on various types of businesses in real-world cases, and the experiments results demonstrate the effectiveness of our methods. D3SP as the core function for store placement has already been implemented as a core component of our business analytics platform and could be potentially used by chain store merchants on Baidu Nuomi.", "creator": "LaTeX with hyperref package"}}}