{"id": "1606.05313", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2016", "title": "Unsupervised Risk Estimation Using Only Conditional Independence Structure", "abstract": "We show how to estimate the test error of a model based on unmarked data on distributions that differ greatly from the training distribution, assuming only that certain conditional dependencies between train and test are maintained. We need not assume that the optimal predictor between train and test is the same, or that the true distribution is within each parametric family. We can also efficiently differentiate the error estimate to perform uncontrolled discriminatory learning. Our technical tool is the method of moments that allows us to exploit conditional dependencies in the absence of a fully specified model. Our framework includes a large family of losses, including the protocol and exponential losses, and extends to structured output settings such as hidden Markov models.", "histories": [["v1", "Thu, 16 Jun 2016 18:48:51 GMT  (785kb,D)", "http://arxiv.org/abs/1606.05313v1", "15 pages"]], "COMMENTS": "15 pages", "reviews": [], "SUBJECTS": "cs.LG cs.AI stat.ML", "authors": ["jacob steinhardt", "percy s liang"], "accepted": true, "id": "1606.05313"}, "pdf": {"name": "1606.05313.pdf", "metadata": {"source": "CRF", "title": "Unsupervised Risk Estimation Using Only Conditional Independence Structure", "authors": ["Jacob Steinhardt", "Percy Liang"], "emails": ["jsteinhardt@cs.stanford.edu", "pliang@cs.stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "How can we assess the accuracy of a model when the test distribution is very different than the training distribution? To address this question, we study the problem of unsupervised risk estimation (Donmez et al., 2010)\u2014that is, given a loss function L(\u03b8;x, y) and a fixed model \u03b8, estimate the risk R(\u03b8) def= Ex,y\u223cp\u2217 [L(\u03b8;x, y)] with respect to a test distribution p\u2217(x, y), given access only to m unlabeled examples x(1:m) \u223c p\u2217(x). Unsupervised risk estimation lets us estimate model accuracy on a novel input distribution, and is thus important for building reliable machine learning systems. Beyond evaluating a single model, it also provides a way of harnessing unlabeled data for learning: by minimizing the estimated risk over \u03b8, we can perform unsupervised learning and domain adaptation.\nUnsupervised risk estimation is impossible without some assumptions on p\u2217, as otherwise p\u2217(y | x)\u2014 about which we have no observable information\u2014could be arbitrary. How satisfied we should be with an estimator depends on how strong its underlying assumptions are. In this paper, we present an approach which rests on surprisingly weak assumptions\u2014that p\u2217 satisfies certain conditional independencies, but not that it lies in any parametric family or is close to the training distribution.\nTo give a flavor for our results, suppose that y \u2208 {1, . . . , k} and that the loss decomposes as a sum of three parts: L(\u03b8;x, y) = \u22113 v=1 fv(\u03b8;xv, y), where x1, x2, and x3 are independent conditioned on y. In this case, we can estimate the risk to error in poly(k)/ 2 samples, independently of the dimension of x or \u03b8; the dependence on k is roughly cubic in practice. In Sections 2 and 3 we generalize this result to capture both the log and exponential losses, and extend beyond the multiclass case to allow y to be the hidden state of a hidden Markov model.\nSome intuition is provided in Figure 1. At a fixed value of x, we can think of each fv as \u201cpredicting\u201d that y = j if fv(xv, j) is low and fv(xv, j\u2032) is high for j\u2032 6= j. Since f1, f2, and f3 all provide independent signals about y, their rate of agreement gives information about the model accuracy. If f1, f2, and f3 all predict that y = 1, then it is likely that the true y equals 1 and the loss is small. Conversely, if f1, f2, and f3 all predict different values of y, then the loss is likely larger. This\nar X\niv :1\n60 6.\n05 31\n3v 1\n[ cs\n.L G\n] 1\n6 Ju\nn 20\nintuition is formalized by Dawid and Skene (1979) when the fv take values in a discrete set (e.g. when the fv measure the 0/1-loss of independent classifiers); they model (f1, f2, f3) as a mixture of independent categorical variables, and use this to impute y as the label of the mixture component. Several others have extended this idea (e.g. Zhang et al., 2014; Platanios, 2015; Jaffe et al., 2015), but continue to focus on the 0/1 loss (with a single exception that we discuss below).\nWhy have continuous losses such as the log loss been ignored, given their utility for gradient-based learning? The issue is that while the 0/1-loss only involves a discrete prediction in {1, . . . , k} (the predicted output), the log loss involves predictions in Rk (the predicted probability distribution over outputs). The former can be fully modeled by a k-dimensional family, while the latter requires infinitely many parameters. We could assume that the predictions are distributed according to some parametric family, but if that assumption is wrong then our risk estimates will be wrong as well.\nTo sidestep this issue, we make use of the method of moments; while the method of moments has seen recent use in machine learning for fitting non-convex latent variable models (e.g. Anandkumar et al., 2012), it has a much older history in the econometrics literature, where it has been used as a tool for making causal identifications under structural assumptions, even when an explicit form for the likelihood is not known (Anderson and Rubin, 1949; 1950; Sargan, 1958; 1959; Hansen, 1982; Powell, 1994; Hansen, 2014). It is upon this older literature that we draw conceptual inspiration, though our technical tools are more closely based on the newer machine learning approaches. The key insight is that certain moment equations\u2013e.g., E[f1f2 | y] = E[f1 | y]E[f2 | y]\u2013 can be derived from the assumed independencies; we then show how to estimate the risk while relying only on these moment conditions, and not on any parametric assumptions about the xv or fv. Moreover, these moment equations also hold for the gradient of fv , which enables efficient unsupervised learning.\nOur paper is structured as follows. In Section 2, we present our basic framework, and state and prove our main result on estimating the risk given f1, f2, and f3. In Section 3, we extend our framework in several directions, including to hidden Markov models. In Section 4, we present a gradient-based learning algorithm and show that the sample complexity needed for learning is d \u00b7 poly(k)/ 2, where d is the dimension of \u03b8. In Section 5, we investigate how our method performs empirically.\nRelated Work. While the formal problem of unsupervised risk estimation was only posed recently by Donmez et al. (2010), several older ideas from domain adaptation and semi-supervised learning are also relevant. The covariate shift assumption assumes access to labeled samples from a base distribution p0(x, y) for which p\u2217(y | x) = p0(y | x). If p\u2217(x) and p0(x) are close together, we can approximate p\u2217 by p0 via sample re-weighting (Shimodaira, 2000; Qui\u00f1onero-Candela et al., 2009). If p\u2217 and p0 are not close, another approach is to assume a well-specified discriminative model family \u0398, such that p0(y | x) = p\u2217(y | x) = p\u03b8\u2217(y | x) for some \u03b8\u2217 \u2208 \u0398; then we need only heed finite-sample error in the estimation of \u03b8\u2217 (Blitzer et al., 2011; Li et al., 2011). Both assumptions are somewhat stringent \u2014 re-weighting only allows small perturbations, and mis-specified models are common in practice. Indeed, many authors report that mis-specification can lead to severe issues in semi-supervised settings (Merialdo, 1994; Nigam et al., 1998; Cozman and Cohen, 2006; Liang and Klein, 2008; Li and Zhou, 2015).\nAs mentioned above, our approach is closer in spirit to that of Dawid and Skene (1979) and its extensions. Similarly to Zhang et al. (2014) and Jaffe et al. (2015), we use the method of moments for estimating latent-variable models However, those papers use it as a tool for parameter estimation in the face of non-convexity, rather than as a way to sidestep model mis-specification. The insight that moments are robust to model mis-specification lets us extend beyond the simple discrete settings they consider in order to handle more complex continuous and structured losses. Another approach to handling continuous losses is given in the intriguing work of Balasubramanian et al. (2011), who show that the distribution of losses L | y is often close to Gaussian in practice, and use this to estimate\nthe risk. A key difference from all of this prior work is that we are the first to perform gradient-based learning and the first to handle a structured loss (in our case, the log loss for hidden Markov models)."}, {"heading": "2 Framework and Estimation Algorithm", "text": "We will focus on multiclass classification; we assume an unknown true distribution p\u2217(x, y) over X \u00d7 Y , where Y = {1, . . . , k}, and are given unlabeled samples x(1), . . . , x(m) drawn i.i.d. from p\u2217(x). Given parameters \u03b8 \u2208 Rd and a loss function L(\u03b8;x, y), our goal is to estimate the risk of \u03b8 on p\u2217: R(\u03b8) def= Ex,y\u223cp\u2217 [L(\u03b8;x, y)]. Throughout, we will make the 3-view assumption: Assumption 1 (3-view). Under p\u2217, x can be split into x1, x2, x3, which are conditionally independent given y (see Figure 2). Moreover, the loss decomposes additively across views: L(\u03b8;x, y) = A(\u03b8;x)\u2212 \u22113 v=1 fv(\u03b8;xv, y), for some functions A and fv .\nNote that if we have v > 3 views x1, . . . , xv, then we can always partition the views into blocks x\u20321 = x1:bv/3c, x \u2032 2 = xbv/3c+1:b2v/3c, x \u2032 3 = xb2v/3c+1:v . Assumption 1 then holds for x \u2032 1, x \u2032 2, x \u2032 3.\n1 In addition, it suffices for just the fv to be independent rather than the xv .\nWe will give some examples where Assumption 1 holds, then state and prove our main result. We start with logistic regression, which will be our primary focus later on:\nExample 1 (Logistic Regression). Suppose that we have a log-linear model p\u03b8(y | x) = exp ( \u03b8> (\u03c61(x1, y) + \u03c62(x2, y) + \u03c63(x3, y))\u2212A(\u03b8;x) ) , where x1, x2, and x3 are independent conditioned on y. If our loss function is the log-loss L(\u03b8;x, y) = \u2212 log p\u03b8(y | x), then Assumption 1 holds with fv(\u03b8;xv, y) = \u03b8>\u03c6v(xv, y), and A(\u03b8;x) equal to the partition function of p\u03b8.\nWe next consider the hinge loss, for which Assumption 1 does not hold. However, it does hold for a modified hinge loss, where we apply the hinge separately to each view:\nExample 2 (Modified Hinge Loss). Suppose that L(\u03b8;x, y) = \u22113 v=1(1 + maxj 6=y \u03b8\n>\u03c6v(xv, j)\u2212 \u03b8>\u03c6v(xv, y))+. In other words, L is the sum of 3 hinge losses, one for each view. Then Assumption 1 holds with A = 0, and \u2212fv equal to the hinge loss for view v.\nThere is nothing special about the hinge loss; for instance, we could instead take a sum of 0/1-losses.\nOur final example shows that linearity is not necessary for Assumption 1 to hold; the model can be arbitrarily non-linear in each view xv , as long as the predictions are combined additively at the end:\nExample 3 (Neural Networks). Suppose that for each view v we have a neural network whose output is a prediction vector (fv(\u03b8;xv, j))kj=1. Suppose further that we add together the predictions f1+f2+ f3, apply a soft-max, and evaluate using the log loss; then L(\u03b8;x, y) = A(\u03b8;x)\u2212 \u22113 v=1 fv(\u03b8;xv, y), where A(\u03b8;x) is the log-normalization constant of the softmax, and hence L satisfies Assumption 1.\nWith these examples in hand, we are ready for our main result on recovering the risk R(\u03b8). The key is to recover the conditional risk matrices Mv \u2208 Rk\u00d7k, defined as\n(Mv)ij = E[fv(\u03b8;xv, i) | y = j]. (1)\n1 For v = 2 views, recovering R is related to non-negative matrix factorization (Lee and Seung, 2001). Exact identification ends up being impossible, though obtaining upper bounds is likely possible.\nIn the case of the 0/1-loss, the Mv are confusion matrices; in general, (Mv)ij measures how strongly we predict class i when the true class is j. If we could recover these matrices along with the marginal class probabilities \u03c0j def = p\u2217(y = j), then estimating the risk would be straightforward; indeed,\nR(\u03b8) = E[A(\u03b8;x)]\u2212 k\u2211 j=1 \u03c0j 3\u2211 v=1 (Mv)j,j , (2)\nwhere E[A(\u03b8;x)] can be estimated from unlabeled data alone.\nCaveat: Class permutation. Suppose that at training time, we learn to predict whether an image contains the digit 0 or 1. At test time, nothing changes except the definitions of 0 and 1 are reversed. It is clearly impossible to detect this from unlabeled data; mathematically, this manifests asMv only being recoverable up to column permutation. We will end up computing the minimum risk over these permutations, which we call the optimistic risk and denote R\u0303(\u03b8) def= min\u03c3\u2208Sym(k) Ex,y\u223cp\u2217 [L(\u03b8;x, \u03c3(y))]. This equals the true risk as long as \u03b8 is at least aligned with the correct labels in the sense that Ex[L(\u03b8;x, j) | y = j] \u2264 Ex[L(\u03b8;x, j\u2032) | y = j] for j\u2032 6= j. The optimal \u03c3 can then be computed from Mv and \u03c0 in O ( k3 ) time using maximum weight bipartite matching; see Section A for details.\nOur main result, Theorem 1, says that we can recover both Mv and \u03c0 up to permutation, with a number of samples that is polynomial in k; in practice the dependence on k seems roughly cubic.\nTheorem 1. Suppose Assumption 1 holds. Then, for any , \u03b4 \u2208 (0, 1), we can estimate Mv and \u03c0 up to column permutation, to error (in Frobenius and\u221e-norm respectively). Our algorithm requires\nm = poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 ) \u00b7 log(2/\u03b4) 2 samples to succeed with probability 1\u2212 \u03b4, where\n\u03c0min def = k min j=1 p\u2217(y = j), \u03c4 def = E [\u2211 v,jfv(\u03b8;xv, j) 2 ] , and \u03bb def= 3 min v=1 \u03c3k(Mv), (3)\nand \u03c3k denotes the kth singular value. Moreover, the algorithm runs in time m \u00b7 poly(k).\nNote that estimates for Mv and \u03c0 imply an estimate for R\u0303 via (2). Importantly, the sample complexity in Theorem 1 depends on the number of classes k, but not on the dimension d of \u03b8. Moreover, Theorem 1 holds even if p\u2217 lies outside the model family \u03b8, and even if the train and test distributions are very different (in fact, the result is totally agnostic to how the model \u03b8 was produced). The only requirement is that the 3-view assumption holds for p\u2217.\nLet us interpret each term in (3). First, \u03c4 tracks the variance of the loss, and we should expect the difficulty of estimating the risk to increase with this variance. The log(2/\u03b4) 2 term is typical and shows up even when estimating the parameter of a Bernoulli variable to accuracy from m samples. The \u03c0\u22121min term appears because, if one of the classes is very rare, we need to wait a long time to observe even a single sample from that class, and even longer to estimate the risk on that class accurately.\nPerhaps least intuitive is the \u03bb\u22121 term, which is large e.g. when two classes have similar conditional risk vectors E[(fv(\u03b8;xv, i))ki=1 | y = j]. To see why this matters, consider an extreme where x1, x2, and x3 are independent not only of each other but also of y. Then p\u2217(y) is completely unconstrained, and it is impossible to estimate R at all. Why does this not contradict Theorem 1? The answer is that in this case, all rows of Mv are equal and hence \u03bb = 0, \u03bb\u22121 =\u221e, and we need infinitely many samples for Theorem 1 to hold; \u03bb thus measures how close we are to this degenerate case.\nProof of Theorem 1. We now outline a proof of Theorem 1. Recall the goal is to estimate the conditional risk matrices Mv, defined as (Mv)ij = E[fv(\u03b8;xv, i) | y = j]; from these we can recover the risk itself using (2). The key insight is that certain moments of p\u2217(y | x) can be expressed as polynomial functions of the matrices Mv, and therefore we can solve for the Mv even without explicitly estimating p\u2217. Our approach follows the technical machinery behind the spectral method of moments (e.g., Anandkumar et al., 2012), which we explain below for completeness.\nDefine the loss vector hv(xv) = (fv(\u03b8;xv, i))ki=1. The conditional independence of the xv means that E[h1(x1)h2(x2)\n> | y] = E[h1(x1) | y]E[h2(x2) | y]>, and similarly for higher-order conditional moments. There is thus low-rank structure in the moments of h, which we can exploit. More precisely,\nAlgorithm 1 Algorithm for estimating R\u0303(\u03b8) from unlabeled data.\n1: Input: unlabeled samples x(1), . . . , x(m) \u223c p\u2217(x). 2: Estimate the left-hand-side of each term in (4) using x(1:m). 3: Compute approximations M\u0302v and \u03c0\u0302v to Mv and \u03c0 using tensor decomposition. 4: Compute \u03c3 maximizing \u2211k j=1 \u03c0\u0302\u03c3(j) \u22113 v=1(M\u0302v)j,\u03c3(j) using maximum bipartite matching.\n5: Output: estimated 1m \u2211m i=1A(\u03b8;x (i))\u2212 \u2211k j=1 \u03c0\u0302\u03c3(j) \u22113 v=1(M\u0302v)j,\u03c3(j).\nby marginalizing over y, we obtain the following equations, where \u2297 denotes outer product:\nE[hv(xv)] = Mv\u03c0, E[hv(xv)hv\u2032(xv\u2032) >] = Mv diag(\u03c0)M > v\u2032 for v 6= v\u2032, and\nE[h1(x1)\u2297h2(x2)\u2297h3(x3)]i1,i2,i3 = k\u2211 j=1 \u03c0j \u00b7 (M1)i1,j(M2)i2,j(M3)i3,j \u2200i1, i2, i3. (4)\nThe left-hand-side of each equation can be estimated from unlabeled data; we can then solve for Mv and \u03c0 using tensor decomposition (Lathauwer, 2006; Comon et al., 2009; Anandkumar et al., 2012; 2013; Kuleshov et al., 2015). In particular, we can recover M and \u03c0 up to permutation: that is, we recover M\u0302 and \u03c0\u0302 such that Mi,j \u2248 M\u0302i,\u03c3(j) and \u03c0j \u2248 \u03c0\u0302\u03c3(j) for some permutation \u03c3 \u2208 Sym(k). This then yields Theorem 1; see Section B for a full proof.\nAssumption 1 therefore yields a set of moment equations (4) that, when solved, let us estimate the risk without any labels y. To summarize the procedure, we (i) approximate the left-hand-side of each term in (4) by sample averages; (ii) use tensor decomposition to solve for \u03c0 and Mv; (iii) use maximum matching to compute the permutation \u03c3; and (iv) use (2) to obtain R\u0303 from \u03c0 and Mv ."}, {"heading": "3 Extensions", "text": "Theorem 1 provides a basic building block which admits several extensions to more complex model structures. We go over several cases below, omitting most proofs to avoid tedium.\nExtension 1 (Hidden Markov Model). Most importantly, the latent variable y need not belong to a small discrete set; we can handle structured output spaces such as a hidden Markov model as long as p\u2217 matches the HMM structure. This is a substantial generalization of previous work on unsupervised risk estimation, which was restricted to multiclass classification.\nSuppose that p\u03b8(y1:T | x1:T ) \u221d \u220fT t=2 f\u03b8(yt\u22121, yt) \u00b7 \u220fT t=1 g\u03b8(yt, xt), with log-loss L(\u03b8;x, y) = \u2212 log p\u03b8(y1:T | x1:T ). We can exploit the decomposition\n\u2212 log p\u03b8(y1:T | x1:T ) = T\u2211 t=2\n\u2212 log p\u03b8(yt\u22121, yt | x1:T )\ufe38 \ufe37\ufe37 \ufe38 def = `t\n\u2212 T\u2211 t=1\n\u2212 log p\u03b8(yt | x1:T )\ufe38 \ufe37\ufe37 \ufe38 def = `\u2032t . (5)\nAssuming that p\u2217 is Markovian with respect to y, each of the losses `t, `\u2032t satisfies Assumption 1 (see Figure 2; for `t, the views are x1:t\u22122, xt\u22121:t, xt+1:T , and for `\u2032t they are x1:t\u22121, xt, xt+1:T ). We use Theorem 1 to estimate each E[`t], E[`\u2032t] individually, and thus also the full risk E[L]. (Note that we actually estimate the risk for y2:T\u22121 | x1:T due to the 3-view assumption failing at the boundaries.) In general, the idea in (5) applies to any structured output problem that is a sum of local 3-view structures. It would be interesting to extend our results to other structures such as more general graphical models (Chaganty and Liang, 2014) and parse trees (Hsu et al., 2012).\nExtension 2 (Exponential Loss). We can also relax the additivity condition L = A\u2212 f1 \u2212 f2 \u2212 f3. For instance, suppose L(\u03b8;x, y) = exp(\u2212\u03b8> \u22113 v=1 \u03c6v(xv, y)) is the exponential loss. We can use Theorem 1 to estimate the matrices Mv corresponding to fv(\u03b8;xv, y) = exp(\u2212\u03b8>\u03c6v(xv, y)). Then\nR(\u03b8) = E [ 3\u220f v=1 fv(\u03b8;xv, y) ] = \u2211 j \u03c0j 3\u220f v=1 E [fv(\u03b8;xv, j) | y = j] (6)\nby conditional independence. Therefore, the risk can be estimated as \u2211 j \u03c0j \u220f3 v=1(Mv)j,j . More\ngenerally, it suffices to have L(\u03b8;x, y) = A(\u03b8;x) + \u2211n i=1 \u220f3 v=1 f v i (\u03b8;xv, y) for some functions f v i .\nExtension 3 (Mediating Variable). Assuming that x1:3 are independent conditioned only on y may not be realistic; there might be multiple subclasses of a label (e.g., multiple ways to write the digit 4) which would induce systematic correlations across views. To address this, we show that independence need only hold conditioned on a mediating variable z, rather than on the label y itself.\nLet z be a refinement of y (in the sense that z \u2192 y is deterministic) which takes on k\u2032 values, and suppose that the views x1, x2, x3 are independent conditioned on z, as in Figure 2. Then we can estimate the risk as long as we can extend the loss vector hv = (fv)ki=1 to a function h \u2032 v : Xv \u2192 Rk \u2032 , such that h\u2032v(xv)i = fv(xv, i) and the matrix (M \u2032 v)ij = E[h \u2032 v(xv)i | z = j] has full rank. The reason is that we can recover the matrices M \u2032v , and then, letting r be the map from z to y, we can express the risk as R(\u03b8) = E[A(\u03b8;x)] + \u2211k\u2032 j=1 p \u2217(z = j) \u22113 v=1(M \u2032 v)r(j),j .\nSummary. Our framework applies to the log loss and exponential loss; to hidden Markov models; and to cases where there are latent variables mediating the independence structure."}, {"heading": "4 From Estimation to Learning", "text": "We now turn our attention to unsupervised learning, i.e., minimizingR(\u03b8) over \u03b8 \u2208 Rd. Unsupervised learning is impossible without some additional information, since even if we could learn the k classes, we wouldn\u2019t know which class had which label. Thus we assume that we have a small amount of information to break this symmetry, in the form of a seed model \u03b80:\nAssumption 2 (Seed Model). We have access to a \u201cseed model\u201d \u03b80 such that R\u0303(\u03b80) = R(\u03b80).\nAssumption 2 merely asks for \u03b80 to be aligned with the true labels on average. We can obtain \u03b80 from a small amount of labeled data (semi-supervised learning) or by training in a nearby domain (domain adaptation). We define gap(\u03b80) to be the difference between R(\u03b80) and the next smallest permutation of the classes, which will affect the difficulty of learning.\nFor simplicity we will focus on the case of logistic regression, and show how to learn given only Assumptions 1 and 2. However, our algorithm extends to general losses, as we show in Section E.\nLearning from moments. Note that for logistic regression (Examples 1), the unobserved components of L(\u03b8;x, y) are linear in the sense that fv(\u03b8;xv, y) = \u03b8>\u03c6v(xv, y) for some \u03c6v . We therefore have\nR(\u03b8) = E[A(\u03b8;x)]\u2212 \u03b8>\u03c6\u0304, where \u03c6\u0304 def= 3\u2211 v=1 E[\u03c6v(xv, y)]. (7)\nFrom (7), we see that it suffices to estimate \u03c6\u0304, after which all terms on the right-hand-side of (7) are known. Given an approximation \u03c6\u0302 to \u03c6\u0304 (we will show how to obtain \u03c6\u0302 below), we can learn a near-optimal \u03b8 by solving the following convex optimization problem:\n\u03b8\u0302 = arg min \u2016\u03b8\u20162\u2264\u03c1\nE[A(\u03b8;x)]\u2212 \u03b8>\u03c6\u0302. (8)\nIn practice we would need to approximate E[A(\u03b8;x)] by samples, but we ignore this for simplicity (it only contributes lower-order terms to the error). The `2-constraint on \u03b8 imparts robustness to errors in \u03c6\u0304. In particular (see Section C for a proof):\nLemma 1. Suppose \u2016\u03c6\u0302\u2212\u03c6\u0304\u20162 \u2264 . Then the output \u03b8\u0302 from (8) satisfiesR(\u03b8\u0302) \u2264 min\u2016\u03b8\u20162\u2264\u03c1R(\u03b8)+2 \u03c1.\nAssuming that the optimal parameter \u03b8\u2217 has `2-norm at most \u03c1, Lemma 1 guarantees that R(\u03b8\u0302) \u2264 R(\u03b8\u2217) + 2 \u03c1. We will see below that computing \u03c6\u0302 requires d \u00b7 poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 ) / 2 samples.\nComputing \u03c6\u0302. Estimating \u03c6\u0304 can be done in a manner similar to estimating R(\u03b8) itself. In addition to the conditional risk matrix Mv \u2208 Rk\u00d7k, we compute the conditional moment matrix Gv \u2208 Rdk\u00d7k defined by (Gv)i+kr,j def = E[\u03c6v(\u03b8;xv, i)r | y = j]. We then have \u03c6\u0304r = \u2211k j=1 \u03c0j \u22113 v=1(Gv)j+kr,j .\nWe can solve for G1, G2, and G3 using the same tensor algorithm as in Theorem 1. Some care is needed to avoid explicitly forming the (kd)\u00d7 (kd)\u00d7 (kd) tensor that would result from the third term in (4), as this would require O ( k3d3 ) memory and is thus intractable for even moderate values of d. We take a standard approach based on random projections (Halko et al., 2011) and described in\nSection 6.1.2 of Anandkumar et al. (2013). We refer the reader to the aforementioned references for details, and cite only the final sample complexity and runtime (see Section D for a proof sketch):\nTheorem 2. Suppose that Assumption 1 holds and that \u03b80 \u2208 \u03980. Let \u03b4 < 1 and < min(1, gap(\u03b80)). Then, given m = poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 ) \u00b7 log(2/\u03b4) 2 samples, where \u03bb and \u03c4 are as defined in (3), with probability 1 \u2212 \u03b4 we can recover Mv and \u03c0 to error , and Gv to error (B/\u03c4) , where B2 = E[ \u2211 i,v \u2016\u03c6v(xv, i)\u201622] measures the `2-norm of the features. The algorithm runs in time O (d (m+ poly(k))), and the errors are in Frobenius norm for M and G, and\u221e-norm for \u03c0.\nInterpretation. Whereas before we estimated Mv to error , now we estimate Gv (and hence \u03c6\u0304) to error (B/\u03c4) . To achieve error in estimating Gv requires (B/\u03c4)2 \u00b7 poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 ) log(2/\u03b4) 2 samples, which is (B/\u03c4)2 times as large as in Theorem 1. The quantity (B/\u03c4)2 typically grows as O(d), and so the sample complexity needed to estimate \u03c6\u0304 is typically d times larger than the sample complexity needed to estimate R. This matches the behavior of the supervised case where we need d times as many samples for learning as compared to (supervised) risk estimation of a fixed model.\nSummary. We have shown how to perform unsupervised logistic regression, given only a seed model \u03b80. This enables unsupervised learning under surprisingly weak assumptions (only the multi-view and seed model assumptions) even for mis-specified models and zero train-test overlap, and without assuming covariate shift. See Section E for learning under more general losses."}, {"heading": "5 Experiments", "text": "To better understand the behavior of our algorithms, we perform experiments on a version of the MNIST data set that is modified to ensure that the 3-view assumption holds. To create an image, we sample a class in {0, . . . , 9}, then sample 3 images at random from that class, letting every third pixel come from the respective image. This guarantees that there will be 3 conditionally independent views. To explore train-test variation, we dim pixel p in the image by exp (a (\u2016p\u2212 p0\u20162 \u2212 0.4)), where p0 is the image center and the distance is normalized to have maximum value 1. We show example images for a = 0 (train) and a = 5 (a possible test distribution) in Figure 3.\nRisk estimation. We use unsupervised risk estimation (Theorem 1) to estimate the risk of a model trained on a = 0 and tested on various values of a \u2208 [0, 10]. We trained the model with AdaGrad (Duchi et al., 2010) on 10, 000 training examples, and used 10, 000 test examples to estimate the risk. To solve for \u03c0 and M in (4), we first use the tensor power method implemented by Chaganty and Liang (2013) to initialize, and then locally minimize a weighted `2-norm of the moment errors with L-BFGS. For comparison, we compute the validation error for a = 0 (i.e., assume train = test), as well as the predictive entropy \u2211 j \u2212p\u03b8(j | x) log p\u03b8(j | x) on the test set (i.e., assume the predictions are well-calibrated). The results are shown in Figure 4a; both the tensor method in isolation and tensor + L-BFGS estimate the risk accurately, with the latter performing slightly better.\nDomain adaptation. We next evaluate our learning algorithm. For \u03b80 we used the trained model at a = 0, and constrained \u2016\u03b8\u20162 \u2264 10 in (8). The results are shown in Figure 4b. For small values of a, our algorithm performs worse than the baseline of directly using \u03b80. However, our algorithm is far more robust as a increases, and tracks the performance of an oracle that was trained on the same distribution as the test examples.\nSemi-supervised learning. Because we only need to provide our algorithm with a seed model, we can perform semi-supervised domain adaptation \u2014 train a model from a small amount of labeled data at a = 0, then use unlabeled data to learn a better model on a new distribution. Concretely, we obtained \u03b80 from only 300 labeled examples. Tensor decomposition sometimes led to bad initializations in this regime, in which case we obtained a different \u03b80 by training with a smaller step size. The results are shown in Figure 4c. Our algorithm generally performs well, but has higher variability than before, seemingly due to higher condition number of the matrices Mv .\nSummary. Our experiments show that given 3 views, we can estimate the risk and perform domain adaptation, even from a small amount of labeled data."}, {"heading": "6 Discussion", "text": "We have presented a method for estimating the risk from unlabeled data, which relies only on conditional independence structure and hence makes no parametric assumptions about the true distribution. Our approach applies to a large family of losses and extends beyond classification tasks to hidden Markov models. We can also perform unsupervised learning given only a seed model that can distinguish between classes in expectation; the seed model can be trained on a related domain, on a small amount of labeled data, or any combination of the two, and thus provides a pleasingly general formulation highlighting the similarities between domain adaptation and semi-supervised learning.\nPrevious approaches to domain adaptation and semi-supervised learning have also exploited multiview structure. Given two views, Blitzer et al. (2011) perform domain adaptation with zero source/target overlap (covariate shift is still assumed). Two-view approaches (e.g. co-training and CCA) are also used in semi-supervised learning (Blum and Mitchell, 1998; Ando and Zhang, 2007; Kakade and Foster, 2007; Balcan and Blum, 2010). These methods all assume some form of low noise or low regret, as do, e.g., transductive SVMs (Joachims, 1999). By focusing on the central problem of risk estimation, our work connects multi-view learning approaches for domain adaptation and semi-supervised learning, and removes covariate shift and low-noise/low-regret assumptions (though we make stronger independence assumptions, and specialize to discrete prediction tasks).\nIn addition to reliability and unsupervised learning, our work is motivated by the desire to build machine learning system with contracts, a challenge recently posed by Bottou (2015); the goal is for machine learning systems to satisfy a well-defined input-output contract in analogy with software systems (Sculley et al., 2015). Theorem 1 provides the contract that under the 3-view assumption the test error is close to our estimate of the test error; this contrasts with the typical weak contract that if train and test are similar, then the test error is close to the training error. One other interesting contract is given by Shafer and Vovk (2008), who provide prediction regions that contain the true prediction with probability 1\u2212 in the online setting, even in the presence of model mis-specification. The most restrictive part of our framework is the three-view assumption, which is inappropriate if the views are not completely independent or if the data have structure that is not captured in terms of multiple views. Since Balasubramanian et al. (2011) obtain results under Gaussianity (which would be implied by many somewhat dependent views), we are optimistic that unsupervised risk estimation is possible for a wider family of structures. Along these lines, we end with the following questions:\nOpen question. In the 3-view setting, suppose the views are not completely independent. Is it still possible to estimate the risk? How does the degree of dependence affect the number of views needed?\nOpen question. Given only two independent views, can one obtain an upper bound on the risk R(\u03b8)?\nThe results of this paper have caused us to adopt the following perspective: To handle unlabeled data, we should make generative structural assumptions, but still optimize discriminative model performance. This hybrid approach allows us to satisfy the traditional machine learning goal of predictive accuracy, while handling lack of supervision and under-specification in a principled way. Perhaps, then, what is needed for learning is to understand the structure of a domain."}, {"heading": "A Details of Computing R\u0303 from M and \u03c0", "text": "In this section we show how, given M , and \u03c0, we can efficiently compute\nR\u0303(\u03b8) = E[A(\u03b8;x)]\u2212 max \u03c3\u2208Sym(k) k\u2211 j=1 \u03c0\u03c3(j) 3\u2211 v=1 (Mv)j,\u03c3(j). (9)\nThe only bottleneck is the maximum over \u03c3 \u2208 Sym(k), which would na\u00efvely require considering k! possibilities. However, we can instead cast this as a form of maximum matching. In particular, form the k \u00d7 k matrix\nXi,j = \u03c0i 3\u2211 v=1 (Mv)j,i. (10)\nThen we are looking for the permutation \u03c3 such that \u2211k j=1X\u03c3(j),j is maximized. If we consider each Xi,j to be the weight of edge (i, j) in a complete bipartite graph, then this is equivalent to asking for a matching of i to j with maximum weight, hence we can maximize over \u03c3 using any maximum-weight matching algorithm such as the Hungarian algorithm, which runs in O ( k3 )\ntime (Tomizawa, 1971; Edmonds and Karp, 1972)."}, {"heading": "B Proof of Theorem 1", "text": "Preliminary reductions. Our goal is to estimate M and \u03c0 to error (with probability of failure 1\u2212 \u03b4) in poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 ) \u00b7 log(1/\u03b4) 2 samples. Note that if we can estimate M and \u03c0 to error with any fixed probability of success 1\u2212 \u03b40 \u2265 34 , then we can amplify the probability of success to 1 \u2212 \u03b4 at the cost of O (log(1/\u03b4)) times as many samples (the idea is to make several independent estimates, then throw out any estimate that is more than 2 away from at least half of the others; all the remaining estimates will then be within distance 3 of the truth with high probability).\nEstimating M . Estimating \u03c0 and M is mostly an exercise in interpreting Theorem 7 of Anandkumar et al. (2012), which we recall below, modifying the statement slightly to fit our language. Here \u03ba denotes condition number (which is the ratio of \u03c31(M) to \u03c3k(M), since all matrices in question have k columns).\nTheorem 3 (Anandkumar et al. (2012)). Let Pv,v\u2032 def = E[hv(x)\u2297 hv\u2032(x)], and P1,2,3 def = E[h1(x)\u2297 h2(x)\u2297 h3(x)]. Also let P\u0302v,v\u2032 and P\u03021,2,3 be sample estimates of Pv,v\u2032 , P1,2,3 that are (for technical convenience) estimated from independent samples of size m. Let \u2016T\u2016F denote the `2-norm of T after unrolling T to a vector. Suppose that:\n\u2022 P [ \u2016P\u0302v,v\u2032 \u2212 Pv,v\u2032\u20162 \u2264 Cv,v\u2032 \u221a log(1/\u03b4)\nm\n] \u2265 1\u2212 \u03b4 for {v, v\u2032} \u2208 {{1, 2}, {1, 3}}, and\n\u2022 P [ \u2016P\u03021,2,3 \u2212 P1,2,3\u2016F \u2264 C1,2,3 \u221a log(1/\u03b4)\nm\n] \u2265 1\u2212 \u03b4.\nThen, there exists constants C, m0, \u03b40 such that the following holds: if m \u2265 m0 and \u03b4 \u2264 \u03b40 and\u221a log(k/\u03b4)\nm \u2264 C \u00b7 minj 6=j \u2032 \u2016(M>3 )j \u2212 (M>3 )j\u2032\u20162 \u00b7 \u03c3k(P1,2) C1,2,3 \u00b7 k5 \u00b7 \u03ba(M1)4 \u00b7 \u03b4 log(k/\u03b4)\n\u00b7 ,\u221a log(1/\u03b4)\nm \u2264 C \u00b7min\n{ minj 6=j\u2032 \u2016(M>3 )j \u2212 (M>3 )j\u2032\u20162 \u00b7 \u03c3k(P1,2)2\nC1,2 \u00b7 \u2016P1,2,3\u2016F \u00b7 k5 \u00b7 \u03ba(M1)4 \u00b7 \u03b4 log(k/\u03b4) , \u03c3k(P1,3) C1,3\n} \u00b7 ,\nthen with probability at least 1\u2212 5\u03b4, we can output M\u03023 with the following guarantee: there exists a permutation \u03c3 \u2208 Sym(k) such that for all j \u2208 {1, . . . , k},\n\u2016(M>3 )j \u2212 (M\u0302>3 )\u03c3(j)\u20162 \u2264 max j\u2032 \u2016(M>3 )j\u2032\u20162 \u00b7 . (11)\nBy symmetry, we can use Theorem 3 to recover each of the matrices Mv, v = 1, 2, 3, up to permutation of the columns. Furthermore, Anandkumar et al. (2012) show in Appendix B.4 of their paper how to match up the columns of the different Mv , so that only a single unknown permutation is applied to each of the Mv simultaneously. We will set \u03b4 = 1/180, which yields an overall probability of success of 11/12 for this part of the proof.\nWe now analyze the rate of convergence implied by Theorem 3. Note that we can take C1,2,3 = O (\u221a E[\u2016h1\u201622\u2016h2\u201622\u2016h3\u201622] ) , and similarly Cv,v\u2032 = O (\u221a E[\u2016hv\u201622\u2016hv\u2032\u201622] ) . Then, since we only\ncare about polynomial factors, it is enough to note that we can estimate the Mv to error given Z/ 2 samples, where Z is polynomial in the following quantities:\n1. k, 2. max3v=1 \u03ba(Mv), where \u03ba denotes condition number, 3. \u221a\nE[\u2016h1\u201622\u2016h2\u201622\u2016h3\u201622] (minj,j\u2032 \u2016(M>v )j\u2212(M>v )j\u2032\u20162)\u00b7\u03c3k(Pv\u2032,v\u2032\u2032 ) , where (v, v\u2032, v\u2032\u2032) is a permutation of (1, 2, 3),\n4. \u2016P1,2,3\u20162 (minj,j\u2032 \u2016(M>v )j\u2212(M>v )j\u2032\u20162)\u00b7\u03c3k(Pv\u2032,v\u2032\u2032 ) , where (v, v\u2032, v\u2032\u2032) is as before, and 5. \u221a\nE[\u2016hv\u201622\u2016hv\u2032\u201622] \u03c3k(Pv,v\u2032) .\n6. maxj,v \u2016(M>v )j\u20162.\nIt suffices to show that each of these quantities are polynomial in k, \u03c0\u22121min, \u03c4 , and \u03bb \u22121.\n(1) k is trivially polynomial in itself. (2) Note that \u03ba(Mv) \u2264 \u03c31(Mv)/\u03bb \u2264 \u2016Mv\u2016F /\u03bb. Furthermore, \u2016Mv\u20162F = \u2211 j \u2016E[hv | j]\u201622 \u2264\u2211\nj E[\u2016hv\u201622 | j] \u2264 k\u03c42. In all, \u03ba(Mv) \u2264 \u221a k\u03c4/\u03bb, which is polynomial in k and \u03c4/\u03bb.\n(3) We first note that minj 6=j\u2032 \u2016(M>v )j\u2212(M>v )j\u2032\u20162 = \u221a\n2 minj 6=j\u2032 \u2016M>v (ej\u2212ej\u2032)\u20162/\u2016ej\u2212ej\u2032\u20162 \u2265 \u03c3k(Mv). Also, \u03c3k(Pv\u2032,v\u2032\u2032) = \u03c3k(Mv\u2032 diag(\u03c0)Mv\u2032\u2032) \u2265 \u03c3k(Mv\u2032)\u03c0min\u03c3k(Mv\u2032\u2032). We can thus upperbound the quantity in (3.) by \u221a\nE[\u2016h1\u201622\u2016h2\u201622\u2016h3\u201622]\u221a 2\u03c0min\u03c3k(M1)\u03c3k(M2)\u03c3k(M3) \u2264 \u03c4 3 \u221a 2\u03c0min\u03bb3 ,\nwhich is polynomial in \u03c0\u22121min, \u03c4/\u03bb.\n(4) We can perform the same calculations as in (3), but now we have to bound \u2016P1,2,3\u20162. However, it is easy to see that\n\u2016P1,2,3\u20162 = \u221a \u2016E[h1 \u2297 h2 \u2297 h3]\u201622\n\u2264 \u221a\nE[\u2016h1 \u2297 h2 \u2297 h3\u201622] = \u221a\nE[\u2016h1\u201622\u2016h2\u201622\u2016h3\u201622]\n= \u221a\u221a\u221a\u221a k\u2211 j=1 \u03c0j 3\u220f v=1 E[\u2016hv\u201622 | y = j]\n\u2264 \u03c43, which yields the same upper bound as in (3).\n(5) We can again perform the same calculations as in (3), where we now only have to deal with a subset of the variables, thus obtaining a bound of \u03c4 2\n\u03c0min\u03bb2 . (6) We have \u2016(M>v )j\u20162 \u2264 \u221a E[\u2016hv\u201622 | y = j] \u2264 \u03c4 .\nIn sum, we have shown that with probability 1112 we can estimate each Mv to column-wise ` 2 error using poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 ) / 2 samples; since there are only k columns, we can make the total\n(Frobenius) error be at most while still using poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 ) / 2 samples. It now remains to estimate \u03c0.\nEstimating \u03c0. This part of the argument follows Appendix B.5 of Anandkumar et al. (2012). Noting that \u03c0 = M\u221211 E[h1], we can estimate \u03c0 as \u03c0\u0302 = M\u03021 \u22121 E\u0302[h1], where E\u0302 denotes the empirical expectation. Hence, we have\n\u2016\u03c0 \u2212 \u03c0\u0302\u2016\u221e \u2264 \u2225\u2225\u2225(M\u03021\u22121 \u2212M\u221211 )E[h1] +M\u221211 (E\u0302[h1]\u2212E[h1]) + (M\u03021\u22121 \u2212M\u221211 )(E\u0302[h1]\u2212E[h1])\u2225\u2225\u2225\u221e\n\u2264 \u2016M\u03021 \u22121 \u2212M\u221211 \u2016F\ufe38 \ufe37\ufe37 \ufe38 (i) \u2016E[h1]\u20162\ufe38 \ufe37\ufe37 \ufe38 (ii) + \u2016M\u221211 \u2016F\ufe38 \ufe37\ufe37 \ufe38 (iii) \u2016E\u0302[h1]\u2212E[h1]\u20162\ufe38 \ufe37\ufe37 \ufe38 (iv) + \u2016M\u03021 \u22121 \u2212M\u221211 \u2016F\ufe38 \ufe37\ufe37 \ufe38 (i) \u2016E\u0302[h1]\u2212E[h1]\u20162\ufe38 \ufe37\ufe37 \ufe38 (iv) .\nWe will bound each of these factors in turn:\n(i) \u2016M\u03021 \u22121 \u2212M\u221211 \u2016F : let E1 = M\u03021 \u2212M1, which by the previous part satisfies \u2016E1\u2016F \u2264\u221a kmaxj \u2016(M\u0302>1 )j \u2212 (M>1 )j\u20162 = poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 ) / \u221a m. Therefore:\n\u2016M\u03021 \u22121 \u2212M\u221211 \u2016F \u2264 \u2016(M1 + E1)\u22121 \u2212M \u22121 1 \u2016F\n= \u2016M\u221211 (I + E1M \u22121 1 ) \u22121 \u2212M\u221211 \u2016F \u2264 \u2016M\u221211 \u2016F \u2016(I + E1M \u22121 1 ) \u22121 \u2212 I\u2016F\n\u2264 k\u03bb\u22121\u03c31 ( I + E1M \u22121 1 ) \u22121 \u2212 I ) \u2264 k\u03bb\u22121 \u03c31(E1M \u22121 1 )\n1\u2212 \u03c31(E1M\u221211 )\n\u2264 k\u03bb\u22122 \u2016E1\u2016F 1\u2212 \u03bb\u22121\u2016E1\u2016F\n\u2264 poly\n( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 )\n1\u2212 poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 ) / \u221a m \u00b7 1\u221a m .\nWe can assume that m \u2265 poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 )\nwithout loss of generality (since otherwise we can trivially obtain the desired bound on \u2016\u03c0 \u2212 \u03c0\u0302\u2016\u221e by simply guessing the uniform distribution), in which case the above quantity is poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 ) \u00b7 1\u221a m .\n(ii) \u2016E[h1]\u20162: we have \u2016E[h1]\u20162 \u2264 \u221a E[\u2016h1\u201622] \u2264 \u03c4 .\n(iii) \u2016M\u221211 \u2016F : since \u2016X\u2016F \u2264 \u221a k\u03c31(F ), we have \u2016M\u221211 \u2016F \u2264 \u221a k\u03bb\u22121. (iv) \u2016E\u0302[h1]\u2212E[h1]\u20162: with any fixed probability (say 11/12), this term is O (\u221a E[\u2016h1\u201622] m ) =\nO (\n\u03c4\u221a m\n) .\nIn sum, with probability at least 1112 all of the terms are poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 ) , and at least one factor\nin each term has a 1\u221a m decay. Therefore, we have \u2016\u03c0 \u2212 \u03c0\u0302\u2016\u221e \u2264 poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 ) \u00b7 \u221a 1 m .\nSince we have shown that we can estimate each of M and \u03c0 individually with probability 1112 , we can estimate them jointly 56 > 3 4 , thus completing the proof."}, {"heading": "C Proof of Lemma 1", "text": "Let B(\u03c1) = {\u03b8 | \u2016\u03b8\u20162 \u2264 \u03c1}. First note that |\u03b8>(\u03c6\u0302 \u2212 \u03c6\u0304)| \u2264 \u2016\u03b8\u20162\u2016\u03c6\u0302 \u2212 \u03c6\u0304\u20162 \u2264 \u03c1 for all \u03b8 \u2208 B(\u03c1). Letting \u03b8\u0303 denote the minimizer of R(\u03b8) over B(\u03c1), we obtain\nR(\u03b8\u0302) = E[A(\u03b8\u0302;x)]\u2212 \u03b8\u0302>\u03c6\u0304 (12) \u2264 E[A(\u03b8\u0302;x)]\u2212 \u03b8\u0302>\u03c6\u0302+ \u03c1 (13) \u2264 E[A(\u03b8\u0303;x)]\u2212 \u03b8\u0303>\u03c6\u0302+ \u03c1 (14) \u2264 E[A(\u03b8\u0303;x)]\u2212 \u03b8\u0303>\u03c6\u0304+ 2 \u03c1 (15) = R(\u03b8\u0303) + 2 \u03c1, (16)\nas claimed."}, {"heading": "D Proof of Theorem 2", "text": "We note that Theorem 7 of Anandkumar et al. (2012) (and hence Theorem 1 above) does not require that the Mv be k \u00d7 k, but only that they have k columns (the number of rows can be arbitrary). It thus applies for any matrix M \u2032v, where the jth columns of M \u2032 v is equal to E[h \u2032 v(xv) | j] for some hv : Xv \u2192 Rd \u2032 . In our specific case, we will take h\u2032 : Xv \u2192 Rk(d+1), where the first k coordinates of h\u2032(xv) are equal to h(xv) (i.e., (fv(xv, i))ki=1), and the remaining kd coordinates of h \u2032(xv) are equal to \u03c4B \u2202 \u2202\u03b8r fv(\u03b8;xv, i) as in the definition of Gv , where the difference is that we have scaled by a\nfactor of \u03c4B . Note that in this case M \u2032 v = [ Mv \u03c4 BGv ] . We let \u03bb\u2032 and \u03c4 \u2032 denote the values of \u03bb and \u03c4 for M \u2032 and h\u2032.\nSince Mv is a submatrix of M \u2032v , we have \u03c3k(M \u2032 v) \u2265 \u03c3k(Mv), so \u03bb\u2032 \u2265 \u03bb. On the other hand, \u03c4 \u2032 = E[ \u2211 v \u2016h\u2032v(xv)\u201622] (17)\n= E[ \u2211 v \u2016hv(xv)\u201622 + \u03c42 B2 \u2211 v,i \u2016\u2207\u03b8fv(\u03b8;xv, i)\u201622] (18)\n\u2264 \u03c42 + \u03c4 2 B2 E[ \u2211 v,i \u2016\u2207\u03b8fv(\u03b8;xv, i)\u201622] (19)\n= 2\u03c42, (20)\nso \u03c4 \u2032 \u2264 \u221a\n2\u03c4 . Since (\u03bb\u2032)\u22121 = O(\u03bb\u22121) and \u03c4 \u2032 = O(\u03c4), we still obtain a sample complexity of poly ( k, \u03c0\u22121min, \u03bb \u22121, \u03c4 ) \u00b7 log(2/\u03b4) 2 . Since \u03b80 \u2208 \u03980 by assumption, we can recover the correct permutation of the columns of Mv (and hence also of Gv , since they are permuted in the same way), which completes the proof."}, {"heading": "E Learning with General Losses", "text": "In Section 4, we formed the conditional moment matrix Gv , which stored the conditional expectation E[\u03c6v(xv, i) | y = j] for each j and i. However, there was nothing special about computing \u03c6 (as opposed to some other moments), and for general losses can form the conditional gradient matrix Gv(\u03b8), defined by\nGv(\u03b8)i+kr,j = E\n[ \u2202\n\u2202\u03b8r fv(\u03b8;xv, i) | y = j\n] . (21)\nTheorem 2 applies identically to the matrix Gv(\u03b8) at any fixed \u03b8. We can then compute the gradient \u2207\u03b8R(\u03b8) using the relationship\n\u2202\n\u2202\u03b8r R(\u03b8) = E\n[ \u2202\n\u2202\u03b8r A(\u03b8;x)\n] \u2212 k\u2211 j=1 \u03c0j 3\u2211 v=1 Gv(\u03b8)j+kr,j . (22)\nFor clarity, we also use Mv(\u03b8) to denote the conditional risk matrix at a value \u03b8. To compute the gradient \u2207\u03b8R(\u03b8), we jointly estimate Mv(\u03b80) and Gv(\u03b8) (note the differing arguments of \u03b80 vs. \u03b8). Since the seed model assumption (Assumption 2) allows us to recover the correct column permutation for Mv(\u03b80), estimating Gv(\u03b8) jointly with Mv(\u03b80) ensures that we recover the correct column permutation for Gv(\u03b8) as well.\nThe final ingredient is any gradient descent procedure that is robust to errors in the gradient (so that after T steps with error on each step, the total error is O( ) and not O( T )). Fortunately, this is the case for many gradient descent algorithms, including any algorithm that can be expressed as mirror descent (we omit the details because they are somewhat beyond our scope, but refer the reader to Lemma 21 of (Steinhardt et al., 2015) for a proof of this in the case of exponentiated gradent).\nThe general learning algorithm is given in Algorithm 2:\nAlgorithm 2 General algorithm for learning via gradient descent. 1: Parameters: step size \u03b7 2: Input: unlabeled samples x(1), . . . , x(m) \u223c p\u2217(x), seed model \u03b80 3: z(1) \u2190 0 \u2208 Rd 4: for t = 1 to T do 5: \u03b8(t) \u2190 arg min\u03b8 12\u03b7\u2016\u03b8 \u2212 \u03b80\u2016 2 2 \u2212 \u03b8>z\n6: Compute (M (t)v , G (t) v ) by jointly estimating Mv(\u03b80), Gv(\u03b8) from x(1:m). 7: for r = 1 to d do 8: gr \u2190 1m \u2211m i=1 \u2202 \u2202\u03b8r A(\u03b8(t);x(i))\u2212 \u2211k j=1 \u03c0j \u22113 v=1(G (t) v )j+kr,j\n9: z(t+1)r \u2190 z(t)r \u2212 gr 10: end for 11: end for 12: Output 1T ( \u03b8(1) + \u00b7 \u00b7 \u00b7+ \u03b8(T ) ) ."}], "references": [{"title": "A method of moments for mixture models and hidden Markov models", "author": ["A. Anandkumar", "D. Hsu", "S.M. Kakade"], "venue": "In Conference on Learning Theory (COLT),", "citeRegEx": "Anandkumar et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Anandkumar et al\\.", "year": 2012}, {"title": "Tensor decompositions for learning latent variable models", "author": ["A. Anandkumar", "R. Ge", "D. Hsu", "S.M. Kakade", "M. Telgarsky"], "venue": null, "citeRegEx": "Anandkumar et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Anandkumar et al\\.", "year": 2013}, {"title": "Estimation of the parameters of a single equation in a complete system of stochastic equations", "author": ["T.W. Anderson", "H. Rubin"], "venue": "The Annals of Mathematical Statistics,", "citeRegEx": "Anderson and Rubin.,? \\Q1949\\E", "shortCiteRegEx": "Anderson and Rubin.", "year": 1949}, {"title": "The asymptotic properties of estimates of the parameters of a single equation in a complete system of stochastic equations", "author": ["T.W. Anderson", "H. Rubin"], "venue": "The Annals of Mathematical Statistics,", "citeRegEx": "Anderson and Rubin.,? \\Q1950\\E", "shortCiteRegEx": "Anderson and Rubin.", "year": 1950}, {"title": "Two-view feature generation model for semi-supervised learning", "author": ["R.K. Ando", "T. Zhang"], "venue": "In Conference on Learning Theory (COLT),", "citeRegEx": "Ando and Zhang.,? \\Q2007\\E", "shortCiteRegEx": "Ando and Zhang.", "year": 2007}, {"title": "Unsupervised supervised learning II: Margin-based classification without labels", "author": ["K. Balasubramanian", "P. Donmez", "G. Lebanon"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Balasubramanian et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Balasubramanian et al\\.", "year": 2011}, {"title": "A discriminative model for semi-supervised learning", "author": ["M. Balcan", "A. Blum"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Balcan and Blum.,? \\Q2010\\E", "shortCiteRegEx": "Balcan and Blum.", "year": 2010}, {"title": "Domain adaptation with coupled subspaces", "author": ["J. Blitzer", "S. Kakade", "D.P. Foster"], "venue": "In Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "Blitzer et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Blitzer et al\\.", "year": 2011}, {"title": "Combining labeled and unlabeled data with co-training", "author": ["A. Blum", "T. Mitchell"], "venue": "In Conference on Learning Theory (COLT),", "citeRegEx": "Blum and Mitchell.,? \\Q1998\\E", "shortCiteRegEx": "Blum and Mitchell.", "year": 1998}, {"title": "Two high stakes challenges in machine learning", "author": ["L. Bottou"], "venue": "Invited talk at the 32nd International Conference on Machine Learning,", "citeRegEx": "Bottou.,? \\Q2015\\E", "shortCiteRegEx": "Bottou.", "year": 2015}, {"title": "Spectral experts for estimating mixtures of linear regressions", "author": ["A. Chaganty", "P. Liang"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Chaganty and Liang.,? \\Q2013\\E", "shortCiteRegEx": "Chaganty and Liang.", "year": 2013}, {"title": "Estimating latent-variable graphical models using moments and likelihoods", "author": ["A. Chaganty", "P. Liang"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Chaganty and Liang.,? \\Q2014\\E", "shortCiteRegEx": "Chaganty and Liang.", "year": 2014}, {"title": "Tensor decompositions, alternating least squares and other tales", "author": ["P. Comon", "X. Luciani", "A.L.D. Almeida"], "venue": "Journal of Chemometrics,", "citeRegEx": "Comon et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Comon et al\\.", "year": 2009}, {"title": "Risks of semi-supervised learning: How unlabeled data can degrade performance of generative classifiers", "author": ["F. Cozman", "I. Cohen"], "venue": "In Semi-Supervised Learning", "citeRegEx": "Cozman and Cohen.,? \\Q2006\\E", "shortCiteRegEx": "Cozman and Cohen.", "year": 2006}, {"title": "Maximum likelihood estimation of observer error-rates using the EM algorithm", "author": ["A.P. Dawid", "A.M. Skene"], "venue": "Applied Statistics,", "citeRegEx": "Dawid and Skene.,? \\Q1979\\E", "shortCiteRegEx": "Dawid and Skene.", "year": 1979}, {"title": "Unsupervised supervised learning I: Estimating classification and regression errors without labels", "author": ["P. Donmez", "G. Lebanon", "K. Balasubramanian"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Donmez et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Donmez et al\\.", "year": 2010}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "In Conference on Learning Theory (COLT),", "citeRegEx": "Duchi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2010}, {"title": "Theoretical improvements in algorithmic efficiency for network flow problems", "author": ["J. Edmonds", "R.M. Karp"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Edmonds and Karp.,? \\Q1972\\E", "shortCiteRegEx": "Edmonds and Karp.", "year": 1972}, {"title": "Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions", "author": ["N. Halko", "P.-G. Martinsson", "J. Tropp"], "venue": "SIAM Review,", "citeRegEx": "Halko et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Halko et al\\.", "year": 2011}, {"title": "Large sample properties of generalized method of moments estimators", "author": ["L.P. Hansen"], "venue": "Econometrica: Journal of the Econometric Society,", "citeRegEx": "Hansen.,? \\Q1982\\E", "shortCiteRegEx": "Hansen.", "year": 1982}, {"title": "Uncertainty outside and inside economic models", "author": ["L.P. Hansen"], "venue": "Journal of Political Economy,", "citeRegEx": "Hansen.,? \\Q2014\\E", "shortCiteRegEx": "Hansen.", "year": 2014}, {"title": "Identifiability and unmixing of latent parse trees", "author": ["D. Hsu", "S.M. Kakade", "P. Liang"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Hsu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2012}, {"title": "Estimating the accuracies of multiple classifiers without labeled data", "author": ["A. Jaffe", "B. Nadler", "Y. Kluger"], "venue": "In Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "Jaffe et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jaffe et al\\.", "year": 2015}, {"title": "Transductive inference for text classification using support vector machines", "author": ["T. Joachims"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Joachims.,? \\Q1999\\E", "shortCiteRegEx": "Joachims.", "year": 1999}, {"title": "Multi-view regression via canonical correlation analysis", "author": ["S.M. Kakade", "D.P. Foster"], "venue": "In Conference on Learning Theory (COLT),", "citeRegEx": "Kakade and Foster.,? \\Q2007\\E", "shortCiteRegEx": "Kakade and Foster.", "year": 2007}, {"title": "Tensor factorization via matrix factorization", "author": ["V. Kuleshov", "A. Chaganty", "P. Liang"], "venue": "In Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "Kuleshov et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kuleshov et al\\.", "year": 2015}, {"title": "A link between the canonical decomposition in multilinear algebra and simultaneous matrix diagonalization", "author": ["L.D. Lathauwer"], "venue": "SIAM Journal of Matrix Analysis and Applications,", "citeRegEx": "Lathauwer.,? \\Q2006\\E", "shortCiteRegEx": "Lathauwer.", "year": 2006}, {"title": "Algorithms for non-negative matrix factorization", "author": ["D.D. Lee", "S.H. Seung"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Lee and Seung.,? \\Q2001\\E", "shortCiteRegEx": "Lee and Seung.", "year": 2001}, {"title": "Knows what it knows: a framework for self-aware learning", "author": ["L. Li", "M.L. Littman", "T.J. Walsh", "A.L. Strehl"], "venue": "Machine learning,", "citeRegEx": "Li et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Li et al\\.", "year": 2011}, {"title": "Towards making unlabeled data never hurt", "author": ["Y. Li", "Z. Zhou"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Li and Zhou.,? \\Q2015\\E", "shortCiteRegEx": "Li and Zhou.", "year": 2015}, {"title": "Analyzing the errors of unsupervised learning", "author": ["P. Liang", "D. Klein"], "venue": "In Human Language Technology and Association for Computational Linguistics (HLT/ACL),", "citeRegEx": "Liang and Klein.,? \\Q2008\\E", "shortCiteRegEx": "Liang and Klein.", "year": 2008}, {"title": "Tagging English text with a probabilistic model", "author": ["B. Merialdo"], "venue": "Computational Linguistics,", "citeRegEx": "Merialdo.,? \\Q1994\\E", "shortCiteRegEx": "Merialdo.", "year": 1994}, {"title": "Learning to classify text from labeled and unlabeled documents", "author": ["K. Nigam", "A. McCallum", "S. Thrun", "T. Mitchell"], "venue": "In Association for the Advancement of Artificial Intelligence (AAAI),", "citeRegEx": "Nigam et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Nigam et al\\.", "year": 1998}, {"title": "Estimating accuracy from unlabeled data", "author": ["E.A. Platanios"], "venue": "Master\u2019s thesis,", "citeRegEx": "Platanios.,? \\Q2015\\E", "shortCiteRegEx": "Platanios.", "year": 2015}, {"title": "Estimation of semiparametric models", "author": ["J.L. Powell"], "venue": "In Handbook of Econometrics,", "citeRegEx": "Powell.,? \\Q1994\\E", "shortCiteRegEx": "Powell.", "year": 1994}, {"title": "Dataset shift in machine learning", "author": ["J. Qui\u00f1onero-Candela", "M. Sugiyama", "A. Schwaighofer", "N.D. Lawrence"], "venue": null, "citeRegEx": "Qui\u00f1onero.Candela et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Qui\u00f1onero.Candela et al\\.", "year": 2009}, {"title": "The estimation of economic relationships using instrumental variables", "author": ["J.D. Sargan"], "venue": null, "citeRegEx": "Sargan.,? \\Q1958\\E", "shortCiteRegEx": "Sargan.", "year": 1958}, {"title": "The estimation of relationships with autocorrelated residuals by the use of instrumental variables", "author": ["J.D. Sargan"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Sargan.,? \\Q1959\\E", "shortCiteRegEx": "Sargan.", "year": 1959}, {"title": "Hidden technical debt in machine learning systems", "author": ["D. Sculley", "G. Holt", "D. Golovin", "E. Davydov", "T. Phillips", "D. Ebner", "V. Chaudhary", "M. Young", "J. Crespo", "D. Dennison"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Sculley et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sculley et al\\.", "year": 2015}, {"title": "A tutorial on conformal prediction", "author": ["G. Shafer", "V. Vovk"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Shafer and Vovk.,? \\Q2008\\E", "shortCiteRegEx": "Shafer and Vovk.", "year": 2008}, {"title": "Improving predictive inference under covariate shift by weighting the log-likelihood function", "author": ["H. Shimodaira"], "venue": "Journal of Statistical Planning and Inference,", "citeRegEx": "Shimodaira.,? \\Q2000\\E", "shortCiteRegEx": "Shimodaira.", "year": 2000}, {"title": "Memory, communication, and statistical queries", "author": ["J. Steinhardt", "G. Valiant", "S. Wager"], "venue": "Electronic Colloquium on Computational Complexity (ECCC),", "citeRegEx": "Steinhardt et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Steinhardt et al\\.", "year": 2015}, {"title": "On some techniques useful for solution of transportation network", "author": ["N. Tomizawa"], "venue": "problems. Networks,", "citeRegEx": "Tomizawa.,? \\Q1971\\E", "shortCiteRegEx": "Tomizawa.", "year": 1971}, {"title": "Spectral methods meet EM: A provably optimal algorithm for crowdsourcing", "author": ["Y. Zhang", "X. Chen", "D. Zhou", "M.I. Jordan"], "venue": null, "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "Proof of Theorem 2 We note that Theorem 7 of Anandkumar et al. (2012) (and hence Theorem 1 above) does not require that the Mv be k \u00d7 k, but only that they have k columns (the number of rows can be arbitrary)", "author": ["D claimed"], "venue": null, "citeRegEx": "claimed.,? \\Q2012\\E", "shortCiteRegEx": "claimed.", "year": 2012}], "referenceMentions": [{"referenceID": 15, "context": "How can we assess the accuracy of a model when the test distribution is very different than the training distribution? To address this question, we study the problem of unsupervised risk estimation (Donmez et al., 2010)\u2014that is, given a loss function L(\u03b8;x, y) and a fixed model \u03b8, estimate the risk R(\u03b8) def = Ex,y\u223cp\u2217 [L(\u03b8;x, y)] with respect to a test distribution p\u2217(x, y), given access only to m unlabeled examples x \u223c p\u2217(x).", "startOffset": 198, "endOffset": 219}, {"referenceID": 33, "context": "Several others have extended this idea (e.g. Zhang et al., 2014; Platanios, 2015; Jaffe et al., 2015), but continue to focus on the 0/1 loss (with a single exception that we discuss below).", "startOffset": 39, "endOffset": 101}, {"referenceID": 22, "context": "Several others have extended this idea (e.g. Zhang et al., 2014; Platanios, 2015; Jaffe et al., 2015), but continue to focus on the 0/1 loss (with a single exception that we discuss below).", "startOffset": 39, "endOffset": 101}, {"referenceID": 2, "context": ", 2012), it has a much older history in the econometrics literature, where it has been used as a tool for making causal identifications under structural assumptions, even when an explicit form for the likelihood is not known (Anderson and Rubin, 1949; 1950; Sargan, 1958; 1959; Hansen, 1982; Powell, 1994; Hansen, 2014).", "startOffset": 225, "endOffset": 319}, {"referenceID": 36, "context": ", 2012), it has a much older history in the econometrics literature, where it has been used as a tool for making causal identifications under structural assumptions, even when an explicit form for the likelihood is not known (Anderson and Rubin, 1949; 1950; Sargan, 1958; 1959; Hansen, 1982; Powell, 1994; Hansen, 2014).", "startOffset": 225, "endOffset": 319}, {"referenceID": 19, "context": ", 2012), it has a much older history in the econometrics literature, where it has been used as a tool for making causal identifications under structural assumptions, even when an explicit form for the likelihood is not known (Anderson and Rubin, 1949; 1950; Sargan, 1958; 1959; Hansen, 1982; Powell, 1994; Hansen, 2014).", "startOffset": 225, "endOffset": 319}, {"referenceID": 34, "context": ", 2012), it has a much older history in the econometrics literature, where it has been used as a tool for making causal identifications under structural assumptions, even when an explicit form for the likelihood is not known (Anderson and Rubin, 1949; 1950; Sargan, 1958; 1959; Hansen, 1982; Powell, 1994; Hansen, 2014).", "startOffset": 225, "endOffset": 319}, {"referenceID": 20, "context": ", 2012), it has a much older history in the econometrics literature, where it has been used as a tool for making causal identifications under structural assumptions, even when an explicit form for the likelihood is not known (Anderson and Rubin, 1949; 1950; Sargan, 1958; 1959; Hansen, 1982; Powell, 1994; Hansen, 2014).", "startOffset": 225, "endOffset": 319}, {"referenceID": 40, "context": "If p\u2217(x) and p0(x) are close together, we can approximate p\u2217 by p0 via sample re-weighting (Shimodaira, 2000; Qui\u00f1onero-Candela et al., 2009).", "startOffset": 91, "endOffset": 141}, {"referenceID": 35, "context": "If p\u2217(x) and p0(x) are close together, we can approximate p\u2217 by p0 via sample re-weighting (Shimodaira, 2000; Qui\u00f1onero-Candela et al., 2009).", "startOffset": 91, "endOffset": 141}, {"referenceID": 7, "context": "If p\u2217 and p0 are not close, another approach is to assume a well-specified discriminative model family \u0398, such that p0(y | x) = p\u2217(y | x) = p\u03b8\u2217(y | x) for some \u03b8\u2217 \u2208 \u0398; then we need only heed finite-sample error in the estimation of \u03b8\u2217 (Blitzer et al., 2011; Li et al., 2011).", "startOffset": 235, "endOffset": 274}, {"referenceID": 28, "context": "If p\u2217 and p0 are not close, another approach is to assume a well-specified discriminative model family \u0398, such that p0(y | x) = p\u2217(y | x) = p\u03b8\u2217(y | x) for some \u03b8\u2217 \u2208 \u0398; then we need only heed finite-sample error in the estimation of \u03b8\u2217 (Blitzer et al., 2011; Li et al., 2011).", "startOffset": 235, "endOffset": 274}, {"referenceID": 31, "context": "Indeed, many authors report that mis-specification can lead to severe issues in semi-supervised settings (Merialdo, 1994; Nigam et al., 1998; Cozman and Cohen, 2006; Liang and Klein, 2008; Li and Zhou, 2015).", "startOffset": 105, "endOffset": 207}, {"referenceID": 32, "context": "Indeed, many authors report that mis-specification can lead to severe issues in semi-supervised settings (Merialdo, 1994; Nigam et al., 1998; Cozman and Cohen, 2006; Liang and Klein, 2008; Li and Zhou, 2015).", "startOffset": 105, "endOffset": 207}, {"referenceID": 13, "context": "Indeed, many authors report that mis-specification can lead to severe issues in semi-supervised settings (Merialdo, 1994; Nigam et al., 1998; Cozman and Cohen, 2006; Liang and Klein, 2008; Li and Zhou, 2015).", "startOffset": 105, "endOffset": 207}, {"referenceID": 30, "context": "Indeed, many authors report that mis-specification can lead to severe issues in semi-supervised settings (Merialdo, 1994; Nigam et al., 1998; Cozman and Cohen, 2006; Liang and Klein, 2008; Li and Zhou, 2015).", "startOffset": 105, "endOffset": 207}, {"referenceID": 29, "context": "Indeed, many authors report that mis-specification can lead to severe issues in semi-supervised settings (Merialdo, 1994; Nigam et al., 1998; Cozman and Cohen, 2006; Liang and Klein, 2008; Li and Zhou, 2015).", "startOffset": 105, "endOffset": 207}, {"referenceID": 7, "context": "intuition is formalized by Dawid and Skene (1979) when the fv take values in a discrete set (e.", "startOffset": 27, "endOffset": 50}, {"referenceID": 0, "context": "Anandkumar et al., 2012), it has a much older history in the econometrics literature, where it has been used as a tool for making causal identifications under structural assumptions, even when an explicit form for the likelihood is not known (Anderson and Rubin, 1949; 1950; Sargan, 1958; 1959; Hansen, 1982; Powell, 1994; Hansen, 2014). It is upon this older literature that we draw conceptual inspiration, though our technical tools are more closely based on the newer machine learning approaches. The key insight is that certain moment equations\u2013e.g., E[f1f2 | y] = E[f1 | y]E[f2 | y]\u2013 can be derived from the assumed independencies; we then show how to estimate the risk while relying only on these moment conditions, and not on any parametric assumptions about the xv or fv. Moreover, these moment equations also hold for the gradient of fv , which enables efficient unsupervised learning. Our paper is structured as follows. In Section 2, we present our basic framework, and state and prove our main result on estimating the risk given f1, f2, and f3. In Section 3, we extend our framework in several directions, including to hidden Markov models. In Section 4, we present a gradient-based learning algorithm and show that the sample complexity needed for learning is d \u00b7 poly(k)/ , where d is the dimension of \u03b8. In Section 5, we investigate how our method performs empirically. Related Work. While the formal problem of unsupervised risk estimation was only posed recently by Donmez et al. (2010), several older ideas from domain adaptation and semi-supervised learning are also relevant.", "startOffset": 0, "endOffset": 1505}, {"referenceID": 0, "context": "Anandkumar et al., 2012), it has a much older history in the econometrics literature, where it has been used as a tool for making causal identifications under structural assumptions, even when an explicit form for the likelihood is not known (Anderson and Rubin, 1949; 1950; Sargan, 1958; 1959; Hansen, 1982; Powell, 1994; Hansen, 2014). It is upon this older literature that we draw conceptual inspiration, though our technical tools are more closely based on the newer machine learning approaches. The key insight is that certain moment equations\u2013e.g., E[f1f2 | y] = E[f1 | y]E[f2 | y]\u2013 can be derived from the assumed independencies; we then show how to estimate the risk while relying only on these moment conditions, and not on any parametric assumptions about the xv or fv. Moreover, these moment equations also hold for the gradient of fv , which enables efficient unsupervised learning. Our paper is structured as follows. In Section 2, we present our basic framework, and state and prove our main result on estimating the risk given f1, f2, and f3. In Section 3, we extend our framework in several directions, including to hidden Markov models. In Section 4, we present a gradient-based learning algorithm and show that the sample complexity needed for learning is d \u00b7 poly(k)/ , where d is the dimension of \u03b8. In Section 5, we investigate how our method performs empirically. Related Work. While the formal problem of unsupervised risk estimation was only posed recently by Donmez et al. (2010), several older ideas from domain adaptation and semi-supervised learning are also relevant. The covariate shift assumption assumes access to labeled samples from a base distribution p0(x, y) for which p\u2217(y | x) = p0(y | x). If p\u2217(x) and p0(x) are close together, we can approximate p\u2217 by p0 via sample re-weighting (Shimodaira, 2000; Qui\u00f1onero-Candela et al., 2009). If p\u2217 and p0 are not close, another approach is to assume a well-specified discriminative model family \u0398, such that p0(y | x) = p\u2217(y | x) = p\u03b8\u2217(y | x) for some \u03b8\u2217 \u2208 \u0398; then we need only heed finite-sample error in the estimation of \u03b8\u2217 (Blitzer et al., 2011; Li et al., 2011). Both assumptions are somewhat stringent \u2014 re-weighting only allows small perturbations, and mis-specified models are common in practice. Indeed, many authors report that mis-specification can lead to severe issues in semi-supervised settings (Merialdo, 1994; Nigam et al., 1998; Cozman and Cohen, 2006; Liang and Klein, 2008; Li and Zhou, 2015). As mentioned above, our approach is closer in spirit to that of Dawid and Skene (1979) and its extensions.", "startOffset": 0, "endOffset": 2581}, {"referenceID": 0, "context": "Anandkumar et al., 2012), it has a much older history in the econometrics literature, where it has been used as a tool for making causal identifications under structural assumptions, even when an explicit form for the likelihood is not known (Anderson and Rubin, 1949; 1950; Sargan, 1958; 1959; Hansen, 1982; Powell, 1994; Hansen, 2014). It is upon this older literature that we draw conceptual inspiration, though our technical tools are more closely based on the newer machine learning approaches. The key insight is that certain moment equations\u2013e.g., E[f1f2 | y] = E[f1 | y]E[f2 | y]\u2013 can be derived from the assumed independencies; we then show how to estimate the risk while relying only on these moment conditions, and not on any parametric assumptions about the xv or fv. Moreover, these moment equations also hold for the gradient of fv , which enables efficient unsupervised learning. Our paper is structured as follows. In Section 2, we present our basic framework, and state and prove our main result on estimating the risk given f1, f2, and f3. In Section 3, we extend our framework in several directions, including to hidden Markov models. In Section 4, we present a gradient-based learning algorithm and show that the sample complexity needed for learning is d \u00b7 poly(k)/ , where d is the dimension of \u03b8. In Section 5, we investigate how our method performs empirically. Related Work. While the formal problem of unsupervised risk estimation was only posed recently by Donmez et al. (2010), several older ideas from domain adaptation and semi-supervised learning are also relevant. The covariate shift assumption assumes access to labeled samples from a base distribution p0(x, y) for which p\u2217(y | x) = p0(y | x). If p\u2217(x) and p0(x) are close together, we can approximate p\u2217 by p0 via sample re-weighting (Shimodaira, 2000; Qui\u00f1onero-Candela et al., 2009). If p\u2217 and p0 are not close, another approach is to assume a well-specified discriminative model family \u0398, such that p0(y | x) = p\u2217(y | x) = p\u03b8\u2217(y | x) for some \u03b8\u2217 \u2208 \u0398; then we need only heed finite-sample error in the estimation of \u03b8\u2217 (Blitzer et al., 2011; Li et al., 2011). Both assumptions are somewhat stringent \u2014 re-weighting only allows small perturbations, and mis-specified models are common in practice. Indeed, many authors report that mis-specification can lead to severe issues in semi-supervised settings (Merialdo, 1994; Nigam et al., 1998; Cozman and Cohen, 2006; Liang and Klein, 2008; Li and Zhou, 2015). As mentioned above, our approach is closer in spirit to that of Dawid and Skene (1979) and its extensions. Similarly to Zhang et al. (2014) and Jaffe et al.", "startOffset": 0, "endOffset": 2634}, {"referenceID": 0, "context": "Anandkumar et al., 2012), it has a much older history in the econometrics literature, where it has been used as a tool for making causal identifications under structural assumptions, even when an explicit form for the likelihood is not known (Anderson and Rubin, 1949; 1950; Sargan, 1958; 1959; Hansen, 1982; Powell, 1994; Hansen, 2014). It is upon this older literature that we draw conceptual inspiration, though our technical tools are more closely based on the newer machine learning approaches. The key insight is that certain moment equations\u2013e.g., E[f1f2 | y] = E[f1 | y]E[f2 | y]\u2013 can be derived from the assumed independencies; we then show how to estimate the risk while relying only on these moment conditions, and not on any parametric assumptions about the xv or fv. Moreover, these moment equations also hold for the gradient of fv , which enables efficient unsupervised learning. Our paper is structured as follows. In Section 2, we present our basic framework, and state and prove our main result on estimating the risk given f1, f2, and f3. In Section 3, we extend our framework in several directions, including to hidden Markov models. In Section 4, we present a gradient-based learning algorithm and show that the sample complexity needed for learning is d \u00b7 poly(k)/ , where d is the dimension of \u03b8. In Section 5, we investigate how our method performs empirically. Related Work. While the formal problem of unsupervised risk estimation was only posed recently by Donmez et al. (2010), several older ideas from domain adaptation and semi-supervised learning are also relevant. The covariate shift assumption assumes access to labeled samples from a base distribution p0(x, y) for which p\u2217(y | x) = p0(y | x). If p\u2217(x) and p0(x) are close together, we can approximate p\u2217 by p0 via sample re-weighting (Shimodaira, 2000; Qui\u00f1onero-Candela et al., 2009). If p\u2217 and p0 are not close, another approach is to assume a well-specified discriminative model family \u0398, such that p0(y | x) = p\u2217(y | x) = p\u03b8\u2217(y | x) for some \u03b8\u2217 \u2208 \u0398; then we need only heed finite-sample error in the estimation of \u03b8\u2217 (Blitzer et al., 2011; Li et al., 2011). Both assumptions are somewhat stringent \u2014 re-weighting only allows small perturbations, and mis-specified models are common in practice. Indeed, many authors report that mis-specification can lead to severe issues in semi-supervised settings (Merialdo, 1994; Nigam et al., 1998; Cozman and Cohen, 2006; Liang and Klein, 2008; Li and Zhou, 2015). As mentioned above, our approach is closer in spirit to that of Dawid and Skene (1979) and its extensions. Similarly to Zhang et al. (2014) and Jaffe et al. (2015), we use the method of moments for estimating latent-variable models However, those papers use it as a tool for parameter estimation in the face of non-convexity, rather than as a way to sidestep model mis-specification.", "startOffset": 0, "endOffset": 2658}, {"referenceID": 0, "context": "Anandkumar et al., 2012), it has a much older history in the econometrics literature, where it has been used as a tool for making causal identifications under structural assumptions, even when an explicit form for the likelihood is not known (Anderson and Rubin, 1949; 1950; Sargan, 1958; 1959; Hansen, 1982; Powell, 1994; Hansen, 2014). It is upon this older literature that we draw conceptual inspiration, though our technical tools are more closely based on the newer machine learning approaches. The key insight is that certain moment equations\u2013e.g., E[f1f2 | y] = E[f1 | y]E[f2 | y]\u2013 can be derived from the assumed independencies; we then show how to estimate the risk while relying only on these moment conditions, and not on any parametric assumptions about the xv or fv. Moreover, these moment equations also hold for the gradient of fv , which enables efficient unsupervised learning. Our paper is structured as follows. In Section 2, we present our basic framework, and state and prove our main result on estimating the risk given f1, f2, and f3. In Section 3, we extend our framework in several directions, including to hidden Markov models. In Section 4, we present a gradient-based learning algorithm and show that the sample complexity needed for learning is d \u00b7 poly(k)/ , where d is the dimension of \u03b8. In Section 5, we investigate how our method performs empirically. Related Work. While the formal problem of unsupervised risk estimation was only posed recently by Donmez et al. (2010), several older ideas from domain adaptation and semi-supervised learning are also relevant. The covariate shift assumption assumes access to labeled samples from a base distribution p0(x, y) for which p\u2217(y | x) = p0(y | x). If p\u2217(x) and p0(x) are close together, we can approximate p\u2217 by p0 via sample re-weighting (Shimodaira, 2000; Qui\u00f1onero-Candela et al., 2009). If p\u2217 and p0 are not close, another approach is to assume a well-specified discriminative model family \u0398, such that p0(y | x) = p\u2217(y | x) = p\u03b8\u2217(y | x) for some \u03b8\u2217 \u2208 \u0398; then we need only heed finite-sample error in the estimation of \u03b8\u2217 (Blitzer et al., 2011; Li et al., 2011). Both assumptions are somewhat stringent \u2014 re-weighting only allows small perturbations, and mis-specified models are common in practice. Indeed, many authors report that mis-specification can lead to severe issues in semi-supervised settings (Merialdo, 1994; Nigam et al., 1998; Cozman and Cohen, 2006; Liang and Klein, 2008; Li and Zhou, 2015). As mentioned above, our approach is closer in spirit to that of Dawid and Skene (1979) and its extensions. Similarly to Zhang et al. (2014) and Jaffe et al. (2015), we use the method of moments for estimating latent-variable models However, those papers use it as a tool for parameter estimation in the face of non-convexity, rather than as a way to sidestep model mis-specification. The insight that moments are robust to model mis-specification lets us extend beyond the simple discrete settings they consider in order to handle more complex continuous and structured losses. Another approach to handling continuous losses is given in the intriguing work of Balasubramanian et al. (2011), who show that the distribution of losses L | y is often close to Gaussian in practice, and use this to estimate", "startOffset": 0, "endOffset": 3184}, {"referenceID": 27, "context": "1 For v = 2 views, recovering R is related to non-negative matrix factorization (Lee and Seung, 2001).", "startOffset": 80, "endOffset": 101}, {"referenceID": 26, "context": "The left-hand-side of each equation can be estimated from unlabeled data; we can then solve for Mv and \u03c0 using tensor decomposition (Lathauwer, 2006; Comon et al., 2009; Anandkumar et al., 2012; 2013; Kuleshov et al., 2015).", "startOffset": 132, "endOffset": 223}, {"referenceID": 12, "context": "The left-hand-side of each equation can be estimated from unlabeled data; we can then solve for Mv and \u03c0 using tensor decomposition (Lathauwer, 2006; Comon et al., 2009; Anandkumar et al., 2012; 2013; Kuleshov et al., 2015).", "startOffset": 132, "endOffset": 223}, {"referenceID": 0, "context": "The left-hand-side of each equation can be estimated from unlabeled data; we can then solve for Mv and \u03c0 using tensor decomposition (Lathauwer, 2006; Comon et al., 2009; Anandkumar et al., 2012; 2013; Kuleshov et al., 2015).", "startOffset": 132, "endOffset": 223}, {"referenceID": 25, "context": "The left-hand-side of each equation can be estimated from unlabeled data; we can then solve for Mv and \u03c0 using tensor decomposition (Lathauwer, 2006; Comon et al., 2009; Anandkumar et al., 2012; 2013; Kuleshov et al., 2015).", "startOffset": 132, "endOffset": 223}, {"referenceID": 11, "context": "It would be interesting to extend our results to other structures such as more general graphical models (Chaganty and Liang, 2014) and parse trees (Hsu et al.", "startOffset": 104, "endOffset": 130}, {"referenceID": 21, "context": "It would be interesting to extend our results to other structures such as more general graphical models (Chaganty and Liang, 2014) and parse trees (Hsu et al., 2012).", "startOffset": 147, "endOffset": 165}, {"referenceID": 18, "context": "We take a standard approach based on random projections (Halko et al., 2011) and described in", "startOffset": 56, "endOffset": 76}, {"referenceID": 0, "context": "2 of Anandkumar et al. (2013). We refer the reader to the aforementioned references for details, and cite only the final sample complexity and runtime (see Section D for a proof sketch): Theorem 2.", "startOffset": 5, "endOffset": 30}, {"referenceID": 16, "context": "We trained the model with AdaGrad (Duchi et al., 2010) on 10, 000 training examples, and used 10, 000 test examples to estimate the risk.", "startOffset": 34, "endOffset": 54}, {"referenceID": 10, "context": "To solve for \u03c0 and M in (4), we first use the tensor power method implemented by Chaganty and Liang (2013) to initialize, and then locally minimize a weighted `-norm of the moment errors with L-BFGS.", "startOffset": 81, "endOffset": 107}, {"referenceID": 8, "context": "co-training and CCA) are also used in semi-supervised learning (Blum and Mitchell, 1998; Ando and Zhang, 2007; Kakade and Foster, 2007; Balcan and Blum, 2010).", "startOffset": 63, "endOffset": 158}, {"referenceID": 4, "context": "co-training and CCA) are also used in semi-supervised learning (Blum and Mitchell, 1998; Ando and Zhang, 2007; Kakade and Foster, 2007; Balcan and Blum, 2010).", "startOffset": 63, "endOffset": 158}, {"referenceID": 24, "context": "co-training and CCA) are also used in semi-supervised learning (Blum and Mitchell, 1998; Ando and Zhang, 2007; Kakade and Foster, 2007; Balcan and Blum, 2010).", "startOffset": 63, "endOffset": 158}, {"referenceID": 6, "context": "co-training and CCA) are also used in semi-supervised learning (Blum and Mitchell, 1998; Ando and Zhang, 2007; Kakade and Foster, 2007; Balcan and Blum, 2010).", "startOffset": 63, "endOffset": 158}, {"referenceID": 23, "context": ", transductive SVMs (Joachims, 1999).", "startOffset": 20, "endOffset": 36}, {"referenceID": 38, "context": "In addition to reliability and unsupervised learning, our work is motivated by the desire to build machine learning system with contracts, a challenge recently posed by Bottou (2015); the goal is for machine learning systems to satisfy a well-defined input-output contract in analogy with software systems (Sculley et al., 2015).", "startOffset": 306, "endOffset": 328}, {"referenceID": 4, "context": "Given two views, Blitzer et al. (2011) perform domain adaptation with zero source/target overlap (covariate shift is still assumed).", "startOffset": 17, "endOffset": 39}, {"referenceID": 4, "context": "co-training and CCA) are also used in semi-supervised learning (Blum and Mitchell, 1998; Ando and Zhang, 2007; Kakade and Foster, 2007; Balcan and Blum, 2010). These methods all assume some form of low noise or low regret, as do, e.g., transductive SVMs (Joachims, 1999). By focusing on the central problem of risk estimation, our work connects multi-view learning approaches for domain adaptation and semi-supervised learning, and removes covariate shift and low-noise/low-regret assumptions (though we make stronger independence assumptions, and specialize to discrete prediction tasks). In addition to reliability and unsupervised learning, our work is motivated by the desire to build machine learning system with contracts, a challenge recently posed by Bottou (2015); the goal is for machine learning systems to satisfy a well-defined input-output contract in analogy with software systems (Sculley et al.", "startOffset": 89, "endOffset": 773}, {"referenceID": 4, "context": "co-training and CCA) are also used in semi-supervised learning (Blum and Mitchell, 1998; Ando and Zhang, 2007; Kakade and Foster, 2007; Balcan and Blum, 2010). These methods all assume some form of low noise or low regret, as do, e.g., transductive SVMs (Joachims, 1999). By focusing on the central problem of risk estimation, our work connects multi-view learning approaches for domain adaptation and semi-supervised learning, and removes covariate shift and low-noise/low-regret assumptions (though we make stronger independence assumptions, and specialize to discrete prediction tasks). In addition to reliability and unsupervised learning, our work is motivated by the desire to build machine learning system with contracts, a challenge recently posed by Bottou (2015); the goal is for machine learning systems to satisfy a well-defined input-output contract in analogy with software systems (Sculley et al., 2015). Theorem 1 provides the contract that under the 3-view assumption the test error is close to our estimate of the test error; this contrasts with the typical weak contract that if train and test are similar, then the test error is close to the training error. One other interesting contract is given by Shafer and Vovk (2008), who provide prediction regions that contain the true prediction with probability 1\u2212 in the online setting, even in the presence of model mis-specification.", "startOffset": 89, "endOffset": 1244}, {"referenceID": 4, "context": "co-training and CCA) are also used in semi-supervised learning (Blum and Mitchell, 1998; Ando and Zhang, 2007; Kakade and Foster, 2007; Balcan and Blum, 2010). These methods all assume some form of low noise or low regret, as do, e.g., transductive SVMs (Joachims, 1999). By focusing on the central problem of risk estimation, our work connects multi-view learning approaches for domain adaptation and semi-supervised learning, and removes covariate shift and low-noise/low-regret assumptions (though we make stronger independence assumptions, and specialize to discrete prediction tasks). In addition to reliability and unsupervised learning, our work is motivated by the desire to build machine learning system with contracts, a challenge recently posed by Bottou (2015); the goal is for machine learning systems to satisfy a well-defined input-output contract in analogy with software systems (Sculley et al., 2015). Theorem 1 provides the contract that under the 3-view assumption the test error is close to our estimate of the test error; this contrasts with the typical weak contract that if train and test are similar, then the test error is close to the training error. One other interesting contract is given by Shafer and Vovk (2008), who provide prediction regions that contain the true prediction with probability 1\u2212 in the online setting, even in the presence of model mis-specification. The most restrictive part of our framework is the three-view assumption, which is inappropriate if the views are not completely independent or if the data have structure that is not captured in terms of multiple views. Since Balasubramanian et al. (2011) obtain results under Gaussianity (which would be implied by many somewhat dependent views), we are optimistic that unsupervised risk estimation is possible for a wider family of structures.", "startOffset": 89, "endOffset": 1656}], "year": 2016, "abstractText": "We show how to estimate a model\u2019s test error from unlabeled data, on distributions very different from the training distribution, while assuming only that certain conditional independencies are preserved between train and test. We do not need to assume that the optimal predictor is the same between train and test, or that the true distribution lies in any parametric family. We can also efficiently differentiate the error estimate to perform unsupervised discriminative learning. Our technical tool is the method of moments, which allows us to exploit conditional independencies in the absence of a fully-specified model. Our framework encompasses a large family of losses including the log and exponential loss, and extends to structured output settings such as hidden Markov models.", "creator": "LaTeX with hyperref package"}}}