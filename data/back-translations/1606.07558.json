{"id": "1606.07558", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2016", "title": "Satisfying Real-world Goals with Dataset Constraints", "abstract": "The goal of minimizing misclassification errors on a training set is often just one of several goals in the real world that could be defined on different sets of data. For example, you may need a classifier to make positive predictions for a specific group (fairness) or to achieve a specific empirical callback. Other goals in the real world include reducing waste related to a previously used model or stabilizing online training. In this paper, we propose to address multiple goals on multiple sets of data by training with data set limitations, using the lead penalty to accurately quantify costs, and presenting an efficient algorithm to approximately optimize the resulting non-convective optimization problem. Experiments on both benchmark and real industry data sets demonstrate the effectiveness of our approach.", "histories": [["v1", "Fri, 24 Jun 2016 03:42:41 GMT  (209kb,D)", "http://arxiv.org/abs/1606.07558v1", null], ["v2", "Wed, 3 May 2017 23:02:56 GMT  (393kb)", "http://arxiv.org/abs/1606.07558v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["gabriel goh", "andrew cotter", "maya r gupta", "michael p friedlander"], "accepted": true, "id": "1606.07558"}, "pdf": {"name": "1606.07558.pdf", "metadata": {"source": "CRF", "title": "Satisfying Real-world Goals with Dataset Constraints", "authors": ["Andrew Cotter", "Michael Friedlander", "Gabriel Goh", "Maya Gupta"], "emails": [], "sections": [{"heading": "1 Real-world goals", "text": "We consider a broad set of design goals and issues important for making classifiers work well in real-world applications, ranging from the standard precision and recall, to some new proposals. The key theme is that these goals can be expressed in terms of the positive and negative classification rates on multiple datasets, as we show in Table 1.\nCoverage: One may wish to control how often a classifier predicts the positive (or negative) class. For example, one may want to ensure that only 10% of customers are selected to receive a printed catalog due to budget constraints, or perhaps to compensate for a biased training set. In practice, constraining the \u201ccoverage rate\u201d (the expected proportion of positive predictions) is often easier than measuring e.g. accuracy or precision because coverage can be computed on unlabeled data\u2014labeling data can be expensive, but acquiring a large number of unlabeled examples is often very easy.\nCoverage was also considered by Mann and McCallum [2007], who proposed what they call \u201clabel regularization\u201d, in which one adds a regularizer that penalizes the relative entropy between the mean classifier score for each class and the desired distribution, with an additional correction to avoid degeneracies.\nChurn: Work does not stop once a machine learning model has been adopted. There will be new training data, improved features, and potentially new model structures. Hence, in practice, one will deploy a series of models, each improving slightly upon the last. In this setting, determining whether each candidate should be deployed is surprisingly challenging: if we evaluate on the same held-out testing set every time a new candidate is proposed, and deploy it if it outperforms its predecessor, then every compare-and-deploy decision will increase the statistical dependence between the deployed model and the testing dataset, causing the model sequence to fit the originally-independent testing data. This problem is magnified if, as is typical, the candidate models tend to disagree only on a relatively small number of examples near the true decision boundary. For example, with a fixed test set of 10 000 random examples, only 100 may be near to the decision boundary, so the risk of the model sequence fitting these 100 examples is heightened.\nar X\niv :1\n60 6.\n07 55\n8v 1\n[ cs\n.L G\n] 2\n4 Ju\nn 20\nA simple and safe solution is to draw a fresh testing sample every time one wishes to compare two models in the sequence, only considering examples on which the two models disagree. Because labeling data is expensive, one would like these freshly sampled testing datasets to be as small as possible. It is here that the problem of \u201cchurn\u201d arises. Imagine that model A, our deployed model, is 70% accurate, and that model B, our candidate, is 75% accurate. In the best case, only 5% of test samples would be labeled differently, and all differences would be \u201cwins\u201d for classifier B. Then only a dozen or so examples would need to be labeled in order to establish that B is the statistically significantly better classifier with 95% confidence. In the worst case, model A would be correct and model B is incorrect 25% of the time, model B correct and model A incorrect 30% of the time, and both models correct the remaining 45% of the time. Then 55% of testing examples will be labeled differently, and closer to 1000 examples would need to be labeled to determine that model B is better.\nWe define the \u201cchurn rate\u201d as the expected proportion of examples on which the prediction of the model being considered (model B above) differs from that of a baseline model (model A). During training, we propose constraining the empirical churn rate with respect to a given baseline model on a large unlabeled dataset.\nStability: A special case of minimizing churn is to ensure stability of an online classifier as it evolves, by constraining it to not deviate too far from a trusted classifier on a large held-out unlabeled dataset.\nFairness: A practitioner may be required to guarantee fairness of a learned classifier, in the sense that it makes positive predictions for members of different subgroups at certain rates. For example, one might require that housing loans be given equally to people of different genders. As noted by Zafar et al. [2015], fairness is sometimes specified by a proportion, such as the 80% rule in US law that certain decisions must be in favor of group B individuals at least 80% as often as in favor of group A individuals [e.g. Biddle, 2005, Vuolo and Levy, 2013]. Zafar et al. [2015] propose learning fair classifiers by imposing linear constraints on the covariance between the predicted labels and the values of certain features. In our framework, rate constraints such as the 80% rule can be imposed directly.\nRecall and Precision: Requirements of real-world classifiers are often expressed in terms of precision and recall, especially when examples are highly imbalanced between positives and negatives. In our framework, we can handle this problem via Neyman-Pearson classification [e.g. Scott and Nowak, 2005, Davenport et al., 2010], in which one seeks to minimize the false negative rate subject to a constraint on the false positive rate. Indeed, our ramp-loss formulation is equivalent to that of Gasso et al. [2011] in this setting.\nEgregious Examples: For certain classification applications, examples may be discovered that are particularly embarrassing if classified incorrectly. One standard approach to handling such examples is to increase their weights during training, but this is difficult to get right, because too large a weight may distort the classifier too much in the surrounding feature space, whereas too small a weight may not fix the problem. Worse, over time the dataset will often be augmented with new training examples and new features, causing the ideal weights to drift. We propose instead simply adding a constraint ensuring that some proportion of a set of such egregious examples is correctly classified. Such constraints should be used with extreme care: if too many are added then the problem may become infeasible."}, {"heading": "2 Optimization problem", "text": "A key aspect of many of the goals of Section 1 is that they are defined on different datasets. For example, we might seek to maximize the accuracy of our classifier on a set of labeled examples drawn in some biased manner, require that its recall be at least 90% on 50 small datasets sampled in an unbiased manner from 50 different countries, desire low churn relative to a deployed classifier on a large unbiased unlabeled dataset, and require that 100 given egregious examples be classified correctly.\nAnother characteristic common to the metrics of Section 1 is that they can be expressed in terms of the positive and negative classification rates on various datasets, where for simplicity, we treat all datasets as unlabeled, as described in Table 1. We\u2019ll restrict our attention to the problem of learning a linear classification function f(x) = \u3008w, x\u3009 \u2212 b parameterized by a weight vector w \u2208 Rd and bias b \u2208 R, for which these rates are:\nwhere 1 is an indicator function that is 1 if its argument is positive, 0 otherwise. In words, sp(D;w, b) and sn(D;w, b) denote the proportion of positive or negative predictions, respectively, that f makes on D. Table 2 specifies how the metrics of Section 1 can be expressed in terms of the sps and sns.\nWe propose handling these goals by minimizing an `2-regularized positive linear combination of prediction rates on different datasets, subject to upper-bound constraints on other positive linear combinations of such prediction rates:\nminimize w\u2208Rd,b\u2208R\n\u2211k i=1 ( \u03b1 (0) i sp(Di;w, b) + \u03b2 (0) i sn(Di;w, b) ) + \u03bb2 \u2016w\u2016 2 2 (2)\ns.t. \u2211k i=1 ( \u03b1 (j) i sp(Di;w, b) + \u03b2 (j) i sn(Di;w, b) ) \u2264 \u03b3(j) j \u2208 {1, . . . ,m}\nwhere \u03bb is the parameter on the `2 regularizer, there are k unlabeled datasets D1, . . . , Dk and m constraints. The metrics minimized by the objective and bounded by the constraints are specified via the choices of the nonnegative coefficients \u03b1(0)i , \u03b1 (j) i , \u03b2 (0) i and \u03b2 (j) i for the ith dataset and, where applicable, the jth constraint\u2014a user should base these choices on Table 2. Note that because sp + sn = 1, it is possible to transform any linear combination of rates into an equivalent positive linear combination, plus a constant (see Appendix A1 for an example).\nWe cannot optimize Problem 2 directly because the rate functions sp and sn are discontinuous. We can, however, work around this difficulty by following Cotter et al. [2013] and training a classifier that makes\n1Appendices may be found in the supplementary material\nAlgorithm 1 Proposed majorization-minimization procedure for (approximately) optimizing the ramp version of Problem 2. Starting from an initial feasible solution w(0), b0, we repeatedly find a convex upper bound problem that is tight at the current candidate solution, and optimize it to yield the next candidate. See Section 2.1 for details, and Section 2.2 for how one can perform the inner optimizations on line 3.\nMajorizationMinimization ( w(0), b0, T ) 1 For t \u2208 {1, 2, . . . , T} 2 Construct an instance of Problem 3 with w\u2032 = w(t\u22121) and b\u2032 = bt\u22121 3 Optimize this convex optimization problem to yield w(t) and bt 4 Return w(t), bt\nrandomized predictions based on the ramp function [Collobert et al., 2006]:\n\u03c3(z) = max{0,min{1, 1/2 + z}}\nwhere the randomized classifier parameterized by w and b will make a positive prediction on x with probability \u03c3 (\u3008w, x\u3009 \u2212 b), and will make a negative prediction otherwise. We can then define the expected positive and negative rates (with the expectation being taken w.r.t. the randomness of the classifier) on an unlabeled dataset D as:\nrp (D;w, b) = 1 |D| \u2211 x\u2208D\u03c3 (\u3008w, x\u3009 \u2212 b) , rn (D;w, b) = rp (D;\u2212w,\u2212b)\nSubstituting these expected rates for sp and sn gives a continuous (but non-convex) problem that we will henceforth refer to as the \u201cramp version\u201d of Problem 2."}, {"heading": "2.1 Optimizing the ramp problem", "text": "To address the non-convexity of the ramp version of our problem, we will iteratively optimize approximations, by, starting from an initial candidate solution, constructing a convex optimization problem upper-bounding the ramp version of Problem 2 that is tight at the current candidate, optimizing this convex problem to yield the next candidate, and repeating.\nOur choice of a ramp for \u03c3 makes finding such tight convex upper bounds easy: both the hinge function max {0, 1/2 + z} and constant-1 function upper bound \u03c3, with the former being tight for all z \u2264 1/2, and the\nlatter for all z \u2265 1/2 (see Figure 1). We\u2019ll therefore define the following upper bounds on \u03c3 and 1\u2212 \u03c3, with the additional parameter z\u2032 determining which of the two bounds (hinge or constant) will be used, such that the bounds will always be tight for z = z\u2032:\n\u03c3\u030cp (z; z \u2032) = { max {0, 1/2 + z} if z\u2032 \u2264 1/2 1 otherwise , \u03c3\u030cn(z; z \u2032) = \u03c3\u030cp (\u2212z;\u2212z\u2032)\nBased upon these we define the following upper bounds on the expected rates:\nr\u030cp (D;w, b;w \u2032, b\u2032) = 1|D| \u2211 x\u2208D \u03c3\u030cp (\u3008w, x\u3009 \u2212 b; \u3008w\u2032, x\u3009 \u2212 b\u2032) r\u030cn (D;w, b;w \u2032, b\u2032) = 1|D| \u2211 x\u2208D \u03c3\u030cn (\u3008w, x\u3009 \u2212 b; \u3008w\u2032, x\u3009 \u2212 b\u2032)\nwhich have the properties that both r\u030cp and r\u030cn are convex in w and b, are upper bounds on the original ramp-based rates:\nr\u030cp (D;w, b;w \u2032, b\u2032) \u2265 rp (D;w, b) and r\u030cn (D;w, b;w\u2032, b\u2032) \u2265 rn (D;w, b)\nand are tight at w\u2032, b\u2032:\nr\u030cp (D;w \u2032, b\u2032;w\u2032, b\u2032) = rp (D;w \u2032, b\u2032) and r\u030cn (D;w\u2032, b\u2032;w\u2032, b\u2032) = rn (D;w\u2032, b\u2032)\nSubstituting these bounds into the ramp version of Equation 2 yields:\nminimize w\u2208Rd,b\u2208R\n\u2211k i=1 ( \u03b1 (0) i r\u030cp (Di;w, b;w \u2032, b\u2032) + \u03b2 (0) i r\u030cn (Di;w, b;w \u2032, b\u2032) ) + \u03bb2 \u2016w\u2016 2 2 (3)\ns.t. \u2211k i=1 ( \u03b1 (j) i r\u030cp (Di;w, b;w \u2032, b\u2032) + \u03b2 (j) i r\u030cn (Di;w, b;w \u2032, b\u2032) ) \u2264 \u03b3(j) j \u2208 {1, . . . ,m}\nAs desired, this problem upper bounds the ramp version of Problem 2, is tight at w\u2032, b\u2032, and is convex (because we only permit positive linear combinations of rates, and any positive linear combination of convex functions is convex).\nAlgorithm 1 contains our proposed (approximate) optimization procedure for solving Problem 3. Given an initial feasible solution, it\u2019s straightforward to verify inductively, using the fact that we construct tight convex upper bounds at every step, that every convex subproblem will have a feasible solution, every w(t), bt will be feasible w.r.t. the ramp version of Problem 2, and every pair (w(t+1), bt+1) will have an objective function value that is no higher that that of (w(t), bt). In other words, no iteration can make negative progress.\nThe non-convexity of the ramp version of Problem 2 will cause Algorithm 1 to arrive at a suboptimal solution that depends on the initial (w(0), b0)."}, {"heading": "2.2 Optimizing the convex subproblems", "text": "Our approach for optimizing the constrained convex subproblems is based on the idea of adding Lagrange multipliers v over the constraints in Problem 3 to obtain the equivalent unconstrained problem:\nmaximize v 0 z(v) = min w,b\n\u03a8 (w, b, v;w\u2032, b\u2032) (4)\nwhere the function:\n\u03a8 (w, b, v;w\u2032, b\u2032) = \u2211k i=1 (( \u03b1 (0) i + \u2211m j=1vj\u03b1 (j) i ) r\u030cp (Di;w, b;w \u2032, b\u2032) (5)\n+ ( \u03b2 (0) i + \u2211m j=1vj\u03b2 (j) i ) r\u030cn (Di;w, b;w \u2032, b\u2032) ) + \u03bb2 \u2016w\u2016 2 2 \u2212 \u2211m j=1vj\u03b3 (j)\nis convex in w and b, and concave in the multipliers v. For the purposes of this section, w\u2032 and b\u2032 are fixed constants.\nAlgorithm 2 Skeleton of a cutting-plane algorithm that solves Problem 4 to within . Here, V \u2286 Rm is compact and convex and l0, u0 \u2208 R are finite with l0 \u2264 maxv z(v) \u2264 u0. There are several options for the CutChooser function on line 8\u2014please see Appendix C for details. The SVMOptimizer function returns w(t) and bt approximately minimizing \u03a8(w, b, v(t);w\u2032, b\u2032), and a lower bound lt \u2264 z(v) for which ut \u2212 lt \u2264 t for ut as defined on line 9.\nCuttingPlane (l0, u0,V, ) 1 Initialize g(0) \u2208 Rm to the all-zero vector 2 For t \u2208 {1, 2, . . . } 3 Let ht (v) = mins\u2208{0,1,...,t\u22121} ( us + \u2329 g(s), v \u2212 v(s)\n\u232a) 4 Let Lt = maxs\u2208{0,1,...,t\u22121} ls and Ut = maxv\u2208V ht (v) 5 If Ut \u2212 Lt \u2264 then 6 Let s \u2208 {1, . . . , t\u2212 1} be an index maximizing ls 7 Return w(s), bs, v(s) 8 Let v(t), t = CutChooser (ht, Lt) 9 Let w(t), bt, lt = SVMOptimizer ( v(t), Lt, ht ( v(t) ) , t )\n10 Let ut = \u03a8(w(t), bt, v(t);w\u2032, b\u2032) and g(t) = \u2207v\u03a8(w(t), bt, v(t);w\u2032, b\u2032)\nThe key insight is that evaluating z(v) is, thanks to our use of hinge and constant upper-bounds on our ramp \u03c3, equivalent to optimization of a support vector machine (SVM) with per-example weights\u2014see Appendix D for details. This observation enables us to solve the saddle system in an inside-out manner. On the \u201cinside\u201d, we optimize over (w, b) for a fixed v using an off-the-shelf SVM solver. On the \u201coutside\u201d, the resulting (w, b)-optimizer is used as a component in an outer optimization over v. Notice that this outer optimization is very low-dimensional, since v \u2208 Rm, where m is the number of constraints.\nAlgorithm 2 contains a skeleton of the cutting-plane algorithm that we use for this outer optimization over v. Because this algorithm is intended to be used as an outer loop in a nested optimization routine, it does not expect that z(v) can be evaluated or differentiated exactly. Rather, it\u2019s based upon the idea of possibly making \u201cshallow\u201d cuts [Bland et al., 1981] by choosing a desired accuracy t at each iteration, and expecting the SVMOptimizer to return a solution with suboptimality t. More precisely, the SVMOptimizer function approximately evaluates z(v(t)) for a given fixed v(t) by constructing the corresponding SVM problem and finding a (w(t), bt) for which the primal and dual objective function values differ by at most t.\nAfter finding (w(t), bt), the SVMOptimizer then evaluates the dual objective function value of the SVM to determine lt. The primal objective function value ut and its gradient g(t) w.r.t. v (calculated on line 9 of Algorithm 2) define the cut ut + \u2329 g(t), v \u2212 v(t) \u232a . Notice that since \u03a8(w(t), bt, v;w\u2032, b\u2032) is a linear function of v, it is equal to this cut function, which therefore upper-bounds minw,b \u03a8(w, b, v;w\u2032, b\u2032). One advantage of this cutting-plane formulation is that typical CutChooser implementations will choose\nt to be large in the early iterations, and will only shrink it to be or smaller once we\u2019re close to convergence. We leave the details of the analysis to the appendices\u2014a summary can be found in Appendix E."}, {"heading": "3 Related work", "text": "One strategy to satisfy some of the goals described in Section 1 is to first train an unconstrained classifier, and then adjust the decision threshold to satisfy the goals as a second step. Another standard approach is to reweight groups of examples as a preprocessing step\u2014notice that, in our formulation, the Lagrange multipliers v play an identical role to such weights, with the difference being that they are dynamically chosen so as to satisfy constraints, rather than being provided by the user.\nCollobert et al. [2006] also use a ramp loss as a relaxation of 0/1 loss (for optimizing accuracy), but do not consider constraints. The most related prior work is that of Gasso et al. [2011]. They also use an iterative ramp loss approximation, but only tackle the Neyman-Pearson problem, and their algorithm is less straightforward than that presented here. Gasso et al. [2011] compared their Neyman-Pearson classifier\nto that of Davenport et al. [2010], which differs in that it uses a hinge loss approximation instead of the ramp loss, and found with the ramp-loss they achieved similar or slightly better results with up to 10\u00d7 less computation.\nNarasimhan et al. [2015] considered optimizing for the F-measure and other quantities that can be written as concave functions of the TP and TN. In their proposed stochastic dual solver, they adaptively linearize concave functions of the rate functions (Equation 1). Joachims [2005] indirectly optimizes upper-bounds on functions of sp(D+), sp(D\u2212), sn(D+), sn(D\u2212) using a hinge loss approximation."}, {"heading": "4 Experiments", "text": "We demonstrate the accuracy of the proposed algorithm for satisfying these goals on a benchmark dataset for fairness, and a real-world problem with churn and recall constraints."}, {"heading": "4.1 Fairness", "text": "We compare training for fairness on the benchmark Adult dataset 2, the same dataset used by Zafar et al. [2015]. The 32 561 training and 16 281 testing examples, derived from the 1994 Census, are 123-dimensional and sparse. Each feature contains categorical attributes such as race, gender, education levels and relationship status. A positive class label means that individual\u2019s income exceeds 50k. Let DM and DF denote the sets of male and female examples. The number of positive labels in DM is roughly six times that of DF . The goal is to train a classifier that respects the fairness constraint sp ( DM ) \u2264 sp ( DF ) /\u03ba. for a parameter \u03ba \u2208 (0, 1] (where \u03ba = 0.8 corresponds to the 80% rule mentioned in Section 1). Our publicly-available Julia implementation3 for these experiments uses LIBLINEAR [Fan et al., 2008] to implement the SVMOptimizer function, and does not include an unregularized bias b. The outer optimization over v does not use the m-dimensional cutting plane algorithm of Algorithm 2, instead using a simpler one-dimensional variant (observe that these experiments involve only one constraint).\n2\u201ca9a\u201d from https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html 3Link redacted for blind review\nWe compare to the method of Zafar et al. [2015], which proposed handling fairness with the constraint: \u3008w, x\u0304\u3009 \u2264 c, x\u0304 = \u2223\u2223DM \u2223\u2223\u22121\u2211x\u2208DMx \u2212 \u2223\u2223DF \u2223\u2223\u22121\u2211x\u2208DF x. (6)\nWe optimized an SVM subject to this constraint (see Appendix B for details), for a range of c values. Results in Figure 2 show the proposed method is much more accurate for any desired fairness, and achieves fairness ratios not reachable with the approach of Zafar et al. [2015] for any choice of c. It is also easier to control: the values of c in Zafar et al. [2015] do not have a clear interpretation, whereas \u03ba is an effective proxy for the fairness ratio."}, {"heading": "4.2 Churn", "text": "Our second set of experiments demonstrates meeting real-world requirements on a proprietary problem from a large internet services company : predicting whether a user interface element should be shown to a user, based on 31 informative features. We are given a currently-deployed model, which we refer to as the baseline. The goals are threefold: train a classifier that (i) has high accuracy, (ii) has no worse recall than the baseline, and (iii) has low churn w.r.t. the baseline.\nWe are given three datasets, D1, D2 and D3, consisting of 131 840, 53 877 and 68 892 examples, respectively. The datasets D1 and D2 are hand-labeled, while D3 is unlabeled. In addition, D1 was chosen via active sampling, while D2 and D3 are sampled i.i.d. from the underlying data distribution. For all three datasets, we split out 80% for training and reserved 20% for testing. We address the three goals in the proposed framework by simultaneously training the classifier to minimize the number of errors on D1 plus the number of false positives on D2, subject to the constraints that the recall on D2 be at least as high as the baseline recall (we\u2019re essentially performing Neyman-Pearson classification on D2), and that the churn w.r.t. the baseline on D3 be no larger than a given target parameter.\nWe found that 31-dimensional linear models were not capable of outperforming the baseline model. Instead, we use a fixed feature transformation \u03a6 that maps each x to a roughly 30 000-dimensional feature vector, and train classifiers that are linear with respect to \u03a6(x).\nThese experiments use a proprietary C++ implementation of Algorithm 2, using the combined SDCA and cutting plane approach of Appendix D to implement the inner optimizations over w and b, with the CutChooser helper functions being as described in Appendices C.1 and D.2.1. We performed 5 iterations of the majorization-minimization procedure of Algorithm 1.\nThe results in Figure 3 show the achieved churn and error rates on train and test sets plotted over a range of churn constraint values (blue line), compared to training an SVM without constraints and then changing its decision threshold to achieve the desired recall (green line). When using deterministic thresholding of the learned classifier (the blue curves, which significantly outperformed randomized classification\u2013the red curves\u2013in this experiment), the proposed method achieves lower churn and better accuracy for all targeted churn rates, while also meeting the recall constraint.\nAs expected, the empirical churn is extremely close to the targeted churn on the training set for the stochastic relaxation (red dashed line, and black line, top left plot), but less so on the 20% held-out test set (top right plot). We hypothesize this disparity is due to overfitting, as the classifier has 30 000 parameters, and D3 is relatively small. However, except for the lowest targeted churn, the actual classifier churn (blue line, top plots) is substantially lower than the targeted churn."}, {"heading": "A Ratio metrics", "text": "Problem 2 minimizes an objective function and imposes upper-bound constraints on metrics that are written as linear combinations of positive and negative rates\u2014we refer to such as \u201clinear combination metrics\u201d. Some metrics of interest, however, cannot be written in this form. One important subclass are the so-called \u201cratio metrics\u201d, which are ratios of linear combinations of rates. Examples of ratio metrics are precision, F-score, win/loss ratio and win/change ratio (recall is a linear combination metric, since its denominator is a constant).\nRatio metrics may not be used directly in the objective of Problem 2, but can be included in constraints by multiplying through by the denominator, then shifting the constraint coefficients to be non-negative. For example, the constraint that precision must be greater than 90% can be expressed as follows:\u2223\u2223D+\u2223\u2223 sp (D+) \u22650.9 (\u2223\u2223D+\u2223\u2223 sp (D+)+ \u2223\u2223D\u2212\u2223\u2223 sp (D\u2212))\n0.1 \u2223\u2223D+\u2223\u2223 sp (D+)\u2212 0.9 \u2223\u2223D\u2212\u2223\u2223 sp (D\u2212) \u22650\n\u22120.1 \u2223\u2223D+\u2223\u2223 sp (D+)+ 0.9 \u2223\u2223D\u2212\u2223\u2223 sp (D\u2212) \u22640\n0.1 \u2223\u2223D+\u2223\u2223 sn (D+)+ 0.9 \u2223\u2223D\u2212\u2223\u2223 sp (D\u2212) \u22640.1 \u2223\u2223D+\u2223\u2223 ,\nwhere we used the fact that sp (D+) + sn (D+) = 1 on the last line\u2014this is an example of a fact that we noted in Section 2: since positive and negative rates must sum to one, it is possible to write any linear combination of rates as a positive linear combination, plus a constant.\nMultiplying through by the denominator is fine for the indicator version of Problem 2, but a natural question is whether, by using a stochastic classifier and optimizing the ramp version, we\u2019re doing the \u201cright thing\u201d in expectation. The answer is: only partly. Since the expectation of a ratio is not the ratio of expectations, e.g. a precision constraint in our original problem (Problem 2) becomes only a constraint on a precision-like quantity (the ratio of the expectations of the precision\u2019s numerator and denominator) in our relaxed problem."}, {"heading": "B Summary Examples", "text": "We note that the constraints of Zafar et al. [2015] can be interpreted as a relaxation of the constraint \u2212c \u2264 sp(DA;w)\u2212 sp(DB ;w) \u2264 c under the linear approximation\nsp(D;w, b) \u2248 1 |D| \u2211 x\u2208D (\u3008w, x\u3009 \u2212 b)\ngiving:\nsp(D A;w, b)\u2212 sp(DB ;w, b) \u2248\n1 |DA| \u2211 x\u2208DA (\u3008w, x\u3009 \u2212 b)\u2212 1 |DB | \u2211 x\u2208DB (\u3008w, x\u3009 \u2212 b) = \u3008w, x\u0304\u3009\nwhere x\u0304 is defined as in Equation 6. We can therefore simulate the approach of Zafar et al. [2015] within our framework by adding the constraints:\n\u3008w, x\u0304\u3009 \u2264 c \u21d0\u21d2 max{0, 1\u2212 \u3008w, x\u0304\u3009} \u2264 c+ 1 c \u2264 \u3008w, x\u0304\u3009 \u21d0\u21d2 max{0, 1 + \u3008w, x\u0304\u3009} \u2264 c+ 1\nand solving the hinge constrained optimization problem described in Problem 3. Going further, we could implement these constraints as egregious examples using the constraint:\n\u3008w, x\u0304\u3009 \u2264 c \u21d0\u21d2 \u2329 w, 1\n4c x\u0304\n\u232a \u2264 1\n4 \u21d0\u21d2 1 2 +\n\u2329 w, 1\n4c x\u0304\n\u232a \u2264 3\n4 \u21d0\u21d2 min { max { 1\n2 +\n\u2329 w, 1\n4c x\u0304\n\u232a , 0 } , 1 } \u2264 3\n4 \u21d0\u21d2 rp(x\u0304) \u2264\n3\n4\npermitting us to perform an analogue of their approximations in ramp form."}, {"heading": "C Cutting plane algorithm", "text": "We\u2019ll now discuss some variants of Algorithm 2. To simplify the presentation, we\u2019ll define:\n\u03c8 (v) = min w,b\n\u03a8(w, b, v;w\u2032, b\u2032)\nas the function that we are attempting to maximize. We assume that:\n\u2022 V \u2286 Rm is compact and convex.\n\u2022 \u03c8 : V \u2192 R is concave.\n\u2022 \u03c8 has a (not necessarily unique) maximizer v\u2217 = argmaxv\u2208V \u03c8 (v).\nC.1 Maximization-based We\u2019re primarily interested in proving convergence rates, and will do so in Appendix C.2. With that said, there is one easy-to-implement variant of Algorithm 2 for which we have not proved a convergence rate, but that we use in some of our experiments due to its simplicity:\nDefinition 1. (Maximization-based Algorithm 2) CutChooser chooses v(t) = argmaxv\u2208V ht (v) and t = (Ut \u2212 Lt)/2.\nObserve that this v(t) can be found at the same time as Ut is computed, since both result from optimization of the same linear program. However, despite the ease of implementing this variant, we have not proved any convergence rates about it.\nC.2 Center of mass-based We\u2019ll now discuss a variant of Algorithm 2 that chooses v(t) and t based on the center of mass of the \u201csuperlevel hypograph\u201d determined by ht and Lt. The hypograph of ht is the set of m+ 1-dimensional points (v, z) for which z \u2264 ht(z), and the intersection of the hypograph with the half-space containing all points for which z \u2265 Lt is what we call the \u201csuperlevel hypograph\u201d. Notice that, in the context of Algorithm 2, the superlevel hypograph defined by ht and Lt corresponds to the set of pairs of candidate maximizers and their possible function values at the tth iteration. Because this variant is based on finding a cut center in the m+ 1-dimensional hypograph, rather than an m-dimensional level set (which is arguably more typical), this is an instance of what Boyd and Vandenberghe [2011] call an \u201cepigraph cutting plane method\u201d.\nThroughout this section, we will take \u00b5 to be the Lebesgue measure (either 1-dimensional, m-dimensional, or m+ 1-dimensional, depending on context). We also must define some notation for dealing with superlevel sets and hypographs. For a concave f : V \u2192 R and y \u2208 R, define:\nL (f, y) = {v \u2208 V | f (v) \u2265 y}\nas the superlevel set of f at y. Further define:\nG (f, y) = {(v, z) \u2208 V \u00d7 R | f (v) \u2265 z \u2265 y}\nas the superlevel hypograph of f above y. With these definitions in place, we\u2019re ready to explicitly state the center of mass-based rule for the CutChooser function on line 8 of Algorithm 2:\nDefinition 2. (Center of mass-based Algorithm 2) CutChooser takes (v(t), zt) to be the center of mass of S(ht, Lt), and define t = (zt \u2212 Lt)/2.\nOur final bit of \u201csetup\u201c before getting to our results is to state two classic theorems, plus a corollary, which will be needed for our proofs. The first enables us to interpolate the areas of superlevel sets:\nTheorem 1. Suppose that the superlevel sets of a concave f : V \u2192 R at y1 and y2 are nonempty, and take \u03b3 \u2208 [0, 1]. Then:\n(\u00b5 (L (f, \u03b3y1 + (1\u2212 \u03b3) y2))) 1/m \u2265 \u03b3 (\u00b5 (L (f, y1))) 1/m + (1\u2212 \u03b3) (\u00b5 (L (f, y2))) 1/m\nProof. This is the Brunn-Minkowski inequality [e.g. Ball, 1997].\nThis theorem has the immediate useful corollary:\nCorollary 1. Suppose that f : V \u2192 R is concave with a maximizer v\u2217 \u2208 V, and that \u03b4 \u2265 0. Then:( \u03b4\nm+ 1\n) \u00b5 (L (f, f (v\u2217)\u2212 \u03b4)) \u2264 \u00b5 (G (f, f (v\u2217) + \u03b4)) \u2264 \u03b4\u00b5 (L (f, f (v\u2217)\u2212 \u03b4))\nProof. By Theorem 1 (lower-bounding the second term on the RHS by zero), for 0 \u2264 z \u2264 \u03b4:\n\u00b5 (L (f, f (v\u2217)\u2212 z)) \u2265 (z \u03b4 )m \u00b5 (L (f, f (v\u2217)\u2212 \u03b4))\nFrom which integrating \u00b5 (G (f, f (v\u2217)\u2212 \u03b4)) = \u222b \u03b4 0 \u00b5 (L (f, f (v\u2217)\u2212 z))m\u00b5(z) yields the claimed lower bound. The upper bound follows immediately from the fact that the superlevel sets shrink as z increases (i.e. \u00b5 (L (f, z\u2032)) \u2264 \u00b5 (L (f, z)) for z\u2032 \u2265 z).\nThe second classic result enables us to bound how much \u201cprogress\u201d is made by a cut based on the center of mass of a superlevel hypograph:\nTheorem 2. Suppose that S \u2286 Rm is a convex set. If we let z \u2208 S be the center of mass of S, then for any half-space H 3 z:\n\u00b5 (S \u2229H) \u00b5 (S)\n\u2265 ( m\nm+ 1 )m \u2265 1 e\nProof. This is Theorem 2 of Gr\u00fcnbaum [1960].\nWith the preliminaries out of the way, we\u2019re ready to move on to our first result: bounding the volumes of the superlevel hypographs of our hts, assuming that we base our cuts on the centers of mass of the superlevel hypographs:\nLemma 1. In the context of Algorithm 2, suppose that we choose v(t) and t as in Definition 2. Then: \u00b5 (G (ht+1, Lt+1)) \u2264 (\n1\u2212 1 2e\n) \u00b5 (G (ht, Lt))\nfrom which it follows that:\n\u00b5 (G (ht, Lt)) \u2264 (\n1\u2212 1 2e\n)t\u22121 (u0 \u2212 l0)\u00b5 (V)\nfor all t.\nProof. We\u2019ll consider two cases: ut \u2264 zt and ut > zt, corresponding to making a \u201cdeep\u201d or \u201cshallow\u201d cut, respectively.\nDeep cut case: If ut \u2264 zt, then the hyperplane ut + \u2329 g(t), v \u2212 v(t) \u232a passes below the center of mass of\nS(ht, Lt), implying by Theorem 2 that: \u00b5 (G (ht+1, Lt+1)) \u2264 \u00b5 (G (ht+1, Lt)) \u2264 (\n1\u2212 1 e\n) \u00b5 (G (ht, Lt))\nShallow cut case: Now suppose that ut > zt. Applying Theorem 2 to the level cut {(v, z) | z \u2264 zt} at zt:\n1 e \u00b5 (G (ht, Lt)) \u2264 \u222b zt Lt \u00b5 ({v \u2208 V | ht (v) \u2265 z}) d\u00b5(z)\n\u2264 \u222b (zt+Lt)/2 Lt \u00b5 ({v \u2208 V | ht (v) \u2265 z}) d\u00b5(z)\n+ \u222b zt (zt+Lt)/2 \u00b5 ({v \u2208 V | ht (v) \u2265 z}) d\u00b5(z)\nSince ht is concave, its superlevel sets shrink for larger z, so the first integral on the RHS above is larger than the second, implying that:\n1\n2e \u00b5 (G (ht, Lt)) \u2264 \u222b (zt+Lt)/2 Lt \u00b5 ({v \u2208 V | ht (v) \u2265 z}) d\u00b5(z)\nThe fact that t = (zt \u2212 Lt)/2 implies that lt > (zt + Lt)/2, so Lt+1 > (zt + Lt)/2, and:\n1\n2e \u00b5 (G (ht, Lt)) \u2264 \u222b Lt+1 Lt \u00b5 ({v \u2208 V | ht (v) \u2265 z}) d\u00b5(z)\nshowing that we will cut off at least a 1/2e-proportion of the total volume, completing the proof of the first claim.\nThe second claim follows immediately by iterating the first, and observing that \u00b5 (G (h1, L1)) = (u0 \u2212 l0)\u00b5 (V).\nThe above result shows that the volumes of the superlevel hypographs of the hts shrink at an exponential rate. However, our actual stopping condition (line 5 of Algorithm 2) depends not on the volume, but rather the \u201cheight\u201d Ut \u2212 Lt, so we would prefer a bound on this height, rather than the volume. We find such a bound in the (proof of the) following lemma, which establishes how many iterations must elapse before the stopping condition is satisfied:\nLemma 2. In the context of Algorithm 2, suppose that we choose v(t) and t as in Definition 2. Then there is a iteration count T satisfying:\nT = O ( m ln ( u0 \u2212 l0 ) + ln ( \u00b5 (V)\n\u00b5 (L (\u03c8, l0)) )) such that, if t \u2265 T , then Ut \u2212 Lt \u2264 . Hence, Algorithm 2 will terminate after T iterations.\nProof. By Corollary 1:\n\u00b5 (G (ht, Lt)) \u2265 ( Ut \u2212 Lt m+ 1 ) \u00b5 (L (ht, Lt))\nIf Lt \u2264 \u03c8 (v\u2217)\u2212 , then \u00b5 (L (ht, Lt)) \u2265 \u00b5 (L (ht, \u03c8 (v\u2217)\u2212 )) because ht is concave. If Lt > \u03c8 (v\u2217)\u2212 , then by Theorem 1:\n\u00b5 (L (ht, Lt)) \u2265 (\nUt \u2212 Lt Ut \u2212 \u03c8 (v\u2217) +\n)m \u00b5 (L (ht, \u03c8 (v \u2217)\u2212 ))\nIn either case, Lt \u2264 \u03c8 (v\u2217) by definition, and we\u2019ll assume that Ut \u2212 Lt > (this will lead to a contradiction), so: \u00b5 (G (ht, Lt)) \u2265 2\u2212m ( Ut \u2212 Lt m+ 1 ) \u00b5 (L (ht, \u03c8 (v \u2217)\u2212 ))\nApplying Lemma 1 yields that:( 1\u2212 1\n2e\n)t\u22121 (u0 \u2212 l0)\u00b5 (V) \u2265 2\u2212m ( Ut \u2212 Lt m+ 1 ) \u00b5 (L (ht, \u03c8 (v \u2217)\u2212 ))\nNext observe that, by Theorem 1:\n\u00b5 (L (ht, \u03c8 (v \u2217)\u2212 )) \u2265\n( Ut \u2212 \u03c8 (v\u2217) +\nUt \u2212 l0\n)m \u00b5 (L (ht, l0)) \u2265 (\nu0 \u2212 l0\n)m \u00b5 (L (\u03c8, l0))\nCombining the previous two equations gives: Ut \u2212 Lt \u2264 (\n1\u2212 1 2e\n)t\u22121 (m+ 1) ( 2 )m (u0 \u2212 l0)m+1 ( \u00b5 (V)\n\u00b5 (L (\u03c8, l0)) ) Simplifying this inequality yields that, if we have performed the claimed number of iterations, then Ut\u2212Lt \u2264 (this contradicts our earlier assumption that Ut \u2212 Lt > , so this is technically a proof by contradiction).\nThe second term in the bound on T measures how closely V matches with the set of all points z on which \u03c8 (z) exceeds our initial lower bound l0. Observe that if l0 \u2264 \u03c8 (v) for all v \u2208 V, then \u00b5 (L (\u03c8, l0)) = \u00b5 (V), and this term will vanish.\nBounding the number of cutting-plane iterations that will be performed is not enough to establish how quickly our procedure will converge, since we rely on performing an inner SVM optimizations with target suboptimality t, and the runtime of these inner optimizations naturally will depend on the magnitudes of the ts, which are bounded in our final lemma:\nLemma 3. In the context of Algorithm 2, suppose that we choose v(t) and t as in Definition 2. Then:\nt \u2265 Ut \u2212 Lt\n2e (m+ 1)\nand in particular, for all t (before termination):\nt \u2265\n2e (m+ 1)\nsince we terminate as soon as Ut \u2212 Lt \u2264 . Proof. Because ht is concave:\n\u00b5 (G (ht, Lt))\u2212 \u00b5 (G (ht, zt)) \u2264 (zt \u2212 Lt)\u00b5 (L (ht, Lt))\nwhere zt is as in Lemma 1. By Corollary 1, \u00b5 (L (ht, Lt)) \u2264 m+1Ut\u2212Lt\u00b5 (G (ht, Lt)), which combined with the above inequality gives that:\n\u00b5 (G (ht, Lt))\u2212 \u00b5 (G (ht, zt)) \u00b5 (G (ht, Lt)) \u2264 zt \u2212 Lt Ut \u2212 Lt (m+ 1)\nBy Theorem 2, the LHS is at least 1/e, and zt \u2212 Lt = 2 t, giving the claimed result."}, {"heading": "D SVM optimization", "text": "We\u2019ll now move onto a discussion of how we propose implementing the SVMOptimizer of Algorithm 2. The easier-to-analyze approach, based on an inner SDCA optimization over w [Shalev-Shwartz and Zhang, 2013] and an outer cutting plane optimization over b (Algorithm 3), will be described in Appendices D.1 and D.2. The easier-to-implement version, which simply calls an off-the-shelf SVM solver, will be described in Appendix D.4.\nD.1 SDCA w-optimization To simplify the presentation, we\u2019re going to begin by reformulating Equation 5 in such a way that all of the datasets are \u201cmashed together\u201d, with the coefficients being defined on a per-example basis, rather than per-dataset. To this end, for fixed w\u2032 and b\u2032, we define, for every i \u2208 {1, . . . , k} and every x \u2208 Di:\n\u03b1\u030c (0) i,x =\n{ \u03b1 (0) i if \u3008w\u2032, x\u3009 \u2212 b\u2032 \u2264 1/2\n0 otherwise\n\u03b2\u030c (0) i,x =\n{ \u03b2 (0) i if \u3008w\u2032, x\u3009 \u2212 b\u2032 \u2265 \u22121/2\n0 otherwise\nThis takes care of the loss coefficients. For the constraint coefficients, define:\n\u03b1\u030c (j) i,x =\n{ \u03b1 (j) i if \u3008w\u2032, x\u3009 \u2212 b\u2032 \u2264 1/2\n0 otherwise\n\u03b2\u030c (j) i,x =\n{ \u03b2 (j) i if \u3008w\u2032, x\u3009 \u2212 b\u2032 \u2265 \u22121/2\n0 otherwise\nand finally, we need to handle the constraint upper bounds:\n\u03b3\u030c(j) =\u03b3(j) \u2212 k\u2211 i=1 1 |Di| ( \u03b1 (j) i |{x \u2208 Di | \u3008w \u2032, x\u3009 \u2212 b\u2032 > 1/2}|\n+\u03b2 (j) i |{x \u2208 Di | \u3008w\n\u2032, x\u3009 \u2212 b\u2032 < \u22121/2}| )\nObserve that the \u03b1\u030c(0)i,xs, \u03b2\u030c (0) i,x s, \u03b1\u030c (j) i,xs, \u03b2\u030c (j) i,x s, and \u03b3\u030c (j)s all have implicit dependencies on w\u2032 and b\u2032. In terms of these definitions, the \u03a8 defined in Equation 5 can be written as:\n\u03a8 (w, b, v;w\u2032, b\u2032) = k\u2211 i=1 1 |Di| \u2211 x\u2208Di \u03b1\u030c(0)i,x + m\u2211 j=1 vj\u03b1\u030c (j) i,x max{0, 1 2 + (\u3008w, x\u3009 \u2212 b) }\n+ \u03b2\u030c(0)i,x + m\u2211 j=1 vj \u03b2\u030c (j) i,x max{0, 1 2 \u2212 (\u3008w, x\u3009 \u2212 b) } + \u03bb\n2 \u2016w\u201622 \u2212 m\u2211 j=1 vj \u03b3\u030c (j)\nThis formulation makes it clear that minimizing \u03a8 as a function of w and b is equivalent to optimizing an SVM, since \u03a8 is just a positive linear combination of hinge losses, plus a `2 regularizer, plus a term that does not depend on w or b. Since \u03a8 can have both \u201cpositive\u201d and \u201cnegative\u201d hinge losses associated with the same\nexample, however, it\u2019s slightly simpler to combine both hinge losses together into a single piecewise linear per-example loss, rather than decomposing it into two separate hinges:\n`i,x (z) = \u03b1\u030ci,x max\n{ 0, 1\n2 + z\n} + \u03b2\u030ci,x max { 0, 1 2 \u2212 z }\nwhere:\n\u03b1\u030ci,x = n\n|Di| \u03b1\u030c(0)i,x + m\u2211 j=1 vj\u03b1\u030c (j) i,x  and \u03b2\u030ci,x = n|Di| \u03b2\u030c(0)i,x + m\u2211 j=1 vj \u03b2\u030c (j) i,x  Here, n = \u2211k i=1 |Di| is the total number of examples across all of the datasets\u2014we introduced the n factor here so that \u03a8 will be written in terms of the average loss (rather than the total loss). Although it is not represented explicitly in our notation, it should be emphasized that `i,x implicitly depends on v, w\u2032 and b\u2032.\nAs the sum of two hinges, the `i,xs are Lipschitz continuous in z, with the Lipschitz constant being:\nL = max i\u2208{1,...,k}\nn\n|Di| (\u03b1(0)i + \u03b2(0)i )+ V m\u2211 j=1 ( \u03b1 (j) i + \u03b2 (j) i ) (7) where V = maxj\u2208{1,...,m} vj is a uniform upper bound on the magnitudes of the Lagrange multipliers associated with the constraints. Notice that, if the datasets are comparable in size, then n/ |Di| will be on the order of k, so L will typically not be as large as the n-dependence of its definition would appear to imply.\nWe may now write \u03a8 in terms of the loss functions `i,x:\n\u03a8 (w, b, v;w\u2032, b\u2032) = 1\nn k\u2211 i=1 \u2211 x\u2208Di `i,x (\u3008w, x\u3009 \u2212 b) + \u03bb 2 \u2016w\u201622 \u2212 m\u2211 j=1 vj \u03b3\u030c (j)\nThis is the form considered by Shalev-Shwartz and Zhang [2013], so we may apply SDCA:\nTheorem 3. If we use SDCA [Shalev-Shwartz and Zhang, 2013] to optimize Equation 8 for fixed b and v, then we will find a suboptimal solution with duality gap \u2032\u2032 after performing at most:\nT \u2032\u2032 = O ( max { 0, n ln ( \u03bbn\nL2X2\n)} + n+ L2X2\n\u03bb \u2032\u2032 ) iterations, where X = maxi\u2208{1,...,k}maxx\u2208Di \u2016x\u20162 is a uniform upper bound on the norms of the training examples.\nProof. This is Theorem 2 of Shalev-Shwartz and Zhang [2013].\nSDCA works by, rather than directly minimizing \u03a8 over w, instead maximizing the following over the dual variables \u03be:\n\u03a8\u2217 (\u03be, b, v;w\u2032, b\u2032) = (8)\n\u2212 1 n k\u2211 i=1 \u2211 x\u2208Di `\u2217i,x (\u03bei,x)\u2212 1 2\u03bb \u2225\u2225\u2225\u2225\u2225 1n k\u2211 i=1 \u2211 x\u2208Di \u03bei,xx \u2225\u2225\u2225\u2225\u2225 2\n2\n\u2212 1 n k\u2211 i=1 \u2211 x\u2208Di \u03bei,xb\u2212 m\u2211 j=1 vj \u03b3\u030c (j)\nusing stochastic coordinate ascent, where:\nw = \u2212 1 \u03bbn k\u2211 i=1 \u2211 x\u2208Di \u03bei,xx\nis the primal solution w corresponding to a given set of dual variables \u03be, and:\n`\u2217i,x (\u03bei,x) = 1\n2 \u2223\u2223\u03bei,x \u2212 \u03b1\u030ci,x + \u03b2\u030ci,x\u2223\u2223\u2212 1 2 ( \u03b1\u030ci,x + \u03b2\u030ci,x ) is the Fenchel conjugate of `i,x, and is defined for \u2212\u03b2\u030ci,x \u2264 \u03bei,x \u2264 \u03b1\u030ci,x (these bounds become box constraints on the \u03bes of Equation 8).\nAlgorithm 3 Skeleton of a cutting-plane algorithm that finds a b \u2208 B minimizing (to within ) minw \u03a8(w, b, v;w\n\u2032, b\u2032), where B \u2286 R is a closed bounded interval. It is assumed that l0, u0 \u2208 R are finite, and that l0 \u2264 maxv minw \u03a8(w, b, v;w\u2032, b\u2032) \u2264 u0. The u\u20320 increase that is \u201cmaybe\u201d performed on line 2, and the CutChooser function on line 9, are discussed in Appendix D.2. The SDCAOptimizer function is as described in Appendix D.1.\nSVMOptimizer (v, l\u20320, u\u20320, \u2032) 1 Initialize g\u20320 \u2208 R to zero 2 Maybe update u\u20320 = u\u20320 + (u\u20320 \u2212 l\u20320) // needed for Lemma 4, but might not help in practice 3 For t \u2208 {1, 2, . . . } 4 Let h\u2032t (b) = maxs\u2208{0,1,...,t\u22121} (l\u2032s + g\u2032s (b\u2212 bs)) 5 Let L\u2032t = minb\u2208B h\u2032t (b) and U \u2032t = mins\u2208{0,1,...,t\u22121} u\u2032s 6 If U \u2032t \u2212 L\u2032t \u2264 \u2032 then 7 Let s \u2208 {1, . . . , t\u2212 1} be an index minimizing u\u2032s 8 Return w(s), bs, L\u2032t 9 Let bt, t = CutChooser (h\u2032t, U \u2032t) 10 Let \u03be(t), w(t) = SDCAOptimizer (bt, v, \u2032t) 11 Let u\u2032t = \u03a8(w(t), bt, v;w\u2032, b\u2032) 12 Let l\u2032t = \u03a8\u2217(\u03be(t), bt, v;w\u2032, b\u2032) and g\u2032t =\n\u2202 \u2202\u2032b \u03a8\u2217(\u03be(t), bt, v;w \u2032, b\u2032)\nD.2 Cutting plane b-optimization Having described in the previous section how we may optimize over w for fixed b and v using SDCA, we now move on to the problem of creating the SVMOptimizer needed by Algorithm 2, which must optimize over both w and b.\nMany linear SVM optimizers do not natively handle an unregularized bias parameter b, and this has long been recognized as a potential issue. For example, Shalev-Shwartz et al. [2011] suggest using Pegasos to perform inner optimizations over w, and a bisection-based outer optimization over b. Our proposal is little different from this, except that Algorithm 3, rather than using bisection, optimizes over b using essentially the same cutting plane algorithm as we used in Algorithm 2. Our two cutting-plane algorithms are essentially identical, except that optimizing over b is a minimization problem (over v is maximization), and we might increase u0 on line 2 for a technical reason (it will be needed by the proof of Lemma 4, but is probably not helpful in practice).\nD.2.1 Minimization-based\nPerhaps the easiest-to-implement version of Algorithm 3 is based on the idea of simply solving for the minimizer of h\u2032t at every iteration.\nDefinition 3. (Minimization-based Algorithm 3) Do not increase u\u20320 on line 2, and have CutChooser choose bt = argminb\u2208B h\u2032t (b) and \u2032t = (Ut \u2212 Lt)/2.\nAs was the case in Appendix C.1, we have no convergence rates for this version.\nD.3 Center of mass-based Essentially the same center of mass-based approach as was described in Appendix C.2 can be used in this setting, except that we must find the center of mass of a 2-dimensional sublevel epigraph, rather than an m+ 1-dimensional superlevel hypograph:\nDefinition 4. (Center of mass-based Algorithm 3) Do increase u\u20320 on line 2, have CutChooser take (bt, zt) to be the center of mass of {(b, z) | h\u2032t (b) \u2264 z \u2264 U \u2032t}, and choose \u2032t = (U \u2032t \u2212 zt)/2.\nDue to the similarity between Algorithms 3 and 2, we can simply recycle the results of Appendix C.2, with the troublesome second term in the bound of Lemma 2 removed by combining the \u201cmaybe\u201d portion of Algorithm 3 with the Lipschitz continuity of \u03a8 as a function of b:\nLemma 4. In the context of Algorithm 3, suppose that we choose bt and \u2032t as in Definition 4. Then there is a iteration count T \u2032 satisfying:\nT \u2032 = O ( ln ( LB (u\u20320 \u2212 l\u20320)\n\u2032 )) such that, if t \u2265 T \u2032 , then U \u2032t \u2212 L\u2032t \u2264 \u2032, where B = [\u2212B,B] is the set of allowed biases and L is as in Equation 7. Hence, Algorithm 3 will terminate after T \u2032 iterations.\nProof. Starting from (and adapting) the final equation in the proof of Lemma 2:\nU \u2032t \u2212 L\u2032t \u226432 (\n1\u2212 1 2e\n)t\u22121( 1\n\u2032\n) (u\u20320 \u2212 l\u20320) 2\n\u00b7 (\nB\n\u00b5 ({b \u2208 [\u2212B,B] | minw\u2208Rd \u03a8 (w, b, v;w\u2032, b\u2032) \u2264 u\u20320}) ) Observe that, as a function of b, \u03a8 (w, b, v;w\u2032, b\u2032) is L-Lipschitz. Hence, if we let w\u2217 \u2208 Rd, b\u2217 \u2208 [\u2212B,B] be the optimal weight and bias, then:\n\u00b5 ({b \u2208 [\u2212B,B] | \u03a8 (w\u2217, b, v;w\u2032, b\u2032) \u2264 u\u20320}) \u2265 min { 2B, u\u20320 \u2212 b\u2217\nL } Since minw\u2208Rd \u03a8 (w, b, v;w\u2032, b\u2032) \u2264 \u03a8 (w\u2217, b, v;w\u2032, b\u2032), it follows that:\nU \u2032t \u2212 L\u2032t \u2264 32 (\n1\u2212 1 2e\n)t\u22121( 1\n\u2032\n) (u\u20320 \u2212 l\u20320) 2 max { 1\n2 ,\nLB\nu\u20320 \u2212 b\u2217 } This is the reason that we increased u\u20320 on line 2 of Algorithm 3, since doing so has the result that u\u20320 \u2212 b\u2217 \u2265 u\u20320 \u2212 l\u20320, so:\nU \u2032t \u2212 L\u2032t \u2264 32 (\n1\u2212 1 2e\n)t\u22121( 1\n\u2032\n) (u\u20320 \u2212 l\u20320) max { u\u20320 \u2212 l\u20320\n2 , LB } The same reasoning as was used in the proof of Lemma 2 then gives the claimed bound on T \u2032 .\nIn addition to the above result, the obvious analogue of Lemma 3 holds as well:\nLemma 5. In the context of Algorithm 3, suppose that we choose bt and \u2032t as in Definition 4. Then:\n\u2032t \u2265 U \u2032t \u2212 L\u2032t\n2e\nand in particular, for all t (before termination):\n\u2032t \u2265 \u2032\n2e\nsince we terminate as soon as U \u2032t \u2212 L\u2032t \u2264 \u2032.\nProof. Same as Lemma 3.\nIn Appendix E, we\u2019ll combine these results with those of Appendices D.1 and C to bound the overall convergence rate of Algorithm 2.\nD.4 Kernelization The foregoing discussion covers the case in which we wish to learn a linear classifier, and use an SVM optimizer (SDCA) that doesn\u2019t handle an unregularized bias. It\u2019s clear that we could freely substitute another linear SVM optimizer for SDCA, as long as it finds both a primal and dual solution, enabling us to calculate the lower and upper bounds required by Algorithm 2.\nOur technique is easily kernelized\u2014the resulting algorithm simply depends on inner kernel SVM optimizations, rather than linear SVM optimizations. SDCA can be used in the kernel setting, but the per-iteration cost increases from O(d) arithmetic operations to O(n) kernel evaluations, where n is the total size of all of the datasets. Kernel-specific optimizers, such as LIBSVM [Chang and Lin, 2011], will generally work better than SDCA in practice, since they typically have the same per-iteration cost, but each iteration is \u201csmarter\u201d. More importantly, such optimizers usually jointly optimize over w and b, eliminating the need for Algorithm 3. Hence, an implementation based on such an optimizer is the simplest version of our proposed approach, since it would be nothing but Algorithms 1 and 2, with the SVMOptimizer helper function being a call to an off-the-shelf solver."}, {"heading": "E Overall convergence rates", "text": "We may now combine the results in Appendices C and D into one bound on the overall convergence rate of Algorithm 2, assuming that we use Algorithm 3, rather than an off-the-shelf SVM solver, to implement the SVMOptimizer. First, for the center of mass-based versions:\nTheorem 4. Assuming that SVMOptimizer is implemented as in Algorithm 3, with the CutChooser functions in Algorithms 2 and 3 being implemented using the center of mass (as in Definitions 2 and 4), and assuming that we have access to an oracle function for finding the center of mass of compact convex polytopes, then Algorithm 2 will perform:\nO ( m ln ( u0 \u2212 l0 ) + ln ( \u00b5 (V)\nA (\u03c8, l0) )) iterations, each of which contains a single call to Algorithm 3, with each such call requiring:\nO (ln (LBm))\niterations, each of which contains a single call to SDCAOptimizer, with each such call requiring:\nO ( max { 0, n ln ( \u03bbn\nL2X2\n)} + n+ L2X2m\n\u03bb ) iterations, each of which requires O(d) arithmetic operations.\nProof. Follows immediately from combining Lemmas 2, 3, 4 and 5 with Theorem 3, and using the fact that the bounds Lt and Ut are passed from Algorithm 2 to Algorithm 3 as u\u20320 = Ut and l\u20320 = Lt.\nIn terms of only n, m, d and , dropping all of the other factors , the overall cost of finding an -suboptimal solution to Problem 3 is therefore O\u0303 ( dnm ln (1/ ) + dm2/ ) total arithmetic operations in the inner SDCA\noptimizers, O\u0303 (m ln (1/ )) calls to the center of mass oracles in Algorithms 2 and 3, and another O\u0303 (m ln (1/ )) calls to a linear programming oracle for finding Ut in Algorithm 2 and Lt in Algorithm 3.\nIt must be pointed out that our reliance on a center of mass oracle is unrealistic, since finding the center of mass is a computationally difficult problem [Nemirovski, 1994, Section 3.2]. With that said, we hope that these results can provide a basis for future work."}], "references": [{"title": "An elementary introduction to modern convex geometry", "author": ["K. Ball"], "venue": "Flavors of Geometry,", "citeRegEx": "Ball.,? \\Q1997\\E", "shortCiteRegEx": "Ball.", "year": 1997}, {"title": "Adverse Impact and Test Validation: A Practitioner\u2019s Guide to Valid and Defensible Employment Testing", "author": ["D. Biddle"], "venue": null, "citeRegEx": "Biddle.,? \\Q2005\\E", "shortCiteRegEx": "Biddle.", "year": 2005}, {"title": "Feature article\u2014the ellipsoid method: A survey", "author": ["R.G. Bland", "D. Goldfarb", "M.J. Todd"], "venue": "Operations Research,", "citeRegEx": "Bland et al\\.,? \\Q1981\\E", "shortCiteRegEx": "Bland et al\\.", "year": 1981}, {"title": "Localization and cutting-plane methods, April 2011. Stanford EE 364b lecture notes", "author": ["S. Boyd", "L. Vandenberghe"], "venue": null, "citeRegEx": "Boyd and Vandenberghe.,? \\Q2011\\E", "shortCiteRegEx": "Boyd and Vandenberghe.", "year": 2011}, {"title": "LIBSVM: A library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "Chang and Lin.,? \\Q2011\\E", "shortCiteRegEx": "Chang and Lin.", "year": 2011}, {"title": "Trading convexity for scalability", "author": ["R. Collobert", "F. Sinz", "J. Weston", "L. Bottou"], "venue": "In ICML,", "citeRegEx": "Collobert et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2006}, {"title": "Learning optimally sparse support vector machines", "author": ["A. Cotter", "S. Shalev-Shwartz", "N. Srebro"], "venue": "In ICML,", "citeRegEx": "Cotter et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cotter et al\\.", "year": 2013}, {"title": "Tuning support vector machines for minimax and NeymanPearson classification", "author": ["M. Davenport", "R.G. Baraniuk", "C.D. Scott"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Davenport et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Davenport et al\\.", "year": 2010}, {"title": "LIBLINEAR: A library for large linear classification", "author": ["R.-E. Fan", "K.-W. Chang", "C.-J. Hsieh", "X.-R. Wang", "C.-J. Lin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Fan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "Batch and online learning algorithms for nonconvex Neyman-Pearson classification", "author": ["G. Gasso", "A. Pappaionannou", "M. Spivak", "L. Bottou"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "Gasso et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gasso et al\\.", "year": 2011}, {"title": "Partitions of mass-distributions and convex bodies by hyperplanes", "author": ["B. Gr\u00fcnbaum"], "venue": "Pacific Journal of Mathematics,", "citeRegEx": "Gr\u00fcnbaum.,? \\Q1960\\E", "shortCiteRegEx": "Gr\u00fcnbaum.", "year": 1960}, {"title": "A support vector method for multivariate performance measures", "author": ["T. Joachims"], "venue": "In ICML,", "citeRegEx": "Joachims.,? \\Q2005\\E", "shortCiteRegEx": "Joachims.", "year": 2005}, {"title": "Simple, robust, scalable semi-supervised learning with expectation regularization", "author": ["G.S. Mann", "A. McCallum"], "venue": "In ICML,", "citeRegEx": "Mann and McCallum.,? \\Q2007\\E", "shortCiteRegEx": "Mann and McCallum.", "year": 2007}, {"title": "Optimizing non-decomposable performance measures: a tale of two classes", "author": ["H. Narasimhan", "P. Kar", "P. Jain"], "venue": "In ICML,", "citeRegEx": "Narasimhan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Narasimhan et al\\.", "year": 2015}, {"title": "Lecture notes: Efficient methods in convex programming", "author": ["A. Nemirovski"], "venue": "URL http://www2.isye. gatech.edu/~nemirovs/Lect_EMCO.pdf", "citeRegEx": "Nemirovski.,? \\Q1994\\E", "shortCiteRegEx": "Nemirovski.", "year": 1994}, {"title": "A Neyman-Pearson approach to statistical learning", "author": ["C.D. Scott", "R.D. Nowak"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Scott and Nowak.,? \\Q2005\\E", "shortCiteRegEx": "Scott and Nowak.", "year": 2005}, {"title": "Stochastic dual coordinate ascent methods for regularized loss", "author": ["S. Shalev-Shwartz", "T. Zhang"], "venue": null, "citeRegEx": "Shalev.Shwartz and Zhang.,? \\Q2013\\E", "shortCiteRegEx": "Shalev.Shwartz and Zhang.", "year": 2013}, {"title": "Pegasos: Primal Estimated sub-GrAdient SOlver for SVM", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro", "A. Cotter"], "venue": "Mathematical Programming,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2011}, {"title": "Disparate impact doctrine in fair housing", "author": ["M.S. Vuolo", "N.B. Levy"], "venue": "New York Law Journal,", "citeRegEx": "Vuolo and Levy.,? \\Q2013\\E", "shortCiteRegEx": "Vuolo and Levy.", "year": 2013}, {"title": "Fairness constraints: A mechanism for fair classification", "author": ["M.B. Zafar", "I. Valera", "M.G. Rodriguez", "K.P. Gummadi"], "venue": "In ICML Workshop on Fairness, Accountability, and Transparency in Machine Learning,", "citeRegEx": "Zafar et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zafar et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 12, "context": "Coverage was also considered by Mann and McCallum [2007], who proposed what they call \u201clabel regularization\u201d, in which one adds a regularizer that penalizes the relative entropy between the mean classifier score for each class and the desired distribution, with an additional correction to avoid degeneracies.", "startOffset": 32, "endOffset": 57}, {"referenceID": 14, "context": "As noted by Zafar et al. [2015], fairness is sometimes specified by a proportion, such as the 80% rule in US law that certain decisions must be in favor of group B individuals at least 80% as often as in favor of group A individuals [e.", "startOffset": 12, "endOffset": 32}, {"referenceID": 1, "context": "Biddle, 2005, Vuolo and Levy, 2013]. Zafar et al. [2015] propose learning fair classifiers by imposing linear constraints on the covariance between the predicted labels and the values of certain features.", "startOffset": 0, "endOffset": 57}, {"referenceID": 1, "context": "Biddle, 2005, Vuolo and Levy, 2013]. Zafar et al. [2015] propose learning fair classifiers by imposing linear constraints on the covariance between the predicted labels and the values of certain features. In our framework, rate constraints such as the 80% rule can be imposed directly. Recall and Precision: Requirements of real-world classifiers are often expressed in terms of precision and recall, especially when examples are highly imbalanced between positives and negatives. In our framework, we can handle this problem via Neyman-Pearson classification [e.g. Scott and Nowak, 2005, Davenport et al., 2010], in which one seeks to minimize the false negative rate subject to a constraint on the false positive rate. Indeed, our ramp-loss formulation is equivalent to that of Gasso et al. [2011] in this setting.", "startOffset": 0, "endOffset": 800}, {"referenceID": 6, "context": "We can, however, work around this difficulty by following Cotter et al. [2013] and training a classifier that makes 1Appendices may be found in the supplementary material", "startOffset": 58, "endOffset": 79}, {"referenceID": 5, "context": "randomized predictions based on the ramp function [Collobert et al., 2006]:", "startOffset": 50, "endOffset": 74}, {"referenceID": 2, "context": "Rather, it\u2019s based upon the idea of possibly making \u201cshallow\u201d cuts [Bland et al., 1981] by choosing a desired accuracy t at each iteration, and expecting the SVMOptimizer to return a solution with suboptimality t.", "startOffset": 67, "endOffset": 87}, {"referenceID": 5, "context": "Collobert et al. [2006] also use a ramp loss as a relaxation of 0/1 loss (for optimizing accuracy), but do not consider constraints.", "startOffset": 0, "endOffset": 24}, {"referenceID": 5, "context": "Collobert et al. [2006] also use a ramp loss as a relaxation of 0/1 loss (for optimizing accuracy), but do not consider constraints. The most related prior work is that of Gasso et al. [2011]. They also use an iterative ramp loss approximation, but only tackle the Neyman-Pearson problem, and their algorithm is less straightforward than that presented here.", "startOffset": 0, "endOffset": 192}, {"referenceID": 5, "context": "Collobert et al. [2006] also use a ramp loss as a relaxation of 0/1 loss (for optimizing accuracy), but do not consider constraints. The most related prior work is that of Gasso et al. [2011]. They also use an iterative ramp loss approximation, but only tackle the Neyman-Pearson problem, and their algorithm is less straightforward than that presented here. Gasso et al. [2011] compared their Neyman-Pearson classifier", "startOffset": 0, "endOffset": 379}, {"referenceID": 19, "context": "Green dots: Zafar et al. [2015]. Green line: unconstrained SVM.", "startOffset": 12, "endOffset": 32}, {"referenceID": 7, "context": "to that of Davenport et al. [2010], which differs in that it uses a hinge loss approximation instead of the ramp loss, and found with the ramp-loss they achieved similar or slightly better results with up to 10\u00d7 less computation.", "startOffset": 11, "endOffset": 35}, {"referenceID": 7, "context": "to that of Davenport et al. [2010], which differs in that it uses a hinge loss approximation instead of the ramp loss, and found with the ramp-loss they achieved similar or slightly better results with up to 10\u00d7 less computation. Narasimhan et al. [2015] considered optimizing for the F-measure and other quantities that can be written as concave functions of the TP and TN.", "startOffset": 11, "endOffset": 255}, {"referenceID": 7, "context": "to that of Davenport et al. [2010], which differs in that it uses a hinge loss approximation instead of the ramp loss, and found with the ramp-loss they achieved similar or slightly better results with up to 10\u00d7 less computation. Narasimhan et al. [2015] considered optimizing for the F-measure and other quantities that can be written as concave functions of the TP and TN. In their proposed stochastic dual solver, they adaptively linearize concave functions of the rate functions (Equation 1). Joachims [2005] indirectly optimizes upper-bounds on functions of sp(D), sp(D), sn(D), sn(D) using a hinge loss approximation.", "startOffset": 11, "endOffset": 513}, {"referenceID": 8, "context": "Our publicly-available Julia implementation3 for these experiments uses LIBLINEAR [Fan et al., 2008] to implement the SVMOptimizer function, and does not include an unregularized bias b.", "startOffset": 82, "endOffset": 100}, {"referenceID": 18, "context": "1 Fairness We compare training for fairness on the benchmark Adult dataset 2, the same dataset used by Zafar et al. [2015]. The 32 561 training and 16 281 testing examples, derived from the 1994 Census, are 123-dimensional and sparse.", "startOffset": 103, "endOffset": 123}, {"referenceID": 19, "context": "We compare to the method of Zafar et al. [2015], which proposed handling fairness with the constraint: \u3008w, x\u0304\u3009 \u2264 c, x\u0304 = \u2223\u2223DM \u2223\u2223\u22121\u2211x\u2208DMx \u2212 \u2223\u2223DF \u2223\u2223\u22121\u2211x\u2208DF x.", "startOffset": 28, "endOffset": 48}, {"referenceID": 19, "context": "We compare to the method of Zafar et al. [2015], which proposed handling fairness with the constraint: \u3008w, x\u0304\u3009 \u2264 c, x\u0304 = \u2223\u2223DM \u2223\u2223\u22121\u2211x\u2208DMx \u2212 \u2223\u2223DF \u2223\u2223\u22121\u2211x\u2208DF x. (6) We optimized an SVM subject to this constraint (see Appendix B for details), for a range of c values. Results in Figure 2 show the proposed method is much more accurate for any desired fairness, and achieves fairness ratios not reachable with the approach of Zafar et al. [2015] for any choice of c.", "startOffset": 28, "endOffset": 440}, {"referenceID": 19, "context": "We compare to the method of Zafar et al. [2015], which proposed handling fairness with the constraint: \u3008w, x\u0304\u3009 \u2264 c, x\u0304 = \u2223\u2223DM \u2223\u2223\u22121\u2211x\u2208DMx \u2212 \u2223\u2223DF \u2223\u2223\u22121\u2211x\u2208DF x. (6) We optimized an SVM subject to this constraint (see Appendix B for details), for a range of c values. Results in Figure 2 show the proposed method is much more accurate for any desired fairness, and achieves fairness ratios not reachable with the approach of Zafar et al. [2015] for any choice of c. It is also easier to control: the values of c in Zafar et al. [2015] do not have a clear interpretation, whereas \u03ba is an effective proxy for the fairness ratio.", "startOffset": 28, "endOffset": 530}, {"referenceID": 19, "context": "We note that the constraints of Zafar et al. [2015] can be interpreted as a relaxation of the constraint \u2212c \u2264 sp(D;w)\u2212 sp(D ;w) \u2264 c under the linear approximation sp(D;w, b) \u2248 1 |D| \u2211", "startOffset": 32, "endOffset": 52}, {"referenceID": 19, "context": "We can therefore simulate the approach of Zafar et al. [2015] within our framework by adding the constraints:", "startOffset": 42, "endOffset": 62}, {"referenceID": 3, "context": "Because this variant is based on finding a cut center in the m+ 1-dimensional hypograph, rather than an m-dimensional level set (which is arguably more typical), this is an instance of what Boyd and Vandenberghe [2011] call an \u201cepigraph cutting plane method\u201d.", "startOffset": 190, "endOffset": 219}, {"referenceID": 10, "context": "This is Theorem 2 of Gr\u00fcnbaum [1960].", "startOffset": 21, "endOffset": 37}, {"referenceID": 16, "context": "The easier-to-analyze approach, based on an inner SDCA optimization over w [Shalev-Shwartz and Zhang, 2013] and an outer cutting plane optimization over b (Algorithm 3), will be described in Appendices D.", "startOffset": 75, "endOffset": 107}, {"referenceID": 16, "context": "If we use SDCA [Shalev-Shwartz and Zhang, 2013] to optimize Equation 8 for fixed b and v, then we will find a suboptimal solution with duality gap \u2032\u2032 after performing at most:", "startOffset": 15, "endOffset": 47}, {"referenceID": 16, "context": "This is the form considered by Shalev-Shwartz and Zhang [2013], so we may apply SDCA: Theorem 3.", "startOffset": 31, "endOffset": 63}, {"referenceID": 16, "context": "This is Theorem 2 of Shalev-Shwartz and Zhang [2013]. SDCA works by, rather than directly minimizing \u03a8 over w, instead maximizing the following over the dual variables \u03be: \u03a8\u2217 (\u03be, b, v;w\u2032, b\u2032) = (8)", "startOffset": 21, "endOffset": 53}, {"referenceID": 17, "context": "For example, Shalev-Shwartz et al. [2011] suggest using Pegasos to perform inner optimizations over w, and a bisection-based outer optimization over b.", "startOffset": 13, "endOffset": 42}, {"referenceID": 4, "context": "Kernel-specific optimizers, such as LIBSVM [Chang and Lin, 2011], will generally work better than SDCA in practice, since they typically have the same per-iteration cost, but each iteration is \u201csmarter\u201d.", "startOffset": 43, "endOffset": 64}], "year": 2017, "abstractText": "The goal of minimizing misclassification error on a training set is often just one of several real-world goals that might be defined on different datasets. For example, one may require a classifier to also make positive predictions at some specified rate for some subpopulation (fairness), or to achieve a specified empirical recall. Other real-world goals include reducing churn with respect to a previously deployed model, or stabilizing online training. In this paper we propose handling multiple goals on multiple datasets by training with dataset constraints, using the ramp penalty to accurately quantify costs, and present an efficient algorithm to approximately optimize the resulting non-convex constrained optimization problem. Experiments on both benchmark and real-world industry datasets demonstrate the effectiveness of our approach.", "creator": "LaTeX with hyperref package"}}}