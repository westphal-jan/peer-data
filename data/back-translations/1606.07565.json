{"id": "1606.07565", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2016", "title": "Adaptability of Neural Networks on Varying Granularity IR Tasks", "abstract": "Recent work in the field of information retrieval (IR) using deep learning models has yielded state-of-the-art results in a variety of IR tasks. Deep Neural Networks (DNN) are capable of learning ideal representations of data during the training process, eliminating the need for independent trait extraction. However, the structures of these DNNs are often tailored to specific datasets. In addition, IR tasks treat texts with varying degrees of granularity from individual faculties to documents containing thousands of words. In this paper, we examine the role of granularity for the performance of common state-of-the-art DNN structures in IR.", "histories": [["v1", "Fri, 24 Jun 2016 04:40:48 GMT  (31kb)", "http://arxiv.org/abs/1606.07565v1", "4 pages, Neu-IR'16 SIGIR Workshop on Neural Information Retrieval, July 21, 2016, Pisa, Italy"]], "COMMENTS": "4 pages, Neu-IR'16 SIGIR Workshop on Neural Information Retrieval, July 21, 2016, Pisa, Italy", "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["daniel cohen", "qingyao ai", "w bruce croft"], "accepted": false, "id": "1606.07565"}, "pdf": {"name": "1606.07565.pdf", "metadata": {"source": "CRF", "title": "Adaptability of Neural Networks on Varying Granularity IR Tasks", "authors": ["Daniel Cohen", "Qingyao Ai", "W. Bruce Croft"], "emails": ["croft}@cs.umass.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 6.\n07 56\n5v 1\n[ cs\n.I R\n] 2\n4 Ju\nn 20\nCCS Concepts \u2022Information systems \u2192 Retrieval models and ranking; Question answering; Document structure; \u2022Computing methodologies \u2192 Neural networks;\nKeywords deep learning; Question Answering; ad-hoc retrieval"}, {"heading": "1. INTRODUCTION", "text": "Learning effective representations of data is a critical component of any system that ranks documents. Conventional approaches rely on transforming text into vectors consisting of lexical, semantic, and syntactic features that capture the information contained in text. This conversion depends on domain knowledge and is an independent step from the optimization process of the ranking method. As this process is separate from the loss function, potential information can be lost that negatively affects performance. Deep learning has been shown to learn internal representations directly from the text in natural language processing and specific IR tasks that yield state of the art performance. However, the deep\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s).\nNeu-IR \u201916 SIGIR Workshop on Neural Information Retrieval, July 21, 2016, Pisa, Italy c\u00a9 2016 Copyright held by the owner/author(s).\nlearning models used for these IR tasks are often tailored for the individual task with the network structure making some assumption about the data, and little work has been done in examining how well these networks can adapt to collections with varying levels of granularity.\nIR focuses on retrieval of information at differing levels of granularity whether at the single word level in the factoid task such as TREC QA, passage level involving community question and answer, or the document level dealing with ad-hoc retrieval. Each of these levels present unique challenges when fitting a model, and we show that DNNs are not exempt from this problem. In the following sections we examine state of the art DNNs on varying levels of granularity to demonstrate the efficacy of different neural structures at each level of granularity."}, {"heading": "2. RELATED WORK", "text": "At each level of granularity, significant improvements have been made by introducing various DNN structures. Convolutional neural networks (CNN) have been used at various layers in the neural net, at the input level over word embeddings demonstrated by Severyn and Moschitti [8], as an intermediary layer within a feedforward network introduced by Feng et al. [2], or as a penultimate stage on top of a recurrent neural network (RNN) to provide more composite representations over the question and answer text by Tan et al. [11]. Regardless of the position of the convolutional layer, the motivation behind implementing a convolutional layer was to extract the most salient features from the input to allow easier similarity comparisons.\nAs language is sequential in nature, RNNs have been shown to work extremely well for IR tasks. Wang and Nyberg [13, 14] show that using a bidirectional Long Short-Term Memory (BiLSTM) network over query-answer pairs to determine relevance is an effective approach to the fine grain level of the TREC QA task as well as for passage level retrieval. Providing additional insight to how LSTM networks process text, Palangi et al. [7] demonstrate the use of a weakly supervised LSTM network to detemine answer sentence similarity and examine how individual cells attenuate information when processing query-answer pairs.\nAnother important attempt that applies DNN for IR tasks is the Deep Structured Semantic Model (DSSM) and its variations. Introduced by Huang et al. [4], DSSM uses a word hashing technique to project varied length text into fixed length vectors as the model\u2019s input and constructs a feed-\nforward neural network above it. The relevance between documents and queries is measured by the cosine similarity between their output vectors. Recently, Shen et al. [9] proposed a convolution network (CLSM) and Palangi et al. [6] proposed a RNN-LSTM model with the same word hashing technique of DSSM. They showed positive results when applying these models on ad-hoc retrieval tasks with web page titles collections. However, the effectiveness of word hashing and DSSM models vary considerably as text length changes. Their performance on standard TREC collections are still poor according to our experiments."}, {"heading": "3. GRANULARITY TASKS", "text": "We examine the efficacy of deep learning on three distinct levels of granularity. First, at the fine grain level, retrieval focuses on a specific word or deals with a short sentence of text containing the relevant information. Second, at the medium granularity level, the information need of the query can no longer be addressed by a single sentence, and often requires multiple sentences to be relevant. Third, we address the coarse grain level, which we view as full document retrieval commonly found on ad-hoc retrieval tasks."}, {"heading": "3.1 Fine Granularity", "text": "The focus of this section is on the TREC QA task. In this task, the length of individual documents are often no more than a single sentence, and queries consist of short questions such as\u201cWhen did James Dean die?\u201dor\u201cWhat is crips\u2019 gang color\u201d. The relevant information in each document is one or two words that directly address the information need of the query.\nFrom the deep learning perspective, CNNs adapt well to the fine grained task as they are able to identify key aspects of an input matrix. This ability has resulted in these networks receiving widespread use in the computer vision task. The same principle can be applied to the sentence level by allowing convolutional layers to extract the most salient information over embeddings of a sentence. This approach has been used for semantic sentence level matching by Hu et al. [3]. Severyn and Moschitti [8] also take advantage of the matching ability of CNNs by implementing a convolutional layer to extract the most salient features between answer and query sentences to compute similarity scores for ranking.\nAn interesting note is the performance of RNNs at the same granularity level. As shown in Yin et al. [15] and Santos et al. [1], conventional CNNs often outperform equivalent LSTM networks at this level of granularity as filter lengths are able to capture the language dependencies and match keywords when the candidate answer sentences are short."}, {"heading": "3.2 Medium Granularity", "text": "The medium granularity level, consisting of passages, contrasts sharply with the granularity of the previous section.\nInstead of identifying specific words contained within a sentence, the passage task deals with information related to the query that can span multiple sentences. However, relevance is not determined solely by topical similarity between document and query. Text in relevant passages can have little term overlap with the query, and conventional IR methods such as BM25 have reflected this in their performance.\nDue to the span of relevant information across the length of candidate answers, LSTM networks are uniquely suited to this task as they are able to model syntactic and semantic dependencies across positions in a sequence and focus less on matching than the CNN does. We demonstrate this on Yahoo\u2019s Webscope L4 CQA collection [10] of \u201cmanner\u201d type questions, where a LSTM model built in a similar fashion to [13] significantly outperforms an equivalent CNN network as shown in Table 1. The purpose of this test was to demonstrate the ability of the two network structures to retain information across long sequences, therefore the candidate answer pool for each query consisted of 10 randomly sampled answers from the collection. These candidate answers are significantly longer than those found in WikiQA [2] or the TREC QA task with a mean length of 75. The filter lengths of CNNs are unable to capture long term dependencies that span multiple sentences, which results in its poor performance relative to the LSTM network.\nPalangi et al. [7] investigate the internal representation of text within a LSTM network. Internal cell states accumulate semantic information across sequences, and their corresponding inputs learn to respond to semantically related words specific to each cell. In addition, the LSTM network is capable of keyword recognition to directly match query and document similarities. This contrasts with a standard RNN without LSTM cells, where the length of the passage task results in the internal representation \u2018forgetting\u2019 previous information due to the vanishing gradient problem."}, {"heading": "3.3 Coarse Granularity", "text": "Tasks with coarse granularity including Ad-hoc retrieval are usually concerned with collections of text with great variation in length. Although the queries tend to be shorter, the documents range from tens of words to thousands of terms. Accompanying the challenge that length variation poses, the concept of relevance varies from document to document as the relevant portion of a document might range from a few sentences to its entirety. These two unique properties of coarse granularity collections result in different challenges for DNNs which are not apparent at other granularity levels.\nWe applied conventional networks discussed in Section 3.2 which performed well on passage length answers, but were unable to perform better than random over the Robust04 collection and thus require a different approach.\nVaried input length. In ad-hoc retrieval tasks, the length differences in documents are so large that they significantly affect the training of deep models. Most neural models include a step that converts varied length input into fixed length vectors (i.e. input layer for DNN, pooling in CNN and memory vectors in RNN). Without accounting for the original length of text, this process could introduce strong bias for short or long documents. For example, to train a deep structure semantic model (DSSM) for ad-hoc retrieval, Huang et al. [4] proposed a word hashing technique that aggregates n-grams of terms to produce a fixed length repre-\nsentation for each document. When applied to short text like web page titles, which have few n-grams, word hashing produces high quality representations without losing too much information. However, this technique becomes problematic as document length increases from tens of words to hundreds of words. According to our observations, the n-gram representations for documents with hundreds of words are dense and noisy. Unsurprisingly, our experiments with DSSM on standard ad-hoc retrieval collections were not effective. The MAP of DSSM and its convolution version (CLSM) are less than 0.1 on Robust04 title queries. Notice that the same metric for query likelihood (QL) model is 0.253 as shown in Table 2.\nVaried relevance granularity. Another problem that makes ad-hoc retrieval difficult for existing deep models is the vague definition for relevance. A short document could be relevant to a query because its main topic is related to the query. Meanwhile, a long document could be relevant to a query if it has a subtopic that describes the query. This characteristic of ad-hoc retrieval presents challenges to both supervised and unsupervised neural models. For supervised models like DNN and RNN, the back propagation of relevance information affects the gradient computation on all input words. However, most of these words may not be related to the document\u2019s relevance with a specific query (especially for long documents). A considerable amount of labeled data is needed in order to learn the weights for a model that can understand the relevance of a document from different angles.\nFor unsupervised models like WE [12] and the paragraph vector model (PV) [5], the embedding representations of documents are constructed to capture their main topics. These representations lack discriminative ability at query time because we cannot distinguish the finer difference between semanticly related words and subtopics [16]. For example, Table 2 shows the performance of retrieval models including WE and PV. WE [12] aggregates embeddings of words to form document representations and ranks documents according to their cosine similarities with queries. PV estimates a language model with paragraph vector model [5] and ranks documents according to the likelihood of queries given document models. Using WE and PV solely did not perform well compared to QL with dirichlet smoothing. We only achieve positive results when we combined these models with language modeling approaches that explicitly capture the exact matching information of queries and documents. As these problems pose significant challenges from a deep learning perspective, one direction of future research is examining the role of the attention mechanism when dealing\nwith documents at the coarse granularity level."}, {"heading": "4. CONCLUSION", "text": "We have shown the efficacy and shortcomings of common neural architectures at varying levels of IR task granularity. When candidate answers are short, CNNs and LSTM networks perform at equivalent levels with differences attributed to attention methods and structure differences beyond the convolutional and LSTM layers. At the passage level, we demonstrate that LSTMs are able to store additional temporal information which an equivalent CNN is unable to accomplish. Lastly, we discuss the unique problem that ad-hoc retrieval poses for neural networks, and potential solutions to overcome these issues."}, {"heading": "5. ACKNOWLEDGMENT", "text": "This work was supported in part by the Center for Intelligent Information Retrieval and in part by NSF IIS-1160894. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor."}, {"heading": "6. REFERENCES", "text": "[1] C. N. dos Santos, M. Tan, B. Xiang, and B. Zhou.\nAttentive pooling networks. CoRR, abs/1602.03609, 2016.\n[2] M. Feng, B. Xiang, M. R. Glass, L. Wang, and B. Zhou. Applying Deep Learning to Answer Selection: A Study and An Open Task. Applying Deep Learning to, aug 2015.\n[3] B. Hu, Z. Lu, H. Li, and Q. Chen. Convolutional neural network architectures for matching natural language sentences. CoRR, abs/1503.03244, 2015.\n[4] P.-S. Huang, X. He, J. Gao, L. Deng, A. Acero, and L. Heck. Learning deep structured semantic models for web search using clickthrough data. In Proceedings of the 22nd ACM international conference on Conference on information & knowledge management, pages 2333\u20132338. ACM, 2013.\n[5] Q. V. Le and T. Mikolov. Distributed representations of sentences and documents. arXiv preprint arXiv:1405.4053, 2014.\n[6] H. Palangi, L. Deng, Y. Shen, J. Gao, X. He, J. Chen, X. Song, and R. Ward. Semantic modelling with long-short-term memory for information retrieval. arXiv preprint arXiv:1412.6629, 2014.\n[7] H. Palangi, L. Deng, Y. Shen, J. Gao, X. He, J. Chen, X. Song, and R. K. Ward. Deep sentence embedding using long short-term memory networks: Analysis and application to information retrieval. IEEE/ACM Trans. Audio, Speech & Language Processing, 24(4):694\u2013707, 2016.\n[8] A. Severyn and A. Moschitti. Learning to rank short text pairs with convolutional deep neural networks. In SIGIR, SIGIR \u201915, pages 373\u2013382, New York, NY, USA, 2015. ACM.\n[9] Y. Shen, X. He, J. Gao, L. Deng, and G. Mesnil. A latent semantic model with convolutional-pooling structure for information retrieval. In Proceedings of\nthe 23rd ACM International Conference on Conference on Information and Knowledge Management, pages 101\u2013110. ACM, 2014.\n[10] M. Surdeanu, M. Ciaramita, and H. Zaragoza. Learning to rank answers on large online qa collections. In ACL:HLT, pages 719\u2013727, 2008.\n[11] M. Tan, B. Xiang, and B. Zhou. Lstm-based deep learning models for non-factoid answer selection. CoRR, abs/1511.04108, 2015.\n[12] I. Vulic\u0301 and M.-F. Moens. Monolingual and cross-lingual information retrieval models based on (bilingual) word embeddings. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 363\u2013372. ACM, 2015.\n[13] D. Wang and E. Nyberg. A recurrent neural network based answer ranking model for web question answering. In WebQA Workshop, SIGIR \u201915, Santiago, Chile.\n[14] D. Wang and E. Nyberg. A recurrent neural network based answer ranking model for web question answering. In WebQA Workshop, SIGIR \u201915, Santiago, Chile.\n[15] W. Yin, H. Schu\u0308tze, B. Xiang, and B. Zhou. ABCNN: attention-based convolutional neural network for modeling sentence pairs. CoRR, abs/1512.05193, 2015.\n[16] C. Zhai. Statistical language models for information retrieval. Synthesis Lectures on Human Language Technologies, 1(1):1\u2013141, 2008."}], "references": [{"title": "Applying Deep Learning to Answer Selection: A Study and An Open Task", "author": ["M. Feng", "B. Xiang", "M.R. Glass", "L. Wang", "B. Zhou"], "venue": "Applying Deep Learning to,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Convolutional neural network architectures for matching natural language sentences", "author": ["B. Hu", "Z. Lu", "H. Li", "Q. Chen"], "venue": "CoRR, abs/1503.03244,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Learning deep structured semantic models for web search using clickthrough data", "author": ["P.-S. Huang", "X. He", "J. Gao", "L. Deng", "A. Acero", "L. Heck"], "venue": "In Proceedings of the 22nd ACM international conference on Conference on information & knowledge management,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Distributed representations of sentences and documents", "author": ["Q.V. Le", "T. Mikolov"], "venue": "arXiv preprint arXiv:1405.4053,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Semantic modelling with long-short-term memory for information retrieval", "author": ["H. Palangi", "L. Deng", "Y. Shen", "J. Gao", "X. He", "J. Chen", "X. Song", "R. Ward"], "venue": "arXiv preprint arXiv:1412.6629,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Deep sentence embedding using long short-term memory networks: Analysis and application to information retrieval", "author": ["H. Palangi", "L. Deng", "Y. Shen", "J. Gao", "X. He", "J. Chen", "X. Song", "R.K. Ward"], "venue": "IEEE/ACM Trans. Audio, Speech & Language Processing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Learning to rank short text pairs with convolutional deep neural networks", "author": ["A. Severyn", "A. Moschitti"], "venue": "In SIGIR,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "A latent semantic model with convolutional-pooling structure for information retrieval", "author": ["Y. Shen", "X. He", "J. Gao", "L. Deng", "G. Mesnil"], "venue": "In Proceedings of  the 23rd ACM International Conference on Conference on Information and Knowledge Management,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Learning to rank answers on large online qa collections", "author": ["M. Surdeanu", "M. Ciaramita", "H. Zaragoza"], "venue": "In ACL:HLT,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Lstm-based deep learning models for non-factoid answer selection", "author": ["M. Tan", "B. Xiang", "B. Zhou"], "venue": "CoRR, abs/1511.04108,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Monolingual and cross-lingual information retrieval models based on (bilingual) word embeddings", "author": ["I. Vuli\u0107", "M.-F. Moens"], "venue": "In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "ABCNN: attention-based convolutional neural network for modeling sentence", "author": ["W. Yin", "H. Sch\u00fctze", "B. Xiang", "B. Zhou"], "venue": "pairs. CoRR,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Statistical language models for information retrieval", "author": ["C. Zhai"], "venue": "Synthesis Lectures on Human Language Technologies,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}], "referenceMentions": [{"referenceID": 6, "context": "Convolutional neural networks (CNN) have been used at various layers in the neural net, at the input level over word embeddings demonstrated by Severyn and Moschitti [8], as an", "startOffset": 166, "endOffset": 169}, {"referenceID": 0, "context": "[2], or as a penultimate stage on top of a recurrent neural network (RNN) to provide more composite representations over the question and answer text by Tan et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[11].", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[7] demonstrate the use of a weakly supervised LSTM network to detemine answer sentence similarity and examine how individual cells attenuate information when processing query-answer pairs.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[4], DSSM uses a word hashing technique to project varied length text into fixed length vectors as the model\u2019s input and constructs a feed-", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[9] proposed a convolution network (CLSM) and Palangi et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[6] proposed a RNN-LSTM model with the same word hashing technique of DSSM.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "Severyn and Moschitti [8] also take advantage of the matching ability of CNNs by implementing a convolutional layer to extract the most salient features between answer and query sentences to compute similarity scores for ranking.", "startOffset": 22, "endOffset": 25}, {"referenceID": 11, "context": "[15] and Santos et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "We demonstrate this on Yahoo\u2019s Webscope L4 CQA collection [10] of \u201cmanner\u201d type", "startOffset": 58, "endOffset": 62}, {"referenceID": 0, "context": "These candidate answers are significantly longer than those found in WikiQA [2] or the TREC QA task with a mean length of 75.", "startOffset": 76, "endOffset": 79}, {"referenceID": 5, "context": "[7] investigate the internal representation of text within a LSTM network.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[4] proposed a word hashing technique that aggregates n-grams of terms to produce a fixed length repre-", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "For unsupervised models like WE [12] and the paragraph vector model (PV) [5], the embedding representations of documents are constructed to capture their main topics.", "startOffset": 32, "endOffset": 36}, {"referenceID": 3, "context": "For unsupervised models like WE [12] and the paragraph vector model (PV) [5], the embedding representations of documents are constructed to capture their main topics.", "startOffset": 73, "endOffset": 76}, {"referenceID": 12, "context": "These representations lack discriminative ability at query time because we cannot distinguish the finer difference between semanticly related words and subtopics [16].", "startOffset": 162, "endOffset": 166}, {"referenceID": 10, "context": "WE [12] aggregates embeddings of words to form document representations and ranks documents according to their cosine similarities with queries.", "startOffset": 3, "endOffset": 7}, {"referenceID": 3, "context": "PV estimates a language model with paragraph vector model [5] and ranks documents according to the likelihood of queries given document models.", "startOffset": 58, "endOffset": 61}], "year": 2016, "abstractText": "Recent work in Information Retrieval (IR) using Deep Learning models has yielded state of the art results on a variety of IR tasks. Deep neural networks (DNN) are capable of learning ideal representations of data during the training process, removing the need for independently extracting features. However, the structures of these DNNs are often tailored to perform on specific datasets. In addition, IR tasks deal with text at varying levels of granularity from single factoids to documents containing thousands of words. In this paper, we examine the role of the granularity on the performance of common state of the art DNN structures in IR.", "creator": "LaTeX with hyperref package"}}}