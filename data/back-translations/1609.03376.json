{"id": "1609.03376", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2016", "title": "Morphological Constraints for Phrase Pivot Statistical Machine Translation", "abstract": "The lack of parallel data for many language pairs poses an important challenge for statistical machine translation (SMT). A common solution is to pivot through a third language for which there is parallel corpora with the source and target languages. Although pivoting is a robust technique, it leads to some low-quality translations, especially when poor morphology is used as a pivot between rich morphology languages. In this paper, we examine the use of synchronous morphological constraints to improve the quality of phrase rotation SMT. We compare handmade constraints with those learned from limited parallel data between source and target languages. The learned morphological constraints are based on projected adjustments between source and target phrases in the pivot and phrase rotation table. We show positive results in Hebrew-Arabic SMT (pivot to EU English) data. We get 1.5 system points based on a leaflet point and an EU-0.8 leaflet point.", "histories": [["v1", "Mon, 12 Sep 2016 12:52:37 GMT  (431kb)", "http://arxiv.org/abs/1609.03376v1", "13 pages; Proceedings of MT Summit XV, vol.1: MT Researchers' Track; Miami, Oct 30 - Nov 3, 2015"]], "COMMENTS": "13 pages; Proceedings of MT Summit XV, vol.1: MT Researchers' Track; Miami, Oct 30 - Nov 3, 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ahmed el kholy", "nizar habash"], "accepted": false, "id": "1609.03376"}, "pdf": {"name": "1609.03376.pdf", "metadata": {"source": "CRF", "title": "Morphological Constraints for Phrase Pivot Statistical Machine Translation", "authors": ["Ahmed El Kholy", "Nizar Habash"], "emails": ["ame2127@columbia.edu", "nizar.habash@nyu.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 9.\n03 37\n6v 1\n[ cs\n.C L\nThe lack of parallel data for many language pairs is an important challenge to statistical machine translation (SMT). One common solution is to pivot through a third language for which there exist parallel corpora with the source and target languages. Although pivoting is a robust technique, it introduces some low quality translations especially when a poor morphology language is used as the pivot between rich morphology languages. In this paper, we examine the use of synchronous morphology constraint features to improve the quality of phrase pivot SMT. We compare hand-crafted constraints to those learned from limited parallel data between source and target languages. The learned morphology constraints are based on projected alignments between the source and target phrases in the pivot phrase table. We show positive results on Hebrew-Arabic SMT (pivoting on English). We get 1.5 BLEU points over a phrase pivot baseline and 0.8 BLEU points over a system combination baseline with a direct model built from parallel data."}, {"heading": "1 Introduction", "text": "One of the main challenges in statistical machine translation (SMT) is the scarcity of parallel data for many language pairs especially when the source and target languages are morphologically rich. A common SMT solution to the lack of parallel data is to pivot the translation through a third language (called pivot or bridge language) for which there exist abundant parallel corpora with the source and target languages. The literature covers many pivoting techniques. One of the best performing techniques, phrase pivoting (Utiyama and Isahara, 2007), builds an induced new phrase table between the source and target. One of the main issues of this technique is that the size of the newly created pivot phrase table is very large. Moreover, many of the produced phrase pairs are of low quality which affects the translation choices during decoding and the overall translation quality.\nIn this paper, we focus on improving phrase pivoting. We introduce morphology constraint scores which are added to the log linear space of features in order to determine the quality of the pivot phrase pairs. We compare two methods of generating the morphology constraints. One method is based on hand-crafted rules relying on the authors knowledge of the source and target languages; while in the other method, the morphology constraints are induced from\navailable parallel data between the source and target languages which we also use to build a direct translation model. We then combine both the pivot and direct models to achieve better coverage and overall translation quality. We show positive results on Hebrew-Arabic SMT. We get 1.5 BLEU points over a phrase-pivot baseline and 0.8 BLEU points over a system combination baseline with a direct model built from given parallel data.\nNext, we briefly discuss some related work. In Section 3, we review the best performing pivoting strategy and how we use it. In Section 4, we discuss the linguistic differences among Hebrew, Arabic, and the pivot language, English. This is followed by our approach to using morphology constraints in Section 5. We finally present our experimental results in Section 6 and a case study in Section 7."}, {"heading": "2 Related Work", "text": "Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009). The main idea is to introduce a pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. Pivoting has been explored for closely related languages (Hajic\u030c et al., 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009). Many different pivot strategies have been presented in the literature. The following three are the most common. The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (Khalilov et al., 2008). The second strategy is based on phrase pivoting (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009). In phrase pivoting, a new source-target phrase table (translation model) is induced from source-pivot and pivot-target phrase tables. Lexical weights and translation probabilities are computed from the two translation models. The third strategy is to create a synthetic source-target corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008). In this paper, we use the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007).\nThere has been recent efforts in improving phrase pivoting. One effort focused on improving alignment symmetrization targeting pivot phrase systems (El Kholy and Habash, 2014). In another recent effort, Multi-Synchronous Context-free Grammar (MSCFG) is leveraged to triangulate source-pivot and pivot-target synchronous Context-free Grammar (SCFG) rule tables into a source-target-pivot MSCFG rule table that helps in remembering the pivot during decoding. Also, pivot LMs are used to assess the naturalness of the derivation (Miura et al., 2015).\nIn our own previous work, we demonstrated quality improvement using connectivity strength features between the source and target phrase pairs in the pivot phrase table (El Kholy et al., 2013). These features provide quality scores based on the number of alignment links between words in the source phrase to words of the target phrase. In this work, we extend on the connectivity scores with morphological constraints through which we provide quality scores based on the morphological compatibility between the connected/aligned source and target words.\nSince both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010; Habash and Sadat, 2006; Kathol and Zheng, 2008). Most of these efforts are focused on syntactic and morphological processing to improve the quality of translation.\nUntil recently, there has not been much parallel Hebrew-English and Hebrew-Arabic data (Tsvetkov and Wintner, 2010), and consequently little work on Hebrew-English and Hebrew-\nArabic SMT. Lavie et al. (2004) built a transfer-based translation system for Hebrew-English and so did Shilon et al. (2012) for translation between Hebrew and Arabic. Our previous work discussed above (El Kholy et al., 2013) was demonstrated on Hebrew-Arabic with English pivoting."}, {"heading": "3 Phrase Pivoting", "text": "In this section, we review the phrase pivoting strategy in detail as we describe how we built our baseline for Arabic-Hebrew via pivoting on English. We also discuss how we overcome the large expansion of source-to-target phrase pairs in the process of creating a pivot phrase table. In phrase pivoting (which is sometimes called triangulation or phrase table multiplication), we train a Hebrew-Arabic and an English-Arabic translation models, such as those used in the sentence pivoting technique. Based on these two models, we induce a new HebrewArabic translation model. Since our models are based on a Moses phrase-based SMT system (Koehn et al., 2007), we use the standard set of phrase-based translation probability distributions.1 We follow Utiyama and Isahara (2007) in computing the pivot phrase pair probabilities. The following are the set of equations used to compute the lexical probabilities (pw) and the phrase translation probabilities (\u03c6):\n\u03c6(h|a) = \u2211\ne\n\u03c6(h|e)\u03c6(e|a)\n\u03c6(a|h) = \u2211\ne\n\u03c6(a|e)\u03c6(e|h)\npw(h|a) = \u2211\ne\npw(h|e)pw(e|a)\npw(a|h) = \u2211\ne\npw(a|e)pw(e|h)\nAbove, h is the Hebrew source phrase; e is the English pivot phrase that is common in both Hebrew-English translation model and English-Arabic translation model; and a is the Arabic target phrase. We also build a Hebrew-Arabic reordering table using the same technique but we compute the reordering probabilities in a similar manner to Henriquez et al. (2010).\nFiltering for Phrase Pivoting As discussed earlier, the induced Hebrew-Arabic phrase and reordering tables are very large. Table 1 shows the amount of parallel corpora used to train the Hebrew-English and the English-Arabic and the equivalent phrase table sizes compared to the induced Hebrew-Arabic phrase table.2 We follow the work of El Kholy et al. (2013) and filter the phrase pairs used in pivoting based on log-linear scores. The main idea of the filtering process is to select the top [n] English candidate phrases for each Hebrew phrase from the Hebrew-English phrase table and similarly select the top [n] Arabic target phrases for each English phrase from the English-Arabic phrase table and then perform the pivoting process described earlier to create a pivoted Hebrew-Arabic phrase table. To select the top candidates, we\n1Four different phrase translation scores are computed in Moses\u2019 phrase tables: two lexical weighting scores and two phrase translation probabilities.\n2The size of the induced phrase table size is computed but not created.\nfirst rank all the candidates based on the log linear scores computed from the phrase translation probabilities and lexical weights multiplied by the optimized decoding weights then we pick the top [n] pairs. In our experiments, we pick the top 1000 pairs for pivoting."}, {"heading": "4 Linguistic Comparison", "text": "In this section we present the challenges of preprocessing Arabic, Hebrew, and English, and how we address them. Both Arabic and Hebrew are morphologically complex languages. One aspect of Arabic\u2019s complexity is its various attachable clitics and numerous morphological features (Habash, 2010). Clitics include conjunction proclitics, e.g., +\u00f0 w+3 \u2018and\u2019, prepositional proclitics, e.g., +\u00c8 l+ \u2018to/for\u2019, the definite article +\u00c8@ Al+ \u2018the\u2019, and the class of pronominal enclitics, e.g., \u00d1\u00eb+ +hm \u2018their/them\u2019. All of these clitics are separate words in English. Beyond the clitics, Arabic words inflect for person, gender, number, aspect, mood, voice, state and case. Additionally, Arabic orthography uses optional diacritics for short vowels and consonant doubling. This, together with Arabic\u2019s morphological richness, leads to a high degree of ambiguity: about 12 analyses per word, typically corresponding to two lemmas on average (Habash, 2010). We follow El Kholy and Habash (2010) and use the PATB tokenization scheme (Maamouri et al., 2004) in our experiments. The PATB scheme separates all clitics except for the determiner clitic Al+(DET). We use MADA v3.1 (Habash and Rambow, 2005; Habash et al., 2009) to tokenize the Arabic text. We only evaluate on detokenized and orthographically correct (enriched) output following the work of El Kholy and Habash (2010).\nSimilar to Arabic, Hebrew poses computational processing challenges typical of Semitic languages (Itai and Wintner, 2008; Shilon et al., 2012). Hebrew orthography also uses optional diacritics and its morphology inflects for gender, number, person, state, tense and definiteness. Furthermore, Similar to Arabic, Hebrew has a set of attachable clitics, e.g., conjunctions (such as + !\u05d5 w+4 \u2018and\u2019), prepositions (such as + !\u05d1 b+ \u2018in\u2019), the definite article (+ !\u05d4 h+ \u2018the\u2019), or pronouns (such as !\u05dd\u05d4+ +hm \u2018their\u2019). These issues contribute to a high degree of ambiguity that is a challenge to translation from Hebrew to English or to any other language. We follow Singh and Habash (2012)\u2019s best preprocessing setup which utilized a Hebrew tagger (Adler, 2007) and produced a tokenization scheme that separated all clitics.\nEnglish, our pivot language, is quite different from both Arabic and Hebrew. English is poor in morphology and barely inflects for number and tense, and for person in a limited context. English preprocessing simply includes down-casing, separating punctuation and splitting off \u201c\u2019s\u201d."}, {"heading": "5 Approach", "text": "One of the main challenges in phrase pivoting is the very large size of the induced phrase table. It becomes even more challenging if either the source or target language is morphologically rich. The number of translation candidates (fanout) increases due to ambiguity and richness which in return increases the number of combinations between source and target phrases. Since the only criteria of matching between the source and target phrase is through a pivot phrase, many of the induced phrase pairs are of low quality. These phrase pairs unnecessarily increase the search space and hurt the overall quality of translation. A basic solution to the combinatorial expansion is to filter the phrase pairs used in pivoting based on log-linear scores as discussed in Section 3, however, this doesn\u2019t solve the low quality problem.\n3Arabic transliteration throughout the paper is presented in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007).\n4The following Hebrew 1-to-1 transliteration is used (in Hebrew alphabetical order): abgdhwzxTiklmns\u2018pcqrs\u030ct. All examples are undiacritized and final forms are not distinguished from non-final forms.\nSimilar to factored translation models (Koehn and Hoang, 2007) where linguistic (morphology) features are augmented to the translation model to improve the translation quality, our approach to address the quality problem is based on constructing a list of synchronous morphology constraints between the source and target languages. These constraints are used to generate scores to determine the quality of pivot phrase pairs. However, unlike factored models, we do not use the morphology in generation and the morphology information comes completely from external resources. In addition, since we work in the pivoting space, we only apply the morphology constraints to the connected words between the source and target languages through the pivot language. This guarantees a fundamental level of semantic equivalence before applying the morphology constraints especially if there is distortion between source and target phrases.\nWe build on our approach in El Kholy et al. (2013) where we introduced connectivity strength features between the source and target phrase pairs in the pivot phrase table. These features provide quality scores based on the number of alignment links between words in the source phrase and words in the target phrase. The alignment links are generated by projecting the alignments of the source-pivot phrase pairs and the pivot-target phrase pairs used in pivoting. We use the same concept but instead of using the lexical mapping between source and target words, we compute quality scores based on the morphological compatibility between the connected source and target words.\nTo choose which morphological features to work with, we performed an automatic error analysis on the output of the phrase-pivot baseline system. We did the analysis using AMEANA (El Kholy and Habash, 2011), an open-source error analysis tool for natural language processing tasks targeting morphologically rich languages. We found that the most problematic morphological features in the Arabic output are gender (GEN), number (NUM) and determiner (DET). We focus on those features in addition to (POS) in our experiments.\nNext, we present our approach to generating the morphology constraint features using hand-crafted rules and compare this approach with inducing these constraints from HebrewArabic parallel data."}, {"heading": "5.1 Rule-based Morphology Constraints", "text": "Our rule-based morphology constraint features are basically a list of hand-crafted mappings of the different morphological features between Hebrew and Arabic. Since both languages are morphologically rich as explained in Section 4, it is straightforward to produce these mappings for GEN, NUM and DET. Note, however, that we also account for ambiguous cases; e.g., feminine gender in Arabic can map to words with ambiguous gender in Hebrew. We additionally use different POS tag sets for Arabic (47 tags) and Hebrew (25 tags) and in many cases one Hebrew tag can map to more than one Arabic tag; for example, three Arabic noun tags abbrev, noun and noun prop map to two Hebrew tags feminine, masculine noun.5 Table 2 shows a sample of the morphological mappings between Arabic and Hebrew.\nAfter building the morphological features mappings, we use them to judge the quality of a given phrase pair in the phrase pivot model. We add two scores Ws and Wt to the log linear space. Given a source-target phrase pair s\u0304, t\u0304 and a word projected alignment a between the source word positions i = 1, ..., n and the target word positions j = 1, ...,m, Ws and Wt are defined in equations 1 and 2. F is the set of morphological features (we focus on GEN, NUM, DET and POS). Mf is the hand-crafted rules mapping between Arabic and Hebrew feature values of feature f \u2208 F . In case of ambiguity for a given feature; for example, a word\u2019s gender being masculine or feminine, we use the maximum likelihood value of this feature given the word. MLEf (i) is the maximum likelihood feature value of feature f for the source word at\n5Please refer to (Habash et al., 2009) for a complete set of Arabic POS tag set and (Adler, 2007) for Hebrew POS tag set.\nposition i, and MLEf (j) is the maximum likelihood feature value of feature f for the target word at position j. The maximum likelihood feature values for Hebrew were computed from the Hebrew side of the training data. As for Arabic, the maximum likelihood feature values were computed from the Arabic side of the training data in addition to Arabic Gigaword corpus, which was used in creating the language model (more details in Section 6.1).\nWs = 1\n|F |\n\u2211\n\u2200f\u2208F\n\u2211\n\u2200(i,j)\u2208a\n1 n [(MLEf (i),MLEf (j)) \u2208 Mf ] (1)\nWt = 1\n|F |\n\u2211\n\u2200f\u2208F\n\u2211\n\u2200(i,j)\u2208a\n1 m [(MLEf (i),MLEf (j)) \u2208 Mf ] (2)"}, {"heading": "5.2 Induced Morphology Constraints", "text": "In this section, we explain our approach in generating morphology constraint features from a given parallel data between source and target languages. Unlike the rule-based approach we build a translation model between the source and target morphological features and we use the morphology translation probabilities as metric to judge a given phrase pair in the pivot phrase table. For the automatically induced constraints, we jointly model mapping between conjunctions of features attached to aligned words rather than tallying each feature match independently. Writing good manual rules for such feature conjunction mappings would be more difficult. Table 3 shows some examples of mapping (GEN), number (NUM) and determiner (DET) in Hebrew to their equivalent in Arabic and their respective bi-directional scores.\nAs in rule-based approach, we add two scores Ws and Wt to the log linear space which are defined in equations 3 and 4. PFC is the conditional morphology probability of a given feature\ncombination (FC) value. Similar to rule-based morphology constraints, we resort to the maximum likelihood value of a feature combination when the values are ambiguous. MLEFC(i) is the maximum likelihood feature combination (FC) value for the source word at position i while MLEFC(j) is the maximum likelihood feature combination (FC) value for the target word at position j.\nWs = 1\nn\n\u2211\n\u2200(i,j)\u2208a\nPFC(MLEFC(i)|MLEFC(j)) (3)\nWt = 1\nm\n\u2211\n\u2200(i,j)\u2208a\nPFC(MLEFC(j)|MLEFC(i)) (4)"}, {"heading": "5.3 Model Combinations", "text": "Since we use parallel data to induce the morphology constraints, it would make sense to measure the effect of combining (a) the pivot model with added morphology constraints, and (b) the direct model trained on the parallel data used to induce the morphology constraints. We perform the combination using Moses\u2019 phrase table combination techniques. Translation options are collected from one table, and additional options are collected from the other tables. If the same translation option (in terms of identical input phrase and output phrase) is found in multiple tables, separate translation options are created for each occurrence, but with different scores (Koehn and Schroeder, 2007). We show results over a learning curve in Section 6.5."}, {"heading": "6 Experiments", "text": "In this section, we present a set of experiments comparing the use of rule-based versus induced morphology constraint features in phrase-pivot SMT as well as model combination to improve Hebrew-Arabic pivot translation quality."}, {"heading": "6.1 Experimental Setup", "text": "In our pivoting experiments, we build two SMT models; one model to translate from Hebrew to English, and another model to translate from English to Arabic. The English-Arabic parallel corpus is about (\u2248 60M words) and is available from LDC6 and GALE7 constrained data. The Hebrew-English corpus is about (\u2248 1M words) and is available from sentence-aligned corpus produced by Tsvetkov and Wintner (2010). For the direct Hebrew-Arabic SMT model, we use a TED parallel corpus of about (\u2248 2M words) (Cettolo et al., 2012).\nWord alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002).\nAll experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight optimization. Weights are optimized using a tuning set of 517 sentences developed by Shilon et al. (2010).\nWe use a maximum phrase length of size 8 across all models. We report results on a Hebrew-Arabic development set (Dev) of 500 sentence with a single reference and an evaluation set (Test) of 300 sentences with three references developed by Shilon et al. (2010). We evaluate using BLEU-4 (Papineni et al., 2002).\n6LDC Catalog IDs: LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2006G05, LDC2007E06, LDC2007E101, LDC2007E103, LDC2007E46, LDC2007E86, LDC2008E40, LDC2008E56, LDC2008G05, LDC2009E16, LDC2009G01.\n7Global Autonomous Language Exploitation, or GALE, was a DARPA-funded research project."}, {"heading": "6.2 Baselines", "text": "We compare the performance of adding the connectivity strength features (+Conn) to the phrase pivoting SMT model (Phrase Pivot) and building a direct SMT model using all parallel He-Ar corpus available. The results are presented in Table 4. Consistently with our previous effort (El Kholy et al., 2013), the performance of the phrase-pivot model improves with the connectivity strength features. While the direct system is better than the phrase pivot model in general, the combination of both models leads to a high performance gain of 1.7/4.4 BLEU points in Dev/Test over the best performers of both the direct and phrase-pivot models."}, {"heading": "6.3 Rule-based Morphology Constraints", "text": "In this experiment, we show the performance of adding hand-crafted morphology constraints (+Morph Rules) to determine the quality of a given phrase pair in the phrase-pivot translation model. The third row in Table 5 shows that although the rules are based on a one-toone mapping between the different morphological features, the translation quality is improved over the baseline phrase-pivot model by 0.5/0.8 BLEU points in Dev/Test sets.\nAs expected, the system combination of the pivot model with the direct model improves the overall performance but the gain we get from the morphology constraints only appears in the Dev set with 0.8 BLEU points, and not much in the Test set."}, {"heading": "6.4 Induced Morphology Constraints", "text": "In this experiment, we measure the effect of using induced morphology constraints (+Morph Auto) on MT quality. The last row in Table 5 shows that the induced morphology constraints improve the results over the baseline phrase-pivot model by 0.5/1.5 BLEU points in\nDev/Test sets and over the Rule-based morphology constraints by 0.7 BLEU points in the Test set.\nSimilar to the Rule-based constraints, the performance did not improve compared to the direct model in the Dev set; but, again, the Test set showed a great improvement of 1.5 and 1.2 BLEU points over the pivot and direct models, respectively. Also the system combination of the pivot model with the direct model improves the overall performance. The model using induced morphological features is the best performer with an increase in the performance gain by 1.0/0.8 BLEU points in Dev/Test sets. This shows that the benefit we get from the induced morphology constraints were not diluted when we do the model combination given the fact that the constraints were induced from the parallel data to start with.\nIt is important to note here that the induced morphology constraints outperformed the rule-based constraints across all settings. This shows that the complex morphology constraints extracted from the parallel data provide knowledge that can not be covered by simple linguistic rules. However, the simple rule-based approach comes in handy when there is no data between the source and target languages."}, {"heading": "6.5 Learning Curve", "text": "In this experiment, we examine the effect of using less data in inducing morphology constraints rules and the overall performance when we combine systems. Table 6 shows the results on a learning curve of 100% (2M words), 25% (500K words) and 6.25% (125K words) of the parallel Hebrew-Arabic corpus.\nAs expected, The system combination between the direct translation models and the phrase-pivot translation model leads to an improvement in the translation quality across the learning curve even when there is small amount of parallel corpora. Despite the weak performance (2.7 BLEU) of the direct system built on 6.25% of the parallel Hebrew-Arabic corpus, the system combination leads to 1.4 BLEU points gain.\nAn interesting observation from the results is that we always get a performance gain from the induced morphology constrains across all settings. This shows that the system combination helps in adding more lexical translation choices while the constraints help in a different dimension, which is selecting the best phrase pairs from the pivot system."}, {"heading": "7 Case Study", "text": "In this section we consider an example from our Dev set that captures many of the patterns and themes in the evaluation. Table 7 shows a Hebrew source sentence and its Arabic reference. This is followed by the output from the pivot system, the direct system, the Phrase Pivot+Conn+Morph Auto system and the combined system.\nTwo particular aspects should be noted. First is the complementary lexical coverage of the direct and pivot systems. This is seen in how one of each covers half of the phrase middlemen and traders. The combined system captures both. Secondly, the gender, number and tense of the main verb prove challenging in many ways (and this is an issue for a majority of the sentences in the Dev set). The Hebrew verb in the present tense is masculine and plural; and naturally follows the subject. The Arabic reference verb appears at the beginning of the sentence, in which location it only agrees with the subject in gender (while number is singular). Arabic Verbs in SVO order agree in gender and number. All the MT systems we compare leave the verb after the subject. The direct, Phrase Pivot+Conn+Morph Auto, and combination systems get the number and gender correctly; however, the direct and combined system make the verb tense past. The Phrase Pivot+Conn+Morph Auto example highlights the value of morphology constraints; but the example points out that they sometimes are hard to evaluate automatically, since there are morphosyntactically allowable forms that do not match the translation references."}, {"heading": "8 Conclusion and Future Work", "text": "In this paper, we presented the use of synchronous morphology constraint features based on hand-crafted rules compared to rules induced from parallel data to improve the quality of phrase-pivot based SMT. We show that the two approaches lead to an improvement in the translation quality. The induced morphology constraints approach is a better performer, however, it relies on the fact there is a parallel corpus between source and target languages. We show positive results on Hebrew-Arabic SMT. We get 1.5 BLEU points over phrase-pivot baseline and 0.8 BLEU points over system combination baseline with direct model built from given parallel data.\nIn the future, we plan to work on reranking experiments as a post-translation step based on morphosyntactic information between source and target languages. We also plan to work on word reordering between morphologically rich language to maintain the relationship between the word order and the morphosyntactic agreement in the context of phrase pivoting."}, {"heading": "Acknowledgments", "text": "The work presented in this paper was possible thanks to a generous Google Research Award. We would like to thank Reshef Shilon and Shuly Winter for helpful discussions and support with processing Hebrew. We also thank the anonymous reviewers for their insightful comments."}, {"heading": "In Proceedings of the 9th Annual Conference of the International Speech Communication Association", "text": "(INTERSPEECH\u20192008), pages 2731\u20132734, Brisbane, Australia.\nKhalilov, M., Costa-jussa\u0301, M. R., Fonollosa, J. A. R., Banchs, R. E., Chen, B., Zhang, M., Aw, A., Li, H., Marin\u0303o, J. B., Herna\u0301ndez, A., and Q., C. A. H. (2008). The talp & i2r smt systems for iwslt 2008. In International Workshop on Spoken Language Translation. IWSLT 2008, pg. 116\u2013123.\nKoehn, P., Birch, A., and Steinberger, R. (2009). 462 machine translation systems for europe. Proceedings of MT Summit XII, pages 65\u201372.\nKoehn, P. and Hoang, H. (2007). Factored translation models. In EMNLP-CoNLL, pages 868\u2013876.\nKoehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., Cowan, B., Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., and Herbst, E. (2007). Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177\u2013180, Prague, Czech Republic.\nKoehn, P. and Schroeder, J. (2007). Experiments in domain adaptation for statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 224\u2013227. Association for Computational Linguistics.\nLavie, A., Probst, K., Peterson, E., Vogel, S., Levin, L., Font-Llitjos, A., and Carbonell, J. (2004). A trainable transfer-based machine translation approach for languages with limited resources. In Proceedings of European Association for Machine Translation Workshop on Broadening horizons of machine translation and its applications, Malta.\nMaamouri, M., Bies, A., Buckwalter, T., and Mekki, W. (2004). The Penn Arabic Treebank: Building a Large-Scale Annotated Arabic Corpus. In NEMLAR Conference on Arabic Language Resources and Tools, pages 102\u2013109, Cairo, Egypt.\nMiura, A., Neubig, G., Sakti, S., Toda, T., and Nakamura, S. (2015). Improving pivot translation by remembering the pivot. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 573\u2013577, Beijing, China. Association for Computational Linguistics.\nOch, F. J. (2003). Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 160\u2013167. Association for Computational Linguistics.\nOch, F. J. and Ney, H. (2003). A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29(1):19\u201352.\nPapineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002). BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311\u2013318, Philadelphia, PA.\nShilon, R., Habash, N., Lavie, A., and Wintner, S. (2010). Machine translation between hebrew and arabic: Needs, challenges and preliminary solutions. In Proceedings of AMTA.\nShilon, R., Habash, N., Lavie, A., and Wintner, S. (2012). Machine translation between Hebrew and Arabic. Machine Translation, 26:177\u2013195.\nSingh, N. and Habash, N. (2012). Hebrew morphological preprocessing for statistical machine translation. In 16th annual conference of the European Association for Machine Translation (EAMT), Trento, Italy.\nStolcke, A. (2002). SRILM - an Extensible Language Modeling Toolkit. In Proceedings of the International Conference on Spoken Language Processing (ICSLP), volume 2, pages 901\u2013904, Denver, CO.\nTsvetkov, Y. and Wintner, S. (2010). Automatic acquisition of parallel corpora from websites with dynamic content. In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC\u201910), pages 3389\u20133392.\nUtiyama, M. and Isahara, H. (2007). A comparison of pivot methods for phrase-based statistical machine translation. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 484\u2013491, Rochester, New York. Association for Computational Linguistics.\nWu, H. and Wang, H. (2009). Revisiting pivot language approach for machine translation. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 154\u2013162, Suntec, Singapore. Association for Computational Linguistics.\nYeniterzi, R. and Oflazer, K. (2010). Syntax-to-morphology mapping in factored phrase-based statistical machine translation from english to turkish. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 454\u2013464, Uppsala, Sweden. Association for Computational Linguistics."}], "references": [{"title": "Hebrew morphological disambiguation: An unsupervised stochastic word-based approach. PhD thesis, Ben-Gurion University of the Negev", "author": ["M.M. Adler"], "venue": null, "citeRegEx": "Adler,? \\Q2007\\E", "shortCiteRegEx": "Adler", "year": 2007}, {"title": "Phrase-based statistical machine translation with pivot languages", "author": ["N. Bertoldi", "M. Barbaiani", "M. Federico", "R. Cattoni"], "venue": "Proceeding of IWSLT,", "citeRegEx": "Bertoldi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bertoldi et al\\.", "year": 2008}, {"title": "Wit: Web inventory of transcribed and translated talks", "author": ["M. Cettolo", "C. Girardi", "M. Federico"], "venue": "In Proceedings of the 16 Conference of the European Association for Machine Translation (EAMT),", "citeRegEx": "Cettolo et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cettolo et al\\.", "year": 2012}, {"title": "Machine translation by triangulation: Making effective use of multiparallel corpora", "author": ["T. Cohn", "M. Lapata"], "venue": "In ANNUAL MEETING-ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,", "citeRegEx": "Cohn and Lapata,? \\Q2007\\E", "shortCiteRegEx": "Cohn and Lapata", "year": 2007}, {"title": "Orthographic and Morphological Processing for English-Arabic Statistical Machine Translation", "author": ["A. El Kholy", "N. Habash"], "venue": "In Proceedings of Traitement Automatique du Langage Naturel (TALN10). Montre\u0301al, Canada", "citeRegEx": "Kholy and Habash,? \\Q2010\\E", "shortCiteRegEx": "Kholy and Habash", "year": 2010}, {"title": "Techniques for Arabic Morphological Detokenization and Orthographic Denormalization", "author": ["A. El Kholy", "N. Habash"], "venue": "In Proceedings of the seventh International Conference on Language Resources and Evaluation (LREC),", "citeRegEx": "Kholy and Habash,? \\Q2010\\E", "shortCiteRegEx": "Kholy and Habash", "year": 2010}, {"title": "Automatic Error Analysis for Morphologically Rich Languages", "author": ["A. El Kholy", "N. Habash"], "venue": "In MT Summit XIII", "citeRegEx": "Kholy and Habash,? \\Q2011\\E", "shortCiteRegEx": "Kholy and Habash", "year": 2011}, {"title": "Alignment symmetrization optimization targeting phrase pivot statistical machine translation", "author": ["A. El Kholy", "N. Habash"], "venue": "In Proceedings of the 17th annual conference of the European Association for Machine Translation,", "citeRegEx": "Kholy and Habash,? \\Q2014\\E", "shortCiteRegEx": "Kholy and Habash", "year": 2014}, {"title": "Language independent connectivity strength features for phrase pivot statistical machine translation", "author": ["A. El Kholy", "N. Habash", "G. Leusch", "E. Matusov", "H. Sawaf"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),", "citeRegEx": "Kholy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kholy et al\\.", "year": 2013}, {"title": "Syntactic Reordering for English-Arabic Phrase-Based Machine Translation", "author": ["J. Elming", "N. Habash"], "venue": "In Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages,", "citeRegEx": "Elming and Habash,? \\Q2009\\E", "shortCiteRegEx": "Elming and Habash", "year": 2009}, {"title": "Arabic Gigaword 3, LDC Catalog No.: LDC2003T40. Linguistic Data Consortium, University of Pennsylvania", "author": ["D. Graff"], "venue": null, "citeRegEx": "Graff,? \\Q2007\\E", "shortCiteRegEx": "Graff", "year": 2007}, {"title": "Introduction to Arabic Natural Language Processing", "author": ["N. Habash"], "venue": null, "citeRegEx": "Habash,? \\Q2010\\E", "shortCiteRegEx": "Habash", "year": 2010}, {"title": "Improving Arabic-Chinese Statistical Machine Translation using English as Pivot Language", "author": ["N. Habash", "J. Hu"], "venue": "In Proceedings of the Fourth Workshop on Statistical Machine Translation,", "citeRegEx": "Habash and Hu,? \\Q2009\\E", "shortCiteRegEx": "Habash and Hu", "year": 2009}, {"title": "Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop", "author": ["N. Habash", "O. Rambow"], "venue": "In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Habash and Rambow,? \\Q2005\\E", "shortCiteRegEx": "Habash and Rambow", "year": 2005}, {"title": "MADA+TOKAN: A toolkit for Arabic tokenization, diacritization, morphological disambiguation, POS tagging, stemming and lemmatization", "author": ["N. Habash", "O. Rambow", "R. Roth"], "venue": "Proceedings of the Second International Conference on Arabic Language Resources and Tools. The MEDAR Consortium", "citeRegEx": "Habash et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Habash et al\\.", "year": 2009}, {"title": "Arabic Preprocessing Schemes for Statistical Machine Translation", "author": ["N. Habash", "F. Sadat"], "venue": "In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers,", "citeRegEx": "Habash and Sadat,? \\Q2006\\E", "shortCiteRegEx": "Habash and Sadat", "year": 2006}, {"title": "On Arabic Transliteration", "author": ["N. Habash", "A. Soudi", "T. Buckwalter"], "venue": null, "citeRegEx": "Habash et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Habash et al\\.", "year": 2007}, {"title": "Machine Translation of Very Close Languages", "author": ["J. Haji\u010d", "J. Hric", "V. Kubon"], "venue": "In Proceedings of the 6th Applied Natural Language Processing Conference", "citeRegEx": "Haji\u010d et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Haji\u010d et al\\.", "year": 2000}, {"title": "Learning reordering models for statistical machine translation with a pivot language", "author": ["C. Henriquez", "R.E. Banchs", "J.B. Mari\u00f1o"], "venue": null, "citeRegEx": "Henriquez et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Henriquez et al\\.", "year": 2010}, {"title": "Language resources for Hebrew", "author": ["A. Itai", "S. Wintner"], "venue": "Language Resources and Evaluation,", "citeRegEx": "Itai and Wintner,? \\Q2008\\E", "shortCiteRegEx": "Itai and Wintner", "year": 2008}, {"title": "Strategies for building a Farsi-English smt system from limited resources", "author": ["A. Kathol", "J. Zheng"], "venue": "In Proceedings of the 9th Annual Conference of the International Speech Communication Association", "citeRegEx": "Kathol and Zheng,? \\Q2008\\E", "shortCiteRegEx": "Kathol and Zheng", "year": 2008}, {"title": "The talp & i2r smt systems for iwslt", "author": ["M. Khalilov", "M.R. Costa-juss\u00e1", "J.A.R. Fonollosa", "R.E. Banchs", "B. Chen", "M. Zhang", "A. Aw", "H. Li", "J.B. Mari\u00f1o", "A. Hern\u00e1ndez", "C.A. H"], "venue": "In International Workshop on Spoken Language Translation. IWSLT", "citeRegEx": "Khalilov et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Khalilov et al\\.", "year": 2008}, {"title": "462 machine translation systems for europe", "author": ["P. Koehn", "A. Birch", "R. Steinberger"], "venue": "Proceedings of MT Summit XII,", "citeRegEx": "Koehn et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2009}, {"title": "Factored translation models", "author": ["P. Koehn", "H. Hoang"], "venue": "In EMNLP-CoNLL,", "citeRegEx": "Koehn and Hoang,? \\Q2007\\E", "shortCiteRegEx": "Koehn and Hoang", "year": 2007}, {"title": "Moses: open source toolkit for statistical machine translation", "author": ["P. Koehn", "H. Hoang", "A. Birch", "C. Callison-Burch", "M. Federico", "N. Bertoldi", "B. Cowan", "W. Shen", "C. Moran", "R. Zens", "C. Dyer", "O. Bojar", "A. Constantin", "E. Herbst"], "venue": "In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,", "citeRegEx": "Koehn et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2007}, {"title": "Experiments in domain adaptation for statistical machine translation", "author": ["P. Koehn", "J. Schroeder"], "venue": "In Proceedings of the Second Workshop on Statistical Machine Translation,", "citeRegEx": "Koehn and Schroeder,? \\Q2007\\E", "shortCiteRegEx": "Koehn and Schroeder", "year": 2007}, {"title": "A trainable transfer-based machine translation approach for languages with limited resources. In Proceedings of European Association for Machine Translation Workshop on Broadening horizons of machine translation and its applications, Malta", "author": ["A. Lavie", "K. Probst", "E. Peterson", "S. Vogel", "L. Levin", "A. Font-Llitjos", "J. Carbonell"], "venue": null, "citeRegEx": "Lavie et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lavie et al\\.", "year": 2004}, {"title": "The Penn Arabic Treebank: Building a Large-Scale Annotated Arabic Corpus", "author": ["M. Maamouri", "A. Bies", "T. Buckwalter", "W. Mekki"], "venue": "In NEMLAR Conference on Arabic Language Resources and Tools,", "citeRegEx": "Maamouri et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Maamouri et al\\.", "year": 2004}, {"title": "Improving pivot translation by remembering the pivot", "author": ["A. Miura", "G. Neubig", "S. Sakti", "T. Toda", "S. Nakamura"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),", "citeRegEx": "Miura et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Miura et al\\.", "year": 2015}, {"title": "Minimum error rate training in statistical machine translation", "author": ["F.J. Och"], "venue": "In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume", "citeRegEx": "Och,? \\Q2003\\E", "shortCiteRegEx": "Och", "year": 2003}, {"title": "A Systematic Comparison of Various Statistical Alignment Models", "author": ["F.J. Och", "H. Ney"], "venue": "Computational Linguistics,", "citeRegEx": "Och and Ney,? \\Q2003\\E", "shortCiteRegEx": "Och and Ney", "year": 2003}, {"title": "BLEU: a Method for Automatic Evaluation of Machine Translation", "author": ["K. Papineni", "S. Roukos", "T. Ward", "Zhu", "W.-J"], "venue": "In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Machine translation between hebrew and arabic: Needs, challenges and preliminary solutions", "author": ["R. Shilon", "N. Habash", "A. Lavie", "S. Wintner"], "venue": "In Proceedings of AMTA", "citeRegEx": "Shilon et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Shilon et al\\.", "year": 2010}, {"title": "Machine translation between Hebrew and Arabic", "author": ["R. Shilon", "N. Habash", "A. Lavie", "S. Wintner"], "venue": "Machine Translation,", "citeRegEx": "Shilon et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Shilon et al\\.", "year": 2012}, {"title": "Hebrew morphological preprocessing for statistical machine translation. In 16th annual conference of the European Association for Machine Translation (EAMT), Trento, Italy", "author": ["N. Singh", "N. Habash"], "venue": null, "citeRegEx": "Singh and Habash,? \\Q2012\\E", "shortCiteRegEx": "Singh and Habash", "year": 2012}, {"title": "SRILM - an Extensible Language Modeling Toolkit", "author": ["A. Stolcke"], "venue": "In Proceedings of the International Conference on Spoken Language Processing (ICSLP),", "citeRegEx": "Stolcke,? \\Q2002\\E", "shortCiteRegEx": "Stolcke", "year": 2002}, {"title": "Automatic acquisition of parallel corpora from websites with dynamic content", "author": ["Y. Tsvetkov", "S. Wintner"], "venue": "In Proceedings of the Seventh conference on International Language Resources and Evaluation", "citeRegEx": "Tsvetkov and Wintner,? \\Q2010\\E", "shortCiteRegEx": "Tsvetkov and Wintner", "year": 2010}, {"title": "A comparison of pivot methods for phrase-based statistical machine translation", "author": ["M. Utiyama", "H. Isahara"], "venue": "In Human Language Technologies", "citeRegEx": "Utiyama and Isahara,? \\Q2007\\E", "shortCiteRegEx": "Utiyama and Isahara", "year": 2007}, {"title": "Revisiting pivot language approach for machine translation", "author": ["H. Wu", "H. Wang"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,", "citeRegEx": "Wu and Wang,? \\Q2009\\E", "shortCiteRegEx": "Wu and Wang", "year": 2009}, {"title": "Syntax-to-morphology mapping in factored phrase-based statistical machine translation from english to turkish", "author": ["R. Yeniterzi", "K. Oflazer"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Yeniterzi and Oflazer,? \\Q2010\\E", "shortCiteRegEx": "Yeniterzi and Oflazer", "year": 2010}], "referenceMentions": [{"referenceID": 37, "context": "One of the best performing techniques, phrase pivoting (Utiyama and Isahara, 2007), builds an induced new phrase table between the source and target.", "startOffset": 55, "endOffset": 82}, {"referenceID": 37, "context": "Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009).", "startOffset": 113, "endOffset": 226}, {"referenceID": 38, "context": "Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009).", "startOffset": 113, "endOffset": 226}, {"referenceID": 21, "context": "Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009).", "startOffset": 113, "endOffset": 226}, {"referenceID": 1, "context": "Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009).", "startOffset": 113, "endOffset": 226}, {"referenceID": 12, "context": "Many researchers have investigated the use of pivoting (or bridging) approaches to solve the data scarcity issue (Utiyama and Isahara, 2007; Wu and Wang, 2009; Khalilov et al., 2008; Bertoldi et al., 2008; Habash and Hu, 2009).", "startOffset": 113, "endOffset": 226}, {"referenceID": 17, "context": "Pivoting has been explored for closely related languages (Haji\u010d et al., 2000) as well as unrelated languages (Koehn et al.", "startOffset": 57, "endOffset": 77}, {"referenceID": 22, "context": ", 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009).", "startOffset": 39, "endOffset": 80}, {"referenceID": 12, "context": ", 2000) as well as unrelated languages (Koehn et al., 2009; Habash and Hu, 2009).", "startOffset": 39, "endOffset": 80}, {"referenceID": 21, "context": "The first strategy is the sentence translation technique in which we first translate the source sentence to the pivot language, and then translate the pivot language sentence to the target language (Khalilov et al., 2008).", "startOffset": 198, "endOffset": 221}, {"referenceID": 37, "context": "The second strategy is based on phrase pivoting (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009).", "startOffset": 48, "endOffset": 117}, {"referenceID": 3, "context": "The second strategy is based on phrase pivoting (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009).", "startOffset": 48, "endOffset": 117}, {"referenceID": 38, "context": "The second strategy is based on phrase pivoting (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009).", "startOffset": 48, "endOffset": 117}, {"referenceID": 1, "context": "The third strategy is to create a synthetic source-target corpus by translating the pivot side of source-pivot corpus to the target language using an existing pivot-target model (Bertoldi et al., 2008).", "startOffset": 178, "endOffset": 201}, {"referenceID": 37, "context": "In this paper, we use the phrase pivoting approach, which has been shown to be the best with comparable settings (Utiyama and Isahara, 2007).", "startOffset": 113, "endOffset": 140}, {"referenceID": 28, "context": "Also, pivot LMs are used to assess the naturalness of the derivation (Miura et al., 2015).", "startOffset": 69, "endOffset": 89}, {"referenceID": 39, "context": "Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010; Habash and Sadat, 2006; Kathol and Zheng, 2008).", "startOffset": 165, "endOffset": 294}, {"referenceID": 9, "context": "Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010; Habash and Sadat, 2006; Kathol and Zheng, 2008).", "startOffset": 165, "endOffset": 294}, {"referenceID": 15, "context": "Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010; Habash and Sadat, 2006; Kathol and Zheng, 2008).", "startOffset": 165, "endOffset": 294}, {"referenceID": 20, "context": "Since both Hebrew and Arabic are morphologically rich, we should mention that there has been a lot of work on translation to and from morphologically rich languages (Yeniterzi and Oflazer, 2010; Elming and Habash, 2009; El Kholy and Habash, 2010; Habash and Sadat, 2006; Kathol and Zheng, 2008).", "startOffset": 165, "endOffset": 294}, {"referenceID": 36, "context": "Until recently, there has not been much parallel Hebrew-English and Hebrew-Arabic data (Tsvetkov and Wintner, 2010), and consequently little work on Hebrew-English and Hebrew-", "startOffset": 87, "endOffset": 115}, {"referenceID": 25, "context": "Lavie et al. (2004) built a transfer-based translation system for Hebrew-English and so did Shilon et al.", "startOffset": 0, "endOffset": 20}, {"referenceID": 25, "context": "Lavie et al. (2004) built a transfer-based translation system for Hebrew-English and so did Shilon et al. (2012) for translation between Hebrew and Arabic.", "startOffset": 0, "endOffset": 113}, {"referenceID": 24, "context": "Since our models are based on a Moses phrase-based SMT system (Koehn et al., 2007), we use the standard set of phrase-based translation probability distributions.", "startOffset": 62, "endOffset": 82}, {"referenceID": 22, "context": "Since our models are based on a Moses phrase-based SMT system (Koehn et al., 2007), we use the standard set of phrase-based translation probability distributions.1 We follow Utiyama and Isahara (2007) in computing the pivot phrase pair probabilities.", "startOffset": 63, "endOffset": 201}, {"referenceID": 18, "context": "We also build a Hebrew-Arabic reordering table using the same technique but we compute the reordering probabilities in a similar manner to Henriquez et al. (2010).", "startOffset": 139, "endOffset": 163}, {"referenceID": 8, "context": "2 We follow the work of El Kholy et al. (2013) and filter the phrase pairs used in pivoting based on log-linear scores.", "startOffset": 27, "endOffset": 47}, {"referenceID": 11, "context": "One aspect of Arabic\u2019s complexity is its various attachable clitics and numerous morphological features (Habash, 2010).", "startOffset": 104, "endOffset": 118}, {"referenceID": 11, "context": "This, together with Arabic\u2019s morphological richness, leads to a high degree of ambiguity: about 12 analyses per word, typically corresponding to two lemmas on average (Habash, 2010).", "startOffset": 167, "endOffset": 181}, {"referenceID": 27, "context": "We follow El Kholy and Habash (2010) and use the PATB tokenization scheme (Maamouri et al., 2004) in our experiments.", "startOffset": 74, "endOffset": 97}, {"referenceID": 13, "context": "1 (Habash and Rambow, 2005; Habash et al., 2009) to tokenize the Arabic text.", "startOffset": 2, "endOffset": 48}, {"referenceID": 14, "context": "1 (Habash and Rambow, 2005; Habash et al., 2009) to tokenize the Arabic text.", "startOffset": 2, "endOffset": 48}, {"referenceID": 19, "context": "Similar to Arabic, Hebrew poses computational processing challenges typical of Semitic languages (Itai and Wintner, 2008; Shilon et al., 2012).", "startOffset": 97, "endOffset": 142}, {"referenceID": 33, "context": "Similar to Arabic, Hebrew poses computational processing challenges typical of Semitic languages (Itai and Wintner, 2008; Shilon et al., 2012).", "startOffset": 97, "endOffset": 142}, {"referenceID": 0, "context": "We follow Singh and Habash (2012)\u2019s best preprocessing setup which utilized a Hebrew tagger (Adler, 2007) and produced a tokenization scheme that separated all clitics.", "startOffset": 92, "endOffset": 105}, {"referenceID": 3, "context": "We follow El Kholy and Habash (2010) and use the PATB tokenization scheme (Maamouri et al.", "startOffset": 13, "endOffset": 37}, {"referenceID": 3, "context": "We follow El Kholy and Habash (2010) and use the PATB tokenization scheme (Maamouri et al., 2004) in our experiments. The PATB scheme separates all clitics except for the determiner clitic Al+(DET). We use MADA v3.1 (Habash and Rambow, 2005; Habash et al., 2009) to tokenize the Arabic text. We only evaluate on detokenized and orthographically correct (enriched) output following the work of El Kholy and Habash (2010). Similar to Arabic, Hebrew poses computational processing challenges typical of Semitic languages (Itai and Wintner, 2008; Shilon et al.", "startOffset": 13, "endOffset": 420}, {"referenceID": 3, "context": "We follow El Kholy and Habash (2010) and use the PATB tokenization scheme (Maamouri et al., 2004) in our experiments. The PATB scheme separates all clitics except for the determiner clitic Al+(DET). We use MADA v3.1 (Habash and Rambow, 2005; Habash et al., 2009) to tokenize the Arabic text. We only evaluate on detokenized and orthographically correct (enriched) output following the work of El Kholy and Habash (2010). Similar to Arabic, Hebrew poses computational processing challenges typical of Semitic languages (Itai and Wintner, 2008; Shilon et al., 2012). Hebrew orthography also uses optional diacritics and its morphology inflects for gender, number, person, state, tense and definiteness. Furthermore, Similar to Arabic, Hebrew has a set of attachable clitics, e.g., conjunctions (such as + !\u05d5 w+4 \u2018and\u2019), prepositions (such as + !\u05d1 b+ \u2018in\u2019), the definite article (+ !\u05d4 h+ \u2018the\u2019), or pronouns (such as !\u05dd\u05d4+ +hm \u2018their\u2019). These issues contribute to a high degree of ambiguity that is a challenge to translation from Hebrew to English or to any other language. We follow Singh and Habash (2012)\u2019s best preprocessing setup which utilized a Hebrew tagger (Adler, 2007) and produced a tokenization scheme that separated all clitics.", "startOffset": 13, "endOffset": 1105}, {"referenceID": 16, "context": "3Arabic transliteration throughout the paper is presented in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007).", "startOffset": 96, "endOffset": 117}, {"referenceID": 23, "context": "Similar to factored translation models (Koehn and Hoang, 2007) where linguistic (morphology) features are augmented to the translation model to improve the translation quality, our approach to address the quality problem is based on constructing a list of synchronous morphology constraints between the source and target languages.", "startOffset": 39, "endOffset": 62}, {"referenceID": 4, "context": "We build on our approach in El Kholy et al. (2013) where we introduced connectivity strength features between the source and target phrase pairs in the pivot phrase table.", "startOffset": 31, "endOffset": 51}, {"referenceID": 14, "context": "5Please refer to (Habash et al., 2009) for a complete set of Arabic POS tag set and (Adler, 2007) for Hebrew POS tag set.", "startOffset": 17, "endOffset": 38}, {"referenceID": 0, "context": ", 2009) for a complete set of Arabic POS tag set and (Adler, 2007) for Hebrew POS tag set.", "startOffset": 53, "endOffset": 66}, {"referenceID": 25, "context": "If the same translation option (in terms of identical input phrase and output phrase) is found in multiple tables, separate translation options are created for each occurrence, but with different scores (Koehn and Schroeder, 2007).", "startOffset": 203, "endOffset": 230}, {"referenceID": 2, "context": "For the direct Hebrew-Arabic SMT model, we use a TED parallel corpus of about (\u2248 2M words) (Cettolo et al., 2012).", "startOffset": 91, "endOffset": 113}, {"referenceID": 30, "context": "Word alignment is done using GIZA++ (Och and Ney, 2003).", "startOffset": 36, "endOffset": 55}, {"referenceID": 10, "context": "For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data.", "startOffset": 80, "endOffset": 93}, {"referenceID": 35, "context": "We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002).", "startOffset": 81, "endOffset": 96}, {"referenceID": 24, "context": "All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007).", "startOffset": 70, "endOffset": 90}, {"referenceID": 29, "context": "We use MERT (Och, 2003) for decoding weight optimization.", "startOffset": 12, "endOffset": 23}, {"referenceID": 31, "context": "We evaluate using BLEU-4 (Papineni et al., 2002).", "startOffset": 25, "endOffset": 48}, {"referenceID": 26, "context": "The Hebrew-English corpus is about (\u2248 1M words) and is available from sentence-aligned corpus produced by Tsvetkov and Wintner (2010). For the direct Hebrew-Arabic SMT model, we use a TED parallel corpus of about (\u2248 2M words) (Cettolo et al.", "startOffset": 106, "endOffset": 134}, {"referenceID": 2, "context": "For the direct Hebrew-Arabic SMT model, we use a TED parallel corpus of about (\u2248 2M words) (Cettolo et al., 2012). Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight optimization. Weights are optimized using a tuning set of 517 sentences developed by Shilon et al. (2010). We use a maximum phrase length of size 8 across all models.", "startOffset": 92, "endOffset": 658}, {"referenceID": 2, "context": "For the direct Hebrew-Arabic SMT model, we use a TED parallel corpus of about (\u2248 2M words) (Cettolo et al., 2012). Word alignment is done using GIZA++ (Och and Ney, 2003). For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus (Graff, 2007) together with the Arabic side of our training data. We use 5-grams for all language models (LMs) implemented using the SRILM toolkit (Stolcke, 2002). All experiments are conducted using the Moses phrase-based SMT system (Koehn et al., 2007). We use MERT (Och, 2003) for decoding weight optimization. Weights are optimized using a tuning set of 517 sentences developed by Shilon et al. (2010). We use a maximum phrase length of size 8 across all models. We report results on a Hebrew-Arabic development set (Dev) of 500 sentence with a single reference and an evaluation set (Test) of 300 sentences with three references developed by Shilon et al. (2010). We evaluate using BLEU-4 (Papineni et al.", "startOffset": 92, "endOffset": 920}], "year": 2016, "abstractText": "The lack of parallel data for many language pairs is an important challenge to statistical machine translation (SMT). One common solution is to pivot through a third language for which there exist parallel corpora with the source and target languages. Although pivoting is a robust technique, it introduces some low quality translations especially when a poor morphology language is used as the pivot between rich morphology languages. In this paper, we examine the use of synchronous morphology constraint features to improve the quality of phrase pivot SMT. We compare hand-crafted constraints to those learned from limited parallel data between source and target languages. The learned morphology constraints are based on projected alignments between the source and target phrases in the pivot phrase table. We show positive results on Hebrew-Arabic SMT (pivoting on English). We get 1.5 BLEU points over a phrase pivot baseline and 0.8 BLEU points over a system combination baseline with a direct model built from parallel data.", "creator": "LaTeX with hyperref package"}}}