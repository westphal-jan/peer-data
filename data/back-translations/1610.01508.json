{"id": "1610.01508", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Oct-2016", "title": "VoxML: A Visualization Modeling Language", "abstract": "We present the specification of a modeling language, VoxML, which encodes semantic knowledge of real objects represented as three-dimensional models, as well as events and attributes related to these objects. VoxML aims to overcome the limitations of existing 3D visual markup languages by enabling the encoding of a wide range of semantic knowledge that can be used by a variety of systems and platforms, leading to multimodal simulations of real scenarios using conceptual objects that represent their semantic values.", "histories": [["v1", "Wed, 5 Oct 2016 16:27:48 GMT  (2904kb,D)", "http://arxiv.org/abs/1610.01508v1", "8 pages, 9 figures, proceedings of LREC 2016"]], "COMMENTS": "8 pages, 9 figures, proceedings of LREC 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["james pustejovsky", "nikhil krishnaswamy"], "accepted": false, "id": "1610.01508"}, "pdf": {"name": "1610.01508.pdf", "metadata": {"source": "CRF", "title": "VoxML: A Visualization Modeling Language", "authors": ["James Pustejovsky", "Nikhil Krishnaswamy"], "emails": ["jamesp@cs.brandeis.edu", "nkrishna@cs.brandeis.edu"], "sections": [{"heading": null, "text": "Keywords: Semantics, Cognitive Methods, Simulation, Lexical Semantics, Visualization"}, {"heading": "1. Introduction", "text": "In this paper, we describe a modeling language for constructing 3D visualizations of concepts denoted by natural language expressions. This language, VoxML (Visual Object Concept Modeling Language), is being used as the platform for creating multimodal semantic simulations in the context of human-computer communication.1 Prior work in visualization from natural language has largely focused on object placement and orientation in static scenes (Coyne and Sproat, 2001; Siskind, 2001; Chang et al., 2015), and we have endeavored to incorporate dynamic semantics and motion language into our model. In previous work (Pustejovsky and Krishnaswamy, 2014; Pustejovsky, 2013), we introduced a method for modeling natural language expressions within a 3D simulation environment built on top of the game development platform Unity (Goldstone, 2009). The goal of that work was to evaluate, through explicit visualizations of linguistic input, the semantic presuppositions inherent in the different lexical choices of an utterance. This work led to two additional lines of research: an explicit encoding for how an object is itself situated relative to its environment; and an operational characterization of how an object changes its location or how an agent acts on an object over time. The former has developed into a semantic notion of situational context, called a habitat (Pustejovsky, 2013; McDonald and Pustejovsky, 2014), while the latter is addressed by dynamic interpretations of event structure (Pustejovsky and Moszkowicz, 2011; Pustejovsky, 2013). The requirements on a visual simulation include, but are not limited to, the following components:\n1. A minimal embedding space (MES) for the simulation must be determined. This is the 3D region within which the state is configured or the event unfolds;\n2. Object-based attributes for participants in a situation or event need to be specified; e.g., orientation, relative size, default position or pose, etc.;\n1This work is being carried out in the context of CwC, a DARPA effort to identify and construct computational semantic elements, for the purpose of carrying out joint plans between a human and computer through NL discourse.\n3. An epistemic condition on the object and event rendering, imposing an implicit point of view (POV);\n4. Agent-dependent embodiment; this determines the relative scaling of an agent and its event participants and their surroundings, as it engages in the environment.\nIn order to construct a robust simulation from linguistic input, an event and its participants must be embedded within an appropriate minimal embedding space. This must sufficiently enclose the event localization, while optionally including space enough for a frame of reference for the event (the viewer\u2019s perspective). We return to this issue later in the paper when constructing our simulation from the semantic interpretation associated with motion events. Existing representation languages for 3D modeling, such as VRML (Parisi and Pesce, 1994), (Carson et al., 1999) or X3D (Brutzman and Daly, 2010), adequately represent the vertices, edges, faces, and UV texture mapping that make up the model itself, but contain no information about how such an object interacts with other objects in a real or simulated environment. Such information is represented on an ad hoc basis for the needs of the particular platform or environment in which the model will be deployed. Our goal in developing VoxML is twofold: to specify a language for both designing and representing data structures that generate simulations of linguistically represented objects, properties, and events. Just as the lexical items in a language are specified and encoded with a richly typed framework, such as Generative Lexicon, most lexemes will have a representation within VoxML that encodes an interpretation of the word\u2019s semantic content as a visualization. We have followed a strict methodology of specification development, as adopted by ISO TC37/SC4 and outlined in (Bunt, 2010) and (Ide and Romary, 2004), and as implemented with the development of ISO-TimeML (Pustejovsky et al., 2005; Pustejovsky et al., 2010) and others in the family of SemAF standards. Further, our work shares many of the goals pursued in (Dobnik et al., 2013; Dobnik and Cooper, 2013), for specifying a rigidly-defined type system for spatial representations associated with linguistic expressions. ar X iv :1 61 0. 01 50 8v 1 [ cs .C L\n] 5\nO ct\n2 01\n6\nIn this paper, we describe a specification language for modeling \u201cvisual object concepts\u201d, VoxML. The object defined within VoxML will be called a voxeme, and the library of voxemes, a voxicon."}, {"heading": "2. Habitats and Affordances", "text": "Before we introduce the VoxML specification, we review our assumptions regarding the semantics underlying the model. Following Generative Lexicon (GL) (Pustejovsky, 1995), lexical entries in the object language are given a feature structure consisting of a word\u2019s basic type, its parameter listing, its event typing, and its qualia structure. The semantics of an object will consist of the following:\n(1) a. Atomic Structure (FORMAL): objects expressed as basic nominal types b. Subatomic Structure (CONST): mereotopological structure of objects c. Event Structure (TELIC and AGENTIVE): origin and functions associated with an object d. Macro Object Structure: how objects fit together in space and through coordinated activities.\nObjects can be partially contextualized through their qualia structure: a food item has a TELIC value of eat, an instrument for writing, a TELIC of write, a cup, a TELIC of hold, and so forth. For example, the lexical semantics for the noun chair carries a TELIC value of sit in:\n(2) \u03bbx\u2203y   chair AS = [ ARG1 = x : e ]\nQS =  \nF = phys(x) T = \u03bbz, e[sit in(e, z, x)]\n \n \nWhile an artifact is designed for a specific purpose (its TELIC role), this can only be achieved under specific circumstances. (Pustejovsky, 2013) introduces the notion of an object\u2019s habitat, which encodes these circumstances. Assume that, for an artifact, x, given the appropriate context C, performing the action \u03c0 will result in the intended or desired resulting state, R, i.e., C \u2192 [\u03c0]R. That is, if a context C (a set of contextual factors) is satisfied, then every time the activity of \u03c0 is performed, the resulting state R will occur. The precondition context C is necessary to specify, since this enables the local modality to be satisfied. Using this notion, we define a habitat as a representation of an object situated within a partial minimal model; it is a directed enhancement of the qualia structure. Multidimensional affordances determine how habitats are deployed and how they modify or augment the context, and compositional operations include procedural (simulation) and operational (selection, specification, refinement) knowledge. The habitat for an object is built by first placing it within an embedding space and then contextualizing it. For example, in order to use a table, the top has to be oriented upward, the surface must be accessible, and so on. A chair must also be oriented up, the seat must be free and accessible, it must be able to support the user, etc. An illustration of\nwhat the resulting knowledge structure for the habitat of a chair is shown below.\n\u03bbx   chairhab\nF = [phys(x), on(x, y1), in(x, y2), orient(x, up)] C = [seat(x1), back(x2), legs(x3), clear(x1)] T = \u03bbz\u03bbe[C \u2192 [sit(e, z, x)]Rsit(x)] A = [made(e\u2032, w, x)]\n \nAs described in more detail below, event simulations are constructed from the composition of object habitats, along with particular constraints imposed by the dynamic event structure inherent in the verb itself, when interpreted as a program. The final step in contextualizing the semantics of an object is to operationalize the TELIC value in its habitat. This effectively is to identify the affordance structure for the object (Gibson, 1977; Gibson, 1979). The affordance structure available to an agent, when presented with an object, is the set of actions that can be performed with it. We refer to these as GIBSONIAN affordances, and they include \u201cgrasp\u201d, \u201cmove\u201d, \u201chold\u201d, \u201cturn\u201d, etc. This is to distinguish them from more goal-directed, intentionally situated activities, what we call TELIC affordances."}, {"heading": "3. The VoxML Specification", "text": ""}, {"heading": "3.1. VoxML Elements", "text": "Entities modeled in VoxML can be objects, programs, or logical types. Objects are logical constants; programs are nary predicates that can take objects or other evaluated predicates as arguments; logical types can be divided into attributes, relations, and functions, all predicates which take objects as arguments. Attributes and relations evaluate to states, and functions evaluate to geometric regions. These entities can then compose into visualizations of natural language concepts and expressions."}, {"heading": "3.2. Objects", "text": "The VoxML OBJECT is used for modeling nouns. The current set of OBJECT attributes is shown below:\nLEX OBJECT\u2019s lexical information TYPE OBJECT\u2019s geometrical typing HABITAT OBJECT\u2019s habitat for actions AFFORD STR OBJECT\u2019s affordance structure EMBODIMENT OBJECT\u2019s agent-relative embodiment\nThe LEX attribute contains the subcomponents PRED, the predicate lexeme denoting the object, and TYPE, the object\u2019s type according to Generative Lexicon. The TYPE attribute (different from LEX\u2019s TYPE subcomponent) contains information to define the object geometry in terms of primitives. HEAD is a primitive 3D shape that roughly describes the object\u2019s form (such as calling an apple an \u201cellipsoid\u201d), or the form of the object\u2019s most semantically salient subpart. We ground our possible values for HEAD in, for completeness, mathematical formalism defining families of polyhedra (Gru\u0308nbaum, 2003), and, for annotator\u2019s ease, common primitives found across\nthe \u201ccorpus\u201d of 3D artwork and 3D modeling software2 (Giambruno, 2002). Using common 3D modeling primitives as convenience definitions provides some built-in redundancy to VoxML, as is found in NL description of structural forms. For example, a rectangular prism is the same as a parallelepiped that has at least two defined planes of reflectional symmetry, meaning that an object whose HEAD is rectangular prism could be defined two ways, an association which a reasoner can unify axiomatically. Possible values for HEAD are given below:\nHEAD prismatoid, pyramid, wedge, parallelepiped, cupola, frustum, cylindroid, ellipsoid, hemiellipsoid, bipyramid, rectangular prism, toroid, sheet\nIt should be emphasized that these values are not intended to reflect the exact structure of a particular geometry, but rather a cognitive approximation of its shape, as is used in some image-recognition work (Goebel and Vincze, 2007). Object subparts are enumerated in COMPONENTS. CONCAVITY can be concave, flat, or convex and refers to any concavity that deforms the HEAD shape. ROTATSYM, or rotational symmetry, defines any of the world\u2019s three orthogonal axes around which the object\u2019s geometry may be rotated for an interval of less than 360 degrees and retain identical form as the unrotated geometry. A sphere may be rotated at any interval around any of the three axes and retain the same form. A rectangular prism may be rotated 180 degrees around any of the three axes and retain the same shape. An object such as a ceiling fan would only have rotational symmetry around the Y axis. Reflectional symmetry, or REFLECTSYM, is defined similarly. If an object may be bisected by a plane defined by two of the world\u2019s three orthogonal axes and then reflected across that plane to obtain the same geometric form as the original object, it is considered to have reflectional symmetry across that plane. A sphere or rectangular prism has reflectional symmetry across the XY, XZ, and YZ planes. A wine bottle only has reflectional symmetry across the XY and YZ planes. The possible values of ROTATSYM and REFLECTSYM are intended to be world-relative, not object-relative. That is, because we are only discussing objects when situated in a minimal embedding space (even an otherwise empty one) wherein all coordinates are given Cartesian values, the axis of rotational symmetry or plane of reflectional symmetry are those denoted in the world, not of the object. Thus, a tetrahedron\u2014which in isolation has seven axes of rotational symmetry, no two of which are orthogonal\u2014when placed in the MES such that it cognitively satisfies all \u201creal-world\u201d constraints, must be situated with one base downward (a tetrahedron placed any other way will fall over). Thus reducing the salient in-world axes of rotational symmetry to one: the world\u2019s Y-axis. When the orientation of the ob-\n2Mathematically curved surfaces such as spheres and cylinders are in fact represented, computed, and rendered as polyhedra by most modern 3D software.\nject is ambiguous relative to the world, the world should be assumed to provide the grounding value. The HABITAT element defines habitats INTRINSIC to the object, regardless of what action it participates in, such as intrinsic orientations or surfaces, as well as EXTRINSIC habitats which must be satisfied for particular actions to take place. We can define intrinsic faces of an object in terms of its geometry and axes. The model of a computer monitor, when axis-aligned according to 3D modeling convention, aligns the screen with the world\u2019s Z-axis facing the direction of increasing Z values. When discussing the object \u201ccomputer monitor,\u201d the lexeme \u201cfront\u201d singles out the screen of the monitor as opposed to any other part. We can therefore correlate the lexeme with the geometrical representation by establishing an intrinsic habitat of the computer monitor of front(+Z). We adopt the terminology of \u201calignment\u201d of an object dimension, d \u2208 {x, y, z}, with the dimension, d\u2032, of its embedding space, Ed\u2032 , as follows: align(d, Ed\u2032). AFFORD STR describes the set of specific actions, along with the requisite conditions, that the object may take part in. There are low-level affordances, called GIBSONIAN, which involve manipulation or maneuver-based actions (grasping, holding, lifting, touching); there are also TELIC affordances (Pustejovsky, 1995), which link directly to what goal-directed activity can be accomplished, by means of the GIBSONIAN affordances. EMBODIMENT qualitatively describes the SCALE of the object compared to an in-world agent (typically assumed to be a human) as well as whether the object is typically MOVABLE by that agent."}, {"heading": "3.3. Programs", "text": "PROGRAM is used for modeling verbs. The current set of PROGRAM attributes is shown below:\nLEX PROGRAM\u2019s lexical information TYPE PROGRAM\u2019s event typing EMBEDDING SPACE PROGRAM\u2019s embedding space as a\nfunction of the participants and their changes over time\nJust like OBJECTs, a PROGRAM\u2019s LEX attribute contains the subcomponents PRED, the predicate lexeme denoting the program, and TYPE, the program\u2019s type as given in a lexical semantic resource, e.g., its GL type. TYPE contains the HEAD, its base form; ARGS, reference to the participants; and BODY, any subevents that are executed in the course of the program\u2019s operation. Top-level values for a PROGRAM\u2019s HEAD are given below:\nHEAD state, process, transition assignment, test\nThe type of a program as shown above is given in terms of how the visualization of the action is realized. Basic program distinctions, such as test versus assignment are included within this typology and further distinguished through subtyping."}, {"heading": "3.4. Logical Types", "text": "Like OBJECTs and PROGRAMS, all functional type classes contain a LEX attribute and a PRED parameter that denote the lexeme related to the VoxML representation. The distinction between ATTRIBUTEs, RELATIONs, and FUNCTIONs lies mainly in differences in their TYPE structure, discussed in each subsection below."}, {"heading": "3.4.1. Attributes", "text": "Adjectival modification and predication involve reference to an ATTRIBUTE in our model, along with a specific value for that attribute. Often, but not always, this attribute is associated with a family of other attributes, structured according to some set of constraints, which we call a SCALE. The least constrained association is a conventional sortal classification, and its associated attribute family is the set of pairwise disjoint and non-overlapping sortal descriptions (nonsuper types). Following (Stevens, 1946; Luce et al., 1990), we will call this classification a nominal scale, and it is the least restrictive scale domain over which we can predicate an individual. binary classifications are a two-state subset of this domain. When we impose more constraints on the values of an attribute, we arrive at more structured domains. For example, by introducing a partial ordering over values, we can have transitive closure, assuming all orderings are defined. This is called an ordinal scale. When fixed units of distance are imposed between the elements on the ordering, we arrive at an interval scale. Finally, when a zero value is introduced, we have a scalar structure called a ratio scale. In reality, of course, there are many more attribute categories than the four listed above, but the goal in VoxML is to use these types as the basis for an underlying cognitive classification for creating measurements from different attribute types. In other words, these scale types are models of cognitive strategies for structuring values for conceptual attributes associated with natural language expressions involving scalar values. VoxML encodes how attributes and the associated programs that change their values can be grouped into these scalar domains of measurement. As VoxML is intended to model visualizations of physical objects and programs, we should note here that we are only examining first-order attributes, and not those that require any subjective interpretation relative to their arguments (that is, VoxML is intended to model \u201cthe image is red\u201d but not \u201cthe image is depressing\u201d). Examples of different SCALE types follow:\nordinal DIMENSION big, little, large, small, long, short binary HARDNESS hard, soft nominal COLOR red, green, blue rational MASS 1kg, 2kg, etc. interval TEMPERATURE 0\u25e6C, 100\u25e6C, etc.\nVoxML also denotes an attribute\u2019s ARITY, or the relative of the attribute to the object it describes compared to other instances of the same object class. transitive attributes are considered to describe object qualities that require comparison to other object instances (e.g. the small cup vs.\nthe big cup), whereas intransitive attributes do not require that comparison (a red cup is not red compared to other cups; it is objectively red\u2014or its redness can be assessed quantitatively). Finally, every attribute must be realized as applying to an object, so attributes require an ARG, a variable representing said object and the typing thereof. This is denoted identically to the individual ARGS of VoxML PROGRAMs."}, {"heading": "3.4.2. Relations", "text": "A RELATION\u2019s type structure specifies a binary CLASS of the relation: configuration or force dynamic, describing the nature of the relation. These classes themselves have subvalues\u2014for configurational relations these are values from the region connection calculus (Randell et al., 1992). Also specified are the arguments participating in the relations. These, as above, are represented as typed variables."}, {"heading": "3.4.3. Functions", "text": "FUNCTIONs\u2019 typing structures take as ARG the OBJECT voxeme being computed over. REFERENT takes any subparameters of the ARG that are semantically salient to the function, such as the voxeme\u2019s HEAD. If unspecified, the entire voxeme should be assumed as the referent. MAPPING is set to a denotation of the type of transformation the function performs over the object, such as dimensionality reduction (notated as dimension(n):n-1 for a function that takes in an object of n dimensions and returns a region of n-1). Finally, ORIENTATION provides three values: SPACE, which notes if the function is performed in world space or object space; AXIS, which notes the primary axis and direction the function exploits; and ARITY, which returns transitive or intransitive based on the boolean value of a specified input variable (x[y]:intransitive denotes a function that returns intransitive if the value of y in x is true). Defintions of transitive and intransitive follow those for ATTRIBUTEs."}, {"heading": "4. Examples of Voxemes", "text": "In this section, we illustrate the representational capabilities of the specification by briefly presenting example voxeme entries from the current VoxML voxicon. VoxML OBJECT representations are intended to correspond with specific voxeme geometries, which are given below the markup example. In cases where a representation instance is given independently of a geometry, it should be assumed to denote a prototypical or \u201cdefault\u201d representation of the voxeme\u2019s associated lexeme. We explore the richness of the language in more detail in the long version of the paper."}, {"heading": "4.1. Objects", "text": "In this section, we illustrate the visual object concept modeling capabilities for objects by differentiating between properties of the object\u2019s type, habitat, afforfance structure, and how it is embodied. Consider the voxeme structures for wall and table.\n(3)   wall LEX =   PRED = wall TYPE = physobj   TYPE =   HEAD = rectangular prism COMPONENTS = nil CONCAVITY = flat ROTATSYM = {X,Y, Z} REFLECTSYM = {XY,XZ, Y Z}   HABITAT =   INTR =   UP = align(Y, EY ) FRONT = front(+Z) CONSTR = Z Y,Z X   EXTR = ...   AFFORD STR =   A1 = H1 \u2192 [E1]R A2 = ... A3 = ...   EMBODIMENT =   SCALE = >agent\nMOVABLE = false\n \n \nWhile walls and tables are both geometries that have habitats which are upwardly aligned, tables have a head geometry of sheet, which is a special case of rectangular prism where the Y dimension is significantly less than X or Z. This head is identified in the habitat as the top of the object, facing up.\n(4)   table LEX =   PRED = table TYPE = physobj   TYPE =   HEAD = sheet [1] COMPONENTS = surface [1], leg+ CONCAVITY = flat ROTATSYM = {Y } REFLECTSYM = {XY, Y Z}   HABITAT =   INTR =   UP = align(Y, EY ) TOP = top(+Y )   EXTR = ...   AFFORD STR =   A1 = H1 \u2192 [E1]R A2 = ... A3 = ...   EMBODIMENT =   SCALE = agent\nMOVABLE = true  \n \nNow consider the voxeme for plate. This illustrates how the habitat feeds into activating the affordance structure associated with the object. Namely, if the appropriate conditions are satisfied ([1]), then the telic affordance associated with a plate is activated; every putting of x on y results in y holding x.\n(5)   plate LEX =   PRED = plate TYPE = physobj   TYPE =   HEAD = sheet COMPONENTS = surface, base CONCAVITY = concave ROTATSYM = {Y } REFLECTSYM = {XY, Y Z}   HABITAT =   INTR = [1]   UP = align(Y, EY ) TOP = top(+Y )   EXTR = ...   AFFORD STR =   A1 = H[1]\u2192 [put(x, y)]hold(y, x) A2 = ... A3 = ...   EMBODIMENT =   SCALE = < agent\nMOVABLE = true  \n \n(6)   apple LEX =   PRED = apple TYPE = physobj   TYPE =   HEAD = ellipsoid [1] COMPONENTS = fruit [1], stem, leaf CONCAVITY = convex ROTATSYM = {Y } REFLECTSYM = {XY, Y Z}   HABITAT =   INTR = {} EXTR = ...   AFFORD STR =   A1 = H1 \u2192 [E1]R A2 = ... A3 = ...   EMBODIMENT =   SCALE = < agent\nMOVABLE = true  \n "}, {"heading": "4.2. Programs", "text": "Events are interpreted as programs, moving an object or changing an object property or relation from state to state, as described in more detail in the next section. Program structure derives largely from the lexical semantics of the verb in GL. However, the semantics of the predicative\nchange over the event structure is interpreted operationally. We illustrate this with two predicates as programs, slide and put.\n(7)   slide LEX =   PRED = slide TYPE = process   TYPE =   HEAD = process ARGS =   A1 = x:physobj A2 = y:physobj   BODY =   E1 = while(EC(x, y), move(x))      \n(8)   put LEX =   PRED = put TYPE = transition event   TYPE =   HEAD = transition ARGS =   A1 = x:agent A2 = y:physobj A3 = z:location   BODY =   E1 = grasp(x, y) E2 = [while( hold(x, y), move(x)] E3 = [at(y, z)\u2192 ungrasp(x, y)]      "}, {"heading": "4.3. Attributes", "text": "Unlike physical objects, which can be associated with specific geometries, attributes are abstract predications over distinct domains, and can only be simulated by application to an element of this domain. Below is an example of the nominal attributive interpretation of the adjective brown, and the ordinal attributive interpretation of small.\n(9)   brown LEX = [ PRED = brown ] TYPE =   SCALE = nominal ARITY = intransitive ARG = x:physobj    \n(10)   small LEX = [ PRED = small ] TYPE =   SCALE = ordinal ARITY = transitive ARG = x:physobj    "}, {"heading": "4.4. Relations", "text": "Spatial relations are propositional expressions, contributing configurational information about two or more objects in a state.\n(11)   touching LEX = [ PRED = is touching ] TYPE =   CLASS = config VALUE = EC ARGS =   A1 = x:3D A2 = y:3D A3 = ...      "}, {"heading": "4.5. Functions", "text": "Finally, we illustrate the semantics of spatial functions with top. This applies to an object of dimensionality n, returning an object of dimensionality n \u2212 1; the top of a cube is a plane; that of a rectangular sheet is a line; and the top of a line is a point.\n(12)   top LEX = [ PRED = top ] TYPE =   ARG = x:physobj REFERENT = x\u2192HEAD MAPPING = dimension(n):n-1 ORIENTATION =   SPACE = world AXIS = +Y ARITY = x\u2192HABITAT\u2192\nINTR[top(axis)]: intransitive\n     "}, {"heading": "5. Using VoxML for Simulation Modeling of Language", "text": "VoxML treats objects and events in terms of a dynamic event semantics, Dynamic Interval Temporal Logic (DITL) (Pustejovsky and Moszkowicz, 2011). The advantage of adopting a dynamic interpretation of events is that we can map linguistic expressions directly into simulations through an operational semantics (Miller and Charles, 1991; Miller and Johnson-Laird, 1976). Models of processes using updating typically make reference to the notion of a state transition (van Benthem, 1991; Harel, 1984). This is done by distinguishing between formulae, \u03c6, and programs, \u03c0. A formula is interpreted as a classical propositional expression, with assignment of a truth value in a specific model. For the present discussion, we represent the dynamics of actions in terms of Labeled Transition Systems (LTSs) (van Benthem, 1991).3 An LTS consists of a triple, \u3008S,Act,\u2192\u3009, where: S is the set of states; Act is a set of actions; and \u2192 is a total transition relation: \u2192\u2286 S \u00d7 Act \u00d7 S. An action, \u03b1 \u2208 Act, provides the labeling on an arrow, making it explicit what brings about a state-to-state transition. As a shorthand for (e1, \u03b1, e2) \u2208\u2192, we will also use e1 \u03b1\u2212\u2192 e2. Simulation generation begins by parsing a natural English sentence, currently using the ClearNLP parser (Choi and McCallum, 2013).4 The dependency parse is then transformed into a predicate-argument set representation using the root of the parse as the main predicate and its dependencies as arguments. Each predicate can have more than one argument and arguments may themselves be predicates (thus higher-order predicates are permissible). This\n3This is consistent with the approach developed in (Fernando, 2009; Fernando, 2013). This approach to a dynamic interpretation of change in language semantics is also inspired by Steedman (2002).\n4We are working toward integrating the lexical entries with a rule-based parser that provides for a compositionally derived interpretation of the sentence being parsed.\npredicate-argument set formula is then evaluated from the innermost first order predicates outward until a single firstorder representation is reached.\nput(apple,<1, 2.3, -0.8>)\nFigure 7: \u201con(plate)\u201d evaluates to coordinates\nThe evaluation of predicates entails the composition of the voxemes involved. Since we allow for program voxemes (verbs), logical type voxemes (relations, attributes, functions) and object voxemes (nominals), evaluation involves executing a snippet of code that operationalizes a program voxeme using the geometric and VoxML-encoded semantic information from the voxeme(s) indicated by the input predicate\u2019s argument(s). In the example given above, the predicate on(plate) is evaluated to a specific location that satisfies the constraint denoted by \u201con the plate\u201d, using information about the plate object, specifically its dimensions and concavity. The program put can then be realized as a DITL program that moves the object apple toward that location until the apple\u2019s location and the location evaluated for on(plate) are equal, and executed as a simple state transition \u00ac\u03c6\ne1 \u03b1\u2212\u2192 \u03c6 e2 . Given a 3D scene that contains voxemes for all nominals referred to in the text, the program can be operationalized in code and the state transition can be executed over the geometries visualized in 3D space. We use an updated version of the the simulator built for (Pustejovsky and Krishnaswamy, 2014) and the C# language to generate visualizations like that shown in Figure 9 below."}, {"heading": "6. Conclusion", "text": "In this paper we have outlined a specification to represent semantic knowledge of real-world objects represented as three-dimensional models. We use a combination of parameters that can be determined from the object\u2019s geometrical properties as well as lexical information from natural language, with methods of correlating the two where applicable. This information allows for the visualization and simulation software to fill in information missing from the natural language input and allows the software to render a\nfunctional visualization of programs being run over objects in a robust and extensible way. Currently we have a voxicon containing 500 object (noun) voxemes and 10 program (verb) voxemes. As our library of available voxemes continues to grow the specification elements may as well, allowing us to operationalize a larger library of various and more complicated programs, and to compose complex behaviors out of simpler ones. The voxeme library and visualization software will be deployed at http://www.voxicon.net. There users may find the current library of voxemes and conduct visualizations of available behaviors driven by VoxML after parsing and interpretation."}, {"heading": "7. Acknowledgements", "text": "This work was supported by Contract W911NF-15-C-0238 with the US Defense Advanced Research Projects Agency (DARPA) and the Army Research Office (ARO). Approved for Public Release, Distribution Unlimited. The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government. All errors and mistakes are, of course, the responsibilities of the authors."}, {"heading": "8. Bibliographical References", "text": "Brutzman, D. and Daly, L. (2010). X3D: extensible 3D\ngraphics for Web authors. Morgan Kaufmann. Bunt, H. (2010). A methodology for designing semantic\nannotation languages exploiting syntactic-semantic isomorphisms. In Proceedings of ICGL 2010, Second International Conference on Global Interoperability for Language Resources.\nCarson, G. S., Puk, R. F., and Carey, R. (1999). Developing the vrml 97 international standard. Computer Graphics and Applications, IEEE, 19(2):52\u201358.\nChang, A., Monroe, W., Savva, M., Potts, C., and Manning, C. D. (2015). Text to 3d scene generation with rich lexical grounding. arXiv preprint arXiv:1505.06289.\nChoi, J. D. and McCallum, A. (2013). Transition-based dependency parsing with selectional branching. In ACL (1), pages 1052\u20131062.\nCoyne, B. and Sproat, R. (2001). Wordseye: an automatic text-to-scene conversion system. In Proceedings of the 28th annual conference on Computer graphics and interactive techniques, pages 487\u2013496. ACM.\nDobnik, S. and Cooper, R. (2013). Spatial descriptions in type theory with records. In Proceedings of IWCS 2013 Workshop on Computational Models of Spatial Language Interpretation and Generation (CoSLI-3). Citeseer.\nDobnik, S., Cooper, R., and Larsson, S. (2013). Modelling language, action, and perception in type theory with records. In Constraint Solving and Language Processing, pages 70\u201391. Springer.\nFernando, T. (2009). Situations in ltl as strings. Information and Computation, 207(10):980\u2013999.\nFernando, T. (2013). Segmenting temporal intervals for tense and aspect. In The 13th Meeting on the Mathematics of Language, page 30.\nGiambruno, M. (2002). 3D graphics and animation. New Riders Publishing.\nGibson, J. J. (1977). The theory of affordances. Perceiving, acting, and knowing: Toward an ecological psychology, pages 67\u201382.\nGibson, J. J. (1979). The ecological approach to visual perception: classic edition. Psychology Press.\nGoebel, P. M. and Vincze, M. (2007). A cognitive modeling approach for the semantic aggregation of object prototypes from geometric primitives: toward understanding implicit object topology. In Advanced Concepts for Intelligent Vision Systems, pages 84\u201396. Springer.\nGoldstone, W. (2009). Unity Game Development Essentials. Packt Publishing Ltd.\nGru\u0308nbaum, B. (2003). Are your polyhedra the same as my polyhedra? In Discrete and Computational Geometry, pages 461\u2013488. Springer.\nHarel, D. (1984). Dynamic logic. In M. Gabbay et al., editors, Handbook of Philosophical Logic, Volume II: Extensions of Classical Logic, page 497?604. Reidel.\nIde, N. and Romary, L. (2004). International standard for a linguistic annotation framework. Natural Language Engineering, 10(3-4):211\u2013225.\nLuce, D., Krantz, D., Suppes, P., and Tversky, A. (1990). Foundations of measurement, vol. iii: Representation, axiomatization, and invariance. McDonald, D. and Pustejovsky, J. (2014). On the representation of inferences and their lexicalization. In Advances in Cognitive Systems, volume 3. Miller, G. and Charles, W. (1991). Contextual correlates of semantic similarity. Language and Cognitive Processes, 6(1):1\u201328. Miller, G. A. and Johnson-Laird, P. N. (1976). Language and perception. Belknap Press. Parisi, A. and Pesce, M. (1994). Virtual reality markup language (vrml). URL: http://www. wired. com/vrml. Pustejovsky, J. and Krishnaswamy, N. (2014). Generating simulations of motion events from verbal descriptions. Lexical and Computational Semantics (* SEM 2014), page 99. Pustejovsky, J. and Moszkowicz, J. (2011). The qualitative spatial dynamics of motion. The Journal of Spatial Cognition and Computation. Pustejovsky, J., Knippen, R., Littman, J., and Saur\u0131\u0301, R. (2005). Temporal and event information in natural language text. Language Resources and Evaluation, 39:123\u2013164, May. Pustejovsky, J., Lee, K., Bunt, H., and Romary, L. (2010). Iso-timeml: A standard for annotating temporal information in language. In Proceedings of LREC, pages 394\u2013 397. Pustejovsky, J. (1995). The Generative Lexicon. Bradford Book. Mit Press. Pustejovsky, J. (2013). Dynamic event structure and habitat theory. In Proceedings of the 6th International Conference on Generative Approaches to the Lexicon (GL2013), pages 1\u201310. ACL. Randell, D., Cui, Z., and Cohn, A. (1992). A spatial logic based on regions and connections. In Morgan Kaufmann, editor, Proceedings of the 3rd Internation Conference on Knowledge Representation and REasoning, pages 165\u2013176, San Mateo. Siskind, J. M. (2001). Grounding the lexical semantics of verbs in visual perception using force dynamics and event logic. J. Artif. Intell. Res.(JAIR), 15:31\u201390. Steedman, M. (2002). Plans, affordances, and combinatory grammar. Linguistics and Philosophy, 25(5-6):723\u2013 753. Stevens, S. S. (1946). On the theory of scales of measurement. van Benthem, J. F. A. K. (1991). Logic and the flow of information."}], "references": [{"title": "X3D: extensible 3D graphics for Web authors", "author": ["D. Brutzman", "L. Daly"], "venue": "Morgan Kaufmann.", "citeRegEx": "Brutzman and Daly,? 2010", "shortCiteRegEx": "Brutzman and Daly", "year": 2010}, {"title": "A methodology for designing semantic annotation languages exploiting syntactic-semantic isomorphisms", "author": ["H. Bunt"], "venue": "Proceedings of ICGL 2010, Second International Conference on Global Interoperability for Language Resources.", "citeRegEx": "Bunt,? 2010", "shortCiteRegEx": "Bunt", "year": 2010}, {"title": "Developing the vrml 97 international standard", "author": ["G.S. Carson", "R.F. Puk", "R. Carey"], "venue": "Computer Graphics and Applications, IEEE, 19(2):52\u201358.", "citeRegEx": "Carson et al\\.,? 1999", "shortCiteRegEx": "Carson et al\\.", "year": 1999}, {"title": "Text to 3d scene generation with rich lexical grounding", "author": ["A. Chang", "W. Monroe", "M. Savva", "C. Potts", "C.D. Manning"], "venue": "arXiv preprint arXiv:1505.06289.", "citeRegEx": "Chang et al\\.,? 2015", "shortCiteRegEx": "Chang et al\\.", "year": 2015}, {"title": "Transition-based dependency parsing with selectional branching", "author": ["J.D. Choi", "A. McCallum"], "venue": "ACL (1), pages 1052\u20131062.", "citeRegEx": "Choi and McCallum,? 2013", "shortCiteRegEx": "Choi and McCallum", "year": 2013}, {"title": "Wordseye: an automatic text-to-scene conversion system", "author": ["B. Coyne", "R. Sproat"], "venue": "Proceedings of the 28th annual conference on Computer graphics and interactive techniques, pages 487\u2013496. ACM.", "citeRegEx": "Coyne and Sproat,? 2001", "shortCiteRegEx": "Coyne and Sproat", "year": 2001}, {"title": "Spatial descriptions in type theory with records", "author": ["S. Dobnik", "R. Cooper"], "venue": "Proceedings of IWCS 2013 Workshop on Computational Models of Spatial Language Interpretation and Generation (CoSLI-3). Citeseer.", "citeRegEx": "Dobnik and Cooper,? 2013", "shortCiteRegEx": "Dobnik and Cooper", "year": 2013}, {"title": "Modelling language, action, and perception in type theory with records", "author": ["S. Dobnik", "R. Cooper", "S. Larsson"], "venue": "Constraint Solving and Language Processing, pages 70\u201391. Springer.", "citeRegEx": "Dobnik et al\\.,? 2013", "shortCiteRegEx": "Dobnik et al\\.", "year": 2013}, {"title": "Situations in ltl as strings", "author": ["T. Fernando"], "venue": "Information and Computation, 207(10):980\u2013999.", "citeRegEx": "Fernando,? 2009", "shortCiteRegEx": "Fernando", "year": 2009}, {"title": "Segmenting temporal intervals for tense and aspect", "author": ["T. Fernando"], "venue": "The 13th Meeting on the Mathematics of Language, page 30.", "citeRegEx": "Fernando,? 2013", "shortCiteRegEx": "Fernando", "year": 2013}, {"title": "3D graphics and animation", "author": ["M. Giambruno"], "venue": "New Riders Publishing.", "citeRegEx": "Giambruno,? 2002", "shortCiteRegEx": "Giambruno", "year": 2002}, {"title": "The theory of affordances", "author": ["J.J. Gibson"], "venue": "Perceiving, acting, and knowing: Toward an ecological psychology, pages 67\u201382.", "citeRegEx": "Gibson,? 1977", "shortCiteRegEx": "Gibson", "year": 1977}, {"title": "The ecological approach to visual perception: classic edition", "author": ["J.J. Gibson"], "venue": "Psychology Press.", "citeRegEx": "Gibson,? 1979", "shortCiteRegEx": "Gibson", "year": 1979}, {"title": "A cognitive modeling approach for the semantic aggregation of object prototypes from geometric primitives: toward understanding implicit object topology", "author": ["P.M. Goebel", "M. Vincze"], "venue": "Advanced Concepts for Intelligent Vision Systems, pages 84\u201396. Springer.", "citeRegEx": "Goebel and Vincze,? 2007", "shortCiteRegEx": "Goebel and Vincze", "year": 2007}, {"title": "Unity Game Development Essentials", "author": ["W. Goldstone"], "venue": "Packt Publishing Ltd.", "citeRegEx": "Goldstone,? 2009", "shortCiteRegEx": "Goldstone", "year": 2009}, {"title": "Are your polyhedra the same as my polyhedra? In Discrete and Computational Geometry, pages 461\u2013488", "author": ["B. Gr\u00fcnbaum"], "venue": "Springer.", "citeRegEx": "Gr\u00fcnbaum,? 2003", "shortCiteRegEx": "Gr\u00fcnbaum", "year": 2003}, {"title": "Dynamic logic", "author": ["D. Harel"], "venue": "M. Gabbay et al., editors, Handbook of Philosophical Logic, Volume II: Extensions of Classical Logic, page 497?604. Reidel.", "citeRegEx": "Harel,? 1984", "shortCiteRegEx": "Harel", "year": 1984}, {"title": "International standard for a linguistic annotation framework", "author": ["N. Ide", "L. Romary"], "venue": "Natural Language Engineering, 10(3-4):211\u2013225.", "citeRegEx": "Ide and Romary,? 2004", "shortCiteRegEx": "Ide and Romary", "year": 2004}, {"title": "Foundations of measurement, vol", "author": ["D. Luce", "D. Krantz", "P. Suppes", "A. Tversky"], "venue": "iii: Representation, axiomatization, and invariance.", "citeRegEx": "Luce et al\\.,? 1990", "shortCiteRegEx": "Luce et al\\.", "year": 1990}, {"title": "On the representation of inferences and their lexicalization", "author": ["D. McDonald", "J. Pustejovsky"], "venue": "Advances in Cognitive Systems, volume 3.", "citeRegEx": "McDonald and Pustejovsky,? 2014", "shortCiteRegEx": "McDonald and Pustejovsky", "year": 2014}, {"title": "Contextual correlates of semantic similarity", "author": ["G. Miller", "W. Charles"], "venue": "Language and Cognitive Processes, 6(1):1\u201328.", "citeRegEx": "Miller and Charles,? 1991", "shortCiteRegEx": "Miller and Charles", "year": 1991}, {"title": "Language and perception", "author": ["G.A. Miller", "P.N. Johnson-Laird"], "venue": "Belknap Press.", "citeRegEx": "Miller and Johnson.Laird,? 1976", "shortCiteRegEx": "Miller and Johnson.Laird", "year": 1976}, {"title": "Virtual reality markup language (vrml)", "author": ["A. Parisi", "M. Pesce"], "venue": "URL: http://www. wired. com/vrml.", "citeRegEx": "Parisi and Pesce,? 1994", "shortCiteRegEx": "Parisi and Pesce", "year": 1994}, {"title": "Generating simulations of motion events from verbal descriptions", "author": ["J. Pustejovsky", "N. Krishnaswamy"], "venue": "Lexical and Computational Semantics (* SEM 2014), page 99.", "citeRegEx": "Pustejovsky and Krishnaswamy,? 2014", "shortCiteRegEx": "Pustejovsky and Krishnaswamy", "year": 2014}, {"title": "The qualitative spatial dynamics of motion", "author": ["J. Pustejovsky", "J. Moszkowicz"], "venue": "The Journal of Spatial Cognition and Computation.", "citeRegEx": "Pustejovsky and Moszkowicz,? 2011", "shortCiteRegEx": "Pustejovsky and Moszkowicz", "year": 2011}, {"title": "Temporal and event information in natural language text", "author": ["J. Pustejovsky", "R. Knippen", "J. Littman", "R. Saur\u0131"], "venue": "Language Resources and Evaluation,", "citeRegEx": "Pustejovsky et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Pustejovsky et al\\.", "year": 2005}, {"title": "Iso-timeml: A standard for annotating temporal information in language", "author": ["J. Pustejovsky", "K. Lee", "H. Bunt", "L. Romary"], "venue": "Proceedings of LREC, pages 394\u2013 397.", "citeRegEx": "Pustejovsky et al\\.,? 2010", "shortCiteRegEx": "Pustejovsky et al\\.", "year": 2010}, {"title": "The Generative Lexicon", "author": ["J. Pustejovsky"], "venue": "Bradford Book. Mit Press.", "citeRegEx": "Pustejovsky,? 1995", "shortCiteRegEx": "Pustejovsky", "year": 1995}, {"title": "Dynamic event structure and habitat theory", "author": ["J. Pustejovsky"], "venue": "Proceedings of the 6th International Conference on Generative Approaches to the Lexicon (GL2013), pages 1\u201310. ACL.", "citeRegEx": "Pustejovsky,? 2013", "shortCiteRegEx": "Pustejovsky", "year": 2013}, {"title": "A spatial logic based on regions and connections", "author": ["D. Randell", "Z. Cui", "A. Cohn"], "venue": "Morgan Kaufmann, editor, Proceedings of the 3rd Internation Conference on Knowledge Representation and REasoning, pages 165\u2013176, San Mateo.", "citeRegEx": "Randell et al\\.,? 1992", "shortCiteRegEx": "Randell et al\\.", "year": 1992}, {"title": "Grounding the lexical semantics of verbs in visual perception using force dynamics and event logic", "author": ["J.M. Siskind"], "venue": "J. Artif. Intell. Res.(JAIR), 15:31\u201390.", "citeRegEx": "Siskind,? 2001", "shortCiteRegEx": "Siskind", "year": 2001}, {"title": "Plans, affordances, and combinatory grammar", "author": ["M. Steedman"], "venue": "Linguistics and Philosophy, 25(5-6):723\u2013 753.", "citeRegEx": "Steedman,? 2002", "shortCiteRegEx": "Steedman", "year": 2002}, {"title": "On the theory of scales of measurement", "author": ["S.S. Stevens"], "venue": null, "citeRegEx": "Stevens,? \\Q1946\\E", "shortCiteRegEx": "Stevens", "year": 1946}, {"title": "Logic and the flow of information", "author": ["van Benthem", "J.F.A. K"], "venue": null, "citeRegEx": "Benthem and K.,? \\Q1991\\E", "shortCiteRegEx": "Benthem and K.", "year": 1991}], "referenceMentions": [{"referenceID": 5, "context": "1 Prior work in visualization from natural language has largely focused on object placement and orientation in static scenes (Coyne and Sproat, 2001; Siskind, 2001; Chang et al., 2015), and we have endeavored to incorporate dynamic semantics and motion language into our model.", "startOffset": 125, "endOffset": 184}, {"referenceID": 30, "context": "1 Prior work in visualization from natural language has largely focused on object placement and orientation in static scenes (Coyne and Sproat, 2001; Siskind, 2001; Chang et al., 2015), and we have endeavored to incorporate dynamic semantics and motion language into our model.", "startOffset": 125, "endOffset": 184}, {"referenceID": 3, "context": "1 Prior work in visualization from natural language has largely focused on object placement and orientation in static scenes (Coyne and Sproat, 2001; Siskind, 2001; Chang et al., 2015), and we have endeavored to incorporate dynamic semantics and motion language into our model.", "startOffset": 125, "endOffset": 184}, {"referenceID": 23, "context": "In previous work (Pustejovsky and Krishnaswamy, 2014; Pustejovsky, 2013), we introduced a method for modeling natural language expressions within a 3D simulation environment built on top of the game development platform Unity (Goldstone, 2009).", "startOffset": 17, "endOffset": 72}, {"referenceID": 28, "context": "In previous work (Pustejovsky and Krishnaswamy, 2014; Pustejovsky, 2013), we introduced a method for modeling natural language expressions within a 3D simulation environment built on top of the game development platform Unity (Goldstone, 2009).", "startOffset": 17, "endOffset": 72}, {"referenceID": 14, "context": "In previous work (Pustejovsky and Krishnaswamy, 2014; Pustejovsky, 2013), we introduced a method for modeling natural language expressions within a 3D simulation environment built on top of the game development platform Unity (Goldstone, 2009).", "startOffset": 226, "endOffset": 243}, {"referenceID": 28, "context": "The former has developed into a semantic notion of situational context, called a habitat (Pustejovsky, 2013; McDonald and Pustejovsky, 2014), while the latter is addressed by dynamic interpretations of event structure (Pustejovsky and Moszkowicz, 2011; Pustejovsky, 2013).", "startOffset": 89, "endOffset": 140}, {"referenceID": 19, "context": "The former has developed into a semantic notion of situational context, called a habitat (Pustejovsky, 2013; McDonald and Pustejovsky, 2014), while the latter is addressed by dynamic interpretations of event structure (Pustejovsky and Moszkowicz, 2011; Pustejovsky, 2013).", "startOffset": 89, "endOffset": 140}, {"referenceID": 24, "context": "The former has developed into a semantic notion of situational context, called a habitat (Pustejovsky, 2013; McDonald and Pustejovsky, 2014), while the latter is addressed by dynamic interpretations of event structure (Pustejovsky and Moszkowicz, 2011; Pustejovsky, 2013).", "startOffset": 218, "endOffset": 271}, {"referenceID": 28, "context": "The former has developed into a semantic notion of situational context, called a habitat (Pustejovsky, 2013; McDonald and Pustejovsky, 2014), while the latter is addressed by dynamic interpretations of event structure (Pustejovsky and Moszkowicz, 2011; Pustejovsky, 2013).", "startOffset": 218, "endOffset": 271}, {"referenceID": 22, "context": "Existing representation languages for 3D modeling, such as VRML (Parisi and Pesce, 1994), (Carson et al.", "startOffset": 64, "endOffset": 88}, {"referenceID": 2, "context": "Existing representation languages for 3D modeling, such as VRML (Parisi and Pesce, 1994), (Carson et al., 1999) or X3D (Brutzman and Daly, 2010), adequately represent the vertices, edges, faces, and UV texture mapping that make up the model itself, but contain no information about how such an object interacts with other objects in a real or simulated environment.", "startOffset": 90, "endOffset": 111}, {"referenceID": 0, "context": ", 1999) or X3D (Brutzman and Daly, 2010), adequately represent the vertices, edges, faces, and UV texture mapping that make up the model itself, but contain no information about how such an object interacts with other objects in a real or simulated environment.", "startOffset": 15, "endOffset": 40}, {"referenceID": 1, "context": "We have followed a strict methodology of specification development, as adopted by ISO TC37/SC4 and outlined in (Bunt, 2010) and (Ide and Romary, 2004), and as implemented with the development of ISO-TimeML (Pustejovsky et al.", "startOffset": 111, "endOffset": 123}, {"referenceID": 17, "context": "We have followed a strict methodology of specification development, as adopted by ISO TC37/SC4 and outlined in (Bunt, 2010) and (Ide and Romary, 2004), and as implemented with the development of ISO-TimeML (Pustejovsky et al.", "startOffset": 128, "endOffset": 150}, {"referenceID": 25, "context": "We have followed a strict methodology of specification development, as adopted by ISO TC37/SC4 and outlined in (Bunt, 2010) and (Ide and Romary, 2004), and as implemented with the development of ISO-TimeML (Pustejovsky et al., 2005; Pustejovsky et al., 2010) and others in the family of SemAF standards.", "startOffset": 206, "endOffset": 258}, {"referenceID": 26, "context": "We have followed a strict methodology of specification development, as adopted by ISO TC37/SC4 and outlined in (Bunt, 2010) and (Ide and Romary, 2004), and as implemented with the development of ISO-TimeML (Pustejovsky et al., 2005; Pustejovsky et al., 2010) and others in the family of SemAF standards.", "startOffset": 206, "endOffset": 258}, {"referenceID": 7, "context": "Further, our work shares many of the goals pursued in (Dobnik et al., 2013; Dobnik and Cooper, 2013), for specifying a rigidly-defined type system for spatial representations associated with linguistic expressions.", "startOffset": 54, "endOffset": 100}, {"referenceID": 6, "context": "Further, our work shares many of the goals pursued in (Dobnik et al., 2013; Dobnik and Cooper, 2013), for specifying a rigidly-defined type system for spatial representations associated with linguistic expressions.", "startOffset": 54, "endOffset": 100}, {"referenceID": 27, "context": "Following Generative Lexicon (GL) (Pustejovsky, 1995), lexical entries in the object language are given a feature structure consisting of a word\u2019s basic type, its parameter listing, its event typing, and its qualia structure.", "startOffset": 34, "endOffset": 53}, {"referenceID": 28, "context": "(Pustejovsky, 2013) introduces the notion of an object\u2019s habitat, which encodes these circumstances.", "startOffset": 0, "endOffset": 19}, {"referenceID": 11, "context": "This effectively is to identify the affordance structure for the object (Gibson, 1977; Gibson, 1979).", "startOffset": 72, "endOffset": 100}, {"referenceID": 12, "context": "This effectively is to identify the affordance structure for the object (Gibson, 1977; Gibson, 1979).", "startOffset": 72, "endOffset": 100}, {"referenceID": 15, "context": "We ground our possible values for HEAD in, for completeness, mathematical formalism defining families of polyhedra (Gr\u00fcnbaum, 2003), and, for annotator\u2019s ease, common primitives found across", "startOffset": 115, "endOffset": 131}, {"referenceID": 10, "context": "the \u201ccorpus\u201d of 3D artwork and 3D modeling software2 (Giambruno, 2002).", "startOffset": 53, "endOffset": 70}, {"referenceID": 13, "context": "It should be emphasized that these values are not intended to reflect the exact structure of a particular geometry, but rather a cognitive approximation of its shape, as is used in some image-recognition work (Goebel and Vincze, 2007).", "startOffset": 209, "endOffset": 234}, {"referenceID": 27, "context": "There are low-level affordances, called GIBSONIAN, which involve manipulation or maneuver-based actions (grasping, holding, lifting, touching); there are also TELIC affordances (Pustejovsky, 1995), which link directly to what goal-directed activity can be accomplished, by means of the GIBSONIAN affordances.", "startOffset": 177, "endOffset": 196}, {"referenceID": 32, "context": "Following (Stevens, 1946; Luce et al., 1990), we will call this classification a nominal scale, and it is the least restrictive scale domain over which we can predicate an individual.", "startOffset": 10, "endOffset": 44}, {"referenceID": 18, "context": "Following (Stevens, 1946; Luce et al., 1990), we will call this classification a nominal scale, and it is the least restrictive scale domain over which we can predicate an individual.", "startOffset": 10, "endOffset": 44}, {"referenceID": 29, "context": "These classes themselves have subvalues\u2014for configurational relations these are values from the region connection calculus (Randell et al., 1992).", "startOffset": 123, "endOffset": 145}, {"referenceID": 24, "context": "VoxML treats objects and events in terms of a dynamic event semantics, Dynamic Interval Temporal Logic (DITL) (Pustejovsky and Moszkowicz, 2011).", "startOffset": 110, "endOffset": 144}, {"referenceID": 20, "context": "The advantage of adopting a dynamic interpretation of events is that we can map linguistic expressions directly into simulations through an operational semantics (Miller and Charles, 1991; Miller and Johnson-Laird, 1976).", "startOffset": 162, "endOffset": 220}, {"referenceID": 21, "context": "The advantage of adopting a dynamic interpretation of events is that we can map linguistic expressions directly into simulations through an operational semantics (Miller and Charles, 1991; Miller and Johnson-Laird, 1976).", "startOffset": 162, "endOffset": 220}, {"referenceID": 16, "context": "Models of processes using updating typically make reference to the notion of a state transition (van Benthem, 1991; Harel, 1984).", "startOffset": 96, "endOffset": 128}, {"referenceID": 4, "context": "Simulation generation begins by parsing a natural English sentence, currently using the ClearNLP parser (Choi and McCallum, 2013).", "startOffset": 104, "endOffset": 129}, {"referenceID": 8, "context": "This is consistent with the approach developed in (Fernando, 2009; Fernando, 2013).", "startOffset": 50, "endOffset": 82}, {"referenceID": 9, "context": "This is consistent with the approach developed in (Fernando, 2009; Fernando, 2013).", "startOffset": 50, "endOffset": 82}, {"referenceID": 8, "context": "This is consistent with the approach developed in (Fernando, 2009; Fernando, 2013). This approach to a dynamic interpretation of change in language semantics is also inspired by Steedman (2002). We are working toward integrating the lexical entries with a rule-based parser that provides for a compositionally derived interpretation of the sentence being parsed.", "startOffset": 51, "endOffset": 194}, {"referenceID": 23, "context": "We use an updated version of the the simulator built for (Pustejovsky and Krishnaswamy, 2014) and the C# language to generate visualizations like that shown in Figure 9 below.", "startOffset": 57, "endOffset": 93}], "year": 2016, "abstractText": "We present the specification for a modeling language, VoxML, which encodes semantic knowledge of real-world objects represented as three-dimensional models, and of events and attributes related to and enacted over these objects.VoxML is intended to overcome the limitations of existing 3D visual markup languages by allowing for the encoding of a broad range of semantic knowledge that can be exploited by a variety of systems and platforms, leading to multimodal simulations of real-world scenarios using conceptual objects that represent their semantic values.", "creator": "LaTeX with hyperref package"}}}