{"id": "1610.05120", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Oct-2016", "title": "Lazifying Conditional Gradient Algorithms", "abstract": "Conditional gradient algorithms (often referred to as Frank Wolfe algorithms) are popular due to their simplicity in requiring only a linear optimization oracle, and have recently gained traction for online learning as well. Although in principle they are simple, the actual implementation of the oracle of linear optimization is costly in many cases. We show a general method of laziness of various conditional gradient algorithms that results in multiple orders of magnitude acceleration of wall clock time in real calculations, achieved by using a faster separation oracle instead of a linear optimization oracle, relying on only a few linear optimization oracle calls.", "histories": [["v1", "Mon, 17 Oct 2016 14:01:25 GMT  (587kb)", "http://arxiv.org/abs/1610.05120v1", "18 pages and 16 pages of computational results"], ["v2", "Fri, 30 Dec 2016 16:53:44 GMT  (4189kb,D)", "http://arxiv.org/abs/1610.05120v2", "18 pages and 16 pages of computational results"]], "COMMENTS": "18 pages and 16 pages of computational results", "reviews": [], "SUBJECTS": "cs.DS cs.LG", "authors": ["g\u00e1bor braun", "sebastian pokutta", "daniel zink"], "accepted": true, "id": "1610.05120"}, "pdf": {"name": "1610.05120.pdf", "metadata": {"source": "META", "title": "Lazifying Conditional Gradient Algorithms", "authors": ["G\u00e1bor Braun", "Sebastian Pokutta"], "emails": ["gabor.braun@gatech.edu", "sebastian.pokutta@gatech.edu", "daniel.zink@gatech.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n61 0.\n05 12\n0v 1\n[ cs\n.D S]\n1 7\nConditional gradient algorithms (also often called Frank-Wolfe algorithms) are popular due to their simplicity of only requiring a linear optimization oracle and more recently they also gained significant traction for online learning. While simple in principle, inmany cases the actual implementation of the linear optimization oracle is costly. We show a general method to lazify various conditional gradient algorithms, which in actual computations leads to several orders of magnitude of speedup in wall-clock time. This is achieved by using a faster separation oracle instead of a linear optimization oracle, relying only on few linear optimization oracle calls."}, {"heading": "1 Introduction", "text": "Convex optimization is an important technique both from a theoretical and an applications perspective. Standard gradient descent based methods are widely used due to their simplicity and easy applicability to many real-world problems. To maintain feasibility, typically a projection step is required, which is potentially computationally expensive, especially for complex feasible regions in very large dimensions. Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012]. These methods eschew the projection step and rather use a linear optimization oracle to stay within the feasible region. While convergence rates and regret bounds are often suboptimal, in many cases the gain due to only having to solve a single linear optimization problem over the feasible region in every iteration still leads to significant computational advantages (see e.g., [Hazan and Kale, 2012, Section 5]). This led to conditional gradients algorithms being often used for e.g., online optimization andmore generallymachine learning, especially because they also naturally generate sparse distributions over the extreme points of the feasible region. Further increasing the relevance of these methods, it was shown recently in Garber and Hazan [2013], Lacoste-Julien and Jaggi [2015], Garber and Meshi [2016] that conditional gradient methods often achieve linear convergence.\nUnfortunately, for complex feasible regions even solving the linear optimization problem might be timeconsuming. To significantly reduce the cost of oracle calls while maintaining identical convergence rates up to small constant factors, we replace the linear optimization oracle by a (weak) separation oracle, see Oracle 1, which approximately solves a separation problem within a multiplicative factor. Note that, weak\nseparation is significantly weaker than approximate minimization; the latter has been already considered in Jaggi [2013]. A (weak) separation oracle can be realized by a single call to a linear optimization oracle, however with two important differences. It allows for caching and early termination: Previous solutions are cached, and first it is verified whether any of the cached solutions satisfy a separation condition. The linear optimization oracle is called only when none of the cached solutions satisfy the condition, and it is stopped as soon as a satisfactory solution is found. We call this technique lazy optimization. We provide conditional gradient algorithms employing the weak separation oracle instead of a linear optimization oracle for the algorithms in [Hazan and Kale, 2012, Garber and Meshi, 2016, Garber and Hazan, 2013] with convergence rates summarized in Table 1. These bounds are identical to their linear optimization counterparts up to a small constant factor. Complementing the theoretical analysis we report computational results demonstrating effectiveness of our approach via a significant reduction in running time compared to their linear optimization counterparts.\nOracle 1Weak Separation Oracle LPsepP(c, x, \u03a6, K) Require: c \u2208 Rn linear objective, x \u2208 P point, K \u2265 1 accuracy, \u03a6 > 0 objective value; Ensure: Either (1) y \u2208 P vertex with c(x \u2212 y) > \u03a6/K, or (2) false: c(x \u2212 z) \u2264 \u03a6 for all z \u2208 P.\nRelated Work\nIn the offline setting we mimick the same setups as in Garber and Hazan [2013], Garber and Meshi [2016] respectively. In the online setup we mimick the setup of Hazan and Kale [2012]. Combinatorial convex optimization has been investigated in a long line of works (see e.g., [Kalai and Vempala, 2005, Audibert et al., 2013, Neu and Bart\u00f3k, 2013]), see [Hazan, 2016] for an exhaustive overview. It is important to note that our regret bounds hold in the structured online learning setting (see e.g., [Cohen and Hazan, 2015, Gupta et al., 2016]) for arbitrary convex functions.\nContribution\nThe main technical contribution of this paper is a new approach, whereby instead of finding the optimal solution, the oracle is used only to find a good enough solution or a certificate that such a solution does not exist, both ensuring the desired convergence rate of the conditional gradient algorithms.\nOur contribution can be summarized as follows: Lazifying approach. We provide a general method to lazify conditional gradient algorithms. For this we replace the linear optimization oracle with a weak separation oracle, which allows us to reuse feasible solutions from previous oracle calls, so that in many cases the oracle call can be skipped. In fact, once a simple representation of the underlying feasible region is learned no further oracle calls are needed.\nLazified conditional gradient algorithms. We exemplify our approach by providing lazy versions of the conditional gradient methods in [Hazan and Kale, 2012, Garber and Hazan, 2013, Garber and Meshi, 2016]\nComputational experiments. We demonstrate computational superiority by extensive comparisons of the weak separation based versions with their original versions. In all cases we report significant speedups in wall-clock time often of several orders of magnitude.\nIn all cases, we maintain identical convergence rates as in the case with a linear optimization oracle up\nto (small!) constant factors. We summarize the bounds for convenience in Table 1."}, {"heading": "2 Preliminaries", "text": "Let \u2016\u00b7\u2016 be an arbitrary norm on Rn, and let \u2016\u00b7\u2016\u2217 denote the dual norm of \u2016\u00b7\u2016. A function f is L-Lipschitz if | f (y)\u2212 f (x)| \u2264 L\u2016y \u2212 x\u2016 for all x, y \u2208 dom f . A convex function f is smooth with curvature at most C if f (\u03b3y + (1 \u2212 \u03b3)x) \u2264 f (x) + \u03b3\u2207 f (x)(y \u2212 x) + C\u03b32/2 for all x, y \u2208 dom f and 0 \u2264 \u03b3 \u2264 1. A function f is S-strongly convex if f (y)\u2212 f (x) \u2265 \u2207 f (x)(y\u2212 x) + S2 \u2016y \u2212 x\u2016 2 for all x, y \u2208 dom f . Unless otherwise stated Lipschitz continuity and strong convexity will be measured in the norm \u2016\u00b7\u2016. Moreover, let Br (x) := {y | \u2016x \u2212 y\u2016 \u2264 r} be the ball around x with radius r with respect to \u2016.\u2016.\nIn the following, P will denote the feasible region, a polytope and the vertices of P will be denoted by v1, . . . , vN."}, {"heading": "3 Lazy Offline Conditional Gradients", "text": "We will first show how the Frank-Wolfe style algorithms in Garber and Hazan [2013] and Garber and Meshi [2016] can be lazified by means of a weak separation oracle as given in Oracle 1. Note that the two cases in Oracle 1 are not mutually exclusive: the oracle might return an y \u2208 P with c(x \u2212 y) > \u03a6/K, while still c(x \u2212 z) \u2264 \u03a6 for all z \u2208 P. In this section \u2016\u00b7\u2016 denotes the \u21132-norm."}, {"heading": "3.1 Lazy Conditional Gradient: a basic example", "text": "We start with lazifying the simplest Conditional Gradent algorithm, adapting the argument of the non-lazy version from Jaggi [2013]. While the vanilla version has suboptimal convergence rate O(1/T), its simplicity makes it an illustrative example of the main idea of lazification. The lazy algorithm (Algorithm 1) maintains an upper bound \u03a6t on the convergence rate, guiding its eagerness for progress when searching for an improving vertex vt. The step size \u03b3t is chosen to (approximately)minimize \u03a6t in Line 2; roughly\u03a6t\u22121/KC.\nTheorem 3.1. (C.f., [Jaggi, 2013, Theorem 1].) Assume f is convex and smooth with curvature C. Then Algorithm 1 with \u03b3t = 2(K2+1) K(t+K2) has convergence rate\nf (xt)\u2212 f (x\u2217) \u2264 2 max{C, \u03a60}(K2 + 1)\nt + K2 , (1)\nwhere x\u2217 is a minimum point of f over P.\nProof. We prove by induction that\nf (xt)\u2212 f (x\u2217) \u2264 \u03a6t\u22121 \u2264 \u03a6t\u22121.\nAlgorithm 1 Lazy Conditional Gradients (LCG) Require: smooth convex f function with curvature C, x1 \u2208 P start vertex, LPsepP weak linear separation oracle, accuracy K > 1, initial upper bound \u03a60 Ensure: xt points in P 1: for t = 1 to T \u2212 1 do 2: \u03a6t \u2190 \u03a6t\u22121+ C\u03b32t 2\n1+ \u03b3t K\n3: vt \u2190 LPsepP(\u2207 f (xt), xt, \u03a6t, K) 4: if vt = false then 5: xt+1 \u2190 xt 6: \u03a6t \u2190 \u03a6t 7: else\n8: xt+1 \u2190 (1 \u2212 \u03b3t)xt + \u03b3tvt 9: \u03a6t \u2190 \u03a6t\u22121 \u2212 ( f (xt)\u2212 f (xt+1)) 10: end if 11: end for\nwith \u03a60 := \u03a60. The claim is clear for t = 1 by the choice of \u03a60. Assuming the claim is true for t, we prove it for t + 1. We distinguish two cases depending on the return value of the weak separation oracle in Line 3.\nWhen the oracle returns an improving solution vt, which we call the positive case, then \u2207 f (xt)(xt \u2212 vt) \u2265 \u03a6t/K, which is used in the second inequality below. The first inequality follows by smoothness of f :\n\u03a6t \u2212 \u03a6t\u22121 = f (xt+1)\u2212 f (xt) \u2264 \u03b3t\u2207 f (xt)(vt \u2212 xt) + C\u03b32t\n2 \u2264 \u2212\u03b3t\n\u03a6t\nK + C\u03b32t 2 = \u03a6t \u2212 \u03a6t\u22121, (2)\nhence \u03a6t \u2264 \u03a6t. By Line 9 and the induction hypothesis, we clearly have\nf (xt+1)\u2212 f (x\u2217) \u2264 f (xt+1)\u2212 f (xt) + \u03a6t\u22121 = \u03a6t.\nWhen the oracle returns no improving solution, then in particular \u2207 f (xt)(xt \u2212 x\u2217) \u2264 \u03a6t, hence by Line 5\nf (xt+1)\u2212 f (x\u2217) = f (xt)\u2212 f (x\u2217) \u2264 \u2207 f (xt)(xt \u2212 x\u2217) \u2264 \u03a6t = \u03a6t. (3) Finally, using the specific values of \u03b3t we prove the upper bound\n\u03a6t\u22121 \u2264 2 max{C, \u03a60}(K2 + 1)\nt + K2 (4)\nby induction on t. The claim is obvious for t = 1. The inductional step is an easy computation relying on the definition of \u03a6t on Line 2:\n\u03a6t = \u03a6t\u22121 +\nC\u03b32t 2\n1 + \u03b3tK \u2264 \u03a6t\u22121 +\nC\u03b32t 2\n1 + \u03b3tK \u2264\n2 max{C,\u03a60}(K2+1) t+K2 + max{C,\u03a60}\u03b32t 2\n1 + \u03b3tK\n= 2 max{C, \u03a60}(K2 + 1) 1 + \u03b3t2K (\n1 + \u03b3tK )\n(t + K2) \u2264 2 max{C, \u03a60}(K 2 + 1) t + 1 + K2 .\n(5)\nHere the last inequality follows from t \u2265 1 and the concrete choice of \u03b3t."}, {"heading": "3.2 Lazy Pairwise Conditional Gradients", "text": "In this section we provide a lazy variant (Algorithm 2) of the Pairwise Conditional Gradient algorithm from Garber and Meshi [2016], using separation instead of linear optimization. We make identical assumptions: the feasible region is a 0/1 polytope given in the form P = {x \u2208 Rn | x \u2265 0, Ax = b}.\nAlgorithm 2 Lazy Pairwise Conditional Gradients (LPCG)\nRequire: polytope P, smooth and S-strongly convex function f with curvature C, accuracy K > 1, \u03b7t nonincreasing step-sizes Ensure: xt points 1: x1 \u2208 P arbitrary and \u03a60 \u2265 f (x1)\u2212 f (x\u2217) 2: for t = 1, . . . , T do 3: define \u2207\u0303 f (xt) \u2208 Rm as follows:\n\u2207\u0303 f (xt)i := { \u2207 f (xt)i if xt > 0 \u2212\u221e if xt = 0\n4: \u03a6t \u2190 2\u03a6t\u22121+\u03b7 2 t C\n2+ \u03b7t\nK\u2206t\n5: ct \u2190 ( \u2207 f (xt),\u2212\u2207\u0303 f (xt) ) 6: (v+t , v \u2212 t ) \u2190 LPsepP\u00d7P ( ct, (xt, xt), \u03a6t \u2206t , K ) 7: if (v+t , v \u2212 t ) = false then 8: xt+1 \u2190 xt 9: else\n10: \u03b7\u0303t \u2190 max{2\u2212\u03b4 | \u03b4 \u2208 Z\u22650, 2\u2212\u03b4 \u2264 \u03b7t} 11: xt+1 \u2190 xt + \u03b7\u0303t(v+t \u2212 v\u2212t ) 12: end if 13: end for\nObserve that Algorithm 2 calls the linear separation oracle LPsep on the cartesian product of P with itself. Choosing the objective function as in Line 5 allows us to simultaneously find an improving direction and an away-step direction.\nTheorem 3.2. Let x\u2217 be a minimum point of f in P, and \u03a60 an upper bound of f (x1) \u2212 f (x\u2217). Furthermore, let M1 := \u221a S 8 card(x\u2217) , M2 := KC/2, \u03ba := min{ M1 2M2 , 1/ \u221a \u03a60}, \u03b7t := \u03ba \u221a\n\u03a6t\u22121 and \u2206t := \u221a\n2 card(x\u2217)\u03a6t\u22121 S , then Algorithm 2 has convergence rate\nf (xt+1)\u2212 f (x\u2217) \u2264 \u03a6t \u2264 \u03a60 ( 1 + B\n1 + 2B\n)t\n,\nwhere B := \u03ba \u00b7 M12K .\nWe recall a technical lemma for the proof.\nLemma 3.3 ([Garber and Meshi, 2016, Lemma 2]). Let x, y \u2208 P. There exists vertices vi of P such that x = \u2211ki=1 \u03bbivi and y = \u2211 k i=1 (\u03bbi \u2212 \u03b3i) vi + ( \u2211 k i=1 \u03b3i )\nz with \u03b3i \u2208 [0, \u03bbi], z \u2208 P and \u2211ki=1 \u03b3i \u2264 \u221a\ncard(y)\u2016x \u2212 y\u2016.\nProof of Theorem 3.2. The feasibility of the iterates xt is ensured by Line 10 and the monotonicity of the sequence {\u03b7t}t\u22651 with the same argument as in [Garber and Meshi, 2016, Lemma 1 and Observation 2].\nWe first show by induction that\nf (xt+1)\u2212 f (x\u2217) \u2264 \u03a6t. For t = 0 we have \u03a60 \u2265 f (x1)\u2212 f (x\u2217). Now assume the statement for some t \u2265 0. In the negative case (Line 8), we use the guarantee of Oracle 1 to get\nct((xt, xt)\u2212 (z1, z2)) \u2264 \u03a6t\n\u2206t\nfor all z1, z2 \u2208 P, which is equivalent to (as ct(xt, xt) = 0)\n\u2207\u0303 f (xt)z2 \u2212\u2207 f (xt)z1 \u2264 \u03a6t\n\u2206t\nand therefore\n\u2207 f (xt)(z\u03032 \u2212 z1) \u2264 \u03a6t\n\u2206t , (6)\nfor all z\u03032, z1 \u2208 P with supp(z\u03032) \u2286 supp(xt). We further use Lemma 3.3 to write xt = \u2211ki=1 \u03bbivi and x\u2217 = \u2211ki=1(\u03bbi \u2212 \u03b3i)vi + \u2211ki=1 \u03b3iz with \u03b3i \u2208 [0, \u03bbi], z \u2208 P and \u2211ki=1 \u03b3i \u2264 \u221a card(x\u2217)\u2016xt \u2212 x\u2217\u2016 \u2264 \u221a\n2 card(x\u2217)\u03a6t\u22121 S = \u2206t, using the induction hypothesis and the strong convexity in the second inequality.\nThen\nf (xt+1)\u2212 f (x\u2217) = f (xt)\u2212 f (x\u2217) \u2264 \u2207 f (xt)(xt \u2212 x\u2217) = k\n\u2211 i=1\n\u03b3i(vi \u2212 z) \u00b7 \u2207 f (xt) \u2264 \u03a6t,\nwhere we used Equation 6 for the last inequality.\nFor the positive case (Lines 10 and 11) we get, using first smoothness of f , then \u03b7t/2 < \u03b7\u0303t \u2264 \u03b7t and \u2207 f (xt)(v+t \u2212 v\u2212t ) \u2264 \u2212\u03a6t/(\u2206tK), and finally the definition of \u03a6t:\nf (xt+1)\u2212 f (x\u2217) = f (xt)\u2212 f (x\u2217) + f (xt + \u03b7\u0303t(v+t \u2212 v\u2212t ))\u2212 f (xt)\n\u2264 \u03a6t\u22121 + \u03b7\u0303t\u2207 f (xt)(v+t \u2212 v\u2212t ) + \u03b7\u03032t C\n2\n\u2264 \u03a6t\u22121 \u2212 \u03b7t 2 \u00b7 \u03a6t \u2206tK +\n\u03b72t C\n2 = \u03a6t.\nPlugging in the values of \u03b7t and \u2206t to the definition of \u03a6t gives the desired bound.\n\u03a6t = 2\u03a6t\u22121 + \u03b72t C\n2 + \u03b7tK\u2206t = \u03a6t\u22121\n1 + \u03ba2 M2/K\n1 + \u03baM1/K \u2264 \u03a6t\u22121\n1 + B\n1 + 2B \u2264 \u03a60\n(\n1 + B\n1 + 2B\n)t\n."}, {"heading": "3.3 Lazy Local Conditional Gradients", "text": "In this sectionwe provide a lazy version (Algorithm3) of the conditional gradient algorithmfromGarber and Hazan [2013]. Let P \u2286 Rn be any polytope, D denote an upper bound on the \u21132-diameter of P, and \u00b5 \u2265 1 be the affine invariant of P from Garber and Hazan [2013]. As the algorithm is not affine invariant by nature, we need a non-invariant version of smoothness: Recall that a convex function f is \u03b2-smooth if f (y)\u2212 f (x) \u2264 \u2207 f (x)(y \u2212 x) + \u03b2\u2016y \u2212 x\u20162/2.\nAlgorithm 3 Lazy Local Conditional Gradients (LLCG)\nRequire: feasible polytope P, \u03b2-smooth and S-strongly convex function f , parameters K, S, \u03b2, \u00b5; diameter D Ensure: xt points 1: x1 \u2208 P arbitrary and \u03a60 \u2265 f (x1)\u2212 f (x\u2217) 2: \u03b1 \u2190 S\n2K\u03b2n\u00b52\n3: for t = 1, . . . , T do 4: \u03a6t \u2190 \u03a6t\u22121+ \u03b2 2 \u03b1 2 min{n\u00b52r2t ,D2} 1+\u03b1/K 5: rt \u2190 \u221a 2\u03a6t\u22121 S 6: pt \u2190 LLPsepP (\u2207 f (xt), xt, rt, \u03a6t, K) 7: if pt = false then 8: xt+1 \u2190 xt 9: else\n10: xt+1 \u2190 xt + \u03b1(pt \u2212 xt) 11: end if 12: end for\nAs an intermediary step, we first implement a local weak separation oracle in Algorithm4, a local version of Oracle 1, analogously to the local linear optimization oracle in Garber and Hazan [2013]. To this end, we recall a technical lemma from Garber and Hazan [2013].\nLemma 3.4. [Garber and Hazan, 2013, Lemma 7] Let P \u2286 Rn be a polytope and v1, . . . , vN be its vertices. Let x, y \u2208 P and x = \u2211Ni=1 \u03bbivi a convex combination of the vertices of P. Then there are numbers 0 \u2264 \u03b3i \u2264 \u03bbi and z \u2208 P satisfying\ny \u2212 x = \u2212 \u2211 i\u2208[N] \u03b3ivi +\n\n \u2211 i\u2208[N] \u03b3i\n\n z (7)\n\u2211 i\u2208[N]\n\u03b3i \u2264 \u221a n\u00b5\nD \u2016x \u2212 y\u2016. (8)\nNow we prove the correctness of the weak local separation algorithm.\nLemma 3.5. Algorithm 4 is correct. In particular LLPsepP(c, x, r, \u03a6, K)\n(i) returns either an y \u2208 P with \u2016x \u2212 y\u2016 \u2264 \u221an\u00b5r and c(x \u2212 y) > \u03a6/K,\n(ii) or establishes c(x \u2212 z) \u2264 \u03a6 for all z \u2208 P \u2229 Br (x).\nAlgorithm 4Weak Local Separation LLPsepP(c, x, r, \u03a6, K) Require: c \u2208 Rn linear objective, x \u2208 P point, r > 0 radius, \u03a6 > 0 objective value Ensure: Either (1) y \u2208 P with \u2016x \u2212 y\u2016 \u2264 \u221an\u00b5r and c(x \u2212 y) > \u03a6/K, or (2) false: c(x \u2212 z) \u2264 \u03a6 for all\nz \u2208 P \u2229 Br (x). 1: \u2206 \u2190 min {\u221a n\u00b5\nD r, 1 }\n2: Decompose x: x = \u2211Mj=1 \u03bbjvj, \u03bbj > 0, \u2211j \u03bbj = 1. 3: Sort vertices: i1, . . . , iM cvi1 \u2265 \u00b7 \u00b7 \u00b7 \u2265 cviM . 4: k \u2190 min{k : \u2211kj=1 \u03bbi j \u2265 \u2206} 5: p\u2212 \u2190 \u2211k\u22121j=1 \u03bbi jvi j + ( \u2206 \u2212 \u2211k\u22121j=1 \u03bbi j ) vik 6: v\u2217 \u2190 LPsepP ( c, p\u2212 \u2206 , \u03a6 \u2206 ) 7: if v\u2217 = false then 8: return false 9: else\n10: return y \u2190 x \u2212 p\u2212 + \u2206v\u2217 11: end if\nProof. We first consider the case when the algorithm exits in Line 10. Observe that y \u2208 P since y is a convex combination of vertices of P. Moreover by construction of y we can write y = \u2211Mj=1(\u03bbi j \u2212 \u03b3j)vi j + \u2206v\u2217 with \u2206 = \u2211Mj=1 \u03b3j \u2264 \u221a n\u00b5 D r. Therefore\n\u2016x \u2212 y\u2016 = \u2225 \u2225 \u2225\n\u2225 \u2225\nM\n\u2211 j=1\n\u03b3jvi j \u2212 \u2206v \u2217 \u2225 \u2225 \u2225 \u2225\n\u2225\n\u2264 M\n\u2211 j=1\n\u03b3j\u2016vi j \u2212 v \u2217\u2016\n\u2264 \u221a n\u00b5r.\nFinally using the guarantee of LPsepP we get\nc(x \u2212 y) = \u2206c ( p\u2212 \u2206 \u2212 v\u2217 ) \u2265 \u03a6 K .\nIf the algorithm exits in Line 8, we use Lemma 3.4 to decompose any y \u2208 P \u2229 Br (x) in the following way:\ny = N\n\u2211 i=1\n(\u03bbi \u2212 \u03b3i)vi + ( N\n\u2211 i=1 \u03b3i\n)\nz,\nwith z \u2208 P and \u2211Ni=1 \u03b3i \u2264 \u221a n\u00b5 D \u2016x \u2212 y\u2016 \u2264 \u2206. Since \u2211Ni=1 \u03bbi = 1 \u2265 \u2206, there are numbers \u03b3i \u2264 \u03b7\u2212i \u2264 \u03bbi with \u2211 N i=1 \u03b7 \u2212 i = \u2206. Let\np\u0303\u2212 := N\n\u2211 i=1\n\u03b7\u2212i vi, (9)\np\u0303+ := y \u2212 x + p\u0303\u2212 = N\n\u2211 i=1\n(\u03b7\u2212i \u2212 \u03b3i)vi + N\n\u2211 i=1 \u03b3iz, (10)\nso that p\u0303+/\u2206 \u2208 P. To bound the function value we first observe that the choice of p\u2212 in the algorithm assures that cu \u2264 cp\u2212 for all u = \u2211Ni=1 \u03b7ivi with \u2211Ni=1 \u03b7i = \u2206 and all \u03b7i \u2265 0. In particular, cp\u0303\u2212 \u2264 cp\u2212. The function value of the positive part p\u0303+ can be bounded with the guarantee of LPsepP:\nc\n(\np\u2212 \u2206 \u2212 p\u0303+ \u2206\n)\n\u2264 \u03a6 \u2206 ,\ni.e., c(p\u2212 \u2212 p\u0303+) \u2264 \u03a6. Finally combining these bounds gives\nc(x \u2212 y) = c ( p\u0303\u2212 \u2212 p\u0303+) \u2264 c(p\u2212 \u2212 p\u0303+) \u2264 \u03a6\nas desired.\nWe are ready to examine the Conditional Gradient Algorithm based on LLPsepP:\nTheorem 3.6. Algorithm 3 converges with the following rate:\nf (xt+1)\u2212 f (x\u2217) \u2264 \u03a6t \u2264 \u03a60 ( 1 + \u03b1/(2K)\n1 + \u03b1/K\n)t\n.\nProof. The proof is similar to the proof of Theorem 3.2. We prove this rate by induction. For t = 0 the choice of \u03a60 guarantees that f (x1)\u2212 f (x\u2217) \u2264 \u03a60. Now assume the theorem holds for t \u2265 0. With strong convexity and the induction hypothesis we get\n\u2016xt \u2212 x\u2217\u20162 \u2264 2 S ( f (xt)\u2212 f (x\u2217)) \u2264 2 S \u03a6t\u22121 = r2t ,\ni.e., x\u2217 \u2208 P \u2229 Brt (xt). In the negative case, i.e., when pt = false, then case (ii) of Lemma 3.5 applies:\nf (xt+1)\u2212 f (x\u2217) = f (xt)\u2212 f (x\u2217) \u2264 \u2207 f (xt)(xt \u2212 x\u2217) \u2264 \u03a6t.\nIn the positive case, i.e., when Line 10 is executed, we get the same inequality via:\nf (xt+1)\u2212 f (x\u2217) \u2264 \u03a6t\u22121 + \u03b1\u2207 f (xt)(pt \u2212 xt) + \u03b2\n2 \u03b12\u2016x \u2212 pt\u20162\n\u2264 \u03a6t\u22121 \u2212 \u03b1 \u03a6t\nK +\n\u03b2 2 \u03b12 min{n\u00b52r2t , D2}\n= \u03a6t.\nTherefore using the definition of \u03b1 and rt we get the desired bound:\n\u03a6t \u2264 \u03a6t\u22121 +\n\u03b2 2 \u03b1 2r2t n\u00b5 2\n1 + \u03b1/K = \u03a6t\u22121\n(\n1 + \u03b1/(2K)\n1 + \u03b1/K\n) \u2264 \u03a60 ( 1 + \u03b1/(2K)\n1 + \u03b1/K\n)t\n."}, {"heading": "4 Lazy Online Conditional Gradients", "text": "In this section we lazify the online conditional gradient algorithm of Hazan and Kale [2012] over arbitrary polytopes P = {x \u2208 Rn | Ax \u2264 b}, resulting in Algorithm 5. We slightly improve constant factors by replacing [Hazan and Kale, 2012, Lemma 3.1] with a better estimation via solving a quadratic inequality arising from strong convexity. In this section the norm \u2016\u00b7\u2016 can be arbitrary.\nAlgorithm 5 Lazy Online Conditional Gradients (LOCG) Require: ft functions, x1 \u2208 P start vertex, LPsepP weak linear separation oracle, parameters K, C, b, S, s; diameter D Ensure: xt points 1: for t = 1 to T \u2212 1 do 2: \u2207t \u2190 \u2207 ft(xt) 3: if t = 1 then 4: h1 \u2190 min{\u2016\u22071\u2016\u2217 D, 2 \u2016\u22071\u2016\u22172 /S} 5: else\n6: ht \u2190 \u03a6t\u22121 + min { \u2016\u2207t\u2016\u2217 D, \u2016\u2207t\u2016 \u22172\nSt1\u2212s + 2\n\u221a\n\u2016\u2207t\u2016\u22172 2St1\u2212s\n(\n\u2016\u2207t\u2016\u22172 2St1\u2212s + \u03a6t\u22121\n)\n}\n7: end if\n8: \u03a6t \u2190 ht+\nCt1\u2212b\u03b32t 2(1\u2212b)\n1+ \u03b3t K\n9: vt \u2190 LPsepP(\u2211ti=1 \u2207 fi(xt), xt, \u03a6t, K) 10: if vt = false then 11: xt+1 \u2190 xt 12: else 13: xt+1 \u2190 (1 \u2212 \u03b3t)xt + \u03b3tvt 14: \u03a6t \u2190 ht \u2212 \u2211ti=1 fi(xt) + \u2211ti=1 fi(xt+1) 15: end if 16: end for\nTheorem 4.1. Let 0 \u2264 b, s < 1. Let K > 1 be an accuracy parameter. Assume ft is L-Lipschitz, and smooth with curvature at most Ct\u2212b. Let D := maxy1,y2\u2208P\u2016y1 \u2212 y2\u2016 denote the diameter of P in norm \u2016\u00b7\u2016. Then the following hold for the points xt computed by Algorithm 5 where x \u2217 T is the minimizer of \u2211 T t=1 ft:\n(i) With the choice\n\u03b3t = t \u2212(1\u2212b)/2,\nthe xt satisfy\n1\nT\nT\n\u2211 t=1\n( ft(xT)\u2212 ft(x\u2217T)) \u2264 AT\u2212(1\u2212b)/2, (11)\nwhere\nA := CK\n2(1 \u2212 b) + L(K + 1)D.\n(ii) Moreover, if all the ft are St \u2212s-strongly convex, then with the choice\n\u03b3t = t (b+s\u22122)/3,\nthe xt satisfy\n1\nT\nT\n\u2211 t=1\n( ft(xT)\u2212 ft(x\u2217T)) \u2264 AT\u2212(2(1+b)\u2212s)/3, (12)\nwhere\nA := 2\n(\n(K + 1)(K + 2) L2\nS +\nCK\n2(1\u2212 b)\n)\n.\nProof. We prove only Claim (ii), as the proof of Claim (i) is similar and simpler. Let FT := \u2211 T t=1 ft. Furthermore, let hT := AT 1\u2212(2(1+b)\u2212s)/3 be T times the right-hand side of Equation (12). In particular, FT is ST-strongly convex, and smooth with curvature at most CFT where\nCFT := CT1\u2212b 1 \u2212 b \u2265 C T\n\u2211 t=1\nt\u2212b, ST := ST1\u2212s \u2264 S T\n\u2211 t=1\nt\u2212s. (13)\nWe prove Ft(xt) \u2212 Ft(x\u2217t ) \u2264 ht \u2264 ht by induction on t. The case t = 1 is clear. Let \u03a6t denote the value of \u03a6t in Line 8, while we reserve \u03a6t to denote its value as used in Line 6. We start by showing Ft(xt+1)\u2212 Ft(x\u2217t ) \u2264 \u03a6t \u2264 \u03a6t. We distinguish two cases depending on vt from Line 9. If vt is false, then \u03a6t = \u03a6t and the weak separation oracle asserts maxy\u2208P \u2207Ft(xt)(xt \u2212 y) \u2264 \u03a6t, which combined with the convexity of Ft provides\nFt(xt+1)\u2212 Ft(x\u2217t ) = Ft(xt)\u2212 Ft(x\u2217t ) \u2264 \u2207Ft(xt)(xt \u2212 xt\u2217) \u2264 \u03a6t = \u03a6t.\nOtherwise vt is a vertex of P, then Line 14 and the induction hypothesis provides Ft(xt+1) \u2212 Ft(x\u2217t ) \u2264 ht + Ft(xt+1)\u2212 Ft(xt) = \u03a6t. To prove \u03a6t \u2264 \u03a6t, we apply the smoothness of Ft followed by the inequality provided by the choice of vt:\nFt(xt+1)\u2212 Ft(xt)\u2212 CFt \u03b3\n2 t\n2 \u2264 \u2207Ft(xt)(xt+1 \u2212 xt) = \u03b3t\u2207Ft(xt)(vt \u2212 xt) \u2264 \u2212 \u03b3t\u03a6t K .\nRearranging provides the inequality below.\n\u03a6t = ht + Ft(xt+1)\u2212 Ft(xt) \u2264 ht \u2212 \u03b3t\u03a6t\nK +\nCFt \u03b3 2 t\n2 = \u03a6t.\nFor later use, we bound the difference between ht and \u03a6t using the value of parameters, ht \u2264 ht, and \u03b3t \u2264 1:\nht \u2212 \u03a6t \u2265 ht \u2212 ht +\nCFt \u03b3 2 t\n2\n1 + \u03b3tK =\nht\u03b3t K \u2212\nCFt \u03b3 2 t\n2 1 + \u03b3tK \u2265\nht\u03b3t K \u2212\nCFt \u03b3 2 t\n2\n1 + 1K =\nA \u2212 CK 2(1\u2212b)\nK + 1 t[2s\u2212(1+b)]/3.\nWe now apply Ft(xt+1)\u2212 Ft(x\u2217t ) \u2264 \u03a6t, together with convexity of ft+1, and the minimality Ft(x\u2217t ) \u2264 Ft(x\u2217t+1) of x \u2217 t , followed by strong convexity of Ft+1:\nFt+1(xt+1)\u2212 Ft+1(x\u2217t+1) \u2264 (Ft(xt+1)\u2212 Ft(x\u2217t )) + ( ft+1(xt+1)\u2212 ft+1(x\u2217t+1)) \u2264 \u03a6t + \u2016\u2207t+1\u2016\u2217 \u00b7 \u2016xt+1 \u2212 x\u2217t+1\u2016\n\u2264 \u03a6t + \u2016\u2207t+1\u2016\u2217 \u221a 2\nSt+1 (Ft+1(xt+1)\u2212 Ft+1(x\u2217t+1)).\n(14)\nSolving the quadratic inequality provides\nFt+1(xt+1)\u2212 Ft+1(x\u2217t+1) \u2264 \u03a6t + \u2016\u2207t+1\u2016\u22172\nSt+1 + 2\n\u221a \u221a \u221a \u221a\n\u2016\u2207t+1\u2016\u22172 2St+1 ( \u2016\u2207t+1\u2016\u22172 2St+1 + \u03a6t ) . (15)\nFrom Equation (14), ignoring the last line, we also obtain Ft+1(xt+1)\u2212 Ft+1(x\u2217t+1) \u2264 \u03a6t + \u2016\u2207t+1\u2016 \u2217 D via the estimate \u2016xt+1 \u2212 x\u2217t+1\u2016 \u2264 D. Thus Ft+1(xt+1)\u2212 Ft+1(x\u2217t+1) \u2264 ht+1, by Line 6, as claimed. Nowwe estimate the right-hand side of Equation (15) by using the actual value of parameters, the estimate \u2016\u2207t+1\u2016\u2217 \u2264 L and the inequality s + b \u2264 2. Actually, we estimate a proxy for the right-hand side. Note that A was chosen to satisfy the second inequality.\nL2\nSt+1 + 2\n\u221a\nL2\n2St+1 ht \u2264\nL2\nSt1\u2212s + 2\n\u221a\nL2\n2St1\u2212s ht \u2264\nL2\nS t[2s\u2212(1+b)]/3 + 2\n\u221a\nL2\n2St1\u2212s ht\n=\n(\nL2\nS +\n\u221a\n2 L2\nS A\n) t[2s\u2212(1+b)]/3 \u2264 A \u2212 CK\n2(1\u2212b) K + 1 t[2s\u2212(1+b)]/3\n\u2264 ht \u2212 \u03a6t \u2264 ht \u2212 \u03a6t.\nIn particular, L 2 2St+1 + \u03a6t \u2264 ht hence combining with Equation (15) we obtain\nht+1 \u2264 \u03a6t + L2\nSt+1 + 2\n\u221a\nL2\n2St+1\n(\nL2\n2St+1 + \u03a6t\n)\n\u2264 \u03a6t + L2\nSt+1 + 2\n\u221a\nL2\n2St+1 ht\n\u2264 ht \u2264 ht+1."}, {"heading": "4.1 Stochastic and Adversarial Versions", "text": "Complementing the offline algorithms from Section 3, we will now derive various versions from the online case. The presented cases here are similar to those in Hazan and Kale [2012] and thus we state them without proof.\nFor stochastic cost functions ft, we obtain bounds from Theorem 4.1 (i) similar to [Hazan and Kale, 2012, Theorems 4.1 and 4.3] (with \u03b4 replaced by \u03b4/T in the bound to correct an inaccuracy in the original argument). The proof is analogous and hence omitted, but note that \u2016y1 \u2212 y2\u20162 \u2264 \u221a \u2016y1 \u2212 y2\u20161\u2016y1 \u2212 y2\u2016\u221e \u2264 \u221a\nk for all y1, y2 \u2208 P. Corollary 4.2. Let ft be convex functions sampled i.i.d. with expectation E [ ft] = f \u2217, and \u03b4 > 0. Assume that the ft are L-Lipschitz in the 2-norm.\n(i) If all the ft are smooth with curvature at most C, then Algorithm 5 applied to the ft (with b = 0) yields with probability 1 \u2212 \u03b4\nT\n\u2211 t=1\nf \u2217(xt)\u2212 min x\u2208P\nT\n\u2211 t=1\nf \u2217(x) \u2264 O ( C \u221a T + Lk \u221a nT log(nT2/\u03b4) log T ) . (16)\n(ii) Without any smoothness assumption, Algorithm 5 (applied to smoothenings of the ft) provides with probability 1 \u2212 \u03b4\nT\n\u2211 t=1\nf \u2217(xt)\u2212 min x\u2208P\nT\n\u2211 t=1\nf \u2217(x) \u2264 O (\u221a nLkT2/3 + Lk \u221a nT log(nT2/\u03b4) log T ) . (17)\nSimilar to [Hazan and Kale, 2012, Theorem 4.4], from Theorem 4.1 (ii) we obtain the following regret\nbound for adversarial cost functions with an analogous proof.\nCorollary 4.3. For any L-Lipschitz convex cost functions ft, Algorithm 5 applied to the functions f\u0303t(x) := \u2207 ft(xt)x + 2L\u221a k t\u22121/4\u2016x \u2212 x1\u201622 (with b = s = 1/4, C = L \u221a k, S = L/ \u221a k, and Lipschitz constant 3L) achieving regret T\n\u2211 t=1\nft(xt)\u2212 min x\u2208P\nT\n\u2211 t=1\nft(x) \u2264 O(L \u221a kT3/4) (18)\nwith at most T calls to the weak separation oracle.\nNote that the gradient of the f\u0303t are easily computed via the formula\u2207 f\u0303t(x) = \u2207 ft(xt) + 4Lt\u22121/4(x \u2212 x1)/ \u221a k, particularly because the gradient of the ft need not be recomputed, so that we obtain a weak separation-based stochastic gradient descent algorithm, where we only have access to the ft through a stochastic gradient oracle, while retaining all the favorable properties of the Frank-Wolfe algorithm with a convergence rate O(T\u22121/4) (c.f., Garber and Hazan [2013])."}, {"heading": "5 Experiments", "text": "We implemented and compared Algorithm 2 (LPCG) to the Pairwise Conditional Gradient Algorithm (PCG) in Garber and Meshi [2016] and we also implemented and compared Algorithm 5 (LOCG) to the Online Frank-WolfeAlgorithm (OCG) ofHazan and Kale [2012]. We did not implement the variant in Garber and Hazan [2013] as for the cases considered here the variant in Garber and Meshi [2016] is more efficient; our method applies to both though as shown earlier.\nWe implemented all algorithms in Python 2.7 with critical functions cythonized for performance, employing Numpy and MKL for arithmetic operations. We used these packages from the Anaconda 2.5 distribution.\nWe used Gurobi 6.5 [Gurobi Optimization, 2016] as a black box solver for the weak separation oracle, using a callback function to stop the optimization as soon as a good enough feasible solution has been found. We have used K = 1.1 as multiplicative factor for the weak separation oracle. The parameters for Gurobi were kept at their default settings except for enforcing the time limit of the tests and setting the acceptable duality gap to 10%, allowing Gurobi to terminate early avoiding the expensive proof of optimality. This is a significant speedup in favour of non-lazy algorithms at the cost of accuracy, while neutral to lazy optimization due to the callback. Without this modification, the non-lazy optimizing algorithms were unable to complete even a single iteration for almost all considered problems here, due to the hard optimality proof.\nThe linear optimization oracle over P \u00d7 P for LPCG was implemented by calling the respective oracle over P twice: once for either component.\nAll experiments were performed on a 16-core machine with Intel Xeon E5-2630 v3 @ 2.40GHz CPUs and 128GB of main memory. While our code does not explicitly use multiple threads, both Gurobi and the numerical libraries use multiple threads internally.\nContrary to the non-lazy version, the lazy algorithms depend on the initial upper bound \u03a60. Hence, in the initial phase, the lazy algorithms perform a binary search for \u03a60: starting from a conservative initial value, using the update rule \u03a60 \u2190 \u03a60/2 until the separation oracle returns an improvement for the first time. Obviously, this initial phase is also included in wall-clock time."}, {"heading": "5.1 Computational results", "text": "We performed computational tests on a large variety of different polytopes and loss functions. We considered polytopes where the underlying optimization problem is easy (spanning trees), and where it is NP-hard (Maximum Cut, Traveling Salesman Problem, Quadratic Unconstrained Boolean Optimization [Dash, 2013], as well as various instances from MIPLIB [Achterberg et al., 2006, Koch et al., 2011]). Note that in real-world examples state-of-the art solvers like Gurobi or CPLEX can solve these NP-hard problems in reasonable time, and hence enabling real-world learning over complex structure.\nWe tested two types of loss functions: random linear functions cx + b with c \u2208 [\u22121,+1]n and b \u2208 [0, 1] and quadratic functions of the form \u2016b \u2212 x\u201622 with b \u2208 [0, 1]n, similar to those in [Hazan and Kale, 2012]. For online algorithms, each experiment used a random sequence of 100 different random loss functions.\nWe used various time limits for the experiments. The time limit was enforced separately for the main\ncode, and the oracle code, so in some cases the actual time used can be larger.\nWe will now present the complete set of results for various polytopes. Every figure contains two columns, each reporting one experiment. The first row reports loss in wall-clock time (including time spent by the oracle), the second row contains loss in the number of iterations, and the third one the cumulative number of calls to the optimization oracle for the lazy algorithm. Red line denotes the non-lazy algorithm, and other colors denote lazy optimization.\nWhile we found convergence rates in the number of iterations quite similar (as expected!), we consistently observe a significant speedup in wall-clock time. In particular for many large-scale or hard combinatorial problems, lazy algorithms performed several thousand iterations whereas the non-lazy versions completed only a handful of iterations due to the large time spent for solving the linear optimization problem to optimality. Actually, the observed cache hit rate was in most cases at least 90%, and often even above 99%, leading to a significant overall speedup."}, {"heading": "5.1.1 Online Results", "text": "For online conditional gradient algorithms, in every figure the left column uses linear loss functions, the right one uses quadratic loss functions over the same polytope.\nWe used the flow-based formulation for Hamiltonian cycles in graphs, i.e., the traveling salesman problem (TSP) for graphs with 11 and 16 nodes (Figures 1 and 2). While relatively small, the oracle problem can be solved in reasonable time for these instances. For the maximumcut problemwe used the standard formulation of the cut polytope for graphs with 23 and 28 nodes (Figures 3 and 4). Another set of NP-hard instances we tested our algorithm on are the quadratic unconstrained boolean optimization (QUBO) instances defined on Chimera graphs [Dash, 2013], which are available athttp://researcher.watson.ibm.com/researcher/files/us-sanjeebd/chimera-data.zip. The instances are relatively hard albeit their rather small size (Figure 5 and 6). We also performed tests on a path instance from http://lime.cs.elte.hu/~kpeter/data/mcf/netgen/ that were generated with the netgen graph generator (Figure 7). Most of these instances are very large-scale minimum cost flow instances with several hundreds of thousands nodes in the underlying graphs, therefore solving still takes considerable time despite the problem being in P. We tested the MIPLIB [Achterberg et al., 2006, Koch et al., 2011]) instances eil33-2 (Figure 8) and air04 (Figure 9). For the spanning tree problem, we used the well-known extended formulation with O(n3) inequalities for an n-node graph. We considered graphs with 10 and 25 nodes (Figures 10 and 11).\nWe observed that while OCG and LOCG converge comparably in the number of iterations, the lazy LOCG performed significantly more iterations; for hard problems, where linear optimization is costly, and convergence requires a large number of iterations, this leaded LOCG converging much faster in wall-clock time. In extreme cases OCG could not complete even a single iteration. This is due to LOCG only requiring\nsome good enough solution, whereas OCG requires a (near) optimal one, which is reflected in faster oracle calls for LOCG."}, {"heading": "5.1.2 Offline Results", "text": "We tested the Pairwise ConditionalGradient AlgorithmonMIPLIB instanceseil33-2, air04, eilB101, nw04, disctom, m100n500k4r1 (Figures 12, 13 and 14) with quadratic loss functions only, as linear optimization immediately finds the optimum of a linear loss function. As we inherit structural restrictions of PCG on the feasible region, the problem repertoire is limited in this case.\nSimilarly to the online case, we observe a significant speedup of LPCG compared to PCG, due to the\nspeedier iteration of the lazy algorithm LPCG."}, {"heading": "5.2 Performance improvements, parameter sensitivity, and tuning", "text": ""}, {"heading": "5.2.1 Effect of caching", "text": "Asmentioned before, lazy algorithms have two improvements: caching and early termination. Herewe depict the effect of caching in Figure 15, comparing OCG (no caching, no early termination), LOCG (caching and early termination) and LOCG (only early termination). We did not include a caching OCG variant, because caching without early termination does not make much sense: in each iteration a new linear optimization problem has to be solved; previous solutions can hardly be reused as they are unlikely to be optimal for the new linear optimization problem."}, {"heading": "5.2.2 Effect of rate amplification", "text": "A major difference between the lazy and non-lazy algorithms is that lazy algorithms converge at a given rate, which is controlled via setting the \u03a6t in Line 8 of Algorithm 5, Line 4 of Algorithm 3, and Line 4 of Algorithm 2. In contrast, the non-lazy algorithms can in principle converge faster as they are parameter free and \u2018adjust\u2019 automatically to the underlying function family. However, we are free to choose a more aggressive rate that we might try to prove with lazy algorithms. This can be done by simply scaling \u03a6t with an additional term t\u2212\u03b1, right before passing it into the weak separation routine, where \u03b1 is an adjustment coefficient of the converge rate.\nWe have considered rate amplification only for the online algorithm LOCG, where subexponential con-\nvergence rates leave much room for improvement. We considered the following two possibilities.\nFirst, by choosing a more aggressive but feasible rate of convergence, LOCG will converge at that rate. Note that this rate can be strictly better than the rate achievable by OCG. It is an open question, whether the optimal rate is always achievable via LOCG by a suitable choice of \u03b1; we suspect the answer to be in the negative.\nIf the chosen rate is infeasible, i.e., we decrease \u03a6t too fast by having chosen \u03b1 too large, LOCG will converge to a suboptimal solution. This is expected and reasonable as the weak separation routine fails to produce an improving solution matching the proposed rate and as such returns the last point.\nWe depict the effect of various choices for \u03b1 in Figure 16. One might argue that the sensitivity to \u03b1 is undesirable. Therefore, second, we tested a simple dynamical adjustment of \u03b1, leading to an overall very smooth and consistent convergence behavior while using an amplified rate. We started with a value \u03b1 = 1 and whenever in k consecutive calls to the weak separation routine no improving solution is found, we update \u03b1 \u2190 (1 \u2212 \u03b5)\u03b1 with \u03b5 = 0.1. (The values for \u03b1 and \u03b5 are arbitrary.) Similarly, whenever in k consecutive calls to the weak separation routine an improving solution\nis returned, we update \u03b1 \u2190 (1 + \u03b5)\u03b1. This dynamic rate adjustment only depends on k and \u03b5 and is rather stable in k. Smaller k values lead to a more agile control, larger values of k to a more conservative one. We depict an example in Figure 17."}], "references": [{"title": "Regret in online combinatorial optimization", "author": ["J.-Y. Audibert", "S. Bubeck", "G. Lugosi"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Audibert et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Audibert et al\\.", "year": 2013}, {"title": "Following the perturbed leader for online structured learning", "author": ["A. Cohen", "T. Hazan"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning", "citeRegEx": "Cohen and Hazan.,? \\Q2015\\E", "shortCiteRegEx": "Cohen and Hazan.", "year": 2015}, {"title": "A note on QUBO instances defined on", "author": ["S. Dash"], "venue": "Chimera graphs. preprint arXiv:1306.1202,", "citeRegEx": "Dash.,? \\Q2013\\E", "shortCiteRegEx": "Dash.", "year": 2013}, {"title": "An algorithm for quadratic programming", "author": ["M. Frank", "P. Wolfe"], "venue": "Naval research logistics quarterly,", "citeRegEx": "Frank and Wolfe.,? \\Q1956\\E", "shortCiteRegEx": "Frank and Wolfe.", "year": 1956}, {"title": "A linearly convergent conditional gradient algorithm with applications to online and stochastic optimization", "author": ["D. Garber", "E. Hazan"], "venue": "arXiv preprint arXiv:1301.4666,", "citeRegEx": "Garber and Hazan.,? \\Q2013\\E", "shortCiteRegEx": "Garber and Hazan.", "year": 2013}, {"title": "Linear-memory and decomposition-invariant linearly convergent conditional gradient algorithm for structured polytopes", "author": ["D. Garber", "O. Meshi"], "venue": "arXiv preprint,", "citeRegEx": "Garber and Meshi.,? \\Q2016\\E", "shortCiteRegEx": "Garber and Meshi.", "year": 2016}, {"title": "Solving combinatorial games using products, projections and lexicographically optimal bases", "author": ["S. Gupta", "M. Goemans", "P. Jaillet"], "venue": "arXiv preprint arXiv:1603.00522,", "citeRegEx": "Gupta et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gupta et al\\.", "year": 2016}, {"title": "Introduction to online convex optimization", "author": ["E. Hazan"], "venue": "Foundations and Trends in Optimization,", "citeRegEx": "Hazan.,? \\Q2016\\E", "shortCiteRegEx": "Hazan.", "year": 2016}, {"title": "Projection-free online learning", "author": ["E. Hazan", "S. Kale"], "venue": "arXiv preprint arXiv:1206.4657,", "citeRegEx": "Hazan and Kale.,? \\Q2012\\E", "shortCiteRegEx": "Hazan and Kale.", "year": 2012}, {"title": "Revisiting Frank\u2013Wolfe: Projection-free sparse convex optimization", "author": ["M. Jaggi"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "Jaggi.,? \\Q2013\\E", "shortCiteRegEx": "Jaggi.", "year": 2013}, {"title": "Efficient algorithms for online decision problems", "author": ["A. Kalai", "S. Vempala"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Kalai and Vempala.,? \\Q2005\\E", "shortCiteRegEx": "Kalai and Vempala.", "year": 2005}, {"title": "Mathematical Programming Computation, 3(2):103\u2013163, 2011", "author": ["T. Koch", "T. Achterberg", "E. Andersen", "O. Bastert", "T. Berthold", "R.E. Bixby", "E. Danna", "G. Gamrath", "A.M. Gleixner", "S. Heinz", "A. Lodi", "H. Mittelmann", "T. Ralphs", "D. Salvagnin", "D.E. Steffy", "K. Wolter. MIPLIB"], "venue": "doi: 10.1007/s12532-011-0025-9. URL http://mpc.zib.de/index.php/MPC/article/view/56/28.", "citeRegEx": "Koch et al\\.,? 2010", "shortCiteRegEx": "Koch et al\\.", "year": 2010}, {"title": "On the global linear convergence of Frank\u2013Wolfe optimization variants", "author": ["S. Lacoste-Julien", "M. Jaggi"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Lacoste.Julien and Jaggi.,? \\Q2015\\E", "shortCiteRegEx": "Lacoste.Julien and Jaggi.", "year": 2015}, {"title": "Constrained minimization methods", "author": ["E.S. Levitin", "B.T. Polyak"], "venue": "USSR Computational mathematics and mathematical physics,", "citeRegEx": "Levitin and Polyak.,? \\Q1966\\E", "shortCiteRegEx": "Levitin and Polyak.", "year": 1966}], "referenceMentions": [{"referenceID": 3, "context": "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012].", "startOffset": 105, "endOffset": 128}, {"referenceID": 13, "context": "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012].", "startOffset": 173, "endOffset": 199}, {"referenceID": 9, "context": "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012].", "startOffset": 210, "endOffset": 223}, {"referenceID": 8, "context": "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012].", "startOffset": 264, "endOffset": 286}, {"referenceID": 3, "context": "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012]. These methods eschew the projection step and rather use a linear optimization oracle to stay within the feasible region. While convergence rates and regret bounds are often suboptimal, in many cases the gain due to only having to solve a single linear optimization problem over the feasible region in every iteration still leads to significant computational advantages (see e.g., [Hazan and Kale, 2012, Section 5]). This led to conditional gradients algorithms being often used for e.g., online optimization andmore generallymachine learning, especially because they also naturally generate sparse distributions over the extreme points of the feasible region. Further increasing the relevance of these methods, it was shown recently in Garber and Hazan [2013], Lacoste-Julien and Jaggi [2015], Garber and Meshi [2016] that conditional gradient methods often achieve linear convergence.", "startOffset": 106, "endOffset": 1048}, {"referenceID": 3, "context": "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012]. These methods eschew the projection step and rather use a linear optimization oracle to stay within the feasible region. While convergence rates and regret bounds are often suboptimal, in many cases the gain due to only having to solve a single linear optimization problem over the feasible region in every iteration still leads to significant computational advantages (see e.g., [Hazan and Kale, 2012, Section 5]). This led to conditional gradients algorithms being often used for e.g., online optimization andmore generallymachine learning, especially because they also naturally generate sparse distributions over the extreme points of the feasible region. Further increasing the relevance of these methods, it was shown recently in Garber and Hazan [2013], Lacoste-Julien and Jaggi [2015], Garber and Meshi [2016] that conditional gradient methods often achieve linear convergence.", "startOffset": 106, "endOffset": 1081}, {"referenceID": 3, "context": "Hence projectionfree methods gained a lot of attention recently, in particular the Frank-Wolfe algorithm [Frank and Wolfe, 1956] (also known as conditional gradient descent [Levitin and Polyak, 1966]; see also [Jaggi, 2013] for an overview) and its online version [Hazan and Kale, 2012]. These methods eschew the projection step and rather use a linear optimization oracle to stay within the feasible region. While convergence rates and regret bounds are often suboptimal, in many cases the gain due to only having to solve a single linear optimization problem over the feasible region in every iteration still leads to significant computational advantages (see e.g., [Hazan and Kale, 2012, Section 5]). This led to conditional gradients algorithms being often used for e.g., online optimization andmore generallymachine learning, especially because they also naturally generate sparse distributions over the extreme points of the feasible region. Further increasing the relevance of these methods, it was shown recently in Garber and Hazan [2013], Lacoste-Julien and Jaggi [2015], Garber and Meshi [2016] that conditional gradient methods often achieve linear convergence.", "startOffset": 106, "endOffset": 1106}, {"referenceID": 5, "context": "separation is significantly weaker than approximate minimization; the latter has been already considered in Jaggi [2013]. A (weak) separation oracle can be realized by a single call to a linear optimization oracle, however with two important differences.", "startOffset": 108, "endOffset": 121}, {"referenceID": 7, "context": ", 2013, Neu and Bart\u00f3k, 2013]), see [Hazan, 2016] for an exhaustive overview.", "startOffset": 36, "endOffset": 49}, {"referenceID": 2, "context": "Related Work In the offline setting we mimick the same setups as in Garber and Hazan [2013], Garber and Meshi [2016] respectively.", "startOffset": 68, "endOffset": 92}, {"referenceID": 2, "context": "Related Work In the offline setting we mimick the same setups as in Garber and Hazan [2013], Garber and Meshi [2016] respectively.", "startOffset": 68, "endOffset": 117}, {"referenceID": 2, "context": "Related Work In the offline setting we mimick the same setups as in Garber and Hazan [2013], Garber and Meshi [2016] respectively. In the online setup we mimick the setup of Hazan and Kale [2012]. Combinatorial convex optimization has been investigated in a long line of works (see e.", "startOffset": 68, "endOffset": 196}, {"referenceID": 4, "context": "We will first show how the Frank-Wolfe style algorithms in Garber and Hazan [2013] and Garber and Meshi [2016] can be lazified by means of a weak separation oracle as given in Oracle 1.", "startOffset": 59, "endOffset": 83}, {"referenceID": 4, "context": "We will first show how the Frank-Wolfe style algorithms in Garber and Hazan [2013] and Garber and Meshi [2016] can be lazified by means of a weak separation oracle as given in Oracle 1.", "startOffset": 59, "endOffset": 111}, {"referenceID": 9, "context": "1 Lazy Conditional Gradient: a basic example We start with lazifying the simplest Conditional Gradent algorithm, adapting the argument of the non-lazy version from Jaggi [2013]. While the vanilla version has suboptimal convergence rate O(1/T), its simplicity makes it an illustrative example of the main idea of lazification.", "startOffset": 164, "endOffset": 177}, {"referenceID": 5, "context": "2 Lazy Pairwise Conditional Gradients In this section we provide a lazy variant (Algorithm 2) of the Pairwise Conditional Gradient algorithm from Garber and Meshi [2016], using separation instead of linear optimization.", "startOffset": 146, "endOffset": 170}, {"referenceID": 4, "context": "3 Lazy Local Conditional Gradients In this sectionwe provide a lazy version (Algorithm3) of the conditional gradient algorithmfromGarber and Hazan [2013]. Let P \u2286 Rn be any polytope, D denote an upper bound on the l2-diameter of P, and \u03bc \u2265 1 be the affine invariant of P from Garber and Hazan [2013].", "startOffset": 130, "endOffset": 154}, {"referenceID": 4, "context": "3 Lazy Local Conditional Gradients In this sectionwe provide a lazy version (Algorithm3) of the conditional gradient algorithmfromGarber and Hazan [2013]. Let P \u2286 Rn be any polytope, D denote an upper bound on the l2-diameter of P, and \u03bc \u2265 1 be the affine invariant of P from Garber and Hazan [2013]. As the algorithm is not affine invariant by nature, we need a non-invariant version of smoothness: Recall that a convex function f is \u03b2-smooth if f (y)\u2212 f (x) \u2264 \u2207 f (x)(y \u2212 x) + \u03b2\u2016y \u2212 x\u2016/2.", "startOffset": 130, "endOffset": 300}, {"referenceID": 4, "context": "As an intermediary step, we first implement a local weak separation oracle in Algorithm4, a local version of Oracle 1, analogously to the local linear optimization oracle in Garber and Hazan [2013]. To this end, we recall a technical lemma from Garber and Hazan [2013].", "startOffset": 174, "endOffset": 198}, {"referenceID": 4, "context": "As an intermediary step, we first implement a local weak separation oracle in Algorithm4, a local version of Oracle 1, analogously to the local linear optimization oracle in Garber and Hazan [2013]. To this end, we recall a technical lemma from Garber and Hazan [2013]. Lemma 3.", "startOffset": 174, "endOffset": 269}, {"referenceID": 7, "context": "In this section we lazify the online conditional gradient algorithm of Hazan and Kale [2012] over arbitrary polytopes P = {x \u2208 Rn | Ax \u2264 b}, resulting in Algorithm 5.", "startOffset": 71, "endOffset": 93}, {"referenceID": 7, "context": "The presented cases here are similar to those in Hazan and Kale [2012] and thus we state them without proof.", "startOffset": 49, "endOffset": 71}, {"referenceID": 4, "context": ", Garber and Hazan [2013]).", "startOffset": 2, "endOffset": 26}, {"referenceID": 4, "context": "We implemented and compared Algorithm 2 (LPCG) to the Pairwise Conditional Gradient Algorithm (PCG) in Garber and Meshi [2016] and we also implemented and compared Algorithm 5 (LOCG) to the Online Frank-WolfeAlgorithm (OCG) ofHazan and Kale [2012].", "startOffset": 103, "endOffset": 127}, {"referenceID": 4, "context": "We implemented and compared Algorithm 2 (LPCG) to the Pairwise Conditional Gradient Algorithm (PCG) in Garber and Meshi [2016] and we also implemented and compared Algorithm 5 (LOCG) to the Online Frank-WolfeAlgorithm (OCG) ofHazan and Kale [2012]. We did not implement the variant in Garber and Hazan [2013] as for the cases considered here the variant in Garber and Meshi [2016] is more efficient; our method applies to both though as shown earlier.", "startOffset": 103, "endOffset": 248}, {"referenceID": 4, "context": "We did not implement the variant in Garber and Hazan [2013] as for the cases considered here the variant in Garber and Meshi [2016] is more efficient; our method applies to both though as shown earlier.", "startOffset": 36, "endOffset": 60}, {"referenceID": 4, "context": "We did not implement the variant in Garber and Hazan [2013] as for the cases considered here the variant in Garber and Meshi [2016] is more efficient; our method applies to both though as shown earlier.", "startOffset": 36, "endOffset": 132}, {"referenceID": 2, "context": "We considered polytopes where the underlying optimization problem is easy (spanning trees), and where it is NP-hard (Maximum Cut, Traveling Salesman Problem, Quadratic Unconstrained Boolean Optimization [Dash, 2013], as well as various instances from MIPLIB [Achterberg et al.", "startOffset": 203, "endOffset": 215}, {"referenceID": 8, "context": "We tested two types of loss functions: random linear functions cx + b with c \u2208 [\u22121,+1]n and b \u2208 [0, 1] and quadratic functions of the form \u2016b \u2212 x\u201622 with b \u2208 [0, 1]n, similar to those in [Hazan and Kale, 2012].", "startOffset": 187, "endOffset": 209}, {"referenceID": 2, "context": "Another set of NP-hard instances we tested our algorithm on are the quadratic unconstrained boolean optimization (QUBO) instances defined on Chimera graphs [Dash, 2013], which are available athttp://researcher.", "startOffset": 156, "endOffset": 168}], "year": 2017, "abstractText": "Conditional gradient algorithms (also often called Frank-Wolfe algorithms) are popular due to their simplicity of only requiring a linear optimization oracle and more recently they also gained significant traction for online learning. While simple in principle, inmany cases the actual implementation of the linear optimization oracle is costly. We show a general method to lazify various conditional gradient algorithms, which in actual computations leads to several orders of magnitude of speedup in wall-clock time. This is achieved by using a faster separation oracle instead of a linear optimization oracle, relying only on few linear optimization oracle calls.", "creator": "LaTeX with hyperref package"}}}