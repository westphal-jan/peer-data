{"id": "1610.08602", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Oct-2016", "title": "A Review of 40 Years of Cognitive Architecture Research: Core Cognitive Abilities and Practical Applications", "abstract": "In this paper, we present a comprehensive overview of the last 40 years of research on cognitive architectures. Although the number of existing architectures approaches a few hundred, most existing surveys do not reflect this growth and focus on a handful of well-established architectures. Although their contributions are undeniable, they represent only part of the research in this area. Therefore, in this study, we wanted to shift the focus toward a more comprehensive and comprehensive overview of research in cognitive architectures. To keep the length of this paper within reasonable limits, we discuss only the basic cognitive skills such as perception, attention mechanisms, learning and memory structure. To assess the range of practical applications of cognitive architectures, we have gathered information on 700 practical projects implemented using the cognitive architectures in our list.", "histories": [["v1", "Thu, 27 Oct 2016 03:48:33 GMT  (2127kb)", "http://arxiv.org/abs/1610.08602v1", "37 pages, 11 figures"], ["v2", "Fri, 8 Sep 2017 02:58:54 GMT  (2341kb)", "http://arxiv.org/abs/1610.08602v2", "63 pages, 10 figures"]], "COMMENTS": "37 pages, 11 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["iuliia kotseruba", "john k tsotsos"], "accepted": false, "id": "1610.08602"}, "pdf": {"name": "1610.08602.pdf", "metadata": {"source": "CRF", "title": "A Review of 40 Years of Cognitive Architecture Research: Focus on Perception, Attention, Learning and Applications", "authors": ["Iuliia Kotseruba", "Oscar J. Avella Gonzalez", "John K. Tsotsos"], "emails": ["yulia_k@cse.yorku.ca", "ojavellag@cse.yorku.ca", "tsotsos@cse.yorku.ca"], "sections": [{"heading": null, "text": "existing architectures is nearing several hundred, most of the existing surveys do not reflect this growth and focus on a handful of well-established architectures. While their contributions are undeniable, they represent only a part of the research in the field. Thus, in this survey we wanted to shift the focus towards a more inclusive and high-level overview of the research in cognitive architectures. Our final set of 86 architectures includes 55 that are still actively developed, and borrow from a diverse set of disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we discuss only the core cognitive abilities, such as perception, attention mechanisms, learning and memory structure. To assess the breadth of practical applications of cognitive architectures we gathered information on over 700 practical projects implemented using the cognitive architectures in our list.\nWe use various visualization techniques to highlight overall trends in the development of the field. For instance, our data confirms that the hybrid approach to cognitive modeling already dominates the field and will likely continue to do so in the future. Our analysis of practical applications shows that most architectures are very narrowly focused on a particular application domain. Furthermore, there is an apparent gap between general research in robotics and computer vision and research in these areas within the cognitive architectures field. It is very clear that biologically inspired models do not have the same range and efficiency compared to the systems based on engineering principles and heuristics. Another observation is related to a general lack of collaboration, which is surprising to see in the inherently interdisciplinary area of cognitive architectures. Several factors hinder communication, among which are the closed nature of the individual projects (only one-third of the reviewed here architectures are open-source) and terminological differences.\nKeywords: survey; cognitive architectures; perception; attention; learning; practical applications\n1 Introduction The goal of this paper is to provide a broad overview of the last 40 years of research in cognitive architectures with an emphasis on perception, attention and practical applications. Although the field of cognitive architectures has been steadily growing, most of the surveys published in the past 10 years do not reflect this growth and feature essentially the same set of a dozen most established architectures. The latest large-scale study was conducted in 2010 by Samsonovich et al. [1] in an attempt to catalog implemented cognitive architectures. Their survey contains descriptions of 54 cognitive architectures submitted by their respective authors. The same information is also presented online in a Comparative Table of Cognitive Architectures1. There are also other listings of cognitive architectures, but they rarely go beyond a short\ndescription and a link to the project site or a software repository.\nSince there is no exhaustive list of cognitive architectures, their exact number is unknown, but it is estimated to be around three hundred, out of which at least one-third of the projects are currently active. To form the initial list for our study we combined architectures mentioned in surveys (published within the last 10 years) and several large online catalogs. We also included more recent projects not yet mentioned in the survey literature. Figure 1 shows the visualization of 195 cognitive architectures featured in 17 sources (surveys, online catalogs and Google Scholar). It is apparent that a small group of architectures including ACT-R, Soar, CLARION, ICARUS, EPIC, RCS and LIDA is present in many sources, while all other projects are only briefly mentioned in online catalogs. While the theoretical and practical contributions of\n1 http://bicasociety.org/cogarch/architectures.htm\nthe major architectures are undeniable, they represent only part of the research in the field. Therefore, in this review we want to shift the focus from detailed descriptions of heavyweights, which has been done elsewhere, towards a high-level overview of the field.\nTo make this survey manageable we reduced the original list of architectures to 86 items. Since, our main focus is on implemented architectures with at least one practical application and several peer-reviewed publications, we do not consider some of the philosophical architectures (e.g. CogAff, Society of Mind, Global Workspace Theory, Pandemonium theory, etc.). We also exclude large scale brain modeling projects, which are low-level and do not easily map onto the breadth of cognitive capabilities modeled by other types of cognitive architectures. Further, many of the brain models do not have any practical applications yet, and thus do not fit the parameters of the present survey. Figure 2 shows all architectures featured in this survey with their approximate timelines recovered from the publications. Of these projects 55 are currently active.\nAs we mentioned earlier, the first step towards creating an inclusive and organized catalog of implemented cognitive architectures was made in [1]. This review contained extended descriptions of 26 projects with the following information: short overview, schematic diagram of major elements, common components and features (memory types, attention, consciousness, etc.), learning and cognitive development, cognitive modeling and applications, scalability and limitations. A survey of this kind brings together researchers from several disjoint communities and helps to establish a mapping between the different approaches and terminology they use. However, the descriptive or tabular format does not allow easy comparisons between architectures. Since our sample of architectures is large, we experimented with alternative visualization strategies, such as alluvial and circular diagrams which are frequently used for organizing complex tabular data. Interactive versions of these diagrams allow to explore the data and view relevant references.\nIn the following sections we will provide an overview of the definitions of cognition and approaches to grouping cognitive architectures. As one of our contributions, we map cognitive architectures according to their perception modality, implemented mechanisms of attention, memory organization, types of learning, and practical applications. Other features of cognitive architectures, such as metacognition, consciousness and emotion, are beyond the scope of this survey.\nIn the process of preparing this paper, we examined the literature widely and this activity led to a 2000 item bibliography of relevant publications. We provide this bibliography, with short summary descriptions for each paper as supplementary material2.\n2 What are Cognitive Architectures? Cognitive architectures are a part of research in general AI, which began in the 1950s with the goal of creating programs that could reason about problems across different domains, develop insights, adapt to new situations and reflect on themselves. Similarly, the ultimate goal of research in cognitive architectures is to achieve human-level artificial intelligence. According to Russell and Norvig [2] such artificial intelligence may be realized in four different ways: systems that think like humans, systems that think rationally, systems that act like humans, and systems that act rationally. The existing cognitive architectures have explored all four possibilities. For instance, human-like thought is pursued by the architectures stemming from cognitive modeling. In this case, the errors made by an intelligent system are tolerated as long as they match errors typically made by people in similar situations. This is in contrast to rationally thinking systems which are required to produce consistent and correct conclusions for arbitrary tasks. A similar distinction is made for machines that act like humans or act rationally. Machines in either of these groups are not expected to think like humans, only their actions or behavior is taken into account.\n2 Links to supplementary materials, bibliography and interactive diagrams are available at http://www.data.nvision2.eecs.yorku.ca/cognitive-architecture-survey.\nHowever, with no clear definition and general theory of cognition, each architecture was based on a different set of premises and assumptions, making comparison and evaluation difficult. Several papers were published to resolve the uncertainties, the most prominent being Sun\u2019s desiderata for cognitive architectures [3] and Newell\u2019s functional criteria (originally published in [4] and [5], and later restated by Anderson and Lebiere [6]). Newell\u2019s criteria include flexible behavior, real-time operation, rationality, large knowledge base, learning, development, linguistic abilities, self-awareness and brain realization. Sun\u2019s desiderata are broader and include ecological, cognitive and bio-evolutionary realism, adaptation, modularity, routineness and synergistic interaction. Besides defining these criteria and applying them to a range of cognitive architectures, Sun also pointed out the lack of clearly defined cognitive assumptions and methodological approaches, which hinder progress in studying intelligence. He also noted an uncertainty regarding essential dichotomies (implicit/explicit, procedural/declarative, etc.), modularity of cognition and structure of memory. However, a quick look at the existing cognitive architectures reveals persisting disagreements in terms of their research goals, structure, operation and application."}, {"heading": "EPIC", "text": "Instead of looking for a particular definition of intelligence, it may be more practical to define it as a set of competencies and behaviors demonstrated by the system. While no comprehensive list of capabilities required for intelligence exists, several broad areas have been identified that may serve as guidance for ongoing work in the cognitive architecture domain. For example, Adams et al. [7] suggest 14 areas, namely, perception, memory, attention, social interaction, planning, motivation, actuation, reasoning, communication, learning, emotion, modeling self/other, building/creation and arithmetic abilities. These are further split into subareas. Arguably, some of these categories may seem more important than the others and historically attracted more attention. For example, the list of cognitive functions frequently mentioned in the recent publications on cognitive architectures, according to Metzler and Shea [8], includes only perception, learning, reasoning, decision making, planning and acting. However, even implementing a reduced set of abilities in a single architecture is a substantial undertaking. Unsurprisingly, Artificial General Intelligence (AGI) is currently pursued by only a handful of architectures, among which are Soar, ACT-R, NARS [9], LIDA [10], and several recent projects, such as SiMA [11] and OpenCogPrime [12]. Others focus on a particular aspect of cognition, e.g. attention (ARCADIA [13], STAR [14]), emotion (CELTS [15]), perception of symmetry (the Cognitive Symmetry Engine [16]) or problem solving (FORR [17], PRODIGY [18]). There are also specialized architectures designed for particular applications, such as ARDIS [19] for visual inspection of surfaces or MusiCog [20] for music comprehension and generation.\nThe criteria on which a software system can be called a cognitive architecture are also rarely addressed. Most of the surveys broadly define cognitive architectures as a blueprint for intelligence, or more specifically, a proposal about the mental representations and computational procedures that operate on these representations enabling a range of intelligent behaviors ([21], [22], [23], [24], [25]). There is generally no need to justify inclusion of the established cognitive architectures such as Soar, ACT-R, EPIC, LIDA, ICARUS and a few others. However, when it comes to less common or new projects, reasons for considering them are less clear. As an example, AKIRA, a framework that explicitly does not self-identify as a cognitive architecture [26], is featured in some surveys anyway [27]. Similarly, a knowledge base Cyc [28], which does not make any claims about general intelligence is presented as an AGI architecture in [29].\nLaird in [30] discussed how cognitive architectures differ from other software systems. While all of them have memory storage, control components, data representation, and input/output devices, the former provide only a fixed model for general computation. Cognitive architectures, on the other hand, must change through development and efficiently use knowledge to perform new tasks. Furthermore, he suggests that agent architectures built using toolkits and frameworks also cannot be considered cognitive architectures because of their lack of theoretical commitments. This is a rather restricting set of conditions, which few architectures other than Soar and ACT-R would satisfy. This view is also not common in the\nsurvey literature, where agent architectures and toolkits used to build them are also included. For example, agent architectures 3T, PRS and ERE are reviewed in [31] and Pogamut, a framework for building intelligent agents, is included in [1].\nRecently, claims have been made that deep learning is capable of \u201csolving AI\u201d by Google (DeepMind3). Likewise, Facebook AI Research (FAIR4) and other companies are actively working in this direction.\nWhere does this work stand with respect to cognitive architectures? At present, some of the most publicized achievements of deep learning include vision processing for self-driving cars (Mobileye5) and Google\u2019s\nneural networks capable of playing Go [32] and multiple video games [33].\nOn the other hand, the publications by DeepMind, not advertised in media, cover a wider range of topics. Many papers, for instance, are dedicated to the theoretical problems related to recurrent and deep neural networks. In addition, neural networks are also used for building sophisticated models of visual attention and memory, for example, an attention-based model for recognizing multiple objects in the image (e.g. house number sequences) [34]. Memory is of special importance in the deep learning domain, since in order to find and exploit complex patterns in data, a network should be able to perform chains of sequential computations. However, in deep networks the information from past computations can be affected by new information. Grid Long Short-Term Memory (Grid LSTM) solves this problem by providing an ability to dynamically select or ignore inputs to retain important memory contents during learning [35].\nOverall, DeepMind research addresses a number of important issues in AI, such as natural language understanding, perceptual processing, general learning, and strategies for evaluating artificial intelligence. Although particular models already demonstrate cognitive abilities in limited domains, at this point they do not represent a unified model of intelligence.\nUnlike DeepMind, the Facebook research team explicitly discusses their work in the broad context of developing intelligent machines in [36]. Their main argument is that AI is too complex to be built all at once and instead its general characteristics should be defined first. Two such characteristics of intelligence are defined, namely, communication and learning, and a concrete roadmap is proposed for developing them incrementally. As a first step in this direction, an artificial ecosystem (or a \u201ckindergarten\u201d) is proposed for teaching an intelligent agent, thus emphasizing the developmental nature of the process. The plan is to start with a simpler simulated environment and gradually increase its complexity, until eventually it can connect the artificial agent to the real world. Given the emphasis on communication and learning, a primary application of such an intelligent machine would be an electronic assistant. Authors acknowledge that similar ideas have been tried in the past (e.g. Blocks World simulation, frequently used by symbolic architectures for learning), but relied too much on the data provided by their creators.\nCurrently there are no publications about developing such a system, but overall research topics pursued by FAIR align with their proposal for AI and also the business interests of the company. Common topics include visual processing, especially segmentation and object detection, data mining, natural language processing, human-computer interaction and network security. Since current deep learning techniques are mainly applied to solving practical problems and do not represent a unified framework we do not include them in this review. However, given their prevalence in other areas of AI, deep learning methods will likely play some role in the cognitive architectures of the future.\nFor the rest of the architectures we defined the following selection criteria, striving both for inclusiveness and consistency: self-identification as cognitive, robotic or agent architecture, existing implementation (not necessarily open-source), and mechanisms for perception, memory, attention and learning. To further limit the scope of the survey we required at least several peer-reviewed papers and existing applications beyond simple illustrative examples. In order to include some of the newer architectures still under development some of these conditions were relaxed.\n3 https://deepmind.com/ 4 https://research.facebook.com/ai/ 5 http://www.mobileye.com/\n3 Taxonomies of Cognitive Architectures Many papers published within the last decade address the problem of evaluation rather than the categorization of cognitive architectures. As mentioned earlier, Newell\u2019s criteria ([4], [5], [6]) and Sun's Desiderata [3] belong in this category. Similarly, Langley et al. [31] define a comprehensive list of capabilities, properties and evaluation criteria for cognitive architectures. The suggested set of cognitive capabilities includes recognition, decision making, perception, prediction, planning, acting, communication and learning. In order to evaluate the architectures, criteria such as generality, versatility and autonomy are proposed, among others. Along the same lines Vernon et al. [37] lists 12 characteristics to compare cognitivist and emergent approaches, which include embodiment, perception, action, adaptation, motivation, autonomy and others. Similarly, Asselman et al. [38] evaluate architectures based on 7 criteria (perception, memory, learning, modularity, goal setting, underlying model and problem-solving) and Thorisson and Helgasson [27] determine their level of autonomy based on 4 criteria (real-time operation, learning, attention and meta-learning).\nWhile many of these criteria could be used to classify the architectures, they are usually too fine-grained to be applied to a generic architecture. Thus it is more common to group cognitive architectures based on the type of information processing they represent. Three categories are defined: symbolic (also referred to as cognitivist), emergent (connectionist) and hybrid. This taxonomy based on information processing was extended by Duch et al. [21] to include typical memory and learning properties for each group (Figure 4). It has been used in other surveys as well ([38], [39]).\nSymbolic systems are often implemented as a set of if-then rules (also called production rules) that can be applied to a set of symbols representing the facts known about the world. Because it is a natural and intuitive representation of knowledge, symbolic manipulation remains very common. Although by design, symbolic systems excel at planning and reasoning, they lack the flexibility and robustness that are required for dealing with a changing environment and for perceptual processing.\nThe emergent approach resolves these issues by building massively parallel models, analogous to neural networks, where information flow is represented by a propagation of signals from the input nodes. However, the resulting system also loses its transparency, since knowledge is no longer a set of symbolic entities and instead is distributed throughout the network. For similar reasons, logical inference in a traditional sense becomes problematic in emergent architectures.\nNaturally, each paradigm has its strengths and weaknesses. For example, any symbolic architecture requires a lot of work to create an initial knowledge base, but once it is done the architecture is fully functional. On the other hand, emergent architectures are easier to design, but they must be trained in order to produce useful behavior. Furthermore, their existing knowledge may deteriorate with the subsequent learning of new behaviors.\nAs neither paradigm is capable of addressing all major AI issues, hybrid architectures attempt to\ncombine elements of both symbolic and emergent approaches. In general, there are no restrictions on how this hybridization is done, but some approaches may be more intuitive and easier to implement. For example, CLARION uses different representations depending on the type of knowledge: explicit factual knowledge is symbolic, while procedural implicit knowledge is subsymbolic [40]. 4CAPS combines a traditional symbolic production system interpreter with connectionist computational mechanisms such as thresholds, activations, weights, and parallel processing [41]. This type of hybridization is termed symbolicconnectionist by Duch et al. [21]. They also define an alternative - a localist-distributed approach. A good example of the latter is Leabra, which uses a localist representation for labels and distributed representation for features when learning invariant object detection [42]. In [43] the two types of hybridization are called a horizontal and vertical integration respectively. A more fine-grained classification of hybrid connectionist-symbolic models is presented in [44].\nInterestingly, emergent architectures have gained more weight only relatively recently, although\nresearch in this direction has been active for at least as long as traditional AI (Figure 2). For example,\nLangley et al. [22] do not include connectionist models in their survey since they do not demonstrate the same functionality as symbolic and hybrid models.\nGiven the advantages of the hybrid approach, it is not surprising that such architectures already are the most numerous with the tendency to grow even more (Figure 3). Thus, our data confirms a prediction made by Duch et al. [21] almost a decade ago.\nThere are not many alternative taxonomies in the literature. A scheme by Sun [47] (Figure 5) emphasizes modularity and communication between the modules. However, following this taxonomy requires implementation details for each architecture, which are often not available. Other classification schemes are very specific, e.g. the one by Gray [46], which focuses on the purpose and use of architectures (Figure 6).\nTherefore, in the present survey we follow the traditional distinction between symbolic, emergent and hybrid architectures. However, since the backgrounds of the architectures presented here span research areas from philosophy to neurobiology, we do not attempt to create a single organizational scheme to fit them all. Instead for each broad cognitive function, namely perception, attention, memory and learning, we extract the relevant data from the publications and group it by frequency.\n4 Perception Regardless of its design and purpose, an intelligent system cannot exist in isolation and requires an input to produce behavior. Perception is a process that transforms raw input into the system's internal representation for carrying out cognitive tasks. The amount and type of incoming perceptual data depends on the type and number of sensors available and cognitive capability of the intelligent system, i.e. what it can derive from this data.\nFigure 7 shows physical and virtual sensors used by cognitive architectures and their corresponding human senses: vision, hearing, touch, smell and proprioception. The taste modality is only featured in BBD robots and is simulated by the conductivity of the object [48]. Other sensory modalities that do not have a correlate among human senses are symbolic input (using keyboard or graphical user interface (GUI)) and various sensors such as LADAR, laser, IR, etc.\nproprioception. The \u201csensor\u201d category includes various sensors that do not correspond to any human senses. The \u201csymbolic input\u201d category means that input to the cognitive architecture is provided as text or through GUI. This does not include text input simulating audio, visual or any other information. Subcategories of the sensory modalities are shown as bands within the sectors (e.g. in vision subcategories include Kinect, monocular cameras, simulations, etc.). Ribbons are drawn between the sensory modalities and architectures that implement them. If an architecture implements several sensory modalities, the ribbons are drawn as more opaque. Visualization is created with www.circos.ca [49]. A list of perceptual modalities for each cognitive architecture with relevant references is included in supplementary materials and in the interactive version of the diagram.\nVision\nVision is the most represented sensory modality. This is evident from the diagram in Figure 7, where the corresponding circle segment is the largest. Even though the fact that in robotics various non-visual sensors and proprioception (e.g. odometry and bumpers) are used for solving visual tasks such as navigation, obstacle avoidance and search, visual input accounts for more than half of all possible input modalities.\nReal environments for embodied cognitive architectures vary both in size and visual complexity. For example, a planetary rover controlled by ATLANTIS performs cross-country navigation in a rough rocky terrain [50], salesman robot Gualzru (CORTEX [51]) moves around a large room full of people and iCub (MACsi [52]) recognizes and picks up various toys from the table. On the other hand, simple environments with no clutter or obstacles are also used in cognitive architectures research (BECCA [53], MDB [54]). In addition, color-coding objects is a common way of simplifying visual processing. For instance, ADAPT tracks a red ball rolling on the table [55] and DAC orients itself towards targets marked with different colors [56].\nCognitive architectures that operate in realistic unstructured environments usually approach vision as an engineering problem and construct chains of standard computer vision techniques for a particular situation. For example, obstacle avoidance in navigation tasks is solved in the same manner as in robot control architectures: 4D-RCS reconstructs the scene from stereo images and applies machine learning to LADAR data and color histograms to find traversable ground [57]. Similarly, the ATLANTIS robot architecture constructs a height map from stereo images and uses it to identify obstacles [58]. The CARACaS architecture also computes a map for hazard avoidance from stereo images and range sensors. In addition, it uses optical flow and model-based segmentation to identify the moving objects in the scene [59].\nA typical task in social robotics is detecting people and their gestures. Here too a combination of input from camera and sensors, and common vision techniques are frequently used. For instance, DIARC uses a neural network for face detection, laser readings for leg detection [60] and least-squares regression over SIFT features for object recognition [61]. The cognitive architecture for the child-like robot iCub utilizes SURFfeatures, AdaBoost learning and a mixture of Gaussians for hand detection and tracking [62]. RoboCog and CORTEX use camera and a proprietary software from Kinect to find people in a robotic salesman scenario [63]. Then, local binary patterns and a SVM classifier are trained to recognize particular persons and infer their gender and age [51]. Kismet, a social robot, uses simple motion detection, skin tone feature map and neural networks to find the faces and eyes of its caregivers [64].\nFewer systems incorporate biologically plausible vision. One of the most elaborate examples is the Leabra vision system called LVis [65], which is based on the anatomy of the ventral pathway of the brain: the primary visual cortex (V1), extrastriate areas (V2, V4) and the inferotemporal (IT) cortex. As in the human visual system, the receptive fields of neurons become less location specific and more featurally complex in the higher levels of the hierarchy. All layers are reciprocally connected, allowing the higherlevel information to influence the bottom-up processing during both the initial learning and subsequent recognition of objects, and contain local, recurrent inhibitory dynamics that limit activity levels across layers. Among its many applications, Leabra is able to distinguish dozens of object categories from synthetic images with noise and occlusion [66].\nThe visual system of Darwin VIII (BBD) is also modeled on the primate ventral visual pathway. Similarly to LVis, neurons in successive areas have progressively larger receptive fields. With this system on board Darwin VIII is able to segment a scene and categorize visual objects (simple shapes and colors) [67].\nThe SASE architecture implements a Staggered Hierarchical Mapping (SHM) for low-level visual feature processing. Although it does not replicate the structure of the human visual pathways, SHM is a hierarchical neural network with localized connections, where each neuron gets input from a restricted region in the previous layer. The sizes of receptive fields within one layer are the same and increase in higher levels [68]. SHM was tested on a SAIL robot in an indoor navigation scenario [69].\nOther biologically inspired neural networks are ART [70] and HTM [71] which are used for various\nvisual recognition and classification tasks.\nGiven that deep learning methods are becoming increasingly popular in computer vision it is surprising to see that not many cognitive architectures employ them. One example is a deep learning architecture DeSTIN, which processes visual input in the OpenCogPrime architecture [72].\nOverall, the architectures that work with realistic visual input, typically in robotics, tend to include specialized pipelines for each scenario, which is becoming easier with the widely available software toolkits such as OpenCV or Kinect API. On the other hand, the systems that try to model more general purpose and biologically plausible visual systems, such as, Leabra or BBD, are not as efficient and their applications are limited to controlled environments.\nSimulations are also commonly used as an alternative to visual processing. Despite varying visual complexity and realism, simulations usually provide the same data: objects, their properties (color, shape, label, etc.), locations and properties of the agent itself and sometimes environmental factors (e.g. weather). Some simulations provide pixel-level data, for example, the one used for the experiments with Leabra [42]. This simulation is represented by 100 categories of objects rendered in 3D with various illumination levels and partial occlusions. Otherwise, the visual realism of the simulation usually serves purely aesthetic purposes (CoJACK [73], Novamente [74], Pogamut [75]).\nAudition\nAudition is less commonly implemented in cognitive architectures. Sound or voice commands are typically used to guide an intelligent system or to communicate with it. Since the auditory modality is purely functional, most architectures resort to using available speech-to-text software rather than develop models of audition. Among the few architectures modeling auditory perception are ART, ACT-R and EPIC. For example, ARTWORD and ARTSTREAM were used to study integration [76] and a model of music interpretation was developed with ACT-R [77].\nMore commonly, dedicated software is used for speech processing, which helps to achieve a high degree of complexity and realism, as is demonstrated by the following example. A salesman robot controlled by the CORTEX architecture can understand and answer questions about itself using a Microsoft Kinect Speech SDK [51]. The Playmate system based on CoSy uses a Nuance Recognizer v8.5 software for speech processing [78] and can have a meaningful conversation in a subset of English. As an illustration, consider a typical dialog from Playmate [79]:\nHuman picks up the red square and puts down a red triangle to the right of the blue\nsquare. Robot: \"What is the thing to the right of the blue square?\" Human: \"It is a red triangle.\" Robot: \"Ok.\"\nThe FORR architecture uses speech recognition for the task of ordering books from the public library by phone. The architecture in this case increases the robustness of the automated speech recognition system based on an Olympus/RavenClaw pipeline (CMU) [80]. In this sample interaction, FX2 is the automated system, the user is a person calling and ASR shows the results of the speech processing:\nFX2: What title would you like? User: Family and Friends ASR: FAMILY.FRIENDS. FX2: I have two guesses. The first is Family and Friends. The second is Family\nHappiness. Is it either of these? User: The first one ASR: ..NEXT..FIRST. FX2: Let\u2019s try something else. Is the full title Family and Friends? User: Yes\nASR: YES\nOther examples of systems using off-the-shelf speech processing software include the Polyscheme using\nViaVoice [81] and ISAC with a Microsoft Speech engine [82].\nIt is easy to notice that most human-robot interactions have to follow a certain script in order to be successful. Some recent architectures, such as DIARC, aim at supporting more naturally sounding requests like \u201cCan you bring me something to cut a tomato?\u201d, however, they are still in the early stages of development [83].\nIn our sample of architectures, we find that most effort is directed at the linguistic and semantic information carried by speech and less attention is paid to the emotional content, e.g. loudness, speech rate, and intonation. Some attempts in this direction are made in social robotics. For example, the robot Kismet does not understand what is being said, but can determine approval, prohibition or soothing based on the prosodic contours of the speech [84]. A virtual agent Gendalf controlled by Ymir architecture also has a prosody analyzer together with a grammar-based speech recognizer that can understand a limited vocabulary of 100 words [85]. Even the sound itself can also be used as a cue, for example, the BBD robots can orient themselves toward the source of a loud sound [67].\nSymbolic input\nThe symbolic input category in Figure 7 combines several input methods which do not fall under physical sensors or simulations. These include input in the form of text commands and data, and through (GUI). Text input is typical for the architectures performing planning and logical inference tasks (e.g. NARS [9], OSCAR [86], MAX [87], Homer [88]). Text commands are usually written in terms of primitive predicates used in the architecture, so no additional parsing is required.\nAlthough many architectures have tools for visualization of results and the intermediate stages of computation, interactive GUIs are less common. They are mainly used in human performance research to simplify input of the expert knowledge and to allow multiple runs of the software with different parameters (IMPRINT [89], MAMID [90], OMAR [91], R-CAST [92]).\nThe data input can be in text or any other format, and is primarily used in the categorization and\nclassification applications (e.g. HTM [93], CSE [16], ART [94]).\n5 Attention Following Chun et al. [95] we consider two major categories of the attention mechanisms - external and internal. External or perceptual attention selects and modulates information incoming from various senses and internal attention modulates internally generated information, such as the contents of working memory or a set of possible behaviors in a given context6. Figure 8 shows common types of external and internal\nattention mechanisms. Here external (perceptual) attention is subdivided into region of interest (ROI) selection, gaze control, top-down (task-driven) and bottom-up (data-driven). Task selection is represented by three broad categories: predefined scenarios, planning, reactive actions and dynamic action selection. Predefined scenarios are usually represented by a predefined set of actions to perform (e.g., replicate an experiment) or in the form of finite state machine. Planning refers to a traditional planning approach common in many symbolic architectures. Here actions are selected automatically based on the computed plan. Reactive actions are typical for robotic systems, where they are connected to particular sensors and have priority over any other action. This feature is useful for safety in robotics (e.g., stop the robot if its bumper sensors touch an obstacle). Finally, dynamic action selection means that the next action depends\n6 Note that external and internal attention are not the same as exogenous (bottom-up, transient) and endogenous (top-down) attention. External attention here includes both top-down and bottom-up attention and any other mechanisms that involve perception. Internal attention involves only the internal action section mechanisms (such as emotions and drives), which may also be indirectly affected by external attention.\non multiple dynamic factors, such as the available sensory information, urgency, previous experience, biases due to emotions and drives, etc. Note that all these mechanisms are not exclusive and many architectures implement several of them at once. For example, FORR architecture integrates reactivity, situation-based behavior, and heuristic reasoning in a three-tiered hierarchical model [96]. Similar hierarchical decision making process is implemented in RCS [97].\nExternal attention A particular implementation of perceptual attention would differ depending on the sensory modality, so auditory data would be treated differently from the visual input. Several architectures can also modulate auditory data (OMAR [98], iCub [99] and MIDAS [100]), but otherwise visual attention is much more common.\nThe selection of visual data to attend can be data-driven (bottom-up) or task-driven (top-down). The bottom-up attentional mechanisms identify salient regions whose visual features are distinct from the surrounding image features, usually along a combination of dimensions, such as color channels, edges, motion, etc. Some architectures resort to the classical visual saliency algorithms, such as Guided Search [101] used by ACT-R [102] and Kismet [103], or the Itti-Koch-Niebur model [104] used by ARCADIA\n[13], iCub [99] and DAC [105]. Other approaches include filtering (DSO), finding unusual motion patterns (MACsi [106]) or discrepancies between observed and expected data (4D-RCS [107]).\nTop-down attention can be applied to further limit the sensory data provided by the bottom-up processing. For example, in visual search, knowing desired features of the object (e.g., the color red) can narrow down the options provided by the data-driven figure-ground segmentation. Many architectures resort to this mechanism to improve search efficiency (ACT-R [108], APEX [109], ARCADIA [110], CERA-CRANIUM [111], CHARISMA [112], DAC [105]). Another option is to use a hard-coded or learned heuristics. For example, CHREST looks at typical positions on a chess board [113] and MIDAS replicates common eye scan patterns of pilots [100]. The limitation of the current top-down approaches is that they can direct vision for only a limited set of predefined visual tasks, however ongoing research in STAR attempts to address this problem [114], [115].\nInternal attention Unlike external attention, which filters perceptual information, internal attention selects an appropriate action from a set of possibilities. The simplest mechanism of selection is reactive. Although few systems besides Subsumption [116] are purely reactive, hardcoded actions for particular scenarios, such as collision avoidance, are common in robotic architectures (e.g. PRS [117], ERE [118], ASMO [119]).\nThe cognitive architectures that run in a single thread or sequentially usually do not require a specific attention mechanism to select the next action or task. It happens automatically by arranging goals in a stack or queue. Since only one goal can be attended at a time, the one on top of the stack is always satisfied first. If the current goal cannot be reached, it is decomposed into subgoals, which are pushed onto the stack and attended sequentially. When all subgoals are successfully resolved, they are popped off the stack and the parent goal becomes the new focus of attention. The goals may be suspended or canceled if a more urgent goal is pushed onto the stack (e.g., bumpers on a robot signaling a collision). This approach is used in ICARUS [120], ACT-R [121], AIS [122], IMPRINT [123] and other primarily symbolic planners.\nA more flexible solution is to dynamically rank available actions based on their relevance to the current goal, urgency or previous success (e.g. CLARION [124], Pogamut [125], NARS [126], Ikon Flux [127], R-CAST [128], COGNET [129]). Since at every cognitive cycle the new sensory information may change the ranking of existing options or add new ones to the mix, these systems should theoretically be more adaptive. In addition to the perceptual evidence and past experience, other internal factors such as emotions or drives may also affect where the focus of attention will be moved next (ARS/SiMA [11]).\nDynamic attention control is also efficient in architectures that simulate cognition as multiple concurrent processes, where only a select few processes reach consciousness (associated with attention). Such architectures are based on the Global Workspace Theory of Baars [130] (ARCADIA [13], CERACRANIUM [131], CELTS [132], LIDA [133], MLECOG [134]) or Society of Mind by Minsky [135] (Cerebus [136]). Attention could be a separate process, evaluating each running process and selecting relevant ones, as in CELTS [137], or values could be updated as a result of interaction with other processes. The processes above threshold are then brought to attention automatically (CERA-CRANIUM [138], LIDA [139]).\n6 Memory Memory is an essential part of any systems-level cognitive model, regardless of whether the model is being used for studying the human mind or for solving engineering problems. For instance, all architectures featured in this review have memory systems that store intermediate results of computations, enabling learning and adaptation to the changing environment. However, despite their functional similarity, the particular implementations of memory systems differ significantly and depend on the research goals and conceptual limitations, such as biological plausibility, as well as engineering factors (e.g. programming language, software architecture, use of frameworks, etc.). Broadly speaking, there are two approaches to modeling memory: 1) introducing distinct memory stores based on duration (short- and long-term) and type\n(procedural, declarative, semantic, etc.), and 2) a single memory structure representing several types of knowledge.\nThe first approach is influenced by the multi-store memory model of Atkinson-Shiffrin (1968) [140], later modified by Baddeley (1976) [141]. Although these theories are dominant in psychology, their validity for engineering is questioned by some because they do not provide a functional description of various memory mechanisms [142]. Nevertheless, most architectures distinguish between various memory types, although the naming conventions differ depending on the conceptual background. For instance, the architectures designed for planning and problem solving have short- and long-term memory storage systems, but do not use terminology from cognitive psychology. The long-term knowledge in planners is usually referred to as a knowledge base for facts and a set of problem-solving rules, which correspond to semantic and procedural long-term memory (e.g. Disciple [143], MACsi [106], PRS [144], ARDIS [145], ATLANTIS [146], IMPRINT). Some architectures also save previously implemented tasks and solved problems, imitating episodic memory (REM [147], PRODIGY [148]). The short-term storage in planners is usually represented by a current world model and a contents of the goal stack.\nFigure 9 shows a visualization of various types of memory implemented by the architectures. Here we primarily distinguish between the long-term and short-term storage. Long-term storage is further subdivided into episodic, semantic and procedural types, which store episodes from the personal experience of the system, factual knowledge and information on what actions should be taken under certain conditions respectively. Short-term storage is split into short-term memory (STM) and working memory (WM) following [149]. STM is a very short-term buffer that stores several recent percepts. It is also referred to as perceptual or sensory memory in some architectures. Working memory is a temporary storage for percepts that also contains other items related to the current task and is frequently associated with the current focus of attention.\nShort-term memory Only a few architectures implement short-term or sensory memory, which is a buffer for temporarily holding the incoming sensory data before it is transferred to other memory structures. Iconic visual memory is part of ACT-R [102], ARCADIA [110], EPIC [150], LIDA [151] and Pogamut [125]. MusiCog implements echoic memory, a sensory memory for auditory signals [152]. In all these architectures the sensory buffer preprocesses and stores recently seen (or heard) information from tens to hundreds of milliseconds.\nWorking memory Working memory is defined as a mechanism for the temporary storage of information related to the current task. In principle, any computation inherently requires a temporary storage for partial and intermediate data, therefore every cognitive architecture on our list implements working memory to some extent. Based on the publications we reviewed, many architectures implement working memory as a dynamic storage with no explicitly defined capacity. For example, in APEX, semantic working memory is represented by an assertional database with timestamped propositions [153], BECCA keeps a weighted combination of several recently attended features and any recent actions [154], in MAMID working memory contains a currently activated set of instructions [155], and Companions utilize working memory as a cache for intermediate results [156]. Similar definitions are given for DSO [157], DIARC [61], CoSy [158], etc.\nSince, by definition, working memory is a relatively small temporary storage, for biological realism, its capacity should be limited. However, there is no agreed upon way of how this should be done. For instance, in GLAIR the contents of working memory are discarded when the agent switches to a new problem [159]. A more common approach is to gradually remove items from the memory based on their recency or relevance in the changing context. The CELTS architecture implements this principle by assigning an activation level to percepts that is proportional to the emotional valence of a perceived situation. This activation level changes over time and as soon as it falls below a set threshold, the percept is discarded [160]. The Novamente Cognitive Engine has a similar mechanism, where atoms stay in memory as long as they build links to other memory elements and increase their utility [161]. It is still unclear if under these conditions the size of working memory can grow substantially without any additional restrictions.\nA simpler solution is to set a hard limit on the number of items in memory, for example 3-6 objects in ARCADIA [110], 4 chunks in CHREST [162] or up to 20 items in MDB, and delete the oldest or the most irrelevant item to avoid overflow.\nItems can also be discarded if they have not been used for some time. The exact amount of time varies from 4-9 seconds (EPIC [150]) to 5 sec (MIDAS [163], CERA-CRANIUM [131]) to tens of seconds (LIDA [164]).\nIn the Recommendation Architecture the limit of 3-4 items in working memory emerges naturally from\nthe structure of the memory system [165].\nLong-term memory Long-term memory (LTM) preserves a large amount of information for a very long time. Typically, it is divided into procedural memory of implicit knowledge (e.g. motor skills and routine behaviors) and\ndeclarative memory, which contains (explicit) knowledge. The latter is further subdivided into semantic (factual) and episodic (autobiographical) memory.\nThe dichotomies between the explicit/implicit and the declarative/procedural long-term memories are usually merged. One of the few exceptions is CLARION, where procedural and declarative memories are separate and both subdivided into an implicit and explicit component. This distinction is preserved on the level of knowledge representation: implicit knowledge is captured by distributed subsymbolic structures like neural networks, while explicit knowledge has a transparent symbolic representation [166].\nLong-term memory is a storage for innate knowledge that enables operation of the system, therefore almost all architectures implement procedural and/or semantic memory. Procedural memory contains knowledge about how to get things done in the task domain. In symbolic production systems, procedural knowledge is represented by a set of if-then rules preprogrammed or learned for a particular domain (3T [167], 4CAPS [41], ACT-R [168], ARDIS [145], EPIC [169], SAL [170], Soar [171], APEX [172]). Other variations include sensory-motor schemas (ADAPT [173]), task schemas (ATLANTIS [146]) and behavioral scripts (FORR [174]). In emergent systems, procedural memory may contain sequences of stateaction pairs (BECCA [53]) or ANNs representing perceptual-motor associations (MDB [175]).\nSemantic memory stores facts about the objects and relationships between them. In the architectures that support symbolic reasoning, semantic knowledge is typically implemented as a network-line ontology, where nodes correspond to concepts and links represent relationships between them (Casimir [176], Cerebus [177], Disciple [178], MIDAS [179], Soar [171], CHREST [180]). In emergent architectures factual knowledge is represented as patterns of activity within the network (BBD [181], SHRUTI [182], HTM [183], ART [184]).\nEpisodic memory stores specific instances of past experience. These can later be reused if a similar situation arises (MAX [185], OMAR [186], iCub [187], Ymir [85]). However, these experiences can also be exploited for learning new semantic or procedural knowledge. For example, CLARION saves actionoriented experiences as \u201cinput, output, result\u201d and uses them to bias future behavior [188]. Similarly, BECCA stores sequences of state-action pairs to make predictions and guide the selection of system actions [53], and MLECOG gradually builds 3D scene representation from perceived situations [189]. MAMID [190] saves the past experience together with the specific affective connotations (positive or negative), which affect the likelihood of selecting similar actions in the future. Other examples include R-CAST [191], Soar [192], Novamente [193] and Theo [194].\nDespite the evidence for the different memory systems, some architectures do not have separate representations for different kinds of knowledge or short- vs long-term memory, and instead use a unified structure to store all information in the system. CORTEX and RoboCog use an integrated, dynamic multigraph object which can represent both sensory data and high-level symbols describing the state of the robot and the environment ([51], [195]). DiPRA uses Fuzzy Cognitive Maps to represent goals and plans [196]. NARS represents all empirical knowledge, regardless of whether its declarative, episodic or procedural, as formal sentences in Narcese [197].\n7 Learning Learning is the capability of a system to improve its performance over time. Ultimately, any kind of learning is based on experience. For example, a system may be able to infer facts and behaviors from observed events or from results of its own actions. The type of learning and its realization depend on many factors, such as design paradigm (e.g. biological, psychological), application scenario, data structures and the algorithms used for implementing the architecture, etc. However, we will not attempt to analyze all these aspects given the diversity and number of the cognitive architectures surveyed. Besides, not all of these pieces of information can be easily found in the publications.\nThus, a more general summary is preferable, where four types of learning are defined: perceptual,\ndeclarative, procedural and attentional. Perceptual learning involves improving skills for processing\nperceptual data, such as recognition, discrimination, categorization, building spatial maps or finding any sort of patterns that could be further exploited. Declarative learning expands semantic knowledge about the world, specifically, the explicit knowledge of facts and relations between them. This knowledge may be learned from experience in the process of solving a problem (e.g. in production systems chunks are automatically added to memory as each goal is completed). Procedural learning enables modifying existing behaviors or generating new ones by committing to memory successful actions to be reused later (specialized behaviors) or by extending known procedures to new circumstances (generalized behaviors). Finally, attentional learning allows improvement in the way the system modifies the action selection rules through accumulating statistics of previous successes and failures of completed actions, reward mechanisms (various kinds of reinforcement learning) or via emotions and drives.\nMore involved cases combine several types of learning at once. A typical example is sensorimotor learning, where a system finds associations between percepts and behaviors. Knowledge is usually obtained in two stages: initially random actions are performed to accrue experience in the form of <action, percept> associations, followed by fitting a model to the accumulated data. This type of learning has been used for navigation and for learning spatial affordances from sensory data (e.g. FORR [198], iCub [199]).\nThere are also 22 architectures that do not implement any learning. In some areas of research learning is not necessary, for example, in human performance modeling, where accurate replication of human performance data is required instead (e.g. APEX, EPIC, IMPRINT, MAMID, MIDAS, etc.). Some of the newer architectures are still in the early development stage and may implement learning in the future (e.g. ARCADIA, SiMA).\nFigure 10 shows a visualization of the learning types for all cognitive architectures. Here the 4 types of\nlearning are further subdivided into categories and linked to the architectures implementing them."}, {"heading": "Perceptual learning", "text": "Although many systems use pre-learned components for processing perceptual data, such as object and face detectors or classifiers, we do not consider these here. Perceptual learning applies to architectures that actively change the way sensory information is handled or how patterns are learned online. This kind of learning is frequently performed to obtain implicit knowledge about the environment, such as spatial maps (4D-RCS [200], AIS [201], MicroPsi [202]), clustering visual features (HTM [203], BECCA [204], Leabra [42]) or finding associations between percepts. The latter can be used within the same sensory modality as in the case of the agent controlled by Novamente engine, which selects a picture of the object it wants to get from a teacher [205]. Learning can also occur between different modalities, for instance, the robot based on SASE architecture learns association between spoken command and action [69] and Darwin VII (BBD) learns to associate taste value of the blocks with their visual properties [206]."}, {"heading": "Declarative learning", "text": "Declarative knowledge is a collection of facts about the world and various relationships defined between them. In production systems such as ACT-R, Soar and others, which implement chunking mechanisms (SAL [207], ADAPT [208], CHREST [209], CLARION [40]), learning new declarative knowledge is automatic. That is to say, each time a goal is completed, a new chunk is added to declarative memory. Automatic acquisition of knowledge has also been demonstrated in systems with distributed representations. For example, in DSO knowledge can be directly input by human experts or learned as contextual information extracted from labeled training data [210]. New symbolic knowledge can also be acquired by applying logical inference rules to already known facts (GMU-BICA [211], Disciple [212], Casimir [176], NARS [213]). In the biologically inspired systems learning new concepts usually takes the form of learning the correspondence between the visual features of the object and its name (iCub [214], Leabra [42], MACsi [106], Novamente [205], CoSy [79], DIARC [215])."}, {"heading": "Procedural learning", "text": "Procedural learning allows an intelligent system to acquire new behaviors or modify existing ones. The simplest way of doing so is by accumulating examples of successfully solved problems to be reused later. For instance, in a navigation task, a traversed path could be saved and used again to go between the same locations later (AIS [201]). The same applies to reasoning tasks, however, in this case previously generated plans or solutions would be added to memory (Companions [216], RoboCog [217]). Obviously, this type of learning is very limited and further processing of accumulated experience is needed for better efficiency\nand flexibility. Many examples of procedural learning using episodic learning have been described in the\nprevious chapter."}, {"heading": "Attentional learning", "text": "Attentional learning affects the action selection process by adjusting the relative priority of the actions or concepts according to their experienced usefulness and relevance. The utility of a rule or action could be inferred from statistics of the past applications (Theo [194], NARS [218]), although reward-driven (reinforcement) learning is far more common and is not restricted to biologically inspired systems (e.g. 4DRCS [219], RALPH [220], BBD [221], CARACaS [222], FORR [223], ICARUS [224], etc.). Emotions\nand drives are additional factors regulating attention of the intelligent agent, although the associations between emotions and actions are usually predefined.\n8 Applications of Cognitive Architectures Most of the cognitive architectures reviewed in this paper are research tools and few are developed outside of academia. However, it is still appropriate to talk about their practical applications, since useful behavior in various situations is declared as a goal of many cognitive architectures.\nAfter a thorough search through the publications we identified more than 700 projects implemented using 86 cognitive architectures, which are shown in Figure 11. All applications were split into major groups, namely human performance modeling (HPM), games and puzzles, robotics, psychological experiments, natural language processing (NLP) and miscellaneous, which included projects not related to any major group but too rare to be separated into a group of their own. Such grouping of projects emphasizes the application aspect of each project, although the goal of the researchers may have been different.\nFor example, navigation using a mobile robot, regardless of whether it was achieved by reasoning or was done as a demonstration of a learning algorithm, is placed in the robotics group. The only exception from the rule are psychological experiments, which also include psychophysiological, fMRI and EEG experiments. The projects in this group are the particular psychological experiments (e.g. n-back task, conditioning or attentional blindness) performed by the cognitive architecture and compared against human data. The category of games and puzzles includes applications to playing board games, video games, solving puzzles and logical reasoning in various domains. HPM is concerned with building models of aircraft crews [225], operators of the nuclear power plant [226], people performing other complex tasks, e.g. telephone operators and air traffic operators. Most NLP applications are concerned with understanding and answering questions given as spoken or typed commands and are related to social robotics, however there are also projects in this group dedicated to sense disambiguation and sentence comprehension in general. Some applications belong to more than one group. For example, Soar has been used to play board games with a robotic arm [227], which is relevant to robotics and games and puzzles. Similarly, ACT-R model of Tower of Hanoi compared to human fMRI data [228] belongs to games and puzzles and psychological experiments. To avoid overcomplicating the diagram, in these cases we placed the project in the dominant group, in the case of Soar that would be game playing, since the contribution to robotics was not as significant, and psychological experiments group for the fMRI experiments using ACT-R.\nHuman Performance Modeling (HPM) Human performance modeling is an area of research concerned with building quantitative models of human performance in a specific task environment. The need for such models comes from engineering domains where the space of design possibilities is too large, so that empirical assessment is infeasible or too costly.\nThis type of modeling has been used extensively for military applications, for example, workload analysis of Apache helicopter crew [229], modeling the impact of communication tasks on the battlefield awareness [230], decision making in the AAW domain [231], etc. Common civil applications include models of air traffic control task (e.g. COGNET [232]), aircraft taxi errors [233], 911 dispatch operator HPM is dominated by a handful of specialized architectures, including OMAR, APEX, COGNET, MIDAS and IMPRINT. Soar was used to implement a pilot model for large-scale distributed military simulations (TacAir-Soar) [234], [235].\nHuman-Robot Interaction (HRI) HRI is a multidisciplinary field studying various aspects of communication between people and robots. Most of these interactions occur in the context of social, assistive or developmental robotics. Depending on\nthe level of autonomy demonstrated by the robot, interactions extend from direct control (teleoperation) to full autonomy of the robot enabling peer-to-peer collaboration. Although none of the systems presented in this survey are yet capable of full autonomy, they allow for some level of supervisory control ranging from single vowels signifying direction of movement for a robot (SASE [236]) to natural language instruction\nincluded in supplementary materials and can also be viewed in the interactive version of this diagram.\n(e.g. Soar [237], HOMER [88], iCub [238]). It is usually assumed that a command is of particular form and uses a limited vocabulary.\nSome architectures also target non-verbal aspects of HRI, for example natural turn-taking in a dialogue (Ymir [239], Kismet [240]), changing facial expression (Kismet [241]) or turning towards the caregiver (MACsi [242]).\nNatural Language Processing (NLP) The applications in this group are concerned with understanding written or spoken language. Although it is common for cognitive architectures to use off-the-shelf software for speech recognition and text parsing, some architectures contributed to the NLP research. Specific examples are anaphora resolution (Polyscheme [243], NARS [244], DIARC [245]), speech recognition benchmarks (Sigma [246], [247], SASE [248]) and learning English passive voice (NARS [244]).\nCategorization and Clustering Categorization, classification, pattern recognition and clustering are common ways of extracting general information from large datasets. In the context of cognitive architectures, these methods are useful for processing noisy sensory data. Applications in this group are almost entirely implemented by emergent architectures, such as ART and HTM, which are used as sophisticated neural networks. The ART networks, in particular, have been applied to classification problems in a wide range of domains: movie recommendations (Netflix dataset [249]), medical diagnosis (Pima-Indian diabetes dataset [250]), fault diagnostics (pneumatic system analysis [251]), vowel recognition (Peterson and Barney dataset [252]), odor identification [253], etc. The HTM architecture is geared towards the analysis of time series data, such as predicting IT failures (grokstream.com), monitoring stocks (numenta.com/htm-for-stocks), predicting taxi passenger demand [254] and recognition of cell phone usage type (email, call, etc.) based on the pressed key pattern [255].\nA few other examples from non-emergent architectures include gesture recognition from tracking suits (Ymir [256]), diagnosis of the failures in a telecommunications network (PRS [257]) and document categorization based on the information about authors and citations (OpenCogPrime [258]).\nComputer Vision Emergent cognitive architectures are also widely applied to solving typical computer vision problems. However, these are mainly standalone examples, such as hand-written character recognition (HTM [259], [260]), image classification benchmarks (HTM [261], [262]), view-invariant letter recognition (ART [263]), texture classification benchmarks (ART [264]), invariant object recognition (Leabra [265]), etc.\nThe computer vision applications that are part of more involved tasks, for example for navigation in\nrobotics, are discussed in the relevant sections.\nGames and Puzzles The category of games and puzzles includes applications like playing board games, video games and problem solving in limited domains. The simple board games with conceptual overlap like tic-tac-toe, the eight puzzle and the five puzzle are frequently used to demonstrate knowledge transfer (e.g. Soar [227], FORR [266]).\nVideo games are also used as virtual domains for cognitive architectures. By far the most popular is Unreal Tournament 2004 (UT2004), for which there is an open-source software toolkit Pogamut [267] making it easier to create intelligent virtual characters. Besides, there are several game playing competitions, which focus not only on the scores and efficiency, but also take into account the believability\nof the agent (2K BotPrize Contest7). Although Pogamut in itself implements many cognitive functions, it\nis also a recommended middleware for the BotPrize contest and is used with modifications by other groups to implement the UT2004 bots ([268], [269], [270], [271], [271], [272]). Other video games are Freeciv (REM [273]), Atari Frogger II (Soar [274]), Infinite Mario (Soar [275]), browser games (STAR [276]) and custom made games.\nPsychological Experiments The psychological experiments group includes replications of a number of psychophysiological, fMRI and EEG experiments using cognitive architectures. Here the goal is either to demonstrate that a cognitive architecture can numerically model human data or give reasonable explanations for existing psychological phenomena. If data produced by a simulation matches the human data in some or most aspects, this is taken as an indication that a given cognitive architecture can imitate human reasoning. The cognitive model can then be either used for making predictions about behaviors in different situations or analyzed further and used as an explanation for the psychological mechanisms behind known phenomena.\nMost of the experiments are conducted in simulated environments, although there are some examples\nimplemented on a physical robot (e.g. a model of perceptual categorization on DarwinVII robot [181]).\nRobotics There are numerous applications of cognitive architectures in robotics. Navigation and obstacle avoidance are basic behaviors, which can be useful on their own or used as part of more complex behaviors, for example in assistive robotics.\nThe fetch and carry tasks were very popular in the early days of robotics research as an effective demonstration of robot abilities. Some well-known examples include a trash collecting mobile robot (3T [277]) and a soda can collecting robot (Subsumption [278]). Through a combination of simple vision techniques such as edge detection and template matching, and sensors for navigation, these robots were able to find the objects of interest in unknown environments.\nMore recent cognitive architectures tend to solve search and object manipulation tasks separately. Typically, experiments involving visual search are done in very controlled environments and preference is given to objects with bright colors or recognizable shapes to minimize visual processing. Sometimes markers are used, such as printed barcodes attached to the object, to simplify recognition (Soar [279]). It is important to note that visual search in these cases is usually a part of a more involved task, such as learning by instruction. When visual search and localization is the end goal, the environments are more realistic (e.g. the robot controlled by CoSy finds a book on a cluttered shelf using a combination of sensors and SIFT features [280]).\nObject manipulation involves arm control to reach and grasp an object. While reaching is a relatively easy problem and many architectures implement some form of arm control, gripping is more challenging even in a simulated environment. Complexity of grasping depends on many factors including the type of gripper and properties of the object. One workaround is to experiment with grasping on soft objects, such as plush toys (ISAC [281]). More recent work involves objects with different grasping types (objects with handles located on top or on a side) demonstrated on a robot controlled by DIARC [282], [282]. Another example is iCub adapting its grasp to cans of different sizes, boxes and a ruler [283].\nOther applications include robotic salesman, tutor, medical robots, etc. Industrial applications are represented by a single architecture - 4D-RCS, which has been used for teleoperated robotic crane operation [284], bridge construction [285], autonomous cleaning and deburring workstation [286], and the automated stamp distribution center for the US Postal Service [287].\n7 http://botprize.org\nVirtual Agents Simulations and virtual reality are frequently used as an alternative to physical embodiment. For instance, in the military domain, simulations model behavior of soldiers in dangerous situations without risking their lives. Some examples include modeling agents in a suicide bomber scenario (CoJACK [73]), peacekeeping mission training (MAMID [190]), command and control in complex and urban terrain (RCAST [288]) and tank battle simulation (CoJACK [289]).\nSimulations are also common for modeling behaviors of intelligent agents in civil applications. One of the advantages of virtual environments is that they can provide useful information about the state of the agent at any point in time. This is useful for studying the effect of emotions on actions, for example, in the social interaction context (ARS/SiMA [290]), or in learning scenarios, such as playing fetch with a virtual dog (Novamente [291]).\n9 Discussion The main contribution of this survey is in gathering and summarizing information on a large number of cognitive architectures from various backgrounds (computer science, psychology, philosophy and neuroscience). In particular, we described common approaches to implementing important aspects of human cognition, such as perception, attention and memory. We also try to answer the question of what are the practical capabilities of the existing architectures by categorizing their demonstrated applications. Finally, we have identified some general trends in the development of the field.\nHistorically psychology and computer science were an inspiration for the first cognitive and agent architectures. Despite the differences in theory and terminology they tackled the same issues of action selection, efficient data processing and storage. For example, action selection in robotics is done using methods ranging from priority queue to reinforcement learning [292], similarly to the traditional cognitive architectures. More biologically realistic models were developed in parallel but became widely recognized as a viable alternative only relatively recently. Some of these models represent the emergent paradigm, however their support for inference and general reasoning is inadequate for solving common AI problems. Thus, hybrid models combining both symbolic and subsymbolic approaches are currently the most promising and will likely continue to be popular in the future. Another rising paradigm is represented by machine learning methods, which have found enormous practical success. However, they are mainly concerned with perception although lately there have been attempts at implementing more general inference and memory mechanisms with deep learning techniques. With respect to cognitive functions, research in cognitive architectures is focused more on higher level abilities such as learning, planning and general reasoning. While the importance of vision and perception in general is universally acknowledged, their treatment by architectures remains rather superficial. For example, simulations are frequently used to simplify or replace vision. Realistic unstructured environments are also rather rare. On the other hand, there is a trend toward implementing multimodal perception, which may lead to interesting applications in the future.\nOur data on practical applications of cognitive architectures demonstrates that with few exceptions architectures are narrowly focused on a particular area. The visualization in Figure 11 highlights the specialization areas of different types of architectures. For instance, emergent architectures are mainly applied to clustering and vision tasks, with several applications in the robotics domain. As expected, symbolic architectures are widely used for planning and reasoning, human performance modeling and psychological experiments. On the other hand, hybrid architectures are more uniformly represented across all application categories.\nOverall, there is a significant gap between general research in robotics and computer vision and research in these areas within the cognitive architectures domain. It is apparent that biologically inspired models cannot demonstrate the same range and efficiency in practical applications compared to the less theoretically restricted systems based on heuristics and engineering. Biological systems are mostly limited to controlled domains and many of their demonstrated results are proof-of-concept. Some exceptions exist,\nfor example Grok8 - a commercial application for IT analytics based on the biologically inspired HTM\narchitecture. On the other hand, as we have mentioned already, there is a clear trend towards developing hybrid cognitive architectures that take advantage of both biologically inspired and engineering techniques, so the performance gap may be reduced in the future.\nWith respect to the field as a whole, there is far less collaboration than would be expected in an interdisciplinary area such as cognitive architectures research. Some of this is due to the fact that many architectures are developed as closed-source projects in small groups, although there are numerous advantages of open-source development. For instance, cognitive architectures such as ART, ACT-R, Soar, HTM and Pogamut, attract a large community of researchers and are frequently referenced in the publications outside the main developing group. Another factor impeding communication is due to the sometimes impenetrable language used by the biologically- or neuro-inspired architectures. This is reminiscent of the terminological differences that existed between the architectures from cognitive and engineering backgrounds, although, at present, terms such as saliency, attention, working memory, etc. are far more commonplace.\nAcknowledgements\nThis research was supported through grants to the senior author, for which all the authors are grateful: Air Force Office of Scientific Research (FA9550-14-1-0393), the Canada Research Chairs Program (950-219525), and the Natural Sciences and Engineering Research Council of Canada (RGPIN-2016-05352).\nReferences [1] A. V. Samsonovich, \u201cToward a unified catalog of implemented cognitive architectures,\u201d in In Proceeding of\nthe 2010 conference on biologically inspired cognitive architectures, 2010, pp. 195\u2013244.\n[2] S. Russell and P. Norvig, Artificial Intelligence: A Modern Approach. Prentice Hall, 1995. [3] R. Sun, \u201cDesiderata for cognitive architectures,\u201d Philos. Psychol., vol. 17, no. 3, pp. 341\u2013373, 2004. [4] A. Newell, \u201cPhysical symbol systems,\u201d Cogn. Sci., vol. 4, no. 2, 1980. [5] A. Newell, \u201cPr\u00e9cis of Unified theories of cognition,\u201d Behav. Brain Sci., vol. 15, pp. 425\u2013492, 1992. [6] J. R. Anderson and C. Lebiere, \u201cThe Newell Test for a theory of cognition.,\u201d Behav. Brain Sci., vol. 26, no.\n5, pp. 587\u2013601, 2003.\n[7] S. Adams, I. Arel, J. Bach, R. Coop, R. Furlan, B. Goertzel, J. S. Hall, A. Samsonovich, M. Scheutz, M.\nSchlesinger, S. C. Shapiro, and J. Sowa, \u201cMapping the Landscape of Human-Level Artificial General Intelligence,\u201d AI Mag., vol. 33, no. 1, pp. 25\u201342, 2012.\n[8] T. Metzler and K. Shea, \u201cTaxonomy of Cognitive Functions,\u201d in Proceedings of the 18th International\nConference on Engineering Design, 2011, pp. 330\u2013341.\n[9] P. Wang, \u201cNatural language processing by reasoning and learning,\u201d in Proceedings of the International\nConference on Artificial General Intelligence, 2013, pp. 160\u2013169.\n[10] U. Faghihi and S. Franklin, \u201cThe LIDA Model as a Foundational Architecture for AGI,\u201d Theor. Found.\nArtif. Gen. Intell., vol. 4, pp. 103\u2013121, 2012.\n[11] S. Schaat, A. Wendt, S. Kollmann, F. Gelbard, and M. Jakubec, \u201cInterdisciplinary Development and\nEvaluation of Cognitive Architectures Exemplified with the SiMA Approach,\u201d in EuroAsianPacific Joint Conference on Cognitive Science, 2015.\n[12] B. Goertzel and G. Yu, \u201cA cognitive API and its application to AGI intelligence assessment,\u201d in\nInternational Conference on Artificial General Intelligence, 2014, pp. 242\u2013245.\n[13] W. Bridewell and P. F. Bello, \u201cIncremental Object Perception in an Attention-Driven Cognitive\nArchitecture,\u201d Proc. 37th Annu. Meet. Cogn. Sci. Soc., pp. 279\u2013284, 2015.\n[14] J. K. Tsotsos, \u201cAttention and Cognition: Principles to Guide Modeling,\u201d in Computational and Cognitive\nNeuroscience of Vision, Q. Zhao, Ed. Elsevier.\n8 http://numenta.com/grok/\n[15] U. Faghihi, P. Poirier, and O. Larue, \u201cEmotional Cognitive Architectures,\u201d in International Conference on\nAffective Computing and Intelligent Interaction, 2011.\n[16] T. C. Henderson and A. Joshi, \u201cThe Cognitive Symmetry Engine,\u201d Tech. Rep. UUCS-13-004, 2013. [17] S. L. Epstein, \u201cMetaknowledge for Autonomous Systems,\u201d in Proceedings of AAAI Spring Symposium on\nKnowledge Representation and Ontology for Autonomous Systems, 2004.\n[18] J. G. Carbonell, J. Blythe, O. Etzioni, Y. Gil, R. Joseph, D. Kahn, C. Knoblock, S. Minton, P. Alicia, S.\nReilly, M. Veloso, and X. Wang, \u201cPRODIGY4.0: TheManual and Tutorial,\u201d Tech. Rep. C., 1992.\n[19] D. Martin, M. Rincon, M. C. Garcia-Alegre, and D. Guinea, \u201cARDIS: Knowledge-based dynamic\narchitecture for real-time surface visual inspection,\u201d Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), vol. 5601, pp. 395\u2013404, 2009.\n[20] J. B. Maxwell, \u201cGenerative Music, Cognitive Modelling, and Computer-Assisted Composition in MusiCog\nand ManuScore,\u201d PhD Thesis, 2014.\n[21] W. Duch, R. J. Oentaryo, and M. Pasquier, \u201cCognitive Architectures: Where do we go from here?,\u201d in\nFrontiers in Artificial Intelligence and Applications, vol. 171, P. Wang, B. Goertzel, and S. Franklin, Eds. IOS Press, 2008, pp. 122\u2013136.\n[22] P. Langley, J. E. Laird, and S. Rogers, \u201cCognitive architectures: Research issues and challenges,\u201d Cogn.\nSyst. Res., vol. 10, no. 2, pp. 141\u2013160, 2009.\n[23] P. Thagard, \u201cCognitive Architectures,\u201d in The Cambridge handbook of cognitive science, W. Frankish and\nW. Ramsay, Eds. Cambridge: Cambridge University Press, 2012, pp. 50\u201370.\n[24] S. Profanter, \u201cCognitive architectures,\u201d in HaupteSeminar Human Robot Interaction, 2012. [25] A. J. Butt, N. A. Butt, A. Mazhar, Z. Khattak, and J. A. Sheikh, \u201cThe Soar of cognitive architectures,\u201d in\nProceedings of the 2013 International Conference on Current Trends in Information Technology, CTIT 2013, 2013.\n[26] G. Pezzulo and G. Calvi, \u201cDynamic Computation and Context Effects in the Hybrid Architecture AKIRA,\u201d\nInt. Interdiscip. Conf. Model. Using Context., 2005.\n[27] K. Th\u00f3risson and H. Helgasson, \u201cCognitive Architectures and Autonomy: A Comparative Review,\u201d J. Artif.\nGen. Intell., vol. 3, no. 2, pp. 1\u201330, 2012.\n[28] D. Foxvog, \u201cCyc,\u201d 2010, pp. 259\u2013278. [29] B. Goertzel, C. Pennachin, and N. Geisweiller, \u201cBrief Survey of Cognitive Architectures,\u201d in Engineering\nGeneral Intelligence, Part 1, Atlantis Press, 2014, pp. 101\u2013142.\n[30] J. E. Laird, \u201cThe Soar Cognitive Architecture,\u201d in AISB Quarterly, vol. 171, no. 134, 2012, pp. 224\u2013235. [31] P. Langley, J. E. Laird, and S. Rogers, \u201cCognitive architectures: Research issues and challenges,\u201d Cogn.\nSyst. Res., vol. 10, no. 2, pp. 141\u2013160, 2009.\n[32] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I.\nAntonoglou, V. Panneershelvam, M. Lanctot, S. Dieleman, D. Grewe, J. Nham, N. Kalchbrenner, I. Sutskever, T. Lillicrap, M. Leach, and K. Kavukcuoglu, \u201cMastering the game of Go with deep neural networks and tree search,\u201d Nature, vol. 529, no. 7585, pp. 484\u2013489, 2016.\n[33] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A. Graves, M. Riedmiller, A.\nK. Fidjeland, G. Ostrovski, S. Petersen, C. Beattie, A. Sadik, I. Antonoglou, H. King, D. Kumaran, D. Wierstra, S. Legg, and D. Hassabis, \u201cHuman-level control through deep reinforcement learning,\u201d Nature, vol. 518, no. 7540, pp. 529\u2013533, 2015.\n[34] J. Ba, V. Mnih, and K. Kavukcuoglu, \u201cMultiple Object Recognition with Visual Attention,\u201d Iclr, pp. 1\u201310,\n2014.\n[35] N. Kalchbrenner, I. Danihelka, and A. Graves, \u201cGrid Long Short-Term Memory,\u201d arXiv Prepr.\narXiv1507.01526, p. 14, 2015.\n[36] T. Mikolov, A. Joulin, and M. Baroni, \u201cA Roadmap towards Machine Intelligence,\u201d arXiv\u202f: 1511.08130v1,\n2015.\n[37] D. Vernon, G. Metta, and G. Sandini, \u201cA Survye of Artificial Cognitive Systems: Implictions for the\nAutonomous Development of Mental Capbilities in Computational Agents,\u201d IEEE Trans. Evol. Comput., pp. 1\u201330, 2007.\n[38] A. Asselman, S. Aammou, and A.-E. Nasseh, \u201cComparative Study of Cognitive Architectures,\u201d Int. Res. J.\nComput. Sci., vol. 2, no. 9, pp. 8\u201313, 2015.\n[39] B. Goertzel, J. Pitt, M. Ikle, C. Pennachin, and L. Rui, \u201cGlocal memory: A critical design principle for\nartificial brains and minds,\u201d Neurocomputing, vol. 74, no. 1\u20133, pp. 84\u201394, 2010.\n[40] R. Sun, T. Peterson, and E. Merrill, \u201cA Hybrid Architecture for Situated Learning of Reactive Sequential\nDecision Making,\u201d Appl. Intell., vol. 11, pp. 109\u2013127, 1999.\n[41] S. Varma, \u201cA computational model of Tower of Hanoi problem solving.,\u201d PhD Thesis, 2006. [42] R. C. O\u2019Reilly, D. Wyatte, S. Herd, B. Mingus, and D. J. Jilk, \u201cRecurrent processing during object\nrecognition,\u201d Front. Psychol., vol. 4, 2013.\n[43] B. Kokinov, \u201cMicro-Level Hybridization in the Cognitive Architecture DUAL,\u201d Connect. Integr. From\nunified to hybrid approaches, 1997.\n[44] R. Sun, \u201cHybrid Connectionist-Symbolic Modules,\u201d AI Mag., vol. 17, no. 2, pp. 99\u2013103, 1996. [45] M. Thalgott, \u201cBrain-Like Artificial Intelligence: Analysis of a Promising Field,\u201d 2013. [46] W. D. Gray, \u201cCognitive architectures: choreographing the dance of mental operations with the task\nenvironment,\u201d Hum. Factors, vol. 50, no. 3, pp. 497\u2013505, 2008.\n[47] R. Sun, \u201cArtificial intelligence: Connectionist and symbolic approaches,\u201d International Encyclopedia of the\nSocial and Behavioral Sciences. Pergamon/Elsevier, pp. 783\u2013789, 2001.\n[48] J. L. Krichmar and J. A. Snook, \u201cA neural approach to adaptive behavior and multi-sensor action selection\nin a mobile device,\u201d in Proceedings of the 2002 IEEE International Conference on Robotics and Automation, 2002.\n[49] M. Krzywinski, J. Schein, I. Birol, J. Connors, R. Gascoyne, S. J. Jones, and M. A. Marra, \u201cCircos: an\nInformation Aesthetic for Comparative Genomics,\u201d Genome Res., vol. 19, no. 9, pp. 1639\u20131645, 2009.\n[50] L. Matthies, \u201cStereo vision for planetary rovers: Stochastic modeling to near real-time implementation,\u201d Int.\nJ. Comput. Vis., vol. 8, no. 1, pp. 71\u201391, 1992.\n[51] A. Romero-Garc\u00e9s, L. V. Calderita, J. Martinez-Gomez, J. P. Bandera, R. Marfil, L. J. Manso, P. Bustos,\nand A. Bandera, \u201cThe cognitive architecture of a robotic salesman,\u201d Conf. Spanish Assoc. Artif. Intell., vol. 15, no. 6, 2015.\n[52] S. Ivaldi, N. Lyubova, D. Gerardeaux-Viret, A. Droniou, S. M. Anzalone, M. Chetouani, D. Filliat, and O.\nSigaud, \u201cPerception and human interaction for developmental learning of objects and affordances,\u201d in IEEERAS International Conference on Humanoid Robots, 2012, pp. 248\u2013254.\n[53] B. Rohrer, M. Bernard, D. J. Morrow, F. Rothganger, and P. Xavier, \u201cModel-free learning and control in a\nmobile robot,\u201d in Proceedings of the 5th International Conference on Natural Computation, ICNC 2009, 2009, pp. 566\u2013572.\n[54] F. Bellas, A. Fai\u00f1a, A. Prieto, and R. J. Duro, \u201cAdaptive Learning Application of the MDB Evolutionary\nCognitive Architecture in Physical Agents,\u201d Int. Conf. Simul. Adapt. Behav., 2006.\n[55] D. P. Benjamin, C. Funk, and D. Lyons, \u201cA cognitive approach to vision for a mobile robot,\u201d SPIE Defense,\nSecur. Sens., 2013.\n[56] G. Maffei, D. Santos-Pata, E. Marcos, M. S\u00e1nchez-Fibla, and P. F. M. J. Verschure, \u201cAn embodied\nbiologically constrained model of foraging: From classical and operant conditioning to adaptive real-world behavior in DAC-X,\u201d Neural Networks, vol. 72, pp. 88\u2013108, 2015.\n[57] J. Albus and A. Barbera, \u201cIntelligent control and tactical behavior development: A long term NIST\npartnership with the army,\u201d in 1st Joint Emergency Preparedness and Response/Robotic and Remote Systems Topical Meeting, 2006.\n[58] D. P. Miller and M. G. Slack, \u201cGlobal symbolic maps from local navigation,\u201d in Proceedings of the ninth\nNational conference on Artificial intelligence AAAI, 1991, pp. 750\u2013755.\n[59] T. Huntsberger, H. Aghazarian, A. Howard, and D. C. Trotz, \u201cStereo vision-based navigation for\nautonomous surface vessels,\u201d J. F. Robot., vol. 28, no. 1, pp. 3\u201318, 2011.\n[60] M. Scheutz, J. McRaven, and G. Cserey, \u201cFast, reliable, adaptive, bimodal people tracking for indoor\nenvironments,\u201d in Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2004, pp. 1347\u20131352.\n[61] P. Schermerhorn, J. Kramer, T. Brick, D. Anderson, A. Dingler, and M. Scheutz, \u201cDIARC: A Testbed for\nNatural Human-Robot Interactions,\u201d in Proceedings of AAAI 2006 Robot Workshop, 2006, pp. 1972\u20131973.\n[62] C. Ciliberto, F. Smeraldi, L. Natale, and G. Metta, \u201cOnline multiple instance learning applied to hand\ndetection in a humanoid robot,\u201d in IProceedings EEE International Conference on Intelligent Robots and Systems, 2011, pp. 1526\u20131532.\n[63] J. Martinez-Gomez, R. Marfil, L. V. Calderita, J. P. Bandera, L. J. Manso, A. Bandera, A. Romero-Garces,\nand P. Bustos, \u201cToward Social Cognition in Robotics: Extracting and Internalizing Meaning from Perception,\u201d in Workshop of Physical Agents, 2014.\n[64] C. Breazeal and B. Scassellati, \u201cChallenges in Building Robots That Imitate People,\u201d in Imitation in Animals\nand Artifacts, no. 1998, K. Dautenhahn and C. Nehaniv, Eds. Cambridge, MA: MIT Press, 2002, pp. 363\u2013 390.\n[65] R. C. O. O\u2019Reilly, D. Wyatte, S. Herd, B. Mingus, and D. J. Jilk, \u201cRecurrent processing during object\nrecognition,\u201d Front. Psychol., vol. 4, 2013.\n[66] D. Wyatte, S. Herd, B. Mingus, and R. O\u2019Reilly, \u201cThe role of competitive inhibition and top-down feedback\nin binding during object recognition,\u201d Front. Psychol., vol. 3, 2012.\n[67] A. K. Seth, J. L. McKinstry, G. M. Edelman, and J. L. Krichmar, \u201cVisual binding through reentrant\nconnectivity and dynamic synchronization in a brain-based device,\u201d Cereb. Cortex, vol. 14, no. 11, pp. 1185\u20131199, 2004.\n[68] N. Zhang, J. Weng, and Z. Zhang, \u201cA developing sensory mapping for robots,\u201d in Proceedings 2nd\nInternational Conference on Development and Learning. ICDL 2002, 2002, pp. 13\u201320.\n[69] J. Weng and Y. Zhang, \u201cDevelopmental Robots - A New Paradigm,\u201d in Proceedings of the Second\nInternational Workshop on Epigenetic Robotics Modeling Cognitive Development in Robotic Systems, 2002, vol. 94, pp. 163\u2013174.\n[70] G. A. Carpenter and S. Grossberg, \u201cAdaptive Resonance Theory,\u201d Encyclopedia of Machine Learning and\nData Mining. Springer-Verlag, 2014.\n[71] J. Hawkins and S. Ahmad, \u201cWhy Neurons Have Thousands of Synapses, a Theory of Sequence Memory in\nNeocortex,\u201d Front. Neural Circuits, vol. 10, 2016.\n[72] B. Goertzel, T. Sanders, and J. O\u2019Neill, \u201cIntegrating deep learning based perception with probabilistic logic\nvia frequent pattern mining,\u201d in International Conference on Artificial General Intelligence, 2013.\n[73] R. Evertsz, M. Pedrotti, P. Busetta, H. Acar, and F. E. Ritter, \u201cPopulating VBS2 with Realistic Virtual\nActors,\u201d in Proceedings of the 18th Conference on Behavior Representation in Modeling and Simulation, 2009, pp. 1\u20138.\n[74] B. Goertzel, C. Pennachin, N. Geissweiller, M. Looks, A. Senna, W. Silva, A. Heljakka, and C. Lopes, \u201cAn\nIntegrative Methodology for Teaching Embodied Non-Linguistic Agents, Applied to Virtual Animals in Second Life,\u201d Front. Artif. Intell. Appl., vol. 171, pp. 161\u2013175, 2008.\n[75] M. Bida, M. Cerny, J. Gemrot, and C. Brom, \u201cEvolution of GameBots project,\u201d in International Conference\non Entertainment Computing, 2012, pp. 397\u2013400.\n[76] D. E. Kieras, G. H. Wakefield, E. Thompson, N. Iyer, and B. D. Simpson, \u201cA cognitive architectural account\nof two-channel speech processing,\u201d in Proceedings of the Human Factors and Ergonomics Society, 2014, pp. 812\u2013816.\n[77] B. Chikhaoui, H. Pigot, M. Beaudoin, G. Pratte, P. Bellefeuille, and F. Laudares, \u201cLearning a Song: an\nACT-R Model,\u201d Proc. Int. Conf. Comput. Intell., pp. 405\u2013410, 2009.\n[78] P. Lison and G.-J. Kruijff, \u201cSalience-driven Contextual Priming of Speech Recognition for Human-Robot\nInteraction,\u201d in Language, 2008, pp. 636\u2013640.\n[79] N. Hawes, J. L. Wyatt, M. Sridharan, M. Kopicki, S. Hongeng, I. Calvert, A. Sloman, G.-J. Kruijff, H.\nJacobsson, M. Brenner, D. Skocaj, A. Vrecko, N. Majer, and M. Zillich, \u201cThe Playmate System,\u201d in Cognitive Systems, 2010.\n[80] S. L. Epstein, R. Passonneau, J. Gordon, and T. Ligorio, \u201cThe Role of Knowledge and Certainty in\nUnderstanding for Dialogue,\u201d in AAAI Fall Symposium: Advances in Cognitive Systems, 2012.\n[81] J. G. Trafton, N. L. Cassimatis, M. D. Bugajska, D. P. Brock, F. E. Mintz, and A. C. Schultz, \u201cEnabling\nEffective Human \u2013 Robot Interaction Using Perspective-Taking in Robots,\u201d IEEE Trans. Syst. Man, Cybern. - Part A Syst. Humans, vol. 35, no. 4, pp. 460\u2013470, 2005.\n[82] R. A. Peters, K. Kawamura, D. M. Wilkes, K. A. Hambuchen, T. E. Rogers, and W. A. Alford, \u201cISAC\nHumanoid: An Architecture for Learning and Emotion,\u201d in Proceedings of the IEEE-RAS International Conference on Humanoid Robots, 2001, no. 1, p. 459.\n[83] V. Sarathy, J. R. Wilson, T. Arnold, and M. Scheutz, \u201cEnabling Basic Normative HRI in a Cognitive\nRobotic Architecture,\u201d arXiv Prepr. arXiv1602.03814, 2016.\n[84] C. Breazeal and L. Aryananda, \u201cRecognition of affective communicative intent in robot-directed speech,\u201d\nAuton. Robots, vol. 12, no. 1, pp. 83\u2013104, 2002.\n[85] K. R. Thorisson, Mind model for multimodal communicative creatures and humanoids, vol. 13, no. 4\u20135.\n1999.\n[86] J. L. Pollock, \u201cPlanning in OSCAR,\u201d Minds Mach., vol. 2, pp. 113\u2013144, 1993. [87] D. R. Kuokka, \u201cIntegrating Planning, Execution, and Learning,\u201d in Proceedings of the NASA Conference on\nSpace Telerobotics, 1989, pp. 377\u2013386.\n[88] S. Vere and T. Bickmore, \u201cA basic agent,\u201d Comput. Intell., vol. 6, no. 1, pp. 41\u201360, 1990. [89] D. K. Mitchell, \u201cWorkload Analysis of the Crew of the Abrams V2 SEP: Phase I Baseline IMPRINT\nModel,\u201d Tehcnical Rep. ARL-TR-5028, no. September, 2009.\n[90] E. Hudlicka, G. Zacharias, and J. Psotka, \u201cIncreasing realism of human agents by modeling individual\ndifferences: Methodology, architecture, and testbed,\u201d Simulating Hum. Agents, Am. Assoc. Artif. Intell. Fall 2000 Symp. Ser., pp. 53\u201359, 2000.\n[91] S. Deutsch and N. Cramer, \u201cOmar Human Performance Modeling in a Decision Support Experiment,\u201d in\nProceedings of the Human Factors and Ergonomics Society 42nd Annual Meeting, 1998, pp. 1232\u20131236.\n[92] J. From, P. Perrin, D. O\u2019Neill, and J. Yen, \u201cSupporting the Commander\u2019s information requirements:\nAutomated support for battle drill processes using R-CAST,\u201d in Proceedings of the IEEE Military Communications Conference MILCOM, 2011.\n[93] A. Lavin and S. Ahmad, \u201cEvaluating Real-time Anomaly Detection Algorithms -- the Numenta Anomaly\nBenchmark,\u201d in Proceedings of the14th International Conference on Machine Learning and Applications (ICMLA), 2015.\n[94] G. A. Carpenter, S. Grossberg, and J. H. Reynolds, \u201cARTMAP: Supervised real-time learning and\nclassification of nonstationary data by a self-organizing neural network,\u201d Neural Networks, vol. 4, no. 5, pp. 565\u2013588, 1991.\n[95] M. M. Chun, J. D. Golomb, and N. B. Turk-Browne, \u201cA Taxonomy of External and Internal Attention,\u201d\nAnnu. Rev. Psychol., vol. 62, pp. 73\u2013101, 2010.\n[96] S. L. Epstein and S. Petrovic, Learning a Mixture of Search Heuristics. Springer Berlin Heidelberg, 2012. [97] J. S. Albus and A. J. Barbera, \u201cRCS: A cognitive architecture for intelligent multi-agent systems,\u201d Annu.\nRev. Control, vol. 29, no. 1, pp. 87\u201399, 2005.\n[98] S. E. Deutsch, J. Macmillan, N. L. Camer, and S. Chopra, \u201cOperability Model Architecture: Demonstration\nFinal Report,\u201d Tech. Rep. AL/HR-TR-1996-0161, 1997.\n[99] J. Ruesch, M. Lopes, A. Bernardino, J. Hornstein, J. Santos-Victor, and R. Pfeifer, \u201cMultimodal saliency-\nbased bottom-up attention a framework for the humanoid robot iCub,\u201d in Proceedings of the IEEE International Conference on Robotics and Automation, 2008, pp. 962\u2013967.\n[100] B. F. Gore, B. L. Hooey, C. D. Wickens, and S. Scott-Nash, \u201cA computational implementation of a human\nattention guiding mechanism in MIDAS v5,\u201d in International Conference on Digital Human Modeling, 2009.\n[101] J. M. Wolfe, \u201cGuided Search 2 . 0 A revised model of visual search,\u201d vol. 1, no. 2, pp. 202\u2013238, 1994. [102] E. Nyamsuren and N. A. Taatgen, \u201cPre-attentive and attentive vision module,\u201d Cogn. Syst. Res., pp. 211\u2013\n216, 2013.\n[103] C. Breazeal and B. Scassellati, \u201cA context-dependent attention system for a social robot,\u201d in Proceedings of\nthe International Joint Conference on Artificial Intelligence, 1999, pp. 1146\u20131151.\n[104] L. Itti, C. Koch, and E. Niebur, \u201cA Model of Saliency-Based Visual Attention for Rapid Scene Analysis,\u201d\nIEEE Trans. Pattern Anal. Mach. Intell., vol. 20, no. 11, pp. 1254\u20131259, 1998.\n[105] Z. Mathews, S. B. I Badia, and P. F. M. J. Verschure, \u201cPASAR: An integrated model of prediction,\nanticipation, sensation, attention and response for artificial sensorimotor systems,\u201d Inf. Sci. (Ny)., vol. 186, no. 1, pp. 1\u201319, 2012.\n[106] S. Ivaldi, S. M. Nguyen, N. Lyubova, A. Droniou, V. Padois, D. Filliat, P. Y. Oudeyer, and O. Sigaud,\n\u201cObject learning through active exploration,\u201d EEE Trans. Auton. Ment. Dev., vol. 6, no. 1, pp. 56\u201372, 2014.\n[107] J. S. Albus, Hui-Min Huang, E. R. Messina, K. Murphy, M. Juberts, A. Lacaze, S. B. Balakirsky, M. O.\nShneier, T. H. Hong, H. a. Scott, F. M. Proctor, W. P. Shackleford, J. L. Michaloski, A. J. Wavering, T. R. Kramer, N. G. Dagalakis, W. G. Rippey, K. a. Stouffer, and S. Legowik, \u201c4D/RCS: A Reference Model Architecture For Unmanned Vehicle Systems Version 2.0,\u201d Proc. SPIE 16th Annu. Int. Symp. AerospaceDefense Sens. Simul. Control., no. August 2002, 2002.\n[108] D. D. Salvucci, \u201cA Model of Eye Movements and Visual Attention,\u201d Proc. Third Int. Conf. Cogn. Model.,\npp. 252\u2013259, 2000.\n[109] M. A. Freed, \u201cSimulating human performance in complex, dynamic environments,\u201d PhD Thesis, no. June,\n1998.\n[110] P. Bello, W. Bridewell, and C. Wasylyshyn, \u201cAttentive and Pre - Attentive Processes in Multiple Object\nTracking: A Computational Investigation Modeling Object Construction and Tracking,\u201d in Proceedings of the 38th Annual Meeting of the Cognitive Science Society, 2016.\n[111] R. Arrabales, A. Ledezma, and A. Sanchis, \u201cA cognitive approach to multimodal attention,\u201d J. Phys. Agents,\nvol. 3, no. 1, pp. 53\u201363, 2009.\n[112] M. Conforth and Y. Meng, \u201cCHARISMA: A Context Hierarchy-based cognitive architecture for self-\nmotivated social agents,\u201d Proc. Int. Jt. Conf. Neural Networks, pp. 1894\u20131901, 2011.\n[113] P. C. R. Lane, F. Gobet, and R. L. Smith, \u201cAttention mechanisms in the CHREST cognitive architecture,\u201d\nLect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), vol. 5395\nLNAI, pp. 183\u2013196, 2009.\n[114] J. K. Tsotsos and W. Kruijne, \u201cCognitive programs: Software for attention\u2019s executive,\u201d Front. Psychol.,\nvol. 5, no. NOV, pp. 1\u201316, 2014.\n[115] J. K. Tsotsos, A computational perspective on visual attention. MIT Press, 2011. [116] R. A. Brooks, \u201cElephants don\u2019t play chess,\u201d Rob. Auton. Syst., vol. 6, no. 1\u20132, pp. 3\u201315, 1990. [117] M. P. Georgeff and F. F. Ingrand, \u201cDecision-Making in an Embedded Reasoning System,\u201d in Proceedings of\nthe Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), 1989.\n[118] J. L. Bresina and M. Drummond, \u201cIntegrating planning and reaction: A preliminary report,\u201d 1990. [119] R. Novianto, B. Johnston, and M. A. Williams, \u201cAttention in the ASMO cognitive architecture,\u201d Front.\nArtif. Intell. Appl., vol. 221, pp. 98\u2013105, 2010.\n[120] P. Langley and D. Choi, \u201cLearning recursive control programs from problem solving,\u201d J. Mach. Learn. Res.,\nvol. 7, pp. 493\u2013518, 2006.\n[121] J. R. Anderson and S. Douglass, \u201cTower of Hanoi: Evidence for the cost of goal retrieval.,\u201d J. Exp. Psychol.\nLearn. Mem. Cogn., vol. 27, no. 6, pp. 1331\u20131346, 2001.\n[122] B. Hayes-Roth, K. Pfleger, P. Lalanda, P. Morignot, and M. Balabanovic, \u201cA Domain-Specific Software\nArchitecture for Adaptive Intelligent Systems,\u201d IEEE Trans. Softw. Eng., vol. 21, no. 4, pp. 288\u2013301, 1995.\n[123] C. (Carnegie M. U. Lebiere, E. (Carnegie M. U. Biefeld, R. (Micro A. & D. Archer, S. (Micro A. & D.\nArcher, L. (Army R. L. Allender, and T. D. (Army R. L. Kelley, \u201cIMPRINT/ACT-R: Integration of a task network modeling architecture with a cognitive architecture and its application to human error modeling,\u201d Proc. 2002 Adv. Simul. Technol. Conf. San Diego, CA, Simul. Ser., vol. 34, pp. 13\u201319, 2002.\n[124] R. Sun and S. H\u00e9lie, Psychologically realistic cognitive agents: taking human cognition seriously, vol. 25,\nno. 1. 2012.\n[125] C. Brom, K. Pe\u0161kov\u00e1, and J. Lukavsky, \u201cWhat Does Your Actor Remember? Towards Characters with a\nFull Episodic Memory,\u201d in International Conference on Virtual Storytelling, 2007, pp. 89\u2013101.\n[126] P. Wang, \u201cThe Logic of Intelligence,\u201d in Artificial General Intelligence, Springer, 2006. [127] E. Nivel and K. R. Th\u00f3risson, \u201cSelf-Programming: Operationalizing Autonomy,\u201d in Proceedings of the 2nd\nConference on Artificial General Intelligence, 2009.\n[128] J. Yen, X. Fan, S. Sun, T. Hanratty, and J. Dumer, \u201cAgents with Shared Mental Models for Enhancing Team\nDecision-Makings,\u201d Decis. Support Syst., vol. 41, no. 3, pp. 634\u2013653, 2006.\n[129] W. Zachary, T. Santarelli, J. Ryder, and J. Stokes, \u201cDeveloping a multi-tasking cognitive agent using the\nCOGNET/iGEN integrative architecture,\u201d 2000.\n[130] B. J. Baars, \u201cGlobal workspace theory of consciousness: Toward a cognitive neuroscience of human\nexperience,\u201d Prog. Brain Res., vol. 150, pp. 45\u201353, 2005.\n[131] R. Arrabales, A. Ledezma, and A. Sanchis, \u201cSimulating Visual Qualia in the CERA-CRANIUM Cognitive\nArchitecture,\u201d in From Brains to Systems, Springer New York, 2011.\n[132] U. Faghihi, P. Fournier-Viger, and R. Nkambou, \u201cImplementing an efficient causal learning mechanism in a\ncognitive tutoring agent,\u201d Int. Conf. Ind. Eng. Other Appl. Appl. Intell. Syst., 2011.\n[133] B. J. Baars and S. Franklin, \u201cConsciousness Is Computational: the LIDA Model of Global Workspace\nTheory,\u201d Int. J. Mach. Conscious., vol. 1, no. 1, pp. 23\u201332, 2009.\n[134] J. A. Starzyk and D. K. Prasad, \u201cA Computational Model of Machine Consciousness,\u201d Int. J. Mach.\nConscious., vol. 3, no. 2, pp. 255\u2013281, 2011.\n[135] M. Minsky, The Society of Mind. New York, NY: Simon & Shuster, Inc., 1986. [136] I. Horswill, R. Zubek, A. Khoo, C. D. Le, and S. Nicholson, \u201cThe Cerebus Project,\u201d in Proceedings of the\nAAAI Fall Symposium on Parallel Cognition, 2000.\n[137] U. Faghihi, P. Poirier, P. Fournier-Viger, and R. Nkambou, \u201cHuman-like learning in a conscious agent,\u201d J.\nExp. Theor. Artif. Intell., vol. 23, no. 4, pp. 497\u2013528, 2011.\n[138] R. Arrabales, A. Ledezma, and A. Sanchis, \u201cCERA-CRANIUM\u202f: A Test Bed for Machine Consciousness\nResearch,\u201d in International Workshop on Machine Consciousness, 2009.\n[139] S. Franklin, T. Madl, S. D\u2019Mello, and J. Snaider, \u201cLIDA: A systems-level architecture for cognition,\nemotion, and learning,\u201d IEEE Trans. Auton. Ment. Dev., vol. 6, no. 1, pp. 19\u201341, 2014.\n[140] R. C. Atkinson and R. M. Shiffrin, \u201cHuman Memory: A Proposed System and its Control Processes,\u201d\nPsychol. Learn. Motiv. - Adv. Res. Theory, vol. 2, no. C, pp. 89\u2013195, 1968.\n[141] A. D. Baddeley and G. Hitch, \u201cWorking Memory,\u201d Psychol. Learn. Motiv. - Adv. Res. Theory, vol. 8, no. C,\npp. 47\u201389, 1974.\n[142] A. Perner and H. Zeilinger, \u201cAction primitives for bionics inspired action planning system: Abstraction\nlayers for action planning based on psychoanalytical concepts,\u201d in IEEE International Conference on\nIndustrial Informatics (INDIN), 2011, pp. 63\u201368.\n[143] G. Tecuci, M. Boicu, M. Bowman, D. Marcu, P. Shyr, and C. Cascaval, \u201cAn Experiment in Agent Teaching\nby Subject Matter Experts,\u201d Int. J. Hum. Comput. Stud., vol. 53, no. 4, pp. 583\u2013610, 2000.\n[144] M. P. Georgeff and A. L. Lansky, \u201cProcedural Knowledge,\u201d in Proceedings of the IEEE, 1986, vol. 74, no.\n10, pp. 1383\u20131398.\n[145] D. Martin, M. Rincon, M. C. Garcia-Alegre, and D. Guinea, \u201cARDIS: Knowledge-based architecture for\nvisual system configuration in dynamic surface inspection,\u201d Expert Syst., vol. 28, no. 4, pp. 353\u2013374, 2011.\n[146] E. Gat, \u201cIntegrating Planning and Reacting in a Heterogeneous Asynchronous Architecture for Controlling\nReal-World Mobile Robots,\u201d AAAI, pp. 809\u2013815, 1992.\n[147] W. Murdock and A. Goel, \u201cMeta-case-Based Reasoning\u202f: Using Functional Models to Adapt Case-Based\nAgents,\u201d in Proceedings of the 4th. International Conference on Case-Based Reasoning, 2001.\n[148] M. Veloso, \u201cPRODILOGY/ANALOGY: Analogical reasoning in general problem solving,\u201d in Topics in\nCase-Based Reasoning, 1993.\n[149] N. Cowan, Chapter 20 What are the differences between long-term, short-term, and working memory?, vol.\n169. Elsevier, 2008.\n[150] D. Kieras, \u201cModeling Visual Search of Displays of Many Objects: The Role of Differential Acuity and\nFixation Memory,\u201d Proc. 10th Int. Conf. Cogn. Model., 2010.\n[151] S. Franklin, T. Madl, S. Strain, U. Faghihi, D. Dong, S. Kugele, J. Snaider, P. Agrawal, and S. Chen, \u201cA\nLIDA cognitive model tutorial,\u201d Biol. Inspired Cogn. Archit., vol. 16, 2016.\n[152] J. B. Maxwell, A. Eigenfeldt, P. Pasquier, and N. G. Thomas, \u201cMusicog: a Cognitive Architecture for Music\nLearning and Generation,\u201d in Proceedings of the 9th Sound and Music Computing Conference, 2012, pp. 521\u2013528.\n[153] M. Freed and R. Remington, \u201cA conceptual framework for predicting error in complex human-machine\nenvironments,\u201d in Proceedings of the 20th Annual Conference of the Cognitive Science Society, 1998.\n[154] R. Brandon, \u201cA developmental agent for learning features, environment models, and general robotics tasks,\u201d\nFront. Comput. Neurosci., vol. 5, pp. 3\u20138, 2011.\n[155] E. Hudlicka, \u201cModeling Cultural and Personality Biases in Decision Making,\u201d in Proceedings of the 3rd\nInternational Conference on Applied Human Factors and Ergonomics (AHFE), 2010.\n[156] K. Forbus, J. Usher, A. Lovett, K. Lockwood, and J. Wetzel, \u201cCogSketch: Sketch understanding for\ncognitive science research and for education,\u201d Top. Cogn. Sci., vol. 3, no. 4, pp. 648\u2013666, 2011.\n[157] X. Pan, L. N. Teow, K. H. Tan, J. H. B. Ang, and G. W. Ng, \u201cA cognitive system for adaptive decision\nmaking,\u201d in 15th International Conference on Information Fusion, FUSION 2012, 2012, pp. 1323\u20131329.\n[158] K. Sjoo, H. Zender, P. Jensfelt, G.-J. M. Kruijff, A. Pronobis, N. Hawes, and M. Brenner, \u201cThe Explorer\nSystem,\u201d in Cognitive Systems, 2010.\n[159] S. C. Shapiro and J. P. Bona, \u201cThe Glair Cognitive Architecture,\u201d Int. J. Mach. Conscious., vol. 2, no. 2, pp.\n307\u2013332, 2010.\n[160] U. Faghihi, P. Fournier-Viger, and R. Nkambou, \u201cCELTS: A cognitive tutoring agent with human-like\nlearning capabilities and emotions,\u201d in Smart Innovation, Systems and Technologies, Springer Berlin Heidelberg, 2013.\n[161] B. Goertzel and C. Pennachin, \u201cThe Novamente Artificial Intelligence Engine,\u201d in Artificial General\nIntelligence, Springer Berlin Heidelberg, 2007, pp. 63\u2013129.\n[162] M. Lloyd-Kelly, P. C. R. Lane, and F. Gobet, \u201cThe Effects of Bounding Rationality on the Performance and\nLearning of CHREST Agents in Tileworld,\u201d Res. Dev. Intell. Syst. XXXI, 2014.\n[163] B. L. Hooey, B. F. Gore, C. D. Wickens, S. Scott-Nash, C. M. Socash, E. Salud, and D. C. Foyle, \u201cHuman\nModelling in Assisted Transportation,\u201d in Proceeding of the Human Modeling in Assisted Transportation Conference, 2010, pp. 327\u2013333.\n[164] S. Franklin, \u201cA Foundational Architecture for Artificial General Intelligence,\u201d Adv. Artif. Gen. Intell.\nConcepts, Archit. Algorithms, pp. 36\u201354, 2007.\n[165] L. A. Coward, \u201cModellingMemory and Learning Consistently from Psychology to Physiology,\u201d in\nPerception-Action Cycle, V. Cutsuridis, A. Hussain, and J. G. Taylor, Eds. 2011, pp. 63\u2013133.\n[166] R. Sun, \u201cMemory systems within a cognitive architecture,\u201d New Ideas Psychol., vol. 30, no. 2, pp. 227\u2013240,\n2012.\n[167] R. J. Firby, \u201cAdaptive Execution in Complex Dynamic Worlds,\u201d 1989. [168] C. Lebiere, P. Pirolli, R. Thomson, J. Paik, M. Rutledge-Taylor, J. Staszewski, and J. R. Anderson, \u201cA\nfunctional model of sensemaking in a neurocognitive architecture,\u201d Comput. Intell. Neurosci., vol. 2013, 2013.\n[169] D. E. Kieras, \u201cEPIC Architecture Principles of Operation.\u201d 2004. [170] S. Herd, A. Szabados, Y. Vinokurov, C. Lebiere, A. Cline, and R. C. O\u2019Reilly, \u201cIntegrating theories of\nmotor sequencing in the SAL hybrid architecture,\u201d Biol. Inspired Cogn. Archit., vol. 8, pp. 98\u2013106, 2014.\n[171] P. Lindes and J. E. Laird, \u201cToward Integrating Cognitive Linguistics and Cognitive Language Processing,\u201d\n2016.\n[172] M. Freed and R. Remington, \u201cMaking human-machine system simulation a practical engineering tool: An\nAPEX overview,\u201d in Proceedings of the 3rd International Conference on Cognitive Modelling, 2000.\n[173] D. P. Benjamin, D. Lyons, and D. Lonsdale, \u201cADAPT\u202f: A Cognitive Architecture for Robotics An\nImplementation of ADAPT,\u201d Proc. Sixth Int. Conf. Cogn. Model., no. October, pp. 337\u2013338, 2004.\n[174] S. L. Epstein, \u201cFor the right reasons: The FORR architecture for learning in a skill domain,\u201d Cogn. Sci., vol.\n18, no. 3, pp. 479\u2013511, 1994.\n[175] R. Salgado, F. Bellas, P. Caamano, B. Santos-Diez, and R. J. Duro, \u201cA procedural Long Term Memory for\ncognitive robotics,\u201d in Proceedings of the IEEE Conference on Evolving and Adaptive Intelligent Systems, 2012, pp. 57\u201362.\n[176] H. Schultheis and T. Barkowsky, \u201cCasimir: An architecture for mental spatial knowledge processing,\u201d Top.\nCogn. Sci., vol. 3, no. 4, pp. 778\u2013795, 2011.\n[177] I. Horswill, \u201cCerebus\u202f: A Higher-Order Behavior-Based System,\u201d AI Magazine, vol. 23, no. 1, 2001. [178] M. Boicu, D. Marcu, C. Boicu, and B. Stanescu, \u201cMixed-initiative Control for Teaching and Learning in\nDisciple,\u201d in Proceedings of the IJCAI-03 Workshop on Mixed-Initiative Intelligent Systems, 2003.\n[179] K. Corker, G. Pisanich, and M. Bunzo, \u201cA cognitive system model for human/automation dynamics in\nairspace management,\u201d in Proceedings of the First European/US Symposium on Air Traffic Management, 1997.\n[180] M. Lloyd-Kelly, F. R. Gobet, and P. C. R. Lane, \u201cPiece of Mind\u202f: Long-Term Memory Structure in ACT-R\nand CHREST,\u201d in Proceedings of the 37th Annual Meeting of the Cognitive Science Society, 2015.\n[181] J. L. Krichmar and G. M. Edelman, \u201cBrain-based devices for the study of nervous systems and the\ndevelopment of intelligent machines,\u201d Artif. Life, vol. 11, no. 1\u20132, pp. 63\u201377, 2005.\n[182] L. Shastri, \u201cSHRUTI: A neurally motivated architecture for rapid, scalable inference,\u201d in Studies in\nComputational Intelligence, Springer Berlin Heidelberg, 2007, pp. 183\u2013203.\n[183] A. Lavin, S. Ahmad, and J. Hawkins, \u201cSparse Distributed Representations,\u201d 2016. [184] G. A. Carpenter, \u201cNeural-network models of learning and memory: Leading questions and an emerging\nframework,\u201d TRENDS Cogn. Sci., vol. 5, no. 3, pp. 114\u2013118, 2001.\n[185] D. R. Kuokka, \u201cMAX: A Meta-Reasoning Architecture for \u2018X,\u2019\u201d SIGART Bull., vol. 2, no. 4, pp. 93\u201397,\n1991.\n[186] S. E. Deutsch, \u201cUAV Operator Human Performance Models,\u201d Tech. Rep. AFRL-RI-RS-TR-2006-0158,\n2006.\n[187] D. Vernon, C. von Hofsten, and L. Fadiga, \u201cThe iCub Cognitive Architecture,\u201d in A Roadmap for Cognitive\nDevelopment in Humanoid Robots, 2010, pp. 121\u2013153.\n[188] R. Sun, E. Merrill, and T. Peterson, \u201cA bottom-up model of skill learning,\u201d Proc. 20th Cogn. Sci. Soc. Conf.,\npp. 1037\u20131042, 1998.\n[189] M. Jaszuk and J. A. Starzyk, \u201cBuilding internal scene representation in cognitive agents,\u201d Knowledge, Inf.\nCreat. Support Syst. Recent Trends, Adv. Solut., pp. 479\u2013491, 2016.\n[190] E. Hudlicka, \u201cThis time with feeling: Integrated model of trait and state effects on cognition and behavior,\u201d\nAppl. Artif. Intell., vol. 16, pp. 611\u2013641, 2002.\n[191] A. Barnes and R. J. Hammell, \u201cDetermining Information Technology Project Status using Recognition-\nprimed Decision- making enabled Collaborative Agents for Simulating Teamwork ( R-CAST ),\u201d in Proceedings of CONISAR, 2008.\n[192] A. M. Nuxoll and J. E. Laird, \u201cExtending Cognitive Architecture with Episodic Memory,\u201d in Proceedings of\nthe National Conference on Artificial Intelligence., 2007.\n[193] R. Lian, B. Goertzel, R. Liu, M. Ross, M. Queiroz, and L. Vepstas, \u201cSentence generation for artificial\nbrains: A glocal similarity-matching approach,\u201d Neurocomputing, vol. 74, no. 1\u20133, pp. 95\u2013103, 2010.\n[194] T. Mitchell, J. Allen, P. Chalasani, J. Cheng, O. Etzioni, M. Ringuette, and J. C. Schlimmer, \u201cTheo: A\nframework for self-improving systems,\u201d in Architectures for intelligence, K. VanLehn, Ed. Erbaum, 1989, pp. 323\u2013356.\n[195] P. Bustos, J. Martinez-Gomez, I. Garcia-Varea, L. Rodriguez-Ruiz, P. Bachiller, L. Calderita, L. J. Manso,\nA. Sanchez, A. Bandera, and J. P. Bandera, \u201cMultimodal Interaction with Loki,\u201d in Workshop of Physical Agents, 2013, pp. 1\u20138.\n[196] G. Pezzulo, G. Calvi, and C. Castelfranchi, \u201cDiPRA: Distributed Practical Reasoning Architecture,\u201d in\nProceedings of International Joint Conference on Artificial Intelligence (IJCAI), 2007, pp. 1458\u20131463.\n[197] P. Wang and P. Hammer, \u201cIssues in Temporal and Causal Inference,\u201d Int. Conf. Artif. Gen. Intell., pp. 1\u201310,\n2015.\n[198] S. L. Epstein, A. Aroor, M. Evanusa, E. I. Sklar, and S. Parsons, \u201cLearning Spatial Models for Navigation,\u201d\nin International Workshop on Spatial Information Theory, 2015.\n[199] G. Metta, L. Natale, F. Nori, G. Sandini, D. Vernon, L. Fadiga, C. von Hofsten, K. Rosander, M. Lopes, J.\nSantos-Victor, A. Bernardino, and L. Montesano, \u201cThe iCub humanoid robot: An open-systems platform for research in cognitive development,\u201d Neural Networks, vol. 23, no. 8\u20139, pp. 1125\u20131134, 2010.\n[200] C. Schlenoff, R. Madhavan, J. Albus, E. Messina, T. Barbera, and S. Balakirsky, \u201cFusing Disparate\nInformation Within the 4D / RCS Architecture,\u201d in 2005 7th International Conference on Information Fusion (FUSION) Fusing, 2005.\n[201] B. Hayes-Roth, P. Lalanda, P. Morignot, K. Pfleger, and M. Balabanovic, \u201cPlans and Behavior in Intelligent\nAgents,\u201d KSL Rep. No. 93-43, 1993.\n[202] J. Bach, C. Bauer, and R. Vuine, \u201cMicroPsi: Contributions to a broad architecture of cognition,\u201d in Annual\nConference on Artificial Intelligence, 2007, pp. 7\u201318.\n[203] I. Kostavelis, L. Nalpantidis, and A. Gasteratos, \u201cObject recognition using saliency maps and HTM\nlearning,\u201d in Proceedings of the IEEE International Conference on Imaging Systems and Techniques, 2012, pp. 528\u2013532.\n[204] B. Rohrer, \u201cAn implemented architecture for feature creation and general reinforcement learning,\u201d\nWorkshop on Self-Programming in AGI Systems, Fourth International Conference on Artificial General Intelligence. 2011.\n[205] B. Goertzel, \u201cA pragmatic path toward endowing virtually-embodied AIs with human-level linguistic\ncapability,\u201d in Proceedings of the International Joint Conference on Neural Networks, 2008, pp. 2956\u2013 2965.\n[206] G. M. Edelman, \u201cLearning in and from brain-based devices,\u201d Science (80-. )., vol. 318, no. 5853, pp. 1103\u2013\n1105, 2007.\n[207] D. J. Jilk, C. Lebiere, R. C. O\u2019Reily, and J. R. Anderson, \u201cSAL: An explicitly pluralistic cognitive\narchitecture,\u201d J. Exp. Theor. Artif. Intell., vol. 20, no. 3, pp. 197\u2013218, 2008.\n[208] D. P. Benjamin, D. Lonsdale, and D. Lyons, \u201cDesigning a Robot Cognitive Architecture with Concurrency\nand Active Perception,\u201d in Proceedings of the AAAI Fall Symposium on the Intersection of Cognitive Science and Robotics, 2004.\n[209] M. R. G. Schiller and F. R. Gobet, \u201cA comparison between cognitive and AI models of blackjack strategy\nlearning,\u201d Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), pp. 143\u2013155, 2012.\n[210] G. W. Ng, X. Xiao, R. Z. Chan, and Y. S. Tan, \u201cScene Understanding using DSO Cognitive Architecture,\u201d\nin Proceedings of the 15th International Conference on Information Fusion (FUSION), 2012, pp. 2277\u2013 2284.\n[211] A. V. Samsonovich, K. A. De Jong, A. Kitsantas, E. E. Peters, N. Dabbagh, and M. Layne Kalbfleisch,\n\u201cCognitive constructor: An intelligent tutoring system based on a biologically inspired cognitive architecture (BICA),\u201d Front. Artif. Intell. Appl., vol. 171, pp. 311\u2013325, 2008.\n[212] C. Boicu, G. Tecuci, and M. Boicu, \u201cImproving Agent Learning through Rule Analysis,\u201d in Proceedings of\nthe International Conference on Artificial Intelligence, 2005.\n[213] P. Wang, \u201cNon-Axiomatic Logic (NAL) Specification,\u201d pp. 1\u201392, 2010. [214] A. Di Nuovo, V. M. De La Cruz, and A. Cangelosi, \u201cGrounding fingers, words and numbers in a cognitive\ndevelopmental robot,\u201d in Proceedings of the IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain, 2014.\n[215] C. Yu, M. Scheutz, and P. Schermerhorn, \u201cInvestigating multimodal real-time patterns of joint attention in\nan HRI word learning task,\u201d in Human-Robot Interaction (HRI), 2010 5th ACM/IEEE International Conference on, 2010, pp. 309\u2013316.\n[216] M. Klenk and K. Forbus, \u201cMeasuring the level of transfer learning by an AP physics problem-solver,\u201d Proc.\nNatl. Conf. Artif. Intell., vol. 22, no. 1, pp. 446\u2013451, 2007.\n[217] L. J. Manso, L. V. Calderita, P. Bustos, J. Garcia, M. Martinez, F. Fernandez, A. Romero-Garces, and A.\nBandera, \u201cA General-Purpose Architecture to Control Mobile Robots,\u201d in XV Workshop of physical agents: Book of proceedings, 2014.\n[218] N. Slam, W. Wang, G. Xue, and P. Wang, \u201cA framework with reasoning capabilities for crisis response\ndecision-support systems,\u201d Eng. Appl. Artif. Intell., vol. 46, pp. 346\u2013353, 2015.\n[219] M. A. Olivares-Mendez, P. Campoy, I. Mondragon, and C. Martinez, \u201cFuzzy-4D/RCS for Unmanned Aerial\nVehicles,\u201d in Proc. International Congress of Brain Inspired Cognitive Systems BICS, 2010, vol. 51.\n[220] G. H. Ogasawara and S. J. Russell, \u201cPlanning Using Multiple Execution Architectures,\u201d in Proceedings of\nthe International Joint Conference on Artificial Intelligence, 1993.\n[221] A. K. Seth and G. M. Edelman, \u201cDistinguishing causal interactions in neural populations,\u201d Neural Comput.,\nvol. 19, no. 4, pp. 910\u201333, 2007.\n[222] T. Huntsberger, \u201cCognitive architecture for mixed human-machine team interactions for space exploration,\u201d\nin IEEE Aerospace Conference Proceedings, 2011.\n[223] J. Gordon and S. L. Epstein, \u201cLearning to balance grounding rationales for dialogue systems,\u201d in\nProceedings of SIGDIAL Conference, 2011, pp. 266\u2013271.\n[224] D. Shapiro, P. Langley, and R. Shachter, \u201cUsing Background Knowledge to Speed Reinforcement Learning\nin Physical Agents,\u201d in Proceedings of the 5th International Conference on Autonomous Agents, 2001, pp. 254\u2013261.\n[225] S. Hart, D. Dahn, A. Atencio, and M. K. Dalal, \u201cEvaluation and Application of MIDAS v2.0,\u201d SAE Tech.\nPap. 2001-01-2648, 2001.\n[226] D. G. Hoecker, E. M. Roth, K. M. Corker, and M. H. Lipner, \u201cMan-Machine Design and Analysis System\n(MIDAS) Applied to a Computer-Based Procedure-Aiding System,\u201d in Proceedings of the Human Factors and Ergonomics Society 39th Annual Meeting, 1994, pp. 195\u2013199.\n[227] J. R. Kirk and J. E. Laird, \u201cLearning General and Efficient Representations of Novel Games Through\nInteractive Instruction,\u201d Adv. Cogn. Syst., vol. 4, 2016.\n[228] J. R. Anderson, M. V. Albert, and J. M. Fincham, \u201cTracing problem solving in real time: fMRI analysis of\nthe subject-paced Tower of Hanoi.,\u201d J. Cogn. Neurosci., vol. 17, no. 8, pp. 1261\u20131274, 2005.\n[229] L. Allender, \u201cModeling Human Performance: Impacting System Design, Performance, and Cost,\u201d in\nProceedings of the Military, Government and Aerospace Simulation Symposium, 2000, pp. 139\u2013144.\n[230] D. K. Mitchell, B. Abounader, and S. Henry, \u201cA Procedure for Collecting Mental Workload Data During an\nExperiment That Is Comparable to IMPRINT Workload Data,\u201d Tehcnical Rep. ARL-TR-5020, 2009.\n[231] W. W. Zachary, J. M. Ryder, J. H. Hicinbothom, J. A. Cannon-Bowers, and E. Salas, \u201cCognitive task\nanalysis and modeling of decision making in complex environments,\u201d in Making decisions under stress: Implications for individual and team training., J. Cannon-Bowers and E. Salas, Eds. Washington, DC, 1998, pp. 315\u2013344.\n[232] T. L. Seamster, R. E. Redding, J. R. Cannon, J. M. Ryder, and J. A. Purcell, \u201cCognitive task analysis of\nexpertise in air traffic control,\u201d Int. J. Aviat. Psychol., vol. 3, no. 4, 1993.\n[233] C. D. Wickens, J. S. Mccarley, A. L. Alexander, L. C. Thomas, M. Ambinder, and S. Zheng, \u201cAttention-\nSituation Awareness (A-SA) Model of Pilot Error,\u201d Hum. Perform. Model. Aviat., pp. 213\u2013239, 2008.\n[234] J. E. Laird, K. J. Coulter, R. M. Jones, P. G. Kenny, F. Koss, and P. E. Nielsen, \u201cIntegrating intelligent\ncomputer generated forces in distributed simulations: TacAir-Soar in STOW-97,\u201d in Proceedings of the 1998 Spring Simulation Interoperability Workshop, 1998.\n[235] R. M. Jones, J. E. Laird, P. E. Nielsen, K. J. Coulter, P. Kenny, and F. V. Koss, \u201cAutomated Intelligent\nPilots for Combat Flight Simulation,\u201d AI Mag., vol. 20, no. 1, pp. 27\u201342, 1999.\n[236] J. Weng, Y.-B. Lee, and C. H. Evans, \u201cThe Developmental Approach to Multimedia Speech Learning,\u201d in\nProceedings., of the IEEE International Conference on Acoustics, Speech, and Signal Processing, 1999.\n[237] J. E. Laird, K. R. Kinkade, S. Mohan, and J. Z. Xu, \u201cCognitive Robotics Using the Soar Cognitive\nArchitecture,\u201d in Proceedings of the 6th International Conference on Cognitive Modelling, 2004, pp. 226\u2013 330.\n[238] V. Tikhanoff, A. Cangelosi, and G. Metta, \u201cIntegration of speech and action in humanoid robots: iCub\nsimulation experiments,\u201d IEEE Trans. Auton. Ment. Dev., vol. 3, no. 1, pp. 17\u201329, 2011.\n[239] K. R. Thorisson, O. Gislason, G. R. Jonsdottir, and H. T. Thorisson, \u201cA Multiparty Multimodal Architecture\nfor Realtime Turntaking,\u201d in International Conference on Intelligent Virtual Agents, 2010.\n[240] C. Breazeal, \u201cToward sociable robots,\u201d Rob. Auton. Syst., vol. 42, no. 3\u20134, pp. 167\u2013175, 2003. [241] C. Breazeal and R. Brooks, \u201cRobot Emotion: A Functional Perspective,\u201d in Who Needs Emotions?: The\nBrain Meets the Robot, 2004.\n[242] S. M. Anzalone, S. Ivaldi, O. Sigaud, and M. Chetouani, \u201cMultimodal people engagement with iCub,\u201d Biol.\ninspired Cogn. Archit., pp. 59\u201364, 2012.\n[243] U. Kurup, P. G. Bignoli, J. R. Scally, and N. L. Cassimatis, \u201cAn architectural framework for complex\ncognition,\u201d Cogn. Syst. Res., vol. 12, no. 3\u20134, pp. 281\u2013292, 2011.\n[244] O. Kilic, \u201cIntelligent Reasoning on Natural Language Data: A Non-Axiomatic Reasoning System\nApproach,\u201d PhD Thesis, 2015.\n[245] T. Williams and M. Scheutz, \u201cA Framework for Resolving Open-World Referential Expressions in\nDistributed Heterogeneous Knowledge Bases,\u201d in Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, 2016.\n[246] H. Joshi, P. S. Rosenbloom, and V. Ustun, \u201cContinuous Phone Recognition in the Sigma Cognitive\nArchitecture,\u201d Biol. Inspired Cogn. Archit., 2016.\n[247] H. Joshi, P. S. Rosenbloom, and V. Ustun, \u201cIsolated word recognition in the Sigma cognitive architecture,\u201d\nBiol. Inspired Cogn. Archit., vol. 10, no. C, pp. 1\u20139, 2014.\n[248] Y. Zhang and J. Weng, \u201cGrounded auditory development by a developmental robot,\u201d in Proceedings of the\nInternational Joint Conference on Neural Networks, 2001.\n[249] G. A. Carpenter and S. C. Gaddam, \u201cBiased ART: A neural architecture that shifts attention toward\npreviously disregarded features following an incorrect prediction,\u201d Neural Networks, vol. 23, no. 3, pp. 435\u2013 451, 2010.\n[250] A. Kaylani, M. Georgiopoulos, M. Mollaghasemi, and G. C. Anagnostopoulos, \u201cAG-ART: An adaptive\napproach to evolvong ART architectures,\u201d Neurocomputing, vol. 72, pp. 2079\u20132092, 2009.\n[251] M. Demetgul, I. N. Tansel, and S. Taskin, \u201cFault diagnosis of pneumatic systems with artificial neural\nnetwork algorithms,\u201d Expert Syst. Appl., vol. 36, no. 7, pp. 10512\u201310519, 2009.\n[252] H. Ames and S. Grossberg, \u201cSpeaker normalization using cortical strip maps: a neural model for steady-state\nvowel categorization.,\u201d J. Acoust. Soc. Am., vol. 124, pp. 3918\u20133936, 2008.\n[253] C. Distante, P. Siciliano, and L. Vasanelli, \u201cOdor discrimination using adaptive resonance theory,\u201d Sensors\nand Actuators, vol. 69, no. 3, pp. 248\u2013252, 2000.\n[254] Y. Cui, S. Ahmad, and J. Hawkins, \u201cContinuous online sequence learning with an unsupervised neural\nnetwork model,\u201d arXiv Prepr. arXiv1512.05463, 2015.\n[255] W. J. C. Melis, S. Chizuwa, and M. Kameyama, \u201cEvaluation of hierarchical temporal memory for a real\nworld application,\u201d Proc. 4th Int. Conf. Innov. Comput. Inf. Control, pp. 144\u2013147, 2009.\n[256] J. Cassell and K. R. Thorisson, \u201cThe power of a nod and a glance: Envelope vs. emotional feedback in\nanimated conversational agents,\u201d Appl. Artif. Intell., vol. 13, no. 4\u20135, pp. 519\u2013538, 1999.\n[257] A. S. Rao and M. P. George, \u201cIntelligent Real-Time Network Management,\u201d in Proceedings of the Tenth\nInternational Conference on AI, Expert Systems and Natural Language, 1991.\n[258] C. Harrigan, B. Goertzel, M. Ikle, A. Belayneh, and G. Yu, \u201cGuiding probabilistic logical inference with\nnonlinear dynamical attention allocation,\u201d in International Conference on Artificial General Intelligence, 2014, pp. 238\u2013241.\n[259] J. Thornton, J. Faichney, M. Blumenstein, and T. Hine, \u201cCharacter Recognition Using Hierarchical Vector\nQuantization and Temporal Pooling,\u201d in Proceedings of the 21st Australasian Joint Conference on Artificial Intelligence: Advances in Artificial Intelligence, 2008, vol. 5360, pp. 562\u2013572.\n[260] S. Stolc and I. Bajla, \u201cApplication of the computational intelligence network based on hierarchical temporal\nmemory to face recognition,\u201d in Proceedings of the 10th IASTED International Conference on Artificial Intelligence and Applications (AIA), 2010, pp. 185\u2013192.\n[261] W. Zhuo, Z. Cao, Y. Qin, Z. Yu, and Y. Xiao, \u201cImage classification using HTM cortical learning\nalgorithms,\u201d in Proceedings of the 21st International Conference on Pattern Recognition (ICPR), 2012, pp. 2452\u20132455.\n[262] X. Mai, X. Zhang, Y. Jin, Y. Yang, and J. Zhang, \u201cSimple Perception-Action Strategy Based on\nHierarchical Temporal Memory,\u201d in Proceeding of the IEEE International Conference on Robotics and Biomimetics (ROBIO), 2013, pp. 1759\u20131764.\n[263] A. Fazl, S. Grossberg, and E. Mingolla, View-invariant object category learning, recognition, and search:\nHow spatial and object attention are coordinated using surface-based attentional shrouds, vol. 58, no. 1. 2009.\n[264] J. Wang, G. Naghdy, and P. Ogunbona, \u201cWavelet-based feature-adaptive adaptive resonance theory neural\nnetwork for texture identification,\u201d J. Electron. Imaging, vol. 6, no. 3, pp. 329\u2013336, 1997.\n[265] R. C. O\u2019Reilly, T. E. Hazy, J. Mollick, P. Mackie, and S. Herd, \u201cGoal-Driven Cognition in the Brain: A\nComputational Framework,\u201d arXiv Prepr. arXiv1404.7591, 2014.\n[266] S. L. Epstein, \u201cLearning to Play Expertly: A Tutorial on Hoyle,\u201d Mach. that Learn to Play games, pp. 153\u2013\n178, 2001.\n[267] R. Kadlec, J. Gemrot, M. Bida, O. Burkert, J. Havlicek, L. Zemcak, R. Pibil, R. Vansa, and C. Brom,\n\u201cExtensions and applications of Pogamut 3 platform,\u201d Int. Work. Intell. Virtual Agents, vol. I, 2009.\n[268] A. M. Mora, F. Aisa, P. Garc\u00eda-S\u00e1nchez, P. \u00c1. Castillo, and J. J. Merelo, \u201cModelling a Human-Like Bot in a\nFirst Person Shooter Game,\u201d Int. J. Creat. Interfaces Comput. Graph., vol. 6, no. 1, pp. 21\u201337, 2015.\n[269] R. Small and C. B. Congdon, \u201cAgent Smith: Towards an evolutionary rule-based agent for interactive\ndynamic games,\u201d in 2009 IEEE Congress on Evolutionary Computation, CEC 2009, 2009, pp. 660\u2013666.\n[270] D. Cuadrado and Y. Saez, \u201cChuck Norris rocks!,\u201d in Proceedings of the IEEE Symposium on Computational\nIntelligence and Games, 2009, pp. 69\u201374.\n[271] D. Wang, B. Subagdja, A. Tan, and G. Ng, \u201cCreating human-like autonomous players in real-time first\nperson shooter computer games,\u201d in Proceedings of the 21st Annual Conference on Innovative Applications of Artificial Intelligence, 2009, pp. 173\u2013178.\n[272] N. Van Hoorn, J. Togelius, and J. Schmidhuber, \u201cHierarchical controller learning in a first-person shooter,\u201d\nin 2009 IEEE Symposium on Computational Intelligence and Games, 2009, pp. 294\u2013301.\n[273] P. Ulam, A. Goel, and J. Jones, \u201cReflection in Action: Model-Based Self-Adaptation in Game Playing\nAgents,\u201d in Challenges in Game Artificial Intelligence: Papers from the AAAI Workshop., 2004.\n[274] S. Wintermute, \u201cImagery in cognitive architecture: Representation and control at multiple levels of\nabstraction,\u201d Cogn. Syst. Res., vol. 19\u201320, pp. 1\u201329, 2012.\n[275] M. Shiwali and J. E. Laird, \u201cLearning to play Mario,\u201d Tech. Rep. CCA-TR-2009-03, 2009. [276] I. Kotseruba, Visual Attention in Dynamic Environments and Its Application To Playing Online Games. MSc\nThesis. York University, 2016.\n[277] J. R. Firby, R. E. Kahn, P. N. Prokopowicz, and M. J. Swain, \u201cAn Architecture for Vision and Action,\u201d in\nProceedings of the 14th international joint conference on Artificial intelligence (IJCAI\u201995), 1995.\n[278] R. A. Brooks, \u201cA robot that walks; emergent behaviors from a carefully evolved\\nnetwork,\u201d Neural\nComput., vol. 1, no. 2, pp. 253\u2013262, 1989.\n[279] A. Mininger and J. Laird, \u201cInteractively Learning Strategies for Handling References to Unseen or\nUnknown Objects,\u201d Adv. Cogn. Syst., vol. 5, 2016.\n[280] D. G. L\u00f3pez, K. Sj\u00f6, C. Paul, and P. Jensfelt, \u201cHybrid laser and vision based object search and localization,\u201d\nProc. IEEE Int. Conf. Robot. Autom., 2008.\n[281] K. Kawamura, R. A. I. Peters, R. E. Bodenheimer, N. Sarkar, J. Park, C. A. Clifton, and A. W. Spratley, \u201cA\nParallel Distributed Cognitive Control System for a Humanoid Robot,\u201d Int. J. Humanoid Robot., vol. 1, no. 1, pp. 65\u201393, 2004.\n[282] J. R. Wilson, E. Krause, M. Rivers, and M. Scheutz, \u201cAnalogical Generalization of Actions from Single\nExemplars in a Robotic Architecture,\u201d in Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems, 2016.\n[283] E. L. Sauser, B. D. Argall, G. Metta, and A. G. Billard, \u201cIterative learning of grasp adaptation through\nhuman corrections,\u201d Rob. Auton. Syst., vol. 60, pp. 55\u201371, 2012.\n[284] A. M. Lytle and K. S. Saidi, \u201cNIST research in autonomous construction,\u201d Auton. Robots, vol. 22, no. 3, pp.\n211\u2013221, 2007.\n[285] R. V. Bostelman, A. Jacoff, and R. Bunch, \u201cDelivery of an Advanced Double-Hull Ship Welding,\u201d in Third\nInternational ICSC (International Computer Science Conventions) Symposia on Intelligent Industrial Automation and Soft Computing, 1999.\n[286] K. N. Murphy, R. J. Norcross, and F. M. Proctor, \u201cCAD directed robotic deburring,\u201d in Proceedings of the\nsecond international symposium on robotics and manufacturing research, education, and applications, 1988.\n[287] J. S. Albus, \u201cThe NIST Real-time Control System (RCS): an approach to intelligent systems research,\u201d J.\nExp. Theor. Artif. Intell., vol. 9, no. 2\u20133, pp. 157\u2013174, 1997.\n[288] X. Fan, B. Sun, S. Sun, M. McNeese, and J. Yen, \u201cRPD-enabled agents teaming with humans for multi-\ncontext decision making,\u201d in Proceedings of the International Conference on Autonomous Agents, 2006.\n[289] F. E. Ritter, J. L. Bittner, S. E. Kase, R. Evertsz, M. Pedrotti, and P. Busetta, \u201cCoJACK: A high-level\ncognitive architecture with demonstrations of moderators, variability, and implications for situation awareness,\u201d Biol. Inspired Cogn. Archit., vol. 1, pp. 2\u201313, 2012.\n[290] S. Schaat, K. Doblhammer, A. Wendt, F. Gelbard, L. Herret, and D. Bruckner, \u201cA psychoanalytically-\ninspired motivational and emotional system for autonomous agents,\u201d Ind. Electron. Soc. IECON 2013-39th Annu. Conf., pp. 6648\u20136653, 2013.\n[291] A. Heljakka, B. Goertzel, W. Silva, C. Pennachin, A. Senna, and I. Goertzel, \u201cProbabilistic Logic Based\nReinforcement Learning of Simple Embodied Behaviors in a 3D Simulation World,\u201d Front. Artifical Intell. Appl., vol. 157, pp. 253\u2013275, 2007.\n[292] P. Pirjanian, \u201cBehavior Coordination Mechanisms,\u201d Tech. Rep. IRIS-99-375, 1999."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "In this paper we present a broad overview of the last 40 years of research on cognitive architectures. Although the number of<lb>existing architectures is nearing several hundred, most of the existing surveys do not reflect this growth and focus on a handful of<lb>well-established architectures. While their contributions are undeniable, they represent only a part of the research in the field. Thus, in this survey we wanted to shift the focus towards a more inclusive and high-level overview of the research in cognitive<lb>architectures. Our final set of 86 architectures includes 55 that are still actively developed, and borrow from a diverse set of<lb>disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we<lb>discuss only the core cognitive abilities, such as perception, attention mechanisms, learning and memory structure. To assess the breadth of practical applications of cognitive architectures we gathered information on over 700 practical projects implemented<lb>using the cognitive architectures in our list.<lb>We use various visualization techniques to highlight overall trends in the development of the field. For instance, our data<lb>confirms that the hybrid approach to cognitive modeling already dominates the field and will likely continue to do so in the future. Our analysis of practical applications shows that most architectures are very narrowly focused on a particular application domain.<lb>Furthermore, there is an apparent gap between general research in robotics and computer vision and research in these areas within<lb>the cognitive architectures field. It is very clear that biologically inspired models do not have the same range and efficiency<lb>compared to the systems based on engineering principles and heuristics. Another observation is related to a general lack of collaboration, which is surprising to see in the inherently interdisciplinary area of cognitive architectures. Several factors hinder<lb>communication, among which are the closed nature of the individual projects (only one-third of the reviewed here architectures are<lb>open-source) and terminological differences.", "creator": "Microsoft\u00ae Word 2013"}}}