{"id": "1610.09995", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Oct-2016", "title": "Generating Sentiment Lexicons for German Twitter", "abstract": "Despite significant progress in developing new Sentiment Lexicon Generation (SLG) methods for English, the task of transferring these approaches to other languages and areas in a solid manner remains open. In this paper, we contribute to solving this problem by systematically comparing the semi-automatic translations of common English polarity lists with the results of the original automatic SLG algorithms applied directly to German data. To determine which of these paradigms is better suited to the inherently noisy realm of social media, we evaluate these lexicographs using 7,992 manually annotated tweets. Our experiments show that semi-automatic translations significantly outperform automatic systems (they achieve a macro-average F1 score of 0.589) and that dictionary-based techniques produce much better polarity lists than body-based approaches (whose best values range between F1 and 0.419 and 0.419, respectively).", "histories": [["v1", "Mon, 31 Oct 2016 16:12:16 GMT  (311kb,D)", "http://arxiv.org/abs/1610.09995v1", "This paper is the first in a planned series of articles on an automatic generation of sentiment lexicons for non-English Twitter. It will be presented as a poster at the PEOPLES workshop (this https URL)"]], "COMMENTS": "This paper is the first in a planned series of articles on an automatic generation of sentiment lexicons for non-English Twitter. It will be presented as a poster at the PEOPLES workshop (this https URL)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["uladzimir sidarenka", "manfred stede"], "accepted": false, "id": "1610.09995"}, "pdf": {"name": "1610.09995.pdf", "metadata": {"source": "CRF", "title": "Generating Sentiment Lexicons for German Twitter", "authors": ["Uladzimir Sidarenka", "Manfred Stede"], "emails": ["sidarenk@uni-potsdam.de", "stede@uni-potsdam.de"], "sections": [{"heading": "1 Introduction", "text": "Sentiment lexicons play a crucial role in many existing and emerging opinion mining applications. Not only do they serve as a valuable source of features for supervised classifiers (Mohammad et al., 2013; Zhu et al., 2014) but they also achieve competitive results when used as the main component of a sentiment analysis system (Taboada et al., 2011). Due to this high impact and tremendous costs of building such lexicons manually, devising new algorithms for an automatic generation of polarity lists has always been an area of active research in the sentiment analysis literature (Liu, 2012, pp. 79-91). Nevertheless, despite some obvious progress in this field (Cambria et al., 2016), the applicability of these approaches to other languages and text genres still raises questions: It is, for instance, unclear whether simply translating the existing English sentiment resources would produce better results than applying the methods that were initially proposed for their creation directly to the target language. Furthermore, for automatic systems which draw their knowledge from lexical taxonomies, such as WORDNET (Miller, 1995), it remains unanswered whether these approaches would also work for languages in which such resources are much smaller in size, and, even if they would, whether the resulting lexicons would then be general enough to carry over to more colloquial texts. Finally, for methods which derive their polarity lists from text corpora, it is not clear whether these approaches would still yield an acceptable quality when operating on inherently noisy input data.\nIn this paper, we try to analyze these and other problems in detail, using the example of German Twitter. More precisely, given a collection of German microblogs with manually labeled polar terms and prior polarities of these expressions, we want to find an SLG method that can best predict these terms and their semantic orientation. For this purpose, we compare the existing German sentiment lexicons\nThis work is licenced under a Creative Commons Attribution 4.0 International License. License details: http:// creativecommons.org/licenses/by/4.0/\nar X\niv :1\n61 0.\n09 99\n5v 1\n[ cs\n.C L\n] 3\n1 O\nct 2\n01 6\n(most of which were semi-automatically translated from popular English resources) with the results of common automatic dictionary- and corpus-based SLG approaches.\nWe begin our study by describing the data set which will be used in our evaluation. Afterwards, in Section 3, we introduce the metrics with which we will assess the quality of various polarity lists. Then, in Section 4, we evaluate three most popular existing German sentiment lexicons\u2014the German Polarity Clues (Waltinger, 2010), SentiWS (Remus et al., 2010), and Zurich Polarity List of Clematide and Klenner (2010), subsequently comparing them with popular automatic SLG approaches in Section 5. Finally, after estimating the impact of different seed sets on the automatic methods and performing a qualitative analysis of their entries, we draw our conclusions and outline directions for future research in the final part of this paper.\nTo avoid unnecessary repetitions, we deliberately omit a summary of related work, since most of the popular SLG algorithms will be referenced in the respective evaluation sections anyway. We should, however, note that, apart from the research on the automatic lexicon generation, our study is also closely related to the experiments of Andreevskaia and Bergler (2008) and the \u201cSentiment Analysis in Twitter\u201d track of the SemEval competition (Nakov et al., 2013; Rosenthal et al., 2014; Rosenthal et al., 2015). In contrast to the former work, however, where the authors trained a supervised classifier on one domain and applied it to another in order to determine the polarities of the sentences, we explicitly model a situation where no annotated training data are available, thus looking for the most general unsupervised SLG strategy which performs best regardless of the target domain, and we also evaluate these strategies on the level of lexical phrases only. Furthermore, unlike in the SemEval track, where the organizers also provided participants with sufficient labeled in-domain training sets and then asked them to predict the contextual polarity of pre-annotated polar expressions in the test data, we simultaneously try to predict polar terms and their prior polarities, learning both of them without supervision."}, {"heading": "2 Data", "text": "We perform our evaluation on the publicly available Potsdam Twitter Sentiment corpus (PotTS; Sidarenka, 2016).1 This collection comprises 7,992 microblogs pertaining to the German federal elections, general political life, papal conclave 2013, as well as casual everyday conversations. Two human experts annotated these posts with polar terms and their prior polarities,2 reaching a substantial agreement of 0.75 binary \u03ba (Cohen, 1960).3 We used the complete data set labeled by one of the annotators as our test corpus, getting a total of 6,040 positive and 3,055 negative terms including multi-word expressions. However, since many of these expressions were emoticons, which, on the one hand, were a priori absent in common lexical taxonomies due to their colloquial nature and therefore not amenable to dictionary-based SLG systems but, on the other hand, could be easily captured by regular expressions, we decided to exclude non-alphabetic smileys altogether from our study. This left us with a set of 3,459 positive and 2,755 negative labeled terms (1,738 and 1,943 unique expressions respectively), whose \u03baagreement run up to 0.59. Besides the test set, we selected a small subset of 400 tweets from the other annotator and used it as development data for tuning the hyper-parameters of the tested approaches.4"}, {"heading": "3 Evaluation Metrics", "text": "A central question to our experiments are the evaluation metrics that we should use for measuring lexicon quality. Usually, this quality is estimated either intrinsically (i.e., taking a lexicon in isolation and immediately assessing its accuracy) or extrinsically (i.e., considering the lexicon within the scope of a bigger application such as a supervised classifier which utilizes lexicon\u2019s entries as features).\n1We use version 0.1.0 of this corpus. 2The annotators had been asked to judge the semantic orientation of a term irrespective of its possible negations. They could, however, consider the context for determining whether a particular reading of a polysemous word in the text was subjective or not.\n3A detailed inter-annotator agreement study of this corpus is provided in (Sidarenka, 2016). 4That way, we only used the labeled corpus for evaluation or parameter optimization, other resources\u2014GERMANET (Hamp\nand Feldweg, 1997) and the German Twitter Snapshot (Scheffler, 2014)\u2014were used for training the methods.\nTraditionally, intrinsic evaluation of English sentiment lexicons amounts to comparing these polarity lists with the General Inquirer (GI; Stone, 1966)\u2014a manually compiled set of 11,895 words annotated with their semantic categories\u2014by taking the intersection of the two resources and estimating the percentage of matches in which automatically induced polar terms have the same polarity as the GI entries. This evaluation method, however, is somewhat problematic: First of all, it is not easily transferable to other languages, since even a manual translation of the GI lexicon is not guaranteed to cover all languageand domain-specific polar expressions. Secondly, due to the intersection, this method does not penalize for a low recall so that a lexicon consisting of just two terms good+ and bad\u2212 will have the highest possible score, often surpassing polarity lists with a greater number of entries. Finally, this comparison does not account for polysemy. As a result, an ambiguous word only one of whose (possibly rare) senses is subjective will always be ranked the same as a purely polar term.\nUnfortunately, an extrinsic evaluation does not always provide a solution in this case, since, depending on the type of the extrinsic system (e.g., a document classifier), it might still presuppose a large data set for training other system components and, furthermore, might yield overly high scores, which, however, are mainly due to these extrinsic modules rather than the quality of the lexicons themselves.\nInstead of using these approaches, we opt for a direct comparison of the induced polarity lists with an existing annotated corpus, since this type of evaluation allows us to solve at least three of the previously mentioned issues: It does account for the recall, it does accommodate polysemous words,5 and it does preclude intermediate components which might artificially boost the results. In particular, in order to check a lexicon against the PotTS data set, we construct a case-insensitive trie (Knuth, 1998, pp. 492\u2013512) from the lexicon entries and match this trie against the contiguously running corpus text,6 simultaneously comparing it with the actual word forms and lemmas of corpus tokens.7 A match is considered correct iff the matched entry absolutely corresponds to the (possibly lemmatized) expert\u2019s annotation and has the same polarity as the one specified by the human coder. That way, we estimate the precision, recall, and F1-score for each particular polarity class (positive, negative, and neutral), considering all words absent in the lexicons (not annotated in the corpus) as neutral."}, {"heading": "4 Semi-Automatic Lexicons", "text": "We first apply the above metric to estimate the quality of the existing German resources: the German Polarity Clues (GPC; Waltinger, 2010), SentiWS (SWS; Remus, 2010), and the Zurich Polarity List (ZPL) of Clematide and Klenner (2010).\nThe GPC set comprises 10,141 subjective entries automatically translated from the English sentiment lexicons Subjectivity Clues (Wilson et al., 2005) and SentiSpin (Takamura et al., 2005), with a subsequent manual correction of these translations, and several synonyms and negated terms added by the authors. The SWS lexicon includes 1,818 positively and 1,650 negatively connoted terms, also providing their part-of-speech tags and inflections (resulting in a total of 32,734 word forms). Similarly to the GPC, the authors used an English sentiment resource\u2014the GI lexicon of Stone et al. (1966)\u2014to bootstrap their polarity list, manually revising these automatic translations afterwards. In addition to that, Remus et al. (2010) also expanded their set with words and phrases frequently co-occurring with positive and negative seed lexemes using collocation information obtained from a corpus of 10,200 customer reviews and the German Collocation Dictionary (Quasthoff, 2010). Finally, the Zurich Polarity List features 8,000 subjective entries taken from GERMANET synsets (Hamp and Feldweg, 1997). These synsets were manually annotated with their prior polarities by human experts. Since the authors, however, found the number of polar adjectives obtained that way insufficient for running further classification experiments, they automatically enriched this lexicon with more attributive terms by analyzing conjoined corpus collocations using the method of Hatzivassiloglou and McKeown (1997).\n5Recall that the annotators of the PotTS data set were asked to annotate a polar expression iff its actual sense in the respective context was polar.\n6In other words, we successively compare lexicon entries with the occurrences of corpus tokens in the same linear order as these occurrences appear in the text.\n7We use the TREETAGGER of Schmid (1995) for lemmatization.\nGPC \u2013 German Polarity Clues (Waltinger, 2010), SWS \u2013 SentiWS (Remus et al., 2010), ZPL \u2013 Zurich Polarity Lexicon\n(Clematide and Klenner, 2010)\nFor our evaluation, we tested the three lexicons in isolation and also built their union and intersection in order to check for \u201csynergy\u201d effects. The results are shown in Table 1. As can be seen from the statistics, with a few exceptions, the highest scores for all classes as well as the best macro- and micro-averaged F1-measures are achieved by the intersection of all three lexicons. On the other hand, as expected, the highest recall of polar expressions (and consequently the best precision at recognizing neutral terms) is attained by the union of these resources. The only case where individual lexicons are able to outperform these combinations is observed for the F1-score of the negative class, where both SentiWS and ZPL show better results than their intersection, which is mainly due to the higher recall of these two polarity lists."}, {"heading": "5 Automatic Methods", "text": "A natural question which arises upon the evaluation of the existing semi-automatic resources is how well fully automatic methods can perform in comparison with these lexicons. Traditionally, automatic SLG algorithms have been grouped into dictionary- and corpus-based ones, with their own complementary strengths and weaknesses. Dictionary-based approaches, for instance, incorporate distilled linguistic knowledge from a typically manually labeled lexical database, but lack any domain specificity. Corpusbased methods, on the other hand, can operate directly on unannotated in-domain data, but often have to deal with an extreme noisiness of their input. Since it was unclear which of these properties would have a stronger impact on the net results, we decided to reimplement the most commonly used algorithms from both of these paradigms and evaluate them on the PotTS corpus."}, {"heading": "5.1 Dictionary-Based Approaches", "text": "For dictionary-based methods, we adopted the systems proposed by Hu and Liu (2004), BlairGoldensohn et al. (2008), Kim and Hovy (2004), Esuli and Sebastiani (2006), as well as the min-cut and label-propagation approaches of Rao and Ravichandran (2009), and the random-walk algorithm described by Awadallah and Radev (2010).\nThe first of these works (Hu and Liu, 2004) expanded a given set of seed terms with known semantic orientations by propagating polarity values of these terms to their WORDNET synonyms and passing reversed polarity scores to the antonyms of these words. Later on, this idea was further refined by BlairGoldensohn et al. (2008), who obtained polarity labels for new terms by multiplying a score vector ~v containing the orientation scores of the known seed words (-1 for negative expressions and 1 for positive ones) with an adjacency matrix A constructed for the WORDNET graph. With various modifications, the core idea of passing the polarity values through a lexical graph was adopted in almost all of the following dictionary-based works: Kim and Hovy (2004), for instance, computed the polarity class for a new word w by multiplying the prior probability of this class with the likelihood of the word w occurring among the synonyms of the seed terms with the given semantic orientation, choosing at the end the polarity which maximized this equation. Other ways of bootstrapping polarity lists were proposed by Esuli and Sebastiani (2006), who created their SENTIWORDNET resource using a committee of Rocchio and SVM classifiers trained on successively expanded sets of polar terms; Rao and Ravichandran (2009), who adopted the min-cut approach of Blum et al. (2004), also comparing it with the label-propagation algorithm of Zhu and Ghahramani (2002); and, finally, Awadallah and Radev (2010), who used a random\nwalk method by estimating the polarity of an unknown word as the difference between an average number of steps a random walker had to make in order to reach a term from the positive or negative set.\nSince some of these approaches relied on different seed sets or pursued different objectives (twoversus three-way classification), we decided to unify their settings and interfaces for the sake of our experiments. In particular, we were using the same translated seed list of Turney and Littman (2003) for all methods, expanding this set by 10 neutral terms (\u201cneutral\u201d neutral, \u201csachlich\u201d objective, \u201ctechnisch\u201d technical, \u201cfinanziell\u201d financial etc.).8 Additionally, we enhanced all binary systems to ternary classifiers, so that each tested method could differentiate between positive, negative, and neutral terms. In the final step, we applied these methods to GERMANET (Hamp and Feldweg, 1997)\u2014a German equivalent of the English WORDNET (Miller, 1995), which, however, is much smaller in size, having 20,792 less synsets for the three common parts of speech (nouns, adjectives, and verbs) than the Princeton resource.\nHL \u2013 Hu and Liu (2004), BG \u2013 Blair-Goldensohn et al. (2008), KH \u2013 Kim and Hovy (2004), ES \u2013 Esuli and Sebastiani (2006),\nRR \u2013 Rao and Ravichandran (2009), AR \u2013 Awadallah and Radev (2010)\nThe results of this evaluation are shown in Table 2. This time, the situation is much more varied, as different systems can achieve best results on just some aspects of certain classes but can hardly attain best overall scores in all categories. This is, for instance, the case for the positive and negative polarities, where the best precision scores are reached by the seed set in the first case and the label propagation algorithm of Rao and Ravichandran (2009) in the second case. However, with respect to the recall, both of these polarity lists perform notably worse than the approach of Esuli and Sebastiani (2006). Yet other systems\u2014the matrix-vector method of Blair-Goldensohn et al. (2008) and the union of the three overall top-scoring systems respectively\u2014reach the highest F1-scores for these two classes. Nevertheless, we can still notice three main tendencies in this evaluation: i) the method of Esuli and Sebastiani (2006) generally gets the highest recall of polar terms and, consequently, achieves the best precision in recognizing neutral words, but suffers from a low precision for the positive and negative polarities; ii) simultaneously five systems attain the same best F1-scores on recognizing neutral terms, which, in turn, leads to the best micro-averaged F1-results for all polarity classes; and, finally, iii) the system of Blair-Goldensohn et al. (2008) shows the best macro-averaged performance. This approach, however, is extremely susceptible to its hyper-parameter settings (in particular, we considered the maximum number of times the initial vector ~v was multiplied with the adjacency matrix A as such a parameter and noticed a dramatic decrease of method\u2019s scores after the fifth iteration)."}, {"heading": "5.2 Corpus-Based Approaches", "text": "An alternative way to generate polarity lists is to use corpus-based approaches. In contrast to dictionarybased methods, these systems typically operate immediately on raw texts and are, therefore, virtually independent of any manually annotated linguistic resources. This flexibility, however, might come at the cost of a reduced accuracy due to an inherent noisiness of the unlabeled data. The most prominent representatives of this class of algorithms are the approaches proposed by Takamura et al. (2005), Velikovich et al. (2010), Kiritchenko et al. (2014), and Severyn and Moschitti (2015), which we briefly describe in this section.\n8All translated seed sets are provided along with the source code for this paper.\nDrawing on the pioneering work of Hatzivassiloglou and McKeown (1997), in which the authors expanded an initial list of polar adjectives by analyzing coordinately conjoined terms from a text corpus, Takamura et al. (2005) enhanced this algorithm, extending it to other parts of speech and also incorporating semantic links from WORDNET in addition to the co-occurrence statistics extracted from the corpus. After representing the final set of terms as an electron lattice, whose edge weights corresponded to the contextual and semantic links between words, the authors computed the most probable polarity distribution for this lattice by adopting the Ising spin model from statistical mechanics.\nThe approach of Velikovich et al. (2010) was mainly inspired by the label-propagation algorithm of Rao and Ravichandran (2009), with the crucial difference that, instead of taking an averaged sum of the adjacent neighbor values when propagating the label scores through the graph, the authors took the maximum of these scores in order to prune unreliable, noisy corpus links. Similarly, Kiritchenko et al. (2014) built on the method of Turney and Littman (2003) and computed polarity scores for new words by taking the difference of their PMI associations with noisy labeled positive and negative classes. Finally, Severyn and Moschitti (2015) trained a supervised SVM classifier on a distantly labeled data set and included the top-ranked unigram and bigram features in their final lexicon.\nFor our evaluation, we applied these methods to the German Twitter Snapshot (Scheffler, 2014)\u2014a collection of 24 M microblogs gathered in April, 2013, constructing the collocation graph from the lemmatized word forms of this corpus and only considering words which appeared at least four times in the analyzed data. We again were using the TREETAGGER of Schmid (1995) for lemmatization and GERMANET (Hamp and Feldweg, 1997) for deriving semantic links between word vertices for the method of Takamura et al. (2005).\nTKM \u2013 Takamura et al. (2005), VEL \u2013 Velikovich et al. (2010), KIR \u2013 Kiritchenko et al. (2014), SEV \u2013 Severyn and Moschitti\n(2015)\nThe results of these experiments are shown in Table 3. This time, we can observe a clear superiority of Takamura et al.\u2019s method, which not only achieves the best recall and F1 in recognizing positive and negative items but also attains the highest micro- and macro-averaged results for all three polarity classes. The cardinality of the other induced lexicons, however, is much smaller than the size of Takamura et al.\u2019s polarity list. Moreover, these lexicons also show absolutely identical scores for the negative expressions as the original seed set. Since these results were somewhat unexpected, we decided to investigate the reasons for possible problems. As it turned out, the macro-averaged F1-values of these methods were rapidly going down on the held-out development set as the number of their induced polar terms increased. Since we considered the lexicon size as one of the hyper-parameters of the tested approaches, we immediately stopped populating these lexicons when we noticed a decrease in their results. As a consequence, only the highest-ranked terms (all of which had the positive polarity) were included in the final lists.\nOne of the reasons for such rapid quality decrease was the surprisingly high positive bias of the initial seed set: While converting the original seed list of Turney and Littman (2003) to German, we translated the English word \u201ccorrect\u201d as \u201crichtig\u201d. This German word, however, also has another reading which means real (as in a real fact or a real sports car) and which was much more frequent in the analyzed snapshot, often appearing in an unequivocally negative context, e.g., \u201cein richtiger Bombenanschlag\u201d (a real bomb attack) or \u201cein richtiger Terrorist\u201d (a real terrorist). As a consequence of this, methods relying on distant supervision had to deal with an extremely unbalanced training set (the automatically labeled corpus that we distantly obtained for the approach of Kiritchenko et al. (2014) using these seeds,\nfor instance, had 716,210 positive versus 92,592 negative training instances)."}, {"heading": "6 Effect of Seed Sets", "text": "Since the set of the initial seed terms appeared to play an important role for at least three of the tested methods, we decided to analyze the impact of this factor in more detail by repeating our experiments with the seed lists proposed by Hu and Liu (2004), Kim and Hovy (2004), Esuli and Sebastiani (2006), and Remus et al. (2010). For this purpose, we manually translated the seed sets of Hu and Liu (2004) and Kim and Hovy (2004) into German. Since the authors, however, only provided some examples of their seeds without specifying the full lists, we filled up our translations with additional polar terms to match the original cardinalities. A different procedure was applied to obtain the seed set of Esuli and Sebastiani (2006)\u2014since this resource comprised a vast number of neutral terms (the authors considered as neutral all words from the General Inquirer lexicon which were not marked there as either positive or negative), we automatically translated the neutral subset of these seeds with the help of a publicly available translation site (http://www.dict.cc), using the first suggestion returned by this service for each original English term.\nThe updated results for the dictionary-based approaches with the alternative seed sets are shown in Figure 1. This time, we again can notice superior scores achieved by the method of Blair-Goldensohn et al. (2008), which not only performs better than the other systems on average but also seems to be less susceptible to the varying quality and size of the different seed lists. The remaining methods typically achieve their best macro-averaged results with either of the two top-scoring polarity sets\u2014the seed list of Kim and Hovy (2004) or the seed set of Esuli and Sebastiani (2006). This is, for instance, the case for the method of Kim and Hovy (2004) and the min-cut approach of Rao and Ravichandran (2009), whose performance with the native Kim-Hovy seed set is on par with their results achieved using the Turney-Littman seeds. The label-propagation and random walk algorithms can even strongly benefit from the seeds provided by Kim and Hovy (2004). The remaining two methods\u2014Hu and Liu (2004) and Esuli and Sebastiani (2006)\u2014work best in combination with the initial polarity set proposed by Esuli and Sebastiani (2006).\nA slightly different situation is observed for the corpus-based approaches as shown in Figure 2. Except for the method of Takamura et al. (2005), all three remaining methods\u2014Velikovich et al. (2010), Kiritchenko et al. (2014), and Severyn and Moschitti (2015)\u2014show very similar (though not identical) scores. Moreover, these scores are also very close to the results achieved by the respective seed sets without any expansion. The primary reasons for this were again the positive bias of the distantly labeled tweets and the consequently premature stopping of the expansion.\nFollowing the suggestion of one of the reviewers, we additionally included two more seed sets in our evaluation: gold precision and emoticons. The former list contained just two polar terms\u2014\u201cgut\u201d (good+) and \u201cschlecht\u201d (bad\u2212)\u2014which showed an almost perfect precision on the PotTS data set.9 The\n9Unfortunately, we could not include more terms in this seed set due to a high lexical ambiguity of other polar words. Even in our proposed prototypical seed list, one of the terms\u2014\u201cgut\u201d (good)\u2014could have another rather rare reading (manor) when used as a noun.\nlatter seed set consisted of two regular expressions: one for capturing positive smileys and another one for matching negative emoticons. As can be seen form the figure, these lists, however, could hardly outperform any of our initially used seed sets."}, {"heading": "7 Analysis of Entries", "text": "Besides investigating the effects of different hyper-parameters and seeds, we also decided to have a closer look at the actual results produced by the tested methods. For this purpose, we extracted ten highest scored entries (not counting the seed terms) from each automatic lexicon and summarized them in Table 4.\nAs can be seen from the table, the approaches of Hu and Liu (2004), Blair-Goldensohn et al. (2008), Kim and Hovy (2004), as well as the label-propagation algorithm of Rao and Ravichandran (2009) produce almost perfect polarity lists. The SENTIWORDNET approach of Esuli and Sebastiani (2006), however, already features some spurious terms (e.g., \u201cabsichtslos\u201d unintentional) among its top-scored entries. Finally, the min-cut approach of Rao and Ravichandran (2009) returns a set of mainly objective terms, which, however, is rather due to the fact that this method performs a cluster-like partitioning of the lexical graph without ranking the words assigned to a cluster.\nAn opposite situation is observed for the corpus-based systems: The top-scoring polarity lists returned by these approaches not only include many apparently objective terms but are also difficult to interpret in\ngeneral, as they contain a substantial number of slang and advertising terms (e.g., \u201cBMKS65\u201d, \u201c#gameinsight\u201d, \u201c#androidgames\u201d etc.). This again supports the hypothesis that an extreme content noisiness of the input domain might pose considerable difficulties to sentiment lexicon generation methods."}, {"heading": "8 Conclusions and Future Work", "text": "Based on the above observations and our experiments, we can formulate the main conclusions that we come to in this paper as follows:\n\u2022 semi-automatic translations of common English polarity lists notably outperform automatic SLG approaches that are applied directly to non-English data;\n\u2022 despite their allegedly worse ability to accommodate new domains, dictionary-based methods are still superior to corpus-based systems (at least in terms of the proposed intrinsic evaluation), provided that a sufficiently big lexical taxonomy exists for the target language;\n\u2022 a potential weakness of the dictionary-based algorithms, however, is their susceptibility to different hyper-parameter settings and the size and composition of the initial seed sets;\n\u2022 nevertheless, the effect of the seed sets might be even stronger for the corpus-based approaches which rely on distant supervision, if the resulting noisy labeled training set becomes highly unbalanced.\nIn this respect, there appears to be a great need for a corpus-based method which can both benefit from in-domain data and be resistant to non-balanced training sets; and we are, in fact, currently working on such an algorithm. By taking advantage of the recent advances in deep learning and distributional semantics, we aim to show an efficient way of getting suitable vector representations for polar terms and generating high-quality sentiment lexicons from these automatically learned vectors."}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers for their suggestions and comments."}], "references": [{"title": "When specialists and generalists work together: Overcoming domain dependence in sentiment tagging", "author": ["Alina Andreevskaia", "Sabine Bergler."], "venue": "ACL 2008, Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, June 15-20, 2008, Columbus, Ohio, USA, pages 290\u2013298. The Association for Computer Linguistics.", "citeRegEx": "Andreevskaia and Bergler.,? 2008", "shortCiteRegEx": "Andreevskaia and Bergler.", "year": 2008}, {"title": "Identifying text polarity using random walks", "author": ["Ahmed Hassan Awadallah", "Dragomir R. Radev."], "venue": "Jan Hajic, Sandra Carberry, and Stephen Clark, editors, ACL 2010, Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, July 11-16, 2010, Uppsala, Sweden, pages 395\u2013403. The Association for Computer Linguistics.", "citeRegEx": "Awadallah and Radev.,? 2010", "shortCiteRegEx": "Awadallah and Radev.", "year": 2010}, {"title": "Building a sentiment summarizer for local service reviews", "author": ["Sasha Blair-Goldensohn", "Tyler Neylon", "Kerry Hannan", "George A. Reis", "Ryan Mcdonald", "Jeff Reynar."], "venue": "In NLP in the Information Explosion Era.", "citeRegEx": "Blair.Goldensohn et al\\.,? 2008", "shortCiteRegEx": "Blair.Goldensohn et al\\.", "year": 2008}, {"title": "Semi-supervised learning using randomized mincuts", "author": ["Avrim Blum", "John D. Lafferty", "Mugizi Robert Rwebangira", "Rajashekar Reddy."], "venue": "Carla E. Brodley, editor, Machine Learning, Proceedings of the Twenty-first International Conference (ICML 2004), Banff, Alberta, Canada, July 4-8, 2004, volume 69 of ACM International Conference Proceeding Series. ACM.", "citeRegEx": "Blum et al\\.,? 2004", "shortCiteRegEx": "Blum et al\\.", "year": 2004}, {"title": "European Language Resources Association", "author": ["Valletta", "Malta"], "venue": "Proceedings of the International Conference on Language Resources and Evaluation,", "citeRegEx": "Valletta and Malta.,? \\Q2010\\E", "shortCiteRegEx": "Valletta and Malta.", "year": 2010}, {"title": "New avenues in knowledge bases for natural language processing", "author": ["Erik Cambria", "Bj\u00f6rn W. Schuller", "Yunqing Xia", "Bebo White."], "venue": "Knowl.-Based Syst., 108:1\u20134.", "citeRegEx": "Cambria et al\\.,? 2016", "shortCiteRegEx": "Cambria et al\\.", "year": 2016}, {"title": "Evaluation and extension of a polarity lexicon for German", "author": ["Simon Clematide", "Manfred Klenner."], "venue": "Proceedings of the First Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, pages 7\u201313.", "citeRegEx": "Clematide and Klenner.,? 2010", "shortCiteRegEx": "Clematide and Klenner.", "year": 2010}, {"title": "A coefficient of agreement for nominal scales", "author": ["Jacob Cohen."], "venue": "Educational and Psychological Measurement, 20(1):37\u201346.", "citeRegEx": "Cohen.,? 1960", "shortCiteRegEx": "Cohen.", "year": 1960}, {"title": "SentiWordNet: a high-coverage lexical resource for opinion mining", "author": ["Andrea Esuli", "Fabrizio Sebastiani."], "venue": "Technical Report ISTI-PP-002/2007, Institute of Information Science and Technologies (ISTI) of the Italian National Research Council (CNR), October.", "citeRegEx": "Esuli and Sebastiani.,? 2006", "shortCiteRegEx": "Esuli and Sebastiani.", "year": 2006}, {"title": "GermaNet - a lexical-semantic net for German", "author": ["Birgit Hamp", "Helmut Feldweg."], "venue": "In Proceedings of ACL workshop Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications, pages 9\u201315.", "citeRegEx": "Hamp and Feldweg.,? 1997", "shortCiteRegEx": "Hamp and Feldweg.", "year": 1997}, {"title": "Predicting the semantic orientation of adjectives", "author": ["Vasileios Hatzivassiloglou", "Kathleen McKeown."], "venue": "Philip R. Cohen and Wolfgang Wahlster, editors, 35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference, 7-12 July 1997, Universidad Nacional de Educaci\u00f3n a Distancia (UNED), Madrid, Spain., pages 174\u2013181. Morgan Kaufmann Publishers / ACL.", "citeRegEx": "Hatzivassiloglou and McKeown.,? 1997", "shortCiteRegEx": "Hatzivassiloglou and McKeown.", "year": 1997}, {"title": "Mining and summarizing customer reviews", "author": ["Minqing Hu", "Bing Liu."], "venue": "Won Kim, Ron Kohavi, Johannes Gehrke, and William DuMouchel, editors, KDD, pages 168\u2013177. ACM.", "citeRegEx": "Hu and Liu.,? 2004", "shortCiteRegEx": "Hu and Liu.", "year": 2004}, {"title": "Determining the sentiment of opinions", "author": ["Soo-Min Kim", "Eduard H. Hovy."], "venue": "COLING 2004, 20th International Conference on Computational Linguistics, Proceedings of the Conference, 23-27 August 2004, Geneva, Switzerland.", "citeRegEx": "Kim and Hovy.,? 2004", "shortCiteRegEx": "Kim and Hovy.", "year": 2004}, {"title": "Sentiment Analysis of Short Informal Texts", "author": ["Svetlana Kiritchenko", "Xiaodan Zhu", "Saif M. Mohammad."], "venue": "J. Artif. Intell. Res. (JAIR), 50:723\u2013762.", "citeRegEx": "Kiritchenko et al\\.,? 2014", "shortCiteRegEx": "Kiritchenko et al\\.", "year": 2014}, {"title": "The Art of Computer Programming, Volume 3: (2Nd Ed.) Sorting and Searching", "author": ["Donald E. Knuth"], "venue": null, "citeRegEx": "Knuth.,? \\Q1998\\E", "shortCiteRegEx": "Knuth.", "year": 1998}, {"title": "Sentiment Analysis and Opinion Mining", "author": ["Bing Liu."], "venue": "Synthesis Lectures on Human Language Technologies. Morgan & Claypool Publishers.", "citeRegEx": "Liu.,? 2012", "shortCiteRegEx": "Liu.", "year": 2012}, {"title": "WordNet: A Lexical Database for English", "author": ["George A. Miller."], "venue": "Communications of ACM, 38(11):39\u201341, November.", "citeRegEx": "Miller.,? 1995", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "NRC-Canada: Building the State-of-the-Art in Sentiment Analysis of Tweets", "author": ["Saif M. Mohammad", "Svetlana Kiritchenko", "Xiaodan Zhu."], "venue": "CoRR, abs/1308.6242.", "citeRegEx": "Mohammad et al\\.,? 2013", "shortCiteRegEx": "Mohammad et al\\.", "year": 2013}, {"title": "SemEval-2013 Task 2: Sentiment Analysis in Twitter", "author": ["Preslav Nakov", "Sara Rosenthal", "Zornitsa Kozareva", "Veselin Stoyanov", "Alan Ritter", "Theresa Wilson."], "venue": "Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 312\u2013320, Atlanta, Georgia, USA, June. Association for Computational Linguistics.", "citeRegEx": "Nakov et al\\.,? 2013", "shortCiteRegEx": "Nakov et al\\.", "year": 2013}, {"title": "Deutsches Kollokationsw\u00f6rterbuch", "author": ["Uwe Quasthoff."], "venue": "deGruyter, Berlin, New York.", "citeRegEx": "Quasthoff.,? 2010", "shortCiteRegEx": "Quasthoff.", "year": 2010}, {"title": "Semi-supervised polarity lexicon induction", "author": ["Delip Rao", "Deepak Ravichandran."], "venue": "Alex Lascarides, Claire Gardent, and Joakim Nivre, editors, EACL 2009, 12th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference, Athens, Greece, March 30 - April 3, 2009, pages 675\u2013682. The Association for Computer Linguistics.", "citeRegEx": "Rao and Ravichandran.,? 2009", "shortCiteRegEx": "Rao and Ravichandran.", "year": 2009}, {"title": "SentiWS - A publicly available German-language resource for sentiment analysis", "author": ["Robert Remus", "Uwe Quasthoff", "Gerhard Heyer."], "venue": "Calzolari et al. (Calzolari et al., 2010).", "citeRegEx": "Remus et al\\.,? 2010", "shortCiteRegEx": "Remus et al\\.", "year": 2010}, {"title": "SemEval-2014 Task 9: Sentiment Analysis in Twitter", "author": ["Sara Rosenthal", "Alan Ritter", "Preslav Nakov", "Veselin Stoyanov."], "venue": "Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 73\u201380, Dublin, Ireland, August. Association for Computational Linguistics and Dublin City University.", "citeRegEx": "Rosenthal et al\\.,? 2014", "shortCiteRegEx": "Rosenthal et al\\.", "year": 2014}, {"title": "Semeval-2015 task 10: Sentiment analysis in twitter", "author": ["Sara Rosenthal", "Preslav Nakov", "Svetlana Kiritchenko", "Saif Mohammad", "Alan Ritter", "Veselin Stoyanov."], "venue": "Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 451\u2013463, Denver, Colorado, June. Association for Computational Linguistics.", "citeRegEx": "Rosenthal et al\\.,? 2015", "shortCiteRegEx": "Rosenthal et al\\.", "year": 2015}, {"title": "A German Twitter Snapshot", "author": ["Tatjana Scheffler."], "venue": "Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asunci\u00f3n Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014), Reykjavik, Iceland, May 26-31, 2014., pages 2284\u20132289. European Language Resources Association (ELRA).", "citeRegEx": "Scheffler.,? 2014", "shortCiteRegEx": "Scheffler.", "year": 2014}, {"title": "Probabilistic part-of-speech tagging using decision trees", "author": ["Helmut Schmid."], "venue": "Proceedings of the ACL SIGDAT-Workshop.", "citeRegEx": "Schmid.,? 1995", "shortCiteRegEx": "Schmid.", "year": 1995}, {"title": "On the automatic learning of sentiment lexicons", "author": ["Aliaksei Severyn", "Alessandro Moschitti."], "venue": "Rada Mihalcea, Joyce Yue Chai, and Anoop Sarkar, editors, NAACL HLT 2015, The 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Denver, Colorado, USA, May 31 - June 5, 2015, pages 1397\u20131402. The Association for Computational Linguistics.", "citeRegEx": "Severyn and Moschitti.,? 2015", "shortCiteRegEx": "Severyn and Moschitti.", "year": 2015}, {"title": "PotTS: The Potsdam Twitter Sentiment Corpus", "author": ["Uladzimir Sidarenka."], "venue": "Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Sara Goggi, Marko Grobelnik, Bente Maegaard, Joseph Mariani, H\u00e9l\u00e8ne Mazo, Asunci\u00f3n Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Tenth International Conference on Language Resources and Evaluation LREC 2016, Portoro\u017e, Slovenia, May 23-28, 2016. European Language Resources Association (ELRA).", "citeRegEx": "Sidarenka.,? 2016", "shortCiteRegEx": "Sidarenka.", "year": 2016}, {"title": "The General Inquirer: A Computer Approach to Content Analysis", "author": ["Philip J. Stone", "Dexter C. Dunphy", "Marshall S. Smith", "Daniel M. Ogilvie."], "venue": "MIT Press, Cambridge, MA.", "citeRegEx": "Stone et al\\.,? 1966", "shortCiteRegEx": "Stone et al\\.", "year": 1966}, {"title": "Lexicon-based methods for sentiment analysis", "author": ["Maite Taboada", "Julian Brooke", "Milan Tofiloski", "Kimberly D. Voll", "Manfred Stede."], "venue": "Computational Linguistics, 37(2):267\u2013307.", "citeRegEx": "Taboada et al\\.,? 2011", "shortCiteRegEx": "Taboada et al\\.", "year": 2011}, {"title": "Extracting semantic orientations of words using spin model", "author": ["Hiroya Takamura", "Takashi Inui", "Manabu Okumura."], "venue": "Kevin Knight, Hwee Tou Ng, and Kemal Oflazer, editors, ACL 2005, 43rd Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, 25-30 June 2005, University of Michigan, USA. The Association for Computer Linguistics.", "citeRegEx": "Takamura et al\\.,? 2005", "shortCiteRegEx": "Takamura et al\\.", "year": 2005}, {"title": "Measuring praise and criticism: Inference of semantic orientation from association", "author": ["Peter D. Turney", "Michael L. Littman."], "venue": "ACM Trans. Inf. Syst., 21(4):315\u2013346.", "citeRegEx": "Turney and Littman.,? 2003", "shortCiteRegEx": "Turney and Littman.", "year": 2003}, {"title": "The viability of webderived polarity lexicons", "author": ["Leonid Velikovich", "Sasha Blair-Goldensohn", "Kerry Hannan", "Ryan T. McDonald."], "venue": "Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings, June 2-4, 2010, Los Angeles, California, USA, pages 777\u2013785. The Association for Computational Linguistics.", "citeRegEx": "Velikovich et al\\.,? 2010", "shortCiteRegEx": "Velikovich et al\\.", "year": 2010}, {"title": "GermanPolarityClues: A Lexical Resource for German Sentiment Analysis", "author": ["Ulli Waltinger."], "venue": "Calzolari et al. (Calzolari et al., 2010).", "citeRegEx": "Waltinger.,? 2010", "shortCiteRegEx": "Waltinger.", "year": 2010}, {"title": "Recognizing contextual polarity in phrase-level sentiment analysis", "author": ["Theresa Wilson", "Janyce Wiebe", "Paul Hoffmann."], "venue": "HLT/EMNLP 2005, Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference, 6-8 October 2005, Vancouver, British Columbia, Canada. The Association for Computational Linguistics.", "citeRegEx": "Wilson et al\\.,? 2005", "shortCiteRegEx": "Wilson et al\\.", "year": 2005}, {"title": "Learning from labeled and unlabeled data with label propagation, cmu-cald-02-107", "author": ["Xiaojin Zhu", "Zoubin Ghahramani."], "venue": "Technical report, Carnegie Mellon University.", "citeRegEx": "Zhu and Ghahramani.,? 2002", "shortCiteRegEx": "Zhu and Ghahramani.", "year": 2002}, {"title": "Nrc-canada-2014: Recent improvements in the sentiment analysis of tweets", "author": ["Xiaodan Zhu", "Svetlana Kiritchenko", "Saif Mohammad."], "venue": "Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 443\u2013447, Dublin, Ireland, August. Association for Computational Linguistics and Dublin City University.", "citeRegEx": "Zhu et al\\.,? 2014", "shortCiteRegEx": "Zhu et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 17, "context": "only do they serve as a valuable source of features for supervised classifiers (Mohammad et al., 2013; Zhu et al., 2014) but they also achieve competitive results when used as the main component of a sentiment analysis system (Taboada et al.", "startOffset": 79, "endOffset": 120}, {"referenceID": 36, "context": "only do they serve as a valuable source of features for supervised classifiers (Mohammad et al., 2013; Zhu et al., 2014) but they also achieve competitive results when used as the main component of a sentiment analysis system (Taboada et al.", "startOffset": 79, "endOffset": 120}, {"referenceID": 29, "context": ", 2014) but they also achieve competitive results when used as the main component of a sentiment analysis system (Taboada et al., 2011).", "startOffset": 113, "endOffset": 135}, {"referenceID": 5, "context": "Nevertheless, despite some obvious progress in this field (Cambria et al., 2016), the applicability of these approaches to other languages and text genres still raises questions: It is, for instance, unclear whether simply translating the existing English sentiment resources would produce better results than applying the methods that were initially proposed for their creation directly to the target language.", "startOffset": 58, "endOffset": 80}, {"referenceID": 16, "context": "Furthermore, for automatic systems which draw their knowledge from lexical taxonomies, such as WORDNET (Miller, 1995), it remains", "startOffset": 103, "endOffset": 117}, {"referenceID": 33, "context": "Then, in Section 4, we evaluate three most popular existing German sentiment lexicons\u2014the German Polarity Clues (Waltinger, 2010), SentiWS (Remus et al.", "startOffset": 112, "endOffset": 129}, {"referenceID": 21, "context": "Then, in Section 4, we evaluate three most popular existing German sentiment lexicons\u2014the German Polarity Clues (Waltinger, 2010), SentiWS (Remus et al., 2010), and Zurich Polarity List of Clematide and Klenner (2010), subsequently comparing them with popular automatic SLG approaches in Section 5.", "startOffset": 139, "endOffset": 159}, {"referenceID": 6, "context": ", 2010), and Zurich Polarity List of Clematide and Klenner (2010), subsequently comparing them with popular automatic SLG approaches in Section 5.", "startOffset": 37, "endOffset": 66}, {"referenceID": 18, "context": "We should, however, note that, apart from the research on the automatic lexicon generation, our study is also closely related to the experiments of Andreevskaia and Bergler (2008) and the \u201cSentiment Analysis in Twitter\u201d track of the SemEval competition (Nakov et al., 2013; Rosenthal et al., 2014; Rosenthal et al., 2015).", "startOffset": 253, "endOffset": 321}, {"referenceID": 22, "context": "We should, however, note that, apart from the research on the automatic lexicon generation, our study is also closely related to the experiments of Andreevskaia and Bergler (2008) and the \u201cSentiment Analysis in Twitter\u201d track of the SemEval competition (Nakov et al., 2013; Rosenthal et al., 2014; Rosenthal et al., 2015).", "startOffset": 253, "endOffset": 321}, {"referenceID": 23, "context": "We should, however, note that, apart from the research on the automatic lexicon generation, our study is also closely related to the experiments of Andreevskaia and Bergler (2008) and the \u201cSentiment Analysis in Twitter\u201d track of the SemEval competition (Nakov et al., 2013; Rosenthal et al., 2014; Rosenthal et al., 2015).", "startOffset": 253, "endOffset": 321}, {"referenceID": 0, "context": "We should, however, note that, apart from the research on the automatic lexicon generation, our study is also closely related to the experiments of Andreevskaia and Bergler (2008) and the \u201cSentiment Analysis in Twitter\u201d track of the SemEval competition (Nakov et al.", "startOffset": 148, "endOffset": 180}, {"referenceID": 27, "context": "We perform our evaluation on the publicly available Potsdam Twitter Sentiment corpus (PotTS; Sidarenka, 2016).", "startOffset": 85, "endOffset": 109}, {"referenceID": 7, "context": "75 binary \u03ba (Cohen, 1960).", "startOffset": 12, "endOffset": 25}, {"referenceID": 27, "context": "A detailed inter-annotator agreement study of this corpus is provided in (Sidarenka, 2016).", "startOffset": 73, "endOffset": 90}, {"referenceID": 9, "context": "That way, we only used the labeled corpus for evaluation or parameter optimization, other resources\u2014GERMANET (Hamp and Feldweg, 1997) and the German Twitter Snapshot (Scheffler, 2014)\u2014were used for training the methods.", "startOffset": 109, "endOffset": 133}, {"referenceID": 24, "context": "That way, we only used the labeled corpus for evaluation or parameter optimization, other resources\u2014GERMANET (Hamp and Feldweg, 1997) and the German Twitter Snapshot (Scheffler, 2014)\u2014were used for training the methods.", "startOffset": 166, "endOffset": 183}, {"referenceID": 33, "context": "Polarity Clues (GPC; Waltinger, 2010), SentiWS (SWS; Remus, 2010), and the Zurich Polarity List (ZPL) of Clematide and Klenner (2010).", "startOffset": 15, "endOffset": 37}, {"referenceID": 6, "context": "Polarity Clues (GPC; Waltinger, 2010), SentiWS (SWS; Remus, 2010), and the Zurich Polarity List (ZPL) of Clematide and Klenner (2010).", "startOffset": 105, "endOffset": 134}, {"referenceID": 34, "context": "The GPC set comprises 10,141 subjective entries automatically translated from the English sentiment lexicons Subjectivity Clues (Wilson et al., 2005) and SentiSpin (Takamura et al.", "startOffset": 128, "endOffset": 149}, {"referenceID": 30, "context": ", 2005) and SentiSpin (Takamura et al., 2005), with a subsequent manual correction of these translations, and several synonyms and negated terms added by the authors.", "startOffset": 22, "endOffset": 45}, {"referenceID": 27, "context": "Similarly to the GPC, the authors used an English sentiment resource\u2014the GI lexicon of Stone et al. (1966)\u2014to bootstrap their polarity list, manually revising these automatic translations afterwards.", "startOffset": 87, "endOffset": 107}, {"referenceID": 21, "context": "In addition to that, Remus et al. (2010) also expanded their set with words and phrases frequently co-occurring with positive and negative", "startOffset": 21, "endOffset": 41}, {"referenceID": 19, "context": "seed lexemes using collocation information obtained from a corpus of 10,200 customer reviews and the German Collocation Dictionary (Quasthoff, 2010).", "startOffset": 131, "endOffset": 148}, {"referenceID": 9, "context": "Finally, the Zurich Polarity List features 8,000 subjective entries taken from GERMANET synsets (Hamp and Feldweg, 1997).", "startOffset": 96, "endOffset": 120}, {"referenceID": 9, "context": "Finally, the Zurich Polarity List features 8,000 subjective entries taken from GERMANET synsets (Hamp and Feldweg, 1997). These synsets were manually annotated with their prior polarities by human experts. Since the authors, however, found the number of polar adjectives obtained that way insufficient for running further classification experiments, they automatically enriched this lexicon with more attributive terms by analyzing conjoined corpus collocations using the method of Hatzivassiloglou and McKeown (1997).", "startOffset": 97, "endOffset": 518}, {"referenceID": 25, "context": "We use the TREETAGGER of Schmid (1995) for lemmatization.", "startOffset": 25, "endOffset": 39}, {"referenceID": 33, "context": "GPC \u2013 German Polarity Clues (Waltinger, 2010), SWS \u2013 SentiWS (Remus et al.", "startOffset": 28, "endOffset": 45}, {"referenceID": 21, "context": "GPC \u2013 German Polarity Clues (Waltinger, 2010), SWS \u2013 SentiWS (Remus et al., 2010), ZPL \u2013 Zurich Polarity Lexicon (Clematide and Klenner, 2010)", "startOffset": 61, "endOffset": 81}, {"referenceID": 6, "context": ", 2010), ZPL \u2013 Zurich Polarity Lexicon (Clematide and Klenner, 2010)", "startOffset": 39, "endOffset": 68}, {"referenceID": 9, "context": "For dictionary-based methods, we adopted the systems proposed by Hu and Liu (2004), BlairGoldensohn et al.", "startOffset": 65, "endOffset": 83}, {"referenceID": 9, "context": "For dictionary-based methods, we adopted the systems proposed by Hu and Liu (2004), BlairGoldensohn et al. (2008), Kim and Hovy (2004), Esuli and Sebastiani (2006), as well as the min-cut and label-propagation approaches of Rao and Ravichandran (2009), and the random-walk algorithm described by Awadallah and Radev (2010).", "startOffset": 65, "endOffset": 114}, {"referenceID": 9, "context": "For dictionary-based methods, we adopted the systems proposed by Hu and Liu (2004), BlairGoldensohn et al. (2008), Kim and Hovy (2004), Esuli and Sebastiani (2006), as well as the min-cut and label-propagation approaches of Rao and Ravichandran (2009), and the random-walk algorithm described by Awadallah and Radev (2010).", "startOffset": 65, "endOffset": 135}, {"referenceID": 7, "context": "(2008), Kim and Hovy (2004), Esuli and Sebastiani (2006), as well as the min-cut and label-propagation approaches of Rao and Ravichandran (2009), and the random-walk algorithm described by Awadallah and Radev (2010).", "startOffset": 29, "endOffset": 57}, {"referenceID": 7, "context": "(2008), Kim and Hovy (2004), Esuli and Sebastiani (2006), as well as the min-cut and label-propagation approaches of Rao and Ravichandran (2009), and the random-walk algorithm described by Awadallah and Radev (2010).", "startOffset": 29, "endOffset": 145}, {"referenceID": 1, "context": "(2008), Kim and Hovy (2004), Esuli and Sebastiani (2006), as well as the min-cut and label-propagation approaches of Rao and Ravichandran (2009), and the random-walk algorithm described by Awadallah and Radev (2010).", "startOffset": 189, "endOffset": 216}, {"referenceID": 11, "context": "The first of these works (Hu and Liu, 2004) expanded a given set of seed terms with known semantic orientations by propagating polarity values of these terms to their WORDNET synonyms and passing reversed polarity scores to the antonyms of these words.", "startOffset": 25, "endOffset": 43}, {"referenceID": 9, "context": "The first of these works (Hu and Liu, 2004) expanded a given set of seed terms with known semantic orientations by propagating polarity values of these terms to their WORDNET synonyms and passing reversed polarity scores to the antonyms of these words. Later on, this idea was further refined by BlairGoldensohn et al. (2008), who obtained polarity labels for new terms by multiplying a score vector ~v containing the orientation scores of the known seed words (-1 for negative expressions and 1 for positive ones) with an adjacency matrix A constructed for the WORDNET graph.", "startOffset": 26, "endOffset": 326}, {"referenceID": 9, "context": "The first of these works (Hu and Liu, 2004) expanded a given set of seed terms with known semantic orientations by propagating polarity values of these terms to their WORDNET synonyms and passing reversed polarity scores to the antonyms of these words. Later on, this idea was further refined by BlairGoldensohn et al. (2008), who obtained polarity labels for new terms by multiplying a score vector ~v containing the orientation scores of the known seed words (-1 for negative expressions and 1 for positive ones) with an adjacency matrix A constructed for the WORDNET graph. With various modifications, the core idea of passing the polarity values through a lexical graph was adopted in almost all of the following dictionary-based works: Kim and Hovy (2004), for instance, computed the polarity class for a new word w by multiplying the prior probability of this class with the likelihood of the word w occurring among the synonyms of the seed terms with the given semantic orientation, choosing at the end the polarity which maximized this equation.", "startOffset": 26, "endOffset": 761}, {"referenceID": 7, "context": "Other ways of bootstrapping polarity lists were proposed by Esuli and Sebastiani (2006), who created their SENTIWORDNET resource using a committee of Rocchio and SVM classifiers trained on successively expanded sets of polar terms; Rao and Ravichandran (2009), who adopted the min-cut approach of Blum et al.", "startOffset": 60, "endOffset": 88}, {"referenceID": 7, "context": "Other ways of bootstrapping polarity lists were proposed by Esuli and Sebastiani (2006), who created their SENTIWORDNET resource using a committee of Rocchio and SVM classifiers trained on successively expanded sets of polar terms; Rao and Ravichandran (2009), who adopted the min-cut approach of Blum et al.", "startOffset": 60, "endOffset": 260}, {"referenceID": 3, "context": "Other ways of bootstrapping polarity lists were proposed by Esuli and Sebastiani (2006), who created their SENTIWORDNET resource using a committee of Rocchio and SVM classifiers trained on successively expanded sets of polar terms; Rao and Ravichandran (2009), who adopted the min-cut approach of Blum et al. (2004), also comparing it with the label-propagation", "startOffset": 297, "endOffset": 316}, {"referenceID": 34, "context": "algorithm of Zhu and Ghahramani (2002); and, finally, Awadallah and Radev (2010), who used a random", "startOffset": 13, "endOffset": 39}, {"referenceID": 1, "context": "algorithm of Zhu and Ghahramani (2002); and, finally, Awadallah and Radev (2010), who used a random", "startOffset": 54, "endOffset": 81}, {"referenceID": 9, "context": "In the final step, we applied these methods to GERMANET (Hamp and Feldweg, 1997)\u2014a German equivalent of the English WORDNET (Miller, 1995), which, however, is much smaller in size, having 20,792 less synsets for the three common parts of speech (nouns, adjectives, and verbs) than the Princeton resource.", "startOffset": 56, "endOffset": 80}, {"referenceID": 16, "context": "In the final step, we applied these methods to GERMANET (Hamp and Feldweg, 1997)\u2014a German equivalent of the English WORDNET (Miller, 1995), which, however, is much smaller in size, having 20,792 less synsets for the three common parts of speech (nouns, adjectives, and verbs) than the Princeton resource.", "startOffset": 124, "endOffset": 138}, {"referenceID": 29, "context": "In particular, we were using the same translated seed list of Turney and Littman (2003) for all methods, expanding this set by 10 neutral terms (\u201cneutral\u201d neutral, \u201csachlich\u201d objective, \u201ctechnisch\u201d technical, \u201cfinanziell\u201d financial etc.", "startOffset": 62, "endOffset": 88}, {"referenceID": 8, "context": "HL \u2013 Hu and Liu (2004), BG \u2013 Blair-Goldensohn et al.", "startOffset": 5, "endOffset": 23}, {"referenceID": 1, "context": "HL \u2013 Hu and Liu (2004), BG \u2013 Blair-Goldensohn et al. (2008), KH \u2013 Kim and Hovy (2004), ES \u2013 Esuli and Sebastiani (2006), RR \u2013 Rao and Ravichandran (2009), AR \u2013 Awadallah and Radev (2010)", "startOffset": 29, "endOffset": 60}, {"referenceID": 1, "context": "HL \u2013 Hu and Liu (2004), BG \u2013 Blair-Goldensohn et al. (2008), KH \u2013 Kim and Hovy (2004), ES \u2013 Esuli and Sebastiani (2006), RR \u2013 Rao and Ravichandran (2009), AR \u2013 Awadallah and Radev (2010)", "startOffset": 29, "endOffset": 86}, {"referenceID": 1, "context": "HL \u2013 Hu and Liu (2004), BG \u2013 Blair-Goldensohn et al. (2008), KH \u2013 Kim and Hovy (2004), ES \u2013 Esuli and Sebastiani (2006), RR \u2013 Rao and Ravichandran (2009), AR \u2013 Awadallah and Radev (2010)", "startOffset": 29, "endOffset": 120}, {"referenceID": 1, "context": "HL \u2013 Hu and Liu (2004), BG \u2013 Blair-Goldensohn et al. (2008), KH \u2013 Kim and Hovy (2004), ES \u2013 Esuli and Sebastiani (2006), RR \u2013 Rao and Ravichandran (2009), AR \u2013 Awadallah and Radev (2010)", "startOffset": 29, "endOffset": 154}, {"referenceID": 1, "context": "(2008), KH \u2013 Kim and Hovy (2004), ES \u2013 Esuli and Sebastiani (2006), RR \u2013 Rao and Ravichandran (2009), AR \u2013 Awadallah and Radev (2010)", "startOffset": 107, "endOffset": 134}, {"referenceID": 18, "context": "algorithm of Rao and Ravichandran (2009) in the second case.", "startOffset": 13, "endOffset": 41}, {"referenceID": 7, "context": "However, with respect to the recall, both of these polarity lists perform notably worse than the approach of Esuli and Sebastiani (2006). Yet other systems\u2014the matrix-vector method of Blair-Goldensohn et al.", "startOffset": 109, "endOffset": 137}, {"referenceID": 2, "context": "Yet other systems\u2014the matrix-vector method of Blair-Goldensohn et al. (2008) and the union of the three overall top-scoring systems respectively\u2014reach the highest F1-scores for these two classes.", "startOffset": 46, "endOffset": 77}, {"referenceID": 2, "context": "Yet other systems\u2014the matrix-vector method of Blair-Goldensohn et al. (2008) and the union of the three overall top-scoring systems respectively\u2014reach the highest F1-scores for these two classes. Nevertheless, we can still notice three main tendencies in this evaluation: i) the method of Esuli and Sebastiani (2006) gen-", "startOffset": 46, "endOffset": 317}, {"referenceID": 2, "context": "erally gets the highest recall of polar terms and, consequently, achieves the best precision in recognizing neutral words, but suffers from a low precision for the positive and negative polarities; ii) simultaneously five systems attain the same best F1-scores on recognizing neutral terms, which, in turn, leads to the best micro-averaged F1-results for all polarity classes; and, finally, iii) the system of Blair-Goldensohn et al. (2008) shows the best macro-averaged performance.", "startOffset": 410, "endOffset": 441}, {"referenceID": 28, "context": "The most prominent representatives of this class of algorithms are the approaches proposed by Takamura et al. (2005), Velikovich et al.", "startOffset": 94, "endOffset": 117}, {"referenceID": 28, "context": "The most prominent representatives of this class of algorithms are the approaches proposed by Takamura et al. (2005), Velikovich et al. (2010), Kiritchenko et al.", "startOffset": 94, "endOffset": 143}, {"referenceID": 13, "context": "(2010), Kiritchenko et al. (2014), and Severyn and Moschitti (2015), which we briefly describe in this section.", "startOffset": 8, "endOffset": 34}, {"referenceID": 13, "context": "(2010), Kiritchenko et al. (2014), and Severyn and Moschitti (2015), which we briefly describe in this section.", "startOffset": 8, "endOffset": 68}, {"referenceID": 10, "context": "Drawing on the pioneering work of Hatzivassiloglou and McKeown (1997), in which the authors ex-", "startOffset": 34, "endOffset": 70}, {"referenceID": 30, "context": "panded an initial list of polar adjectives by analyzing coordinately conjoined terms from a text corpus, Takamura et al. (2005) enhanced this algorithm, extending it to other parts of speech and also incorporating semantic links from WORDNET in addition to the co-occurrence statistics extracted from the corpus.", "startOffset": 105, "endOffset": 128}, {"referenceID": 28, "context": "The approach of Velikovich et al. (2010) was mainly inspired by the label-propagation algorithm of Rao and Ravichandran (2009), with the crucial difference that, instead of taking an averaged sum of the adjacent neighbor values when propagating the label scores through the graph, the authors took the maximum of these scores in order to prune unreliable, noisy corpus links.", "startOffset": 16, "endOffset": 41}, {"referenceID": 19, "context": "(2010) was mainly inspired by the label-propagation algorithm of Rao and Ravichandran (2009), with the crucial difference that, instead of taking an averaged sum of the adjacent neighbor values when propagating the label scores through the graph, the authors took the maximum of these scores in order to prune unreliable, noisy corpus links.", "startOffset": 65, "endOffset": 93}, {"referenceID": 13, "context": "Similarly, Kiritchenko et al. (2014) built on the method of Turney and Littman (2003) and computed polarity scores for new words by taking the difference of their PMI associations with noisy labeled positive and negative classes.", "startOffset": 11, "endOffset": 37}, {"referenceID": 13, "context": "Similarly, Kiritchenko et al. (2014) built on the method of Turney and Littman (2003) and computed polarity scores for new words by taking the difference of their PMI associations with noisy labeled positive and negative classes.", "startOffset": 11, "endOffset": 86}, {"referenceID": 13, "context": "Similarly, Kiritchenko et al. (2014) built on the method of Turney and Littman (2003) and computed polarity scores for new words by taking the difference of their PMI associations with noisy labeled positive and negative classes. Finally, Severyn and Moschitti (2015) trained a supervised SVM classifier on a distantly labeled data set and included the top-ranked unigram and bigram features in their final lexicon.", "startOffset": 11, "endOffset": 268}, {"referenceID": 24, "context": "For our evaluation, we applied these methods to the German Twitter Snapshot (Scheffler, 2014)\u2014a collection of 24 M microblogs gathered in April, 2013, constructing the collocation graph from the lem-", "startOffset": 76, "endOffset": 93}, {"referenceID": 9, "context": "We again were using the TREETAGGER of Schmid (1995) for lemmatization and GERMANET (Hamp and Feldweg, 1997) for deriving semantic links between word vertices for the method of Takamura et al.", "startOffset": 83, "endOffset": 107}, {"referenceID": 24, "context": "We again were using the TREETAGGER of Schmid (1995) for lemmatization and GERMANET (Hamp and Feldweg, 1997) for deriving semantic links between word vertices for the method of Takamura et al.", "startOffset": 38, "endOffset": 52}, {"referenceID": 9, "context": "We again were using the TREETAGGER of Schmid (1995) for lemmatization and GERMANET (Hamp and Feldweg, 1997) for deriving semantic links between word vertices for the method of Takamura et al. (2005).", "startOffset": 84, "endOffset": 199}, {"referenceID": 28, "context": "TKM \u2013 Takamura et al. (2005), VEL \u2013 Velikovich et al.", "startOffset": 6, "endOffset": 29}, {"referenceID": 28, "context": "TKM \u2013 Takamura et al. (2005), VEL \u2013 Velikovich et al. (2010), KIR \u2013 Kiritchenko et al.", "startOffset": 6, "endOffset": 61}, {"referenceID": 13, "context": "(2010), KIR \u2013 Kiritchenko et al. (2014), SEV \u2013 Severyn and Moschitti (2015)", "startOffset": 14, "endOffset": 40}, {"referenceID": 13, "context": "(2010), KIR \u2013 Kiritchenko et al. (2014), SEV \u2013 Severyn and Moschitti (2015)", "startOffset": 14, "endOffset": 76}, {"referenceID": 30, "context": "One of the reasons for such rapid quality decrease was the surprisingly high positive bias of the initial seed set: While converting the original seed list of Turney and Littman (2003) to German, we translated the English word \u201ccorrect\u201d as \u201crichtig\u201d.", "startOffset": 159, "endOffset": 185}, {"referenceID": 13, "context": "As a consequence of this, methods relying on distant supervision had to deal with an extremely unbalanced training set (the automatically labeled corpus that we distantly obtained for the approach of Kiritchenko et al. (2014) using these seeds,", "startOffset": 200, "endOffset": 226}, {"referenceID": 10, "context": "Since the set of the initial seed terms appeared to play an important role for at least three of the tested methods, we decided to analyze the impact of this factor in more detail by repeating our experiments with the seed lists proposed by Hu and Liu (2004), Kim and Hovy (2004), Esuli and Sebastiani (2006), and Remus et al.", "startOffset": 241, "endOffset": 259}, {"referenceID": 10, "context": "Since the set of the initial seed terms appeared to play an important role for at least three of the tested methods, we decided to analyze the impact of this factor in more detail by repeating our experiments with the seed lists proposed by Hu and Liu (2004), Kim and Hovy (2004), Esuli and Sebastiani (2006), and Remus et al.", "startOffset": 241, "endOffset": 280}, {"referenceID": 8, "context": "Since the set of the initial seed terms appeared to play an important role for at least three of the tested methods, we decided to analyze the impact of this factor in more detail by repeating our experiments with the seed lists proposed by Hu and Liu (2004), Kim and Hovy (2004), Esuli and Sebastiani (2006), and Remus et al.", "startOffset": 281, "endOffset": 309}, {"referenceID": 8, "context": "Since the set of the initial seed terms appeared to play an important role for at least three of the tested methods, we decided to analyze the impact of this factor in more detail by repeating our experiments with the seed lists proposed by Hu and Liu (2004), Kim and Hovy (2004), Esuli and Sebastiani (2006), and Remus et al. (2010). For this purpose, we manually translated the seed sets of Hu and Liu (2004) and Kim and Hovy (2004) into German.", "startOffset": 281, "endOffset": 334}, {"referenceID": 8, "context": "Since the set of the initial seed terms appeared to play an important role for at least three of the tested methods, we decided to analyze the impact of this factor in more detail by repeating our experiments with the seed lists proposed by Hu and Liu (2004), Kim and Hovy (2004), Esuli and Sebastiani (2006), and Remus et al. (2010). For this purpose, we manually translated the seed sets of Hu and Liu (2004) and Kim and Hovy (2004) into German.", "startOffset": 281, "endOffset": 411}, {"referenceID": 8, "context": "Since the set of the initial seed terms appeared to play an important role for at least three of the tested methods, we decided to analyze the impact of this factor in more detail by repeating our experiments with the seed lists proposed by Hu and Liu (2004), Kim and Hovy (2004), Esuli and Sebastiani (2006), and Remus et al. (2010). For this purpose, we manually translated the seed sets of Hu and Liu (2004) and Kim and Hovy (2004) into German.", "startOffset": 281, "endOffset": 435}, {"referenceID": 8, "context": "Since the set of the initial seed terms appeared to play an important role for at least three of the tested methods, we decided to analyze the impact of this factor in more detail by repeating our experiments with the seed lists proposed by Hu and Liu (2004), Kim and Hovy (2004), Esuli and Sebastiani (2006), and Remus et al. (2010). For this purpose, we manually translated the seed sets of Hu and Liu (2004) and Kim and Hovy (2004) into German. Since the authors, however, only provided some examples of their seeds without specifying the full lists, we filled up our translations with additional polar terms to match the original cardinalities. A different procedure was applied to obtain the seed set of Esuli and Sebastiani (2006)\u2014since this resource comprised a vast number of neutral terms (the authors considered as neutral all words from the General Inquirer lexicon which were not marked there as either positive or negative), we automatically translated the neutral subset of these seeds with the help of a publicly available translation site (http://www.", "startOffset": 281, "endOffset": 737}, {"referenceID": 2, "context": "This time, we again can notice superior scores achieved by the method of Blair-Goldensohn et al. (2008), which not only performs better than the other systems on average but also seems to be less susceptible to the varying quality and size of the different seed lists.", "startOffset": 73, "endOffset": 104}, {"referenceID": 10, "context": "achieve their best macro-averaged results with either of the two top-scoring polarity sets\u2014the seed list of Kim and Hovy (2004) or the seed set of Esuli and Sebastiani (2006).", "startOffset": 108, "endOffset": 128}, {"referenceID": 8, "context": "achieve their best macro-averaged results with either of the two top-scoring polarity sets\u2014the seed list of Kim and Hovy (2004) or the seed set of Esuli and Sebastiani (2006). This is, for instance, the case for the method of Kim and Hovy (2004) and the min-cut approach of Rao and Ravichandran (2009), whose performance with the native Kim-Hovy seed set is on par with their results achieved using the Turney-Littman seeds.", "startOffset": 147, "endOffset": 175}, {"referenceID": 8, "context": "achieve their best macro-averaged results with either of the two top-scoring polarity sets\u2014the seed list of Kim and Hovy (2004) or the seed set of Esuli and Sebastiani (2006). This is, for instance, the case for the method of Kim and Hovy (2004) and the min-cut approach of Rao and Ravichandran (2009), whose performance with the native Kim-Hovy seed set is on par with their results achieved using the Turney-Littman seeds.", "startOffset": 147, "endOffset": 246}, {"referenceID": 8, "context": "achieve their best macro-averaged results with either of the two top-scoring polarity sets\u2014the seed list of Kim and Hovy (2004) or the seed set of Esuli and Sebastiani (2006). This is, for instance, the case for the method of Kim and Hovy (2004) and the min-cut approach of Rao and Ravichandran (2009), whose performance with the native Kim-Hovy seed set is on par with their results achieved using the Turney-Littman seeds.", "startOffset": 147, "endOffset": 302}, {"referenceID": 8, "context": "achieve their best macro-averaged results with either of the two top-scoring polarity sets\u2014the seed list of Kim and Hovy (2004) or the seed set of Esuli and Sebastiani (2006). This is, for instance, the case for the method of Kim and Hovy (2004) and the min-cut approach of Rao and Ravichandran (2009), whose performance with the native Kim-Hovy seed set is on par with their results achieved using the Turney-Littman seeds. The label-propagation and random walk algorithms can even strongly benefit from the seeds provided by Kim and Hovy (2004). The remaining two methods\u2014Hu and Liu (2004) and Esuli and Sebastiani (2006)\u2014work best in combination with the initial polarity set proposed by Esuli and Sebastiani (2006).", "startOffset": 147, "endOffset": 547}, {"referenceID": 8, "context": "achieve their best macro-averaged results with either of the two top-scoring polarity sets\u2014the seed list of Kim and Hovy (2004) or the seed set of Esuli and Sebastiani (2006). This is, for instance, the case for the method of Kim and Hovy (2004) and the min-cut approach of Rao and Ravichandran (2009), whose performance with the native Kim-Hovy seed set is on par with their results achieved using the Turney-Littman seeds. The label-propagation and random walk algorithms can even strongly benefit from the seeds provided by Kim and Hovy (2004). The remaining two methods\u2014Hu and Liu (2004) and Esuli and Sebastiani (2006)\u2014work best in combination with the initial polarity set proposed by Esuli and Sebastiani (2006).", "startOffset": 147, "endOffset": 592}, {"referenceID": 8, "context": "achieve their best macro-averaged results with either of the two top-scoring polarity sets\u2014the seed list of Kim and Hovy (2004) or the seed set of Esuli and Sebastiani (2006). This is, for instance, the case for the method of Kim and Hovy (2004) and the min-cut approach of Rao and Ravichandran (2009), whose performance with the native Kim-Hovy seed set is on par with their results achieved using the Turney-Littman seeds. The label-propagation and random walk algorithms can even strongly benefit from the seeds provided by Kim and Hovy (2004). The remaining two methods\u2014Hu and Liu (2004) and Esuli and Sebastiani (2006)\u2014work best in combination with the initial polarity set proposed by Esuli and Sebastiani (2006).", "startOffset": 147, "endOffset": 624}, {"referenceID": 8, "context": "achieve their best macro-averaged results with either of the two top-scoring polarity sets\u2014the seed list of Kim and Hovy (2004) or the seed set of Esuli and Sebastiani (2006). This is, for instance, the case for the method of Kim and Hovy (2004) and the min-cut approach of Rao and Ravichandran (2009), whose performance with the native Kim-Hovy seed set is on par with their results achieved using the Turney-Littman seeds. The label-propagation and random walk algorithms can even strongly benefit from the seeds provided by Kim and Hovy (2004). The remaining two methods\u2014Hu and Liu (2004) and Esuli and Sebastiani (2006)\u2014work best in combination with the initial polarity set proposed by Esuli and Sebastiani (2006). A slightly different situation is observed for the corpus-based approaches as shown in Figure 2.", "startOffset": 147, "endOffset": 719}, {"referenceID": 8, "context": "achieve their best macro-averaged results with either of the two top-scoring polarity sets\u2014the seed list of Kim and Hovy (2004) or the seed set of Esuli and Sebastiani (2006). This is, for instance, the case for the method of Kim and Hovy (2004) and the min-cut approach of Rao and Ravichandran (2009), whose performance with the native Kim-Hovy seed set is on par with their results achieved using the Turney-Littman seeds. The label-propagation and random walk algorithms can even strongly benefit from the seeds provided by Kim and Hovy (2004). The remaining two methods\u2014Hu and Liu (2004) and Esuli and Sebastiani (2006)\u2014work best in combination with the initial polarity set proposed by Esuli and Sebastiani (2006). A slightly different situation is observed for the corpus-based approaches as shown in Figure 2. Except for the method of Takamura et al. (2005), all three remaining methods\u2014Velikovich et al.", "startOffset": 147, "endOffset": 865}, {"referenceID": 8, "context": "achieve their best macro-averaged results with either of the two top-scoring polarity sets\u2014the seed list of Kim and Hovy (2004) or the seed set of Esuli and Sebastiani (2006). This is, for instance, the case for the method of Kim and Hovy (2004) and the min-cut approach of Rao and Ravichandran (2009), whose performance with the native Kim-Hovy seed set is on par with their results achieved using the Turney-Littman seeds. The label-propagation and random walk algorithms can even strongly benefit from the seeds provided by Kim and Hovy (2004). The remaining two methods\u2014Hu and Liu (2004) and Esuli and Sebastiani (2006)\u2014work best in combination with the initial polarity set proposed by Esuli and Sebastiani (2006). A slightly different situation is observed for the corpus-based approaches as shown in Figure 2. Except for the method of Takamura et al. (2005), all three remaining methods\u2014Velikovich et al. (2010), Kiritchenko et al.", "startOffset": 147, "endOffset": 919}, {"referenceID": 8, "context": "achieve their best macro-averaged results with either of the two top-scoring polarity sets\u2014the seed list of Kim and Hovy (2004) or the seed set of Esuli and Sebastiani (2006). This is, for instance, the case for the method of Kim and Hovy (2004) and the min-cut approach of Rao and Ravichandran (2009), whose performance with the native Kim-Hovy seed set is on par with their results achieved using the Turney-Littman seeds. The label-propagation and random walk algorithms can even strongly benefit from the seeds provided by Kim and Hovy (2004). The remaining two methods\u2014Hu and Liu (2004) and Esuli and Sebastiani (2006)\u2014work best in combination with the initial polarity set proposed by Esuli and Sebastiani (2006). A slightly different situation is observed for the corpus-based approaches as shown in Figure 2. Except for the method of Takamura et al. (2005), all three remaining methods\u2014Velikovich et al. (2010), Kiritchenko et al. (2014), and Severyn and Moschitti (2015)\u2014show very similar (though not identical) scores.", "startOffset": 147, "endOffset": 946}, {"referenceID": 8, "context": "achieve their best macro-averaged results with either of the two top-scoring polarity sets\u2014the seed list of Kim and Hovy (2004) or the seed set of Esuli and Sebastiani (2006). This is, for instance, the case for the method of Kim and Hovy (2004) and the min-cut approach of Rao and Ravichandran (2009), whose performance with the native Kim-Hovy seed set is on par with their results achieved using the Turney-Littman seeds. The label-propagation and random walk algorithms can even strongly benefit from the seeds provided by Kim and Hovy (2004). The remaining two methods\u2014Hu and Liu (2004) and Esuli and Sebastiani (2006)\u2014work best in combination with the initial polarity set proposed by Esuli and Sebastiani (2006). A slightly different situation is observed for the corpus-based approaches as shown in Figure 2. Except for the method of Takamura et al. (2005), all three remaining methods\u2014Velikovich et al. (2010), Kiritchenko et al. (2014), and Severyn and Moschitti (2015)\u2014show very similar (though not identical) scores.", "startOffset": 147, "endOffset": 980}, {"referenceID": 20, "context": "** \u2013 the min-cut method of Rao and Ravichandran (2009) returns an unsorted set", "startOffset": 27, "endOffset": 55}, {"referenceID": 9, "context": "As can be seen from the table, the approaches of Hu and Liu (2004), Blair-Goldensohn et al.", "startOffset": 49, "endOffset": 67}, {"referenceID": 2, "context": "As can be seen from the table, the approaches of Hu and Liu (2004), Blair-Goldensohn et al. (2008), Kim and Hovy (2004), as well as the label-propagation algorithm of Rao and Ravichandran (2009) produce almost perfect polarity lists.", "startOffset": 68, "endOffset": 99}, {"referenceID": 2, "context": "As can be seen from the table, the approaches of Hu and Liu (2004), Blair-Goldensohn et al. (2008), Kim and Hovy (2004), as well as the label-propagation algorithm of Rao and Ravichandran (2009) produce almost perfect polarity lists.", "startOffset": 68, "endOffset": 120}, {"referenceID": 2, "context": "As can be seen from the table, the approaches of Hu and Liu (2004), Blair-Goldensohn et al. (2008), Kim and Hovy (2004), as well as the label-propagation algorithm of Rao and Ravichandran (2009) produce almost perfect polarity lists.", "startOffset": 68, "endOffset": 195}, {"referenceID": 2, "context": "As can be seen from the table, the approaches of Hu and Liu (2004), Blair-Goldensohn et al. (2008), Kim and Hovy (2004), as well as the label-propagation algorithm of Rao and Ravichandran (2009) produce almost perfect polarity lists. The SENTIWORDNET approach of Esuli and Sebastiani (2006), however, already features some spurious terms (e.", "startOffset": 68, "endOffset": 291}, {"referenceID": 2, "context": "As can be seen from the table, the approaches of Hu and Liu (2004), Blair-Goldensohn et al. (2008), Kim and Hovy (2004), as well as the label-propagation algorithm of Rao and Ravichandran (2009) produce almost perfect polarity lists. The SENTIWORDNET approach of Esuli and Sebastiani (2006), however, already features some spurious terms (e.g., \u201cabsichtslos\u201d unintentional) among its top-scored entries. Finally, the min-cut approach of Rao and Ravichandran (2009) returns a set of mainly objective terms, which, however, is rather due to the fact that this method performs a cluster-like partitioning of the lexical graph without ranking the words assigned to a cluster.", "startOffset": 68, "endOffset": 465}], "year": 2016, "abstractText": "Despite substantial progress made in developing new sentiment lexicon generation (SLG) methods for English, the task of transferring these approaches to other languages and domains in a sound way still remains open. In this paper, we contribute to the solution of this problem by systematically comparing semi-automatic translations of common English polarity lists with the results of the original automatic SLG algorithms, which were applied directly to German data. We evaluate these lexicons on a corpus of 7,992 manually annotated tweets. In addition to that, we also collate the results of dictionaryand corpus-based SLG methods in order to find out which of these paradigms is better suited for the inherently noisy domain of social media. Our experiments show that semi-automatic translations notably outperform automatic systems (reaching a macro-averaged F1-score of 0.589), and that dictionary-based techniques produce much better polarity lists as compared to corpus-based approaches (whose best F1-scores run up to 0.479 and 0.419 respectively) even for the non-standard Twitter genre. All reimplementations of the compared systems and the resulting lexicons of these methods are available online at https://github.com/WladimirSidorenko/SentiLex.", "creator": "TeX"}}}