{"id": "1611.02378", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Nov-2016", "title": "A Surrogate-based Generic Classifier for Chinese TV Series Reviews", "abstract": "With the advent of various online video platforms such as Youtube, Youku and LeTV, online film reviews are becoming more and more important for both film viewers and producers. As a result, the automatic classification of reviews according to different requirements is becoming a popular research topic and is critical to our daily lives. In this article, we focused on reviews of hot TV series in China and successfully trained generic classifiers based on 8 predefined categories. The experimental results showed promising performance and effectiveness of their generalization to different TV series.", "histories": [["v1", "Tue, 8 Nov 2016 03:33:46 GMT  (180kb,D)", "http://arxiv.org/abs/1611.02378v1", null], ["v2", "Mon, 21 Nov 2016 14:55:40 GMT  (225kb,D)", "http://arxiv.org/abs/1611.02378v2", "submitted to IDD"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yufeng ma", "long xia", "wenqi shen", "mi zhou", "weiguo fan"], "accepted": false, "id": "1611.02378"}, "pdf": {"name": "1611.02378.pdf", "metadata": {"source": "CRF", "title": "A Surrogate-based Generic Classifier for Chinese Movie Reviews", "authors": ["Yufeng Ma"], "emails": ["yufengma@vt.edu", "longxia1@vt.edu", "shenw@vt.edu", "wfan@vt.edu"], "sections": [{"heading": "1 Introduction", "text": "With Web 2.0\u2019s development, more and more commercial websites, such as Amazon, Youtube and Youku, encourage people to post reviews on their platforms for what they are interested in or complain about [1, 2]. These reviews are helpful for both readers and product manufacturers. For example, from the online reviews of TV series, the producers can perceive what the viewers like and dislike. Then in the future, when they are going to make new films or TV series, they can take these into account and produce ones attracting more viewers. What\u2019s more, if the reviews focus on the product functions, the manufacturers can get feedbacks from customers to further improve it in the next round of production. On the other hand, readers can just judge or evaluate the product or TV series by viewing other people\u2019s opinions, which will mostly provide a base preference and help them make final decisions of whether to watch or buy it. However, there are plenties of reviews emerging every day. It will take readers lots of time to go over them one by one. Moreover, sometimes readers are only interested in some aspects of the products or movies. It\u2019s been a waste of time to look at other irrelevant ones. As a result, automatic classification of reviews is pretty essential for the review platforms to provide a better perception of the review contents to the users.\nar X\niv :1\n61 1.\n02 37\n8v 1\nMost of the existing review analysis focuses on English product reviews. While in this paper, we shifted our attention to reviews of hot Chinese movie or TV series, which owns some unique characteristics. First, let\u2019s look at the Chinese movies\u2019 development [3] in recent years as shown in Table 1. It\u2019s transparent that the growth of box office and viewers is dramatically high these years, which provides substantial reviewer basis for the movie review data. Moreover, the State Administration of Radio Film and Television also announced that the movie market of China has occupied the 2nd place right under the North America market. If with such great rate of increase, China will definitely become the greatest movie market in the world within the next 5-10 years, which shows the prominence of Chinese movie review analysis. On the other hand, there are differences between contents of product and movie reviews. When a person writes a movie review, he or she probably not only care about the movie elements like actor/actress, visual effect, dialogues and music, but also related teams consisted of director, screenwriter, producer, etc. However, with product reviews, few review authors care about the corresponding backstage teams. What they do care and will comment about are only product related issues like drawbacks of the product functions, or which aspect of the merchandise they like or dislike. Moreover, most of recent researchers\u2019 work has been focused on English texts due to its simpler grammatical structure and less vocabulary, as compared with Chinese. Therefore, Chinese movie reviews not only provide more content based information, but also raise more technical challenges. With bloom of Chinese movies, automatic classification of Chinese movie reviews is really essential and meaningful.\nTable 1: Chinese Movies Box Office Statistics\nYear Box office (million) # of viewers (million)\n2009 6206 204 2010 10172 286 2011 13115 370 2012 17073 467 2013 21769 613 2014 29600 830 2015 44000 1256\nIn this paper, we proposed several strategies to make our classifiers generalize better to agnostic TV series. First, TV series roles\u2019 and actors/actresses\u2019 names are substituted by generic tags like role i and player j, where i and j defines their importance in this movie. On top of such kind of words, feature tokens are further manipulated by feature selection techniques like DRC or \u03c72, in order to make it more generic. We also experimented with different feature sizes with multiple classifiers in order to alleviate overfitting with high dimension features.\nThe remainder of this paper is organized as follows. Section 2 describes some related work. Section 3 states our problem and details our proposed procedure of approaching the problem. In Section 4, experimental results are provided and discussed. Finally, the conclusions are presented in Section 5."}, {"heading": "2 Related Work", "text": "Since we are doing supervised learning task with text input, it is related with work of useful techniques like feature selections and supervised classifiers. Besides, there are only public movie review datasets in English right now, which is different from our language requirement. In the following of this section, we will first introduce some existing feature selection techniques and supervised classifiers we applied in our approach. Then we will present some relevant datasets that are normally used in movie review domain."}, {"heading": "2.1 Feature selection", "text": "Feature selection, or variable selection is a very common strategy applied in machine learning domain, which tries to select a subset of relevant features from the whole set. There are mainly three purposes behind this. Smaller feature set or features with lower dimension can help researchers to\nunderstand or interpret the model they designed more easily. With fewer features, we can also improve the generalization of our model through preventing overfitting, and reduce the whole training time.\nDocument Relevance Correlation(DRC), proposed by W. Fan et al 2005 [4], is a quite useful feature selection technique. The authors apply this approach to profile generation in digital library service and news-monitoring. They\u2019ve compared DRC with other well-know methods like Robertson\u2019s Selection Value [5], and machine learning based ones like information gain [6]. Promising experimental results were shown to demonstrate the effectiveness of DRC as a feature selection in text field.\nAnother popular feature selection method is called \u03c72 [7], which is a variant of \u03c72 test in statistics that tries to test the independence between two events. While in feature selection domain, the two events can be interpreted as the occurrence of feature variable and a particular class. Then we can rank the feature terms with respect to the \u03c72 value. It has been proved to be very useful in text domain, especially with bag of words feature model which only cares about the appearance of each term."}, {"heading": "2.2 Supervised Classifier", "text": "What we need is to classify each review into several generic categories that might be attractive to the readers, so classifier selection is also quite important in our problem. Supervised learning takes labeled training pairs and tries to learn an inferred function, which can be used to predict new samples. Here in this paper, our selection is based on two kinds of learning, i.e., discriminative and generative learning algorithms. And we choose three typical algorithms to compare. Na\u0131\u0308ve Bayes [8], which is the representative of generative learning, will output the class with the highest probability that is generated through the bayes\u2019 rule. While for the discriminative classifiers like logistic regression [9] or Support Vector Machine [10], final decisions are based on the classifier\u2019s output score, which is compared with some threshold to distinguish between different classes."}, {"heading": "2.3 Movie Review Dataset", "text": "Dataset is another important factor influencing the performance of our classifiers. Most of the public available movie review data is in English, like the IMDB dataset collected by Pang/Lee 2004 [11]. Although it covers all kinds of movies in IMDB website, it only has labels related with the sentiment. Its initial goal was for sentiment analysis. Another intact movie review dataset is SNAP [12], which consists of reviews from Amazon but only bearing rating scores. However, what we need is the content or aspect tags that are being discussed in each review. Besides, our review text requirement is for Chinese. Therefore it\u2019s necessary for us to build the review dataset by ourself and label them into generic categories, which can be thought of as one of our contributions."}, {"heading": "3 Chinese Movie Review Classification", "text": "Let R = r1, r2, . . . , rn be a set of Chinese movie reviews with no categorical information. The ultimate task of movie review classification is to label them into different predefined categories as c1, c2, . . . , cm. Starting from sketch, we will need to collect such review set R from some website and then manually label them into generic categories {ci}. Based on the collected dataset, we can apply natural language processing techniques to get raw text features and further learn the classifiers. In the following subsections, we will go through and elaborate all the subtasks shown in Figure 1."}, {"heading": "3.1 Building Dataset", "text": "What we are interested are the reviews of hottest or currently broadcasted TV series, so we select one of the most influential Web2.0 website sharing movie/TV series related activities in China, which is called Douban. For every movie or TV series, you can find corresponding section in Douban. For the sake of popularity, we choose \u201cThe Journey of Flower\u201d, \u201cNirvana in Fire\u201d and \u201cGood Time\u201d as parts of our movie review dataset, which are the hottest TV series from summer to fall in 2015. Reviews of each episode are intended to be collected for the sake of dataset comprehensiveness.\nThen we built the crawler written in python with the help of scrapy. Scrapy will create multiple threads to crawl information we need simultaneously, which saves us lots of time. For each episode, it collected both the short description of this episode and all the reviews under this post. The statistics of our movie review dataset is shown in Table 2."}, {"heading": "3.2 Basic Text Processing", "text": "Based on the collected reviews, we are almost prepared to build a rough classifier. However, before feeding them into a classifier, we need to do some basic preprocessing. Two common basic procedures: tokenization and stop words removal, are applied on top of all the reviews. Let\u2019s take a detour here. We did some tricks to make our reviews more generic before that. We replaced the roles\u2019 and\nactors/actresses\u2019 names in the reviews with some common tokens like role i, actor j, where i and j are determined by their importance in this TV series. Therefore we have the following inference\ni < j =\u21d2 IM(i) > IM(j) (1)\nwhere IM(\u2217) is a function which map a role\u2019s or actor\u2019s index into its importance. But how can we successfully infer this? Luckily, we have Baidu Encyclopedia, which is the Chinese version of Wikipedia. For each movie or TV series, it has all the basic information, where it lists the importance of each role and actor in descending order. So actor/actress in a leading role will be listed at first, while ones in a supporting role and other players are shown below. Thus we can just build another crawler to collect these useful information, and replace the corresponding words in reviews with generic tags.\nAfterwards, word sequence of each review can be manipulated with tokenization and stop words removal. Each sequence is broken up into a vector of unigram-based tokens using NLPIR [13], which is a very powerful tool supporting sentence segmentation in Chinese. While stop words are words that do not contribute to the meaning of the whole sentence and are usually filtered out before following data processing. Since our reviews are collected from online websites, which may include lots of forum words, so for this particular domain, besides the basic Chinese stop words we also include the common forum words. Shown below are some typical examples in English that are widely used in Chinese forums.\nBBS, BT, NB, BS, CU, LOL, 4242, SF, YY, . . .\nThese two processes will help us remove lots of noise in the data."}, {"heading": "3.3 Topic Modelling and Labeling", "text": "With volumes of movie review data, it\u2019s hard for us to define generic categories without looking at them one by one. Therefore, it\u2019s necessary to run some unsupervised models to get an overview of what\u2019s being talked in the whole corpus. Here we applied Latent Dirichlet Allocation [14, 15] to discover the main topics related to the movies and actors. In a nutshell, the LDA model assumes that there exists a hidden structure consisting of the topics appearing in the whole text corpus. The LDA algorithm uses the co-occurrence of observed words to learn this hidden structure. Mathematically, the model calculates the posterior distribution of the unobserved variables. Given a set of training documents, LDA will return two main outputs. The first is the list of topics represented as a set of words, which presumably contribute to this topic in the form of their weights. The second output is a list of documents with a vector of weight values showing the probability of a document containing a specific topic.\nNow that as soon as we get the results of LDA, we should get an idea of the topics being talked. Combined with what we got after manually looking through, we defined the 8 generic categories of movie reviews as in Table 3.\nSince we are trying to classify each review into the above 8 categories, in order to build reasonable classifiers, first we need to be provided with a labeled dataset. Each of the movie reviews was labeled by at least two persons, and only ones with the same label were selected to be included in our training and testing data. In this way, we can filter out movie reviews with human\u2019s biases and 5000 out of each TV series\u2019 reviews were chosen finally."}, {"heading": "3.4 Feature Selection", "text": "When we are provided with labelled cleaned data, we are basically done with preprocessing. One problem is that the vocabulary size of our corpus will be quite large. This most probably will result in overfitting with the training data. As the dimension of the feature goes up, the complexity of our model will also increase. Then there will be quite an amount of difference between what we expect to learn and what we will learn from a particular dataset. One common way of dealing with this is to do feature selection. Here we applied DRC and \u03c72 mentioned in related work. First let\u2019s define a contingency table for each word j like in Table 4. If j = 1, it means the appearance of word j.\nRecall that in classical statistics, \u03c72 is a method designed to measure the independence between two variables or events, which in our case is the word j and its relevance to the class i. Higher \u03c72 value means higher correlations between them. Therefore, based on the definition of \u03c72 in [7] and the above Table 4, we can represent the \u03c72 value as below:\n\u03c72 = N \u00d7 (AD \u2212 CB)\n(A+ C)\u00d7 (B +D)\u00d7 (A+B)\u00d7 (C +D) (2)\nWhile for DRC method, it\u2019s based on Relevance Correlation Value, whose purpose is to measure the similarity between two distributions, i.e., binary distribution of word j\u2019s occurrence and documents\u2019 relevance to class i along all the training data. For a particular word j, its occurrence distribution along all the data can be represented as below(assume we have N reviews):\nIj = \u30081, 1, 0, . . . , 0, 1\u3009 (3)\nAnd we also know each review rk\u2019s relevance with respect to ci using the manually tagged labels.\nRelk = \u30081, 0, 0, . . . , 1, 0\u3009 (4)\nwhere 0 means irrelevant and 1 means relevant. Therefore, we can calculate the similarity between these two vectors as\nRCVj = \u2211N k=1 IkjRelk\u221a\u2211N\nk=1 I 2 kj \u221a\u2211N k=1Rel 2 k\n(5)\nwhere RCVj is called the Relevance Correlation Value for word j. Because Iij is either 1 or 0, with the notation in the contingency table, RCV can be simplified as\nRCVj = A\u221a\nA+B \u221a A+ C\n(6)\nThen on top of RCV, they incorporate the probability of the presence of word j if we are given that the document is relevant. In this way, our final formula for computing DRC becomes\nDRCj = P (wj = 1|R) \u00b7RCVj (7)\n= A2\u221a A+B . (8)\nTherefore, we can apply the above two methods to all the word terms in our dataset and choose words with higher \u03c72 or DRC values to reduce the dimension of our input features."}, {"heading": "3.5 Learning Classifiers", "text": "Finally, we are going to train classifiers on top of our reduced generic features. As we said before, there are two kinds of learning algorithms, i.e., discriminant and generative classifiers. Based on Bayes rule, the optimal classifier is represented as\nh\u2217(x) = argmax ci log p(y = ci|x)\n\u221d argmax ci {log p(x|y = ci) + log p(y = ci)}\nwhere p(y = ci) is the prior information we know about class ci.\nSo for generative approach like Na\u0131\u0308ve Bayes, it will try to estimate both p(x|y) and p(y). During testing time, we can just apply the above Bayes rule to predict y. Why do we call it naive? Remember that we assume that each feature is conditionally independent with each other. So we have\np(x|y) = p(x1|y) \u00b7 p(x2|y) . . . p(xm\u22121|y) \u00b7 p(xm|y) (9) where we made the assumption that there aremwords being used in our input. If features are binary, for each word j we may simply estimate the probability by\np(xi = 1|y = ci) = #{xi = 1, y = ci}+ l\n#{y = ci}+ 2l (10)\nin which, l is a smoothing parameter in case there is no training sample for y = ci and #{\u2217} outputs the number of a set. With all these probabilities computed, we can make decisions by whether\nlog p(y = ci|x) p(y 6= ci|x) = m\u2211 k=1 log p(xk|y = ci) p(xk|y 6= ck) + log p(y = ci) p(y 6= ci) \u2265 0 (11)\nOn the other hand, discriminant learning algorithms will estimate p(y|x) directly, or learn some \u201cdiscriminant\u201d function h(x). Then by comparing h(x) with some threshold, we can make the final decsion. Here we applied two common classifiers logistic regression and support vector machine to classify movie reviews. Logistic regression squeezes the input feature into some interval between 0 and 1 by the sigmoid function, which can be treated as the probability p(y|x).\np(y = ci|x) = \u03c3(wT x) = 1 1 + e\u2212w0\u2212 \u2211 i wixi (12) p(y 6= ci|x) = 1\u2212 \u03c3(wT x) = e\u2212w0\u2212 \u2211 i wixi\n1 + e\u2212w0\u2212 \u2211 i wixi (13)\nThe Maximum A Posteriori of logistic regression with Gaussian priors on parameter w is defined as below\nw\u0302 = argmax w Loss(w) = argmax w logP (w|{xk, yk})\n\u221d argmax w logP (Y |X,w)P (w)\n= argmax w N\u2211 k=1 logP (Yk = yk|{xk,w) + m\u2211 j=0 logP (wj)\nwhich is a concave function with respect to w, so we can use gradient ascent below to optimize the objective function and get the optimal w.\nw(t+1) = w(t) + \u03b7 \u2202Loss(w)\n\u2202w (14)\nwhere \u03b7 is a positive hyper parameter called learning rate. Then we can just use equation (12) to distinguish between classes.\nWhile for Support Vector Machine(SVM), its initial goal is to learn a hyperplane, which will maximize the margin between the two classes\u2019 boundary hyperplanes. Suppose the hyperplane we want to learn is\nwT x + w0 = 0\nThen the soft-margin version of SVM is\nmin w,w0,\u03bek\n1 2 wTw + C N\u2211 k=1 \u03bek\ns.t. yk \u00b7 (wT xk + w0) \u2265 1\u2212 \u03bek \u03bek \u2265 0\nwhere \u03bek is the slack variable representing the error w.r.t. datapoint (xk, yk). If we represent the inequality constraints by hinge loss function\nh(z) = max{0, 1\u2212 z}, (15) What we want to minimize becomes\nmin w,w0,\u03bek\n1 2 wTw + C N\u2211 k=1 h[yk \u00b7 (wT xk + w0)] (16)\nwhich can be solved easily with a Quadratic Programming solver. With learned w and w0, decision is made by determining whether\nwTx+ w0 \u2265 0. (17)\nBased on these classifiers, we may also apply some kernel trick function on input feature to make originally linearly non-separable data to be separable on mapped space, which can further improve our classifier performance. What we\u2019ve tried in our experiments are the polynomial and rbf kernels."}, {"heading": "4 Experimental Results and Discussion", "text": "As our final goal is to learn a generic classifier, which is agnostic to TV series but can predict review\u2019s category reasonably, we did experiments following our procedures of building the classifier as discussed in section 1."}, {"heading": "4.1 Category Determining by LDA", "text": "Before defining the categories of the movie reviews, we should first run some topic modeling method. Here we define categories with the help of LDA. With the number of topics being set as 8, we applied LDA on \u201cThe Journey of Flower\u201d, which definitely is the hottest TV series in 2015 summer. As we are just replying on LDA to guide our category definition, we didn\u2019t run it on other TV series. The results are shown in Figure 2. Note that the input data here haven\u2019t been replaced with the generic tag like role i or actor j, as we want to know the specifics being talked by reviewers. Here we present it in the form of heat maps. For lines with brighter color, the corresponding topic is discussed more, compared with others on the same height for each review. As the original texts are in Chinese, the output of LDA are represented in Chinese as well.\nWe can see that most of the reviews are focused on discussing the roles and analyzing the plots in the movie, i.e., 6th and 7th topics in Figure 2, while quite a few are just following the posts, like the 4th and 5th topic in the figure. Based on this, there comes the category definition shown in Table 3. Then 5000 out of each TV series reviews, with no label bias between readers, are selected to make up our final data set."}, {"heading": "4.2 Feature Size Comparison", "text": "Based on \u03c72 and DRC discussed in section 3.4, we can sort the importance of each word term. With different feature size, we can train the 8 generic classifiers and get their performances on both training and testing set. Here we use SVM as the classifier to compare feature size\u2019s influence, as we find out it performs best among the three. The results are shown in Figure 3. The red squres represent the training accuracy, while the blue triangles are testing accuracies.\nLooking over Figure 3, it\u2019s easy for us to determine the feature size for each classifier. Also it\u2019s obvious that test accuracies of classifiers for plot, actor/actress, analysis, and thumb up or down,\ndidn\u2019t increase much with adding more words. Therefore, the top 1000 words with respect to these classes are fixed as the final feature words. While for the rest of classifiers, they achieved top testing performances at the size of about 4000. Considering this, we use different feature sizes in our final classifiers."}, {"heading": "4.3 Generalization of Classifiers", "text": "To prove the generalization of our classifiers, we use two of the TV series as training data and the rest one as testing set. And we compare them with classifiers trained without the replacement of generic tags like role i or actor j. So 3 sets of experiments are performed, and each are trained on top of Na\u0131\u0308ve Bayes, Logistic Regression and SVM. Average accuracies among them are reported as the performance measure for the sake of space limit. The results are shown in Table 5. \u201c1\u201d, \u201c2\u201d and \u201c3\u201d represent the TV series \u201cThe Journey of Flower\u201d, \u201cNirvana in Fire\u201d and \u201cGood Time\u201d respectively. In each cell, the left value represents accuracy of classifier without replacement of generic tags and winners are bolded.\nFrom the above table, we can see with substitutions of generic tags in movie reviews, the top 5 classifiers have seen performance increase, which proves our method\u2019s effectiveness. However for the rest 3 classifiers, we didn\u2019t see any improvement and the performance of some even dropped a little bit. This might be explained that in the first 5 categories, roles\u2019 or actors\u2019 names are mentioned pretty often while the rest classes don\u2019t care much about these. But some specific names might be helpful in these categories\u2019 classification, so the performance has decreased in some degree."}, {"heading": "5 Conclusion", "text": "In this paper, a surrogate-based approach is proposed to make movie review classification more generic among reviews from different TV series. Based on the topic modeling results, we define 8 generic categories and manually label the collected movie reviews. Then with the help of Baidu Encyclopedia, TV series\u2019 specific information like roles\u2019 and actors\u2019 names are substituted by common tags within TV series domain. Our experimental results showed that such strategy combined with feature selection did improve the performance of classifications. Through this way, we may just build classifiers on already collected movie reviews, and then could successfully classify ones from new TV series."}, {"heading": "6 Acknowledgement", "text": ""}], "references": [{"title": "The world is your library, or the state of international interlibrary loan in 2015", "author": ["K. Munson", "H.H. Thompson", "J. Cabaniss", "H. Nance", "P. Erlandsen", "M. McGrath", "M. Mc- Grath"], "venue": "Interlending & Document Supply, vol. 44, no. 2, 2016.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Resource sharing in a cloud computing age", "author": ["M. Goldner", "K. Birch"], "venue": "Interlending & Document Supply, vol. 40, no. 1, pp. 4\u201311, 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Chinese movie big data analysis report.", "author": ["C. Film"], "venue": "http://sanwen8.cn/p/197jW1H. html,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Effective profiling of consumer information retrieval needs: a unified framework and empirical comparison", "author": ["W. Fan", "M.D. Gordon", "P. Pathak"], "venue": "Decision Support Systems, vol. 40, no. 2, pp. 213\u2013233, 2005.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "On relevance weight estimation and query expansion", "author": ["S.E. Robertson"], "venue": "Journal of Documentation, vol. 42, no. 3, pp. 182\u2013188, 1986.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1986}, {"title": "Hierarchical clustering based on mutual information", "author": ["A. Kraskov", "H. St\u00f6gbauer", "R.G. Andrzejak", "P. Grassberger"], "venue": "arXiv preprint q-bio/0311039, 2003.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Contingency tables involving small numbers and the \u03c7 2 test", "author": ["F. Yates"], "venue": "Supplement to the Journal of the Royal Statistical Society, vol. 1, no. 2, pp. 217\u2013235, 1934.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1934}, {"title": "Tackling the poor assumptions of naive bayes text classifiers", "author": ["J.D. Rennie", "L. Shih", "J. Teevan", "D.R. Karger"], "venue": "ICML, vol. 3, pp. 616\u2013623, Washington DC, 2003.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Estimation of the probability of an event as a function of several independent variables", "author": ["S.H. Walker", "D.B. Duncan"], "venue": "Biometrika, vol. 54, no. 1-2, pp. 167\u2013179, 1967.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1967}, {"title": "Support-vector networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Machine learning, vol. 20, no. 3, pp. 273\u2013 297, 1995.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1995}, {"title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["B. Pang", "L. Lee"], "venue": "Proceedings of the 42nd annual meeting on Association for Computational Linguistics, p. 271, Association for Computational Linguistics, 2004.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "author": ["J.J. McAuley", "J. Leskovec"], "venue": "Proceedings of the 22nd international conference on World Wide Web, pp. 897\u2013908, ACM, 2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Nlpir: A theoretical framework for applying natural language processing to information retrieval", "author": ["L. Zhou", "D. Zhang"], "venue": "Journal of the American Society for Information Science and Technology, vol. 54, no. 2, pp. 115\u2013123, 2003.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2003}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "Journal of machine Learning research, vol. 3, no. Jan, pp. 993\u20131022, 2003.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "On the design of lda models for aspect-based opinion mining", "author": ["S. Moghaddam", "M. Ester"], "venue": "Proceedings of the 21st ACM international conference on Information and knowledge management, pp. 803\u2013812, ACM, 2012. 11", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "0\u2019s development, more and more commercial websites, such as Amazon, Youtube and Youku, encourage people to post reviews on their platforms for what they are interested in or complain about [1, 2].", "startOffset": 189, "endOffset": 195}, {"referenceID": 1, "context": "0\u2019s development, more and more commercial websites, such as Amazon, Youtube and Youku, encourage people to post reviews on their platforms for what they are interested in or complain about [1, 2].", "startOffset": 189, "endOffset": 195}, {"referenceID": 2, "context": "First, let\u2019s look at the Chinese movies\u2019 development [3] in recent years as shown in Table 1.", "startOffset": 53, "endOffset": 56}, {"referenceID": 3, "context": "Fan et al 2005 [4], is a quite useful feature selection technique.", "startOffset": 15, "endOffset": 18}, {"referenceID": 4, "context": "They\u2019ve compared DRC with other well-know methods like Robertson\u2019s Selection Value [5], and machine learning based ones like information gain [6].", "startOffset": 83, "endOffset": 86}, {"referenceID": 5, "context": "They\u2019ve compared DRC with other well-know methods like Robertson\u2019s Selection Value [5], and machine learning based ones like information gain [6].", "startOffset": 142, "endOffset": 145}, {"referenceID": 6, "context": "Another popular feature selection method is called \u03c7 [7], which is a variant of \u03c7 test in statistics that tries to test the independence between two events.", "startOffset": 53, "endOffset": 56}, {"referenceID": 7, "context": "Na\u0131\u0308ve Bayes [8], which is the representative of generative learning, will output the class with the highest probability that is generated through the bayes\u2019 rule.", "startOffset": 13, "endOffset": 16}, {"referenceID": 8, "context": "While for the discriminative classifiers like logistic regression [9] or Support Vector Machine [10], final decisions are based on the classifier\u2019s output score, which is compared with some threshold to distinguish between different classes.", "startOffset": 66, "endOffset": 69}, {"referenceID": 9, "context": "While for the discriminative classifiers like logistic regression [9] or Support Vector Machine [10], final decisions are based on the classifier\u2019s output score, which is compared with some threshold to distinguish between different classes.", "startOffset": 96, "endOffset": 100}, {"referenceID": 10, "context": "Most of the public available movie review data is in English, like the IMDB dataset collected by Pang/Lee 2004 [11].", "startOffset": 111, "endOffset": 115}, {"referenceID": 11, "context": "Another intact movie review dataset is SNAP [12], which consists of reviews from Amazon but only bearing rating scores.", "startOffset": 44, "endOffset": 48}, {"referenceID": 12, "context": "Each sequence is broken up into a vector of unigram-based tokens using NLPIR [13], which is a very powerful tool supporting sentence segmentation in Chinese.", "startOffset": 77, "endOffset": 81}, {"referenceID": 13, "context": "Here we applied Latent Dirichlet Allocation [14, 15] to discover the main topics related to the movies and actors.", "startOffset": 44, "endOffset": 52}, {"referenceID": 14, "context": "Here we applied Latent Dirichlet Allocation [14, 15] to discover the main topics related to the movies and actors.", "startOffset": 44, "endOffset": 52}, {"referenceID": 6, "context": "Therefore, based on the definition of \u03c7 in [7] and the above Table 4, we can represent the \u03c7 value as below: \u03c7 = N \u00d7 (AD \u2212 CB) (A+ C)\u00d7 (B +D)\u00d7 (A+B)\u00d7 (C +D) (2)", "startOffset": 43, "endOffset": 46}], "year": 2017, "abstractText": "With the emerging of various online video platforms like Youtube, Youku and LeTV, online movie reviews become more and more important both for movie viewers and producers. As a result, automatically classifying reviews according to different requirements evolves as a popular research topic and is very essential in our daily life. In this paper, we focused on reviews of hot TV series in China and successfully trained generic classifiers based on 8 predefined categories. The experimental results showed promising performance and effectiveness of its generalization to different TV series.", "creator": "LaTeX with hyperref package"}}}