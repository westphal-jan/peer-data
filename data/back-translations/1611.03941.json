{"id": "1611.03941", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Nov-2016", "title": "Anomaly Detection in Bitcoin Network Using Unsupervised Learning Methods", "abstract": "In short, anomalies are abnormal or improbable things. In financial networks, thieves and illegal activity are often abnormal in nature. Members of a network want to detect anomalies as quickly as possible to prevent them from harming the community and integrity of the network. To solve this problem, many machine learning techniques have been proposed; some results seem quite promising, but there is no obvious superior method. In this paper, we consider anomaly detection specifically for the Bitcoin transaction network. Our goal is to identify which users and transactions are most suspicious; in this case, abnormal behavior is a proxy for suspicious behavior. To this end, we use three uncontrolled learning methods, including K-Mean Clustering, Mahalanobis Removal, and the Unmonitored Support Vector Machine (SVM) on two charts generated by the Bitcoin transaction network: One graph has users as nodes and the other as nodes of transactions.", "histories": [["v1", "Sat, 12 Nov 2016 02:39:41 GMT  (72kb,D)", "http://arxiv.org/abs/1611.03941v1", null], ["v2", "Sat, 25 Feb 2017 00:56:26 GMT  (97kb,D)", "http://arxiv.org/abs/1611.03941v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CR", "authors": ["thai pham", "steven lee"], "accepted": false, "id": "1611.03941"}, "pdf": {"name": "1611.03941.pdf", "metadata": {"source": "META", "title": "Anomaly Detection in Bitcoin Network Using  Unsupervised Learning Methods", "authors": ["Thai T. Pham", "Steven Lee"], "emails": ["thaipham@stanford.edu", "slee2010@stanford.edu"], "sections": [{"heading": "1. Introduction", "text": "Network structures have appeared for a long time, and along with them are those who behave abnormally within the system. We refer to these people or their illegal activities as anomalies. With respect to financial transactional networks, anomalies can include those who execute fraudulent transactions. In these networks, a common goal is to detect those anomalies to prevent future illegal actions.\nBitcoin is a special type of transaction system; more information about it can be found in [1]. We seek\nWe thank Andrew Ng for helpful comments.\nto detect anomalies or suspicious activities in this anonymous network, where nodes (i.e. users, transactions) are unlabeled and there is no confirmation as to whether or not a given node is actually conducting illicit activities.\nIn this project, we focus particularly on the problem of detecting anomalies in the Bitcoin transaction network, which is related to the study of fraud detection in all types of financial transaction systems. Since this problem can be generalized to those in other network settings, which may or may not involve financial transactions, we are examining the more general problem of anomaly detection in networks.\nIn this paper, we use three unsupervised learning methods including k-means clustering, Mahalanobis distance based method, and Unsupervised Support Vector Machines (SVM) on two graphs generated by the Bitcoin transaction network: one graph has users as nodes, and the other has transactions as nodes.\nThe rest of the paper is organized as follows. Section 2 describes everything related to methods, including data collection and parsing, feature extraction, and mathematical descriptions of the machine learning techniques. Section 3 discusses evaluation methods for our proposed algorithms. Section 4 presents the results we obtained by running these techniques on the network-type data set we generated. Section 5 evaluates our methods and results. Section 6 describes future work. Section 7 concludes our study."}, {"heading": "2. Methods", "text": "In this section, we describe data collection and parsing. Then, we describe feature extraction, and finally we provide mathematical explanations for the unsupervised learning techniques we use."}, {"heading": "2.1. Data Collection and Parsing", "text": "We use the Bitcoin transaction data set obtained from the University of Illinois Urbana- Champaign. All Bitcoin transactions are documented in a public ledger\nar X\niv :1\n61 1.\n03 94\n1v 1\n[ cs\n.L G\n] 1\n2 N\nov 2\n01 6\nand are in the currency unit called the Bitcoin (BTC). The data set contains all Bitcoin transactions beginning from the network\u2019s creation until April 7th, 2013. For each transaction, there can be multiple sender and receiver addresses. Furthermore, multiple addresses can belong to a single user. Finally, users are also anonymous in that there are no names or personal information associated with a given user.\nThe data set is quite large: there are 6, 336, 769 users with 37, 450, 461 transactions. We parse the data in two ways. The first way, which we will call the user graph, is quite intuitive: users (where each user owns a list of addresses) are nodes and transactions between users are edges. The second way, which we will call the transaction graph, models transactions as nodes and Bitcoin flow between transactions as edges.\nIn our analysis, we will use both graph types to investigate the Bitcoin network. The user graph will help us detect suspicious users, while the transaction graph will help us detect suspicious transactions. Using these two graph representations, we can not only find out both abnormal users and abnormal activities, but also check if our methods are consistent in the sense that suspicious transactions should belong to suspicious users."}, {"heading": "2.2. Feature Extraction", "text": "In order to use k-means as a baseline, calculate the Mahalanobis distance, use an Unsupervised SVM, for each node in the graph we extract a set of features. In each of the graph representations of the data (mentioned above), we extract the following 12 features. Keep in mind that even with the same names, the features mean different things for the two representations.\n\u2022 In-degree, out-degree, unique in-degree, unique out-degree, clustering coefficient\n\u2022 Average in-transaction, average out-transaction\n\u2022 Average time interval between in-transactions, average time interval between out-transactions,\n\u2022 Balance, creation date, active duration\n2.3. Unsupervised Learning Techniques\n2.3.1. k-means Clustering\nThe purpose of the k-means clustering method is to partition m points (i.e. m nodes in the graph) into k groups of similar characteristics. Technically speaking, k-means clustering itself is not a method for anomaly detection; however, it can be useful. Because we expect outliers to stay far away from the centroids found\nby k-means, k-means can be used to assess our true methods.\nFor this method to work, we first represent each node as a multi-dimensional vector in the Euclidean space; each dimension of a node is a feature that we choose from the list described in part 2.2. For runtime purposes, we select only a subset of features. For the user graph, we use six features: in-degree, out-degree, mean incoming transaction value, mean outgoing transaction value, mean time interval, and clustering coefficient. For transaction graph, we use three features: in-degree, out-degree, total amount of each transaction.\nThis method produces a set of m points (x1, ..., xm) in which xi \u2208 Rn (where n = 6 or 3 depending on graphs) for each i = 1, ...,m. We seek to partition these m points into k clusters S = (S1, ..., Sk) to solve\nmin S k\u2211 i=1 \u2211 x\u2208Si ||x\u2212 \u00b5i||2,\nwhere \u00b5i is the mean of the points in Si for each i = 1, ..., k. We use the k-means clustering algorithm as a heuristic method to solve this problem. The algorithm in details can be found in [2]. Our final note in this part is that we use the normalized log of feature values to account for different value scales of different features."}, {"heading": "2.3.2. Mahalanobis Distance Based Method", "text": "This method is based on the Multivariate Gaussian Distribution assumption.\nSpecifically, we assume the training set (x1, ..., xm) where xi \u2208 Rn (again, n = 6 for user graph and n = 3 for transaction graph) drawn from multivariate normal distribution\np(x;\u00b5,\u03a3) = 1\n(2\u03c0) n 2 |\u03a3| 12\nexp ( \u22121\n2 (x\u2212 \u00b5)T\u03a3\u22121(x\u2212 \u00b5)\n) .\nThe normal parameter fitting method (MLE) implies that \u00b5 and \u03c3 can be estimated by\n\u00b5\u0302 = 1\nm m\u2211 i=1 xi and \u03a3\u0302 = 1 m m\u2211 i=1 (xi \u2212 \u00b5)(xi \u2212 \u00b5)T .\nThen, we will flag x as an anomaly if p(x, \u00b5\u0302, \u03a3\u0302) < for some chosen threshold . Note that our data are unlabelled, so we will train and detect on the same data set."}, {"heading": "2.3.3. Unsupervised SVM", "text": "The usual SVM method does not work here because our data are unlabeled, so we will use a modified ver-\nsion of it. We also take advantage of the Kernel trick so that we can use an infinite dimensional feature space. We also assume the training set (x1, ..., xm) where xi \u2208 Rn for all i.\nWe start with the primal optimization problem:\nmin w,\u03c1\n( 1\n2 wTw\n) s.t. wTxi \u2265 \u03c1 \u2200i = 1, ...,m.\nA new test example x will be labeled sign(wTx \u2212 \u03c1). The point x with label (\u22121) is flagged as an anomaly.\nNote that the data are not linearly separable, so we need to use a soft-margin SVM. However, we will not use the constant C as in the usual soft-margin SVM due to its difficulty in interpretation. Instead, we follow [3] to use \u03bd-SVM method as follows.\nmin w,\u03be,\u03c1\n( 1\n2 wTw +\n1\n\u03bdm m\u2211 i=1 \u03bei \u2212 \u03c1\n) , s.t.\nwTxi \u2265 \u03c1\u2212 \u03bei \u2200i = 1, ...,m and \u03bei \u2265 0 \u2200i = 1, ...,m. Here, \u03bd \u2208 (0, 1] can be interpreted as an upper bound for the fraction of outliers (i.e. anomalies). In the Results section, we will determine which \u03bd is optimal.\nFollowing [3] again, we can write the corresponding dual problem using the Kernel trick:\nmin \u03b1 1 2 m\u2211 i=1 m\u2211 j=1 \u03b1i\u03b1jK(xi, xj)  subject to 0 \u2264 \u03b1i \u2264 1\n\u03bdm \u2200i = 1, ...,m and m\u2211 i=1 \u03b1i = 1.\nHere, we choose K(x, z) = exp(\u2212\u03b3(x\u2212 z)2) where the hyper-parameter \u03b3 will be fine-tuned later.\nTo solve for this optimization problem efficiently, we can use SMO method ([4]).\nFinally for 0 < \u03b1j < 1 \u03bdm , we can recover \u03c1:\n\u03c1 = m\u2211 i=1 \u03b1iK(xi, xj).\nThen a new point x is flagged anomaly if\u2211m i=1 \u03b1iK(xi, x) < \u03c1. Again, since our data are all unlabelled, we will will use the same data set for training and detecting."}, {"heading": "3. Evaluation Methods", "text": "With unlabeled data, evaluating our methods is a difficult challenge. Due to the nature of the network-type data set we have, we propose three evaluation methods.\n\u2022 Using k-means as a baseline, we can calculate the relative distances between the detected outliers and the centroids. If these values are small, then we conclude that our methods are not good enough. We call this \u201cVisualization Evaluation.\u201d\n\u2022 Since we represent our data in two ways with nodes and edges somehow exchanging, we can test for our methods\u2019 consistency by checking if detected suspicious users own detected suspicious transactions. We call this \u201cDual Evaluation.\u201d\nSpecifically, with the user graph we can get the top N user outliers and with the transaction graph we can get the top M transaction outliers. In this paper, we choose N = M = 100. We then determine XN - the set of transactions corresponding to the top N node outliers and YM - the set of users corresponding to the top M transaction outliers defined above. We define\nA1 = |XN \u2229 top XN transaction outliers|\n|XN |\nand\nA2 = |YM \u2229 top YM user outliers|\n|YM | .\nFinally, we define the Dual Evaluation Metric mDE by\nmDE = A1 +A2\n2 .\nNote that mDE \u2208 [0, 1], and the bigger it is the more accurate our method is.\n\u2022 Finally, there are roughly 30 revealed thieves in the Bitcoin network. We can check if they belong to our detected suspicious user and transaction sets. For this reason, these users and their illegal transactions will be included in the test sets of our methods."}, {"heading": "4. Results", "text": "The \u03bd-SVM method takes a long time to run, and since we are not able to use techniques like GPU-parallelized computation at the moment, we will limit our data set to 100, 000 data points for all methods."}, {"heading": "4.1. k-Means Clustering", "text": "Using the k-means clustering metric in [5] we find that setting k = 7 minimizes cross-cluster entropy for the user graph and k = 8 for the transaction graph. (Figure 1.) For the sake of the dual evaluation method, we choose k = 7 for both graph types."}, {"heading": "4.2. Mahalanobis Distance Based Method", "text": "Now, we run the Mahalanobis distance based method for two types of graphs. (Figures 2\u2212 3.)\nThe detected anomalies seem to appear at the border of the plot, which indicates that abnormal activities are usually extreme."}, {"heading": "4.3. Unsupervised SVM", "text": "We now run the Unsupervised (one - class) \u03bd-SVM method for two graph types. We start with identifying the optimal hyper-parameter \u03bd. Based on the evaluation section, we will choose the \u03bd which gives the largest values of A1 and A2. It turns out that the optimal \u03bd is around 0.005. (Figure 4.)\nNow with \u03bd = 0.005, the \u03bd-SVM method gives us the\ndetected anomalies for both types of graph representations in Figures 5 and 6.\nThe suspicious users and transactions suggested by the Unsupervised SVM method appear to be quite similar to those suggested by the Mahalanobis distance based method. They both usually appear on the outer borders of the graphs."}, {"heading": "5. Evaluation Results", "text": "\u2022 Using k-means clustering method, we get k clusters with corresponding k centroids. For each graph type (user and transaction) and for each method (Mahalanobis and Unsupervised SVM), we calculate the average of the ratios of detected anomaly distances to corresponding centroids over max distances from those centroids to their as-\nsigned points for the top 100 outliers.\nFor the Mahalanobis method, we get 0.7619 for the user graph and 0.8277 for the transaction graph. For the Unsupervised SVM method, we get 0.7192 for the user graph and 0.8584 for the transaction graph. These values are as large as we expect them to be since by observations in the Result section, detected anomalies appear to be extreme points.\n\u2022 For the Mahalanobis Distance based method, we calculate A1 and A2 to be 0.02495 and 0.026316 respectively, which gives mDE = 0.025633. Though this value is quite small, it comes out not as a surprise given the simplicity of our method and our small set of data.\nFor the Unsupervised SVM method, we get A1 = 0.1782 and A2 = 0.1101 which gives mDE = 0.14415. This value is much higher than the one produced by the Mahalanobis distance based method, even given our small set of data.\n\u2022 For the Mahalanobis Distance based method, we detect one known theft that occurred in June 2011. The anomalous transaction obtained a total of over 4000 BTC from 620 various addresses and funneled them to a single address.\nFor the Unsupervised SVM based method, we detect one known loss that occurred in October 2011. The anomalous transaction was one of 23 transactions that caused a user to lose over 2, 600 BTC due to corruption in a hashing function."}, {"heading": "6. Future Studies", "text": "We propose to parallelize computation in order to enable faster outlier detection using a GPU. This involves significant work, such as introducing thread-safety in the learning methods, but will allow us to analyze the full dataset of \u223c 38 million transactions."}, {"heading": "7. Conclusions", "text": "In this paper, we have investigate the Bitcoin network. We first represent the data with two focuses: users and transactions. We then use three main social network techniques to detect anomalies, which are potential anomalous users and transactions. While the agreement metrics are not high, we are able to detect two known cases of theft and one known case of loss, out of the 30 known cases we have.\nReferences\n[1] https://bitcoin.org/en/ [2] Lloyd, Stuart P. (1982), Least squares quantization in PCM, IEEE Transactions on Information Theory 28 (2): 129-137. [3] B. Scho\u0308lkopf, J. Platt, J. Shawe-Taylor, A. J. Smola, and R. C. Williamson.Estimating the support of a high-dimensional distribution. Neural Computation, 13, 2001, 1443-1471. [4] J. Platt. Sequential minimal optimization: A fast algorithm for training support vector machines. Technical Report MSR-TR-98-14, Microsoft Research, 1998a. [5] Xiong, H. et al. K-means Clustering versus Validation Measures: A Data Distribution Perspective. KDD\u201906, August 20-23, 2006."}], "references": [{"title": "Least squares quantization in PCM", "author": ["Lloyd", "Stuart P"], "venue": "IEEE Transactions on Information Theory", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1982}, {"title": "Williamson.Estimating the support of a high-dimensional distribution", "author": ["B. Sch\u00f6lkopf", "J. Platt", "J. Shawe-Taylor", "A.J. Smola", "R. C"], "venue": "Neural Computation,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2001}, {"title": "Sequential minimal optimization: A fast algorithm for training support vector machines", "author": ["J. Platt"], "venue": "Technical Report MSR-TR-98-14, Microsoft Research,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1998}, {"title": "K-means Clustering versus Validation Measures: A Data Distribution Perspective", "author": ["H Xiong"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "The algorithm in details can be found in [2].", "startOffset": 41, "endOffset": 44}, {"referenceID": 1, "context": "Instead, we follow [3] to use \u03bd-SVM method as follows.", "startOffset": 19, "endOffset": 22}, {"referenceID": 1, "context": "Following [3] again, we can write the corresponding dual problem using the Kernel trick:", "startOffset": 10, "endOffset": 13}, {"referenceID": 2, "context": "To solve for this optimization problem efficiently, we can use SMO method ([4]).", "startOffset": 75, "endOffset": 78}, {"referenceID": 3, "context": "Using the k-means clustering metric in [5] we find that setting k = 7 minimizes cross-cluster entropy for the user graph and k = 8 for the transaction graph.", "startOffset": 39, "endOffset": 42}], "year": 2017, "abstractText": "The problem of anomaly detection has been studied for a long time. In short, anomalies are abnormal or unlikely things. In financial networks, thieves and illegal activities are often anomalous in nature. Members of a network want to detect anomalies as soon as possible to prevent them from harming the network\u2019s community and integrity. Many Machine Learning techniques have been proposed to deal with this problem; some results appear to be quite promising but there is no obvious superior method. In this paper, we consider anomaly detection particular to the Bitcoin transaction network. Our goal is to detect which users and transactions are the most suspicious; in this case, anomalous behavior is a proxy for suspicious behavior. To this end, we use three unsupervised learning methods including k-means clustering, Mahalanobis distance, and Unsupervised Support Vector Machine (SVM) on two graphs generated by the Bitcoin transaction network: one graph has users as nodes, and the other has transactions as nodes.", "creator": "LaTeX with hyperref package"}}}