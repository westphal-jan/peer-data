{"id": "1612.00341", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2016", "title": "A Compositional Object-Based Approach to Learning Physical Dynamics", "abstract": "We present the Neural Physics Engine (NPE), an object-based neural network architecture for learning predictive models of intuitive physics. Our approach is based on the strengths of both symbolic and neural approaches: Like a symbolic physics engine, the NPE is equipped with general notions of objects and their interactions, but as a neural network it can also be trained using stochastic gradient descent to adapt to specific object properties and dynamics of different worlds. We evaluate the effectiveness of our approach with regard to simple rigid body dynamics in two-dimensional worlds. By comparing it with less structured architectures, we show that the compositional representation of the structure in physical interactions improves its ability to predict movement, refer to different numbers of objects and derive latent properties of objects.", "histories": [["v1", "Thu, 1 Dec 2016 16:39:04 GMT  (7857kb,D)", "http://arxiv.org/abs/1612.00341v1", "Under review as a conference paper for ICLR 2017. 11 pages, 5 figures"], ["v2", "Sat, 4 Mar 2017 17:44:06 GMT  (6899kb,D)", "http://arxiv.org/abs/1612.00341v2", "Published as a conference paper for ICLR 2017. 15 pages, 6 figures"]], "COMMENTS": "Under review as a conference paper for ICLR 2017. 11 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["michael b chang", "tomer ullman", "antonio torralba", "joshua b tenenbaum"], "accepted": true, "id": "1612.00341"}, "pdf": {"name": "1612.00341.pdf", "metadata": {"source": "CRF", "title": "LEARNING PHYSICAL DYNAMICS", "authors": ["Michael B. Chang", "Tomer Ullman", "Antonio Torralba", "Joshua B. Tenenbaum"], "emails": ["mbchang@mit.edu", "tomeru@mit.edu", "torralba@mit.edu", "jbt@mit.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "Physical reasoning is a crucial part of learning, perception, planning, inference, and understanding in artificial intelligence, and can be leveraged to accelerate the learning of new tasks (Lake et al., 2016). Accurately modeling a scene involves reasoning about the spatial properties, identities and locations of objects (Eslami et al., 2016; Hinton et al., 2011; Jaderberg et al., 2015; Kulkarni et al., 2015), but also their physical properties, future dynamics, and causal relationships. Such a sense of intuitive physics can be seen as a program (Anderson, 1990; Goodman and Tenenbaum, 2016) that takes input provided by a physical scene and the past states of objects, and outputs the future states and physical properties of relevant objects for a given task. This program should flexibly scale to model worlds with a variable number of objects, object properties, dynamics, interactions, and physical laws. It must be general enough to express various arrangements and behavior in known worlds, and also flexible enough to adapt to unknown worlds with new configurations.\nAt least two general approaches have emerged in the search for a program that captures commonsense physical reasoning. The top-down approach (Battaglia et al., 2013; Ullman et al., 2014; Wu et al., 2015) formulates the problem as inference over the parameters of a symbolic physics engine, while the bottom-up approach (Agrawal et al., 2016; Fragkiadaki et al., 2015; Lerer et al., 2016; Li et al., 2016; Mottaghi et al., 2015; 2016; Sutskever et al., 2009) learns to directly map physical observations to motion prediction or physical judgments. A program under the top-down approach can generalize across any scenario supported by the entities and operators in its description language. However, it may be brittle under scenarios not supported by its description language, and adapting to these new scenarios requires modifying the code or generating new code for the physics engine itself. In contrast, gradient-based bottom-up approaches can apply the same model architecture and learning algorithm to specific scenarios without requiring the physical dynamics of the scenario to be pre-specified. This often comes at the cost of reduced generality: transferring knowledge to new scenes may require extensive retraining, even in cases that seem trivial to human reasoning.\nThis paper takes a step toward bridging this gap between expressivity and adaptability, by proposing the Neural Physics Engine (NPE), a model that combines rough symbolic structure with gradient-\nar X\niv :1\n61 2.\n00 34\n1v 1\n[ cs\n.A I]\n1 D\nec 2\n01 6\nbased learning for physical inference. This hybrid approach exhibits several strong inductive biases that are explicitly present in symbolic physics engines, such as a notion of objects-specific properties and object interactions. It is also end-to-end differentiable, and thus is able to flexibly tailor itself to the specific object properties and dynamics of a given world through training.\nWhile previous bottom-up approaches (Sec. 4) have coupled learning vision and learning physical dynamics, we take a different approach, and for two reasons. First, we see that disentangling the visual properties of an object from its physical dynamics is a step toward achieving the generality of a physics engine. A program that learns to evolve objects through time can potentially be reused as a subprogram that can be composed under a modular framework with other programs for applications in areas such as model-based planning and model-based reinforcement learning. Second, we are optimistic that those two components indeed can be decoupled, that a vision model can map visual input to an intermediate state space, and a dynamics model can evolve objects in that state space through time. For example, there is much work in object detection and segmentation for extracting position and velocity, as well as work for extracting latent object properties (Wu et al., 2015). Therefore this paper focuses on learning dynamics in that state space, taking a small step toward emulating a general-purpose physics engine (Lake et al., 2016), with the eventual goal of building a system that exhibits the compositionality, modularity, and generality of physics engine whose internal components can be learned through observation.\nThis paper\u2019s contribution links two levels of factorization and composition in learning physical dynamics. On the level of the physical scene, we factorize the scene into object-based representations (Sec. 2.1), and compose smaller building blocks to form larger objects (Sec. 3.4). This framework of representation adapts to complex scenes and configurations with variable number of objects. On the level of the physics program, the NPE architecture (Sec. 2.2) explicitly reflects a causal structure in object interactions by factorizing object dynamics into pairwise interactions. As a predictive model of physical dynamics, the NPE models the future state of a single object as a function composition of the pairwise interactions between itself and other neighboring objects in the scene. This structure serves to guide learning towards object-based reasoning as (Hinton et al., 2011) does, and, by design, allows physical knowledge to transfer across variable number of objects and for object properties to be explicitly inferred. This approach \u2013 starting with a general sketch of a program and filling in the specifics \u2013 is similar to ideas presented by Solar-Lezama (2008); Tenenbaum et al. (2011). The NPE\u2019s general sketch is its architectural structure, and it extends and enriches this sketch to model the specifics of a particular scene by training on observed trajectories from that scene.\nIn Sec. 3 we investigate variations on two-dimensional worlds of balls and obstacles from the matter-js physics engine (Brummitt, http://brm.io/matter-js/) as a testbed for exploring the NPE\u2019s capabilities for modeling simple rigid body dynamics under our state space representation. While these worlds are generated from a simplified physics engine, we believe that learning to model such simple physics under the NPE\u2019s framework is a first and necessary step towards emulating the full capacity of a general physics engine, while maintaining a differentiability that can allow it to eventually learn complex real-world physical phenomena (see Sec. 4) that would be challenging to engineer into these physics engines. This paper establishes that important step."}, {"heading": "2 APPROACH", "text": ""}, {"heading": "2.1 STATE SPACE", "text": "We make two observations (Fig. 1) in our factorization of the scene. First, because physics does not change across inertial frames, it suffices to separately predict the future state of each object conditioned on the past states of itself and the other objects in its neighborhood, similar to Fragkiadaki et al. (2015). Second, because physics is Markovian, this prediction need only be for the immediate next timestep. Therefore, we choose an object-based state representation; a state vector comprises extrinsic properties (position, velocity, orientation, angular velocity), intrinsic properties (mass, object type, object size), and global properties (gravitational, frictional, and pairwise forces) at a given time instance. Sec. 3.4 describes composing objects to represent larger structures."}, {"heading": "2.2 NEURAL PHYSICS ENGINE", "text": "Pairwise Factorization Letting a particular object be the focus object f and all other objects in the scene be context objects c, the NPE models the focus object\u2019s velocity v[t+1]f as a composition of the pairwise interactions between itself and other neighboring context objects in the scene during time t \u2212 1 and t. This input is represented as pairs of object state vectors {(of , oc1)[t\u22121,t], (of , oc2)[t\u22121,t], ...}. The NPE also predicts angular velocity along with velocity, but for the experiments in this paper we always set angular velocity, as well as gravity, friction, and pairwise forces, to zero. As shown in Fig. 2b, the NPE composes an encoder function and a decoder function. The encoder function fenc summarizes the interaction of a single object pair. The decoder function takes the sum of encodings of all pairs and the focus object\u2019s past state as input, and predicts the focus object\u2019s velocity v[t+1]f . In practice, the NPE predicts the change \u2206v between t and t + 1 to compute v[t+1] = v[t] + \u2206v, and updates position using the velocity as a first-order approximation. We do not include acceleration in the state representation because position and velocity fully parametrize an object\u2019s state. Thus acceleration (e.g. collisions) can be learned by observing velocity for two consecutive timesteps, hence our choice for two input timesteps. We explored longer input durations as well and found no additional benefit.\nNeighborhood Mask Each (of , oc) pair is selected to be in the set of neighbors of f by the neighborhood masking function 1 [||pc \u2212 pf )|| < N(of )], which takes value 1 if the Euclidean distance between the positions pf and pc of the focus and context object respectively at time t is less the neighborhood threshold N(of ). Many physics engines use a collision detection scheme with two phases. Broad phase is used for computational efficiency and use a neighborhood threshold to select objects that might, but not necessarily will, collide an object. The actual collision detection is done with narrow phase on that smaller subset of objects, which also resolves the collisions for the objects that do collide. Analogously, our neighborhood mask implements broad phase, and the NPE implements narrow phase. In this paper, we found that 3.5 times the focus object\u2019s radius worked well as N(of ). Future work can view N(of ) as a spatial attention mechanism that can be learned jointly with the other model parameters.\nFunction Composition Symbolic physics engines evolve objects through time based on dynamics that dictate their independent behavior (e.g. friction, gravity, inertia) and their behavior with other objects (e.g. collision, support, attraction, repulsion). Notably, in a particular object\u2019s reference frame, the forces it feels from other objects are additive. The NPE architecture incorporates several inductive biases that reflect this recipe. fenc and fdec induce a causal structure on pairs of objects that can be composed when reasoning about how the object behaves. We provide a loose interpretation of the encoder output ec,f as the effect of object c on object f , and require that these effects are additive as forces are. By design, this allows the NPE to scale naturally to different numbers of neighboring context objects. These inductive biases have the effect of strongly constraining the space of possible programs of predictive models that the NPE can learn, focusing on compositional programs that reflect pairwise causal structure in object interactions."}, {"heading": "2.3 BASELINES", "text": "The purpose of contrasting the NPE with the following two baselines is to illustrate the benefit of pairwise factorization and function composition, which are the key architectural features of the NPE. As the architectures for both baselines have been shown to work well in similar tasks, it is not immediately clear whether the NPE\u2019s assumptions are useful or necessary, so these are good baselines to compare with. Viewed in another way, comparing with these baselines is a lesion study on the NPE because each baseline lacks an aspect of the NPE structure.\nNo-Pairwise The No-Pairwise (NP) baseline is summarized by Fig. 2c. The NP is very similar to the NPE but has the pairwise layer removed; otherwise the NP\u2019s encoder and decoder are the same as the NPE. Therefore the NP most directly highlights the value of the NPE\u2019s pairwise factorization. The NP is also a Markovian variant of the Social LSTM (Alahi et al., 2016); it sums the encodings of context objects after encoding each object independently, similar to the Social LSTM\u2019s \u201csocial pooling.\u201d Information for modeling how objects interact would only be present after the encoding step. Thus one interpretation for how such a structure could predict dynamics is if the encoder\u2019s object encoding comprises an abstract object representation and a force field created by that object. Therefore the NP decoder could apply the sum of the force fields of all context objects to the focus object\u2019s abstract object representation to predict the focus object\u2019s velocity. As Alahi et al. has demonstrated the Social LSTM\u2019s performance in modeling human trajectories, it is interesting to see how the same architectural assumptions performs for the physics of moving objects.\nLSTM Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997) have been shown to sequentially attend to objects (Eslami et al., 2016), so it is interesting to test whether a LSTM is well-suited for modeling object interactions, when the object states are explicitly given as input. From a cognitive science viewpoint, an LSTM can be interpreted as a serial mechanism in object tracking (Pylyshyn and Annan, 2006). Our LSTM architecture (Fig. 2d) accepts the state of each context object until the last step, at which it takes in the focus object\u2019s state and predicts its velocity. Because the LSTM moves through the object space sequentially, its lack of factorized compositional structure highlights the value of the NPE\u2019s function composition of the independent interactions between an object and its neighbors. Unlike the NPE and NP, the LSTM\u2019s structure\ndoes not differentiate between focus and context object, so we add a flag to the state representation to indicate to whether an object is a context or focus object. We shuffle the order of the context objects to account for an ordering bias."}, {"heading": "2.4 IMPLEMENTATION", "text": "We trained all models using the rmsprop Tieleman and Hinton (2012) backpropagation algorithm with a Euclidean loss for 1,200,000 iterations with a learning rate of 0.0003 and a learning rate decay of 0.99 every 2,500 training iterations, beginning at iteration 50,000. We used minibatches of size 50 and used a 70-15-15 split for training, validation, and test data.\nAll models are implemented using the neural network libraries built by Collobert et al.; Le\u0301onard et al.. The NPE encoder is consists of a pairwise layer of 25 hidden units and a 5-layer feedforward network of 50 hidden units per layer each with rectified linear activations. Because we use a binary mask to zero out non-neighboring objects, we implement the encoder layers without bias such that non-neighboring objects do not contribute to the network activations. The encoding parameters are shared across all object pairs. The decoder is a five-layer network with 50 hidden units per layer and ReLU activations after all but the last layer. The NP encoder architecture is the same as the NPE encoder, but without the pairwise layer. The NP decoder architecture is the same as the NPE decoder. The LSTM has three layers of 100 hidden units and a linear layer after the last layer. It has rectified linear activations after each layer of the LSTM.\nWe informally explored several hyperparameters, varying the number of layers from 2 to 5, the hidden dimension from 50 to 100, and learning rates in {10\u22125, 3\u00d7 10\u22125, 10\u22124, 3\u00d7 10\u22124, 10\u22123, 3\u00d7 10\u22123}. Though this is far from an exhaustive search, we found that the above hyperparameter settings work well."}, {"heading": "3 EXPERIMENTS", "text": "Using the matter-js physics engine, we evaluate the NPE on worlds of balls and obstacles. These worlds exhibit self-evident dynamics and support a wide set of scenarios that reflect everyday physics. Bouncing balls have also been of interest in cognitive science to study causality and counterfactual reasoning, as in (Gerstenberg et al., 2012). We trained on 3-timestep windows in trajectories of 60 timesteps (10 timesteps\u2248 1 second). For a world of k objects, we generate 50,000 such trajectories. For experiments where we train on multiple worlds together, we shuffle the examples across all training worlds and train without a curriculum schedule. All worlds have a vertical dimension of 600 pixels and a horizontal dimension of 800 pixels, and we constrain the maximum velocity of an object to be 60 pixels/second. We normalize positions to [0, 1] by dividing by the horizontal dimension, and we normalize velocities to [\u22121, 1] by dividing by the maximum velocity. Plots show results over three independent runs averaged over held-out test data with different random seeds. Randomly selected simulation videos are at https://drive.google.com/ drive/folders/0BxCJLi4FnT_6QW4tcF94d1doLWs?usp=sharing."}, {"heading": "3.1 PREDICTION", "text": "First we consider simple worlds of four balls of uniform mass (Fig. 3a). To measure performance in simulation, we visualize the cosine similarity between the predicted velocity and the ground truth velocity as well as the relative error in magnitude between the predicted velocity and the ground truth velocity over 50 timesteps of simulation (about 5 seconds). The models take timesteps 1 and 2 as initial input, and then use previous predictions as input to future predictions. To measure progress through training, we also display the Euclidean loss on the normalized velocity."}, {"heading": "3.2 GENERALIZATION AND KNOWLEDGE TRANSFER", "text": "We test whether learned knowledge of these simple physics concepts can be transferred and extrapolated to worlds with a number of objects previously unseen (Fig. 3b). The unseen worlds (6, 7, 8 balls) in the test data are combinatorially more complex and varied than the observed worlds (3, 4, 5 balls) in the training data. All objects have equal mass. The NPE\u2019s predictions are more consistent, whereas the NP and LSTM\u2019s prediction begin to diverge wildly towards the end of 50 timesteps\nof simulation (Fig. 3b, middle row). The NPE\u2019s performance on this extrapolation task suggests that its architectural inductive biases are useful for generalizing knowledge learned in Markovian domains with causal structure in object interactions. The next paragraph illustrates another aspect of the NPE\u2019s strong generalization capability."}, {"heading": "3.3 MASS INFERENCE", "text": "We now show that the NPE can infer latent properties such as mass. This proposal is motivated by the experiments in Battaglia et al. (2013), which uses a probabilistic physics simulator to infer various properties of a scene configuration. Whereas the physical rules of their simulator were manually pre-specified, the NPE learns these rules from observation. We train on the same worlds used in both the prediction and generalization tasks, but we uniformly sampled the mass for each ball from the log-spaced set {1, 5, 25}. We chose to use discrete-valued masses to simplify our qualitative understanding of the model\u2019s capacity to infer. For future work we would like to investigate continuously valued masses and evaluate with binary comparisons (e.g. \u201dWhich is heavier?\u201d).\nAs summarized by Fig. 3c and Fig. 4a, we select scenarios exhibiting collisions with the focus object, fix the masses of all other objects, and score the NPE\u2019s prediction under all possible mass hypotheses for the focus object. The prediction is scored against the ground-truth under the same Euclidean loss used in training. The hypothesis whose prediction yields the lowest error is the NPE\u2019s maximum likelihood estimate of the focus object\u2019s mass. The NPE achieves about 90% accuracy, meaning it has 90% probability of inferring the correct mass.\nWe see that a simulator with a more structured model of the world performs more accurate inferences, and that this simulation capability can be learned from observation. Though we adopted a\nparticular parametrization of an object, the NPE is not limited to the semantic meaning of the elements of its input, so we expect other latent object properties can be inferred this way. Because the NPE is differentiable, we expect that it can also infer object properties by backpropagating prediction error to its a randomly sampled input. This would be especially useful for inferring non-categorical values, such as positions of \u201cinvisible\u201d objects, whose effects are felt but whose position is unknown."}, {"heading": "3.4 DIFFERENT SCENE CONFIGURATIONS", "text": "We demonstrate representing large structures as a composition of smaller objects as building blocks in a world of balls and obstacles. These worlds contain 2 balls bouncing around in variations of 4 different wall geometries. \u201cO\u201d and \u201cL\u201d geometries have no internal obstacles and are in the shape of a rectangle and \u201cL\u201d respectively. \u201cU\u201d and \u201cI\u201d have internal obstacles. Obstacles in \u201cU\u201d are linearly attached to the wall like a protrusion, while obstacles in \u201cI\u201d have no constraint in position. We randomly vary the position and orientation of the \u201cL\u201d concavity and the \u201cU\u201d protrusion. We randomly sample the positions of the \u201cI\u201d internal obstacles.\nWe train on the conceptually simpler \u201cO\u201d and \u201cL\u201d worlds and test on the more complex \u201cU\u201d and \u201cI\u201d worlds. Variations in wall geometries adds to the difficulty of this extrapolation task. However, our state space representation was designed to be flexible to this variation, by representing walls as composed of uniformly-sized obstacles, similarly to how many real-world objects are composed of smaller components. At most 12 context objects are present in the focus object\u2019s neighborhood at a time. The \u201cU\u201d geometries have 33 objects in the scene, the most out of all the wall geometries. As shown in Fig. 4b and 5, using such a compositional representation of the scene allows the NPE to scale to different configurations, which would not be straightforward to do without such a representation."}, {"heading": "4 RELATION TO PREVIOUS WORK", "text": "A recent set of top-down approaches (Battaglia et al., 2013; Bates et al., 2015; Ullman et al., 2014) investigate probabilistic and deterministic (Wu et al., 2015) game physics engines as computational models for physical simulation in humans. However, inverting a physics engine, as the Intuitive Physics Engine (IPE) (Battaglia et al., 2013) does, requires a full specification of the physical laws and object geometries. Inferring how physical laws compose and apply to a given scenario is the IPE\u2019s strength, but the nature of these physical laws are pre-defined rather than learned from observation. To manually define, for example, the asymmetrical geometry of a hammer, the fluid motion of a tape dispenser dispensing tape, or the multiple stages of opening a door by its door handle, and in addition the geometry and physical behavior of every other object in a scene, requires extensive hand engineering that is difficult to automate.\nAdapting to a scene with a differentiable model such as a neural network offers a possible path to automatically adapt a general architecture to the specific physical properties of a scene without prior human specification. Thus, we view the NPE as a differentiable model that complements and builds on top of the key structural assumptions in these top-down approaches.\nBottom-up approaches have mapped visual observations to physical judgments (Lerer et al., 2016; Li et al., 2016; Mottaghi et al., 2015; 2016) or passive (Lerer et al., 2016; Srivastava et al., 2015; Sutskever et al., 2009) and action-conditioned (Agrawal et al., 2016; Finn et al., 2016; Fragkiadaki et al., 2015) motion prediction. With the exception of works as (Wu et al., 2015), the bottom-up approaches mentioned above do not infer latent properties as our model does. Because the visual and physical are not disentangled, knowledge transfer to conceptually similar worlds, such as those with different numbers of objects, has been a challenge without retraining.\nOur work brings a different perspective to recent work that have begun to address this problem. Lerer et al. (2016) used a shared network for both predicting future frames and for making physical judgments. Similarly, our work presents a single model that makes physical judgments beyond frame prediction. However, while their network used a specifically designed branch to predict tower stability, our network is less task-specific and infers mass using the same architecture used for prediction. Translation invariance is an explicit assumption in our model that allows our model to exhibit greater ability to extrapolate to larger numbers of objects.\nThis assumption is also core to Fragkiadaki et al. (2015), which conditions motion prediction on individual objects rather than the entire scene. However, a key contrast between their and our work\nis that the NPE\u2019s representations operate over a more abstract symbolic state space while theirs operate over visual attention windows. They argued that the combinatorial structure from a variable number of objects with variable properties and nonlinear behavior such as collisions creates a depth in complexity across which it is difficult to define a single state space. We presented a factorization in 2.1 that allows us to define such a state space.\nRecently, in work we only learned about after implementing our approach, Battaglia et al. (2016) in parallel and independently developed a similar architecture that they call Interaction Networks for learning to model physical systems. They show how such architectures can apply to several different kind of physical systems, including n-body gravitational interactions and a string falling under gravity. Like their work, our model can simulate over many timesteps very effectively when only trained for next-timestep prediction, and can generalize to different world configurations and different numbers of objects.\nCompared to Interaction Networks, a main difference in our architecture is that ours does not take object relations as explicit input, but instead learns the nature of these relations by constraining attention to a neighborhood set of objects. While constraining attention via a neighborhood threshold is more computationally efficient, it cannot capture longer range spatial dependencies such as gravity, which acts from a remote distance. To address this, we propose for future work to learn an adaptive neighborhood threshold, such that the model would infer which context objects at which distances to pay attention to when computing its prediction. Another difference is that while they train an additional classifier on top of their model to do inference, in our work the same model can be reused for both prediction and inference. Our network produces output given inputs during prediction, but infers inputs given outputs during inference. We believe both their and our work bring valuable perspectives in learning to emulate general-purpose physics engines."}, {"heading": "5 DISCUSSION", "text": "While this paper is not the first to explore predictive models of physics, here we take this opportunity to highlight the value of this paper\u2019s contributions. We hope these contributions can seed further research that builds on themes of factorization and composition this paper proposes.\nWe have presented a factorization of a physical scene into composable object-based representations and also a model architecture whose compositional structure factorizes object dynamics into pairwise interactions. We applied the NPE to simple two-dimensional worlds ranging in complexity that demonstrate the usefulness of these two levels of factorization and composition. We showed that NPE achieves low prediction error, extrapolates learned physical knowledge to previously unseen number of objects and world configurations, and can infer latent properties such as mass.\nFurther work includes generalizing beyond object count to new object types and physical laws, such as in worlds with stacked block towers and liquids. Our results invite questions on how much prior information and structure should and could be given to bottom-up neural networks, and what can be learned without building in such structure. It will be interesting to see whether similar model assumptions work for both objects and agents. This paper works toward emulating a general purpose physics engine under a framework where visual and physical aspects of a scene are disentangled. Future work also includes linking the NPE with perceptual programs that extract properties such as position and mass from visual input. We believe the expressiveness of physics engines and the adaptability of neural networks are ingredients that will become increasingly important for modeling larger and more complex physical systems. The Neural Physics Engine proposes a possible path to link those two ingredients."}, {"heading": "ACKNOWLEDGMENTS", "text": "We thank Tejas Kulkarni for insightful discussions and guidance. We thank Ilker Yidirim, Erin Reynolds, Feras Saad, Andreas Stuhlmu\u0308ller, Adam Lerer, Chelsea Finn, Jiajun Wu, and the anonymous reviewers for valuable feedback. We thank Liam Brummit, Kevin Kwok, and Guillermo Webster for help with matter-js. M. Chang was graciously supported by MIT\u2019s SuperUROP and UROP programs."}], "references": [{"title": "Learning to poke by poking: Experiential learning of intuitive physics", "author": ["P. Agrawal", "A. Nair", "P. Abbeel", "J. Malik", "S. Levine"], "venue": "arXiv preprint arXiv:1606.07419,", "citeRegEx": "Agrawal et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agrawal et al\\.", "year": 2016}, {"title": "Social lstm: Human trajectory prediction in crowded spaces. 2016", "author": ["A. Alahi", "K. Goel", "V. Ramanathan", "A. Robicquet", "L. Fei-Fei", "S. Savarese"], "venue": null, "citeRegEx": "Alahi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Alahi et al\\.", "year": 2016}, {"title": "Cognitive psychology and its implications", "author": ["J.R. Anderson"], "venue": "WH Freeman/Times Books/Henry Holt & Co,", "citeRegEx": "Anderson.,? \\Q1990\\E", "shortCiteRegEx": "Anderson.", "year": 1990}, {"title": "Humans predict liquid dynamics using probabilistic simulation", "author": ["C.J. Bates", "I. Yildirim", "J.B. Tenenbaum", "P.W. Battaglia"], "venue": null, "citeRegEx": "Bates et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bates et al\\.", "year": 2015}, {"title": "Interaction networks for learning about objects, relations and physics", "author": ["P. Battaglia", "R. Pascanu", "M. Lai", "D. Jimenez Rezende", "K. Koray"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Battaglia et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Battaglia et al\\.", "year": 2016}, {"title": "Simulation as an engine of physical scene understanding", "author": ["P.W. Battaglia", "J.B. Hamrick", "J.B. Tenenbaum"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Battaglia et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Battaglia et al\\.", "year": 2013}, {"title": "Torch7: A matlab-like environment for machine learning", "author": ["R. Collobert", "K. Kavukcuoglu", "C. Farabet"], "venue": "In BigLearn, NIPS Workshop, number EPFL-CONF-192376,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Attend, infer, repeat: Fast scene understanding with generative models", "author": ["S. Eslami", "N. Heess", "T. Weber", "Y. Tassa", "K. Kavukcuoglu", "G.E. Hinton"], "venue": "arXiv preprint arXiv:1603.08575,", "citeRegEx": "Eslami et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Eslami et al\\.", "year": 2016}, {"title": "Unsupervised learning for physical interaction through video prediction", "author": ["C. Finn", "I. Goodfellow", "S. Levine"], "venue": "arXiv preprint arXiv:1605.07157,", "citeRegEx": "Finn et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Finn et al\\.", "year": 2016}, {"title": "Learning visual predictive models of physics for playing billiards", "author": ["K. Fragkiadaki", "P. Agrawal", "S. Levine", "J. Malik"], "venue": "arXiv preprint arXiv:1511.07404,", "citeRegEx": "Fragkiadaki et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Fragkiadaki et al\\.", "year": 2015}, {"title": "Noisy newtons: Unifying process and dependency accounts of causal attribution", "author": ["T. Gerstenberg", "N. Goodman", "D.A. Lagnado", "J.B. Tenenbaum"], "venue": "In In proceedings of the 34th. Citeseer,", "citeRegEx": "Gerstenberg et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gerstenberg et al\\.", "year": 2012}, {"title": "Probabilistic models of cognition, 2016", "author": ["N.D. Goodman", "J.B. Tenenbaum"], "venue": "URL http: //probmods.org", "citeRegEx": "Goodman and Tenenbaum.,? \\Q2016\\E", "shortCiteRegEx": "Goodman and Tenenbaum.", "year": 2016}, {"title": "Transforming auto-encoders", "author": ["G.E. Hinton", "A. Krizhevsky", "S.D. Wang"], "venue": "In Artificial Neural Networks and Machine Learning\u2013ICANN", "citeRegEx": "Hinton et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2011}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter and Schmidhuber.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Spatial transformer networks", "author": ["M. Jaderberg", "K. Simonyan", "A. Zisserman"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Jaderberg et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jaderberg et al\\.", "year": 2015}, {"title": "Picture: A probabilistic programming language for scene perception", "author": ["T.D. Kulkarni", "P. Kohli", "J.B. Tenenbaum", "V. Mansinghka"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Kulkarni et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kulkarni et al\\.", "year": 2015}, {"title": "Building machines that learn and think like people", "author": ["B.M. Lake", "T.D. Ullman", "J.B. Tenenbaum", "S.J. Gershman"], "venue": "arXiv preprint arXiv:1604.00289,", "citeRegEx": "Lake et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lake et al\\.", "year": 2016}, {"title": "rnn: Recurrent library for torch", "author": ["N. L\u00e9onard", "S. Waghmare", "Y. Wang"], "venue": "arXiv preprint arXiv:1511.07889,", "citeRegEx": "L\u00e9onard et al\\.,? \\Q2015\\E", "shortCiteRegEx": "L\u00e9onard et al\\.", "year": 2015}, {"title": "Learning physical intuition of block towers by example", "author": ["A. Lerer", "S. Gross", "R. Fergus", "J. Malik"], "venue": "arXiv preprint arXiv:1603.01312,", "citeRegEx": "Lerer et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lerer et al\\.", "year": 2016}, {"title": "To fall or not to fall: A visual approach to physical stability prediction", "author": ["W. Li", "S. Azimi", "A. Leonardis", "M. Fritz"], "venue": "arXiv preprint arXiv:1604.00066,", "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Newtonian image understanding: Unfolding the dynamics of objects in static images", "author": ["R. Mottaghi", "H. Bagherinezhad", "M. Rastegari", "A. Farhadi"], "venue": "arXiv preprint arXiv:1511.04048,", "citeRegEx": "Mottaghi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mottaghi et al\\.", "year": 2015}, {"title": "if...\u201d learning to predict the effect of forces in images", "author": ["R. Mottaghi", "M. Rastegari", "A. Gupta", "A. Farhadi"], "venue": "arXiv preprint arXiv:1603.05600,", "citeRegEx": "Mottaghi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mottaghi et al\\.", "year": 2016}, {"title": "Dynamics of target selection in multiple object tracking (mot)", "author": ["Z.W. Pylyshyn", "V. Annan"], "venue": "Spatial vision,", "citeRegEx": "Pylyshyn and Annan.,? \\Q2006\\E", "shortCiteRegEx": "Pylyshyn and Annan.", "year": 2006}, {"title": "Program synthesis by sketching", "author": ["A. Solar-Lezama"], "venue": "ProQuest,", "citeRegEx": "Solar.Lezama.,? \\Q2008\\E", "shortCiteRegEx": "Solar.Lezama.", "year": 2008}, {"title": "Unsupervised learning of video representations using lstms", "author": ["N. Srivastava", "E. Mansimov", "R. Salakhutdinov"], "venue": null, "citeRegEx": "Srivastava et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2015}, {"title": "The recurrent temporal restricted boltzmann machine", "author": ["I. Sutskever", "G.E. Hinton", "G.W. Taylor"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Sutskever et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2009}, {"title": "How to grow a mind: Statistics, structure, and abstraction", "author": ["J.B. Tenenbaum", "C. Kemp", "T.L. Griffiths", "N.D. Goodman"], "venue": null, "citeRegEx": "Tenenbaum et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tenenbaum et al\\.", "year": 2011}, {"title": "Lecture 6.5\u2014RmsProp: Divide the gradient by a running average of its recent magnitude", "author": ["T. Tieleman", "G. Hinton"], "venue": "COURSERA: Neural Networks for Machine Learning,", "citeRegEx": "Tieleman and Hinton.,? \\Q2012\\E", "shortCiteRegEx": "Tieleman and Hinton.", "year": 2012}, {"title": "Learning physics from dynamical scenes", "author": ["T. Ullman", "A. Stuhlm\u00fcller", "N. Goodman"], "venue": null, "citeRegEx": "Ullman et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ullman et al\\.", "year": 2014}, {"title": "Galileo: Perceiving physical object properties by integrating a physics engine with deep learning", "author": ["J. Wu", "I. Yildirim", "J.J. Lim", "B. Freeman", "J. Tenenbaum"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Wu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 16, "context": "Physical reasoning is a crucial part of learning, perception, planning, inference, and understanding in artificial intelligence, and can be leveraged to accelerate the learning of new tasks (Lake et al., 2016).", "startOffset": 190, "endOffset": 209}, {"referenceID": 7, "context": "Accurately modeling a scene involves reasoning about the spatial properties, identities and locations of objects (Eslami et al., 2016; Hinton et al., 2011; Jaderberg et al., 2015; Kulkarni et al., 2015), but also their physical properties, future dynamics, and causal relationships.", "startOffset": 113, "endOffset": 202}, {"referenceID": 12, "context": "Accurately modeling a scene involves reasoning about the spatial properties, identities and locations of objects (Eslami et al., 2016; Hinton et al., 2011; Jaderberg et al., 2015; Kulkarni et al., 2015), but also their physical properties, future dynamics, and causal relationships.", "startOffset": 113, "endOffset": 202}, {"referenceID": 14, "context": "Accurately modeling a scene involves reasoning about the spatial properties, identities and locations of objects (Eslami et al., 2016; Hinton et al., 2011; Jaderberg et al., 2015; Kulkarni et al., 2015), but also their physical properties, future dynamics, and causal relationships.", "startOffset": 113, "endOffset": 202}, {"referenceID": 15, "context": "Accurately modeling a scene involves reasoning about the spatial properties, identities and locations of objects (Eslami et al., 2016; Hinton et al., 2011; Jaderberg et al., 2015; Kulkarni et al., 2015), but also their physical properties, future dynamics, and causal relationships.", "startOffset": 113, "endOffset": 202}, {"referenceID": 2, "context": "Such a sense of intuitive physics can be seen as a program (Anderson, 1990; Goodman and Tenenbaum, 2016) that takes input provided by a physical scene and the past states of objects, and outputs the future states and physical properties of relevant objects for a given task.", "startOffset": 59, "endOffset": 104}, {"referenceID": 11, "context": "Such a sense of intuitive physics can be seen as a program (Anderson, 1990; Goodman and Tenenbaum, 2016) that takes input provided by a physical scene and the past states of objects, and outputs the future states and physical properties of relevant objects for a given task.", "startOffset": 59, "endOffset": 104}, {"referenceID": 5, "context": "The top-down approach (Battaglia et al., 2013; Ullman et al., 2014; Wu et al., 2015) formulates the problem as inference over the parameters of a symbolic physics engine, while the bottom-up approach (Agrawal et al.", "startOffset": 22, "endOffset": 84}, {"referenceID": 28, "context": "The top-down approach (Battaglia et al., 2013; Ullman et al., 2014; Wu et al., 2015) formulates the problem as inference over the parameters of a symbolic physics engine, while the bottom-up approach (Agrawal et al.", "startOffset": 22, "endOffset": 84}, {"referenceID": 29, "context": "The top-down approach (Battaglia et al., 2013; Ullman et al., 2014; Wu et al., 2015) formulates the problem as inference over the parameters of a symbolic physics engine, while the bottom-up approach (Agrawal et al.", "startOffset": 22, "endOffset": 84}, {"referenceID": 0, "context": ", 2015) formulates the problem as inference over the parameters of a symbolic physics engine, while the bottom-up approach (Agrawal et al., 2016; Fragkiadaki et al., 2015; Lerer et al., 2016; Li et al., 2016; Mottaghi et al., 2015; 2016; Sutskever et al., 2009) learns to directly map physical observations to motion prediction or physical judgments.", "startOffset": 123, "endOffset": 261}, {"referenceID": 9, "context": ", 2015) formulates the problem as inference over the parameters of a symbolic physics engine, while the bottom-up approach (Agrawal et al., 2016; Fragkiadaki et al., 2015; Lerer et al., 2016; Li et al., 2016; Mottaghi et al., 2015; 2016; Sutskever et al., 2009) learns to directly map physical observations to motion prediction or physical judgments.", "startOffset": 123, "endOffset": 261}, {"referenceID": 18, "context": ", 2015) formulates the problem as inference over the parameters of a symbolic physics engine, while the bottom-up approach (Agrawal et al., 2016; Fragkiadaki et al., 2015; Lerer et al., 2016; Li et al., 2016; Mottaghi et al., 2015; 2016; Sutskever et al., 2009) learns to directly map physical observations to motion prediction or physical judgments.", "startOffset": 123, "endOffset": 261}, {"referenceID": 19, "context": ", 2015) formulates the problem as inference over the parameters of a symbolic physics engine, while the bottom-up approach (Agrawal et al., 2016; Fragkiadaki et al., 2015; Lerer et al., 2016; Li et al., 2016; Mottaghi et al., 2015; 2016; Sutskever et al., 2009) learns to directly map physical observations to motion prediction or physical judgments.", "startOffset": 123, "endOffset": 261}, {"referenceID": 20, "context": ", 2015) formulates the problem as inference over the parameters of a symbolic physics engine, while the bottom-up approach (Agrawal et al., 2016; Fragkiadaki et al., 2015; Lerer et al., 2016; Li et al., 2016; Mottaghi et al., 2015; 2016; Sutskever et al., 2009) learns to directly map physical observations to motion prediction or physical judgments.", "startOffset": 123, "endOffset": 261}, {"referenceID": 25, "context": ", 2015) formulates the problem as inference over the parameters of a symbolic physics engine, while the bottom-up approach (Agrawal et al., 2016; Fragkiadaki et al., 2015; Lerer et al., 2016; Li et al., 2016; Mottaghi et al., 2015; 2016; Sutskever et al., 2009) learns to directly map physical observations to motion prediction or physical judgments.", "startOffset": 123, "endOffset": 261}, {"referenceID": 29, "context": "For example, there is much work in object detection and segmentation for extracting position and velocity, as well as work for extracting latent object properties (Wu et al., 2015).", "startOffset": 163, "endOffset": 180}, {"referenceID": 16, "context": "Therefore this paper focuses on learning dynamics in that state space, taking a small step toward emulating a general-purpose physics engine (Lake et al., 2016), with the eventual goal of building a system that exhibits the compositionality, modularity, and generality of physics engine whose internal components can be learned through observation.", "startOffset": 141, "endOffset": 160}, {"referenceID": 12, "context": "This structure serves to guide learning towards object-based reasoning as (Hinton et al., 2011) does, and, by design, allows physical knowledge to transfer across variable number of objects and for object properties to be explicitly inferred.", "startOffset": 74, "endOffset": 95}, {"referenceID": 12, "context": "This structure serves to guide learning towards object-based reasoning as (Hinton et al., 2011) does, and, by design, allows physical knowledge to transfer across variable number of objects and for object properties to be explicitly inferred. This approach \u2013 starting with a general sketch of a program and filling in the specifics \u2013 is similar to ideas presented by Solar-Lezama (2008); Tenenbaum et al.", "startOffset": 75, "endOffset": 387}, {"referenceID": 12, "context": "This structure serves to guide learning towards object-based reasoning as (Hinton et al., 2011) does, and, by design, allows physical knowledge to transfer across variable number of objects and for object properties to be explicitly inferred. This approach \u2013 starting with a general sketch of a program and filling in the specifics \u2013 is similar to ideas presented by Solar-Lezama (2008); Tenenbaum et al. (2011). The NPE\u2019s general sketch is its architectural structure, and it extends and enriches this sketch to model the specifics of a particular scene by training on observed trajectories from that scene.", "startOffset": 75, "endOffset": 412}, {"referenceID": 9, "context": "First, because physics does not change across inertial frames, it suffices to separately predict the future state of each object conditioned on the past states of itself and the other objects in its neighborhood, similar to Fragkiadaki et al. (2015). Second, because physics is Markovian, this prediction need only be for the immediate next timestep.", "startOffset": 224, "endOffset": 250}, {"referenceID": 1, "context": "The NP is also a Markovian variant of the Social LSTM (Alahi et al., 2016); it sums the encodings of context objects after encoding each object independently, similar to the Social LSTM\u2019s \u201csocial pooling.", "startOffset": 54, "endOffset": 74}, {"referenceID": 13, "context": "LSTM Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997) have been shown to sequentially attend to objects (Eslami et al.", "startOffset": 44, "endOffset": 78}, {"referenceID": 7, "context": "LSTM Long Short-Term Memory (LSTM) networks (Hochreiter and Schmidhuber, 1997) have been shown to sequentially attend to objects (Eslami et al., 2016), so it is interesting to test whether a LSTM is well-suited for modeling object interactions, when the object states are explicitly given as input.", "startOffset": 129, "endOffset": 150}, {"referenceID": 22, "context": "From a cognitive science viewpoint, an LSTM can be interpreted as a serial mechanism in object tracking (Pylyshyn and Annan, 2006).", "startOffset": 104, "endOffset": 130}, {"referenceID": 27, "context": "We trained all models using the rmsprop Tieleman and Hinton (2012) backpropagation algorithm with a Euclidean loss for 1,200,000 iterations with a learning rate of 0.", "startOffset": 40, "endOffset": 67}, {"referenceID": 10, "context": "Bouncing balls have also been of interest in cognitive science to study causality and counterfactual reasoning, as in (Gerstenberg et al., 2012).", "startOffset": 118, "endOffset": 144}, {"referenceID": 4, "context": "This proposal is motivated by the experiments in Battaglia et al. (2013), which uses a probabilistic physics simulator to infer various properties of a scene configuration.", "startOffset": 49, "endOffset": 73}, {"referenceID": 5, "context": "A recent set of top-down approaches (Battaglia et al., 2013; Bates et al., 2015; Ullman et al., 2014) investigate probabilistic and deterministic (Wu et al.", "startOffset": 36, "endOffset": 101}, {"referenceID": 3, "context": "A recent set of top-down approaches (Battaglia et al., 2013; Bates et al., 2015; Ullman et al., 2014) investigate probabilistic and deterministic (Wu et al.", "startOffset": 36, "endOffset": 101}, {"referenceID": 28, "context": "A recent set of top-down approaches (Battaglia et al., 2013; Bates et al., 2015; Ullman et al., 2014) investigate probabilistic and deterministic (Wu et al.", "startOffset": 36, "endOffset": 101}, {"referenceID": 29, "context": ", 2014) investigate probabilistic and deterministic (Wu et al., 2015) game physics engines as computational models for physical simulation in humans.", "startOffset": 52, "endOffset": 69}, {"referenceID": 5, "context": "However, inverting a physics engine, as the Intuitive Physics Engine (IPE) (Battaglia et al., 2013) does, requires a full specification of the physical laws and object geometries.", "startOffset": 75, "endOffset": 99}, {"referenceID": 18, "context": "Bottom-up approaches have mapped visual observations to physical judgments (Lerer et al., 2016; Li et al., 2016; Mottaghi et al., 2015; 2016) or passive (Lerer et al.", "startOffset": 75, "endOffset": 141}, {"referenceID": 19, "context": "Bottom-up approaches have mapped visual observations to physical judgments (Lerer et al., 2016; Li et al., 2016; Mottaghi et al., 2015; 2016) or passive (Lerer et al.", "startOffset": 75, "endOffset": 141}, {"referenceID": 20, "context": "Bottom-up approaches have mapped visual observations to physical judgments (Lerer et al., 2016; Li et al., 2016; Mottaghi et al., 2015; 2016) or passive (Lerer et al.", "startOffset": 75, "endOffset": 141}, {"referenceID": 18, "context": ", 2015; 2016) or passive (Lerer et al., 2016; Srivastava et al., 2015; Sutskever et al., 2009) and action-conditioned (Agrawal et al.", "startOffset": 25, "endOffset": 94}, {"referenceID": 24, "context": ", 2015; 2016) or passive (Lerer et al., 2016; Srivastava et al., 2015; Sutskever et al., 2009) and action-conditioned (Agrawal et al.", "startOffset": 25, "endOffset": 94}, {"referenceID": 25, "context": ", 2015; 2016) or passive (Lerer et al., 2016; Srivastava et al., 2015; Sutskever et al., 2009) and action-conditioned (Agrawal et al.", "startOffset": 25, "endOffset": 94}, {"referenceID": 0, "context": ", 2009) and action-conditioned (Agrawal et al., 2016; Finn et al., 2016; Fragkiadaki et al., 2015) motion prediction.", "startOffset": 31, "endOffset": 98}, {"referenceID": 8, "context": ", 2009) and action-conditioned (Agrawal et al., 2016; Finn et al., 2016; Fragkiadaki et al., 2015) motion prediction.", "startOffset": 31, "endOffset": 98}, {"referenceID": 9, "context": ", 2009) and action-conditioned (Agrawal et al., 2016; Finn et al., 2016; Fragkiadaki et al., 2015) motion prediction.", "startOffset": 31, "endOffset": 98}, {"referenceID": 29, "context": "With the exception of works as (Wu et al., 2015), the bottom-up approaches mentioned above do not infer latent properties as our model does.", "startOffset": 31, "endOffset": 48}, {"referenceID": 18, "context": "Lerer et al. (2016) used a shared network for both predicting future frames and for making physical judgments.", "startOffset": 0, "endOffset": 20}, {"referenceID": 9, "context": "This assumption is also core to Fragkiadaki et al. (2015), which conditions motion prediction on individual objects rather than the entire scene.", "startOffset": 32, "endOffset": 58}, {"referenceID": 4, "context": "Recently, in work we only learned about after implementing our approach, Battaglia et al. (2016) in parallel and independently developed a similar architecture that they call Interaction Networks for learning to model physical systems.", "startOffset": 73, "endOffset": 97}], "year": 2016, "abstractText": "We present the Neural Physics Engine (NPE), an object-based neural network architecture for learning predictive models of intuitive physics. We propose a factorization of a physical scene into composable object-based representations and also the NPE architecture whose compositional structure factorizes object dynamics into pairwise interactions. Our approach draws on the strengths of both symbolic and neural approaches: like a symbolic physics engine, the NPE is endowed with generic notions of objects and their interactions, but as a neural network it can also be trained via stochastic gradient descent to adapt to specific object properties and dynamics of different worlds. We evaluate the efficacy of our approach on simple rigid body dynamics in two-dimensional worlds. By comparing to less structured architectures, we show that our model\u2019s compositional representation of the structure in physical interactions improves its ability to predict movement, generalize to different numbers of objects, and infer latent properties of objects such as mass.", "creator": "LaTeX with hyperref package"}}}