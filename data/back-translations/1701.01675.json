{"id": "1701.01675", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Nov-2016", "title": "Pareto Efficient Multi Objective Optimization for Local Tuning of Analogy Based Estimation", "abstract": "Analogy Based Effort Estimation (ABE) is one of the most well-known methods of estimating software expenditure. ABE's basic concept is closer to the mentality of expert estimation, but with an automated process in which the final estimate is generated by reusing similar historical projects. The main question when using ABE is how to adjust the effort of the retrieved nearest neighbors. The adaptation process is an essential part of ABE to generate a more successful accurate estimate based on the selected raw solutions, using some adaptation strategies. In this study we show that there are three interlinked decision variables that have a major impact on the success of the adaptation method: (1) number of nearest analogies (k), (2) optimal characteristics needed for the adaptation, and (3) adaptation weights. To find the right decision in relation to these variables, one has to study all possible pre-combinations and optimization measures to evaluate them individually.", "histories": [["v1", "Tue, 29 Nov 2016 15:57:20 GMT  (2096kb)", "http://arxiv.org/abs/1701.01675v1", null]], "reviews": [], "SUBJECTS": "cs.SE cs.AI", "authors": ["mohammad azzeh", "ali bou nassif", "shadi banitaan", "fadi almasalha"], "accepted": false, "id": "1701.01675"}, "pdf": {"name": "1701.01675.pdf", "metadata": {"source": "CRF", "title": "Pareto Efficient Multi Objective Optimization for Local Tuning of Analogy Based Estimation", "authors": ["Mohammad Azzeh"], "emails": ["m.y.azzeh@asu.edu.jo", "abounassif@ieee.org", "banitash@udmercy.edu", "f_masalha@asu.edu.jo"], "sections": [{"heading": null, "text": "concept of ABE is closer to the mentality of expert estimation but with an automated procedure in which the final estimate is generated by reusing similar historical projects. The main key issue when using ABE is how to adapt the effort of the retrieved nearest neighbors. The adaptation process is an essential part of ABE to generate more successful accurate estimation based on tuning the selected raw solutions, using some adaptation strategy. In this study we show that there are three interrelated decision variables that have great impact on the success of adaptation method: (1) number of nearest analogies (k), (2) optimum feature set needed for adaptation, and (3) adaptation weights. To find the right decision regarding these variables, one need to study all possible combinations and evaluate them individually to select the one that can improve all prediction evaluation measures. The existing evaluation measures usually behave differently, presenting sometimes opposite trends in evaluating prediction methods. This means that changing one decision variable could improve one evaluation measure while it is decreasing the others. Therefore, the main theme of this research is how to come up with best decision variables that improve adaptation strategy and thus, the overall evaluation measures without degrading the others. The impact of these decisions together has not been investigated before, therefore we propose to view the building of adaptation procedure as a multi-objective optimization problem. The Particle Swarm Optimization Algorithm (PSO) is utilized to find the optimum solutions for such decision variables based on optimizing multiple evaluation measures. We evaluated the proposed approaches over 15 datasets and using 4 evaluation measures. After extensive experimentation we found that: (1) predictive performance of ABE has noticeably been improved, (2) optimizing all decision variables together is more efficient than ignoring any one of them. (3) Optimizing decision variables for each project individually yield better accuracy than optimizing them for the whole dataset.\nKeywords: Analogy Based Effort Estimation, Adaptation Strategy, Particle Swarm Optimization, Multi-Objective Optimization."}, {"heading": "1. Introduction", "text": "One of the key challenges in software industry is how to obtain the accurate estimation of the development effort, which is particularly important for risk evaluation, resource scheduling as well as progress monitoring [3][15][28]. This importance is clearly portrayed through proposing a vast variety of estimation models in the past years [47]. Inaccuracies in estimations lead to problematic results for both software industry and customers. In one hand the underestimation results in approval of projects that will exceed their planned budgets, while on the other hand the overestimation causes waste of resources and misses opportunities to offer funds for other projects in future [31]. Software effort estimation has been extensively studied in literature since 70\u2019s but they have suffered from common problems such as very large performance deviations as well as being highly dataset dependent [15]. These models can be classified into two main categories: a) Expert Judgment, and b) Learning Oriented models. The former proposes making use of the experiences of human experts whereas, the latter usually generates estimates based on learning methods. The latter has two distinct advantages over the former such that they have capability to model complex set of relationships between dependent variable and the independent variables, and they are capable to learn from historical project data [2][27].\nIn the recent years, a significant research effort was put into utilizing various machine learning (ML) algorithms as a complementary or as a replacement to previous methods [14][17][25][31]. Although they generate successful results in certain datasets, ML algorithms suffered from local tuning problems when they\nwere to be applied in another settings, i.e. they need to be tuned to local data for high accuracy values[15][33]. ML methods have an extremely large space of configuration possibilities [15][42][43]. When we consider configuration possibilities of ML methods induced on different datasets, each method has its own characteristics, so it is not a surprise to see contradictory results [6][9][30][35]. Finding the best estimation model was under a thorough investigation of many comparative studies that attempted to rank and categorize those models based on the quality of estimates they produce [25][27]. Unfortunately, there are no consensus conclusions between these studies on which technique is the best. The most factors that contradict their findings seem to be the error measures [25], datasets preprocessing and their inherent characteristics [3], and finally, the experimental methodology [15].\nThis paper focuses mainly on Analogy-Based Estimation method (hereafter ABE). The idea behind ABE method is rather simple such that a new project\u2019s effort can be estimated by reusing project efforts about similar, already documented projects in a dataset, where in the first step, one has to identify the projects which contain the most similar features. Since the utility of a project cannot be evaluated directly, similarity between project descriptions is used as a heuristic approach to retrieve the projects\u2019 effort [22]. We study ABE for several reasons: a) it reflects human reasoning, b) it works with spare data and complex domains, and c) it provides reasoning in a domain with a small body of knowledge [34]. Previous research has reported that ABE is able to produce more successful results in comparison to traditional regression based methods [3][22]. ABE has been favored over other methods when the dataset contains discontinuities [11]. However, it was remarked that ABE method is subject to a variety of decisions that have a strong impact on its predictive performance. Such decisions include selection of features and/or instances, deciding on the number of analogies to be used and the adaptation strategy [15][19]. Kocaguneli et al. [15] stated that using different solutions for each parameter produce different ABE configuration, hence, different ABE models. Therefore, there is a reasonable belief that choosing the right ABE model is not an easy process. One option is to study the characteristics of a dataset and come up with the suitable choice for each decision. We can reach to more manageable set of ABE models if researchers critically review the space of options for their models.\nIndeed, there is a direct evidence that the choice of right adaptation method has a big influence on the accuracy of ABE as confirmed in [3][13]. Basically, the adaptation method of ABE is composed of three interrelated decision variables: (1) number of nearest analogies, (2) nominated set of features and (3) adaptation strategy weights. The purpose of this process is to generate more accurate estimates and minimize the difference between the estimated effort and actual effort. The original ABE method [22], that is denoted as ABE0, does not use any kind of adaptation strategy, but it uses the mean of k nearest neighbors\u2019 efforts. The k value here is determined manually by an expert for which the overall performance of the whole dataset is improved, but not necessarily the best performance for each individual project. The key challenge here is that the experts tend to find the optimum k value based on minimizing one evaluation measure ignoring other evaluation measures, whereas the final model is evaluated using multiple evaluation measures. Previous studies showed that applying different evaluation measures tend to behave differently in identifying best model [32], therefore finding these decisions should be based on improving all evaluation measures simultaneously. Moreover, the improved ABE models that use adaptation strategy such as regression towards the mean [10], genetics algorithm [5] and neural networks [17] still fail in specifying the appropriate number of the nearest analogies and do not take other decisions in their adaption process.\nAbove all, we believe that finding the right decisions for the ABE adaptation method is a multi-objectives optimization problem. Therefore, in the present study we use Multi-Objective Particle Swarm Optimization (MOPSO) algorithm to tune and adapt ABE. The PSO is a relatively the most common used optimization method among researchers. It has been proposed by Kennedy and Eberhart [39] to perform combination of random and neighborhood search. It mimics the process of birds in searching for foods, further details about PSO can be found in Section 3. However, the conventional PSO can deal with problems that have only one objective function, but when the problem has many conflicting objectives as in our study we should use the extended version of PSO that can support multi-objective functions which is called multi-objective Particle Swarm Optimization (MOPSO) [37][40]. The goal of MOPSO is to find a set of solutions (called Pareto front) that improves the performance of two or more objective functions possibly subject to some constraints on the independent variable ranges. The objective functions used in this study are the evaluation measures such as Standardized Accuracy (SA), Mean Inverse Balanced Relative Error (MIBRE), and Mean Balanced Relative\nError (MBRE). Since these measures tend to behave differently [32], the final outcome of MOPSO is not a single solution but a set of solutions that make a good trade-off between these objective functions. In this study, each possible solution is composed of three variables: (1) number of nearest analogies (k), (2) set of nominated features and (3) adaptation strategy weights.\nThis paper is an extension to our previous works on using optimization for ABE adaptation [44]. In that work we only evaluated the local tuning on adjusting ABE without studying the impact of features and their optimized weight. Bearing that in mind, this paper aims at answering the following research questions: -RQ1. Is there sufficient evidence that the MOPSO algorithm can find the best k value for each project individually? -RQ2. Is there significant difference between Local adaptation and Global adaptation and which of them can improve overall performance for one project? Local adaptation means finding for each project the appropriate decisions that improve its individual accuracy, whereas Global adaptation means finding one common decision for all projects that improve accuracy for the whole dataset on average. Previous studies suggest that adapting each project individually with its own decisions tend to be more accurate than adapting whole dataset with the same decision vector [29]. -RQ3. Does the use of all features within the proposed adaptation strategy have rooms for further improvement rather than using optimized features set? -RQ4. Does the use of equal weights produce more accurate results than the optimized weights in the adaption strategy? The paper is structured as follows: Section 2 introduces an overview to ABE and adaptation methods. Section 3 presents the problem, where Section 4 introduces the objective functions and evaluation measures that will be used during optimization process. Section 5 introduces the MOPSO and its fundamental concepts. Section 6 presents the research methodology. Section 7 shows the descriptions of all datasets used in this study. Section 8 presents experimental setup. Sections 9, 10, 11 and 12 present answers to RQ1, RQ2, RQ3 and RQ4, respectively. Section 13 shows further analysis and comparisons between the proposed adaptation strategy and other adaptation methods. Finally, the paper ends with Section 14 which summarizes our work and outlines main conclusions."}, {"heading": "2. Background & Related Work", "text": "ABE generates a new estimation based on assumption that similar projects with respect to features description have similar efforts [22]. The basic procedure of the ABE method is illustrated in Figure 1 where in the first step the training projects are preprocessed which includes data scaling, handling missing values and performing feature selection if necessary. The second step is to define a new project to be estimated. Then retrieve the similar projects that have been encountered and remembered as successful historical projects using a similarity measure such as Euclidean distance as shown in Eq. 1. Finally, the retrieved solutions are adapted and calibrated to minimize difference with the new project. We refer to the baseline ABE method that does not include adaptation as ABE0.\n   m c jcic )pp(cetandis 1 2 (1)\nwhere m is the number of features, ip and jp are projects under investigation:\nThis paper focuses mainly on the adaptation process which is known as local tuning of ABE method. To address the local tuning problems of ABE method, we have to better understand the relationship among three interrelated key factors of any successful adaptation method. These factors are: a) optimum features set, b) number of nearest analogies (k) and c) The weighting schema used in adaptation. By combining these factors together, we can easily find over thousands of different adaptation models. To select the right model, one has to try many options from the large space of configuration possibilities and then choose what performs better on the local data. This process is daunting and time consuming and hardly to be completed due to the diverse behavior of evaluation measures. Therefore, we suggest to treat this problem as multi-objective optimization problem in which the best solution can be found after searching on a large space of available solutions. We believe that the best solution should make trade-off between various evaluation measures since changing the value of any decision variable tends to behave diversely. Researchers when encounter the literature, they can find many studies that handle this problem but separately, in other words, some studies focus on the problem of predicting the best k number of nearest analogies, while others focus on the weighting methods of adaptations. So we cannot find any study that treat all three interrelated decision variables together in one model.\nThe use of adaptation strategy with ABE has seen significant improvements in terms of accuracy and reliability. Adaptation is a process that attempts to minimize the difference between test observation and each nearest observation and reflects that difference on the derived solution in order to obtain better accuracy. Then all adapted solutions are aggregated using either simple statistical approach such as mean, median or Inverse Ranked Weighted Mean (IRWM) as shown in Eq. (1) and (2), or by more sophisticated approaches such as machine learning algorithms.\n  k i it e\nk e\n1 \u02c6\n1 (1)\n \n\n\n\n \n k\ni\nk\ni ii t\ni\nerk e\n1\n1 \u02c61\n(2)\nWhere te is the new estimated effort and ie\u0302 is the adapted effort of the nearest ith analogy. Before we start reviewing the existing adjustment method we should first mention the basic approach of null EBA adjustment which is based on finding the average of efforts for the nearest k projects. In late 1990s, Walkerden and Jeffery [24] introduced the first adjustment method called Linear Size Extrapolation (LSE). This method aims to calibrate the effort of a new project by making extrapolation between the size of the new project and the size of the nearest project. The principal reason of using only size feature was twofold: (1) it carries useful information about the project such as the amount of software functionality, (2) it has strong statistical significant correlation with project effort. Although the predictive performance of this method was notably superior to null adjustment over very limited number of datasets, there was criticism about the performance of this approach since not all datasets present strong correlation between effort and size feature. Thus, the prediction obtained will possibly be far from optimum. Furthermore, some datasets are described\nwith number of different size features as in the case of web projects, therefore using only one size feature is not entirely reasonable.\nBased on the above limitations, Kirsopp et al. [12] extended Walkerden and Jeffery method to include all size related features. This method is called thereafter Multiple Linear Feature Extrapolation (MLFE). The performance of MLFE has been reported in the study conducted by Mendes et al. [19] based on a dataset collected from web projects. Unfortunately, the replication study on adjustment methods [3] revealed that MLFE is still less useful than LSE under certain experimental conditions. The certain limitations of this approach are: it does not support categorical features and may not work well when any used historical feature contains zero as a denominator, which leads to infinity. The classical solution conducted is to ignore features with zero values.\nOn the other hand, an investigation analysis of many software projects reveals that expert judgment approach is considerably \u201cproductivity based adjustment\u201d. In this context, Jorgensen et al. [10] proposed a different method called Regression Towards the Mean (RTM) to adjust and calibrate nearest projects based on the notion of project productivity. This method assumes that if the nearest projects have extreme productivity values, then the productivity value of the project under estimation should be tuned to bring it closer to the average projects\u2019 productivity values in the dataset. Jorgensen et al. [10] remarked that the productivity distribution of estimated projects are narrower than that of actual projects which proves that the estimated efforts regress towards the mean effort in a particular dataset. Shepperd and Cartwright [23] replicated the work of Jorgensen et al. [10] and advised that the dataset should be partitioned into groups of homogeneous projects so that the adjustment moves to a local productivity mean. Through evaluation of some datasets, there was significant improvement on the accuracy when RTM method is applied.\nIndeed, all previous adjustment methods rely primarily on the project size in order to adjust and calibrate new projects. However, this is not the only solution existing in literature. Li et al. [16] demonstrate that the similarity degree between projects can play important role in adjusting selected projects. Similarity based adjustment appears as a well suited method because it reflects the amount of differences between new project and its nearest analogies on the predicted effort. However, similarity measure can be divided into two levels: local measure and global measure. Local similarity measure is used to find out the similarity degree between two projects with respect to a particular feature where Global similarity measure is used to aggregate all local similarity values. In this approach, the local similarity degrees or global similarity degrees can be used to adjust the selected project by applying sum of product of the normalized similarity and effort. The main advantage of this approach is that it supports both categorical and continuous features.\nPrevious analysis studies report that software datasets are characteristically noisy with complex structure [29]. Therefore the statistical methods cannot learn the differences from the structure of selected projects. Genetic algorithm is used as potential solution to minimize differences between the target project and selected projects. Genetic Algorithm (GA) is a search heuristic method that simulates the natural evolution process. It is widely used in software engineering to solve complex problems such as those encountered in testing and management. A typical example on this approach is the work of Chiu and Heung [5] who used GA to calibrate selected projects based on learning distances between them and reflect that difference on the predicted effort. The adjustment function uses GA to find the optimized value for the adjustment coefficient j based on minimizing one of error measure. The main challenge when using GA is that it needs careful setup for its parameters such as specifying how to encode chromosome, how to perform mutation and crossover, and so forth.\nLikewise, Azzeh [2] used Model Tree to adjust and tune selected projects. Model Tree is a type of decision tree model designed for non-linear regression, where the leave nodes have regression functions instead of numerical values. This adjustment method consists of two stages: Learning and prediction. During the learning phase, the differences between each historical project and its nearest project in the training dataset are computed across all features including efforts. These differences are then used to construct a Model Tree where differences in effort values are considered the output, and differences with respect to features are considered inputs. During the prediction phase, the nearest project to the new project is identified, then differences between them across all features are entered to the constructed Model Tree in order to compute the possible difference in the effort. This amount of difference is then added to selected effort to produce\nhopefully better estimate.\nOn the other hand, Li at al. [17] raised an important concern regarding structure of datasets as they claim that most software cost estimation datasets do not follow uniform distribution as presumed in linear methods. They used artificial neural networks, specifically Multilayer Perceptron, to learn difference in effort from differences in other features. The neurons are arranged in layers where the input data (i.e. feature distances between each source project and its analogy in the same historical dataset) are fed to the network at the input layer. The data then passes through hidden and output layers to produce the solution for a given problem. The solution here is the distance between projects effort. The learned differences are then added to the selected effort. The findings from the Li et al study are promising, but the replication study conducted by Azzeh [3] reported discouraging results where some linear adjustment methods produced more accurate results than neural networks. One possible explanation for these contradictory results is the fact that Multilayer Perceptron can be very sensitive to parameters choice in software effort estimation. So, they can perform very differently depending on the parameters choice.\nFrom these adaptation methods, we can notice that there is no consensus regarding the use of features. Each method uses different set of features, for example: LSE used only the size feature, MLFE used a set of size features, RTM used size and effort features, GA and NN used all features. Likewise, there is no consensus regarding the best number of nearest analogies (k). In recent years, various approaches have been proposed to specify this number such as k nearest neighbor algorithms and similarity cut off point [16][22]. Some studies favor using a pre-determined number of analogies in software effort estimation studies such as k=1, 2\u2026 n-1 [1][2][11][15][19][24]. In this approach, the practitioner starts with k=1 and increase this number until no further improvement on the accuracy can be achieved. Examples on this approach are the studies made by Lipowezky et al. [18] and Walkerden and Jeffery [24] who found k=1 was the most optimum number. Mendes el al. [19] used k = 1, 2, 3 as optimum numbers. Lipowezky et al. [18] proposes a policy that looks for only one prototype, which can be regarded as extreme when dealing with datasets as small as those in software effort estimation. Furthermore, we would like to base our estimations on some sample set of past data, not only on one record, since only one record may be misleading in small and heterogeneous datasets. On the other hand, Azzeh [3] conducted an extensive replication study on various linear and non-linear adaptation strategies using many public datasets, and found that that k=1 was the most prominent number across all experimentations. Kirsopp et al. [12] on the other hand proposes making predictions from the 2 nearest cases as it was found as the optimum value for the datasets of their study. In a further study Kirsopp et al. [19] have increased their accuracy values with case and feature subset selection strategies.\nBesides this approach, other researchers attempted to dynamically find the optimum number of nearest analogies such as [16] and [29]. Li et al. [16] proposed a method to learn the k number based by optimizing similarity threshold. They conducted extensive experimentation on actual and artificial datasets and observed various effects of k values. Azzeh and Elsheikh [29] utilized bisecting k-medoid clustering to understand the structure of certain dataset and come up with best number of analogies for each test project individually. This method is somehow different than other methods because the authors proposed to make dynamic selection for each test instance in the dataset rather than using fixed k values for the whole dataset. The results obtained from this study were promising and still needs further development. Above all, we still believe that the best k number can be found through optimization algorithm which forms motivation for this research.\nAbove all, the results from adaptation studies are usually controversial and cannot be generalized since there are many uncontrollable sources of variations between these studies. In spite of their good performance for ABE method, most adaptation methods are still long way from reaching the real optimal solutions. This can be observed from the inconsistent behavior of such methods. In other words, they perform well in most cases over specific datasets and worse for the remaining. Some of them focus on one side of the problem ignoring the other sides which make producing high accuracy is relatively impossible. A challenging approach to address this issue is to study the impact of dataset characteristics in further details and the relevant of adaptation for each dataset. Therefore, to better understand the problem of adaptation, taking into consideration all sides of the problem, we propose to use multi-objective optimization to make better adaptation for the retrieved analogies. The main theme of this research is not only running individual studies but developing a better understanding of how beneficial is the proposed approach for software industry and at the very end consolidating a body of knowledge. It also allows us to derive lessons from using these\ntechniques for better model performance. If the results are compatible, they can be considered additive, increasing confidence in the original hypothesis."}, {"heading": "3. Problem Representation", "text": "This section describes the proposed adaptation strategy that is used to tune and adapt nearest analogies. The proposed function of ABE adaptation is illustrated in Eq. 3 and 4. The functions are composed of three decision variables: 1) number of nearest analogies (k), 2) feature distance weights (w) and 3) feature set (v). Eq."}, {"heading": "3 shows how each project is tuned whereas Eq. 4 is used to aggregate the adapted projects\u2019 efforts using", "text": "Ordered Weighted Mean (OWM). In OWM, a method with rank (k-i+1) gets a weight  \n\n\n  \n\n\n\n12\n2 1\nk\ni\n, as shown in Eq. 4\nwhere k is the number of nearest analogies and i is the rank of a nearest project. For example, using 3 projects, one might give weight (4/7) for the top ranked project ( 1e\u0302 ), (2/7) for the next one ( 2e\u0302 ) and (1/7) for the 3rd project ( 3e\u0302 )\nso Eq. 4 would appear as follows:        3 7 1 2 7 2 1 7 4 e\u0302e\u0302e\u0302te .\n   m j ijtjjjii ffvw\nm ee\n1 )-(\n1 \u02c6 (3)\n   \n\n\n  \n\n\n  1 1\n12\n12\nki ik e\u0302\nk\ni\nte (4)\nWhere ie is the effort of the nearest ith analogy. Based on the above assumption, each possible solution ( x  ) in the search space is represented as a vector of three decision variables as shown in Eq. 5.\nw,v,kx  \n(5)\nWhere k is the value that represents the number of nearest analogies which should be bounded by minimum of 1 and maximum of the size of training projects (i.e.  nk ,1 where n is the number of training projects). v is a binary vector whose coordinate represent the presence or absence of feature in the adaptation function. For simplicity use with MOPSO, we use v as integer number instead of set of binary values and then we convert that value into its corresponding binary numbers when it is applied to Eq. 3. So the possible range for v as integer would lie between 1 and 2m-1 where m is the maximum number of features in the training dataset. w is a dynamic matrix of size (n \u00d7 m) as shown in Figure 2, which contains the possible weights to tune feature distance as depicted in Eq. 3. Each possible weight would take value between zero and one (i.e.  1,0ijw )\nand the summation of weight values along a particular row should equal 1 as shown in Eq. 6.\nTo illustrate that, consider the following hypothetical solution vector wx ,15,4  and assume n=5, m=6. The w\nmatrix is given in Figure 3. This solution vector shows that only 4 nearest analogies are considered in Eq. 4, the possible feature set after converting v to binary number is {0, 0, 1, 1, 1, 1} which means that all features are included except the first two features in the training dataset. It is important to note that the number of bits equals to m and the first position from the left is the first feature in training dataset."}, {"heading": "4. Objective functions", "text": "This section describes the evaluation measures that will act as objective functions during optimization process and be used later to evaluate the software effort estimation models. Evaluation measures typically comment on the success of a prediction model. The cornerstone of the evaluation measures is the absolute error (AE) between the actual effort of a particular project ( ie ) and the predicted effort of that project ( ie ) as shown in Eq. 7. This measure should be as small as possible because large deviation will have opposite effect on the development progress of the new software project.\niii eeAE  (7)\nBased on this key measure the researchers found a lot of evaluation measures that can work well in evaluating effort prediction models such as Magnitude Relative Error (MRE) and their aggregated forms such as Mean Magnitude Relative Error (MMRE) and Median Magnitude Relative Error (MdMRE). Recent studies arise important concerns about using MRE because it is unbalanced and yields asymmetry distribution [6][21][30]. Therefore it is not always reliable to use MRE and their derived measures to compare between prediction models or to evaluate a single model.\nIn this paper we used the Standardized Accuracy (SA) measure that has been proposed by Shepperd and MacDonell [30] as shown in Eq. 8 which is based on Mean Absolute Error (MAE) because it is not a ratio and it does not present asymmetric distribution as in MMRE. The SA is mainly used to test whether the prediction model in hand really outperforms a baseline of random guessing and generates meaningful predictions. So, the SA is important to test the reliability of the prediction model because it can be interpreted as the ratio of how much better a given model is than random guessing, giving a very good idea of how well the approach\ndoes. The Mean Absolute Error of random guessing ( opMAE ) is obtained as the mean value of a large number runs of random guessing. This is defined as, predict a ie for the target case i by randomly sampling (with equal probability) over all the remaining n - 1 cases and take ri ee  where r is drawn randomly from 1\u2026n  r \u2260 i. This randomization procedure is robust since it makes no assumptions and requires no knowledge concerning population.\nopMAE\nMAE SA  1 (8)\nIn addition to the above mentioned evaluation measures, we used other three reliable evaluation measures mentioned in literature that are considerably less vulnerable to bias or asymmetry distribution as in case of MMRE [31][32]. These measures are Balanced Relative error (BRE) and the Inverted Balanced Relative Error (IBRE) and their average measures mean of BRE (MBRE) and the mean of IBRE (MIBRE) as shown in Eqs. 9, 10, 11, and 12 respectively.\n)e,emin(\nAE BRE\nii\ni i  (9)\n)e,emax(\nAE IBRE\nii\ni i  (10)\n  n i i\nBRE n MBRE 1\n1 (11)\n  n i i\nIBRE n MIBRE 1\n1 (12)\nWhere n is the number of projects in the dataset.\nAll evaluation measures are objectives to be minimized except SA which is to be maximized. These measures were chosen because, even though all of them were initially designed to represent how well a model performs, they can behave very differently from each other as reported in [32]. This allows us to select as many as possible good solutions that can make trade-off between these measures."}, {"heading": "5. Multi-Objective Particle-Swarm Optimization algorithm", "text": "5.1 Basic Concepts Optimization algorithm is a typical solution for the sophisticated problems that have many interrelated design options as encountered in software engineering tasks [5][32]. The problem of optimization can be defined as follows: Given a function Xf : from some set of decision vectors (X) to the set of real numbers ( ), the aim is to find a solution ox  in X such that the objective function is either minimized (\nXinxxfxf o   ),()( ) or maximized ( Xinxxfxf o   ),()( ), where each solution x  can be defined as vector of\ndecision variables in the m-dimensional space as shown in Eq. 13.\n Tsx,,x,xx   21 (13)\nMany problems can be solved based on optimizing a single objective function, but when the problem has many objectives and these objectives are in conflict with each other, we come to situation that there is no single solution but instead there is a good trade-off solutions that represent best compromises among the objectives. The problem of ABE adaptation procedure can be viewed as multi-objective optimization algorithm which contains many interrelated decisions that need to be optimized based on finding trade-off between evaluation measures. As there are many optimization algorithms in literature, we chose Particle Swarm Optimization (PSO) for two reasons: (1) The algorithm is simple and its implementation is straightforward, (2) it showed good performance against some well-known evolutionary algorithms such as Genetics algorithm and Simulated Annealing [36][37]. In the next sections we provide an introduction to PSO algorithm and its application to multi-objectives problems.\n5.2 Particle Swarm Optimization\nThe PSO is a population based heuristic search algorithm which simulates the movements of a flock of birds to find food. It was first developed in 1995 by Kennedy and Eberhart [39]. Basically, the algorithm performs a kind of local and global search combined with random search. This algorithm was originally proposed for balancing weights in neural networks, then soon later became one of the best optimization algorithms. The popularity of PSO stems from its simplicity in performing search and especially global search since it does not need many operators for creating new solution as in evolutionary algorithms, so its implementation is straightforward [37]. But on the other hand, this algorithm suffers from two main problems: 1) slow convergence in refined search stage, and 2) Weak local search ability [40]. These two problems are handled when using different search topology as mentioned later in this section. Before we demonstrate how PSO works we list the key concepts of PSO in Table 1.\nThe algorithm starts with population initialization of random solutions and velocities, and then searches for optima by updating the generations. Particles then fly through the problem space by following the current optimum Particles [39]. The position of a Particle is changed according to its own flying experience as well as the flying experience of neighbours. The pbest and gbest are updated accordingly. To illustrate that, consider that )(txi  is the position of the ith Particle at time t. The new position of that Particle is updated by adding the amount of velocity ( )t(Vi  ) on its previous position as shown in Eq. 14 and 15. Moreover, all particles in PSO are kept as members of the population through the course of the run [38].\n   )t(xxrC)t(xxrC)t(VW)t(V ijleaderijpbestijij i   22111 (14)\n)t(V)t(x)t(x ijijij   1 (15)\nWhere 1r and 2r are random values [0, 1], j represents the index of the decision variable in )(txi  .\nIt is interesting to note that a large inertia weight (W) facilitates a global search while a small inertia weight facilitates a local search [39]. By linearly decreasing the inertia weight from a relatively large value to a small value through the course of the PSO run gives the best PSO performance compared with fixed inertia weight settings. The success of Particle move depends on the success of the other connected particles which are not necessarily be the Particles that are close to each other, but instead the Particles that are close to each other based on the neighborhood topology that defines the swarm structure. Particles can be connected to each other by different topologies represented as a graph, typical examples on PSO topologies include: 1) Empty graph, 2) Local Best, 3) Fully connected Graph, 4) Star network, and 5) Tree network. Each one of these topologies has different implementation and considerations and thus leads to different performance. Fully Connected graph is the widely used topology because it allows fast convergence than others.\nHowever, the classical PSO can deal efficiently when the problem has only one objective function, but when the problem has many conflicting objectives, we should use the extended version of PSO that can support multi-objective functions which is called multi-objective Particle Swarm Optimization (MOPSO) [40] as explained in the next section.\n5.3 Multi-Objective Particle Swarm Optimization (MOPSO)\nThe MOSPO [40] is concerned with the problems that consists of one or more decisions and have many objectives to be optimized simultaneously. The problem of multi-objective optimization can be defined as finding a vector of design options or decisions ( x  ) which will satisfy d inequality constraints (\n.,,2,1,0)( dixgi  ) and p equality constraints ( .,,2,1,0)( pixhi  ) and simultaneously optimizes a\nvector of M conflict objective functions as shown in Eq. 16. The constraints mentioned above define the feasible region which includes all the admissible solutions. The optimal solution is obtained as trade-off between two or more conflicting objectives which is called Pareto optimal solution. Below are some important definitions pertaining to the multi-objective optimization:\n )(,),(),()( 21 xfxfxfxf M     (16)\nDefinition 1 (Dominance): A solution mix   is strictly dominated by a solution mjx   ( ji xx    and ji xx   ) if and only if Mlxfxf jlil ,,2,1),()(    and Mlxfxf jlil ,,2,1),()(    . This concept can be easily\nextended to maximization problem.\nDefinition 2 (Non-Dominance): The solution mix   is called non-dominated solution, if none of the\nobjective functions can be strictly improved in value without degrading some of the other objective values. In other words, it is non-dominated if there does not exist another solution mjx   such that\njiandMlxfxf jlil  .,,2,1),()(    \nDefinition 3 (Pareto Optimal): We say that a solution mx *  is a Pareto optimal if it is non-dominated\nwith respect to the feasible region ( )\nDefinition 4 (Pareto Optimal set): a set X of non-dominated solutions is called Pareto Optimal set which is formally defined as: }|{ optimalParetoaisxx    Definition 5 (Pareto Front): is defined as }|)({   xxff m \nThe key question when extending the PSO to support Multi-Objective problems is how to find global best solution gbest that acts as a leader and guide for other Particles. The answer is very important because it affects both the convergence to the true Pareto front and a well-distributed front. Since there is no single best solution in Multi-Objective problems, the non-dominated solutions found by MOPSO are often stored in a special repository where each Particle can select randomly a non-dominated solution from that repository to act as global guide for its new Position. In spite of its simplicity, it cannot promote convergence. In this research, we used the more efficient MOPSO algorithm based on Crowding Distance (MOPSO-CD) [40]. The crowding distance factor (CD) gives an estimate of the density of solutions surrounding a non-dominated solution and show how much a non-dominated solution is crowded with other solutions. So instead of randomly selecting gbest from the whole solutions in the repository, it is randomly selected from the top 10% less crowded area of the repository for each Particle that is dominated by any solution located in this area [40] [41].\nFigure 4 describes the algorithm of complete MOPSO-CD. At the first step, the swarm is randomly initialized with a predefined number of Particles and its initial velocities. In this step, the content of each Particle is generated randomly and the initial velocities are preferably set to zero. Also, the pbest of each particle is set to its initial position. This step is fully described in Figure 6. In the second step, The fitness of all Particles in the swarm are evaluated based on their current position. The non-dominated Particles are then selected and stored in a special repository (A) [41]. In each iteration the repository is updated and new nondominated Particles are added. The Particles in the repository are then evaluted against the new added Particles and the dominated ones are deleted. It is important to note that the capacity of the repository is limited so when the number of non-dominated Particles exceeds maximum capacity then it is reduced based on applying CD factor. The CD is calculated for non-dominated solution by first sorting the solutions in ascending order according to each objective function [41]. For each objective function, the crowding distance for each Particle is calculated by finding the distance of its neighbors as shown in Eq 17. The CD factor of first and last solution is usually equal to the maximum distance [41]. The final CD for each Particle is the sum of CDs along all objective functions. Figure 5 describes the pesudo code of obtaining CD factors.\n11   iii ffCD (17)\nThe Particles with less crowded spaces are kept whereas the Particles with smallest CD factors are strictly deleted. Likewise, the value of pbest solution for each Particle is examined against current solution and the new pbest is determined based on one of three ways [40]: 1) if the pbest is dominated by current solution then the current solution is the new pbest for that Particle. 2) if the current solution is dominated by pbest then nothing changed, 3) Otherwise, one of them is selected by random as pbest. Meanwhile, the velocity of each particle is updated by using Eq. 14. It is interesting to note that the gbest in MOSPOS-CD represents a solution that is being randomly selected form the repository with less 10% crowded solutions. The new position of each Particle is updated using Eq. 15, but every time the solution is being updated the boundary values of each dimension variable in the solution is checked and adapted as shown in Algorithm 4. The above procedure is repeated until the maximum number of iterations (T) is complete.\nDuring the update of Particles, it is important to mutate the current solution [41]. The mutation procedure is a crucial task in MOPSO to prevent premature convergence due to existing local Pareto fronts in some optimization problems. The mutation procedure used here is straightforward which adjust the position of a Particle by either adding or subtracting a specific value (y) depending on both the current iteration and either\nUpper Bound value (UB) and lower bound value (LB) of each dimension in the solution space as shown in Eqs. 18 and 19.\n1: 2: 3: 4: 5: 6: 7: 8: S GetNumberOfNon-dominatedSol(A) for i=0 to S 0cetandis.xi end for for each Objective function M A sort(A, M) for i=1 to n-1\n MiMiii f.xf.xcetandis.xcetandis.x 11  \n9: 10: 11:\nend for max MS fcetandis.xcetandis.x 0\nend for each\nWhere:\n R is a randomly generated bit (zero and one both have a 50% probability of being generated)  t is the current iteration number  r is a random number generated from a uniform distribution in the range [0,1]  b is a tunable parameter that defines the non-uniformity level of the operator. In this approach, the b"}, {"heading": "6. Methodology", "text": ""}, {"heading": "6.1 Using The Solutions Produced By MOPSO-CD in", "text": "The solutions generated by MOPSO-CD are used in the adaptation strategy of ABE in two ways: Local tuning and global tuning as will be discussed in section 6.2. These solutions are considered the best-fit Pareto solutions with the best train MIBRE, best train MBRE and best train SA. In order to show how the MOPSO-CD algorithm works with ABE we first start with describing the process of initialization as shown in Figure 6. The pseudo code shown how the Particles are initialized with their initial velocity. As we have seen earlier that each Particle represent potential solution which is composed of three variables: k, v and w. Each Particles is initialized with random values for each variable. For example the value of k can take integer number between 1 and n-1 where n is the number of projects in the dataset. The value of v is also initialized with random integer number between 1 and 2m-1. The value of v is converted into binary number during the main run to represent the presence or absence of features in the adaptation process. Finally, the matrix w is initialized with random numbers between 0 and 1 bearing in mind that the summation of each row vector must equal one. The initial velocity for each Particle is also initialized with value 0.\nWhen Particles fly to find better solutions the velocity and position of the Particle is updated based on its experience and that of neighborhoods [37]. The Pseudo code in Figure 7 shows how each particle is updated in this work according to Eq. 14. Recent research papers demonstrates that the velocity usually tends to exceed to a large value, which results in solutions go beyond the boundaries of the search space. This is more likely to happen when a solution is far from gbest and lbest. The typical solution is to truncate the location at the exceeded boundary at this iteration and reflect the velocity in the boundary so that the particle moves away at the next generation [38]. This technique does not necessarily alter the direction of Particle, but permitting the particle to stay in the vicinity of the boundary [38]. However, it does limit the solution step size, thereby preventing further divergence of solutions and permits the Particle to remain close to the\nboundaries during the search process. To make x feasible, the solution is dragged back along its line of movement until it reaches the nearest boundary."}, {"heading": "6.2 Local Tuning Vs. Global Tuning", "text": "The solutions produced by MOPSO-CD are used for ABE in two ways: Local tuning (LT) and Global tuning (GT). The main difference between them is that in LT each project is tuned solely with its own solution vector, i.e. with its own k value, features set and weight values. Whereas in GT all projects in the dataset share the same optimum solution. During both procedures, the goal is to increase accuracy and decrease error rate. One point that needs clarification at this stage is how to use the objective functions in both types of tuning. Since applying evaluation measures for one project is totally different than evaluating the whole dataset, for example, we cannot apply SA evaluation measure on single project because it needs the average of absolute errors for all projects. Therefore, we made a little modification on the type of accuracy used in both tuning ways. During LT the optimum solution is optimized based on minimizing AE, BRE, IBRE after running MOPSO-CD for each project individually. In this case, when a particular project comes to be predicted, the MOPSO-CD is invoked to come up with optimum solution for that project bearing in mind to minimize AE, BRE, IBRE evaluation measures. So for n projects the MOPSO-CD is invoked n times. The final outcome of this process is Pareto front solutions for each project in the dataset. This tends to improve mainly the performance of each individual project and then overall performance of the dataset.\nOn the other hand, during GT all projects have the same solution vectors, i.e. all instances share the same decision values. Unlike LT, every possible solution here is applied to all instances in the training datasets and the objective function is calculated using the aggregated evaluation measures SA, MIBRE and MBRE. In this case, the MOPSO-CD is applied once since the adapted ABE model is run inside MOPSO-CD. In each run one generated solution is evaluated over all projects in the dataset in attempt to increase SA and minimize MIBRE and MBRE. Finally, we end up with one optimum solution that fits the whole dataset and improve overall performance, not the individual performance. Since the Pareto front may contain many solutions so to select the best solution among them is done as follows: The solutions in Pareto front are ranked based on the three employed evaluation measures, in other words the solutions are ranked in terms of each evaluation measure then the accumulative ranking is obtained by measuring the average ranking. The solution with minimum average\nranking is selected."}, {"heading": "7. Datasets", "text": "In order to assess the performance of any model, it is necessary to validate such model over some historical datasets that exhibit different characteristics as shown in Table 2. Most of the methods in literature were tested on a single or a very limited number of datasets, thereby reducing the credibility of the proposed model [26]. To avoid this pitfall, we included 15 software effort datasets that come from different industrial sectors. Specifically, these datasets come from two different sources namely, PROMISE [4] and ISBSG [7]. PROMISE is a publically available data repository and it consists of datasets donated by various researchers around the world. The datasets come from this source are: desharnais, kemerer, albrecht, cocomo, maxwell, china, telecom and nasa datasets. In our study, we also wanted to see the performance of ensembles on homogeneous datasets as well. Therefore, we only selected homogeneous datasets that are as big as the smallest heterogeneous dataset in terms of instance number. Cocomo dataset enables the researchers to classify projects in terms of three different development modes: Organic, semi-detached and embedded [25]. Therefore we used development mode as our breakdown criteria in cocomo and took three homogeneous subsets of cocomo: cocomo_O, cocomo_E and cocomo_S. cocomo_O includes organic projects whereas cocomo_E includes embedded projects and finally cocomo_S includes semi-detached projects. For the desharnais dataset, the development center of projects was the breakdown criteria. Projects in desharnais are developed in one of the three different development type. Like cocomo dataset, we took three subsets of desharnais based on their development type: desharnais_L1, desharnais_L2 and desharnais_L3. This process has results in 15 datasets.\nThe other dataset comes from ISBSG data repository (release 10) [7] which is a large data repository consists of more than 4000 projects collected from different types of projects around the world. Since many projects have missing values only 505 projects with quality rating \u201cA\u201d are considered. 10 useful features were selected, nine of which are numerical features and one of which is categorical feature. Since this dataset is not publically available and in order to allow replication for our study, the used features from ISBSG are represented in Table 3. One caution should be beard in mind here that although the ISBSG guideline suggests to use their criteria to select projects and features, there is no agreement among researchers about the features they have to choose. So we used the criteria that already utilized in our previous research which can be found in [2][29][46].\nThe employed datasets typically contain a unique set of features that can be categorized according to four classes [26]: size features, development features, environment features and project data. Table 2 shows the descriptive statistics of such datasets. From these statistics we can conclude that datasets in the area of software effort estimation share relatively common characteristics. They often have a limited number of observations that are affected by multicollinearity and outliers. Notably, all datasets have positive skewness efforts that range from 1.78 to 4.36 which indicate that the effort of each dataset is not normally distributed and presents a challenge for developing accurate estimation model.\nchina 18 499 hours 26 54620 3921 1829 3.92 maxwell 27 62 hours 583 63694 8223.2 5189.5 3.26 telecom 3 18 months 23.54 1115.5 284.33 222.53 1.78"}, {"heading": "8. Experiment Setup", "text": "The data preprocessing is important task in any prediction model so that we correctly assess the performance of new model with historical models.  Missing Values: all projects with missing values in any feature were excluded from the dataset. For\nexample the desharnais dataset consists of 4 projects have missing values therefore these projects have been ignored from the dataset, which resulted in 77 complete projects.  Standardization: Since the features in the datasets present different scales, all continuous features were\nscaled using min-max transformation as shown in Eq. 20. This step is very important to eliminate the impact from different feature types, and to have same influence degree. Please note that some existing adaption methods such as LSE and RTM cannot work well with standardization since some features may contain zero after standardization and it is highly likely to divide on zero. To avoid this pitfall we followed the same solution conducted by Kirsopp et al. [12] in that all features that would introduce a zero into the denominator (for a particular case) are excluded from the calculation of the adaptation.\n \n   ZminZmax\nZminz z ii\n\n \n(20)\n Unnecessary Dependent features: Since this study is designed for effort estimation, all unnecessary after-the-\nevent features such as duration or time are removed from the data before starting any experiment.\n Similarity function: we used normalized un-weighted Euclidean distance measure to retrieve nearest\nanalogies as shown in Eq. 1. In case of categorical features, we make binary comparison between two values, i.e. 0 if two projects have same feature values and 1 otherwise.  Validation strategy: The leave-one-out cross validation has been used to validate and compare between\ndifferent models. Although some authors favored n-Fold cross validation. The principal reason for this selection, the leave-one-out cross validation has been used in deterministic procedure that can be exactly repeated by any other research with access to a particular dataset [45]. According to previous studies, the leave-one-out cross validation generates lower base estimates than n-Fold cross validation since the methods need to learn from fewer examples. Also, it generates higher variance estimates than n-Fold cross validation since leave-one-out cross validation conducts more tests [45]. In each run, one project is held out as test instance and the remaining projects as training set. The prediction model is developed on\nthe training set while the test set is used to evaluate the model. The error measures are calculated for each test instance. This procedure is continued until all projects within dataset act as test projects. Moreover, the proposed adaptation functions are compared to some well-known adaptation strategies existing in the literature such as: LSE [24], RTM [10], AQUA [16] and GA [5] in addition to the ABE0.  Performance measures: In addition to the performance measures that are mentioned in section 4 as\nobjective functions we used effect size (  ) as shown in Eq. 21 to check whether the predictions of the model in hand are generated by chance, and to justify if there is large effect improvement over guessing since the statistical significance test alone is not so informative if both predictions models are significantly different. The value of  can be interpreted in terms of the categories of small (0.2), medium (0.5) and large (0.8) where value larger than or equal 0.5 is considered better [30]. Besides that, we used Logarithmic Standard Deviation (LSD) as shown in Eq. 22.\no\np\nSP\nMAEMAE o   (21)\n1\n21\n22\n\n  \n\n  \n \n\n \nn\ns\nLSD\nn i i \n(22)\nWhere:  MAE is the mean absolute error of the prediction model.\n opMAE is the mean value of a large number runs of random guessing.  oSP is the sample standard deviation of the random guessing strategy.  2s is an estimator of the variance of the residual i , and )ieln()ieln(i \nPresenting results without statistical significance is not convincing therefore we use win, tie, loss algorithm [25] to compare the predictive performance of the variants of adaptation methods, see Figure 8. To do so, we first check if two methods Methodi; Methodj are statistically different according to the Wilcoxon sum rank test; otherwise, we increase tiei and tiej. If the error distributions are statistically different, we update wini; winj and lossi; lossj, after checking which one is better according to the performance measure at hand E. The performance measures used here are MAE, MBRE, MIBRE, LSD and SA. We used Wilcoxon sum rank test because the models errors are not normally distributed as confirmed by Kolmogorov\u2013Smirnov test. Also, the win-tie-loss algorithm used Wilcoxon test in its procedure [25]."}, {"heading": "9. The Performance of MOPSO in finding Best k values", "text": "This section presents an analysis of the Pareto solutions with concentration on finding the best k nearest\nanalogies for each project. It also presents the answer to RQ1. Usually, researchers tend to start with one analogy and increase this number, then they use the k value that produces the best overall accuracy of the whole dataset. However, this choice may produce overall best accuracy but does not necessarily provide the best accuracy for each individual project, and could not be the perfect choice for other datasets. Furthermore, the selection of k value usually makes the prediction model behaves differently based on the employed evaluation measures. The obtained k value was frequently found based on using only one evaluation measure, usually MMRE, whereas the final model is evaluated using different evaluation measures. To better understand the behavior of k value selection we formulate an empirical analysis using Local tuning method (LT) with only one decision variable (i.e. k) is optimized in the solution vector, while other decision variables feature set (v) and weight matrix (w) remain unchanged during optimization process. Specifically, the v contains ones along all its dimension (i.e. using all features) and weight matrix contains equal weights (i.e. wij=1) for all possible values. In this analysis the outcome is a set of the best k values, one for each project, obtained as trade-off based on optimizing three evaluation measures (AR, BRE, IBRE).\nFigure 9 shows the bar chart of the best selected k numbers for each examined dataset. Since few datasets are sufficient to demonstrate the behaviors of k selection we chose only four datasets telecom, albrecht, desharnais and maxwell. For a dataset of size n training observations, the best k value can range from 1 to n. The x-axis represents the k nearest analogies, and y-axis represents the number of projects selected that k value. The variability of k values shows that the projects in the dataset tend to use different k nearest projects in making final estimates. It is worth nothing that there is no definite pattern for the process of k selection, and there is no clear evidence that few or large number of analogies are sufficient to produce better estimates. This arise another important concern about validity of previous variants of ABE that relies heavily on expert intuition. Previous research studies [1][2][11][15][19][24] use limited number of analogies which is frequently less than or equal to 5 analogies. In spite of the limited efficiency of this mechanism it could ignore other useful analogies that can help to increase the accuracy. Therefore we believe that the expert intuition should be integrated with an automated procedure to predict the best k value.\nAnother important issue that we should focus in this analysis is the ability of MOPSO to generate not only one solution, but Pareto front solutions. The Pareto front contains various solutions that are not emphasizing a particular evaluation measure but on different evaluation measures. Minku et al. [32] showed that using different evaluation measures behave differently therefore they could be useful to produce prediction models that present trade-off between these evaluation measures. If the estimator has no reason for emphasizing a certain evaluation measure, s/he can analyze these solutions and use whichever solution s/he most prefers. If not, s/he may choose the solution more likely to perform best for that measure. At this case the solution that may appear better than another in terms of a certain measure, it may be actually worse in terms of the other measures. In this experiment, we used the first approach where we did not emphasize a certain evaluation measure but a trade-off among different measures, in which the best solution is selected among Pareto front solutions. The solutions in Pareto- front are ranked based on obtained evaluation measures, in other words the solutions are ranked in terms of each evaluation measure then the accumulative ranking is obtained by measuring average ranking. The solution with minimum average ranking is selected. The efficiency of LT is examined in the next sections."}, {"heading": "10. Local Tuning vs. Global Tuning", "text": "This section focuses on answering RQ2 by making comparison between LT and GT. The main difference between them is that LT attempts to find Pareto front solutions that improve accuracy for each project individually, whereas the GT attempts to find Pareto front solutions that improve accuracy for the whole dataset. In LT each project has different solutions than other projects in the same dataset, in other words, each project has different k value, set of features and weigh matrix. In GT, all projects share the same set of good solutions. So, the main theme of the comparison presented in this section is twofold: 1) to analyze whether the LT and GT methods can significantly improve the accuracy over ABE0. 2) To show which technique is more appropriate for the problem of adaptation. The ABE0 used in this comparison is the baseline ABE with best mean of nearest k analogies that minimize MAE. For each dataset, we run ABE0 repeatedly with changing k value from 1 to n-1 every time. Then we select the ABE0 with k value that minimizes MAE. It is important to note that the best value of k is minimized globally (i.e. the k is same for all projects in the dataset). Finally, to\nmake comparison between three variants we performed an empirical investigation over all 15 datasets using the experiment setup mentioned in Section 8.\nTable 4 presents the results of the comparison between LT, GT and ABE0 in terms of SA and \u2206. Although ABE0 was obtained based on minimizing MAE it cannot beat both LT and GT in terms of SA which is an indication to the performance of the optimization for adaptation procedure. Specifically, LT and GT achieve higher SA than ABE0, and both of them perform comparatively well, with superiority to LT as being optimized for each project individually. The effect size \u2206 in relation to random guess is frequently changed from small/medium to large, emphasizing the importance of using LT and GT to make adaptation. The \u2206 with value greater than 0.5 (medium effect size) is sufficient to conclude that the model does not generate its prediction by chance. The effect size test shows considerably large effect size over most datasets which confirms large effect improvement over guessing for both LT and GT. The cells in light grey in Table 4\nrepresent the datasets for which some models could not generate estimates better than random guessing. It is worth noting that ABE0, LT and GT generate predictions by chances for around 50%, 25%, and 33% of the datasets respectively. In contrast to ABE0, the random predictions of LT and GT were frequently over the separated datasets such as desharnais_L1, desharnais_L2 and so forth. The primary reason for this worse behavior may be due to the heterogeneous structure of the separated datasets.\nWe also compare between three variants in terms of MBRE, MIBRE and LSD. These measures are considerably more reliable to compare between various predictions models than MMRE or MdMRE as explained in Section 4. In this section we show that the best Pareto solutions that consists of three decision variables can be used to improve performance of adaptation method in comparison to ABE0. Comparison with other adaptation methods is shown later in Section 13. Table 5 presents the predictive accuracy for each variant over all employed datasets. The cells in grey represent better accuracy but not necessarily statistically different. The overall results suggest that LT performs better than GT and ABE0 over all datasets, and GT still performs better than ABE0. Specifically, the results w.r.t MBRE shows that LT and GT generate more accurate predictions than ABE0 over all datasets, which indicates the performance of optimization and adaptation for improving accuracy of ABE. Although GT model finds the best solutions based on minimizing three evaluation measures: MBRE, MIBRE and LSD simultaneously, it rarely beats LT. Considering MBRE and MIBRE we can notice that LT wins 14 out 15 datasets whereas GT wins 1 out of 15. Considering LSD, we can notice that GT wins 3 out of 15 datasets whereas LT wins 12 out of 15 datasets. ABE0 has never outperformed other variant in any evaluation measure.\ncocomo_O 1142.4 1070.0 3264.0 63.0 44.2 44.9 2.0 1.7 2.2 cocomo_S 3229.2 1710.0 2326.4 75.5 45.9 48.7 2.11 1.9 2.0 china 61.2 45.1 50.5 29.4 17.1 19.6 0.57 0.47 0.49 maxwell 165.2 30.1 35.7 42.5 17.6 20.9 0.89 0.34 0.37 telecom 79.6 33.2 73.9 35.4 31.1 16.6 0.67 0.41 0.64\nIt is important to note that the performance of three variants over separated datasets are very bad with large error deviations. Splitting large datasets such as cocomo and desharnais into coherent small datasets did not improve predictive accuracy. This suggests that separating dataset has greater impact on the structure of that datasets and may lead to worse performance as in our case. In summary, we can notice that the procedure of finding individual best solution for each project would generally perform efficiently than finding shared best solution for all project in the datasets.\nBased on the above comparison, we can conclude that both LT and GT perform better than ABE0, and particularly LT performs better than GT. To make this hypothesis more well-grounded, we did statistical significance tests over all datasets. The Wilcoxon rank-sum statistical tests, in Table 6, at the overall level of significance of 0.05 for comparing all variants detect statistically significant difference for most datasets. The comparison between the predictions generated by LT and ABE0 suggest that there are significance differences between them over all datasets except some separated datasets such as desharnais_L3 and cocomo_O. Likewise, the comparison between ABE0 and GT suggest that there is no significance difference between them over some separated datasets. On the other hand, we cannot find any significance difference between predictions generated by LT and GT over small datasets such as albrecht, kemerer, nasa and telecom, and over separated datasets."}, {"heading": "11. The importance of feature optimization", "text": "As shown in Section 10, LT and GT can be used to automatically find the best decision variables that provide a good trade-off among different evaluation measures, so that the manager does not need to decide on how many analogies should be used or which feature set are more accurate results. This section concentrates on answering RQ3 which states that whether the use of all features with LT and GT have room for further improvements. It is already recognized that using subset of features would perform better than using all features in terms of evaluation measures [8]. But this would arise another concern about how these features should be found. Frequently, previous studies showed that the best feature set that is used to improve ABE0 is frequently found based on minimizing one of the evaluation measures and subject to the decision made by an expert such as similarity measure and data standardization. So these features would perform better in terms of that evaluation measure but worse in terms of others. In previous section, we showed that optimizing features with other decision variables simultaneously based on many evaluation measures work well, especially if they are evaluated by other evaluation measures.\ncocomo_S 0 0.001 0.58 china 0 0 0.046 maxwell 0 0 0.01 telecom 0.008 0.011 0.78\nIn this section we need to investigate that does the features optimization really contribute towards this good performance? To answer this question we re-run the LT and GT but with keeping the feature decision variable v unchanged during optimization process (i.e. v=2M-1) whereas the other decision variables (i.e. k and w) change normally during the run. This allows to see the contribution of feature optimization on the final accuracy. So if the results when using all features do not significantly improve the prediction accuracy, we can definitely confirm that optimizing features within LT or GT is considerably more accurate. The new adaptation strategy without feature optimization will be called hereafter LT* and GT*.\nTable 7 shows the prediction results in terms of four evaluation measures in addition to the effect size for both LT* and GT*. The effect size of LT* and GT* is computed with relation to LT and GT respectively. For example, the Eq. 21 would appear as shown in Eq. 23 for LT*. This allows us to justify if there is large effect improvement over LT and GT since the statistical significance test alone is not so informative if both predictions models are significantly different.\nLT\nLT*LT *LT\nSP\nMAEMAE   (23)\nThe obtained results in terms of SA shows that both LT* and GT* are predicting over all datasets since they fall comfortably beyond the MAE of random guessing. So we can believe that the prediction generated by LT* or GT* are highly unlikely to have arisen by chance. However, when comparing LT* and GT* to LT and GT w.r.t SA we can find LT and GT are more accurate which suggests that using the optimized features is better than using all features. To confirm that we computed effect size for both LT* and GT* with relation to LT and GT respectively. We can notice that none of LT* and GT* has a medium effect size over any dataset. This alone should suggest we cannot find significant improvements when using all features either with GT* or LT*.\nOn the other hand, the accuracy values in terms of MBRE, MIBRE and LSD are also going into that direction. If we look closer at the obtained values and compare it to the results obtained in Table 5 we can find that LT and GT performs better with optimizing feature set. This finding emphasize more on the importance of feature optimization together with other decision variables on the final accuracy. Another important result is that using all feature would also perform better than ABE0.\nThe results without statistical significance test would be not convincing so we make comparison between each two variants (i.e. LT vs LT* and GT vs GT*). The results of statistical significance test based on absolute errors are shown in Table 8. Surprisingly, we cannot find any significance difference between LT against LT* or GT against GT* over the separated datasets. On the other hand we can see that there is significance difference between LT and its counterpart LT*, and between GT and its corresponding counterpart GT* over most datasets. This indicates that both of them generate different predictions with superiority to LT and GT since they yield better performance w.r.t to three evaluation measures. So we believe that there is sufficient evidence that using different feature set for each project is more efficient than using all features as confirmed by the comparison between LT and LT*. Moreover, optimizing feature set for the whole dataset is also better than using all features as shown in the comparison between GT and GT*."}, {"heading": "12. The importance of weighting optimization in the adaptation strategy", "text": "This section concentrates on answering question RQ4 which states that: does the use of weighting values contribute towards improving prediction accuracy of the adaptation technique? It is already known that using weighting mechanism shows considerable performance when it is applied in project retrieval and some adaptation methods such as AQUA and GA [1]. Usually software managers tend to use simple weighting mechanism that is feasible and easy to apply such as inverse ranked weighted mean or similarity between projects. Although these mechanisms follow formal procedures in finding weight values, they are considered useful only when the dataset structure is rather simple and normally distributed. The weight values that found by LT or GT are generated randomly and do not follow a particular algorithm, then are changed according to the best positions of particles. To better understand the importance of weighting in our adaptation strategy we aim at comparing the use of non-weighted form of our adaptation strategy with the weighted version (i.e. original LT or GT).\nTo do so, we re-run the LT and GT but without considering weight values (i.e. using equal weights). The modified variant of both LT and GT will be called hereafter LT+ and GT+ consequentially. Similar to previous section, weighting values remain equal and unchanged (i.e. M,...,,j;n,...,,i,wij 21211  ) during the optimization process while other decision variables (k and v) change normally according to the optimization algorithm. So, the main objective of the comparison presented in this section is to analyze the level of accuracy improvements when optimizing adaptation weights.\nFirst, let\u2019s analyze the accuracy values considering all data sets. Table 9 shows the predictive performance and effect size for the Pareto efficient adaptation method without considering the weight matrix. The results of SA shows that LT+ and GT+ do not frequently generate successful predictions than random guessing which suggest that they are not reliable to ignore the role of weighting mechanism. Moreover, the SA of LT+ and GT+ are worse than those of LT and GT over all datasets. Also, we are interested with the results of effect size in\ncomparison to the original LT and GT. So we measure the effect size for LT+ and GT+ with relation to LT and GT as baseline respectively. The effect size results were almost small (i.e. \u2206 \u2248 0.2) suggesting that small effect size improvements than LT or GT. Likewise, the performance figures in terms of MBRE and MIBRE and LSD suggest that ignoring the weight values did not contribute significantly towards accuracy improvements of LT and GT. The value of these evaluation measures become worse when we use LT+ and GT+ with poor MBRE and MIBRE and relatively bad LSD in comparison to LT and GT respectively. So we can believe that the optimization of three decision variables simultaneously based on optimizing various evaluation measures allow software manager to save time in finding the appropriate decisions in very large space of configurations.\nEven though the effect size suggest bad performance of Non-weighted LT+ and GT+ in comparison to LT and GT, we are still interested to see the p-value of statistical significance test over all datasets. Table 10 shows the p-values of the comparison between each two corresponding opponents LT vs. LT+ and GT vs. GT+ using Wilcoxon sum rank test and based on absolute prediction errors. The general trend shows that there is a significant difference between predictions generated by LT and LT+ and between GT and GT+, which indicates that both LT and GT are able to produce better accuracy. So we believe that the weight values is more important for our adaptation strategy. Nevertheless, even though the LT and GT produce meaningful predictions over LT+ and GT+, we could not find any difference between them over some separated datasets. So we can see that the use of separated datasets is still problematic and did not contribute well in improving accuracy than original dataset.\ncocomo_O 0.39 0.47 cocomo_S 0.28 0.35 china 0.01 0.033 maxwell 0.001 0.001 telecom 0.001 0.04"}, {"heading": "13. Further Analysis", "text": "This section presents performance figures of LT and GT against various adaptation techniques used with ABE. The adaptation methods that have been compared are: LSE, RTM, GA and AQUA as explained in Section 2. The objective of this comparison is to ensure that the proposed adaptation strategy works comparatively well against other adaptation methods existing in literature. To make this comparison much well grounded, we used the same validation procedure followed by LT and GT (i.e. Leave-one-out cross validation). Since the selection of the best k setting in other adaptation methods is not dynamic, there was necessarily to find the best k value that almost fits each model, therefore we perform empirical validation for each method to find the best k value that yield minimum MAE. The principal reason for this process is to ensure all methods undergo the same assumption since the original experiments of those studies found the best k by minimizing MMRE, which is not reliable anymore to be relied on. Thus, the best variant of each method with best k value has been used in the further empirical comparison.\nTable 11 summarize the resulting performance figures for all investigated adaptation methods. The most successful method should have lower MBRE, MIBRE, LSD. The grey cells with superscripts * represent the model and dataset for which GT only has been outperformed. The grey cells with superscripts ** represent the model and dataset for which LT and GT have been outperformed together. If we look closer at the results we can find that LT and GT are rarely beaten by any of the adaptation methods except over some datasets such as china and nasa.\nHowever, these findings are indicative of the superiority of LT and GT in optimizing the adaption decision variables, and consequentially improve overall predictive performance of ABE. One of the advantages of using LT and GT is that they are fully automated procedure because they do not need human intervention to guess how many nearest analogies should be used or which features should be involved. Also from the obtained results we can observe that there is evidence that our adaptation method can work better for datasets with discontinuities (e.g. Maxwell, and COCOMO). We speculate that prior Software Engineering researchers who failed to find best k setting, did not attempt to optimize three decision variables simultaneously with the adaptation method itself for each individual project before building the model.\nTo summarize the results we consult win, tie, loss algorithm [25] to show the complete picture of our analysis to compare the predictive performance of the variants of Adaptation methods as suggested by Kocaguneli et al. [25]. As a consequence, all six adaptation methods have been first evaluated over 15 datasets using Leave-one-out cross validation and four evaluation measures. For each variant of adaptation method, we record MAE, MBRE, MIBRE and LSD. We also consult win, tie, loss algorithm to compute win-loss (i.e. win minus loss) for each variant after comparing all variants with each other across all error measures. All single methods are ranked with respect to all error measures in addition to (win-loss) over all datasets which resulted in (15 \u00d7 4 \u00d7 5) = 300 possible rankings. Figure 10 shows the adaptation methods variants, sorted by the calculated number of losses seen in all evaluation measures and all datasets. The adaptation method with the largest score is ranked #1 which is LT. At the other end of the scale, the adaptation method with the lowest score is ranked #6 which is AQUA. Notice that, all methods are ranked in ascending order (i.e. lowest first) over all error measure. It is clear from final scores that LT and GT variants are the top winners and they also ranked top across all other error measures. The method LT is ranked first among all methods based on accumulative decision, but this method has been the winner over only three error measures (LSD, MBRE and MIBRE). Apparently, there is significant difference between the best and worst methods in terms of number of losses (in the extreme case it is close to 125). The win-tie-loss results offer yet more evidence for the superiority of LT over other adaptation techniques. Also the obtained win-tie-loss results confirmed that the predictions based on LT and GT methods presented statistically significant but necessarily accurate estimations than other methods. This suggests that there is a significant difference if the prediction generated by LT or GT against other models.\nAlthough the GA method is one of the most efficient optimization techniques, it occupied the late positions with the poor performance across multiple evaluation measures. On contrast, the comparative performance of LSE method can be attributed to the fact that it uses the size feature as the adaptation factors, in which this feature is considered the strongest correlated feature with effort in all datasets.\nRecall Kocaguneli et al. [25] results, any method is to be superior to others, should be ranked first and has a minimum number of changes in their ranks. Therefore we used Standard Deviation (SD) of rank changes to measure stability of ranking for each method across different experimental conditions. The minimum SD represents more stable ranking because it has smaller ranking distribution.\nTable 12 shows the success of adaptation methods through ranking over MBRE, MIBRE, and LSD consequentially. It shows the SD and average of ranking across multiple datasets. The most successful models have higher ranking and lower rank change which is indication to the stability of ranking. The \u2018method rank per dataset\u2019 has been obtained by ranking every method based on different error measure (i.e. ranking based MBRE, ranking based MIBRE and LSD) then we aggregate those ranks using across all datasets. Looking carefully at this Table we can notice that the winner over all datasets in terms of MBRE was LT with stable ranking (i.e. rank#1 over all datasets). Other adaptation have instability in ranking which conclude that it was previously hard to identify the superior variant among those historical adaptation methods. While some methods have large amount of changes, other do not. Better yet, as shown in the Figure 10, the LT had the lowest rank change seen in any of other 5 adaptation techniques. Although the RTM has stable ranking with smaller amount of rank changing (i.e. zero) but it ranks lower than other models with bad performance according to all error measures.\nFigure 11 sorts all 6 methods according to their SD of rank changes over three evaluation measures mentioned in Table 12. The y-axis shows the SD of rank changes obtained for each adaptation method, as we compare the ranks across all evaluation measures and over multiple datasets. For example, the top ranked method of LT has nearly 1.1 SD in difference between best and worst ranks. A line drawn parallel to x-axis at y = 1.3 gives methods, whose SD of rank change is less/more than 1.3 whereas the line drawn parallel to y-axis exactly after GT gives methods whose ranked top and have lowest stable rank change. From this figure, we can observe that the LT and GT methods in table 12 have lowest rank changes than others, which is good news since the lowest rank change is an indication of the ranking stability for that method. Notably, RTM is relatively considered stable as they have narrower SD of rank changes but unfortunately they are far from the top ranked methods. Thus, even that these top-ranked methods jumped rank by their maximum change, they would still be working better than most of the others 3 methods. However, LSE, GA and AQUA ranked between #3 and #6 (inclusive) have SD of rank changes above 1.6, i.e. they are \u201cunstable\u201d in this region.\nOther results offer yet more evidence of the performance of LT and GT over existing adaptation methods. Figure 12 depicts plot of the Bonferroni test for ranking methods over three evaluation measures (BRE, IBRE and AE). We use the Bonferroni-Dunn test to compare the ranking of LT and GT methods against various adaptation methods. The plots have been obtained after applying ANOVA test followed by Bonferroni test. The ANOVA test results in pvalue close to zero (i.e. <0.01) which implies that the difference between rankings of LT and GT against other adaptation methods are statistically significant across the three utilized error measures. The horizontal axis in these figures corresponds to the average rank of across different datasets. The more this line is situated to the left, the better performing the method is. The dotted vertical lines in the figures indicate the critical difference at the 95% confidence level. Obviously, the LT and GT occupy better ranks than all adaptation methods including GT in terms of all measures with preference to LT as significantly better than GT in terms of BRE and IBRE. Nevertheless, there was no significance difference between LT and GT in terms of AE."}, {"heading": "14. Conclusions and Future Work", "text": "Finding the appropriate decisions to adapt the nearest analogies in ABE method is relatively a nontrivial task. Prior methods have attempted to use these decisions or part of them manually based on expert opinion. This approach has some limitations because the expert cannot identify all possible decision combinations that may reach thousands. In this paper, we proposed two adaptation methods (LT and GT) based on using multiobjective optimization algorithm MOPSO to identify optimal decision variables (k, v, and w) that present a good trade-off between different evaluation measures. In our study, we defined four research question to study the performance of the proposed adaption methods and investigate the impact of decision variables on the optimization process. Based on our analysis, we summarize the following findings:\n1. The use of LT tends to be more efficient than using GT in most datasets. In other words, optimizing\nall decision variables for each project individually produce better results than optimizing them for the whole dataset. We have shown in section 10 that LT statistically generates better predictions than those of GT over most datasets. 2. Optimizing all three decision variables of adaptation method simultaneously is better than\noptimizing part of them. We have shown in sections 11 and 12 that fixing any one of the decision variable does not improve predictive performance and makes the adaption method to generate worse estimates. This finding has been statistically tested using Wilcoxon sum rank test. 3. Remarkably, the LT and GT work better than other existing adaptation methods as confirmed in\nFigures 10 and 12.\n4. Most adaption methods did not yield good results over the separated datasets comparing to the\nresults of their original datasets. This emphasizes us to recommend not separating dataset based on categorical features. Even though, the LT and GT still perform better than other adaptation methods over these datasets.\nApart from trying to address the reported issues regarding previous ABE studies in terms of dataset and model, we also tried to meet the methodological problems such as testing only on a limited number of datasets and lacking statistical checks on the results. Therefore, we utilized various datasets from multiple resources and evaluated our results on the basis of Wilcoxon signed rank test at a 95% confidence level. Furthermore, rather than proposing a best solution a priori as the traditional ABE methods do, what LT and GT do is automatically identify some Pareto front solutions that make trade-off among different evaluation measures. So we don\u2019t emphasize any particular evaluation measures as in previous studies. Therefore all results obtained support this attitude and show better accuracy than other competitors over all evaluation measures.\nA future work is planned to study the use of MOPSO to select the best design decision of ABE. As we have pointed out in the introduction section the ABE has many design decisions and project manager has no time to find which design decision that best fits his/her data. So the next study aims to evaluate the performance of MPOSO on finding the right decision for the data in hand using multiple evaluation measures.\n(a) BRE\n0 1 2 3 4 5 6\nAQUA\nGA\nRTM\nLSE\nGT\nLT"}, {"heading": "15. Acknowledgements", "text": "The authors are grateful to the Applied Science Private University, Amman, Jordan, for the financial support granted to this research project."}], "references": [{"title": "Optimal project feature weights in analogy-based cost estimation: Improvement and limitations", "author": ["M. Auer", "A. Trendowicz", "B. Graser", "E. Haunschmid", "S. Biffl"], "venue": "IEEE Transactions on Software Engineering vol. 32, no. 2, pp. 83\u201392", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Model tree Based Adaptation Strategy for software Effort estimation by Analogy", "author": ["M. Azzeh"], "venue": "11th IEEE International Conference on Computer and Information Technology, pp. 328-335", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "A replicated assessment and comparison of adaptation techniques for analogy-based effort estimation", "author": ["M. Azzeh"], "venue": "Journal of Empirical Software Engineering, vol. 17, no.1-2, 90-127", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "The PROMISE Repository of empirical software engineering data http://promisedata.googlecode.com", "author": ["T. Menzies", "B. Caglayan", "E. Kocaguneli", "J. Krall", "F. Peters", "B. Turhan"], "venue": "West Virginia University, Department of Computer Science,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "The adapted analogy-based software effort estimation based on similarity distances", "author": ["N.H. Chiu", "S.J. Huang"], "venue": "Journal of Systems and Software, vol. 80, no. 4, pp.628\u2013640", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "A simulation study of the model evaluation criterion MMRE", "author": ["T. Foss", "E. Stensrud", "B. Kitchenham", "I. Myrtveit"], "venue": "IEEE Transactions on Software Engineering vol. 29, no. 11, pp.985\u2013995", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "How to find relevant data for effort estimation? In 5  th International Symposium on Empirical Software Engineering and Measurement (ESEM)", "author": ["E. Kocaguneli", "T. Menzies"], "venue": "pp. 255-264. IEEE, Banff, Canada", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "A review of studies on expert estimation of software development effort", "author": ["M. Jorgensen"], "venue": "Journal of Systems and Software, vol. 70, no. 1, pp. 37\u201360", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "Software effort estimation by analogy and regression toward the mean", "author": ["M. Jorgensen", "U. Indahl", "D. Sjoberg"], "venue": "Journal of Systems and Software, vol. 68, no. 3, pp.253\u2013262", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2003}, {"title": "Experiences using case based reasoning to predict software project effort", "author": ["G. Kadoda", "M. Cartwright", "L. Chen", "M. Shepperd"], "venue": "proceedings of EASE, Evaluation and Assessment in Software Engineering Conference, Keele, UK", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2000}, {"title": "An empirical analysis of linear adaptation techniques for case-based prediction", "author": ["C. Kirsopp", "E. Mendes", "R. Premraj", "M. Shepperd"], "venue": "5  th International Conference on Case Based Reasoning, pp.231\u2013245", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Linear combination of multiple case-based reasoning with optimized weight for software effort estimation", "author": ["D. Wu", "L. Jianping", "L. Yong"], "venue": "The Journal of Supercomputing: Vo. 64, no. 3, pp. 898-918", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Combining multiple learners induced on multiple datasets for software effort prediction", "author": ["E. Kocaguneli", "Y. Kultur", "A. Bener"], "venue": "20  th International Symposium on Software Reliability Engineering (ISSRE)", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Exploiting the Essential Assumptions of Analogy-based Effort Estimation", "author": ["E. Kocaguneli", "T. Menzies", "A. Bener", "J. Keung"], "venue": "IEEE Transactions on Software Engineering, vol.38, no. 2, pp. 425-438", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "A flexible method for software effort estimation by analogy", "author": ["J.Z. Li", "G. Ruhe", "A. Al-Emran", "M. Richter"], "venue": "Journal of Empirical Software Engineering, vol. 12, no. 1, pp. 65\u2013106", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "A study of the non-linear adjustment for analogy based software cost estimation", "author": ["Y.F. Li", "M. Xie", "T.N. Goh"], "venue": "Journal of Empirical Software Engineering, vol. 14, no. 6, pp. 603\u2013643", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Selection of the optimal prototype subset for 1-NN classification", "author": ["U. Lipowezky"], "venue": "Journal of Pattern Recognition Letters, vol. 19, no. 10, pp. 907-918", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1998}, {"title": "A comparative study of cost estimation models for web hypermedia applications", "author": ["E. Mendes", "I. Watson", "C. Triggs", "N. Mosley", "S. Counsell"], "venue": "Journal of Empirical Software Engineering, vol. 8, no. 2, pp.163\u2013196", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2003}, {"title": "Selecting Best Practices for Effort Estimation", "author": ["T. Menzies", "Z. Chen", "J. Hihn", "K. Lum"], "venue": "IEEE Transactions on Software Engineering, vol. 32, no. 11, pp. 883-895", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2006}, {"title": "Reliability and validity in comparative studies of software prediction models", "author": ["I. Myrtveit", "E. Stensrud", "M. Shepperd"], "venue": "IEEE Transactions on Software Engineering, vol. 31, no. 5, pp. 380\u2013391", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2005}, {"title": "Estimating software project effort using analogies", "author": ["M. Shepperd", "C. Schofield"], "venue": "IEEE Transactions on Software Engineering, vol. 23, no. 11 pp. 736\u2013743", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1997}, {"title": "A Replication of the Use of Regression towards the Mean (R2M) as an Adjustment to Effort Estimation Models", "author": ["M. Shepperd", "M. Cartwright"], "venue": "11th IEEE International Software Metrics Symposium (METRICS'05), pp. 38", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2005}, {"title": "An empirical study of analogy-based software effort Estimation", "author": ["F. Walkerden", "D.R. Jeffery"], "venue": "Journal of Empirical Software Engineering, vol. 4, no. 2, pp. 135\u2013158", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1999}, {"title": "On the Value of Ensemble Effort Estimation", "author": ["E. Kocaguneli", "T. Menzies", "J.W. Keung"], "venue": "IEEE Transactions on Software Engineering, vol.38, no.6, pp.1403-1416", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Data Mining Techniques for Software Effort Estimation: A Comparative Study", "author": ["K.K. Dejaeger", "D. Martens W. Verbeke", "B. Baesens"], "venue": "IEEE Transactions on Software Engineering,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Ranking and Clustering Software Cost Estimation Models through a Multiple Comparisons Algorithm", "author": ["N. Mittas", "L. Angelis"], "venue": "IEEE Transactions on Software Engineering, vol. 39, no. 4, pp. 537-551", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Software quality analysis by combining multiple projects and learners", "author": ["M. Khoshgoftaar", "P. Rebours", "N. Seliya"], "venue": "Journal Software Quality Control, vol. 17, no. 1, pp. 25\u201349", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning Best K analogies from Data Distribution for Case-Based Software Effort Estimation", "author": ["M. Azzeh", "Y. Elsheikh"], "venue": "The Seventh International Conference on Software Engineering Advances, pp. 341-347", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "Evaluating prediction systems in software project estimation", "author": ["M. Shepperd", "S. MacDonell"], "venue": "Journal of Information and Software Technology, vol. 54, no. 8, pp. 820-827", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "Ensembles and locality: Insight on improving software effort estimation", "author": ["M. Leandro", "X. Yao"], "venue": "Journal of Information and Software Technology, vol. 55, no. 8, pp. 1512-1528", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2012}, {"title": "Software effort estimation as a multiobjective learning problem, ACM Transactions on Software Engineering and Methodology", "author": ["Leandro", "X. Yao"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}, {"title": "The impact of parameter tuning on software effort estimation using learning machines", "author": ["L. Song", "M. Leandro", "Y. Xin"], "venue": "the 9th International Conference on Predictive Models in Software Engineering. ACM", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}, {"title": "Analogy-X: Providing Statistical Inference to Analogy-Based Software Cost Estimation", "author": ["J. Keung", "B. Kitchenham", "D.R. Jeffery"], "venue": "IEEE Transactions on Software Engineering, Vol. 34, no. 4, pp. 471-484", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2008}, {"title": "Stable rankings for different effort models", "author": ["T. Menzies", "O. Jalali", "J. Hihn", "D. Baker", "K. Lum"], "venue": "Journal of Automated Software Engineering, vol. 17, no. 4, pp. 409-437", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2010}, {"title": "Handling multiple objectives with particle swarm optimization", "author": ["C.A.C Coello", "G.T. Pulido", "T. Pulido", "M.S. Lechuga"], "venue": "IEEE Transactions on Evolutionary Computation, 8.3, pp. 256-279", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2004}, {"title": "Particle swarm optimization", "author": ["K. James"], "venue": "Encyclopaedia of Machine Learning, Springer US, pp. 760-766", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2010}, {"title": "Boundary handling approaches in particle swarm optimization", "author": ["N. Padhye", "K. Deb", "P. Mittal"], "venue": "the 7  th International Conference on Bio-Inspired Computing: Theories and Applications ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2012}, {"title": "Particle Swarm Optimization", "author": ["J. Kennedy", "R.C. Eberhart"], "venue": "the 4  th IEEE International Conference on Neural Networks, pp. 1942\u2013 1948", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1995}, {"title": "Micro-MOPSO: a multi-objective particle swarm optimizer that uses a very small population size", "author": ["J.C.F Cabrera", "C.A.C Coello"], "venue": "Multi-Objective Swarm Intelligent Systems, Springer Berlin Heidelberg, 83-104", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}, {"title": "Using crowding distance to improve multi-objective PSO with local search", "author": ["C.S. Tsou", "S.C. Chang", "P.W. Lai"], "venue": "Swarm Intelligence: Focus on Ant and Particle Swarm Optimization pp. 77-86", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2007}, {"title": "F.Thabta, L.McCluskey, Predicting phishing websites based on self-structuring neural network", "author": ["R. Mohammad"], "venue": "Journal of Neural Computing and Applications,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2014}, {"title": "Artificial neural network for estimation of harbor oscillation in a cargo harbour basin", "author": ["M. Kankal", "O. Yuksek"], "venue": "Journal of Neural Computing and Applications, vol 25, no. 1, pp. 95-103", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2014}, {"title": "A Better Case Adaptation Method for Case-Based Effort Estimation Using Multi-Objective Optimization", "author": ["M. Azzeh", "A.B. Nassif", "S. Banitaan"], "venue": "The 13th International Conference on Machine Learning and Applications (ICMLA'14), Detroit, MI USA", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2014}, {"title": "Software effort models should be assessed via leave-one-out validation", "author": ["E. Kocaguneli", "T. Menzies"], "venue": "Journal of Systems and Software,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2013}, {"title": "Analogy-based software effort estimation using Fuzzy numbers", "author": ["M. Azzeh", "D. Neagu", "P.I. Cowling"], "venue": "Journal of Systems and Software vol. 84, issue 2, pp. 270-284", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2011}, {"title": "An Empirical Analysis of Data Pre-processing for Machine Learning-based Software Cost Estimation", "author": ["J. Huang", "Y-F Li", "M. Xie"], "venue": "Information and Software Technology, Elsevier, In Press, doi:10.1016/j.infsof.2015.07.004", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 2, "context": "Introduction One of the key challenges in software industry is how to obtain the accurate estimation of the development effort, which is particularly important for risk evaluation, resource scheduling as well as progress monitoring [3][15][28].", "startOffset": 232, "endOffset": 235}, {"referenceID": 13, "context": "Introduction One of the key challenges in software industry is how to obtain the accurate estimation of the development effort, which is particularly important for risk evaluation, resource scheduling as well as progress monitoring [3][15][28].", "startOffset": 235, "endOffset": 239}, {"referenceID": 26, "context": "Introduction One of the key challenges in software industry is how to obtain the accurate estimation of the development effort, which is particularly important for risk evaluation, resource scheduling as well as progress monitoring [3][15][28].", "startOffset": 239, "endOffset": 243}, {"referenceID": 45, "context": "This importance is clearly portrayed through proposing a vast variety of estimation models in the past years [47].", "startOffset": 109, "endOffset": 113}, {"referenceID": 29, "context": "In one hand the underestimation results in approval of projects that will exceed their planned budgets, while on the other hand the overestimation causes waste of resources and misses opportunities to offer funds for other projects in future [31].", "startOffset": 242, "endOffset": 246}, {"referenceID": 13, "context": "Software effort estimation has been extensively studied in literature since 70\u2019s but they have suffered from common problems such as very large performance deviations as well as being highly dataset dependent [15].", "startOffset": 209, "endOffset": 213}, {"referenceID": 1, "context": "The latter has two distinct advantages over the former such that they have capability to model complex set of relationships between dependent variable and the independent variables, and they are capable to learn from historical project data [2][27].", "startOffset": 241, "endOffset": 244}, {"referenceID": 25, "context": "The latter has two distinct advantages over the former such that they have capability to model complex set of relationships between dependent variable and the independent variables, and they are capable to learn from historical project data [2][27].", "startOffset": 244, "endOffset": 248}, {"referenceID": 12, "context": "In the recent years, a significant research effort was put into utilizing various machine learning (ML) algorithms as a complementary or as a replacement to previous methods [14][17][25][31].", "startOffset": 174, "endOffset": 178}, {"referenceID": 15, "context": "In the recent years, a significant research effort was put into utilizing various machine learning (ML) algorithms as a complementary or as a replacement to previous methods [14][17][25][31].", "startOffset": 178, "endOffset": 182}, {"referenceID": 23, "context": "In the recent years, a significant research effort was put into utilizing various machine learning (ML) algorithms as a complementary or as a replacement to previous methods [14][17][25][31].", "startOffset": 182, "endOffset": 186}, {"referenceID": 29, "context": "In the recent years, a significant research effort was put into utilizing various machine learning (ML) algorithms as a complementary or as a replacement to previous methods [14][17][25][31].", "startOffset": 186, "endOffset": 190}, {"referenceID": 13, "context": "they need to be tuned to local data for high accuracy values[15][33].", "startOffset": 60, "endOffset": 64}, {"referenceID": 31, "context": "they need to be tuned to local data for high accuracy values[15][33].", "startOffset": 64, "endOffset": 68}, {"referenceID": 13, "context": "ML methods have an extremely large space of configuration possibilities [15][42][43].", "startOffset": 72, "endOffset": 76}, {"referenceID": 40, "context": "ML methods have an extremely large space of configuration possibilities [15][42][43].", "startOffset": 76, "endOffset": 80}, {"referenceID": 41, "context": "ML methods have an extremely large space of configuration possibilities [15][42][43].", "startOffset": 80, "endOffset": 84}, {"referenceID": 5, "context": "When we consider configuration possibilities of ML methods induced on different datasets, each method has its own characteristics, so it is not a surprise to see contradictory results [6][9][30][35].", "startOffset": 184, "endOffset": 187}, {"referenceID": 7, "context": "When we consider configuration possibilities of ML methods induced on different datasets, each method has its own characteristics, so it is not a surprise to see contradictory results [6][9][30][35].", "startOffset": 187, "endOffset": 190}, {"referenceID": 28, "context": "When we consider configuration possibilities of ML methods induced on different datasets, each method has its own characteristics, so it is not a surprise to see contradictory results [6][9][30][35].", "startOffset": 190, "endOffset": 194}, {"referenceID": 33, "context": "When we consider configuration possibilities of ML methods induced on different datasets, each method has its own characteristics, so it is not a surprise to see contradictory results [6][9][30][35].", "startOffset": 194, "endOffset": 198}, {"referenceID": 23, "context": "Finding the best estimation model was under a thorough investigation of many comparative studies that attempted to rank and categorize those models based on the quality of estimates they produce [25][27].", "startOffset": 195, "endOffset": 199}, {"referenceID": 25, "context": "Finding the best estimation model was under a thorough investigation of many comparative studies that attempted to rank and categorize those models based on the quality of estimates they produce [25][27].", "startOffset": 199, "endOffset": 203}, {"referenceID": 23, "context": "The most factors that contradict their findings seem to be the error measures [25], datasets preprocessing and their inherent characteristics [3], and finally, the experimental methodology [15].", "startOffset": 78, "endOffset": 82}, {"referenceID": 2, "context": "The most factors that contradict their findings seem to be the error measures [25], datasets preprocessing and their inherent characteristics [3], and finally, the experimental methodology [15].", "startOffset": 142, "endOffset": 145}, {"referenceID": 13, "context": "The most factors that contradict their findings seem to be the error measures [25], datasets preprocessing and their inherent characteristics [3], and finally, the experimental methodology [15].", "startOffset": 189, "endOffset": 193}, {"referenceID": 20, "context": "Since the utility of a project cannot be evaluated directly, similarity between project descriptions is used as a heuristic approach to retrieve the projects\u2019 effort [22].", "startOffset": 166, "endOffset": 170}, {"referenceID": 32, "context": "We study ABE for several reasons: a) it reflects human reasoning, b) it works with spare data and complex domains, and c) it provides reasoning in a domain with a small body of knowledge [34].", "startOffset": 187, "endOffset": 191}, {"referenceID": 2, "context": "Previous research has reported that ABE is able to produce more successful results in comparison to traditional regression based methods [3][22].", "startOffset": 137, "endOffset": 140}, {"referenceID": 20, "context": "Previous research has reported that ABE is able to produce more successful results in comparison to traditional regression based methods [3][22].", "startOffset": 140, "endOffset": 144}, {"referenceID": 9, "context": "ABE has been favored over other methods when the dataset contains discontinuities [11].", "startOffset": 82, "endOffset": 86}, {"referenceID": 13, "context": "Such decisions include selection of features and/or instances, deciding on the number of analogies to be used and the adaptation strategy [15][19].", "startOffset": 138, "endOffset": 142}, {"referenceID": 17, "context": "Such decisions include selection of features and/or instances, deciding on the number of analogies to be used and the adaptation strategy [15][19].", "startOffset": 142, "endOffset": 146}, {"referenceID": 13, "context": "[15] stated that using different solutions for each parameter produce different ABE configuration, hence, different ABE models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "Indeed, there is a direct evidence that the choice of right adaptation method has a big influence on the accuracy of ABE as confirmed in [3][13].", "startOffset": 137, "endOffset": 140}, {"referenceID": 11, "context": "Indeed, there is a direct evidence that the choice of right adaptation method has a big influence on the accuracy of ABE as confirmed in [3][13].", "startOffset": 140, "endOffset": 144}, {"referenceID": 20, "context": "The original ABE method [22], that is denoted as ABE0, does not use any kind of adaptation strategy, but it uses the mean of k nearest neighbors\u2019 efforts.", "startOffset": 24, "endOffset": 28}, {"referenceID": 30, "context": "Previous studies showed that applying different evaluation measures tend to behave differently in identifying best model [32], therefore finding these decisions should be based on improving all evaluation measures simultaneously.", "startOffset": 121, "endOffset": 125}, {"referenceID": 8, "context": "Moreover, the improved ABE models that use adaptation strategy such as regression towards the mean [10], genetics algorithm [5] and neural networks [17] still fail in specifying the appropriate number of the nearest analogies and do not take other decisions in their adaption process.", "startOffset": 99, "endOffset": 103}, {"referenceID": 4, "context": "Moreover, the improved ABE models that use adaptation strategy such as regression towards the mean [10], genetics algorithm [5] and neural networks [17] still fail in specifying the appropriate number of the nearest analogies and do not take other decisions in their adaption process.", "startOffset": 124, "endOffset": 127}, {"referenceID": 15, "context": "Moreover, the improved ABE models that use adaptation strategy such as regression towards the mean [10], genetics algorithm [5] and neural networks [17] still fail in specifying the appropriate number of the nearest analogies and do not take other decisions in their adaption process.", "startOffset": 148, "endOffset": 152}, {"referenceID": 37, "context": "It has been proposed by Kennedy and Eberhart [39] to perform combination of random and neighborhood search.", "startOffset": 45, "endOffset": 49}, {"referenceID": 35, "context": "However, the conventional PSO can deal with problems that have only one objective function, but when the problem has many conflicting objectives as in our study we should use the extended version of PSO that can support multi-objective functions which is called multi-objective Particle Swarm Optimization (MOPSO) [37][40].", "startOffset": 314, "endOffset": 318}, {"referenceID": 38, "context": "However, the conventional PSO can deal with problems that have only one objective function, but when the problem has many conflicting objectives as in our study we should use the extended version of PSO that can support multi-objective functions which is called multi-objective Particle Swarm Optimization (MOPSO) [37][40].", "startOffset": 318, "endOffset": 322}, {"referenceID": 30, "context": "Since these measures tend to behave differently [32], the final outcome of MOPSO is not a single solution but a set of solutions that make a good trade-off between these objective functions.", "startOffset": 48, "endOffset": 52}, {"referenceID": 42, "context": "This paper is an extension to our previous works on using optimization for ABE adaptation [44].", "startOffset": 90, "endOffset": 94}, {"referenceID": 27, "context": "Previous studies suggest that adapting each project individually with its own decisions tend to be more accurate than adapting whole dataset with the same decision vector [29].", "startOffset": 171, "endOffset": 175}, {"referenceID": 20, "context": "Background & Related Work ABE generates a new estimation based on assumption that similar projects with respect to features description have similar efforts [22].", "startOffset": 157, "endOffset": 161}, {"referenceID": 22, "context": "In late 1990s, Walkerden and Jeffery [24] introduced the first adjustment method called Linear Size Extrapolation (LSE).", "startOffset": 37, "endOffset": 41}, {"referenceID": 10, "context": "[12] extended Walkerden and Jeffery method to include all size related features.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19] based on a dataset collected from web projects.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "Unfortunately, the replication study on adjustment methods [3] revealed that MLFE is still less useful than LSE under certain experimental conditions.", "startOffset": 59, "endOffset": 62}, {"referenceID": 8, "context": "[10] proposed a different method called Regression Towards the Mean (RTM) to adjust and calibrate nearest projects based on the notion of project productivity.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[10] remarked that the productivity distribution of estimated projects are narrower than that of actual projects which proves that the estimated efforts regress towards the mean effort in a particular dataset.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Shepperd and Cartwright [23] replicated the work of Jorgensen et al.", "startOffset": 24, "endOffset": 28}, {"referenceID": 8, "context": "[10] and advised that the dataset should be partitioned into groups of homogeneous projects so that the adjustment moves to a local productivity mean.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16] demonstrate that the similarity degree between projects can play important role in adjusting selected projects.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "Previous analysis studies report that software datasets are characteristically noisy with complex structure [29].", "startOffset": 108, "endOffset": 112}, {"referenceID": 4, "context": "A typical example on this approach is the work of Chiu and Heung [5] who used GA to calibrate selected projects based on learning distances between them and reflect that difference on the predicted effort.", "startOffset": 65, "endOffset": 68}, {"referenceID": 1, "context": "Likewise, Azzeh [2] used Model Tree to adjust and tune selected projects.", "startOffset": 16, "endOffset": 19}, {"referenceID": 15, "context": "[17] raised an important concern regarding structure of datasets as they claim that most software cost estimation datasets do not follow uniform distribution as presumed in linear methods.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "The findings from the Li et al study are promising, but the replication study conducted by Azzeh [3] reported discouraging results where some linear adjustment methods produced more accurate results than neural networks.", "startOffset": 97, "endOffset": 100}, {"referenceID": 14, "context": "In recent years, various approaches have been proposed to specify this number such as k nearest neighbor algorithms and similarity cut off point [16][22].", "startOffset": 145, "endOffset": 149}, {"referenceID": 20, "context": "In recent years, various approaches have been proposed to specify this number such as k nearest neighbor algorithms and similarity cut off point [16][22].", "startOffset": 149, "endOffset": 153}, {"referenceID": 0, "context": "n-1 [1][2][11][15][19][24].", "startOffset": 4, "endOffset": 7}, {"referenceID": 1, "context": "n-1 [1][2][11][15][19][24].", "startOffset": 7, "endOffset": 10}, {"referenceID": 9, "context": "n-1 [1][2][11][15][19][24].", "startOffset": 10, "endOffset": 14}, {"referenceID": 13, "context": "n-1 [1][2][11][15][19][24].", "startOffset": 14, "endOffset": 18}, {"referenceID": 17, "context": "n-1 [1][2][11][15][19][24].", "startOffset": 18, "endOffset": 22}, {"referenceID": 22, "context": "n-1 [1][2][11][15][19][24].", "startOffset": 22, "endOffset": 26}, {"referenceID": 16, "context": "[18] and Walkerden and Jeffery [24] who found k=1 was the most optimum number.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[18] and Walkerden and Jeffery [24] who found k=1 was the most optimum number.", "startOffset": 31, "endOffset": 35}, {"referenceID": 17, "context": "[19] used k = 1, 2, 3 as optimum numbers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] proposes a policy that looks for only one prototype, which can be regarded as extreme when dealing with datasets as small as those in software effort estimation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "On the other hand, Azzeh [3] conducted an extensive replication study on various linear and non-linear adaptation strategies using many public datasets, and found that that k=1 was the most prominent number across all experimentations.", "startOffset": 25, "endOffset": 28}, {"referenceID": 10, "context": "[12] on the other hand proposes making predictions from the 2 nearest cases as it was found as the optimum value for the datasets of their study.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19] have increased their accuracy values with case and feature subset selection strategies.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "Besides this approach, other researchers attempted to dynamically find the optimum number of nearest analogies such as [16] and [29].", "startOffset": 119, "endOffset": 123}, {"referenceID": 27, "context": "Besides this approach, other researchers attempted to dynamically find the optimum number of nearest analogies such as [16] and [29].", "startOffset": 128, "endOffset": 132}, {"referenceID": 14, "context": "[16] proposed a method to learn the k number based by optimizing similarity threshold.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "Azzeh and Elsheikh [29] utilized bisecting k-medoid clustering to understand the structure of certain dataset and come up with best number of analogies for each test project individually.", "startOffset": 19, "endOffset": 23}, {"referenceID": 5, "context": "Recent studies arise important concerns about using MRE because it is unbalanced and yields asymmetry distribution [6][21][30].", "startOffset": 115, "endOffset": 118}, {"referenceID": 19, "context": "Recent studies arise important concerns about using MRE because it is unbalanced and yields asymmetry distribution [6][21][30].", "startOffset": 118, "endOffset": 122}, {"referenceID": 28, "context": "Recent studies arise important concerns about using MRE because it is unbalanced and yields asymmetry distribution [6][21][30].", "startOffset": 122, "endOffset": 126}, {"referenceID": 28, "context": "In this paper we used the Standardized Accuracy (SA) measure that has been proposed by Shepperd and MacDonell [30] as shown in Eq.", "startOffset": 110, "endOffset": 114}, {"referenceID": 29, "context": "In addition to the above mentioned evaluation measures, we used other three reliable evaluation measures mentioned in literature that are considerably less vulnerable to bias or asymmetry distribution as in case of MMRE [31][32].", "startOffset": 220, "endOffset": 224}, {"referenceID": 30, "context": "In addition to the above mentioned evaluation measures, we used other three reliable evaluation measures mentioned in literature that are considerably less vulnerable to bias or asymmetry distribution as in case of MMRE [31][32].", "startOffset": 224, "endOffset": 228}, {"referenceID": 30, "context": "These measures were chosen because, even though all of them were initially designed to represent how well a model performs, they can behave very differently from each other as reported in [32].", "startOffset": 188, "endOffset": 192}, {"referenceID": 4, "context": "1 Basic Concepts Optimization algorithm is a typical solution for the sophisticated problems that have many interrelated design options as encountered in software engineering tasks [5][32].", "startOffset": 181, "endOffset": 184}, {"referenceID": 30, "context": "1 Basic Concepts Optimization algorithm is a typical solution for the sophisticated problems that have many interrelated design options as encountered in software engineering tasks [5][32].", "startOffset": 184, "endOffset": 188}, {"referenceID": 34, "context": "As there are many optimization algorithms in literature, we chose Particle Swarm Optimization (PSO) for two reasons: (1) The algorithm is simple and its implementation is straightforward, (2) it showed good performance against some well-known evolutionary algorithms such as Genetics algorithm and Simulated Annealing [36][37].", "startOffset": 318, "endOffset": 322}, {"referenceID": 35, "context": "As there are many optimization algorithms in literature, we chose Particle Swarm Optimization (PSO) for two reasons: (1) The algorithm is simple and its implementation is straightforward, (2) it showed good performance against some well-known evolutionary algorithms such as Genetics algorithm and Simulated Annealing [36][37].", "startOffset": 322, "endOffset": 326}, {"referenceID": 37, "context": "It was first developed in 1995 by Kennedy and Eberhart [39].", "startOffset": 55, "endOffset": 59}, {"referenceID": 35, "context": "The popularity of PSO stems from its simplicity in performing search and especially global search since it does not need many operators for creating new solution as in evolutionary algorithms, so its implementation is straightforward [37].", "startOffset": 234, "endOffset": 238}, {"referenceID": 38, "context": "But on the other hand, this algorithm suffers from two main problems: 1) slow convergence in refined search stage, and 2) Weak local search ability [40].", "startOffset": 148, "endOffset": 152}, {"referenceID": 37, "context": "Particles then fly through the problem space by following the current optimum Particles [39].", "startOffset": 88, "endOffset": 92}, {"referenceID": 36, "context": "are kept as members of the population through the course of the run [38].", "startOffset": 68, "endOffset": 72}, {"referenceID": 0, "context": "Where 1 r and 2 r are random values [0, 1], j represents the index of the decision variable in ) (t xi \uf072 .", "startOffset": 36, "endOffset": 42}, {"referenceID": 37, "context": "It is interesting to note that a large inertia weight (W) facilitates a global search while a small inertia weight facilitates a local search [39].", "startOffset": 142, "endOffset": 146}, {"referenceID": 38, "context": "However, the classical PSO can deal efficiently when the problem has only one objective function, but when the problem has many conflicting objectives, we should use the extended version of PSO that can support multi-objective functions which is called multi-objective Particle Swarm Optimization (MOPSO) [40] as explained in the next section.", "startOffset": 305, "endOffset": 309}, {"referenceID": 38, "context": "3 Multi-Objective Particle Swarm Optimization (MOPSO) The MOSPO [40] is concerned with the problems that consists of one or more decisions and have many objectives to be optimized simultaneously.", "startOffset": 64, "endOffset": 68}, {"referenceID": 38, "context": "In this research, we used the more efficient MOPSO algorithm based on Crowding Distance (MOPSO-CD) [40].", "startOffset": 99, "endOffset": 103}, {"referenceID": 38, "context": "So instead of randomly selecting gbest from the whole solutions in the repository, it is randomly selected from the top 10% less crowded area of the repository for each Particle that is dominated by any solution located in this area [40] [41].", "startOffset": 233, "endOffset": 237}, {"referenceID": 39, "context": "So instead of randomly selecting gbest from the whole solutions in the repository, it is randomly selected from the top 10% less crowded area of the repository for each Particle that is dominated by any solution located in this area [40] [41].", "startOffset": 238, "endOffset": 242}, {"referenceID": 39, "context": "The non-dominated Particles are then selected and stored in a special repository (A) [41].", "startOffset": 85, "endOffset": 89}, {"referenceID": 39, "context": "The CD is calculated for non-dominated solution by first sorting the solutions in ascending order according to each objective function [41].", "startOffset": 135, "endOffset": 139}, {"referenceID": 39, "context": "The CD factor of first and last solution is usually equal to the maximum distance [41].", "startOffset": 82, "endOffset": 86}, {"referenceID": 38, "context": "Likewise, the value of pbest solution for each Particle is examined against current solution and the new pbest is determined based on one of three ways [40]: 1) if the pbest is dominated by current solution then the current solution is the new pbest for that Particle.", "startOffset": 152, "endOffset": 156}, {"referenceID": 39, "context": "During the update of Particles, it is important to mutate the current solution [41].", "startOffset": 79, "endOffset": 83}, {"referenceID": 0, "context": "Where: \uf0b7 R is a randomly generated bit (zero and one both have a 50% probability of being generated) \uf0b7 t is the current iteration number \uf0b7 r is a random number generated from a uniform distribution in the range [0,1] \uf0b7 b is a tunable parameter that defines the non-uniformity level of the operator.", "startOffset": 211, "endOffset": 216}, {"referenceID": 38, "context": "In this approach, the b parameter is set to 5 as suggested in [40].", "startOffset": 62, "endOffset": 66}, {"referenceID": 35, "context": "When Particles fly to find better solutions the velocity and position of the Particle is updated based on its experience and that of neighborhoods [37].", "startOffset": 147, "endOffset": 151}, {"referenceID": 36, "context": "The typical solution is to truncate the location at the exceeded boundary at this iteration and reflect the velocity in the boundary so that the particle moves away at the next generation [38].", "startOffset": 188, "endOffset": 192}, {"referenceID": 36, "context": "This technique does not necessarily alter the direction of Particle, but permitting the particle to stay in the vicinity of the boundary [38].", "startOffset": 137, "endOffset": 141}, {"referenceID": 24, "context": "Most of the methods in literature were tested on a single or a very limited number of datasets, thereby reducing the credibility of the proposed model [26].", "startOffset": 151, "endOffset": 155}, {"referenceID": 3, "context": "Specifically, these datasets come from two different sources namely, PROMISE [4] and ISBSG [7].", "startOffset": 77, "endOffset": 80}, {"referenceID": 23, "context": "Cocomo dataset enables the researchers to classify projects in terms of three different development modes: Organic, semi-detached and embedded [25].", "startOffset": 143, "endOffset": 147}, {"referenceID": 1, "context": "So we used the criteria that already utilized in our previous research which can be found in [2][29][46].", "startOffset": 93, "endOffset": 96}, {"referenceID": 27, "context": "So we used the criteria that already utilized in our previous research which can be found in [2][29][46].", "startOffset": 96, "endOffset": 100}, {"referenceID": 44, "context": "So we used the criteria that already utilized in our previous research which can be found in [2][29][46].", "startOffset": 100, "endOffset": 104}, {"referenceID": 24, "context": "The employed datasets typically contain a unique set of features that can be categorized according to four classes [26]: size features, development features, environment features and project data.", "startOffset": 115, "endOffset": 119}, {"referenceID": 10, "context": "[12] in that all features that would introduce a zero into the denominator (for a particular case) are excluded from the calculation of the adaptation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 43, "context": "The principal reason for this selection, the leave-one-out cross validation has been used in deterministic procedure that can be exactly repeated by any other research with access to a particular dataset [45].", "startOffset": 204, "endOffset": 208}, {"referenceID": 43, "context": "Also, it generates higher variance estimates than n-Fold cross validation since leave-one-out cross validation conducts more tests [45].", "startOffset": 131, "endOffset": 135}, {"referenceID": 22, "context": "Moreover, the proposed adaptation functions are compared to some well-known adaptation strategies existing in the literature such as: LSE [24], RTM [10], AQUA [16] and GA [5] in addition to the ABE0.", "startOffset": 138, "endOffset": 142}, {"referenceID": 8, "context": "Moreover, the proposed adaptation functions are compared to some well-known adaptation strategies existing in the literature such as: LSE [24], RTM [10], AQUA [16] and GA [5] in addition to the ABE0.", "startOffset": 148, "endOffset": 152}, {"referenceID": 14, "context": "Moreover, the proposed adaptation functions are compared to some well-known adaptation strategies existing in the literature such as: LSE [24], RTM [10], AQUA [16] and GA [5] in addition to the ABE0.", "startOffset": 159, "endOffset": 163}, {"referenceID": 4, "context": "Moreover, the proposed adaptation functions are compared to some well-known adaptation strategies existing in the literature such as: LSE [24], RTM [10], AQUA [16] and GA [5] in addition to the ABE0.", "startOffset": 171, "endOffset": 174}, {"referenceID": 28, "context": "5 is considered better [30].", "startOffset": 23, "endOffset": 27}, {"referenceID": 23, "context": "Presenting results without statistical significance is not convincing therefore we use win, tie, loss algorithm [25] to compare the predictive performance of the variants of adaptation methods, see Figure 8.", "startOffset": 112, "endOffset": 116}, {"referenceID": 23, "context": "Also, the win-tie-loss algorithm used Wilcoxon test in its procedure [25].", "startOffset": 69, "endOffset": 73}, {"referenceID": 23, "context": "8 Pseudo code for win, tie, loss calculation between method Methodi and Methodj based on performance measure E [25].", "startOffset": 111, "endOffset": 115}, {"referenceID": 0, "context": "Previous research studies [1][2][11][15][19][24] use limited number of analogies which is frequently less than or equal to 5 analogies.", "startOffset": 26, "endOffset": 29}, {"referenceID": 1, "context": "Previous research studies [1][2][11][15][19][24] use limited number of analogies which is frequently less than or equal to 5 analogies.", "startOffset": 29, "endOffset": 32}, {"referenceID": 9, "context": "Previous research studies [1][2][11][15][19][24] use limited number of analogies which is frequently less than or equal to 5 analogies.", "startOffset": 32, "endOffset": 36}, {"referenceID": 13, "context": "Previous research studies [1][2][11][15][19][24] use limited number of analogies which is frequently less than or equal to 5 analogies.", "startOffset": 36, "endOffset": 40}, {"referenceID": 17, "context": "Previous research studies [1][2][11][15][19][24] use limited number of analogies which is frequently less than or equal to 5 analogies.", "startOffset": 40, "endOffset": 44}, {"referenceID": 22, "context": "Previous research studies [1][2][11][15][19][24] use limited number of analogies which is frequently less than or equal to 5 analogies.", "startOffset": 44, "endOffset": 48}, {"referenceID": 30, "context": "[32] showed that using different evaluation measures behave differently therefore they could be useful to produce prediction models that present trade-off between these evaluation measures.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "It is already recognized that using subset of features would perform better than using all features in terms of evaluation measures [8].", "startOffset": 132, "endOffset": 135}, {"referenceID": 0, "context": "The importance of weighting optimization in the adaptation strategy This section concentrates on answering question RQ4 which states that: does the use of weighting values contribute towards improving prediction accuracy of the adaptation technique? It is already known that using weighting mechanism shows considerable performance when it is applied in project retrieval and some adaptation methods such as AQUA and GA [1].", "startOffset": 420, "endOffset": 423}, {"referenceID": 23, "context": "26 To summarize the results we consult win, tie, loss algorithm [25] to show the complete picture of our analysis to compare the predictive performance of the variants of Adaptation methods as suggested by Kocaguneli et al.", "startOffset": 64, "endOffset": 68}, {"referenceID": 23, "context": "[25].", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[25] results, any method is to be superior to others, should be ranked first and has a minimum number of changes in their ranks.", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "Analogy Based Effort Estimation (ABE) is one of the prominent methods for software effort estimation. The fundamental concept of ABE is closer to the mentality of expert estimation but with an automated procedure in which the final estimate is generated by reusing similar historical projects. The main key issue when using ABE is how to adapt the effort of the retrieved nearest neighbors. The adaptation process is an essential part of ABE to generate more successful accurate estimation based on tuning the selected raw solutions, using some adaptation strategy. In this study we show that there are three interrelated decision variables that have great impact on the success of adaptation method: (1) number of nearest analogies (k), (2) optimum feature set needed for adaptation, and (3) adaptation weights. To find the right decision regarding these variables, one need to study all possible combinations and evaluate them individually to select the one that can improve all prediction evaluation measures. The existing evaluation measures usually behave differently, presenting sometimes opposite trends in evaluating prediction methods. This means that changing one decision variable could improve one evaluation measure while it is decreasing the others. Therefore, the main theme of this research is how to come up with best decision variables that improve adaptation strategy and thus, the overall evaluation measures without degrading the others. The impact of these decisions together has not been investigated before, therefore we propose to view the building of adaptation procedure as a multi-objective optimization problem. The Particle Swarm Optimization Algorithm (PSO) is utilized to find the optimum solutions for such decision variables based on optimizing multiple evaluation measures. We evaluated the proposed approaches over 15 datasets and using 4 evaluation measures. After extensive experimentation we found that: (1) predictive performance of ABE has noticeably been improved, (2) optimizing all decision variables together is more efficient than ignoring any one of them. (3) Optimizing decision variables for each project individually yield better accuracy than optimizing them for the whole dataset.", "creator": "Microsoft\u00ae Word 2010"}}}