{"id": "1702.03500", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Feb-2017", "title": "Concept Drift Adaptation by Exploiting Historical Knowledge", "abstract": "Incremental learning with concept drift has often been approached through ensemble methods, where previously created models can be retrained to obtain new models for the current data. In developing ensemble methods for incremental learning with concept drift, two design questions must be addressed, i.e., which historical (i.e. previously trained) models should be preserved and how they can be used. In this paper, a novel ensemble learning method, namely diversity and transfer-based ensemble learning (DTEL), is proposed. In the light of newly obtained data, DTEL uses each historical model obtained as a starting model and continues to train it with the new data through transfer learning. In addition, DTEL maintains a diverse set of historical models rather than a set of historical models that are only accurate in terms of classification accuracy. Empirical studies on 15 synthetic data streams and 4 real data streams (all with concept drift) show that DTEL concept drift can be more effective than other state-of-the-art methods.", "histories": [["v1", "Sun, 12 Feb 2017 07:35:49 GMT  (413kb,D)", "http://arxiv.org/abs/1702.03500v1", "First version"]], "COMMENTS": "First version", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["yu sun", "ke tang", "zexuan zhu", "xin yao"], "accepted": false, "id": "1702.03500"}, "pdf": {"name": "1702.03500.pdf", "metadata": {"source": "CRF", "title": "Concept Drift Adaptation by Exploiting Historical Knowledge", "authors": ["Yu Sun", "Zexuan Zhu", "Xin Yao"], "emails": ["sunyu123@mail.ustc.edu.cn;", "ketang@ustc.edu.cn.", "zhuzx@szu.edu.cn.", "X.Yao@cs.bham.ac.uk."], "sections": [{"heading": null, "text": "Index Terms\u2014concept drift, incremental learning, ensemble learning, data stream mining, transfer learning.\nI. INTRODUCTION\nMACHINE learning tasks for which training data areavailable continuously in time have attracted growing attentions due to their wide existence in real-world scenarios, e.g., medical informatics [1], financial data analysis [2], social networks [3], et al. Incremental learning, which updates learning machines (models) when a chunk of new training data arrives, is a major learning paradigm for tackling such tasks. In particular, the learning machines should be updated without access to previous data, such that there is no need to store or re-process the previous data [4], [5].\nAssuming a number of data chunks D1 \u00b7 \u00b7 \u00b7Dt are available sequentially, the incremental learning procedure is composed of t sub-tasks, each of which can be regarded as a traditional learning task with a distinct data chunk as the training data. Although these sub-tasks can be tackled independently, i.e., training a model (e.g., a classifier) from scratch for each subtask, it is natural to ask whether the knowledge gained in one sub-task can be leveraged to benefit solving future subtasks. Ensemble methods [4], [6] offer a natural approach to\nY. Sun and K. Tang are with the USTC-Birmingham Joint Research Institute in Intelligent Computation and its Applications, School of Computer Science and Technology, University of Science and Technology of China, Hefei 230027, China. E-mail: sunyu123@mail.ustc.edu.cn; ketang@ustc.edu.cn.\nZ. Zhu is with the College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518060, China. E-mail: zhuzx@szu.edu.cn.\nX. Yao is with the Centre of Excellence for Research in Computational Intelligence and Applications (CERCIA), School of Computer Science, The University of Birmingham, Edgbaston, Birmingham B15 2TT, UK. E-mail: X.Yao@cs.bham.ac.uk.\nincremental learning, as each model obtained during the course of incremental learning could be preserved as a base learner and be utilized for solving future sub-tasks. It can be observed from the literature [7] that ensemble methods have been used frequently in many advanced incremental learning algorithms and have achieved great successes.\nIf all the data chunks are generated from the same underlying distribution, ensemble methods for incremental learning are not much different from those for traditional batch learning, i.e., different training data are fed to different base learners. However, the underlying distributions may be nonstationary in real-world applications, since the environment, where data are generated from, may change over time. For example, in the click prediction task of a news website, a breaking news may attract more attention from the visitors and the links of this news are more likely to be clicked. This phenomenon, referred to as concept drift, is one of the key challenges that incremental learning approaches [8] [9], including those based on ensembles, need to deal with. Specifically, two research questions need to be answered when designing an ensemble method for incremental learning with concept drift, i.e., which historical (i.e., previously trained) models should be preserved for future use and how to exploit the preserved models to facilitate future learning with concept drift.\nTo address the above two questions, this paper first reviews the latest progresses on ensemble methods for incremental learning, and then proposes a Diversity and Transfer based Ensemble Learning approach (DTEL). DTEL employs a decision tree as the base learner and a diversity-based strategy for preserving historical models. When a new data chunk arrives, the preserved models are exploited as \u201cinitial points\u201d for searching/training new models. Finally, the newly obtained models are combined to form the new ensemble.\nThe rest of this paper is organized as follows. Section II introduces the notations and formal definitions of the learning problem considered in this paper and reviews related work. The DTEL approach is presented in Section III. Section IV reports our empirical studies on DTEL and other state-of-theart methods. Section V concludes the paper with directions for future work."}, {"heading": "II. RELATED WORK", "text": ""}, {"heading": "A. Basic Concepts and Notations", "text": "In incremental learning, at each time step t, a chunk of data Dt = {(xt1, yt1), (xt2, yt2), \u00b7 \u00b7 \u00b7 , (xtn, ytn)}, generated from distribution pt(x, y), is received, where xti is a vector of\nar X\niv :1\n70 2.\n03 50\n0v 1\n[ cs\n.L G\n] 1\n2 Fe\nb 20\n17\n2 attribute values and yti is a class label. Concept drift can thus be defined as the change of the underlying distribution, e.g., pt(x, y) 6= pt\u22121(x, y). It should be noted that a special case of a data chunk is a single data example, which is more often referred to as online learning [10].\nAt each time step t, the learning goal of incremental learning is similar to that of batch learning, i.e., to obtain a good model Ft for pt(x, y), which can be stated as\nFt = argmin f\u2208H E(x,y)\u2208pt(x,y)[`(f(x), y)], (1)\nwhere H is the hypothesis set, E(\u00b7) denotes the expected value of a random variable, and `(\u00b7, \u00b7) is the loss function. Considering a sequence of pt(x, y), the goal of the whole incremental learning process is given by Eq. (2):\nmin F1,F2,\u00b7\u00b7\u00b7 ,Ft,\u00b7\u00b7\u00b7 \u2211 t E(x,y)\u2208pt(x,y)[`(Ft(x), y)] (2)\nFrom Eq. (2), it can be observed that at least t models will be generated during the course of incremental learning, which sets a natural basis for ensemble learning."}, {"heading": "B. Concept Drift Handling Techniques", "text": "There exist several strategies for handling concept drift in incremental learning, including a sliding window, concept drift detection and ensemble methods. The sliding window methods [11], [12], [13], which are mainly applied in the online learning scenario, preserve part of the most recently arrived data and update the current model with both the preserved data and the newly arrived training example. Some other methods [14], [15], [16] explicitly involve a concept drift detection module in the learning algorithm. If no concept drift is detected, the current model is updated with newly arrived data. Otherwise, the current model, which may be either a single learner [14] or an ensemble [16], is discarded and a new model is built from scratch.\nNeither of the above two strategies requires preserving knowledge/models obtained previously. However, one can easily imagine cases where preserving historical models would be beneficial. For example, if a previously occurred concept appears later (i.e., pt(x, y) 6= pt\u22121(x, y) and pt+1(x, y) = pt\u22121(x, y)), a historical model could be used directly. In a more general case, if two concepts are correlated but do not appear consecutively in time, it might be easier to adapt a historical model than further training the current model or building a new one. For such reasons, ensemble methods, which preserve historical models, are gaining more popularity in recent years [6], [7], [17].\nThis paper focuses on incremental learning approaches that preserve historical models and exploit them to form ensembles. Typical examples of such approaches include the Streaming Ensemble Algorithm (SEA) [6], the Temporal Inductive Transfer (TIX) approach [18], the Dynamic Integration of Classifiers (DIC) approach [19], the Learn++ algorithm [4] in Non-Stationary Environments (Learn++.NSE [17]) and Accuracy Updated Ensemble (AUE2) [7]. Although the idea of ensembles is also adopted in the Diversity for Dealing with Drifts (DDD) method [16], we distinguish it from the\nabove-mentioned ensemble methods as DDD does not preserve historical models and the ensembles used in that context could be regarded as a single model for time step t.\nDue to the concept drift, it is clear that historical models may introduce both positive and negative effects to learning the current concept. Hence, a key issue for all the above ensemble methods is how to get benefits from historical models while preventing negative effects. Suppose a new chunk of data has arrived at time step t and a pool of historical models trained in some previous time steps are available. SEA, DIC, AUE2 and Learn++.NSE exploit the historical model in a similar way. That is, the outputs of the historical models are combined with the output of a new model built using Dt to form final decisions on testing examples of the current concept. These methods differ only in the way that the outputs are combined.\nIn SEA, a simple majority voting is utilized. DIC combines the historical models with the new model Dt through Dynamic Selection (DS), Dynamic Voting (DV) or Dynamic Voting with Selection (DVS). For each testing example, its k nearest neighbors in Dt are first identified. Then, the local performance of each individual model is estimated based on these nearest training examples. For each testing example, DS chooses the individual model with the best local performance for classification. DV does not select a single model, but combines the output of all individual models using a weighted voting scheme. DVS is similar to DV, but only takes a half of the individual models that have the best local performance and applies DV to them. AUE2 also employs weighted voting as the combination scheme, where the weights assigned to individual models are determined by mean squared errors of the models. In Learn++.NSE, the weight assigned to an individual model not only depends on its performance on the current training data (as DIC and AUE2), but also depends on its performance on previous data. Specifically, the weight is dynamically adapted as the logarithm of the reciprocal of the model\u2019s error on the current and past data chunks, so that the models that performed well on the data that arrive more recently would generally be assigned larger weights when forming an ensemble for the current concept. TIX employs a different method to leverage historical models. That is, given a new chunk of training data Dt, the outputs of the historical models on Dt are used as new features of Dt, and a new model is built with the augmented Dt. If only linear models are built during the learning process, TIX could also be viewed as a special weighted voting scheme, since a linear combination of the original features of Dt can be viewed as the outputs of a linear model on the original Dt.\nPreserving historical models induces overhead in terms of both storage and computation, e.g., repeatedly assessing the performance of historical models on new training data. Hence, the number of preserved models should be subject to some constraints, instead of increasing unlimitedly. Specifically, given a predefined largest number of preserved models, a selection scheme is needed to decide which historical models should be preserved. This issue is not explicitly addressed in DIC, TIX and Learn++.NSE. Although the DS/DVS scheme of DIC and the time-adjust errors scheme of Learn++.NSE could be adapted to select historical models to preserve,\n3 the effectiveness of such adaptations have not be assessed. SEA and AUE2, in contrast, explicitly control the number of preserved models under a predefined threshold. To be specific, both SEA and AUE2 preserve all historical models if the size of the historical model set is smaller than the predefined value. Otherwise, when a new model is trained, a rule, which assesses the quality of both the preserved models and the new model, is employed to decide whether the new model should replace a previously preserved model. Both approaches measure the quality of individual models from the accuracy perspective. The difference is that SEA considers the overall accuracy of ensembles (obtained by replacing a preserved model with the new model) on the current training data, while AUE2 evaluates each individual model under consideration on the current training data directly. None of the existing ensemble methods for incremental learning has considered ensemble diversity explicitly, although diversity has been shown to play a crucial role in ensembles [20], [21]."}, {"heading": "III. THE PROPOSED APPROACH", "text": "The existing ensemble methods for incremental learning, as discussed in Section II, share a common weakness. That is, when a new data chunk arrives, all the approaches utilize the preserved historical models without adapting them to the new training data. The existing approaches differ only in the schemes for combining the outputs of the historical models to fit a new model/ensemble on the current concept. Albeit simple and easy-to-implement, using historical models without any change might not be the best way to exploit these models. Assuming a historical model is established from concept C1, which is quite different from the current concept C2, this historical model may not perform well on the current data, and a good combination scheme will reduce the effect of the historical model on the final ensemble, e.g., assign a small weight to its output. In the extreme case (a weight of 0), the knowledge contained in this historical model is not exploited at all. However, viewing concepts C1 and C2 from the same incremental learning task as the source and target domains of transfer learning [22], it is reasonable to assume that C1 and C2 are correlated with each other. Then, the historical model could still be adapted to the current concept via knowledge transfer. More importantly, an appropriate transfer learning method in this case might even benefit learning concept C2 in terms of accuracy, learning efficiency, or both. Motivated by this consideration, we propose that the historical models are employed as the initial candidate models for building models for new concepts, which is the core idea behind the DTEL approach proposed in this paper.\nThe framework of DTEL, as given in Algorithm 1, differs from the other ensemble methods for incremental learning in two aspects. First, DTEL does not directly combine the outputs of historical models. Instead, each preserved historical model is first adapted to fit the current data, and then the adapted models and the model constructed from scratch are combined, as illustrated in Fig. 1. Second, historical models are preserved according to a diversity-based criterion, rather than an accuracy-based criterion. These two key components\nAlgorithm 1 Framework of DTEL Input: (D1, D2, \u00b7 \u00b7 \u00b7 , Dt, \u00b7 \u00b7 \u00b7 ): the data stream in incremen-\ntal learning, S: a set of preserved historical models Output: Ft, the generalized ensemble model at each time\nstep t 1: while data chunk Dt is available do 2: train a new base model ft with Dt 3: obtain the transferred models f ti by transferring the preserved historical models fi \u2208 S 4: construct the ensemble model Ft with the transferred models f ti and the newly trained model ft 5: update S with ft to maximize the diversity and meet the requirement of the archive size 6: end while\n\u2026\ud835\udc37\" \ud835\udc37#$\" \ud835\udc37#\n\ud835\udc53#\ndata chunks\nmaintenance\nensemble\nlearner L\n\ud835\udc39# \ud835\udc53'\n(a) Learning flow of the traditional chunk-based ensemble methods.\nas well as concrete steps of DTEL are detailed in the following sections."}, {"heading": "A. A Diversity-based Model Preservation", "text": "Choosing historical models to preserve in the DTEL framework can be stated as a general problem of selecting m historical models out of M , where selected models will be employed as the initial models to be further trained with a new coming data chunk (possibly generated by a drifted concept) and be combined to form an ensemble. In this context, it is the performance of the adapted models after\n4 further training that matters, rather than the performance of the original models on the new-coming data chunk. It is well acknowledged in the ensemble learning literature [20], [21] that, with an appropriate combination scheme, diversity among individual models are essential. Diversity between individual models should be encouraged, which could be implemented by diverse training data, diverse initial models, different learning algorithms [20]. In fact, diversity may play an even more important role in DTEL in case of concept drift. Specifically, without prior knowledge regarding the correlations between different concepts, which are nontrivial to know in practice, a historical model that can be nicely adapted to a new data chunk may not be easily adapted to other concepts that may occur in the future. Since the combination scheme functions as a filter to prevent bad individual models deteriorating the performance of an ensemble, a good final ensemble could still be obtained as long as at least one of the preserved historical models could be adapted to the new concept. For this reason, it is desirable that the preserved historical models have sufficient diversity to deal with different concepts, instead of requiring all of them to adapt to the current concept. Therefore, DTEL employs diversity between historical models, instead of the accuracy of either individual models or the ensemble built for the current concept, as a principle for preserving historical models.\nFollowing the diversity-based principle, DTEL preserves historical models using a two-stage strategy. Let historical models be preserved in an archive of size m. When a data chunk Dt arrives at time step t, the preserved models will be tested on Dt and a new model ft will be built from scratch using Dt. The newly built model ft will be directly preserved if the archive is not full. Otherwise, ft will be temporarily incorporated into the archive. Then, the model whose removal will lead to the largest diversity between the remaining models is removed from the archive. In general, any diversity measure [21] proposed for ensemble learning could be used for this purpose. In this work, the Yules Q-statistic [23] is employed since it is one of the most popular diversity measures in the literature. Concretely, a model (either a historical or the new one) is removed to maximize Eq. (3):\ndiv(S) = 1\u2212 1\u2211 1\u2264i 6=j\u2264m 1 \u2211 1\u2264i 6=j\u2264m Q(fi, fj), (3)\nwhere Q(fi, fj) is the Q-statistic value between fi and fj , and is calculated by:\nQ(fi, fj) = N11N00 \u2212N01N10\nN11N00 +N01N10 , (4)\nwhere Nab is the number of examples for which the classification result is a by fi and b by fj , 1 represents a correct classification and 0 represents a misclassification."}, {"heading": "B. Adapting Historical Models through Knowledge Transfer", "text": "Since different learning machines have different learning mechanisms, adapting a historical model to a new data chunk is a model-dependent problem. DTEL employs decision tree as its base learner. A knowledge transfer method has been\ndesigned to adapt a previously trained decision tree to a new data chunk. Recall that the process of growing a decision tree incrementally splits the feature space into small regions. Each region corresponds to a leaf node of the tree and is assigned a class label. The structure of the tree inherently contains the knowledge learned from previous sub-tasks, while the class labels assigned to the obtained regions determine the decision boundary. Hence, the proposed knowledge transfer method aims to preserve the structure of a historical decision tree, while perturb it to fit the new data chunk. To be specific, this is done in two steps, as detailed below.\n1) Step 1: Place all of the examples in the new data chunk Dt into the leaf nodes, and reset the class labels of the nodes correspondingly. This step could be viewed as requiring the structure of the adapted decision tree to be as similar to that of the original [24], such that the knowledge contained in the original tree could be maintained. 2) Step 2: To meet the requirement of correctly classifying the data in chunk Dt, further train a sub-tree in the leaf node in which the stopping criteria has not been reached.\nIt should be noted that an adapted decision tree derives the knowledge from the current data and the corresponding historical data. Hence, it represents a hybrid knowledge which may not exactly belong to a certain data distribution in the incremental learning task. Besides, the adapted decision trees always fit the current data and are less diverse than the preserved historical trees, since the latter were built with different data chunks. For the reasons given above, the adapted trees will not be preserved, i.e., they will be discarded when the next chunk of data arrives."}, {"heading": "C. Detailed Steps of DTEL", "text": "Given the two key components described in Sections IIIA and III-B, the detailed steps of DTEL are presented in Algorithm 2. Suppose t data chunks D1 \u00b7 \u00b7 \u00b7Dt arrive sequentially. The classification and regression tree (CART) [25], is employed as the base learner in DTEL. DTEL first builds a decision tree, denoted as f1, with the first chunk of data and preserve f1 in an archive. Then, when a new data chunk, say Dt arrives, the preserved decisions tree(s) is adapted to Dt and a new decision tree ft is built from scratch based on Dt. The adapted trees and the new tree are combined to form the final ensemble for time step t. Meanwhile, the new tree ft is used to update the archive of the preserved historical models. Among the combination schemes described in Section II, the weighted voting scheme used by AUE2 is employed because AUE2 showed the best overall performance among ensemble methods for incremental learning [7]. Specifically, the weights for individual adapted trees are determined using Eq. (5). Since the new decision tree ft is treated as a \u201cperfect\u201d classifier, the weight for ft is calculated according to Eq. (6).\nwti = 1\nMSEtr + MSE t i +\n, (5)\nwt = 1\nMSEtr + , (6)\n5 Algorithm 2 DTEL Input: (D1, D2, \u00b7 \u00b7 \u00b7 , Dt, \u00b7 \u00b7 \u00b7 ): the data stream, T : model\ntransfer function, St: the historical model set at time step t, Et: the ensemble model set at time step t, m: the archive size of the historical model set, div: model maintenance function with diversity\nOutput: Ft, the generalized model at each time step t 1: while data chunk Dt is available do 2: ft \u2190 train a new base model with Dt 3: f ti \u2190 T (fi, Dt), for all fi \u2208 St 4: if |St\u22121| < m then 5: St \u2190 St\u22121 \u22c3 {ft}\n6: else 7: S \u2032 t \u2190 St\u22121 \u22c3 {ft} 8: freplace \u2190 argmaxfi div(S \u2032\nt \u2212 {fi}) 9: St \u2190 S \u2032\nt \u2212 {freplace} 10: end if 11: wti \u2190 estimate the weight for each f ti by Eq. (5) 12: wt \u2190 estimate the weight for ft by Eq. (6) 13: Ft = ( \u2211 i w t if t i + wtft)/( \u2211 i w t i + wt) 14: end while\nwhere MSEti estimates the prediction error of the adapted tree fi on data chunk Dt, MSEtr is the mean square error of a random classifier, and is a very small positive value to avoid the denominator of Eq. (5) being 0. MSEti and MSE t r are calculated as follows in Eq. (7) and (8),\nMSEti = 1 |Dt| \u2211\n{x,y}\u2208Dt\n(1\u2212 pti(y|x))2, (7)\nMSEtr = \u2211 y pt(y)(1\u2212 pt(y))2, (8)\nwhere pti(y|x) denotes the posterior probability given by adapted classifier of fi on data in chunk Dt and pt(y) denotes the prior probability of class y in Dt. The posterior probability in the tree model is calculated as the ratio of that class in the corresponding leaf node. When the archive of historical trees is full, lines 9-11 will be activated to decide whether a newly trained tree will replace a preserved tree in the archive."}, {"heading": "IV. EXPERIMENT", "text": "Empirical studies have been conducted to assess the performance of DTEL. Different types of concept drift are involved, and state-of-the-art algorithms are compared in the experiment. The algorithms are evaluated mainly from three aspects, i.e., the classification performance for each chunk, the overall performance for a whole data stream, and the time efficiency.\nThe following representative algorithms are compared in the experiments: SEA [6], Learn++.NSE [17], AUE2 [7], and TIX [18]. These approaches employ different methods for concept drift adaptation. SEA, Learn++.NSE and AUE2 are ensemble methods to exploit the historical knowledge, while TIX uses the historical knowledge by introducing it as new features in a transfer manner. SEA and Learn++.NSE use the historical model directly in an ensemble, while AUE2 updates each historical model with the new chunk of data. In addition,\nfor the weight assignment in the ensemble method, SEA uses the uniform weight, AUE2 employs the performance-based weight, and Learn++.NSE uses the time-adjusted performancebased weight.\nAll of the compared approaches are frameworks. To make the comparisons fair, the decision tree was employed as the base learner in all of these approaches. Specifically, the traditional decision tree method CART [25] is applied in SEA, Learn++.NSE, TIX, and DTEL. Since AUE2 needs to use an on-line model as the base learner, Hoeffding tree [26], an online decision tree method, was applied.\nIn SEA, AUE2, and DTEL, a limited number of historical models are preserved. The archive size of the historical model set is the only parameter to set in the experiment. According to the suggestion in [6], the ensemble size is set to 25 for the compared algorithms, unless mentioned otherwise."}, {"heading": "A. Comparison on Synthetic Data", "text": "1) Datasets: In order to comprehensively investigate the performance of DTEL, five types of concept drift were tested in the experiment. When working with synthetic data, it is known exactly what the type of concept drift is and how dramatic the data distribution changes. Hence, it is important to use the synthetic data for a detailed analysis of the approaches in concept drift adaptation. Based on the previous research [6], [7], [14], [17], [27], [28], five widely used synthetic concept drifts are employed in our experiment, described as follows. \u2022 SEA moving hyperplane concepts (SEA) [6] involves\n3 features with a value between 0 and 10. Only two features (i.e., x1 and x2) are relevant, and x3 is a noisy feature with a random value. The class label of data in this concept is determined by\nax1 + bx2 \u2264 / > \u03b8\nTo simulate the concept drift, the value of \u03b8 changes during the learning process. \u2022 Rotating concepts (ROT) [7], [17] rotates the decision boundary or data points to simulate the change of data distribution. The formulation of rotating the data point in the 2-dimensional feature space around (a, b) is shown as follow.\nx1 \u2190 (x1 \u2212 a) cos \u03b8 \u2212 (x2 \u2212 b) sin \u03b8 + a\nx2 \u2190 (x1 \u2212 a) cos \u03b8 + (x2 \u2212 b) sin \u03b8 + b\nIn the experiment, a data set with 6 classes is used as the data source, and the rotation is implemented evenly in the learning process. \u2022 Circle concepts (CIR) [14], [27] applies a circle as the decision boundary in a 2-dimensional feature space and simulates the concept drift by changing the radius of the circle, i.e.,\n(x1 \u2212 a)2 + (x2 \u2212 b)2 \u2264 / > \u03b8\nIn the experiment, data points are generated evenly locating between -5 and 5 for both dimensions, and the radius value of \u03b8 changes every 25 data chunks.\n6\nTABLE I ARTIFICIAL CONCEPT DRIFT.\nDrift Type Fixed Value Drift Value\nSEA a = 1, b = 1 \u03b8 = 10\u2192 7\u2192 3\u2192 7\u2192 10\u2192 13\u2192 16\u2192 13 \u03b8 = 10\u2192 8\u2192 6\u2192 8\u2192 10\u2192 12\u2192 14\u2192 12 ROT a = 0, b = 0 \u03b8 = 0, \u2206\u03b8 = \u03c0/30 \u03b8 = 0, \u2206\u03b8 = \u03c0/60 CIR a = 0, b = 0 \u03b8 = 3\u2192 2\u2192 1\u2192 2\u2192 3\u2192 4\u2192 5\u2192 4 \u03b8 = 3\u2192 2.5\u2192 2\u2192 2.5\u2192 3\u2192 3.5\u2192 4\u2192 3.5 SIN a = 1, b = 1, c = 0 \u03b8 = 0, \u2206\u03b8 = \u03c0/30 \u03b8 = 0, \u2206\u03b8 = \u03c0/60\nSTA c = S \u2227M \u2227 L\u22272 =1, =2, =3\n(a = R,\u22271, b = C)\u2192 (a = B,\u22281, b = C)\u2192 (a = G,\u22281, b = S)\u2192 (a = G,\u22271, b = T )\u2192 (a = G,\u22281, b = C)\u2192 (a = R,\u22281, b = S) (a = R,\u22271, b = C)\u2192 (a = B,\u22271, b = C)\u2192 (a = B,\u22281, b = C)\u2192 (a = B,\u22281, b = S)\u2192 (a = B,\u22271, b = S)\u2192 (a = G,\u22271, b = S)\n\u2022 Sine concepts (SIN) [14], [27] determines the label of data by a sine curve in a 2-dimensional feature space, which is defined as follow.\na sin(bx1 + \u03b8) + c \u2264 / > x2\nIn the experiment, all of the data locate in the area of [-5, 5] for both dimensions. The value of \u03b8 is evenly changed to generate the change of the data distribution. \u2022 STAGGER Boolean concepts (STA) [27], [28] generates the data with categorical features using a set of rules to determine the class label. According to [27] and [28], the features and values are color \u2208 {red(R), blue(B), green(G)}, shape \u2208 {circle(C), square(S), triangle(T)}, and size \u2208 {small(S), medium(M), large(L)}. The decision rules can be formulated as follow.\ny =((color =1 / 6=1 a) \u22281 / \u22271 (shape =2 / 6=2 b)) \u22282 / \u22272 (size =3 / 6=3 c)\nThe concept drift is simulated by changing the items in the rules.\nThe dramatic degree of concept drift and the size of data chunks may influence the performance of the learning algorithm. In this regard, three data streams are generated for each type of concept drift, with different dramatic degrees of concept drift and different chunk sizes. All of the synthetic data streams are generated with 120 data chunks with 10% noise introduced. The specific setting of the values for simulating the concept drifts are illustrated in Table I. The statistics of the synthetic data streams are described in Table II. For synthetic data streams, two chunks of data are generated at each learning step. The first data chunk is used for training and the other one is used to test the current prediction model.\n2) Results: In order to investigate the performance of the algorithms in concept drift adaptation, the prediction accuracy in each chunk of data are evaluated and presented in Fig. 2. Generally speaking, the accuracy result obtained from the proposed DTEL is not only the highest among the compared algorithms but also relatively stable across different synthetic data streams. Specifically, for SEA data streams (as shown in Fig. 2 (a)-(c)), DTEL performed steadily on each data chunk and was not affected by concept drifts, no matter how dramatic the concept drift is. Although AUE2 obtained the highest accuracy on several of the data chunks, it can be observed\nthat AUE2 is sensitive to the concept drift with a drop in accuracy. All of the compared algorithms are sensitive to the ROT concept drift, with a dramatic fluctuation of classification performance, as shown in Fig. 2 (d)-(f ). However, DTEL still obtained the highest accuracy on all the data chunks, which illustrates the rapid concept drift adaptation ability of DTEL. It is interesting to note that although the ROT concept drift is generated by smoothly rotating the decision boundary, the performance of the compared algorithms periodically rises and falls, instead of decaying gradually. For the CIR concept drift (Fig. 2 (g)-(i)), the performance of the compared algorithms are relatively similar. The dramatic degree of CIR concept drift appears not to influence the performance of DTEL based on the observation of results on CIR200A and CIR200G. In contrast, the other compared algorithms are affected by this type of concept drift. The results obtained from the SIN data streams (as shown in Fig. 2 (j)-(l)) also demonstrate the superiority of DTEL, which performed the best on almost all the data chunks. Different from the previously analysed data streams, STA data streams are generated from decision rules. For the results obtained from STA data streams (Fig. 2 (m)-(o)), the compared algorithms can be divided into two categories. DTEL and TIX show a high accuracy with a low variance among different data chunks, while the accuracy results of SEA, AUE2 and Learn++.NSE fluctuate dramatically and are more sensitive to this type of concept drift.\nTo quantitatively assess the performance of the compared\n7 0 30 60 90 120 Chunk Number 0.6 0.7 0.8 0.9 1 Ac cu ra cy (a) SEA200A DTEL SEA Learn++.NSE AUE2 TIX 0 30 60 90 120 Chunk Number 0.6 0.7 0.8 0.9 1 Ac cu ra cy (b) SEA200G DTEL SEA Learn++.NSE AUE2 TIX 0 30 60 90 120 Chunk Number 0.6 0.7 0.8 0.9 1 Ac cu ra cy (c) SEA500G DTEL SEA Learn++.NSE AUE2 TIX\n0 30 60 90 120 Chunk Number\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Ac cu ra cy\n(d) ROT200A\nDTEL SEA Learn++.NSE AUE2 TIX\n0 30 60 90 120 Chunk Number\n0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Ac cu ra cy\n(e) ROT200G\nDTEL SEA Learn++.NSE AUE2 TIX\n0 30 60 90 120 Chunk Number\n0.4 0.5 0.6 0.7 0.8 0.9\n1\nAc cu\nra cy\n(f) ROT500G\nDTEL SEA Learn++.NSE AUE2 TIX\n0 30 60 90 120 Chunk Number\n0.4 0.5 0.6 0.7 0.8 0.9\n1\nAc cu\nra cy\n(g) CIR200A\nDTEL SEA Learn++.NSE AUE2 TIX\n0 30 60 90 120 Chunk Number\n0.5 0.6 0.7 0.8 0.9\n1\nAc cu\nra cy\n(h) CIR200G\nDTEL SEA Learn++.NSE AUE2 TIX\n0 30 60 90 120 Chunk Number\n0.6\n0.7\n0.8\n0.9\nAc cu\nra cy\n(i) CIR500G\nDTEL SEA Learn++.NSE AUE2 TIX\n0 30 60 90 120 Chunk Number\n0.5\n0.6\n0.7\n0.8\n0.9\nAc cu\nra cy\n(j) SIN200A\nDTEL SEA Learn++.NSE AUE2 TIX\n0 30 60 90 120 Chunk Number\n0.6\n0.7\n0.8\n0.9\nAc cu\nra cy\n(k) SIN200G\nDTEL SEA Learn++.NSE AUE2 TIX\n0 30 60 90 120 Chunk Number\n0.6\n0.7\n0.8 0.9 Ac cu ra\ncy (l) SIN500G\nDTEL SEA Learn++.NSE AUE2 TIX\n0 30 60 90 120 Chunk Number\n0.3 0.4 0.5 0.6 0.7 0.8 0.9\n1\nAc cu\nra cy\n(m) STA200A\nDTEL SEA Learn++.NSE AUE2 TIX\n0 30 60 90 120 Chunk Number\n0.4 0.5 0.6 0.7 0.8 0.9\n1\nAc cu\nra cy\n(n) STA200G\nDTEL SEA Learn++.NSE AUE2 TIX\n0 30 60 90 120 Chunk Number\n0.5 0.6 0.7 0.8 0.9\n1\nAc cu\nra cy\n(o) STA500G\nDTEL SEA Learn++.NSE AUE2 TIX\nFig. 2. Accuracy results on synthetic data streams.\nalgorithms on the whole data stream, the classification accuracy of each algorithm is averaged over the data chunks in a data stream and presented in Table III. The standard deviations over data chunks, which indicates how stably an algorithm performs on a data stream, are also given. Generally, DTEL shows a clear advantage over other algorithms, in terms of high accuracy and low standard deviation on most data streams. On SEA200G, AUE2 obtained the highest accuracy, but its standard variance is higher than DTEL, which means AUE2 is more sensitive to concept drift on SEA200G than DTEL. TIX model performed the best on the STA data streams. The reason might be that the data in STA streams are generated by decision rules and the historical knowledge is represented as a new feature value in TIX. By employing decision tree as the learner, TIX can exploit the useful historical knowledge more easily with the tree structure. The Wilcoxon rank-\n8 sum test at the 95% confidence level has been conducted to check whether the differences (in terms of average accuracy) between DTEL and the compared algorithms are statistically significant, and the result is shown in the last row of Table III as the statistics of win-tie-loss. As shown in the statistical result, DTEL performed statistically significantly better than other algorithms on the synthetic data streams in pairwise comparisons. The average accuracy results in Table III further verify the detailed observation results of the performance of DTEL on each data chunk shown in Fig. 2. It can be concluded that DTEL is able to handle better the concept drift of different types and different dramatic degrees, by using the historical knowledge."}, {"heading": "B. Comparison on Real-world Data", "text": "1) Datasets: In addition to the synthetic data streams, 4 real-world data streams, namely covertype, poker hand, electricity, and click-through rate prediction data were also employed in our experiments. Details of these datasets are described as follow.\n\u2022 Covertype [29] is a real-world dataset for describing the observation of a forest area with 51 cartographic variables. Six class labels are involved to represent the corresponding forest cover type. \u2022 PokerHand [29] describes the suits and ranks of a hand of five playing cards. It involves 5 numerical features and 5 ordinal features for each example. Ten class labels exist in the dataset for describing different poker hands. \u2022 Electricity, a widely used dataset [14], [7], is collected from the New South Wales Electricity Market in Australia, containing 45,312 instances dated from 7 May 1996 to 5 December 1998. Each example is described by 8 features, and the class label identifies the change of the price (i.e., up and down). \u2022 Click-through Rate Prediction (CTRPrediction) is a dataset obtained from the Tencent company. All of the examples in the data set are in their original order collected through 30 days. After the pre-processing of the raw data, 20,000 examples are selected for each day, and totally 600,000 examples with 100 features are tested.\nThe chunk size was set to 1,000 for the first three real-world data streams. The chunk size for CTRPrediction data was set to 10,000 and each chunk of data represents half a day\u2019s observations from the real-world application. The statistics of the real-world data streams are described in Table IV. For realworld data streams, each chunk of data is first used to test the current prediction model and then to update the model in learning. Considering the chunk size is relatively large and the number of chunks in CTRPrediction data is relatively small, the ensemble size was set to 3 for all compared algorithms on this dataset.\n2) Results: The accuracy of the compared algorithms is shown in Fig. 3. Since no detailed information regarding the occurrences and behaviors of concept drift is known in the real-world data streams, it is hard to conduct an exact analysis of the adaptation ability for concept drift. Nevertheless, the\nempirical results on real-world data streams validate the conclusion drawn from the synthetic data. For the Covertype data stream (Fig. 3 (a)), DTEL showed a stable performance along the whole incremental learning process, while the compared algorithms showed an unstable classification performance, especially the SEA approach. On PokerHand data stream (Fig. 3 (b)), SEA performs better than DTEL. A possible reason is that random events may happen in poker card game and lead the data distribution in PokerHand data to be almost randomly changed, which is close to the assumption in SEA approach. On PokerHand data, DTEL generally performed more stable than AUE2 and obtained a better performance on all of the data chunks than Learn++.NSE and TIX. The data streams of Electricity are relatively hard to learn, on which the compared algorithms performed similarly and unstably. It is hard to distinguish the best performed algorithm in Fig. 3 (c). On CTRPrediction data (Fig. 3 (d)), the performance of all of the compared algorithms fluctuates dramatically and DTEL generally obtained the best accuracy on each data chunk.\nIt is worth noting that the accuracy on each chunk of CTRPrediction data may reveal an interesting rule in click habit from the website visitors. The 20,000 examples for each day are randomly extracted from the website, and each day\u2019s data are divided into two consecutive chunks in CTRPrediction. Hence, the consecutive chunks roughly embed the click habits from the first half and second half of a day, which roughly represent the working time and leisure time, respectively. From the result shown in Fig. 3 (d), it can be observed that the classification performance is distinctly different on two consecutive chunks, with a close to 100% accuracy followed by a roughly 50% one. This indicates that the click habit changes in different time spans and also reveals the difficulty in learning the dynamic real-world data.\nTable V presents the average accuracy obtained from the real-world data streams. DTEL shows a great advantage over other algorithms, which is consistent with the results obtained on the synthetic data streams. Specifically, DTEL demonstrates significantly best accuracy results on the real-world data steams, except for Electricity. AUE2 obtained the highest accuracy on the Electricity data stream. However, the value of the corresponding standard variance indicates that AUE2 is more sensitive to the concept drift in Electricity than DTEL and Learn++.NSE. Moreover, there is no statistically significant difference among the performance of the compared algorithms on the Electricity data stream.\nTo make a comprehensive comparison, a Friedman test [30] is conducted based on the average accuracy results on both synthetic data streams (Table III) and real-world data streams (Table V), as shown in Table VI. The rank values of DTEL is 1.2895 and significantly outperform others. The Friedman test result demonstrates that the proposed DTEL is significantly better than all of the compared approaches with regard to the average accuracy value.\nThe runtimes of the approaches are also compared under the same computing environment (2 CPUs of 2.4 GHz Intel Core i5, 8GB main memory) in the experiment. The time complexity of DTEL at each learning step is determined by 3 factors, i.e., the chunk size n, the data dimensionality d,\n9\nand the archive size of the historical model set m. For DTEL impelmented with decision trees, the time complexity for building a base model is O(d2n) [31]. In the transfer operation, the new chunk of data is first placed into the leaf nodes with O(n) time complexity, where the coefficient is the height of the transferred tree. Then, an update is conducted with the new chunk of data with a time complexity of roughly O(d2n). Since DTEL needs to transfer every maintained historical model with the new chunk of data, the time efficiency of DTEL is the worst among the compared approaches. The runtime results are shown in Table VII. It can be observed that DTEL takes about an order of magnitude longer time than the compared algorithms in some cases. The time consumed by the transfer operations in DTEL is also presented in Table VII, which empirically indicates that the transfer operation is time-consuming. Since all the historical models are transferred independently in DTEL, the transfer operations can be\nimplemented in a parallel processing manner. By parallelizing the transfer operations, the speed-up ratio is about m and the runtime of DTEL could be reduced by an order of magnitude to reach a satisfactory runtime level.\nC. Influence of Archive Size\nThe influence of the only parameter in DTEL, i.e., the archive size of the historical model set m, is studied. The appropriate size of the historical model set may be influenced by the data distribution and the types of concept drift in the whole incremental learning process. Five data streams (i.e., SEA200A, ROT200A, CIR200A, SIN200A, and STA200A) are used to test different sizes, and the test result is shown in Fig. 4. The data STA200A is generated from decision rules and the STA concept drift does not change the tree structure of each base model. Hence, a very small archive size is enough to facilitate the incremental learning with concept drift. Comprehensively considering the test result, when the archive size is smaller than 20, the average accuracy improves with the size increasing. Then, the accuracy results remain roughly stable when the value is larger. Hence, for practical applications, the archive size with a value bigger than 20 is recommended.\n10"}, {"heading": "V. CONCLUSIONS AND FUTURE WORK", "text": "This paper presents a new ensemble learning approach, namely DTEL, for incremental learning with concept drift. DTEL employs a diversity-based selection criterion to preserve previously trained models. Instead of being applied directly to form an ensemble for the current concept, the preserved models are further adapted to the current concept through transfer learning. Empirical studies on both synthetic and realworld data streams demonstrate the advantages of DTEL over\na number of state-of-the-art incremental learning methods. The main potential drawback of DTEL is that it is computationally more costly than the compared methods. Although this disadvantage could be alleviated by parallel implementation of DTEL since it can be naturally parallelized, it is still worth investigating other methods to reduce the complexity of DTEL. For example, it might be unnecessary for all the preserved models to be further trained. Alternatively, some heuristic rules can be designed to identify the preserved models that is most worthy of further training. Besides, this paper only considers decision tree as the base learners of DTEL. Other base learners should be investigated. Although the general framework of DTEL (as in Algorithm 1) is not restricted to decision tree, specific transfer learning (further training) methods need to be designed for different base learners. This would also be an interesting direction for research in the future."}, {"heading": "ACKNOWLEDGMENT", "text": "The authors would like to thank..."}], "references": [{"title": "Interpretability of sudden concept drift in medical informatics domain", "author": ["G. Stiglic", "P. Kokol"], "venue": "2011 IEEE 11th International Conference on Data Mining Workshops, Dec 2011, pp. 609\u2013613.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Concept drift-oriented adaptive and dynamic support vector machine ensemble with time window in corporate financial risk prediction", "author": ["J. Sun", "H. Li", "H. Adeli"], "venue": "IEEE Trans. Syst., Man, and Cybern.: Syst.,, vol. 43, pp. 801\u2013813, July 2013.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Online ensemble learning of data streams with gradually evolved classes", "author": ["Y. Sun", "K. Tang", "L.L. Minku", "S. Wang", "X. Yao"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 28, no. 6, pp. 1532\u2013 1545, June 2016.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Learn++: an incremental learning algorithm for supervised neural networks", "author": ["R. Polikar", "L. Upda", "S. Upda", "V. Honavar"], "venue": "IEEE Trans. Syst., Man, and Cybern. C, vol. 31, no. 4, pp. 497\u2013508, Nov 2001.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2001}, {"title": "Incremental learning from stream data", "author": ["H. He", "S. Chen", "K. Li", "X. Xu"], "venue": "IEEE Trans. Neural Netw., vol. 22, no. 12, pp. 1901\u20131914, Dec 2011.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1901}, {"title": "A streaming ensemble algorithm (sea) for large-scale classification", "author": ["W.N. Street", "Y. Kim"], "venue": "KDD. New York, NY, USA: ACM, 2001, pp. 377\u2013382.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "Reacting to different types of concept drift: The accuracy updated ensemble algorithm", "author": ["D. Brzezinski", "J. Stefanowski"], "venue": "IEEE Trans. Neural Netw. Learning Syst., vol. 25, no. 1, pp. 81\u201394, Jan 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "A survey on concept drift adaptation", "author": ["J. a. Gama", "I. \u017dliobait\u0117", "A. Bifet", "M. Pechenizkiy", "A. Bouchachia"], "venue": "ACM Comput. Surv., vol. 46, no. 4, pp. 44:1\u201344:37, Mar. 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "An overview of concept drift applications", "author": ["I. \u017dliobait\u0117", "M. Pechenizkiy", "J. a. Gama"], "venue": "Big Data Analysis: New Algorithms for a New Society, ser. Studies in Big Data, N. Japkowicz and J. Stefanowski, Eds. Springer International Publishing, 2016, vol. 16, pp. 91\u2013114.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Resampling-based ensemble methods for online class imbalance learning", "author": ["S. Wang", "L.L. Minku", "X. Yao"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 27, no. 5, pp. 1356\u20131368, May 2015.  11", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning in the presence of concept drift and hidden contexts", "author": ["G. Widmer", "M. Kubat"], "venue": "Machine Learning, vol. 23, no. 1, pp. 69\u2013101, 1996.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1996}, {"title": "Mining time-changing data streams", "author": ["G. Hulten", "L. Spencer", "P. Domingos"], "venue": "KDD. New York, NY, USA: ACM, 2001, pp. 97\u2013106.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2001}, {"title": "Learning from time-changing data with adaptive windowing", "author": ["R.G. Albert Bifet"], "venue": "SDM, 2006.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning with drift detection", "author": ["J. a. Gama", "P. Medas", "G. Castillo", "P. Rodrigues"], "venue": "SBIA 2004, ser. LNCS. Springer Berlin Heidelberg, 2004, vol. 3171, pp. 286\u2013295.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2004}, {"title": "Early drift detection method", "author": ["A. Bifet"], "venue": "Fourth Int\u2019l Workshop on Knowledge Discovery from Data Streams, vol. 6, 2006, pp. 77\u201386.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Ddd: A new ensemble approach for dealing with concept drift", "author": ["L. Minku", "X. Yao"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 24, no. 4, pp. 619\u2013633, April 2012.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Incremental learning of concept drift in nonstationary environments", "author": ["R. Elwell", "R. Polikar"], "venue": "IEEE Trans. Neural Netw., vol. 22, no. 10, pp. 1517\u20131531, Oct 2011.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Tackling concept drift by temporal inductive transfer", "author": ["G. Forman"], "venue": "SIGIR. New York, NY, USA: ACM, 2006, pp. 252\u2013259.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Dynamic integration of classifiers for handling concept drift", "author": ["A. Tsymbal", "M. Pechenizkiy", "P. Cunningham", "S. Puuronen"], "venue": "Information Fusion, vol. 9, no. 1, pp. 56 \u2013 68, 2008.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "Diversity creation methods: a survey and categorisation", "author": ["G. Brown", "J. Wyatt", "R. Harris", "X. Yao"], "venue": "Information Fusion, vol. 6, no. 1, pp. 5 \u2013 20, 2005, diversity in Multiple Classifier Systems.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2005}, {"title": "An analysis of diversity measures", "author": ["E.K. Tang", "P.N. Suganthan", "X. Yao"], "venue": "Machine Learning, vol. 65, no. 1, pp. 247\u2013271, 2006.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 22, no. 10, pp. 1345\u2013 1359, Oct 2010.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "On the association of attributes in statistics: With illustrations from the material of the childhood society, &c", "author": ["G.U. Yule"], "venue": "Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences, vol. 194, no. 252-261, pp. 257\u2013319, 1900.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1900}, {"title": "Classification and regression trees", "author": ["L. Breiman", "J. Friedman", "C.J. Stone", "R.A. Olshen"], "venue": "Monterey, CA: Wadsworth & Brooks/Cole Advanced Books & Software,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1984}, {"title": "Mining high-speed data streams", "author": ["P. Domingos", "G. Hulten"], "venue": "KDD. New York, NY, USA: ACM, 2000, pp. 71\u201380.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2000}, {"title": "The impact of diversity on online ensemble learning in the presence of concept drift", "author": ["L. Minku", "A. White", "X. Yao"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 22, no. 5, pp. 730\u2013742, May 2010.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Incremental learning from noisy data", "author": ["J.C. Schlimmer", "R.H. Granger", "Jr."], "venue": "Mach. Learn., vol. 1, no. 3, pp. 317\u2013354, Mar. 1986. [Online]. Available: http://dx.doi.org/10.1023/A:1022810614389", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1986}, {"title": "UCI machine learning repository", "author": ["K. Bache", "M. Lichman"], "venue": "2013. [Online]. Available: http://archive.ics.uci.edu/ml", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Statistical comparisons of classifiers over multiple data sets", "author": ["J. Dem\u0161ar"], "venue": "J. Mach. Learn. Res., vol. 7, pp. 1\u201330, Dec. 2006.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": ", medical informatics [1], financial data analysis [2], social networks [3], et al.", "startOffset": 22, "endOffset": 25}, {"referenceID": 1, "context": ", medical informatics [1], financial data analysis [2], social networks [3], et al.", "startOffset": 51, "endOffset": 54}, {"referenceID": 2, "context": ", medical informatics [1], financial data analysis [2], social networks [3], et al.", "startOffset": 72, "endOffset": 75}, {"referenceID": 3, "context": "In particular, the learning machines should be updated without access to previous data, such that there is no need to store or re-process the previous data [4], [5].", "startOffset": 156, "endOffset": 159}, {"referenceID": 4, "context": "In particular, the learning machines should be updated without access to previous data, such that there is no need to store or re-process the previous data [4], [5].", "startOffset": 161, "endOffset": 164}, {"referenceID": 3, "context": "Ensemble methods [4], [6] offer a natural approach to", "startOffset": 17, "endOffset": 20}, {"referenceID": 5, "context": "Ensemble methods [4], [6] offer a natural approach to", "startOffset": 22, "endOffset": 25}, {"referenceID": 6, "context": "It can be observed from the literature [7] that ensemble methods have been used frequently in many advanced incremental learning algorithms and have achieved great successes.", "startOffset": 39, "endOffset": 42}, {"referenceID": 7, "context": "This phenomenon, referred to as concept drift, is one of the key challenges that incremental learning approaches [8] [9], including those based on ensembles, need to deal with.", "startOffset": 113, "endOffset": 116}, {"referenceID": 8, "context": "This phenomenon, referred to as concept drift, is one of the key challenges that incremental learning approaches [8] [9], including those based on ensembles, need to deal with.", "startOffset": 117, "endOffset": 120}, {"referenceID": 9, "context": "It should be noted that a special case of a data chunk is a single data example, which is more often referred to as online learning [10].", "startOffset": 132, "endOffset": 136}, {"referenceID": 10, "context": "The sliding window methods [11], [12], [13], which are mainly applied in the online learning scenario, preserve part of the most recently arrived data and update the current model with both the preserved data and the newly arrived training example.", "startOffset": 27, "endOffset": 31}, {"referenceID": 11, "context": "The sliding window methods [11], [12], [13], which are mainly applied in the online learning scenario, preserve part of the most recently arrived data and update the current model with both the preserved data and the newly arrived training example.", "startOffset": 33, "endOffset": 37}, {"referenceID": 12, "context": "The sliding window methods [11], [12], [13], which are mainly applied in the online learning scenario, preserve part of the most recently arrived data and update the current model with both the preserved data and the newly arrived training example.", "startOffset": 39, "endOffset": 43}, {"referenceID": 13, "context": "Some other methods [14], [15], [16] explicitly involve a concept drift detection module in the learning algorithm.", "startOffset": 19, "endOffset": 23}, {"referenceID": 14, "context": "Some other methods [14], [15], [16] explicitly involve a concept drift detection module in the learning algorithm.", "startOffset": 25, "endOffset": 29}, {"referenceID": 15, "context": "Some other methods [14], [15], [16] explicitly involve a concept drift detection module in the learning algorithm.", "startOffset": 31, "endOffset": 35}, {"referenceID": 13, "context": "Otherwise, the current model, which may be either a single learner [14] or an ensemble [16], is discarded and a new model is built from scratch.", "startOffset": 67, "endOffset": 71}, {"referenceID": 15, "context": "Otherwise, the current model, which may be either a single learner [14] or an ensemble [16], is discarded and a new model is built from scratch.", "startOffset": 87, "endOffset": 91}, {"referenceID": 5, "context": "For such reasons, ensemble methods, which preserve historical models, are gaining more popularity in recent years [6], [7], [17].", "startOffset": 114, "endOffset": 117}, {"referenceID": 6, "context": "For such reasons, ensemble methods, which preserve historical models, are gaining more popularity in recent years [6], [7], [17].", "startOffset": 119, "endOffset": 122}, {"referenceID": 16, "context": "For such reasons, ensemble methods, which preserve historical models, are gaining more popularity in recent years [6], [7], [17].", "startOffset": 124, "endOffset": 128}, {"referenceID": 5, "context": "Typical examples of such approaches include the Streaming Ensemble Algorithm (SEA) [6], the Temporal Inductive Transfer (TIX) approach [18], the Dynamic Integration", "startOffset": 83, "endOffset": 86}, {"referenceID": 17, "context": "Typical examples of such approaches include the Streaming Ensemble Algorithm (SEA) [6], the Temporal Inductive Transfer (TIX) approach [18], the Dynamic Integration", "startOffset": 135, "endOffset": 139}, {"referenceID": 18, "context": "of Classifiers (DIC) approach [19], the Learn++ algorithm [4] in Non-Stationary Environments (Learn++.", "startOffset": 30, "endOffset": 34}, {"referenceID": 3, "context": "of Classifiers (DIC) approach [19], the Learn++ algorithm [4] in Non-Stationary Environments (Learn++.", "startOffset": 58, "endOffset": 61}, {"referenceID": 16, "context": "NSE [17]) and Accuracy Updated Ensemble (AUE2) [7].", "startOffset": 4, "endOffset": 8}, {"referenceID": 6, "context": "NSE [17]) and Accuracy Updated Ensemble (AUE2) [7].", "startOffset": 47, "endOffset": 50}, {"referenceID": 15, "context": "Although the idea of ensembles is also adopted in the Diversity for Dealing with Drifts (DDD) method [16], we distinguish it from the above-mentioned ensemble methods as DDD does not preserve historical models and the ensembles used in that context could be regarded as a single model for time step t.", "startOffset": 101, "endOffset": 105}, {"referenceID": 19, "context": "None of the existing ensemble methods for incremental learning has considered ensemble diversity explicitly, although diversity has been shown to play a crucial role in ensembles [20], [21].", "startOffset": 179, "endOffset": 183}, {"referenceID": 20, "context": "None of the existing ensemble methods for incremental learning has considered ensemble diversity explicitly, although diversity has been shown to play a crucial role in ensembles [20], [21].", "startOffset": 185, "endOffset": 189}, {"referenceID": 21, "context": "However, viewing concepts C1 and C2 from the same incremental learning task as the source and target domains of transfer learning [22], it is reasonable to assume that C1 and C2 are correlated with each other.", "startOffset": 130, "endOffset": 134}, {"referenceID": 19, "context": "It is well acknowledged in the ensemble learning literature [20], [21] that, with an appropriate combination scheme, diversity among individual models are essential.", "startOffset": 60, "endOffset": 64}, {"referenceID": 20, "context": "It is well acknowledged in the ensemble learning literature [20], [21] that, with an appropriate combination scheme, diversity among individual models are essential.", "startOffset": 66, "endOffset": 70}, {"referenceID": 19, "context": "Diversity between individual models should be encouraged, which could be implemented by diverse training data, diverse initial models, different learning algorithms [20].", "startOffset": 165, "endOffset": 169}, {"referenceID": 20, "context": "In general, any diversity measure [21] proposed for ensemble learning could be used for this purpose.", "startOffset": 34, "endOffset": 38}, {"referenceID": 22, "context": "In this work, the Yules Q-statistic [23] is employed since it is one of the most popular diversity measures in the literature.", "startOffset": 36, "endOffset": 40}, {"referenceID": 23, "context": "The classification and regression tree (CART) [25], is employed as the base learner in DTEL.", "startOffset": 46, "endOffset": 50}, {"referenceID": 6, "context": "Among the combination schemes described in Section II, the weighted voting scheme used by AUE2 is employed because AUE2 showed the best overall performance among ensemble methods for incremental learning [7].", "startOffset": 204, "endOffset": 207}, {"referenceID": 5, "context": "The following representative algorithms are compared in the experiments: SEA [6], Learn++.", "startOffset": 77, "endOffset": 80}, {"referenceID": 16, "context": "NSE [17], AUE2 [7], and TIX [18].", "startOffset": 4, "endOffset": 8}, {"referenceID": 6, "context": "NSE [17], AUE2 [7], and TIX [18].", "startOffset": 15, "endOffset": 18}, {"referenceID": 17, "context": "NSE [17], AUE2 [7], and TIX [18].", "startOffset": 28, "endOffset": 32}, {"referenceID": 23, "context": "Specifically, the traditional decision tree method CART [25] is applied in SEA, Learn++.", "startOffset": 56, "endOffset": 60}, {"referenceID": 24, "context": "Since AUE2 needs to use an on-line model as the base learner, Hoeffding tree [26], an online decision tree method, was applied.", "startOffset": 77, "endOffset": 81}, {"referenceID": 5, "context": "According to the suggestion in [6], the ensemble size is set to 25 for the compared algorithms, unless mentioned otherwise.", "startOffset": 31, "endOffset": 34}, {"referenceID": 5, "context": "Based on the previous research [6], [7], [14], [17], [27], [28], five widely used synthetic concept drifts are employed in our experiment, described as follows.", "startOffset": 31, "endOffset": 34}, {"referenceID": 6, "context": "Based on the previous research [6], [7], [14], [17], [27], [28], five widely used synthetic concept drifts are employed in our experiment, described as follows.", "startOffset": 36, "endOffset": 39}, {"referenceID": 13, "context": "Based on the previous research [6], [7], [14], [17], [27], [28], five widely used synthetic concept drifts are employed in our experiment, described as follows.", "startOffset": 41, "endOffset": 45}, {"referenceID": 16, "context": "Based on the previous research [6], [7], [14], [17], [27], [28], five widely used synthetic concept drifts are employed in our experiment, described as follows.", "startOffset": 47, "endOffset": 51}, {"referenceID": 25, "context": "Based on the previous research [6], [7], [14], [17], [27], [28], five widely used synthetic concept drifts are employed in our experiment, described as follows.", "startOffset": 53, "endOffset": 57}, {"referenceID": 26, "context": "Based on the previous research [6], [7], [14], [17], [27], [28], five widely used synthetic concept drifts are employed in our experiment, described as follows.", "startOffset": 59, "endOffset": 63}, {"referenceID": 5, "context": "\u2022 SEA moving hyperplane concepts (SEA) [6] involves 3 features with a value between 0 and 10.", "startOffset": 39, "endOffset": 42}, {"referenceID": 6, "context": "\u2022 Rotating concepts (ROT) [7], [17] rotates the decision boundary or data points to simulate the change of data distribution.", "startOffset": 26, "endOffset": 29}, {"referenceID": 16, "context": "\u2022 Rotating concepts (ROT) [7], [17] rotates the decision boundary or data points to simulate the change of data distribution.", "startOffset": 31, "endOffset": 35}, {"referenceID": 13, "context": "\u2022 Circle concepts (CIR) [14], [27] applies a circle as the decision boundary in a 2-dimensional feature space and simulates the concept drift by changing the radius of the circle, i.", "startOffset": 24, "endOffset": 28}, {"referenceID": 25, "context": "\u2022 Circle concepts (CIR) [14], [27] applies a circle as the decision boundary in a 2-dimensional feature space and simulates the concept drift by changing the radius of the circle, i.", "startOffset": 30, "endOffset": 34}, {"referenceID": 13, "context": "\u2022 Sine concepts (SIN) [14], [27] determines the label of data by a sine curve in a 2-dimensional feature space, which is defined as follow.", "startOffset": 22, "endOffset": 26}, {"referenceID": 25, "context": "\u2022 Sine concepts (SIN) [14], [27] determines the label of data by a sine curve in a 2-dimensional feature space, which is defined as follow.", "startOffset": 28, "endOffset": 32}, {"referenceID": 4, "context": "In the experiment, all of the data locate in the area of [-5, 5] for both dimensions.", "startOffset": 57, "endOffset": 64}, {"referenceID": 25, "context": "\u2022 STAGGER Boolean concepts (STA) [27], [28] generates the data with categorical features using a set of rules to determine the class label.", "startOffset": 33, "endOffset": 37}, {"referenceID": 26, "context": "\u2022 STAGGER Boolean concepts (STA) [27], [28] generates the data with categorical features using a set of rules to determine the class label.", "startOffset": 39, "endOffset": 43}, {"referenceID": 25, "context": "According to [27] and [28], the features and values are color \u2208 {red(R), blue(B), green(G)}, shape \u2208 {circle(C), square(S), triangle(T)}, and size \u2208 {small(S), medium(M), large(L)}.", "startOffset": 13, "endOffset": 17}, {"referenceID": 26, "context": "According to [27] and [28], the features and values are color \u2208 {red(R), blue(B), green(G)}, shape \u2208 {circle(C), square(S), triangle(T)}, and size \u2208 {small(S), medium(M), large(L)}.", "startOffset": 22, "endOffset": 26}, {"referenceID": 27, "context": "\u2022 Covertype [29] is a real-world dataset for describing the observation of a forest area with 51 cartographic variables.", "startOffset": 12, "endOffset": 16}, {"referenceID": 27, "context": "\u2022 PokerHand [29] describes the suits and ranks of a hand of five playing cards.", "startOffset": 12, "endOffset": 16}, {"referenceID": 13, "context": "\u2022 Electricity, a widely used dataset [14], [7], is collected from the New South Wales Electricity Market in Australia, containing 45,312 instances dated from 7 May 1996 to 5 December 1998.", "startOffset": 37, "endOffset": 41}, {"referenceID": 6, "context": "\u2022 Electricity, a widely used dataset [14], [7], is collected from the New South Wales Electricity Market in Australia, containing 45,312 instances dated from 7 May 1996 to 5 December 1998.", "startOffset": 43, "endOffset": 46}, {"referenceID": 28, "context": "To make a comprehensive comparison, a Friedman test [30] is conducted based on the average accuracy results on both synthetic data streams (Table III) and real-world data streams (Table V), as shown in Table VI.", "startOffset": 52, "endOffset": 56}], "year": 2017, "abstractText": "Incremental learning with concept drift has often been tackled by ensemble methods, where models built in the past can be re-trained to attain new models for the current data. Two design questions need to be addressed in developing ensemble methods for incremental learning with concept drift, i.e., which historical (i.e., previously trained) models should be preserved and how to utilize them. A novel ensemble learning method, namely Diversity and Transfer based Ensemble Learning (DTEL), is proposed in this paper. Given newly arrived data, DTEL uses each preserved historical model as an initial model and further trains it with the new data via transfer learning. Furthermore, DTEL preserves a diverse set of historical models, rather than a set of historical models that are merely accurate in terms of classification accuracy. Empirical studies on 15 synthetic data streams and 4 real-world data streams (all with concept drifts) demonstrate that DTEL can handle concept drift more effectively than 4 other state-of-the-art methods.", "creator": "LaTeX with hyperref package"}}}