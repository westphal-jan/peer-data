{"id": "1702.06510", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Feb-2017", "title": "Algorithmes de classification et d'optimisation: participation du LIA/ADOC \\'a DEFT'14", "abstract": "This year, the DEFT campaign (D\\'efi Fouilles de Textes) includes a task aimed at identifying the session in which articles from previous TALN conferences were presented. We describe the three statistical systems developed for this task at the LIA / ADOC. Combining these systems allows us to obtain interesting results (microprecise values of 0.76 measured in the test body).", "histories": [["v1", "Tue, 21 Feb 2017 18:24:52 GMT  (22kb)", "http://arxiv.org/abs/1702.06510v1", "8 pages, 3 tables, Conference paper (in French)"]], "COMMENTS": "8 pages, 3 tables, Conference paper (in French)", "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["luis adri\\'an cabrera-diego", "st\\'ephane huet", "bassam jabaian", "alejandro molina", "juan-manuel torres-moreno", "marc el-b\\`eze", "barth\\'el\\'emy durette"], "accepted": false, "id": "1702.06510"}, "pdf": {"name": "1702.06510.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Luis Adri\u00e1n Cabrera-Diego", "St\u00e9phane Huet", "Bassam Jabaian", "Alejandro Molina", "Juan-Manuel Torres-Moreno", "Marc El-B\u00e8ze"], "emails": ["cabrera@adoc-tm.com,", "bassam.jabaian@univ-avignon.fr,", "stephane.huet@univ-avignon.fr,", "juan-manuel.torres@univ-avignon.fr,", "marc.elbeze@univ-avignon.fr,", "alejandro.molina-villegas@alumni.univ-avignon.fr,", "durette@adoc-tm.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 2.\n06 51\n0v 1\n[ cs\n.I R\n] 2\nMots-cl\u00e9s : classification de textes, optimisation, similarit\u00e9.\nKeywords: text classification, optimization, similarity."}, {"heading": "1 Introduction", "text": "Dans le cadre de la conf\u00e9rence TALN 2014 1, sera organis\u00e9 en juillet 2014 \u00e0 Marseille (France) un atelier centr\u00e9 sur un d\u00e9fi qui avait pour objet la fouille de textes. Ce d\u00e9fi est la dixi\u00e8me \u00e9dition de DEFT (D\u00c9fi Fouille de Textes). De notre c\u00f4t\u00e9, il s\u2019agit de la sixi\u00e8me participation dans DEFT du Laboratoire Informatique d\u2019Avignon (LIA) 2. Cette fois-ci, le LIA a particip\u00e9 coinjointement avec l\u2019entreprise ADOC Talent Management 3.\nLa t\u00e2che 4 de DEFT a et\u00e9 d\u00e9finie comme suit 4 :\n[...Cette t\u00e2che...] se d\u00e9marque des pr\u00e9c\u00e9dentes car elle concerne les articles scientifiques pr\u00e9sent\u00e9s lors des derni\u00e8res conf\u00e9rences TALN. Le corpus se composera des articles pr\u00e9sent\u00e9s en communication orale (ni poster, ni conf\u00e9rence invit\u00e9e). Pour chaque \u00e9dition, seront fournis : un ensemble d\u2019articles (titre, r\u00e9sum\u00e9, mots-cl\u00e9s, texte), la liste des sessions scientifiques de cette \u00e9dition, et la correspondance article/session (sauf pour le test). Le corpus de test se composera d\u2019une \u00e9dition compl\u00e8te de TALN (articles et liste des sessions) pour laquelle il faudra identifier dans quelle session chaque article a \u00e9t\u00e9 pr\u00e9sent\u00e9.\nL\u2019objectif est donc de d\u00e9terminer la session scientifique dans laquelle un article de conf\u00e9rence a \u00e9t\u00e9 pr\u00e9sent\u00e9.\n1. http://www.taln2014.org/site/ 2. http://lia.univ-avignon.fr 3. http://www.adoc-tm.com/ 4. http://deft.limsi.fr/2014/index.php?id=2"}, {"heading": "2 Pr\u00e9traitement et normalisation du corpus d\u2019apprentissage", "text": "Le corpus d\u2019apprentissage pour la t\u00e2che 4 est constitu\u00e9 par l\u2019ensemble des articles scientifiques \u00e9tiquet\u00e9s par leur session et regroup\u00e9 par ann\u00e9e de publication. Pour chaque ann\u00e9e, un fichier pr\u00e9cise \u00e9galement le nombre d\u2019articles pr\u00e9sent\u00e9s par session. Les articles scientifiques \u00e0 traiter sont fournis dans des fichiers *.txt. Ils r\u00e9sultent d\u2019une extraction du texte \u00e0 partir du code source des fichiers PDF avec l\u2019outil pdftotext. Or, cette m\u00e9thode a parfois l\u2019inconv\u00e9nient de g\u00e9n\u00e9rer diff\u00e9rents types d\u2019erreurs.\nUn des probl\u00e8mes les plus r\u00e9currents est celui du codage des lettres accentu\u00e9es, le tr\u00e9ma de \u00ab \u00ef \u00bb devenant par exemple \u00ab \u0131\u00a8 \u00bb. On rencontre aussi certains probl\u00e8mes au niveau de la pr\u00e9servation de la structure du texte. En effet, une phrase peut \u00eatre d\u00e9coup\u00e9e en plusieurs lignes ou une ligne peut contenir plusieurs phrases. De la m\u00eame mani\u00e8re, des erreurs se produisent au niveau du d\u00e9coupage en paragraphes. Pour corriger ces erreurs nous utilisons les m\u00e9thodes propos\u00e9es par (Cabrera-Diego et al., 2013). Les anomalies au niveau des accents sont rep\u00e9r\u00e9es puis corrig\u00e9es \u00e0 l\u2019aide d\u2019expressions r\u00e9guli\u00e8res. En ce qui concerne la structure, nous tenons compte de la ponctuation, des majuscules et des traits d\u2019union afin de reconstituer des phrases et des paragraphes.\nD\u2019autresmanipulations s\u2019av\u00e8rent n\u00e9cessaires pour obtenir de meilleurs r\u00e9sultats. L\u2019\u00e9limination de symboles qui ne contiennent pas d\u2019information s\u00e9mantique, comme les lettres grecques (\u03a3,\u03a0,\u2206), les noms des variables (\u03bb, x, t) ou les caract\u00e8res de contr\u00f4le du document (tabulation verticale, retour chariot...). Nous avons aussi uniformis\u00e9 les diff\u00e9rents caract\u00e8res de citations (guillemets) \u00e0 un seul type et les diff\u00e9rents caract\u00e8res d\u2019union (traits d\u2019union).\nNous avons r\u00e9alis\u00e9 une analyse automatique pour identifier les diff\u00e9rentes parties de l\u2019article : titre, auteurs, r\u00e9sum\u00e9, mots-cl\u00e9s, corps et r\u00e9f\u00e9rences. Pour mener \u00e0 bien cette t\u00e2che nous avons utilis\u00e9 une m\u00e9thode similaire \u00e0 celle employ\u00e9e dans (Cabrera-Diego et al., 2013), qui consiste \u00e0 utiliser des expressions r\u00e9guli\u00e8res pour trouver les diff\u00e9rentes sections.\nLorsque l\u2019article \u00e9tait r\u00e9dig\u00e9 en anglais, nous avons utilis\u00e9 Google Traduction 5 pour les traduire automatiquement en fran\u00e7ais.\nApr\u00e8s tous ces pr\u00e9traitements, un seul fichier XML est produit avec la structure suivante 6 :\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<deftcorpus type=\"training\" year=\"2014\">\n<articles-2002>\n<article numArticle=\"taln-2002-long-007\" normalisedSession=\"syntaxe\">\n<title><![CDATA[...]]></title>\n<authors><![CDATA[...]]></authors>\n<abstract><![CDATA[...]]></abstract>\n<keywords><![CDATA[...]]></keywords>\n<body><![CDATA[...]]>\n</body>\n<biblio><![CDATA[]]>\n</biblio>\n</article>.\n...\n</articles-2002>\n...\n</deftcorpus>"}, {"heading": "3 Syst\u00e8mes du LIA", "text": "Nous avons d\u00e9velopp\u00e9 trois syst\u00e8mes ind\u00e9pendants que nous avons fusionn\u00e9s par la suite :\n1. Syst\u00e8me coll\u00e9gial ;\n2. Syst\u00e8me SimiPro ;\n3. Syst\u00e8me \u00e0 base de Champs Al\u00e9atoires Markoviens (CRF).\n5. translate.google.com. 6. Ce fichier peut \u00eatre consult\u00e9 \u00e0 l\u2019adresse : http://molina.talne.eu/deft2014training.xml"}, {"heading": "3.1 Syst\u00e8me coll\u00e9gial", "text": "Le premier syst\u00e8me du LIA r\u00e9sulte de la fusion des avis \u00e9mis par 5 juges \u00ab ind\u00e9pendants\u00bb d\u2019o\u00f9 le nom de syst\u00e8me coll\u00e9gial. Les approches qui leur sont attach\u00e9es ont d\u00e9j\u00e0 \u00e9t\u00e9 employ\u00e9es par le LIA dans diverses campagnes d\u2019\u00e9valuation comme DEFT (El-B\u00e8ze et al., 2007; Torres-Moreno et al., 2007; Bost et al., 2013), ou REPLAB (Cossu et al., 2013) et ont \u00e9t\u00e9 d\u00e9crites dans les articles qui expliquent les modalit\u00e9s de notre participation \u00e0 ces campagnes ant\u00e9rieures. Parmi les 5 juges r\u00e9unis pour participer \u00e0 DEFT 2014, on trouve une approche de type Cosine, un mod\u00e8le probabiliste de type n-gramme (avec n variable), un mod\u00e8le de Poisson, une similarit\u00e9 de type Jaccard et enfin une approche de type k plus proche voisins.\nLes param\u00e8tres de ces diff\u00e9rents juges ont \u00e9t\u00e9 entra\u00een\u00e9s en faisant de la validation croisi\u00e9e ann\u00e9e par ann\u00e9e sur le corpus d\u2019apprentissage. Ainsi le nombre de plus proches voisins a \u00e9t\u00e9 fix\u00e9 \u00e0 17 sur la globalit\u00e9 du corpus. \u00c0 l\u2019issue des d\u00e9cisions prises par les 5 juges la m\u00e9thode de fusion qui a \u00e9t\u00e9 employ\u00e9e est une fusion lin\u00e9aire.\nEnfin prenant appui sur les nombres de papiers propres \u00e0 chaque session, une r\u00e9affectation par permutations successives a \u00e9t\u00e9 effectu\u00e9e pour maximiser le jugement moyen des 5 juges. Cette m\u00e9thode ne garantit pas l\u2019obtention d\u2019un optimum global."}, {"heading": "3.2 Syst\u00e8me SimiPro", "text": "Dans une conf\u00e9rence scientifique les articles accept\u00e9s sont regroup\u00e9s en sessions. Les articles ayant une th\u00e9matique similaire sont r\u00e9unis dans une m\u00eame session. Le LIA et ADOC Talent Management ont abord\u00e9 la t\u00e2che 4 comme une t\u00e2che de similarit\u00e9 entre une repr\u00e9sentation synth\u00e9tique de chaque session et une repr\u00e9sentation synth\u00e9tique de chaque article. Dans la suite du propos, nous appellerons ces repr\u00e9sentations respectivement \u00ab profil d\u2019article \u00bb (Pa) et \u00ab profil de session \u00bb (Ps). Dans ce travail, un profil est l\u2019ensemble de mots-cl\u00e9s qui repr\u00e9sentent la th\u00e9matique abord\u00e9e. Les profils des sessions et des articles sont compar\u00e9s en utilisant la distance cosinus. L\u2019analyse de ces distances permet de classer les articles dans les sessions. Notre syst\u00e8me est compos\u00e9 de quatre grandes \u00e9tapes qui sont expliqu\u00e9es ci-apr\u00e8s et sont appliqu\u00e9es sur le corpus de test et d\u2019apprentissage.\nLa premi\u00e8re \u00e9tape est la lemmatisation et l\u2019\u00e9tiquetage morpho-syntaxique du corps des articles et des mots-cl\u00e9s indiqu\u00e9s par leurs auteurs. Son but est d\u2019utiliser la forme canonique des mots et leur cat\u00e9gorie grammaticale dans les \u00e9tapes suivantes. Cette \u00e9tape est r\u00e9alis\u00e9e \u00e0 l\u2019aide du logiciel Freeling 3.1 (Padr\u00f3 & Stanilovsky, 2012) pour le fran\u00e7ais.\nLa deuxi\u00e8me \u00e9tape consiste \u00e0 rechercher des s\u00e9quences de mots (c = m1 m2 . . . mj) susceptibles de constituer des mots-cl\u00e9s, c\u2019est-\u00e0-dire des n-grammes de mots qui par leurs caract\u00e9ristiques peuvent repr\u00e9senter les principales th\u00e9matiques. Notre syst\u00e8me utilise les cat\u00e9gories grammaticales identifi\u00e9es par Freeling pour r\u00e9aliser un d\u00e9coupage du texte. Ce d\u00e9coupage est r\u00e9alis\u00e9 au niveau des mots qui, de par leur cat\u00e9gorie grammaticale, sont peu susceptibles de constituer des mot-cl\u00e9s. Plus sp\u00e9cifiquement, le d\u00e9coupage est r\u00e9alis\u00e9 au niveau des verbes, des adverbes, des noms propres, des quantit\u00e9s, des conjonctions, des interjections, des dates et de la ponctuation 7. La m\u00e9thode appliqu\u00e9e ici est similaire \u00e0 celle utilis\u00e9e par le syst\u00e8me d\u2019extraction terminologique LEXTER (Bourigault, 1994). Pour r\u00e9duire encore le nombre de mots-cl\u00e9s candidats, nous d\u00e9coupons \u00e9galement le texte au niveau des mots vides. Ce d\u00e9coupage a comme exception l\u2019article \u00ab le \u00bb et la pr\u00e9position \u00ab de \u00bb quand ils ne se trouvent pas aux extr\u00e9mit\u00e9s d\u2019une s\u00e9quence de mots 8. Un dernier filtre supprime les s\u00e9quences de plus de 4 mots.\nLa troisi\u00e8me \u00e9tape de SimiPro est le classement par pertinence des s\u00e9quences de mots d\u2019un article trouv\u00e9es dans l\u2019\u00e9tape ant\u00e9rieure. Nous utilisons pour cela une version modifi\u00e9e de l\u2019algorithme Rapid Automatic Keyword Extraction que nous avons r\u00e9alis\u00e9e pour DEFT 2014 de mani\u00e8re individuelle sur le corps de chaque article. La version originale de cet algorithme, appel\u00e9 \u00e9galement RAKE, est d\u00e9crite dans (Rose et al., 2010). L\u2019algorithme RAKE calcule le degr\u00e9 de cooccurrence de chaque mot et leur nombre d\u2019occurrences. Puis, il donne un poids P(m) \u00e0 chaque mot m en utilisant la formule suivante :\nP (m) =\n{\ndeg(m) f(m) si f(m) > 1 deg(m) F si f(m) = 1 (1)\no\u00f9 deg(m) est le degr\u00e9 de co-occurence dem, f(m) le nombre d\u2019occurrences dem dans le texte et F le nombre de mots dans le texte. Ensuite, pour chaque s\u00e9quence de mots, c = m1 m2 . . . mj , dans le texte, RAKE attribue le score S(c)\n7. Freeling a la classe \u00ab F \u00bb pour repr\u00e9senter les symboles utilis\u00e9s dans la ponctuation. 8. Ces exceptions permettent au syst\u00e8me de g\u00e9n\u00e9rer des s\u00e9quences de mots comme \u00ab extraction de information \u00bb et \u00ab traitement de le parole \u00bb.\nsuivant :\nS(c) =\n\u2211j\ni=1 P(mi)\nj . (2)\nNotre version modifi\u00e9e de RAKE donne des scores plus homog\u00e8nes pour les s\u00e9quences les plus petites 9 ainsi que celles contenant des mots qui n\u2019appara\u00eessent qu\u2019une seule fois 10.\nLa quatri\u00e8me \u00e9tape de SimiPro est la cr\u00e9ation des profils. Cette \u00e9tape varie selon que l\u2019on consid\u00e8re la phase d\u2019apprentissage ou la phase de test. Pendant la phase d\u2019apprentissage, le syst\u00e8me g\u00e9n\u00e8re des profils de session. Pour cr\u00e9er un profil de session, SimiPro consid\u00e8re tous les mots-cl\u00e9s des articles affect\u00e9s \u00e0 une m\u00eame session, ind\u00e9pendamment de l\u2019ann\u00e9e, pour g\u00e9n\u00e9rer une liste de mots-cl\u00e9s L. Le syst\u00e8me somme les scores des mots-cl\u00e9s apparaissant plusieurs fois. Le syst\u00e8me cr\u00e9e autant de listes L que de sessions. Pendant la phase de test, SimiPro g\u00e9n\u00e8re les profils des articles par ann\u00e9e. Dans ce cas, le syst\u00e8me d\u00e9bute en consid\u00e9rant l\u2019ensemble de mots-cl\u00e9s de chaque article comme une liste L.\nPour chacun des mots-cl\u00e9s dans les listes L g\u00e9n\u00e9r\u00e9es pr\u00e9c\u00e9demment selon la phase, le syst\u00e8me applique une mesure bas\u00e9e sur le TF-IDF. La formule est la suivante :\nV(c) = S(c) \u2217 log\n(\nN\nn\n)\n(3)\no\u00f9 c est la s\u00e9quence de mots, V le nouveau score de c, S le score de c donn\u00e9 par RAKE, N le nombre de documents dans la session dans la phase d\u2019apprentissage, ou dans l\u2019ann\u00e9e dans la phase de test. La variable n est le nombre de documents de la session ou de l\u2019ann\u00e9e o\u00f9 c appara\u00eet selon le cas.\nPour filtrer plus facilement les valeurs deV avec un seuil entre 0 et 1, nous avons d\u00e9cid\u00e9 d\u2019appliquer deux types de normalisations. Le syst\u00e8me commence par une normalisation cosinus (Salton & Buckley, 1988). Chaque liste L est consid\u00e9r\u00e9e comme un vecteur l\u0304 dans le mod\u00e8le vectoriel. Pour chaque vecteur l\u0304, le syst\u00e8me obtient leur norme ||l\u0304||. Puis, SimiPro calcule leur vecteur unitaire l\u0304u = l\u0304/||l\u0304||. Ce vecteur unitaire a comme composantes les scores normalis\u00e9sVn. La deuxi\u00e8me normalisation divise les valeurs de chaque composantes de l\u0304u par la valeur maximale de toutes les composants du vecteur afin d\u2019obtenir un score,Vn2, compris 0 et 1 et ayant une m\u00eame \u00e9chelle pour tous les mots-cl\u00e9s de toutes les listes. \u00c0 l\u2019issue de cette phase de normalisation, les mots-cl\u00e9s des auteurs sont ajout\u00e9s aux listes normalis\u00e9es avec un score de 1.\nLe profil d\u2019une session, Ps, ou d\u2019un article Pa, selon le cas, est g\u00e9n\u00e9r\u00e9 \u00e0 partir de leur liste respective de mots-cl\u00e9s normalis\u00e9e. Seules les s\u00e9quences de mots qui ont une valeur Vn2 sup\u00e9rieure ou \u00e9gale \u00e0 0,50 sont prises en compte.\nPendant la phase de test et une fois les profils des articles cr\u00e9\u00e9s, SimiPro d\u00e9bute la classification des articles parmi les sessions. Le syst\u00e8me charge, premi\u00e8rement, les profils Pa des articles \u00e0 classer d\u2019une ann\u00e9e d\u00e9termin\u00e9e. Puis, il charge les profils Ps des sessions correspondant \u00e0 cette m\u00eame ann\u00e9e 11. Dans le cas d\u2019une nouvelle session n\u2019ayant pas d\u2019\u00e9quivalent dans le corpus d\u2019apprentissage, le syst\u00e8me cr\u00e9e un profil en utilisant l\u2019algorithme suivant : 1/ Le nom de la session s est lemmatis\u00e9 avec Freeling et est consid\u00e9r\u00e9 comme un mot-cl\u00e9 d\u2019un nouveau profil du type Ps. Si s est multi-mots, on prend \u00e9galement le premier et le dernier mot (par exemple : d\u00e9tection de th\u00e8mes\u2192 d\u00e9tection, th\u00e8mes ; taln pour le tic \u2192 taln, tic). 2/ On s\u00e9lectionne les profils de session contenant s. 3/ Le syst\u00e8me cherche s dans tous les profils Ps cr\u00e9\u00e9s pendant l\u2019apprentissage. Il g\u00e9n\u00e8re la liste A contenant les sessions o\u00f9 s a \u00e9t\u00e9 trouv\u00e9e et la liste B contenant les s\u00e9quences de mots contenant s. 4/ La liste B de mots-cl\u00e9s est ajout\u00e9e au nouveau profil. 5/ On croise les mots cl\u00e9s de tous les profils de la liste A et on conserve tous les mots-cl\u00e9s apparaissant plus d\u2019une fois.\nD\u00e8s que SimiPro a charg\u00e9 tous les profils, le syst\u00e8me calcule la similarit\u00e9 entre les profils de sessions Ps et les profils d\u2019articles Pa. Ce calcul est r\u00e9alis\u00e9 en utilisant la mesure cosinus. Les articles sont finalement class\u00e9s parmi les sessions par ordre d\u00e9croissant de score de similarit\u00e9 en prenant en compte les contraintes fournies concernant le nombre d\u2019articles par sessions."}, {"heading": "3.3 Syst\u00e8me bas\u00e9 sur les CRF", "text": "Les CRF (\u00abConditional Random Fields \u00bb ou \u00abChamps Al\u00e9atoires Markoviens\u00bb) sont une famille de mod\u00e8les graphiques introduite par (Lafferty et al., 2001). Ils ont le plus souvent \u00e9t\u00e9 utilis\u00e9s dans le domaine du traitement automatique des langues, pour \u00e9tiqueter des s\u00e9quences d\u2019unit\u00e9s linguistiques. Ces mod\u00e8les poss\u00e8dent \u00e0 la fois les avantages des mod\u00e8les g\u00e9n\u00e9ratifs et des mod\u00e8les discriminants de l\u2019\u00e9tat de l\u2019art. En effet, comme les classifieurs discriminants, ils peuvent\n9. Dans la version originale les s\u00e9quences les plus grandes ont par construction les scores les plus hauts. 10. De m\u00eame, les s\u00e9quences contenant des mots qui n\u2019appara\u00eessent qu\u2019une seule fois ont, par construction, un score \u00e9lev\u00e9 dans RAKE. 11. Pour chaque ann\u00e9e dans le corpus de test les organisateurs ont fournis le nom des sessions et le nombre d\u2019articles par session.\nmanipuler un grand nombre de descripteurs, et comme les mod\u00e8les g\u00e9n\u00e9ratifs, ils int\u00e8grent des d\u00e9pendances entre les \u00e9tiquettes de sortie et prennent une d\u00e9cision globale sur la s\u00e9quence.\nLa repr\u00e9sentation de ces mod\u00e8les est d\u00e9crite comme une probabilit\u00e9 conditionnelle d\u2019une s\u00e9quence de concept C = c1, ..., cT \u00e9tant donn\u00e9e une s\u00e9quence de motsW = w1, ..., wT . Cette probabilit\u00e9 peut \u00eatre calcul\u00e9e comme suit :\nP (C|W ) = 1\nZ\nT \u220f\nt=1\nH(ct\u22121, ct, \u03c6(w N 1 , n))\navec\nH(ct\u22121, ct, \u03c6(w N 1 , n)) = exp(\nM \u2211\nm=1\n\u03bbm \u00b7 hm(ct\u22121, ct, \u03c6(w N 1 , n)))\nH est un mod\u00e8le log-lin\u00e9aire fond\u00e9 sur des fonctions caract\u00e9ristiques hm(ct\u22121, ct, \u03c6(wN1 , n)) qui repr\u00e9sentent l\u2019information extraite du corpus d\u2019apprentissage. Cela peut \u00eatre par exemple wt+2t\u22122 repr\u00e9sentant une fen\u00eatre de voisinage de taille 2 autour du mot courant. Les poids \u03bb du mod\u00e8le log-lin\u00e9aire sont estim\u00e9s lors de l\u2019apprentissage et Z est un terme de normalisation appris au niveau de phrases.\nAfin de b\u00e9n\u00e9ficier des avantages de ces classifieurs discriminants, nous avons propos\u00e9 de consid\u00e9rer la t\u00e2che 4 de DEFT comme un probl\u00e8me d\u2019\u00e9tiquetage d\u2019un document source, sauf que les \u00e9tiquettes possibles sont toutes les sessions de la conf\u00e9rence.\nL\u2019apprentissage d\u2019un mod\u00e8le CRF n\u00e9cessite des donn\u00e9es annot\u00e9es (\u00e9tiquet\u00e9es) au niveau des mots, ainsi chaque mot de chaque article repr\u00e9sente une observation pour le mod\u00e8le. Consid\u00e9rer la totalit\u00e9 de l\u2019article pour la construction du mod\u00e8le CRF peut \u00eatre tr\u00e8s co\u00fbteux en terme de complexit\u00e9 d\u2019autant plus qu\u2019un bruit important peut \u00eatre int\u00e9gr\u00e9 dans le mod\u00e8le \u00e0 cause du nombre important de mots communs entre diff\u00e9rents articles de diff\u00e9rentes sessions. Pour minimiser ce bruit, nous avons fait le choix de s\u00e9lectionner l\u2019information \u00e0 prendre en compte dans le mod\u00e8le et donc pour chaque article seules les donn\u00e9es li\u00e9es aux titre, r\u00e9sum\u00e9, noms d\u2019auteurs et mots-cl\u00e9s sont prises en compte.\nPour l\u2019apprentissage, nous consid\u00e9rons uniquement les articles appartenant \u00e0 des sessions pr\u00e9sentes parmi les sessions du test. Cette r\u00e8gle, qui a pour but d\u2019emp\u00eacher l\u2019\u00e9tiquetage d\u2019un article par une session non attendue dans le test, \u00e9limine une part tr\u00e8s importante des donn\u00e9es d\u2019apprentissage. Pour \u00e9viter cette \u00e9limination massive, une projection de sessions vers des sessions similaires a \u00e9t\u00e9 r\u00e9alis\u00e9e. Par exemple la session \u00ab traduction|alignement\u00bb est remplac\u00e9e par \u00ab alignement \u00bb, \u00ab recherche d\u2019information\u00bb est projet\u00e9e vers \u00ab extraction d\u2019information\u00bb.\nL\u2019outil Wapiti (Lavergne et al., 2010) a \u00e9t\u00e9 utilis\u00e9 pour apprendre les mod\u00e8les CRF en consid\u00e9rant des fonctions (features) uni-grammes avec une fen\u00eatre de voisinage de taille 2 autour du mot courant et des fonctions bi-grammes. L\u2019algorithme de descente de gradient a \u00e9t\u00e9 appliqu\u00e9 pour optimiser les poids du mod\u00e8le.\nUne fonction uni-gramme permet de prendre en compte une seule \u00e9tiquette \u00e0 la fois caract\u00e9risant l\u2019association du mot et de l\u2019\u00e9tiquette. Les fonctions bi-grammes portent sur un couple d\u2019\u00e9tiquettes successives. Ce type de fonction permet par exemple d\u2019apprendre des informations sur une liste de mots-cl\u00e9s ou sur les coauteurs d\u2019une session donn\u00e9e.\nPour le test, nous avons consid\u00e9r\u00e9 le m\u00eame type d\u2019information que pour l\u2019apprentissage du mod\u00e8le (titre, r\u00e9sum\u00e9, auteurs et mots-cl\u00e9s). Lors du d\u00e9codage, le mod\u00e8le attribue \u00e0 chaque mot une \u00e9tiquette avec un score de probabilit\u00e9. Pour un article donn\u00e9, la somme des log-probabilit\u00e9s des mots \u00e9tiquet\u00e9s par la m\u00eame session a \u00e9t\u00e9 calcul\u00e9e et l\u2019article est affect\u00e9 \u00e0 la session qui correspond \u00e0 la somme maximale de ces log-probabilit\u00e9s."}, {"heading": "3.4 Fusion et optimisation", "text": "Les trois syst\u00e8mes pr\u00e9c\u00e9dents fournissent un score s(k)ij d\u2019association d\u2019un article i \u00e0 une session j. De mani\u00e8re \u00e0 faciliter leur combinaison, les scores de chaque syst\u00e8me k sont normalis\u00e9s entre 0 et 1. Les r\u00e9sultats produits par les trois syst\u00e8mes sont combin\u00e9s \u00e0 l\u2019aide d\u2019une interpolation lin\u00e9aire :\nsij =\n3 \u2211\nk=1\n\u03bbks (k) ij . (4)\nLes poids \u03bbk sont optimis\u00e9s \u00e0 l\u2019aide d\u2019une recherche sur grille avec des pas de 0,05 pour maximiser la macro-pr\u00e9cision sur un corpus d\u00e9veloppement, en retenant pour chaque article i la session j qui obtient le meilleur score sij .\nLa t\u00e2che 4 de DEFT, pour laquelle sont fournis le nombre d\u2019articles nj par session j, peut \u00eatre vue comme un probl\u00e8me d\u2019optimisation lin\u00e9aire discr\u00e8te (OLD) consistant \u00e0 trouver les valeurs xij satisfaisant la fonction objectif (5).\nmax\nm \u2211\ni=1\nn \u2211\nj=1\nxijsij (5)\nn \u2211\nj=1\nxij = 1 i = 1...m (6)\nm \u2211\ni=1\nxij = nj j = 1...n (7)\nxij \u2208 {0, 1} i = 1...m, j = 1...n\nLes contraintes (6) s\u2019assurent que chaque article i n\u2019est associ\u00e9 qu\u2019\u00e0 une seule session, tandis que les \u00e9galit\u00e9s (7) repr\u00e9sentent les contraintes quant au nombre d\u2019articles par session. Nous avons employ\u00e9 cette mod\u00e9lisation not\u00e9e OLD en post-traitement de chaque syst\u00e8me ou de leur combinaison par interpolation lin\u00e9aire. Par rapport \u00e0 la m\u00e9thode classique ne retenant que la session j qui maximise un score sij pour chaque article i ind\u00e9pendamment des autres articles, l\u2019optimisation lin\u00e9aire permet de prendre une d\u00e9cision au niveau d\u2019une ann\u00e9e. Le probl\u00e8me OLD est r\u00e9solu \u00e0 l\u2019aide de l\u2019algorithme du simplexe."}, {"heading": "4 Exp\u00e9riences sur le d\u00e9veloppement", "text": "Les articles fournis pour les ann\u00e9es 2008 et 2011 ont \u00e9t\u00e9 utilis\u00e9s comme corpus de d\u00e9veloppement pour r\u00e9gler les diff\u00e9rentes param\u00e8tres de nos syst\u00e8mes et les poids \u03bbi du mod\u00e8le d\u2019interpolation lin\u00e9aire. Le tableau 1 reporte les r\u00e9sultats obtenus sur 2008 et 2011.\nLa comparaison des colonnes 2 et 3 d\u2019une part et 4 et 5 d\u2019autre part montrent que la prise en compte des contraintes sur le nombre d\u2019article gr\u00e2ce \u00e0 l\u2019optimisation lin\u00e9aire discr\u00e8re am\u00e9liorent les r\u00e9sultats pour tous les syst\u00e8mes \u00e0 l\u2019exception de SimiPro et de la fusion pour l\u2019ann\u00e9e 2011.\nLes poids utilis\u00e9s pour combiner les syst\u00e8mes sur 2008 et 2011 sont respectivement indiqu\u00e9es aux colonnes 2 et 3 de la derni\u00e8re ligne du tableau 1 et montrent une grande variabilit\u00e9 entre ces deux corpus. Cette instabilit\u00e9 entre les deux ann\u00e9es se refl\u00e8te dans les valeurs de macro-pr\u00e9cision obtenu par la combinaison (derni\u00e8re ligne) qui ne sont sup\u00e9rieures au meilleur syst\u00e8me que pour l\u2019ann\u00e9e 2011 sans le post-traitement OLD.\nLes poids finalement retenus pour le corpus de test (\u03bbk : 0,1 ; 0,8 ; 0,1) sont optimis\u00e9s sur l\u2019ensemble des articles de 2008 et 2011 pour augmenter la g\u00e9n\u00e9ralisation du mod\u00e8le de combinaison.\n5 R\u00e9sultats\nSur la t\u00e2che 4 il y a eu 5 participants pour un total de 13 soumissions. Les syst\u00e8mes ont \u00e9t\u00e9 \u00e9valu\u00e9s en utilisant les mesures propos\u00e9es par DEFT. Les cinq meilleures soumissions varient (la meilleure de chaque \u00e9quipe) de 0,2778 \u00e0 1,000 (mesure : pr\u00e9cision \u00e0 1). Moyenne=0,5926 ; M\u00e9diane=0,4815 ; \u00c9cart-type=0,2860.\nLe tableau 2 pr\u00e9sente nos r\u00e9sultats obtenus sur le corpus de test. Nous constatons que l\u2019optimisation lin\u00e9aire discr\u00e8te permet des gains, notamment lors de la fusion de nos trois syst\u00e8mes (+0,19 points au niveau de la macro-pr\u00e9cision).\nPour la campagne, trois syst\u00e8mes ont \u00e9t\u00e9 soumis : le r\u00e9sultat de la fusion avec optimisation lin\u00e9aire discr\u00e8te (Tableau 3, ligne 1), le syst\u00e8me SimiPro avec optimisation lin\u00e9aire discr\u00e8te (ligne 2) et le syst\u00e8me coll\u00e9gial avec une optimisation locale par permutation (ligne 3). Comme attendu, la fusion conduit aux meilleurs r\u00e9sultats, m\u00eame si ceux-ci restent tr\u00e8s proches du syst\u00e8me coll\u00e9gial."}, {"heading": "6 Conclusions et travail futur", "text": "Malgr\u00e9 les diff\u00e9rences entre le corpus d\u2019apprentissage et le test, notamment au niveau du nom des sessions, nos algorithmes ont conduit \u00e0 des r\u00e9sultats tr\u00e8s int\u00e9ressants, bien au dessus de la moyenne des participants. La fusion s\u2019est aver\u00e9e une strat\u00e9gie performante, car elle a su combiner les r\u00e9sultats des 3 syst\u00e8mes, en surpassant ceux du meilleur d\u2019entre eux. Par manque de temps, nous n\u2019avons pas int\u00e9gr\u00e9 d\u2019autres composants TAL dans nos approches (entit\u00e9s nomm\u00e9es, resum\u00e9 automatique, etc). Nous pensons qu\u2019un syst\u00e8me de r\u00e9sum\u00e9 automatique guid\u00e9 (Favre et al., 2006; Torres-Moreno, 2011) pourrait \u00eatre utilis\u00e9 dans ce cadre de mani\u00e8re \u00e0 mieux cibler les passages contenant les mots-cl\u00e9s. \u00c9galement, nous consid\u00e9rons que l\u2019extraction de mots-cl\u00e9s pourrait \u00eatre effectu\u00e9e en utilisant des algoritmes performants bas\u00e9s sur les graphes (Mihalcea & Tarau, 2004).\nRemerciements\nNous voulons remercier l\u2019ANRT par le financement de la convetion CIFRE n\u25e6 2012/0293b entre ADOC Talent Management et l\u2019Universit\u00e9 d\u2019Avignon et des Pays de Vaucluse, ainsi que le Consejo Nacional de Ciencia y Tecnolog\u00eda (CONACyT) du Mexique (bourse n\u25e6 327165).\nR\u00e9f\u00e9rences\nBOST X., BRUNETTI I., CABRERA-DIEGO L. A., COSSU J.-V., LINHARES A., MORCHID M., TORRES-MORENO J.-M., EL-B\u00c8ZE M. & DUFOUR R. (2013). Syst\u00e8mes du LIA \u00e0 DEFT\u201913. In Actes du neuvi\u00e8me D\u00e8fi Fouille de Textes, p. 41\u201361 : DEFT/TALN.\nBOURIGAULT D. (1994). Lexter : un Logiciel d\u2019EXtraction de TERminologie : application \u00e0 l\u2019acquisition des connaissances \u00e0 partir de textes. PhD thesis, EHESS.\nCABRERA-DIEGO L. A., TORRES-MORENO J.-M. & EL-B\u00c8ZE M. (2013). SegCV : traitement efficace de CV avec analyse et correction d\u2019erreurs. In F. BOUDIN & L. BARRAULT, Eds., Actes de TALN-RECITAL 2013 (Traitement automatique des langues naturelles), Les Sables d\u2019Olonne : ATALA.\nCOSSU J.-V., BIGOT B., BONNEFOY L., MORCHID M., BOST X., SENAY G., DUFOUR R., BOUVIER V., TORRESMORENO J.-M. & EL-B\u00c8ZE M. (2013). LIA@RepLab 2013. In The CLEF Initiative : CLEF.\nEL-B\u00c8ZE M., TORRES-MORENO J.-M. & B\u00c9CHET F. (2007). Un duel probabiliste pour d\u00e9partager deux Pr\u00e9sidents. RNTI coming soon, p. 1889\u20131918.\nFAVRE B., B\u00c9CHET F., BELLOT P., BOUDIN F., EL-B\u00c8ZE M., GILLARD L., LAPALME G. & TORRES-MORENO J.-M. (2006). The LIA-Thales summarization system at DUC-2006. In Document Understanding Conference (DUC) 2006, p. 131\u2013138 : NIST.\nLAFFERTY J., MCCALLUM A. & PEREIRA F. (2001). Conditional random fields : Probabilistic models for segmenting and labeling sequence data. In The International Conference on Machine Learning (ICML), p. 282\u2013289, Williamstown, USA : Morgan Kaufmann.\nLAVERGNE T., CAPP\u00c9 O. & YVON F. (2010). Practical Very Large Scale CRFs. In The Annual Meeting of the Association for Computational Linguistic (ACL), p. 504\u2013513, Uppsala, Sweden : ACL.\nMIHALCEA R. & TARAU P. (2004). Textrank : Bringing order into texts. Proceedings of EMNLP, 4(4), 275.\nPADR\u00d3 L. & STANILOVSKY E. (2012). Freeling 3.0 : Towards wider multilinguality. In Proceedings of the Language Resources and Evaluation Conference (LREC 2012), Istanbul, Turkey : ELRA.\nROSE S., ENGEL D., CRAMER N. & COWLEY W. (2010). Automatic Keyword Extraction from Individual Documents, In M. W. BERRY & J. KOGAN, Eds., Text Mining, p. 1\u201320. John Wiley & Sons, Ltd.\nSALTON G. & BUCKLEY C. (1988). Term-weighting approaches in automatic text retrieval. Information processing & management, 24(5), 513\u2013523.\nTORRES-MORENO J.-M. (2011). R\u00e9sum\u00e9 automatique de documents : une approche statistique, volume 1. HermesLavoisier (Paris).\nTORRES-MORENO J. M., EL-B\u00c8ZE M., B\u00c9CHET F. & CAMELIN N. (2007). Comment faire pour que l\u2019opinion forg\u00e9e \u00e0 la sortie des urnes soit la bonne ? Application au d\u00e9fi DEFT 2007. In 3\u00e8me D\u00c9fi Fouille de Textes DEFT\u201907, p. 10pp : DEFT."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "This year, the DEFT campaign (D\u00e9fi Fouilles de Textes) incorporates a task which aims at identifying the session in which articles of previous TALN conferences were presented. We describe the three statistical systems developed at LIA/ADOC for this task. A fusion of these systems enables us to obtain interesting results (micro-precision score of 0.76 measured on the test corpus). Mots-cl\u00e9s : classification de textes, optimisation, similarit\u00e9.", "creator": "LaTeX with hyperref package"}}}