{"id": "1703.00760", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2017", "title": "Sampling Variations of Lead Sheets", "abstract": "In this paper, we present an approach to creating structured music sequences. We introduce a mechanism for efficiently sampling variations of music sequences. Starting from an input sequence and a statistical model, this mechanism tries out a series of sequences whose spacing to the input sequence is approximately within certain limits. This mechanism is implemented as an extension of belief propagation and uses local fields to distort the generation. Experimentally, we show that sampled sequences are actually closely correlated to the standard measure of musical similarity defined by Mongeau and Sankoff. Subsequently, we show how this mechanism can be used to implement composition strategies that force arbitrary structures on a problem of sheet music production.", "histories": [["v1", "Thu, 2 Mar 2017 12:33:28 GMT  (3294kb,D)", "http://arxiv.org/abs/1703.00760v1", "16 pages, 11 figures"]], "COMMENTS": "16 pages, 11 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["pierre roy", "alexandre papadopoulos", "fran\\c{c}ois pachet"], "accepted": false, "id": "1703.00760"}, "pdf": {"name": "1703.00760.pdf", "metadata": {"source": "CRF", "title": "Sampling Variations of Lead Sheets", "authors": ["Pierre Roy", "Alexandre Papadopoulos", "Fran\u00e7ois Pachet"], "emails": ["roypie@gmail.com,", "pachetcsl@gmail.com,", "alexandre.papadopoulos@lip6.fr"], "sections": [{"heading": "1 Introduction", "text": "Recent advances in machine learning, especially deep recurrent networks such as Long short-term memeory networks (LSTMs), led to major improvements in the quality of music generation [3, 4]. They achieve spectacular performance for short musical fragments. However, musical structure typically exceeds the scope of statistical models. As a consequence the resulting music lacks a sense of direction and becomes boring to the listener after a short while [9].\nMusical structure is the overall organisation of a composition into sections, phrases, and patterns, very much like the organisation of a text. The structure of musical pieces is scarcely, if ever, linear as it essentially relies on the repetition of these elements, possibly altered. For example, songs are decomposed into repeating sections, called verses and choruses, and each section is constructed with repeating patterns. In fact, the striking illusion discovered by [2] shows that repetition truly creates music, for instance by turning speech into music. This is further confirmed by [5] who observed that inserting arbitrary repetition in non-repetitive music improves listeners rating and confidence that the music was written by a human composer.\nar X\niv :1\n70 3.\n00 76\n0v 1\n[ cs\n.A I]\n2 M\nVariations are a specific type of repetition, in which the original melody is altered in its rhythm, pitch sequence, and/or harmony. Variations are used to create diversity and surprise by subtle, unexpected changes in a repetition. The song \u201cStrangers in the Night\u201d is a typical 32-bar form with an AABA structure consisting of four 8-bar sections. The three \u201cA\u201d sections are variations of each other. The last \u201cA\u201d section, shown in Figure 1, consists of a two-bar cell which is repeated three times. Each occurrence is a subtle variation of the preceding one. The second occurrence (bars 27- 28) is a mere transposition of the original pattern by one descending tone. The third instance (bars 29-30) is also transposed, but with a slight modification in the melody, which creates a surprise and concludes the song. Bars 29-30 are both a variation of the original pattern in bars 25-26. Current models for music generation fail to reproduce such long-range similarities between musical patterns. In this example, it is statistically unlikely that bars 29-30 be almost identical to bars 25-26.\nOur goal is to generate structured musical pieces from statistical models. Our approach is to impose a predefined musical structure that specifies explicitly repetitions and variations of patterns and sections, and use a statistical model to generate music that \u201cinstantiates\u201d this structure. In this approach, musical structure is viewed as a procedural process, external to the statistical model.\nAn essential ingredient to implementing our approach is a mechanism to generate variation of a given musical pattern from a statistical model. Although it is impossible to characterise formally the notion of variation, it was shown that some measures of melodic similarity are efficient at detecting variations of a theme [6]. We propose to use such a similarity measure in a generative context to sample from a Markov model, patterns that are similar to a given pattern. This method is related to work on stochastic edit distances [8, 1], but is integrated as a constraint in a more general model for the generation of musical sequences [7]. Moreover, our approach relies on an existing similarity measure rather than on labeled data (pairs of themes and related variations), which is not available.\nThis article is organised as follows. In Section 2, we present the Mongeau & Sankoff similarity measure between melodies. In Section 3, we describe our model, based on melodic similarity, for the sampling of melodic variations. Section 4 is an experimental evaluation of the variation sampling method. In Section 5, we show variations of a melody and a longer, structured musical piece."}, {"heading": "2 Melodic Similarity", "text": "The traditional string edit distance considers three editing operations: substitution, deletion, and insertion of a character. [6] add two operations motivated by the specificities of musical sequences, and inspired by the time compression and expansion operations considered in time warping. The first operation, called fragmentation, involves the replacement of one note by several, shorter notes. Similarly, the consolidation operation, is the replacement of several notes by a single, longer note.\nMongeau and Sankoff proposed an algorithm to compute the similarity between melodies in polynomial time. Considering melodies as sequences of notes, let A = a1, . . . , am and B = b1, . . . , bn be two melodies. The algorithm is based on dynamic programming, using the following recurrence equation for i = 1, . . . ,m and j = 1, . . . , n\n\u03b4i,j = min  \u03b4i\u22121,j + wdel(ai) \u03b4i,j\u22121 + wins(bj) \u03b4i\u22121,j\u22121 + wsubst(ai, bj)\n{\u03b4i\u22121,j\u2212k + wfrag(ai, bj\u2212k+1, . . . , bj),\u2200k} {\u03b4i\u2212k,j\u22121 + wcons(ai\u2212k+1, . . . , ai, bj),\u2200k}\nwhere the various w functions denotes predefined local weights associated to the basic editing operations.\nThe similarity between A and B is \u03b4m,n, given the following initial conditions\n\u2022 \u03b4i,0 = \u03b4i\u22121,0 + wdel(ai), i \u2265 1,\n\u2022 \u03b40,j = \u03b40,j\u22121 + wins(bj), j \u2265 1,\n\u2022 \u03b40,0 = 0.\nThe weight of the substitution of a note ai with a note bj is the weighted sum of two weights:\nwsubst(ai, bj) = wpitch(ai, bj) + k1wlen(ai, bj), (1)\nwhere k1 is the predefined relative contribution of length difference versus that of pitch difference.\nFor the consolidation operation, the weight is also a weighted sum of wpitch and wlen , where wlen is the difference between the length of the replaced note and the total length of the replacing notes, and where wpitch is the sum of the wpitch weights between each replacing note and the replaced note. The weight associated with the fragmentation operation is defined in the same manner.\nThe Mongeau & Sankoff measure is well-adapted to the detection of variations, but has a minor weakness: there is no penalty associated with fragmenting a long note into several shorter notes of same pitch and same total duration. The same applies to consolidation. This is not adapted in a generative context, as fragmentation/consolidation change the resulting melody. We modify the original measure by adding a penalty p to the weights of the consolidation and fragmentation operations:\nThe weight associated with a fragmentation of a note ai into a sequence of notes bj\u2212k+1, . . . , bj is\nwfrag(ai, bj\u2212k+1, . . . , bj) = wpitch(ai, bj\u2212k+1, . . . , bj)\n+ k1n(ai, bj\u2212k+1, . . . , bj)\n+ p\nFor consolidation, a similar extra-weight is added. The consolidation weight is defined by\nwcons(ai, bj\u2212k+1, . . . , bj) = wpitch(ai, bj\u2212k+1, . . . , bj)\n+ k1n(ai, bj\u2212k+1, . . . , bj)\n+ p."}, {"heading": "3 A Model for the Generation of Variations", "text": "Given an original theme, i.e., a melody or a melody fragment, we generate variations of this theme by sampling a specific graphical model. This graphical model is a modified version of the general model of lead sheets introduced by [7]. We first give a quick outline of this model, and then we show how we can adapt this model to restrict it to producing lead sheets at a controlled Mongeau & Sankoff similarity measure from the theme."}, {"heading": "3.1 The Model of Lead Sheets", "text": "[7] introduces a general, two-voice model of lead sheets, which we briefly summarise. The overall model comprises two graphical models, one for chord sequences, one for melodies. Both models are based on a factor graph that combines a Markov model with a finite state automaton. The Markov model, trained on a corpus of lead sheets, provides the stylistic model. The finite state automaton represents hard temporal constraints that the generated sequences should satisfy, such as metrical properties (e.g., an imposed total duration) or user imposed temporal constraints. A harmonic model, also trained on a corpus of lead sheets, is used to \u201csynchronise\u201d the chord sequences and the melody, ensuring that melodies contain notes that comply harmonically with the chord at the same temporal position. This temporal synchronisation is specified with the use of a temporal probability function p\u03c0 attached to each model, i.e., a conditional probability p\u03c0(e|t, e\u2032) of putting element e after element e\u2032, at temporal position t. Elements can be either chords or notes. For harmonic synchronisation, once a chord sequence is generated, one can define p\u03c0(e|t, e\u2032) to be the probability of placing note e under the chord occurring at time t, and following a note e\u2032. Conversely, an existing melody can be harmonised by generating a chord sequence in a similar fashion. This model is outlined on Figure 2.\nEach factor graph is made of a sequence of variables, represented with circles, encoding the sequence of elements. Each element is a chord or a note e, with a fixed\nduration d(e). Unary factors, represented with a square linked to one variable, introduce a bias on its variable. This is used to encode unary constraints, e.g., start the sequence with an imposed element. Binary factors, represented with a square linking two consecutive variables, combine the Markov transition probabilities with the finite-state automaton transitions, and are additionally used to incorporate to the model the temporal probabilities p\u03c0(e|t) used for harmonic synchronisation. The graphical model defines a distribution over the sequence of variables defined by the product of all unary and binary factors. A Belief Propagation algorithm samples the two models by taking into account partially filled fragments and propagating their effect to all empty sections. This is explained in detail in [7]."}, {"heading": "3.2 Generating Variations on a Theme", "text": "To generate variations of an imposed theme, we exploit the mechanism used for harmonic synchronisation. We modify the temporal probabilities p\u03c0 by introducing a bias on those temporal probabilities, i.e., a bias \u03b2(e|t, e\u2032) for putting element e at time t after e\u2032. The new temporal probabilities become p\u03c0(e|t, e\u2032).\u03b2(e|t, e\u2032), renormalised. As a result, the probability of a sequence in the new model is modified, compared with the original model, by a factor equal to the product of the biases \u03b2(e|t, e\u2032), for all elements e of the sequence. A bias of 1 does not modify the probability of putting element e at time t after e\u2032, and a bias less than 1 decreases this probability. We set the value of \u03b2(e|t, e\u2032) according to a \u201clocalised\u201d similarity measure between the sequence e\u2032, e and the fragment of the theme between t\u2212 d(e\u2032) and t+ d(e).\nThe lead sheet in Figure 3 shows the first four bars of \u201cSolar\u201d by Miles Davis.\nSuppose we train a lead sheet model on a corpus of all songs by Miles Davis. Sampling this model would produce new lead sheets in the style of Miles Davis, but not necessarily similar to Solar specifically. However, it is possible to bias this general model to favour sequences with a C5 dotted quarter note starting at beat 1.5 of the first bar, as in Solar, by setting \u03b2(C5|t = 1.5, n\u2032) = 1, for any preceding note n\u2032, and by decreasing \u03b2(n|t = 1.5, n\u2032) for all other note n 6= C5.\nWe can also bias this model not to produce the same note at the same position, but to produce a similar musical result. For example, if we replace the C5 dotted quarter note at beat 1.5 with a C5 eighth note followed by a quarter note with the same pitch, as shown on Figure 7c, we obtain a very similar musical output. On the contrary, replacing the C5 dotted quarter note by a triplet of eighth notes C5-B24-C5 tied to a C5 whole note, as shown on Figure 7g, produces a totally different musical impression.\nOur approach to the generation of variations of a theme is to evaluate the similarity between each possible note n at a given position t and following note n\u2032 in the generated sequence, and the notes in the theme around position t. We then set each bias \u03b2(n|t, n\u2032) based on this similarity measure.\nTechnically, for every candidate note n, we consider all potential temporal positions t and all potential predecessors n\u2032. We compute the Mongeau & Sankoff similarity between the two-note melody [n\u2032, n] and the melodic fragment of the theme between time t\u2212 d(n\u2032) and t+ d(n), where d(n) is the duration of the note n, i.e., the melodic fragment that would be replaced by placing the melody [n\u2032, n], starting n at time t. The notes of the theme that overlap the time interval [t\u2212 d(n\u2032), t+ d(n)] are trimmed so that the extracted melody has the same duration as the candidate notes. We denote this distance MGD([n\u2032, n], t). Similarly MGD([n\u2032], t) denotes the similarity of the one-note sequence [n\u2032] starting at t \u2212 d(n\u2032). Finally, We refer to this similarity as the localised Mongeau & Sankoff similarity. The idea is that the similarity measure obtained by summing those localised measures over a complete sequence approximates the actual Mongeau & Sankoff similarity. This will be confirmed experimentally in the next section.\nTo convert the distance into a weight between 0 and 1, we rescale those values to the [0, 1] interval, and then invert their order, so that a value of 1 is the closest to the theme, and 0 the furthest away. Finally, we exponentiate the result, so that the logarithm of the product of the biases achieved by the model is proportional to the approximated Mongeau & Sankoff similarity. Formally, we define \u03b2(n|t, n\u2032) as follows, where MGDmax is the maximal value of localised Mongeau & Sankoff similarities:\n\u03b2(n|t, n\u2032) = exp ( 1\u2212 MGD([n\n\u2032, n], t)\u2212MGD([n\u2032], t) MGDmax ) An additional parameter \u03b1 is used to control the strength of the variation mechanism. This parameters affects the slope of the set of values taken by the bias, by redefining \u03b2\u2032(n|t, n\u2032) = (1\u2212 \u03b1).\u03b2(n|t, n\u2032) + \u03b1. When \u03b1 is 0, this does not modify the bias, and as \u03b1 increasing to 1, the bias decrease in strength, and with a value of 1 there is not bias in favour of the theme at all, and the modified model is equivalent to the original one. In between values have an intermediate effect, and decrease the bias less quickly for notes that are further to the theme.\nConsequently, small values of \u03b1 should lead to melodies that are highly similar to the theme. As \u03b1 increases, the generated melodies should be less imitative of the original theme. We will evaluate this in practice in the next section."}, {"heading": "4 Experimental Results", "text": "The approach we proposed is based on the intuition that local similarities, favoured by the biased model, will result in a global similarity between the generated melodies and the theme. In this section, we evaluate our approach according to two aspects. First, we evaluate how the choice of the value for the parameter \u03b1 influences the Mongeau & Sankoff similarity between the generated melodies and the original theme. In particular, we show that the biased model favours sequences closer to the theme and penalises sequences less similar to the theme. Second, we explain the result more analytically, for \u03b1 = 0. We first show that applying the bias to the model approximates the localised Mongeau & Sankoff similarity, and then we show that this localised Mongeau & Sankoff similarity is a good approximation of the actual Mongeau & Sankoff similarity.\nFor the experiments reported in this section, the original theme consists in the melody in the first four bars of \u201cSolar\u201d (Miles Davis, see Figure 3). The training corpus contains 29 lead sheets by Miles Davis, such as \u201cAll Blues\u201d, \u201cNardis\u201d, \u201cSo What\u201d or \u201cSolar\u201d itself. In each experimental setup, we build a general model of 4-bar lead sheets in the style of Miles Davis, called the unbiased model, and then, the model is biased to favour the theme with some value for \u03b1, resulting in a biased model."}, {"heading": "4.1 Correlation between the Biases and the Mongeau & Sankoff Distance", "text": "For one value of \u03b1, we generate 10 000 variations of the original theme (first four bars of \u201cSolar\u201d). For each sequence, we compute its probability po in the unbiased model and its probability pb in the biased model, and then consider the ratio pb/po. This probability ratio shows by how much the sequence has been favoured, for values greater than 1, or conversely penalised, for values less than 1, in the biased model. On Figure 4, points in blue are sequences generated with the biased model with an \u03b1 = 0, i.e., the strictest possible. For each sequence, we plot its probability ratio, on a log scale, against its Mongeau & Sankoff similarity with the theme. We observe that the logarithm of the probability ratio tends to decrease linearly as the Mongeau & Sankoff distance with the theme increases. Sequences at a distance less than 75 from the theme are boosted while sequences at a distance more than 75 from the theme are hindered. Points in black are sequences generated with \u03b1 = 0.95, i.e., almost no bias at all. We observe that most sequences have a probability ratio of 1, i.e., that the biased model hardly affects the probability of sequences. Only sequences very far from the theme have their probability slightly decreased. Points in the red are generated with \u03b1 = 0.5. They display an intermediate behaviour as expected.\nExamples of variations of the first four bars of \u201cSolar\u201d, at various Mongeau & Sankoff distances, are shown in Section 5.1."}, {"heading": "4.2 Explaining the Correlation", "text": "We explain the correlation observed by the application of two successive approximations. We concentrate on the case where \u03b1 = 0, but similar results are obtained with other values. We can break our analysis in three steps.\nFirst, we note that for a given sequence, its probability ratio is equal, by definition of the biased model, to the product of all the local biases applied to each element of the sequence, up to a normalisation factor. This has been verified experimentally too, although we do not show the plot for reasons of space.\nSecond, we show how the probability ratio compares with the approximated Mongeau & Sankoff similarity measure obtained by summing the localised Mongeau & Sankoff similarity measures. For each sequence, we sum, over all its elements, the localised Mongeau & Sankoff that was used when computing the biases, as explained in section Section 3.2. Then, we compare this sum to the product of the local biases, equal to the probability ratio. We plot the result on Figure 5. We observe that the approximated Mongeau & Sankoff similarity measure is tightly correlated with the logarithm of the product of the local biases. In other words, the logarithm of the product of the\nlocal biases approximates closely enough the sum of the localised Mongeau & Sankoff distances.\nFinally, we show that this approximated Mongeau & Sankoff similarity measure approximates the actual Mongeau & Sankoff similarity measure. On Figure 6, we plot for each sequence, the approximate versus the actual similarity measure. We observe that, although the actual measure is a global, dynamic programming-based measure, it is adequately approximated by summing the localised versions. This is probably because the localised measure captures sufficiently the effect of a note on the global similarity measure."}, {"heading": "5 Examples of Variations", "text": "In this section, we show music created using the variation sampling mechanism. We show melodic variations of a short melodic fragment from \u201cSolar\u201d (Section 5.1) and of the whole melody (Section 5.2). Section 5.3 shows a 32-bar lead sheet that has the same structure as \u201cIn a Sentimental Mood\u201d by Duke Ellington, but in a very different style (the Beatles)."}, {"heading": "5.1 First Four Bars of \u201cSolar\u201d", "text": "Figure 7 shows six melodic variations of the first four bars of \u201cSolar\u201d, by Miles Davis. These variations were created using a model trained on 29 songs by Miles Davis (see Section 4). The variations are presented in increasing order of Mongeau & Sankoff distance with the original theme (see Figure 3). Note that the variations are increasingly different from the theme, both rhythmically and melodically."}, {"heading": "5.2 Variations of Entire Lead Sheets", "text": "Figure 8 shows a variation of \u201cSolar\u201d, in the style of Miles Davis (the system was trained using the same corpus as in Section 4). This variation contains a lot more notes that the original melody, i.e., 77 notes instead of 48 notes, including rests and many triplets. Bars 2, 4, 6, 8, and 11-12 are unchanged from the original melody. Bars 9-10 are similar to one another, very much like in the original theme, but are more complex than the original bars. This variation feels like an ornamented version of \u201cSolar\u201d, that is a \u201cSolar\u201d \u201cwith more notes\u201d.\nThe mechanism described in this chapter creates variations based on the Mongeau-\nSankoff distance between melodies. This mechanism may be applied to other types of sequences and other distances, for instance to chord sequences, using any harmonic distance between chords. The lead sheet on Figure 9 was generated in two steps: first, a 12-bar chord sequence was generated as a variation of the chord sequence of \u201cSolar\u201d, then a melodic variation was generated from the original melody. The similarity between chords is computed as the scalar product of the pitch hitograms of the chords. Figure 9 has been generated in the style of the Beatles, using a corpus with 45 lead sheets by the Beatles.\nThe lead sheets in Figures 8 and 9 were played to several musical experts, who rated them as pleasing and not lacking a sense of direction. This supports the intuition that variations retain some of the structural features of the original pieces. These two lead sheets are not original compositions as they are created by transforming an existing piece. In the next section, we will show how the variation mechanism may be used to generate new, structured compositions."}, {"heading": "5.3 Composition of Structured Lead Sheets", "text": "As said in introduction, the model of melodic variations is an essential tool for the generation of structured lead sheets. We illustrate this on a concrete example: generating a lead sheet with the structure of \u201cIn a Sentimental Mood\u201d (Duke Ellington, see Figure 10). This song is a classical AABA 32-bar form preceded by a pickup bar. More precisely, it consists of the following elements:\n\u2022 Sections: \u201cpickup\u201d: bar 1; \u201cA1\u201d: bars 2-9, \u201cA2\u201d: bars 2-8 & 10 (bars 1-8 are played twice), \u201cB\u201d: bars 11-18; \u201cA3\u201d\n\u2022 Bars 2-3 use similar chords (all based on Dm) and the harmony is transposed down by a perfect fifth at bars 4;\n\u2022 Bar 12 is a transposed variation of bar 11;\n\u2022 Bars 15-16 are exact copies of bars 11-12;\n\u2022 Last two bars (25-26) are a variation of the ending of Section \u201cA2\u201d (i.e., bars 8 and 10)\nThe generation is based on a procedure that creates patterns, and variations, and organizes them to comply with an imposed structure. This procedure uses the general two-voice model of lead sheets [7] to generate original patterns and the model of variations of Section 3 to generate variations of these patterns.\nIn practice, the generation follows a left-to-right order, as much as possible. However, repetitions break the left-to-right scheme. For instance, bar 2 is played three times, once at the beginning of each \u201cA\u201d section. Bars that are copied from the past are later integrated as constraints (as explained Section 3) in the model when generating the surrounding elements. For instance, bar 19 at the beginning of Section \u201cA3\u201d, which is a copy of bar 2, will be treated as a constraint when generating the music for the preceding bars (end of Section \u201cB\u201d).\nFigure 11 shows a lead sheet with this structure and generated from a stylistic model of the Beatles (trained from a corpus with 201 lead sheets by the Beatles). The music does not sound similar to \u201cIn a Sentimental Mood\u201d at all, but its structure, with multiple occurrences of similar patterns, make it feel like it was composed with some intentions. This is never the case of structureless 32-bar songs composed from the general model.\nEach part of the lead sheet has a strong internal coherence. The melody in the \u201cA\u201d parts use mostly small steps and fast sixteenth notes, many occurrence of a rhythmic pattern combining a sixteenth note with a dotted eighth note. The \u201cB\u201d part uses many leaps (thirds, fourth and fifth) and a regular eighth note rhythm. This internal coherence is a product of the imposed structure. For instance, in the \u201cB\u201d part, four out of eight bars come from a single original cell, consisting of bar 11.\nThe fact that the \u201cA\u201d and \u201cB\u201d parts contrast with one another is also a nice feature of this lead sheet. This contrast simply results from the default behavior of the general model of lead sheets."}, {"heading": "6 Conclusion", "text": "We have presented a model for sampling variations of melodies from a graphical model. This model is based on the melodic similarity measure proposed by [6]. Technically, we use an approximated version of the Mongeau & Sankoff similarity measure to bias a more general model for the generation of music. Experimental evaluation shows that this approximation allows us to bias the model towards the generation of melodies that are similar to the imposed theme. Moreover, the intensity of the bias may be adjusted to control the similarity between the theme and the variations. This makes\nthis approach a powerful tool for the creation of pieces complying with an imposed musical structure. We have illustrated our method on melodic variations of a wellknown theme and we have shown that this is a building block for a procedure that generates structured musical pieces."}], "references": [{"title": "Stochastic Contextual Edit Distance and Probabilistic FSTs", "author": ["Ryan Cotterell", "Nanyun Peng", "Jason Eisner"], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Illusory Transformation from Speech to Song", "author": ["Diana Deutsch", "Trevor Henthorn", "Rachael Lapidis"], "venue": "The Journal of the Acoustical Society of America,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Deepbach: a steerable model for bach chorales generation", "author": ["G Hadjeres", "F. Pachet"], "venue": "Technical report,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Modelling high-dimensional sequences with lstm-rtrbm: Application to polyphonic music generation", "author": ["Qi Lyu", "Zhiyong Wu", "Jun Zhu", "Helen Meng"], "venue": "In Proceedings of the 24th International Conference on Artificial Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Aesthetic responses to repetition in unfamiliar music", "author": ["Elizabeth Hellmuth Margulis"], "venue": "Empirical Studies of the Arts,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Comparison of Musical Sequences", "author": ["Marcel Mongeau", "David Sankoff"], "venue": "Computers and the Humanities,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1990}, {"title": "Assisted Lead Sheet Composition using FlowComposer", "author": ["Alexandre Papadopoulos", "Pierre Roy", "Fran\u00e7ois Pachet"], "venue": "In Principles and Practice of Constraint Programming \u2013 CP 2016", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Learning String-Edit Distance", "author": ["Eric Sven Ristad", "Peter N Yianilos"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1998}, {"title": "Generating Long-Term Structure in Songs and Stories", "author": ["Elliot Waite"], "venue": "https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}], "referenceMentions": [{"referenceID": 2, "context": "Recent advances in machine learning, especially deep recurrent networks such as Long short-term memeory networks (LSTMs), led to major improvements in the quality of music generation [3, 4].", "startOffset": 183, "endOffset": 189}, {"referenceID": 3, "context": "Recent advances in machine learning, especially deep recurrent networks such as Long short-term memeory networks (LSTMs), led to major improvements in the quality of music generation [3, 4].", "startOffset": 183, "endOffset": 189}, {"referenceID": 8, "context": "As a consequence the resulting music lacks a sense of direction and becomes boring to the listener after a short while [9].", "startOffset": 119, "endOffset": 122}, {"referenceID": 1, "context": "In fact, the striking illusion discovered by [2] shows that repetition truly creates music, for instance by turning speech into music.", "startOffset": 45, "endOffset": 48}, {"referenceID": 4, "context": "This is further confirmed by [5] who observed that inserting arbitrary repetition in non-repetitive music improves listeners rating and confidence that the music was written by a human composer.", "startOffset": 29, "endOffset": 32}, {"referenceID": 5, "context": "Although it is impossible to characterise formally the notion of variation, it was shown that some measures of melodic similarity are efficient at detecting variations of a theme [6].", "startOffset": 179, "endOffset": 182}, {"referenceID": 7, "context": "This method is related to work on stochastic edit distances [8, 1], but is integrated as a constraint in a more general model for the generation of musical sequences [7].", "startOffset": 60, "endOffset": 66}, {"referenceID": 0, "context": "This method is related to work on stochastic edit distances [8, 1], but is integrated as a constraint in a more general model for the generation of musical sequences [7].", "startOffset": 60, "endOffset": 66}, {"referenceID": 6, "context": "This method is related to work on stochastic edit distances [8, 1], but is integrated as a constraint in a more general model for the generation of musical sequences [7].", "startOffset": 166, "endOffset": 169}, {"referenceID": 5, "context": "[6] add two operations motivated by the specificities of musical sequences, and inspired by the time compression and expansion operations considered in time warping.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "This graphical model is a modified version of the general model of lead sheets introduced by [7].", "startOffset": 93, "endOffset": 96}, {"referenceID": 6, "context": "[7] introduces a general, two-voice model of lead sheets, which we briefly summarise.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "This is explained in detail in [7].", "startOffset": 31, "endOffset": 34}, {"referenceID": 0, "context": "To convert the distance into a weight between 0 and 1, we rescale those values to the [0, 1] interval, and then invert their order, so that a value of 1 is the closest to the theme, and 0 the furthest away.", "startOffset": 86, "endOffset": 92}, {"referenceID": 6, "context": "This procedure uses the general two-voice model of lead sheets [7] to generate original patterns and the model of variations of Section 3 to generate variations of these patterns.", "startOffset": 63, "endOffset": 66}, {"referenceID": 5, "context": "This model is based on the melodic similarity measure proposed by [6].", "startOffset": 66, "endOffset": 69}], "year": 2017, "abstractText": "Machine-learning techniques have been recently used with spectacular results to generate artefacts such as music or text. However, these techniques are still unable to capture and generate artefacts that are convincingly structured. In this paper we present an approach to generate structured musical sequences. We introduce a mechanism for sampling efficiently variations of musical sequences. Given a input sequence and a statistical model, this mechanism samples a set of sequences whose distance to the input sequence is approximately within specified bounds. This mechanism is implemented as an extension of belief propagation, and uses local fields to bias the generation. We show experimentally that sampled sequences are indeed closely correlated to the standard musical similarity measure defined by Mongeau and Sankoff. We then show how this mechanism can used to implement composition strategies that enforce arbitrary structure on a musical lead sheet generation problem.", "creator": "LaTeX with hyperref package"}}}