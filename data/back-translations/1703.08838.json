{"id": "1703.08838", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Mar-2017", "title": "Distributed Voting/Ranking with Optimal Number of States per Node", "abstract": "Considering a network with $n $nodes, in which each node votes first for one (or more) of possible $K $decisions, we present a Distributed Multi-Choice Voting / Ranking (DMVR) algorithm to either determine the maximum vote (the voting problem) or evaluate all decisions with respect to their acquired votes (the ranking problem).The proposed algorithm consolidates the votes of the nodes throughout the network by updating the states of the interacting nodes through two key operations, the union and the cut. The proposed algorithm is simple, independent of the network size, and easily scalable in terms of the number of decisions $K $$, using only $K\\ times 2 ^ {K-1} $node states for voting, and $K\\ times K! $node states for ranking. We prove that the number of states in the ranking case is optimal, this complexity is likely to be applied to the full-time electoral algorithm.", "histories": [["v1", "Sun, 26 Mar 2017 16:19:31 GMT  (270kb,D)", "http://arxiv.org/abs/1703.08838v1", null]], "reviews": [], "SUBJECTS": "cs.DC cs.LG", "authors": ["saber salehkaleybar", "arsalan sharif-nassab", "s jamaloddin golestani"], "accepted": false, "id": "1703.08838"}, "pdf": {"name": "1703.08838.pdf", "metadata": {"source": "CRF", "title": "Distributed Voting/Ranking with Optimal Number of States per Node", "authors": ["Saber Salehkaleybar", "Arsalan Sharif-Nassab"], "emails": ["saleh@ee.sharif.edu,", "sharifnassab@ee.sharif.edu,", "golestani@ieee.org"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nOne of the key building blocks in distributed function computation is \u201cMajority Voting\u201d. It can be employed as a subroutine in many network applications such as target detection in sensor networks [1], [2], distributed hypothesis testing [3], quantized consensus [4], voting in distributed systems [5], and molcular nanorobots [6]. In the distributed majority voting, each node chooses a candidate from a set of choices and the goal is to determine the candidate with the majority vote by running a distributed algorithm. As an example in target detection [1], wireless sensors combine their binary decisions about the presence of a target through majority voting, and send a report to the fusion center if the majority is in favor of presence.\nThe majority voting problem for the binary case has been extensively studied in cellular automata (CA) literature. In [7], it has been shown that there is no synchronous deterministic two-state automaton that can solve binary voting problem in a connected network. Several two-state automata have been proposed for the ring topology [8], [9], the most successful of which can get the correct result in nearly 83% of initial configurations of selected votes [10]. In order to circumvent the impossibility result of [7], asynchronous and probabilistic automata have also been presented in CA community [11]\u2013 [13]. However, none of them can obtain the correct result with probability one [14]. Using a different approach, binary voting problem can be solved by a randomized gossip algorithm [15] that computes the average of initial node values. The drawback of this approach is that the number of required states in its\nquantized version [16] grows linearly in terms of the network size [14].\nIn applying gossip algorithms to the implementation of binary majority voting, node does not need to come up with the exact average of the node values; it suffices to determine interval to which the average node values belongs. From this observation, Be\u0301ne\u0301zit et al. [17] proposed an elegant solution based on an automaton, with the state space {0, 0.5\u2212, 0.5+, 1}, which resembles the idea in [16]. The initial state of nodes voting for \u201c0\u201d or \u201c1\u201d is 0 or 1, respectively. When two neighbor nodes get in contact with each other, they exchange their states and update them according to a transition rule. It can be shown that the states of all nodes would be in the set {0, 0.5\u2212} at the end of the algorithm, if the choice \u201c0\u201d is in majority. Otherwise, the state of all nodes would belong to the set {0.5+, 1}. In [14], a Pairwise Asynchronous Graph Automata (PAGA) has been used to extend the above idea to the multiple choice voting problem, and sufficient conditions for convergence are stated. This approach results in a 15- state automaton and a 100-state automaton for the ternary and quaternary voting problems, respectively. For majority voting with more than four choices, pairwise and parallel comparison among the choices, has been proposed [14], requiring \u0398(2K(K\u22121)) number of states in terms of the number of choices, K. At the end, authors posed a few open problems. One of the main problems is whether voting automata exist for any number of multiple choices without running multiple binary or ternary voting automata in parallel? Furthermore, what is the minimum number of states of a possible solution?\nIn more recent works [18]\u2013[21], it has been shown that the majority vote can be obtained with high probability if the initial votes are sufficiently biased to the majority or the network size is large enough. However, none of these works can guarantee convergence to the correct result.\nA generalization of the distributed voting problem, is the distributed ranking problem in which the goal is to rank all the K choices in terms of the number of votes, each get from different network nodes [20]. In this paper, we propose a Distributed Multi-choice Voting/Ranking (DMVR) Algorithm for solving the majority voting and ranking problems in general networks. The proposed algorithm may also be applied where each node is allowed to vote for more than one choice. Our main contributions are summarized as follows: \u2022 Our proposed DMVR algorithm provides a simple and\neasily scalable approach for distributed voting and ranking that works for any number K of choices, requiring\nar X\niv :1\n70 3.\n08 83\n8v 1\n[ cs\n.D C\n] 2\n6 M\nar 2\n01 7\n2 K\u00d72K\u22121 and K\u00d7K! number of states for the voting and ranking problems, respectively. For instance, the number of required states is 12 for ternary voting, and 32 for quaternary voting, compared to respectively 15 and 100 states in the case of PAGA algorithm [14]. Furthermore, unlike the randomized gossip algorithms [15], [16], the number of states is independent from the network size.\n\u2022 We establish a lower bound on the number of required states in any ranking algorithm, and show that the DMVR algorithm achieves this bound. Compared to the existing algorithms, the state of the DMVR algorithm can be encoded by roughly \u0398(K log(K)) bits.\n\u2022 In complete graphs, we analyze the time complexity of the DMVR algorithm for the ranking problem. We will show how the time complexity is related to the percentage of nodes voting for different choices. Besides, we propose a modification for speeding up the DMVR algorithm for the majority voting problem.\nThe remainder of this paper is organized as follows: In Section II, the DMVR algorithm for majority voting and ranking is described. Section III studies the convergence of the DMVR algorithm. Furthermore, the number of states of the DMVR algorithm is analyzed in both cases of voting and ranking. Section IV is devoted to analyze the time complexity of the DMVR algorithm in complete graphs. In Section V, simulation results are provided. Finally, we conclude the paper in Section VI."}, {"heading": "II. THE DISTRIBUTED MULTI-CHOICE VOTING/RANKING (DMVR) ALGORITHM", "text": ""}, {"heading": "A. Problem Statement", "text": "Consider a network with n nodes. The topology of the network is represented by a connected undirected graph, G = (V,E), with the vertex set V = {1, ..., n}, and the edge set E \u2286 V \u00d7V , such that (i, j) \u2208 E if and only if nodes i and j can communicate directly. Furthermore, it is assumed that each node is equipped with a local clock which ticks according to a Poisson process with rate one. Initially, each node i chooses a choice from a set of K choices C = {c1, \u00b7 \u00b7 \u00b7 , cK}. Let #ck be the number of nodes that select the choice ck and \u03c1k , #ck n . In the majority voting problem, the goal is to find the choice ck in majority, i.e. the choice ck satisfying #ck \u2265 #cj , j \u2208 {1, \u00b7 \u00b7 \u00b7 ,K}. In the ranking problem, the desired output is a permutation, [\u03c01, \u00b7 \u00b7 \u00b7 , \u03c0K ] of C such that #\u03c0k \u2265 #\u03c0k+1,\u2200k."}, {"heading": "B. Description of the DMVR algorithm", "text": "A value set vi(t) is associated with each node i at time t. At t = 0, the only member of vi(0) is the selected choice of node i. In the process of the algorithm, vi(t) always remains a subset of C. The algorithm essentially performs two function. One function of the algorithm deals with consolidating node choices across the network. This function utilizes two key operations, the union and the intersection, in order to update the value sets vi(t) and vi(t) of nodes i and j, when they interact. The second part of the algorithm has to do with disseminating the consolidated result of part one throughout\nAlgorithm 1 The Distributed Multi-choice Voting/Ranking Algorithm\n1: Initialization: vi(0) = Initial vote of node i, mi,k(0) = \u2205, 1 \u2264 k \u2264 K, \u2200i \u2208 {1, \u00b7 \u00b7 \u00b7 , n}. 2: if Node i\u2019s clock ticks at time t then 3: Node i contacts with a random neighbor node, say\nnode j: 4: if |vi(t)| \u2264 |vj(t)| then 5: vi(t\n+) := vi(t) \u222a vj(t), vj(t+) := vi(t) \u2229 vj(t). 6: else 7: vi(t\n+) := vi(t) \u2229 vj(t), vj(t+) := vi(t) \u222a vj(t). 8: end if 9: mi,|vi(t+)|(t +) := vi(t +),mj,|vj(t+)|(t +) := vj(t +).\n10: end if\nthe network. For reasons to be clarified later, the above two functions of the algorithm are executed in parallel, not sequentially. The second function of the algorithm operates on a collection of sets mi,k(t), 1 \u2264 k \u2264 K, at each node i. We collectively refer to the sets mi,k(t), 1 \u2264 k \u2264 K, of node i as memory of it. Each mi,k(t) is a subset of C. Unlike the dissemination function, the consolidation function is identical for the voting and ranking. In the following, we describe the dissemination function for the more general case, i.e. for the ranking case, the dissemination for the voting case being a special and simplified version of it.\nWhen node i\u2019s clock ticks at time t, it chooses one of the neighbor nodes, say node j, randomly. Then, nodes i and j update their value sets and memories according to the following transition rules:\nConsolidation Function:{ vi(t\n+) := vi(t) \u222a vj(t), vj(t+) := vi(t) \u2229 vj(t), if |vi(t)| \u2264 |vj(t)|, vi(t +) := vi(t) \u2229 vj(t), vj(t+) := vi(t) \u222a vj(t), Otherwise.\nDissemination Function: mi,|vi(t+)|(t +) := vi(t +), mj,|vj(t+)|(t +) := vj(t +),\n(1)\nwhere there is no memory updating if vi(t+) = \u2205. Furthermore, we have: mi,k(t+) = mi,k(t) for \u2200k 6= |vi(t+)|, \u2200i \u2208 {1, \u00b7 \u00b7 \u00b7 , n}.\nWhen the algorithm converges1, each node i can obtain the correct ranking as follows2:\n\u03c0k = { mi,k(t)\\mi,k\u22121(t), if k > 1, mi,1(t), k = 1.\n(2)\nIn the case of the majority voting problem, it suffices to keep the memory mi,1(t) at each node i. We denote mi,1(t) by mi(t) when the DMVR algorithm is executed for the majority voting problem. The description of the DMVR Algorithm is given in Algorithm 1.\nSuppose that |vi(t)| \u2264 |vj(t)|. It is not difficult to show that the updating rule in (1) has the following properties:\n1In Section III, Theorem 1, we will describe when the algorithm eventually converges to the correct result.\n2 The \u201c\\\u201d is the set-theoretic difference operator, i.e. A\\B = {x : x \u2208 A, x 6\u2208 B} for any sets A and B.\n3 \u2022 Define the size of choice ck as: |{i | ck \u2208 vi(t)}|. The size of every choice ck is preserved during the updates. \u2022 We have vj(t+) \u2286 vi(t+). If vi(t) \u2286 vj(t), the two nodes just exchange their value sets. \u2022 The quantity |vi(t)|2+|vj(t)|2 strictly increases if vi(t) 6\u2286 vj(t). Otherwise, it remains unchanged."}, {"heading": "III. CONVERGENCE ANALYSIS", "text": "In this section, we will show that the DMVR algorithm converges to the correct solution for the majority voting and ranking problems. First, we study how value sets consolidate and get in a convergence set, by defining a Lyapunov function. Then, we discuss how memory updating can disseminate the correct result in parallel to value set updating. Next, we merge value sets and memories of the DMVR algorithm in order to reduce memory usage in both majority voting and ranking problems. At the end, we prove that the proposed implementation is optimal in terms of the required number of states for the ranking problem."}, {"heading": "A. Consolidation of Value Sets", "text": "In this part, we analyze how value sets consolidate in the network until the state of the system gets in a convergence set.\nDefinition 1. Let the network state vector at time t be defined as X(t) = [v1(t), \u00b7 \u00b7 \u00b7 , vn(t)]. The set of all state vectors X(t) = [v1(t), \u00b7 \u00b7 \u00b7 , vn(t)] with the following property is called the convergence set and is denoted by X0:\n|vi(t)| \u2264 |vj(t)| =\u21d2 vi(t) \u2286 vj(t),\u2200i, j \u2208 {1, \u00b7 \u00b7 \u00b7 , n}. (3)\nExample 1. Consider a network of n = 8 nodes and three possible choices C = {c1, c2, c3}. Assume that X(0) = [{c1}, {c1}, {c2}, {c3}, {c1}, {c3}, {c2}, {c1}]. The state vector X(t) = [{c1}, \u2205, {c1, c2, c3}, \u2205, \u2205, {c1, c2}, {c1, c3}, \u2205] cannot be in the set X0 since {c1, c2} 6\u2286 {c1, c3}. However, the state vector X(t) = [{c1, c2, c3}, \u2205, {c1, c2, c3}, \u2205, \u2205, {c1}, {c1}, \u2205] is a member of the convergence set.\nLemma 1. If X(\u03c4) \u2208 X0 at time \u03c4 > 0, then X(t) \u2208 X0, \u2200t \u2265 \u03c4 .\nProof: Assume that the state vector X(\u03c4) is in X0. If two nodes i and j get in contact with each other at any time t > \u03c4 , then according to Definition 1, the outputs of transition, i.e. the sets {vi(t)\u2229vj(t)} and {vi(t)\u222avj(t)} would be {vi(t)}, {vj(t)} or {vj(t)}, {vi(t)}. Since we know that X(\u03c4) \u2208 X0, X(t) is also in X0. Thus, the proof is complete.\nDefinition 2. The Lyapunov function V (X(t)) is defined as follows:\nV (X(t)) = nK2 \u2212 n\u2211 i=1 |vi(t)|2. (4)\nLemma 2. If two nodes i and j contact with each other at time t, and vi(t) 6\u2286 vj(t), vj(t) 6\u2286 vi(t), then there would be a reduction in the Lyapunov function V (X(t)).\nProof: Suppose that |vi(t)| = l, |vj(t)| = l\u2032, and |vi(t)\u2229 vj(t)| = r. The change in the Laypunov function is:\nV (X(t+))\u2212V (X(t)) = \u2212[(l+l\u2032\u2212r)2+r2]+(l2+l\u2032 2\n) \u2264 \u22121, (5)\nwhich is strictly less than zero for all 0 \u2264 r \u2264 min(l, l\u2032)\u2212 1.\nDefinition 3. Let X(0) = x. We denote the time that the state vector hits the set X0 for the first time by \u03c4x, i.e.:\n\u03c4x = min{t > 0|X(t) \u2208 X0}. (6)\nDefinition 4. Let Y (t) be a random walk on the network starting from node p. We define Tpq to be the first time Y (t) visits node q:\nTpq = min{t \u2265 0 | Y (0) = p, Y (t) = q}, (7)\nand the worst case hitting time, \u03c3, is defined as follows:\n\u03c3 = max p,q\u2208V\nE{Tpq}. (8)\nLemma 3. There exists > 0 such that:\nE{V (X(t+ 2\u03c3))\u2212 V (X(t)) | X(t) = y} \u2264 \u2212 , if y 6\u2208 X0, (9)\nwhere \u03c3 is defined in (8).\nProof: Consider two random walks Y (t) and Z(t) on the network starting from nodes p and q, respectively. We define the coalescing time of two random walks Y (t), Z(t) as follows:\nCpq = min{t \u2265 0 | Y (t) = Z(t), Y (0) = p, Z(0) = q}. (10)\nIt follows from Markov inequality that:\nmin p,q\u2208V\nPr{Cpq \u2264 t0} \u2265 1\u2212 \u03c3\nt0 . (11)\nIf X(t) 6\u2208 X0, then there exist vi(t), vj(t) such that vi(t) 6\u2286 vj(t), vj(t) 6\u2286 vi(t). The corresponding random walks meet each other (or some other intermediate such value sets) up to time t + 2\u03c3 with probability at least 12 , which results in reduction of V (X(t)) according to Lemma 2. Otherwise, X(t) is in the set X0.\nLemma 4. The state vector X(t) hits the set X0 in bounded time with probability one.\nProof: We know that the Lyapunov function V (X(t)) is lower bounded by zero. According to Foster\u2019s criteria (see [22], page 21) and Lemma 3, it follows that:\nPr(\u03c4x <\u221e) = 1,\u2200x 6\u2208 X0. (12)\n4"}, {"heading": "B. Dissemination of Result in Memories", "text": "In this part, we show how memory updating disseminates the correct result in the network. Without loss of generality, in the remainder of this paper, we assume that #c1 > #c2 > \u00b7 \u00b7 \u00b7 > #cK .3\nDefinition 5. Assume that the state vector X(t) gets in X0 at time \u03c4 . We define the vector v? = [v1, \u00b7 \u00b7 \u00b7 , vK ] as follows:\nvk = { vi(\u03c4), \u2203i \u2208 {1, \u00b7 \u00b7 \u00b7 , n} : |vi(\u03c4)| = k, \u2205, otherwise.\n(13)\nand rk(t) = \u2223\u2223 {i\u2223\u2223|vi(t)| = k} \u2223\u2223.\nTheorem 1. The vector [\u03c01, \u00b7 \u00b7 \u00b7 , \u03c0K ] defined in (2), gives the correct ranking of choices in a finite time with probability one.\nProof: From Lemma 4, we know that the state vector X(t) eventually gets in the set X0 at time \u03c4x. For a choice ck, let \u03b1(k) be the smallest index such that ck \u2208 v\u03b1(k). According to the definition of the convergence set and the preservation\nproperty, we know that: #ck = K\u2211\ni=\u03b1(k)\nri(t). Hence, we have:\n#ck > #ck\u2032 \u21d0\u21d2 \u03b1(k) < \u03b1(k\u2032). Thus, based on assumption #c1 > #c2 > \u00b7 \u00b7 \u00b7 > #cK , the only possibility is: rk(t) > 0 and \u03b1(k) = k, \u2200k \u2208 {1, \u00b7 \u00b7 \u00b7 ,K} for all t > \u03c4x. Since rk(t) > 0, there exists at least one value set vk, 1 \u2264 k \u2264 K in the network. The value sets vk take random walk in the network and set the memories mi,k(t) to vk for all i \u2208 {1, \u00b7 \u00b7 \u00b7 , n}. Let \u03c4 \u2032 > \u03c4x be the time that mi,k(t) = vk, \u2200i \u2208 {1, \u00b7 \u00b7 \u00b7 , n}, 1 \u2264 k \u2264 K. Based on the definition of \u03b1(k), we have: ck = v\u03b1(k)\\v\u03b1(k)\u22121 = mi,k(t)\\mi,k\u22121(t). Hence, all nodes obtain the correct ranking after time \u03c4 \u2032.\nFrom above theorem, mi,1(t) gives the choice in majority. Hence, the DMVR algorithm can solve the majority voting problem by just updating mi(t) = mi,1(t).\nRemark 1. In the proposed solution, each node can also vote for more than one choice. To do so, it is sufficient to initialize the value set of each node to the union of its preferred choices. In this general case as well, the DMVR algorithm gives the correct ranking based on the size of choices."}, {"heading": "C. State-optimal Implementation of DMVR Algorithm", "text": "For the case of majority voting, the state of node i is the pair (mi(t), vi(t)) where the sets mi(t) and vi(t) have K and 2K possible states, respectively. Thus, the total number of states is K\u00d72K . However, we can implement the DMVR algorithm with fewer states by adding the following rules: \u2022 If the output of updating rule, vi(t)\u2229 vj(t), is the empty\nset, we replace it by the set C. \u2022 If mi(t+) 6\u2286 vi(t+), we select a random member ck \u2208 vi(t\n+) and change mi(t+) to {ck}. Otherwise, mi(t+) remains unchanged. Then, the state of node i is saved in the form of ( mi(t +), vi(t +)\\mi(t+) ) .\n3We assume that #cK > 0. Otherwise, we can reduce the problem to the case with fewer choices. By slight modifications, the DMVR algorithm can also work for the cases where we have choices with equal size.\nWhen X(t) \u2208 X0, there is at least one value set {c1} in the network. When this value set meets a new node with mi(t) 6= {c1}, it updates mi(t) to {c1} and mi(t) will never be changed after that. Because {c1} \u2286 vi(t),\u2200i{1, \u00b7 \u00b7 \u00b7 , n} when X(t) \u2208 X0. For a fixed mi(t+), the number of possible states for vi(t\n+)\\mi(t+) is 2K\u22121. Consequently, the total number of states reduces to K \u00d7 2K\u22121. As an example, in the ternary voting, we have the following 12 states:\n({c1}, \u2205), ({c1}, {c2}), ({c1}, {c3}), ({c1}, {c2, c3}) ({c2}, \u2205), ({c2}, {c1}), ({c2}, {c3}), ({c2}, {c1, c3}) ({c3}, \u2205), ({c3}, {c1}), ({c3}, {c2}), ({c3}, {c1, c2}) (14)\nThus, the number of states for ternary voting is 12 compared to 15 for the PAGA automaton [14] and it is equal to 32 for quaternary voting while the number of states for the PAGA is 100.\nIn the case of ranking problem, we replace the value set and memories by an ordered K-tuple ai(t) = [a1i (t), \u00b7 \u00b7 \u00b7 , aKi (t)], which is a permutation of the set C along with an integer 1 \u2264 pi(t) \u2264 K which we perceive as a pointer to an entry of ai(t). At the beginning of the algorithm, each node i puts its preferred choice in the first entry of ai(0), and sets an arbitrary permutation of other choices in the remaining entries. It also sets pi(0) = 1. Let a 1:pi(t) i be a pi(t)-tuple containing the first pi(t) entries of ai(t) and {a1:pi(t)i } be the set representation of it without any order. For a set A \u2286 C, we define \u03a0A,ai(t) as a permutation of A that preserves the order of entries in accordance with ai(t). Now, assume that two nodes i and j get in contact with each other at time t, and let pi(t) \u2264 pj(t). Then, we apply the following updating rule:\nai(t +) := [\u03a0A1,ai(t),\u03a0A2\\A1,ai(t),\u03a0C\\A2,ai(t)], aj(t +) := [\u03a0A1,aj(t),\u03a0A2\\A1,aj(t),\u03a0C\\A2,aj(t)],\n(15)\nwhere A1 = {a1:pi(t)i } \u2229 {a 1:pj(t) j }, A2 = {a 1:pi(t) i } \u222a {a1:pj(t)j }. We also set pi(t+) := |A2| and pj(t+) := |A1|. It is not difficult to verify that this form of implementing the DMVR algorithm can solve the ranking problem by the same arguments in Theorem 1.\nFrom the above implementation, we can run the DMVR algorithm for the ranking problem with K \u00d7K! states where the terms K and K! are the possible values of the pointer pi(t) and the ordered tuple ai(t), respectively.\nExample 2. Suppose that C = {c1, c2, c3, c4}. Two examples for the updating rule in (15) are given as follows:\nai(t) = [ \u2193 1, 3, 2, 4], aj(t) = [2, \u2193 1, 4, 3]\n\u2212\u2192 ai(t+) = [1, \u2193 2, 3, 4], aj(t +) = [ \u2193 1, 2, 4, 3],\nai(t) = [ \u2193 1, 4, 2, 3], aj(t) = [ \u2193 3, 1, 2, 4]\n\u2212\u2192 ai(t+) = [1, \u2193 3, 4, 2], aj(t +) = [3, 1, 2, \u2193 4],\nwhere the arrow symbol points the pi(t)-th entry of ai(t).\nThe following theorem proposes a lower bound for the required number of states of any ranking algorithm. This\n5 bound meets the required number of states of the DMVR algorithm, proving optimality of it for the ranking problem.\nTheorem 2. Any algorithm that finds the correct ranking in a finite time with probability one over arbitrary network topology, requires at least K\u00d7K! number of states per node.\nProof: It is enough to show that the theorem applies in complete graphs. Suppose that the ranking problem can be solved by running algorithm A at each node in a finite time. Consider that each node i has a state si(t). Let integer r corresponds to the ranking [\u03c01, \u00b7 \u00b7 \u00b7 , \u03c0K ], 1 \u2264 r \u2264 K!. We define a class of states, Sr, as a set of states which nodes associate with ranking r. Algorithm A is said to converge to ranking r at time \u03c4 if si(t) \u2208 Sr,\u2200i \u2208 {1, \u00b7 \u00b7 \u00b7 , n},\u2200t \u2265 \u03c4 . We denote members of the class Sr by Sr = {S1r , \u00b7 \u00b7 \u00b7 ,SDrr } where Dr = |Sr|. Let N1 be the set of initial configurations that are consistent with the ranking r = [\u03c01, \u00b7 \u00b7 \u00b7 , \u03c0K ], i.e.:\nN1 ={ [#\u03c01, \u00b7 \u00b7 \u00b7 ,#\u03c0K ] \u2208 ZK+ : K\u2211 i=1 #\u03c0i = n; #\u03c0i > #\u03c0j ,\u2200i > j } .\n(16)\nLet ni, 1 \u2264 i \u2264 Dr be the number of nodes in {1, \u00b7 \u00b7 \u00b7 , n} whose state is Sir. In complete graphs, the whole information of [s1(t), \u00b7 \u00b7 \u00b7 , sn(t)] can be represented by the set [n1, \u00b7 \u00b7 \u00b7 , nDr ]. Thus, the class Sr corresponds to a subset of the following set:\nN2 = { [n1, \u00b7 \u00b7 \u00b7 , nDr ] \u2208 Z Dr + : Dr\u2211 i=1 ni = n } . (17)\nLet Bz be the set of vectors [n1, \u00b7 \u00b7 \u00b7 , nDr ] that are achievable from the initial configuration z \u2208 N1.\nLemma 5. Consider two initial configurations x, y \u2208 N1, x 6= y. Then, we have: Bx \u2229By = \u2205.\nProof: By contradiction. Suppose that there exists x0 \u2208 Bx\u2229By . We run algorithm A in a complete graph with nodes {1, \u00b7 \u00b7 \u00b7 , n+n\u2032} for two different initial configurations x, y of nodes {1, \u00b7 \u00b7 \u00b7 , n}. The algorithm A should give the correct result for any scheduling of local clocks at nodes. Consider a scheduling which only clocks of nodes in the set {1, \u00b7 \u00b7 \u00b7 , n} are ticking up to time T and the states of these nodes become x0. Now, suppose that a centralized algorithm Ac want to obtain correct ranking by just looking at states of nodes in {1, \u00b7 \u00b7 \u00b7 , n} and votes of nodes in {n+ 1, \u00b7 \u00b7 \u00b7 , n+ n\u2032}. Algorithm Ac finds the ranking of votes of nodes in {1, \u00b7 \u00b7 \u00b7 , n} by the vector x0. But the centralized algorithm still needs to obtain all differences #\u03c0i \u2212 #\u03c0i+1, 1 \u2264 i \u2264 K \u2212 1. Otherwise, it cannot rank votes of nodes in the whole network correctly. However, the two different initial configurations x, y are mapped to the same state vector x0. Consequently, the algorithm Ac cannot recover the correct initial configuration which is a contradiction. Thus, the proof of lemma is complete.\nWe know that |N2| = ( n+Dr\u22121 Dr\u22121 ) = \u0398(nDr\u22121). Further-\nmore, we have:\n|N1| =\n= 1\nK! \u2223\u2223\u2223{[#\u03c01, \u00b7 \u00b7 \u00b7 ,#\u03c0K ] \u2208 ZK+ : K\u2211 i=1 #\u03c0i = n,#\u03c0i 6= #\u03c0j }\u2223\u2223\u2223\n\u2265 1 K! (\u2223\u2223\u2223{[#\u03c01, \u00b7 \u00b7 \u00b7 ,#\u03c0K ] \u2208 ZK+ : K\u2211 i=1 #\u03c0i = n }\u2223\u2223\u2223\u2212\n\u2211 j,k \u2223\u2223\u2223{[#\u03c01, \u00b7 \u00b7 \u00b7 ,#\u03c0K ] \u2208 ZK+ : K\u2211 i=1 #\u03c0i = n,#\u03c0j = #\u03c0k }\u2223\u2223\u2223) = ( n+K \u2212 1 K \u2212 1 ) \u2212 ( K 2 ) \u00d7 ( n+K \u2212 2 K \u2212 2 ) = \u0398(nK\u22121).\n(18)\nLet F : N1 \u2212\u2192 N2 which maps x \u2208 N1 to Bx \u2282 N2. According to Lemma 5, the mapping F should be invertible. For sufficiency large n, this can occur only if Dr \u2265 K. Consequently, it can be concluded that each class Sr has at least K members and total number of states is at least K\u00d7K!."}, {"heading": "IV. TIME COMPLEXITY", "text": "In this section, we first analyze the time complexity of the DMVR algorithm for the binary voting problem in complete graphs. Then, we study the multiple choice case and derive a tight bound on the running time of the DMVR algorithm for the ranking problem. At the end, we propose a method to speed up the DMVR algorithm in majority voting problem."}, {"heading": "A. Binary Voting Case", "text": "In order to study the time complexity of the DMVR algorithm, we divide its execution time into two phases: \u2022 First phase (extinction of {c2}): This phase starts at the\nbeginning of the algorithm and continues until none of the value sets are {c2}. We denote the finishing time of this phase by \u03c41. \u2022 Second phase (dissemination of {c1} in memories): This phase follows the first phase and it ends when memories of all nodes are {c1}. The execution time of this phase is represented by \u03c42.\n1) Time complexity of the first phase: For the binary case, the transition rule of DMVR algorithm is exactly the same as the PAGA algorithm. In [23], an upper bound, O(log(n)/(1 \u2212 2\u03c1)), is given for the PAGA algorithm in complete graphs where \u03c12 = \u03c1. Here, we propose exact average time complexity for the first phase. Suppose that the number of nodes voting for c1, c2 are s = n(1\u2212\u03c1) and r = n\u03c1 at the beginning of the algorithm. We denote the sets of nodes having value sets {c1} and {c2} at time t by S1(t) and S2(t), respectively. Consider the Markov chain in Fig. 1. The state r\u2212 i, 0 \u2264 i \u2264 r, represents the number of nodes whose value sets are {c2}. Suppose that the state of Markov chain is r\u2212 i at time t. The chain undergoes transition from state r \u2212 i to r\u2212i\u22121 if one of nodes in the set S2(t) gets in contact with one of nodes in S1(t), which occurs with rate 2(r\u2212 i)\u00d7 (s\u2212 i)/n.\n6 1 0r 1\u2212r n sr\u00d72 n sr )1()1(2 \u2212\u00d7\u2212 n rs )1(2 +\u2212\nFigure 1. The Markov chain model for the first phase. State r\u2212 i shows the size of the set S2(t).\nAfter updating the value sets, both |S1(t)| and |S2(t)| will decreased exactly by one. Let T 1r\u2212i be the sojourn time in state r \u2212 i. Hence, we have:\nE{\u03c41} = r\u22121\u2211 i=0 E{T 1r\u2212i} = r\u22121\u2211 i=0 n 2 \u00d7 1 (r \u2212 i)(s\u2212 i)\n\u2248 n 2(s\u2212 r) log( r(s\u2212 r) s ),\n(19)\nin terms of time units. Thus, the average running time of the first phase is: E{\u03c41} \u2248 12(1\u22122\u03c1) log( n\u03c1(1\u22122\u03c1) 1\u2212\u03c1 ) time units. Furthermore, we can obtain the variance of \u03c41 as follows:\nVar(\u03c41) = r\u22121\u2211 i=0 Var{T 1r\u2212i} = r\u22121\u2211 i=0 n2 4 \u00d7 1 (r \u2212 i)2(s\u2212 i)2 .\n(20)\n2) Time complexity of the second phase: At the beginning of the second phase, the number of nodes in S1(t) is n(1\u22122\u03c1) and all the remaining nodes have the value sets {c1, c2} or \u2205. Furthermore, the memories of all of these nodes are {c2} in extreme case. Consider the Markov chain in Fig. 2. The state r\u2212 i, 0 \u2264 i \u2264 r, represents the number of nodes having value sets {c1, c2} or \u2205 with memory {c2}. We denote the set of such nodes by M2(t). There is a reduction in |M2(t)| if and only if a node in M2(t) gets in contact with a node in S1(t). If |M2(t)| = r\u2212 i, then with rate 2\u00d7 (r\u2212i)(n\u22122n\u03c1)n , there is a transition from state r \u2212 i to state r \u2212 i\u2212 1. Let T 2r\u2212i be the sojourn time in state r \u2212 i. Then, we have:\nE{\u03c42} \u2264 r\u22121\u2211 i=0 E{T 2r\u2212i} = r\u22121\u2211 i=0 n 2 \u00d7 1 (r \u2212 i)(n\u2212 2n\u03c1)\n\u2248 1 2(1\u2212 2\u03c1) log(2n\u03c1),\n(21)\nThus, we can conclude that the time complexity of the DMVR algorithm is:\nE{\u03c41 + \u03c42} \u2264 1 2(1\u2212 2\u03c1) \u00d7 ( log( n\u03c1(1\u2212 2\u03c1) 1\u2212 \u03c1 ) + log(2n\u03c1) ) .\n(22)"}, {"heading": "B. Multiple Choice Voting Case", "text": "Consider two choices ck and cl. From the state vector X(t) = [v1(t), v2(t), \u00b7 \u00b7 \u00b7 , vn(t)], we define a new state vector Xk,l(t) = [v\u20321(t), \u00b7 \u00b7 \u00b7 , v\u2032n(t)] by projecting the value set of each node i on {ck, cl}, i.e. v\u2032i(t) = vi(t)\u2229{ck, cl}. Thus, the projected state vector Xk,l(t) represents the path of execution\n1 0r 1\u2212r\nn\nnr ))21((2 \u03c1\u2212\u00d7\nn\nnr ))21(()1(2 \u03c1\u2212\u00d7\u2212\nn\nn )21(2 \u03c1\u2212\u00d7\nFigure 2. The Markov chain model for the second phase. State r \u2212 i shows the size of the set M2(t).\nin a binary voting with just two choices ck, cl. We define X k,l0 to be the convergence set of the projected system as follows:\nXk,l(t) \u2208 X k,l0 if |v\u2032i(t)| \u2264 |v\u2032j(t)| =\u21d2 v\u2032i(t) \u2286 v\u2032j(t), \u2200i, j \u2208 {1, \u00b7 \u00b7 \u00b7 , n}.\n(23)\nLemma 6. Let \u03c4x and \u03c4k,lx be the time that the state vectors X(t) and Xk,l(t) hit their corresponding convergence sets. Then, we have: \u03c4x = maxk,l\u2208V,k 6=l \u03c4k,lx .\nProof: First, we prove that \u03c4x \u2265 maxk,l\u2208V,k 6=l \u03c4k,lx . If X(t) \u2208 X0, then for all k, l \u2208 {1, \u00b7 \u00b7 \u00b7 ,K}, k 6= l:\n\u2200i, j \u2208{1, \u00b7 \u00b7 \u00b7 , n}, |vi(t)| \u2264 |vj(t)| \u21d0\u21d2 vi(t) \u2286 vj(t) =\u21d2|v\u2032i(t)| \u2264 |v\u2032j(t)| and v\u2032i(t) \u2286 v\u2032j(t) =\u21d2 Xk,l(t) \u2208 X k,l 0 .\n(24)\nNow, we show that \u03c4x \u2264 maxk,l\u2208V,k 6=l \u03c4k,lx . Consider any two nodes i and j at time t = maxk,l\u2208V,k 6=l \u03c4k,lx . Without loss of generality, assume that |vi(t)| \u2264 |vj(t)|. We will show that vi(t) \u2286 vj(t). By contradiction, suppose that there exists a choice ck such that ck \u2208 vi(t) and ck 6\u2208 vj(t). Now, consider any choice cl \u2208 vj(t). Since t \u2265 \u03c4k,lx , the state vector Xk,l(t) has already hit its convergence set. This occurs if and only if vi(t)\u2229{ck, cl} = {ck, cl} and vj(t)\u2229{ck, cl} = {cl}. Hence, we can conclude that cl \u2208 vi(t),\u2200cl \u2208 vj(t). However, it means that |vi(t)| > |vj(t)| which is a contradiction.\nFrom (19) and (20), E{\u03c4k,lx } and Var(\u03c4k,lx ) can be obtained by substituting r, s with n\u03c1k and n\u03c1l, respectively.\nLemma 7. (Order Statistics [24]) Let [Z1, \u00b7 \u00b7 \u00b7 , ZR] denote R \u2265 2 random variables (not necessarily independent or identically distributed) with means [\u00b5r] and variances [\u03c32r ]. Let Zmax = maxr=1,\u00b7\u00b7\u00b7 ,R Zr. Then, we have:\nE{Zmax} \u2264 1\nR R\u2211 r=1 \u00b5r+ \u221a\u221a\u221a\u221aR\u2212 1 R R\u2211 r=1 [ \u03c32r + (\u00b5r \u2212 1 R R\u2211 r=1 \u00b5r) 2 ]\n(25)\nNow, we can give an upper bound on E{\u03c4x} from above lemma:\nE{\u03c4x} \u2264 \u00b5+ \u221a \u2211 k,l\u2208V,k 6=l [ Var(\u03c4k,lx ) + (E{\u03c4k,lx } \u2212 \u00b5)2 ] = O( log(n)\nmin j=1,\u00b7\u00b7\u00b7 ,K\u22121\n\u03c1j+1 \u2212 \u03c1j ),\n(26)\nwhere \u00b5 = 1 (K2 ) \u2211 k,l\u2208V,k 6=l E{\u03c4k,lx }.\n7 After the state vector gets in the convergence set, we should still wait to copy vector v? in memories of all nodes. At time \u03c4x, the number of nodes with the value state {c1, c2, \u00b7 \u00b7 \u00b7 , cj} is n\u03c1j \u2212n\u03c1j+1, 1 \u2264 j < K. LetM\u2032j be the set of such nodes and \u03c4 \u2032j be the time until memories mi,j(t)\u2019s of all nodes are set to {c1, \u00b7 \u00b7 \u00b7 , cj}. When a node i contacts with any node in M\u2032j , its memory mi,j(t) will be set to {c1, \u00b7 \u00b7 \u00b7 , cj}. With the same arguments in previous part, we have:\nE{\u03c4 \u2032j} \u2264 n\n2 n\u22121\u2211 i=0\n1 (n\u2212 i)(n\u03c1j \u2212 n\u03c1j+1) \u2248 1 2(\u03c1j \u2212 \u03c1j+1) log(n),\nVar(\u03c4 \u2032j) \u2264 n2\n4 n\u22121\u2211 i=0\n1 (n\u2212 i)2(n\u03c1j \u2212 n\u03c1j+1)2 \u2248 1 4(\u03c1j \u2212 \u03c1j+1)2 .\n(27)\nThus, an upper bound on \u03c4 \u2032 = max1\u2264j<K \u03c4 \u2032j can be obtained from order statistics:\nE{\u03c4 \u2032} \u2264 \u00b5\u2032 + \u221a\u221a\u221a\u221aK\u22121\u2211 j=1 [ Var(\u03c4 \u2032j) + (E{\u03c4 \u2032j} \u2212 \u00b5\u2032)2 ] = O( log(n)\nmin j=1,\u00b7\u00b7\u00b7 ,K\u22121\n\u03c1j+1 \u2212 \u03c1j ),\n(28)\nwhere \u00b5\u2032 = 1K\u22121 K\u22121\u2211 j=1 E{\u03c4 \u2032j}. From the bounds in (26) and (28), we can conclude that the time complexity of the DMVR algorithm is O( log(n)min\nj=1,\u00b7\u00b7\u00b7 ,K\u22121 \u03c1j+1\u2212\u03c1j )."}, {"heading": "C. Speeding up the DMVR algorithm for majority voting problem", "text": "The execution time of the DMVR algorithm can be divided into two phases: The first phase starts at time zero and it ends when the state vector X(t) gets in the convergence set X0. Afterwards, the second phase starts and it terminates when all nodes\u2019 memories are set with the majority vote. In order to speed up the second phase, we add the following rule when two nodes i and j contact with each other at time t:\n1: if |vi(t+)| > 1 \u2227 |vj(t+)| > 1 then 2: Generate u from Bernoulli distribution with success\nprobability 0.5. 3: if u = 1 then 4: mi(t\n+) := mj(t), 5: else 6: mj(t\n+) := mi(t). 7: end if 8: end if It is worth mentioning that the added rule is executed from\nthe beginning of the algorithm. The idea behind this rule is that even nodes with the value sets other than the majority vote, cooperate in spreading the majority vote in the memories of all nodes. We call the proposed solution as the enhanced version of the DMVR algorithm. Simulation results show that the enhanced version of the DMVR algorithm can speed up the DMVR algorithm in complete graph, torus, and ring networks.\n0.51 0.52 0.53 0.54 0.55 0.56 0.57 0.58 0.59 0.6 0\n20\n40\n60\n80\n100\n120\n\u03c1 1\nE {\u03c4\ni}\nComplete graph, n=100\nE{\u03c4 1 } (Simulation) E{\u03c4 1 } (Analysis, Eq. (19)) E{\u03c4 2 } (Simulation) E{\u03c4 2 } (Analysis, Eq. (21))\nFigure 3. Time complexities of first and second phases of the DMVR algorithm versus \u03c11 in binary voting, n = 100.\nLemma 8. Each node converges to the majority vote in a finite time with probability one by running the enhanced version of the DMVR algorithm.\nProof: Let \u03c4x be the time that the state vector X(t) gets in the convergence set. Since then, the only value set with size one in the network would be {c1}. Consider the vector M(t) = [m1(t), \u00b7 \u00b7 \u00b7 ,mn(t)]. We define the Lyapunov function V \u2032(M(t)), t > \u03c4x, as follows:\nV \u2032(M(t)) = n\u2212 |{i | c1 \u2208 mi(t)}|, t > \u03c4x. (29)\nSuppose that two nodes i and j get in contact with each other at time t > \u03c4x. Let M0 be the vector of length n with all entries equal to {c1}. Then, we have:\nE{V \u2032(M(t+))\u2212 V \u2032(M(t)) |M(t) = y} =\n= { \u2264 \u2212 , if |vi(t+)| = 1 \u2228 |vj(t+)| = 1, 0 if |vi(t+)| > 1 \u2227 |vj(t+)| > 1,\n(30)\nwhere y 6= M0. Hence, by the same arguments in Lemma 3, we conclude that M(t) converges to vector M0 with probability one."}, {"heading": "V. SIMULATIONS", "text": "In this section, we evaluate the time complexity of the DMVR algorithm through simulations and compare it with PAGA automaton in binary and ternary voting. Furthermore, we study the proposed time complexity bounds in complete graphs. Each point in simulations is averaged over 1000 runs.\nWe compare the proposed bounds on E{\u03c41} and E{\u03c42} derived in (19) and (21) with simulation results for binary voting in Fig. 3. As it can be seen, the bound E{\u03c41} is exact as we expected while there is a constant gap between simulation and analysis for E{\u03c42}.\nIn Fig. 4, the time complexities of DMVR algorithm, its enhanced version, and the PAGA automaton are depicted versus\n8 0.55 0.6 0.65 0.7 0.75 0.8 0 10 20 30 40 50 60 70 80\n\u03c1 1\nE {\u03c4\n} Complete graph, n=100 The PAGA automaton The DMVR algorithm (enhanced version) The DMVR algorithm\nFigure 4. Comparison of time complexities of the DMVR algorithm, its enhanced version, and the PAGA automaton for binary voting in complete graphs, n = 100.\n\u03c11. Since the transition rule of DMVR algorithm is identical to the PAGA automaton in binary case, the performance of two algorithms are very close to each other. However, the enhanced version of DMVR algorithm outperforms the other two algorithms as \u03c11 gets close to 0.5. In Fig. 5, we can also see this trend in ring and torus networks.\nFor ternary voting problem, we consider the percentage of initial votes in the form of [\u03c11, \u03c12, \u03c13] = [ 13 + \u03b4, 1 3 , 1 3 \u2212 \u03b4] where 0 < \u03b4 < 13 . In Fig. 6, time complexities of enhanced version of the DMVR algorithm and the PAGA automaton are given for \u03b4 \u2208 [0.005, 0.041], n = 198. As it can be seen, the enhanced version of the DMVR algorithm outperforms the PAGA automaton for small \u03b4.\nAt the end, we compare the bounds for E{\u03c4x} and E{\u03c4 \u2032} derived in (26) and (28) for the ranking problem with three votes. In Fig. 7, bounds from order statistics have a small gap with simulation results and they can predict the behaviour of the DMVR algorithm accurately based on the percentage of initial votes."}, {"heading": "VI. CONCLUSIONS", "text": "In this paper, we proposed the DMVR algorithm in order to solve the majority voting and ranking problems for any number of choices. The DMVR algorithm is a simple solution with bounded memory and it is optimal for the ranking problem in terms of number of states. Furthermore, we analyzed time complexity of the DMVR algorithm and showed that it relates inversely to min\ni=1,\u00b7\u00b7\u00b7 ,K\u22121 \u03c1i+1\u2212 \u03c1i. As a future work, it is quite\nimportant to obtain the minimum required number of states for solving majority voting problem. We conjecture that the DMVR algorithm is an optimal solution for majority voting problem, i.e. at least K \u00d7 2K\u22121 states are required for any possible solution.\n0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0\n100\n200\n300\n400\n500\n600\n700\n\u03c1 1\nE {\u03c4\n}\nRing, n=100\nThe PAGA automaton The DMVR algorithm (enhanced version)\n(a) Ring networks.\n0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0\n10\n20\n30\n40\n50\n60\n70\n80\n\u03c1 1\nE {\u03c4\n}\nTorus, n=100\nThe PAGA automaton The DMVR algorithm (enhanced version)\n(b) Torus networks."}], "references": [{"title": "Local vote decision fusion for target detection in wireless sensor networks", "author": ["N. Katenka", "E. Levina", "G. Michailidis"], "venue": "Signal Processing, IEEE Transactions on, vol. 56, no. 1, pp. 329\u2013338, 2008.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "An improved threshold approximation for local vote decision fusion", "author": ["M.S. Ridout"], "venue": "Signal Processing, IEEE Transactions on, vol. 61, no. 5, pp. 1104\u20131106, 2013.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Distributed hypothesis testing with social learning and symmetric fusion", "author": ["J.B. Rhim", "V.K. Goyal"], "venue": "Signal Processing, IEEE Transactions on, vol. 62, no. 23, pp. 6298\u20136308, 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Distributed consensus algorithms in sensor networks: Quantized data and random link failures", "author": ["S. Kar", "J.M. Moura"], "venue": "Signal Processing, IEEE Transactions on, vol. 58, no. 3, pp. 1383\u20131400, 2010.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Computation in networks of passively mobile finite-state sensors", "author": ["D. Angluin", "J. Aspnes", "Z. Diamadi", "M.J. Fischer", "R. Peralta"], "venue": "Distributed computing, vol. 18, no. 4, pp. 235\u2013253, 2006.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Programmable chemical controllers made from dna", "author": ["Y.-J. Chen", "N. Dalchau", "N. Srinivas", "A. Phillips", "L. Cardelli", "D. Soloveichik", "G. Seelig"], "venue": "Nature nanotechnology, vol. 8, no. 10, pp. 755\u2013762, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "No two-state ca for density classification exists", "author": ["M. Land", "R. Belew"], "venue": "Physical Review Letters, vol. 74, no. 25, pp. 5148\u20135150, 1995.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1995}, {"title": "Majority consensus and the local majority rule", "author": ["N.H. Mustafa", "A. Peke\u010d"], "venue": "Automata, Languages and Programming. Springer, 2001, pp. 530\u2013542.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2001}, {"title": "The gacs-kurdyumov-levin automaton revisited", "author": ["P.G. de S\u00e1", "C. Maes"], "venue": "Journal of Statistical Physics, vol. 67, no. 3-4, pp. 507\u2013522, 1992.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1992}, {"title": "Distributed probabilistic polling and applications to proportionate agreement", "author": ["Y. Hassin", "D. Peleg"], "venue": "Information and Computation, vol. 171, no. 2, pp. 248\u2013268, 2001.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}, {"title": "Nondeterministic density classification with diffusive probabilistic cellular automata", "author": ["H. Fuk\u015b"], "venue": "Physical Review E, vol. 66, no. 6, p. 066106, 2002.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "Evolution of asynchronous cellular automata for the density task", "author": ["M. Tomassini", "M. Venzi"], "venue": "Parallel Problem Solving from NaturePPSN VII. Springer, 2002, pp. 934\u2013943.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2002}, {"title": "The distributed multiple voting problem", "author": ["F. Benezit", "P. Thiran", "M. Vetterli"], "venue": "Selected Topics in Signal Processing, IEEE Journal of, vol. 5, no. 4, pp. 791\u2013804, 2011.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Randomized gossip algorithms", "author": ["S. Boyd", "A. Ghosh", "B. Prabhakar", "D. Shah"], "venue": "Information Theory, IEEE Transactions on, vol. 52, no. 6,  pp. 2508\u20132530, 2006.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Quantized consensus", "author": ["A. Kashyap", "T. Basar", "R. Srikant"], "venue": "Information Theory, 2006 IEEE International Symposium on, 2006, pp. 635\u2013639.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2006}, {"title": "Interval consensus: from quantized gossip to voting", "author": ["F. B\u00e9n\u00e9zit", "P. Thiran", "M. Vetterli"], "venue": "Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE International Conference on. IEEE, 2009, pp. 3661\u20133664.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Simple dynamics for plurality consensus", "author": ["L. Becchetti", "A. Clementi", "E. Natale", "F. Pasquale", "R. Silvestri", "L. Trevisan"], "venue": "Proceedings of the 26th ACM symposium on Parallelism in algorithms and architectures. ACM, 2014, pp. 247\u2013256.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Plurality consensus in the gossip model", "author": ["L. Becchetti", "A. Clementi", "E. Natale", "F. Pasquale", "R. Silvestri"], "venue": "Proceedings of the 26th ACM-SIAM symposium on discrete algorithms. ACM, 2015, pp. 371\u2013 390.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Distributed ranking in networks with limited memory and communication", "author": ["K. Jung", "B. Kim", "M. Vojnovic"], "venue": "Information Theory Proceedings (ISIT), 2012 IEEE International Symposium on. IEEE, 2012, pp. 980\u2013984.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Distributed multivalued consensus", "author": ["A. Babaee", "M. Draief"], "venue": "The Computer Journal, p. bxt026, 2013.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Convergence speed of binary interval consensus", "author": ["M. Draief", "M. Vojnovic"], "venue": "SIAM Journal on Control and Optimization, vol. 50, no. 3, pp. 1087\u20131109, 2012.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Tight bounds on expected order statistics", "author": ["D. Bertsimas", "K. Natarajan", "C.-P. Teo"], "venue": "Probability in the Engineering and Informational Sciences, vol. 20, no. 04, pp. 667\u2013686, 2006.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "It can be employed as a subroutine in many network applications such as target detection in sensor networks [1], [2], distributed hypothesis testing [3], quantized consensus [4], voting in distributed systems [5], and molcular nanorobots [6].", "startOffset": 108, "endOffset": 111}, {"referenceID": 1, "context": "It can be employed as a subroutine in many network applications such as target detection in sensor networks [1], [2], distributed hypothesis testing [3], quantized consensus [4], voting in distributed systems [5], and molcular nanorobots [6].", "startOffset": 113, "endOffset": 116}, {"referenceID": 2, "context": "It can be employed as a subroutine in many network applications such as target detection in sensor networks [1], [2], distributed hypothesis testing [3], quantized consensus [4], voting in distributed systems [5], and molcular nanorobots [6].", "startOffset": 149, "endOffset": 152}, {"referenceID": 3, "context": "It can be employed as a subroutine in many network applications such as target detection in sensor networks [1], [2], distributed hypothesis testing [3], quantized consensus [4], voting in distributed systems [5], and molcular nanorobots [6].", "startOffset": 174, "endOffset": 177}, {"referenceID": 4, "context": "It can be employed as a subroutine in many network applications such as target detection in sensor networks [1], [2], distributed hypothesis testing [3], quantized consensus [4], voting in distributed systems [5], and molcular nanorobots [6].", "startOffset": 209, "endOffset": 212}, {"referenceID": 5, "context": "It can be employed as a subroutine in many network applications such as target detection in sensor networks [1], [2], distributed hypothesis testing [3], quantized consensus [4], voting in distributed systems [5], and molcular nanorobots [6].", "startOffset": 238, "endOffset": 241}, {"referenceID": 0, "context": "As an example in target detection [1], wireless sensors combine their binary decisions about the presence of a target through majority voting, and send a report to the fusion center if the majority is in favor of presence.", "startOffset": 34, "endOffset": 37}, {"referenceID": 6, "context": "In [7], it has been shown that there is no synchronous deterministic two-state automaton that can solve binary voting problem in a connected network.", "startOffset": 3, "endOffset": 6}, {"referenceID": 7, "context": "Several two-state automata have been proposed for the ring topology [8], [9], the most successful of which can get the correct result in nearly 83% of initial configurations of selected votes [10].", "startOffset": 73, "endOffset": 76}, {"referenceID": 8, "context": "Several two-state automata have been proposed for the ring topology [8], [9], the most successful of which can get the correct result in nearly 83% of initial configurations of selected votes [10].", "startOffset": 192, "endOffset": 196}, {"referenceID": 6, "context": "In order to circumvent the impossibility result of [7], asynchronous and probabilistic automata have also been presented in CA community [11]\u2013 [13].", "startOffset": 51, "endOffset": 54}, {"referenceID": 9, "context": "In order to circumvent the impossibility result of [7], asynchronous and probabilistic automata have also been presented in CA community [11]\u2013 [13].", "startOffset": 137, "endOffset": 141}, {"referenceID": 11, "context": "In order to circumvent the impossibility result of [7], asynchronous and probabilistic automata have also been presented in CA community [11]\u2013 [13].", "startOffset": 143, "endOffset": 147}, {"referenceID": 12, "context": "However, none of them can obtain the correct result with probability one [14].", "startOffset": 73, "endOffset": 77}, {"referenceID": 13, "context": "Using a different approach, binary voting problem can be solved by a randomized gossip algorithm [15] that computes the average of initial node values.", "startOffset": 97, "endOffset": 101}, {"referenceID": 14, "context": "The drawback of this approach is that the number of required states in its quantized version [16] grows linearly in terms of the network size [14].", "startOffset": 93, "endOffset": 97}, {"referenceID": 12, "context": "The drawback of this approach is that the number of required states in its quantized version [16] grows linearly in terms of the network size [14].", "startOffset": 142, "endOffset": 146}, {"referenceID": 15, "context": "[17] proposed an elegant solution based on an automaton, with the state space {0, 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "5, 1}, which resembles the idea in [16].", "startOffset": 35, "endOffset": 39}, {"referenceID": 12, "context": "In [14], a Pairwise Asynchronous Graph Automata (PAGA) has been used to extend the above idea to the multiple choice voting problem, and sufficient conditions for convergence are stated.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "For majority voting with more than four choices, pairwise and parallel comparison among the choices, has been proposed [14], requiring \u0398(2K(K\u22121)) number of states in terms of the number of choices, K.", "startOffset": 119, "endOffset": 123}, {"referenceID": 16, "context": "One of the main problems is whether voting automata exist for any number of multiple choices without running multiple binary or ternary voting automata in parallel? Furthermore, what is the minimum number of states of a possible solution? In more recent works [18]\u2013[21], it has been shown that the majority vote can be obtained with high probability if the initial votes are sufficiently biased to the majority or the network size is large enough.", "startOffset": 260, "endOffset": 264}, {"referenceID": 19, "context": "One of the main problems is whether voting automata exist for any number of multiple choices without running multiple binary or ternary voting automata in parallel? Furthermore, what is the minimum number of states of a possible solution? In more recent works [18]\u2013[21], it has been shown that the majority vote can be obtained with high probability if the initial votes are sufficiently biased to the majority or the network size is large enough.", "startOffset": 265, "endOffset": 269}, {"referenceID": 18, "context": "A generalization of the distributed voting problem, is the distributed ranking problem in which the goal is to rank all the K choices in terms of the number of votes, each get from different network nodes [20].", "startOffset": 205, "endOffset": 209}, {"referenceID": 12, "context": "For instance, the number of required states is 12 for ternary voting, and 32 for quaternary voting, compared to respectively 15 and 100 states in the case of PAGA algorithm [14].", "startOffset": 173, "endOffset": 177}, {"referenceID": 13, "context": "Furthermore, unlike the randomized gossip algorithms [15], [16], the number of states is independent from the network size.", "startOffset": 53, "endOffset": 57}, {"referenceID": 14, "context": "Furthermore, unlike the randomized gossip algorithms [15], [16], the number of states is independent from the network size.", "startOffset": 59, "endOffset": 63}, {"referenceID": 12, "context": "Thus, the number of states for ternary voting is 12 compared to 15 for the PAGA automaton [14] and it is equal to 32 for quaternary voting while the number of states for the PAGA is 100.", "startOffset": 90, "endOffset": 94}, {"referenceID": 20, "context": "In [23], an upper bound, O(log(n)/(1 \u2212 2\u03c1)), is given for the PAGA algorithm in complete graphs where \u03c12 = \u03c1.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "(Order Statistics [24]) Let [Z1, \u00b7 \u00b7 \u00b7 , ZR] denote R \u2265 2 random variables (not necessarily independent or identically distributed) with means [\u03bcr] and variances [\u03c3 r ].", "startOffset": 18, "endOffset": 22}], "year": 2017, "abstractText": "Considering a network with n nodes, where each node initially votes for one (or more) choices out of K possible choices, we present a Distributed Multi-choice Voting/Ranking (DMVR) algorithm to determine either the choice with maximum vote (the voting problem) or to rank all the choices in terms of their acquired votes (the ranking problem). The algorithm consolidates node votes across the network by updating the states of interacting nodes using two key operations; the union and the intersection. The proposed algorithm is simple, independent from network size, and easily scalable in terms of the number of choices K, using only K\u00d72K\u22121 nodal states for voting, and K\u00d7K! nodal states for ranking. We prove the number of states to be optimal in the ranking case; this optimality is conjectured to also apply to the voting case. The time complexity of the algorithm is analyzed in complete graphs. We show that the time complexity for both ranking and voting is O(log(n)) for given vote percentages, and is inversely proportional to the minimum of the vote percentage differences among various choices.", "creator": "LaTeX with hyperref package"}}}