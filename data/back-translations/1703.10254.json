{"id": "1703.10254", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Mar-2017", "title": "Bandit-Based Model Selection for Deformable Object Manipulation", "abstract": "We present a novel approach to manipulating deformable objects that is not based on high-precision modeling. The most important contribution of this paper is the formulation of the task as a multi-armed bandit problem, where each arm is a model of the deformable object. To \"pull\" an arm and evaluate its usefulness, we use the arm model to create a speed command for the gripper (s) that holds and executes the object. As the task and object shapes evolve, the utility of each model may change. Our framework estimates these changes and balances the research of the model set with the use of high-benefit models. We also propose an approach based on Kalman Filtering for Non-stationary Multi-armed Normal Bandits (KF-MANB) to use the coupling between models to learn more from each arm pull. We show that our method outperforms previous methods on synthetic studies and is competitive in multiple manipulation tasks in simulation.", "histories": [["v1", "Wed, 29 Mar 2017 22:15:46 GMT  (768kb)", "http://arxiv.org/abs/1703.10254v1", "Presented at the Workshop on the Algorithmic Foundations of Robotics, 2016, San Francisco, CA"]], "COMMENTS": "Presented at the Workshop on the Algorithmic Foundations of Robotics, 2016, San Francisco, CA", "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["dale mcconachie", "dmitry berenson"], "accepted": false, "id": "1703.10254"}, "pdf": {"name": "1703.10254.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Dmitry Berenson"], "emails": ["dmcconac@umich.edu,", "berenson@eecs.umich.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 3.\n10 25\n4v 1\n[ cs\n.R O\n] 2\n9 M\nar 2"}, {"heading": "1 Introduction", "text": "One of the primary challenges in manipulating deformable objects is the difficulty of modeling and simulating them. The most common simulation methods use Mass-Spring models [1,2], which are generally not accurate for large deformations [3], and Finite-Element models [4,5], which require significant tuning and are very sensitive to the discretization of the object. Approaches like [6,7] bypass this challenge by using offline demonstrations to teach the robot specific manipulation tasks; however, when a new task is attempted a new training set needs to be generated. In our application we are interested in a way to manipulate a deformable object without a high-fidelity model or training set available a priori. For instance, imagine a robot encountering a new piece of clothing for a new task. While it may have models for previously-seen clothes or training sets for previous tasks, there is no guarantee that those models or training sets are appropriate for the new task. Also, depending on the state of the clothing different models may be most useful at different times in the manipulation task.\nRather than assuming we have a high-fidelity model of a deformable object interacting with its environment, our approach is to have multiple models available for use, any one of which may be useful at a given time. We do not assume these models are correct, we simply treat the models as having some measurable utility to the task. The utility of a given model is the expected reduction in task\nerror when using this model to generate robot motion. As the task proceeds, the utility of a given model may change, making other models more suitable for the current part of the task. However, without testing a model\u2019s prediction, we do not know its true utility. Testing every model in the set is impractical, as all models would need to be tested at every step, and performing a test changes the state of the object and may drive it into a local minimum. The key question is then which model should be selected for testing at a given time.\nThe central contribution of this paper is framing the model selection problem as a Multi-Armed Bandit (MAB) problem where the goal is to find the model that has the highest utility for a given task. An arm represents a single model of the deformable object; to \u201cpull\u201d an arm is to use the arm\u2019s model to generate and execute a velocity command for the robot. The reward received is the reduction in task error after executing the command. In order to determine which model has the highest utility we need to explore the model space, however we also want to exploit the information we have gained by using models that we estimate to have high utility. One of the primary challenges in performing this exploration versus exploitation trade-off is that our models are inherently coupled and nonstationary; performing an action changes the state of the system which can change the utility of every model, as well as the reward of pulling each arm.While there is work that frames robust trajectory selection as a MAB problem [8], we are not aware of any previous work which either 1) frames model selection for deformable objects as a MAB problem; or 2) addresses the coupling between arms for non-stationary MAB problems.\nIn our experiments, we show how to formulate a MAB problem with coupled arms for Jacobian-based models. We perform our experiments on three synthetic systems, and on three deformable object manipulation tasks in the Bullet [9] simulator. We demonstrate that formulating model selection as a MAB problem is able to successfully perform all three manipulation tasks. We also show that our proposed MAB algorithm outperforms previous MAB methods on synthetic trials, and performs competitively on the manipulation tasks."}, {"heading": "2 Related Work", "text": "Deformable Object Modeling: One of the key challenges in manipulating deformable objects is the difficulty inherent in modeling and simulating them. While there has been some progress towards online modeling of deformable objects [10,11] these methods rely on a time consuming training phase for each object to be modeled. Of particular interest are Jacobian-based models such as [12] and [13]. In these models we assume that there is some function F : SE(3)G \u2192 RN which maps a configuration of G robot grippers q \u2208 SE(3)G to a parameterization of the deformable object P \u2208 RN , where N is the dimensionality of the parameterization of the deformable object. These models are then\nlinearized by calculating an approximation of the the Jacobian of F :\nP = F (q)\n\u2202P \u2202t = \u2202F (q) \u2202q \u2202q \u2202t\nP\u0307 = J(q)q\u0307 . (1)\nComputation of an exact Jacobian J(q) at a given configuration q is often computationally intractable and requires high-fidelity models and simulators, so instead approximations are frequently used. A shared characteristic of these approximations is some reliance on tuned parameters. This tuning process can be tedious, and in some cases needs to be done on a per-task basis.\nIn this paper we consider two types of approximate Jacobian models. The first approximation we use is a diminishing-rigidity Jacobian [12] which assumes that points on the deformable object that are near a gripper move \u201calmost rigidly\u201d with respect to the gripper while points that are further away move \u201cless rigidly\u201d. This approximation uses deformability parameters to control how quickly the rigidity decreases with distance. The second approximation we use is an adaptive Jacobian [13] which uses online estimation to approximate J(q). Adaptive Jacobian models rely on a learning rate to control how quickly the estimation changes from one timestep to the next.\nModel Selection: In order to accomplish a given manipulation task, we need to determine which type of model to use at the current time to compute the next velocity command, as well as how to set the model parameters. Frequently this selection is done manually, however, there are methods designed to make these determinations automatically. Machine learning techniques such as [14,15] rely on supervised training data in order to intelligently search for the best regression or classification model, however, it is unclear how to acquire such training data for the task at hand without having already performed the task. The most directly applicable methods come from the Multi-Armed Bandit (MAB) literature [16,17,18]. In this framework there are multiple actions we can take, each of which provides us with some reward according to an unknown probability distribution. The problem then is to determine which action to take (which arm to pull) at each time step in order to maximize reward.\nThe MAB approach is well-studied for problems where the reward distributions are stationary; i.e. the distributions do not change over time [16,19]. This is not the case for deformable object manipulation; consider the situation where the object is far away from the goal versus the object being at the goal. In the first case there is a possibility of an action moving the object closer to the goal and thus achieving a positive reward; however, in the second case any motion would, at best, give zero reward.\nRecent work [20] on non-stationary MAB problems offer promising results that utilize independent Kalman filters as the basis for the estimation of a nonstationary reward distribution for each arm. This algorithm (KF-MANB) provides a Bayesian estimate of the reward distribution at each timestep, assuming that the reward is normally distributed. KF-MANB then performs Thompson\nsampling [19] to select which arm to pull, choosing each in proportion to the belief that it is the optimal arm. We build on this approach in this paper to produce a method that also accounts for dependencies between arms by approximating the coupling between arms at each timestep.\nFor the tasks we address, the reward distributions are both non-stationary as well as dependent. Because all arms are operating on the same physical system, pulling one arm both gives us information about the distributions over other arms, as well as changing the future reward distributions of all arms. While work has been done on dependent bandits [21,22], we are not aware of any work addressing the combination of non-stationary and dependent bandits. Our method for model selection is inspired by KF-MANB, however we directly use coupling between models in order to form a joint reward distribution over all models. This enables a pull of a single arm to provide information about all arms, and thus we spend less time exploring the model space and more time exploiting useful models to perform the manipulation task."}, {"heading": "3 Problem Statement", "text": "Let the robot be represented by a set of G grippers with configuration q \u2208 SE(3)G. We assume that the robot configuration can be measured exactly; in this work we assume the robot to be a set of free floating grippers; in practice we can track the motion of these with inverse kinematics on a real robot. We use the Lie algebra [23] of SE(3) to represent robot gripper velocities. This is the tangent space of SE(3), denoted as se(3). The velocity of a single gripper g is then q\u0307g = [ vTg \u03c9 T g ]T \u2208 se(3) where vg and \u03c9g are the translational and rotational components of the gripper velocity. We define the velocity of the entire robot to be q\u0307 = [\nq\u0307T1 . . . q\u0307 T G\n]T \u2208 se(3)G. We define the inner product of two gripper\nvelocities q\u03071, q\u03072 \u2208 se(3) to be \u3008q\u03071, q\u03072\u3009 = \u3008q\u03071, q\u03071\u3009c = vT1 v2 + c\u03c9 T 1 \u03c92, where c is a non-negative scaling factor relating rotational and translational velocities. The configuration of a deformable object is a set P \u2282 R3 of P points. We assume that we have a method of sensing P . To measure the norm of a deformable object velocity P\u0307 = [\nP\u0307T1 . . . P\u0307 T P\n]T \u2208 R3P we will use a weighted Euclidean norm\n\u2016P\u0307\u20162W = P \u2211\ni=1\nwiP\u0307 T i P\u0307i = P\u0307 T diag (W )P\u0307 (2)\nwhere W = [ w1 . . . wP ]T\n\u2208 RP is a set of non-negative weights. The rest of the environment is denoted O and is assumed to be both static, and known exactly.\nLet a deformation model be defined as a function \u03c6 : se(3)G \u2192 R3P which maps a change in robot configuration q\u0307 to a change in object configuration P\u0307 . Let M be a set of M deformable models which satisfy this definition. Each model is associated with a robot command function \u03c8 : R3P \u00d7 RP \u2192 se(3)G which maps a desired deformable object velocity P\u0307 and weightW (Sec. 5.2) to a robot velocity command q\u0307. \u03c6 and \u03c8 also take the object and robot configuration\n(P , q) as additional input, however this is omitted for clarity. When a model m is selected for testing, the model generates a gripper command\nq\u0307m(t) = \u03c8m(P\u0307(t),W (t)) (3)\nwhich is then executed for one unit of time, moving the deformable object to configuration P(t+ 1).\nThe problem we address in this paper is which model m \u2208 M to select in order to to move G grippers such that the points in P align as closely as possible with some task-defined set of T target points T \u2282 R3, while avoiding gripper collision and excessive stretching of the deformable object. Each task defines a function \u03c1 which measures the alignment error between P and T . The method we present is a local method which picks a single model m\u2217 at each timestep to treat as the true model. This model is then used to reduce error as much as possible while avoiding collision and excessive stretching.\nm\u2217 = argmin m\u2208M \u03c1(T ,P(t+ 1)) (4)\nWe show that this problem can be treated as an instance of the multi-arm nonstationary dependent bandit problem."}, {"heading": "4 Bandit-Based Model Selection", "text": "The primary difficulty with solving (4) directly is that the effectiveness of a particular model in minimizing error is unknown. It may be the case that no model in the set produces the optimal option, however, this does not prevent a model from being useful. In particular the utility of a model may change from one task to another, and from one configuration to another as the deformable object changes shape, and moves in and out of contact with the environment. We start by defining the utility um(t) \u2208 R of a model as the expected improvement in task error \u03c1 if model m is used to generate a robot command at time t. If we know which model has the highest utility then we can solve (4). This leads to a classic exploration versus exploitation trade-off where we need to explore the space of models in order to learn which one is the most useful, while also exploiting the knowledge we have already gained. The multi-armed bandit framework is explicitly designed to handle this trade-off.\nIn the MAB framework, each arm represents a model in M; to pull arm m is to command the grippers with velocity q\u0307m(t) (Eq. 3) for 1 unit of time. We then define the reward rm(t + 1) after taking action q\u0307m(t) as the improvement in error\nrm(t+ 1) = \u03c1(t)\u2212 \u03c1(t+ 1) = um(t) + w (5)\nwhere w is a zero-mean noise term. The goal is to pick a sequence of arm pulls to minimize total expected regret R(Tf) over some (possibly infinite) horizon Tf\nE[R(Tf )] =\nTf \u2211\nt=1\n(E[r\u2217(t)]\u2212 E[r(t)]) (6)\nwhere r\u2217(t) is the reward of the best model at time t. The next section describes how to use bandit-based model selection for deformable object manipulation."}, {"heading": "5 MAB Formulation for Deformable Object Manipulation", "text": "Algorithm 1 MainLoop(O, \u03b2, \u03bb) 1: t\u2190 0 2: D \u2190 GeodesicDistanceMatrix(Prelaxed) 3: M \u2190 InitializeModels(D) 4: InitialzeBanditAlgorithm() 5: P(0) \u2190 SensePoints() 6: q(0) \u2190 SenseRobotConfig() 7: while true do 8: m\u2190 SelectArmUsingBanditAlgorithm() 9: T \u2190 GetTargets() 10: P\u0307e,We \u2190 ErrorCorrection(P(t), T ) 11: P\u0307s,Ws \u2190 StretchingCorrection(D, \u03bb,P(t)) 12: P\u0307d,Wd \u2190 CombineTerms(P\u0307e,We, P\u0307s,Ws) 13: q\u0307d \u2190 \u03c8m(P\u0307d,Wd) 14: q\u0307 \u2190 ObstacleRepulsion(q\u0307d,O, \u03b2) 15: CommandConfiguration(q(t) + q\u0307) 16: P(t+ 1) \u2190 SensePoints() 17: q(t+ 1) \u2190 SenseRobotConfig() 18: UpdateBanditAlgorithm() 19: t \u2190 t+ 1 20: end while Our algorithm (Alg. 1) can be broken down into four major sections and an initialization block. In the initialization block we pre-compute the geodesic distance between every pair of points in P when the deformable object is in its \u201cnatural\u201d or \u201crelaxed\u201d state and store the result in D. These distances are used to construct the deformation models (Sec. 5.3), as well as to avoid overstretching the object (Sec. 5.2). At each iteration we: 1) pick a model to use to achieve the desired direction (Sec. 5.1); 2) compute the task-defined desired direction to move the deformable object (Sec. 5.2); 3) generate a velocity command using the chosen model (Sec. 5.3); 4) modify the command to avoid obstacles (Sec. 5.2); and 5) update bandit algorithm parameters (Sec. 5.1)."}, {"heading": "5.1 Algorithms for MAB", "text": "Previous solutions [16,20] to minimizing (6) assume that rewards for each arm are normally and independently distributed and then estimate the mean and variance of each Gaussian distribution. We test three algorithms in our experiments: Upper Confidence Bound for normally distributed bandits UCB1-Normal, Kalman Filter Based Solution to Non-Stationary Multi-arm Normal Bandits (KF-MANB), and our extension of KF-MANB, Kalman Filter Based Solution to Non-Stationary Multi-arm Normal Dependent Bandit (KF-MANDB).\nUCB1-Normal : The UCB1-Normal algorithm [16] treats each arm (model) as independent, estimating an optimistic Upper Confidence Bound (UCB) for the utility of each model. The model with the highest UCB is used to command the robot at each timestep. This algorithm assumes that the utility of each model is stationary, gradually shifting from exploration to exploitation as more information is gained. While our problem is non-stationary and dependant, we use\nUCB1-Normal as a baseline algorithm to compare against due to its prevalence in previous work. The algorithm is shown in App. A.1 for reference.\nKF-MANB : The Kalman Filter Based Solution to Non-Stationary Multi-arm Bandit (KF-MANB) algorithm [20] uses independent Kalman filters to estimate the utility distribution of each model, and then uses Thompson sampling [19] to chose which model to use at each timestep. Because this algorithm explicitly allows for non-stationary reward distributions, it is able to \u201cswitch\u201d between models much faster than UCB1-Normal. The KF-MANB algorithm is shown in App. A.1 for reference.\nKF-MANDB : We also propose a variant of KF-MANB, replacing the independent Kalman filters with a single joint Kalman filter. This enables us to capture the correlations between models, allowing us to learn more from each pull. We start by defining utility as a linear system with Gaussian noise with process model u(t+1) = u(t)+v and observation model r(t) = Cu(t)+w where u(t) is our current estimate of the relative utility of each model, while v and w are zero-mean Gaussian noise terms. C is a row vector with a 1 in the column of the model we used and zeros elsewhere. The variance on w is defined as \u03c32obs\u03b7\n2. \u03b7 is a tuning parameter to scale the covariance to match the reward scale of the specific task, while \u03c3obs controls how much we believe each new observation.\nTo define the process noise v we want to leverage correlations between models; if two model predictions are similar, the utility of these models is likely correlated. To measure the similarity between two models i and j we use the angle between their gripper velocity commands q\u0307i and q\u0307j . This similarity is then used to directly construct a covariance matrix for each arm pull:\nv \u223c N ( 0, \u03c32tr\u03b7 2(\u03be\u03a3 + (1\u2212 \u03be) I) )\n\u03a3i,j = \u3008q\u0307i, q\u0307j\u3009\n\u2016q\u0307i\u2016\u2016q\u0307j\u2016 = cos \u03b8i,j .\n(7)\n\u03c3tr is the standard Kalman Filter transition noise factor tuning parameter. \u03be \u2208 [0, 1] is the correlation strength factor; larger \u03be gives more weight to the arm correlation, while smaller \u03be gives lower weight. When \u03be is zero then KF-MANDB will have the same update rule as KF-MANB, thus we can view KF-MANDB as a generalizion of KF-MANB, allowing for correlation between arms.\nAfter estimating the utility of each model and the noise parameters at the current timestep, these values are then passed into a Kalman filter which estimates a new joint distribution. The next step is the same as KF-MANB; we draw a sample from the resulting distribution, then use the model that yields the largest sample to generate the next robot command. In this way we automatically switch between exploration and exploitation as the system evolves; if we are uncertain of the utility of our models then we are more likely to choose different models from one timstep to the next. If we believe that we have accurate estimates of utility, then we are more likely to choose the model with the highest utility.\n5.2 Determining q\u0307\n10: Ws,i \u2190 max(Ws,i,\u2206i,j) 11: Ws,j \u2190 max(Ws,j, \u2206i,j) 12: end if 13: end for 14: end for 15: return {P\u0307s,Ws}\nError Correction We build on previous work [12], splitting the desired deformable object movement into two parts: an error correction part and a stretching correction part. When defining the direction we want to move the deformable object to minimize error we calculate two values; which direction to move the deformable object points P\u0307e and the importance of moving each deformable object point We. This is analogous to computing the gradient of error, as well as an \u201cimportance factor\u201d for each part of the gradient. We need these weights to be able to differentiate between points of the object where the error function is a plateau versus points where the error function is at a local minimum (Fig. 1). Typically this is achieved using a Hessian, however our error function does not have a second derivative at many points. We use the ErrorCorrection (Alg. 2) function to calculate these values. Each target point Ti \u2208 T defines a potential field, pulling the nearest point on the deformable object Pk towards Ti. We is set to the maximum distance Pk is being pulled by any target point. This allowsWe to be insensitive to changes in discretization.\nStretching Correction Our algorithm for stretching correction is similar to that found in [12], with the addition of a weighting term Ws, and a change in how we combine the two terms. We use the StretchingCorrection function (Alg. 3) to compute P\u0307s and Ws based on a task-defined stretching threshold \u03bb \u2265 0. First we compute the distance between every two points on the object and store the result in E. We then compare E to D which contains the relaxed lengths between every pair of points. If any two points are stretched by more than \u03bb, we attempt to move the points closer to each other. We use the same strategy for setting the importance of this stretch-\ning correction Ws as we use for error correction. When combining stretching correction and error correction terms (Alg. 4) we prioritize stretching correction, accepting only the portion of the error correction that is orthogonal to the stretching correction term for each point.\nAlgorithm 4 CombineTerms(P\u0307e,We, P\u0307s,Ws)\n1: for i \u2208 {1, 2, . . . , P} do 2: P\u0307d,i \u2190 P\u0307s,i + ( P\u0307e,i \u2212 ProjP\u0307s,i P\u0307e,i ) 3: Wd,i \u2190Ws,i +We,i 4: end for 5: return {P\u0307d,Wd}\nAlgorithm 5 ObstacleRepulsion(O, \u03b2)\n1: for g \u2208 {1, 2, . . . , G} do 2: Jpg , x\u0307pg , dg \u2190 Proximity(O, g) 3: \u03b3 \u2190 e\u2212\u03b2dg 4: q\u0307c,g \u2190 J +\npg x\u0307pg\n5: q\u0307c,g \u2190 q\u0307max,o\n\u2016q\u0307c,g\u2016 q\u0307c,g\n6: q\u0307g \u2190 \u03b3 ( q\u0307c,g + ( I\u2212 J+pgJpg ) q\u0307g )\n+ (1\u2212 \u03b3)q\u0307g\n7: end for 8: return q\u0307\nObstacle Avoidance In order to guarantee that the grippers do not collide with any obstacles, we use the same strategy from [12], smoothly switching between collision avoidance and other objectives (see Alg. 5). For every gripper g and an obstacle set O we find the distance dg to the nearest obstacle, a unit vector x\u0307pg pointing from the obstacle to the nearest point on the gripper, and a Jacobian Jpg between the gripper\u2019s DOF and the point on the gripper. The Proximity function is shown in Appendix C. \u03b2 > 0 sets the rate at which we change between servoing and collision avoidance objectives. q\u0307max,o > 0 is an internal parameter that sets how quickly we move the robot away from obstacles."}, {"heading": "5.3 Jacobian Models", "text": "Every model must define a prediction function \u03c6(q\u0307) and has an associated robot command function \u03c8(P\u0307,W ). This paper focuses on Jacobian-basedmodels whose basic formulation Eq. (1) directly defines the deformation model \u03c6\n\u03c6(q\u0307) = Jq\u0307. (8)\nWhen defining the robot command function \u03c8, we use the weights W to focus the robot motion on the important part of P\u0307 . This is done by using a weighted norm in a standard minimization problem\n\u03c8(P\u0307 ,W ) = argmin q\u0307\n\u2016Jq\u0307 \u2212 P\u0307\u20162W s.t. \u2016q\u0307\u2016 2 < q\u03072max,e. (9)\nWe also need to ensure that the grippers do not move too quickly, so we add the constraint that the robot moves no more than q\u0307max,e > 0. To solve (9) we use the Gurobi [24] optimizer. We use two different Jacobian approximation methods in our model set; a diminishing rigidity Jacobian, and an adaptive Jacobian, which are described below.\nDiminishing Rigidity Jacobian The key assumption used by this method [12] is diminishing rigidity: the closer a gripper is to a particular part of the deformable object, the more that part of the object moves in the same way that the gripper does (i.e. more \u201crigidly\u201d). The further away a given point on the object is, the less rigidly it behaves; the less it moves when the gripper moves. Details of how to construct a diminishing rigidity Jacobian are in Appendix B. This approximation depends on two parameters ktrans and krot which control how the translational and rotational rigidity scales with distance. Small values entail very rigid objects; high values entail very deformable objects.\nAdaptive Jacobian A different approach is taken in [13], instead using online estimation to approximate J(q). In this formulation we start with some estimate of the Jacobian J\u0303(0) at time t = 0 and then use the Broyden update rule [25] to update J\u0303(t) at each timestep t\nJ\u0303(t) = J\u0303(t\u2212 1) + \u0393\n( P\u0307(t)\u2212 J\u0303(t\u2212 1)q\u0307(t) )\nq\u0307(t)T q\u0307(t) q\u0307(t)T . (10)\nThis update rule depends on a update rate \u0393 \u2208 (0, 1] which controls how quickly the estimate shifts between timesteps."}, {"heading": "6 Experiments and Results", "text": "We test our method on three synthetic tests and three deformable object manipulation tasks in simulation. The synthetic tasks show that the principles we use to estimate the coupling between models are reasonable; while the simulated tasks show that our method is effective at performing deformable object manipulation tasks."}, {"heading": "6.1 Synthetic Tests", "text": "For the synthetic tests, we set up an underactuated system that is representative of manipulating a deformable object with configuration y \u2208 Rn and control input x\u0307 \u2208 Rm such that m < n and y\u0307 = Jx\u0307. To construct the Jacobian of this system\nwe start with J =\n[\nIm\u00d7m 0(n\u2212m)\u00d7m\n]\nand add uniform noise drawn from [\u22120.1, 0.1]\nto each element of J . The system configuration starts at [ 10 . . . 10 ]T\nwith the target configuration set to the origin. Error is defined as \u03c1(t) = \u2016y(t)\u2016, and the desired direction to move the system at each timestep is y\u0307d(t) = \u2212y(t). These tasks have no obstacles or stretching, thus \u03b2, \u03bb, and q\u0307max,o are unused. Rather than setting the utility noise scale \u03b7 a priori, we use an annealing filter\n\u03b7(t+ 1) = max(10\u221210, 0.9\u03b7(t) + 0.1|r(t+ 1)|) . (11)\nThis enables us to track the changing available reward as the system gets closer to the target. All other parameters are shown in App D.\nTo generate a model for the model set we start with the true Jacobian J and add uniform noise drawn from [\u22120.025, 0.025] to each element of J . For an individual trial, each bandit algorithm uses the same J and the same model set. Each bandit algorithm receives the same random number stream during a trial, ensuring that a more favourable stream doesn\u2019t bias results. We ran one small test using a 3\u00d7 2 Jacobian with 10 arms in order to yield results that are easily visualised. The second and third tests are representative of the scale of the simulation experiments, using the same number of models and similar sizes of Jacobian as are used in simulation. A single trial consists of 1000 pulls (1000 commanded actions); each test was performed 100 times to generate statistically significant results. Our results in Table 1 show that KF-MANDB clearly performs the best for all three tests."}, {"heading": "6.2 Simulation Trials", "text": "We now demonstrate the effectiveness of multi-arm bandit techniques on three example tasks, show how to encode those tasks for use in our framework, and discuss experimental results. The first task shows how our method can be applied to a rope, with the goal of winding the rope around a cylinder in the environment. The second and third tasks show the method applied to cloth. In the second task, two grippers manipulate the cloth so that it covers a table. In the third task, we perform a two-stage coverage task, covering portions of two different cylinders. In all three tasks, the alignment error \u03c1(P , T ) is measured as the sum of the distances between every point in T and the closest point in P in meters. Figure 2 shows the target points in red, and the deformable object in green. The video accompanying this paper shows the task executions.\nAll experiments were conducted in the open-source Bullet simulator [9], with additional wrapper code developed at UC Berkeley. The rope is modeled as a series of 49 small capsules linked together by springs and is 1.225m long. The cloth is modeled as a triangle mesh of size 0.5m \u00d7 0.5m for the table coverage task, and size 0.5m\u00d70.625m for the two-stage coverage task. We emphasize that our method does not have access to the model of the deformable object or the simulation parameters. The simulator is used as a \u201cblack box\u201d for testing.\nWe use models generated using the same parameters for all three tasks with a total of 60 models: 49 diminishing rigidity models with rotation and translational deformability values ktrans and krot ranging from 0 to 24 in steps of 4, as well as 11 adaptive Jacobian models with learning rates \u0393 ranging from 1 to 10\u221210 in multiples of 10. All adaptive Jacobian models are initialized with the\nsame starting values; we use the diminishing rigidity Jacobian for this seed with ktrans = krot = 10 for the rope experiment and ktrans = krot = 14 for the cloth experiments to match the best model found in [12]. We use the same strategy for setting \u03b7 as we use for the synthetic tests. App D shows all other parameters.\nWe evaluate results for the MAB algorithms as well as using each of the models in the set for the entire task. To calculate regret for each MAB algorithm, we create copies of the simulator at every timestep and simulate the gripper command, then measure the resulting reward rm(t) for each model. The reward of the best model r\u2217(t) is then the maximum of individual rewards. As KF-MANB and KF-MANDB are not deterministic algorithms, each task is performed 10 times for these methods. All tests are run on an Intel Xeon E5-2683 v4 processor with 64 GB of RAM. UCB1-Normal and KF-MANB solve Eq. (9) once per timestep, while KF-MANDB solves it for every model in M. Computation times for each test are shown in their respective sections.\nWinding a Rope Around a Cylinder : In the first example task, a single gripper holds a rope that is lying on a table. The task is to wind the rope around a cylinder which is also on the table (see Fig. 2). Our results (Fig. 3) show that at the start of the task all the individual models perform nearly identically, starting to split at 2 seconds (when the gripper first approaches the cylinder) and again at 6 seconds. Despite our model set containing models that are unable to perform the task, our formulation is able to successfully perform the task using all three\nbandit algorithms. Interestingly, while KF-MANDB outperforms UCB1-Normal and KF-MANB in terms of regret, all three algorithms produce very similar results. Solving Eq. (9) at each iteration requires an average of 17.3 ms (std. dev. 5.5 ms) for a single model, and 239.5 ms (std. dev. 153.7 ms) for 60 models.\nSpreading a Cloth Across a Table: The second scenario we consider is spreading a cloth across a table. In this scenario two grippers hold the rectangular cloth at two corners and the task is to cover the top of the table with the cloth. All of the models are able to perform the task (see Fig. 4), however, many single-model runs are slower than the bandit methods at completing the task, showing the advantage of the bandit methods. When comparing between the bandit methods, both error and total regret indicate no performance difference between the methods. Solving Eq. (9) at each iteration requires an average of 89.5 ms (std. dev. 82.4 ms) for a single model, and 605.1 ms (std. dev. 514.3 ms) for 60 models.\nTwo-Part Coverage Task : In this experiment, we consider a two-part task. The first part of the task is to cover the top of a cylinder similar to our second scenario. The second part of the task is to cover the far side of a second cylinder. For this task the GetTargets function used previously pulls the cloth directly into the second cylinder. The collision avoidance term then negates any motion in that direction causing the grippers to stop moving. To deal with this, we\ndiscretize the free space using a voxel grid, and then use Dijkstra\u2019s algorithm to find a collision free path between each cover point and every point in free space. We use the result from Dijkstra\u2019s algorithm to define a vector field that pulls the nearest (as defined by Dijkstra\u2019s) deformable object point pk along the shortest collision free path to the target point. This task is the most complex of the three (see Fig. 5); many models are unable to perform the task at all, becoming stuck early in the task. We also observe that both KF-MANB and KF-MANDB show a preference for some models over others. Two interesting trials using KF-MANDB stand out; in the first the grippers end up on opposite sides of the second cylinder, in this configuration the physics engine has difficulty resolving the scene and allows the cloth to be pulled straight through the second cylinder. In the other trial the cloth is pulled off of the first cylinder, however KF-MANDB is able to recover, moving the cloth back onto the first cylinder. KFMANDB and UCB1-Normal are able to perform the task significantly faster than KF-MANB, though all MAB methods complete the task using our formulation. Solving Eq. (9) at each iteration requires an average of 102.6 ms (std. dev. 30.6 ms) for a single model, and 565.5 ms (std. dev. 389.8 ms) for 60 models."}, {"heading": "7 Conclusion", "text": "We have formulated model selection for deformable object manipulation as a MAB problem. Our formulation enables the application of existing MAB algorithms to deformable object manipulation as well as introduces a novel utility metric to measure how useful a model is at performing a given task. We have\nalso presented Kalman Filtering for Non-stationary Multi-arm Normal Dependent Bandits (KF-MANDB) to leverage coupling between dependent bandits to learn more from each arm pull. Our experiments show how to perform several interesting tasks for rope and cloth using our method.\nOne notable result we observe is that finding and exploiting the best model is less important than avoiding poor models for extended periods of time; in all of the experiments UCB1-Normal never leaves its initial exploration phase, however it is able to successfully perform each task. We believe this is due to many models being able to provide commands that have a positive dot-product with the correct direction of motion.\nOne limitation of KF-MANDB is handling bifurcations; when very small differences in command sent to the robot cause large differences in the result the assumption of coupling between models in KF-MANDB does not hold. In future work we seek to explore how to overcome this limitation, as well as using the predictive accuracy of each model as an additional measure of model coupling."}, {"heading": "8 Acknowledgements", "text": "This work was supported in part by NSF grants IIS-1656101 and IIS-1551219. We gratefully acknowledge Calder Phillips-Grafflin for his assistance with Bullet."}, {"heading": "A MAB Algorithm Blocks", "text": "A.1 UCB1-Normal\nReproduced from [16].\nLoop: For each n = 1, 2, . . .\n\u2013 If there is a machine which has been played less than \u23088 logn\u2309 times then play this machine. If multiple machines qualify, we play the machine that has been played less, selecting the machine with the lower index in the case of a tie. \u2013 Otherwise play machine j that maximizes\nx\u0304j +\n\u221a\n16 \u00b7 qj \u2212 nj x\u03042j nj \u2212 1 \u00b7 ln(n\u2212 1) nj (12)\nwhere x\u0304j is the average reward obtained from machine j, qj is the sum of squared rewards obtained from machine j, and nj is the number of times machine j has been played so far.\n\u2013 Update x\u0304j and qj with the obtained reward xj .\nA.2 KF-MANB\nAlgorithm 6 KF-MANB - reproduced from [20]\nInput: Number of bandit arms L; Observation noise \u03c32ob; Transition noise \u03c3 2 tr. Initialization: \u00b5q[1] = \u00b52[1] = \u00b7 \u00b7 \u00b7 = \u00b5L[1] = A; \u03c31[1] = \u03c32[1] = \u00b7 \u00b7 \u00b7 = \u03c3L[1] = B; # Typically, A can be set to 0, with B being sufficiently large for N = 1, 2, . . . do\n1. For each arm j \u2208 {1, . . . , L}, draw a value xj randomly from the associated normal distribution f(xj ;\u00b5j [N ], \u03c3j [N ]) with the parameters (\u00b5j [N ], \u03c3j [N ]). 2. Pull the arm i whose drawn xi is the largest one:\ni = argmax j\u2208{1,...,L} xj .\n3. Receive reward r\u0303i from pulling arm i, and update parameters as follows: \u2013 Arm i:\n\u00b5i[N + 1] = (\u03c32i [N ] + \u03c3 2 tr) \u00b7 r\u0303i + \u03c3 2 ob \u00b7 \u00b5i[N ]\n\u03c32i [N ] + \u03c3 2 tr + \u03c3 2 ob\n\u03c3 2 i [N + 1] =\n(\u03c32i [N ] + \u03c3 2 tr)\u03c3 2 ob\n\u03c32i [N ] + \u03c3 2 tr + \u03c3 2 ob\n\u2013 Arm j 6= i:\n\u00b5j [N + 1] = \u00b5j [N ]\n\u03c3 2 j [N + 1] = \u03c3j [N ] + \u03c3 2 tr\nend for"}, {"heading": "B Diminishing Rigidity Jacobian Construction", "text": "For every point pi \u2208 P and every gripper g we construct a Jacobian Jrigid(q, i, g) such that if pi was rigidly attached to the gripper g then\np\u0307i = Jrigid (q, i, g)q\u0307g = [ Jtrans(q, i, g) Jrot(q, i, g) ] q\u0307g . (13)\nLet Di,g be a measure of the distance between gripper g and point pi. Then the translational rigidity of point pi with respect to gripper g is defined as\nwtrans(i, g) = e \u2212ktransDi,g (14)\nand the rotational rigidity is defined as\nwrot(i, g) = e \u2212krotDi,g . (15)\nTo construct an approximate Jacobian J\u0303(q) for a single point we combine the rigid Jacobians with their respective rigidity values\nJ\u0303(q, i, g) = [ wtrans(i, g)Jtrans(q, i, g) wrot(i, g)Jrot(q, i, g) ] , (16)\nand then combine the results into a single matrix\nJ\u0303(q) =\n\n    \nJ\u0303(q, 1, 1) J\u0303(q, 1, 2) . . . J\u0303(q, 1, G) J\u0303(q, 2, 1) . . .\n...\nJ\u0303(q, P, 1)\n\n     . (17)"}, {"heading": "C Obstacle Proximity Algorithm", "text": "Algorithm 7 Proximity(g,O) - reproduced from [12]\n1: dg \u2190 \u221e 2: for o \u2208 {1, 2, . . . , |O } do 3: pg, po \u2190 ClosestPoints(g, o) 4: v \u2190 pg \u2212 po 5: if \u2016v\u2016 < dg then 6: dg \u2190 \u2016v\u2016 7: x\u0307pg \u2190\nv \u2016v\u2016\n8: Jpg \u2190 GripperPointJacobian(g, p g)\n9: end if 10: end for 11: return {Jpg , xpg , dg}"}, {"heading": "D Experiment Parameter Values", "text": ""}], "references": [{"title": "A survey of deformable modeling in computer graphics", "author": ["S.F.F. Gibson", "B. Mirtich"], "venue": "Technical report, Mitsubishi Electric Research Laboratories", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1997}, {"title": "Soft Material Modeling for Robotic Manipulation", "author": ["N. Essahbi", "B.C. Bouzgarrou", "G. Gogu"], "venue": "Applied Mechanics and Materials.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Trajectory planning with task constraints in densely filled environments", "author": ["B. Maris", "D. Botturi", "P. Fiorini"], "venue": "IROS.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Stable real-time deformations", "author": ["M. M\u00fcller", "J. Dorsey", "L. McMillan", "R. Jagnow", "B. Cutler"], "venue": "SIGGRAPH.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2002}, {"title": "Finite Element Procedures", "author": ["K.J. Bathe"], "venue": "Klaus-Jurgen Bathe", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning from demonstrations through the use of non-rigid registration", "author": ["J. Schulman", "J. Ho", "C. Lee", "P. Abbeel"], "venue": "Springer Tracts in Advanced Robotics. Volume 114., Springer International Publishing", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Leveraging appearance priors in non-rigid registration, with application to manipulation of deformable objects", "author": ["S.H. Huang", "J. Pan", "G. Mulcaire", "P. Abbeel"], "venue": "IROS.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Robust trajectory selection for rearrangement planning as a multi-armed bandit problem", "author": ["M.C. Koval", "J.E. King", "N.S. Pollard", "S.S. Srinivasa"], "venue": "IROS.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Bullet physics library", "author": ["E. Coumans"], "venue": "Open source: bulletphysics.org", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Acquisition of Elastic Models for Interactive Simulation", "author": ["Jochen Lang", "D.K. Pai", "R.J. Woodham"], "venue": "IJRR 21(8)", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2002}, {"title": "Neural Network Mapping and Clustering of Elastic Behavior From Tactile and Range Imaging for Virtualized Reality Applications", "author": ["A.M. Cretu", "P. Payeur", "E. Petriu"], "venue": "IEEE TIM 57(9)", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Manipulation of deformable objects without modeling and simulating deformation", "author": ["D. Berenson"], "venue": "IROS.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Visually servoed deformation control by robot manipulators", "author": ["D. Navarro-Alarcon", "J.G. Romero"], "venue": "ICRA.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation", "author": ["O. Maron", "A.W. Moore"], "venue": "NIPS.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1994}, {"title": "Automating model search for large scale machine learning", "author": ["E.R. Sparks", "A. Talwalkar", "D. Haas", "M.J. Franklin", "M.I. Jordan", "T. Kraska"], "venue": "SoCC.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Finite-time Analysis of the Multiarmed Bandit Problem", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": "Machine Learning 47(2/3)", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "Multi-armed Bandit Allocation Indices", "author": ["J. Gittins", "K. Glazebrook", "R. Weber"], "venue": "John Wiley & Sons", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Restless Bandits: Activity Allocation in a Changing World", "author": ["P. Whittle"], "venue": "Journal of Applied Probability 25", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1988}, {"title": "Analysis of Thompson Sampling for the multi-armed bandit problem", "author": ["S. Agrawal", "N. Goyal"], "venue": "Conference on Learning Theory", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Solving Non-Stationary Bandit Problems by Random Sampling from Sibling Kalman Filters", "author": ["O.C. Granmo", "S. Berg"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Multi-armed bandit problems with dependent arms", "author": ["S. Pandey", "D. Chakrabarti", "D. Agarwal"], "venue": "ICML, New York, New York, USA", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "The Epoch-Greedy Algorithm for Multi-armed Bandits with Side Information", "author": ["J. Langford", "T. Zhang"], "venue": "NIPS.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "A Mathematical Introduction to Robotic Manipulation", "author": ["R.M. Murray", "Z. Li", "S.S. Sastry"], "venue": "Volume 29. CRC Press", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1994}, {"title": "Gurobi optimization library", "author": ["Gurobi"], "venue": "Proprietary: gurobi.com", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "A class of methods for solving nonlinear simultaneous equations", "author": ["C.G. Broyden"], "venue": "Mathematics of Computation 19(92)", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1965}], "referenceMentions": [{"referenceID": 0, "context": "The most common simulation methods use Mass-Spring models [1,2], which are generally not accurate for large deformations [3], and Finite-Element models [4,5], which require significant tuning and are very sensitive to the discretization of the object.", "startOffset": 58, "endOffset": 63}, {"referenceID": 1, "context": "The most common simulation methods use Mass-Spring models [1,2], which are generally not accurate for large deformations [3], and Finite-Element models [4,5], which require significant tuning and are very sensitive to the discretization of the object.", "startOffset": 58, "endOffset": 63}, {"referenceID": 2, "context": "The most common simulation methods use Mass-Spring models [1,2], which are generally not accurate for large deformations [3], and Finite-Element models [4,5], which require significant tuning and are very sensitive to the discretization of the object.", "startOffset": 121, "endOffset": 124}, {"referenceID": 3, "context": "The most common simulation methods use Mass-Spring models [1,2], which are generally not accurate for large deformations [3], and Finite-Element models [4,5], which require significant tuning and are very sensitive to the discretization of the object.", "startOffset": 152, "endOffset": 157}, {"referenceID": 4, "context": "The most common simulation methods use Mass-Spring models [1,2], which are generally not accurate for large deformations [3], and Finite-Element models [4,5], which require significant tuning and are very sensitive to the discretization of the object.", "startOffset": 152, "endOffset": 157}, {"referenceID": 5, "context": "Approaches like [6,7] bypass this challenge by using offline demonstrations to teach the robot specific manipulation tasks; however, when a new task is attempted a new training set needs to be generated.", "startOffset": 16, "endOffset": 21}, {"referenceID": 6, "context": "Approaches like [6,7] bypass this challenge by using offline demonstrations to teach the robot specific manipulation tasks; however, when a new task is attempted a new training set needs to be generated.", "startOffset": 16, "endOffset": 21}, {"referenceID": 7, "context": "While there is work that frames robust trajectory selection as a MAB problem [8], we are not aware of any previous work which either 1) frames model selection for deformable objects as a MAB problem; or 2) addresses the coupling between arms for non-stationary MAB problems.", "startOffset": 77, "endOffset": 80}, {"referenceID": 8, "context": "We perform our experiments on three synthetic systems, and on three deformable object manipulation tasks in the Bullet [9] simulator.", "startOffset": 119, "endOffset": 122}, {"referenceID": 9, "context": "While there has been some progress towards online modeling of deformable objects [10,11] these methods rely on a time consuming training phase for each object to be modeled.", "startOffset": 81, "endOffset": 88}, {"referenceID": 10, "context": "While there has been some progress towards online modeling of deformable objects [10,11] these methods rely on a time consuming training phase for each object to be modeled.", "startOffset": 81, "endOffset": 88}, {"referenceID": 11, "context": "Of particular interest are Jacobian-based models such as [12] and [13].", "startOffset": 57, "endOffset": 61}, {"referenceID": 12, "context": "Of particular interest are Jacobian-based models such as [12] and [13].", "startOffset": 66, "endOffset": 70}, {"referenceID": 11, "context": "The first approximation we use is a diminishing-rigidity Jacobian [12] which assumes that points on the deformable object that are near a gripper move \u201calmost rigidly\u201d with respect to the gripper while points that are further away move \u201cless rigidly\u201d.", "startOffset": 66, "endOffset": 70}, {"referenceID": 12, "context": "The second approximation we use is an adaptive Jacobian [13] which uses online estimation to approximate J(q).", "startOffset": 56, "endOffset": 60}, {"referenceID": 13, "context": "Machine learning techniques such as [14,15] rely on supervised training data in order to intelligently search for the best regression or classification model, however, it is unclear how to acquire such training data for the task at hand without having already performed the task.", "startOffset": 36, "endOffset": 43}, {"referenceID": 14, "context": "Machine learning techniques such as [14,15] rely on supervised training data in order to intelligently search for the best regression or classification model, however, it is unclear how to acquire such training data for the task at hand without having already performed the task.", "startOffset": 36, "endOffset": 43}, {"referenceID": 15, "context": "The most directly applicable methods come from the Multi-Armed Bandit (MAB) literature [16,17,18].", "startOffset": 87, "endOffset": 97}, {"referenceID": 16, "context": "The most directly applicable methods come from the Multi-Armed Bandit (MAB) literature [16,17,18].", "startOffset": 87, "endOffset": 97}, {"referenceID": 17, "context": "The most directly applicable methods come from the Multi-Armed Bandit (MAB) literature [16,17,18].", "startOffset": 87, "endOffset": 97}, {"referenceID": 15, "context": "the distributions do not change over time [16,19].", "startOffset": 42, "endOffset": 49}, {"referenceID": 18, "context": "the distributions do not change over time [16,19].", "startOffset": 42, "endOffset": 49}, {"referenceID": 19, "context": "Recent work [20] on non-stationary MAB problems offer promising results that utilize independent Kalman filters as the basis for the estimation of a nonstationary reward distribution for each arm.", "startOffset": 12, "endOffset": 16}, {"referenceID": 18, "context": "sampling [19] to select which arm to pull, choosing each in proportion to the belief that it is the optimal arm.", "startOffset": 9, "endOffset": 13}, {"referenceID": 20, "context": "While work has been done on dependent bandits [21,22], we are not aware of any work addressing the combination of non-stationary and dependent bandits.", "startOffset": 46, "endOffset": 53}, {"referenceID": 21, "context": "While work has been done on dependent bandits [21,22], we are not aware of any work addressing the combination of non-stationary and dependent bandits.", "startOffset": 46, "endOffset": 53}, {"referenceID": 22, "context": "We use the Lie algebra [23] of SE(3) to represent robot gripper velocities.", "startOffset": 23, "endOffset": 27}, {"referenceID": 15, "context": "Previous solutions [16,20] to minimizing (6) assume that rewards for each arm are normally and independently distributed and then estimate the mean and variance of each Gaussian distribution.", "startOffset": 19, "endOffset": 26}, {"referenceID": 19, "context": "Previous solutions [16,20] to minimizing (6) assume that rewards for each arm are normally and independently distributed and then estimate the mean and variance of each Gaussian distribution.", "startOffset": 19, "endOffset": 26}, {"referenceID": 15, "context": "UCB1-Normal : The UCB1-Normal algorithm [16] treats each arm (model) as independent, estimating an optimistic Upper Confidence Bound (UCB) for the utility of each model.", "startOffset": 40, "endOffset": 44}, {"referenceID": 19, "context": "KF-MANB : The Kalman Filter Based Solution to Non-Stationary Multi-arm Bandit (KF-MANB) algorithm [20] uses independent Kalman filters to estimate the utility distribution of each model, and then uses Thompson sampling [19] to chose which model to use at each timestep.", "startOffset": 98, "endOffset": 102}, {"referenceID": 18, "context": "KF-MANB : The Kalman Filter Based Solution to Non-Stationary Multi-arm Bandit (KF-MANB) algorithm [20] uses independent Kalman filters to estimate the utility distribution of each model, and then uses Thompson sampling [19] to chose which model to use at each timestep.", "startOffset": 219, "endOffset": 223}, {"referenceID": 0, "context": "\u03be \u2208 [0, 1] is the correlation strength factor; larger \u03be gives more weight to the arm correlation, while smaller \u03be gives lower weight.", "startOffset": 4, "endOffset": 10}, {"referenceID": 11, "context": ", P} do 6: if \u2206i,j > \u03bb then 7: v \u2190 \u2206i,j(Pj \u2212 Pi) 8: \u1e56s,i \u2190 \u1e56s,i + 1 2 v 9: \u1e56s,j \u2190 \u1e56s,j \u2212 1 2 v 10: Ws,i \u2190 max(Ws,i,\u2206i,j) 11: Ws,j \u2190 max(Ws,j, \u2206i,j) 12: end if 13: end for 14: end for 15: return {\u1e56s,Ws} Error Correction We build on previous work [12], splitting the desired deformable object movement into two parts: an error correction part and a stretching correction part.", "startOffset": 245, "endOffset": 249}, {"referenceID": 11, "context": "Stretching Correction Our algorithm for stretching correction is similar to that found in [12], with the addition of a weighting term Ws, and a change in how we combine the two terms.", "startOffset": 90, "endOffset": 94}, {"referenceID": 11, "context": "+ (1\u2212 \u03b3)q\u0307g 7: end for 8: return q\u0307 Obstacle Avoidance In order to guarantee that the grippers do not collide with any obstacles, we use the same strategy from [12], smoothly switching between collision avoidance and other objectives (see Alg.", "startOffset": 160, "endOffset": 164}, {"referenceID": 23, "context": "To solve (9) we use the Gurobi [24] optimizer.", "startOffset": 31, "endOffset": 35}, {"referenceID": 11, "context": "Diminishing Rigidity Jacobian The key assumption used by this method [12] is diminishing rigidity: the closer a gripper is to a particular part of the deformable object, the more that part of the object moves in the same way that the gripper does (i.", "startOffset": 69, "endOffset": 73}, {"referenceID": 12, "context": "Adaptive Jacobian A different approach is taken in [13], instead using online estimation to approximate J(q).", "startOffset": 51, "endOffset": 55}, {"referenceID": 24, "context": "In this formulation we start with some estimate of the Jacobian J\u0303(0) at time t = 0 and then use the Broyden update rule [25] to update J\u0303(t) at each timestep t", "startOffset": 121, "endOffset": 125}, {"referenceID": 8, "context": "All experiments were conducted in the open-source Bullet simulator [9], with additional wrapper code developed at UC Berkeley.", "startOffset": 67, "endOffset": 70}, {"referenceID": 11, "context": "same starting values; we use the diminishing rigidity Jacobian for this seed with ktrans = krot = 10 for the rope experiment and ktrans = krot = 14 for the cloth experiments to match the best model found in [12].", "startOffset": 207, "endOffset": 211}], "year": 2017, "abstractText": "We present a novel approach to deformable object manipulation that does not rely on highly-accurate modeling. The key contribution of this paper is to formulate the task as a Multi-Armed Bandit problem, with each arm representing a model of the deformable object. To \u201cpull\u201d an arm and evaluate its utility, we use the arm\u2019s model to generate a velocity command for the gripper(s) holding the object and execute it. As the task proceeds and the object deforms, the utility of each model can change. Our framework estimates these changes and balances exploration of the model set with exploitation of high-utility models. We also propose an approach based on Kalman Filtering for Non-stationary Multi-armed Normal Bandits (KF-MANB) to leverage the coupling between models to learn more from each arm pull. We demonstrate that our method outperforms previous methods on synthetic trials, and performs competitively on several manipulation tasks in simulation.", "creator": "LaTeX with hyperref package"}}}