{"id": "1705.05088", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-May-2017", "title": "Simulated Penetration Testing and Mitigation Analysis", "abstract": "Penetration testing is a well-established practical concept for identifying potentially exploitable vulnerabilities and an important component of a security audit. A holistic security assessment for networks consisting of several hundred hosts is hardly feasible, even if without some kind of mechanisation. Attenuation, prioritisation of countermeasures taking into account a certain budget, currently lacks a solid theoretical understanding and is therefore more art than science. In this work, we propose the first approach to performing comprehensive what-if analyses in order to think conceptually well about attenuation. To evaluate and compare attenuation strategies, we use simulated penetration tests, i.e. automated attack identification, based on a network model in which a subset of specific attenuation measures, e.g. changes in network topology, system upgrades, configuration changes, etc., are applied. We identify optimal combinations that allow us to build the analysis of the maximum success of a comprehensive mitigation strategy (i.e., minimising the impact of a whole mountain).", "histories": [["v1", "Mon, 15 May 2017 07:05:34 GMT  (632kb,D)", "http://arxiv.org/abs/1705.05088v1", null]], "reviews": [], "SUBJECTS": "cs.CR cs.AI", "authors": ["michael backes", "j\\\"org hoffmann", "robert k\\\"unnemann", "patrick speicher", "marcel steinmetz"], "accepted": false, "id": "1705.05088"}, "pdf": {"name": "1705.05088.pdf", "metadata": {"source": "CRF", "title": "Simulated Penetration Testing and Mitigation Analysis", "authors": ["Michael Backes", "J\u00f6rg Hoffmann", "Robert K\u00fcnnemann", "Marcel Steinmetz"], "emails": ["backes@mpi-sws.org", "hoffmann@cs.uni-saarland.de", "robert.kuennemann@cispa.saarland", "patrick.speicher@cispa.saarland", "steinmetz@cs.uni-saarland.de"], "sections": [{"heading": null, "text": "In this work, we propose the first approach for conducting comprehensive what-if analyses in order to reason about mitigation in a conceptually well-founded manner. To evaluate and compare mitigation strategies, we use simulated penetration testing, i.e., automated attack-finding, based on a network model to which a subset of a given set of mitigation actions, e.g., changes to the network topology, system updates, configuration changes etc. is applied. We determine optimal combinations that minimize the maximal attacker success (similar to a Stackelberg game), and thus provide a well-founded basis for a holistic mitigation strategy. We show that these what-if analysis models can largely be derived from network scan, public vulnerability databases and manual inspection with various degrees of automation and detail, and we simulate mitigation analysis on networks of different size and vulnerability."}, {"heading": "1. Introduction", "text": "Penetration testing (pentesting) evaluates the security of an IT infrastructure by trying to identify and exploit vulnerabilities. It constitutes a central, often mandatory component of a security audit, e.g., the Payment Card Industry Data Security Standard prescribes \u2018network vulnerability scans at least quarterly and after any significant change in the network\u2019 [10]. Network penetration tests are frequently conducted on networks with hundreds of machines. Here, the vulnerability of the network is a combination of host-specific weaknesses that compose to an attack. Consequently, an exhausting search is out of question, as the search space for these combinations grows exponentially with the number\nof hosts. Choosing the right attack vector requires a vast amount of experience, arguably making network pentesting more art than science.\nWhile it is conceivable that an experienced analyst comes up with several of the most severe attack vectors, this is not sufficient to provide for a sound mitigation strategy, as the evaluation of a mitigation strategy requires a holistic security assessment. So far, there is no rigorous foundation for what is arguably the most important step, the step after the penetration test: how to mitigate these vulnerabilities.\nIn practice, the severity of weaknesses is assessed more or less in isolation, proposed counter-measures all too often focus on single vulnerabilities, and the mitigation path is left to the customer. There are exceptions, but they require considerable manual effort.\nSimulated pentesting was proposed to automate largescale network testing by simulating the attack finding process based on a logical model of the network. The model may be generated from network scans, public vulnerability databases and manual inspection with various degrees of automation and detail. To this end, AI planning methods have been proposed [4], [33] and in fact used commercially, at a company called Core Security, since at least 2010 [11]. These approaches, which derive from earlier approaches based on attack graphs [40], [45], [46], assume complete knowledge over the network configuration, which is often unavailable to the modeller, as well as the attacker. We follow a more recent approach favouring Markov decisions processes (MDP) as the underlying state model to obtain a good middle ground between accuracy and practicality [12], [19] (we discuss this in detail as part of our related work discussion, Section 2).\nSimulated penetration testing has been used to great success, but an important feature was overseen so far. If a model of the network is given, one can reason about possible mitigations without implementing them \u2013 namely, by simulating the attacker on a modified model. This allows for analysing and comparing different mitigation strategies in terms of the (hypothetical) network resulting from their\nar X\niv :1\n70 5.\n05 08\n8v 1\n[ cs\n.C R\n] 1\n5 M\napplication. Algorithmically, the attacker-planning problem now becomes part of a larger what-if planning problem, in which the best mitigation plans are constructed.\nThe algorithm we propose optimizes the mitigation strategy based on a set of possible mitigation actions. Mitigation actions can represent, but are not limited to, changes to the network topology, e.g., adding a packet filter, system updates that remove vulnerabilities, and configuration changes or application-level firewalls which work around issues. While, e.g., an application-level firewall might be an efficient temporary workaround for a vulnerability that affects a single host, contracting a software vendor to provide a patch might be more cost-efficient in case the vulnerability appears throughout the network. To reflect cases like this, mitigation actions are assigned a cost for their first application (set-up cost), and another potentially different cost for all subsequent applications (application cost). The algorithm computes optimal combinations w.r.t. minimizing the maximal attacker success for a given budget, and proposes dominant mitigation strategies with respect to cost and attacker success probability. This min-max notion is similar to a Stackelberg game, which are frequently used in security games [29]. The foundational assumption is that the defender acts first, while the adversary can chose her best response after observing this choice, similar to a market leader and her followers. The algorithm thus provides a wellfounded basis for a holistic mitigation strategy.\nAfter discussing related work in Section 2 and giving a running example in Section 3, we present our mitigation analysis models and algorithms in Sections 4 to 6, framed in a formalism suited for a large range of mitigation/attack planning problems. In Section 7, we show that a particular class of these models can be derived by scanning a given network using the Nessus network-vulnerability scanner. The attacker action model is then derived using a vulnerability database and data associated using the Common Vulnerability Scoring System (CVSS). This methodology provides a largely automated method of deriving a model (only the network topology needs to be given by hand), which can then be used as it is, or further refined. In Section 8, we evaluate our algorithms w.r.t. problems from this class, derived from a vulnerability database and a simple scalable network topology."}, {"heading": "2. Related Work", "text": "Our work is rooted in a long line of research on network security modeling and analysis, starting with the consideration of attack graphs. The simulated pentesting branch of this research essentially formulates attack graphs in terms of standard sequential decision making models \u2013 attack planning \u2013 from AI. We give a brief background on the latter first, before considering the history of attack graph models.\nAutomated Planning is one of the oldest sub-areas of AI (see [13] for a comprehensive introduction). The area is concerned with general-purpose planning mechanisms that\nautomatically find a plan, when given as input a highlevel description of the relevant world properties (the state variables), the initial state, a goal condition, and a set of actions, where each action is described in terms of a precondition and a postcondition over state variable values. In classical planning, the initial state is completely known and the actions are deterministic, so the underlying state model is a directed graph (the state space) and the plan is a path from the initial state to a goal state in that graph. In probabilistic planning, the initial state is completely known but the action outcomes are probabilistic, so the underlying state model is a Markov decision process (MDP) and the plan is an action policy mapping states to actions. In partially observable probabilistic planning, we are in addition given a probability distribution over the possible initial states, so the underlying state model is a partially observable MDP (POMDP).\nThe founding motivation for Automated Planning mechanisms is flexible decision taking in autonomous systems, yet the generality of the models considered lends itself to applications as diverse as the control of modular printers, [42], natural language sentence generation [25], [26], greenhouse logistics [18], and, in particular, network security penetration testing [4], [12], [19], [33], [43]. This latter branch of research \u2013 network attack planning as a tool for automated security testing \u2013 has been coined simulated pentesting, and is what we continue here.\nSimulated pentesting is rooted in the consideration of attack graphs, first introduced by Philipps and Swiler [40]. An attack graph breaks down the space of possible attacks into atomic components, often referred to as attack actions, where each action is described by a conjunctive precondition and postcondition over relevant properties of the system under attack. This is closely related to the syntax of classical planning formalisms. Furthermore, the attack graph is intended as an analysis of threats that arise through the possible combinations of these actions. This is, again, much as in classical planning. That said, attack graphs come in many different variants, and the term \u201cattack graph\u201d is rather overloaded. From our point of view here, relevant distinction lines are the following.\nIn several early works (e. g. [45], [50]), the attack graph is the attack-action model itself, presented to the human as an abstracted overview of (atomic) threats. It was then proposed to instead reason about combinations of atomic threats, where the attack graph (also: \u201cfull\u201d attack graph) is the state space arising from all possible sequencings of attack actions (e. g. [41], [46]). Later, positive formulations \u2013 positive preconditions and postconditions only \u2013 where suggested as a relevant special case, where attackers keep gaining new assets, but never lose any assets during the course of the attack [2], [14], [23], [36], [37], [50]. This restriction drastically simplifies the computational problem of non-probabilistic attack graph analysis, yet it also limits expressive power, especially in probabilistic models where a stochastic effect of an attack action (e. g., crashing a\nmachine) may be detrimental to the attacker\u2019s objectives.1\nA close relative of attack graphs are attack trees (e. g. [34], [45]). These arose from early attack graph variants, and developed into \u201cGraphical Security Models\u201d [27]: Directed acyclic AND/OR graphs organizing known possible attacks into a top-down refinement hierarchy. The human user writes that hierarchy, and the computer analyzes how attack costs and probabilities propagate through the hierarchy. In comparison to attack graphs and planning formulations, this has computational advantages, but cannot find unexpected attacks, arising from unforeseen combinations of atomic actions.\nProbabilistic models of attack graphs/trees have been considered widely (e. g. [8], [9], [21], [30], [35], [44], [47]), yet they weren\u2019t, at first, given a formal semantics in terms of standard sequential decision making formalisms. The latter was done later on by the AI community in the simulated pentesting branch of research. After initial works linking non-probabilistic attack graphs to classical planning [4], [33], Sarraute et al. [43] devised a comprehensive model based on POMDPs, designed to capture penetration testing as precisely as possible, explicitly modeling the incomplete knowledge on the attacker\u2019s side, as well as the development of that knowledge during the attack. As POMDPs do not scale \u2013 neither in terms of modeling nor in terms of computation \u2013 it was thereafter proposed to use MDPs as a more scalable intermediate model [12], [19]. Here we build upon this latter model, extending it with automated support for mitigation analysis.\nMitigation analysis models not only the attacker, but also the defender, and in that sense relates to game-theoretic security models. The most prominent application of such models thus far concerns physical infrastructures and defenses (e. g. [49]), quite different from the network security setting. A line of research considers attack-defense trees (e. g. [27], [28], not based on standard sequential decision making formalisms. Some research considers pentesting but from a very abstract theoretical perspective [5]. A basic difference to most game-theoretic models is that our mitigation analysis does not consider arbitrarily long exchanges of action and counter-action, but only a single such exchange: defender applies network fixes, attacker attacks the fixed network. The latter relates to Stackelberg competitions, yet with interacting state-space search models underlying each side of the game."}, {"heading": "3. Running Example", "text": "We will use the following running example for easier introduction of our formalism and to foreshadow the modelling of networks which we will use in Section 7. Let us consider a network of five hosts, i.e., computers that are assigned an address at the network layer. It consists of a\n1. The restriction to positive preconditions and postconditions is actually known in Automated Planning not as a planning problem of interest in its own right, but as a problem relaxation, serving for the estimation of goal distance to guide search on the actual problem [6], [20].\nwebserver W , an application server A, a database server D, and a workstation S. We partition the network into three zones called as follows: 1) the sensitive zone, which contains important assets, i.e., the database server D and the information it stores, 2) the DMZ, which contains the services that need to be available from the outside, i.e., A and W , 3) the user zone, in which S is placed and 4) the internet, which is assumed under adversarial control by default and contains at least a host I .\nThese zones are later (cf. Section 8) used to define the adversarial goals and may consist of several subnets. For now, each zone except the internet consists of exactly one subnet. These subnets are interconnected, with the exception of the internet, which is only connected to the DMZ. Firewalls filter some packets transmitted between the zones. We will assume that the webserver can be accessed via HTTPs (port 443) from the internet."}, {"heading": "4. Penetration Testing Formalism", "text": "Intuitively, the attacks we consider might make a service unavailable, but not physically remove a host from the network or add a physical connection between two hosts. We thus distinguish between network propositions and attacker propositions, where the former describes the network infrastructure and persistent configuration, while the latter describes the attacker\u2019s advance through the network. By means of this distinction, we may assume the state of the network to be fixed, while everything else can be manipulated by the attacker. The network state will, however, be altered during mitigation analysis, which we will discuss in more detail in Section 5.\nNetworks are logically described through a finite set of network propositions PN. A concrete network state is a subset of network propositions sN \u2286 PN that are true in this state. All propositions p 6\u2208 sN are considered to be false.\nExample 1 In the running example, the network topology is described in terms of network propositions subnet(s, h) \u2208 PN assigning a host h to a subnet s, e.g., subnet(sensitive, D) \u2208 PN. Connectivity is defined between subnets, e.g., haclz(internet, dmz, 443, tcp) \u2208 PN indicates that TCP packets with destination port 443 (HTTPS) can pass from the internet into the DMZ. We assume that the webserver W , the workstation S and the database server D are vulnerable, e.g., vul exists(cveW ,W, 443, tcp, integrity) \u2208 PN for a vulnerability with CVE identifier cveW affecting W on TCP port 443, that compromises integrity.\nWe formalize network penetration tests in terms of a probabilistic planning problem:\nDefinition 1 (penetration testing task) A penetration testing task is a tuple \u03a0 = (PA,A, IA,G, bA0 ) consisting of: \u2022 a finite set of attacker propositions PA, \u2022 a finite set of (probabilistic) attacker actions A (cf.\nDefinition 2), \u2022 the attacker\u2019s initial state IA \u2286 PA, \u2022 a conjunction G over attacker proposition literals,\ncalled the attacker goal, and \u2022 a non-negative attacker budget bA \u2208 R+\u222a{\u221e}, includ-\ning the special case of an unlimited budget bA =\u221e.\nThe objective in solving such a task \u2013 the attacker\u2019s objective \u2013 will be to maximize attack probability, i. e., to find action strategies maximizing the likelihood of reaching the goal. We now specify this in detail.\nThe attacker proposition are used to describe the state of the attack, e. g., dynamic aspects of the network and which hosts the attacker has gained access to.\nExample 2 Consider an attacker that initially controls the internet, i.e., controls(I) \u2208 IA and has not yet caused W to crash, available(W ) \u2208 IA. The attacker\u2019s aim might be to inflict a privacy-loss on D, i.e., compromised(D, privacy), with a budget bA of 3 units, which relate to the attacker actions below.\nThe attacks themselves are described in terms of actions which can depend on both network and attacker propositions, but only influence the attacker state.\nDefinition 2 (attacker actions) An attacker action a \u2208 A is a tuple (preN(a), preA(a), c(a), O(a)) where \u2022 preN(a) is a conjunction over network proposition\nliterals called the network-state precondition, \u2022 preA(a) is a conjunction over attacker proposition\nliterals called the attacker-state precondition, \u2022 c(a) \u2208 R+ is the action cost, and \u2022 O(a) is a finite set of outcomes, each o \u2208 O(a)\nconsisting of an outcome probability p(o) \u2208 (0, 1] and a postcondition post(o) over attacker proposition literals. We assume that \u2211 o\u2208O(a) p(o) = 1.\nThe network-state precondition preN(a), attacker-state precondition preA(a) and postconditions post(o) represent\nthe conditions under which a can be applied as well as the stochastic effect of the application of a: post(o) \u2208 O(a) holds after the application of a with probability p(o). This can be used to model attacks that are probabilistic by nature, as well as to model incomplete knowledge (on the attacker\u2019s side) about the actual network configuration.\nBecause post(o) is limited to attacker propositions, we implicitly assume that the attacker cannot have a direct influence on the network itself. Although this is very restrictive, it is a common assumption in the penetration testing literature (e. g.. [14], [23], [36], [37]). The attacker action cost can be used to represent the effort the attacker has to put into executing what is being abstracted by the action. This can for example be the estimated amount of time an action requires to be carried out, or the actual cost in terms of monetary expenses.\nExample 3 If an attacker controls a host which can access a second host that runs a vulnerable service, it can compromise the second host w.r.t. privacy, integrity or availability, depending on the vulnerability. This is reflected, e.g., by an attacker action a \u2208 A which requires access to a vulnerable W within the DMZ, via the internet.\npreN(a) =subnet(dmz,W ) \u2227 subnet(internet, I) \u2227 haclz(internet, dmz, 443, tcp) \u2227 vul exists(cveW ,W, 443, tcp, integrity)\nIn addition, I needs to be under adversarial control (which is the case initially), and W be available: preA(a) = controls(I) \u2227 available(W ).\nThe cost of this known vulnerability maybe set to c(a) = 1, in which case the adversarial budget above relates to the number of such vulnerabilities used. More elaborate models are possible to distinguish known vulnerabilities from zero-day exploits which may exists, but only be bought or developed at high cost, or threats arising from social engineering.\nThere could be three different outcomes O(a) = {osuccess , ofail , ocrash}, with different probabilities: post(osuccess) = compromised(W, integrity) \u2227 controls(W ) in case the exploit succeeds, post(ofail) = > in case the exploit has no effect, and post(ocrash) = \u00acavailable(W ) if it crashes W . For example, we may have p(osuccess) = 0.5, p(ofail) = 0.49, and p(ocrash) = 0.01 because the exploit is of stochastic nature, with a small (but not negligible) probability to crash the machine.\nRegarding the first action outcome, osuccess , note that we step here from a vulnerability that affects integrity, to the adversary gaining control over W . This is, of course, not a requirement of our formalism; it is a practical design decision that we make in our current model acquisition setup (and that was made by previous works on attack graphs with similar model acquisition machinery e. g. [37], [47]), because the vulnerability databases available do not distinguish between a privilege escalation and other forms of integrity violation. We get back to this in Section 7.\nRegarding the third action outcome, ocrash , note that negation is used to denote removal of literals, i. e., the following attacker state will not contain available(W ) anymore, so that all vulnerabilities on W cease to be useful to the attacker.\nAssume a fixed penetration testing task. Given some network state, we can now define the state space, in which attacks are computed.\nDefinition 3 (state space) The state space of \u03a0 in the network state sN is the probabilistic transition system (S,T, s0,S>) where\n\u2022 S is the set of attacker states, or states for short. Each state s \u2208 S is associated with the set of attacker propositions PA(s) \u2286 PA true in s, and the remaining budget bA(s) \u2208 R+0 \u222a {\u221e}. \u2022 T : S \u00d7 A \u00d7 S 7\u2192 [0, 1] is the transition probability function, and corresponds to the application of attacker actions to states. An attacker action a \u2208 A is applicable to a state s \u2208 S in sN if the network precondition preN(a) is satisfied in sN, the attacker precondition preA(a) is satisfied in PA(s), and there is enough budget in s for the application of a, i. e., bA(s) \u2265 c(a). The result of an outcome o \u2208 O(a) in s is the state sJoK where PA(sJoK) contains all propositions p \u2208 PA that are contained in post(o) and all propositions p \u2208 PA(s) whose negation does not occur in post(o). We define bA(sJoK) = bA(s)\u2212 c(a). For states s, t \u2208 S and action a \u2208 A, the transition probabilities are then defined as T (s, a, t) = p(o) if a is applicable to s and t = sJoK for o \u2208 O(a),2 and T (s, a, t) = 0 otherwise. \u2022 s0 is the initial state where PA(s0) = IA and bA(s0) = bA0 . \u2022 S> \u2286 S is the set of goal states, where s \u2208 S> if G is satisfied in PA(s).\nViewing the state space of \u03a0 as a Markov decision process (MDP), an attack in \u03a0 for the network state sN is a solution to that MDP, i. e., a policy. A policy is a partial function \u03c0 : S 7\u2192 A where (1) for every s \u2208 S where \u03c0(s) is defined, \u03c0(s) is applicable to s in sN; and (2) \u03c0 is closed, i. e., \u03c0 is defined for every s reachable under \u03c0 from the initial state s0.\nThere are various objectives for MDP policies, i. e., notions of optimality, in the literature. For attack planning, arguably the most natural objective is success probability: the likelihood that the attack policy will reach a goal state.\nUnfortunately, finding such an optimal policy is EXPTIME-complete in general [32]. Furthermore, recent experiments have shown that, even with very specific restrictions on the action model, finding an optimal policy for a penetration testing task is feasible only for small networks of up\n2. We assume here that each outcome o \u2208 O(a) leads to a different state.\nto 25 hosts [48]. For the sake of scalability we thus focus on finding critical attack paths, instead of entire policies.3\nDefinition 4 (critical attack path) A critical attack path in the network state sN is a path s0, a1, s1, . . . , an, sn within the state space of \u03a0 in sN, that starts in an initial state s0, ends in a goal state sn \u2208 S>, and maximizes\u220fn i=1 T (si\u22121, ai, si) among all paths from s0 to any goal state.\nIn other words, a critical attack path is a sequence of actions whose success probability is maximal. We will also refer to such paths as optimal attack plans, or optimal attack action sequences. In contrast to policies, if any action within a critical attack path does not result in the desired outcome, we consider the attack to have failed. Critical attack paths are conservative approximations of optimal policies, i. e., the success probability of a critical attack path is a lower bound on the success probability of an optimal policy.\nExample 4 Reconsider the outcomes of action a from Example 3, O(a) = {osuccess , ofail , ocrash}. Assuming a reasonable set of attacker actions similar to the previous examples, no critical path will rely on the outcomes ofail or ocrash , as otherwise a would be redundant or even counterproductive. Thus the distinction between these two kinds of failures becomes unnecessary, which is reflected in the models we generate in Section 7 and 8. The downside of considering only single paths instead of policies can be observed in the following example. Consider the case where a second action a\u2032 has similar outcomes O(a\u2032) = {o\u2032success , o\u2032fail , o\u2032crash} to a, but p(o\u2032success) < p(osuccess) while p(o\u2032crash) is considerably smaller than p(ocrash). Assuming that W is the only host that can be used to reach S or D, an optimal policy might chose a\u2032 in favour of a, while a critical attack path will insist on a."}, {"heading": "5. Mitigation Analysis Formalism", "text": "Finding possible attacks, e. g., through a penetration testing task as defined above, is only the first step in securing a network. Once these are identified, the analyst or the operator need to come up with a mitigation plan to mitigate or contain the identified weaknesses. This task can be formalized as follows.\nDefinition 5 (mitigation-analysis task) Let PN be a set of network propositions, and let \u03a0 = (PA,A, IA,G, bA0 ) be a penetration testing task. A \u03a0 mitigation-analysis task is a triple M = (IN,F, bM0 ) consisting of \u2022 the initial network state IN \u2286 PN, \u2022 a finite set of fix-actions F, and \u2022 the mitigation budget bM0 \u2208 R+ \u222a {\u221e}.\n3. Similar approximations have been made in the attack-graph literature. Huang et al. [22], e.g., try to identify critical parts of the attack-graph by analysing only a fraction thereof, in effect identifying only the most probable attacks.\nThe objective in solving such a task \u2013 the defender\u2019s objective \u2013will be to find dominant mitigation strategies within the budget, i. e., fix-action sequences that reduce the attack probability as much as possible while spending the same cost. We now specify this in detail.\nFix-actions encode modifications of the network mitigating attacks simulated through \u03a0.\nDefinition 6 (fix-actions) Each fix-action f \u2208 F is a triple (pre(f), post(f), cM(f)) of precondition pre(f) and postcondition post(f), both conjunctions over network proposition literals, and fix-action cost cM(f) \u2208 R+.\nWe call f applicable to a network state sN if pre(f) is satisfied in sN. The set of applicable f in sN is denoted by app(sN). The result of this application is given by the state sNJfK which contains all propositions with positive occurrences in post(f), and all propositions of sN whose negation is not contained in post(f).\nExample 5 Removing a vulnerability by, e.g., applying a patch, is modelled as a fix-action f with pre(f) = vul exists(cveW ,W, 443, tcp, integrity), post(f) = \u00acpre(f) and cost 1.\nA fix-action with pre(f) = haclz( internet, dmz, 443, tcp) \u2227 \u00acfwapplied(z2), post(f) = \u00achaclz(internet, dmz, 443, tcp) \u2227 fwapplied(z2) and cost 100 may represent adding a firewall between the DMZ and the internet (assuming it was not present before, i.e., fwapplied(z2) 6\u2208 IN). It is much cheaper to add a rule to an existing firewall than to add a firewall, which can be represented by a similar rule with fwapplied(z2) instead of \u00acfwapplied(z2) in the precondition, and lower cost.\nNote that, in contrast to attacker actions, fix-actions f are deterministic. A sequence of fix-actions can be applied to a network in order to lower the success probability of an attacker.\nDefinition 7 (mitigation strategy) A sequence of fixactions \u03c3 = f1, . . . , fn is called a mitigation strategy if it is applicable to the initial network state and its application cost is within the available mitigation budget, where \u2022 f1, . . . , fn are said to be applicable to a network\nstate sN if f1 is applicable to sN and f2, . . . , fn are applicable to sNJf1K. The resulting state is denoted sNJf1, . . . , fnK.\n\u2022 The application cost of f1, . . . , fn is cM(f1, . . . , fn) =\u2211n i=1 c M(fi).\nTo evaluate and compare different mitigation strategies, we consider their effect on the optimal attack. As discussed in the previous section, for the sake of scalability we use critical attack paths (optimal i. e. maximum-success-probability attack-action sequences) to gauge this effect, rather than full optimal MDP policies. As attacker actions in \u03a0 may contain a precondition on the network state, changing the network state affects the attacker actions in the state space of \u03a0, and consequently the critical attack paths. To measure the impact\nof a mitigation strategy, we define p\u2217(sN) to be the success probability of a critical attack path in sN, or p\u2217(sN) = 0 if there is no critical attack path (and thus there is no way in which the attacker can achieve its goal).\nDefinition 8 (dominance, solution) Let \u03c31, \u03c32 be two mitigation strategies. \u03c31 dominates \u03c32 if\n(i) p\u2217(INJ\u03c31K) < p\u2217(INJ\u03c32K) and cM(\u03c31) \u2264 cM(\u03c32), or (ii) p\u2217(INJ\u03c31K) \u2264 p\u2217(INJ\u03c32K) and cM(\u03c31) < cM(\u03c32).\nThe solution F to M is the Pareto frontier of mitigation strategies \u03c3: the set of \u03c3 that are not dominated by any other mitigation strategy.\nIn other words, we consider a mitigation strategy \u03c31 better than another one, \u03c32, if either \u03c31 reduces the probability of an successful attack to the network more, while not imposing a higher cost, or \u03c31 costs less than \u03c32 while it lowers the success probability of an attack at least by the same amount. The solution to our mitigation-analysis task is the set of dominant (non-dominated) mitigation strategies.\nThis is similar Stackelberg games, in which a market leader moves first and is followed by one or more market followers, and thus optimises his strategy w.r.t. their best response. Stackelberg games in the two-player setting are frequently used in security settings [29].\nIt is easy to see that our notion of solutions is welldefined, in the following way:\nTheorem 1 The solution F to M always exists, is nonempty, is unique, and is finite.\nProof: As we assumed that all fix-actions f have positive cost, it immediately follows that the empty mitigation strategy \u03c3 = is not dominated by any other mitigation strategy, and hence \u03c3 \u2208 F . F is unique since it must contain all non-dominated mitigation strategies. Coming to the last part, assume for contradiction that F is not finite. As the number of different network propositions is finite, the number of different network states is finite as well. Therefore, there must be a network state sN that is reached from the initial network state by infinitely many mitigation strategies in F . As all fix-actions have positive cost, there must in particular be two mitigation strategies \u03c31, \u03c32 \u2208 F so that INJ\u03c31K = INJ\u03c32K and cM(\u03c31) < cM(\u03c32), i. e., so that \u03c31 dominates \u03c32, in contradiction to the definition of F ."}, {"heading": "6. Analysis Algorithms", "text": "We actually want to compute F with reasonable efficiency. We thus specify how we compute critical paths and solve mitigation tasks as a whole."}, {"heading": "6.1. Penetration Testing", "text": "We compute critical attack paths through a compilation from network penetration testing tasks to classical, deterministic, planning formalisms. The latter can then be solved using standard algorithms for finding minimal-cost plans.\nThis compilation is compromised of two steps. First, in order to get rid of stochastic action outcomes, we apply the all-outcome determinization (e. g. [31], [53]). That is, we create a deterministic action ao for every attacker action a and stochastic outcome o \u2208 O(a), where ao has the same precondition than a, and the postcondition of o. Second, to get classical planning methods output attack sequences with highest chances of success, instead of minimal cost, we encode the outcome probability p(o) as action costs: c(ao) = \u2212 log(p(o)) (cf. [24]). The attack ao1, . . . , aon resulting from the classical planning method is guaranteed to have minimal cost \u2211n i=1 c(a o i ), and hence \u220fn i=1 p(oi) must be maximal, i. e., a1, . . . , an is a critical attack path. Given this encoding, the attack-planning problem can be solved with standard planning algorithms and tools. The state of the art consists in heuristic search methods [39], which employ search guidance through heuristic functions \u2013 functions mapping states to estimates of cost-to-goal \u2013 to find optimal solutions quickly. In our implementation, we use an extension of the FD system [16], with the LM-cut heuristic function [17]."}, {"heading": "6.2. Mitigation Analysis", "text": "In this section, we formally define the mitigation analysis algorithm used and the pruning techniques employed to improve performance. Finally, we show this techniques correct.\nWe compute the solution to a given mitigation-analysis task M, i.e., the Pareto frontier w.r.t. Definition 8, using a depth-oriented tree search algorithm. While a na\u0131\u0308ve implementation needs to consider every sequence of fix actions over F for inclusion in the global Pareto frontier F , often enough it is sufficient to consider subsets of F, as most fix-actions are commutative and thus the analysis invariant w.r.t. permutations. This is particularly relevant for attack mitigations, as fixes are often local and independent, however, commutativity is not always given, consider, e.g., the firewall rule discussed in Example 5. As a firewall needs to be acquired before firewall rules can be added cheaply, this imposes a constraint that we formalize in the notion of commutativity. We define commutativity on top of interference [52] which we will also need later on.\nDefinition 9 (interference, commutativity) Let \u03a0 be a mitigation-analysis task with network propositions PN and fix-actions F, and let f1, f2 \u2208 F. 1. Action f1 disables f2 if there exists a proposition literal p \u2208 post(f1) and \u00acp \u2208 pre(f2) or vice versa. 2. Actions f1 and f2 conflict if there exists a proposition literal p such that p \u2208 post(f1) and \u00acp \u2208 post(f2) or vice versa. 3. Actions f1 and f2 interfere if they conflict or either disable the other. We write inf(f) for the set of actions f \u2032 \u2208 F with which f interferes. 4. Action f1 enables f2 if there exists a proposition p \u2208 post(f1) and p \u2208 pre(f2) or vice versa.\n5. Actions f1 and f2 are commutative if they do not interfere and not enable the other.\nThe interference and commutativity relations on elements from F can both be computed up front. To avoid considering permutations of commutative actions, we apply a transition reduction technique based on so-called sleep sets [15], [52]. A sleep set for a sequence \u03c3 is a set of operators f that are applicable after \u03c3 but skipped during search. When expanding successor actions for \u03c3, we only consider applicable actions outside sleep(\u03c3). Let f1, ..., fn be these actions, ordered in the same way as they are considered by the search algorithm. For each successor path \u03c3\u25e6\u3008f\u3009, we set sleep(\u03c3 \u25e6 \u3008f\u3009) \u00b7\u00b7= (sleep(\u03c3) \u222a {f1, ..., fi\u22121}) \\ {f | f, fi are not commutative}.\nWe globally maintain a) C0, the current bound for the cost of lowering the attacker probability to zero, in order to prune sequences that are dominated from the start, b) Ofix , a map from network states to cheapest fix-action sequences, in order to prune cases where a fix-action sequence has reached a network state in a cheaper way before, c) and Oatt , a map from network states to optimal attack action sequences, in order to spare the search for an attack action sequence if we have already saved one.\nC0 is always equal to the cost of the cheapest fix-action sequence \u03c3 found so far which leads to a state with zero attacker success probability, i.e. C0 = min\n\u03c3 cM(\u03c3) such that\np\u2217(INJ\u03c3K) = 0. Any fix-action sequence with higher cost is dominated by definition and can thus be safely pruned.\nOfix maps each already considered network state to the cheapest fix-action sequence \u03c3 reaching this state found so far. If \u03c3\u2032 = Ofix (sN) is defined in the current network state sN and cM(\u03c3) > cM(\u03c3\u2032), we can stop right away and prune \u03c3 as well as all successors, as \u03c3 is more expensive than the already known sequence \u03c3\u2032 leading to the same network state. Even if this is not the case, but Ofix (sN) is defined, we can save an additional search in the attacker spate space.\nOatt maps each already considered network state to the computed optimal attack action sequence, i.e., if \u03c3 leading to sN = INJ\u03c3K was considered before, we store the corresponding optimal attack plan ~a, Oatt(sN) \u00b7\u00b7= ~a. We can similarly also make use of the optimal attack plan for the parent state of sN. This can be done by letting \u03c3 be f1, . . . , fn, then computing the parent state sNparent = I\nNJf1, . . . , fn\u22121K and afterwards once again using the map: ~aparent = Oatt(sNparent). Having the parent attack plan ~aparent is useful, because we can also spare an additional search in the attacker state space if ~aparent is still applicable to the state space induced by the current network state sN.\nThe mitigation analysis algorithm PARETOFRONTIER (Figure 3) expects as arguments a network state sN, the corresponding fix-action sequence \u03c3 leading to sN, the sleep set for \u03c3 and the mitigation budget bM. PARETOFRONTIER explores the space of applicable fix sequences in a Iterative Deepening search (IDS) manner as described in Figure 2. This means we keep executing PARETOFRONTIER with an increasing mitigation budget bMcurr until a termination criterion is satisfied. We initialize bMcurr to the cost of the\nprocedure IDS-PARETOFRONTIER() 1: global: \u03a3, C0, Ofix , Oatt , cut off 2: bMcurr \u2190 max\nf\u2208F cM(f);"}, {"heading": "3: loop", "text": "4: cut off \u2190 false; 5: call PARETOFRONTIER(IN, \u3008\u3009, \u2205, bMcurr) 6: if C0 <\u221e then return; endif 7: if not cut off then return; endif 8: if bMcurr = bM0 then return; endif 9: bMcurr \u2190 min(bMcurr \u2217 \u03b3bM , bM0 );\nFigure 2. IDS-oriented algorithm for computing Pareto optimal frontier.\nmost expensive fix-action. We maintain the global boolean flag cut off to indicate in PARETOFRONTIER that the search was cut off because of low budget. The Pareto frontier under construction \u03a3 is initially empty and C0 is initially equal to \u221e. In each iteration, bMcurr is increased by multiplying it with a factor \u03b3bM . The IDS terminates if one of the following conditions holds: 1) we have already found a state sN with p\u2217(sN) = 0, 2) during the last call to PARETOFRONTIER, the search was not cut off because of low budget, or 3) we already tried the maximal budget bM0 .\nTheorem 2 IDS-PARETOFRONTIER always terminates and computes \u03a3 such that it is equal to the pareto frontier F modulo permutations on commutative fix-actions for a given mitigation-analysis task M.\nProof: We will first argue about the correctness of PARETOFRONTIER and lastly about IDSPARETOFRONTIER itself.\nThe plain PARETOFRONTIER algorithm without any of the optimizations would do the following: enumerate all fix action sequences \u03c3 within the budget, compute for every sequence the corresponding network state sN, check whether sN was already seen, compute p\u2217(sN) if this is not the case and finally store it in \u03a3 unless it is dominated by another sequence \u03c3\u2032 in \u03a3. The plain algorithm indeed terminates because of the duplicate check on sN and the finiteness of the network state space, which we already argued in the proof to Theorem 1. Finally, it computes \u03a3 such that is equal to F , because all fix-action sequences in the budget (modulo duplicate states) are checked. It remains to explain why the optimizations conserve this fact. We will argue for each optimization step by step. 1) Checking the applicability of ~aparent in lines 2-5: Consider\nfix-action sequence \u03c3 leading to network state sN with parent network state sNparent and plan ~aparent for state space of sNparent. We can get ~aparent from the map Oatt which is always correctly set in line 17. Consider ~aparent as still being applicable and leading to a goal state for sN which is checked in line 3, ~aparent is a) either an optimal plan for sN and p\u2217(sN) = p\u2217(sNparent) or b) there is another plan ~a optimal for sN with higher success probability\nprocedure PARETOFRONTIER(sN, \u03c3, sleep, bM) 1: let sNparent be parent of sN w.r.t. \u03c3 2: ~aparent \u2190 Oatt(sNparent) 3: if ~aparent applicable to IA and IAJ~aparentK |= G then 4: p\u2217(sN)\u2190 p\u2217(sNparent); 5: ~a\u2190 ~aparent; 6: else if Ofix (sN) and Oatt(sN) are defined then 7: p\u2217(sN)\u2190 cM(Ofix (sN)); 8: ~a\u2190 Oatt(sN); 9: else 10: compute p\u2217(sN) and corresponding ~a; 11: endif 12: if p\u2217(sN) \u2264 min\n\u03c3\u2032\u2208\u03a3 {p\u2217(INJ\u03c3\u2032K) | cM(\u03c3\u2032) \u2264 cM(\u03c3)} then\n13: remove all \u03c3\u2032 \u2208 \u03a3 dominated by \u03c3; 14: add \u03c3 to \u03a3; 15: endif 16: Ofix (sN)\u2190 \u03c3; 17: Oatt(sN)\u2190 ~a; 18: if p\u2217(sN) = 0 then 19: C0 \u2190 cM(\u03c3); 20: return; 21: endif 22: {f1, . . . , fn} \u2190 app(sN); 23: for i = 1, . . . , n do 24: \u03c3succ \u2190 \u03c3 \u25e6 \u3008fi\u3009; 25: if cM(\u03c3succ) > C0 then continue; endif 26: if fi \u2208 sleep then continue; endif 27: sNsucc \u2190 INJ\u03c3succK; 28: if \u03c3\u2032 \u2190 Ofix (sNsucc) is defined then 29: if cM(\u03c3succ) > cM(\u03c3\u2032) then continue; endif 30: if cM(\u03c3succ) > bM then 31: cut off \u2190 true; 32: continue; 33: endif 34: sleep(\u03c3succ)\u2190 sleep \u222a 35: {fj | fi, fj are commutative, 1 \u2264 j < i}; 36: PARETOFRONTIER(sNsucc, \u03c3succ, sleep(\u03c3succ), bM); 37: endfor\nFigure 3. Depth-oriented tree search for computing Pareto optimal frontier.\nthan ~aparent. Everything is fine in case 1a). In case 1b), p\u2217(sNparent) rather gives us a lower bound for p\n\u2217(sN), i.e. p\u2217(sN) > p\u2217(sNparent), which is also fine. The reason is that all we want to know is whether we can add \u03c3 to \u03a3 which we only could if p\u2217(sN) < p\u2217(sNparent). 2) Taking (\u03c3\u2032,~a\u2032) from Ofix (sN) and Oatt(sN) and not further considering \u03c3 if cM(\u03c3) > cM(\u03c3\u2032) in lines 6-8 and 28-29 and: it is clearly not necessary to compute ~a again, if we have done it already for exactly the same sN. It is further safe to prune \u03c3 if cM(\u03c3) > cM(\u03c3\u2032), because for all fix-action suffixes \u03c3suff , \u03c3 \u25e6 \u03c3suff will always be dominated by \u03c3\u2032 \u25e6 \u03c3suff if cM(\u03c3) > cM(\u03c3\u2032). 3) Pruning fix-action sequence \u03c3 such that cM(\u03c3) > C0 in line 25: this can be done because \u03c3 is clearly dominated\nby another sequence \u03c3\u2032 already in \u03a3 with p\u2217(INJ\u03c3\u2032K) = 0 by positivity of p\u2217(INJ\u03c3K). C0 is only assigned in line 19 and only if p\u2217(sN) = 0 and cM(\u03c3) \u2264 C0. The latter is in turn enforced by the check in line 25 itself. 4) Not considering permutations of commutative fix-actions fi and fj by applying the sleep set method in lines 26 and 34: we can easily derive from Definition 9 that commutativity implies for all network states sN, sNJ\u3008fi, fj\u3009K = sNJ\u3008fj , fi\u3009K. With the sleep set method, we enforce that only one ordering of fi and fj is considered if they are both applicable in a state sN. Let app(sN) be f1, . . . , fn and i < j, then we first call PARETOFRONTIER(\u03c3 \u25e6 \u3008fi\u3009, sleep(\u03c3 \u25e6 \u3008fi\u3009)) and fj is not in sleep(\u03c3 \u25e6 \u3008fi\u3009)) and can thus still be considered in the recursion. Later, we call PARETOFRONTIER(\u03c3 \u25e6 \u3008fj\u3009, sleep(\u03c3 \u25e6 \u3008fj\u3009)) and fi is in sleep(\u03c3 \u25e6 \u3008fj\u3009)) and not considered in the recursion such that we effectively only consider action sequences \u03c3 in which fi is ordered before fj . This preserves Pareto optimality because fi and fj are commutative. As a side remark: because we prune permutations of commutative fix actions, the resulting Pareto frontier \u03a3 can only contain at most one permutation of every subset of F, even tough the permutations do not dominate each other. That is why have stated \u201cmodulo permutations on commutative fixactions\u201d in Theorem 2. 5) Calling PARETOFRONTIER in an IDS manner in Figure 2: we observe that PARETOFRONTIER is always called with IN and \u3008\u3009 in IDS-PARETOFRONTIER and recursive calls are constructed in lines 24 and 27 such that effectively for all calls to PARETOFRONTIER, sN and \u03c3 have the relation: sN = INJ\u03c3K. The correctness of the sleep sets is established by calling PARETOFRONTIER with the empty set in IDS-PARETOFRONTIER and the correctness of the construction in line 34. The only problem remaining with the IDS approach could be that we terminate the loop in IDS-PARETOFRONTIER even though \u03a3 is not yet complete or we do not terminate at all. In fact it does not matter with which budgets bMcurr, PARETOFRONTIER is exactly called as long as it is called with a budget large enough such that \u03a3 is complete. We will argue why we only terminate if this is the case. It is safe to terminate as soon as C0 <\u221e since increasing bMcurr can never result in finding another sequence \u03c3 with p\u2217(INJ\u03c3K) = 0 and cM(\u03c3) < C0. Further, increasing bMcurr does not change anything if there was not a single fix-action f not considered because of low budget, i.e. if cut off = false. Lastly, bMcurr cannot be increased if it is already equal to bM0 . IDS-PARETOFRONTIER guarantees termination because bMcurr is increased in every iteration and will thus eventually be equal to bM0 . In case, b M 0 =\u221e, the algorithm will\neventually come to a point where all reachable network states were expanded, line 29 in Figure 3 fires for all applicable fi, cut off will remain false and finally the loop in IDS-PARETOFRONTIER terminates."}, {"heading": "6.3. Strong Stubborn Sets for Mitigation Analysis", "text": "The number n of applicable fix-actions f1, . . . , fn branched over in a given network state sN, cf. line 22 of Figure 3, is a critical scaling parameter as it is the branching factor in a tree search (over fix-action sequences) where each node in the search tree contains another worst-case exponential tree search for an optimal attack plan. It is therefore highly relevant to reduce n as much as possible. We next observe that, to this end, one can adapt a prominent pruning technique called strong stubborn sets (SSS), which allows the search to consider only a subset Ts of applicable actions in each state. SSS were invented in verification and later adapted to AI planning [51], [52]; their known variants are limited to single-agent search, like the attack planning in our setting, i. e., move-countermove setups were not considered. We provide an extension to such a setup \u2013 our setup of fix-action planning vs. attack-action planning \u2013 here. Our key observation is that, where standard SSS notions identify Ts through a subset of actions contributing to achieving the goal, we can here identify Ts through a subset of actions contributing to disvalidating the current critical attack path.\nTo lower the probability of a critical attack path, it is necessary to remove at least some precondition of any of its actions. In each execution of PARETOFRONTIER for network state sN, we have a critical path ~a. Based on this, we can define a \u2018relevant\u2019 set of propositions P which is the set of negated propositions preconditioned in ~a, i.e. P = {\u00acp | p \u2208 pre(ai), ai \u2208 ~a}. Relevant fix-actions then are ones helping to render ~a non-applicable; specifically, we define the set LPs := {f | \u2203 p \u2208 post(f) : p \u2208 P} of those fix-actions that have an element from P in the postcondition. In line with previous AI planning terminology [52], we call LPs a disjunctive action landmark: a set of fix-actions L so that every applicable fix-action sequence that starts in sN and ends in tN where tN \u2229 P 6= \u2205 contains at least one action f \u2208 L. Intuitively, a disjunctive action landmark is a set of actions at least one of which must be used to invalidate ~a.\nNow, towards identifying a subset of applicable fixactions branching over which in a network state sN suffices for Pareto optimality, using only LPs in Ts would be insufficient. This is because it is possible that no action from LPs is actually applicable in s\nN, so we must first enable such an action. For this purpose, we define the notion of necessary enabling set Nfs , as the set of fix-actions achieving a fix-action f precondition not true in sN, i.e. Nfs = {f | \u2203 p \u2208 pre(f). p /\u2208 s \u2227 p \u2208 post(f)}.\nFinally, for the definition of SSS, remember the notion of interference from Definition 9 and that inf(f) is the set of fix-actions with which f interferes. We must also include interfering fix-actions into the set of fix-actions considered, because interfering actions represent alternate exclusive choices that the search needs to branch over.\nDefinition 10 (strong stubborn set [52]) Let \u03a0 be a mitigation-analysis task with network propositions PN and fix-actions F, let sN be a network state of \u03a0, let ~a be a\nprocedure ComputeStubbornSet(sN, P) 1: Ts \u2190 LPs ; /* for some disj. action landmark LPs */ 2: repeat 3: for all f \u2208 Ts do 4: if f \u2208 app(sN) then 5: Ts \u2190 Ts \u222a inf(f); 6: else /* for some nec. enabling set Nfs */ 7: Ts \u2190 Ts \u222aNfs ; 8: until Ts reaches a fix point 9: return Ts\nFigure 4. Strong stubborn set comp. for state s and proposition set P.\ncritical attack path, and let P = {\u00acp | p \u2208 pre(ai), ai \u2208 ~a}. A strong stubborn set (SSS) in sN is an action set Ts \u2286 F such that: 1. Ts contains a disjunctive action landmark LPs for P in sN. 2. For each f \u2208 Ts \u2229 app(sN), we have inf(f) \u2286 Ts. 3. For each f \u2208 Ts \\ app(sN), we have Nfs \u2286 Ts for the\nnecessary enabling set Nfs of f in s N.\nThe SSS computation algorithm in Figure 4 starts with the disjunctive action landmark LPs and adds actions to the candidate set until conditions 2 and 3 are satisfied. Hence, the algorithm indeed computes a SSS. It is called in PARETOFRONTIER in line 22 before iterating over the applicable operators app(sN) \u2286 F. Given the SSS Ts, it is sufficient for the algorithm to iterate solely over the operators in Tapp(sN) := Ts \u2229 app(sN) instead of the complete set app(sN), while preserving the Pareto optimality of the algorithm. This statement is formally proven in Theorem 3.\nTheorem 3 Using only Tapp(sN) instead of app(sN) in line 22 of PARETOFRONTIER preserves Theorem 2.\nProof:For any state fix-action sequence \u03c3 and sN = INJ\u03c3K, non-empty fix-action suffixes \u03c3suff which do not invalidate the attacker plan ~a need not be considered, as ~a would still be a plan for sNJ\u03c3suffK, but (by positivity of fix-action costs) \u03c3\u25e6\u03c3suff would be dominated by \u03c3. We thus show that for all states sN from which a cheapest fix-action sequence leading to a state where ~a is not applicable anymore and consisting of n > 0 actions exists, Tapp(s) contains an action starting such a sequence. A simple induction then shows that PARETOFRONTIER restricted to Tapp(s) is Pareto optimal. The rest of the proof follows that of [1, Theorem 1].\nLet Ts be a SSS computed by Alg. 4 and \u03c3 = f1, . . . , fn be a cheapest sequence for s invalidating ~a. Since Ts contains a disjunctive action landmark for the propositions preconditioned by ~a, \u03c3 contains an action from Ts. Let fk be the action with smallest index in \u03c3 that is also contained in Ts, i.e., fk \u2208 Ts and {f1, . . . , fk\u22121} \u2229 Ts = \u2205. Then: 1) fk \u2208 app(s): otherwise by definition of SSS, a necessary\nenabling set Nfks for fk would have to be contained in Ts, and some action from Nfks would have to occur\nbefore fk in \u03c3 to enable fk, contradicting that fk was chosen with the smallest index. 2) fk is independent of f1, . . . , fk\u22121: otherwise, using fk \u2208 app(s) and the definition of SSS, at least one of f1, . . . , fk\u22121 would have to be contained in Ts, again contradicting the assumption. Hence, we can move fk to the front: \u03c3\u2032 = fk, f1, . . . , fk\u22121, fk+1, . . . , fn is also a sequence for s invalidating ~a. It has the same cost as \u03c3 and is hence a cheapest such sequence. Thus, we have found a cheapest fix-plan of length n started by an action fk \u2208 Tapp(s), completing the proof."}, {"heading": "7. Practical Model Acquisition", "text": "The formalism and algorithm introduced in the previous sections encompass a broad range of network models. In this section, we describe a highly automated approach to acquire a particular form of such network models in practice, demonstrating our method to be readily applicable. The general workflow is similar to MulVAL [38], which integrates machine-readable vulnerability descriptions and reports from network vulnerability scanners such as Nessus to derive a simple logical model specified in Datalog. Our workflow follows the same idea, but in addition we incorporate possible mitigation actions described in a concise and general schema. Moreover, our formalism considers the probabilistic/uncertain nature of exploits.4"}, {"heading": "7.1. Workflow", "text": "From discussion with security analysts, we learned that the amount of information available for analysis is often limited initially, sometimes by nature of the assignment (white-box versus black-box tests), but mostly from the fact that evaluation of in-house software and configurations is a large part of the analysis. Choosing the hosts to focus on, however, requires the identification of critical entry points, in later stages w.r.t. mitigations already considered. We will thus describe the following work-flow, which we plan to evaluate in actual penetration testing scenarios as part of future work (depicted in Figure 5).\n1) In the first step, the user scans a network using the Nessus tool, resulting in an XML report. Our current toolchain supports only network-wide scans. Nessus, as well as several OVAL interpreters [3] supports hostwise scans, which can be gathered centrally. This would give much more precise results, which can be translated in a very similar way. 2) The user describes the network topology in a JSON formatted file, including the set of hosts initially under adversarial control. If this file is not given, we assume all hosts are interconnected w.r.t. every port that appears in the Nessus report. Currently, this file has to be created by hand. Penetration testers often have\n4. Code is available at http://upload.soundadl.bplaced.net/whatif.zip\naccess to firewall rules in machine-readable formats (e.g., Cisco, juniper), which could be used to derive information about connectivity between subnets. The relation between hosts and subnets may be deduced based on IP-Prefixes, or entered by hand. Hence, this part of the workflow can be mechanised easily. 3) The user specifies the fixes the analysis should consider. Initially, this list can be populated by considering all known patches and a generic firewall rule that considers adding a firewall at all possible positions in the network, for the cost of five patches. 4) The user specifies the attacker budget and the mitigation budget; initially, the attacker budget gives the number of exploits the attacker may use, as all exploits are assigned unit cost. Both can be refined in subsequent steps, however, as attacker budget and action cost, as well as mitigation budget and fix-action costs are relative to one another, typically only one is modified. 5) Finally, the analysis gives a Pareto-optimal set of mitigation strategies within the given budget. After observing the fix-actions, the user may refine the fixactions, as some patches might be more expensive than others (which can be reflected in the associated mitigation costs), or some firewalls proposed might be to restrictive (which can be reflected by instantiating the firewall rule). Similarly, if vulnerabilities reported by Nessus are not exploitable in this network, or priori knowledge gives a more accurate estimate about the probability of an exploitable configuration, the action model can be adjusted accordingly. 6) The refinement is repeated, until a feasible mitigation strategy is reached."}, {"heading": "7.2. Network Topology and Vulnerabilities", "text": "Like in Example 1, the network topology is defined via network predicates subnet(z, h) \u2208 IN for every host h in subnet z, haclz(z1, z2, port , proto) \u2208 IN for every z1, from where all hosts in z2 are reachable via (port , proto), which are derived from a JSON file, to allow for easy manual adjustment.\nThe Nessus report is translated to network predicates vul exists(cve, h, port , proto, type) \u2208 IN for CVE cve affecting h on (port , proto), with effect on type \u2208 {confidentiality, integrity, availability}, and an attack-actions a for each z1, h1 in the universe of subnets and hosts, and h2 = h, such that\npreN(a) =subnet(z1, h1) \u2227 subnet(z2, h2) \u2227 haclz(z1, z2, port , proto) \u2227 vul exists(cve, h2, port , proto, type),\nand O(a) = {osuccess , ofail}. The value of type is determined from the U.S. government repository of standards based vulnerability management data, short NVD. As discussed in Example 4, the future availability of a host is disregarded by critical path analysis. Furthermore, the NVD does not provide data on potential side effects in case of failure. Thus, we assume all hosts in the network to be available throughout the attack.\nToday, the NVD does not provide data on how vulnerabilities may impact components other than the vulnerable component, e.g., in case of a privilege escalation. Such escalations are typically filed with type = integrity. Hence, similar to MulVal, we identify this vulnerability with a privilege escalation. The latest version 3 of the CVSS standard, released in June 2015, provides a new metric in_scope to specifically designate such vulnerabilities. While this metric is still not specific enough to accurately\ndescribe propagation, it at least avoids this drastic overapproximation. As of now, all vulnerability feeds provided by the NVD are classified using CVSSv2, hence we hope for quick adoption of the new standard. Consequently, and as opposed to Example 3, preA(a) = compromised(h, integrity), and post(osuccess) = compromised(h, type). CVSSv2 specifies one of three access vectors: \u2018local\u2019, which we ignore altogether, \u2018adjacent network\u2019, which models attacks that can only be mounted within the same subnet and typically pertain to the network layer, and \u2018network\u2019, which can be mounted from a different network. The second differs from the third in that the precondition requires z1 and z2 to be equal.\nAs a first approximation, we assign probabilities according to the \u2018access complexity\u2019 metric, which combines the probability of finding an exploitable configuration, the probability of a probabilistic exploit to succeed, and the skill required to mount the attack into either \u2018low\u2019, \u2018medium\u2019 or \u2018high\u2019. This is translated into a probability p of 0.2, 0.5, or 0.8, respectively. Thus p(Osuccess) = p\u2032 and p(Ofail) = 1 \u2212 p\u2032, where post(ofail) = >. The action cost c(a) is set to 1.\nA separate input file permits the user to refine both action cost and outcome probability of osuccess to reflect assumptions about the skill of the adversary and prior knowledge about the software configurations in the network."}, {"heading": "7.3. Threat Model", "text": "The network configuration file defines subnets that are initially under attacker control, in which case compromised(h, integrity) \u2208 IA, and subnets which the attacker aims to compromise, in which case the goal condition is \u2227 (z, type) marked as target in topology.json zcompromised(z, type).\nAdditional artificial actions permit deriving zcompromised(z, type) whenever compromised(h, type \u2227 subnet(z, h)."}, {"heading": "7.4. Mitigation Model", "text": "Our formalism supports a wide range of fix-actions, but to facilitate its use, we provide three schemas, which we instantiate to a larger number of actions.\nFix schema. The fix schema models the application of existing patches, the development of missing patches and the implementation of local workarounds, e.g., applicationlevel firewalls that protect systems from malicious traffic which are otherwise not fixable. The user specifies the CVE, host and port/protocol the fix applies to. Any of these may be a wild card *, in which case all matching fix actions of the form described in Example 5 are generated. The schema also includes the new probability assigned (which can be 0 to delete these actions) and an initial cost, which\nis applied the first time a fix-action instantiated from this schema is used, and normal cost which are applied for each subsequent use. Thus, the expensive development of a patch (high initial cost, low normal cost) can be compared with local workarounds that have higher marginal cost. The wild cards may be used to model available patches that apply to all hosts, as well as generic local workarounds that apply to any host, as a first approximation for the initial model.\nNon-zero probabilities may be used to model countermeasures which lower the success probability, but cannot remove it completely, e.g., address space layout randomisation. We employ a slightly indirect encoding to accommodate this case, adding additional attack-action copies for the lowered probability. The network state predicate determines uniquely which attack-action among these applies. The generated fix-action modifies the network state predicate accordingly.\nFirewall schema. There are two firewall schemas, one for firewalls between subnets, one for host-wise packet filtering. The former is defined by source and destination subnet along with port and protocol. Similar to the fix schema, any of the value may be specified, or left open as a wild card *, in which case a fix-action similar to the firewall fix in Example 5 is instantiated for every match. In addition, initial costs and cost for each subsequent application can be specified, in order to account for the fact that installing a firewall is more expensive than adding rules. The second firewall schema permits a similar treatment per host instead of subnets, which corresponds to local packet filtering rules."}, {"heading": "8. Experiments", "text": "To evaluate our mitigation analysis algorithm, we use a problem generator that produces network topologies and host configurations based on known vulnerabilities. For details to the generator, we refer the reader to the Appendix A. This facilitates the performance evaluation of our mitigation analysis algorithm w.r.t. several dimensions, as we can sample an arbitrary number of problems for any number of hosts, fix actions and any combination of attacker and mitigation budget. We stress, however, that this provides only insight into the applicability of the algorithm itself, not our approach as a whole. Provided the problems we generate are realistic, our results give an indication of the space of problems we can treat efficiently.\nWe have implemented the mitigation analysis algorithm on top of the FD planning tool [16]. Our experiments were conducted on a cluster of Intel Xeon E5-2660 machines running at 2.20 GHz. We terminated a run if the Pareto frontier was not found within 30 minutes, or the process required more than 4 GB of memory during execution.\nIn our evaluation we focus on coverage values, so the number of instances that could be solved within the time (memory) limits. We investigate how coverage is affected by (1) scaling the network size, (2) scaling the number of fix actions, and (3) the mitigation budget, respectively the attacker budget.\nThe budgets are computed as follows. In a precomputation step, we compute the minimal attacker budget bAmin that is required for non-zero success probability p\u2217(IN). The minimal mitigation budget bMmin is then set to the minimal budget required to lower the attacker success probability with initial attacker budget bA0 = b A min . We experimented with budget values relative to those minimal budget values, resulting from scaling them by factors out of {1, 2.5, 5, 7.5, 10,\u221e}. We denote \u03b3M the factor which is used to scale the mitigation budget, and vice versas \u03b3A the factor for the attacker budget.\nIn Figure 6(a), we observe that the algorithm provides reasonable coverage > 50% for up to 800 hosts, when considering on average 5 vulnerabilities and 5 fix-actions per host. Unless both the attacker and the mitigation budget are scaled to 1 (relative to \u03b3M and \u03b3A, respectively), this result is relatively independent from the budget. One explanation why it is independent from the budget is that there is no huge difference between factors 5 and \u221e in the sense that the attacker cannot find more or better critical paths and the defender cannot find more interesting fix action sequences because of the infinite budgets. In the case that both are scaled to 1, the searches for critical paths and fix actions sequences are vastly simplified. Hence the overall coverage is better.\nNote that the number of fix actions scales linearly with the number of hosts, which in the worst case, i.e., when all sequences need to be regarded, leads to an exponential blowup. The fact that the coverage decreases slower than linearly in number of hosts is promising at likely a result of stubborn set technique employed, as it restricts analysis to fix action sequences eventually effecting the attack actions in the computed critical paths which are only linearly dependent in the number of hosts.\nIn Figure 6(b), we have fixed the number of hosts to 500, but varied the number of fixes that apply per host by scaling \u03bbF in integer steps from 0 to 10, which controls the expected value of patch fixes generated per host. We then plotted the coverage with the total number of fixes, i.e., the number of firewall fixes and patch fixes actually generated. We tested 50 samples per value of \u03bbF and attacker/mitigation budget. We cut of at above 11 fixes per host, were we had too few data points. We furthermore applied a sliding average with a window size of 1 to smoothen the results, as the total number\nof actual fixes varies for a given \u03bbF . Similar to Figure 6(a), the influence of the attacker and mitigation budget is less than expected, except for the extreme case where both are set to their minimal values. The results suggest that the mitigation analysis is reliable up to a number of 4 fixes per hosts, but up to 16 fixes per host, there is still a decent chance for termination.\nFigure 6(c) compares the impact of the mitigation- and attacker-budget factors \u03b3M, \u03b3A \u2208 {1, 2.5, 5, 7.5, 10,\u221e}. The overall picture supports our previous observations. The attacker budget has almost no influence on the performance of the algorithm. This, however, is somewhat surprising given that the attacker budget not only affects the penetration testing task itself, but also influences the mitigation-analysis. Larger attacker budgets in principle allow for more attacks, imposing the requirement to consider more expensive mitigation strategies. It will be interesting to explore this effect, or lack thereof, on real-life networks.\nIn contrast, the algorithm behaves much more sensitive to changes in the mitigation budget. Especially in the step fom \u03b3M = 1.0 to \u03b3M = 2.5, coverage decreases significantly (almost 20 percentage points regardless of the attacker budget value). This can be explained by the effect of the increased mitigation budget on the search space. However, further increasing the mitigation budget has a less severe effect. Again, we attribute this to the problems we generate: In many cases, the mitigation strategy that results in the minimal possible attacker success probability is cheaper than the mitigation budget resulting from \u03b3M = 2.5. In almost half of the instances solved for \u03b3M = 2.5, this minimal attacker success probability turned out to be 0. In these cases specifically, the mitigation analysis can readily prune mitigation strategies with higher costs, even if more mitigation budget is available, as we maintain the current bound for the cost of lowering the attacker probability to zero (C0, see Section 6.2)."}, {"heading": "9. Conclusion & Future work", "text": "The what-if analysis mechanism presented in this work is the first of its kind and provides a semantically clear and thorough methodology for analysing mitigation strategies. We leverage the fact that network attackers can be simulated, and hence strategies for mitigation can be compared before being implemented. We have presented a highly automated\nmodelling approach, which we plan to evaluate on real networks in the future, along with an iterative workflow. Based on a detailed network and configuration model, we demonstrated the feasibility of the approach and scalability of the algorithm.\nTwo major ongoing and future lines of work arise from this contribution, pertaining to more effective algorithms, and to the practical acquisition of more refined models. Regarding effective algorithms, the major challenge lies in the effective computation of the Pareto frontier. As of now, this stands and falls with the speed with which a first good solution \u2013 a cheap fix-action sequence reducing attaker success probability to a small value \u2013 is found. In case that happens quickly, our pruning methods and thus the search become highly effective; in case it does not happen quickly, the search often becomes prohibitively enumerative and exhausts our 30 minute time limit. In other words, the search may, or may not, \u201cget lucky\u201d. What is missing, then, is effective search guidance towards good solutions, making it more likely to \u201cget lucky\u201d. This is exactly the mission statement of heuristic functions in AI heuristic search procedures. The key difference is that these procedures address, not a move-countermove situation as in fix-action sequence search, but single-player (just \u201cmove\u201d) situations (like at our attack-planning level, where as mentioned we are already using these procedures). This necessitates the extension of the heuristic function paradigm \u2013 solving a relaxed (simplified) version of the problem, delivering relaxed solution cost as a lower bound on real solution cost \u2013 to move-countermove situations. This is a far-reaching topic, relevant not only to our research here but to AI at large, that to our knowledge remains entirely unexplored.5 Notions of move-countermove relaxation are required, presumably over-approximating the defender\u2019s side while under-approximating the attacker\u2019s side of the game, and heuristic functions need to be developed that tackle the inherent min/max nature of the combined approximations without spending too much computational effort. For our concrete scenario here, one promising initial idea is to fix the attacker\u2019s side to the current optimal critical attack path, and setting the defender\u2019s objective \u2013 inside the heuristic function over-approximation \u2013 as reducing the success probability of that critical attack path as much as possible, while minimizing the summed-up fix-action cost. This results in an estimation of fix-action quality, which should be highly effective in guiding the fix-action level of the search towards good solutions quickly.\nRegarding the practical acquisition of more refined models, the quality of the results of our analyses of course hinges on the accuracy of the input model. In practice, there is a trade-off between the accuracy of the model, and the degree of automation vs. manual effort with which the model is created. This is partially due to the fact that vulnerabilities are often discovered in the process of pentesting, which\n5. Game-state evaluation mechanisms are of course widely used in gameplaying, yet based on weighing (manually or automatically derived) state features, not on a relaxation paradigm automatically derived from the state model.\na simulation cannot reproduce. (Although potential zeroday exploits can in principle be modeled in our framework as a particular form of attack-actions, that exist only with a given probability.) But it is also due to the fact that current vulnerabilities lack necessary information to derive these models automatically. There are two factors to the latter. First, economically, a more detailed machine-readable description of vulnerabilities requires considerable effort, hence there needs to be an incentive to provide this data. The successful commercial use of simulated pentesting at Core Security is partly the result of fine-grained data available within the company, and is partly the incentive for the further refinement of that data. We hope that mitigation analysis methods such as ours will be adopted and provide further incentives, as centralised knowledge about the nature of vulnerabilities can be used to improve analysis and hence lower mitigation cost. Declarative descriptions like OVAL are well-suited to this end.\nSecond, conceptually, capturing the transitivity in network attacks is not understood well enough. Due to the lack of additional information, we assume that integrity violations allow for full host compromise, which is an overapproximation. While CVSSv3 provides a metric distinguishing attacks that switch scope, it is unclear how exactly this could be of use, as the scope might pertain to user privileges within a service, sandboxes, system users, dom0privileges etc. Similar to OVAL, which describes preconditions declaratively, but defines tests that can evaluate machines, the effect of privilege escalations can be determined on a concrete system, if a vulnerability description provides sufficient information about the type of escalation that takes place. Providing a concise, abstract and versatile model for privilege escalation is thus necessary to provide the basis for automated acquisition of realistic network models."}, {"heading": "1. Scenario Generator", "text": "The problems we generate are modelled exactly as described in Section 7. We hence describe the scenario generation in terms of the topology, i. e., subnet relations defined by the network proposition subnet and connections described by the network proposition haclz, and the assignment of configurations, i.e., the network proposition vul exists and corresponding actions.\nTopology. The network topology generation follows previous works on network penetration testing task generators [43]. Similar to the running example, we generate networks which are partitioned into four zones: users, DMZ, sensitive and internet. The internet consists of only a single host which is initially under adverserial control, and which is connected to the DMZ zone. The DMZ and the sensitive zone each constitute a subnet of hosts, both subnets being connected to each other. The user zone is an hierarchy, tree, of subnets, where every subnet is connected to its parent and the sensitive part. Additionally, the root subnet of the user zone is also connected to the DMZ zone. A firewall is placed on every connection between subnets. While the firewalls inside the user zone are initially empty, i. e., they do not\nblock anything, the firewalls located on connections between two different zones only allow traffic over a fraction of ports. The ports blocked initially are selected randomly. The size of the generated networks is scaled through parameter H determining the overall number of hosts in the network. To distribute H hosts to the different zones, we add for each 40 hosts one to DMZ, one to the sensitive zone, and the remaining to the user zone (cf. [43]).\nConfigurations. Now we come to the assignment of configurations, i.e., set of vulnerabilities to hosts. In many corporate networks, host configurations are standardized, e.g., workstations have equivalent configurations or each machine within a cluster is alike. To this end, we model the distribution of the totality of hosts used in the network by means of a (nested) Dirichlet process.\nDepending on the concentration parameter \u03b1H , the ith host Hi is, with probability \u03b1H/(\u03b1H + n \u2212 1), drawn freshly from the distribution of configurations C , which we will explain in the followup, or otherwise uniformly chosen among all previous Hj , j = 1, . . . , i\u2212 1. Formally, H | C \u223c DP(\u03b1H ,C ). Configurations are drawn using the following process. First, the number of vulnerabilities a configuration has in total is drawn according to a Poisson distribution, N \u223c Pois(\u03bbV ). This number determines how many vulnerabilities are drawn in the next step by means of a second Dirichlet process. This models the fact that the software which is used in the same company tends to repeat across configurations. The base distribution over which the Dirichlet process chooses vulnerabilities is the uniform distribution over the set of vulnerabilities in our database NVD , i.e., V \u223c DP(\u03b1V ,UNVD).\nA configuration C is now chosen by drawing n from N\nand then drawing n samples from V , i.e.,\nPr[C = (c1, . . . , cn)] = Pr[V = n, c1 = V1, . . . , cn = Vn ].\nwhere V1, . . . ,Vn \u223c V . Observe that C are conditionally independent given DP(\u03b1V , UNVD), hence C may define the base distribution for the above mentioned Dirichlet process. Now the configurations are drawn from the distribution we just described, i.e., h1, . . . , hn \u223c C .\nWe are thus able to control the homogeneity of the network, as well as, indirectly, via \u03b1V , the homogeneity of the software configurations used overall. For example, if \u03b1H is low but \u03b1V is high, many configurations are equal, but if they are not, they are likely to not have much intersection (provided NVD is large enough). If \u03b1V is low but \u03b1H is high, many vulnerabilities reappear in different host configurations.\nMitigation model. Akin to Section 7, we consider two different types of fix-actions: closing open ports by adding rules to firewalls, and closing vulnerabilities through applying known patches. For the former, we generate for each subnet and each port available in this subnet a fix-action f that in effect blocks all connections to this subnet over this port, by negating the corresponding haclz propositions. Such fix-actions are always generated for all user subnets. DMZ and sensitive conceptionally do not allow closing all ports, as some ports must remain opened for services running in those subnets. Hence, for DMZ and the sensitive zone, we randomly select a subset of open ports which must not be locked out through firewall rules, and firewall fix-actions are then only generated for the remaining ports. Patch fixactions are drawn from the set of possible patches described inside the OVAL database that is provided from Center for Internet Security.6 In OVAL, each patch is described in terms of an unique identifier, human readable metadata, and a list of vulnerabilties that are closed through the application of this patch. We assign patch actions to each generated configuration. Similar to before, first, the number of patches a configuration has in total is drawn according to a Poisson distribution, NF \u223c Pois(\u03bbF ). For each configuration, first the actual number of patches nF is sampled from NF , and then nF patches are drawn uniformly from the set of patches given by OVAL which affect at least one vulnerability for this configuration.\n6. https://oval.cisecurity.org/repository"}], "references": [{"title": "A stubborn set algorithm for optimal planning", "author": ["Yusra Alkhazraji", "Martin Wehrle", "Robert Mattm\u00fcller", "Malte Helmert"], "venue": "Proceedings of the 20th European Conference on Artificial Intelligence", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Scalable, graph-based network vulnerability analysis", "author": ["Paul Ammann", "Duminda Wijesekera", "Saket Kaushik"], "venue": "In ACM Conference on Computer and Communications Security,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2002}, {"title": "The oval R  \u00a9 language specification", "author": ["Jonathan Baker", "Matthew Hansbury", "Daniel Haynes"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Course of action generation for cyber security using classical planning", "author": ["Mark Boddy", "Jonathan Gohde", "Tom Haigh", "Steven Harp"], "venue": "Proceedings of the 15th International Conference on Automated Planning and Scheduling", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Optimal information security investment with penetration testing", "author": ["Rainer B\u00f6hme", "M\u00e1rk F\u00e9legyh\u00e1zi"], "venue": "In Proceedings of the 1st International Conference on Decision and Game Theory for Security (GameSec\u201910),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "Planning as heuristic search", "author": ["Blai Bonet", "H\u00e9ctor Geffner"], "venue": "Artificial Intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "Rational choice of security measures via multi-parameter attack trees", "author": ["Ahto Buldas", "Peeter Laud", "Jaan Priisalu", "M\u00e4rt Saarepera", "Jan Willemson"], "venue": "In 1st International Workshop on Critical Information Infrastructures Security (CRITIS\u201906),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Upper bounds for adversaries\u2019 utility in attack trees", "author": ["Ahto Buldas", "Roman Stepanenko"], "venue": "In Proceedings of the 3rd International Conference on Decision and Game Theory for Security (GameSec\u201912),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "PCI DSS: A Pocket Guide, 3rd Edition", "author": ["Alan Calder", "Geraint Williams"], "venue": "IT Governance Publishing,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Computing optimal policies for attack graphs with action failures and costs", "author": ["Karel Durkota", "Viliam Lis\u00fd"], "venue": "In 7th European Starting AI Researcher Symposium (STAIRS\u201914),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Automated Planning: Theory and Practice", "author": ["Malik Ghallab", "Dana Nau", "Paolo Traverso"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "An intelligent technique for generating minimal attack graph", "author": ["Nirnay Ghosh", "S.K. Ghosh"], "venue": "In Proceedings of the 1st Workshop on Intelligent Security (SecArt\u201909),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Using partial orders for the efficient verification of deadlock freedom and safety properties", "author": ["Patrice Godefroid", "Pierre Wolper"], "venue": "In Proceedings of the 3rd International Workshop on Computer Aided Verification", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1991}, {"title": "The Fast Downward planning system", "author": ["Malte Helmert"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "Landmarks, critical paths and abstractions: What\u2019s the difference anyway", "author": ["Malte Helmert", "Carmel Domshlak"], "venue": "Proceedings of the 19th International Conference on Automated Planning and Scheduling", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Simulated penetration testing: From \u201cDijkstra\u201d to \u201cTuring Test++", "author": ["J\u00f6rg Hoffmann"], "venue": "Proceedings of the 25th International Conference on Automated Planning and Scheduling", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "The FF planning system: Fast plan generation through heuristic search", "author": ["J\u00f6rg Hoffmann", "Bernhard Nebel"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2001}, {"title": "Aggregating vulnerability metrics in enterprise networks using attack graphs", "author": ["John Homer", "Su Zhang", "Xinming Ou", "David Schmidt", "Yanhui Du", "S. Raj Rajagopalan", "Anoop Singhal"], "venue": "Journal of Computer Security,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Distilling critical attack graph surface iteratively through minimum-cost SAT solving", "author": ["Heqing Huang", "Su Zhang", "Xinming Ou", "Atul Prakash", "Karem A. Sakallah"], "venue": "In 27th Annual Computer Security Applications Conference (ACSAC),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Topological analysis of network attack vulnerability", "author": ["Sushil Jajodia", "Steven Noel", "Brian O\u2019Berry"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}, {"title": "Planning in probabilistic domains using a deterministic numeric planner", "author": ["Sergio Jimenez", "Andrew Coles", "Amanda Smith"], "venue": "In Proceedings of the 25th Workshop of the UK Planning and Scheduling Special Interest Group (PlanSig\u201906),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}, {"title": "Experiences with planning for natural language generation", "author": ["Alexander Koller", "Ronald Petrick"], "venue": "Computational Intelligence,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "ADTool: security analysis with attack-defense trees", "author": ["Barbara Kordy", "Piotr Kordy", "Sjouke Mauw", "Patrick Schweitzer"], "venue": "In Proceedings of the 10th International Conference on Quantitative Evaluation of Systems", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "Foundations of attack-defense trees", "author": ["Barbara Kordy", "Sjouke Mauw", "Sasa Radomirovic", "Patrick Schweitzer"], "venue": "In Proceedings of the 7th International Workshop on Formal Aspects in Security and Trust", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "Stackelberg vs. nash in security games: An extended investigation of interchangeability, equivalence, and uniqueness", "author": ["Dmytro Korzhyk", "Zhengyu Yin", "Christopher Kiekintveld", "Vincent Conitzer", "Milind Tambe"], "venue": "J. Artif. Int. Res.,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2011}, {"title": "Computing optimal attack strategies using unconstrained influence diagrams", "author": ["Viliam Lis\u00fd", "Radek P\u0131\u0301bil"], "venue": "In Pacific Asia Workshop on Intelligence and Security Informatics,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}, {"title": "Probabilistic planning vs replanning", "author": ["Ian Little", "Sylvie Thiebaux"], "venue": "In ICAPS Workshop on the International Planning Competition: Past, Present and Future,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2007}, {"title": "The computational complexity of probabilistic planning", "author": ["Michael L. Littman", "Judy Goldsmith", "Martin Mundhenk"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1998}, {"title": "Attack planning in the real world", "author": ["Jorge Lucangeli", "Carlos Sarraute", "Gerardo Richarte"], "venue": "In Proceedings of the 2nd Workshop on Intelligent Security (SecArt\u201910),", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2010}, {"title": "Foundations of attack trees", "author": ["Sjouke Mauw", "Martijn Oostdijk"], "venue": "In Proceedings of the 8th International Conference on Information Security and Cryptology", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2005}, {"title": "Optimal adversary behavior for the serial model of financial attack trees", "author": ["Margus Niitsoo"], "venue": "In Proceedings of the 5th International Conference on Advances in Information and Computer Security (IWSEC\u201910),", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2010}, {"title": "Advances in topological vulnerability analysis", "author": ["Steven Noel", "Matthew Elder", "Sushil Jajodia", "Pramod Kalapa", "Scott O\u2019Hare", "Kenneth Prole"], "venue": "In Proceedings of the 2009 Cybersecurity Applications & Technology Conference for Homeland Security", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2009}, {"title": "A scalable approach to attack graph generation", "author": ["Xinming Ou", "Wayne F. Boyer", "Miles A. McQueen"], "venue": "In ACM Conference on Computer and Communications Security,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2006}, {"title": "Mulval: A logic-based network security analyzer", "author": ["Xinming Ou", "Sudhakar Govindavajhala", "Andrew W. Appel"], "venue": "In Proceedings of the 14th Conference on USENIX Security Symposium - Volume 14,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2005}, {"title": "A graph-based system for network-vulnerability analysis", "author": ["Cynthia Phillips", "Laura Painton Swiler"], "venue": "In Proceedings of the New Security Paradigms Workshop,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1998}, {"title": "Using model checking to analyze network vulnerabilities", "author": ["Ronald W. Ritchey", "Paul Ammann"], "venue": "In IEEE Symposium on Security and Privacy,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2000}, {"title": "On-line planning and scheduling: An application to controlling modular printers", "author": ["Wheeler Ruml", "Minh Binh Do", "Rong Zhou", "Markus P.J. Fromherz"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2011}, {"title": "POMDPs make better hackers: Accounting for uncertainty in penetration testing", "author": ["Carlos Sarraute", "Olivier Buffet", "J\u00f6rg Hoffmann"], "venue": "Proceedings of the 26th AAAI Conference on Artificial Intelligence", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2012}, {"title": "An algorithm to find optimal attack paths in nondeterministic scenarios", "author": ["Carlos Sarraute", "Gerardo Richarte", "Jorge Luc\u00e1ngeli Obes"], "venue": "In Workshop on Security and Artificial Intelligence,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2011}, {"title": "Attack trees", "author": ["B. Schneier"], "venue": "Dr. Dobbs Journal", "citeRegEx": "45", "shortCiteRegEx": null, "year": 1999}, {"title": "Automated generation and analysis of attack graphs", "author": ["Oleg Sheyner", "Joshua W. Haines", "Somesh Jha", "Richard Lippmann", "Jeannette M. Wing"], "venue": "In IEEE Symposium on Security and Privacy,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2002}, {"title": "Security risk analysis of enterprise networks using probabilistic attack graphs", "author": ["Anoop Singhal", "Xinming Ou"], "venue": "Technical report, NIST Interagency Report", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2011}, {"title": "Goal probability analysis in mdp probabilistic planning: Exploring and enhancing the state of the art", "author": ["Marcel Steinmetz", "J\u00f6rg Hoffmann", "Olivier Buffet"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2016}, {"title": "Security and Game Theory: Algorithms, Deployed Systems, Lessons Learned", "author": ["Milind Tambe"], "venue": null, "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2011}, {"title": "A requires/provides model for computer attacks", "author": ["Steven J. Templeton", "Karl E. Levitt"], "venue": "In Proceedings of the Workshop on New Security Paradigms (NSPW\u201900),", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2000}, {"title": "A stubborn attack on state explosion", "author": ["Antti Valmari"], "venue": "Formal Methods in System Design,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 1992}, {"title": "About partial order reduction in planning and computer aided verification", "author": ["Martin Wehrle", "Malte Helmert"], "venue": "Proceedings of the 22nd International Conference on Automated Planning and Scheduling", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2012}, {"title": "FF-Replan: a baseline for probabilistic planning", "author": ["Sung Wook Yoon", "Alan Fern", "Robert Givan"], "venue": "Proceedings of the 17th International Conference on Automated Planning and Scheduling", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2007}], "referenceMentions": [{"referenceID": 8, "context": ", the Payment Card Industry Data Security Standard prescribes \u2018network vulnerability scans at least quarterly and after any significant change in the network\u2019 [10].", "startOffset": 159, "endOffset": 163}, {"referenceID": 3, "context": "To this end, AI planning methods have been proposed [4], [33] and in fact used commercially, at a company called Core Security, since at least 2010 [11].", "startOffset": 52, "endOffset": 55}, {"referenceID": 28, "context": "To this end, AI planning methods have been proposed [4], [33] and in fact used commercially, at a company called Core Security, since at least 2010 [11].", "startOffset": 57, "endOffset": 61}, {"referenceID": 34, "context": "These approaches, which derive from earlier approaches based on attack graphs [40], [45], [46], assume complete knowledge over the network configuration, which is often unavailable to the modeller, as well as the attacker.", "startOffset": 78, "endOffset": 82}, {"referenceID": 39, "context": "These approaches, which derive from earlier approaches based on attack graphs [40], [45], [46], assume complete knowledge over the network configuration, which is often unavailable to the modeller, as well as the attacker.", "startOffset": 84, "endOffset": 88}, {"referenceID": 40, "context": "These approaches, which derive from earlier approaches based on attack graphs [40], [45], [46], assume complete knowledge over the network configuration, which is often unavailable to the modeller, as well as the attacker.", "startOffset": 90, "endOffset": 94}, {"referenceID": 9, "context": "We follow a more recent approach favouring Markov decisions processes (MDP) as the underlying state model to obtain a good middle ground between accuracy and practicality [12], [19] (we discuss this in detail as part of our related work discussion, Section 2).", "startOffset": 171, "endOffset": 175}, {"referenceID": 15, "context": "We follow a more recent approach favouring Markov decisions processes (MDP) as the underlying state model to obtain a good middle ground between accuracy and practicality [12], [19] (we discuss this in detail as part of our related work discussion, Section 2).", "startOffset": 177, "endOffset": 181}, {"referenceID": 24, "context": "This min-max notion is similar to a Stackelberg game, which are frequently used in security games [29].", "startOffset": 98, "endOffset": 102}, {"referenceID": 10, "context": "Automated Planning is one of the oldest sub-areas of AI (see [13] for a comprehensive introduction).", "startOffset": 61, "endOffset": 65}, {"referenceID": 36, "context": "The founding motivation for Automated Planning mechanisms is flexible decision taking in autonomous systems, yet the generality of the models considered lends itself to applications as diverse as the control of modular printers, [42], natural language sentence generation [25], [26], greenhouse logistics [18], and, in particular, network security penetration testing [4], [12], [19], [33], [43].", "startOffset": 229, "endOffset": 233}, {"referenceID": 21, "context": "The founding motivation for Automated Planning mechanisms is flexible decision taking in autonomous systems, yet the generality of the models considered lends itself to applications as diverse as the control of modular printers, [42], natural language sentence generation [25], [26], greenhouse logistics [18], and, in particular, network security penetration testing [4], [12], [19], [33], [43].", "startOffset": 278, "endOffset": 282}, {"referenceID": 3, "context": "The founding motivation for Automated Planning mechanisms is flexible decision taking in autonomous systems, yet the generality of the models considered lends itself to applications as diverse as the control of modular printers, [42], natural language sentence generation [25], [26], greenhouse logistics [18], and, in particular, network security penetration testing [4], [12], [19], [33], [43].", "startOffset": 368, "endOffset": 371}, {"referenceID": 9, "context": "The founding motivation for Automated Planning mechanisms is flexible decision taking in autonomous systems, yet the generality of the models considered lends itself to applications as diverse as the control of modular printers, [42], natural language sentence generation [25], [26], greenhouse logistics [18], and, in particular, network security penetration testing [4], [12], [19], [33], [43].", "startOffset": 373, "endOffset": 377}, {"referenceID": 15, "context": "The founding motivation for Automated Planning mechanisms is flexible decision taking in autonomous systems, yet the generality of the models considered lends itself to applications as diverse as the control of modular printers, [42], natural language sentence generation [25], [26], greenhouse logistics [18], and, in particular, network security penetration testing [4], [12], [19], [33], [43].", "startOffset": 379, "endOffset": 383}, {"referenceID": 28, "context": "The founding motivation for Automated Planning mechanisms is flexible decision taking in autonomous systems, yet the generality of the models considered lends itself to applications as diverse as the control of modular printers, [42], natural language sentence generation [25], [26], greenhouse logistics [18], and, in particular, network security penetration testing [4], [12], [19], [33], [43].", "startOffset": 385, "endOffset": 389}, {"referenceID": 37, "context": "The founding motivation for Automated Planning mechanisms is flexible decision taking in autonomous systems, yet the generality of the models considered lends itself to applications as diverse as the control of modular printers, [42], natural language sentence generation [25], [26], greenhouse logistics [18], and, in particular, network security penetration testing [4], [12], [19], [33], [43].", "startOffset": 391, "endOffset": 395}, {"referenceID": 34, "context": "Simulated pentesting is rooted in the consideration of attack graphs, first introduced by Philipps and Swiler [40].", "startOffset": 110, "endOffset": 114}, {"referenceID": 39, "context": "[45], [50]), the attack graph is the attack-action model itself, presented to the human as an abstracted overview of (atomic) threats.", "startOffset": 0, "endOffset": 4}, {"referenceID": 44, "context": "[45], [50]), the attack graph is the attack-action model itself, presented to the human as an abstracted overview of (atomic) threats.", "startOffset": 6, "endOffset": 10}, {"referenceID": 35, "context": "[41], [46]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 40, "context": "[41], [46]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 1, "context": "Later, positive formulations \u2013 positive preconditions and postconditions only \u2013 where suggested as a relevant special case, where attackers keep gaining new assets, but never lose any assets during the course of the attack [2], [14], [23], [36], [37], [50].", "startOffset": 223, "endOffset": 226}, {"referenceID": 11, "context": "Later, positive formulations \u2013 positive preconditions and postconditions only \u2013 where suggested as a relevant special case, where attackers keep gaining new assets, but never lose any assets during the course of the attack [2], [14], [23], [36], [37], [50].", "startOffset": 228, "endOffset": 232}, {"referenceID": 19, "context": "Later, positive formulations \u2013 positive preconditions and postconditions only \u2013 where suggested as a relevant special case, where attackers keep gaining new assets, but never lose any assets during the course of the attack [2], [14], [23], [36], [37], [50].", "startOffset": 234, "endOffset": 238}, {"referenceID": 31, "context": "Later, positive formulations \u2013 positive preconditions and postconditions only \u2013 where suggested as a relevant special case, where attackers keep gaining new assets, but never lose any assets during the course of the attack [2], [14], [23], [36], [37], [50].", "startOffset": 240, "endOffset": 244}, {"referenceID": 32, "context": "Later, positive formulations \u2013 positive preconditions and postconditions only \u2013 where suggested as a relevant special case, where attackers keep gaining new assets, but never lose any assets during the course of the attack [2], [14], [23], [36], [37], [50].", "startOffset": 246, "endOffset": 250}, {"referenceID": 44, "context": "Later, positive formulations \u2013 positive preconditions and postconditions only \u2013 where suggested as a relevant special case, where attackers keep gaining new assets, but never lose any assets during the course of the attack [2], [14], [23], [36], [37], [50].", "startOffset": 252, "endOffset": 256}, {"referenceID": 29, "context": "[34], [45]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "[34], [45]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 22, "context": "These arose from early attack graph variants, and developed into \u201cGraphical Security Models\u201d [27]: Directed acyclic AND/OR graphs organizing known possible attacks into a top-down refinement hierarchy.", "startOffset": 93, "endOffset": 97}, {"referenceID": 6, "context": "[8], [9], [21], [30], [35], [44], [47]), yet they weren\u2019t, at first, given a formal semantics in terms of standard sequential decision making formalisms.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8], [9], [21], [30], [35], [44], [47]), yet they weren\u2019t, at first, given a formal semantics in terms of standard sequential decision making formalisms.", "startOffset": 5, "endOffset": 8}, {"referenceID": 17, "context": "[8], [9], [21], [30], [35], [44], [47]), yet they weren\u2019t, at first, given a formal semantics in terms of standard sequential decision making formalisms.", "startOffset": 10, "endOffset": 14}, {"referenceID": 25, "context": "[8], [9], [21], [30], [35], [44], [47]), yet they weren\u2019t, at first, given a formal semantics in terms of standard sequential decision making formalisms.", "startOffset": 16, "endOffset": 20}, {"referenceID": 30, "context": "[8], [9], [21], [30], [35], [44], [47]), yet they weren\u2019t, at first, given a formal semantics in terms of standard sequential decision making formalisms.", "startOffset": 22, "endOffset": 26}, {"referenceID": 38, "context": "[8], [9], [21], [30], [35], [44], [47]), yet they weren\u2019t, at first, given a formal semantics in terms of standard sequential decision making formalisms.", "startOffset": 28, "endOffset": 32}, {"referenceID": 41, "context": "[8], [9], [21], [30], [35], [44], [47]), yet they weren\u2019t, at first, given a formal semantics in terms of standard sequential decision making formalisms.", "startOffset": 34, "endOffset": 38}, {"referenceID": 3, "context": "After initial works linking non-probabilistic attack graphs to classical planning [4], [33], Sarraute et al.", "startOffset": 82, "endOffset": 85}, {"referenceID": 28, "context": "After initial works linking non-probabilistic attack graphs to classical planning [4], [33], Sarraute et al.", "startOffset": 87, "endOffset": 91}, {"referenceID": 37, "context": "[43] devised a comprehensive model based on POMDPs, designed to capture penetration testing as precisely as possible, explicitly modeling the incomplete knowledge on the attacker\u2019s side, as well as the development of that knowledge during the attack.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "As POMDPs do not scale \u2013 neither in terms of modeling nor in terms of computation \u2013 it was thereafter proposed to use MDPs as a more scalable intermediate model [12], [19].", "startOffset": 161, "endOffset": 165}, {"referenceID": 15, "context": "As POMDPs do not scale \u2013 neither in terms of modeling nor in terms of computation \u2013 it was thereafter proposed to use MDPs as a more scalable intermediate model [12], [19].", "startOffset": 167, "endOffset": 171}, {"referenceID": 43, "context": "[49]), quite different from the network security setting.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[27], [28], not based on standard sequential decision making formalisms.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[27], [28], not based on standard sequential decision making formalisms.", "startOffset": 6, "endOffset": 10}, {"referenceID": 4, "context": "Some research considers pentesting but from a very abstract theoretical perspective [5].", "startOffset": 84, "endOffset": 87}, {"referenceID": 5, "context": "The restriction to positive preconditions and postconditions is actually known in Automated Planning not as a planning problem of interest in its own right, but as a problem relaxation, serving for the estimation of goal distance to guide search on the actual problem [6], [20].", "startOffset": 268, "endOffset": 271}, {"referenceID": 16, "context": "The restriction to positive preconditions and postconditions is actually known in Automated Planning not as a planning problem of interest in its own right, but as a problem relaxation, serving for the estimation of goal distance to guide search on the actual problem [6], [20].", "startOffset": 273, "endOffset": 277}, {"referenceID": 37, "context": "[43].", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[14], [23], [36], [37]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[14], [23], [36], [37]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 31, "context": "[14], [23], [36], [37]).", "startOffset": 12, "endOffset": 16}, {"referenceID": 32, "context": "[14], [23], [36], [37]).", "startOffset": 18, "endOffset": 22}, {"referenceID": 32, "context": "[37],", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "[47]), because the vulnerability databases available do not", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "\u2022 T : S \u00d7 A \u00d7 S 7\u2192 [0, 1] is the transition probability function, and corresponds to the application of attacker actions to states.", "startOffset": 19, "endOffset": 25}, {"referenceID": 27, "context": "Unfortunately, finding such an optimal policy is EXPTIME-complete in general [32].", "startOffset": 77, "endOffset": 81}, {"referenceID": 42, "context": "to 25 hosts [48].", "startOffset": 12, "endOffset": 16}, {"referenceID": 18, "context": "[22], e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "Stackelberg games in the two-player setting are frequently used in security settings [29].", "startOffset": 85, "endOffset": 89}, {"referenceID": 26, "context": "[31], [53]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 47, "context": "[31], [53]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 20, "context": "[24]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "In our implementation, we use an extension of the FD system [16], with the LM-cut heuristic function [17].", "startOffset": 60, "endOffset": 64}, {"referenceID": 14, "context": "In our implementation, we use an extension of the FD system [16], with the LM-cut heuristic function [17].", "startOffset": 101, "endOffset": 105}, {"referenceID": 46, "context": "We define commutativity on top of interference [52] which we will also need later on.", "startOffset": 47, "endOffset": 51}, {"referenceID": 12, "context": "To avoid considering permutations of commutative actions, we apply a transition reduction technique based on so-called sleep sets [15], [52].", "startOffset": 130, "endOffset": 134}, {"referenceID": 46, "context": "To avoid considering permutations of commutative actions, we apply a transition reduction technique based on so-called sleep sets [15], [52].", "startOffset": 136, "endOffset": 140}, {"referenceID": 45, "context": "SSS were invented in verification and later adapted to AI planning [51], [52]; their known variants are limited to single-agent search, like the attack planning in our setting, i.", "startOffset": 67, "endOffset": 71}, {"referenceID": 46, "context": "SSS were invented in verification and later adapted to AI planning [51], [52]; their known variants are limited to single-agent search, like the attack planning in our setting, i.", "startOffset": 73, "endOffset": 77}, {"referenceID": 46, "context": "In line with previous AI planning terminology [52], we call Ls a disjunctive action landmark: a set of fix-actions L so that every applicable fix-action sequence that starts in s and ends in t where t \u2229 P 6= \u2205 contains at least one action f \u2208 L.", "startOffset": 46, "endOffset": 50}, {"referenceID": 46, "context": "Definition 10 (strong stubborn set [52]) Let \u03a0 be a mitigation-analysis task with network propositions P and fix-actions F, let s be a network state of \u03a0, let ~a be a", "startOffset": 35, "endOffset": 39}, {"referenceID": 33, "context": "The general workflow is similar to MulVAL [38], which integrates machine-readable vulnerability descriptions and reports from network vulnerability scanners such as Nessus to derive a simple logical model specified in Datalog.", "startOffset": 42, "endOffset": 46}, {"referenceID": 2, "context": "Nessus, as well as several OVAL interpreters [3] supports hostwise scans, which can be gathered centrally.", "startOffset": 45, "endOffset": 48}, {"referenceID": 13, "context": "We have implemented the mitigation analysis algorithm on top of the FD planning tool [16].", "startOffset": 85, "endOffset": 89}], "year": 2017, "abstractText": "Penetration testing is a well-established practical concept for the identification of potentially exploitable security weaknesses and an important component of a security audit. Providing a holistic security assessment for networks consisting of several hundreds hosts is hardly feasible though without some sort of mechanization. Mitigation, prioritizing countermeasures subject to a given budget, currently lacks a solid theoretical understanding and is hence more art than science. In this work, we propose the first approach for conducting comprehensive what-if analyses in order to reason about mitigation in a conceptually well-founded manner. To evaluate and compare mitigation strategies, we use simulated penetration testing, i.e., automated attack-finding, based on a network model to which a subset of a given set of mitigation actions, e.g., changes to the network topology, system updates, configuration changes etc. is applied. We determine optimal combinations that minimize the maximal attacker success (similar to a Stackelberg game), and thus provide a well-founded basis for a holistic mitigation strategy. We show that these what-if analysis models can largely be derived from network scan, public vulnerability databases and manual inspection with various degrees of automation and detail, and we simulate mitigation analysis on networks of different size and vulnerability.", "creator": "LaTeX with hyperref package"}}}