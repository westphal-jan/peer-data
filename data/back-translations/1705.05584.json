{"id": "1705.05584", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2017", "title": "Metaheuristic Design of Feedforward Neural Networks: A Review of Two Decades of Research", "abstract": "For the past two decades, Feedforward Neural Network (FNN) optimization has been a key interest among researchers and practitioners of several disciplines. FNN optimization is often viewed from different perspectives: the optimization of weights, network architecture, activation nodes, learning parameters, learning environment, etc. Researchers adopted such diverse viewpoints primarily to improve the generalization capability of FNN. The gradient descent algorithm, such as backpropagation, has been widely used to optimize FNNs. Its success is evidenced by the application of FNN to numerous real-world problems. Due to the limitations of gradient-based optimization methods, metaheuristic algorithms, including evolutionary algorithms, swarm intelligence, etc., are still widely studied by researchers aiming to obtain generalized NNN for a given problem. This article attempts to apply a wide range of research methods, including NNN, NN and NN analytics, NN methods, NNN methods of intervention and NNNN complexity.", "histories": [["v1", "Tue, 16 May 2017 08:29:00 GMT  (1026kb,D)", "http://arxiv.org/abs/1705.05584v1", null]], "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["varun kumar ojha", "ajith abraham", "v\\'aclav sn\\'a\\v{s}el"], "accepted": false, "id": "1705.05584"}, "pdf": {"name": "1705.05584.pdf", "metadata": {"source": "CRF", "title": "Metaheuristic Design of Feedforward Neural Networks: A Review of Two Decades of Research", "authors": ["Varun Kumar Ojha", "Ajith Abraham", "V\u00e1clav Sn\u00e1\u0161el"], "emails": [], "sections": [{"heading": null, "text": "Over the past two decades, the feedforward neural network (FNN) optimization has been a key interest among the researchers and practitioners of multiple disciplines. The FNN optimization is often viewed from the various perspectives: the optimization of weights, network architecture, activation nodes, learning parameters, learning environment, etc. Researchers adopted such different viewpoints mainly to improve the FNN\u2019s generalization ability. The gradient-descent algorithm such as backpropagation has been widely applied to optimize the FNNs. Its success is evident from the FNN\u2019s application to numerous real-world problems. However, due to the limitations of the gradient-based optimization methods, the metaheuristic algorithms including the evolutionary algorithms, swarm intelligence, etc., are still being widely explored by the researchers aiming to obtain generalized FNN for a given problem. This article attempts to summarize a broad spectrum of FNN optimization methodologies including conventional and metaheuristic approaches. This article also tries to connect various research directions emerged out of the FNN optimization practices, such as evolving neural network (NN), cooperative coevolution NN, complex-valued NN, deep learning, extreme learning machine, quantum NN, etc. Additionally, it provides interesting research challenges for future research to cope-up with the present information processing era. Keywords: Feedforward neural network; metaheuristics; nature-inspired algorithms; multiobjective; ensemble.\n\u2217Corresponding Author\nEngineering Applications of Artificial Intelligence 60 (2017) 97\u2013116\nar X\niv :1\n70 5.\n05 58\n4v 1\n[ cs\n.N E\n] 1\n6 M"}, {"heading": "1 Introduction", "text": "Back in 1943 McCulloch and Pitts [1] proposed a computational model inspired by the human brain, which initiated the research on artificial neural network (ANN). ANNs are capable of learning and recognizing and can solve a broad range of complex problems. Feedforward neural networks (FNNs) are the special type of ANN models. The structural representation of an FNN makes it appealing because it allows perceiving a computational model (a function) in a structural/network form. Moreover, it is the structure of an FNN that makes it a universal function approximator, which has the capabilities of approximating any continuous function [2]. Therefore, a wide range of problems is solved by the FNNs, such as pattern recognition [3], clustering and classification [4], function approximation [5], control [6], bioinformatics [7], signal processing [8], speech processing [9], etc.\nThe structure of an FNN consists of several neurons (processing units) arranged in layerby-layer basis and the neurons in a layer have connections (weights) from the neurons at its previous layer. Fundamentally, an FNN optimization/learning/training is met by searching an appropriate network structure (a function) and the weights (the parameters of the function) [10]. Finding a suitable network structure includes the determination of the appropriate neurons (i.e., activation functions), the number of neurons, and the arrangements of neurons, etc. Similarly, finding the weights indicates the optimization of a vector representing the weights of an FNN. Therefore, learning is an essential and distinguished aspect of the FNNs.\nNumerous algorithms, techniques, and procedures were proposed in the past for the FNNs optimization. Earlier, in FNN research, only the gradient-based optimization techniques were the popular choices. However, gradually because of the limitations of gradient-based algorithms, the necessity of metaheuristic-based optimization methods were recognized.\nMetaheuristics formulate the FNN components, such as weights, structure, nodes, etc., into an optimization problem. Metaheuristics implement various heuristics for finding a nearoptimum solution. Additionally, a multiobjective metaheuristic deals with the multiple objectives simultaneously. The existence of multiple objectives in the FNNs optimization is evident since the minimization of FNN\u2019s approximation error is desirable at one hand, and the generalization and model\u2019s simplification is at the other.\nIn a metaheuristic or multiobjective metaheuristic treatment to an FNN, an initial population of FNNs is guided towards a final population, where usually the best FNN is selected. However, selecting only the best FNN from a population may not always produce a general solution. Therefore, to achieve a general solution without any significant additional cost, an ensemble of many candidates chosen from a metaheuristic final population is recommended.\nThis article provides a comprehensive literature review to address the various aspects of the\nFNN optimization, such as:\n1. The importance of an FNN as a function approximator and its preliminary concepts\n(Section 2), including the introduction to the factors influencing FNN optimization (Section 2.2) and introduction to the conventional optimization algorithms (Section 2.3).\n2. The role of metaheuristics and hybrid metaheuristics in FNNs optimization (Section 3).\n3. The role of multiobjective metaheuristics (Section 4) and the ensemble methods (Sec-\ntion 5).\n4. The current challenges and future research directions (Section 6)."}, {"heading": "2 Feedforward neural networks", "text": "The intelligence of human brain is due to its massively parallel neurons network system. In other words, the architecture of the brain. Similarly, a proper design of an ANN offers a significant improvement to a learning system. The components, such as nodes, weights, and layers are responsible for the developments of various ANN models.\nA single layer perceptron (SLP) consists of an input and an output layer, and it is the simplest form of ANN model [11, 12]. However, SLPs are incapable of solving nonlinearly separable patterns [13]. Hence, a multilayer perceptron (MLP) was proposed, which addressed the limitations of SLPs by including one or more hidden layers in between an input and an output layer [14]. Initially, the backpropagation (BP) algorithm was used for the MLP training [15]. A trained MLP is then found capable of solving nonlinearly separable patterns [15]. In fact, MLPs (in general FNNs) are capable of addressing a large class of problem pertaining to pattern recognition and prediction. Moreover, an FNN is considered as a universal approximator [2]. Cybenko [16] referring to Kolmogorov\u2019s theorem1 showed that an FNN with only a single internal hidden layer\u2014containing a finite number of neurons with any continuous sigmoidal nonlinear activation function\u2014can approximate any continuous function. Also, the FNN structure (architecture) is itself capable enough to be a universal approximator [2, 18]. Hence, several researchers praised FNN for its universal approximation ability [19\u201322].\nMany other ANN models, like radial basis function [23] and support vector machine [24] are a special class of three-layer FNNs. They are capable of solving regression and classification problems using supervised learning methods. In contrast, adaptive resonance theory [25], Kohenen\u2019s self-organizing map [26], and learning-vector-quantization [26] are two-layer FNNs that are capable of solving pattern recognition and data compression problems using unsupervised learning methods.\nAdditionally, the ANN architecture with feedback connections, in other words, a network where connections between the nodes may form cycles is known as a recurrent neural net-\n1Kolmogorov\u2019s theorem: \u201cAll continuous functions of n variables have an exact representation in terms of\nfinite superpositions and compositions of a small number of functions of one variable [17].\u201d\nwork (RNN) or feedback network model. The RNNs are good at performing sequence recognition/reproduction or temporal association/prediction tasks. RNNs such as Hopfield network [27] and Boltzmann machine [28] are good at the application for memory storage and remembering input\u2013output relations. Moreover, Hopfield network was designed for solving nonlinear dynamic systems, where the stability of a dynamic system is studied under the neurodynamic paradigm [27].\nA collection of RNN models, such as temporal RNN [29], echo state RNN [30], liquid state machine [31] and backpropagation de-correlation [32] forms a paradigm called reservoir computing, which addresses several engineering applications including nonlinear signal processing and control. Although some other ANN models that are capable of doing a similar task that of the FNNs were pointed out in this Section, the discussion in this article is; however, limited to only FNNs."}, {"heading": "2.1 Components of FNNs", "text": "FNNs are the computational models that consist of many neurons (node), which are connected using synaptic links (weights) and are arranged in layer-by-layer basis. Thus, the FNNs have a specific structural configuration (architecture) in which the nodes at a layer have forward connections from the nodes at its previous layer (Fig. 1(a)). A node of an FNN is capable of processing information coming through the connection weights (Fig. 1(b)). Mathematically, the output yi (excitation) of a node (node indicated as i) is computed as:\nyi = \u03d5i\n  ni\u2211\nj=1\nwijz i j + b i\n  , (1)\nwhere ni is the total incoming connections, zi is the input, wi is the weight, bi is the bias, and \u03d5i(\u00b7) is the activation function at the i-th node to limits the amplitude of the output the node\ninto a certain range.\nFig. 1(a) is a structural representation of an FNN, i.e., a phenotype of a function f(x,w),\nwhich is parameterized by a p-dimensional input vector x = \u3008x1, x2, . . . , xp\u3009 and an n-dimensional real-valued weight vector w = \u3008w1, w2, . . . , wn\u3009. The function f(x,w) is a solution of a problem. Therefore, two tasks involved in solving a problem using an FNN are: to discover an appropriate function f(x,w) (i.e., the architecture optimization) and to discover an appropriate weight vector w (i.e., the weights optimization) using some learning algorithm.\nThe architecture optimization indicates the search for the appropriate activation functions at the nodes, the number of nodes, number of layers, the arrangements of the nodes, etc. Therefore, several components of an FNN optimization are: the connection weights; the architecture (number of layers in a network, the number of nodes at the hidden layers, the arrangement of the connections between nodes); the nodes (activation functions at the nodes); the learning algorithms (algorithms training parameters); and the learning environment. However, traditionally, the only component that was optimized was the weights of the connections by keeping other components fixed to the initial choice."}, {"heading": "2.2 Influencing factors in FNN optimization", "text": ""}, {"heading": "2.2.1 Learning environments", "text": "An FNN is trained by supplying the training data (X, Y ) of N input\u2013output pairs, i.e., X = (x1,x2, . . . ,xN) and Y = (y1,y2, . . . ,yN). Each input xi = \u3008xi1, xi2, . . . , xip\u3009 is a p-dimensional vector, and it has a corresponding q-dimensional desired output vector yi = \u3008yi1, yi2, . . . , yiq\u3009. For the training data (X, Y ), an FNN produces an output Y\u0302 = (y\u03021, y\u03022, . . . , y\u0302N), where a vector y\u0302i = \u3008y\u0302i1, y\u0302i2, . . . , y\u0302iq\u3009 is a q-dimensional FNNs output, which is then compared with the desired output yi, for all i = 1 to N by using some error/distance/cost function. The minimization/reduction of the error/distance function, in an iterative manner, is referred as a supervised learning. One very commonly known supervised learning algorithm is Delta rule or Widrow-Hoff rule [33,34] in which the n-dimensional weight vector w of an FNN is optimized as:\nwt+1 = wt + \u2206wt, (2)\nwhere \u2206wt is weight change (an additive term) at t-th iteration. The weight change \u2206wt is computed as:\n\u2206wti = \u03b7 tetix t i, (3)\nwhere \u03b7t is a learning rate, which controls the magnitude of weight change at t-th iteration and eti is the error at t-th learning iteration corresponding to i-th training input x t i presented to an FNN. The error eti at the t-th iteration may be computed as: e t i = \u2211q j=1(y t ij \u2212 y\u0302tij)2, where ytij and y\u0302tij are the desired output and FNN\u2019s output at t-th iteration respectively.\nContrary to the supervised learning paradigm, there are two other learning forms for the spacial cases of FNNs: 1) the unsupervised learning\u2014for the unlabeled training data [35], and 2) the reinforcement learning\u2014for the training data with insufficient input\u2013output relations [36]. The focus of this article is, however, on supervised learning paradigms only."}, {"heading": "2.2.2 Error functions", "text": "A supervised learning, essentially, is the minimization of the difference/distance between the desired output yi and the model\u2019s output y\u0302i = f(x,w) by comparing the difference/distance using a cost function cf : Y \u00d7 Y\u0302 \u2212\u2192 R\u22650. For this propose, several cost function can be designed. For instance, in regression problems, mean squared error is one of the commonly used cost function, which is written as:\ncf (yi, y\u0302i) = 1\nN\nN\u2211\ni=1\nq\u2211\nj=1\n(yij \u2212 y\u0302ij)2 , (4)\nwhere yij are the desired response and y\u0302ij are the FNN\u2019s responses, and their differences were summed over N data pairs. Some other functions like sum of squared error, root of mean square error, mean absolute error, correlation coefficient, etc., can be used for evaluating the FNN\u2019s predictability [37].\nThe cost function (4) or any similar squared-error-based cost function is inconsistent for solving classification problems [38]. Instead, the percentage of good classification, which has consistent behavior, can be used [38]. However, the percentage of good classification is satisfactory until no preference was given to a particular class. Therefore, accuracy and miss-classification rate are used as the cost functions. A detailed list of the cost function for evaluating the classification problems is available in [39\u201341].\nIn this article, cost function mentioned for FNN optimization is discussed in a general sense, which can be thought as the equivalent to any other user-defined cost function. Another factor related to fitness of an FNN is to compare the cost functions of two or more FNN models [42,43]. Some researchers also argue to statistically compare the predicted outputs of two or more FNN models to establish the differences in their performances [44]."}, {"heading": "2.2.3 Local minima problem", "text": "Let cf : S \u2212\u2192 R\u22650, where S \u2282 Rn is nonempty and compact (for detailed information about topological compactness, see [45]). Therefore, the following may be defined:\nDefinition 1. A point w\u2217 \u2208 S is called global minima if cf (w\u2217) \u2264 cf (w) for any w \u2208 S holds.\nDefinition 2. A point w\u2217 \u2208 S is called local minima if there exists > 0, and an - neighborhood B (w \u2217, ) around w\u2217 such that cf (w \u2217) \u2264 cf (w) for any w \u2208 S \u2229B (w\u2217, ) holds.\nLearning algorithms when to using the cost function (4) or any similar function for FNN optimization has the tendency to fall in local minima [46]. Moreover, the geometrical structure (parameter space) of a three-layer perceptron may fall to local minima and plateaus during its optimization. It indicates that the critical point corresponding to global minima of a smaller FNN model (model with h \u2212 1 hidden units) can be a local or saddle point of a larger FNN model (model with h hidden units) [47]. However, there are some ways to avoid or eliminate local minima in FNN optimization [48,49]:\n1) If the weights and training patterns are assigned randomly to a three-layer FNN that contains\nh neurons at the hidden layer, then a gradient-descent algorithm can avoid trapping into local minima [50].\n2) If linearly-separable training data and pyramidal network structure are taken, then the error\nsurface will be local minima free [51].\n3) If there are N many noncoincident input patterns to learn and three-layered FNN with N\u22121 sigmoid hidden neurons and one dummy hidden neuron is used, then the corresponding error\nsurface will be local minima free.\n4) If the training algorithms can be improved as similar to as the global descent learning\nalgorithm proposed by Cetin et al. [52] to replace gradient-descent algorithms, then it can avoid local minima.\nThese four methods depend on the number of hidden neurons, the number of training samples, the number of output neurons, and a condition that says the number of hidden neurons should not be less than the number of training samples. Moreover, it does not necessarily guarantee to converge to global minima and to set preconditions for the number of hidden neurons and linearly separable training patterns are unlikely conditions for the real-world problems [53]."}, {"heading": "2.2.4 Generalization", "text": "The generalization is a crucial aspect of an FNN optimization, where it is an ability to offer the general solutions rather than performing best for the particular cases. To achieve generalization, FNNs need to avoid both underfitting and overfitting during training, which is associated with high statistical bias and high statistical variance [54]. Therefore, one has to address trade-offs between bias and variance. Also, for a good generalization, the number of training pattern should be sufficiently larger than the total number of connections in FNN [55].\nThe standard methods to achieving generalization are determining an optimum number of free parameters (i.e., equivalent to find an optimum network architecture), early stopping of training algorithms, adding regularization term with the cost function [56,57], and adding noise to the training data.\nIn early stopping, a dataset is divided into three sets: a training set, cross-validation set, and test set. The early stopping scheme suggests stopping of training at the point (epoch) from which onward the cost function value computed on cross-validation set starts to rise [46,58\u201360]. Similarly, adding noise (jitters) into the training pattern improves FNN\u2019s generalization ability and removing insignificant weights from a trained FNN improves its fault tolerance ability [61]. Moreover, generalization is related to sparsity and stability of a learning algorithm [62].\nNow, if the approximation error of two FNN models trained on the same training data is close/similar, then the model with simple network structure (lower number of free parameters) should be selected as the best model. It is because the model with lower network complexity possesses higher generalization ability than the models with higher network complexity [63]. Moreover, the network with lower weight magnitude possesses better generalization ability [63]."}, {"heading": "2.3 Conventional optimization approaches", "text": "Finding a suitable algorithm for the FNNs optimization has always been a difficult task. The FNN optimization using conventional gradient based algorithms is viewed as an unconstrained optimization problem [10,64]. The cost function cf has to be optimized to satisfy Definition 1. Therefore, the gradient of error gt at t-th iteration is computed as:\ngt = \u2202cf \u2202wt , (5)\nwhere gt is a first-order partial derivative of the cost function cf with respect to weight vector w. Hence, a gradient-descent approach starts with an initial guess w0 and generates a sequence of weight vector w1,w2, . . . such that cf reduces in each iteration. The connection weights at iteration t are updated as:\nwt+1 = wt + \u2206wt, (6)\nwhere the weight change \u2206wt is equal to \u2212 \u03b7tgt, and \u03b7t is the learning rate. The weights updated using (5) and (6) is known as the steepest decent approach. Now, instead of using a first-order partial derivative, a second-order partial derivative (\u22072) of cost function cf can be used as:\nH t = \u22072cf = \u22022cf \u2202w , (7)\nwhere H t is Hessian matrix at the t-th iteration [65]. Hence, the weight change \u2206wt using second\u2013order Taylor\u2019s series expansion of cost function cf around point w t is computed as:\n\u2206wt = \u2212H t\u22121gt, (8)\nwhere H t\u22121 is the inverse of Hessian matrix H t and the weight change \u2206wt is known as the Newton method or Newton update [10]. In the past, several algorithms were proposed using (5) and (8). Some of them are summarized as follows:\nBackpropagation (BP) is a first-order gradient-descent algorithm for the FNNs optimization [14,15]. In BP, the error computed at the output layer is propagated backward to the hidden layers. BP algorithm has two phases of computation: forward computation and backward computation, where at t-th iteration, the weight change \u2206wt for l-th layer is computed as:\n\u2206wtl = \u03b1 twt\u22121l + \u03b7 tgtyl\u22121, (9)\nwhere y is inputs/excitation from previous layer l\u2212 1, \u03b7t is learning rate and \u03b1t is momentum factor.\nThe choice of learning rate \u03b7t and momentum factor \u03b1t are critical to gradient-descent technique. The momentum factor \u03b1t allows BP training to be biased with previous iteration weights that help convergence rate to be faster. BP is sensitive to these parameters [15]. If the learning rate is too small, learning will become slow, and if the learning rate is too large, learning will be zigzag and algorithm may not converge to required degree of satisfaction. Additionally, a high momentum factor leads to a high risk of overshooting minima and a low momentum factor may avoid local minima, but learning will be slow. The classical BP algorithm is slow and has a tendency to fall in local minima [51].\nSince the basic version of BP is sensitivity towards learning rate and momentum factor [15], several improvements were suggested by researchers: 1) a fast BP algorithm, called Quickpro was proposed in [66, 67]; 2) a delta-bar technique and an acceleration technique was suggested for tuning BP learning rate \u03b7 in [68] and in [69] respectively; and 3) a variant of BP, called resilient propagator (Rprop) was proposed in [70].\nIn the Rprop, if the gradient direction in iteration n remains unchanged from its previous iteration t\u22121, then the weight change will occur in larger magnitude, else in smaller. In simple words, if gradient sign remains unchanged from previous iterations, the magnitude of learning rate \u03b7 will be large, otherwise small. The proposed Rprop improves determinism of convergence to global minima [70]. However, it is not faster than the Quickpro, but still faster than BP [71].\nContrary to BP, a second-order minimization method, called conjugate gradient (CG) can be used for weights optimization [72\u201374]. The CG does not proceed down with a gradient; instead, it moves in the direction that is conjugate to the direction of the previous step. In other words, the gradient corresponding to the current step stays perpendicular to the direction of all the previous steps, and each step is at least as good as its previous step. Such series of steps are non-interfering. Hence, the minimization performed in one step will not be undone by any further steps. Several variants of the CG were proposed in the past [75].\nSimilar to the CG, many other variants of derivative-based conventional methods are used for weights optimization: Quasi-Newton [65], Gauss-Newton [76], or Levenberg-Marquardt [77]. Quasi-Newton uses a second-order partial derivative (7) of error (4), and it computes its weight search direction by using Broyden-Fletcher-Goldfarb-Shanno (BFGS) method [78]. In GaussNewton method, the FNNs optimization is framed as a nonlinear least square optimization\nproblem, which suggests to using the sum of squared error (4) [77]. Many researchers suggested that the Levenberg-Marquardt (LM) method outperforms BP, CG, and Quasi-Newton methods [79, 80]. Several other methods were proposed for the FNNs optimization are based on Kalman-filter [81, 82] and recursive least squares method [83]."}, {"heading": "2.4 Comments on conventional approaches", "text": "The gradient-descent based conventional algorithms operate on a single solution (a weight vector) during the optimization. Thus, these algorithms are computationally faster than the algorithms that use two or more solution vectors during the optimization and select the best solution vector at the end of optimization iterations. Moreover, the gradient-decent methods such as BP [15], Online BFGS [84] can be applied for the stochastic as well as batch mode training of the FNNs.\nThe basic advantages of the stochastic/online training of an FNN are its ability to address redundancy in training pattern, the inclusion of training data that are currently not in training set (i.e., the possibility of dynamic learning), and faster training than that of batch mode [85]. Whereas, most of the other second-order gradient-descent methods and metaheuristic algorithms can only use batch mode training. However, a batch mode (offline) training of an FNN can at least guarantee a local minima under a simple condition compared to a stochastic/online training, and for a larger dataset, batch mode training can be faster than stochastic training [86].\nOn the contrary to the advantages of the conventional methods, they have several limitations. For example, they have the tendency to fall in local minima, and they are only used for optimizing the FNN weights. Primarily, the gradient-descent algorithms depend on the error function, e.g., mean square error or sum of squared error. For instance, the least square methods like the Gauss-Newton and LM works only if the cost function is the sum of squared error. The Newton method has to compute a Hessian matrix (7), which has to be positive definite and computing the Hessian matrix (7) can be hard and expensive. Similarly, the Quasi-Newton and CG methods need to use a line-search method that sometimes can be expensive.\nMoreover, the FNN generalization, as mentioned in Section 2.2.4, needs the reduction in the number of weights (less complex network architecture). Hence, the application of conventional algorithms is limited compared to the metaheuristic algorithms such as the genetic algorithm (GA) that can be directly applied to an FNN for its automatic structure determination and complexity reduction [87, 88]. Similarly, a metaheuristic algorithm can formulate an FNN such that the insignificant weights of the network can be eliminated to improve the FNN generalization ability. Moreover, metaheuristic algorithms can evolve an FNN as a whole by optimizing its components simultaneously."}, {"heading": "3 Metaheuristic approaches", "text": "So far, only the gradient-descent based algorithms were discussed, which are local search algorithms. They are good at exploiting the obtained solutions to find new solutions. However, to find a global optimum solution, any optimization algorithm must use two techniques: 1) exploration\u2014to search new and unknown areas in a search space, and 2) exploitation\u2014to take advantage of the already discovered solution [89]. The exploration and exploitation are two contradictory strategies and a good search algorithm must find a trade-off between these two. Metaheuristic is the procedure that implements nature-inspired heuristics to combine these two strategies [90]. Hence, metaheuristic approaches are alternative to the conventional approaches for optimizing the FNNs.\nUnlike the conventional methods, which require the objective function to be continuous and differential, the metaheuristic algorithms have the ability to address complex, nonlinear, and non-differentiable problems. However, the optimization algorithms are often biased towards a specific class of problems, that is, \u201cthere is no such universal optimizer which may solve all class of problem,\u201d which is evident from no free lunch theorem [91].\nWolpert and Macready [91] introduced no free lunch (NFL) theorem to answer the question, \u201cwhether a general purpose optimization algorithm exists.\u201d Moreover, Wolpert [92] introduced NFL for optimization algorithm to answer the question, \u201cHow does the set of problems F1 \u2282 F for which algorithm a1 performs better than algorithm a2 compares to the set F2 \u2282 F for which the reverse is true.\u201d Here, F is space of all possible problems. To answer this question, Wolpert proposed NFL theorem, which says that \u201cthe average performance of any pair of algorithms across all possible problems is identical\u201d [91].\nTherefore, a straightforward interpretation of NFL is as follows. \u201cA general purpose universal optimization strategy is impossible, and the only way one strategy can outperform another if it is specialized to the structure of the specific problem under consideration\u201d [93]. Schumacher et al. [94] argue that the NFL theorem [91] holds only for the set of problems which are closed under permutation (c.u.p). Therefore, indeed the performance of one algorithm can be improved over another for the problems that are not c.u.p and most of the real-world problems are not c.u.p [95]. Such is the reason why in the past researchers were inclined to create and improvise algorithms for optimizing the FNNs."}, {"heading": "3.1 Metaheuristic algorithms", "text": "Since a large variety of metaheuristic algorithms are available, it is difficult to classify metaheuristic algorithms precisely into different classes. Though, intuitively, three basic categorize can be done:"}, {"heading": "3.1.1 Single solution based algorithms", "text": "A single solution based metaheuristic algorithm operates on a single solution (candidate) and applies some heuristic inspired by the nature or some other phenomena on the current solution. For example, algorithms like simulated annealing (SA) [96], tabu search (TS) [97], variable neighborhood search (VNS) [98], greedy randomized adaptive search (GRAP) [99], etc., improves a single solution by searching around its neighborhood and continue to improve the solution until a satisfactory solution is obtained. For instance, the heuristics of some algorithms are as follows:\nSA is a probabilistic approach that imitates the cooling strategy (annealing process) of a metallurgy industry. It uses Monte Carlo method [100] to determine the acceptance probability of a newly generated solution in the neighborhood of the current solution. Hence, for a given search space, SA should guide a solution towards a global optimal solution [96,101]. Similarly, TS is inspired by the human behavior of tabooing objects [97]. In other words, TS discourages (tabu) the acceptance of the solutions that are already explored in the past. Hence, it improves upon SA by introducing some additional restriction on the acceptance of the new solutions.\nSince a single solution based algorithm exploits the current solution, it also is known as the local search algorithm. The focus of this article is to illustrate the application of the metaheuristic algorithms for the FNNs optimization. Hence, for the detailed description of the mentioned algorithms, the readers may explore the respective references."}, {"heading": "3.1.2 Population based algorithms", "text": "Population based algorithms operate on the multiple solutions (candidates) and apply the heuristics inspired by nature, biological evolution, biology, or some other forms. In contrast to the single solution based algorithms, the population based algorithms have a high exploration (global search) ability. The following are the population based algorithms:\nEvolutionary algorithms (EA) Genetic algorithms (GA) [87, 88], evolutionary programming (EP) [102], evolutionary strategy (ES) [103], genetic programming (GP) [104], differential evolution [105], etc., are the algorithms inspired by the dynamics of natural selection and use the operators, such as selection, crossover, and mutation to find a near-optimal solution [88]. EA framework offers an exploration of a vast search space and guarantees to find a near-optimal solution. Since EAs do not depend on gradient information, they solve a large range of complex, nonlinear, nondifferentiable, multimodal optimization problems. Also, EAs give a wider scope in the FNN optimization since EAs can optimize both discreet and continuous optimization problem, and the FNN components can be formulated into both ways.\nThe differences between EAs can be briefly stated as follows: GA uses genetic operators, such as selection, crossover, and mutation to search optimum genetic vector from a search space [88];\nwhereas, only the mutation operator are used in ES to evolve a real vector solution [103]. On the other hand, GP searches an optimum program structure from a topological search space of computer programs [104] and EP are used for evolving parameters of a computer program whose structure is kept fixed [102].\nSwarm intelligence (SI) SI algorithms are inspired by the collective and self-organized behavior of the swarm (insects, birds, fish, etc.). Particle swarm algorithm (PSO) [106], ant colony optimization (ACO) [107], artificial bee colony (ABC) [108], bacterial foraging optimization (BFO) [109], etc., are some widely used SI algorithms. The basic principle of SI algorithms is as follows. First, a swarm (collection of solutions) are randomly generated. Then, the heuristic inspired by the swarm behavior modifies the current solution. For example, in PSO, ACO, ABC, and BFO, the heuristics are inspired by the foraging behavior of birds, ants, bees, and bacteria respectively. In these algorithms, an FNN component is formulated as a solution for the optimization.\nIn PSO, a swarm, as a whole, is like a flock of birds (particles, which are the weight vectors) that collectively foraging (explore search space) for food (best weight vector) and is likely to move close to an optimum food-source [106, 110]. Moreover, each particle bears two properties: location and velocity. The location of a particle is a solution vector (weight vector w), and velocity \u03b7 is a vector equal to the size of the location vector. Each particle determines its movement using knowledge of its best locations, global best location, and random perturbations [106,111].\nIn ACO, the artificial ants explore the area around their nest (colony) for searching a food source. ACO takes advantage of ants ability to choose the shortest path to a food source by communicating among each other\u2019s using a pheromone secretion [112]. This behavior of ants led to the development of ACO algorithm [107].\nSimilarly, in ABC, three kinds of honey bees, such as employed bee, onlooker bee, and scout bee are responsible for searching food source [108]. Each employed bee memorizes a food source, i.e., a solution (weight vector). Then, each onlooker bee examines the nectar amount (fitness of solution) of a food source memorized by the employed bees and depending on nectar amount; they send scout bees for searching new food source. Hence, they iteratively construct the solution. The readers are encouraged to explore the detail description the algorithms in their respective references.\nOther metaheuristics The population based metaheuristic algorithms metaphor is exploited to device several algorithms. There are algorithms inspired by the behavior of animals, birds, and insects, such as gray wolf optimization (GWO) [113], flower pollination (FP) [114], cuckoo search (CS) [115], firefly (FF) [116], etc.\nSimilarly, there are algorithms inspired by some phenomenon observed in the physics and\nchemistry, such as harmony search (HS) [117], central force optimization (CFO) [118], gravitational search optimization (GSO) [119], etc. A detailed list and classification of metaheuristic algorithms are provided in [120].\nThe growing number of metaheuristic algorithms has drawn researchers to examine the metaphor, the novelty, and the significant differences among the metaheuristic algorithms [121, 122]. In [122], the author provided an insight of the metaheuristic developed over the time, starting from SA to TS, EA, ACO, HS, etc. The author claimed that most of the metaheuristic are similar in nature and do not provide a groundbreaking method in optimization. Despite the criticisms, the author acknowledged the quality of metaheuristic research has been produced and can be produced."}, {"heading": "3.1.3 Hybrid and memetic algorithms", "text": "An effective combination of various metaheuristic algorithms may offer a better solution than that of a single algorithm. A paradigm of hybrid algorithms, called memetic algorithm gave a methodological concept for combining two or more metaheuristics (global and local) to explore a search space efficiently and to find a global optimal solution [123].\nThe conventional algorithms have the local minima problem because they lack global search ability, but they are fast and good in local search. On the other hand, the metaheuristics are good in global search, but they suffer premature convergence [124, 125]. Therefore, a combination of these two may offer a better solution in FNN optimization than that of using any one of them alone (Fig. 2). To reach a global optimum, a hybrid strategy can be used. Fig. 2 shows an impact of hybridization of metaheuristics on the FNNs optimization. The hybrid algorithms can be categorized in two paradigms:\n1) The combination of conventional and metaheuristic algorithms\u2014to take advantage of local\nsearch and global search algorithms.\n2) The combination of two or more metaheuristic algorithms\u2014to make use of different heuris-\ntics or a combined influence of two or more heuristics of global search algorithms.\nUnder the definition of memetic algorithms, researchers combine EAs with conventional algorithms [126]. For example, the effectiveness of global (GA) and local search (BP) combination is explained in [127,128]. Similarly, a hybrid PSO and BP algorithms for optimizing FNN were found useful in obtaining better approximation than using one of them alone [129].\nA convergence scenario similar to Fig. 2 was illustrated in [130], where ABC was applied for searching initial weights and LM was applied for optimizing the already discovered weights. An example of effectively combining two metaheuristic GA and PSO is illustrated in [131], where both GA and PSO optimized the same population. A detailed description of the hybrid metaheuristic algorithms for the FNN optimization is described in the following Section.\nst"}, {"heading": "3.2 Metaheuristic formulation of the FNN components", "text": "Metaheuristics are stochastic/non-deterministic algorithms. Hence, they do not guarantee a global optimal solution, but they can offer a near-optimal (satisfactory) solution. Moreover, metaheuristics efficiently solve a wide range of complex continuous optimization problems; especially when the problems have incomplete and imprecise information.\nThe basic form of FNN optimization is the act of searching its weights (free parameters of FNN) such that the cost function (4) or similar function can be minimized. However, the goodness (performance) of FNN cost function depends not only on finding optimum weights, but finding the optimum architecture, activation function, parameter setting of learning algorithm, and training environment are equally important. To apply metaheuristic algorithms for optimizing an FNN, its components (phenotype) need to be formulated into a vector (genotype) form.\nUsually, the FNN components, such as weights, architecture, activation function, learning rule, etc., are considered arbitrarily. Then, a learning algorithm is applied to search weights while the other components are kept fixed to their initial setting. The metaheuristics, on the other hand, allow us to optimization each component simultaneously or a combination of components efficiently (Fig. 3).\nThe Venn diagram in Fig. 3 illustrates the spectrum of FNN components optimization: weights, architecture, activation function, and learning rule\u2019s parameters. In Fig. 3, area \u201ca1\u201d indicates the optimization of weights; area \u201ca2\u201d indicates the optimization of weights and architecture; area \u201ca3\u201d indicates the optimization of weights, architecture, and activation function; and all other possible combinations. Examining Fig. 3, one can say that the strength and complexity of optimization increases from area denoted \u201ca1\u201d to \u201ca8,\u201d where \u201ca1\u201d is the simplest approach and \u201ca8\u201d is the most sophisticated approach.\nEach FNN component can be separately optimized on a one-by-one basis. Therefore, firstly, the weights can be optimized by keeping a fixed architecture; secondly, the architecture can\nbe optimized keeping weights fixed; thirdly, the activation function can be optimized keeping architecture and/or weights fixed; and so on. Another way is to optimize all or a combination of FNN components simultaneously. Therefore, weights and architecture can be optimized, simultaneously; or weights and activation functions, simultaneously; or weights, architecture, and activation functions simultaneously; and so on. In the simultaneous optimization of all or a combination of components, a vectored representation of all components, or a combination of components can be optimized respectively. Once a vectored representation (genotype) is designed, then one of the available metaheuristic algorithms in the literature can be applied to optimize the designed vector to obtained an optimum FNN.\nNow, there are single-solution based and population based metaheuristics [133]. In a singlesolution based metaheuristic algorithm, a genotype w = \u3008w1, w2, . . . , wn\u3009 is used. Whereas, in a population-based metaheuristic algorithm, a collection of many genotypes are used. In other words, a population matrix W = (w1,w2, . . . ,wm) of m weight vectors is used.\nYao and Liu [134] identified evolution at various components of FNN that fall into the spectrum of metaheuristic design of FNN shown in Fig. 3. This Section will describe how researchers applied metaheuristics for evolving FNN. The evolution in FNN components is described here one-by-one, as follows. Here, the word optimization, adaptation, and evolution are used in the similar context."}, {"heading": "3.2.1 Weight optimization", "text": "FNN weight optimization is the most common and widely studied approach, in which the weights are mapped onto an n-dimensional weight vector w, where n is the total number of weights in a network. The vector w is a genotype representation of a phenotype (FNN structure), where the weight w \u2208 Rn. The weights wi, an element of vector w, may be encoded in the following ways: by assigning a real value, l-bits binary coding, l-bits gray coding, IEEE\nfloating point coding, etc. Fig. 4 is an example of phenotype to genotype mapping, where a phenotype shown in Fig. 4(a) that has the connectivity matrix c as per Fig. 4(b) is encoded into three different weight vectors shown in Fig. 4(c).\nFNN weights optimization using metaheuristic is practiced from early 80\u2019s when even the term metaheuristic was not used. Engle\u2019s [135] work on FNN weight vector optimization using SA was the first evidence of metaheuristic application. To optimize weight vector using SA, first, the phenotype was mapped onto a real-valued weight vector (Fig. 4(c)), and to compute fitness of the FNN, a reverse mapping from genotype (weight vector w) to phenotype (FNN) was used. Such process was continued until a satisfactory solution was found. SA based FNN weight optimization was found to be performing better in comparison to conventional approaches [136\u2013138].\nSimilar to Engle\u2019s [135] approach of phenotype to genotype mapping and vice versa, in [139], the FNN weights optimization was performed using TS. In [140], an improvised TS, called reactive tabu search was used for optimizing weights. Several studies show that TS when used for optimizing FNN weights, outperformed BP and SA algorithm [141,142]. However, SA and TS are single solution based algorithms, which has a limited scope of exploring search space to obtain a global optimal solution. In contrast, the EAs, SI, or other bio-inspired metaheuristics are population-based algorithms that operate on multiple agents to explore a search space. Hence, they have a better exploration ability than SA, TS, BP, CG, and other single solution based algorithms [88,110].\nFor optimizing the FNN weights, EAs use two types of vector representation: realvalued and binary valued vector representation. In Fig. 4(c), following weight vector representation are illustrated: 1) real-valued coded chromosome, 2) binary coded chromosome, and 3) binary gray-coded chromosome.\nGoldberg and Holland [88] gave the idea of FNN training using GA. However, Whitley and Hanson [143] were the first to propose \u201cGENITOR,\u201d a GA based FNN training procedure that used binary-coded chromosome (Fig. 4(c)) for optimizing the weights. Many others followed the idea of GENITOR with some additional improvements such as connectivity optimization and reduced search space introduction [144, 145]. On the other hand, in [146], a binary gray\ncoding (Fig. 4(c)) scheme was used for optimizing the weights, where at first, GA was used for finding initial weights that were further optimized by using BP and vice versa.\nThe binary bit-string representation of the weights leads to a precision problem, i.e., how many bits would be sufficient for representing weights and what would be the total length of a chromosome. Moreover, the binary representation is computationally expensive because, in each training iteration, a binary to real-valued mapping and vice versa is required. Hence, it is advantageous to use the real-coded chromosome (Fig. 4(c)) directly [147\u2013151].\nTraditional EA operators are applied on the binary chromosome. Thus, operators, such as bias-mutation, unbiased-mutation, node-mutation, weight-crossover, and gradient-operator, etc., were defined, for operating on the real-valued chromosome [147]. On the other hand, a matrix-based representation of weights, where a column-wise and a row-wise crossover operators were also defined [152]. The GA-based real coded weights optimization outperforms BP and its variants for solving real-world applications [153\u2013156]. Moreover, an evolutionary inspired algorithm, called differential evolution (DE) [105,157] that imitates mutation and crossover operator to solve complex continuous optimization problems was found to be performing efficiently for real-valued weight vector optimization [158\u2013160].\nSimilar to DE, swarm-based or bio-inspired based metaheuristics directly apply heuristics inspired by nature on a real-valued vector. Hence, they are advantageous in comparison to an EA-based algorithm that needs to simulated mutation and crossover operators for real-valued weight vector [110]. It was found that PSO guides a population of the FNN weight vectors towards an optimum population [161,162]. Hence, many researchers resorted to working on swarm based metaheuristics for the FNN optimization.\nA cooperative PSO, which suggests to splitting a solution vector into n parts, where each part optimized by a swarm of m particles [163,164]. Thus, an n\u00d7m combinations are constructs an n-dimensional composite vector, where each m swarm contributes to the fitness of a solution. Such cooperation between swarms led to a better performance than that of the basic version of PSO. Similarly, a multi-phase PSO was proposed in which particle position was updated only when improvement in location was found; otherwise, the location was copied as-it-is into the next generation [165].\nA cultural cooperative particle swarm optimization (CCPSO) approach in which a collection of multiple swarms that interact by exchanging information was proposed by Lin et al. [166]. The CCPSO performed better than BP and GA when it was applied for optimizing a fuzzy neural network. Similarly, a hierarchical particle swarm optimization was used to design a beta basis function neural network [167].\nApart from PSO, there are numerous metaheuristic algorithms among which, some significant metaheuristics were discussed here that were applied for FNN optimization. The continuous version of ACO [168] was efficiently applied to optimize the FNN weight vector [169]. ACO trained FNN was found efficient in solving real-life applications, such as scheduling, prediction,\nimage recognition, etc. [170,171].\nABC was efficiently applied on weight vector for optimizing the FNNs [172\u2013174]. Similarly, considering the efficiency of HS algorithm\u2014that has a slow convergence rate, but guarantees a near-optimum solution [117]\u2014many researchers applied HS for optimizing weight vector of the FNNs [175, 176]. Moreover, the efficiency of HS comes from using m many harmonies (weight vectors), and iteratively improvising each harmony by computing new harmony (new solution vectors) using heuristic inspired by music pitch modification [117,177,178].\nIn the past, many other forms of metaheuristics were also used for optimizing the FNNs. For example, the application of FF, CS, GSO, BFO, and CFO algorithms for the FNN weights optimization is available in [179], [180], [181], [182,183], [184] respectively.\nMoreover, a comparative study showed that FF algorithm performed better than that of BP, GA, and ABC for weight vector optimization [185]. In [186] a detailed study explains the application of the local and global metaheuristic algorithm for FNN optimization. For example, local search algorithms like SA, TS, GRAP, VNS [98], estimations of distribution algorithm [187] and global search algorithms like GA, ACO, and memetic algorithm, were examined thoroughly in [186]. Additionally, many researchers studied the performance of metaheuristic algorithms for the training of the FNN and reported that the metaheuristic approaches outperform all the conventional methods by a huge margin [188\u2013190].\nThe memetic algorithm supports the hybridization of two or more global metaheuristics for the FNN optimization, which is evident from the following examples. A hybrid GA and PSO approach for optimizing the FNN were proposed in [131], where both GA and PSO were suggested to run over the same population\u2014randomly generated population W of m individuals (the same individual was treated as a chromosome in GA and a particle in PSO). In each generation of GA and PSO, the fitness of each individual was computed. Then, the best performing individuals (top-half) were marked as elites. The elite individuals were copied to next generation and half of the copied elites were optimized using PSO and the remaining half using GA through tournament selection and crossover operation.\nSimilarly, a PSO and SA based hybrid algorithm for optimizing FNN were proposed in [191], where, in each iteration, each PSO particle was governed by SA metropolis criteria [100] that determined global best particle for PSO algorithm. There are several other hybrid algorithm examples available in the literature: a hybrid PSO and GA [192]; hybrid GA and DE [193]; hybrid PSO and GSO [194]; and hybrid PSO and optimal foraging theory [195]."}, {"heading": "3.2.2 Architecture plus weight optimization", "text": "The basic architecture optimization approach is a cascade correlation learning, which iteratively adds nodes to hidden layer to construct optimum architecture [66]. Moreover, a constructive (add node iteratively) and destructive (prune nodes iteratively) method [196]. However, the constructive and the destructive methods for optimizing architecture are no different from the\nmanual trial-and-error method. Therefore, genetic representation of the FNN architecture as mentioned in Figs. 5(a), 5(b), 5(c) can be used for architecture optimization, which is equivalent to searching optimum architecture from a compact space of FNN topology [197,198].\nLet us discuss the genetic representation of architecture in detail. A direct encoding scheme (Fig. 5(a)) was proposed in [199, 200], where authors used an adjacency matrix (Fig. 4(b)) to represent connections between nodes, where between any two nodes i and j, a presence of connection is indicated by \u201c1\u201d, and absence of connection is indicated by \u201c0\u201d. Hence, they were able to encode complete structural information into a chromosome. However, it is disadvantageous because chromosome length increases with network size. Therefore, if only the network\u2019s structural information can be encoded into genotype, then, it will avoid chromosome length problem [201]. Additionally, the encoded network structural information can be accessed using rule-based recursive equation [202]. Moreover, the represented parametric/structural information into the chromosome can indirectly provide access to the rest of the structural details from a predefined archive (parametric information) [203].\nThe indirect encoding scheme reduces chromosome length, where parametric information, such as the number of hidden layers, the number of nodes at hidden layers, the number of connection, etc., makes an archive s. The production rule (Fig. 5(b)) allow us to get access to complete structural information (Fig. 5(c)). Hence, a rule based encoding scheme allows a better FNN architecture optimization than a direct encoding scheme [204].\nUnlike the weight optimization that has only limited ways of genetic representation, the FNN architecture optimization is an interesting area of research as there are various ways to represent architecture into genotype. It is evident from a fractal configured FNN representation in [205], where authors define each node using parameters, namely, edge code, input coefficient, and output coefficient. Similarly, in [206], GA was applied to evolve each layer separately and in [207], a grammar encoding and colonial competitive algorithm were proposed.\nAnother approach to the genetic representation of architecture is to encode weights w\n(real vector: Fig. 4(c)) and architecture vector a = \u3008a1, . . . am\u3009 (binary vector as Fig. 5(a)) into a combined genotype. Hence, a single solution vector s = \u3008w1, . . . , wn, a1, . . . , am\u3009 is obtained [208], which can be optimized by using metaheuristics.\nMany researchers improvised the algorithms itself to optimize architecture. Such examples are as follows: in [209], a PSO-PSO method was proposed, in which a PSO (inner PSO block) was applied for optimizing weights that were nested under another PSO (outer PSO block) which was applied for optimizing the architecture of FNN by adding or deleting hidden node. Similarly, in [210, 211], a hybrid Taguchi-genetic algorithm was proposed for optimizing the FNN architecture and weights, where authors used a genetic representation of the weights, but they select structure using constructive method (by adding hidden nodes one-by-one). A multidimensional PSO approach was proposed in [212] for constructing FNN automatically by using an architectural (topological) space. Moreover, the individuals in the swarm population were designed in such a way that it optimized both position (weights) and dimension (architecture) of an individual in each iteration. Thus, optimized FNN weights and architecture simultaneously.\nSo far, only genetic representation was discussed for evolving architecture. However, GP can optimize a phenotype itself, where genetic representation is not required [213]. Therefore, EP and GP can be directly applied to a population FNN architecture to evolve an optimum FNN architecture [148,214,215].\nThe design of the FNN architecture is responsible for processing high-dimensional data. Hence, deep learning paradigm offers study massive and deep structure of the neural network that can process complex problems related to speech processing, natural language processing, signal processing, etc., [216, 217]. Such a variant of the FNN is convolutional neural networks (ConvNets), which is designed to process data from the multiple arrays form such as a color image composed of three 2D arrays [216,217]. The ConvNets has a three-dimensional arrangement of neural nodes. Hence, it efficiently receives 3D inputs and processes them to produce 3D outputs [218].\nIn contrast to deep network paradigm, an extreme learning machine (ELM) based hierarchical learning framework (H-ELM) proposed in [219] claimed a faster learning than deep learning by ELM [220] based auto-encoding. The proposed H-ELM framework worked in two phases: unsupervised hierarchical feature representation and 2) supervised feature classification [219]."}, {"heading": "3.2.3 Input layer optimization", "text": "Input layer optimization resembles feature reduction, which is traditionally performed separately by dimensionality reduction methods [221]. However, reducing input dimension by optimizing input layer, i.e., by feeding a subset of input features at the input layer than by feeding the whole set of input features enhances FNN\u2019s performance [222,223]. Therefore, FNN\nhas a functional dependency on the problem at hand.\nEAs select a subset of input features for which FNN perform better than that of the complete feature set [222]. For this purpose, a genetic representation of input features is required in which the available features are placed on a genetic strip, and the presence of a feature is marked as \u201c1\u201d and the absence of a feature is marked as \u201c0.\u201d Such mechanism of input layer optimization was found advantageous in improving NN performance [224].\nMoreover, binary PSO [225], which is a discrete optimization method was employed for selecting the input features which were binary coded [226, 227]. In [226], a modified version of binary PSO was proposed where EA like mutation operator was applied to mutated binary vectors. Similarly, ACO, which traditional solves discrete optimization problem was applied to select input features and training of an FNN in a hybrid manner [228].\nInput layer optimization which is related to input feature reduction can also be thought as training data optimization. Training data optimization is helpful, particularly when data is insufficient or noisy. In [229], an adaptive selection of input examples was performed by employing genetic selection, where two-point and one-point crossover operations created new example patterns. For the crossover operations, the parent\u2019s examples were drawn from the original input set. Also, mutation operators were also applied for generating new child example. Hence, the efficiency of FNN was improved when trained over the modified new examples.\nAdditionally, in [230], an input example generation methods was proposed in which the input space was divided into many regions, and k-nearest neighbor method was applied to determine/generate a new virtual example, mainly for the sparse region of the input space. Hence, both the above methods of input example generation sought to enrich knowledge space for the FNN learning [229,230]."}, {"heading": "3.2.4 Node optimization", "text": "Primarily, node optimization can be addressed in three ways: 1) by choosing activation functions at the FNN active nodes from a set of activation functions [156, 231]; 2) by optimizing the arguments of activation function [232]; and 3) by placing a complete model at the nodes of a network [233,234].\nIt was found that FNN performed better when it has non-homogeneous nodes (different activation function at different nodes) than that of the homogeneous nodes [235]. In [231], evolution in FNN nodes were offered by selecting sigmoid and Gaussian function adaptively at the nodes [231]. Moreover, adaptation in both nodes and architecture using EAs, where the design of nodes was inspired by locus flight system and tailflip of crayfish [236], can further improve FNN performance [237]. For this purpose, in [238], an input dependent FNN that had a combined chromosome representation (Fig. 6) was proposed, where a real-coded GA for simultaneous optimization of weights, activation functions, and architecture was used.\nOn the other hand, to optimize nodes, a family competitive EA was proposed in [239],\nwhere three operators, such as decrease-Gaussian-mutation, Cauchy-mutation, and self-adaptivemutation were defined. Moreover, family-competition is a process that generates a pool of L many FNNs by recombination and mutation operations and selects an FNN from that pool. The family-competition with different mutation operator is repeated until the best FNN is found. Many others found that the adaptation in FNN nodes by one of the methods mentioned above can improve FNN performance to some extent [240\u2013243].\nThe third aspect of node optimization is to design a node as a model itself. Such modification leads to variate of neural network paradigms such as polynomial neural network [233,244], where the nodes are designed to as a polynomial function based on inputs to the nodes. Similarly, the nodes of a GMDH neural network is designed as an Ivakhnenko polynomial [245]; the nodes of a complex value neural network or multivalued neural network is designed with a complex value activation functions [234]; the node of spiking neural networks has specific behavior, in which a node signal is propagated to another node only if the intrinsic quality of neural activation value is above a defined threshold [246]; the nodes of fuzzy neural network paradigm is designed using the concepts of fuzzy theory [247]; the node and the architecture of the Quantum neural network are inspired by the quantum computing [248\u2013251]. In all such methods, metaheuristics have a significant role in the optimization."}, {"heading": "3.2.5 Learning algorithm optimization", "text": "The initial thought of learning algorithm optimization is the optimization of its parameters. For example, the optimization the learning rate and the mutation factor parameters of BP by applying some metaheuristics [146]. To optimize the parameters of an FNN learning algorithm, its parameters (e.g., BP parameters) and learning rules are encoded onto a genotype [201,252]. However, formulating BP parameter such as learning rule, which is a dynamic concept, into a static chromosome is disadvantageous [253]. Hence, a genetic coding for four components (current weight, activation function of the incoming node and outgoing nodes, input) local to weight in an FNN can encode [253]. Moreover, assuming that each node in a network uses same learning rule, an evolution in learning was proposed in [254], where weights optimization related to a particular node depended only on the input/output at that node. Evolution in learning rule can be described as [255]:\n\u2206wt = n\u2211\nk=1\nn\u2211\ni1,i2,...,ik=1\n( \u03b8i1,i2,...,ik k\u220f\nj=1\nwt\u22121ij\n) (10)\nwhere t is the iteration, \u2206wt is weight change, w1, w2, . . . , wn are weights associated with a node, \u03b8i is real-valued coefficient that is determined by using EAs. However, learning rule (10) is impractical because of it required huge computation time. Hence, bio-inspired algorithms may be employed for determining the coefficient in (10)."}, {"heading": "3.2.6 Combination of FNN components optimization", "text": "Fig. 3 is an impressive representation of the most of FNN optimization combinations, where the genetic representation of the combination of FNN components can be represented in Fig. 6, which refers to a hierarchy of combination, called meta-learning scheme. In the meta-learning scheme, top down or bottom up optimization approach, which means, weights to learning rule and learning rules to weight optimization can be adopted [256]. However, it resembles oneby-one learning scheme. Hence, the advantageous approach is to represent each component of FNN side-by-side onto a genetic vector for optimization, which indicates the confluence of all components of FNN as indicated by area \u201ca8\u201d in Fig. 3.\nYao [132, 255] summarized all such form of adaptation in evolutionary artificial neural network (EANN), which is a special class of artificial neural network, where in addition to learning; evolution is another fundamental form of adaptation. Infact a paradigm, called Neuroevolution that accommodates adaptive learning all or some components of FNN in some intuitive ways by applying EAs. For examples, generalized acquisition of recurrent links (GNARL) [257], evolutionary programming net (EPNet) [258], neuroevolution of augmenting topologies (NEAT) [259], hypercube-based neuroevolution of augmenting topologies (HyperNEAT) [260], evolutionary acquisition of neural topologies (EANT2) [261], and heterogeneous flexible neural tree (HFNT) [262] optimizes both FNN structure and parameters (weights) using some direct or indirect encoding methods. Moreover, several other paradigms and methods proposed in the past for the simultaneous optimization of FNN components are described as follows.\nA structured genetic algorithm was proposed in [263], which simultaneously optimized both architectures and weights. It was found that the simultaneous optimization of both weight and architecture lead to a better generalization [56, 197, 264, 265]. Considering permutation2\n2Permutation problem occurs when using traditional crossover operator, where a population has traditional\nproblem in a GA, EP-based mutation mechanism for evolving FNN architecture was proposed in [258] is known as EPNet.\nA neuroevolution of augmenting topologies (NEAT) introduced in [259] was a GAbased evolution of an FNN phenotype as a whole, in which a special mutation and crossover operator were defined for manipulating nodes and connections of FNN. Specifically, the linear network information FNN weights, nodes, and connection information were encoded using genetic encoding. The proposed NEAT was evaluated over several applications, and its performance was found outperforming static FNN topology.\nA virtual subpopulation approach was proposed in [266] for the optimization of FNN using EAs. Later, while indicating a permutation problem, crossover operator as a combinatorial optimization problem was proposed in which each hidden node was considered as a subnetwork and a complete network was evolved using the evolution of several subnetworks [267]. Additionally, GA-based and SA-based crossover operators were applied to generate an offspring (new individual subnetwork). To maintain diversity in population, two mutation operators such as BP-mutation and random-mutation were proposed. In BP-mutation, few iterations of BP algorithm were applied to update weights of the subnetwork, and in random mutation, weights of subnetwork were randomly replaced with new weights. Hence, a coevolution of FNN weights and architecture was proposed that evolved FNN with the cooperation of the individuals of a subnetwork population.\nA cooperative coevolution neural network process\u2014inspired by virtual subpopulation approach [266]\u2014 was proposed in [268], which was a symbiotic, adaptive neuroevolution (SANE) algorithm for constructing FNN in a dynamic environment. Unlike conventional evolutionary approach, which uses a population of FNNs, SANE uses a population of nodes, where each node establishes connections with the other nodes to form a complete network.\nTwo reasons of better performance of SANE over conventional and stand-alone metaheuristics were suggested. First, since SANE consider the nodes as functional components of the FNN, it accurately searches and evaluates nodes as genetic building blocks. Second, since a node alone cannot perform well and evolutionary process evolves different types of nodes, SANE was able maintains diversity in the population. Later, the concept of SANE was extended, in which the selection of several individuals from a population of hidden nodes was combined in a various permutation in order to form several complete networks, i.e., evolution in hidden nodes led to an evolution of the complete network [269].\nA concept of sparse neural trees, in which GP for evolving network structure and GA for parameter optimization was proposed in [270]. Similarly, a flexible neural tree (FNT) concept, where GP was used for the adaptation in network structure and SA for the optimization of the parameters (including parameters of activation function) was proposed in [271, 272]. FNT is a tree-like model where adaptation in all components of is equally important. Moreover,\ngenetic representation of FNN architecture.\nits components adaptation may take many forms (Fig. 3). Hence, a beta basis function\u2014 which has several controlling parameters, such as shape, size, and center\u2014was used at non-leaf nodes of an FNT [273]. It was observed that embedding beta-basis function at FNT nodes has advantages over other two parametric activation function. A parallel evolution of FNT using MPI programming and GPU programming respectively were proposed in [274] and in [275].\nA slightly different direction of FNN modification and improvement study can be seen as the study of quantum neural network (QNN). At the first place, the QNN as a quantum perceptron was proposed by Lewestein [276], where instead of classical weights, a unitary operator was used to map inputs to an output. The study in QNN encompasses the development of quantum weights, quantum neurons, quantum network, and quantum learning [249].\nThe design/algorithm of quantum network was thought as an algorithm that can find the control parameters for a coupled qubit system [277] as it appears in quantum computing. A comprehensive quantum inspired neural network is presented in [278], where two categories of inspiration were drawn: strongly and weakly quantum inspired FNN. In strongly inspired QNN, each pattern in a training set was considered as a particle which is processed by a number of FNNs in different universes. Such process was compared with the electrons or photons passing through many slits simultaneously. Whereas, in weakly inspired QNN, each training pattern (though as a particle) was in its own universe. Moreover, there were various QNN models proposed in the past by 1) Behrman et al. [279], 2) Chrisley [280], 3) Menneer [278], and Ventura [281]. A detailed description of these QNN models can be found in [282]."}, {"heading": "3.3 Comments on metaheuristics approaches", "text": "It is indeed can be concluded that metaheuristic algorithms have provided various dimension to the optimization of the FNNs. It has opened several ways such that a generalized FNN can be obtained. Especially the architecture simplification which is directly related to the generalization of an FNN can easily be achieved through the evolving FNN together with its other components. However, the primary disadvantage of using metaheuristic algorithms is the training time consumption. Since the metaheuristic algorithms use a population (many solution candidates) during optimization, the time consumption becomes directly proportional to the number of candidates in a population.\nIt can also be argued that both conventional and metaheuristic based FNN training take by far more training time than the extreme learning machine (ELM) [283]. ELM is a three-layered FNN architecture whose weights between input and hidden layer are randomly assigned and never updated. Additionally, the weights between hidden and output layer are updated in a single step using some least square estimation. Hence, extremely less time required for the learning of the FNN.\nIt is stated in NFL theorem [92] that it is difficult to find a metaheuristic algorithm that\nsolves all class of problems. Hence, a metaheuristic algorithm may find difficulty in optimizing the FNN that has been formulated for solving some specific problem (input patterns). Additionally, it is not theoretically possible to understand or determine that how fast a metaheuristics algorithm will converge or finds a satisfactory solution. The only way to determine a metaheuristic algorithm\u2019s convergence is by its empirical evaluations. Moreover, since each metaheuristic applies some specific heuristic, it is difficult to select one metaheuristic as the best metaheuristic at an instance for a problem. It is only possible to select a metaheuristic by empirically comparing the convergence speeds and trained FNN performances."}, {"heading": "4 Multiobjective metaheuristic approaches", "text": "Multiobjective optimization procedure involves in optimizing two or more objectives functions, simultaneously. Multiobjective algorithms are efficient methods for evaluating Pareto-optimal solutions for multiobjective problems. Since optimizing training error cannot provide generalization alone, FNN optimization is viewed from the multiobjective perspective.\nLet us first investigate: why the multiobjective framework is needed for FNN optimization, what are the objective functions required for framing FNN as a multiobjective problem, and how the objective functions can be framed into multiobjective optimization. Answers to these question lie in the following discussion.\nFirst, a cost function (4) or any equivalent function is the foremost necessity for the super-\nvising training of FNN.\nSecond, the generalization of FNN is an essential aspect of its optimization. One approach is to use validation error on cross-validation data because an FNN with low training error may not perform well on unseen (test) data unless FNN is generalized. Moreover, minimization of generalization error is essential than the minimization of training error.\nAnother approach is to add a regularization term to the training error to avoid overfitting. Additionally, minimizing network complexity leads to a better generalization [284]. Hence, generalization can be achieved by adding a complexity indicator term to training error, i.e., the generalization by minimizing training error and simplifying network complexity.\nThird, reducing input-feature\u2014when a problem is available with a huge input dimension (feature)\u2014can lead to a better generalization. However, input dimension reduction and training error reduction are two contradictory objectives.\nFinally, the conclusion is, the training error (4) or equivalent cost function cf needs to be optimized with one or more additional objectives to achieve generalization, which is why multiobjective framework for optimizing FNN are used.\nLet us say that training error (4) is ctrn, and an additional objective is cadd. So, a generalized\nerror cgen may be computed by adding an objective to training error as:\ncgen = ctrn + \u03bbcadd, (11)\nwhere \u03bb > 0 is a hyperparameter that controls the strength of additional objective cadd. The validation error term ccv, regularization term creg, or network complexity cnet or a combination of all can be considered as an additional objective cadd in (11). The regularization term creg is the weight decay or norm of weight vector w as:\ncreg = 1\n2\nn\u2211\ni\nw2i = 1\n2 \u2016 w \u20162 . (12)\nSimilarly, a validation error ccv is usually computed using (4) on a cross-validation data. On the other hand, the network complexity cnet is computed as:\ncnet = z\u2211\ni\nz\u2211\nj\ncij, (13)\nwhere z is the number of nodes in the network c (Fig. 5(a)), or any user-defined function can also be used for evaluating network complexity, e.g., the number of nodes, the number of connections, etc.\nHowever, the generalization objective of the form (11) is a scalarized objective that has two disadvantages [285]. First, determining an appropriate hyperparameter \u03bb that controls the contradicting objectives. Hence, the generalization ability of the produced model by using (11) will be a mystery. Second, the objective (11) leads to a single best model that tells nothing about how contradicting objectives were handled. In other words, no single solution exists that may satisfy both objectives. Therefore, generalization error (11) need to be formulated into a multiobjective form: min{ctrn, creg, ccv, . . .}, i.e., a multiobjective optimization needs to be performed as:\nminimize {c1(w), c2(w), . . . , cm(w)} subject to w \u2208 S,\nwhere m \u2265 2 is the number of objective functions ci : Rn \u2192 R\u22650. The vector of objective functions is denoted by c = \u3008c1(w), c2(w), . . . , cm(w)\u3009. The decision (variable) vectors w = \u3008w1, w2, . . . , wn\u3009 belong to the set S \u2282 Rn, which is a subset of the decision variable space Rn. The word \u201cminimize\u201d indicates the minimization all the objective functions simultaneously.\nA nondominated solution is one in which no one objective function can be improved without a simultaneous detriment to at least one of the other objectives of the solution. The nondominated solution is also known as a Pareto-optimal solution.\nDefinition 3. Pareto-dominance - A solution w1 is said to dominate a solution w2 if \u2200i = 1, 2, . . . ,m, ci(w1) \u2264 ci(w2), and there exists j \u2208 {1, 2, . . . ,m} such that cj(w1) < cj(w2).\nDefinition 4. Pareto-optimal - A solution w1 is called Pareto-optimal if there does not exist any other solution that dominates it. A set Pareto-optimal solution is referred to as a Paretofront.\nNow, a multiobjective algorithm must provide a homogeneous distribution of a population along Pareto front and improve solutions along successive generations [286]. Hence, three basic operators can be used [286]. 1) Fitness assignment to guide a population in the direction of Pareto-front using robust and efficient multiobjective selection method. 2) Density estimation to maintain solutions distributed over entire Pareto-front using operators that take account of the solution\u2019s proximity. 3) Archiving to prevent degradation in fitness during successive generations by maintaining an external population to preserve the best solutions and for periodic input to the main population. A detailed survey of multiobjective algorithms is available in [287, 288]. Now, based on the above discussion on the cost functions and generalization conditions, the multiobjective for FNN optimization can be categorized as non-Pareto based multiobjective approach and Pareto-based multiobjective approach."}, {"heading": "4.1 Non-Pareto based multiobjective approaches", "text": "In non-Pareto based multiobjective approach, the objective functions are aggregated as mentioned in (11) or by some other means. For example, in [289], authors proposed to add a regularization term c0 \u2212 creg to training error c0 \u2212 ctrn, where c0 is the origin of the two objectives. To obtain an efficient solution, they designed a vector vc of scalar objectives by varying the hyperparameter \u03bb from 0 to 1. Hence, training FNN for each scalar objective in vector vc, a Pareto set was obtained, and then, it was possible to select the best solution from the Pareto front. However, this was an expensive approach, which does not use any Paretobased multiobjective algorithm to compute Pareto set; rather, an ellipsoid method [290] was applied to train FNN for each scalar objective vci \u2208 vc sequentially. Similarly, in [291], to achieve generalization, authors proposed a sliding mode control BP algorithm for the multiobjective treatment to FNN objectives ctrn and creg. The optimization trajectory of the 2D space of the objectives ctrn and creg was controlled by modifying BP weight update rules using two sliding surface control indicators each belongs to the mentioned objectives, respectively\nMultiobjective treatment to FNN was also offered by using improvising metaheuristics itself such as a predator-prey algorithm was proposed in [292]. To get a generalized network, the predator-prey algorithm used a family of the randomly generated population of sparse neural networks, called pray population and an externally induced family of predators population whose job was to prune preys populations based on the objectives ctrn and cnet was also generated. Similarly, a hybrid multiobjective approach, where a geometrical measure based on singularvalue-decomposition for estimating a necessary number of nodes in a network was proposed in [293].\nAdditionally, a micro-hybrid genetic algorithm was introduced to fine-tuning the network performance. A hybrid algorithm, which uses GA for evolving FNN and uses PSO, BP, and\nLM for fine-tuning the evolved FNN was proposed in [294]. In the proposed hybrid algorithm, several objectives function such as training error ctrn, validation error ccv, number of hidden layers chid, number of nodes cnode, and activation function cfun were aggregated as:\ncnet = \u03b1ctrn + \u03b2ccv + \u03b3chid + \u03b4cnode + \u03b8cfun, (14)\nwhere, \u03b1, \u03b2, \u03b3, \u03b4, and \u03b8 were controlling parameters. Hence, multiple objectives were optimized simultaneously.\nAs mentioned above in Section 4, the aggregating objective function has disadvantages in obtaining the best generalized solution. It is evident from (14) that determining hyperparameters for controlling objective function is a challenging task. Therefore, Pareto-based multiobjective is an efficient choice for the multiobjective treatment of FNNs."}, {"heading": "4.2 Pareto based multiobjective approaches", "text": "The advantages of applying Pareto-based learning is thoroughly explained and compared with a single and scalerized objective in [295]. For example, a nondominated sorting genetic algorithm version II (NSGA-II) [296] when used for optimizing objectives ctrn and cnet offers a Pareto set by optimizing both objectives simultaneously using a nondominated sorting method as defined in Definition 3. Hence, NSGA-II can be applied to obtained a regularized network by optimizing the objectives ctrn and creg [297].\nSimilarly, Pareto differential evolution (PDE) algorithm and its variant self-adaptive PDE algorithm was applied to optimize objectives ctrn and cnet simultaneously that offered a Pareto-set, from which the best solution was picked-up according to network complexity and approximation error examination [298, 299]. Simultaneous optimization of the objectives ctrn and cnet were also addressed using multiobjective PSO to generalize FNN performance [300].\nFor an image classification problem, authors in [301], pointed out two crucial points: the classification speed and the classification accuracy cacc. The classification speed was then related to the network complexity (number of hidden neurons) cnet. The proposed trade-offs between classification speed and classification accuracy were addressed using NSGA-II.\nSimilarly, in [302], authors studied three methods for image classification problem: linear aggregating (LA), NSGA-II with deterministic selection (DM), and NSGA-II with tournament selection (LM). They proposed to optimize network complexity cnet and accuracy cacc. Moreover, they combined regularization term creg with accuracy cacc and proposed an adaptive strategic for designing network topology using reproduction operators for both hidden layer and input layer. The hidden layer operators were add-connection, delete-connection, add-node, and delete-node. The receptive (input) layer had the following operators: addconnection, delete-connection, add-node, and delete-node. Interestingly, they observed that DM and LM performed better than LA, i.e., Pareto-based multiobjective algorithms performed\nbetter than that of the scalerized objectives. Such ability of the Pareto-based treatment to FNN to obtain general FNN was exploited by several researchers for solving many real-life applications [303\u2013306].\nFurther, the coevolution FNN concept [269,307] was extended in [308] under the multiobjective framework, by using subnetwork and network concepts. A subnetwork was a collection of nodes, i.e., a subnetwork was considered as a hidden node for a network. Therefore, a network was a collection of subnetworks. So, a population P1 of subnetwork, which was evolved separately using NSGA-II was used to construct a population P2 of networks. Then, NSGA-II was again applied to evolve population P2. Interestingly, authors defined separate objectives for population P1 (subnetworks objectives) and P2 (networks objectives) so that the functional diversity in both network and subnetwork can be maintained. Additionally, some metrics (objectives) for measuring network and subnetwork functional diversities were defined. The objective of subnetworks were differences (for maintaining functional diversity of subnetwork), substitution (to replace poor candidates by better candidates), and complexity (for counting the number of connection, nodes, and sum of all weights). Therefore, they coevolved overall network with the cooperation of subnetwork that evolves together with the whole network to get a general solution to a problem.\nApart from the discussed objective in this section, some interesting dimensions in multiobjective treatment to FNN can be noted in [309], in which authors proposed to apply NSGA-II for the simultaneous optimization of three objectives: input-dimension, training error, and network complexity. Hence, an optimized a network that performs well on the minimal set of input dimension was obtained. Similarly, in [41, 310], authors used a Pareto-based memetic algorithm approach for combining PDE and Rprop algorithms to minimize objective pairs true classification rate and minimum sensitivity (miss-classification rate), simultaneously.\nAs a result of metaheuristic or multiobjective metaheuristic treatment, a set of FNN network is obtained and selecting the best FNN from that set is a difficult task. Since selecting a single best FNN from may not offer a generalized solution and the residual error can still be remaining many problems when selection single best FNN [311], then an ensemble of a set of FNNs is recommended."}, {"heading": "5 Ensemble of feedforward neural networks", "text": "Metaheuristics optimization of FNN leads to a final population that contains many solutions close to the best solution. Moreover, the solution in the final population are divers in the following sense: 1) parametric (each FNNs have different sets of weights); structural (each FNNs have different network configurations); and 3) training set (each FNNs are trained on different parts of a training set). Hence, a collective decision (ensemble) of l many diverse candidates selected from a final population may offer desired generalization [312]. The literature that\nexplains how to construct diverse FNNs and how to combine decisions of diverse FNNs are summarized as follows.\nThe very basic idea is to apply single-solution based algorithms on l many FNNs to get l many diverse solutions [46]. The decision of l many candidates which were created either by single solution-based metaheuristics, or by population-based metaheuristics, or by any other means are combined using the following methods [313, 314]: 1) majority voting method (for classification problems); 2) arithmetic mean (for regression problem); 3) rank-based linear combination; 4) linear combination by using recursive least square [315] (to minimize weighted least squares error so that redundant individuals are eliminated); 5) evolutionary weighted mean or majority voting (metaheuristic to determine impact of an FNN in ensemble); and 6) entropy-based method for combining FNNs in ensemble (assigning entropy to FNNs during the learning process) [316].\nSince population-based metaheuristics lead to an optimized final population, it is advantageous to use the final population for making ensemble [312]. However, there are two fundamental problems with it [317]: 1) determining ensemble size, 2) how to maintain diversity in the population. Hence, a negative correlation learning (NCL) algorithm that optimized and combined individual FNNs in an ensemble during learning process was proposed in [317]. NCL optimized all individual FNNs simultaneously and interactively by adding a correlation penalty terms to the cost functions. Moreover, NCL produced negatively correlated and specialized FNNs by using co-operation among each FNNs of a population [318].\nTo determine the size of ensemble automatically, EA-based ensemble procedure was laid down in which NCL was applied during networks training. Moreover, different FNNs were allowed learn different parts of training data and the best (according to fitness) were selected for ensemble [319]. Additionally, a constructive-cooperative-neural-network-ensemble was proposed in [320] that determined ensemble size by focusing on accuracy and diversity during a constructive, cooperative procedure [321].\nHowever, mere training fitness based selection of candidates for the ensemble is insufficient because it does not tell much about candidates role/influence in the ensemble. This problem was addressed in a GA-based selective ensemble method [322], which selects a subset of the population and determine the strength of selected candidates using GA. It was also shown that the ensemble of a subset of the population was found performing better than that of the whole population [322]. The effectiveness such GA-based selection was found efficient than the traditional ensemble methods: bagging [323] and boosting [324].\nIt is beneficial to partition/fracture training data and allows different FNN in the population to learn various parts of training data [323,324]. An evidence of such was examined in [325,326], where it was found that the ensemble of a few FNNs that was trained using bootstrapping performs better than that of an ensemble of a larger number of FNNs. Similarly, the efficiency of using distinct training sets for optimizing different FNNs was proved when a class-switching\nensembles approach proposed in [327] and were compared with bagging and boosting methods.\nAt one hand bootstrapping method allows FNN to learn different training samples. On the contrary, a clustering-and-coevolution approach for constructing neural network ensembles proposed in [328] partition the input space using a clustering method to reduced number of input nodes of FNNs. Hence, in the ensemble, diverse FNNs (different FNNs were specialized in various regions of input space) were created. Moreover, it reduced run time of learning the process by coevolving (divide-and-conquer method) different FNNs using cooperation between FNNs. Such method improves diversity and accuracy of an ensemble system [328].\nSimilarly, a method was suggested in [329] for generating diverse evolutionary FNNs using a fitness-sharing method\u2014a fitness sharing method shares resources if the distance between the individuals is smaller than the predefined sharing radius. Specifically, authors proposed a speciation based evolutionary neural ensemble method for constructing ensemble by combining FNNs using a knowledge space method. On the other hand, a progressive interactive training scheme called a sequential-neural-network-ensemble-learning method, which trained FNNs one-by-one by interaction from a central buffer of FNNs was proposed in [330].\nBoth diversity and accuracy is a crucial aspect in construing ensemble of FNNs [313]. However, accuracy and diversity are contradictory to each other, so, a multiobjective approach may be applied to evolve FNN population by maintaining accuracy and diversity simultaneously [331]. For this purpose, multiobjective regularized negative correlation learning that maximized performance and maximized the negative correlation between individuals in population was found efficient [332]."}, {"heading": "6 Challenges and future scopes", "text": "The effectiveness of FNN training primarily depends on data quality, which is governed by the following data quality assurance parameters: accuracy, reliability, timeliness, relevance, completeness, currency, consistency, flexibility, and precision [333, 334]. Usually, data cleaning is a major step before modeling [335]. Therefore, training of the FNN remains always sensitive to the data cleaning process and it poses a significant challenge to adapt some mechanism in training process such the sensitivity towards data-clean may be reduced. Additionally, one problem related to data-driven modeling (FNN learning) is the data itself which can be insufficient, imbalanced, incomplete, high-dimensional, or abundant.\nFor the case insufficient data, usually the input hyperspace is exploited to generate virtual samples to fill the sparse area of the hyperspace, and by monitoring FNN performance on the virtually generated samples [336]. The second approach exploits the dynamics of EAs in conjunction with FNNs to obtain new samples [229]. However, this area is still much to explore, where some open questions such as how efficiently FNNs can be trained with virtually generate data to mitigate the insufficiency. On the other hand, research in the area of imbalance dataset\nis continued to interest researcher [337].\nThe present era of data analysis is what we call big data, i.e., we need to deal not only with high-dimensional data but also with the variety data and stream data [338]. High-dimensional data, such as gene expression data, speech processing, natural language processing, socialnetwork-data, etc., poses significant challenges. Such challenge is to some extent addressed by deep learning paradigms that allow the arrangement several units/layers of FNNs (or any other model) in a hierarchical manner to process and understand insights of such high-dimensional data [339,340]. High-dimensional data can also be managed/reduced by encoding or decoding methods and using FNNs training [341]. Therefore, FNNs has a greater role in feature reduction.\nIn a non-stationary environment, such as stock-price market, weather forecasting, etc., data comes in the stream, i.e., data comes in sequential order, and traditionally, re-training based mechanics for dynamic learning (online learning) of FNN is the basic option [342]. However, it is still an open problem to design strategies for the dynamic training of FNN.\nApart from the crucial aspects that how to manage non-stationary data, the aspect that how to handle multi-view (heterogeneity) of data is an additional challenge. The quest of developing a model that can stand robust and efficient for the non-stationary data caused by the time-dependent process of data generation, and can accommodate new knowledge (newly generated data sample) is a significant topic in machine learning research [343]. On the other hand, integration of data or of the models for that matter for the heterogeneous data generated or gathered from different instruments and data-generation processes is a significant research problem [344,345].\nMoreover, present era, the fourth industrial revolution, is of Internet of Things (IoT) [346].\nIn IoT, sophisticated technologies such as smartphone and smartwear provide several forms of data, e.g., human activity recognition [347]. Additionally, it demands application to be simple. Hence, FNN models which when aims to such technologies needs to be less complex. Therefore, FNN architecture simplification or model\u2019s complexity reduction is a challenging task. Such problem can be addressed through the integration of FNN with statistical methods like the one usually done with hidden Markov model [348]. Therefore, such kind of modification to network architecture and specialized node design may lead to different paradigms of FNN that may solve various real-world complex problems."}, {"heading": "7 Conclusions", "text": "Feedforward neural network (FNN) is used for solving a wide range of real-world problems, which is why researcher investigated many techniques/methods for optimizing and generalizing FNN. Specifically, metaheuristics allow us to innovate and improvise methods for optimizing FNN that in turn address its local minima and generalization problems.\nInitially, only gradient based linear approximation and quadratic approximation methods\nfor optimizing FNNs were employed to train FNN. These conventional algorithms (backpropagation, Quickpro, Rprop, conjugate gradient, etc.) are local search algorithms that exploit current solution to generate a new solution; however, they lack in exploration ability, therefore, usually, finds local minima of an optimization problem.\nUnlike conventional approaches, metaheuristics (e.g., genetic algorithm, particle swarm optimization, ant colony optimization, etc.) are good at both exploitation and exploration and can address simultaneous adaptation in each component of FNN. However, no single method can solve all kinds of problem. So, we need to improvise, adapt, and construct hybrid methods for optimizing FNN. Therefore, several dynamic designs of FNN are reported in the literature: EPNet (an adaptive method of FNN architecture optimization), neuro-evolution of augmenting topologies, flexible neural tree, cooperative coevolution neural network, etc., are among them. Hence, there is a wide spectrum of FNN optimization/adaptation is possible with metaheuristic treatment to FNNs (Fig. 3) in which the fundamental aspect is the formulation of FNN (phenotype) to vectored form (genotype) or any other form of mechanism for manipulation of FNN components.\nSince there are many components to be manipulated by means of metaheuristic strategies and the availability of the fact that FNN generalization ability depends on the optimization its all the components, multiobjective treatment to FNN were used. The multiobjective-based training allows an FNN to evolve with handling two or more FNN-related objectives, such as approximation error, network complexity, input dimension, etc. Moreover, the generalization ability of system can be easily improved by combining decision of many candidates of the system. Hence, an ensemble of FNNs by making use of the metaheuristic final population was proposed and the two crucial aspect accuracy and diversity of an ensemble were taken care during propose of evolving FNNs.\nIt is evident from such aspects of FNN optimization that the future research will be able to bring the new paradigms of FNNs by applying or by the inspiration from the discussed methods in this article. Hence, that will overcome the data quality problem and will be handling new challenges of big data to cope-up with the new era information processing."}, {"heading": "Acknowledgment", "text": "Authors would like to thank the all the anonymous reviewers for the technical comments, which enhanced the contents of the preliminary version of this paper. This work was supported by the IPROCOM Marie Curie Initial Training Network, funded through the People Programme (Marie Curie Actions) of the European Unions Seventh Framework Programme FP7/20072013/, under REA grant agreement number 316555."}], "references": [{"title": "A logical calculus of the ideas immanent in nervous activity", "author": ["W. McCulloch", "W. Pitts"], "venue": "Bull. Math. Biol., vol. 5, no. 4, pp. 115\u2013133, 1943.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1943}, {"title": "Approximation capabilities of multilayer feedforward networks", "author": ["K. Hornik"], "venue": "Neural Netw., vol. 4, no. 2, pp. 251\u2013257, Oct 1991.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1991}, {"title": "Statistical pattern recognition: a review", "author": ["A. Jain", "R. Duin", "J. Mao"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 22, no. 1, pp. 4\u201337, Jan 2000.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2000}, {"title": "Neural networks for classification: a survey", "author": ["G. Zhang"], "venue": "IEEE Trans. Syst., Man, Cybern. C, Appl. Rev., vol. 30, no. 4, pp. 451\u2013462, Nov 2000.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "Neural-network approximation of piecewise continuous functions: application to friction compensation", "author": ["R. Selmic", "F. Lewis"], "venue": "IEEE Trans. Neural Netw., vol. 13, no. 3, pp. 745\u2013751, May 2002.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Design and stabilization of sampled-data neural-network-based control systems", "author": ["H. Lam", "F. Leung"], "venue": "IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 36, no. 5, pp. 995\u20131005, Oct 2006.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2006}, {"title": "Bioinformatics with soft computing", "author": ["S. Mitra", "Y. Hayashi"], "venue": "IEEE Trans. Syst., Man, Cybern. C, Appl. Rev., vol. 36, no. 5, pp. 616\u2013635, Sep 2006.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "The past, present, and future of neural networks for signal processing", "author": ["M. Niranjan", "J. Principe"], "venue": "IEEE Signal Process. Mag., vol. 14, no. 6, pp. 28\u201348, Nov 1997.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1997}, {"title": "Introduction to the special issue on neural networks for speech processing", "author": ["A. Gorin", "R. Mammone"], "venue": "IEEE Trans. Speech Audio Process., vol. 2, no. 1, pp. 113\u2013114, Jan 1994.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1994}, {"title": "The perceptron: a probabilistic model for information storage and organization in the brain", "author": ["F. Rosenblatt"], "venue": "Psychol. Rev., vol. 65, no. 6, pp. 386 \u2013 408, Nov 1958.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1958}, {"title": "Artificial neural networks: a tutorial", "author": ["A.K. Jain", "J. Mao", "K.M. Mohiuddin"], "venue": "Comput., vol. 29, no. 3, pp. 31\u201344, Mar 1996.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1996}, {"title": "Perceptrons: An Introduction to Computational Geometry", "author": ["M. Minsky", "S.A. Papert"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1988}, {"title": "Beyond regression: new tools for prediction and analysis in the behavioral sciences", "author": ["P.J. Werbos"], "venue": "Ph.D. dissertation, Harvard University, 1974.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1974}, {"title": "Learning representations by back-propagating errors", "author": ["D.E. Rumelhart", "G.E. Hinton", "R.J. Williams"], "venue": "Nature, vol. 323, Oct 1986.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1986}, {"title": "Approximation by superpositions of a sigmoidal function", "author": ["G. Cybenko"], "venue": "Math. Control, Signals, Syst., vol. 2, no. 4, pp. 303\u2013314, Dec 1989.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1989}, {"title": "On the representation of continuous functions of several variables by superposition of continuous functions of one variable and addition (in russian)", "author": ["A.K. Kolmogorov"], "venue": "Dokl. Akad. Nauk SSSR, vol. 114, pp. 369\u2013373, 1957.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1957}, {"title": "Multilayer feedforward networks are universal approximators", "author": ["K. Hornik", "M. Stinchcombe", "H. White"], "venue": "Neural Netw., vol. 2, no. 5, pp. 359\u2013366, Mar 1989. 36", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1989}, {"title": "Kolmogorov\u2019s theorem and multilayer neural networks", "author": ["V. K\u016drkov\u00e1"], "venue": "Neural Netw., vol. 5, no. 3, pp. 501\u2013506, 1992.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1992}, {"title": "Multilayer feedforward networks with a nonpolynomial activation function can approximate any function", "author": ["M. Leshno", "V.Y. Lin", "A. Pinkus", "S. Schocken"], "venue": "Neural Netw., vol. 6, no. 6, pp. 861\u2013867, Mar 1993.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1993}, {"title": "Upper bounds on the number of hidden neurons in feedforward networks with arbitrary bounded nonlinear activation functions", "author": ["G.-B. Huang", "H.A. Babri"], "venue": "IEEE Trans. Neural Netw., vol. 9, no. 1, pp. 224\u2013229, Jan 1998.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1998}, {"title": "Universal approximation using incremental constructive feedforward networks with random hidden nodes", "author": ["G.-B. Huang", "L. Chen", "C.-K. Siew"], "venue": "IEEE Trans. Neural Netw., vol. 17, no. 4, pp. 879\u2013892, Jul 2006.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Multivariable functional interpolation and adaptive networks", "author": ["D. Lowe", "D. Broomhead"], "venue": "Complex Syst., vol. 2, pp. 321\u2013355, 1988.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1988}, {"title": "Support-vector networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Mach. Learn., vol. 20, no. 3, pp. 273\u2013297, Sep 1995.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1995}, {"title": "Competitive learning: From interactive activation to adaptive resonance", "author": ["S. Grossberg"], "venue": "Cogn. Sci., vol. 11, no. 1, pp. 23\u201363, Jan 1987.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1987}, {"title": "Self-organized formation of topologically correct feature maps", "author": ["T. Kohonen"], "venue": "Biol. Cybern., vol. 43, no. 1, pp. 59\u201369, Jan 1982.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1982}, {"title": "Neural networks and physical systems with emergent collective computational abilities", "author": ["J.J. Hopfield"], "venue": "Proc. Natl. Acad. Sci. U.S.A., vol. 79, no. 8, pp. 2554\u20132558, Apr 1982.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1982}, {"title": "A learning algorithm for boltzmann machines", "author": ["D.H. Ackley", "G.E. Hinton", "T.J. Sejnowski"], "venue": "Cogn. Sci., vol. 9, no. 1, pp. 147\u2013169, 1985.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1985}, {"title": "Complex sensory-motor sequence learning based on recurrent state representation and reinforcement learning", "author": ["P.F. Dominey"], "venue": "Biol. Cybern., vol. 73, no. 3, pp. 265\u201374, Aug 1995.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1995}, {"title": "The echo state approach to analysing and training recurrent neural networks-with an erratum note", "author": ["H. Jaeger"], "venue": "German National Research Center for Information Technology, Bonn, Germany, Tech. Rep., 2001.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2001}, {"title": "The \u201dliquid computer\u201d: A novel strategy for real-time computing on time series", "author": ["T. Natschl\u00e4ger", "W. Maass", "H. Markram"], "venue": "Special Issue on Foundations of Information Processing of TELEMATIK, vol. 8, no. 1, p. 39\u201343, 2002.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2002}, {"title": "Backpropagation-decorrelation: online recurrent learning with O(N) complexity", "author": ["J.J. Steil"], "venue": "Proc. 2004 IEEE Int. Jt. Conf. Neural Netw., vol. 2, 2004, pp. 843\u2013848.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2004}, {"title": "Adaptive switching circuits", "author": ["B. Wisrow", "M.E. Hoff"], "venue": "IRE WESCON Conv. Rec., vol. 4, Aug 1960, pp. 96\u2013104.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1960}, {"title": "Adaptive sampled-data systems\u2013 a statistical theory of adaptation", "author": ["B. Widrow"], "venue": "IRE WESCON Conv. Rec., vol. 4, 1959, pp. 74\u201385.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1959}, {"title": "Feature discovery by competitive learning", "author": ["D.E. Rumelhart", "D. Zipser"], "venue": "Cogn. Sci., vol. 9, no. 1, pp. 75\u2013112, Jan 1985.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1985}, {"title": "Reinforcement learning: a survey", "author": ["L.P. Kaelbling", "M.L. Littman", "A.W. Moore"], "venue": "J. Artif. Intell. Res., vol. 4, pp. 237\u2013285, May 1996. 37", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1996}, {"title": "Evaluating the predictive performance of habitat models developed using logistic regression", "author": ["J. Pearce", "S. Ferrier"], "venue": "Ecol. Modell., vol. 133, no. 3, pp. 225\u2013245, 2000.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2000}, {"title": "Performance measures, consistency, and power for artificial neural network models", "author": ["J. Twomey", "A. Smith"], "venue": "Math. Comput. Model., vol. 21, no. 1, pp. 243\u2013258, 1995.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1995}, {"title": "Evaluating the added predictive ability of a new marker: from area under the roc curve to reclassification and beyond", "author": ["M.J. Pencina", "R.B. D Agostino", "R.S. Vasan"], "venue": "Stat. Med., vol. 27, no. 2, pp. 157\u2013172, 2008.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2008}, {"title": "A systematic analysis of performance measures for classification tasks", "author": ["M. Sokolova", "G. Lapalme"], "venue": "Inform. Process. Manage., vol. 45, no. 4, pp. 427\u2013437, Jul 2009.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2009}, {"title": "Sensitivity versus accuracy in multiclass problems using memetic pareto evolutionary neural networks", "author": ["J. Fernandez Caballero", "F. Martinez", "C. Hervas", "P. Gutierrez"], "venue": "IEEE Trans. Neural Netw., vol. 21, no. 5, pp. 750\u2013770, May 2010.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2010}, {"title": "Validating and comparing predictive models", "author": ["J. Baranyi", "C. Pin", "T. Ross"], "venue": "Int. J. Food Microbiol., vol. 48, no. 3, pp. 159\u2013166, 1999.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1999}, {"title": "Comparing the predictive accuracy of models using a simple randomization test", "author": ["H. van der Voet"], "venue": "Chemometr. Intell. Lab. Syst., vol. 25, no. 2, pp. 313\u2013323, 1994.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 1994}, {"title": "Comparing predictive accuracy", "author": ["F.X. Diebold", "R.S. Mariano"], "venue": "J. Bus. Econ. Stat., vol. 13, no. 3, pp. 253\u2013263, 1995.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1995}, {"title": "Neural network ensembles", "author": ["L. Hansen", "P. Salamon"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 12, no. 10, pp. 993\u20131001, Oct 1990.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 1990}, {"title": "Local minima and plateaus in hierarchical structures of multilayer perceptrons", "author": ["K. Fukumizu", "S.-I. Amari"], "venue": "Neural Netw., vol. 13, no. 3, pp. 317 \u2013 327, May 2000.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2000}, {"title": "Avoiding false local minima by proper initialization of connections", "author": ["L.F. Wessels", "E. Barnard"], "venue": "IEEE Trans. Neural Netw., vol. 3, no. 6, pp. 899\u2013905, Nov 1992.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 1992}, {"title": "Deterministic global optimization for fnn training", "author": ["K.-A. Toh"], "venue": "IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 33, no. 6, pp. 977\u2013983, Dec 2003.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2003}, {"title": "Local minima and back propagation", "author": ["T. Poston", "C.-N. Lee", "Y. Choie", "Y. Kwon"], "venue": "Int. Jt. Conf. Neural Netw., 1991., IJCNN, vol. 2, 1991, pp. 173\u2013176.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 1991}, {"title": "On the problem of local minima in backpropagation", "author": ["M. Gori", "A. Tesi"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 14, no. 1, pp. 76\u201386, Jan 1992.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 1992}, {"title": "Global descent replaces gradient descent to avoid local minima problem in learning with artificial neural networks", "author": ["B.C. Cetin", "J.W. Burdick", "J. Barhen"], "venue": "IEEE Int. Conf. Neural Netw., 1993, pp. 836\u2013842.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 1993}, {"title": "The local minima-free condition of feedforward neural networks for outer-supervised learning", "author": ["D.-S. Huang"], "venue": "IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 28, no. 3, pp. 477\u2013480, Jun 1998.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 1998}, {"title": "Neural networks and the bias/variance dilemma", "author": ["S. Geman", "E. Bienenstock", "R. Doursat"], "venue": "Neural Comput., vol. 4, no. 1, pp. 1\u201358, Jan 1992. 38", "citeRegEx": "54", "shortCiteRegEx": null, "year": 1992}, {"title": "30 years of adaptive neural networks: perceptron, madaline, and backpropagation", "author": ["B. Widrow", "M.A. Lehr"], "venue": "Proc. of the IEEE, vol. 78, no. 9, pp. 1415\u20131442, 1990.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 1990}, {"title": "Regularization theory and neural networks architectures", "author": ["F. Girosi", "M. Jones", "T. Poggio"], "venue": "Neural Comput., vol. 7, no. 2, pp. 219\u2013269, Mar 1995.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 1995}, {"title": "Training with noise is equivalent to tikhonov regularization", "author": ["C.M. Bishop"], "venue": "Neural Comput., vol. 7, no. 1, pp. 108\u2013116, 1995.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 1995}, {"title": "Asymptotic statistical theory of overtraining and cross-validation", "author": ["S.-i. Amari", "N. Murata", "K.-R. Muller", "M. Finke", "H.H. Yang"], "venue": "IEEE Trans. Neural Netw., vol. 8, no. 5, pp. 985\u2013996, Sep 1997.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 1997}, {"title": "Automatic early stopping using cross validation: quantifying the criteria", "author": ["L. Prechelt"], "venue": "Neural Netw., vol. 11, no. 4, pp. 761\u2013767, 1998.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 1998}, {"title": "On early stopping in gradient descent learning", "author": ["Y. Yao", "L. Rosasco", "A. Caponnetto"], "venue": "Constructive Approx., vol. 26, no. 2, pp. 289\u2013315, Apr 2007.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2007}, {"title": "Enhanced mlp performance and fault tolerance resulting from synaptic weight noise during training", "author": ["A.F. Murray", "P.J. Edwards"], "venue": "IEEE Trans. on Neural Netw., vol. 5, no. 5, pp. 792\u2013802, 1994.", "citeRegEx": "61", "shortCiteRegEx": null, "year": 1994}, {"title": "Stability and generalization", "author": ["O. Bousquet", "A. Elisseeff"], "venue": "J. Mach. Learn. Res., vol. 2, pp. 499\u2013526, 2002.", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2002}, {"title": "Similarities of error regularization, sigmoid gain scaling, target smoothing, and training with jitter", "author": ["R. Reed", "R.J. Marks", "S. Oh"], "venue": "IEEE Trans. Neural Netw., vol. 6, no. 3, pp. 529\u2013538, 1995.", "citeRegEx": "63", "shortCiteRegEx": null, "year": 1995}, {"title": "An introduction to computing with neural nets", "author": ["R.P. Lippmann"], "venue": "IEEE ASSP Mag., vol. 4, no. 2, pp. 4\u201322, Apr 1987.", "citeRegEx": "64", "shortCiteRegEx": null, "year": 1987}, {"title": "Optimization schemes for neural network training", "author": ["O.T.-C. Chen", "B.J. Sheu"], "venue": "1994 IEEE Int. Conf. Neural Netw., 1994. IEEE World Congr. Comput. Intell., vol. 2, 1994, pp. 817\u2013822.", "citeRegEx": "65", "shortCiteRegEx": null, "year": 1994}, {"title": "The cascade-correlation learning architecture", "author": ["S.E. Fahlman", "C. Lebiere"], "venue": "Advances in Neural Information Processing Systems 2, D. S. Touretzky, Ed. San Francisco, CA, USA: Morgan Kaufmann, 1990, pp. 524\u2013532.", "citeRegEx": "66", "shortCiteRegEx": null, "year": 1990}, {"title": "An empirical study of learning speed in back-propagation networks", "author": ["S.E. Fahlman"], "venue": "Carnegie Mellon University, Tech. Rep., 1988.", "citeRegEx": "67", "shortCiteRegEx": null, "year": 1988}, {"title": "Increased rates of convergence through learning rate adaptation", "author": ["R.A. Jacobs"], "venue": "Neural Netw., vol. 1, no. 4, pp. 295\u2013307, 1988.", "citeRegEx": "68", "shortCiteRegEx": null, "year": 1988}, {"title": "Acceleration techniques for the backpropagation algorithm", "author": ["F.M. Silva", "L.B. Almeida"], "venue": "Neural Networks, ser. Lecture Notes in Computer Science. Springer, 1990, vol. 412, pp. 110\u2013119.", "citeRegEx": "69", "shortCiteRegEx": null, "year": 1990}, {"title": "A direct adaptive method for faster backpropagation learning: The rprop algorithm", "author": ["M. Riedmiller", "H. Braun"], "venue": "IEEE Int. Conf. Neural Netw., 1993., IJCNN, 1993, pp. 586\u2013591.", "citeRegEx": "70", "shortCiteRegEx": null, "year": 1993}, {"title": "Optimization of the backpropagation algorithm for training multilayer perceptrons", "author": ["W. Schiffmann", "M. Joost", "R. Werner"], "venue": "University of Koblenz, Institute of Physics, Rheinau, Koblenz, Tech. Rep., 1994.", "citeRegEx": "71", "shortCiteRegEx": null, "year": 1994}, {"title": "Methods of conjugate gradients for solving linear systems", "author": ["M.R. Hestenes", "E. Stiefel"], "venue": "J. Res. Nat. Bur. Stand., vol. 49, no. 6, pp. 409\u2013436, Dec 1952. 39", "citeRegEx": "72", "shortCiteRegEx": null, "year": 1952}, {"title": "A neural-net training program based on conjugate-gradient optimization", "author": ["E. Barnard", "R.A. Cole"], "venue": "Technical Repport CSE 89-014, Department of Computer Science, Oregon Graduate Institute of Science and Technology, Tech. Rep., 1989.", "citeRegEx": "73", "shortCiteRegEx": null, "year": 1989}, {"title": "Conjugate gradient algorithm for efficient training of artificial neural networks", "author": ["C. Charalambous"], "venue": "IEE Proc. G (Circuits, Devices, Syst.), vol. 139, no. 3, pp. 301\u2013310, Jun 1992.", "citeRegEx": "74", "shortCiteRegEx": null, "year": 1992}, {"title": "A nonlinear conjugate gradient method with a strong global convergence property", "author": ["Y.-H. Dai", "Y. Yuan"], "venue": "SIAM J. Optim., vol. 10, no. 1, pp. 177\u2013182, 1999.", "citeRegEx": "75", "shortCiteRegEx": null, "year": 1999}, {"title": "Nonlinear programming, 2nd ed", "author": ["D.P. Bertsekas"], "venue": "Athena scientific Belmont,", "citeRegEx": "76", "shortCiteRegEx": "76", "year": 1999}, {"title": "An algorithm for least-squares estimation of nonlinear parameters", "author": ["D.W. Marquardt"], "venue": "J. Ind. Appl. Math., vol. 11, no. 2, pp. 431\u2013441, Jun 1963.", "citeRegEx": "77", "shortCiteRegEx": null, "year": 1963}, {"title": "Practical Methods of Optimization", "author": ["R. Fletcher"], "venue": null, "citeRegEx": "78", "shortCiteRegEx": "78", "year": 1987}, {"title": "Training feedforward networks with the Marquardt algorithm", "author": ["M.T. Hagan", "M.B. Menhaj"], "venue": "IEEE Trans. Neural Netw., vol. 5, no. 6, pp. 989\u2013993, Nov 1994.", "citeRegEx": "79", "shortCiteRegEx": null, "year": 1994}, {"title": "Neighborhood based levenberg-marquardt algorithm for neural network training", "author": ["G. Lera", "M. Pinzolas"], "venue": "IEEE Trans. Neural Netw., vol. 13, no. 5, pp. 1200\u20131203, Sep 2002.", "citeRegEx": "80", "shortCiteRegEx": null, "year": 2002}, {"title": "On the kalman filtering method in neural network training and pruning", "author": ["J. Sum", "C.-S. Leung", "G.H. Young", "W.-K. Kan"], "venue": "IEEE Trans. Neural Netw., vol. 10, no. 1, pp. 161\u2013166, 1999.", "citeRegEx": "82", "shortCiteRegEx": null, "year": 1999}, {"title": "Fast learning process of multilayer neural networks using recursive least squares method", "author": ["M.R. Azimi-Sadjadi", "R.-J. Liou"], "venue": "IEEE Trans. Signal Process., vol. 40, no. 2, pp. 446\u2013450, 1992.", "citeRegEx": "83", "shortCiteRegEx": null, "year": 1992}, {"title": "A stochastic quasi-newton method for online convex optimization", "author": ["N.N. Schraudolph", "J. Yu", "S. G\u00fcnter"], "venue": "Proc. 11th Int. Conf. Artif. Intell. Stat., vol. 7, 2007, pp. 436\u2013443.", "citeRegEx": "84", "shortCiteRegEx": null, "year": 2007}, {"title": "The general inefficiency of batch training for gradient descent learning", "author": ["D.R. Wilson", "T.R. Martinez"], "venue": "Neural Netw., vol. 16, no. 10, pp. 1429\u20131451, 2003.", "citeRegEx": "85", "shortCiteRegEx": null, "year": 2003}, {"title": "Theoretical analysis of batch and on-line training for gradient descent learning in neural networks", "author": ["T. Nakama"], "venue": "Neurocomputing, vol. 73, no. 1, pp. 151\u2013159, 2009.", "citeRegEx": "86", "shortCiteRegEx": null, "year": 2009}, {"title": "Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence", "author": ["J.H. Holland"], "venue": null, "citeRegEx": "87", "shortCiteRegEx": "87", "year": 1975}, {"title": "Genetic algorithms and machine learning", "author": ["D.E. Goldberg", "J.H. Holland"], "venue": "Mach. Learn., vol. 3, no. 2, pp. 95\u201399, Oct 1988.", "citeRegEx": "88", "shortCiteRegEx": null, "year": 1988}, {"title": "Exploration and exploitation in organizational learning", "author": ["J.G. March"], "venue": "Org. Sci., vol. 2, no. 1, pp. 71\u201387, Feb 1991.", "citeRegEx": "89", "shortCiteRegEx": null, "year": 1991}, {"title": "Metaheuristics: a bibliography", "author": ["I.H. Osman", "G. Laporte"], "venue": "Ann. Oper. Res., vol. 63, no. 5, pp. 511\u2013623, Oct 1996.", "citeRegEx": "90", "shortCiteRegEx": null, "year": 1996}, {"title": "No free lunch theorems for optimization", "author": ["D.H. Wolpert", "W.G. Macready"], "venue": "IEEE Trans. Evol. Comput., vol. 1, no. 1, pp. 67\u201382, Apr 1997.", "citeRegEx": "91", "shortCiteRegEx": null, "year": 1997}, {"title": "The lack of a priori distinctions between learning algorithms", "author": ["D.H. Wolpert"], "venue": "Neural Comput., vol. 8, no. 7, pp. 1341\u20131390, Oct 1996. 40", "citeRegEx": "92", "shortCiteRegEx": null, "year": 1996}, {"title": "Simple explanation of the no free lunch theorem of optimization", "author": ["Y.-C. Ho", "D.L. Pepyne"], "venue": "Cybern.Syst. Anal., vol. 38, no. 2, pp. 292\u2013298, Mar 2002.", "citeRegEx": "93", "shortCiteRegEx": null, "year": 2002}, {"title": "The no free lunch and problem description length", "author": ["C. Schumacher", "M.D. Vose", "L.D. Whitley"], "venue": "Proc. of the Genetic and Evolutionary Computation Conf. (GECCO-2001), 2001, pp. 565\u2013570.", "citeRegEx": "94", "shortCiteRegEx": null, "year": 2001}, {"title": "On classes of functions for which no free lunch results hold", "author": ["C. Igel", "M. Toussaint"], "venue": "Inf. Process. Lett., vol. 86, no. 6, pp. 317 \u2013 321, 2003.", "citeRegEx": "95", "shortCiteRegEx": null, "year": 2003}, {"title": "Optimization by simulated annealing", "author": ["S. Kirkpatrick", "C.D. Gelatt", "M.P. Vecchi"], "venue": "Sci., vol. 220, no. 4598, pp. 671\u2013680, May 1983.", "citeRegEx": "96", "shortCiteRegEx": null, "year": 1983}, {"title": "Tabu search-part I", "author": ["F. Glover"], "venue": "INFORMS J. Comput., vol. 1, no. 3, 1989.", "citeRegEx": "97", "shortCiteRegEx": null, "year": 1989}, {"title": "Variable neighborhood search", "author": ["N. Mladenovi\u0107", "P. Hansen"], "venue": "Comput. Oper. Res., vol. 24, no. 11, pp. 1097\u20131100, Nov 1997.", "citeRegEx": "98", "shortCiteRegEx": null, "year": 1997}, {"title": "Greedy randomized adaptive search procedures", "author": ["T.A. Feo", "M.G. Resende"], "venue": "J. Glob. Optim., vol. 6, no. 2, pp. 109\u2013133, Jun 1995.", "citeRegEx": "99", "shortCiteRegEx": null, "year": 1995}, {"title": "Equation of state calculations by fast computing machines", "author": ["N. Metropolis", "A.W. Rosenbluth", "M.N. Rosenbluth", "A.H. Teller", "E. Teller"], "venue": "J. Chem. Phys., vol. 21, no. 6, pp. 1087\u20131092, 1953.", "citeRegEx": "100", "shortCiteRegEx": null, "year": 1953}, {"title": "Thermodynamical approach to the traveling salesman problem: an efficient simulation algorithm", "author": ["V. \u010cern\u1ef3"], "venue": "J. Optim. Theory Appl., vol. 45, no. 1, pp. 41\u201351, Jan 1985.", "citeRegEx": "101", "shortCiteRegEx": null, "year": 1985}, {"title": "Evolutionary Computation: The Fossil Record", "author": ["D.B. Fogel"], "venue": null, "citeRegEx": "102", "shortCiteRegEx": "102", "year": 1998}, {"title": "Collective Phenomena in Evolutionary Systems. Universit\u00e4t Dortmund", "author": ["H.-P. Schwefel"], "venue": "Abteilung Informatik,", "citeRegEx": "103", "shortCiteRegEx": "103", "year": 1987}, {"title": "Differential evolution\u2013a simple and efficient heuristic for global optimization over continuous spaces", "author": ["R. Storn", "K. Price"], "venue": "J. Glob. Optim., vol. 11, no. 4, pp. 341\u2013359, Dec 1997.", "citeRegEx": "105", "shortCiteRegEx": null, "year": 1997}, {"title": "A new optimizer using particle swarm theory", "author": ["R. Eberhart", "J. Kennedy"], "venue": "Proc. 6th Int. Symp. Micro Mach. Human Sci., 1995. MHS \u201995, 1995, pp. 39\u201343.", "citeRegEx": "106", "shortCiteRegEx": null, "year": 1995}, {"title": "Ant system: optimization by a colony of cooperating agents", "author": ["M. Dorigo", "V. Maniezzo", "A. Colorni"], "venue": "IEEE Trans. Syst., Man, Cybern., vol. 26, no. 1, pp. 29 \u2013 41, Feb 1996.", "citeRegEx": "107", "shortCiteRegEx": null, "year": 1996}, {"title": "An idea based on honey bee swarm for numerical optimization", "author": ["D. Karaboga"], "venue": "Computer Engineering Department, Erciyes University, Tech. Rep. TR06, 2005.", "citeRegEx": "108", "shortCiteRegEx": null, "year": 2005}, {"title": "Biomimicry of bacterial foraging for distributed optimization and control", "author": ["K.M. Passino"], "venue": "IEEE Control Syst., vol. 22, no. 3, pp. 52\u201367, Jan 2002.", "citeRegEx": "109", "shortCiteRegEx": null, "year": 2002}, {"title": "A modified particle swarm optimizer", "author": ["Y. Shi", "R. Eberhart"], "venue": "The 1998 IEEE Int. Conf. Evol. Comput. Proc., IEEE World Congr. Comput. Intell., 1998, pp. 69\u201373.", "citeRegEx": "111", "shortCiteRegEx": null, "year": 1998}, {"title": "The self-organizing exploratory pattern of the argentine ant", "author": ["J.-L. Deneubourg", "S. Aron", "S. Goss"], "venue": "J. Insect Behav., vol. 3, pp. 159\u2013169, Mar 1990. 41", "citeRegEx": "112", "shortCiteRegEx": null, "year": 1990}, {"title": "Grey wolf optimizer", "author": ["S. Mirjalili", "S.M. Mirjalili", "A. Lewis"], "venue": "Adv. Eng. Softw., vol. 69, pp. 46\u201361, 2014.", "citeRegEx": "113", "shortCiteRegEx": null, "year": 2014}, {"title": "Flower pollination algorithm for global optimization", "author": ["X.-S. Yang"], "venue": "Unconventional computation and natural computation. Springer, 2012, pp. 240\u2013249.", "citeRegEx": "114", "shortCiteRegEx": null, "year": 2012}, {"title": "Cuckoo search via l\u00e9vy flights", "author": ["X.-S. Yang", "S. Deb"], "venue": "World Congr. on Nature and Biologically Inspired Comput., 2009. NaBIC 2009, 2009, pp. 210\u2013214.", "citeRegEx": "115", "shortCiteRegEx": null, "year": 2009}, {"title": "Firefly algorithm, stochastic test functions and design optimisation", "author": ["X.-S. Yang"], "venue": "Int. J. Bio-Inspired Comput., vol. 2, no. 2, pp. 78\u201384, 2010.", "citeRegEx": "116", "shortCiteRegEx": null, "year": 2010}, {"title": "A new heuristic optimization algorithm: harmony search", "author": ["Z.W. Geem", "J.H. Kim", "G. Loganathan"], "venue": "SIMULATION, vol. 76, no. 2, pp. 60\u201368, Feb 2001.", "citeRegEx": "117", "shortCiteRegEx": null, "year": 2001}, {"title": "Central force optimization: a new metaheuristic with applications in applied electromagnetics", "author": ["R.A. Formato"], "venue": "Progress In Electromagnetics Research, vol. 77, pp. 425\u2013491, Jan 2007.", "citeRegEx": "118", "shortCiteRegEx": null, "year": 2007}, {"title": "Gsa: a gravitational search algorithm", "author": ["E. Rashedi", "H. Nezamabadi-pour", "S. Saryazdi"], "venue": "Inform. Sci., vol. 179, no. 13, pp. 2232 \u2013 2248, Jun 2009.", "citeRegEx": "119", "shortCiteRegEx": null, "year": 2009}, {"title": "A brief review of nature-inspired algorithms for optimization", "author": ["I. Fister Jr", "X.-S. Yang", "I. Fister", "J. Brest", "D. Fister"], "venue": "Elektrotehn\u01d0ski vestnik (English Ed.), vol. 80, no. 3, Jul 2013.", "citeRegEx": "120", "shortCiteRegEx": null, "year": 2013}, {"title": "A rigorous analysis of the harmony search algorithm: How the research community can be misled by a \u201dnovel\u201d methodology", "author": ["D. Weyland"], "venue": "Int. J. Appl. Metaheuristic Comput., vol. 1, no. 2, pp. 50\u201360, 2010.", "citeRegEx": "121", "shortCiteRegEx": null, "year": 2010}, {"title": "Metaheuristicsthe metaphor exposed", "author": ["K. S\u00f6rensen"], "venue": "Int. Trans. Oper. Res., vol. 22, no. 1, pp. 3\u201318, 2015.", "citeRegEx": "122", "shortCiteRegEx": null, "year": 2015}, {"title": "On evolution, search, optimization, genetic algorithms and martial arts: Towards memetic algorithms", "author": ["P. Moscato"], "venue": "Caltech, Tech. Rep. Caltech Concurrent Computation Program, C3P Report, 1989.", "citeRegEx": "123", "shortCiteRegEx": null, "year": 1989}, {"title": "Degree of population diversity-a perspective on premature convergence in genetic algorithms and its markov chain analysis", "author": ["Y. Leung", "Y. Gao", "Z.-B. Xu"], "venue": "IEEE Trans. on Neural Netw., vol. 8, no. 5, pp. 1165\u20131176, 1997.", "citeRegEx": "124", "shortCiteRegEx": null, "year": 1997}, {"title": "The particle swarm optimization algorithm: convergence analysis and parameter selection", "author": ["I.C. Trelea"], "venue": "Inf. process. lett., vol. 85, no. 6, pp. 317\u2013325, 2003.", "citeRegEx": "125", "shortCiteRegEx": null, "year": 2003}, {"title": "Clever algorithms: nature-inspired programming recipes", "author": ["J. Brownlee"], "venue": "Jason Brownlee,", "citeRegEx": "126", "shortCiteRegEx": "126", "year": 2011}, {"title": "A hybrid of back propagation neural network and genetic algorithm for optimization of injection molding process parameters", "author": ["F. Yin", "H. Mao", "L. Hua"], "venue": "Mater. Des., vol. 32, no. 6, pp. 3457\u20133464, Jun 2011.", "citeRegEx": "127", "shortCiteRegEx": null, "year": 2011}, {"title": "A hybrid algorithm for artificial neural network training", "author": ["M. Yaghini", "M.M. Khoshraftar", "M. Fallahi"], "venue": "Eng. Appl. Artif. Intell., vol. 26, no. 1, pp. 293\u2013301, Jan 2013.", "citeRegEx": "128", "shortCiteRegEx": null, "year": 2013}, {"title": "A hybrid particle swarm optimization and backpropagation algorithm for feedforward neural network training", "author": ["J.-R. Zhang", "J. Zhang", "T.-M. Lok", "M.R. Lyu"], "venue": "Appl. Math. Comput., vol. 185, no. 2, pp. 1026 \u2013 1037, Feb 2007.", "citeRegEx": "129", "shortCiteRegEx": null, "year": 2007}, {"title": "Hybrid artificial bee colony algorithm for neural network training", "author": ["C. Ozturk", "D. Karaboga"], "venue": "IEEE Congr. Evol. Comput. (CEC), 2011, 2011, pp. 84\u201388. 42", "citeRegEx": "130", "shortCiteRegEx": null, "year": 2011}, {"title": "A hybrid of genetic algorithm and particle swarm optimization for recurrent network design", "author": ["C.-F. Juang"], "venue": "IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 34, no. 2, pp. 997\u20131006, Apr 2004.", "citeRegEx": "131", "shortCiteRegEx": null, "year": 2004}, {"title": "A review of evolutionary artificial neural networks", "author": ["X. Yao"], "venue": "Int. J. Intell. Syst., vol. 8, no. 4, pp. 539\u2013567, 1993.", "citeRegEx": "132", "shortCiteRegEx": null, "year": 1993}, {"title": "A survey on optimization metaheuristics", "author": ["I. Boussaid", "J. Lepagnot", "P. Siarry"], "venue": "Inform. Sci., vol. 237, pp. 82 \u2013 117, Jul 2013.", "citeRegEx": "133", "shortCiteRegEx": null, "year": 2013}, {"title": "Towards designing artificial neural networks by evolution", "author": ["X. Yao", "Y. Liu"], "venue": "Appl. Math. Comput., vol. 91, no. 1, pp. 83 \u2013 90, 1998.", "citeRegEx": "134", "shortCiteRegEx": null, "year": 1998}, {"title": "Teaching feed-forward neural networks by simulated annealing", "author": ["J. Engel"], "venue": "Complex Syst., vol. 2, no. 6, pp. 641\u2013648, 1988.", "citeRegEx": "135", "shortCiteRegEx": null, "year": 1988}, {"title": "Global optimization for neural network training", "author": ["Y. Shang", "B. Wah"], "venue": "Comput., vol. 29, no. 3, pp. 45\u201354, Mar 1996.", "citeRegEx": "136", "shortCiteRegEx": null, "year": 1996}, {"title": "Beyond back propagation: using simulated annealing for training neural networks", "author": ["R.S. Sexton", "R.E. Dorsey", "J.D. Johnson"], "venue": "J. Organ. End User Comput., vol. 11, no. 3, pp. 3\u201310, Jul 1999.", "citeRegEx": "137", "shortCiteRegEx": null, "year": 1999}, {"title": "ANNSA: a hybrid artificial neural network/simulated annealing algorithm for optimal control problems", "author": ["D. Sarkar", "J.M. Modak"], "venue": "Chem. Eng. Sci., vol. 58, no. 14, pp. 3131 \u2013 3142, Jul 2003.", "citeRegEx": "138", "shortCiteRegEx": null, "year": 2003}, {"title": "Tabu learning: a neural network search method for solving nonconvex optimization problems", "author": ["D. Beyer", "R. Ogier"], "venue": "Int. Jt. Conf. Neural Netw., 1991., IJCNN, vol. 2, 1991, pp. 953\u2013961.", "citeRegEx": "139", "shortCiteRegEx": null, "year": 1991}, {"title": "Training neural nets with the reactive tabu search", "author": ["R. Battiti", "G. Tecchiolli"], "venue": "IEEE Trans. Neural Netw., vol. 6, no. 5, pp. 1185\u20131200, 1995.", "citeRegEx": "140", "shortCiteRegEx": null, "year": 1995}, {"title": "Global optimization for artificial neural networks: a tabu search application", "author": ["R.S. Sexton", "B. Alidaee", "R.E. Dorsey", "J.D. Johnson"], "venue": "Eur. J. Oper. Res., vol. 106, no. 2, pp. 570\u2013584, Apr 1998.", "citeRegEx": "141", "shortCiteRegEx": null, "year": 1998}, {"title": "A tabu based neural network learning algorithm", "author": ["J. Ye", "J. Qiao", "M. ai Li", "X. Ruan"], "venue": "Neurocomputing, vol. 70, no. 4, pp. 875 \u2013 882, Jan 2007.", "citeRegEx": "142", "shortCiteRegEx": null, "year": 2007}, {"title": "The GENITOR algorithm and selection pressure: why rank-based allocation of reproductive trials is best", "author": ["D. Whitley"], "venue": "Proc. 3rd Int. Conf. Genetic Algorithms, 1989, pp. 116\u2013121.", "citeRegEx": "143", "shortCiteRegEx": null, "year": 1989}, {"title": "Genetic algorithms and neural networks: optimizing connections and connectivity", "author": ["D. Whitley", "T. Starkweather", "C. Bogart"], "venue": "Parallel Comput., vol. 14, no. 3, pp. 347 \u2013 361, Aug 1990.", "citeRegEx": "144", "shortCiteRegEx": null, "year": 1990}, {"title": "Learning neural network weights using genetic algorithms-improving performance by search-space reduction", "author": ["M. Srinivas", "L. Patnaik"], "venue": "Int. Jt. Conf. Neural Netw., 1991. IJCNN, 1991, pp. 2331\u20132336.", "citeRegEx": "145", "shortCiteRegEx": null, "year": 1991}, {"title": "Evolving networks: using the genetic algorithm with connectionist learning", "author": ["R.K. Belew", "J. Mcinerney", "N.N. Schraudolph"], "venue": "University of California, San Diego, Tech. Rep. CS90\u2013174, 1990.", "citeRegEx": "146", "shortCiteRegEx": null, "year": 1990}, {"title": "Training feedforward neural networks using genetic algorithms", "author": ["D.J. Montana", "L. Davis"], "venue": "Proc. 11th Int. Jt. Conf. Artif. Intell., vol. 1, 1989, pp. 762\u2013767.", "citeRegEx": "147", "shortCiteRegEx": null, "year": 1989}, {"title": "Evolving neural networks", "author": ["D.B. Fogel", "L.J. Fogel", "V. Porto"], "venue": "Biol. Cybern., vol. 63, no. 6, pp. 487\u2013493, Oct 1990.", "citeRegEx": "148", "shortCiteRegEx": null, "year": 1990}, {"title": "Creating artificial neural networks that generalize", "author": ["J. Sietsma", "R.J. Dow"], "venue": "Neural Netw., vol. 4, no. 1, pp. 67\u201379, 1991. 43", "citeRegEx": "149", "shortCiteRegEx": null, "year": 1991}, {"title": "Evidence of hyperplanes in the genetic learning of neural networks", "author": ["F. Menczer", "D. Parisi"], "venue": "Biol. Cybern., vol. 66, no. 3, pp. 283\u2013289, Jan 1992.", "citeRegEx": "150", "shortCiteRegEx": null, "year": 1992}, {"title": "Evolving neural network using real coded genetic algorithm for permeability estimation of the reservoir", "author": ["R. Irani", "R. Nasimi"], "venue": "Expert Syst. Appl., vol. 38, no. 8, pp. 9862\u20139866, Aug 2011.", "citeRegEx": "151", "shortCiteRegEx": null, "year": 2011}, {"title": "A modified genetic algorithm for fast training neural networks", "author": ["D. Kim", "H. Kim", "D. Chung"], "venue": "Advances in Neural Networks ISNN 2005, ser. Lecture Notes in Computer Science, J. Wang, X. Liao, and Z. Yi, Eds. Springer, 2005, vol. 3496, pp. 660\u2013665.", "citeRegEx": "152", "shortCiteRegEx": null, "year": 2005}, {"title": "Empirical studies on the speed of convergence of neural network training using genetic algorithms", "author": ["H. Kitano"], "venue": "Proc. 8th Nat. Conf. Artif. Intell. - Vol. 2, vol. 2, 1990, pp. 789\u2013795.", "citeRegEx": "153", "shortCiteRegEx": null, "year": 1990}, {"title": "Toward global optimization of neural networks: a comparison of the genetic algorithm and backpropagation", "author": ["R.S. Sexton", "R.E. Dorsey", "J.D. Johnson"], "venue": "Decision Support Syst., vol. 22, no. 2, pp. 171 \u2013 185, Feb 1998.", "citeRegEx": "154", "shortCiteRegEx": null, "year": 1998}, {"title": "An optimizing bp neural network algorithm based on genetic algorithm", "author": ["S. Ding", "C. Su", "J. Yu"], "venue": "Artif. Intell. Rev., vol. 36, no. 2, pp. 153\u2013162, Aug 2011.", "citeRegEx": "155", "shortCiteRegEx": null, "year": 2011}, {"title": "Genetic algorithm-neural network (GANN): a study of neural network activation functions and depth of genetic algorithm search applied to feature selection", "author": ["D.L. Tong", "R. Mintram"], "venue": "Int. J. Mach. Learn. Cybern., vol. 1, no. 1-4, pp. 75\u201387, Sep 2010.", "citeRegEx": "156", "shortCiteRegEx": null, "year": 2010}, {"title": "Differential evolution: a survey of the state-of-the-art", "author": ["S. Das", "P.N. Suganthan"], "venue": "IEEE Trans. Evol. Comput., vol. 15, no. 1, pp. 4\u201331, Oct 2011.", "citeRegEx": "157", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning and evolution in neural networks", "author": ["S. Nolfi", "D. Parisi", "J.L. Elman"], "venue": "Adapt. Behav., vol. 3, no. 1, pp. 5\u201328, Jun 1994.", "citeRegEx": "158", "shortCiteRegEx": null, "year": 1994}, {"title": "Differential evolution training algorithm for feed-forward neural networks", "author": ["J. Ilonen", "J.-K. Kamarainen", "J. Lampinen"], "venue": "Neural Process. Lett., vol. 17, no. 1, pp. 93\u2013105, Feb 2003.", "citeRegEx": "159", "shortCiteRegEx": null, "year": 2003}, {"title": "Application of an adaptive differential evolution algorithm with multiple trial vectors to artificial neural network training", "author": ["A. Slowik"], "venue": "IEEE Trans. Ind. Electron., vol. 58, no. 8, pp. 3160\u20133167, Aug 2011.", "citeRegEx": "160", "shortCiteRegEx": null, "year": 2011}, {"title": "Global optimization algorithms for training product unit neural networks", "author": ["A. Ismail", "A. Engelbrecht"], "venue": "Proc. IEEE-INNS-ENNS Int. Jt. Conf. Neural Netw., 2000. IJCNN 2000,, vol. 1, 2000, pp. 132\u2013137.", "citeRegEx": "161", "shortCiteRegEx": null, "year": 2000}, {"title": "A hybrid particle swarm optimization\u2013backpropagation algorithm for feedforward neural network training", "author": ["J.-R. Zhang", "J. Zhang", "T.-M. Lok", "M.R. Lyu"], "venue": "Appl. Math. Comput., vol. 185, no. 2, pp. 1026\u20131037, 2007.", "citeRegEx": "162", "shortCiteRegEx": null, "year": 2007}, {"title": "Training product unit networks using cooperative particle swarm optimisers", "author": ["F. Van den Bergh", "A. Engelbrecht"], "venue": "Proc. 2001. Int. Jt. Conf. Neural Netw., vol. 1, 2001, pp. 126\u2013131.", "citeRegEx": "163", "shortCiteRegEx": null, "year": 2001}, {"title": "A cooperative approach to particle swarm optimization", "author": ["F. Van den Bergh", "A.P. Engelbrecht"], "venue": "IEEE Trans. Evol. Comput., vol. 8, no. 3, pp. 225\u2013239, 2004.", "citeRegEx": "164", "shortCiteRegEx": null, "year": 2004}, {"title": "Training feedforward neural networks using multi-phase particle swarm optimization", "author": ["B. Al-kazemi", "C. Mohan"], "venue": "Proc. 9th Int. Conf. Neural Inform. Process., 2002. ICONIP \u201902, vol. 5, 2002, pp. 2615\u20132619.", "citeRegEx": "165", "shortCiteRegEx": null, "year": 2002}, {"title": "A hybrid of cooperative particle swarm optimization and cultural algorithm for neural fuzzy networks and its prediction applications", "author": ["C.-J. Lin", "C.-H. Chen", "C.-T. Lin"], "venue": "IEEE Trans. Syst., Man, Cybern. C, Appl. Rev., vol. 39, no. 1, pp. 55\u201368, Dec 2009. 44", "citeRegEx": "166", "shortCiteRegEx": null, "year": 2009}, {"title": "Hierarchical particle swarm optimization for the design of beta basis function neural network", "author": ["H. Dhahri", "A. Alimi", "A. Abraham"], "venue": "Intelligent Informatics, ser. Advances in Intelligent Systems and Computing, A. Abraham and S. M. Thampi, Eds. Springer, 2013, vol. 182, pp. 193\u2013205.", "citeRegEx": "167", "shortCiteRegEx": null, "year": 2013}, {"title": "Ant colony optimization for continuous domains", "author": ["K. Socha", "M. Dorigo"], "venue": "Eur. J. Oper. Res., vol. 185, no. 3, pp. 1155 \u2013 1173, Mar 2008.", "citeRegEx": "168", "shortCiteRegEx": null, "year": 2008}, {"title": "An ant colony optimization algorithm for continuous optimization: application to feed-forward neural network training", "author": ["K. Socha", "C. Blum"], "venue": "Neural Comput. Appl., vol. 16, no. 3, pp. 235\u2013247, May 2007.", "citeRegEx": "169", "shortCiteRegEx": null, "year": 2007}, {"title": "An evolving neural network using an ant colony algorithm for a permeability estimation of the reservoir", "author": ["R. Irani", "R. Nasimi"], "venue": "Pet. Sci. Technol., vol. 30, no. 4, pp. 375\u2013384, Feb 2012.", "citeRegEx": "170", "shortCiteRegEx": null, "year": 2012}, {"title": "An ant colony optimisation and nelder\u2013mead simplex hybrid algorithm for training neural networks: an application to bankruptcy prediction in banks", "author": ["N. Sharma", "N. Arun", "V. Ravi"], "venue": "Int. J. Inform. Decision Sci., vol. 5, no. 2, pp. 188\u2013203, 2013.", "citeRegEx": "171", "shortCiteRegEx": null, "year": 2013}, {"title": "Artificial bee colony (ABC) optimization algorithm for training feed-forward neural networks", "author": ["D. Karaboga", "B. Akay", "C. Ozturk"], "venue": "Modeling Decisions for Artificial Intelligence, ser. Lecture Notes in Computer Science, V. Torra, Y. Narukawa, and Y. Yoshida, Eds. Springer, 2007, vol. 4617, pp. 318\u2013329.", "citeRegEx": "172", "shortCiteRegEx": null, "year": 2007}, {"title": "Artificial neural network synthesis by means of artificial bee colony (ABC) algorithm", "author": ["B.A. Garro", "H. Sossa", "R.A. V\u00e1zquez"], "venue": "IEEE Congr. Evol. Comput. (CEC), 2011, 2011, pp. 331\u2013338.", "citeRegEx": "173", "shortCiteRegEx": null, "year": 2011}, {"title": "Training a feed-forward neural network using artificial bee colony with back-propagation algorithm", "author": ["P.P. Sarangi", "A. Sahu", "M. Panda"], "venue": "Intelligent Computing, Networking, and Informatics. Springer, 2014, pp. 511\u2013519.", "citeRegEx": "174", "shortCiteRegEx": null, "year": 2014}, {"title": "Harmony search based supervised training of artificial neural networks", "author": ["A. Kattan", "R. Abdullah", "R. Salam"], "venue": "2010 Int. Conf. Int. Syst., Model. and Simulation (ISMS),, 2010, pp. 105\u2013110.", "citeRegEx": "175", "shortCiteRegEx": null, "year": 2010}, {"title": "Training neural networks with harmony search algorithms for classification problems", "author": ["S. Kulluk", "L. Ozbakir", "A. Baykasoglu"], "venue": "Eng. Appl. Artif. Intell., vol. 25, no. 1, pp. 11 \u2013 19, Feb 2012.", "citeRegEx": "176", "shortCiteRegEx": null, "year": 2012}, {"title": "An improved harmony search algorithm for solving optimization problems", "author": ["M. Mahdavi", "M. Fesanghary", "E. Damangir"], "venue": "Appl. Math. Comput., vol. 188, no. 2, pp. 1567 \u2013 1579, May 2007.", "citeRegEx": "177", "shortCiteRegEx": null, "year": 2007}, {"title": "A self-adaptive global best harmony search algorithm for continuous optimization problems", "author": ["Q.-K. Pan", "P. Suganthan", "M.F. Tasgetiren", "J. Liang"], "venue": "Appl. Math. Comput., vol. 216, no. 3, pp. 830 \u2013 848, Apr 2010.", "citeRegEx": "178", "shortCiteRegEx": null, "year": 2010}, {"title": "Firefly meta-heuristic algorithm for training the radial basis function network for data classification and disease diagnosis", "author": ["M.-H. Horng", "M.-C. Lee", "R.-J. Liou", "Y.-X. Lee"], "venue": "Theory and New Applications of Swarm Intelligence, R. Parpinelli and H. S. Lopes, Eds. InTech, 2012.", "citeRegEx": "179", "shortCiteRegEx": null, "year": 2012}, {"title": "Training spiking neural models using cuckoo search algorithm", "author": ["R.A. V\u00e1zquez"], "venue": "IEEE Congr. Evol. Comput. (CEC), 2011, 2011, pp. 679\u2013686.", "citeRegEx": "180", "shortCiteRegEx": null, "year": 2011}, {"title": "A hybrid neural network and gravitational search algorithm (HNNGSA) method to solve well known wessinger\u2019s equation", "author": ["M. Ghalambaz", "A. Noghrehabadi", "M. Behrang", "E. Assareh", "A. Ghanbarzadeh", "N. Hedayat"], "venue": "World Acad. Sci. Eng. Technol., vol. 5, pp. 803\u2013807, Jan 2011.", "citeRegEx": "181", "shortCiteRegEx": null, "year": 2011}, {"title": "Application of bacterial foraging technique trained artificial and wavelet neural networks in load forecasting", "author": ["M. Ulagammai", "P. Venkatesh", "P. Kannan", "N.P. Padhy"], "venue": "Neurocomputing, vol. 70, no. 16, pp. 2659 \u2013 2667, Oct 2007. 45", "citeRegEx": "182", "shortCiteRegEx": null, "year": 2007}, {"title": "Bacterial foraging optimization based neural network for short-term load forecasting", "author": ["Y. Zhang", "L. Wu", "S. Wang"], "venue": "J. Comput. Inform. Syst., vol. 6, no. 7, pp. 2099\u20132105, Jan 2010.", "citeRegEx": "183", "shortCiteRegEx": null, "year": 2010}, {"title": "Training neural networks using central force optimization and particle swarm optimization: Insights and comparisons", "author": ["R.C.G. II", "L. Wang", "M. Alam"], "venue": "Expert Syst. Appl., vol. 39, no. 1, pp. 555 \u2013 563, Dec 2012.", "citeRegEx": "184", "shortCiteRegEx": null, "year": 2012}, {"title": "Analysis of a nature inspired firefly algorithm based back-propagation neural network training", "author": ["S. Nandy", "P.P. Sarkar", "A. Das"], "venue": "Int. J. Comput. Appl., vol. 43, no. 2, pp. 8 \u2013 16, Apr 2012.", "citeRegEx": "185", "shortCiteRegEx": null, "year": 2012}, {"title": "Metaheuristic Procedures for Training", "author": ["E. Alba", "R. Marti"], "venue": "Neural Networks. Springer,", "citeRegEx": "186", "shortCiteRegEx": "186", "year": 2006}, {"title": "Estimation of Distribution Algorithms: a New Tool for Evolutionary Computation", "author": ["P. Larra\u00f1aga", "J.A. Lozano"], "venue": null, "citeRegEx": "187", "shortCiteRegEx": "187", "year": 2002}, {"title": "Metaheuristics for the feedforward artificial neural network (ann) architecture optimization problem", "author": ["A.R. Carvalho", "F.M. Ramos", "A.A. Chaves"], "venue": "Neural Comput. Appl., vol. 20, no. 8, pp. 1273\u20131284, Dec 2011.", "citeRegEx": "188", "shortCiteRegEx": null, "year": 2011}, {"title": "Meta-learning approach to neural network optimization", "author": ["P. Kord\u0301\u0131k", "J. Kout\u0144\u0131k", "J. Drchal", "O. Kov\u00e1\u0159\u0301\u0131k", "M. \u010cepek", "M. \u0160norek"], "venue": "Neural Netw., vol. 23, no. 4, pp. 568\u2013582, May 2010.", "citeRegEx": "189", "shortCiteRegEx": null, "year": 2010}, {"title": "A comparison of BA, GA, PSO, BP and LM for training feed forward neural networks in e-learning context", "author": ["K. Khan", "A. Sahai"], "venue": "Int. J. Intell. Syst. Appl., vol. 4, no. 7, p. 23, 2012.", "citeRegEx": "190", "shortCiteRegEx": null, "year": 2012}, {"title": "An improved PSO-based ANN with simulated annealing technique", "author": ["Y. Da", "G. Xiurun"], "venue": "Neurocomputing, vol. 63, no. 0, pp. 527 \u2013 533, Jan 2005.", "citeRegEx": "191", "shortCiteRegEx": null, "year": 2005}, {"title": "Reservoir permeability prediction by neural networks combined with hybrid genetic algorithm and particle swarm optimization", "author": ["M. Ali Ahmadi", "S. Zendehboudi", "A. Lohi", "A. Elkamel", "I. Chatzis"], "venue": "Geophys. Prospect., vol. 61, no. 3, pp. 582\u2013598, May 2013.", "citeRegEx": "192", "shortCiteRegEx": null, "year": 2013}, {"title": "Time series forecasting by evolving artificial neural networks with genetic algorithms, differential evolution and estimation of distribution algorithm", "author": ["J.P. Donate", "X. Li", "G.G. S\u00e1nchez", "A.S. de Miguel"], "venue": "Neural Comput. Appl., vol. 22, no. 1, pp. 11\u201320, Jan 2013.", "citeRegEx": "193", "shortCiteRegEx": null, "year": 2013}, {"title": "Training feedforward neural networks using hybrid particle swarm optimization and gravitational search algorithm", "author": ["S. Mirjalili", "S.Z. Mohd Hashim", "H. Moradian Sardroudi"], "venue": "Appl. Math. Comput., vol. 218, no. 22, pp. 11 125\u201311 137, Jul 2012.", "citeRegEx": "194", "shortCiteRegEx": null, "year": 2012}, {"title": "MCPSO: a multi-swarm cooperative particle swarm optimizer", "author": ["B. Niu", "Y. Zhu", "X. He", "H. Wu"], "venue": "Appl. Math. Comput., vol. 185, no. 2, pp. 1050 \u2013 1062, Feb 2007.", "citeRegEx": "195", "shortCiteRegEx": null, "year": 2007}, {"title": "The UPSTART algorithm: a method for constructing and training feedforward neural networks", "author": ["M. Frean"], "venue": "Neural Comput., vol. 2, no. 2, pp. 198\u2013209, Apr 1990.", "citeRegEx": "196", "shortCiteRegEx": null, "year": 1990}, {"title": "Genetic evolution of the topology and weight distribution of neural networks", "author": ["V. Maniezzo"], "venue": "IEEE Trans. Neural Netw., vol. 5, no. 1, pp. 39\u201353, Jan 1994.", "citeRegEx": "197", "shortCiteRegEx": null, "year": 1994}, {"title": "Architecture selection for networks trained with extreme learning machine using localized generalization error model", "author": ["W. Xi-Zhao", "S. Qing-Yan", "M. Qing", "Z. Jun-Hai"], "venue": "Neurocomputing, vol. 102, pp. 3\u20139, Feb 2013.", "citeRegEx": "198", "shortCiteRegEx": null, "year": 2013}, {"title": "Optimizing neural networks using faster, more accurate genetic search", "author": ["D. Whitley", "T. Hanson"], "venue": "Proc. 3rd Int. Conf. Genetic Algorithms, 1989, pp. 391\u2013396. 46", "citeRegEx": "199", "shortCiteRegEx": null, "year": 1989}, {"title": "Using genetic search to exploit the emergent behavior of neural networks", "author": ["J.D. Schaffer", "R.A. Caruana", "L.J. Eshelman"], "venue": "Physica D, vol. 42, no. 1, pp. 244\u2013248, Jun 1990.", "citeRegEx": "200", "shortCiteRegEx": null, "year": 1990}, {"title": "Towards the genetic synthesis of neural network", "author": ["S.A. Harp", "T. Samad", "A. Guha"], "venue": "Proc. 3rd Int. Conf. Genetic Algorithms, 1989, pp. 360\u2013369.", "citeRegEx": "201", "shortCiteRegEx": null, "year": 1989}, {"title": "Scaling, machine learning, and genetic neural nets", "author": ["E. Mjolsness", "D.H. Sharp", "B.K. Alpert"], "venue": "Adv. Appl. Math., vol. 10, no. 2, pp. 137\u2013163, Jun 1989.", "citeRegEx": "202", "shortCiteRegEx": null, "year": 1989}, {"title": "Designing neural networks using genetic algorithms with graph generation system", "author": ["H. Kitano"], "venue": "Complex Syst., vol. 4, no. 4, pp. 461\u2013476, 1990.", "citeRegEx": "203", "shortCiteRegEx": null, "year": 1990}, {"title": "A comparison of matrix rewriting versus direct encoding for evolving neural networks", "author": ["A.A. Siddiqi", "S.M. Lucas"], "venue": "The 1998 IEEE Int. Conf. Evol. Comput. Proc., 1998. IEEE World Congr. Comput. Intell., 1998, pp. 392\u2013397.", "citeRegEx": "204", "shortCiteRegEx": null, "year": 1998}, {"title": "Fractally configured neural networks", "author": ["J.W. Merrill", "R.F. Port"], "venue": "Neural Netw., vol. 4, no. 1, pp. 53\u201360, 1991.", "citeRegEx": "205", "shortCiteRegEx": null, "year": 1991}, {"title": "A constructive algorithm for the training of a multilayer perceptron based on the genetic algorithm", "author": ["H.C. Andersen", "A.C. Tsoi"], "venue": "Complex Syst., vol. 7, no. 4, pp. 249\u2013268, 1993.", "citeRegEx": "206", "shortCiteRegEx": null, "year": 1993}, {"title": "Evolving artificial neural network structure using grammar encoding and colonial competitive algorithm", "author": ["M. Tayefeh Mahmoudi", "F. Taghiyareh", "N. Forouzideh", "C. Lucas"], "venue": "Neural Comput. Appl., vol. 22, no. 1, pp. 1\u201316, May 2013.", "citeRegEx": "207", "shortCiteRegEx": null, "year": 2013}, {"title": "An optimization methodology for neural network weights and architectures", "author": ["T. Ludermir", "A. Yamazaki", "C. Zanchettin"], "venue": "IEEE Trans. Neural Netw., vol. 17, no. 6, pp. 1452\u20131459, Nov 2006.", "citeRegEx": "208", "shortCiteRegEx": null, "year": 2006}, {"title": "Particle swarm optimization of neural network architectures andweights", "author": ["M. Carvalho", "T. Ludermir"], "venue": "7th Int. Conf. Hybrid Intell. Syst., 2007. HIS 2007, 2007, pp. 336\u2013339.", "citeRegEx": "209", "shortCiteRegEx": null, "year": 2007}, {"title": "Hybrid taguchi-genetic algorithm for global numerical optimization", "author": ["J.-T. Tsai", "T.-K. Liu", "J.-H. Chou"], "venue": "IEEE Trans. Evol. Comput., vol. 8, no. 4, pp. 365\u2013377, Aug 2004.", "citeRegEx": "210", "shortCiteRegEx": null, "year": 2004}, {"title": "Tuning the structure and parameters of a neural network by using hybrid taguchi-genetic algorithm", "author": ["J.-T. Tsai", "J.-H. Chou", "T.-K. Liu"], "venue": "IEEE Trans. Neural Netw., vol. 17, no. 1, pp. 69\u201380, Jan 2006.", "citeRegEx": "211", "shortCiteRegEx": null, "year": 2006}, {"title": "Evolutionary artificial neural networks by multidimensional particle swarm optimization", "author": ["S. Kiranyaz", "T. Ince", "A. Yildirim", "M. Gabbouj"], "venue": "Neural Netw., vol. 22, no. 10, pp. 1448 \u2013 1462, Dec 2009.", "citeRegEx": "212", "shortCiteRegEx": null, "year": 2009}, {"title": "Fast learning neural networks using cartesian genetic programming", "author": ["M.M. Khan", "A.M. Ahmad", "G.M. Khan", "J.F. Miller"], "venue": "Neurocomputing, vol. 121, pp. 274 \u2013 289, Dec 2013.", "citeRegEx": "213", "shortCiteRegEx": null, "year": 2013}, {"title": "Genetic generation of both the weights and architecture for a neural network", "author": ["J.R. Koza", "J.P. Rice"], "venue": "Int. Jt. Conf. Neural Netw., 1991., IJCNN, vol. 2, 1991, pp. 397\u2013404.", "citeRegEx": "214", "shortCiteRegEx": null, "year": 1991}, {"title": "Neural network construction and training using grammatical evolution", "author": ["I. Tsoulos", "D. Gavrilis", "E. Glavas"], "venue": "Neurocomputing, vol. 72, no. 1, pp. 269 \u2013 277, Dec 2008.", "citeRegEx": "215", "shortCiteRegEx": null, "year": 2008}, {"title": "Deep learning in neural networks: An overview", "author": ["J. Schmidhuber"], "venue": "Neural Netw., vol. 61, pp. 85\u2013117, 2015.", "citeRegEx": "216", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep learning", "author": ["Y. LeCun", "Y. Bengio", "G. Hinton"], "venue": "Nature, vol. 521, no. 7553, pp. 436\u2013444, 2015.", "citeRegEx": "217", "shortCiteRegEx": null, "year": 2015}, {"title": "Voxnet: A 3d convolutional neural network for real-time object recognition", "author": ["D. Maturana", "S. Scherer"], "venue": "IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS), 2015. IEEE, 2015, pp. 922\u2013928. 47", "citeRegEx": "218", "shortCiteRegEx": null, "year": 2015}, {"title": "Extreme learning machine for multilayer perceptron", "author": ["J. Tang", "C. Deng", "G.-B. Huang"], "venue": "IEEE Trans. Neural Netw. Learn. Syst., vol. 27, no. 4, pp. 809\u2013821, 2016.", "citeRegEx": "219", "shortCiteRegEx": null, "year": 2016}, {"title": "An insight into extreme learning machines: random neurons, random features and kernels", "author": ["G.-B. Huang"], "venue": "Cognit. Comput., vol. 6, no. 3, pp. 376\u2013390, 2014.", "citeRegEx": "220", "shortCiteRegEx": null, "year": 2014}, {"title": "A survey of dimension reduction techniques", "author": ["I.K. Fodor"], "venue": "Lawrence Livermore National Laboratory, Tech. Rep. UCRL-ID-148494, 2002.", "citeRegEx": "221", "shortCiteRegEx": null, "year": 2002}, {"title": "Evolving a learning algorithm for the binary perceptron", "author": ["J. Fontanari", "R. Meir"], "venue": "Network: Comput. Neural Syst., vol. 2, no. 4, pp. 353\u2013359, 1991.", "citeRegEx": "222", "shortCiteRegEx": null, "year": 1991}, {"title": "Using genetic algorithms to select inputs for neural networks", "author": ["Z. Guo", "R.E. Uhrig"], "venue": "Int. Workshop on Combinations of Genetic Algorithms and Neural Netw., 1992., COGANN-92, 1992, pp. 223\u2013234.", "citeRegEx": "223", "shortCiteRegEx": null, "year": 1992}, {"title": "A genetic algorithm to refine input data selection for air temperature prediction using artificial neural networks", "author": ["S. Venkadesh", "G. Hoogenboom", "W. Potter", "R. McClendon"], "venue": "Appl. Soft Comput., vol. 13, no. 5, pp. 2253\u20132260, May 2013.", "citeRegEx": "224", "shortCiteRegEx": null, "year": 2013}, {"title": "A discrete binary version of the particle swarm algorithm", "author": ["J. Kennedy", "R.C. Eberhart"], "venue": "IEEE Int. Conf. on Systems, Man, and Cybernetics, 1997. Computational Cybernetics and Simulation., 1997, vol. 5. IEEE, 1997, pp. 4104\u20134108.", "citeRegEx": "225", "shortCiteRegEx": null, "year": 1997}, {"title": "Particle swarm optimization for parameter determination and feature selection of support vector machines", "author": ["S.-W. Lin", "K.-C. Ying", "S.-C. Chen", "Z.-J. Lee"], "venue": "Expert Syst. Appl., vol. 35, no. 4, pp. 1817\u20131824, 2008.", "citeRegEx": "226", "shortCiteRegEx": null, "year": 1817}, {"title": "Modified binary pso for feature selection using svm applied to mortality prediction of septic patients", "author": ["S.M. Vieira", "L.F. Mendon\u00e7a", "G.J. Farinha", "J.M. Sousa"], "venue": "Appl. Soft. Comput., vol. 13, no. 8, pp. 3494\u20133504, 2013.", "citeRegEx": "227", "shortCiteRegEx": null, "year": 2013}, {"title": "A hybrid approach for feature subset selection using neural networks and ant colony optimization", "author": ["R.K. Sivagaminathan", "S. Ramakrishnan"], "venue": "Expert Syst. Appl., vol. 33, no. 1, pp. 49\u201360, 2007.", "citeRegEx": "228", "shortCiteRegEx": null, "year": 2007}, {"title": "Neural networks that teach themselves through genetic discovery of novel examples", "author": ["B.-T. Zhang", "G. Veenker"], "venue": "Int. Jt. Conf. Neural Netw., 1991., IJCNN, 1991, pp. 690\u2013695.", "citeRegEx": "229", "shortCiteRegEx": null, "year": 1991}, {"title": "Evolution of neural network training set through addition of virtual samples", "author": ["S. Cho", "K. Cha"], "venue": "Proc. IEEE Int. Conf. Evol. Comput., 1996, pp. 685\u2013688.", "citeRegEx": "230", "shortCiteRegEx": null, "year": 1996}, {"title": "Evolutionary design of artificial neural networks with different nodes", "author": ["Y. Liu", "X. Yao"], "venue": "Proc. IEEE Int. Conf. Evol. Comput., 1996, pp. 670\u2013675.", "citeRegEx": "231", "shortCiteRegEx": null, "year": 1996}, {"title": "Simultaneous optimization of neural network weights and active nodes using metaheuristics", "author": ["V.K. Ojha", "A. Abraham", "V. Sn\u00e1\u0161el"], "venue": "14th Int. Conf. on Hybrid Intell. Syst. (HIS), 2014, Dec 2014, pp. 248\u2013253.", "citeRegEx": "232", "shortCiteRegEx": null, "year": 2014}, {"title": "The design of self-organizing polynomial neural networks", "author": ["S.-K. Oh", "W. Pedrycz"], "venue": "Inf. Sci., vol. 141, no. 3, pp. 237\u2013258, 2002.", "citeRegEx": "233", "shortCiteRegEx": null, "year": 2002}, {"title": "Complex-valued neural networks", "author": ["A. Hirose"], "venue": "Springer Science & Business Media,", "citeRegEx": "234", "shortCiteRegEx": "234", "year": 2006}, {"title": "Learning by gradient descent in function space", "author": ["G. Mani"], "venue": "IEEE Int. Conf. Syst., Man, Cybern., 1990, pp. 242\u2013247.", "citeRegEx": "235", "shortCiteRegEx": null, "year": 1990}, {"title": "Neuronal circuits: an evolutionary perspective", "author": ["J.P. Dumont", "R.M. Robertson"], "venue": "Sci., vol. 233, no. 4766, pp. 849\u2013853, Aug 1986. 48", "citeRegEx": "236", "shortCiteRegEx": null, "year": 1986}, {"title": "Preadaptation in neural circuits", "author": ["D.G. Stork", "S. Walker", "M. Burns", "B. Jackson"], "venue": "Int. Jt. Conf. Neural Netw., vol. 1, 1990, pp. 202 \u2013 205.", "citeRegEx": "237", "shortCiteRegEx": null, "year": 1990}, {"title": "Input-dependent neural network trained by real-coded genetic algorithm and its industrial applications", "author": ["S. Ling", "F. Leung", "H. Lam"], "venue": "Soft Comput., vol. 11, no. 11, pp. 1033\u20131052, Sep 2007.", "citeRegEx": "238", "shortCiteRegEx": null, "year": 2007}, {"title": "A robust evolutionary algorithm for training neural networks", "author": ["J.-M. Yang", "C.-Y. Kao"], "venue": "Neural Comput. Appl., vol. 10, no. 3, pp. 214\u2013230, Dec 2001.", "citeRegEx": "239", "shortCiteRegEx": null, "year": 2001}, {"title": "A neural network with evolutionary neurons", "author": ["A. Alvarez"], "venue": "Neural Process. Lett., vol. 16, no. 1, pp. 43\u201352, Aug 2002.", "citeRegEx": "240", "shortCiteRegEx": null, "year": 2002}, {"title": "Tuning of the structure and parameters of a neural network using an improved genetic algorithm", "author": ["F.H.F. Leung", "H. Lam", "S. Ling", "P.-S. Tam"], "venue": "IEEE Trans. Neural Netw., vol. 14, no. 1, pp. 79\u201388, Jan 2003.", "citeRegEx": "241", "shortCiteRegEx": null, "year": 2003}, {"title": "Evolving transfer functions for artificial neural networks", "author": ["M.F. Augusteijn", "T.P. Harrington"], "venue": "Neural Comput. Appl., vol. 13, no. 1, pp. 38\u201346, Apr 2004.", "citeRegEx": "242", "shortCiteRegEx": null, "year": 2004}, {"title": "Hybrid artificial neural network", "author": ["N. Nedjah", "A. Abraham", "L.M. Mourelle"], "venue": "Neural Comput. Appl., vol. 16, no. 3, pp. 207\u2013208, May 2007.", "citeRegEx": "243", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning polynomials with neural networks", "author": ["A. Andoni", "R. Panigrahy", "G. Valiant", "L. Zhang"], "venue": "Proc. of the 31st Int. Conf. on Machine Learning (ICML-14), 2014, pp. 1908\u20131916.", "citeRegEx": "244", "shortCiteRegEx": null, "year": 2014}, {"title": "A gmdh neural network-based approach to passive robust fault detection using a constraint satisfaction backward test", "author": ["V. Puig", "M. Witczak", "F. Nejjari", "J. Quevedo", "J. Korbicz"], "venue": "Eng. Appl. Artif. Intell., vol. 20, no. 7, pp. 886\u2013897, 2007.", "citeRegEx": "245", "shortCiteRegEx": null, "year": 2007}, {"title": "Supervised learning in multilayer spiking neural networks", "author": ["I. Sporea", "A. Gr\u00fcning"], "venue": "Neural computation, vol. 25, no. 2, pp. 473\u2013509, 2013.", "citeRegEx": "246", "shortCiteRegEx": null, "year": 2013}, {"title": "Introduction to neuro-fuzzy systems", "author": ["R. Full\u00e9r"], "venue": "Springer Science & Business Media,", "citeRegEx": "247", "shortCiteRegEx": "247", "year": 2013}, {"title": "Quantum perceptron over a field and neural network architecture selection in a quantum computer", "author": ["A.J. da Silva", "T.B. Ludermir", "W.R. de Oliveira"], "venue": "Neural Netw., vol. 76, pp. 55\u201364, 2016.", "citeRegEx": "248", "shortCiteRegEx": null, "year": 2016}, {"title": "Quantum artificial neural network architectures and components", "author": ["A. Narayanan", "T. Menneer"], "venue": "Inf. Sci., vol. 128, no. 3, pp. 231\u2013255, 2000.", "citeRegEx": "249", "shortCiteRegEx": null, "year": 2000}, {"title": "Qubit neural network and its learning efficiency", "author": ["N. Kouda", "N. Matsui", "H. Nishimura", "F. Peper"], "venue": "Neural Comput. Appl., vol. 14, no. 2, pp. 114\u2013121, 2005.", "citeRegEx": "250", "shortCiteRegEx": null, "year": 2005}, {"title": "A hybrid quantum-inspired neural networks with sequence inputs", "author": ["P. Li", "H. Xiao", "F. Shang", "X. Tong", "X. Li", "M. Cao"], "venue": "Neurocomputing, vol. 117, pp. 81\u201390, 2013.", "citeRegEx": "251", "shortCiteRegEx": null, "year": 2013}, {"title": "The evolution of learning algorithms for artificial neural networks", "author": ["J. Baxter"], "venue": "Complex Syst.\u2013, 1992, pp. 313\u2013326.", "citeRegEx": "252", "shortCiteRegEx": null, "year": 1992}, {"title": "The evolution of learning: an experiment in genetic connectionism", "author": ["D.J. Chalmers"], "venue": "Proc. 1990 Connectionist Models Summer School, 1990, pp. 81\u201390.", "citeRegEx": "253", "shortCiteRegEx": null, "year": 1990}, {"title": "Fast learning method for back-propagation neural network by evolutionary adaptation of learning rates", "author": ["H.B. Kim", "S.H. Jung", "T.G. Kim", "K.H. Park"], "venue": "Neurocomputing, vol. 11, no. 1, pp. 101\u2013106, May 1996.", "citeRegEx": "254", "shortCiteRegEx": null, "year": 1996}, {"title": "Evolving artificial neural networks", "author": ["X. Yao"], "venue": "Proc. IEEE, vol. 87, no. 9, pp. 1423\u20131447, Sep 1999. 49", "citeRegEx": "255", "shortCiteRegEx": null, "year": 1999}, {"title": "Meta learning evolutionary artificial neural networks", "author": ["A. Abraham"], "venue": "Neurocomputing, vol. 56, no. 0, pp. 1 \u2013 38, Jan 2004.", "citeRegEx": "256", "shortCiteRegEx": null, "year": 2004}, {"title": "An evolutionary algorithm that constructs recurrent neural networks", "author": ["P.J. Angeline", "G.M. Saunders", "J.B. Pollack"], "venue": "IEEE Trans. Neural Netw., vol. 5, no. 1, pp. 54\u201365, 1994.", "citeRegEx": "257", "shortCiteRegEx": null, "year": 1994}, {"title": "A new evolutionary system for evolving artificial neural networks", "author": ["X. Yao", "Y. Liu"], "venue": "IEEE Trans. Neural Netw., vol. 8, no. 3, pp. 694\u2013713, May 1997.", "citeRegEx": "258", "shortCiteRegEx": null, "year": 1997}, {"title": "Evolving neural networks through augmenting topologies", "author": ["K.O. Stanley", "R. Miikkulainen"], "venue": "Evol. Comput., vol. 10, no. 2, pp. 99\u2013127, Jun 2002.", "citeRegEx": "259", "shortCiteRegEx": null, "year": 2002}, {"title": "Generating large-scale neural networks through discovering geometric regularities", "author": ["J. Gauci", "K. Stanley"], "venue": "Proc. 9th Ann. Conf. Genetic Evol. Comput. ACM, 2007, pp. 997\u20131004.", "citeRegEx": "260", "shortCiteRegEx": null, "year": 2007}, {"title": "Efficient reinforcement learning through evolutionary acquisition of neural topologies.", "author": ["Y. Kassahun", "G. Sommer"], "venue": "Proc. 13th European Symp. on Artificial Neural Networks", "citeRegEx": "261", "shortCiteRegEx": "261", "year": 2005}, {"title": "Ensemble of heterogeneous flexible neural trees using multiobjective genetic programming", "author": ["V.K. Ojha", "A. Abraham", "V. Sn\u00e1\u0161el"], "venue": "Appl. Soft Comput., vol. in press, 2016.", "citeRegEx": "262", "shortCiteRegEx": null, "year": 2016}, {"title": "Designing application-specific neural networks using the structured genetic algorithm", "author": ["D. Dasgupta", "D. McGregor"], "venue": "Int. Workshop on Combinations of Genetic Algorithms and Neural Netw., 1992., COGANN-92, 1992, pp. 87\u201396.", "citeRegEx": "263", "shortCiteRegEx": null, "year": 1992}, {"title": "Neurogenetic learning: an integrated method of designing and training neural networks using genetic algorithms", "author": ["H. Kitano"], "venue": "Physica D, vol. 75, no. 1, pp. 225 \u2013 238, Aug 1994.", "citeRegEx": "264", "shortCiteRegEx": null, "year": 1994}, {"title": "Using genetic algorithms to select architecture of a feedforward artificial neural network", "author": ["J. Arifovic", "R. Genay"], "venue": "Physica A, vol. 289, pp. 574 \u2013 594, Jan 2001.", "citeRegEx": "265", "shortCiteRegEx": null, "year": 2001}, {"title": "Optimum design of structures by an improved genetic algorithm using neural networks", "author": ["E. Salajegheh", "S. Gholizadeh"], "venue": "Adv. Eng. Softw., vol. 36, no. 1112, pp. 757 \u2013 767, Nov 2005.", "citeRegEx": "266", "shortCiteRegEx": null, "year": 2005}, {"title": "An alternative approach for neural network evolution with a genetic algorithm: crossover by combinatorial optimization", "author": ["N. Gar\u0107\u0131a-Pedrajas", "D. Ortiz-Boyer", "C. Herv\u00e1s-Mart\u0301\u0131nez"], "venue": "Neural Netw., vol. 19, no. 4, pp. 514\u2013528, May 2006.", "citeRegEx": "267", "shortCiteRegEx": null, "year": 2006}, {"title": "Forming neural networks through efficient and adaptive coevolution", "author": ["D.E. Moriarty", "R. Miikkulainen"], "venue": "Evol. Comput., vol. 5, no. 4, pp. 373\u2013399, Dec 1997.", "citeRegEx": "268", "shortCiteRegEx": null, "year": 1997}, {"title": "COVNET: a cooperative coevolutionary model for evolving artificial neural networks", "author": ["N. Garcia-Pedrajas", "C. Hervas-Martinez", "J. Munoz-Perez"], "venue": "IEEE Trans. Neural Netw., vol. 14, no. 3, pp. 575\u2013596, May 2003.", "citeRegEx": "269", "shortCiteRegEx": null, "year": 2003}, {"title": "Evolutionary induction of sparse neural trees", "author": ["B.-T. Zhang", "P. Ohm", "H. M\u00fchlenbein"], "venue": "Evol. Comput., vol. 5, no. 2, pp. 213\u2013236, Jun 1997.", "citeRegEx": "270", "shortCiteRegEx": null, "year": 1997}, {"title": "Nonlinear system modelling via optimal design of neural trees", "author": ["Y. Chen", "B. Yang", "J. Dong"], "venue": "Int. J. Neural Syst., vol. 14, no. 2, pp. 125\u2013137, Apr 2004.", "citeRegEx": "271", "shortCiteRegEx": null, "year": 2004}, {"title": "Feature selection and classification using flexible neural tree", "author": ["Y. Chen", "A. Abraham", "B. Yang"], "venue": "Neurocomputing, vol. 70, no. 1, pp. 305 \u2013 313, Dec 2006.", "citeRegEx": "272", "shortCiteRegEx": null, "year": 2006}, {"title": "Universal approximation propriety of flexible beta basis function neural tree", "author": ["S. Bouaziz", "A.M. Alimi", "A. Abraham"], "venue": "2014 Int. Jt. Conf. Neural Netw. (IJCNN), 2014, pp. 573\u2013580. 50", "citeRegEx": "273", "shortCiteRegEx": null, "year": 2014}, {"title": "A parallel evolving algorithm for flexible neural tree", "author": ["L. Peng", "B. Yang", "L. Zhang", "Y. Chen"], "venue": "Parallel Comput., vol. 37, no. 1011, pp. 653 \u2013 666, Oct 2011.", "citeRegEx": "274", "shortCiteRegEx": null, "year": 2011}, {"title": "Modeling early-age hydration kinetics of portland cement using flexible neural tree", "author": ["L. Wang", "B. Yang", "Y. Chen", "X. Zhao", "J. Chang", "H. Wang"], "venue": "Neural Comput. Appl., vol. 21, no. 5, pp. 877\u2013889, Jul 2012.", "citeRegEx": "275", "shortCiteRegEx": null, "year": 2012}, {"title": "Quantum perceptrons", "author": ["M. Lewenstein"], "venue": "J. Mod. Opt., vol. 41, no. 12, pp. 2491\u20132501, 1994.", "citeRegEx": "276", "shortCiteRegEx": null, "year": 1994}, {"title": "Quantum computing with molecules", "author": ["N. Gershenfeld", "I.L. Chuang"], "venue": "Sci. Am., vol. 278, no. 6, pp. 66\u201371, 1998.", "citeRegEx": "277", "shortCiteRegEx": null, "year": 1998}, {"title": "Quantum-inspired neural networks", "author": ["T. Menneer", "A. Narayanan"], "venue": "Univ. of Exeter., Tech. Rep. Tech. Rep. R329, 1995.", "citeRegEx": "278", "shortCiteRegEx": null, "year": 1995}, {"title": "A quantum dot neural network", "author": ["E.C. Behrman", "J. Niemel", "J.E. Steck", "S.R. Skinner"], "venue": "Proc. of the 4th Workshop on Physics of Computation, 1996, pp. 22\u201324.", "citeRegEx": "279", "shortCiteRegEx": null, "year": 1996}, {"title": "Learning in non-superpositional quantum neurocomputers", "author": ["R.L. Chrisley"], "venue": "Brain, Mind and Physics. IOS Press, Amsterdam, pp. 126\u2013139, 1997.", "citeRegEx": "280", "shortCiteRegEx": null, "year": 1997}, {"title": "An artificial neuron with quantum mechanical properties", "author": ["D. Ventura", "T. Martinez"], "venue": "Artificial Neural Nets and Genetic Algorithms. Springer, 1998, pp. 482\u2013485.", "citeRegEx": "281", "shortCiteRegEx": null, "year": 1998}, {"title": "A heuristic review of quantum neural networks", "author": ["T.G. Rudolph"], "venue": "Ph.D. dissertation, Imperial College London, 2011.", "citeRegEx": "282", "shortCiteRegEx": null, "year": 2011}, {"title": "Extreme learning machine: theory and applications", "author": ["G.-B. Huang", "Q.-Y. Zhu", "C.-K. Siew"], "venue": "Neurocomputing, vol. 70, no. 1, pp. 489\u2013501, 2006.", "citeRegEx": "283", "shortCiteRegEx": null, "year": 2006}, {"title": "Evolutionary multi-objective optimization for simultaneous generation of signal-type and symbol-type representations", "author": ["Y. Jin", "B. Sendhoff", "E. K\u00f6rner"], "venue": "Evolutionary Multi-Criterion Optimization, ser. Lecture Notes in Computer Science, vol. 3410. Springer, 2005, pp. 752\u2013766.", "citeRegEx": "284", "shortCiteRegEx": null, "year": 2005}, {"title": "A closer look at drawbacks of minimizing weighted sums of objectives for pareto set generation in multicriteria optimization problems", "author": ["I. Das", "J.E. Dennis"], "venue": "Struct. Optim., vol. 14, no. 1, pp. 63\u201369, 1997.", "citeRegEx": "285", "shortCiteRegEx": null, "year": 1997}, {"title": "A multi-objective evolutionary algorithm using neural networks to approximate fitness evaluations", "author": ["A. Gaspar-Cunha", "A. Vieira"], "venue": "Int. J. Comput., Syst., Signals, vol. 6, no. 1, pp. 18\u201336, Jan 2005.", "citeRegEx": "286", "shortCiteRegEx": null, "year": 2005}, {"title": "A comprehensive survey of evolutionary-based multiobjective optimization techniques", "author": ["C.A.C. Coello"], "venue": "Knowl. Inform. Syst., vol. 1, no. 3, pp. 129\u2013156, Aug 1999.", "citeRegEx": "287", "shortCiteRegEx": null, "year": 1999}, {"title": "Multiobjective evolutionary algorithms: A survey of the state of the art", "author": ["A. Zhou", "B.-Y. Qu", "H. Li", "S.-Z. Zhao", "P.N. Suganthan", "Q. Zhang"], "venue": "Swarm Evol. Comput., vol. 1, no. 1, pp. 32\u201349, 2011.", "citeRegEx": "288", "shortCiteRegEx": null, "year": 2011}, {"title": "Improving generalization of MLPs with multi-objective optimization", "author": ["R. de Albuquerque Teixeira", "A.P. Braga", "R.H. Takahashi", "R.R. Saldanha"], "venue": "Neurocomputing, vol. 35, no. 1, pp. 189 \u2013 194, Nov 2000.", "citeRegEx": "289", "shortCiteRegEx": null, "year": 2000}, {"title": "The ellipsoid method: A survey", "author": ["R.G. Bland", "D. Goldfarb", "M.J. Todd"], "venue": "Oper. Res., vol. 29, no. 6, pp. 1039\u20131091, 1981.", "citeRegEx": "290", "shortCiteRegEx": null, "year": 1981}, {"title": "Training neural networks with a multi-objective sliding mode control algorithm", "author": ["M.A. Costa", "A.P. Braga", "B.R. Menezes", "R.A. Teixeira", "G.G. Parma"], "venue": "Neurocomputing, vol. 51, pp. 467\u2013473, Apr 2003.", "citeRegEx": "291", "shortCiteRegEx": null, "year": 2003}, {"title": "A genetic algorithms based multi-objective neural net applied to noisy blast furnace data", "author": ["F. Pettersson", "N. Chakraborti", "H. Sax\u00e9n"], "venue": "Appl. Soft Comput., vol. 7, no. 1, pp. 387 \u2013 397, Jan 2007. 51", "citeRegEx": "292", "shortCiteRegEx": null, "year": 2007}, {"title": "Hybrid multiobjective evolutionary design for artificial neural networks", "author": ["C.-K. Goh", "E.-J. Teoh", "K. Chen Tan"], "venue": "IEEE Trans. Neural Netw., vol. 19, no. 9, pp. 1531\u20131548, Jul 2008.", "citeRegEx": "293", "shortCiteRegEx": null, "year": 2008}, {"title": "A multi-objective memetic and hybrid methodology for optimizing the parameters and performance of artificial neural networks", "author": ["L.M. Almeida", "T.B. Ludermir"], "venue": "Neurocomputing, vol. 73, no. 7, pp. 1438 \u2013 1450, Mar 2010.", "citeRegEx": "294", "shortCiteRegEx": null, "year": 2010}, {"title": "Pareto-based multiobjective machine learning: An overview and case studies", "author": ["Y. Jin", "B. Sendhoff"], "venue": "IEEE Tran. on Syst., Man, and Cybern., Part C: Appl. Rev., vol. 38, no. 3, pp. 397\u2013415, 2008.", "citeRegEx": "295", "shortCiteRegEx": null, "year": 2008}, {"title": "A fast elitist non-dominated sorting genetic algorithm for multi-objective optimization: NSGA-II", "author": ["K. Deb", "S. Agrawal", "A. Pratap", "T. Meyarivan"], "venue": "Parallel Problem Solving from Nature PPSN VI, ser. Lecture Notes in Computer Science, M. Schoenauer, K. Deb, G. Rudolph, X. Yao, E. Lutton, J. Merelo, and H.-P. Schwefel, Eds. Springer, 2000, vol. 1917, pp. 849\u2013858.", "citeRegEx": "296", "shortCiteRegEx": null, "year": 2000}, {"title": "Neural network regularization and ensembling using multi-objective evolutionary algorithms", "author": ["Y. Jin", "T. Okabe", "B. Sendhoff"], "venue": "Congr. Evol. Comput., 2004. CEC2004, vol. 1, 2004, pp. 1\u20138.", "citeRegEx": "297", "shortCiteRegEx": null, "year": 2004}, {"title": "Speeding up backpropagation using multiobjective evolutionary algorithms", "author": ["H.A. Abbass"], "venue": "Neural Comput., vol. 15, no. 11, pp. 2705\u20132726, Nov 2003.", "citeRegEx": "298", "shortCiteRegEx": null, "year": 2003}, {"title": "The self-adaptive pareto differential evolution algorithm", "author": ["H. Abbass"], "venue": "Proc. 2002 Congr. Evol. Comput., 2002. CEC \u201902, vol. 1, 2002, pp. 831\u2013836.", "citeRegEx": "299", "shortCiteRegEx": null, "year": 2002}, {"title": "Training neural networks using multiobjective particle swarm optimization", "author": ["J.P.T. Yusiong", "P.C. Naval Jr"], "venue": "Advances in Natural Computation. Springer, 2006, pp. 879\u2013888.", "citeRegEx": "300", "shortCiteRegEx": null, "year": 2006}, {"title": "Evolutionary multi-objective optimisation of neural networks for face detection", "author": ["S. Wiegand", "C. Igel", "U. Handmann"], "venue": "Int. J. Comput. Intell. Appl., vol. 4, no. 3, pp. 237\u2013253, Sep 2004.", "citeRegEx": "301", "shortCiteRegEx": null, "year": 2004}, {"title": "Multi-objective neural network optimization for visual object detection", "author": ["S. Roth", "A. Gepperth", "C. Igel"], "venue": "Multi-Objective Machine Learning, ser. Studies in Computational Intelligence, Y. Jin, Ed. Springer, 2006, vol. 16, pp. 629\u2013655.", "citeRegEx": "302", "shortCiteRegEx": null, "year": 2006}, {"title": "Evolutionary multi-objective optimization for simultaneous generation of signal-type and symbol-type representations", "author": ["Y. Jin", "B. Sendhoff", "E. K\u00f6rner"], "venue": "Evol. Multi-Criterion Optim., ser. Lecture Notes in Computer Science, vol. 3410, 2005, pp. 752\u2013766.", "citeRegEx": "303", "shortCiteRegEx": null, "year": 2005}, {"title": "An elitist non-dominated sorting genetic algorithm enhanced with a neural network applied to the multi-objective optimization of a polysiloxane synthesis process", "author": ["R. Furtuna", "S. Curteanu", "F. Leon"], "venue": "Eng. Appl. Artif. Intell., vol. 24, no. 5, pp. 772 \u2013 785, Aug 2011.", "citeRegEx": "304", "shortCiteRegEx": null, "year": 2011}, {"title": "Hybridization of multi-objective evolutionary algorithms and artificial neural networks for optimizing the performance of electrical drives", "author": ["A.-C. Z\u01cevoianu", "G. Bramerdorfer", "E. Lughofer", "S. Silber", "W. Amrhein", "E.P. Klement"], "venue": "Eng. Appl. Artif. Intell., vol. 26, no. 8, pp. 1781 \u2013 1794, 2013.", "citeRegEx": "305", "shortCiteRegEx": null, "year": 2013}, {"title": "Multi-objective optimization for turning processes using neural network modeling and dynamic-neighborhood particle swarm optimization", "author": ["Y. Karpat", "T. \u00d6zel"], "venue": "Int. J. Adv. Manuf. Technol., vol. 35, no. 3-4, pp. 234\u2013247, Dec 2007.", "citeRegEx": "306", "shortCiteRegEx": null, "year": 2007}, {"title": "SYMBIONT: a cooperative evolutionary model for evolving artificial neural networks for classification", "author": ["N. Gar\u0107\u0131a-Pedrajas", "C. Herv\u00e1s-Mart\u0301\u0131nez", "J. Mu\u0169oz P\u00e9rez"], "venue": "Technologies for Constructing Intelligent Systems 2, ser. Studies in Fuzziness and Soft Computing, B. Bouchon-Meunier, J. Guti\u00e9rrez-\u0154\u0131os, L. Magdalena, and R. R. Yager, Eds. Physica-Verlag HD, 2002, vol. 90, pp. 341\u2013354. 52", "citeRegEx": "307", "shortCiteRegEx": null, "year": 2002}, {"title": "Multi-objective cooperative coevolution of artificial neural networks (multi-objective cooperative networks)", "author": ["N. Gar\u0107\u0131a-Pedrajas", "C. Herv\u00e1s-Mart\u0301\u0131nez", "J. Mu\u00f1oz P\u00e9rez"], "venue": "Neural Netw., vol. 15, no. 10, pp. 1259\u20131278, Dec 2002.", "citeRegEx": "308", "shortCiteRegEx": null, "year": 2002}, {"title": "Optimal design of artificial neural networks by a multi-objective strategy: groundwater level predictions", "author": ["O. Giustolisi", "V. Simeone"], "venue": "Hydrological Sci. J., vol. 51, no. 3, pp. 502\u2013523, Jan 2006.", "citeRegEx": "309", "shortCiteRegEx": null, "year": 2006}, {"title": "Memetic pareto differential evolutionary artificial neural networks to determine growth multi-classes in predictive microbiology", "author": ["M. Cruz-Ram\u0131\u0301rez", "J. Snchez-Monedero", "F. Fernndez-Navarro", "J. Fernndez", "C. Hervs-Martnez"], "venue": "Evol. Intell., vol. 3, no. 3-4, pp. 187\u2013199, Dec 2010.", "citeRegEx": "310", "shortCiteRegEx": null, "year": 2010}, {"title": "Parallel networks that learn to pronounce english text", "author": ["T.J. Sejnowski", "C.R. Rosenberg"], "venue": "Complex Syst., vol. 1, no. 1, pp. 145\u2013168, 1987.", "citeRegEx": "311", "shortCiteRegEx": null, "year": 1987}, {"title": "Making use of population information in evolutionary artificial neural networks", "author": ["X. Yao", "Y. Liu"], "venue": "IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 28, no. 3, pp. 417\u2013425, Jun 1998.", "citeRegEx": "312", "shortCiteRegEx": null, "year": 1998}, {"title": "Ensemble based systems in decision making", "author": ["R. Polikar"], "venue": "IEEE Circuits Syst. Mag., vol. 6, no. 3, pp. 21\u201345, 2006.", "citeRegEx": "313", "shortCiteRegEx": null, "year": 2006}, {"title": "Ensemble structure of evolutionary artificial neural networks", "author": ["X. Yao", "Y. Liu"], "venue": "Proc. IEEE Int. Conf. Evol. Comput., 1996, pp. 659\u2013664.", "citeRegEx": "314", "shortCiteRegEx": null, "year": 1996}, {"title": "Stochastic Modelling and Control", "author": ["M.H. Davis", "R.B. Vinter"], "venue": null, "citeRegEx": "315", "shortCiteRegEx": "315", "year": 1985}, {"title": "Design of ensemble neural network using entropy theory", "author": ["Z. Zhao", "Y. Zhang"], "venue": "Adv. Eng. Softw., vol. 42, no. 10, pp. 838 \u2013 845, Oct 2011.", "citeRegEx": "316", "shortCiteRegEx": null, "year": 2011}, {"title": "Ensemble learning via negative correlation", "author": ["Y. Liu", "X. Yao"], "venue": "Neural Netw., vol. 12, no. 10, pp. 1399\u20131404, Dec 1999.", "citeRegEx": "317", "shortCiteRegEx": null, "year": 1999}, {"title": "Negatively correlated neural network ensemble with multipopulation particle swarm optimization", "author": ["Z. Qin", "Y. Liu", "X. Heng", "X. Wang"], "venue": "Advances in Neural Networks - ISNN 2005, ser. Lecture Notes in Computer Science, J. Wang, X. Liao, and Z. Yi, Eds. Springer, 2005, vol. 3496, pp. 520\u2013525.", "citeRegEx": "318", "shortCiteRegEx": null, "year": 2005}, {"title": "Evolutionary ensembles with negative correlation learning", "author": ["Y. Liu", "X. Yao", "T. Higuchi"], "venue": "IEEE Trans. Evol. Comput., vol. 4, no. 4, pp. 380\u2013387, Nov 2000.", "citeRegEx": "319", "shortCiteRegEx": null, "year": 2000}, {"title": "A constructive algorithm for training cooperative neural network ensembles", "author": ["M.M. Islam", "X. Yao", "K. Murase"], "venue": "IEEE Trans. Neural Netw., vol. 14, no. 4, pp. 820\u2013834, Jul 2003.", "citeRegEx": "320", "shortCiteRegEx": null, "year": 2003}, {"title": "Evolving artificial neural network ensembles", "author": ["X. Yao", "M.M. Islam"], "venue": "IEEE Comput. Intell. Mag., vol. 3, no. 1, pp. 31\u201342, Feb 2008.", "citeRegEx": "321", "shortCiteRegEx": null, "year": 2008}, {"title": "Ensembling neural networks: many could be better than all", "author": ["Z.-H. Zhou", "J. Wu", "W. Tang"], "venue": "Artif. Intell., vol. 137, no. 1, pp. 239 \u2013 263, May 2002.", "citeRegEx": "322", "shortCiteRegEx": null, "year": 2002}, {"title": "Bagging predictors", "author": ["L. Breiman"], "venue": "Mach. Learn., vol. 24, no. 2, pp. 123\u2013140, Aug 1996.", "citeRegEx": "323", "shortCiteRegEx": null, "year": 1996}, {"title": "The strength of weak learnability", "author": ["R.E. Schapire"], "venue": "Mach. Learn., vol. 5, no. 2, pp. 197\u2013227, Jun 1990.", "citeRegEx": "324", "shortCiteRegEx": null, "year": 1990}, {"title": "Clustering ensembles of neural network models", "author": ["B. Bakker", "T. Heskes"], "venue": "Neural Netw., vol. 16, no. 2, pp. 261 \u2013 269, Mar 2003.", "citeRegEx": "325", "shortCiteRegEx": null, "year": 2003}, {"title": "Classification of 2-dimensional array patterns: assembling many small neural networks is better than using a large one", "author": ["L. Chen", "W. Xue", "N. Tokuda"], "venue": "Neural Netw., vol. 23, no. 6, pp. 770 \u2013 781, Aug 2010. 53", "citeRegEx": "326", "shortCiteRegEx": null, "year": 2010}, {"title": "Class-switching neural network ensembles", "author": ["G.M.-M. noz", "A. S\u00e1nchez-Mart\u0301\u0131nez", "D. Hern\u00e1ndez-Lobato", "A. Su\u00e1rez"], "venue": "Neurocomputing, vol. 71, no. 13, pp. 2521 \u2013 2528, Aug 2008.", "citeRegEx": "327", "shortCiteRegEx": null, "year": 2008}, {"title": "Clustering and co-evolution to construct neural network ensembles: an experimental study", "author": ["F.L. Minku", "T.B. Ludermir"], "venue": "Neural Netw., vol. 21, no. 9, pp. 1363 \u2013 1379, Nov 2008.", "citeRegEx": "328", "shortCiteRegEx": null, "year": 2008}, {"title": "Evolutionary ensemble of diverse artificial neural networks using speciation", "author": ["K.-J. Kim", "S.-B. Cho"], "venue": "Neurocomputing, vol. 71, no. 7, pp. 1604 \u2013 1618, Mar 2008.", "citeRegEx": "329", "shortCiteRegEx": null, "year": 2008}, {"title": "Progressive interactive training: a sequential neural network ensemble learning method", "author": ["M. Akhand", "M.M. Islam", "K. Murase"], "venue": "Neurocomputing, vol. 73, no. 1, pp. 260 \u2013 273, Dec 2009.", "citeRegEx": "330", "shortCiteRegEx": null, "year": 2009}, {"title": "Ensemble learning using multi-objective evolutionary algorithms", "author": ["A. Chandra", "X. Yao"], "venue": "J. Math. Model. Algorithms, vol. 5, no. 4, pp. 417\u2013445, Dec 2006.", "citeRegEx": "331", "shortCiteRegEx": null, "year": 2006}, {"title": "Multiobjective neural network ensembles based on regularized negative correlation learning", "author": ["H. Chen", "X. Yao"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 22, no. 12, pp. 1738\u20131751, Feb 2010.", "citeRegEx": "332", "shortCiteRegEx": null, "year": 2010}, {"title": "Anchoring data quality dimensions in ontological foundations", "author": ["Y. Wand", "R.Y. Wang"], "venue": "Commun. ACM, vol. 39, no. 11, pp. 86\u201395, Nov 1996.", "citeRegEx": "333", "shortCiteRegEx": null, "year": 1996}, {"title": "Data quality assessment", "author": ["L.L. Pipino", "Y.W. Lee", "R.Y. Wang"], "venue": "Commun. ACM, vol. 45, no. 4, pp. 211\u2013218, Apr 2002.", "citeRegEx": "334", "shortCiteRegEx": null, "year": 2002}, {"title": "Real-world data is dirty: Data cleansing and the merge/purge problem", "author": ["M.A. Hern\u00e1ndez", "S.J. Stolfo"], "venue": "Data Min. Knowl. Discovery, vol. 2, no. 1, pp. 9\u201337, 1998.", "citeRegEx": "335", "shortCiteRegEx": null, "year": 1998}, {"title": "Virtual sample generation using a population of networks", "author": ["S. Cho", "M. Jang", "S. Chang"], "venue": "Neural Process. Lett., vol. 5, no. 2, pp. 21\u201327, 1997.", "citeRegEx": "336", "shortCiteRegEx": null, "year": 1997}, {"title": "Training neural network classifiers for medical decision making: The effects of imbalanced datasets on classification performance", "author": ["M.A. Mazurowski", "P.A. Habas", "J.M. Zurada", "J.Y. Lo", "J.A. Baker", "G.D. Tourassi"], "venue": "Neural Netw., vol. 21, no. 2, pp. 427\u2013436, 2008.", "citeRegEx": "337", "shortCiteRegEx": null, "year": 2008}, {"title": "Understanding big data: Analytics for enterprise class hadoop and streaming data", "author": ["P. Zikopoulos", "C. Eaton"], "venue": "McGraw-Hill Osborne Media,", "citeRegEx": "338", "shortCiteRegEx": "338", "year": 2011}, {"title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "author": ["G. Hinton", "L. Deng", "D. Yu", "G. Dahl", "A. Mohamed", "N. Jaitly", "A. Senior", "V. Vanhoucke", "P. Nguyen", "T. Sainath", "B. Kingsbury"], "venue": "IEEE Signal Process. Mag., vol. 29, no. 6, pp. 82\u201397, Nov 2012.", "citeRegEx": "339", "shortCiteRegEx": null, "year": 2012}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Y.-W. Teh"], "venue": "Neural Comput., vol. 18, no. 7, pp. 1527\u20131554, Jul 2006.", "citeRegEx": "340", "shortCiteRegEx": null, "year": 2006}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["G.E. Hinton", "R.R. Salakhutdinov"], "venue": "Science, vol. 313, no. 5786, pp. 504\u2013507, 2006.", "citeRegEx": "341", "shortCiteRegEx": null, "year": 2006}, {"title": "On-line learning in neural networks", "author": ["D. Saad"], "venue": null, "citeRegEx": "342", "shortCiteRegEx": "342", "year": 2009}, {"title": "Learning in nonstationary environments: a survey", "author": ["G. Ditzler", "M. Roveri", "C. Alippi", "R. Polikar"], "venue": "IEEE Comput. Intell. Magazine, vol. 10, no. 4, pp. 12\u201325, 2015.", "citeRegEx": "343", "shortCiteRegEx": null, "year": 2015}, {"title": "Methods of integrating data to uncover genotype-phenotype interactions", "author": ["M.D. Ritchie", "E.R. Holzinger", "R. Li", "S.A. Pendergrass", "D. Kim"], "venue": "Nature Rev. Genetics, vol. 16, no. 2, pp. 85\u201397, 2015.", "citeRegEx": "344", "shortCiteRegEx": null, "year": 2015}, {"title": "Gene functional classification from heterogeneous data", "author": ["P. Pavlidis", "J. Weston", "J. Cai", "W.N. Grundy"], "venue": "Proc. of the 5th Ann. Int. Conf. on Comput. Biology. ACM, 2001, pp. 249\u2013255. 54", "citeRegEx": "345", "shortCiteRegEx": null, "year": 2001}, {"title": "Challenges of the fourth industrial revolution", "author": ["P. Prisecaru"], "venue": "Knowledge Horizons. Economics, vol. 8, no. 1, p. 57, 2016.", "citeRegEx": "346", "shortCiteRegEx": null, "year": 2016}, {"title": "Human activity recognition and pattern discovery", "author": ["E. Kim", "S. Helal", "D. Cook"], "venue": "IEEE Pervasive Comput., vol. 9, no. 1, pp. 48\u201353, 2010.", "citeRegEx": "347", "shortCiteRegEx": null, "year": 2010}, {"title": "A survey of hybrid ann/hmm models for automatic speech recognition", "author": ["E. Trentin", "M. Gori"], "venue": "Neurocomputing, vol. 37, no. 1, pp. 91\u2013126, 2001. 55", "citeRegEx": "348", "shortCiteRegEx": null, "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "Back in 1943 McCulloch and Pitts [1] proposed a computational model inspired by the human brain, which initiated the research on artificial neural network (ANN).", "startOffset": 33, "endOffset": 36}, {"referenceID": 1, "context": "Moreover, it is the structure of an FNN that makes it a universal function approximator, which has the capabilities of approximating any continuous function [2].", "startOffset": 157, "endOffset": 160}, {"referenceID": 2, "context": "Therefore, a wide range of problems is solved by the FNNs, such as pattern recognition [3], clustering and classification [4], function approximation [5], control [6], bioinformatics [7], signal processing [8], speech processing [9], etc.", "startOffset": 87, "endOffset": 90}, {"referenceID": 3, "context": "Therefore, a wide range of problems is solved by the FNNs, such as pattern recognition [3], clustering and classification [4], function approximation [5], control [6], bioinformatics [7], signal processing [8], speech processing [9], etc.", "startOffset": 122, "endOffset": 125}, {"referenceID": 4, "context": "Therefore, a wide range of problems is solved by the FNNs, such as pattern recognition [3], clustering and classification [4], function approximation [5], control [6], bioinformatics [7], signal processing [8], speech processing [9], etc.", "startOffset": 150, "endOffset": 153}, {"referenceID": 5, "context": "Therefore, a wide range of problems is solved by the FNNs, such as pattern recognition [3], clustering and classification [4], function approximation [5], control [6], bioinformatics [7], signal processing [8], speech processing [9], etc.", "startOffset": 163, "endOffset": 166}, {"referenceID": 6, "context": "Therefore, a wide range of problems is solved by the FNNs, such as pattern recognition [3], clustering and classification [4], function approximation [5], control [6], bioinformatics [7], signal processing [8], speech processing [9], etc.", "startOffset": 183, "endOffset": 186}, {"referenceID": 7, "context": "Therefore, a wide range of problems is solved by the FNNs, such as pattern recognition [3], clustering and classification [4], function approximation [5], control [6], bioinformatics [7], signal processing [8], speech processing [9], etc.", "startOffset": 206, "endOffset": 209}, {"referenceID": 8, "context": "Therefore, a wide range of problems is solved by the FNNs, such as pattern recognition [3], clustering and classification [4], function approximation [5], control [6], bioinformatics [7], signal processing [8], speech processing [9], etc.", "startOffset": 229, "endOffset": 232}, {"referenceID": 9, "context": "A single layer perceptron (SLP) consists of an input and an output layer, and it is the simplest form of ANN model [11, 12].", "startOffset": 115, "endOffset": 123}, {"referenceID": 10, "context": "A single layer perceptron (SLP) consists of an input and an output layer, and it is the simplest form of ANN model [11, 12].", "startOffset": 115, "endOffset": 123}, {"referenceID": 11, "context": "However, SLPs are incapable of solving nonlinearly separable patterns [13].", "startOffset": 70, "endOffset": 74}, {"referenceID": 12, "context": "Hence, a multilayer perceptron (MLP) was proposed, which addressed the limitations of SLPs by including one or more hidden layers in between an input and an output layer [14].", "startOffset": 170, "endOffset": 174}, {"referenceID": 13, "context": "Initially, the backpropagation (BP) algorithm was used for the MLP training [15].", "startOffset": 76, "endOffset": 80}, {"referenceID": 13, "context": "A trained MLP is then found capable of solving nonlinearly separable patterns [15].", "startOffset": 78, "endOffset": 82}, {"referenceID": 1, "context": "Moreover, an FNN is considered as a universal approximator [2].", "startOffset": 59, "endOffset": 62}, {"referenceID": 14, "context": "Cybenko [16] referring to Kolmogorov\u2019s theorem showed that an FNN with only a single internal hidden layer\u2014containing a finite number of neurons with any continuous sigmoidal nonlinear activation function\u2014can approximate any continuous function.", "startOffset": 8, "endOffset": 12}, {"referenceID": 1, "context": "Also, the FNN structure (architecture) is itself capable enough to be a universal approximator [2, 18].", "startOffset": 95, "endOffset": 102}, {"referenceID": 16, "context": "Also, the FNN structure (architecture) is itself capable enough to be a universal approximator [2, 18].", "startOffset": 95, "endOffset": 102}, {"referenceID": 17, "context": "Hence, several researchers praised FNN for its universal approximation ability [19\u201322].", "startOffset": 79, "endOffset": 86}, {"referenceID": 18, "context": "Hence, several researchers praised FNN for its universal approximation ability [19\u201322].", "startOffset": 79, "endOffset": 86}, {"referenceID": 19, "context": "Hence, several researchers praised FNN for its universal approximation ability [19\u201322].", "startOffset": 79, "endOffset": 86}, {"referenceID": 20, "context": "Hence, several researchers praised FNN for its universal approximation ability [19\u201322].", "startOffset": 79, "endOffset": 86}, {"referenceID": 21, "context": "Many other ANN models, like radial basis function [23] and support vector machine [24] are a special class of three-layer FNNs.", "startOffset": 50, "endOffset": 54}, {"referenceID": 22, "context": "Many other ANN models, like radial basis function [23] and support vector machine [24] are a special class of three-layer FNNs.", "startOffset": 82, "endOffset": 86}, {"referenceID": 23, "context": "In contrast, adaptive resonance theory [25], Kohenen\u2019s self-organizing map [26], and learning-vector-quantization [26] are two-layer FNNs that are capable of solving pattern recognition and data compression problems using unsupervised learning methods.", "startOffset": 39, "endOffset": 43}, {"referenceID": 24, "context": "In contrast, adaptive resonance theory [25], Kohenen\u2019s self-organizing map [26], and learning-vector-quantization [26] are two-layer FNNs that are capable of solving pattern recognition and data compression problems using unsupervised learning methods.", "startOffset": 75, "endOffset": 79}, {"referenceID": 24, "context": "In contrast, adaptive resonance theory [25], Kohenen\u2019s self-organizing map [26], and learning-vector-quantization [26] are two-layer FNNs that are capable of solving pattern recognition and data compression problems using unsupervised learning methods.", "startOffset": 114, "endOffset": 118}, {"referenceID": 15, "context": "Additionally, the ANN architecture with feedback connections, in other words, a network where connections between the nodes may form cycles is known as a recurrent neural netKolmogorov\u2019s theorem: \u201cAll continuous functions of n variables have an exact representation in terms of finite superpositions and compositions of a small number of functions of one variable [17].", "startOffset": 364, "endOffset": 368}, {"referenceID": 25, "context": "RNNs such as Hopfield network [27] and Boltzmann machine [28] are good at the application for memory storage and remembering input\u2013output relations.", "startOffset": 30, "endOffset": 34}, {"referenceID": 26, "context": "RNNs such as Hopfield network [27] and Boltzmann machine [28] are good at the application for memory storage and remembering input\u2013output relations.", "startOffset": 57, "endOffset": 61}, {"referenceID": 25, "context": "Moreover, Hopfield network was designed for solving nonlinear dynamic systems, where the stability of a dynamic system is studied under the neurodynamic paradigm [27].", "startOffset": 162, "endOffset": 166}, {"referenceID": 27, "context": "A collection of RNN models, such as temporal RNN [29], echo state RNN [30], liquid state machine [31] and backpropagation de-correlation [32] forms a paradigm called reservoir computing, which addresses several engineering applications including nonlinear signal processing and control.", "startOffset": 49, "endOffset": 53}, {"referenceID": 28, "context": "A collection of RNN models, such as temporal RNN [29], echo state RNN [30], liquid state machine [31] and backpropagation de-correlation [32] forms a paradigm called reservoir computing, which addresses several engineering applications including nonlinear signal processing and control.", "startOffset": 70, "endOffset": 74}, {"referenceID": 29, "context": "A collection of RNN models, such as temporal RNN [29], echo state RNN [30], liquid state machine [31] and backpropagation de-correlation [32] forms a paradigm called reservoir computing, which addresses several engineering applications including nonlinear signal processing and control.", "startOffset": 97, "endOffset": 101}, {"referenceID": 30, "context": "A collection of RNN models, such as temporal RNN [29], echo state RNN [30], liquid state machine [31] and backpropagation de-correlation [32] forms a paradigm called reservoir computing, which addresses several engineering applications including nonlinear signal processing and control.", "startOffset": 137, "endOffset": 141}, {"referenceID": 31, "context": "One very commonly known supervised learning algorithm is Delta rule or Widrow-Hoff rule [33,34] in which the n-dimensional weight vector w of an FNN is optimized as: w = w + \u2206w, (2) where \u2206w is weight change (an additive term) at t-th iteration.", "startOffset": 88, "endOffset": 95}, {"referenceID": 32, "context": "One very commonly known supervised learning algorithm is Delta rule or Widrow-Hoff rule [33,34] in which the n-dimensional weight vector w of an FNN is optimized as: w = w + \u2206w, (2) where \u2206w is weight change (an additive term) at t-th iteration.", "startOffset": 88, "endOffset": 95}, {"referenceID": 33, "context": "Contrary to the supervised learning paradigm, there are two other learning forms for the spacial cases of FNNs: 1) the unsupervised learning\u2014for the unlabeled training data [35], and 2) the reinforcement learning\u2014for the training data with insufficient input\u2013output relations [36].", "startOffset": 173, "endOffset": 177}, {"referenceID": 34, "context": "Contrary to the supervised learning paradigm, there are two other learning forms for the spacial cases of FNNs: 1) the unsupervised learning\u2014for the unlabeled training data [35], and 2) the reinforcement learning\u2014for the training data with insufficient input\u2013output relations [36].", "startOffset": 276, "endOffset": 280}, {"referenceID": 35, "context": ", can be used for evaluating the FNN\u2019s predictability [37].", "startOffset": 54, "endOffset": 58}, {"referenceID": 36, "context": "The cost function (4) or any similar squared-error-based cost function is inconsistent for solving classification problems [38].", "startOffset": 123, "endOffset": 127}, {"referenceID": 36, "context": "Instead, the percentage of good classification, which has consistent behavior, can be used [38].", "startOffset": 91, "endOffset": 95}, {"referenceID": 37, "context": "A detailed list of the cost function for evaluating the classification problems is available in [39\u201341].", "startOffset": 96, "endOffset": 103}, {"referenceID": 38, "context": "A detailed list of the cost function for evaluating the classification problems is available in [39\u201341].", "startOffset": 96, "endOffset": 103}, {"referenceID": 39, "context": "A detailed list of the cost function for evaluating the classification problems is available in [39\u201341].", "startOffset": 96, "endOffset": 103}, {"referenceID": 40, "context": "Another factor related to fitness of an FNN is to compare the cost functions of two or more FNN models [42,43].", "startOffset": 103, "endOffset": 110}, {"referenceID": 41, "context": "Another factor related to fitness of an FNN is to compare the cost functions of two or more FNN models [42,43].", "startOffset": 103, "endOffset": 110}, {"referenceID": 42, "context": "Some researchers also argue to statistically compare the predicted outputs of two or more FNN models to establish the differences in their performances [44].", "startOffset": 152, "endOffset": 156}, {"referenceID": 43, "context": "Learning algorithms when to using the cost function (4) or any similar function for FNN optimization has the tendency to fall in local minima [46].", "startOffset": 142, "endOffset": 146}, {"referenceID": 44, "context": "It indicates that the critical point corresponding to global minima of a smaller FNN model (model with h \u2212 1 hidden units) can be a local or saddle point of a larger FNN model (model with h hidden units) [47].", "startOffset": 204, "endOffset": 208}, {"referenceID": 45, "context": "However, there are some ways to avoid or eliminate local minima in FNN optimization [48,49]:", "startOffset": 84, "endOffset": 91}, {"referenceID": 46, "context": "However, there are some ways to avoid or eliminate local minima in FNN optimization [48,49]:", "startOffset": 84, "endOffset": 91}, {"referenceID": 47, "context": "1) If the weights and training patterns are assigned randomly to a three-layer FNN that contains h neurons at the hidden layer, then a gradient-descent algorithm can avoid trapping into local minima [50].", "startOffset": 199, "endOffset": 203}, {"referenceID": 48, "context": "2) If linearly-separable training data and pyramidal network structure are taken, then the error surface will be local minima free [51].", "startOffset": 131, "endOffset": 135}, {"referenceID": 49, "context": "[52] to replace gradient-descent algorithms, then it can avoid local minima.", "startOffset": 0, "endOffset": 4}, {"referenceID": 50, "context": "Moreover, it does not necessarily guarantee to converge to global minima and to set preconditions for the number of hidden neurons and linearly separable training patterns are unlikely conditions for the real-world problems [53].", "startOffset": 224, "endOffset": 228}, {"referenceID": 51, "context": "To achieve generalization, FNNs need to avoid both underfitting and overfitting during training, which is associated with high statistical bias and high statistical variance [54].", "startOffset": 174, "endOffset": 178}, {"referenceID": 52, "context": "Also, for a good generalization, the number of training pattern should be sufficiently larger than the total number of connections in FNN [55].", "startOffset": 138, "endOffset": 142}, {"referenceID": 53, "context": ", equivalent to find an optimum network architecture), early stopping of training algorithms, adding regularization term with the cost function [56,57], and adding noise to the training data.", "startOffset": 144, "endOffset": 151}, {"referenceID": 54, "context": ", equivalent to find an optimum network architecture), early stopping of training algorithms, adding regularization term with the cost function [56,57], and adding noise to the training data.", "startOffset": 144, "endOffset": 151}, {"referenceID": 43, "context": "The early stopping scheme suggests stopping of training at the point (epoch) from which onward the cost function value computed on cross-validation set starts to rise [46,58\u201360].", "startOffset": 167, "endOffset": 177}, {"referenceID": 55, "context": "The early stopping scheme suggests stopping of training at the point (epoch) from which onward the cost function value computed on cross-validation set starts to rise [46,58\u201360].", "startOffset": 167, "endOffset": 177}, {"referenceID": 56, "context": "The early stopping scheme suggests stopping of training at the point (epoch) from which onward the cost function value computed on cross-validation set starts to rise [46,58\u201360].", "startOffset": 167, "endOffset": 177}, {"referenceID": 57, "context": "The early stopping scheme suggests stopping of training at the point (epoch) from which onward the cost function value computed on cross-validation set starts to rise [46,58\u201360].", "startOffset": 167, "endOffset": 177}, {"referenceID": 58, "context": "Similarly, adding noise (jitters) into the training pattern improves FNN\u2019s generalization ability and removing insignificant weights from a trained FNN improves its fault tolerance ability [61].", "startOffset": 189, "endOffset": 193}, {"referenceID": 59, "context": "Moreover, generalization is related to sparsity and stability of a learning algorithm [62].", "startOffset": 86, "endOffset": 90}, {"referenceID": 60, "context": "It is because the model with lower network complexity possesses higher generalization ability than the models with higher network complexity [63].", "startOffset": 141, "endOffset": 145}, {"referenceID": 60, "context": "Moreover, the network with lower weight magnitude possesses better generalization ability [63].", "startOffset": 90, "endOffset": 94}, {"referenceID": 61, "context": "The FNN optimization using conventional gradient based algorithms is viewed as an unconstrained optimization problem [10,64].", "startOffset": 117, "endOffset": 124}, {"referenceID": 62, "context": "Now, instead of using a first-order partial derivative, a second-order partial derivative (\u22072) of cost function cf can be used as: H t = \u2207cf = \u2202cf \u2202w , (7) where H t is Hessian matrix at the t-th iteration [65].", "startOffset": 206, "endOffset": 210}, {"referenceID": 12, "context": "Backpropagation (BP) is a first-order gradient-descent algorithm for the FNNs optimization [14,15].", "startOffset": 91, "endOffset": 98}, {"referenceID": 13, "context": "Backpropagation (BP) is a first-order gradient-descent algorithm for the FNNs optimization [14,15].", "startOffset": 91, "endOffset": 98}, {"referenceID": 13, "context": "BP is sensitive to these parameters [15].", "startOffset": 36, "endOffset": 40}, {"referenceID": 48, "context": "The classical BP algorithm is slow and has a tendency to fall in local minima [51].", "startOffset": 78, "endOffset": 82}, {"referenceID": 13, "context": "Since the basic version of BP is sensitivity towards learning rate and momentum factor [15], several improvements were suggested by researchers: 1) a fast BP algorithm, called Quickpro was proposed in [66, 67]; 2) a delta-bar technique and an acceleration technique was suggested for tuning BP learning rate \u03b7 in [68] and in [69] respectively; and 3) a variant of BP, called resilient propagator (Rprop) was proposed in [70].", "startOffset": 87, "endOffset": 91}, {"referenceID": 63, "context": "Since the basic version of BP is sensitivity towards learning rate and momentum factor [15], several improvements were suggested by researchers: 1) a fast BP algorithm, called Quickpro was proposed in [66, 67]; 2) a delta-bar technique and an acceleration technique was suggested for tuning BP learning rate \u03b7 in [68] and in [69] respectively; and 3) a variant of BP, called resilient propagator (Rprop) was proposed in [70].", "startOffset": 201, "endOffset": 209}, {"referenceID": 64, "context": "Since the basic version of BP is sensitivity towards learning rate and momentum factor [15], several improvements were suggested by researchers: 1) a fast BP algorithm, called Quickpro was proposed in [66, 67]; 2) a delta-bar technique and an acceleration technique was suggested for tuning BP learning rate \u03b7 in [68] and in [69] respectively; and 3) a variant of BP, called resilient propagator (Rprop) was proposed in [70].", "startOffset": 201, "endOffset": 209}, {"referenceID": 65, "context": "Since the basic version of BP is sensitivity towards learning rate and momentum factor [15], several improvements were suggested by researchers: 1) a fast BP algorithm, called Quickpro was proposed in [66, 67]; 2) a delta-bar technique and an acceleration technique was suggested for tuning BP learning rate \u03b7 in [68] and in [69] respectively; and 3) a variant of BP, called resilient propagator (Rprop) was proposed in [70].", "startOffset": 313, "endOffset": 317}, {"referenceID": 66, "context": "Since the basic version of BP is sensitivity towards learning rate and momentum factor [15], several improvements were suggested by researchers: 1) a fast BP algorithm, called Quickpro was proposed in [66, 67]; 2) a delta-bar technique and an acceleration technique was suggested for tuning BP learning rate \u03b7 in [68] and in [69] respectively; and 3) a variant of BP, called resilient propagator (Rprop) was proposed in [70].", "startOffset": 325, "endOffset": 329}, {"referenceID": 67, "context": "Since the basic version of BP is sensitivity towards learning rate and momentum factor [15], several improvements were suggested by researchers: 1) a fast BP algorithm, called Quickpro was proposed in [66, 67]; 2) a delta-bar technique and an acceleration technique was suggested for tuning BP learning rate \u03b7 in [68] and in [69] respectively; and 3) a variant of BP, called resilient propagator (Rprop) was proposed in [70].", "startOffset": 420, "endOffset": 424}, {"referenceID": 67, "context": "The proposed Rprop improves determinism of convergence to global minima [70].", "startOffset": 72, "endOffset": 76}, {"referenceID": 68, "context": "However, it is not faster than the Quickpro, but still faster than BP [71].", "startOffset": 70, "endOffset": 74}, {"referenceID": 69, "context": "Contrary to BP, a second-order minimization method, called conjugate gradient (CG) can be used for weights optimization [72\u201374].", "startOffset": 120, "endOffset": 127}, {"referenceID": 70, "context": "Contrary to BP, a second-order minimization method, called conjugate gradient (CG) can be used for weights optimization [72\u201374].", "startOffset": 120, "endOffset": 127}, {"referenceID": 71, "context": "Contrary to BP, a second-order minimization method, called conjugate gradient (CG) can be used for weights optimization [72\u201374].", "startOffset": 120, "endOffset": 127}, {"referenceID": 72, "context": "Several variants of the CG were proposed in the past [75].", "startOffset": 53, "endOffset": 57}, {"referenceID": 62, "context": "Similar to the CG, many other variants of derivative-based conventional methods are used for weights optimization: Quasi-Newton [65], Gauss-Newton [76], or Levenberg-Marquardt [77].", "startOffset": 128, "endOffset": 132}, {"referenceID": 73, "context": "Similar to the CG, many other variants of derivative-based conventional methods are used for weights optimization: Quasi-Newton [65], Gauss-Newton [76], or Levenberg-Marquardt [77].", "startOffset": 147, "endOffset": 151}, {"referenceID": 74, "context": "Similar to the CG, many other variants of derivative-based conventional methods are used for weights optimization: Quasi-Newton [65], Gauss-Newton [76], or Levenberg-Marquardt [77].", "startOffset": 176, "endOffset": 180}, {"referenceID": 75, "context": "Quasi-Newton uses a second-order partial derivative (7) of error (4), and it computes its weight search direction by using Broyden-Fletcher-Goldfarb-Shanno (BFGS) method [78].", "startOffset": 170, "endOffset": 174}, {"referenceID": 74, "context": "problem, which suggests to using the sum of squared error (4) [77].", "startOffset": 62, "endOffset": 66}, {"referenceID": 76, "context": "Many researchers suggested that the Levenberg-Marquardt (LM) method outperforms BP, CG, and Quasi-Newton methods [79, 80].", "startOffset": 113, "endOffset": 121}, {"referenceID": 77, "context": "Many researchers suggested that the Levenberg-Marquardt (LM) method outperforms BP, CG, and Quasi-Newton methods [79, 80].", "startOffset": 113, "endOffset": 121}, {"referenceID": 78, "context": "Several other methods were proposed for the FNNs optimization are based on Kalman-filter [81, 82] and recursive least squares method [83].", "startOffset": 89, "endOffset": 97}, {"referenceID": 79, "context": "Several other methods were proposed for the FNNs optimization are based on Kalman-filter [81, 82] and recursive least squares method [83].", "startOffset": 133, "endOffset": 137}, {"referenceID": 13, "context": "Moreover, the gradient-decent methods such as BP [15], Online BFGS [84] can be applied for the stochastic as well as batch mode training of the FNNs.", "startOffset": 49, "endOffset": 53}, {"referenceID": 80, "context": "Moreover, the gradient-decent methods such as BP [15], Online BFGS [84] can be applied for the stochastic as well as batch mode training of the FNNs.", "startOffset": 67, "endOffset": 71}, {"referenceID": 81, "context": ", the possibility of dynamic learning), and faster training than that of batch mode [85].", "startOffset": 84, "endOffset": 88}, {"referenceID": 82, "context": "However, a batch mode (offline) training of an FNN can at least guarantee a local minima under a simple condition compared to a stochastic/online training, and for a larger dataset, batch mode training can be faster than stochastic training [86].", "startOffset": 241, "endOffset": 245}, {"referenceID": 83, "context": "Hence, the application of conventional algorithms is limited compared to the metaheuristic algorithms such as the genetic algorithm (GA) that can be directly applied to an FNN for its automatic structure determination and complexity reduction [87, 88].", "startOffset": 243, "endOffset": 251}, {"referenceID": 84, "context": "Hence, the application of conventional algorithms is limited compared to the metaheuristic algorithms such as the genetic algorithm (GA) that can be directly applied to an FNN for its automatic structure determination and complexity reduction [87, 88].", "startOffset": 243, "endOffset": 251}, {"referenceID": 85, "context": "However, to find a global optimum solution, any optimization algorithm must use two techniques: 1) exploration\u2014to search new and unknown areas in a search space, and 2) exploitation\u2014to take advantage of the already discovered solution [89].", "startOffset": 235, "endOffset": 239}, {"referenceID": 86, "context": "Metaheuristic is the procedure that implements nature-inspired heuristics to combine these two strategies [90].", "startOffset": 106, "endOffset": 110}, {"referenceID": 87, "context": "However, the optimization algorithms are often biased towards a specific class of problems, that is, \u201cthere is no such universal optimizer which may solve all class of problem,\u201d which is evident from no free lunch theorem [91].", "startOffset": 222, "endOffset": 226}, {"referenceID": 87, "context": "Wolpert and Macready [91] introduced no free lunch (NFL) theorem to answer the question, \u201cwhether a general purpose optimization algorithm exists.", "startOffset": 21, "endOffset": 25}, {"referenceID": 88, "context": "\u201d Moreover, Wolpert [92] introduced NFL for optimization algorithm to answer the question, \u201cHow does the set of problems F1 \u2282 F for which algorithm a1 performs better than algorithm a2 compares to the set F2 \u2282 F for which the reverse is true.", "startOffset": 20, "endOffset": 24}, {"referenceID": 87, "context": "To answer this question, Wolpert proposed NFL theorem, which says that \u201cthe average performance of any pair of algorithms across all possible problems is identical\u201d [91].", "startOffset": 165, "endOffset": 169}, {"referenceID": 89, "context": "\u201cA general purpose universal optimization strategy is impossible, and the only way one strategy can outperform another if it is specialized to the structure of the specific problem under consideration\u201d [93].", "startOffset": 202, "endOffset": 206}, {"referenceID": 90, "context": "[94] argue that the NFL theorem [91] holds only for the set of problems which are closed under permutation (c.", "startOffset": 0, "endOffset": 4}, {"referenceID": 87, "context": "[94] argue that the NFL theorem [91] holds only for the set of problems which are closed under permutation (c.", "startOffset": 32, "endOffset": 36}, {"referenceID": 91, "context": "p [95].", "startOffset": 2, "endOffset": 6}, {"referenceID": 92, "context": "For example, algorithms like simulated annealing (SA) [96], tabu search (TS) [97], variable neighborhood search (VNS) [98], greedy randomized adaptive search (GRAP) [99], etc.", "startOffset": 54, "endOffset": 58}, {"referenceID": 93, "context": "For example, algorithms like simulated annealing (SA) [96], tabu search (TS) [97], variable neighborhood search (VNS) [98], greedy randomized adaptive search (GRAP) [99], etc.", "startOffset": 77, "endOffset": 81}, {"referenceID": 94, "context": "For example, algorithms like simulated annealing (SA) [96], tabu search (TS) [97], variable neighborhood search (VNS) [98], greedy randomized adaptive search (GRAP) [99], etc.", "startOffset": 118, "endOffset": 122}, {"referenceID": 95, "context": "For example, algorithms like simulated annealing (SA) [96], tabu search (TS) [97], variable neighborhood search (VNS) [98], greedy randomized adaptive search (GRAP) [99], etc.", "startOffset": 165, "endOffset": 169}, {"referenceID": 96, "context": "It uses Monte Carlo method [100] to determine the acceptance probability of a newly generated solution in the neighborhood of the current solution.", "startOffset": 27, "endOffset": 32}, {"referenceID": 92, "context": "Hence, for a given search space, SA should guide a solution towards a global optimal solution [96,101].", "startOffset": 94, "endOffset": 102}, {"referenceID": 97, "context": "Hence, for a given search space, SA should guide a solution towards a global optimal solution [96,101].", "startOffset": 94, "endOffset": 102}, {"referenceID": 93, "context": "Similarly, TS is inspired by the human behavior of tabooing objects [97].", "startOffset": 68, "endOffset": 72}, {"referenceID": 83, "context": "Evolutionary algorithms (EA) Genetic algorithms (GA) [87, 88], evolutionary programming (EP) [102], evolutionary strategy (ES) [103], genetic programming (GP) [104], differential evolution [105], etc.", "startOffset": 53, "endOffset": 61}, {"referenceID": 84, "context": "Evolutionary algorithms (EA) Genetic algorithms (GA) [87, 88], evolutionary programming (EP) [102], evolutionary strategy (ES) [103], genetic programming (GP) [104], differential evolution [105], etc.", "startOffset": 53, "endOffset": 61}, {"referenceID": 98, "context": "Evolutionary algorithms (EA) Genetic algorithms (GA) [87, 88], evolutionary programming (EP) [102], evolutionary strategy (ES) [103], genetic programming (GP) [104], differential evolution [105], etc.", "startOffset": 93, "endOffset": 98}, {"referenceID": 99, "context": "Evolutionary algorithms (EA) Genetic algorithms (GA) [87, 88], evolutionary programming (EP) [102], evolutionary strategy (ES) [103], genetic programming (GP) [104], differential evolution [105], etc.", "startOffset": 127, "endOffset": 132}, {"referenceID": 100, "context": "Evolutionary algorithms (EA) Genetic algorithms (GA) [87, 88], evolutionary programming (EP) [102], evolutionary strategy (ES) [103], genetic programming (GP) [104], differential evolution [105], etc.", "startOffset": 189, "endOffset": 194}, {"referenceID": 84, "context": ", are the algorithms inspired by the dynamics of natural selection and use the operators, such as selection, crossover, and mutation to find a near-optimal solution [88].", "startOffset": 165, "endOffset": 169}, {"referenceID": 84, "context": "The differences between EAs can be briefly stated as follows: GA uses genetic operators, such as selection, crossover, and mutation to search optimum genetic vector from a search space [88];", "startOffset": 185, "endOffset": 189}, {"referenceID": 99, "context": "whereas, only the mutation operator are used in ES to evolve a real vector solution [103].", "startOffset": 84, "endOffset": 89}, {"referenceID": 98, "context": "On the other hand, GP searches an optimum program structure from a topological search space of computer programs [104] and EP are used for evolving parameters of a computer program whose structure is kept fixed [102].", "startOffset": 211, "endOffset": 216}, {"referenceID": 101, "context": "Particle swarm algorithm (PSO) [106], ant colony optimization (ACO) [107], artificial bee colony (ABC) [108], bacterial foraging optimization (BFO) [109], etc.", "startOffset": 31, "endOffset": 36}, {"referenceID": 102, "context": "Particle swarm algorithm (PSO) [106], ant colony optimization (ACO) [107], artificial bee colony (ABC) [108], bacterial foraging optimization (BFO) [109], etc.", "startOffset": 68, "endOffset": 73}, {"referenceID": 103, "context": "Particle swarm algorithm (PSO) [106], ant colony optimization (ACO) [107], artificial bee colony (ABC) [108], bacterial foraging optimization (BFO) [109], etc.", "startOffset": 103, "endOffset": 108}, {"referenceID": 104, "context": "Particle swarm algorithm (PSO) [106], ant colony optimization (ACO) [107], artificial bee colony (ABC) [108], bacterial foraging optimization (BFO) [109], etc.", "startOffset": 148, "endOffset": 153}, {"referenceID": 101, "context": "In PSO, a swarm, as a whole, is like a flock of birds (particles, which are the weight vectors) that collectively foraging (explore search space) for food (best weight vector) and is likely to move close to an optimum food-source [106, 110].", "startOffset": 230, "endOffset": 240}, {"referenceID": 101, "context": "Each particle determines its movement using knowledge of its best locations, global best location, and random perturbations [106,111].", "startOffset": 124, "endOffset": 133}, {"referenceID": 105, "context": "Each particle determines its movement using knowledge of its best locations, global best location, and random perturbations [106,111].", "startOffset": 124, "endOffset": 133}, {"referenceID": 106, "context": "ACO takes advantage of ants ability to choose the shortest path to a food source by communicating among each other\u2019s using a pheromone secretion [112].", "startOffset": 145, "endOffset": 150}, {"referenceID": 102, "context": "This behavior of ants led to the development of ACO algorithm [107].", "startOffset": 62, "endOffset": 67}, {"referenceID": 103, "context": "Similarly, in ABC, three kinds of honey bees, such as employed bee, onlooker bee, and scout bee are responsible for searching food source [108].", "startOffset": 138, "endOffset": 143}, {"referenceID": 107, "context": "There are algorithms inspired by the behavior of animals, birds, and insects, such as gray wolf optimization (GWO) [113], flower pollination (FP) [114], cuckoo search (CS) [115], firefly (FF) [116], etc.", "startOffset": 115, "endOffset": 120}, {"referenceID": 108, "context": "There are algorithms inspired by the behavior of animals, birds, and insects, such as gray wolf optimization (GWO) [113], flower pollination (FP) [114], cuckoo search (CS) [115], firefly (FF) [116], etc.", "startOffset": 146, "endOffset": 151}, {"referenceID": 109, "context": "There are algorithms inspired by the behavior of animals, birds, and insects, such as gray wolf optimization (GWO) [113], flower pollination (FP) [114], cuckoo search (CS) [115], firefly (FF) [116], etc.", "startOffset": 172, "endOffset": 177}, {"referenceID": 110, "context": "There are algorithms inspired by the behavior of animals, birds, and insects, such as gray wolf optimization (GWO) [113], flower pollination (FP) [114], cuckoo search (CS) [115], firefly (FF) [116], etc.", "startOffset": 192, "endOffset": 197}, {"referenceID": 111, "context": "chemistry, such as harmony search (HS) [117], central force optimization (CFO) [118], gravitational search optimization (GSO) [119], etc.", "startOffset": 39, "endOffset": 44}, {"referenceID": 112, "context": "chemistry, such as harmony search (HS) [117], central force optimization (CFO) [118], gravitational search optimization (GSO) [119], etc.", "startOffset": 79, "endOffset": 84}, {"referenceID": 113, "context": "chemistry, such as harmony search (HS) [117], central force optimization (CFO) [118], gravitational search optimization (GSO) [119], etc.", "startOffset": 126, "endOffset": 131}, {"referenceID": 114, "context": "A detailed list and classification of metaheuristic algorithms are provided in [120].", "startOffset": 79, "endOffset": 84}, {"referenceID": 115, "context": "The growing number of metaheuristic algorithms has drawn researchers to examine the metaphor, the novelty, and the significant differences among the metaheuristic algorithms [121, 122].", "startOffset": 174, "endOffset": 184}, {"referenceID": 116, "context": "The growing number of metaheuristic algorithms has drawn researchers to examine the metaphor, the novelty, and the significant differences among the metaheuristic algorithms [121, 122].", "startOffset": 174, "endOffset": 184}, {"referenceID": 116, "context": "In [122], the author provided an insight of the metaheuristic developed over the time, starting from SA to TS, EA, ACO, HS, etc.", "startOffset": 3, "endOffset": 8}, {"referenceID": 117, "context": "A paradigm of hybrid algorithms, called memetic algorithm gave a methodological concept for combining two or more metaheuristics (global and local) to explore a search space efficiently and to find a global optimal solution [123].", "startOffset": 224, "endOffset": 229}, {"referenceID": 118, "context": "On the other hand, the metaheuristics are good in global search, but they suffer premature convergence [124, 125].", "startOffset": 103, "endOffset": 113}, {"referenceID": 119, "context": "On the other hand, the metaheuristics are good in global search, but they suffer premature convergence [124, 125].", "startOffset": 103, "endOffset": 113}, {"referenceID": 120, "context": "Under the definition of memetic algorithms, researchers combine EAs with conventional algorithms [126].", "startOffset": 97, "endOffset": 102}, {"referenceID": 121, "context": "For example, the effectiveness of global (GA) and local search (BP) combination is explained in [127,128].", "startOffset": 96, "endOffset": 105}, {"referenceID": 122, "context": "For example, the effectiveness of global (GA) and local search (BP) combination is explained in [127,128].", "startOffset": 96, "endOffset": 105}, {"referenceID": 123, "context": "Similarly, a hybrid PSO and BP algorithms for optimizing FNN were found useful in obtaining better approximation than using one of them alone [129].", "startOffset": 142, "endOffset": 147}, {"referenceID": 124, "context": "2 was illustrated in [130], where ABC was applied for searching initial weights and LM was applied for optimizing the already discovered weights.", "startOffset": 21, "endOffset": 26}, {"referenceID": 125, "context": "An example of effectively combining two metaheuristic GA and PSO is illustrated in [131], where both GA and PSO optimized the same population.", "startOffset": 83, "endOffset": 88}, {"referenceID": 126, "context": "WI2 WI1 Figure 2: Metaheuristic may be used for finding initial weights WI2 and conventional algorithms may be for finding global optima P2 and vice versa [132].", "startOffset": 155, "endOffset": 160}, {"referenceID": 127, "context": "Now, there are single-solution based and population based metaheuristics [133].", "startOffset": 73, "endOffset": 78}, {"referenceID": 128, "context": "Yao and Liu [134] identified evolution at various components of FNN that fall into the spectrum of metaheuristic design of FNN shown in Fig.", "startOffset": 12, "endOffset": 17}, {"referenceID": 129, "context": "Engle\u2019s [135] work on FNN weight vector optimization using SA was the first evidence of metaheuristic application.", "startOffset": 8, "endOffset": 13}, {"referenceID": 130, "context": "SA based FNN weight optimization was found to be performing better in comparison to conventional approaches [136\u2013138].", "startOffset": 108, "endOffset": 117}, {"referenceID": 131, "context": "SA based FNN weight optimization was found to be performing better in comparison to conventional approaches [136\u2013138].", "startOffset": 108, "endOffset": 117}, {"referenceID": 132, "context": "SA based FNN weight optimization was found to be performing better in comparison to conventional approaches [136\u2013138].", "startOffset": 108, "endOffset": 117}, {"referenceID": 129, "context": "Similar to Engle\u2019s [135] approach of phenotype to genotype mapping and vice versa, in [139], the FNN weights optimization was performed using TS.", "startOffset": 19, "endOffset": 24}, {"referenceID": 133, "context": "Similar to Engle\u2019s [135] approach of phenotype to genotype mapping and vice versa, in [139], the FNN weights optimization was performed using TS.", "startOffset": 86, "endOffset": 91}, {"referenceID": 134, "context": "In [140], an improvised TS, called reactive tabu search was used for optimizing weights.", "startOffset": 3, "endOffset": 8}, {"referenceID": 135, "context": "Several studies show that TS when used for optimizing FNN weights, outperformed BP and SA algorithm [141,142].", "startOffset": 100, "endOffset": 109}, {"referenceID": 136, "context": "Several studies show that TS when used for optimizing FNN weights, outperformed BP and SA algorithm [141,142].", "startOffset": 100, "endOffset": 109}, {"referenceID": 84, "context": "Hence, they have a better exploration ability than SA, TS, BP, CG, and other single solution based algorithms [88,110].", "startOffset": 110, "endOffset": 118}, {"referenceID": 84, "context": "Goldberg and Holland [88] gave the idea of FNN training using GA.", "startOffset": 21, "endOffset": 25}, {"referenceID": 137, "context": "However, Whitley and Hanson [143] were the first to propose \u201cGENITOR,\u201d a GA based FNN training procedure that used binary-coded chromosome (Fig.", "startOffset": 28, "endOffset": 33}, {"referenceID": 138, "context": "Many others followed the idea of GENITOR with some additional improvements such as connectivity optimization and reduced search space introduction [144, 145].", "startOffset": 147, "endOffset": 157}, {"referenceID": 139, "context": "Many others followed the idea of GENITOR with some additional improvements such as connectivity optimization and reduced search space introduction [144, 145].", "startOffset": 147, "endOffset": 157}, {"referenceID": 140, "context": "On the other hand, in [146], a binary gray", "startOffset": 22, "endOffset": 27}, {"referenceID": 141, "context": "4(c)) directly [147\u2013151].", "startOffset": 15, "endOffset": 24}, {"referenceID": 142, "context": "4(c)) directly [147\u2013151].", "startOffset": 15, "endOffset": 24}, {"referenceID": 143, "context": "4(c)) directly [147\u2013151].", "startOffset": 15, "endOffset": 24}, {"referenceID": 144, "context": "4(c)) directly [147\u2013151].", "startOffset": 15, "endOffset": 24}, {"referenceID": 145, "context": "4(c)) directly [147\u2013151].", "startOffset": 15, "endOffset": 24}, {"referenceID": 141, "context": ", were defined, for operating on the real-valued chromosome [147].", "startOffset": 60, "endOffset": 65}, {"referenceID": 146, "context": "On the other hand, a matrix-based representation of weights, where a column-wise and a row-wise crossover operators were also defined [152].", "startOffset": 134, "endOffset": 139}, {"referenceID": 147, "context": "The GA-based real coded weights optimization outperforms BP and its variants for solving real-world applications [153\u2013156].", "startOffset": 113, "endOffset": 122}, {"referenceID": 148, "context": "The GA-based real coded weights optimization outperforms BP and its variants for solving real-world applications [153\u2013156].", "startOffset": 113, "endOffset": 122}, {"referenceID": 149, "context": "The GA-based real coded weights optimization outperforms BP and its variants for solving real-world applications [153\u2013156].", "startOffset": 113, "endOffset": 122}, {"referenceID": 150, "context": "The GA-based real coded weights optimization outperforms BP and its variants for solving real-world applications [153\u2013156].", "startOffset": 113, "endOffset": 122}, {"referenceID": 100, "context": "Moreover, an evolutionary inspired algorithm, called differential evolution (DE) [105,157] that imitates mutation and crossover operator to solve complex continuous optimization problems was found to be performing efficiently for real-valued weight vector optimization [158\u2013160].", "startOffset": 81, "endOffset": 90}, {"referenceID": 151, "context": "Moreover, an evolutionary inspired algorithm, called differential evolution (DE) [105,157] that imitates mutation and crossover operator to solve complex continuous optimization problems was found to be performing efficiently for real-valued weight vector optimization [158\u2013160].", "startOffset": 81, "endOffset": 90}, {"referenceID": 152, "context": "Moreover, an evolutionary inspired algorithm, called differential evolution (DE) [105,157] that imitates mutation and crossover operator to solve complex continuous optimization problems was found to be performing efficiently for real-valued weight vector optimization [158\u2013160].", "startOffset": 269, "endOffset": 278}, {"referenceID": 153, "context": "Moreover, an evolutionary inspired algorithm, called differential evolution (DE) [105,157] that imitates mutation and crossover operator to solve complex continuous optimization problems was found to be performing efficiently for real-valued weight vector optimization [158\u2013160].", "startOffset": 269, "endOffset": 278}, {"referenceID": 154, "context": "Moreover, an evolutionary inspired algorithm, called differential evolution (DE) [105,157] that imitates mutation and crossover operator to solve complex continuous optimization problems was found to be performing efficiently for real-valued weight vector optimization [158\u2013160].", "startOffset": 269, "endOffset": 278}, {"referenceID": 155, "context": "It was found that PSO guides a population of the FNN weight vectors towards an optimum population [161,162].", "startOffset": 98, "endOffset": 107}, {"referenceID": 156, "context": "It was found that PSO guides a population of the FNN weight vectors towards an optimum population [161,162].", "startOffset": 98, "endOffset": 107}, {"referenceID": 157, "context": "A cooperative PSO, which suggests to splitting a solution vector into n parts, where each part optimized by a swarm of m particles [163,164].", "startOffset": 131, "endOffset": 140}, {"referenceID": 158, "context": "A cooperative PSO, which suggests to splitting a solution vector into n parts, where each part optimized by a swarm of m particles [163,164].", "startOffset": 131, "endOffset": 140}, {"referenceID": 159, "context": "Similarly, a multi-phase PSO was proposed in which particle position was updated only when improvement in location was found; otherwise, the location was copied as-it-is into the next generation [165].", "startOffset": 195, "endOffset": 200}, {"referenceID": 160, "context": "[166].", "startOffset": 0, "endOffset": 5}, {"referenceID": 161, "context": "Similarly, a hierarchical particle swarm optimization was used to design a beta basis function neural network [167].", "startOffset": 110, "endOffset": 115}, {"referenceID": 162, "context": "The continuous version of ACO [168] was efficiently applied to optimize the FNN weight vector [169].", "startOffset": 30, "endOffset": 35}, {"referenceID": 163, "context": "The continuous version of ACO [168] was efficiently applied to optimize the FNN weight vector [169].", "startOffset": 94, "endOffset": 99}, {"referenceID": 164, "context": "[170,171].", "startOffset": 0, "endOffset": 9}, {"referenceID": 165, "context": "[170,171].", "startOffset": 0, "endOffset": 9}, {"referenceID": 166, "context": "ABC was efficiently applied on weight vector for optimizing the FNNs [172\u2013174].", "startOffset": 69, "endOffset": 78}, {"referenceID": 167, "context": "ABC was efficiently applied on weight vector for optimizing the FNNs [172\u2013174].", "startOffset": 69, "endOffset": 78}, {"referenceID": 168, "context": "ABC was efficiently applied on weight vector for optimizing the FNNs [172\u2013174].", "startOffset": 69, "endOffset": 78}, {"referenceID": 111, "context": "Similarly, considering the efficiency of HS algorithm\u2014that has a slow convergence rate, but guarantees a near-optimum solution [117]\u2014many researchers applied HS for optimizing weight vector of the FNNs [175, 176].", "startOffset": 127, "endOffset": 132}, {"referenceID": 169, "context": "Similarly, considering the efficiency of HS algorithm\u2014that has a slow convergence rate, but guarantees a near-optimum solution [117]\u2014many researchers applied HS for optimizing weight vector of the FNNs [175, 176].", "startOffset": 202, "endOffset": 212}, {"referenceID": 170, "context": "Similarly, considering the efficiency of HS algorithm\u2014that has a slow convergence rate, but guarantees a near-optimum solution [117]\u2014many researchers applied HS for optimizing weight vector of the FNNs [175, 176].", "startOffset": 202, "endOffset": 212}, {"referenceID": 111, "context": "Moreover, the efficiency of HS comes from using m many harmonies (weight vectors), and iteratively improvising each harmony by computing new harmony (new solution vectors) using heuristic inspired by music pitch modification [117,177,178].", "startOffset": 225, "endOffset": 238}, {"referenceID": 171, "context": "Moreover, the efficiency of HS comes from using m many harmonies (weight vectors), and iteratively improvising each harmony by computing new harmony (new solution vectors) using heuristic inspired by music pitch modification [117,177,178].", "startOffset": 225, "endOffset": 238}, {"referenceID": 172, "context": "Moreover, the efficiency of HS comes from using m many harmonies (weight vectors), and iteratively improvising each harmony by computing new harmony (new solution vectors) using heuristic inspired by music pitch modification [117,177,178].", "startOffset": 225, "endOffset": 238}, {"referenceID": 173, "context": "For example, the application of FF, CS, GSO, BFO, and CFO algorithms for the FNN weights optimization is available in [179], [180], [181], [182,183], [184] respectively.", "startOffset": 118, "endOffset": 123}, {"referenceID": 174, "context": "For example, the application of FF, CS, GSO, BFO, and CFO algorithms for the FNN weights optimization is available in [179], [180], [181], [182,183], [184] respectively.", "startOffset": 125, "endOffset": 130}, {"referenceID": 175, "context": "For example, the application of FF, CS, GSO, BFO, and CFO algorithms for the FNN weights optimization is available in [179], [180], [181], [182,183], [184] respectively.", "startOffset": 132, "endOffset": 137}, {"referenceID": 176, "context": "For example, the application of FF, CS, GSO, BFO, and CFO algorithms for the FNN weights optimization is available in [179], [180], [181], [182,183], [184] respectively.", "startOffset": 139, "endOffset": 148}, {"referenceID": 177, "context": "For example, the application of FF, CS, GSO, BFO, and CFO algorithms for the FNN weights optimization is available in [179], [180], [181], [182,183], [184] respectively.", "startOffset": 139, "endOffset": 148}, {"referenceID": 178, "context": "For example, the application of FF, CS, GSO, BFO, and CFO algorithms for the FNN weights optimization is available in [179], [180], [181], [182,183], [184] respectively.", "startOffset": 150, "endOffset": 155}, {"referenceID": 179, "context": "Moreover, a comparative study showed that FF algorithm performed better than that of BP, GA, and ABC for weight vector optimization [185].", "startOffset": 132, "endOffset": 137}, {"referenceID": 180, "context": "In [186] a detailed study explains the application of the local and global metaheuristic algorithm for FNN optimization.", "startOffset": 3, "endOffset": 8}, {"referenceID": 94, "context": "For example, local search algorithms like SA, TS, GRAP, VNS [98], estimations of distribution algorithm [187] and global search algorithms like GA, ACO, and memetic algorithm, were examined thoroughly in [186].", "startOffset": 60, "endOffset": 64}, {"referenceID": 181, "context": "For example, local search algorithms like SA, TS, GRAP, VNS [98], estimations of distribution algorithm [187] and global search algorithms like GA, ACO, and memetic algorithm, were examined thoroughly in [186].", "startOffset": 104, "endOffset": 109}, {"referenceID": 180, "context": "For example, local search algorithms like SA, TS, GRAP, VNS [98], estimations of distribution algorithm [187] and global search algorithms like GA, ACO, and memetic algorithm, were examined thoroughly in [186].", "startOffset": 204, "endOffset": 209}, {"referenceID": 182, "context": "Additionally, many researchers studied the performance of metaheuristic algorithms for the training of the FNN and reported that the metaheuristic approaches outperform all the conventional methods by a huge margin [188\u2013190].", "startOffset": 215, "endOffset": 224}, {"referenceID": 183, "context": "Additionally, many researchers studied the performance of metaheuristic algorithms for the training of the FNN and reported that the metaheuristic approaches outperform all the conventional methods by a huge margin [188\u2013190].", "startOffset": 215, "endOffset": 224}, {"referenceID": 184, "context": "Additionally, many researchers studied the performance of metaheuristic algorithms for the training of the FNN and reported that the metaheuristic approaches outperform all the conventional methods by a huge margin [188\u2013190].", "startOffset": 215, "endOffset": 224}, {"referenceID": 125, "context": "A hybrid GA and PSO approach for optimizing the FNN were proposed in [131], where both GA and PSO were suggested to run over the same population\u2014randomly generated population W of m individuals (the same individual was treated as a chromosome in GA and a particle in PSO).", "startOffset": 69, "endOffset": 74}, {"referenceID": 185, "context": "Similarly, a PSO and SA based hybrid algorithm for optimizing FNN were proposed in [191], where, in each iteration, each PSO particle was governed by SA metropolis criteria [100] that determined global best particle for PSO algorithm.", "startOffset": 83, "endOffset": 88}, {"referenceID": 96, "context": "Similarly, a PSO and SA based hybrid algorithm for optimizing FNN were proposed in [191], where, in each iteration, each PSO particle was governed by SA metropolis criteria [100] that determined global best particle for PSO algorithm.", "startOffset": 173, "endOffset": 178}, {"referenceID": 186, "context": "There are several other hybrid algorithm examples available in the literature: a hybrid PSO and GA [192]; hybrid GA and DE [193]; hybrid PSO and GSO [194]; and hybrid PSO and optimal foraging theory [195].", "startOffset": 99, "endOffset": 104}, {"referenceID": 187, "context": "There are several other hybrid algorithm examples available in the literature: a hybrid PSO and GA [192]; hybrid GA and DE [193]; hybrid PSO and GSO [194]; and hybrid PSO and optimal foraging theory [195].", "startOffset": 123, "endOffset": 128}, {"referenceID": 188, "context": "There are several other hybrid algorithm examples available in the literature: a hybrid PSO and GA [192]; hybrid GA and DE [193]; hybrid PSO and GSO [194]; and hybrid PSO and optimal foraging theory [195].", "startOffset": 149, "endOffset": 154}, {"referenceID": 189, "context": "There are several other hybrid algorithm examples available in the literature: a hybrid PSO and GA [192]; hybrid GA and DE [193]; hybrid PSO and GSO [194]; and hybrid PSO and optimal foraging theory [195].", "startOffset": 199, "endOffset": 204}, {"referenceID": 63, "context": "The basic architecture optimization approach is a cascade correlation learning, which iteratively adds nodes to hidden layer to construct optimum architecture [66].", "startOffset": 159, "endOffset": 163}, {"referenceID": 190, "context": "Moreover, a constructive (add node iteratively) and destructive (prune nodes iteratively) method [196].", "startOffset": 97, "endOffset": 102}, {"referenceID": 0, "context": "u \u2192 [ 1 1 1 1 ] , z \u2192 [ 0 0 0 0 ] , c \u2192 [ 1 0 1 0 ] ,", "startOffset": 4, "endOffset": 15}, {"referenceID": 0, "context": "u \u2192 [ 1 1 1 1 ] , z \u2192 [ 0 0 0 0 ] , c \u2192 [ 1 0 1 0 ] ,", "startOffset": 4, "endOffset": 15}, {"referenceID": 0, "context": "u \u2192 [ 1 1 1 1 ] , z \u2192 [ 0 0 0 0 ] , c \u2192 [ 1 0 1 0 ] ,", "startOffset": 4, "endOffset": 15}, {"referenceID": 0, "context": "u \u2192 [ 1 1 1 1 ] , z \u2192 [ 0 0 0 0 ] , c \u2192 [ 1 0 1 0 ] ,", "startOffset": 4, "endOffset": 15}, {"referenceID": 0, "context": "u \u2192 [ 1 1 1 1 ] , z \u2192 [ 0 0 0 0 ] , c \u2192 [ 1 0 1 0 ] ,", "startOffset": 40, "endOffset": 51}, {"referenceID": 0, "context": "u \u2192 [ 1 1 1 1 ] , z \u2192 [ 0 0 0 0 ] , c \u2192 [ 1 0 1 0 ] ,", "startOffset": 40, "endOffset": 51}, {"referenceID": 0, "context": "a \u2192 [ 1 0 0 0 ] , i \u2192 [ 1 0 0 1 ] ,", "startOffset": 4, "endOffset": 15}, {"referenceID": 0, "context": "a \u2192 [ 1 0 0 0 ] , i \u2192 [ 1 0 0 1 ] ,", "startOffset": 22, "endOffset": 33}, {"referenceID": 0, "context": "a \u2192 [ 1 0 0 0 ] , i \u2192 [ 1 0 0 1 ] ,", "startOffset": 22, "endOffset": 33}, {"referenceID": 191, "context": "5(a), 5(b), 5(c) can be used for architecture optimization, which is equivalent to searching optimum architecture from a compact space of FNN topology [197,198].", "startOffset": 151, "endOffset": 160}, {"referenceID": 192, "context": "5(a), 5(b), 5(c) can be used for architecture optimization, which is equivalent to searching optimum architecture from a compact space of FNN topology [197,198].", "startOffset": 151, "endOffset": 160}, {"referenceID": 193, "context": "5(a)) was proposed in [199, 200], where authors used an adjacency matrix (Fig.", "startOffset": 22, "endOffset": 32}, {"referenceID": 194, "context": "5(a)) was proposed in [199, 200], where authors used an adjacency matrix (Fig.", "startOffset": 22, "endOffset": 32}, {"referenceID": 195, "context": "Therefore, if only the network\u2019s structural information can be encoded into genotype, then, it will avoid chromosome length problem [201].", "startOffset": 132, "endOffset": 137}, {"referenceID": 196, "context": "Additionally, the encoded network structural information can be accessed using rule-based recursive equation [202].", "startOffset": 109, "endOffset": 114}, {"referenceID": 197, "context": "Moreover, the represented parametric/structural information into the chromosome can indirectly provide access to the rest of the structural details from a predefined archive (parametric information) [203].", "startOffset": 199, "endOffset": 204}, {"referenceID": 198, "context": "Hence, a rule based encoding scheme allows a better FNN architecture optimization than a direct encoding scheme [204].", "startOffset": 112, "endOffset": 117}, {"referenceID": 199, "context": "It is evident from a fractal configured FNN representation in [205], where authors define each node using parameters, namely, edge code, input coefficient, and output coefficient.", "startOffset": 62, "endOffset": 67}, {"referenceID": 200, "context": "Similarly, in [206], GA was applied to evolve each layer separately and in [207], a grammar encoding and colonial competitive algorithm were proposed.", "startOffset": 14, "endOffset": 19}, {"referenceID": 201, "context": "Similarly, in [206], GA was applied to evolve each layer separately and in [207], a grammar encoding and colonial competitive algorithm were proposed.", "startOffset": 75, "endOffset": 80}, {"referenceID": 202, "context": ", am\u3009 is obtained [208], which can be optimized by using metaheuristics.", "startOffset": 18, "endOffset": 23}, {"referenceID": 203, "context": "Such examples are as follows: in [209], a PSO-PSO method was proposed, in which a PSO (inner PSO block) was applied for optimizing weights that were nested under another PSO (outer PSO block) which was applied for optimizing the architecture of FNN by adding or deleting hidden node.", "startOffset": 33, "endOffset": 38}, {"referenceID": 204, "context": "Similarly, in [210, 211], a hybrid Taguchi-genetic algorithm was proposed for optimizing the FNN architecture and weights, where authors used a genetic representation of the weights, but they select structure using constructive method (by adding hidden nodes one-by-one).", "startOffset": 14, "endOffset": 24}, {"referenceID": 205, "context": "Similarly, in [210, 211], a hybrid Taguchi-genetic algorithm was proposed for optimizing the FNN architecture and weights, where authors used a genetic representation of the weights, but they select structure using constructive method (by adding hidden nodes one-by-one).", "startOffset": 14, "endOffset": 24}, {"referenceID": 206, "context": "A multidimensional PSO approach was proposed in [212] for constructing FNN automatically by using an architectural (topological) space.", "startOffset": 48, "endOffset": 53}, {"referenceID": 207, "context": "However, GP can optimize a phenotype itself, where genetic representation is not required [213].", "startOffset": 90, "endOffset": 95}, {"referenceID": 142, "context": "Therefore, EP and GP can be directly applied to a population FNN architecture to evolve an optimum FNN architecture [148,214,215].", "startOffset": 116, "endOffset": 129}, {"referenceID": 208, "context": "Therefore, EP and GP can be directly applied to a population FNN architecture to evolve an optimum FNN architecture [148,214,215].", "startOffset": 116, "endOffset": 129}, {"referenceID": 209, "context": "Therefore, EP and GP can be directly applied to a population FNN architecture to evolve an optimum FNN architecture [148,214,215].", "startOffset": 116, "endOffset": 129}, {"referenceID": 210, "context": ", [216, 217].", "startOffset": 2, "endOffset": 12}, {"referenceID": 211, "context": ", [216, 217].", "startOffset": 2, "endOffset": 12}, {"referenceID": 210, "context": "Such a variant of the FNN is convolutional neural networks (ConvNets), which is designed to process data from the multiple arrays form such as a color image composed of three 2D arrays [216,217].", "startOffset": 185, "endOffset": 194}, {"referenceID": 211, "context": "Such a variant of the FNN is convolutional neural networks (ConvNets), which is designed to process data from the multiple arrays form such as a color image composed of three 2D arrays [216,217].", "startOffset": 185, "endOffset": 194}, {"referenceID": 212, "context": "Hence, it efficiently receives 3D inputs and processes them to produce 3D outputs [218].", "startOffset": 82, "endOffset": 87}, {"referenceID": 213, "context": "In contrast to deep network paradigm, an extreme learning machine (ELM) based hierarchical learning framework (H-ELM) proposed in [219] claimed a faster learning than deep learning by ELM [220] based auto-encoding.", "startOffset": 130, "endOffset": 135}, {"referenceID": 214, "context": "In contrast to deep network paradigm, an extreme learning machine (ELM) based hierarchical learning framework (H-ELM) proposed in [219] claimed a faster learning than deep learning by ELM [220] based auto-encoding.", "startOffset": 188, "endOffset": 193}, {"referenceID": 213, "context": "The proposed H-ELM framework worked in two phases: unsupervised hierarchical feature representation and 2) supervised feature classification [219].", "startOffset": 141, "endOffset": 146}, {"referenceID": 215, "context": "Input layer optimization resembles feature reduction, which is traditionally performed separately by dimensionality reduction methods [221].", "startOffset": 134, "endOffset": 139}, {"referenceID": 216, "context": ", by feeding a subset of input features at the input layer than by feeding the whole set of input features enhances FNN\u2019s performance [222,223].", "startOffset": 134, "endOffset": 143}, {"referenceID": 217, "context": ", by feeding a subset of input features at the input layer than by feeding the whole set of input features enhances FNN\u2019s performance [222,223].", "startOffset": 134, "endOffset": 143}, {"referenceID": 216, "context": "EAs select a subset of input features for which FNN perform better than that of the complete feature set [222].", "startOffset": 105, "endOffset": 110}, {"referenceID": 218, "context": "\u201d Such mechanism of input layer optimization was found advantageous in improving NN performance [224].", "startOffset": 96, "endOffset": 101}, {"referenceID": 219, "context": "Moreover, binary PSO [225], which is a discrete optimization method was employed for selecting the input features which were binary coded [226, 227].", "startOffset": 21, "endOffset": 26}, {"referenceID": 220, "context": "Moreover, binary PSO [225], which is a discrete optimization method was employed for selecting the input features which were binary coded [226, 227].", "startOffset": 138, "endOffset": 148}, {"referenceID": 221, "context": "Moreover, binary PSO [225], which is a discrete optimization method was employed for selecting the input features which were binary coded [226, 227].", "startOffset": 138, "endOffset": 148}, {"referenceID": 220, "context": "In [226], a modified version of binary PSO was proposed where EA like mutation operator was applied to mutated binary vectors.", "startOffset": 3, "endOffset": 8}, {"referenceID": 222, "context": "Similarly, ACO, which traditional solves discrete optimization problem was applied to select input features and training of an FNN in a hybrid manner [228].", "startOffset": 150, "endOffset": 155}, {"referenceID": 223, "context": "In [229], an adaptive selection of input examples was performed by employing genetic selection, where two-point and one-point crossover operations created new example patterns.", "startOffset": 3, "endOffset": 8}, {"referenceID": 224, "context": "Additionally, in [230], an input example generation methods was proposed in which the input space was divided into many regions, and k-nearest neighbor method was applied to determine/generate a new virtual example, mainly for the sparse region of the input space.", "startOffset": 17, "endOffset": 22}, {"referenceID": 223, "context": "Hence, both the above methods of input example generation sought to enrich knowledge space for the FNN learning [229,230].", "startOffset": 112, "endOffset": 121}, {"referenceID": 224, "context": "Hence, both the above methods of input example generation sought to enrich knowledge space for the FNN learning [229,230].", "startOffset": 112, "endOffset": 121}, {"referenceID": 150, "context": "Primarily, node optimization can be addressed in three ways: 1) by choosing activation functions at the FNN active nodes from a set of activation functions [156, 231]; 2) by optimizing the arguments of activation function [232]; and 3) by placing a complete model at the nodes of a network [233,234].", "startOffset": 156, "endOffset": 166}, {"referenceID": 225, "context": "Primarily, node optimization can be addressed in three ways: 1) by choosing activation functions at the FNN active nodes from a set of activation functions [156, 231]; 2) by optimizing the arguments of activation function [232]; and 3) by placing a complete model at the nodes of a network [233,234].", "startOffset": 156, "endOffset": 166}, {"referenceID": 226, "context": "Primarily, node optimization can be addressed in three ways: 1) by choosing activation functions at the FNN active nodes from a set of activation functions [156, 231]; 2) by optimizing the arguments of activation function [232]; and 3) by placing a complete model at the nodes of a network [233,234].", "startOffset": 222, "endOffset": 227}, {"referenceID": 227, "context": "Primarily, node optimization can be addressed in three ways: 1) by choosing activation functions at the FNN active nodes from a set of activation functions [156, 231]; 2) by optimizing the arguments of activation function [232]; and 3) by placing a complete model at the nodes of a network [233,234].", "startOffset": 290, "endOffset": 299}, {"referenceID": 228, "context": "Primarily, node optimization can be addressed in three ways: 1) by choosing activation functions at the FNN active nodes from a set of activation functions [156, 231]; 2) by optimizing the arguments of activation function [232]; and 3) by placing a complete model at the nodes of a network [233,234].", "startOffset": 290, "endOffset": 299}, {"referenceID": 229, "context": "It was found that FNN performed better when it has non-homogeneous nodes (different activation function at different nodes) than that of the homogeneous nodes [235].", "startOffset": 159, "endOffset": 164}, {"referenceID": 225, "context": "In [231], evolution in FNN nodes were offered by selecting sigmoid and Gaussian function adaptively at the nodes [231].", "startOffset": 3, "endOffset": 8}, {"referenceID": 225, "context": "In [231], evolution in FNN nodes were offered by selecting sigmoid and Gaussian function adaptively at the nodes [231].", "startOffset": 113, "endOffset": 118}, {"referenceID": 230, "context": "Moreover, adaptation in both nodes and architecture using EAs, where the design of nodes was inspired by locus flight system and tailflip of crayfish [236], can further improve FNN performance [237].", "startOffset": 150, "endOffset": 155}, {"referenceID": 231, "context": "Moreover, adaptation in both nodes and architecture using EAs, where the design of nodes was inspired by locus flight system and tailflip of crayfish [236], can further improve FNN performance [237].", "startOffset": 193, "endOffset": 198}, {"referenceID": 232, "context": "For this purpose, in [238], an input dependent FNN that had a combined chromosome representation (Fig.", "startOffset": 21, "endOffset": 26}, {"referenceID": 233, "context": "On the other hand, to optimize nodes, a family competitive EA was proposed in [239],", "startOffset": 78, "endOffset": 83}, {"referenceID": 234, "context": "Many others found that the adaptation in FNN nodes by one of the methods mentioned above can improve FNN performance to some extent [240\u2013243].", "startOffset": 132, "endOffset": 141}, {"referenceID": 235, "context": "Many others found that the adaptation in FNN nodes by one of the methods mentioned above can improve FNN performance to some extent [240\u2013243].", "startOffset": 132, "endOffset": 141}, {"referenceID": 236, "context": "Many others found that the adaptation in FNN nodes by one of the methods mentioned above can improve FNN performance to some extent [240\u2013243].", "startOffset": 132, "endOffset": 141}, {"referenceID": 237, "context": "Many others found that the adaptation in FNN nodes by one of the methods mentioned above can improve FNN performance to some extent [240\u2013243].", "startOffset": 132, "endOffset": 141}, {"referenceID": 227, "context": "Such modification leads to variate of neural network paradigms such as polynomial neural network [233,244], where the nodes are designed to as a polynomial function based on inputs to the nodes.", "startOffset": 97, "endOffset": 106}, {"referenceID": 238, "context": "Such modification leads to variate of neural network paradigms such as polynomial neural network [233,244], where the nodes are designed to as a polynomial function based on inputs to the nodes.", "startOffset": 97, "endOffset": 106}, {"referenceID": 239, "context": "Similarly, the nodes of a GMDH neural network is designed as an Ivakhnenko polynomial [245]; the nodes of a complex value neural network or multivalued neural network is designed with a complex value activation functions [234]; the node of spiking neural networks has specific behavior, in which a node signal is propagated to another node only if the intrinsic quality of neural activation value is above a defined threshold [246]; the nodes of fuzzy neural network paradigm is designed using the concepts of fuzzy theory [247]; the node and the architecture of the Quantum neural network are inspired by the quantum computing [248\u2013251].", "startOffset": 86, "endOffset": 91}, {"referenceID": 228, "context": "Similarly, the nodes of a GMDH neural network is designed as an Ivakhnenko polynomial [245]; the nodes of a complex value neural network or multivalued neural network is designed with a complex value activation functions [234]; the node of spiking neural networks has specific behavior, in which a node signal is propagated to another node only if the intrinsic quality of neural activation value is above a defined threshold [246]; the nodes of fuzzy neural network paradigm is designed using the concepts of fuzzy theory [247]; the node and the architecture of the Quantum neural network are inspired by the quantum computing [248\u2013251].", "startOffset": 221, "endOffset": 226}, {"referenceID": 240, "context": "Similarly, the nodes of a GMDH neural network is designed as an Ivakhnenko polynomial [245]; the nodes of a complex value neural network or multivalued neural network is designed with a complex value activation functions [234]; the node of spiking neural networks has specific behavior, in which a node signal is propagated to another node only if the intrinsic quality of neural activation value is above a defined threshold [246]; the nodes of fuzzy neural network paradigm is designed using the concepts of fuzzy theory [247]; the node and the architecture of the Quantum neural network are inspired by the quantum computing [248\u2013251].", "startOffset": 426, "endOffset": 431}, {"referenceID": 241, "context": "Similarly, the nodes of a GMDH neural network is designed as an Ivakhnenko polynomial [245]; the nodes of a complex value neural network or multivalued neural network is designed with a complex value activation functions [234]; the node of spiking neural networks has specific behavior, in which a node signal is propagated to another node only if the intrinsic quality of neural activation value is above a defined threshold [246]; the nodes of fuzzy neural network paradigm is designed using the concepts of fuzzy theory [247]; the node and the architecture of the Quantum neural network are inspired by the quantum computing [248\u2013251].", "startOffset": 523, "endOffset": 528}, {"referenceID": 242, "context": "Similarly, the nodes of a GMDH neural network is designed as an Ivakhnenko polynomial [245]; the nodes of a complex value neural network or multivalued neural network is designed with a complex value activation functions [234]; the node of spiking neural networks has specific behavior, in which a node signal is propagated to another node only if the intrinsic quality of neural activation value is above a defined threshold [246]; the nodes of fuzzy neural network paradigm is designed using the concepts of fuzzy theory [247]; the node and the architecture of the Quantum neural network are inspired by the quantum computing [248\u2013251].", "startOffset": 628, "endOffset": 637}, {"referenceID": 243, "context": "Similarly, the nodes of a GMDH neural network is designed as an Ivakhnenko polynomial [245]; the nodes of a complex value neural network or multivalued neural network is designed with a complex value activation functions [234]; the node of spiking neural networks has specific behavior, in which a node signal is propagated to another node only if the intrinsic quality of neural activation value is above a defined threshold [246]; the nodes of fuzzy neural network paradigm is designed using the concepts of fuzzy theory [247]; the node and the architecture of the Quantum neural network are inspired by the quantum computing [248\u2013251].", "startOffset": 628, "endOffset": 637}, {"referenceID": 244, "context": "Similarly, the nodes of a GMDH neural network is designed as an Ivakhnenko polynomial [245]; the nodes of a complex value neural network or multivalued neural network is designed with a complex value activation functions [234]; the node of spiking neural networks has specific behavior, in which a node signal is propagated to another node only if the intrinsic quality of neural activation value is above a defined threshold [246]; the nodes of fuzzy neural network paradigm is designed using the concepts of fuzzy theory [247]; the node and the architecture of the Quantum neural network are inspired by the quantum computing [248\u2013251].", "startOffset": 628, "endOffset": 637}, {"referenceID": 245, "context": "Similarly, the nodes of a GMDH neural network is designed as an Ivakhnenko polynomial [245]; the nodes of a complex value neural network or multivalued neural network is designed with a complex value activation functions [234]; the node of spiking neural networks has specific behavior, in which a node signal is propagated to another node only if the intrinsic quality of neural activation value is above a defined threshold [246]; the nodes of fuzzy neural network paradigm is designed using the concepts of fuzzy theory [247]; the node and the architecture of the Quantum neural network are inspired by the quantum computing [248\u2013251].", "startOffset": 628, "endOffset": 637}, {"referenceID": 140, "context": "For example, the optimization the learning rate and the mutation factor parameters of BP by applying some metaheuristics [146].", "startOffset": 121, "endOffset": 126}, {"referenceID": 195, "context": ", BP parameters) and learning rules are encoded onto a genotype [201,252].", "startOffset": 64, "endOffset": 73}, {"referenceID": 246, "context": ", BP parameters) and learning rules are encoded onto a genotype [201,252].", "startOffset": 64, "endOffset": 73}, {"referenceID": 247, "context": "However, formulating BP parameter such as learning rule, which is a dynamic concept, into a static chromosome is disadvantageous [253].", "startOffset": 129, "endOffset": 134}, {"referenceID": 247, "context": "Hence, a genetic coding for four components (current weight, activation function of the incoming node and outgoing nodes, input) local to weight in an FNN can encode [253].", "startOffset": 166, "endOffset": 171}, {"referenceID": 248, "context": "Moreover, assuming that each node in a network uses same learning rule, an evolution in learning was proposed in [254], where weights optimization related to a particular node depended only on the input/output at that node.", "startOffset": 113, "endOffset": 118}, {"referenceID": 249, "context": "Evolution in learning rule can be described as [255]:", "startOffset": 47, "endOffset": 52}, {"referenceID": 250, "context": "Figure 6: Meta-learning scheme (a), where LR is learning parameter, ND is activation function, AR is architecture, and WT is weight [256].", "startOffset": 132, "endOffset": 137}, {"referenceID": 250, "context": "In the meta-learning scheme, top down or bottom up optimization approach, which means, weights to learning rule and learning rules to weight optimization can be adopted [256].", "startOffset": 169, "endOffset": 174}, {"referenceID": 126, "context": "Yao [132, 255] summarized all such form of adaptation in evolutionary artificial neural network (EANN), which is a special class of artificial neural network, where in addition to learning; evolution is another fundamental form of adaptation.", "startOffset": 4, "endOffset": 14}, {"referenceID": 249, "context": "Yao [132, 255] summarized all such form of adaptation in evolutionary artificial neural network (EANN), which is a special class of artificial neural network, where in addition to learning; evolution is another fundamental form of adaptation.", "startOffset": 4, "endOffset": 14}, {"referenceID": 251, "context": "For examples, generalized acquisition of recurrent links (GNARL) [257], evolutionary programming net (EPNet) [258], neuroevolution of augmenting topologies (NEAT) [259], hypercube-based neuroevolution of augmenting topologies (HyperNEAT) [260], evolutionary acquisition of neural topologies (EANT2) [261], and heterogeneous flexible neural tree (HFNT) [262] optimizes both FNN structure and parameters (weights) using some direct or indirect encoding methods.", "startOffset": 65, "endOffset": 70}, {"referenceID": 252, "context": "For examples, generalized acquisition of recurrent links (GNARL) [257], evolutionary programming net (EPNet) [258], neuroevolution of augmenting topologies (NEAT) [259], hypercube-based neuroevolution of augmenting topologies (HyperNEAT) [260], evolutionary acquisition of neural topologies (EANT2) [261], and heterogeneous flexible neural tree (HFNT) [262] optimizes both FNN structure and parameters (weights) using some direct or indirect encoding methods.", "startOffset": 109, "endOffset": 114}, {"referenceID": 253, "context": "For examples, generalized acquisition of recurrent links (GNARL) [257], evolutionary programming net (EPNet) [258], neuroevolution of augmenting topologies (NEAT) [259], hypercube-based neuroevolution of augmenting topologies (HyperNEAT) [260], evolutionary acquisition of neural topologies (EANT2) [261], and heterogeneous flexible neural tree (HFNT) [262] optimizes both FNN structure and parameters (weights) using some direct or indirect encoding methods.", "startOffset": 163, "endOffset": 168}, {"referenceID": 254, "context": "For examples, generalized acquisition of recurrent links (GNARL) [257], evolutionary programming net (EPNet) [258], neuroevolution of augmenting topologies (NEAT) [259], hypercube-based neuroevolution of augmenting topologies (HyperNEAT) [260], evolutionary acquisition of neural topologies (EANT2) [261], and heterogeneous flexible neural tree (HFNT) [262] optimizes both FNN structure and parameters (weights) using some direct or indirect encoding methods.", "startOffset": 238, "endOffset": 243}, {"referenceID": 255, "context": "For examples, generalized acquisition of recurrent links (GNARL) [257], evolutionary programming net (EPNet) [258], neuroevolution of augmenting topologies (NEAT) [259], hypercube-based neuroevolution of augmenting topologies (HyperNEAT) [260], evolutionary acquisition of neural topologies (EANT2) [261], and heterogeneous flexible neural tree (HFNT) [262] optimizes both FNN structure and parameters (weights) using some direct or indirect encoding methods.", "startOffset": 299, "endOffset": 304}, {"referenceID": 256, "context": "For examples, generalized acquisition of recurrent links (GNARL) [257], evolutionary programming net (EPNet) [258], neuroevolution of augmenting topologies (NEAT) [259], hypercube-based neuroevolution of augmenting topologies (HyperNEAT) [260], evolutionary acquisition of neural topologies (EANT2) [261], and heterogeneous flexible neural tree (HFNT) [262] optimizes both FNN structure and parameters (weights) using some direct or indirect encoding methods.", "startOffset": 352, "endOffset": 357}, {"referenceID": 257, "context": "A structured genetic algorithm was proposed in [263], which simultaneously optimized both architectures and weights.", "startOffset": 47, "endOffset": 52}, {"referenceID": 53, "context": "It was found that the simultaneous optimization of both weight and architecture lead to a better generalization [56, 197, 264, 265].", "startOffset": 112, "endOffset": 131}, {"referenceID": 191, "context": "It was found that the simultaneous optimization of both weight and architecture lead to a better generalization [56, 197, 264, 265].", "startOffset": 112, "endOffset": 131}, {"referenceID": 258, "context": "It was found that the simultaneous optimization of both weight and architecture lead to a better generalization [56, 197, 264, 265].", "startOffset": 112, "endOffset": 131}, {"referenceID": 259, "context": "It was found that the simultaneous optimization of both weight and architecture lead to a better generalization [56, 197, 264, 265].", "startOffset": 112, "endOffset": 131}, {"referenceID": 252, "context": "problem in a GA, EP-based mutation mechanism for evolving FNN architecture was proposed in [258] is known as EPNet.", "startOffset": 91, "endOffset": 96}, {"referenceID": 253, "context": "A neuroevolution of augmenting topologies (NEAT) introduced in [259] was a GAbased evolution of an FNN phenotype as a whole, in which a special mutation and crossover operator were defined for manipulating nodes and connections of FNN.", "startOffset": 63, "endOffset": 68}, {"referenceID": 260, "context": "A virtual subpopulation approach was proposed in [266] for the optimization of FNN using EAs.", "startOffset": 49, "endOffset": 54}, {"referenceID": 261, "context": "Later, while indicating a permutation problem, crossover operator as a combinatorial optimization problem was proposed in which each hidden node was considered as a subnetwork and a complete network was evolved using the evolution of several subnetworks [267].", "startOffset": 254, "endOffset": 259}, {"referenceID": 260, "context": "A cooperative coevolution neural network process\u2014inspired by virtual subpopulation approach [266]\u2014 was proposed in [268], which was a symbiotic, adaptive neuroevolution (SANE) algorithm for constructing FNN in a dynamic environment.", "startOffset": 92, "endOffset": 97}, {"referenceID": 262, "context": "A cooperative coevolution neural network process\u2014inspired by virtual subpopulation approach [266]\u2014 was proposed in [268], which was a symbiotic, adaptive neuroevolution (SANE) algorithm for constructing FNN in a dynamic environment.", "startOffset": 115, "endOffset": 120}, {"referenceID": 263, "context": ", evolution in hidden nodes led to an evolution of the complete network [269].", "startOffset": 72, "endOffset": 77}, {"referenceID": 264, "context": "A concept of sparse neural trees, in which GP for evolving network structure and GA for parameter optimization was proposed in [270].", "startOffset": 127, "endOffset": 132}, {"referenceID": 265, "context": "Similarly, a flexible neural tree (FNT) concept, where GP was used for the adaptation in network structure and SA for the optimization of the parameters (including parameters of activation function) was proposed in [271, 272].", "startOffset": 215, "endOffset": 225}, {"referenceID": 266, "context": "Similarly, a flexible neural tree (FNT) concept, where GP was used for the adaptation in network structure and SA for the optimization of the parameters (including parameters of activation function) was proposed in [271, 272].", "startOffset": 215, "endOffset": 225}, {"referenceID": 267, "context": "Hence, a beta basis function\u2014 which has several controlling parameters, such as shape, size, and center\u2014was used at non-leaf nodes of an FNT [273].", "startOffset": 141, "endOffset": 146}, {"referenceID": 268, "context": "A parallel evolution of FNT using MPI programming and GPU programming respectively were proposed in [274] and in [275].", "startOffset": 100, "endOffset": 105}, {"referenceID": 269, "context": "A parallel evolution of FNT using MPI programming and GPU programming respectively were proposed in [274] and in [275].", "startOffset": 113, "endOffset": 118}, {"referenceID": 270, "context": "At the first place, the QNN as a quantum perceptron was proposed by Lewestein [276], where instead of classical weights, a unitary operator was used to map inputs to an output.", "startOffset": 78, "endOffset": 83}, {"referenceID": 243, "context": "The study in QNN encompasses the development of quantum weights, quantum neurons, quantum network, and quantum learning [249].", "startOffset": 120, "endOffset": 125}, {"referenceID": 271, "context": "The design/algorithm of quantum network was thought as an algorithm that can find the control parameters for a coupled qubit system [277] as it appears in quantum computing.", "startOffset": 132, "endOffset": 137}, {"referenceID": 272, "context": "A comprehensive quantum inspired neural network is presented in [278], where two categories of inspiration were drawn: strongly and weakly quantum inspired FNN.", "startOffset": 64, "endOffset": 69}, {"referenceID": 273, "context": "[279], 2) Chrisley [280], 3) Menneer [278], and Ventura [281].", "startOffset": 0, "endOffset": 5}, {"referenceID": 274, "context": "[279], 2) Chrisley [280], 3) Menneer [278], and Ventura [281].", "startOffset": 19, "endOffset": 24}, {"referenceID": 272, "context": "[279], 2) Chrisley [280], 3) Menneer [278], and Ventura [281].", "startOffset": 37, "endOffset": 42}, {"referenceID": 275, "context": "[279], 2) Chrisley [280], 3) Menneer [278], and Ventura [281].", "startOffset": 56, "endOffset": 61}, {"referenceID": 276, "context": "A detailed description of these QNN models can be found in [282].", "startOffset": 59, "endOffset": 64}, {"referenceID": 277, "context": "It can also be argued that both conventional and metaheuristic based FNN training take by far more training time than the extreme learning machine (ELM) [283].", "startOffset": 153, "endOffset": 158}, {"referenceID": 88, "context": "It is stated in NFL theorem [92] that it is difficult to find a metaheuristic algorithm that", "startOffset": 28, "endOffset": 32}, {"referenceID": 278, "context": "Additionally, minimizing network complexity leads to a better generalization [284].", "startOffset": 77, "endOffset": 82}, {"referenceID": 279, "context": "However, the generalization objective of the form (11) is a scalarized objective that has two disadvantages [285].", "startOffset": 108, "endOffset": 113}, {"referenceID": 280, "context": "Now, a multiobjective algorithm must provide a homogeneous distribution of a population along Pareto front and improve solutions along successive generations [286].", "startOffset": 158, "endOffset": 163}, {"referenceID": 280, "context": "Hence, three basic operators can be used [286].", "startOffset": 41, "endOffset": 46}, {"referenceID": 281, "context": "A detailed survey of multiobjective algorithms is available in [287, 288].", "startOffset": 63, "endOffset": 73}, {"referenceID": 282, "context": "A detailed survey of multiobjective algorithms is available in [287, 288].", "startOffset": 63, "endOffset": 73}, {"referenceID": 283, "context": "For example, in [289], authors proposed to add a regularization term c0 \u2212 creg to training error c0 \u2212 ctrn, where c0 is the origin of the two objectives.", "startOffset": 16, "endOffset": 21}, {"referenceID": 284, "context": "However, this was an expensive approach, which does not use any Paretobased multiobjective algorithm to compute Pareto set; rather, an ellipsoid method [290] was applied to train FNN for each scalar objective vci \u2208 vc sequentially.", "startOffset": 152, "endOffset": 157}, {"referenceID": 285, "context": "Similarly, in [291], to achieve generalization, authors proposed a sliding mode control BP algorithm for the multiobjective treatment to FNN objectives ctrn and creg.", "startOffset": 14, "endOffset": 19}, {"referenceID": 286, "context": "The optimization trajectory of the 2D space of the objectives ctrn and creg was controlled by modifying BP weight update rules using two sliding surface control indicators each belongs to the mentioned objectives, respectively Multiobjective treatment to FNN was also offered by using improvising metaheuristics itself such as a predator-prey algorithm was proposed in [292].", "startOffset": 369, "endOffset": 374}, {"referenceID": 287, "context": "Similarly, a hybrid multiobjective approach, where a geometrical measure based on singularvalue-decomposition for estimating a necessary number of nodes in a network was proposed in [293].", "startOffset": 182, "endOffset": 187}, {"referenceID": 288, "context": "LM for fine-tuning the evolved FNN was proposed in [294].", "startOffset": 51, "endOffset": 56}, {"referenceID": 289, "context": "The advantages of applying Pareto-based learning is thoroughly explained and compared with a single and scalerized objective in [295].", "startOffset": 128, "endOffset": 133}, {"referenceID": 290, "context": "For example, a nondominated sorting genetic algorithm version II (NSGA-II) [296] when used for optimizing objectives ctrn and cnet offers a Pareto set by optimizing both objectives simultaneously using a nondominated sorting method as defined in Definition 3.", "startOffset": 75, "endOffset": 80}, {"referenceID": 291, "context": "Hence, NSGA-II can be applied to obtained a regularized network by optimizing the objectives ctrn and creg [297].", "startOffset": 107, "endOffset": 112}, {"referenceID": 292, "context": "Similarly, Pareto differential evolution (PDE) algorithm and its variant self-adaptive PDE algorithm was applied to optimize objectives ctrn and cnet simultaneously that offered a Pareto-set, from which the best solution was picked-up according to network complexity and approximation error examination [298, 299].", "startOffset": 303, "endOffset": 313}, {"referenceID": 293, "context": "Similarly, Pareto differential evolution (PDE) algorithm and its variant self-adaptive PDE algorithm was applied to optimize objectives ctrn and cnet simultaneously that offered a Pareto-set, from which the best solution was picked-up according to network complexity and approximation error examination [298, 299].", "startOffset": 303, "endOffset": 313}, {"referenceID": 294, "context": "Simultaneous optimization of the objectives ctrn and cnet were also addressed using multiobjective PSO to generalize FNN performance [300].", "startOffset": 133, "endOffset": 138}, {"referenceID": 295, "context": "For an image classification problem, authors in [301], pointed out two crucial points: the classification speed and the classification accuracy cacc.", "startOffset": 48, "endOffset": 53}, {"referenceID": 296, "context": "Similarly, in [302], authors studied three methods for image classification problem: linear aggregating (LA), NSGA-II with deterministic selection (DM), and NSGA-II with tournament selection (LM).", "startOffset": 14, "endOffset": 19}, {"referenceID": 297, "context": "Such ability of the Pareto-based treatment to FNN to obtain general FNN was exploited by several researchers for solving many real-life applications [303\u2013306].", "startOffset": 149, "endOffset": 158}, {"referenceID": 298, "context": "Such ability of the Pareto-based treatment to FNN to obtain general FNN was exploited by several researchers for solving many real-life applications [303\u2013306].", "startOffset": 149, "endOffset": 158}, {"referenceID": 299, "context": "Such ability of the Pareto-based treatment to FNN to obtain general FNN was exploited by several researchers for solving many real-life applications [303\u2013306].", "startOffset": 149, "endOffset": 158}, {"referenceID": 300, "context": "Such ability of the Pareto-based treatment to FNN to obtain general FNN was exploited by several researchers for solving many real-life applications [303\u2013306].", "startOffset": 149, "endOffset": 158}, {"referenceID": 263, "context": "Further, the coevolution FNN concept [269,307] was extended in [308] under the multiobjective framework, by using subnetwork and network concepts.", "startOffset": 37, "endOffset": 46}, {"referenceID": 301, "context": "Further, the coevolution FNN concept [269,307] was extended in [308] under the multiobjective framework, by using subnetwork and network concepts.", "startOffset": 37, "endOffset": 46}, {"referenceID": 302, "context": "Further, the coevolution FNN concept [269,307] was extended in [308] under the multiobjective framework, by using subnetwork and network concepts.", "startOffset": 63, "endOffset": 68}, {"referenceID": 303, "context": "Apart from the discussed objective in this section, some interesting dimensions in multiobjective treatment to FNN can be noted in [309], in which authors proposed to apply NSGA-II for the simultaneous optimization of three objectives: input-dimension, training error, and network complexity.", "startOffset": 131, "endOffset": 136}, {"referenceID": 39, "context": "Similarly, in [41, 310], authors used a Pareto-based memetic algorithm approach for combining PDE and Rprop algorithms to minimize objective pairs true classification rate and minimum sensitivity (miss-classification rate), simultaneously.", "startOffset": 14, "endOffset": 23}, {"referenceID": 304, "context": "Similarly, in [41, 310], authors used a Pareto-based memetic algorithm approach for combining PDE and Rprop algorithms to minimize objective pairs true classification rate and minimum sensitivity (miss-classification rate), simultaneously.", "startOffset": 14, "endOffset": 23}, {"referenceID": 305, "context": "Since selecting a single best FNN from may not offer a generalized solution and the residual error can still be remaining many problems when selection single best FNN [311], then an ensemble of a set of FNNs is recommended.", "startOffset": 167, "endOffset": 172}, {"referenceID": 306, "context": "Hence, a collective decision (ensemble) of l many diverse candidates selected from a final population may offer desired generalization [312].", "startOffset": 135, "endOffset": 140}, {"referenceID": 43, "context": "The very basic idea is to apply single-solution based algorithms on l many FNNs to get l many diverse solutions [46].", "startOffset": 112, "endOffset": 116}, {"referenceID": 307, "context": "The decision of l many candidates which were created either by single solution-based metaheuristics, or by population-based metaheuristics, or by any other means are combined using the following methods [313, 314]: 1) majority voting method (for classification problems); 2) arithmetic mean (for regression problem); 3) rank-based linear combination; 4) linear combination by using recursive least square [315] (to minimize weighted least squares error so that redundant individuals are eliminated); 5) evolutionary weighted mean or majority voting (metaheuristic to determine impact of an FNN in ensemble); and 6) entropy-based method for combining FNNs in ensemble (assigning entropy to FNNs during the learning process) [316].", "startOffset": 203, "endOffset": 213}, {"referenceID": 308, "context": "The decision of l many candidates which were created either by single solution-based metaheuristics, or by population-based metaheuristics, or by any other means are combined using the following methods [313, 314]: 1) majority voting method (for classification problems); 2) arithmetic mean (for regression problem); 3) rank-based linear combination; 4) linear combination by using recursive least square [315] (to minimize weighted least squares error so that redundant individuals are eliminated); 5) evolutionary weighted mean or majority voting (metaheuristic to determine impact of an FNN in ensemble); and 6) entropy-based method for combining FNNs in ensemble (assigning entropy to FNNs during the learning process) [316].", "startOffset": 203, "endOffset": 213}, {"referenceID": 309, "context": "The decision of l many candidates which were created either by single solution-based metaheuristics, or by population-based metaheuristics, or by any other means are combined using the following methods [313, 314]: 1) majority voting method (for classification problems); 2) arithmetic mean (for regression problem); 3) rank-based linear combination; 4) linear combination by using recursive least square [315] (to minimize weighted least squares error so that redundant individuals are eliminated); 5) evolutionary weighted mean or majority voting (metaheuristic to determine impact of an FNN in ensemble); and 6) entropy-based method for combining FNNs in ensemble (assigning entropy to FNNs during the learning process) [316].", "startOffset": 405, "endOffset": 410}, {"referenceID": 310, "context": "The decision of l many candidates which were created either by single solution-based metaheuristics, or by population-based metaheuristics, or by any other means are combined using the following methods [313, 314]: 1) majority voting method (for classification problems); 2) arithmetic mean (for regression problem); 3) rank-based linear combination; 4) linear combination by using recursive least square [315] (to minimize weighted least squares error so that redundant individuals are eliminated); 5) evolutionary weighted mean or majority voting (metaheuristic to determine impact of an FNN in ensemble); and 6) entropy-based method for combining FNNs in ensemble (assigning entropy to FNNs during the learning process) [316].", "startOffset": 723, "endOffset": 728}, {"referenceID": 306, "context": "Since population-based metaheuristics lead to an optimized final population, it is advantageous to use the final population for making ensemble [312].", "startOffset": 144, "endOffset": 149}, {"referenceID": 311, "context": "However, there are two fundamental problems with it [317]: 1) determining ensemble size, 2) how to maintain diversity in the population.", "startOffset": 52, "endOffset": 57}, {"referenceID": 311, "context": "Hence, a negative correlation learning (NCL) algorithm that optimized and combined individual FNNs in an ensemble during learning process was proposed in [317].", "startOffset": 154, "endOffset": 159}, {"referenceID": 312, "context": "Moreover, NCL produced negatively correlated and specialized FNNs by using co-operation among each FNNs of a population [318].", "startOffset": 120, "endOffset": 125}, {"referenceID": 313, "context": "Moreover, different FNNs were allowed learn different parts of training data and the best (according to fitness) were selected for ensemble [319].", "startOffset": 140, "endOffset": 145}, {"referenceID": 314, "context": "Additionally, a constructive-cooperative-neural-network-ensemble was proposed in [320] that determined ensemble size by focusing on accuracy and diversity during a constructive, cooperative procedure [321].", "startOffset": 81, "endOffset": 86}, {"referenceID": 315, "context": "Additionally, a constructive-cooperative-neural-network-ensemble was proposed in [320] that determined ensemble size by focusing on accuracy and diversity during a constructive, cooperative procedure [321].", "startOffset": 200, "endOffset": 205}, {"referenceID": 316, "context": "This problem was addressed in a GA-based selective ensemble method [322], which selects a subset of the population and determine the strength of selected candidates using GA.", "startOffset": 67, "endOffset": 72}, {"referenceID": 316, "context": "It was also shown that the ensemble of a subset of the population was found performing better than that of the whole population [322].", "startOffset": 128, "endOffset": 133}, {"referenceID": 317, "context": "The effectiveness such GA-based selection was found efficient than the traditional ensemble methods: bagging [323] and boosting [324].", "startOffset": 109, "endOffset": 114}, {"referenceID": 318, "context": "The effectiveness such GA-based selection was found efficient than the traditional ensemble methods: bagging [323] and boosting [324].", "startOffset": 128, "endOffset": 133}, {"referenceID": 317, "context": "It is beneficial to partition/fracture training data and allows different FNN in the population to learn various parts of training data [323,324].", "startOffset": 136, "endOffset": 145}, {"referenceID": 318, "context": "It is beneficial to partition/fracture training data and allows different FNN in the population to learn various parts of training data [323,324].", "startOffset": 136, "endOffset": 145}, {"referenceID": 319, "context": "An evidence of such was examined in [325,326], where it was found that the ensemble of a few FNNs that was trained using bootstrapping performs better than that of an ensemble of a larger number of FNNs.", "startOffset": 36, "endOffset": 45}, {"referenceID": 320, "context": "An evidence of such was examined in [325,326], where it was found that the ensemble of a few FNNs that was trained using bootstrapping performs better than that of an ensemble of a larger number of FNNs.", "startOffset": 36, "endOffset": 45}, {"referenceID": 321, "context": "ensembles approach proposed in [327] and were compared with bagging and boosting methods.", "startOffset": 31, "endOffset": 36}, {"referenceID": 322, "context": "On the contrary, a clustering-and-coevolution approach for constructing neural network ensembles proposed in [328] partition the input space using a clustering method to reduced number of input nodes of FNNs.", "startOffset": 109, "endOffset": 114}, {"referenceID": 322, "context": "Such method improves diversity and accuracy of an ensemble system [328].", "startOffset": 66, "endOffset": 71}, {"referenceID": 323, "context": "Similarly, a method was suggested in [329] for generating diverse evolutionary FNNs using a fitness-sharing method\u2014a fitness sharing method shares resources if the distance between the individuals is smaller than the predefined sharing radius.", "startOffset": 37, "endOffset": 42}, {"referenceID": 324, "context": "On the other hand, a progressive interactive training scheme called a sequential-neural-network-ensemble-learning method, which trained FNNs one-by-one by interaction from a central buffer of FNNs was proposed in [330].", "startOffset": 213, "endOffset": 218}, {"referenceID": 307, "context": "Both diversity and accuracy is a crucial aspect in construing ensemble of FNNs [313].", "startOffset": 79, "endOffset": 84}, {"referenceID": 325, "context": "However, accuracy and diversity are contradictory to each other, so, a multiobjective approach may be applied to evolve FNN population by maintaining accuracy and diversity simultaneously [331].", "startOffset": 188, "endOffset": 193}, {"referenceID": 326, "context": "For this purpose, multiobjective regularized negative correlation learning that maximized performance and maximized the negative correlation between individuals in population was found efficient [332].", "startOffset": 195, "endOffset": 200}, {"referenceID": 327, "context": "The effectiveness of FNN training primarily depends on data quality, which is governed by the following data quality assurance parameters: accuracy, reliability, timeliness, relevance, completeness, currency, consistency, flexibility, and precision [333, 334].", "startOffset": 249, "endOffset": 259}, {"referenceID": 328, "context": "The effectiveness of FNN training primarily depends on data quality, which is governed by the following data quality assurance parameters: accuracy, reliability, timeliness, relevance, completeness, currency, consistency, flexibility, and precision [333, 334].", "startOffset": 249, "endOffset": 259}, {"referenceID": 329, "context": "Usually, data cleaning is a major step before modeling [335].", "startOffset": 55, "endOffset": 60}, {"referenceID": 330, "context": "For the case insufficient data, usually the input hyperspace is exploited to generate virtual samples to fill the sparse area of the hyperspace, and by monitoring FNN performance on the virtually generated samples [336].", "startOffset": 214, "endOffset": 219}, {"referenceID": 223, "context": "The second approach exploits the dynamics of EAs in conjunction with FNNs to obtain new samples [229].", "startOffset": 96, "endOffset": 101}, {"referenceID": 331, "context": "is continued to interest researcher [337].", "startOffset": 36, "endOffset": 41}, {"referenceID": 332, "context": ", we need to deal not only with high-dimensional data but also with the variety data and stream data [338].", "startOffset": 101, "endOffset": 106}, {"referenceID": 333, "context": "Such challenge is to some extent addressed by deep learning paradigms that allow the arrangement several units/layers of FNNs (or any other model) in a hierarchical manner to process and understand insights of such high-dimensional data [339,340].", "startOffset": 237, "endOffset": 246}, {"referenceID": 334, "context": "Such challenge is to some extent addressed by deep learning paradigms that allow the arrangement several units/layers of FNNs (or any other model) in a hierarchical manner to process and understand insights of such high-dimensional data [339,340].", "startOffset": 237, "endOffset": 246}, {"referenceID": 335, "context": "High-dimensional data can also be managed/reduced by encoding or decoding methods and using FNNs training [341].", "startOffset": 106, "endOffset": 111}, {"referenceID": 336, "context": ", data comes in sequential order, and traditionally, re-training based mechanics for dynamic learning (online learning) of FNN is the basic option [342].", "startOffset": 147, "endOffset": 152}, {"referenceID": 337, "context": "The quest of developing a model that can stand robust and efficient for the non-stationary data caused by the time-dependent process of data generation, and can accommodate new knowledge (newly generated data sample) is a significant topic in machine learning research [343].", "startOffset": 269, "endOffset": 274}, {"referenceID": 338, "context": "On the other hand, integration of data or of the models for that matter for the heterogeneous data generated or gathered from different instruments and data-generation processes is a significant research problem [344,345].", "startOffset": 212, "endOffset": 221}, {"referenceID": 339, "context": "On the other hand, integration of data or of the models for that matter for the heterogeneous data generated or gathered from different instruments and data-generation processes is a significant research problem [344,345].", "startOffset": 212, "endOffset": 221}, {"referenceID": 340, "context": "Moreover, present era, the fourth industrial revolution, is of Internet of Things (IoT) [346].", "startOffset": 88, "endOffset": 93}, {"referenceID": 341, "context": ", human activity recognition [347].", "startOffset": 29, "endOffset": 34}, {"referenceID": 342, "context": "Such problem can be addressed through the integration of FNN with statistical methods like the one usually done with hidden Markov model [348].", "startOffset": 137, "endOffset": 142}], "year": 2017, "abstractText": "Over the past two decades, the feedforward neural network (FNN) optimization has been a key interest among the researchers and practitioners of multiple disciplines. The FNN optimization is often viewed from the various perspectives: the optimization of weights, network architecture, activation nodes, learning parameters, learning environment, etc. Researchers adopted such different viewpoints mainly to improve the FNN\u2019s generalization ability. The gradient-descent algorithm such as backpropagation has been widely applied to optimize the FNNs. Its success is evident from the FNN\u2019s application to numerous real-world problems. However, due to the limitations of the gradient-based optimization methods, the metaheuristic algorithms including the evolutionary algorithms, swarm intelligence, etc., are still being widely explored by the researchers aiming to obtain generalized FNN for a given problem. This article attempts to summarize a broad spectrum of FNN optimization methodologies including conventional and metaheuristic approaches. This article also tries to connect various research directions emerged out of the FNN optimization practices, such as evolving neural network (NN), cooperative coevolution NN, complex-valued NN, deep learning, extreme learning machine, quantum NN, etc. Additionally, it provides interesting research challenges for future research to cope-up with the present information processing era.", "creator": "LaTeX with hyperref package"}}}