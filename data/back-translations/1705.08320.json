{"id": "1705.08320", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2017", "title": "Explaining Transition Systems through Program Induction", "abstract": "The explanation and reasoning of processes underlying observed black box phenomena enables the discovery of causal mechanisms, the derivation of appropriate abstract representations, and the formulation of robust predictions. We propose to learn highly functional programs to represent abstract models that capture the invariant structure in the observed data. We introduce the $\\ pi $machine (Program Induction Machine) - an architecture that is capable of inducing interpretable LISP-like programs from observed data tracks. We propose an optimization process for program learning based on back propagation, gradient descent, and A * search. We apply the proposed method to three problems: system identification of dynamic systems, explanation of the behavior of a DQN agent, and learning by demonstration in a human-robot interaction scenario. Our experimental results show that the $\\ pi machine can generate data-efficient traces.", "histories": [["v1", "Tue, 23 May 2017 14:38:28 GMT  (876kb,D)", "http://arxiv.org/abs/1705.08320v1", "submitted to Neural Information Processing Systems 2017"]], "COMMENTS": "submitted to Neural Information Processing Systems 2017", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["svetlin penkov", "subramanian ramamoorthy"], "accepted": false, "id": "1705.08320"}, "pdf": {"name": "1705.08320.pdf", "metadata": {"source": "CRF", "title": "Explaining Transition Systems through Program Induction", "authors": ["Svetlin Penkov", "Subramanian Ramamoorthy"], "emails": ["sv.penkov@ed.ac.uk", "s.ramamoorthy@ed.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "Learning models of transition systems has been a core concern within machine learning, with applications ranging from system identification of dynamical systems [1] and inference of human choice behaviour [2, 3] to reverse engineering the behaviour of a device or computer program from observations and traces [4]. With the increasing use of these learnt models in the inner loops of decision making systems, e.g., in robotics and human-machine interfaces, it has become necessary to ensure not only that these models are accurate predictors of behaviour, but also that their causal mechanisms are exposed to the system designer in a more interpretable manner. There is also the need to explain the model in terms of counterfactual reasoning [5], e.g., what would we expect the system to do if a certain variable were changed or removed, or model checking [6] of longer term properties including safety and large deviations in performance. We address these needs through a program induction based framework for explainability.\nWe propose to learn high level functional programs in order to represent abstract models which capture the invariant structure in the observed data. Recent works have demonstrated the usefulness of program representations in capturing human-like concepts [7]. Used in this way, programbased representations boost generalisation and enable one-shot learning. Also, and arguably more importantly, they are significantly more amenable to model checking and human interpretability.\nIn this paper, we introduce the \u03c0-machine (program-induction machine), an architecture which is able to induce LISP-like programs from observed transition system data traces in order to explain various phenomena. Inspired by differentiable neural computers [8, 9], the \u03c0-machine, as shown in Figure 1, is composed of a memory unit and a controller capable of learning programs from data by exploiting the scalability of stochastic gradient descent. However, the final program obtained after training is not an opaque object encoded in the weights of a controller neural network, but a LISP-like program which provides a rigorous and interpretable description of the observed phenomenon. A key feature of our approach is that we allow the user to specify the properties they are interested in understanding\nar X\niv :1\n70 5.\n08 32\n0v 1\n[ cs\n.A I]\n2 3\nM ay\nas well as the context in which the data is to be explained - by providing a set of predicates of interest. By exploiting the equivalence between computational graphs and functional programs we describe a hybrid optimisation procedure based on backpropagation, gradient descent, and A* search which is used to induce programs from data traces.\nWe evaluate the performance of the \u03c0-machine on three different problems. Firstly, we apply it to data from physics experiments and show that it is able to induce programs which represent fundamental laws of physics. The learning procedure has access to relevant variables, but it does not have any other prior knowledge regarding physical laws which it has discovered in the same sense as in [1] although far more computationally tractably. We then study the use of the proposed procedure in explaining control policies learnt by a deep Q-network (DQN). Starting from behaviour traces of a reinforcement learning agent that has learnt to play the game of Pong, we demonstrate how the \u03c0-machine learns a functional program to describe that policy. Finally, we consider the domain of learning by demonstration in human-robot interaction, where the \u03c0-machine successfully induces programs which capture the structure of the human demonstration. In this domain, the learnt program plays a key role in enabling the grounding of abstract knowledge (e.g., in natural language commands) in the embodied sensory signals that robots actually work with, as in [10]."}, {"heading": "2 Related work", "text": "Explainability and interpretability. The immense success of deep neural network based learning systems and their rapid adoption in numerous real world application domains has renewed interest in the interpretability and explainability of learnt models 1. There is recognition that Bayesian rule lists [11, 12], decision trees and probabilistic graphical models are interpretable to the extent that they impose strong structural constraints on models of the observed data and allow for various types of queries, including introspective and counterfactual ones. In contrast, deep learning models usually are trained \u2018per query\u2019 and have numerous parameters that could be hard to interpret. Zeiler and Fergus [13] introduced deconvolutional networks in order to visualise the layers of convolutional networks and provide a more intuitive understanding of why they perform well. Similar approaches can be seen in [14, 15], in the context of autonomous driving. Zahavy et al. [16] describe Semi-Aggregated Markov Decision Process (SAMDP) in order to analyse and understand the behaviour of a DQN based agent. Methods for textual rationalisation of the predictions made by deep models have also been proposed [17\u201319]. While all of these works provide useful direction, we need many more methods, especially generic approaches that need not be hand-crafted to explain specific aspects of individual models. In this sense, we follow the model-agnostic explanation approach of Ribeiro et al. [20], who provide \u201ctextual or visual artefacts\u201d explaining the prediction of any classifier by treating it as a black-box. Similarly to the way in which [20] utilise local classifiers composed together to explain a more complex model, we present an approach to incrementally constructing functional programs that explain a complex transition system from more localised predicates of interest to the user.\nThe \u03c0-machine treats the process which has generated the observed data as a black-box and attempts to induce LISP-like program which can be interpreted and used to explain the data. We show that the proposed method can be applied both to introspection of machine learning models and to the broader context of autonomous agents.\nProgram learning and synthesis. Program learning and synthesis has a long history, with the long-standing challenge being the high complexity deriving from the immense search space. Following classic and pioneering work such as by Shapiro [21] who used inductive inference in a logic programming setting, others have developed methods based on a variety of methods ranging from SAT solvers [22] to genetic algorithms [1], which tend to scale poorly hence often become restricted to a narrow class of programs. Recently, deep neural networks have been augmented with a memory unit resulting in models similar to the original von Neumann architecture. These models can induce programs through stochastic gradient descent by optimising performance on input/output examples [8, 9, 23] or synthetic execution traces [24\u201326]. Programs induced with such neural architectures are encoded in the parameters of the controller network and are, in general, not easily interpretable (particularly from the point of view of being able to ask counterfactual questions or performing\n1See, for instance, the end user concerns that motivate the DARPA Explainable AI Programme: http: //www.darpa.mil/program/explainable-artificial-intelligence\nmodel checking). Interestingly, paradigms from functional programming such as pure functions and immutable data structures have been shown to improve performance of neural interpreters [27]. Another approach is to directly generate the source code of the output program which yields consistent high level programs. Usually, these types of approaches require large amounts of labelled data - either program input/output examples [28, 29] or input paired with the desired output program code [30].\nDetermining how many input/output examples or execution traces are required in order to generalise well is still an open research problem. However, in this paper, we focus attention more on the explanatory power afforded by programs rather than on the broader problems of generalisation in the space of programs. While these characteristics are of course related, we take a view similar to that of [20], arguing that it is possible to build from locally valid program fragments which provide useful insight into the black-box processes generating the data. By combining gradient descent and A* search the \u03c0-machine is able to learn informative and interpretable high-level LISP-like programs, even just from a single observation trace."}, {"heading": "3 Problem definition", "text": "Consider the labelled transition system \u2126(S,A, \u03b4) where S is a non-empty set of states, A is a nonempty set of actions, each parametrised by \u03b8 \u2208 RD, and \u03b4 : S\u00d7A \u2192 S is the state transition function. We define an observation trace T as a sequence of observed state-action pairs (st, at(\u03b8t)) \u2208 S \u00d7A generated by the recursive relationship st+1 = \u03b4 (st, at( \u03b8t)) for 1 \u2264 t \u2264 T . We are interested in inducing a LISP-like functional program \u03c1 which when executed by an abstract machine is mapped to an execution trace T\u03c1 such that T\u03c1 and T are equivalent according to an input specification. We represent the abstract machine as another labelled transition system \u03a0(M, I, \u03b5) whereM is the set of possible memory state configurations, I is the set of supported instructions and \u03b5 :M\u00d7I \u2192M specifies the effect of each instruction. We consider two types of instructions \u2013 primitive actions which emulate the execution of a \u2208 A or arithmetic functions f \u2208 F such that I = A \u222a F . Furthermore, a set of observed state variablesMv \u2286 S , which vary over time, are stored in memory together with a set of induced free parametersMp. The variables inMv form a context which the program will be built on. A custom detectorDv , operating on the raw data stream, could be provided for each variable, thus enabling the user to make queries with respect to different contexts and property specifications.\nThe execution of a program containing primitive actions results in a sequence of actions. Therefore, we represent a program \u03c1 as a function which maps a set of input variables xv \u2282Mv and a set of free parameters xp \u2282Mp to a finite sequence of actions a\u03021(\u03b8\u03021), . . . a\u0302T \u2032( \u02c6\u03b8T \u2032). We are interested in inducing a program which minimises the total error between the executed and the observed actions:\nL(\u03c1) = min(T,T \u2032)\u2211 t=1 \u03c3act(a\u0302t, \u03b8\u0302t, at, \u03b8t) + \u03c3len(T, T \u2032) (1)\nThe error function \u03c3act determines the difference between two actions, while \u03c3len compares the lengths of the generated and observed action traces. By providing the error functions \u03c3act and \u03c3len one can target different aspects of the observation trace to be explained as they specify when two action traces are equivalent."}, {"heading": "4 Method", "text": "The proposed program induction procedure is based on two major steps. Firstly, we explain how a given functional program can be optimised such that the loss L(\u03c1) is minimised. Secondly, we explain how the space of possible program structures can be searched efficiently by utilising gradient information. An architectural overview of the \u03c0-machine is provided in Figure 1."}, {"heading": "4.1 Program optimisation", "text": "Functional programs as computational graphs. Neural networks are naturally expressed as computational graphs which are the most fundamental abstraction in computational deep learning frameworks [31\u201333]. Optimisation within a computational graph is usually performed by pushing the input through the entire graph in order to calculate the output (forward pass) and then backpropagating the error signal to update each parameter (backward pass). A key observation for the development of the \u03c0-machine is that computational graphs and functional programs are equivalent as both describe arbitrary compositions of pure functions applied to input data. For example, Figure 2 shows how a logistic regression classifier can be represented both as a computational graph and as a functional program. Therefore, similarly to a computational graph, a functional program can also be optimised by executing the program (forward pass), measuring the error signal and then performing backpropagation to update the program (backward pass).\nForward pass. When a program is executed it is interpreted to a sequence of instructions i1, . . . , in \u2208 I which are executed by recursively calling \u03b5(. . . \u03b5(\u03b5(M1, i1), i2) . . . , in). M1 is the initial memory state initialised with the observed variables from s1 and any induced parameters. The \u03c0-machine keeps a time counter t which is initialised to 1 and is automatically incremented whenever a primitive action instruction is executed. If the instruction ik is a primitive action, ik \u2208 A, then the \u03c0-machine automatically sets a\u0302t = ik and invokes the error function \u03c3act(a\u0302t, \u03b8\u0302t, at, \u03b8t), where \u03b8\u0302t has been calculated by previous instructions. If the error is above a certain threshold emax the program execution is terminated and the backward pass is initiated. Otherwise, the time counter is incremented and the values of the variables inMv are automatically updated to the new observed state. Essentially, the \u03c0-machine simulates the execution of each action reflecting any changes it has caused in the observed state. Alternatively, if the currently executed instruction ik is a function, ik \u2208 F , then the resulting value is calculated and ik, together with its arguments, is added to a detailed call trace \u03c7 maintained by the \u03c0-machine. Importantly, each function argument is either a parameter or a variable read from memory at time t or the result of another function. All this information is kept in \u03c7 which eventually contains the computational tree for the entire program.\nBackward pass. The gradients of the loss function L(\u03c1) with respect to the program inputs xv and xp are required to perform a gradient descent step. Crucially, programs executed by the \u03c0-machine are automatically differentiated. The \u03c0-machine performs reverse-mode automatic differentiation, similarly to Autograd [34], by traversing the call trace \u03c7, and post-multiplying Jacobian matrices. We assume that the Jacobian matrix with respect to every input argument of any function f \u2208 F or any specified error function \u03c3act is known a priori. Let f \u2208 F be a function whose output needs to be differentiated with respect to the input arguments. There are three types of derivatives, which need to be considered in order to traverse backwards the entire tree of computations:\n1. Let g \u2208 F , then \u2202f\u2202g is the Jacobian matrix of f with respect to the output of g and can be directly calculated.\n2. Let p \u2208 xp, then the gradient \u2202f\u2202p is calculated by multiplying the corresponding Jacobian matrix of f with the value of p.\n3. Let v \u2208 xv, then the gradient \u2202f\u2202v \u2223\u2223\u2223 t=tr is calculated by multiplying the corresponding\nJacobian of f with the value of the variable at the time it was read from memory tr.\nGradient descent step. Once the gradient \u2207pL(\u03c1) of the loss function with respect to each input parameter p \u2208 xp is calculated we utilise AdaGrad [35] to update the values of all parameters after each program execution. The gradient \u2207vL(\u03c1) with respect to each input variable v \u2208 xv is also available. However, a variable cannot be simply updated in the direction of the gradient as it represents a symbol, not just a value. Variables can only take values from memory which is automatically updated according to the observation trace during execution. Nevertheless, the gradient provides important information about the direction of change which we utilise to find variables that minimise the loss. Whenever the memory state is automatically updated, a KD-tree is built for each type of variable stored in memory. We assume that the variables in memory are real vectors with different length. So, we represent the KD-tree which stores all D-dimensional variables in memory at time t as KDt . If a d-dimensional variable v is to be optimised it is replaced with a temporary parameter ptemp initialised with vt which is the value of v read from memory at the respective time step t. The temporary parameter ptemp is also updated with AdaGrad [35]. After each descent step, the nearest neighbour of the updated value p\u2032temp is determined by querying the KD-tree with Kdt (p\u2032temp). If the result of the query is a different d-dimensional variable u then the temporary parameter is immediately set to ptemp = ut. As this often shifts the solution to a new region of the error space the gradient history for all parameters p \u2208 xp is reset. Eventually, when a solution is to be returned, the temporary parameters are substituted with their closest variables according to the respective KDt . The forward and backward passes are repeated until the error is below the maximum error threshold emax or a maximum number of iterations is reached. After that the optimised program \u03c1\u2217 is scored according to its error and complexity, and pushed to a priority queue holding potential solutions."}, {"heading": "4.2 Structure search", "text": "We represent the space of possible program structures as a graph G = (TAST , E) where each node Ti \u2208 TAST is a valid program abstract syntax tree (AST). There is an edge from Ti to Tj if and only if Tj can be obtained by replacing exactly one of the leaves in Ti with a subtree Ts of depth 1. The program induction procedure always starts with an empty program. So, we frame structure search as a path finding problem, solved through the use of A* search.\nScore function. The total cost function we use is ftotal(\u03c1) = C(\u03c1) + L(\u03c1), where L(\u03c1) is the loss function defined in equation (1) and C(\u03c1) is a function which measures the complexity of the program \u03c1. C(\u03c1) can be viewed as the cost to reach \u03c1 and L(\u03c1) as the distance to the desired goal. The complexity function C(\u03c1) is the weighted sum of (i) maximum depth of the program AST; (ii) the number of free parameters; (iii) the number of variables used by the program; the weights of which we set to wC = [10, 5, 1]. These choices have the effect that short programs maximally exploiting structure from the observation trace are preferred.\nNeighbours expansion. When the current best candidate solution is popped from the priority queue, we check if it matches the observation trace according to the input specification. If so, the candidate can be returned as the final solution, otherwise it is used as a seed to propose new candidate\nsolutions. Typically in A* search, all neighbouring nodes are expanded and pushed to the priority queue, which is not feasible in our case, though. Therefore, we utilise the available gradients in order to perform a guided proposal selection. Each leaf in the abstract syntax tree T\u03c1 of a seed candidate solution \u03c1 corresponds to a parameter or a variable. According to the definition of G we need to select exactly 1 leaf to be replaced with a subtree Ts of depth 1. We select leaf l \u2208 T\u03c1 according to:\nl = arg max x\u2208xp\u222axv\n\u2016\u2207xL(\u03c1)\u20162 (2)\nAfter that, all possible replacement subtrees are constructed. An AST subtree Ts of depth 1 represents a function call. We prune the number of possible functions in F by ensuring type consistency. Each leaf of Ts can be a parameter or a variable. So, all possible combinations are considered. New variable leaves are initialised to a random variable with suitable type from memory, while new parameter leaves are sampled from the multivariate normal distribution N (0, 0.1). As a result, if nf functions are type compatible with l and each function takes na arguments at most, then there are 2na \u00b7 nf replacement subtrees, resulting in that many new candidates. All newly proposed candidates are optimised in parallel, scored by ftotal and pushed to the priority queue."}, {"heading": "5 Experimental results", "text": "In order to evaluate the effectiveness of the \u03c0-machine, we apply it to three different scenarios. Firstly, we consider model learning for a physical system. We show that the \u03c0-machine successfully induces basic physical laws from observational data. Secondly, we demonstrate how a program can be induced in order to explain the behaviour of the policy learnt by a DQN network. This experiment is based on our view that the core deep neural network based policy learner and the explanation layer play complementary roles. As is well known by now, there are numerous advantages to performing end-to-end policy learning, such as DQN-learning from raw video. Having done this, there is also a need to explain the behaviour of the learnt policy with respect to user-defined properties of interest, hence as a program defined in terms of user-defined detectors, Dv . Lastly, we apply the \u03c0-machine to a learning-by-demonstration task, where demonstrated behaviour of physical object manipulation is explained through a functional program that describes the abstract structure of that planning task. All experiments are run on an Intel Core i7-4790 processor with 32GB RAM. The \u03c0-machine is implemented in Clojure, which is a LISP dialect supporting powerful data structures and homoiconic syntax. We will be releasing the code once this paper has been accepted for publication.\nGiven the nature of the experimental tasks, we use the following list of supported functions, F , for all of our experiments: vector addition, subtraction and scaling."}, {"heading": "5.1 Physical systems", "text": "The transition dynamics of a second order dynamical system is written as x\u0308(t) = k1x(t) + k2x\u0307(t), where x(t) is the state of the system at time t and k1, k2 are system coefficients. We have recreated an experiment described in Schmidt and Lipson [1], where the authors show the learning of physical laws associated with classical mechanical systems including the simple pendulum and linear oscillator. A diagram of these two systems is shown in Figure 3 (left). We set A = {accel(\u03b8)} where \u03b8 \u2208 R for both experiments. The observation trace for each system is generated by simulating the dynamics\nfor 1s at 100Hz. We specify the action error function as \u03c3act = \u2016\u03b8\u0302 \u2212 \u03b8\u20162 and set \u03c3len = 0. In the pendulum experiment, x \u2208 R is the angular position of the pendulum, while v = x\u0307 \u2208 R is the angular velocity. In the linear oscillator experiment, x and v are the linear position and velocity, respectively.\nThe three best solutions found by the \u03c0-machine for each system are shown in Figure 3 (middle). The best solution for each system correctly represents the underlying laws of motion. The program describing the behaviour of the pendulum was induced in 18 iterations, while the linear oscillator program needed 146 iterations. The total number of possible programs with AST depth of 2, given the described experimental setup, is approximately 1.7\u00d7 104. The average duration of an entire iteration (propose new programs, optimise and evaluate) was 0.6s. Schmidt and Lipson [1] achieve similar execution times, but distributed over 8 quad core computers (32 cores in total). The experimental results demonstrate that the \u03c0-machine can efficiently induce programs representing fundamental laws of physics."}, {"heading": "5.2 Deep Q-network", "text": "We consider explaining the behaviour of a DQN trained to play the ATARI Pong game. We are interested in the question: how does the network control the position of the paddle in order to hit the ball when it is in the right side of the screen. A diagram of the experimental setup is shown in figure 4 (left). The behaviour of the DQN is observed during a single game. Since the environment is deterministic, the state transition function, which generates the observation trace for this experiment, is the policy \u03c0(s) that the DQN has learnt. We would like to explain the behaviour of the DQN in terms of the position of the opponent, the ball and the DQN agent (so, not just in terms of RAM memory values, for instance). Therefore, the observation trace contains those positions which are extracted from each frame by a predefined detector. We set A = {move(\u03b8)} where \u03b8 \u2208 R and represent the discrete actions of the network left, right, nop as move(1), move(\u22121), move(0) respectively. We specify the action error function as \u03c3act = \u2016\u03b8\u0302 \u2212 \u03b8\u20162 and set \u03c3len = 0. The best 3 programs found by the \u03c0-machine are shown in Figure 4 (middle), where it took 38 iterations for the best one (average iteration duration 3.2s). By inspecting the second solution it becomes clear that the neural network behaviour can be explained as a proportional controller minimising the vertical distance between the agent and the ball. However, the best solution reveals even more structure in the behaviour of the DQN. The coefficient in front of the agent position is slightly larger than the one in front of the ball position which results in a small amount of damping in the motion of the paddle. Thus, it is evident that the DQN not only learns the value of each game state, but also the underlying dynamics of controlling the paddle. Furthermore, we have tested the performance of an agent following a greedy policy defined by the induced program. In our experiments over 100 games this agent achieved a score of 11.1(\u00b10.17). This is not quite the score of 18.9(\u00b11.3) obtained by an optimised DQN, but it is better than human performance 9.3 [36]. This difference of course emanates from the predefined detector not capturing all aspects of what the perceptual layers in DQN have learnt, so improved detector choices should yield interpretable programs that also attain performance closer to the higher score of the black-box policy."}, {"heading": "5.3 Learning by demonstration", "text": "Work in collaborative human-robot interaction [10] suggests that programmatic description of the task enables robots to better ground symbols to their physical instances, improving their perceptual capabilities. We consider a learning by demonstration scenario where a person demonstrates how to build a tower in a virtual simulated 2D environment. A typical demonstration is depicted in Figure 5 (left). Our goal is to learn a program describing the demonstration such that it could later be utilised by the robot.\nWe are interested in how a person moves the cubes through the entire demonstration. So, we set A = {pick(\u03b8), place(\u03b8)}, where \u03b8 \u2208 R2 is a 2D location. We specify the action and length error functions as\n\u03c3act(a\u0302, \u03b8\u0302, a, \u03b8) = { \u2016\u03b8\u0302 \u2212 \u03b8\u20162 if a\u0302 = a dmax otherwise\n\u03c3len(T \u2032, T ) = (T \u2032 \u2212 T )2 (3)\nwhere dmax is the maximum distance within the simulated 2D environment. The states in the observation trace contain the 2D position of every cube in the environment.\nWe tested the \u03c0-machine on 300 demonstrations and it successfully induced a program for each one of them. On average, 67 iterations (average iteration duration 0.4s) were needed per demonstration. The solution for one of the demonstrations is shown in Figure 5. From inspection, it can be seen that the program not only describes which cube was picked up and put where, but also what the spatial relations are when stacked. The \u03c0-machine induced and optimised a free parameter which is used to encode the relation \u201cabove\u201d as (+ loc [-0.05 1.17]). This type of information could speed up task learning and improve the robot\u2019s ability to understand its environment."}, {"heading": "6 Discussion", "text": "The \u03c0-machine can be viewed as a framework for automatic network architecture design [37, 38], as different models can be expressed as concise LISP-like programs (see Figure 2). Deep learning methods for limiting the search space of possible programs, which poses the greatest challenge, have been proposed [29], but how they can be applied to more generic frameworks such as the \u03c0-machine is an open question. The specification of variable detectors not only addresses this issue, but enables the user to make targeted and well grounded queries about the observed data trace. Such detectors can also be learnt from raw data in an unsupervised fashion [39, 15]."}, {"heading": "7 Conclusion", "text": "We propose a novel architecture, the \u03c0-machine, for inducing LISP-like functional programs from observed data traces by utilising backpropagation, stochastic gradient descent and A* search. The experimental results demonstrate that the \u03c0-machine can efficiently and successfully induce interpretable programs from short data traces."}], "references": [{"title": "Distilling free-form natural laws from experimental data", "author": ["Michael Schmidt", "Hod Lipson"], "venue": "Science, 324(5923):81\u201385,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Foundations of Neuroeconomic Analysis", "author": ["Paul Glimcher"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Learning spatiotemporal graphs of human activities", "author": ["William Brendel", "Sinisa Todorovic"], "venue": "In Computer vision (ICCV),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Counterfactual reasoning and learning systems: the example of computational advertising", "author": ["L\u00e9on Bottou", "Jonas Peters", "Joaquin Quinonero Candela", "Denis Xavier Charles", "Max Chickering", "Elon Portugaly", "Dipankar Ray", "Patrice Y Simard", "Ed Snelson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Principles of Model Checking", "author": ["Christel Baier", "Joost-Pieter Katoen"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Human-level concept learning through probabilistic program induction", "author": ["Brenden M. Lake", "Ruslan Salakhutdinov", "Joshua B. Tenenbaum"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Neural turing machines", "author": ["Alex Graves", "Greg Wayne", "Ivo Danihelka"], "venue": "arXiv preprint arXiv:1410.5401,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Hybrid computing using a neural network with dynamic external", "author": ["Alex Graves", "Greg Wayne", "Malcolm Reynolds", "Tim Harley", "Ivo Danihelka", "Agnieszka Grabska- Barwi\u0144ska", "Sergio G\u00f3mez Colmenarejo", "Edward Grefenstette", "Tiago Ramalho", "John Agapiou"], "venue": "memory. Nature,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Physical symbol grounding and instance learning through demonstration and eye tracking", "author": ["Svetlin Penkov", "Alejandro Bordallo", "Subramanian Ramamoorthy"], "venue": "In Robotics and Automation,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2017}, {"title": "Interpretable classifiers using rules and bayesian analysis: Building a better stroke prediction model", "author": ["Benjamin Letham", "Cynthia Rudin", "Tyler H McCormick", "David Madigan"], "venue": "The Annals of Applied Statistics,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Scalable bayesian rule lists", "author": ["Hongyu Yang", "Cynthia Rudin", "Margo Seltzer"], "venue": "arXiv preprint arXiv:1602.08610,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Visualizing and understanding convolutional networks", "author": ["Matthew D Zeiler", "Rob Fergus"], "venue": "In European conference on computer vision,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Explaining how a deep neural network trained with end-to-end learning steers a car", "author": ["Mariusz Bojarski", "Philip Yeres", "Anna Choromanska", "Krzysztof Choromanski", "Bernhard Firner", "Lawrence Jackel", "Urs Muller"], "venue": "arXiv preprint arXiv:1704.07911,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2017}, {"title": "Interpretable learning for self-driving cars by visualizing causal attention", "author": ["Jinkyu Kim", "John Canny"], "venue": "arXiv preprint arXiv:1703.10631,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2017}, {"title": "Graying the black box: Understanding dqns", "author": ["Tom Zahavy", "Nir Ben-Zrihem", "Shie Mannor"], "venue": "arXiv preprint arXiv:1602.02658,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Rationalization: A neural machine translation approach to generating natural language explanations", "author": ["Brent Harrison", "Upol Ehsan", "Mark O Riedl"], "venue": "arXiv preprint arXiv:1702.07826,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2017}, {"title": "Generating visual explanations", "author": ["Lisa Anne Hendricks", "Zeynep Akata", "Marcus Rohrbach", "Jeff Donahue", "Bernt Schiele", "Trevor Darrell"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2016}, {"title": "Rationalizing neural predictions", "author": ["Tao Lei", "Regina Barzilay", "Tommi Jaakkola"], "venue": "arXiv preprint arXiv:1606.04155,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Why should i trust you?: Explaining the predictions of any classifier", "author": ["Marco Ribeiro", "Sameer Singh", "Carlos Guestrin"], "venue": "In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Algorithmic Program Debugging", "author": ["Ehud Y. Shapiro"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1983}, {"title": "Combinatorial sketching for finite programs", "author": ["Armando Solar-Lezama", "Liviu Tancau", "Rastislav Bodik", "Sanjit Seshia", "Vijay Saraswat"], "venue": "ACM SIGOPS Operating Systems Review,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Learning to transduce with unbounded memory", "author": ["Edward Grefenstette", "Karl Moritz Hermann", "Mustafa Suleyman", "Phil Blunsom"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Making neural programming architectures generalize via recursion", "author": ["Jonathon Cai", "Richard Shin", "Dawn Song"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2017}, {"title": "Program Induction by Rationale Generation:Learning to Solve and Explain Algebraic Word Problems", "author": ["Wang Ling", "Dani Yogatama", "Chris Dyer", "Phil Blunsom"], "venue": "arXiv preprint arXiv:1705.04146,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2017}, {"title": "Differentiable functional program interpreters", "author": ["John Kser", "Marc Brockschmidt", "Alexander Gaunt", "Daniel Tarlow"], "venue": "arXiv preprint arXiv:1611.01988v2,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2017}, {"title": "Robustfill: Neural program learning under noisy i/o", "author": ["Jacob Devlin", "Jonathan Uesato", "Surya Bhupatiraju", "Rishabh Singh", "Abdel-rahman Mohamed", "Pushmeet Kohli"], "venue": "arXiv preprint arXiv:1703.07469,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2017}, {"title": "Deepcoder: Learning to write programs", "author": ["Matej Balog", "Alexander L Gaunt", "Marc Brockschmidt", "Sebastian Nowozin", "Daniel Tarlow"], "venue": "arXiv preprint arXiv:1611.01989,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "A syntactic neural model for general-purpose code generation", "author": ["Pengcheng Yin", "Graham Neubig"], "venue": "arXiv preprint arXiv:1704.01696,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2017}, {"title": "Chainer: a next-generation open source framework for deep learning. In Proceedings of workshop on machine learning systems (LearningSys) in the twenty-ninth annual conference on neural information processing systems", "author": ["Seiya Tokui", "Kenta Oono", "Shohei Hido", "Justin Clayton"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Theano: A cpu and gpu math compiler in python", "author": ["James Bergstra", "Olivier Breuleux", "Fr\u00e9d\u00e9ric Bastien", "Pascal Lamblin", "Razvan Pascanu", "Guillaume Desjardins", "Joseph Turian", "David Warde-Farley", "Yoshua Bengio"], "venue": "In Proc. 9th Python in Science Conf,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2010}, {"title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems", "author": ["Mart\u00edn Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin"], "venue": "arXiv preprint arXiv:1603.04467,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2016}, {"title": "Autograd: Effortless gradients in numpy", "author": ["Dougal Maclaurin", "David Duvenaud", "Ryan P Adams"], "venue": "In ICML 2015 AutoML Workshop,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2015}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2011}, {"title": "Human-level control through deep reinforcement learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Andrei A Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves", "Martin Riedmiller", "Andreas K Fidjeland", "Georg Ostrovski"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2015}, {"title": "Neural architecture search with reinforcement learning", "author": ["Barret Zoph", "Quoc Le"], "venue": "In International Conference on Learning Representations (ICLR), April 2017", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2017}, {"title": "Deeparchitect: Automatically designing and training deep architectures", "author": ["Renato Negrinho", "Geoff Gordon"], "venue": "arXiv preprint arXiv:1704.08792,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2017}, {"title": "Towards deep symbolic reinforcement learning", "author": ["Marta Garnelo", "Kai Arulkumaran", "Murray Shanahan"], "venue": "arXiv preprint arXiv:1609.05518,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Learning models of transition systems has been a core concern within machine learning, with applications ranging from system identification of dynamical systems [1] and inference of human choice behaviour [2, 3] to reverse engineering the behaviour of a device or computer program from observations and traces [4].", "startOffset": 161, "endOffset": 164}, {"referenceID": 1, "context": "Learning models of transition systems has been a core concern within machine learning, with applications ranging from system identification of dynamical systems [1] and inference of human choice behaviour [2, 3] to reverse engineering the behaviour of a device or computer program from observations and traces [4].", "startOffset": 205, "endOffset": 211}, {"referenceID": 2, "context": "Learning models of transition systems has been a core concern within machine learning, with applications ranging from system identification of dynamical systems [1] and inference of human choice behaviour [2, 3] to reverse engineering the behaviour of a device or computer program from observations and traces [4].", "startOffset": 205, "endOffset": 211}, {"referenceID": 3, "context": "There is also the need to explain the model in terms of counterfactual reasoning [5], e.", "startOffset": 81, "endOffset": 84}, {"referenceID": 4, "context": ", what would we expect the system to do if a certain variable were changed or removed, or model checking [6] of longer term properties including safety and large deviations in performance.", "startOffset": 105, "endOffset": 108}, {"referenceID": 5, "context": "Recent works have demonstrated the usefulness of program representations in capturing human-like concepts [7].", "startOffset": 106, "endOffset": 109}, {"referenceID": 6, "context": "Inspired by differentiable neural computers [8, 9], the \u03c0-machine, as shown in Figure 1, is composed of a memory unit and a controller capable of learning programs from data by exploiting the scalability of stochastic gradient descent.", "startOffset": 44, "endOffset": 50}, {"referenceID": 7, "context": "Inspired by differentiable neural computers [8, 9], the \u03c0-machine, as shown in Figure 1, is composed of a memory unit and a controller capable of learning programs from data by exploiting the scalability of stochastic gradient descent.", "startOffset": 44, "endOffset": 50}, {"referenceID": 0, "context": "The learning procedure has access to relevant variables, but it does not have any other prior knowledge regarding physical laws which it has discovered in the same sense as in [1] although far more computationally tractably.", "startOffset": 176, "endOffset": 179}, {"referenceID": 8, "context": ", in natural language commands) in the embodied sensory signals that robots actually work with, as in [10].", "startOffset": 102, "endOffset": 106}, {"referenceID": 9, "context": "There is recognition that Bayesian rule lists [11, 12], decision trees and probabilistic graphical models are interpretable to the extent that they impose strong structural constraints on models of the observed data and allow for various types of queries, including introspective and counterfactual ones.", "startOffset": 46, "endOffset": 54}, {"referenceID": 10, "context": "There is recognition that Bayesian rule lists [11, 12], decision trees and probabilistic graphical models are interpretable to the extent that they impose strong structural constraints on models of the observed data and allow for various types of queries, including introspective and counterfactual ones.", "startOffset": 46, "endOffset": 54}, {"referenceID": 11, "context": "Zeiler and Fergus [13] introduced deconvolutional networks in order to visualise the layers of convolutional networks and provide a more intuitive understanding of why they perform well.", "startOffset": 18, "endOffset": 22}, {"referenceID": 12, "context": "Similar approaches can be seen in [14, 15], in the context of autonomous driving.", "startOffset": 34, "endOffset": 42}, {"referenceID": 13, "context": "Similar approaches can be seen in [14, 15], in the context of autonomous driving.", "startOffset": 34, "endOffset": 42}, {"referenceID": 14, "context": "[16] describe Semi-Aggregated Markov Decision Process (SAMDP) in order to analyse and understand the behaviour of a DQN based agent.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Methods for textual rationalisation of the predictions made by deep models have also been proposed [17\u201319].", "startOffset": 99, "endOffset": 106}, {"referenceID": 16, "context": "Methods for textual rationalisation of the predictions made by deep models have also been proposed [17\u201319].", "startOffset": 99, "endOffset": 106}, {"referenceID": 17, "context": "Methods for textual rationalisation of the predictions made by deep models have also been proposed [17\u201319].", "startOffset": 99, "endOffset": 106}, {"referenceID": 18, "context": "[20], who provide \u201ctextual or visual artefacts\u201d explaining the prediction of any classifier by treating it as a black-box.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "Similarly to the way in which [20] utilise local classifiers composed together to explain a more complex model, we present an approach to incrementally constructing functional programs that explain a complex transition system from more localised predicates of interest to the user.", "startOffset": 30, "endOffset": 34}, {"referenceID": 19, "context": "Following classic and pioneering work such as by Shapiro [21] who used inductive inference in a logic programming setting, others have developed methods based on a variety of methods ranging from SAT solvers [22] to genetic algorithms [1], which tend to scale poorly hence often become restricted to a narrow class of programs.", "startOffset": 57, "endOffset": 61}, {"referenceID": 20, "context": "Following classic and pioneering work such as by Shapiro [21] who used inductive inference in a logic programming setting, others have developed methods based on a variety of methods ranging from SAT solvers [22] to genetic algorithms [1], which tend to scale poorly hence often become restricted to a narrow class of programs.", "startOffset": 208, "endOffset": 212}, {"referenceID": 0, "context": "Following classic and pioneering work such as by Shapiro [21] who used inductive inference in a logic programming setting, others have developed methods based on a variety of methods ranging from SAT solvers [22] to genetic algorithms [1], which tend to scale poorly hence often become restricted to a narrow class of programs.", "startOffset": 235, "endOffset": 238}, {"referenceID": 6, "context": "These models can induce programs through stochastic gradient descent by optimising performance on input/output examples [8, 9, 23] or synthetic execution traces [24\u201326].", "startOffset": 120, "endOffset": 130}, {"referenceID": 7, "context": "These models can induce programs through stochastic gradient descent by optimising performance on input/output examples [8, 9, 23] or synthetic execution traces [24\u201326].", "startOffset": 120, "endOffset": 130}, {"referenceID": 21, "context": "These models can induce programs through stochastic gradient descent by optimising performance on input/output examples [8, 9, 23] or synthetic execution traces [24\u201326].", "startOffset": 120, "endOffset": 130}, {"referenceID": 22, "context": "These models can induce programs through stochastic gradient descent by optimising performance on input/output examples [8, 9, 23] or synthetic execution traces [24\u201326].", "startOffset": 161, "endOffset": 168}, {"referenceID": 23, "context": "These models can induce programs through stochastic gradient descent by optimising performance on input/output examples [8, 9, 23] or synthetic execution traces [24\u201326].", "startOffset": 161, "endOffset": 168}, {"referenceID": 24, "context": "Interestingly, paradigms from functional programming such as pure functions and immutable data structures have been shown to improve performance of neural interpreters [27].", "startOffset": 168, "endOffset": 172}, {"referenceID": 25, "context": "Usually, these types of approaches require large amounts of labelled data - either program input/output examples [28, 29] or input paired with the desired output program code [30].", "startOffset": 113, "endOffset": 121}, {"referenceID": 26, "context": "Usually, these types of approaches require large amounts of labelled data - either program input/output examples [28, 29] or input paired with the desired output program code [30].", "startOffset": 113, "endOffset": 121}, {"referenceID": 27, "context": "Usually, these types of approaches require large amounts of labelled data - either program input/output examples [28, 29] or input paired with the desired output program code [30].", "startOffset": 175, "endOffset": 179}, {"referenceID": 18, "context": "While these characteristics are of course related, we take a view similar to that of [20], arguing that it is possible to build from locally valid program fragments which provide useful insight into the black-box processes generating the data.", "startOffset": 85, "endOffset": 89}, {"referenceID": 28, "context": "Neural networks are naturally expressed as computational graphs which are the most fundamental abstraction in computational deep learning frameworks [31\u201333].", "startOffset": 149, "endOffset": 156}, {"referenceID": 29, "context": "Neural networks are naturally expressed as computational graphs which are the most fundamental abstraction in computational deep learning frameworks [31\u201333].", "startOffset": 149, "endOffset": 156}, {"referenceID": 30, "context": "Neural networks are naturally expressed as computational graphs which are the most fundamental abstraction in computational deep learning frameworks [31\u201333].", "startOffset": 149, "endOffset": 156}, {"referenceID": 31, "context": "The \u03c0-machine performs reverse-mode automatic differentiation, similarly to Autograd [34], by traversing the call trace \u03c7, and post-multiplying Jacobian matrices.", "startOffset": 85, "endOffset": 89}, {"referenceID": 32, "context": "Once the gradient \u2207pL(\u03c1) of the loss function with respect to each input parameter p \u2208 xp is calculated we utilise AdaGrad [35] to update the values of all parameters after each program execution.", "startOffset": 123, "endOffset": 127}, {"referenceID": 32, "context": "The temporary parameter ptemp is also updated with AdaGrad [35].", "startOffset": 59, "endOffset": 63}, {"referenceID": 8, "context": "The complexity function C(\u03c1) is the weighted sum of (i) maximum depth of the program AST; (ii) the number of free parameters; (iii) the number of variables used by the program; the weights of which we set to wC = [10, 5, 1].", "startOffset": 213, "endOffset": 223}, {"referenceID": 3, "context": "The complexity function C(\u03c1) is the weighted sum of (i) maximum depth of the program AST; (ii) the number of free parameters; (iii) the number of variables used by the program; the weights of which we set to wC = [10, 5, 1].", "startOffset": 213, "endOffset": 223}, {"referenceID": 0, "context": "The complexity function C(\u03c1) is the weighted sum of (i) maximum depth of the program AST; (ii) the number of free parameters; (iii) the number of variables used by the program; the weights of which we set to wC = [10, 5, 1].", "startOffset": 213, "endOffset": 223}, {"referenceID": 0, "context": "We have recreated an experiment described in Schmidt and Lipson [1], where the authors show the learning of physical laws associated with classical mechanical systems including the simple pendulum and linear oscillator.", "startOffset": 64, "endOffset": 67}, {"referenceID": 0, "context": "Schmidt and Lipson [1] achieve similar execution times, but distributed over 8 quad core computers (32 cores in total).", "startOffset": 19, "endOffset": 22}, {"referenceID": 33, "context": "3 [36].", "startOffset": 2, "endOffset": 6}, {"referenceID": 8, "context": "Work in collaborative human-robot interaction [10] suggests that programmatic description of the task enables robots to better ground symbols to their physical instances, improving their perceptual capabilities.", "startOffset": 46, "endOffset": 50}, {"referenceID": 34, "context": "The \u03c0-machine can be viewed as a framework for automatic network architecture design [37, 38], as different models can be expressed as concise LISP-like programs (see Figure 2).", "startOffset": 85, "endOffset": 93}, {"referenceID": 35, "context": "The \u03c0-machine can be viewed as a framework for automatic network architecture design [37, 38], as different models can be expressed as concise LISP-like programs (see Figure 2).", "startOffset": 85, "endOffset": 93}, {"referenceID": 26, "context": "Deep learning methods for limiting the search space of possible programs, which poses the greatest challenge, have been proposed [29], but how they can be applied to more generic frameworks such as the \u03c0-machine is an open question.", "startOffset": 129, "endOffset": 133}, {"referenceID": 36, "context": "Such detectors can also be learnt from raw data in an unsupervised fashion [39, 15].", "startOffset": 75, "endOffset": 83}, {"referenceID": 13, "context": "Such detectors can also be learnt from raw data in an unsupervised fashion [39, 15].", "startOffset": 75, "endOffset": 83}], "year": 2017, "abstractText": "Explaining and reasoning about processes which underlie observed black-box phenomena enables the discovery of causal mechanisms, derivation of suitable abstract representations and the formulation of more robust predictions. We propose to learn high level functional programs in order to represent abstract models which capture the invariant structure in the observed data. We introduce the \u03c0-machine (program-induction machine) \u2013 an architecture able to induce interpretable LISPlike programs from observed data traces. We propose an optimisation procedure for program learning based on backpropagation, gradient descent and A* search. We apply the proposed method to three problems: system identification of dynamical systems, explaining the behaviour of a DQN agent and learning by demonstration in a human-robot interaction scenario. Our experimental results show that the \u03c0machine can efficiently induce interpretable programs from individual data traces.", "creator": "LaTeX with hyperref package"}}}