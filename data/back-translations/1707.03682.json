{"id": "1707.03682", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2017", "title": "A Deep Learning Approach for Blind Drift Calibration of Sensor Networks", "abstract": "Temporary drift of sensory data is a serious problem affecting the data quality of wireless sensor networks (WSNs), a problem known as \"blind calibration.\" In this paper, we propose a novel method called Projection-Recovery Network (PRNet) to blindly calibrate sensor measurements online. PRNet first projects the drift data onto a feature space and uses a powerful deep revolutionary neural network to restore the estimated drift-free measurements. We use a 24-sensor test rig and provide comprehensive empirical evidence that the proposed method greatly improves sensor accuracy and drift sensor detection. Compared to previous methods, PRNet can calibrate two drift sensors at 80% recovery rate below the same level of accuracy.", "histories": [["v1", "Fri, 16 Jun 2017 17:10:13 GMT  (2981kb)", "http://arxiv.org/abs/1707.03682v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.DC", "authors": ["yuzhi wang", "anqi yang", "xiaoming chen", "pengjun wang", "yu wang", "huazhong yang"], "accepted": false, "id": "1707.03682"}, "pdf": {"name": "1707.03682.pdf", "metadata": {"source": "CRF", "title": "A Deep Learning Approach for Blind Drift Calibration of Sensor Networks", "authors": ["Yuzhi Wang", "Anqi Yang", "Xiaoming Chen", "Pengjun Wang", "Yu Wang"], "emails": ["yz-wang12@mails.tsinghua.edu.cn;", "yang-aq14@mails.", "wangpj@tsinghua.edu.cn;", "yu-wang@tsinghua.edu.cn;", "yanghz@tsinghua.edu.cn).", "xchen7@nd.edu)."], "sections": [{"heading": null, "text": "Index Terms\u2014 Sensor networks, blind calibration, deep learning, convolutional neural networks.\nI. INTRODUCTION\nAWIRELESS sensor network (WSN) is composed of agroup of small and inexpensive sensors with the ability of sensing, measuring, data processing, and communication. WSNs can gather information from the environment and transmit the collected data to users [1]. They have important usage in many emerging applications such as environmental monitoring [2], smart cities [3], precise agriculture [4], etc. In recent years, mature WSN technologies have made it possible to deploy large-scale WSNs at an acceptable cost. In practice, many WSNs have hundreds of sensors deployed [2], [5].\nWith the proliferation of large-scale and long-term WSNs, sensor drift, however, has become a serious practical problem. For example, Ni et al. [6] give an example of a drifted\nManuscript received April 3, 2017; revised May 6, 2017; accepted May 6, 2017. Date of publication May 12, 2017; date of current version June 12, 2017. This work was supported by the National Natural Science Foundation of China under Grant 61271269 and Grant 61321061. The associate editor coordinating the review of this paper and approving it for publication was Dr. Ashish Pandharipande. (Corresponding author: Yuzhi Wang.)\nY. Wang, A. Yang, P. Wang, Y. Wang, and H. Yang are with the Department of Electronic Engineering, Tsinghua University, Beijing 100084, China (e-mail: yz-wang12@mails.tsinghua.edu.cn; yang-aq14@mails. tsinghua.edu.cn; wangpj@tsinghua.edu.cn; yu-wang@tsinghua.edu.cn; yanghz@tsinghua.edu.cn).\nX. Chen is with the Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN 46556 USA (e-mail: xchen7@nd.edu).\nDigital Object Identifier 10.1109/JSEN.2017.2703885\nsoil CO2 sensor reporting erroneous data which is about 200% of the expected ground truth. What is worse, WSNs can scale out to hundreds or even thousands of sensors which are often deployed in nearly inaccessible locations, such as wild fields and building structures. It is infeasible to unmount and re-calibrate the sensors individually. Therefore, there is an urgent need to calibrate the sensors without the ground truth data. This problem is called blind calibration [7].\nMany general monitoring applications require blind calibration, such as environmental monitoring, structure health monitoring, precise agriculture, etc. To blindly calibrate a monitoring WSN, we must find an alternative calibration reference instead of the ground truth. However, there are two major challenges in finding an appropriate reference:\n\u2022 Lack of a prior data model: In monitoring applications, there are many kinds of measurands, such as temperature, humidity, air quality, etc. The large amount of complicated, coupling factors make it difficult, if not impossible, to build a white-boxed data model. \u2022 Low-density deployment: For a sensor network monitoring a field of interest, as depicted in Fig. 1(b), measurand data from different sensors may vary significantly. Therefore, measurements from neighbour sensors cannot be directly used as a proper reference.\nIn this paper, we propose a deep neural network named Projection-Recovery network (PRNet) to blindly calibrate sensor measurements online. It conquers the first challenge by learning features from sensory data as opposed to applying a prior data model, and the second challenge is overcome by utilizing the spatial and temporal correlations of data from all sensors instead of the direct equality of neighbour data. PRNet first projects the drifted measurements to a feature space to separate the mixed drift from the signal, and then recovers the\n1558-1748 \u00a9 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.\ndrift-free measurements. Existing blind calibration methods need special assumptions, such as the linearity of the data space and the sparsity of the drift, and also use pre-defined rules for feature extraction and sensor calibration [7]\u2013[13]. On the contrary, PRNet has less application-related assumptions and can better utilize data correlations to calibrate drifted sensors with end-to-end learning approaches. Experimental results show that PRNet brings much higher recovery rate and lower calibration error compared with existing methods.\nThe main contributions of this paper include: \u2022 We propose PRNet, a novel deep neural network architec-\nture which can automatically extract spatial and temporal features from sensory data and generate recovered driftsuppressed measurements. We also provide a data augmentation method to generate infinite samples of training data from limited sensor measurements and improve the robustness of the model. To the best of our knowledge, this is the first work that applies deep learning in sensor data calibration. \u2022 We explore the influence of network architecture and parameter selection on the calibration accuracy, and provide comprehensive insights in designing efficient deep neural networks for spatial-temporal data processing. \u2022 Both simulated and real-world testbed datasets are used to evaluate PRNet. Experimental results show that, compared with the existing SPSR-TSBL (subspace projection and sparse recovery with temporal correlated sparse Bayesian learning) method, PRNet can calibrate two times of drifted sensors at the recovery rate of 80% with the same level of accuracy. More benchmarks on generalization ability show PRNet can calibrate different types of drifts under noisy measurements.\nThe rest of this paper is organized as follows. We first formulate the blind calibration problem and review related work in Section II. Next we describe the architecture and the training method of PRNet in Section III. In Sections IV and V, we benchmark the performance of PRNet on both testbed and simulated datasets, and further explore how different settings can influence PRNet\u2019s performance. We discuss the interpretability of our method and give an intuitive explanation in Section VI. Finally, we conclude this work in Section VII."}, {"heading": "II. PRELIMINARIES", "text": "In this section, we introduce necessary preliminaries of this work, including the problem formulation of blind calibration for sensor networks and existing work for this problem."}, {"heading": "A. Problem Formulation", "text": "Considering a sensor network deployed in a field of interest, we assume that the measurand signal is continuous within the sensing space, and the measurements collected from the sensors are spatially and temporally discrete samples of the signal field, as shown in Fig 2.\nLet N denote the number of sensors, and xi,t denote the ground truth signal value at time epoch t in the position of Sensor-i . Ideally, Sensor-i should report xi,t as its measurement. However, due to the existence of sensor drift and\nmeasurement noise, Sensor-i , in fact reports an erroneous measurement value, denoted as yi,t . We assume that\nyi,t = xi,t + di,t + vi,t (1) where xi,t , di,t and vi,t represent the ground truth signal value, the drift and noise value of Sensor-i at time instant t , respectively. Usually, sensor drift is a long-term process and smoothly increases over time [14], [15], so its value may be at the same order of magnitude with the signal. Measurement noise, however, does not accumulate over time, and, in most cases, noise is much smaller than the signal.\nTo describe the measurement model given by Eq. (1) for a sensor network, we rewrite it into a matrix notation, given by\nY = X + D + v (2) where X , Y , D and v represents the ground truth signal, the measured value, the sensor drift and measurement noise, respectively. Each variable, for example, Y , is an N \u00d7 T matrix, where T is the temporal length. Therefore, each row yi,\u00b7 is a series of measurements reported by sensor-i , and each column y\u00b7,t represents the measurements of all sensors collected at time instant t .\nThe blind calibration process is to recover the unknown ground truth X from sensor measurements Y with unknown sensor drift D and noise v. Let fc(\u00b7) denote a calibration function. Our goal is to find a function fc(\u00b7) to minimize the calibration error. This optimization problem can be written as\nmin fc(\u00b7) \u2016 fc(Y )\u2212 X\u2016 (3) where \u2016 \u00b7 \u2016 represents a general norm operator and X is unknown. Note that this form of optimization goal is an abstract representation. The detailed measurement of the calibration error, and the constraint conditions of Eq. (3) are both specific to the application.\nIn general monitoring applications, the elements of X can be assumed to be correlated over row (space) and column (time). Different ways of building the calibration function result in different calibration methods."}, {"heading": "B. Related Work", "text": "As discussed in the above subsection, the key point of blind calibration is to find the reference signal. Many existing blind calibration methods rely on specific application features, such as a prior data model [16], [17], dense-deployment [18], or sensor mobility [19], [20].\nHowever, for general monitoring applications, sensors are usually deployed in fixed locations at a low density. To find\nthe reference for calibration, a reasonable assumption is that the sensory data are correlated, since they share the same feature set of the sensing field. There are mainly two kinds of calibration scheme based on this assumption: prediction and subspace projection.\nThe prediction-based calibration framework, which is illustrated in Fig. 3(a), is proposed by Takruri et al. [11], where the ground truth of a sensor is first predicted using the neighbour sensors\u2019 measurements, and then a Kalman filter (KF) is employed to track the sensor\u2019s drift. Following works apply different prediction functions in this framework, including support vector regression (SVR) [12] and Kriging interpolation [13]. However, the prediction function can only deal with drift-free measurements, so a sensor should be calibrated before it is used to predict other sensors\u2019 measurements. Therefore, there exists a prediction-calibration loop in this framework. Once the drift estimation becomes inaccurate, the feedback loop will possibly amplify the estimation error, leading to instable and erroneous calibration results.\nBalzano and Nowak [7] first proposed the idea of signal subspace where the sensory data lie in, so a part of calibration parameters can be obtained by solving a homogeneous linear system. In this work, the calibration model contains a scaling term and an offset term. However, only the scaling term can be effectively solved, while estimating the offset term needs further assumptions. In our previous works [8], [9], we extend this idea by modeling the drift calibration problem as sparse signal recovery, and use Kalman filter or sparse Bayesian learning to estimate the sensor drift from measurements. As depicted in Fig. 3(b), the measurement space is divided into the signal subspace and its orthogonal complement, namely, the signal null subspace. The projection of sensor measurements onto the signal null subspace is fully driven by sensor drifts and noise, so this projection is a lower dimensional observation of the drift and noise. As shown in Fig. 3(c), by estimating sensor drift from the drift observation using sparse recovery methods, drifted sensors can be calibrated. Experiments [8], [9] show that the subspace methods are more stable and more accurate than the prediction methods. However, due to the systematic limitation of the under-determined calibration equations, only a portion of sensors can be calibrated.\nIn recent years, deep neural networks have reached the state-of-the-art performance in many applications, especially in computer vision (CV). Some applications, such as image denoising and inpaiting [21] aiming at restoring\ncorrupted images, have some similarities with the sensor calibration problem. However, since sensory data have very different features from images, our experiments show that the networks designed for CV applications cannot work well in sensor calibration. There are also some works that apply deep learning to multivariate time-series applications. Lipton et al. [22] use a recurrent neural network (RNN) to detect events from segments of clinical measurements. However, training such an RNN needs a large amount of long-term time series data, which is infeasible for a specific sensor network with limited data.\nIn this paper, we propose a convolutional neural network (CNN) to blindly calibrate general monitoring sensor networks. As shown in Fig. 3(d), the proposed method directly maps the drifted measurements to drift-suppressed measurements. Similar to the subspace and prediction methods, the calibration function is learned from the sensory data. However, the subspace and prediction methods have two steps: 1) learning the subspace or prediction function, and 2) recovering sensory data using pre-defined rules. In these two steps, only the learning step can fully utilize data features. The proposed neural network, on the contrary, is an end-to-end method, where the feature learning and the drift compensation steps are modeled as different layers, which are jointly trained using sensory data. This means that the proposed method can make better use of data correlations and learn a better data model. In Table I, we give a qualitative comparison of the three blind calibration schemes."}, {"heading": "III. CALIBRATION WITH DEEP FULL CONVOLUTIONAL NEURAL NETWORK", "text": "CNNs [23] are widely used in image processing. To design a CNN-based method for blind calibration of sensor networks, there are two major challenges:\n\u2022 Many existing works on CNNs are proposed for image processing. How do we design the network architecture for sensor drift calibration?\n\u2022 Deep neural networks need to be trained with a large amount of training data, whereas the sensory data collected from a specific sensor network are limited. How to train the neural network with limited sensory data?\nTo solve the first issue, we extend the idea of the previous SPSR framework [9] by designing a projection-recovery CNN architecture named PRNet. The first layer projects the drifted measurements to a feature space, and this layer is trained to keep the drift features. The following recovery layers are trained to fuse the features to drift-free output. When the training converges, the network can automatically extract features from sensory data and fuse these features to drift-free measurements.\nSimilar to previous works [9], [12], we assume that the sensors are calibrated before deployment, so the sensory data collected within a short period after deployment can be regarded as drift-free. We propose a data augmentation method which generates training data from a relatively small dataset. Thus the second issue can be solved."}, {"heading": "A. Convolution on Sensory Data", "text": "Before describing the architecture of PRNet, we present our basic idea of applying convolutions to sensory data. Let Y N\u00d7T denote the matrix containing sensory data collected from a sensor network, where the rows represent measurements from N different sensors, and the columns are measured at T different time instants. The input of a convolution layer is a 3-D tensor, denoted as X(N,T ,c), where N , T , and c represent its numbers rows, columns, and channels, respectively. Therefore, we convert the measurement matrix Y N\u00d7T to a tensor Y (N,T ,1) so that it can be fed to a convolution layer.\nA convolution layer consists of several convolution kernels. Each of them is a filter with the size of (ks, kt , c), which maps a patch of its input tensor to a scalar, given by\nxout = \u03c3( \u2211\nW (ks ,kt ,c) \u25e6 X(ks ,kt ,c) + b) (4) where W (ks ,kt ,c) and b are the parameters of the convolution kernel and the bias term respectively; X(ks ,kt ,c) is a patch of the input tensor; \u25e6 is the Hadamard product, and \u03c3 represents a nonlinear activation function. Usually, as c is decided by the input tensor, we use ks\u00d7kt to denote the size of a convolution kernel. As shown in Fig. 4, a convolution kernel slides over the space (row) and time (column) dimension of the input tensor, and maps a c-channeled input tensor to an 1-channel output tensor. Since a convolution layer contains cout kernels, its output tensor has cout channels. The rows and columns of the output tensor are decided by the padding size of the input tensor and the sliding stride of the filter.\nFig. 4 shows a basic CNN applied to sensor measurements. By properly setting the padding size on the input tensors, the numbers of rows and columns of all tensors can be kept N and T . Because of the cascading structure of CNNs, each element of a feature tensor is a fusion of sensory data from multiple sensors measured at multiple time instants, and this patch of sensory data is named as a receptive field. Therefore, a CNN can utilize both spatial and temporal correlations of sensor measurements.\nThe last convolution layer has only one convolution kernel and outputs an (N, T, 1) tensor, which is of the same size as the input sensor measurements. The task of the output layer is to decode the features extracted by the previous layers and fuse them into drift-suppressed measurements."}, {"heading": "B. Architecture of PRNet", "text": "The architecture of PRNet is derived from the basic CNN for sensory data. We first review the key idea of the previous stateof-the-art subspace-based calibration framework. According to [8], if the drift-free measurements lie in a signal subspace, a projection matrix P can be obtained, which satisfies\nPY = P(X + D) = P D (5) where X , D and Y represents the ground truth signal, sensor drift and drifted measurements, respectively. This equation is the key point of the subspace method, since the projection eliminates the unknown ground truth signal, obtaining a lowerdimensional observation of the drift.\nIn our work, we extend this drift projection by implementing it with a N \u00d7 \u03c4 global convolution layer, where N is the number of sensors and \u03c4 is a temporal window size. Recalling the convolution function of a single kernel in Eq. (4), let w = vec(W (N,\u03c4,1)) and y\u03c4 = vec(Y (N,\u03c4,1)), where W (N,\u03c4,1) is the weight tensor of the convolution kernel, and Y (N,\u03c4,1) is a temporal patch of the drifted measurement tensor, and vec(\u00b7) stacks the columns of a tensor to a column vector. Eq. (4) can be rewritten as\nxout(1,1) = \u03c3(wT y\u03c4 + b). (6) For a convolution layer with R kernels, we stack the weight vectors to a matrix and bias terms to a vector by setting W = [w1,w2, . . . ,wR]T and b = [b1, b2, . . . , bR]. The output function of this convolution layer is\nxout(1,1,R) = \u03c3(W y\u03c4 + b). (7) Thus, we obtain the convolution-based projection, which is a natural extension to the linear projection PY with two advantages. First, the convolution is applied to multiple measurement vectors, so temporal correlations of the sensing signal can be utilized. Second, with the nonlinear activation\nfunction, this projection can be applied to measurements from nonlinear sensing fields. If \u03c4 is set to 1 and the activation function is linear, this convolution projection is equivalent to the linear projection used by subspace methods.\nFig. 5(a) illustrates the overall architecture of the proposed PRNet. The projection layer is a convolution layer with kernel size N \u00d7 7, and the activation function is tanh(\u00b7). The hyperparameter R, which is the number of convolution kernels and the dimension of the projection space, should be decided based on the number of sensors. In practice, a number around 2N is an appropriate choice. The term BN refers to Batch Normalization [25], which helps accelerate the training.\nAfter the drift observation is obtained, the following layers estimate the drift. As the output size of the projection layer is (1, T, R), we first up-sample and reshape it to an (N, T, 4) tensor with a convolution and reshaping layer, followed by a special re-arrangement layer to put the measurements from neighbour sensors into adjacent rows, which will be discussed in Section III-C.\nNext, several convolution layers extract and fuse features from the projected tensor. The architecture of these recovery layers is derived from ResNet [24], [26], which is a state-ofthe-art CNN architecture widely used in CV applications. The basic component of the recovery layers is a ResUnit, depicted in Fig. 5(b). Each ResUnit has two branches. The main branch is an identity shortcut, which directly passes the input to the output, and the auxiliary branch contains convolution layers. The outputs of the two branches are added before being fed to the next layer. The first ResUnit, as the channel size increases from 16 to 64, includes an 1\u00d71 convolution layer in the main branch to ensure the feature maps in its two branches have the same number of channels. Some recent works [27], [28] found that this special architecture has better representational ability and is easier to train than conventional CNN architectures.\nThe output of the last convolution layer is the drift estimation. By subtracting the estimated drift from the drifted measurements, we obtain the estimation of drift-free measurements."}, {"heading": "C. Sensor Re-Arrangement", "text": "In this subsection, we focus on the input and output data of the recovery layers. As discussed before, the recovery layers\nestimate the drifts by utilizing the data correlation within the receptive field of their input data. However, the sizes of their receptive fields are limited. Therefore, it is required that the adjacent rows and columns of the input data should be as correlated as possible. The columns of the input data represent time instants, which are naturally ordered and the adjacent data are naturally correlated. However, the row order of the input data depends on the numbering of sensors. Therefore, we need to re-arrange to rows of the input data in a proper order.\nWe model the sensor re-arrangement operation as a simple matrix multiplication. For a matrix M(K ,N), it is a re-arrangement matrix if and only if the following conditions hold: \u23a7\n\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a8\n\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a9\nK \u2265 N mi, j \u2208 {0, 1} \u2200mi, j \u2208 M(K ,N) \u2211\nM i,\u00b7 = 1 \u2200i \u2208 {1, 2, . . . K } \u2211\nM \u00b7, j \u2265 1 \u2200 j \u2208 {1, 2, . . . N}\n(8)\nEq. (8) means that a re-arrangement matrix is composed of 0 and 1, each row of which only contains one 1 and each column of which contains at least one 1s. Given a measurement matrix X(N,T ), by left multiplying X(N,T ) by M (K ,N), we obtain a re-arranged measurement matrix, given by\nX R(K ,T ) = M(K ,N)X(N,T ). (9) As K can be larger than N , each row of X(N,T ) can appear multiple times in X R(K ,T ).\nBy modeling the re-arrangement operation as matrix multiplication, it is easy to be implemented as a re-arrangement layer in a neural network. We put the re-arrangement layer before the recovery layers, as shown in Fig. 5(a). In addition, after the drift estimation is obtained, we need to inversely arrange the rows of the drift-estimation matrix to match the original sensor order. This operation can also be easily implemented by left multiplying the drift-estimation matrix by an inverse-arrangement matrix M R(N,K ), which is the rownormalized transpose of the re-arrangement matrix, given by:\nM R0(N,K ) = MT(K ,N) (10) M Ri,\u00b7 = M R0i,\u00b7 /\u2016M R0i,\u00b7 \u20160. (11)\nNext, we discuss how to decide the order of the re-arranged matrix. Usually, we can have some prior assumptions on the correlations of different sensors. Without loss of generality, we assume that neighbour sensors are more correlated. In other words, the correlation between two sensors depends on their distance. We denote the distance between sensor-i and sensor- j as d(i, j), and let s[k] be the sensor number corresponding to the k-th row of the re-arranged matrix. To maximize the local correlation of the re-arranged matrix, we need to give an optimal mapping s[\u00b7] to minimize the maximum sensor distance, and every sensor should be included in this mapping, written as\nmin K max i=1 d(s[i ], s[i + 1]) (12) s.t. K\u22c3\ni=1 s[i ] = {1, 2, . . . , N}. (13)\nThe optimal solution of Eq. (12) can be obtained with the following steps:\n1. Generate a minimum spanning tree (MST) on the sensor graph; 2. Duplicate every edge of the MST, obtaining a Eulerian graph; 3. Set s[\u00b7] by traversing over a Eulerian circuit over the Eulerian graph.\nBesides the optimal mapping, an approximation can also be employed, since the convolution kernels in PRNet have the ability to utilize sensor data in its receptive field. In our experiments, for simplicity, we use a greedy nearest neighbour algorithm to generate s[\u00b7]. We first set s[1] to 1, and choose the nearest non-visited neighbour sensor for the next step until all sensors are visited.\nAs long as s[\u00b7] is obtained, M (K ,N) can be calculated by setting M i,s[i] to 1 for all i \u2264 N , and other elements to zero."}, {"heading": "D. Training Data Generation", "text": "As sensor networks deployed in different sensing fields vary a lot in data features, the calibration model for a specified sensing field must be trained using the sensory data collected from the very same field. To train PRNet, pairs of drifted and drift-free measurements are required, but for a deployed sensor network, both the drift-free signal and the drift are unknown. Moreover, the amount of sensory data from one single sensor network is limited, while a neural network must be trained with a large amount of data. Therefore, we propose a data synthesis and augmentation method to build the training dataset.\nWe assume that the sensors are calibrated before deployment, so the sensory data collected within a short period after deployment should contain negligible drift and carry the features of the sensing field. On the contrary, sensor drift and noise, are usually caused by errors and non-ideal factors of sensor hardware [6]. Therefore, we can use drift-free measurements and simulated sensor drift to synthesize drifted measurements. What is more, as infinite samples of sensor drift can be generated according to any possible model, the amount of training data also gets increased.\nSince the temporal sizes of convolution kernels in PRNet are limited, we do not need to use all the training data for each iteration. Instead, we apply random-cropping to generate small patches of measurement data. This is also widely used in other research areas such as time-series bootstrapping [29], [30]. We denote the sensory data of the initial period as X I, which is an N \u00d7 TI matrix, where TI is the length of the initial period. In each iteration, we randomly crop a small N \u00d7 TP patch from X I denoted as XP. Therefore, we can generate TI \u2212 TP patches from the initial sensory data by\n{X P} = {X I\u00b7,\u03c4 :\u03c4+TP | \u2200\u03c4 \u2208 [1 . . . TI \u2212 TP ]} (14) where {X P} stands for the set of patches, and X I\u00b7,\u03c4 :\u03c4+TP is an N \u00d7 TP sub-block of X I from column \u03c4 to \u03c4 + TP . Thus, we obtain TI \u2212 TP segments of sensory data which carry the features of the sensing field. Besides, by cropping the measurements to small patches, the randomness and diversity of the training set get increased, which can help avoid overfitting.\nThe selection of TP depends on the receptive field size over the time dimension of the neural network, denoted as Rt . If TP is smaller than Rt , some layers of the neural network will not be able to obtain enough training data. Our experiment shows that a small TP which is slightly larger than Rt is appropriate.\nFig. 6 illustrates the augmentation process. We randomly crop a drift-free patch X P , and randomly generate N drift and noise samples, denoted as DP and vP . Thus, a patch of drifted measurements can be generated by adding the drift and noise to the drift-free patch, denoted as\nY P = X P + DP + vP . (15) In practice, the drift and noise generation model should be designed based on the sensor type and application requirements. If required, more kinds of corruptions can be added to the measurements, such as random bias, temporary data loss, etc. In this paper, to demonstrate a general calibration process, without loss of generality, noise is modeled as white Gaussian and the sensor drift is modeled as a random walk process. The sensor noise is generated by\nvi,t \u223c N (0, \u03c3 2n ). (16) We assume that the drift of different sensors are independent, and drift increments at different time instants are i.i.d. and Gaussian. This can be written as\ndi,t = di,t\u22121 + \u03b4i,t , \u03b4i,t \u223c N (0, \u03c3 2i,t ) (17)\nwhere di,t is the drift value, and \u03b4i,t is the increment of Sensor-i \u2019s drift at time instant t . Therefore, the sensor drift is the accumulation of a series of Gaussian increments, which is still Gaussian [31], given by\ndi,t \u223c N (0, t\u2211\n\u03c4=0 \u03c3 2i,\u03c4 ). (18)\nNote that Eq. (18) is a time-irrelevant model representing the prior distribution of sensor drift at a single arbitrary time instant. Although it indicates that the expectation of sensor drift is zero, it does not mean that a specific series of sensor drift is zero-mean as Eq. (18) ignores the temporal correlation of drift values.\nCombining Eqs. (18) and (17), we generate drift patches by\ndi,0 = \u03bci + \u03b2, \u03bci \u223c N (0, \u03c3 20 ), \u03b2 \u223c N (0, \u03c3 2b ) (19) di,t = di,t\u22121 + \u03b4i,t , \u03b4i,t \u223c N (0, \u03c3 2d ). (20)\nEq. (19) describes the generation of the start value of the drift patch. Compared with Eq. (18), in addition to the Gaussian variable \u03bci which varies among sensors, we also add a global Gaussian bias value \u03b2. This is to add a small nonzero offset to the drift of sensors within a single patch. Eq. (20) is simplified from Eq. (17), where \u03c3 2d , the variance of drift increment, is a constant value. Another issue is that in many cases, not all sensors in a network are drifted. Therefore, we randomly set d i,\u00b7 to zero at the probability of 0.5.\nThe selection of the drift level parameters \u03c30, \u03c3b and \u03c3d depends on the application requirements. As PRNet learns features of sensory data from drifted patches, it is best that the simulated drift is slightly greater than the real possible drift. Considering that the variance of di,0 is \u03c3 20 + \u03c3 2d , according to the three-sigma rule, in our experiment, we set 3 \u221a \u03c3 20 + \u03c3 2d to 60% of the dynamic range of the sensor measurements. The algorithm for training patch generation is listed in Algorithm 1. In lines 1-10, we first generate an N \u00d7 TP noise patch and drift patch according to Eq. (16), Eq. (19) and Eq. (20), and then randomly crop a drift-free patch from the initial sensor measurements according to Eq. (14) in lines 13 and 14. Finally, corresponding to Eq. (15), by adding the generated drift and noise to drift-free measurements in line 15, we obtain the drifted measurements. As we can generate TI \u2212 TP different patches of drift-free measurements and infinite drift samples, we manage to generate a large amount of data to train PRNet."}, {"heading": "E. Training", "text": "The training process of a neural network is to minimize a loss function with respect to input data by adjusting the network parameters. The loss function of PRNet includes the projection loss and the recovery loss, denoted as\nL P R = L P + L R . (21) Recalling Eq. (5) that the key function of the projection layer is to obtain a drift observation from drifted measurements\nAlgorithm 1 : Generating a Patch for Training\nInput : X IN\u00d7TI : initial sensor measurements, TP : patch length, \u03c30, \u03c3b, \u03c3d , \u03c3n: drift and noise parameters Output: Y p: a patch of drifted measurements, Xp: a patch of drift-free measurements\n1 v \u2190 (vi j )N\u00d7TP with vi j sampled from N (0, \u03c3 2n ) ; 2 \u03b2 \u2190 random number from N (0, \u03c3 2b ); 3 for i \u2190 0 to N \u2212 1 do 4 r \u2190 random number from U(0, 1) ;\n// each sensor has the probability of 0.5 to be drifted\n5 if r \u2264 0.5 then 6 \u03bci \u2190 random number from N (0, \u03c3 20 ) ; 7 d i,0 \u2190 \u03bci + \u03b2 ; 8 for t \u2190 1 to TP \u2212 1 do 9 \u03b4i,t \u2190 random number from N (0, \u03c3 2d ) ;\n10 d i,t \u2190 d i,t\u22121 + \u03b4i,t ;"}, {"heading": "11 else", "text": "12 d i,\u00b7 = 0; 13 \u03c4 \u2190 random number from U(0, TI \u2212 TP) ; 14 Xp \u2190 X I\u00b7,\u03c4 :\u03c4+TP ; // retrieve random patch 15 Y p \u2190 Xp + d + v ;\nto approximate the projected ground truth drift. Therefore, the projection loss is designed as\nL P = 1 2|D|NTP\n\u2211 i\u2208D \u2016 f p(Y Pi )\u2212 f p(Y Pi \u2212 X Pi ))\u20162F (22)\nwhere X P and Y P are patches of drift-free and drifted measurements; f p(\u00b7) represents the function of the projection layer, and D represents the training dataset.\nFor the recovery loss, we simply use the mean square error (MSE) between the calibrated measurements and the ground truth signal:\nL R = 1 2|D|NTP\n\u2211 i\u2208D \u2016 fP R(Y Pi )\u2212 X Pi \u20162F (23)\nwhere fP R(\u00b7) denotes the overall forward function of PRNet. Note that the parameters of the projection layer are also included in this loss, so there are two optimization objectives for the projection function.\nEq. (23) is a concrete form of Eq. (3), where our calibration function is built by designing the architecture and training the parameters of PRNet, and the norm of calibration error is MSE.\nWe use the Adam optimizer [32] to minimize the loss function. The training dataset is divided into mini-batches which are used to train PRNet. When the optimization converges, PRNet will have learned to extract spatial and temporal features of the sensing field and to suppress sensor drift.\nAnother issue about the training dataset is the parameter selection. We apply a simple curriculum learning [33] strategy on selecting the drift emulation parameters \u03c30, \u03c3b, \u03c3d and \u03c3n .\nBecause we need the trained neural network to calibrate sensor drift on different levels, \u03c30 and \u03c3b should be large enough so that the augmented training data can cover more drift levels. However, we found that directly training the neural network with large drift and noise from scratch may not converge. Therefore, we first pre-train the neural network with small drift and noise, then fine-tune the trained neural network with larger drift and noise. Thus, this neural network can deal with different levels of sensor drifts."}, {"heading": "IV. PERFORMANCE EVALUATION", "text": "In this section, we use a real-world sensor dataset to evaluate the proposed method and compare our method with two existing blind calibration methods."}, {"heading": "A. Datasets", "text": "Although there are many WSN projects deployed and running, and some of which have open datasets, we do not know whether those sensors are drifted and how accurate the measurements are. After calibrating these measurements, the correctness of calibration results is unknown either. Therefore, we set up a testbed which has multiple redundant sensors in every position to ensure accurate measurements, and use simulated drift and noise to benchmark calibration algorithms. Besides, as the scale of testbed is limited, we also simulate a nonlinear sensing field to generate a more challenging dataset.\n1) Testbed Dataset: We use the same testbed described in our previous work [9] deployed in our lab to build the dataset. The testbed consists of 6 sensing units deployed in different locations in our lab. Each sensing unit has 4 sensors measuring temperature at the same location, including a commercial thermometer (type WSB-1-H2, prices at $50 each) and 3 cheap temperature sensors (type DS18B20, prices at $0.5 each). The DS18B20 sensors report their measurements every 30 seconds, and the thermometers\u2019 measurements are collected every 5 minutes.\nWe use the collected data from March 1 to April 24, 2016, then re-sample it to a 3-minute interval, and drop the corrupted samples. Hence, the dataset contains measurements from 24 sensors, and each sensor has 25 935 samples. For each DS18B20 sensor, we calculate its offset to its corresponding thermometer. The offset of different sensors varies from \u22120.8 \u25e6C to 0.5 \u25e6C, but for each sensor, its offset variation is within \u00b10.1 \u25e6C over time. Therefore, we use the mean offset to calibrate each DS18B20 sensor, which has the measurement error of \u00b10.1 \u25e6C after calibration, and the calibrated dataset can be considered drift-free.\nWe plot the first 10 000 samples of testbed data from 4 selected sensors in Fig. 7(a). We can see that the measurements from sensors in the same sensing unit are almost identical, while different sensing units report different measurements.\n2) Simulated Dataset: The real-world testbed dataset is collected by 24 sensors deployed in 6 locations in a room, which can not provide much inter-sensor variation. To fully benchmark the performance of PRNet, we simulate a more challenging dataset for calibration algorithms.\nWe simulate a circular sensing field with radius 10, where 50 sensors are deployed in random locations. The driftfree measurement of a sensor is a nonlinear combination of 20 signal sources, given by\nxi,t = ( 20\u2211\nj=1 a j,i s j,t\n)1/2+\u221a(a\u0307i \u02d9si,t )(a\u0308i \u00a8si,t ) \u2200i \u2208 {1, 2, . . . , 50}\n(24)\nwhere xi,t is the drift-free measurement of sensor-i at time instant t , and s j,t represents the signal value of source- j . The special terms \u02d9si,t and \u00a8si,t represent the nearest two signal sources of sensor-i . The combination coefficient a j,i is determined by the distance between a sensor and a source, given by\na j,i = ( j,i + 1)\u22121.5 (25) where j,i represents the distance. For each signal source, we independently simulate 24 000 samples of its signal values with a lowpass-filtered ARMA (Autoregressive moving average) process, plus a random trend signal. Using Eqs. (25) and (24), we obtain the drift-free measurements of 50 sensors, each of which has 24 000 samples. Therefore, the measurements of each simulated sensor is different and nonstationary, but still have nonlinear correlation. We randomly selected 10 sensors and plot the simulated measurements in Fig. 7(b)."}, {"heading": "B. Training Settings", "text": "In both the testbed and simulated datasets, we use the first 8000 samples of each sensor to build the training dataset. The augmentation patch length Tp is set to 20, and the minibatch size is set to 64. For the testbed dataset, we set the dimension of the projection space to 64, and for the simulated\ndataset, we set it to 128. The weight parameters are initialized using the initialization method proposed by He et al. [34], and the bias parameters are initialized to zeros. As the sensor measurement matrix is already ordered in sensing units, we use an identity matrix to bypass the re-arrangement. For the simulated dataset, we obtain the re-arrangement matrix using the nearest-neighbour algorithm.\nDuring the pre-training process, the drift generation parameters \u03c30, \u03c3b and \u03c3d are set to 0.5, 0.2 and 0.02, respectively, and the noise parameter \u03c3n is set to zero. The learning rate is set to 1 \u00d7 10\u22123, and then updated to 1 \u00d7 10\u22124 at the 10 000th iteration, and finally updated to 1 \u00d7 10\u22125 at the 40 000th iteration. The pre-training stops at the 50 000th iteration.\nIn the fine-tuning process, we set \u03c30 to 1.5, \u03c3b to 0.5 and \u03c3d to 0.03, and add noise with \u03c3n set to 0.5. The learning rate starts at 2 \u00d7 10\u22124, and then updates to 1 \u00d7 10\u22124 at the 10 000th iteration and decreases to 1 \u00d7 10\u22125 at the 20 000th iteration. It takes 30 000 iterations for fine-tuning.\nIn the rest of this paper, if not specified, we keep these experiment settings unchanged."}, {"heading": "C. Comparison With Existing Methods", "text": "We compare the calibration performance of PRNet with two representative existing calibration methods, including\n\u2022 SPSR-TSBL: a subspace-based method proposed in [9], which projects drifted measurements to a lower-dimensional drift-observation subspace, and then estimates drift values using the T-SBL algorithm; \u2022 SVR-KF: a prediction-based drift calibration algorithm proposed in [12], which uses SVR to predict sensor measurements and a Kalman filter to smooth the estimated drift.\nWe use two indicators to evaluate the performance of calibration algorithms. One is the rooted mean square error (RMSE) between the ground truth and the calibrated measurements, which indicates the calibration accuracy. It is defined as:\nRMSE(X, X\u0302) def=\n\u221a \u2016X \u2212 X\u0302\u20162F\nNT\nwhere X represents the ground truth and X\u0302 is the calibrated measurements. The other is the recovery rate, which measures the method\u2019s ability to detect and identify the drifted sensors when a part of sensors are drifted. For a sensor network with m drifted sensors, by calibrating their measurements, we can estimate each sensor\u2019s drift. We select m sensors with the largest estimated drift as the guess of drifted sensors. The drift recovery is successful only if the guessed m sensors are exactly those drifted ones. In our experiments, we can simulate a number of drift samples on different sensors, so we can run many times of the drifted sensor detection process, and the ratio of successful trials among all experiments is defined as the recovery rate.\nThe drift is simulated with a random walk process, given by\ndi,0 = 0 di,t = di,t\u22121 + \u03b4i,t , \u03b4i,t \u223c N (0, \u03c3\u0303 2d ). (26)\nFor the testbed dataset, we set the number of drifted sensors m to vary from 1 to 23, and for the simulated dataset, m varies from 1 to 49. At each drift number m, we randomly choose m \u00d7 (N \u2212 m + 1) different combinations of drifted sensors with independently generated drift samples. N is the number of all sensors, which is 24 in the testbed dataset and 50 in the simulated dataset. The drift level parameter \u03c3\u0303d is set to 0.02. For the T-SBL algorithm, according to [9], we set the block size L to 5. The dimension of the signal subspaces estimated by SPSR-TSBL are 5 in the testbed dataset and 17 in the simulated dataset, which means the theoretical limits of drift sensors for the SPSR framework are 18 and 32 [8]. For SVR-KF, we also use the first 8000 samples of measurements to train the SVR prediction model.\nFigs. 8(a) and 8(c) plot the recovery rates of the three methods at different numbers of drifted sensors on testbed and simulated dataset, respectively. The proposed PRNet achieves much higher recovery rates than the other two. On the testbed dataset, PRNet\u2019s recovery rate is always higher than 0.6. For SPSR-TSBL, when more than 10 out of 24 sensors are drifted, its recover rate is below 0.6. The SVR-KF method has the lowest recovery rate among all. When more than 3 sensors are drifted, its recovery rate goes below 0.6. Similar results can be observed on the simulated dataset.\nFigs. 8(b) and 8(d) compare the calibration RMSEs on the testbed and simulated dataset respectively. The solid lines represent the RMSEs of the successful recoveries, and the dashed lines are the RMSEs of the failed recoveries. For the testbed dataset, PRNet has the lowest RMSE among all. When fewer than 10 sensors are drifted, the RMSE of SPSR-TSBL is almost the same as that of PRNet, but it increases rapidly\nwhen the number of drifted sensors gets over 10. SVR-KF has the largest RMSE in the test. For the simulated dataset, however, when the number of drifted sensors is below 15, SPSR-TSBL has the lowest RMSE on successful recoveries, but in the failure cases, PRNet has lower RMSE than SPSR-TSBL. When more than 15 sensors are drifted, PRNet has the lowest RMSE on both successful and failed recoveries.\nIn this experiment, PRNet shows superior performance in drifted sensor detection, where its recovery rate is much higher than the other two. The SVR-KF method does not have the ability to detect sensor drift, so it has the lowest recovery rate, and its way of predicting sensor measurements also limits its calibration accuracy. Due to the theoretical limitations and the sparsity assumption of SPSR framework, it has an obvious performance drop in both recoverability and accuracy when many sensors are drifted. Another weakness of the SPSR framework is that when it fails to correctly detect the drifted sensors, the overall calibration error increases sharply. This is also caused by its sparsity assumption. On the contrary, the proposed PRNet has neither a limitation nor a sparsity assumption on the number of drifted sensors. Instead, it is trained to calibrate any number of drifted sensors, so its calibration performance does not drop a lot when many sensors are drifted."}, {"heading": "D. Generalization Ability: Different Types of Drift and Noise Tolerance", "text": "In this experiment we test the generalization ability of PRNet. As we generate sensor drifts using a random-walk model during training, we need to test PRNet\u2019s performance under other types of drift. We also test its calibration performance on noisy data. The simulated dataset is used in these two tests.\nIn addition to the random-walk drift, we also simulate other four types of drift: bilateral linear drift, positive linear drift, positive sqrt drift and sine drift. To simulate these kinds of drift, for each sensor, we first generate a random number called the end value as the largest drift value it can reach. Next, we generate linear drift by\ndi,t = ei \u00d7 t/T (27) and sqrt drift by\ndi,t = ei \u00d7 \u221a t/T (28)\nand sine drift by\ndi,t = ei \u00d7 sin(ri\u03c0 t/T ) (29) where di,t is the drift value of Sensor-i at time instant t ; ei is the end value; ri is a random number sampled from U(3, 4) and T is the total time length of the simulation. For the bilateral linear drift model, its end value is sampled from a uniform distribution U(\u2212S, S), whereas the end values for positive linear drift, positive sqrt drift and sine drift are sampled from U(0, S), where S is the parameter to control the drift level. Therefore, the expectation of the bilateral linear drift and sine drift is zero, and the positive linear drift and positive sqrt drift always have positive values.\nFor each drift type and level, we run the calibration process 50 times, and for each time 20 randomly selected sensors are drifted. We plot the recovery rates and calibration RMSEs with drift RMSEs in Fig. 9. The recovery rates of different drift types show similar trends. As we identify the drifted sensors using the amplitude of the estimated drift, when the drift is small, it is more difficult to identify drifted sensors accurately. When the drift RMSE is larger than 1.2, for every drift type, PRNet can obtain a recovery rate higher than 0.6. For calibration RMSEs, when the drift RMSE is lower than 1.2, the calibration RMSEs for different drift types are lower than 0.25. The increasing trends of calibration RMSEs with drift RMSEs for different drift types are slightly different. This is caused by the different features of drifts. However, in many cases, random-walk drift, which is the same as the training data, does not have the highest recovery rate or the lowest calibration RMSE, since the randomness and uncertainty of this model make it difficult to calibrate. Therefore, we can conclude that PRNet trained with the augmented data does not overfit the random-walk drift. As long as the drift level is within a reasonable range, the sensor drift can be effectively suppressed. If the drift characteristics in a specific application is not well-simulated by our model, we could simply apply a new model in the drift-generation step to fit the application, which does not substantially change the PRNet framework.\nWe also test PRNet on calibrating noisy measurements with random-walk drift and sine drift. By carefully choosing the drift level parameters, the two drift models produce similar drift RMSEs, where \u03c3\u0303d is set to 0.02 and S to 5.5. For each test case, 20 random selected sensors are drifted, and all sensors are corrupted by Gaussian noise. Table II shows the calibration RMSEs on different noise levels, where the calibration RMSEs of random-walk and sine drift are very close. As we train PRNet at the noise level of \u03c3n = 0.5, in the test cases, when \u03c3\u0303n is smaller than 0.5, or the signal-noise-ratio (SNR) is higher than 26 dB, the calibration RMSEs are almost the same. When it increases over 0.5, the calibration error slightly increases. During training, we should choose the noise level based on application requirements. If the training noise is too large, the calibration precision for low-noise measurements will decrease.\nOne requirement in training neural networks is that the training data should cover the features of the test data.\nIn this experiment, we show that random-walk is an appropriate model which approximately covers various drift types. We also show that PRNet trained with the proposed data augmentation method can calibrate noisy measurements. In real-world applications, we can also add possible corruptions such as instant pulse noise [6] to cover application specific data features."}, {"heading": "V. EXPLORATION ON ARCHITECTURE AND PARAMETERS", "text": "In this section, we use the simulated dataset to explore the influence of different settings to PRNet, including architecture design, temporal kernel size, training patch size, and data-rearrangement."}, {"heading": "A. Architecture Design", "text": "In this experiment, we show the effectiveness of PRNet architecture by comparing its performance with three other architectures, including:\n\u2022 PRNet-RLO: the same architecture with PRNet, trained with recovery loss only (RLO); \u2022 FCN: a two-stage fully convolutional network (FCN) illustrated in Fig. 10(a); \u2022 ColFCN: an FCN with a large convolution kernel in the last layer, illustrated in Fig. 10(b). Compared with Fig. 5(a), ColFCN is similar to a \u201creversed\u201d PRNet.\nThe numbers of layers, parameter sizes, computation time complexity, computation amounts, and the sizes of receptive fields of these networks are listed in Table III. The proposed PRNet has the smallest computation amount and a small parameter size; the ColFCN has the largest receptive field size over the space dimension, and the FCN model is the deepest and has the largest computation and parameter amount.\nWe do not need to run both the pre-training and fine-tuning processes to benchmark these models, since their performance gap appears in the pre-training process. Every 1000 iterations, we validate them with 100 cases of drifted measurements, in each of which 20 randomly selected sensors are drifted, and the drift parameter \u03c3\u0303 2d is set to 0.01. The input data patch size is set to 100 to satisfy the need of the FCN model. We plot the training losses and validation RMSEs in Fig. 11. As all the networks except for PRNet do not have a projection loss, only the recovery loss is accounted.\nAn interesting phenomenon is that the proposed PRNet has the smallest validation RMSE, while it has the largest training loss. First we compare PRNet and PRNet-RLO. Without the projection loss, as the recovery loss becomes the only optimization objective, it is easier for PRNet-RLO to reach a lower recovery loss. However, for the projection layer, separating the information of the ground truth signal and the sensor drift gets more difficult, so PRNet-RLO has a higher validation RMSE than PRNet. Comparing the FCN and ColFCN models, the ColFCN model has both lower training loss and validation RMSE than FCN. This is because that the ColFCN model has a larger spatial receptive field than FCN, so that it can better utilize the global spatial correlations of the sensing field.\nIt is obvious that the projection layer has much contribution in improving the calibration accuracy. In essence, the projection layer introduces a prior assumption to the network that the sensor drift can be observed in a projected space, making it easier for the recovery layers to extract and calibrate the drift. From the network perspective, the FCN and ColFCN models actually have better representation ability since they are deeper and wider than PRNet, but without the projection layer, they overfit the training set and fail to extract essential features of the sensory data."}, {"heading": "B. Patch Size Selection", "text": "In Section III-D we claim that the patch size of training data should be slightly larger than the receptive field of the neural network over the time dimension. In this experiment, we test the performance on different patch sizes.\nAs shown in Table III, the receptive field size of PRNet over the time dimension is 15. We set the patch size Tp to 10, 12, 15, 20 and 40, and train 5 PRNets. As the training loss is related to the patch size, we use the validation RMSE to compare their performances.\nFig. 12 shows the validation RMSEs of PRNets trained with different patch sizes. When the patch size is 10, the validation RMSE gets stuck at a high level, and even slightly increases with training iterations. This is because that the training patch cannot even fill the receptive field of the network, and the features of training data are quite different from those of validation and test data. In contrast, PRNets trained with other patch sizes show very similar performance in validation RMSE. The performance gain of larger patch size is quite limited. Furthermore, larger patch size leads to more computation and a slower training speed. Therefore, as we have suggested, a number that is slightly larger than the receptive field of the network is an appropriate selection. In most of our experiments, the patch size for training PRNet is 20."}, {"heading": "C. Benefit From Temporal Correlation", "text": "In this experiment we show how PRNet utilizes temporal correlation and how temporal correlation contributes to calibration performance. We derive a spatial-only PRNet based on the original one, where all ks \u00d7 kt convolution kernels are replaced by ks \u00d7 1 kernels. This means that the spatial-only PRNet computes on measurements collected at a single time instant. Next we increase the channels of the spatial-only PRNet, so that it has the parameter size of 348.3KB and normalized computation amount of 1.164MOps, which are slightly larger than that of the original one.\nWe plot the training loss and validation RMSEs of the two PRNet models during the pre-training process in Fig. 13. Where both the training loss and validation RMSE of spatialtemporal PRNet are lower than those of spatial-only PRNet. Therefore, spatial-temporal convolution helps PRNet to utilize the temporal correlation of measurement data."}, {"heading": "D. Necessity of Data Re-Arrangement", "text": "In this experiment we show why sensor re-arrangement is indispensable. We train three PRNets with the same architecture using the same training data, but different re-arrangement matrices, including\n\u2022 without re-arrangement: set M to an identity matrix; \u2022 nearest neighbour: calculate M using nearest-neighbour\nalgorithm; \u2022 Eulerian circuit: re-arrange sensors by traversing over the\nEulerian circuit on the edge-duplicated MST. The training losses and validation RMSEs of these PRNets during the pre-training process are plotted in Fig. 14. The one trained without re-arrangement has the largest training loss and validation RMSE. The other two PRNets achieve similar validation RMSEs, but the one trained with Eulerian-circuitbased re-arrangement has lower training loss. As the Euleriancircuit solution ensures that the maximum distance of neighbour sensors is minimized, the organized data should have more local correlation. However, the validation curve shows this does not bring much benefit in validation. Therefore, the sensor re-arrangement step is required, but a greedy approximated solution can provide enough local data correlation.\nWe plot the locations of sensors in Fig. 15, in which the sensor numbers in Fig. 15(a) are in the original order whereas those in Fig. 15(b) is re-arranged using the nearest-neighbour algorithm. Obviously, in the original order, measurements form neighbour sensors may distribute far apart in the measurement matrix, leading to the uncorrelation of adjacent rows, reducing the calibration performance of PRNet. By re-arranging the sensor order, neighbour sensors are more possible to be put\nin adjacent rows, ensuring the local spatial correlation and improving the calibration performance."}, {"heading": "VI. DISCUSSION", "text": "Although we had lots of empirical experiment results evaluating the effectiveness of PRNet, it is difficult to theoretically explain why PRNet surpasses existing methods. In this section, we try to give an intuitive explanation.\nPRNet has two stages: projection and recovery. In Section III-B we have explained that the projection stage is a natural extension to the linear low-dimensional projection used in the subspace method, which can be applied in more applications such as nonlinear sensing fields.\nFor the recovery layers, we claim that the key ingredient is the nonlinear ReLU activation function, given by\nReLU(x) = max(0, x). (30) We first consider the case that the activation functions are linear, then the overall recovery function is also linear. The optimal solution for this case will be a linear least-square regression, which does not have the ability of detecting and calibrating drifted sensors. However, with the ReLU activation function, some of the neurons\u2019 outputs are suppressed to zero, while the rest are linear combinations of the inputs. Therefore, the overall drift-estimation function can suppress the outputs corresponding to non-drifted sensors to zeros, while those of the drifted ones are segmented linear combinations of the input with the least square error. This property of multi-layer neural networks is called universal approximation [35].\nThe ResNet architecture, compared with conventional neural networks, has even higher representation ability. In [27], Hardt and Ma propose a reduced ResNet architecture, and prove that each ResUnit can map some of the input to arbitrary values while keeping the remaining values unchanged. By stacking these ResUnits, the ResNet can map the input to any wanted values. Although they reduce the ResUnit architecture in order to make it mathematically provable, it is reasonable that the full version of ResNet has similar properties.\nIn addition, as ResNet is optimization-friendly [27], [28], it is possible that by training PRNet, it can converge to a near optimal case that the calibrated measurements of non-drifted sensors keep the same with the input, while those of the drifted sensors are mapped to drift-free values."}, {"heading": "VII. CONCLUSION", "text": "With the increasing deployment of large-scale and long-term wireless sensor networks, sensor drift is becoming a serious problem, while calibrating sensors one-by-one is impractical when a sensor network can scale as large as hundreds of sensors. Blind calibration is a practical scheme that recovers drift-free sensory data from drifted measurements without the ground truth, but it is difficult to blindly calibrate general monitoring sensor networks for the lack of a prior data model and low-density deployment.\nIn this paper, we propose a deep learning approach to blindly calibrate sensor measurements named PRNet. We assume that the sensors are calibrated before deployment, so the measurements collected during the initial period can be treated as drift-free. Using the proposed data augmentation method to generate training data from initial measurements, we train PRNet to automatically extract spatial and temporal features of sensor measurements and suppress the drift. Experiments show that our PRNet has superior performance over previous methods in both recovery rate and calibration RMSE, and it can also calibrate noisy measurements with various types of drifts. Therefore, for long-term general monitoring sensor networks with sensors deployed in fixed locations, the proposed method can blindly calibrate sensor measurements, ensuring the data quality and validity."}], "references": [{"title": "Wireless sensor network survey", "author": ["J. Yick", "B. Mukherjee", "D. Ghosal"], "venue": "Comput. Netw., vol. 52, no. 12, pp. 2292\u20132330, Aug. 2008.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Application specific sensor node architecture optimization\u2014Experiences from field deployments", "author": ["W. Liu"], "venue": "Proc. IEEE ASP-DAC, Jan./Feb. 2012, pp. 389\u2013394.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Internet of Things for smart cities", "author": ["A. Zanella", "N. Bui", "A. Castellani", "L. Vangelista", "M. Zorzi"], "venue": "IEEE Internet Things J., vol. 1, no. 1, pp. 22\u201332, Feb. 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "An environment monitoring system for precise agriculture based on wireless sensor networks", "author": ["J. Xia", "Z. Tang", "X. Shi", "L. Fan", "H. Li"], "venue": "Proc. MSN, Dec. 2011, pp. 28\u201335.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "A reliable transfer protocol for multi-parameter data collecting in wireless sensor networks", "author": ["X. Fei"], "venue": "Proc. ICACT, Jan. 2013, pp. 569\u2013573.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Sensor network data fault types", "author": ["K. Ni"], "venue": "ACM Trans. Sensor Netw., vol. 5, no. 3, May 2009, Art. no. 25.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Blind calibration of sensor networks", "author": ["L. Balzano", "R. Nowak"], "venue": "Proc. IPSN, Apr. 2007, pp. 79\u201388.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Blind drift calibration of sensor networks using signal space projection and Kalman filter", "author": ["Y. Wang", "A. Yang", "Z. Li", "P. Wang", "H. Yang"], "venue": "Proc. 10th ISSNIP, Apr. 2015, pp. 1\u20136.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Blind drift calibration of sensor networks using sparse Bayesian learning", "author": ["Y. Wang", "A. Yang", "Z. Li", "X. Chen", "P. Wang", "H. Yang"], "venue": "IEEE Sensors J., vol. 16, no. 16, pp. 6249\u20136260, Aug. 2016.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Drift aware wireless sensor networks", "author": ["M. Takruri", "S. Challa"], "venue": "Proc. ICIF, Jul. 2007, pp. 1\u20137.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Distributed recursive algorithm for auto calibration in drift aware wireless sensor networks", "author": ["M. Takruri", "K. Aboura", "S. Challa"], "venue": "Proc. Innov. Adv. Techn. Syst., Comput. Sci. Softw. Eng., 2008, pp. 21\u201325.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Online drift correction in wireless sensor networks using spatiotemporal modeling", "author": ["M. Takruri", "S. Rajasegarar", "S. Challa", "C. Leckie", "M. Palaniswami"], "venue": "Proc. ICIF, Jun./Jul. 2008, pp. 1\u20138.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Geospatial estimationbased auto drift correction in wireless sensor networks", "author": ["D. Kumar", "S. Rajasegarar", "M. Palaniswami"], "venue": "ACM Trans. Sensor Netw., vol. 11, no. 3, May 2015, Art. no. 50.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Study of long-term drift of a porous silicon humidity sensor and its compensation using ann technique", "author": ["T. Islam", "H. Saha"], "venue": "Sens. Actuators A, Phys., vol. 133, no. 2, pp. 472\u2013479, 2007.  WANG et al.: DEEP LEARNING APPROACH FOR BLIND DRIFT CALIBRATION OF SENSOR NETWORKS  4171", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Pressure sensor drifts in argo and their impacts", "author": ["P.M. Barker", "J.R. Dunn", "C.M. Domingues", "S.E. Wijffels"], "venue": "J. Atmos. Ocean. Technol., vol. 28, no. 8, pp. 1036\u20131049, 2011.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "System-level calibration for data fusion in wireless sensor networks", "author": ["R. Tan"], "venue": "ACM Trans. Sensor Netw., vol. 9, no. 3, 2013, Art. no. 28.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Calibrate without calibrating: An iterative approach in participatory sensing network", "author": ["C. Xiang", "P. Yang", "C. Tian", "H. Cai", "Y. Liu"], "venue": "IEEE Trans. Parallel Distrib. Syst., vol. 26, no. 2, pp. 351\u2013361, Feb. 2015.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "A collaborative approach to in-place sensor calibration", "author": ["V. Bychkovskiy", "S. Megerian", "D. Estrin"], "venue": "Proc. IPSN, 2003, pp. 301\u2013316.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2003}, {"title": "Blind mobile sensor calibration using an informed nonnegative matrix factorization with a relaxed rendezvous model", "author": ["C. Dorffer", "M. Puigt", "G. Delmaire", "G. Roussel"], "venue": "Proc. ICASSP, vol. 2, Mar. 2016, pp. 2941\u20132945.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "A blind calibration scheme exploiting mutual calibration relationships for a dense mobile sensor network", "author": ["B.-T. Lee", "S.-C. Son", "K. Kang"], "venue": "IEEE Sensors J., vol. 14, no. 5, pp. 1518\u20131526, May 2014.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Image denoising and inpainting with deep neural networks", "author": ["J. Xie", "L. Xu", "E. Chen"], "venue": "Proc. NIPS, 2012, pp. 341\u2013349.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning to diagnose with LSTM recurrent neural networks", "author": ["Z.C. Lipton"], "venue": "Proc. ICLR, 2016.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Y. LeCun"], "venue": "Neural Comput., vol. 1, no. 4, pp. 541\u2013551, 1989.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1989}, {"title": "Identity mappings in deep residual networks", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "Proc. ECCV, Mar. 2016, pp. 630\u2013645.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift.", "author": ["S. Ioffe", "C. Szegedy"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "Proc. CVPR, Jun. 2016, pp. 770\u2013778.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2016}, {"title": "Identity matters in deep learning", "author": ["M. Hardt", "T. Ma"], "venue": "Proc. ICLR, 2017, Art. no. 45833.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2017}, {"title": "The loss surface of residual networks: Ensembles and the role of batch normalization.", "author": ["E. Littwin", "L. Wolf. (Nov"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "On blocking rules for the bootstrap with dependent data", "author": ["P. Hall", "J.L. Horowitz", "B.-Y. Jing"], "venue": "Biometrika, vol. 82, no. 3, pp. 561\u2013574, 1995.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1995}, {"title": "Recent developments in bootstrapping time series", "author": ["J. Berkowitz", "L. Kilian"], "venue": "Econ. Rev., vol. 19, no. 1, pp. 1\u201348, 2000.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2000}, {"title": "Why is the sum of independent normal random variables normal?", "author": ["B. Eisenberg", "R. Sullivan"], "venue": "Math. Mag., vol. 81,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2008}, {"title": "Adam: A method for stochastic optimization.", "author": ["D. Kingma", "J. Ba"], "venue": "(Jul", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}, {"title": "Curriculum learning", "author": ["Y. Bengio", "J. Louradour", "R. Collobert", "J. Weston"], "venue": "Proc. ICML, Jun. 2009, pp. 41\u201348.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2009}, {"title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "Proc. IEEE Int. Conf. Comput. Vis. (ICCV), Dec. 2015, pp. 1026\u20131034.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "WSNs can gather information from the environment and transmit the collected data to users [1].", "startOffset": 90, "endOffset": 93}, {"referenceID": 1, "context": "They have important usage in many emerging applications such as environmental monitoring [2], smart cities [3], precise agriculture [4], etc.", "startOffset": 89, "endOffset": 92}, {"referenceID": 2, "context": "They have important usage in many emerging applications such as environmental monitoring [2], smart cities [3], precise agriculture [4], etc.", "startOffset": 107, "endOffset": 110}, {"referenceID": 3, "context": "They have important usage in many emerging applications such as environmental monitoring [2], smart cities [3], precise agriculture [4], etc.", "startOffset": 132, "endOffset": 135}, {"referenceID": 1, "context": "In practice, many WSNs have hundreds of sensors deployed [2], [5].", "startOffset": 57, "endOffset": 60}, {"referenceID": 4, "context": "In practice, many WSNs have hundreds of sensors deployed [2], [5].", "startOffset": 62, "endOffset": 65}, {"referenceID": 5, "context": "[6] give an example of a drifted", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "This problem is called blind calibration [7].", "startOffset": 41, "endOffset": 44}, {"referenceID": 6, "context": "rules for feature extraction and sensor calibration [7]\u2013[13].", "startOffset": 52, "endOffset": 55}, {"referenceID": 12, "context": "rules for feature extraction and sensor calibration [7]\u2013[13].", "startOffset": 56, "endOffset": 60}, {"referenceID": 13, "context": "Usually, sensor drift is a long-term process and smoothly increases over time [14], [15], so its value may be at the same order of magnitude with the signal.", "startOffset": 78, "endOffset": 82}, {"referenceID": 14, "context": "Usually, sensor drift is a long-term process and smoothly increases over time [14], [15], so its value may be at the same order of magnitude with the signal.", "startOffset": 84, "endOffset": 88}, {"referenceID": 15, "context": "Many existing blind calibration methods rely on specific application features, such as a prior data model [16], [17], dense-deployment [18], or sensor mobility [19], [20].", "startOffset": 106, "endOffset": 110}, {"referenceID": 16, "context": "Many existing blind calibration methods rely on specific application features, such as a prior data model [16], [17], dense-deployment [18], or sensor mobility [19], [20].", "startOffset": 112, "endOffset": 116}, {"referenceID": 17, "context": "Many existing blind calibration methods rely on specific application features, such as a prior data model [16], [17], dense-deployment [18], or sensor mobility [19], [20].", "startOffset": 135, "endOffset": 139}, {"referenceID": 18, "context": "Many existing blind calibration methods rely on specific application features, such as a prior data model [16], [17], dense-deployment [18], or sensor mobility [19], [20].", "startOffset": 160, "endOffset": 164}, {"referenceID": 19, "context": "Many existing blind calibration methods rely on specific application features, such as a prior data model [16], [17], dense-deployment [18], or sensor mobility [19], [20].", "startOffset": 166, "endOffset": 170}, {"referenceID": 10, "context": "[11], where the ground truth of a sensor is first predicted using the neighbour sensors\u2019 measurements, and then a Kalman filter (KF) is employed to track the sensor\u2019s drift.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Following works apply different prediction functions in this framework, including support vector regression (SVR) [12] and Kriging interpolation [13].", "startOffset": 114, "endOffset": 118}, {"referenceID": 12, "context": "Following works apply different prediction functions in this framework, including support vector regression (SVR) [12] and Kriging interpolation [13].", "startOffset": 145, "endOffset": 149}, {"referenceID": 6, "context": "Balzano and Nowak [7] first proposed the idea of signal subspace where the sensory data lie in, so a part of calibration parameters can be obtained by solving a homogeneous linear system.", "startOffset": 18, "endOffset": 21}, {"referenceID": 7, "context": "In our previous works [8], [9], we extend this idea by modeling the drift calibration problem as sparse signal recovery, and use Kalman filter or sparse Bayesian learning to", "startOffset": 22, "endOffset": 25}, {"referenceID": 8, "context": "In our previous works [8], [9], we extend this idea by modeling the drift calibration problem as sparse signal recovery, and use Kalman filter or sparse Bayesian learning to", "startOffset": 27, "endOffset": 30}, {"referenceID": 7, "context": "Experiments [8], [9] show that the subspace methods are more stable and more accurate than the prediction methods.", "startOffset": 12, "endOffset": 15}, {"referenceID": 8, "context": "Experiments [8], [9] show that the subspace methods are more stable and more accurate than the prediction methods.", "startOffset": 17, "endOffset": 20}, {"referenceID": 20, "context": "Some applications, such as image denoising and inpaiting [21] aiming at restoring TABLE I", "startOffset": 57, "endOffset": 61}, {"referenceID": 21, "context": "[22] use a recurrent neural network (RNN) to detect events from segments of clinical measurements.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "CNNs [23] are widely used in image processing.", "startOffset": 5, "endOffset": 9}, {"referenceID": 8, "context": "To solve the first issue, we extend the idea of the previous SPSR framework [9] by designing a projection-recovery CNN", "startOffset": 76, "endOffset": 79}, {"referenceID": 8, "context": "Similar to previous works [9], [12], we assume that the", "startOffset": 26, "endOffset": 29}, {"referenceID": 11, "context": "Similar to previous works [9], [12], we assume that the", "startOffset": 31, "endOffset": 35}, {"referenceID": 7, "context": "According to [8], if the drift-free measurements lie in a signal subspace, a projection matrix P can be obtained, which satisfies", "startOffset": 13, "endOffset": 16}, {"referenceID": 23, "context": "(b) Structure of a ResUnit [24].", "startOffset": 27, "endOffset": 31}, {"referenceID": 24, "context": "The term BN refers to Batch Normalization [25], which helps accelerate the training.", "startOffset": 42, "endOffset": 46}, {"referenceID": 23, "context": "The architecture of these recovery layers is derived from ResNet [24], [26], which is a state-ofthe-art CNN architecture widely used in CV applications.", "startOffset": 65, "endOffset": 69}, {"referenceID": 25, "context": "The architecture of these recovery layers is derived from ResNet [24], [26], which is a state-ofthe-art CNN architecture widely used in CV applications.", "startOffset": 71, "endOffset": 75}, {"referenceID": 26, "context": "Some recent works [27], [28] found that this special architecture has better representational ability and is easier to train than conventional CNN architectures.", "startOffset": 18, "endOffset": 22}, {"referenceID": 27, "context": "Some recent works [27], [28] found that this special architecture has better representational ability and is easier to train than conventional CNN architectures.", "startOffset": 24, "endOffset": 28}, {"referenceID": 0, "context": "We first set s[1] to 1, and choose the nearest non-visited neighbour sensor for the next step until all sensors are visited.", "startOffset": 14, "endOffset": 17}, {"referenceID": 5, "context": "On the contrary, sensor drift and noise, are usually caused by errors and non-ideal factors of sensor hardware [6].", "startOffset": 111, "endOffset": 114}, {"referenceID": 28, "context": "This is also widely used in other research areas such as time-series bootstrapping [29], [30].", "startOffset": 83, "endOffset": 87}, {"referenceID": 29, "context": "This is also widely used in other research areas such as time-series bootstrapping [29], [30].", "startOffset": 89, "endOffset": 93}, {"referenceID": 30, "context": "is still Gaussian [31], given by", "startOffset": 18, "endOffset": 22}, {"referenceID": 31, "context": "We use the Adam optimizer [32] to minimize the loss function.", "startOffset": 26, "endOffset": 30}, {"referenceID": 32, "context": "We apply a simple curriculum learning [33] strategy on selecting the drift emulation parameters \u03c30, \u03c3b, \u03c3d and \u03c3n .", "startOffset": 38, "endOffset": 42}, {"referenceID": 8, "context": "1) Testbed Dataset: We use the same testbed described in our previous work [9] deployed in our lab to build the dataset.", "startOffset": 75, "endOffset": 78}, {"referenceID": 33, "context": "[34], and the bias parameters are initialized to zeros.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "We compare the calibration performance of PRNet with two representative existing calibration methods, including \u2022 SPSR-TSBL: a subspace-based method proposed in [9], which projects drifted measurements to a lower-dimensional drift-observation subspace, and then estimates drift values using the T-SBL algorithm; \u2022 SVR-KF: a prediction-based drift calibration algorithm proposed in [12], which uses SVR to predict sensor measurements and a Kalman filter to smooth the estimated drift.", "startOffset": 161, "endOffset": 164}, {"referenceID": 11, "context": "We compare the calibration performance of PRNet with two representative existing calibration methods, including \u2022 SPSR-TSBL: a subspace-based method proposed in [9], which projects drifted measurements to a lower-dimensional drift-observation subspace, and then estimates drift values using the T-SBL algorithm; \u2022 SVR-KF: a prediction-based drift calibration algorithm proposed in [12], which uses SVR to predict sensor measurements and a Kalman filter to smooth the estimated drift.", "startOffset": 381, "endOffset": 385}, {"referenceID": 8, "context": "For the T-SBL algorithm, according to [9], we set the block size L to 5.", "startOffset": 38, "endOffset": 41}, {"referenceID": 7, "context": "The dimension of the signal subspaces estimated by SPSR-TSBL are 5 in the testbed dataset and 17 in the simulated dataset, which means the theoretical limits of drift sensors for the SPSR framework are 18 and 32 [8].", "startOffset": 212, "endOffset": 215}, {"referenceID": 5, "context": "In real-world applications, we can also add possible corruptions such as instant pulse noise [6] to cover application specific data features.", "startOffset": 93, "endOffset": 96}, {"referenceID": 26, "context": "In [27], Hardt and Ma propose a reduced ResNet architecture, and prove that each ResUnit can map some of the input to arbitrary values while keeping the remaining values unchanged.", "startOffset": 3, "endOffset": 7}, {"referenceID": 26, "context": "In addition, as ResNet is optimization-friendly [27], [28], it is possible that by training PRNet, it can converge to a near optimal case that the calibrated measurements of non-drifted sensors keep the same with the input, while those of the drifted", "startOffset": 48, "endOffset": 52}, {"referenceID": 27, "context": "In addition, as ResNet is optimization-friendly [27], [28], it is possible that by training PRNet, it can converge to a near optimal case that the calibrated measurements of non-drifted sensors keep the same with the input, while those of the drifted", "startOffset": 54, "endOffset": 58}], "year": 2017, "abstractText": "Temporal drift of sensory data is a severe problem impacting the data quality of wireless sensor networks (WSNs). With the proliferation of large-scale and long-term WSNs, it is becoming more important to calibrate sensors when the ground truth is unavailable. This problem is called \"blind calibration\". In this paper, we propose a novel deep learning method named projection-recovery network (PRNet) to blindly calibrate sensor measurements online. The PRNet first projects the drifted data to a feature space, and uses a powerful deep convolutional neural network to recover the estimated driftfree measurements. We deploy a 24-sensor testbed and provide comprehensive empirical evidence showing that the proposed method significantly improves the sensing accuracy and drifted sensor detection. Compared with previous methods, PRNet can calibrate 2\u00d7 of drifted sensors at the recovery rate of 80% under the same level of accuracy requirement. We also provide helpful insights for designing deep neural networks for sensor calibration. We hope our proposed simple and effective approach will serve as a solid baseline in blind drift calibration of sensor networks.", "creator": null}}}