{"id": "1709.01848", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Sep-2017", "title": "Depression and Self-Harm Risk Assessment in Online Forums", "abstract": "In this paper, we present a neural framework to support and study users in both types of communities; we propose methods for identifying posts in support communities that may indicate a risk of self-harm; and we demonstrate that our approach exceeds the methods previously proposed for identifying such posts. Self-harm is closely related to depression, making identifying depressed users in general forums a critical related task; we present an extensive general forum dataset (\"RSDD\") consisting of users whose self-reported depression diagnoses are matched with control users; we show how our method can be used to effectively identify depressed users based solely on their language use; and we show that our methodology outperforms strong baseline data on this general forum dataset.", "histories": [["v1", "Wed, 6 Sep 2017 14:50:42 GMT  (103kb,D)", "http://arxiv.org/abs/1709.01848v1", "Expanded version of EMNLP17 paper. Added sections 6.1, 6.2, 6.4, FastText baseline, and CNN-R"]], "COMMENTS": "Expanded version of EMNLP17 paper. Added sections 6.1, 6.2, 6.4, FastText baseline, and CNN-R", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["andrew yates", "arman cohan", "nazli goharian"], "accepted": true, "id": "1709.01848"}, "pdf": {"name": "1709.01848.pdf", "metadata": {"source": "CRF", "title": "Depression and Self-Harm Risk Assessment in Online Forums", "authors": ["Andrew Yates", "Arman Cohan", "Nazli Goharian"], "emails": ["ayates@mpi-inf.mpg.de", "arman@ir.cs.georgetown.edu", "nazli@ir.cs.georgetown.edu"], "sections": [{"heading": "1 Introduction", "text": "Mental health remains a major challenge in public health care. Depression is one of the most common mental disorders and 350 million people are estimated to suffer from depression worldwide (WHO, 2010). In 2014 an estimated 7% of all U.S. adults had experienced at least one major depressive disorder (2015). Suicide and selfharm are major related concerns in public mental health. Suicide is one of the leading causes of death (CDC, 2015), and each suicide case has\n\u2217 The first two authors contributed equally to this work.\nmajor consequences on the physical and emotional well-being of families and on societies in general. Therefore identifying individuals at risk of selfharm and providing support to prevent it remains an important problem (Ferrari et al., 2014).\nSocial media is often used by people with mental health problems to express their mental issues and seek support. This makes social media a significant resource for studying language related to depression, suicide, and self-harm, as well as understanding the authors\u2019 reasons for making such posts, and identifying individuals at risk of harm (Coppersmith et al., 2014a). Depression and suicide are closely related given that depression is the psychiatric diagnosis most commonly associated with suicide. Research has demonstrated that forums are powerful platforms for selfdisclosure and social support seeking around mental health concerns (De Choudhury and De, 2014; Manikonda and De Choudhury, 2017). Such support forums are often staffed by moderators who are mental health experts, trained volunteers, or more experienced users whose role is to identify forum posts suggesting that a user is at risk of selfharm and to provide support.\nStudies have shown that self expression and social support are beneficial in improving the individual\u2019s state of the mind (Turner et al., 1983; Choudhury and Kiciman, 2017) and, thus such communities and interventions are important in suicide prevention. However, there are often thousands of user posts published in such support forums daily, making it difficult to manually identify individuals at risk of self-harm. Additionally, users in acute distress need prompt attention, and any delay in responding to these users could have adverse consequences. Therefore, identifying individuals at risk of self-harm in such support forums is an important challenge. Identifying signs of depression in general social media, on the ar X\niv :1\n70 9.\n01 84\n8v 1\n[ cs\n.C L\n] 6\nS ep\n2 01\n7\nother hand, is also a difficult task that has applications for both better understanding the relationship between mental health and language use and for monitoring a specific user\u2019s state (e.g., in the context of monitoring a user\u2019s response to clinical care). In this work we propose and evaluate a framework for performing self-harm risk assessment and for identifying depression in online forums.\nWe present a general neural network architecture for combining posts into a representation of a user\u2019s activity that is used to classify the user. To address the challenge of depression risk assessment over the general forums, we introduce a large-scale novel Reddit dataset that is substantially larger than the existing data and has a much more realistic number of control users. The dataset contains over 9,000 users with selfreported depression diagnoses matched with over 107,000 control users. We apply our approach to (1) identify the users with depression on a general forum like Reddit, and to (2) estimate the risk of self-harm indicated by posts in a more specific mental-health support forum. Our methods perform significantly better on both datasets than strong existing methods, demonstrating that our approach can be used both to identify depressed users and to estimate the risk of self-harm posed by individual posts."}, {"heading": "2 Related Work", "text": "There is a growing body of related work analyzing mental health-related discourse and language usage in social media to better discover and understand mental health related concerns (Resnik et al., 2013; De Choudhury et al., 2013; Coppersmith et al., 2014b,a; Mitchell et al., 2015; Tsugawa et al., 2015; Coppersmith et al., 2015a; Althoff et al., 2016; Mowery et al., 2016; Benton et al., 2017b). To investigate NLP methods for identifying depression and PTSD users on Twitter, a shared task (Coppersmith et al., 2015b) at the 2nd Computational Linguistics and Clinical Psychology Workshop (CLPsych 2015) was introduced where the participants evaluated their methods on a dataset of about 1800 Twitter users. Other work has used data from approximately 900 Reddit.com users to support self-reported diagnosis detection (Losada and Crestani, 2016). Previous work identifying depression and other mental health problems, including the methods partic-\nipating in CLPsych 2015 (e.g. works by Resnik et al. (2015) and Preot\u0327iuc-Pietro et al. (2015)) heavily rely on utilizing features such as LIWC (Pennebaker et al., 2015), topic modeling, manual lexicons, or other domain-dependent applicationspecific features. Aside from the effort required to design effective features, these approaches usually model the problem with respect to the selected features and ignore other indicators and signals that can improve prediction. In contrast, our model only relies on text and is not dependent on any external or domain-specific features. Existing self-reported diagnosis detection datasets contain a limited number of both control users and diagnosed users. In contrast to this, we construct a new dataset with over 9,000 depressed users matched with a realistic number of control users.\nIn addition to general studies addressing mental health, related work has also specifically studied suicide and self-harm through social media (Jashinsky et al., 2014; Thompson et al., 2014; Gunn and Lester, 2015; De Choudhury et al., 2016; Coppersmith et al., 2016). Recently, CLPsych 2016 (Hollingshead and Ungar, 2016) investigated approaches for detecting the self-harm risk of mental health forum posts (Milne et al., 2016). Most related work in this area uses variations of linear classifiers with some sort of feature engineering; successful methods have employed: a combination of sparse (bag-of-words) and dense (doc2vec) representation of the target forum posts (Kim et al., 2016), a stack of featurerich Random Forest and linear Support Vector Machine (SVM) (Malmasi et al., 2016), an RBF SVM classifier utilizing similar sets of features (Brew, 2016), and various contextual and psycholinguistic features (Cohan et al., 2016, 2017). In contrast to the above works, our model does not use any general or domain specific feature engineering; it learns appropriate representations of documents by considering only their textual content.\nOur proposed models consist of a shared architecture based on a CNN, a merge layer, modelspecific loss functions, and an output layer (as we will describe in \u00a74). While our model shares similarities with CNN-based models in prior work (Kalchbrenner et al., 2014; Kim, 2014; Xiao and Cho, 2016), it focuses on learning representations of user\u2019s posts and combining the post representations into an overall representation of the user\u2019s activity. In the case of self-harm risk assessment,\nwe experiment with several loss functions to determine whether considering the ordinal nature of self-harm risk labels (i.e., green, amber, red, and crisis) can improve performance. Evaluation results suggest that the model variant using this loss function is more robust than our other variants."}, {"heading": "3 Data", "text": ""}, {"heading": "3.1 Depression dataset construction.", "text": "We created a new dataset to support the task of identifying forum users with self-reported depression diagnoses. The Reddit Self-reported Depression Diagnosis (RSDD) dataset was created by annotating users from a publicly-available Reddit dataset1. Users to annotate were selected by identifying all users who made a post between January 2006 and October 2016 matching a highprecision diagnosis pattern.2 Users with fewer than 100 posts made before their diagnosis post were discarded. Each of the remaining diagnosis posts was then viewed by three layperson annotators to decide whether the user was claiming to have been diagnosed with depression; the most common false positives included hypotheticals (e.g., \u201cif I was diagnosed with depression\u201d), negations (e.g., \u201cit\u2019s not like I\u2019ve been diagnosed with depression\u201d), and quotes (e.g., \u201cmy brother announced \u2018I was just diagnosed with depression\u2019 \u201d). Only users with at least two positive annotations were included in the final group of diagnosed users.\nA pool of potential control users was identified by selecting only those users who had (1) never posted in a subreddit related to mental health, and (2) never used a term related to depression or mental health. These restrictions minimize the likelihood that users with depression are included in the control group. In order to prevent the diagnosed users from being easily identified by the usage of specific keywords that are never used by the control users, we removed all posts by diagnosed users that met either one of the aforementioned conditions (i.e., that was posted in a mental health subreddit or included a depression term).\nFor each diagnosed user and potential control user, we calculated the probability that the user would post in each subreddit (while ignoring diagnosed users\u2019 posts made to mental health subreddits). Each diagnosed user was then greedily\n1https://files.pushshift.io/reddit/ 2e.g., \u201cI was just diagnosed with depression.\u201d\nmatched with the 12 control users who had the smallest Hellinger distance between the diagnosed user\u2019s and the control user\u2019s subreddit post probability distributions, excluding control users with 10% more or fewer posts than the diagnosed user. This matching approach ensures that diagnosed users are matched with control users who are interested in similar subreddits and have similar activity levels, preventing biases based on the subreddits users are involved in or based on how active the users are on Reddit. This yielded a dataset containing 9,210 diagnosed users and 107,274 control users. On average each user in the dataset has 969 posts (median 646). The mean post length is 148 tokens (median 74).\nThe Reddit Self-reported Depression Diagnosis (RSDD) dataset differs from prior work creating self-reported diagnoses datasets in several ways: it is an order of magnitude larger, posts were annotated to confirm that they contained claims of a diagnosis, and a realistic number of control users were matched with each diagnosed user. The lists of terms related to mental health, subreddits related to mental health, high-precision depression diagnosis patterns, and further information are available3. We note that this dataset has some (inevitable) caveats: (i) the method only captures a subpopulation of depressed people (i.e. those with self-reported diagnosis), (ii) Reddit users may not be a representative sample of the population as a whole, and (iii) there is no way to verify whether the users with self-reported diagnoses are truthful."}, {"heading": "3.2 Self-harm assessment.", "text": "For self-harm risk assessment we use data from mental health forum posts from ReachOut.com, which is a successful Australian support forum for young people. In addition to providing peersupport, ReachOut moderators and trained volunteers monitor and participate in the forum discussions. The NAACL 2016 Computational Linguistics and Clinical Psychology Workshop (Hollingshead and Ungar, 2016) released a Triage dataset containing 65,024 forum posts from ReachOut, with annotations for 1,227 posts indicating the author\u2019s risk of self-harm (Milne et al., 2016). The annotations consist of one of four labels: green (indicating no action is required from ReachOut\u2019s moderators), amber (non-urgent attention is required), red (urgent attention is required), and cri-\n3http://ir.cs.georgetown.edu/data/reddit depression/\nsis (a risk that requires immediate attention)."}, {"heading": "3.3 Ethical concerns.", "text": "Social media data are often sensitive, and even more so when the data are related to mental health. Privacy concerns and the risk to the individuals in the data should always be considered (Hovy and Spruit, 2016; S\u030custer et al., 2017; Benton et al., 2017a). We note that the risks associated with the data used in this work are minimal. This assessment is supported by previous work on the ReachOut dataset (Milne et al., 2016), on Twitter data (Coppersmith et al., 2015b), and on other Reddit data (Losada and Crestani, 2016). The RSDD dataset contains only publicly available Reddit posts. Annotators were shown only anonymized posts and agreed to make no attempts to deanonymize or contact them. The RSDD dataset will only be made available to researchers who agree to follow ethical guidelines, which include requirements not to contact or attempt to deanonymize any of the users. Additionally, for the ReachOut forum data that was explicitly related to mental health, the forum\u2019s rules require the users to stay anonymous; moderators actively redact any user identifying information."}, {"heading": "4 Methodology", "text": "We describe a general neural network architecture for performing text classification over multiple input texts. We propose models based on this architecture for performing two tasks in the social media and mental health domains that we call selfharm risk classification and detecting depression. The task of self-harm risk classification is estimat-\ning a user\u2019s current self-harm risk given the user\u2019s post on a mental health support forum and the previous posts in the thread. The task of detecting depressions in users is identifying Reddit users with self-reported depression diagnoses given the users\u2019 post histories (excluding posts containing mental health keywords or posted in subreddits related to mental health).\nWhile both tasks are focused on predicting a user\u2019s mental health status, they differ in both the type of classification performed (i.e., estimating severity on a four point scale vs. boolean classification) and in the amount of data available. Our general architecture is based on a two step process: (1) identifying relevant features in each input text, and (2) combining the features observed in the model\u2019s inputs to classify the user."}, {"heading": "4.1 Shared Architecture", "text": "Our proposed models share a common architecture that takes one or more posts as input, processes the posts using a convolutional layer to identify features present in sliding windows of text, merges the features identified into a vector representation of the user\u2019s activity, and uses a series of dense layers to perform classification on the merged vector representation. The type of merging performed and the output layers are properties of the model variant, which we describe in detail in the following section. Convolutional networks have commonly been applied to the task of text classification, such as by Kim (2014). We use cat-\negorical cross-entropy as a loss function with both methods, but also experiment with other loss functions when performing severity classification.\nFirst, the model takes one or more posts as input and processes each post with a convolutional network containing a convolutional layer and a pooling layer. This process is illustrated with a max pooling layer in Figure 2. The convolutional layer applies filters to a sliding window of k terms (a) and outputs a feature value for each sliding window region and each filter (b). The same filters are applied to each window; each filter can be viewed as a feature detector and the overall process can be conceptualized as looking for windows of terms that contain specific features. The features are not specified a priori through feature engineering, but instead are learned automatically when the model is trained. After identifying the features present in each region (i.e., sliding window), a max pooling layer considers non-overlapping regions of length n and keeps the highest feature value for each region (c). This step eliminates the regions (i.e., sliding windows) that do not contain useful features, which reduces the size of the convolutional network\u2019s output. The same convolutional network is applied to each input post, meaning that the model learns to look for the same set of features in each.\nAfter each input post has been processed by a convolutional network, the output of each convolutional network is merged to create a representation of the user\u2019s activity across all input posts. This representation is processed by one or more dense layers (i.e., fully connected layers) with dropout (Srivastava et al., 2014) before being processed by a final output layer to perform classification. The type of output layer is dependent on the model variant. Our shared model architecture is illustrated in Figure 1. The architecture\u2019s hyperparameters (e.g., the sliding window size k, the number of convolutional filters used, and type of pooling) also vary among models and are described in \u00a75. Both the convolutional and dense layers use ReLU activations (Nair and Hinton, 2010) in all model variants."}, {"heading": "4.2 Models", "text": ""}, {"heading": "4.2.1 Depression detection", "text": "Our model for depression detection takes a user\u2019s posts as input and processes each post with a convolutional network. Each convolutional network performs average pooling to produce its output.\nThese post representations are then merged with a second convolutional layer to create a user representation; we found this approach led to more stable performance than using a second average pooling or max pooling layer. The user representation created by the merge step is then passed to one or more dense layers before being passed to a dense output layer with a softmax activation function to perform classification. The number of dense layers used is a hyperparameter described in \u00a75. Categorical cross-entropy is used as the model\u2019s loss function."}, {"heading": "4.2.2 Self-harm risk assessment", "text": "Our model for self-harm risk classification takes two inputs: the target post being classified and the prior posts (if any) in the target post\u2019s thread. The prior posts provide context and are thus useful for estimating the risk of self-harm present in the target post. The two inputs are both processed by a convolutional network as in user-level classification, but in this case the convolutional network\u2019s outputs correspond to a representation of the target post and to a representation of the target post\u2019s context (i.e., the prior posts in the thread). Given that these two outputs represent different aspects, they are merged by concatenating them together. This merged representation is then passed to one or more dense layers and to an output layer; the type of output layer depends on the loss function used. There are four self-harm risk assessment model variants in total:\nCategorical Cross Ent. uses an output layer with a softmax activation function, and categorical cross-entropy as its loss function. This mirrors the output layer and loss function used in the user level classification model.\nMSE uses an output layer with a linear activation function, and mean squared error as its loss function. The model\u2019s output is thus a single value; to perform classification, this output value is rounded to the nearest integer in the interval [0, t\u2212 1], where t is the number of target classes.\nThe final two loss functions perform metric learning rather than performing classification directly. They learn representations of a user\u2019s activity and of the four self-harm risk severity labels; classification is performed by comparing the euclidean distance between a representation of a user\u2019s activity (produced by the final layer) and each of the four severity label representations.\nClass Metric: Let d be the size of the output\nlayer and X be the layer\u2019s d-dimensional output. Class Metric learns a d-dimensional representation of each class Ci such that ||X \u2212 Ci||2 is minimized for the correct class i; this is accomplished with the loss function: Li,p,n = max ( 0, ||Xi\u2212Cp||2\u2212||Xi\u2212Cn||2+\u03b1\n) where Cp is the correct (i.e., positive) class for Xi, Cn is a randomly chosen incorrect (i.e., negative) class, and \u03b1 is a constant to enforce a minimum margin between classes. Classification is performed by computing the similarity between Xi and each class Cj .\nClass Metric (Ordinal) extends Class Metric to enforce a margin between ordinal classes as a function of the distance between classes. Given a ranked list of classes such that more similar classes have closer rankings, that is \u2200i sim(Ci, Ci\u00b11) > sim(Ci, Ci\u00b12), we incorporate the class distance into the margin such that more distant incorrect class labels must be further away from the correct class label in the metric space. The loss function becomes\nLi,p,n = max ( 0, ||Xi \u2212 Cp||2 \u2212 ||Xi \u2212 Cn||2 + \u03b1|p\u2212 n|\n) where |p \u2212 n| causes the margin to scale with the distance between classes p and n."}, {"heading": "5 Experiments", "text": "In this section, we describe the model hyperparameters used and present our results on the depression detection and self-harm risk assessment tasks. To facilitate reproducibility we provide our code and will provide the Reddit depression dataset to researchers who sign a data usage agreement4.\n4http://ir.cs.georgetown.edu/data/reddit depression/"}, {"heading": "5.1 Experimental setup.", "text": "The hyperparameters used with our models are shown in Table 1. The severity risk assessment models\u2019 hyperparameters were chosen using 10- fold cross validation on the 947 ReachOut training posts, with 15% of each fold used as validation data. The depression identification model\u2019s hyperparameters were chosen using the Reddit validation set. The depression identification model\u2019s second convolutional layer (i.e., the layer used to merge post representations) used filters of length 15, a stride of length 15, and the same number of filters as the first convolutional layer. All models were trained using stochastic gradient descent with the Adam optimizer (Kingma and Ba, 2014). The hyperparameters that varied across models are shown in Table 1. The convolution size, number of convolutional filters, pooling type, pooling length, and number of dense layers was similar across all post models. Class balancing was performed with Categorical Cross Ent. by weighting classes inversely proportional to their frequencies, whereas sampling an equal number of instances for each class worked best with the other methods.\nAddressing limited data. The post classification models\u2019 input consists of skip-thought vectors (Kiros et al., 2015); each vector used is a 7200- dimensional representation of a sentence. Thus, the convolutional windows used for post classification are over sentences rather than over terms. This input representation was chosen to mitigate the effects of the ReachOut dataset\u2019s relatively small size. The skip-thought vectors were generated from the the ReachOut forum dataset by sequentially splitting the posts in the training set into sentences, tokenizing them, and training skipthoughts using Kiros et al.\u2019s implementation with the default parameters. Sentence boundary detection was performed using the Punkt sentence tokenizer (Kiss and Strunk, 2006) available in NLTK (Bird et al., 2009). These 2400-dimensional forum\npost skip-thought vectors were concatenated with the 4800-dimensional book corpus skip-thought vectors available from Kiros et al.. Experiments on the training set indicated that using only the ReachOut skip-thought vectors slightly decreased performance, while using only the book corpus skip-thought vectors substantially decreased performance. As input the post models received the last 20 sentences in each target post and the last 20 sentences in the thread prior to the target post; any prior sentences are ignored."}, {"heading": "5.2 Depression detection.", "text": "The data used for depression detection was described in \u00a73. As baselines we compare our model against the FastText classifier (Joulin et al., 2016) and MNB and SVM classifiers (Wang and Manning, 2012) using features from prior work. We tune FastText\u2019s hyperparameters on the validation set. Specifically, we consider a maximum n-gram size \u2208 [1, 2, 3, 4, 5], an embedding size \u2208 [50, 100, 150], and a learning rate \u2208 [0.05, 0.1, 0.25, 0.5] as suggested in the documentation. We consider two sets of features for the MNB and SVM classifiers. The first set of features is the post content itself represented as sparse bag of words features (BoW baselines). The second set of features (feature-rich baselines) comprises a large set of features including bag of words features encoded as sparse weighted vectors, external psycholinguistic features captured by LIWC5 (2015), and emotion lexicon features (Staiano and Guerini, 2014). Since our problem is identifying depression among users, psycholinguistic signals and emotional attributes in the text are potentially important features for the task. These features (as described in \u00a72) have been also previously used by successful methods in the Twitter self-reported diagnosis detection task (Coppersmith et al., 2015b). Thus, we argue that these are strong baselines for our self-reported diagnosis detection task. We apply count based and TF-IDF based feature weighting for bag of words features. We perform standard preprocessing by removing stopwords and lowercasing the input text.6\nThe data is split into training, validation, and testing datasets each containing approximately\n5http://liwc.wpengine.com/ 6During experimentation, we found TF-IDF sparse feature weighting to be superior than other weighting schemes. Additional features such as LDA topics and \u03c72 feature selection did not result in any further improvements.\n3,000 diagnosed users and their matched control users. The validation set is used for tuning development and hyperparameter tuning of our models and the baselines. The reported results are on the test set. The depression detection models\u2019 input consisted of raw terms encoded as one-hot vectors. We used an input layer to learn 50-dimensional representation of the terms. For each target user, the CNN received up to npost posts containing up to nterm terms. In this section we present results for two values of npost. The earliest post approach (CNN-E) takes each user\u2019s npost = 400 earliest posts as input. The random approach (CNN-R) samples npost = 1500 random posts from each user. We empirically set nterm = 100 with both approaches. We later analyze the model\u2019s performance as npost and nterm vary in \u00a76.1 and as the post selection strategy varies in \u00a76.2.\nResults. The results of identifying depressed users for our model and baselines are shown in Table 2. Our proposed model outperforms the baselines by a large margin in terms of recall and F1 on the diagnosed users (increases of 41% and 16%, respectively), but performs worse in terms of precision. As described later in the analysis section, the CNN identifies language associated with negative sentiment across a user\u2019s posts."}, {"heading": "5.3 Self-harm risk classification.", "text": "We train our methods to label the ReachOut posts and compare them against the top methods from CLPsych \u201916. We use the same experimental protocol as was used in CLPsych \u201916; our methods were trained on the 947 training posts and evaluated on the remaining 280 testing posts. We used 15% of the 947 training posts as validation data.\nWe report results using the same metrics used in CLPsych, which were: the macro-averaged F1 for the amber, red, and crisis labels (non-\ngreen posts); the macro-averaged F1 of green posts vs. amber \u222a red \u222a crisis (flagged posts); and the macro-averaged F1 of green \u222a amber vs. red\u222acrisis (urgent posts). The non-green F1 was used as the official CLPsych metric with the intention of placing emphasis on classification performance for the non-green categories (i.e., those that required some response). The binary flagged meta-class was chosen to measure models\u2019 abilities to differentiate between posts that require attention and posts that do not, and the binary urgent meta-class was chosen to measure their abilities to differentiate between posts that require quick responses and posts that do not. In addition to macro-averaged F1, CLPsych also reported the accuracy for each category. We additionally report F1 macro-averaged over all classes.\nResults. The results on the self-harm risk assessment task for our models and for the current best-performing methods (briefly explained in \u00a72) are shown in Table 3. We also report a baseline result which is based on a SVM classifier with bigram features. When measured by non-green\nF1, the official metric of the CLPsych \u201916 Triage Task, our proposed models perform up to 19% better than the best existing methods. Similarly, our models perform up to 11% better when measured with an F1 macro-averaged across all categories (i.e., all column) and up to 5% better with measured accuracy across all categories. Categorical Cross Ent. performs best in all of these cases, though the difference between the performance of Categorical Cross Ent. and Class Metric with an ordinal margin is not statistically significant.\nWe also evaluate the performance of our methods on the training set using 10-fold cross validation to better observe performance differences (Table 4). All model variants perform substantially better on the training set than on the test set. This is partially explained by the fact that the models were tuned on the training set, but the large difference in some cases (e.g., the increase in the highest non-green F1 from 0.50 to 0.87) suggest there may be qualitative differences between the datasets. The best-performing method on the test set, Categorical Cross Ent., performs the worst on\n0 500 1000 1500 2000 2500 3000 3500 4000 Posts per user\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nC D\nF\n(a)\n0 100 200 300 400 500 Post length\n0.0\n0.2\n0.4\n0.6\n0.8 1.0 C D F\n(b)\nFigure 4: Empirical cumulative distribution functions (CDF) of the number of posts per user (a) and the post length (b) in the RSDD dataset.\nthe training set; worst-performing method on the test set, MSE, performs the best on the training set. Class Metric (Ordinal) performs well on both the testing and training sets, however, suggesting that it is more robust than the other methods. Furthermore, there is no statistically significant difference between Class Metric (Ordinal) and the best-performing method on either dataset."}, {"heading": "6 Analysis", "text": ""}, {"heading": "6.1 Posts per user and post length", "text": "In this section we consider the effects of the maximum number of posts per user (i.e., npost) and the maximum post length (i.e., nterm) on the Reddit dataset. To do so we train the CNN-R model as described in \u00a75.1 and report F1 on the validation set. When varying npost we set nterm = 100, and when varying nterm we set npost = 1500.\nAs shown in Figure 3, the best performance of the CNN-R model is reached when it considers 100 terms in posts and up to 1750 posts for each user. F1 increases as npost increases, up to the maximum tested value of 1750 (Figure 3a). There is relatively little change in F1 from npost = 1250 to npost = 1750, however, so we use npost = 1500 in our experiments for efficiency reasons. As shown in Figure 4a, approximately 20% of users have more than 1500 posts. The effect of the maximum post length is not consistent (Figure 3b), but performance is maximized at nterm = 100. As shown in Figure 4b, approximately 40% of posts are longer than 100 terms."}, {"heading": "6.2 Post selection", "text": "For users with more than the maximum number of posts npost, a post selection strategy dictates which posts are used as input to the model. Table\n5 shows the effect of the post selection strategy on the Reddit dataset\u2019s validation set. Selecting a user\u2019s earliest posts performs the worst regardless of npost\u2019s value, though the differences in F1 are smaller when npost = 400. Randomly selecting posts for each user performs the best across all metrics when npost = 1500, with a large increase in precision over selecting users\u2019 earliest posts and a small increase over choosing users\u2019 latest posts."}, {"heading": "6.3 Phrases contributing to classification", "text": "In this section we analyze the language that strongly contributed to the identification of depressed users on the Reddit dataset. Unfortunately, it is impossible to show entire Reddit posts without compromising users\u2019 anonymity; we found that even when a post is paraphrased, enough information remains that it can easily be identified using a Web search engine. For example, one Reddit post that strongly contributed to the author\u2019s classification as a depressed user contained the mention of a specific type of abuse and several comments vaguely related to this type of abuse. We attempted to paraphrase this post, but found that any paraphrase containing general language related to both the type of abuse and to the user\u2019s comments was enough to identify the user. Thus, to protect the anonymity of the users in our dataset, we do not publish posts in any form.\nRather than publishing posts, we identify key phrases in posts from users who were correctly identified as being depressed. Phrases from eight\nself-reported depressed users are shown in Table 6; to prevent these phrases from being used to identify users, we retain only the top phrase from each user. These phrases were identified by using the model\u2019s convolutional filter weights to identify posts in the validation dataset that are strongly contributing to the model\u2019s classification decision, and then using the convolutional filter weights to identify the phrase within each post that most strongly contributed to the post\u2019s classification (i.e., had the highest feature values).\nIn keeping with the design of our dataset, terms related to depression or diagnoses are not present. Instead, the model identifies phrases that often could be associated with a negative sentiment or outlook. For example, \u201cmy whole\u201d could be part of a negative comment referring to the poster\u2019s whole life. It should be noted that the model makes classification decisions based on the occurrence of phrases across many posts by the same user. Though one can imagine how the phrases shown here could be used to convey negative sentiment, the presence of a single such phrase is not sufficient to cause the model to classify a user as depressed."}, {"heading": "6.4 CLPsych \u201917 shared task", "text": "In this section we report results on the 2017 CLPsych Workshop\u2019s self-harm risk classification task.7 While CLPsych \u201917 featured the same self-harm risk classification task as CLPsych \u201916 (\u00a75.3), new test data was used to conduct the evaluation. This provides an opportunity to further evaluate our model on the task of self-harm risk assessment and to conduct an error analysis. The methods were configured and evaluated in the\n7The 2017 test data was released after the initial version of this manuscript had been completed. An official overview paper for CLPysch \u201917 is not yet available at the time of writing.\nsame manner as described in \u00a75.3.8 Results are shown in Table 7. All methods perform substantially worse than they performed on the CLPsych \u201916 test data as measured by nongreen, urgent, and overall F1. The trends across methods remain similar, however, with Categorical Cross Ent. performing the best as measured by non-green and overall F1, and with no statistically significant difference between Class Metric (Ordinal) and the best performing method.\nNotably, the methods\u2019 flagged F1 scores do not see a similar decrease on the CLPsych \u201917 data. This suggests that the decreased performance is being caused by an inability to distinguish between the non-green classes (i.e., amber, red, and crisis). The importance of differentiating between the red and crisis classes increased with the 2017 shared task, because the proportion of crisis labels in the data increased from 0.4% (2016 testing) and 4% (2016 training) to 11% (2017 testing). The methods rarely classify a post as crisis, however, causing an increase in the number of misclassifications on the 2017 testing data. For example, Class Metric (Ordinal) classified only four posts from the 2017 test data as crisis, and it classified no posts from the 2016 test data as crisis. We leave improving the model to better identify crisis posts as future work."}, {"heading": "7 Conclusion", "text": "In this work, we argued for the close connection between social media and mental health, and described a neural network architecture for performing self-harm risk classification and depression detection on social media posts. We described\n8The results in this section differ slightly from the methods\u2019 results as reported by CLPsych \u201917. Here the methods were trained on only CLPsych \u201916 training data to match the experimental setup described earlier, whereas the methods were trained on both the CLPsych \u201916 training and test data in the official results reported by CLPsych \u201917.\nthe construction of the Reddit Self-reported Depression Diagnosis (RSDD) dataset9, containing over 9,000 users with self-reported depression diagnoses matched with over 107,000 similar control users; the dataset is available under a data usage agreement. We applied our classification approach to the task of identifying depressed users on this dataset and found that it substantially outperformed strong existing methods in terms of Recall and F1. While these depression detection results are encouraging, the absolute values of the metrics illustrate that this is a challenging task and worthy of further exploration. We also applied our classification approach to the task of estimating the self-harm risk posed by posts on the ReachOut.com mental health support forum, and found that it substantially outperformed strong previously-proposed methods.\nOur approach and results are significant from several perspectives: they provide a strong approach to identifying posts indicating a risk of self-harm in social media; they demonstrate a means for large scale public mental health studies surrounding the state of depression; and they demonstrate the possibility of sensitive applications in the context of clinical care, where clinicians could be notified if the activities of their patients suggest they are at risk of self-harm. Furthermore, large-scale datasets such as the one presented in this paper can provide complementary information to existing data on mental health which are generally relatively smaller collections."}], "references": [{"title": "Ethical research protocols for social media health research", "author": ["Adrian Benton", "Glen Coppersmith", "Mark Dredze."], "venue": "EACL 2017, page 94.", "citeRegEx": "Benton et al\\.,? 2017a", "shortCiteRegEx": "Benton et al\\.", "year": 2017}, {"title": "Multitask learning for mental health conditions with limited social media data", "author": ["Adrian Benton", "Margaret Mitchell", "Dirk Hovy."], "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics:", "citeRegEx": "Benton et al\\.,? 2017b", "shortCiteRegEx": "Benton et al\\.", "year": 2017}, {"title": "Natural Language Processing with Python", "author": ["Steven Bird", "Ewan Klein", "Edward Loper."], "venue": "O\u2019Reilly Media.", "citeRegEx": "Bird et al\\.,? 2009", "shortCiteRegEx": "Bird et al\\.", "year": 2009}, {"title": "Classifying reachout posts with a radial basis function svm", "author": ["Chris Brew."], "venue": "Proceedings of the Third Workshop on Computational Lingusitics and Clinical Psychology, pages 138\u2013142, San Diego, CA, USA. Association for Computational Linguistics.", "citeRegEx": "Brew.,? 2016", "shortCiteRegEx": "Brew.", "year": 2016}, {"title": "Suicide fact sheet, suicide facts at a glance", "author": ["CDC."], "venue": "National Center for Injury Prevention and Control.", "citeRegEx": "CDC.,? 2015", "shortCiteRegEx": "CDC.", "year": 2015}, {"title": "The language of social support in social media and its effect on suicidal ideation risk", "author": ["Munmun De Choudhury", "Emre Kiciman."], "venue": "Proceedings of the International Conference onWeb and Social Media (ICWSM). AAAI.", "citeRegEx": "Choudhury and Kiciman.,? 2017", "shortCiteRegEx": "Choudhury and Kiciman.", "year": 2017}, {"title": "Triaging mental health forum posts", "author": ["Arman Cohan", "Sydney Young", "Nazli Goharian."], "venue": "Proceedings of the 3rd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 143\u2013147.", "citeRegEx": "Cohan et al\\.,? 2016", "shortCiteRegEx": "Cohan et al\\.", "year": 2016}, {"title": "Triaging content severity in online mental health forums", "author": ["Arman Cohan", "Sydney Young", "Andrew Yates", "Nazli Goharian."], "venue": "Journal of the Association for Information Science and Technology.", "citeRegEx": "Cohan et al\\.,? 2017", "shortCiteRegEx": "Cohan et al\\.", "year": 2017}, {"title": "Quantifying mental health signals in Twitter", "author": ["Glen Coppersmith", "Mark Dredze", "Craig Harman."], "venue": "Proceedings of the Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality.", "citeRegEx": "Coppersmith et al\\.,? 2014a", "shortCiteRegEx": "Coppersmith et al\\.", "year": 2014}, {"title": "From adhd to sad: Analyzing the language of mental health on twitter through self-reported diagnoses", "author": ["Glen Coppersmith", "Mark Dredze", "Craig Harman", "Kristy Hollingshead."], "venue": "CLPysch, pages 1\u201310.", "citeRegEx": "Coppersmith et al\\.,? 2015a", "shortCiteRegEx": "Coppersmith et al\\.", "year": 2015}, {"title": "Clpsych 2015 shared task: Depression and ptsd on twitter", "author": ["Glen Coppersmith", "Mark Dredze", "Craig Harman", "Kristy Hollingshead", "Margaret Mitchell."], "venue": "NAACL HLT 2015, page 31.", "citeRegEx": "Coppersmith et al\\.,? 2015b", "shortCiteRegEx": "Coppersmith et al\\.", "year": 2015}, {"title": "Measuring post traumatic stress disorder in twitter", "author": ["Glen Coppersmith", "Craig Harman", "Mark Dredze."], "venue": "ICWSM.", "citeRegEx": "Coppersmith et al\\.,? 2014b", "shortCiteRegEx": "Coppersmith et al\\.", "year": 2014}, {"title": "Exploratory analysis of social media prior to a suicide", "author": ["Glen Coppersmith", "Kim Ngo", "Ryan Leary", "Anthony Wood"], "venue": null, "citeRegEx": "Coppersmith et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Coppersmith et al\\.", "year": 2016}, {"title": "Mental health discourse on reddit: Self-disclosure, social support, and anonymity", "author": ["Munmun De Choudhury", "Sushovan De."], "venue": "ICWSM.", "citeRegEx": "Choudhury and De.,? 2014", "shortCiteRegEx": "Choudhury and De.", "year": 2014}, {"title": "Predicting Depression via Social Media", "author": ["Munmun De Choudhury", "Michael Gamon", "Scott Counts", "Eric Horvitz."], "venue": "AAAI.", "citeRegEx": "Choudhury et al\\.,? 2013", "shortCiteRegEx": "Choudhury et al\\.", "year": 2013}, {"title": "Discovering shifts to suicidal ideation from mental health content in social media", "author": ["Munmun De Choudhury", "Emre Kiciman", "Mark Dredze", "Glen Coppersmith", "Mrinal Kumar."], "venue": "Proceedings of the 34rd Annual ACM Conference on Human Factors in", "citeRegEx": "Choudhury et al\\.,? 2016", "shortCiteRegEx": "Choudhury et al\\.", "year": 2016}, {"title": "The burden attributable to mental and substance use disorders as risk factors", "author": ["Alize J Ferrari", "Rosana E Norman", "Greg Freedman", "Amanda J Baxter", "Jane E Pirkis", "Meredith G Harris", "Andrew Page", "Emily Carnahan", "Louisa Degenhardt", "Theo Vos"], "venue": null, "citeRegEx": "Ferrari et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ferrari et al\\.", "year": 2014}, {"title": "Twitter postings and suicide: An analysis of the postings of a fatal suicide in the 24 hours prior to death", "author": ["John F Gunn", "David Lester."], "venue": "Suicidologi, 17(3).", "citeRegEx": "Gunn and Lester.,? 2015", "shortCiteRegEx": "Gunn and Lester.", "year": 2015}, {"title": "The social impact of natural language processing", "author": ["Dirk Hovy", "Shannon L Spruit."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, volume 2, pages 591\u2013 598.", "citeRegEx": "Hovy and Spruit.,? 2016", "shortCiteRegEx": "Hovy and Spruit.", "year": 2016}, {"title": "Tracking suicide risk factors through Twitter in the US", "author": ["Jared Jashinsky", "Scott H Burton", "Carl L Hanson", "Josh West", "Christophe Giraud-Carrier", "Michael D Barnes", "Trenton Argyle."], "venue": "Crisis.", "citeRegEx": "Jashinsky et al\\.,? 2014", "shortCiteRegEx": "Jashinsky et al\\.", "year": 2014}, {"title": "Bag of tricks for efficient text classification", "author": ["Armand Joulin", "Edouard Grave", "Piotr Bojanowski", "Tomas Mikolov."], "venue": "arXiv preprint arXiv:1607.01759.", "citeRegEx": "Joulin et al\\.,? 2016", "shortCiteRegEx": "Joulin et al\\.", "year": 2016}, {"title": "A convolutional neural network for modelling sentences", "author": ["Nal Kalchbrenner", "Edward Grefenstette", "Phil Blunsom."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages", "citeRegEx": "Kalchbrenner et al\\.,? 2014", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Data61-csiro systems at the clpsych 2016 shared task", "author": ["Sunghwan Mac Kim", "Yufei Wang", "Stephen Wan", "Cecile Paris."], "venue": "Proceedings of the Third Workshop on Computational Lingusitics and Clinical Psychology, pages 128\u2013132, San Diego,", "citeRegEx": "Kim et al\\.,? 2016", "shortCiteRegEx": "Kim et al\\.", "year": 2016}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1746\u20131751.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik P. Kingma", "Jimmy Ba."], "venue": "arXiv preprints, arXiv:1412.6980.", "citeRegEx": "Kingma and Ba.,? 2014", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Skip-thought vectors", "author": ["Ryan Kiros", "Yukun Zhu", "Ruslan Salakhutdinov", "Richard S. Zemel", "Antonio Torralba", "Raquel Urtasun", "Sanja Fidler."], "venue": "NIPS, Cambridge, MA, USA. MIT Press.", "citeRegEx": "Kiros et al\\.,? 2015", "shortCiteRegEx": "Kiros et al\\.", "year": 2015}, {"title": "Unsupervised multilingual sentence boundary detection", "author": ["Tibor Kiss", "Jan Strunk."], "venue": "Comput. Linguist., 32(4).", "citeRegEx": "Kiss and Strunk.,? 2006", "shortCiteRegEx": "Kiss and Strunk.", "year": 2006}, {"title": "A test collection for research on depression and language use", "author": ["David E Losada", "Fabio Crestani."], "venue": "International Conference of the Cross-Language Evaluation Forum for European Languages, pages 28\u201339.", "citeRegEx": "Losada and Crestani.,? 2016", "shortCiteRegEx": "Losada and Crestani.", "year": 2016}, {"title": "Predicting post severity in mental health forums", "author": ["Shervin Malmasi", "Marcos Zampieri", "Mark Dras."], "venue": "Proceedings of the Third Workshop on Computational Lingusitics and Clinical Psychology, pages 133\u2013137, San Diego, CA, USA. Association", "citeRegEx": "Malmasi et al\\.,? 2016", "shortCiteRegEx": "Malmasi et al\\.", "year": 2016}, {"title": "Modeling and understanding visual attributes of mental health disclosures in social media", "author": ["L Manikonda", "M De Choudhury."], "venue": "CHI \u201917.", "citeRegEx": "Manikonda and Choudhury.,? 2017", "shortCiteRegEx": "Manikonda and Choudhury.", "year": 2017}, {"title": "Clpsych 2016 shared task: Triaging content in online peer-support forums", "author": ["David N. Milne", "Glen Pink", "Ben Hachey", "Rafael A. Calvo."], "venue": "Proceedings of the 3rd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to", "citeRegEx": "Milne et al\\.,? 2016", "shortCiteRegEx": "Milne et al\\.", "year": 2016}, {"title": "Quantifying the language of schizophrenia in social media", "author": ["Margaret Mitchell", "Kristy Hollingshead", "Glen Coppersmith."], "venue": "NAACL-HLT Workshop on CLPsych 2015, page 11.", "citeRegEx": "Mitchell et al\\.,? 2015", "shortCiteRegEx": "Mitchell et al\\.", "year": 2015}, {"title": "Towards automatically classifying depressive symptoms from twitter data for population health", "author": ["Danielle Mowery", "Albert Park", "Mike Conway", "Craig Bryan."], "venue": "Proceedings of the Workshop on Computational Modeling of Peoples Opinions, Per-", "citeRegEx": "Mowery et al\\.,? 2016", "shortCiteRegEx": "Mowery et al\\.", "year": 2016}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["Vinod Nair", "Geoffrey E. Hinton."], "venue": "Proceedings of the 27th International Conference on Machine Learning (ICML-10), pages 807\u2013814.", "citeRegEx": "Nair and Hinton.,? 2010", "shortCiteRegEx": "Nair and Hinton.", "year": 2010}, {"title": "The development and psychometric properties of liwc2015", "author": ["James W Pennebaker", "Ryan L Boyd", "Kayla Jordan", "Kate Blackburn."], "venue": "UT Faculty/Researcher Works.", "citeRegEx": "Pennebaker et al\\.,? 2015", "shortCiteRegEx": "Pennebaker et al\\.", "year": 2015}, {"title": "The role of personality, age, and gender in tweeting about mental illness", "author": ["Daniel Preo\u0163iuc-Pietro", "Johannes Eichstaedt", "Gregory Park", "Maarten Sap", "Laura Smith", "Victoria Tobolsky", "H. Andrew Schwartz", "Lyle Ungar."], "venue": "Proceedings of the 2nd Workshop", "citeRegEx": "Preo\u0163iuc.Pietro et al\\.,? 2015", "shortCiteRegEx": "Preo\u0163iuc.Pietro et al\\.", "year": 2015}, {"title": "The university of maryland clpsych 2015 shared task system", "author": ["Philip Resnik", "William Armstrong", "Leonardo Claudino", "Thang Nguyen."], "venue": "Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychol-", "citeRegEx": "Resnik et al\\.,? 2015", "shortCiteRegEx": "Resnik et al\\.", "year": 2015}, {"title": "Using topic modeling to improve prediction of neuroticism and depression", "author": ["Philip Resnik", "Anderson Garron", "Rebecca Resnik."], "venue": "EMNLP, pages 1348\u20131353. Association for Computational Linguistics.", "citeRegEx": "Resnik et al\\.,? 2013", "shortCiteRegEx": "Resnik et al\\.", "year": 2013}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey E Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov."], "venue": "Journal of Machine Learning Research, 15(1):1929\u20131958.", "citeRegEx": "Srivastava et al\\.,? 2014", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Depechemood: a lexicon for emotion analysis from crowd-annotated news", "author": ["Jacopo Staiano", "Marco Guerini."], "venue": "arXiv preprints, arXiv:1405.1605.", "citeRegEx": "Staiano and Guerini.,? 2014", "shortCiteRegEx": "Staiano and Guerini.", "year": 2014}, {"title": "A short review of ethical challenges in clinical natural language processing", "author": ["Simon \u0160uster", "St\u00e9phan Tulkens", "Walter Daelemans."], "venue": "arXiv preprint arXiv:1703.10090.", "citeRegEx": "\u0160uster et al\\.,? 2017", "shortCiteRegEx": "\u0160uster et al\\.", "year": 2017}, {"title": "Predicting military and veteran suicide risk: Cultural aspects", "author": ["Paul Thompson", "Craig Bryan", "Chris Poulin."], "venue": "Proceedings of the Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 1\u20136, Bal-", "citeRegEx": "Thompson et al\\.,? 2014", "shortCiteRegEx": "Thompson et al\\.", "year": 2014}, {"title": "Recognizing depression from twitter activity", "author": ["Sho Tsugawa", "Yusuke Kikuchi", "Fumio Kishino", "Kosuke Nakajima", "Yuichi Itoh", "Hiroyuki Ohsaki."], "venue": "Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. ACM.", "citeRegEx": "Tsugawa et al\\.,? 2015", "shortCiteRegEx": "Tsugawa et al\\.", "year": 2015}, {"title": "Social support: Conceptualization, measurement, and implications for mental health", "author": ["R Jay Turner", "B Gail Frankel", "Deborah M Levin."], "venue": "Research in Community & Mental Health.", "citeRegEx": "Turner et al\\.,? 1983", "shortCiteRegEx": "Turner et al\\.", "year": 1983}, {"title": "Baselines and bigrams: Simple, good sentiment and topic classification", "author": ["Sida Wang", "Christopher D Manning."], "venue": "ACL \u201912.", "citeRegEx": "Wang and Manning.,? 2012", "shortCiteRegEx": "Wang and Manning.", "year": 2012}, {"title": "World Health Organization", "author": ["Health Statistics"], "venue": "Yijun Xiao and Kyunghyun Cho. 2016. Efficient", "citeRegEx": "Statistics,? 2010", "shortCiteRegEx": "Statistics", "year": 2010}], "referenceMentions": [{"referenceID": 4, "context": "Suicide is one of the leading causes of death (CDC, 2015), and each suicide case has", "startOffset": 46, "endOffset": 57}, {"referenceID": 16, "context": "Therefore identifying individuals at risk of selfharm and providing support to prevent it remains an important problem (Ferrari et al., 2014).", "startOffset": 119, "endOffset": 141}, {"referenceID": 8, "context": "ing such posts, and identifying individuals at risk of harm (Coppersmith et al., 2014a).", "startOffset": 60, "endOffset": 87}, {"referenceID": 37, "context": "There is a growing body of related work analyzing mental health-related discourse and language usage in social media to better discover and understand mental health related concerns (Resnik et al., 2013; De Choudhury et al., 2013; Coppersmith et al., 2014b,a; Mitchell et al., 2015; Tsugawa et al., 2015; Coppersmith et al., 2015a; Althoff et al., 2016; Mowery et al., 2016; Benton et al., 2017b).", "startOffset": 182, "endOffset": 396}, {"referenceID": 31, "context": "There is a growing body of related work analyzing mental health-related discourse and language usage in social media to better discover and understand mental health related concerns (Resnik et al., 2013; De Choudhury et al., 2013; Coppersmith et al., 2014b,a; Mitchell et al., 2015; Tsugawa et al., 2015; Coppersmith et al., 2015a; Althoff et al., 2016; Mowery et al., 2016; Benton et al., 2017b).", "startOffset": 182, "endOffset": 396}, {"referenceID": 42, "context": "There is a growing body of related work analyzing mental health-related discourse and language usage in social media to better discover and understand mental health related concerns (Resnik et al., 2013; De Choudhury et al., 2013; Coppersmith et al., 2014b,a; Mitchell et al., 2015; Tsugawa et al., 2015; Coppersmith et al., 2015a; Althoff et al., 2016; Mowery et al., 2016; Benton et al., 2017b).", "startOffset": 182, "endOffset": 396}, {"referenceID": 9, "context": "There is a growing body of related work analyzing mental health-related discourse and language usage in social media to better discover and understand mental health related concerns (Resnik et al., 2013; De Choudhury et al., 2013; Coppersmith et al., 2014b,a; Mitchell et al., 2015; Tsugawa et al., 2015; Coppersmith et al., 2015a; Althoff et al., 2016; Mowery et al., 2016; Benton et al., 2017b).", "startOffset": 182, "endOffset": 396}, {"referenceID": 32, "context": "There is a growing body of related work analyzing mental health-related discourse and language usage in social media to better discover and understand mental health related concerns (Resnik et al., 2013; De Choudhury et al., 2013; Coppersmith et al., 2014b,a; Mitchell et al., 2015; Tsugawa et al., 2015; Coppersmith et al., 2015a; Althoff et al., 2016; Mowery et al., 2016; Benton et al., 2017b).", "startOffset": 182, "endOffset": 396}, {"referenceID": 1, "context": "There is a growing body of related work analyzing mental health-related discourse and language usage in social media to better discover and understand mental health related concerns (Resnik et al., 2013; De Choudhury et al., 2013; Coppersmith et al., 2014b,a; Mitchell et al., 2015; Tsugawa et al., 2015; Coppersmith et al., 2015a; Althoff et al., 2016; Mowery et al., 2016; Benton et al., 2017b).", "startOffset": 182, "endOffset": 396}, {"referenceID": 10, "context": "To investigate NLP methods for identifying depression and PTSD users on Twitter, a shared task (Coppersmith et al., 2015b) at the 2nd Computational Linguistics and Clinical Psychology Workshop (CLPsych 2015) was introduced where the participants evaluated their methods on a dataset of about 1800 Twitter users.", "startOffset": 95, "endOffset": 122}, {"referenceID": 27, "context": "com users to support self-reported diagnosis detection (Losada and Crestani, 2016).", "startOffset": 55, "endOffset": 82}, {"referenceID": 0, "context": ", 2016; Benton et al., 2017b). To investigate NLP methods for identifying depression and PTSD users on Twitter, a shared task (Coppersmith et al., 2015b) at the 2nd Computational Linguistics and Clinical Psychology Workshop (CLPsych 2015) was introduced where the participants evaluated their methods on a dataset of about 1800 Twitter users. Other work has used data from approximately 900 Reddit.com users to support self-reported diagnosis detection (Losada and Crestani, 2016). Previous work identifying depression and other mental health problems, including the methods participating in CLPsych 2015 (e.g. works by Resnik et al. (2015) and Preo\u0163iuc-Pietro et al.", "startOffset": 8, "endOffset": 641}, {"referenceID": 0, "context": ", 2016; Benton et al., 2017b). To investigate NLP methods for identifying depression and PTSD users on Twitter, a shared task (Coppersmith et al., 2015b) at the 2nd Computational Linguistics and Clinical Psychology Workshop (CLPsych 2015) was introduced where the participants evaluated their methods on a dataset of about 1800 Twitter users. Other work has used data from approximately 900 Reddit.com users to support self-reported diagnosis detection (Losada and Crestani, 2016). Previous work identifying depression and other mental health problems, including the methods participating in CLPsych 2015 (e.g. works by Resnik et al. (2015) and Preo\u0163iuc-Pietro et al. (2015))", "startOffset": 8, "endOffset": 675}, {"referenceID": 34, "context": "heavily rely on utilizing features such as LIWC (Pennebaker et al., 2015), topic modeling, manual lexicons, or other domain-dependent applicationspecific features.", "startOffset": 48, "endOffset": 73}, {"referenceID": 22, "context": "forum posts (Kim et al., 2016), a stack of featurerich Random Forest and linear Support Vector Machine (SVM) (Malmasi et al.", "startOffset": 12, "endOffset": 30}, {"referenceID": 28, "context": ", 2016), a stack of featurerich Random Forest and linear Support Vector Machine (SVM) (Malmasi et al., 2016), an RBF SVM classifier utilizing similar sets of features (Brew, 2016), and various contextual and psycholinguistic features (Cohan et al.", "startOffset": 86, "endOffset": 108}, {"referenceID": 3, "context": ", 2016), an RBF SVM classifier utilizing similar sets of features (Brew, 2016), and various contextual and psycholinguistic features (Cohan et al.", "startOffset": 66, "endOffset": 78}, {"referenceID": 21, "context": "similarities with CNN-based models in prior work (Kalchbrenner et al., 2014; Kim, 2014; Xiao and Cho, 2016), it focuses on learning representations of user\u2019s posts and combining the post representations into an overall representation of the user\u2019s activity.", "startOffset": 49, "endOffset": 107}, {"referenceID": 23, "context": "similarities with CNN-based models in prior work (Kalchbrenner et al., 2014; Kim, 2014; Xiao and Cho, 2016), it focuses on learning representations of user\u2019s posts and combining the post representations into an overall representation of the user\u2019s activity.", "startOffset": 49, "endOffset": 107}, {"referenceID": 30, "context": "shead and Ungar, 2016) released a Triage dataset containing 65,024 forum posts from ReachOut, with annotations for 1,227 posts indicating the author\u2019s risk of self-harm (Milne et al., 2016).", "startOffset": 169, "endOffset": 189}, {"referenceID": 18, "context": "(Hovy and Spruit, 2016; \u0160uster et al., 2017; Benton et al., 2017a).", "startOffset": 0, "endOffset": 66}, {"referenceID": 40, "context": "(Hovy and Spruit, 2016; \u0160uster et al., 2017; Benton et al., 2017a).", "startOffset": 0, "endOffset": 66}, {"referenceID": 0, "context": "(Hovy and Spruit, 2016; \u0160uster et al., 2017; Benton et al., 2017a).", "startOffset": 0, "endOffset": 66}, {"referenceID": 30, "context": "This assessment is supported by previous work on the ReachOut dataset (Milne et al., 2016), on Twitter data (Coppersmith et al.", "startOffset": 70, "endOffset": 90}, {"referenceID": 10, "context": ", 2016), on Twitter data (Coppersmith et al., 2015b), and", "startOffset": 25, "endOffset": 52}, {"referenceID": 27, "context": "on other Reddit data (Losada and Crestani, 2016).", "startOffset": 21, "endOffset": 48}, {"referenceID": 23, "context": "Convolutional networks have commonly been applied to the task of text classification, such as by Kim (2014). We use cat-", "startOffset": 97, "endOffset": 108}, {"referenceID": 38, "context": ", fully connected layers) with dropout (Srivastava et al., 2014) before being processed by a final output layer to perform classification.", "startOffset": 39, "endOffset": 64}, {"referenceID": 33, "context": "Both the convolutional and dense layers use ReLU activations (Nair and Hinton, 2010) in all model variants.", "startOffset": 61, "endOffset": 84}, {"referenceID": 24, "context": "All models were trained using stochastic gradient descent with the Adam optimizer (Kingma and Ba, 2014).", "startOffset": 82, "endOffset": 103}, {"referenceID": 25, "context": "The post classification models\u2019 input consists of skip-thought vectors (Kiros et al., 2015); each vector used is a 7200dimensional representation of a sentence.", "startOffset": 71, "endOffset": 91}, {"referenceID": 26, "context": "enizer (Kiss and Strunk, 2006) available in NLTK (Bird et al.", "startOffset": 7, "endOffset": 30}, {"referenceID": 2, "context": "enizer (Kiss and Strunk, 2006) available in NLTK (Bird et al., 2009).", "startOffset": 49, "endOffset": 68}, {"referenceID": 20, "context": "As baselines we compare our model against the FastText classifier (Joulin et al., 2016) and MNB and SVM classifiers (Wang and Manning, 2012) using features from prior work.", "startOffset": 66, "endOffset": 87}, {"referenceID": 44, "context": ", 2016) and MNB and SVM classifiers (Wang and Manning, 2012) using features from prior work.", "startOffset": 36, "endOffset": 60}, {"referenceID": 39, "context": "a large set of features including bag of words features encoded as sparse weighted vectors, external psycholinguistic features captured by LIWC5 (2015), and emotion lexicon features (Staiano and Guerini, 2014).", "startOffset": 182, "endOffset": 209}, {"referenceID": 10, "context": "These features (as described in \u00a72) have been also previously used by successful methods in the Twitter self-reported diagnosis detection task (Coppersmith et al., 2015b).", "startOffset": 143, "endOffset": 170}, {"referenceID": 30, "context": "Baseline (Milne et al., 2016) 0.", "startOffset": 9, "endOffset": 29}, {"referenceID": 3, "context": "83 Brew (2016) 0.", "startOffset": 3, "endOffset": 15}, {"referenceID": 3, "context": "83 Brew (2016) 0.42 0.78 0.85 0.69 0.93 0.54 0.79 Cohan et al. (2016) 0.", "startOffset": 3, "endOffset": 70}, {"referenceID": 30, "context": "Results for the other methods are from (Milne et al., 2016).", "startOffset": 39, "endOffset": 59}], "year": 2017, "abstractText": "Users suffering from mental health conditions often turn to online resources for support, including specialized online support communities or general communities such as Twitter and Reddit. In this work, we present a neural framework for supporting and studying users in both types of communities. We propose methods for identifying posts in support communities that may indicate a risk of self-harm, and demonstrate that our approach outperforms strong previously proposed methods for identifying such posts. Self-harm is closely related to depression, which makes identifying depressed users on general forums a crucial related task. We introduce a large-scale general forum dataset (\u201cRSDD\u201d) consisting of users with selfreported depression diagnoses matched with control users. We show how our method can be applied to effectively identify depressed users from their use of language alone. We demonstrate that our method outperforms strong baselines on this general forum dataset.", "creator": "LaTeX with hyperref package"}}}