{"id": "1709.02418", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2017", "title": "How Does Knowledge of the AUC Constrain the Set of Possible Ground-truth Labelings?", "abstract": "Recent work to protect privacy in machine learning has explored how data mining contests like Kaggle can potentially be \"hacked,\" either intentionally or unintentionally, using information from an oracle that indicates the accuracy of a classifier on the test set. Specifically, for binary classification tasks, the Area Under the ROC Curve (AUC) is one of the most common accuracy metrics, and in this paper we examine the mathematical structure of how the AUC is calculated from an n-vector of real \"guesses\" regarding the soil truth labels. Finally, we show how knowledge of the AUC of a classifier on the test set can limit the amount of possible soil truth labels, and we derive an algorithm to both calculate the exact number of such labels and efficiently enumerate them. Finally, we provide empirical evidence that the number of compatible labels on the test set can actually decrease as it grows, depending on the test being reached.", "histories": [["v1", "Thu, 7 Sep 2017 19:30:57 GMT  (82kb,D)", "http://arxiv.org/abs/1709.02418v1", null], ["v2", "Mon, 11 Sep 2017 15:11:28 GMT  (82kb,D)", "http://arxiv.org/abs/1709.02418v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jacob whitehill"], "accepted": false, "id": "1709.02418"}, "pdf": {"name": "1709.02418.pdf", "metadata": {"source": "CRF", "title": "How Does Knowledge of the AUC Constrain the Set of Possible Ground-truth Labelings?", "authors": ["Jacob Whitehill"], "emails": ["jrwhitehill@wpi.edu"], "sections": [{"heading": "1 Introduction and Related Work", "text": "Datamining contests such as Kaggle and KDDCup can accelerate progress in many application domains by providing standardized datasets and a fair basis of comparing multiple algorithmic approaches. However, their utility will diminish if the integrity of leaderboard rankings is called into question due to either intentional or accidental overfitting to the test data. Recent research on privacy-preserving machine learning (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information on the accuracy of a contestant\u2019s guesses, returned to the contestant by an oracle, can divulge information about the test data\u2019s true labels. Such oracles are often provided by the organizers of the competition themselves. For example, in the 2017 Intel & MobileODT Cervical Cancer Screening competition1 hosted by Kaggle, every contestant can submit her/his guesses up to 5 times per day, and for each submission the oracle returns the log-loss of the guesses with respect to the ground-truth values of the entire 512-element test set. The contestant can use the accuracy information to improve (hopefully) the classifier design and then re-submit.\nAUC: For binary classification problems, one of the most commonly used accuracy metrics is the Area Under the Receiver Operating Characteristics Curve (AUC). In contrast to other accuracy metrics such as log-loss and 0/1 loss, which can be computed as the sum of example-wise losses over each example in the test set, the AUC statistic is computed over all possible pairs of test examples, such that each pair contains one example from each class. In a recent paper, Whitehill (2016) showed that an oracle that provides contestants with information on the AUC of their guesses can inadvertently divulge information on the ground-truth labels of the test examples. As a concrete example, suppose\n1 https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\nar X\niv :1\n70 9.\n02 41\n8v 1\n[ cs\n.L G\n] 7\nS ep\nthat a tiny test set contains just 4 examples; a contestant\u2019s real-valued guesses for these labels is y\u0302 = (0.2, 0.5, 0.9, 0.1); and an oracle informs the contestant that her/his guesses have achieved an AUC of exactly 0.75 = 3/4. How does this information constrain the set of possible binary ground-truth vectors for the test set? In this example, it turns out that there is exactly one possible ground-truth vector \u2013 namely y = (1, 0, 1, 0) \u2013 for which the AUC of the contestant\u2019s guesses is exactly 0.75. Hence, based on a single oracle query, the contestant has managed to deduce the test labels with complete certainty. This simple example raises more general questions: For a test set with n examples and a fixed AUC of c = p/q (where p, q \u2208 Z), how many compatible binary ground-truth vectors are there? Does this number grow monotonically in n, or might there exist some \u201cpathological\u201d combinations of the number of test examples n, number of positively labeled examples n1, and the contestant\u2019s AUC c, such that this number is small? If the number is small, can the solution candidates be enumerated efficiently? This paper explores these questions in some detail.\nRelated work: Over the past few years there has been growing theoretical and practical interest in the statistical validity of scientific results that are obtained from adaptive data analyses, in which the results of one experiment inform the design of the next (Dwork et al., 2015; Hardt and Ullman, 2014). For the particular application of datamining contests \u2013 in which contestants can submit their guesses to an oracle, receive information on their accuracy, revise their guesses, and resubmit \u2013 a potential danger is that the rankings and associated accuracy statistics of different contestants may be unreliable. Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution.\nWhile the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. The AUC statistic, in particular, has been investigated in the context of privacy: Stoddard, Chen, and Machanavajjhala (2014) proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics. Matthews and Harel (2013) showed how an attacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an empirical ROC curve, i.e., a set of classifier thresholds and corresponding true positive and false positive rates.\nThe prior work most similar to ours is by Whitehill (2016). They showed a weak form of lower bound on the number of possible binary ground-truth vectors y \u2208 {0, 1}n for which the contestant\u2019s guesses y\u0302 achieve any fixed AUC c. Specifically, for every AUC value c = p/q \u2208 (0, 1), there exists an infinite sequence of dataset sizes (n = 4q, 8q, 12q, . . .) such that the number of satisfying ground-truth vectors y \u2208 {0, 1}n grows exponentially in n. However, this result does not preclude the possibility that there might be certain pathological cases \u2013 combinations of p, q, n0, and n1 \u2013 for which the number of satisfying ground-truth vectors is actually much smaller. Conceivably, there might be values of n that lie between integer multiples of 4q for which the number of satisfying solutions is small. Moreover, the lower bound in Whitehill (2016) applies only to datasets that contain at least 4q examples and says nothing about smaller (but possibly still substantial) datasets.\nContributions: The novel contributions of our paper are the following: (1) We derive an algorithm to compute the exact number of n-dimensional binary ground-truth vectors for which a contestant\u2019s real-valued vector of guesses achieves a fixed AUC, along with an algorithm to efficiently generate all such vectors. (2) We show that the number of distinct binary ground-truth vectors, in which n1 entries are 1, and for which a contestant\u2019s guesses achieve a fixed AUC, is equal to the number of elements in a truncated n1-dimensional discrete simplex (i.e., a subset of \u2206n1d ). (3) We provide empirical evidence that the number of satisfying binary ground-truth vectors can actually decrease with increasing n, until a test set-dependent threshold is reached."}, {"heading": "2 Notation and Assumptions", "text": "Let y = (y1, . . . , yn) \u2208 {0, 1}n be the ground-truth binary labels of n test examples, and let y\u0302 = (y\u03021, . . . , y\u0302n) \u2208 Rn be the contestant\u2019s real-valued guesses. Let L1(y) = {i : yi = 1} and L0(y) = {i : yi = 0} represent the index sets of the examples that are labeled 1 and 0, respectively. Similarly define n1(y) = |L1(y)| and n0(y) = |L0(y)| to be the number of examples labeled 1 and 0 in y, respectively. For brevity, we sometimes write simply n1, n0, L0, or L1 if the argument to these functions is clear from the context.\nWe assume that the contestant\u2019s guesses y\u03021, . . . , y\u0302n are all distinct (i.e., y\u0302i = y\u0302j \u21d0\u21d2 i = j). In machine learning applications where classifiers analyze high-dimensional, real-valued feature vectors, this is common.\nImportantly, but without loss of generality, we assume that the test examples are ordered according to y\u03021, . . . , y\u0302n, i.e., y\u0302i > y\u0302j \u21d0\u21d2 i > j. This significantly simplifies the notation. Finally, we assume that the oracle provides the contestant with perfect knowledge of the AUC c = p/q, where p/q is a reduced fraction (i.e., the greatest common factor of p and q 1) on the entire test set, and that the contestant knows both p and q."}, {"heading": "3 AUC Accuracy Metric", "text": "The AUC has two mathematically equivalent definitions (Tyler and Chen, 2000; Agarwal et al., 2005): (1) the AUC is the Area under the Receiver Operating Characteristics (ROC) curve, which plots the true positive rate against the false positive rate of a classifier on some test set. The ROC thus characterizes the performance of the classifier over all possible thresholds on its real-valued output, and the AUC is the integral of the ROC over all possible false positive rates in the interval [0, 1]. (2) The AUC represents the fraction of pairs of test examples \u2013 one labeled 1 and one labeled 0 \u2013 in which the classifier can correctly identify the positively labeled example based on the classifier output. Specifically, since we assume that all of the contestant\u2019s guesses are distinct, then the AUC can be computed as:\nAUC(y, y\u0302) = 1\nn0n1 \u2211 i\u2208L0 \u2211 j\u2208L1 I[y\u0302i < y\u0302j ] (1)\nEquivalently, we can define the AUC in terms of the number of misclassified pairs h:\nAUC(y, y\u0302) = 1\u2212 h(y, y\u0302) n0n1\nwhere h(y, y\u0302) = \u2211 i\u2208L0 \u2211 j\u2208L1 I[y\u0302i > y\u0302j ]\nAs is evident in Eq. 1, all that matters to the AUC is the relative ordering of the y\u0302i, not their exact values. Also, if all examples belong to the same class and either n1 = 0 or n0 = 0, then the AUC is undefined. Finally, the AUC is a rational number because it can be written as the fraction of two integers p and q, where q must divide n0n1.\nSince we assume (without loss of generality) that the contestant\u2019s guesses are ordered such that y\u0302i < y\u0302j \u21d0\u21d2 i < j, then we can simplify the definition of h to be:\nh(y, y\u0302) = \u2211 i\u2208L0 \u2211 j\u2208L1 I[i > j] (2)\n4 Computing the Exact Number of Binary Labelings for which AUC=c\nIn this paper, we are interested in determining the number of unique binary vectors y \u2208 {0, 1}n such that the contestant\u2019s guesses y\u0302 \u2208 Rn achieve a fixed AUC of c. The bulk of the effort is to derive a recursive formula for the number of unique binary vectors with a fixed number n1 of 1s that give the desired AUC value.\nIntuition: Given a real-valued vector y\u0302 representing the contestant\u2019s guesses and a corresponding binary vector y representing the ground-truth test labels, the number h(y, y\u0302) of misclassified pairs\nof examples (such that each pair contains one example from each class) can be increased by 1 by \u201cleft-swapping\u201d any occurrence of 1 in y (at index j\u2032) with a 0 that occurs immediately to the left of it (i.e., at index j\u2032 \u2212 1) \u2013 see Figure 1. To generate a vector y such that h(y, y\u0302) = d for any desired d \u2208 {0, . . . , q}, we start with a vector r in \u201cright-most configuration\u201d \u2013 i.e., where all the 0s occur to the left of all the 1s \u2013 because (as we will show) h(r, y\u0302) = 0. We then apply a sequence of multiple left-swaps to each of the 1s in r, and count the number of ways of doing so such that the total number is d. Because we want to determine the number of unique vectors y such that h(y, y\u0302) = d, we restrict the numbers s1, . . . , sn1 of left-swaps applied to the n1 different 1s in r so that si \u2265 sj for all i < j. This results in a proof that the number of possible ground-truth binary labelings, for any given value of n1 and for which a given vector of guesses misclassifies d pairs of examples, is equal to the number of points in a n1-dimensional discrete simplex \u2206n1d that has been truncated by the additional constraint that n0 \u2265 s1 \u2265 . . . \u2265 sn1 . To get started, we first define \u201cleft-swap\u201d and \u201cright-most configuration\u201d more precisely:\nDefinition 1. For any y \u2208 {0, 1}n and i \u2208 {2, . . . , n} where yi = 1 and yi\u22121 = 0, define the (partial) function \u03c3 : {0, 1}n \u00d7 Z+ \u2192 {0, 1}n such that \u03c3(y, i) = (y1, . . . , yi, yi\u22121, yi+1, . . . , yn). Function \u03c3 is said to perform a left-swap on y from index i. Definition 2. For any y \u2208 {0, 1}n, i \u2208 {2, . . . , n}, and k < i where yi = 1 and yi\u22121 = . . . = yi\u2212k = 0, define the (partial) function \u03c1 : {0, 1}n \u00d7 Z+ \u00d7 Z+ \u2192 {0, 1}n, where\n\u03c1(y, i, k) =  \u03c3(y, i) for k = 1\n\u03c3(. . . (\u03c3(\u03c3\ufe38 \ufe37\ufe37 \ufe38 k (y, i), i\u2212 1), . . .), i\u2212 (k \u2212 1)) for k > 1\nFunction \u03c1 is said to perform k consecutive left-swaps on y from index i. Example 1. Let y = (y1, y2, y3, y4, y5) \u2208 {0, 1}5. Then \u03c3(y, 4) = (y1, y2, y4, y3, y5) and \u03c1(y, 4, 3) = (y4, y1, y2, y3, y5).\nDefinition 3. Let y be a vector of n binary labels such that n1 entries are 1. Let L1(y) = {p1, . . . , pn1}, ordered such that pi < pj \u21d0\u21d2 i < j, be the indices of the 1s in the vector. Then we say y is in a right-most configuration iff pi = n\u2212 n1 + i for every i \u2208 {1, . . . , n1}. Proposition 1. Let r = (r1, . . . , rn) be a binary vector of length n in right-most configuration such that n1 entries are 1. Let y\u0302 = (y\u03021, . . . , y\u0302n) be a vector of n real-valued guesses, ordered such that y\u0302i < y\u0302j \u21d0\u21d2 i < j. Then h(r, y\u0302) = 0.\nProof. Since r is in right-most configuration, it is clear that the right-hand side of h(r, y\u0302) = \u2211\ni\u2208L0(r) \u2211 j\u2208L1(r) I[i > j]\nsums to 0.\nProposition 2. Let y be a vector of n binary labels, and let z = \u03c3(y, j\u2032) be another vector of binary labels that is produced by a single left-swap of y at index j\u2032 \u2208 {2, . . . , n}, where yj\u2032 = 1 and yi\u2032 = 0, and i\u2032 = j\u2032\u22121. Let y\u0302 be a vector of real-valued guesses. Then the number of pairs misclassified by y\u0302 w.r.t. z is one more than the number of pairs misclassified by y\u0302 w.r.t. y \u2013 i.e., h(z, y\u0302) = h(y, y\u0302) + 1.\nProof. To shorten the notation, let L0 = L0(y),L1 = L1(y), and let L\u03030 = L0(z), L\u03031 = L1(z). We can split the summation in Equation 2 into four sets of pairs (see Figure 1): (a) those involving neither i\u2032 nor j\u2032; (b) those involving j\u2032 but not i\u2032; (c) those involving i\u2032 but not j\u2032; and (d) the single pair involving both i\u2032 and j\u2032. By grouping the pairs this way, we obtain:\nh(z, y\u0302)\n=  \u2211 i\u2208\nL\u03030\\{j\u2032}\n\u2211 j\u2208\nL\u03031\\{i\u2032}\nI[i > j] +  \u2211\ni\u2208 L\u03030\\{j\u2032}\nI[i > i\u2032] +  \u2211\nj\u2208 L\u03031\\{i\u2032}\nI[j\u2032 > j] + I[j\u2032 > i\u2032] Notice that L\u03030 = (L0(y) \\ {i\u2032}) \u222a {j\u2032}, and hence L0(y) \\ {i\u2032} = L\u03030(z) \\ {j\u2032}. Similarly, L\u03031 \\ {i\u2032} = L1 \\ {j\u2032}. Then we have:\nh(z, y\u0302) = \u2211 i\u2208\nL0\\{i\u2032}\n\u2211 j\u2208\nL1\\{j\u2032}\nI[i > j] + \u2211 i\u2208\nL0\\{i\u2032}\nI[i > i\u2032] + \u2211 j\u2208\nL1\\{j\u2032}\nI[j\u2032 > j] + I[j\u2032 > i\u2032]\nSince i\u2032 + 1 = j\u2032, then there cannot exist any index i \u2208 L0 \\ {i\u2032} whose value is \u201cbetween\u201d i\u2032 and j\u2032; in other words, i > i\u2032 \u21d0\u21d2 i > j\u2032 for every i \u2208 L0 \\ {i\u2032}. Similarly, j\u2032 > j \u21d0\u21d2 i\u2032 > j for every j \u2208 L1 \\ {j\u2032}. Hence:\nh(z, y\u0302) = \u2211 i\u2208\nL0\\{i\u2032}\n\u2211 j\u2208\nL1\\{j\u2032}\nI[i > j] + \u2211 i\u2208\nL0\\{i\u2032}\nI[i > j\u2032] + \u2211 j\u2208\nL1\\{j\u2032}\nI[i\u2032 > j] + I[j\u2032 > i\u2032]\nFinally, since I[j\u2032 > i\u2032] = 1 and I[i\u2032 < j\u2032] = 0, then: h(z, y\u0302) = \u2211 i\u2208\nL0\\{i\u2032}\n\u2211 j\u2208\nL1\\{j\u2032}\nI[i > j] + \u2211 i\u2208\nL0\\{i\u2032}\nI[i > j\u2032] + \u2211 j\u2208\nL1\\{j\u2032}\nI[i\u2032 > j] + I[i\u2032 > j\u2032] + 1\n= h(y, y\u0302) + 1\nProposition 3. Suppose a dataset contains n examples, of which n1 are labeled 1 and n0 = n\u2212 n1 are labeled 0. Let Yn1 = {y \u2208 {0, 1}n : \u2211 i yi = n1}, and let Sn1 = {(s1, . . . , sn1) \u2208 Zn1 : n0 \u2265 s1 \u2265 . . . \u2265 sn1 \u2265 0}. Then Yn1 and Sn1 are in 1-to-1 correspondence.\nProof. Every binary vector y \u2208 Yn1 of length n, of which n1 entries are 1, can be described by a unique vector of integers in the set Pn1 = {(p1, . . . , pn1) \u2208 Z+ : 1 \u2264 p1 < . . . < pn1 \u2264 n} specifying the indices of the 1s in y in increasing order. In particular, Yn1 and Pn1 are in 1-to-1 correspondence with a bijection fp : Yn1 \u2192 Pn1 . Hence, if we can show a bijection fs : Pn1 \u2192 Sn1 , then we can compose fs with fp to yield a new function f : Yn1 \u2192 Sn1 ; since the composition of two bijections is bijective, then f will be bijective.\nWe can construct such an fs as follows:\nfs(p1, . . . , pn1) = (s1, . . . , sn1) where si = n\u2212 n1 + i\u2212 pi We must first show that (s1, . . . , sn1) = fs(p1, . . . , pn1) \u2208 Sn1 for every (p1, . . . , pn1) \u2208 Pn1 ; in particular, we must show that n0 \u2265 s1 \u2265 . . . \u2265 sn1 \u2265 0. Since every pi is an integer, we have that pj \u2212 pi \u2265 j \u2212 i for every j > i. Hence:\nn\u2212 n1 + pj \u2212 pi \u2265 n\u2212 n1 + j \u2212 i\nWe then add i to and subtract pj from both sides to obtain:\nn\u2212 n1 + i\u2212 pi \u2265 n\u2212 n1 + j \u2212 pj si \u2265 sj \u2200j > i\nThe two boundary cases are sn1 :\nsn1 = n\u2212 n1 + n1 \u2212 pn1 = n\u2212 pn1 \u2265 0\nand s1: s1 = n\u2212 n1 + 1\u2212 p1 = n0 + 1\u2212 p1 \u2264 n0\nfs is 1-to-1: Suppose (s1, . . . , sn1) = fs(p1, . . . , pn1) and (s\u20321, . . . , s\u2032n1) = fs(p \u2032 1, . . . , p \u2032 n1), and suppose si = s\u2032i for each i. Then:\nn\u2212 n1 + i\u2212 pi = n\u2212 n1 + i\u2212 p\u2032i (3) \u21d0\u21d2 (4)\npi = p \u2032 i (5)\nfor each i.\nfs is onto: For every (s1, . . . , sn1) \u2208 Sn1 , we can find (p1, . . . , pn1) such that fs(p1, . . . , pn1) = (s1, . . . , sn1) by setting pi = n\u2212 n1 + i\u2212 si for each i. It only remains to be shown that 1 \u2264 p1 < . . . < pn1 \u2264 n: For any j > i, pj \u2212 pi = j \u2212 i+ si \u2212 sj Since si \u2265 sj (by definition of Sn1 ), we have:\npj \u2212 pi \u2265 j \u2212 i > 0\nand hence pj > pi. Moreover,\np1 = n\u2212 n1 + 1\u2212 s1 \u2265 n\u2212 n1 + 1\u2212 n0 \u2265 1\nand\npn1 = n\u2212 n1 + n1 \u2212 sn1 \u2264 n\nTheorem 1. Suppose a dataset contains n examples, of which n1 are labeled 1 and n0 are labeled 0. Let Y(d)n1 = {y \u2208 {0, 1}n : \u2211 i yi = n1 \u2227 h(y, y\u0302) = d}, and let S (d) n1 = {(s1, . . . , sn1) \u2208 Zn1 :\nn0 \u2265 s1 \u2265 . . . \u2265 sn1 \u2265 0 \u2227 \u2211 i si = d}. Then Y (d) n1 and S (d) n1 are in 1-to-1 correspondence.\nProof. Since Y(d)n1 \u2282 Yn1 and S (d) n1 \u2282 Sn1 , and since Yn1 and Sn1 are in 1-to-1 correspondence with bijection f (from Proposition 3) then we must show only that the image of Y(d)n1 through f is S (d) n1 . Suppose that (s1, . . . , sn1) = f(y) for some y \u2208 Y (d) n1 . Then we can write y as\ny = \u03c1(\u03c1(. . . (\u03c1\ufe38 \ufe37\ufe37 \ufe38 n1 (r, n\u2212 n1 + 1, s1), n\u2212 n1 + 2, s2) . . .), n, sn1)\nIn other words, y \u2208 Y(d)n1 can be obtained from r (a binary vector of length n, such that n1 elements are labeled 1, in right-most configuration) by performing a sequence of consecutive left-swaps on\nthe 1s in r. To see this, observe that the first 1 in r is always immediately preceded by n0 0s; hence, we can perform s1 \u2264 n0 consecutive left-swaps on r from index n\u2212 n1 + 1. (See Figure 2 for an illustration.) Moreover, after performing these consecutive left-swaps, then the second 1 in r will be immediately preceded by s1 0s; hence, we can perform s2 \u2264 s1 consecutive left-swaps on r from index n\u2212 n1 + 2. After performing these consecutive left-swaps, then the third 1 in r will be immediately preceded by s2 0s; and so on. After performing the consecutive left-swaps for each of the 1s in r, then the position of the ith 1 in the resulting vector is n\u2212 n1 + i\u2212 si = pi for each i, as desired.\nNext, recall that, by Proposition 1, h(r, y\u0302) = 0. Moreover, by Proposition 2, each left-swap increases the value of h by 1; hence, applying \u03c1 to perform si consecutive left-swaps increases the value of h by si. Summing over all 1s results in a total of \u2211n1 i=1 si misclassified pairs, i.e.,\nh(y, y\u0302) = \u2211n1\ni=1 si. But since y \u2208 Y (d) n1 , we already know that h(y, y\u0302) = d. Therefore, \u2211 i si = d,\nand hence (s1, . . . , sn1) \u2208 Y (d) n1 .\nInterestingly, the set S(d)n1 is a discrete n1-dimensional simplex \u2206n1d that has been truncated by the additional constraint that n0 \u2265 s1 \u2265 . . . \u2265 sn1 ."}, {"heading": "4.1 Summing over all possible n1", "text": "Based on Theorem 1, we can compute the number, v(n0, n1, d), of binary vectors of length n = n0 + n1, such that n1 of the entries are labeled 1 and for which h(y, y\u0302) = d. Recall that the AUC can be computed by dividing the number d of misclassified pairs by the total number of example-pairs n0n1. Hence, to compute the total number, w(n, c), of binary vectors of length n for which AUC(y, y\u0302) = c, we must first determine the set N1 of possible values for n1, and then sum v(n0, n1, d) over every value in N1 and the corresponding value d. Suppose that the oracle reports an AUC of c = p/q, where p/q is a reduced fraction, Since c represents the fraction of all pairs of examples \u2013 one from each class \u2013 that are classified by the contestant\u2019s guesses correctly, then q must divide the total number (n0n1) of pairs in the test set. Hence:\nN1 = {n1 : (0 < n1 < n) \u2227 (q | (n\u2212 n1)n1)}\nSince it is possible that q < n0n1, we must scale (q \u2212 p) by n0n1/q to determine the actual number of misclassified pairs d. In particular, we define\nd(n1) = (q \u2212 p)n0n1/q = (q \u2212 p)(n\u2212 n1)n1/q\nBased on N1 and m, we can finally compute:\nw(n, c) = \u2223\u2223\u2223\u2223\u2223 \u22c3 n1\u2208N1 S(d(n1))n1 \u2223\u2223\u2223\u2223\u2223 = \u2211 n1\u2208N1 v(n\u2212 n1, n1, d(n1)) since the S(d(n1))n1 are disjoint."}, {"heading": "5 Recursion Relation", "text": "We can derive a recursion relation for v(n0, n1, d) as follows: Given any binary vector r of length n, with n1 1s, in right-most configuration, we can apply k \u2208 {0, 1, . . . ,min(d, n0)} left-swaps on r from index n\u2212 n1 + 1 (i.e., from the left-most 1) to yield y = \u03c1(r, n\u2212 n1 + 1, k). Then the vector (yn\u2212n1\u2212k+2, yn\u2212n1\u2212k+3, yn\u2212n1\u2212k+4, . . . , yn) (i.e., the last n1 \u2212 1 + k elements of y) consists of k 0s followed by (n1 \u2212 1) 1s; in other words, it is in right-most configuration. Thus, by iterating over all possible k and computing for each choice how many more left-swaps are necessary to reach a total of d, we can define v recursively:\nv(n0, n1, d) = min(d,n0)\u2211 k=0 v(k, n1 \u2212 1, d\u2212 k)\nwith initial conditions:\nv(n0, n1, 0) = 1 \u2200n0 \u2265 0, n1 \u2265 0 v(0, n1, d) = 0 \u2200n1 \u2265 0, d > 0 v(n0, 0, d) = 0 \u2200n0 \u2265 0, d > 0\nDynamic programming using a three-dimensional memoization table can be used to compute v in time O(n0n1d). Moreover, the recursive algorithm above can also be used constructively (though with large space costs) to compute the set of all binary vectors y of length n, of which n1 are 1, such that h(y, y\u0302) = d for any d; conceivably, this could be useful for performing some kind of attack that uses the set of all compatible binary ground-truth vectors to improve the contestant\u2019s accuracy (Whitehill, 2016). In order to apply this construction, the test examples must first be sorted in increasing value of the contestant\u2019s guesses; the constructive algorithm is then applied to generate all possible y; and then the components of each of the possible binary vectors must be reordered to recover the original order of the test examples.\n6 Growth of w(n, c) in n for fixed c\nWhitehill (2016) showed that, for every fixed rational c = p/q \u2208 (0, 1), the number of possible binary ground-truth vectors for which the contestant\u2019s guesses achieve AUC of exactly c, grows exponentially in n. However, their result applies only to datasets that are at least n = 4q in size. What can happen for smaller n?\nUsing the recursive formula from Section 5, we found empirical evidence thatw(n, c) may actually be (initially) monotonically decreasing in n, until n reaches a threshold (specific to q) at which it begins to increase again. As an example with p = 1387 and q = 1440 (and hence d = 1440\u2212 1387 = 53), we can compute the number of possible binary labelings that are compatible with an AUC of exactly c = p/q = 1387/1440 (which is approximately 96.3%) as a function of n:\nn N1 w(n, c) 76 {36, 40} 657488 77 {32, 45} 654344 78 {30, 48} 650822 84 {24, 60} 622952 92 {20, 72} 572728 98 {18, 80} 529382 106 {16, 90} 468686\nHere, w(n, c) decreases steadily until n = 106. We conjecture that w(n, c) is monotonically nonincreasing in n for n \u2264 min{n0 + n1 : n0n1 = 2q}, for every fixed c. While the number of satisfying solutions in this example for n = 106 is still in the hundreds of thousands, it is easily small enough to allow each possibility to be considered individually, e.g., as part of some algorithmic attack to maximize performance within a datamining competition (Whitehill, 2016). Furthermore, we note that test sets on the order of hundreds of examples are not uncommon \u2013 the 2017 Intel & MobileODT Cervical Cancer Screening is one example."}, {"heading": "7 Summary & Future Work", "text": "We have investigated the mathematical structure of how the Area Under the Receiver Operating Characteristics Curve (AUC) accuracy metric is computed from the binary vector of ground-truth labels and a real-valued vector of guesses. In particular, we derived an efficient recursive algorithm with which to count the exact number of binary vectors for which the AUC of a fixed vector of guesses is some value c; we also derived a constructive algorithm with which to enumerate all such binary vectors.\nIn future work it would be interesting to examine whether and how knowledge of the possible groundtruth labelings could be exploited to improve an existing vector of guesses; a simple mechanism\nwas proposed by Whitehill (2016), but it is practical only for tiny datasets. In addition, it would be useful to explore how multiple subsequent oracle queries might be used to prune the set of possible ground-truth labelings more rapidly."}], "references": [{"title": "Generalization bounds for the area under the ROC curve", "author": ["S. Agarwal", "T. Graepel", "R. Herbrich", "S. Har-Peled", "D. Roth"], "venue": "Journal of Machine Learning Research, 393\u2013425.", "citeRegEx": "Agarwal et al\\.,? 2005", "shortCiteRegEx": "Agarwal et al\\.", "year": 2005}, {"title": "The ladder: A reliable leaderboard for machine learning competitions", "author": ["A. Blum", "M. Hardt"], "venue": "arXiv preprint arXiv:1502.04585.", "citeRegEx": "Blum and Hardt,? 2015", "shortCiteRegEx": "Blum and Hardt", "year": 2015}, {"title": "A learning theory approach to noninteractive database privacy", "author": ["A. Blum", "K. Ligett", "A. Roth"], "venue": "Journal of the ACM (JACM) 60(2):12.", "citeRegEx": "Blum et al\\.,? 2013", "shortCiteRegEx": "Blum et al\\.", "year": 2013}, {"title": "Privacy-preserving logistic regression", "author": ["K. Chaudhuri", "C. Monteleoni"], "venue": "Advances in Neural Information Processing Systems, 289\u2013296.", "citeRegEx": "Chaudhuri and Monteleoni,? 2009", "shortCiteRegEx": "Chaudhuri and Monteleoni", "year": 2009}, {"title": "Preserving statistical validity in adaptive data analysis", "author": ["C. Dwork", "V. Feldman", "M. Hardt", "T. Pitassi", "O. Reingold", "A.L. Roth"], "venue": "Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing, 117\u2013126. ACM.", "citeRegEx": "Dwork et al\\.,? 2015", "shortCiteRegEx": "Dwork et al\\.", "year": 2015}, {"title": "Differential privacy", "author": ["C. Dwork"], "venue": "van Tilborg, H., and Jajodia, S., eds., Encyclopedia of Cryptography and Security. Springer US. 338\u2013340.", "citeRegEx": "Dwork,? 2011", "shortCiteRegEx": "Dwork", "year": 2011}, {"title": "Preventing false discovery in interactive data analysis is hard", "author": ["M. Hardt", "J. Ullman"], "venue": "Foundations of Computer Science (FOCS), 2014 IEEE 55th Annual Symposium on, 454\u2013463. IEEE.", "citeRegEx": "Hardt and Ullman,? 2014", "shortCiteRegEx": "Hardt and Ullman", "year": 2014}, {"title": "An examination of data confidentiality and disclosure issues related to publication of empirical roc curves", "author": ["G.J. Matthews", "O. Harel"], "venue": "Academic radiology 20(7):889\u2013896.", "citeRegEx": "Matthews and Harel,? 2013", "shortCiteRegEx": "Matthews and Harel", "year": 2013}, {"title": "Differentially private algorithms for empirical machine learning", "author": ["B. Stoddard", "Y. Chen", "A. Machanavajjhala"], "venue": "CoRR abs/1411.5428.", "citeRegEx": "Stoddard et al\\.,? 2014", "shortCiteRegEx": "Stoddard et al\\.", "year": 2014}, {"title": "Signal detection theory in the 2AFC paradigm: attention, channel uncertainty and probability summation", "author": ["C. Tyler", "Chen", "C.-C."], "venue": "Vision Research 40(22):3121\u20133144.", "citeRegEx": "Tyler et al\\.,? 2000", "shortCiteRegEx": "Tyler et al\\.", "year": 2000}, {"title": "Exploiting an oracle that reports AUC scores in machine learning contests", "author": ["J. Whitehill"], "venue": "AAAI, 1345\u20131351.", "citeRegEx": "Whitehill,? 2016", "shortCiteRegEx": "Whitehill", "year": 2016}, {"title": "Toward a better understanding of leaderboard", "author": ["W. Zheng"], "venue": "arXiv preprint arXiv:1510.03349.", "citeRegEx": "Zheng,? 2015", "shortCiteRegEx": "Zheng", "year": 2015}], "referenceMentions": [{"referenceID": 1, "context": "Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016).", "startOffset": 268, "endOffset": 344}, {"referenceID": 6, "context": "Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016).", "startOffset": 268, "endOffset": 344}, {"referenceID": 11, "context": "Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016).", "startOffset": 268, "endOffset": 344}, {"referenceID": 10, "context": "Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016).", "startOffset": 268, "endOffset": 344}, {"referenceID": 10, "context": "Recent research on privacy-preserving machine learning (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information on the accuracy of a contestant\u2019s guesses, returned to the contestant by an oracle, can divulge information about the test data\u2019s true labels.", "startOffset": 55, "endOffset": 107}, {"referenceID": 1, "context": "Recent research on privacy-preserving machine learning (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information on the accuracy of a contestant\u2019s guesses, returned to the contestant by an oracle, can divulge information about the test data\u2019s true labels.", "startOffset": 55, "endOffset": 107}, {"referenceID": 11, "context": "Recent research on privacy-preserving machine learning (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information on the accuracy of a contestant\u2019s guesses, returned to the contestant by an oracle, can divulge information about the test data\u2019s true labels.", "startOffset": 55, "endOffset": 107}, {"referenceID": 1, "context": "Recent research on privacy-preserving machine learning (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information on the accuracy of a contestant\u2019s guesses, returned to the contestant by an oracle, can divulge information about the test data\u2019s true labels. Such oracles are often provided by the organizers of the competition themselves. For example, in the 2017 Intel & MobileODT Cervical Cancer Screening competition1 hosted by Kaggle, every contestant can submit her/his guesses up to 5 times per day, and for each submission the oracle returns the log-loss of the guesses with respect to the ground-truth values of the entire 512-element test set. The contestant can use the accuracy information to improve (hopefully) the classifier design and then re-submit. AUC: For binary classification problems, one of the most commonly used accuracy metrics is the Area Under the Receiver Operating Characteristics Curve (AUC). In contrast to other accuracy metrics such as log-loss and 0/1 loss, which can be computed as the sum of example-wise losses over each example in the test set, the AUC statistic is computed over all possible pairs of test examples, such that each pair contains one example from each class. In a recent paper, Whitehill (2016) showed that an oracle that provides contestants with information on the AUC of their guesses can inadvertently divulge information on the ground-truth labels of the test examples.", "startOffset": 73, "endOffset": 1269}, {"referenceID": 4, "context": "Related work: Over the past few years there has been growing theoretical and practical interest in the statistical validity of scientific results that are obtained from adaptive data analyses, in which the results of one experiment inform the design of the next (Dwork et al., 2015; Hardt and Ullman, 2014).", "startOffset": 262, "endOffset": 306}, {"referenceID": 6, "context": "Related work: Over the past few years there has been growing theoretical and practical interest in the statistical validity of scientific results that are obtained from adaptive data analyses, in which the results of one experiment inform the design of the next (Dwork et al., 2015; Hardt and Ullman, 2014).", "startOffset": 262, "endOffset": 306}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015).", "startOffset": 238, "endOffset": 273}, {"referenceID": 11, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015).", "startOffset": 238, "endOffset": 273}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution.", "startOffset": 239, "endOffset": 312}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset.", "startOffset": 239, "endOffset": 882}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset.", "startOffset": 239, "endOffset": 915}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset.", "startOffset": 239, "endOffset": 946}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. The AUC statistic, in particular, has been investigated in the context of privacy: Stoddard, Chen, and Machanavajjhala (2014) proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics.", "startOffset": 239, "endOffset": 1223}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. The AUC statistic, in particular, has been investigated in the context of privacy: Stoddard, Chen, and Machanavajjhala (2014) proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics. Matthews and Harel (2013) showed how an attacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an empirical ROC curve, i.", "startOffset": 239, "endOffset": 1337}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. The AUC statistic, in particular, has been investigated in the context of privacy: Stoddard, Chen, and Machanavajjhala (2014) proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics. Matthews and Harel (2013) showed how an attacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an empirical ROC curve, i.e., a set of classifier thresholds and corresponding true positive and false positive rates. The prior work most similar to ours is by Whitehill (2016). They showed a weak form of lower bound on the number of possible binary ground-truth vectors y \u2208 {0, 1} for which the contestant\u2019s guesses \u0177 achieve any fixed AUC c.", "startOffset": 239, "endOffset": 1640}, {"referenceID": 1, "context": "Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. The AUC statistic, in particular, has been investigated in the context of privacy: Stoddard, Chen, and Machanavajjhala (2014) proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics. Matthews and Harel (2013) showed how an attacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an empirical ROC curve, i.e., a set of classifier thresholds and corresponding true positive and false positive rates. The prior work most similar to ours is by Whitehill (2016). They showed a weak form of lower bound on the number of possible binary ground-truth vectors y \u2208 {0, 1} for which the contestant\u2019s guesses \u0177 achieve any fixed AUC c. Specifically, for every AUC value c = p/q \u2208 (0, 1), there exists an infinite sequence of dataset sizes (n = 4q, 8q, 12q, . . .) such that the number of satisfying ground-truth vectors y \u2208 {0, 1} grows exponentially in n. However, this result does not preclude the possibility that there might be certain pathological cases \u2013 combinations of p, q, n0, and n1 \u2013 for which the number of satisfying ground-truth vectors is actually much smaller. Conceivably, there might be values of n that lie between integer multiples of 4q for which the number of satisfying solutions is small. Moreover, the lower bound in Whitehill (2016) applies only to datasets that contain at least 4q examples and says nothing about smaller (but possibly still substantial) datasets.", "startOffset": 239, "endOffset": 2431}, {"referenceID": 0, "context": "The AUC has two mathematically equivalent definitions (Tyler and Chen, 2000; Agarwal et al., 2005): (1) the AUC is the Area under the Receiver Operating Characteristics (ROC) curve, which plots the true positive rate against the false positive rate of a classifier on some test set.", "startOffset": 54, "endOffset": 98}, {"referenceID": 10, "context": "Moreover, the recursive algorithm above can also be used constructively (though with large space costs) to compute the set of all binary vectors y of length n, of which n1 are 1, such that h(y, \u0177) = d for any d; conceivably, this could be useful for performing some kind of attack that uses the set of all compatible binary ground-truth vectors to improve the contestant\u2019s accuracy (Whitehill, 2016).", "startOffset": 382, "endOffset": 399}, {"referenceID": 10, "context": ", as part of some algorithmic attack to maximize performance within a datamining competition (Whitehill, 2016).", "startOffset": 93, "endOffset": 110}], "year": 2017, "abstractText": "Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016). For binary classification tasks in particular, one of the most common accuracy metrics is the Area Under the ROC Curve (AUC), and in this paper we explore the mathematical structure of how the AUC is computed from an n-vector of real-valued \u201cguesses\u201d with respect to the ground-truth labels. We show how knowledge of a classifier\u2019s AUC on the test set can constrain the set of possible ground-truth labelings, and we derive an algorithm both to compute the exact number of such labelings and to enumerate efficiently over them. Finally, we provide empirical evidence that, surprisingly, the number of compatible labelings can actually decrease as n grows, until a test set-dependent threshold is reached.", "creator": "LaTeX with hyperref package"}}}